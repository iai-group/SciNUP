{"id": "0708.0522", "contents": "Title: Quasi-stationary distributions as centrality measures of reducible\n  graphs Abstract: Random walk can be used as a centrality measure of a directed graph. However,\nif the graph is reducible the random walk will be absorbed in some subset of\nnodes and will never visit the rest of the graph. In Google PageRank the\nproblem was solved by introduction of uniform random jumps with some\nprobability. Up to the present, there is no clear criterion for the choice this\nparameter. We propose to use parameter-free centrality measure which is based\non the notion of quasi-stationary distribution. Specifically we suggest four\nquasi-stationary based centrality measures, analyze them and conclude that they\nproduce approximately the same ranking. The new centrality measures can be\napplied in spam detection to detect ``link farms'' and in image search to find\nphoto albums. \n\n"}
{"id": "0708.1859", "contents": "Title: Multiple-Description Coding by Dithered Delta-Sigma Quantization Abstract: We address the connection between the multiple-description (MD) problem and\nDelta-Sigma quantization. The inherent redundancy due to oversampling in\nDelta-Sigma quantization, and the simple linear-additive noise model resulting\nfrom dithered lattice quantization, allow us to construct a symmetric and\ntime-invariant MD coding scheme. We show that the use of a noise shaping filter\nmakes it possible to trade off central distortion for side distortion.\nAsymptotically as the dimension of the lattice vector quantizer and order of\nthe noise shaping filter approach infinity, the entropy rate of the dithered\nDelta-Sigma quantization scheme approaches the symmetric two-channel MD\nrate-distortion function for a memoryless Gaussian source and MSE fidelity\ncriterion, at any side-to-central distortion ratio and any resolution. In the\noptimal scheme, the infinite-order noise shaping filter must be minimum phase\nand have a piece-wise flat power spectrum with a single jump discontinuity. An\nimportant advantage of the proposed design is that it is symmetric in rate and\ndistortion by construction, so the coding rates of the descriptions are\nidentical and there is therefore no need for source splitting. \n\n"}
{"id": "0708.3699", "contents": "Title: Convolutional Entanglement Distillation Abstract: We develop a theory of entanglement distillation that exploits a\nconvolutional coding structure. We provide a method for converting an arbitrary\nclassical binary or quaternary convolutional code into a convolutional\nentanglement distillation protocol. The imported classical convolutional code\ndoes not have to be dual-containing or self-orthogonal. The yield and\nerror-correcting properties of such a protocol depend respectively on the rate\nand error-correcting properties of the imported classical convolutional code. A\nconvolutional entanglement distillation protocol has several other benefits.\nTwo parties sharing noisy ebits can distill noiseless ebits ``online'' as they\nacquire more noisy ebits. Distillation yield is high and decoding complexity is\nsimple for a convolutional entanglement distillation protocol. Our theory of\nconvolutional entanglement distillation reduces the problem of finding a good\nconvolutional entanglement distillation protocol to the well-established\nproblem of finding a good classical convolutional code. \n\n"}
{"id": "0709.2833", "contents": "Title: Distributed Space Time Codes with Low Decoding Complexity for\n  Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time code (DSTC) structure that admit its application in the\nproposed transmission scheme are identified and it is pointed out that the\nrecently proposed full diversity four group decodable DSTCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time codes applicable in this new transmission scheme for\npower of two number of relays are also provided. \n\n"}
{"id": "0710.5161", "contents": "Title: Decomposable Subspaces, Linear Sections of Grassmann Varieties, and\n  Higher Weights of Grassmann Codes Abstract: Given a homogeneous component of an exterior algebra, we characterize those\nsubspaces in which every nonzero element is decomposable. In geometric terms,\nthis corresponds to characterizing the projective linear subvarieties of the\nGrassmann variety with its Plucker embedding. When the base field is finite, we\nconsider the more general question of determining the maximum number of points\non sections of Grassmannians by linear subvarieties of a fixed (co)dimension.\nThis corresponds to a known open problem of determining the complete weight\nhierarchy of linear error correcting codes associated to Grassmann varieties.\nWe recover most of the known results as well as prove some new results. In the\nprocess we obtain, and utilize, a simple generalization of the Griesmer-Wei\nbound for arbitrary linear codes. \n\n"}
{"id": "0711.3629", "contents": "Title: Convolutional codes from units in matrix and group rings Abstract: A general method for constructing convolutional codes from units in Laurent\nseries over matrix rings is presented. Using group ring as matrix rings, this\nforms a basis for in-depth exploration of convolutional codes from group ring\nencoding, wherein the ring in the group ring is itself a group ring. The method\nis used to algebraically construct series of convolutional codes. Algebraic\nmethods are used to compute free distances and to construct convolutional codes\nto prescribed distances. \n\n"}
{"id": "0711.3983", "contents": "Title: Self-dual, dual-containing and related quantum codes from group rings Abstract: Classes of self-dual codes and dual-containing codes are constructed. The\ncodes are obtained within group rings and, using an isomorphism between group\nrings and matrices, equivalent codes are obtained in matrix form. Distances and\nother properties are derived by working within the group ring. Quantum codes\nare constructed from the dual-containing codes. \n\n"}
{"id": "0712.2384", "contents": "Title: Multi-group ML Decodable Collocated and Distributed Space Time Block\n  Codes Abstract: In this paper, collocated and distributed space-time block codes (DSTBCs)\nwhich admit multi-group maximum likelihood (ML) decoding are studied. First the\ncollocated case is considered and the problem of constructing space-time block\ncodes (STBCs) which optimally tradeoff rate and ML decoding complexity is\nposed. Recently, sufficient conditions for multi-group ML decodability have\nbeen provided in the literature and codes meeting these sufficient conditions\nwere called Clifford Unitary Weight (CUW) STBCs. An algebraic framework based\non extended Clifford algebras is proposed to study CUW STBCs and using this\nframework, the optimal tradeoff between rate and ML decoding complexity of CUW\nSTBCs is obtained for few specific cases. Code constructions meeting this\ntradeoff optimally are also provided. The paper then focuses on multi-group ML\ndecodable DSTBCs for application in synchronous wireless relay networks and\nthree constructions of four-group ML decodable DSTBCs are provided. Finally,\nthe OFDM based Alamouti space-time coded scheme proposed by Li-Xia for a 2\nrelay asynchronous relay network is extended to a more general transmission\nscheme that can achieve full asynchronous cooperative diversity for arbitrary\nnumber of relays. It is then shown how differential encoding at the source can\nbe combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Four-group decodable DSTBCs applicable in\nthe proposed OFDM based transmission scheme are also given. \n\n"}
{"id": "0804.0036", "contents": "Title: Complexity and algorithms for computing Voronoi cells of lattices Abstract: In this paper we are concerned with finding the vertices of the Voronoi cell\nof a Euclidean lattice. Given a basis of a lattice, we prove that computing the\nnumber of vertices is a #P-hard problem. On the other hand we describe an\nalgorithm for this problem which is especially suited for low dimensional (say\ndimensions at most 12) and for highly-symmetric lattices. We use our\nimplementation, which drastically outperforms those of current computer algebra\nsystems, to find the vertices of Voronoi cells and quantizer constants of some\nprominent lattices. \n\n"}
{"id": "0804.0611", "contents": "Title: Channel State Feedback Schemes for Multiuser MIMO-OFDM Downlink Abstract: Channel state feedback schemes for the MIMO broadcast downlink have been\nwidely studied in the frequency-flat case. This work focuses on the more\nrelevant frequency selective case, where some important new aspects emerge. We\nconsider a MIMO-OFDM broadcast channel and compare achievable ergodic rates\nunder three channel state feedback schemes: analog feedback, direction\nquantized feedback and \"time-domain\" channel quantized feedback. The first two\nschemes are direct extensions of previously proposed schemes. The third scheme\nis novel, and it is directly inspired by rate-distortion theory of Gaussian\ncorrelated sources. For each scheme we derive the conditions under which the\nsystem achieves full multiplexing gain. The key difference with respect to the\nwidely treated frequency-flat case is that in MIMO-OFDM the frequency-domain\nchannel transfer function is a Gaussian correlated source. The new time-domain\nquantization scheme takes advantage of the channel frequency correlation\nstructure and outperforms the other schemes. Furthermore, it is by far simpler\nto implement than complicated spherical vector quantization. In particular, we\nobserve that no structured codebook design and vector quantization is actually\nneeded for efficient channel state information feedback. \n\n"}
{"id": "0804.0980", "contents": "Title: Large MIMO Detection: A Low-Complexity Detector at High Spectral\n  Efficiencies Abstract: We consider large MIMO systems, where by `{\\em large}' we mean number of\ntransmit and receive antennas of the order of tens to hundreds. Such large MIMO\nsystems will be of immense interest because of the very high spectral\nefficiencies possible in such systems. We present a low-complexity detector\nwhich achieves uncoded near-exponential diversity performance for hundreds of\nantennas (i.e., achieves near SISO AWGN performance in a large MIMO fading\nenvironment) with an average per-bit complexity of just $O(N_tN_r)$, where\n$N_t$ and $N_r$ denote the number of transmit and receive antennas,\nrespectively. With an outer turbo code, the proposed detector achieves good\ncoded bit error performance as well. For example, in a 600 transmit and 600\nreceive antennas V-BLAST system with a high spectral efficiency of 200 bps/Hz\n(using BPSK and rate-1/3 turbo code), our simulation results show that the\nproposed detector performs close to within about 4.6 dB from theoretical\ncapacity. We also adopt the proposed detector for the low-complexity decoding\nof high-rate non-orthogonal space-time block codes (STBC) from division\nalgebras (DA). For example, we have decoded the $16\\times 16$ full-rate\nnon-orthogonal STBC from DA using the proposed detector and show that it\nperforms close to within about 5.5 dB of the capacity using 4-QAM and rate-3/4\nturbo code at a spectral efficiency of 24 bps/Hz. The practical feasibility of\nthe proposed high-performance low-complexity detector could potentially trigger\nwide interest in the implementation of large MIMO systems. In large MC-CDMA\nsystems with hundreds of users, the proposed detector is shown to achieve near\nsingle-user performance at an average per-bit complexity linear in number of\nusers, which is quite appealing for its use in practical CDMA systems. \n\n"}
{"id": "0804.3784", "contents": "Title: On the metric distortion of nearest-neighbour graphs on random point\n  sets Abstract: We study the graph constructed on a Poisson point process in $d$ dimensions\nby connecting each point to the $k$ points nearest to it. This graph a.s. has\nan infinite cluster if $k > k_c(d)$ where $k_c(d)$, known as the critical\nvalue, depends only on the dimension $d$. This paper presents an improved upper\nbound of 188 on the value of $k_c(2)$. We also show that if $k \\geq 188$ the\ninfinite cluster of $\\NN(2,k)$ has an infinite subset of points with the\nproperty that the distance along the edges of the graphs between these points\nis at most a constant multiplicative factor larger than their Euclidean\ndistance. Finally we discuss in detail the relevance of our results to the\nstudy of multi-hop wireless sensor networks. \n\n"}
{"id": "0806.3650", "contents": "Title: Recursive Code Construction for Random Networks Abstract: A modification of Koetter-Kschischang codes for random networks is presented\n(these codes were also studied by Wang et al. in the context of authentication\nproblems). The new codes have higher information rate, while maintaining the\nsame error-correcting capabilities. An efficient error-correcting algorithm is\nproposed for these codes. \n\n"}
{"id": "0806.4200", "contents": "Title: The Secrecy Rate Region of the Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers, while a wire-tapper\nalso receives the transmitted signal. This model is motivated by wireless\ncommunications, where individual secure messages are broadcast over open media\nand can be received by any illegitimate receiver. The secrecy level is measured\nby equivocation rate at the eavesdropper. We first study the general\n(non-degraded) broadcast channel with confidential messages. We present an\ninner bound on the secrecy capacity region for this model. The inner bound\ncoding scheme is based on a combination of random binning and the\nGelfand-Pinsker bining. This scheme matches the Marton's inner bound on the\nbroadcast channel without confidentiality constraint. We further study the\nsituation where the channels are degraded. For the degraded broadcast channel\nwith confidential messages, we present the secrecy capacity region. Our\nachievable coding scheme is based on Cover's superposition scheme and random\nbinning. We refer to this scheme as Secret Superposition Scheme. In this\nscheme, we show that randomization in the first layer increases the secrecy\nrate of the second layer. This capacity region matches the capacity region of\nthe degraded broadcast channel without security constraint. It also matches the\nsecrecy capacity for the conventional wire-tap channel. Our converse proof is\nbased on a combination of the converse proof of the conventional degraded\nbroadcast channel and Csiszar lemma. Finally, we assume that the channels are\nAdditive White Gaussian Noise (AWGN) and show that secret superposition scheme\nwith Gaussian codebook is optimal. The converse proof is based on the\ngeneralized entropy power inequality. \n\n"}
{"id": "0808.0234", "contents": "Title: DMT of Multi-hop Cooperative Networks - Part I: Basic Results Abstract: In this two-part paper, the DMT of cooperative multi-hop networks is\nexamined. The focus is on single-source single-sink (ss-ss) multi-hop relay\nnetworks having slow-fading links and relays that potentially possess multiple\nantennas. The present paper examines the two end-points of the DMT of\nfull-duplex networks. In particular, the maximum achievable diversity of\narbitrary multi-terminal wireless networks is shown to be equal to the min-cut.\nThe maximum multiplexing gain of arbitrary full-duplex ss-ss networks is shown\nto be equal to the min-cut rank, using a new connection to a deterministic\nnetwork. We also prove some basic results including a proof that the colored\nnoise encountered in AF protocols for cooperative networks can be treated as\nwhite noise for DMT computations. The DMT of a parallel channel with\nindependent MIMO links is also computed here. As an application of these basic\nresults, we prove that a linear tradeoff between maximum diversity and maximum\nmultiplexing gain is achievable for full-duplex networks with single antenna\nnodes. All protocols in this paper are explicit and rely only upon\namplify-and-forward (AF) relaying. Half duplex networks are studied, and\nexplicit codes for all protocols proposed in both parts, are provided in the\ncompanion paper. \n\n"}
{"id": "0808.0948", "contents": "Title: Capacity of a Class of Diamond Channels Abstract: We study a special class of diamond channels which was introduced by Schein\nin 2001. In this special class, each diamond channel consists of a transmitter,\na noisy relay, a noiseless relay and a receiver. We prove the capacity of this\nclass of diamond channels by providing an achievable scheme and a converse. The\ncapacity we show is strictly smaller than the cut-set bound. Our result also\nshows the optimality of a combination of decode-and-forward (DAF) and\ncompress-and-forward (CAF) at the noisy relay node. This is the first example\nwhere a combination of DAF and CAF is shown to be capacity achieving. Finally,\nwe note that there exists a duality between this diamond channel coding problem\nand the Kaspi-Berger source coding problem. \n\n"}
{"id": "0808.1368", "contents": "Title: On some deterministic dictionaries supporting sparsity Abstract: We describe a new construction of an incoherent dictionary, referred to as\nthe oscillator dictionary, which is based on considerations in the\nrepresentation theory of finite groups. The oscillator dictionary consists of\norder of p^5 unit vectors in a Hilbert space of dimension p, where p is an odd\nprime, whose pairwise inner products have magnitude of at most 4/sqrt(p). An\nexplicit algorithm to construct a large portion of the oscillator dictionary is\npresented. \n\n"}
{"id": "0809.1366", "contents": "Title: Network Coding Security: Attacks and Countermeasures Abstract: By allowing intermediate nodes to perform non-trivial operations on packets,\nsuch as mixing data from multiple streams, network coding breaks with the\nruling store and forward networking paradigm and opens a myriad of challenging\nsecurity questions. Following a brief overview of emerging network coding\nprotocols, we provide a taxonomy of their security vulnerabilities, which\nhighlights the differences between attack scenarios in which network coding is\nparticularly vulnerable and other relevant cases in which the intrinsic\nproperties of network coding allow for stronger and more efficient security\nsolutions than classical routing. Furthermore, we give practical examples where\nnetwork coding can be combined with classical cryptography both for secure\ncommunication and secret key distribution. Throughout the paper we identify a\nnumber of research challenges deemed relevant towards the applicability of\nsecure network coding in practical networks. \n\n"}
{"id": "0809.3540", "contents": "Title: A Note on the Equivalence of Gibbs Free Energy and Information Theoretic\n  Capacity Abstract: The minimization of Gibbs free energy is based on the changes in work and\nfree energy that occur in a physical or chemical system. The maximization of\nmutual information, the capacity, of a noisy channel is determined based on the\nmarginal probabilities and conditional entropies associated with a\ncommunications system. As different as the procedures might first appear,\nthrough the exploration of a simple, \"dual use\" Ising model, it is seen that\nthe two concepts are in fact the same. In particular, the case of a binary\nsymmetric channel is calculated in detail. \n\n"}
{"id": "0810.1808", "contents": "Title: A Central Limit Theorem for the SINR at the LMMSE Estimator Output for\n  Large Dimensional Signals Abstract: This paper is devoted to the performance study of the Linear Minimum Mean\nSquared Error estimator for multidimensional signals in the large dimension\nregime. Such an estimator is frequently encountered in wireless communications\nand in array processing, and the Signal to Interference and Noise Ratio (SINR)\nat its output is a popular performance index. The SINR can be modeled as a\nrandom quadratic form which can be studied with the help of large random matrix\ntheory, if one assumes that the dimension of the received and transmitted\nsignals go to infinity at the same pace. This paper considers the asymptotic\nbehavior of the SINR for a wide class of multidimensional signal models that\nincludes general multi-antenna as well as spread spectrum transmission models.\n  The expression of the deterministic approximation of the SINR in the large\ndimension regime is recalled and the SINR fluctuations around this\ndeterministic approximation are studied. These fluctuations are shown to\nconverge in distribution to the Gaussian law in the large dimension regime, and\ntheir variance is shown to decrease as the inverse of the signal dimension. \n\n"}
{"id": "0810.2336", "contents": "Title: A Mordell Inequality for Lattices over Maximal Orders Abstract: In this paper we prove an analogue of Mordell's inequality for lattices in\nfinite-dimensional complex or quaternionic Hermitian space that are modules\nover a maximal order in an imaginary quadratic number field or a totally\ndefinite rational quaternion algebra. This inequality implies that the\n16-dimensional Barnes-Wall lattice has optimal density among all 16-dimensional\nlattices with Hurwitz structures. \n\n"}
{"id": "0810.4658", "contents": "Title: Indexability of Restless Bandit Problems and Optimality of Whittle's\n  Index for Dynamic Multichannel Access Abstract: We consider a class of restless multi-armed bandit problems (RMBP) that\narises in dynamic multichannel access, user/server scheduling, and optimal\nactivation in multi-agent systems. For this class of RMBP, we establish the\nindexability and obtain Whittle's index in closed-form for both discounted and\naverage reward criteria. These results lead to a direct implementation of\nWhittle's index policy with remarkably low complexity. When these Markov chains\nare stochastically identical, we show that Whittle's index policy is optimal\nunder certain conditions. Furthermore, it has a semi-universal structure that\nobviates the need to know the Markov transition probabilities. The optimality\nand the semi-universal structure result from the equivalency between Whittle's\nindex policy and the myopic policy established in this work. For non-identical\nchannels, we develop efficient algorithms for computing a performance upper\nbound given by Lagrangian relaxation. The tightness of the upper bound and the\nnear-optimal performance of Whittle's index policy are illustrated with\nsimulation examples. \n\n"}
{"id": "0811.0196", "contents": "Title: Reduced-Complexity Reed--Solomon Decoders Based on Cyclotomic FFTs Abstract: In this paper, we reduce the computational complexities of partial and dual\npartial cyclotomic FFTs (CFFTs), which are discrete Fourier transforms where\nspectral and temporal components are constrained, based on their properties as\nwell as a common subexpression elimination algorithm. Our partial CFFTs achieve\nsmaller computational complexities than previously proposed partial CFFTs.\nUtilizing our CFFTs in both transform- and time-domain Reed--Solomon decoders,\nwe achieve significant complexity reductions. \n\n"}
{"id": "0812.0319", "contents": "Title: Secrecy Capacity of a Class of Broadcast Channels with an Eavesdropper Abstract: We study the security of communication between a single transmitter and\nmultiple receivers in a broadcast channel in the presence of an eavesdropper.\nWe consider several special classes of channels. As the first model, we\nconsider the degraded multi-receiver wiretap channel where the legitimate\nreceivers exhibit a degradedness order while the eavesdropper is more noisy\nwith respect to all legitimate receivers. We establish the secrecy capacity\nregion of this channel model. Secondly, we consider the parallel multi-receiver\nwiretap channel with a less noisiness order in each sub-channel, where this\norder is not necessarily the same for all sub-channels. We establish the common\nmessage secrecy capacity and sum secrecy capacity of this channel. Thirdly, we\nstudy a special class of degraded parallel multi-receiver wiretap channels and\nprovide a stronger result. In particular, we study the case with two\nsub-channels two users and one eavesdropper, where there is a degradedness\norder in each sub-channel such that in the first (resp. second) sub-channel the\nsecond (resp. first) receiver is degraded with respect to the first (resp.\nsecond) receiver, while the eavesdropper is degraded with respect to both\nlegitimate receivers in both sub-channels. We determine the secrecy capacity\nregion of this channel. Finally, we focus on a variant of this previous channel\nmodel where the transmitter can use only one of the sub-channels at any time.\nWe characterize the secrecy capacity region of this channel as well. \n\n"}
{"id": "0812.4889", "contents": "Title: Statistical Physics of Signal Estimation in Gaussian Noise: Theory and\n  Examples of Phase Transitions Abstract: We consider the problem of signal estimation (denoising) from a statistical\nmechanical perspective, using a relationship between the minimum mean square\nerror (MMSE), of estimating a signal, and the mutual information between this\nsignal and its noisy version. The paper consists of essentially two parts. In\nthe first, we derive several statistical-mechanical relationships between a few\nimportant quantities in this problem area, such as the MMSE, the differential\nentropy, the Fisher information, the free energy, and a generalized notion of\ntemperature. We also draw analogies and differences between certain relations\npertaining to the estimation problem and the parallel relations in\nthermodynamics and statistical physics. In the second part of the paper, we\nprovide several application examples, where we demonstrate how certain analysis\ntools that are customary in statistical physics, prove useful in the analysis\nof the MMSE. In most of these examples, the corresponding\nstatistical-mechanical systems turn out to consist of strong interactions that\ncause phase transitions, which in turn are reflected as irregularities and\ndiscontinuities (similar to threshold effects) in the behavior of the MMSE. \n\n"}
{"id": "0901.0044", "contents": "Title: Information Inequalities for Joint Distributions, with Interpretations\n  and Applications Abstract: Upper and lower bounds are obtained for the joint entropy of a collection of\nrandom variables in terms of an arbitrary collection of subset joint entropies.\nThese inequalities generalize Shannon's chain rule for entropy as well as\ninequalities of Han, Fujishige and Shearer. A duality between the upper and\nlower bounds for joint entropy is developed. All of these results are shown to\nbe special cases of general, new results for submodular functions-- thus, the\ninequalities presented constitute a richly structured class of Shannon-type\ninequalities. The new inequalities are applied to obtain new results in\ncombinatorics, such as bounds on the number of independent sets in an arbitrary\ngraph and the number of zero-error source-channel codes, as well as new\ndeterminantal inequalities in matrix theory. A new inequality for relative\nentropies is also developed, along with interpretations in terms of hypothesis\ntesting. Finally, revealing connections of the results to literature in\neconomics, computer science, and physics are explored. \n\n"}
{"id": "0901.1869", "contents": "Title: Low-Complexity Near-ML Decoding of Large Non-Orthogonal STBCs Using PDA Abstract: Non-orthogonal space-time block codes (STBC) from cyclic division algebras\n(CDA) having large dimensions are attractive because they can simultaneously\nachieve both high spectral efficiencies (same spectral efficiency as in V-BLAST\nfor a given number of transmit antennas) {\\em as well as} full transmit\ndiversity. Decoding of non-orthogonal STBCs with hundreds of dimensions has\nbeen a challenge. In this paper, we present a probabilistic data association\n(PDA) based algorithm for decoding non-orthogonal STBCs with large dimensions.\nOur simulation results show that the proposed PDA-based algorithm achieves near\nSISO AWGN uncoded BER as well as near-capacity coded BER (within about 5 dB of\nthe theoretical capacity) for large non-orthogonal STBCs from CDA. We study the\neffect of spatial correlation on the BER, and show that the performance loss\ndue to spatial correlation can be alleviated by providing more receive spatial\ndimensions. We report good BER performance when a training-based iterative\ndecoding/channel estimation is used (instead of assuming perfect channel\nknowledge) in channels with large coherence times. A comparison of the\nperformances of the PDA algorithm and the likelihood ascent search (LAS)\nalgorithm (reported in our recent work) is also presented. \n\n"}
{"id": "0901.1936", "contents": "Title: A Lower Bound on the Capacity of Wireless Erasure Networks with Random\n  Node Locations Abstract: In this paper, a lower bound on the capacity of wireless ad hoc erasure\nnetworks is derived in closed form in the canonical case where $n$ nodes are\nuniformly and independently distributed in the unit area square. The bound\nholds almost surely and is asymptotically tight. We assume all nodes have fixed\ntransmit power and hence two nodes should be within a specified distance $r_n$\nof each other to overcome noise. In this context, interference determines\noutages, so we model each transmitter-receiver pair as an erasure channel with\na broadcast constraint, i.e. each node can transmit only one signal across all\nits outgoing links. A lower bound of $\\Theta(n r_n)$ for the capacity of this\nclass of networks is derived. If the broadcast constraint is relaxed and each\nnode can send distinct signals on distinct outgoing links, we show that the\ngain is a function of $r_n$ and the link erasure probabilities, and is at most\na constant if the link erasure probabilities grow sufficiently large with $n$.\nFinally, the case where the erasure probabilities are themselves random\nvariables, for example due to randomness in geometry or channels, is analyzed.\nWe prove somewhat surprisingly that in this setting, variability in erasure\nprobabilities increases network capacity. \n\n"}
{"id": "0903.1022", "contents": "Title: On-Off Random Access Channels: A Compressed Sensing Framework Abstract: This paper considers a simple on-off random multiple access channel, where n\nusers communicate simultaneously to a single receiver over m degrees of\nfreedom. Each user transmits with probability lambda, where typically lambda n\n< m << n, and the receiver must detect which users transmitted. We show that\nwhen the codebook has i.i.d. Gaussian entries, detecting which users\ntransmitted is mathematically equivalent to a certain sparsity detection\nproblem considered in compressed sensing. Using recent sparsity results, we\nderive upper and lower bounds on the capacities of these channels. We show that\ncommon sparsity detection algorithms, such as lasso and orthogonal matching\npursuit (OMP), can be used as tractable multiuser detection schemes and have\nsignificantly better performance than single-user detection. These methods do\nachieve some near-far resistance but--at high signal-to-noise ratios\n(SNRs)--may achieve capacities far below optimal maximum likelihood detection.\nWe then present a new algorithm, called sequential OMP, that illustrates that\niterative detection combined with power ordering or power shaping can\nsignificantly improve the high SNR performance. Sequential OMP is analogous to\nsuccessive interference cancellation in the classic multiple access channel.\nOur results thereby provide insight into the roles of power control and\nmultiuser detection on random-access signalling. \n\n"}
{"id": "0903.3131", "contents": "Title: Matrix Completion With Noise Abstract: On the heels of compressed sensing, a remarkable new field has very recently\nemerged. This field addresses a broad range of problems of significant\npractical interest, namely, the recovery of a data matrix from what appears to\nbe incomplete, and perhaps even corrupted, information. In its simplest form,\nthe problem is to recover a matrix from a small sample of its entries, and\ncomes up in many areas of science and engineering including collaborative\nfiltering, machine learning, control, remote sensing, and computer vision to\nname a few.\n  This paper surveys the novel literature on matrix completion, which shows\nthat under some suitable conditions, one can recover an unknown low-rank matrix\nfrom a nearly minimal set of entries by solving a simple convex optimization\nproblem, namely, nuclear-norm minimization subject to data constraints.\nFurther, this paper introduces novel results showing that matrix completion is\nprovably accurate even when the few observed entries are corrupted with a small\namount of noise. A typical result is that one can recover an unknown n x n\nmatrix of low rank r from just about nr log^2 n noisy samples with an error\nwhich is proportional to the noise level. We present numerical results which\ncomplement our quantitative analysis and show that, in practice, nuclear norm\nminimization accurately fills in the many missing entries of large low-rank\nmatrices from just a few noisy samples. Some analogies between matrix\ncompletion and compressed sensing are discussed throughout. \n\n"}
{"id": "0904.1281", "contents": "Title: Asymptotically Optimal Joint Source-Channel Coding with Minimal Delay Abstract: We present and analyze a joint source-channel coding strategy for the\ntransmission of a Gaussian source across a Gaussian channel in n channel uses\nper source symbol. Among all such strategies, our scheme has the following\nproperties: i) the resulting mean-squared error scales optimally with the\nsignal-to-noise ratio, and ii) the scheme is easy to implement and the incurred\ndelay is minimal, in the sense that a single source symbol is encoded at a\ntime. \n\n"}
{"id": "0905.2341", "contents": "Title: Differential approach for the study of duals of algebraic-geometric\n  codes on surfaces Abstract: The purpose of the present article is the study of duals of functional codes\non algebraic surfaces. We give a direct geometrical description of them, using\ndifferentials. Even if this geometrical description is less trivial, it can be\nregarded as a natural extension to surfaces of the result asserting that the\ndual of a functional code on a curve is a differential code. We study the\nparameters of such codes and state a lower bound for their minimum distance.\nUsing this bound, one can study some examples of codes on surfaces, and in\nparticular surfaces with Picard number 1 like elliptic quadrics or some\nparticular cubic surfaces. The parameters of some of the studied codes reach\nthose of the best known codes up to now. \n\n"}
{"id": "0905.3360", "contents": "Title: A Generalized Statistical Complexity Measure: Applications to Quantum\n  Systems Abstract: A two-parameter family of complexity measures $\\tilde{C}^{(\\alpha,\\beta)}$\nbased on the R\\'enyi entropies is introduced and characterized by a detailed\nstudy of its mathematical properties. This family is the generalization of a\ncontinuous version of the LMC complexity, which is recovered for $\\alpha=1$ and\n$\\beta=2$. These complexity measures are obtained by multiplying two quantities\nbringing global information on the probability distribution defining the\nsystem. When one of the parameters, $\\alpha$ or $\\beta$, goes to infinity, one\nof the global factors becomes a local factor. For this special case, the\ncomplexity is calculated on different quantum systems: H-atom, harmonic\noscillator and square well. \n\n"}
{"id": "0905.3689", "contents": "Title: Optimized Training and Feedback for MIMO Downlink Channels Abstract: We consider a MIMO fading broadcast channel where channel state information\nis acquired at user terminals via downlink training and channel feedback is\nused to provide transmitter channel state information (CSIT) to the base\nstation. The feedback channel (the corresponding uplink) is modeled as an AWGN\nchannel, orthogonal across users. The total bandwidth consumed is the sum of\nthe bandwidth/resources used for downlink training, channel feedback, and data\ntransmission. Assuming that the channel follows a block fading model and that\nzeroforcing beamforming is used, we optimize the net achievable rate for\nunquantized (analog) and quantized (digital) channel feedback. The optimal\nnumber of downlink training pilots is seen to be essentially the same for both\nfeedback techniques, but digital feedback is shown to provide a larger net rate\nthan analog feedback. \n\n"}
{"id": "0906.0997", "contents": "Title: Division Algebras and Wireless Communication Abstract: We survey the recent use of division algebras in wireless communication. \n\n"}
{"id": "0906.3667", "contents": "Title: A Deterministic Equivalent for the Analysis of Correlated MIMO Multiple\n  Access Channels Abstract: In this article, novel deterministic equivalents for the Stieltjes transform\nand the Shannon transform of a class of large dimensional random matrices are\nprovided. These results are used to characterise the ergodic rate region of\nmultiple antenna multiple access channels, when each point-to-point propagation\nchannel is modelled according to the Kronecker model. Specifically, an\napproximation of all rates achieved within the ergodic rate region is derived\nand an approximation of the linear precoders that achieve the boundary of the\nrate region as well as an iterative water-filling algorithm to obtain these\nprecoders are provided. An original feature of this work is that the proposed\ndeterministic equivalents are proved valid even for strong correlation patterns\nat both communication sides. The above results are validated by Monte Carlo\nsimulations. \n\n"}
{"id": "0907.0505", "contents": "Title: Multi-User MISO Interference Channels with Single-User Detection:\n  Optimality of Beamforming and the Achievable Rate Region Abstract: For a multi-user interference channel with multi-antenna transmitters and\nsingle-antenna receivers, by restricting each transmitter to Gaussian input and\neach receiver to a single-user detector, computing the largest achievable rate\nregion amounts to solving a family of non-convex optimization problems.\nRecognizing the intrinsic connection between the signal power at the intended\nreceiver and the interference power at the unintended receiver, the original\nfamily of non-convex optimization problems is converted into a new family of\nconvex optimization problems. It is shown that, for such interference channels\nwith each receiver implementing single-user detection, transmitter beamforming\ncan achieve all boundary points of the achievable rate region. \n\n"}
{"id": "0907.5402", "contents": "Title: Optimal Scheduling for Fair Resource Allocation in Ad Hoc Networks with\n  Elastic and Inelastic Traffic Abstract: This paper studies the problem of congestion control and scheduling in ad hoc\nwireless networks that have to support a mixture of best-effort and real-time\ntraffic. Optimization and stochastic network theory have been successful in\ndesigning architectures for fair resource allocation to meet long-term\nthroughput demands. However, to the best of our knowledge, strict packet delay\ndeadlines were not considered in this framework previously. In this paper, we\npropose a model for incorporating the quality of service (QoS) requirements of\npackets with deadlines in the optimization framework. The solution to the\nproblem results in a joint congestion control and scheduling algorithm which\nfairly allocates resources to meet the fairness objectives of both elastic and\ninelastic flows, and per-packet delay requirements of inelastic flows. \n\n"}
{"id": "0908.0856", "contents": "Title: Outage Capacity of Incremental Relaying at Low Signal-to-Noise Ratios Abstract: We present the \\epsilon-outage capacity of incremental relaying at low\nsignal-to-noise ratios (SNR) in a wireless cooperative network with slow\nRayleigh fading channels. The relay performs decode-and-forward and repetition\ncoding is employed in the network, which is optimal in the low SNR regime. We\nderive an expression on the optimal relay location that maximizes the\n\\epsilon-outage capacity. It is shown that this location is independent of the\noutage probability and SNR but only depends on the channel conditions\nrepresented by a path-loss factor. We compare our results to the\n\\epsilon-outage capacity of the cut-set bound and demonstrate that the ratio\nbetween the \\epsilon-outage capacity of incremental relaying and the cut-set\nbound lies within 1/\\sqrt{2} and 1. Furthermore, we derive lower bounds on the\n\\epsilon-outage capacity for the case of K relays. \n\n"}
{"id": "0908.2282", "contents": "Title: Real Interference Alignment: Exploiting the Potential of Single Antenna\n  Systems Abstract: In this paper, the available spatial Degrees-Of-Freedoms (DOF) in single\nantenna systems is exploited. A new coding scheme is proposed in which several\ndata streams having fractional multiplexing gains are sent by transmitters and\ninterfering streams are aligned at receivers. Viewed as a field over rational\nnumbers, a received signal has infinite fractional DOFs, allowing simultaneous\ninterference alignment of any finite number of signals at any finite number of\nreceivers. The coding scheme is backed up by a recent result in the field of\nDiophantine approximation, which states that the convergence part of the\nKhintchine-Groshev theorem holds for points on non-degenerate manifolds. The\nproposed coding scheme is proved to be optimal for three communication\nchannels, namely the Gaussian Interference Channel (GIC), the uplink channel in\ncellular systems, and the $X$ channel. It is proved that the total DOF of the\n$K$-user GIC is $\\frac{K}{2}$ almost surely, i.e. each user enjoys half of its\nmaximum DOF. Having $K$ cells and $M$ users within each cell in a cellular\nsystem, the total DOF of the uplink channel is proved to be $\\frac{KM}{M+1}$.\nFinally, the total DOF of the $X$ channel with $K$ transmitters and $M$\nreceivers is shown to be $\\frac{KM}{K+M-1}$. \n\n"}
{"id": "0908.3512", "contents": "Title: The Infinite-message Limit of Two-terminal Interactive Source Coding Abstract: A two-terminal interactive function computation problem with alternating\nmessages is studied within the framework of distributed block source coding\ntheory. For any finite number of messages, a single-letter characterization of\nthe sum-rate-distortion function was established in previous works using\nstandard information-theoretic techniques. This, however, does not provide a\nsatisfactory characterization of the infinite-message limit, which is a new,\nunexplored dimension for asymptotic-analysis in distributed block source coding\ninvolving potentially an infinite number of infinitesimal-rate messages. In\nthis paper, the infinite-message sum-rate-distortion function, viewed as a\nfunctional of the joint source pmf and the distortion levels, is characterized\nas the least element of a partially ordered family of functionals having\ncertain convex-geometric properties. The new characterization does not involve\nevaluating the infinite-message limit of a finite-message sum-rate-distortion\nexpression. This characterization leads to a family of lower bounds for the\ninfinite-message sum-rate-distortion expression and a simple criterion to test\nthe optimality of any achievable infinite-message sum-rate-distortion\nexpression. For computing the amplewise Boolean AND function, the\ninfinite-message minimum sum-rates are characterized in closed analytic form.\nThese sum-rates are shown to be achievable using infinitely many\ninfinitesimal-rate messages. The new convex-geometric characterization is used\nto develop an iterative algorithm for evaluating any finite-message\nsumrate-distortion function. It is also used to construct the first examples\nwhich demonstrate that for lossy source reproduction, two messages can strictly\nimprove the one-message Wyner-Ziv rate-distortion function settling an\nunresolved question from a 1985 paper. \n\n"}
{"id": "0909.1115", "contents": "Title: Capacity Region of Layered Erasure One-sided Interference Channels\n  without CSIT Abstract: This paper studies a layered erasure interference channel model, which is a\nsimplification of the Gaussian interference channel with fading using the\ndeterministic model approach. In particular, the capacity region of the layered\nerasure one-sided interference channel is completely determined, assuming that\nthe channel state information (CSI) is known to the receivers, but there is no\nCSI at transmitters (CSIT). The result holds for arbitrary fading statistics.\nPrevious results of Aggarwal, Sankar, Calderbank and Poor on the capacity\nregion or sum capacity under several interference configurations are shown to\nbe special cases of the capacity region shown in this paper. \n\n"}
{"id": "0909.4575", "contents": "Title: Randomness Efficient Steganography Abstract: Steganographic protocols enable one to embed covert messages into\ninconspicuous data over a public communication channel in such a way that no\none, aside from the sender and the intended receiver, can even detect the\npresence of the secret message. In this paper, we provide a new\nprovably-secure, private-key steganographic encryption protocol secure in the\nframework of Hopper et al. We first present a \"one-time stegosystem\" that\nallows two parties to transmit messages of length at most that of the shared\nkey with information-theoretic security guarantees. The employment of a\npseudorandom generator (PRG) permits secure transmission of longer messages in\nthe same way that such a generator allows the use of one-time pad encryption\nfor messages longer than the key in symmetric encryption. The advantage of our\nconstruction, compared to all previous work is randomness efficiency: in the\ninformation theoretic setting our protocol embeds a message of length n bits\nusing a shared secret key of length (1+o(1))n bits while achieving security\n2^{-n/log^{O(1)}n}; simply put this gives a rate of key over message that is 1\nas n tends to infinity (the previous best result achieved a constant rate\ngreater than 1 regardless of the security offered). In this sense, our protocol\nis the first truly randomness efficient steganographic system. Furthermore, in\nour protocol, we can permit a portion of the shared secret key to be public\nwhile retaining precisely n private key bits. In this setting, by separating\nthe public and the private randomness of the shared key, we achieve security of\n2^{-n}. Our result comes as an effect of the application of randomness\nextractors to stegosystem design. To the best of our knowledge this is the\nfirst time extractors have been applied in steganography. \n\n"}
{"id": "0909.4876", "contents": "Title: A Program in Dialectical Rough Set Theory Abstract: A dialectical rough set theory focussed on the relation between roughly\nequivalent objects and classical objects was introduced in \\cite{AM699} by the\npresent author. The focus of our investigation is on elucidating the minimal\nconditions on the nature of granularity, underlying semantic domain and nature\nof the general rough set theories (RST) involved for possible extension of the\nsemantics to more general RST on a paradigm. On this basis we also formulate a\nprogram in dialectical rough set theory. The dialectical approach provides\nbetter semantics in many difficult cases and helps in formalising a wide\nvariety of concepts and notions that remain untamed at meta levels in the usual\napproaches. This is a brief version of a more detailed forthcoming paper by the\npresent author. \n\n"}
{"id": "0910.0575", "contents": "Title: A Note on Functional Averages over Gaussian Ensembles Abstract: In this work we find a new formula for matrix averages over the Gaussian\nensemble. Let ${\\bf H}$ be an $n\\times n$ Gaussian random matrix with complex,\nindependent, and identically distributed entries of zero mean and unit\nvariance. Given an $n\\times n$ positive definite matrix ${\\bf A}$, and a\ncontinuous function $f:\\R^{+}\\to\\R$ such that $\\int_{0}^{\\infty}{e^{-\\alpha\nt}|f(t)|^2\\,dt}<\\infty$ for every $\\alpha>0$, we find a new formula for the\nexpectation $\\E[\\mathrm{Tr}(f({\\bf HAH^{*}}))]$. Taking $f(x)=\\log(1+x)$ gives\nanother formula for the capacity of the MIMO communication channel, and taking\n$f(x)=(1+x)^{-1}$ gives the MMSE achieved by a linear receiver. \n\n"}
{"id": "0911.0519", "contents": "Title: Xampling: Signal Acquisition and Processing in Union of Subspaces Abstract: We introduce Xampling, a unified framework for signal acquisition and\nprocessing of signals in a union of subspaces. The main functions of this\nframework are two. Analog compression that narrows down the input bandwidth\nprior to sampling with commercial devices. A nonlinear algorithm then detects\nthe input subspace prior to conventional signal processing. A representative\nunion model of spectrally-sparse signals serves as a test-case to study these\nXampling functions. We adopt three metrics for the choice of analog\ncompression: robustness to model mismatch, required hardware accuracy and\nsoftware complexities. We conduct a comprehensive comparison between two\nsub-Nyquist acquisition strategies for spectrally-sparse signals, the random\ndemodulator and the modulated wideband converter (MWC), in terms of these\nmetrics and draw operative conclusions regarding the choice of analog\ncompression. We then address lowrate signal processing and develop an algorithm\nfor that purpose that enables convenient signal processing at sub-Nyquist rates\nfrom samples obtained by the MWC. We conclude by showing that a variety of\nother sampling approaches for different union classes fit nicely into our\nframework. \n\n"}
{"id": "0911.1388", "contents": "Title: Binary Non-tiles Abstract: A subset V of GF(2)^n is a tile if GF(2)^n can be covered by disjoint\ntranslates of V. In other words, V is a tile if and only if there is a subset A\nof GF(2)^n such that V+A = GF(2)^n uniquely (i.e., v + a = v' + a' implies that\nv=v' and a=a' where v,v' in V and a,a' in A). In some problems in coding theory\nand hashing we are given a putative tile V, and wish to know whether or not it\nis a tile. In this paper we give two computational criteria for certifying that\nV is not a tile. The first involves impossibility of a bin-packing problem, and\nthe second involves infeasibility of a linear program. We apply both criteria\nto a list of putative tiles given by Gordon, Miller, and Ostapenko in that none\nof them are, in fact, tiles. \n\n"}
{"id": "0911.1745", "contents": "Title: Sequence Folding, Lattice Tiling, and Multidimensional Coding Abstract: Folding a sequence $S$ into a multidimensional box is a well-known method\nwhich is used as a multidimensional coding technique. The operation of folding\nis generalized in a way that the sequence $S$ can be folded into various shapes\nand not just a box. The new definition of folding is based on a lattice tiling\nfor the given shape $\\cS$ and a direction in the $D$-dimensional integer grid.\nNecessary and sufficient conditions that a lattice tiling for $\\cS$ combined\nwith a direction define a folding of a sequence into $\\cS$ are derived. The\nimmediate and most impressive application is some new lower bounds on the\nnumber of dots in two-dimensional synchronization patterns. This can be also\ngeneralized for multidimensional synchronization patterns. The technique and\nits application for two-dimensional synchronization patterns, raise some\ninteresting problems in discrete geometry. We will also discuss these problems.\nIt is also shown how folding can be used to construct multidimensional\nerror-correcting codes. Finally, by using the new definition of folding,\nmultidimensional pseudo-random arrays with various shapes are generated. \n\n"}
{"id": "0911.2053", "contents": "Title: Interference Mitigation Through Limited Receiver Cooperation Abstract: Interference is a major issue limiting the performance in wireless networks.\nCooperation among receivers can help mitigate interference by forming\ndistributed MIMO systems. The rate at which receivers cooperate, however, is\nlimited in most scenarios. How much interference can one bit of receiver\ncooperation mitigate? In this paper, we study the two-user Gaussian\ninterference channel with conferencing decoders to answer this question in a\nsimple setting. We identify two regions regarding the gain from receiver\ncooperation: linear and saturation regions. In the linear region receiver\ncooperation is efficient and provides a degrees-of-freedom gain, which is\neither one cooperation bit buys one more bit or two cooperation bits buy one\nmore bit until saturation. In the saturation region receiver cooperation is\ninefficient and provides a power gain, which is at most a constant regardless\nof the rate at which receivers cooperate. The conclusion is drawn from the\ncharacterization of capacity region to within two bits. The proposed strategy\nconsists of two parts: (1) the transmission scheme, where superposition\nencoding with a simple power split is employed, and (2) the cooperative\nprotocol, where one receiver quantize-bin-and-forwards its received signal, and\nthe other after receiving the side information decode-bin-and-forwards its\nreceived signal. \n\n"}
{"id": "0911.4207", "contents": "Title: An information theoretic approach to statistical dependence: copula\n  information Abstract: We discuss the connection between information and copula theories by showing\nthat a copula can be employed to decompose the information content of a\nmultivariate distribution into marginal and dependence components, with the\nlatter quantified by the mutual information. We define the information excess\nas a measure of deviation from a maximum entropy distribution. The idea of\nmarginal invariant dependence measures is also discussed and used to show that\nempirical linear correlation underestimates the amplitude of the actual\ncorrelation in the case of non-Gaussian marginals. The mutual information is\nshown to provide an upper bound for the asymptotic empirical log-likelihood of\na copula. An analytical expression for the information excess of T-copulas is\nprovided, allowing for simple model identification within this family. We\nillustrate the framework in a financial data set. \n\n"}
{"id": "0911.4222", "contents": "Title: Message Passing Algorithms for Compressed Sensing: II. Analysis and\n  Validation Abstract: In a recent paper, the authors proposed a new class of low-complexity\niterative thresholding algorithms for reconstructing sparse signals from a\nsmall set of linear measurements \\cite{DMM}. The new algorithms are broadly\nreferred to as AMP, for approximate message passing. This is the second of two\nconference papers describing the derivation of these algorithms, connection\nwith related literature, extensions of original framework, and new empirical\nevidence.\n  This paper describes the state evolution formalism for analyzing these\nalgorithms, and some of the conclusions that can be drawn from this formalism.\nWe carried out extensive numerical simulations to confirm these predictions. We\npresent here a few representative results. \n\n"}
{"id": "0911.4530", "contents": "Title: MIMO Z-Interference Channels: Capacity Under Strong and Noisy\n  Interference Abstract: The capacity regions of multiple-input multiple-output Gaussian\nZ-interference channels are established for the very strong interference and\naligned strong interference cases. The sum-rate capacity of such channels is\nestablished under noisy interference. These results generalize known results\nfor scalar Gaussian Z-interference channels. \n\n"}
{"id": "0911.5300", "contents": "Title: Improving zero-error classical communication with entanglement Abstract: Given one or more uses of a classical channel, only a certain number of\nmessages can be transmitted with zero probability of error. The study of this\nnumber and its asymptotic behaviour constitutes the field of classical\nzero-error information theory, the quantum generalisation of which has started\nto develop recently. We show that, given a single use of certain classical\nchannels, entangled states of a system shared by the sender and receiver can be\nused to increase the number of (classical) messages which can be sent with no\nchance of error. In particular, we show how to construct such a channel based\non any proof of the Bell-Kochen-Specker theorem. This is a new example of the\nuse of quantum effects to improve the performance of a classical task. We\ninvestigate the connection between this phenomenon and that of\n``pseudo-telepathy'' games. The use of generalised non-signalling correlations\nto assist in this task is also considered. In this case, a particularly elegant\ntheory results and, remarkably, it is sometimes possible to transmit\ninformation with zero-error using a channel with no unassisted zero-error\ncapacity. \n\n"}
{"id": "0911.5515", "contents": "Title: Finite Dimensional Statistical Inference Abstract: In this paper, we derive the explicit series expansion of the eigenvalue\ndistribution of various models, namely the case of non-central Wishart\ndistributions, as well as correlated zero mean Wishart distributions. The tools\nused extend those of the free probability framework, which have been quite\nsuccessful for high dimensional statistical inference (when the size of the\nmatrices tends to infinity), also known as free deconvolution. This\ncontribution focuses on the finite Gaussian case and proposes algorithmic\nmethods to compute the moments. Cases where asymptotic results fail to apply\nare also discussed. \n\n"}
{"id": "0912.1628", "contents": "Title: KF-CS: Compressive Sensing on Kalman Filtered Residual Abstract: We consider the problem of recursively reconstructing time sequences of\nsparse signals (with unknown and time-varying sparsity patterns) from a limited\nnumber of linear incoherent measurements with additive noise. The idea of our\nproposed solution, KF CS-residual (KF-CS) is to replace compressed sensing (CS)\non the observation by CS on the Kalman filtered (KF) observation residual\ncomputed using the previous estimate of the support. KF-CS error stability over\ntime is studied. Simulation comparisons with CS and LS-CS are shown. \n\n"}
{"id": "0912.1790", "contents": "Title: A Note on the Injection Distance Abstract: Koetter and Kschischang showed in [R. Koetter and F.R. Kschischang, \"Coding\nfor Errors and Erasures in Random Network Coding,\" IEEE Trans. Inform. Theory,\n{54(8), 2008] that the network coding counterpart of Gabidulin codes performs\nasymptotically optimal with respect to the subspace distance. Recently, Silva\nand Kschischang introduced in [D. Silva and F.R. Kschischang, \"On Metrics for\nError Correction in Network Coding,\" To appear in IEEE Trans. Inform. Theory,\nArXiv: 0805.3824v4[cs.IT], 2009] the injection distance to give a detailed\npicture of what happens in noncoherent network coding. We show that the above\ncodes are also asymptotically optimal with respect to this distance. \n\n"}
{"id": "0912.3029", "contents": "Title: Interference Alignment and a Noisy Interference Regime for Many-to-One\n  Interference Channels Abstract: We study the capacity of discrete memoryless many-to-one interference\nchannels, i.e., K user interference channels where only one receiver faces\ninterference. For a class of many-to-one interference channels, we identify a\nnoisy interference regime, i.e., a regime where random coding and treating\ninterference as noise achieves sum-capacity. Specializing our results to the\nGaussian MIMO many-to-one interference channel, which is a special case of the\nclass of channels considered, we obtain new capacity results. Firstly, we\nextend the noisy interference regime, previously studied for (many-to-one)\ninterference channels with average power constraints on the inputs, to a more\ngeneral class of inputs. This more general class includes the practical\nscenario of inputs being restricted to fixed finite-size constellations such as\nPSK or QAM. Secondly, we extend noisy interference results previously studied\nin SISO interference channels with full channel state information (CSI) at all\nnodes, to MIMO and parallel Gaussian many-to-one interference channels, and to\nfading Gaussian many-to-one interference channels without CSI at the\ntransmitters. While the many-to-one interference channel requires interference\nalignment, which in turn requires structured codes in general, we argue that in\nthe noisy interference regime, interference is implicitly aligned by random\ncoding irrespective of the input distribution. As a byproduct of our study, we\nidentify a second class of many-to-one interference channels (albeit\ndeterministic) where random coding is optimal (though interference is not\ntreated as noise). The optimality of random coding in this second class of\nchannels is due to an interference resolvability condition which precludes\ninterference alignment and hence obviates the need of structured codes. \n\n"}
{"id": "0912.3264", "contents": "Title: Random Access: An Information-Theoretic Perspective Abstract: This paper considers a random access system where each sender can be in two\nmodes of operation, active or not active, and where the set of active users is\navailable to a common receiver only. Active transmitters encode data into\nindependent streams of information, a subset of which are decoded by the\nreceiver, depending on the value of the collective interference. The main\ncontribution is to present an information-theoretic formulation of the problem\nwhich allows us to characterize, with a guaranteed gap to optimality, the rates\nthat can be achieved by different data streams.\n  Our results are articulated as follows. First, we exactly characterize the\ncapacity region of a two-user system assuming a binary-expansion deterministic\nchannel model. Second, we extend this result to a two-user additive white\nGaussian noise channel, providing an approximate characterization within\n$\\sqrt{3}/2$ bit of the actual capacity. Third, we focus on the symmetric\nscenario in which users are active with the same probability and subject to the\nsame received power constraint, and study the maximum achievable expected\nsum-rate, or throughput, for any number of users. In this case, for the\nsymmetric binary expansion deterministic channel (which is related to the\npacket collision model used in the networking literature), we show that a\nsimple coding scheme which does not employ superposition coding achieves the\nsystem throughput. This result also shows that the performance of slotted ALOHA\nsystems can be improved by allowing encoding rate adaptation at the\ntransmitters. For the symmetric additive white Gaussian noise channel, we\npropose a scheme that is within one bit of the system throughput for any value\nof the underlying parameters. \n\n"}
{"id": "0912.5537", "contents": "Title: Quantum Reverse Shannon Theorem Abstract: Dual to the usual noisy channel coding problem, where a noisy (classical or\nquantum) channel is used to simulate a noiseless one, reverse Shannon theorems\nconcern the use of noiseless channels to simulate noisy ones, and more\ngenerally the use of one noisy channel to simulate another. For channels of\nnonzero capacity, this simulation is always possible, but for it to be\nefficient, auxiliary resources of the proper kind and amount are generally\nrequired. In the classical case, shared randomness between sender and receiver\nis a sufficient auxiliary resource, regardless of the nature of the source, but\nin the quantum case the requisite auxiliary resources for efficient simulation\ndepend on both the channel being simulated, and the source from which the\nchannel inputs are coming. For tensor power sources (the quantum generalization\nof classical IID sources), entanglement in the form of standard ebits\n(maximally entangled pairs of qubits) is sufficient, but for general sources,\nwhich may be arbitrarily correlated or entangled across channel inputs,\nadditional resources, such as entanglement-embezzling states or backward\ncommunication, are generally needed. Combining existing and new results, we\nestablish the amounts of communication and auxiliary resources needed in both\nthe classical and quantum cases, the tradeoffs among them, and the loss of\nsimulation efficiency when auxiliary resources are absent or insufficient. In\nparticular we find a new single-letter expression for the excess forward\ncommunication cost of coherent feedback simulations of quantum channels (i.e.\nsimulations in which the sender retains what would escape into the environment\nin an ordinary simulation), on non-tensor-power sources in the presence of\nunlimited ebits but no other auxiliary resource. Our results on tensor power\nsources establish a strong converse to the entanglement-assisted capacity\ntheorem. \n\n"}
{"id": "1001.1026", "contents": "Title: On Network-Error Correcting Convolutional Codes under the BSC Edge Error\n  Model Abstract: Convolutional network-error correcting codes (CNECCs) are known to provide\nerror correcting capability in acyclic instantaneous networks within the\nnetwork coding paradigm under small field size conditions. In this work, we\ninvestigate the performance of CNECCs under the error model of the network\nwhere the edges are assumed to be statistically independent binary symmetric\nchannels, each with the same probability of error $p_e$($0\\leq p_e<0.5$). We\nobtain bounds on the performance of such CNECCs based on a modified generating\nfunction (the transfer function) of the CNECCs. For a given network, we derive\na mathematical condition on how small $p_e$ should be so that only single edge\nnetwork-errors need to be accounted for, thus reducing the complexity of\nevaluating the probability of error of any CNECC. Simulations indicate that\nconvolutional codes are required to possess different properties to achieve\ngood performance in low $p_e$ and high $p_e$ regimes. For the low $p_e$ regime,\nconvolutional codes with good distance properties show good performance. For\nthe high $p_e$ regime, convolutional codes that have a good \\textit{slope} (the\nminimum normalized cycle weight) are seen to be good. We derive a lower bound\non the slope of any rate $b/c$ convolutional code with a certain degree. \n\n"}
{"id": "1001.1386", "contents": "Title: On the List-Decodability of Random Linear Codes Abstract: For every fixed finite field $\\F_q$, $p \\in (0,1-1/q)$ and $\\epsilon > 0$, we\nprove that with high probability a random subspace $C$ of $\\F_q^n$ of dimension\n$(1-H_q(p)-\\epsilon)n$ has the property that every Hamming ball of radius $pn$\nhas at most $O(1/\\epsilon)$ codewords.\n  This answers a basic open question concerning the list-decodability of linear\ncodes, showing that a list size of $O(1/\\epsilon)$ suffices to have rate within\n$\\epsilon$ of the \"capacity\" $1-H_q(p)$. Our result matches up to constant\nfactors the list-size achieved by general random codes, and gives an\nexponential improvement over the best previously known list-size bound of\n$q^{O(1/\\epsilon)}$.\n  The main technical ingredient in our proof is a strong upper bound on the\nprobability that $\\ell$ random vectors chosen from a Hamming ball centered at\nthe origin have too many (more than $\\Theta(\\ell)$) vectors from their linear\nspan also belong to the ball. \n\n"}
{"id": "1001.1705", "contents": "Title: On the Pseudocodeword Redundancy Abstract: We define the AWGNC, BSC, and max-fractional pseudocodeword redundancy of a\ncode as the smallest number of rows in a parity-check matrix such that the\ncorresponding minimum pseudoweight is equal to the minimum Hamming distance. We\nshow that most codes do not have a finite pseudocodeword redundancy. We also\nprovide bounds on the pseudocodeword redundancy for some families of codes,\nincluding codes based on designs. \n\n"}
{"id": "1001.2767", "contents": "Title: Universally Optimal Privacy Mechanisms for Minimax Agents Abstract: A scheme that publishes aggregate information about sensitive data must\nresolve the trade-off between utility to information consumers and privacy of\nthe database participants. Differential privacy is a well-established\ndefinition of privacy--this is a universal guarantee against all attackers,\nwhatever their side-information or intent. In this paper, we present a\nuniversal treatment of utility based on the standard minimax rule from decision\ntheory (in contrast to the utility model in, which is Bayesian). In our model,\ninformation consumers are minimax (risk-averse) agents, each possessing some\nside-information about the query, and each endowed with a loss-function which\nmodels their tolerance to inaccuracies. Further, information consumers are\nrational in the sense that they actively combine information from the mechanism\nwith their side-information in a way that minimizes their loss. Under this\nassumption of rational behavior, we show that for every fixed count query, a\ncertain geometric mechanism is universally optimal for all minimax information\nconsumers. Additionally, our solution makes it possible to release query\nresults at multiple levels of privacy in a collusion-resistant manner. \n\n"}
{"id": "1001.3388", "contents": "Title: Approximate Privacy: PARs for Set Problems Abstract: In previous work (arXiv:0910.5714), we introduced the Privacy Approximation\nRatio (PAR) and used it to study the privacy of protocols for second-price\nVickrey auctions and Yao's millionaires problem. Here, we study the PARs of\nmultiple protocols for both the disjointness problem (in which two\nparticipants, each with a private subset of {1,...,k}, determine whether their\nsets are disjoint) and the intersection problem (in which the two participants,\neach with a private subset of {1,...,k}, determine the intersection of their\nprivate sets).\n  We show that the privacy, as measured by the PAR, provided by any protocol\nfor each of these problems is necessarily exponential (in k). We also consider\nthe ratio between the subjective PARs with respect to each player in order to\nshow that one protocol for each of these problems is significantly fairer than\nthe others (in the sense that it has a similarly bad effect on the privacy of\nboth players). \n\n"}
{"id": "1001.3403", "contents": "Title: Real Interference Alignment Abstract: In this paper, we show that the total Degrees-Of-Freedoms (DOF) of the\n$K$-user Gaussian Interference Channel (GIC) can be achieved by incorporating a\nnew alignment technique known as \\emph{real interference alignment}. This\ntechnique compared to its ancestor \\emph{vector interference alignment}\nperforms on a single real line and exploits the properties of real numbers to\nprovide optimal signaling. The real interference alignment relies on a new\ncoding scheme in which several data streams having fractional multiplexing\ngains are sent by transmitters and interfering streams are aligned at\nreceivers. The coding scheme is backed up by a recent result in the field of\nDiophantine approximation, which states that the convergence part of the\nKhintchine-Groshev theorem holds for points on non-degenerate manifolds. \n\n"}
{"id": "1002.1313", "contents": "Title: Half-Duplex Active Eavesdropping in Fast Fading Channels: A Block-Markov\n  Wyner Secrecy Encoding Scheme Abstract: In this paper we study the problem of half-duplex active eavesdropping in\nfast fading channels. The active eavesdropper is a more powerful adversary than\nthe classical eavesdropper. It can choose between two functional modes:\neavesdropping the transmission between the legitimate parties (Ex mode), and\njamming it (Jx mode) -- the active eavesdropper cannot function in full duplex\nmode. We consider a conservative scenario, when the active eavesdropper can\nchoose its strategy based on the legitimate transmitter-receiver pair's\nstrategy -- and thus the transmitter and legitimate receiver have to plan for\nthe worst. We show that conventional physical-layer secrecy approaches perform\npoorly (if at all), and we introduce a novel encoding scheme, based on very\nlimited and unsecured feedback -- the Block-Markov Wyner (BMW) encoding scheme\n-- which outperforms any schemes currently available. \n\n"}
{"id": "1002.2813", "contents": "Title: Distributed Rate Allocation for Wireless Networks Abstract: This paper develops a distributed algorithm for rate allocation in wireless\nnetworks that achieves the same throughput region as optimal centralized\nalgorithms. This cross-layer algorithm jointly performs medium access control\n(MAC) and physical-layer rate adaptation. The paper establishes that this\nalgorithm is throughput-optimal for general rate regions. In contrast to on-off\nscheduling, rate allocation enables optimal utilization of physical-layer\nschemes by scheduling multiple rate levels. The algorithm is based on local\nqueue-length information, and thus the algorithm is of significant practical\nvalue. The algorithm requires that each link can determine the global\nfeasibility of increasing its current data-rate. In many classes of networks,\nany one link's data-rate primarily impacts its neighbors and this impact decays\nwith distance. Hence, local exchanges can provide the information needed to\ndetermine feasibility. Along these lines, the paper discusses the potential use\nof existing physical-layer control messages to determine feasibility. This can\nbe considered as a technique analogous to carrier sensing in CSMA (Carrier\nSense Multiple Access) networks. An important application of this algorithm is\nin multiple-band multiple-radio throughput-optimal distributed scheduling for\nwhite-space networks. \n\n"}
{"id": "1002.4510", "contents": "Title: On linear $q$-ary completely regular codes with $\\rho=2$ and dual\n  antipodal Abstract: We characterize all linear $q$-ary completely regular codes with covering\nradius $\\rho=2$ when the dual codes are antipodal. These completely regular\ncodes are extensions of linear completely regular codes with covering radius 1,\nwhich are all classified. For $\\rho=2$, we give a list of all such codes known\nto us. This also gives the characterization of two weight linear antipodal\ncodes. \n\n"}
{"id": "1002.4935", "contents": "Title: Multiarray Signal Processing: Tensor decomposition meets compressed\n  sensing Abstract: We discuss how recently discovered techniques and tools from compressed\nsensing can be used in tensor decompositions, with a view towards modeling\nsignals from multiple arrays of multiple sensors. We show that with appropriate\nbounds on a measure of separation between radiating sources called coherence,\none could always guarantee the existence and uniqueness of a best rank-r\napproximation of the tensor representing the signal. We also deduce a\ncomputationally feasible variant of Kruskal's uniqueness condition, where the\ncoherence appears as a proxy for k-rank. Problems of sparsest recovery with an\ninfinite continuous dictionary, lowest-rank tensor representation, and blind\nsource separation are treated in a uniform fashion. The decomposition of the\nmeasurement tensor leads to simultaneous localization and extraction of\nradiating sources, in an entirely deterministic manner. \n\n"}
{"id": "1003.0064", "contents": "Title: Decoding by Sampling: A Randomized Lattice Algorithm for Bounded\n  Distance Decoding Abstract: Despite its reduced complexity, lattice reduction-aided decoding exhibits a\nwidening gap to maximum-likelihood (ML) performance as the dimension increases.\nTo improve its performance, this paper presents randomized lattice decoding\nbased on Klein's sampling technique, which is a randomized version of Babai's\nnearest plane algorithm (i.e., successive interference cancelation (SIC)). To\nfind the closest lattice point, Klein's algorithm is used to sample some\nlattice points and the closest among those samples is chosen. Lattice reduction\nincreases the probability of finding the closest lattice point, and only needs\nto be run once during pre-processing. Further, the sampling can operate very\nefficiently in parallel. The technical contribution of this paper is two-fold:\nwe analyze and optimize the decoding radius of sampling decoding resulting in\nbetter error performance than Klein's original algorithm, and propose a very\nefficient implementation of random rounding. Of particular interest is that a\nfixed gain in the decoding radius compared to Babai's decoding can be achieved\nat polynomial complexity. The proposed decoder is useful for moderate\ndimensions where sphere decoding becomes computationally intensive, while\nlattice reduction-aided decoding starts to suffer considerable loss. Simulation\nresults demonstrate near-ML performance is achieved by a moderate number of\nsamples, even if the dimension is as high as 32. \n\n"}
{"id": "1003.2606", "contents": "Title: Asymptotically-Optimal, Fast-Decodable, Full-Diversity STBCs Abstract: For a family/sequence of STBCs $\\mathcal{C}_1,\\mathcal{C}_2,\\dots$, with\nincreasing number of transmit antennas $N_i$, with rates $R_i$ complex symbols\nper channel use (cspcu), the asymptotic normalized rate is defined as $\\lim_{i\n\\to \\infty}{\\frac{R_i}{N_i}}$. A family of STBCs is said to be\nasymptotically-good if the asymptotic normalized rate is non-zero, i.e., when\nthe rate scales as a non-zero fraction of the number of transmit antennas, and\nthe family of STBCs is said to be asymptotically-optimal if the asymptotic\nnormalized rate is 1, which is the maximum possible value. In this paper, we\nconstruct a new class of full-diversity STBCs that have the least ML decoding\ncomplexity among all known codes for any number of transmit antennas $N>1$ and\nrates $R>1$ cspcu. For a large set of $\\left(R,N\\right)$ pairs, the new codes\nhave lower ML decoding complexity than the codes already available in the\nliterature. Among the new codes, the class of full-rate codes ($R=N$) are\nasymptotically-optimal and fast-decodable, and for $N>5$ have lower ML decoding\ncomplexity than all other families of asymptotically-optimal, fast-decodable,\nfull-diversity STBCs available in the literature. The construction of the new\nSTBCs is facilitated by the following further contributions of this paper:(i)\nFor $g > 1$, we construct $g$-group ML-decodable codes with rates greater than\none cspcu. These codes are asymptotically-good too. For $g>2$, these are the\nfirst instances of $g$-group ML-decodable codes with rates greater than $1$\ncspcu presented in the literature. (ii) We construct a new class of\nfast-group-decodable codes for all even number of transmit antennas and rates\n$1 < R \\leq 5/4$.(iii) Given a design with full-rank linear dispersion\nmatrices, we show that a full-diversity STBC can be constructed from this\ndesign by encoding the real symbols independently using only regular PAM\nconstellations. \n\n"}
{"id": "1003.2822", "contents": "Title: Innovation Rate Sampling of Pulse Streams with Application to Ultrasound\n  Imaging Abstract: Signals comprised of a stream of short pulses appear in many applications\nincluding bio-imaging and radar. The recent finite rate of innovation\nframework, has paved the way to low rate sampling of such pulses by noticing\nthat only a small number of parameters per unit time are needed to fully\ndescribe these signals. Unfortunately, for high rates of innovation, existing\nsampling schemes are numerically unstable. In this paper we propose a general\nsampling approach which leads to stable recovery even in the presence of many\npulses. We begin by deriving a condition on the sampling kernel which allows\nperfect reconstruction of periodic streams from the minimal number of samples.\nWe then design a compactly supported class of filters, satisfying this\ncondition. The periodic solution is extended to finite and infinite streams,\nand is shown to be numerically stable even for a large number of pulses. High\nnoise robustness is also demonstrated when the delays are sufficiently\nseparated. Finally, we process ultrasound imaging data using our techniques,\nand show that substantial rate reduction with respect to traditional ultrasound\nsampling schemes can be achieved. \n\n"}
{"id": "1003.5309", "contents": "Title: Gossip Algorithms for Distributed Signal Processing Abstract: Gossip algorithms are attractive for in-network processing in sensor networks\nbecause they do not require any specialized routing, there is no bottleneck or\nsingle point of failure, and they are robust to unreliable wireless network\nconditions. Recently, there has been a surge of activity in the computer\nscience, control, signal processing, and information theory communities,\ndeveloping faster and more robust gossip algorithms and deriving theoretical\nperformance guarantees. This article presents an overview of recent work in the\narea. We describe convergence rate results, which are related to the number of\ntransmitted messages and thus the amount of energy consumed in the network for\ngossiping. We discuss issues related to gossiping over wireless links,\nincluding the effects of quantization and noise, and we illustrate the use of\ngossip algorithms for canonical signal processing tasks including distributed\nestimation, source localization, and compression. \n\n"}
{"id": "1004.2648", "contents": "Title: Optimality and Approximate Optimality of Source-Channel Separation in\n  Networks Abstract: We consider the source-channel separation architecture for lossy source\ncoding in communication networks. It is shown that the separation approach is\noptimal in two general scenarios, and is approximately optimal in a third\nscenario. The two scenarios for which separation is optimal complement each\nother: the first is when the memoryless sources at source nodes are arbitrarily\ncorrelated, each of which is to be reconstructed at possibly multiple\ndestinations within certain distortions, but the channels in this network are\nsynchronized, orthogonal and memoryless point-to-point channels; the second is\nwhen the memoryless sources are mutually independent, each of which is to be\nreconstructed only at one destination within a certain distortion, but the\nchannels are general, including multi-user channels such as multiple access,\nbroadcast, interference and relay channels, possibly with feedback. The third\nscenario, for which we demonstrate approximate optimality of source-channel\nseparation, generalizes the second scenario by allowing each source to be\nreconstructed at multiple destinations with different distortions. For this\ncase, the loss from optimality by using the separation approach can be\nupper-bounded when a \"difference\" distortion measure is taken, and in the\nspecial case of quadratic distortion measure, this leads to universal constant\nbounds. \n\n"}
{"id": "1004.5157", "contents": "Title: Deriving Good LDPC Convolutional Codes from LDPC Block Codes Abstract: Low-density parity-check (LDPC) convolutional codes are capable of achieving\nexcellent performance with low encoding and decoding complexity. In this paper\nwe discuss several graph-cover-based methods for deriving families of\ntime-invariant and time-varying LDPC convolutional codes from LDPC block codes\nand show how earlier proposed LDPC convolutional code constructions can be\npresented within this framework. Some of the constructed convolutional codes\nsignificantly outperform the underlying LDPC block codes. We investigate some\npossible reasons for this \"convolutional gain,\" and we also discuss the ---\nmostly moderate --- decoder cost increase that is incurred by going from LDPC\nblock to LDPC convolutional codes. \n\n"}
{"id": "1006.3385", "contents": "Title: A Fixed Precoding Approach to Achieve the Degrees of Freedom in X\n  channel Abstract: This paper aims to provide a fixed precoding scheme to achieve the Degrees of\nFreedom DoF of the generalized ergodic X channel. This is achieved through\nusing the notion of ergodic interference alignment technique. Accordingly, in\nthe proposed method the transmitters do not require to know the full channel\nstate information, while this assumption is the integral part of existing\nmethods. Instead, a finite-rate feed-back channel is adequate to achieve the\nDoF. In other words, it is demonstrated that quantized versions of channel\ngains are adequate to achieve theDOF. To get an insight regarding the\nfunctionality of the proposed method, first we rely on finite field channel\nmodels, and then extend the terminology to more realistic cases, including\ndispersive fading channels in the presence of quantizer. Accordingly, in a\nRayliegh fading environment, it is shown a feedback rate of\n2log(p)+Theta(log(log(p))) can provide the DoF, where $p$ is the total transmit\npower. \n\n"}
{"id": "1006.5686", "contents": "Title: Geometric Approximations of Some Aloha-like Stability Regions Abstract: Most bounds on the stability region of Aloha give necessary and sufficient\nconditions for the stability of an arrival rate vector under a specific\ncontention probability (control) vector. But such results do not yield\neasy-to-check bounds on the overall Aloha stability region because they\npotentially require checking membership in an uncountably infinite number of\nsets parameterized by each possible control vector. In this paper we consider\nan important specific inner bound on Aloha that has this property of difficulty\nto check membership in the set. We provide ellipsoids (for which membership is\neasy-to-check) that we conjecture are inner and outer bounds on this set. We\nalso study the set of controls that stabilize a fixed arrival rate vector; this\nset is shown to be a convex set. \n\n"}
{"id": "1007.0528", "contents": "Title: Binary Independent Component Analysis with OR Mixtures Abstract: Independent component analysis (ICA) is a computational method for separating\na multivariate signal into subcomponents assuming the mutual statistical\nindependence of the non-Gaussian source signals. The classical Independent\nComponents Analysis (ICA) framework usually assumes linear combinations of\nindependent sources over the field of realvalued numbers R. In this paper, we\ninvestigate binary ICA for OR mixtures (bICA), which can find applications in\nmany domains including medical diagnosis, multi-cluster assignment, Internet\ntomography and network resource management. We prove that bICA is uniquely\nidentifiable under the disjunctive generation model, and propose a\ndeterministic iterative algorithm to determine the distribution of the latent\nrandom variables and the mixing matrix. The inverse problem concerning\ninferring the values of latent variables are also considered along with noisy\nmeasurements. We conduct an extensive simulation study to verify the\neffectiveness of the propose algorithm and present examples of real-world\napplications where bICA can be applied. \n\n"}
{"id": "1007.0563", "contents": "Title: Graphical Models as Block-Tree Graphs Abstract: We introduce block-tree graphs as a framework for deriving efficient\nalgorithms on graphical models. We define block-tree graphs as a\ntree-structured graph where each node is a cluster of nodes such that the\nclusters in the graph are disjoint. This differs from junction-trees, where two\nclusters connected by an edge always have at least one common node. When\ncompared to junction-trees, we show that constructing block-tree graphs is\nfaster, and finding optimal block-tree graphs has a much smaller search space.\nApplying our block-tree graph framework to graphical models, we show that, for\nsome graphs, e.g., grid graphs, using block-tree graphs for inference is\ncomputationally more efficient than using junction-trees. For graphical models\nwith boundary conditions, the block-tree graph framework transforms the\nboundary valued problem into an initial value problem. For Gaussian graphical\nmodels, the block-tree graph framework leads to a linear state-space\nrepresentation. Since exact inference in graphical models can be\ncomputationally intractable, we propose to use spanning block-trees to derive\napproximate inference algorithms. Experimental results show the improved\nperformance in using spanning block-trees versus using spanning trees for\napproximate estimation over Gaussian graphical models. \n\n"}
{"id": "1007.1253", "contents": "Title: Efficient Sketches for the Set Query Problem Abstract: We develop an algorithm for estimating the values of a vector x in R^n over a\nsupport S of size k from a randomized sparse binary linear sketch Ax of size\nO(k). Given Ax and S, we can recover x' with ||x' - x_S||_2 <= eps ||x -\nx_S||_2 with probability at least 1 - k^{-\\Omega(1)}. The recovery takes O(k)\ntime.\n  While interesting in its own right, this primitive also has a number of\napplications. For example, we can:\n  1. Improve the linear k-sparse recovery of heavy hitters in Zipfian\ndistributions with O(k log n) space from a (1+eps) approximation to a (1 +\no(1)) approximation, giving the first such approximation in O(k log n) space\nwhen k <= O(n^{1-eps}).\n  2. Recover block-sparse vectors with O(k) space and a (1+eps) approximation.\nPrevious algorithms required either omega(k) space or omega(1) approximation. \n\n"}
{"id": "1007.3706", "contents": "Title: Cooperative Convex Optimization in Networked Systems: Augmented\n  Lagrangian Algorithms with Directed Gossip Communication Abstract: We study distributed optimization in networked systems, where nodes cooperate\nto find the optimal quantity of common interest, x=x^\\star. The objective\nfunction of the corresponding optimization problem is the sum of private (known\nonly by a node,) convex, nodes' objectives and each node imposes a private\nconvex constraint on the allowed values of x. We solve this problem for generic\nconnected network topologies with asymmetric random link failures with a novel\ndistributed, decentralized algorithm. We refer to this algorithm as AL-G\n(augmented Lagrangian gossiping,) and to its variants as AL-MG (augmented\nLagrangian multi neighbor gossiping) and AL-BG (augmented Lagrangian broadcast\ngossiping.) The AL-G algorithm is based on the augmented Lagrangian dual\nfunction. Dual variables are updated by the standard method of multipliers, at\na slow time scale. To update the primal variables, we propose a novel,\nGauss-Seidel type, randomized algorithm, at a fast time scale. AL-G uses\nunidirectional gossip communication, only between immediate neighbors in the\nnetwork and is resilient to random link failures. For networks with reliable\ncommunication (i.e., no failures,) the simplified, AL-BG (augmented Lagrangian\nbroadcast gossiping) algorithm reduces communication, computation and data\nstorage cost. We prove convergence for all proposed algorithms and demonstrate\nby simulations the effectiveness on two applications: l_1-regularized logistic\nregression for classification and cooperative spectrum sensing for cognitive\nradio networks. \n\n"}
{"id": "1007.3808", "contents": "Title: Characterization of Graph-cover Pseudocodewords of Codes over $F_3$ Abstract: Linear-programming pseudocodewords play a pivotal role in our understanding\nof the linear-programming decoding algorithms. These pseudocodewords are known\nto be equivalent to the graph-cover pseudocodewords. The latter\npseudocodewords, when viewed as points in the multidimensional Euclidean space,\nlie inside a fundamental cone. This fundamental cone depends on the choice of a\nparity-check matrix of a code, rather than on the choice of the code itself.\nThe cone does not depend on the channel, over which the code is employed. The\nknowledge of the boundaries of the fundamental cone could help in studying\nvarious properties of the pseudocodewords, such as their minimum pseudoweight,\npseudoredundancy of the codes, etc. For the binary codes, the full\ncharacterization of the fundamental cone was derived by Koetter et al. However,\nif the underlying alphabet is large, such characterization becom is more\ninvolved. In this work, a characterization of the fundamental cone for codes\nover $F_3$ is discussed. \n\n"}
{"id": "1008.2147", "contents": "Title: Quantum Tagging: Authenticating Location via Quantum Information and\n  Relativistic Signalling Constraints Abstract: We define the task of {\\it quantum tagging}, that is, authenticating the\nclassical location of a classical tagging device by sending and receiving\nquantum signals from suitably located distant sites, in an environment\ncontrolled by an adversary whose quantum information processing and\ntransmitting power is unbounded. We define simple security models for this task\nand briefly discuss alternatives.\n  We illustrate the pitfalls of naive quantum cryptographic reasoning in this\ncontext by describing several protocols which at first sight appear\nunconditionally secure but which, as we show, can in fact be broken by\nteleportation-based attacks. We also describe some protocols which cannot be\nbroken by these specific attacks, but do not prove they are unconditionally\nsecure.\n  We review the history of quantum tagging protocols, which we first discussed\nin 2002 and described in a 2006 patent (for an insecure protocol). The\npossibility has recently been reconsidered by other authors. All the more\nrecently discussed protocols of which we are aware were either previously\nconsidered by us in 2002-3 or are variants of schemes then considered, and all\nare provably insecure. \n\n"}
{"id": "1008.2249", "contents": "Title: A Novel Association Policy for Web Browsing in a Multirate WLAN Abstract: We obtain an association policy for STAs in an IEEE 802.11 WLAN by taking\ninto account explicitly two aspects of practical importance: (a) TCP-controlled\nshort file downloads interspersed with read times (motivated by web browsing),\nand (b) different STAs associated with an AP at possibly different rates\n(depending on distance from the AP). Our approach is based on two steps. First,\nwe consider an analytical model to obtain the aggregate AP throughput for long\nTCP-controlled file downloads when STAs are associated at k different rates r1,\nr2, : : :, rk; this extends earlier work in the literature. Second, we present\na 2-node closed queueing network model to approximate the expected\naverage-sized file download time for a user who shares the AP with other users\nassociated at a multiplicity of rates. These analytical results motivate the\nproposed association policy, called the Estimated Delay based Association (EDA)\npolicy: Associate with the AP at which the expected file download time is the\nleast. Simulations indicate that for a web-browsing type traffic scenario, EDA\noutperforms other policies that have been proposed earlier; the extent of\nimprovement ranges from 12.8% to 46.4% for a 9-AP network. To the best of our\nknowledge, this is the first work that proposes an association policy tailored\nspecifically for web browsing. Apart from this, our analytical results could be\nof independent interest \n\n"}
{"id": "1008.2857", "contents": "Title: Bidirectional multi-pair network with a MIMO relay: Beamforming\n  strategies and lack of duality Abstract: We address the problem of a multi-user relay network, where multiple\nsingle-antenna node pairs want to exchange information by using a multiple\nantenna relay node. Due to the half-duplex constraint of the relay, the\nexchange of information takes place in two steps. In the first step, the nodes\ntransmit their data to the relay, while in the second step, the relay is\nbroadcasting the data by using linear and non-linear precoding strategies. We\nfocus on the second step in this paper. We first consider the problem of\nmaximizing the overall rate achievable using linear and dirty-paper type\nprecoding strategies at the relay. Then, we consider minimizing the total power\nat the relay subject to individual SINR constraints using the same strategies\nat the relay. We show that the downlink-uplink duality does not hold for the\nsetup considered here, which is a somewhat surprising result. We also show that\nthe beamforming strategy which is optimal in the single-pair case performs very\nwell in the multi-pair case for practically relevant SNR. The results are\nillustrated by numerical simulations. \n\n"}
{"id": "1008.2972", "contents": "Title: Algebraic Signal Processing Theory: Cooley-Tukey Type Algorithms for\n  Polynomial Transforms Based on Induction Abstract: A polynomial transform is the multiplication of an input vector $x\\in\\C^n$ by\na matrix $\\PT_{b,\\alpha}\\in\\C^{n\\times n},$ whose $(k,\\ell)$-th element is\ndefined as $p_\\ell(\\alpha_k)$ for polynomials $p_\\ell(x)\\in\\C[x]$ from a list\n$b=\\{p_0(x),\\dots,p_{n-1}(x)\\}$ and sample points $\\alpha_k\\in\\C$ from a list\n$\\alpha=\\{\\alpha_0,\\dots,\\alpha_{n-1}\\}$. Such transforms find applications in\nthe areas of signal processing, data compression, and function interpolation.\nImportant examples include the discrete Fourier and cosine transforms. In this\npaper we introduce a novel technique to derive fast algorithms for polynomial\ntransforms. The technique uses the relationship between polynomial transforms\nand the representation theory of polynomial algebras. Specifically, we derive\nalgorithms by decomposing the regular modules of these algebras as a stepwise\ninduction. As an application, we derive novel $O(n\\log{n})$ general-radix\nalgorithms for the discrete Fourier transform and the discrete cosine transform\nof type 4. \n\n"}
{"id": "1008.4161", "contents": "Title: Percolation and Connectivity in the Intrinsically Secure Communications\n  Graph Abstract: The ability to exchange secret information is critical to many commercial,\ngovernmental, and military networks. The intrinsically secure communications\ngraph (iS-graph) is a random graph which describes the connections that can be\nsecurely established over a large-scale network, by exploiting the physical\nproperties of the wireless medium. This paper aims to characterize the global\nproperties of the iS-graph in terms of: (i) percolation on the infinite plane,\nand (ii) full connectivity on a finite region. First, for the Poisson iS-graph\ndefined on the infinite plane, the existence of a phase transition is proven,\nwhereby an unbounded component of connected nodes suddenly arises as the\ndensity of legitimate nodes is increased. This shows that long-range secure\ncommunication is still possible in the presence of eavesdroppers. Second, full\nconnectivity on a finite region of the Poisson iS-graph is considered. The\nexact asymptotic behavior of full connectivity in the limit of a large density\nof legitimate nodes is characterized. Then, simple, explicit expressions are\nderived in order to closely approximate the probability of full connectivity\nfor a finite density of legitimate nodes. The results help clarify how the\npresence of eavesdroppers can compromise long-range secure communication. \n\n"}
{"id": "1008.4747", "contents": "Title: Entanglement-assisted quantum low-density parity-check codes Abstract: This paper develops a general method for constructing entanglement-assisted\nquantum low-density parity-check (LDPC) codes, which is based on combinatorial\ndesign theory. Explicit constructions are given for entanglement-assisted\nquantum error-correcting codes (EAQECCs) with many desirable properties. These\nproperties include the requirement of only one initial entanglement bit, high\nerror correction performance, high rates, and low decoding complexity. The\nproposed method produces infinitely many new codes with a wide variety of\nparameters and entanglement requirements. Our framework encompasses various\ncodes including the previously known entanglement-assisted quantum LDPC codes\nhaving the best error correction performance and many new codes with better\nblock error rates in simulations over the depolarizing channel. We also\ndetermine important parameters of several well-known classes of quantum and\nclassical LDPC codes for previously unsettled cases. \n\n"}
{"id": "1009.3052", "contents": "Title: Secret-key Agreement with Channel State Information at the Transmitter Abstract: We study the capacity of secret-key agreement over a wiretap channel with\nstate parameters. The transmitter communicates to the legitimate receiver and\nthe eavesdropper over a discrete memoryless wiretap channel with a memoryless\nstate sequence. The transmitter and the legitimate receiver generate a shared\nsecret key, that remains secret from the eavesdropper. No public discussion\nchannel is available. The state sequence is known noncausally to the\ntransmitter. We derive lower and upper bounds on the secret-key capacity. The\nlower bound involves constructing a common state reconstruction sequence at the\nlegitimate terminals and binning the set of reconstruction sequences to obtain\nthe secret-key. For the special case of Gaussian channels with additive\ninterference (secret-keys from dirty paper channel) our bounds differ by 0.5\nbit/symbol and coincide in the high signal-to-noise-ratio and high\ninterference-to-noise-ratio regimes. For the case when the legitimate receiver\nis also revealed the state sequence, we establish that our lower bound achieves\nthe the secret-key capacity. In addition, for this special case, we also\npropose another scheme that attains the capacity and requires only causal side\ninformation at the transmitter and the receiver. \n\n"}
{"id": "1010.0933", "contents": "Title: Interference Alignment with Limited Feedback on Two-cell Interfering\n  Two-User MIMO-MAC Abstract: In this paper, we consider a two-cell interfering two-user multiple-input\nmultiple-output multiple access channel (MIMO-MAC) with limited feedback. We\nfirst investigate the multiplexing gain of such channel when users have perfect\nchannel state information at transmitter (CSIT) by exploiting an interference\nalignment scheme. In addition, we propose a feedback framework for the\ninterference alignment in the limited feedback system. On the basis of the\nproposed feedback framework, we analyze the rate gap loss and it is shown that\nin order to keep the same multiplexing gain with the case of perfect CSIT, the\nnumber of feedback bits per receiver scales as $B \\geq\n(M\\!-1\\!)\\!\\log_{2}(\\textsf{SNR})+C$, where $M$ and $C$ denote the number of\ntransmit antennas and a constant, respectively. Throughout the simulation\nresults, it is shown that the sum-rate performance coincides with the derived\nresults. \n\n"}
{"id": "1010.0937", "contents": "Title: Signal Space Alignment for an Encryption Message and Successive Network\n  Code Decoding on the MIMO K-way Relay Channel Abstract: This paper investigates a network information flow problem for a\nmultiple-input multiple-output (MIMO) Gaussian wireless network with $K$-users\nand a single intermediate relay having $M$ antennas. In this network, each user\nintends to convey a multicast message to all other users while receiving $K-1$\nindependent messages from the other users via an intermediate relay. This\nnetwork information flow is termed a MIMO Gaussian $K$-way relay channel. For\nthis channel, we show that $\\frac{K}{2}$ degrees of freedom is achievable if\n$M=K-1$. To demonstrate this, we come up with an encoding and decoding strategy\ninspired from cryptography theory. The proposed encoding and decoding strategy\ninvolves a \\textit{signal space alignment for an encryption message} for the\nmultiple access phase (MAC) and \\textit{zero forcing with successive network\ncode decoding} for the broadcast (BC) phase. The idea of the \\emph{signal space\nalignment for an encryption message} is that all users cooperatively choose the\nprecoding vectors to transmit the message so that the relay can receive a\nproper encryption message with a special structure, \\textit{network code chain\nstructure}. During the BC phase, \\emph{zero forcing combined with successive\nnetwork code decoding} enables all users to decipher the encryption message\nfrom the relay despite the fact that they all have different self-information\nwhich they use as a key. \n\n"}
{"id": "1010.2741", "contents": "Title: MIMO Interference Alignment Over Correlated Channels with Imperfect CSI Abstract: Interference alignment (IA), given uncorrelated channel components and\nperfect channel state information, obtains the maximum degrees of freedom in an\ninterference channel. Little is known, however, about how the sum rate of IA\nbehaves at finite transmit power, with imperfect channel state information, or\nantenna correlation. This paper provides an approximate closed-form\nsignal-to-interference-plus-noise-ratio (SINR) expression for IA over\nmultiple-input-multiple-output (MIMO) channels with imperfect channel state\ninformation and transmit antenna correlation. Assuming linear processing at the\ntransmitters and zero-forcing receivers, random matrix theory tools are\nutilized to derive an approximation for the post-processing SINR distribution\nof each stream for each user. Perfect channel knowledge and i.i.d. channel\ncoefficients constitute special cases. This SINR distribution not only allows\neasy calculation of useful performance metrics like sum rate and symbol error\nrate, but also permits a realistic comparison of IA with other transmission\ntechniques. More specifically, IA is compared with spatial multiplexing and\nbeamforming and it is shown that IA may not be optimal for some performance\ncriteria. \n\n"}
{"id": "1010.2787", "contents": "Title: Interference Alignment with Analog Channel State Feedback Abstract: Interference alignment (IA) is a multiplexing gain optimal transmission\nstrategy for the interference channel. While the achieved sum rate with IA is\nmuch higher than previously thought possible, the improvement often comes at\nthe cost of requiring network channel state information at the transmitters.\nThis can be achieved by explicit feedback, a flexible yet potentially costly\napproach that incurs large overhead. In this paper we propose analog feedback\nas an alternative to limited feedback or reciprocity based alignment. We show\nthat the full multiplexing gain observed with perfect channel knowledge is\npreserved by analog feedback and that the mean loss in sum rate is bounded by a\nconstant when signal-to-noise ratio is comparable in both forward and feedback\nchannels. When signal-to-noise ratios are not quite symmetric, a fraction of\nthe multiplexing gain is achieved. We consider the overhead of training and\nfeedback and use this framework to optimize the system's effective throughput.\nWe present simulation results to demonstrate the performance of IA with analog\nfeedback, verify our theoretical analysis, and extend our conclusions on\noptimal training and feedback length. \n\n"}
{"id": "1010.2993", "contents": "Title: Broadcasting with an Energy Harvesting Rechargeable Transmitter Abstract: In this paper, we investigate the transmission completion time minimization\nproblem in a two-user additive white Gaussian noise (AWGN) broadcast channel,\nwhere the transmitter is able to harvest energy from the nature, using a\nrechargeable battery. The harvested energy is modeled to arrive at the\ntransmitter randomly during the course of transmissions. The transmitter has a\nfixed number of packets to be delivered to each receiver. Our goal is to\nminimize the time by which all of the packets for both users are delivered to\ntheir respective destinations. To this end, we optimize the transmit powers and\ntransmission rates intended for both users. We first analyze the structural\nproperties of the optimal transmission policy. We prove that the optimal total\ntransmit power has the same structure as the optimal single-user transmit\npower. We also prove that there exists a cut-off power level for the stronger\nuser. If the optimal total transmit power is lower than this cut-off level, all\ntransmit power is allocated to the stronger user, and when the optimal total\ntransmit power is larger than this cut-off level, all transmit power above this\nlevel is allocated to the weaker user. Based on these structural properties of\nthe optimal policy, we propose an algorithm that yields the globally optimal\noff-line scheduling policy. Our algorithm is based on the idea of reducing the\ntwo-user broadcast channel problem into a single-user problem as much as\npossible. \n\n"}
{"id": "1010.4751", "contents": "Title: Sparse coding and dictionary learning based on the MDL principle Abstract: The power of sparse signal coding with learned dictionaries has been\ndemonstrated in a variety of applications and fields, from signal processing to\nstatistical inference and machine learning. However, the statistical properties\nof these models, such as underfitting or overfitting given sets of data, are\nstill not well characterized in the literature. This work aims at filling this\ngap by means of the Minimum Description Length (MDL) principle -- a well\nestablished information-theoretic approach to statistical inference. The\nresulting framework derives a family of efficient sparse coding and modeling\n(dictionary learning) algorithms, which by virtue of the MDL principle, are\ncompletely parameter free. Furthermore, such framework allows to incorporate\nadditional prior information in the model, such as Markovian dependencies, in a\nnatural way. We demonstrate the performance of the proposed framework with\nresults for image denoising and classification tasks. \n\n"}
{"id": "1010.4920", "contents": "Title: Jointly Optimal Channel Pairing and Power Allocation for Multichannel\n  Multihop Relaying Abstract: We study the problem of channel pairing and power allocation in a\nmultichannel multihop relay network to enhance the end-to-end data rate. Both\namplify-and-forward (AF) and decode-and-forward (DF) relaying strategies are\nconsidered. Given fixed power allocation to the channels, we show that channel\npairing over multiple hops can be decomposed into independent pairing problems\nat each relay, and a sorted-SNR channel pairing strategy is sum-rate optimal,\nwhere each relay pairs its incoming and outgoing channels by their SNR order.\nFor the joint optimization of channel pairing and power allocation under both\ntotal and individual power constraints, we show that the problem can be\ndecoupled into two subproblems solved separately. This separation principle is\nestablished by observing the equivalence between sorting SNRs and sorting\nchannel gains in the jointly optimal solution. It significantly reduces the\ncomputational complexity in finding the jointly optimal solution. It follows\nthat the channel pairing problem in joint optimization can be again decomposed\ninto independent pairing problems at each relay based on sorted channel gains.\nThe solution for optimizing power allocation for DF relaying is also provided,\nas well as an asymptotically optimal solution for AF relaying. Numerical\nresults are provided to demonstrate substantial performance gain of the jointly\noptimal solution over some suboptimal alternatives. It is also observed that\nmore gain is obtained from optimal channel pairing than optimal power\nallocation through judiciously exploiting the variation among multiple\nchannels. Impact of the variation of channel gain, the number of channels, and\nthe number of hops on the performance gain is also studied through numerical\nexamples. \n\n"}
{"id": "1010.5644", "contents": "Title: Fast-Decodable Asymmetric Space-Time Codes from Division Algebras Abstract: Multiple-input double-output (MIDO) codes are important in the near-future\nwireless communications, where the portable end-user device is physically small\nand will typically contain at most two receive antennas. Especially tempting is\nthe 4 x 2 channel due to its immediate applicability in the digital video\nbroadcasting (DVB). Such channels optimally employ rate-two space-time (ST)\ncodes consisting of (4 x 4) matrices. Unfortunately, such codes are in general\nvery complex to decode, hence setting forth a call for constructions with\nreduced complexity.\n  Recently, some reduced complexity constructions have been proposed, but they\nhave mainly been based on different ad hoc methods and have resulted in\nisolated examples rather than in a more general class of codes. In this paper,\nit will be shown that a family of division algebra based MIDO codes will always\nresult in at least 37.5% worst-case complexity reduction, while maintaining\nfull diversity and, for the first time, the non-vanishing determinant (NVD)\nproperty. The reduction follows from the fact that, similarly to the Alamouti\ncode, the codes will be subsets of matrix rings of the Hamiltonian quaternions,\nhence allowing simplified decoding. At the moment, such reductions are among\nthe best known for rate-two MIDO codes. Several explicit constructions are\npresented and shown to have excellent performance through computer simulations. \n\n"}
{"id": "1010.5644", "contents": "Title: Fast-Decodable Asymmetric Space-Time Codes from Division Algebras Abstract: Multiple-input double-output (MIDO) codes are important in the near-future\nwireless communications, where the portable end-user device is physically small\nand will typically contain at most two receive antennas. Especially tempting is\nthe 4 x 2 channel due to its immediate applicability in the digital video\nbroadcasting (DVB). Such channels optimally employ rate-two space-time (ST)\ncodes consisting of (4 x 4) matrices. Unfortunately, such codes are in general\nvery complex to decode, hence setting forth a call for constructions with\nreduced complexity.\n  Recently, some reduced complexity constructions have been proposed, but they\nhave mainly been based on different ad hoc methods and have resulted in\nisolated examples rather than in a more general class of codes. In this paper,\nit will be shown that a family of division algebra based MIDO codes will always\nresult in at least 37.5% worst-case complexity reduction, while maintaining\nfull diversity and, for the first time, the non-vanishing determinant (NVD)\nproperty. The reduction follows from the fact that, similarly to the Alamouti\ncode, the codes will be subsets of matrix rings of the Hamiltonian quaternions,\nhence allowing simplified decoding. At the moment, such reductions are among\nthe best known for rate-two MIDO codes. Several explicit constructions are\npresented and shown to have excellent performance through computer simulations. \n\n"}
{"id": "1011.2361", "contents": "Title: Distributed Storage Codes with Repair-by-Transfer and Non-achievability\n  of Interior Points on the Storage-Bandwidth Tradeoff Abstract: Regenerating codes are a class of recently developed codes for distributed\nstorage that, like Reed-Solomon codes, permit data recovery from any subset of\nk nodes within the n-node network. However, regenerating codes possess in\naddition, the ability to repair a failed node by connecting to an arbitrary\nsubset of d nodes. It has been shown that for the case of functional-repair,\nthere is a tradeoff between the amount of data stored per node and the\nbandwidth required to repair a failed node. A special case of functional-repair\nis exact-repair where the replacement node is required to store data identical\nto that in the failed node. Exact-repair is of interest as it greatly\nsimplifies system implementation. The first result of the paper is an explicit,\nexact-repair code for the point on the storage-bandwidth tradeoff corresponding\nto the minimum possible repair bandwidth, for the case when d=n-1. This code\nhas a particularly simple graphical description and most interestingly, has the\nability to carry out exact-repair through mere transfer of data and without any\nneed to perform arithmetic operations. Hence the term `repair-by-transfer'. The\nsecond result of this paper shows that the interior points on the\nstorage-bandwidth tradeoff cannot be achieved under exact-repair, thus pointing\nto the existence of a separate tradeoff under exact-repair. Specifically, we\nidentify a set of scenarios, termed `helper node pooling', and show that it is\nthe necessity to satisfy such scenarios that over-constrains the system. \n\n"}
{"id": "1011.3347", "contents": "Title: On sizes of complete arcs in PG(2,q) Abstract: New upper bounds on the smallest size t_{2}(2,q) of a complete arc in the\nprojective plane PG(2,q) are obtained for 853 <= q <= 4561 and q\\in T1\\cup T2\nwhere T1={173,181,193,229,243,257,271,277,293,343,373,409,443,449,457,\n461,463,467,479,487,491,499,529,563,569,571,577,587,593,599,601,607,613,617,619,631,\n641,661,673,677,683,691, 709},\nT2={4597,4703,4723,4733,4789,4799,4813,4831,5003,5347,5641,5843,6011,8192}.\nFrom these new bounds it follows that for q <= 2593 and q=2693,2753, the\nrelation t_{2}(2,q) < 4.5\\sqrt{q} holds. Also, for q <= 4561 we have t_{2}(2,q)\n< 4.75\\sqrt{q}. It is showed that for 23 <= q <= 4561 and q\\in T2\\cup\n{2^{14},2^{15},2^{18}}, the inequality t_{2}(2,q) < \\sqrt{q}ln^{0.75}q is true.\nMoreover, the results obtained allow us to conjecture that this estimate holds\nfor all q >= 23. The new upper bounds are obtained by finding new small\ncomplete arcs with the help of a computer search using randomized greedy\nalgorithms. Also new constructions of complete arcs are proposed. These\nconstructions form families of k-arcs in PG(2,q) containing arcs of all sizes k\nin a region k_{min} <= k <= k_{max} where k_{min} is of order q/3 or q/4 while\nk_{max} has order q/2. The completeness of the arcs obtained by the new\nconstructions is proved for q <= 1367 and 2003 <= q <= 2063. There is reason to\nsuppose that the arcs are complete for all q > 1367. New sizes of complete arcs\nin PG(2,q) are presented for 169 <= q <= 349 and q=1013,2003. \n\n"}
{"id": "1012.0602", "contents": "Title: LDPC Codes for Compressed Sensing Abstract: We present a mathematical connection between channel coding and compressed\nsensing. In particular, we link, on the one hand, \\emph{channel coding linear\nprogramming decoding (CC-LPD)}, which is a well-known relaxation o\nmaximum-likelihood channel decoding for binary linear codes, and, on the other\nhand, \\emph{compressed sensing linear programming decoding (CS-LPD)}, also\nknown as basis pursuit, which is a widely used linear programming relaxation\nfor the problem of finding the sparsest solution of an under-determined system\nof linear equations. More specifically, we establis a tight connection between\nCS-LPD based on a zero-one measurement matrix over the reals and CC-LPD of the\nbinary linear channel code that is obtained by viewing this measurement matrix\nas a binary parity-check matrix. This connection allows the translation of\nperformance guarantees from one setup to the other. The main message of this\npaper is that parity-check matrices of \"good\" channel codes can be used as\nprovably \"good\" measurement matrices under basis pursuit. In particular, we\nprovide the first deterministic construction of compressed sensing measurement\nmatrices with an order-optimal number of rows using high-girth low-density\nparity-check (LDPC) codes constructed by Gallager. \n\n"}
{"id": "1012.2509", "contents": "Title: Nonadaptive Mastermind Algorithms for String and Vector Databases, with\n  Case Studies Abstract: In this paper, we study sparsity-exploiting Mastermind algorithms for\nattacking the privacy of an entire database of character strings or vectors,\nsuch as DNA strings, movie ratings, or social network friendship data. Based on\nreductions to nonadaptive group testing, our methods are able to take advantage\nof minimal amounts of privacy leakage, such as contained in a single bit that\nindicates if two people in a medical database have any common genetic\nmutations, or if two people have any common friends in an online social\nnetwork. We analyze our Mastermind attack algorithms using theoretical\ncharacterizations that provide sublinear bounds on the number of queries needed\nto clone the database, as well as experimental tests on genomic information,\ncollaborative filtering data, and online social networks. By taking advantage\nof the generally sparse nature of these real-world databases and modulating a\nparameter that controls query sparsity, we demonstrate that relatively few\nnonadaptive queries are needed to recover a large majority of each database. \n\n"}
{"id": "1012.4552", "contents": "Title: On the Throughput Cost of Physical Layer Security in Decentralized\n  Wireless Networks Abstract: This paper studies the throughput of large-scale decentralized wireless\nnetworks with physical layer security constraints. In particular, we are\ninterested in the question of how much throughput needs to be sacrificed for\nachieving a certain level of security. We consider random networks where the\nlegitimate nodes and the eavesdroppers are distributed according to independent\ntwo-dimensional Poisson point processes. The transmission capacity framework is\nused to characterize the area spectral efficiency of secure transmissions with\nconstraints on both the quality of service (QoS) and the level of security.\nThis framework illustrates the dependence of the network throughput on key\nsystem parameters, such as the densities of legitimate nodes and eavesdroppers,\nas well as the QoS and security constraints. One important finding is that the\nthroughput cost of achieving a moderate level of security is quite low, while\nthroughput must be significantly sacrificed to realize a highly secure network.\nWe also study the use of a secrecy guard zone, which is shown to give a\nsignificant improvement on the throughput of networks with high security\nrequirements. \n\n"}
{"id": "1012.5197", "contents": "Title: Accessible Capacity of Secondary Users Abstract: A new problem formulation is presented for the Gaussian interference channels\n(GIFC) with two pairs of users, which are distinguished as primary users and\nsecondary users, respectively. The primary users employ a pair of encoder and\ndecoder that were originally designed to satisfy a given error performance\nrequirement under the assumption that no interference exists from other users.\nIn the scenario when the secondary users attempt to access the same medium, we\nare interested in the maximum transmission rate (defined as {\\em accessible\ncapacity}) at which secondary users can communicate reliably without affecting\nthe error performance requirement by the primary users under the constraint\nthat the primary encoder (not the decoder) is kept unchanged. By modeling the\nprimary encoder as a generalized trellis code (GTC), we are then able to treat\nthe secondary link and the cross link from the secondary transmitter to the\nprimary receiver as finite state channels (FSCs). Based on this, upper and\nlower bounds on the accessible capacity are derived. The impact of the error\nperformance requirement by the primary users on the accessible capacity is\nanalyzed by using the concept of interference margin. In the case of\nnon-trivial interference margin, the secondary message is split into common and\nprivate parts and then encoded by superposition coding, which delivers a lower\nbound on the accessible capacity. For some special cases, these bounds can be\ncomputed numerically by using the BCJR algorithm. Numerical results are also\nprovided to gain insight into the impacts of the GTC and the error performance\nrequirement on the accessible capacity. \n\n"}
{"id": "1101.5809", "contents": "Title: The Degrees of Freedom Region and Interference Alignment for the MIMO\n  Interference Channel with Delayed CSI Abstract: The degrees of freedom (DoF) region of the 2-user multiple-antenna or MIMO\n(multiple-input, multiple-output) interference channel (IC) is studied under\nfast fading and the assumption of {\\em delayed} channel state information (CSI)\nwherein all terminals know all (or certain) channel matrices perfectly, but\nwith a delay, and each receiver in addition knows its own incoming channels\ninstantaneously. The general MIMO IC is considered with an arbitrary number of\nantennas at each of the four terminals. Dividing it into several classes\ndepending on the relation between the numbers of antennas at the four\nterminals, the fundamental DoF regions are characterized under the delayed CSI\nassumption for {\\em all} possible values of number of antennas at the four\nterminals. In particular, an outer bound on the DoF region of the general MIMO\nIC is derived. This bound is then shown to be tight for all MIMO ICs by\ndeveloping interference alignment based achievability schemes for each class. A\ncomparison of these DoF regions under the delayed CSI assumption is made with\nthose of the idealistic `perfect CSI' assumption where perfect and\ninstantaneous CSI is available at all terminals on the one hand and with the\nDoF regions of the conservative `no CSI' assumption on the other, where CSI is\navailable at the receivers but not at all at the transmitters. \n\n"}
{"id": "1101.6033", "contents": "Title: Some More Functions That Are Not APN Infinitely Often. The Case of\n  Kasami exponents Abstract: We prove a necessary condition for some polynomials of Kasami degree to be\nAPN over F_{q^n} for large n. \n\n"}
{"id": "1102.2250", "contents": "Title: Modeling the pairwise key distribution scheme in the presence of\n  unreliable links Abstract: We investigate the secure connectivity of wireless sensor networks under the\npairwise key distribution scheme of Chan et al.. Unlike recent work which was\ncarried out under the assumption of full visibility, here we assume a\n(simplified) communication model where unreliable wireless links are\nrepresented as on/off channels. We present conditions on how to scale the model\nparameters so that the network i) has no secure node which is isolated and ii)\nis securely connected, both with high probability when the number of sensor\nnodes becomes large. The results are given in the form of zero-one laws, and\nexhibit significant differences with corresponding results in the full\nvisibility case. Through simulations these zero-one laws are shown to be valid\nalso under a more realistic communication model, i.e., the disk model. \n\n"}
{"id": "1102.3013", "contents": "Title: Content replication and placement in mobile networks Abstract: Performance and reliability of content access in mobile networks is\nconditioned by the number and location of content replicas deployed at the\nnetwork nodes. Location theory has been the traditional, centralized approach\nto study content replication: computing the number and placement of replicas in\na static network can be cast as a facility location problem. The endeavor of\nthis work is to design a practical solution to the above joint optimization\nproblem that is suitable for mobile wireless environments. We thus seek a\nreplication algorithm that is lightweight, distributed, and reactive to network\ndynamics. We devise a solution that lets nodes (i) share the burden of storing\nand providing content, so as to achieve load balancing, and (ii) autonomously\ndecide whether to replicate or drop the information, so as to adapt the content\navailability to dynamic demands and time-varying network topologies. We\nevaluate our mechanism through simulation, by exploring a wide range of\nsettings, including different node mobility models, content characteristics and\nsystem scales. Furthermore, we compare our mechanism to state-of-the-art\napproaches to content delivery in static and mobile networks. Results show that\nour mechanism, which uses local measurements only, is: (i) extremely precise in\napproximating an optimal solution to content placement and replication; (ii)\nrobust against network mobility; (iii) flexible in accommodating various\ncontent access patterns. Moreover, our scheme outperforms alternative\napproaches to content dissemination both in terms of content access delay and\naccess congestion. \n\n"}
{"id": "1102.3298", "contents": "Title: A family of fast-decodable MIDO codes from crossed-product algebras over\n  Q Abstract: Multiple Input Double Output (MIDO) asymmetric space-time codes for 4\ntransmit antennas and 2 receive antennas can be employed in the downlink from\nbase stations to portable devices. Previous MIDO code constructions with low\nMaximum Likelihood (ML) decoding complexity, full diversity and the\nnon-vanishing determinant (NVD) property are mostly based on cyclic division\nalgebras. In this paper, a new family of MIDO codes with the NVD property based\non crossed-product algebras over Q is introduced. Fast decodability follows\nnaturally from the structure of the codewords which consist of four generalized\nAlamouti blocks. The associated ML complexity order is the lowest known for\nfull-rate MIDO codes (O(M^{10}) instead of O(M^{16}) with respect to the real\nconstellation size M). Numerical simulations show that these codes have a\nperformance from comparable up to 1dB gain compared to the best known MIDO code\nwith the same complexity. \n\n"}
{"id": "1102.3751", "contents": "Title: Utility-Privacy Tradeoff in Databases: An Information-theoretic Approach Abstract: Ensuring the usefulness of electronic data sources while providing necessary\nprivacy guarantees is an important unsolved problem. This problem drives the\nneed for an analytical framework that can quantify the safety of personally\nidentifiable information (privacy) while still providing a quantifable benefit\n(utility) to multiple legitimate information consumers. This paper presents an\ninformation-theoretic framework that promises an analytical model guaranteeing\ntight bounds of how much utility is possible for a given level of privacy and\nvice-versa. Specific contributions include: i) stochastic data models for both\ncategorical and numerical data; ii) utility-privacy tradeoff regions and the\nencoding (sanization) schemes achieving them for both classes and their\npractical relevance; and iii) modeling of prior knowledge at the user and/or\ndata source and optimal encoding schemes for both cases. \n\n"}
{"id": "1102.3947", "contents": "Title: Subspace Expanders and Matrix Rank Minimization Abstract: Matrix rank minimization (RM) problems recently gained extensive attention\ndue to numerous applications in machine learning, system identification and\ngraphical models. In RM problem, one aims to find the matrix with the lowest\nrank that satisfies a set of linear constraints. The existing algorithms\ninclude nuclear norm minimization (NNM) and singular value thresholding. Thus\nfar, most of the attention has been on i.i.d. Gaussian measurement operators.\nIn this work, we introduce a new class of measurement operators, and a novel\nrecovery algorithm, which is notably faster than NNM. The proposed operators\nare based on what we refer to as subspace expanders, which are inspired by the\nwell known expander graphs based measurement matrices in compressed sensing. We\nshow that given an $n\\times n$ PSD matrix of rank $r$, it can be uniquely\nrecovered from a minimal sampling of $O(nr)$ measurements using the proposed\nstructures, and the recovery algorithm can be cast as matrix inversion after a\nfew initial processing steps. \n\n"}
{"id": "1103.4335", "contents": "Title: Diviseurs de la forme 2D-G sans sections et rang de la multiplication\n  dans les corps finis (Divisors of the form 2D-G without sections and bilinear\n  complexity of multiplication in finite fields) Abstract: Let X be an algebraic curve, defined over a perfect field, and G a divisor on\nX. If X has sufficiently many points, we show how to construct a divisor D on X\nsuch that l(2D-G)=0, of essentially any degree such that this is compatible the\nRiemann-Roch theorem. We also generalize this construction to the case of a\nfinite number of constraints, l(k_i.D-G_i)=0, where |k_i|\\leq 2.\n  Such a result was previously claimed by Shparlinski-Tsfasman-Vladut, in\nrelation with the Chudnovsky-Chudnovsky method for estimating the bilinear\ncomplexity of the multiplication in finite fields based on interpolation on\ncurves; unfortunately, as noted by Cascudo et al., their proof was flawed. So\nour work fixes the proof of Shparlinski-Tsfasman-Vladut and shows that their\nestimate m_q\\leq 2(1+1/(A(q)-1)) holds, at least when A(q)\\geq 5. We also fix a\nstatement of Ballet that suffers from the same problem, and then we point out a\nfew other possible applications. \n\n"}
{"id": "1103.4774", "contents": "Title: Full-Rate Full-Diversity Achieving MIMO Precoding with Partial CSIT Abstract: In this paper, we consider a $n_t\\times n_r$ multiple-input multiple-output\n(MIMO) channel subjected to block fading. Reliability (in terms of achieved\ndiversity order) and rate (in number of symbols transmitted per channel use)\nare of interest in such channels. We propose a new precoding scheme which\nachieves both full diversity ($n_tn_r$th order diversity) as well as full rate\n($n_t$ symbols per channel use) using partial channel state information at the\ntransmitter (CSIT), applicable in MIMO systems including $n_r<n_t$ asymmetric\nMIMO. The proposed scheme achieves full diversity and improved coding gain\nthrough an optimization over the choice of constellation sets. The optimization\nmaximizes $d_{min}^2$ for our precoding scheme subject to an energy constraint.\nThe scheme requires feedback of $n_t-1$ angle parameter values, compared to\n$2n_tn_r$ real coefficients in case of full CSIT. Error rate performance\nresults for $3\\times 1$, $3\\times 2$, $4\\times 1$, $8\\times 1$ precoded MIMO\nsystems (with $n_t=3,3,4,8$ symbols per channel use, respectively) show that\nthe proposed precoding achieves 3rd, 6th, 4th and 8th order diversities,\nrespectively. These performances are shown to be better than other precoding\nschemes in the literature; the better performance is due to the choice of the\nsignal sets and the feedback angles in the proposed scheme. \n\n"}
{"id": "1104.0005", "contents": "Title: On the binary codes with parameters of triply-shortened 1-perfect codes Abstract: We study properties of binary codes with parameters close to the parameters\nof 1-perfect codes. An arbitrary binary $(n=2^m-3, 2^{n-m-1}, 4)$ code $C$,\ni.e., a code with parameters of a triply-shortened extended Hamming code, is a\ncell of an equitable partition of the $n$-cube into six cells. An arbitrary\nbinary $(n=2^m-4, 2^{n-m}, 3)$ code $D$, i.e., a code with parameters of a\ntriply-shortened Hamming code, is a cell of an equitable family (but not a\npartition) from six cells. As a corollary, the codes $C$ and $D$ are completely\nsemiregular; i.e., the weight distribution of such a code depends only on the\nminimal and maximal codeword weights and the code parameters. Moreover, if $D$\nis self-complementary, then it is completely regular. As an intermediate\nresult, we prove, in terms of distance distributions, a general criterion for a\npartition of the vertices of a graph (from rather general class of graphs,\nincluding the distance-regular graphs) to be equitable. Keywords: 1-perfect\ncode; triply-shortened 1-perfect code; equitable partition; perfect coloring;\nweight distribution; distance distribution \n\n"}
{"id": "1104.0136", "contents": "Title: On Interference Alignment and the Deterministic Capacity for Cellular\n  Channels with Weak Symmetric Cross Links Abstract: In this paper, we study the uplink of a cellular system using the linear\ndeterministic approximation model, where there are two users transmitting to a\nreceiver, mutually interfering with a third transmitter communicating with a\nsecond receiver. We give an achievable coding scheme and prove its optimality,\ni.e. characterize the capacity region. This scheme is a form of interference\nalignment which exploits the channel gain difference of the two-user cell. \n\n"}
{"id": "1105.0087", "contents": "Title: Higher weights of Grassmann codes in terms of properties of Schubert\n  unions Abstract: We describe the higher weights of the Grassmann codes $G(2,m)$ over finite\nfields ${\\mathbb F}_q$ in terms of properties of Schubert unions, and in each\ncase we determine the weight as the minimum of two explicit polynomial\nexpressions in $q$. \n\n"}
{"id": "1105.2865", "contents": "Title: Error Correction for Index Coding with Side Information Abstract: A problem of index coding with side information was first considered by Y.\nBirk and T. Kol (IEEE INFOCOM, 1998). In the present work, a generalization of\nindex coding scheme, where transmitted symbols are subject to errors, is\nstudied. Error-correcting methods for such a scheme, and their parameters, are\ninvestigated. In particular, the following question is discussed: given the\nside information hypergraph of index coding scheme and the maximal number of\nerroneous symbols $\\delta$, what is the shortest length of a linear index code,\nsuch that every receiver is able to recover the required information? This\nquestion turns out to be a generalization of the problem of finding a\nshortest-length error-correcting code with a prescribed error-correcting\ncapability in the classical coding theory.\n  The Singleton bound and two other bounds, referred to as the $\\alpha$-bound\nand the $\\kappa$-bound, for the optimal length of a linear error-correcting\nindex code (ECIC) are established. For large alphabets, a construction based on\nconcatenation of an optimal index code with an MDS classical code, is shown to\nattain the Singleton bound. For smaller alphabets, however, this construction\nmay not be optimal. A random construction is also analyzed. It yields another\nimplicit bound on the length of an optimal linear ECIC.\n  Further, the problem of error-correcting decoding by a linear ECIC is\nstudied. It is shown that in order to decode correctly the desired symbol, the\ndecoder is required to find one of the vectors, belonging to an affine space\ncontaining the actual error vector. The syndrome decoding is shown to produce\nthe correct output if the weight of the error pattern is less or equal to the\nerror-correcting capability of the corresponding ECIC.\n  Finally, the notion of static ECIC, which is suitable for use with a family\nof instances of an index coding problem, is introduced. \n\n"}
{"id": "1105.5476", "contents": "Title: Feedback-Topology Designs for Interference Alignment in MIMO\n  Interference Channels Abstract: Interference alignment (IA) is a joint-transmission technique that achieves\nthe capacity of the interference channel for high signal-to-noise ratios\n(SNRs). Most prior work on IA is based on the impractical assumption that\nperfect and global channel-state information(CSI) is available at all\ntransmitters. To implement IA, each receiver has to feed back CSI to all\ninterferers, resulting in overwhelming feedback overhead. In particular, the\nsum feedback rate of each receiver scales quadratically with the number of\nusers even if the quantized CSI is fed back. To substantially suppress feedback\noverhead, this paper focuses on designing efficient arrangements of feedback\nlinks, called feedback topologies, under the IA constraint. For the\nmultiple-input-multiple-output (MIMO) K-user interference channel, we propose\nthe feedback topology that supports sequential CSI exchange (feedback and\nfeedforward) between transmitters and receivers so as to achieve IA\nprogressively. This feedback topology is shown to reduce the network feedback\noverhead from a cubic function of K to a linear one. To reduce the delay in the\nsequential CSI exchange, an alternative feedback topology is designed for\nsupporting two-hop feedback via a control station, which also achieves the\nlinear feedback scaling with K. Next, given the proposed feedback topologies,\nthe feedback-bit allocation algorithm is designed for allocating feedback bits\nby each receiver to different feedback links so as to regulate the residual\ninterference caused by the finite-rate feedback. Simulation results demonstrate\nthat the proposed bit allocation leads to significant throughput gains\nespecially in strong interference environments. \n\n"}
{"id": "1105.5639", "contents": "Title: Asynchronous Communication: Capacity Bounds and Suboptimality of\n  Training Abstract: Several aspects of the problem of asynchronous point-to-point communication\nwithout feedback are developed when the source is highly intermittent. In the\nsystem model of interest, the codeword is transmitted at a random time within a\nprescribed window whose length corresponds to the level of asynchronism between\nthe transmitter and the receiver. The decoder operates sequentially and\ncommunication rate is defined as the ratio between the message size and the\nelapsed time between when transmission commences and when the decoder makes a\ndecision.\n  For such systems, general upper and lower bounds on capacity as a function of\nthe level of asynchronism are established, and are shown to coincide in some\nnontrivial cases. From these bounds, several properties of this asynchronous\ncapacity are derived. In addition, the performance of training-based schemes is\ninvestigated. It is shown that such schemes, which implement synchronization\nand information transmission on separate degrees of freedom in the encoding,\ncannot achieve the asynchronous capacity in general, and that the penalty is\nparticularly significant in the high-rate regime. \n\n"}
{"id": "1106.5930", "contents": "Title: An Algorithm for Classification of Binary Self-Dual Codes Abstract: An efficient algorithm for classification of binary self-dual codes is\npresented. As an application, a complete classification of the self-dual codes\nof length 38 is given. \n\n"}
{"id": "1107.3862", "contents": "Title: Achieving \"Massive MIMO\" Spectral Efficiency with a Not-so-Large Number\n  of Antennas Abstract: The main focus and contribution of this paper is a novel network-MIMO TDD\narchitecture that achieves spectral efficiencies comparable with \"Massive\nMIMO\", with one order of magnitude fewer antennas per active user per cell. The\nproposed architecture is based on a family of network-MIMO schemes defined by\nsmall clusters of cooperating base stations, zero-forcing multiuser MIMO\nprecoding with suitable inter-cluster interference constraints, uplink pilot\nsignals reuse across cells, and frequency reuse. The key idea consists of\npartitioning the users population into geographically determined \"bins\", such\nthat all users in the same bin are statistically equivalent, and use the\noptimal network-MIMO architecture in the family for each bin. A scheduler takes\ncare of serving the different bins on the time-frequency slots, in order to\nmaximize a desired network utility function that captures some desired notion\nof fairness. This results in a mixed-mode network-MIMO architecture, where\ndifferent schemes, each of which is optimized for the served user bin, are\nmultiplexed in time-frequency. In order to carry out the performance analysis\nand the optimization of the proposed architecture in a clean and\ncomputationally efficient way, we consider the large-system regime where the\nnumber of users, the number of antennas, and the channel coherence block length\ngo to infinity with fixed ratios. The performance predicted by the large-system\nasymptotic analysis matches very well the finite-dimensional simulations.\nOverall, the system spectral efficiency obtained by the proposed architecture\nis similar to that achieved by \"Massive MIMO\", with a 10-fold reduction in the\nnumber of antennas at the base stations (roughly, from 500 to 50 antennas). \n\n"}
{"id": "1108.4129", "contents": "Title: Spatial Interactions of Peers and Performance of File Sharing Systems Abstract: We propose a new model for peer-to-peer networking which takes the network\nbottlenecks into account beyond the access. This model allows one to cope with\nkey features of P2P networking like degree or locality constraints or the fact\nthat distant peers often have a smaller rate than nearby peers. We show that\nthe spatial point process describing peers in their steady state then exhibits\nan interesting repulsion phenomenon. We analyze two asymptotic regimes of the\npeer-to-peer network: the fluid regime and the hard--core regime. We get closed\nform expressions for the mean (and in some cases the law) of the peer latency\nand the download rate obtained by a peer as well as for the spatial density of\npeers in the steady state of each regime, as well as an accurate approximation\nthat holds for all regimes. The analytical results are based on a mix of\nmathematical analysis and dimensional analysis and have important design\nimplications. The first of them is the existence of a setting where the\nequilibrium mean latency is a decreasing function of the load, a phenomenon\nthat we call super-scalability. \n\n"}
{"id": "1108.6185", "contents": "Title: Weighted Reed-Muller codes revisited Abstract: We consider weighted Reed-Muller codes over point ensemble $S_1\n\\times...\\times S_m$ where $S_i$ needs not be of the same size as $S_j$. For $m\n= 2$ we determine optimal weights and analyze in detail what is the impact of\nthe ratio $|S_1|/|S_2|$ on the minimum distance. In conclusion the weighted\nReed-Muller code construction is much better than its reputation. For a class\nof affine variety codes that contains the weighted Reed-Muller codes we then\npresent two list decoding algorithms. With a small modification one of these\nalgorithms is able to correct up to 31 errors of the [49, 11, 28] Joyner code. \n\n"}
{"id": "1109.4314", "contents": "Title: On the Degrees of Freedom of $K$-User SISO Interference and X Channels\n  with Delayed CSIT Abstract: The $K$-user single-input single-output (SISO) AWGN interference channel and\n$2\\times K$ SISO AWGN X channel are considered where the transmitters have the\ndelayed channel state information (CSI) through noiseless feedback links.\nMulti-phase transmission schemes are proposed for both channels which possess\nnovel ingredients, namely, multi-phase partial interference nulling,\ndistributed interference management via user scheduling, and distributed\nhigher-order symbol generation. The achieved degrees of freedom (DoF) values\nare greater than the best previously known DoFs for both channels with delayed\nCSI at transmitters. \n\n"}
{"id": "1109.5779", "contents": "Title: The Degrees of Freedom Region of the MIMO Interference Channel with\n  Shannon Feedback Abstract: The two-user multiple-input multiple-output (MIMO) fast-fading interference\nchannel (IC) with an arbitrary number of antennas at each of the four terminals\nis studied under the settings of Shannon feedback, limited Shannon feedback,\nand output feedback, wherein all or certain channel matrices and outputs, or\njust the channel outputs, respectively, are available to the transmitters with\na finite delay. While for most numbers of antennas at the four terminals, it is\nshown that the DoF regions with Shannon feedback and for the limited Shannon\nfeedback settings considered here are identical, and equal to the DoF region\nwith just delayed channel state information (CSIT), it is shown that this is\nnot always the case. For a specific class of MIMO ICs characterized by a\ncertain relationship between the numbers of antennas at the four nodes, the DoF\nregions with Shannon and the limited Shannon feedback settings, while again\nbeing identical, are strictly bigger than the DoF region with just delayed\nCSIT. To realize these DoF gains with Shannon or limited Shannon feedback, a\nnew retrospective interference alignment scheme is developed wherein\ntransmitter cooperation made possible by output feedback in addition to delayed\nCSIT is employed to effect a more efficient form of interference alignment than\nis feasible with previously known schemes that use just delayed CSIT. The DoF\nregion for just output feedback, in which each transmitter has delayed\nknowledge of only the receivers' outputs, is also obtained for all but a class\nof MIMO ICs that satisfy one of two inequalities involving the numbers of\nantennas. \n\n"}
{"id": "1110.3559", "contents": "Title: Separation of source-network coding and channel coding in wireline\n  networks Abstract: In this paper we prove the separation of source-network coding and channel\ncoding in wireline networks. For the purposes of this work, a wireline network\nis any network of independent, memoryless, point-to-point, finite-alphabet\nchannels used to transmit dependent sources either losslessly or subject to a\ndistortion constraint. In deriving this result, we also prove that in a general\nmemoryless network with dependent sources, lossless and zero-distortion\nreconstruction are equivalent provided that the conditional entropy of each\nsource given the other sources is non-zero. Furthermore, we extend the\nseparation result to the case of continuous-alphabet, point-to-point channels\nsuch as additive white Gaussian noise (AWGN) channels. \n\n"}
{"id": "1111.0663", "contents": "Title: On Identity Testing of Tensors, Low-rank Recovery and Compressed Sensing Abstract: We study the problem of obtaining efficient, deterministic, black-box\npolynomial identity testing algorithms for depth-3 set-multilinear circuits\n(over arbitrary fields). This class of circuits has an efficient,\ndeterministic, white-box polynomial identity testing algorithm (due to Raz and\nShpilka), but has no known such black-box algorithm. We recast this problem as\na question of finding a low-dimensional subspace H, spanned by rank 1 tensors,\nsuch that any non-zero tensor in the dual space ker(H) has high rank. We obtain\nexplicit constructions of essentially optimal-size hitting sets for tensors of\ndegree 2 (matrices), and obtain quasi-polynomial sized hitting sets for\narbitrary tensors (but this second hitting set is less explicit).\n  We also show connections to the task of performing low-rank recovery of\nmatrices, which is studied in the field of compressed sensing. Low-rank\nrecovery asks (say, over the reals) to recover a matrix M from few\nmeasurements, under the promise that M is rank <=r. We also give a formal\nconnection between low-rank recovery and the task of sparse (vector) recovery:\nany sparse-recovery algorithm that exactly recovers vectors of length n and\nsparsity 2r, using m non-adaptive measurements, yields a low-rank recovery\nscheme for exactly recovering nxn matrices of rank <=r, making 2nm non-adaptive\nmeasurements. Furthermore, if the sparse-recovery algorithm runs in time \\tau,\nthen the low-rank recovery algorithm runs in time O(rn^2+n\\tau). We obtain this\nreduction using linear-algebraic techniques, and not using convex optimization,\nwhich is more commonly seen in compressed sensing algorithms. By using a dual\nReed-Solomon code, we are able to (deterministically) construct low-rank\nrecovery schemes taking 4nr measurements over the reals, such that the\nmeasurements can be all rank-1 matrices, or all sparse matrices. \n\n"}
{"id": "1111.1051", "contents": "Title: Multiuser Diversity in Interfering Broadcast Channels: Achievable\n  Degrees of Freedom and User Scaling Law Abstract: This paper investigates how multiuser dimensions can effectively be exploited\nfor target degrees of freedom (DoF) in interfering broadcast channels (IBC)\nconsisting of K-transmitters and their user groups. First, each transmitter is\nassumed to have a single antenna and serve a singe user in its user group where\neach user has receive antennas less than K. In this case, a K-transmitter\nsingle-input multiple-output (SIMO) interference channel (IC) is constituted\nafter user selection. Without help of multiuser diversity, K-1 interfering\nsignals cannot be perfectly removed at each user since the number of receive\nantennas is smaller than or equal to the number of interferers. Only with\nproper user selection, non-zero DoF per transmitter is achievable as the number\nof users increases. Through geometric interpretation of interfering channels,\nwe show that the multiuser dimensions have to be used first for reducing the\nDoF loss caused by the interfering signals, and then have to be used for\nincreasing the DoF gain from its own signal. The sufficient number of users for\nthe target DoF is derived. We also discuss how the optimal strategy of\nexploiting multiuser diversity can be realized by practical user selection\nschemes. Finally, the single transmit antenna case is extended to the\nmultiple-input multiple-output (MIMO) IBC where each transmitter with multiple\nantennas serves multiple users. \n\n"}
{"id": "1111.2637", "contents": "Title: Some Extremal Self-Dual Codes and Unimodular Lattices in Dimension 40 Abstract: In this paper, binary extremal singly even self-dual codes of length 40 and\nextremal odd unimodular lattices in dimension 40 are studied. We give a\nclassification of extremal singly even self-dual codes of length 40. We also\ngive a classification of extremal odd unimodular lattices in dimension 40 with\nshadows having 80 vectors of norm 2 through their relationships with extremal\ndoubly even self-dual codes of length 40. \n\n"}
{"id": "1111.3274", "contents": "Title: Pilotless Recovery of Clipped OFDM Signals by Compressive Sensing over\n  Reliable Data Carriers Abstract: In this paper we propose a novel form of clipping mitigation in OFDM using\ncompressive sensing that completely avoids tone reservation and hence rate loss\nfor this purpose. The method builds on selecting the most reliable\nperturbations from the constellation lattice upon decoding at the receiver, and\nperforms compressive sensing over these observations in order to completely\nrecover the temporally sparse nonlinear distortion. As such, the method\nprovides a unique practical solution to the problem of initial erroneous\ndecoding decisions in iterative ML methods, offering both the ability to\naugment these techniques and to solely recover the distorted signal in one\nshot. \n\n"}
{"id": "1111.3966", "contents": "Title: Partial Decode-Forward Binning Schemes for the Causal Cognitive Relay\n  Channels Abstract: The causal cognitive relay channel (CRC) has two sender-receiver pairs, in\nwhich the second sender obtains information from the first sender causally and\nassists the transmission of both senders. In this paper, we study both the\nfull- and half-duplex modes. In each mode, we propose two new coding schemes\nbuilt successively upon one another to illustrate the impact of different\ncoding techniques. The first scheme called partial decode-forward binning\n(PDF-binning) combines the ideas of partial decode-forward relaying and\nGelfand-Pinsker binning. The second scheme called Han-Kobayashi partial\ndecode-forward binning (HK-PDF-binning) combines PDF-binning with Han-Kobayashi\ncoding by further splitting rates and applying superposition coding,\nconditional binning and relaxed joint decoding.\n  In both schemes, the second sender decodes a part of the message from the\nfirst sender, then uses Gelfand-Pinsker binning technique to bin against the\ndecoded codeword, but in such a way that allows both state nullifying and\nforwarding. For the Gaussian channels, this PDF-binning essentializes to a\ncorrelation between the transmit signal and the binning state, which\nencompasses the traditional dirty-paper-coding binning as a special case when\nthis correlation factor is zero. We also provide the closed-form optimal\nbinning parameter for each scheme.\n  The 2-phase half-duplex schemes are adapted from the full-duplex ones by\nremoving block Markov encoding, sending different message parts in different\nphases and applying joint decoding across both phases. Analysis shows that the\nHK-PDF-binning scheme in both modes encompasses the Han-Kobayashi rate region\nand achieves both the partial decode-forward relaying rate for the first sender\nand interference-free rate for the second sender. Furthermore, this scheme\noutperforms all existing schemes. \n\n"}
{"id": "1112.3471", "contents": "Title: A Nonstochastic Information Theory for Communication and State\n  Estimation Abstract: In communications, unknown variables are usually modelled as random\nvariables, and concepts such as independence, entropy and information are\ndefined in terms of the underlying probability distributions. In contrast,\ncontrol theory often treats uncertainties and disturbances as bounded unknowns\nhaving no statistical structure. The area of networked control combines both\nfields, raising the question of whether it is possible to construct meaningful\nanalogues of stochastic concepts such as independence, Markovness, entropy and\ninformation without assuming a probability space. This paper introduces a\nframework for doing so, leading to the construction of a maximin information\nfunctional for nonstochastic variables. It is shown that the largest maximin\ninformation rate through a memoryless, error-prone channel in this framework\ncoincides with the block-coding zero-error capacity of the channel. Maximin\ninformation is then used to derive tight conditions for uniformly estimating\nthe state of a linear time-invariant system over such a channel, paralleling\nrecent results of Matveev and Savkin. \n\n"}
{"id": "1112.3599", "contents": "Title: Cooperative Network Navigation: Fundamental Limit and its Geometrical\n  Interpretation Abstract: Localization and tracking of moving nodes via network navigation gives rise\nto a new paradigm, where nodes exploit both temporal and spatial cooperation to\ninfer their positions based on intra- and inter-node measurements. While such\ncooperation can significantly improve the performance, it imposes intricate\ninformation processing that impedes network design and operation. In this\npaper, we establish a theoretical framework for cooperative network navigation\nand determine the fundamental limits of navigation accuracy using equivalent\nFisher information analysis. We then introduce the notion of carry-over\ninformation, and provide a geometrical interpretation of the navigation\ninformation and its evolution in time. Our framework unifies the navigation\ninformation obtained from temporal and spatial cooperation, leading to a deep\nunderstanding of information evolution in the network and benefit of\ncooperation. \n\n"}
{"id": "1112.4167", "contents": "Title: Iterative Deterministic Equivalents for the Performance Analysis of\n  Communication Systems Abstract: In this article, we introduce iterative deterministic equivalents as a novel\ntechnique for the performance analysis of communication systems whose channels\nare modeled by complex combinations of independent random matrices. This\ntechnique extends the deterministic equivalent approach for the study of\nfunctionals of large random matrices to a broader class of random matrix models\nwhich naturally arise as channel models in wireless communications. We present\ntwo specific applications: First, we consider a multi-hop amplify-and-forward\n(AF) MIMO relay channel with noise at each stage and derive deterministic\napproximations of the mutual information after the Kth hop. Second, we study a\nMIMO multiple access channel (MAC) where the channel between each transmitter\nand the receiver is represented by the double-scattering channel model. We\nprovide deterministic approximations of the mutual information, the\nsignal-to-interference-plus-noise ratio (SINR) and sum-rate with\nminimum-mean-square-error (MMSE) detection and derive the asymptotically\noptimal precoding matrices. In both scenarios, the approximations can be\ncomputed by simple and provably converging fixed-point algorithms and are shown\nto be almost surely tight in the limit when the number of antennas at each node\ngrows infinitely large. Simulations suggest that the approximations are\naccurate for realistic system dimensions. The technique of iterative\ndeterministic equivalents can be easily extended to other channel models of\ninterest and is, therefore, also a new contribution to the field of random\nmatrix theory. \n\n"}
{"id": "1112.4625", "contents": "Title: Pseudocodewords from Bethe Permanents Abstract: It was recently conjectured that a vector with components equal to the Bethe\npermanent of certain submatrices of a parity-check matrix is a pseudocodeword.\nIn this paper we prove a stronger version of this conjecture for some important\ncases and investigate the families of pseudocodewords obtained by using the\nBethe permanent. We also highlight some interesting properties of the permanent\nof block matrices and their effects on pseudocodewords. \n\n"}
{"id": "1112.4879", "contents": "Title: Interference Alignment: From Degrees-of-Freedom to Constant-Gap Capacity\n  Approximations Abstract: Interference alignment is a key technique for communication scenarios with\nmultiple interfering links. In several such scenarios, interference alignment\nwas used to characterize the degrees-of-freedom of the channel. However, these\ndegrees-of-freedom capacity approximations are often too weak to make accurate\npredictions about the behavior of channel capacity at finite signal-to-noise\nratios (SNRs). The aim of this paper is to significantly strengthen these\nresults by showing that interference alignment can be used to characterize\ncapacity to within a constant gap. We focus on real, time-invariant,\nfrequency-flat X-channels. The only known solutions achieving the\ndegrees-of-freedom of this channel are either based on real interference\nalignment or on layer-selection schemes. Neither of these solutions seems\nsufficient for a constant-gap capacity approximation.\n  In this paper, we propose a new communication scheme and show that it\nachieves the capacity of the Gaussian X-channel to within a constant gap. To\naid in this process, we develop a novel deterministic channel model. This\ndeterministic model depends on the 0.5log(SNR) most-significant bits of the\nchannel coefficients rather than only the single most-significant bit used in\nconventional deterministic models. The proposed deterministic model admits a\nwider range of achievable schemes that can be translated to the Gaussian\nchannel. For this deterministic model, we find an approximately optimal\ncommunication scheme. We then translate this scheme for the deterministic\nchannel to the original Gaussian X-channel and show that it achieves capacity\nto within a constant gap. This is the first constant-gap result for a general,\nfully-connected network requiring interference alignment. \n\n"}
{"id": "1201.0110", "contents": "Title: Weighted-Sum-Rate-Maximizing Linear Transceiver Filters for the K-User\n  MIMO Interference Channel Abstract: This letter is concerned with transmit and receive filter optimization for\nthe K-user MIMO interference channel. Specifically, linear transmit and receive\nfilter sets are designed which maximize the weighted sum rate while allowing\neach transmitter to utilize only the local channel state information. Our\napproach is based on extending the existing method of minimizing the weighted\nmean squared error (MSE) for the MIMO broadcast channel to the K-user\ninterference channel at hand. For the case of the individual transmitter power\nconstraint, however, a straightforward generalization of the existing method\ndoes not reveal a viable solution. It is in fact shown that there exists no\nclosed-form solution for the transmit filter but simple one-dimensional\nparameter search yields the desired solution. Compared to the direct filter\noptimization using gradient-based search, our solution requires considerably\nless computational complexity and a smaller amount of feedback resources while\nachieving essentially the same level of weighted sum rate. A modified filter\ndesign is also presented which provides desired robustness in the presence of\nchannel uncertainty \n\n"}
{"id": "1201.1997", "contents": "Title: An Enhanced DMT-optimality Criterion for STBC-schemes for Asymmetric\n  MIMO Systems Abstract: For any $n_t$ transmit, $n_r$ receive antenna ($n_t\\times n_r$) MIMO system\nin a quasi-static Rayleigh fading environment, it was shown by Elia et al. that\nlinear space-time block code-schemes (LSTBC-schemes) which have the\nnon-vanishing determinant (NVD) property are diversity-multiplexing gain\ntradeoff (DMT)-optimal for arbitrary values of $n_r$ if they have a code-rate\nof $n_t$ complex dimensions per channel use. However, for asymmetric MIMO\nsystems (where $n_r < n_t$), with the exception of a few LSTBC-schemes, it is\nunknown whether general LSTBC-schemes with NVD and a code-rate of $n_r$ complex\ndimensions per channel use are DMT-optimal. In this paper, an enhanced\nsufficient criterion for any STBC-scheme to be DMT-optimal is obtained, and\nusing this criterion, it is established that any LSTBC-scheme with NVD and a\ncode-rate of $\\min\\{n_t,n_r\\}$ complex dimensions per channel use is\nDMT-optimal. This result settles the DMT-optimality of several well-known,\nlow-ML-decoding-complexity LSTBC-schemes for certain asymmetric MIMO systems. \n\n"}
{"id": "1201.3328", "contents": "Title: Dynamic Spectrum Sharing Among Repeatedly Interacting Selfish Users With\n  Imperfect Monitoring Abstract: We develop a novel design framework for dynamic distributed spectrum sharing\namong secondary users (SUs) who adjust their power levels to compete for\nspectrum opportunities while satisfying the interference temperature (IT)\nconstraints imposed by primary users. The considered interaction among the SUs\nis characterized by the following three features. First, since the SUs are\ndecentralized, they are selfish and aim to maximize their own long-term payoffs\nfrom utilizing the network rather than obeying the prescribed allocation of a\ncentralized controller. Second, the SUs interact with each other repeatedly and\nthey can coexist in the system for a long time. Third, the SUs have limited and\nimperfect monitoring ability: they only observe whether the IT constraints are\nviolated, and their observation is imperfect due to the erroneous measurements.\nTo capture these features, we model the interaction of the SUs as a repeated\ngame with imperfect monitoring. We first characterize the set of Pareto optimal\npayoffs that can be achieved by deviation-proof spectrum sharing policies,\nwhich are policies that the selfish users find it in their interest to comply\nwith. Next, for any given payoff in this set, we show how to construct a\ndeviation-proof policy to achieve it. The constructed deviation-proof policy is\namenable to distributed implementation, and allows users to transmit in a\ntime-division multiple-access (TDMA) fashion. In the presence of strong\nmulti-user interference, our policy outperforms existing spectrum sharing\npolicies that dictate users to transmit at constant power levels\nsimultaneously. Moreover, our policy can achieve Pareto optimality even when\nthe SUs have limited and imperfect monitoring ability, as opposed to existing\nsolutions based on repeated games, which require perfect monitoring abilities. \n\n"}
{"id": "1201.3979", "contents": "Title: The one-way unlocalizable quantum discord Abstract: In this paper, we present the concept of the one-way unlocalizable quantum\ndiscord and investigate its properties. We provide a polygamy inequality for it\nin tripartite pure quantum system of arbitrary dimension. Several tradeoff\nrelations between the one-way unlocalizable quantum discord and other\ncorrelations are given. If the von Neumann measurement is on a part of the\nsystem, we give two expressions of the one-way unlocalizable quantum discord in\nterms of partial distillable entanglement and quantum disturbance. Finally, we\nalso provide a lower bound for bipartite shareability of quantum correlation\nbeyond entanglement in a tripartite system. \n\n"}
{"id": "1201.4334", "contents": "Title: Classification of Binary Self-Dual [48,24,10] Codes with an Automorphism\n  of Odd Prime Order Abstract: The purpose of this paper is to complete the classification of binary\nself-dual [48,24,10] codes with an automorphism of odd prime order. We prove\nthat if there is a self-dual [48, 24, 10] code with an automorphism of type\np-(c,f) with p being an odd prime, then p=3, c=16, f=0. By considering only an\nautomorphism of type 3-(16,0), we prove that there are exactly 264 inequivalent\nself-dual [48, 24, 10] codes with an automorphism of odd prime order,\nequivalently, there are exactly 264 inequivalent cubic self-dual [48, 24, 10]\ncodes. \n\n"}
{"id": "1201.6313", "contents": "Title: On X-Channels with Feedback and Delayed CSI Abstract: The sum degrees of freedom (DoF) of the two-user MIMO X-channel is\ncharacterized in the presence of output feedback and delayed channel state\ninformation (CSI). The number of antennas at each transmitters is assumed to be\nM and the number of antennas at each of the receivers is assumed to be N. It is\nshown that the sum DoF of the two-user MIMO X-channel is the same as the sum\nDoF of a two-user MIMO broadcast channel with 2M transmit antennas, and N\nantennas at each receiver. Hence, for this symmetric antenna configuration,\nthere is no performance loss in the sum degrees of freedom due to the\ndistributed nature of the transmitters. This result highlights the usefulness\nof feedback and delayed CSI for the MIMO X-channel.\n  The K-user X-channel with single antenna at each transmitter and each\nreceiver is also studied. In this network, each transmitter has a message\nintended for each receiver. For this network, it is shown that the sum DoF with\npartial output feedback alone is at least 2K/(K+1). This lower bound is\nstrictly better than the best lower bound known for the case of delayed CSI\nassumption for all values of K. \n\n"}
{"id": "1202.0206", "contents": "Title: Non-adaptive Group Testing: Explicit bounds and novel algorithms Abstract: We consider some computationally efficient and provably correct algorithms\nwith near-optimal sample-complexity for the problem of noisy non-adaptive group\ntesting. Group testing involves grouping arbitrary subsets of items into pools.\nEach pool is then tested to identify the defective items, which are usually\nassumed to be \"sparse\". We consider non-adaptive randomly pooling measurements,\nwhere pools are selected randomly and independently of the test outcomes. We\nalso consider a model where noisy measurements allow for both some false\nnegative and some false positive test outcomes (and also allow for asymmetric\nnoise, and activation noise). We consider three classes of algorithms for the\ngroup testing problem (we call them specifically the \"Coupon Collector\nAlgorithm\", the \"Column Matching Algorithms\", and the \"LP Decoding Algorithms\"\n-- the last two classes of algorithms (versions of some of which had been\nconsidered before in the literature) were inspired by corresponding algorithms\nin the Compressive Sensing literature. The second and third of these algorithms\nhave several flavours, dealing separately with the noiseless and noisy\nmeasurement scenarios. Our contribution is novel analysis to derive explicit\nsample-complexity bounds -- with all constants expressly computed -- for these\nalgorithms as a function of the desired error probability; the noise\nparameters; the number of items; and the size of the defective set (or an upper\nbound on it). We also compare the bounds to information-theoretic lower bounds\nfor sample complexity based on Fano's inequality and show that the upper and\nlower bounds are equal up to an explicitly computable universal constant factor\n(independent of problem parameters). \n\n"}
{"id": "1202.0357", "contents": "Title: Channel Identification and its Impact on Quantum LDPC Code Performance Abstract: In this work we probe the impact of channel estimation on the performance of\nquantum LDPC codes. Our channel estimation is based on an optimal estimate of\nthe relevant decoherence parameter via its quantum Fisher information. Using\nstate-of-the art quantum LDPC codes designed for the quantum depolarization\nchannel, and utilizing various quantum probes with different entanglement\nproperties, we show how the performance of such codes can deteriorate by an\norder of magnitude when optimal channel identification is fed into a belief\npropagation decoding algorithm. Our work highlights the importance in quantum\ncommunications of a viable channel identification campaign prior to decoding,\nand highlights the trade-off between entanglement consumption and quantum LDPC\ncode performance. \n\n"}
{"id": "1202.0533", "contents": "Title: Polar coding to achieve the Holevo capacity of a pure-loss optical\n  channel Abstract: In the low-energy high-energy-efficiency regime of classical optical\ncommunications---relevant to deep-space optical channels---there is a big gap\nbetween reliable communication rates achievable via conventional optical\nreceivers and the ultimate (Holevo) capacity. Achieving the Holevo capacity\nrequires not only optimal codes but also receivers that make collective\nmeasurements on long (modulated) codeword waveforms, and it is impossible to\nimplement these collective measurements via symbol-by-symbol detection along\nwith classical postprocessing. Here, we apply our recent results on the\nclassical-quantum polar code---the first near-explicit, linear,\nsymmetric-Holevo-rate achieving code---to the lossy optical channel, and we\nshow that it almost closes the entire gap to the Holevo capacity in the low\nphoton number regime. In contrast, Arikan's original polar codes, applied to\nthe DMC induced by the physical optical channel paired with any conceivable\nstructured optical receiver (including optical homodyne, heterodyne, or\ndirect-detection) fails to achieve the ultimate Holevo limit to channel\ncapacity. However, our polar code construction (which uses the quantum fidelity\nas a channel parameter rather than the classical Bhattacharyya quantity to\nchoose the \"good channels\" in the polar-code construction), paired with a\nquantum successive-cancellation receiver---which involves a sequence of\ncollective non-destructive binary projective measurements on the joint quantum\nstate of the received codeword waveform---can attain the Holevo limit, and can\nhence in principle achieve higher rates than Arikan's polar code and decoder\ndirectly applied to the optical channel. However, even a theoretical recipe for\nconstruction of an optical realization of the quantum successive-cancellation\nreceiver remains an open question. \n\n"}
{"id": "1202.0607", "contents": "Title: On the Alternative Relaying Diamond Channel with Conferencing Links Abstract: In this paper, the diamond relay channel is considered, which consists of one\nsource-destination pair and two relay nodes connected with rate-limited\nout-of-band conferencing links. In particular, we focus on the half-duplex\nalternative relaying strategy, in which the two relays operate alternatively\nover time. With different amounts of delay, two conferencing strategies are\nproposed, each of which can be implemented by either a general two-side\nconferencing scheme (for which both of the two conferencing links are used) or\na special-case one-side conferencing scheme (for which only one of the two\nconferencing links is used). Based on the most general two-side conferencing\nscheme, we derive the achievable rates by using the decode-and-forward (DF) and\namplify-and-forward (AF) relaying schemes, and show that these rate\nmaximization problems are convex. By further exploiting the properties of the\noptimal solutions, the simpler one-side conferencing is shown to be equally\ngood as the two-side conferencing in term of the achievable rates under\narbitrary channel conditions. Based on this, the DF rate in closed-form is\nobtained, and the principle to use which one of the two conferencing links for\none-side conferencing is also established. Moreover, the DF scheme is shown to\nbe capacity-achieving under certain conditions with even one-side conferencing.\nFor the AF relaying scheme, one-side conferencing is shown to be sub-optimal in\ngeneral. Finally, numerical results are provided to validate our analysis. \n\n"}
{"id": "1202.0977", "contents": "Title: The Capacity of the Semi-Deterministic Cognitive Interference Channel\n  with a Common Cognitive Message and Approximate Capacity for the Gaussian\n  Case Abstract: In this paper the study of the cognitive interference channel with a common\nmessage, a variation of the classical cognitive interference channel in which\nthe cognitive message is decoded at both receivers. We derive the capacity for\nthe semideterministic channel in which the output at the cognitive decoder is a\ndeterministic function of the channel inputs. We also show capacity to within a\nconstant gap and a constant factor for the Gaussian channel in which the\noutputs are linear combinations of the channel inputs plus an additive Gaussian\nnoise term. Most of these results are shown using an interesting transmission\nscheme in which the cognitive message, decoded at both receivers, is also\npre-coded against the interference experienced at the cognitive decoder. The\npre-coding of the cognitive message does not allow the primary decoder to\nreconstruct the interfering signal. The cognitive message acts instead as a\nside information at the primary receiver when decoding its intended message. \n\n"}
{"id": "1202.1332", "contents": "Title: Secure Multiplex Coding with Dependent and Non-Uniform Multiple Messages Abstract: The secure multiplex coding (SMC) is a technique to remove rate loss in the\ncoding for wire-tap channels and broadcast channels with confidential messages\ncaused by the inclusion of random bits into transmitted signals. SMC replaces\nthe random bits by other meaningful secret messages, and a collection of secret\nmessages serves as the random bits to hide the rest of messages. In the\nprevious researches, multiple secret messages were assumed to have independent\nand uniform distributions, which is difficult to be ensured in practice. We\nremove this restrictive assumption by a generalization of the channel\nresolvability technique.\n  We also give practical construction techniques for SMC by using an arbitrary\ngiven error-correcting code as an ingredient, and channel-universal coding of\nSMC. By using the same principle as the channel-universal SMC, we give coding\nfor the broadcast channel with confidential messages universal to both channel\nand source distributions. \n\n"}
{"id": "1202.3987", "contents": "Title: Beyond the Blacklist: Modeling Malware Spread and the Effect of\n  Interventions Abstract: Malware spread among websites and between websites and clients is an\nincreasing problem. Search engines play an important role in directing users to\nwebsites and are a natural control point for intervening, using mechanisms such\nas blacklisting. The paper presents a simple Markov model of malware spread\nthrough large populations of websites and studies the effect of two\ninterventions that might be deployed by a search provider: blacklisting\ninfected web pages by removing them from search results entirely and a\ngeneralization of blacklisting, called depreferencing, in which a website's\nranking is decreased by a fixed percentage each time period the site remains\ninfected. We analyze and study the trade-offs between infection exposure and\ntraffic loss due to false positives (the cost to a website that is incorrectly\nblacklisted) for different interventions. As expected, we find that\ninterventions are most effective when websites are slow to remove infections.\nSurprisingly, we also find that low infection or recovery rates can increase\ntraffic loss due to false positives. Our analysis also shows that heavy-tailed\ndistributions of website popularity, as documented in many studies, leads to\nhigh sample variance of all measured outcomes. These result implies that it\nwill be difficult to determine empirically whether certain website\ninterventions are effective, and it suggests that theoretical models such as\nthe one described in this paper have an important role to play in improving web\nsecurity. \n\n"}
{"id": "1202.3993", "contents": "Title: Internet Topology over Time Abstract: There are few studies that look closely at how the topology of the Internet\nevolves over time; most focus on snapshots taken at a particular point in time.\nIn this paper, we investigate the evolution of the topology of the Autonomous\nSystems graph of the Internet, examining how eight commonly-used topological\nmeasures change from January 2002 to January 2010. We find that the\ndistributions of most of the measures remain unchanged, except for average path\nlength and clustering coefficient. The average path length has slowly and\nsteadily increased since 2005 and the average clustering coefficient has\nsteadily declined. We hypothesize that these changes are due to changes in\npeering policies as the Internet evolves. We also investigate a surprising\nfeature, namely that the maximum degree has changed little, an aspect that\ncannot be captured without modeling link deletion. Our results suggest that\nevaluating models of the Internet graph by comparing steady-state generated\ntopologies to snapshots of the real data is reasonable for many measures.\nHowever, accurately matching time-variant properties is more difficult, as we\ndemonstrate by evaluating ten well-known models against the 2010 data. \n\n"}
{"id": "1202.5302", "contents": "Title: Application of Steganography for Anonymity through the Internet Abstract: In this paper, a novel steganographic scheme based on chaotic iterations is\nproposed. This research work takes place into the information hiding security\nframework. The applications for anonymity and privacy through the Internet are\nregarded too. To guarantee such an anonymity, it should be possible to set up a\nsecret communication channel into a web page, being both secure and robust. To\nachieve this goal, we propose an information hiding scheme being stego-secure,\nwhich is the highest level of security in a well defined and studied category\nof attacks called \"watermark-only attack\". This category of attacks is the best\ncontext to study steganography-based anonymity through the Internet. The\nsteganalysis of our steganographic process is also studied in order to show it\nsecurity in a real test framework. \n\n"}
{"id": "1202.5413", "contents": "Title: On the Joint Error-and-Erasure Decoding for Irreducible Polynomial\n  Remainder Codes Abstract: A general class of polynomial remainder codes is considered. Such codes are\nvery flexible in rate and length and include Reed-Solomon codes as a special\ncase.\n  As an extension of previous work, two joint error-and-erasure decoding\napproaches are proposed. In particular, both the decoding approaches by means\nof a fixed transform are treated in a way compatible with the error-only\ndecoding. In the end, a collection of gcd-based decoding algorithm is obtained,\nsome of which appear to be new even when specialized to Reed-Solomon codes. \n\n"}
{"id": "1202.5830", "contents": "Title: On Secrecy Rate of the Generalized Artificial-Noise Assisted Secure\n  Beamforming for Wiretap Channels Abstract: In this paper we consider the secure transmission in fast Rayleigh fading\nchannels with full knowledge of the main channel and only the statistics of the\neavesdropper's channel state information at the transmitter. For the\nmultiple-input, single-output, single-antenna eavesdropper systems, we\ngeneralize Goel and Negi's celebrated artificial-noise (AN) assisted\nbeamforming, which just selects the directions to transmit AN heuristically.\nOur scheme may inject AN to the direction of the message, which outperforms\nGoel and Negi's scheme where AN is only injected in the directions orthogonal\nto the main channel. The ergodic secrecy rate of the proposed AN scheme can be\nrepresented by a highly simplified power allocation problem. To attain it, we\nprove that the optimal transmission scheme for the message bearing signal is a\nbeamformer, which is aligned to the direction of the legitimate channel. After\ncharacterizing the optimal eigenvectors of the covariance matrices of signal\nand AN, we also provide the necessary condition for transmitting AN in the main\nchannel to be optimal. Since the resulting secrecy rate is a non-convex power\nallocation problem, we develop an algorithm to efficiently solve it. Simulation\nresults show that our generalized AN scheme outperforms Goel and Negi's,\nespecially when the quality of legitimate channel is much worse than that of\neavesdropper's. In particular, the regime with non-zero secrecy rate is\nenlarged, which can significantly improve the connectivity of the secure\nnetwork when the proposed AN assisted beamforming is applied. \n\n"}
{"id": "1202.5857", "contents": "Title: Algebraic Fast-Decodable Relay Codes for Distributed Communications Abstract: In this paper, fast-decodable lattice code constructions are designed for the\nnonorthogonal amplify-and-forward (NAF) multiple-input multiple-output (MIMO)\nchannel. The constructions are based on different types of algebraic\nstructures, e.g. quaternion division algebras. When satisfying certain\nproperties, these algebras provide us with codes whose structure naturally\nreduces the decoding complexity. The complexity can be further reduced by\nshortening the block length, i.e., by considering rectangular codes called less\nthan minimum delay (LMD) codes. \n\n"}
{"id": "1202.6038", "contents": "Title: Multiflow Transmission in Delay Constrained Cooperative Wireless\n  Networks Abstract: This paper considers the problem of energy-efficient transmission in\nmulti-flow multihop cooperative wireless networks. Although the performance\ngains of cooperative approaches are well known, the combinatorial nature of\nthese schemes makes it difficult to design efficient polynomial-time algorithms\nfor joint routing, scheduling and power control. This becomes more so when\nthere is more than one flow in the network. It has been conjectured by many\nauthors, in the literature, that the multiflow problem in cooperative networks\nis an NP-hard problem. In this paper, we formulate the problem, as a\ncombinatorial optimization problem, for a general setting of $k$-flows, and\nformally prove that the problem is not only NP-hard but it is\n$o(n^{1/7-\\epsilon})$ inapproxmiable. To our knowledge*, these results provide\nthe first such inapproxmiablity proof in the context of multiflow cooperative\nwireless networks. We further prove that for a special case of k = 1 the\nsolution is a simple path, and devise a polynomial time algorithm for jointly\noptimizing routing, scheduling and power control. We then use this algorithm to\nestablish analytical upper and lower bounds for the optimal performance for the\ngeneral case of $k$ flows. Furthermore, we propose a polynomial time heuristic\nfor calculating the solution for the general case and evaluate the performance\nof this heuristic under different channel conditions and against the analytical\nupper and lower bounds. \n\n"}
{"id": "1203.0474", "contents": "Title: Orthogonal Designs and a Cubic Binary Function Abstract: Orthogonal designs are fundamental mathematical notions used in the\nconstruction of space time block codes for wireless transmissions. Designs have\ntwo important parameters, the rate and the decoding delay; the main problem of\nthe theory is to construct designs maximizing the rate and minimizing the\ndecoding delay. All known constructions of CODs are inductive or algorithmic.\nIn this paper, we present an explicit construction of optimal CODs. We do not\napply recurrent procedures and do calculate the matrix elements directly. Our\nformula is based on a cubic function in two binary n-vectors. In our previous\nwork (Comm. Math. Phys., 2010, and J. Pure and Appl. Algebra, 2011), we used\nthis function to define a series of non-associative algebras generalizing the\nclassical algebra of octonions and to obtain sum of squares identities of\nHurwitz-Radon type. \n\n"}
{"id": "1203.1527", "contents": "Title: Optimum Subcodes of Self-Dual Codes and Their Optimum Distance Profiles Abstract: Binary optimal codes often contain optimal or near-optimal subcodes. In this\npaper we show that this is true for the family of self-dual codes. One approach\nis to compute the optimum distance profiles (ODPs) of linear codes, which was\nintroduced by Luo, et. al. (2010). One of our main results is the development\nof general algorithms, called the Chain Algorithms, for finding ODPs of linear\ncodes. Then we determine the ODPs for the Type II codes of lengths up to 24 and\nthe extremal Type II codes of length 32, give a partial result of the ODP of\nthe extended quadratic residue code $q_{48}$ of length 48. We also show that\nthere does not exist a $[48,k,16]$ subcode of $q_{48}$ for $k \\ge 17$, and we\nfind a first example of a doubly-even self-complementary $[48, 16, 16]$ code. \n\n"}
{"id": "1203.1854", "contents": "Title: Local-Optimality Guarantees for Optimal Decoding Based on Paths Abstract: This paper presents a unified analysis framework that captures recent\nadvances in the study of local-optimality characterizations for codes on\ngraphs. These local-optimality characterizations are based on combinatorial\nstructures embedded in the Tanner graph of the code. Local-optimality implies\nboth unique maximum-likelihood (ML) optimality and unique linear-programming\n(LP) decoding optimality. Also, an iterative message-passing decoding algorithm\nis guaranteed to find the unique locally-optimal codeword, if one exists.\n  We demonstrate this proof technique by considering a definition of\nlocal-optimality that is based on the simplest combinatorial structures in\nTanner graphs, namely, paths of length $h$. We apply the technique of\nlocal-optimality to a family of Tanner codes. Inverse polynomial bounds in the\ncode length are proved on the word error probability of LP-decoding for this\nfamily of Tanner codes. \n\n"}
{"id": "1203.2297", "contents": "Title: Analog network coding in general SNR regime: Performance of a greedy\n  scheme Abstract: The problem of maximum rate achievable with analog network coding for a\nunicast communication over a layered relay network with directed links is\nconsidered. A relay node performing analog network coding scales and forwards\nthe signals received at its input. Recently this problem has been considered\nunder certain assumptions on per node scaling factor and received SNR.\nPreviously, we established a result that allows us to characterize the optimal\nperformance of analog network coding in network scenarios beyond those that can\nbe analyzed using the approaches based on such assumptions.\n  The key contribution of this work is a scheme to greedily compute a lower\nbound to the optimal rate achievable with analog network coding in the general\nlayered networks. This scheme allows for exact computation of the optimal\nachievable rates in a wider class of layered networks than those that can be\naddressed using existing approaches. For the specific case of Gaussian N-relay\ndiamond network, to the best of our knowledge, the proposed scheme provides the\nfirst exact characterization of the optimal rate achievable with analog network\ncoding. Further, for general layered networks, our scheme allows us to compute\noptimal rates within a constant gap from the cut-set upper bound asymptotically\nin the source power. \n\n"}
{"id": "1203.2316", "contents": "Title: Near-optimal quantization and linear network coding for relay networks Abstract: We introduce a discrete network corresponding to any Gaussian wireless\nnetwork that is obtained by simply quantizing the received signals and\nrestricting the transmitted signals to a finite precision. Since signals in the\ndiscrete network are obtained from those of a Gaussian network, the Gaussian\nnetwork can be operated on the quantization-based digital interface defined by\nthe discrete network. We prove that this digital interface is near-optimal for\nGaussian relay networks and the capacities of the Gaussian and the discrete\nnetworks are within a bounded gap of O(M^2) bits, where M is the number of\nnodes.\n  We prove that any near-optimal coding strategy for the discrete network can\nbe naturally transformed into a near-optimal coding strategy for the Gaussian\nnetwork merely by quantization. We exploit this by designing a linear coding\nstrategy for the case of layered discrete relay networks. The linear coding\nstrategy is near-optimal for Gaussian and discrete networks and achieves rates\nwithin O(M^2) bits of the capacity, independent of channel gains or SNR. The\nlinear code is robust and the relays need not know the channel gains. The\ntransmit and receive signals at all relays are simply quantized to binary\ntuples of the same length $n$ . The linear network code requires all the relay\nnodes to collect the received binary tuples into a long binary vector and apply\na linear transformation on the long vector. The resulting binary vector is\nsplit into smaller binary tuples for transmission by the relays. The\nquantization requirements of the linear network code are completely defined by\nthe parameter $n$, which also determines the resolution of the\nanalog-to-digital and digital-to-analog convertors for operating the network\nwithin a bounded gap of the network's capacity. The linear network code\nexplicitly connects network coding for wireline networks with codes for\nGaussian networks. \n\n"}
{"id": "1203.3037", "contents": "Title: Expanding the Transfer Entropy to Identify Information Subgraphs in\n  Complex Systems Abstract: We propose a formal expansion of the transfer entropy to put in evidence\nirreducible sets of variables which provide information for the future state of\neach assigned target. Multiplets characterized by a large contribution to the\nexpansion are associated to informational circuits present in the system, with\nan informational character which can be associated to the sign of the\ncontribution. For the sake of computational complexity, we adopt the assumption\nof Gaussianity and use the corresponding exact formula for the conditional\nmutual information. We report the application of the proposed methodology on\ntwo EEG data sets. \n\n"}
{"id": "1203.4865", "contents": "Title: Successive Refinement with Decoder Cooperation and its Channel Coding\n  Duals Abstract: We study cooperation in multi terminal source coding models involving\nsuccessive refinement. Specifically, we study the case of a single encoder and\ntwo decoders, where the encoder provides a common description to both the\ndecoders and a private description to only one of the decoders. The decoders\ncooperate via cribbing, i.e., the decoder with access only to the common\ndescription is allowed to observe, in addition, a deterministic function of the\nreconstruction symbols produced by the other. We characterize the fundamental\nperformance limits in the respective settings of non-causal, strictly-causal\nand causal cribbing. We use a new coding scheme, referred to as Forward\nEncoding and Block Markov Decoding, which is a variant of one recently used by\nCuff and Zhao for coordination via implicit communication. Finally, we use the\ninsight gained to introduce and solve some dual channel coding scenarios\ninvolving Multiple Access Channels with cribbing. \n\n"}
{"id": "1203.4867", "contents": "Title: Multi-hop Analog Network Coding: An Amplify-and-Forward Approach Abstract: In this paper, we study the performance of an amplify-and-forward (AF) based\nanalog network coding (ANC) relay scheme in a multi-hop wireless network under\nindividual power constraints. In the first part, a unicast scenario is\nconsidered. The problem of finding the maximum achievable rate is formulated as\nan optimization problem. Rather than solving this non-concave maximization\nproblem, we derive upper and lower bounds for the optimal rate. A cut-set like\nupper bound is obtained in a closed form for a layered relay network. A\npseudo-optimal AF scheme is developed for a two-hop parallel network, which is\ndifferent from the conventional scheme with all amplification gains chosen as\nthe maximum possible values. The conditions under which either the novel scheme\nor the conventional one achieves a rate within half a bit of the upper bound\nare found. Then we provide an AF-based multi-hop ANC scheme with the two\nschemes for a layered relay network. It is demonstrated that the lower bound of\nthe optimal rate can asymptotically achieve the upper bound when the network is\nin the generalized high-SNR regime. In the second part, the optimal rate region\nfor a two-hop multiple access channel (MAC) via AF relays is investigated. In a\nsimilar manner, we first derive an outer bound for it and then focus on\ndesigning low complexity AF-based ANC schemes for different scenarios. Several\nexamples are given and the numerical results indicate that the achievable rate\nregion of the ANC schemes can perform close to the outer bound. \n\n"}
{"id": "1203.5572", "contents": "Title: Causal conditioning and instantaneous coupling in causality graphs Abstract: The paper investigates the link between Granger causality graphs recently\nformalized by Eichler and directed information theory developed by Massey and\nKramer. We particularly insist on the implication of two notions of causality\nthat may occur in physical systems. It is well accepted that dynamical\ncausality is assessed by the conditional transfer entropy, a measure appearing\nnaturally as a part of directed information. Surprisingly the notion of\ninstantaneous causality is often overlooked, even if it was clearly understood\nin early works. In the bivariate case, instantaneous coupling is measured\nadequately by the instantaneous information exchange, a measure that\nsupplements the transfer entropy in the decomposition of directed information.\nIn this paper, the focus is put on the multivariate case and conditional graph\nmodeling issues. In this framework, we show that the decomposition of directed\ninformation into the sum of transfer entropy and information exchange does not\nhold anymore. Nevertheless, the discussion allows to put forward the two\nmeasures as pillars for the inference of causality graphs. We illustrate this\non two synthetic examples which allow us to discuss not only the theoretical\nconcepts, but also the practical estimation issues. \n\n"}
{"id": "1203.5638", "contents": "Title: On MMSE Properties and I-MMSE Implications in Parallel MIMO Gaussian\n  Channels Abstract: The scalar additive Gaussian noise channel has the \"single crossing point\"\nproperty between the minimum-mean square error (MMSE) in the estimation of the\ninput given the channel output, assuming a Gaussian input to the channel, and\nthe MMSE assuming an arbitrary input. This paper extends the result to the\nparallel MIMO additive Gaussian channel in three phases: i) The channel matrix\nis the identity matrix, and we limit the Gaussian input to a vector of Gaussian\ni.i.d. elements. The \"single crossing point\" property is with respect to the\nsnr (as in the scalar case). ii) The channel matrix is arbitrary, the Gaussian\ninput is limited to an independent Gaussian input. A \"single crossing point\"\nproperty is derived for each diagonal element of the MMSE matrix. iii) The\nGaussian input is allowed to be an arbitrary Gaussian random vector. A \"single\ncrossing point\" property is derived for each eigenvalue of the MMSE matrix.\n  These three extensions are then translated to new information theoretic\nproperties on the mutual information, using the fundamental relationship\nbetween estimation theory and information theory. The results of the last phase\nare also translated to a new property of Fisher's information. Finally, the\napplicability of all three extensions on information theoretic problems is\ndemonstrated through: a proof of a special case of Shannon's vector EPI, a\nconverse proof of the capacity region of the parallel degraded MIMO broadcast\nchannel (BC) under per-antenna power constrains and under covariance\nconstraints, and a converse proof of the capacity region of the compound\nparallel degraded MIMO BC under covariance constraint. \n\n"}
{"id": "1203.6396", "contents": "Title: Achievable Rates for Noisy Channels with Synchronization Errors Abstract: We develop several lower bounds on the capacity of binary input symmetric\noutput channels with synchronization errors which also suffer from other types\nof impairments such as substitutions, erasures, additive white Gaussian noise\n(AWGN) etc. More precisely, we show that if the channel with synchronization\nerrors can be decomposed into a cascade of two channels where only the first\none suffers from synchronization errors and the second one is a memoryless\nchannel, a lower bound on the capacity of the original channel in terms of the\ncapacity of the synchronization error-only channel can be derived. To\naccomplish this, we derive lower bounds on the mutual information rate between\nthe transmitted and received sequences (for the original channel) for an\narbitrary input distribution, and then relate this result to the channel\ncapacity. The results apply without the knowledge of the exact capacity\nachieving input distributions. A primary application of our results is that we\ncan employ any lower bound derived on the capacity of the first channel\n(synchronization error channel in the decomposition) to find lower bounds on\nthe capacity of the (original) noisy channel with synchronization errors. We\napply the general ideas to several specific classes of channels such as\nsynchronization error channels with erasures and substitutions, with symmetric\nq-ary outputs and with AWGN explicitly, and obtain easy-to-compute bounds. We\nillustrate that, with our approach, it is possible to derive tighter capacity\nlower bounds compared to the currently available bounds in the literature for\ncertain classes of channels, e.g., deletion/substitution channels and\ndeletion/AWGN channels (for certain signal to noise ratio (SNR) ranges). \n\n"}
{"id": "1203.6866", "contents": "Title: Cryptanalysis of a one round chaos-based Substitution Permutation\n  Network Abstract: The interleaving of chaos and cryptography has been the aim of a large set of\nworks since the beginning of the nineties. Many encryption proposals have been\nintroduced to improve conventional cryptography. However, many proposals\npossess serious problems according to the basic requirements for the secure\nexchange of information. In this paper we highlight some of the main problems\nof chaotic cryptography by means of the analysis of a very recent chaotic\ncryptosystem based on a one round Substitution Permutation Network. More\nspecifically, we show that it is not possible to avoid the security problems of\nthat encryption architecture just by including a chaotic system as core of the\nderived encryption system. \n\n"}
{"id": "1204.0562", "contents": "Title: Atomic norm denoising with applications to line spectral estimation Abstract: Motivated by recent work on atomic norms in inverse problems, we propose a\nnew approach to line spectral estimation that provides theoretical guarantees\nfor the mean-squared-error (MSE) performance in the presence of noise and\nwithout knowledge of the model order. We propose an abstract theory of\ndenoising with atomic norms and specialize this theory to provide a convex\noptimization problem for estimating the frequencies and phases of a mixture of\ncomplex exponentials. We show that the associated convex optimization problem\ncan be solved in polynomial time via semidefinite programming (SDP). We also\nshow that the SDP can be approximated by an l1-regularized least-squares\nproblem that achieves nearly the same error rate as the SDP but can scale to\nmuch larger problems. We compare both SDP and l1-based approaches with\nclassical line spectral analysis methods and demonstrate that the SDP\noutperforms the l1 optimization which outperforms MUSIC, Cadzow's, and Matrix\nPencil approaches in terms of MSE over a wide range of signal-to-noise ratios. \n\n"}
{"id": "1204.1595", "contents": "Title: Femtocaching and Device-to-Device Collaboration: A New Architecture for\n  Wireless Video Distribution Abstract: We present a new architecture to handle the ongoing explosive increase in the\ndemand for video content in wireless networks. It is based on distributed\ncaching of the content in femto-basestations with small or non-existing\nbackhaul capacity but with considerable storage space, called helper nodes. We\nalso consider using the mobile terminals themselves as caching helpers, which\ncan distribute video through device-to-device communications. This approach\nallows an improvement in the video throughput without deployment of any\nadditional infrastructure. The new architecture can improve video throughput by\none to two orders-of-magnitude. \n\n"}
{"id": "1204.2611", "contents": "Title: Recovery from Linear Measurements with Complexity-Matching Universal\n  Signal Estimation Abstract: We study the compressed sensing (CS) signal estimation problem where an input\nsignal is measured via a linear matrix multiplication under additive noise.\nWhile this setup usually assumes sparsity or compressibility in the input\nsignal during recovery, the signal structure that can be leveraged is often not\nknown a priori. In this paper, we consider universal CS recovery, where the\nstatistics of a stationary ergodic signal source are estimated simultaneously\nwith the signal itself. Inspired by Kolmogorov complexity and minimum\ndescription length, we focus on a maximum a posteriori (MAP) estimation\nframework that leverages universal priors to match the complexity of the\nsource. Our framework can also be applied to general linear inverse problems\nwhere more measurements than in CS might be needed. We provide theoretical\nresults that support the algorithmic feasibility of universal MAP estimation\nusing a Markov chain Monte Carlo implementation, which is computationally\nchallenging. We incorporate some techniques to accelerate the algorithm while\nproviding comparable and in many cases better reconstruction quality than\nexisting algorithms. Experimental results show the promise of universality in\nCS, particularly for low-complexity sources that do not exhibit standard\nsparsity or compressibility. \n\n"}
{"id": "1204.4204", "contents": "Title: Tilings with $n$-Dimensional Chairs and their Applications to Asymmetric\n  Codes Abstract: An $n$-dimensional chair consists of an $n$-dimensional box from which a\nsmaller $n$-dimensional box is removed. A tiling of an $n$-dimensional chair\nhas two nice applications in coding for write-once memories. The first one is\nin the design of codes which correct asymmetric errors with limited-magnitude.\nThe second one is in the design of $n$ cells $q$-ary write-once memory codes.\nWe show an equivalence between the design of a tiling with an integer lattice\nand the design of a tiling from a generalization of splitting (or of Sidon\nsequences). A tiling of an $n$-dimensional chair can define a perfect code for\ncorrecting asymmetric errors with limited-magnitude. We present constructions\nfor such tilings and prove cases where perfect codes for these type of errors\ndo not exist. \n\n"}
{"id": "1204.5028", "contents": "Title: Regenerating Codes: A System Perspective Abstract: The explosion of the amount of data stored in cloud systems calls for more\nefficient paradigms for redundancy. While replication is widely used to ensure\ndata availability, erasure correcting codes provide a much better trade-off\nbetween storage and availability. Regenerating codes are good candidates for\nthey also offer low repair costs in term of network bandwidth. While they have\nbeen proven optimal, they are difficult to understand and parameterize. In this\npaper we provide an analysis of regenerating codes for practitioners to grasp\nthe various trade-offs. More specifically we make two contributions: (i) we\nstudy the impact of the parameters by conducting an analysis at the level of\nthe system, rather than at the level of a single device; (ii) we compare the\ncomputational costs of various implementations of codes and highlight the most\nefficient ones. Our goal is to provide system designers with concrete\ninformation to help them choose the best parameters and design for regenerating\ncodes. \n\n"}
{"id": "1204.5507", "contents": "Title: Dynamic Network Delay Cartography Abstract: Path delays in IP networks are important metrics, required by network\noperators for assessment, planning, and fault diagnosis. Monitoring delays of\nall source-destination pairs in a large network is however challenging and\nwasteful of resources. The present paper advocates a spatio-temporal Kalman\nfiltering approach to construct network-wide delay maps using measurements on\nonly a few paths. The proposed network cartography framework allows efficient\ntracking and prediction of delays by relying on both topological as well as\nhistorical data. Optimal paths for delay measurement are selected in an online\nfashion by leveraging the notion of submodularity. The resulting predictor is\noptimal in the class of linear predictors, and outperforms competing\nalternatives on real-world datasets. \n\n"}
{"id": "1204.6100", "contents": "Title: On the Overhead of Interference Alignment: Training, Feedback, and\n  Cooperation Abstract: Interference alignment (IA) is a cooperative transmission strategy that,\nunder some conditions, achieves the interference channel's maximum number of\ndegrees of freedom. Realizing IA gains, however, is contingent upon providing\ntransmitters with sufficiently accurate channel knowledge. In this paper, we\nstudy the performance of IA in multiple-input multiple-output systems where\nchannel knowledge is acquired through training and analog feedback. We design\nthe training and feedback system to maximize IA's effective sum-rate: a\nnon-asymptotic performance metric that accounts for estimation error, training\nand feedback overhead, and channel selectivity. We characterize effective\nsum-rate with overhead in relation to various parameters such as\nsignal-to-noise ratio, Doppler spread, and feedback channel quality. A main\ninsight from our analysis is that, by properly designing the CSI acquisition\nprocess, IA can provide good sum-rate performance in a very wide range of\nfading scenarios. Another observation from our work is that such overhead-aware\nanalysis can help solve a number of practical network design problems. To\ndemonstrate the concept of overhead-aware network design, we consider the\nexample problem of finding the optimal number of cooperative IA users based on\nsignal power and mobility. \n\n"}
{"id": "1205.0618", "contents": "Title: Wireless Information and Power Transfer: Architecture Design and\n  Rate-Energy Tradeoff Abstract: Simultaneous information and power transfer over the wireless channels\npotentially offers great convenience to mobile users. Yet practical receiver\ndesigns impose technical constraints on its hardware realization, as practical\ncircuits for harvesting energy from radio signals are not yet able to decode\nthe carried information directly. To make theoretical progress, we propose a\ngeneral receiver operation, namely, dynamic power splitting (DPS), which splits\nthe received signal with adjustable power ratio for energy harvesting and\ninformation decoding, separately. Three special cases of DPS, namely, time\nswitching (TS), static power splitting (SPS) and on-off power splitting (OPS)\nare investigated. The TS and SPS schemes can be treated as special cases of\nOPS. Moreover, we propose two types of practical receiver architectures,\nnamely, separated versus integrated information and energy receivers. The\nintegrated receiver integrates the front-end components of the separated\nreceiver, thus achieving a smaller form factor. The rate-energy tradeoff for\nthe two architectures are characterized by a so-called rate-energy (R-E)\nregion. The optimal transmission strategy is derived to achieve different\nrate-energy tradeoffs. With receiver circuit power consumption taken into\naccount, it is shown that the OPS scheme is optimal for both receivers. For the\nideal case when the receiver circuit does not consume power, the SPS scheme is\noptimal for both receivers. In addition, we study the performance for the two\ntypes of receivers under a realistic system setup that employs practical\nmodulation. Our results provide useful insights to the optimal practical\nreceiver design for simultaneous wireless information and power transfer\n(SWIPT). \n\n"}
{"id": "1205.1069", "contents": "Title: Asymptotic $L^4$ norm of polynomials derived from characters Abstract: Littlewood investigated polynomials with coefficients in $\\{-1,1\\}$\n(Littlewood polynomials), to see how small their ratio of norms\n$||f||_4/||f||_2$ on the unit circle can become as $deg(f)\\to\\infty$. A small\nlimit is equivalent to slow growth in the mean square autocorrelation of the\nassociated binary sequences of coefficients of the polynomials. The\nautocorrelation problem for arrays and higher dimensional objects has also been\nstudied; it is the natural generalization to multivariable polynomials. Here we\nfind, for each $n > 1$, a family of $n$-variable Littlewood polynomials with\nlower asymptotic $||f||_4/||f||_2$ than any known hitherto. We discover these\nthrough a wide survey, infeasible with previous methods, of polynomials whose\ncoefficients come from finite field characters. This is the first time that the\nlowest known asymptotic ratio of norms $||f||_4/||f||_2$ for multivariable\npolynomials $f(z_1,...,z_n)$ is strictly less than what could be obtained by\nusing products $f_1(z_1)... f_n(z_n)$ of the best known univariate polynomials. \n\n"}
{"id": "1205.5134", "contents": "Title: Iterated Space-Time Code Constructions from Cyclic Algebras Abstract: We propose a full-rate iterated space-time code construction, to design\n2n-dimensional codes from n-dimensional cyclic algebra based codes. We give a\ncondition to determine whether the resulting codes satisfy the full-diversity\nproperty, and study their maximum likelihood decoding complexity with respect\nto sphere decoding. Particular emphasis is given to the cases n = 2, sometimes\nreferred to as MIDO (multiple input double output) codes, and n = 3. In the\nprocess, we derive an interesting way of obtaining division algebras, and study\ntheir center and maximal subfield. \n\n"}
{"id": "1205.5603", "contents": "Title: The Finite Field Multi-Way Relay Channel with Correlated Sources: Beyond\n  Three Users Abstract: The multi-way relay channel (MWRC) models cooperative communication networks\nin which many users exchange messages via a relay. In this paper, we consider\nthe finite field MWRC with correlated messages. The problem is to find all\nachievable rates, defined as the number of channel uses required per reliable\nexchange of message tuple. For the case of three users, we have previously\nestablished that for a special class of source distributions, the set of all\nachievable rates can be found [Ong et al., ISIT 2010]. The class is specified\nby an almost balanced conditional mutual information (ABCMI) condition. In this\npaper, we first generalize the ABCMI condition to the case of more than three\nusers. We then show that if the sources satisfy the ABCMI condition, then the\nset of all achievable rates is found and can be attained using a separate\nsource-channel coding architecture. \n\n"}
{"id": "1205.5614", "contents": "Title: Performance Analysis of Optimal Single Stream Beamforming in MIMO\n  Dual-Hop AF Systems Abstract: This paper investigates the performance of optimal single stream beamforming\nschemes in multiple-input multiple-output (MIMO) dual-hop amplify-and-forward\n(AF) systems. Assuming channel state information is not available at the source\nand relay, the optimal transmit and receive beamforming vectors are computed at\nthe destination, and the transmit beamforming vector is sent to the transmitter\nvia a dedicated feedback link. Then, a set of new closed-form expressions for\nthe statistical properties of the maximum eigenvalue of the resultant channel\nis derived, i.e., the cumulative density function (cdf), probability density\nfunction (pdf) and general moments, as well as the first order asymptotic\nexpansion and asymptotic large dimension approximations. These analytical\nexpressions are then applied to study three important performance metrics of\nthe system, i.e., outage probability, average symbol error rate and ergodic\ncapacity. In addition, more detailed treatments are provided for some important\nspecial cases, e.g., when the number of antennas at one of the nodes is one or\nlarge, simple and insightful expressions for the key parameters such as\ndiversity order and array gain of the system are derived. With the analytical\nresults, the joint impact of source, relay and destination antenna numbers on\nthe system performance is addressed, and the performance of optimal beamforming\nschemes and orthogonal space-time block-coding (OSTBC) schemes are compared.\nResults reveal that the number of antennas at the relay has a great impact on\nhow the numbers of antennas at the source and destination contribute to the\nsystem performance, and optimal beamforming not only achieves the same maximum\ndiversity order as OSTBC, but also provides significant power gains over OSTBC. \n\n"}
{"id": "1205.6593", "contents": "Title: New Deep Holes of Generalized Reed-Solomon Codes Abstract: Deep holes play an important role in the decoding of generalized Reed-Solomon\ncodes. Recently, Wu and Hong \\cite{WH} found a new class of deep holes for\nstandard Reed-Solomon codes. In the present paper, we give a concise method to\nobtain a new class of deep holes for generalized Reed-Solomon codes. In\nparticular, for standard Reed-Solomon codes, we get the new class of deep holes\ngiven in \\cite{WH}.\n  Li and Wan \\cite{L.W1} studied deep holes of generalized Reed-Solomon codes\n$GRS_{k}(\\f,D)$ and characterized deep holes defined by polynomials of degree\n$k+1$. They showed that this problem is reduced to be a subset sum problem in\nfinite fields. Using the method of Li and Wan, we obtain some new deep holes\nfor special Reed-Solomon codes over finite fields with even characteristic.\nFurthermore, we study deep holes of the extended Reed-Solomon code, i.e.,\n$D=\\f$ and show polynomials of degree $k+2$ can not define deep holes. \n\n"}
{"id": "1205.7036", "contents": "Title: Upper Bounds on the Rate of Low Density Stabilizer Codes for the Quantum\n  Erasure Channel Abstract: Using combinatorial arguments, we determine an upper bound on achievable\nrates of stabilizer codes used over the quantum erasure channel. This allows us\nto recover the no-cloning bound on the capacity of the quantum erasure channel,\nR is below 1-2p, for stabilizer codes: we also derive an improved upper bound\nof the form : R is below 1-2p-D(p) with a function D(p) that stays positive for\n0 < p < 1/2 and for any family of stabilizer codes whose generators have\nweights bounded from above by a constant - low density stabilizer codes.\n  We obtain an application to percolation theory for a family of self-dual\ntilings of the hyperbolic plane. We associate a family of low density\nstabilizer codes with appropriate finite quotients of these tilings. We then\nrelate the probability of percolation to the probability of a decoding error\nfor these codes on the quantum erasure channel. The application of our upper\nbound on achievable rates of low density stabilizer codes gives rise to an\nupper bound on the critical probability for these tilings. \n\n"}
{"id": "1206.0489", "contents": "Title: Sumset and Inverse Sumset Inequalities for Differential Entropy and\n  Mutual Information Abstract: The sumset and inverse sumset theories of Freiman, Pl\\\"{u}nnecke and Ruzsa,\ngive bounds connecting the cardinality of the sumset $A+B=\\{a+b\\;;\\;a\\in\nA,\\,b\\in B\\}$ of two discrete sets $A,B$, to the cardinalities (or the finer\nstructure) of the original sets $A,B$. For example, the sum-difference bound of\nRuzsa states that, $|A+B|\\,|A|\\,|B|\\leq|A-B|^3$, where the difference set $A-B=\n\\{a-b\\;;\\;a\\in A,\\,b\\in B\\}$. Interpreting the differential entropy $h(X)$ of a\ncontinuous random variable $X$ as (the logarithm of) the size of the effective\nsupport of $X$, the main contribution of this paper is a series of natural\ninformation-theoretic analogs for these results. For example, the Ruzsa\nsum-difference bound becomes the new inequality, $h(X+Y)+h(X)+h(Y)\\leq\n3h(X-Y)$, for any pair of independent continuous random variables $X$ and $Y$.\nOur results include differential-entropy versions of Ruzsa's triangle\ninequality, the Pl\\\"{u}nnecke-Ruzsa inequality, and the\nBalog-Szemer\\'{e}di-Gowers lemma. Also we give a differential entropy version\nof the Freiman-Green-Ruzsa inverse-sumset theorem, which can be seen as a\nquantitative converse to the entropy power inequality. Versions of most of\nthese results for the discrete entropy $H(X)$ were recently proved by Tao,\nrelying heavily on a strong, functional form of the submodularity property of\n$H(X)$. Since differential entropy is {\\em not} functionally submodular, in the\ncontinuous case many of the corresponding discrete proofs fail, in many cases\nrequiring substantially new proof strategies. We find that the basic property\nthat naturally replaces the discrete functional submodularity, is the data\nprocessing property of mutual information. \n\n"}
{"id": "1206.1405", "contents": "Title: Recovery of Sparse 1-D Signals from the Magnitudes of their Fourier\n  Transform Abstract: The problem of signal recovery from the autocorrelation, or equivalently, the\nmagnitudes of the Fourier transform, is of paramount importance in various\nfields of engineering. In this work, for one-dimensional signals, we give\nconditions, which when satisfied, allow unique recovery from the\nautocorrelation with very high probability. In particular, for sparse signals,\nwe develop two non-iterative recovery algorithms. One of them is based on\ncombinatorial analysis, which we prove can recover signals upto sparsity\n$o(n^{1/3})$ with very high probability, and the other is developed using a\nconvex optimization based framework, which numerical simulations suggest can\nrecover signals upto sparsity $o(n^{1/2})$ with very high probability. \n\n"}
{"id": "1206.2292", "contents": "Title: An Intercell Interference Model based on Scheduling for Future\n  Generation Wireless Networks (Part 1 and Part 2) Abstract: This technical report is divided into two parts. The first part of the\ntechnical report presents a novel framework for modeling the uplink and\ndownlink intercell interference (ICI) in a multiuser cellular network. The\nproposed framework assists in quantifying the impact of various fading channel\nmodels and multiuser scheduling schemes on the uplink and downlink ICI.\nFirstly, we derive a semi-analytical expression for the distribution of the\nlocation of the scheduled user in a given cell considering a wide range of\nscheduling schemes. Based on this, we derive the distribution and moment\ngenerating function (MGF) of the ICI considering a single interfering cell.\nConsequently, we determine the MGF of the cumulative ICI observed from all\ninterfering cells and derive explicit MGF expressions for three typical fading\nmodels. Finally, we utilize the obtained expressions to evaluate important\nnetwork performance metrics such as the outage probability, ergodic capacity\nand average fairness numerically. Monte-Carlo simulation results are provided\nto demonstrate the efficacy of the derived analytical expressions {\\bf The\nfirst part of the technical report is currently submitted to IEEE Transactions\non Wireless Communications}. The second part of the technical report deals with\nthe statistical modeling of uplink inter-cell interference (ICI) considering\ngreedy scheduling with power adaptation based on channel conditions. The\nderived model is utilized to evaluate important network performance metrics\nsuch as ergodic capacity, average fairness and average power preservation\nnumerically. In parallel to the literature, we have shown that greedy\nscheduling with power adaptation reduces the ICI, average power consumption of\nusers, and enhances the average fairness among users, compared to the case\nwithout power adaptation. \n\n"}
{"id": "1206.2656", "contents": "Title: A Construction of Quantum LDPC Codes from Cayley Graphs Abstract: We study a construction of Quantum LDPC codes proposed by MacKay, Mitchison\nand Shokrollahi. It is based on the Cayley graph of Fn together with a set of\ngenerators regarded as the columns of the parity-check matrix of a classical\ncode. We give a general lower bound on the minimum distance of the Quantum code\nin $\\mathcal{O}(dn^2)$ where d is the minimum distance of the classical code.\nWhen the classical code is the $[n, 1, n]$ repetition code, we are able to\ncompute the exact parameters of the associated Quantum code which are $[[2^n,\n2^{\\frac{n+1}{2}}, 2^{\\frac{n-1}{2}}]]$. \n\n"}
{"id": "1206.4767", "contents": "Title: On the Secrecy Rate Region of a Fading Multiple-Antenna Gaussian\n  Broadcast Channel with Confidential Messages and Partial CSIT Abstract: In this paper we consider the secure transmission over the fast fading\nmultiple antenna Gaussian broadcast channels with confidential messages\n(FMGBC-CM), where a multiple-antenna transmitter sends independent confidential\nmessages to two users with information theoretic secrecy and only the\nstatistics of the receivers' channel state information are known at the\ntransmitter. We first use the same marginal property of the FMGBC-CM to\nclassify the non-trivial cases, i.e., those not degraded to the common wiretap\nchannels. We then derive the achievable rate region for the FMGBC-CM by solving\nthe channel input covariance matrices and the inflation factor. Due to the\ncomplicated rate region formulae, we resort to low SNR analysis to investigate\nthe characteristics of the channel. Finally, the numerical examples show that\nunder the information-theoretic secrecy requirement both users can achieve\npositive rates simultaneously. \n\n"}
{"id": "1207.1138", "contents": "Title: Parsing a sequence of qubits Abstract: We develop a theoretical framework for frame synchronization, also known as\nblock synchronization, in the quantum domain which makes it possible to attach\nclassical and quantum metadata to quantum information over a noisy channel even\nwhen the information source and sink are frame-wise asynchronous. This\neliminates the need of frame synchronization at the hardware level and allows\nfor parsing qubit sequences during quantum information processing. Our\nframework exploits binary constant-weight codes that are self-synchronizing.\nPossible applications may include asynchronous quantum communication such as a\nself-synchronizing quantum network where one can hop into the channel at any\ntime, catch the next coming quantum information with a label indicating the\nsender, and reply by routing her quantum information with control qubits for\nquantum switches all without assuming prior frame synchronization between\nusers. \n\n"}
{"id": "1207.1779", "contents": "Title: Violating the Shannon capacity of metric graphs with entanglement Abstract: The Shannon capacity of a graph G is the maximum asymptotic rate at which\nmessages can be sent with zero probability of error through a noisy channel\nwith confusability graph G. This extensively studied graph parameter disregards\nthe fact that on atomic scales, Nature behaves in line with quantum mechanics.\nEntanglement, arguably the most counterintuitive feature of the theory, turns\nout to be a useful resource for communication across noisy channels. Recently,\nLeung, Mancinska, Matthews, Ozols and Roy [Comm. Math. Phys. 311, 2012]\npresented two examples of graphs whose Shannon capacity is strictly less than\nthe capacity attainable if the sender and receiver have entangled quantum\nsystems. Here we give new, possibly infinite, families of graphs for which the\nentangled capacity exceeds the Shannon capacity. \n\n"}
{"id": "1207.3094", "contents": "Title: Vanishingly Sparse Matrices and Expander Graphs, With Application to\n  Compressed Sensing Abstract: We revisit the probabilistic construction of sparse random matrices where\neach column has a fixed number of nonzeros whose row indices are drawn\nuniformly at random with replacement. These matrices have a one-to-one\ncorrespondence with the adjacency matrices of fixed left degree expander\ngraphs. We present formulae for the expected cardinality of the set of\nneighbors for these graphs, and present tail bounds on the probability that\nthis cardinality will be less than the expected value. Deducible from these\nbounds are similar bounds for the expansion of the graph which is of interest\nin many applications. These bounds are derived through a more detailed analysis\nof collisions in unions of sets. Key to this analysis is a novel {\\em dyadic\nsplitting} technique. The analysis led to the derivation of better order\nconstants that allow for quantitative theorems on existence of lossless\nexpander graphs and hence the sparse random matrices we consider and also\nquantitative compressed sensing sampling theorems when using sparse non\nmean-zero measurement matrices. \n\n"}
{"id": "1207.3107", "contents": "Title: Expectation-Maximization Gaussian-Mixture Approximate Message Passing Abstract: When recovering a sparse signal from noisy compressive linear measurements,\nthe distribution of the signal's non-zero coefficients can have a profound\neffect on recovery mean-squared error (MSE). If this distribution was apriori\nknown, then one could use computationally efficient approximate message passing\n(AMP) techniques for nearly minimum MSE (MMSE) recovery. In practice, though,\nthe distribution is unknown, motivating the use of robust algorithms like\nLASSO---which is nearly minimax optimal---at the cost of significantly larger\nMSE for non-least-favorable distributions. As an alternative, we propose an\nempirical-Bayesian technique that simultaneously learns the signal distribution\nwhile MMSE-recovering the signal---according to the learned\ndistribution---using AMP. In particular, we model the non-zero distribution as\na Gaussian mixture, and learn its parameters through expectation maximization,\nusing AMP to implement the expectation step. Numerical experiments on a wide\nrange of signal classes confirm the state-of-the-art performance of our\napproach, in both reconstruction error and runtime, in the high-dimensional\nregime, for most (but not all) sensing operators. \n\n"}
{"id": "1207.4883", "contents": "Title: Bounds of restricted isometry constants in extreme asymptotics: formulae\n  for Gaussian matrices Abstract: Restricted Isometry Constants (RICs) provide a measure of how far from an\nisometry a matrix can be when acting on sparse vectors. This, and related\nquantities, provide a mechanism by which standard eigen-analysis can be applied\nto topics relying on sparsity. RIC bounds have been presented for a variety of\nrandom matrices and matrix dimension and sparsity ranges. We provide explicitly\nformulae for RIC bounds, of n by N Gaussian matrices with sparsity k, in three\nsettings: a) n/N fixed and k/n approaching zero, b) k/n fixed and n/N\napproaching zero, and c) n/N approaching zero with k/n decaying inverse\nlogrithmically in N/n; in these three settings the RICs a) decay to zero, b)\nbecome unbounded (or approach inherent bounds), and c) approach a non-zero\nconstant. Implications of these results for RIC based analysis of compressed\nsensing algorithms are presented. \n\n"}
{"id": "1207.5660", "contents": "Title: Achieving the Capacity of the N-Relay Gaussian Diamond Network Within\n  log N Bits Abstract: We consider the N-relay Gaussian diamond network where a source node\ncommunicates to a destination node via N parallel relays through a cascade of a\nGaussian broadcast (BC) and a multiple access (MAC) channel. Introduced in 2000\nby Schein and Gallager, the capacity of this relay network is unknown in\ngeneral. The best currently available capacity approximation, independent of\nthe coefficients and the SNR's of the constituent channels, is within an\nadditive gap of 1.3 N bits, which follows from the recent capacity\napproximations for general Gaussian relay networks with arbitrary topology.\n  In this paper, we approximate the capacity of this network within 2 log N\nbits. We show that two strategies can be used to achieve the\ninformation-theoretic cutset upper bound on the capacity of the network up to\nan additive gap of O(log N) bits, independent of the channel configurations and\nthe SNR's. The first of these strategies is simple partial decode-and-forward.\nHere, the source node uses a superposition codebook to broadcast independent\nmessages to the relays at appropriately chosen rates; each relay decodes its\nintended message and then forwards it to the destination over the MAC channel.\nA similar performance can be also achieved with compress-and-forward type\nstrategies (such as quantize-map-and-forward and noisy network coding) that\nprovide the 1.3 N-bit approximation for general Gaussian networks, but only if\nthe relays quantize their observed signals at a resolution inversely\nproportional to the number of relay nodes N. This suggest that the\nrule-of-thumb to quantize the received signals at the noise level in the\ncurrent literature can be highly suboptimal. \n\n"}
{"id": "1207.6656", "contents": "Title: Measuring the Complexity of Ultra-Large-Scale Adaptive Systems Abstract: Ultra-large scale (ULS) systems are becoming pervasive. They are inherently\ncomplex, which makes their design and control a challenge for traditional\nmethods. Here we propose the design and analysis of ULS systems using measures\nof complexity, emergence, self-organization, and homeostasis based on\ninformation theory. These measures allow the evaluation of ULS systems and thus\ncan be used to guide their design. We evaluate the proposal with a ULS\ncomputing system provided with adaptation mechanisms. We show the evolution of\nthe system with stable and also changing workload, using different fitness\nfunctions. When the adaptive plan forces the system to converge to a predefined\nperformance level, the nodes may result in highly unstable configurations, that\ncorrespond to a high variance in time of the measured complexity. Conversely,\nif the adaptive plan is less \"aggressive\", the system may be more stable, but\nthe optimal performance may not be achieved. \n\n"}
{"id": "1207.6991", "contents": "Title: The probability of finding a fixed pattern in random data depends\n  monotonically on the bifix indicator Abstract: We consider the problem of finding a fixed L-ary sequence in a stream of\nrandom L-ary data. It is known that the expected search time is a strictly\nincreasing function of the lengths of the bifices of the pattern. In this paper\nwe prove the related statement that the probability of finding the pattern in a\nfinite random word is a strictly decreasing function of the lengths of the\nbifices of the pattern. \n\n"}
{"id": "1208.3291", "contents": "Title: When to look at a noisy Markov chain in sequential decision making if\n  measurements are costly? Abstract: A decision maker records measurements of a finite-state Markov chain\ncorrupted by noise. The goal is to decide when the Markov chain hits a specific\ntarget state. The decision maker can choose from a finite set of sampling\nintervals to pick the next time to look at the Markov chain. The aim is to\noptimize an objective comprising of false alarm, delay cost and cumulative\nmeasurement sampling cost. Taking more frequent measurements yields accurate\nestimates but incurs a higher measurement cost. Making an erroneous decision\ntoo soon incurs a false alarm penalty. Waiting too long to declare the target\nstate incurs a delay penalty. What is the optimal sequential strategy for the\ndecision maker? The paper shows that under reasonable conditions, the optimal\nstrategy has the following intuitive structure: when the Bayesian estimate\n(posterior distribution) of the Markov chain is away from the target state,\nlook less frequently; while if the posterior is close to the target state, look\nmore frequently. Bounds are derived for the optimal strategy. Also the\nachievable optimal cost of the sequential detector as a function of transition\ndynamics and observation distribution is analyzed. The sensitivity of the\noptimal achievable cost to parameter variations is bounded in terms of the\nKullback divergence. To prove the results in this paper, novel stochastic\ndominance results on the Bayesian filtering recursion are derived. The\nformulation in this paper generalizes quickest time change detection to\nconsider optimal sampling and also yields useful results in sensor scheduling\n(active sensing). \n\n"}
{"id": "1208.4536", "contents": "Title: In-Vivo Bytecode Instrumentation for Improving Privacy on Android\n  Smartphones in Uncertain Environments Abstract: In this paper we claim that an efficient and readily applicable means to\nimprove privacy of Android applications is: 1) to perform runtime monitoring by\ninstrumenting the application bytecode and 2) in-vivo, i.e. directly on the\nsmartphone. We present a tool chain to do this and present experimental results\nshowing that this tool chain can run on smartphones in a reasonable amount of\ntime and with a realistic effort. Our findings also identify challenges to be\naddressed before running powerful runtime monitoring and instrumentations\ndirectly on smartphones. We implemented two use-cases leveraging the tool\nchain: BetterPermissions, a fine-grained user centric permission policy system\nand AdRemover an advertisement remover. Both prototypes improve the privacy of\nAndroid systems thanks to in-vivo bytecode instrumentation. \n\n"}
{"id": "1208.4651", "contents": "Title: Throughput Maximization for an Energy Harvesting Communication System\n  with Processing Cost Abstract: In wireless networks, energy consumed for communication includes both the\ntransmission and the processing energy. In this paper, point-to-point\ncommunication over a fading channel with an energy harvesting transmitter is\nstudied considering jointly the energy costs of transmission and processing.\nUnder the assumption of known energy arrival and fading profiles, optimal\ntransmission policy for throughput maximization is investigated. Assuming that\nthe transmitter has sufficient amount of data in its buffer at the beginning of\nthe transmission period, the average throughput by a given deadline is\nmaximized. Furthermore, a \"directional glue pouring algorithm\" that computes\nthe optimal transmission policy is described. \n\n"}
{"id": "1208.6125", "contents": "Title: Bounded-Contention Coding for Wireless Networks in the High SNR Regime Abstract: Efficient communication in wireless networks is typically challenged by the\npossibility of interference among several transmitting nodes. Much important\nresearch has been invested in decreasing the number of collisions in order to\nobtain faster algorithms for communication in such networks.\n  This paper proposes a novel approach for wireless communication, which\nembraces collisions rather than avoiding them, over an additive channel. It\nintroduces a coding technique called Bounded-Contention Coding (BCC) that\nallows collisions to be successfully decoded by the receiving nodes into the\noriginal transmissions and whose complexity depends on a bound on the\ncontention among the transmitters.\n  BCC enables deterministic local broadcast in a network with n nodes and at\nmost a transmitters with information of l bits each within O(a log n + al) bits\nof communication with full-duplex radios, and O((a log n + al)(log n)) bits,\nwith high probability, with half-duplex radios. When combined with random\nlinear network coding, BCC gives global broadcast within O((D + a + log n)(a\nlog n + l)) bits, with high probability. This also holds in dynamic networks\nthat can change arbitrarily over time by a worst-case adversary. When no bound\non the contention is given, it is shown how to probabilistically estimate it\nand obtain global broadcast that is adaptive to the true contention in the\nnetwork. \n\n"}
{"id": "1208.6464", "contents": "Title: Bayesian compressed sensing with new sparsity-inducing prior Abstract: Sparse Bayesian learning (SBL) is a popular approach to sparse signal\nrecovery in compressed sensing (CS). In SBL, the signal sparsity information is\nexploited by assuming a sparsity-inducing prior for the signal that is then\nestimated using Bayesian inference. In this paper, a new sparsity-inducing\nprior is introduced and efficient algorithms are developed for signal recovery.\nThe main algorithm is shown to produce a sparser solution than existing SBL\nmethods while preserving their desirable properties. Numerical simulations with\none-dimensional synthetic signals and two-dimensional images verify our\nanalysis and show that for sparse signals the proposed algorithm outperforms\nits SBL peers in both the signal recovery accuracy and computational speed. Its\nimproved performance is also demonstrated in comparison with other\nstate-of-the-art methods in CS. \n\n"}
{"id": "1209.4145", "contents": "Title: Network Massive MIMO for Cell-Boundary Users: From a Precoding\n  Normalization Perspective Abstract: In this paper, we propose network massive multiple- input multiple-output\n(MIMO) systems, where three radio units (RUs) connected via one digital unit\n(DU) support multiple user equipments (UEs) at a cell-boundary through the same\nradio resource, i.e., the same frequency/time band. For precoding designs,\nzero-forcing (ZF) and matched filter (MF) with vector or matrix normalization\nare considered. We also derive the formulae of the lower and upper bounds of\nthe achievable sum rate for each precoding. Based on our analytical results, we\nobserve that vector normalization is better for ZF while matrix normalization\nis better for MF. Given antenna configurations, we also derive the optimal\nswitching point as a function of the number of active users in a network.\nNumerical simulations confirm our analytical \n\n"}
{"id": "1209.4889", "contents": "Title: A Unified Relay Framework with both D-F and C-F Relay Nodes Abstract: Decode-and-forward (D-F) and compress-and-forward (C-F) are two fundamentally\ndifferent relay strategies proposed by (Cover and El Gamal, 1979).\nIndividually, either of them has been successfully generalized to multi-relay\nchannels. In this paper, to allow each relay node the freedom of choosing\neither of the two strategies, we propose a unified framework, where both the\nD-F and C-F strategies can be employed simultaneously in the network. It turns\nout that, to fully incorporate the advantages of both the best known D-F and\nC-F strategies into a unified framework, the major challenge arises as follows:\nFor the D-F relay nodes to fully utilize the help of the C-F relay nodes,\ndecoding at the D-F relay nodes should not be conducted until all the blocks\nhave been finished; However, in the multi-level D-F strategy, the upstream\nnodes have to decode prior to the downstream nodes in order to help, which\nmakes simultaneous decoding at all the D-F relay nodes after all the blocks\nhave been finished inapplicable. To tackle this problem, nested blocks combined\nwith backward decoding are used in our framework, so that the D-F relay nodes\nat different levels can perform backward decoding at different frequencies. As\nsuch, the upstream D-F relay nodes can decode before the downstream D-F relay\nnodes, and the use of backward decoding at each D-F relay node ensures the full\nexploitation of the help of both the other D-F relay nodes and the C-F relay\nnodes. The achievable rates under our unified relay framework are found to\ncombine both the best known D-F and C-F achievable rates and include them as\nspecial cases. \n\n"}
{"id": "1209.5083", "contents": "Title: A Simple Proof for the Existence of \"Good\" Pairs of Nested Lattices Abstract: This paper provides a simplified proof for the existence of nested lattice\ncodebooks allowing to achieve the capacity of the additive white Gaussian noise\nchannel, as well as the optimal rate-distortion trade-off for a Gaussian\nsource. The proof is self-contained and relies only on basic probabilistic and\ngeometrical arguments. An ensemble of nested lattices that is different, and\nmore elementary, than the one used in previous proofs is introduced. This\nensemble is based on lifting different subcodes of a linear code to the\nEuclidean space using Construction A. In addition to being simpler, our\nanalysis is less sensitive to the assumption that the additive noise is\nGaussian. In particular, for additive ergodic noise channels it is shown that\nthe achievable rates of the nested lattice coding scheme depend on the noise\ndistribution only via its power. Similarly, the nested lattice source coding\nscheme attains the same rate-distortion trade-off for all ergodic sources with\nthe same second moment. \n\n"}
{"id": "1209.5978", "contents": "Title: Two-way Communication with Adaptive Data Acquisition Abstract: Motivated by computer networks and machine-to-machine communication\napplications, a bidirectional link is studied in which two nodes, Node 1 and\nNode 2, communicate to fulfill generally conflicting informational\nrequirements. Node 2 is able to acquire information from the environment, e.g.,\nvia access to a remote data base or via sensing. Information acquisition is\nexpensive in terms of system resources, e.g., time, bandwidth and energy and\nthus should be done efficiently by adapting the acquisition process to the\nneeds of the application. As a result of the forward communication from Node 1\nto Node 2, the latter wishes to compute some function, such as a suitable\naverage, of the data available at Node 1 and of the data obtained from the\nenvironment. The forward link is also used by Node 1 to query Node 2 with the\naim of retrieving suitable information from the environment on the backward\nlink. The problem is formulated in the context of multi-terminal\nrate-distortion theory and the optimal trade-off between communication rates,\ndistortions of the information produced at the two nodes and costs for\ninformation acquisition at Node 2 is derived. The issue of robustness to\npossible malfunctioning of the data acquisition process at Node 2 is also\ninvestigated. The results are illustrated via an example that demonstrates the\ndifferent roles played by the forward communication, namely data exchange,\nquery and control. \n\n"}
{"id": "1209.5982", "contents": "Title: PlaceRaider: Virtual Theft in Physical Spaces with Smartphones Abstract: As smartphones become more pervasive, they are increasingly targeted by\nmalware. At the same time, each new generation of smartphone features\nincreasingly powerful onboard sensor suites. A new strain of sensor malware has\nbeen developing that leverages these sensors to steal information from the\nphysical environment (e.g., researchers have recently demonstrated how malware\ncan listen for spoken credit card numbers through the microphone, or feel\nkeystroke vibrations using the accelerometer). Yet the possibilities of what\nmalware can see through a camera have been understudied. This paper introduces\na novel visual malware called PlaceRaider, which allows remote attackers to\nengage in remote reconnaissance and what we call virtual theft. Through\ncompletely opportunistic use of the camera on the phone and other sensors,\nPlaceRaider constructs rich, three dimensional models of indoor environments.\nRemote burglars can thus download the physical space, study the environment\ncarefully, and steal virtual objects from the environment (such as financial\ndocuments, information on computer monitors, and personally identifiable\ninformation). Through two human subject studies we demonstrate the\neffectiveness of using mobile devices as powerful surveillance and virtual\ntheft platforms, and we suggest several possible defenses against visual\nmalware. \n\n"}
{"id": "1209.6325", "contents": "Title: Arbitrarily varying and compound classical-quantum channels and a note\n  on quantum zero-error capacities Abstract: We consider compound as well as arbitrarily varying classical-quantum channel\nmodels. For classical-quantum compound channels, we give an elementary proof of\nthe direct part of the coding theorem. A weak converse under average error\ncriterion to this statement is also established. We use this result together\nwith the robustification and elimination technique developed by Ahlswede in\norder to give an alternative proof of the direct part of the coding theorem for\na finite classical-quantum arbitrarily varying channels with the criterion of\nsuccess being average error probability. Moreover we provide a proof of the\nstrong converse to the random coding capacity in this setting.The notion of\nsymmetrizability for the maximal error probability is defined and it is shown\nto be both necessary and sufficient for the capacity for message transmission\nwith maximal error probability criterion to equal zero. Finally, it is shown\nthat the connection between zero-error capacity and certain arbitrarily varying\nchannels is, just like in the case of quantum channels, only partially valid\nfor classical-quantum channels. \n\n"}
{"id": "1210.5219", "contents": "Title: The Domino Effect in Decentralized Wireless Networks Abstract: Convergence of resource allocation algorithms is well covered in the\nliterature as convergence to a steady state is important due to stability and\nperformance. However, research is lacking when it comes to the propagation of\nchange that occur in a network due to new nodes arriving or old nodes leaving\nor updating their allocation. As change can propagate through the network in a\nmanner similar to how domino pieces falls, we call this propagation of change\nthe domino effect. In this paper we investigate how change at one node can\naffect other nodes for a simple power control algorithm. We provide analytical\nresults from a deterministic network as well as a Poisson distributed network\nthrough percolation theory and provide simulation results that highlight some\naspects of the domino effect. The difficulty of mitigating this domino effect\nlies in the fact that to avoid it, one needs to have a margin of tolerance for\nchanges in the network. However, a high margin leads to poor system performance\nin a steady-state and therefore one has to consider a trade-off between\nperformance and propagation of change. \n\n"}
{"id": "1210.5594", "contents": "Title: Cross-Entropy Clustering Abstract: We construct a cross-entropy clustering (CEC) theory which finds the optimal\nnumber of clusters by automatically removing groups which carry no information.\nMoreover, our theory gives simple and efficient criterion to verify cluster\nvalidity.\n  Although CEC can be build on an arbitrary family of densities, in the most\nimportant case of Gaussian CEC:\n  {\\em -- the division into clusters is affine invariant;\n  -- the clustering will have the tendency to divide the data into\nellipsoid-type shapes;\n  -- the approach is computationally efficient as we can apply Hartigan\napproach.}\n  We study also with particular attention clustering based on the Spherical\nGaussian densities and that of Gaussian densities with covariance $s \\I$. In\nthe letter case we show that with $s$ converging to zero we obtain the\nclassical k-means clustering. \n\n"}
{"id": "1210.5940", "contents": "Title: Properties of perfect transitive binary codes of length 15 and extended\n  perfect transitive binary codes of length 16 Abstract: Some properties of perfect transitive binary codes of length 15 and extended\nperfect transitive binary codes of length 16 are presented for reference\npurposes. \n\n"}
{"id": "1211.0658", "contents": "Title: On the Non-existence of Lattice Tilings by Quasi-crosses Abstract: We study necessary conditions for the existence of lattice tilings of $\\R^n$\nby quasi-crosses. We prove non-existence results, and focus in particular on\nthe two smallest unclassified shapes, the $(3,1,n)$-quasi-cross and the\n$(3,2,n)$-quasi-cross. We show that for dimensions $n\\leq 250$, apart from the\nknown constructions, there are no lattice tilings of $\\R^n$ by\n$(3,1,n)$-quasi-crosses except for ten remaining cases, and no lattice tilings\nof $\\R^n$ by $(3,2,n)$-quasi-crosses except for eleven remaining cases. \n\n"}
{"id": "1211.1125", "contents": "Title: Limits of privacy amplification against non-signalling memory attacks Abstract: The task of privacy amplification, in which Alice holds some partially secret\ninformation with respect to an adversary Eve and wishes to distill it until it\nis completely secret, is known to be solvable almost optimally both in the\nclassical and quantum world. Unfortunately, when considering an adversary who\nis only limited by non-signalling constraints such a statement cannot be made\nin general. We here prove that under the natural assumptions of time-ordered\nnon-signalling system, which allow past subsystems to signal future subsystems\n(using the device's memory for example), super-polynomial privacy amplification\nby any hashing is impossible. This is in great relevance when considering\npractical device independent key distribution protocols which assume a\nsuper-quantum adversary. \n\n"}
{"id": "1211.3189", "contents": "Title: A characterization of two-weight projective cyclic codes Abstract: We give necessary conditions for a two-weight projective cyclic code to be\nthe direct sum of two one-weight irreducible cyclic subcodes of the same\ndimension, following the work of Wolfmann and Vega. This confirms Vega's\nconjecture that all the two-weight cyclic codes of this type are the known ones\nin the projective case. \n\n"}
{"id": "1211.5264", "contents": "Title: Source and Channel Polarization over Finite Fields and Reed-Solomon\n  Matrices Abstract: Polarization phenomenon over any finite field $\\mathbb{F}_{q}$ with size $q$\nbeing a power of a prime is considered. This problem is a generalization of the\noriginal proposal of channel polarization by Arikan for the binary field, as\nwell as its extension to a prime field by Sasoglu, Telatar, and Arikan. In this\npaper, a necessary and sufficient condition of a matrix over a finite field\n$\\mathbb{F}_q$ is shown under which any source and channel are polarized.\nFurthermore, the result of the speed of polarization for the binary alphabet\nobtained by Arikan and Telatar is generalized to arbitrary finite field. It is\nalso shown that the asymptotic error probability of polar codes is improved by\nusing the Reed-Solomon matrix, which can be regarded as a natural\ngeneralization of the $2\\times 2$ binary matrix used in the original proposal\nby Arikan. \n\n"}
{"id": "1211.6401", "contents": "Title: On the Performance Bound of Sparse Estimation with Sensing Matrix\n  Perturbation Abstract: This paper focusses on the sparse estimation in the situation where both the\nthe sensing matrix and the measurement vector are corrupted by additive\nGaussian noises. The performance bound of sparse estimation is analyzed and\ndiscussed in depth. Two types of lower bounds, the constrained Cram\\'{e}r-Rao\nbound (CCRB) and the Hammersley-Chapman-Robbins bound (HCRB), are discussed. It\nis shown that the situation with sensing matrix perturbation is more complex\nthan the one with only measurement noise. For the CCRB, its closed-form\nexpression is deduced. It demonstrates a gap between the maximal and nonmaximal\nsupport cases. It is also revealed that a gap lies between the CCRB and the MSE\nof the oracle pseudoinverse estimator, but it approaches zero asymptotically\nwhen the problem dimensions tend to infinity. For a tighter bound, the HCRB,\ndespite of the difficulty in obtaining a simple expression for general sensing\nmatrix, a closed-form expression in the unit sensing matrix case is derived for\na qualitative study of the performance bound. It is shown that the gap between\nthe maximal and nonmaximal cases is eliminated for the HCRB. Numerical\nsimulations are performed to verify the theoretical results in this paper. \n\n"}
{"id": "1212.0075", "contents": "Title: Optimal Power Allocation for Outage Minimization in Fading Channels with\n  Energy Harvesting Constraints Abstract: This paper studies the optimal power allocation for outage minimization in\npoint-to-point fading channels with the energy-harvesting constraints and\nchannel distribution information (CDI) at the transmitter. Both the cases with\nnon-causal and causal energy state information (ESI) are considered, which\ncorrespond to the energy harvesting rates being known and unknown prior to the\ntransmissions, respectively. For the non-causal ESI case, the average outage\nprobability minimization problem over a finite horizon is shown to be\nnon-convex for a large class of practical fading channels. However, the\nglobally optimal \"offline\" power allocation is obtained by a forward search\nalgorithm with at most $N$ one-dimensional searches, and the optimal power\nprofile is shown to be non-decreasing over time and have an interesting\n\"save-then-transmit\" structure. In particular, for the special case of N=1, our\nresult revisits the classic outage capacity for fading channels with uniform\npower allocation. Moreover, for the case with causal ESI, we propose both the\noptimal and suboptimal \"online\" power allocation algorithms, by applying the\ntechnique of dynamic programming and exploring the structure of optimal offline\nsolutions, respectively. \n\n"}
{"id": "1212.3866", "contents": "Title: Agnostic insurability of model classes Abstract: Motivated by problems in insurance, our task is to predict finite upper\nbounds on a future draw from an unknown distribution $p$ over the set of\nnatural numbers. We can only use past observations generated independently and\nidentically distributed according to $p$. While $p$ is unknown, it is known to\nbelong to a given collection ${\\cal P}$ of probability distributions on the\nnatural numbers.\n  The support of the distributions $p \\in {\\cal P}$ may be unbounded, and the\nprediction game goes on for \\emph{infinitely} many draws. We are allowed to\nmake observations without predicting upper bounds for some time. But we must,\nwith probability 1, start and then continue to predict upper bounds after a\nfinite time irrespective of which $p \\in {\\cal P}$ governs the data.\n  If it is possible, without knowledge of $p$ and for any prescribed confidence\nhowever close to 1, to come up with a sequence of upper bounds that is never\nviolated over an infinite time window with confidence at least as big as\nprescribed, we say the model class ${\\cal P}$ is \\emph{insurable}.\n  We completely characterize the insurability of any class ${\\cal P}$ of\ndistributions over natural numbers by means of a condition on how the\nneighborhoods of distributions in ${\\cal P}$ should be, one that is both\nnecessary and sufficient. \n\n"}
{"id": "1212.4899", "contents": "Title: New inequalities of Mill's ratio and Its Application to The Inverse\n  Q-function Approximation Abstract: In this paper, we investigate the Mill's ratio estimation problem and get two\nnew inequalities. Compared to the well known results obtained by Gordon, they\nbecomes tighter. Furthermore, we also discuss the inverse Q-function\napproximation problem and present some useful results on the inverse solution.\nNumerical results confirm the validness of our theoretical analysis. In\naddition, we also present a conjecture on the bounds of inverse solution on\nQ-function. \n\n"}
{"id": "1212.4902", "contents": "Title: On the Capacity Region and the Generalized Degrees of Freedom Region for\n  the MIMO Interference Channel with Feedback Abstract: In this paper, we study the effect of feedback on two-user MIMO interference\nchannels. The capacity region of MIMO interference channels with feedback is\ncharacterized within a constant number of bits, where this constant is\nindependent of the channel matrices. Further, it is shown that the capacity\nregion of a MIMO interference channel with feedback and its reciprocal\ninterference channel are within a constant number of bits. Finally, the\ngeneralized degrees of freedom region for the MIMO interference channel with\nfeedback is characterized. \n\n"}
{"id": "1212.6465", "contents": "Title: Quantized Iterative Message Passing Decoders with Low Error Floor for\n  LDPC Codes Abstract: The error floor phenomenon observed with LDPC codes and their graph-based,\niterative, message-passing (MP) decoders is commonly attributed to the\nexistence of error-prone substructures -- variously referred to as near\ncodewords, trapping sets, absorbing sets, or pseudocodewords -- in a Tanner\ngraph representation of the code. Many approaches have been proposed to lower\nthe error floor by designing new LDPC codes with fewer such substructures or by\nmodifying the decoding algorithm. Using a theoretical analysis of iterative MP\ndecoding in an idealized trapping set scenario, we show that a contributor to\nthe error floors observed in the literature may be the imprecise implementation\nof decoding algorithms and, in particular, the message quantization rules used.\nWe then propose a new quantization method -- (q+1)-bit quasi-uniform\nquantization -- that efficiently increases the dynamic range of messages,\nthereby overcoming a limitation of conventional quantization schemes. Finally,\nwe use the quasi-uniform quantizer to decode several LDPC codes that suffer\nfrom high error floors with traditional fixed-point decoder implementations.\nThe performance simulation results provide evidence that the proposed\nquantization scheme can, for a wide variety of codes, significantly lower error\nfloors with minimal increase in decoder complexity. \n\n"}
{"id": "1301.1294", "contents": "Title: FAST CLOUD: Pushing the Envelope on Delay Performance of Cloud Storage\n  with Coding Abstract: Our paper presents solutions that can significantly improve the delay\nperformance of putting and retrieving data in and out of cloud storage. We\nfirst focus on measuring the delay performance of a very popular cloud storage\nservice Amazon S3. We establish that there is significant randomness in service\ntimes for reading and writing small and medium size objects when assigned\ndistinct keys. We further demonstrate that using erasure coding, parallel\nconnections to storage cloud and limited chunking (i.e., dividing the object\ninto a few smaller objects) together pushes the envelope on service time\ndistributions significantly (e.g., 76%, 80%, and 85% reductions in mean, 90th,\nand 99th percentiles for 2 Mbyte files) at the expense of additional storage\n(e.g., 1.75x). However, chunking and erasure coding increase the load and hence\nthe queuing delays while reducing the supportable rate region in number of\nrequests per second per node. Thus, in the second part of our paper we focus on\nanalyzing the delay performance when chunking, FEC, and parallel connections\nare used together. Based on this analysis, we develop load adaptive algorithms\nthat can pick the best code rate on a per request basis by using off-line\ncomputed queue backlog thresholds. The solutions work with homogeneous services\nwith fixed object sizes, chunk sizes, operation type (e.g., read or write) as\nwell as heterogeneous services with mixture of object sizes, chunk sizes, and\noperation types. We also present a simple greedy solution that\nopportunistically uses idle connections and picks the erasure coding rate\naccordingly on the fly. Both backlog and greedy solutions support the full rate\nregion and provide best mean delay performance when compared to the best fixed\ncoding rate policy. Our evaluations show that backlog based solutions achieve\nbetter delay performance at higher percentile values than the greedy solution. \n\n"}
{"id": "1301.1415", "contents": "Title: On Complex LLL Algorithm for Integer Forcing Linear Receivers Abstract: Integer-forcing (IF) linear receiver has been recently introduced for\nmultiple-input multiple-output (MIMO) fading channels. The receiver has to\ncompute an integer linear combination of the symbols as a part of the decoding\nprocess. In particular, the integer coefficients have to be chosen based on the\nchannel realizations, and the choice of such coefficients is known to determine\nthe receiver performance. The original known solution of finding these integers\nwas based on exhaustive search. A practical algorithm based on\nHermite-Korkine-Zolotareff (HKZ) and Minkowski lattice reduction algorithms was\nalso proposed recently. In this paper, we propose a low-complexity method based\non complex LLL algorithm to obtain the integer coefficients for the IF\nreceiver. For the 2 X 2 MIMO channel, we study the effectiveness of the\nproposed method in terms of the ergodic rate. We also compare the bit error\nrate (BER) of our approach with that of other linear receivers, and show that\nthe suggested algorithm outperforms the minimum mean square estimator (MMSE)\nand zero-forcing (ZF) linear receivers, but trades-off error performance for\ncomplexity in comparison with the IF receiver based on exhaustive search or on\nHKZ and Minkowski lattice reduction algorithms. \n\n"}
{"id": "1301.3230", "contents": "Title: A Framework for Quality of Service with a Multiple Access Strategy Abstract: We study a problem of scheduling real-time traffic with hard delay\nconstraints in an unreliable wireless channel. Packets arrive at a constant\nrate to the network and have to be delivered within a fixed number of slots in\na fading wireless channel. For an infrastructure mode of traffic with a\ncentralized scheduler, we are interested in the long time average throughput\nachievable for the real time traffic. In [1], the authors have stud- ied the\nfeasible throughput vectors by identifying the necessary and sufficient\nconditions using work load characterization. In our work, we provide a\ncharacterization of the feasible throughput vectors using the notion of the\nrate region. We then discuss an extension to the network model studied in [1]\nby allowing multiple access during contention and propose an enhancement to the\nrate region of the wireless network. We characterize the feasible throughput\nvectors with the multiple access technique and study throughput optimal and\nutility maximizing strategies for the network scenario. Using simulations, we\nevaluate the performance of the proposed strategy and discuss its advantages. \n\n"}
{"id": "1301.3452", "contents": "Title: Exponential communication gap between weak and strong classical\n  simulations of quantum communication Abstract: The most trivial way to simulate classically the communication of a quantum\nstate is to transmit the classical description of the quantum state itself.\nHowever, this requires an infinite amount of classical communication if the\nsimulation is exact. A more intriguing and potentially less demanding strategy\nwould encode the full information about the quantum state into the probability\ndistribution of the communicated variables, so that this information is never\nsent in each single shot. This kind of simulation is called weak, as opposed to\nstrong simulations, where the quantum state is communicated in individual\nshots. In this paper, we introduce a bounded-error weak protocol for simulating\nthe communication of an arbitrary number of qubits and a subsequent two-outcome\nmeasurement consisting of an arbitrary pure state projector and its complement.\nThis protocol requires an amount of classical communication independent of the\nnumber of qubits and proportional to Delta^{-1}, where Delta is the error and a\nfree parameter of the protocol. Conversely, a bounded-error strong protocol\nrequires an amount of classical communication growing exponentially with the\nnumber of qubits for a fixed error. Our result improves a previous protocol,\nbased on the Johnson-Lindenstrauss lemma, with communication cost scaling as\nDelta^{-2} log Delta^{-1}. \n\n"}
{"id": "1301.4211", "contents": "Title: Information-related complexity: a problem-oriented approach Abstract: A general notion of information-related complexity applicable to both natural\nand man-made systems is proposed. The overall approach is to explicitly\nconsider a rational agent performing a certain task with a quantifiable degree\nof success. The complexity is defined as the minimum (quasi-)quantity of\ninformation that's necessary to complete the task to the given extent --\nmeasured by the corresponding loss. The complexity so defined is shown to\ngeneralize the existing notion of statistical complexity when the system in\nquestion can be described by a discrete-time stochastic process. The proposed\ndefinition also applies, in particular, to optimization and decision making\nproblems under uncertainty in which case it gives the agent a useful measure of\nthe problem's \"susceptibility\" to additional information and allows for an\nestimation of the potential value of the latter. \n\n"}
{"id": "1301.4773", "contents": "Title: Binary Cyclic codes with two primitive nonzeros Abstract: In this paper, we make some progress towards a well-known conjecture on the\nminimum weights of binary cyclic codes with two primitive nonzeros. We also\ndetermine the Walsh spectrum of $\\Tr(x^d)$ over $\\F_{2^{m}}$ in the case where\n$m=2t$, $d=3+2^{t+1}$ and $\\gcd(d, 2^{m}-1)=1$. \n\n"}
{"id": "1301.5004", "contents": "Title: Planar functions and perfect nonlinear monomials over finite fields Abstract: The study of finite projective planes involves planar functions, namely,\nfunctions f : F_q --> F_q such that, for each nonzero a in F_q, the function c\n--> f(c+a) - f(c) is a bijection on F_q. Planar functions are also used in the\nconstruction of DES-like cryptosystems, where they are called perfect nonlinear\nfunctions. We determine all planar functions on F_q of the form c --> c^t,\nunder the assumption that q >= (t-1)^4. This implies two conjectures of\nHernando, McGuire and Monserrat. Our arguments also yield a new proof of a\nconjecture of Segre and Bartocci from 1971 about monomial hyperovals in finite\nDesarguesian projective planes. \n\n"}
{"id": "1301.5309", "contents": "Title: Capacity Results for Binary Fading Interference Channels with Delayed\n  CSIT Abstract: To study the effect of lack of up-to-date channel state information at the\ntransmitters (CSIT), we consider two-user binary fading interference channels\nwith Delayed-CSIT. We characterize the capacity region for such channels under\nhomogeneous assumption where channel gains have identical and independent\ndistributions across time and space, eliminating the possibility of exploiting\ntime/space correlation. We introduce and discuss several novel coding\nopportunities created by outdated CSIT that can enlarge the achievable rate\nregion. The capacity-achieving scheme relies on accurate combination,\nconcatenation, and merging of these opportunities, depending on the channel\nstatistics. The outer-bounds are based on an extremal inequality we develop for\na binary broadcast channel with Delayed-CSIT. We further extend the results and\ncharacterize the capacity region when output feedback links are available from\nthe receivers to the transmitters in addition to the delayed knowledge of the\nchannel state information. We also discuss the extension of our results to the\nnon-homogeneous setting. \n\n"}
{"id": "1301.5942", "contents": "Title: Confidence Intervals for the Mutual Information Abstract: By combining a bound on the absolute value of the difference of mutual\ninformation between two joint probablity distributions with a fixed variational\ndistance, and a bound on the probability of a maximal deviation in variational\ndistance between a true joint probability distribution and an empirical joint\nprobability distribution, confidence intervals for the mutual information of\ntwo random variables with finite alphabets are established. Different from\nprevious results, these intervals do not need any assumptions on the\ndistribution and the sample size. \n\n"}
{"id": "1301.6302", "contents": "Title: Simultaneous Information and Energy Transfer: A Two-User MISO\n  Interference Channel Case Abstract: This paper considers the sum rate maximization problem of a two-user\nmultiple-input single-output interference channel with receivers that can\nscavenge energy from the radio signals transmitted by the transmitters. We\nfirst study the optimal transmission strategy for an ideal scenario where the\ntwo receivers can simultaneously decode the information signal and harvest\nenergy. Then, considering the limitations of the current circuit technology, we\npropose two practical schemes based on TDMA, where, at each time slot, the\nreceiver either operates in the energy harvesting mode or in the information\ndetection mode. Optimal transmission strategies for the two practical schemes\nare respectively investigated. Simulation results show that the three schemes\nexhibit interesting tradeoff between achievable sum rate and energy harvesting\nrequirement, and do not dominate each other in terms of maximum achievable sum\nrate. \n\n"}
{"id": "1302.0019", "contents": "Title: Fixed-to-Variable Length Distribution Matching Abstract: Fixed-to-variable length (f2v) matchers are used to reversibly transform an\ninput sequence of independent and uniformly distributed bits into an output\nsequence of bits that are (approximately) independent and distributed according\nto a target distribution. The degree of approximation is measured by the\ninformational divergence between the output distribution and the target\ndistribution. An algorithm is developed that efficiently finds optimal f2v\ncodes. It is shown that by encoding the input bits blockwise, the informational\ndivergence per bit approaches zero as the block length approaches infinity. A\nrelation to data compression by Tunstall coding is established. \n\n"}
{"id": "1302.4474", "contents": "Title: On the multiple unicast capacity of 3-source, 3-terminal directed\n  acyclic networks Abstract: We consider the multiple unicast problem with three source-terminal pairs\nover directed acyclic networks with unit-capacity edges. The three $s_i-t_i$\npairs wish to communicate at unit-rate via network coding. The connectivity\nbetween the $s_i - t_i$ pairs is quantified by means of a connectivity level\nvector, $[k_1 k_2 k_3]$ such that there exist $k_i$ edge-disjoint paths between\n$s_i$ and $t_i$. In this work we attempt to classify networks based on the\nconnectivity level. It can be observed that unit-rate transmission can be\nsupported by routing if $k_i \\geq 3$, for all $i = 1, \\dots, 3$. In this work,\nwe consider, connectivity level vectors such that $\\min_{i = 1, \\dots, 3} k_i <\n3$. We present either a constructive linear network coding scheme or an\ninstance of a network that cannot support the desired unit-rate requirement,\nfor all such connectivity level vectors except the vector $[1~2~4]$ (and its\npermutations). The benefits of our schemes extend to networks with higher and\npotentially different edge capacities. Specifically, our experimental results\nindicate that for networks where the different source-terminal paths have a\nsignificant overlap, our constructive unit-rate schemes can be packed along\nwith routing to provide higher throughput as compared to a pure routing\napproach. \n\n"}
{"id": "1302.5860", "contents": "Title: A universal, operational theory of unicast multi-user communication with\n  fidelity criteria Abstract: This is a three part paper.\n  Optimality of source-channel separation for communication with a fidelity\ncriterion when the channel is compound as defined by Csiszar and Korner in\ntheir book and general as defined by Verdu and Han, is proved in Part I. It is\nassumed that random codes are permitted. The word \"universal\" in the title of\nthis paper refers to the fact that the channel model is compound. The proof\nuses a layered black-box or a layered input-output view-point. In particular,\nonly the end-to-end description of the channel as being capable of\ncommunicating a source to within a certain distortion level is used when\nproving separation. This implies that the channel model does not play any role\nfor separation to hold as long as there is a source model. Further implications\nof the layered black-box view-point are discussed.\n  Optimality of source-medium separation for multi-user communication with\nfidelity criteria over a general, compound medium in the unicast setting is\nproved in Part II, thus generalizing Part I to the unicast, multi-user setting.\n  Part III gets to an understanding of the question, \"Why is a channel which is\ncapable of communicating a source to within a certain distortion level, also\ncapable of communicating bits at any rate less than the infimum of the rates\nneeded to code the source to within the distortion level\": this lies at the\nheart of why optimality of separation for communication with a fidelity\ncriterion holds. The perspective taken to get to this understanding is a\nrandomized covering-packing perspective, and the proof is operational. \n\n"}
{"id": "1302.5872", "contents": "Title: A Piggybacking Design Framework for Read-and Download-efficient\n  Distributed Storage Codes Abstract: We present a new 'piggybacking' framework for designing distributed storage\ncodes that are efficient in data-read and download required during node-repair.\nWe illustrate the power of this framework by constructing classes of explicit\ncodes that entail the smallest data-read and download for repair among all\nexisting solutions for three important settings: (a) codes meeting the\nconstraints of being Maximum-Distance-Separable (MDS), high-rate and having a\nsmall number of substripes, arising out of practical considerations for\nimplementation in data centers, (b) binary MDS codes for all parameters where\nbinary MDS codes exist, (c) MDS codes with the smallest repair-locality. In\naddition, we employ this framework to enable efficient repair of parity nodes\nin existing codes that were originally constructed to address the repair of\nonly the systematic nodes. The basic idea behind our framework is to take\nmultiple instances of existing codes and add carefully designed functions of\nthe data of one instance to the other. Typical savings in data-read during\nrepair is 25% to 50% depending on the choice of the code parameters. \n\n"}
{"id": "1303.0070", "contents": "Title: Entropy Distance Abstract: Motivated by the approach of random linear codes, a new distance in the\nvector space over a finite field is defined as the logarithm of the \"surface\narea\" of a Hamming ball with radius being the corresponding Hamming distance.\nIt is named entropy distance because of its close relation with entropy\nfunction. It is shown that entropy distance is a metric for a non-binary field\nand a pseudometric for the binary field. The entropy distance of a linear code\nis defined to be the smallest entropy distance between distinct codewords of\nthe code. Analogues of the Gilbert bound, the Hamming bound, and the Singleton\nbound are derived for the largest size of a linear code given the length and\nentropy distance of the code. Furthermore, as an important property related to\nlossless joint source-channel coding, the entropy distance of a linear encoder\nis defined. Very tight upper and lower bounds are obtained for the largest\nentropy distance of a linear encoder with given dimensions of input and output\nvector spaces. \n\n"}
{"id": "1303.0088", "contents": "Title: Half-Duplex or Full-Duplex Relaying: A Capacity Analysis under\n  Self-Interference Abstract: In this paper multi-antenna half-duplex and full-duplex relaying are compared\nfrom the perspective of achievable rates. Full-duplexing operation requires\nadditional resources at the relay such as antennas and RF chains for\nself-interference cancellation. Using a practical model for the residual\nself-interference, full-duplex achievable rates and degrees of freedom are\ncomputed for the cases for which the relay has the same number of antennas or\nthe same number of RF chains as in the half-duplex case, and compared with\ntheir half-duplex counterparts. It is shown that power scaling at the relay is\nnecessary to maximize the the degrees of freedom in the full-duplex mode. \n\n"}
{"id": "1303.0817", "contents": "Title: On Cooperation in Multi-Terminal Computation and Rate Distortion Abstract: A receiver wants to compute a function of two correlated sources separately\nobserved by two transmitters. One of the transmitters may send a possibly\nprivate message to the other transmitter in a cooperation phase before both\ntransmitters communicate to the receiver. For this network configuration this\npaper investigates both a function computation setup, wherein the receiver\nwants to compute a given function of the sources exactly, and a rate distortion\nsetup, wherein the receiver wants to compute a given function within some\ndistortion.\n  For the function computation setup, a general inner bound to the rate region\nis established and shown to be tight in a number of cases: partially invertible\nfunctions, full cooperation between transmitters, one-round point-to-point\ncommunication, two-round point-to-point communication, and the cascade setup\nwhere the transmitters and the receiver are aligned. In particular it is shown\nthat the ratio of the total number of transmitted bits without cooperation and\nthe total number of transmitted bits with cooperation can be arbitrarily large.\nFurthermore, one bit of cooperation suffices to arbitrarily reduce the amount\nof information both transmitters need to convey to the receiver.\n  For the rate distortion version, an inner bound to the rate region is\nexhibited which always includes, and sometimes strictly, the convex hull of\nKaspi-Berger's related inner bounds. The strict inclusion is shown via two\nexamples. \n\n"}
{"id": "1303.1026", "contents": "Title: Non-overlapping codes Abstract: We say that a $q$-ary length $n$ code is \\emph{non-overlapping} if the set of\nnon-trivial prefixes of codewords and the set of non-trivial suffices of\ncodewords are disjoint. These codes were first studied by Levenshtein in 1964,\nmotivated by applications in synchronisation. More recently these codes were\nindependently invented (under the name \\emph{cross-bifix-free} codes) by\nBaji\\'c and Stojanovi\\'c.\n  We provide a simple construction for a class of non-overlapping codes which\nhas optimal cardinality whenever $n$ divides $q$. Moreover, for all parameters\n$n$ and $q$ we show that a code from this class is close to optimal, in the\nsense that it has cardinality within a constant factor of an upper bound due to\nLevenshtein from 1970. Previous constructions have cardinality within a\nconstant factor of the upper bound only when $q$ is fixed.\n  Chee, Kiah, Purkayastha and Wang showed that a $q$-ary length $n$\nnon-overlapping code contains at most $q^n/(2n-1)$ codewords; this bound is\nweaker than the Levenshtein bound. Their proof appealed to the application in\nsynchronisation: we provide a direct combinatorial argument to establish the\nbound of Chee \\emph{et al}.\n  We also consider codes of short length, finding the leading term of the\nmaximal cardinality of a non-overlapping code when $n$ is fixed and\n$q\\rightarrow \\infty$. The largest cardinality of non-overlapping codes of\nlengths $3$ or less is determined exactly. \n\n"}
{"id": "1303.1144", "contents": "Title: Recursive Sparse Recovery in Large but Structured Noise - Part 2 Abstract: We study the problem of recursively recovering a time sequence of sparse\nvectors, St, from measurements Mt := St + Lt that are corrupted by structured\nnoise Lt which is dense and can have large magnitude. The structure that we\nrequire is that Lt should lie in a low dimensional subspace that is either\nfixed or changes \"slowly enough\"; and the eigenvalues of its covariance matrix\nare \"clustered\". We do not assume any model on the sequence of sparse vectors.\nTheir support sets and their nonzero element values may be either independent\nor correlated over time (usually in many applications they are correlated). The\nonly thing required is that there be some support change every so often. We\nintroduce a novel solution approach called Recursive Projected Compressive\nSensing with cluster-PCA (ReProCS-cPCA) that addresses some of the limitations\nof earlier work. Under mild assumptions, we show that, with high probability,\nReProCS-cPCA can exactly recover the support set of St at all times; and the\nreconstruction errors of both St and Lt are upper bounded by a time-invariant\nand small value. \n\n"}
{"id": "1303.3475", "contents": "Title: Nonasymptotic Probability Bounds for Fading Channels Exploiting Dedekind\n  Zeta Functions Abstract: In this paper, new probability bounds are derived for algebraic lattice\ncodes. This is done by using the Dedekind zeta functions of the algebraic\nnumber fields involved in the lattice constructions. In particular, it is shown\nhow to upper bound the error performance of a finite constellation on a\nRayleigh fading channel and the probability of an eavesdropper's correct\ndecision in a wiretap channel. As a byproduct, an estimate of the number of\nelements with a certain algebraic norm within a finite hyper-cube is derived.\nWhile this type of estimates have been, to some extent, considered in algebraic\nnumber theory before, they are now brought into novel practice in the context\nof fading channel communications. Hence, the interest here is in\nsmall-dimensional lattices and finite constellations rather than in the\nasymptotic behavior. \n\n"}
{"id": "1303.3734", "contents": "Title: Future Evolution of CSMA Protocols for the IEEE 802.11 Standard Abstract: In this paper a candidate protocol to replace the prevalent CSMA/CA medium\naccess control in Wireless Local Area Networks is presented. The proposed\nprotocol can achieve higher throughput than CSMA/CA, while maintaining\nfairness, and without additional implementation complexity. Under certain\ncircumstances, it is able to reach and maintain collision-free operation, even\nwhen the number of contenders is variable and potentially large. It is backward\ncompatible, allowing for new and legacy stations to coexist without degrading\none another's performance, a property that can make the adoption process by\nfuture versions of the standard smooth and inexpensive. \n\n"}
{"id": "1303.4645", "contents": "Title: Gradient methods for convex minimization: better rates under weaker\n  conditions Abstract: The convergence behavior of gradient methods for minimizing convex\ndifferentiable functions is one of the core questions in convex optimization.\nThis paper shows that their well-known complexities can be achieved under\nconditions weaker than the commonly accepted ones. We relax the common gradient\nLipschitz-continuity condition and strong convexity condition to ones that hold\nonly over certain line segments. Specifically, we establish complexities\n$O(\\frac{R}{\\epsilon})$ and $O(\\sqrt{\\frac{R}{\\epsilon}})$ for the ordinary and\naccelerate gradient methods, respectively, assuming that $\\nabla f$ is\nLipschitz continuous with constant $R$ over the line segment joining $x$ and\n$x-\\frac{1}{R}\\nabla f$ for each $x\\in\\dom f$. Then we improve them to\n$O(\\frac{R}{\\nu}\\log(\\frac{1}{\\epsilon}))$ and\n$O(\\sqrt{\\frac{R}{\\nu}}\\log(\\frac{1}{\\epsilon}))$ for function $f$ that also\nsatisfies the secant inequality $\\ < \\nabla f(x), x- x^*\\ > \\ge \\nu\\|x-x^*\\|^2$\nfor each $x\\in \\dom f$ and its projection $x^*$ to the minimizer set of $f$.\nThe secant condition is also shown to be necessary for the geometric decay of\nsolution error. Not only are the relaxed conditions met by more functions, the\nrestrictions give smaller $R$ and larger $\\nu$ than they are without the\nrestrictions and thus lead to better complexity bounds. We apply these results\nto sparse optimization and demonstrate a faster algorithm. \n\n"}
{"id": "1303.7460", "contents": "Title: Some results related to the conjecture by Belfiore and Sol\\'e Abstract: In the first part of the paper, we consider the relation between kissing\nnumber and the secrecy gain. We show that on an $n=24m+8k$-dimensional even\nunimodular lattice, if the shortest vector length is $\\geq 2m$, then as the\nnumber of vectors of length $2m$ decreases, the secrecy gain increases. We will\nalso prove a similar result on general unimodular lattices. We will also\nconsider the situations with shorter vectors. Furthermore, assuming the\nconjecture by Belfiore and Sol\\'e, we will calculate the difference between\ninverses of secrecy gains as the number of vectors varies. We will show by an\nexample that there exist two lattices in the same dimension with the same\nshortest vector length and the same kissing number, but different secrecy\ngains. Finally, we consider some cases of a question by Elkies by providing an\nanswer for a special class of lattices assuming the conjecture of Belfiore and\nSol\\'e. We will also get a conditional improvement on some Gaulter's results\nconcerning the conjecture. \n\n"}
{"id": "1304.0001", "contents": "Title: Optimality of $\\ell_2/\\ell_1$-optimization block-length dependent\n  thresholds Abstract: The recent work of \\cite{CRT,DonohoPol} rigorously proved (in a large\ndimensional and statistical context) that if the number of equations\n(measurements in the compressed sensing terminology) in the system is\nproportional to the length of the unknown vector then there is a sparsity\n(number of non-zero elements of the unknown vector) also proportional to the\nlength of the unknown vector such that $\\ell_1$-optimization algorithm succeeds\nin solving the system. In more recent papers\n\\cite{StojnicCSetamBlock09,StojnicICASSP09block,StojnicJSTSP09} we considered\nunder-determined systems with the so-called \\textbf{block}-sparse solutions. In\na large dimensional and statistical context in \\cite{StojnicCSetamBlock09} we\ndetermined lower bounds on the values of allowable sparsity for any given\nnumber (proportional to the length of the unknown vector) of equations such\nthat an $\\ell_2/\\ell_1$-optimization algorithm succeeds in solving the system.\nThese lower bounds happened to be in a solid numerical agreement with what one\ncan observe through numerical experiments. Here we derive the corresponding\nupper bounds. Moreover, the upper bounds that we obtain in this paper match the\nlower bounds from \\cite{StojnicCSetamBlock09} and ultimately make them optimal. \n\n"}
{"id": "1304.5007", "contents": "Title: Building one-time memories from isolated qubits Abstract: One-time memories (OTM's) are simple tamper-resistant cryptographic devices,\nwhich can be used to implement one-time programs, a very general form of\nsoftware protection and program obfuscation. Here we investigate the\npossibility of building OTM's using quantum mechanical devices. It is known\nthat OTM's cannot exist in a fully-quantum world or in a fully-classical world.\nInstead, we propose a new model based on \"isolated qubits\" -- qubits that can\nonly be accessed using local operations and classical communication (LOCC).\nThis model combines a quantum resource (single-qubit measurements) with a\nclassical restriction (on communication between qubits), and can be implemented\nusing current technologies, such as nitrogen vacancy centers in diamond. In\nthis model, we construct OTM's that are information-theoretically secure\nagainst one-pass LOCC adversaries that use 2-outcome measurements.\n  Our construction resembles Wiesner's old idea of quantum conjugate coding,\nimplemented using random error-correcting codes; our proof of security uses\nentropy chaining to bound the supremum of a suitable empirical process. In\naddition, we conjecture that our random codes can be replaced by some class of\nefficiently-decodable codes, to get computationally-efficient OTM's that are\nsecure against computationally-bounded LOCC adversaries.\n  In addition, we construct data-hiding states, which allow an LOCC sender to\nencode an (n-O(1))-bit messsage into n qubits, such that at most half of the\nmessage can be extracted by a one-pass LOCC receiver, but the whole message can\nbe extracted by a general quantum receiver. \n\n"}
{"id": "1304.5357", "contents": "Title: Exact-Regenerating Codes between MBR and MSR Points Abstract: In this paper we study distributed storage systems with exact repair. We give\na construction for regenerating codes between the minimum storage regenerating\n(MSR) and the minimum bandwidth regenerating (MBR) points and show that in the\ncase that the parameters n, k, and d are close to each other our constructions\nare close to optimal when comparing to the known capacity when only functional\nrepair is required. We do this by showing that when the distances of the\nparameters n, k, and d are fixed but the actual values approach to infinity,\nthe fraction of the performance of our codes with exact repair and the known\ncapacity of codes with functional repair approaches to one. \n\n"}
{"id": "1304.5856", "contents": "Title: Fundamental Limits of Distributed Caching in D2D Wireless Networks Abstract: We consider a wireless Device-to-Device (D2D) network where communication is\nrestricted to be single-hop, users make arbitrary requests from a finite\nlibrary of possible files and user devices cache information in the form of\nlinear combinations of packets from the files in the library (coded caching).\nWe consider the combined effect of coding in the caching and delivery phases,\nachieving \"coded multicast gain\", and of spatial reuse due to local short-range\nD2D communication. Somewhat counterintuitively, we show that the coded\nmulticast gain and the spatial reuse gain do not cumulate, in terms of the\nthroughput scaling laws. In particular, the spatial reuse gain shown in our\nprevious work on uncoded random caching and the coded multicast gain shown in\nthis paper yield the same scaling laws behavior, but no further scaling law\ngain can be achieved by using both coded caching and D2D spatial reuse. \n\n"}
{"id": "1304.6528", "contents": "Title: Nonanticipative Rate Distortion Function for General Source-Channel\n  Matching Abstract: In this paper we invoke a nonanticipative information Rate Distortion\nFunction (RDF) for sources with memory, and we analyze its importance in\nprobabilistic matching of the source to the channel so that transmission of a\nsymbol-by-symbol code with memory without anticipation is optimal, with respect\nto an average distortion and excess distortion probability. We show\nachievability of the symbol-by-symbol code with memory without anticipation,\nand we evaluate the probabilistic performance of the code for a Markov source. \n\n"}
{"id": "1304.6589", "contents": "Title: Partitions of Frobenius Rings Induced by the Homogeneous Weight Abstract: The values of the homogeneous weight are determined for finite Frobenius\nrings that are a direct product of local Frobenius rings. This is used to\ninvestigate the partition induced by this weight and its dual partition under\ncharacter-theoretic dualization. A characterization is given of those rings for\nwhich the induced partition is reflexive or even self-dual. \n\n"}
{"id": "1304.7162", "contents": "Title: The automorphism group of a self-dual [72,36,16] code is not an\n  elementary abelian group of order 8 Abstract: The existence of an extremal self-dual binary linear code C of length 72 is a\nlong-standing open problem. We continue the investigation of its automorphism\ngroup: looking at the combination of the subcodes fixed by different\ninvolutions and doing a computer calculation with Magma, we prove that Aut(C)\nis not isomorphic to the elementary abelian group of order 8. Combining this\nwith the known results in the literature one obtains that Aut(C) has order at\nmost 5. \n\n"}
{"id": "1304.7480", "contents": "Title: The Ergodic Capacity of the Multiple Access Channel Under Distributed\n  Scheduling - Order Optimality of Linear Receivers Abstract: Consider the problem of a Multiple-Input Multiple-Output (MIMO)\nMultiple-Access Channel (MAC) at the limit of large number of users. Clearly,\nin practical scenarios, only a small subset of the users can be scheduled to\nutilize the channel simultaneously. Thus, a problem of user selection arises.\nHowever, since solutions which collect Channel State Information (CSI) from all\nusers and decide on the best subset to transmit in each slot do not scale when\nthe number of users is large, distributed algorithms for user selection are\nadvantageous.\n  In this paper, we analyse a distributed user selection algorithm, which\nselects a group of users to transmit without coordinating between users and\nwithout all users sending CSI to the base station. This threshold-based\nalgorithm is analysed for both Zero-Forcing (ZF) and Minimum Mean Square Error\n(MMSE) receivers, and its expected sum-rate in the limit of large number of\nusers is investigated. It is shown that for large number of users it achieves\nthe same scaling laws as the optimal centralized scheme. \n\n"}
{"id": "1304.7751", "contents": "Title: On the Minimax Capacity Loss under Sub-Nyquist Universal Sampling Abstract: This paper investigates the information rate loss in analog channels when the\nsampler is designed to operate independent of the instantaneous channel\noccupancy. Specifically, a multiband linear time-invariant Gaussian channel\nunder universal sub-Nyquist sampling is considered. The entire channel\nbandwidth is divided into $n$ subbands of equal bandwidth. At each time only\n$k$ constant-gain subbands are active, where the instantaneous subband\noccupancy is not known at the receiver and the sampler. We study the\ninformation loss through a capacity loss metric, that is, the capacity gap\ncaused by the lack of instantaneous subband occupancy information. We\ncharacterize the minimax capacity loss for the entire sub-Nyquist rate regime,\nprovided that the number $n$ of subbands and the SNR are both large. The\nminimax limits depend almost solely on the band sparsity factor and the\nundersampling factor, modulo some residual terms that vanish as $n$ and SNR\ngrow. Our results highlight the power of randomized sampling methods (i.e. the\nsamplers that consist of random periodic modulation and low-pass filters),\nwhich are able to approach the minimax capacity loss with exponentially high\nprobability. \n\n"}
{"id": "1305.2233", "contents": "Title: Asymptotic Coverage Probability and Rate in Massive MIMO Networks Abstract: Massive multiple-input multiple-output (MIMO) is a transmission technique for\ncellular systems that uses many antennas to support not-as-many users. Thus\nfar, the performance of massive MIMO has only been examined in finite cellular\nnetworks. In this letter, we analyze its performance in random cellular\nnetworks with Poisson distributed base station locations. Specifically, we\nprovide analytical expressions for the asymptotic coverage probability and rate\nin both downlink and uplink when each base station has a large number of\nantennas. The results show that, though limited by pilot contamination, massive\nMIMO can provide significantly higher asymptotic data rate per user than the\nsingle-antenna network. \n\n"}
{"id": "1305.3969", "contents": "Title: Two-Hop Interference Channels: Impact of Linear Time-Varying Schemes Abstract: We consider the two-hop interference channel (IC) with constant real channel\ncoefficients, which consists of two source-destination pairs, separated by two\nrelays. We analyze the achievable degrees of freedom (DoF) of such network when\nrelays are restricted to perform scalar amplify-forward (AF) operations, with\npossibly time-varying coefficients. We show that, somewhat surprisingly, by\nproviding the flexibility of choosing time-varying AF coefficients at the\nrelays, it is possible to achieve 4/3 sum-DoF. We also develop a novel outer\nbound that matches our achievability, hence characterizing the sum-DoF of\ntwo-hop interference channels with time-varying AF relaying strategies. \n\n"}
{"id": "1305.4274", "contents": "Title: Conditional Random Fields, Planted Constraint Satisfaction, and Entropy\n  Concentration Abstract: This paper studies a class of probabilistic models on graphs, where edge\nvariables depend on incident node variables through a fixed probability kernel.\nThe class includes planted con- straint satisfaction problems (CSPs), as well\nas more general structures motivated by coding and community clustering\nproblems. It is shown that under mild assumptions on the kernel and for sparse\nrandom graphs, the conditional entropy of the node variables given the edge\nvariables concentrates around a deterministic threshold. This implies in\nparticular the concentration of the number of solutions in a broad class of\nplanted CSPs, the existence of a threshold function for the disassortative\nstochastic block model, and the proof of a conjecture on parity check codes. It\nalso establishes new connections among coding, clustering and satisfiability. \n\n"}
{"id": "1305.5082", "contents": "Title: Performance of Joint Channel and Physical Network Coding Based on\n  Alamouti STBC Abstract: This work considers the protograph-coded physical network coding (PNC) based\non Alamouti space-time block coding (STBC) over Nakagami-fading two-way relay\nchannels, in which both the two sources and relay possess two antennas. We\nfirst propose a novel precoding scheme at the two sources so as to implement\nthe iterative decoder efficiently at the relay. We further address a simplified\nupdating rule of the log-likelihood-ratio (LLR) in such a decoder. Based on the\nsimplified LLR-updating rule and Gaussian approximation, we analyze the\ntheoretical bit-error-rate (BER) of the system, which is shown to be consistent\nwith the decoding thresholds and simulated results. Moreover, the theoretical\nanalysis has lower computational complexity than the protograph extrinsic\ninformation transfer (PEXIT) algorithm. Consequently, the analysis not only\nprovides a simple way to evaluate the error performance but also facilitates\nthe design of the joint channel-and-PNC (JCNC) in wireless communication\nscenarios. \n\n"}
{"id": "1305.6126", "contents": "Title: Problems on q-Analogs in Coding Theory Abstract: The interest in $q$-analogs of codes and designs has been increased in the\nlast few years as a consequence of their new application in error-correction\nfor random network coding. There are many interesting theoretical, algebraic,\nand combinatorial coding problems concerning these q-analogs which remained\nunsolved. The first goal of this paper is to make a short summary of the large\namount of research which was done in the area mainly in the last few years and\nto provide most of the relevant references. The second goal of this paper is to\npresent one hundred open questions and problems for future research, whose\nsolution will advance the knowledge in this area. The third goal of this paper\nis to present and start some directions in solving some of these problems. \n\n"}
{"id": "1306.0772", "contents": "Title: Equivalence and comparison of heterogeneous cellular networks Abstract: We consider a general heterogeneous network in which, besides general\npropagation effects (shadowing and/or fading), individual base stations can\nhave different emitting powers and be subject to different parameters of\nHata-like path-loss models (path-loss exponent and constant) due to, for\nexample, varying antenna heights. We assume also that the stations may have\nvarying parameters of, for example, the link layer performance (SINR threshold,\netc). By studying the propagation processes of signals received by the typical\nuser from all antennas marked by the corresponding antenna parameters, we show\nthat seemingly different heterogeneous networks based on Poisson point\nprocesses can be equivalent from the point of view a typical user. These\nneworks can be replaced with a model where all the previously varying\npropagation parameters (including path-loss exponents) are set to constants\nwhile the only trade-off being the introduction of an isotropic base station\ndensity. This allows one to perform analytic comparisons of different network\nmodels via their isotropic representations. In the case of a constant path-loss\nexponent, the isotropic representation simplifies to a homogeneous modification\nof the constant intensity of the original network, thus generalizing a previous\nresult showing that the propagation processes only depend on one moment of the\nemitted power and propagation effects. We give examples and applications to\nmotivate these results and highlight an interesting observation regarding\nrandom path-loss exponents. \n\n"}
{"id": "1306.1922", "contents": "Title: Collaborative 20 Questions for Target Localization Abstract: We consider the problem of 20 questions with noise for multiple players under\nthe minimum entropy criterion in the setting of stochastic search, with\napplication to target localization. Each player yields a noisy response to a\nbinary query governed by a certain error probability. First, we propose a\nsequential policy for constructing questions that queries each player in\nsequence and refines the posterior of the target location. Second, we consider\na joint policy that asks all players questions in parallel at each time instant\nand characterize the structure of the optimal policy for constructing the\nsequence of questions. This generalizes the single player probabilistic\nbisection method for stochastic search problems. Third, we prove an equivalence\nbetween the two schemes showing that, despite the fact that the sequential\nscheme has access to a more refined filtration, the joint scheme performs just\nas well on average. Fourth, we establish convergence rates of the mean-square\nerror (MSE) and derive error exponents. Lastly, we obtain an extension to the\ncase of unknown error probabilities. This framework provides a mathematical\nmodel for incorporating a human in the loop for active machine learning\nsystems. \n\n"}
{"id": "1306.5277", "contents": "Title: Weight distribution of two classes of cyclic codes with respect to two\n  distinct order elements Abstract: Cyclic codes are an interesting type of linear codes and have wide\napplications in communication and storage systems due to their efficient\nencoding and decoding algorithms. Cyclic codes have been studied for many\nyears, but their weight distribution are known only for a few cases. In this\npaper, let $\\Bbb F_r$ be an extension of a finite field $\\Bbb F_q$ and $r=q^m$,\nwe determine the weight distribution of the cyclic codes $\\mathcal C=\\{c(a, b):\na, b \\in \\Bbb F_r\\},$ $$c(a, b)=(\\mbox {Tr}_{r/q}(ag_1^0+bg_2^0), \\ldots, \\mbox\n{Tr}_{r/q}(ag_1^{n-1}+bg_2^{n-1})), g_1, g_2\\in \\Bbb F_r,$$ in the following\ntwo cases: (1) $\\ord(g_1)=n, n|r-1$ and $g_2=1$; (2) $\\ord(g_1)=n$,\n$g_2=g_1^2$, $\\ord(g_2)=\\frac n 2$, $m=2$ and $\\frac{2(r-1)}n|(q+1)$. \n\n"}
{"id": "1306.6265", "contents": "Title: Towards Secure Two-Party Computation from the Wire-Tap Channel Abstract: We introduce a new protocol for secure two-party computation of linear\nfunctions in the semi-honest model, based on coding techniques. We first\nestablish a parallel between the second version of the wire-tap channel model\nand secure two-party computation. This leads us to our protocol, that combines\nlinear coset coding and oblivious transfer techniques. Our construction\nrequires the use of binary intersecting codes or $q$-ary minimal codes, which\nare also studied in this paper. \n\n"}
{"id": "1307.2295", "contents": "Title: Duality Codes and the Integrality Gap Bound for Index Coding Abstract: This paper considers a base station that delivers packets to multiple\nreceivers through a sequence of coded transmissions. All receivers overhear the\nsame transmissions. Each receiver may already have some of the packets as side\ninformation, and requests another subset of the packets. This problem is known\nas the index coding problem and can be represented by a bipartite digraph. An\ninteger linear program is developed that provides a lower bound on the minimum\nnumber of transmissions required for any coding algorithm. Conversely, its\nlinear programming relaxation is shown to provide an upper bound that is\nachievable by a simple form of vector linear coding. Thus, the information\ntheoretic optimum is bounded by the integrality gap between the integer program\nand its linear relaxation. In the special case when the digraph has a planar\nstructure, the integrality gap is shown to be zero, so that exact optimality is\nachieved. Finally, for non-planar problems, an enhanced integer program is\nconstructed that provides a smaller integrality gap. The dual of this problem\ncorresponds to a more sophisticated partial clique coding strategy that\ntime-shares between Reed-Solomon erasure codes. This work illuminates the\nrelationship between index coding, duality, and integrality gaps between\ninteger programs and their linear relaxations. \n\n"}
{"id": "1307.4149", "contents": "Title: Self-Interference Cancellation with Phase Noise Induced ICI Suppression\n  for Full-Duplex Systems Abstract: One of the main bottlenecks in practical full-duplex systems is the\noscillator phase noise, which bounds the possible cancellable self-interference\npower. In this paper, a digitaldomain self-interference cancellation scheme for\nfull-duplex orthogonal frequency division multiplexing systems is proposed. The\nproposed scheme increases the amount of cancellable selfinterference power by\nsuppressing the effect of both transmitter and receiver oscillator phase noise.\nThe proposed scheme consists of two main phases, an estimation phase and a\ncancellation phase. In the estimation phase, the minimum mean square error\nestimator is used to jointly estimate the transmitter and receiver phase noise\nassociated with the incoming self-interference signal. In the cancellation\nphase, the estimated phase noise is used to suppress the intercarrier\ninterference caused by the phase noise associated with the incoming\nself-interference signal. The performance of the proposed scheme is numerically\ninvestigated under different operating conditions. It is demonstrated that the\nproposed scheme could achieve up to 9dB more self-interference cancellation\nthan the existing digital-domain cancellation schemes that ignore the\nintercarrier interference suppression. \n\n"}
{"id": "1307.6864", "contents": "Title: Convex recovery from interferometric measurements Abstract: This note formulates a deterministic recovery result for vectors $x$ from\nquadratic measurements of the form $(Ax)_i \\overline{(Ax)_j}$ for some\nleft-invertible $A$. Recovery is exact, or stable in the noisy case, when the\ncouples $(i,j)$ are chosen as edges of a well-connected graph. One possible way\nof obtaining the solution is as a feasible point of a simple semidefinite\nprogram. Furthermore, we show how the proportionality constant in the error\nestimate depends on the spectral gap of a data-weighted graph Laplacian. Such\nquadratic measurements have found applications in phase retrieval, angular\nsynchronization, and more recently interferometric waveform inversion. \n\n"}
{"id": "1307.7159", "contents": "Title: MacWilliams Extension Theorems and the Local-Global Property for Codes\n  over Rings Abstract: The MacWilliams extension theorem is investigated for various weight\nfunctions over finite Frobenius rings. The problem is reformulated in terms of\na local-global property for subgroups of the general linear group. Among other\nthings, it is shown that the extension theorem holds true for poset weights if\nand only if the underlying poset is hierarchical. Specifically, the\nRosenbloom-Tsfasman weight for vector codes satisfies the extension theorem,\nwhereas the Niederreiter-Rosenbloom-Tsfasman weight for matrix codes does not.\nA short character-theoretic proof of the well-known MacWilliams extension\ntheorem for the homogeneous weight is provided. Moreover it is shown that the\nextension theorem carries over to direct products of weights, but not to\nsymmetrized products. \n\n"}
{"id": "1307.7375", "contents": "Title: Flow-level performance of random wireless networks Abstract: We study the flow-level performance of random wireless networks. The\nlocations of base stations (BSs) follow a Poisson point process. The number and\npositions of active users are dynamic. We associate a queue to each BS. The\nperformance and stability of a BS depend on its load. In some cases, the full\ndistribution of the load can be derived. Otherwise we derive formulas for the\nfirst and second moments. Networks on the line and on the plane are considered.\nOur model is generic enough to include features of recent wireless networks\nsuch as 4G (LTE) networks. In dense networks, we show that the inter-cell\ninterference power becomes normally distributed, simplifying many computations.\nNumerical experiments demonstrate that in cases of practical interest, the\nloads distribution can be well approximated by a gamma distribution with known\nmean and variance. \n\n"}
{"id": "1308.0786", "contents": "Title: Content Distribution Strategies in Opportunistic Networks Abstract: This paper describes a mechanism for content distribution through\nopportunistic contacts between subscribers. A subset of subscribers in the\nnetwork are seeded with the content. The remaining subscribers obtain the\ninformation through opportunistic contact with a user carrying the updated\ncontent. We study how the rate of content retrieval by subscribers is affected\nby the number of initial seeders in the network. We also study the rate of\ncontent retrieval by the subscribers under coding strategies (Network Coding,\nErasure Coding) and under Flooding, Epidemic Routing. \n\n"}
{"id": "1308.2454", "contents": "Title: Understanding the Benefits of Open Access in Femtocell Networks:\n  Stochastic Geometric Analysis in the Uplink Abstract: We introduce a comprehensive analytical framework to compare between open\naccess and closed access in two-tier femtocell networks, with regard to uplink\ninterference and outage. Interference at both the macrocell and femtocell\nlevels is considered. A stochastic geometric approach is employed as the basis\nfor our analysis. We further derive sufficient conditions for open access and\nclosed access to outperform each other in terms of the outage probability,\nleading to closed-form expressions to upper and lower bound the difference in\nthe targeted received power between the two access modes. Simulations are\nconducted to validate the accuracy of the analytical model and the correctness\nof the bounds. \n\n"}
{"id": "1308.2462", "contents": "Title: Wireless Information and Power Transfer in Multiuser OFDM Systems Abstract: In this paper, we study the optimal design for simultaneous wireless\ninformation and power transfer (SWIPT) in downlink multiuser orthogonal\nfrequency division multiplexing (OFDM) systems. For information transmission,\nwe consider two types of multiple access schemes, namely, time division\nmultiple access (TDMA) and orthogonal frequency division multiple access\n(OFDMA). At the receiver side, due to the practical limitation that circuits\nfor harvesting energy from radio signals are not yet able to decode the carried\ninformation directly, each user applies either time switching (TS) or power\nsplitting (PS) to coordinate the energy harvesting (EH) and information\ndecoding (ID) processes. For the TDMA-based information transmission, we employ\nTS at the receivers; for the OFDMA-based information transmission, we employ PS\nat the receivers. Under the above two scenarios, we address the problem of\nmaximizing the weighted sum-rate over all users by varying the time/frequency\npower allocation and either TS or PS ratio, subject to a minimum harvested\nenergy constraint on each user as well as a peak and/or total transmission\npower constraint. For the TS scheme, by an appropriate variable transformation\nthe problem is reformulated as a convex problem, for which the optimal power\nallocation and TS ratio are obtained by the Lagrange duality method. For the PS\nscheme, we propose an iterative algorithm to optimize the power allocation,\nsubcarrier (SC) allocation and the PS ratio for each user. The performances of\nthe two schemes are compared numerically as well as analytically for the\nspecial case of single-user setup. It is revealed that the peak power\nconstraint imposed on each OFDM SC as well as the number of users in the system\nplay a key role in the rate-energy performance comparison by the two proposed\nschemes. \n\n"}
{"id": "1308.5434", "contents": "Title: Multilevel Topological Interference Management Abstract: The robust principles of treating interference as noise (TIN) when it is\nsufficiently weak, and avoiding it when it is not, form the background for this\nwork. Combining TIN with the topological interference management (TIM)\nframework that identifies optimal interference avoidance schemes, a baseline\nTIM-TIN approach is proposed which decomposes a network into TIN and TIM\ncomponents, allocates the signal power levels to each user in the TIN\ncomponent, allocates signal vector space dimensions to each user in the TIM\ncomponent, and guarantees that the product of the two is an achievable number\nof signal dimensions available to each user in the original network. \n\n"}
{"id": "1308.6007", "contents": "Title: Tree Codes and a Conjecture on Exponential Sums Abstract: We propose a new conjecture on some exponential sums. These particular sums\nhave not apparently been considered in the literature. Subject to the\nconjecture we obtain the first effective construction of asymptotically good\ntree codes. The available numerical evidence is consistent with the conjecture\nand is sufficient to certify codes for significant-length communications. \n\n"}
{"id": "1309.0448", "contents": "Title: Distributed Sensing and Transmission of Sporadic Random Samples in a\n  Multiple-Access Channel Abstract: This work considers distributed sensing and transmission of sporadic random\nsamples. Lower bounds are derived for the reconstruction error of a single\nnormally or uniformly-distributed finite-dimensional vector imperfectly\nmeasured by a network of sensors and transmitted with finite energy to a common\nreceiver via an additive white Gaussian noise asynchronous multiple-access\nchannel. Transmission makes use of a perfect causal feedback link to the\nencoder connected to each sensor. A retransmission protocol inspired by the\nclassical scheme in [1] applied to the transmission of single and bi-variate\nanalog samples analyzed in [2] and [3] is extended to the more general network\nscenario, for which asymptotic upper-bounds on the reconstruction error are\nprovided. Both the upper and lower-bounds show that collaboration can be\nachieved through energy accumulation under certain circumstances. In order to\ninvestigate the practical performance of the proposed retransmission protocol\nwe provide a numerical evaluation of the upper-bounds in the non-asymptotic\nenergy regime using low-order quantization in the sensors. The latter includes\na minor modification of the protocol to improve reconstruction fidelity.\nNumerical results show that an increase in the size of the network brings\nbenefit in terms of performance, but that the gain in terms of energy\nefficiency diminishes quickly at finite energies due to a non-coherent\ncombining loss. \n\n"}
{"id": "1309.3522", "contents": "Title: Tail bounds via generic chaining Abstract: We modify Talagrand's generic chaining method to obtain upper bounds for all\np-th moments of the supremum of a stochastic process. These bounds lead to an\nestimate for the upper tail of the supremum with optimal deviation parameters.\nWe apply our procedure to improve and extend some known deviation inequalities\nfor suprema of unbounded empirical processes and chaos processes. As an\napplication we give a significantly simplified proof of the restricted isometry\nproperty of the subsampled discrete Fourier transform. \n\n"}
{"id": "1309.7528", "contents": "Title: Finite-Length Analyses for Source and Channel Coding on Markov Chains Abstract: We study finite-length bounds for source coding with side information for\nMarkov sources and channel coding for channels with conditional Markovian\nadditive noise. For this purpose, we propose two criteria for finite-length\nbounds. One is the asymptotic optimality and the other is the efficient\ncomputability of the bound. Then, we derive finite-length upper and lower\nbounds for coding length in both settings so that their computational\ncomplexity is efficient. To discuss the first criterion, we derive the large\ndeviation bounds, the moderate deviation bounds, and second order bounds for\nthese two topics, and show that these finite-length bounds achieves the\nasymptotic optimality in these senses. For this discussion, we introduce\nseveral kinds of information measure for transition matrices. \n\n"}
{"id": "1310.0776", "contents": "Title: Permutation polynomials on F_q induced from bijective Redei functions on\n  subgroups of the multiplicative group of F_q Abstract: We construct classes of permutation polynomials over F_{Q^2} by exhibiting\nclasses of low-degree rational functions over F_{Q^2} which induce bijections\non the set of (Q+1)-th roots of unity in F_{Q^2}. As a consequence, we prove\ntwo conjectures about permutation trinomials from a recent paper by Tu, Zeng,\nHu and Li. \n\n"}
{"id": "1310.3202", "contents": "Title: New Identities Relating Wild Goppa Codes Abstract: For a given support $L \\in \\mathbb{F}_{q^m}^n$ and a polynomial $g\\in\n\\mathbb{F}_{q^m}[x]$ with no roots in $\\mathbb{F}_{q^m}$, we prove equality\nbetween the $q$-ary Goppa codes $\\Gamma_q(L,N(g)) = \\Gamma_q(L,N(g)/g)$ where\n$N(g)$ denotes the norm of $g$, that is $g^{q^{m-1}+\\cdots +q+1}.$ In\nparticular, for $m=2$, that is, for a quadratic extension, we get\n$\\Gamma_q(L,g^q) = \\Gamma_q(L,g^{q+1})$. If $g$ has roots in\n$\\mathbb{F}_{q^m}$, then we do not necessarily have equality and we prove that\nthe difference of the dimensions of the two codes is bounded above by the\nnumber of distinct roots of $g$ in $\\mathbb{F}_{q^m}$. These identities provide\nnumerous code equivalences and improved designed parameters for some families\nof classical Goppa codes. \n\n"}
{"id": "1310.5930", "contents": "Title: A Unifying Model for External Noise Sources and ISI in Diffusive\n  Molecular Communication Abstract: This paper considers the impact of external noise sources, including\ninterfering transmitters, on a diffusive molecular communication system, where\nthe impact is measured as the number of noise molecules expected to be observed\nat a passive receiver. A unifying model for noise, multiuser interference, and\nintersymbol interference is presented, where, under certain circumstances,\ninterference can be approximated as a noise source that is emitting\ncontinuously. The model includes the presence of advection and molecule\ndegradation. The time-varying and asymptotic impact is derived for a series of\nspecial cases, some of which facilitate closed-form solutions. Simulation\nresults show the accuracy of the expressions derived for the impact of a\ncontinuously-emitting noise source, and show how approximating intersymbol\ninterference as a noise source can simplify the calculation of the expected bit\nerror probability of a weighted sum detector. \n\n"}
{"id": "1310.7028", "contents": "Title: Multiplicativity of completely bounded $p$-norms implies a strong\n  converse for entanglement-assisted capacity Abstract: The fully quantum reverse Shannon theorem establishes the optimal rate of\nnoiseless classical communication required for simulating the action of many\ninstances of a noisy quantum channel on an arbitrary input state, while also\nallowing for an arbitrary amount of shared entanglement of an arbitrary form.\nTurning this theorem around establishes a strong converse for the\nentanglement-assisted classical capacity of any quantum channel. This paper\nproves the strong converse for entanglement-assisted capacity by a completely\ndifferent approach and identifies a bound on the strong converse exponent for\nthis task. Namely, we exploit the recent entanglement-assisted \"meta-converse\"\ntheorem of Matthews and Wehner, several properties of the recently established\nsandwiched Renyi relative entropy (also referred to as the quantum Renyi\ndivergence), and the multiplicativity of completely bounded $p$-norms due to\nDevetak et al. The proof here demonstrates the extent to which the Arimoto\napproach can be helpful in proving strong converse theorems, it provides an\noperational relevance for the multiplicativity result of Devetak et al., and it\nadds to the growing body of evidence that the sandwiched Renyi relative entropy\nis the correct quantum generalization of the classical concept for all\n$\\alpha>1$. \n\n"}
{"id": "1310.7311", "contents": "Title: On the Degrees of Freedom of Asymmetric MIMO Interference Broadcast\n  Channels Abstract: In this paper, we study the degrees of freedom (DoF) of the asymmetric\nmulti-input-multi-output interference broadcast channel (MIMO-IBC). By\nintroducing a notion of connection pattern chain, we generalize the genie chain\nproposed in [11] to derive and prove the necessary condition of IA feasibility\nfor asymmetric MIMO-IBC, which is denoted as irreducible condition. It is\nnecessary for both linear interference alignment (IA) and asymptotic IA\nfeasibility in MIMO-IBC with arbitrary configurations. In a special class of\nasymmetric two-cell MIMOIBC, the irreducible condition is proved to be the\nsufficient and necessary condition for asymptotic IA feasibility, while the\ncombination of proper condition and irreducible condition is proved to the\nsufficient and necessary condition for linear IA feasibility. From these\nconditions, we derive the information theoretic maximal DoF per user and the\nmaximal DoF per user achieved by linear IA, and these DoFs are also the DoF per\nuser upper-bounds of asymmetric G-cell MIMO-IBC with asymptotic IA and linear\nIA, respectively. \n\n"}
{"id": "1310.7320", "contents": "Title: High Dimensional Robust M-Estimation: Asymptotic Variance via\n  Approximate Message Passing Abstract: In a recent article (Proc. Natl. Acad. Sci., 110(36), 14557-14562), El Karoui\net al. study the distribution of robust regression estimators in the regime in\nwhich the number of parameters p is of the same order as the number of samples\nn. Using numerical simulations and `highly plausible' heuristic arguments, they\nunveil a striking new phenomenon. Namely, the regression coefficients contain\nan extra Gaussian noise component that is not explained by classical concepts\nsuch as the Fisher information matrix. We show here that that this phenomenon\ncan be characterized rigorously techniques that were developed by the authors\nto analyze the Lasso estimator under high-dimensional asymptotics. We introduce\nan approximate message passing (AMP) algorithm to compute M-estimators and\ndeploy state evolution to evaluate the operating characteristics of AMP and so\nalso M-estimates. Our analysis clarifies that the `extra Gaussian noise'\nencountered in this problem is fundamentally similar to phenomena already\nstudied for regularized least squares in the setting n<p. \n\n"}
{"id": "1311.3868", "contents": "Title: On the automorphism groups of binary linear codes Abstract: Let C be a binary linear code and suppose that its automorphism group\ncontains a non trivial subgroup G. What can we say about C knowing G? In this\npaper we collect some answers to this question in the cases G=C_p, G=C_2p and\nG=D_2p (p an odd prime), with a particular regard to the case in which C is\nself-dual. Furthermore we generalize some methods used in other papers on this\nsubject. Finally we give a short survey on the problem of determining the\nautomorphism group of a putative self-dual [72,36,16] code, in order to show\nwhere these methods can be applied. \n\n"}
{"id": "1311.7113", "contents": "Title: Systematic Codes for Rank Modulation Abstract: The goal of this paper is to construct systematic error-correcting codes for\npermutations and multi-permutations in the Kendall's $\\tau$-metric. These codes\nare important in new applications such as rank modulation for flash memories.\nThe construction is based on error-correcting codes for multi-permutations and\na partition of the set of permutations into error-correcting codes. For a given\nlarge enough number of information symbols $k$, and for any integer $t$, we\npresent a construction for ${(k+r,k)}$ systematic $t$-error-correcting codes,\nfor permutations from $S_{k+r}$, with less redundancy symbols than the number\nof redundancy symbols in the codes of the known constructions. In particular,\nfor a given $t$ and for sufficiently large $k$ we can obtain $r=t+1$. The same\nconstruction is also applied to obtain related systematic error-correcting\ncodes for multi-permutations. \n\n"}
{"id": "1312.0522", "contents": "Title: Analog Baseband Cancellation for Full-Duplex: An Experiment Driven\n  Analysis Abstract: Recent wireless testbed implementations have proven that full-duplex\ncommunication is in fact possible and can outperform half-duplex systems. Many\nof these implementations modify existing half-duplex systems to operate in\nfull-duplex. To realize the full potential of full-duplex, radios need to be\ndesigned with self-interference in mind. In our work, we use a novel patch\nantenna prototype in an experimental setup to characterize the\nself-interference channel between transmit and receive radios. We derive an\nequivalent analytical baseband model and propose analog baseband cancellation\ntechniques to complement the RF cancellation provided by the patch antenna\nprototype. Our results show that a wide bandwidth, moderate isolation scheme\nachieves up to 2.4 bps/Hz higher achievable rate than a narrow bandwidth, high\nisolation scheme. Furthermore, the analog baseband cancellation yields a\n10-10,000 improvement in BER over RF only cancellation. \n\n"}
{"id": "1312.0914", "contents": "Title: Characterizing the Rate Region of the (4,3,3) Exact-Repair Regenerating\n  Codes Abstract: Exact-repair regenerating codes are considered for the case (n,k,d)=(4,3,3),\nfor which a complete characterization of the rate region is provided. This\ncharacterization answers in the affirmative the open question whether there\nexists a non-vanishing gap between the optimal bandwidth-storage tradeoff of\nthe functional-repair regenerating codes (i.e., the cut-set bound) and that of\nthe exact-repair regenerating codes. To obtain an explicit information\ntheoretic converse, a computer-aided proof (CAP) approach based on primal and\ndual relation is developed. This CAP approach extends Yeung's linear\nprogramming (LP) method, which was previously only used on information\ntheoretic problems with a few random variables due to the exponential growth of\nthe number of variables in the corresponding LP problem. The symmetry in the\nexact-repair regenerating code problem allows an effective reduction of the\nnumber of variables, and together with several other problem-specific\nreductions, the LP problem is reduced to a manageable scale. For the\nachievability, only one non-trivial corner point of the rate region needs to be\naddressed in this case, for which an explicit binary code construction is\ngiven. \n\n"}
{"id": "1312.1037", "contents": "Title: Blind Fractional Interference Alignment Abstract: Fractional Interference Alignment (FIA) is a transmission scheme which\nachieves any value between [0,1] for the Symbols transmitted per Antenna per\nChannel use (SpAC). FIA was designed in [1] specifically for Finite Alphabet\n(FA) signals, under the constraint that the Minimum Distance (MD) detector is\nused at all the receivers. Similar to classical interference alignment, the FIA\nprecoder also needs perfect channel state information at all the transmitters\n(CSIT). In this work, a novel Blind Fractional Interference Alignment (B-FIA)\nscheme is introduced, where the basic assumption is that CSIT is not available.\nWe consider two popular channel models, namely: Broadcast channel, and\nInterference channel. For these two channel models, the maximum achievable\nvalue of SpAC satisfying the constraints of the MD detector is obtained, but\nwith no CSIT, and also a precoder design is provided to obtain any value of\nSpAC in the achievable range.\n  Further, the precoder structure provided has one distinct advantage:\ninterference channel state information at the receiver (I-CSIR) is not needed,\nwhen all the transmitters and receivers are equipped with one antenna each.\nWhen two or more antennas are used at both ends, I-CSIR must be available to\nobtain the maximum achievable value of SpAC. The receiver designs for both the\nMinimum Distance and the Maximum Likelihood (ML) decoders are discussed, where\nthe interference statistics is estimated from the received signal samples.\nSimulation results of the B-FIA show that the ML decoder with estimated\nstatistics achieves a significantly better error rate performance when compared\nto the MD decoder with known statistics, since the MD decoder assumes the\ninterference plus noise term as colored Gaussian noise. \n\n"}
{"id": "1312.1325", "contents": "Title: Permutation polynomials induced from permutations of subfields, and some\n  complete sets of mutually orthogonal latin squares Abstract: We present a general technique for obtaining permutation polynomials over a\nfinite field from permutations of a subfield. By applying this technique to the\nsimplest classes of permutation polynomials on the subfield, we obtain several\nnew families of permutation polynomials. Some of these have the additional\nproperty that both f(x) and f(x)+x induce permutations of the field, which has\ncombinatorial consequences. We use some of our permutation polynomials to\nexhibit complete sets of mutually orthogonal latin squares. In addition, we\nsolve the open problem from a recent paper by Wu and Lin, and we give simpler\nproofs of much more general versions of the results in two other recent papers. \n\n"}
{"id": "1312.1763", "contents": "Title: Optimal Error Rates for Interactive Coding II: Efficiency and List\n  Decoding Abstract: We study coding schemes for error correction in interactive communications.\nSuch interactive coding schemes simulate any $n$-round interactive protocol\nusing $N$ rounds over an adversarial channel that corrupts up to $\\rho N$\ntransmissions. Important performance measures for a coding scheme are its\nmaximum tolerable error rate $\\rho$, communication complexity $N$, and\ncomputational complexity.\n  We give the first coding scheme for the standard setting which performs\noptimally in all three measures: Our randomized non-adaptive coding scheme has\na near-linear computational complexity and tolerates any error rate $\\delta <\n1/4$ with a linear $N = \\Theta(n)$ communication complexity. This improves over\nprior results which each performed well in two of these measures.\n  We also give results for other settings of interest, namely, the first\ncomputationally and communication efficient schemes that tolerate $\\rho <\n\\frac{2}{7}$ adaptively, $\\rho < \\frac{1}{3}$ if only one party is required to\ndecode, and $\\rho < \\frac{1}{2}$ if list decoding is allowed. These are the\noptimal tolerable error rates for the respective settings. These coding schemes\nalso have near linear computational and communication complexity.\n  These results are obtained via two techniques: We give a general black-box\nreduction which reduces unique decoding, in various settings, to list decoding.\nWe also show how to boost the computational and communication efficiency of any\nlist decoder to become near linear. \n\n"}
{"id": "1312.2222", "contents": "Title: A Stability Result for Sparse Convolutions Abstract: We will establish in this note a stability result for sparse convolutions on\ntorsion-free additive (discrete) abelian groups. Sparse convolutions on\ntorsion-free groups are free of cancellations and hence admit stability, i.e.\ninjectivity with a universal lower bound $\\alpha=\\alpha(s,f)$, only depending\non the cardinality $s$ and $f$ of the supports of both input sequences. More\nprecisely, we show that $\\alpha$ depends only on $s$ and $f$ and not on the\nambient dimension. This statement follows from a reduction argument which\ninvolves a compression into a small set preserving the additive structure of\nthe supports. \n\n"}
{"id": "1312.3837", "contents": "Title: Tables of parameters of symmetric configurations $v_{k}$ Abstract: Tables of the currently known parameters of symmetric configurations are\ngiven. Formulas for parameters of the known infinite families of symmetric\nconfigurations are presented as well. The results of the recent paper [18] are\nused. This work can be viewed as an appendix to [18], in the sense that the\ntables given here cover a much larger set of parameters. \n\n"}
{"id": "1312.3889", "contents": "Title: Cyclotomy of Weil Sums of Binomials Abstract: The Weil sum $W_{K,d}(a)=\\sum_{x \\in K} \\psi(x^d + a x)$ where $K$ is a\nfinite field, $\\psi$ is an additive character of $K$, $d$ is coprime to\n$|K^\\times|$, and $a \\in K^\\times$ arises often in number-theoretic\ncalculations, and in applications to finite geometry, cryptography, digital\nsequence design, and coding theory. Researchers are especially interested in\nthe case where $W_{K,d}(a)$ assumes three distinct values as $a$ runs through\n$K^\\times$. A Galois-theoretic approach, combined with $p$-divisibility results\non Gauss sums, is used here to prove a variety of new results that constrain\nwhich fields $K$ and exponents $d$ support three-valued Weil sums, and restrict\nthe values that such Weil sums may assume. \n\n"}
{"id": "1312.4182", "contents": "Title: Adaptive Protocols for Interactive Communication Abstract: How much adversarial noise can protocols for interactive communication\ntolerate? This question was examined by Braverman and Rao (IEEE Trans. Inf.\nTheory, 2014) for the case of \"robust\" protocols, where each party sends\nmessages only in fixed and predetermined rounds. We consider a new class of\nnon-robust protocols for Interactive Communication, which we call adaptive\nprotocols. Such protocols adapt structurally to the noise induced by the\nchannel in the sense that both the order of speaking, and the length of the\nprotocol may vary depending on observed noise.\n  We define models that capture adaptive protocols and study upper and lower\nbounds on the permissible noise rate in these models. When the length of the\nprotocol may adaptively change according to the noise, we demonstrate a\nprotocol that tolerates noise rates up to $1/3$. When the order of speaking may\nadaptively change as well, we demonstrate a protocol that tolerates noise rates\nup to $2/3$. Hence, adaptivity circumvents an impossibility result of $1/4$ on\nthe fraction of tolerable noise (Braverman and Rao, 2014). \n\n"}
{"id": "1312.4716", "contents": "Title: More Classes of Complete Permutation Polynomials over $\\F_q$ Abstract: In this paper, by using a powerful criterion for permutation polynomials\ngiven by Zieve, we give several classes of complete permutation monomials over\n$\\F_{q^r}$. In addition, we present a class of complete permutation\nmultinomials, which is a generalization of recent work. \n\n"}
{"id": "1312.4811", "contents": "Title: Finite-Length Analysis of BATS Codes Abstract: BATS codes were proposed for communication through networks with packet loss.\nA BATS code consists of an outer code and an inner code. The outer code is a\nmatrix generation of a fountain code, which works with the inner code that\ncomprises random linear coding at the intermediate network nodes. In this\npaper, the performance of finite-length BATS codes is analyzed with respect to\nboth belief propagation (BP) decoding and inactivation decoding. Our results\nenable us to evaluate efficiently the finite-length performance in terms of the\nnumber of batches used for decoding ranging from 1 to a given maximum number,\nand provide new insights on the decoding performance. Specifically, for a fixed\nnumber of input symbols and a range of the number of batches used for decoding,\nwe obtain recursive formulae to calculate respectively the stopping time\ndistribution of BP decoding and the inactivation probability in inactivation\ndecoding. We also find that both the failure probability of BP decoding and the\nexpected number of inactivations in inactivation decoding can be expressed in a\npower-sum form where the number of batches appears only as the exponent. This\npower-sum expression reveals clearly how the decoding failure probability and\nthe expected number of inactivation decrease with the number of batches. When\nthe number of batches used for decoding follows a Poisson distribution, we\nfurther derive recursive formulae with potentially lower computational\ncomplexity for both decoding algorithms. For the BP decoder that consumes\nbatches one by one, three formulae are provided to characterize the expected\nnumber of consumed batches until all the input symbols are decoded. \n\n"}
{"id": "1312.5276", "contents": "Title: Integration by parts and representation of information functionals Abstract: We introduce a new formalism for computing expectations of functionals of\narbitrary random vectors, by using generalised integration by parts formulae.\nIn doing so we extend recent representation formulae for the score function\nintroduced in Nourdin, Peccati and Swan (JFA, to appear) and also provide a new\nproof of a central identity first discovered in Guo, Shamai, and Verd{\\'u}\n(IEEE Trans. Information Theory, 2005). We derive a representation for the\nstandardized Fisher information of sums of i.i.d. random vectors which use our\nidentities to provide rates of convergence in information theoretic central\nlimit theorems (both in Fisher information distance and in relative entropy). \n\n"}
{"id": "1401.1671", "contents": "Title: Distributed Energy Efficient Channel Allocation Abstract: Design of energy efficient protocols for modern wireless systems has become\nan important area of research. In this paper, we propose a distributed\noptimization algorithm for the channel assignment problem for multiple\ninterfering transceiver pairs that cannot communicate with each other. We first\nmodify the auction algorithm for maximal energy efficiency and show that the\nproblem can be solved without explicit message passing using the carrier sense\nmultiple access (CSMA) protocols. We then develop a novel scheme by converting\nthe channel assignment problem into perfect matchings on bipartite graphs. The\nproposed scheme improves the energy efficiency and does not require any\nexplicit message passing or a shared memory between the users. We derive bounds\non the convergence rate and show that the proposed algorithm converges faster\nthan the distributed auction algorithm and achieves near-optimal performance\nunder Rayleigh fading channels. We also present an asymptotic performance\nanalysis of the fast matching algorithm for energy efficient resource\nallocation and prove the optimality for large enough number of users and number\nof channels. Finally, we provide numerical assessments that confirm the energy\nefficiency gains compared to the state of the art. \n\n"}
{"id": "1401.1944", "contents": "Title: Exploiting Frequency and Spatial Dimensions in Small Cell Wireless\n  Networks Abstract: This paper examines the efficiency of spatial and frequency dimensions in\nserving multiple users in the downlink of a small cell wireless network with\nrandomly deployed access points. For this purpose, the stochastic geometry\nframework is incorporated, taking into account the user distribution within\neach cell and the effect of sharing the available system resources to multiple\nusers. An analysis of performance in terms of signal-to-interference-ratio and\nachieved user rate is provided that holds under the class of non-cooperative\nmultiple access schemes. In order to obtain concrete results, two simple\ninstances of multiple access schemes are considered. It is shown that\nperformance depends critically on both the availability of frequency and/or\nspatial dimensions as well as the way they are employed. In particular,\nincreasing the number of available frequency dimensions alone is beneficial for\nusers experiencing large interference, whereas increasing spatial dimensions\nwithout employing frequency dimensions degrades performance. However, best\nperformance is achieved when both dimensions are combined in serving the users. \n\n"}
{"id": "1401.2774", "contents": "Title: Exact Optimized-cost Repair in Multi-hop Distributed Storage Networks Abstract: The problem of exact repair of a failed node in multi-hop networked\ndistributed storage systems is considered. Contrary to the most of the current\nstudies which model the repair process by the direct links from surviving nodes\nto the new node, the repair is modeled by considering the multi-hop network\nstructure, and taking into account that there might not exist direct links from\nall the surviving nodes to the new node. In the repair problem of these\nsystems, surviving nodes may cooperate to transmit the repair traffic to the\nnew node. In this setting, we define the total number of packets transmitted\nbetween nodes as repair-cost. A lower bound of the repaircost can thus be found\nby cut-set bound analysis. In this paper, we show that the lower bound of the\nrepair-cost is achievable for the exact repair of MDS codes in tandem and grid\nnetworks, thus resulting in the minimum-cost exact MDS codes. Further, two\nsuboptimal (achievable) bounds for the large scale grid networks are proposed. \n\n"}
{"id": "1401.2794", "contents": "Title: On Binomial Ideals associated to Linear Codes Abstract: Recently, it was shown that a binary linear code can be associated to a\nbinomial ideal given as the sum of a toric ideal and a non-prime ideal. Since\nthen two different generalizations have been provided which coincide for the\nbinary case. In this paper, we establish some connections between the two\napproaches. In particular, we show that the corresponding code ideals are\nrelated by elimination. Finally, a new heuristic decoding method for linear\ncodes over prime fields is discussed using Gr\\\"obner bases. \n\n"}
{"id": "1401.3098", "contents": "Title: Interference Alignment (IA) and Coordinated Multi-Point (CoMP) overheads\n  and RF impairments: testbed results Abstract: In this work we investigate the network MIMO techniques of interference\nalignment (IA) and fully adaptive joint transmission coordinated multipoint\n(CoMP) in an indoor very small cell environment. Our focus is on the overheads\nin a system with quantized channel state feedback from the receiver to the\ntransmitter (based on the 802.11ac standard) and on the impact of non-ideal\nhardware. The indoor office scenario should be the most favourable case in\nterms of the required feedback rates due to the large coherence bandwidth and\ncoherence time of the channel. The evaluations are done using a real-world\nwireless testbed with three BSs and three MSs all having two antennas. The\nsignal to noise ratio in the measurements is very high, 35-60dB, due to the\nshort transmission range. Under such conditions radio hardware impairments\nbecomes a major limitation on the performance. We quantify the impact of these\nimpairments. For a 23ms update interval the overhead is 2.5% and IA and CoMP\nimproves the sum throughput 27% and 47% in average (over the reference schemes\ne.g. TDMA MIMO), under stationary conditions. When two people are walking in\nthe measurement area the throughput improvements drops to 16% and 45%,\nrespectively. \n\n"}
{"id": "1401.5234", "contents": "Title: On the third weight of generalized Reed-Muller codes Abstract: In this paper, we study the third weight of generalized Reed-Muller codes. We\nprove under some restrictive condition that the third weight of generalized\nReed-Muller codes depends on the third weight of generalized Reed-Muller codes\nof small order with two variables. In some cases, we are able to determine the\nthird weight and the third weight codewords of generalized Reed-Muller codes. \n\n"}
{"id": "1401.6354", "contents": "Title: Local Identification of Overcomplete Dictionaries Abstract: This paper presents the first theoretical results showing that stable\nidentification of overcomplete $\\mu$-coherent dictionaries $\\Phi \\in\n\\mathbb{R}^{d\\times K}$ is locally possible from training signals with sparsity\nlevels $S$ up to the order $O(\\mu^{-2})$ and signal to noise ratios up to\n$O(\\sqrt{d})$. In particular the dictionary is recoverable as the local maximum\nof a new maximisation criterion that generalises the K-means criterion. For\nthis maximisation criterion results for asymptotic exact recovery for sparsity\nlevels up to $O(\\mu^{-1})$ and stable recovery for sparsity levels up to\n$O(\\mu^{-2})$ as well as signal to noise ratios up to $O(\\sqrt{d})$ are\nprovided. These asymptotic results translate to finite sample size recovery\nresults with high probability as long as the sample size $N$ scales as $O(K^3dS\n\\tilde \\varepsilon^{-2})$, where the recovery precision $\\tilde \\varepsilon$\ncan go down to the asymptotically achievable precision. Further, to actually\nfind the local maxima of the new criterion, a very simple Iterative\nThresholding and K (signed) Means algorithm (ITKM), which has complexity\n$O(dKN)$ in each iteration, is presented and its local efficiency is\ndemonstrated in several experiments. \n\n"}
{"id": "1401.6683", "contents": "Title: Resource Allocation Under Channel Uncertainties for Relay-Aided\n  Device-to-Device Communication Underlaying LTE-A Cellular Networks Abstract: Device-to-device (D2D) communication in cellular networks allows direct\ntransmission between two cellular devices with local communication needs. Due\nto the increasing number of autonomous heterogeneous devices in future mobile\nnetworks, an efficient resource allocation scheme is required to maximize\nnetwork throughput and achieve higher spectral efficiency. In this paper,\nperformance of network-integrated D2D communication under channel uncertainties\nis investigated where D2D traffic is carried through relay nodes. Considering a\nmulti-user and multi-relay network, we propose a robust distributed solution\nfor resource allocation with a view to maximizing network sum-rate when the\ninterference from other relay nodes and the link gains are uncertain. An\noptimization problem is formulated for allocating radio resources at the relays\nto maximize end-to-end rate as well as satisfy the quality-of-service (QoS)\nrequirements for cellular and D2D user equipments under total power constraint.\nEach of the uncertain parameters is modeled by a bounded distance between its\nestimated and bounded values. We show that the robust problem is convex and a\ngradient-aided dual decomposition algorithm is applied to allocate radio\nresources in a distributed manner. Finally, to reduce the cost of robustness\ndefined as the reduction of achievable sum-rate, we utilize the \\textit{chance\nconstraint approach} to achieve a trade-off between robustness and optimality.\nThe numerical results show that there is a distance threshold beyond which\nrelay-aided D2D communication significantly improves network performance when\ncompared to direct communication between D2D peers. \n\n"}
{"id": "1401.6728", "contents": "Title: A Generalized Typicality for Abstract Alphabets Abstract: A new notion of typicality for arbitrary probability measures on standard\nBorel spaces is proposed, which encompasses the classical notions of weak and\nstrong typicality as special cases. Useful lemmas about strong typical sets,\nincluding conditional typicality lemma, joint typicality lemma, and packing and\ncovering lemmas, which are fundamental tools for deriving many inner bounds of\nvarious multi-terminal coding problems, are obtained in terms of the proposed\nnotion. This enables us to directly generalize lots of results on finite\nalphabet problems to general problems involving abstract alphabets, without any\ncomplicated additional arguments. For instance, quantization procedure is no\nlonger necessary to achieve such generalizations. Another fundamental lemma,\nMarkov lemma, is also obtained but its scope of application is quite limited\ncompared to others. Yet, an alternative theory of typical sets for Gaussian\nmeasures, free from this limitation, is also developed. Some remarks on a\npossibility to generalize the proposed notion for sources with memory are also\ngiven. \n\n"}
{"id": "1401.7485", "contents": "Title: Superimposed Codes and Threshold Group Testing Abstract: We will discuss superimposed codes and non-adaptive group testing designs\narising from the potentialities of compressed genotyping models in molecular\nbiology. The given paper was motivated by the 30th anniversary of\nD'yachkov-Rykov recurrent upper bound on the rate of superimposed codes\npublished in 1982. We were also inspired by recent results obtained for\nnon-adaptive threshold group testing which develop the theory of superimposed\ncodes \n\n"}
{"id": "1402.0614", "contents": "Title: Vector Bin-and-Cancel for MIMO Distributed Full-Duplex Abstract: In a multi-input multi-output (MIMO) full-duplex network, where an in-band\nfull-duplex infrastruc- ture node communicates with two half-duplex mobiles\nsupporting simultaneous up- and downlink flows, the inter-mobile interference\nbetween the up- and downlink mobiles limits the system performance. We study\nthe impact of leveraging an out-of-band side-channel between mobiles in such\nnetwork under different channel models. For time-invariant channels, we aim to\ncharacterize the generalized degrees- of-freedom (GDoF) of the side-channel\nassisted MIMO full-duplex network. For slow-fading channels, we focus on the\ndiversity-multiplexing tradeoff (DMT) of the system with various assumptions as\nto the availability of channel state information at the transmitter (CSIT). The\nkey to the optimal performance is a vector bin-and-cancel strategy leveraging\nHan-Kobayashi message splitting, which is shown to achieve the system capacity\nregion to within a constant bit. We quantify how the side-channel improve the\nGDoF and DMT compared to a system without the extra orthogonal spectrum. The\ninsights gained from our analysis reveal: i) the tradeoff between spatial\nresources from multiple antennas at different nodes and spectral resources of\nthe side-channel, and ii) the interplay between the channel uncertainty at the\ntransmitter and use of the side-channel. \n\n"}
{"id": "1402.0729", "contents": "Title: Stability and Performance Issues of a Relay Assisted Multiple Access\n  Scheme with MPR Capabilities Abstract: In this work, we study the impact of a relay node to a network with a finite\nnumber of users-sources and a destination node. We assume that the users have\nsaturated queues and the relay node does not have packets of its own; we have\nrandom access of the medium and the time is slotted. The relay node stores a\nsource packet that it receives successfully in its queue when the transmission\nto the destination node has failed. The relay and the destination nodes have\nmulti-packet reception capabilities. We obtain analytical equations for the\ncharacteristics of the relay's queue such as average queue length, stability\nconditions etc. We also study the throughput per user and the aggregate\nthroughput for the network. \n\n"}
{"id": "1402.3264", "contents": "Title: Polynomial Time Attack on Wild McEliece Over Quadratic Extensions Abstract: We present a polynomial time structural attack against the McEliece system\nbased on Wild Goppa codes from a quadratic finite field extension. This attack\nuses the fact that such codes can be distinguished from random codes to compute\nsome filtration, that is to say a family of nested subcodes which will reveal\ntheir secret algebraic description. \n\n"}
{"id": "1402.4576", "contents": "Title: On the Average Performance of Caching and Coded Multicasting with Random\n  Demands Abstract: For a network with one sender, $n$ receivers (users) and $m$ possible\nmessages (files), caching side information at the users allows to satisfy\narbitrary simultaneous demands by sending a common (multicast) coded message.\nIn the worst-case demand setting, explicit deterministic and random caching\nstrategies and explicit linear coding schemes have been shown to be order\noptimal. In this work, we consider the same scenario where the user demands are\nrandom i.i.d., according to a Zipf popularity distribution. In this case, we\npose the problem in terms of the minimum average number of equivalent message\ntransmissions. We present a novel decentralized random caching placement and a\ncoded delivery scheme which are shown to achieve order-optimal performance. As\na matter of fact, this is the first order-optimal result for the caching and\ncoded multicasting problem in the case of random demands. \n\n"}
{"id": "1402.4729", "contents": "Title: On the Degrees-of-freedom of the 3-user MISO Broadcast Channel with\n  Hybrid CSIT Abstract: The 3-user multiple-input single-output (MISO) broadcast channel (BC) with\nhybrid channel state information at the transmitter (CSIT) is considered. In\nthis framework, there is perfect and instantaneous CSIT from a subset of users\nand delayed CSIT from the remaining users. We present new results on the\ndegrees of freedom (DoF) of the 3-user MISO BC with hybrid CSIT. In particular,\nfor the case of 2 transmit antennas, we show that with perfect CSIT from one\nuser and delayed CSIT from the remaining two users, the optimal DoF is 5/3. For\nthe case of 3 transmit antennas and the same hybrid CSIT setting, it is shown\nthat a higher DoF of 9/5 is achievable and this result improves upon the best\nknown bound. Furthermore, with 3 transmit antennas, and the hybrid CSIT setting\nin which there is perfect CSIT from two users and delayed CSIT from the third\none, a novel scheme is presented which achieves 9/4 DoF. Our results also\nreveal new insights on how to utilize hybrid channel knowledge for multi-user\nscenarios. \n\n"}
{"id": "1402.5074", "contents": "Title: Binary Fused Compressive Sensing: 1-Bit Compressive Sensing meets Group\n  Sparsity Abstract: We propose a new method, {\\it binary fused compressive sensing} (BFCS), to\nrecover sparse piece-wise smooth signals from 1-bit compressive measurements.\nThe proposed algorithm is a modification of the previous {\\it binary iterative\nhard thresholding} (BIHT) algorithm, where, in addition to the sparsity\nconstraint, the total-variation of the recovered signal is upper constrained.\nAs in BIHT, the data term of the objective function is an one-sided $\\ell_1$\n(or $\\ell_2$) norm. Experiments on the recovery of sparse piece-wise smooth\nsignals show that the proposed algorithm is able to take advantage of the\npiece-wise smoothness of the original signal, achieving more accurate recovery\nthan BIHT. \n\n"}
{"id": "1402.6294", "contents": "Title: Frankl-R\\\"odl type theorems for codes and permutations Abstract: We give a new proof of the Frankl-R\\\"odl theorem on forbidden intersections,\nvia the probabilistic method of dependent random choice. Our method extends to\ncodes with forbidden distances, where over large alphabets our bound is\nsignificantly better than that obtained by Frankl and R\\\"odl. We also apply our\nbound to a question of Ellis on sets of permutations with forbidden distances,\nand to establish a weak form of a conjecture of Alon, Shpilka and Umans on\nsunflowers. \n\n"}
{"id": "1402.6299", "contents": "Title: Necessary and sufficient optimality conditions for classical simulations\n  of quantum communication processes Abstract: We consider the process consisting of preparation, transmission through a\nquantum channel, and subsequent measurement of quantum states. The\ncommunication complexity of the channel is the minimal amount of classical\ncommunication required for classically simulating it. Recently, we reduced the\ncomputation of this quantity to a convex minimization problem with linear\nconstraints. Every solution of the constraints provides an upper bound on the\ncommunication complexity. In this paper, we derive the dual maximization\nproblem of the original one. The feasible points of the dual constraints, which\nare inequalities, give lower bounds on the communication complexity, as\nillustrated with an example. The optimal values of the two problems turn out to\nbe equal (zero duality gap). By this property, we provide necessary and\nsufficient conditions for optimality in terms of a set of equalities and\ninequalities. We use these conditions and two reasonable but unproven\nhypotheses to derive the lower bound $n 2^{n-1}$ for a noiseless quantum\nchannel with capacity equal to $n$ qubits. This lower bound can have\ninteresting consequences in the context of the recent debate on the reality of\nthe quantum state. \n\n"}
{"id": "1403.0054", "contents": "Title: Multi-Objective Resource Allocation for Secure Communication in\n  Cognitive Radio Networks with Wireless Information and Power Transfer Abstract: In this paper, we study resource allocation for multiuser multiple-input\nsingle-output secondary communication systems with multiple system design\nobjectives. We consider cognitive radio networks where the secondary receivers\nare able to harvest energy from the radio frequency when they are idle. The\nsecondary system provides simultaneous wireless power and secure information\ntransfer to the secondary receivers. We propose a multi-objective optimization\nframework for the design of a Pareto optimal resource allocation algorithm\nbased on the weighted Tchebycheff approach. In particular, the algorithm design\nincorporates three important system objectives: total transmit power\nminimization, energy harvesting efficiency maximization, and interference power\nleakage-to-transmit power ratio minimization. The proposed framework takes into\naccount a quality of service requirement regarding communication secrecy in the\nsecondary system and the imperfection of the channel state information of\npotential eavesdroppers (idle secondary receivers and primary receivers) at the\nsecondary transmitter. The adopted multi-objective optimization problem is\nnon-convex and is recast as a convex optimization problem via semidefinite\nprogramming (SDP) relaxation. It is shown that the global optimal solution of\nthe original problem can be constructed by exploiting both the primal and the\ndual optimal solutions of the SDP relaxed problem. Besides, two suboptimal\nresource allocation schemes for the case when the solution of the dual problem\nis unavailable for constructing the optimal solution are proposed. Numerical\nresults not only demonstrate the close-to-optimal performance of the proposed\nsuboptimal schemes, but also unveil an interesting trade-off between the\nconsidered conflicting system design objectives. \n\n"}
{"id": "1403.0836", "contents": "Title: Locally-Optimized Reweighted Belief Propagation for Decoding LDPC Codes\n  with Finite-Length Abstract: In practice, LDPC codes are decoded using message passing methods. These\nmethods offer good performance but tend to converge slowly and sometimes fail\nto converge and to decode the desired codewords correctly. Recently,\ntree-reweighted message passing methods have been modified to improve the\nconvergence speed at little or no additional complexity cost. This paper\nextends this line of work and proposes a new class of locally optimized\nreweighting strategies, which are suitable for both regular and irregular LDPC\ncodes. The proposed decoding algorithm first splits the factor graph into\nsubgraphs and subsequently performs a local optimization of reweighting\nparameters. Simulations show that the proposed decoding algorithm significantly\noutperforms the standard message passing and existing reweighting techniques. \n\n"}
{"id": "1403.4118", "contents": "Title: Efficient Maximum-Likelihood Decoding of Linear Block Codes on Binary\n  Memoryless Channels Abstract: In this work, we consider efficient maximum-likelihood decoding of linear\nblock codes for small-to-moderate block lengths. The presented approach is a\nbranch-and-bound algorithm using the cutting-plane approach of Zhang and Siegel\n(IEEE Trans. Inf. Theory, 2012) for obtaining lower bounds. We have compared\nour proposed algorithm to the state-of-the-art commercial integer program\nsolver CPLEX, and for all considered codes our approach is faster for both low\nand high signal-to-noise ratios. For instance, for the benchmark (155,64)\nTanner code our algorithm is more than 11 times as fast as CPLEX for an SNR of\n1.0 dB on the additive white Gaussian noise channel. By a small modification,\nour algorithm can be used to calculate the minimum distance, which we have\nagain verified to be much faster than using the CPLEX solver. \n\n"}
{"id": "1403.4311", "contents": "Title: The lower bound of the PCM quantization error in high dimension Abstract: In this note, we investigate the performance of the PCM scheme with linear\nquantization rule for quantizing unit-norm tight frame expansions for ${\\mathbb\nR}^d$ without the White Noise Hypothesis. In \\cite{WX}, Wang and Xu showed that\nfor asymptotically equidistributed unit-norm tight frame the PCM quantization\nerror has an upper bound ${\\mathcal O}(\\delta^{(d+1)/2})$ and they conjecture\nthe upper bound is sharp. In this note, we confirm the conjecture with\nemploying the asymptotic estimate of the Bessel functions. \n\n"}
{"id": "1403.4452", "contents": "Title: The Homogeneous Weight Partition and its Character-Theoretic Dual Abstract: The values of the normalized homogeneous weight are determined for arbitrary\nfinite Frobenius rings and expressed in a form that is independent from a\ngenerating character and the M\\\"obius function on the ring. The weight\nnaturally induces a partition of the ring, which is invariant under left or\nright multiplication by units. It is shown that the character-theoretic\nleft-sided dual of this partition coincides with the right-sided dual, and even\nmore, the left- and right-sided Krawtchouk coefficients coincide. An example is\nprovided showing that this is not the case for general invariant partitions if\nthe ring is not semisimple. \n\n"}
{"id": "1403.4643", "contents": "Title: Information Content of Systems as a Physical Principle Abstract: To explain conceptual gap between classical/quantum and other, hypothetical\ndescriptions of world, several principles has been proposed. So far, all these\nprinciples have not explicitly included the uncertainty relation. Here we\nintroduce an information content principle (ICP) which represents the new -\nconstrained uncertainty principle. The principle, by taking into account the\nencoding/decoding properties of single physical system, is capable of\nseparation both classicality and quanta from a number of potential physical\ntheories including hidden variable theories. The ICP, which is satisfied by\nboth classical and quantum theory, states that the amount of non-redundant\ninformation which may be extracted from a given system is bounded by a\nperfectly decodable information content of the system. We show that ICP allows\nto discriminate theories which do not allow for correlations stronger than\nTsirelson's bound. We show also how to apply the principle to composite\nsystems, ruling out some theories despite their elementary constituents behave\nquantumly. \n\n"}
{"id": "1403.6143", "contents": "Title: Exact correct-decoding exponent of the wiretap channel decoder Abstract: The security level of the achievability scheme for Wyner's wiretap channel\nmodel is examined from the perspective of the probability of correct decoding,\n$P_c$, at the wiretap channel decoder. In particular, for finite-alphabet\nmemoryless channels, the exact random coding exponent of $P_c$ is derived as a\nfunction of the total coding rate $R_1$ and the rate of each sub-code $R_2$.\nTwo different representations are given for this function and its basic\nproperties are provided. We also characterize the region of pairs of rates\n$(R_1,R_2)$ of full security in the sense of the random coding exponent of\n$P_c$, in other words, the region where the exponent of this achievability\nscheme is the same as that of blind guessing at the eavesdropper side. Finally,\nan analogous derivation of the correct-decoding exponent is outlined for the\ncase of the Gaussian channel. \n\n"}
{"id": "1404.1193", "contents": "Title: Cost minimization for fading channels with energy harvesting and\n  conventional energy Abstract: In this paper, we investigate resource allocation strategies for a\npoint-to-point wireless communications system with hybrid energy sources\nconsisting of an energy harvester and a conventional energy source. In\nparticular, as an incentive to promote the use of renewable energy, we assume\nthat the renewable energy has a lower cost than the conventional energy. Then,\nby assuming that the non-causal information of the energy arrivals and the\nchannel power gains are available, we minimize the total energy cost of such a\nsystem over $N$ fading slots under a proposed outage constraint together with\nthe energy harvesting constraints. The outage constraint requires a minimum\nfixed number of slots to be reliably decoded, and thus leads to a mixed-integer\nprogramming formulation for the optimization problem. This constraint is\nuseful, for example, if an outer code is used to recover all the data bits.\nOptimal linear time algorithms are obtained for two extreme cases, i.e., the\nnumber of outage slot is $1$ or $N-1$. For the general case, a lower bound\nbased on the linear programming relaxation, and two suboptimal algorithms are\nproposed. It is shown that the proposed suboptimal algorithms exhibit only a\nsmall gap from the lower bound. We then extend the proposed algorithms to the\nmulti-cycle scenario in which the outage constraint is imposed for each cycle\nseparately. Finally, we investigate the resource allocation strategies when\nonly causal information on the energy arrivals and only channel statistics is\navailable. It is shown that the greedy energy allocation is optimal for this\nscenario. \n\n"}
{"id": "1404.1484", "contents": "Title: MUSIC for Single-Snapshot Spectral Estimation: Stability and\n  Super-resolution Abstract: This paper studies the problem of line spectral estimation in the continuum\nof a bounded interval with one snapshot of array measurement. The\nsingle-snapshot measurement data is turned into a Hankel data matrix which\nadmits the Vandermonde decomposition and is suitable for the MUSIC algorithm.\nThe MUSIC algorithm amounts to finding the null space (the noise space) of the\nHankel matrix, forming the noise-space correlation function and identifying the\ns smallest local minima of the noise-space correlation as the frequency set.\n  In the noise-free case exact reconstruction is guaranteed for any arbitrary\nset of frequencies as long as the number of measurements is at least twice the\nnumber of distinct frequencies to be recovered. In the presence of noise the\nstability analysis shows that the perturbation of the noise-space correlation\nis proportional to the spectral norm of the noise matrix as long as the latter\nis smaller than the smallest (nonzero) singular value of the noiseless Hankel\ndata matrix. Under the assumption that frequencies are separated by at least\ntwice the Rayleigh Length (RL), the stability of the noise-space correlation is\nproved by means of novel discrete Ingham inequalities which provide bounds on\nnonzero singular values of the noiseless Hankel data matrix.\n  The numerical performance of MUSIC is tested in comparison with other\nalgorithms such as BLO-OMP and SDP (TV-min). While BLO-OMP is the stablest\nalgorithm for frequencies separated above 4 RL, MUSIC becomes the best\nperforming one for frequencies separated between 2 RL and 3 RL. Also, MUSIC is\nmore efficient than other methods. MUSIC truly shines when the frequency\nseparation drops to 1 RL or below when all other methods fail. Indeed, the\nresolution length of MUSIC decreases to zero as noise decreases to zero as a\npower law with an exponent much smaller than an upper bound established by\nDonoho. \n\n"}
{"id": "1404.2904", "contents": "Title: Construction A of Lattices over Number Fields and Block Fading Wiretap\n  Coding Abstract: We propose a lattice construction from totally real and CM fields, which\nnaturally generalizes the Construction A of lattices from $p$-ary codes\nobtained from the cyclotomic field $\\mathbb{Q}(\\zeta_p)$, $p$ a prime, which in\nturn contains the so-called Construction A of lattices from binary codes as a\nparticular case. We focus on the maximal totally real subfield\n$\\mathbb{Q}(\\zeta_{p^r}+\\zeta_{p}^{-r})$ of the cyclotomic field\n$\\mathbb{Q}(\\zeta_{p^r})$, $r\\geq 1$. Our construction has applications to\ncoset encoding of algebraic lattice codes, and we detail the case of coset\nencoding of block fading wiretap codes. \n\n"}
{"id": "1404.3010", "contents": "Title: On the Energy-Spectral Efficiency Trade-off of the MRC Receiver in\n  Massive MIMO Systems with Transceiver Power Consumption Abstract: We consider the uplink of a multiuser massive MIMO system wherein a base\nstation (BS) having $M$ antennas communicates coherently with $K$ single\nantenna user terminals (UTs). We study the energy efficiency of this system\nwhile taking the transceiver power consumption at the UTs and the BS into\nconsideration. For a given spectral efficiency $R$ and fixed transceiver power\nconsumption parameters, we propose and analyze the problem of maximizing the\nenergy efficiency as a function of $(M,K)$. For the maximum ratio combining\n(MRC) detector at the BS we show that with increasing $R$, $(M,K)$ can be\nadaptively increased in such a way that the energy efficiency converges to a\npositive constant as $R \\rightarrow \\infty$ ($(M,K)$ is increased in such a way\nthat a constant per-user spectral efficiency $R/K$ is maintained). This is in\ncontrast to the fixed $(M,K)$ scenario where the energy efficiency is known to\nconverge to zero as $R \\rightarrow \\infty$. We also observe that for large $R$,\nthe optimal $(M,K)$ maximizing the energy efficiency is such that, the total\npower consumed by the power amplifiers (PA) in all the $K$ UTs is a small\nfraction of the total system power consumption. \n\n"}
{"id": "1404.3458", "contents": "Title: Novel Polynomial Basis and Its Application to Reed-Solomon Erasure Codes Abstract: In this paper, we present a new basis of polynomial over finite fields of\ncharacteristic two and then apply it to the encoding/decoding of Reed-Solomon\nerasure codes. The proposed polynomial basis allows that $h$-point polynomial\nevaluation can be computed in $O(h\\log_2(h))$ finite field operations with\nsmall leading constant. As compared with the canonical polynomial basis, the\nproposed basis improves the arithmetic complexity of addition, multiplication,\nand the determination of polynomial degree from $O(h\\log_2(h)\\log_2\\log_2(h))$\nto $O(h\\log_2(h))$. Based on this basis, we then develop the encoding and\nerasure decoding algorithms for the $(n=2^r,k)$ Reed-Solomon codes. Thanks to\nthe efficiency of transform based on the polynomial basis, the encoding can be\ncompleted in $O(n\\log_2(k))$ finite field operations, and the erasure decoding\nin $O(n\\log_2(n))$ finite field operations. To the best of our knowledge, this\nis the first approach supporting Reed-Solomon erasure codes over\ncharacteristic-2 finite fields while achieving a complexity of $O(n\\log_2(n))$,\nin both additive and multiplicative complexities. As the complexity leading\nfactor is small, the algorithms are advantageous in practical applications. \n\n"}
{"id": "1404.4435", "contents": "Title: Low-power Distance Bounding Abstract: A distance bounding system guarantees an upper bound on the physical distance\nbetween a verifier and a prover. However, in contrast to a conventional\nwireless communication system, distance bounding systems introduce tight\nrequirements on the processing delay at the prover and require high distance\nmeasurement precision making their practical realization challenging. Prior\nproposals of distance bounding systems focused primarily on building provers\nwith minimal processing delays but did not consider the power limitations of\nprovers and verifiers. However, in a wide range of applications (e.g., physical\naccess control), provers are expected to be fully or semi-passive introducing\nadditional constraints on the design and implementation of distance bounding\nsystems.\n  In this work, we propose a new physical layer scheme for distance bounding\nand leverage this scheme to implement a distance bounding system with a\nlow-power prover. Our physical layer combines frequency modulated continuous\nwave (FMCW) and backscatter communication. The use of backscatter communication\nenables low power consumption at the prover which is critical for a number of\ndistance bounding applications. By using the FMCW-based physical layer, we\nfurther decouple the physical distance estimation from the processing delay at\nthe prover, thereby enabling the realization of the majority of distance\nbounding protocols developed in prior art. We evaluate our system under various\nattack scenarios and show that it offers strong security guarantees against\ndistance, mafia and terrorist frauds. Additionally, we validate the\ncommunication and distance measurement characteristics of our system through\nsimulations and experiments and show that it is well suited for short-range\nphysical access control and payment applications. \n\n"}
{"id": "1404.6441", "contents": "Title: A note on the minimum distance of quantum LDPC codes Abstract: We provide a new lower bound on the minimum distance of a family of quantum\nLDPC codes based on Cayley graphs proposed by MacKay, Mitchison and\nShokrollahi. Our bound is exponential, improving on the quadratic bound of\nCouvreur, Delfosse and Z\\'emor. This result is obtained by examining a family\nof subsets of the hypercube which locally satisfy some parity conditions. \n\n"}
{"id": "1404.6688", "contents": "Title: Network Control without CSI using Rateless Codes for Downlink Cellular\n  Systems Abstract: Wireless network scheduling and control techniques (e.g., opportunistic\nscheduling) rely heavily on access to Channel State Information (CSI). However,\nobtaining this information is costly in terms of bandwidth, time, and power,\nand could result in large overhead. Therefore, a critical question is how to\noptimally manage network resources in the absence of such information. To that\nend, we develop a cross-layer solution for downlink cellular systems with\nimperfect (and possibly no) CSI at the transmitter. We use rateless codes to\nresolve channel uncertainty. To keep the decoding complexity low, we explicitly\nincorporate time-average block-size constraints, and aim to maximize the system\nutility. The block-size of a rateless code is determined by both the network\ncontrol decisions and the unknown CSI of many time slots. Therefore, unlike\nstandard utility maximization problems, this problem can be viewed as a\nconstrained partial observed Markov decision problem (CPOMDP), which is known\nto be hard due to the \"curse of dimensionality.\" However, by using a modified\nLyapunov drift method, we develop a dynamic network control scheme, which\nyields a total network utility within O(1/Lav) of utility-optimal point\nachieved by infinite block-size channel codes, where Lav is the enforced value\nof the time-average block-size of rateless codes. This opens the door of being\nable to trade complexity/delay for performance gains in the absence of accurate\nCSI. Our simulation results show that the proposed scheme improves the network\nthroughput by up to 68% over schemes that use fixed-rate codes. \n\n"}
{"id": "1404.6690", "contents": "Title: The Effect of Maximal Rate Codes on the Interfering Message Rate Abstract: The effect of \"good\", point-to-point capacity achieving, code sequences on an\nadditional signal, of bounded variance, transmitted over the additive Gaussian\nnoise channel is examined. For such code sequences, it is shown that their\neffect, in terms of mutual information, on the additional bounded variance\nsignal, is as if additional additive Gaussian noise has been transmitted.\nMoreover, the analysis shows that for reliable communication the bounded\nvariance signal must be completely estimated by the receiver (i.e., the minimum\nmean-square error tends to zero). This result resolves the \"Costa Conjecture\"\nregarding the corner points of the two-user Gaussian interference channel for\ncode sequences of bounded variance, and shows that both messages must be\nreliably decoded. \n\n"}
{"id": "1404.6851", "contents": "Title: Weight enumerator of some irreducible cyclic codes Abstract: In this article, we show explicitly all possible weight enumerators for every\nirreducible cyclic code of length $n$ over a finite field $\\mathbb F_q$, in the\ncase which each prime divisor of $n$ is also a divisor of $q-1$. \n\n"}
{"id": "1405.0032", "contents": "Title: Distributed Space-Time Interference Alignment with Moderately-Delayed\n  CSIT Abstract: This paper proposes an interference alignment method with distributed and\ndelayed channel state information at the transmitter (CSIT) for a class of\ninterference networks. The core idea of the proposed method is to align\ninterference signals over time at the unintended receivers in a distributed\nmanner. With the proposed method, achievable trade-offs between the sum of\ndegrees of freedom (sum-DoF) and feedback delay of CSI are characterized in\nboth the X-channel and three-user interference channel to reveal the impact on\nhow the CSI feedback delay affects the sum-DoF of the interference networks. A\nmajor implication of derived results is that distributed and moderately-\ndelayed CSIT is useful to strictly improve the sum-DoF over the case of no CSI\nat the transmitter in a certain class of interference networks. For a class of\nX-channels, the results show how to optimally use distributed and\nmoderately-delayed CSIT to yield the same sum-DoF as instantaneous and global\nCSIT. Further, leveraging the proposed transmission method and the known outer\nbound results, the sum-capacity of the two-user X-channel with a particular set\nof channel coefficients is characterized within a constant number of bits. \n\n"}
{"id": "1405.1008", "contents": "Title: Realistic and Efficient Channel Modeling for Vehicular Networks Abstract: To date, VANET research efforts have relied heavily on simulations, due to\nprohibitive costs of deploying real world testbeds. Existing channel models\nimplemented in discrete-event VANET simulators are by and large simple\nstochastic radio models, based on the statistical properties of the chosen\nenvironment. It was shown that such models are unable to provide satisfactory\naccuracy for typical VANET scenarios.\n  We performed extensive measurements in different environments (open space,\nhighway, suburban, urban, parking lot) to characterize in detail the impact\nthat vehicles have on communication in terms of received power, packet delivery\nrate, and effective communication range. Since the impact of vehicles was found\nto be significant, we developed a model that accounts for vehicles as\nthree-dimensional obstacles and takes into account their impact on the line of\nsight obstruction, received signal power, packet reception rate, and message\nreachability. The model is based on the empirically derived vehicle dimensions,\naccurate vehicle positioning, and realistic mobility patterns. We validate the\nmodel against extensive measurements. To enable realistic modeling in urban and\nsuburban environments, we developed a model that incorporates static objects as\nwell. The model requires minimum geographic information: the location and the\ndimensions of modeled objects (vehicles, buildings, and foliage). We validate\nthe model against measurements and show that it successfully captures both\nsmall-scale and large-scale propagation effects in different environments\n(highway, urban, suburban, open space). \n\n"}
{"id": "1405.2113", "contents": "Title: Empirical Bayes and Full Bayes for Signal Estimation Abstract: We consider signals that follow a parametric distribution where the parameter\nvalues are unknown. To estimate such signals from noisy measurements in scalar\nchannels, we study the empirical performance of an empirical Bayes (EB)\napproach and a full Bayes (FB) approach. We then apply EB and FB to solve\ncompressed sensing (CS) signal estimation problems by successively denoising a\nscalar Gaussian channel within an approximate message passing (AMP) framework.\nOur numerical results show that FB achieves better performance than EB in\nscalar channel denoising problems when the signal dimension is small. In the CS\nsetting, the signal dimension must be large enough for AMP to work well; for\nlarge signal dimensions, AMP has similar performance with FB and EB. \n\n"}
{"id": "1405.2786", "contents": "Title: Distributed Compressive CSIT Estimation and Feedback for FDD Multi-user\n  Massive MIMO Systems Abstract: To fully utilize the spatial multiplexing gains or array gains of massive\nMIMO, the channel state information must be obtained at the transmitter side\n(CSIT). However, conventional CSIT estimation approaches are not suitable for\nFDD massive MIMO systems because of the overwhelming training and feedback\noverhead. In this paper, we consider multi-user massive MIMO systems and deploy\nthe compressive sensing (CS) technique to reduce the training as well as the\nfeedback overhead in the CSIT estimation. The multi-user massive MIMO systems\nexhibits a hidden joint sparsity structure in the user channel matrices due to\nthe shared local scatterers in the physical propagation environment. As such,\ninstead of naively applying the conventional CS to the CSIT estimation, we\npropose a distributed compressive CSIT estimation scheme so that the compressed\nmeasurements are observed at the users locally, while the CSIT recovery is\nperformed at the base station jointly. A joint orthogonal matching pursuit\nrecovery algorithm is proposed to perform the CSIT recovery, with the\ncapability of exploiting the hidden joint sparsity in the user channel\nmatrices. We analyze the obtained CSIT quality in terms of the normalized mean\nabsolute error, and through the closed-form expressions, we obtain simple\ninsights into how the joint channel sparsity can be exploited to improve the\nCSIT recovery performance. \n\n"}
{"id": "1405.2957", "contents": "Title: What Will 5G Be? Abstract: What will 5G be? What it will not be is an incremental advance on 4G. The\nprevious four generations of cellular technology have each been a major\nparadigm shift that has broken backwards compatibility. And indeed, 5G will\nneed to be a paradigm shift that includes very high carrier frequencies with\nmassive bandwidths, extreme base station and device densities and unprecedented\nnumbers of antennas. But unlike the previous four generations, it will also be\nhighly integrative: tying any new 5G air interface and spectrum together with\nLTE and WiFi to provide universal high-rate coverage and a seamless user\nexperience. To support this, the core network will also have to reach\nunprecedented levels of flexibility and intelligence, spectrum regulation will\nneed to be rethought and improved, and energy and cost efficiencies will become\neven more critical considerations. This paper discusses all of these topics,\nidentifying key challenges for future research and preliminary 5G\nstandardization activities, while providing a comprehensive overview of the\ncurrent literature, and in particular of the papers appearing in this special\nissue. \n\n"}
{"id": "1405.3182", "contents": "Title: Scalable Coordinated Beamforming for Dense Wireless Cooperative Networks Abstract: To meet the ever growing demand for both high throughput and uniform coverage\nin future wireless networks, dense network deployment will be ubiquitous, for\nwhich co- operation among the access points is critical. Considering the\ncomputational complexity of designing coordinated beamformers for dense\nnetworks, low-complexity and suboptimal precoding strategies are often adopted.\nHowever, it is not clear how much performance loss will be caused. To enable\noptimal coordinated beamforming, in this paper, we propose a framework to\ndesign a scalable beamforming algorithm based on the alternative direction\nmethod of multipliers (ADMM) method. Specifically, we first propose to apply\nthe matrix stuffing technique to transform the original optimization problem to\nan equivalent ADMM-compliant problem, which is much more efficient than the\nwidely-used modeling framework CVX. We will then propose to use the ADMM\nalgorithm, a.k.a. the operator splitting method, to solve the transformed\nADMM-compliant problem efficiently. In particular, the subproblems of the ADMM\nalgorithm at each iteration can be solved with closed-forms and in parallel.\nSimulation results show that the proposed techniques can result in significant\ncomputational efficiency compared to the state- of-the-art interior-point\nsolvers. Furthermore, the simulation results demonstrate that the optimal\ncoordinated beamforming can significantly improve the system performance\ncompared to sub-optimal zero forcing beamforming. \n\n"}
{"id": "1405.4375", "contents": "Title: Algebraic Codes and a New Physical Layer Transmission Protocol for\n  Wireless Distributed Storage Systems Abstract: In a wireless storage system, having to communicate over a fading channel\nmakes repair transmissions prone to physical layer errors. The first approach\nto combat fading is to utilize the existing optimal space-time codes. However,\nit was recently pointed out that such codes are in general too complex to\ndecode when the number of helper nodes is bigger than the number of antennas at\nthe newcomer or data collector. In this paper, a novel protocol for wireless\nstorage transmissions based on algebraic space-time codes is presented in order\nto improve the system reliability while enabling feasible decoding. The\ndiversity-multiplexing gain tradeoff (DMT) of the system together with\nsphere-decodability even with low number of antennas are used as the main\ndesign criteria, thus naturally establishing a DMT-complexity tradeoff. It is\nshown that the proposed protocol outperforms the simple time-division multiple\naccess (TDMA) protocol, while still falling behind the optimal DMT. \n\n"}
{"id": "1405.4522", "contents": "Title: Secure Transmission in Amplify and Forward Networks for Multiple\n  Degraded Eavesdroppers Abstract: We have evaluated the optimal secrecy rate for Amplify-and-Forward (AF) relay\nnetworks with multiple eavesdroppers. Assuming i.i.d. Gaussian noise at the\ndestination and the eavesdroppers, we have devised technique to calculate\noptimal scaling factor for relay nodes to obtain optimal secrecy rate under\nboth sum power constraint and individual power constraint. Initially, we have\nconsidered special channel conditions for both destination and eavesdroppers,\nwhich led us to analytical solution of the problem. Contrarily, the general\nscenario being a non-convex optimization problem, not only lacks an analytical\nsolution, but also is hard to solve. Therefore, we have proposed an efficiently\nsolvable quadratic program (QP) which provides a sub-optimal solution to the\noriginal problem. Then, we have devised an iterative scheme for calculating\noptimal scaling factor efficiently for both the sum power and individual power\nconstraint scenario. Necessary figures are provided in result section to affirm\nthe validity of our proposed solution. \n\n"}
{"id": "1405.4807", "contents": "Title: Scalable Semidefinite Relaxation for Maximum A Posterior Estimation Abstract: Maximum a posteriori (MAP) inference over discrete Markov random fields is a\nfundamental task spanning a wide spectrum of real-world applications, which is\nknown to be NP-hard for general graphs. In this paper, we propose a novel\nsemidefinite relaxation formulation (referred to as SDR) to estimate the MAP\nassignment. Algorithmically, we develop an accelerated variant of the\nalternating direction method of multipliers (referred to as SDPAD-LR) that can\neffectively exploit the special structure of the new relaxation. Encouragingly,\nthe proposed procedure allows solving SDR for large-scale problems, e.g.,\nproblems on a grid graph comprising hundreds of thousands of variables with\nmultiple states per node. Compared with prior SDP solvers, SDPAD-LR is capable\nof attaining comparable accuracy while exhibiting remarkably improved\nscalability, in contrast to the commonly held belief that semidefinite\nrelaxation can only been applied on small-scale MRF problems. We have evaluated\nthe performance of SDR on various benchmark datasets including OPENGM2 and PIC\nin terms of both the quality of the solutions and computation time.\nExperimental results demonstrate that for a broad class of problems, SDPAD-LR\noutperforms state-of-the-art algorithms in producing better MAP assignment in\nan efficient manner. \n\n"}
{"id": "1405.5193", "contents": "Title: Towards $k$-connectivity of the random graph induced by a pairwise key\n  predistribution scheme with unreliable links Abstract: We study the secure and reliable connectivity of wireless sensor networks.\nSecurity is assumed to be ensured by the random pairwise key predistribution\nscheme of Chan, Perrig, and Song, and unreliable wireless links are represented\nby independent on/off channels. Modeling the network by an intersection of a\nrandom $K$-out graph and an Erd\\H{o}s-R\\'enyi graph, we present scaling\nconditions (on the number of nodes, the scheme parameter $K$, and the\nprobability of a wireless channel being on) such that the resulting graph\ncontains no nodes with degree less than $k$ with high probability, when the\nnumber of nodes gets large. Results are given in the form of zero-one laws and\nare shown to improve the previous results by Ya\\u{g}an and Makowski on the\nabsence of isolated nodes (i.e., absence of nodes with degree zero). Via\nsimulations, the established zero-one laws are shown to hold also for the\nproperty of $k$-connectivity; i.e., the property that graph remains connected\ndespite the deletion of any $k-1$ nodes or edges. \n\n"}
{"id": "1405.7161", "contents": "Title: Secure Transmission in Multi-Cell Massive MIMO Systems Abstract: In this paper, we consider physical layer security provisioning in multi-cell\nmassive multiple-input multiple-output (MIMO) systems. Specifically, we\nconsider secure downlink transmission in a multi-cell massive MIMO system with\nmatched-filter precoding and artificial noise (AN) generation at the base\nstation (BS) in the presence of a passive multi-antenna eavesdropper. We\ninvestigate the resulting achievable ergodic secrecy rate and the secrecy\noutage probability for the cases of perfect training and pilot contamination.\nThereby, we consider two different AN shaping matrices, namely, the\nconventional AN shaping matrix, where the AN is transmitted in the null space\nof the matrix formed by all user channels, and a random AN shaping matrix,\nwhich avoids the complexity associated with finding the null space of a large\nmatrix. Our analytical and numerical results reveal that in multi-cell massive\nMIMO systems employing matched-filter precoding (1) AN generation is required\nto achieve a positive ergodic secrecy rate if the user and the eavesdropper\nexperience the same path-loss, (2) even with AN generation secure transmission\nmay not be possible if the number of eavesdropper antennas is too large and not\nenough power is allocated to channel estimation, (3) for a given fraction of\npower allocated to AN and a given number of users, in case of pilot\ncontamination, the ergodic secrecy rate is not a monotonically increasing\nfunction of the number of BS antennas, and (4) random AN shaping matrices\nprovide a favourable performance/complexity tradeoff and are an attractive\nalternative to conventional AN shaping matrices. \n\n"}
{"id": "1406.0267", "contents": "Title: Joint density of eigenvalues in spiked multivariate models Abstract: The classical methods of multivariate analysis are based on the eigenvalues\nof one or two sample covariance matrices. In many applications of these\nmethods, for example to high dimensional data, it is natural to consider\nalternative hypotheses which are a low rank departure from the null hypothesis.\nFor rank one alternatives, this note provides a representation for the joint\neigenvalue density in terms of a single contour integral. This will be of use\nfor deriving approximate distributions for likelihood ratios and linear\nstatistics used in testing. \n\n"}
{"id": "1406.0767", "contents": "Title: A generalization of Witsenhausen's zero-error rate for directed graphs Abstract: We investigate a communication setup where a source output is sent through a\nfree noisy channel first and an additional codeword is sent through a noiseless\nbut expensive channel later. With the help of the second message the decoder\nshould be able to decide with zero-error whether its decoding of the first\nmessage was error-free. This scenario leads to the definition of a digraph\nparameter that generalizes Witsenhausen's zero-error rate for directed graphs.\nWe investigate this new parameter for some specific directed graphs and explore\nits relations to other digraph parameters like Sperner capacity and dichromatic\nnumber.\n  When the original problem is modified to require zero-error decoding of the\nwhole message then we arrive back to the Witsenhausen rate of an appropriately\ndefined undirected graph. \n\n"}
{"id": "1406.1569", "contents": "Title: Two-Part Reconstruction with Noisy-Sudocodes Abstract: We develop a two-part reconstruction framework for signal recovery in\ncompressed sensing (CS), where a fast algorithm is applied to provide partial\nrecovery in Part 1, and a CS algorithm is applied to complete the residual\nproblem in Part 2. Partitioning the reconstruction process into two\ncomplementary parts provides a natural trade-off between runtime and\nreconstruction quality. To exploit the advantages of the two-part framework, we\npropose a Noisy-Sudocodes algorithm that performs two-part reconstruction of\nsparse signals in the presence of measurement noise. Specifically, we design a\nfast algorithm for Part 1 of Noisy-Sudocodes that identifies the zero\ncoefficients of the input signal from its noisy measurements. Many existing CS\nalgorithms could be applied to Part 2, and we investigate approximate message\npassing (AMP) and binary iterative hard thresholding (BIHT). For\nNoisy-Sudocodes with AMP in Part 2, we provide a theoretical analysis that\ncharacterizes the trade-off between runtime and reconstruction quality. In a\n1-bit CS setting where a new 1-bit quantizer is constructed for Part 1 and BIHT\nis applied to Part 2, numerical results show that the Noisy-Sudocodes algorithm\nimproves over BIHT in both runtime and reconstruction quality. \n\n"}
{"id": "1406.4600", "contents": "Title: Gr\\\"obner Bases for Linearized Polynomials Abstract: In this work we develop the theory of Gr\\\"obner bases for modules over the\nring of univariate linearized polynomials with coefficients from a finite\nfield. \n\n"}
{"id": "1406.4736", "contents": "Title: Seek and Decode: Random Access with Physical-Layer Network Coding and\n  Multiuser Detection Abstract: We present a novel cross layer approach to random access (RA) that combines\nphysical-layer network coding (PLNC) with multiuser detection (MUD). PLNC and\nMUD are applied jointly at the physical level in order to extract any linear\ncombination of messages experiencing a collision. The set of combinations\nextracted from a whole frame is then processed by the receiver to recover the\noriginal packets. A simple pre-coding stage at the transmitting terminals\nallows the receiver to further increase system diversity. We derive an\nanalytical bound on the system throughput and present simulation results for\nthe decoding at the physical level as well as several performance measures at\nframe level in block fading channels, namely throughput, packet loss rate and\nenergy efficiency. The results we present are promising and suggest that a\ncross layer approach leveraging on the joint use of PLNC and MUD can\nsignificantly improve the performance of RA systems. \n\n"}
{"id": "1406.4852", "contents": "Title: Outer bounds for exact repair codes Abstract: We address the open problem of establishing the rate region for exact-repair\nregenerating codes for given parameters (n,k,d). Tian determined the rate\nregion for a (4,3,3) code and found that it lies strictly within the\nfunctional-repair rate region. Using different methods, Sasidharan, Senthoor\nand Kumar proved a non-vanishing gap between the functional-repair outer bound\nand the exact-repair outer bound for codes with k>=3. Our main results are two\nimproved outer bounds for exact-repair regenerating codes. They capture and\nthen extend essential parts in the proofs by Tian and by Sasidharan, Senthoor\nand Kumar. We show that the bounds can be combined for further improvements. \n\n"}
{"id": "1406.6959", "contents": "Title: Maximum Likelihood Estimation of Functionals of Discrete Distributions Abstract: We consider the problem of estimating functionals of discrete distributions,\nand focus on tight nonasymptotic analysis of the worst case squared error risk\nof widely used estimators. We apply concentration inequalities to analyze the\nrandom fluctuation of these estimators around their expectations, and the\ntheory of approximation using positive linear operators to analyze the\ndeviation of their expectations from the true functional, namely their\n\\emph{bias}.\n  We characterize the worst case squared error risk incurred by the Maximum\nLikelihood Estimator (MLE) in estimating the Shannon entropy $H(P) = \\sum_{i =\n1}^S -p_i \\ln p_i$, and $F_\\alpha(P) = \\sum_{i = 1}^S p_i^\\alpha,\\alpha>0$, up\nto multiplicative constants, for any alphabet size $S\\leq \\infty$ and sample\nsize $n$ for which the risk may vanish. As a corollary, for Shannon entropy\nestimation, we show that it is necessary and sufficient to have $n \\gg S$\nobservations for the MLE to be consistent. In addition, we establish that it is\nnecessary and sufficient to consider $n \\gg S^{1/\\alpha}$ samples for the MLE\nto consistently estimate $F_\\alpha(P), 0<\\alpha<1$. The minimax rate-optimal\nestimators for both problems require $S/\\ln S$ and $S^{1/\\alpha}/\\ln S$\nsamples, which implies that the MLE has a strictly sub-optimal sample\ncomplexity. When $1<\\alpha<3/2$, we show that the worst-case squared error rate\nof convergence for the MLE is $n^{-2(\\alpha-1)}$ for infinite alphabet size,\nwhile the minimax squared error rate is $(n\\ln n)^{-2(\\alpha-1)}$. When\n$\\alpha\\geq 3/2$, the MLE achieves the minimax optimal rate $n^{-1}$ regardless\nof the alphabet size.\n  As an application of the general theory, we analyze the Dirichlet prior\nsmoothing techniques for Shannon entropy estimation. We show that no matter how\nwe tune the parameters in the Dirichlet prior, this technique cannot achieve\nthe minimax rates in entropy estimation. \n\n"}
{"id": "1406.7435", "contents": "Title: Compression in the Space of Permutations Abstract: We investigate lossy compression (source coding) of data in the form of\npermutations. This problem has direct applications in the storage of ordinal\ndata or rankings, and in the analysis of sorting algorithms. We analyze the\nrate-distortion characteristic for the permutation space under the uniform\ndistribution, and the minimum achievable rate of compression that allows a\nbounded distortion after recovery. Our analysis is with respect to different\npractical and useful distortion measures, including Kendall-tau distance,\nSpearman's footrule, Chebyshev distance and inversion-$\\ell_1$ distance. We\nestablish equivalence of source code designs under certain distortions and show\nsimple explicit code designs that incur low encoding/decoding complexities and\nare asymptotically optimal. Finally, we show that for the Mallows model, a\npopular nonuniform ranking model on the permutation space, both the entropy and\nthe maximum distortion at zero rate are much lower than the uniform\ncounterparts, which motivates the future design of efficient compression\nschemes for this model. \n\n"}
{"id": "1407.0536", "contents": "Title: Analysis of the Decoupled Access for Downlink and Uplink in Wireless\n  Heterogeneous Networks Abstract: Wireless cellular networks evolve towards a heterogeneous infrastructure,\nfeaturing multiple types of Base Stations (BSs), such as Femto BSs (FBSs) and\nMacro BSs (MBSs). A wireless device observes multiple points (BSs) through\nwhich it can access the infrastructure and it may choose to receive the\ndownlink (DL) traffic from one BS and send uplink (UL) traffic through another\nBS. Such a situation is referred to as decoupled DL/UL access. Using the\nframework of stochastic geometry, we derive the association probability for\nDL/UL. In order to maximize the average received power, as the relative density\nof FBSs initially increases, a large fraction of devices chooses decoupled\naccess, i.e. receive from a MBS in DL and transmit through a FBS in UL. We\nanalyze the impact that this type of association has on the average throughput\nin the system. \n\n"}
{"id": "1407.1497", "contents": "Title: Content-Aware Network Coding over Device-to-Device Networks Abstract: Consider a scenario of broadcasting a common content to a group of\ncooperating mobile devices that are within proximity of each other. Devices in\nthis group may receive partial content from the source due to packet losses\nover wireless broadcast links. We further consider that packet losses are\ndifferent for different devices. The remaining missing content at each device\ncan then be recovered, thanks to cooperation among the devices by exploiting\ndevice-to-device (D2D) connections. In this context, the minimum amount of time\nthat can guarantee a complete acquisition of the common content at every device\nis referred to as the \"completion time\". It has been shown that instantly\ndecodable network coding (IDNC) reduces the completion time as compared to no\nnetwork coding in this scenario. Yet, for applications such as video streaming,\nnot all packets have the same importance and not all devices are interested in\nthe same quality of content. This problem is even more interesting when\nadditional, but realistic constraints, such as strict deadline, bandwidth, or\nlimited energy are added in the problem formulation. We assert that direct\napplication of IDNC in such a scenario yields poor performance in terms of\ncontent quality and completion time. In this paper, we propose a novel Content\nand Loss-Aware IDNC scheme that improves content quality and network coding\nopportunities jointly by taking into account importance of each packet towards\nthe desired quality of service (QoS) as well as the channel losses over D2D\nlinks. Our proposed Content and Loss-Aware IDNC (i) maximizes the quality under\nthe completion time constraint, and (ii) minimizes the completion time under\nthe quality constraint. We demonstrate the benefits of Content and Loss-Aware\nIDNC through simulations. \n\n"}
{"id": "1407.1508", "contents": "Title: Performance Analysis of Network-Assisted Two-Hop D2D Communications Abstract: Network-assisted single-hop device-to-device (D2D) communication can increase\nthe spectral and energy efficiency of cellular networks by taking advantage of\nthe proximity, reuse, and hop gains when radio resources are properly managed\nbetween the cellular and D2D layers. In this paper we argue that D2D technology\ncan be used to further increase the spectral and energy efficiency if the key\nD2D radio resource management algorithms are suitably extended to support\nnetwork assisted multi-hop D2D communications. Specifically, we propose a\nnovel, distributed utility maximizing D2D power control (PC) scheme that is\nable to balance spectral and energy efficiency while taking into account mode\nselection and resource allocation constraints that are important in the\nintegrated cellular-D2D environment. Our analysis and numerical results\nindicate that multi-hop D2D communications combined with the proposed PC scheme\ncan be useful not only for harvesting the potential gains previously identified\nin the literature, but also for extending the coverage of cellular networks. \n\n"}
{"id": "1407.1931", "contents": "Title: Deterministic Near-Optimal P2P Streaming Abstract: We consider streaming over a peer-to-peer network with homogeneous nodes in\nwhich a single source broadcasts a data stream to all the users in the system.\nPeers are allowed to enter or leave the system (adversarially) arbitrarily.\nPrevious approaches for streaming in this setting have either used randomized\ndistribution graphs or structured trees with randomized maintenance algorithms.\nRandomized graphs handle peer churn well but have poor connectivity guarantees,\nwhile structured trees have good connectivity but have proven hard to maintain\nunder peer churn. We improve upon both approaches by presenting a novel\ndistribution structure with a deterministic and distributed algorithm for\nmaintenance under peer churn; our result is inspired by a recent work proposing\ndeterministic algorithms for rumor spreading in graphs. A key innovation in our\napproach is in having redundant links in the distribution structure. While this\nleads to a reduction in the maximum streaming rate possible, we show that for\nthe amount of redundancy used, the delay guarantee of the proposed algorithm is\nnear optimal. We introduce a tolerance parameter that captures the worst-case\ntransient streaming rate received by the peers during churn events and\ncharacterize the fundamental tradeoff between rate, delay and tolerance. A\nnatural generalization of the deterministic algorithm achieves this tradeoff\nnear optimally. Finally, the proposed deterministic algorithm is robust enough\nto handle various generalizations: ability to deal with heterogeneous node\ncapacities of the peers and more complicated streaming patterns where multiple\nsource transmissions are present. \n\n"}
{"id": "1407.3962", "contents": "Title: Rank weight hierarchy of some classes of cyclic codes Abstract: We study the rank weight hierarchy, thus in particular the rank metric, of\ncyclic codes over the finite field $\\mathbb F_{q^m}$, $q$ a prime power, $m\n\\geq 2$. We establish the rank weight hierarchy for $[n,n-1]$ cyclic codes and\ncharacterize $[n,k]$ cyclic codes of rank metric 1 when (1) $k=1$, (2) $n$ and\n$q$ are coprime, and (3) the characteristic $char(\\mathbb F_q)$ divides $n$.\nFinally, for $n$ and $q$ coprime, cyclic codes of minimal $r$-rank are\ncharacterized, and a refinement of the Singleton bound for the rank weight is\nderived. \n\n"}
{"id": "1407.6560", "contents": "Title: Combining subspace codes with classical linear error-correcting codes Abstract: We discuss how subspace codes can be used to simultaneously correct errors\nand erasures when the network performs random linear network coding and the\nedges are noisy channels. This is done by combining the subspace code with a\nclassical linear error-correcting code. The classical code then takes care of\nthe errors and the subspace codes takes care of the erasures. \n\n"}
{"id": "1407.6692", "contents": "Title: 2-Server PIR with sub-polynomial communication Abstract: A 2-server Private Information Retrieval (PIR) scheme allows a user to\nretrieve the $i$th bit of an $n$-bit database replicated among two servers\n(which do not communicate) while not revealing any information about $i$ to\neither server. In this work we construct a 1-round 2-server PIR with total\ncommunication cost $n^{O({\\sqrt{\\log\\log n/\\log n}})}$. This improves over the\ncurrently known 2-server protocols which require $O(n^{1/3})$ communication and\nmatches the communication cost of known 3-server PIR schemes. Our improvement\ncomes from reducing the number of servers in existing protocols, based on\nMatching Vector Codes, from 3 or 4 servers to 2. This is achieved by viewing\nthese protocols in an algebraic way (using polynomial interpolation) and\nextending them using partial derivatives. \n\n"}
{"id": "1407.7103", "contents": "Title: On Joint Source-Channel Coding for Correlated Sources Over\n  Multiple-Access Relay Channels Abstract: We study the transmission of correlated sources over discrete memoryless (DM)\nmultiple-access-relay channels (MARCs), in which both the relay and the\ndestination have access to side information arbitrarily correlated with the\nsources. As the optimal transmission scheme is an open problem, in this work we\npropose a new joint source-channel coding scheme based on a novel combination\nof the correlation preserving mapping (CPM) technique with Slepian-Wolf (SW)\nsource coding, and obtain the corresponding sufficient conditions. The proposed\ncoding scheme is based on the decode-and-forward strategy, and utilizes CPM for\nencoding information simultaneously to the relay and the destination, whereas\nthe cooperation information from the relay is encoded via SW source coding. It\nis shown that there are cases in which the new scheme strictly outperforms the\nschemes available in the literature. This is the first instance of a\nsource-channel code that uses CPM for encoding information to two different\nnodes (relay and destination). In addition to sufficient conditions, we present\nthree different sets of single-letter necessary conditions for reliable\ntransmission of correlated sources over DM MARCs. The newly derived conditions\nare shown to be at least as tight as the previously known necessary conditions. \n\n"}
{"id": "1407.7267", "contents": "Title: On Spectrum Sharing Between Energy Harvesting Cognitive Radio Users and\n  Primary Users Abstract: This paper investigates the maximum secondary throughput for a rechargeable\nsecondary user (SU) sharing the spectrum with a primary user (PU) plugged to a\nreliable power supply. The SU maintains a finite energy queue and harvests\nenergy from natural resources and primary radio frequency (RF) transmissions.\nWe propose a power allocation policy at the PU and analyze its effect on the\nthroughput of both the PU and SU. Furthermore, we study the impact of the\nbursty arrivals at the PU on the energy harvested by the SU from RF\ntransmissions. Moreover, we investigate the impact of the rate of energy\nharvesting from natural resources on the SU throughput. We assume fading\nchannels and compute exact closed-form expressions for the energy harvested by\nthe SU under fading. Results reveal that the proposed power allocation policy\nalong with the implemented RF energy harvesting at the SU enhance the\nthroughput of both primary and secondary links. \n\n"}
{"id": "1408.2242", "contents": "Title: Off-the-Grid Line Spectrum Denoising and Estimation with Multiple\n  Measurement Vectors Abstract: Compressed Sensing suggests that the required number of samples for\nreconstructing a signal can be greatly reduced if it is sparse in a known\ndiscrete basis, yet many real-world signals are sparse in a continuous\ndictionary. One example is the spectrally-sparse signal, which is composed of a\nsmall number of spectral atoms with arbitrary frequencies on the unit interval.\nIn this paper we study the problem of line spectrum denoising and estimation\nwith an ensemble of spectrally-sparse signals composed of the same set of\ncontinuous-valued frequencies from their partial and noisy observations. Two\napproaches are developed based on atomic norm minimization and structured\ncovariance estimation, both of which can be solved efficiently via semidefinite\nprogramming. The first approach aims to estimate and denoise the set of signals\nfrom their partial and noisy observations via atomic norm minimization, and\nrecover the frequencies via examining the dual polynomial of the convex\nprogram. We characterize the optimality condition of the proposed algorithm and\nderive the expected convergence rate for denoising, demonstrating the benefit\nof including multiple measurement vectors. The second approach aims to recover\nthe population covariance matrix from the partially observed sample covariance\nmatrix by motivating its low-rank Toeplitz structure without recovering the\nsignal ensemble. Performance guarantee is derived with a finite number of\nmeasurement vectors. The frequencies can be recovered via conventional spectrum\nestimation methods such as MUSIC from the estimated covariance matrix. Finally,\nnumerical examples are provided to validate the favorable performance of the\nproposed algorithms, with comparisons against several existing approaches. \n\n"}
{"id": "1408.3661", "contents": "Title: Overhead Performance Tradeoffs - A Resource Allocation Perspective Abstract: A key aspect of many resource allocation problems is the need for the\nresource controller to compute a function, such as the max or arg max, of the\ncompeting users metrics. Information must be exchanged between the competing\nusers and the resource controller in order for this function to be computed. In\nmany practical resource controllers the competing users' metrics are\ncommunicated to the resource controller, which then computes the desired\nextremization function. However, in this paper it is shown that information\nrate savings can be obtained by recognizing that controller only needs to\ndetermine the result of this extremization function. If the extremization\nfunction is to be computed losslessly, the rate savings are shown in most cases\nto be at most 2 bits independent of the number of competing users. Motivated by\nthe small savings in the lossless case, simple achievable schemes for both the\nlossy and interactive variants of this problem are considered. It is shown that\nboth of these approaches have the potential to realize large rate savings,\nespecially in the case where the number of competing users is large. For the\nlossy variant, it is shown that the proposed simple achievable schemes are in\nfact close to the fundamental limit given by the rate distortion function. \n\n"}
{"id": "1408.3757", "contents": "Title: Tier Association Probability and Spectrum Partitioning for Maximum Rate\n  Coverage in Multi-tier Heterogeneous Networks Abstract: For a wireless multi-tier heterogeneous network with orthogonal spectrum\nallocation across tiers, we optimize the association probability and the\nfraction of spectrum allocated to each tier so as to maximize rate coverage. In\npractice, the association probability can be controlled using a biased received\nsignal power. The optimization problem is non-convex and we are forced to\nexplore locally optimal solutions. We make two contributions in this paper:\nfirst, we show that there exists a relation between the first derivatives of\nthe objective function with respect to each of the optimization variables. This\ncan be used to simplify numerical solutions to the optimization problem.\nSecond, we explore the optimality of the intuitive solution that the fraction\nof spectrum allocated to each tier should be equal to the tier association\nprobability. We show that, in this case, a closed-form solution exists.\nImportantly, our numerical results show that there is essentially zero\nperformance loss. The results also illustrate the significant gains possible by\njointly optimizing the user association and the resource allocation. \n\n"}
{"id": "1408.4238", "contents": "Title: Distributed User Scheduling for MIMO-Y Channel Abstract: In this paper, distributed user scheduling schemes are proposed for the\nmulti-user MIMO-Y channel, where three $N_{T}$-antenna users ($N_{T}=2N,\\,3N$)\nare selected from three clusters to exchange information via an $N_{R}$-antenna\namplify-and-forward (AF) relay ($N_{R}=3N$), and $N\\geq1$ represents the number\nof data stream(s) of each unicast transmission within the MIMO-Y channel. The\nproposed schemes effectively harvest multi-user diversity (MuD) without the\nneed of global channel state information (CSI) or centralized computations. In\nparticular, a novel reference signal space (RSS) is proposed to enable the\ndistributed scheduling for both cluster-wise (CS) and group-wise (GS) patterns.\nThe minimum user-antenna (Min-UA) transmission with $N_{T}=2N$ is first\nconsidered. Next, we consider an equal number of relay and user antenna (ER-UA)\ntransmission with ${N_{T}=3N}$, with the aim of reducing CSI overhead as\ncompared to Min-UA. For ER-UA transmission, the achievable MuD orders of the\nproposed distributed scheduling schemes are analytically derived, which proves\nthe superiority and optimality of the proposed RSS-based distributed\nscheduling. These results reveal some fundamental behaviors of MuD and the\nperformance-complexity tradeoff of user scheduling schemes in the MIMO-Y\nchannel. \n\n"}
{"id": "1408.5445", "contents": "Title: A Circulant Approach to Skew-Constacyclic Codes Abstract: We introduce circulant matrices that capture the structure of a\nskew-polynomial ring F[x;\\theta] modulo the left ideal generated by a\npolynomial of the type x^n-a. This allows us to develop an approach to\nskew-constacyclic codes based on such circulants. Properties of these\ncirculants are derived, and in particular it is shown that the transpose of a\ncertain circulant is a circulant again. This recovers the well-known result\nthat the dual of a skew-constacyclic code is a constacyclic code again. Special\nattention is paid to the case where x^n-a is two-sided. \n\n"}
{"id": "1408.5945", "contents": "Title: A Lightweight Identification Protocol for Embedded Devices Abstract: The task of this paper is to introduce a new lightweight identification\nprotocol based on biometric data and elliptic curves. In fact, we combine\nbiometric data and asymetric cryptography, namely elliptic curves and standard\ntools to design a multifactor identification protocol. Our scheme is light,\nvery fast, secure and robust against all the known attacks on identification\nprotocol. Therefore, one can use it in any constraint device such as embedded\nsystems. \n\n"}
{"id": "1408.6876", "contents": "Title: Informational and Causal Architecture of Discrete-Time Renewal Processes Abstract: Renewal processes are broadly used to model stochastic behavior consisting of\nisolated events separated by periods of quiescence, whose durations are\nspecified by a given probability law. Here, we identify the minimal sufficient\nstatistic for their prediction (the set of causal states), calculate the\nhistorical memory capacity required to store those states (statistical\ncomplexity), delineate what information is predictable (excess entropy), and\ndecompose the entropy of a single measurement into that shared with the past,\nfuture, or both. The causal state equivalence relation defines a new subclass\nof renewal processes with a finite number of causal states despite having an\nunbounded interevent count distribution. We use these formulae to analyze the\noutput of the parametrized Simple Nonunifilar Source, generated by a simple\ntwo-state hidden Markov model, but with an infinite-state epsilon-machine\npresentation. All in all, the results lay the groundwork for analyzing\nprocesses with infinite statistical complexity and infinite excess entropy. \n\n"}
{"id": "1409.1434", "contents": "Title: Run Vector Analysis and Barker Sequences of Odd Length Abstract: The run vector of a binary sequence reflects the run structure of the\nsequence, which is given by the set of all substrings of the run length\nencoding. The run vector and the aperiodic autocorrelations of a binary\nsequence are strongly related. In this paper, we analyze the run vector of\nskew-symmetric binary sequences. Using the derived results we present a new and\ndifferent proof that there exists no Barker sequence of odd length n > 13.\nBarker sequences are binary sequences whose off-peak aperiodic autocorrelations\nare all in magnitude at most 1. \n\n"}
{"id": "1409.2792", "contents": "Title: The Interplay between Massive MIMO and Underlaid D2D Networking Abstract: In a device-to-device (D2D) underlaid cellular network, the uplink spectrum\nis reused by the D2D transmissions, causing mutual interference with the\nongoing cellular transmissions. Massive MIMO is appealing in such a context as\nthe base station's (BS's) large antenna array can nearly null the D2D-to-BS\ninterference. The multi-user transmission in massive MIMO, however, may lead to\nincreased cellular-to-D2D interference. This paper studies the interplay\nbetween massive MIMO and underlaid D2D networking in a multi-cell setting. We\ninvestigate cellular and D2D spectral efficiency under both perfect and\nimperfect channel state information (CSI) at the receivers that employ partial\nzero-forcing. Compared to the case without D2D, there is a loss in cellular\nspectral efficiency due to D2D underlay. With perfect CSI, the loss can be\ncompletely overcome if the number of canceled D2D interfering signals is scaled\nwith the number of BS antennas at an arbitrarily slow rate. With imperfect CSI,\nin addition to pilot contamination, a new asymptotic effect termed underlay\ncontamination arises. In the non-asymptotic regime, simple analytical lower\nbounds are derived for both the cellular and D2D spectral efficiency. \n\n"}
{"id": "1409.2835", "contents": "Title: Power Estimation in LTE systems with the General Framework of Standard\n  Interference Mappings Abstract: We devise novel techniques to obtain the downlink power inducing a given load\nin long-term evolution (LTE) systems, where we define load as the fraction of\nresource blocks in the time-frequency grid being requested by users from a\ngiven base station. These techniques are particularly important because\nprevious studies have proved that the data rate requirement of users can be\nsatisfied with lower transmit energy if we allow the load to increase. Those\nstudies have also shown that obtaining the power assignment from a desired load\nprofile can be posed as a fixed point problem involving standard interference\nmappings, but so far the mappings have not been obtained explicitly. One of our\nmain contributions in this study is to close this gap. We derive an\ninterference mapping having as its fixed point the power assignment inducing a\ndesired load, assuming that such an assignment exists. Having this mapping in\nclosed form, we simplify the proof of the aforementioned known results, and we\nalso devise novel iterative algorithms for power computation that have many\nnumerical advantages over previous methods. \n\n"}
{"id": "1409.3188", "contents": "Title: Counterexample to the $l$-modular Belfiore-Sol\\'e Conjecture Abstract: We show that the secrecy function conjecture that states that the maximum of\nthe secrecy function of an $l$-modular lattice occurs at $1/\\sqrt{l}$ is false,\nby proving that the 4-modular lattice $C^(4) = \\mathbb{Z} \\oplus\n\\sqrt{2}\\mathbb{Z} \\oplus 2\\mathbb{Z}$ fails to satisfy this conjecture. We\nalso indicate how the secrecy function must be modified in the $l$-modular case\nto have a more reasonable chance for it to have a maximum at $1/\\sqrt{l}$, and\nshow that the conjecture, modified with this new secrecy function, is true for\nvarious odd 2-modular lattices. \n\n"}
{"id": "1409.3426", "contents": "Title: No-Signalling Assisted Zero-Error Capacity of Quantum Channels and an\n  Information Theoretic Interpretation of the Lovasz Number Abstract: We study the one-shot zero-error classical capacity of a quantum channel\nassisted by quantum no-signalling correlations, and the reverse problem of\nexact simulation of a prescribed channel by a noiseless classical one. Quantum\nno-signalling correlations are viewed as two-input and two-output completely\npositive and trace preserving maps with linear constraints enforcing that the\ndevice cannot signal. Both problems lead to simple semidefinite programmes\n(SDPs) that depend only on the Kraus operator space of the channel. In\nparticular, we show that the zero-error classical simulation cost is precisely\nthe conditional min-entropy of the Choi-Jamiolkowski matrix of the given\nchannel. The zero-error classical capacity is given by a similar-looking but\ndifferent SDP; the asymptotic zero-error classical capacity is the\nregularization of this SDP, and in general we do not know of any simple form.\n  Interestingly however, for the class of classical-quantum channels, we show\nthat the asymptotic capacity is given by a much simpler SDP, which coincides\nwith a semidefinite generalization of the fractional packing number suggested\nearlier by Aram Harrow. This finally results in an operational interpretation\nof the celebrated Lovasz $\\vartheta$ function of a graph as the zero-error\nclassical capacity of the graph assisted by quantum no-signalling correlations,\nthe first information theoretic interpretation of the Lovasz number. \n\n"}
{"id": "1409.3525", "contents": "Title: Cryptographic security of quantum key distribution Abstract: This work is intended as an introduction to cryptographic security and a\nmotivation for the widely used Quantum Key Distribution (QKD) security\ndefinition. We review the notion of security necessary for a protocol to be\nusable in a larger cryptographic context, i.e., for it to remain secure when\ncomposed with other secure protocols. We then derive the corresponding security\ncriterion for QKD. We provide several examples of QKD composed in sequence and\nparallel with different cryptographic schemes to illustrate how the error of a\ncomposed protocol is the sum of the errors of the individual protocols. We also\ndiscuss the operational interpretations of the distance metric used to quantify\nthese errors. \n\n"}
{"id": "1409.6540", "contents": "Title: Compositional inverses, complete mappings, orthogonal Latin squares and\n  bent functions Abstract: We study compositional inverses of permutation polynomials, complete\nmappings, mutually orthogonal Latin squares, and bent vectorial functions.\nRecently it was obtained in [33] the compositional inverses of linearized\npermutation binomials over finite fields. It was also noted in [29] that\ncomputing inverses of bijections of subspaces have applications in determining\nthe compositional inverses of certain permutation classes related to linearized\npolynomials. In this paper we obtain compositional inverses of a class of\nlinearized binomials permuting the kernel of the trace map. As an application\nof this result, we give the compositional inverse of a class of complete\nmappings. This complete mapping class improves upon a recent construction given\nin [34]. We also construct recursively a class of complete mappings involving\nmulti-trace functions. Finally we use these complete mappings to derive a set\nof mutually orthogonal Latin squares, and to construct a class of $p$-ary bent\nvectorial functions from the Maiorana-McFarland class. \n\n"}
{"id": "1409.8460", "contents": "Title: Delay Reduction in Multi-Hop Device-to-Device Communication using\n  Network Coding Abstract: This paper considers the problem of reducing the broadcast decoding delay of\nwireless networks using instantly decodable network coding (IDNC) based\ndevice-to-device (D2D) communications. In a D2D configuration, devices in the\nnetwork can help hasten the recovery of the lost packets of other devices in\ntheir transmission range by sending network coded packets. Unlike previous\nworks that assumed fully connected network, this paper proposes a partially\nconnected configuration in which the decision should be made not only on the\npacket combinations but also on the set of transmitting devices. First, the\ndifferent events occurring at each device are identified so as to derive an\nexpression for the probability distribution of the decoding delay. The joint\noptimization problem over the set of transmitting devices and the packet\ncombinations of each is, then, formulated. The optimal solution of the joint\noptimization problem is derived using a graph theory approach by introducing\nthe cooperation graph and reformulating the problem as a maximum weight clique\nproblem in which the weight of each vertex is the contribution of the device\nidentified by the vertex. Through extensive simulations, the decoding delay\nexperienced by all devices in the Point to Multi-Point (PMP) configuration, the\nfully connected D2D (FC-D2D) configuration and the more practical partially\nconnected D2D (PC-D2D) configuration are compared. Numerical results suggest\nthat the PC-D2D outperforms the FC-D2D and provides appreciable gain especially\nfor poorly connected networks. \n\n"}
{"id": "1410.0952", "contents": "Title: Robust Binary Hypothesis Testing Under Contaminated Likelihoods Abstract: In hypothesis testing, the phenomenon of label noise, in which hypothesis\nlabels are switched at random, contaminates the likelihood functions. In this\npaper, we develop a new method to determine the decision rule when we do not\nhave knowledge of the uncontaminated likelihoods and contamination\nprobabilities, but only have knowledge of the contaminated likelihoods. In\nparticular we pose a minimax optimization problem that finds a decision rule\nrobust against this lack of knowledge. The method simplifies by application of\nlinear programming theory. Motivation for this investigation is provided by\nproblems encountered in workforce analytics. \n\n"}
{"id": "1410.1002", "contents": "Title: A Rate-Distortion Based Secrecy System with Side Information at the\n  Decoders Abstract: A secrecy system with side information at the decoders is studied in the\ncontext of lossy source compression over a noiseless broadcast channel. The\ndecoders have access to different side information sequences that are\ncorrelated with the source. The fidelity of the communication to the legitimate\nreceiver is measured by a distortion metric, as is traditionally done in the\nWyner-Ziv problem. The secrecy performance of the system is also evaluated\nunder a distortion metric. An achievable rate-distortion region is derived for\nthe general case of arbitrarily correlated side information. Exact bounds are\nobtained for several special cases in which the side information satisfies\ncertain constraints. An example is considered in which the side information\nsequences come from a binary erasure channel and a binary symmetric channel. \n\n"}
{"id": "1410.2090", "contents": "Title: Power-Constrained Sparse Gaussian Linear Dimensionality Reduction over\n  Noisy Channels Abstract: In this paper, we investigate power-constrained sensing matrix design in a\nsparse Gaussian linear dimensionality reduction framework. Our study is carried\nout in a single--terminal setup as well as in a multi--terminal setup\nconsisting of orthogonal or coherent multiple access channels (MAC). We adopt\nthe mean square error (MSE) performance criterion for sparse source\nreconstruction in a system where source-to-sensor channel(s) and\nsensor-to-decoder communication channel(s) are noisy. Our proposed sensing\nmatrix design procedure relies upon minimizing a lower-bound on the MSE in\nsingle-- and multiple--terminal setups. We propose a three-stage sensing matrix\noptimization scheme that combines semi-definite relaxation (SDR) programming, a\nlow-rank approximation problem and power-rescaling. Under certain conditions,\nwe derive closed-form solutions to the proposed optimization procedure. Through\nnumerical experiments, by applying practical sparse reconstruction algorithms,\nwe show the superiority of the proposed scheme by comparing it with other\nrelevant methods. This performance improvement is achieved at the price of\nhigher computational complexity. Hence, in order to address the complexity\nburden, we present an equivalent stochastic optimization method to the problem\nof interest that can be solved approximately, while still providing a superior\nperformance over the popular methods. \n\n"}
{"id": "1410.3656", "contents": "Title: Compute-and-Forward: Finding the Best Equation Abstract: Compute-and-Forward is an emerging technique to deal with interference. It\nallows the receiver to decode a suitably chosen integer linear combination of\nthe transmitted messages. The integer coefficients should be adapted to the\nchannel fading state. Optimizing these coefficients is a Shortest Lattice\nVector (SLV) problem. In general, the SLV problem is known to be prohibitively\ncomplex. In this paper, we show that the particular SLV instance resulting from\nthe Compute-and-Forward problem can be solved in low polynomial complexity and\ngive an explicit deterministic algorithm that is guaranteed to find the optimal\nsolution. \n\n"}
{"id": "1410.4319", "contents": "Title: Achieving High Resolution for Super-resolution via Reweighted Atomic\n  Norm Minimization Abstract: The super-resolution theory developed recently by Cand\\`{e}s and\nFernandes-Granda aims to recover fine details of a sparse frequency spectrum\nfrom coarse scale information only. The theory was then extended to the cases\nwith compressive samples and/or multiple measurement vectors. However, the\nexisting atomic norm (or total variation norm) techniques succeed only if the\nfrequencies are sufficiently separated, prohibiting commonly known high\nresolution. In this paper, a reweighted atomic-norm minimization (RAM) approach\nis proposed which iteratively carries out atomic norm minimization (ANM) with a\nsound reweighting strategy that enhances sparsity and resolution. It is\ndemonstrated analytically and via numerical simulations that the proposed\nmethod achieves high resolution with application to DOA estimation. \n\n"}
{"id": "1410.6289", "contents": "Title: Signal inference with unknown response: Calibration-uncertainty\n  renormalized estimator Abstract: The calibration of a measurement device is crucial for every scientific\nexperiment, where a signal has to be inferred from data. We present CURE, the\ncalibration uncertainty renormalized estimator, to reconstruct a signal and\nsimultaneously the instrument's calibration from the same data without knowing\nthe exact calibration, but its covariance structure. The idea of CURE,\ndeveloped in the framework of information field theory, is starting with an\nassumed calibration to successively include more and more portions of\ncalibration uncertainty into the signal inference equations and to absorb the\nresulting corrections into renormalized signal (and calibration) solutions.\nThereby, the signal inference and calibration problem turns into solving a\nsingle system of ordinary differential equations and can be identified with\ncommon resummation techniques used in field theories. We verify CURE by\napplying it to a simplistic toy example and compare it against existent\nself-calibration schemes, Wiener filter solutions, and Markov Chain Monte Carlo\nsampling. We conclude that the method is able to keep up in accuracy with the\nbest self-calibration methods and serves as a non-iterative alternative to it. \n\n"}
{"id": "1410.6457", "contents": "Title: A conditional construction of restricted isometries Abstract: We study the restricted isometry property of a matrix that is built from the\ndiscrete Fourier transform matrix by collecting rows indexed by quadratic\nresidues. We find an $\\epsilon>0$ such that, conditioned on a folklore\nconjecture in number theory, this matrix satisfies the restricted isometry\nproperty with sparsity parameter $K=\\Omega(M^{1/2+\\epsilon})$, where $M$ is the\nnumber of rows. \n\n"}
{"id": "1410.8837", "contents": "Title: Codes for DNA Storage Channels Abstract: We consider the problem of assembling a sequence based on a collection of its\nsubstrings observed through a noisy channel. The mathematical basis of the\nproblem is the construction and design of sequences that may be discriminated\nbased on a collection of their substrings observed through a noisy channel. We\nexplain the connection between the sequence reconstruction problem and the\nproblem of DNA synthesis and sequencing, and introduce the notion of a DNA\nstorage channel. We analyze the number of sequence equivalence classes under\nthe channel mapping and propose new asymmetric coding techniques to combat the\neffects of synthesis and sequencing noise. In our analysis, we make use of\nrestricted de Bruijn graphs and Ehrhart theory for rational polytopes. \n\n"}
{"id": "1411.0114", "contents": "Title: On the Transmit Beamforming for MIMO Wiretap Channels: Large-System\n  Analysis Abstract: With the growth of wireless networks, security has become a fundamental issue\nin wireless communications due to the broadcast nature of these networks. In\nthis work, we consider MIMO wiretap channels in a fast fading environment, for\nwhich the overall performance is characterized by the ergodic MIMO secrecy\nrate. Unfortunately, the direct solution to finding ergodic secrecy rates is\nprohibitive due to the expectations in the rates expressions in this setting.\nTo overcome this difficulty, we invoke the large-system assumption, which\nallows a deterministic approximation to the ergodic mutual information.\nLeveraging results from random matrix theory, we are able to characterize the\nachievable ergodic secrecy rates. Based on this characterization, we address\nthe problem of covariance optimization at the transmitter. Our numerical\nresults demonstrate a good match between the large-system approximation and the\nactual simulated secrecy rates, as well as some interesting features of the\nprecoder optimization. \n\n"}
{"id": "1411.2045", "contents": "Title: Multivariate f-Divergence Estimation With Confidence Abstract: The problem of f-divergence estimation is important in the fields of machine\nlearning, information theory, and statistics. While several nonparametric\ndivergence estimators exist, relatively few have known convergence properties.\nIn particular, even for those estimators whose MSE convergence rates are known,\nthe asymptotic distributions are unknown. We establish the asymptotic normality\nof a recently proposed ensemble estimator of f-divergence between two\ndistributions from a finite number of samples. This estimator has MSE\nconvergence rate of O(1/T), is simple to implement, and performs well in high\ndimensions. This theory enables us to perform divergence-based inference tasks\nsuch as testing equality of pairs of distributions based on empirical samples.\nWe experimentally validate our theoretical results and, as an illustration, use\nthem to empirically bound the best achievable classification error. \n\n"}
{"id": "1411.2417", "contents": "Title: Capacity Results for Multicasting Nested Message Sets over Combination\n  Networks Abstract: The problem of multicasting two nested messages is studied over a class of\nnetworks known as combination networks. A source multicasts two messages, a\ncommon and a private message, to several receivers. A subset of the receivers\n(called the public receivers) only demand the common message and the rest of\nthe receivers (called the private receivers) demand both the common and the\nprivate message. Three encoding schemes are discussed that employ linear\nsuperposition coding and their optimality is proved in special cases. The\nstandard linear superposition scheme is shown to be optimal for networks with\ntwo public receivers and any number of private receivers. When the number of\npublic receivers increases, this scheme stops being optimal. Two improvements\nare discussed: one using pre-encoding at the source, and one using a block\nMarkov encoding scheme. The rate-regions that are achieved by the two schemes\nare characterized in terms of feasibility problems. Both inner-bounds are shown\nto be the capacity region for networks with three (or fewer) public and any\nnumber of private receivers. Although the inner bounds are not comparable in\ngeneral, it is shown through an example that the region achieved by the block\nMarkov encoding scheme may strictly include the region achieved by the\npre-encoding/linear superposition scheme. Optimality results are founded on the\ngeneral framework of Balister and Bollob\\'as (2012) for sub-modularity of the\nentropy function. An equivalent graphical representation is introduced and a\nlemma is proved that might be of independent interest.\n  Motivated by the connections between combination networks and broadcast\nchannels, a new block Markov encoding scheme is proposed for broadcast channels\nwith two nested messages. The rate-region that is obtained includes the\npreviously known rate-regions. It remains open whether this inclusion is\nstrict. \n\n"}
{"id": "1411.2513", "contents": "Title: Constructions of Optimal and Near-Optimal Multiply Constant-Weight Codes Abstract: Multiply constant-weight codes (MCWCs) have been recently studied to improve\nthe reliability of certain physically unclonable function response. In this\npaper, we give combinatorial constructions for MCWCs which yield several new\ninfinite families of optimal MCWCs. Furthermore, we demonstrate that the\nJohnson type upper bounds of MCWCs are asymptotically tight for fixed weights\nand distances. Finally, we provide bounds and constructions of two dimensional\nMCWCs. \n\n"}
{"id": "1411.3545", "contents": "Title: Error-Correction Capability of Reed-Muller codes Abstract: We present an asymptotic limit between correctable and uncor-rectable errors\non the Reed-Muller codes of any order. This limit is theoretical and does not\ndepend of any decoding algorithm. \n\n"}
{"id": "1411.3643", "contents": "Title: Six Constructions of Difference Families Abstract: In this paper, six constructions of difference families are presented. These\nconstructions make use of difference sets, almost difference sets and disjoint\ndifference families, and give new point of views of relationships among these\ncombinatorial objects. Most of the constructions work for all finite groups.\nThough these constructions look simple, they produce many difference families\nwith new parameters. In addition to the six new constructions, new results\nabout intersection numbers are also derived. \n\n"}
{"id": "1411.4226", "contents": "Title: Roy's largest root under rank-one alternatives:The complex valued case\n  and applications Abstract: The largest eigenvalue of a Wishart matrix, known as Roy's largest root\n(RLR), plays an important role in a variety of applications. Most works to date\nderived approximations to its distribution under various asymptotic regimes,\nsuch as degrees of freedom, dimension, or both tending to infinity. However,\nseveral applications involve finite and relative small parameters, for which\nthe above approximations may be inaccurate. Recently, via a small noise\nperturbation approach with fixed dimension and degrees of freedom, Johnstone\nand Nadler derived simple yet accurate stochastic approximations to the\ndistribution of Roy's largest root in the real valued case, under a rank-one\nalternative. In this paper, we extend their results to the complex valued case.\nFurthermore, we analyze the behavior of the leading eigenvector by developing\nnew stochastic approximations. Specifically, we derive simple stochastic\napproximations to the distribution of the largest eigenvalue under five common\ncomplex single-matrix and double-matrix scenarios. We then apply these results\nto investigate several problems in signal detection and communications. In\nparticular, we analyze the performance of RLR detector in cognitive radio\nspectrum sensing and constant modulus signal detection in the high\nsignal-to-noise ratio (SNR) regime. Moreover, we address the problem of\ndetermining the optimal transmit-receive antenna configuration (here optimality\nis in the sense of outage minimization) for rank-one multiple-input\nmultiple-output Rician Fading channels at high SNR. \n\n"}
{"id": "1411.4253", "contents": "Title: Energy-efficient Decoders for Compressive Sensing: Fundamental Limits\n  and Implementations Abstract: The fundamental problem considered in this paper is \"What is the\n\\textit{energy} consumed for the implementation of a \\emph{compressive sensing}\ndecoding algorithm on a circuit?\". Using the \"information-friction\" framework,\nwe examine the smallest amount of \\textit{bit-meters} as a measure for the\nenergy consumed by a circuit. We derive a fundamental lower bound for the\nimplementation of compressive sensing decoding algorithms on a circuit. In the\nsetting where the number of measurements scales linearly with the sparsity and\nthe sparsity is sub-linear with the length of the signal, we show that the\n\\textit{bit-meters} consumption for these algorithms is order-tight, i.e., it\nmatches the lower bound asymptotically up to a constant factor. Our\nimplementations yield interesting insights into design of energy-efficient\ncircuits that are not captured by the notion of computational efficiency alone. \n\n"}
{"id": "1411.4373", "contents": "Title: Design of Spatially Coupled LDPC Codes over GF(q) for Windowed Decoding Abstract: In this paper we consider the generalization of binary spatially coupled\nlow-density parity-check (SC-LDPC) codes to finite fields GF$(q)$, $q\\geq 2$,\nand develop design rules for $q$-ary SC-LDPC code ensembles based on their\niterative belief propagation (BP) decoding thresholds, with particular emphasis\non low-latency windowed decoding (WD). We consider transmission over both the\nbinary erasure channel (BEC) and the binary-input additive white Gaussian noise\nchannel (BIAWGNC) and present results for a variety of $(J,K)$-regular SC-LDPC\ncode ensembles constructed over GF$(q)$ using protographs. Thresholds are\ncalculated using protograph versions of $q$-ary density evolution (for the BEC)\nand $q$-ary extrinsic information transfer analysis (for the BIAWGNC). We show\nthat WD of $q$-ary SC-LDPC codes provides significant threshold gains compared\nto corresponding (uncoupled) $q$-ary LDPC block code (LDPC-BC) ensembles when\nthe window size $W$ is large enough and that these gains increase as the finite\nfield size $q=2^m$ increases. Moreover, we demonstrate that the new design\nrules provide WD thresholds that are close to capacity, even when both $m$ and\n$W$ are relatively small (thereby reducing decoding complexity and latency).\nThe analysis further shows that, compared to standard flooding-schedule\ndecoding, WD of $q$-ary SC-LDPC code ensembles results in significant\nreductions in both decoding complexity and decoding latency, and that these\nreductions increase as $m$ increases. For applications with a near-threshold\nperformance requirement and a constraint on decoding latency, we show that\nusing $q$-ary SC-LDPC code ensembles, with moderate $q>2$, instead of their\nbinary counterparts results in reduced decoding complexity. \n\n"}
{"id": "1411.4591", "contents": "Title: Number field lattices achieve Gaussian and Rayleigh channel capacity\n  within a constant gap Abstract: This paper proves that a family of number field lattice codes simultaneously\nachieves a constant gap to capacity in Rayleigh fast fading and Gaussian\nchannels.\n  The key property in the proof is the existence of infinite towers of Hilbert\nclass fields with bounded root discriminant. The gap to capacity of the\nproposed families is determined by the root discriminant.\n  The comparison between the Gaussian and fading case reveals that in Rayleigh\nfading channels the normalized minimum product distance plays an analogous role\nto the Hermite invariant in Gaussian channels. \n\n"}
{"id": "1411.5323", "contents": "Title: Genetic Algorithms in Wireless Networking: Techniques, Applications, and\n  Issues Abstract: In recent times, wireless access technology is becoming increasingly\ncommonplace due to the ease of operation and installation of untethered\nwireless media. The design of wireless networking is challenging due to the\nhighly dynamic environmental condition that makes parameter optimization a\ncomplex task. Due to the dynamic, and often unknown, operating conditions,\nmodern wireless networking standards increasingly rely on machine learning and\nartificial intelligence algorithms. Genetic algorithms (GAs) provide a\nwell-established framework for implementing artificial intelligence tasks such\nas classification, learning, and optimization. GAs are well-known for their\nremarkable generality and versatility, and have been applied in a wide variety\nof settings in wireless networks. In this paper, we provide a comprehensive\nsurvey of the applications of GAs in wireless networks. We provide both an\nexposition of common GA models and configuration and provide a broad ranging\nsurvey of GA techniques in wireless networks. We also point out open research\nissues and define potential future work. While various surveys on GAs exist in\nliterature, our paper is the first paper, to the best of our knowledge, which\nfocuses on their application in wireless networks. \n\n"}
{"id": "1411.5782", "contents": "Title: New Bounds For Frameproof Codes Abstract: Frameproof codes are used to fingerprint digital data. It can prevent\ncopyrighted materials from unauthorized use. In this paper, we study upper and\nlower bounds for $w$-frameproof codes of length $N$ over an alphabet of size\n$q$. The upper bound is based on a combinatorial approach and the lower bound\nis based on a probabilistic construction. Both bounds can improve previous\nresults when $q$ is small compared to $w$, say $cq\\leq w$ for some constant\n$c\\leq q$. Furthermore, we pay special attention to binary frameproof codes. We\nshow a binary $w$-frameproof code of length $N$ can not have more than $N$\ncodewords if $N<\\binom{w+1}{2}$. \n\n"}
{"id": "1411.6359", "contents": "Title: Packet-Level Network Compression: Realization and Scaling of the\n  Network-Wide Benefits Abstract: The existence of considerable amount of redundancy in the Internet traffic at\nthe packet level has stimulated the deployment of packet-level redundancy\nelimination techniques within the network by enabling network nodes to memorize\ndata packets. Redundancy elimination results in traffic reduction which in turn\nimproves the efficiency of network links. In this paper, the concept of network\ncompression is introduced that aspires to exploit the statistical correlation\nbeyond removing large duplicate strings from the flow to better suppress\nredundancy.\n  In the first part of the paper, we introduce \"memory-assisted compression\",\nwhich utilizes the memorized content within the network to learn the statistics\nof the information source generating the packets which can then be used toward\nreducing the length of codewords describing the packets emitted by the source.\nUsing simulations on data gathered from real network traces, we show that\nmemory-assisted compression can result in significant traffic reduction.\n  In the second part of the paper, we study the scaling of the average\nnetwork-wide benefits of memory-assisted compression. We discuss routing and\nmemory placement problems in network for the reduction of overall traffic. We\nderive a closed-form expression for the scaling of the gain in Erdos-Renyi\nrandom network graphs, where obtain a threshold value for the number of\nmemories deployed in a random graph beyond which network-wide benefits start to\nshine. Finally, the network-wide benefits are studied on Internet-like\nscale-free networks. We show that non-vanishing network compression gain is\nobtained even when only a tiny fraction of the total number of nodes in the\nnetwork are memory-enabled. \n\n"}
{"id": "1412.0616", "contents": "Title: Logical Entropy for Quantum States Abstract: The novel concept of quantum logical entropy is presented and analyzed. We\nprove several basic properties of this entropy with regard to density matrices.\nWe hereby motivate a different approach for the assignment of quantum entropy\nto density matrices. \n\n"}
{"id": "1412.1257", "contents": "Title: Fast-Decodable Space-Time Codes for the $N$-Relay and Multiple-Access\n  MIMO Channel Abstract: In this article, the first general constructions of fast-decodable, more\nspecifically (conditionally) $g$-group decodable, space-time block codes for\nthe Nonorthogonal Amplify and Forward (NAF) Multiple-Input Multiple-Output\n(MIMO) relay channel under the half-duplex constraint are proposed. In this\nscenario, the source and the intermediate relays used for data amplification\nare allowed to employ multiple antennas for data transmission and reception.\nThe worst-case decoding complexity of the obtained codes is reduced by up to\n$75%$. In addition to being fast-decodable, the proposed codes achieve\nfull-diversity and have nonvanishing determinants, which has been shown to be\nuseful for achieving the optimal Diversity-Multiplexing Tradeoff (DMT) of the\nNAF channel.\n  Further, it is shown that the same techniques as in the cooperative scenario\ncan be utilized to achieve fast-decodability for $K$-user MIMO Multiple-Access\nChannel (MAC) space-time block codes. The resulting codes in addition exhibit\nthe conditional nonvanishing determinant property which, for its part, has been\nshown to be useful for achieving the optimal MAC-DMT. \n\n"}
{"id": "1412.1340", "contents": "Title: On spin scale-discretised wavelets on the sphere for the analysis of CMB\n  polarisation Abstract: A new spin wavelet transform on the sphere is proposed to analyse the\npolarisation of the cosmic microwave background (CMB), a spin $\\pm 2$ signal\nobserved on the celestial sphere. The scalar directional scale-discretised\nwavelet transform on the sphere is extended to analyse signals of arbitrary\nspin. The resulting spin scale-discretised wavelet transform probes the\ndirectional intensity of spin signals. A procedure is presented using this new\nspin wavelet transform to recover E- and B-mode signals from partial-sky\nobservations of CMB polarisation. \n\n"}
{"id": "1412.1565", "contents": "Title: Recovery Analysis for Weighted $\\ell_1$-Minimization Using a Null Space\n  Property Abstract: We study the recovery of sparse signals from underdetermined linear\nmeasurements when a potentially erroneous support estimate is available. Our\nresults are twofold. First, we derive necessary and sufficient conditions for\nsignal recovery from compressively sampled measurements using weighted\n$\\ell_1$-norm minimization. These conditions, which depend on the choice of\nweights as well as the size and accuracy of the support estimate, are on the\nnull space of the measurement matrix. They can guarantee recovery even when\nstandard $\\ell_1$ minimization fails. Second, we derive bounds on the number of\nGaussian measurements for these conditions to be satisfied, i.e., for weighted\n$\\ell_1$ minimization to successfully recover all sparse signals whose support\nhas been estimated sufficiently accurately. Our bounds show that weighted\n$\\ell_1$ minimization requires significantly fewer measurements than standard\n$\\ell_1$ minimization when the support estimate is relatively accurate. \n\n"}
{"id": "1412.4130", "contents": "Title: Energy Consumption of VLSI Decoders Abstract: Thompson's model of VLSI computation relates the energy of a computation to\nthe product of the circuit area and the number of clock cycles needed to carry\nout the computation. It is shown that for any family of circuits implemented\naccording to this model, using any algorithm that performs decoding of a\ncodeword passed through a binary erasure channel, as the block length\napproaches infinity either (a) the probability of block error is asymptotically\nlower bounded by 1/2 or (b) the energy of the computation scales at least as\nOmega(n(log n)^(1/2)), and so the energy of successful decoding, per decoded\nbit, must scale at least as Omega((log n)^(1/2)). This implies that the average\nenergy per decoded bit must approach infinity for any sequence of codes that\napproaches capacity. The analysis techniques used are then extended to the case\nof serial computation, showing that if a circuit is restricted to serial\ncomputation, then as block length approaches infinity, either the block error\nprobability is lower bounded by 1/2 or the energy scales at least as fast as\nOmega(n log(n)). In a very general case that allows for the number of output\npins to vary with block length, it is shown that the average energy per decoded\nbit must scale as Omega(n(log n)^(1/5)). A simple example is provided of a\nclass of circuits performing low-density parity-check decoding whose energy\ncomplexity scales as O(n^2 log log n). \n\n"}
{"id": "1412.6946", "contents": "Title: Probability Estimates for Fading and Wiretap Channels from Ideal Class\n  Zeta Functions Abstract: In this paper, new probability estimates are derived for ideal lattice codes\nfrom totally real number fields using ideal class Dedekind zeta functions. In\ncontrast to previous work on the subject, it is not assumed that the ideal in\nquestion is principal. In particular, it is shown that the corresponding\ninverse norm sum depends not only on the regulator and discriminant of the\nnumber field, but also on the values of the ideal class Dedekind zeta\nfunctions. Along the way, we derive an estimate of the number of elements in a\ngiven ideal with a certain algebraic norm within a finite hypercube. We provide\nseveral examples which measure the accuracy and predictive ability of our\ntheorems. \n\n"}
{"id": "1412.6946", "contents": "Title: Probability Estimates for Fading and Wiretap Channels from Ideal Class\n  Zeta Functions Abstract: In this paper, new probability estimates are derived for ideal lattice codes\nfrom totally real number fields using ideal class Dedekind zeta functions. In\ncontrast to previous work on the subject, it is not assumed that the ideal in\nquestion is principal. In particular, it is shown that the corresponding\ninverse norm sum depends not only on the regulator and discriminant of the\nnumber field, but also on the values of the ideal class Dedekind zeta\nfunctions. Along the way, we derive an estimate of the number of elements in a\ngiven ideal with a certain algebraic norm within a finite hypercube. We provide\nseveral examples which measure the accuracy and predictive ability of our\ntheorems. \n\n"}
{"id": "1412.7188", "contents": "Title: Layered Interference Alignment: Achieving the Total DoF of MIMO X\n  Channels Abstract: The $K\\times 2$ and $2\\times K$, Multiple-Input Multiple-Output (MIMO) X\nchannel with constant channel coefficients available at all transmitters and\nreceivers is considered. A new alignment scheme, named \\emph{layered\ninterference alignment}, is proposed in which both vector and real interference\nalignment are exploited, in conjunction with joint processing at receiver\nsides. Data streams with fractional multiplexing gains are sent in the desired\ndirections to align the interfering signals at receivers. To decode the\nintended messages at receivers, a joint processing/simultaneous decoding\ntechnique, which exploits the availability of several receive antennas, is\nproposed. This analysis is subsequently backed up by metrical results for\nsystems of linear forms. In particular, for such linear forms,\nKhintchine--Groshev type theorems are proved over real and complex numbers. It\nis observed that $K\\times 2$ and $2\\times K$, X channels with $M$ antennas at\nall transmitters/receivers enjoy duality in Degrees of Freedom (DoF). It is\nshown that incorporating the layered interference alignment is essential to\ncharacterize the total DoF of $\\frac{2KM}{K+1}$ in the $K\\times 2$ and $2\\times\nK$, $M$ antenna X channels. \n\n"}
{"id": "1412.7650", "contents": "Title: Division algebra codes achieve MIMO block fading channel capacity within\n  a constant gap Abstract: This work addresses the question of achieving capacity with lattice codes in\nmulti-antenna block fading channels when the number of fading blocks tends to\ninfinity. In contrast to the standard approach in the literature which employs\nrandom lattice ensembles, the existence results in this paper are derived from\nnumber theory. It is shown that a multiblock construction based on division\nalgebras achieves rates within a constant gap from block fading capacity both\nunder maximum likelihood decoding and naive lattice decoding. First the gap to\ncapacity is shown to depend on the discriminant of the chosen division algebra;\nthen class field theory is applied to build families of algebras with small\ndiscriminants. The key element in the construction is the choice of a sequence\nof division algebras whose centers are number fields with small root\ndiscriminants. \n\n"}
{"id": "1501.00163", "contents": "Title: Error Correction in Polynomial Remainder Codes with Non-Pairwise Coprime\n  Moduli and Robust Chinese Remainder Theorem for Polynomials Abstract: This paper investigates polynomial remainder codes with non-pairwise coprime\nmoduli. We first consider a robust reconstruction problem for polynomials from\nerroneous residues when the degrees of all residue errors are assumed small,\nnamely robust Chinese Remainder Theorem (CRT) for polynomials. It basically\nsays that a polynomial can be reconstructed from erroneous residues such that\nthe degree of the reconstruction error is upper bounded by $\\tau$ whenever the\ndegrees of all residue errors are upper bounded by $\\tau$, where a sufficient\ncondition for $\\tau$ and a reconstruction algorithm are obtained. By releasing\nthe constraint that all residue errors have small degrees, another robust\nreconstruction is then presented when there are multiple unrestricted errors\nand an arbitrary number of errors with small degrees in the residues. By making\nfull use of redundancy in moduli, we obtain a stronger residue error correction\ncapability in the sense that apart from the number of errors that can be\ncorrected in the previous existing result, some errors with small degrees can\nbe also corrected in the residues. With this newly obtained result,\nimprovements in uncorrected error probability and burst error correction\ncapability in a data transmission are illustrated. \n\n"}
{"id": "1501.00602", "contents": "Title: An analogue of Vosper's Theorem for Extension Fields Abstract: We are interested in characterising pairs $S,T$ of $F$-linear subspaces in a\nfield extension $L/F$ such that the linear span $ST$ of the set of products of\nelements of $S$ and of elements of $T$ has small dimension. Our central result\nis a linear analogue of Vosper's Theorem, which gives the structure of vector\nspaces $S, T$ in a prime extension $L$ of a finite field $F$ for which\n$\\dim_FST =\\dim_F S+\\dim_F T-1,$ when $\\dim_F S, \\dim_F T\\ge 2$ and $\\dim_F\nST\\le [L:F]-2$. \n\n"}
{"id": "1501.01360", "contents": "Title: On double cyclic codes over Z_4 Abstract: Let $R=\\mathbb{Z}_4$ be the integer ring mod $4$. A double cyclic code of\nlength $(r,s)$ over $R$ is a set that can be partitioned into two parts that\nany cyclic shift of the coordinates of both parts leaves invariant the code.\nThese codes can be viewed as $R[x]$-submodules of $R[x]/(x^r-1)\\times\nR[x]/(x^s-1)$. In this paper, we determine the generator polynomials of this\nfamily of codes as $R[x]$-submodules of $R[x]/(x^r-1)\\times R[x]/(x^s-1)$.\nFurther, we also give the minimal generating sets of this family of codes as\n$R$-submodules of $R[x]/(x^r-1)\\times R[x]/(x^s-1)$. Some optimal or suboptimal\nnonlinear binary codes are obtained from this family of codes. Finally, we\ndetermine the relationship of generators between the double cyclic code and its\ndual. \n\n"}
{"id": "1501.01773", "contents": "Title: Estimates for the growth of inverse determinant sums of quasi-orthogonal\n  and number field lattices Abstract: Inverse determinant sums appear naturally as a tool for analyzing performance\nof space-time codes in Rayleigh fading channels. This work will analyze the\ngrowth of inverse determinant sums of a family of quasi-orthogonal codes and\nwill show that the growths are in logarithmic class. This is considerably lower\nthan that of comparable number field codes. \n\n"}
{"id": "1501.02419", "contents": "Title: Delay Minimizing User Association in Cellular Networks via\n  Hierarchically Well-Separated Trees Abstract: We study downlink delay minimization within the context of cellular user\nassociation policies that map mobile users to base stations. We note the delay\nminimum user association problem fits within a broader class of network utility\nmaximization and can be posed as a non-convex quadratic program. This\nnon-convexity motivates a split quadratic objective function that captures the\noriginal problem's inherent tradeoff: association with a station that provides\nthe highest signal-to-interference-plus-noise ratio (SINR) vs. a station that\nis least congested. We find the split-term formulation is amenable to\nlinearization by embedding the base stations in a hierarchically well-separated\ntree (HST), which offers a linear approximation with constant distortion. We\nprovide a numerical comparison of several problem formulations and find that\nwith appropriate optimization parameter selection, the quadratic reformulation\nproduces association policies with sum delays that are close to that of the\noriginal network utility maximization. We also comment on the more difficult\nproblem when idle base stations (those without associated users) are\ndeactivated. \n\n"}
{"id": "1501.05757", "contents": "Title: On the Geometric Ergodicity of Metropolis-Hastings Algorithms for\n  Lattice Gaussian Sampling Abstract: Sampling from the lattice Gaussian distribution is emerging as an important\nproblem in coding and cryptography. In this paper, the classic\nMetropolis-Hastings (MH) algorithm from Markov chain Monte Carlo (MCMC) methods\nis adapted for lattice Gaussian sampling. Two MH-based algorithms are proposed,\nwhich overcome the restriction suffered by the default Klein's algorithm. The\nfirst one, referred to as the independent Metropolis-Hastings-Klein (MHK)\nalgorithm, tries to establish a Markov chain through an independent proposal\ndistribution. We show that the Markov chain arising from the independent MHK\nalgorithm is uniformly ergodic, namely, it converges to the stationary\ndistribution exponentially fast regardless of the initial state. Moreover, the\nrate of convergence is explicitly calculated in terms of the theta series,\nleading to a predictable mixing time. In order to further exploit the\nconvergence potential, a symmetric Metropolis-Klein (SMK) algorithm is\nproposed. It is proven that the Markov chain induced by the SMK algorithm is\ngeometrically ergodic, where a reasonable selection of the initial state is\ncapable to enhance the convergence performance. \n\n"}
{"id": "1501.06683", "contents": "Title: Codes With Hierarchical Locality Abstract: In this paper, we study the notion of {\\em codes with hierarchical locality}\nthat is identified as another approach to local recovery from multiple\nerasures. The well-known class of {\\em codes with locality} is said to possess\nhierarchical locality with a single level. In a {\\em code with two-level\nhierarchical locality}, every symbol is protected by an inner-most local code,\nand another middle-level code of larger dimension containing the local code. We\nfirst consider codes with two levels of hierarchical locality, derive an upper\nbound on the minimum distance, and provide optimal code constructions of low\nfield-size under certain parameter sets. Subsequently, we generalize both the\nbound and the constructions to hierarchical locality of arbitrary levels. \n\n"}
{"id": "1501.06698", "contents": "Title: On Error Correction for Physical Unclonable Functions Abstract: Physical Unclonable Functions evaluate manufacturing variations to generate\nsecure cryptographic keys for embedded systems without secure key storage. It\nis explained how methods from coding theory are applied in order to ensure\nreliable key reproduction. We show how better results can be obtained using\ncode classes and decoding principles not used for this scenario before. These\nmethods are exemplified by specific code constructions which improve existing\ncodes with respect to error probability, decoding complexity and codeword\nlength. \n\n"}
{"id": "1501.07072", "contents": "Title: On the stability of asynchronous Random Access Schemes Abstract: Slotted Aloha-based Random Access (RA) techniques have recently regained\nattention in light of the use of Interference Cancellation (IC) as a mean to\nexploit diversity created through the transmission of multiple burst copies per\npacket content (CRDSA). Subsequently, the same concept has been extended to\npure ALOHA-based techniques in order to boost the performance also in case of\nasynchronous RA schemes. In this paper, throughput as well as packet delay and\nrelated stability for asynchronous ALOHA techniques under geometrically\ndistributed retransmissions are analyzed both in case of finite and infinite\npopulation size. Moreover, a comparison between pure ALOHA, its evolution\n(known as CRA) and CRDSA techniques is presented, in order to give a measure of\nthe achievable gain that can be reached in a closed-loop scenario with respect\nto the previous state of the art. \n\n"}
{"id": "1501.07439", "contents": "Title: The Arbitrarily Varying Wiretap Channel - Secret Randomness, Stability\n  and Super-Activation Abstract: We define the common randomness assisted capacity of an arbitrarily varying\nchannel (AVWC) when the Eavesdropper is kept ignorant about the common\nrandomness. We prove a multi-letter capacity formula for this model. We prove\nthat, if enough common randomness is used, the capacity formula can be given a\nsingle-shot form again. We then consider the opposite extremal case, where no\ncommon randomness is available. It is known that the capacity of the system can\nbe discontinuous under these circumstances. We prove here that it is still\nstable in the sense that it is continuous around its positivity points. We\nfurther prove that discontinuities can only arise if the legal link is\nsymmetrizable and characterize the points where it is positive. These results\nshed new light on the design principles of communication systems with embedded\nsecurity features. At last we investigate the effect of super-activation of the\nmessage transmission capacity of AVWCs under the average error criterion. We\ngive a complete characterization of those AVWCs that may be super-activated.\nThe effect is thereby also related to the (conjectured) super-activation of the\ncommon randomness assisted capacity of AVWCs with an eavesdropper that gets to\nknow the common randomness. Super-activation is based on the idea of \"wasting\"\na few bits of non-secret messages in order to enable provably secret\ntransmission of a large bulk of data, a concept that may prove to be of further\nimportance in the design of communication systems. In this work we provide\nfurther insight into this phenomenon by providing a class of codes that is\ncapacity-achieving and does not convey any information to the Eavesdropper. \n\n"}
{"id": "1501.07440", "contents": "Title: Limits on Support Recovery with Probabilistic Models: An\n  Information-Theoretic Framework Abstract: The support recovery problem consists of determining a sparse subset of a set\nof variables that is relevant in generating a set of observations, and arises\nin a diverse range of settings such as compressive sensing, and subset\nselection in regression, and group testing. In this paper, we take a unified\napproach to support recovery problems, considering general probabilistic models\nrelating a sparse data vector to an observation vector. We study the\ninformation-theoretic limits of both exact and partial support recovery, taking\na novel approach motivated by thresholding techniques in channel coding. We\nprovide general achievability and converse bounds characterizing the trade-off\nbetween the error probability and number of measurements, and we specialize\nthese to the linear, 1-bit, and group testing models. In several cases, our\nbounds not only provide matching scaling laws in the necessary and sufficient\nnumber of measurements, but also sharp thresholds with matching constant\nfactors. Our approach has several advantages over previous approaches: For the\nachievability part, we obtain sharp thresholds under broader scalings of the\nsparsity level and other parameters (e.g., signal-to-noise ratio) compared to\nseveral previous works, and for the converse part, we not only provide\nconditions under which the error probability fails to vanish, but also\nconditions under which it tends to one. \n\n"}
{"id": "1502.00033", "contents": "Title: Analyzing Interference from Static Cellular Cooperation using the\n  Nearest Neighbour Model Abstract: The problem of base station cooperation has recently been set within the\nframework of Stochastic Geometry. Existing works consider that a user\ndynamically chooses the set of stations that cooperate for his/her service.\nHowever, this assumption often does not hold. Cooperation groups could be\npredefined and static, with nodes connected by fixed infrastructure. To analyse\nsuch a potential network, in this work we propose a grouping method based on\nproximity. It is a variation of the so called Nearest Neighbour Model. We\nrestrict ourselves to the simplest case where only singles and pairs of base\nstations are allowed to be formed. For this, two new point processes are\ndefined from the dependent thinning of a Poisson Point Process, one for the\nsingles and one for the pairs. Structural characteristics for the two are\nprovided, including their density, Voronoi surface, nearest neighbour, empty\nspace and J-function. We further make use of these results to analyse their\ninterference fields and give explicit formulas to their expected value and\ntheir Laplace transform. The results constitute a novel toolbox towards the\nperformance evaluation of networks with static cooperation. \n\n"}
{"id": "1502.00389", "contents": "Title: Privacy-preserving Network Functionality Outsourcing Abstract: Since the advent of software defined networks ({SDN}), there have been many\nattempts to outsource the complex and costly local network functionality, i.e.\nthe middlebox, to the cloud in the same way as outsourcing computation and\nstorage. The privacy issues, however, may thwart the enterprises' willingness\nto adopt this innovation since the underlying configurations of these\nmiddleboxes may leak crucial and confidential information which can be utilized\nby attackers. To address this new problem, we use firewall as an sample\nfunctionality and propose the first privacy preserving outsourcing framework\nand schemes in SDN. The basic technique that we exploit is a ground-breaking\ntool in cryptography, the \\textit{cryptographic multilinear map}. In contrast\nto the infeasibility in efficiency if a naive approach is adopted, we devise\npractical schemes that can outsource the middlebox as a blackbox after\n\\textit{obfuscating} it such that the cloud provider can efficiently perform\nthe same functionality without knowing its underlying private configurations.\nBoth theoretical analysis and experiments on real-world firewall rules\ndemonstrate that our schemes are secure, accurate, and practical. \n\n"}
{"id": "1502.02539", "contents": "Title: Random variate generation using only finitely many unbiased,\n  independently and identically distributed random bits Abstract: For any discrete probability distributions with bounded entropy, we can\ngenerate exactly a random variate using only a finite expected number of\nperfect coin flips. A perfect coin flip is the outcome of an unbiased Bernoulli\nrandom variable. Coin flips are unbiased, independently and identically\ndistributed in all our work. We survey well-known algorithms for the discrete\ncase such as the one from Knuth and Yao as well as the one from Han and Hoshi.\nWe also discuss briefly about a practical implementation for the algorithm\nproposed by Knuth and Yao. For the continuous case, only approximations can be\nhoped for. The freedom to choose the accuracy for the approximations matters,\nand, for that, we propose to measure accuracy in terms of the Wasserstein\n$L_\\infty$-metric. We derive a universal lower bound for the expected number of\nperfect coin flips required to reach a desired accuracy. We also provide\nseveral algorithms for absolutely continuous distributions that come within our\nuniversal lower bound. \n\n"}
{"id": "1502.02927", "contents": "Title: On the shape of the general error locator polynomial for cyclic codes Abstract: A general result on the explicit form of the general error locator polynomial\nfor all cyclic codes is given, along with several results for infinite classes\nof cyclic codes with $t=2$ and $t=3$. From these, a theoretically justification\nof the sparsity of the general error locator polynomial is obtained for all\ncyclic codes with $t\\leq 3$ and $n<63$, except for three cases where the\nsparsity is proved by a computer check. Moreover, we discuss some consequences\nof our results to the understanding of the complexity of bounded-distance\ndecoding of cyclic codes. \n\n"}
{"id": "1502.03068", "contents": "Title: Multi-Sensor Scheduling for State Estimation with Event-Based,\n  Stochastic Triggers Abstract: In networked systems, state estimation is hampered by communication limits.\nPast approaches, which consider scheduling sensors through deterministic\nevent-triggers, reduce communication and maintain estimation quality. However,\nthese approaches destroy the Gaussian property of the state, making it\ncomputationally intractable to obtain an exact minimum mean squared error\nestimate. We propose a stochastic event-triggered sensor schedule for state\nestimation which preserves the Gaussianity of the system, extending previous\nresults from the single-sensor to the multi-sensor case. \n\n"}
{"id": "1502.03124", "contents": "Title: Order-Optimal Rate of Caching and Coded Multicasting with Random Demands Abstract: We consider the canonical {\\em shared link network} formed by a source node,\nhosting a library of $m$ information messages (files), connected via a\nnoiseless common link to $n$ destination nodes (users), each with a cache of\nsize M files. Users request files at random and independently, according to a\ngiven a-priori demand distribution $\\qv$. A coding scheme for this network\nconsists of a caching placement (i.e., a mapping of the library files into the\nuser caches) and delivery scheme (i.e., a mapping for the library files and\nuser demands into a common multicast codeword) such that, after the codeword\ntransmission, all users can retrieve their requested file. The rate of the\nscheme is defined as the {\\em average} codeword length normalized with respect\nto the length of one file, where expectation is taken over the random user\ndemands. For the same shared link network, in the case of deterministic\ndemands, the optimal min-max rate has been characterized within a uniform\nbound, independent of the network parameters. In particular, fractional caching\n(i.e., storing file segments) and using linear network coding has been shown to\nprovide a min-max rate reduction proportional to 1/M with respect to standard\nschemes such as unicasting or \"naive\" uncoded multicasting. The case of random\ndemands was previously considered by applying the same order-optimal min-max\nscheme separately within groups of files requested with similar probability.\nHowever, no order-optimal guarantee was provided for random demands under the\naverage rate performance criterion. In this paper, we consider the random\ndemand setting and provide general achievability and converse results. In\nparticular, we consider a family of schemes that combine random fractional\ncaching according to a probability distribution $\\pv$ that depends on the\ndemand distribution $\\qv$, with a linear coded delivery scheme based on ... \n\n"}
{"id": "1502.04071", "contents": "Title: The generalized Lasso with non-linear observations Abstract: We study the problem of signal estimation from non-linear observations when\nthe signal belongs to a low-dimensional set buried in a high-dimensional space.\nA rough heuristic often used in practice postulates that non-linear\nobservations may be treated as noisy linear observations, and thus the signal\nmay be estimated using the generalized Lasso. This is appealing because of the\nabundance of efficient, specialized solvers for this program. Just as noise may\nbe diminished by projecting onto the lower dimensional space, the error from\nmodeling non-linear observations with linear observations will be greatly\nreduced when using the signal structure in the reconstruction. We allow general\nsignal structure, only assuming that the signal belongs to some set K in R^n.\nWe consider the single-index model of non-linearity. Our theory allows the\nnon-linearity to be discontinuous, not one-to-one and even unknown. We assume a\nrandom Gaussian model for the measurement matrix, but allow the rows to have an\nunknown covariance matrix. As special cases of our results, we recover\nnear-optimal theory for noisy linear observations, and also give the first\ntheoretical accuracy guarantee for 1-bit compressed sensing with unknown\ncovariance matrix of the measurement vectors. \n\n"}
{"id": "1502.07586", "contents": "Title: Joint Hybrid Backhaul and Access Links Design in Cloud-Radio Access\n  Networks Abstract: The cloud-radio access network (CRAN) is expected to be the core network\narchitecture for next generation mobile radio systems. In this paper, we\nconsider the downlink of a CRAN formed of one central processor (the cloud) and\nseveral base-station (BS), where each BS is connected to the cloud via either a\nwireless or capacity-limited wireline backhaul link. The paper addresses the\njoint design of the hybrid backhaul links (i.e., designing the wireline and\nwireless backhaul connections from the cloud to the BSs) and the access links\n(i.e., determining the sparse beamforming solution from the BSs to the users).\nThe paper formulates the hybrid backhaul and access link design problem by\nminimizing the total network power consumption. The paper solves the problem\nusing a two-stage heuristic algorithm. At one stage, the sparse beamforming\nsolution is found using a weighted mixed `1=`2 norm minimization approach; the\ncorrelation matrix of the quantization noise of the wireline backhaul links is\ncomputed using the classical rate-distortion theory. At the second stage, the\ntransmit powers of the wireless backhaul links are found by solving a power\nminimization problem subject to quality-of-service constraints, based on the\nprinciple of conservation of rate by utilizing the rates found in the first\nstage. Simulation results suggest that the performance of the proposed\nalgorithm approaches the global optimum solution, especially at high\nsignal-to-interference-plus-noise ratio (SINR). \n\n"}
{"id": "1503.00267", "contents": "Title: Distributed Cloud Association in Downlink Multicloud Radio Access\n  Networks Abstract: This paper considers a multicloud radio access network (M-CRAN), wherein each\ncloud serves a cluster of base-stations (BS's) which are connected to the\nclouds through high capacity digital links. The network comprises several\nremote users, where each user can be connected to one (and only one) cloud.\nThis paper studies the user-to-cloud-assignment problem by maximizing a\nnetwork-wide utility subject to practical cloud connectivity constraints. The\npaper solves the problem by using an auction-based iterative algorithm, which\ncan be implemented in a distributed fashion through a reasonable exchange of\ninformation between the clouds. The paper further proposes a centralized\nheuristic algorithm, with low computational complexity. Simulations results\nshow that the proposed algorithms provide appreciable performance improvements\nas compared to the conventional cloud-less assignment solutions. \n\n"}
{"id": "1503.01402", "contents": "Title: Deterministic construction of sparse binary and ternary matrices from\n  existing binary sensing matrices Abstract: In the present work, we discuss a procedure for constructing sparse binary\nand ternary matrices from existing two binary sensing matrices. The matrices\nthat we construct have several attractive properties such as smaller density,\nwhich supports algorithms with low computational complexity. As an application\nof our method, we show that a CS matrix of general row size different from $p,\np^2, pq$ (for different primes $p,q$) can be constructed. \n\n"}
{"id": "1503.02955", "contents": "Title: Low-Delay Adaptive Video Streaming Based on Short-Term TCP Throughput\n  Prediction Abstract: Recently, HTTP-Based Adaptive Streaming has become the de facto standard for\nvideo streaming over the Internet. It allows the client to adapt media\ncharacteristics to varying network conditions in order to maximize Quality of\nExperience (QoE). In the case of live streaming this task becomes particularly\nchallenging. An important factor than might help improving performance is the\ncapability to correctly predict network throughput dynamics on short to medium\ntimescales. It becomes notably difficult in wireless networks that are often\nsubject to continuous throughput fluctuations.\n  In the present work, we develop an adaptation algorithm for HTTP-Based\nAdaptive Live Streaming that, for each adaptation decision, maximizes a\nQoE-based utility function depending on the probability of playback\ninterruptions, average video quality, and the amount of video quality\nfluctuations. To compute the utility function the algorithm leverages\nthroughput predictions, and dynamically estimated prediction accuracy.\n  We are trying to close the gap created by the lack of studies analyzing TCP\nthroughput on short to medium timescales. We study several time series\nprediction methods and their error distributions. We observe that Simple Moving\nAverage performs best in most cases. We also observe that the relative\nunderestimation error is best represented by a truncated normal distribution,\nwhile the relative overestimation error is best represented by a Lomax\ndistribution. Moreover, underestimations and overestimations exhibit a temporal\ncorrelation that we use to further improve prediction accuracy.\n  We compare the proposed algorithm with a baseline approach that uses a fixed\nmargin between past throughput and selected media bit rate, and an oracle-based\napproach that has perfect knowledge over future throughput for a certain time\nhorizon. \n\n"}
{"id": "1503.04030", "contents": "Title: Totally Distributed Energy-Efficient Transmission in MIMO Interference\n  Channels Abstract: In this paper, we consider the problem of maximizing the energy efficiency\n(EE) for multi-input multi-output (MIMO) interference channels, subject to the\nper-link power constraint. To avoid extensive information exchange among all\nlinks, the optimization problem is formulated as a noncooperative game, where\neach link maximizes its own EE. We show that this game always admits a Nash\nequilibrium (NE) and the sufficient condition for the uniqueness of the NE is\nderived for the case of arbitrary channel matrices, which can be checked in\npractice. To reach the NE of this game, we develop a totally distributed EE\nalgorithm, in which each link updates its own transmit covariance matrix in a\ncompletely distributed and asynchronous way: Some players may update their\nsolutions more frequently than others or even use the outdated interference\ninformation. The sufficient conditions that guarantee the global convergence of\nthe proposed algorithm to the NE of the game have been given as well. We also\nstudy the impact of the circuit power consumption on the sum-EE performance of\nthe proposed algorithm in the case when the links are separated sufficiently\nfar away. Moreover, the tradeoff between the sum-EE and the sum-spectral\nefficiency (SE) is investigated with the proposed algorithm under two special\ncases: 1) low transmit power constraint regime; 2) high transmit power\nconstraint regime. Finally, extensive simulations are conducted to evaluate the\nimpact of various system parameters on the system performance. \n\n"}
{"id": "1503.04604", "contents": "Title: Multi-Antenna Wireless Energy Transfer for Backscatter Communication\n  Systems Abstract: We study RF-enabled wireless energy transfer (WET) via energy beamforming,\nfrom a multi-antenna energy transmitter (ET) to multiple energy receivers (ERs)\nin a backscatter communication system, such as RFID, where each ER (or RFID\ntag) reflects back a portion of the incident signal to the ET (or RFID reader).\nFor such a system, the acquisition of the forward-channel (i.e., ET-to-ER)\nstate information (F-CSI) at the ET is challenging, since the ERs are typically\ntoo energy-and-hardware-constrained to estimate or feed back the F-CSI. The ET\nleverages its observed backscatter signals to estimate the backscatter-channel\n(i.e., ET-to-ER-to-ET) state information (BS-CSI) directly. We first analyze\nthe harvested energy obtained by using the estimated BS-CSI. Furthermore, we\noptimize the channel-training energy and the energy allocation weights for\ndifferent energy beams, for weighted-sum-energy (WSE) maximization and\nproportional-fair-energy (PFE) maximization. For WET to single ER, we obtain\nthe optimal channel-training energy in a semi-closed form. For WET to multiple\nERs, the optimal WET scheme for WSE maximization is shown to use only one\nenergy beam. For PFE maximization, we show it is a biconvex problem, and\npropose a block-coordinate-descent based algorithm to find the close-to-optimal\nsolution. Numerical results show that with the optimized solutions, the\nharvested energy suffers slight reduction of less than 10%, compared to that\nobtained by using the perfect F-CSI. Hence, energy beamforming by using the\nestimated BS-CSI is promising, as the complexity and energy requirement is\nshifted from the ERs to the ET. \n\n"}
{"id": "1503.05365", "contents": "Title: Caching at the Edge: a Green Perspective for 5G Networks Abstract: Endowed with context-awareness and proactive capabilities, caching users'\ncontent locally at the edge of the network is able to cope with increasing data\ntraffic demand in 5G wireless networks. In this work, we focus on the energy\nconsumption aspects of cache-enabled wireless cellular networks, specifically\nin terms of area power consumption (APC) and energy efficiency (EE). We assume\nthat both base stations (BSs) and mobile users are distributed according to\nhomogeneous Poisson point processes (PPPs) and we introduce a detailed power\nmodel that takes into account caching. We study the conditions under which the\narea power consumption is minimized with respect to BS transmit power, while\nensuring a certain quality of service (QoS) in terms of coverage probability.\nFurthermore, we provide the optimal BS transmit power that maximizes the area\nspectral efficiency per unit total power spent. The main takeaway of this paper\nis that caching seems to be an energy efficient solution. \n\n"}
{"id": "1503.09039", "contents": "Title: Operational Region of D2D Communications for Enhancing Cellular Network\n  Performance Abstract: An important enabler towards the successful deployment of any new\nelement/feature to the cellular network is the investigation and\ncharacterization of the operational conditions where its introduction will\nenhance performance. Even though there has been significant research activity\non the potential of device-to-device (D2D) communications, there are currently\nno clear indications of whether D2D communications are actually able to provide\nbenefits for a wide range of operational conditions, thus justifying their\nintroduction to the system. This paper attempts to fill this gap by taking a\nstochastic geometry approach on characterizing the set (region) of operational\nconditions for which D2D communications enhance performance in terms of average\nuser rate. For the practically interesting case of a heavy loaded network, the\noperational region is provided in closed form as a function of a variety of\nparameters such as maximum D2D link distances and user densities, reflecting a\nwide range of operational conditions (points). It is shown that under the\nappropriate deployment scheme, D2D communications can indeed be beneficial not\nonly for the usually considered regime of \"proximal communications\" but to a\nwide range of operational conditions that include D2D link distances comparable\nto the distance to the cellular access point and considerably large user\ndensities. \n\n"}
{"id": "1504.00082", "contents": "Title: A Unified Scheme for Two-Receiver Broadcast Channels with Receiver\n  Message Side Information Abstract: This paper investigates the capacity regions of two-receiver broadcast\nchannels where each receiver (i) has both common and private-message requests,\nand (ii) knows part of the private message requested by the other receiver as\nside information. We first propose a transmission scheme and derive an inner\nbound for the two-receiver memoryless broadcast channel. We next prove that\nthis inner bound is tight for the deterministic channel and the more capable\nchannel, thereby establishing their capacity regions. We show that this inner\nbound is also tight for all classes of two-receiver broadcast channels whose\ncapacity regions were known prior to this work. Our proposed scheme is\nconsequently a unified capacity-achieving scheme for these classes of broadcast\nchannels. \n\n"}
{"id": "1504.01123", "contents": "Title: Coded Caching with Heterogenous Cache Sizes Abstract: We investigate the coded caching scheme under heterogenous cache sizes. \n\n"}
{"id": "1504.01185", "contents": "Title: Byzantine Attack and Defense in Cognitive Radio Networks: A Survey Abstract: The Byzantine attack in cooperative spectrum sensing (CSS), also known as the\nspectrum sensing data falsification (SSDF) attack in the literature, is one of\nthe key adversaries to the success of cognitive radio networks (CRNs). In the\npast couple of years, the research on the Byzantine attack and defense\nstrategies has gained worldwide increasing attention. In this paper, we provide\na comprehensive survey and tutorial on the recent advances in the Byzantine\nattack and defense for CSS in CRNs. Specifically, we first briefly present the\npreliminaries of CSS for general readers, including signal detection\ntechniques, hypothesis testing, and data fusion. Second, we analyze the spear\nand shield relation between Byzantine attack and defense from three aspects:\nthe vulnerability of CSS to attack, the obstacles in CSS to defense, and the\ngames between attack and defense. Then, we propose a taxonomy of the existing\nByzantine attack behaviors and elaborate on the corresponding attack\nparameters, which determine where, who, how, and when to launch attacks. Next,\nfrom the perspectives of homogeneous or heterogeneous scenarios, we classify\nthe existing defense algorithms, and provide an in-depth tutorial on the\nstate-of-the-art Byzantine defense schemes, commonly known as robust or secure\nCSS in the literature. Furthermore, we highlight the unsolved research\nchallenges and depict the future research directions. \n\n"}
{"id": "1504.01274", "contents": "Title: The Weight Hierarchy of Some Reducible Cyclic Codes Abstract: The generalized Hamming weights (GHWs) of linear codes are fundamental\nparameters, the knowledge of which is of great interest in many applications.\nHowever, to determine the GHWs of linear codes is difficult in general. In this\npaper, we study the GHWs for a family of reducible cyclic codes and obtain the\ncomplete weight hierarchy in several cases. This is achieved by extending the\nidea of \\cite{YLFL} into higher dimension and by employing some interesting\ncombinatorial arguments. It shall be noted that these cyclic codes may have\narbitrary number of nonzeroes. \n\n"}
{"id": "1504.01355", "contents": "Title: MacWilliams Extension Theorem for MDS additive codes Abstract: The MacWilliams Extension Theorem states that each linear isometry of a\nlinear code extends to a monomial map. Unlike the linear codes, in general,\nadditive codes do not have the extension property. In this paper, an analogue\nof the extension theorem for additive codes in the case of additive MDS codes\nis proved. More precisely, it is shown that for almost all additive MDS codes\ntheir additive isometries extend to isometries of the ambient space. \n\n"}
{"id": "1504.04092", "contents": "Title: One-Shot Mutual Covering Lemma and Marton's Inner Bound with a Common\n  Message Abstract: By developing one-shot mutual covering lemmas, we derive a one-shot\nachievability bound for broadcast with a common message which recovers Marton's\ninner bound (with three auxiliary random variables) in the i.i.d.~case. The\nencoder employed is deterministic. Relationship between the mutual covering\nlemma and a new type of channel resolvability problem is discussed. \n\n"}
{"id": "1504.05227", "contents": "Title: Fully Quantum Source Compression with a Quantum Helper Abstract: We study source compression with a helper in the fully quantum regime,\nextending our earlier result on classical source compression with a quantum\nhelper [arXiv:1501.04366, 2015]. We characterise the quantum resources involved\nin this problem, and derive a single-letter expression of the achievable rate\nregion when entanglement assistance is available. The direct coding proof is\nbased on a combination of two fundamental protocols, namely the quantum state\nmerging protocol and the quantum reverse Shannon theorem (QRST). This result\ndemonstrates an unexpected connection between distributed source compression\nwith the QRST protocol, a quantum protocol that consumes noiseless resources to\nsimulate a noisy quantum channel. \n\n"}
{"id": "1504.05294", "contents": "Title: On Approximating the Sum-Rate for Multiple-Unicasts Abstract: We study upper bounds on the sum-rate of multiple-unicasts. We approximate\nthe Generalized Network Sharing Bound (GNS cut) of the multiple-unicasts\nnetwork coding problem with $k$ independent sources. Our approximation\nalgorithm runs in polynomial time and yields an upper bound on the joint source\nentropy rate, which is within an $O(\\log^2 k)$ factor from the GNS cut. It\nfurther yields a vector-linear network code that achieves joint source entropy\nrate within an $O(\\log^2 k)$ factor from the GNS cut, but \\emph{not} with\nindependent sources: the code induces a correlation pattern among the sources.\n  Our second contribution is establishing a separation result for vector-linear\nnetwork codes: for any given field $\\mathbb{F}$ there exist networks for which\nthe optimum sum-rate supported by vector-linear codes over $\\mathbb{F}$ for\nindependent sources can be multiplicatively separated by a factor of\n$k^{1-\\delta}$, for any constant ${\\delta>0}$, from the optimum joint entropy\nrate supported by a code that allows correlation between sources. Finally, we\nestablish a similar separation result for the asymmetric optimum vector-linear\nsum-rates achieved over two distinct fields $\\mathbb{F}_{p}$ and\n$\\mathbb{F}_{q}$ for independent sources, revealing that the choice of field\ncan heavily impact the performance of a linear network code. \n\n"}
{"id": "1504.05538", "contents": "Title: Joint Source-Channel Secrecy Using Hybrid Coding Abstract: The secrecy performance of a source-channel model is studied in the context\nof lossy source compression over a noisy broadcast channel. The source is\ncausally revealed to the eavesdropper during decoding. The fidelity of the\ntransmission to the legitimate receiver and the secrecy performance at the\neavesdropper are both measured by a distortion metric. Two achievability\nschemes using the technique of hybrid coding are analyzed and compared with an\noperationally separate source-channel coding scheme. A numerical example is\nprovided and the comparison results show that the hybrid coding schemes\noutperform the operationally separate scheme. \n\n"}
{"id": "1504.05639", "contents": "Title: Asymmetric quantum convolutional codes Abstract: In this paper, we construct the first families of asymmetric quantum\nconvolutional codes (AQCC)'s. These new AQCC's are constructed by means of the\nCSS-type construction applied to suitable families of classical convolutional\ncodes, which are also constructed here. The new codes have noncatastrophic\ngenerator matrices and they present great asymmetry. Since our constructions\nare performed algebraically, it is possible to derive several families of such\ncodes and not only codes with specific parameters. Additionally, several\ndifferent types of such codes are obtained. \n\n"}
{"id": "1504.05837", "contents": "Title: New Perspectives on Multiple Source Localization in Wireless Sensor\n  Networks Abstract: In this paper we address the challenging problem of multiple source\nlocalization in Wireless Sensor Networks (WSN). We develop an efficient\nstatistical algorithm, based on the novel application of Sequential Monte Carlo\n(SMC) sampler methodology, that is able to deal with an unknown number of\nsources given quantized data obtained at the fusion center from different\nsensors with imperfect wireless channels. We also derive the Posterior\nCram\\'er-Rao Bound (PCRB) of the source location estimate. The PCRB is used to\nanalyze the accuracy of the proposed SMC sampler algorithm and the impact that\nquantization has on the accuracy of location estimates of the sources.\nExtensive experiments show that the benefits of the proposed scheme in terms of\nthe accuracy of the estimation method that are required for model selection\n(i.e., the number of sources) and the estimation of the source characteristics\ncompared to the classical importance sampling method. \n\n"}
{"id": "1504.05931", "contents": "Title: Effect of Number of Users in Multi-level Coded Caching Abstract: It has been recently established that joint design of content delivery and\nstorage (coded caching) can significantly improve performance over conventional\ncaching. This has also been extended to the case when content has non-uniform\npopularity through several models. In this paper we focus on a multi-level\npopularity model, where content is divided into levels based on popularity. We\nconsider two extreme cases of user distribution across caches for the\nmulti-level popularity model: a single user per cache (single-user setup)\nversus a large number of users per cache (multi-user setup). When the capacity\napproximation is universal (independent of number of popularity levels as well\nas number of users, files and caches), we demonstrate a dichotomy in the\norder-optimal strategies for these two extreme cases. In the multi-user case,\nsharing memory among the levels is order-optimal, whereas for the single-user\ncase clustering popularity levels and allocating all the memory to them is the\norder-optimal scheme. In proving these results, we develop new\ninformation-theoretic lower bounds for the problem. \n\n"}
{"id": "1504.06316", "contents": "Title: Interactive Communication with Unknown Noise Rate Abstract: Alice and Bob want to run a protocol over a noisy channel, where a certain\nnumber of bits are flipped adversarially. Several results take a protocol\nrequiring $L$ bits of noise-free communication and make it robust over such a\nchannel. In a recent breakthrough result, Haeupler described an algorithm that\nsends a number of bits that is conjectured to be near optimal in such a model.\nHowever, his algorithm critically requires $a \\ priori$ knowledge of the number\nof bits that will be flipped by the adversary.\n  We describe an algorithm requiring no such knowledge. If an adversary flips\n$T$ bits, our algorithm sends $L + O\\left(\\sqrt{L(T+1)\\log L} + T\\right)$ bits\nin expectation and succeeds with high probability in $L$. It does so without\nany $a \\ priori$ knowledge of $T$. Assuming a conjectured lower bound by\nHaeupler, our result is optimal up to logarithmic factors.\n  Our algorithm critically relies on the assumption of a private channel. We\nshow that privacy is necessary when the amount of noise is unknown. \n\n"}
{"id": "1504.06746", "contents": "Title: Massive MIMO Full-Duplex Relaying with Optimal Power Allocation for\n  Independent Multipairs Abstract: With the help of an in-band full-duplex relay station, it is possible to\nsimultaneously transmit and receive signals from multiple users. The\nperformance of such system can be greatly increased when the relay station is\nequipped with a large number of antennas on both transmitter and receiver\nsides. In this paper, we exploit the use of massive arrays to effectively\nsuppress the loopback interference (LI) of a decode-and-forward relay (DF) and\nevaluate the performance of the end-to-end (e2e) transmission. This paper\nassumes imperfect channel state information is available at the relay and\ndesigns a minimum mean-square error (MMSE) filter to mitigate the interference.\nSubsequently, we adopt zero-forcing (ZF) filters for both detection and\nbeamforming. The performance of such system is evaluated in terms of bit error\nrate (BER) at both relay and destinations, and an optimal choice for the\ntransmission power at the relay is shown. We then propose a complexity\nefficient optimal power allocation (OPA) algorithm that, using the channel\nstatistics, computes the minimum power that satisfies the rate constraints of\neach pair. The results obtained via simulation show that when both MMSE\nfiltering and OPA method are used, better values for the energy efficiency are\nattained. \n\n"}
{"id": "1505.00810", "contents": "Title: Optimizing Data Aggregation for Uplink Machine-to-Machine Communication\n  Networks Abstract: Machine-to-machine (M2M) communication's severe power limitations challenge\nthe interconnectivity, access management, and reliable communication of data.\nIn densely deployed M2M networks, controlling and aggregating the generated\ndata is critical. We propose an energy efficient data aggregation scheme for a\nhierarchical M2M network. We develop a coverage probability-based optimal data\naggregation scheme for M2M devices to minimize the average total energy\nexpenditure per unit area per unit time or simply the {\\em energy density} of\nan M2M communication network. Our analysis exposes the key tradeoffs between\nthe energy density of the M2M network and the coverage characteristics for\nsuccessive and parallel transmission schemes that can be either half-duplex or\nfull-duplex. Comparing the rate and energy performances of the transmission\nmodels, we observe that successive mode and half-duplex parallel mode have\nbetter coverage characteristics compared to full-duplex parallel scheme.\nSimulation results show that the uplink coverage characteristics dominate the\ntrend of the energy consumption for both successive and parallel schemes. \n\n"}
{"id": "1505.01137", "contents": "Title: On the Reliability Function of Variable-Rate Slepian-Wolf Coding Abstract: The reliability function of variable-rate Slepian-Wolf coding is linked to\nthe reliability function of channel coding with constant composition codes,\nthrough which computable lower and upper bounds are derived. The bounds\ncoincide at rates close to the Slepian-Wolf limit, yielding a complete\ncharacterization of the reliability function in that rate regime. It is shown\nthat variable-rate Slepian-Wolf codes can significantly outperform fixed-rate\nSlepian-Wolf codes in terms of rate-error tradeoff. The reliability function of\nvariable-rate Slepian-Wolf coding with rate below the Slepian-Wolf limit is\ndetermined. In sharp contrast with fixed-rate Slepian-Wolf codes for which the\ncorrect decoding probability decays to zero exponentially fast if the rate is\nbelow the Slepian-Wolf limit, the correct decoding probability of variable-rate\nSlepian-Wolf codes can be bounded away from zero. \n\n"}
{"id": "1505.01181", "contents": "Title: Deploying Dense Networks for Maximal Energy Efficiency: Small Cells Meet\n  Massive MIMO Abstract: How would a cellular network designed for maximal energy efficiency look\nlike? To answer this fundamental question, tools from stochastic geometry are\nused in this paper to model future cellular networks and obtain a new lower\nbound on the average uplink spectral efficiency. This enables us to formulate a\ntractable uplink energy efficiency (EE) maximization problem and solve it\nanalytically with respect to the density of base stations (BSs), the transmit\npower levels, the number of BS antennas and users per cell, and the pilot reuse\nfactor. The closed-form expressions obtained from this general EE maximization\nframework provide valuable insights on the interplay between the optimization\nvariables, hardware characteristics, and propagation environment. Small cells\nare proved to give high EE, but the EE improvement saturates quickly with the\nBS density. Interestingly, the maximal EE is achieved by also equipping the BSs\nwith multiple antennas and operate in a \"massive MIMO\" fashion, where the array\ngain from coherent detection mitigates interference and the multiplexing of\nmany users reduces the energy cost per user. \n\n"}
{"id": "1505.02186", "contents": "Title: Construction of Subspace Codes through Linkage Abstract: A construction is presented that allows to produce subspace codes of long\nlength using subspace codes of shorter length in combination with a rank metric\ncode. The subspace distance of the resulting code, called linkage code, is as\ngood as the minimum subspace distance of the constituent codes. As a special\napplication, the construction of the best known partial spreads is reproduced.\nFinally, for a special case of linkage, a decoding algorithm is presented which\namounts to decoding with respect to the smaller constituent codes and which can\nbe parallelized. \n\n"}
{"id": "1505.02862", "contents": "Title: A Numerical Study on the Wiretap Network with a Simple Network Topology Abstract: In this paper, we study a security problem on a simple wiretap network,\nconsisting of a source node S, a destination node D, and an intermediate node\nR. The intermediate node connects the source and the destination nodes via a\nset of noiseless parallel channels, with sizes $n_1$ and $n_2$, respectively. A\nmessage $M$ is to be sent from S to D. The information in the network may be\neavesdropped by a set of wiretappers. The wiretappers cannot communicate with\none another. Each wiretapper can access a subset of channels, called a wiretap\nset. All the chosen wiretap sets form a wiretap pattern. A random key $K$ is\ngenerated at S and a coding scheme on $(M, K)$ is employed to protect $M$. We\ndefine two decoding classes at D: In Class-I, only $M$ is required to be\nrecovered and in Class-II, both $M$ and $K$ are required to be recovered. The\nobjective is to minimize $H(K)/H(M)$ {for a given wiretap pattern} under the\nperfect secrecy constraint. The first question we address is whether routing is\noptimal on this simple network. By enumerating all the wiretap patterns on the\nClass-I/II $(3,3)$ networks and harnessing the power of Shannon-type\ninequalities, we find that gaps exist between the bounds implied by routing and\nthe bounds implied by Shannon-type inequalities for a small fraction~($<2\\%$)\nof all the wiretap patterns. The second question we investigate is the\nfollowing: What is $\\min H(K)/H(M)$ for the remaining wiretap patterns where\ngaps exist? We study some simple wiretap patterns and find that their Shannon\nbounds (i.e., the lower bound induced by Shannon-type inequalities) can be\nachieved by linear codes, which means routing is not sufficient even for the\n($3$, $3$) network. For some complicated wiretap patterns, we study the\nstructures of linear coding schemes under the assumption that they can achieve\nthe corresponding Shannon bounds.... \n\n"}
{"id": "1505.05428", "contents": "Title: Simplex and MacDonald Codes over $R_{q}$ Abstract: In this paper, we introduce the homogeneous weight and homogeneous Gray map\nover the ring $R_{q}=\\mathbb{F}_{2}[u_{1},u_{2},\\ldots,u_{q}]/\\left\\langle\nu_{i}^{2}=0,u_{i}u_{j}=u_{j}u_{i}\\right\\rangle$ for $q \\geq 2$. We also\nconsider the construction of simplex and MacDonald codes of types $\\alpha$ and\n$\\beta$ over this ring. \n\n"}
{"id": "1505.05576", "contents": "Title: The Complete Weight Enumerator of Several Cyclic Codes Abstract: Cyclic codes have attracted a lot of research interest for decades. In this\npaper, for an odd prime $p$, we propose a general strategy to compute the\ncomplete weight enumerator of cyclic codes via the value distribution of the\ncorresponding exponential sums. As applications of this general strategy, we\ndetermine the complete weight enumerator of several $p$-ary cyclic codes and\ngive some examples to illustrate our results. \n\n"}
{"id": "1505.05646", "contents": "Title: A mechanized proof of loop freedom of the (untimed) AODV routing\n  protocol Abstract: The Ad hoc On-demand Distance Vector (AODV) routing protocol allows the nodes\nin a Mobile Ad hoc Network (MANET) or a Wireless Mesh Network (WMN) to know\nwhere to forward data packets. Such a protocol is 'loop free' if it never leads\nto routing decisions that forward packets in circles. This paper describes the\nmechanization of an existing pen-and-paper proof of loop freedom of AODV in the\ninteractive theorem prover Isabelle/HOL. The mechanization relies on a novel\ncompositional approach for lifting invariants to networks of nodes. We exploit\nthe mechanization to analyse several improvements of AODV and show that\nIsabelle/HOL can re-establish most proof obligations automatically and identify\nexactly the steps that are no longer valid. \n\n"}
{"id": "1505.06241", "contents": "Title: PIR with Low Storage Overhead: Coding instead of Replication Abstract: Private information retrieval (PIR) protocols allow a user to retrieve a data\nitem from a database without revealing any information about the identity of\nthe item being retrieved. Specifically, in information-theoretic $k$-server\nPIR, the database is replicated among $k$ non-communicating servers, and each\nserver learns nothing about the item retrieved by the user. The cost of PIR\nprotocols is usually measured in terms of their communication complexity, which\nis the total number of bits exchanged between the user and the servers, and\nstorage overhead, which is the ratio between the total number of bits stored on\nall the servers and the number of bits in the database. Since single-server\ninformation-theoretic PIR is impossible, the storage overhead of all existing\nPIR protocols is at least $2$.\n  In this work, we show that information-theoretic PIR can be achieved with\nstorage overhead arbitrarily close to the optimal value of $1$, without\nsacrificing the communication complexity. Specifically, we prove that all known\n$k$-server PIR protocols can be efficiently emulated, while preserving both\nprivacy and communication complexity but significantly reducing the storage\noverhead. To this end, we distribute the $n$ bits of the database among $s+r$\nservers, each storing $n/s$ coded bits (rather than replicas). For every fixed\n$k$, the resulting storage overhead $(s+r)/s$ approaches $1$ as $s$ grows;\nexplicitly we have $r\\le k\\sqrt{s}(1+o(1))$. Moreover, in the special case $k =\n2$, the storage overhead is only $1 + \\frac{1}{s}$. In order to achieve these\nresults, we introduce and study a new kind of binary linear codes, called here\n$k$-server PIR codes. We then show how such codes can be constructed, and we\nestablish several bounds on the parameters of $k$-server PIR codes. Finally, we\nbriefly discuss extensions of our results to nonbinary alphabets, to robust\nPIR, and to $t$-private PIR. \n\n"}
{"id": "1505.07493", "contents": "Title: Duality Preserving Gray Maps for Codes over Rings Abstract: Given a finite ring $A$ which is a free left module over a subring $R$ of\n$A$, two types of $R$-bases, pseudo-self-dual bases (similar to trace\northogonal bases) and symmetric bases, are defined which in turn are used to\ndefine duality preserving maps from codes over $A$ to codes over $R$. Both\ntypes of bases are generalizations of similar concepts for fields. Many\nillustrative examples are given to shed light on the advantages to such\nmappings as well as their abundance. \n\n"}
{"id": "1505.07503", "contents": "Title: Quantifying randomness in real networks Abstract: Represented as graphs, real networks are intricate combinations of order and\ndisorder. Fixing some of the structural properties of network models to their\nvalues observed in real networks, many other properties appear as statistical\nconsequences of these fixed observables, plus randomness in other respects.\nHere we employ the $dk$-series, a complete set of basic characteristics of the\nnetwork structure, to study the statistical dependencies between different\nnetwork properties. We consider six real networks---the Internet, US airport\nnetwork, human protein interactions, technosocial web of trust, English word\nnetwork, and an fMRI map of the human brain---and find that many important\nlocal and global structural properties of these networks are closely reproduced\nby $dk$-random graphs whose degree distributions, degree correlations, and\nclustering are as in the corresponding real network. We discuss important\nconceptual, methodological, and practical implications of this evaluation of\nnetwork randomness, and release software to generate $dk$-random graphs. \n\n"}
{"id": "1505.07717", "contents": "Title: Exploring multimodal data fusion through joint decompositions with\n  flexible couplings Abstract: A Bayesian framework is proposed to define flexible coupling models for joint\ntensor decompositions of multiple data sets. Under this framework, a natural\nformulation of the data fusion problem is to cast it in terms of a joint\nmaximum a posteriori (MAP) estimator. Data driven scenarios of joint posterior\ndistributions are provided, including general Gaussian priors and non Gaussian\ncoupling priors. We present and discuss implementation issues of algorithms\nused to obtain the joint MAP estimator. We also show how this framework can be\nadapted to tackle the problem of joint decompositions of large datasets. In the\ncase of a conditional Gaussian coupling with a linear transformation, we give\ntheoretical bounds on the data fusion performance using the Bayesian Cramer-Rao\nbound. Simulations are reported for hybrid coupling models ranging from simple\nadditive Gaussian models, to Gamma-type models with positive variables and to\nthe coupling of data sets which are inherently of different size due to\ndifferent resolution of the measurement devices. \n\n"}
{"id": "1506.02677", "contents": "Title: Convex Optimization Approach for Stable Decomposition of Stream of\n  Pulses Abstract: This paper deals with the problem of estimating the delays and amplitudes of\na weighted superposition of pulses, called stream of pulses. This problem is\nmotivated by a variety of applications, such as ultrasound and radar. This\npaper shows that the recovery error of a tractable convex optimization problem\nis proportional to the noise level. Additionally, the estimated delays are\nclustered around the true delays. This holds provided that the pulse meets a\nfew mild localization properties and that a separation condition holds. If the\namplitudes are known to be positive, the separation is unnecessary. In this\ncase, the recovery error is proportional to the noise level and depends on the\nmaximal number of delays within a resolution cell. \n\n"}
{"id": "1506.02865", "contents": "Title: On defining generalized rank weights Abstract: This paper investigates the generalized rank weights, with a definition\nimplied by the study of the generalized rank weight enumerator. We study rank\nmetric codes over $L$, where $L$ is a finite Galois extension of a field $K$.\nThis is a generalization of the case where $K = \\mathbb{F}_q$ and $L =\n\\mathbb{F}_{q^m}$ of Gabidulin codes to arbitrary characteristic. We show\nequivalence to previous definitions, in particular the ones by\nKurihara-Matsumoto-Uyematsu, Oggier-Sboui and Ducoat. As an application of the\nnotion of generalized rank weights, we discuss codes that are degenerate with\nrespect to the rank metric. \n\n"}
{"id": "1506.03040", "contents": "Title: The gap between the null space property and the restricted isometry\n  property Abstract: The null space property (NSP) and the restricted isometry property (RIP) are\ntwo properties which have received considerable attention in the compressed\nsensing literature. As the name suggests, NSP is a property that depends solely\non the null space of the measurement procedure and as such, any two matrices\nwhich have the same null space will have NSP if either one of them does. On the\nother hand, RIP is a property of the measurement procedure itself, and given an\nRIP matrix it is straightforward to construct another matrix with the same null\nspace that is not RIP. %Furthermore, RIP is known to imply NSP and therefore\nRIP is a strictly stronger assumption than NSP. We say a matrix is RIP-NSP if\nit has the same null space as an RIP matrix. We show that such matrices can\nprovide robust recovery of compressible signals under Basis pursuit which in\nmany applicable settings is comparable to the guarantee that RIP provides. More\nimportantly, we constructively show that the RIP-NSP is stronger than NSP with\nthe aid of this robust recovery result, which shows that RIP is fundamentally\nstronger than NSP. \n\n"}
{"id": "1506.03394", "contents": "Title: Spatial Self-Interference Isolation for In-Band Full-Duplex Wireless: A\n  Degrees-of-Freedom Analysis Abstract: The challenge to in-band full-duplex wireless communication is managing\nself-interference. Many designs have employed spatial isolation mechanisms,\nsuch as shielding or multi-antenna beamforming, to isolate the\nself-interference wave from the receiver. Such spatial isolation methods are\neffective, but by confining the transmit and receive signals to a subset of the\navailable space, the full spatial resources of the channel be under-utilized,\nexpending a cost that may nullify the net benefit of operating in full-duplex\nmode. In this paper we leverage an antenna-theory-based channel model to\nanalyze the spatial degrees of freedom available to a full-duplex capable base\nstation, and observe that whether or not spatial isolation out-performs\ntime-division (i.e. half-duplex) depends heavily on the geometric distribution\nof scatterers. Unless the angular spread of the objects that scatter to the\nintended users is overlapped by the spread of objects that backscatter to the\nbase station, then spatial isolation outperforms time division, otherwise time\ndivision may be optimal. \n\n"}
{"id": "1506.03407", "contents": "Title: Strong Successive Refinability and Rate-Distortion-Complexity Tradeoff Abstract: We investigate the second order asymptotics (source dispersion) of the\nsuccessive refinement problem. Similarly to the classical definition of a\nsuccessively refinable source, we say that a source is strongly successively\nrefinable if successive refinement coding can achieve the second order optimum\nrate (including the dispersion terms) at both decoders. We establish a\nsufficient condition for strong successive refinability. We show that any\ndiscrete source under Hamming distortion and the Gaussian source under\nquadratic distortion are strongly successively refinable.\n  We also demonstrate how successive refinement ideas can be used in\npoint-to-point lossy compression problems in order to reduce complexity. We\ngive two examples, the binary-Hamming and Gaussian-quadratic cases, in which a\nlayered code construction results in a low complexity scheme that attains\noptimal performance. For example, when the number of layers grows with the\nblock length $n$, we show how to design an $O(n^{\\log(n)})$ algorithm that\nasymptotically achieves the rate-distortion bound. \n\n"}
{"id": "1506.04079", "contents": "Title: Energy Harvesting Systems with Continuous Energy and Data Arrivals: the\n  Optimal Offline and a Heuristic Online Algorithms Abstract: Energy harvesting has been developed as an effective technology for\ncommunication systems in order to extend the lifetime of these systems. In this\nwork, we consider a singleuser energy harvesting wireless communication system,\nin which arrival data and harvested energy curves are modeled as continuous\nfunctions. For the single-user model, our first goal is to find an offline\nalgorithm, which maximizes the amount of data which is transmitted to the\nreceiver node by a given deadline. If more than one scheme exists that\ntransmits the maximum data, we choose the one with minimum utilized energy at\nthe transmitter node. Next, we propose an online algorithm for this system. We\nalso consider a multi-hop energy harvesting wireless communication system in a\nfull-duplex mode and find the optimal offline algorithm to maximize the\nthroughput. \n\n"}
{"id": "1506.04812", "contents": "Title: Empirical Coordination with Two-Sided State Information and Correlated\n  Source and State Abstract: The coordination of autonomous agents is a critical issue for decentralized\ncommunication networks. Instead of transmitting information, the agents\ninteract in a coordinated manner in order to optimize a general objective\nfunction. A target joint probability distribution is achievable if there exists\na code such that the sequences of symbols are jointly typical. The empirical\ncoordination is strongly related to the joint source-channel coding with\ntwo-sided state information and correlated source and state. This problem is\nalso connected to state communication and is open for non-causal encoder and\ndecoder. We characterize the optimal solutions for perfect channel, for\nlossless decoding, for independent source and channel, for causal encoding and\nfor causal decoding. \n\n"}
{"id": "1506.05525", "contents": "Title: Some new results on permutation polynomials over finite fields Abstract: Permutation polynomials over finite fields constitute an active research area\nand have applications in many areas of science and engineering. In this paper,\nfour classes of monomial complete permutation polynomials and one class of\ntrinomial complete permutation polynomials are presented, one of which confirms\na conjecture proposed by Wu et al. (Sci. China Math., to appear. Doi:\n10.1007/s11425-014-4964-2). Furthermore, we give two classes of trinomial\npermutation polynomials, and make some progress on a conjecture about the\ndifferential uniformity of power permutation polynomials proposed by Blondeau\net al. (Int. J. Inf. Coding Theory, 2010, 1, pp. 149-170). \n\n"}
{"id": "1506.06988", "contents": "Title: From Entropy to Information: Biased Typewriters and the Origin of Life Abstract: The origin of life can be understood mathematically to be the origin of\ninformation that can replicate. The likelihood that entropy spontaneously\nbecomes information can be calculated from first principles, and depends\nexponentially on the amount of information that is necessary for replication.\nWe do not know what the minimum amount of information for self-replication is\nbecause it must depend on the local chemistry, but we can study how this\nlikelihood behaves in different known chemistries, and we can study ways in\nwhich this likelihood can be enhanced. Here we present evidence from numerical\nsimulations (using the digital life chemistry \"Avida\") that using a biased\nprobability distribution for the creation of monomers (the \"biased typewriter\")\ncan exponentially increase the likelihood of spontaneous emergence of\ninformation from entropy. We show that this likelihood may depend on the length\nof the sequence that the information is embedded in, but in a non-trivial\nmanner: there may be an optimum sequence length that maximizes the likelihood.\nWe conclude that the likelihood of spontaneous emergence of self-replication is\nmuch more malleable than previously thought, and that the biased probability\ndistributions of monomers that are the norm in biochemistry may significantly\nenhance these likelihoods \n\n"}
{"id": "1506.07468", "contents": "Title: Coexistence Analysis between Radar and Cellular System in LoS Channel Abstract: Sharing spectrum with incumbents such as radar systems is an attractive\nsolution for cellular operators in order to meet the ever growing bandwidth\nrequirements and ease the spectrum crunch problem. In order to realize\nefficient spectrum sharing, interference mitigation techniques are required. In\nthis letter we address techniques to mitigate MIMO radar interference at MIMO\ncellular base stations (BSs). We specifically look at the amount of power\nreceived at BSs when radar uses null space projection (NSP)-based interference\nmitigation method. NSP reduces the amount of projected power at targets that\nare in-close vicinity to BSs. We study this issue and show that this can be\navoided if radar employs a larger transmit array. In addition, we compute the\ncoherence time of channel between radar and BSs and show that the coherence\ntime of channel is much larger than the pulse repetition interval of radars.\nTherefore, NSP-based interference mitigation techniques which depends on\naccurate channel state information (CSI) can be effective as the problem of CSI\nbeing outdated does not occur for most practical scenarios. \n\n"}
{"id": "1507.00071", "contents": "Title: Optimal time sharing in underlay cognitive radio systems with RF energy\n  harvesting Abstract: Due to the fundamental tradeoffs, achieving spectrum efficiency and energy\nefficiency are two contending design challenges for the future wireless\nnetworks. However, applying radio-frequency (RF) energy harvesting (EH) in a\ncognitive radio system could potentially circumvent this tradeoff, resulting in\na secondary system with limitless power supply and meaningful achievable\ninformation rates. This paper proposes an online solution for the optimal time\nallocation (time sharing) between the EH phase and the information transmission\n(IT) phase in an underlay cognitive radio system, which harvests the RF energy\noriginating from the primary system. The proposed online solution maximizes the\naverage achievable rate of the cognitive radio system, subject to the\n$\\varepsilon$-percentile protection criteria for the primary system. The\noptimal time sharing achieves significant gains compared to equal time\nallocation between the EH and IT phases. \n\n"}
{"id": "1507.00182", "contents": "Title: Modeling and Analysis of Content Caching in Wireless Small Cell Networks Abstract: Network densification with small cell base stations is a promising solution\nto satisfy future data traffic demands. However, increasing small cell base\nstation density alone does not ensure better users quality-of-experience and\nincurs high operational expenditures. Therefore, content caching on different\nnetwork elements has been proposed as a mean of offloading he backhaul by\ncaching strategic contents at the network edge, thereby reducing latency. In\nthis paper, we investigate cache-enabled small cells in which we model and\ncharacterize the outage probability, defined as the probability of not\nsatisfying users requests over a given coverage area. We analytically derive a\nclosed form expression of the outage probability as a function of\nsignal-to-interference ratio, cache size, small cell base station density and\nthreshold distance. By assuming the distribution of base stations as a Poisson\npoint process, we derive the probability of finding a specific content within a\nthreshold distance and the optimal small cell base station density that\nachieves a given target cache hit probability. Furthermore, simulation results\nare performed to validate the analytical model. \n\n"}
{"id": "1507.01491", "contents": "Title: Finite nonassociative algebras obtained from skew polynomials and\n  possible applications to $(f,\\sigma,\\delta)$-codes Abstract: Let $S$ be a unital ring, $S[t;\\sigma,\\delta]$ a skew polynomial ring where\n$\\sigma$ is an injective endomorphism and $\\delta$ a left $\\sigma$-derivation,\nand suppose $f\\in S[t;\\sigma,\\delta]$ has degree $m$ and an invertible leading\ncoefficient. Using right division by $f$ to define the multiplication, we\nobtain unital nonassociative algebras $S_f$ on the set of skew polynomials in\n$S[t;\\sigma,\\delta]$ of degree less than $m$. We study the structure of these\nalgebras. When $S$ is a Galois ring and $f$ base irreducible, these algebras\nyield families of finite unital nonassociative rings $A$, whose set of (left or\nright) zero divisors has the form $pA$ for some prime $p$. For reducible $f$,\nthe $S_f$ can be employed both to design linear $(f,\\sigma,\\delta)$-codes over\nunital rings and to study their behaviour. \n\n"}
{"id": "1507.02037", "contents": "Title: Sparse Time-Frequency decomposition for multiple signals with same\n  frequencies Abstract: In this paper, we consider multiple signals sharing same instantaneous\nfrequencies. This kind of data is very common in scientific and engineering\nproblems. To take advantage of this special structure, we modify our\ndata-driven time-frequency analysis by updating the instantaneous frequencies\nsimultaneously. Moreover, based on the simultaneously sparsity approximation\nand fast Fourier transform, some efficient algorithms is developed. Since the\ninformation of multiple signals is used, this method is very robust to the\nperturbation of noise. And it is applicable to the general nonperiodic signals\neven with missing samples or outliers. Several synthetic and real signals are\nused to test this method. The performances of this method are very promising. \n\n"}
{"id": "1507.02839", "contents": "Title: Principle of maximum force and holographic principle: two principles or\n  one? Abstract: We show how the maximum force principle can be derived from the holographic\nprinciple and vice versa, thus demonstrating equivalence of the two principles. \n\n"}
{"id": "1507.02874", "contents": "Title: On the Public Communication Needed to Achieve SK Capacity in the\n  Multiterminal Source Model Abstract: The focus of this paper is on the public communication required for\ngenerating a maximal-rate secret key (SK) within the multiterminal source model\nof Csisz{\\'a}r and Narayan. Building on the prior work of Tyagi for the\ntwo-terminal scenario, we derive a lower bound on the communication complexity,\n$R_{\\text{SK}}$, defined to be the minimum rate of public communication needed\nto generate a maximal-rate SK. It is well known that the minimum rate of\ncommunication for omniscience, denoted by $R_{\\text{CO}}$, is an upper bound on\n$R_{\\text{SK}}$. For the class of pairwise independent network (PIN) models\ndefined on uniform hypergraphs, we show that a certain \"Type $\\mathcal{S}$\"\ncondition, which is verifiable in polynomial time, guarantees that our lower\nbound on $R_{\\text{SK}}$ meets the $R_{\\text{CO}}$ upper bound. Thus, PIN\nmodels satisfying our condition are $R_{\\text{SK}}$-maximal, meaning that the\nupper bound $R_{\\text{SK}} \\le R_{\\text{CO}}$ holds with equality. This allows\nus to explicitly evaluate $R_{\\text{SK}}$ for such PIN models. We also give\nseveral examples of PIN models that satisfy our Type $\\mathcal S$ condition.\nFinally, we prove that for an arbitrary multiterminal source model, a stricter\nversion of our Type $\\mathcal S$ condition implies that communication from\n\\emph{all} terminals (\"omnivocality\") is needed for establishing a SK of\nmaximum rate. For three-terminal source models, the converse is also true:\nomnivocality is needed for generating a maximal-rate SK only if the strict Type\n$\\mathcal S$ condition is satisfied. Counterexamples exist that show that the\nconverse is not true in general for source models with four or more terminals. \n\n"}
{"id": "1507.06737", "contents": "Title: The Degrees of Freedom of the Interference Channel with a Cognitive\n  Relay under Delayed Feedback Abstract: This paper studies the interference channel with a cognitive relay (ICCR)\nunder delayed feedback. Three types of delayed feedback are studied: delayed\nchannel state information at the transmitter (CSIT), delayed output feedback,\nand delayed Shannon feedback. Outer bounds are derived for the DoF region of\nthe two-user multiple-input multiple-output (MIMO) ICCR with delayed feedback\nas well as without feedback. For the single-input single-output (SISO)\nscenario, optimal schemes are proposed based on retrospective interference\nalignment. It is shown that while a cognitive relay without feedback cannot\nextend the sum-DoF beyond $1$ in the two-user SISO interference channel,\ndelayed feedback in the same scenario can extend the sum-DoF to $4/3$. For the\nMIMO case, achievable schemes are obtained via extensions of retrospective\ninterference alignment, leading to DoF regions that meet the respective upper\nbounds. \n\n"}
{"id": "1507.07395", "contents": "Title: Almost universal codes achieving ergodic MIMO capacity within a constant\n  gap Abstract: This work addresses the question of achieving capacity with lattice codes in\nmulti-antenna block fading channels when the number of fading blocks tends to\ninfinity. A design criterion based on the normalized minimum determinant is\nproposed for division algebra multiblock space-time codes over fading channels;\nthis plays a similar role to the Hermite invariant for Gaussian channels. It is\nshown that this criterion is sufficient to guarantee transmission rates within\na constant gap from capacity both for slow fading channels and ergodic fading\nchannels. This performance is achieved both under maximum likelihood decoding\nand naive lattice decoding. In the case of independent identically distributed\nRayleigh fading, it is also shown that the error probability vanishes\nexponentially fast. In contrast to the standard approach in the literature\nwhich employs random lattice ensembles, the existence results in this paper are\nderived from number theory. First the gap to capacity is shown to depend on the\ndiscriminant of the chosen division algebra; then class field theory is applied\nto build families of algebras with small discriminants. The key element in the\nconstruction is the choice of a sequence of division algebras whose centers are\nnumber fields with small root discriminants. \n\n"}
{"id": "1508.02015", "contents": "Title: On cyclic DNA codes over the Ring $\\Z_4 + u \\Z_4$ Abstract: In this paper, we study the theory for constructing DNA cyclic codes of odd\nlength over $\\Z_4[u]/\\langle u^2 \\rangle$ which play an important role in DNA\ncomputing. Cyclic codes of odd length over $\\Z_4 + u \\Z_4$ satisfy the reverse\nconstraint and the reverse-complement constraint are studied in this paper. The\nstructure and existence of such codes are also studied. The paper concludes\nwith some DNA example obtained via the family of cyclic codes. \n\n"}
{"id": "1508.04030", "contents": "Title: Performance Characterization of Relay-Assisted Wireless Optical CDMA\n  Networks in Turbulent Underwater Channel Abstract: In this paper, we characterize the performance of relay-assisted underwater\nwireless optical code division multiple access (OCDMA) networks over turbulent\nchannels. In addition to scattering and absorption effects of underwater\nchannels, we also consider optical turbulence as a log-normal fading\ncoefficient in our analysis. To simultaneously and asynchronously share medium\namong many users, we assign a unique optical orthogonal code (OOC) to each user\nin order to actualize OCDMA-based underwater network. The most significant\nchallenge in underwater optical communication is in the ability to extend the\nshort range of its coverage. In order to expand the viable communication range,\nwe consider multi-hop transmission to the destination. Moreover, we evaluate\nthe performance of a relay-assisted point-to-point UWOC system as a special\ncase of the proposed relay-assisted OCDMA network. Our numerical results\nindicate significant performance improvement by employing intermediate relays,\ne.g., one can achieve $32$ {dB} improvement in the bit error rate (BER) of\n$10^{-6}$ using only a dual-hop transmission in a $90$ {m} point-to-point clear\nocean link. \n\n"}
{"id": "1508.04726", "contents": "Title: A Lower Bound on the per Soliton Capacity of the Nonlinear Optical Fibre\n  Channel Abstract: A closed-form expression for a lower bound on the per soliton capacity of the\nnonlinear optical fibre channel in the presence of (optical) amplifier\nspontaneous emission (ASE) noise is derived. This bound is based on a\nnon-Gaussian conditional probability density function for the soliton amplitude\njitter induced by the ASE noise and is proven to grow logarithmically as the\nsignal-to-noise ratio increases. \n\n"}
{"id": "1508.05538", "contents": "Title: Optimal Algorithms and Lower Bounds for Testing Closeness of Structured\n  Distributions Abstract: We give a general unified method that can be used for $L_1$ {\\em closeness\ntesting} of a wide range of univariate structured distribution families. More\nspecifically, we design a sample optimal and computationally efficient\nalgorithm for testing the equivalence of two unknown (potentially arbitrary)\nunivariate distributions under the $\\mathcal{A}_k$-distance metric: Given\nsample access to distributions with density functions $p, q: I \\to \\mathbb{R}$,\nwe want to distinguish between the cases that $p=q$ and\n$\\|p-q\\|_{\\mathcal{A}_k} \\ge \\epsilon$ with probability at least $2/3$. We show\nthat for any $k \\ge 2, \\epsilon>0$, the {\\em optimal} sample complexity of the\n$\\mathcal{A}_k$-closeness testing problem is $\\Theta(\\max\\{\nk^{4/5}/\\epsilon^{6/5}, k^{1/2}/\\epsilon^2 \\})$. This is the first $o(k)$\nsample algorithm for this problem, and yields new, simple $L_1$ closeness\ntesters, in most cases with optimal sample complexity, for broad classes of\nstructured distributions. \n\n"}
{"id": "1508.06369", "contents": "Title: Wireless Communications in the Era of Big Data Abstract: The rapidly growing wave of wireless data service is pushing against the\nboundary of our communication network's processing power. The pervasive and\nexponentially increasing data traffic present imminent challenges to all the\naspects of the wireless system design, such as spectrum efficiency, computing\ncapabilities and fronthaul/backhaul link capacity. In this article, we discuss\nthe challenges and opportunities in the design of scalable wireless systems to\nembrace such a \"bigdata\" era. On one hand, we review the state-of-the-art\nnetworking architectures and signal processing techniques adaptable for\nmanaging the bigdata traffic in wireless networks. On the other hand, instead\nof viewing mobile bigdata as a unwanted burden, we introduce methods to\ncapitalize from the vast data traffic, for building a bigdata-aware wireless\nnetwork with better wireless service quality and new mobile applications. We\nhighlight several promising future research directions for wireless\ncommunications in the mobile bigdata era. \n\n"}
{"id": "1508.07590", "contents": "Title: New Classes of Permutation Binomials and Permutation Trinomials over\n  Finite Fields Abstract: Permutation polynomials over finite fields play important roles in finite\nfields theory. They also have wide applications in many areas of science and\nengineering such as coding theory, cryptography, combinatorial design,\ncommunication theory and so on. Permutation binomials and trinomials attract\npeople's interest due to their simple algebraic form and additional\nextraordinary properties. In this paper, several new classes of permutation\nbinomials and permutation trinomials are constructed. Some of these permutation\npolynomials are generalizations of known ones. \n\n"}
{"id": "1509.01187", "contents": "Title: Unmanned Aerial Vehicle with Underlaid Device-to-Device Communications:\n  Performance and Tradeoffs Abstract: In this paper, the deployment of an unmanned aerial vehicle (UAV) as a flying\nbase station used to provide on the fly wireless communications to a given\ngeographical area is analyzed. In particular, the co-existence between the UAV,\nthat is transmitting data in the downlink, and an underlaid device-todevice\n(D2D) communication network is considered. For this model, a tractable\nanalytical framework for the coverage and rate analysis is derived. Two\nscenarios are considered: a static UAV and a mobile UAV. In the first scenario,\nthe average coverage probability and the system sum-rate for the users in the\narea are derived as a function of the UAV altitude and the number of D2D users.\nIn the second scenario, using the disk covering problem, the minimum number of\nstop points that the UAV needs to visit in order to completely cover the area\nis computed. Furthermore, considering multiple retransmissions for the UAV and\nD2D users, the overall outage probability of the D2D users is derived.\nSimulation and analytical results show that, depending on the density of D2D\nusers, optimal values for the UAV altitude exist for which the system sum-rate\nand the coverage probability are maximized. Moreover, our results also show\nthat, by enabling the UAV to intelligently move over the target area, the total\nrequired transmit power of UAV while covering the entire area, is minimized.\nFinally, in order to provide a full coverage for the area of interest, the\ntradeoff between the coverage and delay, in terms of the number of stop points,\nis discussed. \n\n"}
{"id": "1509.02427", "contents": "Title: Approximate Message Passing in Coded Aperture Snapshot Spectral Imaging Abstract: We consider a compressive hyperspectral imaging reconstruction problem, where\nthree-dimensional spatio-spectral information about a scene is sensed by a\ncoded aperture snapshot spectral imager (CASSI). The approximate message\npassing (AMP) framework is utilized to reconstruct hyperspectral images from\nCASSI measurements, and an adaptive Wiener filter is employed as a\nthree-dimensional image denoiser within AMP. We call our algorithm\n\"AMP-3D-Wiener.\" The simulation results show that AMP-3D-Wiener outperforms\nexisting widely-used algorithms such as gradient projection for sparse\nreconstruction (GPSR) and two-step iterative shrinkage/thresholding (TwIST)\ngiven the same amount of runtime. Moreover, in contrast to GPSR and TwIST,\nAMP-3D-Wiener need not tune any parameters, which simplifies the reconstruction\nprocess. \n\n"}
{"id": "1509.03000", "contents": "Title: Full-Duplex Transceiver for Future Cellular Network: A Smart Antenna\n  Approach Abstract: In this paper, we propose a transceiver architecture for full-duplex (FD)\neNodeB (eNB) and FD user equipment (UE) transceiver. For FD\ncommunication,.i.e., simultaneous in-band uplink and downlink operation, same\nsubcarriers can be allocated to UE in both uplink and downlink. Hence, contrary\nto traditional LTE, we propose using single-carrier frequency division multiple\naccesses (SC-FDMA) for downlink along with the conventional method of using it\nfor uplink. The use of multiple antennas at eNB and singular value\ndecomposition (SVD) in the downlink allows multiple users (MU) to operate on\nthe same set of ubcarriers. In the uplink, successive interference cancellation\nwith optimal ordering (SSIC-OO) algorithm is used to decouple signals of UEs\noperating in the same set of subcarriers. A smart antenna approach is adopted\nwhich prevents interference, in downlink of a UE, from uplink signals of other\nUEs sharing same subcarriers. The approach includes using multiple antennas at\nUEs to form directed beams towards eNode and nulls towards other UEs. The\nproposed architecture results in significant improvement of the overall\nspectrum efficiency per cell of the cellular network. \n\n"}
{"id": "1509.06253", "contents": "Title: Convergence of the Generalized Alternating Projection Algorithm for\n  Compressive Sensing Abstract: The convergence of the generalized alternating projection (GAP) algorithm is\nstudied in this paper to solve the compressive sensing problem $\\yv = \\Amat \\xv\n+ \\epsilonv$. By assuming that $\\Amat\\Amat\\ts$ is invertible, we prove that GAP\nconverges linearly within a certain range of step-size when the sensing matrix\n$\\Amat$ satisfies restricted isometry property (RIP) condition of\n$\\delta_{2K}$, where $K$ is the sparsity of $\\xv$. The theoretical analysis is\nextended to the adaptively iterative thresholding (AIT) algorithms, for which\nthe convergence rate is also derived based on $\\delta_{2K}$ of the sensing\nmatrix. We further prove that, under the same conditions, the convergence rate\nof GAP is faster than that of AIT. Extensive simulation results confirm the\ntheoretical assertions. \n\n"}
{"id": "1510.00661", "contents": "Title: HTML5 Zero Configuration Covert Channels: Security Risks and Challenges Abstract: In recent months there has been an increase in the popularity and public\nawareness of secure, cloudless file transfer systems. The aim of these services\nis to facilitate the secure transfer of files in a peer-to- peer (P2P) fashion\nover the Internet without the need for centralised authentication or storage.\nThese services can take the form of client installed applications or entirely\nweb browser based interfaces. Due to their P2P nature, there is generally no\nlimit to the file sizes involved or to the volume of data transmitted - and\nwhere these limitations do exist they will be purely reliant on the capacities\nof the systems at either end of the transfer. By default, many of these\nservices provide seamless, end-to-end encryption to their users. The\ncybersecurity and cyberforensic consequences of the potential criminal use of\nsuch services are significant. The ability to easily transfer encrypted data\nover the Internet opens up a range of opportunities for illegal use to\ncybercriminals requiring minimal technical know-how. This paper explores a\nnumber of these services and provides an analysis of the risks they pose to\ncorporate and governmental security. A number of methods for the forensic\ninvestigation of such transfers are discussed. \n\n"}
{"id": "1510.03510", "contents": "Title: Repeat-Accumulate Codes for Reconciliation in Continuous Variable\n  Quantum Key Distribution Abstract: This paper investigates the design of low-complexity error correction codes\nfor the verification step in continuous variable quantum key distribution\n(CVQKD) systems. We design new coding schemes based on quasi-cyclic\nrepeat-accumulate codes which demonstrate good performances for CVQKD\nreconciliation. \n\n"}
{"id": "1510.06454", "contents": "Title: Many Access for Small Packets Based on Precoding and Sparsity-aware\n  Recovery Abstract: Modern mobile terminals produce massive small data packets. For these\nshort-length packets, it is inefficient to follow the current multiple access\nschemes to allocate transmission resources due to heavy signaling overhead. We\npropose a non-orthogonal many-access scheme that is well suited for the future\ncommunication systems equipped with many receive antennas. The system is\nmodeled as having a block-sparsity pattern with unknown sparsity level (i.e.,\nunknown number of transmitted messages). Block precoding is employed at each\nsingle-antenna transmitter to enable the simultaneous transmissions of many\nusers. The number of simultaneously served active users is allowed to be even\nmore than the number of receive antennas. Sparsity-aware recovery is designed\nat the receiver for joint user detection and symbol demodulation. To reduce the\neffects of channel fading on signal recovery, normalized block orthogonal\nmatching pursuit (BOMP) algorithm is introduced, and based on its approximate\nperformance analysis, we develop interference cancellation based BOMP (ICBOMP)\nalgorithm. The ICBOMP performs error correction and detection in each iteration\nof the normalized BOMP. Simulation results demonstrate the effectiveness of the\nproposed scheme in small packet services, as well as the advantages of ICBOMP\nin improving signal recovery accuracy and reducing computational cost. \n\n"}
{"id": "1510.07713", "contents": "Title: Phase Retrieval: An Overview of Recent Developments Abstract: The problem of phase retrieval is a classic one in optics and arises when one\nis interested in recovering an unknown signal from the magnitude (intensity) of\nits Fourier transform. While there have existed quite a few approaches to phase\nretrieval, recent developments in compressed sensing and convex\noptimization-based signal recovery have inspired a host of new ones. This work\npresents an overview of these approaches.\n  Since phase retrieval, by its very nature, is ill-posed, to make the problem\nmeaningful one needs to either assume prior structure on the signal (e.g.,\nsparsity) or obtain additional measurements (e.g., masks, structured\nilluminations). For both the cases, we review conditions for the\nidentifiability of the signal, as well as practical algorithms for signal\nrecovery. In particular, we demonstrate that it is possible to robustly and\nefficiently identify an unknown signal solely from phaseless Fourier\nmeasurements, a fact with potentially far-reaching implications. \n\n"}
{"id": "1510.07930", "contents": "Title: Interplay Between Delayed CSIT and Network Topology for Secure MISO BC Abstract: We study the problem of secure transmission over a Gaussian two-user\nmulti-input single-output (MISO) broadcast channel under the assumption that\nlinks connecting the transmitter to the two receivers may have unequal strength\nstatistically. In addition to this, the state of the channel to each receiver\nis conveyed in a strictly causal manner to the transmitter. We focus on a two\nstate topological setting of strong v.s. weak links. Under these assumptions,\nwe first consider the MISO wiretap channel and establish bounds on generalized\nsecure degrees of freedom (GSDoF). Next, we extend this model to the two-user\nMISO broadcast channel and establish inner and outer bounds on GSDoF region\nwith different topology states. The encoding scheme sheds light on the usage of\nboth resources, i.e., topology of the model and strictly causal channel state\ninformation at the transmitter (CSIT); and, allows digitization and\nmulti-casting of overheard side information, while transmitting confidential\nmessage over the stronger link. Furthermore, for a special class of channels,\nwe show that the established bounds agree and so we characterize the sum GSDoF. \n\n"}
{"id": "1510.07932", "contents": "Title: Downlink Power Control in Two-Tier Cellular Networks with\n  Energy-Harvesting Small Cells as Stochastic Games Abstract: Energy harvesting in cellular networks is an emerging technique to enhance\nthe sustainability of power-constrained wireless devices. This paper considers\nthe co-channel deployment of a macrocell overlaid with small cells. The small\ncell base stations (SBSs) harvest energy from environmental sources whereas the\nmacrocell base station (MBS) uses conventional power supply. Given a stochastic\nenergy arrival process for the SBSs, we derive a power control policy for the\ndownlink transmission of both MBS and SBSs such that they can achieve their\nobjectives (e.g., maintain the signal-to-interference-plus-noise ratio (SINR)\nat an acceptable level) on a given transmission channel. We consider a\ncentralized energy harvesting mechanism for SBSs, i.e., there is a central\nenergy storage (CES) where energy is harvested and then distributed to the\nSBSs. When the number of SBSs is small, the game between the CES and the MBS is\nmodeled as a single-controller stochastic game and the equilibrium policies are\nobtained as a solution of a quadratic programming problem. However, when the\nnumber of SBSs tends to infinity (i.e., a highly dense network), the\ncentralized scheme becomes infeasible, and therefore, we use a mean field\nstochastic game to obtain a distributed power control policy for each SBS. By\nsolving a system of partial differential equations, we derive the power control\npolicy of SBSs given the knowledge of mean field distribution and the available\nharvested energy levels in the batteries of the SBSs. \n\n"}
{"id": "1511.00353", "contents": "Title: Universally Near Optimal Online Power Control for Energy Harvesting\n  Nodes Abstract: We consider online power control for an energy harvesting system with random\ni.i.d. energy arrivals and a finite size battery. We propose a simple online\npower control policy for this channel that requires minimal information\nregarding the distribution of the energy arrivals and prove that it is\nuniversally near-optimal for all parameter values. In particular, the policy\ndepends on the distribution of the energy arrival process only through its mean\nand it achieves the optimal long-term average throughput of the channel within\nboth constant additive and multiplicative gaps. Existing heuristics for online\npower control fail to achieve such universal performance. This result also\nallows us to approximate the long-term average throughput of the system with a\nsimple formula, which sheds some light on the qualitative behavior of the\nthroughput, namely how it depends on the distribution of the energy arrivals\nand the size of the battery. \n\n"}
{"id": "1511.02307", "contents": "Title: On the Capacity Achieving Probability Measures for Molecular Receivers Abstract: In this paper, diffusion-based molecular commu- nication with ligand receptor\nreceivers is studied. Information messages are assumed to be encoded via\nvariations of the con- centration of molecules. The randomness in the ligand\nreception process induces uncertainty in the communication; limiting the rate\nof information decoding. We model the ligand receptor receiver by a set of\nfinite-state Markov channels and study the general capacity of such a receiver.\nFurthermore, the i.i.d. capacity of the receiver is characterized as a lower\nbound for the general capacity. It is also proved that a finite support\nprobability measure can achieve the i.i.d. capacity of the receiver. Moreover,\na bound on the number of points in the support of the probability measure is\nobtained. \n\n"}
{"id": "1511.03350", "contents": "Title: A Stochastic Geometry Analysis of Large-scale Cooperative Wireless\n  Networks Powered by Energy Harvesting Abstract: Energy harvesting is a technology for enabling green, sustainable, and\nautonomous wireless networks. In this paper, a large-scale wireless network\nwith energy harvesting transmitters is considered, where a group of\ntransmitters forms a cluster to cooperatively serve a desired receiver amid\ninterference and noise. To characterize the link-level performance, closed-form\nexpressions are derived for the transmission success probability at a receiver\nin terms of key parameters such as node densities, energy harvesting\nparameters, channel parameters, and cluster size, for a given cluster geometry.\nThe analysis is further extended to characterize a network-level performance\nmetric, capturing the tradeoff between link quality and the fraction of\nreceivers served. Numerical simulations validate the accuracy of the analytical\nmodel. Several useful insights are provided. For example, while more\ncooperation helps improve the link-level performance, the network-level\nperformance might degrade with the cluster size. Numerical results show that a\nsmall cluster size (typically 3 or smaller) optimizes the network-level\nperformance. Furthermore, substantial performance can be extracted with a\nrelatively small energy buffer. Moreover, the utility of having a large energy\nbuffer increases with the energy harvesting rate as well as with the cluster\nsize in sufficiently dense networks. \n\n"}
{"id": "1511.03829", "contents": "Title: Secure Numerical and Logical Multi Party Operations Abstract: We derive algorithms for efficient secure numerical and logical operations\nusing a recently introduced scheme for secure multi-party\ncomputation~\\cite{sch15} in the semi-honest model ensuring statistical or\nperfect security. To derive our algorithms for trigonometric functions, we use\nbasic mathematical laws in combination with properties of the additive\nencryption scheme in a novel way. For division and logarithm we use a new\napproach to compute a Taylor series at a fixed point for all numbers. All our\nlogical operations such as comparisons and large fan-in AND gates are perfectly\nsecure. Our empirical evaluation yields speed-ups of more than a factor of 100\nfor the evaluated operations compared to the state-of-the-art. \n\n"}
{"id": "1511.04763", "contents": "Title: Evaluation of Channel Assignment Performance Prediction Techniques in\n  Random Wireless Mesh Networks Abstract: Performance of wireless mesh networks (WMNs) in terms of network capacity,\nend-to-end latency, and network resilience depends upon the prevalent levels of\ninterference. Thus, interference alleviation is a fundamental design concern in\nmulti-radio multi-channel (MRMC) WMNs, and is achieved through a judicious\nchannel assignment (CA) to the radios in a WMN. In our earlier works we have\ntried to address the problem of estimating the intensity of interference in a\nwireless network and predicting the performance of CA schemes based on the\nmeasure of the interference estimate. We have proposed reliable CA performance\nprediction approaches which have proven effective in grid WMNs. In this work,\nwe further assess the reliability of these CA performance prediction techniques\nin a large MRMC WMN which comprises of randomly placed mesh routers. We perform\nexhaustive simulations on an ns-3 802.11n environment. We obtain conclusive\nresults to demonstrate the efficacy of proposed schemes in random WMNs as well. \n\n"}
{"id": "1511.06149", "contents": "Title: Blind Recovery of Sparse Signals from Subsampled Convolution Abstract: Subsampled blind deconvolution is the recovery of two unknown signals from\nsamples of their convolution. To overcome the ill-posedness of this problem,\nsolutions based on priors tailored to specific application have been developed\nin practical applications. In particular, sparsity models have provided\npromising priors. However, in spite of empirical success of these methods in\nmany applications, existing analyses are rather limited in two main ways: by\ndisparity between the theoretical assumptions on the signal and/or measurement\nmodel versus practical setups; or by failure to provide a performance guarantee\nfor parameter values within the optimal regime defined by the information\ntheoretic limits. In particular, it has been shown that a naive sparsity model\nis not a strong enough prior for identifiability in the blind deconvolution\nproblem. Instead, in addition to sparsity, we adopt a conic constraint, which\nenforces spectral flatness of the signals. Under this prior, we provide an\niterative algorithm that achieves guaranteed performance in blind deconvolution\nat near optimal sample complexity. Numerical results show the empirical\nperformance of the iterative algorithm agrees with the performance guarantee. \n\n"}
{"id": "1511.06253", "contents": "Title: Diffusing Private Data over Networks Abstract: The emergence of social and technological networks has enabled rapid sharing\nof data and information. This has resulted in significant privacy concerns\nwhere private information can be either leaked or inferred from public data.\nThe problem is significantly harder for social networks where we may reveal\nmore information to our friends than to strangers. Nonetheless, our private\ninformation can still leak to strangers as our friends are their friends and so\non. In order to address this important challenge, in this paper, we present a\nprivacy-preserving mechanism that enables private data to be diffused over a\nnetwork. In particular, whenever a user wants to access another users' data,\nthe proposed mechanism returns a differentially private response that ensures\nthat the amount of private data leaked depends on the distance between the two\nusers in the network. While allowing global statistics to be inferred by users\nacting as analysts, our mechanism guarantees that no individual user, or a\ngroup of users, can harm the privacy guarantees of any other user. We\nillustrate our mechanism with two examples: one on synthetic data where the\nusers share their GPS coordinates; and one on a Facebook ego-network where a\nuser shares her infection status. \n\n"}
{"id": "1511.07542", "contents": "Title: Caching-Aided Coded Multicasting with Multiple Random Requests Abstract: The capacity of caching networks has received considerable attention in the\npast few years. A particularly studied setting is the shared link caching\nnetwork, in which a single source with access to a file library communicates\nwith multiple users, each having the capability to store segments (packets) of\nthe library files, over a shared multicast link. Each user requests one file\nfrom the library according to a common demand distribution and the server sends\na coded multicast message to satisfy all users at once. The problem consists of\nfinding the smallest possible average codeword length to satisfy such requests.\nIn this paper, we consider the generalization to the case where each user\nplaces L >= 1 independent requests according to the same common demand\ndistribution. We propose an achievable scheme based on random vector\n(packetized) caching placement and multiple groupcast index coding, shown to be\norder-optimal in the asymptotic regime in which the number of packets per file\nB goes to infinity. We then show that the scalar (B = 1) version of the\nproposed scheme can still preserve order-optimality when the number of per-user\nrequests L is large enough. Our results provide the first order-optimal\ncharacterization of the shared link caching network with multiple random\nrequests, revealing the key effects of L on the performance of caching-aided\ncoded multicast schemes. \n\n"}
{"id": "1512.00156", "contents": "Title: Covariance-domain Dictionary Learning for Overcomplete EEG Source\n  Identification Abstract: We propose an algorithm targeting the identification of more sources than\nchannels for electroencephalography (EEG). Our overcomplete source\nidentification algorithm, Cov-DL, leverages dictionary learning methods applied\nin the covariance-domain. Assuming that EEG sources are uncorrelated within\nmoving time-windows and the scalp mixing is linear, the forward problem can be\ntransferred to the covariance domain which has higher dimensionality than the\noriginal EEG channel domain. This allows for learning the overcomplete mixing\nmatrix that generates the scalp EEG even when there may be more sources than\nsensors active at any time segment, i.e. when there are non-sparse sources.\nThis is contrary to straight-forward dictionary learning methods that are based\non the assumption of sparsity, which is not a satisfied condition in the case\nof low-density EEG systems. We present two different learning strategies for\nCov-DL, determined by the size of the target mixing matrix. We demonstrate that\nCov-DL outperforms existing overcomplete ICA algorithms under various scenarios\nof EEG simulations and real EEG experiments. \n\n"}
{"id": "1512.00259", "contents": "Title: NetCodCCN: a Network Coding approach for Content-Centric Networks Abstract: Content-Centric Networking (CCN) naturally supports multi-path communication,\nas it allows the simultaneous use of multiple interfaces (e.g. LTE and WiFi).\nWhen multiple sources and multiple clients are considered, the optimal set of\ndistribution trees should be determined in order to optimally use all the\navailable interfaces. This is not a trivial task, as it is a computationally\nintense procedure that should be done centrally. The need for central\ncoordination can be removed by employing network coding, which also offers\nimproved resiliency to errors and large throughput gains. In this paper, we\npropose NetCodCCN, a protocol for integrating network coding in CCN. In\ncomparison to previous works proposing to enable network coding in CCN,\nNetCodCCN permit Interest aggregation and Interest pipelining, which reduce the\ndata retrieval times. The experimental evaluation shows that the proposed\nprotocol leads to significant improvements in terms of content retrieval delay\ncompared to the original CCN. Our results demonstrate that the use of network\ncoding adds robustness to losses and permits to exploit more efficiently the\navailable network resources. The performance gains are verified for content\nretrieval in various network scenarios. \n\n"}
{"id": "1512.02592", "contents": "Title: The minimum volume of subspace trades Abstract: A subspace bitrade of type $T_q(t,k,v)$ is a pair $(T_0,T_1)$ of two disjoint\nnonempty collections of $k$-dimensional subspaces of a $v$-dimensional space\n$V$ over the finite field of order $q$ such that every $t$-dimensional subspace\nof $V$ is covered by the same number of subspaces from $T_0$ and $T_1$. In a\nprevious paper, the minimum cardinality of a subspace $T_q(t,t+1,v)$ bitrade\nwas established. We generalize that result by showing that for admissible $v$,\n$t$, and $k$, the minimum cardinality of a subspace $T_q(t,k,v)$ bitrade does\nnot depend on $k$. An example of a minimum bitrade is represented using\ngenerator matrices in the reduced echelon form. For $t=1$, the uniqueness of a\nminimum bitrade is proved. \n\n"}
{"id": "1512.05486", "contents": "Title: When the extension property does not hold Abstract: A complete extension theorem for linear codes over a module alphabet and the\nsymmetrized weight composition is proved. It is shown that an extension\nproperty with respect to arbitrary weight function does not hold for module\nalphabets with a noncyclic socle. \n\n"}
{"id": "1512.06298", "contents": "Title: Streaming Data Transmission in the Moderate Deviations and Central Limit\n  Regimes Abstract: We consider streaming data transmission over a discrete memoryless channel. A\nnew message is given to the encoder at the beginning of each block and the\ndecoder decodes each message sequentially, after a delay of $T$ blocks. In this\nstreaming setup, we study the fundamental interplay between the rate and error\nprobability in the central limit and moderate deviations regimes and show that\ni) in the moderate deviations regime, the moderate deviations constant improves\nover the block coding or non-streaming setup by a factor of $T$ and ii) in the\ncentral limit regime, the second-order coding rate improves by a factor of\napproximately $\\sqrt{T}$ for a wide range of channel parameters. For both\nregimes, we propose coding techniques that incorporate a joint encoding of\nfresh and previous messages. In particular, for the central limit regime, we\npropose a coding technique with truncated memory to ensure that a summation of\nconstants, which arises as a result of applications of the central limit\ntheorem, does not diverge in the error analysis.\n  Furthermore, we explore interesting variants of the basic streaming setup in\nthe moderate deviations regime. We first consider a scenario with an erasure\noption at the decoder and show that both the exponents of the total error and\nthe undetected error probabilities improve by factors of $T$. Next, by\nutilizing the erasure option, we show that the exponent of the total error\nprobability can be improved to that of the undetected error probability (in the\norder sense) at the expense of a variable decoding delay. Finally, we also\nextend our results to the case where the message rate is not fixed but\nalternates between two values. \n\n"}
{"id": "1512.06667", "contents": "Title: Polynomially Solvable Instances of the Shortest and Closest Vector\n  Problems with Applications to Compute-and-Forward Abstract: A particular instance of the Shortest Vector Problem (SVP) appears in the\ncontext of Compute-and-Forward. Despite the NP-hardness of the SVP, we will\nshow that this certain instance can be solved in complexity order\n$O(n\\psi\\log(n\\psi))$ where $\\psi = \\sqrt{P\\|{\\bf h}\\|^2+1}$ depends on the\ntransmission power and the norm of the channel vector. We will then extend our\nresults to Integer-Forcing and finally, introduce a more general class of\nlattices for which the SVP and the and the Closest Vector Problem (CVP) can be\napproximated within a constant factor. \n\n"}
{"id": "1512.07347", "contents": "Title: Galois Self-Dual Constacyclic Codes Abstract: Generalizing Euclidean inner product and Hermitian inner product, we\nintroduce Galois inner products, and study the Galois self-dual constacyclic\ncodes in a very general setting by a uniform method. The conditions for\nexistence of Galois self-dual and isometrically Galois self-dual constacyclic\ncodes are obtained. As consequences, the results on self-dual, iso-dual and\nHermitian self-dual constacyclic codes are derived. \n\n"}
{"id": "1512.07743", "contents": "Title: Cloud Radio Access Network: Virtualizing Wireless Access for Dense\n  Heterogeneous Systems Abstract: Cloud Radio Access Network (C-RAN) refers to the virtualization of base\nstation functionalities by means of cloud computing. This results in a novel\ncellular architecture in which low-cost wireless access points, known as radio\nunits (RUs) or remote radio heads (RRHs), are centrally managed by a\nreconfigurable centralized \"cloud\", or central, unit (CU). C-RAN allows\noperators to reduce the capital and operating expenses needed to deploy and\nmaintain dense heterogeneous networks. This critical advantage, along with\nspectral efficiency, statistical multiplexing and load balancing gains, make\nC-RAN well positioned to be one of the key technologies in the development of\n5G systems. In this paper, a succinct overview is presented regarding the state\nof the art on the research on C-RAN with emphasis on fronthaul compression,\nbaseband processing, medium access control, resource allocation, system-level\nconsiderations and standardization efforts. \n\n"}
{"id": "1601.02082", "contents": "Title: Mixed-ADC Massive MIMO Uplink in Frequency-Selective Channels Abstract: The aim of this paper is to investigate the recently developed mixed-ADC\narchitecture for frequency-selective channels. Multi-carrier techniques such as\northogonal frequency division multiplexing (OFDM) are employed to handle\ninter-symbol interference (ISI). A frequency-domain equalizer is designed for\nmitigating the inter-carrier interference (ICI) introduced by the nonlinearity\nof one-bit quantization. For static single-input-multiple-output (SIMO)\nchannels, a closed-form expression of the generalized mutual information (GMI)\nis derived, and based on which the linear frequency-domain equalizer is\noptimized. The analysis is then extended to ergodic time-varying SIMO channels\nwith estimated channel state information (CSI), where numerically tight lower\nand upper bounds of the GMI are derived. The analytical framework is naturally\napplicable to the multi-user scenario, for both static and time-varying\nchannels. Extensive numerical studies reveal that the mixed-ADC architecture\nwith a small proportion of high-resolution ADCs does achieve a dominant portion\nof the achievable rate of ideal conventional architecture, and that it\nremarkably improves the performance as compared with one-bit massive MIMO. \n\n"}
{"id": "1601.03468", "contents": "Title: Energy Harvesting in Secure MIMO Systems Abstract: The problems of energy harvesting in wireless com- munication systems have\nrecently drawn much attention. In this paper, we focus on the investigation of\nenergy harvesting maximization (EHM) in the important secrecy multi-input\nmulti- output (MIMO) systems where little research has been done due to their\ncomplexity. Particularly, this paper studies the resource allocation strategies\nin MIMO wiretap channels, wherein we attempt to maximize the harvested energy\nby one or multiple multi-antenna energy receivers (ERs) (potential\neavesdropper) while guaranteeing the secure communication for the multi-\nantenna information receiver (IR). Two types of IR, with and without the\ncapability to cancel the interference from energy signals, are taken into\naccount. In the scenario of single energy receiver (ER), we consider the joint\ndesign of the transmis- sion information and energy covariances for EHM. Both\nof the optimization problems for the two types of IR are non- convex, and\nappear to be difficult. To circumvent them, the combination of first order\nTaylor approximation and sequential convex optimization approach is proposed.\nThen, we extend our attention to the scenario with multiple ERs, where the\nartificial noise (AN) aided weighted sum-energy harvesting maximization\n(WS-EHM) problem is considered. Other than the approaches adopted in solving\nthe EHM problems, an algorithm conducts in an alternating fashion is proposed\nto handle this problem. In particular, we first perform a judicious\ntransformation of the WS- EHM problem. Then, a block Gauss-Seidel (GS)\nalgorithm based on logarithmic barrier method and gradient projection (GP) is\nderived to obtain the optimal solution of the reformulation by solving convex\nproblems alternately. Furthermore, the resulting block GS method is proven to\nconverge to a Karush-Kuhn-Tucker (KKT) point of the original WS-EHM problem... \n\n"}
{"id": "1601.03617", "contents": "Title: Interactive Communication for Data Exchange Abstract: Two parties observing correlated data seek to exchange their data using\ninteractive communication. How many bits must they communicate? We propose a\nnew interactive protocol for data exchange which increases the communication\nsize in steps until the task is done. Next, we derive a lower bound on the\nminimum number of bits that is based on relating the data exchange problem to\nthe secret key agreement problem. Our single-shot analysis applies to all\ndiscrete random variables and yields upper and lower bound of a similar form.\nIn fact, the bounds are asymptotically tight and lead to a characterization of\nthe optimal rate of communication needed for data exchange for a general\nsequence such as mixture of IID random variables as well as the optimal\nsecond-order asymptotic term in the length of communication needed for data\nexchange for the IID random variables, when the probability of error is fixed.\nThis gives a precise characterization of the asymptotic reduction in the length\nof optimal communication due to interaction; in particular, two-sided\nSlepian-Wolf compression is strictly suboptimal. \n\n"}
{"id": "1601.03763", "contents": "Title: Compressed Sensing-based Pilot Assignment and Reuse for Mobile UEs in\n  mmWave Cellular Systems Abstract: Technologies for mmWave communication are at the forefront of investigations\nin both industry and academia, as the mmWave band offers the promise of orders\nof magnitude additional available bandwidths to what has already been allocated\nto cellular networks. The much larger number of antennas that can be supported\nin a small footprint at mmWave bands can be leveraged to harvest massive-MIMO\ntype beamforming and spatial multiplexing gains. Similar to LTE systems, two\nprerequisites for harvesting these benefits are detecting users and acquiring\nuser channel state information (CSI) in the training phase. However, due to the\nfact that mmWave channels encounter much harsher propagation and decorrelate\nmuch faster, the tasks of user detection and CSI acquisition are both\nimperative and much more challenging than in LTE bands.\n  In this paper, we investigate the problem of fast user detection and CSI\nacquisition in the downlink of small cell mmWave networks. We assume TDD\noperation and channel-reciprocity based CSI acquisition. To achieve\ndensification benefits we propose pilot designs and channel estimators that\nleverage a combination of aggressive pilot reuse with fast user detection at\nthe base station and compressed sensing channel estimation. As our simulations\nshow, the number of users that can be simultaneously served by the entire\nmmWave-band network with the proposed schemes increases substantially with\nrespect to traditional compressed sensing based approaches with conventional\npilot reuse. \n\n"}
{"id": "1601.05690", "contents": "Title: A New Converse Bound for Coded Caching Abstract: An information-theoretic lower bound is developed for the caching system\nstudied by Maddah-Ali and Niesen. By comparing the proposed lower bound with\nthe decentralized coded caching scheme of Maddah-Ali and Niesen, the optimal\nmemory--rate tradeoff is characterized to within a multiplicative gap of $4.7$\nfor the worst case, improving the previous analytical gap of $12$. Furthermore,\nfor the case when users' requests follow the uniform distribution, the\nmultiplicative gap is tightened to $4.7$, improving the previous analytical gap\nof $72$. As an independent result of interest, for the single-user average case\nin which the user requests multiple files, it is proved that caching the most\nrequested files is optimal. \n\n"}
{"id": "1601.05879", "contents": "Title: Construction of a Channel Code from an Arbitrary Source Code with\n  Decoder Side Information Abstract: The construction of a channel code by using a source code with decoder side\ninformation is introduced. For the construction, any pair of encoder and\ndecoder is available for a source code with decoder side information. A\nconstrained-random-number generator, which generates random numbers satisfying\na condition specified by a function and its value, is used to construct a\nstochastic channel encoder. The result suggests that we can divide the channel\ncoding problem into the problems of channel encoding and source decoding with\nside information. \n\n"}
{"id": "1601.06035", "contents": "Title: Recommender systems inspired by the structure of quantum theory Abstract: Physicists use quantum models to describe the behavior of physical systems.\nQuantum models owe their success to their interpretability, to their relation\nto probabilistic models (quantization of classical models) and to their high\npredictive power. Beyond physics, these properties are valuable in general data\nscience. This motivates the use of quantum models to analyze general\nnonphysical datasets. Here we provide both empirical and theoretical insights\ninto the application of quantum models in data science. In the theoretical part\nof this paper, we firstly show that quantum models can be exponentially more\nefficient than probabilistic models because there exist datasets that admit\nlow-dimensional quantum models and only exponentially high-dimensional\nprobabilistic models. Secondly, we explain in what sense quantum models realize\na useful relaxation of compressed probabilistic models. Thirdly, we show that\nsparse datasets admit low-dimensional quantum models and finally, we introduce\na method to compute hierarchical orderings of properties of users (e.g.,\npersonality traits) and items (e.g., genres of movies). In the empirical part\nof the paper, we evaluate quantum models in item recommendation and observe\nthat the predictive power of quantum-inspired recommender systems can compete\nwith state-of-the-art recommender systems like SVD++ and PureSVD. Furthermore,\nwe make use of the interpretability of quantum models by computing hierarchical\norderings of properties of users and items. This work establishes a connection\nbetween data science (item recommendation), information theory (communication\ncomplexity), mathematical programming (positive semidefinite factorizations)\nand physics (quantum models). \n\n"}
{"id": "1601.06280", "contents": "Title: Sub-Quadratic Decoding of Gabidulin Codes Abstract: This paper shows how to decode errors and erasures with Gabidulin codes in\nsub-quadratic time in the code length, improving previous algorithms which had\nat least quadratic complexity. The complexity reduction is achieved by\naccelerating operations on linearized polynomials. In particular, we present\nfast algorithms for division, multi-point evaluation and interpolation of\nlinearized polynomials and show how to efficiently compute minimal subspace\npolynomials. \n\n"}
{"id": "1601.06847", "contents": "Title: Battery-Powered Devices in WPCNs Abstract: Wireless powered communication networks are becoming an effective solution\nfor improving self sustainability of mobile devices. In this context, a hybrid\naccess point transfers energy to a group of nodes, which use the harvested\nenergy to perform computation or transmission tasks. While the availability of\nthe wireless energy transfer mechanism opens up new frontiers, an appropriate\nchoice of the network parameters (e.g., transmission powers, transmission\nduration, amount of transferred energy, etc.) is required in order to achieve\nhigh performance. In this work, we study the throughput optimization problem in\na system composed of an access point which recharges the batteries of two\ndevices at different distances. In the literature, the main focus so far has\nbeen on slot-oriented optimization, in which all the harvested energy is used\nin the same slot in which it is harvested. However, this approach is strongly\nsub-optimal because it does not exploit the possibility to store the energy and\nuse it at a later time. Thus, instead of considering the slot-oriented case, we\naddress the long-term maximization. This assumption greatly increases the\noptimization complexity, requiring to consider, e.g., the channel state\nrealizations, its statistics and the batteries evolution. Our objective is to\nfind the best scheduling scheme, both for the energy transferred by the access\npoint and for the data sent by the two nodes. We discuss how to perform the\nmaximization with optimal as well as approximate techniques and show that the\nslot-oriented policies proposed so far are strongly sub-optimal in the long\nrun. \n\n"}
{"id": "1601.06880", "contents": "Title: Bounds on Asymptotic Rate of Capacitive Crosstalk Avoidance Codes for\n  On-chip Buses Abstract: In order to prevent the capacitive crosstalk in on-chip buses, several types\nof capacitive crosstalk avoidance codes have been devised. These codes are\ndesigned to prohibit transition patterns prone to the capacity crosstalk from\nany consecutive two words transmitted to on-chip buses. This paper provides a\nrigorous analysis on the asymptotic rate of (p,q)-transition free word\nsequences under the assumption that coding is based on a pair of a stateful\nencoder and a stateless decoder. The symbols p and q represent k-bit transition\npatterns that should not be appeared in any consecutive two words at the same\nadjacent k-bit positions. It is proved that the maximum rate of the sequences\nequals to the subgraph domatic number of (p,q)-transition free graph. Based on\nthe theoretical results on the subgraph domatic partition problem, a pair of\nlower and upper bounds on the asymptotic rate is derived. We also present that\nthe asymptotic rate 0.8325 is achievable for the (10,01)-transition free word\nsequences. \n\n"}
{"id": "1601.07011", "contents": "Title: Distributed Detection over Adaptive Networks: Refined Asymptotics and\n  the Role of Connectivity Abstract: We consider distributed detection problems over adaptive networks, where\ndispersed agents learn continually from streaming data by means of local\ninteractions. The simultaneous requirements of adaptation and cooperation are\nachieved by employing diffusion algorithms with constant step-size {\\mu}. In\n[1], [2] some main features of adaptive distributed detection were revealed. By\nresorting to large deviations analysis, it was established that the Type-I and\nType-II error probabilities of all agents vanish exponentially as functions of\n1/{\\mu}, and that all agents share the same Type-I and Type-II error exponents.\nHowever, numerical evidences presented in [1], [2] showed that the theory of\nlarge deviations does not capture the fundamental impact of network\nconnectivity on performance, and that additional tools and efforts are required\nto obtain accurate predictions for the error probabilities. This work addresses\nthese open issues and extends the results of [1], [2] in several directions. By\nconducting a refined asymptotic analysis based on the mathematical framework of\nexact asymptotics, we arrive at a revealing and powerful understanding of the\nuniversal behavior of distributed detection over adaptive networks: as\nfunctions of 1/{\\mu}, the error (log-)probability curves corresponding to\ndifferent agents stay nearly-parallel to each other (as already discovered in\n[1], [2]), however, these curves are ordered following a criterion reflecting\nthe degree of connectivity of each agent. Depending on the combination weights,\nthe more connected an agent is, the lower its error probability curve will be.\nInteresting and somehow unexpected behaviors emerge, in terms of the interplay\nbetween the network topology, the combination weights, and the inference\nperformance. The lesson learned is that connectivity matters. \n\n"}
{"id": "1601.07865", "contents": "Title: Grid Energy Consumption and QoS Tradeoff in Hybrid Energy Supply\n  Wireless Networks Abstract: Hybrid energy supply (HES) wireless networks have recently emerged as a new\nparadigm to enable green networks, which are powered by both the electric grid\nand harvested renewable energy. In this paper, we will investigate two critical\nbut conflicting design objectives of HES networks, i.e., the grid energy\nconsumption and quality of service (QoS). Minimizing grid energy consumption by\nutilizing the harvested energy will make the network environmentally friendly,\nbut the achievable QoS may be degraded due to the intermittent nature of energy\nharvesting. To investigate the tradeoff between these two aspects, we introduce\nthe total service cost as the performance metric, which is the weighted sum of\nthe grid energy cost and the QoS degradation cost. Base station assignment and\npower control is adopted as the main strategy to minimize the total service\ncost, while both cases with non-causal and causal side information are\nconsidered. With non-causal side information, a Greedy Assignment algorithm\nwith low complexity and near-optimal performance is proposed. With causal side\ninformation, the design problem is formulated as a discrete Markov decision\nproblem. Interesting solution structures are derived, which shall help to\ndevelop an efficient monotone backward induction algorithm. To further reduce\ncomplexity, a Look-Ahead policy and a Threshold-based Heuristic policy are also\nproposed. Simulation results shall validate the effectiveness of the proposed\nalgorithms and demonstrate the unique grid energy consumption and QoS tradeoff\nin HES networks. \n\n"}
{"id": "1602.00095", "contents": "Title: Walsh Sampling with Incomplete Noisy Signals Abstract: With the advent of massive data outputs at a regular rate, admittedly, signal\nprocessing technology plays an increasingly key role. Nowadays, signals are not\nmerely restricted to physical sources, they have been extended to digital\nsources as well.\n  Under the general assumption of discrete statistical signal sources, we\npropose a practical problem of sampling incomplete noisy signals for which we\ndo not know a priori and the sampling size is bounded. We approach this\nsampling problem by Shannon's channel coding theorem. Our main results\ndemonstrate that it is the large Walsh coefficient(s) that characterize(s)\ndiscrete statistical signals, regardless of the signal sources. By the\nconnection of Shannon's theorem, we establish the necessary and sufficient\ncondition for our generic sampling problem for the first time. Our generic\nsampling results find practical and powerful applications in not only\nstatistical cryptanalysis, but software system performance optimization. \n\n"}
{"id": "1602.01458", "contents": "Title: Private Information Retrieval from MDS Coded Data in Distributed Storage\n  Systems Abstract: The problem of providing privacy, in the private information retrieval (PIR)\nsense, to users requesting data from a distributed storage system (DSS), is\nconsidered. The DSS is coded by an $(n,k,d)$ Maximum Distance Separable (MDS)\ncode to store the data reliably on unreliable storage nodes. Some of these\nnodes can be spies which report to a third party, such as an oppressive regime,\nwhich data is being requested by the user. An information theoretic PIR scheme\nensures that a user can satisfy its request while revealing, to the spy nodes,\nno information on which data is being requested. A user can trivially achieve\nPIR by downloading all the data in the DSS. However, this is not a feasible\nsolution due to its high communication cost. We construct PIR schemes with low\ndownload communication cost. When there is $b=1$ spy node in the DSS, we\nconstruct PIR schemes with download cost $\\frac{1}{1-R}$ per unit of requested\ndata ($R=k/n$ is the code rate), achieving the information theoretic limit for\nlinear schemes. The proposed schemes are universal since they depend on the\ncode rate, but not on the generator matrix of the code. Also, when $b\\leq\nn-\\delta k$, for some $\\delta \\in \\mathbb{N^+}$, we construct linear PIR\nschemes with $cPoP = \\frac{b+\\delta k}{\\delta}$. \n\n"}
{"id": "1602.03115", "contents": "Title: Towards Robustness in Residue Number Systems Abstract: The problem of robustly reconstructing a large number from its erroneous\nremainders with respect to several moduli, namely the robust remaindering\nproblem, may occur in many applications including phase unwrapping, frequency\ndetection from several undersampled waveforms, wireless sensor networks, etc.\nAssuming that the dynamic range of the large number is the maximal possible\none, i.e., the least common multiple (lcm) of all the moduli, a method called\nrobust Chinese remainder theorem (CRT) for solving the robust remaindering\nproblem has been recently proposed. In this paper, by relaxing the assumption\nthat the dynamic range is fixed to be the lcm of all the moduli, a trade-off\nbetween the dynamic range and the robustness bound for two-modular systems is\nstudied. It basically says that a decrease in the dynamic range may lead to an\nincrease of the robustness bound. We first obtain a general condition on the\nremainder errors and derive the exact dynamic range with a closed-form formula\nfor the robustness to hold. We then propose simple closed-form reconstruction\nalgorithms. Furthermore, the newly obtained two-modular results are applied to\nthe robust reconstruction for multi-modular systems and generalized to real\nnumbers. Finally, some simulations are carried out to verify our proposed\ntheoretical results. \n\n"}
{"id": "1602.03490", "contents": "Title: Tremain equiangular tight frames Abstract: Equiangular tight frames provide optimal packings of lines through the\norigin. We combine Steiner triple systems with Hadamard matrices to produce a\nnew infinite family of equiangular tight frames. This in turn leads to new\nconstructions of strongly regular graphs and distance-regular antipodal covers\nof the complete graph. \n\n"}
{"id": "1602.03722", "contents": "Title: Sequences with small correlation Abstract: The extent to which a sequence of finite length differs from a shifted\nversion of itself is measured by its aperiodic autocorrelations. Of particular\ninterest are sequences whose entries are 1 or -1, called binary sequences, and\nsequences whose entries are complex numbers of unit magnitude, called\nunimodular sequences. Since the 1950s, there is sustained interest in sequences\nwith small aperiodic autocorrelations relative to the sequence length. One of\nthe main motivations is that a sequence with small aperiodic autocorrelations\nis intrinsically suited for the separation of signals from noise, and therefore\nhas natural applications in digital communications. This survey reviews the\nstate of knowledge concerning the two central problems in this area: How small\ncan the aperiodic autocorrelations of a binary or a unimodular sequence\ncollectively be and how can we efficiently find the best such sequences? Since\nthe analysis and construction of sequences with small aperiodic\nautocorrelations is closely tied to the (often much easier) analysis of\nperiodic autocorrelation properties, several fundamental results on\ncorresponding problems in the periodic setting are also reviewed. \n\n"}
{"id": "1602.03906", "contents": "Title: How to group wireless nodes together? Abstract: This report presents a survey on how to group together in a static way planar\nnodes, that may belong to a wireless network (ad hoc or cellular). The aim is\nto identify appropriate methods that could also be applied for Point Processes.\nSpecifically matching pairs and algorithms are initially discussed. Next,\nspecifically for Point Processes, the Nearest Neighbour and Lilypond models are\npresented. Properties and results for the two models are stated. Original\nbounds are given for the value of the so-called generation number, which is\nrelated to the size of the nearest neighbour cluster. Finally, a variation of\nthe nearest neighbour grouping is proposed and an original metric is\nintroduced, named here the ancestor number. This is used to facilitate the\nanalysis of the distribution of cluster size. Based on this certain related\nbounds are derived. The report and the analysis included show clearly the\ndifficulty of working in point processes with static clusters of size greater\nthan two, when these are defined by proximity criteria. \n\n"}
{"id": "1602.04482", "contents": "Title: Bounds on the Maximal Minimum Distance of Linear Locally Repairable\n  Codes Abstract: Locally repairable codes (LRCs) are error correcting codes used in\ndistributed data storage. Besides a global level, they enable errors to be\ncorrected locally, reducing the need for communication between storage nodes.\nThere is a close connection between almost affine LRCs and matroid theory which\ncan be utilized to construct good LRCs and derive bounds on their performance.\n  A generalized Singleton bound for linear LRCs with parameters\n$(n,k,d,r,\\delta)$ was given in [N. Prakash et al., \"Optimal Linear Codes with\na Local-Error-Correction Property\", IEEE Int. Symp. Inf. Theory]. In this\npaper, a LRC achieving this bound is called perfect. Results on the existence\nand nonexistence of linear perfect $(n,k,d,r,\\delta)$-LRCs were given in [W.\nSong et al., \"Optimal locally repairable codes\", IEEE J. Sel. Areas Comm.].\nUsing matroid theory, these existence and nonexistence results were later\nstrengthened in [T. Westerb\\\"ack et al., \"On the Combinatorics of Locally\nRepairable Codes\", Arxiv: 1501.00153], which also provided a general lower\nbound on the maximal achievable minimum distance $d_{\\rm{max}}(n,k,r,\\delta)$\nthat a linear LRC with parameters $(n,k,r,\\delta)$ can have. This article\nexpands the class of parameters $(n,k,d,r,\\delta)$ for which there exist\nperfect linear LRCs and improves the lower bound for\n$d_{\\rm{max}}(n,k,r,\\delta)$. Further, this bound is proved to be optimal for\nthe class of matroids that is used to derive the existence bounds of linear\nLRCs. \n\n"}
{"id": "1602.06506", "contents": "Title: Evaluation of Generalized Degrees of Freedom for Sparse Estimation by\n  Replica Method Abstract: We develop a method to evaluate the generalized degrees of freedom (GDF),\nwhich is a key quantity of a model selection criterion, for linear regression\nwith sparse regularization. Using the replica method, GDF is expressed by the\nvariables that characterize the saddle point of the free energy without\ndepending on the form of the regularization. Within the framework of replica\nsymmetric (RS) analysis, GDF is provided with a physical meaning as the\neffective density of non-zero components. The validity of our method in the RS\nphase is supported by the consistency of our results with previous mathematical\nresults. The analytical results in the RS phase are numerically achieved by the\nbelief propagation algorithm. \n\n"}
{"id": "1602.06598", "contents": "Title: Initial Beam Association in Millimeter Wave Cellular Systems: Analysis\n  and Design Insights Abstract: Enabling the high data rates of millimeter wave (mmWave) cellular systems\nrequires deploying large antenna arrays at both the basestations and mobile\nusers. The beamforming weights of these large arrays need to be tuned to\nguarantee sufficient beamforming gains. Prior work on coverage and rate of\nmmWave cellular networks focused mainly on the case when basestations and\nmobile users beamfomring vectors are perfectly designed for maximum beamforming\ngains. Designing beamforming/combining vectors, though, requires training which\nmay impact both the SINR coverage and rate of mmWave cellular systems. This\npaper characterizes and evaluates the performance of mmWave cellular networks\nwhile accounting for the beam training/association overhead. First, a model for\nthe initial beam association is developed based on beam sweeping and downlink\ncontrol pilot reuse. To incorporate the impact of beam training into system\nperformance, a new metric, called the effective reliable rate, is defined and\nadopted. Using stochastic geometry, the effective reliable rate of mmWave\ncellular networks is derived for two special cases: with near-orthogonal\ncontrol pilots and with full pilot reuse. Analytical and simulation results\nprovide insights into the answers of three important questions: (i) What is the\nimpact of beam association on mmWave network performance? (ii) Should\northogonal or reused control pilots be employed in the initial beam association\nphase? (iii) Should exhaustive or hierarchical search be adopted for the beam\ntraining phase? The results show that unless the employed beams are very wide\nor the system coherence block length is very small, exhaustive search with full\npilot reuse is nearly as good as perfect beam alignment. \n\n"}
{"id": "1602.09115", "contents": "Title: Throughput and Coverage for a Mixed Full and Half Duplex Small Cell\n  Network Abstract: Recent advances in self-interference cancellation enable radios to transmit\nand receive on the same frequency at the same time. Such a full duplex radio is\nbeing considered as a potential candidate for the next generation of wireless\nnetworks due to its ability to increase the spectral efficiency of wireless\nsystems. In this paper, the performance of full duplex radio in small cellular\nsystems is analyzed by assuming full duplex capable base stations and half\nduplex user equipment. However, using only full duplex base stations increases\ninterference leading to outage. We therefore propose a mixed multi-cell system,\ncomposed of full duplex and half duplex cells. A stochastic geometry based\nmodel of the proposed mixed system is provided, which allows us to derive the\noutage and area spectral efficiency of such a system. The effect of full duplex\ncells on the performance of the mixed system is presented under different\nnetwork parameter settings. We show that the fraction of cells that have full\nduplex base stations can be used as a design parameter by the network operator\nto target an optimal tradeoff between area spectral efficiency and outage in a\nmixed system. \n\n"}
{"id": "1602.09134", "contents": "Title: The Capacity of Private Information Retrieval Abstract: In the private information retrieval (PIR) problem a user wishes to retrieve,\nas efficiently as possible, one out of $K$ messages from $N$ non-communicating\ndatabases (each holds all $K$ messages) while revealing nothing about the\nidentity of the desired message index to any individual database. The\ninformation theoretic capacity of PIR is the maximum number of bits of desired\ninformation that can be privately retrieved per bit of downloaded information.\nFor $K$ messages and $N$ databases, we show that the PIR capacity is\n$(1+1/N+1/N^2+\\cdots+1/N^{K-1})^{-1}$. A remarkable feature of the capacity\nachieving scheme is that if we eliminate any subset of messages (by setting the\nmessage symbols to zero), the resulting scheme also achieves the PIR capacity\nfor the remaining subset of messages. \n\n"}
{"id": "1602.09140", "contents": "Title: Information Reconciliation for Continuous-Variable Quantum Key\n  Distribution using Non-Binary Low-Density Parity-Check Codes Abstract: An information reconciliation method for continuous-variable quantum key\ndistribution with Gaussian modulation that is based on non-binary low-density\nparity-check (LDPC) codes is presented. Sets of regular and irregular LDPC\ncodes with different code rates over the Galois fields $GF(8)$, $GF(16)$,\n$GF(32)$, and $GF(64)$ have been constructed. We have performed simulations to\nanalyze the efficiency and the frame error rate using the sum-product\nalgorithm. The proposed method achieves an efficiency between $0.94$ and $0.98$\nif the signal-to-noise ratio is between $4$ dB and $24$ dB. \n\n"}
{"id": "1603.01573", "contents": "Title: McCulloch-Pitts brains and pseudorandom functions Abstract: In a pioneering classic, Warren McCulloch and Walter Pitts proposed a model\nof the central nervous system. Motivated by EEG recordings of normal brain\nactivity, Chv\\'atal and Goldsmith asked whether or not these dynamical systems\ncan be engineered to produce trajectories which are irregular, disorderly,\napparently unpredictable. We show that they cannot build weak pseudorandom\nfunctions. \n\n"}
{"id": "1603.05736", "contents": "Title: Construction of polar codes for arbitrary discrete memoryless channels Abstract: It is known that polar codes can be efficiently constructed for binary-input\nchannels. At the same time, existing algorithms for general input alphabets are\nless practical because of high complexity. We address the construction problem\nfor the general case, and analyze an algorithm that is based on successive\nreduction of the output alphabet size of the subchannels in each recursion\nstep. For this procedure we estimate the approximation error as\n$O(\\mu^{-1/(q-1)}),$ where $\\mu$ is the \"quantization parameter,\" i.e., the\nmaximum size of the subchannel output alphabet allowed by the algorithm. The\ncomplexity of the code construction scales as $O(N\\mu^4),$ where $N$ is the\nlength of the code.\n  We also show that if the polarizing operation relies on modulo-$q$ addition,\nit is possible to merge subsets of output symbols without any loss in\nsubchannel capacity. Performing this procedure before each approximation step\nresults in a further speed-up of the code construction, and the resulting codes\nhave smaller gap to capacity. We show that a similar acceleration can be\nattained for polar codes over finite field alphabets.\n  Experimentation shows that the suggested construction algorithms can be used\nto construct long polar codes for alphabets of size $q=16$ and more with\nacceptable loss of the code rate for a variety of polarizing transforms. \n\n"}
{"id": "1603.06286", "contents": "Title: A Generalized LDPC Framework for Robust and Sublinear Compressive\n  Sensing Abstract: Compressive sensing aims to recover a high-dimensional sparse signal from a\nrelatively small number of measurements. In this paper, a novel design of the\nmeasurement matrix is proposed. The design is inspired by the construction of\ngeneralized low-density parity-check codes, where the capacity-achieving\npoint-to-point codes serve as subcodes to robustly estimate the signal support.\nIn the case that each entry of the $n$-dimensional $k$-sparse signal lies in a\nknown discrete alphabet, the proposed scheme requires only $O(k \\log n)$\nmeasurements and arithmetic operations. In the case of arbitrary, possibly\ncontinuous alphabet, an error propagation graph is proposed to characterize the\nresidual estimation error. With $O(k \\log^2 n)$ measurements and computational\ncomplexity, the reconstruction error can be made arbitrarily small with high\nprobability. \n\n"}
{"id": "1603.07322", "contents": "Title: On Delay-Optimal Scheduling in Queueing Systems with Replications Abstract: In modern computer systems, jobs are divided into short tasks and executed in\nparallel. Empirical observations in practical systems suggest that the task\nservice times are highly random and the job service time is bottlenecked by the\nslowest straggling task. One common solution for straggler mitigation is to\nreplicate a task on multiple servers and wait for one replica of the task to\nfinish early. The delay performance of replications depends heavily on the\nscheduling decisions of when to replicate, which servers to replicate on, and\nwhich job to serve first. So far, little is understood on how to optimize these\nscheduling decisions for minimizing the delay to complete the jobs. In this\npaper, we present a comprehensive study on delay-optimal scheduling of\nreplications in both centralized and distributed multi-server systems.\nLow-complexity scheduling policies are designed and are proven to be\ndelay-optimal or near delay-optimal in stochastic ordering among all causal and\nnon-preemptive policies. These theoretical results are established for general\nsystem settings and delay metrics that allow for arbitrary arrival processes,\narbitrary job sizes, arbitrary due times, and heterogeneous servers with data\nlocality constraints. Novel sample-path tools are developed to prove these\nresults. \n\n"}
{"id": "1603.07576", "contents": "Title: Power and Channel Allocation for Non-orthogonal Multiple Access in 5G\n  Systems: Tractability and Computation Abstract: Network capacity calls for significant increase for 5G cellular systems. A\npromising multi-user access scheme, non-orthogonal multiple access (NOMA) with\nsuccessive interference cancellation (SIC), is currently under consideration.\nIn NOMA, spectrum efficiency is improved by allowing more than one user to\nsimultaneously access the same frequency-time resource and separating\nmulti-user signals by SIC at the receiver. These render resource allocation and\noptimization in NOMA different from orthogonal multiple access in 4G. In this\npaper, we provide theoretical insights and algorithmic solutions to jointly\noptimize power and channel allocation in NOMA. For utility maximization, we\nmathematically formulate NOMA resource allocation problems. We characterize and\nanalyze the problems' tractability under a range of constraints and utility\nfunctions. For tractable cases, we provide polynomial-time solutions for global\noptimality. For intractable cases, we prove the NP-hardness and propose an\nalgorithmic framework combining Lagrangian duality and dynamic programming\n(LDDP) to deliver near-optimal solutions. To gauge the performance of the\nobtained solutions, we also provide optimality bounds on the global optimum.\nNumerical results demonstrate that the proposed algorithmic solution can\nsignificantly improve the system performance in both throughput and fairness\nover orthogonal multiple access as well as over a previous NOMA resource\nallocation scheme. \n\n"}
{"id": "1603.08585", "contents": "Title: On Fast Decoding of High Dimensional Signals from One-Bit Measurements Abstract: In the problem of one-bit compressed sensing, the goal is to find a\n$\\delta$-close estimation of a $k$-sparse vector $x \\in \\mathbb{R}^n$ given the\nsigns of the entries of $y = \\Phi x$, where $\\Phi$ is called the measurement\nmatrix. For the one-bit compressed sensing problem, previous work\n\\cite{Plan-robust,support} achieved $\\Theta (\\delta^{-2} k \\log(n/k))$ and\n$\\tilde{ \\Oh} ( \\frac{1}{ \\delta } k \\log (n/k))$ measurements, respectively,\nbut the decoding time was $\\Omega ( n k \\log (n / k ))$. \\ In this paper, using\ntools and techniques developed in the context of two-stage group testing and\nstreaming algorithms, we contribute towards the direction of very fast decoding\ntime. We give a variety of schemes for the different versions of one-bit\ncompressed sensing, such as the for-each and for-all version, support recovery;\nall these have $poly(k, \\log n)$ decoding time, which is an exponential\nimprovement over previous work, in terms of the dependence of $n$. \n\n"}
{"id": "1603.08876", "contents": "Title: Locally recoverable codes on algebraic curves Abstract: A code over a finite alphabet is called locally recoverable (LRC code) if\nevery symbol in the encoding is a function of a small number (at most $r$)\nother symbols of the codeword. In this paper we introduce a construction of LRC\ncodes on algebraic curves, extending a recent construction of Reed-Solomon like\ncodes with locality. We treat the following situations: local recovery of a\nsingle erasure, local recovery of multiple erasures, and codes with several\ndisjoint recovery sets for every coordinate (the {\\em availability problem}).\nFor each of these three problems we describe a general construction of codes on\ncurves and construct several families of LRC codes. We also describe a\nconstruction of codes with availability that relies on automorphism groups of\ncurves. \n\n"}
{"id": "1604.00074", "contents": "Title: Waveform Design for Wireless Power Transfer Abstract: Far-field Wireless Power Transfer (WPT) has attracted significant attention\nin recent years. Despite the rapid progress, the emphasis of the research\ncommunity in the last decade has remained largely concentrated on improving the\ndesign of energy harvester (so-called rectenna) and has left aside the effect\nof transmitter design. In this paper, we study the design of transmit waveform\nso as to enhance the DC power at the output of the rectenna. We derive a\ntractable model of the non-linearity of the rectenna and compare with a linear\nmodel conventionally used in the literature. We then use those models to design\nnovel multisine waveforms that are adaptive to the channel state information\n(CSI). Interestingly, while the linear model favours narrowband transmission\nwith all the power allocated to a single frequency, the non-linear model\nfavours a power allocation over multiple frequencies. Through realistic\nsimulations, waveforms designed based on the non-linear model are shown to\nprovide significant gains (in terms of harvested DC power) over those designed\nbased on the linear model and over non-adaptive waveforms. We also compute\nanalytically the theoretical scaling laws of the harvested energy for various\nwaveforms as a function of the number of sinewaves and transmit antennas. Those\nscaling laws highlight the benefits of CSI knowledge at the transmitter in WPT\nand of a WPT design based on a non-linear rectenna model over a linear model.\nResults also motivate the study of a promising architecture relying on\nlarge-scale multisine multi-antenna waveforms for WPT. As a final note, results\nstress the importance of modeling and accounting for the non-linearity of the\nrectenna in any system design involving wireless power. \n\n"}
{"id": "1604.03617", "contents": "Title: A note on the duals of skew constacyclic codes Abstract: Let $\\mathbb{F}_q$ be a finite field with $q$ elements and denote by $\\theta\n: \\mathbb{F}_q\\to\\mathbb{F}_q$ an automorphism of $\\mathbb{F}_q$. In this\npaper, we deal with skew constacyclic codes, that is, linear codes of\n$\\mathbb{F}_q^n$ which are invariant under the action of a semi-linear map\n$\\Phi_{\\alpha,\\theta}:\\mathbb{F}_q^n\\to\\mathbb{F}_q^n$, defined by\n$\\Phi_{\\alpha,\\theta}(a_0,...,a_{n-2}, a_{n-1}):=(\\alpha\n\\theta(a_{n-1}),\\theta(a_0),...,\\theta(a_{n-2}))$ for some\n$\\alpha\\in\\mathbb{F}_q\\setminus\\{0\\}$ and $n\\geq 2$. In particular, we study\nsome algebraic and geometric properties of their dual codes and we give some\nconsequences and research results on $1$-generator skew quasi-twisted codes and\non MDS skew constacyclic codes. \n\n"}
{"id": "1604.03698", "contents": "Title: Frequency-domain equalization aided iterative detection of\n  faster-than-Nyquist signaling with noise whitening Abstract: In this paper, we propose a serially concatenated turbo-encoded\nfaster-than-Nyquist signaling (FTNS) transceiver that takes into account\nFTNS-specific colored noise effects. The proposed low-complexity receiver\ncarries out soft-decision frequency-domain equalization with the aid of the\nminimum-mean square error criterion while whitening the colored noise.\nSimulation results demonstrate that the proposed multi-stage-concatenated FTNS\nsystem achieves a better error-ratio performance than previous systems that do\nnot consider colored noise effects in the high-symbol-packing FTNS regime.\nFurthermore, as an explicit benefit of the proposed iterative decoder,\nnear-capacity performance is achieved with practical decoding complexity. \n\n"}
{"id": "1604.04826", "contents": "Title: On the Non-existence of certain classes of generalized bent functions Abstract: We obtain new non-existence results of generalized bent functions from\n\\ZZ^n_q to \\ZZ_q (called type [n,q]). The first case is a class of types where\nq=2p_1^{r_1}p_2^{r_2}. The second case contains two types [1 <= n <= 3, 2 *\n31^e]$ and [1 <= n <= 7,2 * 151^e]. \n\n"}
{"id": "1604.05453", "contents": "Title: An entropic characterization of long memory stationary process Abstract: Long memory or long range dependency is an important phenomenon that may\narise in the analysis of time series or spatial data. Most of the definitions\nof long memory of a stationary process $X=\\{X_1, X_2,\\cdots,\\}$ are based on\nthe second-order properties of the process. The excess entropy of a stationary\nprocess is the summation of redundancies which relates to the rate of\nconvergence of the conditional entropy $H(X_n|X_{n-1},\\cdots, X_1)$ to the\nentropy rate. It is proved that the excess entropy is identical to the mutual\ninformation between the past and the future when the entropy $H(X_1)$ is\nfinite. We suggest the definition that a stationary process is long memory if\nthe excess entropy is infinite. Since the definition of excess entropy of a\nstationary process requires very weak moment condition on the distribution of\nthe process, it can be applied to processes whose distributions without bounded\nsecond moment. A significant property of excess entropy is that it is invariant\nunder invertible transformation, which enables us to know the excess entropy of\na stationary process from the excess entropy of other process. For stationary\nGuassian process, the excess entropy characterization of long memory relates to\npopular characterization well. It is proved that the excess entropy of\nfractional Gaussian noise is infinite if the Hurst parameter $H \\in (1/2, 1)$. \n\n"}
{"id": "1604.07957", "contents": "Title: Degrees of Freedom of Full-Duplex Cellular Networks with Reconfigurable\n  Antennas at Base Station Abstract: Full-duplex (FD) cellular networks are considered in which a FD base station\n(BS) simultaneously supports a set of half-duplex (HD) downlink (DL) users and\na set of HD uplink (UL) users. The transmitter and the receiver of the BS are\nequipped with reconfigurable antennas, each of which can choose its transmit or\nreceive mode from several preset modes. Under the no self-interference\nassumption arisen from FD operation at the BS, the sum degrees of freedom (DoF)\nof FD cellular networks is investigated for both no channel state information\nat the transmit side (CSIT) and partial CSIT. In particular, the sum DoF is\ncompletely characterized for no CSIT model and an achievable sum DoF is\nestablished for the partial CSIT model, which improves the sum DoF of the\nconventional HD cellular networks. For both no CSIT and partial CSIT models,\nthe results show that the FD BS with reconfigurable antennas can double the sum\nDoF even in the presence of user-to-user interference as both the numbers of DL\nand UL users and preset modes increase. It is further demonstrated that such\nDoF improvement indeed yields the sum rate improvement at the finite and\noperational signal-to-noise ratio regime. \n\n"}
{"id": "1604.08744", "contents": "Title: Enabling Relaying Over Heterogeneous Backhauls in the Uplink of Wireless\n  Femtocell Networks Abstract: In this paper, we develop novel two-tier interference management strategies\nthat enable macrocell users (MUEs) to improve their performance, with the help\nof open-access femtocells. To this end, we propose a rate-splitting technique\nusing which the MUEs optimize their uplink transmissions by dividing their\nsignals into two types: a coarse message that is intended for direct\ntransmission to the macrocell base station and a fine message that is decoded\nby a neighboring femtocell and subsequently relayed over a heterogeneous\n(wireless/wired) backhaul. For deploying the proposed technique, we formulate a\nnon-cooperative game between the MUEs in which each MUE can decide on its\nrelaying femtocell while maximizing a utility function that captures both the\nachieved throughput and the expected backhaul delay. Simulation results show\nthat the proposed approach yields up to 125% rate improvement and up to 2 times\ndelay reduction with wired backhaul and, 150% rate improvement and up to 10\ntimes delay reduction with wireless backhaul, relative to classical\ninterference management approaches, with no cross-tier cooperation. \n\n"}
{"id": "1605.00635", "contents": "Title: The Capacity of Robust Private Information Retrieval with Colluding\n  Databases Abstract: Private information retrieval (PIR) is the problem of retrieving as\nefficiently as possible, one out of $K$ messages from $N$ non-communicating\nreplicated databases (each holds all $K$ messages) while keeping the identity\nof the desired message index a secret from each individual database. The\ninformation theoretic capacity of PIR (equivalently, the reciprocal of minimum\ndownload cost) is the maximum number of bits of desired information that can be\nprivately retrieved per bit of downloaded information. $T$-private PIR is a\ngeneralization of PIR to include the requirement that even if any $T$ of the\n$N$ databases collude, the identity of the retrieved message remains completely\nunknown to them. Robust PIR is another generalization that refers to the\nscenario where we have $M \\geq N$ databases, out of which any $M - N$ may fail\nto respond. For $K$ messages and $M\\geq N$ databases out of which at least some\n$N$ must respond, we show that the capacity of $T$-private and Robust PIR is\n$\\left(1+T/N+T^2/N^2+\\cdots+T^{K-1}/N^{K-1}\\right)^{-1}$. The result includes\nas special cases the capacity of PIR without robustness ($M=N$) or $T$-privacy\nconstraints ($T=1$). \n\n"}
{"id": "1605.00975", "contents": "Title: Breaking the Limits -- Redefining the Instantaneous Frequency Abstract: The Carson and Fry (1937) introduced the concept of variable frequency as a\ngeneralization of the constant frequency. The instantaneous frequency (IF) is\nthe time derivative of the instantaneous phase and it is well-defined only when\nthis derivative is positive. If this derivative is negative, the IF creates\nproblem because it does not provide any physical significance. This study\nproposes a mathematical solution and eliminate this problem by redefining the\nIF such that it is valid for all monocomponent and multicomponent signals which\ncan be nonlinear and nonstationary in nature. This is achieved by using the\nproperty of the multivalued inverse tangent function. The efforts and\nunderstanding of all the methods based on the IF would improve significantly by\nusing this proposed definition of the IF. We also demonstrate that the\ndecomposition of a signal, using zero-phase filtering based on the well\nestablished Fourier and filter theory, into a set of desired frequency bands\nwith proposed IF produces accurate time-frequency-energy (TFE) distribution\nthat reveals true nature of signal. Simulation results demonstrate the efficacy\nof the proposed IF that makes zero-phase filter based decomposition most\npowerful, for the TFE analysis of a signal, as compared to other existing\nmethods in the literature. \n\n"}
{"id": "1605.01160", "contents": "Title: Successive Interference Cancellation in Bipolar Ad Hoc Networks with\n  SWIPT Abstract: Successive interference cancellation (SIC) is based on the idea that some\ninterfering signals may be strong enough to decode in order to be removed from\nthe aggregate received signal and thus boost performance. In this letter, we\nstudy the SIC technique from a simultaneous wireless information and power\ntransfer (SWIPT) standpoint. We consider a bipolar ad hoc network and evaluate\nthe impact of SIC on the SWIPT performance for the power splitting technique.\nTheoretical and numerical results show that our proposed approach can achieve\nsignificant energy gains and under certain scenarios the average harvested\nenergy converges to its upper bound. \n\n"}
{"id": "1605.01345", "contents": "Title: A Linearization Technique for Self-Interference Cancellation in\n  Full-Duplex Radios Abstract: The fundamental problem in the design of a full-duplex radio is the\ncancellation of the self-interference (SI) signal generated by the\ntransmitter.Current techniques for suppressing SI rely on generating a copy of\nthe SI signal and subtracting it partly in the RF (radio frequency) and digital\ndomains. A critical step in replicating the self-interference is the estimation\nof the multi-path channel through which the transmitted signal propagates to\nthe antenna. Since there is no prior model on the number of multipath\nreflections, current techniques assume a tap delay line filter (in the RF and\ndigital domain) with a large number of taps, and estimate the taps in the\nanalog and the digital domain. Assuming such a model leads to a large\nform-factor for the analog and RF circuits and increased complexity in the\ndigital domain.\n  In this paper, using a linearization technique, we show that the\nself-interference channel in an indoor environment can be effectively modelled\nas $H(f)=C_0 + C_1f$ in the frequency domain. Thus, the effective\nself-interference channel can be represented by two parameters $C_0$ and $C_1$,\nirrespective of the multipath environment. We also provide experimental\nevidence to verify the above channel model and propose novel low-complexity\ndesigns for self-interference cancellation. Linearization not only aids in the\npracticality of analog cancellation by reducing the form factor, but also\nresults in a simpler SI filter model in the digital domain due to\ndimensionality reduction of the channel parameters. Therefore this method can\nenable the widespread adoption of full-duplex techniques to portable devices in\naddition to infrastructure base-stations. \n\n"}
{"id": "1605.01690", "contents": "Title: Fog-Aided Wireless Networks for Content Delivery: Fundamental Latency\n  Trade-Offs Abstract: A fog-aided wireless network architecture is studied in which edge-nodes\n(ENs), such as base stations, are connected to a cloud processor via dedicated\nfronthaul links, while also being endowed with caches. Cloud processing enables\nthe centralized implementation of cooperative transmission strategies at the\nENs, albeit at the cost of an increased latency due to fronthaul transfer. In\ncontrast, the proactive caching of popular content at the ENs allows for the\nlow-latency delivery of the cached files, but with generally limited\nopportunities for cooperative transmission among the ENs. The interplay between\ncloud processing and edge caching is addressed from an information-theoretic\nviewpoint by investigating the fundamental limits of a high\nSignal-to-Noise-Ratio (SNR) metric, termed normalized delivery time (NDT),\nwhich captures the worst-case coding latency for delivering any requested\ncontent to the users. The NDT is defined under the assumptions of either serial\nor pipelined fronthaul-edge transmission, and is studied as a function of\nfronthaul and cache capacity constraints. Placement and delivery strategies\nacross both fronthaul and wireless, or edge, segments are proposed with the aim\nof minimizing the NDT. Information-theoretic lower bounds on the NDT are also\nderived. Achievability arguments and lower bounds are leveraged to characterize\nthe minimal NDT in a number of important special cases, including systems with\nno caching capabilities, as well as to prove that the proposed schemes achieve\noptimality within a constant multiplicative factor of 2 for all values of the\nproblem parameters. \n\n"}
{"id": "1605.02277", "contents": "Title: On-Average KL-Privacy and its equivalence to Generalization for\n  Max-Entropy Mechanisms Abstract: We define On-Average KL-Privacy and present its properties and connections to\ndifferential privacy, generalization and information-theoretic quantities\nincluding max-information and mutual information. The new definition\nsignificantly weakens differential privacy, while preserving its minimalistic\ndesign features such as composition over small group and multiple queries as\nwell as closeness to post-processing. Moreover, we show that On-Average\nKL-Privacy is **equivalent** to generalization for a large class of\ncommonly-used tools in statistics and machine learning that samples from Gibbs\ndistributions---a class of distributions that arises naturally from the maximum\nentropy principle. In addition, a byproduct of our analysis yields a lower\nbound for generalization error in terms of mutual information which reveals an\ninteresting interplay with known upper bounds that use the same quantity. \n\n"}
{"id": "1605.02821", "contents": "Title: Finite-Block-Length Analysis in Classical and Quantum Information Theory Abstract: Coding technology is used in several information processing tasks. In\nparticular, when noise during transmission disturbs communications, coding\ntechnology is employed to protect the information. However, there are two types\nof coding technology: coding in classical information theory and coding in\nquantum information theory. Although the physical media used to transmit\ninformation ultimately obey quantum mechanics, we need to choose the type of\ncoding depending on the kind of information device, classical or quantum, that\nis being used. In both branches of information theory, there are many elegant\ntheoretical results under the ideal assumption that an infinitely large system\nis available. In a realistic situation, we need to account for finite size\neffects. The present paper reviews finite size effects in classical and quantum\ninformation theory with respect to various topics, including applied aspects. \n\n"}
{"id": "1605.04042", "contents": "Title: Sum Degrees of Freedom of the $K$-user Interference Channel with Blind\n  CSI Abstract: In this paper, we consider the problem of the interference alignment for the\n$K$-user SISO interference channel (IC) with blind channel state information\n(CSI) at transmitters. Our achievement in contrast to the traditional $K-$user\ninterference alignment (IA) scheme has more practical notions. In this case,\nevery receiver is equipped with one reconfigurable antenna which tries to place\nits desired signal in a subspace which is linearly independent of interference\nsignals. We show that if the channel values are known to the receivers only,\nthe sum degrees-of-freedom (DoF) of the linear blind IA (BIA) with\nreconfigurable antenna is $\\frac{Kr}{r^2-r+K}$, where $r = \\left\n\\lceil{\\frac{\\sqrt{1+4K}-1}{2}} \\right \\rceil$. The result indicates that the\noptimum sum DoF for the $K-$user IC is to achieve the sum DoF of $\\lim_{K\n\\rightarrow \\infty} {\\frac{Kr}{r^2-r+K}}=\\frac{\\sqrt{K}}{2}$ for an\nasymptotically large interference network. Thus, the DoF of the $K$-user IC\nusing reconfigurable antenna grows sublinearly with the number of the users,\nwhereas it grows linearly in the case where transmitters access to the CSI. In\naddition, we propose both achievability and converse proof so as to show that\nthis is the sum DoF of linear BIA with the reconfigurable antenna. \n\n"}
{"id": "1605.04288", "contents": "Title: Almost all matroids are non-representable Abstract: We prove that, as $n$ approaches infinity, the proportion of $n$-element\nmatroids that are representable tends to zero. \n\n"}
{"id": "1605.05482", "contents": "Title: Non-negativity constraints in the one-dimensional discrete-time phase\n  retrieval problem Abstract: Phase retrieval problems occur in a width range of applications in physics\nand engineering such as crystallography, astronomy, and laser optics. Common to\nall of them is the recovery of an unknown signal from the intensity of its\nFourier transform. Because of the well-known ambiguousness of these problems,\nthe determination of the original signal is generally challenging. Although\nthere are many approaches in the literature to incorporate the assumption of\nnon-negativity of the solution into numerical algorithms, theoretical\nconsiderations about the solvability with this constraint occur rarely. In this\npaper, we consider the one-dimensional discrete-time setting and investigate\nwhether the usually applied a priori non-negativity can overcame the\nambiguousness of the phase retrieval problem or not. We show that the assumed\nnon-negativity of the solution is usually not a sufficient a priori condition\nto ensure uniqueness in one-dimensional phase retrieval. More precisely, using\nan appropriate characterization of the occurring ambiguities, we show that\nneither the uniqueness nor the ambiguousness are rare exceptions. \n\n"}
{"id": "1605.05614", "contents": "Title: Slotless Protocols for Fast and Energy-Efficient Neighbor Discovery Abstract: In mobile ad-hoc networks, neighbor discovery protocols are used to find\nsurrounding devices and to establish a first contact between them. Since the\nclocks of the devices are not synchronized and their energy-budgets are\nlimited, usually duty-cycled, asynchronous discovery protocols are applied.\nOnly if two devices are awake at the same point in time, they can rendezvous.\nCurrently, time-slotted protocols, which subdivide time into multiple intervals\nwith equal lengths (slots), are considered to be the most efficient discovery\nschemes. In this paper, we break away from the assumption of slotted time. We\npropose a novel, continuous-time discovery protocol, which temporally decouples\nbeaconing and listening. Each device periodically sends packets with a certain\ninterval, and periodically listens for a given duration with a different\ninterval. By optimizing these interval lengths, we show that this scheme can,\nto the best of our knowledge, outperform all known protocols such as DISCO,\nU-Connect or Searchlight significantly. For example, Searchlight takes up to\n740 % longer than our proposed technique to discover a device with the same\nduty-cycle. Further, our proposed technique can also be applied in widely-used\nasymmetric purely interval-based protocols such as ANT or Bluetooth Low Energy. \n\n"}
{"id": "1605.06844", "contents": "Title: Information-Theoretic Lower Bounds on the Storage Cost of Shared Memory\n  Emulation Abstract: The focus of this paper is to understand storage costs of emulating an atomic\nshared memory over an asynchronous, distributed message passing system.\nPrevious literature has developed several shared memory emulation algorithms\nbased on replication and erasure coding techniques. In this paper, we present\ninformation-theoretic lower bounds on the storage costs incurred by shared\nmemory emulation algorithms. Our storage cost lower bounds are universally\napplicable, that is, we make no assumption on the structure of the algorithm or\nthe method of encoding the data.\n  We consider an arbitrary algorithm $A$ that implements an atomic multi-writer\nsingle-reader (MWSR) shared memory variable whose values come from a finite set\n$\\mathcal{V}$ over a system of $N$ servers connected by point-to-point\nasynchronous links. We require that in every fair execution of algorithm $A$\nwhere the number of server failures is smaller than a parameter $f$, every\noperation invoked at a non-failing client terminates. We define the storage\ncost of a server in algorithm $A$ as the logarithm (to base 2) of number of\nstates it can take on; the total-storage cost of algorithm $A$ is the sum of\nthe storage cost of all servers.\n  Our results are as follows. (i) We show that if algorithm $A$ does not use\nserver gossip, then the total storage cost is lower bounded by $2\n\\frac{N}{N-f+1}\\log_2|\\mathcal{V}|-o(\\log_2|\\mathcal{V}|)$. (ii) The total\nstorage cost is at least $2 \\frac{N}{N-f+2}\n\\log_{2}|\\mathcal{V}|-o(\\log_{2}|\\mathcal{V}|)$ even if the algorithm uses\nserver gossip. (iii) We consider algorithms where the write protocol sends\ninformation about the value in at most one phase. We show that the total\nstorage cost is at least $\\nu^* \\frac{N}{N-f+\\nu^*-1} \\log_2( |\\mathcal{V}|)-\no(\\log_2(|\\mathcal{V}|),$ where $\\nu^*$ is the minimum of $f+1$ and the number\nof active write operations of an execution. \n\n"}
{"id": "1605.07516", "contents": "Title: Robust phase retrieval with the swept approximate message passing\n  (prSAMP) algorithm Abstract: In phase retrieval, the goal is to recover a complex signal from the\nmagnitude of its linear measurements. While many well-known algorithms\nguarantee deterministic recovery of the unknown signal using i.i.d. random\nmeasurement matrices, they suffer serious convergence issues some\nill-conditioned matrices. As an example, this happens in optical imagers using\nbinary intensity-only spatial light modulators to shape the input wavefront.\nThe problem of ill-conditioned measurement matrices has also been a topic of\ninterest for compressed sensing researchers during the past decade. In this\npaper, using recent advances in generic compressed sensing, we propose a new\nphase retrieval algorithm that well-adopts for both Gaussian i.i.d. and binary\nmatrices using both sparse and dense input signals. This algorithm is also\nrobust to the strong noise levels found in some imaging applications. \n\n"}
{"id": "1605.08023", "contents": "Title: Online Placement of Multi-Component Applications in Edge Computing\n  Environments Abstract: Mobile edge computing is a new cloud computing paradigm which makes use of\nsmall-sized edge-clouds to provide real-time services to users. These mobile\nedge-clouds (MECs) are located in close proximity to users, thus enabling users\nto seamlessly access applications running on MECs. Due to the co-existence of\nthe core (centralized) cloud, users, and one or multiple layers of MECs, an\nimportant problem is to decide where (on which computational entity) to place\ndifferent components of an application. This problem, known as the application\nor workload placement problem, is notoriously hard, and therefore, heuristic\nalgorithms without performance guarantees are generally employed in common\npractice, which may unknowingly suffer from poor performance as compared to the\noptimal solution. In this paper, we address the application placement problem\nand focus on developing algorithms with provable performance bounds. We model\nthe user application as an application graph and the physical computing system\nas a physical graph, with resource demands/availabilities annotated on these\ngraphs. We first consider the placement of a linear application graph and\npropose an algorithm for finding its optimal solution. Using this result, we\nthen generalize the formulation and obtain online approximation algorithms with\npolynomial-logarithmic (poly-log) competitive ratio for tree application graph\nplacement. We jointly consider node and link assignment, and incorporate\nmultiple types of computational resources at nodes. \n\n"}
{"id": "1605.08201", "contents": "Title: Towards optimal nonlinearities for sparse recovery using higher-order\n  statistics Abstract: We consider machine learning techniques to develop low-latency approximate\nsolutions to a class of inverse problems. More precisely, we use a\nprobabilistic approach for the problem of recovering sparse stochastic signals\nthat are members of the $\\ell_p$-balls. In this context, we analyze the\nBayesian mean-square-error (MSE) for two types of estimators: (i) a linear\nestimator and (ii) a structured estimator composed of a linear operator\nfollowed by a Cartesian product of univariate nonlinear mappings. By\nconstruction, the complexity of the proposed nonlinear estimator is comparable\nto that of its linear counterpart since the nonlinear mapping can be\nimplemented efficiently in hardware by means of look-up tables (LUTs). The\nproposed structure lends itself to neural networks and iterative\nshrinkage/thresholding-type algorithms restricted to a single iterate (e.g. due\nto imposed hardware or latency constraints). By resorting to an alternating\nminimization technique, we obtain a sequence of optimized linear operators and\nnonlinear mappings that converge in the MSE objective. The result is attractive\nfor real-time applications where general iterative and convex optimization\nmethods are infeasible. \n\n"}
{"id": "1605.09013", "contents": "Title: Flexible constrained de Finetti reductions and applications Abstract: De Finetti theorems show how sufficiently exchangeable states are\nwell-approximated by convex combinations of i.i.d. states. Recently, it was\nshown that in many quantum information applications a more relaxed de Finetti\nreduction (i.e. only a matrix inequality between the symmetric state and one of\nde Finetti form) is enough, and that it leads to more concise and elegant\narguments. Here we show several uses and general flexible applicability of a\nconstrained de Finetti reduction in quantum information theory, which was\nrecently discovered by Duan, Severini and Winter. In particular we show that\nthe technique can accommodate other symmetries commuting with the permutation\naction, and permutation-invariant linear constraints. We then demonstrate that,\nin some cases, it is also fruitful with convex constraints, in particular\nseparability in a bipartite setting. This is a constraint particularly\ninteresting in the context of the complexity class $\\mathrm{QMA}(2)$ of\ninteractive quantum Merlin-Arthur games with unentangled provers, and our\nresults relate to the soundness gap amplification of $\\mathrm{QMA}(2)$\nprotocols by parallel repetition. It is also relevant for the regularization of\ncertain entropic channel parameters. Finally, we explore an extension to\ninfinite-dimensional systems, which usually pose inherent problems to de\nFinetti techniques in the quantum case. \n\n"}
{"id": "1606.00161", "contents": "Title: An Alternating Qubit Protocol and Its Correctness Checking Abstract: In this paper, a quantum version of classical alternating bit protocol is\nproposed. This protocol provides a reliable method to transmit the secret\nquantum data via a noisy quantum channel while the entanglement between\nparticles is not broken. Our protocol is based on quantum teleportation and\nsuperdense coding. By assuming that the participants can distinguish the\nalternating qubit from other messages and also the assumption that data can be\nresent unlimited times, an abstraction of this protocol can be derived. Using\nthe quantum process algebra \\textit{full} $qACP$, we show that the proposed\nprotocol is correct, so the desired external behaviour of the protocol is\nguaranteed. \n\n"}
{"id": "1606.00717", "contents": "Title: Biased Contribution Index: A Simpler Mechanism to Maintain Fairness in\n  Peer to Peer Network Abstract: To maintain fairness, in the terms of resources shared by an individual peer,\na proper incentive policy is required in a peer to peer network. This letter\nproposes, a simpler mechanism to rank the peers based on their resource\ncontributions to the network. This mechanism will suppress the free riders from\ndownloading the resources from the network. Contributions of the peers are\nbiased in such a way that it can balance the download and upload amount of\nresources at each peer. This mechanism can be implemented in a distributed\nsystem and it converges much faster than the other existing approaches. \n\n"}
{"id": "1606.01567", "contents": "Title: Fast and Provable Algorithms for Spectrally Sparse Signal Reconstruction\n  via Low-Rank Hankel Matrix Completion Abstract: A spectrally sparse signal of order $r$ is a mixture of $r$ damped or\nundamped complex sinusoids. This paper investigates the problem of\nreconstructing spectrally sparse signals from a random subset of $n$ regular\ntime domain samples, which can be reformulated as a low rank Hankel matrix\ncompletion problem. We introduce an iterative hard thresholding (IHT) algorithm\nand a fast iterative hard thresholding (FIHT) algorithm for efficient\nreconstruction of spectrally sparse signals via low rank Hankel matrix\ncompletion. Theoretical recovery guarantees have been established for FIHT,\nshowing that $O(r^2\\log^2(n))$ number of samples are sufficient for exact\nrecovery with high probability. Empirical performance comparisons establish\nsignificant computational advantages for IHT and FIHT. In particular, numerical\nsimulations on $3$D arrays demonstrate the capability of FIHT on handling large\nand high-dimensional real data. \n\n"}
{"id": "1606.01745", "contents": "Title: Computing the generator polynomials of\n  $\\mathbb{Z}_2\\mathbb{Z}_4$-additive cyclic codes Abstract: A ${\\mathbb{Z}}_2{\\mathbb{Z}}_4$-additive code ${\\cal\nC}\\subseteq{\\mathbb{Z}}_2^\\alpha\\times{\\mathbb{Z}}_4^\\beta$ is called cyclic if\nthe set of coordinates can be partitioned into two subsets, the set of\n${\\mathbb{Z}}_2$ and the set of ${\\mathbb{Z}}_4$ coordinates, such that any\nsimultaneous cyclic shift of the coordinates of both subsets leaves invariant\nthe code. These codes can be identified as submodules of the\n$\\mathbb{Z}_4[x]$-module\n$\\mathbb{Z}_2[x]/(x^\\alpha-1)\\times\\mathbb{Z}_4[x]/(x^\\beta-1)$. Any\n$\\mathbb{Z}_2\\mathbb{Z}_4$-additive cyclic code ${\\cal C}$ is of the form\n$\\langle (b(x)\\mid{ 0}), (\\ell(x) \\mid f(x)h(x) +2f(x)) \\rangle$ for some\n$b(x), \\ell(x)\\in\\mathbb{Z}_2[x]/(x^\\alpha-1)$ and $f(x),h(x)\\in\n{\\mathbb{Z}}_4[x]/(x^\\beta-1)$. A new algorithm is presented to compute the\ngenerator polynomials for ${\\mathbb{Z}}_2{\\mathbb{Z}}_4$-additive cyclic codes. \n\n"}
{"id": "1606.01750", "contents": "Title: On the Degrees of Freedom of MIMO X Networks with Non-Cooperation\n  Transmitters Abstract: Due to limited backhaul/feedback link capacity and channel state information\n(CSI) feedback delay, obtaining global and instantaneous channel state\ninformation at the transmitter (CSIT) is a main obstacle in practice. In this\npaper, novel transmission schemes are proposed for a class of interference\nnetworks that can achieve new trade-off regions between the sum of degrees of\nfreedom (sum-DoF) and CSI feedback delay with distributed and\ntemperately-delayed CSIT. More specifically, a distributed space-time\ninterference alignment (STIA) scheme is proposed for the two-user\nmultiple-input multiple-output (MIMO) X channel via a novel precoding method\ncalled Cyclic Zero-padding. The achieved sum-DoFs herein for certain antenna\nconfigurations are greater than the best known sum-DoFs in literature with\ndelayed CSIT. Furthermore, we propose a distributed retrospective interference\nalignment (RIA) scheme that achieves more than 1 sum-DoF for the K-user\nsingle-input single-output (SISO) X network. Finally, we extend the distributed\nSTIA to the MxN user multiple-input single-output (MISO) X network where each\ntransmitter has N-1 antennas and each receiver has a single antenna, yielding\nthe same sum-DoF as that in the global and instantaneous CSIT case. The\ndiscussion and the result of the MISO X network can be extended to the MIMO\ncase due to spatial scale invariance property. \n\n"}
{"id": "1606.01946", "contents": "Title: Minimum-Information LQG Control - Part I: Memoryless Controllers Abstract: With the increased demand for power efficiency in feedback-control systems,\ncommunication is becoming a limiting factor, raising the need to trade off the\nexternal cost that they incur with the capacity of the controller's\ncommunication channels. With a proper design of the channels, this translates\ninto a sequential rate-distortion problem, where we minimize the rate of\ninformation required for the controller's operation under a constraint on its\nexternal cost. Memoryless controllers are of particular interest both for the\nsimplicity and frugality of their implementation and as a basis for studying\nmore complex controllers. In this paper we present the optimality principle for\nmemoryless linear controllers that utilize minimal information rates to achieve\na guaranteed external-cost level. We also study the interesting and useful\nphenomenology of the optimal controller, such as the principled reduction of\nits order. \n\n"}
{"id": "1606.02087", "contents": "Title: Continuous Transmission of Spatially-Coupled LDPC Code Chains Abstract: We propose a novel encoding/transmission scheme called continuous chain (CC)\ntransmission that is able to improve the finite-length performance of a system\nusing spatially-coupled low-density parity-check (SC-LDPC) codes. In CC\ntransmission, instead of transmitting a sequence of independent codewords from\na terminated SC-LDPC code chain, we connect multiple chains in a layered\nformat, where encoding, transmission, and decoding are now performed in a\ncontinuous fashion. The connections between chains are created at specific\npoints, chosen to improve the finite-length performance of the code structure\nunder iterative decoding. We describe the design of CC schemes for different\nSC-LDPC code ensembles constructed from protographs: a (J,K)-regular SC-LDPC\ncode chain, a spatially-coupled repeat-accumulate (SC-RA) code, and a\nspatially-coupled accumulate-repeat-jagged-accumulate (SC- ARJA) code. In all\ncases, significant performance improvements are reported and, in addition, it\nis shown that using CC transmission only requires a small increase in decoding\ncomplexity and decoding delay with respect to a system employing a single\nSC-LDPC code chain for transmission. \n\n"}
{"id": "1606.02809", "contents": "Title: On Uplink User Capacity for Massive MIMO Cellular Networks Abstract: Under the conditions where performance in a massive MIMO network is limited\nby pilot contamination, the reverse link signal-to-interference ratio (SIR)\nexhibits different distributions when using different pilot allocation schemes.\nBy utilising different sets of orthogonal pilot sequences, as opposed to reused\nsequences amongst adjacent cells, the resulting SIR distribution is more\nfavourable with respect to maximising the number of users on the network while\nmaintaining a given quality of service (QoS) for all users. This paper provides\na simple expression for uplink user capacity on such networks and presents\nuplink user capacity figures for both pilot allocation schemes for a selection\nof quality of service targets. \n\n"}
{"id": "1606.03182", "contents": "Title: Cyber Attack Thread: A Control-flow Based Approach to Deconstruct and\n  Mitigate Cyber Threats Abstract: Attacks in cyberspace have got attention due to risk at privacy, breach of\ntrust and financial losses for individuals as well as organizations. In recent\nyears, these attacks have become more complex to analyze technically, as well\nas to detect and prevent from accessing confidential data. Although there are\nmany methodologies and mechanisms which have been suggested for cyber-attack\ndetection and prevention, but not from the perspective of an attacker. This\npaper presents the cyber-defence as hindrances, faced by the attacker, by\nunderstanding attack thread and defence possibilities with existing security\nmechanisms. Seven phases of Cyber Attack Thread are introduced and technical\naspects are discussed with reference to APT attacks. The paper aims for\nsecurity practitioner and administrators as well as for the general audience to\nunderstand the attack scenario and defensive security measures. \n\n"}
{"id": "1606.03472", "contents": "Title: Super-Resolution From Binary Measurements With Unknown Threshold Abstract: We address the problem of super-resolution of point sources from binary\nmeasurements, where random projections of the blurred measurement of the actual\nsignal are encoded using only the sign information. The threshold used for\nbinary quantization is not known to the decoder. We develop an algorithm that\nsolves convex programs iteratively and achieves signal recovery. The proposed\nalgorithm, which we refer to as the binary super-resolution (BSR) algorithm,\nrecovers point sources with reasonable accuracy, albeit up to a scale factor.\nWe show through simulations that the BSR algorithm is successful in recovering\nthe locations and the amplitudes of the point sources, even in the presence of\nsignificant amount of blurring. We also propose a framework for handling noisy\nmeasurements and demonstrate that BSR gives a reliable reconstruction\n(correspondingly, reconstruction signal-to-noise ratio (SNR) of about 22 dB)\nfor a measurement SNR of 15 dB. \n\n"}
{"id": "1606.03639", "contents": "Title: Sparse Spectrum Sensing in Infrastructure-less Cognitive Radio Networks\n  via Binary Consensus Algorithms Abstract: Compressive Sensing has been utilized in Cognitive Radio Networks (CRNs) to\nexploit the sparse nature of the occupation of the primary users. Also,\ndistributed spectrum sensing has been proposed to tackle the wireless channel\nproblems, like node or link failures, rather than the common (centralized\napproach) for spectrum sensing. In this paper, we propose a distributed\nspectrum sensing framework based on consensus algorithms where SU nodes\nexchange their binary decisions to take global decisions without a fusion\ncenter to coordinate the sensing process. Each SU will share its decision with\nits neighbors, and at every new iteration each SU will take a new decision\nbased on its current decision and the decisions it receives from its neighbors;\nin the next iteration, each SU will share its new decision with its neighbors.\nWe show via simulations that the detection performance can tend to the\nperformance of majority rule Fusion Center based CRNs. \n\n"}
{"id": "1606.04073", "contents": "Title: On Probabilistic Shaping of Quadrature Amplitude Modulation for the\n  Nonlinear Fiber Channel Abstract: Different aspects of probabilistic shaping for a multi-span optical\ncommunication system are studied. First, a numerical analysis of the additive\nwhite Gaussian noise (AWGN) channel investigates the effect of using a small\nnumber of input probability mass functions (PMFs) for a range of\nsignal-to-noise ratios (SNRs), instead of optimizing the constellation shaping\nfor each SNR. It is shown that if a small penalty of at most 0.1 dB SNR to the\nfull shaping gain is acceptable, just two shaped PMFs are required per\nquadrature amplitude modulation (QAM) over a large SNR range. For a multi-span\nwavelength division multiplexing (WDM) optical fiber system with 64QAM input,\nit is shown that just one PMF is required to achieve large gains over uniform\ninput for distances from 1,400 km to 3,000 km. Using recently developed\ntheoretical models that extend the Gaussian noise (GN) model and full-field\nsplit-step simulations, we illustrate the ramifications of probabilistic\nshaping on the effective SNR after fiber propagation. Our results show that,\nfor a fixed average optical launch power, a shaping gain is obtained for the\nnoise contributions from fiber amplifiers and modulation-independent nonlinear\ninterference (NLI), whereas shaping simultaneously causes a penalty as it leads\nto an increased NLI. However, this nonlinear shaping loss is found to have a\nrelatively minor impact, and optimizing the shaped PMF with a\nmodulation-dependent GN model confirms that the PMF found for AWGN is also a\ngood choice for a multi-span fiber system. \n\n"}
{"id": "1606.04778", "contents": "Title: The Learning and Prediction of Application-level Traffic Data in\n  Cellular Networks Abstract: Traffic learning and prediction is at the heart of the evaluation of the\nperformance of telecommunications networks and attracts a lot of attention in\nwired broadband networks. Now, benefiting from the big data in cellular\nnetworks, it becomes possible to make the analyses one step further into the\napplication level. In this paper, we firstly collect a significant amount of\napplication-level traffic data from cellular network operators. Afterwards,\nwith the aid of the traffic \"big data\", we make a comprehensive study over the\nmodeling and prediction framework of cellular network traffic. Our results\nsolidly demonstrate that there universally exist some traffic statistical\nmodeling characteristics, including ALPHA-stable modeled property in the\ntemporal domain and the sparsity in the spatial domain. Meanwhile, the results\nalso demonstrate the distinctions originated from the uniqueness of different\nservice types of applications. Furthermore, we propose a new traffic prediction\nframework to encompass and explore these aforementioned characteristics and\nthen develop a dictionary learning-based alternating direction method to solve\nit. Besides, we validate the prediction accuracy improvement and the robustness\nof the proposed framework through extensive simulation results. \n\n"}
{"id": "1606.05825", "contents": "Title: Wireless network signals with moderately correlated shadowing still\n  appear Poisson Abstract: We consider the point process of signal strengths emitted from transmitters\nin a wireless network and observed at a fixed position. In our model,\ntransmitters are placed deterministically or randomly according to a hard core\nor Poisson point process and signals are subjected to power law path loss and\nrandom propagation effects that may be correlated between transmitters.\n  We provide bounds on the distance between the point process of signal\nstrengths and a Poisson process with the same mean measure, assuming correlated\nlog-normal shadowing. For \"strong shadowing\" and moderate correlations, we find\nthat the signal strengths are close to a Poisson process, generalizing a\nrecently shown analogous result for independent shadowing. \n\n"}
{"id": "1606.06099", "contents": "Title: Information Bounds and Flatness Factor Approximation for Fading Wiretap\n  MIMO Channels Abstract: In this article, the design of secure lattice coset codes for general\nwireless channels with fading and Gaussian noise is studied. Recalling the\neavesdropper's probability and information bounds, a variant of the latter is\ngiven from which it is explicitly seen that both quantities are upper bounded\nby (increasing functions of) the expected flatness factor of the faded lattice\nrelated to the eavesdropper.\n  By making use of a recently developed approximation of the theta series of a\nlattice, it is further shown how the average flatness factor can be\napproximated numerically. In particular, based on the numerical computations,\nthe average flatness factor not only bounds but also orders correctly the\nperformance of different lattices. \n\n"}
{"id": "1606.07561", "contents": "Title: On (Secure) Information flow for Multiple-Unicast Sessions: Analysis\n  with Butterfly Network Abstract: This paper considers a class of wireline networks, derived from the\nwell-known butterfly network, over which two independent unicast sessions take\nplace simultaneously. The main objectives are to understand when network coding\ntype of operations are beneficial with and without security considerations and\nto derive the ultimate gains that cooperation among sources and sinks can\nbring. Towards these goals, the capacity region of the butterfly network with\narbitrary edge capacities is first derived. It is then shown that no rate can\nbe guaranteed over this network under security considerations, when an\neavesdropper wiretaps any of the links. Three variants of the butterfly\nnetwork, such as the case of co-located sources, are analyzed as well and their\nsecure and non-secure capacity regions are characterized. By using the\nbutterfly network and its variants as building blocks, these results can be\nused to design high-throughput achieving transmission schemes for general\nmultiple-unicast networks. \n\n"}
{"id": "1607.00235", "contents": "Title: PIR Array Codes with Optimal Virtual Server Rate Abstract: There has been much recent interest in Private information Retrieval (PIR) in\nmodels where a database is stored across several servers using coding\ntechniques from distributed storage, rather than being simply replicated. In\nparticular, a recent breakthrough result of Fazelli, Vardy and Yaakobi\nintroduces the notion of a PIR code and a PIR array code, and uses this notion\nto produce efficient PIR protocols.\n  In this paper we are interested in designing PIR array codes. We consider the\ncase when we have $m$ servers, with each server storing a fraction $(1/s)$ of\nthe bits of the database; here $s$ is a fixed rational number with $s > 1$. A\nPIR array code with the $k$-PIR property enables a $k$-server PIR protocol\n(with $k\\leq m$) to be emulated on $m$ servers, with the overall storage\nrequirements of the protocol being reduced. The communication complexity of a\nPIR protocol reduces as $k$ grows, so the virtual server rate, defined to be\n$k/m$, is an important parameter. We study the maximum virtual server rate of a\nPIR array code with the $k$-PIR property. We present upper bounds on the\nachievable virtual server rate, some constructions, and ideas how to obtain PIR\narray codes with the highest possible virtual server rate. In particular, we\npresent constructions that asymptotically meet our upper bounds, and the exact\nlargest virtual server rate is obtained when $1 < s \\leq 2$.\n  A $k$-PIR code (and similarly a $k$-PIR array code) is also a locally\nrepairable code with symbol availability $k-1$. Such a code ensures $k$\nparallel reads for each information symbol. So the virtual server rate is very\nclosely related to the symbol availability of the code when used as a locally\nrepairable code. The results of this paper are discussed also in this context,\nwhere subspace codes also have an important role. \n\n"}
{"id": "1607.01537", "contents": "Title: Optimal Locally Repairable Systematic Codes Based on Packings Abstract: Locally repairable codes are desirable for distributed storage systems to\nimprove the repair efficiency. In this paper, we first build a bridge between\nlocally repairable code and packing. As an application of this bridge, some\noptimal locally repairable codes can be obtained by packings, which gives\noptimal locally repairable codes with flexible parameters. \n\n"}
{"id": "1607.02279", "contents": "Title: Rates of DNA Sequence Profiles for Practical Values of Read Lengths Abstract: A recent study by one of the authors has demonstrated the importance of\nprofile vectors in DNA-based data storage. We provide exact values and lower\nbounds on the number of profile vectors for finite values of alphabet size $q$,\nread length $\\ell$, and word length $n$.Consequently, we demonstrate that for\n$q\\ge 2$ and $n\\le q^{\\ell/2-1}$, the number of profile vectors is at least\n$q^{\\kappa n}$ with $\\kappa$ very close to one.In addition to enumeration\nresults, we provide a set of efficient encoding and decoding algorithms for\neach of two particular families of profile vectors. \n\n"}
{"id": "1607.02668", "contents": "Title: Optimal Joint Power and Subcarrier Allocation for Full-Duplex\n  Multicarrier Non-Orthogonal Multiple Access Systems Abstract: In this paper, we investigate resource allocation algorithm design for\nmulticarrier non-orthogonal multiple access (MC-NOMA) systems employing a\nfull-duplex (FD) base station (BS) for serving multiple half-duplex (HD)\ndownlink (DL) and uplink (UL) users simultaneously. The proposed algorithm is\nobtained from the solution of a non-convex optimization problem for the\nmaximization of the weighted sum system throughput. We apply monotonic\noptimization to develop an optimal joint power and subcarrier allocation\npolicy. The optimal resource allocation policy serves as a system performance\nbenchmark due to its high computational complexity. Furthermore, a suboptimal\niterative scheme based on successive convex approximation is proposed to strike\na balance between computational complexity and optimality. Our simulation\nresults reveal that the proposed suboptimal algorithm achieves a\nclose-to-optimal performance. Besides, FD MC-NOMA systems employing the\nproposed resource allocation algorithms provide a substantial system throughput\nimprovement compared to conventional HD multicarrier orthogonal multiple access\n(MC-OMA) systems and other baseline schemes. Also, our results unveil that the\nproposed FD MC-NOMA systems achieve a fairer resource allocation compared to\ntraditional HD MC-OMA systems. \n\n"}
{"id": "1607.03025", "contents": "Title: Data Dissemination using Instantly Decodable Binary Codes in Fog-Radio\n  Access Networks Abstract: Consider a device-to-device (D2D) fog-radio access network wherein a set of\ndevices are required to store a set of files. Each device is connected to a\nsubset of the cloud data centers and thus possesses a subset of the data. This\npaper investigates the problem of disseminating all files among the devices\nwhile reducing the total time of communication, i.e., the completion time,\nusing instantly decodable network coding (IDNC). While previous studies on the\nuse of IDNC in D2D systems assume a fully connected communication network, this\npaper tackles the more realistic scenario of a partially connected network in\nwhich devices can only target devices in their transmission range. The paper\nfirst formulates the optimal joint optimization of selecting the transmitting\ndevice(s) and the file combination(s) and exhibits its intractability. The\ncompletion time is approximated using the celebrated decoding delay approach by\nderiving the relationship between the quantities in a partially connected\nnetwork. The paper introduces the cooperation graph and demonstrates that the\nrelaxed problem is equivalent to a maximum weight clique problem over the newly\ndesigned graph wherein the weights are obtained by solving a similar problem on\nthe local IDNC graphs. Extensive simulations reveal that the proposed solution\nprovides noticeable performance enhancement and outperforms previously proposed\nIDNC-based schemes. \n\n"}
{"id": "1607.03132", "contents": "Title: Density of Spherically-Embedded Stiefel and Grassmann Codes Abstract: The density of a code is the fraction of the coding space covered by packing\nballs centered around the codewords. This paper investigates the density of\ncodes in the complex Stiefel and Grassmann manifolds equipped with the chordal\ndistance. The choice of distance enables the treatment of the manifolds as\nsubspaces of Euclidean hyperspheres. In this geometry, the densest packings are\nnot necessarily equivalent to maximum-minimum-distance codes. Computing a\ncode's density follows from computing: i) the normalized volume of a metric\nball and ii) the kissing radius, the radius of the largest balls one can pack\naround the codewords without overlapping. First, the normalized volume of a\nmetric ball is evaluated by asymptotic approximations. The volume of a small\nball can be well-approximated by the volume of a locally-equivalent tangential\nball. In order to properly normalize this approximation, the precise volumes of\nthe manifolds induced by their spherical embedding are computed. For larger\nballs, a hyperspherical cap approximation is used, which is justified by a\nvolume comparison theorem showing that the normalized volume of a ball in the\nStiefel or Grassmann manifold is asymptotically equal to the normalized volume\nof a ball in its embedding sphere as the dimension grows to infinity. Then,\nbounds on the kissing radius are derived alongside corresponding bounds on the\ndensity. Unlike spherical codes or codes in flat spaces, the kissing radius of\nGrassmann or Stiefel codes cannot be exactly determined from its minimum\ndistance. It is nonetheless possible to derive bounds on density as functions\nof the minimum distance. Stiefel and Grassmann codes have larger density than\ntheir image spherical codes when dimensions tend to infinity. Finally, the\nbounds on density lead to refinements of the standard Hamming bounds for\nStiefel and Grassmann codes. \n\n"}
{"id": "1607.03651", "contents": "Title: $r-$Bell polynomials in combinatorial Hopf algebras Abstract: We introduce partial $r$-Bell polynomials in three combinatorial Hopf\nalgebras. We prove a factorization formula for the generating functions which\nis a consequence of the Zassenhauss formula. \n\n"}
{"id": "1607.03725", "contents": "Title: Millimeter Wave Receiver Efficiency: A Comprehensive Comparison of\n  Beamforming Schemes with Low Resolution ADCs Abstract: In this work, we study the achievable rate and the energy efficiency of\nAnalog, Hybrid and Digital Combining (AC, HC and DC) for millimeter wave (mmW)\nreceivers. We take into account the power consumption of all receiver\ncomponents, not just Analog-to-Digital Converters (ADC), determine some\npractical limitations of beamforming in each architecture, and develop\nperformance analysis charts that enable comparison of different receivers\nsimultaneously in terms of two metrics, namely, Spectral Efficiency (SE) and\nEnergy Efficiency (EE). We present a multi-objective utility optimization\ninterpretation to find the best SE-EE weighted trade-off among AC, DC and HC\nschemes. We consider an Additive Quantization Noise Model (AQNM) to evaluate\nthe achievable rates with low resolution ADCs. Our analysis shows that AC is\nonly advantageous if the channel rank is strictly one, the link has very low\nSNR, or there is a very stringent low power constraint at the receiver.\nOtherwise, we show that the usual claim that DC requires the highest power is\nnot universally valid. Rather, either DC or HC alternatively result in the\nbetter SE vs EE trade-off depending strongly on the considered power\nconsumption characteristic values for each component of the mmW receiver. \n\n"}
{"id": "1607.04333", "contents": "Title: Unequal Error Protection in Coded Slotted ALOHA Abstract: We analyze the performance of coded slotted ALOHA systems for a scenario\nwhere users have different error protection requirements and correspondingly\ncan be divided into user classes. The main goal is to design the system so that\nthe requirements for each class are satisfied. To that end, we derive\nanalytical error floor approximations of the packet loss rate for each class in\nthe finite frame length regime, as well as the density evolution in the\nasymptotic case. Based on this analysis, we propose a heuristic approach for\nthe optimization of the degree distributions to provide the required unequal\nerror protection. In addition, we analyze the decoding delay for users in\ndifferent classes and show that better protected users experience a smaller\naverage decoding delay. \n\n"}
{"id": "1607.04815", "contents": "Title: Infinite families of $t$-designs from a type of five-weight codes Abstract: It has been known for a long time that $t$-designs can be employed to\nconstruct both linear and nonlinear codes and that the codewords of a fixed\nweight in a code may hold a $t$-design. While a lot of progress in the\ndirection of constructing codes from $t$-designs has been made, only a small\namount of work on the construction of $t$-designs from codes has been done. The\nobjective of this paper is to construct infinite families of $2$-designs and\n$3$-designs from a type of binary linear codes with five-weights. The total\nnumber of $2$-designs and $3$-designs obtained in this paper are exponential in\nany odd $m$ and the block size of the designs varies in a huge range. \n\n"}
{"id": "1607.06521", "contents": "Title: Joint Uplink/Downlink Optimization for Backhaul-Limited Mobile Cloud\n  Computing with User Scheduling Abstract: Mobile cloud computing enables the offloading of computationally heavy\napplications, such as for gaming, object recognition or video processing, from\nmobile users (MUs) to cloudlet or cloud servers, which are connected to\nwireless access points, either directly or through finite-capacity backhaul\nlinks. In this paper, the design of a mobile cloud computing system is\ninvestigated by proposing the joint optimization of computing and communication\nresources with the aim of minimizing the energy required for offloading across\nall MUs under latency constraints at the application layer. The proposed design\naccounts for multiantenna uplink and downlink interfering transmissions, with\nor without cooperation on the downlink, along with the allocation of backhaul\nand computational resources and user selection. The resulting design\noptimization problems are nonconvex, and stationary solutions are computed by\nmeans of successive convex approximation (SCA) techniques. Numerical results\nillustrate the advantages in terms of energy-latency trade-off of the joint\noptimization of computing and communication resources, as well as the impact of\nsystem parameters, such as backhaul capacity, and of the network architecture. \n\n"}
{"id": "1607.07241", "contents": "Title: Hilbert quasi-polynomial for order domains and application to coding\n  theory Abstract: We present an application of Hilbert quasi-polynomials to order domains,\nallowing the effective check of the second order-domain condition in a direct\nway. We also provide an improved algorithm for the computation of the related\nHilbert quasi-polynomials. This allows to identify order domain codes more\neasily. \n\n"}
{"id": "1607.07335", "contents": "Title: An Explicit, Coupled-Layer Construction of a High-Rate MSR Code with Low\n  Sub-Packetization Level, Small Field Size and All-Node Repair Abstract: This paper presents an explicit construction for an $((n,k,d=n-1),\n(\\alpha,\\beta))$ regenerating code over a field $\\mathbb{F}_Q$ operating at the\nMinimum Storage Regeneration (MSR) point. The MSR code can be constructed to\nhave rate $k/n$ as close to $1$ as desired, sub-packetization given by\n$r^{\\frac{n}{r}}$, for $r=(n-k)$, field size no larger than $n$ and where all\ncode symbols can be repaired with the same minimum data download. The\nconstruction modifies a prior construction by Sasidharan et. al. which required\nfar larger field-size. A building block appearing in the construction is a\nscalar MDS code of block length $n$. The code has a simple layered structure\nwith coupling across layers, that allows both node repair and data recovery to\nbe carried out by making multiple calls to a decoder for the scalar MDS code.\nWhile this work was carried out independently, there is considerable overlap\nwith a prior construction by Ye and Barg.\n  It is shown here that essentially the same architecture can be employed to\nconstruct MSR codes using vector binary MDS codes as building blocks in place\nof scalar MDS codes. The advantage here is that computations can now be carried\nout over a field of smaller size potentially even over the binary field as we\ndemonstrate in an example. Further, we show how the construction can be\nextended to handle the case of $d<(n-1)$ under a mild restriction on the choice\nof helper nodes. \n\n"}
{"id": "1608.00095", "contents": "Title: Service Function Chaining Resource Allocation: A Survey Abstract: Service Function Chaining (SFC) is a crucial technology for future Internet.\nIt aims to overcome the limitation of current deployment models which is rigid\nand static. Application of this technology relies on algorithms that can\noptimally mapping SFC to substrate network. This category of algorithms is\nreferred as \"Service Function Chaining Resource Allocation (SFC-RA)\" algorithms\nor \"VNF placement (VNFP)\" algorithms. This paper presents a survey of current\nresearches in SFC-RA algorithms. After presenting the formulation and related\nproblems, several variants of SFC-RA problem are summarized. At last, we\ndiscussed several future research directions. \n\n"}
{"id": "1608.04459", "contents": "Title: Entanglement as an axiomatic foundation for statistical mechanics Abstract: We propose four information-theoretic axioms for the foundations of\nstatistical mechanics in general physical theories. The axioms---Causality,\nPurity Preservation, Pure Sharpness, and Purification---identify a class of\ntheories where every mixed state can be modelled as the marginal of a pure\nentangled state and where every unsharp measurement can be modelled as a sharp\nmeasurement on a composite system. This class of theories, called sharp\ntheories with purification, includes quantum theory both with complex and real\namplitudes, as well as a suitable extension of classical probability theory\nwhere classical systems can be entangled with other, non-classical systems.\nTheories satisfying our axioms support well-behaved notions of majorization,\nentropy, and Gibbs states, allowing for an information-theoretic derivation of\nLandauer's principle. We conjecture that every theory admitting a sensible\nthermodynamics must be extendable to a sharp theory with purification. \n\n"}
{"id": "1608.05430", "contents": "Title: Entropy Jumps for Radially Symmetric Random Vectors Abstract: We establish a quantitative bound on the entropy jump associated to the sum\nof independent, identically distributed (IID) radially symmetric random vectors\nhaving dimension greater than one. Following the usual approach, we first\nconsider the analogous problem of Fisher information dissipation, and then\nintegrate along the Ornstein-Uhlenbeck semigroup to obtain an entropic\ninequality. In a departure from previous work, we appeal to a result by\nDesvillettes and Villani on entropy production associated to the Landau\nequation. This obviates strong regularity assumptions, such as presence of a\nspectral gap and log-concavity of densities, but comes at the expense of radial\nsymmetry. As an application, we give a quantitative estimate of the deficit in\nthe Gaussian logarithmic Sobolev inequality for radially symmetric functions. \n\n"}
{"id": "1608.05493", "contents": "Title: Network Volume Anomaly Detection and Identification in Large-scale\n  Networks based on Online Time-structured Traffic Tensor Tracking Abstract: This paper addresses network anomography, that is, the problem of inferring\nnetwork-level anomalies from indirect link measurements. This problem is cast\nas a low-rank subspace tracking problem for normal flows under incomplete\nobservations, and an outlier detection problem for abnormal flows. Since\ntraffic data is large-scale time-structured data accompanied with noise and\noutliers under partial observations, an efficient modeling method is essential.\nTo this end, this paper proposes an online subspace tracking of a Hankelized\ntime-structured traffic tensor for normal flows based on the Candecomp/PARAFAC\ndecomposition exploiting the recursive least squares (RLS) algorithm. We\nestimate abnormal flows as outlier sparse flows via sparsity maximization in\nthe underlying under-constrained linear-inverse problem. A major advantage is\nthat our algorithm estimates normal flows by low-dimensional matrices with\ntime-directional features as well as the spatial correlation of multiple links\nwithout using the past observed measurements and the past model parameters.\nExtensive numerical evaluations show that the proposed algorithm achieves\nfaster convergence per iteration of model approximation, and better volume\nanomaly detection performance compared to state-of-the-art algorithms. \n\n"}
{"id": "1608.07857", "contents": "Title: Optimizing Content Caching to Maximize the Density of Successful\n  Receptions in Device-to-Device Networking Abstract: Device-to-device (D2D) communication is a promising approach to optimize the\nutilization of air interface resources in 5G networks, since it allows\ndecentralized opportunistic short-range communication. For D2D to be useful,\nmobile nodes must possess content that other mobiles want. Thus, intelligent\ncaching techniques are essential for D2D. In this paper we use results from\nstochastic geometry to derive the probability of successful content delivery in\nthe presence of interference and noise. We employ a general transmission\nstrategy where multiple files are cached at the users and different files can\nbe transmitted simultaneously throughout the network. We then formulate an\noptimization problem, and find the caching distribution that maximizes the\ndensity of successful receptions (DSR) under a simple transmission strategy\nwhere a single file is transmitted at a time throughout the network. We model\nfile requests by a Zipf distribution with exponent $\\gamma_r$, which results in\nan optimal caching distribution that is also a Zipf distribution with exponent\n$\\gamma_c$, which is related to $\\gamma_r$ through a simple expression\ninvolving the path loss exponent. We solve the optimal content placement\nproblem for more general demand profiles under Rayleigh, Ricean and Nakagami\nsmall-scale fading distributions. Our results suggest that it is required to\nflatten the request distribution to optimize the caching performance. We also\ndevelop strategies to optimize content caching for the more general case with\nmultiple files, and bound the DSR for that scenario. \n\n"}
{"id": "1608.08182", "contents": "Title: Data Poisoning Attacks on Factorization-Based Collaborative Filtering Abstract: Recommendation and collaborative filtering systems are important in modern\ninformation and e-commerce applications. As these systems are becoming\nincreasingly popular in the industry, their outputs could affect business\ndecision making, introducing incentives for an adversarial party to compromise\nthe availability or integrity of such systems. We introduce a data poisoning\nattack on collaborative filtering systems. We demonstrate how a powerful\nattacker with full knowledge of the learner can generate malicious data so as\nto maximize his/her malicious objectives, while at the same time mimicking\nnormal user behavior to avoid being detected. While the complete knowledge\nassumption seems extreme, it enables a robust assessment of the vulnerability\nof collaborative filtering schemes to highly motivated attacks. We present\nefficient solutions for two popular factorization-based collaborative filtering\nalgorithms: the \\emph{alternative minimization} formulation and the\n\\emph{nuclear norm minimization} method. Finally, we test the effectiveness of\nour proposed algorithms on real-world data and discuss potential defensive\nstrategies. \n\n"}
{"id": "1608.08313", "contents": "Title: Sub-channel Assignment, Power Allocation and User Scheduling for\n  Non-Orthogonal Multiple Access Networks Abstract: In this paper, we study the resource allocation and user scheduling problem\nfor a downlink nonorthogonal multiple access network where the base station\nallocates spectrum and power resources to a set of users. We aim to jointly\noptimize the sub-channel assignment and power allocation to maximize the\nweighted total sum-rate while taking into account user fairness. We formulate\nthe sub-channel allocation problem as equivalent to a many-to-many two-sided\nuser-subchannel matching game in which the set of users and sub-channels are\nconsidered as two sets of players pursuing their own interests. We then propose\na matching algorithm which converges to a two-side exchange stable matching\nafter a limited number of iterations. A joint solution is thus provided to\nsolve the sub-channel assignment and power allocation problems iteratively.\nSimulation results show that the proposed algorithm greatly outperforms the\northogonal multiple access scheme and a previous non-orthogonal multiple access\nscheme. \n\n"}
{"id": "1609.01030", "contents": "Title: Device-independent characterizations of a shared quantum state\n  independent of any Bell inequalities Abstract: In a Bell experiment two parties share a quantum state and perform local\nmeasurements on their subsystems separately, and the statistics of the\nmeasurement outcomes are recorded as a Bell correlation. For any Bell\ncorrelation, it turns out {that} a quantum state with minimal size that is able\nto produce this correlation can always be pure. In this work, we first exhibit\ntwo device-independent characterizations for the pure state that Alice and Bob\nshare using only the correlation data. Specifically, we give two conditions\nthat the Schmidt coefficients must satisfy, which can be tight, and have\nvarious applications in quantum tasks. First, one of the characterizations\nallows us to bound the entanglement between Alice and Bob using Renyi entropies\nand also to {bound} the underlying Hilbert space dimension. Second, when the\n{Hilbert space dimension bound} is tight, the shared pure quantum state has to\nbe maximally entangled. Third, the second characterization gives a sufficient\ncondition that a Bell correlation cannot be generated by particular quantum\nstates. We also show that our results can be generalized to the case of shared\nmixed states. \n\n"}
{"id": "1609.01795", "contents": "Title: MC^2: A Two-Phase Algorithm for Leveraged Matrix Completion Abstract: Leverage scores, loosely speaking, reflect the importance of the rows and\ncolumns of a matrix. Ideally, given the leverage scores of a rank-$r$ matrix\n$M\\in\\mathbb{R}^{n\\times n}$, that matrix can be reliably completed from just\n$O(rn\\log^{2}n)$ samples if the samples are chosen randomly from a nonuniform\ndistribution induced by the leverage scores. In practice, however, the leverage\nscores are often unknown a priori. As such, the sample complexity in uniform\nmatrix completion---using uniform random sampling---increases to\n$O(\\eta(M)\\cdot rn\\log^{2}n)$, where $\\eta(M)$ is the largest leverage score of\n$M$. In this paper, we propose a two-phase algorithm called MC$^2$ for matrix\ncompletion: in the first phase, the leverage scores are estimated based on\nuniform random samples, and then in the second phase the matrix is resampled\nnonuniformly based on the estimated leverage scores and then completed. For\nwell-conditioned matrices, the total sample complexity of MC$^2$ is no worse\nthan uniform matrix completion, and for certain classes of well-conditioned\nmatrices---namely, reasonably coherent matrices whose leverage scores exhibit\nmild decay---MC$^2$ requires substantially fewer samples. Numerical simulations\nsuggest that the algorithm outperforms uniform matrix completion in a broad\nclass of matrices, and in particular, is much less sensitive to the condition\nnumber than our theory currently requires. \n\n"}
{"id": "1609.03106", "contents": "Title: On Some Universally Good Fractional Repetition Codes Abstract: Data storage in Distributed Storage Systems (DSSs) is a multidimensional\noptimization problem. Using network coding, one wants to provide reliability,\nscalability, security, reduced storage overhead, reduced bandwidth for repair\nand minimal disk I/O etc. in such systems. Regenerating codes have been used to\noptimize some of these parameters, where a file can be reconstructed by\ncontacting any k nodes in the system and in case of node failure it can be\nrepaired by using any d nodes in the system. This was further generalized to\nFractional repetition (FR) codes (a smart replication of encoded packets) on n\nnodes which also provides optimized disk I/O and where a node failure can be\nrepaired by contacting some specific set of nodes in the system. Several\nconstructions of FR codes using graphs and combinatorial designs are known. In\nparticular, some constructions of codes for heterogeneous DSSs are given using\npartial regular graph (where number of packets on each node is different) and\nring construction. In this work, we show that the codes constructed using the\npartial regular graph are universally good code. Further, we found several\nuniversally good codes using ring construction and t-construction. \n\n"}
{"id": "1609.03498", "contents": "Title: LTE in Unlicensed Bands is neither Friend nor Foe to Wi-Fi Abstract: Proponents of deploying LTE in the 5 GHz band for providing additional\ncellular network capacity have claimed that LTE would be a better neighbour to\nWi-Fi in the unlicensed band, than Wi-Fi is to itself. On the other side of the\ndebate, the Wi-Fi community has objected that LTE would be highly detrimental\nto Wi-Fi network performance. However, there is a lack of transparent and\nsystematic engineering evidence supporting the contradicting claims of the two\ncamps, which is essential for ascertaining whether regulatory intervention is\nin fact required to protect the Wi-Fi incumbent from the new LTE entrant. To\nthis end, we present a comprehensive coexistence study of Wi-Fi and\nLTE-in-unlicensed, surveying a large parameter space of coexistence mechanisms\nand a range of representative network densities and deployment scenarios. Our\nresults show that, typically, harmonious coexistence between Wi-Fi and LTE is\nensured by the large number of 5 GHz channels. For the worst-case scenario of\nforced co-channel operation, LTE is sometimes a better neighbour to Wi-Fi -\nwhen effective node density is low - but sometimes worse - when density is\nhigh. We find that distributed interference coordination is only necessary to\nprevent a \"tragedy of the commons\" in regimes where interference is very\nlikely. We also show that in practice it does not make a difference to the\nincumbent what kind of coexistence mechanism is added to LTE-in-unlicensed, as\nlong as one is in place. We therefore conclude that LTE is neither friend nor\nfoe to Wi-Fi in the unlicensed bands in general. We submit that the systematic\nengineering analysis exemplified by our case study is a best-practice approach\nfor supporting evidence-based rulemaking by the regulator. \n\n"}
{"id": "1609.05178", "contents": "Title: Privacy Preserving Distance Computation using Somewhat-trusted Third\n  Parties Abstract: A critically important component of most signal processing procedures is that\nof computing the distance between signals. In multi-party processing\napplications where these signals belong to different parties, this introduces\nprivacy challenges. The signals may themselves be private, and the parties to\nthe computation may not be willing to expose them. Solutions proposed to the\nproblem in the literature generally invoke homomorphic encryption schemes,\nsecure multi-party computation, or other cryptographic methods which introduce\nsignificant computational complexity into the proceedings, often to the point\nof making more complex computations requiring repeated computations unfeasible.\nOther solutions invoke third parties, making unrealistic assumptions about\ntheir trustworthiness.\n  In this paper we propose an alternate approach, also based on third party\ncomputation, but without assuming as much trust in the third party. Individual\nparticipants to the computation \"secure\" their data through a proposed secure\nhashing scheme with shared keys, prior to sharing it with the third party. The\nhashing ensures that the third party cannot recover any information about the\nindividual signals or their statistics, either from analysis of individual\ncomputations or their long-term aggregate patterns. We provide theoretical\nproof of these properties and empirical demonstration of the feasibility of the\ncomputation. \n\n"}
{"id": "1609.07027", "contents": "Title: PIR schemes with small download complexity and low storage requirements Abstract: In the classical model for (information theoretically secure) Private\nInformation Retrieval (PIR), a user wishes to retrieve one bit of a database\nthat is stored on a set of $n$ servers, in such a way that no individual server\ngains information about which bit the user is interested in. The aim is to\ndesign schemes that minimise communication between the user and the servers.\nMore recently, there have been moves to consider more realistic models where\nthe total storage of the set of servers, or the per server storage, should be\nminimised (possibly using techniques from distributed storage), and where the\ndatabase is divided into $R$-bit records with $R>1$, and the user wishes to\nretrieve one record rather than one bit. When $R$ is large, downloads from the\nservers to the user dominate the communication complexity and so the aim is to\nminimise the total number of downloaded bits. Shah, Rashmi and Ramchandran show\nthat at least $R+1$ bits must be downloaded from servers in the worst case, and\nprovide PIR schemes meeting this bound. Sun and Jafar determine the best\nasymptotic download cost of a PIR scheme (as $R\\rightarrow\\infty$), where this\ncost is defined as the ratio of the message length $R$ and the total number of\nbits downloaded.\n  This paper provides various bounds on the download complexity of a PIR\nscheme, generalising those of Shah et al. to the case when the number $n$ of\nservers is bounded, and providing links with classical techniques due to Chor\net al. The paper also provides a range of constructions for PIR schemes that\nare either simpler or perform better than previously known schemes, including\nexplicit schemes that achieve the best asymptotic download complexity of Sun\nand Jafar with significantly lower upload complexity, and general techniques\nfor constructing a scheme with good worst case download complexity from a\nscheme with good download complexity on average. \n\n"}
{"id": "1609.07256", "contents": "Title: Towards Fairness of Cryptocurrency Payments Abstract: Motivated by the great success and adoption of Bitcoin, a number of\ncryptocurrencies such as Litecoin, Dogecoin, and Ethereum are becoming\nincreasingly popular. Although existing blockchain-based cryptocurrency schemes\ncan ensure reasonable security for transactions, they do not consider any\nnotion of fairness. Fair exchange allows two players to exchange digital\n\"items\", such as digital signatures, over insecure networks fairly, so that\neither each player gets the other's item, or neither player does. Given that\nblockchain participants typically do not trust each other, enabling fairness in\nexisting cryptocurrencies is an essential but insufficiently explored problem.\n  In this paper, we explore the solution space for enabling the fair exchange\nof a cryptocurrency payment for a receipt. We identify the timeliness of an\nexchange as an important property especially when one of the parties involved\nin the exchange is resource-constrained. We introduce the notion of strong\ntimeliness for a fair exchange protocol and propose two fair\npayment-for-receipt protocol instantiations that leverage functionality of the\nblockchain to achieve strong timeliness. We implement both and compare their\nsecurity and efficiency. \n\n"}
{"id": "1609.08138", "contents": "Title: The Capacity of Private Information Retrieval from Coded Databases Abstract: We consider the problem of private information retrieval (PIR) over a\ndistributed storage system. The storage system consists of $N$ non-colluding\ndatabases, each storing a coded version of $M$ messages. In the PIR problem,\nthe user wishes to retrieve one of the available messages without revealing the\nmessage identity to any individual database. We derive the\ninformation-theoretic capacity of this problem, which is defined as the maximum\nnumber of bits of the desired message that can be privately retrieved per one\nbit of downloaded information. We show that the PIR capacity in this case is\n$C=\\left(1+\\frac{K}{N}+\\frac{K^2}{N^2}+\\cdots+\\frac{K^{M-1}}{N^{M-1}}\\right)^{-1}=(1+R_c+R_c^2+\\cdots+R_c^{M-1})^{-1}=\\frac{1-R_c}{1-R_c^M}$,\nwhere $R_c$ is the rate of the $(N,K)$ code used. The capacity is a function of\nthe code rate and the number of messages only regardless of the explicit\nstructure of the storage code. The result implies a fundamental tradeoff\nbetween the optimal retrieval cost and the storage cost. The result generalizes\nthe achievability and converse results for the classical PIR with replicating\ndatabases to the case of coded databases. \n\n"}
{"id": "1609.08935", "contents": "Title: Binary Cyclic Codes that are Locally Repairable Abstract: Codes for storage systems aim to minimize the repair locality, which is the\nnumber of disks (or nodes) that participate in the repair of a single failed\ndisk. Simultaneously, the code must sustain a high rate, operate on a small\nfinite field to be practically significant and be tolerant to a large number of\nerasures. To this end, we construct new families of binary linear codes that\nhave an optimal dimension (rate) for a given minimum distance and locality.\nSpecifically, we construct cyclic codes that are locally repairable for\nlocality 2 and distances 2, 6 and 10. In doing so, we discover new upper bounds\non the code dimension, and prove the optimality of enabling local repair by\nprovisioning disjoint groups of disks. Finally, we extend our construction to\nbuild codes that have multiple repair sets for each disk. \n\n"}
{"id": "1609.09047", "contents": "Title: Quantum Tokens for Digital Signatures Abstract: The fisherman caught a quantum fish. \"Fisherman, please let me go\", begged\nthe fish, \"and I will grant you three wishes\". The fisherman agreed. The fish\ngave the fisherman a quantum computer, three quantum signing tokens and his\nclassical public key. The fish explained: \"to sign your three wishes, use the\ntokenized signature scheme on this quantum computer, then show your valid\nsignature to the king, who owes me a favor\".\n  The fisherman used one of the signing tokens to sign the document \"give me a\ncastle!\" and rushed to the palace. The king executed the classical verification\nalgorithm using the fish's public key, and since it was valid, the king\ncomplied.\n  The fisherman's wife wanted to sign ten wishes using their two remaining\nsigning tokens. The fisherman did not want to cheat, and secretly sailed to\nmeet the fish. \"Fish, my wife wants to sign ten more wishes\". But the fish was\nnot worried: \"I have learned quantum cryptography following the previous story\n(The Fisherman and His Wife by the brothers Grimm). The quantum tokens are\nconsumed during the signing. Your polynomial wife cannot even sign four wishes\nusing the three signing tokens I gave you\".\n  \"How does it work?\" wondered the fisherman. \"Have you heard of quantum money?\nThese are quantum states which can be easily verified but are hard to copy.\nThis tokenized quantum signature scheme extends Aaronson and Christiano's\nquantum money scheme, which is why the signing tokens cannot be copied\".\n  \"Does your scheme have additional fancy properties?\" the fisherman asked.\n\"Yes, the scheme has other security guarantees: revocability, testability and\neverlasting security. Furthermore, if you're at sea and your quantum phone has\nonly classical reception, you can use this scheme to transfer the value of the\nquantum money to shore\", said the fish, and swam away. \n\n"}
{"id": "1609.09577", "contents": "Title: Numerical Approach to Maximize SNR for CDMA Systems Abstract: Signal to Noise Ratio (SNR) is an important index for wireless\ncommunications. There are many methods for increasing SNR. In CDMA systems,\nspreading sequences are used. To increase SNR, we have to improve spreading\nsequences. In classical approaches, the expression of SNR is not differentiable\nin terms of the parameter of the spreading sequences even in no fading\nsituations. Thus, we express it as the differentiable form and construct the\nnon-linear programing for maximizing SNR. In particular, we solve the problem\nof maximizing SNR numerically by obtaining spreading sequences whose SNR is\nguaranteed to be high. \n\n"}
{"id": "1610.06098", "contents": "Title: Leveraging Diversity and Sparsity in Blind Deconvolution Abstract: This paper considers recovering $L$-dimensional vectors $\\boldsymbol{w}$, and\n$\\boldsymbol{x}_1,\\boldsymbol{x}_2, \\ldots, \\boldsymbol{x}_N$ from their\ncircular convolutions $\\boldsymbol{y}_n = \\boldsymbol{w}*\\boldsymbol{x}_n, \\ n\n= 1,2,3, \\ldots, N$. The vector $\\boldsymbol{w}$ is assumed to be $S$-sparse in\na known basis that is spread out in the Fourier domain, and each input\n$\\boldsymbol{x}_n$ is a member of a known $K$-dimensional random subspace.\n  We prove that whenever $K + S\\log^2S \\lesssim L /\\log^4(LN)$, the problem can\nbe solved effectively by using only the nuclear-norm minimization as the convex\nrelaxation, as long as the inputs are sufficiently diverse and obey $N \\gtrsim\n\\log^2(LN)$. By \"diverse inputs\", we mean that the $\\boldsymbol{x}_n$'s belong\nto different, generic subspaces. To our knowledge, this is the first\ntheoretical result on blind deconvolution where the subspace to which\n$\\boldsymbol{w}$ belongs is not fixed, but needs to be determined.\n  We discuss the result in the context of multipath channel estimation in\nwireless communications. Both the fading coefficients, and the delays in the\nchannel impulse response $\\boldsymbol{w}$ are unknown. The encoder codes the\n$K$-dimensional message vectors randomly and then transmits coded messages\n$\\boldsymbol{x}_n$'s over a fixed channel one after the other. The decoder then\ndiscovers all of the messages and the channel response when the number of\nsamples taken for each received message are roughly greater than\n$(K+S\\log^2S)\\log^4(LN)$, and the number of messages is roughly at least\n$\\log^2(LN)$. \n\n"}
{"id": "1610.07108", "contents": "Title: Fast and Reliable Parameter Estimation from Nonlinear Observations Abstract: In this paper we study the problem of recovering a structured but unknown\nparameter ${\\bf{\\theta}}^*$ from $n$ nonlinear observations of the form\n$y_i=f(\\langle {\\bf{x}}_i,{\\bf{\\theta}}^*\\rangle)$ for $i=1,2,\\ldots,n$. We\ndevelop a framework for characterizing time-data tradeoffs for a variety of\nparameter estimation algorithms when the nonlinear function $f$ is unknown.\nThis framework includes many popular heuristics such as projected/proximal\ngradient descent and stochastic schemes. For example, we show that a projected\ngradient descent scheme converges at a linear rate to a reliable solution with\na near minimal number of samples. We provide a sharp characterization of the\nconvergence rate of such algorithms as a function of sample size, amount of\na-prior knowledge available about the parameter and a measure of the\nnonlinearity of the function $f$. These results provide a precise understanding\nof the various tradeoffs involved between statistical and computational\nresources as well as a-prior side information available for such nonlinear\nparameter estimation problems. \n\n"}
{"id": "1610.08004", "contents": "Title: On Fractional Linear Network Coding Solution of Multiple-Unicast\n  Networks Abstract: It is known that there exists a multiple-unicast network which has a rate $1$\nlinear network coding solution if and only if the characteristic of the finite\nfield belongs to a given finite or co-finite set of primes. In this paper, we\nshow that for any non-zero positive rational number $\\frac{k}{n}$, there exists\na multiple-unicast network which has a rate $\\frac{k}{n}$ fractional linear\nnetwork coding solution if and only if the characteristic of the finite field\nbelongs to a given finite or co-finite set of primes. \n\n"}
{"id": "1610.08727", "contents": "Title: Combining Usability and Privacy Protection in Free-Access Public Cloud\n  Storage Servers: Review of the Main Threats and Challenges Abstract: The 21st century belongs to the world of computing, specially as a result of\nthe so-called cloud computing. This technology enables ubiquitous information\nmanagement and thus people can access all their data from any place and at any\ntime. In this landscape, the emergence of cloud storage has had an important\nrole in the last five years. Nowadays, several free-access public cloud storage\nservices make it possible for users to have a free backup of their assets and\nto manage and share them, representing a low-cost opportunity for Small and\nMedium Companies (SME). However, the adoption of cloud storage involves data\noutsourcing, so a user does not have the guarantee about the way her data will\nbe processed and protected. Therefore, it seems necessary to endow public cloud\nstorage with a set of means to protect users' confidentiality and privacy, to\nassess data integrity and to guarantee a proper backup of information assets.\nAlong this paper we discuss the main challenges to achieve such a goal,\nunderlining the set of functionalities already implemented in the most popular\npublic cloud storage services. \n\n"}
{"id": "1610.09028", "contents": "Title: Through the Haze: a Non-Convex Approach to Blind Gain Calibration for\n  Linear Random Sensing Models Abstract: Computational sensing strategies often suffer from calibration errors in the\nphysical implementation of their ideal sensing models. Such uncertainties are\ntypically addressed by using multiple, accurately chosen training signals to\nrecover the missing information on the sensing model, an approach that can be\nresource-consuming and cumbersome. Conversely, blind calibration does not\nemploy any training signal, but corresponds to a bilinear inverse problem whose\nalgorithmic solution is an open issue. We here address blind calibration as a\nnon-convex problem for linear random sensing models, in which we aim to recover\nan unknown signal from its projections on sub-Gaussian random vectors, each\nsubject to an unknown positive multiplicative factor (or gain). To solve this\noptimisation problem we resort to projected gradient descent starting from a\nsuitable, carefully chosen initialisation point. An analysis of this algorithm\nallows us to show that it converges to the exact solution provided a sample\ncomplexity requirement is met, i.e., relating convergence to the amount of\ninformation collected during the sensing process. Interestingly, we show that\nthis requirement grows linearly (up to log factors) in the number of unknowns\nof the problem. This sample complexity is found both in absence of prior\ninformation, as well as when subspace priors are available for both the signal\nand gains, allowing a further reduction of the number of observations required\nfor our recovery guarantees to hold. Moreover, in the presence of noise we show\nhow our descent algorithm yields a solution whose accuracy degrades gracefully\nwith the amount of noise affecting the measurements. Finally, we present some\nnumerical experiments in an imaging context, where our algorithm allows for a\nsimple solution to blind calibration of the gains in a sensor array. \n\n"}
{"id": "1610.09247", "contents": "Title: Generalized I-MMSE for K-User Gaussian Channels Abstract: In this paper, we generalize the fundamental relation between the mutual\ninformation and the minimum mean squared error (MMSE) by Guo, Shamai, and Verdu\n[1] to K-User Gaussian channels. We prove that the derivative of the multiuser\nmutual information with respect to the signal to noise ratio (SNR) is equal to\nthe total MMSE plus a covariance term with respect to the cross correlation of\nthe multiuser input estimates, the channels and the precoding matrices. We shed\nlight that such relation is a generalized I-MMSE with one step lookahead and\nlookback, applied to the Successive Interference Cancellation (SIC) in the\ndecoding process. \n\n"}
{"id": "1610.09785", "contents": "Title: Generalized Solution for the Demodulation of Reaction Shift Keying\n  Signals in Molecular Communication Networks Abstract: This paper considers a diffusion-based molecular communication system where\nthe transmitter uses Reaction Shift Keying (RSK) as the modulation scheme. We\nfocus on the demodulation of RSK signal at the receiver. The receiver consists\nof a front-end molecular circuit and a back-end demodulator. The front-end\nmolecular circuit is a set of chemical reactions consisting of multiple\nchemical species. The optimal demodulator computes the posteriori probability\nof the transmitted symbols given the history of the observation. The derivation\nof the optimal demodulator requires the solution to a specific Bayesian\nfiltering problem. The solution to this Bayesian filtering problem had been\nderived for a few specific molecular circuits and specific choice(s) of\nobserved chemical species. The derivation of such solution is also lengthy. The\nkey contribution of this paper is to present a general solution to this\nBayesian filtering problem which can be applied to any molecular circuit and\nany choice of observed species. \n\n"}
{"id": "1611.01376", "contents": "Title: Denoising based Vector Approximate Message Passing Abstract: The denoising-based approximate message passing (D-AMP) methodology, recently\nproposed by Metzler, Maleki, and Baraniuk, allows one to plug in sophisticated\ndenoisers like BM3D into the AMP algorithm to achieve state-of-the-art\ncompressive image recovery. But AMP diverges with small deviations from the\ni.i.d.-Gaussian assumption on the measurement matrix. Recently, the vector AMP\n(VAMP) algorithm has been proposed to fix this problem. In this work, we show\nthat the benefits of VAMP extend to D-VAMP. \n\n"}
{"id": "1611.01428", "contents": "Title: Almost universal codes for MIMO wiretap channels Abstract: Despite several works on secrecy coding for fading and MIMO wiretap channels\nfrom an error probability perspective, the construction of\ninformation-theoretically secure codes over such channels remains an open\nproblem. In this paper, we consider a fading wiretap channel model where the\ntransmitter has only partial statistical channel state information. Our channel\nmodel includes static channels, i.i.d. block fading channels, and ergodic\nstationary fading with fast decay of large deviations for the eavesdropper's\nchannel.\n  We extend the flatness factor criterion from the Gaussian wiretap channel to\nfading and MIMO wiretap channels, and establish a simple design criterion where\nthe normalized product distance / minimum determinant of the lattice and its\ndual should be maximized simultaneously.\n  Moreover, we propose concrete lattice codes satisfying this design criterion,\nwhich are built from algebraic number fields with constant root discriminant in\nthe single-antenna case, and from division algebras centered at such number\nfields in the multiple-antenna case. The proposed lattice codes achieve strong\nsecrecy and semantic security for all rates $R<C_b-C_e-\\kappa$, where $C_b$ and\n$C_e$ are Bob and Eve's channel capacities respectively, and $\\kappa$ is an\nexplicit constant gap. Furthermore, these codes are almost universal in the\nsense that a fixed code is good for secrecy for a wide range of fading models.\n  Finally, we consider a compound wiretap model with a more restricted\nuncertainty set, and show that rates $R<\\bar{C}_b-\\bar{C}_e-\\kappa$ are\nachievable, where $\\bar{C}_b$ is a lower bound for Bob's capacity and\n$\\bar{C}_e$ is an upper bound for Eve's capacity for all the channels in the\nset. \n\n"}
{"id": "1611.01726", "contents": "Title: LSTM-Based System-Call Language Modeling and Robust Ensemble Method for\n  Designing Host-Based Intrusion Detection Systems Abstract: In computer security, designing a robust intrusion detection system is one of\nthe most fundamental and important problems. In this paper, we propose a\nsystem-call language-modeling approach for designing anomaly-based host\nintrusion detection systems. To remedy the issue of high false-alarm rates\ncommonly arising in conventional methods, we employ a novel ensemble method\nthat blends multiple thresholding classifiers into a single one, making it\npossible to accumulate 'highly normal' sequences. The proposed system-call\nlanguage model has various advantages leveraged by the fact that it can learn\nthe semantic meaning and interactions of each system call that existing methods\ncannot effectively consider. Through diverse experiments on public benchmark\ndatasets, we demonstrate the validity and effectiveness of the proposed method.\nMoreover, we show that our model possesses high portability, which is one of\nthe key aspects of realizing successful intrusion detection systems. \n\n"}
{"id": "1611.02062", "contents": "Title: Private Information Retrieval from Coded Databases with Colluding\n  Servers Abstract: We present a general framework for Private Information Retrieval (PIR) from\narbitrary coded databases, that allows one to adjust the rate of the scheme\naccording to the suspected number of colluding servers. If the storage code is\na generalized Reed-Solomon code of length n and dimension k, we design PIR\nschemes which simultaneously protect against t colluding servers and provide\nPIR rate 1-(k+t-1)/n, for all t between 1 and n-k. This interpolates between\nthe previously studied cases of t=1 and k=1 and asymptotically achieves the\nknown capacity bounds in both of these cases, as the size of the database\ngrows. \n\n"}
{"id": "1611.02828", "contents": "Title: What Is the True Value of Dynamic TDD: A MAC Layer Perspective Abstract: Small cell networks (SCNs) are envisioned to embrace dynamic time division\nduplexing (TDD) in order to tailor downlink (DL)/uplink (UL) subframe resources\nto quick variations and burstiness of DL/UL traffic. The study of dynamic TDD\nis particularly important because it provides valuable insights on the full\nduplex transmission technology, which has been identified as one of the\ncandidate technologies for the 5th-generation (5G) networks. Up to now, the\nexisting works on dynamic TDD have shown that the UL of dynamic TDD suffers\nfrom severe performance degradation due to the strong DL-to-UL interference in\nthe physical (PHY) layer. This conclusion raises a fundamental question:\nDespite such obvious technology disadvantage, what is the true value of dynamic\nTDD? In this paper, we answer this question from a media access control (MAC)\nlayer viewpoint and present analytical results on the DL/UL time resource\nutilization (TRU) of synchronous dynamic TDD, which has been widely adopted in\nthe existing 4th-generation (4G) systems. Our analytical results shed new light\non the dynamic TDD in future synchronous 5G networks. \n\n"}
{"id": "1611.03054", "contents": "Title: Throughput Analysis of Decentralized Coded Content Caching in Cellular\n  Networks Abstract: Decentralized coded content caching for next generation cellular networks is\nstudied. The contents are linearly combined and cached in under-utilized caches\nof User Terminals (UTs) and its throughput capacity is compared with\ndecentralized uncoded content caching. In both scenarios, we consider multihop\nDevice-to-Device (D2D) communications and the use of femtocaches in the\nnetwork. It is shown that decentralized coded content caching can increase the\nnetwork throughput capacity compared to decentralized uncoded caching by\nreducing the number of hops needed to deliver the desired content. Further, the\nthroughput capacity for Zipfian content request distribution is computed and it\nis shown that the decentralized coded content cache placement can increase the\nthroughput capacity of cellular networks by a factor of $(\\log(n))^2$ where $n$\nis the number of nodes served by a femtocache. \n\n"}
{"id": "1611.04227", "contents": "Title: Robust Consensus-Based Network Intrusion Detection in Presence of\n  Byzantine Attacks Abstract: Consensus algorithms provide strategies to solve problems in a distributed\nsystem with the added constraint that data can only be shared between adjacent\ncomputing nodes. We find these algorithms in applications for wireless and\nsensor networks, spectrum sensing for cognitive radio, even for some IoT\nservices. However, consensus-based applications are not resilient to\ncompromised nodes sending falsified data to their neighbors, i.e. they can be\nthe target of Byzantine attacks. Several solutions have been proposed in the\nliterature inspired from reputation based systems, outlier detection or\nmodel-based fault detection techniques in process control. We have reviewed\nsome of these solutions, and propose two mitigation techniques to protect the\nconsensus-based Network Intrusion Detection System in\n\\cite{toulouse2015consensus}. We analyze several implementation issues such as\ncomputational overhead, fine tuning of the solution parameters, impacts on the\nconvergence of the consensus phase, accuracy of the intrusion detection system. \n\n"}
{"id": "1611.07722", "contents": "Title: A Survey on Privacy-preserving Schemes for Smart Grid Communications Abstract: In this paper, we present a comprehensive survey of privacy-preserving\nschemes for Smart Grid communications. Specifically, we select and in-detail\nexamine thirty privacy preserving schemes developed for or applied in the\ncontext of Smart Grids. Based on the communication and system models, we\nclassify these schemes that are published between 2013 and 2016, in five\ncategories, including, 1) Smart grid with the advanced metering infrastructure,\n2) Data aggregation communications, 3) Smart grid marketing architecture, 4)\nSmart community of home gateways, and 5) Vehicle-to grid architecture. For each\nscheme, we survey the attacks of leaking privacy, countermeasures, and game\ntheoretic approaches. In addition, we review the survey articles published in\nthe recent years that deal with Smart Grids communications, applications,\nstandardization, and security. Based on the current survey, several\nrecommendations for further research are discussed at the end of this paper. \n\n"}
{"id": "1611.09011", "contents": "Title: Scalable Fine-grained Path Control in Software Defined Networks Abstract: The OpenFlow-based SDN is widely studied to better network performance\nthrough planning fine-grained paths. However, being designed to configure path\nhop-by-hop, it faces the scalability issue that both the flow table overhead\nand path setup delay are unacceptable for large-scale networks. In this paper,\nwe propose PACO, a framework based on Source Routing to address that problem\nthrough quickly pushing paths into the packet header at network edges and\npre-installing few rules at the network core. The straightforward\nimplementation of SR is inefficient as it would incur too many path labels;\nother efficient approaches would sacrifice path flexibility (e.g., DEFO). To\nimplement SR efficiently and flexibly, PACO presents each path as a\nconcatenation of pathlets and introduces algorithms to compute pathlets and\nconcatenate paths with minimum path labels. Our extensive simulations confirm\nthe scalability of PACO as it saves the flow table overhead up to 94% compared\nwith OpenFlow-SDN solutions and show that PACO outperforms SR-SDN solutions by\nsupporting more than 40% paths with few label overhead. \n\n"}
{"id": "1612.03560", "contents": "Title: Circulant Matrix Representation of PN-sequences with Ideal\n  Autocorrelation Property Abstract: In this paper, we investigate PN-sequences with ideal autocorrelation\nproperty and the consequences of this property on the number of +1s and -1s and\nrun structure of sequences. We begin by discussing and surveying about the\nlength of PNsequences with ideal autocorrelation property. From our discussion\nand survey we introduce circulant matrix representation of PN-sequence. Through\ncirculant matrix representation we obtain system of non-linear equations that\nlead to ideal autocorrelation property. Rewriting PN-sequence and its\nautocorrelation property in {0,1} leads to a definition based on Hamming weight\nand Hamming distance and hence we can easily prove some results on the\nPN-sequences with ideal autocorrelation property. \n\n"}
{"id": "1612.04703", "contents": "Title: Lexicodes over Finite Principal Left Ideal Rings Abstract: Let R be a finite principal left ideal ring. Via a total ordering of the ring\nelements and an ordered basis a lexicographic ordering of the module R^n is\nproduced. This is used to set up a greedy algorithm that selects vectors for\nwhich all linear combination with the previously selected vectors satisfy a\npre-specified selection property and updates the to-be-constructed code to the\nlinear hull of the vectors selected so far. The output is called a lexicode.\nThis process was discussed earlier in the literature for fields and chain\nrings. In this paper we investigate the properties of such lexicodes over\nfinite principal left ideal rings and show that the total ordering of the ring\nelements has to respect containment of ideals in order for the algorithm to\nproduce meaningful results. Only then it is guaranteed that the algorithm is\nexhaustive and thus produces codes that are maximal with respect to inclusion.\nIt is further illustrated that the output of the algorithm heavily depends on\nthe total ordering and chosen basis. \n\n"}
{"id": "1612.05461", "contents": "Title: Least reliable messages based early termination method for LT soft\n  decoder Abstract: In this paper, we propose a new early termination method (ETM) for Luby\ntransform (LT) belief propagation (BP) decoder. The proposed ETM, which we call\nleast reliable messages (LRM), observes only sign alterations of a small\ncluster in log-likelihood ratio (LLR) messages passing between nodes in BP\ndecoder. Simulation results and complexity analyzes show that LRM significantly\nlower computational complexity of early termination section in decoder without\nany performance degradation and decreases the average decoding iteration\namounts compared to conventional ETMs in literature. The method can be easily\napplied to code families which can be decoded by BP such as low density parity\ncheck (LDPC) codes, polar codes and Raptor codes. \n\n"}
{"id": "1612.05523", "contents": "Title: Two-weight codes from trace codes over $R_k$ Abstract: We construct a family of two-Lee-weight codes over the ring $R_k,$ which is\ndefined as trace codes with algebraic structure of abelian codes. The Lee\nweight distribution of the two-weight codes is given. Taking the Gray map, we\nobtain optimal abelian binary two-weight codes by using the Griesmer bound. An\napplication to secret sharing schemes is also given. \n\n"}
{"id": "1612.05997", "contents": "Title: On the absolute irreducibility of hyperplane sections of generalized\n  Fermat varieties in $\\Bbb{P}^3$ and the conjecture on exceptional APN\n  functions: the Kasami-Welch degree case Abstract: Let $f$ be a function on a finite field $F$. The decomposition of the\ngeneralized Fermat variety $X$ defined by the multivariate polynomial of degree\n$n$, $\\phi(x,y,z)=f(x)+f(y)+f(z)$ in $\\Bbb{P}^3(\\overline{\\mathbb{F}}_2)$,\nplays a crucial role in the study of almost perfect non-linear (APN) functions\nand exceptional APN functions. Their structure depends fundamentally on the\nFermat varieties corresponding to the monomial functions of exceptional degrees\n$n=2^k+1$ and $n=2^{2k}-2^k+1$ (Gold and Kasami-Welch numbers, respectively).\nVery important results for these have been obtained by Janwa, McGuire and\nWilson in [12,13]. In this paper we study $X$ related to the Kasami-Welch\ndegree monomials and its decomposition into absolutely irreducible components.\nWe show that, in this decomposition, the components intersect transversally at\na singular point.\n  This structural fact implies that the corresponding generalized Fermat\nhypersurfaces, related to Kasami-Welch degree polynomial families, are\nabsolutely irreducible. In particular, we prove that if\n$f(x)=x^{2^{2k}-2^k+1}+h(x)$, where ${\\rm deg}(h)\\equiv 3{\\pmod 4}$, then the\ncorresponding APN multivariate hypersurface is absolutely irreducible, and\nhence $f(x)$ is not exceptional APN function. We also prove conditional result\nin the case when ${\\rm deg}(h)\\equiv 5{\\pmod 8}$. Since for odd degree $f(x)$,\nthe conjecture needs to be resolved only for the Gold degree and the\nKasami-Welch degree cases our results contribute substantially to the proof of\nthe conjecture on exceptional APN functions---in the hardest case: the\nKasami-Welch degree. \n\n"}
{"id": "1612.06299", "contents": "Title: Simple Black-Box Adversarial Perturbations for Deep Networks Abstract: Deep neural networks are powerful and popular learning models that achieve\nstate-of-the-art pattern recognition performance on many computer vision,\nspeech, and language processing tasks. However, these networks have also been\nshown susceptible to carefully crafted adversarial perturbations which force\nmisclassification of the inputs. Adversarial examples enable adversaries to\nsubvert the expected system behavior leading to undesired consequences and\ncould pose a security risk when these systems are deployed in the real world.\n  In this work, we focus on deep convolutional neural networks and demonstrate\nthat adversaries can easily craft adversarial examples even without any\ninternal knowledge of the target network. Our attacks treat the network as an\noracle (black-box) and only assume that the output of the network can be\nobserved on the probed inputs. Our first attack is based on a simple idea of\nadding perturbation to a randomly selected single pixel or a small set of them.\nWe then improve the effectiveness of this attack by carefully constructing a\nsmall set of pixels to perturb by using the idea of greedy local-search. Our\nproposed attacks also naturally extend to a stronger notion of\nmisclassification. Our extensive experimental results illustrate that even\nthese elementary attacks can reveal a deep neural network's vulnerabilities.\nThe simplicity and effectiveness of our proposed schemes mean that they could\nserve as a litmus test for designing robust networks. \n\n"}
{"id": "1612.07084", "contents": "Title: Private Information Retrieval in Distributed Storage Systems Using an\n  Arbitrary Linear Code Abstract: We propose an information-theoretic private information retrieval (PIR)\nscheme for distributed storage systems where data is stored using a linear\nsystematic code of rate $R > 1/2$. The proposed scheme generalizes the PIR\nscheme for data stored using maximum distance separable codes recently proposed\nby Tajeddine and El Rouayheb for the scenario of a single spy node. We further\npropose an algorithm to optimize the communication price of privacy (cPoP)\nusing the structure of the underlying linear code. As an example, we apply the\nproposed algorithm to several distributed storage codes, showing that the cPoP\ncan be significantly reduced by exploiting the structure of the distributed\nstorage code. \n\n"}
{"id": "1612.08465", "contents": "Title: Constructive Interference Based Secure Precoding: A New Dimension in\n  Physical Layer Security Abstract: Conventionally, interference and noise are treated as catastrophic elements\nin wireless communications. However, it has been shown recently that exploiting\nknown interference constructively can even contribute to signal detection\nability at the receiving end. This paper exploits this concept to design\nartificial noise (AN) beamformers constructive to the intended receiver (IR)\nyet keeping AN disruptive to possible eavesdroppers (Eves). The scenario\nconsidered here is a multiple-input single-output (MISO) wiretap channel with\nmultiple eavesdroppers. Both perfect and imperfect channel information have\nbeen considered. The main objective is to improve the receive\nsignal-to-interference and noise ratio (SINR) at IR through exploitation of AN\npower in an attempt to minimize the total transmit power, while confusing the\nEves. Numerical simulations demonstrate that the proposed constructive AN\nprecoding approach yields superior performance over conventional AN schemes in\nterms of transmit power as well as symbol error rate (SER). \n\n"}
{"id": "1701.00062", "contents": "Title: Finite size analysis of the detectability limit of the stochastic block\n  model Abstract: It has been shown in recent years that the stochastic block model (SBM) is\nsometimes undetectable in the sparse limit, i.e., that no algorithm can\nidentify a partition correlated with the partition used to generate an\ninstance, if the instance is sparse enough and infinitely large. In this\ncontribution, we treat the finite case explicitly, using arguments drawn from\ninformation theory and statistics. We give a necessary condition for\nfinite-size detectability in the general SBM. We then distinguish the concept\nof average detectability from the concept of instance-by-instance detectability\nand give explicit formulas for both definitions. Using these formulas, we prove\nthat there exist large equivalence classes of parameters, where widely\ndifferent network ensembles are equally detectable with respect to our\ndefinitions of detectability. In an extensive case study, we investigate the\nfinite-size detectability of a simplified variant of the SBM, which encompasses\na number of important models as special cases. These models include the\nsymmetric SBM, the planted coloring model, and more exotic SBMs not previously\nstudied. We conclude with three appendices, where we study the interplay of\nnoise and detectability, establish a connection between our\ninformation-theoretic approach and random matrix theory, and provide proofs of\nsome of the more technical results. \n\n"}
{"id": "1701.00939", "contents": "Title: Dense Associative Memory is Robust to Adversarial Inputs Abstract: Deep neural networks (DNN) trained in a supervised way suffer from two known\nproblems. First, the minima of the objective function used in learning\ncorrespond to data points (also known as rubbish examples or fooling images)\nthat lack semantic similarity with the training data. Second, a clean input can\nbe changed by a small, and often imperceptible for human vision, perturbation,\nso that the resulting deformed input is misclassified by the network. These\nfindings emphasize the differences between the ways DNN and humans classify\npatterns, and raise a question of designing learning algorithms that more\naccurately mimic human perception compared to the existing methods.\n  Our paper examines these questions within the framework of Dense Associative\nMemory (DAM) models. These models are defined by the energy function, with\nhigher order (higher than quadratic) interactions between the neurons. We show\nthat in the limit when the power of the interaction vertex in the energy\nfunction is sufficiently large, these models have the following three\nproperties. First, the minima of the objective function are free from rubbish\nimages, so that each minimum is a semantically meaningful pattern. Second,\nartificial patterns poised precisely at the decision boundary look ambiguous to\nhuman subjects and share aspects of both classes that are separated by that\ndecision boundary. Third, adversarial images constructed by models with small\npower of the interaction vertex, which are equivalent to DNN with rectified\nlinear units (ReLU), fail to transfer to and fool the models with higher order\ninteractions. This opens up a possibility to use higher order models for\ndetecting and stopping malicious adversarial attacks. The presented results\nsuggest that DAM with higher order energy functions are closer to human visual\nperception than DNN with ReLUs. \n\n"}
{"id": "1701.01093", "contents": "Title: Private Incremental Regression Abstract: Data is continuously generated by modern data sources, and a recent challenge\nin machine learning has been to develop techniques that perform well in an\nincremental (streaming) setting. In this paper, we investigate the problem of\nprivate machine learning, where as common in practice, the data is not given at\nonce, but rather arrives incrementally over time.\n  We introduce the problems of private incremental ERM and private incremental\nregression where the general goal is to always maintain a good empirical risk\nminimizer for the history observed under differential privacy. Our first\ncontribution is a generic transformation of private batch ERM mechanisms into\nprivate incremental ERM mechanisms, based on a simple idea of invoking the\nprivate batch ERM procedure at some regular time intervals. We take this\nconstruction as a baseline for comparison. We then provide two mechanisms for\nthe private incremental regression problem. Our first mechanism is based on\nprivately constructing a noisy incremental gradient function, which is then\nused in a modified projected gradient procedure at every timestep. This\nmechanism has an excess empirical risk of $\\approx\\sqrt{d}$, where $d$ is the\ndimensionality of the data. While from the results of [Bassily et al. 2014]\nthis bound is tight in the worst-case, we show that certain geometric\nproperties of the input and constraint set can be used to derive significantly\nbetter results for certain interesting regression problems. \n\n"}
{"id": "1701.01212", "contents": "Title: Downlink Coverage Analysis for a Finite 3D Wireless Network of Unmanned\n  Aerial Vehicles Abstract: In this paper, we consider a finite network of unmanned aerial vehicles\n(UAVs) serving a given region. Modeling this network as a uniform binomial\npoint process (BPP), we derive the downlink coverage probability of a reference\nreceiver located at an arbitrary position on the ground assuming Nakagami-$m$\nfading for all wireless links. The reference receiver is assumed to connect to\nits closest transmitting node as is usually the case in cellular systems. After\nderiving the distribution of distances from the reference receiver to the\nserving and interfering nodes, we derive an exact expression for downlink\ncoverage probability in terms of the derivative of Laplace transform of\ninterference power distribution. In the downlink of this system, it is not\nunusual to encounter scenarios in which the line-of-sight (LOS) component is\nsignificantly stronger than the reflected multipath components. To emulate such\nscenarios, we also derive the coverage probability in the absence of fading\nfrom the results of Nakagami-$m$ fading by taking the limit $m \\to \\infty$.\nUsing asymptotic expansion of incomplete gamma function, we concretely show\nthat this limit reduces to a redundant condition. Consequently, we derive an\naccurate coverage probability approximation for this case using dominant\ninterferer-based approach in which the effect of dominant interferer is exactly\ncaptured and the residual interference from other interferers is carefully\napproximated. We then derive the bounds of the approximate coverage probability\nusing Berry-Esseen theorem. Our analyses reveal several useful trends in\ncoverage probability as a function of height of the transmitting nodes and the\nlocation of reference receiver on the ground. \n\n"}
{"id": "1701.01544", "contents": "Title: Dense Small Cell Networks: From Noise-Limited to Dense\n  Interference-Limited Abstract: Considering both non-line-of-sight (NLoS) and line-of-sight (LoS)\ntransmissions, the transitional behaviors from noise-limited regime to dense\ninterference-limited regime have been investigated for the fifth generation\n(5G) small cell networks (SCNs). Besides, we identify four performance regimes\nbased on base station (BS) density, i.e., (i) the noise-limited regime, (ii)\nthe signal-dominated regime, (iii) the interference-dominated regime, and (iv)\nthe interference-limited regime. To characterize the performance regime, we\npropose a unified framework analyzing the future 5G wireless networks over\ngeneralized shadowing/fading channels, in which the user association schemes\nbased on the strongest instantaneous received power (SIRP) and the strongest\naverage received power (SARP) can be studied, while NLoS/LoS transmissions and\nmulti-slop path loss model are considered. Simulation results indicate that\ndifferent factors, i.e., noise, desired signal, and interference, successively\nand separately dominate the network performance with the increase of BS\ndensity. Hence, our results shed new light on the design and management of SCNs\nin urban and rural areas with different BS deployment densities. \n\n"}
{"id": "1701.01625", "contents": "Title: Opportunistic Downlink Interference Alignment for Multi-Cell MIMO\n  Networks Abstract: In this paper, we propose an opportunistic downlink interference alignment\n(ODIA) for interference-limited cellular downlink, which intelligently combines\nuser scheduling and downlink IA techniques. The proposed ODIA not only\nefficiently reduces the effect of inter-cell interference from other-cell base\nstations (BSs) but also eliminates intra-cell interference among spatial\nstreams in the same cell. We show that the minimum number of users required to\nachieve a target degrees-of-freedom (DoF) can be fundamentally reduced, i.e.,\nthe fundamental user scaling law can be improved by using the ODIA, compared\nwith the existing downlink IA schemes. In addition, we adopt a limited feedback\nstrategy in the ODIA framework, and then analyze the number of feedback bits\nrequired for the system with limited feedback to achieve the same user scaling\nlaw of the ODIA as the system with perfect CSI. We also modify the original\nODIA in order to further improve sum-rate, which achieves the optimal multiuser\ndiversity gain, i.e., $\\log\\log N$, per spatial stream even in the presence of\ndownlink inter-cell interference, where $N$ denotes the number of users in a\ncell. Simulation results show that the ODIA significantly outperforms existing\ninterference management techniques in terms of sum-rate in realistic cellular\nenvironments. Note that the ODIA operates in a non-collaborative and decoupled\nmanner, i.e., it requires no information exchange among BSs and no iterative\nbeamformer optimization between BSs and users, thus leading to an easier\nimplementation. \n\n"}
{"id": "1701.01800", "contents": "Title: Variable-Length Lossy Compression Allowing Positive Overflow and Excess\n  Distortion Probabilities Abstract: This paper investigates the problem of variable-length lossy source coding\nallowing a positive excess distortion probability and an overflow probability\nof codeword lengths. Novel one-shot achievability and converse bounds of the\noptimal rate are established by a new quantity based on the smooth max entropy\n(the smooth R\\'enyi entropy of order zero). To derive the achievability bounds,\nwe give an explicit code construction based on a distortion ball instead of\nusing the random coding argument. The basic idea of the code construction is\nsimilar to the optimal code construction in the variable-length lossless source\ncoding. Our achievability bounds are slightly different, depending on whether\nthe encoder is stochastic or deterministic. One-shot results yield a general\nformula of the optimal rate for blocklength $n$. In addition, our general\nformula is applied to asymptotic analysis for a stationary memoryless source.\nAs a result, we derive a single-letter characterization of the optimal rate by\nusing the rate-distortion and rate-dispersion functions. \n\n"}
{"id": "1701.02054", "contents": "Title: Unitary Reconstruction of Secret for Stabilizer Based Quantum Secret\n  Sharing Abstract: We propose a unitary procedure to reconstruct quantum secret for a quantum\nsecret sharing scheme constructed from stabilizer quantum error-correcting\ncodes. Erasure correcting procedures for stabilizer codes need to add missing\nshares for reconstruction of quantum secret while unitary reconstruction\nprocedures for certain class of quantum secret sharing are known to work\nwithout adding missing shares. The proposed procedure also works without adding\nmissing shares. \n\n"}
{"id": "1701.02911", "contents": "Title: Quantum Stabilizer Codes Can Realize Access Structures Impossible by\n  Classical Secret Sharing Abstract: We show a simple example of a secret sharing scheme encoding classical secret\nto quantum shares that can realize an access structure impossible by classical\ninformation processing with limitation on the size of each share. The example\nis based on quantum stabilizer codes. \n\n"}
{"id": "1701.02940", "contents": "Title: Cell Coverage Extension with Orthogonal Random Precoding for Massive\n  MIMO Systems Abstract: In this paper, we investigate a coverage extension scheme based on orthogonal\nrandom precoding (ORP) for the downlink of massive multiple-input\nmultiple-output (MIMO) systems. In this scheme, a precoding matrix consisting\nof orthogonal vectors is employed at the transmitter to enhance the maximum\nsignal-to-interference-plus-noise ratio (SINR) of the user. To analyze and\noptimize the ORP scheme in terms of cell coverage, we derive the analytical\nexpressions of the downlink coverage probability for two receiver structures,\nnamely, the single-antenna (SA) receiver and multiple-antenna receiver with\nantenna selection (AS). The simulation results show that the analytical\nexpressions accurately capture the coverage behaviors of the systems employing\nthe ORP scheme. It is also shown that the optimal coverage performance is\nachieved when a single precoding vector is used under the condition that the\nthreshold of the signal-to-noise ratio of the coverage is greater than one. The\nperformance of the ORP scheme is further analyzed when different random\nprecoder groups are utilized over multiple time slots to exploit precoding\ndiversity. The numerical results show that the proposed ORP scheme over\nmultiple time slots provides a substantial coverage gain over the space-time\ncoding scheme despite its low feedback overhead. \n\n"}
{"id": "1701.03119", "contents": "Title: How to Quantize $n$ Outputs of a Binary Symmetric Channel to $n-1$ Bits? Abstract: Suppose that $Y^n$ is obtained by observing a uniform Bernoulli random vector\n$X^n$ through a binary symmetric channel with crossover probability $\\alpha$.\nThe \"most informative Boolean function\" conjecture postulates that the maximal\nmutual information between $Y^n$ and any Boolean function $\\mathrm{b}(X^n)$ is\nattained by a dictator function. In this paper, we consider the \"complementary\"\ncase in which the Boolean function is replaced by\n$f:\\left\\{0,1\\right\\}^n\\to\\left\\{0,1\\right\\}^{n-1}$, namely, an $n-1$ bit\nquantizer, and show that $I(f(X^n);Y^n)\\leq (n-1)\\cdot\\left(1-h(\\alpha)\\right)$\nfor any such $f$. Thus, in this case, the optimal function is of the form\n$f(x^n)=(x_1,\\ldots,x_{n-1})$. \n\n"}
{"id": "1701.03590", "contents": "Title: Generalized Approximate Message-Passing Decoder for Universal Sparse\n  Superposition Codes Abstract: Sparse superposition (SS) codes were originally proposed as a\ncapacity-achieving communication scheme over the additive white Gaussian noise\nchannel (AWGNC) [1]. Very recently, it was discovered that these codes are\nuniversal, in the sense that they achieve capacity over any memoryless channel\nunder generalized approximate message-passing (GAMP) decoding [2], although\nthis decoder has never been stated for SS codes. In this contribution we\nintroduce the GAMP decoder for SS codes, we confirm empirically the\nuniversality of this communication scheme through its study on various channels\nand we provide the main analysis tools: state evolution and potential. We also\ncompare the performance of GAMP with the Bayes-optimal MMSE decoder. We\nempirically illustrate that despite the presence of a phase transition\npreventing GAMP to reach the optimal performance, spatial coupling allows to\nboost the performance that eventually tends to capacity in a proper limit. We\nalso prove that, in contrast with the AWGNC case, SS codes for binary input\nchannels have a vanishing error floor in the limit of large codewords.\nMoreover, the performance of Hadamard-based encoders is assessed for practical\nimplementations. \n\n"}
{"id": "1701.03767", "contents": "Title: Analysis of Coupled Scalar Systems by Displacement Convexity Abstract: Potential functionals have been introduced recently as an important tool for\nthe analysis of coupled scalar systems (e.g. density evolution equations). In\nthis contribution, we investigate interesting properties of this potential.\nUsing the tool of displacement convexity, we show that, under mild assumptions\non the system, the potential functional is displacement convex. Furthermore, we\ngive the conditions on the system such that the potential is strictly\ndisplacement convex, in which case the minimizer is unique. \n\n"}
{"id": "1701.03916", "contents": "Title: On H\\\"older projective divergences Abstract: We describe a framework to build distances by measuring the tightness of\ninequalities, and introduce the notion of proper statistical divergences and\nimproper pseudo-divergences. We then consider the H\\\"older ordinary and reverse\ninequalities, and present two novel classes of H\\\"older divergences and\npseudo-divergences that both encapsulate the special case of the Cauchy-Schwarz\ndivergence. We report closed-form formulas for those statistical\ndissimilarities when considering distributions belonging to the same\nexponential family provided that the natural parameter space is a cone (e.g.,\nmultivariate Gaussians), or affine (e.g., categorical distributions). Those new\nclasses of H\\\"older distances are invariant to rescaling, and thus do not\nrequire distributions to be normalized. Finally, we show how to compute\nstatistical H\\\"older centroids with respect to those divergences, and carry out\ncenter-based clustering toy experiments on a set of Gaussian distributions that\ndemonstrate empirically that symmetrized H\\\"older divergences outperform the\nsymmetric Cauchy-Schwarz divergence. \n\n"}
{"id": "1701.04065", "contents": "Title: On the Asymptotic Behavior of Ultra-Densification under a Bounded\n  Dual-Slope Path Loss Model Abstract: In this paper, we investigate the impact of network densification on the\nperformance in terms of downlink signal-to-interference (SIR) coverage\nprobability and network area spectral efficiency (ASE). A sophisticated bounded\ndual-slope path loss model and practical user equipment (UE) densities are\nincorporated in the analysis, which have never been jointly considered before.\nBy using stochastic geometry, we derive an integral expression along with\nclosed-form bounds of the coverage probability and ASE, validated by simulation\nresults. Through these, we provide the asymptotic behavior of\nultra-densification. The coverage probability and ASE have non-zero convergence\nin asymptotic regions unless UE density goes to infinity (full load).\nMeanwhile, the effect of UE density on the coverage probability is analyzed.\nThe coverage probability will reveal an U-shape for large UE densities due to\ninterference fall into the near-field, but it will keep increasing for low UE\ndensites. Furthermore, our results indicate that the performance is\noverestimated without applying the bounded dual-slope path loss model. The\nderived expressions and results in this work pave the way for future network\nprovisioning. \n\n"}
{"id": "1701.04581", "contents": "Title: Modeling and Performance Studies of Data Communication Networks using\n  Dynamic Complex Networks Abstract: All the existing real world networks are evolving, hence, study of traffic\ndynamics in these enlarged networks is a challenging task. The critical issue\nis to optimize the network structure to improve network capacity and avoid\ntraffic congestion. We are interested in taking user's routes such that it is\nleast congested with optimal network capacity. Network capacity may be improved\neither by optimizing network topology or enhancing in routing approach. In this\ncontext, we propose and design a model of the time varying data communication\nnetworks (TVCN) based on the dynamics of in-flowing links. Newly appeared node\nprefers to attach with most influential node present in the network. In this\npaper, influence is termed as \\textit{reputation} and is applied for computing\noverall congestion at any node. User path with least betweenness centrality and\nmost reputation is preferred for routing. Kelly's optimization formulation for\na rate allocation problem is used for obtaining optimal rates of distinct users\nat different time instants and it is found that the user's path with lowest\nbetweenness centrality and highest reputation will always give maximum rate at\nstable point. \n\n"}
{"id": "1701.05212", "contents": "Title: Locally recoverable codes from algebraic curves and surfaces Abstract: A locally recoverable code is a code over a finite alphabet such that the\nvalue of any single coordinate of a codeword can be recovered from the values\nof a small subset of other coordinates. Building on work of Barg, Tamo, and\nVl\\u{a}du\\c{t}, we present several constructions of locally recoverable codes\nfrom algebraic curves and surfaces. \n\n"}
{"id": "1701.05711", "contents": "Title: Age-Optimal Information Updates in Multihop Networks Abstract: The problem of reducing the age-of-information has been extensively studied\nin the single-hop networks. In this paper, we minimize the age-of-information\nin general multihop networks. If the packet transmission times over the network\nlinks are exponentially distributed, we prove that a preemptive Last Generated\nFirst Served (LGFS) policy results in smaller age processes at all nodes of the\nnetwork (in a stochastic ordering sense) than any other causal policy. In\naddition, for arbitrary general distributions of packet transmission times, the\nnon-preemptive LGFS policy is shown to minimize the age processes at all nodes\nof the network among all non-preemptive work-conserving policies (again in a\nstochastic ordering sense). It is surprising that such simple policies can\nachieve optimality of the joint distribution of the age processes at all nodes\neven under arbitrary network topologies, as well as arbitrary packet generation\nand arrival times. These optimality results not only hold for the age\nprocesses, but also for any non-decreasing functional of the age processes. \n\n"}
{"id": "1701.06174", "contents": "Title: Feedback capacity and coding for the BIBO channel with a\n  no-repeated-ones input constraint Abstract: In this paper, a general binary-input binary-output (BIBO) channel is\ninvestigated in the presence of feedback and input constraints. The feedback\ncapacity and the optimal input distribution of this setting are calculated for\nthe case of an $(1,\\infty)$-RLL input constraint, that is, the input sequence\ncontains no consecutive ones. These results are obtained via explicit solution\nof a corresponding dynamic programming optimization problem. A simple coding\nscheme is designed based on the principle of posterior matching, which was\nintroduced by Shayevitz and Feder for memoryless channels. The posterior\nmatching scheme for our input-constrained setting is shown to achieve capacity\nusing two new ideas: \\textit{message history}, which captures the memory\nembedded in the setting, and \\textit{message splitting}, which eases the\nanalysis of the scheme. Additionally, in the special case of an S-channel, we\ngive a very simple zero-error coding scheme that is shown to achieve capacity.\nFor the input-constrained BSC, we show using our capacity formula that feedback\nincreases capacity when the cross-over probability is small. \n\n"}
{"id": "1701.06338", "contents": "Title: SCW Codes for Optimal CSI-Free Detection in Diffusive Molecular\n  Communications Abstract: Instantaneous or statistical channel state information (CSI) is needed for\nmost detection schemes developed in the molecular communication (MC)\nliterature. Since the MC channel changes, e.g., due to variations in the\nvelocity of flow, the temperature, or the distance between transmitter and\nreceiver, CSI acquisition has to be conducted repeatedly to keep track of CSI\nvariations. Frequent CSI acquisition may entail a large overhead whereas\ninfrequent CSI acquisition may result in a low CSI estimation quality. To cope\nwith these issues, we design codes which facilitate maximum likelihood sequence\ndetection at the receiver without instantaneous or statistical CSI. In\nparticular, assuming concentration shift keying modulation, we show that a\nclass of codes, referred to as strongly constant-weight (SCW) codes, enables\noptimal CSI-free sequence detection at the cost of decreasing the data rate.\nFor the proposed SCW codes, we analyze the code rate and the error rate.\nSimulation results verify our analytical derivations and reveal that the\nproposed CSI-free detector for SCW codes outperforms the baseline coherent and\nnon-coherent detectors for uncoded transmission. \n\n"}
{"id": "1701.06610", "contents": "Title: The Augustin Center and The Sphere Packing Bound For Memoryless Channels Abstract: For any channel with a convex constraint set and finite Augustin capacity,\nexistence of a unique Augustin center and associated Erven-Harremoes bound are\nestablished. Augustin-Legendre capacity, center, and radius are introduced and\nproved to be equal to the corresponding Renyi-Gallager entities. Sphere packing\nbounds with polynomial prefactors are derived for codes on two families of\nchannels: (possibly non-stationary) memoryless channels with multiple additive\ncost constraints and stationary memoryless channels with convex constraints on\nthe empirical distribution of the input codewords. \n\n"}
{"id": "1701.07098", "contents": "Title: A novel alternative to Cloud RAN for throughput densification: Coded\n  pilots and fast user-packet scheduling at remote radio heads Abstract: We consider wireless networks of remote radio heads (RRH) with large\nantenna-arrays, operated in TDD, with uplink (UL) training and\nchannel-reciprocity based downlink (DL) transmission. To achieve large area\nspectral efficiencies, we advocate the use of methods that rely on rudimentary\nscheduling, decentralized operation at each RRH and user-centric DL\ntransmission.\n  A slotted system is assumed, whereby users are randomly scheduled (e.g., via\nshuffled round robin) in slots and across the limited pilot dimensions per\nslot. As a result, multiple users in the vicinity of an RRH can simultaneously\ntransmit pilots on the same pilot dimension (and thus interfering with one\nanother). Each RRH performs rudimentary processing of the pilot observations in\n\"sectors\". In a sector, the RRH is able to resolve a scheduled user's channel\nwhen that user is determined to be the only one among the scheduled users (on\nthe same pilot dimension) with significant received power in the sector.\nSubsequently, only the subset of scheduled users whose channels are resolved in\nat least one sector can be served by the system.\n  We consider a spatially consistent evaluation of the area multiplexing gains\nby means of a Poisson Point Process (PPP) problem formulation where RRHs,\nblockers, scatterers and scheduled user terminals are all PPPs with individual\nintensities. Also, we study directional training at the user terminals. Our\nsimulations suggest that, by controlling the intensity of the scheduled user\nPPP and the user-pilot beam-width, many fold improvements can be expected in\narea multiplexing gains with respect to conventional spatial pilot reuse\nsystems. \n\n"}
{"id": "1701.07477", "contents": "Title: Group Testing using left-and-right-regular sparse-graph codes Abstract: We consider the problem of non-adaptive group testing of $N$ items out of\nwhich $K$ or less items are known to be defective. We propose a testing scheme\nbased on left-and-right-regular sparse-graph codes and a simple iterative\ndecoder. We show that for any arbitrarily small $\\epsilon>0$ our scheme\nrequires only $m=c_\\epsilon K\\log \\frac{c_1N}{K}$ tests to recover\n$(1-\\epsilon)$ fraction of the defective items with high probability (w.h.p)\ni.e., with probability approaching $1$ asymptotically in $N$ and $K$, where the\nvalue of constants $c_\\epsilon$ and $\\ell$ are a function of the desired error\nfloor $\\epsilon$ and constant $c_1=\\frac{\\ell}{c_\\epsilon}$ (observed to be\napproximately equal to 1 for various values of $\\epsilon$). More importantly\nthe iterative decoding algorithm has a sub-linear computational complexity of\n$\\mathcal{O}(K\\log \\frac{N}{K})$ which is known to be optimal. Also for $m=c_2\nK\\log K\\log \\frac{N}{K}$ tests our scheme recovers the \\textit{whole} set of\ndefective items w.h.p. These results are valid for both noiseless and noisy\nversions of the problem as long as the number of defective items scale\nsub-linearly with the total number of items, i.e., $K=o(N)$. The simulation\nresults validate the theoretical results by showing a substantial improvement\nin the number of tests required when compared to the testing scheme based on\nleft-regular sparse-graphs. \n\n"}
{"id": "1701.08059", "contents": "Title: Efficient Medium Access Arbitration Among Interfering WBANs Using Latin\n  Rectangles Abstract: The overlap of transmission ranges among multiple Wireless Body Area Networks\n(WBANs) is referred to as coexistence. The interference is most likely to\naffect the communication links and degrade the performance when sensors of\ndifferent WBANs simultaneously transmit using the same channel. In this paper,\nwe propose a distributed approach that adapts to the size of the network, i.e.,\nthe number of coexisting WBANs, and to the density of sensors forming each\nindividual WBAN in order to minimize the impact of co-channel interference\nthrough dynamic channel hopping based on Latin rectangles. Furthermore, the\nproposed approach opts to reduce the overhead resulting from channel hopping,\nand lowers the transmission delay, and saves the power resource at both sensor-\nand WBAN-levels. Specifically, we propose two schemes for channel allocation\nand medium access scheduling to diminish the probability of inter-WBAN\ninterference. The first scheme, namely, Distributed Interference Avoidance\nusing Latin rectangles (DAIL), assigns channel and time-slot combination that\nreduces the probability of medium access collision. DAIL suits crowded areas,\ne.g., high density of coexisting WBANs, and involves overhead due to frequent\nchannel hopping at the WBAN coordinator and sensors. The second scheme, namely,\nCHIM, takes advantage of the relatively lower density of collocated WBANs to\nsave power by hopping among channels only when interference is detected at the\nlevel of the individual nodes. We present an analytical model that derives the\ncollision probability and network throughput. The performance of DAIL and CHIM\nis further validated through simulations. \n\n"}
{"id": "1701.08083", "contents": "Title: Ensemble Estimation of Generalized Mutual Information with Applications\n  to Genomics Abstract: Mutual information is a measure of the dependence between random variables\nthat has been used successfully in myriad applications in many fields.\nGeneralized mutual information measures that go beyond classical Shannon mutual\ninformation have also received much interest in these applications. We derive\nthe mean squared error convergence rates of kernel density-based plug-in\nestimators of general mutual information measures between two multidimensional\nrandom variables $\\mathbf{X}$ and $\\mathbf{Y}$ for two cases: 1) $\\mathbf{X}$\nand $\\mathbf{Y}$ are continuous; 2) $\\mathbf{X}$ and $\\mathbf{Y}$ may have any\nmixture of discrete and continuous components. Using the derived rates, we\npropose an ensemble estimator of these information measures called GENIE by\ntaking a weighted sum of the plug-in estimators with varied bandwidths. The\nresulting ensemble estimators achieve the $1/N$ parametric mean squared error\nconvergence rate when the conditional densities of the continuous variables are\nsufficiently smooth. To the best of our knowledge, this is the first\nnonparametric mutual information estimator known to achieve the parametric\nconvergence rate for the mixture case, which frequently arises in applications\n(e.g. variable selection in classification). The estimator is simple to\nimplement and it uses the solution to an offline convex optimization problem\nand simple plug-in estimators. A central limit theorem is also derived for the\nensemble estimators and minimax rates are derived for the continuous case. We\ndemonstrate the ensemble estimator for the mixed case on simulated data and\napply the proposed estimator to analyze gene relationships in single cell data. \n\n"}
{"id": "1701.08924", "contents": "Title: Validating and describing linked data portals using shapes Abstract: Linked data portals need to be able to advertise and describe the structure\nof their content. A sufficiently expressive and intuitive schema language will\nallow portals to communicate these structures. Validation tools will aid in the\npublication and maintenance of linked data and increase their quality.\n  Two schema language proposals have recently emerged for describing the\nstructures of RDF graphs: Shape Expressions (ShEx) and Shapes Constraint\nLanguage (SHACL). In this paper we describe how these formalisms can be used in\nthe development of a linked data portal to describe and validate its contents.\nAs a use case, we specify a data model inspired by the WebIndex data model, a\nmedium size linked data portal, using both ShEx and SHACL, and we propose a\nbenchmark that can generate compliant test data structures of any size. We then\nperform some preliminary experiments showing performance of one validation\nengine based on ShEx. \n\n"}
{"id": "1702.01739", "contents": "Title: Multi-Message Private Information Retrieval: Capacity Results and\n  Near-Optimal Schemes Abstract: We consider the problem of multi-message private information retrieval (MPIR)\nfrom $N$ non-communicating replicated databases. In MPIR, the user is\ninterested in retrieving $P$ messages out of $M$ stored messages without\nleaking the identity of the retrieved messages. The information-theoretic sum\ncapacity of MPIR $C_s^P$ is the maximum number of desired message symbols that\ncan be retrieved privately per downloaded symbol. For the case $P \\geq\n\\frac{M}{2}$, we determine the exact sum capacity of MPIR as\n$C_s^P=\\frac{1}{1+\\frac{M-P}{PN}}$. The achievable scheme in this case is based\non downloading MDS-coded mixtures of all messages. For $P \\leq \\frac{M}{2}$, we\ndevelop lower and upper bounds for all $M,P,N$. These bounds match if the total\nnumber of messages $M$ is an integer multiple of the number of desired messages\n$P$, i.e., $\\frac{M}{P} \\in \\mathbb{N}$. In this case,\n$C_s^P=\\frac{1-\\frac{1}{N}}{1-(\\frac{1}{N})^{M/P}}$. The achievable scheme in\nthis case generalizes the single-message capacity achieving scheme to have\nunbalanced number of stages per round of download. For all the remaining cases,\nthe difference between the lower and upper bound is at most $0.0082$, which\noccurs for $M=5$, $P=2$, $N=2$. Our results indicate that joint retrieval of\ndesired messages is more efficient than successive use of single-message\nretrieval schemes. \n\n"}
{"id": "1702.02685", "contents": "Title: Combinatorial Alphabet-Dependent Bounds for Locally Recoverable Codes Abstract: Locally recoverable (LRC) codes have recently been a focus point of research\nin coding theory due to their theoretical appeal and applications in\ndistributed storage systems. In an LRC code, any erased symbol of a codeword\ncan be recovered by accessing only a small number of other symbols. For LRC\ncodes over a small alphabet (such as binary), the optimal rate-distance\ntrade-off is unknown. We present several new combinatorial bounds on LRC codes\nincluding the locality-aware sphere packing and Plotkin bounds. We also develop\nan approach to linear programming (LP) bounds on LRC codes. The resulting LP\nbound gives better estimates in examples than the other upper bounds known in\nthe literature. Further, we provide the tightest known upper bound on the rate\nof linear LRC codes with a given relative distance, an improvement over the\nprevious best known bounds. \n\n"}
{"id": "1702.04563", "contents": "Title: Characterizing the Rate-Memory Tradeoff in Cache Networks within a\n  Factor of 2 Abstract: We consider a basic caching system, where a single server with a database of\n$N$ files (e.g. movies) is connected to a set of $K$ users through a shared\nbottleneck link. Each user has a local cache memory with a size of $M$ files.\nThe system operates in two phases: a placement phase, where each cache memory\nis populated up to its size from the database, and a following delivery phase,\nwhere each user requests a file from the database, and the server is\nresponsible for delivering the requested contents. The objective is to design\nthe two phases to minimize the load (peak or average) of the bottleneck link.\nWe characterize the rate-memory tradeoff of the above caching system within a\nfactor of $2.00884$ for both the peak rate and the average rate (under uniform\nfile popularity), improving state of the arts that are within a factor of $4$\nand $4.7$ respectively. Moreover, in a practically important case where the\nnumber of files ($N$) is large, we exactly characterize the tradeoff for\nsystems with no more than $5$ users, and characterize the tradeoff within a\nfactor of $2$ otherwise. To establish these results, we develop two new\nconverse bounds that improve over the state of the art. \n\n"}
{"id": "1702.04582", "contents": "Title: On the number of inequivalent Gabidulin codes Abstract: Maximum rank-distance (MRD) codes are extremal codes in the space of $m\\times\nn$ matrices over a finite field, equipped with the rank metric. Up to\ngeneralizations, the classical examples of such codes were constructed in the\n1970s and are today known as Gabidulin codes. Motivated by several recent\napproaches to construct MRD codes that are inequivalent to Gabidulin codes, we\nstudy the equivalence issue for Gabidulin codes themselves. This shows in\nparticular that the family of Gabidulin codes already contains a huge subset of\nMRD codes that are pairwise inequivalent, provided that $2\\le m\\le n-2$. \n\n"}
{"id": "1702.06901", "contents": "Title: Scaling Deep Learning-based Decoding of Polar Codes via Partitioning Abstract: The training complexity of deep learning-based channel decoders scales\nexponentially with the codebook size and therefore with the number of\ninformation bits. Thus, neural network decoding (NND) is currently only\nfeasible for very short block lengths. In this work, we show that the\nconventional iterative decoding algorithm for polar codes can be enhanced when\nsub-blocks of the decoder are replaced by neural network (NN) based components.\nThus, we partition the encoding graph into smaller sub-blocks and train them\nindividually, closely approaching maximum a posteriori (MAP) performance per\nsub-block. These blocks are then connected via the remaining conventional\nbelief propagation decoding stage(s). The resulting decoding algorithm is\nnon-iterative and inherently enables a high-level of parallelization, while\nshowing a competitive bit error rate (BER) performance. We examine the\ndegradation through partitioning and compare the resulting decoder to\nstate-of-the-art polar decoders such as successive cancellation list and belief\npropagation decoding. \n\n"}
{"id": "1702.07498", "contents": "Title: Secure Clustered Distributed Storage Against Eavesdroppers Abstract: This paper considers the security issue of practical distributed storage\nsystems (DSSs) which consist of multiple clusters of storage nodes. Noticing\nthat actual storage nodes constituting a DSS are distributed in multiple\nclusters, two novel eavesdropper models - the node-restricted model and the\ncluster-restricted model - are suggested which reflect the clustered nature of\nDSSs. In the node-restricted model, an eavesdropper cannot access the\nindividual nodes, but can eavesdrop incoming/outgoing data for $L_c$\ncompromised clusters. In the cluster-restricted model, an eavesdropper can\naccess a total of $l$ individual nodes but the number of accessible clusters is\nlimited to $L_c$. We provide an upper bound on the securely storable data for\neach model, while a specific network coding scheme which achieves the upper\nbound is obtained for the node-restricted model, given some mild condition on\nthe node storage size. \n\n"}
{"id": "1702.08033", "contents": "Title: Euclidean and Hermitian LCD MDS codes Abstract: Linear codes with complementary duals (abbreviated LCD) are linear codes\nwhose intersection with their dual is trivial. When they are binary, they play\nan important role in armoring implementations against side-channel attacks and\nfault injection attacks. Non-binary LCD codes in characteristic 2 can be\ntransformed into binary LCD codes by expansion. On the other hand, being\noptimal codes, maximum distance separable codes (abbreviated MDS) have been of\nmuch interest from many researchers due to their theoretical significant and\npractical implications. However, little work has been done on LCD MDS codes. In\nparticular, determining the existence of $q$-ary $[n,k]$ LCD MDS codes for\nvarious lengths $n$ and dimensions $k$ is a basic and interesting problem. In\nthis paper, we firstly study the problem of the existence of $q$-ary $[n,k]$\nLCD MDS codes and completely solve it for the Euclidean case. More\nspecifically, we show that for $q>3$ there exists a $q$-ary $[n,k]$ Euclidean\nLCD MDS code, where $0\\le k \\le n\\le q+1$, or, $q=2^{m}$, $n=q+2$ and $k= 3\n\\text{or} q-1$. Secondly, we investigate several constructions of new Euclidean\nand Hermitian LCD MDS codes. Our main techniques in constructing Euclidean and\nHermitian LCD MDS codes use some linear codes with small dimension or\ncodimension, self-orthogonal codes and generalized Reed-Solomon codes. \n\n"}
{"id": "1703.00064", "contents": "Title: Ending the Anomaly: Achieving Low Latency and Airtime Fairness in WiFi Abstract: With more devices connected, delays and jitter at the WiFi hop become more\nprevalent, and correct functioning during network congestion becomes more\nimportant. However, two important performance issues prevent modern WiFi from\nreaching its potential: Increased latency under load caused by excessive\nqueueing (i.e. bufferbloat) and the 802.11 performance anomaly.\n  To remedy these issues, we present a novel two-part solution: We design a new\nqueueing scheme that eliminates bufferbloat in the wireless setting. Leveraging\nthis queueing scheme, we then design an airtime fairness scheduler that\noperates at the access point and doesn't require any changes to clients.\n  We evaluate our solution using both a theoretical model and experiments in a\ntestbed environment, formulating a suitable analytical model in the process. We\nshow that our solution achieves an order of magnitude reduction in latency\nunder load, large improvements in multi-station throughput, and nearly perfect\nairtime fairness for both TCP and downstream UDP traffic. Further experiments\nwith application traffic confirm that the solution provides significant\nperformance gains for real-world traffic.We develop a production quality\nimplementation of our solution in the Linux kernel, the platform powering most\naccess points outside of the managed enterprise setting. The implementation has\nbeen accepted into the mainline kernel distribution, making it available for\ndeployment on billions of devices running Linux today. \n\n"}
{"id": "1703.00134", "contents": "Title: Collision Resolution and Interference Elimination in Multiaccess\n  Communication Networks Abstract: We define a multiaccess communication scheme that effectively eliminates\ninterference and resolves collisions in many-to-one and many-to-many\ncommunication scenarios. Each transmitter is uniquely identified by a steering\nvector. All signals issued from a specific transmitter will be steered into the\nsame single-dimensional or double-dimensional subspace at all receivers hearing\nthis transmission. This subspace is orthogonal to the noise subspace at a\nreceiver and the signals within the subspace can be extracted using the\nroot-MUSIC method. At high SNR, local channel knowledge and strict\nsynchronization, the algorithm asymptotically achieves full network capacity on\ncondition that a channel remains constant within a single time slot. Without\nsynchronization, the worst case asymptotic performance is still greater than\nthe $50\\%$ throughput achieved by collision resolution algorithms and\ninterference management techniques like interference alignment. \n\n"}
{"id": "1703.00893", "contents": "Title: Being Robust (in High Dimensions) Can Be Practical Abstract: Robust estimation is much more challenging in high dimensions than it is in\none dimension: Most techniques either lead to intractable optimization problems\nor estimators that can tolerate only a tiny fraction of errors. Recent work in\ntheoretical computer science has shown that, in appropriate distributional\nmodels, it is possible to robustly estimate the mean and covariance with\npolynomial time algorithms that can tolerate a constant fraction of\ncorruptions, independent of the dimension. However, the sample and time\ncomplexity of these algorithms is prohibitively large for high-dimensional\napplications. In this work, we address both of these issues by establishing\nsample complexity bounds that are optimal, up to logarithmic factors, as well\nas giving various refinements that allow the algorithms to tolerate a much\nlarger fraction of corruptions. Finally, we show on both synthetic and real\ndata that our algorithms have state-of-the-art performance and suddenly make\nhigh-dimensional robust estimation a realistic possibility. \n\n"}
{"id": "1703.01080", "contents": "Title: Good cyclic codes and the uncertainty principle Abstract: A long standing problem in the area of error correcting codes asks whether\nthere exist good cyclic codes. Most of the known results point in the direction\nof a negative answer.\n  The uncertainty principle is a classical result of harmonic analysis\nasserting that given a non-zero function $f$ on some abelian group, either $f$\nor its Fourier transform $\\hat{f}$ has large support.\n  In this note, we observe a connection between these two subjects. We point\nout that even a weak version of the uncertainty principle for fields of\npositive characteristic would imply that good cyclic codes do exist. We also\nprovide some heuristic arguments supporting that this is indeed the case. \n\n"}
{"id": "1703.03028", "contents": "Title: Beamspace Aware Adaptive Channel Estimation for Single-Carrier\n  Time-varying Massive MIMO Channels Abstract: In this paper, the problem of sequential beam construction and adaptive\nchannel estimation based on reduced rank (RR) Kalman filtering for\nfrequency-selective massive multiple-input multiple-output (MIMO) systems\nemploying single-carrier (SC) in time division duplex (TDD) mode are\nconsidered. In two-stage beamforming, a new algorithm for statistical\npre-beamformer design is proposed for spatially correlated time-varying\nwideband MIMO channels under the assumption that the channel is a stationary\nGauss-Markov random process. The proposed algorithm yields a nearly optimal\npre-beamformer whose beam pattern is designed sequentially with low complexity\nby taking the user-grouping into account, and exploiting the properties of\nKalman filtering and associated prediction error covariance matrices. The\nresulting design, based on the second order statistical properties of the\nchannel, generates beamspace on which the RR Kalman estimator can be realized\nas accurately as possible. It is observed that the adaptive channel estimation\ntechnique together with the proposed sequential beamspace construction shows\nremarkable robustness to the pilot interference. This comes with significant\nreduction in both pilot overhead and dimension of the pre-beamformer lowering\nboth hardware complexity and power consumption. \n\n"}
{"id": "1703.04006", "contents": "Title: Waveform Optimization for Radio-Frequency Wireless Power Transfer Abstract: In this paper, we study the waveform design problem for a single-input\nsingle-output (SISO) radio-frequency (RF) wireless power transfer (WPT) system\nin frequency-selective channels. First, based on the actual non-linear\ncurrent-voltage model of the diode at the energy receiver, we derive a\nsemi-closed-form expression for the deliverable DC voltage in terms of the\nincident RF signal and hence obtain the average harvested power. Next, by\nadopting a multisine waveform structure for the transmit signal of the energy\ntransmitter, we jointly design the multisine signal amplitudes and phases\noverall frequency tones according to the channel state information (CSI) to\nmaximize the deliverable DC voltage or harvested power. Although our formulated\nproblem is non-convex and difficult to solve, we propose two suboptimal\nsolutions to it, based on the frequency-domain maximal ratio transmission (MRT)\nprinciple and the sequential convex optimization (SCP) technique, respectively.\nUsing various simulations, the performance gain of our solutions over the\nexisting waveform designs is shown. \n\n"}
{"id": "1703.04349", "contents": "Title: Interference Networks with Caches at Both Ends Abstract: A $K_T \\times K_R$ cache-aided wireless interference network, in which both\nthe transmitters and the receivers are equipped with cache memories is studied.\nEach user requests one file from a library of $N$ popular files. The goal is to\ndesign the cache contents without the knowledge of the particular user demands,\nsuch that all possible demand combinations can be satisfied reliably over the\ninterference channel. The achievable sum degrees-of-freedom ($\\mathrm{sDoF}$)\nand the normalized delivery time (NDT) are studied for centralized and\ndecentralized network architectures, respectively. First, using a combination\nof interference alignment (IA), zero-forcing (ZF) and interference cancellation\n(IC) techniques, a novel caching and transmission scheme for centralized\nnetworks is introduced, and it is shown to improve the $\\mathrm{sDoF}$ upon the\nstate-of-the-art. Then, the NDT is studied when the content placement at the\nreceiver caches is carried out in a decentralized manner. Our results indicate\nthat, for this particular network architecture, caches located at the receiver\nside are more effective than those at the transmitter side in order to reduce\nthe NDT. \n\n"}
{"id": "1703.04995", "contents": "Title: Statistical Multiplexing of Computations in C-RAN with Tradeoffs in\n  Latency and Energy Abstract: In the Cloud Radio Access Network (C-RAN) architecture, the baseband signals\nfrom multiple remote radio heads are processed in a centralized baseband unit\n(BBU) pool. This architecture allows network operators to adapt the BBU's\ncomputational resources to the aggregate access load experienced at the BBU,\nwhich can change in every air-interface access frame. The degree of savings\nthat can be achieved by adapting the resources is a tradeoff between savings,\nadaptation frequency, and increased queuing time. If the time scale for\nadaptation of the resource multiplexing is greater than the access frame\nduration, then this may result in additional access latency and limit the\nenergy savings. In this paper we investigate the tradeoff by considering two\nextreme time-scales for the resource multiplexing: (i) long-term, where the\ncomputational resources are adapted over periods much larger than the access\nframe durations; (ii) short-term, where the adaption is below the access frame\nduration. We develop a general C-RAN queuing model that describes the access\nlatency and show, for Poisson arrivals, that long-term multiplexing achieves\nsavings comparable to short-term multiplexing, while offering low\nimplementation complexity. \n\n"}
{"id": "1703.06714", "contents": "Title: Generalized Compute-Compress-and-Forward Abstract: Compute-and-forward (CF) harnesses interference in wireless communications by\nexploiting structured coding. The key idea of CF is to compute integer\ncombinations of codewords from multiple source nodes, rather than to decode\nindividual codewords by treating others as noise. Compute-compress-and-forward\n(CCF) can further enhance the network performance by introducing compression\noperations at receivers. In this paper, we develop a more general compression\nframework, termed generalized compute-compress-and-forward (GCCF), where the\ncompression function involves multiple quantization-and-modulo lattice\noperations. We show that GCCF achieves a broader compression rate region than\nCCF. We also compare our compression rate region with the fundamental\nSlepian-Wolf (SW) region. We show that GCCF is optimal in the sense of\nachieving the minimum total compression rate. We also establish the criteria\nunder which GCCF achieves the SW region. In addition, we consider a two-hop\nrelay network employing the GCCF scheme. We formulate a sum-rate maximization\nproblem and develop an approximate algorithm to solve the problem. Numerical\nresults are presented to demonstrate the performance superiority of GCCF over\nCCF and other schemes. \n\n"}
{"id": "1703.08337", "contents": "Title: Taming Tail Latency for Erasure-coded, Distributed Storage Systems Abstract: Distributed storage systems are known to be susceptible to long tails in\nresponse time. In modern online storage systems such as Bing, Facebook, and\nAmazon, the long tails of the service latency are of particular concern. with\n99.9th percentile response times being orders of magnitude worse than the mean.\nAs erasure codes emerge as a popular technique to achieve high data reliability\nin distributed storage while attaining space efficiency, taming tail latency\nstill remains an open problem due to the lack of mathematical models for\nanalyzing such systems. To this end, we propose a framework for quantifying and\noptimizing tail latency in erasure-coded storage systems. In particular, we\nderive upper bounds on tail latency in closed form for arbitrary service time\ndistribution and heterogeneous files. Based on the model, we formulate an\noptimization problem to jointly minimize the weighted latency tail probability\nof all files over the placement of files on the servers, and the choice of\nservers to access the requested files. The non-convex problem is solved using\nan efficient, alternating optimization algorithm. Numerical results show\nsignificant reduction of tail latency for erasure-coded storage systems with a\nrealistic workload. \n\n"}
{"id": "1703.08947", "contents": "Title: In Vivo Evaluation of the Secure Opportunistic Schemes Middleware using\n  a Delay Tolerant Social Network Abstract: Over the past decade, online social networks (OSNs) such as Twitter and\nFacebook have thrived and experienced rapid growth to over 1 billion users. A\nmajor evolution would be to leverage the characteristics of OSNs to evaluate\nthe effectiveness of the many routing schemes developed by the research\ncommunity in real-world scenarios. In this paper, we showcase the Secure\nOpportunistic Schemes (SOS) middleware which allows different routing schemes\nto be easily implemented relieving the burden of security and connection\nestablishment. The feasibility of creating a delay tolerant social network is\ndemonstrated by using SOS to power AlleyOop Social, a secure delay tolerant\nnetworking research platform that serves as a real-life mobile social\nnetworking application for iOS devices. SOS and AlleyOop Social allow users to\ninteract, publish messages, and discover others that share common interests in\nan intermittent network using Bluetooth, peer-to-peer WiFi, and infrastructure\nWiFi. \n\n"}
{"id": "1703.09025", "contents": "Title: Service Overlay Forest Embedding for Software-Defined Cloud Networks Abstract: Network Function Virtualization (NFV) on Software-Defined Networks (SDN) can\neffectively optimize the allocation of Virtual Network Functions (VNFs) and the\nrouting of network flows simultaneously. Nevertheless, most previous studies on\nNFV focus on unicast service chains and thereby are not scalable to support a\nlarge number of destinations in multicast. On the other hand, the allocation of\nVNFs has not been supported in the current SDN multicast routing algorithms. In\nthis paper, therefore, we make the first attempt to tackle a new challenging\nproblem for finding a service forest with multiple service trees, where each\ntree contains multiple VNFs required by each destination. Specifically, we\nformulate a new optimization, named Service Overlay Forest (SOF), to minimize\nthe total cost of all allocated VNFs and all multicast trees in the forest. We\ndesign a new $3\\rho_{ST}$-approximation algorithm to solve the problem, where\n$\\rho_{ST}$ denotes the best approximation ratio of the Steiner Tree problem,\nand the distributed implementation of the algorithm is also presented.\nSimulation results on real networks for data centers manifest that the proposed\nalgorithm outperforms the existing ones by over 25%. Moreover, the\nimplementation of an experimental SDN with HP OpenFlow switches indicates that\nSOF can significantly improve the QoE of the Youtube service. \n\n"}
{"id": "1704.01891", "contents": "Title: On Multi-source Networks: Enumeration, Rate Region Computation, and\n  Hierarchy Abstract: Recent algorithmic developments have enabled computers to automatically\ndetermine and prove the capacity regions of small hypergraph networks under\nnetwork coding. A structural theory relating network coding problems of\ndifferent sizes is developed to make best use of this newfound computational\ncapability. A formal notion of network minimality is developed which removes\ncomponents of a network coding problem that are inessential to its core\ncomplexity. Equivalence between different network coding problems under\nrelabeling is formalized via group actions, an algorithm which can directly\nlist single representatives from each equivalence class of minimal networks up\nto a prescribed network size is presented. This algorithm, together with rate\nregion software, is leveraged to create a database containing the rate regions\nfor all minimal network coding problems with five or fewer sources and edges, a\ncollection of 744119 equivalence classes representing more than 9 million\nnetworks. In order to best learn from this database, and to leverage it to\ninfer rate regions and their characteristics of networks at scale, a hierarchy\nbetween different network coding problems is created with a new theory of\ncombinations and embedding operators. \n\n"}
{"id": "1704.02275", "contents": "Title: Mitigating Interference in Content Delivery Networks by Spatial Signal\n  Alignment: The Approach of Shot-Noise Ratio Abstract: Multimedia content especially videos is expected to dominate data traffic in\nnext-generation mobile networks. Caching popular content at the network edge\nhas emerged to be a solution for low-latency content delivery. Compared with\nthe traditional wireless communication, content delivery has a key\ncharacteristic that many signals coexisting in the air carry identical popular\ncontent. They, however, can interfere with each other at a receiver if their\nmodulation-and-coding (MAC) schemes are adapted to individual channels\nfollowing the classic approach. To address this issue, we present a novel idea\nof content adaptive MAC (CAMAC) where adapting MAC schemes to content ensures\nthat all signals carry identical content are encoded using an identical MAC\nscheme, achieving spatial MAC alignment. Consequently, interference can be\nharnessed as signals, to improve the reliability of wireless delivery. In the\nremaining part of the paper, we focus on quantifying the gain CAMAC can bring\nto a content-delivery network using a stochastic-geometry model. Specifically,\ncontent helpers are distributed as a Poisson point process, each of which\ntransmits a file from a content database based on a given popularity\ndistribution. It is discovered that the successful content-delivery probability\nis closely related to the distribution of the ratio of two independent shot\nnoise processes, named a shot-noise ratio. The distribution itself is an open\nmathematical problem that we tackle in this work. Using stable-distribution\ntheory and tools from stochastic geometry, the distribution function is derived\nin closed form. Extending the result in the context of content-delivery\nnetworks with CAMAC yields the content-delivery probability in different closed\nforms. In addition, the gain in the probability due to CAMAC is shown to grow\nwith the level of skewness in the content popularity distribution. \n\n"}
{"id": "1704.03311", "contents": "Title: $b$-symbol distance distribution of repeated-root cyclic codes Abstract: Symbol-pair codes, introduced by Cassuto and Blaum [1], have been raised for\nsymbol-pair read channels. This new idea is motivated by the limitation of the\nreading process in high-density data storage technologies. Yaakobi et al. [8]\nintroduced codes for $b$-symbol read channels, where the read operation is\nperformed as a consecutive sequence of $b>2$ symbols. In this paper, we come up\nwith a method to compute the $b$-symbol-pair distance of two $n$-tuples, where\n$n$ is a positive integer. Also, we deal with the $b$-symbol-pair distances of\nsome kind of cyclic codes of length $p^e$ over $\\mathbb{F}_{p^m}$. \n\n"}
{"id": "1704.03519", "contents": "Title: On Codes over $\\mathbb{F}_{q}+v\\mathbb{F}_{q}+v^{2}\\mathbb{F}_{q}$ Abstract: In this paper we investigate linear codes with complementary dual (LCD) codes\nand formally self-dual codes over the ring $R=\\F_{q}+v\\F_{q}+v^{2}\\F_{q}$,\nwhere $v^{3}=v$, for $q$ odd. We give conditions on the existence of LCD codes\nand present construction of formally self-dual codes over $R$. Further, we give\nbounds on the minimum distance of LCD codes over $\\F_q$ and extend these to\ncodes over $R$. \n\n"}
{"id": "1704.03591", "contents": "Title: Bayesian Optimal Data Detector for mmWave OFDM System with\n  Low-Resolution ADC Abstract: Orthogonal frequency division multiplexing (OFDM) has been widely used in\ncommunication systems operating in the millimeter wave (mmWave) band to combat\nfrequency-selective fading and achieve multi-Gbps transmissions, such as IEEE\n802.15.3c and IEEE 802.11ad. For mmWave systems with ultra high sampling rate\nrequirements, the use of low-resolution analog-to-digital converters (ADCs)\n(i.e., 1-3 bits) ensures an acceptable level of power consumption and system\ncosts. However, orthogonality among sub-channels in the OFDM system cannot be\nmaintained because of the severe non-linearity caused by low-resolution ADC,\nwhich renders the design of data detector challenging. In this study, we\ndevelop an efficient algorithm for optimal data detection in the mmWave OFDM\nsystem with low-resolution ADCs. The analytical performance of the proposed\ndetector is derived and verified to achieve the fundamental limit of the\nBayesian optimal design. On the basis of the derived analytical expression, we\nfurther propose a power allocation (PA) scheme that seeks to minimize the\naverage symbol error rate. In addition to the optimal data detector, we also\ndevelop a feasible channel estimation method, which can provide high-quality\nchannel state information without significant pilot overhead. Simulation\nresults confirm the accuracy of our analysis and illustrate that the\nperformance of the proposed detector in conjunction with the proposed PA scheme\nis close to the optimal performance of the OFDM system with infinite-resolution\nADC. \n\n"}
{"id": "1704.04007", "contents": "Title: Matroid Theory and Storage Codes: Bounds and Constructions Abstract: Recent research on distributed storage systems (DSSs) has revealed\ninteresting connections between matroid theory and locally repairable codes\n(LRCs). The goal of this chapter is to introduce the reader to matroids and\npolymatroids, and illustrate their relation to distribute storage systems.\nWhile many of the results are rather technical in nature, effort is made to\nincrease accessibility via simple examples. The chapter embeds all the\nessential features of LRCs, namely locality, availability, and hierarchy\nalongside with related generalised Singleton bounds. \n\n"}
{"id": "1704.04194", "contents": "Title: Ultrametrics in the genetic code and the genome Abstract: Ultrametric approach to the genetic code and the genome is considered and\ndeveloped. $p$-Adic degeneracy of the genetic code is pointed out. Ultrametric\ntree of the codon space is presented. It is shown that codons and amino acids\ncan be treated as $p$-adic ultrametric networks. Ultrametric modification of\nthe Hamming distance is defined and noted how it can be useful. Ultrametric\napproach with $p$-adic distance is an attractive and promising trend towards\ninvestigation of bioinformation. \n\n"}
{"id": "1704.04548", "contents": "Title: On the Gap Between Strict-Saddles and True Convexity: An Omega(log d)\n  Lower Bound for Eigenvector Approximation Abstract: We prove a \\emph{query complexity} lower bound on rank-one principal\ncomponent analysis (PCA). We consider an oracle model where, given a symmetric\nmatrix $M \\in \\mathbb{R}^{d \\times d}$, an algorithm is allowed to make $T$\n\\emph{exact} queries of the form $w^{(i)} = Mv^{(i)}$ for $i \\in\n\\{1,\\dots,T\\}$, where $v^{(i)}$ is drawn from a distribution which depends\narbitrarily on the past queries and measurements $\\{v^{(j)},w^{(j)}\\}_{1 \\le j\n\\le i-1}$. We show that for a small constant $\\epsilon$, any adaptive,\nrandomized algorithm which can find a unit vector $\\widehat{v}$ for which\n$\\widehat{v}^{\\top}M\\widehat{v} \\ge (1-\\epsilon)\\|M\\|$, with even small\nprobability, must make $T = \\Omega(\\log d)$ queries. In addition to settling a\nwidely-held folk conjecture, this bound demonstrates a fundamental gap between\nconvex optimization and \"strict-saddle\" non-convex optimization of which PCA is\na canonical example: in the former, first-order methods can have dimension-free\niteration complexity, whereas in PCA, the iteration complexity of\ngradient-based methods must necessarily grow with the dimension. Our argument\nproceeds via a reduction to estimating the rank-one spike in a deformed Wigner\nmodel. We establish lower bounds for this model by developing a \"truncated\"\nanalogue of the $\\chi^2$ Bayes-risk lower bound of Chen et al. \n\n"}
{"id": "1704.04595", "contents": "Title: Exploiting Non-Causal CPU-State Information for Energy-Efficient Mobile\n  Cooperative Computing Abstract: Scavenging the idling computation resources at the enormous number of mobile\ndevices can provide a powerful platform for local mobile cloud computing. The\nvision can be realized by peer-to-peer cooperative computing between edge\ndevices, referred to as co-computing. This paper considers a co-computing\nsystem where a user offloads computation of input-data to a helper. The helper\ncontrols the offloading process for the objective of minimizing the user's\nenergy consumption based on a predicted helper's CPU-idling profile that\nspecifies the amount of available computation resource for co-computing.\nConsider the scenario that the user has one-shot input-data arrival and the\nhelper buffers offloaded bits. The problem for energy-efficient co-computing is\nformulated as two sub-problems: the slave problem corresponding to adaptive\noffloading and the master one to data partitioning. Given a fixed offloaded\ndata size, the adaptive offloading aims at minimizing the energy consumption\nfor offloading by controlling the offloading rate under the deadline and buffer\nconstraints. By deriving the necessary and sufficient conditions for the\noptimal solution, we characterize the structure of the optimal policies and\npropose algorithms for computing the policies. Furthermore, we show that the\nproblem of optimal data partitioning for offloading and local computing at the\nuser is convex, admitting a simple solution using the sub-gradient method.\nLast, the developed design approach for co-computing is extended to the\nscenario of bursty data arrivals at the user accounting for data causality\nconstraints. Simulation results verify the effectiveness of the proposed\nalgorithms. \n\n"}
{"id": "1704.05623", "contents": "Title: Maximum Likelihood Detection for Cooperative Molecular Communication Abstract: In this paper, symbol-by-symbol maximum likelihood (ML) detection is proposed\nfor a cooperative diffusion-based molecular communication (MC) system. In this\nsystem, a fusion center (FC) chooses the transmitter's symbol that is more\nlikely, given the likelihood of the observations from multiple receivers (RXs).\nWe propose three different ML detection variants according to different\nconstraints on the information available to the FC, which enables us to\ndemonstrate trade-offs in their performance versus the information available.\nThe system error probability for one variant is derived in closed form.\nNumerical and simulation results show that the ML detection variants provide\nlower bounds on the error performance of the simpler cooperative variants and\ndemonstrate that majority rule detection has performance comparable to ML\ndetection when the reporting is noisy. \n\n"}
{"id": "1704.06785", "contents": "Title: A general private information retrieval scheme for MDS coded databases\n  with colluding servers Abstract: The problem of private information retrieval gets renewed attentions in\nrecent years due to its information-theoretic reformulation and applications in\ndistributed storage systems. PIR capacity is the maximal number of bits\nprivately retrieved per one bit of downloaded bit. The capacity has been fully\nsolved for some degenerating cases. For a general case where the database is\nboth coded and colluded, the exact capacity remains unknown. We build a general\nprivate information retrieval scheme for MDS coded databases with colluding\nservers. Our scheme achieves the rate $(1+R+R^2+\\cdots+R^{M-1})$, where\n$R=1-\\frac{{{N-T}\\choose K}}{{N\\choose K}}$. Compared to existing PIR schemes,\nour scheme performs better for a certain range of parameters and is suitable\nfor any underlying MDS code used in the distributed storage system. \n\n"}
{"id": "1704.07223", "contents": "Title: Entropic Trace Estimates for Log Determinants Abstract: The scalable calculation of matrix determinants has been a bottleneck to the\nwidespread application of many machine learning methods such as determinantal\npoint processes, Gaussian processes, generalised Markov random fields, graph\nmodels and many others. In this work, we estimate log determinants under the\nframework of maximum entropy, given information in the form of moment\nconstraints from stochastic trace estimation. The estimates demonstrate a\nsignificant improvement on state-of-the-art alternative methods, as shown on a\nwide variety of UFL sparse matrices. By taking the example of a general Markov\nrandom field, we also demonstrate how this approach can significantly\naccelerate inference in large-scale learning methods involving the log\ndeterminant. \n\n"}
{"id": "1704.07693", "contents": "Title: Coding for Arbitrarily Varying Remote Sources Abstract: We study a lossy source coding problem for a memoryless remote source. The\nsource data is broadcast over an arbitrarily varying channel (AVC) controlled\nby an adversary. One output of the AVC is received as input at the encoder, and\nanother output is received as side information at the decoder. The adversary is\nassumed to know the source data non-causally, and can employ randomized jamming\nstrategies arbitrarily correlated to the source data. The decoder reconstructs\nthe source data from the encoded message and the side information. We prove\nupper and lower bounds on the adversarial rate distortion function for the\nsource under randomized coding. Furthermore, we present some interesting\nspecial cases of our general setup where the above bounds coincide, and thus,\nprovide their complete rate distortion function characterization. \n\n"}
{"id": "1704.07766", "contents": "Title: A lower bound on the differential entropy of log-concave random vectors\n  with applications Abstract: We derive a lower bound on the differential entropy of a log-concave random\nvariable $X$ in terms of the $p$-th absolute moment of $X$. The new bound leads\nto a reverse entropy power inequality with an explicit constant, and to new\nbounds on the rate-distortion function and the channel capacity.\n  Specifically, we study the rate-distortion function for log-concave sources\nand distortion measure $| x - \\hat x|^r$, and we establish that the difference\nbetween the rate distortion function and the Shannon lower bound is at most\n$\\log(\\sqrt{\\pi e}) \\approx 1.5$ bits, independently of $r$ and the target\ndistortion $d$. For mean-square error distortion, the difference is at most\n$\\log (\\sqrt{\\frac{\\pi e}{2}}) \\approx 1$ bits, regardless of $d$.\n  We also provide bounds on the capacity of memoryless additive noise channels\nwhen the noise is log-concave. We show that the difference between the capacity\nof such channels and the capacity of the Gaussian channel with the same noise\npower is at most $\\log (\\sqrt{\\frac{\\pi e}{2}}) \\approx 1$ bits.\n  Our results generalize to the case of vector $X$ with possibly dependent\ncoordinates, and to $\\gamma$-concave random variables. Our proof technique\nleverages tools from convex geometry. \n\n"}
{"id": "1704.07901", "contents": "Title: Fundamental Limits of Coded Caching: From Uncoded Prefetching to Coded\n  Prefetching Abstract: In order to characterize the fundamental limit of the tradeoff between the\namount of cache memory and the delivery transmission rate of multiuser caching\nsystems, various coding schemes have been proposed in the literature. These\nschemes can largely be categorized into two classes, namely uncoded prefetching\nschemes and coded prefetching schemes. While uncoded prefetching schemes in\ngeneral offer order-wise optimal performance, coded prefetching schemes often\nhave better performance at the low cache memory regime. The significant\ndifferences in the coding components between the two classes may leave the\nimpression that they are largely unrelated. In this work, we provide a\nconnection between the uncoded prefetching scheme proposed by Maddah Ali and\nNiesen (and its improved version by Yu et al) and the coded prefetching scheme\nproposed by Tian and Chen. A critical observation is first given where a coding\ncomponent in the Tian-Chen scheme can be replaced by a binary .code, which\nenables us to view the two schemes as the extremes of a more general scheme. An\nexplicit example is given to show that the intermediate operating points of\nthis general scheme can in fact provide new memory-rate tradeoff points\npreviously not known to be achievable in the literature. This new general\ncoding scheme is then presented and analyzed rigorously, which yields a new\ninner bound to the memory-rate tradeoff for the caching problem. \n\n"}
{"id": "1705.00763", "contents": "Title: Improved Bounds for Universal One-Bit Compressive Sensing Abstract: Unlike compressive sensing where the measurement outputs are assumed to be\nreal-valued and have infinite precision, in \"one-bit compressive sensing\",\nmeasurements are quantized to one bit, their signs. In this work, we show how\nto recover the support of sparse high-dimensional vectors in the one-bit\ncompressive sensing framework with an asymptotically near-optimal number of\nmeasurements. We also improve the bounds on the number of measurements for\napproximately recovering vectors from one-bit compressive sensing measurements.\nOur results are universal, namely the same measurement scheme works\nsimultaneously for all sparse vectors.\n  Our proof of optimality for support recovery is obtained by showing an\nequivalence between the task of support recovery using 1-bit compressive\nsensing and a well-studied combinatorial object known as Union Free Families. \n\n"}
{"id": "1705.01213", "contents": "Title: Informative and misinformative interactions in a school of fish Abstract: It is generally accepted that, when moving in groups, animals process\ninformation to coordinate their motion. Recent studies have begun to apply\nrigorous methods based on Information Theory to quantify such distributed\ncomputation. Following this perspective, we use transfer entropy to quantify\ndynamic information flows locally in space and time across a school of fish\nduring directional changes around a circular tank, i.e. U-turns. This analysis\nreveals peaks in information flows during collective U-turns and identifies two\ndifferent flows: an informative flow (positive transfer entropy) based on fish\nthat have already turned about fish that are turning, and a misinformative flow\n(negative transfer entropy) based on fish that have not turned yet about fish\nthat are turning. We also reveal that the information flows are related to\nrelative position and alignment between fish, and identify spatial patterns of\ninformation and misinformation cascades. This study offers several\nmethodological contributions and we expect further application of these\nmethodologies to reveal intricacies of self-organisation in other animal groups\nand active matter in general. \n\n"}
{"id": "1705.01394", "contents": "Title: A Characterization of the Shannon Ordering of Communication Channels Abstract: The ordering of communication channels was first introduced by Shannon. In\nthis paper, we aim to find a characterization of the Shannon ordering. We show\nthat $W'$ contains $W$ if and only if $W$ is the skew-composition of $W'$ with\na convex-product channel. This fact is used to derive a characterization of the\nShannon ordering that is similar to the Blackwell-Sherman-Stein theorem. Two\nchannels are said to be Shannon-equivalent if each one is contained in the\nother. We investigate the topologies that can be constructed on the space of\nShannon-equivalent channels. We introduce the strong topology and the BRM\nmetric on this space. Finally, we study the continuity of a few channel\nparameters and operations under the strong topology. \n\n"}
{"id": "1705.03186", "contents": "Title: Private Information Retrieval from MDS Coded Databases with Colluding\n  Servers under Several Variant Models Abstract: Private information retrieval (PIR) gets renewed attentions due to its\ninformation-theoretic reformulation and its application in distributed storage\nsystem (DSS). The general PIR model considers a coded database containing $N$\nservers storing $M$ files. Each file is stored independently via the same\narbitrary $(N,K)$-MDS code. A user wants to retrieve a specific file from the\ndatabase privately against an arbitrary set of $T$ colluding servers. A key\nproblem is to analyze the PIR capacity, defined as the maximal number of bits\nprivately retrieved per one downloaded bit. Several extensions for the general\nmodel appear by bringing in various additional constraints. In this paper, we\npropose a general PIR scheme for several variant PIR models including: PIR with\nrobust servers, PIR with Byzantine servers, the multi-file PIR model and PIR\nwith arbitrary collusion patterns. \n\n"}
{"id": "1705.04048", "contents": "Title: Phaseless compressive sensing using partial support information Abstract: We study the recovery conditions of weighted $\\ell_1$ minimization for\nreal-valued signal reconstruction from phaseless compressive sensing\nmeasurements when partial support information is available. A strong restricted\nisometry property condition is provided to ensure the stable recovery.\nMoreover, we present the weighted null space property as the sufficient and\nnecessary condition for the success of $k$-sparse phaseless recovery via\nweighted $\\ell_1$ minimization. Numerical experiments are conducted to\nillustrate our results. \n\n"}
{"id": "1705.06891", "contents": "Title: Energy-Efficient Resource Allocation for Elastic Optical Networks using\n  Convex Optimization Abstract: We propose a two-stage algorithm for energy-efficient resource allocation\nconstrained to QoS and physical requirements in OFDM-based EONs. The first\nstage deals with routing, grooming and traffic ordering and aims at minimizing\namplifier power consumption and number of active transponders. We provide a\nheuristic procedure which yields an acceptable solution for the complex ILP\nformulation of the routing and grooming. In the second stage, we optimize\ntransponder configuration including spectrum and transmit power parameters to\nminimize transponder power consumption. We show how QoS and transponder power\nconsumption are represented by convex expressions and use the results to\nformulate a convex problem for configuring transponders in which transmit\noptical power is an optimization variable. Simulation results demonstrate that\nthe power consumption is reduced by 9% when the proposed routing and grooming\nalgorithm is applied to European Cost239 network with aggregate traffic 60\nTbps. It is shown that our convex formulation for transponder parameter\nassignment is considerably faster than its MINLP counterpart and its ability to\noptimize transmit optical power improves transponder power consumption by 8%\nfor aggregate traffic 60 Tbps. Furthermore, we investigate the effect of\nadaptive modulation assignment and transponder capacity on inherent tradeoff\nbetween network CAPEX and OPEX. \n\n"}
{"id": "1705.08808", "contents": "Title: Friendship and Selfishness Forwarding: applying machine learning\n  techniques to Opportunistic Networks data forwarding Abstract: Opportunistic networks could become the solution to provide communication\nsupport in both cities where the cellular network could be overloaded, and in\nscenarios where a fixed infrastructure is not available, like in remote and\ndeveloping regions. A critical issue that still requires a satisfactory\nsolution is the design of an efficient data delivery solution. Social\ncharacteristics are recently being considered as a promising alternative. Most\nopportunistic network applications rely on the different mobile devices carried\nby users, and whose behavior affects the use of the device itself.\n  This work presents the \"Friendship and Selfishness Forwarding\" (FSF)\nalgorithm. FSF analyses two aspects to make message forwarding decisions when a\ncontact opportunity arises: First, it classifies the friendship strength among\na pair of nodes by using a machine learning algorithm to quantify the\nfriendship strength among pairs of nodes in the network. Next, FSF assesses the\nrelay node selfishness to consider those cases in which, despite a strong\nfriendship with the destination, the relay node may not accept to receive the\nmessage because it is behaving selfishly, or because its device has resource\nconstraints in that moment.\n  By using trace-driven simulations through the ONE simulator, we show that the\nFSF algorithm outperforms previously proposed schemes in terms of delivery\nrate, average cost, and efficiency. \n\n"}
{"id": "1705.08948", "contents": "Title: Provable Dynamic Robust PCA or Robust Subspace Tracking Abstract: Dynamic robust PCA refers to the dynamic (time-varying) extension of robust\nPCA (RPCA). It assumes that the true (uncorrupted) data lies in a\nlow-dimensional subspace that can change with time, albeit slowly. The goal is\nto track this changing subspace over time in the presence of sparse outliers.\nWe develop and study a novel algorithm, that we call simple-ReProCS, based on\nthe recently introduced Recursive Projected Compressive Sensing (ReProCS)\nframework. Our work provides the first guarantee for dynamic RPCA that holds\nunder weakened versions of standard RPCA assumptions, slow subspace change and\na lower bound assumption on most outlier magnitudes. Our result is significant\nbecause (i) it removes the strong assumptions needed by the two previous\ncomplete guarantees for ReProCS-based algorithms; (ii) it shows that it is\npossible to achieve significantly improved outlier tolerance, compared with all\nexisting RPCA or dynamic RPCA solutions by exploiting the above two simple\nextra assumptions; and (iii) it proves that simple-ReProCS is online (after\ninitialization), fast, and, has near-optimal memory complexity. \n\n"}
{"id": "1705.09373", "contents": "Title: Capacity Scaling of Cellular Networks: Impact of Bandwidth,\n  Infrastructure Density and Number of Antennas Abstract: The availability of very wide spectrum in millimeter wave bands combined with\nlarge antenna arrays and ultra dense networks raises two basic questions: What\nis the true value of overly abundant degrees of freedom and how can networks be\ndesigned to fully exploit them? This paper determines the capacity scaling of\nlarge cellular networks as a function of bandwidth, area, number of antennas\nand base station density. It is found that the network capacity has a\nfundamental bandwidth scaling limit, beyond which the network becomes\npower-limited. An infrastructure multi-hop protocol achieves the optimal\nnetwork capacity scaling for all network parameters. In contrast, current\nprotocols that use only single-hop direct transmissions can not achieve the\ncapacity scaling in wideband regimes except in the special case when the\ndensity of base stations is taken to impractical extremes. This finding\nsuggests that multi-hop communication will be important to fully realize the\npotential of next-generation cellular networks. Dedicated relays, if\nsufficiently dense, can also perform this task, relieving user nodes from the\nbattery drain of cooperation. On the other hand, more sophisticated strategies\nsuch as hierarchical cooperation, that are essential for achieving capacity\nscaling in ad hoc networks, are unnecessary in the cellular context. \n\n"}
{"id": "1705.09378", "contents": "Title: Analog Beam Tracking in Linear Antenna Arrays: Convergence, Optimality,\n  and Performance Abstract: The directionality of millimeter-wave (mmWave) communications creates a\nsignificant challenge in serving fast-moving mobile terminals on, e.g.,\nhigh-speed vehicles, trains, and UAVs. This challenge is exacerbated in mmWave\nsystems using analog antenna arrays, because of the inherent non-convexity in\nthe control of the phase shifters. In this paper, we develop a recursive beam\ntracking algorithm which can simultaneously achieve fast tracking speed, high\ntracking accuracy, low complexity, and low pilot overhead. In static scenarios,\nthis algorithm converges to the minimum Cram\\'er-Rao lower bound (CRLB) of beam\ntracking with high probability. In dynamic scenarios, even at SNRs as low as\n0dB, our algorithm is capable of tracking a mobile moving randomly at an\nabsolute angular velocity of 10-20 degrees per second, using only 5 pilot\nsymbols per second. If combining with a simple TDMA pilot pattern, this\nalgorithm can track hundreds of high-speed mobiles in 5G configurations. Our\nsimulations show that the tracking performance of this algorithm is much better\nthan several state-of-the-art algorithms. \n\n"}
{"id": "1705.10305", "contents": "Title: Near Optimal Online Distortion Minimization for Energy Harvesting Nodes Abstract: We consider online scheduling for an energy harvesting communication system\nwhere a sensor node collects samples from a Gaussian source and sends them to a\ndestination node over a Gaussian channel. The sensor is equipped with a\nfinite-sized battery that is recharged by an independent and identically\ndistributed (i.i.d.) energy harvesting process over time. The goal is to\nminimize the long term average distortion of the source samples received at the\ndestination. We study two problems: the first is when sampling is cost-free,\nand the second is when there is a sampling cost incurred whenever samples are\ncollected. We show that fixed fraction policies [Shaviv-Ozgur], in which a\nfixed fraction of the battery state is consumed in each time slot, are\nnear-optimal in the sense that they achieve a long term average distortion that\nlies within a constant additive gap from the optimal solution for all energy\narrivals and battery sizes. For the problem with sampling costs, the\ntransmission policy is bursty; the sensor can collect samples and transmit for\nonly a portion of the time. \n\n"}
{"id": "1706.00362", "contents": "Title: More new classes of permutation trinomials over $\\mathbb{F}_{2^n}$ Abstract: Permutation polynomials over finite fields have wide applications in many\nareas of science and engineering. In this paper, we present six new classes of\npermutation trinomials over $\\mathbb{F}_{2^n}$ which have explicit forms by\ndetermining the solutions of some equations. \n\n"}
{"id": "1706.00440", "contents": "Title: The conditional Entropy Power Inequality for bosonic quantum systems Abstract: We prove the conditional Entropy Power Inequality for Gaussian quantum\nsystems. This fundamental inequality determines the minimum quantum conditional\nvon Neumann entropy of the output of the beam-splitter or of the squeezing\namong all the input states where the two inputs are conditionally independent\ngiven the memory and have given quantum conditional entropies. We also prove\nthat, for any couple of values of the quantum conditional entropies of the two\ninputs, the minimum of the quantum conditional entropy of the output given by\nthe conditional Entropy Power Inequality is asymptotically achieved by a\nsuitable sequence of quantum Gaussian input states. Our proof of the\nconditional Entropy Power Inequality is based on a new Stam inequality for the\nquantum conditional Fisher information and on the determination of the\nuniversal asymptotic behaviour of the quantum conditional entropy under the\nheat semigroup evolution. The beam-splitter and the squeezing are the central\nelements of quantum optics, and can model the attenuation, the amplification\nand the noise of electromagnetic signals. This conditional Entropy Power\nInequality will have a strong impact in quantum information and quantum\ncryptography. Among its many possible applications there is the proof of a new\nuncertainty relation for the conditional Wehrl entropy. \n\n"}
{"id": "1706.00752", "contents": "Title: Double-Edge Factor Graphs: Definition, Properties, and Examples Abstract: Some of the most interesting quantities associated with a factor graph are\nits marginals and its partition sum. For factor graphs \\emph{without cycles}\nand moderate message update complexities, the sum-product algorithm (SPA) can\nbe used to efficiently compute these quantities exactly. Moreover, for various\nclasses of factor graphs \\emph{with cycles}, the SPA has been successfully\napplied to efficiently compute good approximations to these quantities. Note\nthat in the case of factor graphs with cycles, the local functions are usually\nnon-negative real-valued functions. In this paper we introduce a class of\nfactor graphs, called double-edge factor graphs (DE-FGs), which allow local\nfunctions to be complex-valued and only require them, in some suitable sense,\nto be positive semi-definite. We discuss various properties of the SPA when\nrunning it on DE-FGs and we show promising numerical results for various\nexample DE-FGs, some of which have connections to quantum information\nprocessing. \n\n"}
{"id": "1706.01442", "contents": "Title: The Capacity of Private Information Retrieval from Byzantine and\n  Colluding Databases Abstract: We consider the problem of single-round private information retrieval (PIR)\nfrom $N$ replicated databases. We consider the case when $B$ databases are\noutdated (unsynchronized), or even worse, adversarial (Byzantine), and\ntherefore, can return incorrect answers. In the PIR problem with Byzantine\ndatabases (BPIR), a user wishes to retrieve a specific message from a set of\n$M$ messages with zero-error, irrespective of the actions performed by the\nByzantine databases. We consider the $T$-privacy constraint in this paper,\nwhere any $T$ databases can collude, and exchange the queries submitted by the\nuser. We derive the information-theoretic capacity of this problem, which is\nthe maximum number of \\emph{correct symbols} that can be retrieved privately\n(under the $T$-privacy constraint) for every symbol of the downloaded data. We\ndetermine the exact BPIR capacity to be\n$C=\\frac{N-2B}{N}\\cdot\\frac{1-\\frac{T}{N-2B}}{1-(\\frac{T}{N-2B})^M}$, if $2B+T\n< N$. This capacity expression shows that the effect of Byzantine databases on\nthe retrieval rate is equivalent to removing $2B$ databases from the system,\nwith a penalty factor of $\\frac{N-2B}{N}$, which signifies that even though the\nnumber of databases needed for PIR is effectively $N-2B$, the user still needs\nto access the entire $N$ databases. The result shows that for the\nunsynchronized PIR problem, if the user does not have any knowledge about the\nfraction of the messages that are mis-synchronized, the single-round capacity\nis the same as the BPIR capacity. Our achievable scheme extends the optimal\nachievable scheme for the robust PIR (RPIR) problem to correct the\n\\emph{errors} introduced by the Byzantine databases as opposed to\n\\emph{erasures} in the RPIR problem. Our converse proof uses the idea of the\ncut-set bound in the network coding problem against adversarial nodes. \n\n"}
{"id": "1706.03353", "contents": "Title: Fast structure learning with modular regularization Abstract: Estimating graphical model structure from high-dimensional and undersampled\ndata is a fundamental problem in many scientific fields. Existing approaches,\nsuch as GLASSO, latent variable GLASSO, and latent tree models, suffer from\nhigh computational complexity and may impose unrealistic sparsity priors in\nsome cases. We introduce a novel method that leverages a newly discovered\nconnection between information-theoretic measures and structured latent factor\nmodels to derive an optimization objective which encourages modular structures\nwhere each observed variable has a single latent parent. The proposed method\nhas linear stepwise computational complexity w.r.t. the number of observed\nvariables. Our experiments on synthetic data demonstrate that our approach is\nthe only method that recovers modular structure better as the dimensionality\nincreases. We also use our approach for estimating covariance structure for a\nnumber of real-world datasets and show that it consistently outperforms\nstate-of-the-art estimators at a fraction of the computational cost. Finally,\nwe apply the proposed method to high-resolution fMRI data (with more than 10^5\nvoxels) and show that it is capable of extracting meaningful patterns. \n\n"}
{"id": "1706.06364", "contents": "Title: Lattice Codes for Physical Layer Communications Abstract: Lattices are deceptively simple mathematical structures that have become\nindispensable for code design for physical layer communications. While\nlattice-related problems are interesting in their own right, the usefulness of\nthese discrete structures in wireless communications provides additional\nmotivation for their study and enables a multidisciplinary line of research.\n  This thesis is devoted to the study of lattice code design for physical layer\ncommunications. Modern wireless communication networks are required to\naccommodate significantly varied types of mobile devices, differing in\navailable computational power or number of equipped antennas. Additionally, the\ndensity of the networks increases rapidly, and many communication protocols\ndiverge from the classical direct point-to-point transmission in favor of\nallowing for intermediate relays to process and forward data. An important\nconsequence of this shift towards more sophisticated transmission protocols is\nthat traditional well-performing codes become futile for modern communications,\nthus the study and development of novel codes is called for.\n  Yet, however involved a transmission protocol may be, the characteristics of\nthe physical medium, i.e., the wireless channel, stay unaffected. It is thus\nnatural that an underlying lattice structure for code design remains crucial.\nThis thesis consists of several articles considering lattice code design for\nfour different communication settings relevant in modern wireless\ncommunications. \n\n"}
{"id": "1706.07582", "contents": "Title: Fundamental Limits of Universal Variable-to-Fixed Length Coding of\n  Parametric Sources Abstract: Universal variable-to-fixed (V-F) length coding of $d$-dimensional\nexponential family of distributions is considered. We propose an achievable\nscheme consisting of a dictionary, used to parse the source output stream,\nmaking use of the previously-introduced notion of quantized types. The\nquantized type class of a sequence is based on partitioning the space of\nminimal sufficient statistics into cuboids. Our proposed dictionary consists of\nsequences in the boundaries of transition from low to high quantized type class\nsize. We derive the asymptotics of the $\\epsilon$-coding rate of our coding\nscheme for large enough dictionaries. In particular, we show that the\nthird-order coding rate of our scheme is $H\\frac{d}{2}\\frac{\\log\\log M}{\\log\nM}$, where $H$ is the entropy of the source and $M$ is the dictionary size. We\nfurther provide a converse, showing that this rate is optimal up to the\nthird-order term. \n\n"}
{"id": "1707.00421", "contents": "Title: On Binary Matroid Minors and Applications to Data Storage over Small\n  Fields Abstract: Locally repairable codes for distributed storage systems have gained a lot of\ninterest recently, and various constructions can be found in the literature.\nHowever, most of the constructions result in either large field sizes and hence\ntoo high computational complexity for practical implementation, or in low rates\ntranslating into waste of the available storage space. In this paper we address\nthis issue by developing theory towards code existence and design over a given\nfield. This is done via exploiting recently established connections between\nlinear locally repairable codes and matroids, and using matroid-theoretic\ncharacterisations of linearity over small fields. In particular, nonexistence\ncan be shown by finding certain forbidden uniform minors within the lattice of\ncyclic flats. It is shown that the lattice of cyclic flats of binary matroids\nhave additional structure that significantly restricts the possible locality\nproperties of $\\mathbb{F}_{2}$-linear storage codes. Moreover, a collection of\ncriteria for detecting uniform minors from the lattice of cyclic flats of a\ngiven matroid is given, which is interesting in its own right. \n\n"}
{"id": "1707.00808", "contents": "Title: Deconvolution of Point Sources: A Sampling Theorem and Robustness\n  Guarantees Abstract: In this work we analyze a convex-programming method for estimating\nsuperpositions of point sources or spikes from nonuniform samples of their\nconvolution with a known kernel. We consider a one-dimensional model where the\nkernel is either a Gaussian function or a Ricker wavelet, inspired by\napplications in geophysics and imaging. Our analysis establishes that\nminimizing a continuous counterpart of the $\\ell_1$ norm achieves exact\nrecovery of the original spikes as long as (1) the signal support satisfies a\nminimum-separation condition and (2) there are at least two samples close to\nevery spike. In addition, we derive theoretical guarantees on the robustness of\nthe approach to both dense and sparse additive noise. \n\n"}
{"id": "1707.01858", "contents": "Title: Packings in real projective spaces Abstract: This paper applies techniques from algebraic and differential geometry to\ndetermine how to best pack points in real projective spaces. We present a\ncomputer-assisted proof of the optimality of a particular 6-packing in\n$\\mathbb{R}\\mathbf{P}^3$, we introduce a linear-time constant-factor\napproximation algorithm for packing in the so-called Gerzon range, and we\nprovide local optimality certificates for two infinite families of packings.\nFinally, we present perfected versions of various putatively optimal packings\nfrom Sloane's online database, along with a handful of infinite families they\nsuggest, and we prove that these packings enjoy a certain weak notion of\noptimality. \n\n"}
{"id": "1707.02152", "contents": "Title: Secure Symmetric Private Information Retrieval from Colluding Databases\n  with Adversaries Abstract: The problem of symmetric private information retrieval (SPIR) from replicated\ndatabases with colluding servers and adversaries is studied. Specifically, the\ndatabase comprises $K$ files, which are replicatively stored among $N$ servers.\nA user wants to retrieve one file from the database by communicating with the\n$N$ servers, without revealing the identity of the desired file to any server.\nFurthermore, the user shall learn nothing about the other $K-1$ files. Any $T$\nout of $N$ servers may collude, that is, they may communicate their\ninteractions with the user to guess the identity of the requested file. An\nadversary in the system can tap in on or even try to corrupt the communication.\nThree types of adversaries are considered: a Byzantine adversary who can\noverwrite the transmission of any $B$ servers to the user; a passive\neavesdropper who can tap in on the incoming and outgoing transmissions of any\n$E$ servers; and a combination of both -- an adversary who can tap in on a set\nof any $E$ nodes, and overwrite the transmission of a set of any $B$ nodes. The\nproblems of SPIR with colluding servers and the three types of adversaries are\nnamed T-BSPIR, T-ESPIR and T-BESPIR respectively. The capacity of the problem\nis defined as the maximum number of information bits of the desired file\nretrieved per downloaded bit. We show that the information-theoretical capacity\nof T-BSPIR equals $1-\\frac{2B+T}{N}$, if the servers share common randomness\n(unavailable at the user) with amount at least $\\frac{2B+T}{N-2B-T}$ times the\nfile size. Otherwise, the capacity equals zero. The capacity of T-ESPIR is\nproved to equal $1-\\frac{\\max(T,E)}{N}$, with common randomness at least\n$\\frac{\\max(T,E)}{N-\\max(T,E)}$ times the file size. Finally, the capacity of\nT-BESPIR is proved to be $1-\\frac{2B+\\max(T,E)}{N}$, with common randomness at\nleast $\\frac{2B+\\max(T,E)}{N-2B-\\max(T,E)}$ times the file size. \n\n"}
{"id": "1707.04282", "contents": "Title: Polynomial Counting in Anonymous Dynamic Networks with Applications to\n  Anonymous Dynamic Algebraic Computations Abstract: Starting with Michail, Chatzigiannakis, and Spirakis work, the problem of\nCounting the number of nodes in Anonymous Dynamic Networks has attracted a lot\nof attention. The problem is challenging because nodes are indistinguishable\n(they lack identifiers and execute the same program) and the topology may\nchange arbitrarily from round to round of communication, as long as the network\nis connected in each round. The problem is central in distributed computing as\nthe number of participants is frequently needed to make important decisions,\nsuch as termination, agreement, synchronization, and many others. A variety of\nalgorithms built on top of mass-distribution techniques have been presented,\nanalyzed, and also experimentally evaluated; some of them assumed additional\nknowledge of network characteristics, such as bounded degree or given upper\nbound on the network size. However, the question of whether Counting can be\nsolved deterministically in sub-exponential time remained open. In this work,\nwe answer this question positively by presenting Methodical Counting, which\nruns in polynomial time and requires no knowledge of network characteristics.\nMoreover, we also show how to extend Methodical Counting to compute the sum of\ninput values and more complex functions without extra cost. Our analysis\nleverages previous work on random walks in evolving graphs, combined with\ncarefully chosen alarms in the algorithm that control the process and its\nparameters. To the best of our knowledge, our Counting algorithm and its\nextensions to other algebraic and Boolean functions are the first that can be\nimplemented in practice with worst-case guarantees. \n\n"}
{"id": "1707.08203", "contents": "Title: Positioning for Visible Light Communication System Exploiting Multipath\n  Reflections Abstract: In this paper, we introduce a new uplink visible light indoor positioning\nsystem that estimates the position of the users in the network-side of a\nvisible light communications (VLC) system. This technique takes advantage of\nthe diffuse components of the uplink channel impulse response for positioning,\nwhich has been considered as a destructive noise in existing visible light\ncommunication positioning literature. Exploiting the line of sight (LOS)\ncomponent, the most significant diffusive component of the channel (the second\npower peak (SPP)), and the delay time between LOS and SPP, we present a proof\nof concept analysis for positioning using fixed reference points, i.e. uplink\nphotodetectors (PDs). Simulation results show the root mean square (RMS)\npositioning accuracy of 25 cm and 5 cm for one and 4 PDs scenarios,\nrespectively. \n\n"}
{"id": "1707.09108", "contents": "Title: Ensemble Performance of Biometric Authentication Systems Based on Secret\n  Key Generation Abstract: We study the ensemble performance of biometric authentication systems, based\non secret key generation, which work as follows. In the enrollment stage, an\nindividual provides a biometric signal that is mapped into a secret key and a\nhelper message, the former being prepared to become available to the system at\na later time (for authentication), and the latter is stored in a public\ndatabase. When an authorized user requests authentication, claiming his/her\nidentity as one of the subscribers, s/he has to provide a biometric signal\nagain, and then the system, which retrieves also the helper message of the\nclaimed subscriber, produces an estimate of the secret key, that is finally\ncompared to the secret key of the claimed user. In case of a match, the\nauthentication request is approved, otherwise, it is rejected.Referring to an\nensemble of systems based on Slepian-Wolf binning, we provide a detailed\nanalysis of the false-reject and false-accept probabilities, for a wide class\nof stochastic decoders. We also comment on the security for the typical code in\nthe ensemble. \n\n"}
{"id": "1707.09916", "contents": "Title: Robust Private Information Retrieval on Coded Data Abstract: We consider the problem of designing PIR scheme on coded data when certain\nnodes are unresponsive. We provide the construction of $\\nu$-robust PIR schemes\nthat can tolerate up to $\\nu$ unresponsive nodes. These schemes are adaptive\nand universally optimal in the sense of achieving (asymptotically) optimal\ndownload cost for any number of unresponsive nodes up to $\\nu$. \n\n"}
{"id": "1708.03495", "contents": "Title: Algorithms based on *-algebras, and their applications to isomorphism of\n  polynomials with one secret, group isomorphism, and polynomial identity\n  testing Abstract: We consider two basic algorithmic problems concerning tuples of\n(skew-)symmetric matrices. The first problem asks to decide, given two tuples\nof (skew-)symmetric matrices $(B_1, \\dots, B_m)$ and $(C_1, \\dots, C_m)$,\nwhether there exists an invertible matrix $A$ such that for every $i\\in\\{1,\n\\dots, m\\}$, $A^tB_iA=C_i$. We show that this problem can be solved in\nrandomized polynomial time over finite fields of odd size, the real field, and\nthe complex field. The second problem asks to decide, given a tuple of square\nmatrices $(B_1, \\dots, B_m)$, whether there exist invertible matrices $A$ and\n$D$, such that for every $i\\in\\{1, \\dots, m\\}$, $AB_iD$ is (skew-)symmetric. We\nshow that this problem can be solved in deterministic polynomial time over\nfields of characteristic not $2$. For both problems we exploit the structure of\nthe underlying $*$-algebras, and utilize results and methods from the module\nisomorphism problem.\n  Applications of our results range from multivariate cryptography, group\nisomorphism, to polynomial identity testing. Specifically, these results imply\nefficient algorithms for the following problems. (1) Test isomorphism of\nquadratic forms with one secret over a finite field of odd size. This problem\nbelongs to a family of problems that serves as the security basis of certain\nauthentication schemes proposed by Patarin (Eurocrypto 1996). (2) Test\nisomorphism of $p$-groups of class 2 and exponent $p$ ($p$ odd) with order\n$p^k$ in time polynomial in the group order, when the commutator subgroup is of\norder $p^{O(\\sqrt{k})}$. (3) Deterministically reveal two families of\nsingularity witnesses caused by the skew-symmetric structure, which represents\na natural next step for the polynomial identity testing problem following the\ndirection set up by the recent resolution of the non-commutative rank problem\n(Garg et al., FOCS 2016; Ivanyos et al., ITCS 2017). \n\n"}
{"id": "1708.03895", "contents": "Title: Local Large deviations for empirical locality measure of typed Random\n  Graph Models Abstract: In this article, we prove a local large deviation principle (LLDP) for the\nempirical locality measure of typed random networks on $n$ nodes conditioned to\nhave a given \\emph{ empirical type measure} and \\emph{ empirical link measure.}\nFrom the LLDP, we deduce a full large deviation principle for the typed random\ngraph, and the classical Erdos-Renyi graphs, where $nc/2$ links are inserted at\nrandom among $n$ nodes. No topological restrictions are required for these\nresults. \n\n"}
{"id": "1708.04186", "contents": "Title: Boundaries as an Enhancement Technique for Physical Layer Security Abstract: In this paper, we study the receiver performance with physical layer security\nin a Poisson field of interferers. We compare the performance in two deployment\nscenarios: (i) the receiver is located at the corner of a quadrant, (ii) the\nreceiver is located in the infinite plane. When the channel state information\n(CSI) of the eavesdropper is not available at the transmitter, we calculate the\nprobability of secure connectivity using the Wyner coding scheme, and we show\nthat hiding the receiver at the corner is beneficial at high rates of the\ntransmitted codewords and detrimental at low transmission rates. When the CSI\nis available, we show that the average secrecy capacity is higher when the\nreceiver is located at the corner, even if the intensity of interferers in this\ncase is four times higher than the intensity of interferers in the bulk.\nTherefore boundaries can also be used as a secrecy enhancement technique for\nhigh data rate applications. \n\n"}
{"id": "1708.05478", "contents": "Title: Weight hierarchy of a class of linear codes relating to non-degenerate\n  quadratic forms Abstract: In this paper, we discuss the generalized Hamming weights of a class of\nlinear codes associated with non-degenerate quadratic forms. In order to do so,\nwe study the quadratic forms over subspaces of finite field and obtain some\ninteresting results about subspaces and their dual spaces. On this basis, we\nsolve all the generalized Hamming weights of these linear codes. \n\n"}
{"id": "1708.05673", "contents": "Title: Linear Symmetric Private Information Retrieval for MDS Coded Distributed\n  Storage with Colluding Servers Abstract: The problem of symmetric private information retrieval (SPIR) from a coded\ndatabase which is distributively stored among colluding servers is studied.\nSpecifically, the database comprises $K$ files, which are stored among $N$\nservers using an $(N,M)$-MDS storage code. A user wants to retrieve one file\nfrom the database by communicating with the $N$ servers, without revealing the\nidentity of the desired file to any server. Furthermore, the user shall learn\nnothing about the other $K-1$ files in the database. In the $T$-colluding SPIR\nproblem (hence called TSPIR), any $T$ out of $N$ servers may collude, that is,\nthey may communicate their interactions with the user to guess the identity of\nthe requested file. We show that for linear schemes, the information-theoretic\ncapacity of the MDS-TSPIR problem, defined as the maximum number of information\nbits of the desired file retrieved per downloaded bit, equals\n$1-\\frac{M+T-1}{N}$, if the servers share common randomness (unavailable at the\nuser) with amount at least $\\frac{M+T-1}{N-M-T+1}$ times the file size.\nOtherwise, the capacity equals zero. We conjecture that our capacity holds also\nfor general MDS-TSPIR schemes. \n\n"}
{"id": "1708.05950", "contents": "Title: New extremal singly even self-dual codes of lengths $64$ and $66$ Abstract: For lengths $64$ and $66$, we construct extremal singly even self-dual codes\nwith weight enumerators for which no extremal singly even self-dual codes were\npreviously known to exist. We also construct new $40$ inequivalent extremal\ndoubly even self-dual $[64,32,12]$ codes with covering radius $12$ meeting the\nDelsarte bound. \n\n"}
{"id": "1708.06298", "contents": "Title: Bounds on absolutely maximally entangled states from shadow\n  inequalities, and the quantum MacWilliams identity Abstract: A pure multipartite quantum state is called absolutely maximally entangled\n(AME), if all reductions obtained by tracing out at least half of its parties\nare maximally mixed. Maximal entanglement is then present across every\nbipartition. The existence of such states is in many cases unclear. With the\nhelp of the weight enumerator machinery known from quantum error correction and\nthe generalized shadow inequalities, we obtain new bounds on the existence of\nAME states in dimensions larger than two. To complete the treatment on the\nweight enumerator machinery, the quantum MacWilliams identity is derived in the\nBloch representation. Finally, we consider AME states whose subsystems have\ndifferent local dimensions, and present an example for a $2 \\times3 \\times 3\n\\times 3$ system that shows maximal entanglement across every bipartition. \n\n"}
{"id": "1708.07548", "contents": "Title: Audio signal encryption using chaotic H\\'enon map and lifting wavelet\n  transforms Abstract: We propose a new audio signal encryption scheme based on the chaotic H\\'enon\nmap. The scheme mainly comprises two phases: one is the preprocessing stage\nwhere the audio signal is transformed into a data by the lifting wavelet scheme\nand the other in which the transformed data is encrypted by chaotic data set\nand hyperbolic functions. Furthermore, we use dynamic keys and consider the key\nspace size to be large enough to resist any kind of cryptographic attacks. A\nstatistical investigation is also made to test the security and the efficiency\nof the proposed scheme. \n\n"}
{"id": "1708.08100", "contents": "Title: Plain stopping time and conditional complexities revisited Abstract: In this paper we analyze the notion of \"stopping time complexity\", informally\ndefined as the amount of information needed to specify when to stop while\nreading an infinite sequence. This notion was introduced by Vovk and Pavlovic\n(2016). It turns out that plain stopping time complexity of a binary string $x$\ncould be equivalently defined as (a) the minimal plain complexity of a Turing\nmachine that stops after reading $x$ on a one-directional input tape; (b) the\nminimal plain complexity of an algorithm that enumerates a prefix-free set\ncontaining $x$; (c)~the conditional complexity $C(x|x*)$ where $x$ in the\ncondition is understood as a prefix of an infinite binary sequence while the\nfirst $x$ is understood as a terminated binary string; (d) as a minimal upper\nsemicomputable function $K$ such that each binary sequence has at most $2^n$\nprefixes $z$ such that $K(z)<n$; (e) as $\\max C^X(x)$ where $C^X(z)$ is plain\nKolmogorov complexity of $z$ relative to oracle $X$ and the maximum is taken\nover all extensions $X$ of $x$.\n  We also show that some of these equivalent definitions become non-equivalent\nin the more general setting where the condition $y$ and the object $x$ may\ndiffer. We also answer an open question from Chernov, Hutter and~Schmidhuber. \n\n"}
{"id": "1708.09149", "contents": "Title: Algorithmic Networks: central time to trigger expected emergent\n  open-endedness Abstract: This article investigates emergence and complexity in complex systems that\ncan share information on a network. To this end, we use a theoretical approach\nfrom information theory, computability theory, and complex networks. One key\nstudied question is how much emergent complexity (or information) arises when a\npopulation of computable systems is networked compared with when this\npopulation is isolated. First, we define a general model for networked\ntheoretical machines, which we call algorithmic networks. Then, we narrow our\nscope to investigate algorithmic networks that optimize the average fitnesses\nof nodes in a scenario in which each node imitates the fittest neighbor and the\nrandomly generated population is networked by a time-varying graph. We show\nthat there are graph-topological conditions that cause these algorithmic\nnetworks to have the property of expected emergent open-endedness for large\nenough populations. In other words, the expected emergent algorithmic\ncomplexity of a node tends to infinity as the population size tends to\ninfinity. Given a dynamic network, we show that these conditions imply the\nexistence of a central time to trigger expected emergent open-endedness.\nMoreover, we show that networks with small diameter compared to the network\nsize meet these conditions. We also discuss future research based on how our\nresults are related to some problems in network science, information theory,\ncomputability theory, distributed computing, game theory, evolutionary biology,\nand synergy in complex systems. \n\n"}
{"id": "1708.09517", "contents": "Title: Upper and Lower Bounds on the Capacity of Amplitude-Constrained MIMO\n  Channels Abstract: In this work, novel upper and lower bounds for the capacity of channels with\narbitrary constraints on the support of the channel input symbols are derived.\nAs an immediate practical application, the case of multiple-input\nmultiple-output channels with amplitude constraints is considered. The bounds\nare shown to be within a constant gap if the channel matrix is invertible and\nare tight in the high amplitude regime for arbitrary channel matrices.\nMoreover, in the high amplitude regime, it is shown that the capacity scales\nlinearly with the minimum between the number of transmit and receive antennas,\nsimilarly to the case of average power-constrained inputs. \n\n"}
{"id": "1708.09661", "contents": "Title: Context-aware Cluster Based Device-to-Device Communication to Serve\n  Machine Type Communications Abstract: Billions of Machine Type Communication (MTC) devices are foreseen to be\ndeployed in next ten years and therefore potentially open a new market for next\ngeneration wireless network. However, MTC applications have different\ncharacteristics and requirements compared with the services provided by legacy\ncellular networks. For instance, an MTC device sporadically requires to\ntransmit a small data packet containing information generated by sensors. At\nthe same time, due to the massive deployment of MTC devices, it is inefficient\nto charge their batteries manually and thus a long battery life is required for\nMTC devices. In this sense, legacy networks designed to serve human-driven\ntraffics in real time can not support MTC efficiently. In order to improve the\navailability and battery life of MTC devices, context-aware device-to-device\n(D2D) communication is exploited in this paper. By applying D2D communication,\nsome MTC users can serve as relays for other MTC users who experience bad\nchannel conditions. Moreover, signaling schemes are also designed to enable the\ncollection of context information and support the proposed D2D communication\nscheme. Last but not least, a system level simulator is implemented to evaluate\nthe system performance of the proposed technologies and a large performance\ngain is shown by the numerical results. \n\n"}
{"id": "1708.09827", "contents": "Title: Walking Through Waypoints Abstract: We initiate the study of a fundamental combinatorial problem: Given a\ncapacitated graph $G=(V,E)$, find a shortest walk (\"route\") from a source $s\\in\nV$ to a destination $t\\in V$ that includes all vertices specified by a set\n$\\mathscr{W}\\subseteq V$: the \\emph{waypoints}. This waypoint routing problem\nfinds immediate applications in the context of modern networked distributed\nsystems. Our main contribution is an exact polynomial-time algorithm for graphs\nof bounded treewidth. We also show that if the number of waypoints is\nlogarithmically bounded, exact polynomial-time algorithms exist even for\ngeneral graphs. Our two algorithms provide an almost complete characterization\nof what can be solved exactly in polynomial-time: we show that more general\nproblems (e.g., on grid graphs of maximum degree 3, with slightly more\nwaypoints) are computationally intractable. \n\n"}
{"id": "1709.01317", "contents": "Title: A Unification and Generalization of Exact Distributed First Order\n  Methods Abstract: Recently, there has been significant progress in the development of\ndistributed first order methods. (At least) two different types of methods,\ndesigned from very different perspectives, have been proposed that achieve both\nexact and linear convergence when a constant step size is used -- a favorable\nfeature that was not achievable by most prior methods. In this paper, we unify,\ngeneralize, and improve convergence speed of these exact distributed first\norder methods. We first carry out a novel unifying analysis that sheds light on\nhow the different existing methods compare. The analysis reveals that a major\ndifference between the methods is on how a past dual gradient of an associated\naugmented Lagrangian dual function is weighted. We then capitalize on the\ninsights from the analysis to derive a novel method -- with a tuned past\ngradient weighting -- that improves upon the existing methods. We establish for\nthe proposed generalized method global R-linear convergence rate under strongly\nconvex costs with Lipschitz continuous gradients. \n\n"}
{"id": "1709.01702", "contents": "Title: Wireless Networks for Mobile Edge Computing: Spatial Modeling and\n  Latency Analysis (Extended version) Abstract: Next-generation wireless networks will provide users ubiquitous low-latency\ncomputing services using devices at the network edge, called mobile edge\ncomputing (MEC). The key operation of MEC, mobile computation offloading (MCO),\nis to offload computation intensive tasks from users. Since each edge device\ncomprises an access point (AP) and a computer server (CS), a MEC network can be\ndecomposed as a radio access network (RAN) cascaded with a CS network (CSN).\nBased on the architecture, we investigate network constrained latency\nperformance, namely communication latency (comm-latency) and computation\nlatency (comp-latency) under the constraints of RAN coverage and CSN stability.\nTo this end, a spatial random network is modeled featuring random node\ndistribution, parallel computing, non-orthogonal multiple access, and random\ncomputation-task generation. Given the model and the said network constraints,\nwe derive the scaling laws of comm-latency and comp-latency with respect to\nnetwork-load parameters (density of mobiles and their task-generation rates)\nand network-resource parameters (bandwidth, density of APs/CSs, CS computation\nrate). Essentially, the analysis involves the interplay of theories of\nstochastic geometry, queueing, and parallel computing. Combining the derived\nscaling laws quantifies the tradeoffs between the latencies, network coverage\nand network stability. The results provide useful guidelines for MEC-network\nprovisioning and planning by avoiding either of the cascaded RAN or CSN being a\nperformance bottleneck. \n\n"}
{"id": "1709.02950", "contents": "Title: Spectral and Energy Efficiency of Cell-Free Massive MIMO Systems with\n  Hardware Impairments Abstract: Cell-free massive multiple-input multiple-output (MIMO), with a large number\nof distributed access points (APs) that jointly serve the user equipments\n(UEs), is a promising network architecture for future wireless communications.\nTo reduce the cost and power consumption of such systems, it is important to\nutilize low-quality transceiver hardware at the APs. However, the impact of\nhardware impairments on cell-free massive MIMO has thus far not been studied.\nIn this paper, we take a first look at this important topic by utilizing\nwell-established models of hardware distortion and deriving new closed-form\nexpressions for the spectral and energy efficiency. These expressions provide\nimportant insights into the practical impact of hardware impairments and also\nhow to efficiently deploy cell-free systems. Furthermore, a novel\nhardware-quality scaling law is presented. It proves that the impact of\nhardware impairments at the APs vanish as the number of APs grows. Numerical\nresults validate that cell-free massive MIMO systems are inherently resilient\nto hardware impairments. \n\n"}
{"id": "1709.03776", "contents": "Title: Privacy Risk Assessment: From Art to Science, By Metrics Abstract: Privacy risk assessments aim to analyze and quantify the privacy risks\nassociated with new systems. As such, they are critically important in ensuring\nthat adequate privacy protections are built in. However, current methods to\nquantify privacy risk rely heavily on experienced analysts picking the\n\"correct\" risk level on e.g. a five-point scale. In this paper, we argue that a\nmore scientific quantification of privacy risk increases accuracy and\nreliability and can thus make it easier to build privacy-friendly systems. We\ndiscuss how the impact and likelihood of privacy violations can be decomposed\nand quantified, and stress the importance of meaningful metrics and units of\nmeasurement. We suggest a method of quantifying and representing privacy risk\nthat considers a collection of factors as well as a variety of contexts and\nattacker models. We conclude by identifying some of the major research\nquestions to take this approach further in a variety of application scenarios. \n\n"}
{"id": "1709.05172", "contents": "Title: Optimal Base Station Design with Limited Fronthaul: Massive Bandwidth or\n  Massive MIMO? Abstract: To reach a cost-efficient 5G architecture, the use of remote radio heads\nconnected through a fronthaul to baseband controllers is a promising solution.\nHowever, the fronthaul links must support high bit rates as 5G networks are\nprojected to use wide bandwidths and many antennas. Upgrading all of the\nexisting fronthaul connections would be cumbersome, while replacing the remote\nradio head and upgrading the software in the baseband controllers is relatively\nsimple. In this paper, we consider the uplink and seek the answer to the\nquestion: If we have a fixed fronthaul capacity and can deploy any technology\nin the remote radio head, what is the optimal technology? In particular, we\noptimize the number of antennas, quantization bits and bandwidth to maximize\nthe sum rate under a fronthaul capacity constraint. The analytical results\nsuggest that operating with many antennas equipped with low-resolution\nanalog-to-digital converters, while the interplay between number of antennas\nand bandwidth depends on various parameters. The numerical analysis provides\nfurther insights into the design of communication systems with limited\nfronthaul capacity. \n\n"}
{"id": "1709.05710", "contents": "Title: Fine-Grained Endpoint-Driven In-Network Traffic Control for Proactive\n  DDoS Attack Mitigation Abstract: Volumetric attacks, which overwhelm the bandwidth of a destination, are among\nthe most common DDoS attacks today. Despite considerable effort made by both\nresearch and industry, our recent interviews with over 100 potential DDoS\nvictims in over 10 industry segments indicate that today's DDoS prevention is\nfar from perfect. On one hand, few academical proposals have ever been deployed\nin the Internet; on the other hand, solutions offered by existing DDoS\nprevention vendors are not a silver bullet to defend against the entire attack\nspectrum. Guided by such large-scale study of today's DDoS defense, in this\npaper, we present MiddlePolice, the first readily deployable and proactive DDoS\nprevention mechanism. We carefully architect MiddlePolice such that it requires\nno changes from both the Internet core and the network stack of clients,\nyielding instant deployability in the current Internet architecture. Further,\nrelying on our novel capability feedback mechanism, MiddlePolice is able to\nenforce destination-driven traffic control so that it guarantees to deliver\nvictim-desired traffic regardless of the attacker strategies. We implement a\nprototype of MiddlePolice, and demonstrate its feasibility via extensive\nevaluations in the Internet, hardware testbed and large-scale simulations. \n\n"}
{"id": "1709.05733", "contents": "Title: The Stochastic Geometry Analyses of Cellular Networks with\n  {\\alpha}-Stable Self-Similarity Abstract: To understand the spatial deployment of base stations (BSs) is the first step\nto analyze the performance of cellular networks and further design efficient\nnetworking protocols. Poisson point process (PPP), which has been widely\nadopted to characterize the deployment of BSs and established the reputation to\ngive tractable results in the stochastic geometry analyses, usually assumes a\nstatic BS deployment density in homogeneous PPP (HPPP) models or delicately\ndesigned location-dependent density functions in in-homogeneous PPP (IPPP)\nmodels. However, the simultaneous existence of attractiveness and repulsiveness\namong BSs practically deployed in a large-scale area defies such an assumption,\nand the $\\alpha$-stable distribution, one kind of heavy-tailed distributions,\nhas recently demonstrated superior accuracy to statistically model the varying\nBS density in different areas. In this paper, we start with these new findings\nand investigate the intrinsic feature (i.e., the spatial self-similarity)\nembedded in the BSs. Afterwards, we refer to a generalized PPP setup with\n$\\alpha$-stable distributed density and theoretically derive the related\ncoverage probability. In particular, we give an upper bound of the derived\ncoverage probability for high signal-to-interference-plus-noise ratio (SINR)\nthresholds and show the monotonically decreasing property of this bound with\nrespect to the variance of BS density. Besides, we prove that our model could\nreduce to the single-tier HPPP for some special cases, and demonstrate the\nsuperior accuracy of the $\\alpha$-stable model to approach the real\nenvironment. \n\n"}
{"id": "1709.06278", "contents": "Title: Random Caching in Backhaul-Limited Multi-Antenna Networks: Analysis and\n  Area Spectrum Efficiency Optimization Abstract: Caching at base stations is a promising technology to satisfy the increasing\ncapacity requirements and reduce the backhaul loads in future wireless\nnetworks. Careful design of random caching can fully exploit the file\npopularity and achieve good performance. However, previous works on random\ncaching scheme usually assumed single antenna at BSs and users, which is not\nthe case in practical multi-antenna networks. In this paper, we consider the\nanalysis and optimization in the cache-enabled multi-antenna networks with\nlimited backhaul. We first derive a closed-form expression and a simple tight\nupper bound of the successful transmission probability, using tools from\nstochastic geometry and a gamma approximation. Based on the analytic results,\nwe then consider the area spectrum efficiency maximization by optimizing design\nparameters, which is a complicated mixed-integer optimization problem. After\nanalyzing the optimal properties, we obtain a local optimal solution with lower\ncomplexity. To further simplify the optimization, we then solve an asymptotic\noptimization problem in the high user density region, using the upper bound as\nthe objective function. Numerical simulations show that the asymptotic optimal\ncaching scheme achieves better performance over existing caching schemes. The\nanalysis and optimization results provide insightful design guidelines for\nrandom caching in practical networks. \n\n"}
{"id": "1709.06599", "contents": "Title: Unsupervised Machine Learning for Networking: Techniques, Applications\n  and Research Challenges Abstract: While machine learning and artificial intelligence have long been applied in\nnetworking research, the bulk of such works has focused on supervised learning.\nRecently there has been a rising trend of employing unsupervised machine\nlearning using unstructured raw network data to improve network performance and\nprovide services such as traffic engineering, anomaly detection, Internet\ntraffic classification, and quality of service optimization. The interest in\napplying unsupervised learning techniques in networking emerges from their\ngreat success in other fields such as computer vision, natural language\nprocessing, speech recognition, and optimal control (e.g., for developing\nautonomous self-driving cars). Unsupervised learning is interesting since it\ncan unconstrain us from the need of labeled data and manual handcrafted feature\nengineering thereby facilitating flexible, general, and automated methods of\nmachine learning. The focus of this survey paper is to provide an overview of\nthe applications of unsupervised learning in the domain of networking. We\nprovide a comprehensive survey highlighting the recent advancements in\nunsupervised learning techniques and describe their applications for various\nlearning tasks in the context of networking. We also provide a discussion on\nfuture directions and open research issues, while also identifying potential\npitfalls. While a few survey papers focusing on the applications of machine\nlearning in networking have previously been published, a survey of similar\nscope and breadth is missing in literature. Through this paper, we advance the\nstate of knowledge by carefully synthesizing the insights from these survey\npapers while also providing contemporary coverage of recent advances. \n\n"}
{"id": "1709.08718", "contents": "Title: Detecting Censor Detection Abstract: Our goal is to empirically discover how censors react to the introduction of\nnew proxy servers that can be used to circumvent their information controls. We\nexamine a specific case, that of obfuscated Tor bridges, and conduct\nexperiments designed to discover how long it takes censors to block them (if\nthey do block at all). Through a year's worth of active measurements from\nChina, Iran, Kazakhstan, and other countries, we learn when bridges become\nblocked. In China we found the most interesting behavior, including long and\nvarying delays before blocking, frequent failures during which blocked bridges\nbecame reachable, and an advancement in blocking technique midway through the\nexperiment. Throughout, we observed surprising behavior by censors, not in\naccordance with what we would have predicted, calling into question our\nassumptions and suggesting potential untapped avenues for circumvention. \n\n"}
{"id": "1709.10000", "contents": "Title: Using Blockchain and smart contracts for secure data provenance\n  management Abstract: Blockchain technology has evolved from being an immutable ledger of\ntransactions for cryptocurrencies to a programmable interactive the environment\nfor building distributed reliable applications. Although, blockchain technology\nhas been used to address various challenges, to our knowledge none of the\nprevious work focused on using blockchain to develop a secure and immutable\nscientific data provenance management framework that automatically verifies the\nprovenance records. In this work, we leverage blockchain as a platform to\nfacilitate trustworthy data provenance collection, verification, and\nmanagement. The developed system utilizes smart contracts and open provenance\nmodel (OPM) to record immutable data trails. We show that our proposed\nframework can efficiently and securely capture and validate provenance data,\nand prevent any malicious modification to the captured data as long as the\nmajority of the participants are honest. \n\n"}
{"id": "1709.10119", "contents": "Title: Distributed Join-the-Idle-Queue for Low Latency Cloud Services Abstract: Low latency is highly desirable for cloud services. To achieve low response\ntime, stringent timing requirements are needed for task scheduling in a\nlarge-scale server farm spanning thousands of servers. In this paper, we\nconduct an in-depth analysis for distributed Join-the-Idle-Queue (JIQ), a\npromising new approximation of an idealized task-scheduling algorithm. In\nparticular, we derive semi-closed form expressions for the delay performance of\ndistributed JIQ, and we propose a new variant of distributed JIQ that offers\nclear advantages over alternative algorithms for large systems. \n\n"}
{"id": "1710.00196", "contents": "Title: New binary and ternary LCD codes Abstract: LCD codes are linear codes with important cryptographic applications.\nRecently, a method has been presented to transform any linear code into an LCD\ncode with the same parameters when it is supported on a finite field with\ncardinality larger than 3. Hence, the study of LCD codes is mainly open for\nbinary and ternary fields. Subfield-subcodes of $J$-affine variety codes are a\ngeneralization of BCH codes which have been successfully used for constructing\ngood quantum codes. We describe binary and ternary LCD codes constructed as\nsubfield-subcodes of $J$-affine variety codes and provide some new and good LCD\ncodes coming from this construction. \n\n"}
{"id": "1710.00395", "contents": "Title: Channel Hardening and Favorable Propagation in Cell-Free Massive MIMO\n  with Stochastic Geometry Abstract: Cell-Free (CF) Massive MIMO is an alternative topology for future wireless\nnetworks, where a large number of single-antenna access points (APs) are\ndistributed over the coverage area. There are no cells but all users are\njointly served by the APs using network MIMO methods. Prior works have claimed\nthat CF Massive MIMO inherits the basic properties of cellular Massive MIMO,\nnamely channel hardening and favorable propagation. In this paper, we evaluate\nif one can rely on these properties when having a realistic stochastic AP\ndeployment. Our results show that channel hardening only appears in special\ncases, for example, when the pathloss exponent is small. However, by using\n5--10 antennas per AP, instead of one, we can substantially improve the\nhardening. Only spatially well-separated users will exhibit favorable\npropagation, but when adding more antennas and/or reducing the pathloss\nexponent, it becomes more likely for favorable propagation to occur. The\nconclusion is that we cannot rely on channel hardening and favorable\npropagation when analyzing and designing CF Massive MIMO networks, but we need\nto use achievable rate expressions and resource allocation schemes that work\nwell also in the absence of these properties. Some options are reviewed in this\npaper. \n\n"}
{"id": "1710.00812", "contents": "Title: Entropy Inequalities for Sums in Prime Cyclic Groups Abstract: Lower bounds for the R\\'enyi entropies of sums of independent random\nvariables taking values in cyclic groups of prime order under permutations are\nestablished. The main ingredients of our approach are extended rearrangement\ninequalities in prime cyclic groups building on Lev (2001), and notions of\nstochastic ordering. Several applications are developed, including to discrete\nentropy power inequalities, the Littlewood-Offord problem, and counting\nsolutions of certain linear systems. \n\n"}
{"id": "1710.01874", "contents": "Title: Efficiently repairing algebraic geometry codes Abstract: Minimum storage regenerating codes have minimum storage of data in each node\nand therefore are maximal distance separable (MDS for short) codes. Thus, the\nnumber of nodes is upper bounded by $2^{\\fb}$, where $\\fb$ is the bits of data\nstored in each node. From both theoretical and practical points of view (see\nthe details in Section 1), it is natural to consider regenerating codes that\nnearly have minimum storage of data, and meanwhile the number of nodes is\nunbounded. One of the candidates for such regenerating codes is an algebraic\ngeometry code. In this paper, we generalize the repairing algorithm of\nReed-Solomon codes given in \\cite[STOC2016]{GW16} to algebraic geometry codes\nand present an efficient repairing algorithm for arbitrary one-point algebraic\ngeometry codes. By applying our repairing algorithm to the one-point algebraic\ngeometry codes based on the Garcia-Stichtenoth tower, one can repair a code of\nrate $1-\\Ge$ and length $n$ over $\\F_{q}$ with bandwidth $(n-1)(1-\\Gt)\\log q$\nfor any $\\Ge=2^{(\\Gt-1/2)\\log q}$ with a real $\\tau\\in(0,1/2)$. In addition,\nstorage in each node for an algebraic geometry code is close to the minimum\nstorage. Due to nice structures of Hermitian curves, repairing of Hermitian\ncodes is also investigated. As a result, we are able to show that algebraic\ngeometry codes are regenerating codes with good parameters. An example reveals\nthat Hermitian codes outperform Reed-Solomon codes for certain parameters. \n\n"}
{"id": "1710.02067", "contents": "Title: Codes Endowed With the Rank Metric Abstract: We review the main results of the theory of rank-metric codes, with emphasis\non their combinatorial properties. We study their duality theory and\nMacWilliams identities, comparing in particular rank-metric codes in vector and\nmatrix representation. We then investigate the combinatorial structure of MRD\ncodes and optimal anticodes in the rank metric, describing how they relate to\neach other. \n\n"}
{"id": "1710.02796", "contents": "Title: Vulnerabilities of Massive MIMO Systems Against Pilot Contamination\n  Attacks Abstract: We consider a single-cell massive MIMO system in which a base station (BS)\nwith a large number of antennas transmits simultaneously to several\nsingle-antenna users in the presence of an attacker.The BS acquires the channel\nstate information (CSI) based on uplink pilot transmissions. In this work, we\ndemonstrate the vulnerability of CSI estimation phase to malicious attacks. For\nthat purpose, we study two attack models. In the first model, the attacker aims\nat minimizing the sum-rate of downlink transmissions by contaminating the\nuplink pilots. In the second model, the attacker exploits its in-band\nfull-duplex capabilities to generate jamming signals in both the CSI estimation\nand data transmission phases. We study these attacks under two downlink power\nallocation strategies when the attacker knows and does not know the locations\nof the BS and users. The formulated problems are solved using stochastic\noptimization, Lagrangian minimization, and game-theoretic methods. A\nclosed-form solution for a special case of the problem is obtained.\nFurthermore, we analyze the achievable individual secrecy rates under a pilot\ncontamination attack, and provide an upper bound on these rates. Our results\nindicate that the proposed attacks degrade the throughput of a massive MIMO\nsystem by more than half. \n\n"}
{"id": "1710.02811", "contents": "Title: On Reusing Pilots Among Interfering Cells in Massive MIMO Abstract: Pilot contamination, caused by the reuse of pilots among interfering cells,\nremains as a significant obstacle that limits the performance of massive\nmulti-input multi-output antenna systems. To handle this problem, less\naggressive reuse of pilots involving allocation of additional pilots for\ninterfering users is closely examined in this paper. Hierarchical pilot reuse\nmethods are proposed, which effectively mitigate pilot contamination and\nincrease the net throughput of the system. Among the suggested hierarchical\npilot reuse schemes, the optimal way of assigning pilots to different users is\nobtained in a closed-form solution which maximizes the net sum-rate in a given\ncoherence time. Simulation results confirm that when the ratio of the channel\ncoherence time to the number of users in each cell is sufficiently large, less\naggressive reuse of pilots yields significant performance advantage relative to\nthe case where all cells reuse the same pilot set. \n\n"}
{"id": "1710.03654", "contents": "Title: Quantized Spectral Compressed Sensing: Cramer-Rao Bounds and Recovery\n  Algorithms Abstract: Efficient estimation of wideband spectrum is of great importance for\napplications such as cognitive radio. Recently, sub-Nyquist sampling schemes\nbased on compressed sensing have been proposed to greatly reduce the sampling\nrate. However, the important issue of quantization has not been fully\naddressed, particularly for high-resolution spectrum and parameter estimation.\nIn this paper, we aim to recover spectrally-sparse signals and the\ncorresponding parameters, such as frequency and amplitudes, from heavy\nquantizations of their noisy complex-valued random linear measurements, e.g.\nonly the quadrant information. We first characterize the Cramer-Rao bound under\nGaussian noise, which highlights the trade-off between sample complexity and\nbit depth under different signal-to-noise ratios for a fixed budget of bits.\nNext, we propose a new algorithm based on atomic norm soft thresholding for\nsignal recovery, which is equivalent to proximal mapping of properly designed\nsurrogate signals with respect to the atomic norm that motivates spectral\nsparsity. The proposed algorithm can be applied to both the single measurement\nvector case, as well as the multiple measurement vector case. It is shown that\nunder the Gaussian measurement model, the spectral signals can be reconstructed\naccurately with high probability, as soon as the number of quantized\nmeasurements exceeds the order of K log n, where K is the level of spectral\nsparsity and $n$ is the signal dimension. Finally, numerical simulations are\nprovided to validate the proposed approaches. \n\n"}
{"id": "1710.04578", "contents": "Title: Mobile IMUs Reveal Driver's Identity From Vehicle Turns Abstract: As vehicle maneuver data becomes abundant for assisted or autonomous driving,\ntheir implication of privacy invasion/leakage has become an increasing concern.\nIn particular, the surface for fingerprinting a driver will expand\nsignificantly if the driver's identity can be linked with the data collected\nfrom his mobile or wearable devices which are widely deployed worldwide and\nhave increasing sensing capabilities. In line with this trend, this paper\ninvestigates a fast emerging driving data source that has driver's privacy\nimplications. We first show that such privacy threats can be materialized via\nany mobile device with IMUs (e.g., gyroscope and accelerometer). We then\npresent Dri-Fi (Driver Fingerprint), a driving data analytic engine that can\nfingerprint the driver with vehicle turn(s). Dri-Fi achieves this based on IMUs\ndata taken only during the vehicle's turn(s). Such an approach expands the\nattack surface significantly compared to existing driver fingerprinting\nschemes. From this data, Dri-Fi extracts three new features --- acceleration\nalong the end-of-turn axis, its deviation, and the deviation of the yaw rate\n--- and exploits them to identify the driver. Our extensive evaluation shows\nthat an adversary equipped with Dri-Fi can correctly fingerprint the driver\nwithin just one turn with 74.1%, 83.5%, and 90.8% accuracy across 12, 8, and 5\ndrivers --- typical of an immediate family or close-friends circle ---\nrespectively. Moreover, with measurements on more than one turn, the adversary\ncan achieve up to 95.3%, 95.4%, and 96.6% accuracy across 12, 8, and 5 drivers,\nrespectively. \n\n"}
{"id": "1710.04999", "contents": "Title: Matrix-Product Constructions for Hermitian Self-Orthogonal Codes Abstract: Self-orthogonal codes have been of interest due to there rich algebraic\nstructures and wide applications. Euclidean self-orthogonal codes have been\nquite well studied in literature. Here, we have focused on Hermitian\nself-orthogonal codes. Constructions of such codes have been given based on the\nwell-known matrix-product construction for linear codes. Criterion for the\nunderlying matrix and the input codes required in such constructions have been\ndetermined. In many cases, the Hermitian self-orthogonality of the input codes\nand the assumption that the underlying matrix is unitary can be relaxed. Some\nspecial matrices used in the constructions and illustrative examples of good\nHermitian self-orthogonal codes have been provided as well. \n\n"}
{"id": "1710.05130", "contents": "Title: MinDelay: Low-latency Forwarding and Caching Algorithms for\n  Information-Centric Networks Abstract: We present a new unified framework for minimizing congestion-dependent\nnetwork cost in information-centric networks by jointly optimizing forwarding\nand caching strategies. As caching variables are integer-constrained, the\nresulting optimization problem is NP-hard. To make progress, we focus on a\nrelaxed version of the optimization problem, where caching variables are\nallowed to be real-valued. We develop necessary optimality conditions for the\nrelaxed problem, and leverage this result to design MinDelay, an adaptive and\ndistributed joint forwarding and caching algorithm, based on the conditional\ngradient algorithm. The MinDelay algorithm elegantly yields feasible routing\nvariables and integer caching variables at each iteration, and can be\nimplemented in a distributed manner with low complexity and overhead. Over a\nwide range of network topologies, simulation results show that MinDelay\ntypically has significantly better delay performance in the low to moderate\nrequest rate regions. Furthermore, the MinDelay and VIP algorithms complement\neach other in delivering superior delay performance across the entire range of\nrequest arrival rates. \n\n"}
{"id": "1710.05876", "contents": "Title: On Lower Bounds on Sub-Packetization Level of MSR codes and On The\n  Structure of Optimal-Access MSR Codes Achieving The Bound Abstract: We present two lower bounds on sub-packetization level $\\alpha$ of MSR codes\nwith parameters $(n, k, d=n-1, \\alpha)$ where $n$ is the block length, $k$\ndimension, $d$ number of helper nodes contacted during single node repair and\n$\\alpha$ the sub-packetization level. The first bound we present is for any MSR\ncode and is given by $\\alpha \\ge e^{\\frac{(k-1)(r-1)}{2r^2}}$.\n  The second bound we present is for the case of optimal-access MSR codes and\nthe bound is given by $\\alpha \\ge \\min \\{ r^{\\frac{n-1}{r}}, r^{k-1} \\}$. There\nexist optimal-access MSR constructions that achieve the second\nsub-packetization level bound with an equality making this bound tight.\n  We also prove that for an optimal-access MSR codes to have optimal\nsub-packetization level under the constraint that the indices of helper symbols\nare dependant only on the failed node, it is needed that the support of the\nparity check matrix is same as the support structure of several other optimal\nconstructions in literature. \n\n"}
{"id": "1710.06025", "contents": "Title: Quantum query complexity of entropy estimation Abstract: Estimation of Shannon and R\\'enyi entropies of unknown discrete distributions\nis a fundamental problem in statistical property testing and an active research\ntopic in both theoretical computer science and information theory. Tight bounds\non the number of samples to estimate these entropies have been established in\nthe classical setting, while little is known about their quantum counterparts.\nIn this paper, we give the first quantum algorithms for estimating\n$\\alpha$-R\\'enyi entropies (Shannon entropy being 1-Renyi entropy). In\nparticular, we demonstrate a quadratic quantum speedup for Shannon entropy\nestimation and a generic quantum speedup for $\\alpha$-R\\'enyi entropy\nestimation for all $\\alpha\\geq 0$, including a tight bound for the\ncollision-entropy (2-R\\'enyi entropy). We also provide quantum upper bounds for\nextreme cases such as the Hartley entropy (i.e., the logarithm of the support\nsize of a distribution, corresponding to $\\alpha=0$) and the min-entropy case\n(i.e., $\\alpha=+\\infty$), as well as the Kullback-Leibler divergence between\ntwo distributions. Moreover, we complement our results with quantum lower\nbounds on $\\alpha$-R\\'enyi entropy estimation for all $\\alpha\\geq 0$. \n\n"}
{"id": "1710.07025", "contents": "Title: Second Order Asymptotics for Communication under Strong Asynchronism Abstract: The capacity under strong asynchronism was recently shown to be essentially\nunaffected by the imposed output sampling rate $\\rho$ and decoding delay\n$d$---the elapsed time between when information is available at the transmitter\nand when it is decoded. This paper examines this result in the finite\nblocklength regime and shows that, by contrast with capacity, the second order\nterm in the rate expansion is sensitive to both parameters. When the receiver\nmust exactly locate the sent codeword, that is $d=n$ where $n$ denotes\nblocklength, the second order term in the rate expansion is of order\n$\\Theta(1/\\rho)$ for any $\\rho=O(1/\\sqrt{n})$---and $\\rho =\\omega(1/n)$ for\notherwise reliable communication is impossible. However, if\n$\\rho=\\omega(1/\\sqrt{n})$ then the second order term is the same as under full\nsampling and is given by a standard $O(\\sqrt{n})$ term whose dispersion\nconstant only depends on the level of asynchronism. This second order term also\ncorresponds to the case of the slightly relaxed delay constraint $d\\leq\nn(1+o(1))$ for any $\\rho=\\omega(1/n)$. \n\n"}
{"id": "1710.07879", "contents": "Title: Stable Blind Deconvolution over the Reals from Additional\n  Autocorrelations Abstract: Recently the one-dimensional time-discrete blind deconvolution problem was\nshown to be solvable uniquely, up to a global phase, by a semi-definite program\nfor almost any signal, provided its autocorrelation is known. We will show in\nthis work that under a sufficient zero separation of the corresponding signal\nin the $z-$domain, a stable reconstruction against additive noise is possible.\nMoreover, the stability constant depends on the signal dimension and on the\nsignals magnitude of the first and last coefficients. We give an analytical\nexpression for this constant by using spectral bounds of Vandermonde matrices. \n\n"}
{"id": "1710.07900", "contents": "Title: Analysis of Discrete-Time MIMO OFDM-Based Orthogonal Time Frequency\n  Space Modulation Abstract: Orthogonal Time Frequency Space (OTFS) is a novel modulation scheme designed\nin the Doppler-delay domain to fully exploit time and frequency diversity of\ngeneral time-varying channels. In this paper, we present a novel discrete-time\nanalysis of OFDM-based OTFS transceiver with a concise and vectorized\ninput-output relationship that clearly characterizes the contribution of each\nunderlying signal processing block in such systems. When adopting cyclic prefix\nin the time domain, our analysis reveals that the proposed MIMO OTFS and OFDM\nsystems have the same ergodic capacity despite the well-known fact that the\nformer has great advantages in low-complexity receiver design for high Doppler\nchannels. The proposed discrete-time vectorized formulation is applicable to\ngeneral fast fading channels with arbitrary window functions. It also enables\npractical low-complexity receiver design for which such a concise formulation\nof the input-output relationship is of great benefits. \n\n"}
{"id": "1710.08478", "contents": "Title: Key Technologies and System Trade-Offs for Detection and Localization of\n  Amateur Drones Abstract: The use of amateur drones (ADrs) is expected to significantly increase over\nthe upcoming years. However, regulations do not allow such drones to fly over\nall areas, in addition to typical altitude limitations. As a result, there is\nan urgent need for ADrs surveillance solutions. These solutions should include\nmeans of accurate detection, classification, and localization of the unwanted\ndrones in a no-fly zone. In this paper, we give an overview of promising\ntechniques for modulation classification and signal strength based localization\nof ADrs by using surveillance drones (SDrs). By introducing a generic altitude\ndependent propagation model, we show how detection and localization performance\ndepend on the altitude of SDrs. Particularly, our simulation results show a 25\ndB reduction in the minimum detectable power or 10 times coverage enhancement\nof an SDr by flying at the optimum altitude. Moreover, for a target no-fly\nzone, the location estimation error of an ADr can be remarkably reduced by\noptimizing the positions of the SDrs. Finally, we conclude the paper with a\ngeneral discussion about the future work and possible challenges of the aerial\nsurveillance systems. \n\n"}
{"id": "1710.09884", "contents": "Title: On Quantum Stabilizer Codes derived from Local Frobenius Rings Abstract: In this paper we consider stabilizer codes over local Frobenius rings. First,\nwe study the relative minimum distances of a stabilizer code and its reduction\nonto the residue field. We show that for various scenarios, a free stabilizer\ncode over the ring does not underperform the according stabilizer code over the\nfield. This leads us to conjecture that the same is true for all free\nstabilizer codes. Secondly, we focus on the isometries of stabilizer codes. We\npresent some preliminary results and introduce some interesting open problems. \n\n"}
{"id": "1710.10225", "contents": "Title: Adversarial Detection of Flash Malware: Limitations and Open Issues Abstract: During the past four years, Flash malware has become one of the most\ninsidious threats to detect, with almost 600 critical vulnerabilities targeting\nAdobe Flash disclosed in the wild. Research has shown that machine learning can\nbe successfully used to detect Flash malware by leveraging static analysis to\nextract information from the structure of the file or its bytecode. However,\nthe robustness of Flash malware detectors against well-crafted evasion attempts\n- also known as adversarial examples - has never been investigated. In this\npaper, we propose a security evaluation of a novel, representative Flash\ndetector that embeds a combination of the prominent, static features employed\nby state-of-the-art tools. In particular, we discuss how to craft adversarial\nFlash malware examples, showing that it suffices to manipulate the\ncorresponding source malware samples slightly to evade detection. We then\nempirically demonstrate that popular defense techniques proposed to mitigate\nevasion attempts, including re-training on adversarial examples, may not always\nbe sufficient to ensure robustness. We argue that this occurs when the feature\nvectors extracted from adversarial examples become indistinguishable from those\nof benign data, meaning that the given feature representation is intrinsically\nvulnerable. In this respect, we are the first to formally define and\nquantitatively characterize this vulnerability, highlighting when an attack can\nbe countered by solely improving the security of the learning algorithm, or\nwhen it requires also considering additional features. We conclude the paper by\nsuggesting alternative research directions to improve the security of\nlearning-based Flash malware detectors. \n\n"}
{"id": "1710.10663", "contents": "Title: List-decodable zero-rate codes Abstract: We consider list-decoding in the zero-rate regime for two cases: the binary\nalphabet and the spherical codes in Euclidean space. Specifically, we study the\nmaximal $\\tau \\in [0,1]$ for which there exists an arrangement of $M$ balls of\nrelative Hamming radius $\\tau$ in the binary hypercube (of arbitrary dimension)\nwith the property that no point of the latter is covered by $L$ or more of\nthem. As $M\\to \\infty$ the maximal $\\tau$ decreases to a well-known critical\nvalue $\\tau_L$. In this work, we prove several results on the rate of this\nconvergence.\n  For the binary case, we show that the rate is $\\Theta(M^{-1})$ when $L$ is\neven, thus extending the classical results of Plotkin and Levenshtein for\n$L=2$. For $L=3$ the rate is shown to be $\\Theta(M^{-\\tfrac{2}{3}})$.\n  For the similar question about spherical codes, we prove the rate is\n$\\Omega(M^{-1})$ and $O(M^{-\\tfrac{2L}{L^2-L+2}})$. \n\n"}
{"id": "1711.00379", "contents": "Title: Non-Linear Digital Self-Interference Cancellation for In-Band\n  Full-Duplex Radios Using Neural Networks Abstract: Full-duplex systems require very strong self-interference cancellation in\norder to operate correctly and a significant part of the self-interference\nsignal is due to non-linear effects created by various transceiver impairments.\nAs such, linear cancellation alone is usually not sufficient and sophisticated\nnon-linear cancellation algorithms have been proposed in the literature. In\nthis work, we investigate the use of a neural network as an alternative to the\ntraditional non-linear cancellation method that is based on polynomial basis\nfunctions. Measurement results from a full-duplex testbed demonstrate that a\nsmall and simple feed-forward neural network canceler works exceptionally well,\nas it can match the performance of the polynomial non-linear canceler with\nsignificantly lower computational complexity. \n\n"}
{"id": "1711.01110", "contents": "Title: A Rudimentary Model for Low-Latency Anonymous Communication Systems Abstract: In this paper we present a rudimentary model for low-latency anonymous\ncommunication systems. Specifically, we study distributed OR algorithm as an\nabstract of the system. Based on our model, we give several satisfactory lower\nbounds of anonymity leakage of a deterministic OR algorithm. Some of them\nreveal a trade-off between anonymity and communication complexity. For the\nrandomized OR algorithm, we only give a relatively trivial but possibly tight\nlower bound when leaving out communication complexity. And we find the\nrelationship between our model and some open case in the study of secret\nsharing scheme, if considering communication complexity. \n\n"}
{"id": "1711.01351", "contents": "Title: Uplink Performance Analysis of a Drone Cell in a Random Field of Ground\n  Interferers Abstract: Aerial base stations are a promising technology to increase the capabilities\nof the existing communication networks. However, the existing analytical\nframeworks do not sufficiently characterize the impact of ground interferers on\nthe aerial base stations. In order to address this issue, we model the effect\nof interference coming from the coexisting ground networks on the aerial link,\nwhich could be the uplink of an aerial cell served by a drone base station. By\nconsidering a Poisson field of ground interferers, we characterize the\naggregate interference experienced by the drone. This result includes the\neffect of the drone antenna pattern, the height-dependent shadowing, and\nvarious types of environment. We show that the benefits that a drone obtains\nfrom a better line-of-sight (LoS) at high altitudes is counteracted by a high\nvulnerability to the interference coming from the ground. However, by deriving\nthe link coverage probability and transmission rate we show that a drone base\nstation is still a promising technology if the overall system is properly\ndimensioned according to the given density and transmission power of the\ninterferers. Particularly, our results illustrate how the benefits of such\nnetwork is maximized by defining the optimal drone altitude and signal-to-\ninterference (SIR) requirement. \n\n"}
{"id": "1711.01939", "contents": "Title: Advanced Analytics for Connected Cars Cyber Security Abstract: The vehicular connectivity revolution is fueling the automotive industry's\nmost significant transformation seen in decades. However, as modern vehicles\nbecome more connected, they also become much more vulnerable to cyber-attacks.\nIn this paper, a fully working machine learning approach is proposed to protect\nconnected vehicles (fleets and individuals) against such attacks. We present a\nsystem that monitors different vehicle's interfaces (Network, CAN and OS),\nextracts relevant information based on configurable rules and sends it to a\ntrained generative model to detect deviations from normal behavior. Using\nconfigurable data collector, we provide a higher level of data abstraction as\nthe model is trained based on events instead of raw data, which has a\nnoise-filtering effect and eliminates the need to retrain the model whenever a\nprotocol changes. We present a new approach for detecting anomalies, tailored\nto the temporal nature of our domain. Adapting the hybrid approach of Gutflaish\net al. (2017) to the fully temporal setting, we first train a Hidden Markov\nModel to learn normal vehicle behavior, and then a regression model to\ncalibrate the likelihood threshold for anomaly. Using this architecture, our\nmethod detects sophisticated and realistic anomalies, which are missed by other\nexisting methods monitoring the CAN bus only. We also demonstrate the\nsuperiority of adaptive thresholds over static ones. Furthermore, our approach\nscales efficiently from monitoring individual cars to serving large fleets. We\ndemonstrate the competitive advantage of our model via encouraging empirical\nresults. \n\n"}
{"id": "1711.02348", "contents": "Title: Multi-mode Tracking of a Group of Mobile Agents Abstract: We consider the problem of tracking a group of mobile nodes with limited\navailable computational and energy resources given noisy RSSI measurements and\nposition estimates from group members. The multilateration solutions are known\nfor energy efficiency. However, these solutions are not directly applicable to\ndynamic grouping scenarios where neighbourhoods and resource availability may\nfrequently change. Existing algorithms such as cluster-based GPS duty-cycling,\nindividual-based tracking, and multilateration-based tracking can only\npartially deal with the challenges of dynamic grouping scenarios. To cope with\nthese challenges in an effective manner, we propose a new group-based\nmulti-mode tracking algorithm. The proposed algorithm takes the topological\nstructure of the group as well as the availability of the resources into\nconsideration and decides the best solution at any particular time instance. We\nconsider a clustering approach where a cluster head coordinates the usage of\nresources among the cluster members. We evaluate the energy-accuracy trade-off\nof the proposed algorithm for various fixed sampling intervals. The evaluation\nis based on the 2D position tracks of 40 nodes generated using Reynolds'\nflocking model. For a given energy budget, the proposed algorithm reduces the\nmean tracking error by up to $20\\%$ in comparison to the existing\nenergy-efficient cooperative algorithms. Moreover, the proposed algorithm is as\naccurate as the individual-based tracking while using almost half the energy. \n\n"}
{"id": "1711.03941", "contents": "Title: A TTL-based Approach for Content Placement in Edge Networks Abstract: Edge networks are promising to provide better services to users by\nprovisioning computing and storage resources at the edge of networks. However,\ndue to the uncertainty and diversity of user interests, content popularity,\ndistributed network structure, cache sizes, it is challenging to decide where\nto place the content, and how long it should be cached. In this paper, we study\nthe utility optimization of content placement at edge networks through\ntimer-based (TTL) policies. We propose provably optimal distributed algorithms\nthat operate at each network cache to maximize the overall network utility. Our\nTTL-based optimization model provides theoretical answers to how long each\ncontent must be cached, and where it should be placed in the edge network.\nExtensive evaluations show that our algorithm significantly outperforms path\nreplication with conventional caching algorithms over some network topologies. \n\n"}
{"id": "1711.04677", "contents": "Title: Private Function Retrieval Abstract: The widespread use of cloud computing services raises the question of how one\ncan delegate the processing tasks to the untrusted distributed parties without\nbreeching the privacy of its data and algorithms. Motivated by the algorithm\nprivacy concerns in a distributed computing system, in this paper, we introduce\nthe private function retrieval (PFR) problem, where a user wishes to\nefficiently retrieve a linear function of $K$ messages from $N$\nnon-communicating replicated servers while keeping the function hidden from\neach individual server. The goal is to find a scheme with minimum communication\ncost. To characterize the fundamental limits of the communication cost, we\ndefine the capacity of PFR problem as the size of the message that can be\nprivately retrieved (which is the size of one file) normalized to the required\ndownloaded information bits. We first show that for the PFR problem with $K$\nmessages, $N=2$ servers and a linear function with binary coefficients the\ncapacity is $C=\\frac{1}{2}\\Big(1-\\frac{1}{2^K}\\Big)^{-1}$. Interestingly, this\nis the capacity of retrieving one of $K$ messages from $N=2$ servers while\nkeeping the index of the requested message hidden from each individual server,\nthe problem known as private information retrieval (PIR). Then, we extend the\nproposed achievable scheme to the case of arbitrary number of servers and\ncoefficients in the field $GF(q)$ with arbitrary $q$ and obtain\n$R=\\Big(1-\\frac{1}{N}\\Big)\\Big(1+\\frac{\\frac{1}{N-1}}{(\\frac{q^K-1}{q-1})^{N-1}}\\Big)$. \n\n"}
{"id": "1711.05219", "contents": "Title: LAA LTE and WiFi based Smart Grid Metering Infrastructure in 3.5 GHz\n  Band Abstract: Advanced metering infrastructure (AMI) of smart grid requires bidirectional\ncommunication for transferring data to billing center, for which WiFi is an\nattractive choice. However, WiFi operates in the unlicensed bands and LTE needs\nto offload data in the same unlicensed band. Recent release of 3.5 GHz (also\ntermed as citizen broadband radio service (CBRS)) can be an attractive shared\nband where LTE and WiFi can coexist. In our study, we propose a fixed duty\ncycled LTE-U and WiFi based smart grid metering infrastructure where smart\nmeter uses WiFi and data collector (termed as Access Point (AP)) of smart\nmeters uses LTE for transferring data. We investigate the coexistence\nperformance of LTE-WiFi in the 3.5 GHz band using a time division duplexing\n(TDD) LTE confederated by WiFi along with FTP traffic model for system level\nsimulation. The simulation results demonstrate a good neighboring coexistence\nbetween LTE and WiFi resulting a candidate AMI architecture for smart grid in\nthe 3.5 GHz band. \n\n"}
{"id": "1711.05244", "contents": "Title: Private Information Retrieval from Storage Constrained Databases --\n  Coded Caching meets PIR Abstract: Private information retrieval (PIR) allows a user to retrieve a desired\nmessage out of $K$ possible messages from $N$ databases without revealing the\nidentity of the desired message. Majority of existing works on PIR assume the\npresence of replicated databases, each storing all the $K$ messages. In this\nwork, we consider the problem of PIR from storage constrained databases. Each\ndatabase has a storage capacity of $\\mu KL$ bits, where $K$ is the number of\nmessages, $L$ is the size of each message in bits, and $\\mu \\in [1/N, 1]$ is\nthe normalized storage. In the storage constrained PIR problem, there are two\nkey design questions: a) how to store content across each database under\nstorage constraints; and b) construction of schemes that allow efficient PIR\nthrough storage constrained databases. The main contribution of this work is a\ngeneral achievable scheme for PIR from storage constrained databases for any\nvalue of storage. In particular, for any $(N,K)$, with normalized storage $\\mu=\nt/N$, where the parameter $t$ can take integer values $t \\in \\{1, 2, \\ldots,\nN\\}$, we show that our proposed PIR scheme achieves a download cost of\n$\\left(1+ \\frac{1}{t}+ \\frac{1}{t^{2}}+ \\cdots + \\frac{1}{t^{K-1}}\\right)$. The\nextreme case when $\\mu=1$ (i.e., $t=N$) corresponds to the setting of\nreplicated databases with full storage. For this extremal setting, our scheme\nrecovers the information-theoretically optimal download cost characterized by\nSun and Jafar as $\\left(1+ \\frac{1}{N}+ \\cdots + \\frac{1}{N^{K-1}}\\right)$. For\nthe other extreme, when $\\mu= 1/N$ (i.e., $t=1$), the proposed scheme achieves\na download cost of $K$. The interesting aspect of the result is that for\nintermediate values of storage, i.e., $1/N < \\mu <1$, the proposed scheme can\nstrictly outperform memory-sharing between extreme values of storage. \n\n"}
{"id": "1711.05893", "contents": "Title: On Communication Complexity of Classification Problems Abstract: This work studies distributed learning in the spirit of Yao's model of\ncommunication complexity: consider a two-party setting, where each of the\nplayers gets a list of labelled examples and they communicate in order to\njointly perform some learning task. To naturally fit into the framework of\nlearning theory, the players can send each other examples (as well as bits)\nwhere each example/bit costs one unit of communication. This enables a uniform\ntreatment of infinite classes such as half-spaces in $\\mathbb{R}^d$, which are\nubiquitous in machine learning.\n  We study several fundamental questions in this model. For example, we provide\ncombinatorial characterizations of the classes that can be learned with\nefficient communication in the proper-case as well as in the improper-case.\nThese findings imply unconditional separations between various learning\ncontexts, e.g.\\ realizable versus agnostic learning, proper versus improper\nlearning, etc.\n  The derivation of these results hinges on a type of decision problems we term\n\"{\\it realizability problems}\" where the goal is deciding whether a distributed\ninput sample is consistent with an hypothesis from a pre-specified class.\n  From a technical perspective, the protocols we use are based on ideas from\nmachine learning theory and the impossibility results are based on ideas from\ncommunication complexity theory. \n\n"}
{"id": "1711.06487", "contents": "Title: Optimal Index Codes via a Duality between Index Coding and Network\n  Coding Abstract: In Index Coding, the goal is to use a broadcast channel as efficiently as\npossible to communicate information from a source to multiple receivers which\ncan possess some of the information symbols at the source as side-information.\nIn this work, we present a duality relationship between index coding (IC) and\nmultiple-unicast network coding (NC). It is known that the IC problem can be\nrepresented using a side-information graph $G$ (with number of vertices $n$\nequal to the number of source symbols). The size of the maximum acyclic induced\nsubgraph, denoted by $MAIS$ is a lower bound on the \\textit{broadcast rate}.\nFor IC problems with $MAIS=n-1$ and $MAIS=n-2$, prior work has shown that\nbinary (over ${\\mathbb F}_2$) linear index codes achieve the $MAIS$ lower bound\nfor the broadcast rate and thus are optimal. In this work, we use the the\nduality relationship between NC and IC to show that for a class of IC problems\nwith $MAIS=n-3$, binary linear index codes achieve the $MAIS$ lower bound on\nthe broadcast rate. In contrast, it is known that there exists IC problems with\n$MAIS=n-3$ and optimal broadcast rate strictly greater than $MAIS$. \n\n"}
{"id": "1711.06600", "contents": "Title: On optimal coding of non-linear dynamical systems Abstract: We consider the problem of zero-delay coding of a dynamical system over a\ndiscrete noiseless channel under three estimation criteria concerned with the\nlow-distortion regime. For these three criteria, formulated stochastically in\nterms of a probability distribution for the initial state, we characterize the\nsmallest channel capacities above which the estimation objectives can be\nachieved. The results establish further connections between topological and\nmetric entropy of dynamical systems and information theory. \n\n"}
{"id": "1711.07324", "contents": "Title: On DNA Codes using the Ring Z4 + wZ4 Abstract: In this work, we study the DNA codes from the ring R = Z4 + wZ4, where w^2 =\n2+2w with 16 elements. We establish a one to one correspondence between the\nelements of the ring R and all the DNA codewords of length 2 by defining a\ndistance-preserving Gau map phi. Using this map, we give several new classes of\nthe DNA codes which satisfies reverse and reverse complement constraints. Some\nof the constructed DNA codes are optimal. \n\n"}
{"id": "1711.07689", "contents": "Title: LTE-based Satellite Communications in LEO Mega-Constellations Abstract: The integration of satellite and terrestrial networks is a promising solution\nfor extending broadband coverage to areas not connected to a terrestrial\ninfrastructure, as also demonstrated by recent commercial and standardisation\nendeavours. However, the large delays and Doppler shifts over the satellite\nchannel pose severe technical challenges to traditional terrestrial systems, as\nLTE or 5G. In this paper, two architectures are proposed for a LEO\nmega-constellation realising a satellite-enabled LTE system, in which the on-\nground LTE entity is either an eNB (Sat-eNB) or a Relay Node (Sat-RN). The\nimpact of satellite channel impairments as large delays and Doppler shifts on\nLTE PHY/MAC procedures is discussed and assessed. The proposed analysis shows\nthat, while carrier spacings, Random Access, and RN attach procedures do not\npose specific issues, HARQ requires substantial modifications. Moreover,\nadvanced handover procedures will be also required due to the satellites'\nmovement. \n\n"}
{"id": "1711.07703", "contents": "Title: Construction of asymptotically good locally repairable codes via\n  automorphism groups of function fields Abstract: Locally repairable codes have been investigated extensively in recent years\ndue to practical application in distributed storage as well as theoretical\ninterest. However, not much work on asymptotical behavior of locally repairable\ncodes has been done until now. In particular, there is a little result on\nconstructive lower bound on asymptotical behavior of locally repairable codes.\nIn this paper, we extend the construction given in \\cite{BTV17} via\nautomorphism groups of function field towers. The main advantage of our\nconstruction is to allow more flexibility of locality. Furthermore, we show\nthat the Gilbert-Varshamov type bound on locally repairable codes can be\nimproved for all sufficiently large alphabet size $q$. \n\n"}
{"id": "1711.10767", "contents": "Title: Parameter-free $\\ell_p$-Box Decoding of LDPC Codes Abstract: The Alternating Direction Method of Multipliers (ADMM) decoding of Low\nDensity Parity Check (LDPC) codes has received many attentions due to its\nexcellent performance at the error floor region. In this paper, we develop a\nparameter-free decoder based on Linear Program (LP) decoding by replacing the\nbinary constraint with the intersection of a box and an $\\ell_p$ sphere. An\nefficient $\\ell_2$-box ADMM is designed to handle this model in a distributed\nfashion. Numerical experiments demonstrate that our decoder attains better\nadaptability to different Signal-to-Noise Ratio and channels. \n\n"}
{"id": "1711.11202", "contents": "Title: On deep-holes of Gabidulin codes Abstract: In this paper, we determine the covering radius and a class of deep holes for\nGabidulin codes with both rank metric and Hamming metric. Moreover, we give a\nnecessary and sufficient condition for deciding whether a word is not a deep\nhole for Gabidulin codes, by which we study the error distance of a special\nclass of words to certain Gabidulin codes. \n\n"}
{"id": "1711.11510", "contents": "Title: Assessing Information Transmission in Data Transformations with the\n  Channel Multivariate Entropy Triangle Abstract: Data transformation, e.g. feature transformation and selection, is an\nintegral part of any machine learning procedure. In this paper we introduce an\ninformation-theoretic model and tools to assess the quality of data\ntransformations in machine learning tasks. In an unsupervised fashion, we\nanalyze the transfer of information of the transformation of a discrete,\nmultivariate source of information X into a discrete, multivariate sink of\ninformation Y related by a distribution PXY . The first contribution is a\ndecomposition of the maximal potential entropy of (X, Y) that we call a balance\nequation, into its a) non-transferable, b) transferable but not transferred and\nc) transferred parts. Such balance equations can be represented in (de Finetti)\nentropy diagrams, our second set of contributions. The most important of these,\nthe aggregate Channel Multivariate Entropy Triangle is a visual exploratory\ntool to assess the effectiveness of multivariate data transformations in\ntransferring information from input to output variables. We also show how these\ndecomposition and balance equation also apply to the entropies of X and Y\nrespectively and generate entropy triangles for them. As an example, we present\nthe application of these tools to the assessment of information transfer\nefficiency for PCA and ICA as unsupervised feature transformation and selection\nprocedures in supervised classification tasks. \n\n"}
{"id": "1712.02700", "contents": "Title: milliProxy: a TCP Proxy Architecture for 5G mmWave Cellular Systems Abstract: TCP is the most widely used transport protocol in the internet. However, it\noffers suboptimal performance when operating over high bandwidth mmWave links.\nThe main issues introduced by communications at such high frequencies are (i)\nthe sensitivity to blockage and (ii) the high bandwidth fluctuations due to\nLine of Sight (LOS) to Non Line of Sight (NLOS) transitions and vice versa. In\nparticular, TCP has an abstract view of the end-to-end connection, which does\nnot properly capture the dynamics of the wireless mmWave link. The consequence\nis a suboptimal utilization of the available resources. In this paper we\npropose a TCP proxy architecture that improves the performance of TCP flows\nwithout any modification at the remote sender side. The proxy is installed in\nthe Radio Access Network, and exploits information available at the gNB in\norder to maximize throughput and minimize latency. \n\n"}
{"id": "1712.03405", "contents": "Title: RHyTHM: A Randomized Hybrid Scheme To Hide in the Mobile Crowd Abstract: Any on-demand pseudonym acquisition strategy is problematic should the\nconnectivity to the credential management infrastructure be intermittent. If a\nvehicle runs out of pseudonyms with no connectivity to refill its pseudonym\npool, one solution is the on-the-fly generation of pseudonyms, e.g., leveraging\nanonymous authentication. However, such a vehicle would stand out in the crowd:\none can simply distinguish pseudonyms, thus signed messages, based on the\npseudonym issuer signature, link them and track the vehicle. To address this\nchallenge, we propose a randomized hybrid scheme, RHyTHM, to enable vehicles to\nremain operational when disconnected without compromising privacy: vehicles\nwith valid pseudonyms help others to enhance their privacy by randomly joining\nthem in using on-the-fly self-certified pseudonyms along with aligned\nlifetimes. This way, the privacy of disconnected users is enhanced with a\nreasonable computational overhead. \n\n"}
{"id": "1712.03898", "contents": "Title: Achieving Maximum Distance Separable Private Information Retrieval\n  Capacity With Linear Codes Abstract: We propose three private information retrieval (PIR) protocols for\ndistributed storage systems (DSSs) where data is stored using an arbitrary\nlinear code. The first two protocols, named Protocol 1 and Protocol 2, achieve\nprivacy for the scenario with noncolluding nodes. Protocol 1 requires a file\nsize that is exponential in the number of files in the system, while Protocol 2\nrequires a file size that is independent of the number of files and is hence\nsimpler. We prove that, for certain linear codes, Protocol 1 achieves the\nmaximum distance separable (MDS) PIR capacity, i.e., the maximum PIR rate (the\nratio of the amount of retrieved stored data per unit of downloaded data) for a\nDSS that uses an MDS code to store any given (finite and infinite) number of\nfiles, and Protocol 2 achieves the asymptotic MDS-PIR capacity (with infinitely\nlarge number of files in the DSS). In particular, we provide a necessary and a\nsufficient condition for a code to achieve the MDS-PIR capacity with Protocols\n1 and 2 and prove that cyclic codes, Reed-Muller (RM) codes, and a class of\ndistance-optimal local reconstruction codes achieve both the finite MDS-PIR\ncapacity (i.e., with any given number of files) and the asymptotic MDS-PIR\ncapacity with Protocols 1 and 2, respectively. Furthermore, we present a third\nprotocol, Protocol 3, for the scenario with multiple colluding nodes, which can\nbe seen as an improvement of a protocol recently introduced by Freij-Hollanti\net al.. Similar to the noncolluding case, we provide a necessary and a\nsufficient condition to achieve the maximum possible PIR rate of Protocol 3.\nMoreover, we provide a particular class of codes that is suitable for this\nprotocol and show that RM codes achieve the maximum possible PIR rate for the\nprotocol. For all three protocols, we present an algorithm to optimize their\nPIR rates. \n\n"}
{"id": "1712.04689", "contents": "Title: Energy-Efficient Non-Orthogonal Transmission under Reliability and\n  Finite Blocklength Constraints Abstract: This paper investigates an energy-efficient non-orthogonal transmission\ndesign problem for two downlink receivers that have strict reliability and\nfinite blocklength (latency) constraints. The Shannon capacity formula widely\nused in traditional designs needs the assumption of infinite blocklength and\nthus is no longer appropriate. We adopt the newly finite blocklength coding\ncapacity formula for explicitly specifying the trade-off between reliability\nand code blocklength. However, conventional successive interference\ncancellation (SIC) may become infeasible due to heterogeneous blocklengths. We\nthus consider several scenarios with different channel conditions and\nwith/without SIC. By carefully examining the problem structure, we present in\nclosed-form the optimal power and code blocklength for energy-efficient\ntransmissions. Simulation results provide interesting insights into conditions\nfor which non-orthogonal transmission is more energy efficient than the\northogonal transmission such as TDMA. \n\n"}
{"id": "1712.04930", "contents": "Title: Combination Networks with or without Secrecy Constraints: The Impact of\n  Caching Relays Abstract: This paper considers a two-hop network architecture known as a combination\nnetwork, where a layer of relay nodes connects a server to a set of end users.\nIn particular, a new model is investigated where the intermediate relays employ\ncaches in addition to the end users. First, a new centralized coded caching\nscheme is developed that utilizes maximum distance separable (MDS) coding,\njointly optimizes cache placement and delivery phase, and enables decomposing\nthe combination network into a set virtual multicast sub-networks. It is shown\nthat if the sum of the memory of an end user and its connected relay nodes is\nsufficient to store the database, then the server can disengage in the delivery\nphase and all the end users' requests can be satisfied by the caches in the\nnetwork. Lower bounds on the normalized delivery load using genie-aided cut-set\narguments are presented along with second hop optimality. Next recognizing the\ninformation security concerns of coded caching, this new model is studied under\nthree different secrecy settings: 1) secure delivery where we require an\nexternal entity must not gain any information about the database files by\nobserving the transmitted signals over the network links, 2) secure caching,\nwhere we impose the constraint that end users must not be able to obtain any\ninformation about files that they did not request, and 3) both secure delivery\nand secure caching, simultaneously. We demonstrate how network topology affects\nthe system performance under these secrecy requirements. Finally, we provide\nnumerical results demonstrating the system performance in each of the settings\nconsidered. \n\n"}
{"id": "1712.04980", "contents": "Title: Edge Computing Aware NOMA for 5G Networks Abstract: With the fast development of Internet of things (IoT), the fifth generation\n(5G) wireless networks need to provide massive connectivity of IoT devices and\nmeet the demand for low latency. To satisfy these requirements, Non-Orthogonal\nMultiple Access (NOMA) has been recognized as a promising solution for 5G\nnetworks to significantly improve the network capacity. In parallel with the\ndevelopment of NOMA techniques, Mobile Edge Computing (MEC) is becoming one of\nthe key emerging technologies to reduce the latency and improve the Quality of\nService (QoS) for 5G networks. In order to capture the potential gains of NOMA\nin the context of MEC, this paper proposes an edge computing aware NOMA\ntechnique which can enjoy the benefits of uplink NOMA in reducing MEC users'\nuplink energy consumption. To this end, we formulate a NOMA based optimization\nframework which minimizes the energy consumption of MEC users via optimizing\nthe user clustering, computing and communication resource allocation, and\ntransmit powers. In particular, similar to frequency Resource Blocks (RBs), we\ndivide the computing capacity available at the cloudlet to computing RBs.\nAccordingly, we explore the joint allocation of the frequency and computing RBs\nto the users that are assigned to different order indices within the NOMA\nclusters. We also design an efficient heuristic algorithm for user clustering\nand RBs allocation, and formulate a convex optimization problem for the power\ncontrol to be solved independently per NOMA cluster. The performance of the\nproposed NOMA scheme is evaluated via simulations. \n\n"}
{"id": "1712.05099", "contents": "Title: The Sound and the Fury: Hiding Communications in Noisy Wireless Networks\n  with Interference Uncertainty Abstract: Covert communication can prevent the adversary from knowing that a wireless\ntransmission has occurred. In the additive white Gaussian noise channels, a\nsquare root law is obtained and the result shows that Alice can reliably and\ncovertly transmit $\\mathcal{O}(\\sqrt{n})$ bits to Bob in $n$ channel uses. If\nadditional \"friendly\" node near the adversary can inject artificial noise to\naid Alice in hiding her transmission attempt, covert throughput can be\nimproved, i.e., Alice can covertly transmit\n$\\mathcal{O}(\\min\\{n,\\lambda^{\\alpha/2}\\sqrt{n}\\})$ bits to Bob over $n$ uses\nof the channel ($\\lambda$ is the density of friendly nodes and $\\alpha$ is the\npath loss exponent of wireless channels). In this paper, we consider the covert\ncommunication in a noisy wireless network, where Bob and the adversary Willie\nnot only experience the background noise, but also the aggregated interference\nfrom other transmitters. Our results show that uncertainty in interference\nexperienced by Willie is beneficial to Alice. When the distance between Alice\nand Willie $d_{a,w}=\\omega(n^{\\delta/4})$ ($\\delta=2/\\alpha$ is stability\nexponent), Alice can reliably and covertly transmit\n$\\mathcal{O}(\\log_2\\sqrt{n})$ bits to Bob in $n$ channel uses. Although the\ncovert throughput is lower than the square root law and the friendly jamming\nscheme, the spatial throughput is higher. From the network perspective, the\ncommunications are hidden in \"the sound and the fury\" of noisy wireless\nnetworks, and what Willie sees is merely a \"shadow\" wireless network. He knows\nfor certain that some nodes are transmitting, but he cannot catch anyone\nred-handed. \n\n"}
{"id": "1712.05431", "contents": "Title: Achievability Performance Bounds for Integer-Forcing Source Coding Abstract: Integer-forcing source coding has been proposed as a low-complexity method\nfor compression of distributed correlated Gaussian sources. In this scheme,\neach encoder quantizes its observation using the same fine lattice and reduces\nthe result modulo a coarse lattice. Rather than directly recovering the\nindividual quantized signals, the decoder first recovers a full-rank set of\njudiciously chosen integer linear combinations of the quantized signals, and\nthen inverts it. It has been observed that the method works very well for\n\"most\" but not all source covariance matrices. The present work quantifies the\nmeasure of bad covariance matrices by studying the probability that\ninteger-forcing source coding fails as a function of the allocated rate, %in\nexcess of the %Berger-Tung benchmark, where the probability is with respect to\na random orthonormal transformation that is applied to the sources prior to\nquantization. For the important case where the signals to be compressed\ncorrespond to the antenna inputs of relays in an i.i.d. Rayleigh fading\nenvironment, this orthonormal transformation can be viewed as being performed\nby nature. Hence, the results provide performance guarantees for distributed\nsource coding via integer forcing in this scenario. \n\n"}
{"id": "1712.05702", "contents": "Title: Secret Message Transmission over Quantum Channels under Adversarial\n  Quantum Noise: Secrecy Capacity and Super-Activation Abstract: We determine the secrecy capacities of AVQCs (arbitrarily varying quantum\nchannels). Both secrecy capacity with average error probability and with\nmaximal error probability are derived. Both derivations are based on one common\ncode construction. The code we construct fulfills a stringent secrecy\nrequirement, which is called the strong code concept. We determine when the\nsecrecy capacity is a continuous function of the system parameters and\ncompletely characterize its discontinuity points both for average error\ncriterion and for maximal error criterion. Furthermore, we prove the phenomenon\n\"super-activation\" for secrecy capacities of AVQCs, i.e., two quantum channels\nboth with zero secrecy capacity, which, if used together, allow secure\ntransmission with positive capacity. We also discuss the relations between the\nentanglement distillation capacity, the entanglement generating capacity, and\nthe strong subspace transmission capacity for AVQCs. \n\n"}
{"id": "1712.05908", "contents": "Title: Fingerprinting Cryptographic Protocols with Key Exchange using an\n  Entropy Measure Abstract: Encryption has increasingly been used in all applications for various\npurposes, but it also brings big challenges to network security. In this paper,\nwe take first steps towards addressing some of these chal- lenges by\nintroducing a novel system to identify key exchange protocols, which are\nusually required if encryption keys are not pre-shared. We ob- served that key\nexchange protocols yield certain patterns of high-entropy data blocks, e.g. as\nfound in key material. We propose a multi-resolution approach of accurately\ndetecting high-entropy data blocks and a method of generating scalable\nfingerprints for cryptographic protocols. We pro- vide experimental evidence\nthat our approach has great potential for identifying cryptographic protocols\nby their unique key exchanges, and furthermore for detecting malware traffic\nthat includes customized key exchange protocols. \n\n"}
{"id": "1712.06120", "contents": "Title: Hypothesis Testing for High-Dimensional Multinomials: A Selective Review Abstract: The statistical analysis of discrete data has been the subject of extensive\nstatistical research dating back to the work of Pearson. In this survey we\nreview some recently developed methods for testing hypotheses about\nhigh-dimensional multinomials. Traditional tests like the $\\chi^2$ test and the\nlikelihood ratio test can have poor power in the high-dimensional setting. Much\nof the research in this area has focused on finding tests with asymptotically\nNormal limits and developing (stringent) conditions under which tests have\nNormal limits. We argue that this perspective suffers from a significant\ndeficiency: it can exclude many high-dimensional cases when - despite having\nnon Normal null distributions - carefully designed tests can have high power.\nFinally, we illustrate that taking a minimax perspective and considering\nrefinements of this perspective can lead naturally to powerful and practical\ntests. \n\n"}
{"id": "1712.06793", "contents": "Title: Two-dimensional Anti-jamming Mobile Communication Based on Reinforcement\n  Learning Abstract: By using smart radio devices, a jammer can dynamically change its jamming\npolicy based on opposing security mechanisms; it can even induce the mobile\ndevice to enter a specific communication mode and then launch the jamming\npolicy accordingly. On the other hand, mobile devices can exploit spread\nspectrum and user mobility to address both jamming and interference. In this\npaper, a two-dimensional anti-jamming mobile communication scheme is proposed\nin which a mobile device leaves a heavily jammed/interfered-with frequency or\narea. It is shown that, by applying reinforcement learning techniques, a mobile\ndevice can achieve an optimal communication policy without the need to know the\njamming and interference model and the radio channel model in a dynamic game\nframework. More specifically, a hotbooting deep Q-network based two-dimensional\nmobile communication scheme is proposed that exploits experiences in similar\nscenarios to reduce the exploration time at the beginning of the game, and\napplies deep convolutional neural network and macro-action techniques to\naccelerate the learning speed in dynamic situations. Several real-world\nscenarios are simulated to evaluate the proposed method. These simulation\nresults show that our proposed scheme can improve both the\nsignal-to-interference-plus-noise ratio of the signals and the utility of the\nmobile devices against cooperative jamming compared with benchmark schemes. \n\n"}
{"id": "1712.07078", "contents": "Title: Tables, bounds and graphics of short linear codes with covering radius 3\n  and codimension 4 and 5 Abstract: The length function $\\ell_q(r,R)$ is the smallest length of a $q$-ary linear\ncode of codimension (redundancy) $r$ and covering radius $R$. The $d$-length\nfunction $\\ell_q(r,R,d)$ is the smallest length of a $q$-ary linear code with\ncodimension $r$, covering radius $R$, and minimum distance $d$. By computer\nsearch in wide regions of $q$, we obtained following short codes of covering\nradius $R=3$: $[n,n-4,5]_q3$ quasi-perfect MDS codes, $[n,n-5,5]_q3$\nquasi-perfect Almost MDS codes, and $[n,n-5,3]_q3$ codes. In computer search,\nwe use the step-by-step leximatrix and inverse leximatrix algorithms to obtain\nparity check matrices of codes. The new codes imply the following new upper\nbounds (called lexi-bounds) on the length and $d$-length functions:\n$$\\ell_q(4,3)\\le\\ell_q(4,3,5)<2.8\\sqrt[3]{\\ln q}\\cdot\nq^{(4-3)/3}=2.8\\sqrt[3]{\\ln q}\\cdot\\sqrt[3]{q}=2.8\\sqrt[3]{q\\ln\nq}~\\text{for}~11\\le q\\le7057;$$ $$\\ell_q(5,3)\\le\\ell_q(5,3,5)<3\\sqrt[3]{\\ln\nq}\\cdot q^{(5-3)/3}=3\\sqrt[3]{\\ln q}\\cdot\\sqrt[3]{q^2}=3\\sqrt[3]{q^2\\ln\nq}~~\\text{ for }~37\\le q\\le839.$$ Moreover, we improve the lexi-bounds,\napplying randomized greedy algorithms, and show that $$\\ell_q(4,3)\\le\n\\ell_q(4,3,5)< 2.61\\sqrt[3]{q\\ln q}~\\text{ if }~13\\le q\\le4373;$$\n$$\\ell_q(4,3)\\le \\ell_q(4,3,5)< 2.65\\sqrt[3]{q\\ln q}~\\text{ if\n}~4373<q\\le7057;$$ $$\\ell_q(5,3)<2.785\\sqrt[3]{q^2\\ln q}~\\text{ if }~11\\le\nq\\le401;$$ $$\\ell_q(5,3)\\le\\ell_q(5,3,5)<2.884\\sqrt[3]{q^2\\ln q}~\\text{ if\n}~401<q\\le839.$$ The codes, obtained in this paper by leximatrix and inverse\nleximatrix algorithms, provide new upper bounds (called density lexi-bounds) on\nthe smallest covering density $\\mu_q(r,R)$ of a $q$-ary linear code of\ncodimension $r$ and covering radius $R$: $$\\mu_q(4,3)<3.3\\cdot\\ln q~~\\text{ for\n}~11\\le q\\le7057;$$ $$\\mu_q(5,3)<4.2\\cdot\\ln q~~\\text{ for }~37\\le q\\le839.$$ \n\n"}
{"id": "1712.07182", "contents": "Title: Algebraic lattice codes for linear fading channels Abstract: In the decades following Shannon's work, the quest to design codes for the\nadditive white Gaussian noise (AWGN) channel led to the development of a rich\ntheory, revealing a number of beautiful connections between information theory\nand geometry of numbers. One of the most striking examples is the connection\nbetween classical lattice sphere packing and the capacity of the AWGN channel.\nThe main result states that any family of lattice codes with linearly growing\nHermite invariant achieves a constant gap to capacity. These classical results\nand many more can be found in the comprehensive book by Conway and Sloane\n[5]..... \n\n"}
{"id": "1712.07196", "contents": "Title: Calibrating Noise to Variance in Adaptive Data Analysis Abstract: Datasets are often used multiple times and each successive analysis may\ndepend on the outcome of previous analyses. Standard techniques for ensuring\ngeneralization and statistical validity do not account for this adaptive\ndependence. A recent line of work studies the challenges that arise from such\nadaptive data reuse by considering the problem of answering a sequence of\n\"queries\" about the data distribution where each query may depend arbitrarily\non answers to previous queries.\n  The strongest results obtained for this problem rely on differential privacy\n-- a strong notion of algorithmic stability with the important property that it\n\"composes\" well when data is reused. However the notion is rather strict, as it\nrequires stability under replacement of an arbitrary data element. The simplest\nalgorithm is to add Gaussian (or Laplace) noise to distort the empirical\nanswers. However, analysing this technique using differential privacy yields\nsuboptimal accuracy guarantees when the queries have low variance. Here we\npropose a relaxed notion of stability that also composes adaptively. We\ndemonstrate that a simple and natural algorithm based on adding noise scaled to\nthe standard deviation of the query provides our notion of stability. This\nimplies an algorithm that can answer statistical queries about the dataset with\nsubstantially improved accuracy guarantees for low-variance queries. The only\nprevious approach that provides such accuracy guarantees is based on a more\ninvolved differentially private median-of-means algorithm and its analysis\nexploits stronger \"group\" stability of the algorithm. \n\n"}
{"id": "1712.07365", "contents": "Title: Intelligent Power Control for Spectrum Sharing in Cognitive Radios: A\n  Deep Reinforcement Learning Approach Abstract: We consider the problem of spectrum sharing in a cognitive radio system\nconsisting of a primary user and a secondary user. The primary user and the\nsecondary user work in a non-cooperative manner. Specifically, the primary user\nis assumed to update its transmit power based on a pre-defined power control\npolicy. The secondary user does not have any knowledge about the primary user's\ntransmit power, or its power control strategy. The objective of this paper is\nto develop a learning-based power control method for the secondary user in\norder to share the common spectrum with the primary user. To assist the\nsecondary user, a set of sensor nodes are spatially deployed to collect the\nreceived signal strength information at different locations in the wireless\nenvironment. We develop a deep reinforcement learning-based method, which the\nsecondary user can use to intelligently adjust its transmit power such that\nafter a few rounds of interaction with the primary user, both users can\ntransmit their own data successfully with required qualities of service. Our\nexperimental results show that the secondary user can interact with the primary\nuser efficiently to reach a goal state (defined as a state in which both users\ncan successfully transmit their data) from any initial states within a few\nnumber of steps. \n\n"}
{"id": "1712.07890", "contents": "Title: A Recursive Construction of Permutation Polynomials over\n  $\\mathbb{F}_{q^2}$ with Odd Characteristic from R\\'{e}dei Functions Abstract: In this paper, we construct two classes of permutation polynomials over\n$\\mathbb{F}_{q^2}$ with odd characteristic from rational R\\'{e}dei functions. A\ncomplete characterization of their compositional inverses is also given. These\npermutation polynomials can be generated recursively. As a consequence, we can\ngenerate recursively permutation polynomials with arbitrary number of terms.\nMore importantly, the conditions of these polynomials being permutations are\nvery easy to characterize. For wide applications in practice, several classes\nof permutation binomials and trinomials are given. With the help of a computer,\nwe find that the number of permutation polynomials of these types is very\nlarge. \n\n"}
{"id": "1712.09511", "contents": "Title: Artificial-noise-aided Secure Multicast Precoding for Directional\n  Modulation Systems Abstract: In multi-cast scenario, all desired users are divided into $K$ groups. Each\ngroup receives its own individual confidential message stream. Eavesdropper\ngroup aims to intercept $K$ confidential-message streams. To achieve a secure\ntransmission, two secure schemes are proposed: maximum group receive power plus\nnull-space (NS) projection (Max-GRP plus NSP) and leakage. The former obtains\nits precoding vector per group by maximizing its own group receive power\nsubject to the orthogonal constraint, and its AN projection matrix consist of\nall bases of NS of all desired steering vectors from all groups. The latter\nattains its desired precoding vector per group by driving the current\nconfidential message power to its group steering space and reducing its power\nleakage to eavesdropper group and other $K-1$ desired ones by maximizing signal\nto leakage and noise ratio (Max-SLNR). And its AN projection matrix is designed\nby forcing AN power into the eavesdropper steering space by viewing AN as a\nuseful signal for eavesdropper group and maximizing AN to leakage-and-noise\nratio (Max-ANLNR). Simulation results show that the proposed two methods are\nbetter than conventional method in terms of both bit-error-rate (BER) and\nsecrecy sum-rate per group. Also, the leakage scheme performs better than\nMax-GRP-NSP , especially in the presence of direction measurement errors.\nHowever, the latter requires no channel statistical parameters and thus is\nsimpler compared to the former. \n\n"}
{"id": "1712.10061", "contents": "Title: The Age of Information in Multihop Networks Abstract: Information updates in multihop networks such as Internet of Things (IoT) and\nintelligent transportation systems have received significant recent attention.\nIn this paper, we minimize the age of a single information flow in\ninterference-free multihop networks. When preemption is allowed and the packet\ntransmission times are exponentially distributed, we prove that a preemptive\nLast-Generated, First-Served (LGFS) policy results in smaller age processes\nacross all nodes in the network than any other causal policy (in a stochastic\nordering sense). In addition, for the class of New-Better-than-Used (NBU)\ndistributions, we show that the non-preemptive LGFS policy is within a constant\nage gap from the optimum average age. In contrast, our numerical result shows\nthat the preemptive LGFS policy can be very far from the optimum for some NBU\ntransmission time distributions. Finally, when preemption is prohibited and the\npacket transmission times are arbitrarily distributed, the non-preemptive LGFS\npolicy is shown to minimize the age processes across all nodes in the network\namong all work-conserving policies (again in a stochastic ordering sense).\nInterestingly, these results hold under quite general conditions, including (i)\narbitrary packet generation and arrival times, and (ii) for minimizing both the\nage processes in stochastic ordering and any non-decreasing functional of the\nage processes. \n\n"}
{"id": "1801.00518", "contents": "Title: Statistical and Computational Limits for Sparse Matrix Detection Abstract: This paper investigates the fundamental limits for detecting a\nhigh-dimensional sparse matrix contaminated by white Gaussian noise from both\nthe statistical and computational perspectives. We consider $p\\times p$\nmatrices whose rows and columns are individually $k$-sparse. We provide a tight\ncharacterization of the statistical and computational limits for sparse matrix\ndetection, which precisely describe when achieving optimal detection is easy,\nhard, or impossible, respectively. Although the sparse matrices considered in\nthis paper have no apparent submatrix structure and the corresponding\nestimation problem has no computational issue at all, the detection problem has\na surprising computational barrier when the sparsity level $k$ exceeds the\ncubic root of the matrix size $p$: attaining the optimal detection boundary is\ncomputationally at least as hard as solving the planted clique problem.\n  The same statistical and computational limits also hold in the sparse\ncovariance matrix model, where each variable is correlated with at most $k$\nothers. A key step in the construction of the statistically optimal test is a\nstructural property for sparse matrices, which can be of independent interest. \n\n"}
{"id": "1801.00606", "contents": "Title: Secrecy Capacity-Memory Tradeoff of Erasure Broadcast Channels Abstract: This paper derives upper and lower bounds on the secrecy capacity-memory\ntradeoff of a wiretap erasure broadcast channel (BC) with Kw weak receivers and\nKs strong receivers, where weak receivers, respectively strong receivers, have\nsame erasure probabilities and cache sizes. The lower bounds are achieved by\nschemes that meticulously combine joint cache-channel coding with wiretap\ncoding and key-aided one-time pads. The presented upper bound holds more\ngenerally for arbitrary degraded BCs and arbitrary cache sizes. When only weak\nreceivers have cache memories, upper and lower bounds coincide for small and\nlarge cache memories, thus providing the exact secrecy capacity-memory tradeoff\nfor this setup. The derived bounds allow to further conclude that the secrecy\ncapacity is positive even when the eavesdropper is stronger than all the\nlegitimate receivers with cache memories. Moreover, they show that the secrecy\ncapacity-memory tradeoff can be significantly smaller than its non-secure\ncounterpart, but it grows much faster when cache memories are small. The paper\nalso presents a lower bound on the global secrecy capacity-memory tradeoff\nwhere one is allowed to optimize the cache assignment subject to a total cache\nbudget. It is close to the best known lower bound without secrecy constraint.\nFor small total cache budget, the global secrecy capacity-memory tradeoff is\nachieved by assigning all the available cache memory uniformly over all\nreceivers if the eavesdropper is stronger than all legitimate receivers, and it\nis achieved by assigning the cache memory uniformly only over the weak\nreceivers if the eavesdropper is weaker than the strong receivers. \n\n"}
{"id": "1801.00823", "contents": "Title: MVG Mechanism: Differential Privacy under Matrix-Valued Query Abstract: Differential privacy mechanism design has traditionally been tailored for a\nscalar-valued query function. Although many mechanisms such as the Laplace and\nGaussian mechanisms can be extended to a matrix-valued query function by adding\ni.i.d. noise to each element of the matrix, this method is often suboptimal as\nit forfeits an opportunity to exploit the structural characteristics typically\nassociated with matrix analysis. To address this challenge, we propose a novel\ndifferential privacy mechanism called the Matrix-Variate Gaussian (MVG)\nmechanism, which adds a matrix-valued noise drawn from a matrix-variate\nGaussian distribution, and we rigorously prove that the MVG mechanism preserves\n$(\\epsilon,\\delta)$-differential privacy. Furthermore, we introduce the concept\nof directional noise made possible by the design of the MVG mechanism.\nDirectional noise allows the impact of the noise on the utility of the\nmatrix-valued query function to be moderated. Finally, we experimentally\ndemonstrate the performance of our mechanism using three matrix-valued queries\non three privacy-sensitive datasets. We find that the MVG mechanism notably\noutperforms four previous state-of-the-art approaches, and provides comparable\nutility to the non-private baseline. \n\n"}
{"id": "1801.01170", "contents": "Title: Optimization-based AMP for Phase Retrieval: The Impact of Initialization\n  and $\\ell_2$-regularization Abstract: We consider an $\\ell_2$-regularized non-convex optimization problem for\nrecovering signals from their noisy phaseless observations. We design and study\nthe performance of a message passing algorithm that aims to solve this\noptimization problem. We consider the asymptotic setting $m,n \\rightarrow\n\\infty$, $m/n \\rightarrow \\delta$ and obtain sharp performance bounds, where\n$m$ is the number of measurements and $n$ is the signal dimension. We show that\nfor complex signals the algorithm can perform accurate recovery with only $m=\n\\left(\\frac{64}{\\pi^2}-4\\right)n \\approx 2.5n$ measurements. Also, we provide\nsharp analysis on the sensitivity of the algorithm to noise. We highlight the\nfollowing facts about our message passing algorithm: (i) Adding $\\ell_2$\nregularization to the non-convex loss function can be beneficial. (ii) Spectral\ninitialization has marginal impact on the performance of the algorithm. The\nsharp analyses in this paper, not only enable us to compare the performance of\nour method with other phase recovery schemes, but also shed light on designing\nbetter iterative algorithms for other non-convex optimization problems. \n\n"}
{"id": "1801.01633", "contents": "Title: Understanding Android Obfuscation Techniques: A Large-Scale\n  Investigation in the Wild Abstract: In this paper, we seek to better understand Android obfuscation and depict a\nholistic view of the usage of obfuscation through a large-scale investigation\nin the wild. In particular, we focus on four popular obfuscation approaches:\nidentifier renaming, string encryption, Java reflection, and packing. To obtain\nthe meaningful statistical results, we designed efficient and lightweight\ndetection models for each obfuscation technique and applied them to our massive\nAPK datasets (collected from Google Play, multiple third-party markets, and\nmalware databases). We have learned several interesting facts from the result.\nFor example, malware authors use string encryption more frequently, and more\napps on third-party markets than Google Play are packed. We are also interested\nin the explanation of each finding. Therefore we carry out in-depth code\nanalysis on some Android apps after sampling. We believe our study will help\ndevelopers select the most suitable obfuscation approach, and in the meantime\nhelp researchers improve code analysis systems in the right direction. \n\n"}
{"id": "1801.02310", "contents": "Title: Efficient Encoding/Decoding of Irreducible Words for Codes Correcting\n  Tandem Duplications Abstract: Tandem duplication is the process of inserting a copy of a segment of DNA\nadjacent to the original position. Motivated by applications that store data in\nliving organisms, Jain et al. (2017) proposed the study of codes that correct\ntandem duplications. Known code constructions are based on {\\em irreducible\nwords}.\n  We study efficient encoding/decoding methods for irreducible words. First, we\ndescribe an $(\\ell,m)$-finite state encoder and show that when\n$m=\\Theta(1/\\epsilon)$ and $\\ell=\\Theta(1/\\epsilon)$, the encoder achieves rate\nthat is $\\epsilon$ away from the optimal. Next, we provide ranking/unranking\nalgorithms for irreducible words and modify the algorithms to reduce the space\nrequirements for the finite state encoder. \n\n"}
{"id": "1801.02324", "contents": "Title: Building Capacity-Achieving PIR Schemes with Optimal Sub-Packetization\n  over Small Fields Abstract: Suppose a database containing $M$ records is replicated across $N$ servers,\nand a user wants to privately retrieve one record by accessing the servers such\nthat identity of the retrieved record is secret against any up to $T$ servers.\nA scheme designed for this purpose is called a $T$-private information\nretrieval ($T$-PIR) scheme. Three indexes are concerned for PIR schemes:\n(1)rate, indicating the amount of retrieved information per unit of downloaded\ndata. The highest achievable rate is characterized by the capacity; (2)\nsub-packetization, reflexing the implementation complexity for linear schemes;\n(3) field size. We consider linear schemes over a finite field. In this paper,\na general $T$-PIR scheme simultaneously attaining the optimality of almost all\nof the three indexes is presented. Specifically, we design a linear\ncapacity-achieving $T$-PIR scheme with sub-packetization $\\!dn^{M-1}\\!$ over a\nfinite field $\\mathbb{F}_q$, $q\\geq N$. The sub-packetization $\\!dn^{M-1}\\!$,\nwhere $\\!d\\!=\\!{\\rm gcd}(N,T)\\!$ and $\\!n\\!=\\!N/d$, has been proved to be\noptimal in our previous work. The field size of all existing capacity-achieving\n$T$-PIR schemes must be larger than $Nt^{M-2}$ where $t=T/d$, while our scheme\nreduces the field size by an exponential factor. \n\n"}
{"id": "1801.02563", "contents": "Title: Information Theoretic Security for Side-Channel Attacks to the Shannon\n  Cipher System Abstract: We study side-channel attacks for the Shannon cipher system. To pose side\nchannel-attacks to the Shannon cipher system, we regard them as a signal\nestimation via encoded data from two distributed sensors. This can be\nformulated as the one helper source coding problem posed and investigated by\nAhlswede, K\\\"orner(1975), and Wyner(1975). We further investigate the posed\nproblem to derive new secrecy bounds. Our results are derived by a coupling of\nthe result Watanabe and Oohama(2012) obtained on bounded storage evasdropper\nwith the exponential strong converse theorem Oohama(2015) established for the\none helper source coding problem. \n\n"}
{"id": "1801.02743", "contents": "Title: Enhancing Performance of Random Caching in Large-Scale Wireless Networks\n  with Multiple Receive Antennas Abstract: To improve signal-to-interference ratio (SIR) and make better use of file\ndiversity provided by random caching, we consider two types of linear\nreceivers, i.e., maximal ratio combining (MRC) receiver and partial zero\nforcing (PZF) receiver, at users in a large-scale cache-enabled single-input\nmulti-output (SIMO) network. First, for each receiver, by utilizing tools from\nstochastic geometry, we derive a tractable expression and a tight upper bound\nfor the successful transmission probability (STP). In the case of the MRC\nreceiver, we also derive a closed-form expression for the asymptotic outage\nprobability in the low SIR threshold regime. Then, for each receiver, we\nmaximize the STP. In the case of the MRC receiver, we consider the maximization\nof the tight upper bound on the STP by optimizing the caching distribution,\nwhich is a non-convex problem. We obtain a stationary point, by solving an\nequivalent difference of convex (DC) programming problem using concave-convex\nprocedure (CCCP). We also obtain a closed-form asymptotically optimal solution\nin the low SIR threshold regime. In the case of the PZF receiver, we consider\nthe maximization of the tight upper bound on the STP by optimizing the caching\ndistribution and the degrees of freedom (DoF) allocation (for boosting the\nsignal power), which is a mixed discrete-continuous problem. Based on\nstructural properties, we obtain a low-complexity near optimal solution by\nusing an alternating optimization approach. The analysis and optimization\nresults reveal the impact of antenna resource at users on random caching.\nFinally, by numerical results, we show that the random caching design with the\nPZF receiver achieves significant performance gains over the random caching\ndesign with the MRC receiver and some baseline caching designs. \n\n"}
{"id": "1801.02850", "contents": "Title: Less is More: Culling the Training Set to Improve Robustness of Deep\n  Neural Networks Abstract: Deep neural networks are vulnerable to adversarial examples. Prior defenses\nattempted to make deep networks more robust by either changing the network\narchitecture or augmenting the training set with adversarial examples, but both\nhave inherent limitations. Motivated by recent research that shows outliers in\nthe training set have a high negative influence on the trained model, we\nstudied the relationship between model robustness and the quality of the\ntraining set. We first show that outliers give the model better generalization\nability but weaker robustness. Next, we propose an adversarial example\ndetection framework, in which we design two methods for removing outliers from\ntraining set to obtain the sanitized model and then detect adversarial example\nby calculating the difference of outputs between the original and the sanitized\nmodel. We evaluated the framework on both MNIST and SVHN. Based on the\ndifference measured by Kullback-Leibler divergence, we could detect adversarial\nexamples with accuracy between 94.67% to 99.89%. \n\n"}
{"id": "1801.04035", "contents": "Title: EdgeChain: Blockchain-based Multi-vendor Mobile Edge Application\n  Placement Abstract: The state-of-the-art mobile edge applications are generating intense traffic\nand posing rigorous latency requirements to service providers. While resource\nsharing across multiple service providers can be a way to maximize the\nutilization of limited resources at the network edge, it requires a centralized\nrepository maintained by all parties for service providers to share status.\nMoreover, service providers have to trust each other for resource allocation\nfairness, which is difficult because of potential conflicts of interest. We\npropose EdgeChain, a blockchain-based architecture to make mobile edge\napplication placement decisions for multiple service providers. We first\nformulate a stochastic programming problem minimizing the placement cost for\nmobile edge application placement scenarios. Based on our model, we present a\nheuristic mobile edge application placement algorithm. As a decentralized\npublic ledger, the blockchain then takes the logic of our algorithm as the\nsmart contract, with the consideration of resources from all mobile edge hosts\nparticipating in the system. The algorithm is agreed by all parties and the\nresults will only be accepted by majority of the mining nodes on the\nblockchain. When a placement decision is made, an edge host meeting the\nconsumer's latency and budget requirements will be selected at the lowest cost.\nAll placement transactions are stored on the blockchain and are traceable by\nevery mobile edge service provider and application vendor who consumes\nresources at the mobile edge. \n\n"}
{"id": "1801.04299", "contents": "Title: Belief Propagation Decoding of Polar Codes on Permuted Factor Graphs Abstract: We show that the performance of iterative belief propagation (BP) decoding of\npolar codes can be enhanced by decoding over different carefully chosen factor\ngraph realizations. With a genie-aided stopping condition, it can achieve the\nsuccessive cancellation list (SCL) decoding performance which has already been\nshown to achieve the maximum likelihood (ML) bound provided that the list size\nis sufficiently large. The proposed decoder is based on different realizations\nof the polar code factor graph with randomly permuted stages during decoding.\nAdditionally, a different way of visualizing the polar code factor graph is\npresented, facilitating the analysis of the underlying factor graph and the\ncomparison of different graph permutations. In our proposed decoder, a high\nrate Cyclic Redundancy Check (CRC) code is concatenated with a polar code and\nused as an iteration stopping criterion (i.e., genie) to even outperform the\nSCL decoder of the plain polar code (without the CRC-aid). Although our\npermuted factor graph-based decoder does not outperform the SCL-CRC decoder, it\nachieves, to the best of our knowledge, the best performance of all iterative\npolar decoders presented thus far. \n\n"}
{"id": "1801.04613", "contents": "Title: Software Defined Networks based Smart Grid Communication: A\n  Comprehensive Survey Abstract: The current power grid is no longer a feasible solution due to\never-increasing user demand of electricity, old infrastructure, and reliability\nissues and thus require transformation to a better grid a.k.a., smart grid\n(SG). The key features that distinguish SG from the conventional electrical\npower grid are its capability to perform two-way communication, demand side\nmanagement, and real time pricing. Despite all these advantages that SG will\nbring, there are certain issues which are specific to SG communication system.\nFor instance, network management of current SG systems is complex, time\nconsuming, and done manually. Moreover, SG communication (SGC) system is built\non different vendor specific devices and protocols. Therefore, the current SG\nsystems are not protocol independent, thus leading to interoperability issue.\nSoftware defined network (SDN) has been proposed to monitor and manage the\ncommunication networks globally. This article serves as a comprehensive survey\non SDN-based SGC. In this article, we first discuss taxonomy of advantages of\nSDNbased SGC.We then discuss SDN-based SGC architectures, along with case\nstudies. Our article provides an in-depth discussion on routing schemes for\nSDN-based SGC. We also provide detailed survey of security and privacy schemes\napplied to SDN-based SGC. We furthermore present challenges, open issues, and\nfuture research directions related to SDN-based SGC. \n\n"}
{"id": "1801.05112", "contents": "Title: Exact Error and Erasure Exponents for the Asymmetric Broadcast Channel Abstract: Consider the asymmetric broadcast channel with a random superposition\ncodebook, which may be comprised of constant composition or \\iid codewords. By\napplying Forney's optimal decoder for individual messages and the message pair\nfor the receiver that decodes both messages, exact (ensemble-tight) error and\nerasure exponents are derived. It is shown that the optimal decoder designed to\ndecode the pair of messages achieves the optimal trade-off between the total\nand undetected exponents associated with the optimal decoder for the private\nmessage. Convex optimization-based procedures to evaluate the exponents\nefficiently are proposed. Finally, numerical examples are presented to\nillustrate the results. \n\n"}
{"id": "1801.05240", "contents": "Title: de Finetti reductions for partially exchangeable probability\n  distributions Abstract: We introduce a general framework for de Finetti reduction results, applicable\nto various notions of partially exchangeable probability distributions.\nExplicit statements are derived for the cases of exchangeability, Markov\nexchangeability, and some generalizations of these. Our techniques are\ncombinatorial and rely on the \"BEST\" theorem, enumerating the Eulerian cycles\nof a multigraph. \n\n"}
{"id": "1801.05707", "contents": "Title: Quantum dynamical mode (QDM): A possible extension of belief function Abstract: Dempster-Shafer evidence theory has been widely used in various fields of\napplications, because of the flexibility and effectiveness in modeling\nuncertainties without prior information. Besides, it has been proven that the\nquantum theory has powerful capabilities of solving the decision making\nproblems, especially for modelling human decision and cognition. However, the\nclassical Dempster-Shafer evidence theory modelled by real numbers cannot be\nintegrated directly with the quantum theory modelled by complex numbers. So,\nhow can we establish a bridge of communications between the classical\nDempster-Shafer evidence theory and the quantum theory? To answer this\nquestion, a generalized Dempster-Shafer evidence theory is proposed in this\npaper. The main contribution in this study is that, unlike the existing\nevidence theory, a mass function in the generalized Dempster-Shafer evidence\ntheory is modelled by a complex number, called as a complex mass function. In\naddition, compared with the classical Dempster's combination rule, the\ncondition in terms of the conflict coefficient between two evidences K < 1 is\nreleased in the generalized Dempster's combination rule so that it is more\ngeneral and applicable than the classical Dempster's combination rule. When the\ncomplex mass function is degenerated from complex numbers to real numbers, the\ngeneralized Dempster's combination rule degenerates to the classical evidence\ntheory under the condition that the conflict coefficient between the evidences\nK is less than 1. Numerical examples are illustrated to show the efficiency of\nthe generalized Dempster-Shafer evidence theory. Finally, an application of an\nevidential quantum dynamical model is implemented by integrating the\ngeneralized Dempster-Shafer evidence theory with the quantum dynamical model.\nFrom the experimental results, it validates the feasibility and effectiveness\nof the proposed method. \n\n"}
{"id": "1801.05870", "contents": "Title: Quantized Compressive Sensing with RIP Matrices: The Benefit of\n  Dithering Abstract: Quantized compressive sensing (QCS) deals with the problem of coding\ncompressive measurements of low-complexity signals with quantized, finite\nprecision representations, i.e., a mandatory process involved in any practical\nsensing model. While the resolution of this quantization clearly impacts the\nquality of signal reconstruction, there actually exist incompatible\ncombinations of quantization functions and sensing matrices that proscribe\narbitrarily low reconstruction error when the number of measurements increases.\nThis work shows that a large class of random matrix constructions known to\nrespect the restricted isometry property (RIP) is \"compatible\" with a simple\nscalar and uniform quantization if a uniform random vector, or a random dither,\nis added to the compressive signal measurements before quantization. In the\ncontext of estimating low-complexity signals (e.g., sparse or compressible\nsignals, low-rank matrices) from their quantized observations, this\ncompatibility is demonstrated by the existence of (at least) one signal\nreconstruction method, the projected back projection (PBP), whose\nreconstruction error decays when the number of measurements increases.\nInterestingly, given one RIP matrix and a single realization of the dither, a\nsmall reconstruction error can be proved to hold uniformly for all signals in\nthe considered low-complexity set. We confirm these observations numerically in\nseveral scenarios involving sparse signals, low-rank matrices, and compressible\nsignals, with various RIP matrix constructions such as sub-Gaussian random\nmatrices and random partial discrete cosine transform (DCT) matrices. \n\n"}
{"id": "1801.05948", "contents": "Title: Uplink Coverage Performance of an Underlay Drone Cell for Temporary\n  Events Abstract: Using a drone as an aerial base station (ABS) to provide coverage to users on\nthe ground is envisaged as a promising solution for beyond fifth generation\n(beyond-5G) wireless networks. While the literature to date has examined\ndownlink cellular networks with ABSs, we consider an uplink cellular network\nwith an ABS. Specifically, we analyze the use of an underlay ABS to provide\ncoverage for a temporary event, such as a sporting event or a concert in a\nstadium. Using stochastic geometry, we derive the analytical expressions for\nthe uplink coverage probability of the terrestrial base station (TBS) and the\nABS. The results are expressed in terms of (i) the Laplace transforms of the\ninterference power distribution at the TBS and the ABS and (ii) the distance\ndistribution between the ABS and an independently and uniformly distributed\n(i.u.d.) ABS-supported user equipment and between the ABS and an i.u.d.\nTBS-supported user equipment. The accuracy of the analytical results is\nverified by Monte Carlo simulations. Our results show that varying the ABS\nheight leads to a trade-off between the uplink coverage probability of the TBS\nand the ABS. In addition, assuming a quality of service of 90% at the TBS, an\nuplink coverage probability of the ABS of over 85% can be achieved, with the\nABS deployed at or below its optimal height of typically between 250-500 m for\nthe considered setup. \n\n"}
{"id": "1801.06022", "contents": "Title: Reconstruction Codes for DNA Sequences with Uniform Tandem-Duplication\n  Errors Abstract: DNA as a data storage medium has several advantages, including far greater\ndata density compared to electronic media. We propose that schemes for data\nstorage in the DNA of living organisms may benefit from studying the\nreconstruction problem, which is applicable whenever multiple reads of noisy\ndata are available. This strategy is uniquely suited to the medium, which\ninherently replicates stored data in multiple distinct ways, caused by\nmutations. We consider noise introduced solely by uniform tandem-duplication,\nand utilize the relation to constant-weight integer codes in the Manhattan\nmetric. By bounding the intersection of the cross-polytope with hyperplanes, we\nprove the existence of reconstruction codes with greater capacity than known\nerror-correcting codes, which we can determine analytically for any set of\nparameters. \n\n"}
{"id": "1801.06358", "contents": "Title: Sparse recovery based on q-ratio constrained minimal singular values Abstract: We study verifiable sufficient conditions and computable performance bounds\nfor sparse recovery algorithms such as the Basis Pursuit, the Dantzig selector\nand the Lasso estimator, in terms of a newly defined family of quality measures\nfor the measurement matrices. With high probability, the developed measures for\nsubgaussian random matrices are bounded away from zero as long as the number of\nmeasurements is reasonably large. Comparing to the restricted isotropic\nconstant based performance analysis, the arguments in this paper are much more\nconcise and the obtained bounds are tighter. Numerical experiments are\npresented to illustrate our theoretical results. \n\n"}
{"id": "1801.07379", "contents": "Title: Secure Mobile Crowdsensing with Deep Learning Abstract: In order to stimulate secure sensing for Internet of Things (IoT)\napplications such as healthcare and traffic monitoring, mobile crowdsensing\n(MCS) systems have to address security threats, such as jamming, spoofing and\nfaked sensing attacks, during both the sensing and the information exchange\nprocesses in large-scale dynamic and heterogenous networks. In this article, we\ninvestigate secure mobile crowdsensing and present how to use deep learning\n(DL) methods such as stacked autoencoder (SAE), deep neural network (DNN), and\nconvolutional neural network (CNN) to improve the MCS security approaches\nincluding authentication, privacy protection, faked sensing countermeasures,\nintrusion detection and anti-jamming transmissions in MCS. We discuss the\nperformance gain of these DL-based approaches compared with traditional\nsecurity schemes and identify the challenges that need to be addressed to\nimplement them in practical MCS systems. \n\n"}
{"id": "1801.08590", "contents": "Title: Individual testing is optimal for nonadaptive group testing in the\n  linear regime Abstract: We consider nonadaptive probabilistic group testing in the linear regime,\nwhere each of n items is defective independently with probability p in (0,1),\nand p is a constant independent of n. We show that testing each item\nindividually is optimal, in the sense that with fewer than n tests the error\nprobability is bounded away from zero. \n\n"}
{"id": "1801.09176", "contents": "Title: Mitigating Pilot Contamination in Multi-cell Hybrid Millimeter Wave\n  Systems Abstract: In this paper, we investigate the system performance of a multi-cell\nmulti-user (MU) hybrid millimeter wave (mmWave) multiple-input multiple-output\n(MIMO) network adopting the channel estimation algorithm proposed in [1] for\nchannel estimation. Due to the reuse of orthogonal pilot symbols among\ndifferent cells, the channel estimation is expected to be affected by pilot\ncontamination, which is considered as a fundamental performance bottleneck of\nconventional multicell MU massive MIMO networks. To analyze the impact of pilot\ncontamination on the system performance, we derive the closed-form\napproximation expression of the normalized mean squared error (MSE) of the\nchannel estimation performance. Our analytical and simulation results show that\nthe channel estimation error incurred by the impact of pilot contamination and\nnoise vanishes asymptotically with an increasing number of antennas equipped at\neach radio frequency (RF) chain deployed at the desired BS. Thus, pilot\ncontamination is no longer the fundamental problem for multi-cell hybrid mmWave\nsystems. \n\n"}
{"id": "1801.10117", "contents": "Title: PrivPy: Enabling Scalable and General Privacy-Preserving Machine\n  Learning Abstract: We introduce PrivPy, a practical privacy-preserving collaborative computation\nframework, especially optimized for machine learning tasks. PrivPy provides an\neasy-to-use and highly compatible Python programming front-end which supports\nhigh-level array operations and different secure computation engines to allow\nfor security assumptions and performance trade-offs. With PrivPy, programmers\ncan write modern machine learning algorithms conveniently and efficiently in\nPython. We also design and implement a new efficient computation engine, with\nwhich people can use competing cloud providers to efficiently perform general\narithmetics over real numbers. We demonstrate the usability and scalability of\nPrivPy using common machine learning models (e.g. logistic regression and\nconvolutional neural networks) and real-world datasets (including a\n5000-by-1-million matrix). \n\n"}
{"id": "1801.10282", "contents": "Title: Stochastic Optimization and Control Framework for 5G Network Slicing\n  with Effective Isolation Abstract: Network slicing is an emerging technique for providing resources to diverse\nwireless services with heterogeneous quality-of-service needs. However, beyond\nsatisfying end-to-end requirements of network users, network slicing needs to\nalso provide isolation between slices so as to prevent one slice's faults and\ncongestion from affecting other slices. In this paper, the problem of network\nslicing is studied in the context of a wireless system having a time-varying\nnumber of users that require two types of slices: reliable low latency (RLL)\nand self-managed (capacity limited) slices. To address this problem, a novel\ncontrol framework for stochastic optimization is proposed based on the Lyapunov\ndrift-plus-penalty method. This new framework enables the system to minimize\npower, maintain slice isolation, and provide reliable and low latency\nend-to-end communication for RLL slices. Simulation results show that the\nproposed approach can maintain the system's reliability while providing\neffective slice isolation in the event of sudden changes in the network\nenvironment. \n\n"}
{"id": "1801.10433", "contents": "Title: Hierarchical restricted isometry property for Kronecker product\n  measurements Abstract: Hierarchically sparse signals and Kronecker product structured measurements\narise naturally in a variety of applications. The simplest example of a\nhierarchical sparsity structure is two-level $(s,\\sigma)$-hierarchical sparsity\nwhich features $s$-block-sparse signals with $\\sigma$-sparse blocks. For a\nlarge class of algorithms recovery guarantees can be derived based on the\nrestricted isometry property (RIP) of the measurement matrix and model-based\nvariants thereof. We show that given two matrices $\\mathbf{A}$ and $\\mathbf{B}$\nhaving the standard $s$-sparse and $\\sigma$-sparse RIP their Kronecker product\n$\\mathbf{A}\\otimes\\mathbf{B}$ has two-level $(s,\\sigma)$-hierarchically sparse\nRIP (HiRIP). This result can be recursively generalized to signals with\nmultiple hierarchical sparsity levels and measurements with multiple Kronecker\nproduct factors. As a corollary we establish the efficient reconstruction of\nhierarchical sparse signals from Kronecker product measurements using the HiHTP\nalgorithm. We argue that Kronecker product measurement matrices allow to design\nlarge practical compressed sensing systems that are deterministically certified\nto reliably recover signals in a stable fashion. We elaborate on their\nmotivation from the perspective of applications. \n\n"}
{"id": "1801.10484", "contents": "Title: Cache-Aided Non-Orthogonal Multiple Access: The Two-User Case Abstract: In this paper, we propose a cache-aided non-orthogonal multiple access (NOMA)\nscheme for spectrally efficient downlink transmission. The proposed scheme not\nonly reaps the benefits associated with NOMA and caching, but also exploits the\ndata cached at the users for interference cancellation. As a consequence,\ncaching can help to reduce the residual interference power, making multiple\ndecoding orders at the users feasible. The resulting flexibility in decoding\ncan be exploited for improved NOMA detection. We characterize the achievable\nrate region of cache-aided NOMA and derive the Pareto optimal rate tuples\nforming the boundary of the rate region. Moreover, we optimize cache-aided NOMA\nfor minimization of the time required for completing file delivery. The optimal\ndecoding order and the optimal transmit power and rate allocation are derived\nas functions of the cache status, the file sizes, and the channel conditions.\nSimulation results confirm that, compared to several baseline schemes, the\nproposed cache-aided NOMA scheme significantly expands the achievable rate\nregion and increases the sum rate for downlink transmission, which translates\ninto substantially reduced file delivery times. \n\n"}
{"id": "1802.00476", "contents": "Title: On a fractional version of Haemers' bound Abstract: In this note, we present a fractional version of Haemers' bound on the\nShannon capacity of a graph, which is originally due to Blasiak. This bound is\na common strengthening of both Haemers' bound and the fractional chromatic\nnumber of a graph. We show that this fractional version outperforms any bound\non the Shannon capacity that could be attained through Haemers' bound. We show\nalso that this bound is multiplicative, unlike Haemers' bound. \n\n"}
{"id": "1802.01806", "contents": "Title: Detection of persistent signals and its relation to coherent feedforward\n  loops Abstract: Many studies have shown that cells use temporal dynamics of signalling\nmolecules to encode information. One particular class of temporal dynamics is\npersistent and transient signals, i.e. signals of long and short durations\nrespectively. It has been shown that the coherent type-1 feedforward loop with\nan AND logic at the output (or C1-FFL for short) can be used to discriminate a\npersistent input signal from a transient one. This has been done by modelling\nthe C1-FFL, and then use the model to show that persistent and transient input\nsignals give, respectively, a non-zero and zero output. Instead of assuming the\nstructure of C1-FFL, this paper shows that it is possible to deduce the C1-FFL\nmodel from the requirement of discriminating a persistent signal. We do this by\nfirst formulating a statistical detection problem of distinguishing persistent\nsignals from transient ones. The solution of the detection problem is to\ncompute the log-likelihood ratio of observing a persistent signal to a\ntransient signal. We show that, if this log-likelihood ratio is positive, which\nhappens when the signal is likely to be persistent, then it can be\napproximately computed by a C1-FFL. Although the capability of C1-FFL to\ndiscriminate persistent signals is known, this paper adds an information\nprocessing interpretation on how a C1-FFL works as a detector of persistent\nsignals. \n\n"}
{"id": "1802.05856", "contents": "Title: Algorithmic Complexity and Reprogrammability of Chemical Structure\n  Networks Abstract: Here we address the challenge of profiling causal properties and tracking the\ntransformation of chemical compounds from an algorithmic perspective. We\nexplore the potential of applying a computational interventional calculus based\non the principles of algorithmic probability to chemical structure networks. We\nprofile the sensitivity of the elements and covalent bonds in a chemical\nstructure network algorithmically, asking whether reprogrammability affords\ninformation about thermodynamic and chemical processes involved in the\ntransformation of different compound classes. We arrive at numerical results\nsuggesting a correspondence between some physical, structural and functional\nproperties. Our methods are capable of separating chemical classes that reflect\nfunctional and natural differences without considering any information about\natomic and molecular properties. We conclude that these methods, with their\nlinks to chemoinformatics via algorithmic, probability hold promise for future\nresearch. \n\n"}
{"id": "1802.05973", "contents": "Title: Information Rates and Error Exponents for Probabilistic Amplitude\n  Shaping Abstract: Probabilistic Amplitude Shaping (PAS) is a coded-modulation scheme in which\nthe encoder is a concatenation of a distribution matcher with a systematic\nForward Error Correction (FEC) code. For reduced computational complexity the\ndecoder can be chosen as a concatenation of a mismatched FEC decoder and\ndematcher. This work studies the theoretic limits of PAS. The classical joint\nsource-channel coding (JSCC) setup is modified to include systematic FEC and\nthe mismatched FEC decoder. At each step error exponents and achievable rates\nfor the corresponding setup are derived. \n\n"}
{"id": "1802.06910", "contents": "Title: Single or Multiple Frames Content Delivery for Next-Generation Networks? Abstract: This paper addresses the four enabling technologies, namely multi-user sparse\ncode multiple access (SCMA), content caching, energy harvesting, and physical\nlayer security for proposing an energy and spectral efficient resource\nallocation algorithm for the access and backhaul links in heterogeneous\ncellular networks. Although each of the above mentioned issues could be a topic\nof research, in a real situation, we would face a complicated scenario where\nthey should be considered jointly, and hence, our target is to consider these\ntechnologies jointly in a unified framework. Moreover, we propose two novel\ncontent delivery scenarios: 1) single frame content delivery (SFCD), and 2)\nmultiple frames content delivery (MFCD), where the time duration of serving\nuser requests is divided into several frames. In the first scenario, the\nrequested content by each user is served over one frame. However, in the second\nscenario, the requested content by each user can be delivered over several\nframes. We formulate the resource allocation for the proposed scenarios as\noptimization problems where our main aim is to maximize the energy efficiency\nof access links subject to the transmit power and rate constraints of access\nand backhaul links, caching and energy harvesting constraints, and SCMA\ncodebook allocation limitations. Due to the practical limitations, we assume\nthat the channel state information values between eavesdroppers and base\nstations are uncertain and design the network for the worst case scenario.\nSince the corresponding optimization problems are mixed integer non-linear and\nnonconvex programming, NP-hard, and intractable, we propose an iterative\nalgorithm based on the well-known alternate and successive convex approximation\nmethods. \n\n"}
{"id": "1802.08223", "contents": "Title: Achievable Rate of Private Function Retrieval from MDS Coded Databases Abstract: We study the problem of private function retrieval (PFR) in a distributed\nstorage system. In PFR the user wishes to retrieve a linear combination of $M$\nmessages stored in non-colluding $(N,K)$ MDS coded databases while revealing no\ninformation about the coefficients of the intended linear combination to any of\nthe individual databases. We present an achievable scheme for MDS coded PFR\nwith a rate that matches the capacity for coded private information retrieval\nderived recently, $R=(1+R_c+R_c^2+\\dots+R_c^{M-1})^{-1}=\\frac{1-R_c}{1-R_c^M}$,\nwhere $R_c=\\frac{K}{N}$ is the rate of the MDS code. This achievable rate is\ntight in some special cases. \n\n"}
{"id": "1802.08887", "contents": "Title: Water from Two Rocks: Maximizing the Mutual Information Abstract: We build a natural connection between the learning problem, co-training, and\nforecast elicitation without verification (related to peer-prediction) and\naddress them simultaneously using the same information theoretic approach.\n  In co-training/multiview learning, the goal is to aggregate two views of data\ninto a prediction for a latent label. We show how to optimally combine two\nviews of data by reducing the problem to an optimization problem. Our work\ngives a unified and rigorous approach to the general setting.\n  In forecast elicitation without verification we seek to design a mechanism\nthat elicits high quality forecasts from agents in the setting where the\nmechanism does not have access to the ground truth. By assuming the agents'\ninformation is independent conditioning on the outcome, we propose mechanisms\nwhere truth-telling is a strict equilibrium for both the single-task and\nmulti-task settings. Our multi-task mechanism additionally has the property\nthat the truth-telling equilibrium pays better than any other strategy profile\nand strictly better than any other \"non-permutation\" strategy profile when the\nprior satisfies some mild conditions. \n\n"}
{"id": "1802.10011", "contents": "Title: Stochastic Control of Computation Offloading to a Helper with a\n  Dynamically Loaded CPU Abstract: Due to densification of wireless networks, there exist abundance of idling\ncomputation resources at edge devices. These resources can be scavenged by\noffloading heavy computation tasks from small IoT devices in proximity, thereby\novercoming their limitations and lengthening their battery lives. However,\nunlike dedicated servers, the spare resources offered by edge helpers are\nrandom and intermittent. Thus, it is essential for a user to intelligently\ncontrol the amounts of data for offloading and local computing so as to ensure\na computation task can be finished in time consuming minimum energy. In this\npaper, we design energy-efficient control policies in a computation offloading\nsystem with a random channel and a helper with a dynamically loaded CPU.\nSpecifically, the policy adopted by the helper aims at determining the sizes of\noffloaded and locally-computed data for a given task in different slots such\nthat the total energy consumption for transmission and local CPU is minimized\nunder a task-deadline constraint. As the result, the polices endow an\noffloading user robustness against channel-and-helper randomness besides\nbalancing offloading and local computing. By modeling the channel and\nhelper-CPU as Markov chains, the problem of offloading control is converted\ninto a Markov-decision process. Though dynamic programming (DP) for numerically\nsolving the problem does not yield the optimal policies in closed form, we\nleverage the procedure to quantify the optimal policy structure and apply the\nresult to design optimal or sub-optimal policies. For different cases ranging\nfrom zero to large buffers, the low-complexity of the policies overcomes the\n\"curse-of-dimensionality\" in DP arising from joint consideration of channel,\nhelper CPU and buffer states. \n\n"}
{"id": "1803.00239", "contents": "Title: Dual skew codes from annihilators: Transpose Hamming ring extensions Abstract: In this paper a framework to study the dual of skew cyclic codes is proposed.\nThe transposed Hamming ring extensions are based in the existence of an\nanti-isomorphism of algebras between skew polynomial rings. Our construction is\napplied to left ideal convolutional codes, skew constacyclic codes and skew\nReed-Solomon code, showing that the dual of these codes belong to the same\nclass. \n\n"}
{"id": "1803.00680", "contents": "Title: A Tutorial on UAVs for Wireless Networks: Applications, Challenges, and\n  Open Problems Abstract: The use of flying platforms such as unmanned aerial vehicles (UAVs),\npopularly known as drones, is rapidly growing. In particular, with their\ninherent attributes such as mobility, flexibility, and adaptive altitude, UAVs\nadmit several key potential applications in wireless systems. On the one hand,\nUAVs can be used as aerial base stations to enhance coverage, capacity,\nreliability, and energy efficiency of wireless networks. On the other hand,\nUAVs can operate as flying mobile terminals within a cellular network. Such\ncellular-connected UAVs can enable several applications ranging from real-time\nvideo streaming to item delivery. In this paper, a comprehensive tutorial on\nthe potential benefits and applications of UAVs in wireless communications is\npresented. Moreover, the important challenges and the fundamental tradeoffs in\nUAV-enabled wireless networks are thoroughly investigated. In particular, the\nkey UAV challenges such as three-dimensional deployment, performance analysis,\nchannel modeling, and energy efficiency are explored along with representative\nresults. Then, open problems and potential research directions pertaining to\nUAV communications are introduced. Finally, various analytical frameworks and\nmathematical tools such as optimization theory, machine learning, stochastic\ngeometry, transport theory, and game theory are described. The use of such\ntools for addressing unique UAV problems is also presented. In a nutshell, this\ntutorial provides key guidelines on how to analyze, optimize, and design\nUAV-based wireless communication systems. \n\n"}
{"id": "1803.00983", "contents": "Title: Power Control and Channel Allocation for D2D Underlaid Cellular Networks Abstract: Device-to-Device (D2D) communications underlaying cellular networks is a\nviable network technology that can potentially increase spectral utilization\nand improve power efficiency for proximitybased wireless applications and\nservices. However, a major challenge in such deployment scenarios is the\ninterference caused by D2D links when sharing the same resources with cellular\nusers. In this work, we propose a channel allocation (CA) scheme together with\na set of three power control (PC) schemes to mitigate interference in a D2D\nunderlaid cellular system modeled as a random network using the mathematical\ntool of stochastic geometry. The novel aspect of the proposed CA scheme is that\nit enables D2D links to share resources with multiple cellular users as opposed\nto one as previously considered in the literature. Moreover, the accompanying\ndistributed PC schemes further manage interference during link establishment\nand maintenance. The first two PC schemes compensate for large-scale path-loss\neffects and maximize the D2D sum rate by employing distance-dependent pathloss\nparameters of the D2D link and the base station, including an error estimation\nmargin. The third scheme is an adaptive PC scheme based on a variable target\nsignal-to-interference-plus-noise ratio, which limits the interference caused\nby D2D users and provides sufficient coverage probability for cellular users.\nClosed-form expressions for the coverage probability of cellular links, D2D\nlinks, and sum rate of D2D links are derived in terms of the allocated power,\ndensity of D2D links, and path-loss exponent. The impact of these key system\nparameters on network performance is analyzed and compared with previous work.\nSimulation results demonstrate an enhancement in cellular and D2D coverage\nprobabilities, and an increase in spectral and power efficiency. \n\n"}
{"id": "1803.01462", "contents": "Title: Optimal Status Updating for an Energy Harvesting Sensor with a Noisy\n  Channel Abstract: Consider an energy harvesting sensor continuously monitors a system and sends\ntime-stamped status update to a destination. The destination keeps track of the\nsystem status through the received updates. Under the energy causality\nconstraint at the sensor, our objective is to design an optimal online status\nupdating policy to minimize the long-term average Age of Information (AoI) at\nthe destination. We focus on the scenario where the the channel between the\nsource and the destination is noisy, and each transmitted update may fail\nindependently with a constant probability. We assume there is no channel state\ninformation or transmission feedback available to the sensor. We prove that\nwithin a broadly defined class of online policies, the best-effort uniform\nupdating policy, which was shown to be optimal when the channel is perfect, is\nstill optimal in the presence of update failures. Our proof relies on tools\nfrom Martingale processes, and the construction of a sequence of virtual\npolicies. \n\n"}
{"id": "1803.02560", "contents": "Title: Vesper: Using Echo-Analysis to Detect Man-in-the-Middle Attacks in LANs Abstract: The Man-in-the-Middle (MitM) attack is a cyber-attack in which an attacker\nintercepts traffic, thus harming the confidentiality, integrity, and\navailability of the network. It remains a popular attack vector due to its\nsimplicity. However, existing solutions are either not portable, suffer from a\nhigh false positive rate, or are simply not generic. In this paper, we propose\nVesper: a novel plug-and-play MitM detector for local area networks. Vesper\nuses a technique inspired from impulse response analysis used in the domain of\nacoustic signal processing. Analogous to how echoes in a cave capture the shape\nand construction of the environment, so to can a short and intense pulse of\nICMP echo requests model the link between two network hosts. Vesper uses neural\nnetworks called autoencoders to model the normal patterns of the echoed pulses,\nand detect when the environment changes. Using this technique, Vesper is able\nto detect MitM attacks with high accuracy while incurring minimal network\noverhead. We evaluate Vesper on LANs consisting of video surveillance cameras,\nservers, and PC workstations. We also investigate several possible adversarial\nattacks against Vesper, and demonstrate how Vesper mitigates these attacks. \n\n"}
{"id": "1803.03030", "contents": "Title: Sample Complexity of Total Variation Minimization Abstract: This work considers the use of Total variation (TV) minimization in the\nrecovery of a given gradient sparse vector from Gaussian linear measurements.\nIt has been shown in recent studies that there exist a sharp phase transition\nbehavior in TV minimization in asymptotic regimes. The phase transition curve\nspecifies the boundary of success and failure of TV minimization for large\nnumber of measurements. It is a challenging task to obtain a theoretical bound\nthat reflects this curve. In this work, we present a novel upper-bound that\nsuitably approximates this curve and is asymptotically sharp. Numerical results\nshow that our bound is closer to the empirical TV phase transition curve than\nthe previously known bound obtained by Kabanava. \n\n"}
{"id": "1803.03448", "contents": "Title: A Family of Droids -- Android Malware Detection via Behavioral Modeling:\n  Static vs Dynamic Analysis Abstract: Following the increasing popularity of mobile ecosystems, cybercriminals have\nincreasingly targeted them, designing and distributing malicious apps that\nsteal information or cause harm to the device's owner. Aiming to counter them,\ndetection techniques based on either static or dynamic analysis that model\nAndroid malware, have been proposed. While the pros and cons of these analysis\ntechniques are known, they are usually compared in the context of their\nlimitations e.g., static analysis is not able to capture runtime behaviors,\nfull code coverage is usually not achieved during dynamic analysis, etc.\nWhereas, in this paper, we analyze the performance of static and dynamic\nanalysis methods in the detection of Android malware and attempt to compare\nthem in terms of their detection performance, using the same modeling approach.\n  To this end, we build on MaMaDroid, a state-of-the-art detection system that\nrelies on static analysis to create a behavioral model from the sequences of\nabstracted API calls. Then, aiming to apply the same technique in a dynamic\nanalysis setting, we modify CHIMP, a platform recently proposed to crowdsource\nhuman inputs for app testing, in order to extract API calls' sequences from the\ntraces produced while executing the app on a CHIMP virtual device. We call this\nsystem AuntieDroid and instantiate it by using both automated (Monkey) and\nuser-generated inputs. We find that combining both static and dynamic analysis\nyields the best performance, with F-measure reaching 0.92. We also show that\nstatic analysis is at least as effective as dynamic analysis, depending on how\napps are stimulated during execution, and, finally, investigate the reasons for\ninconsistent misclassifications across methods. \n\n"}
{"id": "1803.03614", "contents": "Title: Divergence-Optimal Fixed-to-Fixed Length Distribution Matching With\n  Shell Mapping Abstract: Distribution matching (DM) transforms independent and Bernoulli(1/2)\ndistributed bits into a sequence of output symbols with a desired distribution.\nA fixed-to-fixed length, invertible DM architecture based on shell mapping is\npresented. It is shown that shell mapping for distribution matching (SMDM) is\nthe optimum DM for the informational divergence metric and that finding energy\noptimal sequences is a special case of divergence minimization. Additionally,\nit is shown how to find the required shell mapping weight function to\napproximate arbitrary output distributions. SMDM is combined with probabilistic\namplitude shaping (PAS) to operate close to the Shannon limit. SMDM exhibits\nexcellent performance for short blocklengths as required by ultra-reliable\nlow-latency (URLLC) applications. SMDM outperforms constant composition DM\n(CCDM) by 0.6 dB when used with 64-QAM at a spectral efficiency of 3\nbits/channel use and a 5G low-density parity-check code with a short\nblocklength of 192 bits \n\n"}
{"id": "1803.03965", "contents": "Title: BEBP: An Poisoning Method Against Machine Learning Based IDSs Abstract: In big data era, machine learning is one of fundamental techniques in\nintrusion detection systems (IDSs). However, practical IDSs generally update\ntheir decision module by feeding new data then retraining learning models in a\nperiodical way. Hence, some attacks that comprise the data for training or\ntesting classifiers significantly challenge the detecting capability of machine\nlearning-based IDSs. Poisoning attack, which is one of the most recognized\nsecurity threats towards machine learning-based IDSs, injects some adversarial\nsamples into the training phase, inducing data drifting of training data and a\nsignificant performance decrease of target IDSs over testing data. In this\npaper, we adopt the Edge Pattern Detection (EPD) algorithm to design a novel\npoisoning method that attack against several machine learning algorithms used\nin IDSs. Specifically, we propose a boundary pattern detection algorithm to\nefficiently generate the points that are near to abnormal data but considered\nto be normal ones by current classifiers. Then, we introduce a Batch-EPD\nBoundary Pattern (BEBP) detection algorithm to overcome the limitation of the\nnumber of edge pattern points generated by EPD and to obtain more useful\nadversarial samples. Based on BEBP, we further present a moderate but effective\npoisoning method called chronic poisoning attack. Extensive experiments on\nsynthetic and three real network data sets demonstrate the performance of the\nproposed poisoning method against several well-known machine learning\nalgorithms and a practical intrusion detection method named FMIFS-LSSVM-IDS. \n\n"}
{"id": "1803.04020", "contents": "Title: Maximum Weight Spectrum Codes Abstract: In the recent work \\cite{shi18}, a combinatorial problem concerning linear\ncodes over a finite field $\\F_q$ was introduced. In that work the authors\nstudied the weight set of an $[n,k]_q$ linear code, that is the set of non-zero\ndistinct Hamming weights, showing that its cardinality is upper bounded by\n$\\frac{q^k-1}{q-1}$. They showed that this bound was sharp in the case $ q=2 $,\nand in the case $ k=2 $. They conjectured that the bound is sharp for every\nprime power $ q $ and every positive integer $ k $. In this work quickly\nestablish the truth of this conjecture. We provide two proofs, each employing\ndifferent construction techniques. The first relies on the geometric view of\nlinear codes as systems of projective points. The second approach is purely\nalgebraic. We establish some lower bounds on the length of codes that satisfy\nthe conjecture, and the length of the new codes constructed here are discussed. \n\n"}
{"id": "1803.04072", "contents": "Title: Blind Identification of Invertible Graph Filters with Multiple Sparse\n  Inputs Abstract: This paper deals with problem of blind identification of a graph filter and\nits sparse input signal, thus broadening the scope of classical blind\ndeconvolution of temporal and spatial signals to irregular graph domains. While\nthe observations are bilinear functions of the unknowns, a mild requirement on\ninvertibility of the filter enables an efficient convex formulation, without\nrelying on matrix lifting that can hinder applicability to large graphs. On top\nof scaling, it is argued that (non-cyclic) permutation ambiguities may arise\nwith some particular graphs. Deterministic sufficient conditions under which\nthe proposed convex relaxation can exactly recover the unknowns are stated,\nalong with those guaranteeing identifiability under the Bernoulli-Gaussian\nmodel for the inputs. Numerical tests with synthetic and real-world networks\nillustrate the merits of the proposed algorithm, as well as the benefits of\nleveraging multiple signals to aid the (blind) localization of sources of\ndiffusion. \n\n"}
{"id": "1803.05844", "contents": "Title: Iterative Turbo Receiver for LDPC-Coded MIMO Systems Based on\n  Semi-definite Relaxation Abstract: In this work, we develop a new iterative turbo receiver for LDPC-coded\nmulti-antenna systems based on semidefinite relaxation (SDR). For a classical\nturbo receiver, forward error correction (FEC) code is only used at decoder.\nNonetheless, by taking advantage of FEC code in the detection stage, our\nproposed SDR detector can output extrinsic information with much improved\nreliability to the decoder. We also propose a simplified SDR turbo receiver\nthat solves only one SDR problem per codeword instead of solving multiple SDR\nproblems in the iterative turbo processing. This scheme significantly reduces\nthe time complexity of SDR turbo receiver, while the error performance remains\nsimilar as before. In fact, our simplified scheme is generic in the sense that\nit is applicable to any list-based iterative receivers. \n\n"}
{"id": "1803.06007", "contents": "Title: Covert Communication over a K-User Multiple Access Channel Abstract: We consider a scenario in which $K$ transmitters attempt to communicate\ncovert messages reliably to a legitimate receiver over a discrete memoryless\nMAC while simultaneously escaping detection from an adversary who observes\ntheir communication through another discrete memoryless MAC. We assume that\neach transmitter may use a secret key that is shared only between itself and\nthe legitimate receiver. We show that each of the $K$ transmitters can transmit\non the order of $\\sqrt{n}$ reliable and covert bits per $n$ channel uses,\nexceeding which, the warden will be able to detect the communication. We\nidentify the optimal pre-constants of the scaling, which leads to a complete\ncharacterization of the covert capacity region of the $K$-user binary-input\nMAC. We show that, asymptotically, all sum-rate constraints are inactive unlike\nthe traditional MAC capacity region. We also characterize the channel\nconditions that have to be satisfied for the transmitters to operate without a\nsecret key. \n\n"}
{"id": "1803.07588", "contents": "Title: A Push-Pull Gradient Method for Distributed Optimization in Networks Abstract: In this paper, we focus on solving a distributed convex optimization problem\nin a network, where each agent has its own convex cost function and the goal is\nto minimize the sum of the agents' cost functions while obeying the network\nconnectivity structure. In order to minimize the sum of the cost functions, we\nconsider a new distributed gradient-based method where each node maintains two\nestimates, namely, an estimate of the optimal decision variable and an estimate\nof the gradient for the average of the agents' objective functions. From the\nviewpoint of an agent, the information about the decision variable is pushed to\nthe neighbors, while the information about the gradients is pulled from the\nneighbors (hence giving the name \"push-pull gradient method\"). The method\nunifies the algorithms with different types of distributed architecture,\nincluding decentralized (peer-to-peer), centralized (master-slave), and\nsemi-centralized (leader-follower) architecture. We show that the algorithm\nconverges linearly for strongly convex and smooth objective functions over a\ndirected static network. In our numerical test, the algorithm performs well\neven for time-varying directed networks. \n\n"}
{"id": "1803.07812", "contents": "Title: Covert Wireless Communications with Channel Inversion Power Control in\n  Rayleigh Fading Abstract: In this work, we adopt channel inversion power control (CIPC) to achieve\ncovert communications aided by a full-duplex receiver. Specifically, the\ntransmitter varies the power and phase of transmitted signals as per the\nchannel to the receiver, such that the receiver can decode these signals\nwithout knowing the channel state information. This eliminates the required\nfeedback from the transmitter to the receiver, which aids hiding the\ntransmitter from a warden. The truncated CIPC and conventional CIPC schemes are\nproposed and examined, where for truncated CIPC covert transmission ceases when\nthe channel quality from the transmitter to the receiver is low, while for\nconventional CIPC covert transmission always occurs regardless of this channel\nquality. We examine their performance in terms of the achieved effective covert\nthroughput (ECT), which quantifies the amount of information that the\ntransmitter can reliably convey to the receiver, subject to the constraint that\nthe warden's detection error probability is no less than some specific value.\nOur examination shows that the truncated CIPC scheme can outperform the\nconventional CIPC scheme due to this constraint. \n\n"}
{"id": "1803.07993", "contents": "Title: Age of Information in a Network of Preemptive Servers Abstract: A source submits status updates to a network for delivery to a destination\nmonitor. Updates follow a route through a series of network nodes. Each node is\na last-come-first-served queue supporting preemption in service. We\ncharacterize the average age of information at the input and output of each\nnode in the route induced by the updates passing through. For Poisson arrivals\nto a line network of preemptive memoryless servers, we show that average age\naccumulates through successive network nodes. \n\n"}
{"id": "1803.09160", "contents": "Title: Handling Adversarial Concept Drift in Streaming Data Abstract: Classifiers operating in a dynamic, real world environment, are vulnerable to\nadversarial activity, which causes the data distribution to change over time.\nThese changes are traditionally referred to as concept drift, and several\napproaches have been developed in literature to deal with the problem of drift\nhandling and detection. However, most concept drift handling techniques,\napproach it as a domain independent task, to make them applicable to a wide\ngamut of reactive systems. These techniques were developed from an adversarial\nagnostic perspective, where they are naive and assume that drift is a benign\nchange, which can be fixed by updating the model. However, this is not the case\nwhen an active adversary is trying to evade the deployed classification system.\nIn such an environment, the properties of concept drift are unique, as the\ndrift is intended to degrade the system and at the same time designed to avoid\ndetection by traditional concept drift detection techniques. This special\ncategory of drift is termed as adversarial drift, and this paper analyzes its\ncharacteristics and impact, in a streaming environment. A novel framework for\ndealing with adversarial concept drift is proposed, called the Predict-Detect\nstreaming framework. Experimental evaluation of the framework, on generated\nadversarial drifting data streams, demonstrates that this framework is able to\nprovide reliable unsupervised indication of drift, and is able to recover from\ndrifts swiftly. While traditional partially labeled concept drift detection\nmethodologies fail to detect adversarial drifts, the proposed framework is able\nto detect such drifts and operates with <6% labeled data, on average. Also, the\nframework provides benefits for active learning over imbalanced data streams,\nby innately providing for feature space honeypots, where minority class\nadversarial samples may be captured. \n\n"}
{"id": "1803.09162", "contents": "Title: A Dynamic-Adversarial Mining Approach to the Security of Machine\n  Learning Abstract: Operating in a dynamic real world environment requires a forward thinking and\nadversarial aware design for classifiers, beyond fitting the model to the\ntraining data. In such scenarios, it is necessary to make classifiers - a)\nharder to evade, b) easier to detect changes in the data distribution over\ntime, and c) be able to retrain and recover from model degradation. While most\nworks in the security of machine learning has concentrated on the evasion\nresistance (a) problem, there is little work in the areas of reacting to\nattacks (b and c). Additionally, while streaming data research concentrates on\nthe ability to react to changes to the data distribution, they often take an\nadversarial agnostic view of the security problem. This makes them vulnerable\nto adversarial activity, which is aimed towards evading the concept drift\ndetection mechanism itself. In this paper, we analyze the security of machine\nlearning, from a dynamic and adversarial aware perspective. The existing\ntechniques of Restrictive one class classifier models, Complex learning models\nand Randomization based ensembles, are shown to be myopic as they approach\nsecurity as a static task. These methodologies are ill suited for a dynamic\nenvironment, as they leak excessive information to an adversary, who can\nsubsequently launch attacks which are indistinguishable from the benign data.\nBased on empirical vulnerability analysis against a sophisticated adversary, a\nnovel feature importance hiding approach for classifier design, is proposed.\nThe proposed design ensures that future attacks on classifiers can be detected\nand recovered from. The proposed work presents motivation, by serving as a\nblueprint, for future work in the area of Dynamic-Adversarial mining, which\ncombines lessons learned from Streaming data mining, Adversarial learning and\nCybersecurity. \n\n"}
{"id": "1803.10623", "contents": "Title: Stability and Dynamic Control of Underlay Mobile Edge Networks Abstract: This paper studies the stability and dynamic control of underlay mobile edge\nnetworks. First, the stability region for a multiuser edge network is obtained\nunder the assumption of full channel state information. This result provides a\nbenchmark figure for comparing performance of the proposed algorithms. Second,\na centralized joint flow control and scheduling algorithm is proposed to\nstabilize the queues of edge devices while respecting the average and\ninstantaneous interference power constraints at the core access point. This\nalgorithm is proven to converge to a utility point arbitrarily close to the\nmaximum achievable utility within the stability region. Finally, more practical\nimplementation issues such as distributed scheduling are examined by designing\nefficient scheduling algorithms taking advantage of communications diversity.\nThe proposed distributed solutions utilize mini slots for contention resolution\nand achieve a certain fraction of the utility optimal point. The performance\nlower bounds for distributed algorithms are determined analytically. The\ndetailed simulation study is performed to pinpoint the cost of distributed\ncontrol for mobile edge networks with respect to centralized control. \n\n"}
{"id": "1803.10844", "contents": "Title: Rank-Metric Codes and $q$-Polymatroids Abstract: This paper contributes to the study of rank-metric codes from an algebraic\nand combinatorial point of view. We introduce $q$-polymatroids, the\n$q$-analogue of polymatroids, and develop their basic properties. We associate\na pair of q-polymatroids to a rank-metric codes and show that several\ninvariants and structural properties of the code, such as generalized weights,\nthe property of being MRD or an optimal anticode, and duality, are captured by\nthe associated combinatorial object. \n\n"}
{"id": "1803.11052", "contents": "Title: Decaying Indicators of Compromise Abstract: The steady increase in the volume of indicators of compromise (IoC) as well\nas their volatile nature makes their processing challenging. Once compromised\ninfrastructures are cleaned up, threat actors are moving to on to other target\ninfrastructures or simply changing attack strategies. To ease the evaluation of\nIoCs as well as to harness the combined analysis capabilities, threat\nintelligence sharing platforms were introduced in order to foster collaboration\non a community level. In this paper, the open-source threat intelligence\nplatform MISP is used to implement and showcase a generic scoring model for\ndecaying IoCs shared within MISP communities matching their heterogeneous\nobjectives. The model takes into account existing meta-information shared along\nwith indicators of compromise,facilitating the decision making process for\nmachines in regards to the validity of the shared indicator of compromise. The\nmodel is applied on common use-cases that are normally encountered during\nincident response. \n\n"}
{"id": "1804.00057", "contents": "Title: Understanding Autoencoders with Information Theoretic Concepts Abstract: Despite their great success in practical applications, there is still a lack\nof theoretical and systematic methods to analyze deep neural networks. In this\npaper, we illustrate an advanced information theoretic methodology to\nunderstand the dynamics of learning and the design of autoencoders, a special\ntype of deep learning architectures that resembles a communication channel. By\ngeneralizing the information plane to any cost function, and inspecting the\nroles and dynamics of different layers using layer-wise information quantities,\nwe emphasize the role that mutual information plays in quantifying learning\nfrom data. We further suggest and also experimentally validate, for mean square\nerror training, three fundamental properties regarding the layer-wise flow of\ninformation and intrinsic dimensionality of the bottleneck layer, using\nrespectively the data processing inequality and the identification of a\nbifurcation point in the information plane that is controlled by the given\ndata. Our observations have a direct impact on the optimal design of\nautoencoders, the design of alternative feedforward training methods, and even\nin the problem of generalization. \n\n"}
{"id": "1804.01221", "contents": "Title: Tight Query Complexity Lower Bounds for PCA via Finite Sample Deformed\n  Wigner Law Abstract: We prove a \\emph{query complexity} lower bound for approximating the top $r$\ndimensional eigenspace of a matrix. We consider an oracle model where, given a\nsymmetric matrix $\\mathbf{M} \\in \\mathbb{R}^{d \\times d}$, an algorithm\n$\\mathsf{Alg}$ is allowed to make $\\mathsf{T}$ exact queries of the form\n$\\mathsf{w}^{(i)} = \\mathbf{M} \\mathsf{v}^{(i)}$ for $i$ in\n$\\{1,...,\\mathsf{T}\\}$, where $\\mathsf{v}^{(i)}$ is drawn from a distribution\nwhich depends arbitrarily on the past queries and measurements\n$\\{\\mathsf{v}^{(j)},\\mathsf{w}^{(i)}\\}_{1 \\le j \\le i-1}$. We show that for\nevery $\\mathtt{gap} \\in (0,1/2]$, there exists a distribution over matrices\n$\\mathbf{M}$ for which 1) $\\mathrm{gap}_r(\\mathbf{M}) = \\Omega(\\mathtt{gap})$\n(where $\\mathrm{gap}_r(\\mathbf{M})$ is the normalized gap between the $r$ and\n$r+1$-st largest-magnitude eigenvector of $\\mathbf{M}$), and 2) any algorithm\n$\\mathsf{Alg}$ which takes fewer than $\\mathrm{const} \\times \\frac{r \\log\nd}{\\sqrt{\\mathtt{gap}}}$ queries fails (with overwhelming probability) to\nidentity a matrix $\\widehat{\\mathsf{V}} \\in \\mathbb{R}^{d \\times r}$ with\northonormal columns for which $\\langle \\widehat{\\mathsf{V}}, \\mathbf{M}\n\\widehat{\\mathsf{V}}\\rangle \\ge (1 - \\mathrm{const} \\times\n\\mathtt{gap})\\sum_{i=1}^r \\lambda_i(\\mathbf{M})$. Our bound requires only that\n$d$ is a small polynomial in $1/\\mathtt{gap}$ and $r$, and matches the upper\nbounds of Musco and Musco '15. Moreover, it establishes a strict separation\nbetween convex optimization and \\emph{randomized}, \"strict-saddle\" non-convex\noptimization of which PCA is a canonical example: in the former, first-order\nmethods can have dimension-free iteration complexity, whereas in PCA, the\niteration complexity of gradient-based methods must necessarily grow with the\ndimension. \n\n"}
{"id": "1804.01922", "contents": "Title: Approaching Waterfilling Capacity of Parallel Channels by Higher Order\n  Modulation and Probabilistic Amplitude Shaping Abstract: Parallel, additive white Gaussian noise (AWGN) channels with an average sum\npower constraint are considered. It is shown how the waterfilling Shannon\ncapacity can be approached by higher order modulation and probabilistic\namplitude shaping (PAS). This is achieved by a new distribution matching\napproach called product distribution matching (PDM). The asymptotic performance\nof PDM is analyzed by achievable rates. A heuristic for optimizing the input\ndistribution is proposed, which enables signaling at a target spectral\nefficiency with a fixed-rate forward error correction (FEC) code, while the\noptimal power allocation is ensured by mercury-waterfilling and a simple\nbit-loading strategy. Finite blocklength simulation results with 5G low-density\nparity-check codes show power savings of around 1 dB compared to a conventional\nscheme with uniform input distributions. \n\n"}
{"id": "1804.02219", "contents": "Title: Binary Subspace Codes in Small Ambient Spaces Abstract: Codes in finite projective spaces equipped with the subspace distance have\nbeen proposed for error control in random linear network coding. Here we\ncollect the present knowledge on lower and upper bounds for binary subspace\ncodes for projective dimensions of at most $7$. We obtain several improvements\nof the bounds and perform two classifications of optimal subspace codes, which\nare unknown so far in the literature. \n\n"}
{"id": "1804.03794", "contents": "Title: Differentially Private Confidence Intervals for Empirical Risk\n  Minimization Abstract: The process of data mining with differential privacy produces results that\nare affected by two types of noise: sampling noise due to data collection and\nprivacy noise that is designed to prevent the reconstruction of sensitive\ninformation. In this paper, we consider the problem of designing confidence\nintervals for the parameters of a variety of differentially private machine\nlearning models. The algorithms can provide confidence intervals that satisfy\ndifferential privacy (as well as the more recently proposed concentrated\ndifferential privacy) and can be used with existing differentially private\nmechanisms that train models using objective perturbation and output\nperturbation. \n\n"}
{"id": "1804.04406", "contents": "Title: Cashtag piggybacking: uncovering spam and bot activity in stock\n  microblogs on Twitter Abstract: Microblogs are increasingly exploited for predicting prices and traded\nvolumes of stocks in financial markets. However, it has been demonstrated that\nmuch of the content shared in microblogging platforms is created and publicized\nby bots and spammers. Yet, the presence (or lack thereof) and the impact of\nfake stock microblogs has never systematically been investigated before. Here,\nwe study 9M tweets related to stocks of the 5 main financial markets in the US.\nBy comparing tweets with financial data from Google Finance, we highlight\nimportant characteristics of Twitter stock microblogs. More importantly, we\nuncover a malicious practice - referred to as cashtag piggybacking -\nperpetrated by coordinated groups of bots and likely aimed at promoting\nlow-value stocks by exploiting the popularity of high-value ones. Among the\nfindings of our study is that as much as 71% of the authors of suspicious\nfinancial tweets are classified as bots by a state-of-the-art spambot detection\nalgorithm. Furthermore, 37% of them were suspended by Twitter a few months\nafter our investigation. Our results call for the adoption of spam and bot\ndetection techniques in all studies and applications that exploit\nuser-generated content for predicting the stock market. \n\n"}
{"id": "1804.05529", "contents": "Title: A Bound on the Shannon Capacity via a Linear Programming Variation Abstract: We prove an upper bound on the Shannon capacity of a graph via a linear\nprogramming variation. We show that our bound can outperform both the Lov\\'asz\ntheta number and the Haemers minimum rank bound. As a by-product, we also\nobtain a new upper bound on the broadcast rate of Index Coding. \n\n"}
{"id": "1804.06003", "contents": "Title: The Subfield Codes of Hyperoval and Conic codes Abstract: Hyperovals in $\\PG(2,\\gf(q))$ with even $q$ are maximal arcs and an\ninteresting research topic in finite geometries and combinatorics. Hyperovals\nin $\\PG(2,\\gf(q))$ are equivalent to $[q+2,3,q]$ MDS codes over $\\gf(q)$,\ncalled hyperoval codes, in the sense that one can be constructed from the\nother. Ovals in $\\PG(2,\\gf(q))$ for odd $q$ are equivalent to $[q+1,3,q-1]$ MDS\ncodes over $\\gf(q)$, which are called oval codes. In this paper, we investigate\nthe binary subfield codes of two families of hyperoval codes and the $p$-ary\nsubfield codes of the conic codes. The weight distributions of these subfield\ncodes and the parameters of their duals are determined. As a byproduct, we\ngeneralize one family of the binary subfield codes to the $p$-ary case and\nobtain its weight distribution. The codes presented in this paper are optimal\nor almost optimal in many cases. In addition, the parameters of these binary\ncodes and $p$-ary codes seem new. \n\n"}
{"id": "1804.07642", "contents": "Title: On the Effects of Subpacketization in Content-Centric Mobile Networks Abstract: A large-scale content-centric mobile ad hoc network employing\nsubpacketization is studied in which each mobile node having finite-size cache\nmoves according to the reshuffling mobility model and requests a content object\nfrom the library independently at random according to the Zipf popularity\ndistribution. Instead of assuming that one content object is transferred in a\nsingle time slot, we consider a more challenging scenario where the size of\neach content object is considerably large and thus only a subpacket of a file\ncan be delivered during one time slot, which is motivated by a fast mobility\nscenario. Under our mobility model, we consider a single-hop-based content\ndelivery and characterize the fundamental trade-offs between throughput and\ndelay. The order-optimal throughput-delay trade-off is analyzed by presenting\nthe following two content reception strategies: the sequential reception for\nuncoded caching and the random reception for maximum distance separable\n(MDS)-coded caching. We also perform numerical evaluation to validate our\nanalytical results. In particular, we conduct performance comparisons between\nthe uncoded caching and the MDS-coded caching strategies by identifying the\nregimes in which the performance difference between the two caching strategies\nbecomes prominent with respect to system parameters such as the Zipf exponent\nand the number of subpackets. In addition, we extend our study to the random\nwalk mobility scenario and show that our main results are essentially the same\nas those in the reshuffling mobility model. \n\n"}
{"id": "1804.09356", "contents": "Title: Age-Optimal Trajectory Planning for UAV-Assisted Data Collection Abstract: Unmanned aerial vehicle (UAV)-aided data collection is a new and promising\napplication in many practical scenarios. In this work, we study the age-optimal\ntrajectory planning problem in UAV-enabled wireless sensor networks, where a\nUAV is dispatched to collect data from the ground sensor nodes (SNs). The age\nof information (AoI) collected from each SN is characterized by the data\nuploading time and the time elapsed since the UAV leaves this SN. We attempt to\ndesign two age-optimal trajectories, referred to as the Max-AoI-optimal and\nAve-AoI-optimal trajectories, respectively. The Max-AoI-optimal trajectory\nplanning is to minimize the age of the `oldest' sensed information among the\nSNs. The Ave-AoI-optimal trajectory planning is to minimize the average AoI of\nall the SNs. Then, we show that each age-optimal flight trajectory corresponds\nto a shortest Hamiltonian path in the wireless sensor network where the\ndistance between any two SNs represents the amount of inter-visit time. The\ndynamic programming (DP) method and genetic algorithm (GA) are adopted to find\nthe two different age-optimal trajectories. Simulation results validate the\neffectiveness of the proposed methods, and show how the UAV's trajectory is\naffected by the two AoI metrics. \n\n"}
{"id": "1804.09360", "contents": "Title: Analysis of Indoor Uplink Optical Communication Positioning System\n  Exploiting Multipath Reflections Abstract: In this paper, we introduce an uplink optical wireless positioning system for\nindoor applications. This technique uses fingerprints based on the indoor\noptical wireless channel impulse response for localization. Exploiting the line\nof sight peak power (LOS), the second power peak (SPP) of the impulse response,\nand the delay between the LOS and SPP, we present a proof of concept design and\ntheoretical analysis for localization employing a single fixed reference point,\ni.e., a photodetector (PD) on the ceiling. Adding more PDs leads to more\naccurate transmitter position estimation. As a benchmark, we present analytical\nexpressions of the Cramer-Rao lower bound (CRLB) for different numbers of PDs\nand features. We further present closed form analytical approximations for the\nchosen features of the channel impulse response. Simulation results show a root\nmean square (RMS) positioning accuracy of 25\\,cm and 5\\,cm for one and four\nPDs, respectively, for a typical indoor room at high SNR. Numerical results\nverify that the derived analytic approximations closely match the simulations. \n\n"}
{"id": "1804.10334", "contents": "Title: Deep Learning Coordinated Beamforming for Highly-Mobile Millimeter Wave\n  Systems Abstract: Supporting high mobility in millimeter wave (mmWave) systems enables a wide\nrange of important applications such as vehicular communications and wireless\nvirtual/augmented reality. Realizing this in practice, though, requires\novercoming several challenges. First, the use of narrow beams and the\nsensitivity of mmWave signals to blockage greatly impact the coverage and\nreliability of highly-mobile links. Second, highly-mobile users in dense mmWave\ndeployments need to frequently hand-off between base stations (BSs), which is\nassociated with critical control and latency overhead. Further, identifying the\noptimal beamforming vectors in large antenna array mmWave systems requires\nconsiderable training overhead, which significantly affects the efficiency of\nthese mobile systems. In this paper, a novel integrated machine learning and\ncoordinated beamforming solution is developed to overcome these challenges and\nenable highly-mobile mmWave applications. In the proposed solution, a number of\ndistributed yet coordinating BSs simultaneously serve a mobile user. This user\nideally needs to transmit only one uplink training pilot sequence that will be\njointly received at the coordinating BSs using omni or quasi-omni beam\npatterns. These received signals draw a defining signature not only for the\nuser location, but also for its interaction with the surrounding environment.\nThe developed solution then leverages a deep learning model that learns how to\nuse these signatures to predict the beamforming vectors at the BSs. This\nrenders a comprehensive solution that supports highly-mobile mmWave\napplications with reliable coverage, low latency, and negligible training\noverhead. Simulation results show that the proposed deep-learning coordinated\nbeamforming strategy approaches the achievable rate of the genie-aided solution\nthat knows the optimal beamforming vectors with no training overhead. \n\n"}
{"id": "1804.10654", "contents": "Title: Resolving SINR Queries in a Dynamic Setting Abstract: We consider a set of transmitters broadcasting simultaneously on the same\nfrequency under the SINR model. Transmission power may vary from one\ntransmitter to another, and a transmitter's signal strength at a given point is\nmodeled by the transmitter's power divided by some constant power $\\alpha$ of\nthe distance it traveled. Roughly, a receiver at a given location can hear a\nspecific transmitter only if the transmitter's signal is stronger by a\nspecified ratio than the signals of all other transmitters combined. An SINR\nquery is to determine whether a receiver at a given location can hear any\ntransmitter, and if yes, which one.\n  An approximate answer to an SINR query is such that one gets a definite YES\nor definite NO, when the ratio between the strongest signal and all other\nsignals combined is well above or well below the reception threshold, while the\nanswer in the intermediate range is allowed to be either YES or NO.\n  We describe compact data structures that support approximate SINR queries in\nthe plane in a dynamic context, i.e., where transmitters may be inserted and\ndeleted over time. We distinguish between two main variants --- uniform power\nand non-uniform power. In both variants the preprocessing time is $O(n\n\\mathop{\\textrm{polylog}} n)$ and the amortized update time is\n$O(\\mathop{\\textrm{polylog}} n)$, while the query time is\n$O(\\mathop{\\textrm{polylog}} n)$ for uniform power, and randomized time\n$O(\\sqrt{n} \\mathop{\\textrm{polylog}} n)$ with high probability for non-uniform\npower.\n  Finally, we observe that in the static context the latter data structure can\nbe implemented differently, so that the query time is also\n$O(\\mathop{\\textrm{polylog}} n)$, thus significantly improving all previous\nresults for this problem. \n\n"}
{"id": "1804.10729", "contents": "Title: Secure Computation-and-Forward with Linear Codes Abstract: We discuss secure transmission via an untrusted relay when we have a multiple\naccess phase from two nodes to the relay and broadcast phase from the relay to\nthe two nodes. To realize the security, we construct a code that securely\ntransmits the modulo sum of the messages of two nodes via a multiple access\nchannel. In this code, the relay cannot obtain any information for the message\nof each node, and can decode only the messages of the two nodes. Our code is\nconstructed by simple combination of an existing liner code and universal2 hash\nfunction. \n\n"}
{"id": "1805.00904", "contents": "Title: SynTF: Synthetic and Differentially Private Term Frequency Vectors for\n  Privacy-Preserving Text Mining Abstract: Text mining and information retrieval techniques have been developed to\nassist us with analyzing, organizing and retrieving documents with the help of\ncomputers. In many cases, it is desirable that the authors of such documents\nremain anonymous: Search logs can reveal sensitive details about a user,\ncritical articles or messages about a company or government might have severe\nor fatal consequences for a critic, and negative feedback in customer surveys\nmight negatively impact business relations if they are identified. Simply\nremoving personally identifying information from a document is, however,\ninsufficient to protect the writer's identity: Given some reference texts of\nsuspect authors, so-called authorship attribution methods can reidentfy the\nauthor from the text itself.\n  One of the most prominent models to represent documents in many common text\nmining and information retrieval tasks is the vector space model where each\ndocument is represented as a vector, typically containing its term frequencies\nor related quantities. We therefore propose an automated text anonymization\napproach that produces synthetic term frequency vectors for the input documents\nthat can be used in lieu of the original vectors. We evaluate our method on an\nexemplary text classification task and demonstrate that it only has a low\nimpact on its accuracy. In contrast, we show that our method strongly affects\nauthorship attribution techniques to the level that they become infeasible with\na much stronger decline in accuracy. Other than previous authorship obfuscation\nmethods, our approach is the first that fulfills differential privacy and hence\ncomes with a provable plausible deniability guarantee. \n\n"}
{"id": "1805.01498", "contents": "Title: Improved decoding of Folded Reed-Solomon and Multiplicity Codes Abstract: In this work, we show new and improved error-correcting properties of folded\nReed-Solomon codes and multiplicity codes. Both of these families of codes are\nbased on polynomials over finite fields, and both have been the sources of\nrecent advances in coding theory. Folded Reed-Solomon codes were the first\nexplicit constructions of codes known to achieve list-decoding capacity;\nmultivariate multiplicity codes were the first constructions of high-rate\nlocally correctable codes; and univariate multiplicity codes are also known to\nachieve list-decoding capacity.\n  However, previous analyses of the error-correction properties of these codes\ndid not yield optimal results. In particular, in the list-decoding setting, the\nguarantees on the list-sizes were polynomial in the block length, rather than\nconstant; and for multivariate multiplicity codes, local list-decoding\nalgorithms could not go beyond the Johnson bound.\n  In this paper, we show that Folded Reed-Solomon codes and multiplicity codes\nare in fact better than previously known in the context of list-decoding and\nlocal list-decoding. More precisely, we first show that Folded RS codes achieve\nlist-decoding capacity with constant list sizes, independent of the block\nlength; and that high-rate univariate multiplicity codes can also be\nlist-recovered with constant list sizes. Using our result on univariate\nmultiplicity codes, we show that multivariate multiplicity codes are high-rate,\nlocally list-recoverable codes. Finally, we show how to combine the above\nresults with standard tools to obtain capacity achieving locally list decodable\ncodes with query complexity significantly lower than was known before. \n\n"}
{"id": "1805.03338", "contents": "Title: On the Optimal Achievable Rates for Linear Computation With Random\n  Homologous Codes Abstract: The problem of computing a linear combination of sources over a multiple\naccess channel is studied. Inner and outer bounds on the optimal tradeoff\nbetween the communication rates are established when encoding is restricted to\nrandom ensembles of homologous codes, namely, structured nested coset codes\nfrom the same generator matrix and individual shaping functions, but when\ndecoding is optimized with respect to the realization of the encoders. For the\nspecial case in which the desired linear combination is \"matched\" to the\nstructure of the multiple access channel in a natural sense, these inner and\nouter bounds coincide. This result indicates that most, if not all, coding\nschemes for computation in the literature that rely on random construction of\nnested coset codes cannot be improved by using more powerful decoders, such as\nthe maximum likelihood decoder. The proof techniques are adapted to\ncharacterize the rate region for broadcast channels achieved by Marton's\n(random) coding scheme under maximum likelihood decoding. \n\n"}
{"id": "1805.05838", "contents": "Title: Gradient-Leaks: Understanding and Controlling Deanonymization in\n  Federated Learning Abstract: Federated Learning (FL) systems are gaining popularity as a solution to\ntraining Machine Learning (ML) models from large-scale user data collected on\npersonal devices (e.g., smartphones) without their raw data leaving the device.\nAt the core of FL is a network of anonymous user devices sharing training\ninformation (model parameter updates) computed locally on personal data.\nHowever, the type and degree to which user-specific information is encoded in\nthe model updates is poorly understood. In this paper, we identify model\nupdates encode subtle variations in which users capture and generate data. The\nvariations provide a strong statistical signal, allowing an adversary to\neffectively deanonymize participating devices using a limited set of auxiliary\ndata. We analyze resulting deanonymization attacks on diverse tasks on\nreal-world (anonymized) user-generated data across a range of closed- and\nopen-world scenarios. We study various strategies to mitigate the risks of\ndeanonymization. As random perturbation methods do not offer convincing\noperating points, we propose data-augmentation strategies which introduces\nadversarial biases in device data and thereby, offer substantial protection\nagainst deanonymization threats with little effect on utility. \n\n"}
{"id": "1805.06541", "contents": "Title: Towards Malware Detection via CPU Power Consumption: Data Collection\n  Design and Analytics (Extended Version) Abstract: This paper presents an experimental design and data analytics approach aimed\nat power-based malware detection on general-purpose computers. Leveraging the\nfact that malware executions must consume power, we explore the postulate that\nmalware can be accurately detected via power data analytics. Our experimental\ndesign and implementation allow for programmatic collection of CPU power\nprofiles for fixed tasks during uninfected and infected states using five\ndifferent rootkits. To characterize the power consumption profiles, we use both\nsimple statistical and novel, sophisticated features. We test a one-class\nanomaly detection ensemble (that baselines non-infected power profiles) and\nseveral kernel-based SVM classifiers (that train on both uninfected and\ninfected profiles) in detecting previously unseen malware and clean profiles.\nThe anomaly detection system exhibits perfect detection when using all features\nand tasks, with smaller false detection rate than the supervised classifiers.\nThe primary contribution is the proof of concept that baselining power of fixed\ntasks can provide accurate detection of rootkits. Moreover, our treatment\npresents engineering hurdles needed for experimentation and allows analysis of\neach statistical feature individually. This work appears to be the first step\ntowards a viable power-based detection capability for general-purpose\ncomputers, and presents next steps toward this goal. \n\n"}
{"id": "1805.06752", "contents": "Title: Scheduling Policies for Age Minimization in Wireless Networks with\n  Unknown Channel State Abstract: Age of information (AoI) is a recently proposed metric that measures the time\nelapsed since the generation of the last received information update. We\nconsider the problem of AoI minimization for a network under general\ninterference constraints, and time varying channel. We study the case where the\nchannel statistics are known, but the current channel state is unknown. We\npropose two scheduling policies, namely, the virtual queue based policy and\nage-based policy. In the virtual queue based policy, the scheduler schedules\nlinks with maximum weighted sum of the virtual queue lengths, while in the\nage-based policy, the scheduler schedules links with maximum weighted sum of a\nfunction of link AoI. We prove that the virtual queue based policy is peak age\noptimal, up to an additive constant, while the age-based policy is at most\nfactor 4 away from the optimal age. Numerical results suggest that both the\nproposed policies are, in fact, very close to the optimal. \n\n"}
{"id": "1805.06786", "contents": "Title: Betting on Blockchain Consensus with Fantomette Abstract: Blockchain-based consensus protocols present the opportunity to develop new\nprotocols, due to their novel requirements of open participation and explicit\nincentivization of participants. To address the first requirement, it is\nnecessary to consider the leader election inherent in consensus protocols,\nwhich can be difficult to scale to a large and untrusted set of participants.\nTo address the second, it is important to consider ways to provide\nincentivization without relying on the resource-intensive proofs-of-work used\nin Bitcoin. In this paper, we propose a secure leader election protocol,\nCaucus; we next fit this protocol into a broader blockchain-based consensus\nprotocol, Fantomette, that provides game-theoretic guarantees in addition to\ntraditional blockchain security properties. Fantomette is the first\nproof-of-stake protocol to give formal game-theoretic proofs of security in the\npresence of non-rational players. \n\n"}
{"id": "1805.07190", "contents": "Title: Private Information Retrieval using Product-Matrix Minimum Storage\n  Regenerating Codes Abstract: Private Information Retrieval (PIR) schemes allow a user to retrieve a record\nfrom the server without revealing any information on which record is being\ndownloaded. In this paper, we consider PIR schemes where the database is stored\nusing Minimum Storage Regenerating (MSR) codes which is a class of optimal\nregenerating codes providing efficient repair when a node failure occurs in the\nsystem. We analyse the relationship between the costs of privacy, storage and\nrepair, and also construct an explicit PIR scheme that uses the MSR codes from\n[3] to achieve the optimal curve of the trade-off. \n\n"}
{"id": "1805.07876", "contents": "Title: Noncoherent Short-Packet Communication via Modulation on Conjugated\n  Zeros Abstract: We introduce a novel blind (noncoherent) communication scheme, called\nmodulation on conjugate-reciprocal zeros (MOCZ), to reliably transmit short\nbinary packets over unknown finite impulse response systems as used, for\nexample, to model underspread wireless multipath channels. In MOCZ, the\ninformation is modulated onto the zeros of the transmitted signals\n$z-$transform. In the absence of additive noise, the zero structure of the\nsignal is perfectly preserved at the receiver, no matter what the channel\nimpulse response (CIR) is. Furthermore, by a proper selection of the zeros, we\nshow that MOCZ is not only invariant to the CIR, but also robust against\nadditive noise. Starting with the maximum-likelihood estimator, we define a low\ncomplexity and reliable decoder and compare it to various state-of-the art\nnoncoherent schemes. \n\n"}
{"id": "1805.07958", "contents": "Title: Can Hardware Distortion Correlation be Neglected When Analyzing Uplink\n  SE in Massive MIMO? Abstract: This paper analyzes how the distortion created by hardware impairments in a\nmultiple-antenna base station affects the uplink spectral efficiency (SE), with\nfocus on Massive MIMO. The distortion is correlated across the antennas, but\nhas been often approximated as uncorrelated to facilitate (tractable) SE\nanalysis. To determine when this approximation is accurate, basic properties of\nthe distortion correlation are first uncovered. Then, we focus on third-order\nnon-linearities and prove analytically and numerically that the correlation can\nbe neglected in the SE analysis when there are many users. In i.i.d. Rayleigh\nfading with equal signal-to-noise ratios, this occurs when having five users. \n\n"}
{"id": "1805.08925", "contents": "Title: Covert Transmission with a Self-sustained Relay Abstract: This work examines the possibility, performance limits, and associated costs\nfor a self-sustained relay to transmit its own covert information to a\ndestination on top of forwarding the source's information. Since the source\nprovides energy to the relay for forwarding its information, the source does\nnot allow the relay's covert transmission and is to detect it. Considering the\ntime switching (TS) and power splitting (PS) schemes for energy harvesting,\nwhere all the harvested energy is used for transmission at the self-sustained\nrelay, we derive the minimum detection error probability $\\xi^{\\ast}$ at the\nsource, based on which we determine the maximum effective covert rate\n$\\Psi^{\\ast}$ subject to a given covertness constraint on $\\xi^{\\ast}$. Our\nanalysis shows that $\\xi^{\\ast}$ is the same for the TS and PS schemes, which\nleads to the fact that the cost of achieving $\\Psi^{\\ast}$ in both the two\nschemes in terms of the required increase in the energy conversion efficiency\nat the relay is the same, although the values of $\\Psi^{\\ast}$ in these two\nschemes can be different in specific scenarios. For example, the TS scheme\noutperforms the PS scheme in terms of achieving a higher $\\Psi^{\\ast}$ when the\ntransmit power at the source is relatively low. If the covertness constraint is\ntighter than a specific value, it is the covertness constraint that limits\n$\\Psi^{\\ast}$, and otherwise it is upper bound on the energy conversion\nefficiency that limits $\\Psi^{\\ast}$. \n\n"}
{"id": "1805.11090", "contents": "Title: GenAttack: Practical Black-box Attacks with Gradient-Free Optimization Abstract: Deep neural networks are vulnerable to adversarial examples, even in the\nblack-box setting, where the attacker is restricted solely to query access.\nExisting black-box approaches to generating adversarial examples typically\nrequire a significant number of queries, either for training a substitute\nnetwork or performing gradient estimation. We introduce GenAttack, a\ngradient-free optimization technique that uses genetic algorithms for\nsynthesizing adversarial examples in the black-box setting. Our experiments on\ndifferent datasets (MNIST, CIFAR-10, and ImageNet) show that GenAttack can\nsuccessfully generate visually imperceptible adversarial examples against\nstate-of-the-art image recognition models with orders of magnitude fewer\nqueries than previous approaches. Against MNIST and CIFAR-10 models, GenAttack\nrequired roughly 2,126 and 2,568 times fewer queries respectively, than ZOO,\nthe prior state-of-the-art black-box attack. In order to scale up the attack to\nlarge-scale high-dimensional ImageNet models, we perform a series of\noptimizations that further improve the query efficiency of our attack leading\nto 237 times fewer queries against the Inception-v3 model than ZOO.\nFurthermore, we show that GenAttack can successfully attack some\nstate-of-the-art ImageNet defenses, including ensemble adversarial training and\nnon-differentiable or randomized input transformations. Our results suggest\nthat evolutionary algorithms open up a promising area of research into\neffective black-box attacks. \n\n"}
{"id": "1805.11530", "contents": "Title: Neural Network Aided Decoding for Physical-Layer Network Coding Random\n  Access Abstract: Hinging on ideas from physical-layer network coding, some promising proposals\nof coded random access systems seek to improve system performance (while\npreserving low complexity) by means of packet repetitions and decoding of\nlinear combinations of colliding packets, whenever the decoding of individual\npackets fails. The resulting linear combinations are then temporarily stored in\nthe hope of gathering enough linearly independent combinations so as to\neventually recover all individual packets through the resolution of a linear\nsystem at the end of the contention frame. However, it is unclear which among\nthe numerous linear combinations---whose number grows exponentially with the\ndegree of collision---will have low probability of decoding error. Since no\nanalytical framework exists to determine which combinations are easiest to\ndecode, this makes the case for a machine learning algorithm to assist the\nreceiver in deciding which linear combinations to target. For this purpose, we\ntrain neural networks that approximate the error probability for every possible\nlinear combination based on the estimated channel gains and demonstrate the\neffectiveness of our approach by numerical simulations. \n\n"}
{"id": "1805.11892", "contents": "Title: Multi-Message Private Information Retrieval with Private Side\n  Information Abstract: We consider the problem of private information retrieval (PIR) where a single\nuser with private side information aims to retrieve multiple files from a\nlibrary stored (uncoded) at a number of servers. We assume the side information\nat the user includes a subset of files stored privately (i.e., the server does\nnot know the indices of these files). In addition, we require that the identity\nof the requests and side information at the user are not revealed to any of the\nservers. The problem involves finding the minimum load to be transmitted from\nthe servers to the user such that the requested files can be decoded with the\nhelp of received and side information. By providing matching lower and upper\nbounds, for certain regimes, we characterize the minimum load imposed to all\nthe servers (i.e., the capacity of this PIR problem). Our result shows that the\ncapacity is the same as the capacity of a multi-message PIR problem without\nprivate side information, but with a library of reduced size. The effective\nsize of the library is equal to the original library size minus the size of\nside information. \n\n"}
{"id": "1806.00673", "contents": "Title: Hybrid Data-Sharing and Compression Strategy for Downlink Cloud Radio\n  Access Network Abstract: This paper studies transmission strategies for the downlink of a cloud radio\naccess network, in which the base stations are connected to a centralized\ncloud-computing based processor with digital fronthaul or backhaul links. We\nprovide a system-level performance comparison of two fundamentally different\nstrategies, namely the data-sharing strategy and the compression strategy, that\ndiffer in the way the fronthaul/backhaul is utilized. It is observed that the\nperformance of both strategies depends crucially on the available fronthaul or\nbackhaul capacity. When the fronthaul/backhaul capacity is low, the datasharing\nstrategy performs better, while under moderate-to-high fronthaul/backhaul\ncapacity, the compression strategy is superior. Using insights from such a\ncomparison, we propose a novel hybrid strategy, combining the data-sharing and\ncompression strategies, that allows for better control over the\nfronthaul/backhaul capacity utilization. An optimization framework for the\nhybrid strategy is proposed. Numerical evidence demonstrates the performance\ngain of the hybrid strategy. \n\n"}
{"id": "1806.01471", "contents": "Title: PAC-learning in the presence of evasion adversaries Abstract: The existence of evasion attacks during the test phase of machine learning\nalgorithms represents a significant challenge to both their deployment and\nunderstanding. These attacks can be carried out by adding imperceptible\nperturbations to inputs to generate adversarial examples and finding effective\ndefenses and detectors has proven to be difficult. In this paper, we step away\nfrom the attack-defense arms race and seek to understand the limits of what can\nbe learned in the presence of an evasion adversary. In particular, we extend\nthe Probably Approximately Correct (PAC)-learning framework to account for the\npresence of an adversary. We first define corrupted hypothesis classes which\narise from standard binary hypothesis classes in the presence of an evasion\nadversary and derive the Vapnik-Chervonenkis (VC)-dimension for these, denoted\nas the adversarial VC-dimension. We then show that sample complexity upper\nbounds from the Fundamental Theorem of Statistical learning can be extended to\nthe case of evasion adversaries, where the sample complexity is controlled by\nthe adversarial VC-dimension. We then explicitly derive the adversarial\nVC-dimension for halfspace classifiers in the presence of a sample-wise\nnorm-constrained adversary of the type commonly studied for evasion attacks and\nshow that it is the same as the standard VC-dimension, closing an open\nquestion. Finally, we prove that the adversarial VC-dimension can be either\nlarger or smaller than the standard VC-dimension depending on the hypothesis\nclass and adversary, making it an interesting object of study in its own right. \n\n"}
{"id": "1806.01799", "contents": "Title: Survey and Taxonomy of Lossless Graph Compression and Space-Efficient\n  Graph Representations Abstract: Various graphs such as web or social networks may contain up to trillions of\nedges. Compressing such datasets can accelerate graph processing by reducing\nthe amount of I/O accesses and the pressure on the memory subsystem. Yet,\nselecting a proper compression method is challenging as there exist a plethora\nof techniques, algorithms, domains, and approaches in compressing graphs. To\nfacilitate this, we present a survey and taxonomy on lossless graph compression\nthat is the first, to the best of our knowledge, to exhaustively analyze this\ndomain. Moreover, our survey does not only categorize existing schemes, but\nalso explains key ideas, discusses formal underpinning in selected works, and\ndescribes the space of the existing compression schemes using three dimensions:\nareas of research (e.g., compressing web graphs), techniques (e.g., gap\nencoding), and features (e.g., whether or not a given scheme targets dynamic\ngraphs). Our survey can be used as a guide to select the best lossless\ncompression scheme in a given setting. \n\n"}
{"id": "1806.02005", "contents": "Title: Swift-Link: A compressive beam alignment algorithm for practical mmWave\n  radios Abstract: Next generation wireless networks will exploit the large amount of spectrum\navailable at millimeter wave (mmWave) frequencies. Design of mmWave systems,\nhowever, is challenging due to strict power, cost and hardware constraints at\nhigher bandwidths. To achieve a good SNR for communication, mmWave systems use\nlarge antenna arrays. Beamforming with highly directional beams is one way to\nuse the antennas. As the channel changes over time, the beams that maximize the\nSNR have to be estimated quickly to reduce the training overhead. Prior work\nhas exploited the observation that mmWave channels are sparse to perform\ncompressed sensing (CS) based beam alignment with few channel measurements.\nMost of the existing CS-based algorithms, however, assume perfect\nsynchronization and fail in the presence of carrier frequency offset (CFO).\nThis paper presents Swift-Link, a fast beam alignment algorithm that is robust\nagainst the offset. Swift-Link includes a novel randomized beam training\nsequence that minimizes the beam alignment errors due to CFO and a\nlow-complexity algorithm that corrects these errors. Even with strict hardware\nconstraints, our algorithm uses fewer channel measurements than comparable CS\nalgorithms and has analytical guarantees. Swift-Link requires a small output\ndynamic range at the analog-to-digital converter compared to beam-scanning\ntechniques. \n\n"}
{"id": "1806.02015", "contents": "Title: Distributed Hypothesis Testing with Privacy Constraints Abstract: We revisit the distributed hypothesis testing (or hypothesis testing with\ncommunication constraints) problem from the viewpoint of privacy. Instead of\nobserving the raw data directly, the transmitter observes a sanitized or\nrandomized version of it. We impose an upper bound on the mutual information\nbetween the raw and randomized data. Under this scenario, the receiver, which\nis also provided with side information, is required to make a decision on\nwhether the null or alternative hypothesis is in effect. We first provide a\ngeneral lower bound on the type-II exponent for an arbitrary pair of\nhypotheses. Next, we show that if the distribution under the alternative\nhypothesis is the product of the marginals of the distribution under the null\n(i.e., testing against independence), then the exponent is known exactly.\nMoreover, we show that the strong converse property holds. Using ideas from\nEuclidean information theory, we also provide an approximate expression for the\nexponent when the communication rate is low and the privacy level is high.\nFinally, we illustrate our results with a binary and a Gaussian example. \n\n"}
{"id": "1806.03516", "contents": "Title: A Taxonomy of Malicious Traffic for Intrusion Detection Systems Abstract: With the increasing number of network threats it is essential to have a\nknowledge of existing and new network threats in order to design better\nintrusion detection systems. In this paper we propose a taxonomy for\nclassifying network attacks in a consistent way, allowing security researchers\nto focus their efforts on creating accurate intrusion detection systems and\ntargeted datasets. \n\n"}
{"id": "1806.04583", "contents": "Title: Network-Connected UAV Communications: Potentials and Challenges Abstract: This article explores the use of network-connected unmanned aerial vehicle\n(UAV) communications as a compelling solution to achieve high-rate information\ntransmission and support ultra-reliable UAV remote command and control. We\nfirst discuss the use cases of UAVs and the resulting communication\nrequirements, accompanied with a flexible architecture for network-connected\nUAV communications. Then, the signal transmission and interference\ncharacteristics are theoretically analyzed, and subsequently we highlight the\ndesign and optimization considerations, including antenna design,\nnon-orthogonal multiple access communications, as well as network selection and\nassociation optimization. Finally, case studies are provided to show the\nfeasibility of network-connected UAV communications. \n\n"}
{"id": "1806.04589", "contents": "Title: Computation Rate Maximization in UAV-Enabled Wireless Powered\n  Mobile-Edge Computing Systems Abstract: Mobile edge computing (MEC) and wireless power transfer (WPT) are two\npromising techniques to enhance the computation capability and to prolong the\noperational time of low-power wireless devices that are ubiquitous in Internet\nof Things. However, the computation performance and the harvested energy are\nsignificantly impacted by the severe propagation loss. In order to address this\nissue, an unmanned aerial vehicle (UAV)-enabled MEC wireless powered system is\nstudied in this paper. The computation rate maximization problems in a\nUAV-enabled MEC wireless powered system are investigated under both partial and\nbinary computation offloading modes, subject to the energy harvesting causal\nconstraint and the UAV's speed constraint. These problems are non-convex and\nchallenging to solve. A two-stage algorithm and a three-stage alternative\nalgorithm are respectively proposed for solving the formulated problems. The\nclosed-form expressions for the optimal central processing unit frequencies,\nuser offloading time, and user transmit power are derived. The optimal\nselection scheme on whether users choose to locally compute or offload\ncomputation tasks is proposed for the binary computation offloading mode.\nSimulation results show that our proposed resource allocation schemes\noutperforms other benchmark schemes. The results also demonstrate that the\nproposed schemes converge fast and have low computational complexity. \n\n"}
{"id": "1806.05241", "contents": "Title: Quasi-tight Framelets with Directionality or High Vanishing Moments\n  Derived from Arbitrary Refinable Functions Abstract: Construction of multivariate tight framelets is known to be a challenging\nproblem. Multivariate dual framelets with vanishing moments generalize tight\nframelets and are not easy to be constructed either. Compactly supported\nmultivariate framelets with directionality or high vanishing moments are of\ninterest and importance in both theory and applications. In this paper we\nintroduce the notion of a quasi-tight framelet, which is a dual framelet, but\nbehaves almost like a tight framelet. Let $\\phi\\in L_2(R^d)$ be an arbitrary\ncompactly supported $M$-refinable function such that its underlying low-pass\nfilter satisfies the basic sum rule. We first constructively prove by a\nstep-by-step algorithm that we can always easily derive from the arbitrary\n$M$-refinable function $\\phi$ a directional compactly supported quasi-tight\n$M$-framelet in $L_2(R^d)$ associated with a directional quasi-tight\n$M$-framelet filter bank, each of whose high-pass filters has only two nonzero\ncoefficients with opposite signs. If in addition all the coefficients of its\nlow-pass filter are nonnegative, such a quasi-tight $M$-framelet becomes a\ndirectional tight $M$-framelet in $L_2(R^d)$. Furthermore, we show by a\nconstructive algorithm that we can always derive from the arbitrary\n$M$-refinable function $\\phi$ a compactly supported quasi-tight $M$-framelet in\n$L_2(R^d)$ with the highest possible order of vanishing moments. We shall also\npresent a result on quasi-tight framelets whose associated high-pass filters\nare purely differencing filters with the highest order of vanishing moments.\nSeveral examples will be provided to illustrate our main theoretical results\nand algorithms in this paper. \n\n"}
{"id": "1806.05776", "contents": "Title: Tiny Codes for Guaranteeable Delay Abstract: Future 5G systems will need to support ultra-reliable low-latency\ncommunications scenarios. From a latency-reliability viewpoint, it is\ninefficient to rely on average utility-based system design. Therefore, we\nintroduce the notion of guaranteeable delay which is the average delay plus\nthree standard deviations of the mean. We investigate the trade-off between\nguaranteeable delay and throughput for point-to-point wireless erasure links\nwith unreliable and delayed feedback, by bringing together signal flow\ntechniques to the area of coding. We use tiny codes, i.e. sliding window by\ncoding with just 2 packets, and design three variations of selective-repeat ARQ\nprotocols, by building on the baseline scheme, i.e. uncoded ARQ, developed by\nAusavapattanakun and Nosratinia: (i) Hybrid ARQ with soft combining at the\nreceiver; (ii) cumulative feedback-based ARQ without rate adaptation; and (iii)\nCoded ARQ with rate adaptation based on the cumulative feedback. Contrasting\nthe performance of these protocols with uncoded ARQ, we demonstrate that HARQ\nperforms only slightly better, cumulative feedback-based ARQ does not provide\nsignificant throughput while it has better average delay, and Coded ARQ can\nprovide gains up to about 40% in terms of throughput. Coded ARQ also provides\ndelay guarantees, and is robust to various challenges such as imperfect and\ndelayed feedback, burst erasures, and round-trip time fluctuations. This\nfeature may be preferable for meeting the strict end-to-end latency and\nreliability requirements of future use cases of ultra-reliable low-latency\ncommunications in 5G, such as mission-critical communications and industrial\ncontrol for critical control messaging. \n\n"}
{"id": "1806.07761", "contents": "Title: Quick and Plenty: Achieving Low Delay and High Rate in 802.11ac Edge\n  Networks Abstract: We consider transport layer approaches for achieving high rate, low delay\ncommunication over edge paths where the bottleneck is an 802.11ac WLAN. We\nfirst show that by regulating send rate so as to maintain a target aggregation\nlevel it is possible to realise high rate, low delay communication over\n802.11ac WLANs. We then address two important practical issues arising in\nproduction networks, namely that (i) many client devices are non-rooted mobile\nhandsets/tablets and (ii) the bottleneck may lie in the backhaul rather than\nthe WLAN, or indeed vary between the two over time. We show that both these\nissues can be resolved by use of simple and robust machine learning techniques.\nWe present a prototype transport layer implementation of our low delay rate\nallocation approach and use this to evaluate performance under real radio\nconditions. \n\n"}
{"id": "1806.08006", "contents": "Title: Private Information Retrieval from Coded Storage Systems with Colluding,\n  Byzantine, and Unresponsive Servers Abstract: The problem of Private Information Retrieval (PIR) from coded storage systems\nwith colluding, byzantine, and unresponsive servers is considered. An explicit\nscheme using an $[n,k]$ Reed-Solomon storage code is designed, protecting\nagainst $t$-collusion and handling up to $b$ byzantine and $r$ unresponsive\nservers, when $n>k+t+2b+r-1$. This scheme achieves a PIR rate of\n$\\frac{n-r-(k+2b+t-1)}{n-r}$. In the case where the capacity is known, namely\nwhen $k=1$, it is asymptotically capacity-achieving as the number of files\ngrows. Lastly, the scheme is adapted to symmetric PIR. \n\n"}
{"id": "1806.09387", "contents": "Title: Outage of Periodic Downlink Wireless Networks with Hard Deadlines Abstract: We consider a downlink periodic wireless communications system where multiple\naccess points (APs) cooperatively transmit packets to a number of devices, e.g.\nactuators in an industrial control system. Each period consists of two phases:\nan uplink training phase and a downlink data transmission phase. Each actuator\nmust successfully receive its unique packet within a single transmission phase,\nelse an outage is declared. Such an outage can be caused by two events: a\ntransmission error due to transmission at a rate that the channel cannot\nactually support or time overflow, where the downlink data phase is too short\ngiven the channel conditions to successfully communicate all the packets. We\ndetermine closed-form expressions for the probability of time overflow when\nthere are just two field devices, as well as the probability of transmission\nerror for an arbitrary number of devices. Also, we provide upper and lower\nbounds on the time overflow probability for an arbitrary number of devices. We\npropose a novel variable-rate transmission method that eliminates time\noverflow. Detailed system-level simulations are used to identify system design\nguidelines, such as the optimal amount of uplink training time, as well as for\nbenchmarking the proposed system design versus non-cooperative cellular,\ncooperative fixed-rate, and cooperative relaying. \n\n"}
{"id": "1806.10583", "contents": "Title: On the Error in Phase Transition Computations for Compressed Sensing Abstract: Evaluating the statistical dimension is a common tool to determine the\nasymptotic phase transition in compressed sensing problems with Gaussian\nensemble. Unfortunately, the exact evaluation of the statistical dimension is\nvery difficult and it has become standard to replace it with an upper-bound. To\nensure that this technique is suitable, [1] has introduced an upper-bound on\nthe gap between the statistical dimension and its approximation. In this work,\nwe first show that the error bound in [1] in some low-dimensional models such\nas total variation and $\\ell_1$ analysis minimization becomes poorly large.\nNext, we develop a new error bound which significantly improves the estimation\ngap compared to [1]. In particular, unlike the bound in [1] that is not\napplicable to settings with overcomplete dictionaries, our bound exhibits a\ndecaying behavior in such cases. \n\n"}
{"id": "1807.00145", "contents": "Title: Sampling and Reconstruction of Signals on Product Graphs Abstract: In this paper, we consider the problem of subsampling and reconstruction of\nsignals that reside on the vertices of a product graph, such as sensor network\ntime series, genomic signals, or product ratings in a social network.\nSpecifically, we leverage the product structure of the underlying domain and\nsample nodes from the graph factors. The proposed scheme is particularly useful\nfor processing signals on large-scale product graphs. The sampling sets are\ndesigned using a low-complexity greedy algorithm and can be proven to be\nnear-optimal. To illustrate the developed theory, numerical experiments based\non real datasets are provided for sampling 3D dynamic point clouds and for\nactive learning in recommender systems. \n\n"}
{"id": "1807.00801", "contents": "Title: Deepcode: Feedback Codes via Deep Learning Abstract: The design of codes for communicating reliably over a statistically well\ndefined channel is an important endeavor involving deep mathematical research\nand wide-ranging practical applications. In this work, we present the first\nfamily of codes obtained via deep learning, which significantly beats\nstate-of-the-art codes designed over several decades of research. The\ncommunication channel under consideration is the Gaussian noise channel with\nfeedback, whose study was initiated by Shannon; feedback is known theoretically\nto improve reliability of communication, but no practical codes that do so have\never been successfully constructed.\n  We break this logjam by integrating information theoretic insights\nharmoniously with recurrent-neural-network based encoders and decoders to\ncreate novel codes that outperform known codes by 3 orders of magnitude in\nreliability. We also demonstrate several desirable properties of the codes: (a)\ngeneralization to larger block lengths, (b) composability with known codes, (c)\nadaptation to practical constraints. This result also has broader ramifications\nfor coding theory: even when the channel has a clear mathematical model, deep\nlearning methodologies, when combined with channel-specific\ninformation-theoretic insights, can potentially beat state-of-the-art codes\nconstructed over decades of mathematical research. \n\n"}
{"id": "1807.00929", "contents": "Title: Log-Concave Polynomials I: Entropy and a Deterministic Approximation\n  Algorithm for Counting Bases of Matroids Abstract: We give a deterministic polynomial time $2^{O(r)}$-approximation algorithm\nfor the number of bases of a given matroid of rank $r$ and the number of common\nbases of any two matroids of rank $r$. To the best of our knowledge, this is\nthe first nontrivial deterministic approximation algorithm that works for\narbitrary matroids. Based on a lower bound of Azar, Broder, and Frieze [ABF94]\nthis is almost the best possible result assuming oracle access to independent\nsets of the matroid.\n  There are two main ingredients in our result: For the first, we build upon\nrecent results of Adiprasito, Huh, and Katz [AHK15] and Huh and Wang [HW17] on\ncombinatorial hodge theory to derive a connection between matroids and\nlog-concave polynomials. We expect that several new applications in\napproximation algorithms will be derived from this connection in future.\nFormally, we prove that the multivariate generating polynomial of the bases of\nany matroid is log-concave as a function over the positive orthant. For the\nsecond ingredient, we develop a general framework for approximate counting in\ndiscrete problems, based on convex optimization. The connection goes through\nsubadditivity of the entropy. For matroids, we prove that an approximate\nsuperadditivity of the entropy holds by relying on the log-concavity of the\ncorresponding polynomials. \n\n"}
{"id": "1807.01185", "contents": "Title: Robustness of Two-Dimensional Line Spectral Estimation Against Spiky\n  Noise Abstract: The aim of two-dimensional line spectral estimation is to super-resolve the\nspectral point sources of the signal from time samples. In many associated\napplications such as radar and sonar, due to cut-off and saturation regions in\nelectronic devices, some of the numbers of samples are corrupted by spiky\nnoise. To overcome this problem, we present a new convex program to\nsimultaneously estimate spectral point sources and spiky noise in two\ndimensions. To prove uniqueness of the solution, it is sufficient to show that\na dual certificate exists. Construction of the dual certificate imposes a mild\ncondition on the separation of the spectral point sources. Also, the number of\nspikes and detectable sparse sources are shown to be a logarithmic function of\nthe number of time samples. Simulation results confirm the conclusions of our\ngeneral theory. \n\n"}
{"id": "1807.01432", "contents": "Title: Treating Content Delivery in Multi-Antenna Coded Caching as General\n  Message Sets Transmission: A DoF Region Perspective Abstract: Coded caching can create coded multicasting thus significantly accelerates\ncontent delivery in broadcast channels with receiver caches. While the original\ndelivery scheme in coded caching multicasts each coded message sequentially, it\nis not optimal for multiple-input multiple-output (MIMO) broadcast channels.\nThis work aims to investigate the full spatial multiplexing gain in\nmulti-antenna coded caching by transmitting all coded messages concurrently. In\nspecific, we propose to treat the content delivery as the transmission problem\nwith general message sets where all possible messages are present, each with\ndifferent length and intended for different user set. We first obtain inner and\nouter bounds of the degrees of freedom (DoF) region of a $K$-user $(M,N)$\nbroadcast channel with general message sets, with $M$ and $N$ being the number\nof transmit and receive antennas, respectively. Then for any given set of coded\nmessages, we find its minimum normalized delivery time (NDT) by searching the\noptimal DoF tuple in the DoF regions. The obtained minimum NDT is optimal at\nantenna configuration $\\frac{M}{N} \\in (0,1]\\cup[K, \\infty)$ and is within a\nmultiplicative gap of $\\frac{M}{N}$ to optimum at $\\frac{M}{N} \\in (1,K)$. Our\nNDT results can be evaluated for any user demand with both centralized and\ndecentralized cache placement. \n\n"}
{"id": "1807.02683", "contents": "Title: Diffusive Molecular Communication in Biological Cylindrical Environment Abstract: Diffusive molecular communication (DMC) is one of the most promising\napproaches for realizing nano-scale communications in biological environments\nfor healthcare applications. In this paper, a DMC system in biological\ncylindrical environment is considered, inspired by blood vessel structures in\nthe body. The internal surface of the cylinder boundary is assumed to be\ncovered by the biological receptors which may irreversibly react with hitting\nmolecules. Also, information molecules diffusing in the fluid medium are\nsubject to a degradation reaction and flow. The concentration Green's function\nof diffusion in this environment is analytically derived which takes into\naccount asymmetry in all radial, axial and azimuthal coordinates. Employing\nobtained Green's function, information channel between transmitter and\ntransparent receiver of DMC is characterized. To evaluate the DMC system in the\nbiological cylinder, a simple on-off keying modulation scheme is adopted and\ncorresponding error probability is derived. Particle based simulation results\nconfirm the proposed analysis. Also, the effect of different system parameters\non the concentration Green's function are examined. Our results reveal that the\ndegradation reaction and the boundary covered by biological receptors may be\nutilized to mitigate intersymbol interference and outperform corresponding\nerror probability. \n\n"}
{"id": "1807.05473", "contents": "Title: Codes with hierarchical locality from covering maps of curves Abstract: Locally recoverable (LRC) codes provide ways of recovering erased coordinates\nof the codeword without having to access each of the remaining coordinates. A\nsubfamily of LRC codes with hierarchical locality (H-LRC codes) provides added\nflexibility to the construction by introducing several tiers of recoverability\nfor correcting different numbers of erasures. We present a general construction\nof codes with 2-level hierarchical locality from maps between algebraic curves\nand specialize it to several code families obtained from quotients of curves by\na subgroup of the automorphism group, including rational, elliptic, Kummer, and\nArtin-Schreier curves. We further address the question of H-LRC codes with\navailability, and suggest a general construction of such codes from fiber\nproducts of curves. Detailed calculations of parameters for H-LRC codes with\navailability are performed for Reed-Solomon- and Hermitian-like code families.\nFinally, we construct asymptotically good families of H-LRC codes from curves\nrelated to the Garcia-Stichtenoth tower. \n\n"}
{"id": "1807.06463", "contents": "Title: Performance Evaluation and Optimization of LPWA IoT Networks: A\n  Stochastic Geometry Approach Abstract: Leveraging grant-free radio access for enabling lowpower wide-area (LPWA)\nInternet of Things (IoT) connectivity has attracted lots of attention in recent\nyears. Regarding lack of research on LPWA IoT networks, this work is devoted to\nreliability modeling, battery-lifetime analysis, and operation-control of such\nnetworks. We derive the interplay amongst density of the access points,\ncommunication bandwidth, volume of traffic from heterogeneous sources, and\nquality of service (QoS) in communications. The presented analytical framework\ncomprises modeling of interference from heterogeneous sources with correlated\ndeployment locations and time-frequency asynchronous radio-resource usage\npatterns. The derived expressions represent the operation regions and rates in\nwhich, energy and cost resources of devices and the access network,\nrespectively, could be traded to achieve a given level of QoS in\ncommunications. For example, our expressions indicate the expected increase in\nQoS by increasing number of transmitted replicas, transmit power, density of\nthe access points, and communication bandwidth. Our results further shed light\non scalability of such networks and figure out the bounds up to which, scaling\nresources can compensate the increase in traffic volume and QoS demand.\nFinally, we present an energy-optimized operation control policy for IoT\ndevices. The simulation results confirm tightness of the derived analytical\nexpressions, and indicate usefulness of them in planning and operation control\nof IoT networks. \n\n"}
{"id": "1807.07095", "contents": "Title: Ricci curvature for parametric statistics via optimal transport Abstract: We elaborate the notion of a Ricci curvature lower bound for parametrized\nstatistical models. Following the seminal ideas of Lott-Strum-Villani, we\ndefine this notion based on the geodesic convexity of the Kullback-Leibler\ndivergence in a Wasserstein statistical manifold, that is, a manifold of\nprobability distributions endowed with a Wasserstein metric tensor structure.\nWithin these definitions, the Ricci curvature is related to both, information\ngeometry and Wasserstein geometry. These definitions allow us to formulate\nbounds on the convergence rate of Wasserstein gradient flows and information\nfunctional inequalities in parameter space. We discuss examples of Ricci\ncurvature lower bounds and convergence rates in exponential family models. \n\n"}
{"id": "1807.07648", "contents": "Title: An improved uncertainty principle for functions with symmetry Abstract: Chebotar\\\"ev proved that every minor of a discrete Fourier matrix of prime\norder is nonzero. We prove a generalization of this result that includes\nanalogues for discrete cosine and discrete sine matrices as special cases. We\nestablish these results via a generalization of the Bir\\'o-Meshulam-Tao\nuncertainty principle to functions with symmetries that arise from certain\ngroup actions, with some of the simplest examples being even and odd functions.\nWe show that our result is best possible and in some cases is stronger than\nthat of Bir\\'o-Meshulam-Tao. Some of these results hold in certain\ncircumstances for non-prime fields; Gauss sums play a central role in such\ninvestigations. \n\n"}
{"id": "1807.10262", "contents": "Title: Seeded Graph Matching via Large Neighborhood Statistics Abstract: We study a well known noisy model of the graph isomorphism problem. In this\nmodel, the goal is to perfectly recover the vertex correspondence between two\nedge-correlated Erd\\H{o}s-R\\'{e}nyi random graphs, with an initial seed set of\ncorrectly matched vertex pairs revealed as side information. For seeded\nproblems, our result provides a significant improvement over previously known\nresults. We show that it is possible to achieve the information-theoretic limit\nof graph sparsity in time polynomial in the number of vertices $n$. Moreover,\nwe show the number of seeds needed for exact recovery in polynomial-time can be\nas low as $n^{3\\epsilon}$ in the sparse graph regime (with the average degree\nsmaller than $n^{\\epsilon}$) and $\\Omega(\\log n)$ in the dense graph regime.\n  Our results also shed light on the unseeded problem. In particular, we give\nsub-exponential time algorithms for sparse models and an $n^{O(\\log n)}$\nalgorithm for dense models for some parameters, including some that are not\ncovered by recent results of Barak et al. \n\n"}
{"id": "1807.10617", "contents": "Title: Temporal connectivity in finite networks with non-uniform measures Abstract: Soft Random Geometric Graphs (SRGGs) have been widely applied to various\nmodels including those of wireless sensor, communication, social and neural\nnetworks. SRGGs are constructed by randomly placing nodes in some space and\nmaking pairwise links probabilistically using a connection function that is\nsystem specific and usually decays with distance. In this paper we focus on the\napplication of SRGGs to wireless communication networks where information is\nrelayed in a multi hop fashion, although the analysis is more general and can\nbe applied elsewhere by using different distributions of nodes and/or\nconnection functions. We adopt a general non-uniform density which can model\nthe stationary distribution of different mobility models, with the interesting\ncase being when the density goes to zero along the boundaries. The global\nconnectivity properties of these non-uniform networks are likely to be\ndetermined by highly isolated nodes, where isolation can be caused by the\nspatial distribution or the local geometry (boundaries). We extend the analysis\nto temporal-spatial networks where we fix the underlying non-uniform\ndistribution of points and the dynamics are caused by the temporal variations\nin the link set, and explore the probability a node near the corner is isolated\nat time $T$. This work allows for insight into how non-uniformity (caused by\nmobility) and boundaries impact the connectivity features of temporal-spatial\nnetworks. We provide a simple method for approximating these probabilities for\na range of different connection functions and verify them against simulations.\nBoundary nodes are numerically shown to dominate the connectivity properties of\nthese finite networks with non-uniform measure. \n\n"}
{"id": "1808.00591", "contents": "Title: Impact of Beam Misalignment on Hybrid Beamforming NOMA for mmWave\n  Communications Abstract: This paper studies hybrid beamforming (HB)-based non-orthogonal multiple\naccess (NOMA) in multiuser millimeter wave (mmWave) communications. HB offers\npower-efficient and low-complexity precoding for downlink multiuser mmWave\nsystems which increases multiplexing gain and spectral efficiency of the\nsystem. Applying NOMA to HB-based systems, called HB-NOMA, can scale the number\nof users while offering a high spectral efficiency. However, an imperfect\ncorrelation between the effective channels of users in each NOMA cluster\nseriously degrades the achievable rate of HB-NOMA. In this paper, first a\nsum-rate maximization problem is formulated for HB-NOMA, and an algorithm is\nproposed to solve it effectively. It is then shown that the relationship\nbetween the effective channels of the users in each NOMA cluster can be\napproximated by a correlation factor. Next, the effect of imperfect correlation\nis analyzed, and a lower bound on the achievable rate of the users is derived\nfor both perfect and imperfect correlation. Finally, the rate gap resulting\nfrom an imperfect correlation is evaluated and a tight upper bound is derived\nfor that. Simulation results show that low correlation degrades the achievable\nrate of users. The lower bounds are tight in the large dimensional regime and\nin single-path channels. \n\n"}
{"id": "1808.01750", "contents": "Title: Beyond the Central Limit Theorem: Universal and Non-universal\n  Simulations of Random Variables by General Mappings Abstract: Motivated by the Central Limit Theorem, in this paper, we study both\nuniversal and non-universal simulations of random variables with an arbitrary\ntarget distribution $Q_{Y}$ by general mappings, not limited to linear ones (as\nin the Central Limit Theorem). We derive the fastest convergence rate of the\napproximation errors for such problems. Interestingly, we show that for\ndiscontinuous or absolutely continuous $P_{X}$, the approximation error for the\nuniversal simulation is almost as small as that for the non-universal one; and\nmoreover, for both universal and non-universal simulations, the approximation\nerrors by general mappings are strictly smaller than those by linear mappings.\nFurthermore, we also generalize these results to simulation from Markov\nprocesses, and simulation of random elements (or general random variables). \n\n"}
{"id": "1808.01896", "contents": "Title: Two Practical Random-Subcarrier-Selection Methods for Secure Precise\n  Wireless Transmission Abstract: In secure precise directional modulation (DM) networks, two practical\nrandom-subcarrier-selection (RSS) methods are proposed to transmit confidential\nmessage to the desired user per orthogonal frequency division multiplexing\n(OFDM) symbol with only single receive power peak formed by constructing random\nsubcarrier set and performing a randomization procedure. This scheme completely\naddresses the crucial problem facing secure precise wireless transmission\n(SPWT), how to achieve the SPWT per OFDM symbol while the traditional SPWT\nholds only in statistically average sense. Several necessary conditions for\nSPWT per OFDM is derived and proposed: randomly distributed, sparse, and\ndistinct subcarrier distance between two pair of adjacent antennas. Two random\nsubcarrier sets (RSSs), quadratic subcarrier set (QSS) and prime subcarrier set\n(PSS), are constructed, where the former means the subcarrier index associated\nwith any antennas is the square of antenna index, and the latter implies that\nthe subcarrier indices over all antennas are prime numbers. Subsequently,\nfollowing those conditions for SPWT per OFDM, a random factor is defined, and a\nrandomization procedure (RP) is proposed. Its detailed process includes the\nfollowing steps: integer mod, ordering, blocking, and block interleaving where\nBI is repeated until the random factor is greater than the predefined\nthreshold. This yields a single main receive energy peak (SMREP) at the desired\nposition with other positions, outside the SMREP, harvesting only weak receive\nenergy seriously corrupted by AN. \n\n"}
{"id": "1808.02023", "contents": "Title: Multi-Message Private Information Retrieval using Product-Matrix MSR and\n  MBR Codes Abstract: Multi-message private information retrieval (MPIR) is an interesting\nvariation of PIR which allows a user to download multiple messages from the\ndatabase without revealing the identity of the desired messages. Obviously, the\nuser can repeatly use a single-message PIR scheme, but we wish for a more\nefficient way to reduce the download cost. In [1], Banawan and Ukulus\ninvestigate the multi-message PIR problem with replicated database. In this\npaper, we consider multi-message PIR schemes where the database is stored using\nminimum storage regenerating (MSR) or minimum bandwidth regenerating (MBR)\ncodes which are classes of optimal regenerating codes providing efficient\nrepair when a node in the system fails. The relationships between the costs of\nstorage, retrieval and repair are analysed, and explicit schemes using the MSR\nand MBR codes from [2], which both achieve the optimal curve of the trade-off,\nare given. To the best of our knowledge, our work is the first to explore the\nmulti-message PIR with coded database. \n\n"}
{"id": "1808.04309", "contents": "Title: Precise Performance Analysis of the LASSO under Matrix Uncertainties Abstract: In this paper, we consider the problem of recovering an unknown sparse signal\n$\\xv_0 \\in \\mathbb{R}^n$ from noisy linear measurements $\\yv = \\Hm \\xv_0+ \\zv\n\\in \\mathbb{R}^m$. A popular approach is to solve the $\\ell_1$-norm regularized\nleast squares problem which is known as the LASSO. In many practical\nsituations, the measurement matrix $\\Hm$ is not perfectely known and we only\nhave a noisy version of it. We assume that the entries of the measurement\nmatrix $\\Hm$ and of the noise vector $\\zv$ are iid Gaussian with zero mean and\nvariances $1/n$ and $\\sigma_{\\zv}^2$. In this work, an imperfect measurement\nmatrix is considered under which we precisely characterize the limiting\nbehavior of the mean squared error and the probability of support recovery of\nthe LASSO. The analysis is performed when the problem dimensions grow\nsimultaneously to infinity at fixed rates. Numerical simulations validate the\ntheoretical predictions derived in this paper. \n\n"}
{"id": "1808.06062", "contents": "Title: The Capacity of Some P\\'olya String Models Abstract: We study random string-duplication systems, which we call P\\'olya string\nmodels. These are motivated by DNA storage in living organisms, and certain\nrandom mutation processes that affect their genome. Unlike previous works that\nstudy the combinatorial capacity of string-duplication systems, or various\nstring statistics, this work provides exact capacity or bounds on it, for\nseveral probabilistic models. In particular, we study the capacity of noisy\nstring-duplication systems, including the tandem-duplication, end-duplication,\nand interspersed-duplication systems. Interesting connections are drawn between\nsome systems and the signature of random permutations, as well as to the beta\ndistribution common in population genetics. \n\n"}
{"id": "1808.07097", "contents": "Title: Angle Feedback for NOMA Transmission in mmWave Drone Networks Abstract: In this paper, we consider an unmanned aerial vehicle (UAV) based wireless\nnetwork using non-orthogonal multiple access (NOMA) transmission in\nmillimeter-wave frequencies to deliver broadband data in a spectrally efficient\nfashion at hotspot scenarios. The necessity for the NOMA transmitter to gather\ninformation on user channel quality becomes a major drawback in practical\ndeployments. We therefore consider various limited feedback schemes for NOMA\ntransmission, to relieve the complexity of tracking and feeding back the full\nchannel state information (CSI) of the users. In particular, through\nbeamforming we allow NOMA to exploit the space domain, and hence the user angle\nemerges as a promising (yet novel) limited feedback scheme. We show that as the\nuser region for NOMA transmission gets wider, the users become more distinctive\nat the transmitter side with respect to their angles, making user angle\nfeedback a better alternative than distance feedback in such scenarios. We\nrigorously derive and analyze the outage sum rate performance for NOMA\ntransmission considering various user ordering strategies involving full CSI,\nangle, and distance feedback schemes. Our analytical results for NOMA outage\nsum rates using those feedback schemes match closely with simulations, and\nprovide useful insights on properly choosing a limited feedback scheme for\ndifferent deployment geometries and operating configurations. \n\n"}
{"id": "1808.09018", "contents": "Title: On the Fundamental Limit of Private Information Retrieval for Coded\n  Distributed Storage Abstract: We consider private information retrieval (PIR) for distributed storage\nsystems (DSSs) with noncolluding nodes where data is stored using a non maximum\ndistance separable (MDS) linear code. It was recently shown that if data is\nstored using a particular class of non-MDS linear codes, the MDS-PIR capacity,\ni.e., the maximum possible PIR rate for MDS-coded DSSs, can be achieved. For\nthis class of codes, we prove that the PIR capacity is indeed equal to the\nMDS-PIR capacity, giving the first family of non-MDS codes for which the PIR\ncapacity is known. For other codes, we provide asymmetric PIR protocols that\nachieve a strictly larger PIR rate compared to existing symmetric PIR\nprotocols. \n\n"}
{"id": "1809.02809", "contents": "Title: A conjecture on permutation trinomials over finite fields of\n  characteristic two Abstract: In this paper, by analyzing the quadratic factors of an $11$-th degree\npolynomial over the finite field $\\ftwon$, a conjecture on permutation\ntrinomials over $\\ftwon[x]$ proposed very recently by Deng and Zheng is\nsettled, where $n=2m$ and $m$ is a positive integer with $\\gcd(m,5)=1$. \n\n"}
{"id": "1809.03117", "contents": "Title: Mixed-ADC/DAC Multipair Massive MIMO Relaying Systems: Performance\n  Analysis and Power Optimization Abstract: High power consumption and expensive hardware are two bottlenecks for\npractical massive multiple-input multiple-output (mMIMO) systems. One promising\nsolution is to employ low-resolution analog-to-digital converters (ADCs) and\ndigital-to-analog converters (DACs). In this paper, we consider a general\nmultipair mMIMO relaying system with a mixed-ADC/DAC architecture, in which\nsome antennas are connected to low-resolution ADCs/DACs, while the rest of the\nantennas are connected to high-resolution ADCs/DACs. Leveraging on the additive\nquantization noise model, both exact and approximate closed-form expressions\nfor the achievable rate are derived. It is shown that the achievable rate can\napproach the unquantized one by using only 2-3 bits of resolutions. Moreover, a\npower scaling law is presented to reveal that the transmit power can be scaled\ndown inversely proportional to the number of antennas at the relay. We further\npropose an efficient power allocation scheme by solving a complementary\ngeometric programming problem. In addition, a trade-off between the achievable\nrate and power consumption for different numbers of low-resolution ADCs/DACs is\ninvestigated by deriving the energy efficiency. Our results reveal that the\nlarge antenna array can be exploited to enable the mixed-ADC/DAC architecture,\nwhich significantly reduces the power consumption and hardware cost for\npractical mMIMO systems. \n\n"}
{"id": "1809.04380", "contents": "Title: Binary MDS Array Codes with Optimal Repair Abstract: Consider a binary maximum distance separable (MDS) array code composed of an\n$m\\times (k+r)$ array of bits with $k$ information columns and $r$ parity\ncolumns, such that any $k$ out of $k+r$ columns suffice to reconstruct the $k$\ninformation columns. Our goal is to provide {\\em optimal repair access} for\nbinary MDS array codes, meaning that the bandwidth triggered to repair any\nsingle failed information or parity column is minimized. In this paper, we\npropose a generic transformation framework for binary MDS array codes, using\nEVENODD codes as a motivating example, to support optimal repair access for\n$k+1\\le d \\le k+r-1$, where $d$ denotes the number of non-failed columns that\nare connected for repair; note that when $d<k+r-1$, some of the chosen $d$\ncolumns in repairing a failed column are specific. In addition, we show how our\ntransformation framework applies to an example of binary MDS array codes with\nasymptotically optimal repair access of any single information column and\nenables asymptotically or exactly optimal repair access for any column.\nFurthermore, we present a new transformation for EVENODD codes with two parity\ncolumns such that the existing efficient repair property of any information\ncolumn is preserved and the repair access of parity column is optimal. \n\n"}
{"id": "1809.04727", "contents": "Title: Text-based Passwords Generated From Topological Graphic Passwords Abstract: Topological graphic passwords (Topsnut-gpws) are one of graph-type passwords,\nbut differ from the existing graphical passwords, since Topsnut-gpws are saved\nin computer by algebraic matrices. We focus on the transformation between\ntext-based passwords (TB-paws) and Topsnut-gpws in this article. Several\nmethods for generating TB-paws from Topsnut-gpws are introduced; these methods\nare based on topological structures and graph coloring/labellings, such that\nauthentications must have two steps: one is topological structure\nauthentication, and another is text-based authentication. Four basic\ntopological structure authentications are introduced and many text-based\nauthentications follow Topsnut-gpws. Our methods are based on algebraic, number\ntheory and graph theory, many of them can be transformed into polynomial\nalgorithms. A new type of matrices for describing Topsnut-gpws is created here,\nand such matrices can produce TB-paws in complex forms and longer bytes.\nEstimating the space of TB-paws made by Topsnut-gpws is very important for\napplication. We propose to encrypt dynamic networks and try to face: (1)\nthousands of nodes and links of dynamic networks; (2) large numbers of\nTopsnut-gpws generated by machines rather than human's hands. As a try, we\napply spanning trees of dynamic networks and graphic groups (Topsnut-groups) to\napproximate the solutions of these two problems. We present some unknown\nproblems in the end of the article for further research. \n\n"}
{"id": "1809.04798", "contents": "Title: Multi-Dimensional Spatially-Coupled Code Design Through Informed\n  Relocation of Circulants Abstract: A circulant-based spatially-coupled (SC) code is constructed by partitioning\nthe circulants of an underlying block code into a number of components, and\nthen coupling copies of these components together. By connecting (coupling)\nseveral SC codes, multi-dimensional SC (MD-SC) codes are constructed. In this\npaper, we present a systematic framework for constructing MD-SC codes with\nnotably better girth properties than their 1D-SC counterparts. In our\nframework, informed multi-dimensional coupling is performed via an optimal\nrelocation and an (optional) power adjustment of problematic circulants in the\nconstituent SC codes. Compared to the 1D-SC codes, our MD-SC codes are\ndemonstrated to have up to 85% reduction in the population of the smallest\ncycle, and up to 3.8 orders of magnitude BER improvement in the early error\nfloor region. The results of this work can be particularly beneficial in data\nstorage systems, e.g., 2D magnetic recording and 3D Flash systems, as\nhigh-performance MD-SC codes are robust against various channel impairments and\nnon-uniformity. \n\n"}
{"id": "1809.08383", "contents": "Title: Secure and Energy-Efficient Transmissions in Cache-Enabled Heterogeneous\n  Cellular Networks: Performance Analysis and Optimization Abstract: This paper studies physical-layer security for a cache-enabled heterogeneous\ncellular network comprised of a macro base station and multiple small base\nstations (SBSs). We investigate a joint design on caching placement and file\ndelivery for realizing secure and energy-efficient transmissions against\nrandomly distributed eavesdroppers. We propose a novel hybrid \"most popular\ncontent\" and \"largest content diversity\" caching placement policy to distribute\nfiles of different popularities. Depending on the availability and placement of\nthe requested file, we employ three cooperative transmission schemes, namely,\ndistributed beamforming, frequency-domain orthogonal transmission, and best SBS\nrelaying, respectively. We derive analytical expressions for the connection\noutage probability and secrecy outage probability for each transmission scheme.\nAfterwards, we design the optimal transmission rates and caching allocation\nsuccessively to achieve a maximal overall secrecy throughput and secrecy energy\nefficiency, respectively. Numerical results verify the theoretical analyses and\ndemonstrate the superiority of the proposed hybrid caching policy. \n\n"}
{"id": "1809.09336", "contents": "Title: A Model-Driven Deep Learning Network for MIMO Detection Abstract: In this paper, we propose a model-driven deep learning network for\nmultiple-input multiple-output (MIMO) detection. The structure of the network\nis specially designed by unfolding the iterative algorithm. Some trainable\nparameters are optimized through deep learning techniques to improve the\ndetection performance. Since the number of trainable variables of the network\nis equal to that of the layers, the network can be easily trained within a very\nshort time. Furthermore, the network can handle time-varying channel with only\na single training. Numerical results show that the proposed approach can\nimprove the performance of the iterative algorithm significantly under Rayleigh\nand correlated MIMO channels. \n\n"}
{"id": "1809.10372", "contents": "Title: Spanoids - an abstraction of spanning structures, and a barrier for LCCs Abstract: We introduce a simple logical inference structure we call a\n$\\textsf{spanoid}$ (generalizing the notion of a matroid), which captures\nwell-studied problems in several areas. These include combinatorial geometry,\nalgebra (arrangements of hypersurfaces and ideals), statistical physics\n(bootstrap percolation) and coding theory. We initiate a thorough investigation\nof spanoids, from computational and structural viewpoints, focusing on\nparameters relevant to the applications areas above and, in particular, to\nquestions regarding Locally Correctable Codes (LCCs).\n  One central parameter we study is the $\\textsf{rank}$ of a spanoid, extending\nthe rank of a matroid and related to the dimension of codes. This leads to one\nmain application of our work, establishing the first known barrier to improving\nthe nearly 20-year old bound of Katz-Trevisan (KT) on the dimension of LCCs. On\nthe one hand, we prove that the KT bound (and its more recent refinements)\nholds for the much more general setting of spanoid rank. On the other hand we\nshow that there exist (random) spanoids whose rank matches these bounds. Thus,\nto significantly improve the known bounds one must step out of the spanoid\nframework.\n  Another parameter we explore is the $\\textsf{functional rank}$ of a spanoid,\nwhich captures the possibility of turning a given spanoid into an actual code.\nThe question of the relationship between rank and functional rank is one of the\nmain questions we raise as it may reveal new avenues for constructing new LCCs\n(perhaps even matching the KT bound). As a first step, we develop an entropy\nrelaxation of functional rank to create a small constant gap and amplify it by\ntensoring to construct a spanoid whose functional rank is smaller than rank by\na polynomial factor. This is evidence that the entropy method we develop can\nprove polynomially better bounds than KT-type methods on the dimension of LCCs. \n\n"}
{"id": "1809.10921", "contents": "Title: Large deviations for conditional guesswork Abstract: The guesswork problem was originally studied by Massey to quantify the number\nof guesses needed to ascertain a discrete random variable. It has been shown\nthat for a large class of random processes the rescaled logarithm of the\nguesswork satisfies the large deviation principle and this has been extended to\nthe case where $k$ out $m$ sequences are guessed. The study of conditional\nguesswork, where guessing of a sequence is aided by the observation of another\none, was initiated by Ar{\\i}kan in his simple derivation of the upper bound of\nthe cutoff rate for sequential decoding. In this note, we extend these large\ndeviation results to the setting of conditional guesswork. \n\n"}
{"id": "1810.00356", "contents": "Title: DELMU: A Deep Learning Approach to Maximising the Utility of Virtualised\n  Millimetre-Wave Backhauls Abstract: Advances in network programmability enable operators to 'slice' the physical\ninfrastructure into independent logical networks. By this approach, each\nnetwork slice aims to accommodate the demands of increasingly diverse services.\nHowever, precise allocation of resources to slices across future 5G\nmillimetre-wave backhaul networks, to optimise the total network utility, is\nchallenging. This is because the performance of different services often\ndepends on conflicting requirements, including bandwidth, sensitivity to delay,\nor the monetary value of the traffic incurred. In this paper, we put forward a\ngeneral rate utility framework for slicing mm-wave backhaul links, encompassing\nall known types of service utilities, i.e. logarithmic, sigmoid, polynomial,\nand linear. We then introduce DELMU, a deep learning solution that tackles the\ncomplexity of optimising non-convex objective functions built upon arbitrary\ncombinations of such utilities. Specifically, by employing a stack of\nconvolutional blocks, DELMU can learn correlations between traffic demands and\nachievable optimal rate assignments. We further regulate the inferences made by\nthe neural network through a simple 'sanity check' routine, which guarantees\nboth flow rate admissibility within the network's capacity region and minimum\nservice levels. The proposed method can be trained within minutes, following\nwhich it computes rate allocations that match those obtained with\nstate-of-the-art global optimisation algorithms, yet orders of magnitude\nfaster. This confirms the applicability of DELMU to highly dynamic traffic\nregimes and we demonstrate up to 62% network utility gains over a baseline\ngreedy approach. \n\n"}
{"id": "1810.00827", "contents": "Title: Five Driving Forces of Multi-Access Edge Computing Abstract: The emergence of Multi-Access Edge Computing (MEC) technology aims at\nextending cloud computing capabilities to the edge of the wireless access\nnetworks. MEC provides real-time, high-bandwidth, low-latency access to radio\nnetwork resources, allowing operators to open their networks to a new ecosystem\nand value chain. Moreover, it will provide a new insight to the design of\nfuture 5th Generation (5G) wireless systems. This paper describes five key\ntechnologies, including Network Function Vitalization (NFV), Software Defined\nNetworking (SDN), Network Slicing, Information Centric Networking (ICN) and\nInternet of Things (IoT), that intensify the widespread of MEC and its\nadoption. Our goal is to provide the associativity between MEC and these five\ndriving technologies in 5G context while identifying the open challenges,\nfuture directions, and tangible integration paths. \n\n"}
{"id": "1810.02023", "contents": "Title: Detecting DGA domains with recurrent neural networks and side\n  information Abstract: Modern malware typically makes use of a domain generation algorithm (DGA) to\navoid command and control domains or IPs being seized or sinkholed. This means\nthat an infected system may attempt to access many domains in an attempt to\ncontact the command and control server. Therefore, the automatic detection of\nDGA domains is an important task, both for the sake of blocking malicious\ndomains and identifying compromised hosts. However, many DGAs use English\nwordlists to generate plausibly clean-looking domain names; this makes\nautomatic detection difficult. In this work, we devise a notion of difficulty\nfor DGA families called the smashword score; this measures how much a DGA\nfamily looks like English words. We find that this measure accurately reflects\nhow much a DGA family's domains look like they are made from natural English\nwords. We then describe our new modeling approach, which is a combination of a\nnovel recurrent neural network architecture with domain registration side\ninformation. Our experiments show the model is capable of effectively\nidentifying domains generated by difficult DGA families. Our experiments also\nshow that our model outperforms existing approaches, and is able to reliably\ndetect difficult DGA families such as matsnu, suppobox, rovnix, and others. The\nmodel's performance compared to the state of the art is best for DGA families\nthat resemble English words. We believe that this model could either be used in\na standalone DGA domain detector---such as an endpoint security\napplication---or alternately the model could be used as a part of a larger\nmalware detection system. \n\n"}
{"id": "1810.03116", "contents": "Title: Underwater Anchor-AUV Localization Geometries with an Isogradient Sound\n  Speed Profile: A CRLB-Based Optimality Analysis Abstract: Existing works have explored the anchor deployment for autonomous underwater\nvehicles (AUVs) localization under the assumption that the sound propagates\nstraightly underwater at a constant speed. Considering that the underwater\nacoustic waves propagate along bent curves at varying speeds in practice, it\nbecomes much more challenging to determine a proper anchor deployment\nconfiguration. In this paper, taking the practical variability of underwater\nsound speed into account, we investigate the anchor-AUV geometry problem in a\n3-D time-of-flight (ToF) based underwater scenario from the perspective of\nlocalization accuracy. To address this problem, we first rigorously derive the\nJacobian matrix of measurement errors to quantify the Cramer-Rao lower bound\n(CRLB) with a widely-adopted isogradient sound speed profile (SSP). We then\nformulate an optimization problem that minimizes the trace of the CRLB subject\nto the angle and range constraints to figure out the anchor-AUV geometry, which\nis multivariate and nonlinear and thus generally hard to handle. For\nmathematical tractability, by adopting tools from the estimation theory, we\ninterestingly find that this problem can be equivalently transformed into a\nmore explicit univariate optimization problem. By this, we obtain an\neasy-to-implement anchor-AUV geometry that yields satisfactory localization\nperformance, referred to as the uniform sea-surface circumference (USC)\ndeployment. Extensive simulation results validate our theoretical analysis and\nshow that our proposed USC scheme outperforms both the cube and the random\ndeployment schemes in terms of localization accuracy under the same parameter\nsettings. \n\n"}
{"id": "1810.03556", "contents": "Title: A quantum network stack and protocols for reliable entanglement-based\n  networks Abstract: We present a stack model for breaking down the complexity of\nentanglement-based quantum networks. More specifically, we focus on the\nstructures and architectures of quantum networks and not on concrete physical\nimplementations of network elements. We construct the quantum network stack in\na hierarchical manner comprising several layers, similar to the classical\nnetwork stack, and identify quantum networking devices operating on each of\nthese layers. The layers responsibilities range from establishing\npoint-to-point connectivity, over intra-network graph state generation, to\ninter-network routing of entanglement. In addition we propose several protocols\noperating on these layers. In particular, we extend the existing intra-network\nprotocols for generating arbitrary graph states to ensure reliability inside a\nquantum network, where here reliability refers to the capability to compensate\nfor devices failures. Furthermore, we propose a routing protocol for quantum\nrouters which enables to generate arbitrary graph states across network\nboundaries. This protocol, in correspondence with classical routing protocols,\ncan compensate dynamically for failures of routers, or even complete networks,\nby simply re-routing the given entanglement over alternative paths. We also\nconsider how to connect quantum routers in a hierarchical manner to reduce\ncomplexity, as well as reliability issues arising in connecting these quantum\nnetworking devices. \n\n"}
{"id": "1810.04105", "contents": "Title: Multibeam for Joint Communication and Sensing Using Steerable Analog\n  Antenna Arrays Abstract: Beamforming has great potential for joint communication and sensing (JCAS),\nwhich is becoming a demanding feature on many emerging platforms such as\nunmanned aerial vehicles and smart cars. Although beamforming has been\nextensively studied for communication and radar sensing respectively, its\napplication in the joint system is not straightforward due to different\nbeamforming requirements by communication and sensing. In this paper, we\npropose a novel multibeam framework using steerable analog antenna arrays,\nwhich allows seamless integration of communication and sensing. Different to\nconventional JCAS schemes that support JCAS using a single beam, our framework\nis based on the key innovation of multibeam technology: providing fixed subbeam\nfor communication and packet-varying scanning subbeam for sensing,\nsimultaneously from a single transmitting array. We provide a system\narchitecture and protocols for the proposed framework, complying well with\nmodern packet communication systems with multicarrier modulation. We also\npropose low-complexity and effective multibeam design and generation methods,\nwhich offer great flexibility in meeting different communication and sensing\nrequirements. We further develop sensing parameter estimation algorithms using\nconventional digital Fourier transform and 1D compressive sensing techniques,\nmatching well with the multibeam framework. Simulation results are provided and\nvalidate the effectiveness of our proposed framework, beamforming design\nmethods and the sensing algorithms. \n\n"}
{"id": "1810.04118", "contents": "Title: Semi-supervised Deep Reinforcement Learning in Support of IoT and Smart\n  City Services Abstract: Smart services are an important element of the smart cities and the Internet\nof Things (IoT) ecosystems where the intelligence behind the services is\nobtained and improved through the sensory data. Providing a large amount of\ntraining data is not always feasible; therefore, we need to consider\nalternative ways that incorporate unlabeled data as well. In recent years, Deep\nreinforcement learning (DRL) has gained great success in several application\ndomains. It is an applicable method for IoT and smart city scenarios where\nauto-generated data can be partially labeled by users' feedback for training\npurposes. In this paper, we propose a semi-supervised deep reinforcement\nlearning model that fits smart city applications as it consumes both labeled\nand unlabeled data to improve the performance and accuracy of the learning\nagent. The model utilizes Variational Autoencoders (VAE) as the inference\nengine for generalizing optimal policies. To the best of our knowledge, the\nproposed model is the first investigation that extends deep reinforcement\nlearning to the semi-supervised paradigm. As a case study of smart city\napplications, we focus on smart buildings and apply the proposed model to the\nproblem of indoor localization based on BLE signal strength. Indoor\nlocalization is the main component of smart city services since people spend\nsignificant time in indoor environments. Our model learns the best action\npolicies that lead to a close estimation of the target locations with an\nimprovement of 23% in terms of distance to the target and at least 67% more\nreceived rewards compared to the supervised DRL model. \n\n"}
{"id": "1810.05206", "contents": "Title: MeshAdv: Adversarial Meshes for Visual Recognition Abstract: Highly expressive models such as deep neural networks (DNNs) have been widely\napplied to various applications. However, recent studies show that DNNs are\nvulnerable to adversarial examples, which are carefully crafted inputs aiming\nto mislead the predictions. Currently, the majority of these studies have\nfocused on perturbation added to image pixels, while such manipulation is not\nphysically realistic. Some works have tried to overcome this limitation by\nattaching printable 2D patches or painting patterns onto surfaces, but can be\npotentially defended because 3D shape features are intact. In this paper, we\npropose meshAdv to generate \"adversarial 3D meshes\" from objects that have rich\nshape features but minimal textural variation. To manipulate the shape or\ntexture of the objects, we make use of a differentiable renderer to compute\naccurate shading on the shape and propagate the gradient. Extensive experiments\nshow that the generated 3D meshes are effective in attacking both classifiers\nand object detectors. We evaluate the attack under different viewpoints. In\naddition, we design a pipeline to perform black-box attack on a photorealistic\nrenderer with unknown rendering parameters. \n\n"}
{"id": "1810.07181", "contents": "Title: Deep-Waveform: A Learned OFDM Receiver Based on Deep Complex-valued\n  Convolutional Networks Abstract: The (inverse) discrete Fourier transform (DFT/IDFT) is often perceived as\nessential to orthogonal frequency-division multiplexing (OFDM) systems. In this\npaper, a deep complex-valued convolutional network (DCCN) is developed to\nrecover bits from time-domain OFDM signals without relying on any explicit\nDFT/IDFT. The DCCN can exploit the cyclic prefix (CP) of OFDM waveform for\nincreased SNR by replacing DFT with a learned linear transform, and has the\nadvantage of combining CP-exploitation, channel estimation, and intersymbol\ninterference (ISI) mitigation, with a complexity of $\\mathcal{O}(N^2)$.\nNumerical tests show that the DCCN receiver can outperform the legacy channel\nestimators based on ideal and approximate linear minimum mean square error\n(LMMSE) estimation and a conventional CP-enhanced technique in Rayleigh fading\nchannels with various delay spreads and mobility. The proposed approach\nbenefits from the expressive nature of complex-valued neural networks, which,\nhowever, currently lack support from popular deep learning platforms. In\nresponse, guidelines of exact and approximate implementations of a\ncomplex-valued convolutional layer are provided for the design and analysis of\nconvolutional networks for wireless PHY. Furthermore, a suite of novel training\ntechniques are developed to improve the convergence and generalizability of the\ntrained model in fading channels. This work demonstrates the capability of deep\nneural networks in processing OFDM waveforms and the results suggest that the\nFFT processor in OFDM receivers can be replaced by a hardware AI accelerator. \n\n"}
{"id": "1810.07339", "contents": "Title: Security Matters: A Survey on Adversarial Machine Learning Abstract: Adversarial machine learning is a fast growing research area, which considers\nthe scenarios when machine learning systems may face potential adversarial\nattackers, who intentionally synthesize input data to make a well-trained model\nto make mistake. It always involves a defending side, usually a classifier, and\nan attacking side that aims to cause incorrect output. The earliest studies on\nthe adversarial examples for machine learning algorithms start from the\ninformation security area, which considers a much wider varieties of attacking\nmethods. But recent research focus that popularized by the deep learning\ncommunity places strong emphasis on how the \"imperceivable\" perturbations on\nthe normal inputs may cause dramatic mistakes by the deep learning with\nsupposed super-human accuracy. This paper serves to give a comprehensive\nintroduction to a range of aspects of the adversarial deep learning topic,\nincluding its foundations, typical attacking and defending strategies, and some\nextended studies. \n\n"}
{"id": "1810.08510", "contents": "Title: Alphabet-Dependent Bounds for Linear Locally Repairable Codes Based on\n  Residual Codes Abstract: Locally repairable codes (LRCs) have gained significant interest for the\ndesign of large distributed storage systems as they allow a small number of\nerased nodes to be recovered by accessing only a few others. Several works have\nthus been carried out to understand the optimal rate-distance tradeoff, but\nonly recently the size of the alphabet has been taken into account. In this\npaper, a novel definition of locality is proposed to keep track of the precise\nnumber of nodes required for a local repair when the repair sets do not yield\nMDS codes. Then, a new alphabet-dependent bound is derived, which applies both\nto the new definition and the initial definition of locality. The new bound is\nbased on consecutive residual codes and intrinsically uses the Griesmer bound.\nA special case of the bound yields both the extension of the Cadambe-Mazumdar\nbound and the Singleton-type bound for codes with locality $(r, {\\delta})$,\nimplying that the new bound is at least as good as these bounds. Furthermore,\nan upper bound on the asymptotic rate-distance tradeoff of LRCs is derived, and\nyields the tightest known upper bound for large relative minimum distances.\nAchievability results are also provided by deriving the locality of the family\nof Simplex codes together with a few examples of optimal codes. \n\n"}
{"id": "1810.10123", "contents": "Title: Finding Safety in Numbers with Secure Allegation Escrows Abstract: For fear of retribution, the victim of a crime may be willing to report it\nonly if other victims of the same perpetrator also step forward. Common\nexamples include 1) identifying oneself as the victim of sexual harassment,\nespecially by a person in a position of authority or 2) accusing an influential\npolitician, an authoritarian government, or ones own employer of corruption. To\nhandle such situations, legal literature has proposed the concept of an\nallegation escrow: a neutral third-party that collects allegations anonymously,\nmatches them against each other, and de-anonymizes allegers only after\nde-anonymity thresholds (in terms of number of co-allegers), pre-specified by\nthe allegers, are reached.\n  An allegation escrow can be realized as a single trusted third party;\nhowever, this party must be trusted to keep the identity of the alleger and\ncontent of the allegation private. To address this problem, this paper\nintroduces Secure Allegation Escrows (SAE, pronounced \"say\"). A SAE is a group\nof parties with independent interests and motives, acting jointly as an escrow\nfor collecting allegations from individuals, matching the allegations, and\nde-anonymizing the allegations when designated thresholds are reached. By\ndesign, SAEs provide a very strong property: No less than a majority of parties\nconstituting a SAE can de-anonymize or disclose the content of an allegation\nwithout a sufficient number of matching allegations (even in collusion with any\nnumber of other allegers). Once a sufficient number of matching allegations\nexist, the join escrow discloses the allegation with the allegers' identities.\nWe describe how SAEs can be constructed using a novel authentication protocol\nand a novel allegation matching and bucketing algorithm, provide formal proofs\nof the security of our constructions, and evaluate a prototype implementation,\ndemonstrating feasibility in practice. \n\n"}
{"id": "1810.10718", "contents": "Title: Beamforming Optimization for Intelligent Reflecting Surface with\n  Discrete Phase Shifts Abstract: Intelligent reflecting surface (IRS) is a promising technology for achieving\nhigh spectrum efficiency in future wireless networks by leveraging massive\nlow-cost reflecting elements with each reflecting the incident signal with a\nproper phase shift. However, prior works on IRS are mainly based on the\noptimization of infinite-resolution phase shifters which are practically\ninfeasible due to hardware imperfections. In contrast, we study in this paper\nan IRS-aided wireless network, where an IRS with only finite-resolution phase\nshifter available at each element is deployed to assist in the communication\nfrom a multi-antenna access point (AP) to a single-antenna user. We aim to\nminimize the transmit power at the AP by jointly optimizing the transmit\nbeamforming at the AP and reflect beamforming at the IRS, subject to the\nsignal-to-noise ratio (SNR) constraint and practical discrete phase shift\nconstraints. We first propose a suboptimal but low-complexity algorithm by\nexploiting the alternating optimization technique. Then, we reveal that as in\nthe case with continuous phase shifts, the IRS with discrete phase shifts also\nachieves the squared power gain for asymptotically large number of reflecting\nelements, despite suffering a performance loss that depends only on the\nresolution of phase shifters. \n\n"}
{"id": "1810.10983", "contents": "Title: Stochastic Control with Stale Information--Part I: Fully Observable\n  Systems Abstract: In this study, we adopt age of information as a measure of the staleness of\ninformation, and take initial steps towards analyzing the control performance\nof stochastic systems with stale information. Our goals are to cast light on a\nfundamental limit on the information staleness that is required for a certain\nlevel of the control performance and to specify the corresponding stalest\ninformation pattern. In the asymptotic regime, such a limit asserts a critical\ninformation staleness that is required for stabilization. We achieve these\ngoals by formulating the problem as a stochastic optimization problem and\ncharacterizing the associated optimal solutions. These solutions are in fact a\ncontrol policy, which specifies the control inputs of the plant, and a queuing\npolicy, which specifies the staleness of information at the controller. \n\n"}
{"id": "1810.12983", "contents": "Title: Sleeping Multi-Armed Bandit Learning for Fast Uplink Grant Allocation in\n  Machine Type Communications Abstract: Scheduling fast uplink grant transmissions for machine type communications\n(MTCs) is one of the main challenges of future wireless systems. In this paper,\na novel fast uplink grant scheduling method based on the theory of multi-armed\nbandits (MABs) is proposed. First, a single quality-of-service metric is\ndefined as a combination of the value of data packets, maximum tolerable access\ndelay, and data rate. Since full knowledge of these metrics for all machine\ntype devices (MTDs) cannot be known in advance at the base station (BS) and the\nset of active MTDs changes over time, the problem is modeled as a sleeping MAB\nwith stochastic availability and a stochastic reward function. In particular,\ngiven that, at each time step, the knowledge on the set of active MTDs is\nprobabilistic, a novel probabilistic sleeping MAB algorithm is proposed to\nmaximize the defined metric. Analysis of the regret is presented and the effect\nof the prediction error of the source traffic prediction algorithm on the\nperformance of the proposed sleeping MAB algorithm is investigated. Moreover,\nto enable fast uplink allocation for multiple MTDs at each time, a novel method\nis proposed based on the concept of best arms ordering in the MAB setting.\nSimulation results show that the proposed framework yields a three-fold\nreduction in latency compared to a random scheduling policy since it\nprioritises the scheduling of MTDs that have stricter latency requirements.\nMoreover, by properly balancing the exploration versus exploitation tradeoff,\nthe proposed algorithm can provide system fairness by allowing the most\nimportant MTDs to be scheduled more often while also allowing the less\nimportant MTDs to be selected enough times to ensure the accuracy of estimation\nof their importance. \n\n"}
{"id": "1811.00591", "contents": "Title: Defining a Metric Space of Host Logs and Operational Use Cases Abstract: Host logs, in particular, Windows Event Logs, are a valuable source of\ninformation often collected by security operation centers (SOCs). The\nsemi-structured nature of host logs inhibits automated analytics, and while\nmanual analysis is common, the sheer volume makes manual inspection of all logs\nimpossible. Although many powerful algorithms for analyzing time-series and\nsequential data exist, utilization of such algorithms for most cyber security\napplications is either infeasible or requires tailored, research-intensive\npreparations. In particular, basic mathematic and algorithmic developments for\nproviding a generalized, meaningful similarity metric on system logs is needed\nto bridge the gap between many existing sequential data mining methods and this\ncurrently available but under-utilized data source. In this paper, we provide a\nrigorous definition of a metric product space on Windows Event Logs, providing\nan embedding that allows for the application of established machine learning\nand time-series analysis methods. We then demonstrate the utility and\nflexibility of this embedding with multiple use-cases on real data: (1)\ncomparing known infected to new host log streams for attack detection and\nforensics, (2) collapsing similar streams of logs into semantically-meaningful\ngroups (by user, by role), thereby reducing the quantity of data but not the\ncontent, (3) clustering logs as well as short sequences of logs to identify and\nvisualize user behaviors and background processes over time. Overall, we\nprovide a metric space framework for general host logs and log sequences that\nrespects semantic similarity and facilitates a wide variety of data science\nanalytics to these logs without data-specific preparations for each. \n\n"}
{"id": "1811.00866", "contents": "Title: Efficient Neural Network Robustness Certification with General\n  Activation Functions Abstract: Finding minimum distortion of adversarial examples and thus certifying\nrobustness in neural network classifiers for given data points is known to be a\nchallenging problem. Nevertheless, recently it has been shown to be possible to\ngive a non-trivial certified lower bound of minimum adversarial distortion, and\nsome recent progress has been made towards this direction by exploiting the\npiece-wise linear nature of ReLU activations. However, a generic robustness\ncertification for general activation functions still remains largely\nunexplored. To address this issue, in this paper we introduce CROWN, a general\nframework to certify robustness of neural networks with general activation\nfunctions for given input data points. The novelty in our algorithm consists of\nbounding a given activation function with linear and quadratic functions, hence\nallowing it to tackle general activation functions including but not limited to\nfour popular choices: ReLU, tanh, sigmoid and arctan. In addition, we\nfacilitate the search for a tighter certified lower bound by adaptively\nselecting appropriate surrogates for each neuron activation. Experimental\nresults show that CROWN on ReLU networks can notably improve the certified\nlower bounds compared to the current state-of-the-art algorithm Fast-Lin, while\nhaving comparable computational efficiency. Furthermore, CROWN also\ndemonstrates its effectiveness and flexibility on networks with general\nactivation functions, including tanh, sigmoid and arctan. \n\n"}
{"id": "1811.01272", "contents": "Title: Anomaly Detection in Paleoclimate Records using Permutation Entropy Abstract: Permutation entropy techniques can be useful in identifying anomalies in\npaleoclimate data records, including noise, outliers, and post-processing\nissues. We demonstrate this using weighted and unweighted permutation entropy\nof water-isotope records in a deep polar ice core. In one region of these\nisotope records, our previous calculations revealed an abrupt change in the\ncomplexity of the traces: specifically, in the amount of new information that\nappeared at every time step. We conjectured that this effect was due to noise\nintroduced by an older laboratory instrument. In this paper, we validate that\nconjecture by re-analyzing a section of the ice core using a more-advanced\nversion of the laboratory instrument. The anomalous noise levels are absent\nfrom the permutation entropy traces of the new data. In other sections of the\ncore, we show that permutation entropy techniques can be used to identify\nanomalies in the raw data that are not associated with climatic or\nglaciological processes, but rather effects occurring during field work,\nlaboratory analysis, or data post-processing. These examples make it clear that\npermutation entropy is a useful forensic tool for identifying sections of data\nthat require targeted re-analysis---and can even be useful in guiding that\nanalysis. \n\n"}
{"id": "1811.01282", "contents": "Title: Partitions of Matrix Spaces With an Application to $q$-Rook Polynomials Abstract: We study the row-space partition and the pivot partition on the matrix space\n$\\mathbb{F}_q^{n \\times m}$. We show that both these partitions are reflexive\nand that the row-space partition is self-dual. Moreover, using various\ncombinatorial methods, we explicitly compute the Krawtchouk coefficients\nassociated with these partitions. This establishes MacWilliams-type identities\nfor the row-space and pivot enumerators of linear rank-metric codes. We then\ngeneralize the Singleton-like bound for rank-metric codes, and introduce two\nnew concepts of code extremality. Both of them generalize the notion of MRD\ncodes and are preserved by trace-duality. Moreover, codes that are extremal\naccording to either notion satisfy strong rigidity properties analogous to\nthose of MRD codes. As an application of our results to combinatorics, we give\nclosed formulas for the $q$-rook polynomials associated with Ferrers diagram\nboards. Moreover, we exploit connections between matrices over finite fields\nand rook placements to prove that the number of matrices of rank $r$ over\n$\\mathbb{F}_q$ supported on a Ferrers diagram is a polynomial in $q$, whose\ndegree is strictly increasing in $r$. Finally, we investigate the natural\nanalogues of the MacWilliams Extension Theorem for the rank, the row-space, and\nthe pivot partitions. \n\n"}
{"id": "1811.02203", "contents": "Title: On-the-fly Uplink Training and Pilot Code Sequence Design for Cellular\n  Networks Abstract: Cellular networks of massive MIMO base-stations employing TDD/OFDM and\nrelying on uplink training for both downlink and uplink transmission are viewed\nas an attractive candidate for 5G deployments, as they promise high area\nspectral and energy efficiencies with relatively simple low-latency operation.\nWe investigate the use of non-orthogonal uplink pilot designs as a means for\nimproving the area spectral efficiency in the downlink of such massive MIMO\ncellular networks. We develop a class of pilot designs that are locally\northogonal within each cell, while maintaining low inner-product properties\nbetween codes in different cells. Using channel estimates provided by\nobservations on these codes, each cell independently serves its locally active\nusers with MU-MIMO transmission that is also designed to mitigate interference\nto a subset of `strongly interfered' out-of-cell users. As our simulation-based\nanalysis shows, such cellular operation based on the proposed codes yields\nuser-rate CDF improvement with respect to conventional operation, which can be\nexploited to improve cell and/or cell-throughput performance. \n\n"}
{"id": "1811.06261", "contents": "Title: Efficient Edge Rewiring Strategies for Enhancement in Network Capacity Abstract: The structure of the network has great impact on its traffic dynamics. Most\nof the real world networks follow the heterogeneous structure and exhibit\nscale-free feature. In scale-free network, a new node prefers to connect with\nhub nodes and the network capacity is curtailed by smaller degree nodes.\nTherefore, we propose rewiring a fraction of links in the network, to improve\nthe network transport efficiency. In this paper, we discuss some efficient link\nrewiring strategies and perform simulations on scale-free networks, confirming\nthe effectiveness of these strategies. The rewiring strategies actually reduce\nthe centrality of the nodes having higher betweenness centrality. After the\nlink rewiring process, the degree distribution of the network remains the same.\nThis work will be beneficial for the enhancement of network performance. \n\n"}
{"id": "1811.07975", "contents": "Title: On polycyclic codes over a finite chain ring Abstract: Galois images of polycyclic codes over a finite chain ring $S$ and their\nannihilator dual are investigated. The case when a polycyclic codes is\nGalois-disjoint over the ring $S,$ is characterized and, the trace codes and\nrestrictions of free polycyclic codes over $S$ are also determined givind an\nanalogue of Delsarte theorem among trace map, any S -linear code and its\nannihilator dual. \n\n"}
{"id": "1811.08528", "contents": "Title: Minimum Guesswork with an Unreliable Oracle Abstract: We study a guessing game where Alice holds a discrete random variable $X$,\nand Bob tries to sequentially guess its value. Before the game begins, Bob can\nobtain side-information about $X$ by asking an oracle, Carole, any binary\nquestion of his choosing. Carole's answer is however unreliable, and is\nincorrect with probability $\\epsilon$. We show that Bob should always ask\nCarole whether the index of $X$ is odd or even with respect to a descending\norder of probabilities -- this question simultaneously minimizes all the\nguessing moments for any value of $\\epsilon$. In particular, this result\nsettles a conjecture of Burin and Shayevitz. We further consider a more general\nsetup where Bob can ask a multiple-choice $M$-ary question, and then observe\nCarole's answer through a noisy channel. When the channel is completely\nsymmetric, i.e., when Carole decides whether to lie regardless of Bob's\nquestion and has no preference when she lies, a similar question about the\nordered index of $X$ (modulo $M$) is optimal. Interestingly however, the\nproblem of testing whether a given question is optimal appears to be generally\ndifficult in other symmetric channels. We provide supporting evidence for this\ndifficulty, by showing that a core property required in our proofs becomes\nNP-hard to test in the general $M$-ary case. We establish this hardness result\nvia a reduction from the problem of testing whether a system of modular\ndifference disequations has a solution, which we prove to be NP-hard for $M\\geq\n3$. \n\n"}
{"id": "1811.08602", "contents": "Title: On-off Switched Interference Alignment for Diversity Multiplexing\n  Tradeoff Improvement in the 2-User X-Network with Two Antennas Abstract: To improve diversity gain in an interference channel and hence to maximize\ndiversity multiplexing tradeoff (DMT), we propose on-off switched interference\nalignment (IA) where IA is intermittently utilized by switching IA on/off. For\non-off switching, either IA with symbol extension or IA with Alamouti coding is\nadopted in this paper. Deriving and analyzing DMT of the proposed schemes, we\nreveal that the intermittent utilization of IA with simultaneous non-unique\ndecoding can improve DMT in the 2-user X-channel with two antennas. Both the\nproposed schemes are shown to achieve diversity gain of 4 and DoF per user of\n$\\frac{4}{3}$. In particular, the on-off switched IA with Alamouti coding, to\nthe best of our knowledge, surpasses any other existing schemes for the 2-user\nX-channel with two antennas and nearly approaches the ideal DMT. \n\n"}
{"id": "1811.08730", "contents": "Title: Media-Based Modulation for Future Wireless Systems: A Tutorial Abstract: The wireless revolution has already started with the specified vision,\noverall objectives, and the first official 3GPP release of 5th generation (5G)\nwireless networks. Despite the development of several modern communication\ntechnologies, since the beginning of the modern era of digital communications,\nwe have been mostly conveying information by altering the amplitude, the phase,\nor the frequency of sinusoidal carrier signals, which has inherent drawbacks.\nOn the other hand, index modulation (IM) provides an alternative dimension to\ntransmit digital information: the indices of the corresponding communication\nsystems' building blocks. Media-based modulation (MBM), which is one of the\nnewest and the most prominent members of the IM family, performs the\ntransmission of information by altering the far-field radiation pattern of\nreconfigurable antennas (RAs) and provides a completely new dimension to convey\ninformation: wireless channel fade realizations themselves through the unique\nsignature of received signals. The aim of this article is to shed light on this\npromising frontier from a broad communication engineering perspective by\ndiscussing the most recent advances as well as possible interesting research\ndirections in MBM technologies. \n\n"}
{"id": "1811.09695", "contents": "Title: Multilevel-Coded Pulse-Position Modulation for Covert Communications\n  over Binary-Input Discrete Memoryless Channels Abstract: We develop a low-complexity coding scheme to achieve covert communications\nover binary-input discrete memoryless channels (BI-DMCs). We circumvent the\nimpossibility of covert communication with linear codes by introducing\nnon-linearity through the use of pulse position modulation (PPM) and multilevel\ncoding (MLC). We show that the MLC-PPM scheme exhibits many appealing\nproperties; in particular, the channel at a given index level remains\nstationary as the number of level increases, which allows one to use families\nof channel capacity- and channel resolvability-achieving codes to concretely\ninstantiate the covert communication scheme. \n\n"}
{"id": "1811.09731", "contents": "Title: In-network Congestion-aware Load Balancing at Transport Layer Abstract: Load balancing at transport layer is an important function in data centers,\ncontent delivery networks, and mobile networks, where per-connection\nconsistency (PCC) has to be met for optimal performance. Cloud-native L4 load\nbalancers are commonly deployed as virtual network functions (VNFs) and are a\ncritical forwarding element in modern cloud infrastructure. We identify load\nimbalance among service instances as the main cause of additional processing\ndelay caused by transport-layer load balancers. Existing transport-layer load\nbalancers rely on one of two methods: host-level traffic redirection, which may\nadd as much as 12.48% additional traffic to underlying networks, or connection\ntracking, which consumes a considerable amount of memory in load balancers.\nBoth of these methods result in inefficient usage of network resources. We\npropose the in-network congestion-aware load Balancer (INCAB) to achieve even\nload distribution among service instances and optimal network resources usage\nin addition to meeting the PCC requirement. We show that INCAB is capable of\nidentifying and monitoring each instance's most-utilized resource and can\nimprove the load distribution among all service instances. INCAB utilizes a\nBloom filter and an ultra-compact connection table for in-network flow\ndistribution. Furthermore, it does not rely on end hosts for traffic\nredirection. Our flow level simulations show that INCAB improves flows' average\ncompletion time by 31.97% compared to stateless solutions. \n\n"}
{"id": "1811.11099", "contents": "Title: Cooperative Transmission and Probabilistic Caching for Clustered D2D\n  Networks Abstract: In this paper, we aim at maximizing the cache offloading gain for a clustered\n\\ac{D2D} caching network by exploiting probabilistic caching and cooperative\ntransmission among the cluster devices. Devices with surplus memory\nprobabilistically cache a content from a known library. A requested content is\neither brought from the device's local cache, cooperatively transmitted from\ncatering devices, or downloaded from the macro base station as a last resort.\nUsing stochastic geometry, we derive a closed-form expression for the\noffloading gain and formulate the offloading maximization problem. In order to\nsimplify the objective function and obtain analytically tractable expressions,\nwe derive a lower bound on the offloading gain, for which a suboptimal solution\nis obtained when considering a special case. Results reveal that the obtained\nsuboptimal solution can achieve up to 12% increase in the offloading gain\ncompared to the Zipf's caching technique. Besides, we show that the spatial\nscaling parameters of the network, e.g., the density of clusters and distance\nbetween devices in the same cluster, play a crucial role in identifying the\ntradeoff between the content diversity gain and the cooperative transmission\ngain. \n\n"}
{"id": "1811.11402", "contents": "Title: Adversarial Machine Learning And Speech Emotion Recognition: Utilizing\n  Generative Adversarial Networks For Robustness Abstract: Deep learning has undoubtedly offered tremendous improvements in the\nperformance of state-of-the-art speech emotion recognition (SER) systems.\nHowever, recent research on adversarial examples poses enormous challenges on\nthe robustness of SER systems by showing the susceptibility of deep neural\nnetworks to adversarial examples as they rely only on small and imperceptible\nperturbations. In this study, we evaluate how adversarial examples can be used\nto attack SER systems and propose the first black-box adversarial attack on SER\nsystems. We also explore potential defenses including adversarial training and\ngenerative adversarial network (GAN) to enhance robustness. Experimental\nevaluations suggest various interesting aspects of the effective utilization of\nadversarial examples useful for achieving robustness for SER systems opening up\nopportunities for researchers to further innovate in this space. \n\n"}
{"id": "1811.11948", "contents": "Title: Low-Complexity Adaptive Beam and Channel Tracking for Mobile mmWave\n  Communications Abstract: In this paper, we study low-complexity algorithms for beam and channel\ntracking for millimeter-wave (mmWave) communications. In particular, the least\nmean squares (LMS) and bidirectional LMS (BiLMS) algorithms are derived for a\nmobile mmWave transmission scenario, where channel measurement is a nonlinear\nfunction of the unknown angle-of-arrival (AoA) and angle-of-departure (AoD).\nNumerical results confirm that LMS is superior to widely used Extended Kalman\nFilter (EKF) algorithm in tracking the mmWave beam, when the initialization of\nAoA/AoD and channel gains is imperfect (i.e., performed using noisy channel\nestimates). Moreover, BiLMS exhibits a very good mean square error (MSE)\nperformance as compared to both LMS and EKF, which makes it a promising channel\ntracking algorithm for a mobile mmWave transmission scenario. We also show that\nLMS and BiLMS algorithms are more robust against the impairments due to the\nnon-optimal antenna array size as compared to EKF, and show relatively faster\nconvergence characteristic along with increasing signal-to-noise ratio (SNR). \n\n"}
{"id": "1811.12082", "contents": "Title: Joint Service Pricing and Cooperative Relay Communication for Federated\n  Learning Abstract: For the sake of protecting data privacy and due to the rapid development of\nmobile devices, e.g., powerful central processing unit (CPU) and nascent neural\nprocessing unit (NPU), collaborative machine learning on mobile devices, e.g.,\nfederated learning, has been envisioned as a new AI approach with broad\napplication prospects. However, the learning process of the existing federated\nlearning platforms rely on the direct communication between the model owner,\ne.g., central cloud or edge server, and the mobile devices for transferring the\nmodel update. Such a direct communication may be energy inefficient or even\nunavailable in mobile environments. In this paper, we consider adopting the\nrelay network to construct a cooperative communication platform for supporting\nmodel update transfer and trading. In the system, the mobile devices generate\nmodel updates based on their training data. The model updates are then\nforwarded to the model owner through the cooperative relay network. The model\nowner enjoys the learning service provided by the mobile devices. In return,\nthe mobile devices charge the model owner certain prices. Due to the coupled\ninterference of wireless transmission among the mobile devices that use the\nsame relay node, the rational mobile devices have to choose their relay nodes\nas well as deciding on their transmission powers. Thus, we formulate a\nStackelberg game model to investigate the interaction among the mobile devices\nand that between the mobile devices and the model owner. The Stackelberg\nequilibrium is investigated by capitalizing on the exterior point method.\nMoreover, we provide a series of insightful analytical and numerical results on\nthe equilibrium of the Stackelberg game. \n\n"}
{"id": "1811.12257", "contents": "Title: Locally Differentially-Private Randomized Response for Discrete\n  Distribution Learning Abstract: We consider a setup in which confidential i.i.d. samples $X_1,\\dotsc,X_n$\nfrom an unknown finite-support distribution $\\boldsymbol{p}$ are passed through\n$n$ copies of a discrete privatization channel (a.k.a. mechanism) producing\noutputs $Y_1,\\dotsc,Y_n$. The channel law guarantees a local differential\nprivacy of $\\epsilon$. Subject to a prescribed privacy level $\\epsilon$, the\noptimal channel should be designed such that an estimate of the source\ndistribution based on the channel outputs $Y_1,\\dotsc,Y_n$ converges as fast as\npossible to the exact value $\\boldsymbol{p}$. For this purpose we study the\nconvergence to zero of three distribution distance metrics: $f$-divergence,\nmean-squared error and total variation. We derive the respective normalized\nfirst-order terms of convergence (as $n\\to\\infty$), which for a given target\nprivacy $\\epsilon$ represent a rule-of-thumb factor by which the sample size\nmust be augmented so as to achieve the same estimation accuracy as that of a\nnon-randomizing channel. We formulate the privacy-fidelity trade-off problem as\nbeing that of minimizing said first-order term under a privacy constraint\n$\\epsilon$. We further identify a scalar quantity that captures the essence of\nthis trade-off, and prove bounds and data-processing inequalities on this\nquantity. For some specific instances of the privacy-fidelity trade-off\nproblem, we derive inner and outer bounds on the optimal trade-off curve. \n\n"}
{"id": "1811.12924", "contents": "Title: Joint Information Freshness and Completion Time Optimization for\n  Vehicular Networks Abstract: The demand for real-time cloud applications has seen an unprecedented growth\nover the past decade. These applications require rapidly data transfer and fast\ncomputations. This paper considers a scenario where multiple IoT devices update\ninformation on the cloud, and request a computation from the cloud at certain\ntimes. The time required to complete the request for computation includes the\ntime to wait for computation to start on busy virtual machines, performing the\ncomputation, waiting and service in the networking stage for delivering the\noutput to the end user. In this context, the freshness of the information is an\nimportant concern and is different from the completion time. This paper\nproposes novel scheduling strategies for both computation and networking\nstages. Based on these strategies, the age-of-information (AoI) metric and the\ncompletion time are characterized. A convex combination of the two metrics is\noptimized over the scheduling parameters. The problem is shown to be convex and\nthus can be solved optimally. Moreover, based on the offline policy, an online\nalgorithm for job scheduling is developed. Numerical results demonstrate\nsignificant improvement as compared to the considered baselines. \n\n"}
{"id": "1812.00802", "contents": "Title: A Hybrid Beamforming Receiver with Two-Stage Analog Combining and\n  Low-Resolution ADCs Abstract: In this paper, we propose a two-stage analog combining architecture for\nmillimeter wave (mmWave) communications with hybrid analog/digital beamforming\nand low-resolution analog-to-digital converters (ADCs). We first derive a\ntwo-stage combining solution by solving a mutual information (MI) maximization\nproblem without a constant modulus constraint on analog combiners. With the\nderived solution, the proposed receiver architecture splits the analog\ncombining into a channel gain aggregation stage followed by a spreading stage\nto maximize the MI by effectively managing quantization error. We show that the\nderived two-stage combiner achieves the optimal scaling law with respect to the\nnumber of radio frequency (RF) chains and maximizes the MI for homogeneous\nsingular values of a MIMO channel. Then, we develop a two-stage analog\ncombining algorithm to implement the derived solution under a constant modulus\nconstraint for mmWave channels. Simulation results validate the algorithm\nperformance in terms of MI. \n\n"}
{"id": "1812.02969", "contents": "Title: Polar-Coded Pulse Position Modulation for the Poisson Channel Abstract: A polar-coded modulation scheme for deep-space optical communication is\nproposed. The photon counting Poisson channel with pulse position modulation\n(PPM) is considered. We use the fact that PPM is particularly well suited to be\nused with multilevel codes to design a polar-coded modulation scheme for the\nsystem in consideration. The construction of polar codes for the Poisson\nchannel based on Gaussian approximation is demonstrated to be accurate. The\nproposed scheme uses a cyclic redundancy check outer code and a successive\ncancellation decoder with list decoding and it is shown that it outperforms the\ncompeting schemes. \n\n"}
{"id": "1812.03286", "contents": "Title: Cryptanalysis of a One-Time Code-Based Digital Signature Scheme Abstract: We consider a one-time digital signature scheme recently proposed by\nPersichetti and show that a successful key recovery attack can be mounted with\nlimited complexity. The attack we propose exploits a single signature\nintercepted by the attacker, and relies on a statistical analysis performed\nover such a signature, followed by information set decoding. We assess the\nattack complexity and show that a full recovery of the secret key can be\nperformed with a work factor that is far below the claimed security level. The\nefficiency of the attack is motivated by the sparsity of the signature, which\nleads to a significant information leakage about the secret key. \n\n"}
{"id": "1812.03556", "contents": "Title: How to Increase the Achievable Information Rate by Per-Channel\n  Dispersion Compensation Abstract: Deploying periodic inline chromatic dispersion compensation enables reducing\nthe complexity of the digital back propagation (DBP) algorithm. However,\ncompared with nondispersion-managed (NDM) links, dispersion-managed (DM) ones\nsuffer a stronger cross-phase modulation (XPM). Utilizing per-channel\ndispersion-managed (CDM) links (e.g., using fiber Bragg grating) allows for a\ncomplexity reduction of DBP, while abating XPM compared to DM links. In this\npaper, we show for the first time that CDM links enable also a more effective\nXPM compensation compared to NDM ones, allowing a higher achievable information\nrate (AIR). This is explained by resorting to the frequency-resolved\nlogarithmic perturbation model and showing that per-channel dispersion\ncompensation increases the frequency correlation of the distortions induced by\nXPM over the channel bandwidth, making them more similar to a conventional\nphase noise. We compare the performance (in terms of the AIR) of a DM, an NDM,\nand a CDM link, considering two types of mismatched receivers: one neglects the\nXPM phase distortion and the other compensates for it. With the former, the CDM\nlink is inferior to the NDM one due to an increased in-band signal--noise\ninteraction. However, with the latter, a higher AIR is obtained with the CDM\nlink than with the NDM one owing to a higher XPM frequency correlation. The DM\nlink has the lowest AIR for both receivers because of a stronger XPM. \n\n"}
{"id": "1812.03705", "contents": "Title: Defending Against Universal Perturbations With Shared Adversarial\n  Training Abstract: Classifiers such as deep neural networks have been shown to be vulnerable\nagainst adversarial perturbations on problems with high-dimensional input\nspace. While adversarial training improves the robustness of image classifiers\nagainst such adversarial perturbations, it leaves them sensitive to\nperturbations on a non-negligible fraction of the inputs. In this work, we show\nthat adversarial training is more effective in preventing universal\nperturbations, where the same perturbation needs to fool a classifier on many\ninputs. Moreover, we investigate the trade-off between robustness against\nuniversal perturbations and performance on unperturbed data and propose an\nextension of adversarial training that handles this trade-off more gracefully.\nWe present results for image classification and semantic segmentation to\nshowcase that universal perturbations that fool a model hardened with\nadversarial training become clearly perceptible and show patterns of the target\nscene. \n\n"}
{"id": "1812.05670", "contents": "Title: When to Preempt? Age of Information Minimization under Link Capacity\n  Constraint Abstract: In this paper, we consider a scenario where a source continuously monitors an\nobject and sends time-stamped status updates to a destination through a\nrate-limited link. We assume updates arrive randomly at the source according to\na Bernoulli process. Due to the link capacity constraint, it takes multiple\ntime slots for the source to complete the transmission of an update. Therefore,\nwhen a new update arrives at the source during the transmission of another\nupdate, the source needs to decide whether to skip the new arrival or to switch\nto it, in order to minimize the expected average age of information (AoI) at\nthe destination. We start with the setting where all updates are of the same\nsize, and prove that within a broadly defined class of online policies, the\noptimal policy should be a renewal policy, and has a sequential switching\nproperty. We then show that the optimal decision of the source in any time slot\nhas threshold structures, and only depends on the age of the update being\ntransmitted and the AoI at the destination. We then consider the setting where\nupdates are of different sizes, and show that the optimal Markovian policy also\nhas a multiple-threshold structure. For each of the settings, we explicitly\nidentify the thresholds by formulating the problem as a Markov Decision Process\n(MDP), and solve it through value iteration. Special structural properties of\nthe corresponding optimal policy are utilized to reduce the computational\ncomplexity of the value iteration algorithm. \n\n"}
{"id": "1812.07236", "contents": "Title: Sparse mmWave OFDM Channel Estimation Using Compressed Sensing in OFDM\n  Systems Abstract: This paper proposes and analyzes a mmWave sparse channel estimation technique\nfor OFDM systems that uses the Orthogonal Matching Pursuit (OMP) algorithm.\nThis greedy algorithm retrieves one additional multipath component (MPC) per\niteration until a stop condition is met. We obtain an analytical approximation\nfor the OMP estimation error variance that grows with the number of retrieved\nMPCs (iterations). The OMP channel estimator error variance outperforms a\nclassic maximum-likelihood (ML) non-sparse channel estimator by a factor of\napproximately $2\\hat{L}/M$ where $\\hat{L}$ is the number of retrieved MPCs\n(iterations) and $M$ the number of taps of the Discrete Equivalent Channel.\nWhen the MPC amplitude distribution is heavy-tailed, the channel power is\nconcentrated in a subset of dominant MPCs. In this case OMP performs fewer\niterations as it retrieves only these dominant large MPCs. Hence for this MPC\namplitude distribution the estimation error advantage of OMP over ML is\nimproved. In particular, for channels with MPCs that have\nlognormally-distributed amplitudes, the OMP estimator recovers approximately\n5-15 dominant MPCs in typical mmWave channels, with 15-45 weak MPCs that remain\nundetected. \n\n"}
{"id": "1812.07966", "contents": "Title: Determinantal conditions for homomorphic sensing Abstract: With $k$ an infinite field and $\\tau_1,\\tau_2$ endomorphisms of $k^m$, we\nprovide a dimension bound on an open locus of a determinantal scheme, under\nwhich, for a general subspace $V \\subseteq k^m$ of dimension $n \\le m/2$, for\n$v_1,v_2 \\in V$ we have $\\tau_1(v_1)=\\tau_2(v_2)$ only if $v_1=v_2$.\nSpecializing to permutations composed by coordinate projections, we obtain an\nabstract proof of the unlabeled sensing theorem. \n\n"}
{"id": "1812.08130", "contents": "Title: Derandomizing compressed sensing with combinatorial design Abstract: Compressed sensing is the art of reconstructing structured $n$-dimensional\nvectors from substantially fewer measurements than naively anticipated. A\nplethora of analytic reconstruction guarantees support this credo. The\nstrongest among them are based on deep results from large-dimensional\nprobability theory that require a considerable amount of randomness in the\nmeasurement design. Here, we demonstrate that derandomization techniques allow\nfor considerably reducing the amount of randomness that is required for such\nproof strategies. More, precisely we establish uniform s-sparse reconstruction\nguarantees for $C s \\log (n)$ measurements that are chosen independently from\nstrength-four orthogonal arrays and maximal sets of mutually unbiased bases,\nrespectively. These are highly structured families of $\\tilde{C} n^2$ vectors\nthat imitate signed Bernoulli and standard Gaussian vectors in a (partially)\nderandomized fashion. \n\n"}
{"id": "1812.08562", "contents": "Title: Efficient Error-Correcting Codes in the Short Blocklength Regime Abstract: The design of block codes for short information blocks (e.g., a thousand or\nless information bits) is an open research problem that is gaining relevance\nthanks to emerging applications in wireless communication networks. In this\npaper, we review some of the most promising code constructions targeting the\nshort block regime, and we compare them with both finite-length performance\nbounds and classical error-correction coding schemes. The work addresses the\nuse of both binary and high-order modulations over the additive white Gaussian\nnoise channel. We will illustrate how to effectively approach the theoretical\nbounds with various performance versus decoding complexity tradeoffs. \n\n"}
{"id": "1812.09147", "contents": "Title: Reed-Solomon-Gabidulin Codes Abstract: We introduce Reed-Solomon-Gabidulin codes which is, at the same time, an\nextension to Reed-Solomon codes on the one hand and Gabidulin codes on the\nother hand. We prove that our codes have good properties with respect to the\nminimal distance and design an efficient decoding algorithm. \n\n"}
{"id": "1901.00481", "contents": "Title: Minimizing The Age of Information in a CSMA Environment Abstract: In this paper, we investigate a network of N interfering links contending for\nthe channel to send their data by employing the well-known Carrier Sense\nMultiple Access (CSMA) scheme. By leveraging the notion of stochastic hybrid\nsystems, we find a closed form of the total average age of the network in this\nsetting. Armed with this expression, we formulate the optimization problem of\nminimizing the total average age of the network by calibrating the back-off\ntime of each link. By analyzing its structure, the optimization problem is then\nconverted to an equivalent convex problem that can be solved efficiently to\nfind the optimal back-off time of each link. Insights on the interaction\nbetween the links is provided and numerical implementations of our optimized\nCSMA scheme in an IEEE 802.11 environment is presented to highlight its\nperformance. We also show that, although optimized, the standard CSMA scheme\nstill lacks behind other distributed schemes in terms of average age in some\nspecial cases. These results suggest the necessity to find new distributed\nschemes to further minimize the average age of any general network. \n\n"}
{"id": "1901.01148", "contents": "Title: Rational Threshold Cryptosystems Abstract: We propose a framework for threshold cryptosystems under a\npermissionless-economic model in which the participants are rational\nprofit-maximizing entities. To date, threshold cryptosystems have been\nconsidered under permissioned settings with a limited adversary. Our framework\nrelies on an escrow service that slashes and redistributes deposits to\nincentivize participants to adhere desired behaviors. Today, more than ever,\nsophisticated escrow services can be implemented over public blockchains like\nEthereum, without additional trust assumptions. The key threat to rational\nthreshold cryptosystems is collusion---by cooperating `illegally', a subset of\nparticipants can reveal the cryptosystem's secret, which, in turn is translated\nto unfair profit. Our countermeasure to collusion is framing. If the escrow is\nnotified of collusion, it rewards the framer and slashes the deposits of all\nother participants. We show that colluding parties find themselves in the\nprisoner's dilemma, where the dominant strategy is framing. \n\n"}
{"id": "1901.01605", "contents": "Title: Bounds on the Length of Functional PIR and Batch codes Abstract: A functional $k$-PIR code of dimension $s$ consists of $n$ servers storing\nlinear combinations of $s$ linearly independent information symbols. Any linear\ncombination of the $s$ information symbols can be recovered by $k$ disjoint\nsubsets of servers. The goal is to find the smallest number of servers for\ngiven $k$ and $s$. We provide lower bounds on the number of servers and\nconstructions which yield upper bounds on this number. For $k \\leq 4$, exact\nbounds on the number of servers are proved. Furthermore, we provide some\nasymptotic bounds. The problem coincides with the well known private\ninformation retrieval problem based on a coded database to reduce the storage\noverhead, when each linear combination contains exactly one information symbol.\n  If any multiset of size $k$ of linear combinations from the linearly\nindependent information symbols can be recovered by $k$ disjoint subset of\nservers, then the servers form a functional $k$-batch code. A~functional\n$k$-batch code is a functional $k$-PIR code, where all the $k$ linear\ncombinations in the multiset are equal. We provide some bounds on the number of\nservers for functional $k$-batch codes. In particular we present a random\nconstruction and a construction based on simplex codes, WOM codes, and RIO\ncodes. \n\n"}
{"id": "1901.02787", "contents": "Title: On Secure Network Coding for Multiple Unicast Traffic Abstract: This paper investigates the problem of secure communication in a wireline\nnoiseless scenario where a source wishes to communicate to a number of\ndestinations in the presence of a passive external adversary. Different from\nthe multicast scenario, where all destinations are interested in receiving the\nsame message, in this setting different destinations are interested in\ndifferent messages. The main focus of this paper is on characterizing the\nsecure capacity region, when the adversary has unbounded computational\ncapabilities, but limited network presence. First, an outer bound on the secure\ncapacity region is derived for arbitrary network topologies and general number\nof destinations. Then, secure transmission schemes are designed and analyzed in\nterms of achieved rate performance. In particular, for the case of two\ndestinations, it is shown that the designed scheme matches the outer bound,\nhence characterizing the secure capacity region. It is also numerically\nverified that the designed scheme matches the outer bound for a special class\nof networks with general number of destinations, referred to as combination\nnetwork. Finally, for an arbitrary network topology with general number of\ndestinations, a two-phase polynomial time in the network size scheme is\ndesigned and its rate performance {is} compared with the capacity-achieving\nscheme for networks with two destinations. \n\n"}
{"id": "1901.02938", "contents": "Title: Private Information Retrieval from Locally Repairable Databases with\n  Colluding Servers Abstract: We consider information-theoretical private information retrieval (PIR) from\na coded database with colluding servers. We target, for the first time, locally\nrepairable storage codes (LRCs). We consider any number of local groups $ g $,\nlocality $ r $, local distance $ \\delta $ and dimension $ k $. Our main\ncontribution is a PIR scheme for maximally recoverable (MR) LRCs based on\nlinearized Reed--Solomon codes, which achieve the smallest field sizes among\nMR-LRCs for many parameter regimes. In our scheme, nodes are identified with\ncodeword symbols and servers are identified with local groups of nodes. Only\nlocally non-redundant information is downloaded from each server, that is, only\n$ r $ nodes (out of $ r+\\delta-1 $) are downloaded per server. The PIR scheme\nachieves the (download) rate $ R = (N - k - rt + 1)/N $, where $ N = gr $ is\nthe length of the MDS code obtained after removing the local parities, and for\nany $ t $ colluding servers such that $ k + rt \\leq N $. For an unbounded\nnumber of stored files, the obtained rate is strictly larger than those of\nknown PIR schemes that work for any MDS code. Finally, the obtained PIR scheme\ncan also be adapted when communication between the user and each server is\nperformed via linear network coding, achieving the same rate as previous PIR\nschemes for this scenario but with polynomial finite field sizes, instead of\nexponential. Our rates are equal to those of PIR schemes for Reed--Solomon\ncodes, but Reed--Solomon codes are incompatible with the MR-LRC property or\nlinear network coding, thus our PIR scheme is less restrictive in its\napplications. \n\n"}
{"id": "1901.05096", "contents": "Title: Status from a Random Field: How Densely Should One Update? Abstract: In many applications, status information of a general spatial process, in\ncontrast to a point information source, is of interest. In this paper, we\nconsider a system where status information is drawn from a random field and\ntransmitted to a fusion center through a wireless multiaccess channel. The\noptimal density of spatial sampling points to minimize the remote status\nestimation error is investigated. Assuming a one-dimensional Gauss Markov\nrandom field and an exponential correlation function, closed-form expressions\nof remote estimation error are obtained for First-Come First-Served (FCFS) and\nLast-Come First-Served (LCFS) service disciplines. The optimal spatial sampling\ndensity for the LCFS case is given explicitly. Simulation results are presented\nwhich agree with our analysis. \n\n"}
{"id": "1901.05428", "contents": "Title: Relative Age of Information: A New Metric for Status Update Systems Abstract: In this paper, we introduce a new data freshness metric, relative Age of\nInformation (rAoI), and examine it in a single server system with various\npacket management schemes. The (classical) AoI metric was introduced to measure\nthe staleness of status updates at the receiving end with respect to their\ngeneration at the source. This metric addresses systems where the timings of\nupdate generation at the source are absolute and can be designed separately or\njointly with the transmission schedules. In many decentralized applications,\ntransmission schedules are blind to update generation timing, and the\ntransmitter can know the timing of an update packet only after it arrives. As\nsuch, an update becomes stale after a new one arrives. The rAoI metric measures\nhow fresh the data is at the receiver with respect to the data at the\ntransmitter. It introduces a particularly explicit dependence on the arrival\nprocess in the evaluation of age. We investigate several queuing disciplines\nand provide closed form expressions for rAoI and numerical comparisons. \n\n"}
{"id": "1901.05445", "contents": "Title: Deep Holes of Projective Reed-Solomon Codes Abstract: Projective Reed-Solomon (PRS) codes are Reed-Solomon codes of the maximum\npossible length q+1. The classification of deep holes --received words with\nmaximum possible error distance-- for PRS codes is an important and difficult\nproblem. In this paper, we use algebraic methods to explicitly construct three\nclasses of deep holes for PRS codes. We show that these three classes\ncompletely classify all deep holes of PRS codes with redundancy at most four.\nPreviously, the deep hole classification was only known for PRS codes with\nredundancy at most three in work arXiv:1612.05447 \n\n"}
{"id": "1901.06346", "contents": "Title: Entanglement-Assisted Quantum Data Compression Abstract: Ask how the quantum compression of ensembles of pure states is affected by\nthe availability of entanglement, and in settings where the encoder has access\nto side information. We find the optimal asymptotic quantum rate and the\noptimal tradeoff (rate region) of quantum and entanglement rates. It turns out\nthat the amount by which the quantum rate beats the Schumacher limit, the\nentropy of the source, is precisely half the entropy of classical information\nthat can be extracted from the source and side information states without\ndisturbing them at all (\"reversible extraction of classical information\").\n  In the special case that the encoder has no side information, or that she has\naccess to the identity of the states, this problem reduces to the known\nsettings of blind and visible Schumacher compression, respectively, albeit here\nadditionally with entanglement assistance. We comment on connections to\npreviously studied and further rate tradeoffs when also classical information\nis considered. \n\n"}
{"id": "1901.06368", "contents": "Title: Outage in Motorway Multi-Lane VANETs with Hardcore Headway Distance\n  Using Synthetic Traces Abstract: In this paper we analyze synthetic mobility traces generated for three-lane\nunidirectional motorway traffic to find that the locations of vehicles along a\nlane are better modeled by a hardcore point process instead of the\nwidely-accepted Poisson point process (PPP). In order to capture the repulsion\nbetween successive vehicles while maintaining a level of analytical\ntractability, we make a simple extension to PPP: We model the inter-vehicle\ndistance along a lane equal to the sum of a constant hardcore distance and an\nexponentially distributed random variable. We calculate the J-function and the\nRipley's K-function for this hardcore point process. We fit its parameters to\nthe available traces, and we illustrate that the higher the average speed along\na lane, the more prominent the hardcore component becomes. In addition, we\nconsider a transmitter-receiver link on the same lane, and we generate simple\nformulae for the moments of interference under reduced Palm measure for that\nlane, and without conditioning for other lanes. We illustrate that under\nRayleigh fading a shifted-gamma approximation for the distribution of\ninterference per lane provides a very good fit to the simulated outage\nprobability using the synthetic traces, while the fit using the PPP is poor. \n\n"}
{"id": "1901.06741", "contents": "Title: Constructions of Batch Codes via Finite Geometry Abstract: A primitive $k$-batch code encodes a string $x$ of length $n$ into string $y$\nof length $N$, such that each multiset of $k$ symbols from $x$ has $k$ mutually\ndisjoint recovering sets from $y$. We develop new explicit and random coding\nconstructions of linear primitive batch codes based on finite geometry. In some\nparameter regimes, our proposed codes have lower redundancy than previously\nknown batch codes. \n\n"}
{"id": "1901.07057", "contents": "Title: A New Design Framework on Device-to-Device Coded Caching with Optimal\n  Rate and Significantly Less Subpacketizations Abstract: In this paper, we propose a new design framework on Device-to-Device (D2D)\ncoded caching networks with optimal rate but significantly less file\nsubpacketizations compared to that of the well-known D2D coded caching scheme\nproposed by Ji, Caire and Molisch (JCM). The proposed design framework is\nreferred to as the {\\em Packet Type-based (PTB) design}, where D2D users are\nfirst partitioned into multiple groups, which leads to a so-called {\\em raw\npacket saving gain}. Then the corresponding multicasting group types and packet\ntypes are specified based on the prescribed node partition. By a careful\nselection of transmitters within each multicasting group, a so-called {\\em\nfurther splitting ratio gain} can also be achieved. By the joint effect of the\n{\\em raw packet saving gain} and the {\\em further splitting ratio gain}, an\norder-wise subpacketization reduction can be achieved compared to the JCM\nscheme while preserving the optimal rate for large system parameter regimes. In\naddition, as the first time presented in the literature according to our\nknowledge, we find that unequal subpacketizaton is a key to achieve a\nsubpacketization gain when the number of users is odd. As a by-product, instead\nof directly translating shared link caching schemes to D2D caching schemes, at\nleast for the sake of subpackeitzations, a new design framework is indeed\nneeded. \n\n"}
{"id": "1901.08782", "contents": "Title: Robust Transceiver Design for MIMO Decode-and-Forward Full-Duplex Relay Abstract: Robust transceiver design against unresolvable system uncertainties is of\ncrucial importance for reliable communication. For instance, full-duplex\ncommunication suffers from such uncertainties when canceling the\nself-interference, since the residual self-interference (RSI) remains\nuncanceled due to imperfect channel knowledge. We consider a MIMO multi-hop\nsystem, where the source, the relay and the destination are equipped with\nmultiple antennas. We allow multi-stream beamforming granted by MIMO technique,\nwithout restricting the transmissions to single streaming. The relay can\noperate in either half-duplex or full-duplex mode, and it changes the mode\ndepending on the RSI strength. Furthermore, the relay is assumed to perform a\ndecode-and-forward (DF) strategy. We investigate a robust transceiver design\nproblem, which maximizes the throughput rate of the worst-case RSI under RSI\nchannel uncertainty bound constraint. The problem turns out to be a non-convex\noptimization problem. We propose an efficient algorithm to obtain a local\noptimal solution iteratively. Eventually, we obtain insights on the optimal\nantenna allocation at the relay input-frontend and output-frontend, for relay\nreception and transmission, respectively. Interestingly, with less number of\nantennas at the source than that at the destination, more number of antennas\nshould be used at the relay input-frontend than the relay output-frontend. \n\n"}
{"id": "1901.09496", "contents": "Title: Characterizing the Shape of Activation Space in Deep Neural Networks Abstract: The representations learned by deep neural networks are difficult to\ninterpret in part due to their large parameter space and the complexities\nintroduced by their multi-layer structure. We introduce a method for computing\npersistent homology over the graphical activation structure of neural networks,\nwhich provides access to the task-relevant substructures activated throughout\nthe network for a given input. This topological perspective provides unique\ninsights into the distributed representations encoded by neural networks in\nterms of the shape of their activation structures. We demonstrate the value of\nthis approach by showing an alternative explanation for the existence of\nadversarial examples. By studying the topology of network activations across\nmultiple architectures and datasets, we find that adversarial perturbations do\nnot add activations that target the semantic structure of the adversarial class\nas previously hypothesized. Rather, adversarial examples are explainable as\nalterations to the dominant activation structures induced by the original\nimage, suggesting the class representations learned by deep networks are\nproblematically sparse on the input space. \n\n"}
{"id": "1901.10979", "contents": "Title: On checkable codes in group algebras Abstract: We classify, in terms of the structure of the finite group G, all group\nalgebras KG for which all right ideals are right annihilators of principal left\nideals. This means in the language of coding theory that we classify\ncode-checkable group algebras KG which have been considered so far only for\nabelian groups G. Optimality of checkable codes and asymptotic results are\ndiscussed. \n\n"}
{"id": "cond-mat/0503087", "contents": "Title: On the Bias of Traceroute Sampling; or, Power-law Degree Distributions\n  in Regular Graphs Abstract: Understanding the structure of the Internet graph is a crucial step for\nbuilding accurate network models and designing efficient algorithms for\nInternet applications. Yet, obtaining its graph structure is a surprisingly\ndifficult task, as edges cannot be explicitly queried. Instead, empirical\nstudies rely on traceroutes to build what are essentially single-source,\nall-destinations, shortest-path trees. These trees only sample a fraction of\nthe network's edges, and a recent paper by Lakhina et al. found empirically\nthat the resuting sample is intrinsically biased. For instance, the observed\ndegree distribution under traceroute sampling exhibits a power law even when\nthe underlying degree distribution is Poisson.\n  In this paper, we study the bias of traceroute sampling systematically, and,\nfor a very general class of underlying degree distributions, calculate the\nlikely observed distributions explicitly. To do this, we use a continuous-time\nrealization of the process of exposing the BFS tree of a random graph with a\ngiven degree distribution, calculate the expected degree distribution of the\ntree, and show that it is sharply concentrated. As example applications of our\nmachinery, we show how traceroute sampling finds power-law degree distributions\nin both delta-regular and Poisson-distributed random graphs. Thus, our work\nputs the observations of Lakhina et al. on a rigorous footing, and extends them\nto nearly arbitrary degree distributions. \n\n"}
{"id": "cond-mat/0603861", "contents": "Title: Congestion-gradient driven transport on complex networks Abstract: We present a study of transport on complex networks with routing based on\nlocal information. Particles hop from one node of the network to another\naccording to a set of routing rules with different degrees of congestion\nawareness, ranging from random diffusion to rigid congestion-gradient driven\nflow. Each node can be either source or destination for particles and all nodes\nhave the same routing capacity, which are features of ad-hoc wireless networks.\nIt is shown that the transport capacity increases when a small amount of\ncongestion awareness is present in the routing rules, and that it then\ndecreases as the routing rules become too rigid when the flow becomes strictly\ncongestion-gradient driven. Therefore, an optimum value of the congestion\nawareness exists in the routing rules. It is also shown that, in the limit of a\nlarge number of nodes, networks using routing based on local information jam at\nany nonzero load. Finally, we study the correlation between congestion at node\nlevel and a betweenness centrality measure. \n\n"}
{"id": "cs/0412111", "contents": "Title: On the asymptotic accuracy of the union bound Abstract: A new lower bound on the error probability of maximum likelihood decoding of\na binary code on a binary symmetric channel was proved in Barg and McGregor\n(2004, cs.IT/0407011). It was observed in that paper that this bound leads to a\nnew region of code rates in which the random coding exponent is asymptotically\ntight, giving a new region in which the reliability of the BSC is known\nexactly. The present paper explains the relation of these results to the union\nbound on the error probability. \n\n"}
{"id": "cs/0511001", "contents": "Title: Capacity with Causal and Non-Causal Side Information - A Unified View Abstract: We identify the common underlying form of the capacity expression that is\napplicable to both cases where causal or non-causal side information is made\navailable to the transmitter. Using this common form we find that for the\nsingle user channel, the multiple access channel, the degraded broadcast\nchannel, and the degraded relay channel, the sum capacity with causal and\nnon-causal side information are identical when all the transmitter side\ninformation is also made available to all the receivers. A genie-aided\nouterbound is developed that states that when a genie provides $n$ bits of side\ninformation to a receiver the resulting capacity improvement can not be more\nthan $n$ bits. Combining these two results we are able to bound the relative\ncapacity advantage of non-causal side information over causal side information\nfor both single user as well as various multiple user communication scenarios.\nApplications of these capacity bounds are demonstrated through examples of\nrandom access channels. Interestingly, the capacity results indicate that the\nexcessive MAC layer overheads common in present wireless systems may be avoided\nthrough coding across multiple access blocks. It is also shown that even one\nbit of side information at the transmitter can result in unbounded capacity\nimprovement. As a side, we obtain the sum capacity for a multiple access\nchannel when the side information available to the transmitter is causal and\npossibly correlated to the side information available to the receiver. \n\n"}
{"id": "cs/0511007", "contents": "Title: K-core decomposition of Internet graphs: hierarchies, self-similarity\n  and measurement biases Abstract: We consider the $k$-core decomposition of network models and Internet graphs\nat the autonomous system (AS) level. The $k$-core analysis allows to\ncharacterize networks beyond the degree distribution and uncover structural\nproperties and hierarchies due to the specific architecture of the system. We\ncompare the $k$-core structure obtained for AS graphs with those of several\nnetwork models and discuss the differences and similarities with the real\nInternet architecture. The presence of biases and the incompleteness of the\nreal maps are discussed and their effect on the $k$-core analysis is assessed\nwith numerical experiments simulating biased exploration on a wide range of\nnetwork models. We find that the $k$-core analysis provides an interesting\ncharacterization of the fluctuations and incompleteness of maps as well as\ninformation helping to discriminate the original underlying structure. \n\n"}
{"id": "cs/0611017", "contents": "Title: A New Data Processing Inequality and Its Applications in Distributed\n  Source and Channel Coding Abstract: In the distributed coding of correlated sources, the problem of\ncharacterizing the joint probability distribution of a pair of random variables\nsatisfying an n-letter Markov chain arises. The exact solution of this problem\nis intractable. In this paper, we seek a single-letter necessary condition for\nthis n-letter Markov chain. To this end, we propose a new data processing\ninequality on a new measure of correlation by means of spectrum analysis. Based\non this new data processing inequality, we provide a single-letter necessary\ncondition for the required joint probability distribution. We apply our results\nto two specific examples involving the distributed coding of correlated\nsources: multi-terminal rate-distortion region and multiple access channel with\ncorrelated sources, and propose new necessary conditions for these two\nproblems. \n\n"}
{"id": "cs/0701003", "contents": "Title: Magnification Laws of Winner-Relaxing and Winner-Enhancing Kohonen\n  Feature Maps Abstract: Self-Organizing Maps are models for unsupervised representation formation of\ncortical receptor fields by stimuli-driven self-organization in laterally\ncoupled winner-take-all feedforward structures. This paper discusses\nmodifications of the original Kohonen model that were motivated by a potential\nfunction, in their ability to set up a neural mapping of maximal mutual\ninformation. Enhancing the winner update, instead of relaxing it, results in an\nalgorithm that generates an infomax map corresponding to magnification exponent\nof one. Despite there may be more than one algorithm showing the same\nmagnification exponent, the magnification law is an experimentally accessible\nquantity and therefore suitable for quantitative description of neural\noptimization principles. \n\n"}
{"id": "cs/0702018", "contents": "Title: Estimation of the Rate-Distortion Function Abstract: Motivated by questions in lossy data compression and by theoretical\nconsiderations, we examine the problem of estimating the rate-distortion\nfunction of an unknown (not necessarily discrete-valued) source from empirical\ndata. Our focus is the behavior of the so-called \"plug-in\" estimator, which is\nsimply the rate-distortion function of the empirical distribution of the\nobserved data. Sufficient conditions are given for its consistency, and\nexamples are provided to demonstrate that in certain cases it fails to converge\nto the true rate-distortion function. The analysis of its performance is\ncomplicated by the fact that the rate-distortion function is not continuous in\nthe source distribution; the underlying mathematical problem is closely related\nto the classical problem of establishing the consistency of maximum likelihood\nestimators. General consistency results are given for the plug-in estimator\napplied to a broad class of sources, including all stationary and ergodic ones.\nA more general class of estimation problems is also considered, arising in the\ncontext of lossy data compression when the allowed class of coding\ndistributions is restricted; analogous results are developed for the plug-in\nestimator in that case. Finally, consistency theorems are formulated for\nmodified (e.g., penalized) versions of the plug-in, and for estimating the\noptimal reproduction distribution. \n\n"}
{"id": "cs/0702035", "contents": "Title: New Models for the Correlation in Sensor Data Abstract: In this paper, we propose two new models of spatial correlations in sensor\ndata in a data-gathering sensor network. A particular property of these models\nis that if a sensor node knows in \\textit{how many} bits it needs to transmit\nits data, then it also knows \\textit{which} bits of its data it needs to\ntransmit. \n\n"}
{"id": "cs/0703005", "contents": "Title: State Amplification Abstract: We consider the problem of transmitting data at rate R over a state dependent\nchannel p(y|x,s) with the state information available at the sender and at the\nsame time conveying the information about the channel state itself to the\nreceiver. The amount of state information that can be learned at the receiver\nis captured by the mutual information I(S^n; Y^n) between the state sequence\nS^n and the channel output Y^n. The optimal tradeoff is characterized between\nthe information transmission rate R and the state uncertainty reduction rate\n\\Delta, when the state information is either causally or noncausally available\nat the sender. This result is closely related and in a sense dual to a recent\nstudy by Merhav and Shamai, which solves the problem of masking the state\ninformation from the receiver rather than conveying it. \n\n"}
{"id": "cs/0703120", "contents": "Title: Sequential decoding for lossless streaming source coding with side\n  information Abstract: The problem of lossless fixed-rate streaming coding of discrete memoryless\nsources with side information at the decoder is studied. A random time-varying\ntree-code is used to sequentially bin strings and a Stack Algorithm with a\nvariable bias uses the side information to give a delay-universal coding system\nfor lossless source coding with side information. The scheme is shown to give\nexponentially decaying probability of error with delay, with exponent equal to\nGallager's random coding exponent for sources with side information. The mean\nof the random variable of computation for the stack decoder is bounded, and\nconditions on the bias are given to guarantee a finite $\\rho^{th}$ moment for\n$0 \\leq \\rho \\leq 1$.\n  Further, the problem is also studied in the case where there is a discrete\nmemoryless channel between encoder and decoder. The same scheme is slightly\nmodified to give a joint-source channel encoder and Stack Algorithm-based\nsequential decoder using side information. Again, by a suitable choice of bias,\nthe probability of error decays exponentially with delay and the random\nvariable of computation has a finite mean. Simulation results for several\nexamples are given. \n\n"}
{"id": "math/0005281", "contents": "Title: Connections between Linear Systems and Convolutional Codes Abstract: The article reviews different definitions for a convolutional code which can\nbe found in the literature. The algebraic differences between the definitions\nare worked out in detail. It is shown that bi-infinite support systems are dual\nto finite-support systems under Pontryagin duality. In this duality the dual of\na controllable system is observable and vice versa. Uncontrollability can occur\nonly if there are bi-infinite support trajectories in the behavior, so finite\nand half-infinite-support systems must be controllable. Unobservability can\noccur only if there are finite support trajectories in the behavior, so\nbi-infinite and half-infinite-support systems must be observable. It is shown\nthat the different definitions for convolutional codes are equivalent if one\nrestricts attention to controllable and observable codes. \n\n"}
{"id": "math/0302172", "contents": "Title: Results on zeta functions for codes Abstract: We give a new and short proof of the Mallows-Sloane upper bound for self-dual\ncodes. We formulate a version of Greene's theorem for normalized weight\nenumerators. We relate normalized rank-generating polynomials to two-variable\nzeta functions. And we show that a self-dual code has the Clifford property,\nbut that the same property does not hold in general for formally self-dual\ncodes. \n\n"}
{"id": "math/0307196", "contents": "Title: Convolutional Codes with Maximum Distance Profile Abstract: Maximum distance profile codes are characterized by the property that two\ntrajectories which start at the same state and proceed to a different state\nwill have the maximum possible distance from each other relative to any other\nconvolutional code of the same rate and degree.\n  In this paper we use methods from systems theory to characterize maximum\ndistance profile codes algebraically. Tha main result shows that maximum\ndistance profile codes form a generic set inside the variety which parametrizes\nthe set of convolutional codes of a fixed rate and a fixed degree. \n\n"}
{"id": "math/0309425", "contents": "Title: Algebraic Aspects of Multiple Zeta Values Abstract: Multiple zeta values have been studied by a wide variety of methods. In this\narticle we summarize some of the results about them that can be obtained by an\nalgebraic approach. This involves \"coding\" the multiple zeta values by\nmonomials in two noncommuting variables x and y. Multiple zeta values can then\nbe thought of as defining a map \\zeta: H^0 -> R, where H^0 is the graded\nrational vector space generated by the \"admissible words\" of the noncommutative\npolynomial algebra Q<x,y>. Now H^0 admits two (commutative) products making\n\\zeta a homomorphism: the shuffle product and the \"harmonic\" product. The\nlatter makes H^0 a subalgebra of the algebra QSym of quasi-symmetric functions.\nWe also discuss some results about multiple zeta values that can be stated in\nterms of derivations and cyclic derivations of Q<x,y>, and define an action of\nthe Hopf algebra QSym on Q<x,y> that appears useful. Finally, we apply the\nalgebraic approach to finite partial sums of multiple zeta value series. \n\n"}
{"id": "math/0401045", "contents": "Title: Unitary Space Time Constellation Analysis: An Upper Bound for the\n  Diversity Abstract: The diversity product and the diversity sum are two very important parameters\nfor a good-performing unitary space time constellation. A basic question is\nwhat the maximal diversity product (or sum) is. In this paper we are going to\nderive general upper bounds on the diversity sum and the diversity product for\nunitary constellations of any dimension $n$ and any size $m$ using packing\ntechniques on the compact Lie group U(n). \n\n"}
{"id": "math/0510013", "contents": "Title: Network Kriging Abstract: Network service providers and customers are often concerned with aggregate\nperformance measures that span multiple network paths. Unfortunately, forming\nsuch network-wide measures can be difficult, due to the issues of scale\ninvolved. In particular, the number of paths grows too rapidly with the number\nof endpoints to make exhaustive measurement practical. As a result, it is of\ninterest to explore the feasibility of methods that dramatically reduce the\nnumber of paths measured in such situations while maintaining acceptable\naccuracy.\n  We cast the problem as one of statistical prediction--in the spirit of the\nso-called `kriging' problem in spatial statistics--and show that end-to-end\nnetwork properties may be accurately predicted in many cases using a\nsurprisingly small set of carefully chosen paths. More precisely, we formulate\na general framework for the prediction problem, propose a class of linear\npredictors for standard quantities of interest (e.g., averages, totals,\ndifferences) and show that linear algebraic methods of subset selection may be\nused to effectively choose which paths to measure. We characterize the\nperformance of the resulting methods, both analytically and numerically. The\nsuccess of our methods derives from the low effective rank of routing matrices\nas encountered in practice, which appears to be a new observation in its own\nright with potentially broad implications on network measurement generally. \n\n"}
{"id": "physics/0608185", "contents": "Title: Updating Probabilities Abstract: We show that Skilling's method of induction leads to a unique general theory\nof inductive inference, the method of Maximum relative Entropy (ME). The main\ntool for updating probabilities is the logarithmic relative entropy; other\nentropies such as those of Renyi or Tsallis are ruled out. We also show that\nBayes updating is a special case of ME updating and thus, that the two are\ncompletely compatible. \n\n"}
{"id": "quant-ph/0306118", "contents": "Title: Unconditionally Secure Multipartite Quantum Key Distribution Abstract: We consider the problem of secure key distribution among $n$ trustful agents:\nthe goal is to distribute an identical random bit-string among the $n$ agents\nover a noisy channel such that eavesdroppers learn little about it. We study\nthe general situation where the only resources required are secure bipartite\nkey distribution and authenticated classical communication. Accordingly,\nmultipartite quantum key distribution can be proven unconditionally secure by\nreducing the problem to the biparitite case and invoking the proof of security\nof bipartite quantum key distribution. \n\n"}
