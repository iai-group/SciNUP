{"id": "0704.3572", "contents": "Title: The subpulse modulation properties of pulsars at 92 cm and the frequency\n  dependence of subpulse modulation Abstract: A large sample of pulsars has been observed to study their subpulse\nmodulation at an observing wavelength (when achievable) of both 21 and 92 cm\nusing the Westerbork Synthesis Radio Telescope. In this paper we present the\n92-cm data and a comparison is made with the already published 21-cm results.\nWe analysed 191 pulsars at 92 cm using fluctuation spectra. The sample of\npulsars is as unbiased as possible towards any particular pulsar\ncharacteristics. For 15 pulsars drifting subpulses are discovered for the first\ntime and 26 of the new drifters found in the 21-cm data are confirmed. We\ndiscovered nulling for 8 sources and 8 pulsars are found to intermittently emit\nsingle pulses that have pulse energies similar to giant pulses. It is estimated\nthat at least half of the total population of pulsars have drifting subpulses\nwhen observations with a high enough signal-to-noise ratio would be available.\nIt could well be that the drifting subpulse mechanism is an intrinsic property\nof the emission mechanism itself, although for some pulsars it is difficult or\nimpossible to detect. Drifting subpulses are in general found at both\nfrequencies, although the chance of detecting drifting subpulses is possibly\nslightly higher at 92 cm. It appears that the youngest pulsars have the most\ndisordered subpulses and the subpulses become more and more organized into\ndrifting subpulses as the pulsar ages. The correlations with the modulation\nindices are argued to be consistent with the picture in which the radio\nemission can be divided in a drifting subpulse signal plus a quasi-steady\nsignal which becomes, on average, stronger at high observing frequencies. The\nmeasured values of P3 at the two frequencies are highly correlated, but there\nis no evidence for a correlation with other pulsar parameters. \n\n"}
{"id": "0704.3594", "contents": "Title: Search for Baryonic Resonances Decaying to Xi pi in Deep-Inelastic\n  Scattering at HERA Abstract: A search for narrow baryonic resonances decaying into Xi- pi- or Xi- pi+ and\ntheir antiparticles is carried out with the H1 detector using deep inelastic\nscattering events at HERA in the range of negative photon four-momentum\ntransfer squared 2 < Q^2 < 100 GeV^2. No signal is observed for a new baryonic\nstate in the mass range 1600 - 2300 MeV in either the doubly charged or the\nneutral decay channels. The known baryon Xi0 is observed through its decay mode\ninto Xi- pi+. Upper limits are given on the ratio of the production rates of\nnew baryonic states, such as the hypothetical pentaquark states Xi^{--}_{5q} or\nXi^{0}_{5q}, relative to the Xi0 baryon state. \n\n"}
{"id": "0706.0200", "contents": "Title: Leptogenesis With Many Neutrinos Abstract: We consider leptogenesis in scenarios with many neutrino singlets. We find\nthat the lower bound for the reheating temperature can be significantly relaxed\nwith respect to the hierarchical three neutrino case. We further argue that the\nupper bound for the neutrino mass scale from leptogenesis gets significantly\nlifted in these scenarios. As a specific realization, we then discuss an\nextra-dimensional model, where the large number of neutrinos is provided by\nKaluza-Klein excitations. \n\n"}
{"id": "0706.1645", "contents": "Title: Dynamics of Three Agent Games Abstract: We study the dynamics and resulting score distribution of three-agent games\nwhere after each competition a single agent wins and scores a point. A single\ncompetition is described by a triplet of numbers $p$, $t$ and $q$ denoting the\nprobabilities that the team with the highest, middle or lowest accumulated\nscore wins. We study the full family of solutions in the regime, where the\nnumber of agents and competitions is large, which can be regarded as a\nhydrodynamic limit. Depending on the parameter values $(p,q,t)$, we find six\nqualitatively different asymptotic score distributions and we also provide a\nqualitative understanding of these results. We checked our analytical results\nagainst numerical simulations of the microscopic model and find these to be in\nexcellent agreement. The three agent game can be regarded as a social model\nwhere a player can be favored or disfavored for advancement, based on his/her\naccumulated score. It is also possible to decide the outcome of a three agent\ngame through a mini tournament of two-a gent competitions among the\nparticipating players and it turns out that the resulting possible score\ndistributions are a subset of those obtained for the general three agent-games.\nWe discuss how one can add a steady and democratic decline rate to the model\nand present a simple geometric construction that allows one to write down the\ncorresponding score evolution equations for $n$-agent games. \n\n"}
{"id": "0706.3160", "contents": "Title: Spin pumping by a field-driven domain wall Abstract: We calculate the charge current in a metallic ferromagnet to first order in\nthe time derivative of the magnetization direction. Irrespective of the\nmicroscopic details, the result can be expressed in terms of the conductivities\nof the majority and minority electrons and the non-adiabatic spin transfer\ntorque parameter $\\beta$. The general expression is evaluated for the specific\ncase of a field-driven domain wall and for that case depends strongly on the\nratio of $\\beta$ and the Gilbert damping constant. These results may provide an\nexperimental method to determine this ratio, which plays a crucial role for\ncurrent-driven domain-wall motion. \n\n"}
{"id": "0706.3857", "contents": "Title: The onset of photoionization in Sakurai's Object (V4334 Sgr) Abstract: We investigate the reheating of the very late thermal pulse (VLTP) object\nV4334 Sgr (Sakurai's Object) using radio observations from the Very Large\nArray, and optical spectra obtained with the Very Large Telescope. We find a\nsudden rise of the radio flux at 5 and 8 GHz - from <= 90 micro-Jy and 80 +/-\n30 micro-Jy in February 2005 to 320 micro-Jy and 280 micro-Jy in June 2006.\nOptical line emission is also evolving, but the emission lines are fading. The\noptical line emission and early radio flux are attributed to a fast shock (and\nnot photoionization as was reported earlier) which occurred around 1998. The\nfading is due to post-shock cooling and recombination. The recent rapid\nincrease in radio flux is evidence for the onset of photoionization of carbon\nstarting around 2005. The current results indicate an increase in the stellar\ntemperature to 12 kK in 2006. The mass ejected in the VLTP eruption is M_ej >=\n1e-4 Msol, but could be as high as 1e-2 Msol, depending mainly on the distance\nand the clumping factor of the outflow. We derive a distance between 1.8 and 5\nkpc. A high mass loss could expose the helium layer and yield abundances\ncompatible with those of [WC] and PG1159 stars. \n\n"}
{"id": "0708.0998", "contents": "Title: Fine-tune your smile: Correction to Hagan et al Abstract: In this small note we use results derived in Berestycki et al. to correct the\ncelebrated formulae of Hagan et al. We derive explicitly the correct zero order\nterm in the expansion of the implied volatility in time to maturity. The new\nterm is consistent as $\\beta\\to 1$. Furthermore, numerical simulations show\nthat it reduces or eliminates known pathologies of the earlier formula. \n\n"}
{"id": "0708.1304", "contents": "Title: Interaction-Induced Strong Localization in Quantum Dots Abstract: We argue that Coulomb blockade phenomena are a useful probe of the cross-over\nto strong correlation in quantum dots. Through calculations at low density\nusing variational and diffusion quantum Monte Carlo (up to r_s ~ 55), we find\nthat the addition energy shows a clear progression from features associated\nwith shell structure to those caused by commensurability of a Wigner crystal.\nThis cross-over (which occurs near r_s ~ 20 for spin-polarized electrons) is,\nthen, a signature of interaction-driven localization. As the addition energy is\ndirectly measurable in Coulomb blockade conductance experiments, this provides\na direct probe of localization in the low density electron gas. \n\n"}
{"id": "0708.4022", "contents": "Title: Time reversal invariance in finance Abstract: Time reversal invariance can be summarized as follows: no difference can be\nmeasured if a sequence of events is run forward or backward in time. Because\nprice time series are dominated by a randomness that hides possible structures\nand orders, the existence of time reversal invariance requires care to be\ninvestigated. Different statistics are constructed with the property to be zero\nfor time series which are time reversal invariant; they all show that\nhigh-frequency empirical foreign exchange prices are not invariant. The same\nstatistics are applied to mathematical processes that should mimic empirical\nprices. Monte Carlo simulations show that only some ARCH processes with a\nmulti-timescales structure can reproduce the empirical findings. A GARCH(1,1)\nprocess can only reproduce some asymmetry. On the other hand, all the\nstochastic volatility type processes are time reversal invariant. This clear\ndifference related to the process structures gives some strong selection\ncriterion for processes. \n\n"}
{"id": "0709.0182", "contents": "Title: Bell-state preparation for electron spins in a semiconductor double\n  quantum dot Abstract: A robust scheme for state preparation and state trapping for the spins of two\nelectrons in a semiconductor double quantum dot is presented. The system is\nmodeled by two spins coupled to two independent bosonic reservoirs. Decoherence\neffects due to this environment are minimized by application of optimized\ncontrol fields which make the target state to the ground state of the isolated\ndriven spin system. We show that stable spin entanglement with respect to pure\ndephasing is possible. Specifically, we demonstrate state trapping in a\nmaximally entangled state (Bell state) in the presence of decoherence. \n\n"}
{"id": "0709.1255", "contents": "Title: Local structure of algebraic monoids Abstract: We describe the local structure of an irreducible algebraic monoid $M$ at an\nidempotent element $e$. When $e$ is minimal, we show that $M$ is an induced\nvariety over the kernel $MeM$ (a homogeneous space) with fibre the two-sided\nstabilizer $M_e$ (a connected affine monoid having a zero element and a dense\nunit group). This yields the irreducibility of stabilizers and centralizers of\nidempotents when $M$ is normal, and criteria for normality and smoothness of an\narbitrary $M$. Also, we show that $M$ is an induced variety over an abelian\nvariety, with fiber a connected affine monoid having a dense unit group. \n\n"}
{"id": "0711.0866", "contents": "Title: Gauge Thresholds and Kaehler Metrics for Rigid Intersecting D-brane\n  Models Abstract: The gauge threshold corrections for globally consistent Z2 x Z2' orientifolds\nwith rigid intersecting D6-branes are computed. The one-loop corrections to the\nholomorphic gauge kinetic function are extracted and the Kaehler metrics for\nthe charged chiral multiplets are determined up to two constants. \n\n"}
{"id": "0712.0493", "contents": "Title: Linear and nonlinear tails II: exact decay rates in spherical symmetry Abstract: We derive the exact late-time asymptotics for small spherically symmetric\nsolutions of nonlinear wave equations with a potential. The dominant tail is\nshown to result from the competition between linear and nonlinear effects. \n\n"}
{"id": "0712.1975", "contents": "Title: Reentrant spin glass transition in LuFe2O4 Abstract: We have carried out a comprehensive investigation of magnetic properties of\nLuFe$_2$O$_4$, using AC susceptibility, DC magnetization and specific heat. A\nmagnetic phase transition around $\\sim$236 K was observed with DC magnetization\nand specific heat measurements, which is identified as a paramagnetic to\nferrimagnetic transition based on the nonlinear susceptibility data. Upon\nfurther cooling below this temperature, we also observed highly relaxational\nmagnetic behavior: the DC magnetization exhibits history and time dependence,\nand the real and imaginary part of the AC susceptibility shows large frequency\ndependence. Dynamic scaling of the AC susceptibility data suggests that this\nlow temperature phase can be described as a reentrant spin glass phase. We also\ndiscuss magnetic field dependence of the spin glass transition and aging,\nmemory and rejuvenation effect below the glass transition temperature around\n228 K. \n\n"}
{"id": "0801.0021", "contents": "Title: Bootstrap Approximations in Contractor Renormalization Abstract: We propose a bootstrap method for approximating the long-range terms in the\nContractor Renormalization (CORE) method. The idea is tested on the 2-D\nHeisenberg antiferromagnet and the frustrated J_2-J_1 model. We obtain\nrenormalization group flows that directly reveal the Neel phase of the\nunfrustrated HAF and the existence of a phase transition in the J_2-J_1 model\nfor weak frustration. However, we find that this bootstrap method is dependent\non blocking and truncation schemes. For this reason, we discuss these\ndependencies and unresolved issues that researchers who use this approach must\nconsider. \n\n"}
{"id": "0801.0836", "contents": "Title: Phase transition of clock models on hyperbolic lattice studied by corner\n  transfer matrix renormalization group method Abstract: Two-dimensional ferromagnetic N-state clock models are studied on a\nhyperbolic lattice represented by tessellation of pentagons. The lattice lies\non the hyperbolic plane with a constant negative scalar curvature. We observe\nthe spontaneous magnetization, the internal energy, and the specific heat at\nthe center of sufficiently large systems, where the fixed boundary conditions\nare imposed, for the cases N>=3 up to N=30. The model with N=3, which is\nequivalent to the 3-state Potts model on the hyperbolic lattice, exhibits the\nfirst order phase transition. A mean-field like phase transition of the second\norder is observed for the cases N>=4. When N>=5 we observe the Schottky type\nspecific heat below the transition temperature, where its peak hight at low\ntemperatures scales as N^{-2}. From these facts we conclude that the phase\ntransition of classical XY-model deep inside the hyperbolic lattices is not of\nthe Berezinskii-Kosterlitz-Thouless type. \n\n"}
{"id": "0802.0505", "contents": "Title: How to constrain inflationary parameter space with minimal priors Abstract: We update constraints on the Hubble function H(phi) during inflation, using\nthe most recent cosmic microwave background (CMB) and large scale structure\n(LSS) data. Our main focus is on a comparison between various commonly used\nmethods of calculating the primordial power spectrum via analytical\napproximations and the results obtained by integrating the exact equations\nnumerically. In each case, we impose naive, minimally restrictive priors on the\nduration of inflation. We find that the choice of priors has an impact on the\nresults: the bounds on inflationary parameters can vary by up to a factor two.\nNevertheless, it should be noted that within the region allowed by the minimal\nprior of the exact method, the accuracy of the approximations is sufficient for\ncurrent data. We caution however that a careless minimal implementation of the\napproximative methods allows models for which the assumptions behind the\nanalytical approximations fail, and recommend using the exact numerical method\nfor a self-consistent analysis of cosmological data. \n\n"}
{"id": "0802.1162", "contents": "Title: Approximate substitutions and the normal ordering problem Abstract: In this paper, we show that the infinite generalised Stirling matrices\nassociated with boson strings with one annihilation operator are projective\nlimits of approximate substitutions, the latter being characterised by a finite\nset of algebraic equations. \n\n"}
{"id": "0802.1799", "contents": "Title: The supersymmetric solutions and extensions of ungauged matter-coupled\n  N=1,d=4 supergravity Abstract: We find the most general supersymmetric solutions of ungauged N=1,d=4\nsupergravity coupled to an arbitrary number of vector and chiral\nsupermultiplets, which turn out to be essentially pp-waves and strings. We also\nintroduce magnetic 1-forms and their supersymmetry transformations and 2-forms\nassociated to the isometries of the scalar manifold and their supersymmetry\ntransformations. Only the latter can couple to BPS objects (strings), in\nagreement with our results. \n\n"}
{"id": "0802.3989", "contents": "Title: Modelling the Berezinskii-Kosterlitz-Thouless Transition in the\n  NiGa_2S_4 Abstract: In the two-dimensional superfluidity, the proliferation of the vortices and\nthe anti-vortices results in a new class of phase transition,\nBerezinskii-Kosterlitz-Thouless (BKT) transition. This class of the phase\ntransitions is also anticipated in the two-dimensional magnetic systems.\nHowever, its existence in the real magnetic systems still remains mysterious.\nHere we propose a phenomenological model to illustrate that the novel\nspin-freezing transition recently uncovered in the NMR experiment on the\nNiGa_2S_4 compound is the BKT-type. The novel spin-freezing state observed in\nthe NiGa_2S_4 possesses the power-law decayed spin correlation. \n\n"}
{"id": "0802.4411", "contents": "Title: Chi-square simulation of the CIR process and the Heston model Abstract: The transition probability of a Cox-Ingersoll-Ross process can be represented\nby a non-central chi-square density. First we prove a new representation for\nthe central chi-square density based on sums of powers of generalized Gaussian\nrandom variables. Second we prove Marsaglia's polar method extends to this\ndistribution, providing a simple, exact, robust and efficient\nacceptance-rejection method for generalized Gaussian sampling and thus central\nchi-square sampling. Third we derive a simple, high-accuracy, robust and\nefficient direct inversion method for generalized Gaussian sampling based on\nthe Beasley-Springer-Moro method. Indeed the accuracy of the approximation to\nthe inverse cumulative distribution function is to the tenth decimal place. We\nthen apply our methods to non-central chi-square variance sampling in the\nHeston model. We focus on the case when the number of degrees of freedom is\nsmall and the zero boundary is attracting and attainable, typical in foreign\nexchange markets. Using the additivity property of the chi-square distribution,\nour methods apply in all parameter regimes. \n\n"}
{"id": "0803.1118", "contents": "Title: First Observation of the Decay D_s^+ to proton anti-neutron Abstract: Using e^+e^- -> D_s^*+ D_s^- data collected near the peak D_s production\nenergy, E_cm=4170 MeV, with the CLEO-c detector, we present the first\nobservation of the decay D_s^+ -> proton anti-neutron. We measure a branching\nfraction B(D_s^+ -> p anti-n = (1.30 +- 0.36 +0.12 -0.16) x 10^-3. This is the\nfirst observation of a charmed meson decaying into a baryon-antibaryon final\nstate. \n\n"}
{"id": "0803.1389", "contents": "Title: Determining the Fractal Dimension of the Interstellar Medium Abstract: The Interstellar Medium seems to have an underlying fractal structure, which\ncan be characterized through its fractal dimension (Df). However, several\nfactors may affect the determination of Df, such as distortions due to\nprojection, low image resolution, opacity of the cloud, and low signal-to-noise\nratio. Here we use both simulated clouds and real molecular cloud maps to study\nthese effects in order to estimate Df in a reliable way. Our results indicate\nin a self-consistent way that the fractal dimension of the Interstellar Medium\nis in the range 2.6 < Df < 2.8, which is significantly higher than the value Df\n= 2.3 usually assumed in the literature. \n\n"}
{"id": "0804.0900", "contents": "Title: Nonlinear Fokker-Planck Equation in the Model of Asset Returns Abstract: The Fokker-Planck equation with diffusion coefficient quadratic in space\nvariable, linear drift coefficient, and nonlocal nonlinearity term is\nconsidered in the framework of a model of analysis of asset returns at\nfinancial markets. For special cases of such a Fokker-Planck equation we\ndescribe a construction of exact solution of the Cauchy problem. In the general\ncase, we construct the leading term of the Cauchy problem solution asymptotic\nin a formal small parameter in semiclassical approximation following the\ncomplex WKB-Maslov method in the class of trajectory concentrated functions. \n\n"}
{"id": "0804.2193", "contents": "Title: Mutually unbiased bases, orthogonal Latin squares, and hidden-variable\n  models Abstract: Mutually unbiased bases encapsulate the concept of complementarity - the\nimpossibility of simultaneous knowledge of certain observables - in the\nformalism of quantum theory. Although this concept is at the heart of quantum\nmechanics, the number of these bases is unknown except for systems of dimension\nbeing a power of a prime. We develop the relation between this physical problem\nand the mathematical problem of finding the number of mutually orthogonal Latin\nsquares. We derive in a simple way all known results about the unbiased bases,\nfind their lower number, and disprove the existence of certain forms of the\nbases in dimensions different than power of a prime. Using the Latin squares,\nwe construct hidden-variable models which efficiently simulate results of\ncomplementary quantum measurements. \n\n"}
{"id": "0804.3827", "contents": "Title: Inverse Temperature 4-vector in Special Relativity Abstract: There exist several prescriptions for identifying the notion of temperature\nin special relativity. We argue that the inverse temperature 4-vector $\\bf\n\\beta$ is the only viable option from the laws of thermodynamics, and $\\bf\n\\beta$ is a future-directed timelike 4-vector. Using a superfluidity thought\nexperiment, one can show that $\\bf \\beta$ is not necessarily along the time\ndirection of the comoving frame of the system, as is usually thought. It is\nconjectured that, for an isolated system, the 4-vector is determined from the\nentropy-maximum principle. \n\n"}
{"id": "0804.4103", "contents": "Title: Exploring FSR open cluster candidates within $|\\Delta\\ell|=20^\\circ$ of\n  the Galactic anticentre Abstract: We investigate the nature of a sample of star cluster candidates detected as\nstellar overdensities towards the Galactic anticentre. Taken from the catalogue\nof Froebrich, Scholz, and Raftery (FSR), the sample contains 28 star cluster\ncandidates located within $|\\Delta\\ell|=20^\\circ$ of the anticentre. These are\nall the candidates in that sector classified by FSR with a high probability of\nbeing star clusters. Our main goals are to determine the fraction of such\ncandidates that are unknown star clusters, to derive their astrophysical\nparameters, and to investigate the relationship of cluster parameters with\nposition in the Galaxy. When photometric and radial distribution properties are\nconsidered together, an important fraction of the stellar overdensities with a\nfluctuation level $\\ga3\\sigma$ are shown to be star clusters. Thus, catalogues\nof star cluster candidates, coupled to the present kind of study, are an\nimportant source for identifying unknown open clusters. Such efforts affect the\nunderstanding of the star-formation rate, cluster dynamical evolution, and\nGalactic structure, among others. \n\n"}
{"id": "0805.0540", "contents": "Title: Probability distribution of returns in the exponential\n  Ornstein-Uhlenbeck model Abstract: We analyze the problem of the analytical characterization of the probability\ndistribution of financial returns in the exponential Ornstein-Uhlenbeck model\nwith stochastic volatility. In this model the prices are driven by a Geometric\nBrownian motion, whose diffusion coefficient is expressed through an\nexponential function of an hidden variable Y governed by a mean-reverting\nprocess. We derive closed-form expressions for the probability distribution and\nits characteristic function in two limit cases. In the first one the\nfluctuations of Y are larger than the volatility normal level, while the second\none corresponds to the assumption of a small stationary value for the variance\nof Y. Theoretical results are tested numerically by intensive use of Monte\nCarlo simulations. The effectiveness of the analytical predictions is checked\nvia a careful analysis of the parameters involved in the numerical\nimplementation of the Euler-Maruyama scheme and is tested on a data set of\nfinancial indexes. In particular, we discuss results for the German DAX30 and\nDow Jones Euro Stoxx 50, finding a good agreement between the empirical data\nand the theoretical description. \n\n"}
{"id": "0805.0611", "contents": "Title: Transformation methods for evaluating approximations to the optimal\n  exercise boundary for linear and nonlinear Black-Scholes equations Abstract: The purpose of this survey chapter is to present a transformation technique\nthat can be used in analysis and numerical computation of the early exercise\nboundary for an American style of vanilla options that can be modelled by class\nof generalized Black-Scholes equations. We analyze qualitatively and\nquantitatively the early exercise boundary for a linear as well as a class of\nnonlinear Black-Scholes equations with a volatility coefficient which can be a\nnonlinear function of the second derivative of the option price itself. A\nmotivation for studying the nonlinear Black-Scholes equation with a nonlinear\nvolatility arises from option pricing models taking into account e.g.\nnontrivial transaction costs, investor's preferences, feedback and illiquid\nmarkets effects and risk from a volatile (unprotected) portfolio. We present a\nmethod how to transform the free boundary problem for the early exercise\nboundary position into a solution of a time depending nonlinear nonlocal\nparabolic equation defined on a fixed domain. We furthermore propose an\niterative numerical scheme that can be used in order to find an approximation\nof the free boundary. In the case of a linear Black-Scholes equation we are\nable to derive a nonlinear integral equation for the position of the free\nboundary. We present results of numerical approximation of the early exercise\nboundary for various types of linear and nonlinear Black-Scholes equations and\nwe discuss dependence of the free boundary on model parameters. Finally, we\ndiscuss an application of the transformation method for the pricing equation\nfor American type of Asian options. \n\n"}
{"id": "0805.1360", "contents": "Title: Infinite self-gravitating systems and cosmological structure formation Abstract: The usual thermodynamic limit for systems of classical self-gravitating point\nparticles becomes well defined, as a {\\it dynamical} problem, using a simple\nphysical prescription for the calculation of the force, equivalent to the\nso-called ``Jeans' swindle''. The relation of the resulting intrinsically out\nof equilibrium problem, of particles evolving from prescribed uniform initial\nconditions in an infinite space, to the one studied in current cosmological\nmodels (in an expanding universe) is explained. We then describe results of a\nnumerical study of the dynamical evolution of such a system, starting from a\nsimple class of infinite ``shuffled lattice'' initial conditions. The\nclustering, which develops in time starting from scales around the grid scale,\nis qualitatively very similar to that seen in cosmological simulations, which\nbegin from lattices with applied correlated displacements and incorporate an\nexpanding spatial background. From very soon after the formation of the first\nnon-linear structures, a spatio-temporal scaling relation describes well the\nevolution of the two-point correlations. At larger times the dynamics of these\ncorrelations converges to what is termed ``self-similar'' evolution in\ncosmology, in which the time dependence in the scaling relation is specified\nentirely by that of the linearized fluid theory. We show how this statistical\nmechanical ``toy model'' can be useful in addressing various questions about\nthese systems which are relevant in cosmology. Some of these questions are\nclosely analagous to those currently studied in the literature on long range\ninteractions, notably the relation of the evolution of the particle system to\nthat in the Vlasov limit and the nature of approximately quasi-stationary\nstates. \n\n"}
{"id": "0805.3838", "contents": "Title: Cohen-Macaulay clutters with combinatorial optimization properties and\n  parallelizations of normal edge ideals Abstract: Let C be a uniform clutter and let I=I(C) be its edge ideal. We prove that if\nC satisfies the packing property (resp. max-flow min-cut property), then there\nis a uniform Cohen-Macaulay clutter C1 satisfying the packing property (resp.\nmax-flow min-cut property) such that C is a minor of C1. For arbitrary edge\nideals of clutters we prove that the normality property is closed under\nparallelizations. Then we show some applications to edge ideals and clutters\nwhich are related to a conjecture of Conforti and Cornu\\'ejols and to max-flow\nmin-cut problems. \n\n"}
{"id": "0805.4658", "contents": "Title: Multi-matrix models and emergent geometry Abstract: Encouraged by the AdS/CFT correspondence, we study emergent local geometry in\nlarge N multi-matrix models from the perspective of a strong coupling\nexpansion. By considering various solvable interacting models we show how the\nemergence or non-emergence of local geometry at strong coupling is captured by\nobservables that effectively measure the mass of off-diagonal excitations about\na semiclassical eigenvalue background. We find emergent geometry at strong\ncoupling in models where a mass term regulates an infrared divergence. We also\nshow that our notion of emergent geometry can be usefully applied to fuzzy\nspheres. Although most of our results are analytic, we have found numerical\ninput valuable in guiding and checking our results. \n\n"}
{"id": "0806.1117", "contents": "Title: Nonholonomic Constraints: a New Viewpoint Abstract: The purpose of this paper is to show that, at least for Lagrangians of\nmechanical type, nonholonomic Euler-Lagrange equations for a nonholonomic\nlinear constraint D may be viewed as non-constrained Euler-Lagrange equations\nbut on a new (generally not Lie) algebroid structure on D. The proposed novel\nformalism allows us to treat in a unified way a variety of situations in\nnonholonomic mechanics and gives rise to a version of Neoether Theorem\nproducing actual first integrals in case of symmetries. \n\n"}
{"id": "0806.4506", "contents": "Title: Geometric extension of put-call symmetry in the multiasset setting Abstract: In this paper we show how to relate European call and put options on multiple\nassets to certain convex bodies called lift zonoids. Based on this, geometric\nproperties can be translated into economic statements and vice versa. For\ninstance, the European call-put parity corresponds to the central symmetry\nproperty, while the concept of dual markets can be explained by reflection with\nrespect to a plane. It is known that the classical univariate log-normal model\nbelongs to a large class of distributions with an extra property, analytically\nknown as put-call symmetry. The geometric interpretation of this symmetry\nproperty motivates a natural multivariate extension. The financial meaning of\nthis extension is explained, the asset price distributions that have this\nproperty are characterised and their further properties explored. It is also\nshown how to relate some multivariate asymmetric distributions to symmetric\nones by a power transformation that is useful to adjust for carrying costs. A\nparticular attention is devoted to the case of asset prices driven by L\\'evy\nprocesses. Based on this, semi-static hedging techniques for multiasset barrier\noptions are suggested. \n\n"}
{"id": "0806.4626", "contents": "Title: Realistic Hybrid Inflation in 5D Orbifold SO(10) GUT Abstract: We discuss the smooth hybrid inflation scenario in the context of a simple\nsupersymmetric SO(10) GUT in 5D orbifold. In this GUT model, the SO(10) gauge\nsymmetry is broken down to the Pati-Salam (PS) gauge group, SU(4)$_c \\times$\nSU(2)$_L \\times$ SU(2)$_R$, by orbifold boundary conditions and all matter and\nHiggs multiplets are placed only on the brane (PS brane) where only the PS\nsymmetry is manifest. Further breaking of the Pati-Salam group to the Standard\nModel one is realized by VEVs of the Higgs multiplets $({\\bf 4},{\\bf 1},{\\bf\n2}) \\oplus (\\overline{{\\bf 4}},{\\bf 1},{\\bf 2})$. The gauge coupling\nunification is successfully realized at $M_{\\rm GUT} =4.6 \\times 10^{17}$ GeV\nafter incorporating the threshold corrections of the Kaluza-Klein modes, with\nthe compactification scale (assumed to be the same as the PS symmetry breaking\nscale) $M_c = v_{\\rm PS}= 1.2 \\times 10^{16}$ GeV. We show that this orbifold\nGUT model can naturally leads us to the smooth hybrid inflation, which tunes\nout to be consistent with the WMAP 5-year data with the predicted $M_{\\rm GUT}$\nand $v_{PS}$ in the model. \n\n"}
{"id": "0807.3745", "contents": "Title: Fine-tuning criteria for inflation and the search for primordial\n  gravitational waves Abstract: We revisit arguments that simple models of inflation with a small red tilt in\nthe scalar power spectrum generically yield an observable tensor spectrum. We\nshow that criteria for fine-tuning based upon the algebraic simplicity of the\npotential depend strongly upon the explicit assumptions they incorporate,\nparticularly regarding the end of inflation. In addition, some models with\nalgebraically simple potentials require carefully tuned initial field\nconfigurations, and not all types of fine-tuning are identifiable via the\nalgebraic simplicity of the potential. Conversely, in the absence of a strong\nprior on the mechanism that ends inflation, we demonstrate the existence of\npotentials with vanishingly small tensor amplitudes which are natural in terms\nof both their algebraic form and initial conditions. We thus argue that\nproposed experiments (CMBPol or BBO) which make highly sensitive measurements\nof the tensor amplitude cannot definitively rule out the inflationary paradigm. \n\n"}
{"id": "0808.0501", "contents": "Title: I-V curves of Fe/MgO (001) single- and double-barrier tunnel junctions Abstract: In this work, we calculate with ab initio methods the current-voltage\ncharacteristics for ideal single- and double-barrier Fe/MgO (001) magnetic\ntunnel junctions. The current is calculated in the phase-coherent limit by\nusing the recently developed SMEAGOL code, combining the nonequilibrium Green\nfunction formalism with density-functional theory. In general we find that\ndouble-barrier junctions display a larger magnetoresistance, which decays with\nbias at a slower pace than their single-barrier counterparts. This is explained\nin terms of enhanced spin filtering from the middle Fe layer sandwiched in\nbetween the two MgO barriers. In addition, for double-barrier tunnel junctions,\nwe find a well defined peak in the magnetoresistance at a voltage of V=0.1 V.\nThis is the signature of resonant tunneling across a majority quantum well\nstate. Our findings are discussed in relation to recent experiments. \n\n"}
{"id": "0808.1628", "contents": "Title: Doubly special relativity and translation invariance Abstract: We propose a new interpretation of doubly special relativity (DSR) based on\nthe distinction between the momentum and the translation generators in its\nphase space realization. We also argue that the implementation of DSR theories\ndoes not necessarily require a deformation of the Lorentz symmetry, but only of\nthe translation invariance. \n\n"}
{"id": "0809.0301", "contents": "Title: Esscher transform and the duality principle for multidimensional\n  semimartingales Abstract: The duality principle in option pricing aims at simplifying valuation\nproblems that depend on several variables by associating them to the\ncorresponding dual option pricing problem. Here, we analyze the duality\nprinciple for options that depend on several assets. The asset price processes\nare driven by general semimartingales, and the dual measures are constructed\nvia an Esscher transformation. As an application, we can relate swap and quanto\noptions to standard call and put options. Explicit calculations for jump models\nare also provided. \n\n"}
{"id": "0809.3060", "contents": "Title: Non-Gibrat's law in the middle scale region Abstract: By using numerical simulation, we confirm that Takayasu--Sato--Takayasu (TST)\nmodel which leads Pareto's law satisfies the detailed balance under Gibrat's\nlaw. In the simulation, we take an exponential tent-shaped function as the\ngrowth rate distribution. We also numerically confirm the reflection law\nequivalent to the equation which gives the Pareto index $\\mu$ in TST model.\nMoreover, we extend the model modifying the stochastic coefficient under a\nNon-Gibrat's law. In this model, the detailed balance is also numerically\nobserved. The resultant pdf is power-law in the large scale Gibrat's law\nregion, and is the log-normal distribution in the middle scale Non-Gibrat's\none. These are accurately confirmed in the numerical simulation. \n\n"}
{"id": "0809.3534", "contents": "Title: Comparing Absolute and relative Gromov--Witten invariants Abstract: This note compares the usual (absolute) Gromov-Witten invariants of a\nsymplectic manifold with the invariants that count the curves relative to a\n(symplectic) divisor D. We give explicit examples where these invariants differ\neven though it seems at first that they should agree, for example when counting\ngenus zero curves in a class \\be such that \\be\\cdot D=0. The main tool is the\ndecomposition formula in the form developed by A. Li--Ruan. \n\n"}
{"id": "0809.4728", "contents": "Title: Emergent Spacetime and The Origin of Gravity Abstract: We present an exposition on the geometrization of the electromagnetic force.\nWe show that, in noncommutative (NC) spacetime, there always exists a\ncoordinate transformation to locally eliminate the electromagnetic force, which\nis precisely the Darboux theorem in symplectic geometry. As a consequence, the\nelectromagnetism can be realized as a geometrical property of spacetime like\ngravity. We show that the geometrization of the electromagnetic force in NC\nspacetime is the origin of gravity, dubbed as the emergent gravity. We discuss\nhow the emergent gravity reveals a novel, radically different picture about the\norigin of spacetime. In particular, the emergent gravity naturally explains the\ndynamical origin of flat spacetime, which is absent in Einstein gravity. This\nspacetime picture turns out to be crucial for a tenable solution of the\ncosmological constant problem. \n\n"}
{"id": "0809.4816", "contents": "Title: Doping evoluton of antiferromagnetic order and structural distortion in\n  LaFeAsO$_{1-x}$F$_x$ Abstract: We use neutron scattering to study the structural distortion and\nantiferromagnetic (AFM) order in LaFeAsO$_{1-x}$F$_{x}$ as the system is doped\nwith fluorine (F) to induce superconductivity. In the undoped state, LaFeAsO\nexhibits a structural distortion, changing the symmetry from tetragonal (space\ngroup $P4/nmm$) to orthorhombic (space group $Cmma$) at 155 K, and then\nfollowed by an AFM order at 137 K. Doping the system with F gradually decreases\nthe structural distortion temperature, but suppresses the long range AFM order\nbefore the emergence of superconductivity. Therefore, while superconductivity\nin these Fe oxypnictides can survive in either the tetragonal or the\northorhombic crystal structure, it competes directly with static AFM order. \n\n"}
{"id": "0810.0055", "contents": "Title: Comparisons for backward stochastic differential equations on Markov\n  chains and related no-arbitrage conditions Abstract: Most previous contributions to BSDEs, and the related theories of nonlinear\nexpectation and dynamic risk measures, have been in the framework of continuous\ntime diffusions or jump diffusions. Using solutions of BSDEs on spaces related\nto finite state, continuous time Markov chains, we develop a theory of\nnonlinear expectations in the spirit of [Dynamically consistent nonlinear\nevaluations and expectations (2005) Shandong Univ.]. We prove basic properties\nof these expectations and show their applications to dynamic risk measures on\nsuch spaces. In particular, we prove comparison theorems for scalar and vector\nvalued solutions to BSDEs, and discuss arbitrage and risk measures in the\nscalar case. \n\n"}
{"id": "0810.4313", "contents": "Title: Light Higgs Boson Production in Two Higgs Doublets Models type III Abstract: By using the Cheng, Sher and Yuan's anzats, we study the light Higgs Boson\nproduction associated with $b$ quark production at TEVATRON using the 2HDM type\nIII.\n  We compare the simulations with experimental results coming from TEVATRON,\nfinding valid ranges for the $bb$ coupling. By using these results, we\ncalculate the cross section for the process $pp \\to b\\bar bh(b\\bar b)$ for the\nLHC collider. \n\n"}
{"id": "0811.0213", "contents": "Title: New approach to the Parton Distribution Functions: Self-Organizing Maps Abstract: We propose a Parton Distribution Function (PDF) fitting technique which is\nbased on an interactive neural network algorithm using Self-Organizing Maps\n(SOMs). SOMs are visualization algorithms based on competitive learning among\nspatially-ordered neurons. Our SOMs are trained with stochastically generated\nPDF samples. On every optimization iteration the PDFs are clustered on the SOM\naccording to a user-defined feature and the most promising candidates are\nselected as a seed for the subsequent iteration. Our main goal is thus to\nprovide a fitting procedure that, at variance with the global analyses and\nstandard neural network approaches, allows for an increased control of the\nsystematic bias by enabling user interaction in the various stages of the\nfitting process. \n\n"}
{"id": "0811.3056", "contents": "Title: Monopoles and Modifications of Bundles over Elliptic Curves Abstract: Modifications of bundles over complex curves is an operation that allows one\nto construct a new bundle from a given one. Modifications can change a\ntopological type of bundle. We describe the topological type in terms of the\ncharacteristic classes of the bundle. Being applied to the Higgs bundles\nmodifications establish an equivalence between different classical integrable\nsystems. Following Kapustin and Witten we define the modifications in terms of\nmonopole solutions of the Bogomolny equation. We find the Dirac monopole\nsolution in the case $R $\\times$ (elliptic curve). This solution is a\nthree-dimensional generalization of the Kronecker series. We give two\nrepresentations for this solution and derive a functional equation for it\ngeneralizing the Kronecker results. We use it to define Abelian modifications\nfor bundles of arbitrary rank. We also describe non-Abelian modifications in\nterms of theta-functions with characteristic. \n\n"}
{"id": "0811.4501", "contents": "Title: Two-Dimensional Dilaton Gravity and Toda - Liouville Integrable Models Abstract: General properties of a class of two-dimensional dilaton gravity (DG)\ntheories with multi-exponential potentials are studied and a subclass of these\ntheories, in which the equations of motion reduce to Toda and Liouville\nequations, is treated in detail. A combination of parameters of the equations\nshould satisfy a certain constraint that is identified and solved for the\ngeneral multi-exponential model. From the constraint it follows that in DG\ntheories the integrable Toda equations, generally, cannot appear without\naccompanying Liouville equations.\n  We also show how the wave-like solutions of the general Toda-Liouville\nsystems can be simply derived. In the dilaton gravity theory, these solutions\ndescribe nonlinear waves coupled to gravity as well as static states and\ncosmologies. A special attention is paid to making the analytic structure of\nthe solutions of the Toda equations as simple and transparent as possible, with\nthe aim to gain a better understanding of realistic theories reduced to\ndimensions 1+1 and 1+0 or 0+1. \n\n"}
{"id": "0812.0200", "contents": "Title: Spherical Collapse and Cluster Counts in Modified Gravity Models Abstract: Modifications to the gravitational potential affect the nonlinear\ngravitational evolution of large scale structures in the Universe. To\nillustrate some generic features of such changes, we study the evolution of\nspherically symmetric perturbations when the modification is of Yukawa type;\nthis is non-trivial, because we should not and do not assume that Birkhoff's\ntheorem applies. We then show how to estimate the abundance of virialized\nobjects in such models. Comparison with numerical simulations shows reasonable\nagreement: When normalized to have the same fluctuations at early times, weaker\nlarge scale gravity produces fewer massive halos. However, the opposite can be\ntrue for models that are normalized to have the same linear theory power\nspectrum today, so the abundance of rich clusters potentially places\ninteresting constraints on such models. Our analysis also indicates that the\nformation histories and abundances of sufficiently low mass objects are\nunchanged from standard gravity. This explains why simulations have found that\nthe nonlinear power-spectrum at large k is unaffected by such modifications to\nthe gravitational potential. In addition, the most massive objects in\nCMB-normalized models with weaker gravity are expected to be similar to the\nhigh-redshift progenitors of the most massive objects in models with stronger\ngravity. Thus, the difference between the cluster and field galaxy populations\nis expected to be larger in models with stronger large-scale gravity. \n\n"}
{"id": "0812.1902", "contents": "Title: Evaluation of neutrino masses from $m_{\\beta\\beta}$ values Abstract: A neutrino mass matrix is considered under conditions of a CP invariance and\na small reactor mixing $\\theta_{13}$ angle. Absolute mass values for three\nneutrinos are evaluated for normal and inverted hierarchy spectra on the ground\nof data for oscillation mixing neutrino parameters and an effective neutrino\nmass $m_{\\beta\\beta}$ related to a probability of neutrinoless two beta decay. \n\n"}
{"id": "0812.3819", "contents": "Title: Quantum ground-state cooling and tripartite entanglement with three-mode\n  optoacoustic interactions Abstract: We present a quantum analysis of three-mode optoacoustic parametric\ninteractions in an optical cavity, in which two orthogonal transverse\noptical-cavity modes are coupled to one acoustic mode through radiation\npressure. Due to the optimal frequency matching -- the frequency separation of\ntwo cavity modes is equal to the acoustic-mode frequency -- the carrier and\nsideband fields simultaneously resonate and coherently build up. This mechanism\nsignificantly enhances the optoacoustic couplings in the quantum regime. It\nallows exploration of quantum behavior of optoacoustic interactions in\nsmall-scale table-top experiments. We show explicitly that given an\nexperimentally achievable parameter, three-mode scheme can realize quantum\nground-state cooling of milligram scale mechanical oscillators and create\nrobust stationary tripartite optoacoustic quantum entanglements. \n\n"}
{"id": "0812.4352", "contents": "Title: Multipole Representation of the Fermi Operator with Application to the\n  Electronic Structure Analysis of Metallic Systems Abstract: We propose a multipole representation of the Fermi-Dirac function and the\nFermi operator, and use this representation to develop algorithms for\nelectronic structure analysis of metallic systems. The new algorithm is quite\nsimple and efficient. Its computational cost scales logarithmically with\n$\\beta\\Delta\\eps$ where $\\beta$ is the inverse temperature, and $\\Delta \\eps$\nis the width of the spectrum of the discretized Hamiltonian matrix. \n\n"}
{"id": "0901.0638", "contents": "Title: Quantile Mechanics II: Changes of Variables in Monte Carlo methods and\n  GPU-Optimized Normal Quantiles Abstract: This article presents differential equations and solution methods for the\nfunctions of the form $Q(x) = F^{-1}(G(x))$, where $F$ and $G$ are cumulative\ndistribution functions. Such functions allow the direct recycling of Monte\nCarlo samples from one distribution into samples from another. The method may\nbe developed analytically for certain special cases, and illuminate the idea\nthat it is a more precise form of the traditional Cornish-Fisher expansion. In\nthis manner the model risk of distributional risk may be assessed free of the\nMonte Carlo noise associated with resampling. Examples are given of equations\nfor converting normal samples to Student t, and converting exponential to\nhyperbolic, variance gamma and normal. In the case of the normal distribution,\nthe change of variables employed allows the sampling to take place to good\naccuracy based on a single rational approximation over a very wide range of the\nsample space. The avoidance of any branching statement is of use in optimal GPU\ncomputations as it avoids the effect of {\\it warp divergence}, and we give\nexamples of branch-free normal quantiles that offer performance improvements in\na GPU environment, while retaining the best precision characteristics of\nwell-known methods. We also offer models based on a low-probability of warp\ndivergence. Comparisons of new and old forms are made on the Nvidia Quadro\n4000, GTX 285 and 480, and Tesla C2050 GPUs. We argue that in single-precision\nmode, the change-of-variables approach offers performance competitive with the\nfastest existing scheme while substantially improving precision, and that in\ndouble-precision mode, this approach offers the most GPU-optimal Gaussian\nquantile yet, and without compromise on precision for Monte Carlo applications,\nworking twice as fast as the CUDA 4 library function with increased precision. \n\n"}
{"id": "0902.0078", "contents": "Title: Update on the quantum properties of the Supermembrane Abstract: In this note we summarize some of the quantum properties found since the\nearly 80's until nowdays that characterize at quantum level the spectrum of the\nsupermembrane. In particular we will focus on a topological sector of the 11D\nsupermembrane that, contrary to the general case, has a purely discrete\nspectrum at supersymmetric level. This construction has been consistently\nimplemented in different types of backgrounds: toroidal and orbifold-type with\nG2 structure able to lead to a true G2 compactification manifold. This theory\nhas N=1 supersymmetries in 4D. comment on the relevant points of this\nconstruction as well as on its spectral characteristics. We will also make some\ncomments on the quantum properties of some effective formulation of multiple\nM2's theories recently found. \n\n"}
{"id": "0902.2032", "contents": "Title: Some Paradoxes in Special Relativity Abstract: The special theory of relativity is the foundation of modern physics, but its\nunusual postulate of invariant vacuum speed of light results in a number of\nplausible paradoxes. This situation leads to radical criticisms and suspicions\nagainst the theory of relativity. In this paper, from the perspective that the\nrelativity is nothing but a geometry, we give a uniform resolution to some\nfamous and typical paradoxes such as the ladder paradox, the Ehrenfest's\nrotational disc paradox. The discussion shows that all the paradoxes are caused\nby misinterpretation of concepts. We misused the global simultaneity and the\nprinciple of relativity. As a geometry of Minkowski space-time, special\nrelativity can never result in a logical contradiction. \n\n"}
{"id": "0902.3034", "contents": "Title: Quantum theory of optical temporal phase and instantaneous frequency.\n  II. Continuous time limit and state-variable approach to phase-locked loop\n  design Abstract: We consider the continuous-time version of our recently proposed quantum\ntheory of optical temporal phase and instantaneous frequency [Tsang, Shapiro,\nand Lloyd, Phys. Rev. A 78, 053820 (2008)]. Using a state-variable approach to\nestimation, we design homodyne phase-locked loops that can measure the temporal\nphase with quantum-limited accuracy. We show that post-processing can further\nimprove the estimation performance, if delay is allowed in the estimation. We\nalso investigate the fundamental uncertainties in the simultaneous estimation\nof harmonic-oscillator position and momentum via continuous optical phase\nmeasurements from the classical estimation theory perspective. In the case of\ndelayed estimation, we find that the inferred uncertainty product can drop\nbelow that allowed by the Heisenberg uncertainty relation. Although this result\nseems counter-intuitive, we argue that it does not violate any basic principle\nof quantum mechanics. \n\n"}
{"id": "0903.1115", "contents": "Title: Fine tuning as an indication of physics beyond the MSSM Abstract: We investigate the amount of fine tuning of the electroweak scale in the\npresence of new physics beyond the MSSM, parametrized by higher dimensional\noperators. We show that these significantly reduce the MSSM fine tuning to\nDelta<10 for a Higgs mass between the LEPII bound and 130 GeV, and a\ncorresponding scale M_* of new physics as high as 30 to 65 times the Higgsino\nmass. If the fine-tuning criterion is indeed of physical relevance, the\nfindings indicate the presence of new physics in the form of new states of mass\nof O(M_*) that generated the effective operators in the first instance. At\nsmall $\\tan\\beta$ these states can be a gauge singlet or a SU(2) triplet. We\nderive analytical results for the EW scale fine-tuning for the MSSM with higher\ndimensional operators, including the quantum corrections which are also\napplicable to the pure MSSM case in the limit the coefficients of the higher\ndimension operators vanish. A general expression for the fine-tuning is also\nobtained for an arbitrary two-Higgs doublet potential. \n\n"}
{"id": "0903.1592", "contents": "Title: Monte Carlo sampling given a Characteristic Function: Quantile Mechanics\n  in Momentum Space Abstract: In mathematical finance and other applications of stochastic processes, it is\nfrequently the case that the characteristic function may be known but explicit\nforms for density functions are not available. The simulation of any\ndistribution is greatly facilitated by a knowledge of the quantile function, by\nwhich uniformly distributed samples may be converted to samples of the given\ndistribution. This article analyzes the calculation of a quantile function\ndirect from the characteristic function of a probability distribution, without\nexplicit knowledge of the density. We form a non-linear integro-differential\nequation that despite its complexity admits an iterative solution for the power\nseries of the quantile about the median. We give some examples including tail\nmodels and show how to generate C-code for examples. \n\n"}
{"id": "0903.1629", "contents": "Title: Spectral densities of Wishart-Levy free stable random matrices:\n  Analytical results and Monte Carlo validation Abstract: Random matrix theory is used to assess the significance of weak correlations\nand is well established for Gaussian statistics. However, many complex systems,\nwith stock markets as a prominent example, exhibit statistics with power-law\ntails, that can be modelled with Levy stable distributions. We review\ncomprehensively the derivation of an analytical expression for the spectra of\ncovariance matrices approximated by free Levy stable random variables and\nvalidate it by Monte Carlo simulation. \n\n"}
{"id": "0903.1945", "contents": "Title: Hessian and concavity of mutual information, differential entropy, and\n  entropy power in linear vector Gaussian channels Abstract: Within the framework of linear vector Gaussian channels with arbitrary\nsignaling, closed-form expressions for the Jacobian of the minimum mean square\nerror and Fisher information matrices with respect to arbitrary parameters of\nthe system are calculated in this paper. Capitalizing on prior research where\nthe minimum mean square error and Fisher information matrices were linked to\ninformation-theoretic quantities through differentiation, closed-form\nexpressions for the Hessian of the mutual information and the differential\nentropy are derived. These expressions are then used to assess the concavity\nproperties of mutual information and differential entropy under different\nchannel conditions and also to derive a multivariate version of the entropy\npower inequality due to Costa. \n\n"}
{"id": "0903.2390", "contents": "Title: Two-Phase Galaxy Formation Abstract: We propose and test a scenario for the assembly and evolution of luminous\nmatter in galaxies which substantially differs from that adopted by other\nsemianalytic models. As for the dark matter (DM), we follow the detailed\nevolution of halos within the canonical LCDM cosmology using standard\nMontecarlo methods. However, when overlaying prescriptions for baryon\nevolution, we take into account an effect pointed out in the past few years by\na number of studies mostly based on intensive N-body simulations, namely that\ntypical halo growth occurs in two phases: an early, fast collapse phase\nfeaturing several major merger events, followed by a late, quiescent accretion\nonto the halo outskirts. We propose that the two modes of halo growth drive two\ndistinct modes for the evolution of baryonic matter, favoring the development\nof the spheroidal and disc components of galaxies, respectively. We test this\nidea using the semianalytic technique. Our galaxy formation model envisages an\nearly coevolution of spheroids and the central supermassive black holes,\nalready tested in our previous works, followed by a relatively quiescent growth\nof discs around the preformed spheroids. In this exploratory study, we couple\nour model to the spectrophotometric code GRASIL, and compare our results on\nseveral properties of the local galaxy population with observations, Finding an\nencouraging agreement. \n\n"}
{"id": "0904.0624", "contents": "Title: A new approach for scenario generation in Risk management Abstract: We provide a new dynamic approach to scenario generation for the purposes of\nrisk management in the banking industry. We connect ideas from conventional\ntechniques -- like historical and Monte Carlo simulation -- and we come up with\na hybrid method that shares the advantages of standard procedures but\neliminates several of their drawbacks. Instead of considering the static\nproblem of constructing one or ten day ahead distributions for vectors of risk\nfactors, we embed the problem into a dynamic framework, where any time horizon\ncan be consistently simulated. Additionally, we use standard models from\nmathematical finance for each risk factor, whence bridging the worlds of\ntrading and risk management.\n  Our approach is based on stochastic differential equations (SDEs), like the\nHJM-equation or the Black-Scholes equation, governing the time evolution of\nrisk factors, on an empirical calibration method to the market for the chosen\nSDEs, and on an Euler scheme (or high-order schemes) for the numerical\nevaluation of the respective SDEs. The empirical calibration procedure\npresented in this paper can be seen as the SDE-counterpart of the so called\nFiltered Historical Simulation method; the behavior of volatility stems in our\ncase out of the assumptions on the underlying SDEs. Furthermore, we are able to\neasily incorporate \"middle-size\" and \"large-size\" events within our framework\nalways making a precise distinction between the information obtained from the\nmarket and the one coming from the necessary a-priori intuition of the risk\nmanager.\n  Results of one concrete implementation are provided. \n\n"}
{"id": "0904.1372", "contents": "Title: The Analytic Continuation of the Lippmann-Schwinger Eigenfunctions, and\n  Antiunitary Symmetries Abstract: We review the way to analytically continue the Lippmann-Schwinger bras and\nkets into the complex plane. We will see that a naive analytic continuation\nleads to nonsensical results in resonance theory, and we will explain how the\nnon-obvious but correct analytical continuation is done. We will see that the\nphysical basis for the non-obvious but correct analytic continuation lies in\nthe invariance of the Hamiltonian under anti-unitary symmetries such as time\nreversal or PT. \n\n"}
{"id": "0904.1918", "contents": "Title: Dynamical coupled-channels analysis of 1H(e,e'pi)N reactions Abstract: We have performed a dynamical coupled-channels analysis of available\np(e,e'pi)N data in the region of W < 1.6 GeV and Q^2 < 1.45 (GeV/c)^2. The\nchannels included are gamma^* N, pi N, eta N, and pi pi N which has pi Delta,\nrho N, and sigma N components. With the hadronic parameters of the model\ndetermined in our previous investigations of pi N --> pi N, pi pi N reactions,\nwe have found that the available data in the considered W < 1.6 GeV region can\nbe fitted well by only adjusting the bare gamma^* N --> N^* helicity amplitudes\nfor the lowest N^* states in P33, P11, S11 and D13 partial waves. The\nsensitivity of the resulting parameters to the amount of data included in the\nanalysis is investigated. The importance of coupled-channels effect on the\np(e,e' pi)N cross sections is demonstrated. The meson cloud effects, as\nrequired by the unitarity conditions, on the gamma^* N --> N^* form factors are\nalso examined. Necessary future developments, both experimentally and\ntheoretically, are discussed. \n\n"}
{"id": "0904.4074", "contents": "Title: Dynamic operational risk: modeling dependence and combining different\n  sources of information Abstract: In this paper, we model dependence between operational risks by allowing risk\nprofiles to evolve stochastically in time and to be dependent. This allows for\na flexible correlation structure where the dependence between frequencies of\ndifferent risk categories and between severities of different risk categories\nas well as within risk categories can be modeled. The model is estimated using\nBayesian inference methodology, allowing for combination of internal data,\nexternal data and expert opinion in the estimation procedure. We use a\nspecialized Markov chain Monte Carlo simulation methodology known as Slice\nsampling to obtain samples from the resulting posterior distribution and\nestimate the model parameters. \n\n"}
{"id": "0905.0582", "contents": "Title: Empirical regularities of opening call auction in Chinese stock market Abstract: We study the statistical regularities of opening call auction using the\nultra-high-frequency data of 22 liquid stocks traded on the Shenzhen Stock\nExchange in 2003. The distribution of the relative price, defined as the\nrelative difference between the order price in opening call auction and the\nclosing price of last trading day, is asymmetric and that the distribution\ndisplays a sharp peak at zero relative price and a relatively wide peak at\nnegative relative price. The detrended fluctuation analysis (DFA) method is\nadopted to investigate the long-term memory of relative order prices. We\nfurther study the statistical regularities of order sizes in opening call\nauction, and observe a phenomenon of number preference, known as order size\nclustering. The probability density function (PDF) of order sizes could be well\nfitted by a $q$-Gamma function, and the long-term memory also exists in order\nsizes. In addition, both the average volume and the average number of orders\ndecrease exponentially with the price level away from the best bid or ask price\nlevel in the limit-order book (LOB) established immediately after the opening\ncall auction, and a price clustering phenomenon is observed. \n\n"}
{"id": "0905.0781", "contents": "Title: Variance-covariance based risk allocation in credit portfolios:\n  analytical approximation Abstract: High precision analytical approximation is proposed for variance-covariance\nbased risk allocation in a portfolio of risky assets. A general case of a\nsingle-period multi-factor Merton-type model with stochastic recovery is\nconsidered. The accuracy of the approximation as well as its speed are compared\nto and shown to be superior to those of Monte Carlo simulation. \n\n"}
{"id": "0906.0471", "contents": "Title: Cross-Sections of Large-Angle Hadron Production in Proton- and\n  Pion-Nucleus Interactions III: Tantalum Nuclei and Beam Momenta from +/-3\n  Gev/c to +/-15 Gev/c Abstract: We report on double-differential inclusive cross-sections of the production\nof secondary protons, charged pions, and deuterons, in the interactions with a\n5% nuclear interaction length thick stationary tantalum target, of proton and\npion beams with momentum from +/-3 GeV/c to +/-15 GeV/c. Results are given for\nsecondary particles with production angles between 20 and 125 degrees. They are\nof particular relevance for the optimization of the design parameters of the\nproton driver of a neutrino factory. \n\n"}
{"id": "0906.2474", "contents": "Title: A comprehensive approach to new physics simulations Abstract: We describe a framework to develop, implement and validate any perturbative\nLagrangian-based particle physics model for further theoretical,\nphenomenological and experimental studies. The starting point is FeynRules, a\nMathematica package that allows to generate Feynman rules for any Lagrangian\nand then, through dedicated interfaces, automatically pass the corresponding\nrelevant information to any supported Monte Carlo event generator. We prove the\npower, robustness and flexibility of this approach by presenting a few examples\nof new physics models (the Hidden Abelian Higgs Model, the general\nTwo-Higgs-Doublet Model, the most general Minimal Supersymmetric Standard\nModel, the Minimal Higgsless Model, Universal and Large Extra Dimensions, and\nQCD-inspired effective Lagrangians) and their implementation/validation in\nFeynArts/FormCalc, CalcHep, MadGraph/MadEvent, and Sherpa. \n\n"}
{"id": "0906.4091", "contents": "Title: Dark Energy Regulation with Approximate Emergent Conformal Symmetry Abstract: A cosmic potential which can relax the vacuum energy is proposed in a\nframework of scalar-tensor gravity. In the phase of the gravity scalar field\naround the evolution with an approximate emergent conformal symmetry, we have\nobtained a set of cosmological equations with the dark energy regulated to the\norder of a conformal anomaly parameter. Through a role of the cosmic potential,\nthe vacuum energy which could be generated in matter Lagrangian does not\ncontribute to the dark energy in the phase. \n\n"}
{"id": "0906.4112", "contents": "Title: Gravity Dual for Reggeon Field Theory and Non-linear Quantum Finance Abstract: We study scale invariant but not necessarily conformal invariant deformations\nof non-relativistic conformal field theories from the dual gravity viewpoint.\nWe present the corresponding metric that solves the Einstein equation coupled\nwith a massive vector field. We find that, within the class of metric we study,\nwhen we assume the Galilean invariance, the scale invariant deformation always\npreserves the non-relativistic conformal invariance. We discuss applications to\nscaling regime of Reggeon field theory and non-linear quantum finance. These\ntheories possess scale invariance but may or may not break the conformal\ninvariance, depending on the underlying symmetry assumptions. \n\n"}
{"id": "0906.4456", "contents": "Title: Path integral approach to Asian options in the Black-Scholes model Abstract: We derive a closed-form solution for the price of an average price as well as\nan average strike geometric Asian option, by making use of the path integral\nformulation. Our results are compared to a numerical Monte Carlo simulation. We\nalso develop a pricing formula for an Asian option with a barrier on a control\nprocess, combining the method of images with a partitioning of the set of paths\naccording to the average along the path. This formula is exact when the\ncorrelation is zero, and is approximate when the correlation increases. \n\n"}
{"id": "0906.4853", "contents": "Title: Shaping tail dependencies by nesting box copulas Abstract: We introduce a family of copulas which are locally piecewise uniform in the\ninterior of the unit cube of any given dimension. Within that family, the\nsimultaneous control of tail dependencies of all projections to faces of the\ncube is possible and we give an efficient sampling algorithm. The combination\nof these two properties may be appealing to risk modellers. \n\n"}
{"id": "0906.5581", "contents": "Title: Strong Taylor approximation of stochastic differential equations and\n  application to the L\\'evy LIBOR model Abstract: In this article we develop a method for the strong approximation of\nstochastic differential equations (SDEs) driven by L\\'evy processes or general\nsemimartingales. The main ingredients of our method is the perturbation of the\nSDE and the Taylor expansion of the resulting parameterized curve. We apply\nthis method to develop strong approximation schemes for LIBOR market models. In\nparticular, we derive fast and precise algorithms for the valuation of\nderivatives in LIBOR models which are more tractable than the simulation of the\nfull SDE. A numerical example for the L\\'evy LIBOR model illustrates our\nmethod. \n\n"}
{"id": "0907.0980", "contents": "Title: Introduction to the multiple-quantum operator spaces Abstract: The multiple-quantum NMR spectroscopy has an extensive application in\ndetermination of the bio-macro-molecular structures and in the investigation of\nthe properties of a variety of physical materials. In quantum computation the\nmultiple-quantum transition processes have been used to construct the quantum\ncircuits, quantum algorithms, and quantum simulations. The multiple-quantum\noperator algebra spaces are closely related to the symmetries of a\nmultiple-spin quantum system. They may have an important effect on the\nmultiple-quantum transition processes and the multiple-quantum NMR spectroscopy\nof the spin system. Here gives a brief introduction to the multiple-quantum\noperator algebra spaces. \n\n"}
{"id": "0907.1221", "contents": "Title: Credit risk premia and quadratic BSDEs with a single jump Abstract: This paper is concerned with the determination of credit risk premia of\ndefaultable contingent claims by means of indifference valuation principles.\nAssuming exponential utility preferences we derive representations of\nindifference premia of credit risk in terms of solutions of Backward Stochastic\nDifferential Equations (BSDE). The class of BSDEs needed for that\nrepresentation allows for quadratic growth generators and jumps at random\ntimes. Since the existence and uniqueness theory for this class of BSDEs has\nnot yet been developed to the required generality, the first part of the paper\nis devoted to fill that gap. By using a simple constructive algorithm, and\nknown results on continuous quadratic BSDEs, we provide sufficient conditions\nfor the existence and uniqueness of quadratic BSDEs with discontinuities at\nrandom times. \n\n"}
{"id": "0907.2810", "contents": "Title: Anomalous magnetoresistance on the topological surface Abstract: We investigate charge transport in two-dimensional ferromagnet/feromagnet\njunction on a topological insulator. The conductance across the interface\ndepends sensitively on the directions of the magnetizations of the two\nferromagnets, showing anomalous behaviors compared with the conventional\nspin-valve. It is found that the conductance depends strongly on the in-plane\ndirection of the magnetization. Moreover, in sharp contrast to the conventional\nmagnetoresistance effect, in the p-n junction, the conductance at the parallel\nconfiguration is much smaller than that at the antiparallel configuration. This\nstems from the way how the wavefunctions connect between both sides. \n\n"}
{"id": "0907.3231", "contents": "Title: Phenomenology of minority games in efficient regime Abstract: We present a comprehensive study of utility function of the minority game in\nits efficient regime. We develop an effective description of state of the game.\nFor the payoff function $g(x)=\\sgn (x)$ we explicitly represent the game as the\nMarkov process and prove the finitness of number of states. We also demonstrate\nboundedness of the utility function. Using these facts we can explain all\ninteresting observable features of the aggregated demand: appearance of strong\nfluctuations, their periodicity and existence of prefered levels. For another\npayoff, $g(x)=x$, the number of states is still finite and utility remains\nbounded but the number of states cannot be reduced and probabilities of states\nare not calculated. However, using properties of the utility and analysing the\ngame in terms of de Bruijn graphs, we can also explain distinct peaks of demand\nand their frequencies. \n\n"}
{"id": "0907.5276", "contents": "Title: Bayesian Inference on QGARCH Model Using the Adaptive Construction\n  Scheme Abstract: We study the performance of the adaptive construction scheme for a Bayesian\ninference on the Quadratic GARCH model which introduces the asymmetry in time\nseries dynamics. In the adaptive construction scheme a proposal density in the\nMetropolis-Hastings algorithm is constructed adaptively by changing the\nparameters of the density to fit the posterior density. Using artificial QGARCH\ndata we infer the QGARCH parameters by applying the adaptive construction\nscheme to the Bayesian inference of QGARCH model. We find that the adaptive\nconstruction scheme samples QGARCH parameters effectively, i.e. correlations\nbetween the sampled data are very small. We conclude that the adaptive\nconstruction scheme is an efficient method to the Bayesian estimation of the\nQGARCH model. \n\n"}
{"id": "0908.1086", "contents": "Title: On the uniqueness of classical solutions of Cauchy problems Abstract: Given that the terminal condition is of at most linear growth, it is well\nknown that a Cauchy problem admits a unique classical solution when the\ncoefficient multiplying the second derivative (i.e., the volatility) is also a\nfunction of at most linear growth. In this note, we give a condition on the\nvolatility that is necessary and sufficient for a Cauchy problem to admit a\nunique solution. \n\n"}
{"id": "0908.2982", "contents": "Title: Bayesian inference with an adaptive proposal density for GARCH models Abstract: We perform the Bayesian inference of a GARCH model by the Metropolis-Hastings\nalgorithm with an adaptive proposal density. The adaptive proposal density is\nassumed to be the Student's t-distribution and the distribution parameters are\nevaluated by using the data sampled during the simulation. We apply the method\nfor the QGARCH model which is one of asymmetric GARCH models and make empirical\nstudies for for Nikkei 225, DAX and Hang indexes. We find that autocorrelation\ntimes from our method are very small, thus the method is very efficient for\ngenerating uncorrelated Monte Carlo data. The results from the QGARCH model\nshow that all the three indexes show the leverage effect, i.e. the volatility\nis high after negative observations. \n\n"}
{"id": "0908.3043", "contents": "Title: Gauge Invariance, Geometry and Arbitrage Abstract: In this work, we identify the most general measure of arbitrage for any\nmarket model governed by It\\^o processes. We show that our arbitrage measure is\ninvariant under changes of num\\'{e}raire and equivalent probability. Moreover,\nsuch measure has a geometrical interpretation as a gauge connection. The\nconnection has zero curvature if and only if there is no arbitrage. We prove an\nextension of the Martingale pricing theorem in the case of arbitrage. In our\ncase, the present value of any traded asset is given by the expectation of\nfuture cash-flows discounted by a line integral of the gauge connection. We\ndevelop simple strategies to measure arbitrage using both simulated and real\nmarket data. We find that, within our limited data sample, the market is\nefficient at time horizons of one day or longer. However, we provide strong\nevidence for non-zero arbitrage in high frequency intraday data. Such events\nseem to have a decay time of the order of one minute. \n\n"}
{"id": "0908.3987", "contents": "Title: Phase spaces of twisted Lie-algebraically deformed relativistic and\n  nonrelativistic symmetries Abstract: The twisted Lie-algebraically deformed relativistic and nonrelativistic phase\nspaces are constructed with the use of Heisenberg double procedure. The\ncorresponding Heisenberg uncertainty principles are discussed as well. \n\n"}
{"id": "0909.0065", "contents": "Title: Hybrid Atlas models Abstract: We study Atlas-type models of equity markets with local characteristics that\ndepend on both name and rank, and in ways that induce a stable capital\ndistribution. Ergodic properties and rankings of processes are examined with\nreference to the theory of reflected Brownian motions in polyhedral domains. In\nthe context of such models we discuss properties of various investment\nstrategies, including the so-called growth-optimal and universal portfolios. \n\n"}
{"id": "0909.1478", "contents": "Title: Markov Chain Monte Carlo on Asymmetric GARCH Model Using the Adaptive\n  Construction Scheme Abstract: We perform Markov chain Monte Carlo simulations for a Bayesian inference of\nthe GJR-GARCH model which is one of asymmetric GARCH models. The adaptive\nconstruction scheme is used for the construction of the proposal density in the\nMetropolis-Hastings algorithm and the parameters of the proposal density are\ndetermined adaptively by using the data sampled by the Markov chain Monte Carlo\nsimulation. We study the performance of the scheme with the artificial\nGJR-GARCH data. We find that the adaptive construction scheme samples GJR-GARCH\nparameters effectively and conclude that the Metropolis-Hastings algorithm with\nthe adaptive construction scheme is an efficient method to the Bayesian\ninference of the GJR-GARCH model. \n\n"}
{"id": "0909.2341", "contents": "Title: Generalized integrands and bond portfolios: Pitfalls and counter\n  examples Abstract: We construct Zero-Coupon Bond markets driven by a cylindrical Brownian motion\nin which the notion of generalized portfolio has important flaws: There exist\nbounded smooth random variables with generalized hedging portfolios for which\nthe price of their risky part is $+\\infty$ at each time. For these generalized\nportfolios, sequences of the prices of the risky part of approximating\nportfolios can be made to converges to any given extended real number in\n$[-\\infty,\\infty].$ \n\n"}
{"id": "0909.3266", "contents": "Title: Controlling the carrier concentration of the high temperature\n  superconductor Bi2Sr2CaCu2O{8+x} in Angle Resolved Photoemission Spectroscopy\n  (ARPES) experiments Abstract: We study the variation of the electronic properties at the surface of a high\ntemperature superconductor as a function of vacuum conditions in angle resolved\nphotoemission spectroscopy (ARPES) experiments. Normally, under less than ideal\nvacuum conditions the carrier concentration of Bi2Sr2CaCu2O{8+x} (Bi2212)\nincreases with time due to the absorption of oxygen from CO2 and CO molecules\nthat are prime contaminants present in ultra high vacuum (UHV) systems. We find\nthat in a high quality vacuum environment at low temperatures, the surface of\nBi2212 is quite stable (the carrier concentration remains constant), however at\nelevated temperatures the carrier concentration decreases due to the loss of\noxygen atoms from the Bi-O layer. These two effects can be used to control the\ncarrier concentration in-situ. Our finding opens the possibility of studying\nthe electronic properties of the cuprates as a function of doping across the\nphase diagram on the same piece of sample (i.e. with the same impurities and\ndefects). We envision that this method could be utilized in other surface\nsensitive techniques such as scanning tunneling microscopy/spectroscopy. \n\n"}
{"id": "0909.3570", "contents": "Title: On the rates of convergence of simulation based optimization algorithms\n  for optimal stopping problems Abstract: In this paper we study simulation based optimization algorithms for solving\ndiscrete time optimal stopping problems. This type of algorithms became popular\namong practioneers working in the area of quantitative finance. Using large\ndeviation theory for the increments of empirical processes, we derive optimal\nconvergence rates and show that they can not be improved in general. The rates\nderived provide a guide to the choice of the number of simulated paths needed\nin optimization step, which is crucial for the good performance of any\nsimulation based optimization algorithm. Finally, we present a numerical\nexample of solving optimal stopping problem arising in option pricing that\nillustrates our theoretical findings. \n\n"}
{"id": "0909.3978", "contents": "Title: A Generalized Fourier Transform Approach to Risk Measures Abstract: We introduce the formalism of generalized Fourier transforms in the context\nof risk management. We develop a general framework to efficiently compute the\nmost popular risk measures, Value-at-Risk and Expected Shortfall (also known as\nConditional Value-at-Risk). The only ingredient required by our approach is the\nknowledge of the characteristic function describing the financial data in use.\nThis allows to extend risk analysis to those non-Gaussian models defined in the\nFourier space, such as Levy noise driven processes and stochastic volatility\nmodels. We test our analytical results on data sets coming from various\nfinancial indexes, finding that our predictions outperform those provided by\nthe standard Log-Normal dynamics and are in remarkable agreement with those of\nthe benchmark historical approach. \n\n"}
{"id": "0909.4918", "contents": "Title: Quantization on space-like surfaces Abstract: We give a mathematical definition of dynamical evolution in quantum field\ntheory, including evolution on space-like surfaces, and show its relationship\nwith the axiomatic and perturbative approaches to QFT. \n\n"}
{"id": "0909.4948", "contents": "Title: Optimal Stopping for Dynamic Convex Risk Measures Abstract: We use martingale and stochastic analysis techniques to study a\ncontinuous-time optimal stopping problem, in which the decision maker uses a\ndynamic convex risk measure to evaluate future rewards. We also find a saddle\npoint for an equivalent zero-sum game of control and stopping, between an agent\n(the \"stopper\") who chooses the termination time of the game, and an agent (the\n\"controller\", or \"nature\") who selects the probability measure. \n\n"}
{"id": "0909.5436", "contents": "Title: Active Galaxies and the Study of Black Hole Demographics Abstract: We discuss the critical importance of black hole mass indicators based on\nscaling relations in active galaxies. We highlight outstanding uncertainties in\nthese methods and potential paths to substantial progress in the next decade. \n\n"}
{"id": "0910.1394", "contents": "Title: Statistical mixing and aggregation in Feller diffusion Abstract: We consider Feller mean-reverting square-root diffusion, which has been\napplied to model a wide variety of processes with linearly state-dependent\ndiffusion, such as stochastic volatility and interest rates in finance, and\nneuronal and populations dynamics in natural sciences. We focus on the\nstatistical mixing (or superstatistical) process in which the parameter related\nto the mean value can fluctuate - a plausible mechanism for the emergence of\nheavy-tailed distributions. We obtain analytical results for the associated\nprobability density function (both stationary and time dependent), its\ncorrelation structure and aggregation properties. Our results are applied to\nexplain the statistics of stock traded volume at different aggregation scales. \n\n"}
{"id": "0910.2091", "contents": "Title: BSDEs with random default time and their applications to default risk Abstract: In this paper we are concerned with backward stochastic differential\nequations with random default time and their applications to default risk. The\nequations are driven by Brownian motion as well as a mutually independent\nmartingale appearing in a defaultable setting. We show that these equations\nhave unique solutions and a comparison theorem for their solutions. As an\napplication, we get a saddle-point strategy for the related zero-sum stochastic\ndifferential game problem. \n\n"}
{"id": "0910.2309", "contents": "Title: Closed form asymptotics for local volatility models Abstract: We obtain new closed-form pricing formulas for contingent claims when the\nasset follows a Dupire-type local volatility model. To obtain the formulas we\nuse the Dyson-Taylor commutator method that we have recently developed in [5,\n6, 8] for short-time asymptotic expansions of heat kernels, and obtain a family\nof general closed-form approximate solutions for both the pricing kernel and\nderivative price. A bootstrap scheme allows us to extend our method to large\ntime. We also perform analytic as well as a numerical error analysis, and\ncompare our results to other known methods. \n\n"}
{"id": "0910.2696", "contents": "Title: Implied Multi-Factor Model for Bespoke CDO Tranches and other Portfolio\n  Credit Derivatives Abstract: This paper introduces a new semi-parametric approach to the pricing and risk\nmanagement of bespoke CDO tranches, with a particular attention to bespokes\nthat need to be mapped onto more than one reference portfolio. The only user\ninput in our framework is a multi-factor model (a \"prior\" model hereafter) for\nindex portfolios, such as CDX.NA.IG or iTraxx Europe, that are chosen as\nbenchmark securities for the pricing of a given bespoke CDO. Parameters of the\nprior model are fixed, and not tuned to match prices of benchmark index\ntranches. Instead, our calibration procedure amounts to a proper reweightening\nof the prior measure using the Minimum Cross Entropy method. As the latter\nproblem reduces to convex optimization in a low dimensional space, our model is\ncomputationally efficient. Both the static (one-period) and dynamic versions of\nthe model are presented. The latter can be used for pricing and risk management\nof more exotic instruments referencing bespoke portfolios, such as\nforward-starting tranches or tranche options, and for calculation of credit\nvaluation adjustment (CVA) for bespoke tranches. \n\n"}
{"id": "0910.2905", "contents": "Title: The lattice ghost propagator in Landau gauge up to three loops using\n  Numerical Stochastic Perturbation Theory Abstract: We complete our high-accuracy studies of the lattice ghost propagator in\nLandau gauge in Numerical Stochastic Perturbation Theory up to three loops. We\npresent a systematic strategy which allows to extract with sufficient precision\nthe non-logarithmic parts of logarithmically divergent quantities as a function\nof the propagator momentum squared in the infinite-volume and $a\\to 0$ limits.\nWe find accurate coincidence with the one-loop result for the ghost self-energy\nknown from standard Lattice Perturbation Theory and improve our previous\nestimate for the two-loop constant contribution to the ghost self-energy in\nLandau gauge. Our results for the perturbative ghost propagator are compared\nwith Monte Carlo measurements of the ghost propagator performed by the Berlin\nHumboldt university group which has used the exponential relation between\npotentials and gauge links. \n\n"}
{"id": "0910.4257", "contents": "Title: Obstacle problem for Arithmetic Asian options Abstract: We prove existence, regularity and a Feynman-Ka\\v{c} representation formula\nof the strong solution to the free boundary problem arising in the financial\nproblem of the pricing of the American Asian option with arithmetic average. \n\n"}
{"id": "0911.1775", "contents": "Title: Correlation-hole induced paired quantum Hall states in lowest Landau\n  level Abstract: A theory is developed for the paired even-denominator fractional quantum Hall\nstates in the lowest Landau level. We show that electrons bind to quantized\nvortices to form composite fermions, interacting through an exact instantaneous\ninteraction that favors chiral p-wave pairing. Two canonically dual pairing gap\nfunctions are related by the bosonic Laughlin wavefunction (Jastraw factor) due\nto the correlation holes. We find that the ground state is the Moore-Read\npfaffian in the long wavelength limit for weak Coulomb interactions, a new\npfaffian of an oscillatory pairing function for intermediate interactions, and\na Read-Rezayi composite Fermi liquid beyond a critical interaction strength.\nOur findings are consistent with recent experimental observations of the 1/2\nand 1/4 fractional quantum Hall effects in asymmetric wide quantum wells. \n\n"}
{"id": "0911.2580", "contents": "Title: Baryon Resonances Abstract: In this talk I show recent results on how many excited baryon resonances\nappear as systems of one meson and one baryon, or two mesons and one baryon,\nwith the mesons being either pseudoscalar or vectors. Connection with\nexperiment is made including a discussion on old predictions and recent results\nfor the photoproduction of the $\\Lambda(1405)$ resonance, as well as the\nprediction of one $1/2^+$ baryon state around 1920 MeV which might have been\nseen in the $\\gamma p \\to K^+ \\Lambda$ reaction. \n\n"}
{"id": "0911.2923", "contents": "Title: Okounkov bodies of filtered linear series Abstract: We associate to a filtration of a graded linear series of a big line bundle a\nconcave function on the Okounkov body whose law with respect to Lebesgue's\nmeasure describes the asymptotic distribution of the jumps of the filtration.\nAs a consequence we obtain a Fujita-type approximation theorem in this general\nfiltered setting. We then specialize these results to filtrations by minima in\nthe usual context of Arakelov geometry, thereby obtaining in a simple way a\nnatural construction of an arithmetic Okounkov body, the existence of the\narithmetic volume as a limit and the arithmetic Fujita approximation theorem\nfor adelically normed graded linear series. We also obtain by a variant of this\nconstruction a short proof of the existence of the sectional capacity. \n\n"}
{"id": "0911.4259", "contents": "Title: Financial rogue waves Abstract: The financial rogue waves are reported analytically in the nonlinear option\npricing model due to Ivancevic, which is nonlinear wave alternative of the\nBlack-Scholes model. These solutions may be used to describe the possible\nphysical mechanisms for rogue wave phenomenon in financial markets and related\nfields. \n\n"}
{"id": "0911.5273", "contents": "Title: Dirac gaugino as leptophilic dark matter Abstract: We investigate the leptophilic properties of Dirac gauginos in an\nR--symmetric N=2 supersymmetric model with extended gauge and Higgs sectors.\nThe annihilation of Dirac gauginos to leptons requires no chirality flip in the\nfinal states so that it is not suppressed as in the Majorana case. This implies\nthat it can be sizable enough to explain the positron excess observed by the\nPAMELA experiment with moderate or no boost factors. When squark masses are\nheavy, the annihilation of Dirac gauginos to hadrons is controlled by their\nHiggsino fraction and is driven by the $hZ$ and $W^+W^-$ final states.\nMoreover, at variance with the Majorana case, Dirac gauginos with a\nnon-vanishing higgsino fraction can also have a vector coupling with the $Z$\ngauge boson leading to a sizable spin--independent scattering cross section off\nnuclei. Saturating the current antiproton limit, we show that Dirac gauginos\ncan leave a signal in direct detection experiments at the level of the\nsensitivity of dark matter searches at present and in the near future. \n\n"}
{"id": "0912.0556", "contents": "Title: On Unitary Evolution in Quantum Field Theory in Curved Spacetime Abstract: We investigate the question of unitarity of evolution between hypersurfaces\nin quantum field theory in curved spacetime from the perspective of the general\nboundary formulation. Unitarity thus means unitarity of the quantum operator\nthat maps the state space associated with one hypersurface to the state space\nassociated with the other hypersurface. Working in Klein-Gordon theory, we find\nthat such an evolution is generically unitary given a one-to-one correspondence\nbetween classical solutions in neighborhoods of the respective hypersurfaces.\nThis covers the case of pairs of Cauchy hypersurfaces, but also certain cases\nwhere hypersurfaces are timelike. The tools we use are the Schroedinger\nrepresentation and the Feynman path integral. \n\n"}
{"id": "0912.1289", "contents": "Title: Sub-nanoscale Resolution for Atom Localization, Lithography and\n  Microscopy via Coherent Population Trapping Abstract: We present a coherent population trapping based scheme to attain\nsub-nanoscale resolution for atom localization, microscopy and lithography. Our\nmethod uses three-level atoms coupled to amplitude modulated probe field and\nspatially dependent drive field. The modulation of the probe field allows us to\ntap into the steep dispersion normally associated with electromagnetically\ninduced transparency and offers an avenue to attain sub-nanometer resolution\nusing just optical fields. We illustrate application of the techniques to the\narea of microscopy and lithography and show how multilevel schemes offer the\npossibility of improving resolution further. \n\n"}
{"id": "0912.1859", "contents": "Title: On the correlation between the X-ray and gamma-ray emission in TeV\n  blazars Abstract: The observations of TeV blazars published recently show an unexpected\nquadratic or even cubic correlation between the X-ray and gamma-ray emission. A\nstandard model of the synchrotron self-Compton emission of a compact source\ninside a jet is not able to explain such a correlation. Therefore, we propose\nan alternative scenario where the emission of at least two independent compact\ncomponents is observed at the same time.\n  We compare two different models. The first model assumes the injection of\nrelativistic particles into a downstream region of a shock wave inside a jet\nthat creates the emitting source. The model precisely describes the evolution\nof the particle energy spectrum inside the source and takes into account a\nlight-crossing time effect for the produced radiation. The second model assumes\nan intrinsically constant emission of a homogeneous source that travels inside\nthe jet along a curved trajectory, where the activity is produced simply by\ndifferent values of the source's Doppler factor. To verify the two models we\nuse recentlu published observations of Mrk 421.\n  Our simulations show that simultaneous radiation of at least two independent\nsources, where the first source dominates the emission in the X-ray range and\nthe second source radiates strongly in the gamma-ray range, can explain the\nobserved correlations. However, the injection model provides inadequate results\nbecause it gives different values for the correlation of the rise and decay of\na flare. This problem is negligible in the scenario that uses the Doppler\nboosting effect. Therefore, this approach yields much better results. \n\n"}
{"id": "0912.1879", "contents": "Title: The Opportunity Process for Optimal Consumption and Investment with\n  Power Utility Abstract: We study the utility maximization problem for power utility random fields in\na semimartingale financial market, with and without intermediate consumption.\nThe notion of an opportunity process is introduced as a reduced form of the\nvalue process of the resulting stochastic control problem. We show how the\nopportunity process describes the key objects: optimal strategy, value\nfunction, and dual problem. The results are applied to obtain monotonicity\nproperties of the optimal consumption. \n\n"}
{"id": "0912.2524", "contents": "Title: Nuclear physics from strong coupling QCD Abstract: The strong coupling limit (beta_gauge = 0) of QCD offers a number of\nremarkable research possibilities, of course at the price of large lattice\nartifacts. Here, we determine the complete phase diagram as a function of\ntemperature T and baryon chemical potential mu_B, for one flavor of staggered\nfermions in the chiral limit, with emphasis on the determination of a\ntricritical point and on the T ~ 0 transition to nuclear matter. The latter is\nknown to happen for mu_B substantially below the baryon mass, indicating strong\nnuclear interactions in QCD at infinite gauge coupling. This leads us to\nstudying the properties of nuclear matter from first principles. We determine\nthe nucleon-nucleon potential in the strong coupling limit, as well as masses\nm_A of nuclei as a function of their atomic number A. Finally, we clarify the\norigin of nuclear interactions at strong coupling, which turns out to be a\nsteric effect. \n\n"}
{"id": "0912.4685", "contents": "Title: Two new type surface polaritons excited into nanoholes in metal films Abstract: First, we argue that the smooth metal-air interface should be regarded as a\ndistinct dielectric medium, the skin of the metal. The existence of this metal\nskin leads to theoretical explanation of experimental data on the excitation of\nelectromagnetic surface shape resonances in lamellar metallic gratings by light\nin the visible to near-infrared range. Surface polaritons have been observed in\nreflection modes on metallized gratings where the electric field is highly\nlocalized inside the grooves (around 300-1000 times larger than intensity of\nincoming optical light). Here we present quantized Maxwell's equations for\nelectromagnetic field in an isotropic homogeneous medium, allowing us to solve\nthe absorption anomaly property of these metal films. The results imply the\nexistence of light boson particles with spin one and effective mass $m=\n2.5\\cdot 10^{-5} m_e$. We also show the presence of two new type surface\npolaritons into nanoholes in metal films. \n\n"}
{"id": "1001.0401", "contents": "Title: Numerical simulation of BSDEs with drivers of quadratic growth Abstract: This article deals with the numerical resolution of Markovian backward\nstochastic differential equations (BSDEs) with drivers of quadratic growth with\nrespect to $z$ and bounded terminal conditions. We first show some bound\nestimates on the process $Z$ and we specify the Zhang's path regularity\ntheorem. Then we give a new time discretization scheme with a non uniform time\nnet for such BSDEs and we obtain an explicit convergence rate for this scheme. \n\n"}
{"id": "1001.0615", "contents": "Title: Adaptive Wave Models for Option Pricing Evolution: Nonlinear and Quantum\n  Schr\\\"odinger Approaches Abstract: Adaptive wave model for financial option pricing is proposed, as a\nhigh-complexity alternative to the standard Black--Scholes model. The new\noption-pricing model, representing a controlled Brownian motion, includes two\nwave-type approaches: nonlinear and quantum, both based on (adaptive form of)\nthe Schr\\\"odinger equation. The nonlinear approach comes in two flavors: (i)\nfor the case of constant volatility, it is defined by a single adaptive\nnonlinear Schr\\\"odinger (NLS) equation, while for the case of stochastic\nvolatility, it is defined by an adaptive Manakov system of two coupled NLS\nequations. The linear quantum approach is defined in terms of de Broglie's\nplane waves and free-particle Schr\\\"odinger equation. In this approach,\nfinancial variables have quantum-mechanical interpretation and satisfy the\nHeisenberg-type uncertainty relations. Both models are capable of successful\nfitting of the Black--Scholes data, as well as defining Greeks.\n  Keywords: Black--Scholes option pricing, adaptive nonlinear Schr\\\"odinger\nequation, adaptive Manakov system, quantum-mechanical option pricing,\nmarket-heat potential\n  PACS: 89.65.Gh, 05.45.Yv, 03.65.Ge \n\n"}
{"id": "1001.1380", "contents": "Title: Forward equations for option prices in semimartingale models Abstract: We derive a forward partial integro-differential equation for prices of call\noptions in a model where the dynamics of the underlying asset under the pricing\nmeasure is described by a -possibly discontinuous- semimartingale. A uniqueness\ntheorem is given for the solutions of this equation. This result generalizes\nDupire's forward equation to a large class of non-Markovian models with jumps. \n\n"}
{"id": "1001.3006", "contents": "Title: Asymptotic equivalence and sufficiency for volatility estimation under\n  microstructure noise Abstract: The basic model for high-frequency data in finance is considered, where an\nefficient price process is observed under microstructure noise. It is shown\nthat this nonparametric model is in Le Cam's sense asymptotically equivalent to\na Gaussian shift experiment in terms of the square root of the volatility\nfunction $\\sigma$. As an application, simple rate-optimal estimators of the\nvolatility and efficient estimators of the integrated volatility are\nconstructed. \n\n"}
{"id": "1001.3972", "contents": "Title: Martingale representation for Poisson processes with applications to\n  minimal variance hedging Abstract: We consider a Poisson process $\\eta$ on a measurable space\n$(\\BY,\\mathcal{Y})$ equipped with a partial ordering, assumed to be strict\nalmost everwhwere with respect to the intensity measure $\\lambda$ of $\\eta$. We\ngive a Clark-Ocone type formula providing an explicit representation of square\nintegrable martingales (defined with respect to the natural filtration\nassociated with $\\eta$), which was previously known only in the special case,\nwhen $\\lambda$ is the product of Lebesgue measure on $\\R_+$ and a\n$\\sigma$-finite measure on another space $\\BX$. Our proof is new and based on\nonly a few basic properties of Poisson processes and stochastic integrals. We\nalso consider the more general case of an independent random measure in the\nsense of It\\^o of pure jump type and show that the Clark-Ocone type\nrepresentation leads to an explicit version of the Kunita-Watanabe\ndecomposition of square integrable martingales. We also find the explicit\nminimal variance hedge in a quite general financial market driven by an\nindependent random measure. \n\n"}
{"id": "1001.4151", "contents": "Title: New Financial Research Program: General Option-Price Wave Modeling Abstract: Recently, a novel adaptive wave model for financial option pricing has been\nproposed in the form of adaptive nonlinear Schr\\\"{o}dinger (NLS) equation\n[Ivancevic a], as a high-complexity alternative to the linear\nBlack-Scholes-Merton model [Black-Scholes-Merton]. Its quantum-mechanical basis\nhas been elaborated in [Ivancevic b]. Both the solitary and shock-wave\nsolutions of the nonlinear model, as well as its linear (periodic) quantum\nsimplification are shown to successfully fit the Black-Scholes data, and define\nthe financial Greeks. This initial wave model (called the Ivancevic option\npricing model) has been further extended in [Yan], by providing the new NLS\nsolutions in the form of rogue waves (one-rogon and two-rogon solutions). In\nthis letter, I propose a new financial research program, with a goal to develop\na general wave-type model for realistic option-pricing prediction and control.\n  Keywords: General option-price wave modeling, new financial research program \n\n"}
{"id": "1001.4188", "contents": "Title: Loop quantum gravity - a short review Abstract: In this article we review the foundations and the present status of loop\nquantum gravity. It is short and relatively non-technical, the emphasis is on\nthe ideas, and the flavor of the techniques. In particular, we describe the\nkinematical quantization and the implementation of the Hamilton constraint, as\nwell as the quantum theory of black hole horizons, semiclassical states, and\nmatter propagation. Spin foam models and loop quantum cosmology are mentioned\nonly in passing, as these will be covered in separate reviews to be published\nalongside this one. \n\n"}
{"id": "1001.4324", "contents": "Title: Einstein-Cartan gravity excludes extra dimensions Abstract: We show that the electron in the Riemann-Cartan spacetime with extra\ndimensions has a finite size that is much larger than the experimental upper\nlimit on its radius. Thus the Arkani-Hamed-Dimopoulos-Dvali and Randall-Sundrum\nmodels of the weak/Planck hierarchy in particle physics are not viable if spin\nproduces torsion according to the Einstein-Cartan theory of gravity. \n\n"}
{"id": "1001.4931", "contents": "Title: Decay-lepton correlations as probes of anomalous ZZH and gammaZH\n  interactions in e+e- --> ZH with polarized beams Abstract: We examine the contributions of various couplings in general ZZH and gammaZH\ninteractions arising from new physics to the Higgs production process e+e- -->\nHZ, followed by the decay of the Z into a charged-lepton pair. We take into\naccount possible longitudinal or transverse beam polarization likely to be\navailable at a linear collider. We show how expectation values of certain\nsimple observables in suitable combinations with appropriate longitudinal beam\npolarizations can be used to disentangle various couplings from one another.\nLongitudinal polarization can also improve the sensitivity for measurement of\nseveral couplings. A striking result is that using transverse polarization, one\nof the gammaZH couplings, not otherwise accessible, can be determined\nindependently of all other couplings. \n\n"}
{"id": "1002.2265", "contents": "Title: Sequential optimizing investing strategy with neural networks Abstract: In this paper we propose an investing strategy based on neural network models\ncombined with ideas from game-theoretic probability of Shafer and Vovk. Our\nproposed strategy uses parameter values of a neural network with the best\nperformance until the previous round (trading day) for deciding the investment\nin the current round. We compare performance of our proposed strategy with\nvarious strategies including a strategy based on supervised neural network\nmodels and show that our procedure is competitive with other strategies. \n\n"}
{"id": "1002.2505", "contents": "Title: Modeling the Diversity of Type Ia Supernova Explosions Abstract: Type Ia supernovae (SNe Ia) are a prime tool in observational cosmology. A\nrelation between their peak luminosities and the shapes of their light curves\nallows to infer their intrinsic luminosities and to use them as distance\nindicators. This relation has been established empirically. However, a\ntheoretical understanding is necessary in order to get a handle on the\nsystematics in SN Ia cosmology. Here, a model reproducing the observed\ndiversity of normal SNe Ia is presented. The challenge in the numerical\nimplementation arises from the vast range of scales involved in the physical\nmechanism. Simulating the supernova on scales of the exploding white dwarf\nrequires specific models of the microphysics involved in the thermonuclear\ncombustion process. Such techniques are discussed and results of simulations\nare presented. \n\n"}
{"id": "1002.3018", "contents": "Title: Subgraphs of dense random graphs with specified degrees Abstract: Let d = (d1, d2, ..., dn) be a vector of non-negative integers with even sum.\nWe prove some basic facts about the structure of a random graph with degree\nsequence d, including the probability of a given subgraph or induced subgraph.\nAlthough there are many results of this kind, they are restricted to the sparse\ncase with only a few exceptions. Our focus is instead on the case where the\naverage degree is approximately a constant fraction of n. Our approach is the\nmultidimensional saddle-point method. This extends the enumerative work of\nMcKay and Wormald (1990) and is analogous to the theory developed for bipartite\ngraphs by Greenhill and McKay (arXiv:math/0701600, 2009). \n\n"}
{"id": "1002.4710", "contents": "Title: Heavy-Baryon Spectroscopy from Lattice QCD Abstract: We use a four-dimensional lattice calculation of the full-QCD (quantum\nchromodynamics, the non-abliean gauge theory of the strong interactions of\nquarks and gluons) path integrals needed to determine the masses of the charmed\nand bottom baryons. In the charm sector, our results are in good agreement with\nexperiment within our systematics, except for the spin-1/2 $\\Xi_{cc}$, for\nwhich we found the isospin-averaged mass to be $\\Xi_{cc}$ to be\n$3665\\pm17\\pm14^{+0}_{-78}$ MeV. We predict the mass of the (isospin-averaged)\nspin-1/2 $\\Omega_{cc}$ to be $3763\\pm19\\pm26^{+13}_{-79}$ {MeV}. In the bottom\nsector, our results are also in agreement with experimental observations and\nother lattice calculations within our statistical and systematic errors. In\nparticular, we find the mass of the $\\Omega_b$ to be consistent with the recent\nCDF measurement. We also predict the mass for the as yet unobserved\n$\\Xi^\\prime_b$ to be 5955(27) MeV. \n\n"}
{"id": "1002.5031", "contents": "Title: Global existence, regularity and a probabilistic scheme for a class of\n  ultraparabolic Cauchy problems Abstract: In this paper we establish a constructive method in order to show global\nexistence and regularity for a class of degenerate parabolic Cauchy problems\nwhich satisfy a weak Hoermander condition on a subset of the domain where the\ndata are measurable and which have regular data on the complementary set of the\ndomain. This result has practical incentives related to the computation of\nGreeks in reduced LIBOR market models, which are standard computable\napproximations of the HJM-description of interest rate markets. The method\nleads to a probabilistic scheme for the computation of the value function and\nits sensitivities based on Malliavin calculus. From a practical perspective the\nmain contribution of the paper is an Monte-Carlo algorithm which includes\nweight corrections for paths which move in time into a region where a (weak)\nHoermander condition holds. \n\n"}
{"id": "1003.2920", "contents": "Title: Computational LPPL Fit to Financial Bubbles Abstract: The log-periodic power law (LPPL) is a model of asset prices during\nendogenous bubbles. If the on-going development of a bubble is suspected, asset\nprices can be fit numerically to the LPPL law. The best solutions can then\nindicate whether a bubble is in progress and, if so, the bubble critical time\n(i.e., when the bubble is expected to burst). Consequently, the LPPL model is\nuseful only if the data can be fit to the model with algorithms that are\naccurate and computationally efficient. In this paper, we address primarily the\ncomputational efficiency and secondarily the precision of the LPPL non-linear\nleast-square fit. Specifically, we present a parallel Levenberg-Marquardt\nalgorithm (LMA) for LPPL least-square fit that sped up computation of more than\na factor of four over a sequential LMA on historical and synthetic price\nseries. Additionally, we isolate a linear sub-structure of the LPPL\nleast-square fit that can be paired with an exact computation of the Jacobian,\ngive new settings for the Levenberg-Marquardt damping factor, and describe a\nheuristic method to choose initial solutions. \n\n"}
{"id": "1003.5147", "contents": "Title: AP Theory III: Cone-like Graded SUSY, Dynamic Dark Energy and the YM\n  Millenium Problem Abstract: Artin Presentation Theory, (AP Theory), is a new, direct infusion, via pure\nbraid theory, of discrete group theory, (i.e., symmetry in its purest form),\ninto the theory of {\\it smooth} 4-manifolds, (i.e.,$(3+1)$-Quantum Gravity in\nits purest topological form), thus exhibiting the most basic, rigorous,\nuniversal, model-free intrinsic {\\it gauge-gravity} duality in a\nnon-infinitesimal, cone-like graded, as holographic as possible,\nmodel-independent, non-perturbative, background-independent, parameter-free\nmanner. {\\it In AP Theory even smooth topology change becomes gauge-theoretic,\nsetting the stage for a rigorous smooth topological $(3+1)$-QFT of Dynamic Dark\nEnergy.} In this theory, the rigid $\\infty$ of the dimension of classical\nHilbert space is substituted by the dynamic $\\infty$ of the $\\infty$ generation\nat each stage of a cone-like graded subgroup of topology-changing\ntransitions/interactions. As a corollary, the Cosmological Constant problem and\nthe YM Millenium Mass Gap problem, two of the most perplexing main problems of\nmodern physics, become rigorously, intimately mathematically related, by having\nthe same qualitative {\\it dynamical} roots. Ultimately our main point is\nmeta-mathematical, as far as modern physics is concerned: due to the discrete\ngroup-theoretic conceptual simplicity of the theory, with its group-theoretic\n'Planckian membrane/discreteness' starting point, {\\it the fact that it is not\njust a mere mathematical model,} and all its properties above, any other {\\it\nmathematically rigorous} approach has to built on AP Theory and be\ntopologically absorbed and enveloped by it. \n\n"}
{"id": "1003.6058", "contents": "Title: More generalizations of pseudocompactness Abstract: We introduce a covering notion depending on two cardinals, which we call\n$\\mathcal O $-$ [ \\mu, \\lambda ]$-compactness, and which encompasses both\npseudocompactness and many other generalizations of pseudocompactness. For\nTychonoff spaces, pseudocompactness turns out to be equivalent to $\\mathcal O\n$-$ [ \\omega, \\omega ]$-compactness. We provide several characterizations of\n$\\mathcal O $-$ [ \\mu, \\lambda ]$-compactness, and we discuss its connection\nwith $D$-pseudocompactness, for $D$ an ultrafilter. We analyze the behaviour of\nthe above notions with respect to products. Finally, we show that our results\nhold in a more general framework, in which compactness properties are defined\nrelative to an arbitrary family of subsets of some topological space $X$. \n\n"}
{"id": "1004.1522", "contents": "Title: Dynamics on/in financial markets: dynamical decoupling and stylized\n  facts Abstract: Stylized facts can be regarded as constraints for any modeling attempt of\nprice dynamics on a financial market, in that an empirically reasonable model\nhas to reproduce these stylized facts at least qualitatively. The dynamics of\nmarket prices is modeled on a macro-level as the result of the dynamic coupling\nof two dynamical components. The degree of their dynamical decoupling is shown\nto have a significant impact on the stochastic properties of return trials such\nas the return distribution, volatility clustering, and the multifractal\nbehavior of time scales of asset returns. Particularly we observe a cross over\nin the return distribution from a Gaussian-like to a Levy-like shape when the\ndegree of decoupling increases. In parallel, the larger the degree of\ndecoupling is the more pronounced is volatility clustering. These findings\nsuggest that the considerations of time in an economic system, in general, and\nthe coupling of constituting processes is essential for understanding the\nbehavior of a financial market. \n\n"}
{"id": "1004.2206", "contents": "Title: A maximum principle for forward-backward stochastic Volterra integral\n  equations and applications in finance Abstract: This paper formulates and studies a stochastic maximum principle for\nforward-backward stochastic Volterra integral equations (FBSVIEs in short),\nwhile the control area is assumed to be convex. Then a linear quadratic (LQ in\nshort) problem for backward stochastic Volterra integral equations (BSVIEs in\nshort) is present to illustrate the aforementioned optimal control problem.\nMotivated by the technical skills in solving above problem, a more convenient\nand briefer method for the unique solvability of M-solution for BSVIEs is\nproposed. At last, we will investigate a risk minimization problem by means of\nthe maximum principle for FBSVIEs. Closed-form optimal portfolio is obtained in\nsome special cases. \n\n"}
{"id": "1004.2248", "contents": "Title: Results on numerics for FBSDE with drivers of quadratic growth Abstract: We consider the problem of numerical approximation for forward-backward\nstochastic differential equations with drivers of quadratic growth (qgFBSDE).\nTo illustrate the significance of qgFBSDE, we discuss a problem of cross\nhedging of an insurance related financial derivative using correlated assets.\nFor the convergence of numerical approximation schemes for such systems of\nstochastic equations, path regularity of the solution processes is\ninstrumental. We present a method based on the truncation of the driver, and\nexplicitly exhibit error estimates as functions of the truncation height. We\ndiscuss a reduction method to FBSDE with globally Lipschitz continuous drivers,\nby using the Cole-Hopf exponential transformation. We finally illustrate our\nnumerical approximation methods by giving simulations for prices and optimal\nhedges of simple insurance derivatives. \n\n"}
{"id": "1004.2548", "contents": "Title: Chain ladder method: Bayesian bootstrap versus classical bootstrap Abstract: The intention of this paper is to estimate a Bayesian distribution-free chain\nladder (DFCL) model using approximate Bayesian computation (ABC) methodology.\nWe demonstrate how to estimate quantities of interest in claims reserving and\ncompare the estimates to those obtained from classical and credibility\napproaches. In this context, a novel numerical procedure utilising Markov chain\nMonte Carlo (MCMC), ABC and a Bayesian bootstrap procedure was developed in a\ntruly distribution-free setting. The ABC methodology arises because we work in\na distribution-free setting in which we make no parametric assumptions, meaning\nwe can not evaluate the likelihood point-wise or in this case simulate directly\nfrom the likelihood model. The use of a bootstrap procedure allows us to\ngenerate samples from the intractable likelihood without the requirement of\ndistributional assumptions, this is crucial to the ABC framework. The developed\nmethodology is used to obtain the empirical distribution of the DFCL model\nparameters and the predictive distribution of the outstanding loss liabilities\nconditional on the observed claims. We then estimate predictive Bayesian\ncapital estimates, the Value at Risk (VaR) and the mean square error of\nprediction (MSEP). The latter is compared with the classical bootstrap and\ncredibility methods. \n\n"}
{"id": "1004.3106", "contents": "Title: Fractional processes as models in stochastic finance Abstract: We survey some new progress on the pricing models driven by fractional\nBrownian motion \\cb{or} mixed fractional Brownian motion. In particular, we\ngive results on arbitrage opportunities, hedging, and option pricing in these\nmodels. We summarize some recent results on fractional Black & Scholes pricing\nmodel with transaction costs. We end the paper by giving some approximation\nresults and indicating some open problems related to the paper. \n\n"}
{"id": "1004.3310", "contents": "Title: Dividend problem with Parisian delay for a spectrally negative L\\'evy\n  risk process Abstract: In this paper we consider dividend problem for an insurance company whose\nrisk evolves as a spectrally negative L\\'{e}vy process (in the absence of\ndividend payments) when Parisian delay is applied. The objective function is\ngiven by the cumulative discounted dividends received until the moment of ruin\nwhen so-called barrier strategy is applied. Additionally we will consider two\npossibilities of delay. In the first scenario ruin happens when the surplus\nprocess stays below zero longer than fixed amount of time $\\zeta>0$. In the\nsecond case there is a time lag $d$ between decision of paying dividends and\nits implementation. \n\n"}
{"id": "1004.3830", "contents": "Title: Model Selection and Adaptive Markov chain Monte Carlo for Bayesian\n  Cointegrated VAR model Abstract: This paper develops a matrix-variate adaptive Markov chain Monte Carlo (MCMC)\nmethodology for Bayesian Cointegrated Vector Auto Regressions (CVAR). We\nreplace the popular approach to sampling Bayesian CVAR models, involving griddy\nGibbs, with an automated efficient alternative, based on the Adaptive\nMetropolis algorithm of Roberts and Rosenthal, (2009). Developing the adaptive\nMCMC framework for Bayesian CVAR models allows for efficient estimation of\nposterior parameters in significantly higher dimensional CVAR series than\npreviously possible with existing griddy Gibbs samplers. For a n-dimensional\nCVAR series, the matrix-variate posterior is in dimension $3n^2 + n$, with\nsignificant correlation present between the blocks of matrix random variables.\nWe also treat the rank of the CVAR model as a random variable and perform joint\ninference on the rank and model parameters. This is achieved with a Bayesian\nposterior distribution defined over both the rank and the CVAR model\nparameters, and inference is made via Bayes Factor analysis of rank.\nPractically the adaptive sampler also aids in the development of automated\nBayesian cointegration models for algorithmic trading systems considering\ninstruments made up of several assets, such as currency baskets. Previously the\nliterature on financial applications of CVAR trading models typically only\nconsiders pairs trading (n=2) due to the computational cost of the griddy\nGibbs. We are able to extend under our adaptive framework to $n >> 2$ and\ndemonstrate an example with n = 10, resulting in a posterior distribution with\nparameters up to dimension 310. By also considering the rank as a random\nquantity we can ensure our resulting trading models are able to adjust to\npotentially time varying market conditions in a coherent statistical framework. \n\n"}
{"id": "1004.5559", "contents": "Title: A Direct Proof of the Bichteler--Dellacherie Theorem and Connections to\n  Arbitrage Abstract: We give an elementary proof of the celebrated Bichteler-Dellacherie Theorem\nwhich states that the class of stochastic processes $S$ allowing for a useful\nintegration theory consists precisely of those processes which can be written\nin the form $S=M+A$, where $M$ is a local martingale and $A$ is a finite\nvariation process. In other words, $S$ is a good integrator if and only if it\nis a semi-martingale. We obtain this decomposition rather directly from an\nelementary discrete-time Doob-Meyer decomposition. By passing to convex\ncombinations we obtain a direct construction of the continuous time\ndecomposition, which then yields the desired decomposition. As a by-product of\nour proof we obtain a characterization of semi-martingales in terms of a\nvariant of \\emph{no free lunch}, thus extending a result from [DeSc94]. \n\n"}
{"id": "1005.0182", "contents": "Title: A Multi Agent Model for the Limit Order Book Dynamics Abstract: In the present work we introduce a novel multi-agent model with the aim to\nreproduce the dynamics of a double auction market at microscopic time scale\nthrough a faithful simulation of the matching mechanics in the limit order\nbook. The agents follow a noise decision making process where their actions are\nrelated to a stochastic variable, \"the market sentiment\", which we define as a\nmixture of public and private information. The model, despite making just few\nbasic assumptions over the trading strategies of the agents, is able to\nreproduce several empirical features of the high-frequency dynamics of the\nmarket microstructure not only related to the price movements but also to the\ndeposition of the orders in the book. \n\n"}
{"id": "1005.1324", "contents": "Title: Quasiconformality and mass Abstract: We identify universal quasiconformal (walking) behaviour in non-Abelian gauge\nfield theories based on the mass-dependent all-order beta-function introduced\nin arXiv:0908.1364. We find different types of walking behaviour in the\npresence of (partially) massive species. We employ our findings to the\nconstruction of candidate theories for dynamical electroweak symmetry breaking\nby walking technicolour. \n\n"}
{"id": "1005.2247", "contents": "Title: The sum of a maximal monotone operator of type (FPV) and a maximal\n  monotone operator with full domain is maximal monotone Abstract: The most important open problem in Monotone Operator Theory concerns the\nmaximal monotonicity of the sum of two maximal monotone operators provided that\nRockafellar's constraint qualification holds.\n  In this paper, we prove the maximal monotonicity of $A+B$ provided that $A$\nand $B$ are maximal monotone operators such that $\\dom A\\cap\\inte\\dom\nB\\neq\\varnothing$, $A+N_{\\overline{\\dom B}}$ is of type (FPV), and $\\dom\nA\\cap\\overline{\\dom B}\\subseteq\\dom B$. The proof utilizes the Fitzpatrick\nfunction in an essential way. \n\n"}
{"id": "1006.1223", "contents": "Title: Measurements of forward proton production with incident protons and\n  charged pions on nuclear targets at the CERN Proton Synchroton Abstract: Measurements of the double-differential proton production cross-section in\nthe range of momentum 0.5 GeV/c < p < 8.0 GeV/c and angle 0.05 rad < \\theta <\n0.25 rad in collisions of charged pions and protons on beryllium, carbon,\naluminium, copper, tin, tantalum and lead are presented. The data were taken\nwith the large acceptance HARP detector in the T9 beam line of the CERN Proton\nSynchrotron. Incident particles were identified by an elaborate system of beam\ndetectors and impinged on a target of 5 % of a nuclear interaction length. The\ntracking and identification of the produced particles was performed using the\nforward spectrometer of the HARP experiment. Results are obtained for the\ndouble-differential cross-sections mainly at four incident beam momenta (3\nGeV/c, 5 GeV/c, 8 GeV/c and 12 GeV/c). Measurements are compared with\npredictions of the GEANT4 and MARS Monte Carlo generators. \n\n"}
{"id": "1006.1356", "contents": "Title: The Bestest Little Higgs Abstract: While little Higgs models provide an interesting way to address the hierarchy\nproblem, concrete models in the literature typically face two major obstacles.\nFirst, the mechanism for generating a Higgs quartic coupling often leads to\nlarge violations of custodial symmetry. Second, there is a tension between\nprecision electroweak observables in the gauge sector and fine-tuning in the\ntop sector. In this work, we present a new little Higgs model which solves both\nof these problems. The model is based on an SO(6)xSO(6)/SO(6) coset space which\nhas custodial symmetry built in. The Higgs quartic coupling takes a\nparticularly simple form and does not suffer from the \"dangerous singlet\"\npathology. We introduce a gauge breaking module which decouples the mass of\ngauge partners from the mass of top partners, allowing for natural electroweak\nsymmetry breaking. The collider phenomenology is dominated by production and\ndecay of the top partners, which are considerably lighter than in traditional\nlittle Higgs theories. \n\n"}
{"id": "1006.3096", "contents": "Title: Non-Hermitean Wishart random matrices (I) Abstract: A non-Hermitean extension of paradigmatic Wishart random matrices is\nintroduced to set up a theoretical framework for statistical analysis of (real,\ncomplex and real quaternion) stochastic time series representing two \"remote\"\ncomplex systems. The first paper in a series provides a detailed spectral\ntheory of non-Hermitean Wishart random matrices composed of complex valued\nentries. The great emphasis is placed on an asymptotic analysis of the mean\neigenvalue density for which we derive, among other results, a complex-plane\nanalogue of the Marchenko-Pastur law. A surprising connection with a class of\nmatrix models previously invented in the context of quantum chromodynamics is\npointed out. \n\n"}
{"id": "1006.3224", "contents": "Title: Outperforming the market portfolio with a given probability Abstract: Our goal is to resolve a problem proposed by Fernholz and Karatzas [On\noptimal arbitrage (2008) Columbia Univ.]: to characterize the minimum amount of\ninitial capital with which an investor can beat the market portfolio with a\ncertain probability, as a function of the market configuration and time to\nmaturity. We show that this value function is the smallest nonnegative\nviscosity supersolution of a nonlinear PDE. As in Fernholz and Karatzas [On\noptimal arbitrage (2008) Columbia Univ.], we do not assume the existence of an\nequivalent local martingale measure, but merely the existence of a local\nmartingale deflator. \n\n"}
{"id": "1007.1294", "contents": "Title: Factorization Law for Two Lower Bounds of Concurrence Abstract: We study the dynamics of two lower bounds of concurrence in bipartite quantum\nsystems when one party goes through an arbitrary channel. We show that these\nlower bounds obey the factorization law similar to that of [Konrad et al., Nat.\nPhys. 4, 99 (2008)]. We also, discuss the application of this property, in an\nexample. \n\n"}
{"id": "1008.0149", "contents": "Title: Bayesian Cointegrated Vector Autoregression models incorporating\n  Alpha-stable noise for inter-day price movements via Approximate Bayesian\n  Computation Abstract: We consider a statistical model for pairs of traded assets, based on a\nCointegrated Vector Auto Regression (CVAR) Model. We extend standard CVAR\nmodels to incorporate estimation of model parameters in the presence of price\nseries level shifts which are not accurately modeled in the standard Gaussian\nerror correction model (ECM) framework. This involves developing a novel matrix\nvariate Bayesian CVAR mixture model comprised of Gaussian errors intra-day and\nAlpha-stable errors inter-day in the ECM framework. To achieve this we derive a\nnovel conjugate posterior model for the Scaled Mixtures of Normals (SMiN CVAR)\nrepresentation of Alpha-stable inter-day innovations. These results are\ngeneralized to asymmetric models for the innovation noise at inter-day\nboundaries allowing for skewed Alpha-stable models.\n  Our proposed model and sampling methodology is general, incorporating the\ncurrent literature on Gaussian models as a special subclass and also allowing\nfor price series level shifts either at random estimated time points or known a\npriori time points. We focus analysis on regularly observed non-Gaussian level\nshifts that can have significant effect on estimation performance in\nstatistical models failing to account for such level shifts, such as at the\nclose and open of markets. We compare the estimation accuracy of our model and\nestimation approach to standard frequentist and Bayesian procedures for CVAR\nmodels when non-Gaussian price series level shifts are present in the\nindividual series, such as inter-day boundaries. We fit a bi-variate\nAlpha-stable model to the inter-day jumps and model the effect of such jumps on\nestimation of matrix-variate CVAR model parameters using the likelihood based\nJohansen procedure and a Bayesian estimation. We illustrate our model and the\ncorresponding estimation procedures we develop on both synthetic and actual\ndata. \n\n"}
{"id": "1008.1108", "contents": "Title: Calculation of aggregate loss distributions Abstract: Estimation of the operational risk capital under the Loss Distribution\nApproach requires evaluation of aggregate (compound) loss distributions which\nis one of the classic problems in risk theory. Closed-form solutions are not\navailable for the distributions typically used in operational risk. However\nwith modern computer processing power, these distributions can be calculated\nvirtually exactly using numerical methods. This paper reviews numerical\nalgorithms that can be successfully used to calculate the aggregate loss\ndistributions. In particular Monte Carlo, Panjer recursion and Fourier\ntransformation methods are presented and compared. Also, several closed-form\napproximations based on moment matching and asymptotic result for heavy-tailed\ndistributions are reviewed. \n\n"}
{"id": "1008.1606", "contents": "Title: Ideal Triangulations of Pseudo-Anosov Mapping Tori Abstract: We show how to construct an ideal triangulation of a mapping torus of a\npseudo-Anosov map punctured along the singular fibers. This gives rise to a new\nconjugacy invariant of mapping classes, and a new proof of a theorem of\nFarb-Leininger-Margalit. The approach in this paper is based on ideas of\nHamenstadt. \n\n"}
{"id": "1008.2226", "contents": "Title: Non-existence of Markovian time dynamics for graphical models of\n  correlated default Abstract: Filiz et al. (2008) proposed a model for the pattern of defaults seen among a\ngroup of firms at the end of a given time period. The ingredients in the model\nare a graph, where the vertices correspond to the firms and the edges describe\nthe network of interdependencies between the firms, a parameter for each vertex\nthat captures the individual propensity of that firm to default, and a\nparameter for each edge that captures the joint propensity of the two connected\nfirms to default. The correlated default model can be re-rewritten as a\nstandard Ising model on the graph by identifying the set of defaulting firms in\nthe default model with the set of sites in the Ising model for which the spin\nis +1. We ask whether there is a suitable continuous time Markov chain taking\nvalues in the subsets of the vertex set such that the initial state of the\nchain is the empty set, each jump of the chain involves the inclusion of a\nsingle extra vertex, the distribution of the chain at some fixed time horizon\ntime is the one given by the default model, and the distribution of the chain\nfor other times is described by a probability distribution in the same family\nas the default model. We show for three simple but financially natural special\ncases that this is not possible outside of the trivial case where there is\ncomplete independence between the firms. \n\n"}
{"id": "1008.3276", "contents": "Title: No-arbitrage of second kind in countable markets with proportional\n  transaction costs Abstract: Motivated by applications to bond markets, we propose a multivariate\nframework for discrete time financial markets with proportional transaction\ncosts and a countable infinite number of tradable assets. We show that the\nno-arbitrage of second kind property (NA2 in short), recently introduced by\nRasonyi for finite-dimensional markets, allows us to provide a closure property\nfor the set of attainable claims in a very natural way, under a suitable\nefficient friction condition. We also extend to this context the equivalence\nbetween NA2 and the existence of many (strictly) consistent price systems. \n\n"}
{"id": "1008.4611", "contents": "Title: Large systems of diffusions interacting through their ranks Abstract: We study the limiting behaviour of the empirical measure of a system of\ndiffusions interacting through their ranks when the number of diffusions tends\nto infinity. We prove that the limiting dynamics is given by a McKean-Vlasov\nevolution equation. Moreover, we show that in a wide range of cases the\nevolution of the cumulative distribution function under the limiting dynamics\nis governed by the generalized porous medium equation with convection. The\nuniqueness theory for the latter is used to establish the uniqueness of\nsolutions of the limiting McKean-Vlasov equation and the law of large numbers\nfor the corresponding systems of interacting diffusions. The implications of\nthe results for rank-based models of capital distributions in financial markets\nare also explained. \n\n"}
{"id": "1008.4841", "contents": "Title: Path Integral and Asian Options Abstract: In this paper we analytically study the problem of pricing an arithmetically\naveraged Asian option in the path integral formalism. By a trick about the\nDirac delta function, the measure of the path integral is defined by an\neffective action functional whose potential term is an exponential function.\nThis path integral is evaluated by use of the Feynman-Kac theorem. After\nworking out some auxiliary integrations involving Bessel and Whittaker\nfunctions, we arrive at the spectral expansion for the value of Asian options. \n\n"}
{"id": "1009.0635", "contents": "Title: Numerical methods for optimal insurance demand under marked point\n  processes shocks Abstract: This paper deals with numerical solutions of maximizing expected utility from\nterminal wealth under a non-bankruptcy constraint. The wealth process is\nsubject to shocks produced by a general marked point process. The problem of\nthe agent is to derive the optimal insurance strategy which allows \"lowering\"\nthe level of the shocks. This optimization problem is related to a suitable\ndual stochastic control problem in which the delicate boundary constraints\ndisappear. In Mnif \\cite{mnif10}, the dual value function is characterized as\nthe unique viscosity solution of the corresponding Hamilton Jacobi Bellman\nVariational Inequality (HJBVI in short). We characterize the optimal insurance\nstrategy by the solution of the variational inequality which we solve\nnumerically by using an algorithm based on policy iterations. \n\n"}
{"id": "1009.1583", "contents": "Title: Gravity or Turbulence? The velocity dispersion-size relation Abstract: We discuss the nature of the velocity dispersion vs. size relation for\nmolecular clouds. In particular, we add to previous observational results\nshowing that the velocity dispersions in molecular clouds and cores are not\npurely functions of spatial scale but involve surface gas densities as well. We\nemphasize that hydrodynamic turbulence is required to produce the first\ncondensations in the progenitor medium. However, as the cloud is forming, it\nalso becomes bound, and gravitational accelerations dominate the motions.\nEnergy conservation in this case implies $|E_g| \\sim E_k$, in agreement with\nobservational data, and providing an interpretation for two recent\nobservational results: the scatter in the $\\delta v-R$ plane, and the\ndependence of the velocity dispersion on the surface density ${\\delta v^2/ R}\n\\propto \\Sigma$. We argue that the observational data are consistent with\nmolecular clouds in a state of hierarchical gravitational collapse, i.e.,\ndeveloping local centers of collapse throughout the whole cloud while the cloud\nitself is collapsing, and making equilibrium unnecessary at all stages prior to\nthe formation of actual stars. Finally, we discuss how this mechanism need not\nbe in conflict with the observed star formation rate. \n\n"}
{"id": "1009.4193", "contents": "Title: Observational constraints on the LLTB model Abstract: We directly compare the concordance LCDM model to the inhomogeneous\nmatter-only alternative represented by LTB void models. To achieve a\n\"democratic\" confrontation we explore LLTB models with non-vanishing\ncosmological constant and perform a global likelihood analysis in the parameter\nspace of cosmological constant and void radius. In our analysis we carefully\nconsider SNe, Hubble constant, CMB and BAO measurements, marginalizing over\nspectral index, age of the universe and background curvature. We find that the\nLCDM model is not the only possibility compatible with the observations, and\nthat a matter-only void model is a viable alternative to the concordance model\nonly if the BAO constraints are relaxed. Moreover, we will show that the areas\nof the parameter space which give a good fit to the observations are always\ndisconnected with the result that a small local void does not significantly\naffect the parameter extraction for LCDM models. \n\n"}
{"id": "1009.4818", "contents": "Title: Semi-Closed Form Cubature and Applications to Financial Diffusion Models Abstract: Cubature methods, a powerful alternative to Monte Carlo due to\nKusuoka~[Adv.~Math.~Econ.~6, 69--83, 2004] and\nLyons--Victoir~[Proc.~R.~Soc.\\\\Lond.~Ser.~A 460, 169--198, 2004], involve the\nsolution to numerous auxiliary ordinary differential equations. With focus on\nthe Ninomiya-Victoir algorithm~[Appl.~Math.~Fin.~15, 107--121, 2008], which\ncorresponds to a concrete level $5$ cubature method, we study some parametric\ndiffusion models motivated from financial applications, and exhibit structural\nconditions under which all involved ODEs can be solved explicitly and\nefficiently. We then enlarge the class of models for which this technique\napplies, by introducing a (model-dependent) variation of the Ninomiya-Victoir\nmethod. Our method remains easy to implement; numerical examples illustrate the\nsavings in computation time. \n\n"}
{"id": "1010.0831", "contents": "Title: Constraining the expansion rate of the Universe using low-redshift\n  ellipticals as cosmic chronometers Abstract: We present a new methodology to determine the expansion history of the\nUniverse analyzing the spectral properties of early type galaxies (ETG). We\nfound that for these galaxies the 4000\\AA break is a spectral feature that\ncorrelates with the relative ages of ETGs. In this paper we describe the\nmethod, explore its robustness using theoretical synthetic stellar population\nmodels, and apply it using a SDSS sample of $\\sim$14 000 ETGs. Our motivation\nto look for a new technique has been to minimise the dependence of the cosmic\nchronometer method on systematic errors. In particular, as a test of our\nmethod, we derive the value of the Hubble constant $H_0 = 72.6 \\pm 2.8$ (stat)\n$\\pm2.3$ (syst) (68% confidence), which is not only fully compatible with the\nvalue derived from the Hubble key project, but also with a comparable error\nbudget. Using the SDSS, we also derive, assuming w=constant, a value for the\ndark energy equation of state parameter $w = -1 \\pm 0.2$ (stat) $\\pm0.3$\n(syst). Given the fact that the SDSS ETG sample only reaches $z \\sim 0.3$, this\nresult shows the potential of the method. In future papers we will present\nresults using the high-redshift universe, to yield a determination of H(z) up\nto $z \\sim 1$. \n\n"}
{"id": "1010.1773", "contents": "Title: Multi-scalar field cosmology from SFT: an exactly solvable approximation Abstract: We consider the appearance of multiple scalar fields in SFT inspired\nnon-local models with a single scalar field at late times. In this regime all\nthe scalar fields are free. This system minimally coupled to gravity can be\nanalyzed approximately or numerically. The main result of this note is the\nintroduction of an exactly solvable model which obeys an exact solution in the\ncosmological context for the Friedmann equations and that reproduces the\nbehavior expected from SFT in the asymptotic regime. Different applications of\nsuch a potential to multi-field cosmological models are discussed. \n\n"}
{"id": "1010.4408", "contents": "Title: Sublinear Optimization for Machine Learning Abstract: We give sublinear-time approximation algorithms for some optimization\nproblems arising in machine learning, such as training linear classifiers and\nfinding minimum enclosing balls. Our algorithms can be extended to some\nkernelized versions of these problems, such as SVDD, hard margin SVM, and\nL2-SVM, for which sublinear-time algorithms were not known before. These new\nalgorithms use a combination of a novel sampling techniques and a new\nmultiplicative update algorithm. We give lower bounds which show the running\ntimes of many of our algorithms to be nearly best possible in the unit-cost RAM\nmodel. We also give implementations of our algorithms in the semi-streaming\nsetting, obtaining the first low pass polylogarithmic space and sublinear time\nalgorithms achieving arbitrary approximation factor. \n\n"}
{"id": "1010.4831", "contents": "Title: Replicating financial market dynamics with a simple self-organized\n  critical lattice model Abstract: We explore a simple lattice field model intended to describe statistical\nproperties of high frequency financial markets. The model is relevant in the\ncross-disciplinary area of econophysics. Its signature feature is the emergence\nof a self-organized critical state. This implies scale invariance of the model,\nwithout tuning parameters. Prominent results of our simulation are time series\nof gains, prices, volatility, and gains frequency distributions, which all\ncompare favorably to features of historical market data. Applying a standard\nGARCH(1,1) fit to the lattice model gives results that are almost\nindistinguishable from historical NASDAQ data. \n\n"}
{"id": "1010.4962", "contents": "Title: QCD and Light-Front Dynamics Abstract: AdS/QCD, the correspondence between theories in a dilaton-modified\nfive-dimensional anti-de Sitter space and confining field theories in physical\nspace-time, provides a remarkable semiclassical model for hadron physics.\nLight-front holography allows hadronic amplitudes in the AdS fifth dimension to\nbe mapped to frame-independent light-front wavefunctions of hadrons in physical\nspace-time. The result is a single-variable light-front Schrodinger equation\nwhich determines the eigenspectrum and the light-front wavefunctions of hadrons\nfor general spin and orbital angular momentum. The coordinate z in AdS space is\nuniquely identified with a Lorentz-invariant coordinate zeta which measures the\nseparation of the constituents within a hadron at equal light-front time and\ndetermines the off-shell dynamics of the bound state wavefunctions as a\nfunction of the invariant mass of the constituents. The hadron eigenstates\ngenerally have components with different orbital angular momentum; e.g., the\nproton eigenstate in AdS/QCD with massless quarks has L=0 and L=1 light-front\nFock components with equal probability. Higher Fock states with extra\nquark-anti quark pairs also arise. The soft-wall model also predicts the form\nof the non-perturbative effective coupling and its beta-function. The AdS/QCD\nmodel can be systematically improved by using its complete orthonormal\nsolutions to diagonalize the full QCD light-front Hamiltonian or by applying\nthe Lippmann-Schwinger method to systematically include QCD interaction terms.\nSome novel features of QCD are discussed, including the consequences of\nconfinement for quark and gluon condensates. A method for computing the\nhadronization of quark and gluon jets at the amplitude level is outlined. \n\n"}
{"id": "1011.0820", "contents": "Title: Adiabaticity and emergence of classical space-time in time-dependent\n  matrix theories Abstract: We discuss the low-curvature regime of time-dependent matrix theories\nproposed to describe non-perturbative quantum gravity in asymptotically\nplane-wave space-times. The emergence of near-classical space-time in this\nlimit turns out to be closely linked to the adiabaticity of the matrix theory\nevolution. Supersymmetry restoration at low curvatures, which is crucial for\nthe usual space-time interpretation of matrix theories, becomes an obvious\nfeature of the adiabatic regime. \n\n"}
{"id": "1011.1482", "contents": "Title: Comment on \"Response calculations with an independent particle system\n  with an exact one-particle density matrix'' Abstract: We point out an error in the argument [PRL 105, 013002 (2010)] that the time\nindependence of the occupation numbers in the adiabatic approximation follows\nfrom the invariance of the ground-state interaction energy functional with\nrespect to changes in the phases of the natural orbitals. \n\n"}
{"id": "1011.2659", "contents": "Title: Metastable supersymmetry breaking without scales Abstract: We construct new examples of models of metastable D=4 N=1 supersymmetry\nbreaking in which all scales are generated dynamically. Our models rely on\nSeiberg duality and on the ISS mechanism of supersymmetry breaking in massive\nSQCD. Some of the electric quark superfields arise as composites of a strongly\ncoupled gauge sector. This allows us to start with a simple cubic\nsuperpotential and an asymptotically free gauge group in the ultraviolet, and\nend up with an infrared effective theory which breaks supersymmetry dynamically\nin a metastable state. \n\n"}
{"id": "1011.3685", "contents": "Title: Multidimensional dynamic risk measure via conditional g-expectation Abstract: This paper deals with multidimensional dynamic risk measures induced by\nconditional $g$-expectations. A notion of multidimensional $g$-expectation is\nproposed to provide a multidimensional version of nonlinear expectations. By a\ntechnical result on explicit expressions for the comparison theorem, uniqueness\ntheorem and viability on a rectangle of solutions to multidimensional backward\nstochastic differential equations, some necessary and sufficient conditions are\ngiven for the constancy, monotonicity, positivity, homogeneity and\ntranslatability properties of multidimensional conditional $g$-expectations and\nmultidimensional dynamic risk measures; we prove that a multidimensional\ndynamic $g$-risk measure is nonincreasingly convex if and only if the generator\n$g$ satisfies a quasi-monotone increasingly convex condition. A general dual\nrepresentation is given for the multidimensional dynamic convex $g$-risk\nmeasure in which the penalty term is expressed more precisely. It is shown that\nmodel uncertainty leads to the convexity of risk measures. As to applications,\nwe show how this multidimensional approach can be applied to measure the\ninsolvency risk of a firm with interacted subsidiaries; optimal risk sharing\nfor $\\protect\\gamma $-tolerant $g$-risk measures is investigated. Insurance\n$g$-risk measure and other ways to induce $g$-risk measures are also studied at\nthe end of the paper. \n\n"}
{"id": "1011.5020", "contents": "Title: Wavelet-Based Prediction for Governance, Diversification and Value\n  Creation Variables Abstract: We study the possibility of completing data bases of a sample of governance,\ndiversification and value creation variables by providing a well adapted method\nto reconstruct the missing parts in order to obtain a complete sample to be\napplied for testing the ownership-structure/diversification relationship. It\nconsists of a dynamic procedure based on wavelets. A comparison with Neural\nNetworks, the most used method, is provided to prove the efficiency of the\nhere-developed one. The empirical tests are conducted on a set of French firms. \n\n"}
{"id": "1012.0352", "contents": "Title: Casimir Effect at finite temperature for the Kalb-Ramond field Abstract: We use the thermofield dynamics (TFD) formalism to obtain the energy-momentum\ntensor for the Kalb-Ramond (KR) field in a topology $% S^{1}\\times S^{1}\\times\nR^{2}$. The compactification is carried out by a generalized TFD-Bogoliubov\ntransformation that is used to define a renormalized energy-momentum tensor.\nThe expressions for the Casimir energy and pressure at finite temperature are\nthen derived. A comparative analysis with the electromagnetic case is\ndeveloped, and the results may be important for applications, as in cuprate\nsuperconductivity, for instance. \n\n"}
{"id": "1012.1878", "contents": "Title: Heat Kernel Interest Rate Models with Time-Inhomogeneous Markov\n  Processes Abstract: We consider a heat kernel approach for the development of stochastic pricing\nkernels. The kernels are constructed by positive propagators, which are driven\nby time-inhomogeneous Markov processes. We multiply such a propagator with a\npositive, time-dependent and decreasing weight function, and integrate the\nproduct over time. The result is a so-called weighted heat kernel that by\nconstruction is a supermartingale with respect to the filtration generated by\nthe time-inhomogeneous Markov processes. As an application, we show how this\nframework naturally fits the information-based asset pricing framework where\ntime-inhomogeneous Markov processes are utilized to model partial information\nabout random economic factors. We present examples of pricing kernel models\nwhich lead to analytical formulae for bond prices along with explicit\nexpressions for the associated interest rate and market price of risk.\nFurthermore, we also address the pricing of fixed-income derivatives within\nthis framework. \n\n"}
{"id": "1012.2702", "contents": "Title: Long-range interactions between an atom in its ground S state and an\n  open-shell linear molecule Abstract: Theory of long-range interactions between an atom in its ground S state and a\nlinear molecule in a degenerate state with a non-zero projection of the\nelectronic orbital angular momentum is presented. It is shown how the\nlong-range coefficients can be related to the first and second-order molecular\nproperties. The expressions for the long-range coefficients are written in\nterms of all components of the static and dynamic multipole polarizability\ntensor, including the nonadiagonal terms connecting states with the opposite\nprojection of the electronic orbital angular momentum. It is also shown that\nfor the interactions of molecules in excited states that are connected to the\nground state by multipolar transition moments additional terms in the\nlong-range induction energy appear. All these theoretical developments are\nillustrated with the numerical results for systems of interest for the\nsympathetic cooling experiments: interactions of the ground state Rb($^2$S)\natom with CO($^3\\Pi$), OH($^2\\Pi$), NH($^1\\Delta$), and CH($^2\\Pi$) and of the\nground state Li($^2$S) atom with CH($^2\\Pi$). \n\n"}
{"id": "1012.5986", "contents": "Title: Bayesian estimation of GARCH model with an adaptive proposal density Abstract: A Bayesian estimation of a GARCH model is performed for US Dollar/Japanese\nYen exchange rate by the Metropolis-Hastings algorithm with a proposal density\ngiven by the adaptive construction scheme. In the adaptive construction scheme\nthe proposal density is assumed to take a form of a multivariate Student's\nt-distribution and its parameters are evaluated by using the sampled data and\nupdated adaptively during Markov Chain Monte Carlo simulations. We find that\nthe autocorrelation times between the data sampled by the adaptive construction\nscheme are considerably reduced. We conclude that the adaptive construction\nscheme works efficiently for the Bayesian inference of the GARCH model. \n\n"}
{"id": "1101.3107", "contents": "Title: Financial Rogue Waves Appearing in the Coupled Nonlinear Volatility and\n  Option Pricing Model Abstract: The coupled nonlinear volatility and option pricing model presented recently\nby Ivancevic is investigated, which generates a leverage effect, i.e., stock\nvolatility is (negatively) correlated to stock returns, and can be regarded as\na coupled nonlinear wave alternative of the Black-Scholes option pricing model.\nIn this short report, we analytically propose the two-component financial rogue\nwaves of the coupled nonlinear volatility and option pricing model without an\nembedded w-learning. Moreover, we exhibit their dynamical behaviors for chosen\ndifferent parameters. The two-component financial rogue wave solutions may be\nused to describe the possible physical mechanisms for the rogue wave phenomena\nand to further excite the possibility of relative researches and potential\napplications of rogue waves in the financial markets and other related fields. \n\n"}
{"id": "1101.4089", "contents": "Title: Resonant Regeneration in the Sub-Quantum Regime -- A demonstration of\n  fractional quantum interference Abstract: Light shining through wall experiments (in the optical as well as in the\nmicrowave regime) are a powerful tool to search for light particles coupled\nvery weakly to photons such as axions or extra hidden sector photons. Resonant\nregeneration, where a resonant cavity is employed to enhance the regeneration\nrate of photons, is one of the most promising techniques to improve the\nsensitivity of the next generation of experiments. However, doubts have been\nvoiced if such methods work at very low regeneration rates where on average the\ncavity contains less than one photon. In this note we report on a demonstration\nexperiment using a microwave cavity driven with extremely low power, to show\nthat resonant amplification works also in this regime. In accordance with\nstandard quantum mechanics this is a demonstration that interference also works\nat the level of less than one quantum. As an additional benefit this experiment\nshows that thermal photons inside the cavity cause no adverse effects. \n\n"}
{"id": "1102.1464", "contents": "Title: Two binomial coefficient conjectures Abstract: Much is known about binomial coefficients where primes are concerned, but\nconsiderably less is known regarding prime powers and composites. This paper\nprovides two conjectures in these directions, one about counting binomial\ncoefficients modulo 16 and one about the value of Binomial[n, 2p] modulo n. \n\n"}
{"id": "1102.1624", "contents": "Title: On the criticality of inferred models Abstract: Advanced inference techniques allow one to reconstruct the pattern of\ninteraction from high dimensional data sets. We focus here on the statistical\nproperties of inferred models and argue that inference procedures are likely to\nyield models which are close to a phase transition. On one side, we show that\nthe reparameterization invariant metrics in the space of probability\ndistributions of these models (the Fisher Information) is directly related to\nthe model's susceptibility. As a result, distinguishable models tend to\naccumulate close to critical points, where the susceptibility diverges in\ninfinite systems. On the other, this region is the one where the estimate of\ninferred parameters is most stable. In order to illustrate these points, we\ndiscuss inference of interacting point processes with application to financial\ndata and show that sensible choices of observation time-scales naturally yield\nmodels which are close to criticality. \n\n"}
{"id": "1102.2162", "contents": "Title: Integral points of bounded height on compactifications of semi-simple\n  groups Abstract: We study the asymptotic distribution of integral points of bounded height on\npartial bi-equivariant compactifications of semi-simple groups of adjoint type. \n\n"}
{"id": "1102.4230", "contents": "Title: Cooperation amongst competing agents in minority games Abstract: We study a variation of the minority game. There are N agents. Each has to\nchoose between one of two alternatives everyday, and there is reward to each\nmember of the smaller group. The agents cannot communicate with each other, but\ntry to guess the choice others will make, based only the past history of number\nof people choosing the two alternatives. We describe a simple probabilistic\nstrategy using which the agents acting independently, can still maximize the\naverage number of people benefitting every day. The strategy leads to a very\nefficient utilization of resources, and the average deviation from the maximum\npossible can be made of order $(N^{\\epsilon})$, for any $\\epsilon >0$. We also\nshow that a single agent does not expect to gain by not following the strategy. \n\n"}
{"id": "1102.5527", "contents": "Title: Permutation Complexity and the Letter Doubling Map Abstract: Given a countable set X (usually taken to be N or Z), an infinite permutation\n$\\pi$ of X is a linear ordering $<_\\pi$ of X. This paper investigates the\ncombinatorial complexity of infinite permutations on N associated with the\nimage of uniformly recurrent aperiodic binary words under the letter doubling\nmap. An upper bound for the complexity is found for general words, and a\nformula for the complexity is established for the Sturmian words and the\nThue-Morse word. \n\n"}
{"id": "1103.0606", "contents": "Title: Bayesian Model Choice of Grouped t-copula Abstract: One of the most popular copulas for modeling dependence structures is\nt-copula. Recently the grouped t-copula was generalized to allow each group to\nhave one member only, so that a priori grouping is not required and the\ndependence modeling is more flexible. This paper describes a Markov chain Monte\nCarlo (MCMC) method under the Bayesian inference framework for estimating and\nchoosing t-copula models. Using historical data of foreign exchange (FX) rates\nas a case study, we found that Bayesian model choice criteria overwhelmingly\nfavor the generalized t-copula. In addition, all the criteria also agree on the\nsecond most likely model and these inferences are all consistent with classical\nlikelihood ratio tests. Finally, we demonstrate the impact of model choice on\nthe conditional Value-at-Risk for portfolios of six major FX rates. \n\n"}
{"id": "1103.1050", "contents": "Title: Inf-convolution of g_\\Gamma-solution and its applications Abstract: A risk-neutral method is always used to price and hedge contingent claims in\ncomplete market, but another method based on utility maximization or risk\nminimization is wildly used in more general case. One can find all kinds of\nspecial risk measure in literature. In this paper, instead of using market\nmodified risk measure, we use a kind of risk measure induced by\ng_\\Gamma-solution or the minimal solution of a Constrained Backward Stochastic\nDifferential Equation (CBSDE) directly when constraints on wealth and portfolio\nprocess comes to our consideration. Such g_\\Gamma-solution and the risk measure\ngenerated by it is well defined on appropriate space under suitable conditions.\nWe adopt the inf-convolution of convex risk measures to solve some optimization\nproblem. A dynamic version risk measures defined through g_\\Gamma-solution and\nsome similar results about optimal problem can be got in our new framework and\nby our new approach. \n\n"}
{"id": "1103.2126", "contents": "Title: Trajectories of Rubber Balloons used in Balloon Releases: Theory and\n  Application Abstract: Balloon releases are one of the main attractions of many fairs. Helium filled\nrubber balloons are released to carry postcards over preferably long distances.\nAlthough such balloons have been considered in atmospheric sciences and air\nsafety analysis, there is only scarce literature available on the subject. This\nwork intends to close this gap by providing a comprehensive theoretical\noverview and a thorough analysis of real-life data. All relevant physical\nproperties of a rubber balloon are carefully modelled and supplemented by\nweather observations to form a self-contained trajectory simulation tool. The\nanalysis of diverse balloon releases provided detailed insight into the flight\ndynamics and potential optimisations. Helium balloons are found to reach\nroutinely altitudes above 10 km. Under optimal conditions, they could stay more\nthan 24 hours airborne while reaching flight distances close to 3000 km.\nHowever, external weather effects reduce the typical lifetime to 2-5 hours. \n\n"}
{"id": "1103.4541", "contents": "Title: Defaultable Bonds via HKA Abstract: To construct a no-arbitrage defaultable bond market, we work on the state\nprice density framework. Using the heat kernel approach (HKA for short) with\nthe killing of a Markov process, we construct a single defaultable bond market\nthat enables an explicit expression of a defaultable bond and credit spread\nunder quadratic Gaussian settings. Some simulation results show that the model\nis not only tractable but realistic. \n\n"}
{"id": "1104.1387", "contents": "Title: Resonant Leptogenesis with nonholomorphic R-Parity violation and LHC\n  Phenomenology Abstract: In R-parity violating supersymmetric models both leptogenesis and the correct\nneutrino masses are hard to achieve together. The presence of certain soft\nnonholomorphic R-parity violating terms helps to resolve this problem. We\nconsider a scenario where the lightest and the second-lightest neutralino are\nnearly degenerate in mass and enough CP-asymmetry can be produced through\nresonant leptogenesis. In this model, the lighter chargino and the lightest\nneutralino are highly degenerate. We have relatively lighter gauginos which can\nbe produced at the LHC leading to heavily ionizing charged tracks. At the same\ntime this model can also generate the correct neutrino mass scale. Thus our\nscenario is phenomenologically rich and testable at colliders. \n\n"}
{"id": "1104.1625", "contents": "Title: Magnetization Dissipation in Ferromagnets from Scattering Theory Abstract: The magnetization dynamics of ferromagnets are often formulated in terms of\nthe Landau-Lifshitz-Gilbert (LLG) equation. The reactive part of this equation\ndescribes the response of the magnetization in terms of effective fields,\nwhereas the dissipative part is parameterized by the Gilbert damping tensor. We\nformulate a scattering theory for the magnetization dynamics and map this\ndescription on the linearized LLG equation by attaching electric contacts to\nthe ferromagnet. The reactive part can then be expressed in terms of the static\nscattering matrix. The dissipative contribution to the low-frequency\nmagnetization dynamics can be described as an adiabatic energy pumping process\nto the electronic subsystem by the time-dependent magnetization. The Gilbert\ndamping tensor depends on the time derivative of the scattering matrix as a\nfunction of the magnetization direction. By the fluctuation-dissipation\ntheorem, the fluctuations of the effective fields can also be formulated in\nterms of the quasistatic scattering matrix. The theory is formulated for\ngeneral magnetization textures and worked out for monodomain precessions and\ndomain wall motions. We prove that the Gilbert damping from scattering theory\nis identical to the result obtained by the Kubo formalism. \n\n"}
{"id": "1104.4261", "contents": "Title: New results on the energy of integral circulant graphs Abstract: Circulant graphs are an important class of interconnection networks in\nparallel and distributed computing. Integral circulant graphs play an important\nrole in modeling quantum spin networks supporting the perfect state transfer as\nwell. The integral circulant graph $\\ICG_n (D)$ has the vertex set $Z_n = \\{0,\n1, 2, ..., n - 1\\}$ and vertices $a$ and $b$ are adjacent if $\\gcd(a-b,n)\\in\nD$, where $D \\subseteq \\{d : d \\mid n,\\ 1\\leq d<n\\}$. These graphs are highly\nsymmetric, have integral spectra and some remarkable properties connecting\nchemical graph theory and number theory. The energy of a graph was first\ndefined by Gutman, as the sum of the absolute values of the eigenvalues of the\nadjacency matrix. Recently, there was a vast research for the pairs and\nfamilies of non-cospectral graphs having equal energies. Following [R. B.\nBapat, S. Pati, \\textit{Energy of a graph is never an odd integer}, Bull.\nKerala Math. Assoc. 1 (2004) 129--132.], we characterize the energy of integral\ncirculant graph modulo 4. Furthermore, we establish some general closed form\nexpressions for the energy of integral circulant graphs and generalize some\nresults from [A. Ili\\' c, \\textit{The energy of unitary Cayley graphs}, Linear\nAlgebra Appl. 431 (2009), 1881--1889.]. We close the paper by proposing some\nopen problems and characterizing extremal graphs with minimal energy among\nintegral circulant graphs with $n$ vertices, provided $n$ is even. \n\n"}
{"id": "1104.5249", "contents": "Title: Two-stream-like instability in dilute hot relativistic beams and\n  astrophysical relativistic shocks Abstract: Relativistic collisionless shocks are believed to be efficient particle\naccelerators. Nonlinear outcome of the interaction of accelerated particles\nthat run ahead of the shock, the so-called \"precursor\", with the unperturbed\nplasma of the shock upstream, is thought to facilitate additional acceleration\nof these particles and to possibly modify the hydrodynamic structure of the\nshock. We explore here the linear growth of kinetic modes appearing in the\nprecursor-upstream interaction in relativistic shocks propagating in non and\nweakly magnetized plasmas: electrostatic two-stream parallel mode and\nelectrostatic oblique modes. These modes are of particular interest because\nthey are the fastest growing modes known in this type of system. Using a\nsimplified distribution function for a dilute ultra-relativistic beam that is\nrelativistically hot in its own rest frame, yet has momenta that are narrowly\ncollimated in the frame of the cold upstream plasma into which it propagates,\nwe identify the fastest growing mode in the full $k$-space and calculate its\ngrowth rate. We consider all types of plasma (pairs and ions-electrons) and\nbeam (charged and charge-neutral). We find that unstable electrostatic modes\nare present in any type of plasma and for any shock parameters. We further find\nthat two modes, one parallel ($k_\\perp=0$) and the other one oblique ($k_\\perp\n\\sim k_\\|$), are competing for dominance and that either one may dominate the\ngrowth rate in different regions of the phase space. The dominant mode is\ndetermined mostly by the perpendicular spread of the accelerated particle\nmomenta in the upstream frame, which reflects the shock Lorentz factor. The\nparallel mode becomes more dominant in shocks with lower Lorentz factors (i.e.,\nwith larger momentum spreads). We briefly discuss possible implications of our\nresults for external shocks in gamma-ray burst sources. \n\n"}
{"id": "1104.5527", "contents": "Title: Affine holomorphic quantization Abstract: We present a rigorous and functorial quantization scheme for affine field\ntheories, i.e., field theories where local spaces of solutions are affine\nspaces. The target framework for the quantization is the general boundary\nformulation, allowing to implement manifest locality without the necessity for\nmetric or causal background structures. The quantization combines the\nholomorphic version of geometric quantization for state spaces with the Feynman\npath integral quantization for amplitudes. We also develop an adapted notion of\ncoherent states, discuss vacuum states, and consider observables and their\nBerezin-Toeplitz quantization. Moreover, we derive a factorization identity for\nthe amplitude in the special case of a linear field theory modified by a\nsource-like term and comment on its use as a generating functional for a\ngeneralized S-matrix. \n\n"}
{"id": "1105.3180", "contents": "Title: The small-maturity smile for exponential Levy models Abstract: We derive a small-time expansion for out-of-the-money call options under an\nexponential Levy model, using the small-time expansion for the distribution\nfunction given in Figueroa-Lopez & Houdre (2009), combined with a change of\nnum\\'eraire via the Esscher transform. In particular, we quantify find that the\neffect of a non-zero volatility $\\sigma$ of the Gaussian component of the\ndriving L\\'{e}vy process is to increase the call price by $1/2\\sigma^2 t^2\ne^{k}\\nu(k)(1+o(1))$ as $t \\to 0$, where $\\nu$ is the L\\'evy density. Using the\nsmall-time expansion for call options, we then derive a small-time expansion\nfor the implied volatility, which sharpens the first order estimate given in\nTankov (2010). Our numerical results show that the second order approximation\ncan significantly outperform the first order approximation. Our results are\nalso extended to a class of time-changed L\\'evy models. We also consider a\nsmall-time, small log-moneyness regime for the CGMY model, and apply this\napproach to the small-time pricing of at-the-money call options. \n\n"}
{"id": "1105.6229", "contents": "Title: The Wilson Dirac Spectrum for QCD with Dynamical Quarks Abstract: All microscopic correlation functions of the spectrum of the Hermitian Wilson\nDirac operator with any number of flavors with equal masses are computed. In\nparticular, we give explicit results for the spectral density in the physical\ncase with two light quark flavors. The results include the leading effect in\nthe discretization error and are given for fixed index of the Wilson Dirac\noperator. They have been obtained starting from chiral Lagrangians for the\ngenerating function of the Dirac spectrum. Microscopic correlation functions of\nthe real eigenvalues of the Wilson Dirac operator are computed following the\nsame approach. \n\n"}
{"id": "1106.0184", "contents": "Title: Detection of the Pulsar Wind Nebula HESS J1825-137 with the Fermi Large\n  Area Telescope Abstract: We announce the discovery of 1 - 100 GeV gamma-ray emission from the\narchetypal TeV pulsar wind nebula HESS J1825-137 using 20 months of survey data\nfrom the Fermi Large Area Telescope (LAT). The gamma-ray emission detected by\nthe LAT is significantly spatially extended, with a best-fit rms extension of\nsigma = 0.56{\\deg} $\\pm$ 0.07{\\deg} for an assumed Gaussian model. The 1 - 100\nGeV LAT spectrum of this source is well described by a power-law with a\nspectral index of 1.38 $\\pm$ 0.12 $\\pm$ 0.16 and an integral flux above 1 GeV\nof (6.50 $\\pm$ 0.21 $\\pm$ 3.90) x 10^{-9} cm^{-2} s^{-1}. The first errors\nrepresent the statistical errors on the fit parameters, while the second ones\nare the systematic uncertainties. Detailed morphological and spectral analyses\nbring new constraints on the energetics and magnetic field of the pulsar wind\nnebula system. The spatial extent and hard spectrum of the GeV emission are\nconsistent with the picture of an inverse Compton origin of the GeV-TeV\nemission in a cooling-limited nebula powered by the pulsar PSR J1826-1334. \n\n"}
{"id": "1106.1395", "contents": "Title: Utility based pricing and hedging of jump diffusion processes with a\n  view to applications Abstract: We discuss utility based pricing and hedging of jump diffusion processes with\nemphasis on the practical applicability of the framework. We point out two\ndifficulties that seem to limit this applicability, namely drift dependence and\nessential risk aversion independence. We suggest to solve these by a\nre-interpretation of the framework. This leads to the notion of an implied\ndrift. We also present a heuristic derivation of the marginal indifference\nprice and the marginal optimal hedge that might be useful in numerical\ncomputations. \n\n"}
{"id": "1106.2095", "contents": "Title: Duality and Convergence for Binomial Markets with Friction Abstract: We prove limit theorems for the super-replication cost of European options in\na Binomial model with friction. The examples covered are markets with\nproportional transaction costs and the illiquid markets. The dual\nrepresentation for the super-replication cost in these models are obtained and\nused to prove the limit theorems. In particular, the existence of the liquidity\npremium for the continuous time limit of the model proposed in [6] is proved.\nHence, this paper extends the previous convergence result of [13] to the\ngeneral non-Markovian case. Moreover, the special case of small transaction\ncosts yields, in the continuous limit, the $G$-expectation of Peng as earlier\nproved by Kusuoka in [14]. \n\n"}
{"id": "1106.3007", "contents": "Title: The bi-stability jump as the origin for multiple P-Cygni absorption\n  components in Luminous Blue Variables Abstract: Luminous Blue Variables (LBVs) oftentimes show double-troughed absorption in\ntheir strong Halpha lines, which are as yet not understood. Intriguingly, the\nfeature has also been seen in the interacting supernova SN 2005gj, which was\nfor this reason suggested to have an LBV progenitor. Our aims are to understand\nthe double-troughed absorption feature in LBVs and investigate whether this\nphenomenon is related to wind variability. To this purpose, we perform\ntime-dependent radiative transfer modeling using CMFGEN. We find that abrupt\nchanges in the wind-terminal velocity - as expected from the bi-stability jump\n- are required to explain the double-troughed absorption profiles in LBVs. This\nstrengthens scenarios that discuss the link between LBVs and SNe utilizing the\nprogenitor's wind variability resulting from the bi-stability jump. We also\ndiscuss why the presence of double-troughed P-Cygni components may become an\nefficient tool to detect extra-galactic LBVs and how to analyze their mass-loss\nhistory on the basis of just one single epoch of spectral observations. \n\n"}
{"id": "1106.5040", "contents": "Title: Optimal High Frequency Trading with limit and market orders Abstract: We propose a framework for studying optimal market making policies in a limit\norder book (LOB). The bid-ask spread of the LOB is modelled by a Markov chain\nwith finite values, multiple of the tick size, and subordinated by the Poisson\nprocess of the tick-time clock. We consider a small agent who continuously\nsubmits limit buy/sell orders and submits market orders at discrete dates. The\nobjective of the market maker is to maximize her expected utility from revenue\nover a short term horizon by a tradeoff between limit and market orders, while\ncontrolling her inventory position. This is formulated as a mixed regime\nswitching regular/ impulse control problem that we characterize in terms of\nquasi-variational system by dynamic programming methods. In the case of a\nmean-variance criterion with martingale reference price or when the asset price\nfollows a Levy process and with exponential utility criterion, the dynamic\nprogramming system can be reduced to a system of simple equations involving\nonly the inventory and spread variables. Calibration procedures are derived for\nestimating the transition matrix and intensity parameters for the spread and\nfor Cox processes modelling the execution of limit orders. Several\ncomputational tests are performed both on simulated and real data, and\nillustrate the impact and profit when considering execution priority in limit\norders and market orders \n\n"}
{"id": "1107.2748", "contents": "Title: The explicit Laplace transform for the Wishart process Abstract: We derive the explicit formula for the joint Laplace transform of the Wishart\nprocess and its time integral which extends the original approach of Bru. We\ncompare our methodology with the alternative results given by the variation of\nconstants method, the linearization of the Matrix Riccati ODE's and the\nRunge-Kutta algorithm. The new formula turns out to be fast and accurate. \n\n"}
{"id": "1107.5720", "contents": "Title: An algorithm for calculating the set of superhedging portfolios in\n  markets with transaction costs Abstract: We study the explicit calculation of the set of superhedging portfolios of\ncontingent claims in a discrete-time market model for d assets with\nproportional transaction costs. The set of superhedging portfolios can be\nobtained by a recursive construction involving set operations, going backward\nin the event tree. We reformulate the problem as a sequence of linear vector\noptimization problems and solve it by adapting known algorithms. The\ncorresponding superhedging strategy can be obtained going forward in the tree.\nExamples are given involving multiple correlated assets and basket options.\nFurthermore, we relate existing algorithms for the calculation of the scalar\nsuperhedging price to the set-valued algorithm by a recent duality theory for\nvector optimization problems. The main contribution of the paper is to\nestablish the connection to linear vector optimization, which allows to solve\nnumerically multi-asset superhedging problems under transaction costs. \n\n"}
{"id": "1107.5807", "contents": "Title: Reconstruction of some cosmological models in f(R,T) gravity Abstract: In this paper, we reconstruct cosmological models in the framework of\n$f(R,T)$ gravity, where $R$ is the Ricci scalar and $T$ is the trace of the\nstress-energy tensor. We show that the dust fluid reproduces $\\Lambda $CDM,\nphantom-non-phantom era and the phantom cosmology. Further, we reconstruct\ndifferent cosmological models including, Chaplygin gas, scalar field with some\nspecific forms of $f(R,T)$. Our numerical simulation for Hubble parameter shows\ngood agreement with the BAO observational data for low redshifts $z<2$. \n\n"}
{"id": "1108.3386", "contents": "Title: Small-time expansions for local jump-diffusion models with infinite jump\n  activity Abstract: We consider a Markov process $X$, which is the solution of a stochastic\ndifferential equation driven by a L\\'{e}vy process $Z$ and an independent\nWiener process $W$. Under some regularity conditions, including non-degeneracy\nof the diffusive and jump components of the process as well as smoothness of\nthe L\\'{e}vy density of $Z$ outside any neighborhood of the origin, we obtain a\nsmall-time second-order polynomial expansion for the tail distribution and the\ntransition density of the process $X$. Our method of proof combines a recent\nregularizing technique for deriving the analog small-time expansions for a\nL\\'{e}vy process with some new tail and density estimates for jump-diffusion\nprocesses with small jumps based on the theory of Malliavin calculus, flow of\ndiffeomorphisms for SDEs, and time-reversibility. As an application, the\nleading term for out-of-the-money option prices in short maturity under a local\njump-diffusion model is also derived. \n\n"}
{"id": "1108.4058", "contents": "Title: Jet trails and Mach cones: The interaction of microquasars with the ISM Abstract: A sub-set of microquasars exhibit high peculiar velocity with respect to the\nlocal standard of rest due to the kicks they receive when being born in\nsupernovae. The interaction between the radio plasma released by microquasar\njets from such high-velocity binaries with the ISM must lead to the production\nof trails and bow shocks similar to what is observed in narrow-angle tailed\nradio galaxies and pulsar wind nebulae. We present a set of numerical\nsimulations of this interaction that illuminate the long term dynamical\nevolution and the observational properties of these microquasar bow shock\nnebulae and trails. We find that this interaction always produces a structure\nthat consists of a bow shock, a trailing neck, and an expanding bubble. Using\nour simulations to model emission, we predict that the shock surrounding the\nbubble and the neck should be visible in H{\\alpha} emission, the interior of\nthe bubble should be visible in synchrotron radio emission, and only the bow\nshock is likely to be detectable in X-ray emission. We construct an analytic\nmodel for the evolution of the neck and bubble shape and compare this model\nwith observations of X-ray binary SAX J1712.6-3739. \n\n"}
{"id": "1108.5572", "contents": "Title: Hadron production from $\\mu-Deuteron$ scattering at $\\sqrt{s}=17 GeV$ at\n  COMPASS Abstract: Hadrons proceeding from quasi-real photo-production are one of the many\nprobes accesible at the Common Muon Proton Apparatus for Structure and\nSpectroscopy (COMPASS) at CERN. These hadrons provide information on the\nscattering between photon and partons through \\gamma-gluon(g) direct channels\nas well as q-g resolved processes. Comparisons of unpolarized differential\ncross section measurements to next-to-leading order (NLO) pQCD calculations are\nessential to develop our understanding of proton-proton and lepton-nucleon\nscattering at varying center of mass energies. These measurements are important\nto asses the applicability of NLO pQCD in interpreting polarized processes. In\nthis talk we will present the unidentified charged separated hadron\ncross-sections measured by the COMPASS experiment at center of mass energy of\n\\sqrt{s}=17GeV, low Q^{2} (Q^{2}<0.1GeV^{2}/c^{2}) and high transverse momenta\n(p_{T}>1.0 GeV/c.) \n\n"}
{"id": "1108.5767", "contents": "Title: Neutrino trapping in braneworld extremely compact stars Abstract: Extremely Compact Stars (ECS) contain trapped null geodesics. When such\nobjects enter the evolution period admitting geodetical motion of neutrinos,\ncertain part of neutrinos produced in their interior will be trapped\ninfluencing their neutrino luminosity and thermal evolution. We study neutrino\ntrapping in the braneworld ECS, assuming uniform distribution of neutrino\nemissivity and massless neutrinos. We give the efficiency of the neutrino\ntrapping effects in the framework of the simple model of the internal spacetime\nwith uniform distribution of energy density, and external spacetime described\nby the Reissner-Nordstr\\\"om geometry characterized by the braneworld \"tidal\"\nparameter $b$. For $b < 0$ the external spacetime is of the black-hole type,\nwhile for $b > 0$ the external spacetime can be of both black-hole and\nnaked-singularity type. Then the ECS surface radius $R$ can be located also\nabove the unstable (outer) photon circular orbit. Such basically new types of\nthe spacetimes strongly alter the trapping phenomena as compared to the\nstandard case of $b = 0$. It is shown that the neutrino trapping effects are\nslightly lowered by the presence of physically more plausible case of $b < 0$,\nas compared to the standard internal Schwarzschild spacetime, while they can be\nmagnified by positive tidal charges if $b < 1$ and lowered for $b > 1$.\nHowever, potential astrophysical relevance of the trapping phenomena is\nstrongly enhanced for negative tidal charges enabling a significant enlargement\nof the ECS surface radius to values coherent with recent observations. \n\n"}
{"id": "1109.0435", "contents": "Title: The string prediction models as an invariants of time series in forex\n  market Abstract: In this paper we apply a new approach of the string theory to the real\nfinancial market. It is direct extension and application of the work [1] into\nprediction of prices. The models are constructed with an idea of prediction\nmodels based on the string invariants (PMBSI). The performance of PMBSI is\ncompared to support vector machines (SVM) and artificial neural networks (ANN)\non an artificial and a financial time series. Brief overview of the results and\nanalysis is given. The first model is based on the correlation function as\ninvariant and the second one is an application based on the deviations from the\nclosed string/pattern form (PMBCS). We found the difference between these two\napproaches. The first model cannot predict the behavior of the forex market\nwith good efficiency in comparison with the second one which is, in addition,\nable to make relevant profit per year. \n\n"}
{"id": "1109.1734", "contents": "Title: Gamma rays from extragalactic astrophysical sources Abstract: Presently there are several classes of detected gamma-ray extragalatic\nsources. They are mostly associated to active galactic nuclei (AGN) and (at\nsoft gamma rays) to gamma-ray bursts (GRB), but not only. Active galactic\nnuclei consist of accreting supermassive black holes hosted by a galaxy that\npresent in some cases powerful relativistic jet activity. These sources, which\nhave been studied in gamma rays for several decades, are probably the most\nenergetic astrophysical objects, and their appearance depends much on whether\ntheir jets point to us. Gamma-ray bursts, thought to be associated to\ncollapsing or merging stellar-mass objects at cosmological distances, are also\naccreting highly relativistic jet sources that shine strongly at high energies.\nThese are very short-duration events, but they are also the most luminous.\nRecently, star formation galaxies have turned out to be also gamma-ray\nemitters. On the other hand, clusters of galaxies have not been detected beyond\nX-rays yet. These are the largest known structures in the Universe; in their\nformation through accretion and merging, shocks and turbulence are generated,\nwhich may lead to gamma-ray production. In this work, the gamma-ray physics of\nAGNs is briefly presented, as well as that of starburst galaxies, GRBs and\nclusters of galaxies. Afterwards, we consider some particular cases of\ngamma-ray production in non-blazar AGN jets interacting with their medium at\ndifferent scales. \n\n"}
{"id": "1110.0674", "contents": "Title: Neutrino nucleus reactions within the GiBUU model Abstract: The GiBUU model, which implements all reaction channels relevant at medium\nneutrino energy, is used to investigate the neutrino and antineutrino\nscattering on iron. Results for integrated cross sections are compared with\nNOMAD and MINOS data. It is shown, that final state interaction can noticeably\nchange the spectra of the outgoing hadrons. Predictions for the Miner$\\nu$a\nexperiment are made for pion spectra, averaged over NuMI neutrino and\nantineutrino fluxes. \n\n"}
{"id": "1110.4924", "contents": "Title: Freeze-out yields of radioactivities in core-collapse supernovae Abstract: We explore the nucleosynthesis trends from two mechanisms during freeze-out\nexpansions in core-collapse supernovae. The first mechanism is related to the\nconvection and instabilities within homogeneous stellar progenitor matter that\nis accreted through the supernova shock. The second mechanism is related to the\nimpact of the supersonic wind termination shock (reverse shock) within the\ntumultuous inner regions of the ejecta above the proto-neutron star. Our\nresults suggest that isotopes in the mass range 12<=A<=122 that are produced\nduring the freeze-out expansions may be classified in two families. The\nisotopes of the first family manifest a common mass fraction evolutionary\nprofile, whose specific shape per isotope depends on the characteristic\ntransition between two equilibrium states (equilibrium state transition) during\neach type of freeze-out expansion. The first family includes the majority of\nisotopes in this mass range. The second family is limited to magic nuclei and\nisotopes in their locality, which do not sustain any transition, become nuclear\nflow hubs, and dominate the final composition. We use exponential and power-law\nadiabatic profiles to identify dynamic large-scale and small-scale equilibrium\npatterns among nuclear reactions. (truncated abstract) In addition, we\nintroduce non-monotonic parameterized profiles to probe the impact of the\nreverse shock and multi-dimensional explosion asymmetries on nucleosynthesis.\nCases are shown in which the non-monotonic profiles favor the production of\nradioactivities. Non-monotonic freeze-out profiles involve longer\nnon-equilibrium nucleosynthesis intervals compared with the exponential and\npower-law profiles, resulting in mass fraction trends and yield distributions\nthat may not be achieved by the monotonic freeze-out profiles. \n\n"}
{"id": "1110.5568", "contents": "Title: B -> rho K and B -> pi K^* decays in SCET Abstract: Exploring hints of New Physics in the decay modes B -> pi K^* and B -> rho K\ncan shed light on the B -> K pi puzzle. In this talk we discuss supersymmetric\ncontributions to the direct CP asymmetries of the decays B -> pi K^* and B ->\nrho K within Soft Collinear Effective Theory. We consider non-minimal flavor\nSUSY contributions mediated by gluino exchange and apply the Mass Insertion\nApproximation in the analysis. We show that gluino contributions can enhance\nthe CP asymmetries and accommodate the experimental results. \n\n"}
{"id": "1110.5594", "contents": "Title: Boundary-degenerate elliptic operators and Holder continuity for\n  solutions to variational equations and inequalities Abstract: The Heston stochastic volatility process, which is widely used as an asset\nprice model in mathematical finance, is a paradigm for a degenerate diffusion\nprocess where the degeneracy in the diffusion coefficient is proportional to\nthe square root of the distance to the boundary of the half-plane. The\ngenerator of this process with killing, called the elliptic Heston operator, is\na second-order, degenerate-elliptic partial differential operator whose\ncoefficients have linear growth in the spatial variables and where the\ndegeneracy in the operator symbol is proportional to the distance to the\nboundary of the half-plane. With the aid of weighted Sobolev spaces, we prove\nsupremum bounds, a Harnack inequality, and H\\\"older continuity near the\nboundary for solutions to variational equations defined by the elliptic Heston\noperator, as well as H\\\"older continuity up to the boundary for solutions to\nvariational inequalities defined by the elliptic Heston operator. In\nmathematical finance, solutions to obstacle problems for the elliptic Heston\noperator correspond to value functions for perpetual American-style options on\nthe underlying asset. \n\n"}
{"id": "1110.6418", "contents": "Title: GammaLib - A new framework for the analysis of Astronomical Gamma-Ray\n  Data Abstract: With the advent of a new generation of telescopes (INTEGRAL, Fermi, H.E.S.S.,\nMAGIC, VERITAS, MILAGRO) and the prospects of planned observatories such as CTA\nor HAWC, gamma-ray astronomy is becoming an integral part of modern\nastrophysical research. Analysing gamma-ray data is still a major challenge,\nand today relies on a large diversity of tools and software frameworks that\nwere specifically developed for each instrument. With the goal of facilitating\nand unifying the analysis of gamma-ray data, we are currently developing an\ninnovative data analysis toolbox, called the GammaLib, that enables gamma-ray\ndata analysis in an instrument independent way. We will present the basic ideas\nthat are behind the GammaLib, and describe its architecture and usage. \n\n"}
{"id": "1110.6774", "contents": "Title: The k-th Smallest Dirac Operator Eigenvalue and the Pion Decay Constant Abstract: We derive an analytical expression for the distribution of the k-th smallest\nDirac eigenvalue in QCD with imaginary isospin chemical potential in the Dirac\noperator. Because of its dependence on the pion decay constant F through the\nchemical potential in the epsilon-regime of chiral perturbation theory this can\nbe used for lattice determinations of that low-energy constant. On the\ntechnical side we use a chiral Random-Two Matrix Theory, where we express the\nk-th eigenvalue distribution through the joint probability of the ordered k\nsmallest eigenvalues. The latter can be computed exactly for finite and\ninfinite N, for which we derive generalisations of Dyson's integration Theorem\nand Sonine's identity. \n\n"}
{"id": "1111.0280", "contents": "Title: Generating Functionals and Lagrangian PDEs Abstract: We introduce the concept of Type-I/II generating functionals defined on the\nspace of boundary data of a Lagrangian field theory. On the Lagrangian side, we\ndefine an analogue of Jacobi's solution to the Hamilton-Jacobi equation for\nfield theories, and we show that by taking variational derivatives of this\nfunctional, we obtain an isotropic submanifold of the space of Cauchy data,\ndescribed by the so-called multisymplectic form formula. We also define a\nHamiltonian analogue of Jacobi's solution, and we show that this functional is\na Type-II generating functional. We finish the paper by defining a similar\nframework of generating functions for discrete field theories, and we show that\nfor the linear wave equation, we recover the multisymplectic conservation law\nof Bridges. \n\n"}
{"id": "1111.5802", "contents": "Title: Future Observations of Cosmic Magnetic Fields with the SKA and its\n  Precursors Abstract: The origin of magnetic fields in the Universe is an open problem in\nastrophysics and fundamental physics. Polarization observations with the\nforthcoming large radio telescopes, especially the Square Kilometre Array\n(SKA), will open a new era in the observation of magnetic fields and should\nhelp to understand their origin. Low-frequency radio synchrotron emission, to\nbe observed with LOFAR, MWA and the SKA, traces low-energy cosmic ray electrons\nand allows us to map the structure of weak magnetic fields in the outer regions\nand halos of galaxies, in halos and relics of galaxy clusters and in the Milky\nWay. Polarization at higher frequencies (1-10 GHz), to be observed with the SKA\nand its precursors ASKAP and MeerKAT, will trace magnetic fields in the disks\nand central regions of galaxies and in cluster relics in unprecedented detail.\nAll-sky surveys of Faraday rotation measures towards a dense grid of polarized\nbackground sources with ASKAP (project POSSUM) and the SKA are dedicated to\nmeasure magnetic fields in intervening galaxies, clusters and intergalactic\nfilaments, and will be used to model the overall structure and strength of\nmagnetic fields in the Milky Way. \"Cosmic Magnetism\" is key science for LOFAR,\nASKAP and the SKA. \n\n"}
{"id": "1111.6192", "contents": "Title: Comments on \"First Results of the Phase II SIMPLE Dark Matter Search\" Abstract: The SIMPLE Collaboration has reported results from their superheated C2ClF5\ndroplet detectors, including a description of acoustic discrimination between\n\\alpha decays and nuclear recoils. Our concern is that the events in the\nneutron calibration data and the events identified as neutrons in the physics\ndata are not drawn from the same parent distribution. This fact calls into\nquestion the identification of the background events as neutrons, the use of\nthe calibration data to define the acceptance of WIMP-induced nuclear recoils,\nand the observation of discrimination against \\alpha's. \n\n"}
{"id": "1111.6575", "contents": "Title: Reconstruction of f(T) gravity according to holographic dark energy Abstract: We develop the reconstruction of a model of $f(T)$ gravity according to the\nholographic dark energy. $T$ is the torsion scalar and its initial value from\nthe Teleparallel gravity is imposed for fitting the initial value of the\nfunction $f(T)$. The result shows a polynomial function for $f(T)$, and we also\nobserve that, when $\\Omega_V\\rightarrow 1$ at the future time, $\\omega_V$ may\ncross -1 for some values of the input parameter $b$. Another interesting aspect\nof the obtained model is that it provides the unification of the dark matter\nwith the dark energy. \n\n"}
{"id": "1111.7127", "contents": "Title: Quantum astrometric observables I: time delay in classical and quantum\n  gravity Abstract: A class of diffeomorphism invariant, physical observables, so-called\nastrometric observables, is introduced. A particularly simple example, the time\ndelay, which expresses the difference between two initially synchronized proper\ntime clocks in relative inertial motion, is analyzed in detail. It is found to\nsatisfy some interesting inequalities related to the causal structure of\nclassical Lorentzian spacetimes. Thus it can serve as a probe of causal\nstructure and in particular of violations of causality. A quantum model of this\nobservable as well as the calculation of its variance due to vacuum\nfluctuations in quantum linearized gravity are sketched. The question of\nwhether the causal inequalities are still satisfied by quantized gravity, which\nis pertinent to the nature of causality in quantum gravity, is raised, but it\nis shown that perturbative calculations cannot provide a definite answer. Some\npotential applications of astrometric observables in quantum gravity are\ndiscussed. \n\n"}
{"id": "1112.3885", "contents": "Title: Dissipative quantum light field engineering Abstract: We put forward a dissipative preparation scheme for strongly correlated\nphoton states. Our approach is based on a two-photon loss mechanism that is\nrealised via a single four-level atom inside a bimodal optical cavity. Each\nelementary two-photon emission event removes one photon out of each of the two\nmodes. The dark states of this loss mechanism are given by NOON states and\narbitrary superpositions thereof. We find that the steady state of the two\ncavity modes exhibits entanglement and for certain parameters, a mixture of two\ncoherent entangled states is produced. We discuss how the quantum correlations\nin the cavity modes and the output fields can be measured. \n\n"}
{"id": "1112.4176", "contents": "Title: Reply to \"Comment\" by A. V. Tsiganov Abstract: For the Goryachev case we obtain, in the explicit form, the Abel-Jacobi\nequations with the polynomial of degree six under the radical. We choose the\nparameters of two families of linear generators of a one sheet hyperboloid to\nbe the separation variables. These variables, as well as the shifted separation\nvariables in the original work of S. Kowalevski, do not commute. \n\n"}
{"id": "1112.4215", "contents": "Title: Frequency Multiplexed SQUID Readout of Large Bolometer Arrays for Cosmic\n  Microwave Background Measurements Abstract: A technological milestone for experiments employing Transition Edge Sensor\n(TES) bolometers operating at sub-kelvin temperature is the deployment of\ndetector arrays with 100s--1000s of bolometers. One key technology for such\narrays is readout multiplexing: the ability to read out many sensors\nsimultaneously on the same set of wires. This paper describes a\nfrequency-domain multiplexed readout system which has been developed for and\ndeployed on the APEX-SZ and South Pole Telescope millimeter wavelength\nreceivers. In this system, the detector array is divided into modules of seven\ndetectors, and each bolometer within the module is biased with a unique ~MHz\nsinusoidal carrier such that the individual bolometer signals are well\nseparated in frequency space. The currents from all bolometers in a module are\nsummed together and pre-amplified with Superconducting Quantum Interference\nDevices (SQUIDs) operating at 4 K. Room-temperature electronics demodulate the\ncarriers to recover the bolometer signals, which are digitized separately and\nstored to disk. This readout system contributes little noise relative to the\ndetectors themselves, is remarkably insensitive to unwanted microphonic\nexcitations, and provides a technology pathway to multiplexing larger numbers\nof sensors. \n\n"}
{"id": "1112.4444", "contents": "Title: The 400d Galaxy Cluster Survey weak lensing programme: II: Weak lensing\n  study of seven clusters with MMT/Megacam Abstract: Evolution in the mass function of galaxy clusters sensitively traces both the\nexpansion history of the Universe and cosmological structure formation. Robust\ncluster mass determinations are a key ingredient for a reliable measurement of\nthis evolution, especially at high redshift. Weak gravitational lensing is a\npromising tool for, on average, unbiased mass estimates. This weak lensing\nproject aims at measuring reliable weak lensing masses for a complete X-ray\nselected sample of 36 high redshift (0.35<z<0.9) clusters. The goal of this\npaper is to demonstrate the robustness of the methodology against commonly\nencountered problems, including pure instrumental effects, the presence of\nbright (8--9 mag) stars close to the cluster centre, ground based measurements\nof high-z (z~0.8) clusters, and the presence of massive unrelated structures\nalong the line-sight. We select a subsample of seven clusters observed with\nMMT/Megacam. Instrumental effects are checked in detail by cross-comparison\nwith an archival CFHT/MegaCam observation. We derive mass estimates for seven\nclusters by modelling the tangential shear with an NFW profile, in two cases\nwith multiple components to account for projected structures in the\nline-of-sight. We firmly detect lensing signals from all seven clusters at more\nthan $3.5\\sigma$ and determine their masses, ranging from $10^{14} M_{\\odot}$\nto $10^{15} M_{\\odot}$, despite the presence of nearby bright stars. We\nretrieve the lensing signal of more than one cluster in the CL 1701+6414 field,\nwhile apparently observing CL 1701+6414 through a massive foreground filament.\nWe also find a multi-peaked shear signal in CL 1641+4001. Shear structures\nmeasured in the MMT and CFHT images of CL 1701+6414 are highly correlated. \n\n"}
{"id": "1112.4824", "contents": "Title: A Schauder approach to degenerate-parabolic partial differential\n  equations with unbounded coefficients Abstract: Motivated by applications to probability and mathematical finance, we\nconsider a parabolic partial differential equation on a half-space whose\ncoefficients are suitably Holder continuous and allowed to grow linearly in the\nspatial variable and which become degenerate along the boundary of the\nhalf-space. We establish existence and uniqueness of solutions in weighted\nHolder spaces which incorporate both the degeneracy at the boundary and the\nunboundedness of the coefficients. In our companion article [arXiv:1211.4636],\nwe apply the main result of this article to show that the martingale problem\nassociated with a degenerate-elliptic partial differential operator is\nwell-posed in the sense of Stroock and Varadhan. \n\n"}
{"id": "1201.5868", "contents": "Title: Gauge Coupling Beta Functions in the Standard Model to Three Loops Abstract: In this paper we compute the three-loop corrections to the beta functions of\nthe three gauge couplings in the Standard Model of particle physics using the\nminimal subtraction scheme and taking into account Yukawa and Higgs self\ncouplings. \n\n"}
{"id": "1202.0142", "contents": "Title: Heavy-tails in economic data: fundamental assumptions, modelling and\n  analysis Abstract: The study of heavy-tailed distributions in economic and financial systems has\nbeen widely addressed since financial time series has become a research\nsubject.After the eighties, several \"highly improbable\" market drops were\nobserved (e.g. the 1987 stock market drop known as \"Black Monday\" and on even\nmore recent ones, already in the 21st century) that produce heavy losses that\nwere unexplainable in a GN environment. The losses incurred in these large\nmarket drop events did not change significantly the market practices or the way\nregulation is done but drove some attention back to the study of heavy-tails\nand their underlying mechanisms. Some recent findings in these context is the\nscope of this manuscript. \n\n"}
{"id": "1202.0473", "contents": "Title: On a decomposition lemma for positive semi-definite block-matrices Abstract: This short note, in part of expository nature, points out several new or\nrecent consequences of a quite nice decomposition for positive semi-definite\nmatrices. \n\n"}
{"id": "1202.0608", "contents": "Title: Perturbative Expansion of FBSDE in an Incomplete Market with Stochastic\n  Volatility Abstract: In this work, we apply our newly proposed perturbative expansion technique to\na quadratic growth FBSDE appearing in an incomplete market with stochastic\nvolatility that is not perfectly hedgeable. By combining standard asymptotic\nexpansion technique for the underlying volatility process, we derive explicit\nexpression for the solution of the FBSDE up to the third order of\nvolatility-of-volatility, which can be directly translated into the optimal\ninvestment strategy. We compare our approximation with the exact solution,\nwhich is known to be derived by the Cole-Hopf transformation in this popular\nsetup. The result is very encouraging and shows good accuracy of the\napproximation up to quite long maturities. Since our new methodology can be\nextended straightforwardly to multi-dimensional setups, we expect it will open\nreal possibilities to obtain explicit optimal portfolios or hedging strategies\nunder realistic assumptions. \n\n"}
{"id": "1202.0972", "contents": "Title: Symmetric Regularization, Reduction and Blow-Up of the Planar Three-Body\n  Problem Abstract: We carry out a sequence of coordinate changes for the planar three-body\nproblem which successively eliminate the translation and rotation symmetries,\nregularize all three double collision singularities and blow-up the triple\ncollision. Parametrizing the configurations by the three relative position\nvectors maintains the symmetry among the masses and simplifies the\nregularization of binary collisions. Using size and shape coordinates\nfacilitates the reduction by rotations and the blow-up of triple collision\nwhile emphasizing the role of the shape sphere. By using homogeneous\ncoordinates to describe Hamiltonian systems whose configurations spaces are\nspheres or projective spaces, we are able to take a modern, global approach to\nthese familiar problems. We also show how to obtain the reduced and regularized\ndifferential equations in several convenient local coordinates systems. \n\n"}
{"id": "1202.1096", "contents": "Title: Radio-to-TeV Phase-resolved Emission from the Crab Pulsar: The Annular\n  Gap Model Abstract: In the framework of the three-dimensional (3D) annular gap model with\nreasonable parameters (the magnetic inclination angle \\alpha = 45 deg and the\nview angle \\zeta = 63 deg), we first use the latest hight energy data to\nself-consistently calculate radio, X-ray, gamma-ray and TeV (MAGIC and VERITAS)\nlight curves, phase-averaged spectrum and phase-resolved spectra for the Crab\npulsar. It is found that the acceleration electric field and potential in the\nannular gap and core gap are huge enough in the several tens of neutron star\nradii. The pulsed emission of radio, X-ray, gamma-ray and TeV are mainly\ngenerated from the emission of primary particles or secondary particles with\ndifferent emission mechanisms in the nearly similar region of the annular gap\nlocated in the only one magnetic pole, which leads to the nearly\n\"phase-aligned\" multi-wavelength light curves. The emission of peak 1 (P1) and\npeak 2 (P2) is originated from the annular gap region near the null charge\nsurface, while the emission of bridge is mainly originated from the core gap\nregion. The phase-averaged spectrum and phase-resolved spectra of the Crab\npulsar from soft X-ray to TeV band are produced by four components: synchrotron\nradiation from CR-induced and ICS-induced pairs dominates the X-ray band to\nsoft gamma-ray band (100 eV to 10 MeV); curvature radiation and synchrotron\nradiation from the primary particles mainly contribute to gamma-ray band (10\nMeV to \\sim 20 GeV); ICS from the pairs significantly contributes to the TeV\ngamma-ray band (\\sim 20 GeV to 400 GeV). The multi-wavelength pulsed emission\nfrom the Crab pulsar has been well modeled with the annular gap and core gap\nmodel. To distinguish our single magnetic pole model from two-pole models, the\nconvincing values of the magnetic inclination angle and the viewing angle will\nplay a key role. \n\n"}
{"id": "1202.1160", "contents": "Title: Maximal Entropy Random Walk: solvable cases of dynamics Abstract: We focus on the study of dynamics of two kinds of random walk: generic random\nwalk (GRW) and maximal entropy random walk (MERW) on two model networks: Cayley\ntrees and ladder graphs. The stationary probability distribution for MERW is\ngiven by the squared components of the eigenvector associated with the largest\neigenvalue \\lambda_0 of the adjacency matrix of a graph, while the dynamics of\nthe probability distribution approaching to the stationary state depends on the\nsecond largest eigenvalue \\lambda_1.\n  Firstly, we give analytic solutions for Cayley trees with arbitrary branching\nnumber, root degree, and number of generations. We determine three regimes of a\ntree structure that result in different statics and dynamics of MERW, which are\ndue to strongly, critically, and weakly branched roots. We show how the\nrelaxation times, generically shorter for MERW than for GRW, scale with the\ngraph size.\n  Secondly, we give numerical results for ladder graphs with symmetric defects.\nMERW shows a clear exponential growth of the relaxation time with the size of\ndefective regions, which indicates trapping of a particle within highly\nentropic intact region and its escaping that resembles quantum tunneling\nthrough a potential barrier. GRW shows standard diffusive dependence\nirrespective of the defects. \n\n"}
{"id": "1203.1264", "contents": "Title: Quantum cost for sending entanglement Abstract: Establishing quantum entanglement between two distant parties is an essential\nstep of many protocols in quantum information processing. One possibility for\nproviding long-distance entanglement is to create an entangled composite state\nwithin a lab and then physically send one subsystem to a distant lab. However,\nis this the \"cheapest\" way? Here, we investigate the minimal \"cost\" that is\nnecessary for establishing a certain amount of entanglement between two distant\nparties. We prove that this cost is intrinsically quantum, and is specified by\nquantum correlations. Our results provide an optimal protocol for entanglement\ndistribution and show that quantum correlations are the essential resource for\nthis task. \n\n"}
{"id": "1203.2355", "contents": "Title: Small-time asymptotics of stopped L\\'evy bridges and simulation schemes\n  with controlled bias Abstract: We characterize the small-time asymptotic behavior of the exit probability of\na L\\'evy process out of a two-sided interval and of the law of its overshoot,\nconditionally on the terminal value of the process. The asymptotic expansions\nare given in the form of a first-order term and a precise computable error\nbound. As an important application of these formulas, we develop a novel\nadaptive discretization scheme for the Monte Carlo computation of functionals\nof killed L\\'evy processes with controlled bias. The considered functionals\nappear in several domains of mathematical finance (e.g., structural credit risk\nmodels, pricing of barrier options, and contingent convertible bonds) as well\nas in natural sciences. The proposed algorithm works by adding discretization\npoints sampled from the L\\'evy bridge density to the skeleton of the process\nuntil the overall error for a given trajectory becomes smaller than the maximum\ntolerance given by the user. \n\n"}
{"id": "1203.3328", "contents": "Title: COPAR - Multivariate time series modeling using the COPula\n  AutoRegressive model Abstract: Analysis of multivariate time series is a common problem in areas like\nfinance and economics. The classical tool for this purpose are vector\nautoregressive models. These however are limited to the modeling of linear and\nsymmetric dependence. We propose a novel copula-based model which allows for\nnon-linear and asymmetric modeling of serial as well as between-series\ndependencies. The model exploits the flexibility of vine copulas which are\nbuilt up by bivariate copulas only. We describe statistical inference\ntechniques for the new model and demonstrate its usefulness in three relevant\napplications: We analyze time series of macroeconomic indicators, of\nelectricity load demands and of bond portfolio returns. \n\n"}
{"id": "1203.4893", "contents": "Title: Production of $\\chi_{b}$-mesons at LHC Abstract: In the present paper, we discuss the $P$-wave bottomonium production within\nthe both color octet and color singlet models in NLO at LHC energies. We\ncalculate the production and the transverse momentum distributions of the\n$\\chi_{1,2b}$ states. We found, that the ratios of bottomonium and charmonium\nspin states are fundamentally complementary at different $p_T$ scales. We give\npredictions for the ratio of the $n=2$ and $n=1$ radial excitations production\ncross sections. \n\n"}
{"id": "1203.5729", "contents": "Title: Quantile Mechanics 3: Series Representations and Approximation of some\n  Quantile Functions appearing in Finance Abstract: It has long been agreed by academics that the inversion method is the method\nof choice for generating random variates, given the availability of the\nquantile function. However for several probability distributions arising in\npractice a satisfactory method of approximating these functions is not\navailable. The main focus of this paper will be to develop Taylor and\nasymptotic series expansions for the quantile functions belonging to the\nfollowing probability distributions; Variance Gamma, Generalized Inverse\nGaussian, Hyperbolic and alpha-Stable. As a secondary matter, based on these\nanalytic expressions we briefly investigate the problem of approximating the\nquantile function. \n\n"}
{"id": "1203.6877", "contents": "Title: The maximum maximum of a martingale with given $n$ marginals Abstract: We obtain bounds on the distribution of the maximum of a martingale with\nfixed marginals at finitely many intermediate times. The bounds are sharp and\nattained by a solution to $n$-marginal Skorokhod embedding problem in\nOb{\\l}\\'oj and Spoida [An iterated Az\\'ema-Yor type embedding for finitely many\nmarginals (2013) Preprint]. It follows that their embedding maximizes the\nmaximum among all other embeddings. Our motivating problem is superhedging\nlookback options under volatility uncertainty for an investor allowed to\ndynamically trade the underlying asset and statically trade European call\noptions for all possible strikes and finitely-many maturities. We derive a\npathwise inequality which induces the cheapest superhedging value, which\nextends the two-marginals pathwise inequality of Brown, Hobson and Rogers\n[Probab. Theory Related Fields 119 (2001) 558-578]. This inequality, proved by\nelementary arguments, is derived by following the stochastic control approach\nof Galichon, Henry-Labord\\`ere and Touzi [Ann. Appl. Probab. 24 (2014)\n312-336]. \n\n"}
{"id": "1204.0087", "contents": "Title: Ramanujan type congruences for modular forms of several variables Abstract: We give congruences between the Eisenstein series and a cusp form in the\ncases of Siegel modular forms and Hermitian modular forms. We should emphasize\nthat there is a relation between the existence of a prime dividing the $k-1$-th\ngeneralized Bernoulli number and the existence of non-trivial Hermitian cusp\nforms of weight $k$. We will conclude by giving numerical examples for each\ncase. \n\n"}
{"id": "1204.0915", "contents": "Title: Equivalence of interest rate models and lattice gases Abstract: We consider the class of short rate interest rate models for which the short\nrate is proportional to the exponential of a Gaussian Markov process x(t) in\nthe terminal measure r(t) = a(t) exp(x(t)). These models include the Black,\nDerman, Toy and Black, Karasinski models in the terminal measure. We show that\nsuch interest rate models are equivalent with lattice gases with attractive\ntwo-body interaction V(t1,t2)= -Cov(x(t1),x(t2)). We consider in some detail\nthe Black, Karasinski model with x(t) an Ornstein, Uhlenbeck process, and show\nthat it is similar with a lattice gas model considered by Kac and Helfand, with\nattractive long-range two-body interactions V(x,y) = -\\alpha (e^{-\\gamma |x -\ny|} - e^{-\\gamma (x + y)}). An explicit solution for the model is given as a\nsum over the states of the lattice gas, which is used to show that the model\nhas a phase transition similar to that found previously in the Black, Derman,\nToy model in the terminal measure. \n\n"}
{"id": "1204.2638", "contents": "Title: Perturbative Expansion Technique for Non-linear FBSDEs with Interacting\n  Particle Method Abstract: In this paper, we propose an efficient Monte Carlo implementation of\nnon-linear FBSDEs as a system of interacting particles inspired by the ideas of\nbranching diffusion method. It will be particularly useful to investigate large\nand complex systems, and hence it is a good complement of our previous work\npresenting an analytical perturbation procedure for generic non-linear FBSDEs.\nThere appear multiple species of particles, where the first one follows the\ndiffusion of the original underlying state, and the others the Malliavin\nderivatives with a grading structure. The number of branching points are capped\nby the order of perturbation, which is expected to make the scheme less\nnumerically intensive. The proposed method can be applied to semi-linear\nproblems, such as American and Bermudan options, Credit Value Adjustment (CVA),\nand even fully non-linear issues, such as the optimal portfolio problems in\nincomplete and/or constrained markets, feedbacks from large investors, and also\nthe analysis of various risk measures. \n\n"}
{"id": "1204.3326", "contents": "Title: Majorana qubit decoherence by quasiparticle poisoning Abstract: We consider the problem of quasiparticle poisoning in a nanowire-based\nrealization of a Majorana qubit, where a spin-orbit-coupled semiconducting wire\nis placed on top of a (bulk) superconductor. By making use of recent\nexperimental data exhibiting evidence of a low-temperature residual\nnon-equilibrium quasiparticle population in superconductors, we show by means\nof analytical and numerical calculations that the dephasing time due to the\ntunneling of quasiparticles into the nanowire may be problematically short to\nallow for qubit manipulation. \n\n"}
{"id": "1204.4877", "contents": "Title: Optimal simulation schemes for L\\'evy driven stochastic differential\n  equations Abstract: We consider a general class of high order weak approximation schemes for\nstochastic differential equations driven by L\\'evy processes with infinite\nactivity. These schemes combine a compound Poisson approximation for the jump\npart of the L\\'evy process with a high order scheme for the Brownian driven\ncomponent, applied between the jump times. The overall approximation is\nanalyzed using a stochastic splitting argument. The resulting error bound\ninvolves separate contributions of the compound Poisson approximation and of\nthe discretization scheme for the Brownian part, and allows, on one hand, to\nbalance the two contributions in order to minimize the computational time, and\non the other hand, to study the optimal design of the approximating compound\nPoisson process. For driving processes whose L\\'evy measure explodes near zero\nin a regularly varying way, this procedure allows to construct discretization\nschemes with arbitrary order of convergence. \n\n"}
{"id": "1205.6097", "contents": "Title: Evidence for the higher twists effects in diffractive DIS at HERA Abstract: We study a twist decomposition of diffractive structure functions in the\ndiffractive deep inelastic scattering at HERA. At low $Q^2$ and at large energy\nthe data exhibit a strong deviation from the twist-2 NLO DGLAP description. It\nis found that this deviation in consistent with higher twist effects. We\nconclude that the DDIS at HERA provides the first, strong evidence of higher\ntwist effects in DIS. \n\n"}
{"id": "1206.0831", "contents": "Title: C^{1,1} regularity for degenerate elliptic obstacle problems Abstract: The Heston stochastic volatility process is a degenerate diffusion process\nwhere the degeneracy in the diffusion coefficient is proportional to the square\nroot of the distance to the boundary of the half-plane. The generator of this\nprocess with killing, called the elliptic Heston operator, is a second-order,\ndegenerate-elliptic partial differential operator, where the degeneracy in the\noperator symbol is proportional to the distance to the boundary of the\nhalf-plane. In mathematical finance, solutions to the obstacle problem for the\nelliptic Heston operator correspond to value functions for perpetual\nAmerican-style options on the underlying asset. With the aid of weighted\nSobolev spaces and weighted Holder spaces, we establish the optimal $C^{1,1}$\nregularity (up to the boundary of the half-plane) for solutions to obstacle\nproblems for the elliptic Heston operator when the obstacle functions are\nsufficiently smooth. \n\n"}
{"id": "1206.1504", "contents": "Title: Preliminary remarks on option pricing and dynamic hedging Abstract: An elementary arbitrage principle and the existence of trends in financial\ntime series, which is based on a theorem published in 1995 by P. Cartier and Y.\nPerrin, lead to a new understanding of option pricing and dynamic hedging.\nIntricate problems related to violent behaviors of the underlying, like the\nexistence of jumps, become then quite straightforward by incorporating them\ninto the trends. Several convincing computer experiments are reported. \n\n"}
{"id": "1206.2333", "contents": "Title: An algorithm for the orthogonal decomposition of financial return data Abstract: We present an algorithm for the decomposition of periodic financial return\ndata into orthogonal factors of expected return and \"systemic\", \"productive\",\nand \"nonproductive\" risk. Generally, when the number of funds does not exceed\nthe number of periods, the expected return of a portfolio is an affine function\nof its productive risk. \n\n"}
{"id": "1206.2757", "contents": "Title: Role of delay in the mechanism of cluster formation Abstract: We study the role of delay in phase synchronization and phenomena responsible\nfor cluster formation in delayed coupled maps on various networks. Using\nnumerical simulations, we demonstrate that the presence of delay may change the\nmechanism of unit to unit interaction. At weak coupling values, same parity\ndelays are associated with the same phenomenon of cluster formation and exhibit\nsimilar dynamical evolution. Intermediate coupling values yield rich\ndelay-induced driven cluster patterns. A Lyapunov function analysis sheds light\non the robustness of the driven clusters observed for delayed bipartite\nnetworks. Our results reveal that delay may lead to a completely different\nrelation, between dynamical and structural clusters, than observed for the\nundelayed case. \n\n"}
{"id": "1206.2934", "contents": "Title: A Numerical Scheme Based on Semi-Static Hedging Strategy Abstract: In the present paper, we introduce a numerical scheme for the price of a\nbarrier option when the price of the underlying follows a diffusion process.\nThe numerical scheme is based on an extension of a static hedging formula of\nbarrier options. For getting the static hedging formula, the underlying process\nneeds to have a symmetry. We introduce a way to \"symmetrize\" a given diffusion\nprocess. Then the pricing of a barrier option is reduced to that of plain\noptions under the symmetrized process. To show how our symmetrization scheme\nworks, we will present some numerical results applying (path-independent)\nEuler-Maruyama approximation to our scheme, comparing them with the\npath-dependent Euler-Maruyama scheme when the model is of the Black-Scholes,\nCEV, Heston, and $ (\\lambda) $-SABR, respectively. The results show the\neffectiveness of our scheme. \n\n"}
{"id": "1206.3212", "contents": "Title: All noncontextuality inequalities for the n-cycle scenario Abstract: The problem of separating classical from quantum correlations is in general\nintractable and has been solved explicitly only in few cases. In particular,\nknown methods cannot provide general solutions for an arbitrary number of\nsettings. We provide the complete characterization of the classical\ncorrelations and the corresponding maximal quantum violations for the case of n\n>= 4 observables X_0, ...,X_{n-1}, where each consecutive pair {X_i,X_{i+1}},\nsum modulo n, is jointly measurable. This generalizes both the\nClauser-Horne-Shimony-Holt and the Klyachko-Can-Binicioglu-Shumovsky scenarios,\nwhich are the simplest ones for, respectively, locality and noncontextuality.\nIn addition, we provide explicit quantum states and settings with maximal\nquantum violation and minimal quantum dimension. \n\n"}
{"id": "1206.3989", "contents": "Title: Effect of Light Fermions on the Confinement Transition in QCD-like\n  Theories Abstract: Dependence of the confinement transition parameters on the fermion content\nprovides information on the mechanism of confinement. Recent progress in\nlattice gauge theories has allowed to study it for light flavor number $N_f\\sim\nO(10)$ and found this transition to shift toward significantly stronger\ncoupling. We propose an explanation for that: light fermions can occupy the\nchromo-magnetic monopoles, via zero modes, making them \"distinguishable\" and\nunsuitable for Bose-Einstein Condensation. Such dilution of unoccuplied\nmonopoles is compensated by stronger coupling that makes them lighter and more\nnumerous. We also suggest that flavor-carrying quark-monopole objects account\nfor the density beyond quark Fermi sphere seen in cold dense phase of $N_c=2$\nlattice QCD. \n\n"}
{"id": "1206.4721", "contents": "Title: Pion and kaon elastic form factors in a refined light-front model Abstract: Within the framework of light-front field theory, we reassess the\nelectromagnetic form factors of the pion and kaon. Comparison with experiment\nis made for the full range of momentum transfer, q^2<0, including recent data.\nThe light-front model's single regulator mass, m_R, of the \\bar qq bound-state\nvertex function is initially adjusted to reproduce the weak decay constants,\nf_\\pi\\ and f_K, and both meson's charge radii, r_\\pi\\ and r_K. We study the\nbehavior of these observables under variation of the quark masses and find an\noptimized parameter set, m_u=m_d, m_s and m_R, for which they are in sensibly\nbetter agreement with experiment than in a previous analysis; a feature also\nobserved for the elastic form factors, in particular at small q^2. This model\nrefinement is important in view of an extension to vector and heavy-light\nmesons. \n\n"}
{"id": "1206.4804", "contents": "Title: A No-Arbitrage Model of Liquidity in Financial Markets involving\n  Brownian Sheets Abstract: We consider a dynamic market model where buyers and sellers submit limit\norders. If at a given moment in time, the buyer is unable to complete his\nentire order due to the shortage of sell orders at the required limit price,\nthe unmatched part of the order is recorded in the order book. Subsequently\nthese buy unmatched orders may be matched with new incoming sell orders. The\nresulting demand curve constitutes the sole input to our model. The clearing\nprice is then mechanically calculated using the market clearing condition. We\nuse a Brownian sheet to model the demand curve, and provide some theoretical\nassumptions under which such a model is justified.\n  Our main result is the proof that if there exists a unique equivalent\nmartingale measure for the clearing price, then under some mild assumptions\nthere is no arbitrage. We use the Ito- Wentzell formula to obtain that result,\nand also to characterize the dynamics of the demand curve and of the clearing\nprice in the equivalent measure. We find that the volatility of the clearing\nprice is (up to a stochastic factor) inversely proportional to the sum of buy\nand sell order flow density (evaluated at the clearing price), which confirms\nthe intuition that volatility is inversely proportional to volume. We also\ndemonstrate that our approach is implementable. We use real order book data and\nsimulate option prices under a particularly simple parameterization of our\nmodel.\n  The no-arbitrage conditions we obtain are applicable to a wide class of\nmodels, in the same way that the Heath-Jarrow-Morton conditions apply to a wide\nclass of interest rate models. \n\n"}
{"id": "1207.0105", "contents": "Title: Optimal inferential models for a Poisson mean Abstract: Statistical inference on the mean of a Poisson distribution is a\nfundamentally important problem with modern applications in, e.g., particle\nphysics. The discreteness of the Poisson distribution makes this problem\nsurprisingly challenging, even in the large-sample case. Here we propose a new\napproach, based on the recently developed framework of inferential models\n(IMs). Specifically, we construct optimal, or at least approximately optimal,\nIMs for two important classes of assertions/hypotheses about the Poisson mean.\nFor point assertions, we develop a novel recursive sorting algorithm to\nconstruct this optimal IM. Numerical comparisons of the proposed method to\nexisting methods are given, for both the mean and the more challenging\nmean-plus-background problem. \n\n"}
{"id": "1207.0233", "contents": "Title: From characteristic functions to implied volatility expansions Abstract: For any strictly positive martingale $S = \\exp(X)$ for which $X$ has a\ncharacteristic function, we provide an expansion for the implied volatility.\nThis expansion is explicit in the sense that it involves no integrals, but only\npolynomials in the log strike. We illustrate the versatility of our expansion\nby computing the approximate implied volatility smile in three well-known\nmartingale models: one finite activity exponential L\\'evy model (Merton), one\ninfinite activity exponential L\\'evy model (Variance Gamma), and one stochastic\nvolatility model (Heston). Finally, we illustrate how our expansion can be used\nto perform a model-free calibration of the empirically observed implied\nvolatility surface. \n\n"}
{"id": "1207.0750", "contents": "Title: The Exact Smile of some Local Volatility Models Abstract: We introduce a new class of local volatility models. Within this framework,\nwe obtain expressions for both (i) the price of any European option and (ii)\nthe induced implied volatility smile. As an illustration of our framework, we\nperform specific pricing and implied volatility computations for a CEV-like\nexample. Numerical examples are provided. \n\n"}
{"id": "1207.5352", "contents": "Title: Zero energy bound states in tunneling conductance spectra at the\n  interface of an s-wave superconductor and a topological insulator in\n  NbN-$Bi_2Se_3$-Au thin film junctions Abstract: Measurements of conductance spectra in a superconductor - topological\ninsulator - normal metal thin film junctions of NbN-$\\rm Bi_2Se_3$-Au are\nreported. Junctions with ex-situ and in-situ prepared $\\rm NbN-Bi_2Se_3$\ninterfaces were studied. At low temperatures, all the ex-situ junctions showed\ncoherence peaks in their conductance spectra, but imbedded robust zero bias\nconductance peaks were observed only in junctions with a metallic or a metal to\ninsulator transition below $\\rm T_c$ of the NbN electrode. The in-situ\njunctions which had about two orders of magnitude lower resistance at low\ntemperatures, generally showed flat conductance spectra at low bias, with no\ncoherence or broad Andreev peaks, since the critical current of the NbN\nelectrode was reached first, at voltage bias below the energy gap of the\nsuperconductor. A weak zero bias conductance peak however, was observed in one\nof these junctions. We conclude that significant tunneling barriers, as in the\nex-situ prepared junctions, are essential for the observation of coherence\npeaks and the zero energy bound states. The later seem to originate in the $\\rm\nBi_2Se_3$-NbN interface, as they are absent in reference Au-NbN junctions\nwithout the topological layer sandwiched in between. \n\n"}
{"id": "1207.5809", "contents": "Title: A control problem with fuel constraint and Dawson-Watanabe\n  superprocesses Abstract: We solve a class of control problems with fuel constraint by means of the\nlog-Laplace transforms of $J$-functionals of Dawson-Watanabe superprocesses.\nThis solution is related to the superprocess solution of quasilinear parabolic\nPDEs with singular terminal condition. For the probabilistic verification\nproof, we develop sharp bounds on the blow-up behavior of log-Laplace\nfunctionals of $J$-functionals, which might be of independent interest. \n\n"}
{"id": "1207.6469", "contents": "Title: Singlet Ground State of the Quantum Antiferromagnet Ba3CuSb2O9 Abstract: We present local probe results on the honeycomb lattice antiferromagnet\nBa3CuSb2O9. Muon spin relaxation measurements in zero field down to 20 mK show\nunequivocally that there is a total absence of spin freezing in the ground\nstate. Sb NMR measurements allow us to track the intrinsic susceptibility of\nthe lattice, which shows a maximum at around 55 K and drops to zero in the\nlow-temperature limit. The spin-lattice relaxation rate shows two\ncharacteristic energy scales, including a field-dependent crossover to\nexponential low-temperature behavior, implying gapped magnetic excitations. \n\n"}
{"id": "1207.6566", "contents": "Title: Conditional sampling for barrier option pricing under the Heston model Abstract: We propose a quasi-Monte Carlo algorithm for pricing knock-out and knock-in\nbarrier options under the Heston (1993) stochastic volatility model. This is\ndone by modifying the LT method from Imai and Tan (2006) for the Heston model\nsuch that the first uniform variable does not influence the stochastic\nvolatility path and then conditionally modifying its marginals to fulfill the\nbarrier condition(s). We show this method is unbiased and never does worse than\nthe unconditional algorithm. Additionally the conditioning is combined with a\nroot finding method to also force positive payouts. The effectiveness of this\nmethod is shown by extensive numerical results. \n\n"}
{"id": "1207.6569", "contents": "Title: Higher-order Kerr improve quantitative modeling of laser filamentation Abstract: We test numerical filamentation models against experimental data about the\npeak intensity and filament density in laser filaments. We show that the\nconsideration of the higher-order Kerr effect (HOKE) improves the quantitative\nagreement without the need of adjustable parameters. \n\n"}
{"id": "1208.2422", "contents": "Title: High Mass X-ray Binaries: Future Evolution and Fate Abstract: BH-NS and BH-BH systems are among the most promising gravitational wave\nsources detectable by advanced LIGO/VIRGO and the Einstein Telescope. Although\nthe rates of these systems may be above those of NS-NS mergers, BH-NS and BH-BH\nsystems are difficult to detect, and thusfar none have been observed. But the\nprogenitors of BH-NS and BH-BH binary systems may have been observed, in the\nform of High-Mass X-ray Binaries (HMXBs). In this paper, we continue work\nstudying these potential progenitors of these important gravitational wave\nsources. In the first two papers of the series, we have demonstrated that IC10\nX-1 and NGC300 X-1 are direct progenitors of BH-BH systems and that Cyg X-1 may\nform, alas with a very low probability, a BH-NS system. Here, we analyze the\nGalactic binaries GX 301-2, Vela X-1, XTEJ1855-026, 4U1907+09, Cir X-1 and\nextra-galactic LMC X-1, LMC X-3, M33 X-1. In each case, we find that the future\nevolution will not allow the formation of a BH-NS nor a BH-BH system. Most of\nthese binaries will soon merge in the common envelope phase, with a compact\nobject sinking into a helium-rich core of a stellar companion. This\n\"helium-merger\" may be a progenitor for long duration gamma-ray bursts (GRBs).\nBased on the observed HMXB population, the rate of helium-mergers may make up a\nsizable fraction of long-duration GRBs. Due to this high number of potential\nGRB progenitors, a chance that a Galactic HMXB has caused one of the recent\nmajor mass extinction events is significant (10-20%). \n\n"}
{"id": "1208.2658", "contents": "Title: Degenerate-elliptic operators in mathematical finance and higher-order\n  regularity for solutions to variational equations Abstract: We establish higher-order weighted Sobolev and Holder regularity for\nsolutions to variational equations defined by the elliptic Heston operator, a\nlinear second-order degenerate-elliptic operator arising in mathematical\nfinance. Furthermore, given $C^\\infty$-smooth data, we prove\n$C^\\infty$-regularity of solutions up to the portion of the boundary where the\noperator is degenerate. In mathematical finance, solutions to obstacle problems\nfor the elliptic Heston operator correspond to value functions for perpetual\nAmerican-style options on the underlying asset. \n\n"}
{"id": "1208.3023", "contents": "Title: Bound States of Conical Singularities in Graphene-Based Topological\n  Insulators Abstract: We investigate the electronic structure induced by wedge-disclinations\n(conical singularities) in a honeycomb lattice model realizing Chern numbers\n$\\gamma=\\pm 1$. We establish a correspondence between the bound state of (i) an\nisolated $\\Phi_0/2$-flux, (ii) an isolated pentagon $(n=1)$ or heptagon\n$(n=-1)$ defect with an external flux of magnitude $n\\gamma \\Phi_0/4$ through\nthe center and (iii) an isolated square or octagon defect without external\nflux, where $\\Phi_0=h/e$ is the flux quantum. Due to the above correspondence,\nthe existence of isolated electronic states bound to the disclinations is\nrobust against various perturbations. These results are also generalized to\ngraphene-based time-reversal invariant topological insulators. \n\n"}
{"id": "1208.4198", "contents": "Title: Chemical evolution and the galactic habitable zone of M31 (the Andromeda\n  Galaxy) Abstract: We have computed the Galactic Habitable Zones (GHZs) of the Andromeda galaxy\n(M31) based on the probability of terrestrial planet formation, which depends\non the metallicity (Z) of the interstellar medium, and the number of formed\nstars per surface unit. The GHZ was therefore obtained from a chemical\nevolution model built to reproduce a precise metallicity gradient in the\ngalactic disk, [O/H](r) $ = -0.015 \\pm 0.003 dex kpc^{-1} x r(kpc) + 0.44 \\pm\n0.04 dex $. This gradient is the most probable when intrinsic scatter is\npresent in the observational data. The chemical evolution model predicted a\nhigher star formation history in both the halo and disk components of M31 and a\nless efficient inside-out galactic formation, compared to those of the Milky\nWay. If we assumed that Earth-like planets form with a probability law that\nfollows the Z distribution shown by stars with detected planets and the SFH\npredicted by the CEM, the most probable GHZ per pc$^2$ is located between 3 and\n7 kpc for planets with ages between 6 and 7 Gy, approximately. But the highest\nnumber of stars with habitable planets is in a ring located between 12 and 14\nkpc with mean age of $\\sim$7 Gy. 11 % and 6.5 % of the all formed stars in M31\nmay have planets with basic and complex life, respectively. \n\n"}
{"id": "1209.0120", "contents": "Title: Decoherence-Free Communication over Multiaccess Quantum Channels Abstract: In this paper we consider decoherence-free communication over multiple access\nand $k$-user quantum channels. First, we concentrate on a hermitian unitary\nnoise model $U$ for a two-access bi-unitary channel and show that in this case\na decoherence-free code exists if the space of Schmidt matrices of an\neigensubspace of $U$ exhibits certain properties of decomposability. Then, we\nshow that our technique is also applicable for generic random unitary\ntwo-access channels. Finally, we consider the applicability of the result to\nthe case of a larger number of senders and general Kraus operators. \n\n"}
{"id": "1209.0390", "contents": "Title: First order strong approximations of scalar SDEs with values in a domain Abstract: We are interested in strong approximations of one-dimensional SDEs which have\nnon-Lipschitz coefficients and which take values in a domain. Under a set of\ngeneral assumptions we derive an implicit scheme that preserves the domain of\nthe SDEs and is strongly convergent with rate one. Moreover, we show that this\ngeneral result can be applied to many SDEs we encounter in mathematical finance\nand bio-mathematics. We will demonstrate flexibility of our approach by\nanalysing classical examples of SDEs with sublinear coefficients (CIR, CEV\nmodels and Wright-Fisher diffusion) and also with superlinear coefficients\n(3/2-volatility, Ait-Sahalia model).\n  Our goal is to justify an efficient Multi-Level Monte Carlo (MLMC) method for\na rich family of SDEs, which relies on good strong convergence properties. \n\n"}
{"id": "1209.1545", "contents": "Title: Universal contact for a Tonks-Girardeau gas at finite temperature Abstract: We determine the finite-temperature momentum distribution of a strongly\ninteracting 1D Bose gas in the Tonks-Girardeau (impenetrable-boson) limit under\nharmonic confinement, and explore its universal properties associated to the\nscale invariance of the model. We show that, at difference from the unitary\nFermi gas in three dimensions, the weight of its large-momentum tails -- given\nby the Tan's contact -- increase with temperature, and calculate the\nhigh-temperature universal second contact coefficient using a virial expansion. \n\n"}
{"id": "1209.1845", "contents": "Title: Exact Half-BPS Flux Solutions in M-theory with $D(2, 1; c'; 0)^2$\n  Symmetry: Local Solutions Abstract: We construct local solutions to 11-dimensional supergravity (or M-theory),\nwhich are invariant under the superalgebra $D(2, 1; c'; 0)\\oplus D(2, 1; c';\n0)$ for all values of the parameter $c'$. The BPS constraints are reduced to a\nsingle linear PDE on a complex function $G$. The PDE was solved in 0806.0605\nmodulo application of boundary and regularity conditions. The physical fields\nof the solutions are determined by $c'$, a harmonic function $h$, and the\ncomplex function $G$. $ h$ and $G$ are both functions on a 2-dimensional\ncompact Riemannian manifold. The harmonic function $ h$ is freely chosen. We\nobtain the expressions for the metric and the field strength in terms of $G$,\n$h$, and $c'$ and show that these are indeed valid solutions of the Einstein,\nMaxwell, and Bianchi equations. Finally we give a construction of one parameter\ndeformations of $AdS_7 \\times S^4$ and $AdS_4 \\times S^7$ as a function of\n$c'$. \n\n"}
{"id": "1209.3503", "contents": "Title: Pricing Illiquid Options with $N+1$ Liquid Proxies Using Mixed\n  Dynamic-Static Hedging Abstract: We study the problem of optimal pricing and hedging of a European option\nwritten on an illiquid asset $Z$ using a set of proxies: a liquid asset $S$,\nand $N$ liquid European options $P_i$, each written on a liquid asset $Y_i,\ni=1,N$. We assume that the $S$-hedge is dynamic while the multi-name $Y$-hedge\nis static. Using the indifference pricing approach with an exponential utility,\nwe derive a HJB equation for the value function, and build an efficient\nnumerical algorithm. The latter is based on several changes of variables, a\nsplitting scheme, and a set of Fast Gauss Transforms (FGT), which turns out to\nbe more efficient in terms of complexity and lower local space error than a\nfinite-difference method. While in this paper we apply our framework to an\nincomplete market version of the credit-equity Merton's model, the same\napproach can be used for other asset classes (equity, commodity, FX, etc.),\ne.g. for pricing and hedging options with illiquid strikes or illiquid exotic\noptions. \n\n"}
{"id": "1209.4393", "contents": "Title: Two distinct phases in the first 13 seconds of GRB110731A prompt\n  emission Abstract: In this work, the time-resolved BAT/GBM/LAT joint spectral analysis of\nGRB110731A during the prompt phase from the GBM trigger and up to 13 seconds\nlater showed that, at the very early phase of prompt emission, the emission\nmechanism is closest to the standard fireball model. This model over-predicts\nthe thermal photospheric emission and used to contradict observations.\nLightcurves at different energy bands revealed two distinguishable phases that\nmay come from different regions. First, we have an early phase, which is not\ndetected by LAT, and is dominated by lower energies, which arises from the\nphotospheric emissions without any emissions involved in dissipation mechanisms\nand characterized by low Lorentz factor and high radiation efficiency. This is\nfollowed by a later phase, having a more complex structure that remarkably\nfollows the same track in all energy bands and is attributed to emissions from\ninternal shocks. This burst is a good candidate to study both thermal and\nnon-thermal emissions, since the two phases can be clearly separated in\nlightcurve and spectrum. The rapid variation of Lorentz factor and the values\nof photospheric radii, which are relatively far away from the central engine in\nPhase 2, are more consistent with the mechanism of collisional heating in\nbaryonic jets. Further information can be obtained by combining more\nwavelengths with the help of the other detectors. \n\n"}
{"id": "1209.6463", "contents": "Title: Clustering and Classification via Cluster-Weighted Factor Analyzers Abstract: In model-based clustering and classification, the cluster-weighted model\nconstitutes a convenient approach when the random vector of interest\nconstitutes a response variable Y and a set p of explanatory variables X.\nHowever, its applicability may be limited when p is high. To overcome this\nproblem, this paper assumes a latent factor structure for X in each mixture\ncomponent. This leads to the cluster-weighted factor analyzers (CWFA) model. By\nimposing constraints on the variance of Y and the covariance matrix of X, a\nnovel family of sixteen CWFA models is introduced for model-based clustering\nand classification. The alternating expectation-conditional maximization\nalgorithm, for maximum likelihood estimation of the parameters of all the\nmodels in the family, is described; to initialize the algorithm, a 5-step\nhierarchical procedure is proposed, which uses the nested structures of the\nmodels within the family and thus guarantees the natural ranking among the\nsixteen likelihoods. Artificial and real data show that these models have very\ngood clustering and classification performance and that the algorithm is able\nto recover the parameters very well. \n\n"}
{"id": "1210.0259", "contents": "Title: Systems of Brownian particles with asymmetric collisions Abstract: We study systems of Brownian particles on the real line, which interact by\nsplitting the local times of collisions among themselves in an asymmetric\nmanner. We prove the strong existence and uniqueness of such processes and\nidentify them with the collections of ordered processes in a Brownian particle\nsystem, in which the drift coefficients, the diffusion coefficients, and the\ncollision local times for the individual particles are assigned according to\ntheir ranks. These Brownian systems can be viewed as generalizations of those\narising in first-order models for equity markets in the context of stochastic\nportfolio theory, and are able to correct for several shortcomings of such\nmodels while being equally amenable to computations. We also show that, in\naddition to being of interest in their own right, such systems of Brownian\nparticles arise as universal scaling limits of systems of jump processes on the\ninteger lattice with local interactions. A key step in the proof is the\nanalysis of a generalization of Skorokhod maps which include `local times' at\nthe intersection of faces of the nonnegative orthant. The result extends the\nconvergence of TASEP to its continuous analogue. Finally, we identify those\namong the Brownian particle systems which have a probabilistic structure of\ndeterminantal type. \n\n"}
{"id": "1210.1562", "contents": "Title: On irreducible polynomials over finite fields Abstract: For n=1,2,3,... let N_n(q) denote the number of monic irreducible polynomials\nover the finite field F_q. We mainly show that the sequence N_n(q)^{1/n}\n(n>e^{3+7/(q-1)^2}) is strictly increasing and the sequence\nN_{n+1}(q)^{1/(n+1)}/N_n(q)^{1/n} (n>=5.835*10^{14}) is strictly decreasing. We\nalso prove that if q>8 then N_{n+1}(q)/N_n(q) (n=1,2,3,...) is strictly\nincreasing. \n\n"}
{"id": "1210.2617", "contents": "Title: The solution of discretionary stopping problems with applications to the\n  optimal timing of investment decisions Abstract: We present a methodology for obtaining explicit solutions to infinite time\nhorizon optimal stopping problems involving general, one-dimensional, It\\^o\ndiffusions, payoff functions that need not be smooth and state-dependent\ndiscounting. This is done within a framework based on dynamic programming\ntechniques employing variational inequalities and links to the probabilistic\napproaches employing $r$-excessive functions and martingale theory. The aim of\nthis paper is to facilitate the the solution of a wide variety of problems,\nparticularly in finance or economics. \n\n"}
{"id": "1210.3851", "contents": "Title: An introduction to particle integration methods: with applications to\n  risk and insurance Abstract: Interacting particle methods are increasingly used to sample from complex and\nhigh-dimensional distributions. These stochastic particle integration\ntechniques can be interpreted as an universal acceptance-rejection sequential\nparticle sampler equipped with adaptive and interacting recycling mechanisms.\nPractically, the particles evolve randomly around the space independently and\nto each particle is associated a positive potential function. Periodically,\nparticles with high potentials duplicate at the expense of low potential\nparticle which die. This natural genetic type selection scheme appears in\nnumerous applications in applied probability, physics, Bayesian statistics,\nsignal processing, biology, and information engineering. It is the intention of\nthis paper to introduce them to risk modeling. From a purely mathematical point\nof view, these stochastic samplers can be interpreted as Feynman-Kac particle\nintegration methods. These functional models are natural mathematical\nextensions of the traditional change of probability measures, commonly used to\ndesign an importance sampling strategy. In this article, we provide a brief\nintroduction to the stochastic modeling and the theoretical analysis of these\nparticle algorithms. Then we conclude with an illustration of a subset of such\nmethods to resolve important risk measure and capital estimation in risk and\ninsurance modelling. \n\n"}
{"id": "1210.4059", "contents": "Title: Band-filling and correlation controlling electronic properties and\n  magnetism in K$_{x}$Fe$_{2-y}$Se$_{2}$: A slave boson study Abstract: In this paper we investigate the electronic and magnetic properties of\nK$_{x}$Fe$_{2-y}$Se$_{2}$ materials at different band fillings utilizing the\nmulti-orbital Kotliar-Ruckenstein's slave-boson mean field approach. We find\nthat at three-quarter filling, corresponding to KFe$_{2}$Se$_{2}$, the ground\nstate is a paramagnetic bad metal. Through band renormalization analysis and\ncomparison with the angle-resolved photoemission spectra data, we identify that\nKFe$_{2}$Se$_{2}$ is also an intermediate correlated system, similar to\niron-pnictide systems. At two-third filling, corresponding to the\nFe$^{2+}$-based systems, the ground state is a striped antiferromagnetic (SAFM)\nmetal with spin density wave gap partially opened near the Fermi level. In\ncomparison, at half filling case, corresponding to the Fe$^{3+}$-based\ncompounds, besides SAFM, a $N\\acute{e}el$ antiferromagnetic metallic ground\nstate without orbital ordering is observed in the intermediate correlation\nrange, and an orbital selective Mott phase (OSMP) accompanied with an\nintermediate-spin to high-spin transition is also found. These results\ndemonstrate that the band filling and correlation control the electronic state,\nFermi surface topology and magnetism in K$_{x}$Fe$_{2-y}$Se$_{2}$. \n\n"}
{"id": "1210.6727", "contents": "Title: Schauder a priori estimates and regularity of solutions to\n  boundary-degenerate elliptic linear second-order partial differential\n  equations Abstract: We establish Schauder a priori estimates and regularity for solutions to a\nclass of boundary-degenerate elliptic linear second-order partial differential\nequations. Furthermore, given a smooth source function, we prove regularity of\nsolutions up to the portion of the boundary where the operator is degenerate.\nDegenerate-elliptic operators of the kind described in our article appear in a\ndiverse range of applications, including as generators of affine diffusion\nprocesses employed in stochastic volatility models in mathematical finance,\ngenerators of diffusion processes arising in mathematical biology, and the\nstudy of porous media. \n\n"}
{"id": "1210.7721", "contents": "Title: Halton-type sequences from global function fields Abstract: For any prime power $q$ and any dimension $s$, a new construction of\n$(t,s)$-sequences in base $q$ using global function fields is presented. The\nconstruction yields an analog of Halton sequences for global function fields.\nIt is the first general construction of $(t,s)$-sequences that is not based on\nthe digital method. The construction can also be put into the framework of the\ntheory of $(u,e,s)$-sequences that was recently introduced by Tezuka and leads\nin this way to better discrepancy bounds for the constructed sequences. \n\n"}
{"id": "1211.0304", "contents": "Title: Modules de cycles et classes non ramifi\\'ees sur un espace classifiant Abstract: Let G be a finite group of exponent m and let k be a field of characteristic\nprime to m, containing the m-th roots of unity. For any Rost cycle module M\nover k, we construct exact sequences detecting the unramified elements in\nSerre's group of invariants of G with values in M in terms of \"residue\"\nmorphisms associated to pairs (D,g), where D runs through the subgroups of G\nand g runs through the homomorphisms \\mu_m \\to G whose image centralises D.\nThis allows us to recover results of Bogomolov and Peyre on the unramified\ncohomology of fields of invariants of G, and to generalise them. \n\n"}
{"id": "1211.1064", "contents": "Title: Theta divisors of stable vector bundles may be nonreduced Abstract: A generic strictly semistable bundle of degree zero over a curve X has a\nreducible theta divisor, given by the sum of the theta divisors of the stable\nsummands of the associated graded bundle. The converse is not true: Beauville\nand Raynaud have each constructed stable bundles with reducible theta divisors.\nFor X of genus at least 5, we construct stable vector bundles over X of rank\n$r$ for all $r \\geq 5$, with reducible and nonreduced theta divisors. We also\nadapt the construction to symplectic bundles.\n  In the appendix, Raynaud's original example of a stable rank 2 vector bundle\nwith reducible theta divisor over a bi-elliptic curve of genus 3 is generalized\nto bi-elliptic curves of genus $g \\geq 3$. \n\n"}
{"id": "1211.3626", "contents": "Title: The radial part of Brownian motion with respect to\n  $\\mathcal{L}$-distance under Ricci flow Abstract: Let $\\{g_t\\}_{t\\in [0,T)}$ be a family of complete time-depending Riemannian\nmatrics on a manifold which evolves under backwards Ricci flow. The It\\^{o}\nformula is established for the $\\mathcal{L}$-distance of the $g_t$-Brownian\nmotion to a fixed reference point ($\\mathcal{L}$-base). Furthermore, as an\napplication, we construct a coupling by parallel displacement which yields a\nnew proof of some results of Topping. \n\n"}
{"id": "1211.4636", "contents": "Title: On the martingale problem for degenerate-parabolic partial differential\n  operators with unbounded coefficients and a mimicking theorem for Ito\n  processes Abstract: Using results from our companion article [arXiv:1112.4824v2] on a Schauder\napproach to existence of solutions to a degenerate-parabolic partial\ndifferential equation, we solve three intertwined problems, motivated by\nprobability theory and mathematical finance, concerning degenerate diffusion\nprocesses. We show that the martingale problem associated with a\ndegenerate-elliptic differential operator with unbounded, locally Holder\ncontinuous coefficients on a half-space is well-posed in the sense of Stroock\nand Varadhan. Second, we prove existence, uniqueness, and the strong Markov\nproperty for weak solutions to a stochastic differential equation with\ndegenerate diffusion and unbounded coefficients with suitable H\\\"older\ncontinuity properties. Third, for an Ito process with degenerate diffusion and\nunbounded but appropriately regular coefficients, we prove existence of a\nstrong Markov process, unique in the sense of probability law, whose\none-dimensional marginal probability distributions match those of the given Ito\nprocess. \n\n"}
{"id": "1211.5867", "contents": "Title: An FBSDE Approach to American Option Pricing with an Interacting\n  Particle Method Abstract: In the paper, we propose a new calculation scheme for American options in the\nframework of a forward backward stochastic differential equation (FBSDE). The\nwell-known decomposition of an American option price with that of a European\noption of the same maturity and the remaining early exercise premium can be\ncast into the form of a decoupled non-linear FBSDE. We numerically solve the\nFBSDE by applying an interacting particle method recently proposed by Fujii and\nTakahashi (2012d), which allows one to perform a Monte Carlo simulation in a\nfully forward-looking manner. We perform the fourth-order analysis for the\nBlack-Scholes (BS) model and the third-order analysis for the Heston model. The\ncomparison to those obtained from existing tree algorithms shows the\neffectiveness of the particle method. \n\n"}
{"id": "1212.1269", "contents": "Title: Approximate Dynamic Programming via Sum of Squares Programming Abstract: We describe an approximate dynamic programming method for stochastic control\nproblems on infinite state and input spaces. The optimal value function is\napproximated by a linear combination of basis functions with coefficients as\ndecision variables. By relaxing the Bellman equation to an inequality, one\nobtains a linear program in the basis coefficients with an infinite set of\nconstraints. We show that a recently introduced method, which obtains convex\nquadratic value function approximations, can be extended to higher order\npolynomial approximations via sum of squares programming techniques. An\napproximate value function can then be computed offline by solving a\nsemidefinite program, without having to sample the infinite constraint. The\npolicy is evaluated online by solving a polynomial optimization problem, which\nalso turns out to be convex in some cases. We experimentally validate the\nmethod on an autonomous helicopter testbed using a 10-dimensional helicopter\nmodel. \n\n"}
{"id": "1212.1377", "contents": "Title: Multilevel Monte Carlo methods for applications in finance Abstract: Since Giles introduced the multilevel Monte Carlo path simulation method\n[18], there has been rapid development of the technique for a variety of\napplications in computational finance. This paper surveys the progress so far,\nhighlights the key features in achieving a high rate of multilevel variance\nconvergence, and suggests directions for future research. \n\n"}
{"id": "1212.3376", "contents": "Title: Linearly Reconfigurable Kalman Filtering for a Vector Process Abstract: In this paper, we consider a dynamic linear system in state-space form where\nthe observation equation depends linearly on a set of parameters. We address\nthe problem of how to dynamically calculate these parameters in order to\nminimize the mean-squared error (MSE) of the state estimate achieved by a\nKalman filter. We formulate and solve two kinds of problems under a quadratic\nconstraint on the observation parameters: minimizing the sum MSE (Min-Sum-MSE)\nor minimizing the maximum MSE (Min-Max-MSE). In each case, the optimization\nproblem is divided into two sub-problems for which optimal solutions can be\nfound: a semidefinite programming (SDP) problem followed by a constrained\nleast-squares minimization. A more direct solution is shown to exist for the\nspecial case of a scalar observation; in particular, the Min-Sum-MSE solution\ncan be found directly using a generalized eigendecomposition, and is optimally\nsolved utilizing Rayleigh quotient, and the Min-Max-MSE problem reduces to an\nSDP feasibility test that can be solved via the bisection method. \n\n"}
{"id": "1212.5141", "contents": "Title: Asymptotics of radiation fields in asymptotically Minkowski space Abstract: We consider a non-trapping $n$-dimensional Lorentzian manifold endowed with\nan end structure modeled on the radial compactification of Minkowski space. We\nfind a full asymptotic expansion for tempered forward solutions of the wave\nequation in all asymptotic regimes. The rates of decay seen in the asymptotic\nexpansion are related to the resonances of a natural asymptotically hyperbolic\nproblem on the \"northern cap\" of the compactification. For small perturbations\nof Minkowski space that fit into our framework, we show a rate of decay that\nimproves on the Klainerman--Sobolev estimates. \n\n"}
{"id": "1212.6818", "contents": "Title: Off-diagonal terms in Yukawa textures of the Type-III 2-Higgs doublet\n  model and light charged Higgs boson phenomenology Abstract: We discuss flavor-violating constraints and consequently possible charged\nHiggs boson phenomenology emerging from a four-zero Yukawa texture embedded\nwithin the Type-III 2-Higgs Doublet Model (2HDM-III). Firstly, we show in\ndetail how we can obtain several kinds of 2HDMs when some parameters in the\nYukawa texture are absent. Secondly, we present a comprehensive study of the\nmain B-physics constraints on such parameters induced by flavor-changing\nprocesses, in particular on the off-diagonal terms of such a texture: i.e.,\nfrom $\\mu -e$ universality in $\\tau$ decays, several leptonic B-decays ($B \\to\n\\tau \\nu$, $D \\to \\mu \\nu$ and $D_s \\to {l} \\nu$), the semi-leptonic transition\n$B\\to D \\tau \\nu$, plus $B \\to X_s \\gamma$, including $B^0-\\bar B^0$ mixing,\n$B_s \\to \\mu^+ \\mu^-$ and the radiative decay $Z\\to b \\bar{b}$. Thirdly, having\nselected the surviving 2HDM-III parameter space, we show that the $H^- c\n\\bar{b}$ coupling can be very large over sizable expanses of it, in fact, a\nvery different situation with respect to 2HDMs with a flavor discrete symmetry\n(i.e., ${\\mathcal{Z}}_2$) and very similar to the case of the Aligned-2HDM\n(A2HDM) as well as of models with three or more Higgs doublets. Fourthly, we\nstudy in detail the ensuing $H^\\pm$ phenomenology at the Large Hadron Collider\n(LHC), chiefly the $c\\bar b \\to H^+$ production mode and the $H^+\\to c\\bar b$\ndecay channel while assuming $\\tau^+\\nu_\\tau$ decays in the former and $t\\to\nbH^+$ production in the latter, showing that significant scope exists in both\ncases. \n\n"}
{"id": "1301.0109", "contents": "Title: On Reduced Form Intensity-based Model with Trigger Events Abstract: Corporate defaults may be triggered by some major market news or events such\nas financial crises or collapses of major banks or financial institutions. With\na view to develop a more realistic model for credit risk analysis, we introduce\na new type of reduced-form intensity-based model that can incorporate the\nimpacts of both observable \"trigger\" events and economic environment on\ncorporate defaults. The key idea of the model is to augment a Cox process with\ntrigger events. Both single-default and multiple-default cases are considered\nin this paper. In the former case, a simple expression for the distribution of\nthe default time is obtained. Applications of the proposed model to price\ndefaultable bonds and multi-name Credit Default Swaps (CDSs) are provided. \n\n"}
{"id": "1301.3628", "contents": "Title: On the origin of inflation by using exotic smoothness Abstract: In this paper we discuss a spacetime having the topology of S^3 x R but with\na different smoothness structure leading to a geometric model for inflation,\ncalled geometric inflation. In particular this spacetime is not globally\nhyperbolic and we obtain a time line with a spatial topology change from the\n3-sphere to a homology 3-sphere and back. The topology of the spacetime remains\ninvariant. Among the infinite possible smoothness structures of this spacetime,\nwe choose a homology 3-sphere constructed from the knot 8_{10} with hyperbolic\ngeometry, i.e. admitting a homogenous metric of negative scalar curvature. We\ndiscuss the accelerated expansion for FLRW cosmology caused by the topology\nchange. In contrast to other inflation models, this process stops after a\nfinite time. Alternatively, the topology change can be also described by a\nSU(2)-valued scalar field. Then we calculate the expansion rate (having more\nthan 60 e-folds) and the energy time scale. The coupling to matter is also\ninterpreted geometrically and the reheating process (as well the supercooled\nexpansion during inflation) is naturally obtained. The model depends only on a\nsingle parameter, a topological invariant of the homology 3-sphere, and assumes\na Planck size universe of S^3-topology. The dependence of the model on the\ninitial state and the a geometric interpretation of quantum fluctuations are\nalso discussed. \n\n"}
{"id": "1301.4194", "contents": "Title: Financial Portfolio Optimization: Computationally guided agents to\n  investigate, analyse and invest!? Abstract: Financial portfolio optimization is a widely studied problem in mathematics,\nstatistics, financial and computational literature. It adheres to determining\nan optimal combination of weights associated with financial assets held in a\nportfolio. In practice, it faces challenges by virtue of varying math.\nformulations, parameters, business constraints and complex financial\ninstruments. Empirical nature of data is no longer one-sided; thereby\nreflecting upside and downside trends with repeated yet unidentifiable cyclic\nbehaviours potentially caused due to high frequency volatile movements in asset\ntrades. Portfolio optimization under such circumstances is theoretically and\ncomputationally challenging. This work presents a novel mechanism to reach an\noptimal solution by encoding a variety of optimal solutions in a solution bank\nto guide the search process for the global investment objective formulation. It\nconceptualizes the role of individual solver agents that contribute optimal\nsolutions to a bank of solutions, a super-agent solver that learns from the\nsolution bank, and, thus reflects a knowledge-based computationally guided\nagents approach to investigate, analyse and reach to optimal solution for\ninformed investment decisions.\n  Conceptual understanding of classes of solver agents that represent varying\nproblem formulations and, mathematically oriented deterministic solvers along\nwith stochastic-search driven evolutionary and swarm-intelligence based\ntechniques for optimal weights are discussed. Algorithmic implementation is\npresented by an enhanced neighbourhood generation mechanism in Simulated\nAnnealing algorithm. A framework for inclusion of heuristic knowledge and human\nexpertise from financial literature related to investment decision making\nprocess is reflected via introduction of controlled perturbation strategies\nusing a decision matrix for neighbourhood generation. \n\n"}
{"id": "1301.4442", "contents": "Title: USLV: Unspanned Stochastic Local Volatility Model Abstract: We propose a new framework for modeling stochastic local volatility, with\npotential applications to modeling derivatives on interest rates, commodities,\ncredit, equity, FX etc., as well as hybrid derivatives. Our model extends the\nlinearity-generating unspanned volatility term structure model by Carr et al.\n(2011) by adding a local volatility layer to it. We outline efficient numerical\nschemes for pricing derivatives in this framework for a particular four-factor\nspecification (two \"curve\" factors plus two \"volatility\" factors). We show that\nthe dynamics of such a system can be approximated by a Markov chain on a\ntwo-dimensional space (Z_t,Y_t), where coordinates Z_t and Y_t are given by\ndirect (Kroneker) products of values of pairs of curve and volatility factors,\nrespectively. The resulting Markov chain dynamics on such partly \"folded\" state\nspace enables fast pricing by the standard backward induction. Using a\nnonparametric specification of the Markov chain generator, one can accurately\nmatch arbitrary sets of vanilla option quotes with different strikes and\nmaturities. Furthermore, we consider an alternative formulation of the model in\nterms of an implied time change process. The latter is specified\nnonparametrically, again enabling accurate calibration to arbitrary sets of\nvanilla option quotes. \n\n"}
{"id": "1302.0976", "contents": "Title: Work distribution in time-dependent logarithmic-harmonic potential:\n  exact results and asymptotic analysis Abstract: We investigate the distribution of work performed on a Brownian particle in a\ntime-dependent asymmetric potential well. The potential has a harmonic\ncomponent with time-dependent force constant and a time-independent logarithmic\nbarrier at the origin. For arbitrary driving protocol, the problem of solving\nthe Fokker-Planck equation for the joint probability density of work and\nparticle position is reduced to the solution of the Riccati differential\nequation. For a particular choice of the driving protocol, an exact solution of\nthe Riccati equation is presented. Asymptotic analysis of the resulting\nexpression yields the tail behavior of the work distribution for small and\nlarge work values. In the limit of vanishing logarithmic barrier, the work\ndistribution for the breathing parabola model is obtained. \n\n"}
{"id": "1302.2534", "contents": "Title: Stationarity and ergodicity for an affine two factor model Abstract: We study the existence of a unique stationary distribution and ergodicity for\na 2-dimensional affine process. The first coordinate is supposed to be a\nso-called alpha-root process with \\alpha\\in(1,2]. The existence of a unique\nstationary distribution for the affine process is proved in case of\n\\alpha\\in(1,2]; further, in case of \\alpha=2, the ergodicity is also shown. \n\n"}
{"id": "1302.2963", "contents": "Title: Geant4 Applications for Modeling Molecular Transport in Complex Vacuum\n  Geometries Abstract: We discuss a novel use of the Geant4 simulation toolkit to model molecular\ntransport in a vacuum environment, in the molecular flow regime. The Geant4\ntoolkit was originally developed by the high energy physics community to\nsimulate the interactions of elementary particles within complex detector\nsystems. Here its capabilities are utilized to model molecular vacuum transport\nin geometries where other techniques are impractical. The techniques are\nverified with an application representing a simple vacuum geometry that has\nbeen studied previously both analytically and by basic Monte Carlo simulation.\nWe discuss the use of an application with a very complicated geometry, that of\nthe Large Synoptic Survey Telescope camera cryostat, to determine probabilities\nof transport of contaminant molecules to optical surfaces where control of\ncontamination is crucial. \n\n"}
{"id": "1302.3141", "contents": "Title: X-ray frequency combs from optically controlled resonance fluorescence Abstract: An x-ray pulse-shaping scheme is put forward for imprinting an optical\nfrequency comb onto the radiation emitted on a driven x-ray transition, thus\nproducing an x-ray frequency comb. A four-level system is used to describe the\nlevel structure of N ions driven by narrow-bandwidth x rays, an optical\nauxiliary laser, and an optical frequency comb. By including many-particle\nenhancement of the emitted resonance fluorescence, a spectrum is predicted\nconsisting of equally spaced narrow lines which are centered on an x-ray\ntransition energy and separated by the same tooth spacing as the driving\noptical frequency comb. Given a known x-ray reference frequency, our comb could\nbe employed to determine an unknown x-ray frequency. While relying on the\nquality of the light fields used to drive the ensemble of ions, the model has\nvalidity at energies from the 100 eV to the keV range. \n\n"}
{"id": "1302.3226", "contents": "Title: CosMIn: The Solution to the Cosmological Constant Problem Abstract: The current acceleration of the universe can be modeled in terms of a\ncosmological constant. We show that the extremely small value of \\Lambda L_P^2\n~ 3.4 x 10^{-122}, the holy grail of theoretical physics, can be understood in\nterms of a new, dimensionless, conserved number CosMIn (N), which counts the\nnumber of modes crossing the Hubble radius during the three phases of evolution\nof the universe. Theoretical considerations suggest that N ~ 4\\pi. This single\npostulate leads us to the correct, observed numerical value of the cosmological\nconstant! This approach also provides a unified picture of cosmic evolution\nrelating the early inflationary phase to the late-time accelerating phase. \n\n"}
{"id": "1302.3654", "contents": "Title: Pricing Corporate Defaultable Bond using Declared Firm Value Abstract: We study the pricing problem for corporate defaultable bond from the\nviewpoint of the investors outside the firm that could not exactly know about\nthe information of the firm. We consider the problem for pricing of corporate\ndefaultable bond in the case when the firm value is only declared in some fixed\ndiscrete time and unexpected default intensity is determined by the declared\nfirm value. Here we provide a partial differential equation model for such a\ndefaultable bond and give its pricing formula. Our pricing model is derived to\nsolving problems of partial differential equations with random constants (de-\nfault intensity) and terminal values of binary types. Our main method is to use\nthe solving method of a partial differential equation with a random constant in\nevery subinterval and to take expectation to remove the random constants. \n\n"}
{"id": "1302.4676", "contents": "Title: Analysis of multilevel Monte Carlo path simulation using the Milstein\n  discretisation Abstract: The multilevel Monte Carlo path simulation method introduced by Giles ({\\it\nOperations Research}, 56(3):607-617, 2008) exploits strong convergence\nproperties to improve the computational complexity by combining simulations\nwith different levels of resolution. In this paper we analyse its efficiency\nwhen using the Milstein discretisation; this has an improved order of strong\nconvergence compared to the standard Euler-Maruyama method, and it is proved\nthat this leads to an improved order of convergence of the variance of the\nmultilevel estimator. Numerical results are also given for basket options to\nillustrate the relevance of the analysis. \n\n"}
{"id": "1302.4854", "contents": "Title: An Explicit Martingale Version of Brenier's Theorem Abstract: By investigating model-independent bounds for exotic options in financial\nmathematics, a martingale version of the Monge-Kantorovich mass transport\nproblem was introduced in \\cite{BeiglbockHenry\nLaborderePenkner,GalichonHenry-LabordereTouzi}. In this paper, we extend the\none-dimensional Brenier's theorem to the present martingale version. We provide\nthe explicit martingale optimal transference plans for a remarkable class of\ncoupling functions corresponding to the lower and upper bounds. These explicit\nextremal probability measures coincide with the unique left and right monotone\nmartingale transference plans, which were introduced in \\cite{BeiglbockJuillet}\nby suitable adaptation of the notion of cyclic monotonicity. Instead, our\napproach relies heavily on the (weak) duality result stated in\n\\cite{BeiglbockHenry-LaborderePenkner}, and provides, as a by-product, an\nexplicit expression for the corresponding optimal semi-static hedging\nstrategies. We finally provide an extension to the multiple marginals case. \n\n"}
{"id": "1302.5008", "contents": "Title: Classical homogeneous multidimensional continued fraction algorithms are\n  ergodic Abstract: Homogeneous continued fraction algorithms are multidimensional\ngeneralizations of the classical Euclidean algorithm, the dissipative map $$\n(x_1,x_2) \\in \\mathbb{R}_+^2 \\longmapsto \\left\\{\\begin{array}{ll}\n  (x_1 - x_2, x_2), & \\mbox{if $x_1 \\geq x_2$}\n  (x_1, x_2 - x_1), & \\mbox{otherwise.} \\end{array} \\right. $$ We focus on\nthose which act piecewise linearly on finitely many copies of positive cones\nwhich we call Rauzy induction type algorithms.\n  In particular, a variation Selmer algorithm belongs to this class. We prove\nthat Rauzy induction type algorithms, as well as Selmer algorithms, are ergodic\nwith respect to Lebesgue measure. \n\n"}
{"id": "1302.6038", "contents": "Title: L-packets and formal degrees for SL_2(K) with K a local function field\n  of characteristic 2 Abstract: Let G = SL_2(K) with K a local function field of characteristic 2. We review\nArtin-Schreier theory for the field K, and show that this leads to a\nparametrization of L-packets in the smooth dual of G. We relate this to a\nrecent geometric conjecture. The L-packets in the principal series are\nparametrized by quadratic extensions, and the supercuspidal L-packets by\nbiquadratic extensions. We compute the formal degrees of the elements in the\nsupercuspidal packets. \n\n"}
{"id": "1302.7246", "contents": "Title: An analytic multi-currency model with stochastic volatility and\n  stochastic interest rates Abstract: We introduce a tractable multi-currency model with stochastic volatility and\ncorrelated stochastic interest rates that takes into account the smile in the\nFX market and the evolution of yield curves. The pricing of vanilla options on\nFX rates can be performed effciently through the FFT methodology thanks to the\naffinity of the model Our framework is also able to describe many non trivial\nlinks between FX rates and interest rates: a second calibration exercise\nhighlights the ability of the model to fit simultaneously FX implied\nvolatilities while being coherent with interest rate products. \n\n"}
{"id": "1303.0200", "contents": "Title: Non-relativistic pair annihilation of nearly mass degenerate neutralinos\n  and charginos II. P-wave and next-to-next-to-leading order S-wave\n  coefficients Abstract: This paper is a continuation of an earlier work (arXiv:1210.7928) which\ncomputed analytically the tree-level annihilation rates of a collection of\nnon-relativistic neutralino and chargino two-particle states in the general\nMSSM. Here we extend the results by providing the next-to-next-to-leading order\ncorrections to the rates in the non-relativistic expansion in momenta and mass\ndifferences, which include leading P-wave effects, in analytic form. The\nresults are a necessary input for the calculation of the Sommerfeld-enhanced\ndark matter annihilation rates including short-distance corrections at\nnext-to-next-to-leading order in the non-relativistic expansion in the general\nMSSM with neutralino LSP. \n\n"}
{"id": "1303.2351", "contents": "Title: Almost complex circle actions with few fixed points Abstract: We show that almost complex circle actions with exactly three fixed points do\nnot exist in dimension 8 and present an infinite series of 6-dimensional\nmanifolds possessing an almost complex circle action with exactly two fixed\npoints. \n\n"}
{"id": "1303.2723", "contents": "Title: Dusty starburst galaxies in the early Universe as revealed by\n  gravitational lensing Abstract: In the past decade, our understanding of galaxy evolution has been\nrevolutionized by the discovery that luminous, dusty, starburst galaxies were\n1,000 times more abundant in the early Universe than at present. It has,\nhowever, been difficult to measure the complete redshift 2 distribution of\nthese objects, especially at the highest redshifts (z > 4). Here we report a\nredshift survey at a wavelength of three millimeters, targeting carbon monoxide\nline emission from the star-forming molecular gas in the direction of\nextraordinarily bright millimetrewave-selected sources. High-resolution imaging\ndemonstrates that these sources are strongly gravitationally lensed by\nforeground galaxies. We detect spectral lines in 23 out of 26 sources and\nmultiple lines in 12 of those 23 sources, from which we obtain robust,\nunambiguous redshifts. At least 10 of the sources are found to lie at z > 4,\nindicating that the fraction of dusty starburst galaxies at high redshifts is\ngreater than previously thought. Models of lens geometries in the sample\nindicate that the background objects are ultra-luminous infrared galaxies,\npowered by extreme bursts of star formation. \n\n"}
{"id": "1304.1539", "contents": "Title: Taking the \"Un\" out of \"Unnovae\" Abstract: It has long been expected that some massive stars produce stellar mass black\nholes (BHs) upon death. Unfortunately, the observational signature of such\nevents has been unclear. It has even been suggested that the result may be an\n\"unnova,\" in which the formation of a BH is marked by the disappearance of a\nstar rather than an electromagnetic outburst. I argue that when the progenitor\nis a red supergiant, evidence for BH creation may instead be a ~3-10 day\noptical transient with a peak luminosity of ~10^{40}-10^{41} erg s^{-1}, a\ntemperature of ~10^4 K, slow ejection speeds of ~200 km s^{-1}, and a spectrum\ndevoid of the nucleosynthetic products associated with explosive burning. This\nsignal is the breakout of a shock generated by the hydrodynamic response of a\nmassive stellar envelope when the protoneutron star loses ~few*0.1Msun to\nneutrino emission prior to collapse to a BH. Current and future wide-field,\nhigh-cadence optical surveys make this an ideal time to discover and study\nthese events. Motivated by the unique parameter space probed by this scenario,\nI discuss more broadly the range of properties expected for shock breakout\nflashes, with emphasis on progenitors with large radii and/or small shock\nenergies. This may have application in a wider diversity of explosive events,\nfrom pair instability supernovae to newly discovered but yet to be understood\ntransients. \n\n"}
{"id": "1304.1783", "contents": "Title: A convolution method for numerical solution of backward stochastic\n  differential equations Abstract: We propose a new method for the numerical solution of backward stochastic\ndifferential equations (BSDEs) which finds its roots in Fourier analysis. The\nmethod consists of an Euler time discretization of the BSDE with certain\nconditional expectations expressed in terms of Fourier transforms and computed\nusing the fast Fourier transform (FFT). The problem of error control is\naddressed and a local error analysis is provided. We consider the extension of\nthe method to forward-backward stochastic differential equations (FBSDEs) and\nreflected FBSDEs. Numerical examples are considered from finance demonstrating\nthe performance of the method. \n\n"}
{"id": "1304.2477", "contents": "Title: Sheaves of G-structures and generic G-models Abstract: In this article we give an equivariant version for the construction of\ngeneric models on presheaves of structures. We deal with first order structures\nendowed with a suitable action of some fixed group, say $G$; we call them\n$G$-structures. We show that every exact presheaf of $G$-structures\n$\\mathcal{M}$ has a generic (equivariant) $G$-model $\\mathcal{M}^{^{gen}}$. \n\n"}
{"id": "1304.3159", "contents": "Title: Efficient Solution of Backward Jump-Diffusion PIDEs with Splitting and\n  Matrix Exponentials Abstract: We propose a new, unified approach to solving jump-diffusion partial\nintegro-differential equations (PIDEs) that often appear in mathematical\nfinance. Our method consists of the following steps. First, a second-order\noperator splitting on financial processes (diffusion and jumps) is applied to\nthese PIDEs. To solve the diffusion equation, we use standard finite-difference\nmethods, which for multi-dimensional problems could also include splitting on\nvarious dimensions. For the jump part, we transform the jump integral into a\npseudo-differential operator. Then for various jump models we show how to\nconstruct an appropriate first and second order approximation on a grid which\nsupersets the grid that we used for the diffusion part. These approximations\nmake the scheme to be unconditionally stable in time and preserve positivity of\nthe solution which is computed either via a matrix exponential, or via P{\\'a}de\napproximation of the matrix exponent. Various numerical experiments are\nprovided to justify these results. \n\n"}
{"id": "1304.3622", "contents": "Title: On model structure for coreflective subcategories of a model category Abstract: Let $\\bf C$ be a coreflective subcategory of a cofibrantly generated model\ncategory $\\bf D$. In this paper we show that under suitable conditions $\\bf C$\nadmits a cofibrantly generated model structure which is left Quillen adjunct to\nthe model structure on $\\bf D$. As an application, we prove that well-known\nconvenient categories of topological spaces, such as $k$-spaces, compactly\ngenerated spaces, and $\\Delta$-generated spaces \\cite{DN} (called numerically\ngenerated in \\cite{KKH}) admit a finitely generated model structure which is\nQuillen equivalent to the standard model structure on the category $\\bf Top$ of\ntopological spaces. \n\n"}
{"id": "1305.3891", "contents": "Title: Kepler-77b: a very low albedo, Saturn-mass transiting planet around a\n  metal-rich solar-like star Abstract: We report the discovery of Kepler-77b (alias KOI-127.01), a Saturn-mass\ntransiting planet in a 3.6-day orbit around a metal-rich solar-like star. We\ncombined the publicly available Kepler photometry (quarters 1-13) with\nhigh-resolution spectroscopy from the Sandiford@McDonald and FIES@NOT\nspectrographs. We derived the system parameters via a simultaneous joint fit to\nthe photometric and radial velocity measurements. Our analysis is based on the\nBayesian approach and is carried out by sampling the parameter posterior\ndistributions using a Markov chain Monte Carlo simulation. Kepler-77b is a\nmoderately inflated planet with a mass of Mp=0.430+/-0.032 Mjup, a radius of\nRp=0.960+/-0.016 Rjup, and a bulk density of 0.603+/-0.055 g/cm^3. It orbits a\nslowly rotating (P=36+/-6 days) G5V star with M*=0.95+/-0.04 Msun,\nR*=0.99+/-0.02 Rsun, Teff=5520+/-60 K, [M/H]=0.20+/-0.05, that has an age of\n7.5+/-2.0 Gyr. The lack of detectable planetary occultation with a depth higher\nthan about 10 ppm implies a planet geometric and Bond albedo of\nAg<0.087+/-0.008 and Ab<0.058+/-0.006, respectively, placing Kepler-77b among\nthe gas-giant planets with the lowest albedo known so far. We found neither\nadditional planetary transit signals nor transit-timing variations at a level\nof about 0.5 minutes, in accordance with the trend that close-in gas giant\nplanets seem to belong to single-planet systems. The 106 transits observed in\nshort-cadence mode by Kepler for nearly 1.2 years show no detectable signatures\nof the planet's passage in front of starspots. We explored the implications of\nthe absence of detectable spot-crossing events for the inclination of the\nstellar spin-axis, the sky-projected spin-orbit obliquity, and the latitude of\nmagnetically active regions. \n\n"}
{"id": "1305.5790", "contents": "Title: Nucleon-Nucleon scattering from the dispersive N/D method:\n  next-to-leading order study Abstract: We consider nucleon-nucleon ($NN$) interactions from Chiral Effective Field\nTheory applying the $N/D$ method. The dynamical input is given by the\ndiscontinuity of the $NN$ partial-wave amplitudes across the left-hand cut\n(LHC) calculated in Chiral Perturbation Theory (ChPT) by including one-pion\nexchange (OPE), once-iterated OPE and leading irreducible two-pion exchange\n(TPE). We discuss both uncoupled and coupled partial-waves. We show\nalgebraically that the resulting integral equation has a unique solution when\nthe input is taken only from OPE because it is of the Fredholm type with a\nsquared integrable kernel and an inhomogeneous term. Phase shifts and mixing\nangles are typically rather well reproduced, and a clear improvement of the\nresults obtained previously with only OPE is manifest. We also show that the\ncontributions to the discontinuity across the LHC are amenable to a chiral\nexpansion. Our method also establishes correlations between the $S$-wave\neffective ranges and scattering lengths based on unitarity, analyticity and\nchiral symmetry. \n\n"}
{"id": "1305.6988", "contents": "Title: Integrals of Higher Binary Options and Defaultable Bond with Discrete\n  Default Information Abstract: In this article, we study the problem of pricing defaultable bond with\ndiscrete default intensity and barrier under constant risk free short rate\nusing higher order binary options and their integrals. In our credit risk\nmodel, the risk free short rate is a constant and the default event occurs in\nan expected manner when the firm value reaches a given default barrier at\npredetermined discrete announcing dates or in an unexpected manner at the first\njump time of a Poisson process with given default intensity given by a step\nfunction of time variable, respectively. We consider both endogenous and\nexogenous default recovery. Our pricing problem is derived to a solving problem\nof inhomogeneous or homogeneous Black-Scholes PDEs with different coefficients\nand terminal value of binary type in every subinterval between the two adjacent\nannouncing dates. In order to deal with the difference of coefficients in\nsubintervals we use a relation between prices of higher order binaries with\ndifferent coefficients. In our model, due to the inhomogenous term related to\nendogenous recovery, our pricing formulae are represented by not only the\nprices of higher binary options but also the integrals of them. So we consider\na special binary option called integral of i-th binary or nothing and then we\nobtain the pricing formulae of our defaultable corporate bond by using the\npricing formulae of higher binary options and integrals of them. \n\n"}
{"id": "1305.7031", "contents": "Title: Cosmological Effects of Scalar-Photon Couplings: Dark Energy and\n  Varying-alpha Models Abstract: We study cosmological models involving scalar fields coupled to radiation and\ndiscuss their effect on the redshift evolution of the cosmic microwave\nbackground temperature, focusing on links with varying fundamental constants\nand dynamical dark energy. We quantify how allowing for the coupling of scalar\nfields to photons, and its important effect on luminosity distances, weakens\ncurrent and future constraints on cosmological parameters. In particular, for\nevolving dark energy models, joint constraints on the dark energy equation of\nstate combining BAO radial distance and SN luminosity distance determinations,\nwill be strongly dominated by BAO. Thus, to fully exploit future SN data one\nmust also independently constrain photon number non-conservation arising from\nthe possible coupling of SN photons to the dark energy scalar field. We discuss\nhow observational determinations of the background temperature at different\nredshifts can, in combination with distance measures data, set tight\nconstraints on interactions between scalar fields and photons, thus breaking\nthis degeneracy. We also discuss prospects for future improvements,\nparticularly in the context of Euclid and the E-ELT and show that Euclid can,\neven on its own, provide useful dark energy constraints while allowing for\nphoton number non-conservation. \n\n"}
{"id": "1306.0701", "contents": "Title: Populations in statistical genetic modelling and inference Abstract: What is a population? This review considers how a population may be defined\nin terms of understanding the structure of the underlying genetics of the\nindividuals involved. The main approach is to consider statistically\nidentifiable groups of randomly mating individuals, which is well defined in\ntheory for any type of (sexual) organism. We discuss generative models using\ndrift, admixture and spatial structure, and the ancestral recombination graph.\nThese are contrasted with statistical models for inference, principle component\nanalysis and other `non-parametric' methods. The relationships between these\napproaches are explored with both simulated and real-data examples. The\nstate-of-the-art practical software tools are discussed and contrasted. We\nconclude that populations are a useful theoretical construct that can be well\ndefined in theory and often approximately exist in practice. \n\n"}
{"id": "1306.0901", "contents": "Title: Mass-sheet degeneracy, power-law models and external convergence: Impact\n  on the determination of the Hubble constant from gravitational lensing Abstract: The light travel time differences in strong gravitational lensing systems\nallows an independent determination of the Hubble constant. This method has\nbeen successfully applied to several lens systems. The formally most precise\nmeasurements are, however, in tension with the recent determination of $H_0$\nfrom the Planck satellite for a spatially flat six-parameters $\\Lambda CDM$\ncosmology. We reconsider the uncertainties of the method, concerning the mass\nprofile of the lens galaxies, and show that the formal precision relies on the\nassumption that the mass profile is a perfect power law. Simple analytical\narguments and numerical experiments reveal that mass-sheet like transformations\nyield significant freedom in choosing the mass profile, even when exquisite\nEinstein rings are observed. Furthermore, the characterization of the\nenvironment of the lens does not break that degeneracy which is not physically\nlinked to extrinsic convergence. We present an illustrative example where the\nmultiple imaging properties of a composite (baryons + dark matter) lens can be\nextremely well reproduced by a power-law model having the same velocity\ndispersion, but with predictions for the Hubble constant that deviate by $\\sim\n20%$. Hence we conclude that the impact of degeneracies between parametrized\nmodels have been underestimated in current $H_0$ measurements from lensing, and\nneed to be carefully reconsidered. \n\n"}
{"id": "1306.3359", "contents": "Title: Making Mean-Variance Hedging Implementable in a Partially Observable\n  Market Abstract: The mean-variance hedging (MVH) problem is studied in a partially observable\nmarket where the drift processes can only be inferred through the observation\nof asset or index processes. Although most of the literatures treat the MVH\nproblem by the duality method, here we study a system consisting of three BSDEs\nderived by Mania and Tevzadze (2003) and Mania et.al.(2008) and try to provide\nmore explicit expressions directly implementable by practitioners. Under the\nBayesian and Kalman-Bucy frameworks, we find that a relevant BSDE yields a\nsemi-closed solution via a simple set of ODEs which allow a quick numerical\nevaluation. This renders remaining problems equivalent to solving European\ncontingent claims under a new forward measure, and it is straightforward to\nobtain a forward looking non-sequential Monte Carlo simulation scheme. We also\ngive a special example where the hedging position is available in a semi-closed\nform. For more generic setups, we provide explicit expressions of approximate\nhedging portfolio by an asymptotic expansion. These analytic expressions not\nonly allow the hedgers to update the hedging positions in real time but also\nmake a direct analysis of the terminal distribution of the hedged portfolio\nfeasible by standard Monte Carlo simulation. \n\n"}
{"id": "1306.3923", "contents": "Title: Applying the Wiener-Hopf Monte Carlo simulation technique for Levy\n  processes to path functionals such as first passage times, undershoots and\n  overshoots Abstract: In this note we apply the recently established Wiener-Hopf Monte Carlo (WHMC)\nsimulation technique for Levy processes from Kuznetsov et al. [17] to path\nfunctionals, in particular first passage times, overshoots, undershoots and the\nlast maximum before the passage time. Such functionals have many applications,\nfor instance in finance (the pricing of exotic options in a Levy model) and\ninsurance (ruin time, debt at ruin and related quantities for a Levy insurance\nrisk process). The technique works for any Levy process whose running infimum\nand supremum evaluated at an independent exponential time allows sampling from.\nThis includes classic examples such as stable processes, subclasses of\nspectrally one sided Levy processes and large new families such as meromorphic\nLevy processes. Finally we present some examples. A particular aspect that is\nillustrated is that the WHMC simulation technique performs much better at\napproximating first passage times than a `plain' Monte Carlo simulation\ntechnique based on sampling increments of the Levy process. \n\n"}
{"id": "1306.5457", "contents": "Title: Massive Gravity Acausality Redux Abstract: Massive gravity (mGR) is a 5(=2s+1) degree of freedom, finite range extension\nof GR. However, amongst other problems, it is plagued by superluminal\npropagation, first uncovered via a second order shock analysis. First order mGR\nshock structures have also been studied, but the existence of superluminal\npropagation in that context was left open. We present here a concordance of\nthese methods, by an explicit (first order) characteristic matrix computation,\nwhich confirms mGR's superluminal propagation as well as acausality. \n\n"}
{"id": "1306.6402", "contents": "Title: On Modeling Economic Default Time: A Reduced-Form Model Approach Abstract: In the aftermath of the global financial crisis, much attention has been paid\nto investigating the appropriateness of the current practice of default risk\nmodeling in banking, finance and insurance industries. A recent empirical study\nby Guo et al.(2008) shows that the time difference between the economic and\nrecorded default dates has a significant impact on recovery rate estimates. Guo\net al.(2011) develop a theoretical structural firm asset value model for a firm\ndefault process that embeds the distinction of these two default times. To be\nmore consistent with the practice, in this paper, we assume the market\nparticipants cannot observe the firm asset value directly and developed a\nreduced-form model to characterize the economic and recorded default times. We\nderive the probability distribution of these two default times. The numerical\nstudy on the difference between these two shows that our proposed model can\nboth capture the features and fit the empirical data. \n\n"}
{"id": "1307.1982", "contents": "Title: Star Formation in the First Galaxies - II: Clustered Star Formation and\n  the Influence of Metal Line Cooling Abstract: Population III stars are believed to have been more massive than typical\nstars today and to have formed in relative isolation. The thermodynamic impact\nof metals is expected to induce a transition leading to clustered, low-mass\nPopulation II star formation. In this work, we present results from three\ncosmological simulations, only differing in gas metallicity, that focus on the\nimpact of metal fine-structure line cooling on the formation of stellar\nclusters in a high-redshift atomic cooling halo. Introduction of sink particles\nallows us to follow the process of gas hydrodynamics and accretion onto cluster\nstars for 4 Myr corresponding to multiple local free-fall times. At\nmetallicities at least $10^{-3}\\, Z_{\\odot}$, gas is able to reach the CMB\ntemperature floor and fragment pervasively resulting in a stellar cluster of\nsize $\\sim1$ pc and total mass $\\sim1000\\, M_{\\odot}$. The masses of individual\nsink particles vary, but are typically $\\sim100\\, M_{\\odot}$, consistent with\nthe Jeans mass when gas cools to the CMB temperature, though some solar mass\nfragments are also produced. At the low metallicity of $10^{-4}\\, Z_{\\odot}$,\nfragmentation is completely suppressed on scales greater than 0.01 pc and total\nstellar mass is lower by a factor of 3 than in the higher metallicity\nsimulations. The sink particle accretion rates, and thus their masses, are\ndetermined by the mass of the gravitationally unstable gas cloud and the\nprolonged gas accretion over many Myr. The simulations thus exhibit features of\nboth monolithic collapse and competitive accretion. Even considering possible\ndust induced fragmentation that would occur at higher densities, the formation\nof a bona fide stellar cluster seems to require metal line cooling and\nmetallicities of at least $10^{-3}\\, Z_{\\odot}$. \n\n"}
{"id": "1307.4108", "contents": "Title: The shocks during the accretion of an ultrarelativistic supersonic gas\n  onto a rotating black hole Abstract: In this work, we track the evolution of an ultrarelativistic fluid onto a\nKerr black hole, on the equatorial plane. In this treatment, we consider the\nlimit where the rest mass density is neglected, that is, the approximation is\nvalid in the regime where the internal energy dominates over the rest mass\ndensity. We particularly concentrate in the case of a gas with $\\Gamma$ = 4/3,\nwhich corresponds to a radiation fluid. We show, as in several cases, that a\nshock cone appears when the asymptotic velocity of the fluid is larger than the\nasymptotic relativistic sound speed of the gas. On the other hand, in order to\nshow the system approaches to steady state, we calculate the accreted total\nenergy rate on a spherical surface. Finally, we also show the gas distribution\nand various of its properties. \n\n"}
{"id": "1307.7178", "contents": "Title: A hybrid approach for the implementation of the Heston model Abstract: We propose a hybrid tree-finite difference method in order to approximate the\nHeston model. We prove the convergence by embedding the procedure in a\nbivariate Markov chain and we study the convergence of European and American\noption prices. We finally provide numerical experiments that give accurate\noption prices in the Heston model, showing the reliability and the efficiency\nof the algorithm. \n\n"}
{"id": "1308.1198", "contents": "Title: Chirality from interfacial spin-orbit coupling effects in magnetic\n  bilayers Abstract: As nanomagnetic devices scale to smaller sizes, spin-orbit coupling due to\nthe broken structural inversion symmetry at interfaces becomes increasingly\nimportant. Here we study interfacial spin-orbit coupling effects in magnetic\nbilayers using a simple Rashba model. The spin-orbit coupling introduces\nchirality into the behavior of the electrons and through them into the\nenergetics of the magnetization. In the derived form of the magnetization\ndynamics, all of the contributions that are linear in the spin-orbit coupling\nfollow from this chirality, considerably simplifying the analysis. For these\nsystems, an important consequence is a correlation between the\nDzyaloshinskii-Moriya interaction and the spin-orbit torque. We use this\ncorrelation to analyze recent experiments. \n\n"}
{"id": "1308.1623", "contents": "Title: On the structure of vertex cuts separating the ends of a graph Abstract: Dinits, Karzanov and Lomonosov showed that the minimal edge cuts of a finite\ngraph have the structure of a cactus, a tree-like graph constructed from\ncycles. Evangelidou and Papasoglu extended this to minimal cuts separating the\nends of an infinite graph. In this paper we show that minimal vertex cuts\nseparating the ends of a graph can be encoded by a succulent, a mild\ngeneralization of a cactus that is still tree-like. We go on to show that the\nearlier cactus results follow from our work. \n\n"}
{"id": "1308.4093", "contents": "Title: Nuclear medium cooling scenario in the light of new Cas A cooling data\n  and the 2 M_sun pulsar mass measurements Abstract: Recently, Elshamounty et al. performed a reanalysis of the surface\ntemperature of the neutron star in the supernova remnant Cassiopeia A on the\nbasis of Chandra data measured during last decade, and added a new data point.\nWe show that all reliably known temperature data of neutron stars including\nthose belonging to Cassiopea A can be comfortably explained in our \"nuclear\nmedium cooling\" scenario of neutron stars. The cooling rates account for\nmedium-modified one-pion exchange in dense matter, polarization effects in the\npair-breaking-formation processes operating on superfluid neutrons and protons\npaired in the 1S_0 state, and other relevant processes. The emissivity of the\npair-breaking-formation process in the 3P_2 state is a tiny quantity within our\nscenario. Crucial for a successful description of the Cassiopeia A cooling\nproves to be the thermal conductivity from both, the electrons and nucleons,\nbeing reduced by medium effects. Moreover, we exploit an EoS which stiffens at\nhigh densities due to an excluded volume effect and is capable of describing a\nmaximum mass of 2.1 M_sun, thus including the recent measurements of PSR\nJ1614-2230 and PSR J0348+0432. \n\n"}
{"id": "1308.4993", "contents": "Title: Spectrum of the open QCD flux tube in d=2+1 and its effective string\n  description Abstract: Simulations in lattice gauge theory suggest that the formation of a flux tube\nbetween quark and antiquark leads to quark confinement. It is conjectured that\nthe infrared behaviour of the flux tube is governed by an effective string\ntheory and simulations show good agreement between lattice data and its\npredictions. To next-to leading order ($R^{-3}$) in the inverse $q\\bar{q}$\nseparation $R$ the effective string theory is equivalent to Nambu-Goto string\ntheory. For the open flux tube in three dimensions corrections appear at order\n$R^{-4}$. We compare these predictions to high-accuracy measurements of the\ngroundstate energy of the flux tube in 3d SU(2) and SU(3) gauge theory and\nextract the coefficient of the leading order boundary term in the effective\naction. \n\n"}
{"id": "1308.5901", "contents": "Title: Torus equivariant D-modules and hypergeometric systems Abstract: We formalize, at the level of D-modules, the notion that A-hypergeometric\nsystems are equivariant versions of the classical hypergeometric equations. For\nthis purpose, we construct a functor on a suitable category of torus\nequivariant D-modules and show that it preserves key properties, such as\nholonomicity, regularity, and reducibility of monodromy representation. We also\nexamine its effect on solutions, characteristic varieties, and singular loci.\nWhen applied to certain binomial D-modules, our functor produces saturations of\nthe classical hypergeometric differential equations, a fact that sheds new\nlight on the D-module theoretic properties of these classical systems. \n\n"}
{"id": "1309.1390", "contents": "Title: Classification of homogeneous Einstein metrics on pseudo-hyperbolic\n  spaces Abstract: We classify the effective and transitive actions of a Lie group $G$ on an\nn-dimensional non-degenerate hyperboloid (also called real pseudo-hyperbolic\nspace), under the assumption that $G$ is a closed, connected Lie subgroup of\n$SO_0(n-r,r+1)$, the connected component of the indefinite special orthogonal\ngroup. Assuming additionally that $G$ acts completely reducible on $\\mathbb\nR^{n+1}$, we also obtain that any $G$-homogeneous Einstein pseudo-Riemannian\nmetric on a real, complex or quaternionic pseudo-hyperbolic space, or on a\npara-complex or para-quaternionic projective space is homothetic to either the\ncanonical metric or the Einstein metric of the canonical variation of a Hopf\npseudo-Riemannian submersion. \n\n"}
{"id": "1309.2292", "contents": "Title: Infrared absorption by graphene-hBN heterostructures Abstract: We propose a theory of optical absorption in monolayer graphene-hexagonal\nboron nitride (hBN) heterostructures. In highly oriented heterostructures, the\nhBN underlay produces a long-range moir\\'e superlattice potential for the\ngraphene electrons which modifies the selection rules for absorption of\nincoming photons in the infrared to visible frequency range. The details of the\nabsorption spectrum modification depend on the relative strength of the various\nsymmetry-allowed couplings between the graphene electrons and the hBN, and the\nresulting nature of the reconstructed band structure. \n\n"}
{"id": "1310.1020", "contents": "Title: Shapes of implied volatility with positive mass at zero Abstract: We study the shapes of the implied volatility when the underlying\ndistribution has an atom at zero and analyse the impact of a mass at zero on\nat-the-money implied volatility and the overall level of the smile. We further\nshow that the behaviour at small strikes is uniquely determined by the mass of\nthe atom up to high asymptotic order, under mild assumptions on the remaining\ndistribution on the positive real line. We investigate the structural\ndifference with the no-mass-at-zero case, showing how one\ncan--theoretically--distinguish between mass at the origin and a\nheavy-left-tailed distribution. We numerically test our model-free results in\nstochastic models with absorption at the boundary, such as the CEV process, and\nin jump-to-default models. Note that while Lee's moment formula tells that\nimplied variance is at most asymptotically linear in log-strike, other\ncelebrated results for exact smile asymptotics such as Benaim and Friz (09) or\nGulisashvili (10) do not apply in this setting--essentially due to the\nbreakdown of Put-Call duality. \n\n"}
{"id": "1310.1911", "contents": "Title: The 5D Standing Wave Braneworld With Real Scalar Field Abstract: We introduce the new 5D braneworld with the real scalar field in the bulk.\nThe model represents the brane which bounds collective oscillations of\ngravitational and scalar field standing waves. These waves are out of phase,\ni.e. the energy of oscillations passes back and forth between the scalar and\ngravitational waves. When the amplitude of the standing waves is small the\nbrane width and the size of the horizon in extra space are of a same order of\nmagnitude, and matter fields are localized in extra dimension due to the\npresence of the horizon. When oscillations are large trapping of matter fields\non the brane is provided mainly by the pressure of bulk waves. It is shown that\nin this case the mass of the lightest KK mode is determined by the smaller\nenergy scale corresponding to the horizon size, i.e. these modes can be created\nin accelerators at relatively low energies, which gives a chance to check the\npresent model. \n\n"}
{"id": "1310.3553", "contents": "Title: Suzaku observations of the diffuse x-ray emission across the fermi\n  bubbles' edges Abstract: We present Suzaku X-ray observations along two edge regions of the Fermi\nBubbles, with eight ~20 ksec pointings across the northern part of the North\nPolar Spur (NPS) surrounding the north bubble and six across the southernmost\nedge of the south bubble. After removing compact X-ray features, diffuse X-ray\nemission is clearly detected and is well reproduced by a three-component\nspectral model consisting of unabsorbed thermal emission (temperature kT ~0.1\nkeV from the Local Bubble (LB), absorbed kT ~0.3 keV thermal emission related\nto the NPS and/or Galactic Halo (GH), and a power-law component at a level\nconsistent with the cosmic X-ray background. The emission measure (EM) of the\n0.3 keV plasma decreases by ~50% toward the inner regions of the north-east\nbubble, with no accompanying temperature change. However, such a jump in the EM\nis not clearly seen in the south bubble data. While it is unclear if the NPS\noriginates from a nearby supernova remnant or is related to previous activity\nwithin/around the Galactic Center, our Suzaku observations provide evidence\nsuggestive of the latter scenario. In the latter framework, the presence of a\nlarge amount of neutral matter absorbing the X-ray emission as well as the\nexistence of the kT ~ 0.3 keV gas can be naturally interpreted as a weak shock\ndriven by the bubbles' expansion in the surrounding medium, with velocity v_exp\n~300 km/s (corresponding to shock Mach number M ~1.5), compressing the GH gas\nto form the NPS feature. We also derived an upper limit for any non-thermal\nX-ray emission component associated with the bubbles and demonstrate, that in\nagreement with the findings above, the non-thermal pressure and energy\nestimated from a one-zone leptonic model of its broad-band spectrum, are in\nrough equilibrium with that of the surrounding thermal plasma. \n\n"}
{"id": "1310.3694", "contents": "Title: A primal-dual algorithm for BSDEs Abstract: We generalize the primal-dual methodology, which is popular in the pricing of\nearly-exercise options, to a backward dynamic programming equation associated\nwith time discretization schemes of (reflected) backward stochastic\ndifferential equations (BSDEs). Taking as an input some approximate solution of\nthe backward dynamic program, which was pre-computed, e.g., by least-squares\nMonte Carlo, our methodology allows to construct a confidence interval for the\nunknown true solution of the time discretized (reflected) BSDE at time 0. We\nnumerically demonstrate the practical applicability of our method in two\nfive-dimensional nonlinear pricing problems where tight price bounds were\npreviously unavailable. \n\n"}
{"id": "1310.4142", "contents": "Title: Quantum harmonic oscillator in option pricing Abstract: The Black-Scholes model anticipates rather well the observed prices for\noptions in the case of a strike price that is not too far from the current\nprice of the underlying asset. Some useful extensions can be obtained by an\nadequate modification of the coefficients in the Black-Scholes equation. We\ninvestigate from a mathematical point of view an extension directly related to\nthe quantum harmonic oscillator. In the considered case, the solution is the\nsum of a series involving the Hermite-Gauss functions. A finite-dimensional\nversion is obtained by using a finite oscillator and the Harper functions. This\nsimplified model keeps the essential characteristics of the continuous one and\nuses finite sums instead of series and integrals. \n\n"}
{"id": "1310.5121", "contents": "Title: Generalized geometry, T-duality, and renormalization group flow Abstract: We interpret the physical $B$-field renormalization group flow in the\nlanguage of Courant algebroids, clarifying the sense in which this flow is the\nnatural \"Ricci flow\" for generalized geometry. Next we show that the $B$-field\nrenormalization group flow preserves T-duality in a natural sense. As\ncorollaries we obtain new long time existence results for the $B$-field\nrenormalization group flow. \n\n"}
{"id": "1310.6526", "contents": "Title: Exact simulation pricing with Gamma processes and their extensions Abstract: Exact path simulation of the underlying state variable is of great practical\nimportance in simulating prices of financial derivatives or their sensitivities\nwhen there are no analytical solutions for their pricing formulas. However, in\ngeneral, the complex dependence structure inherent in most nontrivial\nstochastic volatility (SV) models makes exact simulation difficult. In this\npaper, we present a nontrivial SV model that parallels the notable Heston SV\nmodel in the sense of admitting exact path simulation as studied by Broadie and\nKaya. The instantaneous volatility process of the proposed model is driven by a\nGamma process. Extensions to the model including superposition of independent\ninstantaneous volatility processes are studied. Numerical results show that the\nproposed model outperforms the Heston model and two other L\\'evy driven SV\nmodels in terms of model fit to the real option data. The ability to exactly\nsimulate some of the path-dependent derivative prices is emphasized. Moreover,\nthis is the first instance where an infinite-activity volatility process can be\napplied exactly in such pricing contexts. \n\n"}
{"id": "1311.0675", "contents": "Title: On strong binomial approximation for stochastic processes and\n  applications for financial modelling Abstract: This paper considers binomial approximation of continuous time stochastic\nprocesses. It is shown that, under some mild integrability conditions, a\nprocess can be approximated in mean square sense and in other strong metrics by\nbinomial processes, i.e., by processes with fixed size binary increments at\nsampling points. Moreover, this approximation can be causal, i.e., at every\ntime it requires only past historical values of the underlying process. In\naddition, possibility of approximation of solutions of stochastic differential\nequations by solutions of ordinary equations with binary noise is established.\nSome consequences for the financial modelling and options pricing models are\ndiscussed. \n\n"}
{"id": "1311.1545", "contents": "Title: Varadhan's formula, conditioned diffusions, and local volatilities Abstract: Motivated by marginals-mimicking results for It\\^o processes via SDEs and by\ntheir applications to volatility modeling in finance, we discuss the weak\nconvergence of the law of a hypoelliptic diffusions conditioned to belong to a\ntarget affine subspace at final time, namely $\\mathcal{L}(Z_t|Y_t = y)$ if\n$X_{\\cdot}=(Y_\\cdot,Z_{\\cdot})$. To do so, we revisit Varadhan-type estimates\nin a small-noise regime (as opposed to small-time), studying the density of the\nlower-dimensional component $Y$. The application to stochastic volatility\nmodels include the small-time and, for certain models, the large-strike\nasymptotics of the Gyongy-Dupire's local volatility function. The final product\nare asymptotic formulae that can (i) motivate parameterizations of the local\nvolatility surface and (ii) be used to extrapolate local volatilities in a\ngiven model. \n\n"}
{"id": "1311.3216", "contents": "Title: Breaking the EOS-Gravity Degeneracy with Masses and Pulsating\n  Frequencies of Neutron Stars Abstract: A thorough understanding of many astrophysical phenomena associated with\ncompact objects requires reliable knowledge about both the equation of state\n(EOS)of super-dense nuclear matter and the theory of strong-field gravity\nsimultaneously because of the EOS-gravity degeneracy. Currently, variations of\nthe neutron star (NS) mass-radius correlation from using alternative gravity\ntheories are much larger than those from changing the NS matter EOS within\nknown constraints. At least two independent observables are required to break\nthe EOS-gravity degeneracy. Using model EOSs for hybrid stars and a Yukawa-type\nnon-Newtonian gravity, we investigate both the mass-radius correlation and\npulsating frequencies of NSs. While the maximum mass of NSs increases, the\nfrequencies of the $f$, $p_1$, $p_2$, and $w_I$ pulsating modes are found to\ndecrease with the increasing strength of the Yukawa-type non-Newtonian gravity,\nproviding a useful reference for future determination simultaneously of both\nthe strong-field gravity and the supranuclear EOS by combining data of x-ray\nand gravitational wave emissions of neutron stars. \n\n"}
{"id": "1311.3881", "contents": "Title: Functional Ito Calculus, Path-dependence and the Computation of Greeks Abstract: Dupire's functional It\\^o calculus provides an alternative approach to the\nclassical Malliavin calculus for the computation of sensitivities, also called\nGreeks, of path-dependent derivatives prices. In this paper, we introduce a\nmeasure of path-dependence of functionals within the functional It\\^o calculus\nframework. Namely, we consider the Lie bracket of the space and time functional\nderivatives, which we use to classify functionals accordingly to their degree\nof path-dependence. We then revisit the problem of efficient numerical\ncomputation of Greeks for path-dependent derivatives using integration by parts\ntechniques. Special attention is paid to path-dependent functionals with zero\nLie bracket, called locally weakly path-dependent functionals in our\nclassification. Hence, we derive the weighted-expectation formulas for their\nGreeks. In the more general case of fully path-dependent functionals, we show\nthat, equipped with the functional It\\^o calculus, we are able to analyze the\neffect of the Lie bracket on the computation of Greeks. Moreover, we are also\nable to consider the more general dynamics of path-dependent volatility. These\nwere not achieved using Malliavin calculus. \n\n"}
{"id": "1311.6257", "contents": "Title: Filters and smoothers for self-exciting Markov modulated counting\n  processes Abstract: We consider a self-exciting counting process, the parameters of which depend\non a hidden finite-state Markov chain. We derive the optimal filter and\nsmoother for the hidden chain based on observation of the jump process. This\nfilter is in closed form and is finite dimensional. We demonstrate the\nperformance of this filter both with simulated data, and by analysing the\n`flash crash' of 6th May 2010 in this framework. \n\n"}
{"id": "1312.2281", "contents": "Title: Small-time asymptotics for a general local-stochastic volatility model\n  with a jump-to-default: curvature and the heat kernel expansion Abstract: We compute a sharp small-time estimate for implied volatility under a general\nuncorrelated local-stochastic volatility model. For this we use the Bellaiche\n\\cite{Bel81} heat kernel expansion combined with Laplace's method to integrate\nover the volatility variable on a compact set, and (after a gauge\ntransformation) we use the Davies \\cite{Dav88} upper bound for the heat kernel\non a manifold with bounded Ricci curvature to deal with the tail integrals. If\nthe correlation $\\rho < 0$, our approach still works if the drift of the\nvolatility takes a specific functional form and there is no local volatility\ncomponent, and our results include the SABR model for $\\beta=1, \\rho \\le 0$.\n\\bl{For uncorrelated stochastic volatility models, our results also include a\nSABR-type model with $\\beta=1$ and an affine mean-reverting drift, and the\nexponential Ornstein-Uhlenbeck model.} We later augment the model with a single\njump-to-default with intensity $\\lm$, which produces qualitatively different\nbehaviour for the short-maturity smile; in particular, for $\\rho=0$,\nlog-moneyness $x > 0$, the implied volatility increases by $\\lm f(x) t +o(t) $\nfor some function $f(x)$ which blows up as $x \\searrow 0$. Finally, we compare\nour result with the general asymptotic expansion in Lorig, Pagliarani \\&\nPascucci \\cite{LPP15}, and we verify our results numerically for the SABR model\nusing Monte Carlo simulation and the exact closed-form solution given in\nAntonov \\& Spector \\cite{AS12} for the case $\\rho=0$. \n\n"}
{"id": "1312.5427", "contents": "Title: The Novikov-Veselov Equation: Theory and Computation Abstract: Recent progress in the theory and computation for the Novikov-Veselov (NV)\nequation is reviewed with initial potentials decaying at infinity, focusing\nmainly on the zero-energy case. The inverse scattering method for the\nzero-energy NV equation is presented in the context of Manakov triples,\ntreating initial data of conductivity type rigorously. Special closed-form\nsolutions are presented, including multisolitons, ring solitons, and breathers.\nThe computational inverse scattering method is used to study zero-energy\nexceptional points and the relationship between supercritical, critical, and\nsubcritical potentials. \n\n"}
{"id": "1312.5881", "contents": "Title: Asymptotic formulas and inequalities for gamma function in terms of\n  tri-gamma function Abstract: In the paper, the authors establish some asymptotic formulas and double\ninequalities for the factorial $n!$ and the gamma function $\\Gamma$ in terms of\nthe tri-gamma function $\\psi'$. \n\n"}
{"id": "1312.7328", "contents": "Title: A family of density expansions for L\\'evy-type processes Abstract: We consider a defaultable asset whose risk-neutral pricing dynamics are\ndescribed by an exponential Levy-type martingale subject to default. This class\nof models allows for local volatility, local default intensity, and a locally\ndependent Levy measure. Generalizing and extending the novel adjoint expansion\ntechnique of Pagliarani, Pascucci, and Riga (2013), we derive a family of\nasymptotic expansions for the transition density of the underlying as well as\nfor European-style option prices and defaultable bond prices. For the density\nexpansion, we also provide error bounds for the truncated asymptotic series.\nOur method is numerically efficient; approximate transition densities and\nEuropean option prices are computed via Fourier transforms; approximate bond\nprices are computed as finite series. Additionally, as in Pagliarani et al.\n(2013), for models with Gaussian-type jumps, approximate option prices can be\ncomputed in closed form. Sample Mathematica code is provided. \n\n"}
{"id": "1401.1457", "contents": "Title: Measures of Causality in Complex Datasets with application to financial\n  data Abstract: This article investigates the causality structure of financial time series.\nWe concentrate on three main approaches to measuring causality: linear Granger\ncausality, kernel generalisations of Granger causality (based on ridge\nregression and the Hilbert--Schmidt norm of the cross-covariance operator) and\ntransfer entropy, examining each method and comparing their theoretical\nproperties, with special attention given to the ability to capture nonlinear\ncausality. We also present the theoretical benefits of applying non-symmetrical\nmeasures rather than symmetrical measures of dependence. We apply the measures\nto a range of simulated and real data. The simulated data sets were generated\nwith linear and several types of nonlinear dependence, using bivariate, as well\nas multivariate settings. An application to real-world financial data\nhighlights the practical difficulties, as well as the potential of the methods.\nWe use two real data sets: (1) U.S. inflation and one-month Libor; (2) S$\\&$P\ndata and exchange rates for the following currencies: AUDJPY, CADJPY, NZDJPY,\nAUDCHF, CADCHF, NZDCHF. Overall, we reach the conclusion that no single method\ncan be recognised as the best in all circumstances, and each of the methods has\nits domain of best applicability. We also highlight areas for improvement and\nfuture research. \n\n"}
{"id": "1401.1856", "contents": "Title: Pricing of basket options I Abstract: Pricing of high-dimensional options is a deep problem of the Theoretical\nFinancial Mathematics. In this article we present a new class of L\\'{e}vy\ndriven models of stock markets. In our opinion, any market model should be\nbased on a transparent and intuitively easily acceptable concept. In our case\nthis is a linear system of stochastic equations. Our market model is based on\nthe principle of inheritance, i.e. for the particular choice of parameters it\ncoincides with known models. Also, the model proposed is effectively\nnumerically realizable. For the class of models under cosideration, we give an\nexplicit representations of characteristic functions. This allows us us to\nconstruct a sequence of approximation formulas to price basket options. We show\nthat our approximation formulas have almost optimal rate of convergence in the\nsense of respective n-widths. \n\n"}
{"id": "1401.2314", "contents": "Title: Optimal Hedging for Fund & Insurance Managers with Partially Observable\n  Investment Flows Abstract: All the financial practitioners are working in incomplete markets full of\nunhedgeable risk-factors. Making the situation worse, they are only equipped\nwith the imperfect information on the relevant processes. In addition to the\nmarket risk, fund and insurance managers have to be prepared for sudden and\npossibly contagious changes in the investment flows from their clients so that\nthey can avoid the over- as well as under-hedging. In this work, the prices of\nsecurities, the occurrences of insured events and (possibly a network of) the\ninvestment flows are used to infer their drifts and intensities by a stochastic\nfiltering technique. We utilize the inferred information to provide the optimal\nhedging strategy based on the mean-variance (or quadratic) risk criterion. A\nBSDE approach allows a systematic derivation of the optimal strategy, which is\nshown to be implementable by a set of simple ODEs and the standard Monte Carlo\nsimulation. The presented framework may also be useful for manufactures and\nenergy firms to install an efficient overlay of dynamic hedging by financial\nderivatives to minimize the costs. \n\n"}
{"id": "1401.3988", "contents": "Title: A Hamiltonian Monte Carlo Method for Non-Smooth Energy Sampling Abstract: Efficient sampling from high-dimensional distributions is a challenging issue\nwhich is encountered in many large data recovery problems involving Markov\nchain Monte Carlo schemes. In this context, sampling using Hamiltonian dynamics\nis one of the recent techniques that have been proposed to exploit the target\ndistribution geometry. Such schemes have clearly been shown to be efficient for\nmulti-dimensional sampling, but are rather adapted to the exponential families\nof distributions with smooth energy function. In this paper, we address the\nproblem of using Hamiltonian dynamics to sample from probability distributions\nhaving non-differentiable energy functions such as $\\ell_1$. Such distributions\nare being more and more used in sparse signal and image recovery applications.\nThe proposed technique uses a modified leapfrog transform involving a proximal\nstep. The resulting non-smooth Hamiltonian Monte Carlo (ns-HMC) method is\ntested and validated on a number of experiments. Results show its ability to\naccurately sample according to various multivariate target distributions. The\nproposed technique is illustrated on synthetic examples and is applied to an\nimage denoising problem. \n\n"}
{"id": "1402.0243", "contents": "Title: Faster Comparison of Stopping Times by Nested Conditional Monte Carlo Abstract: We show that deliberately introducing a nested simulation stage can lead to\nsignificant variance reductions when comparing two stopping times by Monte\nCarlo. We derive the optimal number of nested simulations and prove that the\nalgorithm is remarkably robust to misspecifications of this number. The method\nis applied to several problems related to Bermudan/American options. In these\napplications, our method allows to substantially increase the efficiency of\nother variance reduction techniques, namely, Quasi-Control Variates and\nMultilevel Monte Carlo. \n\n"}
{"id": "1402.0594", "contents": "Title: The non-Abelian geometric phase in the diamond nitrogen-vacancy center Abstract: This paper introduces a theoretical framework for understanding the\naccumulation of non-Abelian geometric phases in rotating nitrogen-vacancy\ncenters in diamond. Specifically, we consider how degenerate states can be\nachieved and demonstrate that the resulting geometric phase for multiple paths\nis non-Abelian. We find that the non-Abelian nature of the phase is robust to\nfluctuations in the path and magnetic field. In contrast to previous studies of\nthe accumulation of Abelian geometric phases for nitrogen-vacancy centers under\nrotation we find that the limiting time-scale is $T_{1}$. As such a non-Abelian\ngeometric phase accumulation in nitrogen-vacancy centers has potential\nadvantages for applications as gyroscopes. \n\n"}
{"id": "1402.4685", "contents": "Title: The optimal decay estimates on the framework of Besov spaces for\n  generally dissipative systems Abstract: We give a new decay framework for general dissipative hyperbolic system and\nhyperbolic-parabolic composite system, which allow us to pay less attention on\nthe traditional spectral analysis in comparison with previous efforts. New\ningredients lie in the high-frequency and low-frequency decomposition of a\npseudo-differential operator and an interpolation inequality related to\nhomogeneous Besov spaces of negative order. Furthermore, we develop the\nLittlewood-Paley pointwise energy estimates and new time-weighted energy\nfunctionals to establish the optimal decay estimates on the framework of\nspatially critical Besov spaces for degenerately dissipative hyperbolic system\nof balance laws. Based on the $L^{p}(\\mathbb{R}^{n})$ embedding and improved\nGagliardo-Nirenberg inequality, the optimal\n$L^{p}(\\mathbb{R}^{n})$-$L^{2}(\\mathbb{R}^{n})(1\\leq p<2)$ decay rates and\n$L^{p}(\\mathbb{R}^{n})$-$L^{q}(\\mathbb{R}^{n})(1\\leq p<2\\leq q\\leq\\infty)$\ndecay rates are further shown. Finally, as a direct application, the optimal\ndecay rates for 3D damped compressible Euler equations are also obtained. \n\n"}
{"id": "1402.5352", "contents": "Title: Systemic Risk and Default Clustering for Large Financial Systems Abstract: As it is known in the finance risk and macroeconomics literature,\nrisk-sharing in large portfolios may increase the probability of creation of\ndefault clusters and of systemic risk. We review recent developments on\nmathematical and computational tools for the quantification of such phenomena.\nLimiting analysis such as law of large numbers and central limit theorems allow\nto approximate the distribution in large systems and study quantities such as\nthe loss distribution in large portfolios. Large deviations analysis allow us\nto study the tail of the loss distribution and to identify pathways to default\nclustering. Sensitivity analysis allows to understand the most likely ways in\nwhich different effects, such as contagion and systematic risks, combine to\nlead to large default rates. Such results could give useful insights into how\nto optimally safeguard against such events. \n\n"}
{"id": "1402.6204", "contents": "Title: The role of information in a two-traders market Abstract: In a very simple stock market, made by only two \\emph{initially equivalent}\ntraders, we discuss how the information can affect the performance of the\ntraders. More in detail, we first consider how the portfolios of the traders\nevolve in time when the market is \\emph{closed}. After that, we discuss two\nmodels in which an interaction with the outer world is allowed. We show that,\nin this case, the two traders behave differently, depending on \\textbf{i)} the\namount of information which they receive from outside; and \\textbf{ii)}the\nquality of this information. \n\n"}
{"id": "1403.1804", "contents": "Title: High-Order Splitting Methods for Forward PDEs and PIDEs Abstract: This paper is dedicated to the construction of high-order (in both space and\ntime) finite-difference schemes for both forward and backward PDEs and PIDEs,\nsuch that option prices obtained by solving both the forward and backward\nequations are consistent. This approach is partly inspired by Andreasen & Huge,\n2011 who reported a pair of consistent finite-difference schemes of first-order\napproximation in time for an uncorrelated local stochastic volatility model. We\nextend their approach by constructing schemes that are second-order in both\nspace and time and that apply to models with jumps and discrete dividends.\nTaking correlation into account in our approach is also not an issue. \n\n"}
{"id": "1403.3086", "contents": "Title: Kiloparsec-scale outflows are prevalent among luminous AGN: outflows and\n  feedback in the context of the overall AGN population Abstract: We present integral field unit (IFU) observations covering the [O\nIII]4959,5007 and H-Beta emission lines of sixteen z<0.2 type 2 active galactic\nnuclei (AGN). Our targets are selected from a well-constrained parent sample of\n24,000 AGN so that we can place our observations into the context of the\noverall AGN population. Our targets are radio-quiet with star formation rates\n(<~[10-100] Msol/yr) that are consistent with normal star-forming galaxies. We\ndecouple the kinematics of galaxy dynamics and mergers from outflows. We find\nhigh-velocity ionised gas (velocity widths of 600-1500 km/s and maximum\nvelocities of <=1700 km/s) with observed spatial extents of >~(6-16) kpc in all\ntargets and observe signatures of spherical outflows and bi-polar superbubbles.\nWe show that our targets are representative of z<0.2, luminous (i.e., L([O\nIII]) > 5x10^41 erg/s) type 2 AGN and that ionised outflows are not only common\nbut also in >=70% (3 sigma confidence) of cases, they are extended over\nkiloparsec scales. Our study demonstrates that galaxy-wide energetic outflows\nare not confined to the most extreme star-forming galaxies or radio-luminous\nAGN; however, there may be a higher incidence of the most extreme outflow\nvelocities in quasars hosted in ultra-luminous infrared galaxies. Both star\nformation and AGN activity appear to be energetically viable to drive the\noutflows and we find no definitive evidence that favours one process over the\nother. Although highly uncertain, we derive mass outflow rates (typically ~10x\nthe SFRs), kinetic energies (~0.5-10% of L[AGN]) and momentum rates (typically\n>~10-20x L[AGN]/c) consistent with theoretical models that predict AGN-driven\noutflows play a significant role in shaping the evolution of galaxies. \n\n"}
{"id": "1403.4099", "contents": "Title: High-speed detection of emergent market clustering via an unsupervised\n  parallel genetic algorithm Abstract: We implement a master-slave parallel genetic algorithm (PGA) with a bespoke\nlog-likelihood fitness function to identify emergent clusters within price\nevolutions. We use graphics processing units (GPUs) to implement a PGA and\nvisualise the results using disjoint minimal spanning trees (MSTs). We\ndemonstrate that our GPU PGA, implemented on a commercially available general\npurpose GPU, is able to recover stock clusters in sub-second speed, based on a\nsubset of stocks in the South African market. This represents a pragmatic\nchoice for low-cost, scalable parallel computing and is significantly faster\nthan a prototype serial implementation in an optimised C-based\nfourth-generation programming language, although the results are not directly\ncomparable due to compiler differences. Combined with fast online intraday\ncorrelation matrix estimation from high frequency data for cluster\nidentification, the proposed implementation offers cost-effective,\nnear-real-time risk assessment for financial practitioners. \n\n"}
{"id": "1403.7052", "contents": "Title: Analysis of a discontinuous Galerkin method for Koiter shell Abstract: We present an analysis for a mixed finite element method for the bending\nproblem of Koiter shell. We derive an error estimate showing that when the\ngeometrical coefficients of the shell mid-surface satisfy certain conditions\nthe finite element method has the optimal order of accuracy, which is uniform\nwith respect to the shell thickness. Generally, the error estimate shows how\nthe accuracy is affected by the shell geometry and thickness. It suggests that\nto achieve optimal rate of convergence, the triangulation should be properly\nrefined in regions where the shell geometry changes dramatically. The analysis\nis carried out for a balanced method in which the normal component of\ndisplacement is approximated by discontinuous piecewise cubic polynomials,\nwhile the tangential components are approximated by discontinuous piecewise\nquadratic polynomials, with some enrichment on elements that have edges on the\nfree boundary. Components of the membrane stress are approximated by continuous\npiecewise linear functions. \n\n"}
{"id": "1404.2824", "contents": "Title: Normal, Abby Normal, Prefix Normal Abstract: A prefix normal word is a binary word with the property that no substring has\nmore 1s than the prefix of the same length. This class of words is important in\nthe context of binary jumbled pattern matching. In this paper we present\nresults about the number $pnw(n)$ of prefix normal words of length $n$, showing\nthat $pnw(n) =\\Omega\\left(2^{n - c\\sqrt{n\\ln n}}\\right)$ for some $c$ and\n$pnw(n) = O \\left(\\frac{2^n (\\ln n)^2}{n}\\right)$. We introduce efficient\nalgorithms for testing the prefix normal property and a \"mechanical algorithm\"\nfor computing prefix normal forms. We also include games which can be played\nwith prefix normal words. In these games Alice wishes to stay normal but Bob\nwants to drive her \"abnormal\" -- we discuss which parameter settings allow\nAlice to succeed. \n\n"}
{"id": "1404.3153", "contents": "Title: Asymptotics for $d$-dimensional L\\'evy-type processes Abstract: We consider a general d-dimensional Levy-type process with killing. Combining\nthe classical Dyson series approach with a novel polynomial expansion of the\ngenerator A(t) of the Levy-type process, we derive a family of asymptotic\napproximations for transition densities and European-style options prices.\nExamples of stochastic volatility models with jumps are provided in order to\nillustrate the numerical accuracy of our approach. The methods described in\nthis paper extend the results from Corielli et al. (2010), Pagliarani and\nPascucci (2013) and Lorig et al. (2013a) for Markov diffusions to Markov\nprocesses with jumps. \n\n"}
{"id": "1404.3742", "contents": "Title: A 2.5% measurement of the growth rate from small-scale redshift space\n  clustering of SDSS-III CMASS galaxies Abstract: We perform the first fit to the anisotropic clustering of SDSS-III CMASS DR10\ngalaxies on scales of ~ 0.8 - 32 Mpc/h. A standard halo occupation distribution\nmodel evaluated near the best fit Planck LCDM cosmology provides a good fit to\nthe observed anisotropic clustering, and implies a normalization for the\npeculiar velocity field of M ~ 2 x 10^13 Msun/h halos of f*sigma8(z=0.57) =\n0.450 +/- 0.011. Since this constraint includes both quasi-linear and\nnon-linear scales, it should severely constrain modified gravity models that\nenhance pairwise infall velocities on these scales. Though model dependent, our\nmeasurement represents a factor of 2.5 improvement in precision over the\nanalysis of DR11 on large scales, f*sigma8(z=0.57) = 0.447 +/- 0.028, and is\nthe tightest single constraint on the growth rate of cosmic structure to date.\nOur measurement is consistent with the Planck LCDM prediction of 0.480 +/-\n0.010 at the ~1.9 sigma level. Assuming a halo mass function evaluated at the\nbest fit Planck cosmology, we also find that 10% of CMASS galaxies are\nsatellites in halos of mass M ~ 6 x 10^13 Msun/h. While none of our tests and\nmodel generalizations indicate systematic errors due to an insufficiently\ndetailed model of the galaxy-halo connection, the precision of these first\nresults warrant further investigation into the modeling uncertainties and\ndegeneracies with cosmological parameters. \n\n"}
{"id": "1404.4213", "contents": "Title: Noncommutative SO(2,3) gauge theory and noncommutative gravity Abstract: In this paper noncommutative gravity is constructed as a gauge theory of the\nnoncommutative SO(2,3) group, while the noncommutativity is canonical\n(constant). The Seiberg-Witten map is used to express noncommutative fields in\nterms of the corresponding commutative fields. The commutative limit of the\nmodel is the Einstein-Hilbert action with the cosmological constant term and\nthe topological Gauss-Bonnet term. We calculate the second order correction to\nthis model and obtain terms that are of zeroth to fourth power in the curvature\ntensor and torsion. Trying to relate our results with $f(R)$ and $f(T)$ models,\nwe analyze different limits of our model. In the limit of big cosmological\nconstant and vanishing torsion we obtain a $x$-dependent correction to the\ncosmological constant, i.e. noncommutativity leads to a $x$-dependent\ncosmological constant. We also discuss the limit of small cosmological constant\nand vanishing torsion and the teleparallel limit. \n\n"}
{"id": "1404.6792", "contents": "Title: Leveraged {ETF} implied volatilities from {ETF} dynamics Abstract: The growth of the exhange-traded fund (ETF) industry has given rise to the\ntrading of options written on ETFs and their leveraged counterparts {(LETFs)}.\nWe study the relationship between the ETF and LETF implied volatility surfaces\nwhen the underlying ETF is modeled by a general class of local-stochastic\nvolatility models. A closed-form approximation for prices is derived for\nEuropean-style options whose payoff depends on the terminal value of the ETF\nand/or LETF. Rigorous error bounds for this pricing approximation are\nestablished. A closed-form approximation for implied volatilities is also\nderived. We also discuss a scaling procedure for comparing implied volatilities\nacross leverage ratios. The implied volatility expansions and scalings are\ntested in three well-known settings: CEV, Heston and SABR. \n\n"}
{"id": "1405.2366", "contents": "Title: X-ray Observations of Complex Temperature Structure in the Cool-core\n  cluster Abell 85 Abstract: X-ray observations were used to examine the complex temperature structure of\nAbell 85, a cool-core galaxy cluster. Temperature features can provide evidence\nof merging events which shock heat the intracluster gas. Temperature maps were\nmade from both \\textit{Chandra} and \\textit{XMM-Newton} obervations. The\ncombination of a new, long-exposure \\textit{XMM} observation and an improved\ntemperature map binning technique produced the highest fidelity temperature\nmaps of A85 to date. Hot regions were detected near the subclusters to the\nSouth and Southwest in both the \\textit{Chandra} and \\textit{XMM} temperature\nmaps. The presence of these structures implies A85 is not relaxed. The hot\nregions may indicate the presence of shocks. The Mach numbers were estimated to\nbe $\\sim$1.9 at the locations of the hot spots. Observational effects will tend\nto systematically reduce temperature jumps, so the measured Mach numbers are\nlikely underestimated. Neither temperature map showed evidence for a shock in\nthe vicinity of the presumed radio relic near the Southwest subcluster.\nHowever, the presence of a weak shock cannot be ruled out. There was tension\nbetween the temperatures measured by the two instruments. \n\n"}
{"id": "1405.3284", "contents": "Title: PynPoint Code for Exoplanet Imaging Abstract: We announce the public release of PynPoint, a Python package that we have\ndeveloped for analysing exoplanet data taken with the angular differential\nimaging observing technique. In particular, PynPoint is designed to model the\npoint spread function of the central star and to subtract its flux contribution\nto reveal nearby faint companion planets. The current version of the package\ndoes this correction by using a principal component analysis method to build a\nbasis set for modelling the point spread function of the observations. We\ndemonstrate the performance of the package by reanalysing publicly available\ndata on the exoplanet beta Pictoris b, which consists of close to 24,000\nindividual image frames. We show that PynPoint is able to analyse this typical\ndata in roughly 1.5 minutes on a Mac Pro, when the number of images is reduced\nby co-adding in sets of 5. The main computational work parallelises well as a\nresult of a reliance on SciPy and NumPy functions. For this calculation the\npeak memory load is 6Gb, which can be run comfortably on most workstations. A\nsimpler calculation, by co-adding over 50, takes 3 seconds with a peak memory\nusage of 600 Mb. This can be performed easily on a laptop. In developing the\npackage we have modularised the code so that we will be able to extend\nfunctionality in future releases, through the inclusion of more modules,\nwithout it affecting the users application programming interface. We distribute\nthe PynPoint package through the central PyPi sever, and the documentation is\navailable online (http://pynpoint.ethz.ch). \n\n"}
{"id": "1405.3561", "contents": "Title: An explicit Euler scheme with strong rate of convergence for financial\n  SDEs with non-Lipschitz coefficients Abstract: We consider the approximation of stochastic differential equations (SDEs)\nwith non-Lipschitz drift or diffusion coefficients. We present a modified\nexplicit Euler-Maruyama discretisation scheme that allows us to prove strong\nconvergence, with a rate. Under some regularity and integrability conditions,\nwe obtain the optimal strong error rate. We apply this scheme to SDEs widely\nused in the mathematical finance literature, including the\nCox-Ingersoll-Ross~(CIR), the 3/2 and the Ait-Sahalia models, as well as a\nfamily of mean-reverting processes with locally smooth coefficients. We\nnumerically illustrate the strong convergence of the scheme and demonstrate its\nefficiency in a multilevel Monte Carlo setting. \n\n"}
{"id": "1405.4444", "contents": "Title: Arithmetic functions at consecutive shifted primes Abstract: For each of the functions $f \\in \\{\\phi, \\sigma, \\omega, \\tau\\}$ and every\nnatural number $k$, we show that there are infinitely many solutions to the\ninequalities $f(p_n-1) < f(p_{n+1}-1) < \\dots < f(p_{n+k}-1)$, and similarly\nfor $f(p_n-1) > f(p_{n+1}-1) > \\dots > f(p_{n+k}-1)$. We also answer some\nquestions of Sierpi\\'nski on the digit sums of consecutive primes. The\narguments make essential use of Maynard and Tao's method for producing many\nprimes in intervals of bounded length. \n\n"}
{"id": "1405.6111", "contents": "Title: Splitting and Matrix Exponential approach for jump-diffusion models with\n  Inverse Normal Gaussian, Hyperbolic and Meixner jumps Abstract: This paper is a further extension of the method proposed in Itkin, 2014 as\napplied to another set of jump-diffusion models: Inverse Normal Gaussian,\nHyperbolic and Meixner. To solve the corresponding PIDEs we accomplish few\nsteps. First, a second-order operator splitting on financial processes\n(diffusion and jumps) is applied to these PIDEs. To solve the diffusion\nequation, we use standard finite-difference methods. For the jump part, we\ntransform the jump integral into a pseudo-differential operator and construct\nits second order approximation on a grid which supersets the grid that we used\nfor the diffusion part. The proposed schemes are unconditionally stable in time\nand preserve positivity of the solution which is computed either via a matrix\nexponential, or via P'ade approximation of the matrix exponent. Various\nnumerical experiments are provided to justify these results. \n\n"}
{"id": "1405.7611", "contents": "Title: VAR and ES/CVAR Dependence on data cleaning and Data Models: Analysis\n  and Resolution Abstract: Historical (Stressed-) Value-at-Risk ((S)VAR), and Expected Shortfall (ES),\nare widely used risk measures in regulatory capital and Initial Margin, i.e.\nfunding, computations. However, whilst the definitions of VAR and ES are\nunambiguous, they depend on input distributions that are data-cleaning- and\nData-Model-dependent. We quantify the scale of these effects from USD CDS\n(2004--2014), and from USD interest rates (1989--2014, single-curve setup\nbefore 2004, multi-curve setup after 2004), and make two standardisation\nproposals: for data; and for Data-Models. VAR and ES are required for lifetime\nportfolio calculations, i.e. collateral calls, which cover a wide range of\nmarket states. Hence we need standard, i.e. clean, complete, and common (i.e.\nidentical for all banks), market data also covering this wide range of market\nstates. This data is historically incomplete and not clean hence data\nstandardization is required. Stressed VAR and ES require moving market\nmovements during a past (usually not recent) window to current, and future,\nmarket states. All choices (e.g. absolute difference, relative, relative scaled\nby some function of market states) implicitly define a Data Model for\ntransformation of extreme market moves (recall that 99th percentiles are\ntypical, and the behaviour of the rest is irrelevant). Hence we propose\nstandard Data Models. These are necessary because different banks have\ndifferent stress windows. Where there is no data, or a requirement for\nsimplicity, we propose standard lookup tables (one per window, etc.). Without\nthis standardization of data and Data Models we demonstrate that VAR and ES are\ncomplex derivatives of subjective choices. \n\n"}
{"id": "1406.1719", "contents": "Title: Smooth Parametrizations in Dynamics, Analysis, Diophantine and\n  Computational Geometry Abstract: Smooth parametrization consists in a subdivision of the mathematical objects\nunder consideration into simple pieces, and then parametric representation of\neach piece, while keeping control of high order derivatives. The main goal of\nthe present paper is to provide a short overview of some results and open\nproblems on smooth parametrization and its applications in several apparently\nrather separated domains: Smooth Dynamics, Diophantine Geometry, Approximation\nTheory, and Computational Geometry.\n  The structure of the results, open problems, and conjectures in each of these\ndomains shows in many cases a remarkable similarity, which we try to stress.\nSometimes this similarity can be easily explained, sometimes the reasons remain\nsomewhat obscure, and it motivates some natural questions discussed in the\npaper. We present also some new results, stressing interconnection between\nvarious types and various applications of smooth parametrization. \n\n"}
{"id": "1406.2053", "contents": "Title: A Method of Reducing Dimension of Space Variables in Multi-dimensional\n  Black-Scholes Equations Abstract: We study a method of reducing space dimension in multi-dimensional\nBlack-Scholes partial differential equations as well as in multi-dimensional\nparabolic equations. We prove that a multiplicative transformation of space\nvariables in the Black-Scholes partial differential equation reserves the form\nof Black-Scholes partial differential equation and reduces the space dimension.\nWe show that this transformation can reduce the number of sources of risks by\ntwo or more in some cases by giving remarks and several examples of financial\npricing problems. We also present that the invariance of the form of\nBlack-Scholes equations is based on the invariance of the form of parabolic\nequation under a change of variables with the linear combination of variables. \n\n"}
{"id": "1406.2335", "contents": "Title: No-Go Theorems for Unitary and Interacting Partially Massless Spin-Two\n  Fields Abstract: We examine the generic theory of a partially massless (PM) spin-two field\ninteracting with gravity in four dimensions from a bottom-up perspective. By\nanalyzing the most general form of the Lagrangian, we first show that if such a\ntheory exists, its de Sitter background must admit either so(1, 5) or so(2, 4)\nglobal symmetry depending on the relative sign of the kinetic terms: the former\nfor a positive sign the latter for a negative sign. Further analysis reveals\nthat the coupling constant of the PM cubic self-interaction must be fixed with\na purely imaginary number in the case of a positive sign. We conclude that\nthere cannot exist a unitary theory of a PM spin-two field coupled to Einstein\ngravity with a perturbatively local Lagrangian. In the case of a negative sign\nwe recover conformal gravity. As a special case of our analysis, it is shown\nthat the PM limit of massive gravity also lacks the PM gauge symmetry. \n\n"}
{"id": "1406.2581", "contents": "Title: Multilevel path simulation for weak approximation schemes Abstract: In this paper we discuss the possibility of using multilevel Monte Carlo\n(MLMC) methods for weak approximation schemes. It turns out that by means of a\nsimple coupling between consecutive time discretisation levels, one can achieve\nthe same complexity gain as under the presence of a strong convergence. We\nexemplify this general idea in the case of weak Euler scheme for L\\'evy driven\nstochastic differential equations, and show that, given a weak convergence of\norder $\\alpha\\geq 1/2,$ the complexity of the corresponding \"weak\" MLMC\nestimate is of order $\\varepsilon^{-2}\\log ^{2}(\\varepsilon).$ The numerical\nperformance of the new \"weak\" MLMC method is illustrated by several numerical\nexamples. \n\n"}
{"id": "1406.4329", "contents": "Title: Ergodic BSDEs with jumps and time dependence Abstract: In this paper we look at ergodic BSDEs in the case where the forward dynamics\nare given by the solution to a non-autonomous (time-periodic coefficients)\nOrnstein-Uhlenbeck SDE with L\\'evy noise, taking values in a separable Hilbert\nspace. We establish the existence of a unique bounded solution to an infinite\nhorizon discounted BSDE. We then use the vanishing discount approach, together\nwith coupling techniques, to obtain a Markovian solution to the EBSDE. We also\nprove uniqueness under certain growth conditions. Applications are then given,\nin particular to risk-averse ergodic optimal control and power plant evaluation\nunder uncertainty. \n\n"}
{"id": "1406.6090", "contents": "Title: Semiclassical approximation in stochastic optimal control I. Portfolio\n  construction problem Abstract: This is the first in a series of papers in which we study an efficient\napproximation scheme for solving the Hamilton-Jacobi-Bellman equation for\nmulti-dimensional problems in stochastic control theory. The method is a\ncombination of a WKB style asymptotic expansion of the value function, which\nreduces the second order HJB partial differential equation to a hierarchy of\nfirst order PDEs, followed by a numerical algorithm to solve the first few of\nthe resulting first order PDEs. This method is applicable to stochastic systems\nwith a relatively large number of degrees of freedom, and does not seem to\nsuffer from the curse of dimensionality. Computer code implementation of the\nmethod using modest computational resources runs essentially in real time. We\napply the method to solve a general portfolio construction problem. \n\n"}
{"id": "1406.6496", "contents": "Title: Using an Artificial Financial Market for studying a Cryptocurrency\n  Market Abstract: This paper presents an agent-based artificial cryptocurrency market in which\nheterogeneous agents buy or sell cryptocurrencies, in particular Bitcoins. In\nthis market, there are two typologies of agents, Random Traders and Chartists,\nwhich interact with each other by trading Bitcoins. Each agent is initially\nendowed with a finite amount of crypto and/or fiat cash and issues buy and sell\norders, according to her strategy and resources. The number of Bitcoins\nincreases over time with a rate proportional to the real one, even if the\nmining process is not explicitly modelled.\n  The model proposed is able to reproduce some of the real statistical\nproperties of the price absolute returns observed in the Bitcoin real market.\nIn particular, it is able to reproduce the autocorrelation of the absolute\nreturns, and their cumulative distribution function. The simulator has been\nimplemented using object-oriented technology, and could be considered a valid\nstarting point to study and analyse the cryptocurrency market and its future\nevolutions. \n\n"}
{"id": "1406.7526", "contents": "Title: Predictability of Volatility Homogenised Financial Time Series Abstract: Modelling financial time series as a time change of a simpler process has\nbeen proposed in various forms over the years. One of such recent approaches is\ncalled volatility homogenisation decomposition, and has been designed\nspecifically to aid the forecasting of price changes on financial markets. The\nauthors of this method have attempted to prove the its usefulness by applying a\nspecific forecasting procedure and determining the effectiveness of this\nprocedure on the decomposed time series, as compared with the original time\nseries. This is problematic in at least two ways. First, the choice of the\nforecasting procedure obviously has an effect on the results, rendering them\nnon-exhaustive. Second, the results obtained were not completely convincing,\nwith some values falling under 50% guessing rate. Additionally, only nine\nAustralian stocks were being investigated, which further limits the scope of\nthis proof. In this study we propose to find the usefulness of volatility\nhomogenisation by calculating the predictability of the decomposed time series\nand comparing it to the predictability of the original time series. We are\napplying information-theoretic notion of entropy rate to quantify\npredictability, which guarantees the result is not tied to a specific method of\nprediction, and additionally we base our calculations on a large number of\nstocks from the Warsaw Stock Exchange. \n\n"}
{"id": "1406.7580", "contents": "Title: Hypercontractivity for Functional Stochastic Differential Equations Abstract: An explicit sufficient condition on the hypercontractivity is derived for the\nMarkov semigroup associated to a class of functional stochastic differential\nequations. Consequently, the semigroup $P_t$ converges exponentially to its\nunique invariant probability measure $\\mu$ in entropy, $L^2(\\mu)$ and the\ntotally variational norm, and it is compact in $L^2(\\mu)$ for large $t>0$. This\nprovides a natural class of non-symmetric Markov semigroups which are compact\nfor large time but non-compact for small time. A semi-linear model which may\nnot satisfy this sufficient condition is also investigated. \n\n"}
{"id": "1407.0256", "contents": "Title: To sigmoid-based functional description of the volatility smile Abstract: We propose a new static parameterization of the implied volatility surface\nwhich is constructed by using polynomials of sigmoid functions combined with\nsome other terms. This parameterization is flexible enough to fit market\nimplied volatilities which demonstrate smile or skew. An arbitrage-free\ncalibration algorithm is considered that constructs the implied volatility\nsurface as a grid in the strike-expiration space and guarantees a lack of\narbitrage at every node of this grid. We also demonstrate how to construct an\narbitrage-free interpolation and extrapolation in time, as well as build a\nlocal volatility and implied pdf surfaces. Asymptotic behavior of this\nparameterization is discussed, as well as results on stability of the\ncalibrated parameters are presented. Numerical examples show robustness of the\nproposed approach in building all these surfaces as well as demonstrate a\nbetter quality of the fit as compared with some known models. \n\n"}
{"id": "1407.1321", "contents": "Title: Exact Solutions of Fractional Chern Insulators: Interacting Particles in\n  the Hofstadter Model at Finite Size Abstract: We show that all the bands of the Hofstadter model on the torus have an\nexactly flat dispersion and Berry curvature when a special system size is\nchosen. This result holds for any hopping and Chern number. Our analysis\ntherefore provides a simple rule for choosing a particularly advantageous\nsystem size when designing a Hofstadter system whose size is controllable, like\na qubit lattice or an optical cavity array. The density operators projected\nonto the flat bands obey exactly the Girvin-MacDonald-Platzman algebra, like\nfor Landau levels in the continuum in the case of $C=1$, or obey its\nstraightforward generalization in the case of $C>1$. This allows a mapping\nbetween density-density interaction Hamiltonians for particles in the\nHofstatder model and in a continuum Landau level. By using the well-known\npseudopotential construction in the latter case, we obtain fractional Chern\ninsulator phases, the lattice counterpart of fractional quantum Hall phases,\nthat are exact zero-energy ground states of the Hofstadter model with certain\ninteractions. Finally, the addition of a harmonic trapping potential is shown\nto lead to an appealingly symmetric description in which a new Hofstadter model\nappears in momentum space. \n\n"}
{"id": "1407.1637", "contents": "Title: Bounds and algorithms for limited packings in graphs Abstract: We consider (closed neighbourhood) packings and their generalization in\ngraphs called limited packings. A vertex set X in a graph G is a k-limited\npacking if for any vertex $v\\in V(G)$, $\\left|N[v] \\cap X\\right| \\le k$, where\n$N[v]$ is the closed neighbourhood of $v$. The k-limited packing number\n$L_k(G)$ is the largest size of a k-limited packing in G. Limited packing\nproblems can be considered as secure facility location problems in networks. We\ndevelop probabilistic and greedy approaches to limited packings in graphs,\nproviding lower bounds for the k-limited packing number, and randomized and\ngreedy algorithms to find k-limited packings satisfying the bounds. Some upper\nbounds for $L_k(G)$ are given as well. The problem of finding a maximum size\nk-limited packing is known to be NP-complete even in split or bipartite graphs. \n\n"}
{"id": "1407.3422", "contents": "Title: A Spectral Algorithm for Inference in Hidden Semi-Markov Models Abstract: Hidden semi-Markov models (HSMMs) are latent variable models which allow\nlatent state persistence and can be viewed as a generalization of the popular\nhidden Markov models (HMMs). In this paper, we introduce a novel spectral\nalgorithm to perform inference in HSMMs. Unlike expectation maximization (EM),\nour approach correctly estimates the probability of given observation sequence\nbased on a set of training sequences. Our approach is based on estimating\nmoments from the sample, whose number of dimensions depends only\nlogarithmically on the maximum length of the hidden state persistence.\nMoreover, the algorithm requires only a few matrix inversions and is therefore\ncomputationally efficient. Empirical evaluations on synthetic and real data\ndemonstrate the advantage of the algorithm over EM in terms of speed and\naccuracy, especially for large datasets. \n\n"}
{"id": "1407.5020", "contents": "Title: Causal Non-Linear Financial Networks Abstract: In our previous study we have presented an approach to studying lead--lag\neffect in financial markets using information and network theories. Methodology\npresented there, as well as previous studies using Pearson's correlation for\nthe same purpose, approached the concept of lead--lag effect in a naive way. In\nthis paper we further investigate the lead--lag effect in financial markets,\nthis time treating them as causal effects. To incorporate causality in a manner\nconsistent with our previous study, that is including non-linear\ninterdependencies, we base this study on a generalisation of Granger causality\nin the form of transfer entropy, or equivalently a special case of conditional\n(partial) mutual information. This way we are able to produce networks of\nstocks, where directed links represent causal relationships for a specific time\nlag. We apply this procedure to stocks belonging to the NYSE 100 index for\nvarious time lags, to investigate the short-term causality on this market, and\nto comment on the resulting Bonferroni networks. \n\n"}
{"id": "1407.7860", "contents": "Title: Clustering-based Redshift Estimation: Comparison to Spectroscopic\n  Redshifts Abstract: We investigate the potential and accuracy of clustering-based redshift\nestimation using the method proposed by M\\'enard et al. (2013). This technique\nenables the inference of redshift distributions from measurements of the\nspatial clustering of arbitrary sources, using a set of reference objects for\nwhich redshifts are known. We apply it to a sample of spectroscopic galaxies\nfrom the Sloan Digital Sky Survey and show that, after carefully controlling\nthe sampling efficiency over the sky, we can estimate redshift distributions\nwith high accuracy. Probing the full colour space of the SDSS galaxies, we show\nthat we can recover the corresponding mean redshifts with an accuracy ranging\nfrom $\\delta$z=0.001 to 0.01. We indicate that this mapping can be used to\ninfer the redshift probability distribution of a single galaxy. We show how the\nlack of information on the galaxy bias limits the accuracy of the inference and\nshow comparisons between clustering redshifts and photometric redshifts for\nthis dataset. This analysis demonstrates, using real data, that\nclustering-based redshift inference provides a powerful data-driven technique\nto explore the redshift distribution of arbitrary datasets, without any prior\nknowledge on the spectral energy distribution of the sources. \n\n"}
{"id": "1408.3656", "contents": "Title: Width, Ricci curvature and minimal hypersurfaces Abstract: Let $(M,g_0)$ be a closed Riemannian manifold of dimension $n$, for $3 \\leq n\n\\leq 7$, and non-negative Ricci curvature. Let $g = \\phi^2 g_0$ be a metric in\nthe conformal class of $g_0$. We show that there exists a smooth closed\nembedded minimal hypersurface in $(M,g)$ of volume bounded by $C\nV^{\\frac{n-1}{n}}$, where $V$ is the total volume of $(M,g)$ and $C$ is a\nconstant that depends only on $n$. When $Ric(M,g_0) \\geq -(n-1)$ we obtain a\nsimilar bound with constant $C$ depending only on $n$ and the volume of\n$(M,g_0)$.\n  Our second result concerns manifolds $(M,g)$ of positive Ricci curvature. We\nobtain an effective version of a theorem of F. Coda Marques and A. Neves on the\nexistence of infinitely many minimal hypersurfaces on $(M,g)$. We show that for\nany such manifold there exists $k$ minimal hypersurfaces of volume at most $C_n\nV \\left( sys_{n-1}(M)\\right)^{-\\frac{1}{n-1}} k ^ {\\frac{1}{n-1}}$, where $V$\ndenotes the volume of $(M,g_0)$ and $sys_{n-1}(M)$ is the smallest volume of a\nnon-trivial minimal hypersurface. \n\n"}
{"id": "1408.3934", "contents": "Title: On Detecting Messaging Abuse in Short Text Messages using Linguistic and\n  Behavioral patterns Abstract: The use of short text messages in social media and instant messaging has\nbecome a popular communication channel during the last years. This rising\npopularity has caused an increment in messaging threats such as spam, phishing\nor malware as well as other threats. The processing of these short text message\nthreats could pose additional challenges such as the presence of lexical\nvariants, SMS-like contractions or advanced obfuscations which can degrade the\nperformance of traditional filtering solutions. By using a real-world SMS data\nset from a large telecommunications operator from the US and a social media\ncorpus, in this paper we analyze the effectiveness of machine learning filters\nbased on linguistic and behavioral patterns in order to detect short text spam\nand abusive users in the network. We have also explored different ways to deal\nwith short text message challenges such as tokenization and entity detection by\nusing text normalization and substring clustering techniques. The obtained\nresults show the validity of the proposed solution by enhancing baseline\napproaches. \n\n"}
{"id": "1408.4101", "contents": "Title: Noncommutative Generalization of Wilson Lines Abstract: A classical Wilson line is a cooresponedce between closed paths and elemets\nof a gauge group. However the noncommutative geometry does not have closed\npaths. But noncommutative geometry have good generalizations of both: the\ncovering projection, and the group of covering transformations. These notions\nare used for a construction of noncommutative Wilson lines. Wilson lines can\nalso be constructed as global pure gauge fields on the universal covering\nspace. The noncommutative analog of this construction is also developed. \n\n"}
{"id": "1408.6513", "contents": "Title: Efficient solution of structural default models with correlated jumps\n  and mutual obligations Abstract: The structural default model of Lipton and Sepp, 2009 is generalized for a\nset of banks with mutual interbank liabilities whose assets are driven by\ncorrelated Levy processes with idiosyncratic and common components. The\nmulti-dimensional problem is made tractable via a novel computational method,\nwhich generalizes the one-dimensional fractional partial differential equation\nmethod of Itkin, 2014 to the two- and three-dimensional cases. This method is\nunconditionally stable and of the second order of approximation in space and\ntime; in addition, for many popular Levy models it has linear complexity in\neach dimension. Marginal and joint survival probabilities for two and three\nbanks with mutual liabilities are computed. The effects of mutual liabilities\nare discussed, and numerical examples are given to illustrate these effects. \n\n"}
{"id": "1408.6938", "contents": "Title: Fast and Simple Method for Pricing Exotic Options using Gauss-Hermite\n  Quadrature on a Cubic Spline Interpolation Abstract: There is a vast literature on numerical valuation of exotic options using\nMonte Carlo, binomial and trinomial trees, and finite difference methods. When\ntransition density of the underlying asset or its moments are known in closed\nform, it can be convenient and more efficient to utilize direct integration\nmethods to calculate the required option price expectations in a backward\ntime-stepping algorithm. This paper presents a simple, robust and efficient\nalgorithm that can be applied for pricing many exotic options by computing the\nexpectations using Gauss-Hermite integration quadrature applied on a cubic\nspline interpolation. The algorithm is fully explicit but does not suffer the\ninherent instability of the explicit finite difference counterpart. A `free'\nbonus of the algorithm is that it already contains the function for fast and\naccurate interpolation of multiple solutions required by many discretely\nmonitored path dependent options. For illustrations, we present examples of\npricing a series of American options with either Bermudan or continuous\nexercise features, and a series of exotic path-dependent options of target\naccumulation redemption note (TARN). Results of the new method are compared\nwith Monte Carlo and finite difference methods, including some of the most\nadvanced or best known finite difference algorithms in the literature. The\ncomparison shows that, despite its simplicity, the new method can rival with\nsome of the best finite difference algorithms in accuracy and at the same time\nit is significantly faster. Virtually the same algorithm can be applied to\nprice other path-dependent financial contracts such as Asian options and\nvariable annuities. \n\n"}
{"id": "1409.0118", "contents": "Title: Analysis of Spin Financial Market by GARCH Model Abstract: A spin model is used for simulations of financial markets. To determine\nreturn volatility in the spin financial market we use the GARCH model often\nused for volatility estimation in empirical finance. We apply the Bayesian\ninference performed by the Markov Chain Monte Carlo method to the parameter\nestimation of the GARCH model. It is found that volatility determined by the\nGARCH model exhibits \"volatility clustering\" also observed in the real\nfinancial markets. Using volatility determined by the GARCH model we examine\nthe mixture-of-distribution hypothesis (MDH) suggested for the asset return\ndynamics. We find that the returns standardized by volatility are approximately\nstandard normal random variables. Moreover we find that the absolute\nstandardized returns show no significant autocorrelation. These findings are\nconsistent with the view of the MDH for the return dynamics. \n\n"}
{"id": "1409.1710", "contents": "Title: Bonus scaling and BCFW in N=7 supergravity Abstract: In search of natural building blocks for supergravity amplitudes, a tentative\ncriteria is term-by-term bonus z^-2 large momentum scaling. For a given choice\nof deformation legs, we present such an expansion in the form of a BCFW\nrepresentation in N=7 supergravity based on a special shift. We will show that\nthis improved scaling behavior, with respect to the fully N=8 representation,\nis due to its automatic incorporation of the so called bonus relations. \n\n"}
{"id": "1409.4668", "contents": "Title: High-resolution, H band Spectroscopy of Be Stars with SDSS-III/APOGEE:\n  I. New Be Stars, Line Identifications, and Line Profiles Abstract: APOGEE has amassed the largest ever collection of multi-epoch,\nhigh-resolution (R~22,500), H-band spectra for B-type emission line (Be) stars.\nThe 128/238 APOGEE Be stars for which emission had never previously been\nreported serve to increase the total number of known Be stars by ~6%. We focus\non identification of the H-band lines and analysis of the emission peak\nvelocity separations (v_p) and emission peak intensity ratios (V/R) of the\nusually double-peaked H I and non-hydrogen emission lines. H I Br11 emission is\nfound to preferentially form in the circumstellar disks at an average distance\nof ~2.2 stellar radii. Increasing v_p toward the weaker Br12--Br20 lines\nsuggests these lines are formed interior to Br11. By contrast, the observed IR\nFe II emission lines present evidence of having significantly larger formation\nradii; distinctive phase lags between IR Fe II and H I Brackett emission lines\nfurther supports that these species arise from different radii in Be disks.\nSeveral emission lines have been identified for the first time including\n~16895, a prominent feature in the spectra for almost a fifth of the sample\nand, as inferred from relatively large v_p compared to the Br11-Br20, a tracer\nof the inner regions of Be disks. Unlike the typical metallic lines observed\nfor Be stars in the optical, the H-band metallic lines, such as Fe II 16878,\nnever exhibit any evidence of shell absorption, even when the H I lines are\nclearly shell-dominated. The first known example of a quasi-triple-peaked Br11\nline profile is reported for HD 253659, one of several stars exhibiting intra-\nand/or extra-species V/R and radial velocity variation within individual\nspectra. Br11 profiles are presented for all discussed stars, as are full\nAPOGEE spectra for a portion of the sample. \n\n"}
{"id": "1410.7316", "contents": "Title: Randomisation and recursion methods for mixed-exponential Levy models,\n  with financial applications Abstract: We develop a new Monte Carlo variance reduction method to estimate the\nexpectation of two commonly encountered path-dependent functionals:\nfirst-passage times and occupation times of sets. The method is based on a\nrecursive approximation of the first-passage time probability and expected\noccupation time of sets of a Levy bridge process that relies in part on a\nrandomisation of the time parameter. We establish this recursion for general\nLevy processes and derive its explicit form for mixed-exponential\njump-diffusions, a dense subclass (in the sense of weak approximation) of Levy\nprocesses, which includes Brownian motion with drift, Kou's double-exponential\nmodel and hyper-exponential jump-diffusion models. We present a highly accurate\nnumerical realisation and derive error estimates. By way of illustration the\nmethod is applied to the valuation of range accruals and barrier options under\nexponential Levy models and Bates-type stochastic volatility models with\nexponential jumps. Compared with standard Monte Carlo methods, we find that the\nmethod is significantly more efficient. \n\n"}
{"id": "1410.8522", "contents": "Title: The physics inside the scaling relations for X-ray galaxy clusters: gas\n  clumpiness, gas mass fraction and slope of the pressure profile Abstract: In galaxy clusters, the relations between observables in X-ray and millimeter\nwave bands and the total mass have normalizations, slopes and redshift\nevolutions that are simple to estimate in a self-similar scenario. We study\nthese scaling relations and show that they can be efficiently expressed, in a\nmore coherent picture, by fixing the normalizations and slopes to the\nself-similar predictions, and advocating, as responsible of the observed\ndeviations, only three physical mass-dependent quantities: the gas clumpiness\n$C$, the gas mass fraction $f_g$ and the logarithmic slope of the thermal\npressure profile $\\beta_P$. We use samples of the observed gas masses,\ntemperature, luminosities, and Compton parameters in local clusters to\nconstrain normalization and mass dependence of these 3 physical quantities, and\nmeasure: $C^{0.5} f_g = 0.110 (\\pm 0.002 \\pm 0.002) \\left( E_z M / 5 \\times\n10^{14} M_{\\odot} \\right)^{0.198 (\\pm 0.025 \\pm 0.04)}$ and $\\beta_P = -d \\ln\nP/d \\ln r = 3.14 (\\pm 0.04 \\pm 0.02) \\left( E_z M / 5 \\times 10^{14} M_{\\odot}\n\\right)^{0.071 (\\pm 0.012 \\pm 0.004)}$, where both a statistical and systematic\nerror (the latter mainly due to the cross-calibration uncertainties affecting\nthe \\cxo\\ and \\xmm\\ results used in the present analysis) are quoted. The\ndegeneracy between $C$ and $f_g$ is broken by using the estimates of the\nCompton parameters. Together with the self-similar predictions, these estimates\non $C$, $f_g$ and $\\beta_P$ define an inter-correlated internally-consistent\nset of scaling relations that reproduces the mass estimates with the lowest\nresiduals. \n\n"}
{"id": "1411.0034", "contents": "Title: Hypercharge Flux in Heterotic Compactifications Abstract: We study heterotic Calabi-Yau models with hypercharge flux breaking, where\nthe visible E8 gauge group is directly broken to the standard model group by a\nnon-flat gauge bundle, rather than by a two-step process involving an\nintermediate grand unified theory and a Wilson line. It is shown that the\nrequired alternative E8 embeddings of hypercharge, normalized as required for\ngauge unification, can be found and we classify these possibilities. However,\nfor all but one of these embeddings we prove a general no-go theorem which\nasserts that no suitable geometry and vector bundle leading to a standard model\nspectrum can be found. Intuitively, this happens due to the large number of\nindex conditions which have to be imposed in order to obtain a correct physical\nspectrum in the absence of an underlying grand unified theory. \n\n"}
{"id": "1411.1624", "contents": "Title: General smile asymptotics with bounded maturity Abstract: We provide explicit conditions on the distribution of risk-neutral\nlog-returns which yield sharp asymptotic estimates on the implied volatility\nsmile. We allow for a variety of asymptotic regimes, including both small\nmaturity (with arbitrary strike) and extreme strike (with arbitrary bounded\nmaturity), extending previous work of Benaim and Friz [Math. Finance 19 (2009),\n1-12]. We present applications to popular models, including Carr-Wu finite\nmoment logstable model, Merton's jump diffusion model and Heston's model. \n\n"}
{"id": "1411.1646", "contents": "Title: Metric and non-metric proximity transformations at linear costs Abstract: Domain specific (dis-)similarity or proximity measures used e.g. in alignment\nalgorithms of sequence data, are popular to analyze complex data objects and to\ncover domain specific data properties. Without an underlying vector space these\ndata are given as pairwise (dis-)similarities only. The few available methods\nfor such data focus widely on similarities and do not scale to large data sets.\nKernel methods are very effective for metric similarity matrices, also at large\nscale, but costly transformations are necessary starting with non-metric (dis-)\nsimilarities. We propose an integrative combination of Nystroem approximation,\npotential double centering and eigenvalue correction to obtain valid kernel\nmatrices at linear costs in the number of samples. By the proposed approach\neffective kernel approaches, become accessible. Experiments with several larger\n(dis-)similarity data sets show that the proposed method achieves much better\nruntime performance than the standard strategy while keeping competitive model\naccuracy. The main contribution is an efficient and accurate technique, to\nconvert (potentially non-metric) large scale dissimilarity matrices into\napproximated positive semi-definite kernel matrices at linear costs. \n\n"}
{"id": "1411.5453", "contents": "Title: Valuation of Variable Annuities with Guaranteed Minimum Withdrawal and\n  Death Benefits via Stochastic Control Optimization Abstract: In this paper we present a numerical valuation of variable annuities with\ncombined Guaranteed Minimum Withdrawal Benefit (GMWB) and Guaranteed Minimum\nDeath Benefit (GMDB) under optimal policyholder behaviour solved as an optimal\nstochastic control problem. This product simultaneously deals with financial\nrisk, mortality risk and human behaviour. We assume that market is complete in\nfinancial risk and mortality risk is completely diversified by selling enough\npolicies and thus the annuity price can be expressed as appropriate\nexpectation. The computing engine employed to solve the optimal stochastic\ncontrol problem is based on a robust and efficient Gauss-Hermite quadrature\nmethod with cubic spline. We present results for three different types of death\nbenefit and show that, under the optimal policyholder behaviour, adding the\npremium for the death benefit on top of the GMWB can be problematic for\ncontracts with long maturities if the continuous fee structure is kept, which\nis ordinarily assumed for a GMWB contract. In fact for some long maturities it\ncan be shown that the fee cannot be charged as any proportion of the account\nvalue -- there is no solution to match the initial premium with the fair\nannuity price. On the other hand, the extra fee due to adding the death benefit\ncan be charged upfront or in periodic instalment of fixed amount, and it is\ncheaper than buying a separate life insurance. \n\n"}
{"id": "1411.7783", "contents": "Title: From neural PCA to deep unsupervised learning Abstract: A network supporting deep unsupervised learning is presented. The network is\nan autoencoder with lateral shortcut connections from the encoder to decoder at\neach level of the hierarchy. The lateral shortcut connections allow the higher\nlevels of the hierarchy to focus on abstract invariant features. While standard\nautoencoders are analogous to latent variable models with a single layer of\nstochastic variables, the proposed network is analogous to hierarchical latent\nvariables models. Learning combines denoising autoencoder and denoising sources\nseparation frameworks. Each layer of the network contributes to the cost\nfunction a term which measures the distance of the representations produced by\nthe encoder and the decoder. Since training signals originate from all levels\nof the network, all layers can learn efficiently even in deep networks. The\nspeedup offered by cost terms from higher levels of the hierarchy and the\nability to learn invariant features are demonstrated in experiments. \n\n"}
{"id": "1412.0818", "contents": "Title: Progenitor model of Cosmic Ray knee Abstract: Primary energy spectrum of cosmic rays exhibits a knee at about $3$ PeV where\na change in the spectral index occurs. Despite many efforts the origin of such\na feature of the spectrum is not satisfactorily solved yet. Here it is proposed\nthat the steepening of the spectrum beyond the knee may be a consequence of\nmass distribution of progenitor of cosmic ray source. The proposed speculative\nmodel can account all the major observed features about cosmic rays without\ninvoking any fine tuning to match flux or spectra at any energy point. The\nprediction of the proposed model regarding primary composition scenario beyond\nthe knee is quite different from most of the prevailing models of the knee and\nthereby can be discriminated from precise experimental measurement of the\nprimary composition. \n\n"}
{"id": "1412.1900", "contents": "Title: McSAS: A package for extracting quantitative form-free distributions Abstract: A reliable and user-friendly characterisation of nano-objects in a target\nmaterial is presented here in the form of a software data analysis package for\ninterpreting small-angle X-ray scattering (SAXS) patterns. When provided with\ndata on absolute scale with reasonable uncertainty estimates, the software\noutputs (size) distributions in absolute volume fractions complete with\nuncertainty estimates and minimum evidence limits, and outputs all distribution\nmodes of a user definable range of one or more model parameters. A multitude of\nmodels are included, including prolate and oblate nanoparticles, core-shell\nobjects, polymer models (Gaussian chain and Kholodenko worm) and a model for\ndensely packed spheres (using the LMA-PY approximations). The McSAS software\ncan furthermore be integrated as part of an automated reduction and analysis\nprocedure in laboratory instruments or at synchrotron beamlines. \n\n"}
{"id": "1412.3140", "contents": "Title: Multilevel approximation of backward stochastic differential equations Abstract: We develop a multilevel approach to compute approximate solutions to backward\ndifferential equations (BSDEs). The fully implementable algorithm of our\nmultilevel scheme constructs sequential martingale control variates along a\nsequence of refining time-grids to reduce statistical approximation errors in\nan adaptive and generic way. We provide an error analysis with explicit and\nnon-asymptotic error estimates for the multilevel scheme under general\nconditions on the forward process and the BSDE data. It is shown that the\nmultilevel approach can reduce the computational complexity to achieve\nprecision $\\epsilon$, ensured by error estimates, essentially by one order (in\n$\\epsilon^{-1}$) in comparison to established methods, which is substantial.\nComputational examples support the validity of the theoretical analysis,\ndemonstrating efficiency improvements in practice. \n\n"}
{"id": "1412.3623", "contents": "Title: Monte Carlo Calculation of Exposure Profiles and Greeks for Bermudan and\n  Barrier Options under the Heston Hull-White Model Abstract: Valuation of Credit Valuation Adjustment (CVA) has become an important field\nas its calculation is required in Basel III, issued in 2010, in the wake of the\ncredit crisis. Exposure, which is defined as the potential future loss of a\ndefault event without any recovery, is one of the key elementsfor pricing CVA.\nThis paper provides a backward dynamics framework for assessing exposure\nprofiles of European, Bermudan and barrier options under the Heston and Heston\nHull-White asset dynamics. We discuss the potential of an efficient and\nadaptive Monte Carlo approach, the Stochastic Grid Bundling Method}(SGBM),\nwhich employs the techniques of simulation, regression and bundling. Greeks of\nthe exposure profiles can be calculated in the same backward iteration with\nlittle extra effort. Assuming independence between default event and exposure\nprofiles, we give examples of calculating exposure, CVA and Greeks for Bermudan\nand barrier options. \n\n"}
{"id": "1412.3948", "contents": "Title: Coupling news sentiment with web browsing data improves prediction of\n  intra-day price dynamics Abstract: The new digital revolution of big data is deeply changing our capability of\nunderstanding society and forecasting the outcome of many social and economic\nsystems. Unfortunately, information can be very heterogeneous in the\nimportance, relevance, and surprise it conveys, affecting severely the\npredictive power of semantic and statistical methods. Here we show that the\naggregation of web users' behavior can be elicited to overcome this problem in\na hard to predict complex system, namely the financial market. Specifically,\nour in-sample analysis shows that the combined use of sentiment analysis of\nnews and browsing activity of users of Yahoo! Finance greatly helps forecasting\nintra-day and daily price changes of a set of 100 highly capitalized US stocks\ntraded in the period 2012-2013. Sentiment analysis or browsing activity when\ntaken alone have very small or no predictive power. Conversely, when\nconsidering a \"news signal\" where in a given time interval we compute the\naverage sentiment of the clicked news, weighted by the number of clicks, we\nshow that for nearly 50% of the companies such signal Granger-causes hourly\nprice returns. Our result indicates a \"wisdom-of-the-crowd\" effect that allows\nto exploit users' activity to identify and weigh properly the relevant and\nsurprising news, enhancing considerably the forecasting power of the news\nsentiment. \n\n"}
{"id": "1412.4063", "contents": "Title: The detection rate of early UV emission from supernovae: A dedicated\n  GALEX/PTF survey and calibrated theoretical estimates Abstract: The radius and surface composition of an exploding massive star,as well as\nthe explosion energy per unit mass, can be measured using early UV observations\nof core collapse supernovae (SNe). We present the first results from a\nsimultaneous GALEX/PTF search for early UV emission from SNe. Six Type II SNe\nand one Type II superluminous SN (SLSN-II) are clearly detected in the GALEX\nNUV data. We compare our detection rate with theoretical estimates based on\nearly, shock-cooling UV light curves calculated from models that fit existing\nSwift and GALEX observations well, combined with volumetric SN rates. We find\nthat our observations are in good agreement with calculated rates assuming that\nred supergiants (RSGs) explode with fiducial radii of 500 solar, explosion\nenergies of 10^51 erg, and ejecta masses of 10 solar masses. Exploding blue\nsupergiants and Wolf-Rayet stars are poorly constrained. We describe how such\nobservations can be used to derive the progenitor radius, surface composition\nand explosion energy per unit mass of such SN events, and we demonstrate why UV\nobservations are critical for such measurements. We use the fiducial RSG\nparameters to estimate the detection rate of SNe during the shock-cooling phase\n(<1d after explosion) for several ground-based surveys (PTF, ZTF, and LSST). We\nshow that the proposed wide-field UV explorer ULTRASAT mission, is expected to\nfind >100 SNe per year (~0.5 SN per deg^2), independent of host galaxy\nextinction, down to an NUV detection limit of 21.5 mag AB. Our pilot GALEX/PTF\nproject thus convincingly demonstrates that a dedicated, systematic SN survey\nat the NUV band is a compelling method to study how massive stars end their\nlife. \n\n"}
{"id": "1412.5558", "contents": "Title: Backtest of Trading Systems on Candle Charts Abstract: In this paper we try to design the necessary calculation needed for\nbacktesting trading systems when only candle chart data are available. We lay\nparticular emphasis on situations which are not or not uniquely decidable and\ngive possible strategies to handle such situations. \n\n"}
{"id": "1412.7523", "contents": "Title: Classical Noether's theory with application to the linearly damped\n  particle Abstract: This paper provides a modern presentation of Noether's theory in the realm of\nclassical dynamics, with application to the problem of a particle submitted to\nboth a potential and a linear dissipation. After a review of the close\nrelationships between Noether symmetries and first integrals, we investigate\nthe variational point symmetries of the Lagrangian introduced by Bateman,\nCaldirola and Kanai. This analysis leads to the determination of all the\ntime-independent potentials allowing such symmetries, in the one-dimensional\nand the radial cases. Then we develop a symmetry-based transformation of\nLagrangians into autonomous others, and apply it to our problem. To be\ncomplete, we enlarge the study to Lie point symmetries which we associate\nlogically to Noether ones. Finally, we succinctly address the issue of a\n`weakened' Noether's theory, in connection with on-flows symmetries and\nnon-local constant of motions, for it has a direct physical interpretation in\nour specific problem. Since the Lagrangian we use gives rise to simple\ncalculations, we hope that this work will be of didactic interest to graduate\nstudents, and give teaching material as well as food for thought for physicists\nregarding Noether's theory and the recent developments around the idea of\nsymmetry in classical mechanics. \n\n"}
{"id": "1412.7766", "contents": "Title: Branch merging on continuum trees with applications to regenerative tree\n  growth Abstract: We introduce a family of branch merging operations on continuum trees and\nshow that Ford CRTs are distributionally invariant. This operation is new even\nin the special case of the Brownian CRT, which we explore in more detail. The\noperations are based on spinal decompositions and a regenerativity preserving\nmerging procedure of $(\\alpha, \\theta)$-strings of beads, that is, random\nintervals $[0, L_{\\alpha, \\theta}]$ equipped with a random discrete measure\n$dL^{-1}$ arising in the limit of ordered $(\\alpha, \\theta)$-Chinese restaurant\nprocesses as introduced recently by Pitman and Winkel. Indeed, we iterate the\nbranch merging operation recursively and give an alternative approach to the\nleaf embedding problem on Ford CRTs related to $(\\alpha,\n2-\\alpha)$-regenerative tree growth processes. \n\n"}
{"id": "1501.02453", "contents": "Title: Resistance of a Rotating-Moving Brane with Background Fields Against\n  Collapse Abstract: Using the boundary state formalism we investigate the effect of tachyon\ncondensation process on a rotating and moving D$p$-brane with various\nbackground fields in the bosonic string theory. The rotation and motion are\ninside the brane volume. We demonstrate that some specific rotations and/or\nmotions can preserve the brane from instability and collapse. \n\n"}
{"id": "1501.04080", "contents": "Title: Differentially Private Bayesian Optimization Abstract: Bayesian optimization is a powerful tool for fine-tuning the hyper-parameters\nof a wide variety of machine learning models. The success of machine learning\nhas led practitioners in diverse real-world settings to learn classifiers for\npractical problems. As machine learning becomes commonplace, Bayesian\noptimization becomes an attractive method for practitioners to automate the\nprocess of classifier hyper-parameter tuning. A key observation is that the\ndata used for tuning models in these settings is often sensitive. Certain data\nsuch as genetic predisposition, personal email statistics, and car accident\nhistory, if not properly private, may be at risk of being inferred from\nBayesian optimization outputs. To address this, we introduce methods for\nreleasing the best hyper-parameters and classifier accuracy privately.\nLeveraging the strong theoretical guarantees of differential privacy and known\nBayesian optimization convergence bounds, we prove that under a GP assumption\nthese private quantities are also near-optimal. Finally, even if this\nassumption is not satisfied, we can use different smoothness guarantees to\nprotect privacy. \n\n"}
{"id": "1501.05206", "contents": "Title: Theory of fads: Traveling-wave solution of evolutionary dynamics in a\n  one-dimensional trait space Abstract: We consider an infinite-sized population where an infinite number of traits\ncompete simultaneously. The replicator equation with a diffusive term describes\ntime evolution of the probability distribution over the traits due to selection\nand mutation on a mean-field level. We argue that this dynamics can be\nexpressed as a variant of the Fisher equation with high-order correction terms.\nThe equation has a traveling-wave solution, and the phase-space method shows\nhow the wave shape depends on the correction. We compare this solution with\nempirical time-series data of given names in Quebec, treating it as a\ndescriptive model for the observed patterns. Our model explains the reason that\nmany names exhibit a similar pattern of the rise and fall as time goes by. At\nthe same time, we have found that their dissimilarities are also statistically\nsignificant. \n\n"}
{"id": "1501.06084", "contents": "Title: Convergence of an Euler scheme for a hybrid stochastic-local volatility\n  model with stochastic rates in foreign exchange markets Abstract: We study the Heston-Cox-Ingersoll-Ross++ stochastic-local volatility model in\nthe context of foreign exchange markets and propose a Monte Carlo simulation\nscheme which combines the full truncation Euler scheme for the stochastic\nvolatility component and the stochastic domestic and foreign short interest\nrates with the log-Euler scheme for the exchange rate. We establish the\nexponential integrability of full truncation Euler approximations for the\nCox-Ingersoll-Ross process and find a lower bound on the explosion time of\nthese exponential moments. Under a full correlation structure and a realistic\nset of assumptions on the so-called leverage function, we prove the strong\nconvergence of the exchange rate approximations and deduce the convergence of\nMonte Carlo estimators for a number of vanilla and path-dependent options.\nThen, we perform a series of numerical experiments for an autocallable barrier\ndual currency note. \n\n"}
{"id": "1501.06561", "contents": "Title: Improved Practical Matrix Sketching with Guarantees Abstract: Matrices have become essential data representations for many large-scale\nproblems in data analytics, and hence matrix sketching is a critical task.\nAlthough much research has focused on improving the error/size tradeoff under\nvarious sketching paradigms, the many forms of error bounds make these\napproaches hard to compare in theory and in practice. This paper attempts to\ncategorize and compare most known methods under row-wise streaming updates with\nprovable guarantees, and then to tweak some of these methods to gain practical\nimprovements while retaining guarantees.\n  For instance, we observe that a simple heuristic iSVD, with no guarantees,\ntends to outperform all known approaches in terms of size/error trade-off. We\nmodify the best performing method with guarantees FrequentDirections under the\nsize/error trade-off to match the performance of iSVD and retain its\nguarantees. We also demonstrate some adversarial datasets where iSVD performs\nquite poorly. In comparing techniques in the time/error trade-off, techniques\nbased on hashing or sampling tend to perform better. In this setting we modify\nthe most studied sampling regime to retain error guarantee but obtain dramatic\nimprovements in the time/error trade-off.\n  Finally, we provide easy replication of our studies on APT, a new testbed\nwhich makes available not only code and datasets, but also a computing platform\nwith fixed environmental settings. \n\n"}
{"id": "1502.01550", "contents": "Title: Measurements of neutrino oscillation in appearance and disappearance\n  channels by the T2K experiment with 6.6E20 protons on target Abstract: We report on measurements of neutrino oscillation using data from the T2K\nlong-baseline neutrino experiment collected between 2010 and 2013. In an\nanalysis of muon neutrino disappearance alone, we find the following estimates\nand 68% confidence intervals for the two possible mass hierarchies:\n  Normal Hierarchy: $\\sin^2\\theta_{23}=0.514^{+0.055}_{-0.056}$ and $\\Delta\nm^2_{32}=(2.51\\pm0.10)\\times 10^{-3}$ eV$^2$/c$^4$\n  Inverted Hierarchy: $\\sin^2\\theta_{23}=0.511\\pm0.055$ and $\\Delta\nm^2_{13}=(2.48\\pm0.10)\\times 10^{-3}$ eV$^2$/c$^4$\n  The analysis accounts for multi-nucleon mechanisms in neutrino interactions\nwhich were found to introduce negligible bias.\n  We describe our first analyses that combine measurements of muon neutrino\ndisappearance and electron neutrino appearance to estimate four oscillation\nparameters and the mass hierarchy. Frequentist and Bayesian intervals are\npresented for combinations of these parameters, with and without including\nrecent reactor measurements. At 90% confidence level and including reactor\nmeasurements, we exclude the region:\n  $\\delta_{CP}=[0.15,0.83]\\pi$ for normal hierarchy and\n$\\delta_{CP}=[-0.08,1.09]\\pi$ for inverted hierarchy.\n  The T2K and reactor data weakly favor the normal hierarchy with a Bayes\nFactor of 2.2. The most probable values and 68% 1D credible intervals for the\nother oscillation parameters, when reactor data are included, are:\n  $\\sin^2\\theta_{23}=0.528^{+0.055}_{-0.038}$ and $|\\Delta\nm^2_{32}|=(2.51\\pm0.11)\\times 10^{-3}$ eV$^2$/c$^4$. \n\n"}
{"id": "1502.02026", "contents": "Title: Generalized ADE Classification of Gapped Domain Walls Abstract: In this paper we would like to demonstrate how the known rules of anyon\ncondensation motivated physically proposed by Bais \\textit{et al} can be\nrecovered by the mathematics of twist-free commutative separable Frobenius\nalgebra (CSFA). In some simple cases, those physical rules are also sufficient\nconditions defining a twist-free CSFA. This allows us to make use of the\ngeneralized $ADE$ classification of CSFA's and modular invariants to classify\nanyon condensation, and thus characterizing all gapped domain walls and gapped\nboundaries of a large class of topological orders. In fact, this classification\nis equivalent to the classification we proposed in Ref.1. \n\n"}
{"id": "1502.03018", "contents": "Title: Approximating explicitly the mean reverting CEV process Abstract: In this paper we want to exploit further the semi-discrete method appeared in\nHalidias and Stamatiou (2015). We are interested in the numerical solution of\nmean reverting CEV processes that appear in financial mathematics models and\nare described as non negative solutions of certain stochastic differential\nequations with sub-linear diffusion coefficients of the form $(x_t)^q,$ where\n$\\frac{1}{2}<q<1.$ Our goal is to construct explicit numerical schemes that\npreserve positivity. We prove convergence of the proposed SD scheme with rate\ndepending on the parameter $q.$ Furthermore, we verify our findings through\nnumerical experiments and compare with other positivity preserving schemes.\nFinally, we show how to treat the whole two-dimensional stochastic volatility\nmodel, with instantaneous variance process given by the above mean reverting\nCEV process. \n\n"}
{"id": "1502.03359", "contents": "Title: Asymptotic indifference pricing in exponential L\\'evy models Abstract: Financial markets based on L\\'evy processes are typically incomplete and\noption prices depend on risk attitudes of individual agents. In this context,\nthe notion of utility indifference price has gained popularity in the academic\ncircles. Although theoretically very appealing, this pricing method remains\ndifficult to apply in practice, due to the high computational cost of solving\nthe nonlinear partial integro-differential equation associated to the\nindifference price. In this work, we develop closed form approximations to\nexponential utility indifference prices in exponential L\\'evy models. To this\nend, we first establish a new non-asymptotic approximation of the indifference\nprice which extends earlier results on small risk aversion asymptotics of this\nquantity. Next, we use this formula to derive a closed-form approximation of\nthe indifference price by treating the L\\'evy model as a perturbation of the\nBlack-Scholes model. This extends the methodology introduced in a recent paper\nfor smooth linear functionals of L\\'evy processes (A. \\v{C}ern\\'y, S. Denkl and\nJ. Kallsen, arXiv:1309.7833) to nonlinear and non-smooth functionals. Our\nclosed formula represents the indifference price as the linear combination of\nthe Black-Scholes price and correction terms which depend on the variance,\nskewness and kurtosis of the underlying L\\'evy process, and the derivatives of\nthe Black-Scholes price. As a by-product, we obtain a simple explicit formula\nfor the spread between the buyer's and the seller's indifference price. This\nformula allows to quantify, in a model-independent fashion, how sensitive a\ngiven product is to jump risk in the limit of small jump size. \n\n"}
{"id": "1502.03656", "contents": "Title: Quasi-Newton particle Metropolis-Hastings Abstract: Particle Metropolis-Hastings enables Bayesian parameter inference in general\nnonlinear state space models (SSMs). However, in many implementations a random\nwalk proposal is used and this can result in poor mixing if not tuned correctly\nusing tedious pilot runs. Therefore, we consider a new proposal inspired by\nquasi-Newton algorithms that may achieve similar (or better) mixing with less\ntuning. An advantage compared to other Hessian based proposals, is that it only\nrequires estimates of the gradient of the log-posterior. A possible application\nis parameter inference in the challenging class of SSMs with intractable\nlikelihoods. We exemplify this application and the benefits of the new proposal\nby modelling log-returns of future contracts on coffee by a stochastic\nvolatility model with $\\alpha$-stable observations. \n\n"}
{"id": "1502.03978", "contents": "Title: Non Parametric Estimates of Option Prices Using Superhedging Abstract: We propose a new non parametric technique to estimate the CALL function based\non the superhedging principle. Our approach does not require absence of\narbitrage and easily accommodates bid/ask spreads and other market\nimperfections. We prove some optimal statistical properties of our estimates.\nAs an application we first test the methodology on a simulated sample of option\nprices and then on the S\\&P 500 index options. \n\n"}
{"id": "1503.00713", "contents": "Title: The ideal energy of classical lattice dynamics Abstract: We define, as local quantities, the least energy and momentum allowed by\nquantum mechanics and special relativity for physical realizations of some\nclassical lattice dynamics. These definitions depend on local rates of\nfinite-state change. In two example dynamics, we see that these rates evolve\nlike classical mechanical energy and momentum. \n\n"}
{"id": "1503.02012", "contents": "Title: QCD description of backward vector meson hard electroproduction Abstract: We consider backward vector meson exclusive electroproduction off nucleons in\nthe framework of collinear QCD factorization. Nucleon to vector meson\ntransition distribution amplitudes arise as building blocks for the\ncorresponding factorized amplitudes. In the near-backward kinematics, the\nsuggested factorization mechanism results in the dominance of the transverse\ncross section of vector meson production ($\\sigma_T \\gg \\sigma_L$) and in the\ncharacteristic $1/Q^8$-scaling behavior of the cross section. We evaluate\nnucleon to vector meson TDAs in the cross-channel nucleon exchange model and\npresent estimates of the differential cross section for backward $\\rho^0$,\n$\\omega$ and $\\phi$ meson production off protons. The resulting cross sections\nare shown to be measurable in the forthcoming JLab@12 GeV experiments. \n\n"}
{"id": "1503.02133", "contents": "Title: Equivariant class group. III. Almost principal fibrer bundles Abstract: As a formulation of 'codimension-two arguments' in invariant theory, we\ndefine a (rational) almost principal bundle. It is a principal bundle off\nclosed subsets of codimension two or more. We discuss the behavior of the\ncategory of reflexive modules over locally Krull schemes, the category of the\ncoherent sheaves which satisfy Serre's condition $(S'_2)$ over Noetherian\n$(S_2)$ schemes with dualizing complexes, the class group, the canonical\nmodule, the Frobenius pushforwards, and global $F$-regularity, of a rational\nalmost principal bundle. We give examples of finite group schemes, multisection\nrings, surjectively graded rings, and determinantal rings, and give unified\ntreatment and new proofs to known results in invariant theory, algebraic\ngeometry, and commutative algebra, and generalize some of them. In particular,\nwe generalize the result on the canonical module of the multisection ring of a\nsequence of divisors by Kurano and the author. We also give a new proof of a\ngeneralization of Thomsen's result on the Frobenius pushforwards of the\nstructure sheaf of a toric variety. \n\n"}
{"id": "1503.03705", "contents": "Title: A hybrid tree/finite-difference approach for Heston-Hull-White type\n  models Abstract: We study a hybrid tree-finite difference method which permits to obtain\nefficient and accurate European and American option prices in the Heston\nHull-White and Heston Hull-White2d models. Moreover, as a by-product, we\nprovide a new simulation scheme to be used for Monte Carlo evaluations.\nNumerical results show the reliability and the efficiency of the proposed\nmethods \n\n"}
{"id": "1503.03793", "contents": "Title: Small scale structure of spacetime: van Vleck determinant and\n  equi-geodesic surfaces Abstract: It has recently been argued that if spacetime $\\mathcal M$ possesses\nnon-trivial structure at small scales, an appropriate semi-classical\ndescription of it should be based on non-local bi-tensors instead of local\ntensors such as the metric $g_{ab}$. Two most relevant bi-tensors in this\ncontext are Synge's World function $\\Omega(p,p_0)$ and the van Vleck\ndeterminant (VVD) $\\Delta(p,p_0)$, as they encode the metric properties of\nspacetime and (de)focussing behaviour of geodesics. They also characterize the\nleading short distance behavior of two point functions of the d'Alembartian\n$_{p_0} \\square_p$. We begin by discussing the intrinsic and extrinsic geometry\nof equi-geodesic surfaces $\\Sigma_{G,p_0}$ defined by $\\Omega(p,p_0)=constant$\nin a geodesically convex neighbourhood of an event $p_0$, and highlight some\nelementary identities relating the VVD with geometry of these surfaces. As an\naside, we also comment on the contribution of $\\Sigma_{G,p_0}$ to the surface\nterm in the Einstein-Hilbert (EH) action and show that it can be written as a\nvolume integral of $\\square \\ln \\Delta$. We then study the small scale\nstructure of spacetime in presence of a Lorentz invariant short distance\ncut-off $\\ell_0$ using $\\Omega$ and $\\Delta$, based on some recently developed\nideas. We derive a 2nd rank bi-tensor $q_{ab}$ which naturally yields geodesic\nintervals bounded from below, and present a general and mathematically rigorous\nanalysis of short distance structure of spacetime based on (a) geometry of\n$\\Sigma_{G,p_0}$, (b) structure of the non local d'Alembartian associated with\n$q_{ab}$, and (c) properties of the VVD. In particular, we show that the Ricci\nbi-scalar of $q_{ab}$ is completely determined by $\\Sigma_{G,p_0}$, the tidal\ntensor, and first two derivatives of the van Vleck determinant, and has a\nnon-trivial \"classical\" limit given by (constant) $R_{ab} q^a q^b$ (see text). \n\n"}
{"id": "1503.05555", "contents": "Title: The Hunt for Exomoons with Kepler (HEK): V. A Survey of 41 Planetary\n  Candidates for Exomoons Abstract: We present a survey of 41 Kepler Objects of Interest (KOIs) for exomoons\nusing Bayesian photodynamics, more than tripling the number of KOIs surveyed\nwith this technique. We find no compelling evidence for exomoons although\nthirteen KOIs yield spurious detections driven by instrumental artifacts,\nstellar activity and/or perturbations from unseen bodies. Regarding the latter,\nwe find seven KOIs exhibiting >5 sigma evidence of transit timing variations,\nincluding the 'mega-Earth' Kepler-10c, likely indicating an additional planet\nin that system. We exploit the moderately large sample of 57 unique KOIs\nsurveyed to date to infer several useful statistics. For example, although\nthere is a diverse range in sensitivities, we find that we are sensitive to\nPluto-Charon mass-ratio systems for ~40% of KOIs studied and Earth-Moon\nmass-ratios for 1 in 8 cases. In terms of absolute mass, our limits probe down\nto 1.7 Ganymede masses, with a sensitivity to Earth-mass moons for 1 in 3 cases\nstudied and to the smallest moons capable of sustaining an Earth-like\natmosphere (0.3 Earth masses) for 1 in 4. Despite the lack of positive\ndetections to date, we caution against drawing conclusions yet, since our most\ninteresting objects remain under analysis. Finally, we point out that had we\nsearched for the photometric transit signals of exomoons alone, rather than\nusing photodynamics, we estimate that 1 in 4 KOIs would have erroneously been\nconcluded to harbor exomoons due to residual time correlated noise in the\nKepler data, posing a serious problem for alternative methods. \n\n"}
{"id": "1503.05706", "contents": "Title: On Nash images of Euclidean spaces Abstract: In this work we characterize the subsets of ${\\mathbb R}^n$ that are images\nof Nash maps $f:{\\mathbb R}^m\\to{\\mathbb R}^n$. We prove Shiota's conjecture\nand show that a subset ${\\mathcal S}\\subset{\\mathbb R}^n$ is the image of a\nNash map $f:{\\mathbb R}^m\\to{\\mathbb R}^n$ if and only if ${\\mathcal S}$ is\nsemialgebraic, pure dimensional of dimension $d\\leq m$ and there exists an\nanalytic path $\\alpha:[0,1]\\to{\\mathcal S}$ whose image meets all the connected\ncomponents of the set of regular points of ${\\mathcal S}$. Some remarkable\nconsequences are the following: (1) pure dimensional irreducible semialgebraic\nsets of dimension $d$ with arc-symmetric closure are Nash images of ${\\mathbb\nR}^d$; (2) semialgebraic sets are projections of irreducible algebraic sets\nwhose connected components are Nash diffeomorphic to Euclidean spaces; and (3)\ncompact $d$-dimensional smooth manifolds with boundary are smooth images of\n${\\mathbb R}^d$. \n\n"}
{"id": "1503.05909", "contents": "Title: Principal Components Analysis for Semimartingales and Stochastic PDE Abstract: In this work, we develop a novel principal component analysis (PCA) for\nsemimartingales by introducing a suitable spectral analysis for the quadratic\nvariation operator. Motivated by high-dimensional complex systems typically\nfound in interest rate markets, we investigate correlation in high-dimensional\nhigh-frequency data generated by continuous semimartingales. In contrast to the\ntraditional PCA methodology, the directions of large variations are not\ndeterministic, but rather they are bounded variation adapted processes which\nmaximize quadratic variation almost surely. This allows us to reduce\ndimensionality from high-dimensional semimartingale systems in terms of\nquadratic covariation rather than the usual covariance concept.\n  The proposed methodology allows us to investigate space-time data driven by\nmulti-dimensional latent semimartingale state processes. The theory is applied\nto discretely-observed stochastic PDEs which admit finite-dimensional\nrealizations. In particular, we provide consistent estimators for\nfinite-dimensional invariant manifolds for Heath-Jarrow-Morton models. More\nimportantly, components of the invariant manifold associated to volatility and\ndrift dynamics are consistently estimated and identified. The proposed\nmethodology is illustrated with both simulated and real data sets. \n\n"}
{"id": "1503.07109", "contents": "Title: Converting separable conditions to entanglement breaking conditions Abstract: We present a general method to derive entanglement breaking (EB) conditions\nfor continuous-variable quantum gates. We start with an arbitrary entanglement\nwitness, and reach an EB condition. The resultant EB condition is applicable\nnot only for quantum channels but also for general quantum operations, namely,\ntrace-non-increasing class of completely positive maps. We illustrate our\nmethod associated with a quantum benchmark based on the input ensemble of\nGaussian distributed coherent states. We also exploit our idea for channels\nacting on finite dimensional systems and present a Schmidt-number benchmark\nbased on input states of two mutually unbiased bases and measurements of\ngeneralized Pauli operators. \n\n"}
{"id": "1503.09008", "contents": "Title: IMEX schemes for a Parabolic-ODE system of European Options with\n  Liquidity Shocks Abstract: The coupled system, where one is a degenerate parabolic equation and the\nother has not a diffusion term arises in the modeling of European options with\nliquidity shocks. Two implicit-explicit (IMEX) schemes that preserve the\npositivity of the differential problem solution are constructed and analyzed.\nNumerical experiments confirm the theoretical results and illustrate the high\naccuracy and efficiency of the schemes in combination with Richardson\nextrapolation \n\n"}
{"id": "1504.03817", "contents": "Title: Gauge-Higgs Grand Unification Abstract: $SO(11)$ gauge-Higgs grand unification in the Randall-Sundrum warped space is\nproposed. Orbifold boundary conditions and one brane scalar field reduce\n$SO(11)$ to the standard model symmetry, which is further broken to $SU(3)_C\n\\times U(1)_{EM}$ by the Hosotani mechanism. In a minimal model quarks and\nleptons are contained in a multiplet in ${\\bf 32}$ of $SO(11)$ in each\ngeneration. Proton decay is naturally suppressed by a conserved fermion number. \n\n"}
{"id": "1504.04774", "contents": "Title: Time-consistency of risk measures with GARCH volatilities and their\n  estimation Abstract: In this paper we study time-consistent risk measures for returns that are\ngiven by a GARCH(1,1) model. We present a construction of risk measures based\non their static counterparts that overcomes the lack of time-consistency. We\nthen study in detail our construction for the risk measures Value-at-Risk (VaR)\nand Average Value-at-Risk (AVaR). While in the VaR case we can derive an\nanalytical formula for its time-consistent counterpart, in the AVaR case we\nderive lower and upper bounds to its time-consistent version. Furthermore, we\nincorporate techniques from Extreme Value Theory (EVT) to allow for a more\ntail-geared statistical analysis of the corresponding risk measures. We\nconclude with an application of our results to a data set of stock prices. \n\n"}
{"id": "1504.05723", "contents": "Title: Noise Robust Online Inference for Linear Dynamic Systems Abstract: We revisit the Bayesian online inference problems for the linear dynamic\nsystems (LDS) under non- Gaussian environment. The noises can naturally be\nnon-Gaussian (skewed and/or heavy tailed) or to accommodate spurious\nobservations, noises can be modeled as heavy tailed. However, at the cost of\nsuch noise robustness, the performance may degrade when such spurious\nobservations are absent. Therefore, any inference engine should not only be\nrobust to noise outlier, but also be adaptive to potentially unknown and time\nvarying noise parameters; yet it should be scalable and easy to implement.\n  To address them, we envisage here a new noise adaptive Rao-Blackwellized\nparticle filter (RBPF), by leveraging a hierarchically Gaussian model as a\nproxy for any non-Gaussian (process or measurement) noise density. This leads\nto a conditionally linear Gaussian model (CLGM), that is tractable. However,\nthis framework requires a valid transition kernel for the intractable state,\ntargeted by the particle filter (PF). This is typically unknown. We outline how\nsuch kernel can be constructed provably, at least for certain classes\nencompassing many commonly occurring non-Gaussian noises, using auxiliary\nlatent variable approach. The efficacy of this RBPF algorithm is demonstrated\nthrough numerical studies. \n\n"}
{"id": "1504.06094", "contents": "Title: Reflected BSDEs when the obstacle is not right-continuous and optimal\n  stopping Abstract: In the first part of the paper, we study reflected backward stochastic\ndifferential equations (RBSDEs) with lower obstacle which is assumed to be\nright upper-semicontinuous but not necessarily right-continuous. We prove\nexistence and uniqueness of the solutions to such RBSDEs in appropriate Banach\nspaces. The result is established by using some tools from the general theory\nof processes such as Mertens decomposition of optional strong (but not\nnecessarily right-continuous) supermartingales, some tools from optimal\nstopping theory, as well as an appropriate generalization of It{\\^o}'s formula\ndue to Gal'chouk and Lenglart. In the second part of the paper, we provide some\nlinks between the RBSDE studied in the first part and an optimal stopping\nproblem in which the risk of a financial position $\\xi$ is assessed by an\n$f$-conditional expectation $\\mathcal{E}^f(\\cdot)$ (where $f$ is a Lipschitz\ndriver). We characterize the \"value function\" of the problem in terms of the\nsolution to our RBSDE. Under an additional assumption of left\nupper-semicontinuity on $\\xi$, we show the existence of an optimal stopping\ntime. We also provide a generalization of Mertens decomposition to the case of\nstrong $\\mathcal{E}^f$-supermartingales. \n\n"}
{"id": "1504.07241", "contents": "Title: Simultaneous multifrequency radio observations of the Galactic Centre\n  magnetar SGR J1745-2900 Abstract: We report on simultaneous observations of the magnetar SGR J1745-2900 at\nfrequencies $\\nu = 2.54$ to $225\\,\\rm{GHz}$ using the Nancay 94-m equivalent,\nEffelsberg 100-m, and IRAM 30-m radio telescopes. We detect SGR J1745-2900 up\nto 225 GHz, the highest radio frequency detection of pulsed emission from a\nneutron star to date. Strong single pulses are also observed from 4.85 up to\n154 GHz. At the millimetre band we see significant flux density and spectral\nindex variabilities on time scales of tens of minutes, plus variability between\ndays at all frequencies. Additionally, SGR J1745-2900 was observed at a\ndifferent epoch at frequencies 296 to 472 GHz using the APEX 12-m radio\ntelescope, with no detections. Over the period MJD 56859.83-56862.93 the fitted\nspectrum yields a spectral index of $\\left<\\alpha\\right> = -0.4 \\pm 0.1$ for a\nreference flux density $\\left< S_{154} \\right> = 1.1 \\pm 0.2\\rm{\\,mJy}$ (with\n$S_{\\nu} \\propto {\\nu}^{\\alpha})$, a flat spectrum alike those of the other\nradio-loud magnetars. These results show that strongly magnetized neutron stars\ncan be effective radio emitters at frequencies notably higher to what was\npreviously known and that pulsar searches in the Galactic Centre are possible\nin the millimetre band. \n\n"}
{"id": "1504.08038", "contents": "Title: Two distinct topological phases in the mixed valence compound YbB6 and\n  its differences from SmB6 Abstract: We discuss the evolution of topological states and their orbital textures in\nthe mixed valence compounds SmB6 and YbB6 within the framework of the\ngeneralized gradient approximation plus onsite Coulomb interaction (GGA+U)\nscheme for a wide range of values of U. In SmB6, the topological Kondo\ninsulator (TKI) gap is found to be insensitive to the value of U, but in sharp\ncontrast, Kondo physics in isostructural YbB6 displays a surprising sensitivity\nto U. In particular, as U is increased in YbB6, the correlated TKI state in the\nweak-coupling regime transforms into a d-p-type topological insulator phase\nwith a band inversion between Yb-5d and B-2p orbitals in the intermediate\ncoupling range, without closing the insulating energy gap throughout this\nprocess. Our theoretical predictions related to the TKI and non-TKI phases in\nSmB6 and YbB6 are in substantial accord with recent angle-resolved\nphotoemission spectroscopy (ARPES) experiments. \n\n"}
{"id": "1505.00596", "contents": "Title: The aperiodic X-ray variability of the accreting millisecond pulsar SAX\n  J1808.4-3658 Abstract: We have studied the aperiodic variability of the 401 Hz accreting millisecond\nX-ray pulsar SAX J1808.4-3658 using the complete data set collected with the\nRossi X-ray Timing Explorer over 14 years of observation. The source shows a\nnumber of exceptional aperiodic timing phenomena that are observed against a\nbackdrop of timing properties that show consistent trends in all five observed\noutbursts and closely resemble those of other atoll sources. We performed a\ndetailed study of the enigmatic ~410 Hz QPO, which has only been observed in\nSAX J1808.4-3658. We find that it appears only when the upper kHz QPO frequency\nis less than the 401 Hz spin frequency. The difference between the ~410 Hz QPO\nfrequency and the spin frequency follows a similar frequency correlation as the\nlow frequency power spectral components, suggesting that the ~410 Hz QPO is a\nretrograde beat against the spin frequency of a rotational phenomenon in the 9\nHz range. Comparing this 9 Hz beat feature with the Low-Frequency QPO in SAX\nJ1808.4-3658 and other neutron star sources, we conclude that these two might\nbe part of the same basic phenomenon. We suggest that they might be caused by\nretrograde precession due to a combination of relativistic, classical and\nmagnetic torques. Additionally we present two new measurements of the lower kHz\nQPO, allowing us, for the first time, to measure the frequency evolution of the\ntwin kHz QPOs in this source. The twin kHz QPOs are seen to move together over\n150 Hz, maintaining a centroid frequency separation of $(0.446 \\pm 0.009)\n\\nu_{spin}$. \n\n"}
{"id": "1505.00965", "contents": "Title: An Introduction to Multilevel Monte Carlo for Option Valuation Abstract: Monte Carlo is a simple and flexible tool that is widely used in\ncomputational finance. In this context, it is common for the quantity of\ninterest to be the expected value of a random variable defined via a stochastic\ndifferential equation. In 2008, Giles proposed a remarkable improvement to the\napproach of discretizing with a numerical method and applying standard Monte\nCarlo. His multilevel Monte Carlo method offers an order of speed up given by\nthe inverse of epsilon, where epsilon is the required accuracy. So computations\ncan run 100 times more quickly when two digits of accuracy are required. The\nmultilevel philosophy has since been adopted by a range of researchers and a\nwealth of practically significant results has arisen, most of which have yet to\nmake their way into the expository literature.\n  In this work, we give a brief, accessible, introduction to multilevel Monte\nCarlo and summarize recent results applicable to the task of option evaluation. \n\n"}
{"id": "1505.02039", "contents": "Title: Structural default model with mutual obligations Abstract: This paper considers mutual obligations in the interconnected bank system and\nanalyzes their influence on joint and marginal survival probabilities as well\nas CDS and FTD prices for the individual banks. To make the role of mutual\nobligations more transparent, a simple structural default model with banks'\nassets driven by correlated multidimensional Brownian motion with drift is\nconsidered. This model enables a closed form representation for many quantities\nof interest, at least in a 2D case, to be obtained, and moreover, model\ncalibration is provided. Finally, we demonstrate that mutual obligations have\nto be taken into account in order to get correct values for model parameters. \n\n"}
{"id": "1505.03030", "contents": "Title: On the Exact Simulation of (Jump) Diffusion Bridges Abstract: In this paper we outline methodology to efficiently simulate (jump) diffusion\nbridge sample paths without discretisation error. We achieve this by\nconsidering the simulation of conditioned (jump) diffusion bridge sample paths\nin light of recent work developing a mathematical framework for simulating\nfinite dimensional sample path skeletons (which flexibly characterise the\nentirety of sample paths). \n\n"}
{"id": "1505.03423", "contents": "Title: Cross-Phase Modulation Enhancement Via a Resonating Cavity:\n  Semiclassical Description Abstract: We evaluate the advantages of performing cross-phase modulation (XPM) on a\nvery-far-off-resonance atomic system. We consider a ladder system with a weak\n(few-photon level) control coherent field imparting a conditional nonlinear\nphase shift on a probe beam. We find that by coupling to an optical resonator\nthe optimal XPM is enhanced proportional to the finesse of the resonator by a\nfactor of $F/4\\pi$. We present a semi-classical description of the system and\nshow that the phenomenon is optimal in the self-defined condition of\noff-resonance-effective-cooperativity equal to one. \n\n"}
{"id": "1505.04648", "contents": "Title: Chebyshev Interpolation for Parametric Option Pricing Abstract: Recurrent tasks such as pricing, calibration and risk assessment need to be\nexecuted accurately and in real-time. Simultaneously we observe an increase in\nmodel sophistication on the one hand and growing demands on the quality of risk\nmanagement on the other. To address the resulting computational challenges, it\nis natural to exploit the recurrent nature of these tasks. We concentrate on\nParametric Option Pricing (POP) and show that polynomial interpolation in the\nparameter space promises to reduce run-times while maintaining accuracy. The\nattractive properties of Chebyshev interpolation and its tensorized extension\nenable us to identify criteria for (sub)exponential convergence and explicit\nerror bounds. We show that these results apply to a variety of European\n(basket) options and affine asset models. Numerical experiments confirm our\nfindings. Exploring the potential of the method further, we empirically\ninvestigate the efficiency of the Chebyshev method for multivariate and\npath-dependent options. \n\n"}
{"id": "1505.04723", "contents": "Title: Interpretations of Elastic Electron Scattering Abstract: Elastic scattering of relativistic electrons from the nucleon yields Lorentz\ninvariant form factors that describe the fundamental distribution of charge and\nmagnetism. The spatial dependence of the nucleon's charge and magnetism is\ntypically interpreted in the Breit reference frame which is related by a\nLorentz boost from the laboratory frame, where the nucleon is at rest. We\nconstruct a toy model to estimate how the charge and magnetic radii of the\nnucleon are modified between the Breit and lab. frames. This has implications\nfor the ratio of the proton electric to magnetic elastic form factors as a\nfunction of momentum transfer as well as for determinations of the proton\ncharge radius. Predicted corrections based on the model are provided for the\nrms charge radii of the deuteron, the triton, and the helium isotopes. \n\n"}
{"id": "1505.06807", "contents": "Title: MLlib: Machine Learning in Apache Spark Abstract: Apache Spark is a popular open-source platform for large-scale data\nprocessing that is well-suited for iterative machine learning tasks. In this\npaper we present MLlib, Spark's open-source distributed machine learning\nlibrary. MLlib provides efficient functionality for a wide range of learning\nsettings and includes several underlying statistical, optimization, and linear\nalgebra primitives. Shipped with Spark, MLlib supports several languages and\nprovides a high-level API that leverages Spark's rich ecosystem to simplify the\ndevelopment of end-to-end machine learning pipelines. MLlib has experienced a\nrapid growth due to its vibrant open-source community of over 140 contributors,\nand includes extensive documentation to support further growth and to let users\nquickly get up to speed. \n\n"}
{"id": "1506.00697", "contents": "Title: Approximations of Bond and Swaption Prices in a Black-Karasi\\'{n}ski\n  Model Abstract: We derive semi-analytic approximation formulae for bond and swaption prices\nin a Black-Karasi\\'{n}ski interest rate model. Approximations are obtained\nusing a novel technique based on the Karhunen-Lo\\`{e}ve expansion. Formulas are\neasily computable and prove to be very accurate in numerical tests. This makes\nthem useful for numerically efficient calibration of the model. \n\n"}
{"id": "1506.00715", "contents": "Title: Cell structures for the Yokonuma-Hecke algebra and the algebra of braids\n  and ties Abstract: We construct a faithful tensor representation for the Yokonuma-Hecke algebra\nY, and use it to give a concrete isomorphism between Y and Shoji's modified\nAriki-Koike algebra. We give a cellular basis for Y and show that the\nJucys-Murphy elements for Y are JM-elements in the abstract sense. Finally, we\nconstruct a cellular basis for the Aicardi-Juyumaya algebra of braids and ties. \n\n"}
{"id": "1506.00972", "contents": "Title: Approaching Many-Body Localization from Disordered Luttinger Liquids via\n  the Functional Renormalization Group Abstract: We study the interplay of interactions and disorder in a one-dimensional\nfermion lattice coupled adiabatically to infinite reservoirs. We employ both\nthe functional renormalization group (FRG) as well as matrix product state\ntechniques, which serve as an accurate benchmark for small systems. Using the\nFRG, we compute the length- and temperature-dependence of the conductance\naveraged over $10^4$ samples for lattices as large as $10^{5}$ sites. We\nidentify regimes in which non-ohmic power law behavior can be observed and\ndemonstrate that the corresponding exponents can be understood by adapting\nearlier predictions obtained perturbatively for disordered Luttinger liquids.\nIn presence of both disorder and isolated impurities, the conductance has a\nuniversal single-parameter scaling form. This lays the groundwork for an\napplication of the functional renormalization group to the realm of many-body\nlocalization. \n\n"}
{"id": "1506.02283", "contents": "Title: Observation of Negative Magnetoresistance and nontrivial $\\pi$ Berrys\n  phase in 3D Weyl semi-metal NbAs Abstract: We report the electric transport properties of NbAs, which is a Weyl\nsemimetal candidate proposed by recent theoretical calculations and confirmed\nby recent angle-resolved photoemission spectroscopy (ARPES) data. We detected\nthe long-anticipated negative magneto-resistance generated by the chiral\nanomaly in NbAs. Clear Shubnikov de Haas (SdH) oscillations have been detected\nstarting from very weak magnetic field. Analysis of the SdH peaks gives the\nBerry phase accumulated along the cyclotron orbits to be $\\pi$, indicating the\nexistence of Weyl points. \n\n"}
{"id": "1506.02725", "contents": "Title: Comparing combinatorial models of moduli space and their\n  compactifications Abstract: We compare two combinatorial models for the moduli space of two-dimensional\ncobordisms: B\\\"odigheimer's radial slit configurations and Godin's admissible\nfat graphs, producing an explicit homotopy equivalence using a \"critical graph\"\nmap. We also discuss natural compactifications of these two models, the\nunilevel harmonic compactification and Sullivan diagrams respectively, and\nprove that the homotopy equivalence induces a cellular homeomorphism between\nthese compactifications. \n\n"}
{"id": "1506.04178", "contents": "Title: Robust preparation noncontextuality inequalities in the simplest\n  scenario Abstract: Contextuality is the leading notion of nonclassicality for a single system.\nHowever, an experimental demonstration requires finding procedures that are\noperationally equivalent, which might seem impossible to achieve exactly. Here\nI focus on the simplest non-trivial case, four preparations and two\ntomographically complete binary measurements. Exploiting a subtle connection to\nthe CHSH scenario gives eight non-linear inequalities which are together\nnecessary and sufficient for the experimental statistics to admit a preparation\nnoncontextual model in such a scenario. No fixed operational equivalences are\nrequired, removing a key difficulty with experimental tests of older\npreparation noncontextuality inequalities. \n\n"}
{"id": "1506.06180", "contents": "Title: Portfolio Optimization under Local-Stochastic Volatility: Coefficient\n  Taylor Series Approximations & Implied Sharpe Ratio Abstract: We study the finite horizon Merton portfolio optimization problem in a\ngeneral local-stochastic volatility setting. Using model coefficient expansion\ntechniques, we derive approximations for the both the value function and the\noptimal investment strategy. We also analyze the `implied Sharpe ratio' and\nderive a series approximation for this quantity. The zeroth-order approximation\nof the value function and optimal investment strategy correspond to those\nobtained by Merton (1969) when the risky asset follows a geometric Brownian\nmotion. The first-order correction of the value function can, for general\nutility functions, be expressed as a differential operator acting on the\nzeroth-order term. For power utility functions, higher order terms can also be\ncomputed as a differential operator acting on the zeroth-order term. We give a\nrigorous accuracy bound for the higher order approximations in this case in\npure stochastic volatility models. A number of examples are provided in order\nto demonstrate numerically the accuracy of our approximations. \n\n"}
{"id": "1506.08595", "contents": "Title: Central Clearing Valuation Adjustment Abstract: This paper develops an XVA (costs) analysis of centrally cleared trading,\nparallel to the one that has been developed in the last years for bilateral\ntransactions. We introduce a dynamic framework that incorporates the sequence\nof cash-flows involved in the waterfall of resources of a clearing house. The\ntotal cost of the clearance framework for a clearing member, called CCVA for\ncentral clearing valuation adjustment, is decomposed into a CVA corresponding\nto the cost of its losses on the default fund in case of defaults of other\nmember, an MVA corresponding to the cost of funding its margins and a KVA\ncorresponding to the cost of the regulatory capital and also of the capital at\nrisk that the member implicitly provides to the CCP through its default fund\ncontribution. In the end the structure of the XVA equations for bilateral and\ncleared portfolios is similar, but the input data to these equations are not\nthe same, reflecting different financial network structures. The resulting XVA\nnumbers differ, but, interestingly enough, they become comparable after scaling\nby a suitable netting ratio. \n\n"}
{"id": "1506.08858", "contents": "Title: Machine learning for many-body physics: efficient solution of dynamical\n  mean-field theory Abstract: Machine learning methods for solving the equations of dynamical mean-field\ntheory are developed. The method is demonstrated on the three dimensional\nHubbard model. The key technical issues are defining a mapping of an input\nfunction to an output function, and distinguishing metallic from insulating\nsolutions. Both metallic and Mott insulator solutions can be predicted. The\nvalidity of the machine learning scheme is assessed by comparing predictions of\nfull correlation functions, of quasi-particle weight and particle density to\nvalues directly computed. The results indicate that with modest further\ndevelopment, machine learning approach may be an attractive computational\nefficient option for real materials predictions for strongly correlated\nsystems. \n\n"}
{"id": "1507.00784", "contents": "Title: Twitter Sentiment Analysis Applied to Finance: A Case Study in the\n  Retail Industry Abstract: This paper presents a financial analysis over Twitter sentiment analytics\nextracted from listed retail brands. We investigate whether there is\nstatistically-significant information between the Twitter sentiment and volume,\nand stock returns and volatility. Traditional newswires are also considered as\na proxy for the market sentiment for comparative purpose. The results suggest\nthat social media is indeed a valuable source in the analysis of the financial\ndynamics in the retail sector even when compared to mainstream news such as the\nWall Street Journal and Dow Jones Newswires. \n\n"}
{"id": "1507.02896", "contents": "Title: Energy analysis in ice hockey arenas and analytical formula for the\n  temperature profile in the ice pad with transient boundary conditions Abstract: The energy efficiency of ice hockey arenas is a central concern for the\nadministrations, as these buildings are well known to consume a large amount of\nenergy. Since they are composite, complex systems, solutions to such a problem\ncan be approached from many different areas, from managerial to technological\nto more strictly physical.\n  In this paper we consider heat transfer processes in an ice hockey hall,\nduring operating conditions, with a bottom-up approach based upon on-site\nmeasurements. Detailed heat flux, relative humidity and temperature data for\nthe ice pad and the indoor air are used for a heat balance calculation in the\nsteady-state regime, which quantifies the impact of each single heat source. We\nthen solve the heat conduction equation for the ice pad in transient regime,\nand obtain a generic analytical formula for the temperature profile that can be\nused in practical applications.\n  We then apply this formula to the resurfacing process for validation, and\nfind good agreement with an analogous numerical solution. Since it is given\nwith implicit initial condition and boundary conditions, it can be used not\nonly in ice hockey halls, but in a large variety of engineering applications. \n\n"}
{"id": "1507.05473", "contents": "Title: Field of a moving locked charge as applied to beam-beam interactions in\n  storage rings Abstract: It is shown that the Lorentz transformation cannot in general be formally\napplied to potentials and fields of particles locked in a certain region. In\nparticular, this property relates to nucleons in nuclei and to particles and\nnuclei in storage rings. Even if they move with high velocities, their electric\nfields are defined by the Coulomb law. The result obtained is rather important\nfor the planned deuteron electric-dipole-moment experiment in storage rings. \n\n"}
{"id": "1507.05715", "contents": "Title: Ab initio downfolding study of the iron-based ladder superconductor\n  BaFe$_2$S$_3$ Abstract: Motivated by the recent discovery of superconductivity in the iron-based\nladder compound BaFe$_2$S$_3$ under high pressure, we derive low-energy\neffective Hamiltonians from first principles. We show that the complex band\nstructure around the Fermi level is represented only by the Fe 3$d_{xz}$ (mixed\nwith 3$d_{xy}$) and 3$d_{x^2-y^2}$ orbitals. The characteristic band degeneracy\nallows us to construct a four-band model with the band unfolding approach. We\nalso estimate the interaction parameters and show that the system is more\ncorrelated than the 1111 family of iron-based superconductors. Provided the\nsuperconductivity is mediated by spin fluctuations, the $3d_{xz}$-like band\nplays an essential role, and the gap function changes its sign between the\nFermi surface around the $\\Gamma$ point and that around the Brillouin-zone\nboundary. \n\n"}
{"id": "1507.06514", "contents": "Title: Optimum Liquidation Problem Associated with the Poisson Cluster Process Abstract: In this research, we develop a trading strategy for the discrete-time optimal\nliquidation problem of large order trading with different market\nmicrostructures in an illiquid market. In this framework, the flow of orders\ncan be viewed as a point process with stochastic intensity. We model the price\nimpact as a linear function of a self-exciting dynamic process. We formulate\nthe liquidation problem as a discrete-time Markov Decision Processes, where the\nstate process is a Piecewise Deterministic Markov Process (PDMP). The numerical\nresults indicate that an optimal trading strategy is dependent on\ncharacteristics of the market microstructure. When no orders above certain\nvalue come the optimal solution takes offers in the lower levels of the limit\norder book in order to prevent not filling of orders and facing final inventory\ncosts. \n\n"}
{"id": "1507.06869", "contents": "Title: Nilpotence and descent in equivariant stable homotopy theory Abstract: Let $G$ be a finite group and let $\\mathscr{F}$ be a family of subgroups of\n$G$. We introduce a class of $G$-equivariant spectra that we call\n$\\mathscr{F}$-nilpotent. This definition fits into the general theory of\ntorsion, complete, and nilpotent objects in a symmetric monoidal stable\n$\\infty$-category, with which we begin. We then develop some of the basic\nproperties of $\\mathscr{F}$-nilpotent $G$-spectra, which are explored further\nin the sequel to this paper.\n  In the rest of the paper, we prove several general structure theorems for\n$\\infty$-categories of module spectra over objects such as equivariant real and\ncomplex $K$-theory and Borel-equivariant $MU$. Using these structure theorems\nand a technique with the flag variety dating back to Quillen, we then show that\nlarge classes of equivariant cohomology theories for which a type of\ncomplex-orientability holds are nilpotent for the family of abelian subgroups.\nIn particular, we prove that equivariant real and complex $K$-theory, as well\nas the Borel-equivariant versions of complex-oriented theories, have this\nproperty. \n\n"}
{"id": "1507.07162", "contents": "Title: Forecasting Leading Death Causes in Australia using Extended\n  CreditRisk$+$ Abstract: Recently we developed a new framework in Hirz et al (2015) to model\nstochastic mortality using extended CreditRisk$^+$ methodology which is very\ndifferent from traditional time series methods used for mortality modelling\npreviously. In this framework, deaths are driven by common latent stochastic\nrisk factors which may be interpreted as death causes like neoplasms,\ncirculatory diseases or idiosyncratic components. These common factors\nintroduce dependence between policyholders in annuity portfolios or between\ndeath events in population. This framework can be used to construct life tables\nbased on mortality rate forecast. Moreover this framework allows stress testing\nand, therefore, offers insight into how certain health scenarios influence\nannuity payments of an insurer. Such scenarios may include improvement in\nhealth treatments or better medication. In this paper, using publicly available\ndata for Australia, we estimate the model using Markov chain Monte Carlo method\nto identify leading death causes across all age groups including long term\nforecast for 2031 and 2051. On top of general reduced mortality, the proportion\nof deaths for certain certain causes has changed massively over the period 1987\nto 2011. Our model forecasts suggest that if these trends persist, then the\nfuture gives a whole new picture of mortality for people aged above 40 years.\nNeoplasms will become the overall number-one death cause. Moreover, deaths due\nto mental and behavioural disorders are very likely to surge whilst deaths due\nto circulatory diseases will tend to decrease. This potential increase in\ndeaths due to mental and behavioural disorders for older ages will have a\nmassive impact on social systems as, typically, such patients need long-term\ngeriatric care. \n\n"}
{"id": "1507.07835", "contents": "Title: Measurement of longitudinal single-spin asymmetries for $W^{\\pm}$ boson\n  production in polarized $p+p$ collisions at $\\sqrt{s}=510$ GeV at STAR Abstract: $W^\\pm$ boson production in longitudinally polarized $p+p$ collisions\nprovides unique and clean access to the individual helicity polarizations of\n$u$ / $d$ quarks and anti-quarks. Due to the maximal violation of parity in the\ncoupling, $W$ bosons couple to left-handed quarks and right-handed anti-quarks\nand hence offer direct probes of their respective helicity distributions in the\nnucleon. These can be extracted from measured parity-violating longitudinal\nsingle-spin asymmetries, $A_L$, for $W^{+(-)}$ boson production as a function\nof the decay lepton (positron) pseudo-rapidity $\\eta$. The STAR experiment is\nwell equipped to measure $A_L$ for $W^\\pm$ boson production for $|\\eta|<1$. The\npublished STAR $A_L$ results (2011 and 2012 data combined) have been used by\nseveral theoretical analyses suggesting a significant impact in constraining\nthe helicity distributions of anti-$u$ and anti-$d$ quarks. In 2013 the STAR\nexperiment has collected a large data sample of $\\sim$250 pb$^{-1}$ which is\nmore than 3 times larger than the total integrated luminosity in 2012, at\n$\\sqrt{s}=510$ GeV with an average beam polarization of $\\sim$54\\%, comparable\nto run 2012. The status of the 2013 $A_L$ analysis will be discussed along with\nan overview of future plans. \n\n"}
{"id": "1507.08779", "contents": "Title: Impact of Multiple Curve Dynamics in Credit Valuation Adjustments under\n  Collateralization Abstract: We present a detailed analysis of interest rate derivatives valuation under\ncredit risk and collateral modeling. We show how the credit and collateral\nextended valuation framework in Pallavicini et al (2011), and the related\ncollateralized valuation measure, can be helpful in defining the key market\nrates underlying the multiple interest rate curves that characterize current\ninterest rate markets. A key point is that spot Libor rates are to be treated\nas market primitives rather than being defined by no-arbitrage relationships.\nWe formulate a consistent realistic dynamics for the different rates emerging\nfrom our analysis and compare the resulting model performances to simpler\nmodels used in the industry. We include the often neglected margin period of\nrisk, showing how this feature may increase the impact of different rates\ndynamics on valuation. We point out limitations of multiple curve models with\ndeterministic basis considering valuation of particularly sensitive products\nsuch as basis swaps. We stress that a proper wrong way risk analysis for such\nproducts requires a model with a stochastic basis and we show numerical results\nconfirming this fact. \n\n"}
{"id": "1508.00322", "contents": "Title: A State-Space Estimation of the Lee-Carter Mortality Model and\n  Implications for Annuity Pricing Abstract: In this article we investigate a state-space representation of the Lee-Carter\nmodel which is a benchmark stochastic mortality model for forecasting\nage-specific death rates. Existing relevant literature focuses mainly on\nmortality forecasting or pricing of longevity derivatives, while the full\nimplications and methods of using the state-space representation of the\nLee-Carter model in pricing retirement income products is yet to be examined.\nThe main contribution of this article is twofold. First, we provide a rigorous\nand detailed derivation of the posterior distributions of the parameters and\nthe latent process of the Lee-Carter model via Gibbs sampling. Our assumption\nfor priors is slightly more general than the current literature in this area.\nMoreover, we suggest a new form of identification constraint not yet utilised\nin the actuarial literature that proves to be a more convenient approach for\nestimating the model under the state-space framework. Second, by exploiting the\nposterior distribution of the latent process and parameters, we examine the\npricing range of annuities, taking into account the stochastic nature of the\ndynamics of the mortality rates. In this way we aim to capture the impact of\nlongevity risk on the pricing of annuities. The outcome of our study\ndemonstrates that an annuity price can be more than 4% under-valued when\ndifferent assumptions are made on determining the survival curve constructed\nfrom the distribution of the forecasted death rates. Given that a typical\nannuity portfolio consists of a large number of policies with maturities which\nspan decades, we conclude that the impact of longevity risk on the accurate\npricing of annuities is a significant issue to be further researched. In\naddition, we find that mis-pricing is increasingly more pronounced for older\nages as well as for annuity policies having a longer maturity. \n\n"}
{"id": "1508.04487", "contents": "Title: Dynamic Mode Decomposition for Financial Trading Strategies Abstract: We demonstrate the application of an algorithmic trading strategy based upon\nthe recently developed dynamic mode decomposition (DMD) on portfolios of\nfinancial data. The method is capable of characterizing complex dynamical\nsystems, in this case financial market dynamics, in an equation-free manner by\ndecomposing the state of the system into low-rank terms whose temporal\ncoefficients in time are known. By extracting key temporal coherent structures\n(portfolios) in its sampling window, it provides a regression to a best fit\nlinear dynamical system, allowing for a predictive assessment of the market\ndynamics and informing an investment strategy. The data-driven analytics\ncapitalizes on stock market patterns, either real or perceived, to inform\nbuy/sell/hold investment decisions. Critical to the method is an associated\nlearning algorithm that optimizes the sampling and prediction windows of the\nalgorithm by discovering trading hot-spots. The underlying mathematical\nstructure of the algorithms is rooted in methods from nonlinear dynamical\nsystems and shows that the decomposition is an effective mathematical tool for\ndata-driven discovery of market patterns. \n\n"}
{"id": "1508.04512", "contents": "Title: LIBOR troubles: anomalous movements detection based on Maximum Entropy Abstract: According to the definition of the London Interbank Offered Rate (LIBOR),\ncontributing banks should give fair estimates of their own borrowing costs in\nthe interbank market. Between 2007 and 2009, several banks made inappropriate\nsubmissions of LIBOR, sometimes motivated by profit-seeking from their trading\npositions. In 2012, several newspapers' articles began to cast doubt on LIBOR\nintegrity, leading surveillance authorities to conduct investigations on banks'\nbehavior. Such procedures resulted in severe fines imposed to involved banks,\nwho recognized their financial inappropriate conduct. In this paper, we uncover\nsuch unfair behavior by using a forecasting method based on the Maximum Entropy\nprinciple. Our results are robust against changes in parameter settings and\ncould be of great help for market surveillance. \n\n"}
{"id": "1508.04900", "contents": "Title: Detecting intraday financial market states using temporal clustering Abstract: We propose the application of a high-speed maximum likelihood clustering\nalgorithm to detect temporal financial market states, using correlation\nmatrices estimated from intraday market microstructure features. We first\ndetermine the ex-ante intraday temporal cluster configurations to identify\nmarket states, and then study the identified temporal state features to extract\nstate signature vectors which enable online state detection. The state\nsignature vectors serve as low-dimensional state descriptors which can be used\nin learning algorithms for optimal planning in the high-frequency trading\ndomain. We present a feasible scheme for real-time intraday state detection\nfrom streaming market data feeds. This study identifies an interesting\nhierarchy of system behaviour which motivates the need for time-scale-specific\nstate space reduction for participating agents. \n\n"}
{"id": "1508.05392", "contents": "Title: Baryogenesis via Mesino Oscillations Abstract: We propose a new mechanism for baryogenesis at the 1-200 MeV scale.\nEnhancement of CP violation takes place via interference between oscillations\nand decays of mesinos--bound states of a scalar quark and antiquark and their\nCP conjugates. We present the mechanism in a simplified model with four new\nfundamental particles, with masses between 300 GeV and 10 TeV, and show that\nsome of the experimentally allowed parameter space can give the observed\nbaryon-to-entropy ratio. \n\n"}
{"id": "1508.06182", "contents": "Title: Solving the Optimal Trading Trajectory Problem Using a Quantum Annealer Abstract: We solve a multi-period portfolio optimization problem using D-Wave Systems'\nquantum annealer. We derive a formulation of the problem, discuss several\npossible integer encoding schemes, and present numerical examples that show\nhigh success rates. The formulation incorporates transaction costs (including\npermanent and temporary market impact), and, significantly, the solution does\nnot require the inversion of a covariance matrix. The discrete multi-period\nportfolio optimization problem we solve is significantly harder than the\ncontinuous variable problem. We present insight into how results may be\nimproved using suitable software enhancements, and why current quantum\nannealing technology limits the size of problem that can be successfully solved\ntoday. The formulation presented is specifically designed to be scalable, with\nthe expectation that as quantum annealing technology improves, larger problems\nwill be solvable using the same techniques. \n\n"}
{"id": "1508.06449", "contents": "Title: Global existence of bounded weak solutions to degenerate cross-diffusion\n  equations in moving domain Abstract: The aim of this note is to present preliminary existence results for a system\nof cross-diffusion equations defined on a domain with moving boundaries, which\nmodel the evolution of the concentrations of different chemical species in a\nsolid during a Chemical Vapor Deposition process. The system of equations, when\nthe domain remains fixed over time, can be seen formally as a gradient flow\nsystem which can be analyzed using the boundedness by entropy method introduced\nby Burger and J\\\"ungel. Preliminary existence results are presented in the case\nof a one-dimensional moving boundary domain. \n\n"}
{"id": "1508.06492", "contents": "Title: Ninomiya-Victoir scheme: strong convergence, antithetic version and\n  application to multilevel estimators Abstract: In this paper, we are interested in the strong convergence properties of the\nNinomiya-Victoir scheme which is known to exhibit weak convergence with order\n2. We prove strong convergence with order $1/2$. This study is aimed at\nanalysing the use of this scheme either at each level or only at the finest\nlevel of a multilevel Monte Carlo estimator: indeed, the variance of a\nmultilevel Monte Carlo estimator is related to the strong error between the two\nschemes used on the coarse and fine grids at each level. Recently, Giles and\nSzpruch proposed a scheme permitting to construct a multilevel Monte Carlo\nestimator achieving the optimal complexity $O\\left(\\epsilon^{-2}\\right)$ for\nthe precision $\\epsilon$. In the same spirit, we propose a modified\nNinomiya-Victoir scheme, which may be strongly coupled with order $1$ to the\nGiles-Szpruch scheme at the finest level of a multilevel Monte Carlo estimator.\nNumerical experiments show that this choice improves the efficiency, since the\norder $2$ of weak convergence of the Ninomiya-Victoir scheme permits to reduce\nthe number of discretization levels. \n\n"}
{"id": "1508.06586", "contents": "Title: Financial Market Modeling with Quantum Neural Networks Abstract: Econophysics has developed as a research field that applies the formalism of\nStatistical Mechanics and Quantum Mechanics to address Economics and Finance\nproblems. The branch of Econophysics that applies of Quantum Theory to\nEconomics and Finance is called Quantum Econophysics. In Finance, Quantum\nEconophysics' contributions have ranged from option pricing to market dynamics\nmodeling, behavioral finance and applications of Game Theory, integrating the\nempirical finding, from human decision analysis, that shows that nonlinear\nupdate rules in probabilities, leading to non-additive decision weights, can be\ncomputationally approached from quantum computation, with resulting quantum\ninterference terms explaining the non-additive probabilities. The current work\ndraws on these results to introduce new tools from Quantum Artificial\nIntelligence, namely Quantum Artificial Neural Networks as a way to build and\nsimulate financial market models with adaptive selection of trading rules,\nleading to turbulence and excess kurtosis in the returns distributions for a\nwide range of parameters. \n\n"}
{"id": "1508.07159", "contents": "Title: Fibr\\'e de Tango pond\\'er\\'e g\\'en\\'eralis\\'e de rang $n-1$ sur l'espace\n  $\\mathbb{P}^{n}$ Abstract: We study in this paper a new family of stable algebraic vector bundles of\nrank $ n-1 $ on the complex projective space $\\mathbb{P}^{n}$ whose weighted\nTango bundles of Cascini \\cite{ca} belongs to. We show that these bundles are\ninvariant under a miniversal deformation. \n\n"}
{"id": "1509.00217", "contents": "Title: A permutation Information Theory tour through different interest rate\n  maturities: the Libor case Abstract: This paper analyzes Libor interest rates for seven different maturities and\nreferred to operations in British Pounds, Euro, Swiss Francs and Japanese Yen,\nduring the period years 2001 to 2015. The analysis is performed by means of two\nquantifiers derived from Information Theory: the permutation Shannon entropy\nand the permutation Fisher information measure. An anomalous behavior in the\nLibor is detected in all currencies except Euro during the years 2006--2012.\nThe stochastic switch is more severe in 1, 2 and 3 months maturities. Given the\nspecial mechanism of Libor setting, we conjecture that the behavior could have\nbeen produced by the manipulation that was uncovered by financial authorities.\nWe argue that our methodology is pertinent as a market overseeing instrument. \n\n"}
{"id": "1509.00629", "contents": "Title: Correlated Poisson processes and self-decomposable laws Abstract: We analyze a method to produce pairs of non independent Poisson processes\n$M(t),N(t)$ from positively correlated, self-decomposable, exponential\nrenewals. In particular the present paper provides the family of copulas\npairing the renewals, along with the closed form for the joint distribution\n$p_{m,n}(s,t)$ of the pair $\\big(M(s),N(t)\\big)$, an outcome which turns out to\nbe instrumental to produce explicit algorithms for applications in finance and\nqueuing theory. We finally discuss the cross-correlation properties of the two\nprocesses and the relative timing of their jumps \n\n"}
{"id": "1509.00980", "contents": "Title: Sequential Design for Ranking Response Surfaces Abstract: We propose and analyze sequential design methods for the problem of ranking\nseveral response surfaces. Namely, given $L \\ge 2$ response surfaces over a\ncontinuous input space $\\cal X$, the aim is to efficiently find the index of\nthe minimal response across the entire $\\cal X$. The response surfaces are not\nknown and have to be noisily sampled one-at-a-time. This setting is motivated\nby stochastic control applications and requires joint experimental design both\nin space and response-index dimensions. To generate sequential design\nheuristics we investigate stepwise uncertainty reduction approaches, as well as\nsampling based on posterior classification complexity. We also make connections\nbetween our continuous-input formulation and the discrete framework of pure\nregret in multi-armed bandits. To model the response surfaces we utilize\nkriging surrogates. Several numerical examples using both synthetic data and an\nepidemics control problem are provided to illustrate our approach and the\nefficacy of respective adaptive designs. \n\n"}
{"id": "1509.01144", "contents": "Title: Cointegrating Jumps: an Application to Energy Facilities Abstract: Based on the concept of self-decomposable random variables we discuss the\napplication of a model for a pair of dependent Poisson processes to energy\nfacilities. Due to the resulting structure of the jump events we can see the\nself-decomposability as a form of cointegration among jumps. In the context of\nenergy facilities, the application of our approach to model power or gas\ndynamics and to evaluate transportation assets seen as spread options is\nstraightforward. We study the applicability of our methodology first assuming a\nMerton market model with two underlying assets; in a second step we consider\nprice dynamics driven by an exponential mean-reverting Geometric\nOrnstein-Uhlenbeck plus compound Poisson that are commonly used in the energy\nfield. In this specific case we propose a price spot dynamics for each\nunderlying that has the advantage of being treatable to find non-arbitrage\nconditions. In particular we can find close-form formulas for vanilla options\nso that the price and the Greeks of spread options can be calculated in close\nform using the Margrabe formula (if the strike is zero) or some other well\nknown approximation. \n\n"}
{"id": "1509.01479", "contents": "Title: A mixed Monte Carlo and PDE variance reduction method for foreign\n  exchange options under the Heston-CIR model Abstract: In this paper, the valuation of European and path-dependent options in\nforeign exchange (FX) markets is considered when the currency exchange rate\nevolves according to the Heston model combined with the Cox-Ingersoll-Ross\ndynamics for the stochastic domestic and foreign short interest rates. The\nmixed Monte Carlo/PDE method requires that we simulate only the paths of the\nsquared volatility and the two interest rates, while an \"inner\"\nBlack-Scholes-type expectation is evaluated by means of a PDE. This can lead to\na substantial variance reduction and complexity improvements under certain\ncircumstances depending on the contract and the model parameters. In this work,\nwe establish the uniform boundedness of moments of the exchange rate process\nand its approximation, and prove strong convergence in $L^p$ ($p\\geq1$) of the\nlatter. Then, we carry out a variance reduction analysis and obtain accurate\napproximations for quantities of interest. All theoretical contributions can be\nextended to multi-factor short rates in a straightforward manner. Finally, we\nillustrate the efficiency of the method for the four-factor Heston-CIR model\nthrough a detailed quantitative assessment. \n\n"}
{"id": "1509.07902", "contents": "Title: Enabling Arbitrary Wavelength Optical Frequency Combs on Chip Abstract: A necessary condition for generation of bright soliton Kerr frequency combs\nin microresonators is to achieve anomalous group velocity dispersion (GVD) for\nthe resonator modes. This condition is hard to implement in visible as well as\nultraviolet since the majority of optical materials are characterized with\nlarge normal GVD in these wavelength regions. We overcome this challenge by\nborrowing ideas from strongly dispersive coupled systems in solid state physics\nand optics. We show that photonic compound ring resonators can possess large\nanomalous GVD at any desirable wavelength, even if each individual resonator is\ncharacterized with normal GVD. Based on this concept we design a mode locked\nfrequency comb with thin-film silicon nitride compound ring resonators in the\nvicinity of Rubidium D1 line (794.6nm) and propose to use this optical comb as\na flywheel for chip-scale optical clocks. \n\n"}
{"id": "1509.07976", "contents": "Title: The laws of thermodynamics and information for emergent cosmology Abstract: The aim here is to provide a set of equations for cosmology in terms of\ninformation and thermodynamical parameters. The method we implement in order to\ndescribe the universe is a development of Padmanabhan\\rq{}s approach which is\nbased on the fact that emergence of the cosmic space is provided by the\nevolution of the cosmic time. In this line we obtain the Friedmann equation or\nits equivalent the conservation law in terms of information by the\nimplementation of Laundauer\\rq{}s principle or in other words the information\nloss/production rate. Hence, a self consistent description of the universe is\nprovided in terms of thermodynamical parameters. This is due to the fact that\nin this work the role of information which is the most important actor of all\ntimes, has stepped in to cosmology. We provide a picture of the emergent\ncosmology merely based on the information theory. In addition, we introduce a\nnovel entropy on the horizon, which can also generalize Bekenstein-Hawking\nentropy for the asymptotic holographic principle. \n\n"}
{"id": "1509.08226", "contents": "Title: Singlet baryons in the graded symmetry approach to partially quenched\n  QCD Abstract: Progress in the calculation of the electromagnetic properties of baryon\nexcitations in lattice QCD is presenting new challenges in the determination of\nsea-quark loop contributions to matrix elements. A reliable estimation of the\nsea-quark loop contributions presents a pressing issue in the accurate\ncomparison of lattice QCD results with experiment. In this article, an\nextension of the graded symmetry approach to partially quenched QCD is\npresented, which builds on previous theory by explicitly including\nflavor-singlet baryons in its construction. The formalism takes into account\nthe interactions among both octet and singlet baryons, octet mesons, and their\nghost counterparts; the latter enables the isolation of the quark-flow\ndisconnected sea-quark loop contributions. The introduction of the\nflavor-singlet states anticipates the application of the method to baryon\nexcitations such as the lowest-lying odd-parity Lambda baryon, the\nLambda(1405), which is considered in detail as a worked example. \n\n"}
{"id": "1509.08248", "contents": "Title: Correctness of Backtest Engines Abstract: In recent years several trading platforms appeared which provide a backtest\nengine to calculate historic performance of self designed trading strategies on\nunderlying candle data. The construction of a correct working backtest engine\nis, however, a subtle task as shown by Maier-Paape and Platen (cf.\narXiv:1412.5558 [q-fin.TR]). Several platforms are struggling on the\ncorrectness.\n  In this work, we discuss the problem how the correctness of backtest engines\ncan be verified. We provide models for candles and for intra-period prices\nwhich will be applied to conduct a proof of correctness for a given backtest\nengine if the here provided tests on specific model candles are successful.\nFurthermore, we hint to algorithmic considerations in order to allow for a fast\nimplementation of these tests necessary for the proof of correctness. \n\n"}
{"id": "1509.08503", "contents": "Title: Volume Weighted Average Price Optimal Execution Abstract: We study the problem of optimal execution of a trading order under Volume\nWeighted Average Price (VWAP) benchmark, from the point of view of a\nrisk-averse broker. The problem consists in minimizing mean-variance of the\nslippage, with quadratic transaction costs. We devise multiple ways to solve\nit, in particular we study how to incorporate the information coming from the\nmarket during the schedule. Most related works in the literature eschew the\nissue of imperfect knowledge of the total market volume. We instead incorporate\nit in our model. We validate our method with extensive simulation of order\nexecution on real NYSE market data. Our proposed solution, using a simple model\nfor market volumes, reduces by 10% the VWAP deviation RMSE of the standard\n\"static\" solution (and can simultaneously reduce transaction costs). \n\n"}
{"id": "1510.03590", "contents": "Title: Coupling Importance Sampling and Multilevel Monte Carlo using Sample\n  Average Approximation Abstract: In this work, we propose a smart idea to couple importance sampling and\nMultilevel Monte Carlo (MLMC). We advocate a per level approach with as many\nimportance sampling parameters as the number of levels, which enables us to\ncompute the different levels independently. The search for parameters is\ncarried out using sample average approximation, which basically consists in\napplying deterministic optimisation techniques to a Monte Carlo approximation\nrather than resorting to stochastic approximation. Our innovative estimator\nleads to a robust and efficient procedure reducing both the discretization\nerror (the bias) and the variance for a given computational effort. In the\nsetting of discretized diffusions, we prove that our estimator satisfies a\nstrong law of large numbers and a central limit theorem with optimal limiting\nvariance, in the sense that this is the variance achieved by the best\nimportance sampling measure (among the class of changes we consider), which is\nhowever non tractable. Finally, we illustrate the efficiency of our method on\nseveral numerical challenges coming from quantitative finance and show that it\noutperforms the standard MLMC estimator. \n\n"}
{"id": "1510.05208", "contents": "Title: Hairy black holes in scalar extended massive gravity Abstract: We construct static, spherically symmetric black hole solutions in scalar\nextended ghost-free massive gravity and show the existence of hairy black holes\nin this class of extension. While the existence seems to be a generic feature,\nwe focus on the simplest models of this extension and find that asymptotically\nflat hairy black holes can exist without fine-tuning the theory parameters,\nunlike the bi-gravity extension, where asymptotical flatness requires\nfine-tuning in the parameter space. Like the bi-gravity extension, we are\nunable to obtain asymptotically dS regular black holes in the simplest models\nconsidered, but it is possible to obtain asymptotically AdS black holes. \n\n"}
{"id": "1510.05423", "contents": "Title: Kazhdan-Margulis theorem for Invariant Random Subgroups Abstract: Given a simple Lie group $G$, we show that the lattices in $G$ are weakly\nuniformly discrete. This is a strengthening of the Kazhdan-Margulis theorem.\nOur proof however is straightforward --- considering general IRS rather than\nlattices allows us to apply a compactness argument. In terms of p.m.p. actions,\nwe show that for every $\\epsilon$ there is an identity neighbourhood $U$ which\nintersects trivially the stabilizers of $1-\\epsilon$ of the points in every\nnon-atomic $G$-space. \n\n"}
{"id": "1510.05510", "contents": "Title: Mathematical Foundations of Realtime Equity Trading. Liquidity Deficit\n  and Market Dynamics. Automated Trading Machines Abstract: We postulates, and then show experimentally, that liquidity deficit is the\ndriving force of the markets. In the first part of the paper a kinematic of\nliquidity deficit is developed. The calculus-like approach, which is based on\nRadon--Nikodym derivatives and their generalization, allows us to calculate\nimportant characteristics of observable market dynamics. In the second part of\nthe paper this calculus is used in an attempt to build a dynamic equation in\nthe form: future price tend to the value maximizing the number of shares traded\nper unit time. To build a practical automated trading machine P&L dynamics\ninstead of price dynamics is considered. This allows a trading automate\nresilient to catastrophic P&L drains to be built. The results are very\npromising, yet when all the fees and trading commissions are taken into\naccount, are close to breakeven. In the end of the paper important criteria for\nautomated trading systems are presented. We list the system types that can and\ncannot make money on the market. These criteria can be successfully applied not\nonly by automated trading machines, but also by a human trader. \n\n"}
{"id": "1510.07029", "contents": "Title: Covariantised Vector Galileons Abstract: Vector Galileons are ghost-free systems containing higher derivative\ninteractions of vector fields. They break the vector gauge symmetry, and the\ndynamics of the longitudinal vector polarizations acquire a Galileon symmetry\nin an appropriate decoupling limit in Minkowski space. Using an ADM approach,\nwe carefully reconsider the coupling with gravity of vector Galileons, with the\naim of studying the necessary conditions to avoid the propagation of ghosts. We\ndevelop arguments that put on a more solid footing the results previously\nobtained in the literature. Moreover, working in analogy with the scalar\ncounterpart, we find indications for the existence of a `beyond Horndeski'\ntheory involving vector degrees of freedom, that avoids the propagation of\nghosts thanks to secondary constraints. In addition, we analyze a Higgs\nmechanism for generating vector Galileons through spontaneous symmetry\nbreaking, and we present its consistent covariantisation. \n\n"}
{"id": "1510.08945", "contents": "Title: Non-asymptotical sharp exponential estimates for maximum distribution of\n  discontinuous random fields Abstract: We offer in this paper the non-asymptotical bilateral sharp exponential\nestimates for tail of maximum distribution of {\\it discontinuous} random\nfields.\n  Our consideration based on the theory of Prokhorov-Skorokhod spaces of random\nfields and on the theory of multivariate Banach spaces of random variables with\nexponential decreasing tails of distributions. \n\n"}
{"id": "1511.00203", "contents": "Title: Mordell integrals and Giveon-Kutasov duality Abstract: We solve, for finite $N$, the matrix model of supersymmetric $U(N)$\nChern-Simons theory coupled to $N_{f}$ massive hypermultiplets of $R$-charge\n$\\frac{1}{2}$, together with a Fayet-Iliopoulos term. We compute the partition\nfunction by identifying it with a determinant of a Hankel matrix, whose entries\nare parametric derivatives (of order $N_{f}-1$) of Mordell integrals. We obtain\nfinite Gauss sums expressions for the partition functions. We also apply these\nresults to obtain an exhaustive test of Giveon-Kutasov (GK) duality in the\n$\\mathcal{N}=3$ setting, by systematic computation of the matrix models\ninvolved. The phase factor that arises in the duality is then obtained\nexplicitly. We give an expression characterized by modular arithmetic (mod 4)\nbehavior that holds for all tested values of the parameters (checked up to\n$N_{f}=12$ flavours). \n\n"}
{"id": "1511.00848", "contents": "Title: A backward Monte Carlo approach to exotic option pricing Abstract: We propose a novel algorithm which allows to sample paths from an underlying\nprice process in a local volatility model and to achieve a substantial variance\nreduction when pricing exotic options. The new algorithm relies on the\nconstruction of a discrete multinomial tree. The crucial feature of our\napproach is that -- in a similar spirit to the Brownian Bridge -- each random\npath runs backward from a terminal fixed point to the initial spot price. We\ncharacterize the tree in two alternative ways: in terms of the optimal grids\noriginating from the Recursive Marginal Quantization algorithm and following an\napproach inspired by the finite difference approximation of the diffusion's\ninfinitesimal generator. We assess the reliability of the new methodology\ncomparing the performance of both approaches and benchmarking them with\ncompetitor Monte Carlo methods. \n\n"}
{"id": "1511.00884", "contents": "Title: Magic points in finance: Empirical integration for parametric option\n  pricing Abstract: We propose an offline-online procedure for Fourier transform based option\npricing. The method supports the acceleration of such essential tasks of\nmathematical finance as model calibration, real-time pricing, and, more\ngenerally, risk assessment and parameter risk estimation. We adapt the\nempirical magic point interpolation method of Barrault, Nguyen, Maday and\nPatera (2004) to parametric Fourier pricing. In the offline phase, a quadrature\nrule is tailored to the family of integrands of the parametric pricing problem.\nIn the online phase, the quadrature rule then yields fast and accurate\napproximations of the option prices. Under analyticity assumptions the pricing\nerror decays exponentially. Numerical experiments in one dimension confirm our\ntheoretical findings and show a significant gain in efficiency, even for\nexamples beyond the scope of the theoretical results. \n\n"}
{"id": "1511.01460", "contents": "Title: LSV models with stochastic interest rates and correlated jumps Abstract: Pricing and hedging exotic options using local stochastic volatility models\ndrew a serious attention within the last decade, and nowadays became almost a\nstandard approach to this problem. In this paper we show how this framework\ncould be extended by adding to the model stochastic interest rates and\ncorrelated jumps in all three components. We also propose a new fully implicit\nmodification of the popular Hundsdorfer and Verwer and Modified Craig-Sneyd\nfinite-difference schemes which provides second order approximation in space\nand time, is unconditionally stable and preserves positivity of the solution,\nwhile still has a linear complexity in the number of grid nodes. \n\n"}
{"id": "1511.03618", "contents": "Title: Bayesian parameter estimation for effective field theories Abstract: We present procedures based on Bayesian statistics for estimating, from data,\nthe parameters of effective field theories (EFTs). The extraction of low-energy\nconstants (LECs) is guided by theoretical expectations in a quantifiable way\nthrough the specification of Bayesian priors. A prior for natural-sized LECs\nreduces the possibility of overfitting, and leads to a consistent accounting of\ndifferent sources of uncertainty. A set of diagnostic tools are developed that\nanalyze the fit and ensure that the priors do not bias the EFT parameter\nestimation. The procedures are illustrated using representative model problems,\nincluding the extraction of LECs for the nucleon mass expansion in SU(2) chiral\nperturbation theory from synthetic lattice data. \n\n"}
{"id": "1511.05865", "contents": "Title: Quantitative Transformation for Implementation of Adder Circuits in\n  Physical Systems Abstract: Computing devices are composed of spatial arrangements of simple funda-\nmental logic gates. These gates may be combined to form more complex adding\ncircuits and, ultimately, complete computer systems. Implementing classical\nadding circuits using unconventional, or even living substrates such as slime\nmould Physarum polycephalum, is made difficult and often impracti- cal by the\nchallenges of branching fan-out of inputs and regions where circuit lines must\ncross without interference. In this report we explore whether it is possible to\navoid spatial propagation, branching and crossing completely in the design of\nadding circuits. We analyse the input and output patterns of a single-bit full\nadder circuit. A simple quantitative transformation of the input patterns which\nconsiders the total number of bits in the input string allows us to map the\nrespective input combinations to the correct outputs patterns of the full adder\ncircuit, reducing the circuit combinations from a 2:1 mapping to a 1:1 mapping.\nThe mapping of inputs to outputs also shows an incremental linear progression,\nsuggesting its implementation in a range of physical systems. We demonstrate an\nexample implementation, first in simulation, inspired by self-oscillatory\ndynamics of the acellular slime mould Physarum polycephalum. We then assess the\npotential implementation using plasmodium of slime mould itself. This simple\ntransformation may enrich the potential for using unconventional computing\nsubstrates to implement digital circuits. \n\n"}
{"id": "1511.06196", "contents": "Title: Importance Sampling: Intrinsic Dimension and Computational Cost Abstract: The basic idea of importance sampling is to use independent samples from a\nproposal measure in order to approximate expectations with respect to a target\nmeasure. It is key to understand how many samples are required in order to\nguarantee accurate approximations. Intuitively, some notion of distance between\nthe target and the proposal should determine the computational cost of the\nmethod. A major challenge is to quantify this distance in terms of parameters\nor statistics that are pertinent for the practitioner. The subject has\nattracted substantial interest from within a variety of communities. The\nobjective of this paper is to overview and unify the resulting literature by\ncreating an overarching framework. A general theory is presented, with a focus\non the use of importance sampling in Bayesian inverse problems and filtering. \n\n"}
{"id": "1511.06321", "contents": "Title: Neural network-based clustering using pairwise constraints Abstract: This paper presents a neural network-based end-to-end clustering framework.\nWe design a novel strategy to utilize the contrastive criteria for pushing\ndata-forming clusters directly from raw data, in addition to learning a feature\nembedding suitable for such clustering. The network is trained with weak\nlabels, specifically partial pairwise relationships between data instances. The\ncluster assignments and their probabilities are then obtained at the output\nlayer by feed-forwarding the data. The framework has the interesting\ncharacteristic that no cluster centers need to be explicitly specified, thus\nthe resulting cluster distribution is purely data-driven and no distance\nmetrics need to be predefined. The experiments show that the proposed approach\nbeats the conventional two-stage method (feature embedding with k-means) by a\nsignificant margin. It also compares favorably to the performance of the\nstandard cross entropy loss for classification. Robustness analysis also shows\nthat the method is largely insensitive to the number of clusters. Specifically,\nwe show that the number of dominant clusters is close to the true number of\nclusters even when a large k is used for clustering. \n\n"}
{"id": "1511.07385", "contents": "Title: The initial physical conditions of Kepler-36 b & c Abstract: The Kepler planetary system consists of two exoplanets at similar separations\n(0.115 & 0.128 AU), which have dramatically different densities. The inner\nplanet has a density consistent with an Earth-like composition, while the outer\nplanet is extremely low-density, such that it must contain a voluminous H/He\nenvelope. Such a density difference would pose a problem for any formation\nmechanism if their current densities were representative of their composition\nat formation. However, both planets are at close enough separations to have\nundergone significant evaporation in the past. We constrain the core-mass, core\ncomposition, initial envelope-mass, and initial cooling-time of each planet\nusing evaporation models conditioned on their present-day masses and radii, as\ninferred from Kepler photometry and transit timing analysis. The inner planet\nis consistent with being an evaporatively stripped core, while the outer planet\nhas retained some of its initial envelope due to its higher core-mass.\nTherefore, both planets could have had a similar formation pathway, with the\ninner planet having an initial envelope-mass fraction of $\\lesssim 10\\%$ and\ncore-mass of $\\sim4.4$ M$_\\oplus$, while the outer had an initial envelope-mass\nfraction of order 15-30\\% and core-mass $\\sim7.3$ M$_\\oplus$. Finally, our\nresults indicate that the outer planet had a long ($\\gtrsim30$ Myr) initial\ncooling-time, much longer than would naively be predicted from simple timescale\narguments. The long initial cooling-time could be evidence for a dramatic early\ncooling episode such as the recently proposed \"boil-off\" process. \n\n"}
{"id": "1511.08997", "contents": "Title: Realized Volatility Analysis in A Spin Model of Financial Markets Abstract: We calculate the realized volatility in the spin model of financial markets\nand examine the returns standardized by the realized volatility. We find that\nmoments of the standardized returns agree with the theoretical values of\nstandard normal variables. This is the first evidence that the return dynamics\nof the spin financial market is consistent with the view of the\nmixture-of-distribution hypothesis that also holds in the real financial\nmarkets. \n\n"}
{"id": "1512.01609", "contents": "Title: Data Center Server Provision: Distributed Asynchronous Control for\n  Coupled Renewal Systems Abstract: This paper considers a cost minimization problem for data centers with N\nservers and randomly arriving service requests. A central router decides which\nserver to use for each new request. Each server has three types of states\n(active, idle, setup) with different costs and time durations. The servers\noperate asynchronously over their own states and can choose one of multiple\nsleep modes when idle. We develop an online distributed control algorithm so\nthat each server makes its own decisions, the request queues are bounded and\nthe overall time average cost is near optimal with probability 1. The algorithm\ndoes not need probability information for the arrival rate or job sizes. Next,\nan improved algorithm that uses a single queue is developed via a\n\"virtualization\" technique which is shown to provide the same (near optimal)\ncosts. Simulation experiments on a real data center traffic trace demonstrate\nthe efficiency of our algorithm compared to other existing algorithms. \n\n"}
{"id": "1512.04419", "contents": "Title: Sentence Entailment in Compositional Distributional Semantics Abstract: Distributional semantic models provide vector representations for words by\ngathering co-occurrence frequencies from corpora of text. Compositional\ndistributional models extend these from words to phrases and sentences. In\ncategorical compositional distributional semantics, phrase and sentence\nrepresentations are functions of their grammatical structure and\nrepresentations of the words therein. In this setting, grammatical structures\nare formalised by morphisms of a compact closed category and meanings of words\nare formalised by objects of the same category. These can be instantiated in\nthe form of vectors or density matrices. This paper concerns the applications\nof this model to phrase and sentence level entailment. We argue that\nentropy-based distances of vectors and density matrices provide a good\ncandidate to measure word-level entailment, show the advantage of density\nmatrices over vectors for word level entailments, and prove that these\ndistances extend compositionally from words to phrases and sentences. We\nexemplify our theoretical constructions on real data and a toy entailment\ndataset and provide preliminary experimental evidence. \n\n"}
{"id": "1512.04916", "contents": "Title: Deep Learning Stock Volatility with Google Domestic Trends Abstract: We have applied a Long Short-Term Memory neural network to model S&P 500\nvolatility, incorporating Google domestic trends as indicators of the public\nmood and macroeconomic factors. In a held-out test set, our Long Short-Term\nMemory model gives a mean absolute percentage error of 24.2%, outperforming\nlinear Ridge/Lasso and autoregressive GARCH benchmarks by at least 31%. This\nevaluation is based on an optimal observation and normalization scheme which\nmaximizes the mutual information between domestic trends and daily volatility\nin the training set. Our preliminary investigation shows strong promise for\nbetter predicting stock behavior via deep learning and neural network models. \n\n"}
{"id": "1512.05149", "contents": "Title: Spin orbit coupling at the level of a single electron Abstract: We utilize electron counting techniques to distinguish a spin conserving fast\ntunneling process and a slower process involving spin flips in\nAlGaAs/GaAs-based double quantum dots. By studying the dependence of the rates\non the interdot tunnel coupling of the two dots, we find that as many as 4% of\nthe tunneling events occur with a spin flip related to spin-orbit coupling in\nGaAs. Our measurement has a fidelity of 99 % in terms of resolving whether a\ntunneling event occurred with a spin flip or not. \n\n"}
{"id": "1512.05924", "contents": "Title: Quadratic-exponential growth BSDEs with Jumps and their Malliavin's\n  Differentiability Abstract: We investigate a class of quadratic-exponential growth BSDEs with jumps. The\nquadratic structure introduced by Barrieu & El Karoui (2013) yields the\nuniversal bounds on the possible solutions. With local Lipschitz continuity and\nthe so-called A_gamma-condition for the comparison principle to hold, we prove\nthe existence of a unique solution under the general quadratic-exponential\nstructure. We have also shown that the strong convergence occurs under more\ngeneral (not necessarily monotone) sequence of drivers, which is then applied\nto give the sufficient conditions for the Malliavin's differentiability. \n\n"}
{"id": "1601.00822", "contents": "Title: Volume of the steady-state space of financial flows in a monetary\n  stock-flow-consistent model Abstract: We show that a steady-state stock-flow consistent macro-economic model can be\nrepresented as a Constraint Satisfaction Problem (CSP).The set of solutions is\na polytope, which volume depends on the constraintsapplied and reveals the\npotential fragility of the economic circuit,with no need to study the dynamics.\nSeveral methods to compute the volume are compared, inspired by operations\nresearch methods and theanalysis of metabolic networks, both exact and\napproximate.We also introduce a random transaction matrix, and study the\nparticularcase of linear flows with respect to money stocks. \n\n"}
{"id": "1601.00919", "contents": "Title: Exponential integrability properties of Euler discretization schemes for\n  the Cox-Ingersoll-Ross process Abstract: We analyze exponential integrability properties of the Cox-Ingersoll-Ross\n(CIR) process and its Euler discretizations with various types of truncation\nand reflection at 0. These properties play a key role in establishing the\nfiniteness of moments and the strong convergence of numerical approximations\nfor a class of stochastic differential equations arising in finance. We prove\nthat both implicit and explicit Euler-Maruyama discretizations for the CIR\nprocess preserve the exponential integrability of the exact solution for a wide\nrange of parameters, and find lower bounds on the explosion time. \n\n"}
{"id": "1601.01128", "contents": "Title: Option pricing in the model with stochastic volatility driven by\n  Ornstein--Uhlenbeck process. Simulation Abstract: We consider a discrete-time approximation of paths of an Ornstein--Uhlenbeck\nprocess as a mean for estimation of a price of European call option in the\nmodel of financial market with stochastic volatility. The Euler--Maruyama\napproximation scheme is implemented. We determine the estimates for the option\nprice for predetermined sets of parameters. The rate of convergence of the\nprice and an average volatility when discretization intervals tighten are\ndetermined. Discretization precision is analyzed for the case where the exact\nvalue of the price can be derived. \n\n"}
{"id": "1601.01142", "contents": "Title: Streaming Gibbs Sampling for LDA Model Abstract: Streaming variational Bayes (SVB) is successful in learning LDA models in an\nonline manner. However previous attempts toward developing online Monte-Carlo\nmethods for LDA have little success, often by having much worse perplexity than\ntheir batch counterparts. We present a streaming Gibbs sampling (SGS) method,\nan online extension of the collapsed Gibbs sampling (CGS). Our empirical study\nshows that SGS can reach similar perplexity as CGS, much better than SVB. Our\ndistributed version of SGS, DSGS, is much more scalable than SVB mainly because\nthe updates' communication complexity is small. \n\n"}
{"id": "1601.02698", "contents": "Title: Efficient Markov Chain Monte Carlo Sampling for Hierarchical Hidden\n  Markov Models Abstract: Traditional Markov chain Monte Carlo (MCMC) sampling of hidden Markov models\n(HMMs) involves latent states underlying an imperfect observation process, and\ngenerates posterior samples for top-level parameters concurrently with nuisance\nlatent variables. When potentially many HMMs are embedded within a hierarchical\nmodel, this can result in prohibitively long MCMC runtimes. We study\ncombinations of existing methods, which are shown to vastly improve\ncomputational efficiency for these hierarchical models while maintaining the\nmodeling flexibility provided by embedded HMMs. The methods include discrete\nfiltering of the HMM likelihood to remove latent states, reduced data\nrepresentations, and a novel procedure for dynamic block sampling of posterior\ndimensions. The first two methods have been used in isolation in existing\napplication-specific software, but are not generally available for\nincorporation in arbitrary model structures. Using the NIMBLE package for R, we\ndevelop and test combined computational approaches using three examples from\necological capture-recapture, although our methods are generally applicable to\nany embedded discrete HMMs. These combinations provide several orders of\nmagnitude improvement in MCMC sampling efficiency, defined as the rate of\ngenerating effectively independent posterior samples. In addition to being\ncomputationally significant for this class of hierarchical models, this result\nunderscores the potential for vast improvements to MCMC sampling efficiency\nwhich can result from combinations of known algorithms. \n\n"}
{"id": "1601.04535", "contents": "Title: A nonlinear impact: evidences of causal effects of social media on\n  market prices Abstract: Online social networks offer a new way to investigate financial markets'\ndynamics by enabling the large-scale analysis of investors' collective\nbehavior. We provide empirical evidence that suggests social media and stock\nmarkets have a nonlinear causal relationship. We take advantage of an extensive\ndata set composed of social media messages related to DJIA index components. By\nusing information-theoretic measures to cope for possible nonlinear causal\ncoupling between social media and stock markets systems, we point out stunning\ndifferences in the results with respect to linear coupling. Two main\nconclusions are drawn: First, social media significant causality on stocks'\nreturns are purely nonlinear in most cases; Second, social media dominates the\ndirectional coupling with stock market, an effect not observable within linear\nmodeling. Results also serve as empirical guidance on model adequacy in the\ninvestigation of sociotechnical and financial systems. \n\n"}
{"id": "1601.04652", "contents": "Title: Large deviations for the branching Brownian motion in presence of\n  selection or coalescence Abstract: The large deviation function has been known for a long time in the literature\nfor the displacement of the rightmost particle in a branching random walk\n(BRW), or in a branching Brownian motion (BBM). More recently a number of\ngeneralizations of the BBM and of the BRW have been considered where selection\nor coalescence mechanisms tend to limit the exponential growth of the number of\nparticles. Here we try to estimate the large deviation function of the position\nof the rightmost particle for several such generalizations: the $L$-BBM, the\n$N$-BBM, and the CBRW (coalescing branching random walk) which is closely\nrelated to the noisy FKPP equation. Our approach allows us to obtain only upper\nbounds on these large deviation functions. One noticeable feature of our\nresults is their non analytic dependence on the parameters (such as the\ncoalescence rate in the CBRW). \n\n"}
{"id": "1601.05363", "contents": "Title: An explanation of metastability in the viscous Burgers equation with\n  periodic boundary conditions via a spectral analysis Abstract: A \"metastable solution\" to a differential equation typically refers to a\nfamily of solutions for which nearby initial data converges to the family much\nfaster than evolution along the family. Metastable families have been observed\nboth experimentally and numerically in various contexts, they are believed to\nbe particularly relevant for organizing the dynamics of fluid flows. In this\nwork we propose a candidate metastable family for the Burgers equation with\nperiodic boundary conditions. Our choice of family is motivated by our\nnumerical experiments. We furthermore explain the metastable behavior of the\nfamily without reference to the Cole--Hopf transformation, but rather by\nlinearizing the Burgers equation about the family and analyzing the spectrum of\nthe resulting operator. We hope this may make the analysis more readily\ntransferable to more realistic systems like the Navier--Stokes equations. Our\nanalysis is motivated by ideas from singular perturbation theory and Melnikov\ntheory. \n\n"}
{"id": "1601.07864", "contents": "Title: On construction of boundary preserving numerical schemes Abstract: Our aim in this note is to extend the semi discrete technique by combine it\nwith the split step method. We apply our new method to the Ait-Sahalia model\nand propose an explicit and positivity preserving numerical scheme. \n\n"}
{"id": "1602.00386", "contents": "Title: Scene Invariant Crowd Segmentation and Counting Using Scale-Normalized\n  Histogram of Moving Gradients (HoMG) Abstract: The problem of automated crowd segmentation and counting has garnered\nsignificant interest in the field of video surveillance. This paper proposes a\nnovel scene invariant crowd segmentation and counting algorithm designed with\nhigh accuracy yet low computational complexity in mind, which is key for\nwidespread industrial adoption. A novel low-complexity, scale-normalized\nfeature called Histogram of Moving Gradients (HoMG) is introduced for highly\neffective spatiotemporal representation of individuals and crowds within a\nvideo. Real-time crowd segmentation is achieved via boosted cascade of weak\nclassifiers based on sliding-window HoMG features, while linear SVM regression\nof crowd-region HoMG features is employed for real-time crowd counting.\nExperimental results using multi-camera crowd datasets show that the proposed\nalgorithm significantly outperform state-of-the-art crowd counting algorithms,\nas well as achieve very promising crowd segmentation results, thus\ndemonstrating the efficacy of the proposed method for highly-accurate,\nreal-time video-driven crowd analysis. \n\n"}
{"id": "1602.02478", "contents": "Title: Quantum Phase Transitions of the Bose-Hubbard Model inside a Cavity Abstract: The superfluid to Mott insulator transition and the superradiant transition\nare textbook examples for quantum phase transition and coherent quantum optics,\nrespectively. Recent experiments in ETH and Hamburg succeeded in loading\ndegenerate bosonic atomic gases in optical lattices inside a cavity, which\nenables the first experimental study of the interplay between these two\ntransitions. In this letter we present the theoretical phase diagram for the\nETH experimental setup, and determine the phase boundaries and the orders of\nthe phase transitions between the normal superfluid phase, the superfluid with\nsuperradiant light, the normal Mott insulator and the Mott insulator with\nsuperradiant light. We find that in contrast to the second-order superradiant\ntransition in a weakly interacting Bose condensate, strong correlations in the\nsuperfluid nearby a Mott transition can render the superradiant transition to a\nfirst order one. Our results will stimulate further experimental studies of\ninteractions between cavity light and strongly interacting quantum matters. \n\n"}
{"id": "1602.04395", "contents": "Title: Black Hole: The Interior Spacetime Abstract: The information loss paradox is often discussed from the perspective of the\nobservers who stay outside of a black hole. However, the interior spacetime of\na black hole can be rather nontrivial. We discuss the open problems regarding\nthe volume of a black hole, and whether it plays any role in information\nstorage. We also emphasize the importance of resolving the black hole\nsingularity, if one were to resolve the information loss paradox. \n\n"}
{"id": "1602.04423", "contents": "Title: Market Dynamics. On Supply and Demand Concepts Abstract: The disbalance of Supply and Demand is typically considered as the driving\nforce of the markets. However, the measurement or estimation of Supply and\nDemand at price different from the execution price is not possible even after\nthe transaction. An approach in which Supply and Demand are always matched, but\nthe rate $I=dv/dt$ (number of units traded per unit time) of their matching\nvaries, is proposed. The state of the system is determined not by a price $p$,\nbut by a probability distribution defined as the square of a wavefunction\n$\\psi(p)$. The equilibrium state $\\psi^{[H]}$ is postulated to be the one\ngiving maximal $I$ and obtained from maximizing the matching rate functional\n$<I\\psi^2(p)>/<\\psi^2(p)>$, i.e. solving the dynamic equation of the form\n\"future price tend to the value maximizing the number of shares traded per unit\ntime\". An application of the theory in a quasi--stationary case is\ndemonstrated. This transition from Supply and Demand concept to Liquidity\nDeficit concept, described by the matching rate $I$, allows to operate only\nwith observable variables, and have a theory applicable to practical problems. \n\n"}
{"id": "1602.05915", "contents": "Title: The VIPERS Multi-Lambda Survey. I. UV and NIR Observations, multi-color\n  catalogues and photometric redshifts Abstract: We present observations collected in the CFHTLS-VIPERS region in the\nultraviolet (UV) with the GALEX satellite (far and near UV channels) and the\nnear infrared with the CFHT/WIRCam camera ($K_s$-band) over an area of 22 and\n27 deg$^2$, respectively. The depth of the photometry was optimized to measure\nthe physical properties (e.g., SFR, stellar masses) of all the galaxies in the\nVIPERS spectroscopic survey. The large volume explored by VIPERS will enable a\nunique investigation of the relationship between the galaxy properties and\ntheir environment (density field and cosmic web) at high redshift (0.5 < z <\n1.2). In this paper, we present the observations, the data reductions and the\nbuild-up of the multi-color catalogues. The CFHTLS-T0007 (gri-{\\chi}^2) images\nare used as reference to detect and measure the $K_s$-band photometry, while\nthe T0007 u-selected sources are used as priors to perform the GALEX photometry\nbased on a dedicated software (EMphot). Our final sample reaches $NUV_{AB}$~25\n(at 5{\\sigma}) and $K_{AB}$~22 (at 3{\\sigma}). The large spectroscopic sample\n(~51,000 spectroscopic redshifts) allows us to highlight the robustness of our\nstar/galaxy separation, and the reliability of our photometric redshifts with a\ntypical accuracy $\\sigma_z \\le$ 0.04 and a catastrophic failure rate {\\eta} <\n2% down to i~23. We present various tests on the $K_s$ band completeness and\nphotometric redshift accuracy by comparing with existing, overlapping deep\nphotometric catalogues. Finally, we discuss the BzK sample of passive and\nactive galaxies at high redshift and the evolution of galaxy morphology in the\n(NUV-r) vs (r-K_s) diagram at low redshift (z < 0.25) thanks to the high image\nquality of the CFHTLS. The images, catalogues and photometric redshifts for 1.5\nmillion sources (down to $NUV \\le$ 25 or $K_s \\le$ 22) are released and\navailable at this URL: http://cesam.lam.fr/vipers-mls/ \n\n"}
{"id": "1602.06628", "contents": "Title: Composite (pseudo) scalar contributions to muon g-2 Abstract: We have calculated the composite (pseudo) scalar contributions to the\nanomalous magnetic moment of muons in models of walking technicolor. By the\naxial or scale anomaly the light scalars such as techni-dilaton, techni-pions\nor techni-eta have anomalous couplings to two-photons, which make them natural\ncandidates for the recent 750 GeV resonance excess, observed at LHC. Due to the\nanomalous couplings, their contributions to muon (g-2) are less suppressed and\nmight explain the current deviation in muon (g-2) measurements from theory. \n\n"}
{"id": "1602.09078", "contents": "Title: Pricing and Hedging GMWB in the Heston and in the Black-Scholes with\n  Stochastic Interest Rate Models Abstract: Valuing Guaranteed Minimum Withdrawal Benefit (GMWB) has attracted\nsignificant attention from both the academic field and real world financial\nmarkets. As remarked by Yang and Dai, the Black and Scholes framework seems to\nbe inappropriate for such a long maturity products. Also Chen Vetzal and\nForsyth in showed that the price of these products is very sensitive to\ninterest rate and volatility parameters. We propose here to use a stochastic\nvolatility model (Heston model) and a Black Scholes model with stochastic\ninterest rate (Hull White model). For this purpose we present four numerical\nmethods for pricing GMWB variables annuities: a hybrid tree-finite difference\nmethod and a Hybrid Monte Carlo method, an ADI finite difference scheme, and a\nStandard Monte Carlo method. These methods are used to determine the\nno-arbitrage fee for the most popular versions of the GMWB contract, and to\ncalculate the Greeks used in hedging. Both constant withdrawal, optimal\nsurrender and optimal withdrawal strategies are considered. Numerical results\nare presented which demonstrate the sensitivity of the no-arbitrage fee to\neconomic, contractual and longevity assumptions. \n\n"}
{"id": "1603.03012", "contents": "Title: Capital Valuation Adjustment and Funding Valuation Adjustment Abstract: In the aftermath of the 2007 global financial crisis, banks started\nreflecting into derivative pricing the cost of capital and collateral funding\nthrough XVA metrics. Here XVA is a catch-all acronym whereby X is replaced by a\nletter such as C for credit, D for debt, F for funding, K for capital and so\non, and VA stands for valuation adjustment. This behaviour is at odds with\neconomies where markets for contingent claims are complete, whereby trades\nclear at fair valuations and the costs for capital and collateral are both\nirrelevant to investment decisions. In this paper, we set forth a mathematical\nformalism for derivative portfolio management in incomplete markets for banks.\nA particular emphasis is given to the problem of finding optimal strategies for\nretained earnings which ensure a sustainable dividend policy. \n\n"}
{"id": "1603.05313", "contents": "Title: Market Dynamics vs. Statistics: Limit Order Book Example Abstract: Commonly used limit order book attributes are empirically considered based on\nNASDAQ ITCH data. It is shown that some of them have the properties drastically\ndifferent from the ones assumed in many market dynamics study. Because of this\ndifference we propose to make a transition from \"Statistical\" type of order\nbook study (typical for academics) to \"Dynamical\" type of study (typical for\nmarket practitioners). Based on market data analysis we conclude, that most of\nmarket dynamics information is contained in attributes with spikes (e.g.\nexecuted trades flow $I=dv/dt$), there is no any \"stationary case\" on the\nmarket and typical market dynamics is a \"fast excitation and then slow\nrelaxation\" type of behavior with a wide distribution of excitation frequencies\nand relaxation times. A computer code, providing full depth order book\ninformation and recently executed trades is available from authors [1]. \n\n"}
{"id": "1603.05532", "contents": "Title: The Wilson Flow and the finite temperature phase transition Abstract: We consider the determination of the finite temperature phase transition in\nthe Yang--Mills SU(3) gauge theory. We compute the difference of the spatial\nand temporal energy density at a physical Wilson flow time. This difference is\nzero in the confined phase and becomes non zero in the deconfined phase. We\nlocate the phase transition by using a new technique based on an exponential\nsmoothing spline. This method is an alternative to the determination of the\nphase transition based on the Polyakov loop susceptibility and can also be used\nwith dynamical fermions. \n\n"}
{"id": "1603.06805", "contents": "Title: Using real-time cluster configurations of streaming asynchronous\n  features as online state descriptors in financial markets Abstract: We present a scheme for online, unsupervised state discovery and detection\nfrom streaming, multi-featured, asynchronous data in high-frequency financial\nmarkets. Online feature correlations are computed using an unbiased, lossless\nFourier estimator. A high-speed maximum likelihood clustering algorithm is then\nused to find the feature cluster configuration which best explains the\nstructure in the correlation matrix. We conjecture that this feature\nconfiguration is a candidate descriptor for the temporal state of the system.\nUsing a simple cluster configuration similarity metric, we are able to\nenumerate the state space based on prevailing feature configurations. The\nproposed state representation removes the need for human-driven data\npre-processing for state attribute specification, allowing a learning agent to\nfind structure in streaming data, discern changes in the system, enumerate its\nperceived state space and learn suitable action-selection policies. \n\n"}
{"id": "1603.07225", "contents": "Title: Numerical stability of a hybrid method for pricing options Abstract: We develop and study stability properties of a hybrid approximation of\nfunctionals of the Bates jump model with stochastic interest rate that uses a\ntree method in the direction of the volatility and the interest rate and a\nfinite-difference approach in order to handle the underlying asset price\nprocess. We also propose hybrid simulations for the model, following a binomial\ntree in the direction of both the volatility and the interest rate, and a\nspace-continuous approximation for the underlying asset price process coming\nfrom a Euler-Maruyama type scheme. We show that our methods allow to obtain\nefficient and accurate European and American option prices. Numerical\nexperiments are provided, and show the reliability and the efficiency of the\nalgorithms. \n\n"}
{"id": "1604.01306", "contents": "Title: Search for new phenomena in events with a photon and missing transverse\n  momentum in $pp$ collisions at $\\sqrt{s}=13$ TeV with the ATLAS detector Abstract: Results of a search for new phenomena in events with an energetic photon and\nlarge missing transverse momentum with the ATLAS experiment at the Large Hadron\nCollider are reported. The data were collected in proton--proton collisions at\na centre-of-mass energy of 13 TeV and correspond to an integrated luminosity of\n3.2 $\\rm fb^{-1}$. The observed data are in agreement with the Standard Model\nexpectations. Exclusion limits are presented in models of new phenomena\nincluding pair production of dark matter candidates or large extra spatial\ndimensions. In a simplified model of dark matter and an axial-vector mediator,\nthe search excludes mediator masses of up to 710 GeV for dark matter candidate\nmasses up to 150 GeV. In an effective theory of dark matter production, values\nof the suppression scale $M_*$ up to 570 GeV are excluded and the effect of\ntruncation for various coupling values is reported. For the ADD large extra\nspatial dimension model the search places more stringent limits than earlier\nsearches in the same event topology, excluding $M_{\\rm D}$ up to about 2.3\n(2.8) TeV for two (six) additional spatial dimensions; the limits are reduced\nby 20--40% depending on the number of additional spatial dimensions when\napplying a truncation procedure. \n\n"}
{"id": "1604.01368", "contents": "Title: Early Universe Dynamos from Neutrino Oscillations Induced by Torsion Abstract: Earlier de Sabbata and Gasperini have shown that neutrinos oscillation which\ngives them a mass can be induced by torsion. More recently Enqvist et al have\nshown that it is possible to use massive neutrinos BBN magnetic fields to seed\ngalactic magnetic fields. Thus based on these previous investigations we\npresent several examples of how obtaining cosmological magnetic seed fields as\ngalactic magnetic fields from massive neutrino densities and also from the\ntorsion obtained by Nitsch as $T\\approx{10^{-24}s^{-1}}$ at the present day\nwhich yields magnetic seed field of the order of $B_{seed}\\approx{10^{-12}G}$.\nIn the case we use torsion derived from massive neutrinos given by\n$T_{\\nu}\\approx{10^{-26}s^{-1}}$ one obtains in BBN time $t\\approx{1s}$ with\nthe primordial nucleosynthesis magnetic field given by\n$B_{BBN}\\approx{10^{11}G}$ a relic magnetic field $B_{c}\\approx{10^{39}G}$\nwhich shows that the result obtained by Enqvist et al for the cosmological\nfields at the early universe. Galactic dynamo seed could be obtained from\nneutrinos at recombination. It is also shown that in the approximation of weak\nfields torsion can slow down the decay of magnetic fields which confirms\nprevious results. At Planck era where the time is $t\\sim{10^{-43}s}$ and\n$B_{Pl}\\sim{10^{58}G}$ the use of formula with the strongest torsion\n$10^{-19}G$this yields $B_{seed}\\sim{10^{-4}G}$ is a too strong field to\nwarrant a galactic dynamo seed. \n\n"}
{"id": "1604.01923", "contents": "Title: Galaxy And Mass Assembly (GAMA): Accurate Panchromatic Photometry from\n  Optical Priors using LAMBDAR Abstract: We present the Lambda Adaptive Multi-Band Deblending Algorithm in R\n(LAMBDAR), a novel code for calculating matched aperture photometry across\nimages that are neither pixel- nor PSF-matched, using prior aperture\ndefinitions derived from high resolution optical imaging. The development of\nthis program is motivated by the desire for consistent photometry and\nuncertainties across large ranges of photometric imaging, for use in\ncalculating spectral energy distributions. We describe the program,\nspecifically key features required for robust determination of panchromatic\nphotometry: propagation of apertures to images with arbitrary resolution, local\nbackground estimation, aperture normalisation, uncertainty determination and\npropagation, and object deblending. Using simulated images, we demonstrate that\nthe program is able to recover accurate photometric measurements in both\nhigh-resolution, low-confusion, and low-resolution, high-confusion, regimes. We\napply the program to the 21-band photometric dataset from the Galaxy And Mass\nAssembly (GAMA) Panchromatic Data Release (PDR; Driver et al. 2016), which\ncontains imaging spanning the far-UV to the far-IR. We compare photometry\nderived from LAMBDAR with that presented in Driver et al. (2016), finding broad\nagreement between the datasets. Nonetheless, we demonstrate that the photometry\nfrom LAMBDAR is superior to that from the GAMA PDR, as determined by a\nreduction in the outlier rate and intrinsic scatter of colours in the LAMBDAR\ndataset. We similarly find a decrease in the outlier rate of stellar masses and\nstar formation rates using LAMBDAR photometry. Finally, we note an exceptional\nincrease in the number of UV and mid-IR sources able to be constrained, which\nis accompanied by a significant increase in the mid-IR colour-colour\nparameter-space able to be explored. \n\n"}
{"id": "1604.05178", "contents": "Title: High order finite difference schemes on non-uniform meshes for the\n  time-fractional Black-Scholes equation Abstract: We construct a three-point compact finite difference scheme on a non-uniform\nmesh for the time-fractional Black-Scholes equation. We show that for special\ngraded meshes used in finance, the Tavella-Randall and the quadratic meshes the\nnumerical solution has a fourth-order accuracy in space. Numerical experiments\nare discussed. \n\n"}
{"id": "1604.05896", "contents": "Title: Random selection of factors preserves the correlation structure in a\n  linear factor model to a high degree Abstract: In a very high-dimensional vector space, two randomly-chosen vectors are\nalmost orthogonal with high probability. Starting from this observation, we\ndevelop a statistical factor model, the random factor model, in which factors\nare chosen at random based on the random projection method. Randomness of\nfactors has the consequence that covariance matrix is well preserved in a\nlinear factor representation. It also enables derivation of probabilistic\nbounds for the accuracy of the random factor representation of time-series,\ntheir cross-correlations and covariances. As an application, we analyze\nreproduction of time-series and their cross-correlation coefficients in the\nwell-diversified Russell 3,000 equity index. \n\n"}
{"id": "1604.06247", "contents": "Title: Finite determinacy of matrices over local rings.II. Tangent modules to\n  the miniversal deformations for group-actions involving the ring\n  automorphisms Abstract: We consider matrices with entries in a local ring, Mat(m,n;R). Fix an action\nof group G on Mat(m,n;R), and a subset of allowed deformations, \\Sigma in\nMat(m,n;R). The standard question (along the lines of Singularity Theory) is\nthe finite-(\\Sigma,G)-determinacy of matrices.\n  In our previous work this determinacy question was reduced to the study of\nthe tangent spaces to \\Sigma and to the orbit, T_{(\\Sigma,A)}, T_{(GA,A)}, and\ntheir quotient: the tangent module to the miniversal deformation. In\nparticular, the order of determinacy is controlled by the annihilator of this\ntangent module.\n  Then we have studied this tangent module for the group action GL(m,R)\\times\nGL(n,R) on Mat(m,n;R) and for various natural subgroups of it. These are\nR-linear group actions.\n  In the current work we study this tangent module for group actions that\ninvolve the automorphisms of the ring, or, geometrically, group-actions that\ninvolve the local coordinate changes. (These actions are not R-linear.) We\nobtain various bounds on the support of this module. This gives ready-to-use\ncriteria of determinacy for matrices, (embedded) modules and (skew-)symmetric\nforms. \n\n"}
{"id": "1604.06342", "contents": "Title: Optimal trading with online parameters revisions Abstract: The aim of this paper is to explain how parameters adjustments can be\nintegrated in the design or the control of automates of trading. Typically, we\nare interested by the online estimation of the market impacts generated by\nrobots or single orders, and how they/the controller should react in an optimal\nway to the informations generated by the observation of the realized impacts.\nThis can be formulated as an optimal impulse control problem with unknown\nparameters, on which a prior is given. We explain how a mix of the classical\nBayesian updating rule and of optimal control techniques allows one to derive\nthe dynamic programming equation satisfied by the corresponding value function,\nfrom which the optimal policy can be inferred. We provide an example of\nconvergent finite difference scheme and consider typical examples of\napplications. \n\n"}
{"id": "1604.06609", "contents": "Title: Linear quadratic optimal control of conditional McKean-Vlasov equation\n  with random coefficients and applications * Abstract: We consider the optimal control problem for a linear conditional\nMcKean-Vlasov equation with quadratic cost functional. The coefficients of the\nsystem and the weigh-ting matrices in the cost functional are allowed to be\nadapted processes with respect to the common noise filtration. Semi closed-loop\nstrategies are introduced, and following the dynamic programming approach in\n[32], we solve the problem and characterize time-consistent optimal control by\nmeans of a system of decoupled backward stochastic Riccati differential\nequations. We present several financial applications with explicit solutions,\nand revisit in particular optimal tracking problems with price impact, and the\nconditional mean-variance portfolio selection in incomplete market model. \n\n"}
{"id": "1605.00307", "contents": "Title: Semi-analytic path integral solution of SABR and Heston equations:\n  pricing Vanilla and Asian options Abstract: We discuss a semi-analytical method for solving SABR-type equations based on\npath integrals. In this approach, one set of variables is integrated\nanalytically while the second set is integrated numerically via Monte-Carlo.\nThis method, known in the literature as Conditional Monte-Carlo, leads to\ncompact expressions functional on three correlated stochastic variables. The\nmethodology is practical and efficient when solving Vanilla pricing in the\nSABR, Heston and Bates models with time depending parameters. Further, it can\nalso be practically applied to pricing Asian options in the $\\beta=0$ SABR\nmodel and to other $\\beta=0$ type models. \n\n"}
{"id": "1605.01998", "contents": "Title: Unbiased Monte Carlo Simulation of Diffusion Processes Abstract: Monte Carlo simulations of diffusion processes often introduce bias in the\nfinal result, due to time discretization. Using an auxiliary Poisson process,\nit is possible to run simulations which are unbiased. In this article, we\npropose such a Monte Carlo scheme which converges to the exact value. We manage\nto keep the simulation variance finite in all cases, so that the strong law of\nlarge numbers guarantees the convergence. Moreover, the simulation noise is a\ndecreasing function of the Poisson process intensity. Our method handles\nmultidimensional processes with nonconstant drifts and nonconstant\nvariance-covariance matrices. It also encompasses stochastic interest rates. \n\n"}
{"id": "1605.02058", "contents": "Title: Quasinormal frequencies of black hole in the braneworld Abstract: We have studied scalar, electromagnetic and gravitational perturbations of\nthe four-dimensional Reissner-Nordstr\\\"{o}m-like black holes with a\n\\textit{tidal charge} in the Randall-Sundrum braneworld. The quasinormal modes\nof these scalar, electromagnetic, as well as axial and polar gravitational\nperturbations, have been studied in both normal and eikonal regimes.\nCalculations have shown that the black holes on the Randall-Sundrum brane are\nstable against scalar, electromagnetic and gravitational perturbations.\nMoreover, we determine the grey body factor, giving transmission and reflection\nof the scattered waves through the scalar, electromagnetic and gravitational\neffective potentials. It has been shown that the scalar perturbative fields are\nthe most favorite to the reflected as compared to the latter. With increasing\nvalue of the tidal charge ability of the all perturbative potentials to reflect\nthe waves decreases. Our calculations in low- and high-frequency regimes have\nshown that black holes on the braneworld always have a bigger absorption cross\nsection of massless scalar waves than the Schwarzschild and standard\nReissner-Nordstr\\\"{o}m black holes. \n\n"}
{"id": "1605.03156", "contents": "Title: Assessing lepton-flavour non-universality from $B\\to K^*\\ell\\ell$\n  angular analyses Abstract: The $B\\to K^*\\mu\\mu$ decay exhibits deviations with respect to Standard Model\nexpectations and the measurement of the ratio $R_K$ hints at a violation of\nlepton-flavour universality in $B\\to K\\ell\\ell$ transitions. Both effects can\nbe understood in model-independent fits as a short-distance contribution to the\nWilson coefficient $C_{9\\mu}$, with some room for similar contributions in\nother Wilson coefficients for $b\\to s\\mu\\mu$ transitions. We discuss how a full\nangular analysis of $B\\to K^*ee$ and its comparison with $B\\to K^*\\mu\\mu$ could\nimprove our understanding of these anomalies and help confirming their\ninterpretation in terms of short-distance New Physics. We discuss several\nobservables of interest in this context and provide predictions for them within\nthe Standard Model as well as within several New Physics benchmark scenarios.\nWe pay special attention to the sensitivity of these observables to hadronic\nuncertainties from SM contributions with charm loops. \n\n"}
{"id": "1605.03568", "contents": "Title: Noncommutative Ergodic Theorems for Connected Amenable Groups Abstract: This paper is devoted to the study of noncommutative ergodic theorems for\nconnected amenable locally compact groups. For a dynamical system\n$(\\mathcal{M},\\tau,G,\\sigma)$, where $(\\mathcal{M},\\tau)$ is a von Neumann\nalgebra with a normal faithful finite trace and $(G,\\sigma)$ is a connected\namenable locally compact group with a well defined representation on\n$\\mathcal{M}$, we try to find the largest noncommutative function spaces\nconstructed from $\\mathcal{M}$ on which the individual ergodic theorems hold.\nBy using the Emerson-Greenleaf's structure theorem, we transfer the key\nquestion to proving the ergodic theorems for $\\mathbb{R}^d$ group actions.\nSplitting the $\\mathbb{R}^d$ actions problem in two cases according to\ndifferent multi-parameter convergence types---cube convergence and unrestricted\nconvergence, we can give maximal ergodic inequalities on $L_1(\\mathcal{M})$ and\non noncommutative Orlicz space $L_1\\log^{2(d-1)}L(\\mathcal{M})$, each of which\nis deduced from the result already known in discrete case. Finally we give the\nindividual ergodic theorems for $G$ acting on $L_1(\\mathcal{M})$ and on\n$L_1\\log^{2(d-1)}L(\\mathcal{M})$, where the ergodic averages are taken along\ncertain sequences of measurable subsets of $G$. \n\n"}
{"id": "1605.04318", "contents": "Title: Magnetic Influences on the Solar Wind (Ph.D. Dissertation) Abstract: The steady, supersonic outflow from the Sun we call the solar wind was first\nposited in the 1950s and initial theories rightly linked the acceleration of\nthe wind to the existence of the million-degree solar corona. Still today, the\nwind acceleration mechanisms and the coronal heating processes remain unsolved\nchallenges in solar physics. In this work, I seek to answer a portion of the\nmystery by focusing on a particular acceleration process: Alfven waves launched\nby the motion of magnetic field footpoints in the photosphere. The entire\ncorona is threaded with magnetic loops and flux tubes that open up into the\nheliosphere. I have sought a better understanding of the role these magnetic\nfields play in determining solar wind properties in open flux tubes. After an\nintroduction of relevant material, I discuss my parameter study of magnetic\nfield profiles and the statistical understanding we can draw from the resulting\nsteady-state wind. In the chapter following, I describe how I extended this\nwork to consider time dependence in the turbulent heating by Alfven waves in\nthree dimensional simulations. The bursty nature of this heating led to a\nnatural next step that expands my work to include not only the theoretical, but\nalso a project to analyze observations of small network jets in the\nchromosphere and transition region, and the underlying photospheric magnetic\nfield that forms thresholds in jet production. In summary, this work takes a\nbroad look at the extent to which Alfven-wave-driven turbulent heating can\nexplain measured solar wind properties and other observed phenomena. \n\n"}
{"id": "1605.04600", "contents": "Title: Learning zero-cost portfolio selection with pattern matching Abstract: We consider and extend the adversarial agent-based learning approach of\nGy{\\\"o}rfi {\\it et al} to the situation of zero-cost portfolio selection\nimplemented with a quadratic approximation derived from the mutual fund\nseparation theorems. The algorithm is applied to daily sampled sequential\nOpen-High-Low-Close data and sequential intraday 5-minute bar-data from the\nJohannesburg Stock Exchange (JSE). Statistical tests of the algorithms are\nconsidered. The algorithms are directly compared to standard NYSE test cases\nfrom prior literature. The learning algorithm is used to select parameters for\nagents (or experts) generated by pattern matching past dynamics using a simple\nnearest-neighbour search algorithm. It is shown that there is a speed advantage\nassociated with using an analytic solution of the mutual fund separation\ntheorems. It is argued that the expected loss in performance does not undermine\nthe potential application to intraday quantitative trading and that when\ntransactions costs and slippage are considered the strategies can still remain\nprofitable when unleveraged. The paper demonstrates that patterns in financial\ntime-series on the JSE can be systematically exploited in collective but that\nthis does not imply predictability of the individual asset time-series\nthemselves. \n\n"}
{"id": "1605.06699", "contents": "Title: Multiplicity and rapidity dependence of strange hadron production in pp,\n  pPb, and PbPb collisions at the LHC Abstract: Measurements of strange hadron (K0s, Lambda + anti-Lambda, and Xi+ + Xi-)\ntransverse momentum spectra in pp, pPb, and PbPb collisions are presented over\na wide range of rapidity and event charged-particle multiplicity. The data were\ncollected with the CMS detector at the CERN LHC in pp collisions at sqrt(s) = 7\nTeV, pPb collisions at sqrt(s[NN]) = 5.02 TeV, and PbPb collisions at\nsqrt(s[NN]) = 2.76 TeV. The average transverse kinetic energy is found to\nincrease with multiplicity, at a faster rate for heavier strange particle\nspecies in all systems. At similar multiplicities, the difference in average\ntransverse kinetic energy between different particle species is observed to be\nlarger for pp and pPb events than for PbPb events. In pPb collisions, the\naverage transverse kinetic energy is found to be slightly larger in the\nPb-going direction than in the p-going direction for events with large\nmultiplicity. The spectra are compared to models motivated by hydrodynamics. \n\n"}
{"id": "1605.08628", "contents": "Title: The NIKA2 commissioning campaign: performance and first results Abstract: The New IRAM KID Array 2 (NIKA 2) is a dual-band camera operating with three\nfrequency-multiplexed kilopixels arrays of Lumped Element Kinetic Inductance\nDetectors (LEKID) cooled at 150 mK. NIKA 2 is designed to observe the intensity\nand polarisation of the sky at 1.15 and 2.0 mm wavelength from the IRAM 30 m\ntelescope. The NIKA 2 instrument represents a huge step in performance as\ncompared to the NIKA pathfinder instrument, which has already shown\nstate-of-the-art detector and photometric performance. After the commissioning\nplanned to be accomplished at the end of 2016, NIKA 2 will be an IRAM resident\ninstrument for the next ten years or more. NIKA 2 should allow the\nastrophysical community to tackle a large number of open questions reaching\nfrom the role of the Galactic magnetic field in star formation to the\ndiscrepancy between cluster-based and CMB-based cosmology possibly induced by\nthe unknown cluster physics. We present an overview of the commissioning phase\ntogether with some first results. \n\n"}
{"id": "1605.09085", "contents": "Title: Stochastic Function Norm Regularization of Deep Networks Abstract: Deep neural networks have had an enormous impact on image analysis.\nState-of-the-art training methods, based on weight decay and DropOut, result in\nimpressive performance when a very large training set is available. However,\nthey tend to have large problems overfitting to small data sets. Indeed, the\navailable regularization methods deal with the complexity of the network\nfunction only indirectly. In this paper, we study the feasibility of directly\nusing the $L_2$ function norm for regularization. Two methods to integrate this\nnew regularization in the stochastic backpropagation are proposed. Moreover,\nthe convergence of these new algorithms is studied. We finally show that they\noutperform the state-of-the-art methods in the low sample regime on benchmark\ndatasets (MNIST and CIFAR10). The obtained results demonstrate very clear\nimprovement, especially in the context of small sample regimes with data laying\nin a low dimensional manifold. Source code of the method can be found at\n\\url{https://github.com/AmalRT/DNN_Reg}. \n\n"}
{"id": "1606.01495", "contents": "Title: The Problem of Calibrating an Agent-Based Model of High-Frequency\n  Trading Abstract: Agent-based models, particularly those applied to financial markets,\ndemonstrate the ability to produce realistic, simulated system dynamics,\ncomparable to those observed in empirical investigations. Despite this, they\nremain fairly difficult to calibrate due to their tendency to be\ncomputationally expensive, even with recent advances in technology. For this\nreason, financial agent-based models are frequently validated by demonstrating\nan ability to reproduce well-known log return time series and central limit\norder book stylized facts, as opposed to being rigorously calibrated to\ntransaction data. We thus apply an established financial agent-based model\ncalibration framework to a simple model of high- and low-frequency trader\ninteraction and demonstrate possible inadequacies of a stylized fact-centric\napproach to model validation. We further argue for the centrality of\ncalibration to the validation of financial agent-based models and possible\npitfalls of current approaches to financial agent-based modeling. \n\n"}
{"id": "1606.02475", "contents": "Title: Unfolded equations for massive higher spin supermultiplets in AdS_3 Abstract: In this paper we give an explicit construction of unfolded equations for\nmassive higher spin supermultiplets of the minimal (1,0) supersymmetry in AdS_3\nspace. For that purpose we use an unfolded formulation for massive bosonic and\nfermionic higher spins and find supertransformations leaving appropriate set of\nunfolded equations invariant. We provide two general supermultiplets (s, s+1/2)\nand (s, s-1/2) with arbitrary integer s, as well as a number of lower spin\nexamples. \n\n"}
{"id": "1606.02585", "contents": "Title: Fully Convolutional Networks for Dense Semantic Labelling of\n  High-Resolution Aerial Imagery Abstract: The trend towards higher resolution remote sensing imagery facilitates a\ntransition from land-use classification to object-level scene understanding.\nRather than relying purely on spectral content, appearance-based image features\ncome into play. In this work, deep convolutional neural networks (CNNs) are\napplied to semantic labelling of high-resolution remote sensing data. Recent\nadvances in fully convolutional networks (FCNs) are adapted to overhead data\nand shown to be as effective as in other domains. A full-resolution labelling\nis inferred using a deep FCN with no downsampling, obviating the need for\ndeconvolution or interpolation. To make better use of image features, a\npre-trained CNN is fine-tuned on remote sensing data in a hybrid network\ncontext, resulting in superior results compared to a network trained from\nscratch. The proposed approach is applied to the problem of labelling\nhigh-resolution aerial imagery, where fine boundary detail is important. The\ndense labelling yields state-of-the-art accuracy for the ISPRS Vaihingen and\nPotsdam benchmark data sets. \n\n"}
{"id": "1606.05507", "contents": "Title: Coloring Graphs with Forbidden Minors Abstract: Hadwiger's conjecture from 1943 states that for every integer $t\\ge1$, every\ngraph either can be $t$-colored or has a subgraph that can be contracted to the\ncomplete graph on $t+1$ vertices. As pointed out by Paul Seymour in his recent\nsurvey on Hadwiger's conjecture, proving that graphs with no $K_7$ minor are\n$6$-colorable is the first case of Hadwiger's conjecture that is still open. It\nis not known yet whether graphs with no $K_7$ minor are $7$-colorable. Using a\nKempe-chain argument along with the fact that an induced path on three vertices\nis dominating in a graph with independence number two, we first give a very\nshort and computer-free proof of a recent result of Albar and Gon\\c{c}alves and\ngeneralize it to the next step by showing that every graph with no $K_t$ minor\nis $(2t-6)$-colorable, where $t\\in\\{7,8,9\\}$. We then prove that graphs with no\n$K_8^-$ minor are $9$-colorable and graphs with no $K_8^=$ minor are\n$8$-colorable. Finally we prove that if Mader's bound for the extremal function\nfor $K_p$ minors is true, then every graph with no $K_p$ minor is\n$(2t-6)$-colorable for all $p\\ge5$. This implies our first result. We believe\nthat the Kempe-chain method we have developed in this paper is of independent\ninterest. \n\n"}
{"id": "1606.05815", "contents": "Title: Quantum kicked harmonic oscillator in contact with a heat bath Abstract: We consider the quantum harmonic oscillator in contact with a finite\ntemperature bath, modelled by the Caldeira-Leggett master equation. Applying\nperiodic kicks to the oscillator, we study the system in different dynamical\nregimes between classical integrability and chaos on the one hand, and\nballistic or diffusive energy absorption on the other. We then investigate the\ninfluence of the heat bath on the oscillator in each case. Phase space\ntechniques allow us to simulate the evolution of the system efficiently. In\nthis way, we calculate high resolution Wigner functions at long times, where\nthe system approaches a quasi-stationary cyclic evolution. Thereby, we are able\nto perform an accurate study of the thermodynamic properties of a\nnon-integrable, quantum chaotic system in contact with a heat bath. \n\n"}
{"id": "1606.05834", "contents": "Title: Convergence of Nonlinear Observers on R^n with a Riemannian Metric (Part\n  II) Abstract: In [1], it is established that a convergent observer with an infinite gain\nmargin can be designed for a given nonlinear system when a Riemannian metric\nshowing that the system is differentially detectable (i.e., the Lie derivative\nof the Riemannian metric along the system vector field is negative in the space\ntangent to the output function level sets) and the level sets of the output\nfunction are geodesically convex is available. In this paper, we propose\ntechniques for designing a Riemannian metric satisfying the first property in\nthe case where the system is strongly infinitesimally observable (i.e., each\ntime-varying linear system resulting from the linearization along a solution to\nthe system satisfies a uniform observability property) or where it is strongly\ndifferentially observable (i.e. the mapping state to output derivatives is an\ninjective immersion) or where it is Lagrangian. Also, we give results that are\ncomplementary to those in [1]. In particular, we provide a locally convergent\nobserver and make a link to the existence of a reduced order observer. Examples\nillustrating the results are presented. \n\n"}
{"id": "1606.06143", "contents": "Title: Vibrato and automatic differentiation for high order derivatives and\n  sensitivities of financial options Abstract: This paper deals with the computation of second or higher order greeks of\nfinancial securities. It combines two methods, Vibrato and automatic\ndifferentiation and compares with other methods. We show that this combined\ntechnique is faster than standard finite difference, more stable than automatic\ndifferentiation of second order derivatives and more general than Malliavin\nCalculus. We present a generic framework to compute any greeks and present\nseveral applications on different types of financial contracts: European and\nAmerican options, multidimensional Basket Call and stochastic volatility models\nsuch as Heston's model. We give also an algorithm to compute derivatives for\nthe Longstaff-Schwartz Monte Carlo method for American options. We also extend\nautomatic differentiation for second order derivatives of options with\nnon-twice differentiable payoff. 1. Introduction. Due to BASEL III regulations,\nbanks are requested to evaluate the sensitivities of their portfolios every day\n(risk assessment). Some of these portfolios are huge and sensitivities are time\nconsuming to compute accurately. Faced with the problem of building a software\nfor this task and distrusting automatic differentiation for non-differentiable\nfunctions, we turned to an idea developed by Mike Giles called Vibrato. Vibrato\nat core is a differentiation of a combination of likelihood ratio method and\npathwise evaluation. In Giles [12], [13], it is shown that the computing time,\nstability and precision are enhanced compared with numerical differentiation of\nthe full Monte Carlo path. In many cases, double sensitivities, i.e. second\nderivatives with respect to parameters, are needed (e.g. gamma hedging). Finite\ndifference approximation of sensitivities is a very simple method but its\nprecision is hard to control because it relies on the appropriate choice of the\nincrement. Automatic differentiation of computer programs bypass the difficulty\nand its computing cost is similar to finite difference, if not cheaper. But in\nfinance the payoff is never twice differentiable and so generalized derivatives\nhave to be used requiring approximations of Dirac functions of which the\nprecision is also doubtful. The purpose of this paper is to investigate the\nfeasibility of Vibrato for second and higher derivatives. We will first compare\nVibrato applied twice with the analytic differentiation of Vibrato and show\nthat it is equivalent, as the second is easier we propose the best compromise\nfor second derivatives: Automatic Differentiation of Vibrato. In [8], Capriotti\nhas recently investigated the coupling of different mathematical methods --\nnamely pathwise and likelihood ratio methods -- with an Automatic differ \n\n"}
{"id": "1606.07094", "contents": "Title: Sharp Adams-Moser-Trudinger type inequalities in the hyperbolic space Abstract: The purpose of this paper is to establish some Adams-Moser-Trudinger\ninequalities, which are the borderline cases of the Sobolev embedding, in the\nhyperbolic space $\\mathbb H^n$. First, we prove a sharp Adams inequality of\norder two with the exact growth condition in $\\mathbb H^n$. Then we use it to\nderive a sharp Adams-type inequality and an Adachi-Tanaka-type inequality. We\nalso prove a sharp Adams-type inequality with Navier boundary condition on any\nbounded domain of $\\mathbb H^n$, which generalizes the result of Tarsi to the\nsetting of hyperbolic spaces. Finally, we establish a Lions-type lemma and an\nimproved Adams-type inequality in the spirit of Lions in $\\mathbb H^n$. Our\nproofs rely on the symmetrization method extended to hyperbolic spaces. \n\n"}
{"id": "1606.07691", "contents": "Title: Topological quantum phase transition driven by anisotropic spin-orbit\n  coupling in trinuclear organometallic coordination crystals Abstract: We show how quasi-one-dimensional correlated insulating states arise at\ntwo-thirds filling in organometallic multinuclear coordination complexes\ndescribed by layered decorated honeycomb lattices. The interplay of spin-orbit\ncoupling and electronic correlations leads to pseudospin-1 moments arranged in\nweakly coupled chains with highly anisotropic exchange and a large trigonal\nsplitting. This leads to a quantum phase transition from a Haldane phase to a\ntopologically trivial phase as the relative strength of the spin-orbit coupling\nincreases. \n\n"}
{"id": "1607.00268", "contents": "Title: Well-posedness for mean-field evolutions arising in superconductivity Abstract: We establish the existence of a global solution for a new family of\nfluid-like equations, which are obtained in a joint work with Serfaty in\ncertain regimes as the mean-field evolution of the supercurrent density in a\n(2D section of a) type-II superconductor with pinning and with imposed electric\ncurrent. We also consider general vortex-sheet initial data, and investigate\nthe uniqueness and regularity properties of the solution. For some choice of\nparameters, the equation under investigation coincides with the so-called lake\nequation from 2D shallow water fluid dynamics, and our analysis then leads to a\nnew existence result for rough initial data. \n\n"}
{"id": "1607.00650", "contents": "Title: The effects of the U$_\\textrm{Y}$(1) Chern-Simons term and its baryonic\n  contribution on matter asymmetries and hypermagnetic fields Abstract: In this paper, we study the significance of the U$_\\textrm{Y}$(1)\nChern-Simons term in general, and its baryonic contribution in particular, for\nthe evolution of the matter asymmetries and the hypermagnetic field in the\ntemperature range $100$GeV$\\leq T \\leq 10$TeV. We show that an initial helical\nhypermagnetic field, denoted by $B_Y^{(0)}$, can grow matter asymmetries from\nzero initial value. However, the growth which is initially quadratic with\nrespect to $B_Y^{(0)}$, saturates for values larger than a critical value. The\ninclusion of the baryonic contribution reduces this critical value, leading to\nsmaller final matter asymmetries. Meanwhile, $B_Y(T_{EW})$ becomes slightly\nlarger than $B_Y^{(0)}$. In the absence of the U$_\\textrm{Y}$(1) Chern-Simons\nterm, the final values of matter asymmetries grow without saturation.\nConversely, we show that an initial matter asymmetry can grow an initial seed\nof hypermagnetic field, provided the Chern-Simons term is taken into account.\nThe growth process saturates when the matter asymmetry drops abruptly. When the\nbaryonic contribution is included, the saturation occurs at an earlier time,\nand $B_Y (T_{EW})$ becomes larger. We also show the results can be within the\nacceptable range of present day data, provided the inverse cascade process is\nalso taken into account. \n\n"}
{"id": "1607.01244", "contents": "Title: On stability of exponential cosmological solutions with non-static\n  volume factor in the Einstein-Gauss-Bonnet model Abstract: A (n+1)-dimensional gravitational model with Gauss-Bonnet term and\ncosmological constant term is considered. When ansatz with diagonal\ncosmological metrics is adopted, the solutions with exponential dependence of\nscale factors: a_i ~ exp( v^i t), i = 1, ..., n, are analysed for n > 3. We\nstudy the stability of the solutions with non-static volume factor, i.e. if\nK(v) = \\sum_{k = 1}^{n} v^k \\neq 0. We prove that under certain restriction R\nimposed solutions with K(v) > 0 are stable while solutions with K(v) < 0 are\nunstable. Certain examples of stable solutions are presented. We show that the\nsolutions with v^1 = v^2 = v^3 = H > 0 and zero variation of the effective\ngravitational constant are stable if the restriction R is obeyed. \n\n"}
{"id": "1607.01743", "contents": "Title: BPS states in the Minahan-Nemeschansky E6 theory Abstract: We use the method of spectral networks to compute BPS state degeneracies in\nthe Minahan-Nemeschansky $E_6$ theory, on its Coulomb branch, without turning\non a mass deformation. The BPS multiplicities come out in representations of\nthe $E_6$ flavor symmetry. For example, along the simplest ray in\nelectromagnetic charge space, we give the first $14$ numerical degeneracies,\nand the first $7$ degeneracies as representations of $E_6$. We find a\ncomplicated spectrum, exhibiting exponential growth of multiplicities as a\nfunction of the electromagnetic charge. There is one unexpected outcome: the\nspectrum is consistent (in a nontrivial way) with the hypothesis of \"spin\npurity,\" that if a BPS state in this theory has electromagnetic charge equal to\n$n$ times a primitive charge, then it appears in a spin-$\\frac{n}{2}$\nmultiplet. \n\n"}
{"id": "1607.03541", "contents": "Title: Is there a signal for Lorentz non-invariance in existing radioactive\n  decay data? Abstract: Measurements of the beta decay rates of nuclei have revealed annual\nperiodicities with approximately the same relative amplitude even though the\nhalf-lives range over nine orders of magnitude. Here we show that this can be\nexplained if the emitted neutrinos behave as if they propagate in a medium with\na refractive index which varies as the Earth orbits the sun. This refractive\nindex may be due to fundamental Lorentz non-invariance (LNI), or apparent LNI\narising from interactions with solar or relic neutrinos, or dark matter.\nAdditionally, this medium could have consequences for experiments attempting to\nmeasure the neutrino mass. \n\n"}
{"id": "1607.04542", "contents": "Title: Diffusions under a local strong H\\\"ormander condition. Part I: density\n  estimates Abstract: We study lower and upper bounds for the density of a diffusion process in\n${\\mathbb{R}}^n$ in a small (but not asymptotic) time, say $\\delta$. We assume\nthat the diffusion coefficients $\\sigma_1,\\ldots,\\sigma_d$ may degenerate at\nthe starting time $0$ and point $x_0$ but they satisfy a strong H\\\"ormander\ncondition involving the first order Lie brackets. The density estimates are\nwritten in terms of a norm which accounts for the non-isotropic structure of\nthe problem: in a small time $\\delta$, the diffusion process propagates with\nspeed $\\sqrt{\\delta}$ in the direction of the diffusion vector fields\n$\\sigma_{j}$ and with speed $\\delta=\\sqrt{\\delta}\\times \\sqrt{\\delta}$ in the\ndirection of $[\\sigma_{i},\\sigma_{j}]$. In the second part of this paper, such\nestimates will be used in order to study lower and upper bounds for the\nprobability that the diffusion process remains in a tube around a skeleton path\nup to a fixed time. \n\n"}
{"id": "1607.05816", "contents": "Title: Scaling Algorithms for Unbalanced Transport Problems Abstract: This article introduces a new class of fast algorithms to approximate\nvariational problems involving unbalanced optimal transport. While classical\noptimal transport considers only normalized probability distributions, it is\nimportant for many applications to be able to compute some sort of relaxed\ntransportation between arbitrary positive measures. A generic class of such\n\"unbalanced\" optimal transport problems has been recently proposed by several\nauthors. In this paper, we show how to extend the, now classical, entropic\nregularization scheme to these unbalanced problems. This gives rise to fast,\nhighly parallelizable algorithms that operate by performing only diagonal\nscaling (i.e. pointwise multiplications) of the transportation couplings. They\nare generalizations of the celebrated Sinkhorn algorithm. We show how these\nmethods can be used to solve unbalanced transport, unbalanced gradient flows,\nand to compute unbalanced barycenters. We showcase applications to 2-D shape\nmodification, color transfer, and growth models. \n\n"}
{"id": "1607.07099", "contents": "Title: Inverse Optimization of Convex Risk Functions Abstract: The theory of convex risk functions has now been well established as the\nbasis for identifying the families of risk functions that should be used in\nrisk averse optimization problems. Despite its theoretical appeal, the\nimplementation of a convex risk function remains difficult, as there is little\nguidance regarding how a convex risk function should be chosen so that it also\nwell represents one's own risk preferences. In this paper, we address this\nissue through the lens of inverse optimization. Specifically, given solution\ndata from some (forward) risk-averse optimization problems we develop an\ninverse optimization framework that generates a risk function that renders the\nsolutions optimal for the forward problems. The framework incorporates the\nwell-known properties of convex risk functions, namely, monotonicity,\nconvexity, translation invariance, and law invariance, as the general\ninformation about candidate risk functions, and also the feedbacks from\nindividuals, which include an initial estimate of the risk function and\npairwise comparisons among random losses, as the more specific information. Our\nframework is particularly novel in that unlike classical inverse optimization,\nno parametric assumption is made about the risk function, i.e. it is\nnon-parametric. We show how the resulting inverse optimization problems can be\nreformulated as convex programs and are polynomially solvable if the\ncorresponding forward problems are polynomially solvable. We illustrate the\nimputed risk functions in a portfolio selection problem and demonstrate their\npractical value using real-life data. \n\n"}
{"id": "1607.07487", "contents": "Title: High braking index pulsar PSR J1640-4631: low-mass neutron star with a\n  large inclination angle? Abstract: Recent timing observation constrained the braking index of the X-ray pulsar\nPSR J1640-4631 to be $n=3.15\\pm0.03$, which is the highest value of all pulsars\nwith measured braking indices so far. In this Letter, we investigate whether\npulsar braking by combined between the magnetic dipole emission and the\ngravitational radiation might have a braking index greater than three. For\nconventional neutron star and low mass quark star candidates, the inferred\nellipticities derived by the observed braking index are obviously much larger\nthan the theoretical estimated maximum value. If PSR J1640-4631 is a low-mass\nneutron star with a mass of $0.1~ \\rm M_{\\odot}$, the inferred ellipticity can\nbe approximately equal to the theoretical estimated maximum value. Because of\nthe radio-quiet nature of this source, we employ the vacuum gap model developed\nby Ruderman and Sutherland to constrain the inclination angle to be\n$87.2-90^{\\circ}$. Based on this, we propose that a low-mass neutron star with\na large inclination angle can interpret the high braking index and the\nradio-quiet nature of this source. Future observations such as gravitational\nwave detection and long-term timing for this source are required to confirm or\nconfute our scenario. \n\n"}
{"id": "1607.08068", "contents": "Title: Harnack inequality for kinetic Fokker-Planck equations with rough\n  coefficients and application to the Landau equation Abstract: We extend the De Giorgi--Nash--Moser theory to a class of kinetic\nFokker-Planck equations and deduce new results on the Landau-Coulomb equation.\nMore precisely, we first study the H{\\\"o}lder regularity and establish a\nHarnack inequality for solutions to a general linear equation of Fokker-Planck\ntype whose coefficients are merely measurable and essentially bounded, i.e.\nassuming no regularity on the coefficients in order to later derive results for\nnon-linear problems. This general equation has the formal structure of the\nhypoelliptic equations \"of type II\" , sometimes also called ultraparabolic\nequations of Kolmogorov type, but with rough coefficients: it combines a\nfirst-order skew-symmetric operator with a second-order elliptic operator\ninvolving derivatives along only part of the coordinates and with rough\ncoefficients. These general results are then applied to the non-negative\nessentially bounded weak solutions of the Landau equation with inverse-power\nlaw $\\gamma$ $\\in$ [--d, 1] whose mass, energy and entropy density are bounded\nand mass is bounded away from 0, and we deduce the H{\\\"o}lder regularity of\nthese solutions. \n\n"}
{"id": "1608.04745", "contents": "Title: Secretly Asymmetric Dark Matter Abstract: We study a mechanism where the dark matter number density today arises from\nasymmetries generated in the dark sector in the early universe, even though\ntotal dark matter number remains zero throughout the history of the universe.\nThe dark matter population today can be completely symmetric, with annihilation\nrates above those expected from thermal WIMPs. We give a simple example of this\nmechanism using a benchmark model of flavored dark matter. We discuss the\nexperimental signatures of this setup, which arise mainly from the sector that\nannihilates the symmetric component of dark matter. \n\n"}
{"id": "1608.05184", "contents": "Title: Constraining the X-ray AGN halo occupation distribution: implications\n  for eROSITA Abstract: The X-ray emission from active galactic nucleus (AGN) is a major component of\nextragalactic X-ray sky. In this paper, we use the X-ray luminosity function\n(XLF) and halo occupation distribution (HOD) formalism to construct a halo\nmodel for the X-ray emission from AGNs. Verifying that the two inputs (XLF and\nHOD) are in agreement with each other, we compute the auto-correlation power\nspectrum in the soft X-ray band (0.5-2 keV) due to the AGNs potentially\nresolved by eROSITA (extended ROentgen Survey with an Imaging Telescope Array)\nmission and explore the redshift and mass dependence of the power spectrum.\nStudying the relative contribution of the Poisson and the clustering terms to\nthe total power, we find that at multipoles $l\\lesssim 1000$ (i.e. large\nscales), the clustering term is larger than the Poisson term. We also forecast\nthe potential of X-ray auto-correlation power spectrum and X-ray-lensing\ncross-correlation power spectrum using eROSITA and eROSITA-LSST (Large Synoptic\nSurvey Telescope) surveys, respectively, to constrain the HOD parameters and\ntheir redshift evolution. In addition, we compute the power spectrum of the\nAGNs lying below the flux resolution limit of eROSITA, which is essential to\nunderstand in order to extract the X-ray signal from the hot diffuse gas\npresent in galaxies and clusters. \n\n"}
{"id": "1608.05377", "contents": "Title: Classical branch structure from spatial redundancy in a many-body\n  wavefunction Abstract: When the wavefunction of a large quantum system unitarily evolves away from a\nlow-entropy initial state, there is strong circumstantial evidence it develops\n\"branches\": a decomposition into orthogonal components that is\nindistinguishable from the corresponding incoherent mixture with feasible\nobservations. Is this decomposition unique? Must the number of branches\nincrease with time? These questions are hard to answer because there is no\nformal definition of branches, and most intuition is based on toy models with\narbitrarily preferred degrees of freedom. Here, assuming only the tensor\nstructure associated with spatial locality, I show that branch decompositions\nare highly constrained just by the requirement that they exhibit redundant\nlocal records. The set of all redundantly recorded observables induces a\npreferred decomposition into simultaneous eigenstates unless their records are\nhighly extended and delicately overlapping, as exemplified by the Shor\nerror-correcting code. A maximum length scale for records is enough to\nguarantee uniqueness. Speculatively, objective branch decompositions may speed\nup numerical simulations of nonstationary many-body states, illuminate the\nthermalization of closed systems, and demote measurement from fundamental\nprimitive in the quantum formalism. \n\n"}
{"id": "1609.00504", "contents": "Title: Quantifying lost information due to covariance matrix estimation in\n  parameter inference Abstract: Parameter inference with an estimated covariance matrix systematically loses\ninformation due to the remaining uncertainty of the covariance matrix. Here, we\nquantify this loss of precision and develop a framework to hypothetically\nrestore it, which allows to judge how far away a given analysis is from the\nideal case of a known covariance matrix. We point out that it is insufficient\nto estimate this loss by debiasing a Fisher matrix as previously done, due to a\nfundamental inequality that describes how biases arise in non-linear functions.\nWe therefore develop direct estimators for parameter credibility contours and\nthe figure of merit. We apply our results to DES Science Verification weak\nlensing data, detecting a 10% loss of information that increases their\ncredibility contours. No significant loss of information is found for KiDS. For\na Euclid-like survey, with about 10 nuisance parameters we find that 2900\nsimulations are sufficient to limit the systematically lost information to 1%,\nwith an additional uncertainty of about 2%. Without any nuisance parameters\n1900 simulations are sufficient to only lose 1% of information. We also derive\nan estimator for the Fisher matrix of the unknown true covariance matrix, two\nestimators of its inverse with different physical meanings, and an estimator\nfor the optimally achievable figure of merit. The formalism here quantifies the\ngains to be made by running more simulated datasets, allowing decisions to be\nmade about numbers of simulations in an informed way. \n\n"}
{"id": "1609.02108", "contents": "Title: The characteristic function of rough Heston models Abstract: It has been recently shown that rough volatility models, where the volatility\nis driven by a fractional Brownian motion with small Hurst parameter, provide\nvery relevant dynamics in order to reproduce the behavior of both historical\nand implied volatilities. However, due to the non-Markovian nature of the\nfractional Brownian motion, they raise new issues when it comes to derivatives\npricing. Using an original link between nearly unstable Hawkes processes and\nfractional volatility models, we compute the characteristic function of the\nlog-price in rough Heston models. In the classical Heston model, the\ncharacteristic function is expressed in terms of the solution of a Riccati\nequation. Here we show that rough Heston models exhibit quite a similar\nstructure, the Riccati equation being replaced by a fractional Riccati\nequation. \n\n"}
{"id": "1609.03171", "contents": "Title: Linear Stability of Rotating Black Holes: Outline of the Proof Abstract: After a brief introduction to the black hole stability problem, we outline\nour recent proof of the linear stability of the non-extreme Kerr geometry. \n\n"}
{"id": "1609.05758", "contents": "Title: Impact of instructional approach on students' epistemologies about\n  experimental physics Abstract: Student learning in undergraduate physics laboratory courses has garnered\nincreased attention within the PER community. Considerable work has been done\nto develop curricular materials and pedagogical techniques designed to enhance\nstudent learning within laboratory learning environments. Examples of these\ntransformation efforts include the Investigative Science Learning Environment\n(ISLE), Modeling Instruction, and integrated lab/lecture environments (e.g.,\nstudio physics). In addition to improving students' understanding of the\nphysics content, lab courses often have an implicit or explicit goal of\nincreasing students' understanding and appreciation of the nature of\nexperimental physics. We examine students' responses to a laboratory-focused\nepistemological assessment -- the Colorado Learning Attitudes about Science\nSurvey for Experimental Physics (E-CLASS) -- to explore whether courses using\ntransformed curricula or pedagogy show more expert-like student epistemologies\nrelative to courses using traditional guided labs, as well as how this trend\nvaries based on student major or gender. Data for this study are drawn from an\nexisting data set of responses to the E-CLASS from multiple courses and\ninstitutions. \n\n"}
{"id": "1609.06636", "contents": "Title: Quantum Approximate Markov Chains are Thermal Abstract: We prove that any one-dimensional (1D) quantum state with small quantum\nconditional mutual information in all certain tripartite splits of the system,\nwhich we call a quantum approximate Markov chain, can be well-approximated by a\nGibbs state of a short-range quantum Hamiltonian. Conversely, we also derive an\nupper bound on the (quantum) conditional mutual information of Gibbs states of\n1D short-range quantum Hamiltonians. We show that the conditional mutual\ninformation between two regions A and C conditioned on the middle region B\ndecays exponentially with the square root of the length of B.\n  These two results constitute a variant of the Hammersley-Clifford theorem\n(which characterizes Markov networks, i.e. probability distributions which have\nvanishing conditional mutual information, as Gibbs states of classical\nshort-range Hamiltonians) for 1D quantum systems. The result can be seen as a\nstrengthening - for 1D systems - of the mutual information area law for thermal\nstates. It directly implies an efficient preparation of any 1D Gibbs state at\nfinite temperature by a constant-depth quantum circuit. \n\n"}
{"id": "1609.07269", "contents": "Title: Tight fluctuations of weight-distances in random graphs with\n  infinite-variance degrees Abstract: We prove results for first-passage percolation on the configuration model\nwith i.i.d. degrees having finite mean, infinite variance and i.i.d. weights\nwith strictly positive support of the form Y=a+X, where a is a positive\nconstant. We prove that the weight of the optimal path has tight fluctuations\naround the asymptotical mean of the graph-distance if and only if the following\ncondition holds: the random variable X is such that the continuous-time\nbranching process describing first-passage percolation exploration in the same\ngraph with excess edge weight X has a positive probability to reach infinitely\nmany individuals in a finite time. This shows that almost shortest paths in the\ngraph-distance proliferate, in the sense that there are even ones having tight\ntotal excess edge weight for various edge-weight distributions. \n\n"}
{"id": "1609.07472", "contents": "Title: Gated Neural Networks for Option Pricing: Rationality by Design Abstract: We propose a neural network approach to price EU call options that\nsignificantly outperforms some existing pricing models and comes with\nguarantees that its predictions are economically reasonable. To achieve this,\nwe introduce a class of gated neural networks that automatically learn to\ndivide-and-conquer the problem space for robust and accurate pricing. We then\nderive instantiations of these networks that are 'rational by design' in terms\nof naturally encoding a valid call option surface that enforces no arbitrage\nprinciples. This integration of human insight within data-driven learning\nprovides significantly better generalisation in pricing performance due to the\nencoded inductive bias in the learning, guarantees sanity in the model's\npredictions, and provides econometrically useful byproduct such as risk neutral\ndensity. \n\n"}
{"id": "1610.02157", "contents": "Title: Quantitative Diophantine approximation on affine subspaces Abstract: Recently, Adiceam, Beresnevich, Levesley, Velani and Zorin proved a\nquantitative version of the convergence case of the Khintchine-Groshev theorem\nfor nondegenerate manifolds, motivated by applications to interference\nalignment. In the present paper, we obtain analogues of their results for\naffine subspaces. \n\n"}
{"id": "1610.03314", "contents": "Title: Spontaneous particle-hole symmetry breaking of correlated fermions on\n  the Lieb lattice Abstract: We study spinless fermions with nearest-neighbor repulsive interactions\n($t$-$V$ model) on the two-dimensional three-band Lieb lattice. At\nhalf-filling, the free electronic band structure consists of a flat band at\nzero energy and a single cone with linear dispersion. The flat band is expected\nto be unstable upon inclusion of electronic correlations, and a natural channel\nis charge order. However, due to the three-orbital unit cell, commensurate\ncharge order implies an imbalance of electron and hole densities and therefore\ndoping away from half-filling. Our numerical results show that below a\nfinite-temperature Ising transition a charge density wave with one electron and\ntwo holes per unit cell and its partner under particle-hole transformation are\nspontaneously generated. Our calculations are based on recent advances in\nauxiliary-field and continuous-time quantum Monte Carlo simulations that allow\nsign-free simulations of spinless fermions at half-filling. It is argued that\nparticle-hole symmetry breaking provides a route to access levels of finite\ndoping, without introducing a sign problem. \n\n"}
{"id": "1610.05383", "contents": "Title: Detection of intensity bursts using Hawkes processes: an application to\n  high frequency financial data Abstract: Given a stationary point process, an intensity burst is defined as a short\ntime period during which the number of counts is larger than the typical count\nrate. It might signal a local non-stationarity or the presence of an external\nperturbation to the system. In this paper we propose a novel procedure for the\ndetection of intensity bursts within the Hawkes process framework. By using a\nmodel selection scheme we show that our procedure can be used to detect\nintensity bursts when both their occurrence time and their total number is\nunknown. Moreover, the initial time of the burst can be determined with a\nprecision given by the typical inter-event time. We apply our methodology to\nthe mid-price change in FX markets showing that these bursts are frequent and\nthat only a relatively small fraction is associated to news arrival. We show\nlead-lag relations in intensity burst occurrence across different FX rates and\nwe discuss their relation with price jumps. \n\n"}
{"id": "1610.07470", "contents": "Title: White Dwarf Period Tables - I. Pulsators with hydrogen-dominated\n  atmospheres Abstract: We aimed at collecting all known white dwarf pulsators with\nhydrogen-dominated atmospheres and list their main photometric and atmospheric\nparameters together with their pulsation periods and amplitudes observed at\ndifferent epochs. For this purpose, we explored the pulsating white dwarf\nrelated literature with the systematic use of the SIMBAD and the NASA's\nAstrophysics Data System (ADS) databases. We summarized our results in four\ntables listing seven ZZ Ceti stars in detached white dwarf plus main-sequence\nbinaries, seven extremely low-mass DA pulsators, three hot DAVs and 180 ZZ Ceti\nstars. \n\n"}
{"id": "1610.07838", "contents": "Title: Sharp Estimates for Geman-Yor Processes and applications to Arithmetic\n  Average Asian options Abstract: We prove the existence and pointwise lower and upper bounds for the\nfundamental solution of the degenerate second order partial differential\nequation related to Geman-Yor stochastic processes, that arise in models for\noption pricing theory in finance.\n  Lower bounds are obtained by using repeatedly an invariant Harnack inequality\nand by solving an associated optimal control problem with quadratic cost. Upper\nbounds are obtained by the fact that the optimal cost satisfies a specific\nHamilton-Jacobi-Bellman equation. \n\n"}
{"id": "1611.03022", "contents": "Title: Stealths on $(1+1)$-dimensional dilatonic gravity Abstract: We study gravitational stealth configurations emerging on a charged dilatonic\n$(1+1)$-D black hole spacetime. We accomplish this by considering the coupling\nof a non-minimally scalar field $\\phi$ and a self-interacting scalar field\n$\\Psi$ living in a $(1+1)$-D charged black hole background. In addition, the\nself-interacting potential for $\\Psi$ is obtained which exhibits transitions\nfor some specific values of the non-minimal parameter. Atypically, we found\nthat the solutions for these stealth scalar fields do not have a dependence on\nthe temporal coordinate. \n\n"}
{"id": "1611.05109", "contents": "Title: Low-rank Bilinear Pooling for Fine-Grained Classification Abstract: Pooling second-order local feature statistics to form a high-dimensional\nbilinear feature has been shown to achieve state-of-the-art performance on a\nvariety of fine-grained classification tasks. To address the computational\ndemands of high feature dimensionality, we propose to represent the covariance\nfeatures as a matrix and apply a low-rank bilinear classifier. The resulting\nclassifier can be evaluated without explicitly computing the bilinear feature\nmap which allows for a large reduction in the compute time as well as\ndecreasing the effective number of parameters to be learned.\n  To further compress the model, we propose classifier co-decomposition that\nfactorizes the collection of bilinear classifiers into a common factor and\ncompact per-class terms. The co-decomposition idea can be deployed through two\nconvolutional layers and trained in an end-to-end architecture. We suggest a\nsimple yet effective initialization that avoids explicitly first training and\nfactorizing the larger bilinear classifiers. Through extensive experiments, we\nshow that our model achieves state-of-the-art performance on several public\ndatasets for fine-grained classification trained with only category labels.\nImportantly, our final model is an order of magnitude smaller than the recently\nproposed compact bilinear model, and three orders smaller than the standard\nbilinear CNN model. \n\n"}
{"id": "1611.06344", "contents": "Title: Regression-based complexity reduction of the nested Monte Carlo methods Abstract: In this paper we propose a novel dual regression-based approach for pricing\nAmerican options. This approach reduces the complexity of the nested Monte\nCarlo method and has especially simple form for time discretised diffusion\nprocesses. We analyse the complexity of the proposed approach both in the case\nof fixed and increasing number of exercise dates. The method is illustrated by\nseveral numerical examples. \n\n"}
{"id": "1611.06452", "contents": "Title: Model reduction for calibration of American options Abstract: American put options are among the most frequently traded single stock\noptions, and their calibration is computationally challenging since no\nclosed-form expression is available. Due to the higher flexibility in\ncomparison to European options, the mathematical model involves additional\nconstraints, and a variational inequality is obtained. We use the Heston\nstochastic volatility model to describe the price of a single stock option. In\norder to speed up the calibration process, we apply two model reduction\nstrategies. Firstly, a reduced basis method (RBM) is used to define a suitable\nlow-dimensional basis for the numerical approximation of the\nparameter-dependent partial differential equation ($\\mu$PDE) model. By doing so\nthe computational complexity for solving the $\\mu$PDE is drastically reduced,\nand applications of standard minimization algorithms for the calibration are\nsignificantly faster than working with a high-dimensional finite element basis.\nSecondly, so-called de-Americanization strategies are applied. Here, the main\nidea is to reformulate the calibration problem for American options as a\nproblem for European options and to exploit closed-form solutions. Both\nreduction techniques are systematically compared and tested for both synthetic\nand market data sets. \n\n"}
{"id": "1611.08088", "contents": "Title: Multiple Time Series Ising Model for Financial Market Simulations Abstract: In this paper we propose an Ising model which simulates multiple financial\ntime series. Our model introduces the interaction which couples to spins of\nother systems. Simulations from our model show that time series exhibit the\nvolatility clustering that is often observed in the real financial markets.\nFurthermore we also find non-zero cross correlations between the volatilities\nfrom our model. Thus our model can simulate stock markets where volatilities of\nstocks are mutually correlated. \n\n"}
{"id": "1611.08510", "contents": "Title: Can Agent-Based Models Probe Market Microstructure? Abstract: We extend prior evidence that naively using intraday agent-based models that\ninvolve realistic order-matching processes for modeling continuous-time double\nauction markets seems to fail to be able to provide a robust link between data\nand many model parameters, even when these models are able to reproduce a\nnumber of well-known stylized facts of return time series. We demonstrate that\nwhile the parameters of intraday agent-based models rooted in market\nmicrostructure can be meaningfully calibrated, those exclusively related to\nagent behaviors and incentives remain problematic. This could simply be a\nfailure of the calibration techniques used but we argue that the observed\nparameter degeneracies are most likely a consequence of the realistic matching\nprocesses employed in these models. This suggests that alternative approaches\nto linking data, phenomenology and market structure may be necessary and that\nit is conceivable that one could construct a useful model that does not\ndirectly depend on the nuances of agent behaviors, even when it is known that\nthe real agents engage in complex behaviors. \n\n"}
{"id": "1611.09179", "contents": "Title: Optimal stopping with f -expectations: the irregular case Abstract: We consider the optimal stopping problem with non-linear $f$-expectation\n(induced by a BSDE) without making any regularity assumptions on the reward\nprocess $\\xi$. and with general filtration. We show that the value family can\nbe aggregated by an optional process $Y$. We characterize the process $Y$ as\nthe $\\mathcal{E}^f$-Snell envelope of $\\xi$. We also establish an infinitesimal\ncharacterization of the value process $Y$ in terms of a Reflected BSDE with\n$\\xi$ as the obstacle. To do this, we first establish a comparison theorem for\nirregular RBSDEs. We give an application to the pricing of American options\nwith irregular pay-off in an imperfect market model. \n\n"}
{"id": "1611.10324", "contents": "Title: On the critical branching random walk I: Branching capacity and visiting\n  probability Abstract: We extend the theory of discrete capacity to critical branching random walk.\nWe introduce branching capacity for any finite subset of $\\Z^d, d\\geq5$.\nAnalogous to the regular discrete capacity, branching capacity is closely\nrelated to the asymptotics of the probability of visiting a fixed finite set by\na critical branching random walk starting from a distant point and the\nconditional distribution of the hitting point. \n\n"}
{"id": "1612.01821", "contents": "Title: Principal fiber bundles in non-commutative geometry Abstract: These are the expanded notes of a course given at the Summer school\n\"Geometric, topological and algebraic methods for quantum field theory\" held at\nVilla de Leyva, Colombia in July 2015. We first give an introduction to\nnon-commutative geometry and to the language of Hopf algebras. We next build up\na theory of non-commutative principal fiber bundles and consider various\naspects of such objects. Finally, we illustrate the theory using the quantum\nenveloping algebra $U_q\\mathfrak{sl}(2)$ and related Hopf algebras. \n\n"}
{"id": "1612.05255", "contents": "Title: Stratified regression-based variance reduction approach for weak\n  approximation schemes Abstract: In this paper we suggest a modification of the regression-based variance\nreduction approach recently proposed in Belomestny et al. This modification is\nbased on the stratification technique and allows for a further significant\nvariance reduction. The performance of the proposed approach is illustrated by\nseveral numerical examples. \n\n"}
{"id": "1612.08719", "contents": "Title: Equilibrium mappings in polar-isotropic confined active particles Abstract: Despite their fundamentally non-equilibrium nature, the individual and\ncollective behavior of active systems with polar propulsion and isotropic\ninteractions (polar-isotropic active systems) are remarkably well captured by\nequilibrium mapping techniques. Here we examine two signatures of equilibrium\nsystems -- the existence of a local free energy function and the independence\nof the coarse- grained behavior on the details of the microscopic dynamics --\nin polar-isotropic active particles confined by hard walls of arbitrary\ngeometry at the one-particle level. We find that boundaries that possess\nconcave regions make the density profile strongly dynamics-dependent and give\nit a nonlocal dependence on the geometry of the confining box. This in turn\nconstrains the scope of equilibrium mapping techniques in polar-isotropic\nactive systems. \n\n"}
{"id": "1701.00030", "contents": "Title: Numerical analysis of an extended structural default model with mutual\n  liabilities and jump risk Abstract: We consider a structural default model in an interconnected banking network\nas in Lipton [International Journal of Theoretical and Applied Finance, 19(6),\n2016], with mutual obligations between each pair of banks. We analyse the model\nnumerically for two banks with jumps in their asset value processes.\nSpecifically, we develop a finite difference method for the resulting\ntwo-dimensional partial integro-differential equation, and study its stability\nand consistency. We then compute joint and marginal survival probabilities, as\nwell as prices of credit default swaps (CDS), first-to-default swaps (FTD),\ncredit and debt value adjustments (CVA and DVA). Finally, we calibrate the\nmodel to market data and assess the impact of jump risk. \n\n"}
{"id": "1701.00306", "contents": "Title: K-energy on polarized compactifications of Lie groups Abstract: In this paper, we study Mabuchi's K-energy on a compactification M of a\nreductive Lie group G, which is a complexification of its maximal compact\nsubgroup K. We give a criterion for the properness of K-energy on the space of\nK \\times K-invariant Kahler potentials. In particular, it turns to give an\nalternative proof of Delcroix's theorem for the existence of Kahler-Einstein\nmetrics in case of Fano manifolds M . We also study the existence of minimizers\nof K-energy for general Kahler classes of M. \n\n"}
{"id": "1701.02076", "contents": "Title: Hecke-Hopf algebras Abstract: Let $W$ be a Coxeter group. The goal of the paper is to construct new Hopf\nalgebras that contain Hecke algebras $H_{\\bf q}(W)$ as (left) coideal\nsubalgebras. Our Hecke-Hopf algebras ${\\bf H}(W)$ have a number of\napplications. In particular they provide new solutions of quantum Yang-Baxter\nequation and lead to a construction of a new family of endo-functors of the\ncategory of $H_{\\bf q}(W)$-modules. Hecke-Hopf algebras for the symmetric group\nare related to Fomin-Kirillov algebras, for an arbitrary Coxeter group $W$ the\n\"Demazure\" part of ${\\bf H}(W)$ is being acted upon by generalized braided\nderivatives which generate the corresponding (generalized) Nichols algebra. \n\n"}
{"id": "1701.02626", "contents": "Title: The left tail of renewal measure Abstract: In the paper, we find exact asymptotics of the left tail of renewal measure\nfor a broad class of two-sided random walks. We only require that an\nexponential moment of the left tail is finite. Through a simple change of\nmeasure approach, our result turns out to be almost equivalent to Blackwell's\nTheorem. \n\n"}
{"id": "1701.02798", "contents": "Title: Phase-type Approximation of the Gerber-Shiu Function Abstract: The Gerber-Shiu function provides a way of measuring the risk of an insurance\ncompany. It is given by the expected value of a function that depends on the\nruin time, the deficit at ruin, and the surplus prior to ruin. Its computation\nrequires the evaluation of the overshoot/undershoot distributions of the\nsurplus process at ruin. In this paper, we use the recent developments of the\nfluctuation theory and approximate it in a closed form by fitting the\nunderlying process by phase-type Levy processes. A sequence of numerical\nresults are given. \n\n"}
{"id": "1701.02821", "contents": "Title: Modeling stochastic skew of FX options using SLV models with stochastic\n  spot/vol correlation and correlated jumps Abstract: It is known that the implied volatility skew of FX options demonstrates a\nstochastic behavior which is called stochastic skew. In this paper we create\nstochastic skew by assuming the spot/instantaneous variance correlation to be\nstochastic. Accordingly, we consider a class of SLV models with stochastic\ncorrelation where all drivers - the spot, instantaneous variance and their\ncorrelation are modeled by Levy processes. We assume all diffusion components\nto be fully correlated as well as all jump components. A new fully implicit\nsplitting finite-difference scheme is proposed for solving forward PIDE which\nis used when calibrating the model to market prices of the FX options with\ndifferent strikes and maturities. The scheme is unconditionally stable, of\nsecond order of approximation in time and space, and achieves a linear\ncomplexity in each spatial direction. The results of simulation obtained by\nusing this model demonstrate capacity of the presented approach in modeling\nstochastic skew. \n\n"}
{"id": "1701.03512", "contents": "Title: Parallelizing Computation of Expected Values in Recombinant Binomial\n  Trees Abstract: Recombinant binomial trees are binary trees where each non-leaf node has two\nchild nodes, but adjacent parents share a common child node. Such trees arise\nin finance when pricing an option. For example, valuation of a European option\ncan be carried out by evaluating the expected value of asset payoffs with\nrespect to random paths in the tree. In many variants of the option valuation\nproblem, a closed form solution cannot be obtained and computational methods\nare needed. The cost to exactly compute expected values over random paths grows\nexponentially in the depth of the tree, rendering a serial computation of one\nbranch at a time impractical. We propose a parallelization method that\ntransforms the calculation of the expected value into an \"embarrassingly\nparallel\" problem by mapping the branches of the binomial tree to the processes\nin a multiprocessor computing environment. We also propose a parallel Monte\nCarlo method which takes advantage of the mapping to achieve a reduced variance\nover the basic Monte Carlo estimator. Performance results from R and Julia\nimplementations of the parallelization method on a distributed computing\ncluster indicate that both the implementations are scalable, but Julia is\nsignificantly faster than a similarly written R code. A simulation study is\ncarried out to verify the convergence and the variance reduction behavior in\nthe proposed Monte Carlo method. \n\n"}
{"id": "1701.05016", "contents": "Title: Mean-Reverting Portfolio Design with Budget Constraint Abstract: This paper considers the mean-reverting portfolio design problem arising from\nstatistical arbitrage in the financial markets. We first propose a general\nproblem formulation aimed at finding a portfolio of underlying component assets\nby optimizing a mean-reversion criterion characterizing the mean-reversion\nstrength, taking into consideration the variance of the portfolio and an\ninvestment budget constraint. Then several specific problems are considered\nbased on the general formulation, and efficient algorithms are proposed.\nNumerical results on both synthetic and market data show that our proposed\nmean-reverting portfolio design methods can generate consistent profits and\noutperform the traditional design methods and the benchmark methods in the\nliterature. \n\n"}
{"id": "1701.05640", "contents": "Title: Stochastic evolution equations for large portfolios of stochastic\n  volatility models Abstract: We consider a large market model of defaultable assets in which the asset\nprice processes are modelled as Heston-type stochastic volatility models with\ndefault upon hitting a lower boundary. We assume that both the asset prices and\ntheir volatilities are correlated through systemic Brownian motions. We are\ninterested in the loss process that arises in this setting and we prove the\nexistence of a large portfolio limit for the empirical measure process of this\nsystem. This limit evolves as a measure valued process and we show that it will\nhave a density given in terms of a solution to a stochastic partial\ndifferential equation of filtering type in the two-dimensional half-space, with\na Dirichlet boundary condition. We employ Malliavin calculus to establish the\nexistence of a regular density for the volatility component, and an\napproximation by models of piecewise constant volatilities combined with a\nkernel smoothing technique to obtain existence and regularity for the full\ntwo-dimensional filtering problem. We are able to establish good regularity\nproperties for solutions, however uniqueness remains an open problem. \n\n"}
{"id": "1702.01045", "contents": "Title: Invariance times Abstract: On a probability space $(\\Omega,\\mathcal{A},\\mathbb{Q})$ we consider two\nfiltrations $\\mathbb{F}\\subset \\mathbb{G}$ and a $\\mathbb{G}$ stopping time\n$\\theta$ such that the $\\mathbb{G}$ predictable processes coincide with\n$\\mathbb{F}$ predictable processes on $(0,\\theta]$. In this setup it is\nwell-known that, for any $\\mathbb{F}$ semimartingale $X$, the process\n$X^{\\theta-}$ ($X$ stopped \"right before $\\theta$\") is a $\\mathbb{G}$\nsemimartingale.Given a positive constant $T$, we call $\\theta$ an invariance\ntime if there exists a probability measure $\\mathbb{P}$ equivalent to\n$\\mathbb{Q}$ on $\\mathcal{F}\\_T$ such that, for any $(\\mathbb{F},\\mathbb{P})$\nlocal martingale $X$, $X^{\\theta-}$ is a $(\\mathbb{G},\\mathbb{Q})$ local\nmartingale. We characterize invariance times in terms of the\n$(\\mathbb{F},\\mathbb{Q})$ Az\\'ema supermartingale of $\\theta$ and we derive a\nmild and tractable invariance time sufficiency condition. We discuss invariance\ntimes in mathematical finance and BSDE applications. \n\n"}
{"id": "1702.03098", "contents": "Title: Estimation of Risk Contributions with MCMC Abstract: Determining risk contributions of unit exposures to portfolio-wide economic\ncapital is an important task in financial risk management. Computing risk\ncontributions involves difficulties caused by rare-event simulations. In this\nstudy, we address the problem of estimating risk contributions when the total\nrisk is measured by value-at-risk (VaR). Our proposed estimator of VaR\ncontributions is based on the Metropolis-Hasting (MH) algorithm, which is one\nof the most prevalent Markov chain Monte Carlo (MCMC) methods. Unlike existing\nestimators, our MH-based estimator consists of samples from conditional loss\ndistribution given a rare event of interest. This feature enhances sample\nefficiency compared with the crude Monte Carlo method. Moreover, our method has\nthe consistency and asymptotic normality, and is widely applicable to various\nrisk models having joint loss density. Our numerical experiments based on\nsimulation and real-world data demonstrate that in various risk models, even\nthose having high-dimensional (approximately 500) inhomogeneous margins, our MH\nestimator has smaller bias and mean squared error compared with existing\nestimators. \n\n"}
{"id": "1702.03232", "contents": "Title: Invariance properties in the dynamic gaussian copula model * Abstract: We prove that the default times (or any of their minima) in the dynamic\nGaussian copula model of Cr{\\'e}pey, Jeanblanc, and Wu (2013) are invariance\ntimes in the sense of Cr{\\'e}pey and Song (2017), with related invariance\nprobability measures different from the pricing measure. This reflects a\ndeparture from the immersion property, whereby the default intensities of the\nsurviving names and therefore the value of credit protection spike at default\ntimes. These properties are in line with the wrong-way risk feature of\ncounterparty risk embedded in credit derivatives, i.e. the adverse dependence\nbetween the default risk of a counterparty and an underlying credit derivative\nexposure. \n\n"}
{"id": "1702.04388", "contents": "Title: Estimating VaR in credit risk: Aggregate vs single loss distribution Abstract: Using Monte Carlo simulation to calculate the Value at Risk (VaR) as a\npossible risk measure requires adequate techniques. One of these techniques is\nthe application of a compound distribution for the aggregates in a portfolio.\nIn this paper, we consider the aggregated loss of Gamma distributed severities\nand estimate the VaR by introducing a new approach to calculate the quantile\nfunction of the Gamma distribution at high confidence levels. We then compare\nthe VaR obtained from the aggregation process with the VaR obtained from a\nsingle loss distribution where the severities are drawn first from an\nexponential and then from a truncated exponential distribution. We observe that\nthe truncated exponential distribution as a model for the severities yields\nresults closer to those obtained from the aggregation process. The deviations\ndepend strongly on the number of obligors in the portfolio, but also on the\namount of gross loss which truncates the exponential distribution. \n\n"}
{"id": "1702.06797", "contents": "Title: Spitzer Observations of Large Amplitude Variables in the LMC and IC 1613 Abstract: The 3.6 and 4.5 micron characteristics of AGB variables in the LMC and IC1613\nare discussed. For C-rich Mira variables there is a very clear\nperiod-luminosity-colour relation, where the [3.6]-[4.5] colour is associated\nwith the amount of circumstellar material and correlated with the pulsation\namplitude. The [4.5] period-luminosity relation for dusty stars is\napproximately one mag brighter than for their naked counterparts with\ncomparable periods. \n\n"}
{"id": "1702.07541", "contents": "Title: New approach to initializing hydrodynamic fields and mini-jet\n  propagation in quark-gluon fluids Abstract: We propose a new approach to initialize the hydrodynamic fields such as\nenergy density distributions and four flow velocity fields in hydrodynamic\nmodeling of high-energy nuclear collisions at the collider energies. Instead of\nmatching the energy-momentum tensor or putting the initial conditions of\nquark-gluon fluids at a fixed initial time, we utilize a framework of\nrelativistic hydrodynamic equations with source terms to describe the initial\nstage. Putting the energy and momentum loss rate of the initial partons into\nthe source terms, we obtain hydrodynamic initial conditions dynamically. The\nresultant initial profile of the quark-gluon fluid looks highly bumpy as seen\nin the conventional event-by-event initial conditions. In addition, initial\nrandom flow velocity fields also are generated as a consequence of momentum\ndeposition from the initial partons. We regard the partons that survive after\nthe dynamical initialization process as the mini-jets and find sizable effects\nof both mini-jet propagation in the quark-gluon fluids and initial random\ntransverse flow on the final momentum spectra and anisotropic flow observables.\nWe perform event-by-event $(3+1)$-dimensional ideal hydrodynamic simulations\nwith this new framework that enables us to describe the hydrodynamic bulk\ncollectivity, parton energy loss, and interplay among them in a unified manner. \n\n"}
{"id": "1703.02311", "contents": "Title: Mini-symposium on automatic differentiation and its applications in the\n  financial industry Abstract: Automatic differentiation is involved for long in applied mathematics as an\nalternative to finite difference to improve the accuracy of numerical\ncomputation of derivatives. Each time a numerical minimization is involved,\nautomatic differentiation can be used. In between formal derivation and\nstandard numerical schemes, this approach is based on software solutions\napplying mechanically the chain rule to obtain an exact value for the desired\nderivative. It has a cost in memory and cpu consumption. For participants of\nfinancial markets (banks, insurances, financial intermediaries, etc), computing\nderivatives is needed to obtain the sensitivity of its exposure to well-defined\npotential market moves. It is a way to understand variations of their balance\nsheets in specific cases. Since the 2008 crisis, regulation demand to compute\nthis kind of exposure to many different case, to be sure market participants\nare aware and ready to face a wide spectrum of configurations. This paper shows\nhow automatic differentiation provides a partial answer to this recent\nexplosion of computation to perform. One part of the answer is a\nstraightforward application of Adjoint Algorithmic Differentiation (AAD), but\nit is not enough. Since financial sensitivities involves specific functions and\nmix differentiation with Monte-Carlo simulations, dedicated tools and\nassociated theoretical results are needed. We give here short introductions to\ntypical cases arising when one use AAD on financial markets. \n\n"}
{"id": "1703.03316", "contents": "Title: Converting quasiclassical states into arbitrary Fock state\n  superpositions in a superconducting cavity Abstract: We propose and experimentally demonstrate a new method to generate arbitrary\nFock-state superpositions in a superconducting quantum circuit, where a qubit\nis dispersively coupled to a microwave cavity mode without the need of\nfine-frequency tuning. Here the qubit is used to conditionally modulate the\nprobability amplitudes of the Fock state components of a coherent state to\nthose of the desired superposition state, instead of pumping photons one by one\ninto the cavity as in previous schemes. Our method does not require the\nadjustment of the qubit frequency during the cavity state preparation, and is\nmore robust to noise and accumulation of experimental errors compared to\nprevious ones. Using the method, we experimentally generate high-fidelity phase\neigenstates under various Hilbert-space dimensions and squeezed states, which\nare useful for quantum walk and high-precision measurements. \n\n"}
{"id": "1703.04640", "contents": "Title: The many-nucleon theory of nuclear collective structure and its\n  macroscopic limits: an algebraic perspective Abstract: The nuclear collective models introduced by Bohr, Mottelson and Rainwater,\ntogether with the Mayer-Jensen shell model, have provided the central framework\nfor the development of nuclear physics. This paper reviews the microscopic\nevolution of the collective models and their underlying foundations. In\nparticular, it is shown that the Bohr-Mottelson models have expressions as\nmacroscopic limits of microscopic models that have precisely-defined\nexpressions in many-nucleon quantum mechanics. Understanding collective models\nin this way is especially useful because it enables the analysis of nuclear\nproperties in terms of them to be revisited and reassessed in the light of\ntheir microscopic foundations. \n\n"}
{"id": "1703.06687", "contents": "Title: Graph-Variate Signal Analysis Abstract: Incorporating graphs in the analysis of multivariate signals is becoming a\nstandard way to understand the interdependency of activity recorded at\ndifferent sites. The new research frontier in this direction includes the\nimportant problem of how to assess dynamic changes of signal activity. We\naddress this problem in a novel way by defining the graph-variate signal\nalongside methods for its analysis. Essentially, graph-variate signal analysis\nleverages graphs of reliable connectivity information to filter instantaneous\nbivariate functions of the multivariate signal. This opens up a new and robust\napproach to analyse joint signal and network dynamics at sample resolution.\nFurthermore, our method can be formulated as instantaneous networks on which\nstandard network analysis can be implemented. When graph connectivity is\nestimated from the multivariate signal itself, the appropriate consideration of\ninstantaneous graph signal functions allows for a novel dynamic connectivity\nmeasure-- graphvariate dynamic (GVD) connectivity-- which is robust to spurious\nshort-term dependencies. Particularly, we present appropriate functions for\nthree pertinent connectivity metrics-- correlation, coherence and the phase-lag\nindex. We show that our approach can determine signals with a single correlated\ncouple against wholly uncorrelated data of up to 128 nodes in signal size (1\nout of 8128 weighted edges). GVD connectivity is also shown to be more robust\nthan i) other GSP approaches at detecting a randomly traveling spheroid on a 3D\ngrid and ii) standard dynamic connectivity in determining differences in EEG\nrestingstate and task-related activity. We also demonstrate its use in\nrevealing hidden depth correlations from geophysical gamma ray data. We expect\nthat the methods and framework presented will provide new approaches to data\nanalysis in a variety of applied settings. \n\n"}
{"id": "1703.07422", "contents": "Title: Effects of the direct light in the surface detectors (SD) of the Pierre\n  Auger Observatory and their change in time Abstract: Cosmic Rays (CR) are particles which come to the earth from Universe. Their\norigin and production mechanisms are still unknown. The Pierre Auger\nObservatory is located in Mendoza, Argentina. It is dedicated to the study of\nCR. When CR arrive to the earth's atmosphere they produce a shower of secondary\nparticles called \\textit{air shower}. The surface detector (SD) of the Pierre\nAuger Observatory consists of tanks full of pure water, where CR produce\n\\textit{Cherenkov radiation}, when going through them. This light is detected\nby three photomultiplier tubes (PMT) located on the top of each tank. Depending\nof the angle of arrival direction of the primary CR, each PMT is able to\nregister different signal than the other. The goal of this study is to look at\nthese effects of direct light on the PMT's to explore if they change in time.\nThe obtained results may give information about the physical status of the\ntanks in order to monitor the work of the SD, and to estimate possible\nsystematic effects on the measurements. The current results of this study are\nshown. \n\n"}
{"id": "1703.08161", "contents": "Title: The sinking of the El Faro: predicting real world rogue waves during\n  Hurricane Joaquin Abstract: We present a study on the prediction of rogue waves during the 1-hour sea\nstate of Hurricane Joaquin when the Merchant Vessel El Faro sank east of the\nBahamas on October 1, 2015. High-resolution hindcast of hurricane-generated sea\nstates and wave simulations are combined with novel probabilistic models to\nquantify the likelihood of rogue wave conditions. The data suggests that the El\nFaro vessel was drifting at an average speed of approximately~$2.5$~m/s prior\nto its sinking. As a result, we estimated that the probability that El Faro\nencounters a rogue wave whose crest height exceeds 14 meters while drifting\nover a time interval of 10~(50) minutes is $\\sim1/400$~$(1/130)$. The largest\nsimulated rogue wave has similar generating mechanism and characteristics of\nthe Andrea, Draupner and Killard rogue waves as the constructive interference\nof elementary waves enhanced by bound nonlinearities. \n\n"}
{"id": "1703.10183", "contents": "Title: Black holes will break up solitons and white holes may destroy them Abstract: We consider a quantum analogue of black holes and white holes using\nBose-Einstein condensates. The model is described by the nonlinear Schrodinger\nequation with a 'stream flow' potential, that induces a spatial translation to\nstanding waves. We then mainly consider the dynamics of dark solitons in a\nblack hole or white hole flow analogue and their interactions with the event\nhorizon. A reduced equation describing the position of the dark solitons was\nobtained using variational method. Through numerical computations and\ncomparisons with the analytical approximation we show that solitons can pass\nthrough black hole horizons even though they will break up into several\nsolitons after the collision. In the interaction with a white hole horizon, we\nshow that solitons either pass through the horizon or will be destroyed by it. \n\n"}
{"id": "1704.00416", "contents": "Title: Skewed target range strategy for multiperiod portfolio optimization\n  using a two-stage least squares Monte Carlo method Abstract: In this paper, we propose a novel investment strategy for portfolio\noptimization problems. The proposed strategy maximizes the expected portfolio\nvalue bounded within a targeted range, composed of a conservative lower target\nrepresenting a need for capital protection and a desired upper target\nrepresenting an investment goal. This strategy favorably shapes the entire\nprobability distribution of returns, as it simultaneously seeks a desired\nexpected return, cuts off downside risk and implicitly caps volatility and\nhigher moments. To illustrate the effectiveness of this investment strategy, we\nstudy a multiperiod portfolio optimization problem with transaction costs and\ndevelop a two-stage regression approach that improves the classical least\nsquares Monte Carlo (LSMC) algorithm when dealing with difficult payoffs, such\nas highly concave, abruptly changing or discontinuous functions. Our numerical\nresults show substantial improvements over the classical LSMC algorithm for\nboth the constant relative risk-aversion (CRRA) utility approach and the\nproposed skewed target range strategy (STRS). Our numerical results illustrate\nthe ability of the STRS to contain the portfolio value within the targeted\nrange. When compared with the CRRA utility approach, the STRS achieves a\nsimilar mean-variance efficient frontier while delivering a better downside\nrisk-return trade-off. \n\n"}
{"id": "1704.03680", "contents": "Title: Small Groebner Fans of Ideals of Points Abstract: In the context of modeling biological systems, it is of interest to generate\nideals of points with a unique reduced Groebner basis, and the first main goal\nof this paper is to identify classes of ideals in polynomial rings which share\nthis property. Moreover, we provide methodologies for constructing such ideals.\nWe then relax the condition of uniqueness. The second and most relevant topic\ndiscussed here is to consider and identify pairs of ideals with the same number\nof reduced Groebner bases, that is, with the same cardinality of their\nassociated Groebner fan. \n\n"}
{"id": "1704.04365", "contents": "Title: Limited Feedback in Single and Multi-user MIMO Systems with Finite-Bit\n  ADCs Abstract: Communication systems with low-resolution analog-to-digital-converters (ADCs)\ncan exploit channel state information at the transmitter and receiver. This\npaper presents codebook designs and performance analyses for limited feedback\nMIMO systems with finite-bit ADCs. A point-to-point single-user channel is\nfirstly considered. When the received signal is sliced by 1-bit ADCs, the\nabsolute phase at the receiver is important to align the phase of the received\nsignals. A new codebook design for beamforming, which separately quantizes the\nchannel direction and the residual phase, is therefore proposed. For the\nmulti-bit case where the optimal transmission method is unknown, suboptimal\nGaussian signaling and eigenvector beamforming is assumed to obtain a lower\nbound of the achievable rate. It is found that to limit the rate loss, more\nfeedback bits are needed in the medium SNR regime than the low and high SNR\nregimes, which is quite different from the conventional infinite-bit ADC case.\nSecond, a multi-user system where a multiple-antenna transmitter sends signals\nto multiple single-antenna receivers with finite-bit ADCs is considered. Based\non the derived performance loss due to finite-bit ADCs and finite-bit CSI\nfeedback, the number of bits per feedback should increase linearly with the ADC\nresolution in order to restrict the rate loss. \n\n"}
{"id": "1704.05308", "contents": "Title: High-order compact finite difference scheme for option pricing in\n  stochastic volatility jump models Abstract: We derive a new high-order compact finite difference scheme for option\npricing in stochastic volatility jump models, e.g. in Bates model. In such\nmodels the option price is determined as the solution of a partial\nintegro-differential equation. The scheme is fourth order accurate in space and\nsecond order accurate in time. Numerical experiments for the European option\npricing problem are presented. We validate the stability of the scheme\nnumerically and compare its performance to standard finite difference and\nfinite element methods. The new scheme outperforms a standard discretisation\nbased on a second-order central finite difference approximation in all our\nexperiments. At the same time, it is very efficient, requiring only one initial\n$LU$-factorisation of a sparse matrix to perform the option price valuation.\nCompared to finite element approaches, it is very parsimonious in terms of\nmemory requirements and computational effort, since it achieves high-order\nconvergence without requiring additional unknowns, unlike finite element\nmethods with higher polynomial order basis functions. The new high-order\ncompact scheme can also be useful to upgrade existing implementations based on\nstandard finite differences in a straightforward manner to obtain a highly\nefficient option pricing code. \n\n"}
{"id": "1704.06529", "contents": "Title: Accessing the topological susceptibility via the Gribov horizon Abstract: The topological susceptibility, $\\chi^4$, following the work of Witten and\nVeneziano, plays a key role in identifying the relative magnitude of the\n$\\eta^{\\prime}$ mass, the so-called $U(1)_{A}$ problem. A nonzero $\\chi^4$ is\ncaused by the Veneziano ghost, the occurrence of an unphysical massless pole in\nthe correlation function of the topological current. In a recent paper\n(Phys.Rev.Lett.114 (2015) 24, 242001), an explicit relationship between this\nVeneziano ghost and color confinement was proposed, by connecting the dynamics\nof the Veneziano ghost, and thus the topological susceptibility, with Gribov\ncopies. However, the analysis is incompatible with BRST symmetry (Phys.Rev.D 93\n(2016) no.8, 085010). In this paper, we investigate the topological\nsusceptibility, $\\chi^4$, in SU(3) and SU(2) Euclidean Yang-Mills theory using\nan appropriate Pad\\'e approximation tool and a non-perturbative gluon\npropagator, within a BRST invariant framework and by taking into account Gribov\ncopies in a general linear covariant gauge. \n\n"}
{"id": "1704.07321", "contents": "Title: Strong order 1/2 convergence of full truncation Euler approximations to\n  the Cox-Ingersoll-Ross process Abstract: We study convergence properties of the full truncation Euler scheme for the\nCox-Ingersoll-Ross process in the regime where the boundary point zero is\ninaccessible. Under some conditions on the model parameters (precisely, when\nthe Feller ratio is greater than three), we establish the strong order 1/2\nconvergence in $L^{p}$ of the scheme to the exact solution. This is consistent\nwith the optimal rate of strong convergence for Euler approximations of\nstochastic differential equations with globally Lipschitz coefficients, despite\nthe fact that the diffusion coefficient in the Cox-Ingersoll-Ross model is not\nLipschitz. \n\n"}
{"id": "1704.08243", "contents": "Title: C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0\n  Dataset Abstract: Visual Question Answering (VQA) has received a lot of attention over the past\ncouple of years. A number of deep learning models have been proposed for this\ntask. However, it has been shown that these models are heavily driven by\nsuperficial correlations in the training data and lack compositionality -- the\nability to answer questions about unseen compositions of seen concepts. This\ncompositionality is desirable and central to intelligence. In this paper, we\npropose a new setting for Visual Question Answering where the test\nquestion-answer pairs are compositionally novel compared to training\nquestion-answer pairs. To facilitate developing models under this setting, we\npresent a new compositional split of the VQA v1.0 dataset, which we call\nCompositional VQA (C-VQA). We analyze the distribution of questions and answers\nin the C-VQA splits. Finally, we evaluate several existing VQA models under\nthis new setting and show that the performances of these models degrade by a\nsignificant amount compared to the original VQA setting. \n\n"}
{"id": "1704.08488", "contents": "Title: Optimal client recommendation for market makers in illiquid financial\n  products Abstract: The process of liquidity provision in financial markets can result in\nprolonged exposure to illiquid instruments for market makers. In this case,\nwhere a proprietary position is not desired, pro-actively targeting the right\nclient who is likely to be interested can be an effective means to offset this\nposition, rather than relying on commensurate interest arising through natural\ndemand. In this paper, we consider the inference of a client profile for the\npurpose of corporate bond recommendation, based on typical recorded information\navailable to the market maker. Given a historical record of corporate bond\ntransactions and bond meta-data, we use a topic-modelling analogy to develop a\nprobabilistic technique for compiling a curated list of client recommendations\nfor a particular bond that needs to be traded, ranked by probability of\ninterest. We show that a model based on Latent Dirichlet Allocation offers\npromising performance to deliver relevant recommendations for sales traders. \n\n"}
{"id": "1705.00558", "contents": "Title: Implied Stopping Rules for American Basket Options from Markovian\n  Projection Abstract: This work addresses the problem of pricing American basket options in a\nmultivariate setting, which includes among others, the Bachelier and the\nBlack-Scholes models. In high dimensions, nonlinear partial differential\nequation methods for solving the problem become prohibitively costly due to the\ncurse of dimensionality. Instead, this work proposes to use a stopping rule\nthat depends on the dynamics of a low-dimensional Markovian projection of the\ngiven basket of assets. It is shown that the ability to approximate the\noriginal value function by a lower-dimensional approximation is a feature of\nthe dynamics of the system and is unaffected by the path-dependent nature of\nthe American basket option. Assuming that we know the density of the forward\nprocess and using the Laplace approximation, we first efficiently evaluate the\ndiffusion coefficient corresponding to the low-dimensional Markovian projection\nof the basket. Then, we approximate the optimal early-exercise boundary of the\noption by solving a Hamilton-Jacobi-Bellman partial differential equation in\nthe projected, low-dimensional space. The resulting near-optimal early-exercise\nboundary is used to produce an exercise strategy for the high-dimensional\noption, thereby providing a lower bound for the price of the American basket\noption. A corresponding upper bound is also provided. These bounds allow to\nassess the accuracy of the proposed pricing method. Indeed, our approximate\nearly-exercise strategy provides a straightforward lower bound for the American\nbasket option price. Following a duality argument due to Rogers, we derive a\ncorresponding upper bound solving only the low-dimensional optimal control\nproblem. Numerically, we show the feasibility of the method using baskets with\ndimensions up to fifty. In these examples, the resulting option price relative\nerrors are only of the order of few percent. \n\n"}
{"id": "1705.00864", "contents": "Title: Towards the Exact Simulation Using Hyperbolic Brownian Motion Abstract: In the present paper, an expansion of the transition density of Hyperbolic\nBrownian motion with drift is given, which is potentially useful for pricing\nand hedging of options under stochastic volatility models. We work on a\ncondition on the drift which dramatically simplifies the proof. \n\n"}
{"id": "1705.03666", "contents": "Title: Hybrid PDE solver for data-driven problems and modern branching Abstract: The numerical solution of large-scale PDEs, such as those occurring in\ndata-driven applications, unavoidably require powerful parallel computers and\ntailored parallel algorithms to make the best possible use of them. In fact,\nconsiderations about the parallelization and scalability of realistic problems\nare often critical enough to warrant acknowledgement in the modelling phase.\nThe purpose of this paper is to spread awareness of the Probabilistic Domain\nDecomposition (PDD) method, a fresh approach to the parallelization of PDEs\nwith excellent scalability properties. The idea exploits the stochastic\nrepresentation of the PDE and its approximation via Monte Carlo in combination\nwith deterministic high-performance PDE solvers. We describe the ingredients of\nPDD and its applicability in the scope of data science. In particular, we\nhighlight recent advances in stochastic representations for nonlinear PDEs\nusing branching diffusions, which have significantly broadened the scope of\nPDD.\n  We envision this work as a dictionary giving large-scale PDE practitioners\nreferences on the very latest algorithms and techniques of a non-standard, yet\nhighly parallelizable, methodology at the interface of deterministic and\nprobabilistic numerical methods. We close this work with an invitation to the\nfully nonlinear case and open research questions. \n\n"}
{"id": "1705.03787", "contents": "Title: A note on the impact of management fees on the pricing of variable\n  annuity guarantees Abstract: Variable annuities, as a class of retirement income products, allow equity\nmarket exposure for a policyholder's retirement fund with electable additional\nguarantees to limit the downside risk of the market. Management fees and\nguarantee insurance fees are charged respectively for the market exposure and\nfor the protection from the downside risk. We investigate the impact of\nmanagement fees on the pricing of variable annuity guarantees under optimal\nwithdrawal strategies. Two optimal strategies, from policyholder's and from\ninsurer's perspectives, are respectively formulated and the corresponding\npricing problems are solved using dynamic programming. Our results show that\nwhen management fees are present, the two strategies can deviate significantly\nfrom each other, leading to a substantial difference of the guarantee insurance\nfees. This provides a possible explanation of lower guarantee insurance fees\nobserved in the market. Numerical experiments are conducted to illustrate our\nresults. \n\n"}
{"id": "1705.05668", "contents": "Title: Transmitter Beam Selection in Millimeter-wave MIMO with In-Band\n  Position-Aiding Abstract: Emerging wireless communication systems will be characterized by a tight\ncoupling between communication and positioning. This is particularly apparent\nin millimeter-wave (mm-wave) communications, where devices use a large number\nof antennas and the propagation is well described by geometric channel models.\nFor mm-wave communications, initial access, consisting in the beam selection\nand alignment of two devices, is challenging and time-consuming in the absence\nof location information. Conversely, accurate positioning relies on\nhigh-quality communication links with proper beam alignment. This paper studies\nthis interaction and proposes a new position-aided beam selection protocol,\nwhich considers the problem of joint communication and positioning in scenarios\nwith direct line-of-sight and scattering. Simulation results show significant\nreductions in latency with respect to a standard protocol. \n\n"}
{"id": "1705.05808", "contents": "Title: Deuteron transverse densities in holographic QCD Abstract: We investigate the transverse charge density in the longitudinally as well as\ntransversely polarized deuteron using the recent empirical description of the\ndeuteron electromagnetic form factors in the framework of holographic QCD. The\npredictions of the holographic QCD are compared with the results of a standard\nphenomenological parameterization. In addition, we evaluate GPDs and the\ngravitational form factors for the deuteron. The longitudinal momentum\ndensities are also investigated in the transverse plane. \n\n"}
{"id": "1705.06755", "contents": "Title: A General Model for Robust Tensor Factorization with Unknown Noise Abstract: Because of the limitations of matrix factorization, such as losing spatial\nstructure information, the concept of low-rank tensor factorization (LRTF) has\nbeen applied for the recovery of a low dimensional subspace from high\ndimensional visual data. The low-rank tensor recovery is generally achieved by\nminimizing the loss function between the observed data and the factorization\nrepresentation. The loss function is designed in various forms under different\nnoise distribution assumptions, like $L_1$ norm for Laplacian distribution and\n$L_2$ norm for Gaussian distribution. However, they often fail to tackle the\nreal data which are corrupted by the noise with unknown distribution. In this\npaper, we propose a generalized weighted low-rank tensor factorization method\n(GWLRTF) integrated with the idea of noise modelling. This procedure treats the\ntarget data as high-order tensor directly and models the noise by a Mixture of\nGaussians, which is called MoG GWLRTF. The parameters in the model are\nestimated under the EM framework and through a new developed algorithm of\nweighted low-rank tensor factorization. We provide two versions of the\nalgorithm with different tensor factorization operations, i.e., CP\nfactorization and Tucker factorization. Extensive experiments indicate the\nrespective advantages of this two versions in different applications and also\ndemonstrate the effectiveness of MoG GWLRTF compared with other competing\nmethods. \n\n"}
{"id": "1706.00263", "contents": "Title: Fast calibration of the Libor Market Model with Stochastic Volatility\n  and Displaced Diffusion Abstract: This paper demonstrates the efficiency of using Edgeworth and Gram-Charlier\nexpansions in the calibration of the Libor Market Model with Stochastic\nVolatility and Displaced Diffusion (DD-SV-LMM). Our approach brings together\ntwo research areas; first, the results regarding the SV-LMM since the work of\nWu and Zhang (2006), especially on the moment generating function, and second\nthe approximation of density distributions based on Edgeworth or Gram-Charlier\nexpansions. By exploring the analytical tractability of moments up to fourth\norder, we are able to perform an adjustment of the reference Bachelier model\nwith normal volatilities for skewness and kurtosis, and as a by-product to\nderive a smile formula relating the volatility to the moneyness with\ninterpretable parameters. As a main conclusion, our numerical results show a\n98% reduction in computational time for the DD-SV-LMM calibration process\ncompared to the classical numerical integration method developed by Heston\n(1993). \n\n"}
{"id": "1706.02936", "contents": "Title: Principal-Agent Problem with Common Agency without Communication Abstract: In this paper, we consider a problem of contract theory in which several\nPrincipals hire a common Agent and we study the model in the continuous time\nsetting. We show that optimal contracts should satisfy some equilibrium\nconditions and we reduce the optimisation problem of the Principals to a system\nof coupled Hamilton-Jacobi-Bellman (HJB) equations. We provide conditions\nensuring that for risk-neutral Principals, the system of coupled HJB equations\nadmits a solution. Further, we apply our study in a more specific\nlinear-quadratic model where two interacting Principals hire one common Agent.\nIn this continuous time model, we extend the result of Bernheim and Whinston\n(1986) in which the authors compare the optimal effort of the Agent in a\nnon-cooperative Principals model and that in the aggregate model, by showing\nthat these two optimisations coincide only in the first best case. We also\nstudy the sensibility of the optimal effort and the optimal remunerations with\nrespect to appetence parameters and the correlation between the projects. \n\n"}
{"id": "1706.06012", "contents": "Title: Radiopurity assessment of the energy readout for the NEXT double beta\n  decay experiment Abstract: The Neutrino Experiment with a Xenon Time-Projection Chamber (NEXT)\nexperiment intends to investigate the neutrinoless double beta decay of 136Xe,\nand therefore requires a severe suppression of potential backgrounds. An\nextensive material screening and selection process was undertaken to quantify\nthe radioactivity of the materials used in the experiment. Separate energy and\ntracking readout planes using different sensors allow us to combine the\nmeasurement of the topological signature of the event for background\ndiscrimination with the energy resolution optimization. The design of radiopure\nreadout planes, in direct contact with the gas detector medium, was especially\nchallenging since the required components typically have activities too large\nfor experiments demanding ultra-low background conditions. After studying the\ntracking plane, here the radiopurity control of the energy plane is presented,\nmainly based on gamma-ray spectroscopy using ultra-low background germanium\ndetectors at the Laboratorio Subterr\\'aneo de Canfranc (Spain). All the\navailable units of the selected model of photomultiplier have been screened\ntogether with most of the components for the bases, enclosures and windows.\nAccording to these results for the activity of the relevant radioisotopes, the\nselected components of the energy plane would give a contribution to the\noverall background level in the region of interest of at most 2.4 x 10-4 counts\nkeV-1 kg-1 y-1, satisfying the sensitivity requirements of the NEXT experiment. \n\n"}
{"id": "1706.06709", "contents": "Title: Singular Fourier-Pad\\'e Series Expansion of European Option Prices Abstract: We apply a new numerical method, the singular Fourier-Pad\\'e (SFP) method\ninvented by Driscoll and Fornberg (2001, 2011), to price European-type options\nin L\\'evy and affine processes. The motivation behind this application is to\nreduce the inefficiency of current Fourier techniques when they are used to\napproximate piecewise continuous (non-smooth) probability density functions.\nWhen techniques such as fast Fourier transforms and Fourier series are applied\nto price and hedge options with non-smooth probability density functions, they\ncause the Gibbs phenomenon, accordingly, the techniques converge slowly for\ndensity functions with jumps in value or derivatives. This seriously adversely\naffects the efficiency and accuracy of these techniques. In this paper, we\nderive pricing formulae and their option Greeks using the SFP method to resolve\nthe Gibbs phenomenon and restore the global spectral convergence rate.\nMoreover, we show that our method requires a small number of terms to yield\nfast error convergence, and it is able to accurately price any European-type\noption deep in/out of the money and with very long/short maturities.\nFurthermore, we conduct an error-bound analysis of the SFP method in option\npricing. This new method performs favourably in numerical experiments compared\nwith existing techniques. \n\n"}
{"id": "1706.07375", "contents": "Title: Strong convergence rates for Euler approximations to a class of\n  stochastic path-dependent volatility models Abstract: We consider a class of stochastic path-dependent volatility models where the\nstochastic volatility, whose square follows the Cox-Ingersoll-Ross model, is\nmultiplied by a (leverage) function of the spot price, its running maximum, and\ntime. We propose a Monte Carlo simulation scheme which combines a log-Euler\nscheme for the spot process with the full truncation Euler scheme or the\nbackward Euler-Maruyama scheme for the squared stochastic volatility component.\nUnder some mild regularity assumptions and a condition on the Feller ratio, we\nestablish the strong convergence with order 1/2 (up to a logarithmic factor) of\nthe approximation process up to a critical time. The model studied in this\npaper contains as special cases Heston-type stochastic-local volatility models,\nthe state-of-the-art in derivative pricing, and a relatively new class of\npath-dependent volatility models. The present paper is the first to prove the\nconvergence of the popular Euler schemes with a positive rate, which is\nmoreover consistent with that for Lipschitz coefficients and hence optimal. \n\n"}
{"id": "1706.10059", "contents": "Title: A Deep Reinforcement Learning Framework for the Financial Portfolio\n  Management Problem Abstract: Financial portfolio management is the process of constant redistribution of a\nfund into different financial products. This paper presents a\nfinancial-model-free Reinforcement Learning framework to provide a deep machine\nlearning solution to the portfolio management problem. The framework consists\nof the Ensemble of Identical Independent Evaluators (EIIE) topology, a\nPortfolio-Vector Memory (PVM), an Online Stochastic Batch Learning (OSBL)\nscheme, and a fully exploiting and explicit reward function. This framework is\nrealized in three instants in this work with a Convolutional Neural Network\n(CNN), a basic Recurrent Neural Network (RNN), and a Long Short-Term Memory\n(LSTM). They are, along with a number of recently reviewed or published\nportfolio-selection strategies, examined in three back-test experiments with a\ntrading period of 30 minutes in a cryptocurrency market. Cryptocurrencies are\nelectronic and decentralized alternatives to government-issued money, with\nBitcoin as the best-known example of a cryptocurrency. All three instances of\nthe framework monopolize the top three positions in all experiments,\noutdistancing other compared trading algorithms. Although with a high\ncommission rate of 0.25% in the backtests, the framework is able to achieve at\nleast 4-fold returns in 50 days. \n\n"}
{"id": "1706.10101", "contents": "Title: The Pad\\'e interpolation method applied to additive difference\n  Painlev\\'e equations Abstract: We study Pad\\'e interpolation problems on an additive grid, related to\nadditive difference ($d$-) Painlev\\'e equations of type $E_7^{(1)}$,\n$E_6^{(1)}$, $D_4^{(1)}$ and $A_3^{(1)}$. By choosing suitable Pad\\'e problems,\nwe can derive time evolution equations, scalar Lax pairs of contiguous type and\ndeterminant formulae of special solutions given in terms of hypergeometric\nfunctions, for the corresponding $d$-Painlev\\'e equations. \n\n"}
{"id": "1707.00356", "contents": "Title: Analytical and numerical results for American style of perpetual put\n  options through transformation into nonlinear stationary Black-Scholes\n  equations Abstract: We analyze and calculate the early exercise boundary for a class of\nstationary generalized Black-Scholes equations in which the volatility function\ndepends on the second derivative of the option price itself. A motivation for\nstudying the nonlinear Black Scholes equation with a nonlinear volatility\narises from option pricing models including, e.g., non-zero transaction costs,\ninvestors preferences, feedback and illiquid markets effects and risk from\nunprotected portfolio. We present a method how to transform the problem of\nAmerican style of perpetual put options into a solution of an ordinary\ndifferential equation and implicit equation for the free boundary position. We\nfinally present results of numerical approximation of the early exercise\nboundary, option price and their dependence on model parameters. \n\n"}
{"id": "1707.01789", "contents": "Title: Damping optimization of parameter dependent mechanical systems by\n  rational interpolation Abstract: We consider an optimization problem related to semi-active damping of\nvibrating systems. The main problem is to determine the best damping matrix\nable to minimize influence of the input on the output of the system. We use a\nminimization criteria based on the $\\mathcal{H}_2$ system norm.\n  The objective function is non-convex and the associated optimization problem\ntypically requires a large number of objective function evaluations. We propose\nan optimization approach that calculates `interpolatory' reduced order models,\nallowing for significant acceleration of the optimization process.\n  In our approach, we use parametric model reduction (PMOR) based on the\nIterative Rational Krylov Algorithm, which ensures good approximations relative\nto the $\\mathcal{H}_2$ system norm, aligning well with the underlying damping\ndesign objectives. For the parameter sampling that occurs within each PMOR\ncycle, we consider approaches with predetermined sampling and approaches using\nadaptive sampling, and each of these approaches may be combined with three\npossible strategies for internal reduction. In order to preserve important\nsystem properties, we maintain second-order structure, which through the use of\nmodal coordinates, allows for very efficient implementation.\n  The methodology proposed here provides a significant acceleration of the\noptimization process; the gain in efficiency is illustrated in numerical\nexperiments. \n\n"}
{"id": "1707.02843", "contents": "Title: Holographic Butterfly Effect and Diffusion in Quantum Critical Region Abstract: We investigate the butterfly effect and charge diffusion near the quantum\nphase transition in holographic approach. We argue that their criticality is\ncontrolled by the holographic scaling geometry with deformations induced by a\nrelevant operator at finite temperature. Specifically, in the quantum critical\nregion controlled by a single fixed point, the butterfly velocity decreases\nwhen deviating from the critical point. While, in the non-critical region, the\nbehavior of the butterfly velocity depends on the specific phase at low\ntemperature. Moreover, in the holographic Berezinskii-Kosterlitz-Thouless\ntransition, the universal behavior of the butterfly velocity is absent.\nFinally, the tendency of our holographic results matches with the numerical\nresults of Bose-Hubbard model. A comparison between our result and that in the\n$O(N)$ nonlinear sigma model is also given. \n\n"}
{"id": "1707.04380", "contents": "Title: On Minimax Optimality of Sparse Bayes Predictive Density Estimates Abstract: We study predictive density estimation under Kullback-Leibler loss in\n$\\ell_0$-sparse Gaussian sequence models. We propose proper Bayes predictive\ndensity estimates and establish asymptotic minimaxity in sparse models. A\nsurprise is the existence of a phase transition in the future-to-past variance\nratio $r$. For $r < r_0 = (\\surd 5 - 1)/4$, the natural discrete prior ceases\nto be asymptotically optimal. Instead, for subcritical $r$, a `bi-grid' prior\nwith a central region of reduced grid spacing recovers asymptotic minimaxity.\nThis phenomenon seems to have no analog in the otherwise parallel theory of\npoint estimation of a multivariate normal mean under quadratic loss. For\nspike-and-slab priors to have any prospect of minimaxity, we show that the\nsparse parameter space needs also to be magnitude constrained. Within a\nsubstantial range of magnitudes, spike-and-slab priors can attain asymptotic\nminimaxity. \n\n"}
{"id": "1707.05234", "contents": "Title: Discrete-type approximations for non-Markovian optimal stopping\n  problems: Part I Abstract: In this paper, we present a discrete-type approximation scheme to solve\ncontinuous-time optimal stopping problems based on fully non-Markovian\ncontinuous processes adapted to the Brownian motion filtration. The\napproximations satisfy suitable variational inequalities which allow us to\nconstruct $\\epsilon$-optimal stopping times and optimal values in full\ngenerality. Explicit rates of convergence are presented for optimal values\nbased on reward functionals of path-dependent SDEs driven by fractional\nBrownian motion. In particular, the methodology allows us to design concrete\nMonte-Carlo schemes for non-Markovian optimal stopping time problems as\ndemonstrated in the companion paper by Bezerra, Ohashi and Russo. \n\n"}
{"id": "1707.05250", "contents": "Title: Discrete-type approximations for non-Markovian optimal stopping\n  problems: Part II Abstract: In this paper, we present a Longstaff-Schwartz-type algorithm for optimal\nstopping time problems based on the Brownian motion filtration. The algorithm\nis based on Le\\~ao, Ohashi and Russo and, in contrast to previous works, our\nmethodology applies to optimal stopping problems for fully non-Markovian and\nnon-semimartingale state processes such as functionals of path-dependent\nstochastic differential equations and fractional Brownian motions. Based on\nstatistical learning theory techniques, we provide overall error estimates in\nterms of concrete approximation architecture spaces with finite\nVapnik-Chervonenkis dimension. Analytical properties of continuation values for\npath-dependent SDEs and concrete linear architecture approximating spaces are\nalso discussed. \n\n"}
{"id": "1707.06876", "contents": "Title: Evolving Morphology of the Large-Scale Relativistic Jets from XTE\n  J1550-564 Abstract: We present an in-depth study of the large-scale, western jet of the\nmicroquasar XTE J1550-564, based on X-ray and radio observations performed in\n2002-2003. The jet is spatially resolved in both observing windows. The X-ray\njet is expanding in time along the axis of the jet's propagation: we observe\nthe formation of a tail (~2.25\"), which appears to extend backwards with an\napparent velocity ~-0.10c. The origin of this feature is discussed in the\nframework of scenarios of energy dissipation. A single power-law adequately\ndescribes the broadband spectra, supporting a synchrotron origin of the X-ray\nemission. However, a spectral break at ~10^{15} Hz is necessary in coincidence\nwith a re-flare at 8.64 GHz in September 2002. This finding may be indicative\nof emission from newly accelerated low-energy particles. The first detection of\nthe jet is in February 2001 (F_{8.64GHz}=0.25+/-0.09 mJy) in the flux rising\nphase. A phase of stable emission is followed by a rapid decay\n(t_{decay}=167+/-5 days). The decay at radio frequencies is significantly\nshorter than in X-rays (t_{decay}=338+/-14 days). We detected a high fraction\n(up to ~9%) of linearly polarized radiation at 4.8 GHz and 8.6 GHz. The\norientation of the electric vector is consistent with the picture of a\nshock-compressed magnetic field, and there are hints of variations on\nmonth-timescales, possibly connected with the evolution of the jet structure. \n\n"}
{"id": "1707.06979", "contents": "Title: Superconvergence in a DPG method for an ultra-weak formulation Abstract: In this work we study a DPG method for an ultra-weak variational formulation\nof a reaction-diffusion problem. We improve existing a priori convergence\nresults by sharpening an approximation result for the numerical flux. By\nduality arguments we show that higher convergence rates for the scalar field\nvariable are obtained if the polynomial order of the corresponding\napproximation space is increased by one. Furthermore, we introduce a simple\nelementwise postprocessing of the solution and prove superconvergence.\nNumerical experiments indicate that the obtained results are valid beyond the\nunderlying model problem. \n\n"}
{"id": "1707.07035", "contents": "Title: Coverage in Downlink Heterogeneous mmWave Cellular Networks with\n  User-Centric Small Cell Deployment Abstract: A K-tier heterogeneous downlink millimeter wave (mmWave) cellular network\nwith user-centric small cell deployments is studied in this paper. In\nparticular, we consider a heterogeneous network model with user equipments\n(UEs) being distributed according to a Poisson Cluster Process (PCP).\nSpecifically, we address two cluster processes, namely (i) Thomas cluster\nprocess, where the UEs are clustered around the base stations (BSs) and the\ndistances between UEs and the BS are modeled as Gaussian distributed, and (ii)\nMatern cluster process, where the UEs are scattered according to a uniform\ndistribution. In addition, distinguishing features of mmWave communications\nincluding directional beamforming and a sophisticated path loss model\nincorporating both line-of-sight (LOS) and non-line-of-sight (NLOS)\ntransmissions, are taken into account. Initially, the complementary cumulative\ndistribution function (CCDF) and probability density function (PDF) of path\nloss are provided. Subsequently, using tools from stochastic geometry, we\nderive a general expression for the signal-to-interference-plus-noise ratio\n(SINR) coverage probability. Our results demonstrate that coverage probability\ncan be improved by decreasing the size of UE clusters around BSs, decreasing\nthe beamwidth of the main lobe, or increasing the main lobe directivity gain.\nMoreover, interference has noticeable influence on the coverage performance of\nour model. We also show that better coverage performance is achieved in the\npresence of clustered users compared to the case in which the users are\ndistributed according to a Poisson Point Process (PPP). \n\n"}
{"id": "1708.01789", "contents": "Title: Planck stars: new sources in radio and gamma astronomy? Abstract: A new phenomenon, recently studied in theoretical physics, may have\nconsiderable interest for astronomers: the explosive decay of old primordial\nblack holes via quantum tunnelling. Models predict radio and gamma bursts with\na characteristic frequency-distance relation making them identifiable. Their\ndetection would be of major theoretical importance. \n\n"}
{"id": "1708.01823", "contents": "Title: High-fidelity state transfer through long-range correlated disordered\n  quantum channels Abstract: We study quantum-state transfer in $XX$ spin-$1/2$ chains where both\ncommunicating spins are weakly coupled to a channel featuring disordered\non-site magnetic fields. Fluctuations are modelled by long-range correlated\nsequences with self-similar profile obeying a power-law spectrum. We show that\nthe channel is able to perform an almost perfect quantum-state transfer in most\nof the samples even in the presence of significant amounts of disorder provided\nthe degree of those correlations is strong enough. In that case, we also show\nthat the lack of mirror symmetry does not affect much the likelihood of having\nhigh-quality outcomes. Our results advance a further step in designing robust\ndevices for quantum communication protocols. \n\n"}
{"id": "1708.02563", "contents": "Title: Turbocharging Monte Carlo pricing for the rough Bergomi model Abstract: The rough Bergomi model, introduced by Bayer, Friz and Gatheral [Quant.\nFinance 16(6), 887-904, 2016], is one of the recent rough volatility models\nthat are consistent with the stylised fact of implied volatility surfaces being\nessentially time-invariant, and are able to capture the term structure of skew\nobserved in equity markets. In the absence of analytical European option\npricing methods for the model, we focus on reducing the runtime-adjusted\nvariance of Monte Carlo implied volatilities, thereby contributing to the\nmodel's calibration by simulation. We employ a novel composition of variance\nreduction methods, immediately applicable to any conditionally log-normal\nstochastic volatility model. Assuming one targets implied volatility estimates\nwith a given degree of confidence, thus calibration RMSE, the results we\ndemonstrate equate to significant runtime reductions - roughly 20 times on\naverage, across different correlation regimes. \n\n"}
{"id": "1708.06586", "contents": "Title: Dynamic correlations at different time-scales with Empirical Mode\n  Decomposition Abstract: The Empirical Mode Decomposition (EMD) provides a tool to characterize time\nseries in terms of its implicit components oscillating at different\ntime-scales. We apply this decomposition to intraday time series of the\nfollowing three financial indices: the S\\&P 500 (USA), the IPC (Mexico) and the\nVIX (volatility index USA), obtaining time-varying multidimensional\ncross-correlations at different time-scales. The correlations computed over a\nrolling window are compared across the three indices, across the components at\ndifferent time-scales, at different lags and over time. We uncover a rich\nheterogeneity of interactions which depends on the time-scale and has important\nled-lag relations which can have practical use for portfolio management, risk\nestimation and investments. \n\n"}
{"id": "1708.07463", "contents": "Title: Network Slicing for Service-Oriented Networks Under Resource Constraints Abstract: To support multiple on-demand services over fixed communication networks,\nnetwork operators must allow flexible customization and fast provision of their\nnetwork resources. One effective approach to this end is network\nvirtualization, whereby each service is mapped to a virtual subnetwork\nproviding dedicated on-demand support to network users. In practice, each\nservice consists of a prespecified sequence of functions, called a service\nfunction chain (SFC), while each service function in a SFC can only be provided\nby some given network nodes. Thus, to support a given service, we must select\nnetwork function nodes according to the SFC and determine the routing strategy\nthrough the function nodes in a specified order. A crucial network slicing\nproblem that needs to be addressed is how to optimally localize the service\nfunctions in a physical network as specified by the SFCs, subject to link and\nnode capacity constraints. In this paper, we formulate the network slicing\nproblem as a mixed binary linear program and establish its strong NP-hardness.\nFurthermore, we propose efficient penalty successive upper bound minimization\n(PSUM) and PSUM-R(ounding) algorithms, and two heuristic algorithms to solve\nthe problem. Simulation results are shown to demonstrate the effectiveness of\nthe proposed algorithms. \n\n"}
{"id": "1708.07469", "contents": "Title: DGM: A deep learning algorithm for solving partial differential\n  equations Abstract: High-dimensional PDEs have been a longstanding computational challenge. We\npropose to solve high-dimensional PDEs by approximating the solution with a\ndeep neural network which is trained to satisfy the differential operator,\ninitial condition, and boundary conditions. Our algorithm is meshfree, which is\nkey since meshes become infeasible in higher dimensions. Instead of forming a\nmesh, the neural network is trained on batches of randomly sampled time and\nspace points. The algorithm is tested on a class of high-dimensional free\nboundary PDEs, which we are able to accurately solve in up to $200$ dimensions.\nThe algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman PDE\nand Burgers' equation. The deep learning algorithm approximates the general\nsolution to the Burgers' equation for a continuum of different boundary\nconditions and physical conditions (which can be viewed as a high-dimensional\nspace). We call the algorithm a \"Deep Galerkin Method (DGM)\" since it is\nsimilar in spirit to Galerkin methods, with the solution approximated by a\nneural network instead of a linear combination of basis functions. In addition,\nwe prove a theorem regarding the approximation power of neural networks for a\nclass of quasilinear parabolic PDEs. \n\n"}
{"id": "1708.08307", "contents": "Title: Studying superconformal symmetry enhancement through indices Abstract: In this note we classify the necessary and the sufficient conditions that an\nindex of a superconformal theory in $3\\leq d \\leq 6$ must obey for the theory\nto have enhanced supersymmetry. We do that by noting that the index\ndistinguishes a superconformal multiplet contribution to the index only up to a\ncertain equivalence class it lies in. We classify the equivalence classes in\n$d=4$ and build a correspondence between ${\\cal N} = 1$ and ${\\cal N}>1$\nequivalence classes. Using this correspondence, we find a set of necessary\nconditions and a sufficient condition on the $d=4$ ${\\cal N} = 1$ index for the\ntheory to have ${\\cal N}>1$ SUSY. We also find a necessary and sufficient\ncondition on a $d=4$ ${\\cal N}>1$ index to correspond to a theory with ${\\cal\nN} > 2$. We then use our results to study some of the $d=4$ theories described\nby Agarwal, Maruyoshi and Song, and find that the theories in question have\nonly ${\\cal N} = 1$ SUSY despite having rational central charges. In $d=3$ we\nclassify the equivalence classes, and build a correspondence between ${\\cal N}\n= 2$ and ${\\cal N}>2$ equivalence classes. Using this correspondence, we\nclassify all necessary or sufficient conditions on an ${\\cal N}=1-3$\nsuperconformal index in $d=3$ to correspond to a theory with higher SUSY, and\nfind a necessary and sufficient condition on an ${\\cal N} = 4$ index to\ncorrespond to an ${\\cal N} > 4$ theory. Finally, in $d=6$ we find a necessary\nand sufficient condition for an ${\\cal N} = 1$ index to correspond to an ${\\cal\nN}=2$ theory. \n\n"}
{"id": "1708.09201", "contents": "Title: Theoretical aspects of the study of top quark properties Abstract: We review some recent theoretical progresses towards the determination of the\ntop-quark couplings beyond the standard model. We briefly introduce the global\neffective field theory approach to the top-quark production and decay\nprocesses, and discuss the most useful observables to constrain the deviations.\nRecent improvements with a focus on QCD corrections and corresponding tools are\nalso discussed. \n\n"}
{"id": "1709.01412", "contents": "Title: Deep learning: Technical introduction Abstract: This note presents in a technical though hopefully pedagogical way the three\nmost common forms of neural network architectures: Feedforward, Convolutional\nand Recurrent. For each network, their fundamental building blocks are\ndetailed. The forward pass and the update rules for the backpropagation\nalgorithm are then derived in full. \n\n"}
{"id": "1709.02790", "contents": "Title: Biharmonic Distance and the Performance of Second-Order Consensus\n  Networks with Stochastic Disturbances Abstract: We study second order consensus dynamics with random additive disturbances.\nWe investigate three different performance measures: the steady-state variance\nof pairwise differences between vertex states, the steady-state variance of the\ndeviation of each vertex state from the average, and the total steady-state\nvariance of the system. We show that these performance measures are closely\nrelated to the biharmonic distance; the square of the biharmonic distance plays\nsimilar role in the system performance as resistance distances plays in the\nperformance of first-order noisy consensus dynamics. We further define the new\nconcepts of biharmonic Kirchhoff index and vertex centrality based on the\nbiharmonic distance. Finally, we derive analytical results for the performance\nmeasures and concepts for complete graphs, star graphs, cycles, and paths, and\nwe use this analysis to compare the asymptotic behavior of the steady-variance\nin first- and second-order systems. \n\n"}
{"id": "1709.03803", "contents": "Title: Deep Stock Representation Learning: From Candlestick Charts to\n  Investment Decisions Abstract: We propose a novel investment decision strategy (IDS) based on deep learning.\nThe performance of many IDSs is affected by stock similarity. Most existing\nstock similarity measurements have the problems: (a) The linear nature of many\nmeasurements cannot capture nonlinear stock dynamics; (b) The estimation of\nmany similarity metrics (e.g. covariance) needs very long period historic data\n(e.g. 3K days) which cannot represent current market effectively; (c) They\ncannot capture translation-invariance. To solve these problems, we apply\nConvolutional AutoEncoder to learn a stock representation, based on which we\npropose a novel portfolio construction strategy by: (i) using the deeply\nlearned representation and modularity optimisation to cluster stocks and\nidentify diverse sectors, (ii) picking stocks within each cluster according to\ntheir Sharpe ratio (Sharpe 1994). Overall this strategy provides low-risk\nhigh-return portfolios. We use the Financial Times Stock Exchange 100 Index\n(FTSE 100) data for evaluation. Results show our portfolio outperforms FTSE 100\nindex and many well known funds in terms of total return in 2000 trading days. \n\n"}
{"id": "1709.04059", "contents": "Title: Random walks and market efficiency in Chinese and Indian equity markets Abstract: Hypothesis of Market Efficiency is an important concept for the investors\nacross the globe holding diversified portfolios. With the world economy getting\nmore integrated day by day, more people are investing in global emerging\nmarkets. This means that it is pertinent to understand the efficiency of these\nmarkets. This paper tests for market efficiency by studying the impact of\nglobal financial crisis of 2008 and the recent Chinese crisis of 2015 on stock\nmarket efficiency in emerging stock markets of China and India. The data for\nlast 20 years was collected from both Bombay Stock Exchange (BSE200) and the\nShanghai Stock Exchange Composite Index and divided into four sub-periods, i.e.\nbefore financial crisis period (period-I), during recession (period-II), after\nrecession and before Chinese Crisis (periodIII) and from the start of Chinese\ncrisis till date (period- IV). Daily returns for the SSE and BSE were examined\nand tested for randomness using a combination of auto correlation tests, runs\ntests and unit root tests (Augmented Dickey-Fuller) for the entire sample\nperiod and the four sub-periods. The evidence from all these tests supports\nthat both the Indian and Chinese stock markets do not exhibit weak form of\nmarket efficiency. They do not follow random walk overall and in the first\nthree periods (1996 till the 2015) implying that recession did not impact the\nmarkets to a great extent, although the efficiency in percentage terms seems to\nbe increasing after the global financial crisis of 2008. \n\n"}
{"id": "1709.05287", "contents": "Title: Sampling of probability measures in the convex order by Wasserstein\n  projection Abstract: In this paper, for $\\mu$ and $\\nu$ two probability measures on $\\mathbb{R}^d$\nwith finite moments of order $\\rho\\ge 1$, we define the respective projections\nfor the $W_\\rho$-Wasserstein distance of $\\mu$ and $\\nu$ on the sets of\nprobability measures dominated by $\\nu$ and of probability measures larger than\n$\\mu$ in the convex order. The $W_2$-projection of $\\mu$ can be easily computed\nwhen $\\mu$ and $\\nu$ have finite support by solving a quadratic optimization\nproblem with linear constraints. In dimension $d=1$, Gozlan et al.~(2018) have\nshown that the projections do not depend on $\\rho$. We explicit their quantile\nfunctions in terms of those of $\\mu$ and $\\nu$. The motivation is the design of\nsampling techniques preserving the convex order in order to approximate\nMartingale Optimal Transport problems by using linear programming solvers. We\nprove convergence of the Wasserstein projection based sampling methods as the\nsample sizes tend to infinity and illustrate them by numerical experiments. \n\n"}
{"id": "1709.06517", "contents": "Title: Numerical analysis for a unified 2 factor model of structural and\n  reduced form types for corporate bonds with fixed discrete coupon Abstract: Conditions of Stability for explicit finite difference scheme and some\nresults of numerical analysis for a unified 2 factor model of structural and\nreduced form types for corporate bonds with fixed discrete coupon are provided.\nIt seems to be difficult to get solution formula for PDE model which\ngeneralizes Agliardi's structural model [1] for discrete coupon bonds into a\nunified 2 factor model of structural and reduced form types and we study a\nnumerical analysis for it by explicit finite difference scheme. These equations\nare parabolic equations with 3 variables and they include mixed derivatives, so\nthe explicit finite difference scheme is not stable in general. We find\nconditions for the explicit finite difference scheme to be stable, in the case\nthat it is stable, numerically compute the price of the bond and analyze its\ncredit spread and duration. \n\n"}
{"id": "1709.06759", "contents": "Title: Market Dynamics. On A Muse Of Cash Flow And Liquidity Deficit Abstract: A first attempt at obtaining market--directional information from a\nnon--stationary solution of the dynamic equation \"future price tends to the\nvalue that maximizes the number of shares traded per unit time\" [1] is\npresented. We demonstrate that the concept of price impact is poorly applicable\nto market dynamics. Instead, we consider the execution flow $I=dV/dt$ operator\nwith the \"impact from the future\" term providing information about\nnot--yet--executed trades. The \"impact from the future\" on $I$ can be directly\nestimated from the already--executed trades, the directional information on\nprice is then obtained from the experimentally observed fact that the $I$ and\n$p$ operators have the same eigenfunctions (the exact result in the dynamic\nimpact approximation $p=p(I)$). The condition for \"no information about the\nfuture\" is found and directional prediction quality is discussed. This work\nmakes a substantial contribution toward solving the ultimate market dynamics\nproblem: find evidence of existence (or proof of non--existence) of an\nautomated trading machine which consistently makes positive P\\&L on a free\nmarket as an autonomous agent (aka the existence of the market dynamics\nequation). The software with a reference implementation of the theory is\nprovided. \n\n"}
{"id": "1710.00978", "contents": "Title: Supervised Q-walk for Learning Vector Representation of Nodes in\n  Networks Abstract: Automatic feature learning algorithms are at the forefront of modern day\nmachine learning research. We present a novel algorithm, supervised Q-walk,\nwhich applies Q-learning to generate random walks on graphs such that the walks\nprove to be useful for learning node features suitable for tackling with the\nnode classification problem. We present another novel algorithm, k-hops\nneighborhood based confidence values learner, which learns confidence values of\nlabels for unlabelled nodes in the network without first learning the node\nembedding. These confidence values aid in learning an apt reward function for\nQ-learning.\n  We demonstrate the efficacy of supervised Q-walk approach over existing\nstate-of-the-art random walk based node embedding learners in solving the\nsingle / multi-label multi-class node classification problem using several real\nworld datasets.\n  Summarising, our approach represents a novel state-of-the-art technique to\nlearn features, for nodes in networks, tailor-made for dealing with the node\nclassification problem. \n\n"}
{"id": "1710.01227", "contents": "Title: Keep It Real: Tail Probabilities of Compound Heavy-Tailed Distributions Abstract: We propose an analytical approach to the computation of tail probabilities of\ncompound distributions whose individual components have heavy tails. Our\napproach is based on the contour integration method, and gives rise to a\nrepresentation of the tail probability of a compound distribution in the form\nof a rapidly convergent one-dimensional integral involving a discontinuity of\nthe imaginary part of its moment generating function across a branch cut. The\nlatter integral can be evaluated in quadratures, or alternatively represented\nas an asymptotic expansion. Our approach thus offers a viable (especially at\nhigh percentile levels) alternative to more standard methods such as Monte\nCarlo or the Fast Fourier Transform, traditionally used for such problems. As a\npractical application, we use our method to compute the operational Value at\nRisk (VAR) of a financial institution, where individual losses are modeled as\nspliced distributions whose large loss components are given by power-law or\nlognormal distributions. Finally, we briefly discuss extensions of the present\nformalism for calculation of tail probabilities of compound distributions made\nof compound distributions with heavy tails. \n\n"}
{"id": "1710.01789", "contents": "Title: Enhanced Neural Machine Translation by Learning from Draft Abstract: Neural machine translation (NMT) has recently achieved impressive results. A\npotential problem of the existing NMT algorithm, however, is that the decoding\nis conducted from left to right, without considering the right context. This\npaper proposes an two-stage approach to solve the problem. In the first stage,\na conventional attention-based NMT system is used to produce a draft\ntranslation, and in the second stage, a novel double-attention NMT system is\nused to refine the translation, by looking at the original input as well as the\ndraft translation. This drafting-and-refinement can obtain the right-context\ninformation from the draft, hence producing more consistent translations. We\nevaluated this approach using two Chinese-English translation tasks, one with\n44k pairs and 1M pairs respectively. The experiments showed that our approach\nachieved positive improvements over the conventional NMT system: the\nimprovements are 2.4 and 0.9 BLEU points on the small-scale and large-scale\ntasks, respectively. \n\n"}
{"id": "1710.01797", "contents": "Title: The Chebyshev method for the implied volatility Abstract: The implied volatility is a crucial element of any financial toolbox, since\nit is used for quoting and the hedging of options as well as for model\ncalibration. In contrast to the Black-Scholes formula its inverse, the implied\nvolatility, is not explicitly available and numerical approximation is\nrequired. We propose a bivariate interpolation of the implied volatility\nsurface based on Chebyshev polynomials. This yields a closed-form approximation\nof the implied volatility, which is easy to implement and to maintain. We prove\na subexponential error decay. This allows us to obtain an accuracy close to\nmachine precision with polynomials of a low degree. We compare the performance\nof the method in terms of runtime and accuracy to the most common reference\nmethods. In contrast to existing interpolation methods, the proposed method is\nable to compute the implied volatility for all relevant option data. In this\ncontext, numerical experiments confirm a considerable increase in efficiency,\nespecially for large data sets. \n\n"}
{"id": "1710.04455", "contents": "Title: Computational Analysis of the structural properties of Economic and\n  Financial Networks Abstract: In recent years, methods from network science are gaining rapidly interest in\neconomics and finance. A reason for this is that in a globalized world the\ninterconnectedness among economic and financial entities are crucial to\nunderstand and networks provide a natural framework for representing and\nstudying such systems. In this paper, we are surveying the use of networks and\nnetwork-based methods for studying economy related questions. We start with a\nbrief overview of graph theory and basic definitions. Then we discuss\ndescriptive network measures and network complexity measures for quantifying\nstructural properties of economic networks. Finally, we discuss different\nnetwork and tree structures as relevant for applications. \n\n"}
{"id": "1710.05015", "contents": "Title: Coherence of quantum channels Abstract: We investigate the coherence of quantum channels using the\nChoi-Jamio\\l{}kowski isomorphism. The relation between the coherence and the\npurity of the channel respects a duality relation. It characterizes the allowed\nvalues of coherence when the channel has certain purity. This duality has been\ndepicted via the Coherence-Purity (Co-Pu) diagrams. In particular, we study the\nquantum coherence of the unital and non-unital qubit channels and find out the\nallowed region of coherence for a fixed purity. We also study coherence of\ndifferent incoherent channels, namely, incoherent operation (IO), strictly\nincoherent operation (SIO), physical incoherent operation (PIO) etc.\nInterestingly, we find that the allowed region for different incoherent\noperations maintain the relation $PIO\\subset SIO \\subset IO$. In fact, we find\nthat if PIOs are coherence preserving operations (CPO), its coherence is zero\notherwise it has unit coherence and unit purity. Interestingly, different kinds\nof qubit channels can be distinguished using the Co-Pu diagram. The unital\nchannels generally do not create coherence whereas some nonunital can. All\ncoherence breaking channels are shown to have zero coherence, whereas, this is\nnot usually true for entanglement breaking channels. It turns out that the\ncoherence preserving qubit channels have unit coherence. Although the coherence\nof the Choi matrix of the incoherent channels might have finite values, its\nsubsystem contains no coherence. This indicates that the incoherent channels\ncan either be unital or nonunital under some conditions. \n\n"}
{"id": "1710.05542", "contents": "Title: Efficient hedging in Bates model using high-order compact finite\n  differences Abstract: We evaluate the hedging performance of a high-order compact finite difference\nscheme from [4] for option pricing in Bates model. We compare the scheme's\nhedging performance to standard finite difference methods in different\nexamples. We observe that the new scheme outperforms a standard, second-order\ncentral finite difference approximation in all our experiments. \n\n"}
{"id": "1710.07030", "contents": "Title: Asymptotic Expansion as Prior Knowledge in Deep Learning Method for high\n  dimensional BSDEs Abstract: We demonstrate that the use of asymptotic expansion as prior knowledge in the\n\"deep BSDE solver\", which is a deep learning method for high dimensional BSDEs\nproposed by Weinan E, Han & Jentzen (2017), drastically reduces the loss\nfunction and accelerates the speed of convergence. We illustrate the technique\nand its implications by using Bergman's model with different lending and\nborrowing rates as a typical model for FVA as well as a class of solvable BSDEs\nwith quadratic growth drivers. We also present an extension of the deep BSDE\nsolver for reflected BSDEs representing American option prices. \n\n"}
{"id": "1710.07492", "contents": "Title: Multilevel estimation of expected exit times and other functionals of\n  stopped diffusions Abstract: This paper proposes and analyses a new multilevel Monte Carlo method for the\nestimation of mean exit times for multi-dimensional Brownian diffusions, and\nassociated functionals which correspond to solutions to high-dimensional\nparabolic PDEs through the Feynman-Kac formula. In particular, it is proved\nthat the complexity to achieve an $\\varepsilon$ root-mean-square error is\n$O(\\varepsilon^{-2}\\, |\\!\\log \\varepsilon|^3)$. \n\n"}
{"id": "1710.07638", "contents": "Title: M Dwarf rotation from the ${\\it K2}$ young clusters to the field. I. A\n  Mass-Rotation Correlation at 10 Myr Abstract: Recent observations of the low-mass rotation distributions of the Pleiades\nand Praesepe clusters have revealed a ubiquitous correlation between mass and\nrotation, such that late M dwarfs rotate an order-of-magnitude faster than\nearly M dwarfs. In this paper, we demonstrate that this mass-rotation\ncorrelation is present in the 10 Myr Upper Scorpius association, as revealed by\nnew ${\\it K2}$ rotation measurements. Using rotational evolution models we show\nthat the low-mass ($0.1-0.6 M_{\\odot}$) rotation distribution of the 125 Myr\nPleiades cluster can only be produced if it hosted an equally strong\nmass-rotation correlation at 10 Myr. This suggests that physical processes\nimportant in the early pre-main sequence (star formation, accretion,\ndisk-locking) are primarily responsible for the M dwarf rotation morphology,\nand not quirks of later angular momentum evolution. Such early mass trends must\nbe taken into account when constructing initial conditions for future studies\nof stellar rotation. Finally, we show that the average M star loses $\\sim\n25-40$% of its angular momentum between 10 and 125 Myr, a figure accurately and\ngenerically predicted by modern solar-calibrated wind models. Their success\nrules out a lossless pre-main sequence, and validates the extrapolation of\nmagnetic wind laws designed for solar-type stars to the low-mass regime at\nearly times. \n\n"}
{"id": "1710.07911", "contents": "Title: Computational Methods for Martingale Optimal Transport problems Abstract: We establish numerical methods for solving the martingale optimal transport\nproblem (MOT) - a version of the classical optimal transport with an additional\nmartingale constraint on transport's dynamics. We prove that the MOT value can\nbe approximated using linear programming (LP) problems which result from a\ndiscretisation of the marginal distributions combined with a suitable\nrelaxation of the martingale constraint. Specialising to dimension one, we\nprovide bounds on the convergence rate of the above scheme. We also show a\nstability result under only partial specification of the marginal\ndistributions. Finally, we specialise to a particular discretisation scheme\nwhich preserves the convex ordering and does not require the martingale\nrelaxation. We introduce an entropic regularisation for the corresponding LP\nproblem and detail the corresponding iterative Bregman projection. We also\nrewrite its dual problem as a minimisation problem without constraint and solve\nit by computing the concave envelope of scattered data. \n\n"}
{"id": "1710.08878", "contents": "Title: Classification on Large Networks: A Quantitative Bound via Motifs and\n  Graphons Abstract: When each data point is a large graph, graph statistics such as densities of\ncertain subgraphs (motifs) can be used as feature vectors for machine learning.\nWhile intuitive, motif counts are expensive to compute and difficult to work\nwith theoretically. Via graphon theory, we give an explicit quantitative bound\nfor the ability of motif homomorphisms to distinguish large networks under both\ngenerative and sampling noise. Furthermore, we give similar bounds for the\ngraph spectrum and connect it to homomorphism densities of cycles. This results\nin an easily computable classifier on graph data with theoretical performance\nguarantee. Our method yields competitive results on classification tasks for\nthe autoimmune disease Lupus Erythematosus. \n\n"}
{"id": "1710.11435", "contents": "Title: Quantization goes Polynomial Abstract: Quantization algorithms have been successfully adopted to option pricing in\nfinance thanks to the high convergence rate of the numerical approximation. In\nparticular, very recently, recursive marginal quantization has been proven to\nbe a flexible and versatile tool when applied to stochastic volatility\nprocesses. In this paper we apply for the first time quantization techniques to\nthe family of polynomial processes, by exploiting their peculiar nature. We\nfocus our analysis on the stochastic volatility Jacobi process, by presenting\ntwo alternative quantization procedures: the first is a new discretization\ntechnique, whose foundation lies on the polynomial structure of the underlying\nprocess and which is suitable for vanilla option pricing, the second is based\non recursive marginal quantization and it allows for pricing of (vanilla and)\nexotic derivatives. We prove theoretical results to assess the induced\napproximation errors, and we describe in numerical examples practical tools for\nfast vanilla and exotic option pricing. \n\n"}
{"id": "1711.00872", "contents": "Title: Necessary and sufficient state condition for two-qubit steering using\n  two measurement settings per party and monogamy of steering Abstract: We consider the Cavalcanti-Foster-Fuwa-Wiseman inequality~\\cite{achsh} which\nis a necessary and sufficient steerability condition for two-qubit states with\ntwo measurement settings on each side. We derive the criterion which an\narbitrary two-qubit state must satisfy in order to violate this inequality, and\nobtain its maximum attainable violation in quantum mechanics. The derived\ncondition on the state parameters enables us to establish a tight monogamy\nrelation for two-qubit steering. \n\n"}
{"id": "1711.01299", "contents": "Title: BoostClean: Automated Error Detection and Repair for Machine Learning Abstract: Predictive models based on machine learning can be highly sensitive to data\nerror. Training data are often combined with a variety of different sources,\neach susceptible to different types of inconsistencies, and new data streams\nduring prediction time, the model may encounter previously unseen\ninconsistencies. An important class of such inconsistencies is domain value\nviolations that occur when an attribute value is outside of an allowed domain.\nWe explore automatically detecting and repairing such violations by leveraging\nthe often available clean test labels to determine whether a given detection\nand repair combination will improve model accuracy. We present BoostClean which\nautomatically selects an ensemble of error detection and repair combinations\nusing statistical boosting. BoostClean selects this ensemble from an extensible\nlibrary that is pre-populated general detection functions, including a novel\ndetector based on the Word2Vec deep learning model, which detects errors across\na diverse set of domains. Our evaluation on a collection of 12 datasets from\nKaggle, the UCI repository, real-world data analyses, and production datasets\nthat show that Boost- Clean can increase absolute prediction accuracy by up to\n9% over the best non-ensembled alternatives. Our optimizations including\nparallelism, materialization, and indexing techniques show a 22.2x end-to-end\nspeedup on a 16-core machine. \n\n"}
{"id": "1711.03023", "contents": "Title: The Calibration of Stochastic-Local Volatility Models - An Inverse\n  Problem Perspective Abstract: We tackle the calibration of the so-called Stochastic-Local Volatility (SLV)\nmodel. This is the class of financial models that combines the local and\nstochastic volatility features and has been subject of the attention by many\nresearchers recently. More precisely, given a local volatility surface and a\nchoice of stochastic volatility parameters, we calibrate the corresponding\nleverage function. Our approach makes use of regularization techniques from the\ninverse-problem theory, respecting the integrity of the data and thus avoiding\ndata interpolation. The result is a stable and robust algorithm which is\nresilient to instabilities in the regions of low probability density of the\nspot price and of the instantaneous variance. We substantiate our claims with\nnumerical experiments using simulated as well as real data. \n\n"}
{"id": "1711.03733", "contents": "Title: Variance optimal hedging with application to Electricity markets Abstract: In Electricity markets, illiquidity, transaction costs and market price\ncharacteristics prevent managers to replicate exactly contracts. A residual\nrisk is always present and the hedging strategy depends on a risk criterion\nchosen. We present an algorithm to hedge a position for a mean variance\ncriterion taking into account the transaction cost and the small depth of the\nmarket. We show its effectiveness on a typical problem coming from the field of\nelectricity markets. \n\n"}
{"id": "1711.07133", "contents": "Title: Influence of jump-at-default in IR and FX on Quanto CDS prices Abstract: We propose a new model for pricing Quanto CDS and risky bonds. The model\noperates with four stochastic factors, namely: hazard rate, foreign exchange\nrate, domestic interest rate, and foreign interest rate, and also allows for\njumps-at-default in the FX and foreign interest rates. Corresponding systems of\nPDEs are derived similar to how this is done in Bielecki at al., 2005. A\nlocalized version of the RBF partition of unity method is used to solve these\n4D PDEs. The results of our numerical experiments presented in the paper\nqualitatively explain the discrepancies observed in the marked values of CDS\nspreads traded in domestic and foreign economies. \n\n"}
{"id": "1711.07318", "contents": "Title: Lifshitz tails for Schr\\\"odinger operators with random breather\n  potential Abstract: We prove a Lifshitz tail bound on the integrated density of states of random\nbreather Schr\\\"odinger operators. The potential is composed of translated\nsingle site potentials. The single site potential is an indicator function of\nset $tA$ where $t$ is from the unit interval and $A$ is a measurable set\ncontained in the unit cell. The challenges of this model are: Since $A$ is not\nassumed to be star-shaped the dependence of the potential on the parameter $t$\nis not monotone. It is also non-linear and not differentiable. \n\n"}
{"id": "1711.07513", "contents": "Title: Self-Similarity Based Time Warping Abstract: In this work, we explore the problem of aligning two time-ordered point\nclouds which are spatially transformed and re-parameterized versions of each\nother. This has a diverse array of applications such as cross modal time series\nsynchronization (e.g. MOCAP to video) and alignment of discretized curves in\nimages. Most other works that address this problem attempt to jointly uncover a\nspatial alignment and correspondences between the two point clouds, or to\nderive local invariants to spatial transformations such as curvature before\ncomputing correspondences. By contrast, we sidestep spatial alignment\ncompletely by using self-similarity matrices (SSMs) as a proxy to the\ntime-ordered point clouds, since self-similarity matrices are blind to\nisometries and respect global geometry. Our algorithm, dubbed \"Isometry Blind\nDynamic Time Warping\" (IBDTW), is simple and general, and we show that its\nassociated dissimilarity measure lower bounds the L1 Gromov-Hausdorff distance\nbetween the two point sets when restricted to warping paths. We also present a\nlocal, partial alignment extension of IBDTW based on the Smith Waterman\nalgorithm. This eliminates the need for tedious manual cropping of time series,\nwhich is ordinarily necessary for global alignment algorithms to function\nproperly. \n\n"}
{"id": "1711.09852", "contents": "Title: Pricing Derivatives under Multiple Stochastic Factors by Localized\n  Radial Basis Function Methods Abstract: We propose two localized Radial Basis Function (RBF) methods, the Radial\nBasis Function Partition of Unity method (RBF-PUM) and the Radial Basis\nFunction generated Finite Differences method (RBF-FD), for solving financial\nderivative pricing problems arising from market models with multiple stochastic\nfactors. We demonstrate the useful features of the proposed methods, such as\nhigh accuracy, sparsity of the differentiation matrices, mesh-free nature and\nmulti-dimensional extendability, and show how to apply these methods for\nsolving time-dependent higher-dimensional PDEs in finance. We test these\nmethods on several problems that incorporate stochastic asset, volatility, and\ninterest rate dynamics by conducting numerical experiments. The results\nillustrate the capability of both methods to solve the problems to a sufficient\naccuracy within reasonable time. Both methods exhibit similar orders of\nconvergence, which can be further improved by a more elaborate choice of the\nmethod parameters. Finally, we discuss the parallelization potentials of the\nproposed methods and report the speedup on the example of RBF-FD. \n\n"}
{"id": "1712.00202", "contents": "Title: InverseNet: Solving Inverse Problems with Splitting Networks Abstract: We propose a new method that uses deep learning techniques to solve the\ninverse problems. The inverse problem is cast in the form of learning an\nend-to-end mapping from observed data to the ground-truth. Inspired by the\nsplitting strategy widely used in regularized iterative algorithm to tackle\ninverse problems, the mapping is decomposed into two networks, with one\nhandling the inversion of the physical forward model associated with the data\nterm and one handling the denoising of the output from the former network,\ni.e., the inverted version, associated with the prior/regularization term. The\ntwo networks are trained jointly to learn the end-to-end mapping, getting rid\nof a two-step training. The training is annealing as the intermediate variable\nbetween these two networks bridges the gap between the input (the degraded\nversion of output) and output and progressively approaches to the ground-truth.\nThe proposed network, referred to as InverseNet, is flexible in the sense that\nmost of the existing end-to-end network structure can be leveraged in the first\nnetwork and most of the existing denoising network structure can be used in the\nsecond one. Extensive experiments on both synthetic data and real datasets on\nthe tasks, motion deblurring, super-resolution, and colorization, demonstrate\nthe efficiency and accuracy of the proposed method compared with other image\nprocessing algorithms. \n\n"}
{"id": "1712.00975", "contents": "Title: Temporal Attention augmented Bilinear Network for Financial Time-Series\n  Data Analysis Abstract: Financial time-series forecasting has long been a challenging problem because\nof the inherently noisy and stochastic nature of the market. In the\nHigh-Frequency Trading (HFT), forecasting for trading purposes is even a more\nchallenging task since an automated inference system is required to be both\naccurate and fast. In this paper, we propose a neural network layer\narchitecture that incorporates the idea of bilinear projection as well as an\nattention mechanism that enables the layer to detect and focus on crucial\ntemporal information. The resulting network is highly interpretable, given its\nability to highlight the importance and contribution of each temporal instance,\nthus allowing further analysis on the time instances of interest. Our\nexperiments in a large-scale Limit Order Book (LOB) dataset show that a\ntwo-hidden-layer network utilizing our proposed layer outperforms by a large\nmargin all existing state-of-the-art results coming from much deeper\narchitectures while requiring far fewer computations. \n\n"}
{"id": "1712.01060", "contents": "Title: A Numerical Method for Pricing Discrete Double Barrier Option by\n  Lagrange Interpolation on Jacobi Node Abstract: In this paper, a rapid and high accurate numerical method for pricing\ndiscrete single and double barrier knock-out call options is presented.\nAccording to the well-known Black-Scholes framework, the price of option in\neach monitoring date could be calculate by computing a recursive integral\nformula upon the heat equation solution. We have approximated these recursive\nsolutions with the aim of Lagrange interpolation on Jacobi polynomials node.\nAfter that, an operational matrix, that makes our computation significantly\nfast, has been driven. The most important feature of this method is that its\nCPU time dose not increase when the number of monitoring dates increases. The\nnumerical results confirm the accuracy and efficiency of the presented\nnumerical algorithm. \n\n"}
{"id": "1712.01837", "contents": "Title: Large deviations in the presence of cooperativity and slow dynamics Abstract: We study simple models of intermittency, involving switching between two\nstates, within the dynamical large-deviation formalism. Singularities appear in\nthe formalism when switching is cooperative, or when its basic timescale\ndiverges. In the first case the unbiased trajectory distribution undergoes a\nsymmetry breaking, leading to a change of shape of the large-deviation rate\nfunction for a particular dynamical observable. In the second case the symmetry\nof the unbiased trajectory distribution remains unbroken. Comparison of these\nmodels suggests that singularities of the dynamical large-deviation formalism\ncan signal the dynamical equivalent of an equilibrium phase transition, but do\nnot necessarily do so. \n\n"}
{"id": "1712.03740", "contents": "Title: Holographic entanglement entropy and entanglement thermodynamics of\n  `black' non-susy D3 brane Abstract: Like BPS D3 brane, the non-supersymmetric (non-susy) D3 brane of type IIB\nstring theory is also known to have a decoupling limit and leads to a\nnon-supersymmetric AdS/CFT correspondence. The throat geometry in this case\nrepresents a QFT which is neither conformal nor supersymmetric. The `black'\nversion of the non-susy D3 brane in the decoupling limit describes a QFT at\nfinite temperature. Here we first compute the entanglement entropy for small\nsubsystem of such QFT from the decoupled geometry of `black' non-susy D3 brane\nusing holographic technique. Then we study the entanglement thermodynamics for\nthe weakly excited states of this QFT from the asymptotically AdS geometry of\nthe decoupled `black' non-susy D3 brane. We observe that for small subsystem\nthis background indeed satisfies a first law like relation with a universal\n(entanglement) temperature inversely proportional to the size of the subsystem\nand an (entanglement) pressure normal to the entangling surface. Finally we\nshow how the entanglement entropy makes a cross-over to the thermal entropy at\nhigh temperature. \n\n"}
{"id": "1712.03855", "contents": "Title: Rigorous mathematical analysis of the quasispecies model: From Manfred\n  Eigen to the recent developments Abstract: We review the major progress in the rigorous analysis of the classical\nquasispecies model that usually comes in two related but different forms: the\nEigen model and the Crow--Kimura model. The model itself was formulated almost\n50 years ago, and in its stationary form represents an easy to formulate\neigenvalue problem. Notwithstanding the simplicity of the problem statement, we\nstill lack full understanding of the behavior of the mean population fitness\nand the quasispecies distribution for an arbitrary fitness landscape. Our main\ngoal in this review is two-fold: First, to highlight a number of impressive\nmathematical results, including some of the recent ones, which pertain to the\nmathematical development of the quasispecies theory. Second, to emphasize that,\ndespite these 50 years of vigorous research, there are still very natural both\nbiological and mathematical questions that remain to be addressed within the\nquasispecies framework. Our hope is that at least some of the approaches we\nreview in this text can be of help for anyone embarking on further analysis of\nthe quasispecies model. \n\n"}
{"id": "1712.06182", "contents": "Title: Multiscale analysis of singularly perturbed finite dimensional gradient\n  flows: the minimizing movement approach Abstract: We perform a convergence analysis of a discrete-in-time minimization scheme\napproximating a finite dimensional singularly perturbed gradient flow. We allow\nfor different scalings between the viscosity parameter $\\varepsilon$ and the\ntime scale $\\tau$. When the ratio $\\frac{\\varepsilon}{\\tau}$ diverges, we\nrigorously prove the convergence of this scheme to a (discontinuous) Balanced\nViscosity solution of the quasistatic evolution problem obtained as formal\nlimit, when $\\varepsilon\\to 0$, of the gradient flow. We also characterize the\nlimit evolution corresponding to an asymptotically finite ratio between the\nscales, which is of a different kind. In this case, a discrete interfacial\nenergy is optimized at jump times. \n\n"}
{"id": "1712.07383", "contents": "Title: Monte-Carlo methods for the pricing of American options: a semilinear\n  BSDE point of view Abstract: We extend the viscosity solution characterization proved in [5] for call/put\nAmerican option prices to the case of a general payoff function in a\nmulti-dimensional setting: the price satisfies a semilinear re-action/diffusion\ntype equation. Based on this, we propose two new numerical schemes inspired by\nthe branching processes based algorithm of [8]. Our numerical experiments show\nthat approximating the discontinu-ous driver of the associated\nreaction/diffusion PDE by local polynomials is not efficient, while a simple\nrandomization procedure provides very good results. \n\n"}
{"id": "1712.07955", "contents": "Title: Connecting Holographic Wess--Zumino Consistency Conditions to the\n  Holographic Anomaly Abstract: The Holographic Wess--Zumino (HWZ) consistency conditions are shown through a\nstep by step mapping of renormalization group flows to Hamiltonian systems, to\nlead to the Holographic anomaly. These conditions codify how the energy scale,\nwhen treated as the emergent bulk direction in Holographic theories, is put on\nequal footing as the other directions of the space the field theory inhabits.\nSo, this is a defining feature of theories possessing local Holographic bulk\nduals. In four dimensional Holographic conformal field theories, the $a$ and\n$c$ anomaly coefficients are equated, and this is seen as a defining property\nof theories which possess General Relativity coupled to matter as a dual.\nHence, showing how the former consistency conditions leads to the latter\nrelation between anomaly coefficients adds evidence to the claim that the HWZ\nconditions are a defining feature of theories possessing local gravity duals. \n\n"}
{"id": "1712.08299", "contents": "Title: Quantum entanglement in de Sitter space from Stringy Axion: An analysis\n  using $\\alpha$ vacua Abstract: In this work, we study the phenomena of quantum entanglement by computing de\nSitter entanglement entropy from von Neumann measure. For this purpose we\nconsider a bipartite quantum field theoretic setup in presence of axion\noriginating from ${\\bf Type~ II~B}$ string theory. We consider the initial\nvacuum to be CPT invariant non-adiabatic $\\alpha$ vacua state under ${\\bf\nSO(1,4)}$ ismometry, which is characterized by a real one-parameter family. To\nimplement this technique we use a ${\\bf S^2}$ which divide the de Sitter into\ntwo exterior and interior sub-regions. First, we derive the wave function of\naxion in an open chart for $\\alpha$ vacua by applying Bogoliubov transformation\non the solution for Bunch-Davies vacuum state. Further, we quantify the density\nmatrix by tracing over the contribution from the exterior region. Using this\nresult we derive entanglement entropy, R$\\acute{e}$nyi entropy and explain the\nlong-range quantum effects in primordial cosmological correlations. We also\nprovide a comparison between the results obtained from Bunch-Davies vacuum and\nthe generalized $\\alpha$ vacua, which implies that the amount of quantum\nentanglement and the long-range effects are larger for non zero value of the\nparameter $\\alpha$. Most significantly, our derived results for $\\alpha$ vacua\nprovides the necessary condition for generating non zero entanglement entropy\nin primordial cosmology. \n\n"}
{"id": "1712.09201", "contents": "Title: Approximation methods for piecewise deterministic Markov processes and\n  their costs Abstract: In this paper, we analyse piecewise deterministic Markov processes, as\nintroduced in Davis (1984). Many models in insurance mathematics can be\nformulated in terms of the general concept of piecewise deterministic Markov\nprocesses. In this context, one is interested in computing certain quantities\nof interest such as the probability of ruin of an insurance company, or the\ninsurance company's value, defined as the expected discounted future dividend\npayments until the time of ruin. Instead of explicitly solving the\nintegro-(partial) differential equation related to the quantity of interest\nconsidered (an approach which can only be used in few special cases), we adapt\nthe problem in a manner that allows us to apply deterministic numerical\nintegration algorithms such as quasi-Monte Carlo rules; this is in contrast to\napplying random integration algorithms such as Monte Carlo. To this end, we\nreformulate a general cost functional as a fixed point of a particular integral\noperator, which allows for iterative approximation of the functional.\nFurthermore, we introduce a smoothing technique which is applied to the\nintegrands involved, in order to use error bounds for deterministic cubature\nrules. On the analytical side, we prove a convergence result for our PDMP\napproximation, which is of independent interest as it justifies phase-type\napproximations on the process level. We illustrate the smoothing technique for\na risk-theoretic example, and provide a comparative study of deterministic and\nMonte Carlo integration. \n\n"}
{"id": "1712.09471", "contents": "Title: Using Ramsey theory to measure unavoidable spurious correlations in Big\n  Data Abstract: Given a dataset we quantify how many patterns must always exist in the\ndataset. Formally this is done through the lens of Ramsey theory of graphs, and\na quantitative bound known as Goodman's theorem. Combining statistical tools\nwith Ramsey theory of graphs gives a nuanced understanding of how far away a\ndataset is from random, and what qualifies as a meaningful pattern.\n  This method is applied to a dataset of repeated voters in the 1984 US\ncongress, to quantify how homogeneous a subset of congressional voters is. We\nalso measure how transitive a subset of voters is. Statistical Ramsey theory is\nalso used with global economic trading data to provide evidence that global\nmarkets are quite transitive. \n\n"}
{"id": "1801.00362", "contents": "Title: Transition probability of Brownian motion in the octant and its\n  application to default modeling Abstract: We derive a semi-analytic formula for the transition probability of\nthree-dimensional Brownian motion in the positive octant with absorption at the\nboundaries. Separation of variables in spherical coordinates leads to an\neigenvalue problem for the resulting boundary value problem in the two angular\ncomponents. The main theoretical result is a solution to the original problem\nexpressed as an expansion into special functions and an eigenvalue which has to\nbe chosen to allow a matching of the boundary condition. We discuss and test\nseveral computational methods to solve a finite-dimensional approximation to\nthis nonlinear eigenvalue problem. Finally, we apply our results to the\ncomputation of default probabilities and credit valuation adjustments in a\nstructural credit model with mutual liabilities. \n\n"}
{"id": "1801.03018", "contents": "Title: Predict Forex Trend via Convolutional Neural Networks Abstract: Deep learning is an effective approach to solving image recognition problems.\nPeople draw intuitive conclusions from trading charts; this study uses the\ncharacteristics of deep learning to train computers in imitating this kind of\nintuition in the context of trading charts. The three steps involved are as\nfollows: 1. Before training, we pre-process the input data from quantitative\ndata to images. 2. We use a convolutional neural network (CNN), a type of deep\nlearning, to train our trading model. 3. We evaluate the model's performance in\nterms of the accuracy of classification. A trading model is obtained with this\napproach to help devise trading strategies. The main application is designed to\nhelp clients automatically obtain personalized trading strategies. \n\n"}
{"id": "1801.04073", "contents": "Title: Quantum Many-Body Effects in X-Ray Spectra Efficiently Computed using a\n  Basic Graph Algorithm Abstract: The growing interest in using x-ray spectroscopy for refined materials\ncharacterization calls for accurate electronic-structure theory to interpret\nx-ray near-edge fine structure. In this work, we propose an efficient and\nunified framework to describe all the many-electron processes in a Fermi liquid\nafter a sudden perturbation (such as a core hole). This problem has been\nvisited by the Mahan-Nozi\\'eres-De Dominicis (MND) theory, but it is\nintractable to implement various Feynman diagrams within first-principles\ncalculations. Here, we adopt a non-diagrammatic approach and treat all the\nmany-electron processes in the MND theory on an equal footing. Starting from a\nrecently introduced determinant formalism [Phys. Rev. Lett. 118, 096402\n(2017)], we exploit the linear-dependence of determinants describing different\nfinal states involved in the spectral calculations. An elementary graph\nalgorithm, breadth-first search, can be used to quickly identify the important\ndeterminants for shaping the spectrum, which avoids the need to evaluate a\ngreat number of vanishingly small terms. This search algorithm is performed\nover the tree-structure of the many-body expansion, which mimics a path-finding\nprocess. We demonstrate that the determinantal approach is computationally\ninexpensive even for obtaining x-ray spectra of extended systems. Using\nKohn-Sham orbitals from two self-consistent fields (ground and core-excited\nstate) as input for constructing the determinants, the calculated x-ray spectra\nfor a number of transition metal oxides are in good agreement with experiments.\nMany-electron aspects beyond the Bethe-Salpeter equation, as captured by this\napproach, are also discussed, such as shakeup excitations and many-body wave\nfunction overlap considered in Anderson's orthogonality catastrophe. \n\n"}
{"id": "1801.05597", "contents": "Title: Numerical analysis on quadratic hedging strategies for normal inverse\n  Gaussian models Abstract: The authors aim to develop numerical schemes of the two representative\nquadratic hedging strategies: locally risk minimizing and mean-variance hedging\nstrategies, for models whose asset price process is given by the exponential of\na normal inverse Gaussian process, using the results of Arai et al. \\cite{AIS},\nand Arai and Imai. Here normal inverse Gaussian process is a framework of\nL\\'evy processes frequently appeared in financial literature. In addition, some\nnumerical results are also introduced. \n\n"}
{"id": "1801.06077", "contents": "Title: The QLBS Q-Learner Goes NuQLear: Fitted Q Iteration, Inverse RL, and\n  Option Portfolios Abstract: The QLBS model is a discrete-time option hedging and pricing model that is\nbased on Dynamic Programming (DP) and Reinforcement Learning (RL). It combines\nthe famous Q-Learning method for RL with the Black-Scholes (-Merton) model's\nidea of reducing the problem of option pricing and hedging to the problem of\noptimal rebalancing of a dynamic replicating portfolio for the option, which is\nmade of a stock and cash. Here we expand on several NuQLear (Numerical\nQ-Learning) topics with the QLBS model. First, we investigate the performance\nof Fitted Q Iteration for a RL (data-driven) solution to the model, and\nbenchmark it versus a DP (model-based) solution, as well as versus the BSM\nmodel. Second, we develop an Inverse Reinforcement Learning (IRL) setting for\nthe model, where we only observe prices and actions (re-hedges) taken by a\ntrader, but not rewards. Third, we outline how the QLBS model can be used for\npricing portfolios of options, rather than a single option in isolation, thus\nproviding its own, data-driven and model independent solution to the (in)famous\nvolatility smile problem of the Black-Scholes model. \n\n"}
{"id": "1801.06514", "contents": "Title: Compact Perturbative Expressions for Neutrino Oscillations in Matter: II Abstract: In this paper we rewrite the neutrino mixing angles and mass squared\ndifferences in matter given, in our original paper, in a notation that is more\nconventional for the reader. Replacing the usual neutrino mixing angles and\nmass squared differences in the expressions for the vacuum oscillation\nprobabilities with these matter mixing angles and mass squared differences\ngives an excellent approximation to the oscillation probabilities in matter.\nComparisons for T2K, NOvA, T2HKK and DUNE are also given for neutrinos and\nanti-neutrinos, disappearance and appearance channels, normal ordering and\ninverted ordering. \n\n"}
{"id": "1801.07733", "contents": "Title: On the Key Generation Rate of Physically Unclonable Functions Abstract: In this paper, an algebraic binning based coding scheme and its associated\nachievable rate for key generation using physically unclonable functions (PUFs)\nis determined. This achievable rate is shown to be optimal under the\ngenerated-secret (GS) model for PUFs. Furthermore, a polar code based\npolynomial-time encoding and decoding scheme that achieves this rate is also\npresented. \n\n"}
{"id": "1801.08215", "contents": "Title: Target volatility option pricing in lognormal fractional SABR model Abstract: We examine in this article the pricing of target volatility options in the\nlognormal fractional SABR model. A decomposition formula by Ito's calculus\nyields a theoretical replicating strategy for the target volatility option,\nassuming the accessibilities of all variance swaps and swaptions. The same\nformula also suggests an approximation formula for the price of target\nvolatility option in small time by the technique of freezing the coefficient.\nAlternatively, we also derive closed formed expressions for a small volatility\nof volatility expansion of the price of target volatility option. Numerical\nexperiments show accuracy of the approximations in a reasonably wide range of\nparameters. \n\n"}
{"id": "1801.08222", "contents": "Title: A bright future for financial agent-based models Abstract: The history of research in finance and economics has been widely impacted by\nthe field of Agent-based Computational Economics (ACE). While at the same time\nbeing popular among natural science researchers for its proximity to the\nsuccessful methods of physics and chemistry for example, the field of ACE has\nalso received critics by a part of the social science community for its lack of\nempiricism. Yet recent trends have shifted the weights of these general\narguments and potentially given ACE a whole new range of realism. At the base\nof these trends are found two present-day major scientific breakthroughs: the\nsteady shift of psychology towards a hard science due to the advances of\nneuropsychology, and the progress of artificial intelligence and more\nspecifically machine learning due to increasing computational power and big\ndata. These two have also found common fields of study in the form of\ncomputational neuroscience, and human-computer interaction, among others. We\noutline here the main lines of a computational research study of collective\neconomic behavior via Agent-Based Models (ABM) or Multi-Agent System (MAS),\nwhere each agent would be endowed with specific cognitive and behavioral biases\nknown to the field of neuroeconomics, and at the same time autonomously\nimplement rational quantitative financial strategies updated by machine\nlearning. We postulate that such ABMs would offer a whole new range of realism. \n\n"}
{"id": "1801.08675", "contents": "Title: Short-term at-the-money asymptotics under stochastic volatility models Abstract: A small-time Edgeworth expansion of the density of an asset price is given\nunder a general stochastic volatility model, from which asymptotic expansions\nof put option prices and at-the-money implied volatilities follow. A limit\ntheorem for at-the-money implied volatility skew and curvature is also given as\na corollary. The rough Bergomi model is treated as an example. \n\n"}
{"id": "1801.09866", "contents": "Title: Accelerating recurrent neural network language model based online speech\n  recognition system Abstract: This paper presents methods to accelerate recurrent neural network based\nlanguage models (RNNLMs) for online speech recognition systems. Firstly, a\nlossy compression of the past hidden layer outputs (history vector) with\ncaching is introduced in order to reduce the number of LM queries. Next, RNNLM\ncomputations are deployed in a CPU-GPU hybrid manner, which computes each layer\nof the model on a more advantageous platform. The added overhead by data\nexchanges between CPU and GPU is compensated through a frame-wise batching\nstrategy. The performance of the proposed methods evaluated on LibriSpeech test\nsets indicates that the reduction in history vector precision improves the\naverage recognition speed by 1.23 times with minimum degradation in accuracy.\nOn the other hand, the CPU-GPU hybrid parallelization enables RNNLM based\nreal-time recognition with a four times improvement in speed. \n\n"}
{"id": "1801.10202", "contents": "Title: The Multi Vehicle Stereo Event Camera Dataset: An Event Camera Dataset\n  for 3D Perception Abstract: Event based cameras are a new passive sensing modality with a number of\nbenefits over traditional cameras, including extremely low latency,\nasynchronous data acquisition, high dynamic range and very low power\nconsumption. There has been a lot of recent interest and development in\napplying algorithms to use the events to perform a variety of 3D perception\ntasks, such as feature tracking, visual odometry, and stereo depth estimation.\nHowever, there currently lacks the wealth of labeled data that exists for\ntraditional cameras to be used for both testing and development. In this paper,\nwe present a large dataset with a synchronized stereo pair event based camera\nsystem, carried on a handheld rig, flown by a hexacopter, driven on top of a\ncar and mounted on a motorcycle, in a variety of different illumination levels\nand environments. From each camera, we provide the event stream, grayscale\nimages and IMU readings. In addition, we utilize a combination of IMU, a\nrigidly mounted lidar system, indoor and outdoor motion capture and GPS to\nprovide accurate pose and depth images for each camera at up to 100Hz. For\ncomparison, we also provide synchronized grayscale images and IMU readings from\na frame based stereo camera system. \n\n"}
{"id": "1801.10359", "contents": "Title: Multi-factor approximation of rough volatility models Abstract: Rough volatility models are very appealing because of their remarkable fit of\nboth historical and implied volatilities. However, due to the non-Markovian and\nnon-semimartingale nature of the volatility process, there is no simple way to\nsimulate efficiently such models, which makes risk management of derivatives an\nintricate task. In this paper, we design tractable multi-factor stochastic\nvolatility models approximating rough volatility models and enjoying a\nMarkovian structure. Furthermore, we apply our procedure to the specific case\nof the rough Heston model. This in turn enables us to derive a numerical method\nfor solving fractional Riccati equations appearing in the characteristic\nfunction of the log-price in this setting. \n\n"}
{"id": "1801.10446", "contents": "Title: Self-testing of Pauli observables for device-independent entanglement\n  certification Abstract: We present self-testing protocols to certify the presence of tensor products\nof Pauli measurements on maximally entangled states of local dimension $2^n$\nfor $n\\in\\mathbb{N}$. This provides self-tests of sets of informationally\ncomplete measurements in arbitrarily high dimension. We then show that this can\nbe used for the device-independent certification of the entanglement of all\nbipartite entangled states by exploiting a connection to measurement\ndevice-independent entanglement witnesses and quantum networks. This work\nextends a more compact parallel work on the same subject and provides all the\nrequired technical proofs. \n\n"}
{"id": "1802.00168", "contents": "Title: Deep Neural Nets with Interpolating Function as Output Activation Abstract: We replace the output layer of deep neural nets, typically the softmax\nfunction, by a novel interpolating function. And we propose end-to-end training\nand testing algorithms for this new architecture. Compared to classical neural\nnets with softmax function as output activation, the surrogate with\ninterpolating function as output activation combines advantages of both deep\nand manifold learning. The new framework demonstrates the following major\nadvantages: First, it is better applicable to the case with insufficient\ntraining data. Second, it significantly improves the generalization accuracy on\na wide variety of networks. The algorithm is implemented in PyTorch, and code\nwill be made publicly available. \n\n"}
{"id": "1802.00531", "contents": "Title: A generalization of Menon's identity with Dirichlet characters Abstract: The classical Menon's identity [7] states that\n  \\begin{equation*}\\label{oldbegin1} \\sum_{\\substack{a\\in\\Bbb Z_n^\\ast }}\\gcd(a\n-1,n)=\\varphi(n) \\sigma_{0} (n), \\end{equation*} where for a positive integer\n$n$, $\\Bbb Z_n^\\ast$ is the group of units of the ring $\\Bbb Z_n=\\Bbb Z/n\\Bbb\nZ$, $\\gcd(\\ ,\\ )$ represents the greatest common divisor, $\\varphi(n)$ is the\nEuler's totient function and $\\sigma_{k} (n) =\\sum_{d|n } d^{k}$ is the divisor\nfunction.\n  In this paper, we generalize Menon's identity with Dirichlet characters in\nthe following way: \\begin{equation*}\n  \\sum_{\\substack{a\\in\\Bbb Z_n^\\ast b_1, ..., b_k\\in\\Bbb Z_n}}\n  \\gcd(a-1,b_1, ..., b_k, n)\\chi(a)=\\varphi(n)\\sigma_k\\left(\\frac{n}{d}\\right),\n\\end{equation*} where $k$ is a non-negative integer and $\\chi$ is a Dirichlet\ncharacter modulo $n$ whose conductor is $d$.\n  Our result can be viewed as an extension of Zhao and Cao's result [16] to\n$k>0$.\n  It can also be viewed as an extension of Sury's result [12] to Dirichlet\ncharacters. \n\n"}
{"id": "1802.01143", "contents": "Title: The Power of Trading Polarity: Evidence from China Stock Market Crash Abstract: The imbalance of buying and selling functions profoundly in the formation of\nmarket trends, however, a fine-granularity investigation of the imbalance is\nstill missing. This paper investigates a unique transaction dataset that\nenables us to inspect the imbalance of buying and selling on the man-times\nlevel at high frequency, what we call 'trading polarity', for a large\ncross-section of stocks from Shenzhen Stock Exchange. The trading polarity\nmeasures the market sentiment toward stocks from a view of very essence of\ntrading desire. When using the polarity to examine market crash, we find that\ntrading polarity successfully reflects the changing of market-level behavior in\nterms of its flipping times, depth, and length. We further investigate the\nrelationship between polarity and return. At market-level, trading polarity is\nnegatively correlated with returns, while at stock-level, this correlation\nchanges according to market conditions, which becomes a good signal of market\npsychology transition. Also, the significant correlation disclosed by the\nmarket polarity and market emotion implies that our presented polarity, which\nessentially calculated in the context of high-frequency trading data, can\nreal-timely reflect the sentiment of the market. The trading polarity indeed\nprovides a new way to understand and foresee the market behavior. \n\n"}
{"id": "1802.01307", "contents": "Title: Asian Option Pricing with Orthogonal Polynomials Abstract: In this paper we derive a series expansion for the price of a continuously\nsampled arithmetic Asian option in the Black-Scholes setting. The expansion is\nbased on polynomials that are orthogonal with respect to the log-normal\ndistribution. All terms in the series are fully explicit and no numerical\nintegration nor any special functions are involved. We provide sufficient\nconditions to guarantee convergence of the series. The moment indeterminacy of\nthe log-normal distribution introduces an asymptotic bias in the series,\nhowever we show numerically that the bias can safely be ignored in practice. \n\n"}
{"id": "1802.01861", "contents": "Title: Generating virtual scenarios of multivariate financial data for\n  quantitative trading applications Abstract: In this paper, we present a novel approach to the generation of virtual\nscenarios of multivariate financial data of arbitrary length and composition of\nassets. With this approach, decades of realistic time-synchronized data can be\nsimulated for a large number of assets, producing diverse scenarios to test and\nimprove quantitative investment strategies. Our approach is based on the\nanalysis and synthesis of the time-dependent individual and joint\ncharacteristics of real financial time series, using stochastic sequences of\nmarket trends to draw multivariate returns from time-dependent probability\nfunctions preserving both distributional properties of asset returns and\ntime-dependent correlation among time series. Moreover, new time-synchronized\nassets can be arbitrarily generated through a PCA-based procedure to obtain any\nnumber of assets in the final virtual scenario. For the validation of such\nsimulated data, they are tested with an extensive set of measurements showing a\nsignificant degree of agreement with the reference performance of real\nfinancial series, better than that obtained with other classical and\nstate-of-the-art approaches. \n\n"}
{"id": "1802.03042", "contents": "Title: Deep Hedging Abstract: We present a framework for hedging a portfolio of derivatives in the presence\nof market frictions such as transaction costs, market impact, liquidity\nconstraints or risk limits using modern deep reinforcement machine learning\nmethods.\n  We discuss how standard reinforcement learning methods can be applied to\nnon-linear reward structures, i.e. in our case convex risk measures. As a\ngeneral contribution to the use of deep learning for stochastic processes, we\nalso show that the set of constrained trading strategies used by our algorithm\nis large enough to $\\epsilon$-approximate any optimal solution.\n  Our algorithm can be implemented efficiently even in high-dimensional\nsituations using modern machine learning tools. Its structure does not depend\non specific market dynamics, and generalizes across hedging instruments\nincluding the use of liquid derivatives. Its computational performance is\nlargely invariant in the size of the portfolio as it depends mainly on the\nnumber of hedging instruments available.\n  We illustrate our approach by showing the effect on hedging under transaction\ncosts in a synthetic market driven by the Heston model, where we outperform the\nstandard \"complete market\" solution. \n\n"}
{"id": "1802.03405", "contents": "Title: Particle-without-Particle: a practical pseudospectral collocation method\n  for linear partial differential equations with distributional sources Abstract: Partial differential equations with distributional sources---in particular,\ninvolving (derivatives of) delta distributions---have become increasingly\nubiquitous in numerous areas of physics and applied mathematics. It is often of\nconsiderable interest to obtain numerical solutions for such equations, but any\nsingular (\"particle\"-like) source modeling invariably introduces nontrivial\ncomputational obstacles. A common method to circumvent these is through some\nform of delta function approximation procedure on the computational grid;\nhowever, this often carries significant limitations on the efficiency of the\nnumerical convergence rates, or sometimes even the resolvability of the problem\nat all.\n  In this paper, we present an alternative technique for tackling such\nequations which avoids the singular behavior entirely: the\n\"Particle-without-Particle\" method. Previously introduced in the context of the\nself-force problem in gravitational physics, the idea is to discretize the\ncomputational domain into two (or more) disjoint pseudospectral\n(Chebyshev-Lobatto) grids such that the \"particle\" is always at the interface\nbetween them; thus, one only needs to solve homogeneous equations in each\ndomain, with the source effectively replaced by jump (boundary) conditions\nthereon. We prove here that this method yields solutions to any linear PDE the\nsource of which is any linear combination of delta distributions and\nderivatives thereof supported on a one-dimensional subspace of the problem\ndomain. We then implement it to numerically solve a variety of relevant PDEs:\nhyperbolic (with applications to neuroscience and acoustics), parabolic (with\napplications to finance), and elliptic. We generically obtain improved\nconvergence rates relative to typical past implementations relying on delta\nfunction approximations. \n\n"}
{"id": "1802.04205", "contents": "Title: Efficient Hierarchical Robot Motion Planning Under Uncertainty and\n  Hybrid Dynamics Abstract: Noisy observations coupled with nonlinear dynamics pose one of the biggest\nchallenges in robot motion planning. By decomposing nonlinear dynamics into a\ndiscrete set of local dynamics models, hybrid dynamics provide a natural way to\nmodel nonlinear dynamics, especially in systems with sudden discontinuities in\ndynamics due to factors such as contacts. We propose a hierarchical POMDP\nplanner that develops cost-optimized motion plans for hybrid dynamics models.\nThe hierarchical planner first develops a high-level motion plan to sequence\nthe local dynamics models to be visited and then converts it into a detailed\ncontinuous state plan. This hierarchical planning approach results in a\ndecomposition of the POMDP planning problem into smaller sub-parts that can be\nsolved with significantly lower computational costs. The ability to sequence\nthe visitation of local dynamics models also provides a powerful way to\nleverage the hybrid dynamics to reduce state uncertainty. We evaluate the\nproposed planner on a navigation task in the simulated domain and on an\nassembly task with a robotic manipulator, showing that our approach can solve\ntasks having high observation noise and nonlinear dynamics effectively with\nsignificantly lower computational costs compared to direct planning approaches. \n\n"}
{"id": "1802.04804", "contents": "Title: Predictions and sensitivity forecasts for reionization-era [C II] line\n  intensity mapping Abstract: Observations of the high-redshift Universe using the 21 cm line of neutral\nhydrogen and complimentary emission lines from the first galaxies promise to\nopen a new door for our understanding of the epoch of reionization. We present\npredictions for the [C II] 158-micron line and H I 21 cm emission from\nredshifts z=6--9 using high-dynamic-range cosmological simulations combined\nwith semi-analytical models. We find that the CONCERTO experiment should be\nable to detect the large scale power spectrum of [C II] emission to redshifts\nof up to z=8 (signal-to-noise ratio ~ 1 at k = 0.1 h/cMpc with 1500 hr of\nintegration). A Stage II experiment similar to CCAT-p should be able to detect\n[C II] from even higher redshifts to high significance for similar integration\ntimes (signal-to-noise ratio of ~50 at k = 0.2 h/cMpc at z=6--9). We study the\npossibility of combining such future [C II] measurements with 21 cm\nmeasurements using LOFAR and SKA to measure the [C II]-21cm cross power\nspectra, and find that a Stage II experiment should be able to measure the\ncross-power spectrum for k < 1 h/cMpc to signal-to-noise ratio of better than\n10. We discuss the capability of such measurements to constrain astrophysical\nparameters relevant to reionization and show that a measurement of the [C\nII]-21cm cross power spectrum helps break the degeneracy between the mass and\nbrightness of ionizing sources. \n\n"}
{"id": "1802.04837", "contents": "Title: Adapting the CVA model to Leland's framework Abstract: We consider the framework proposed by Burgard and Kjaer (2011) that derives\nthe PDE which governs the price of an option including bilateral counterparty\nrisk and funding. We extend this work by relaxing the assumption of absence of\ntransaction costs in the hedging portfolio by proposing a cost proportional to\nthe amount of assets traded and the traded price. After deriving the nonlinear\nPDE, we prove the existence of a solution for the corresponding\ninitial-boundary value problem. Moreover, we develop a numerical scheme that\nallows to find the solution of the PDE by setting different values for each\nparameter of the model. To understand the impact of each variable within the\nmodel, we analyze the Greeks of the option and the sensitivity of the price to\nchanges in all the risk factors. \n\n"}
{"id": "1802.05016", "contents": "Title: Multilevel nested simulation for efficient risk estimation Abstract: We investigate the problem of computing a nested expectation of the form\n$\\mathbb{P}[\\mathbb{E}[X|Y]\n\\!\\geq\\!0]\\!=\\!\\mathbb{E}[\\textrm{H}(\\mathbb{E}[X|Y])]$ where $\\textrm{H}$ is\nthe Heaviside function. This nested expectation appears, for example, when\nestimating the probability of a large loss from a financial portfolio. We\npresent a method that combines the idea of using Multilevel Monte Carlo (MLMC)\nfor nested expectations with the idea of adaptively selecting the number of\nsamples in the approximation of the inner expectation, as proposed by (Broadie\net al., 2011). We propose and analyse an algorithm that adaptively selects the\nnumber of inner samples on each MLMC level and prove that the resulting MLMC\nmethod with adaptive sampling has an $\\mathcal{O}\\left(\n\\varepsilon^{-2}|\\log\\varepsilon|^2 \\right)$ complexity to achieve a root\nmean-squared error $\\varepsilon$. The theoretical analysis is verified by\nnumerical experiments on a simple model problem. We also present a stochastic\nroot-finding algorithm that, combined with our adaptive methods, can be used to\ncompute other risk measures such as Value-at-Risk (VaR) and Conditional\nValue-at-Risk (CVaR), with the latter being achieved with\n$\\mathcal{O}\\left(\\varepsilon^{-2}\\right)$ complexity. \n\n"}
{"id": "1802.06520", "contents": "Title: Pricing Options with Exponential Levy Neural Network Abstract: In this paper, we propose the exponential Levy neural network (ELNN) for\noption pricing, which is a new non-parametric exponential Levy model using\nartificial neural networks (ANN). The ELNN fully integrates the ANNs with the\nexponential Levy model, a conventional pricing model. So, the ELNN can improve\nANN-based models to avoid several essential issues such as unacceptable\noutcomes and inconsistent pricing of over-the-counter products. Moreover, the\nELNN is the first applicable non-parametric exponential Levy model by virtue of\noutstanding researches on optimization in the field of ANN. The existing\nnon-parametric models are too vulnerable to be employed in practice. The\nempirical tests with S\\&P 500 option prices show that the ELNN outperforms two\nparametric models, the Merton and Kou models, in terms of fitting performance\nand stability of estimates. \n\n"}
{"id": "1802.08457", "contents": "Title: Resilience against Misbehaving Nodes in Asynchronous Networks Abstract: Network systems are one of the most active research areas in the engineering\ncommunity as they feature a paradigm shift from centralized to distributed\ncontrol and computation. When dealing with network systems, a fundamental\nchallenge is to ensure their functioning even when some of the network nodes do\nnot operate as intended due to faults or attacks. The objective of this paper\nis to address the problem of resilient consensus in a context where the nodes\nhave their own clocks, possibly operating in an asynchronous way, and can make\nupdates at arbitrary time instants. The results represent a first step towards\nthe development of resilient event-triggered and self-triggered coordination\nprotocols. \n\n"}
{"id": "1802.09294", "contents": "Title: Regularity theory for parabolic equations with singular degenerate\n  coefficients Abstract: In this paper, we study parabolic equations in divergence form with\ncoefficients that are singular degenerate as some Muckenhoupt weight functions\nin one spatial variable. Under certain conditions, weighted reverse\nH\\\"{o}lder's inequalities are established. Lipschitz estimates for weak\nsolutions are proved for homogeneous equations with singular degenerate\ncoefficients depending only on one spatial variable. These estimates are then\nused to establish interior, boundary, and global weighted estimates of\nCalder\\'{o}n-Zygmund type for weak solutions, assuming that the coefficients\nare partially VMO (vanishing mean oscillations) with respect to the considered\nweights. The solvability in weighted Sobolev spaces is also achieved. Our\nresults are new even for elliptic equations, and non-trivially extend known\nresults for uniformly elliptic and parabolic equations. The results are also\nuseful in the study of fractional elliptic and parabolic equations with\nmeasurable coefficients. \n\n"}
{"id": "1802.09611", "contents": "Title: An Expanded Local Variance Gamma model Abstract: The paper proposes an expanded version of the Local Variance Gamma model of\nCarr and Nadtochiy by adding drift to the governing underlying process. Still\nin this new model it is possible to derive an ordinary differential equation\nfor the option price which plays a role of Dupire's equation for the standard\nlocal volatility model. It is shown how calibration of multiple smiles (the\nwhole local volatility surface) can be done in such a case. Further, assuming\nthe local variance to be a piecewise linear function of strike and piecewise\nconstant function of time this ODE is solved in closed form in terms of\nConfluent hypergeometric functions. Calibration of the model to market smiles\ndoes not require solving any optimization problem and, in contrast, can be done\nterm-by-term by solving a system of non-linear algebraic equations for each\nmaturity, which is fast. \n\n"}
{"id": "1803.02087", "contents": "Title: Two limit theorems for the high-dimensional two-stage contact process Abstract: In this paper we are concerned with the two-stage contact process introduced\nin \\cite{Krone1999} on a high-dimensional lattice. By comparing this process\nwith an auxiliary model which is a linear system, we obtain two limit theorems\nfor this process as the dimension of the lattice grows to infinity. The first\ntheorem is about the upper invariant measure of the process. The second theorem\nis about asymptotic behavior of the critical value of the process. These two\ntheorems can be considered as extensions of their counterparts for the basic\ncontact processes proved in \\cite{Grif1983} and \\cite{Schonmann1986}. \n\n"}
{"id": "1803.02916", "contents": "Title: A Bayesian framework for molecular strain identification from mixed\n  diagnostic samples Abstract: We provide a mathematical formulation and develop a computational framework\nfor identifying multiple strains of microorganisms from mixed samples of DNA.\nOur method is applicable in public health domains where efficient\nidentification of pathogens is paramount, e.g., for the monitoring of disease\noutbreaks. We formulate strain identification as an inverse problem that aims\nat simultaneously estimating a binary matrix (encoding presence or absence of\nmutations in each strain) and a real-valued vector (representing the mixture of\nstrains) such that their product is approximately equal to the measured data\nvector. The problem at hand has a similar structure to blind deconvolution,\nexcept for the presence of binary constraints, which we enforce in our\napproach. Following a Bayesian approach, we derive a posterior density. We\npresent two computational methods for solving the non-convex maximum a\nposteriori estimation problem. The first one is a local optimization method\nthat is made efficient and scalable by decoupling the problem into smaller\nindependent subproblems, whereas the second one yields a global minimizer by\nconverting the problem into a convex mixed-integer quadratic programming\nproblem. The decoupling approach also provides an efficient way to integrate\nover the posterior. This provides useful information about the ambiguity of the\nunderdetermined problem and, thus, the uncertainty associated with numerical\nsolutions. We evaluate the potential and limitations of our framework in silico\nusing synthetic and experimental data with available ground truths. \n\n"}
{"id": "1803.04838", "contents": "Title: Thermodynamic dislocation theory: Bauschinger effect Abstract: The thermodynamic dislocation theory developed for non-uniform plastic\ndeformations is used here to simulate the stress-strain curves for crystals\nsubjected to anti-plane shear-controlled load reversal. We show that the\npresence of the positive back stress during the load reversal reduces the\nmagnitude of shear stress required to pull excess dislocations back to the\ncenter of the specimen. There, the excess dislocations of opposite signs meet\nand annihilate each other leading to the Bauschinger effect. \n\n"}
{"id": "1803.07152", "contents": "Title: Exploring the predictability of range-based volatility estimators using\n  RNNs Abstract: We investigate the predictability of several range-based stock volatility\nestimators, and compare them to the standard close-to-close estimator which is\nmost commonly acknowledged as the volatility. The patterns of volatility\nchanges are analyzed using LSTM recurrent neural networks, which are a state of\nthe art method of sequence learning. We implement the analysis on all current\nconstituents of the Dow Jones Industrial Average index, and report averaged\nevaluation results. We find that changes in the values of range-based\nestimators are more predictable than that of the estimator using daily closing\nvalues only. \n\n"}
{"id": "1803.07216", "contents": "Title: Mixing LSMC and PDE Methods to Price Bermudan Options Abstract: We develop a mixed least squares Monte Carlo-partial differential equation\n(LSMC-PDE) method for pricing Bermudan style options on assets whose volatility\nis stochastic. The algorithm is formulated for an arbitrary number of assets\nand volatility processes and we prove the algorithm converges almost surely for\na class of models. We also discuss two methods to improve the algorithm's\ncomputational complexity. Our numerical examples focus on the single ($2d$) and\nmulti-dimensional ($4d$) Heston models and we compare our hybrid algorithm with\nclassical LSMC approaches. In each case, we find that the hybrid algorithm\noutperforms standard LSMC in terms of estimating prices and optimal exercise\nboundaries. \n\n"}
{"id": "1803.07904", "contents": "Title: A path integral based model for stocks and order dynamics Abstract: We introduce a model for the short-term dynamics of financial assets based on\nan application to finance of quantum gauge theory, developing ideas of Ilinski.\nWe present a numerical algorithm for the computation of the probability\ndistribution of prices and compare the results with APPLE stocks prices and the\nS&P500 index. \n\n"}
{"id": "1803.11309", "contents": "Title: Simulation Methods for Stochastic Storage Problems: A Statistical\n  Learning Perspective Abstract: We consider solution of stochastic storage problems through regression Monte\nCarlo (RMC) methods. Taking a statistical learning perspective, we develop the\ndynamic emulation algorithm (DEA) that unifies the different existing\napproaches in a single modular template. We then investigate the two central\naspects of regression architecture and experimental design that constitute DEA.\nFor the regression piece, we discuss various non-parametric approaches, in\nparticular introducing the use of Gaussian process regression in the context of\nstochastic storage. For simulation design, we compare the performance of\ntraditional design (grid discretization), against space-filling, and several\nadaptive alternatives. The overall DEA template is illustrated with multiple\nexamples drawing from natural gas storage valuation and optimal control of\nback-up generator in a microgrid. \n\n"}
{"id": "1803.11403", "contents": "Title: Extraordinary SEAWs under influence of the spin-spin interaction and the\n  quantum Bohm potential Abstract: The separate spin evolution (SSE) of electrons causes the existence of the\nspin-electron acoustic wave. Extraordinary spin-electron acoustic waves (SEAWs)\npropagating perpendicular to the external magnetic field have large\ncontribution of the transverse electric field. Its spectrum has been studied in\nthe quasi-classical limit at the consideration of the separate spin evolution.\nThe spin-spin interaction and the quantum Bohm potential give contribution in\nthe spectrum extraordinary SEAW. This contribution is studied in this paper.\nMoreover, it is demonstrated that the spin-spin interaction leads to the\nexistence of the extraordinary SEAWs if the SSE is neglected. The hybridization\nof the extraordinary SEAW and the lower extraordinary wave in the regime, where\nthe cyclotron frequency is larger then the Langmuir frequency is studied\neither. \n\n"}
{"id": "1803.11467", "contents": "Title: Local Control Regression: Improving the Least Squares Monte Carlo Method\n  for Portfolio Optimization Abstract: The least squares Monte Carlo algorithm has become popular for solving\nportfolio optimization problems. A simple approach is to approximate the value\nfunctions on a discrete grid of portfolio weights, then use control regression\nto generalize the discrete estimates. However, the classical global control\nregression can be expensive and inaccurate. To overcome this difficulty, we\nintroduce a local control regression technique, combined with adaptive grids.\nWe show that choosing a coarse grid for local regression can produce\nsufficiently accurate results. \n\n"}
{"id": "1804.00512", "contents": "Title: Expanding a robot's life: Low power object recognition via FPGA-based\n  DCNN deployment Abstract: FPGAs are commonly used to accelerate domain-specific algorithmic\nimplementations, as they can achieve impressive performance boosts, are\nreprogrammable and exhibit minimal power consumption. In this work, the\nSqueezeNet DCNN is accelerated using an SoC FPGA in order for the offered\nobject recognition resource to be employed in a robotic application.\nExperiments are conducted to investigate the performance and power consumption\nof the implementation in comparison to deployment on other widely-used\ncomputational systems. \n\n"}
{"id": "1804.02721", "contents": "Title: Image Segmentation using Sparse Subset Selection Abstract: In this paper, we present a new image segmentation method based on the\nconcept of sparse subset selection. Starting with an over-segmentation, we\nadopt local spectral histogram features to encode the visual information of the\nsmall segments into high-dimensional vectors, called superpixel features. Then,\nthe superpixel features are fed into a novel convex model which efficiently\nleverages the features to group the superpixels into a proper number of\ncoherent regions. Our model automatically determines the optimal number of\ncoherent regions and superpixels assignment to shape final segments. To solve\nour model, we propose a numerical algorithm based on the alternating direction\nmethod of multipliers (ADMM), whose iterations consist of two highly\nparallelizable sub-problems. We show each sub-problem enjoys closed-form\nsolution which makes the ADMM iterations computationally very efficient.\nExtensive experiments on benchmark image segmentation datasets demonstrate that\nour proposed method in combination with an over-segmentation can provide high\nquality and competitive results compared to the existing state-of-the-art\nmethods. \n\n"}
{"id": "1804.03975", "contents": "Title: Monte Carlo pathwise sensitivities for barrier options Abstract: The Monte Carlo pathwise sensitivities approach is well established for\nsmooth payoff functions. In this work, we present a new Monte Carlo algorithm\nthat is able to calculate the pathwise sensitivities for discontinuous payoff\nfunctions. Our main tool is to combine the one-step survival idea of Glasserman\nand Staum with the stable differentiation approach of Alm, Harrach, Harrach and\nKeller. As an application we use the derived results for a two-dimensional\ncalibration of a CoCo-Bond, which we model with different types of discretely\nmonitored barrier options. \n\n"}
{"id": "1804.07396", "contents": "Title: Making Change in 2048 Abstract: The 2048 game involves tiles labeled with powers of two that can be merged to\nform bigger powers of two; variants of the same puzzle involve similar merges\nof other tile values. We analyze the maximum score achievable in these games by\nproving a min-max theorem equating this maximum score (in an abstract\ngeneralized variation of 2048 that allows all the moves of the original game)\nwith the minimum value that causes a greedy change-making algorithm to use a\ngiven number of coins. A widely-followed strategy in 2048 maintains tiles that\nrepresent the move number in binary notation, and a similar strategy in the\nFibonacci number variant of the game (987) maintains the Zeckendorf\nrepresentation of the move number as a sum of the fewest possible Fibonacci\nnumbers; our analysis shows that the ability to follow these strategies is\nintimately connected with the fact that greedy change-making is optimal for\nbinary and Fibonacci coinage. For variants of 2048 using tile values for which\ngreedy change-making is suboptimal, it is the greedy strategy, not the optimal\nrepresentation as sums of tile values, that controls the length of the game. In\nparticular, the game will always terminate whenever the sequence of allowable\ntile values has arbitrarily large gaps between consecutive values. \n\n"}
{"id": "1804.07534", "contents": "Title: Fourth order compact scheme for option pricing under Merton and Kou\n  jump-diffusion models Abstract: In this article, a three-time levels compact scheme is proposed to solve the\npartial integro-differential equation governing the option prices under\njump-diffusion models. In the proposed compact scheme, the second derivative\napproximation of unknowns is approximated by the value of unknowns and their\nfirst derivative approximations which allow us to obtain a tri-diagonal system\nof linear equations for the fully discrete problem. Moreover, consistency and\nstability of the proposed compact scheme are proved. Due to the low regularity\nof typical initial conditions, the smoothing operator is employed to ensure the\nfourth-order convergence rate. Numerical illustrations for pricing European\noptions under Merton and Kou jump-diffusion models are presented to validate\nthe theoretical results. \n\n"}
{"id": "1804.08546", "contents": "Title: Energy-, momentum-, density-, and positivity-preserving spatio-temporal\n  discretizations for the nonlinear Landau collision operator with exact\n  H-theorems Abstract: This paper explores energy-, momentum-, density-, and positivity-preserving\nspatio-temporal discretizations for the nonlinear Landau collision operator. We\ndiscuss two approaches, namely direct Galerkin formulations and discretizations\nof the underlying infinite-dimensional metriplectic structure of the collision\nintegral. The spatial discretizations are chosen to reproduce the\ntime-continuous conservation laws that correspond to Casimir invariants and to\nguarantee the positivity of the distribution function. Both the direct and the\nmetriplectic discretization are demonstrated to have exact H-theorems and\nunique, physically exact equilibrium states. Most importantly, the two\napproaches are shown to coincide, given the chosen Galerkin method. A temporal\ndiscretization, preserving all of the mentioned properties, is achieved with\nso-called discrete gradients. Hence the proposed algorithm successfully\ntranslates all properties of the infinite-dimensional time-continuous Landau\ncollision operator to time- and space-discrete sparse-matrix equations suitable\nfor numerical simulation. \n\n"}
{"id": "1804.09253", "contents": "Title: DeepTriangle: A Deep Learning Approach to Loss Reserving Abstract: We propose a novel approach for loss reserving based on deep neural networks.\nThe approach allows for joint modeling of paid losses and claims outstanding,\nand incorporation of heterogeneous inputs. We validate the models on loss\nreserving data across lines of business, and show that they improve on the\npredictive accuracy of existing stochastic methods. The models require minimal\nfeature engineering and expert input, and can be automated to produce forecasts\nmore frequently than manual workflows. \n\n"}
{"id": "1804.09651", "contents": "Title: New relations for graviton-matter amplitudes Abstract: We present new relations for scattering amplitudes of color ordered gluons,\nmassive quarks and scalars minimally coupled to gravity. Tree-level amplitudes\nof arbitrary matter and gluon multiplicities involving one graviton are reduced\nto partial amplitudes in QCD or scalar QCD. The obtained relations are a direct\ngeneralization of the recently found Einstein-Yang-Mills relations. The proof\nof the new relation employs a simple diagrammatic argument trading the\ngraviton-matter couplings to an `upgrade' of a gluon coupling with a\ncolor-kinematic replacement rule enforced. The use of the\nMelia-Johansson-Ochirov color basis is a key element of the reduction. We\ncomment on the generalization to multiple gravitons in the single color trace\ncase. \n\n"}
{"id": "1804.10240", "contents": "Title: Towards the ICRF3: astrometric comparison of the USNO 2016A VLBI\n  solution with ICRF2 and Gaia DR1 Abstract: The VLBI USNO 2016A (U16A) solution is part of a work-in-progress effort by\nUSNO towards the preparation of the ICRF3. Most of the astrometric improvement\nwith respect to the ICRF2 is due to the re-observation of the VCS sources. Our\nobjective in this paper is to assess U16A's astrometry. A comparison with ICRF2\nshows statistically significant offsets of size 0.1 mas between the two\nsolutions. While Gaia DR1 positions are not precise enough to resolve these\noffsets, they are found to be significantly closer to U16A than ICRF2. In\nparticular, the trend for typically larger errors for Southern sources in VLBI\nsolutions are decreased in U16A. Overall, the VLBI-Gaia offsets are reduced by\n21%. The U16A list includes 718 sources not previously included in ICRF2.\nTwenty of those new sources have statistically significant radio-optical\noffsets. In two-thirds of the cases, these offsets can be explained from\nPanSTARRS images. \n\n"}
{"id": "1804.10655", "contents": "Title: Milky Way Cepheid Standards for Measuring Cosmic Distances and\n  Application to Gaia DR2: Implications for the Hubble Constant Abstract: We present HST photometry of a selected sample of 50 long-period,\nlow-extinction Milky Way Cepheids measured on the same WFC3 F555W, F814W, and\nF160W-band photometric system as extragalactic Cepheids in SN Ia hosts. These\nbright Cepheids were observed with the WFC3 spatial scanning mode in the\noptical and near-infrared to mitigate saturation and reduce pixel-to-pixel\ncalibration errors to reach a mean photometric error of 5 millimags per\nobservation. We use the new Gaia DR2 parallaxes and HST photometry to\nsimultaneously constrain the cosmic distance scale and to measure the DR2\nparallax zeropoint offset appropriate for Cepheids. We find a value for the\nzeropoint offset of -46 +/- 13 muas or +/- 6 muas for a fixed distance scale,\nhigher than found from quasars, as expected, for these brighter and redder\nsources. The precision of the distance scale from DR2 has been reduced by a\nfactor of 2.5 due to the need to independently determine the parallax offset.\nThe best fit distance scale is 1.006 +/- 0.033, relative to the scale from\nRiess et al 2016 with H0=73.24 km/s/Mpc used to predict the parallaxes\nphotometrically, and is inconsistent with the scale needed to match the Planck\n2016 CMB data combined with LCDM at the 2.9 sigma confidence level (99.6%). At\n96.5% confidence we find that the formal DR2 errors may be underestimated as\nindicated. We identify additional error associated with the use of augmented\nCepheid samples utilizing ground-based photometry and discuss their likely\norigins. Including the DR2 parallaxes with all prior distance ladder data\nraises the current tension between the late and early Universe route to the\nHubble constant to 3.8 sigma (99.99 %). With the final expected precision from\nGaia, the sample of 50 Cepheids with HST photometry will limit to 0.5% the\ncontribution of the first rung of the distance ladder to the uncertainty in the\nHubble constant. \n\n"}
{"id": "1805.00558", "contents": "Title: Sentiment-Based Prediction of Alternative Cryptocurrency Price\n  Fluctuations Using Gradient Boosting Tree Model Abstract: In this paper, we analyze Twitter signals as a medium for user sentiment to\npredict the price fluctuations of a small-cap alternative cryptocurrency called\n\\emph{ZClassic}. We extracted tweets on an hourly basis for a period of 3.5\nweeks, classifying each tweet as positive, neutral, or negative. We then\ncompiled these tweets into an hourly sentiment index, creating an unweighted\nand weighted index, with the latter giving larger weight to retweets. These two\nindices, alongside the raw summations of positive, negative, and neutral\nsentiment were juxtaposed to $\\sim 400$ data points of hourly pricing data to\ntrain an Extreme Gradient Boosting Regression Tree Model. Price predictions\nproduced from this model were compared to historical price data, with the\nresulting predictions having a 0.81 correlation with the testing data. Our\nmodel's predictive data yielded statistical significance at the $p < 0.0001$\nlevel. Our model is the first academic proof of concept that social media\nplatforms such as Twitter can serve as powerful social signals for predicting\nprice movements in the highly speculative alternative cryptocurrency, or\n\"alt-coin\", market. \n\n"}
{"id": "1805.01252", "contents": "Title: Improving a Neural Semantic Parser by Counterfactual Learning from Human\n  Bandit Feedback Abstract: Counterfactual learning from human bandit feedback describes a scenario where\nuser feedback on the quality of outputs of a historic system is logged and used\nto improve a target system. We show how to apply this learning framework to\nneural semantic parsing. From a machine learning perspective, the key challenge\nlies in a proper reweighting of the estimator so as to avoid known degeneracies\nin counterfactual learning, while still being applicable to stochastic gradient\noptimization. To conduct experiments with human users, we devise an easy-to-use\ninterface to collect human feedback on semantic parses. Our work is the first\nto show that semantic parsers can be improved significantly by counterfactual\nlearning from logged human feedback data. \n\n"}
{"id": "1805.04704", "contents": "Title: The Heston stochastic volatility model with piecewise constant\n  parameters - efficient calibration and pricing of window barrier options Abstract: The Heston stochastic volatility model is a standard model for valuing\nfinancial derivatives, since it can be calibrated using semi-analytical\nformulas and captures the most basic structure of the market for financial\nderivatives with simple structure in time-direction. However, extending the\nmodel to the case of time-dependent parameters, which would allow for a\nparametrization of the market at multiple timepoints, proves more challenging.\nWe present a simple and numerically efficient approach to the calibration of\nthe Heston stochastic volatility model with piecewise constant parameters. We\nshow that semi-analytical formulas can also be derived in this more complex\ncase and combine them with recent advances in computational techniques for the\nHeston model. Our numerical scheme is based on the calculation of the\ncharacteristic function using Gauss-Kronrod quadrature with an additional\ncontrol variate that stabilizes the numerical integrals. We use our method to\ncalibrate the Heston model with piecewise constant parameters to the foreign\nexchange (FX) options market. Finally, we demonstrate improvements of the\nHeston model with piecewise constant parameters upon the standard Heston model\nin selected cases. \n\n"}
{"id": "1805.05617", "contents": "Title: Aggregating multiple types of complex data in stock market prediction: A\n  model-independent framework Abstract: The increasing richness in volume, and especially types of data in the\nfinancial domain provides unprecedented opportunities to understand the stock\nmarket more comprehensively and makes the price prediction more accurate than\nbefore. However, they also bring challenges to classic statistic approaches\nsince those models might be constrained to a certain type of data. Aiming at\naggregating differently sourced information and offering type-free capability\nto existing models, a framework for predicting stock market of scenarios with\nmixed data, including scalar data, compositional data (pie-like) and functional\ndata (curve-like), is established. The presented framework is\nmodel-independent, as it serves like an interface to multiple types of data and\ncan be combined with various prediction models. And it is proved to be\neffective through numerical simulations. Regarding to price prediction, we\nincorporate the trading volume (scalar data), intraday return series\n(functional data), and investors' emotions from social media (compositional\ndata) through the framework to competently forecast whether the market goes up\nor down at opening in the next day. The strong explanatory power of the\nframework is further demonstrated. Specifically, it is found that the intraday\nreturns impact the following opening prices differently between bearish market\nand bullish market. And it is not at the beginning of the bearish market but\nthe subsequent period in which the investors' \"fear\" comes to be indicative.\nThe framework would help extend existing prediction models easily to scenarios\nwith multiple types of data and shed light on a more systemic understanding of\nthe stock market. \n\n"}
{"id": "1805.05968", "contents": "Title: On the local equivalence of complete bipartite and repeater graph states Abstract: Classifying locally equivalent graph states, and stabilizer states more\nbroadly, is a significant problem in the theories of quantum information and\nmultipartite entanglement. A special focus is given to those graph states for\nwhich equivalence through local unitaries implies equivalence through local\nClifford unitaries (LU $\\Leftrightarrow$ LC). Identification of locally\nequivalent states in this class is facilitated by a convenient transformation\nrule on the underlying graphs and an efficient algorithm. Here we investigate\nthe question of local equivalence of the graph states behind the all-photonic\nquantum repeater. We show that complete bipartite graph (biclique) states,\nimperfect repeater graph states and small \"crazy graph\" states satisfy LU\n$\\Leftrightarrow$ LC. We continue by discussing biclique states more generally\nand placing them in the context of counterexamples to the LU-LC Conjecture. To\nthis end, we offer some alternative proofs and clarifications on existing\nresults. \n\n"}
{"id": "1805.06126", "contents": "Title: Market Self-Learning of Signals, Impact and Optimal Trading: Invisible\n  Hand Inference with Free Energy Abstract: We present a simple model of a non-equilibrium self-organizing market where\nasset prices are partially driven by investment decisions of a bounded-rational\nagent. The agent acts in a stochastic market environment driven by various\nexogenous \"alpha\" signals, agent's own actions (via market impact), and noise.\nUnlike traditional agent-based models, our agent aggregates all traders in the\nmarket, rather than being a representative agent. Therefore, it can be\nidentified with a bounded-rational component of the market itself, providing a\nparticular implementation of an Invisible Hand market mechanism. In such\nsetting, market dynamics are modeled as a fictitious self-play of such\nbounded-rational market-agent in its adversarial stochastic environment. As\nrewards obtained by such self-playing market agent are not observed from market\ndata, we formulate and solve a simple model of such market dynamics based on a\nneuroscience-inspired Bounded Rational Information Theoretic Inverse\nReinforcement Learning (BRIT-IRL). This results in effective asset price\ndynamics with a non-linear mean reversion - which in our model is generated\ndynamically, rather than being postulated. We argue that our model can be used\nin a similar way to the Black-Litterman model. In particular, it represents, in\na simple modeling framework, market views of common predictive signals, market\nimpacts and implied optimal dynamic portfolio allocations, and can be used to\nassess values of private signals. Moreover, it allows one to quantify a\n\"market-implied\" optimal investment strategy, along with a measure of market\nrationality. Our approach is numerically light, and can be implemented using\nstandard off-the-shelf software such as TensorFlow. \n\n"}
{"id": "1805.09427", "contents": "Title: General multilevel Monte Carlo methods for pricing discretely monitored\n  Asian options Abstract: We describe general multilevel Monte Carlo methods that estimate the price of\nan Asian option monitored at $m$ fixed dates. Our approach yields unbiased\nestimators with standard deviation $O(\\epsilon)$ in $O(m + (1/\\epsilon)^{2})$\nexpected time for a variety of processes including the Black-Scholes model,\nMerton's jump-diffusion model, the Square-Root diffusion model, Kou's double\nexponential jump-diffusion model, the variance gamma and NIG exponential Levy\nprocesses and, via the Milstein scheme, processes driven by scalar stochastic\ndifferential equations. Using the Euler scheme, our approach estimates the\nAsian option price with root mean square error $O(\\epsilon)$ in\n$O(m+(\\ln(\\epsilon)/\\epsilon)^{2})$ expected time for processes driven by\nmultidimensional stochastic differential equations. Numerical experiments\nconfirm that our approach outperforms the conventional Monte Carlo method by a\nfactor of order $m$. \n\n"}
{"id": "1805.11036", "contents": "Title: A Macroscopic Portfolio Model: From Rational Agents to Bounded\n  Rationality Abstract: We introduce a microscopic model of interacting financial agents, where each\nagent is characterized by two portfolios; money invested in bonds and money\ninvested in stocks. Furthermore, each agent is faced with an optimization\nproblem in order to determine the optimal asset allocation. The stock price\nevolution is driven by the aggregated investment decision of all agents. In\nfact, we are faced with a differential game since all agents aim to invest\noptimal. Mathematically such a problem is ill posed and we introduce the\nconcept of Nash equilibrium solutions to ensure the existence of a solution.\nEspecially, we denote an agent who solves this Nash equilibrium exactly a\nrational agent. As next step we use model predictive control to approximate the\ncontrol problem. This enables us to derive a precise mathematical\ncharacterization of the degree of rationality of a financial agent. This is a\nnovel concept in portfolio optimization and can be regarded as a general\napproach. In a second step we consider the case of a fully myopic agent, where\nwe can solve the optimal investment decision of investors analytically. We\nselect the running cost to be the expected missed revenue of an agent and we\nassume quadratic transaction costs. More precisely the expected revenues are\ndetermined by a combination of a fundamentalist or chartist strategy. Then we\nderive the mean field limit of the microscopic model in order to obtain a\nmacroscopic portfolio model. The novelty in comparison to existent\nmacroeconomic models in literature is that our model is derived from\nmicroeconomic dynamics. The resulting portfolio model is a three dimensional\nODE system which enables us to derive analytical results. Simulations reveal,\nthat our model is able to replicate the most prominent features of financial\nmarkets, namely booms and crashes. \n\n"}
{"id": "1805.11909", "contents": "Title: Quantitative approach to multifractality induced by correlations and\n  broad distribution of data Abstract: We analyze quantitatively the effect of spurious multifractality induced by\nthe presence of fat-tailed symmetric and asymmetric probability distributions\nof fluctuations in time series. In the presented approach different kinds of\nsymmetric and asymmetric broad probability distributions of synthetic data are\nexamined starting from Levy regime up to those with finite variance. We use\nnonextensive Tsallis statistics to construct all considered data in order to\nhave good analytical description of frequencies of fluctuations in the whole\nrange of their magnitude and simultaneously the full control over exponent of\npower-law decay for tails of probability distribution. The semi-analytical\ncompact formulas are then provided to express the level of spurious\nmultifractality generated by the presence of fat tails in terms of Tsallis\nparameter $\\tilde{q}$ and the scaling exponent $\\beta$ of the asymptotic decay\nof cumulated probability density function (CDF).The results are presented in\nHurst and H\\\"{o}lder languages - more often used in study of multifractal\nphenomena. According to the provided semi-analytical relations, it is argued\nhow one can make a clear quantitative distinction for any real data between\ntrue multifractality caused by the presence of nonlinear correlations, spurious\nmultifractality generated by fat-tailed shape of distributions - eventually\nwith their asymmetry, and the correction due to linear autocorrelations in\nanalyzed time series of finite length. In particular, the spurious multifractal\neffect of fat tails is found basic for proper quantitative estimation of all\nspurious multifractal effects. Examples from stock market data are presented to\nsupport these findings. \n\n"}
{"id": "1806.01734", "contents": "Title: Estimating option prices using multilevel particle filters Abstract: Option valuation problems are often solved using standard Monte Carlo (MC)\nmethods. These techniques can often be enhanced using several strategies\nespecially when one discretizes the dynamics of the underlying asset, of which\nwe assume follows a diffusion process. We consider the combination of two\nmethodologies in this direction. The first is the well-known multilevel Monte\nCarlo (MLMC) method, which is known to reduce the computational effort to\nachieve a given level of mean square error relative to MC in some cases.\nSequential Monte Carlo (or the particle filter (PF)) methods have also been\nshown to be beneficial in many option pricing problems potentially reducing\nvariances by large magnitudes (relative to MC). We propose a multilevel\nparticle filter (MLPF) as an alternative approach to price options. The\ncomputational savings obtained in using MLPF over PF for pricing both vanilla\nand exotic options is demonstrated via numerical simulations. \n\n"}
{"id": "1806.02798", "contents": "Title: Soliton decomposition of the Box-Ball System Abstract: The Box-Ball System, shortly BBS, was introduced by Takahashi and Satsuma as\na discrete counterpart of the KdV equation. Both systems exhibit solitons whose\nshape and speed are conserved after collision with other solitons. We introduce\na slot decomposition of ball configurations, each component being an infinite\nvector describing the number of size $k$ solitons in each $k$-slot. The\ndynamics of the components is linear: the $k$-th component moves rigidly at\nspeed $k$. Let $\\zeta$ be a translation invariant family of independent random\nvectors under a summability condition and $\\eta$ the ball configuration with\ncomponents $\\zeta$. We show that the law of $\\eta$ is translation invariant and\ninvariant for the BBS. This recipe allows us to construct a big family of\ninvariant measures, including product measures and stationary Markov chains\nwith ball density less than $\\frac12$. We also show that starting BBS with an\nergodic measure, the position of a tagged $k$-soliton at time $t$, divided by\n$t$ converges as $t\\to\\infty$ to an effective speed $v_k$. The vector of speeds\nsatisfies a system of linear equations related with the Generalized Gibbs\nEnsemble of conservative laws. \n\n"}
{"id": "1806.03683", "contents": "Title: On The Calibration of Short-Term Interest Rates Through a CIR Model Abstract: It is well known that the Cox-Ingersoll-Ross (CIR) stochastic model to study\nthe term structure of interest rates, as introduced in 1985, is inadequate for\nmodelling the current market environment with negative short interest rates.\nMoreover, the diffusion term in the rate dynamics goes to zero when short rates\nare small; both volatility and long-run mean do not change with time; they do\nnot fit with the skewed (fat tails) distribution of the interest rates, etc.\nThe aim of the present work is to suggest a new framework, which we call the\nCIR\\# model, that well fits the term structure of short interest rates so that\nthe market volatility structure is preserved as well as the analytical\ntractability of the original CIR model. \n\n"}
{"id": "1806.05876", "contents": "Title: Financial Risk and Returns Prediction with Modular Networked Learning Abstract: An artificial agent for financial risk and returns' prediction is built with\na modular cognitive system comprised of interconnected recurrent neural\nnetworks, such that the agent learns to predict the financial returns, and\nlearns to predict the squared deviation around these predicted returns. These\ntwo expectations are used to build a volatility-sensitive interval prediction\nfor financial returns, which is evaluated on three major financial indices and\nshown to be able to predict financial returns with higher than 80% success rate\nin interval prediction in both training and testing, raising into question the\nEfficient Market Hypothesis. The agent is introduced as an example of a class\nof artificial intelligent systems that are equipped with a Modular Networked\nLearning cognitive system, defined as an integrated networked system of machine\nlearning modules, where each module constitutes a functional unit that is\ntrained for a given specific task that solves a subproblem of a complex main\nproblem expressed as a network of linked subproblems. In the case of neural\nnetworks, these systems function as a form of an \"artificial brain\", where each\nmodule is like a specialized brain region comprised of a neural network with a\nspecific architecture. \n\n"}
{"id": "1806.07254", "contents": "Title: Emergent Open-Endedness from Contagion of the Fittest Abstract: In this paper, we study emergent irreducible information in populations of\nrandomly generated computable systems that are networked and follow a\n\"Susceptible-Infected-Susceptible\" contagion model of imitation of the fittest\nneighbor. We show that there is a lower bound for the stationary prevalence (or\naverage density of \"infected\" nodes) that triggers an unlimited increase of the\nexpected local emergent algorithmic complexity (or information) of a node as\nthe population size grows. We call this phenomenon expected (local) emergent\nopen-endedness. In addition, we show that static networks with a power-law\ndegree distribution following the Barab\\'asi-Albert model satisfy this lower\nbound and, thus, display expected (local) emergent open-endedness. \n\n"}
{"id": "1806.07460", "contents": "Title: Six line configurations and string dualities Abstract: We study the family of K3 surfaces of Picard rank sixteen associated with the\ndouble cover of the projective plane branched along the union of six lines, and\nthe family of its Van Geemen-Sarti partners, i.e., K3 surfaces with special\nNikulin involutions, such that quotienting by the involution and blowing up\nrecovers the former. We prove that the family of Van Geemen-Sarti partners is a\nfour-parameter family of K3 surfaces with $H \\oplus E_7(-1) \\oplus E_7(-1)$\nlattice polarization. We describe explicit Weierstrass models on both families\nusing even modular forms on the bounded symmetric domain of type $IV$. We also\nshow that our construction provides a geometric interpretation, called\ngeometric two-isogeny, for the F-theory/heterotic string duality in eight\ndimensions. As a result, we obtain novel F-theory models, dual to non-geometric\nheterotic string compactifications in eight dimensions with two non-vanishing\nWilson line parameters. \n\n"}
{"id": "1806.08825", "contents": "Title: Staircase-PIR: Universally Robust Private Information Retrieval Abstract: We consider the problem of designing private information retrieval (PIR)\nschemes on data of $m$ files replicated on $n$ servers that can possibly\ncollude. We focus on devising robust PIR schemes that can tolerate stragglers,\ni.e., slow or unresponsive servers. In many settings, the number of stragglers\nis not known a priori or may change with time. We define universally robust PIR\nas schemes that achieve PIR capacity asymptotically in $m$ and simultaneously\nfor any number of stragglers up to a given threshold. We introduce\nStaircase-PIR schemes and prove that they are universally robust. Towards that\nend, we establish an equivalence between robust PIR and communication efficient\nsecret sharing. \n\n"}
{"id": "1806.09156", "contents": "Title: ATLAS Tile calorimeter calibration and monitoring systems Abstract: The ATLAS Tile Calorimeter (TileCal) is the central section of the hadronic\ncalorimeter of the ATLAS experiment at LHC. This sampling calorimeter uses\nsteel plates as absorber and scintillating tiles as active medium. The light\nproduced by the passage of charged particles is transmitted by wavelength\nshifting fibers to photo-multiplier tubes (PMTs), located in the outer part of\nthe calorimeter. The readout is segmented into about 5000 cells, each one being\nread out by two PMTs in parallel. To calibrate and monitor the stability and\nperformance of the full readout chain during the data taking, a set of\ncalibration sub-systems is used. The TileCal calibration system comprises\nCesium radioactive sources, laser, charge injection elements, and an integrator\nbased readout system. Combined information from all systems allows to monitor\nand to equalize the calorimeter response at each stage of the signal evolution,\nfrom scintillation light to digitization. Calibration runs are monitored from a\ndata quality perspective and used as a crosscheck for physics runs. Data\nquality in physics runs is monitored extensively and continuously. Any problems\nare reported and immediately investigated. The data quality efficiency achieved\nwas 99.6% in 2012, 100% in 2015, 98.9% in 2016 and 99.4% in 2017.\n  Based on LHC Run-I experience, all calibration systems were improved for\nRun-II. TileCal performance during LHC Run-II, (2015-2017), is discussed,\nincluding calibration, stability, absolute energy scale, uniformity and time\nresolution. Results show that the TileCal performance is within the design\nrequirements and has given essential contribution to reconstructed objects and\nphysics results. \n\n"}
{"id": "1806.11290", "contents": "Title: On The Ruin Problem With Investment When The Risky Asset Is A\n  Semimartingale Abstract: In this paper, we study the ruin problem with investment in a general\nframework where the business part X is a L{\\'e}vy process and the return on\ninvestment R is a semimartingale. We obtain upper bounds on the finite and\ninfinite time ruin probabilities that decrease as a power function when the\ninitial capital increases. When R is a L{\\'e}vy process, we retrieve the\nwell-known results. Then, we show that these bounds are asymptotically optimal\nin the finite time case, under some simple conditions on the characteristics of\nX. Finally, we obtain a condition for ruin with probability one when X is a\nBrownian motion with negative drift and express it explicitly using the\ncharacteristics of R. \n\n"}
{"id": "1807.02227", "contents": "Title: Polynomial time algorithm for optimal stopping with fixed accuracy Abstract: The problem of high-dimensional path-dependent optimal stopping (OS) is\nimportant to multiple academic communities and applications. Modern OS tasks\noften have a large number of decision epochs, and complicated non-Markovian\ndynamics, making them especially challenging. Standard approaches, often\nrelying on ADP, duality, deep learning and other heuristics, have shown strong\nempirical performance, yet have limited rigorous guarantees (which may scale\nexponentially in the problem parameters and/or require previous knowledge of\nbasis functions or additional continuity assumptions). Although past work has\nplaced these problems in the framework of computational complexity and\npolynomial-time approximability, those analyses were limited to simple\none-dimensional problems. For long-horizon complex OS problems, is a polynomial\ntime solution even theoretically possible? We prove that given access to an\nefficient simulator of the underlying information process, and fixed accuracy\nepsilon, there exists an algorithm that returns an epsilon-optimal solution\n(both stopping policies and approximate optimal values) with computational\ncomplexity scaling polynomially in the time horizon and underlying dimension.\nLike the first polynomial-time (approximation) algorithms for several other\nwell-studied problems, our theoretical guarantees are polynomial yet\nimpractical. Our approach is based on a novel expansion for the optimal value\nwhich may be of independent interest. \n\n"}
{"id": "1807.02968", "contents": "Title: USINE: semi-analytical models for Galactic cosmic-ray propagation Abstract: I present the first public releases (v3.4 and v3.5) of the USINE code for\ncosmic-ray propagation in the Galaxy (https://lpsc.in2p3.fr/usine). It contains\nseveral semi-analytical propagation models previously used in the literature\n(leaky-box model, 2-zone 1D and 2D diffusion models) for the calculation of\nnuclei ($Z=1-30$), anti-protons, and anti-deuterons. For minimisations, the\ngeometry, transport, and source parameters of all models can be enabled as free\nparameters, whereas nuisance parameters are enabled on solar modulation levels,\ncross sections (inelastic and production), and systematics of the CR data. With\na single ASCII initialisation file to configure runs, its many displays, and\nthe speed associated to semi-analytical approaches, USINE should be a useful\ntool for beginners, but also for experts to perform statistical analyses of\nhigh-precision cosmic-ray data. \n\n"}
{"id": "1807.04294", "contents": "Title: Bit Threads in Higher Curvature Gravity Abstract: We generalize holographic bit threads to bulk theories with a gravitational\naction containing higher-curvature terms. Bit threads are a reformulation of\nholographic entanglement entropy, where the entropy is given by the maximum\nnumber of threads emanating from a boundary region into the bulk. We show that\nthe addition of higher-curvature terms adds corrections to the bit thread\nthickness that depend on the local geometry and thread orientation. Two\ndifferent methods are given: determination of the density bound by requiring\nthe maximum number of threads through a given surface to reproduce the\nentanglement entropy functional on that surface, and application of Lagrange\ndualization. The results of the two methods are applied to Gauss-Bonnet gravity\nas the simplest non-trivial example. \n\n"}
{"id": "1807.04484", "contents": "Title: 10~Mb/s quantum key distribution Abstract: We report the first quantum key distribution (QKD) systems capable of\ndelivering sustainable, real-time secure keys continuously at rates exceeding\n10 Mb/s. To achieve such rates, we developed high speed post-processing\nmodules, achieving maximum data throughputs of 60 MC/s, 55 Mb/s, and 108 Mb/s\nfor standalone operation of sifting, error correction and privacy amplification\nmodules, respectively. The photonic layer of the QKD systems features\nhigh-speed single photon detectors based on self-differencing InGaAs avalanche\nphotodiodes, phase encoding using asymmetric Mach-Zehnder interferometer, and\nactive stabilization of the interferometer phase and photon polarisation. An\nefficient variant of the decoy-state BB84 protocol is implemented for security\nanalysis, with a large dataset size of $10^8$ bits selected to mitigate\nfinite-size effects. Over a 2 dB channel, a record secure key rate of 13.72\nMb/s has been achieved averaged over 4.4 days of operation. We confirm the\nrobustness and long-term stability on a second QKD system continuously running\nfor 1 month without any user intervention. \n\n"}
{"id": "1807.04975", "contents": "Title: Recognition in Terra Incognita Abstract: It is desirable for detection and classification algorithms to generalize to\nunfamiliar environments, but suitable benchmarks for quantitatively studying\nthis phenomenon are not yet available. We present a dataset designed to measure\nrecognition generalization to novel environments. The images in our dataset are\nharvested from twenty camera traps deployed to monitor animal populations.\nCamera traps are fixed at one location, hence the background changes little\nacross images; capture is triggered automatically, hence there is no human\nbias. The challenge is learning recognition in a handful of locations, and\ngeneralizing animal detection and classification to new locations where no\ntraining data is available. In our experiments state-of-the-art algorithms show\nexcellent performance when tested at the same location where they were trained.\nHowever, we find that generalization to new locations is poor, especially for\nclassification systems. \n\n"}
{"id": "1807.06622", "contents": "Title: Deep Learning-Based BSDE Solver for Libor Market Model with Application\n  to Bermudan Swaption Pricing and Hedging Abstract: The Libor market model is a mainstay term structure model of interest rates\nfor derivatives pricing, especially for Bermudan swaptions, and other exotic\nLibor callable derivatives. For numerical implementation the pricing of\nderivatives with Libor market models is mainly carried out with Monte Carlo\nsimulation. The PDE grid approach is not particularly feasible due to Curse of\nDimensionality. The standard Monte Carlo method for American/Bermudan swaption\npricing more or less uses regression to estimate expected value as a linear\ncombination of basis functions (Longstaff and Schwartz). However, Monte Carlo\nmethod only provides the lower bound for American option price. Another\ncomplexity is the computation of the sensitivities of the option, the so-called\nGreeks, which are fundamental for a trader's hedging activity. Recently, an\nalternative numerical method based on deep learning and backward stochastic\ndifferential equations appeared in quite a few researches. For European style\noptions the feedforward deep neural networks (DNN) show not only feasibility\nbut also efficiency to obtain both prices and numerical Greeks. In this paper,\na new backward DNN solver is proposed for Bermudan swaptions. Our approach is\nrepresenting financial pricing problems in the form of high dimensional\nstochastic optimal control problems, FBSDEs, or equivalent PDEs. We demonstrate\nthat using backward DNN the high-dimension Bermudan swaption pricing and\nhedging can be solved effectively and efficiently. A comparison between Monte\nCarlo simulation and the new method for pricing vanilla interest rate options\nmanifests the superior performance of the new method. We then use this method\nto calculate prices and Greeks of Bermudan swaptions as a prelude for other\nLibor callable derivatives. \n\n"}
{"id": "1807.08406", "contents": "Title: A compactness theorem for scalar-flat metrics on 3-manifolds with\n  boundary Abstract: Let (M,g) be a compact Riemannian three-dimensional manifold with boundary.\nWe prove the compactness of the set of scalar-flat metrics which are in the\nconformal class of g and have the boundary as a constant mean curvature\nhypersurface. This involves a blow-up analysis of a Yamabe-type equation with\ncritical Sobolev exponent on the boundary. \n\n"}
{"id": "1807.11917", "contents": "Title: Direct $CP$ violation from isospin symmetry breaking effects in PQCD Abstract: We investigate the direct $CP$ violation for the decay process of\n$\\bar{B}_{s}\\rightarrow P(V)\\pi^{0}$ (P,V refer to the pseudoscalar meson and\nvector meson, respectively) via isospin symmetry breaking effects from the\n$\\pi^{0}-\\eta-\\eta'$ mixing mechanism in PQCD factorization approach. Isospin\nsymmetry breaking arises from the electroweak interaction and the u-d quark\nmass difference by the strong interaction which are known to be tiny. However,\nwe find that isospin symmetry breaking at the leading order shifts the $CP$\nviolation due to the new strong phases. \n\n"}
{"id": "1808.01657", "contents": "Title: A phenomenon of splitting resonant-tunneling one-point interactions Abstract: The so-called $\\delta'$-interaction as a particular example in Kurasov's\ndistribution theory developed on the space of discontinuous (at the point of\nsingularity) test functions, is identified with the diagonal transmission\nmatrix, {\\em continuously} depending on the strength of this interaction. On\nthe other hand, in several recent publications, the $\\delta'$-potential has\nbeen shown to be transparent at some {\\em discrete} values of the strength\nconstant and opaque beyond these values. This discrepancy is resolved here on\nthe simple physical example, namely the heterostructure consisting of two\nextremely thin layers separated by infinitesimal distance. In the three-scale\nsqueezing limit as the thickness of the layers and the distance between them\nsimultaneously tend to zero, a whole variety of single-point interactions is\nrealized. The key point is the generalization of the $\\delta'$-interaction to\nthe family for which the resonance sets appear in the form of a countable\nnumber of continuous two-dimensional curves. In this way, the connection\nbetween Kurasov's $\\delta'$-interaction and the resonant-tunneling point\ninteractions is derived and the splitting of the resonance sets for tunneling\npla ys a crucial role. \n\n"}
{"id": "1808.02236", "contents": "Title: Focusing NLS with inverse square potential Abstract: In this paper, we utilize the method in Dodson-Murphy [4] to establish the\nradial scattering result for the focusing nonlinear Schr\\\"odinger equation with\ninverse square potential $i\\pa_tu-\\la u=-|u|^{p-1}u$ in the energy space\n$H^1_a(\\R^d)$ in dimensions $d\\geq3$, which extends the result of [10,11] to\nhigher dimensions cases but with radial initial data. The new ingredient is to\nestablish the dispersive estimate for radial function and overcome the weak\ndispersive estimate when $a<0$. \n\n"}
{"id": "1808.02341", "contents": "Title: Optimal stopping via reinforced regression Abstract: In this note we propose a new approach towards solving numerically optimal\nstopping problems via reinforced regression based Monte Carlo algorithms. The\nmain idea of the method is to reinforce standard linear regression algorithms\nin each backward induction step by adding new basis functions based on\npreviously estimated continuation values. The proposed methodology is\nillustrated by a numerical example from mathematical finance. \n\n"}
{"id": "1808.02365", "contents": "Title: Pricing Financial Derivatives using Radial Basis Function generated\n  Finite Differences with Polyharmonic Splines on Smoothly Varying Node Layouts Abstract: In this paper, we study the benefits of using polyharmonic splines and node\nlayouts with smoothly varying density for developing robust and efficient\nradial basis function generated finite difference (RBF-FD) methods for pricing\nof financial derivatives. We present a significantly improved RBF-FD scheme and\nsuccessfully apply it to two types of multidimensional partial differential\nequations in finance: a two-asset European call basket option under the\nBlack--Scholes--Merton model, and a European call option under the Heston\nmodel. We also show that the performance of the improved method is equally high\nwhen it comes to pricing American options. By studying convergence,\ncomputational performance, and conditioning of the discrete systems, we show\nthe superiority of the introduced approaches over previously used versions of\nthe RBF-FD method in financial applications. \n\n"}
{"id": "1808.02601", "contents": "Title: Constraints on the hybrid equation of state with a crossover\n  hadron-quark phase transition in the light of GW170817 Abstract: In this paper, we use the recent updated source properties of GW170817 to\nconstrain the hybrid equation of state (EOS) constructed by a three-window\nmodeling between the hadronic EOS and quark EOS. Specifically, the hadronic EOS\nis described by NL3$\\omega\\rho$ model whose corresponding pure neutron star\n(NS) is already excluded by the constraint of tidal deformability (TD) from\nGW170817, and the quark EOS is calculated with 2+1 flavors Nambu-Jona-Lasinio\n(NJL) model. We also consider other four constraints on the hybrid EOS. As a\nresult, we find the parameter set ($B^{\\frac{1}{4}}, \\tilde{\\mu}, \\Gamma$) can\nbe well constrained, indicating the possible existence of the hybrid star (HS)\nwith a crossover inside. The type of the two stars in the binary system for\nnine representative hybrid EOSs is shown in this paper too. Furthermore, the\nHSs restricted by five constraints do not suggest a pure quark core but a\nmixed-phase in center. \n\n"}
{"id": "1808.03668", "contents": "Title: DeepLOB: Deep Convolutional Neural Networks for Limit Order Books Abstract: We develop a large-scale deep learning model to predict price movements from\nlimit order book (LOB) data of cash equities. The architecture utilises\nconvolutional filters to capture the spatial structure of the limit order books\nas well as LSTM modules to capture longer time dependencies. The proposed\nnetwork outperforms all existing state-of-the-art algorithms on the benchmark\nLOB dataset [1]. In a more realistic setting, we test our model by using one\nyear market quotes from the London Stock Exchange and the model delivers a\nremarkably stable out-of-sample prediction accuracy for a variety of\ninstruments. Importantly, our model translates well to instruments which were\nnot part of the training set, indicating the model's ability to extract\nuniversal features. In order to better understand these features and to go\nbeyond a \"black box\" model, we perform a sensitivity analysis to understand the\nrationale behind the model predictions and reveal the components of LOBs that\nare most relevant. The ability to extract robust features which translate well\nto other instruments is an important property of our model which has many other\napplications. \n\n"}
{"id": "1808.04725", "contents": "Title: Dynamic programming for optimal stopping via pseudo-regression Abstract: We introduce new variants of classical regression-based algorithms for\noptimal stopping problems based on computation of regression coefficients by\nMonte Carlo approximation of the corresponding $L^2$ inner products instead of\nthe least-squares error functional. Coupled with new proposals for simulation\nof the underlying samples, we call the approach \"pseudo regression\". A detailed\nconvergence analysis is provided and it is shown that the approach\nasymptotically leads to less computational cost for a pre-specified error\ntolerance, hence to lower complexity. The method is justified by numerical\nexamples. \n\n"}
{"id": "1808.05311", "contents": "Title: Semi-analytical solution of a McKean-Vlasov equation with feedback\n  through hitting a boundary Abstract: In this paper, we study the non-linear diffusion equation associated with a\nparticle system where the common drift depends on the rate of absorption of\nparticles at a boundary. We provide an interpretation as a structural credit\nrisk model with default contagion in a large interconnected banking system.\nUsing the method of heat potentials, we derive a coupled system of Volterra\nintegral equations for the transition density and for the loss through\nabsorption. An approximation by expansion is given for a small interaction\nparameter. We also present a numerical solution algorithm and conduct\ncomputational tests. \n\n"}
{"id": "1808.05890", "contents": "Title: A High Order Method for Pricing of Financial Derivatives using Radial\n  Basis Function generated Finite Differences Abstract: In this paper, we consider the numerical pricing of financial derivatives\nusing Radial Basis Function generated Finite Differences in space. Such\ndiscretization methods have the advantage of not requiring Cartesian grids.\nInstead, the nodes can be placed with higher density in areas where there is a\nneed for higher accuracy. Still, the discretization matrix is fairly sparse. As\na model problem, we consider the pricing of European options in 2D. Since such\noptions have a discontinuity in the first derivative of the payoff function\nwhich prohibits high order convergence, we smooth this function using an\nestablished technique for Cartesian grids. Numerical experiments show that we\nacquire a fourth order scheme in space, both for the uniform and the nonuniform\nnode layouts that we use. The high order method with the nonuniform node layout\nachieves very high accuracy with relatively few nodes. This renders the\npotential for solving pricing problems in higher spatial dimensions since the\ncomputational memory and time demand become much smaller with this method\ncompared to standard techniques. \n\n"}
{"id": "1808.09072", "contents": "Title: Holographic Spacetimes as Quantum Circuits of Path-Integrations Abstract: We propose that holographic spacetimes can be regarded as collections of\nquantum circuits based on path-integrals. We relate a codimension one surface\nin a gravity dual to a quantum circuit given by a path-integration on that\nsurface with an appropriate UV cut off. Our proposal naturally generalizes the\nconjectured duality between the AdS/CFT and tensor networks. This largely\nstrengthens the surface/state duality and also provides a holographic\nexplanation of path-integral optimizations. For static gravity duals, our new\nframework provides a derivation of the holographic complexity formula given by\nthe gravity action on the WDW patch. We also propose a new formula which\nrelates numbers of quantum gates to surface areas, even including time-like\nsurfaces, as a generalization of the holographic entanglement entropy formula.\nWe argue the time component of the metric in AdS emerges from the density of\nunitary quantum gates in the dual CFT. Our proposal also provides a heuristic\nunderstanding how the gravitational force emerges from quantum circuits. \n\n"}
{"id": "1808.09375", "contents": "Title: Inference based on Kotlarski's Identity Abstract: Kotlarski's identity has been widely used in applied economic research.\nHowever, how to conduct inference based on this popular identification approach\nhas been an open question for two decades. This paper addresses this open\nproblem by constructing a novel confidence band for the density function of a\nlatent variable in repeated measurement error model. The confidence band builds\non our finding that we can rewrite Kotlarski's identity as a system of linear\nmoment restrictions. The confidence band controls the asymptotic size uniformly\nover a class of data generating processes, and it is consistent against all\nfixed alternatives. Simulation studies support our theoretical results. \n\n"}
{"id": "1808.10322", "contents": "Title: PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local\n  Descriptors Abstract: We present PPF-FoldNet for unsupervised learning of 3D local descriptors on\npure point cloud geometry. Based on the folding-based auto-encoding of well\nknown point pair features, PPF-FoldNet offers many desirable properties: it\nnecessitates neither supervision, nor a sensitive local reference frame,\nbenefits from point-set sparsity, is end-to-end, fast, and can extract powerful\nrotation invariant descriptors. Thanks to a novel feature visualization, its\nevolution can be monitored to provide interpretable insights. Our extensive\nexperiments demonstrate that despite having six degree-of-freedom invariance\nand lack of training labels, our network achieves state of the art results in\nstandard benchmark datasets and outperforms its competitors when rotations and\nvarying point densities are present. PPF-FoldNet achieves $9\\%$ higher recall\non standard benchmarks, $23\\%$ higher recall when rotations are introduced into\nthe same datasets and finally, a margin of $>35\\%$ is attained when point\ndensity is significantly decreased. \n\n"}
{"id": "1808.10811", "contents": "Title: On Bose-Einstein condensation in the Luttinger-Sy model with finite\n  interaction strength Abstract: We study Bose-Einstein condensation (BEC) in the Luttinger-Sy model. Here,\nBose point particles in one spatial dimension do not interact with each other,\nbut, through a positive (repulsive) point potential with impurities which are\nrandomly located along the real line according to the points of a Poisson\nprocess. Our emphasis is on the case in which the interaction strength is not\ninfinite. As a main result, we prove that in thermal equilibrium the\none-particle ground state is macroscopically occupied, provided that the\nparticle density is larger than a critical one depending on the temperature. \n\n"}
{"id": "1809.00082", "contents": "Title: NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation Abstract: Effective feature representation is key to the predictive performance of any\nalgorithm. This paper introduces a meta-procedure, called Non-Euclidean\nUpgrading (NEU), which learns feature maps that are expressive enough to embed\nthe universal approximation property (UAP) into most model classes while only\noutputting feature maps that preserve any model class's UAP. We show that NEU\ncan learn any feature map with these two properties if that feature map is\nasymptotically deformable into the identity. We also find that the\nfeature-representations learned by NEU are always submanifolds of the feature\nspace. NEU's properties are derived from a new deep neural model that is\nuniversal amongst all orientation-preserving homeomorphisms on the input space.\nWe derive qualitative and quantitative approximation guarantees for this\narchitecture. We quantify the number of parameters required for this new\narchitecture to memorize any set of input-output pairs while simultaneously\nfixing every point of the input space lying outside some compact set, and we\nquantify the size of this set as a function of our model's depth. Moreover, we\nshow that no deep feed-forward network with commonly used activation function\nhas all these properties. NEU's performance is evaluated against competing\nmachine learning methods on various regression and dimension reduction tasks\nboth with financial and simulated data. \n\n"}
{"id": "1809.01342", "contents": "Title: A model for stocks dynamics based on a non-Gaussian path integral Abstract: We introduce a model for the dynamics of stock prices based on a non\nquadratic path integral. The model is a generalization of Ilinski's path\nintegral model, more precisely we choose a different action, which can be tuned\nto different time scales. The result is a model with a very small number of\nparameters that provides very good fits of some stock prices and indices\nfluctuations. \n\n"}
{"id": "1809.01650", "contents": "Title: Classifying 5d SCFTs via 6d SCFTs: Rank one Abstract: Following a recent proposal, we delineate a general procedure to classify 5d\nSCFTs via compactifications of 6d SCFTs on a circle (possibly with a twist by a\ndiscrete global symmetry). The path from 6d SCFTs to 5d SCFTs can be divided\ninto two steps. The first step involves computing the Coulomb branch data of\nthe 5d KK theory obtained by compactifying a 6d SCFT on a circle of finite\nradius. The second step involves computing the limit of the KK theory when the\ninverse radius along with some other mass parameters is sent to infinity. Under\nthis RG flow, the KK theory reduces to a 5d SCFT. We illustrate these ideas in\nthe case of untwisted compactifications of rank one 6d SCFTs that can be\nconstructed in F-theory without frozen singularities. The data of the\ncorresponding KK theory can be packaged in the geometry of a Calabi-Yau\nthreefold that we explicitly compute for every case. The RG flows correspond to\nflopping a collection of curves in the threefold and we formulate a concrete\nset of criteria which can be used to determine which collection of curves can\ninduce the relevant RG flows, and, in principle, to determine the Calabi-Yau\ngeometries describing the endpoints of these flows. We also comment on how to\ngeneralize our results to arbitrary rank. \n\n"}
{"id": "1809.02233", "contents": "Title: Deeply Learning Derivatives Abstract: This paper uses deep learning to value derivatives. The approach is broadly\napplicable, and we use a call option on a basket of stocks as an example. We\nshow that the deep learning model is accurate and very fast, capable of\nproducing valuations a million times faster than traditional models. We develop\na methodology to randomly generate appropriate training data and explore the\nimpact of several parameters including layer width and depth, training data\nquality and quantity on model speed and accuracy. \n\n"}
{"id": "1809.04925", "contents": "Title: Measuring Systematic Risk with Neural Network Factor Model Abstract: In this paper, we measure systematic risk with a new nonparametric factor\nmodel, the neural network factor model. The suitable factors for systematic\nrisk can be naturally found by inserting daily returns on a wide range of\nassets into the bottleneck network. The network-based model does not stick to a\nprobabilistic structure unlike parametric factor models, and it does not need\nfeature engineering because it selects notable features by itself. In addition,\nwe compare performance between our model and the existing models using 20-year\ndata of S&P 100 components. Although the new model can not outperform the best\nones among the parametric factor models due to limitations of the variational\ninference, the estimation method used for this study, it is still noteworthy in\nthat it achieves the performance as best the comparable models could without\nany prior knowledge. \n\n"}
{"id": "1809.05328", "contents": "Title: Computing Credit Valuation Adjustment solving coupled PIDEs in the Bates\n  model Abstract: Credit value adjustment (CVA) is the charge applied by financial institutions\nto the counterparty to cover the risk of losses on a counterpart default event.\nIn this paper we estimate such a premium under the Bates stochastic model\n(Bates [4]), which considers an underlying affected by both stochastic\nvolatility and random jumps. We propose an efficient method which improves the\nfinite-difference Monte Carlo (FDMC) approach introduced by de Graaf et al.\n[11]. In particular, the method we propose consists in replacing the Monte\nCarlo step of the FDMC approach with a finite difference step and the whole\nmethod relies on the efficient solution of two coupled partial\nintegro-differential equations (PIDE) which is done by employing the Hybrid\nTree-Finite Difference method developed by Briani et al. [6, 7, 8]. Moreover,\nthe direct application of the hybrid techniques in the original FDMC approach\nis also considered for comparison purposes. Several numerical tests prove the\neffectiveness and the reliability of the proposed approach when both European\nand American options are considered. \n\n"}
{"id": "1809.05643", "contents": "Title: Kernel-based collocation methods for Heath-Jarrow-Morton models with\n  Musiela parametrization Abstract: We propose kernel-based collocation methods for numerical solutions to\nHeath-Jarrow-Morton models with Musiela parametrization. The methods can be\nseen as the Euler-Maruyama approximation of some finite dimensional stochastic\ndifferential equations, and allow us to compute the derivative prices by the\nusual Monte Carlo methods. We derive a bound on the rate of convergence under\nsome decay condition on the inverse of the interpolation matrix and some\nregularity conditions on the volatility functionals. \n\n"}
{"id": "1809.06078", "contents": "Title: Stapp, Bohm and the Algebra of Process Abstract: Henry Stapp has made many significant contributions in quantum physics and\nits use in trying to understand the mind-matter relationship. I have been\ninfluenced by his use of the notion of {\\em process} to bring more clarity to\nunderstand quantum phenomena. In this paper I want to summarise the latest\nideas on the time development of quantum processes that relate the\ntransformation theory of Dirac, Feynman and Schwinger to the notion of weak\nvalues which has triggered experimental investigations of the nature of a\ndeeper underlying stochastic structure of quantum processes. \n\n"}
{"id": "1809.06400", "contents": "Title: Lorentz-violating extension of the spin-one Duffin-Kemmer-Petiau\n  equation Abstract: We investigate the breaking of Lorentz symmetry caused by the inclusion of an\nexternal four-vector via a Chern-Simons-like term in the Duffin-Kemmer-Petiau\nLagrangian for massless and massive spin-one fields. The resulting equations of\nmotion lead to the appearance of birefringence, where the corresponding photons\nare split into two propagation modes. We discuss the gauge invariance of the\nextended Lagrangian. Throughout the paper, we utilize projection operators to\nreduce the wave-functions to their physical components, and we provide many new\nproperties of these projection operators. \n\n"}
{"id": "1809.07727", "contents": "Title: Geometric Local Variance Gamma model Abstract: This paper describes another extension of the Local Variance Gamma model\noriginally proposed by P. Carr in 2008, and then further elaborated on by Carr\nand Nadtochiy, 2017 (CN2017), and Carr and Itkin, 2018 (CI2018). As compared\nwith the latest version of the model developed in CI2018 and called the ELVG\n(the Expanded Local Variance Gamma model), here we provide two innovations.\nFirst, in all previous papers the model was constructed based on a Gamma\ntime-changed {\\it arithmetic} Brownian motion: with no drift in CI2017, and\nwith drift in CI2018, and the local variance to be a function of the spot level\nonly. In contrast, here we develop a {\\it geometric} version of this model with\ndrift. Second, in CN2017 the model was calibrated to option smiles assuming the\nlocal variance is a piecewise constant function of strike, while in CI2018 the\nlocal variance is a piecewise linear} function of strike. In this paper we\nconsider 3 piecewise linear models: the local variance as a function of strike,\nthe local variance as function of log-strike, and the local volatility as a\nfunction of strike (so, the local variance is a piecewise quadratic function of\nstrike). We show that for all these new constructions it is still possible to\nderive an ordinary differential equation for the option price, which plays a\nrole of Dupire's equation for the standard local volatility model, and,\nmoreover, it can be solved in closed form. Finally, similar to CI2018, we show\nthat given multiple smiles the whole local variance/volatility surface can be\nrecovered which does not require solving any optimization problem. Instead, it\ncan be done term-by-term by solving a system of non-linear algebraic equations\nfor each maturity which is fast. \n\n"}
{"id": "1809.08635", "contents": "Title: Exact Solutions for a GBM-type Stochastic Volatility Model having a\n  Stationary Distribution Abstract: We find various exact solutions for a new stochastic volatility (SV) model:\nthe transition probability density, European-style option values, and (when it\nexists) the martingale defect. This may represent the first example of an SV\nmodel combining exact solutions, GBM-type volatility noise, and a stationary\nvolatility density. \n\n"}
{"id": "1809.09466", "contents": "Title: Derivatives pricing using signature payoffs Abstract: We introduce signature payoffs, a family of path-dependent derivatives that\nare given in terms of the signature of the price path of the underlying asset.\nWe show that these derivatives are dense in the space of continuous payoffs, a\nresult that is exploited to quickly price arbitrary continuous payoffs. This\napproach to pricing derivatives is then tested with European options, American\noptions, Asian options, lookback options and variance swaps. As we show,\nsignature payoffs can be used to price these derivatives with very high\naccuracy. \n\n"}
{"id": "1809.10460", "contents": "Title: Sample Efficient Adaptive Text-to-Speech Abstract: We present a meta-learning approach for adaptive text-to-speech (TTS) with\nfew data. During training, we learn a multi-speaker model using a shared\nconditional WaveNet core and independent learned embeddings for each speaker.\nThe aim of training is not to produce a neural network with fixed weights,\nwhich is then deployed as a TTS system. Instead, the aim is to produce a\nnetwork that requires few data at deployment time to rapidly adapt to new\nspeakers. We introduce and benchmark three strategies: (i) learning the speaker\nembedding while keeping the WaveNet core fixed, (ii) fine-tuning the entire\narchitecture with stochastic gradient descent, and (iii) predicting the speaker\nembedding with a trained neural network encoder. The experiments show that\nthese approaches are successful at adapting the multi-speaker neural network to\nnew speakers, obtaining state-of-the-art results in both sample naturalness and\nvoice similarity with merely a few minutes of audio data from new speakers. \n\n"}
{"id": "1809.10812", "contents": "Title: Constraining small scale magnetic fields through plasma lensing:\n  Application to the Black widow eclipsing pulsar binary Abstract: In regions with strongly varying electron density, radio emission can be\nmagnified significantly by plasma lensing. In the presence of magnetic fields,\nmagnification in time and frequency will be different for two circular\npolarizations. We show how these effects can be used to measure or constrain\nthe magnetic field parallel to the line of sight, $B_\\parallel$, as well as its\nspatial structure, $\\sigma_{B_\\parallel}$, in the lensing region. In addition,\nwe discuss how generalized Faraday rotation can constrain the strength of the\nperpendicular field, $B_\\perp$. We attempt to make such measurements for the\nBlack Widow pulsar, PSR~B1957+20, in which plasma lensing was recently\ndiscovered. For this system, pressure equilibrium suggests $B\\gtrsim 20\\,$G at\nthe interface between the pulsar and companion winds, where the radio eclipse\nstarts and ends, and where most lensing occurs. We find no evidence for\nlarge-scale magnetic fields, with, on average, $B_\\parallel=0.02\\pm0.09\\,$G\nover the egress lensing region. From individual lensing events, we strongly\nconstrain small scale magnetic structure to $\\sigma_B<10\\,$mG, thus excluding\nscenarios with a strong but rapidly varying field. Finally, from the lack of\nreduction of average circular polarization in the same region, we rule out a\nstrong, quasi-transverse field. We cannot identify any plausible scenario in\nwhich a large magnetic field in this system is concealed, leaving the nature of\nthe interface between the pulsar and companion winds an enigma. Our method can\nbe applied to other sources showing plasma lensing, including other eclipsing\npulsars and fast radio bursts, to study the local properties of the magnetic\nfield. \n\n"}
{"id": "1810.00895", "contents": "Title: Non-uniformly flat affine algebraic hypersurfaces Abstract: The relationship between interpolation and separation properties of\nhypersurfaces in Bargmann-Fock spaces over $\\mathbb{C} ^n$ is not\nwell-understood except for $n=1$. We present four examples of smooth affine\nalgebraic hypersurfaces that are not uniformly flat, and show that exactly two\nof them are interpolating. \n\n"}
{"id": "1810.01116", "contents": "Title: Inverse Gaussian quadrature and finite normal-mixture approximation of\n  the generalized hyperbolic distribution Abstract: In this study, a numerical quadrature for the generalized inverse Gaussian\ndistribution is derived from the Gauss-Hermite quadrature by exploiting its\nrelationship with the normal distribution. The proposed quadrature is not\nGaussian, but it exactly integrates the polynomials of both positive and\nnegative orders. Using the quadrature, the generalized hyperbolic distribution\nis efficiently approximated as a finite normal variance-mean mixture.\nTherefore, the expectations under the distribution, such as cumulative\ndistribution function and European option price, are accurately computed as\nweighted sums of those under normal distributions. The generalized hyperbolic\nrandom variates are also sampled in a straightforward manner. The accuracy of\nthe methods is illustrated with numerical examples. \n\n"}
{"id": "1810.01165", "contents": "Title: Semi-supervised Text Regression with Conditional Generative Adversarial\n  Networks Abstract: Enormous online textual information provides intriguing opportunities for\nunderstandings of social and economic semantics. In this paper, we propose a\nnovel text regression model based on a conditional generative adversarial\nnetwork (GAN), with an attempt to associate textual data and social outcomes in\na semi-supervised manner. Besides promising potential of predicting\ncapabilities, our superiorities are twofold: (i) the model works with\nunbalanced datasets of limited labelled data, which align with real-world\nscenarios; and (ii) predictions are obtained by an end-to-end framework,\nwithout explicitly selecting high-level representations. Finally we point out\nrelated datasets for experiments and future research directions. \n\n"}
{"id": "1810.02390", "contents": "Title: On the First Hitting Time Density of an Ornstein-Uhlenbeck Process Abstract: In this paper, we study the classical problem of the first passage hitting\ndensity of an Ornstein--Uhlenbeck process. We give two complementary (forward\nand backward) formulations of this problem and provide semi-analytical\nsolutions for both. The corresponding problems are comparable in complexity. By\nusing the method of heat potentials, we show how to reduce these problems to\nlinear Volterra integral equations of the second kind. For small values of $t$,\nwe solve these equations analytically by using Abel equation approximation; for\nlarger $t$ we solve them numerically. We also provide a comparison with other\nknown methods for finding the hitting density of interest, and argue that our\nmethod has considerable advantages and provides additional valuable insights. \n\n"}
{"id": "1810.02529", "contents": "Title: Fast Super-Paramagnetic Clustering Abstract: We map stock market interactions to spin models to recover their hierarchical\nstructure using a simulated annealing based Super-Paramagnetic Clustering (SPC)\nalgorithm. This is directly compared to a modified implementation of a maximum\nlikelihood approach we call Fast Super-Paramagnetic Clustering (f-SPC). The\nmethods are first applied standard toy test-case problems, and then to a\ndata-set of 447 stocks traded on the New York Stock Exchange (NYSE) over 1249\ndays. The signal to noise ratio of stock market correlation matrices is briefly\nconsidered. Our result recover approximately clusters representative of\nstandard economic sectors and mixed ones whose dynamics shine light on the\nadaptive nature of financial markets and raise concerns relating to the\neffectiveness of industry based static financial market classification in the\nworld of real-time data analytics. A key result is that we show that f-SPC\nmaximum likelihood solutions converge to ones found within the\nSuper-Paramagnetic Phase where the entropy is maximum, and those solutions are\nqualitatively better for high dimensionality data-sets. \n\n"}
{"id": "1810.02639", "contents": "Title: Tropical moments of tropical Jacobians Abstract: Each metric graph has canonically associated to it a polarized real torus\ncalled its tropical Jacobian. A fundamental real-valued invariant associated to\neach polarized real torus is its tropical moment. We give an explicit and\nefficiently computable formula for the tropical moment of a tropical Jacobian\nin terms of potential theory on the underlying metric graph. We show that there\nexists a universal linear relation between the tropical moment, the tau\ninvariant, and the total length of a metric graph. We argue that this linear\nrelation is a non-archimedean analogue of a recent remarkable identity\nestablished by Wilms for invariants of compact Riemann surfaces. We also relate\nour work to the computation of heights attached to principally polarized\nabelian varieties. \n\n"}
{"id": "1810.03384", "contents": "Title: Sharp threshold phenomena in statistical physics Abstract: This text describes the content of the Takagi lectures given by the author in\nKyoto in 2017. The lectures present some aspects of the theory of sharp\nthresholds for boolean functions and its application to the study of phase\ntransitions in statistical physics. \n\n"}
{"id": "1810.03807", "contents": "Title: A Dichotomy Theorem for First-Fit Chain Partitions Abstract: First-Fit is a greedy algorithm for partitioning the elements of a poset into\nchains. Let $\\textrm{FF}(w,Q)$ be the maximum number of chains that First-Fit\nuses on a $Q$-free poset of width $w$. A result due to Bosek, Krawczyk, and\nMatecki states that $\\textrm{FF}(w,Q)$ is finite when $Q$ has width at most\n$2$. We describe a family of posets $\\mathcal{Q}$ and show that the following\ndichotomy holds: if $Q\\in\\mathcal{Q}$, then $\\textrm{FF}(w,Q) \\le 2^{c(\\log\nw)^2}$ for some constant $c$ depending only on $Q$, and if\n$Q\\not\\in\\mathcal{Q}$, then $\\textrm{FF}(w,Q) \\ge 2^w - 1$. \n\n"}
{"id": "1810.03814", "contents": "Title: SNAP: A semismooth Newton algorithm for pathwise optimization with\n  optimal local convergence rate and oracle properties Abstract: We propose a semismooth Newton algorithm for pathwise optimization (SNAP) for\nthe LASSO and Enet in sparse, high-dimensional linear regression. SNAP is\nderived from a suitable formulation of the KKT conditions based on Newton\nderivatives. It solves the semismooth KKT equations efficiently by actively and\ncontinuously seeking the support of the regression coefficients along the\nsolution path with warm start. At each knot in the path, SNAP converges locally\nsuperlinearly for the Enet criterion and achieves an optimal local convergence\nrate for the LASSO criterion, i.e., SNAP converges in one step at the cost of\ntwo matrix-vector multiplication per iteration. Under certain regularity\nconditions on the design matrix and the minimum magnitude of the nonzero\nelements of the target regression coefficients, we show that SNAP hits a\nsolution with the same signs as the regression coefficients and achieves a\nsharp estimation error bound in finite steps with high probability. The\ncomputational complexity of SNAP is shown to be the same as that of LARS and\ncoordinate descent algorithms per iteration. Simulation studies and real data\nanalysis support our theoretical results and demonstrate that SNAP is faster\nand accurate than LARS and coordinate descent algorithms. \n\n"}
{"id": "1810.04868", "contents": "Title: Lifting the Heston model Abstract: How to reconcile the classical Heston model with its rough counterpart? We\nintroduce a lifted version of the Heston model with n multi-factors, sharing\nthe same Brownian motion but mean reverting at different speeds. Our model\nnests as extreme cases the classical Heston model (when n = 1), and the rough\nHeston model (when n goes to infinity). We show that the lifted model enjoys\nthe best of both worlds: Markovianity and satisfactory fits of implied\nvolatility smiles for short maturities with very few parameters. Further, our\napproach speeds up the calibration time and opens the door to time-efficient\nsimulation schemes. \n\n"}
{"id": "1810.05094", "contents": "Title: Unbiased deep solvers for linear parametric PDEs Abstract: We develop several deep learning algorithms for approximating families of\nparametric PDE solutions. The proposed algorithms approximate solutions\ntogether with their gradients, which in the context of mathematical finance\nmeans that the derivative prices and hedging strategies are computed\nsimulatenously. Having approximated the gradient of the solution one can\ncombine it with a Monte-Carlo simulation to remove the bias in the deep network\napproximation of the PDE solution (derivative price). This is achieved by\nleveraging the Martingale Representation Theorem and combining the Monte Carlo\nsimulation with the neural network. The resulting algorithm is robust with\nrespect to quality of the neural network approximation and consequently can be\nused as a black-box in case only limited a priori information about the\nunderlying problem is available. We believe this is important as neural network\nbased algorithms often require fair amount of tuning to produce satisfactory\nresults. The methods are empirically shown to work for high-dimensional\nproblems (e.g. 100 dimensions). We provide diagnostics that shed light on\nappropriate network architectures. \n\n"}
{"id": "1810.06696", "contents": "Title: Predicting digital asset market based on blockchain activity data Abstract: Blockchain technology shows significant results and huge potential for\nserving as an interweaving fabric that goes through every industry and market,\nallowing decentralized and secure value exchange, thus connecting our\ncivilization like never before. The standard approach for asset value\npredictions is based on market analysis with an LSTM neural network. Blockchain\ntechnologies, however, give us access to vast amounts of public data, such as\nthe executed transactions and the account balance distribution. We explore\nwhether analyzing this data with modern Deep Leaning techniques results in\nhigher accuracies than the standard approach. During a series of experiments on\nthe Ethereum blockchain, we achieved $4$ times error reduction with blockchain\ndata than an LSTM approach with trade volume data. By utilizing blockchain\naccount distribution histograms, spatial dataset modeling, and a Convolutional\narchitecture, the error was reduced further by 26\\%. The proposed methodologies\nare implemented in an open source cryptocurrency prediction framework, allowing\nthem to be used in other analysis contexts. \n\n"}
{"id": "1810.08584", "contents": "Title: Reverse Quantum Annealing Approach to Portfolio Optimization Problems Abstract: We investigate a hybrid quantum-classical solution method to the\nmean-variance portfolio optimization problems. Starting from real financial\ndata statistics and following the principles of the Modern Portfolio Theory, we\ngenerate parametrized samples of portfolio optimization problems that can be\nrelated to quadratic binary optimization forms programmable in the analog\nD-Wave Quantum Annealer 2000Q. The instances are also solvable by an\nindustry-established Genetic Algorithm approach, which we use as a classical\nbenchmark. We investigate several options to run the quantum computation\noptimally, ultimately discovering that the best results in terms of expected\ntime-to-solution as a function of number of variables for the hardest instances\nset are obtained by seeding the quantum annealer with a solution candidate\nfound by a greedy local search and then performing a reverse annealing\nprotocol. The optimized reverse annealing protocol is found to be more than 100\ntimes faster than the corresponding forward quantum annealing on average. \n\n"}
{"id": "1810.08923", "contents": "Title: CNNPred: CNN-based stock market prediction using several data sources Abstract: Feature extraction from financial data is one of the most important problems\nin market prediction domain for which many approaches have been suggested.\nAmong other modern tools, convolutional neural networks (CNN) have recently\nbeen applied for automatic feature selection and market prediction. However, in\nexperiments reported so far, less attention has been paid to the correlation\namong different markets as a possible source of information for extracting\nfeatures. In this paper, we suggest a CNN-based framework with specially\ndesigned CNNs, that can be applied on a collection of data from a variety of\nsources, including different markets, in order to extract features for\npredicting the future of those markets. The suggested framework has been\napplied for predicting the next day's direction of movement for the indices of\nS&P 500, NASDAQ, DJI, NYSE, and RUSSELL markets based on various sets of\ninitial features. The evaluations show a significant improvement in\nprediction's performance compared to the state of the art baseline algorithms. \n\n"}
{"id": "1810.09112", "contents": "Title: Quantifying the Model Risk Inherent in the Calibration and Recalibration\n  of Option Pricing Models Abstract: We focus on two particular aspects of model risk: the inability of a chosen\nmodel to fit observed market prices at a given point in time (calibration\nerror) and the model risk due to recalibration of model parameters (in\ncontradiction to the model assumptions). In this context, we follow the\napproach of Glasserman and Xu (2014) and use relative entropy as a pre-metric\nin order to quantify these two sources of model risk in a common framework, and\nconsider the trade-offs between them when choosing a model and the frequency\nwith which to recalibrate to the market. We illustrate this approach applied to\nthe models of Black and Scholes (1973) and Heston (1993), using option data for\nApple (AAPL) and Google (GOOG). We find that recalibrating a model more\nfrequently simply shifts model risk from one type to another, without any\nsubstantial reduction of aggregate model risk. Furthermore, moving to a more\ncomplicated stochastic model is seen to be counterproductive if one requires a\nhigh degree of robustness, for example as quantified by a 99 percent quantile\nof aggregate model risk. \n\n"}
{"id": "1810.10132", "contents": "Title: Smoothed Online Optimization for Regression and Control Abstract: We consider Online Convex Optimization (OCO) in the setting where the costs\nare $m$-strongly convex and the online learner pays a switching cost for\nchanging decisions between rounds. We show that the recently proposed Online\nBalanced Descent (OBD) algorithm is constant competitive in this setting, with\ncompetitive ratio $3 + O(1/m)$, irrespective of the ambient dimension.\nAdditionally, we show that when the sequence of cost functions is\n$\\epsilon$-smooth, OBD has near-optimal dynamic regret and maintains strong\nper-round accuracy. We demonstrate the generality of our approach by showing\nthat the OBD framework can be used to construct competitive algorithms for a\nvariety of online problems across learning and control, including online\nvariants of ridge regression, logistic regression, maximum likelihood\nestimation, and LQR control. \n\n"}
{"id": "1810.10563", "contents": "Title: A Relaxed Optimization Approach for Cardinality-Constrained Portfolio\n  Optimization Abstract: A cardinality-constrained portfolio caps the number of stocks to be traded\nacross and within groups or sectors. These limitations arise from real-world\nscenarios faced by fund managers, who are constrained by transaction costs and\nclient preferences as they seek to maximize return and limit risk.\n  We develop a new approach to solve cardinality-constrained portfolio\noptimization problems, extending both Markowitz and conditional value at risk\n(CVaR) optimization models with cardinality constraints. We derive a continuous\nrelaxation method for the NP-hard objective, which allows for very efficient\nalgorithms with standard convergence guarantees for nonconvex problems. For\nsmaller cases, where brute force search is feasible to compute the globally\noptimal cardinality- constrained portfolio, the new approach finds the best\nportfolio for the cardinality-constrained Markowitz model and a very good local\nminimum for the cardinality-constrained CVaR model. For higher dimensions,\nwhere brute-force search is prohibitively expensive, we find feasible\nportfolios that are nearly as efficient as their non-cardinality constrained\ncounterparts. \n\n"}
{"id": "1810.11039", "contents": "Title: Geometrically Convergent Simulation of the Extrema of L\\'{e}vy Processes Abstract: We develop a novel approximate simulation algorithm for the joint law of the\nposition, the running supremum and the time of the supremum of a general L\\'evy\nprocess at an arbitrary finite time. We identify the law of the error in simple\nterms. We prove that the error decays geometrically in $L^p$ (for any $p\\geq\n1$) as a function of the computational cost, in contrast with the polynomial\ndecay for the approximations available in the literature. We establish a\ncentral limit theorem and construct non-asymptotic and asymptotic confidence\nintervals for the corresponding Monte Carlo estimator. We prove that the\nmultilevel Monte Carlo estimator has optimal computational complexity (i.e. of\norder $\\epsilon^{-2}$ if the mean squared error is at most $\\epsilon^2$) for\nlocally Lipschitz and barrier-type functionals of the triplet and develop an\nunbiased version of the estimator. We illustrate the performance of the\nalgorithm with numerical examples. \n\n"}
{"id": "1810.13248", "contents": "Title: High-order compact finite difference scheme for option pricing in\n  stochastic volatility with contemporaneous jump models Abstract: We extend the scheme developed in B. D\\\"uring, A. Pitkin, \"High-order compact\nfinite difference scheme for option pricing in stochastic volatility jump\nmodels\", 2019, to the so-called stochastic volatility with contemporaneous\njumps (SVCJ) model, derived by Duffie, Pan and Singleton. The performance of\nthe scheme is assessed through a number of numerical experiments, using\ncomparisons against a standard second-order central difference scheme. We\nobserve that the new high-order compact scheme achieves fourth order\nconvergence and discuss the effects on efficiency and computation time. \n\n"}
{"id": "1811.02028", "contents": "Title: A Splitting Strategy for the Calibration of Jump-Diffusion Models Abstract: We present a detailed analysis and implementation of a splitting strategy to\nidentify simultaneously the local-volatility surface and the jump-size\ndistribution from quoted European prices. The underlying model consists of a\njump-diffusion driven asset with time and price dependent volatility. Our\napproach uses a forward Dupire-type partial-integro-differential equations for\nthe option prices to produce a parameter-to-solution map. The ill-posed inverse\nproblem for such map is then solved by means of a Tikhonov-type convex\nregularization. The proofs of convergence and stability of the algorithm are\nprovided together with numerical examples that substantiate the robustness of\nthe method both for synthetic and real data. \n\n"}
{"id": "1811.02094", "contents": "Title: WIMPy Leptogenesis in extended Scotogenic Model Abstract: We address the possibility of realizing successful leptogenesis from dark\nmatter annihilations in the scotogenic model of neutrino masses to explain the\nsame order of magnitude abundance of dark matter and baryons in the present\nUniverse. After showing that the minimal model in this category cannot satisfy\nall these requirements, we study a minimal extension of this model and find\nthat the scale of leptogenesis can be as low as 5 TeV, lower than the one in\nvanilla leptogenesis scenario in scotogenic model along with the additional\nadvantage of explaining the baryon-dark matter coincidence. Due to such low\nscale, the model remains predictive at dark matter direct detection and rare\ndecay experiments looking for charged lepton flavor violating processes. \n\n"}
{"id": "1811.05140", "contents": "Title: Amplitude-Aware Lossy Compression for Quantum Circuit Simulation Abstract: Classical simulation of quantum circuits is crucial for evaluating and\nvalidating the design of new quantum algorithms. However, the number of quantum\nstate amplitudes increases exponentially with the number of qubits, leading to\nthe exponential growth of the memory requirement for the simulations. In this\npaper, we present a new data reduction technique to reduce the memory\nrequirement of quantum circuit simulations. We apply our amplitude-aware lossy\ncompression technique to the quantum state amplitude vector to trade the\ncomputation time and fidelity for memory space. The experimental results show\nthat our simulator only needs 1/16 of the original memory requirement to\nsimulate Quantum Fourier Transform circuits with 99.95% fidelity. The reduction\namount of memory requirement suggests that we could increase 4 qubits in the\nquantum circuit simulation comparing to the simulation without our technique.\nAdditionally, for some specific circuits, like Grover's search, we could\nincrease the simulation size by 18 qubits. \n\n"}
{"id": "1811.05640", "contents": "Title: Quasi-local energy from a Minkowski reference Abstract: The specification of energy for gravitating systems has been an unsettled\nissue since Einstein proposed his pseudotensor. It is now understood that\nenergy-momentum is \\emph{quasi-local} (associated with a closed 2-surface).\nHere we consider quasi-local proposals (including pseudotensors) in the\nLagrangian-Noether-Hamiltonian formulations. There are two ambiguities: (i)\nthere are many possible expressions, (ii) they depend on some non-dynamical\nstructure, e.g., a reference frame. The Hamiltonian approach gives a handle on\nboth problems. The Hamiltonian perspective helped us to make a remarkable\ndiscovery: with an isometric Minkowski reference a large class of\nexpressions---namely all those that agree with the Einstein pseudotensor's\nFreud superpotential to linear order---give a common quasi-local energy value.\nMoreover, with a best-matched reference on the boundary this is the Wang-Yau\nmass value. \n\n"}
{"id": "1811.05764", "contents": "Title: Space-time localisation for the dynamic $\\Phi^4_3$ model Abstract: We prove an a priori bound for solutions of the dynamic $\\Phi^4_3$ equation.\nThis bound provides a control on solutions on a compact space-time set only in\nterms of the realisation of the noise on an enlargement of this set, and it\ndoes not depend on any choice of space-time boundary conditions.\n  We treat the large and small scale behaviour of solutions with completely\ndifferent arguments. For small scales we use bounds akin to those presented in\nHairer's theory of regularity structures. We stress immediately that our proof\nis fully self-contained, but we give a detailed explanation of how our\narguments relate to Hairer's. For large scales we use a PDE argument based on\nthe maximum principle. Both regimes are connected by a solution-dependent\nregularisation procedure.\n  The fact that our bounds do not depend on space-time boundary conditions\nmakes them useful for the analysis of large scale properties of solutions. They\ncan for example be used in a compactness argument to construct solutions on the\nfull space and their invariant measures. \n\n"}
{"id": "1811.06173", "contents": "Title: Leveraging Financial News for Stock Trend Prediction with\n  Attention-Based Recurrent Neural Network Abstract: Stock market prediction is one of the most attractive research topic since\nthe successful prediction on the market's future movement leads to significant\nprofit. Traditional short term stock market predictions are usually based on\nthe analysis of historical market data, such as stock prices, moving averages\nor daily returns. However, financial news also contains useful information on\npublic companies and the market. Existing methods in finance literature exploit\nsentiment signal features, which are limited by not considering factors such as\nevents and the news context. We address this issue by leveraging deep neural\nmodels to extract rich semantic features from news text. In particular, a\nBidirectional-LSTM are used to encode the news text and capture the context\ninformation, self attention mechanism are applied to distribute attention on\nmost relative words, news and days. In terms of predicting directional changes\nin both Standard & Poor's 500 index and individual companies stock price, we\nshow that this technique is competitive with other state of the art approaches,\ndemonstrating the effectiveness of recent NLP technology advances for\ncomputational finance. \n\n"}
{"id": "1811.06630", "contents": "Title: Nudging Neural Conversational Model with Domain Knowledge Abstract: Neural conversation models are attractive because one can train a model\ndirectly on dialog examples with minimal labeling. With a small amount of data,\nhowever, they often fail to generalize over test data since they tend to\ncapture spurious features instead of semantically meaningful domain knowledge.\nTo address this issue, we propose a novel approach that allows any human\nteachers to transfer their domain knowledge to the conversation model in the\nform of natural language rules. We tested our method with three different\ndialog datasets. The improved performance across all domains demonstrates the\nefficacy of our proposed method. \n\n"}
{"id": "1811.07792", "contents": "Title: The ETS challenges: a machine learning approach to the evaluation of\n  simulated financial time series for improving generation processes Abstract: This paper presents an evaluation framework that attempts to quantify the\n\"degree of realism\" of simulated financial time series, whatever the simulation\nmethod could be, with the aim of discover unknown characteristics that are not\nbeing properly reproduced by such methods in order to improve them. For that\npurpose, the evaluation framework is posed as a machine learning problem in\nwhich some given time series examples have to be classified as simulated or\nreal financial time series. The \"challenge\" is proposed as an open competition,\nsimilar to those published at the Kaggle platform, in which participants must\nsend their classification results along with a description of the features and\nthe classifiers used. The results of these \"challenges\" have revealed some\ninteresting properties of financial data, and have lead to substantial\nimprovements in our simulation methods under research, some of which will be\ndescribed in this work. \n\n"}
{"id": "1811.08726", "contents": "Title: Neural Network for CVA: Learning Future Values Abstract: A new challenge to quantitative finance after the recent financial crisis is\nthe study of credit valuation adjustment (CVA), which requires modeling of the\nfuture values of a portfolio. In this paper, following recent work in [Weinan\nE(2017), Han(2017)], we apply deep learning to attack this problem. The future\nvalues are parameterized by neural networks, and the parameters are then\ndetermined through optimization. Two concrete products are studied: Bermudan\nswaption and Mark-to-Market cross-currency swap. We obtain their expected\npositive/negative exposures, and further study the resulting functional form of\nfuture values. Such an approach represents a new framework for modeling XVA,\nand it also sheds new lights on other methods like American Monte Carlo. \n\n"}
{"id": "1811.08782", "contents": "Title: Solving Nonlinear and High-Dimensional Partial Differential Equations\n  via Deep Learning Abstract: In this work we apply the Deep Galerkin Method (DGM) described in Sirignano\nand Spiliopoulos (2018) to solve a number of partial differential equations\nthat arise in quantitative finance applications including option pricing,\noptimal execution, mean field games, etc. The main idea behind DGM is to\nrepresent the unknown function of interest using a deep neural network. A key\nfeature of this approach is the fact that, unlike other commonly used numerical\napproaches such as finite difference methods, it is mesh-free. As such, it does\nnot suffer (as much as other numerical methods) from the curse of\ndimensionality associated with highdimensional PDEs and PDE systems. The main\ngoals of this paper are to elucidate the features, capabilities and limitations\nof DGM by analyzing aspects of its implementation for a number of different\nPDEs and PDE systems. Additionally, we present: (1) a brief overview of PDEs in\nquantitative finance along with numerical methods for solving them; (2) a brief\noverview of deep learning and, in particular, the notion of neural networks;\n(3) a discussion of the theoretical foundations of DGM with a focus on the\njustification of why this method is expected to perform well. \n\n"}
{"id": "1811.08794", "contents": "Title: Cobordisms of global quotient orbifolds and an equivariant\n  Pontrjagin-Thom construction Abstract: We introduce an equivariant Pontrjagin-Thom construction which identifies\nequivariant cohomotopy classes with certain fixed point bordism classes. This\nprovides a concrete geometric model for equivariant cohomotopy which works for\nany compact Lie group G. In the special case when G is finite or a torus, we\nshow that our construction recovers the construction of Wasserman, providing a\nnew perspective on equivariant bordism. We connect the results with bordisms of\nglobal quotient orbifolds, utilizing the machinery of Gepner-Henriques to\ndescribe bordisms of framed orbifolds in terms of equivariant cohomotopy. We\nalso illustrate the utility of the theory by applying our results to M-theory,\nthus connecting with recent work of Huerta, Sati and Schreiber. \n\n"}
{"id": "1811.09288", "contents": "Title: Common nonlinear features and spin-orbit coupling effects in the Zeeman\n  splitting of novel wurtzite materials Abstract: The response of semiconductor materials to external magnetic fields is a\nreliable approach to probe intrinsic electronic and spin-dependent properties.\nIn this study, we investigate the common Zeeman splitting features of novel\nwurtzite materials, namely InP, InAs, and GaAs. We present values for the\neffective g-factors of different energy bands and show that spin-orbit coupling\neffects, responsible for the spin splittings, also have noticeable\ncontributions to the g-factors. Within the Landau level picture, we show that\nthe nonlinear Zeeman splitting recently explained in magneto photoluminescence\nexperiments for InP nanowires by Tedeschi et al. [Phys. Rev. B 99, 161204\n(2019)] are also present in InAs, GaAs and even in the conventional GaN. Such\nnonlinear features stem from the peculiar coupling of the A and B valence\nbands, as a consequence of the interplay between the wurtzite crystal symmetry\nand the breaking of time-reversal symmetry by the external magnetic field.\nMoreover, we develop an analytical model to describe the experimental nonlinear\nZeeman splitting and apply it to InP and GaAs data. Extrapolating our fitted\nresults, we found that the Zeeman splitting of InP reaches a maximum value,\nwhich is a prediction that could be probed at higher magnetic fields. \n\n"}
{"id": "1811.09549", "contents": "Title: Idiosyncrasies and challenges of data driven learning in electronic\n  trading Abstract: We outline the idiosyncrasies of neural information processing and machine\nlearning in quantitative finance. We also present some of the approaches we\ntake towards solving the fundamental challenges we face. \n\n"}
{"id": "1811.10041", "contents": "Title: BDLOB: Bayesian Deep Convolutional Neural Networks for Limit Order Books Abstract: We showcase how dropout variational inference can be applied to a large-scale\ndeep learning model that predicts price movements from limit order books\n(LOBs), the canonical data source representing trading and pricing movements.\nWe demonstrate that uncertainty information derived from posterior predictive\ndistributions can be utilised for position sizing, avoiding unnecessary trades\nand improving profits. Further, we test our models by using millions of\nobservations across several instruments and markets from the London Stock\nExchange. Our results suggest that those Bayesian techniques not only deliver\nuncertainty information that can be used for trading but also improve\npredictive performance as stochastic regularisers. To the best of our\nknowledge, we are the first to apply Bayesian networks to LOBs. \n\n"}
{"id": "1811.10195", "contents": "Title: Bull Bear Balance: A Cluster Analysis of Socially Informed Financial\n  Volatility Abstract: Using a method rooted in information theory, we present results that have\nidentified a large set of stocks for which social media can be informative\nregarding financial volatility. By clustering stocks based on the joint feature\nsets of social and financial variables, our research provides an important\ncontribution by characterizing the conditions in which social media signals can\nlead financial volatility. The results indicate that social media is most\ninformative about financial market volatility when the ratio of bullish to\nbearish sentiment is high, even when the number of messages is low. The\nrobustness of these findings is verified across 500 stocks from both NYSE and\nNASDAQ exchanges. The reported results are reproducible via an open-source\nlibrary for social-financial analysis made freely available. \n\n"}
{"id": "1811.10807", "contents": "Title: Mirror theorems for root stacks and relative pairs Abstract: Given a smooth projective variety $X$ with a smooth nef divisor $D$ and a\npositive integer $r$, we construct an $I$-function, an explicit slice of\nGivental's Lagrangian cone, for Gromov--Witten theory of the root stack\n$X_{D,r}$. As an application, we also obtain an $I$-function for relative\nGromov--Witten theory following the relation between relative and orbifold\nGromov--Witten invariants. \n\n"}
{"id": "1811.11287", "contents": "Title: Lagged correlation-based deep learning for directional trend change\n  prediction in financial time series Abstract: Trend change prediction in complex systems with a large number of noisy time\nseries is a problem with many applications for real-world phenomena, with stock\nmarkets as a notoriously difficult to predict example of such systems. We\napproach predictions of directional trend changes via complex lagged\ncorrelations between them, excluding any information about the target series\nfrom the respective inputs to achieve predictions purely based on such\ncorrelations with other series. We propose the use of deep neural networks that\nemploy step-wise linear regressions with exponential smoothing in the\npreparatory feature engineering for this task, with regression slopes as trend\nstrength indicators for a given time interval. We apply this method to\nhistorical stock market data from 2011 to 2016 as a use case example of lagged\ncorrelations between large numbers of time series that are heavily influenced\nby externally arising new information as a random factor. The results\ndemonstrate the viability of the proposed approach, with state-of-the-art\naccuracies and accounting for the statistical significance of the results for\nadditional validation, as well as important implications for modern financial\neconomics. \n\n"}
{"id": "1811.11812", "contents": "Title: Post-Newtonian Dynamics in Dense Star Clusters: Binary Black Holes in\n  the LISA Band Abstract: The dynamical processing of black holes in the dense cores of globular\nclusters (GCs), makes them efficient factories for producing binary black holes\n(BBHs). Here we explore the population of BBHs that form dynamically in GCs and\nmay be observable at mHz frequencies or higher with LISA. We use our Monte\nCarlo stellar dynamics code, which includes gravitational radiation reaction\neffects for all BH encounters. By creating a representative local universe of\nGCs, we show that up to dozens of these systems may be resolvable by LISA with\nsignal-to-noise ratios of at least 5. Approximately one third of these binaries\nwill have measurable eccentricities ($e > 10^{-3}$) in the LISA band and a\nsmall number ($\\lesssim 5$) may evolve from the LISA band to the LIGO band\nduring the LISA mission. \n\n"}
{"id": "1811.11965", "contents": "Title: RCW 120: A possible case of hit and run, elucidated by multi temperature\n  dust mapping Abstract: We present resolution-enhanced images of warm dust at multiple temperatures\nand opacity index values in the star-forming bubble/HII region, RCW 120. The\nimage set, representing a 4D hypercube of differential column density, was\nobtained using our Bayesian procedure, ppmap. The cool peripheral material\n($\\sim16$-22 K) exhibits ragged clumpy structure as noted previously by others.\nHowever, at higher temperatures ($\\stackrel{>}{_\\sim}26$ K) the geometry\nchanges dramatically, showing a bubble boundary which is accurately circular in\nprojection, except for the previously-reported opening in the north. Comparison\nwith Spitzer 8 $\\mu$m data suggests that the $\\sim26$-30 K dust seen by\nHerschel resides in the photodissociation region (PDR) surrounding the HII\nregion. Its projected radial profile is consistent with that of a spherical\nshell, thus arguing against previous suggestions of cylindrical or planar\ngeometry. The inferred geometry is, in fact, consistent with previous\ninterpretations of the HII region as a classical Str\\\"omgren sphere, except for\nthe fact that the ionising star (CD -38.11636; O8V) is displaced by more than\nhalf a radius from its geometric centre. None of the previously published\nmodels has satisfactorily accounted for that displacement. It could, however,\nbe explained by proper motion of the O star at $\\sim2$-4 km s$^{-1}$ since its\nformation, possibly due to a cloud-cloud collision. We suggest that the current\nspherical bubble constitutes the fossilised remnant of the initial expansion of\nthe HII region following the formation of the star, which now continues to flee\nits formation site. \n\n"}
{"id": "1812.02166", "contents": "Title: On unbalanced Boolean functions with best correlation immunity Abstract: It is known that the order of correlation immunity of a nonconstant\nunbalanced Boolean function in $n$ variables cannot exceed $2n/3-1$; moreover,\nit is $2n/3-1$ if and only if the function corresponds to an equitable\n$2$-partition of the $n$-cube with an eigenvalue $-n/3$ of the quotient matrix.\nThe known series of such functions have proportion $1:3$, $3:5$, or $7:9$ of\nthe number of ones and zeros. We prove that if a nonconstant unbalanced Boolean\nfunction attains the correlation-immunity bound and has ratio $C:B$ of the\nnumber of ones and zeros, then $CB$ is divisible by $3$. In particular, this\nproves the nonexistence of equitable partitions for an infinite series of\nputative quotient matrices. We also establish that there are exactly $2$\nequivalence classes of the equitable partitions of the $12$-cube with quotient\nmatrix $[[3,9],[7,5]]$ and $16$ classes, with $[[0,12],[4,8]]$. These\nparameters correspond to the Boolean functions in $12$ variables with\ncorrelation immunity $7$ and proportion $7:9$ and $1:3$, respectively (the case\n$3:5$ remains unsolved). This also implies the characterization of the\northogonal arrays OA$(1024,12,2,7)$ and OA$(512,11,2,6)$. \n\n"}
{"id": "1812.02340", "contents": "Title: Continual Learning Augmented Investment Decisions Abstract: Investment decisions can benefit from incorporating an accumulated knowledge\nof the past to drive future decision making. We introduce Continual Learning\nAugmentation (CLA) which is based on an explicit memory structure and a feed\nforward neural network (FFNN) base model and used to drive long term financial\ninvestment decisions. We demonstrate that our approach improves accuracy in\ninvestment decision making while memory is addressed in an explainable way. Our\napproach introduces novel remember cues, consisting of empirically learned\nchange points in the absolute error series of the FFNN. Memory recall is also\nnovel, with contextual similarity assessed over time by sampling distances\nusing dynamic time warping (DTW). We demonstrate the benefits of our approach\nby using it in an expected return forecasting task to drive investment\ndecisions. In an investment simulation in a broad international equity universe\nbetween 2003-2017, our approach significantly outperforms FFNN base models. We\nalso illustrate how CLA's memory addressing works in practice, using a worked\nexample to demonstrate the explainability of our approach. \n\n"}
{"id": "1812.04486", "contents": "Title: Trade Selection with Supervised Learning and OCA Abstract: In recent years, state-of-the-art methods for supervised learning have\nexploited increasingly gradient boosting techniques, with mainstream efficient\nimplementations such as xgboost or lightgbm. One of the key points in\ngenerating proficient methods is Feature Selection (FS). It consists in\nselecting the right valuable effective features. When facing hundreds of these\nfeatures, it becomes critical to select best features. While filter and\nwrappers methods have come to some maturity, embedded methods are truly\nnecessary to find the best features set as they are hybrid methods combining\nfeatures filtering and wrapping. In this work, we tackle the problem of finding\nthrough machine learning best a priori trades from an algorithmic strategy. We\nderive this new method using coordinate ascent optimization and using block\nvariables. We compare our method to Recursive Feature Elimination (RFE) and\nBinary Coordinate Ascent (BCA). We show on a real life example the capacity of\nthis method to select good trades a priori. Not only this method outperforms\nthe initial trading strategy as it avoids taking loosing trades, it also\nsurpasses other method, having the smallest feature set and the highest score\nat the same time. The interest of this method goes beyond this simple trade\nclassification problem as it is a very general method to determine the optimal\nfeature set using some information about features relationship as well as using\ncoordinate ascent optimization. \n\n"}
{"id": "1812.05158", "contents": "Title: Interference-induced localization in quantum random walk on clean cyclic\n  graph Abstract: We quantitatively differentiate between the spreads of discrete-time quantum\nand classical random walks on a cyclic graph. Due to the closed nature of any\ncyclic graph, there is additional \"collision\"- like interference in the quantum\nrandom walk along with the usual interference in any such walk on any graph,\nclosed or otherwise. We find that the quantum walker remains localized in\ncomparison to the classical one, even in the absence of disorder, a phenomenon\nthat is potentially attributable to the additional interference in the quantum\ncase. This is to be contrasted with the situation on open graphs, where the\nquantum walker, being effectively denied the collision-like interference,\ngarners a much higher spread than its classical counterpart. We use Shannon\nentropy of the position probability distribution to quantify spread of the\nwalker in both quantum and classical cases. We find that for a given number of\nvertices on a cyclic graph, the entropy with respect to number of steps for the\nquantum walker saturates, on average, to a value lower than that for the\ncorresponding classical one. We also analyze variations of the entropies with\nrespect to system size, and look at the corresponding asymptotic growth rates. \n\n"}
{"id": "1812.05315", "contents": "Title: Calibrating rough volatility models: a convolutional neural network\n  approach Abstract: In this paper we use convolutional neural networks to find the H\\\"older\nexponent of simulated sample paths of the rBergomi model, a recently proposed\nstock price model used in mathematical finance. We contextualise this as a\ncalibration problem, thereby providing a very practical and useful application. \n\n"}
{"id": "1812.05916", "contents": "Title: Deep neural networks algorithms for stochastic control problems on\n  finite horizon: numerical applications Abstract: This paper presents several numerical applications of deep learning-based\nalgorithms that have been introduced in [HPBL18]. Numerical and comparative\ntests using TensorFlow illustrate the performance of our different algorithms,\nnamely control learning by performance iteration (algorithms NNcontPI and\nClassifPI), control learning by hybrid iteration (algorithms Hybrid-Now and\nHybrid-LaterQ), on the 100-dimensional nonlinear PDEs examples from [EHJ17] and\non quadratic backward stochastic differential equations as in [CR16]. We also\nperformed tests on low-dimension control problems such as an option hedging\nproblem in finance, as well as energy storage problems arising in the valuation\nof gas storage and in microgrid management. Numerical results and comparisons\nto quantization-type algorithms Qknn, as an efficient algorithm to numerically\nsolve low-dimensional control problems, are also provided; and some\ncorresponding codes are available on https://github.com/comeh/. \n\n"}
{"id": "1812.06600", "contents": "Title: Double Deep Q-Learning for Optimal Execution Abstract: Optimal trade execution is an important problem faced by essentially all\ntraders. Much research into optimal execution uses stringent model assumptions\nand applies continuous time stochastic control to solve them. Here, we instead\ntake a model free approach and develop a variation of Deep Q-Learning to\nestimate the optimal actions of a trader. The model is a fully connected Neural\nNetwork trained using Experience Replay and Double DQN with input features\ngiven by the current state of the limit order book, other trading signals, and\navailable execution actions, while the output is the Q-value function\nestimating the future rewards under an arbitrary action. We apply our model to\nnine different stocks and find that it outperforms the standard benchmark\napproach on most stocks using the measures of (i) mean and median\nout-performance, (ii) probability of out-performance, and (iii) gain-loss\nratios. \n\n"}
{"id": "1812.08533", "contents": "Title: Hierarchical adaptive sparse grids and quasi Monte Carlo for option\n  pricing under the rough Bergomi model Abstract: The rough Bergomi (rBergomi) model, introduced recently in [5], is a\npromising rough volatility model in quantitative finance. It is a parsimonious\nmodel depending on only three parameters, and yet remarkably fits with\nempirical implied volatility surfaces. In the absence of analytical European\noption pricing methods for the model, and due to the non-Markovian nature of\nthe fractional driver, the prevalent option is to use the Monte Carlo (MC)\nsimulation for pricing. Despite recent advances in the MC method in this\ncontext, pricing under the rBergomi model is still a time-consuming task. To\novercome this issue, we have designed a novel, hierarchical approach, based on\ni) adaptive sparse grids quadrature (ASGQ), and ii) quasi-Monte Carlo (QMC).\nBoth techniques are coupled with a Brownian bridge construction and a\nRichardson extrapolation on the weak error. By uncovering the available\nregularity, our hierarchical methods demonstrate substantial computational\ngains with respect to the standard MC method, when reaching a sufficiently\nsmall relative error tolerance in the price estimates across different\nparameter constellations, even for very small values of the Hurst parameter.\nOur work opens a new research direction in this field, i.e., to investigate the\nperformance of methods other than Monte Carlo for pricing and calibrating under\nthe rBergomi model. \n\n"}
{"id": "1812.09248", "contents": "Title: Trigonal deformations of rank one and Jacobians Abstract: In this paper we study the infinitesimal deformations of a trigonal curve\nthat preserve the trigonal series and such that the associate infinitesimal\nvariation of Hodge structure (IVHS) is of rank 1. We show that if the genus g\nis greater or equal to 8 or g=6,7 and the curve is Maroni general, this locus\nis zero dimensional. Moreover, we complete a result of Naranjo and Pirola. We\nshow in fact that if the genus g is greater or equal to 6, the hyperelliptic\nlocus is the only 2g-1-dimensional sub-locus Y of the moduli space of curves of\ngenus g, such that for the general element [C] in Y, its Jacobian J(C) is\ndominated by a hyperelliptic Jacobian of genus g' greater or equal to g. \n\n"}
{"id": "1812.09472", "contents": "Title: Big Bang nucleosynthesis in a weakly non-ideal plasma Abstract: We propose a correction of the standard Big Bang nucleosynthesis (BBN)\nscenario to resolve the primordial lithium problem by considering a possibility\nthat the primordial plasma can deviate from the ideal state. In the standard\nBBN, the primordial plasma is assumed to be ideal, with particles and photons\nsatisfying the Maxwell-Boltzmann and Planck distribution, respectively. We\nsuggest that this assumption of the primordial plasma being ideal might\noversimplify the early Universe and cause the lithium problem. We find that\ndeviation of photon distribution from the Planck distribution, which is\nparameterised with the help of Tsallis statistics, can resolve the primordial\nlithium problem when the particle distributions of the primordial plasma still\nfollow the MaxwellBoltzmann distribution. We discuss how the primordial plasma\ncan be weakly non-ideal in this specific fashion and its effects on the cosmic\nevolution. \n\n"}
{"id": "1812.09904", "contents": "Title: A volatility-of-volatility expansion of the option prices in the SABR\n  stochastic volatility model Abstract: We propose a general, very fast method to quickly approximate the solution of\na parabolic Partial Differential Equation (PDEs) with explicit formulas. Our\nmethod also provides equaly fast approximations of the derivatives of the\nsolution, which is a challenge for many other methods. Our approach is based on\na computable series expansion in terms of a \"small\" parameter. As an example,\nwe treat in detail the important case of the SABR PDE for $\\beta = 1$, namely\n$\\partial_{\\tau}u = \\sigma^2 \\big [ \\frac{1}{2} (\\partial^2_xu - \\partial_xu) +\n\\nu \\rho \\partial_x\\partial_\\sigma u + \\frac{1}{2} \\nu^2 \\partial^2_\\sigma u \\,\n\\big ] + \\kappa (\\theta - \\sigma) \\partial_\\sigma$, by choosing $\\nu$ as small\nparameter. This yields $u = u_0 + \\nu u_1 + \\nu^2 u_2 + \\ldots$, with $u_j$\nindependent of $\\nu$. The terms $u_j$ are explicitly computable, which is also\na challenge for many other, related methods. Truncating this expansion leads to\ncomputable approximations of $u$ that are in \"closed form,\" and hence can be\nevaluated very quickly. Most of the other related methods use the \"time\" $\\tau$\nas a small parameter. The advantage of our method is that it leads to shorter\nand hence easier to determine and to generalize formulas. We obtain also an\nexplicit expansion for the implied volatility in the SABR model in terms of\n$\\nu$, similar to Hagan's formula, but including also the {\\em mean reverting\nterm.} We provide several numerical tests that show the performance of our\nmethod. In particular, we compare our formula to the one due to Hagan. Our\nresults also behave well when used for actual market data and show the mean\nreverting property of the volatility. \n\n"}
{"id": "1812.10738", "contents": "Title: Revisiting pattern avoidance and quasisymmetric functions Abstract: Let S_n be the nth symmetric group. Given a set of permutations Pi we denote\nby S_n(Pi) the set of permutations in S_n which avoid Pi in the sense of\npattern avoidance. Consider the generating function Q_n(Pi) = sum_pi F_{Des pi}\nwhere the sum is over all pi in S_n(Pi) and F_{Des pi} is the fundamental\nquasisymmetric function corresponding to the descent set of pi. Hamaker,\nPawlowski, and Sagan introduced Q_n(Pi) and studied its properties, in\nparticular, finding criteria for when this quasisymmetric function is symmetric\nor even Schur nonnegative for all n >= 0. The purpose of this paper is to\ncontinue their investigation answering some of their questions, proving one of\ntheir conjectures, as well as considering other natural questions about\nQ_n(Pi). In particular we look at Pi of small cardinality, superstandard hooks,\npartial shuffles, Knuth classes, and a stability property. \n\n"}
{"id": "1812.10752", "contents": "Title: How to avoid the zero-power trap in testing for correlation Abstract: In testing for correlation of the errors in regression models the power of\ntests can be very low for strongly correlated errors. This counterintuitive\nphenomenon has become known as the \"zero-power trap\". Despite a considerable\namount of literature devoted to this problem, mainly focusing on its detection,\na convincing solution has not yet been found. In this article we first discuss\ntheoretical results concerning the occurrence of the zero-power trap\nphenomenon. Then, we suggest and compare three ways to avoid it. Given an\ninitial test that suffers from the zero-power trap, the method we recommend for\npractice leads to a modified test whose power converges to one as the\ncorrelation gets very strong. Furthermore, the modified test has approximately\nthe same power function as the initial test, and thus approximately preserves\nall of its optimality properties. We also provide some numerical illustrations\nin the context of testing for network generated correlation. \n\n"}
{"id": "1901.00967", "contents": "Title: Enhanced Fulde-Ferrell-Larkin-Ovchinnikov and Sarma superfluid states\n  near an orbital Feshbach resonance Abstract: We investigate the inhomogeneous Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) and\nhomogeneous Sarma superfluid states in alkaline-earth-like $^{173}$Yb atomic\ngases near an orbital Feshbach resonance at zero temperature with population\nimbalances in both the open and closed channels (or bands). We find that in\nhomogeneous space by adjusting the open-channel Zeeman energy $h_o$, both the\nSarma and Fulde-Ferrell superfluid states are greatly enhanced by the\nspin-exchange interaction while the closed-channel Zeeman energy $h_c$ remains\nsmall. In the presence of an external harmonic trap, the trapped gas features a\nshell structure of separated phases, where the Sarma phase leaves detectable\nvalley structure in the columnar-integrated momentum distribution, and the\nFulde-Ferrell state acquires enhanced spatial anisotropy. As both signatures\ncan be easily detected in time-of-flight images, our findings are helpful to\nrealize and detect the long-sought FFLO and Sarma superfluid states at the same\ntime in experiments. \n\n"}
{"id": "1901.02404", "contents": "Title: GILT: Generating Images from Long Text Abstract: Creating an image reflecting the content of a long text is a complex process\nthat requires a sense of creativity. For example, creating a book cover or a\nmovie poster based on their summary or a food image based on its recipe. In\nthis paper we present the new task of generating images from long text that\ndoes not describe the visual content of the image directly. For this, we build\na system for generating high-resolution 256 $\\times$ 256 images of food\nconditioned on their recipes. The relation between the recipe text (without its\ntitle) to the visual content of the image is vague, and the textual structure\nof recipes is complex, consisting of two sections (ingredients and\ninstructions) both containing multiple sentences.\n  We used the recipe1M dataset to train and evaluate our model that is based on\na the StackGAN-v2 architecture. \n\n"}
{"id": "1901.02787", "contents": "Title: On Secure Network Coding for Multiple Unicast Traffic Abstract: This paper investigates the problem of secure communication in a wireline\nnoiseless scenario where a source wishes to communicate to a number of\ndestinations in the presence of a passive external adversary. Different from\nthe multicast scenario, where all destinations are interested in receiving the\nsame message, in this setting different destinations are interested in\ndifferent messages. The main focus of this paper is on characterizing the\nsecure capacity region, when the adversary has unbounded computational\ncapabilities, but limited network presence. First, an outer bound on the secure\ncapacity region is derived for arbitrary network topologies and general number\nof destinations. Then, secure transmission schemes are designed and analyzed in\nterms of achieved rate performance. In particular, for the case of two\ndestinations, it is shown that the designed scheme matches the outer bound,\nhence characterizing the secure capacity region. It is also numerically\nverified that the designed scheme matches the outer bound for a special class\nof networks with general number of destinations, referred to as combination\nnetwork. Finally, for an arbitrary network topology with general number of\ndestinations, a two-phase polynomial time in the network size scheme is\ndesigned and its rate performance {is} compared with the capacity-achieving\nscheme for networks with two destinations. \n\n"}
{"id": "1901.03478", "contents": "Title: Deep Learning for Ranking Response Surfaces with Applications to Optimal\n  Stopping Problems Abstract: In this paper, we propose deep learning algorithms for ranking response\nsurfaces, with applications to optimal stopping problems in financial\nmathematics. The problem of ranking response surfaces is motivated by\nestimating optimal feedback policy maps in stochastic control problems, aiming\nto efficiently find the index associated to the minimal response across the\nentire continuous input space $\\mathcal{X} \\subseteq \\mathbb{R}^d$. By\nconsidering points in $\\mathcal{X}$ as pixels and indices of the minimal\nsurfaces as labels, we recast the problem as an image segmentation problem,\nwhich assigns a label to every pixel in an image such that pixels with the same\nlabel share certain characteristics. This provides an alternative method for\nefficiently solving the problem instead of using sequential design in our\nprevious work [R. Hu and M. Ludkovski, SIAM/ASA Journal on Uncertainty\nQuantification, 5 (2017), 212--239].\n  Deep learning algorithms are scalable, parallel and model-free, i.e., no\nparametric assumptions needed on the response surfaces. Considering ranking\nresponse surfaces as image segmentation allows one to use a broad class of deep\nneural networks, e.g., UNet, SegNet, DeconvNet, which have been widely applied\nand numerically proved to possess high accuracy in the field. We also\nsystematically study the dependence of deep learning algorithms on the input\ndata generated on uniform grids or by sequential design sampling, and observe\nthat the performance of deep learning is {\\it not} sensitive to the noise and\nlocations (close to/away from boundaries) of training data. We present a few\nexamples including synthetic ones and the Bermudan option pricing problem to\nshow the efficiency and accuracy of this method. \n\n"}
{"id": "1901.04200", "contents": "Title: Remarks on stochastic automatic adjoint differentiation and financial\n  models calibration Abstract: In this work, we discuss the Automatic Adjoint Differentiation (AAD) for\nfunctions of the form $G=\\frac{1}{2}\\sum_1^m (Ey_i-C_i)^2$, which often appear\nin the calibration of stochastic models. { We demonstrate that it allows a\nperfect SIMD\\footnote{Single Input Multiple Data} parallelization and provide\nits relative computational cost. In addition we demonstrate that this\ntheoretical result is in concordance with numeric experiments.} \n\n"}
{"id": "1901.05514", "contents": "Title: Assessing molecular simulation for the analysis of lipid monolayer\n  reflectometry Abstract: Using molecular simulation to aid in the analysis of neutron reflectometry\nmeasurements is commonplace. However, reflectometry is a tool to probe\nlarge-scale structures, and therefore the use of all-atom simulation may be\nirrelevant. This work presents the first direct comparison between the\nreflectometry profiles obtained from different all-atom and coarse-grained\nmolecular dynamics simulations. These are compared with a traditional model\nlayer structure analysis method to determine the minimum simulation resolution\nrequired to accurately reproduce experimental data. We find that systematic\nlimits reduce the efficacy of the MARTINI potential model, while the Berger\nunited-atom and Slipids all-atom potential models agree similarly well with the\nexperimental data. The model layer structure gives the best agreement, however,\nthe higher resolution simulation-dependent methods produce an agreement that is\ncomparable. Finally, we use the atomistic simulation to advise on possible\nimprovements that may be offered to the model layer structures, creating a more\nrealistic monolayer model. \n\n"}
{"id": "1901.06021", "contents": "Title: A Probabilistic Approach to Nonparametric Local Volatility Abstract: The local volatility model is a widely used for pricing and hedging financial\nderivatives. While its main appeal is its capability of reproducing any given\nsurface of observed option prices---it provides a perfect fit---the essential\ncomponent is a latent function which can be uniquely determined only in the\nlimit of infinite data. To (re)construct this function, numerous calibration\nmethods have been suggested involving steps of interpolation and extrapolation,\nmost often of parametric form and with point-estimate representations. We look\nat the calibration problem in a probabilistic framework with a nonparametric\napproach based on a Gaussian process prior. This immediately gives a way of\nencoding prior beliefs about the local volatility function and a hypothesis\nmodel which is highly flexible yet not prone to over-fitting. Besides providing\na method for calibrating a (range of) point-estimate(s), we draw posterior\ninference from the distribution over local volatility. This leads to a better\nunderstanding of uncertainty associated with the calibration in particular, and\nwith the model in general. Further, we infer dynamical properties of local\nvolatility by augmenting the hypothesis space with a time dimension. Ideally,\nthis provides predictive distributions not only locally, but also for entire\nsurfaces forward in time. We apply our approach to S&P 500 market data. \n\n"}
{"id": "1901.06715", "contents": "Title: A Backward Simulation Method for Stochastic Optimal Control Problems Abstract: A number of optimal decision problems with uncertainty can be formulated into\na stochastic optimal control framework. The Least-Squares Monte Carlo (LSMC)\nalgorithm is a popular numerical method to approach solutions of such\nstochastic control problems as analytical solutions are not tractable in\ngeneral. This paper generalizes the LSMC algorithm proposed in Shen and Weng\n(2017) to solve a wide class of stochastic optimal control models. Our\nalgorithm has three pillars: a construction of auxiliary stochastic control\nmodel, an artificial simulation of the post-action value of state process, and\na shape-preserving sieve estimation method which equip the algorithm with a\nnumber of merits including bypassing forward simulation and control\nrandomization, evading extrapolating the value function, and alleviating\ncomputational burden of the tuning parameter selection. The efficacy of the\nalgorithm is corroborated by an application to pricing equity-linked insurance\nproducts. \n\n"}
{"id": "1901.07648", "contents": "Title: Finite-Sum Smooth Optimization with SARAH Abstract: The total complexity (measured as the total number of gradient computations)\nof a stochastic first-order optimization algorithm that finds a first-order\nstationary point of a finite-sum smooth nonconvex objective function\n$F(w)=\\frac{1}{n} \\sum_{i=1}^n f_i(w)$ has been proven to be at least\n$\\Omega(\\sqrt{n}/\\epsilon)$ for $n \\leq \\mathcal{O}(\\epsilon^{-2})$ where\n$\\epsilon$ denotes the attained accuracy $\\mathbb{E}[ \\|\\nabla\nF(\\tilde{w})\\|^2] \\leq \\epsilon$ for the outputted approximation $\\tilde{w}$\n(Fang et al., 2018). In this paper, we provide a convergence analysis for a\nslightly modified version of the SARAH algorithm (Nguyen et al., 2017a;b) and\nachieve total complexity that matches the lower-bound worst case complexity in\n(Fang et al., 2018) up to a constant factor when $n \\leq\n\\mathcal{O}(\\epsilon^{-2})$ for nonconvex problems. For convex optimization, we\npropose SARAH++ with sublinear convergence for general convex and linear\nconvergence for strongly convex problems; and we provide a practical version\nfor which numerical experiments on various datasets show an improved\nperformance. \n\n"}
{"id": "1901.08280", "contents": "Title: Temporal Logistic Neural Bag-of-Features for Financial Time series\n  Forecasting leveraging Limit Order Book Data Abstract: Time series forecasting is a crucial component of many important\napplications, ranging from forecasting the stock markets to energy load\nprediction. The high-dimensionality, velocity and variety of the data collected\nin these applications pose significant and unique challenges that must be\ncarefully addressed for each of them. In this work, a novel Temporal Logistic\nNeural Bag-of-Features approach, that can be used to tackle these challenges,\nis proposed. The proposed method can be effectively combined with deep neural\nnetworks, leading to powerful deep learning models for time series analysis.\nHowever, combining existing BoF formulations with deep feature extractors pose\nsignificant challenges: the distribution of the input features is not\nstationary, tuning the hyper-parameters of the model can be especially\ndifficult and the normalizations involved in the BoF model can cause\nsignificant instabilities during the training process. The proposed method is\ncapable of overcoming these limitations by a employing a novel adaptive scaling\nmechanism and replacing the classical Gaussian-based density estimation\ninvolved in the regular BoF model with a logistic kernel. The effectiveness of\nthe proposed approach is demonstrated using extensive experiments on a\nlarge-scale financial time series dataset that consists of more than 4 million\nlimit orders. \n\n"}
{"id": "1901.08555", "contents": "Title: Light-cone reduction of Witten's open string field theory Abstract: We elucidate some exact relations between light-cone and covariant string\nfield theories on the basis of the homological perturbation lemma for\n$A_{\\infty }$. The covariant string field splits into the light-cone string\nfield and trivial excitations of BRST quartets: The latter generates the gauge\nsymmetry and covariance. We first show that the reduction of gauge degrees can\nbe performed by applying the lemma, which gives a refined version of the\nno-ghost theorem of covariant strings. Then, we demonstrate that after the\nreduction, gauge-fixed theory can be regarded as a kind of effective field\ntheory and it provides an exact gauge-fixing procedure taking into account\ninteractions. As a result, a novel light-cone string field theory is obtained\nfrom Witten's open string field theory. \n\n"}
{"id": "1901.08943", "contents": "Title: Pricing options and computing implied volatilities using neural networks Abstract: This paper proposes a data-driven approach, by means of an Artificial Neural\nNetwork (ANN), to value financial options and to calculate implied volatilities\nwith the aim of accelerating the corresponding numerical methods. With ANNs\nbeing universal function approximators, this method trains an optimized ANN on\na data set generated by a sophisticated financial model, and runs the trained\nANN as an agent of the original solver in a fast and efficient way. We test\nthis approach on three different types of solvers, including the analytic\nsolution for the Black-Scholes equation, the COS method for the Heston\nstochastic volatility model and Brent's iterative root-finding method for the\ncalculation of implied volatilities. The numerical results show that the ANN\nsolver can reduce the computing time significantly. \n\n"}
{"id": "1901.09175", "contents": "Title: Hamilton cycles and perfect matchings in the KPKVB model Abstract: In this paper we consider the existence of Hamilton cycles and perfect\nmatchings in a random graph model proposed by Krioukov et al.~in 2010. In this\nmodel, nodes are chosen randomly inside a disk in the hyperbolic plane and two\nnodes are connected if they are at most a certain hyperbolic distance from each\nother. It has been previously shown that this model has various properties\nassociated with complex networks, including a power-law degree distribution,\n\"short distances\" and a strictly positive clustering coefficient. The model is\nspecified using three parameters: the number of nodes $n$, which we think of as\ngoing to infinity, and $\\alpha, \\nu > 0$, which we think of as constant.\nRoughly speaking $\\alpha$ controls the power law exponent of the degree\nsequence and $\\nu$ the average degree.\n  Here we show that for every $\\alpha < 1/2$ and $\\nu=\\nu(\\alpha)$ sufficiently\nsmall, the model does not contain a perfect matching with high probability,\nwhereas for every $\\alpha < 1/2$ and $\\nu=\\nu(\\alpha)$ sufficiently large, the\nmodel contains a Hamilton cycle with high probability. \n\n"}
{"id": "1901.09462", "contents": "Title: A deep learning-based method for prostate segmentation in T2-weighted\n  magnetic resonance imaging Abstract: We propose a novel automatic method for accurate segmentation of the prostate\nin T2-weighted magnetic resonance imaging (MRI). Our method is based on\nconvolutional neural networks (CNNs). Because of the large variability in the\nshape, size, and appearance of the prostate and the scarcity of annotated\ntraining data, we suggest training two separate CNNs. A global CNN will\ndetermine a prostate bounding box, which is then resampled and sent to a local\nCNN for accurate delineation of the prostate boundary. This way, the local CNN\ncan effectively learn to segment the fine details that distinguish the prostate\nfrom the surrounding tissue using the small amount of available training data.\nTo fully exploit the training data, we synthesize additional data by deforming\nthe training images and segmentations using a learned shape model. We apply the\nproposed method on the PROMISE12 challenge dataset and achieve state of the art\nresults. Our proposed method generates accurate, smooth, and artifact-free\nsegmentations. On the test images, we achieve an average Dice score of 90.6\nwith a small standard deviation of 2.2, which is superior to all previous\nmethods. Our two-step segmentation approach and data augmentation strategy may\nbe highly effective in segmentation of other organs from small amounts of\nannotated medical images. \n\n"}
{"id": "1901.11081", "contents": "Title: Gaussian Process Regression for Derivative Portfolio Modeling and\n  Application to CVA Computations Abstract: Modeling counterparty risk is computationally challenging because it requires\nthe simultaneous evaluation of all the trades with each counterparty under both\nmarket and credit risk. We present a multi-Gaussian process regression\napproach, which is well suited for OTC derivative portfolio valuation involved\nin CVA computation. Our approach avoids nested simulation or simulation and\nregression of cash flows by learning a Gaussian metamodel for the\nmark-to-market cube of a derivative portfolio. We model the joint posterior of\nthe derivatives as a Gaussian process over function space, with the spatial\ncovariance structure imposed on the risk factors. Monte-Carlo simulation is\nthen used to simulate the dynamics of the risk factors. The uncertainty in\nportfolio valuation arising from the Gaussian process approximation is\nquantified numerically. Numerical experiments demonstrate the accuracy and\nconvergence properties of our approach for CVA computations, including a\ncounterparty portfolio of interest rate swaps. \n\n"}
{"id": "adap-org/9907011", "contents": "Title: Phase Transition in Random Networks with Multiple States Abstract: The critical boundaries separating ordered from chaotic behavior in randomly\nwired S-state networks are calculated. These networks are a natural\ngeneralization of random Boolean nets and are proposed as on extended approach\nto genetic regulatory systems, sets of cells in different states or collectives\nof agents engaged into a set of S possible tasks. A order parameter for the\ntransition is computed and analysed. The relevance of these networks to\nbiology, their relationships with standard cellular automata and possible\nextensions are outlined. \n\n"}
{"id": "astro-ph/0005094", "contents": "Title: Redshift Distortions and Clustering in the PSCz Survey Abstract: We have constrained the redshift-distortion parameter $\\beta \\equiv\n\\Omega^{0.6}/b$ and the real-space power spectrum of the IRAS PSCz survey using\na spherical-harmonic redshift-distortion analysis combined with a data\ncompression method which is designed to deal with correlated parameters. Our\nlatest result, $\\beta=0.4 \\pm 0.1$, strongly rules out $\\beta=1$. \n\n"}
{"id": "astro-ph/0106407", "contents": "Title: r-Process in Prompt Supernova Explosions Revisited Abstract: We reanalyze $r$-process nucleosynthesis in the neutron-rich ejecta from a\nprompt supernova explosion of a low-mass (11 M$_\\odot$) progenitor. A pompt\nexplosion is not yet ruled out as a possibility for low-mass supernova\nprogenitors. Moreover, there is mounting evidence that a new $r$-process site\nmay be required. Hence, we assume that a prompt explosion can occur and make a\nstudy of r-process nucleosynthesis in the supernova ejecta. To achieve a prompt\nexplosion we have performed a general relativistic hydrodynamic simulation of\nadiabatic collapse and bounce using a relativistic nuclear-matter equation of\nstate. The electron fraction $Y_e$ during the collapse was fixed at the\ninitial-model value. The size of the inner collapsing core was then large\nenough to enable a prompt explosion to occur. Adopting the calculated\ntrajectories of promptly ejected material, we explicitly computed the burst of\nneutronization due to electron captures on free protons in the photodissociated\nejecta after the passage of the shock. The thermal and compositional evolution\nof the resulting neutron-rich ejecta originating from near the surface of\nproto-neutron star was obtained. These were used in nuclear reaction network\ncalculations to evaluate the products of $r$-process nucleosynthesis. We find\nthat, unlike earlier studies, the amount of $r$-process material ejected per\nsupernova is quite consistent with observed galactic $r$-process abundances.\nFurthermore, the computed $r$-process abundances are in good agreement with\nSolar abundances of $r$-process elements for A$> 100$. This suggests that\nprompt supernovae are still a viable $r$-process site. Such events may be\nresponsible for the abundances of the heaviest $r$-process nuclei. \n\n"}
{"id": "astro-ph/0207139", "contents": "Title: Cosmological parameters from lensed supernovae Abstract: We investigate the possibility of measuring the Hubble constant, the\nfractional energy density components and the equation of state parameter of the\n``dark energy'' using lensed multiple images of high-redshift supernovae. With\nfuture instruments, such as the SNAP and NGST satellites, it will become\npossible to observe several hundred lensed core-collapse supernovae with\nmultiple images. Accurate measurements of the image separation, flux-ratio,\ntime-delay and lensing foreground galaxy will provide complementary information\nto the cosmological tests based on, e.g., the magnitude-redshift relation of\nType Ia supernovae, especially with regards to the Hubble parameter that could\nbe measured with a statistical uncertainty at the one percent level. Assuming a\nflat universe, the statistical uncertainty on the mass density is found to be\nsigma^stat_m <0.05. However, systematic effects from the uncertainty of the\nlens modeling are likely to dominate. E.g., if the lensing galaxies are\nextremely compact but are (erroneously) modeled as singular isothermal spheres,\nthe mass density is biased by sigma^syst_m =0.1.\n  We argue that wide-field near-IR instruments such as the one proposed for the\nSNAP mission are critical for collecting large statistics of lensed supernovae. \n\n"}
{"id": "astro-ph/0211199", "contents": "Title: The VLBA 2cm Survey: Kinematics of pc-Scale Structures in Active\n  Galactic Nuclei Abstract: The kinematics of jets in active galactic nuclei (QSOs, BL Lacs, Radio\nGalaxies and Empty Field objects) on parsec scales is being studied with Very\nLong Baseline Array observations at 15 GHz of a sample of more than 170 radio\nsources. More than 1000 images have been taken since 1994. Here we present an\noverview of the results of our study, including the proper motions of\ncomponents in the jets, and their relationship with other source properties. \n\n"}
{"id": "astro-ph/0301181", "contents": "Title: Physics of Gamma-Ray Bursts: Turbulence, Energy Transfer and\n  Reconnection Abstract: Understanding of the nature of gamma-ray bursts (GRBs) is one of the\nchallenging problem facing the astrophysics community. The field of gamma ray\nbursts is a rapidly developing one and we expect that new missions, like SWIFT\nand GLAST will bring the field to a new quantitative level. The detail of the\nexplosion, the formation of the fireball, its propagation, the generation of\nthe shocks, the source of the magnetic fields and soft photons, the particle\nacceleration process, and the details of the radiation process are all still\noutstanding questions. The goal of this review is to attract the attention of\nthe community to a number of physical processes (MHD turbulence and particle\nacceleration, magnetic reconnection, etc.) that seem to be very relevant for\nthese sources. \n\n"}
{"id": "astro-ph/0301438", "contents": "Title: Neutrino energy loss rate in a stellar plasma Abstract: We review the purely leptonic neutrino emission processes, contributing to\nthe energy loss rate of the stellar plasma. We perform a complete analysis up\nto the first order in the electromagnetic coupling constant. In particular the\nradiative electromagnetic corrections, at order $\\alpha$, to the process $e^+\ne^- -> \\nu \\bar{\\nu}$ at finite density and temperature have been computed.\nThis process gives one of the main contributions to the cooling of stellar\ninterior in the late stages of star evolution. As a result of the analysis we\nfind that the corrections affect the energy loss rate, computed at tree level,\nby a factor $(-4 \\div 1) %$ in the temperature and density region where the\npair annihilation is the most efficient cooling mechanism. \n\n"}
{"id": "astro-ph/0306570", "contents": "Title: High resolution 21 cm mapping of the Ursa Major Galactic cirrus: power\n  spectra of the high-latitude HI gas Abstract: We present a power spectrum analysis of interferometric 21 cm observations of\nthe Ursa Major high-latitude cirrus, obtained with the Dominion Radio\nAstrophysical Observatory (DRAO) of Penticton (Canada). These high-resolution\ndata reveal the intricate structure of the diffuse Galactic HI, at angular\nscales from 1 arcminute to 3 degrees. A filtering method based on a wavelet\ndecomposition was used to enhance the signal-to-noise ratio of the data. The\npower spectra of the integrated emission and of the centroid velocity fields\nwere used to deduce the three-dimensional (3D) spectral index of the density\nand velocity fields of the HI cirrus. The spectral index is similar for the 3D\ndensity and velocity fields with a value of -3.6\\pm0.2. Using the\nLeiden/Dwingeloo observations, this analysis was extended to the whole North\nCelestial Loop (which includes the Ursa Major cirrus), showing that the scaling\nlaws prevail from 0.1 to 25 pc. The centroid velocity and integrated emission\nfields show moderate correlation, with a maximum cross-correlation value of\n0.44. \n\n"}
{"id": "astro-ph/0309303", "contents": "Title: Direct constraints on the dark matter self-interaction cross-section\n  from the merging galaxy cluster 1E0657-56 Abstract: We compare new maps of the hot gas, dark matter, and galaxies for 1E0657-56,\na cluster with a rare, high-velocity merger occurring nearly in the plane of\nthe sky. The X-ray observations reveal a bullet-like gas subcluster just\nexiting the collision site. A prominent bow shock gives an estimate of the\nsubcluster velocity, 4500 km/s, which lies mostly in the plane of the sky. The\noptical image shows that the gas lags behind the subcluster galaxies. The\nweak-lensing mass map reveals a dark matter clump lying ahead of the\ncollisional gas bullet, but coincident with the effectively collisionless\ngalaxies. From these observations, one can directly estimate the cross-section\nof the dark matter self-interaction. That the dark matter is not fluid-like is\nseen directly in the X-ray -- lensing mass overlay; more quantitative limits\ncan be derived from three simple independent arguments. The most sensitive\nconstraint, sigma/m<1 cm^2/g, comes from the consistency of the subcluster\nmass-to-light ratio with the main cluster (and universal) value, which rules\nout a significant mass loss due to dark matter particle collisions. This limit\nexcludes most of the 0.5-5 cm^2/g interval proposed to explain the flat mass\nprofiles in galaxies. Our result is only an order-of-magnitude estimate which\ninvolves a number of simplifying, but always conservative, assumptions;\nstronger constraints may be derived using hydrodynamic simulations of this\ncluster. \n\n"}
{"id": "astro-ph/0310337", "contents": "Title: X-raying Active Galaxies Found and Missed by the Sloan Digital Sky\n  Survey Abstract: Current X-ray observatories, archival X-ray data, and the Sloan Digital Sky\nSurvey (SDSS) represent a powerful combination for addressing key questions\nabout active galactic nuclei (AGN). We describe a few selected issues at the\nforefront of X-ray AGN research and the relevance of the SDSS to them. Bulk\nX-ray/SDSS AGN investigations, X-ray weak AGN, red AGN, hard X-ray selected\nAGN, high-redshift AGN demography, and future prospects are all briefly\ndiscussed. \n\n"}
{"id": "astro-ph/0403001", "contents": "Title: The Observed and Predicted Spatial Distribution of Milky Way Satellite\n  Galaxies Abstract: We review evidence that the census of Milky Way satellites similar to those\nknown may be incomplete at low latitude due to obscuration and in the outer\nhalo due to a decreasing sensitivity to dwarf satellites with distance. We\nevaluate the possible impact that incompleteness has on comparisons with\nsubstructure models by estimating corrections to the known number of dwarfs\nusing empirical and theoretical models. If we assume that the true distribution\nof Milky Way satellites is uniform with latitude, then we estimate a 33%\nincompleteness in the total number of dwarfs due to obscuration at low\nlatitude. Similarly, if we suppose that the radial distribution of Milky Way\nsatellites matches that of M31, or that of the oldest sub-halos or the most\nmassive sub-halos in a simulation, we estimate a total number of Milky Way\ndwarfs ranging from 1 -- 3 times the known population. Although the true level\nof incompleteness is quite uncertain, the fact that our extrapolations yield\naverage total numbers of MW dwarfs that are realistically 1.5 -- 2 times the\nknown population, shows that incompleteness needs to be taken seriously when\ncomparing to models of dwarf galaxy formation. Interestingly, the radial\ndistribution of the oldest sub-halos in a Lambda+CDM simulation of a Milky\nWay-like galaxy possess a close match to the observed distribution of M31's\nsatellites, which suggests that reionization may be an important factor\ncontrolling the observability of sub-halos. We also assess the prospects for a\nnew SDSS search for Milky Way satellites to constrain the possible\nincompleteness in the outer halo. \n\n"}
{"id": "astro-ph/0506222", "contents": "Title: Phantom damping of matter perturbations Abstract: Cosmological scaling solutions are particularly important in solving the\ncoincidence problem of dark energy. We derive the equations of sub-Hubble\nlinear matter perturbations for a general scalar-field Lagrangian--including\nquintessence, tachyon, dilatonic ghost condensate and k-essence--and solve them\nanalytically for scaling solutions. We find that matter perturbations are\nalways damped if a phantom field is coupled to dark matter and identify the\ncases in which the gravitational potential is constant. This provides an\ninteresting possibility to place stringent observational constraints on scaling\ndark energy models. \n\n"}
{"id": "astro-ph/0508506", "contents": "Title: The Fourth VLBA Calibrator Survey - VCS4 Abstract: This paper presents the fourth extension to the Very Long Baseline Array\n(VLBA) Calibrator Survey, containing 258 new sources not previously observed\nwith very long baseline interferometry (VLBI). This survey, based on three 24\nhour VLBA observing sessions, fills remaining areas on the sky above\ndeclination -40 degrees where the calibrator density is less than one source\nwithin a 4 degree radius disk at any given direction. The share of these area\nwas reduced from 4.6% to 1.9%. Source positions were derived from astrometric\nanalysis of group delays determined at 2.3 and 8.6 GHz frequency bands using\nthe Calc/Solve software package. The VCS4 catalogue of source positions, plots\nof correlated flux density versus projected baseline length, contour plots and\nfits files of naturally weighted CLEAN images, as well as calibrated visibility\nfunction files are available on the Web at http://gemini.gsfc.nasa.gov/vcs4 . \n\n"}
{"id": "astro-ph/0512576", "contents": "Title: Constraints on the Physical Parameters of the Dark Energy Using a\n  Model-Independent Approach Abstract: Understanding the physical nature of the dark energy which appears to drive\nthe accelerated expansion of the unvierse is one of the key problems in physics\nand cosmology today. This important problem is best studied using a variety of\nmutually complementary approaches. Daly and Djorgovski (2003, 2004) proposed a\nmodel independent approach to determine a number of important physical\nparameters of the dark energy as functions of redshift directly from the data.\nHere, we expand this method to include the determinations of its potential and\nkinetic energy as functions of redshift. We show that the dark energy potential\nand kinetic energy may be written as combinations of the first and second\nderivatives of the coordinate distance with respect to redshift. We expand the\ndata set to include new supernova measurements, and now use a total of 248\ncoordinate distances that span the redshift range from zero to 1.79. First and\nsecond derivatives of the coordinate distance are obtained as functions of\nredshift, and these are combined to determine the potential and kinetic energy\nof the dark energy as functions of redshift. An update on the redshift behavior\nof the dimensionless expansion rate E(z), the acceleration rate q(z), and the\ndark energy pressure p(z), energy density f(z), and equation of state w(z) is\nalso presented. We find that the standard Omega = 0.3 and Lambda = 0.7 model is\nin an excellent agreement with the data. We also show tentative evidence that\nthe Cardassian and Chaplygin gas models in a spatially flat universe do not fit\nthe data as well. \n\n"}
{"id": "astro-ph/0602266", "contents": "Title: MOND habitats within the solar system Abstract: MOdified Newtonian Dynamics (MOND) is an interesting alternative to dark\nmatter in extragalactic systems. We here examine the possibility that mild or\neven strong MOND behavior may become evident well inside the solar system, in\nparticular near saddle points of the total gravitational potential. Whereas in\nNewtonian theory tidal stresses are finite at saddle points, they are expected\nto diverge in MOND, and to remain distinctly large inside a sizeable oblate\nellipsoid around the saddle point. We work out the MOND effects using the\nnonrelativistic limit of the T$e$V$e$S theory, both in the perturbative nearly\nNewtonian regime and in the deep MOND regime. While strong MOND behavior would\nbe a spectacular ``backyard'' vindication of the theory, pinpointing the\nMOND-bubbles in the setting of the realistic solar system may be difficult.\nSpace missions, such as the LISA Pathfinder, equipped with sensitive\naccelerometers, may be able to explore the larger perturbative region. \n\n"}
{"id": "astro-ph/0602619", "contents": "Title: Models of the Structure and Evolution of Protoplanetary Disks Abstract: We review advances in the modeling of protoplanetary disks. This review will\nfocus on the regions of the disk beyond the dust sublimation radius, i.e.\nbeyond 0.1 - 1 AU, depending on the stellar luminosity. We will be mostly\nconcerned with models that aim to fit spectra of the dust continuum or gas\nlines, and derive physical parameters from these fits. For optically thick\ndisks, these parameters include the accretion rate through the disk onto the\nstar, the geometry of the disk, the dust properties, the surface chemistry and\nthe thermal balance of the gas. For the latter we are mostly concerned with the\nupper layers of the disk, where the gas and dust temperature decouple and a\nphotoevaporative flow may originate. We also briefly discuss optically thin\ndisks, focusing mainly on the gas, not the dust. The evolution of these disks\nis dominated by accretion, viscous spreading, photoevaporation, and dust\nsettling and coagulation. The density and temperature structure arising from\nthe surface layer models provide input to models of photoevaporation, which\noccurs largely in the outer disk. We discuss the consequences of\nphotoevaporation on disk evolution and planet formation. \n\n"}
{"id": "astro-ph/0606317", "contents": "Title: COSMOGRAIL: the COSmological MOnitoring of GRAvItational Lenses V. The\n  time delay in SDSS J1650+4251 Abstract: Aims: Our aim is to measure the time delay between the two gravitationally\nlensed images of the z = 1.547 quasar SDSS J1650+4251, in order to estimate the\nHubble constant H_0.\n  Methods: Our measurement is based on R-band light curves with 57 epochs\nobtained at Maidanak Observatory, in Uzbekistan, from May 2004 to September\n2005. The photometry is performed using simultaneous deconvolution of the data,\nwhich provides the individual light curves of the otherwise blended quasar\nimages. The time delay is determined from the light curves using two very\ndifferent numerical techniques, i.e., polynomial fitting and direct\ncross-correlation. The time delay is converted into H_0 following analytical\nmodeling of the potential well.\n  Results: Our best estimate of the time delay is Dt = 49.5 +/- 1.9 days, i.e.,\nwe reach a 3.8% accuracy. The R-band flux ratio between the quasar images,\ncorrected for the time delay and for slow microlensing, is F_A /F_B = 6.2 +/-\n5%.\n  Conclusions: The accuracy reached on the time delay allows us to discriminate\nwell between families of lens models. As for most other multiply imaged\nquasars, only models of the lensing galaxy that have a de Vaucouleurs mass\nprofile plus external shear give a Hubble constant compatible with the current\nmost popular value (H_0 = 72 +/- 8 km s-1 Mpc-1). A more realistic singular\nisothermal sphere model plus external shear gives H_0 = 51.7 +4.0 -3.0 km s-1\nMpc-1. \n\n"}
{"id": "astro-ph/0611373", "contents": "Title: X-ray Radio Correlation In Black Hole Sources Abstract: We examine the X-ray - radio correlation in Galactic black hole sources. We\nhighlight some of the results which extend the flux-flux relations to sources\nwith very high accretion rates. Some of the recent results indicate that the\nsynchrotron process is unlikely to be the mechanism responsible for the X-ray\nemission, particularly at high accretion rates. We present a truncated\naccretion disk scenario and argue that accretion rate and accretion disk\ngeometry ultimately act as a driver of the X-ray - radio correlation. We stress\nthe importance of wide-band X-ray spectral measurements to understand the\ndisk-jet connection and briefly outline some attempts made in the Indian\ncontext to build instruments for wide-band X-ray spectroscopy. \n\n"}
{"id": "astro-ph/0701093", "contents": "Title: An Abrupt Upper Envelope Cut-off in the Distribution of Angular Motions\n  in Quasar Jets is Compatible in all Respects with a Simple Non-Relativistic\n  Ejection Model Abstract: A remarkable correlation is found in radio-loud quasars and BLLacs when the\ndirectly observed angular motions, u, of features ejected in the innermost\nregions of their jets are plotted on logarithmic scales versus the directly\nobserved 15 GHz flux density, S, of their central engines: an abrupt upper\nenvelope cut-off with a slope of 0.5 is obtained. This upper envelope and slope\ncan be explained in a simple non-relativistic ejection model if (a), radio-loud\nquasars are radio standard candles and (b), for the sources defining the\ncut-off, the features are all ejected with similar speeds. The upper envelope\nis then due to the maximum projected velocity seen when the accretion disk is\nedge-on, and ejections are in the plane of the sky. In our simple ejection\nmodel, where S is a good measure of relative distance, the observed\ndistribution of angular motions can be explained if the radio luminosity of the\nsource is a function of viewing angle, increasing towards face-on. Here we show\nthat when u is plotted versus redshift, z, the same upper envelope cut-off is\nseen. It is not as sharply defined, since, in this simple model, the u upper\nenvelope will be smeared out by sources lying at different cosmological\ndistances, z_(c). Normalizing all sources to the same distance (1 Jy) using the\nflux density, S, removes this smearing and improves the sharpness of the upper\nenvelope, supporting our assumption that S is a measure of relative distance.\nIn this model the redshift of quasars cannot be a reliable indication of their\ndistance. (abridged) \n\n"}
{"id": "astro-ph/0701380", "contents": "Title: New Constraints on Oscillations in the Primordial Spectrum of\n  Inflationary Perturbations Abstract: We revisit the problem of constraining steps in the inflationary potential\nwith cosmological data. We argue that a step in the inflationary potential\nproduces qualitatively similar oscillations in the primordial power spectrum,\nindependently of the details of the inflationary model. We propose a\nphenomenological description of these oscillations and constrain these features\nusing a selection of cosmological data including the baryonic peak data from\nthe correlation function of luminous red galaxies in the Sloan Digital Sky\nSurvey. Our results show that degeneracies of the oscillation with standard\ncosmological parameters are virtually non-existent. The inclusion of new data\nseverely tightens the constraints on the parameter space of oscillation\nparameters with respect to older work. This confirms that extensions to the\nsimplest inflationary models can be successfully constrained using cosmological\ndata. \n\n"}
{"id": "astro-ph/9509064", "contents": "Title: Problems of Dark Matter Abstract: The data indicating existence of different forms of dark matter in the\nuniverse as well as the role of this matter in structure formation are briefly\nreviewed. It is argued that vacuum energy gives a dominant contribution into\nthe total energy density of the universe. The model of structure formation with\nunstable tau-neutrino with MeV-mass and KeV-majoron is described. \n\n"}
{"id": "astro-ph/9610120", "contents": "Title: Weak Lensing and Cosmology Abstract: We explore the dependence of weak lensing phenomena on the background\ncosmology. We first generalise the relation between $P_\\psi(\\omega)$, the\nangular power spectrum of the distortion, and the power spectrum of density\nfluctuations to non-flat cosmologies. We then compute $P_\\psi$ for various\nillustrative models. A useful cosmological discriminator is the growth of\n$P_\\psi$ with source redshift which is much stronger in low matter density\nmodels, and especially in $\\Lambda$-dominated models. With even crude redshift\ninformation (say from broad band colours) it should be possible to constrain\nthe cosmological world model. The amplitude of $P_\\psi(\\omega)$ is also quite\nsensitive to the cosmology, but requires a reliable external normalisation for\nthe mass fluctuations. If one normalises to galaxy clustering, with $M/L$ fixed\nby small-scale galaxy dynamics, then low density models predict a much stronger\ndistortion. If, however, one normalises to large-scale bulk-flows, the\npredicted distortion for sources at redshifts $Z_s \\sim 1-3$ is rather\ninsensitive to the background cosmology. The signals predicted here can be\ndetected at a very high level of significance with a photometric survey\ncovering say 10 square degrees, but sparse sampling is needed to avoid large\nsampling variance and we discuss the factors influencing the design of an\noptimum survey. Turning to weak lensing by clusters we find that for high lens\nredshifts ($Z_l\\simeq1$) the critical density is substantially reduced in\n$\\Lambda$ models, but that the ratio of the shear or convergence to the\nvelocity dispersions or X-ray temperature of clusters is only very weakly\ndependent on the cosmology. \n\n"}
{"id": "astro-ph/9611168", "contents": "Title: Testing Tree-Level Perturbation Theory for Large-Scale Structure with\n  the Local Lagrangian Approximation Abstract: We test tree-level perturbation theory for Gaussian initial conditions with\npower spectra $P(k)\\propto k^n$ by comparing the probability distribution\nfunction (PDF) for the density predicted by the Local Lagrangian Approximation\n(LLA) with the results of numerical gravitational clustering simulations. Our\nresults indicate that our approximation correctly reproduces the evolved\ndensity PDF for $-3 \\leq n \\leq-1$ power spectra up to the weakly nonlinear\nregime, while it shows marginal agreement for power indices n=0 and +1 in the\nlinear regime and poor agreement beyond this point. This suggests that\ntree-level perturbation theory (as realized in the Local Lagrangian\nApproximation) can accurately predict the density distribution function for $-3\n\\leq n \\leq -1$ but fails for $n \\ge 0$. \n\n"}
{"id": "astro-ph/9809083", "contents": "Title: On the Fate of Gas Accreting at a Low Rate onto a Black Hole Abstract: Gas supplied conservatively to a black hole at rates well below the Eddington\nrate may not be able to radiate effectively and the net energy flux, including\nthe energy transported by the viscous torque, is likely to be close to zero at\nall radii. This has the consequence that the gas accretes with positive energy\nso that it may escape. Accordingly, we propose that only a small fraction of\nthe gas supplied actually falls onto the black hole and that the binding energy\nit releases is transported radially outward by the torque so as to drive away\nthe remainder in the form of a wind. This is a generalization of and an\nalternative to an \"ADAF\" solution. Some observational implications and possible\nways to distinguish these two types of flow are briefly discussed. \n\n"}
{"id": "astro-ph/9809403", "contents": "Title: Towards a Continuous Record of the Sky Abstract: It is currently feasible to start a continuous digital record of the entire\nsky sensitive to any visual magnitude brighter than 15 each night. Such a\nrecord could be created with a modest array of small telescopes, which\ncollectively generate no more than a few Gigabytes of data daily.\nAlternatively, a few small telescopes could continually re-point to scan and\nreco rd the entire sky down to any visual magnitude brighter than 15 with a\nrecurrence epoch of at most a few weeks, again always generating less than one\nGigabyte of data each night. These estimates derive from CCD ability and\nbudgets typical of university research projects. As a prototype, we have\ndeveloped and are utilizing an inexpensive single-telescope system that obtains\noptical data from about 1500 square degrees. We discuss the general case of\ncreating and storing data from a both an epochal survey, where a small number\nof telescopes continually scan the sky, and a continuous survey, composed of a\nconstellation of telescopes dedicated each continually inspect a designated\nsection of the sky. We compute specific limitations of canonical surveys in\nvisible light, and estimate that all-sky continuous visual light surveys could\nbe sensitive to magnitude 20 in a single night by about 2010. Possible\nscientific returns of continuous and epochal sky surveys include continued\nmonitoring of most known variable stars, establishing case histories for\nvariables of future interest, uncovering new forms of stellar variability,\ndiscovering the brightest cases of microlensing, discovering new novae and\nsupernovae, discovering new counterparts to gamma-ray bursts, monitoring known\nSolar System objects, discovering new Solar System objects, and discovering\nobjects that might strike the Earth. \n\n"}
{"id": "astro-ph/9811242", "contents": "Title: Mergers and Galaxy Assembly Abstract: Theoretical considerations and observational data support the idea that\nmergers were more frequent in the past. At redshifts z = 2 to 5, violent\ninteractions and mergers may be implicated by observations of Lyman-break\ngalaxies, sub-mm starbursts, and active galactic nuclei. Most stars in cluster\nellipticals probably formed at such redshifts, as did most of the halo and\nglobular clusters of the Milky Way; these events may all be connected with\nmergers. But what kind of galaxies merged at high redshifts, and are\npresent-epoch mergers useful guides to these early collisions? I will approach\nthese questions by describing ideas for the formation of the Milky Way,\nelliptical galaxies, and systems of globular clusters. \n\n"}
{"id": "astro-ph/9812009", "contents": "Title: Clustering of Galaxies in a Hierarchical Universe: III. Mock Redshift\n  Surveys Abstract: This is the third paper in a series which combines N-body simulations and\nsemi-analytic modelling to provide a fully spatially resolved simulation of the\ngalaxy formation and clustering processes. Here we extract mock redshift\nsurveys from our simulations: a Cold Dark Matter model with either Omega_0=1\n(tauCDM) or Omega_0=0.3 and Lambda=0.7 (LambdaCDM). We compare the mock\ncatalogues with the northern region (CfA2N) of the Center for Astrophysics\n(CfA) Redshift Surveys. We study the properties of galaxy groups and clusters\nidentified using standard observational techniques and we study the relation of\nthese groups to real virialised systems. Most features of CfA2N groups are\nreproduced quite well by both models with no obvious dependence on Omega_0.\nRedshift space correlations and pairwise velocities are also similar in the two\ncosmologies. The luminosity functions predicted by our galaxy formation models\ndepend sensitively on the treatment of star formation and feedback. For the\nparticular choices of Paper I they agree poorly with the CfA survey. To isolate\nthe effect of this discrepancy on our mock redshift surveys, we modify galaxy\nluminosities in our simulations to reproduce the CfA luminosity function\nexactly. This adjustment improves agreement with the observed abundance of\ngroups, which depends primarily on the galaxy luminosity density, but other\nstatistics, connected more closely with the underlying mass distribution,\nremain unaffected. Regardless of the luminosity function adopted, modest\ndifferences with observation remain. These can be attributed to the presence of\nthe ``Great Wall'' in the CfA2N. It is unclear whether the greater coherence of\nthe real structure is a result of cosmic variance, given the relatively small\nregion studied, or reflects a physical deficiency of the models. \n\n"}
{"id": "astro-ph/9901371", "contents": "Title: X-ray Variability from the Compact Source in the Supernova Remnant RCW\n  103 Abstract: A new ASCA observation of 1E 161348-5055, the central compact X-ray source in\nthe supernova remnant RCW 103, reveals an order-of-magnitude decrease in its 3\n- 10 keV flux since the previous ASCA measurement four years earlier. This\nresult is hard to reconcile with suggestions that the bulk of the emission is\nsimple quasi-blackbody, cooling radiation from an isolated neutron star.\nFurthermore, archived EINSTEIN and ROSAT datasets spanning 18 years confirm\nthat this source manifests long-term variability, to a lesser degree. This\nprovides a natural explanation for difficulties encountered in reproducing the\noriginal EINSTEIN detection of 1E 161348-5055. Spectra from the new data are\nconsistent with no significant spectral change despite the decline in\nluminosity. We find no evidence for a pulsed component in any of the data sets,\nwith a best upper limit on the pulsed modulation of 13 percent. We discuss the\nphenomenology of this remarkable source. \n\n"}
{"id": "cond-mat/0011042", "contents": "Title: From Minority Games to real markets Abstract: We address the question of market efficiency using the Minority Game (MG)\nmodel. First we show that removing unrealistic features of the MG leads to\nmodels which reproduce a scaling behavior close to what is observed in real\nmarkets. In particular we find that i) fat tails and clustered volatility arise\nat the phase transition point and that ii) the crossover to random walk\nbehavior of prices is a finite size effect. This, on one hand, suggests that\nmarkets operate close to criticality, where the market is marginally efficient.\nOn the other it allows one to measure the distance from criticality of real\nmarket, using cross-over times. The artificial market described by the MG is\nthen studied as an ecosystem with different_species_ of traders. This clarifies\nthe nature of the interaction and the particular role played by the various\npopulations. \n\n"}
{"id": "cond-mat/0011430", "contents": "Title: Analytical Results for Trapped Weakly Interacting Bosons in Two\n  Dimensions Abstract: We consider a model of N two-dimensional bosons in a harmonic trap with\ntranslational and rotational invariant, weak two-particle interaction. We\npresent in configuration space a systematical recursive method for constructing\nall wave functions with angular momentum L and corresponding energies and apply\nit to L\\leq 6 for all N. The lower and the upper bounds for interaction energy\nare estimated. We analitically confirm the conjecture of Smith et al. that\nelementary symmetric polynomial is the ground state for repulsive delta\ninteraction, for all N\\geq L up to L\\leq 6. Additionally, we find that there\nexist vanishing-energy solutions for L\\geq N(N-1), signalizing the exclusive\nstatistics. Finally, we consider briefly the case of attractive power-like\npotential r^k, k>-2, and prove that the lowest-energy state is still the one in\nwhich all angular momentum is absorbed by the center-of-mass motion. \n\n"}
{"id": "cond-mat/0106058", "contents": "Title: A model solid-state structural transformation: Tetragonal to\n  Orthorhombic Abstract: We study equilibrium properties of a system of particles in two dimensions,\ninteracting with pair and three body potentials, which undergoes a structural\ntransition from a square to a rhombic lattice and thus constitutes a simple\nmodel for a generic tetragonal to orthorhombic transition. We aim at an\nintermediate level of description lying in-between that of coarse grained\nelastic strain hamiltonians and microscopic ab-initio approaches. Macroscopic\nthermodynamic properties and phase diagram at zero and finite temperatures as a\nfunction of the density and the relative strengths of the pair and three body\nenergies are obtained using lattice sums, an approximate `cell-model' theory\nand molecular dynamics simulations in the NVT ensemble. We propose that this\nmodel solid can be used as a test bed for studies of statics and dynamics of\nstructural transitions. \n\n"}
{"id": "cond-mat/0107385", "contents": "Title: Spin-orbit coupling effects on quantum transport in lateral\n  semiconductor dots Abstract: The effects of interplay between spin-orbit coupling and Zeeman splitting on\nweak localisation and universal conductance fluctuations in lateral\nsemiconductor quantum dots are analysed: All possible symmetry classes of\ncorresponding random matrix theories are listed and crossovers between them\nachievable by sweeping magnetic field and changing the dot parameters are\ndescribed. We also suggest experiments to measure the spin-orbit coupling\nconstants. \n\n"}
{"id": "cond-mat/0204170", "contents": "Title: Reply to Comment on: ''Exact solutions of the Lawrence-Doniach model for\n  layered superconductors'' Abstract: In the recent Comment [V. M. Krasnov, Phys. Rev. B vol. 65, 096503 (2002)],\nthe author claims to have ''disproved'' our theoretical conclusion [S. V.\nKuplevakhsky, Phys. Rev. B vol. 60, 7496 (1999); Phys. Rev. B vol. 63, 054508\n(2001)] that isolated Josephson vortices in layered superconductors and stacked\njunctions are absolutely unstable in the presence of an external field. We show\nthat this claim has no grounds. Moreover, by solving an appropriate boundary\nvalue problem, we obtain a complete classification of soliton (vortex)\nsolutions to coupled static sine-Gordon equations. We also discuss the problem\nof vortex penetration and analyze available experimental data. \n\n"}
{"id": "cond-mat/0212137", "contents": "Title: Reinterpretation of the equilibrium magnetization of a Tl-based single\n  crystal. Another phase transition in the mixed state of high-Tc\n  superconductors? Abstract: We apply a recently developed scaling procedure for the analysis of the\nequilibrium magnetization M that was measured on a Tl-based single crystal and\nwas recently reported in the literature. The results of our analysis are\ndistinctly different from those obtained in the original publication where the\nHao-Clem model served to analyze the magnetization data. We argue that the\nHao-Clem model is not adequate for a quantitative description of the mixed\nstate in high-Tc superconductors especially in high magnetic fields. The scaled\nequilibrium magnetization data reveal a pronounced kink in the M(H) dependence\nthat might be indicative of a phase transition in the mixed state. \n\n"}
{"id": "cond-mat/0212211", "contents": "Title: Quantum Phase Transition in the SU(4) Spin-Orbital Model on the\n  Triangular Lattice Abstract: Motivated by the absence of cooperative Jahn-Teller effect in LiNiO2 and\nBaVS3, two layered oxides with triangular planes, we study the SU(4) symmetric\nspin-orbital model on the triangular lattice. Upon reducing the next-nearest\nneighbour coupling, we show that the system undergoes a quantum phase\ntransition to a liquid phase. A variational approach to this liquid phase shows\nthat simple types of long-range correlations are suppressed, suggesting that it\nis stable against lattice distortions. \n\n"}
{"id": "cond-mat/0303025", "contents": "Title: Shot noise of coupled semiconductor quantum dots Abstract: The low-frequency shot noise properties of two electrostatically coupled\nsemiconductor quantum dot states which are connected to emitter/collector\ncontacts are studied. A master equation approach is used to analyze the bias\nvoltage dependence of the Fano factor as a measure of temporal correlations in\ntunneling current caused by Pauli's exclusion principle and the Coulomb\ninteraction. In particular, the influence of the Coulomb interaction on the\nshot noise behavior is discussed in detail and predictions for future\nexperiments will be given. Furthermore, we propose a mechanism for negative\ndifferential conductance and investigate the related super-Poissonian shot\nnoise. \n\n"}
{"id": "cond-mat/0307392", "contents": "Title: Exposing the spin glass ground state of the non-superconducting\n  La$_{2-x}$Sr$_x$Cu$_{1-y}$Zn$_{y}$O$_4$ high-$T_c$ oxide Abstract: We have studied the spin glass behaviour of non-superconducting\nLa$_{2-x}$Sr$_x$Cu$_{0.95}$Zn$_{0.05}$O$_4$ ($x=0.10-0.22$). As in the\nsuperconducting analogues of these samples the spin glass transition\ntemperature $T_g$ decreases with increasing $x$, and vanishes at $x=0.19$. A\nlocal enhancement in $T_g$ at $x=0.12$ is also observed and attributed to\nstripe ordering. The disappearance of $T_g$ for $x\\geq0.19$ is discussed in\nterms of a quantum phase transition. \n\n"}
{"id": "cond-mat/0404375", "contents": "Title: Phase diagram of ultracold atoms on optical lattice: Comparative study\n  to slave fermion and slave boson for Bose Hubbard modelPhase diagram of\n  ultracold atoms in optical lattices: Comparative study of slave fermion and\n  slave boson approaches to Bose-Hubbard model Abstract: We perform a comparative study of the finite temperature behavior of\nultracold Bose atoms in optical lattices by the slave fermion and the slave\nboson approaches to the Bose Hubbard model. The phase diagram of the system is\npresented. Although both approaches are equivalent without approximations, the\nmean field theory based on the slave fermion technique is quantitatively more\nappropriate. Conceptually, the slave fermion approach automatically excludes\nthe double occupancy of two identical fermions on the same lattice site. By\ncomparing to known results in limiting cases, we find the slave fermion\napproach better than the slave boson approach. For example, in the\nnon-interacting limit, the critical temperature of the superfluid-normal liquid\ntransition calculated by the slave fermion approach is closer to the well-known\nideal Bose gas result. At zero-temperature limit of the critical interaction\nstrength from the slave fermion approach is also closer to that from the direct\ncalculation using a zero-temperature mean field theory. \n\n"}
{"id": "cond-mat/0407216", "contents": "Title: Exact ground states of a frustrated 2D magnet: deconfined fractional\n  excitations at a first order quantum phase transition Abstract: We introduce a frustrated spin 1/2 Hamiltonian which is an extension of the\ntwo dimensional $J_1 - J_2$ Heisenberg model. The ground states of this model\nare exactly obtained at a first order quantum phase transition between two\nregions with different valence bond solid order parameters. At this point, the\nlow energy excitations are deconfined spinons and spin-charge separation occurs\nunder doping in the limit of low concentration of holes. In addition, this\npoint is characterized by the proliferation of topological defects that signal\nthe emergence of $Z_2$ gauge symmetry. \n\n"}
{"id": "cond-mat/0506293", "contents": "Title: A new many-body wave function for BCS-BEC crossover in Fermi gases Abstract: We present a new many body formalism for BCS-BEC crossover, which represents\na modification of the BCS-Leggett ground state to include 4-fermion, and higher\ncorrelations. In the BEC regime, we show how our approach contains the\n\\textit{Petrov et al} 4-fermion behavior and associated scattering length\n$a_{dd}$ at short distances, and secondly reduces to composite-boson Bogoliubov\nphysics at long distances. It reproduces the Lee-Yang term, whose numerical\nvalue is also fixed by $a_{dd}$. We have also examined the next term beyond the\nLee-Yang correction in a phenomenological fashion, building on cloud size data\nand collective mode experiments. However, one has to view this phenomenological\nanalysis with some caution since experiments are in a state of flux and are\nperformed close to unitarity. \n\n"}
{"id": "cond-mat/0508722", "contents": "Title: Generation of tunable Terahertz radiation using Josephson vortices Abstract: We propose how to control the THz radiation generated by fast moving\nJosephson vortices in spatially modulated (either along the c-axis or the\nab-plane) samples of Bi-2212 and related superconducting compounds. We show\nthat the JVs moving in a subset of weaker junctions can generate\nout-of-ab-plane and outside-the-cone Cherenkov radiation. The ab-plane\nmodulation of superconducting properties (achieved, for instance, by ion\nirradiation lithography) can result in transition radiation within certain\nfrequency windows, i.e., allowing the design of tunable THz emitters and THz\nphotonic crystals. \n\n"}
{"id": "cond-mat/0605103", "contents": "Title: Some formal results for the valence bond basis Abstract: In a system with an even number of SU(2) spins, there is an overcomplete set\nof states--consisting of all possible pairings of the spins into valence\nbonds--that spans the S=0 Hilbert subspace. Operator expectation values in this\nbasis are related to the properties of the closed loops that are formed by the\noverlap of valence bond states. We construct a generating function for spin\ncorrelation functions of arbitrary order and show that all nonvanishing\ncontributions arise from configurations that are topologically irreducible. We\nderive explicit formulas for the correlation functions at second, fourth, and\nsixth order. We then extend the valence bond basis to include triplet bonds and\ndiscuss how to compute properties that are related to operators acting outside\nthe singlet sector. These results are relevant to analytical calculations and\nto numerical valence bond simulations using quantum Monte Carlo, variational\nwavefunctions, or exact diagonalization. \n\n"}
{"id": "cond-mat/0605599", "contents": "Title: Exchange-correlation orbital functionals in current-density-functional\n  theory: Application to a quantum dot in magnetic fields Abstract: The description of interacting many-electron systems in external magnetic\nfields is considered in the framework of the optimized effective potential\nmethod extended to current-spin-density functional theory. As a case study, a\ntwo-dimensional quantum dot in external magnetic fields is investigated.\nExcellent agreement with quantum Monte Carlo results is obtained when\nself-interaction corrected correlation energies from the standard local\nspin-density approximation are added to exact-exchange results. Full\nself-consistency within the complete current-spin-density-functional framework\nis found to be of minor importance. \n\n"}
{"id": "cond-mat/0607225", "contents": "Title: Phase transition of triangulated spherical surfaces with elastic\n  skeletons Abstract: A first-order transition is numerically found in a spherical surface model\nwith skeletons, which are linked to each other at junctions. The shape of the\ntriangulated surfaces is maintained by skeletons, which have a one-dimensional\nbending elasticity characterized by the bending rigidity $b$, and the surfaces\nhave no two-dimensional bending elasticity except at the junctions. The\nsurfaces swell and become spherical at large $b$ and collapse and crumple at\nsmall $b$. These two phases are separated from each other by the first-order\ntransition. Although both of the surfaces and the skeleton are allowed to\nself-intersect and, hence, phantom, our results indicate a possible phase\ntransition in biological or artificial membranes whose shape is maintained by\ncytoskeletons. \n\n"}
{"id": "cond-mat/9704037", "contents": "Title: Gutzwiller-correlated wave functions for degenerate bands: exact results\n  in infinite dimensions Abstract: We introduce Gutzwiller-correlated wave functions for the variational\ninvestigation of general multi-band Hubbard models. We set up a diagrammatic\nformalism which allows us to evaluate analytically ground-state properties in\nthe limit of infinite spatial dimensions. In this limit recent results obtained\nwithin the Gutzwiller approximation are seen to become exact for these wave\nfunctions. We further show that the Slave Boson mean-field theory for\ndegenerate bands becomes variationally controlled at zero temperature in\ninfinite dimensions. Lastly, we briefly comment on the variational approach to\nthe Anderson transition in strongly correlated electron systems. \n\n"}
{"id": "cond-mat/9709035", "contents": "Title: Phase Transitions in One-Dimensional Truncated Bosonic Hubbard Model and\n  Its Spin-1 Analog Abstract: We study one-dimensional truncated (no more than 2 particles on a site)\nbosonic Hubbard model in both repulsive and attractive regimes by exact\ndiagonalization and exact worldline Monte Carlo simulation. In the commensurate\ncase (one particle per site) we demonstrate that the point of Mott-insulator --\nsuperfluid transition, $(U/t)_c=0.50\\pm 0.05$, is remarkably far from that of\nthe full model. In the attractive region we observe the phase transition from\none-particle superfluid to two-particle one. The paring gap demonstrates a\nlinear behavior in the vicinity of the critical point. The critical state\nfeatures marginal response to the gauge phase. We argue that the two-particle\nsuperfluid is a macroscopic analog of a peculiar phase observed earlier in a\nspin-1 model with axial anisotropy. \n\n"}
{"id": "cond-mat/9710331", "contents": "Title: Conductivity and Atomic Structure of Isolated Multiwalled Carbon\n  Nanotubes Abstract: We report associated high resolution transmission electron microscopy (HRTEM)\nand transport measurements on a series of isolated multiwalled carbon\nnanotubes. HRTEM observations, by revealing relevant structural features of the\ntubes, shed some light on the variety of observed transport behaviors, from\nsemiconducting to quasi-metallic type. Non Ohmic behavior is observed for\ncertain samples which exhibit \"bamboo like\" structural defects. The resistance\nof the most conducting sample, measured down to 20 mK, exhibits a pronounced\nmaximum at 0.6 K and strong positive magnetoresistance. \n\n"}
{"id": "cond-mat/9802136", "contents": "Title: ``String'' formulation of the Dynamics of the Forward Interest Rate\n  Curve Abstract: We propose a formulation of the term structure of interest rates in which the\nforward curve is seen as the deformation of a string. We derive the general\ncondition that the partial differential equations governing the motion of such\nstring must obey in order to account for the condition of absence of arbitrage\nopportunities. This condition takes a form similar to a fluctuation-dissipation\ntheorem, albeit on the same quantity (the forward rate), linking the bias to\nthe covariance of variation fluctuations. We provide the general structure of\nthe models that obey this constraint in the framework of stochastic partial\n(possibly non-linear) differential equations. We derive the general solution\nfor the pricing and hedging of interest rate derivatives within this framework,\nalbeit for the linear case (we also provide in the appendix a simple and\nintuitive derivation of the standard European option problem). We also show how\nthe ``string'' formulation simplifies into a standard N-factor model under a\nGalerkin approximation. \n\n"}
{"id": "cond-mat/9803049", "contents": "Title: Numerical Renormalization Group Study of non-Fermi-liquid State on\n  Dilute Uranium Systems Abstract: We investigate the non-Fermi-liquid (NFL) behavior of the impurity Anderson\nmodel (IAM) with non-Kramers doublet ground state of the f$^2$ configuration\nunder the tetragonal crystalline electric field (CEF). The low energy spectrum\nis explained by a combination of the NFL and the local-Fermi-liquid parts which\nare independent with each other. The NFL part of the spectrum has the same form\nto that of two-channel-Kondo model (TCKM). We have a parameter range that the\nIAM shows the $- \\ln T$ divergence of the magnetic susceptibility together with\nthe positive magneto resistance. We point out a possibility that the anomalous\nproperties of U$_x$Th$_{1-x}$Ru$_2$Si$_2$ including the decreasing resistivity\nwith decreasing temperature can be explained by the NFL scenario of the TCKM\ntype. We also investigate an effect of the lowering of the crystal symmetry. It\nbreaks the NFL behavior at around the temperature, $\\delta /10$, where $\\delta$\nis the orthorhombic CEF splitting. The NFL behavior is still expected above the\ntemperature, $\\delta/10$. \n\n"}
{"id": "cond-mat/9806090", "contents": "Title: Strong tunneling and charge quantization in S-I-N Coulomb blockade\n  structures Abstract: We study the charge of a small normal island connected by a tunnel junction\nto a superconducting lead. Unlike the N-I-N case, the steps of the Coulomb\nstaircase remain sharp even if the conductance of the tunneling barrier exceeds\ne^2/h. One can observe the transition from sharp steps to the smeared ones by\napplying magnetic field to destroy the superconductivity. \n\n"}
{"id": "cond-mat/9904018", "contents": "Title: Elastic Rod Model of a Supercoiled DNA Molecule Abstract: We study the elastic behaviour of a supercoiled DNA molecule. The simplest\nmodel is that of a rod like chain, involving two elastic constants, the bending\nand the twist rigidities. We show that this model is singular and needs a small\ndistance cut-off, which is a natural length scale giving the limit of validity\nof the model, of the order of the double helix pitch. The rod like chain in\npresence of the cutoff is able to reproduce quantitatively the experimentally\nobserved effects of supercoiling on the elongation-force characteristics, in\nthe small supercoiling regime. An exact solution of the model, using both\ntransfer matrix techniques and its mapping to a quantum mechanics problem,\nallows to extract, from the experimental data,the value of the twist rigidity.\nWe also analyse the variation of the torque and the writhe to twist ratio\nversus supercoiling, showing analytically the existence of a rather sharp\ncrossover regime which can be related to the excitation of plectonemic-like\nstructures. Finally we study the extension fluctuations of a stretched and\nsupercoiled DNA molecule, both at fixed torque and at fixed supercoiling angle,\nand we compare the theoretical predictions to some preliminary experimental\ndata. \n\n"}
{"id": "cond-mat/9906196", "contents": "Title: Stochastic relaxational dynamics applied to finance: towards\n  non-equilibrium option pricing theory Abstract: Non-equilibrium phenomena occur not only in physical world, but also in\nfinance. In this work, stochastic relaxational dynamics (together with path\nintegrals) is applied to option pricing theory. A recently proposed model (by\nIlinski et al.) considers fluctuations around this equilibrium state by\nintroducing a relaxational dynamics with random noise for intermediate\ndeviations called ``virtual'' arbitrage returns. In this work, the model is\nincorporated within a martingale pricing method for derivatives on securities\n(e.g. stocks) in incomplete markets using a mapping to option pricing theory\nwith stochastic interest rates. Using a famous result by Merton and with some\nhelp from the path integral method, exact pricing formulas for European call\nand put options under the influence of virtual arbitrage returns (or\nintermediate deviations from economic equilibrium) are derived where only the\nfinal integration over initial arbitrage returns needs to be performed\nnumerically. This result is complemented by a discussion of the hedging\nstrategy associated to a derivative, which replicates the final payoff but\nturns out to be not self-financing in the real world, but self-financing {\\it\nwhen summed over the derivative's remaining life time}. Numerical examples are\ngiven which underline the fact that an additional positive risk premium (with\nrespect to the Black-Scholes values) is found reflecting extra hedging costs\ndue to intermediate deviations from economic equilibrium. \n\n"}
{"id": "gr-qc/0007068", "contents": "Title: Some Higher Dimensional Vacuum Solutions Abstract: We study an even dimensional manifold with a pseudo-Riemannian metric with\narbitrary signature and arbitrary dimensions. We consider the Ricci flat\nequations and present a procedure to construct solutions to some higher (even)\ndimensional Ricci flat field equations from the four diemnsional Ricci flat\nmetrics. When the four dimensional Ricci flat geometry correponds to a\ncolliding gravitational vacuum spacetime our approach provides an exact\nsolution to the vacuum Einstein field equations for colliding graviational\nplane waves in an (arbitrary) even dimensional spacetime. We give explicitly\nhigher dimensional Szekeres metrics and study their singularity behaviors. \n\n"}
{"id": "gr-qc/0108082", "contents": "Title: Instability of Extremal Relativistic Charged Spheres Abstract: With the question, ``Can relativistic charged spheres form extremal black\nholes?\" in mind, we investigate the properties of such spheres from a classical\npoint of view. The investigation is carried out numerically by integrating the\nOppenheimer-Volkov equation for relativistic charged fluid spheres and finding\ninterior Reissner-Nordstr\\\"om solutions for these objects. We consider both\nconstant density and adiabatic equations of state, as well as several possible\ncharge distributions, and examine stability by both a normal mode and an energy\nanalysis. In all cases, the stability limit for these spheres lies between the\nextremal ($Q = M$) limit and the black hole limit ($R = R_+$). That is, we find\nthat charged spheres undergo gravitational collapse before they reach $Q = M$,\nsuggesting that extremal Reissner-Nordtr\\\"om black holes produced by collapse\nare ruled out. A general proof of this statement would support a strong form of\nthe cosmic censorship hypothesis, excluding not only stable naked\nsingularities, but stable extremal black holes. The numerical results also\nindicate that although the interior mass-energy $m(R)$ obeys the usual $m/R <\n4/9$ stability limit for the Schwarzschild interior solution, the gravitational\nmass $M$ does not. Indeed, the stability limit approaches $R_+$ as $Q \\to M$.\nIn the Appendix we also argue that Hawking radiation will not lead to an\nextremal Reissner-Nordstr\\\"om black hole. All our results are consistent with\nthe third law of black hole dynamics, as currently understood. \n\n"}
{"id": "gr-qc/0312054", "contents": "Title: An Einstein-like theory of gravity with a non-newtonian weak-field limit Abstract: We propose a model describing Einstein gravity coupled to a scalar field with\nan exponential potential. We show that the weak-field limit of the model has\nstatic solutions given by a gravitational potential behaving for large\ndistances as \\ln r . The Newtonian term GM/r appears only as subleading. Our\nmodel can be used to give a phenomenological explanation of the rotation curves\nof the galaxies without postulating the presence of dark matter. This can be\nachieved only by giving up at galactic scales Einstein equivalence principle. \n\n"}
{"id": "gr-qc/0505141", "contents": "Title: On static spherically symmetric solutions of the vacuum Brans-Dicke\n  theory Abstract: It is shown that among the four classes of the static spherically symmetric\nsolution of the vacuum Brans-Dicke theory of gravity only two are really\nindependent. Further by matching exterior and interior (due to physically\nreasonable spherically symmetric matter source) scalar fields it is found that\nonly Brans class I solution with certain restriction on solution parameters may\nrepresent exterior metric for a nonsingular massive object. The physical\nviability of the black hole nature of the solution is investigated. It is\nconcluded that no physical black hole solution different from the Schwarzschild\nblack hole is available in the Brans-Dicke theory. \n\n"}
{"id": "gr-qc/0702006", "contents": "Title: No hair theorems for positive \\Lambda Abstract: We extend all known black hole no-hair theorems to space-times endowed with a\npositive cosmological constant $\\Lambda.$ Specifically, we prove that static\nspherical black holes with $\\Lambda>0$ cannot support scalar fields in convex\npotentials and Proca-massive vector fields in the region between black hole and\ncosmic horizons. We also demonstrate the existence of at least one type of\nquantum hair, and of exactly one charged solution for the Abelian Higgs model.\nOur method of proof can be applied to investigate other types of quantum or\ntopological hair on black holes in the presence of a positive $\\Lambda.$ \n\n"}
{"id": "gr-qc/9712011", "contents": "Title: Remarks on the Reduced Phase Space of (2+1)-Dimensional Gravity on a\n  Torus in the Ashtekar Formulation Abstract: We examine the reduced phase space of the Barbero-Varadarajan solutions of\nthe Ashtekar formulation of (2+1)-dimensional general relativity on a torus. We\nshow that it is a finite-dimensional space due to existence of an infinite\ndimensional residual gauge invariance which reduces the infinite-dimensional\nspace of solutions to a finite-dimensional space of gauge-inequivalent\nsolutions. This is in agreement with general arguments which imply that the\nnumber of physical degrees of freedom for (2+1)-dimensional Ashtekar gravity on\na torus is finite. \n\n"}
{"id": "gr-qc/9901010", "contents": "Title: Notes on Black Hole Fluctuations and Backreaction Abstract: In these notes we prepare the ground for a systematic investigation into the\nissues of black hole fluctuations and backreaction by discussing the\nformulation of the problem, commenting on possible advantages and shortcomings\nof existing works, and introducing our own approach via a stochastic\nsemiclassical theory of gravity based on the Einstein-Langevin equation and the\nfluctuation-dissipation relation for a self-consistent description of metric\nfluctuations and dissipative dynamics of the black hole with backreaction of\nits Hawking radiance. \n\n"}
{"id": "hep-ex/0202022", "contents": "Title: Rare Hadronic and Radiative Penguin B Decays at BaBar Abstract: We report recent results in the study of rare hadronic and radiative penguin\ndecays of B mesons. These results are based on a sample of 23 million B B-bar\npairs collected by the BaBar Collaboration at the SLAC PEP-II e+e- B Factory. \n\n"}
{"id": "hep-ex/9903032", "contents": "Title: Recent Heavy-Flavor Measurements from OPAL Abstract: A selection of recent heavy-flavor results from OPAL using the LEP1 data\nsample are presented. The average polarization of b baryons in hadronic Z^0\ndecay has been measured to be -0.56^{+0.20}_{-0.13} (stat.) +- 0.09(syst.)\nusing semileptonic decays of Lambda_b baryons. A search has been conducted for\nthe radially excited D*' and has produced a 95% CL upper limit on its\nproduction of f(Z^0 -> D*'+-(2629))xBr(D*'+- -> D*+- pi+ pi-) < 2.1x10^{-3}.\nFinally, the measurement of the product branching ratio $f(b ->\nLambda_b)xBr(Lambda_b -> Lambda X)= (2.67 +- 0.38 (stat)\n^{+0.67}_{-0.60}(syst.))% has been made. This measurement, along with an\nearlier measurement of the product branching ratio f(b -> Lambda_b)xBr(Lambda_b\n-> Lambda l X), has been used to compute an updated R_{Lambda l} = Br(Lambda_b\n-> Lambda l X)/Br(Lambda_b -> \\Lambda X)= (8.0 +- 1.2 (stat.) +- 0.9 (syst.))%,\nconsistent with the expected low semileptonic branching fraction of the\nLambda_b inferred from its short lifetime compared to the other b hadrons. \n\n"}
{"id": "hep-lat/0007010", "contents": "Title: Anomalous Chiral Behavior in Quenched Lattice QCD Abstract: A study of the chiral behavior of pseudoscalar masses and decay constants is\ncarried out in quenched lattice QCD with Wilson fermions. Using the modified\nquenched approximation (MQA) to cure the exceptional configuration problem,\naccurate results are obtained for pion masses as low as $\\approx$ 200 MeV. The\nanomalous chiral log effect associated with quenched $\\eta'$ loops is studied\nin both the relation between $m_{\\pi}^2$ vs. $m_q$ and in the light-mass\nbehavior of the pseudoscalar and axial vector matrix elements. The size of\nthese effects agrees quantitatively with a direct measurement of the $\\eta'$\nhairpin graph, as well as with a measurement of the topological susceptibility,\nthus providing several independent and quantitatively consistent determinations\nof the quenched chiral log parameter $\\delta$. For $\\beta=5.7$ with\nclover-improved fermions $(C_{sw} =1.57)$ all results are consistent with\n$\\delta=0.065\\pm 0.013$ . \n\n"}
{"id": "hep-lat/0112035", "contents": "Title: The Area Law in Matrix Models for Large N QCD Strings Abstract: We study the question whether matrix models obtained in the zero volume limit\nof 4d Yang-Mills theories can describe large N QCD strings. The matrix model we\nuse is a variant of the Eguchi-Kawai model in terms of Hermitian matrices, but\nwithout any twists or quenching. This model was originally proposed as a toy\nmodel of the IIB matrix model. In contrast to common expectations, we do\nobserve the area law for Wilson loops in a significant range of scale of the\nloop area. Numerical simulations show that this range is stable as N increases\nup to 768, which strongly suggests that it persists in the large N limit. Hence\nthe equivalence to QCD strings may hold for length scales inside a finite\nregime. \n\n"}
{"id": "hep-lat/0202001", "contents": "Title: Witten-Veneziano Relation, Quenched QCD, and Overlap Fermions Abstract: The quarks in quenched QCD have an anomalous self-interaction in the flavor\nsinglet Goldstone boson channel. This coupling is extracted from a graph with\ndisconnected quark lines, and is used to infer the mass of the eta-prime meson\nin full QCD. When the fermions are described by an overlap action, the\nWitten-Veneziano relation is an exact relation between the topological\nsusceptibility (as defined through fermionic zero modes) and the inferred value\nof the eta-prime mass. Using an overlap action we compute the hairpin amplitude\nand determine the fermion zero-mode susceptibility, the inferred eta-prime mass\nand other parameters characterizing the low energy chiral properties of\nquenched QCD. \n\n"}
{"id": "hep-lat/0605017", "contents": "Title: The nucleon electromagnetic form factors from Lattice QCD Abstract: We evaluate the isovector nucleon electromagnetic form factors in quenched\nand full QCD on the lattice using Wilson fermions. In the quenched theory we\nuse a lattice of spatial size 3 fm at beta=6.0 enabling us to reach low\nmomentum transfers and a lowest pion mass of about 400 MeV. In the full theory\nwe use a lattice of spatial size 1.9 fm at beta=5.6 and lowest pion mass of\nabout 380 MeV enabling comparison with the results obtained in the quenched\ntheory. We compare our lattice results to the isovector part of the\nexperimentally measured form factors. \n\n"}
{"id": "hep-lat/9805024", "contents": "Title: Inverse Symmetry Breaking with 4d Lattice Simulations Abstract: According to resummed perturbation theory, certain scalar theories have a\nglobal symmetry, which is restored in the vacuum but is broken at high\ntemperatures. Recently, this phenomenon has been studied with 4d finite\ntemperature lattice simulations, and it has been suggested that the\nnon-perturbative dynamics thus incorporated would hinder the transition. We\nhave carried out another lattice study, for a theory with very small coupling\nconstants. We find perfect compatibility with next-to-leading order resummed\nperturbation theory, and demonstrate that ``inverse'' symmetry breaking can\nindeed take place at high temperatures. \n\n"}
{"id": "hep-ph/0004022", "contents": "Title: A perturbative treatment of double gluon exchange in gamma*-proton DIS Abstract: A new model for the exchange of two gluons between the virtual photon and the\nproton, in non-diffractive deeply inelastic electron-proton scattering, is\ndeveloped and studied. This model relies on a perturbative calculation,\npreviously applied to diffraction, and a general result from Regge theory. As a\nfirst application of the model, we study corrections to the momentum transfer\nto the quark-anti-quark pair, at the photon-vertex. We find a significant\nenhancement of the cross-section at ~Q^2 momentum transfers, and large negative\ncorrections for small momentum transfers. The implication of this result for\njet-distributions measured at HERA, is discussed. \n\n"}
{"id": "hep-ph/0010131", "contents": "Title: O(alpha^3 ln alpha) corrections to muonium and positronium hyperfine\n  splitting Abstract: We compute O(alpha^3 ln alpha) relative corrections to the ground state\nhyperfine splitting of a QED two body bound state with different masses of\nconstituents. The general result is then applied to muonium and positronium. In\nparticular, a new value of the muon to electron mass ratio is derived from the\nmuonium ground state hyperfine splitting. \n\n"}
{"id": "hep-ph/0010265", "contents": "Title: Weak Interactions of Light Flavours Abstract: An overview is given of weak interaction physics of the light flavours. It\nstarts with the definition of the CKM matrix and the measurement of its\ncomponents in the light-flavour sector via semi-leptonic decays. The main part\nof the lectures is devoted to non-leptonic decays with a main emphasis on\nanalytical calculations of $K\\to\\pi\\pi$ and $K^0\\leftrightarrow \\kob$ mixing.\nIt finishes with an overview of Chiral Perturbation Theory in $K\\to3\\pi$ and of\nrare Kaon decays. \n\n"}
{"id": "hep-ph/0102113", "contents": "Title: The Generic Supersymmetric Standard Model as the Complete Theory of\n  Supersymmetry without R-parity Abstract: The generic supersymmetric standard model is a model built from a\nsupersymmetrized standard model field spectrum the gauge symmetries only. The\npopular minimal supersymmetric standard model differs from the generic version\nin having R-parity imposed by hand. We review an efficient formulation of the\nmodel in which all the admissible R-parity violating terms are incorporated\nwithout bias. The model gives many new interesting R-parity violating\nphenomenological features only started to be studied recently. Some of our\nrecent results will be discussed, including newly identified 1-loop\ncontributions to neutrino masses and electric dipole moments of neutron and\nelectron. This is related to the largely overlooked R-parity violating\ncontributions to squark and slepton mixings, which we also present in detail. \n\n"}
{"id": "hep-ph/0102170", "contents": "Title: Semileptonic B Decays - Recent Results from LEP and Comparison with\n  Upsilon(4S) Data Abstract: Recent analyses of the LEP and Upsilon(4S) data have better outlined the\npicture of semileptonic B decays. Results on inclusive and exclusive decay\nbranching fractions and on the extraction of the |Vub| and |Vcb| elements of\nthe CKM mixing matrix are discussed, together with some of the still open\nquestions and the sources of model systematics. \n\n"}
{"id": "hep-ph/0102272", "contents": "Title: Projection Operator Approach to Langevin Equations in $\\phi^4$ Theory Abstract: We apply the projection operator method (POM) to $\\phi^4$ theory and derive\nboth quantum and semiclassical equations of motion for the soft modes. These\nequations have no time-convolution integral term, in sharp contrast with other\nwell-known results obtained using the influence functional method (IFM) and the\nclosed time path method (CTP). However, except for the fluctuation force field\nterms, these equations are similar to the corresponding equations obtained\nusing IFM with the linear harmonic approximation, which was introduced to\nremove the time-convolution integral. The quantum equation of motion in POM can\nbe regarded as a kind of quantum Langevin equation in which the fluctuation\nforce field is given in terms of the operators of the hard modes. These\noperators are then replaced with c-numbers using a certain procedure to obtain\na semiclassical Langevin equation. It is pointed out that there are significant\ndifferences between the fluctuation force fields introduced in this paper and\nthose introduced in IFM. The arbitrariness of the definition of the fluctuation\nforce field in IFM is also discussed. \n\n"}
{"id": "hep-ph/0106322", "contents": "Title: Brane-skyrmions and wrapped states Abstract: In the context of a brane world and including an induced curvature term in\nthe brane action, we obtain the effective lagrangian for the Goldstone bosons\n(branons) associated with the spontaneous breaking of the translational\ninvariance in the bulk. In addition to the branons, this effective action has\nSkyrmion-like solitonic states which can be understood as holes in the brane.\nWe study their main properties such as mass and size, the Skyrmion-branon\ninteraction and their possible fermionic quantization. We also consider states\nwhere the brane is wrapped around the extra dimensions and their relation with\nthe brane-skyrmions. Finally, we extend our results to higher-dimensional\nbranes, such as those appearing in M-theory, where brane-skyrmions could also\nbe present. \n\n"}
{"id": "hep-ph/0206019", "contents": "Title: Note on Triangle Anomalies and Assignment of Singlet in 331-like Model Abstract: It is pointed out that in the $331-$like model which uses both fundamental\nand complex conjugate representations for an assignment of the representations\nto the left-handed quarks and the scalar representation to their corresponding\nright-handed counterparts, the nature of the scalar should be taken into\naccount in order to make the fermion triangle anomalies in the theory\nanomaly-free, i.e. renormalizable in a sense with no anomalies, even after the\nspontaneous symmetry breaking. \n\n"}
{"id": "hep-ph/0207131", "contents": "Title: B -> X_s gamma after completion of the NLO QCD calculations Abstract: Several years ago, Stefan Pokorski, Manfred Muenz and us outlined a program\nfor calculation of the NLO QCD corrections to the weak radiative B meson decay\nB -> X_s gamma. Very recently, just before the 60th birthday of Stefan\nPokorski, this program has been formally completed. In the present paper, we\nsummarize the existing results and discuss perspectives for further improvement\nof the accuracy of the Standard Model prediction for BR[ B -> X_s gamma]. \n\n"}
{"id": "hep-ph/0208159", "contents": "Title: B_{s,d} -> l^+ l^- and K_L -> l^+ l^- in SUSY models with non-minimal\n  sources of flavour mixing Abstract: We present a general analysis of B_{s,d}-> l^+ l^- and K_L -> l^+ l^- decays\nin supersymmetric models with non-minimal sources of flavour mixing. In spite\nof the existing constraints on off-diagonal squark mass terms, these modes\ncould still receive sizeable corrections, mainly because of Higgs-mediated\nFCNCs arising at large tan(beta). The severe limits on scenarios with large\ntan(beta) and non-negligible {tilde d}^i_{R(L)}-{d-tilde}^j_{R(L)} mixing\nimposed by the present experimental bounds on these modes and Delta B=2\nobservables are discussed in detail. In particular, we show that scalar-current\ncontributions to K_L -> l^+ l^- and B-{bar B} mixing set non-trivial\nconstraints on the possibility that B_s -> l^+ l^- and B_d -> l^+ l^- receive\nlarge corrections. \n\n"}
{"id": "hep-ph/0310229", "contents": "Title: Beyond the standard model with B and K physics Abstract: In the first part of the talk the flavor physics input to models beyond the\nStandard Model is described. One specific example of such a new physics model\nis given: a model with bulk fermions in one non-factorizable extra dimension.\nIn the second part of the talk we discuss several observables that are\nsensitive to new physics. We explain what type of new physics can produce\ndeviations from the Standard Model predictions in each of these observables. \n\n"}
{"id": "hep-ph/0311039", "contents": "Title: Hard exclusive reactions and the two-gluon components of eta and eta'\n  mesons Abstract: The formalism for treating the leading-twist contributions of the two-gluon\nFock components occurring in hard exclusive processes that involve eta and eta'\nmesons is reviewed. The calculation of the eta, eta'--photon transition form\nfactor in next-to-leading order in alpha_s, as well as, the analysis of the g*\ng* eta' vertex and the electro- and photoproduction of eta, eta' mesons are\npresented. Applications of this formalism to other relevant quantities such as\nglueballs are also discussed. \n\n"}
{"id": "hep-ph/0406097", "contents": "Title: Transport Theory beyond Binary Collisions Abstract: Using the Schwinger-Keldysh technique, we derive the transport equations for\na system of quantum scalar fields. We first discuss the general structure of\nthe equations and then their collision terms. Taking into account up to\nthree-loop diagrams in \\phi^3 model and up to four-loop diagrams in \\phi^4\nmodel, we obtain the transport equations which include the contributions of\nmulti-particle collisions and particle production processes, in addition to\nmean-field effects and binary interactions. \n\n"}
{"id": "hep-ph/0408293", "contents": "Title: Negative parity pentaquarks in large Nc QCD and quark model Abstract: Recently, the 1/Nc expansion has been applied to the study of exotic baryons\ncontaining both quarks and antiquarks. We extend this approach to exotic states\nwith mixed symmetric spin-flavor symmetry, which correspond in the quark model\nto negative parity pentaquarks, and discuss the large Nc predictions for their\nmass spectrum. The heavy exotics Qbar q^4 transform as 3, 6bar,15 and 15' under\nflavor SU(3), while the light states include the exotic multiplets 10bar, 27,\n35. We give mass relations among these multiplets following from the 1/Nc\nexpansion. In the quark model, the mass splittings between these states are\ngiven by color-spin interactions. Using the observation of an anticharmed\nexotic by the H1 collaboration, we give predictions for the masses of other\nexpected heavy pentaquarks. \n\n"}
{"id": "hep-ph/0409191", "contents": "Title: A global description of heavy-ion collisions Abstract: A model for the evolution of ultrarelativistic heavy-ion collisions at both\nCERN SPS and RHIC top energies is presented. Based on the assumption of\nthermalization and a parametrization of the space-time expansion of the\nproduced matter, this model is able to describe a large set of observables\nincluding hadronic momentum spectra, correlations and abundancies, the emission\nof real photons, dilepton radiation and the suppression pattern of charmonia.\nEach of these obervables provides unique capabilities to study the reaction\ndynamics and taken together they form a strong and consistent picture of the\nevolving system. Based on the emission of hard photons measured at SPS, we\nargue that a strongly interacting, hot and dense system with temperatures above\n250 MeV has to be created early in the reaction. Such a system is bound to be\ndifferent from hadronic matter and likely to be a quark-gluon plasma, and we\nfind that this assumption is in line with the subsequent evolution of the\nsystem that is reflected in other observables. \n\n"}
{"id": "hep-ph/0412228", "contents": "Title: k_perp-factorization for Hard Processes on Nuclei in the Saturation\n  Regime Abstract: We discuss applications of the recently developed nonlinear\nk_perp--factorization for hard processes on nuclei. The starting point is the\ncolor dipole approach which allows to introduce the concept of a collective\nunintegrated nuclear gluon distribution. We focus on single--jet spectra, which\ndepend on the collective nuclear glue in a nonlinear manner. We briefly comment\non the Cronin effect. \n\n"}
{"id": "hep-ph/0507003", "contents": "Title: Collider Signatures of Axino and Gravitino Dark Matter Abstract: The axino and the gravitino are extremely weakly interacting candidates for\nthe lightest supersymmetric particle (LSP). We demonstrate that either of them\ncould provide the right amount of cold dark matter. Assuming that a charged\nslepton is the next-to-lightest supersymmetric particle (NLSP), we discuss how\nNLSP decays into the axino/gravitino LSP can provide evidence for\naxino/gravitino dark matter at future colliders. We show that these NLSP decays\nwill allow us to estimate the value of the Peccei-Quinn scale and the axino\nmass if the axino is the LSP. In the case of the gravitino LSP, we illustrate\nthat the gravitino mass can be determined. This is crucial for insights into\nthe mechanism of supersymmetry breaking and can lead to a microscopic\nmeasurement of the Planck scale. \n\n"}
{"id": "hep-ph/0508061", "contents": "Title: Is it possible to predict the sign of the Matter-Antimatter Asymmetry in\n  the Universe? Abstract: I investigate the possibility to define the sign of the leptonic asymmetry by\nthe low energy parameters. It is shown that in the context of the minimal\nrenormalizable SO(10) model the sign of the matter-antimatter asymmetry can be\ndefined by the leptonic mixing and masses in the case of Type II see-saw. \n\n"}
{"id": "hep-ph/0512275", "contents": "Title: Third order Bose-Einstein correlations by means of Coulomb wave function\n  revisited Abstract: In previous works, in order to include correction by the Coulomb wave\nfunction in Bose-Einstein correlations (BEC), the two-body Coulomb scattering\nwave functions have been utilized in the formulation of three-body BEC.\nHowever, the three-body Coulomb scattering wave function, which satisfies\napproximately the three-body Coulomb scattering Schrodinger equation, cannot be\nwritten by the product of the two-body scattering wave functions. Therefore, we\nreformulate the three-body BEC, and reanalyze the data. A set of reasonable\nparameters is obtained. \n\n"}
{"id": "hep-ph/0601040", "contents": "Title: Minimal Trinification Abstract: We study the trinified model, SU(3)_C x SU(3)_L x SU(3)_R x Z_3, with the\nminimal Higgs sector required for symmetry breaking. There are five Higgs\ndoublets, and gauge-coupling unification results if all five are at the weak\nscale, without supersymmetry. The radiative see-saw mechanism yields sub-eV\nneutrino masses, without the need for intermediate scales, additional Higgs\nfields, or higher-dimensional operators. The proton lifetime is above the\nexperimental limits, with the decay modes p -> \\bar\\nu K^+ and p -> \\mu^+ K^0\npotentially observable. We also consider supersymmetric versions of the model,\nwith one or two Higgs doublets at the weak scale. The radiative see-saw\nmechanism fails with weak-scale supersymmetry due to the nonrenormalization of\nthe superpotential, but operates in the split-SUSY scenario. \n\n"}
{"id": "hep-ph/0610211", "contents": "Title: Low scale leptogenesis with an SU(2)_L singlet scalar Abstract: We consider thermal leptogenesis as the origin of the matter-antimatter\nasymmetry of the Universe. Some phenomenologically unpleasant features of the\nusual leptogenesis scenario are reviewed. We propose a minimal alternative,\nwhich makes use of a charged scalar $\\delta^+$, singlet under $SU(2)_L$. Such\nparticle is contained in natural extensions of the Standard Model. The lepton\nasymmetry is generated by the decays of a right-handed neutrino into $\\delta^+$\nand a right-handed charged lepton and it turns out to be sufficiently large for\nscales as low as $\\sim$ TeV. The phenomenological signatures at colliders are\ndiscussed. \n\n"}
{"id": "hep-ph/9411239", "contents": "Title: Radiative Symmetry Breaking in a Supersymmetric Model with an Extra\n  $U(1)$ Abstract: Radiative symmetry breaking is studied in a superstring-inspired\nsupersymmetric model which is extended with a low energy extra $U(1)$ symmetry.\nIn this model the $\\mu$-problem is radiatively solved in an automatic way. The\nright-handed neutrino can be heavy and the seesaw mechanism will produce the\nsmall neutrino mass which makes the MSW solution applicable to the solar\nneutrino problem. We search a parameter region which has the favorable feature\nfor the radiative symmetry breaking at the weak scale. Rather wide parameter\nregion is found to be allowed. The upper bound of the extra $Z$ boson mass is\nestimated as $M_{Z_2} \\le 2000$~GeV for a top mass range $ 150~{\\rm GeV} \\le\nm_t \\le 190~{\\rm GeV}$. Some phenomenological features of the extra $Z$ boson\nare also presented. \n\n"}
{"id": "hep-ph/9606216", "contents": "Title: Feynman Diagrams to Three Loops in Three Dimensional Field Theory Abstract: The two point integrals contributing to the self energy of a particle in a\nthree dimensional quantum field theory are calculated to two loop order in\nperturbation theory as well as the vacuum ones contributing to the effective\npotential to three loop order. For almost every integral an expression in terms\nof elementary and dilogarithm functions is obtained. For two integrals, the\nmaster integral and the Mercedes integral, a one dimensional integral\nrepresentation is obtained with an integrand consisting only of elementary\nfunctions. The results are applied to a scalar $\\lambda\\phi^4$ theory. \n\n"}
{"id": "hep-ph/9703287", "contents": "Title: On the Expectations for Leptoquarks in the Mass Range of O(200 GeV) Abstract: A summary is given on the experimental bounds for the couplings and masses of\nscalar and vector leptoquarks associated to the first fermion generation. We\ninvestigate to which extent an interpretation of the recently reported excess\nof events in the large $x$ and $Q^2$ range at HERA in terms of single\nleptoquark production is compatible with other experimental results. \n\n"}
{"id": "hep-ph/9803408", "contents": "Title: HBT correlations and charge ratios in multiple production of pions Abstract: The influence of the HBT effect on the multiplicity distribution and charge\nratios of independently produced pions is studied. It is shown that, for a wide\nclass of models, there is a critical point, where the average number of pions\nbecomes very large and the multiplicity distibution becomes very broad. In this\nregime unusual charge ratios (\"centauros\", \"anticentauros\") are strongly\nenhanced. The prospects for reaching this regime are discussed. \n\n"}
{"id": "hep-ph/9904399", "contents": "Title: Seasonal Variations of the 7Be Solar Neutrino Flux Abstract: Measuring the 7Be solar neutrino flux is crucial towards solving the solar\nneutrino puzzle. The Borexino experiment, and possibly the KamLAND experiment,\nwill be capable of studying the 7Be neutrinos in the near future. We discuss\n(1) how the seasonal variation of the Borexino and KamLAND data can be used to\nmeasure the 7Be solar neutrino flux in a background independent way and (2) how\nanomalous seasonal variations might be used to discover vacuum neutrino\noscillations, independent of the solar model and the measurement of the\nbackground. In particular, we find that, after three years of Borexino or\nKamLAND running, vacuum neutrino oscillations can be either established or\nexcluded for almost all values of (sin^2 2 theta, Delta m^2) preferred by the\nHomestake, GALLEX, SAGE, and Super-Kamiokande data. We also discuss how well\nseasonal variations of the data can be used to measure (sin^2 2 theta, Delta\nm^2) in the case of vacuum oscillations. \n\n"}
{"id": "hep-ph/9908337", "contents": "Title: Deeply virtual Compton scattering in next-to-leading order Abstract: We study the amplitude of deeply virtual Compton scattering in\nnext-to-leading order of perturbation theory including the two-loop evolution\neffects for different sets of skewed parton distributions (SPDs). It turns out\nthat in the minimal subtraction scheme the relative radiative corrections are\nof order 20-50%. We analyze the dependence of our predictions on the choice of\nSPD, that will allow to discriminate between possible models of SPDs from\nfuture high precision experimental data, and discuss shortly theoretical\nuncertainties induced by the radiative corrections. \n\n"}
{"id": "hep-th/0003222", "contents": "Title: Interacting six-dimensional topological field theories Abstract: We study the gauge-fixing and symmetries (BRST-invariance and vector\nsupersymmetry) of various six-dimensional topological models involving Abelian\nor non-Abelian 2-form potentials. \n\n"}
{"id": "hep-th/0004004", "contents": "Title: Black Hole Evaporation and Large Extra Dimensions Abstract: We study the evaporation of black holes in space-times with extra dimensions\nof size L. We first obtain a potential which describes the expected behaviors\nof very large and very small black holes and then show that a (first order)\nphase transition, possibly signaled by an outburst of energy, occurs in the\nsystem when the horizon shrinks below L from a larger value. This is related to\nboth a change in the topology of the horizon and the restoring of the\ntranslational symmetry along the extra dimensions. \n\n"}
{"id": "hep-th/0005127", "contents": "Title: (Non)-singular brane-world cosmology induced by quantum effects in d5\n  dilatonic gravity Abstract: 5d dilatonic gravity (bosonic sector of gauged supergravity) with non-trivial\nbulk potential and with surface terms (boundary cosmological constant and trace\nanomaly induced effective action for brane quantum matter) is considered. For\nconstant bulk potential and maximally SUSY Yang-Mills theory (CFT living on the\nbrane) the inflationary brane-world is constructed. The bulk is singular\nasymptotically AdS space with non-constant dilaton and dilatonic de Sitter or\nhyperbolic brane is induced by quantum matter effects. At the same time,\ndilaton on the brane is determined dynamically. This all is natural realization\nof warped compactification in AdS/CFT correspondence. For fine-tuned toy\nexample of non-constant bulk potential we found the non-singular dilatonic\nbrane-world where bulk again represents asymptotically AdS space and de Sitter\nbrane (inflationary phase of observable Universe) is induced exclusively by\nquantum effects. The radius of the brane and dilaton are determined\ndynamically. The analytically solvable example of exponential bulk potential\nleading to singular asymptotically AdS dilatonic bulk space with de Sitter (or\nhyperbolic) brane is also presented.In all cases under discussion the gravity\non the brane is trapped via Randall-Sundrum scenario. It is shown that\nqualitatively the same types of brane-worlds occur when quantum brane matter is\ndescribed by $N$ dilaton coupled spinors. \n\n"}
{"id": "hep-th/0005280", "contents": "Title: On Renormalization Group in Abstract QFT Abstract: The basics of RG equations for generic partition functions are briefly\nreviewed, keeping in mind an application to the Polyakov-de Boer-Verlindes\ndescription of the holomorphic RG flow. \n\n"}
{"id": "hep-th/0201241", "contents": "Title: Inhomogeneous Near-extremal Black Branes Abstract: It has recently been shown that there exist stable inhomogeneous neutral\nblack strings in higher dimensional gravity. These solutions were motivated by\nthe fact that the corresponding homogeneous solutions are unstable. We show\nthat there exist new inhomogeneous black string and black p-brane solutions\neven when the corresponding translationally invariant solutions are stable. In\nparticular, we show there exist inhomogeneous near-extremal black strings and\np-branes. Some of these solutions remain inhomogeneous even when the size of\nthe compact direction (at infinity) is very small. \n\n"}
{"id": "hep-th/0302113", "contents": "Title: Quaternionic and Octonionic Spinors. A Classification Abstract: Quaternionic and octonionic realizations of Clifford algebras and spinors are\nclassified and explicitly constructed in terms of recursive formulas. The most\ngeneral free dynamics in arbitrary signature space-times for both quaternionic\nand octonionic spinors is presented. In the octonionic case we further provide\na systematic list of results and tables expressing, e.g., the relations of the\noctonionic Clifford algebras with the $G_2$ cosets over the Lorentz algebras,\nthe identities satisfied by the higher-rank antisymmetric octonionic tensors\nand so on. Applications of these results range from the classification of\noctonionic generalized supersymmetries, the construction of octonionic\nsuperstrings, as well as the investigations concerning the recently discovered\noctonionic $M$-superalgebra and its superconformal extension. \n\n"}
{"id": "hep-th/0304041", "contents": "Title: Perturbative Evaluation of Interacting Scalar Fields on a Curved\n  Manifold with Boundary Abstract: The effects of quantum corrections to a conformally invariant scalar field\ntheory on a curved manifold of positive constant curvature with boundary are\nconsidered in the context of a renormalisation procedure. The renormalisation\nof the theory to second order in the scalar self-coupling pursued herein\ninvolves explicit calculations of up to third loop-order and reveals that, in\naddition to the renormalisation of the scalar self-coupling and scalar field,\nthe removal of all divergences necessitates the introduction of conformally\nnon-invariant counterterms proportional to $ R\\Phi^2$ and $ K\\Phi^2$ in the\nbare scalar action as well as counterterms proportional to $ RK^2$, $ R^2$ and\n$ RK$ in the gravitational action. The substantial backreaction effects and\ntheir relevance to the renormalisation procedure are analysed. \n\n"}
{"id": "hep-th/0310045", "contents": "Title: The minimal curvature of the universe in modified gravity and conformal\n  anomaly resolution of the instabilities Abstract: We discuss the modified gravity which may produce the current cosmic\naceleration of the universe and eliminates the need for dark energy. It is\nshown that such models where the action quickly grows with the decrease of the\ncurvature define the FRW universe with the minimal curvature. It is required\nthe infinite time to reach the minimal curvature during the universe evolution.\nIt is demonstrated that quantum effects of conformal fields may strongly\nsuppress the instabilities discovered in modified gravity. We also briefly\nspeculate on the modification of gravity combined with the presence of the\ncosmological constant dark energy. \n\n"}
{"id": "hep-th/0311138", "contents": "Title: Non-supersymmetric deformation of the Klebanov-Strassler model and the\n  related plane wave theory Abstract: We discuss a regular non-supersymmetric deformation of the Klebanov-Strassler\nsolution related to gaugino mass terms in the dual gauge theory. We also\ndescribe the Penrose limit of the new background and the corresponding plane\nwave string theory. \n\n"}
{"id": "hep-th/0403144", "contents": "Title: Superconformal field theories in analytic superspace Abstract: We summarise recent work on superconformal field theories using analytic\nsuperspace. All operators of N=4 SYM can be given as unconstrained superfields\non analytic superspace. We show how to write down operators as superfields on\nanalytic superspace and how to completely solve the Ward indentities for their\ncorrelation functions. We discuss the non-renormalisation of certain operators,\nand of some of their correlation functions. We discuss the relationship between\nharmonic and analytic superspace. Finally we discuss applications of these\ntechniques to superconformal field theory in 6 dimensions. \n\n"}
{"id": "hep-th/0403265", "contents": "Title: The Background Field Method and the Linearization Problem for Poisson\n  Manifolds Abstract: The background field method (BFM) for the Poisson Sigma Model (PSM) is\nstudied as an example of the application of the BFM technique to open gauge\nalgebras. The relationship with Seiberg-Witten maps arising in non-commutative\ngauge theories is clarified. It is shown that the implementation of the BFM for\nthe PSM in the Batalin-Vilkovisky formalism is equivalent to the solution of a\ngeneralized linearization problem (in the formal sense) for Poisson structures\nin the presence of gauge fields. Sufficient conditions for the existence of a\nsolution and a constructive method to derive it are presented. \n\n"}
{"id": "hep-th/0406149", "contents": "Title: (Semi)classical analysis of sine-Gordon theory on a strip Abstract: Classical sine-Gordon theory on a strip with integrable boundary conditions\nis considered analyzing the static (ground state) solutions, their existence,\nenergy and stability under small perturbations. The classical analogue of\nBethe-Yang quantization conditions for the (linearized) first breather is\nderived, and the dynamics of the ground states is investigated as a function of\nthe volume. The results are shown to be consistent with the expectations from\nthe quantum theory, as treated in the perturbed conformal field theory\nframework using the truncated conformal space method and thermodynamic Bethe\nAnsatz. The asymptotic form of the finite volume corrections to the ground\nstate energies is also derived, which must be regarded as the classical limit\nof some (as yet unknown) Luscher type formula. \n\n"}
{"id": "hep-th/0409090", "contents": "Title: Strings, Junctions and Stability Abstract: Identification of string junction states of pure SU(2) Seiberg-Witten theory\nas B-branes wrapped on a Calabi-Yau manifold in the geometric engineering limit\nis discussed. The wrapped branes are known to correspond to objects in the\nbounded derived category of coherent sheaves on the projective line $\\cp{1}$ in\nthis limit. We identify the pronged strings with triangles in the underlying\ntriangulated category using Pi-stability. The spiral strings in the weak\ncoupling region are interpreted as certain projective resolutions of the\ninvertible sheaves. We discuss transitions between the spiral strings and\njunctions using the grade introduced for Pi-stability through the central\ncharges of the corresponding objects. \n\n"}
{"id": "hep-th/0605016", "contents": "Title: WZW action in odd dimensional gauge theories Abstract: It is shown that Wess-Zumino-Witten (WZW) type actions can be constructed in\nodd dimensional space-times using Wilson line or Wilson loop. WZW action\nconstructed using Wilson line gives anomalous gauge variations and the WZW\naction constructed using Wilson loop gives anomalous chiral transformation. We\nshow that pure gauge theory including Yang-Mills action, Chern-Simons action\nand the WZW action can be defined in odd dimensional space-times with even\ndimensional boundaries. Examples in 3D and 5D are given. We emphasize that this\noffers a way to generalize gauge theory in odd dimensions. The WZW action\nconstructed using Wilson line can not be considered as action localized on\nboundary space-times since it can give anomalous gauge transformations on\nseparated boundaries. We try to show that such WZW action can be obtained in\nthe effective theory when making localized chiral fermions decouple. \n\n"}
{"id": "hep-th/0607204", "contents": "Title: BPS Condensates, Matrix Models and Emergent String Theory Abstract: A prescription is given for computing anomalous dimensions of single trace\noperators in SYM at strong coupling and large $N$ using a reduced model of\nmatrix quantum mechanics. The method involves treating some parts of the\noperators as \"BPS condensates\" which, in certain limit, have a dual description\nas null geodesics on the $S^5$. In the gauge theory, the condensate is similar\nto a representative of the chiral ring and it is described by a background of\ncommuting matrices. Excitations around these condensates correspond to\nexcitations around this background and take the form of \"string bits\" which are\ndual to the \"giant magnons\" of Hofman and Maldacena. In fact, the matrix model\napproach gives a {\\it quantum} description of these string configurations and\nexplains why the infinite momentum limit suppresses the quantum effects. This\nmethod allows, not only to derive part of the classical sigma model Hamiltonian\nof the dual string (in the infinite momentum limit), but also its quantum\ncanonical structure. Therefore, it provides an alternative method of testing\nthe AdS/CFT correspondence without the need of integrability. \n\n"}
{"id": "hep-th/0610169", "contents": "Title: Nonlinear Properties of Vielbein Massive Gravity Abstract: We propose a non-linear extension of the Fierz-Pauli mass for the graviton\nthrough a functional of the vielbein and an external Minkowski background. The\nfunctional generalizes the notion of the measure, since it reduces to a\ncosmological constant if the external background is formally sent to zero. Such\na term and the explicit external background, emerge dynamically from a\nbi--gravity theory, having both a massless and a massive graviton in its\nspectrum, in a specific limit in which the massless mode decouples, while the\nmassive one couples universally to matter. We investigate the massive theory\nusing the Stueckelberg method and providing a 't Hooft-Feynman gauge fixing in\nwhich the tensor, vector and scalar Stueckelberg fields decouple. We show that\nthis model has the softest possible ultraviolet behavior which can be expected\nfrom any generic (Lorentz invariant) theory of massive gravity, namely that it\nbecomes strong only at the scale Lambda_3 = (m_g^2 M_P)^{1/3}. \n\n"}
{"id": "hep-th/9301076", "contents": "Title: Dual Isomonodromic Deformations and Moment Maps to Loop Algebras Abstract: The Hamiltonian structure of the monodromy preserving deformation equations\nof Jimbo {\\it et al } is explained in terms of parameter dependent pairs of\nmoment maps from a symplectic vector space to the dual spaces of two different\nloop algebras. The nonautonomous Hamiltonian systems generating the\ndeformations are obtained by pulling back spectral invariants on Poisson\nsubspaces consisting of elements that are rational in the loop parameter and\nidentifying the deformation parameters with those determining the moment maps.\nThis construction is shown to lead to ``dual'' pairs of matrix differential\noperators whose monodromy is preserved under the same family of deformations.\nAs illustrative examples, involving discrete and continuous reductions, a\nhigher rank generalization of the Hamiltonian equations governing the\ncorrelation functions for an impenetrable Bose gas is obtained, as well as dual\npairs of isomonodromy representations for the equations of the Painleve\ntranscendents $P_{V}$ and $P_{VI}$. \n\n"}
{"id": "hep-th/9609009", "contents": "Title: General covariance, and supersymmetry without supersymmetry Abstract: An unusual four-dimensional generally covariant and supersymmetric SU(2)\ngauge theory is described. The theory has propagating degrees of freedom, and\nis invariant under a local (left-handed) chiral supersymmetry, which is half\nthe supersymmetry of supergravity. The Hamiltonian 3+1 decomposition of the\ntheory reveals the remarkable feature that the local supersymmetry is a\nconsequence of Yang-Mills symmetry, in a manner reminiscent of how general\ncoordinate invariance in Chern-Simons theory is a consequence of Yang-Mills\nsymmetry. It is possible to write down an infinite number of conserved\ncurrents, which strongly suggests that the theory is classically integrable. A\npossible scheme for non-perturbative quantization is outlined. This utilizes\nideas that have been developed and applied recently to the problem of\nquantizing gravity. \n\n"}
{"id": "hep-th/9610085", "contents": "Title: Recent developments in non-perturbative quantum field theory Abstract: We report on recent advances in the understanding of non-perturbative\nphenomena in the quantum theory of fields and strings. \n\n"}
{"id": "hep-th/9803079", "contents": "Title: Causal Theory for the Gauged Thirring Model Abstract: We consider the (2+1)-dimensional massive Thirring model as a gauge theory,\nwith one fermion flavor, in the framework of the causal perturbation theory and\naddress the problem of dynamical mass generation for the gauge boson. In this\ncontext we get an unambiguous expression for the coefficient of the induced\nChern-Simons term. \n\n"}
{"id": "hep-th/9811111", "contents": "Title: Conformal Unification of General Relativity and Standard Model Abstract: The unification of general relativity and standard model for strong and\nelectro-weak interactions is considered on the base of the conformal symmetry\nprinciple. The Penrose-Chernikov-Tagirov Lagrangian is used to describe the\nHiggs scalar field modulus and gravitation. We show that the procedure of the\nHamiltonian reduction converts the homogeneous part of the Higgs field into the\ndynamical parameter of evolution of the equivalent reduced system. The equation\nof dynamics of the \"proper time\" of an observer with respect to the evolution\nparameter reproduces the Friedmann-like equation, which reflects the\ncosmological evolution of elementary particle masses. The value of the Higgs\nfield is determined, at the present time, by the values of mean density of\nmatter and the Hubble parameter in satisfactory agreement with the data of\ncosmological observations. \n\n"}
{"id": "hep-th/9905025", "contents": "Title: Dynamics and integrability property of the chiral string model Abstract: The effect of fermionic string conductivity by purely right (or purely left)\nmoving ``zero modes'' is shown to be governed by a simple Lagrangian\ncharacterising a certain ``chiral'' (null current carrying) string model whose\ndynamical equations of motion turn out to be explicitly integrable in a flat\nspacetime background. \n\n"}
{"id": "hep-th/9911243", "contents": "Title: The Mass Spectrum of N=1 SYM(2+1) at Strong Coupling Abstract: We consider supersymmetric Yang-Mills theory on R x S^1 x S^1. In particular,\nwe choose one of the compact directions to be light-like and another to be\nspace-like. Since the SDLCQ regularization explicitly preserves supersymmetry,\nthis theory is totally finite, and thus we can solve for bound state wave\nfunctions and masses numerically without renormalizing. We present the masses\nas functions of the longitudinal and transverse resolutions and show that the\nmasses converge rapidly in both resolutions. We also study the behavior of the\nspectrum as a function of the coupling and find that at strong coupling there\nis a stable, well defined spectrum which we present. We also find several\nunphysical states that decouple at large transverse resolution. There are two\nsets of massless states; one set is massless only at zero coupling and the\nother is massless at all couplings. Together these sets of massless states are\nin one-to-one correspondence with the full spectrum of the dimensionally\nreduced theory. \n\n"}
{"id": "hep-th/9912200", "contents": "Title: Irreducible Hamiltonian BRST analysis of Stueckelberg coupled p-form\n  gauge theories Abstract: The irreducible Hamiltonian BRST symmetry for p-form gauge theories with\nStueckelberg coupling is derived. The cornerstone of our approach is\nrepresented by the construction of an irreducible theory that is equivalent\nfrom the point of view of the BRST formalism with the original system. The\nequivalence makes permissible the substitution of the BRST quantization of the\nreducible model by that of the irreducible theory. Our procedure maintains the\nLorentz covariance of the irreducible path integral. \n\n"}
{"id": "math-ph/0410021", "contents": "Title: Generic sets in spaces of measures and generic singular continuous\n  spectrum for Delone Hamiltonians Abstract: We show that geometric disorder leads to purely singular continuous spectrum\ngenerically.\n  The main input is a result of Simon known as the ``Wonderland theorem''.\nHere, we provide an alternative approach and actually a slight strengthening by\nshowing that various sets of measures defined by regularity properties are\ngeneric in the set of all measures on a locally compact metric space.\n  As a byproduct we obtain that a generic measure on euclidean space is\nsingular continuous. \n\n"}
{"id": "math/0003108", "contents": "Title: A Survey of Noncommutative Chern Characters Abstract: We report in this survey some new results concerning noncommutative Chern\ncharacters: construction and the cases when they are exactly computed. The\nmajor result indicates some clear relation of these noncommutative objects and\ntheir commutative counterparts. This survey can be considered as the second\npart of the previous survey (J. of Lie Theory vol. 3 (1993), 149-176. \n\n"}
{"id": "math/0005265", "contents": "Title: Induced corepresentations of locally compact quantum groups Abstract: We introduce the construction of induced corepresentations in the setting of\nlocally compact quantum groups and prove that the resulting induced\ncorepresentations are unitary under some mild integrability condition. We also\nestablish a quantum analogue of the classical bijective correspondence between\nquasi-invariant measures and certain measures on the larger locally compact\ngroup. \n\n"}
{"id": "math/0306091", "contents": "Title: Uniqueness of crepant resolutions and symplectic singularities Abstract: We prove the uniqueness of crepant resolutions for some quotient\nsingularities and for some nilpotent orbits. The finiteness of non-isomorphic\nsymplectic resolutions for 4-dimenensional symplectic singularities is proved.\nWe also give an example of symplectic singularity which admits two\nnon-equivalent symplectic resolutions. \n\n"}
{"id": "math/0310330", "contents": "Title: The Weinstein conjecture and the theorems of nearby and almost existence Abstract: The Weinstein conjecture, as the general existence problem for periodic\norbits of Hamiltonian or Reeb flows, has been among the central questions in\nsymplectic topology for over two decades and its investigation has led to\nunderstanding of some fundamental properties of Hamiltonian flows.\n  In this paper we survey some recently developed and well-known methods of\nproving various particular cases of this conjecture and the closely related\nalmost existence theorem. We also examine differentiability and continuity\nproperties of the Hofer-Zehnder capacity function and relate these properties\nto the features of the underlying Hamiltonian dynamics, e.g., to the period\ngrowth. \n\n"}
{"id": "math/0311075", "contents": "Title: Two Gauss-Bonnet and Poincar\\'{e}-Hopf Theorems for Orbifolds with\n  Boundary Abstract: The goal of this work is to generalize the Gauss-Bonnet and Poincar\\'{e}-Hopf\nTheorems to the case of orbifolds with boundary. We present two such\ngeneralizations, the first in the spirit of Satake. In this case, the local\ndata (i.e. integral of the curvature in the case of the Gauss-Bonnet Theorem\nand the index of the vector field in the case of the Poincar\\'{e}-Hopf Theorem)\nis related to Satake's orbifold Euler characteristic, a rational number which\ndepends on the orbifold structure. For the second pair of generalizations, we\nuse the Chen-Ruan orbifold cohomology to express the local data in a way which\ncan be related to the Euler characteristic of the underlying space of the\norbifold. This case applies only to orbifolds which admit almost-complex\nstructures. \n\n"}
{"id": "math/0411068", "contents": "Title: Singular cotangent bundle reduction and spin Calogero-Moser systems Abstract: We develop a bundle picture for the case that the configuration manifold has\nonly a single isotropy type, and give a formula for the reduced symplectic form\nin this setting. Furthermore, as an application of this bundle picture we\nconsider Calogero-Moser systems with spin associated to polar representations\nof compact Lie groups. \n\n"}
{"id": "math/0507112", "contents": "Title: Enumeration of non-positive planar trivalent graphs Abstract: In this paper we construct inverse bijections between two sequences of finite\nsets. One sequence is defined by planar diagrams and the other by lattice\nwalks. G. Kuperberg has shown that the number of elements in these two sets are\nequal. This problem and the methods we use are motivated by the representation\ntheory of the exceptional simple Lie algebra $G_2$. However in this account we\nhave emphasised the combinatorics. \n\n"}
{"id": "math/0509016", "contents": "Title: Absolutely continuous laws of Jump-Diffusions in finite and infinite\n  dimensions with applications to mathematical Finance Abstract: In mathematical Finance calculating the Greeks by Malliavin weights has\nproved to be a numerically satisfactory procedure for finite-dimensional\nIt\\^{o}-diffusions. The existence of Malliavin weights relies on absolute\ncontinuity of laws of the projected diffusion process and a sufficiently\nregular density. In this article we first prove results on absolute continuity\nfor laws of projected jump-diffusion processes in finite and infinite\ndimensions, and a general result on the existence of Malliavin weights in\nfinite dimension. In both cases we assume H\\\"ormander conditions and hypotheses\non the invertibility of the so-called linkage operators. The purpose of this\narticle is to show that for the construction of numerical procedures for the\ncalculation of the Greeks in fairly general jump-diffusion cases one can\nproceed as in a pure diffusion case. We also show how the given results apply\nto infinite dimensional questions in mathematical Finance. There we start from\nthe Vasi\\v{c}ek model, and add -- by pertaining no arbitrage -- a jump\ndiffusion component. We prove that we can obtain in this case an interest rate\nmodel, where the law of any projection is absolutely continuous with respect to\nLebesgue measure on $\\mathbb{R}^M $. \n\n"}
{"id": "math/0602592", "contents": "Title: On the density of properly maximal claims in financial markets with\n  transaction costs Abstract: We consider trading in a financial market with proportional transaction\ncosts. In the frictionless case, claims are maximal if and only if they are\npriced by a consistent price process--the equivalent of an equivalent\nmartingale measure. This result fails in the presence of transaction costs. A\nproperly maximal claim is one which does have this property. We show that the\nproperly maximal claims are dense in the set of maximal claims (with the\ntopology of convergence in probability). \n\n"}
{"id": "math/0608361", "contents": "Title: On stability manifolds of Calabi-Yau surfaces Abstract: We prove some general statements on stability conditions of Calabi-Yau\nsurfaces and discuss the stability manifold of the cotangent bundle of P^1. Our\nprimary interest is in spherical objects. \n\n"}
{"id": "math/0608780", "contents": "Title: Global well-posedness for the Schroedinger equation coupled to a\n  nonlinear oscillator Abstract: The Schroedinger equation with the nonlinearity concentrated at a single\npoint proves to be an interesting and important model for the analysis of\nlong-time behavior of solutions, such as the asymptotic stability of solitary\nwaves and properties of weak global attractors. In this note, we prove global\nwell-posedness of this system in the energy space $H\\sp 1$. \n\n"}
{"id": "math/0609220", "contents": "Title: Homotopy Transition Cocycles Abstract: For locally homotopy trivial fibrations, one can define transition functions\n$$ g\\dab : U\\da\\cap U\\db \\to H = H(F)$$ where $H$ is the monoid of homotopy\nequivalences of $F$ to itself but, instead of the cocycle condition, one\nobtains only that $g\\dab g\\dbgam$ is homotopic to $g\\dagam$ as a map of\n$U\\da\\cap U\\db\\cap U\\dgam$ into $H$. Moreover on multiple intersections, higher\nhomotopies arise and are relevant to classifying the fibration.\n  The full theory was worked out by the first author in his 1965 Notre Dame\nthesis \\cite{wirth:diss}. Here we present it using language that has been\ndeveloped in the interim. We also show how this points a direction `on beyond\ngerbes'. \n\n"}
{"id": "math/0610773", "contents": "Title: Variational status of a class of fully nonlinear curvature prescription\n  problems Abstract: Prescribing, by conformal transformation, the kth-elementary symmetric\npolynomial of the Schouten tensor $P$ to be constant is a generalisation of the\nYamabe problem. On compact Riemannian n-manifolds we show that, for k between\nand including 3 and n, this prescription equation is an Euler-Lagrange equation\nof some action if and only if the structure is locally conformally flat. \n\n"}
{"id": "math/0611212", "contents": "Title: Strongly Semistable Bundles on a Curve over a finite field Abstract: We show that a principal G bundle on a smooth projective curve over a finite\nfield is strongly semistable if and only if it is defined by a representation\nof the fundamental group scheme of the curve into G. \n\n"}
{"id": "math/0703782", "contents": "Title: A Proof of the Smoothness of the Finite Time Horizon American Put Option\n  for Jump Diffusions Abstract: We give a new proof of the fact that the value function of the finite time\nhorizon American put option for a jump diffusion, when the jumps are from a\ncompound Poisson process, is the classical solution of a free boundary\nequation. We also show that the value function is $C^1$ across the optimal\nstopping boundary. Our proof, which only uses the classical theory of parabolic\npartial differential equations of [7,8], is an alternative to the proof that\nuses the the theory of vicosity solutions [14]. This new proof relies on\nconstructing a monotonous sequence of functions, each of which is a value\nfunction of an optimal stopping problem for a geometric Brownian motion,\nconverging to the value function uniformly and exponentially fast. This\nsequence is constructed by iterating a functional operator that maps a certain\nclass of convex functions to classical solutions of corresponding free boundary\nequations. On the other handsince the approximating sequence converges to the\nvalue function exponentially fast, it naturally leads to a good numerical\nscheme. We also show that the assumption that [14] makes on the parameters of\nthe problem, in order to guarantee that the value function is the \\emph{unique}\nclassical solution of the corresponding free boundary equation, can be dropped. \n\n"}
{"id": "nucl-th/0001060", "contents": "Title: Deeply bound levels in kaonic atoms Abstract: Using a microscopic antikaon-nucleus optical potential recently developed by\nRamos and Oset (nucl-th/9906016, in print in Nuclear Physics A) from a chiral\nmodel, we calculate strong interaction shifts and widths for $K^-$ atoms. This\npurely theoretical potential gives an acceptable description of the measured\ndata ($\\chi^2/{\\rm num.data}= 3.8$), though it turns out to be less attractive\nthan what can be inferred from the existing kaon atomic data. We also use a\nmodified potential, obtained by adding to the latter theoretical one a s-wave\nterm which is fitted to known experimental kaonic data ($\\chi^2/{\\rm degree of\nfreedom}= 1.6$), to predict deeply bound $K^-$ atomic levels, not detected yet.\nThis improved potential predicts, in general, states even narrower than those\nrecently reported by Friedman and Gal. (Phys.Let.B459, 1999, 43). This\nreinforces the idea that these deeply atomic states can be detected and\nresolved by using suitable nuclear reactions. Besides, we also study $K^-$ and\n$\\bar K^0$ nuclear bound states and compute binding energies and widths, for\nboth species of antikaons, in $^{12}$C, $^{40}$Ca and $^{208}$Pb. Despite of\nrestricting our study only to potentials obtained from best fits to the known\nkaonic atom data, the dynamics of these nuclear bound states depend\ndramatically on the particular optical potential used. \n\n"}
{"id": "nucl-th/0006037", "contents": "Title: Neutron beta decay and the current determination of Vud Abstract: Measurements of neutron beta decay observables required to determine\n$|V_{ud}|$ are reaching the 0.1% accuracy. In this paper we review the\ncalculation of the decay rate of this process, discuss its relevant\nuncertainties, and obtain an expression that is precise at the $10^{-4}$ level.\nOur analysis clearly shows the necessity of measurements of $\\lambda$, the\nratio of axial/vector couplings. The current situation in neutron beta decay is\nthat one cannot yet quote a single consistent value for $|V_{ud}|$ from it. We\nalso discuss the region of parameter space in the $|V_{ud}|$--$\\lambda$ plane\nwhere new physics effects should lie, if they contribute to neutron beta decay. \n\n"}
{"id": "nucl-th/0007038", "contents": "Title: Microscopic dynamics of a phase transition: equilibrium vs\n  out-of-equilibrium regime Abstract: We present for the first time to the nuclear physics community the\nHamiltonian Mean Field (HMF) model. The model can be solved analytically in the\ncanonical ensemble and shows a second-order phase transition in the\nthermodynamic limit. Numerical microcanonical simulations show interesting\nfeatures in the out-of-equilibrium regime: in particular the model has a\nnegative specific heat. The potential relevance for nuclear multifragmentation\nis discussed. \n\n"}
{"id": "nucl-th/0207034", "contents": "Title: Low Energy Expansion in the Three Body System to All Orders and the\n  Triton Channel Abstract: We extend and systematise the power counting for the three-body system, in\nthe context of the ``pion-less'' Effective Field Theory approach, to all orders\nin the low-energy expansion. We show that a sub-leading part of the three-body\nforce appears at the third order and delineate how the expansion proceeds at\nhigher orders. After discussing the renormalisation issues in a simple bosonic\nmodel, we compute the phase shifts for neutron-deuteron scattering in the\ndoublet S wave (triton) channel and compare our results with phase shift\nanalysis and potential model calculations. \n\n"}
{"id": "nucl-th/0209038", "contents": "Title: The Explicit and Dynamical Chiral Symmetry Breaking in an Effective\n  Quark-quark Interaction Model Abstract: A method for obtaining the small current quark mass effect on the dressed\nquark propagator from an effective quark-quark interaction model is developed.\nWithin this approach both explicit and dynamical chiral symmetry breaking has\nbeen analyzed. a comparision with previous results is given. \n\n"}
{"id": "nucl-th/0304084", "contents": "Title: The 2p-2h electromagnetic response in the quasielastic peak and beyond Abstract: The contribution to the nuclear transverse response function R_T arising from\ntwo particle-two hole (2p-2h) states excited through the action of\nelectromagnetic meson exchange currents (MEC) is computed in a fully\nrelativistic framework. The MEC considered are those carried by the pion and by\nDelta degrees of freedom, the latter being viewed as a virtual nucleonic\nresonance. The calculation is performed in the relativistic Fermi gas model in\nwhich Lorentz covariance can be maintained. All 2p-2h many-body diagrams\ncontaining two pionic lines that contribute to R_T are taken into account and\nthe relative impact of the various components of the MEC on R_T is addressed.\nThe non-relativistic limit of the MEC contributions is also discussed and\ncompared with the relativistic results to explore the role played by relativity\nin obtaining the 2p-2h nuclear response. \n\n"}
{"id": "nucl-th/0402044", "contents": "Title: Nucleon resonances and the production of light vector mesons near\n  thresholds Abstract: The production of the light vector mesons $V = \\rho, \\omega, \\phi$ in the\nreactions $\\pi N \\to V N$ and $N N \\to V N N$ near threshold is studied. The\nsubsequent electromagnetic decay $V \\to \\gamma^* \\to e^+ e^-$ is particularly\nsuited for exploring subthreshold $\\omega N$ resonances. \n\n"}
{"id": "nucl-th/0505054", "contents": "Title: Inhomogeneities in the freeze-out of relativistic heavy ion collisions\n  at CERN SPS Abstract: We study the role of temperature and density inhomogeneities on the\nfreeze-out of relativistic heavy ion collisions at CERN SPS. Especially the\nimpact on the particle abundancies is investigated. The quality of the fits to\nthe measured particle ratios in 158 AGeV Pb+Pb collisions significantly\nimproves as compared to a homogeneous model. \n\n"}
{"id": "nucl-th/9607034", "contents": "Title: Towards Study of Color Transparency with Medium Energy Electron Beams Abstract: Interference between vector mesons electroproduced at different longitudinal\ncoordinates leads within Glauber approximation to a $Q^2$-dependence of nuclear\neffects similar to what is expected to be an onset of color transparency (CT).\nWe suggest such a mapping of the photon energies and virtualities, which\neliminates the undesirable $Q^2$-variation and allows to measure a net CT\neffect. We develop a multichannel evolution equation, which for the first time\nincorporates CT and the effects of the coherence length in the exclusive\nelectroproduction of vector mesons. \n\n"}
{"id": "patt-sol/9912002", "contents": "Title: Defect Chaos of Oscillating Hexagons in Rotating Convection Abstract: Using coupled Ginzburg-Landau equations, the dynamics of hexagonal patterns\nwith broken chiral symmetry are investigated, as they appear in rotating\nnon-Boussinesq or surface-tension-driven convection. We find that close to the\nsecondary Hopf bifurcation to oscillating hexagons the dynamics are well\ndescribed by a single complex Ginzburg-Landau equation (CGLE) coupled to the\nphases of the hexagonal pattern. At the bandcenter these equations reduce to\nthe usual CGLE and the system exhibits defect chaos. Away from the bandcenter a\ntransition to a frozen vortex state is found. \n\n"}
{"id": "physics/0007091", "contents": "Title: Critical dynamics of two-replica cluster algorithms Abstract: The dynamic critical behavior of the two-replica cluster algorithm is\nstudied. Several versions of the algorithm are applied to the two-dimensional,\nsquare lattice Ising model with a staggered field. The dynamic exponent for the\nfull algorithm is found to be less than 0.4. It is found that odd translations\nof one replica with respect to the other together with global flips are\nessential for obtaining a small value of the dynamic exponent. \n\n"}
{"id": "physics/0106035", "contents": "Title: Electron recombination with multicharged ions via chaotic many-electron\n  states Abstract: We show that a dense spectrum of chaotic multiply-excited eigenstates can\nplay a major role in collision processes involving many-electron multicharged\nions. A statistical theory based on chaotic properties of the eigenstates\nenables one to obtain relevant energy-averaged cross sections in terms of sums\nover single-electron orbitals. Our calculation of the low-energy electron\nrecombination of Au$^{25+}$ shows that the resonant process is 200 times more\nintense than direct radiative recombination, which explains the recent\nexperimental results of Hoffknecht {\\em et al.} [J. Phys. B {\\bf 31}, 2415\n(1998)]. \n\n"}
{"id": "physics/0111017", "contents": "Title: On non-equivalence of Lorentz and Coulomb gauges within classical\n  electrodynamics Abstract: It is shown that the well-known procedure for proving the equivalence of the\nexpressions for the electric field calculated using the Lorentz and Coulomb\ngauges is incorrect. The difference between the two gauges is due to the\ndifference in the speed of propagation of a disturbance of the scalar\npotential. As an auxiliary result, it is proven that the solution for the\nelectric field cannot be obtained directly from the Maxwell equations, i.e.\nwithout introducing the scalar and vector potentials. \n\n"}
{"id": "physics/0505192", "contents": "Title: Low magnetic Prandtl number dynamos with helical forcing Abstract: We present direct numerical simulations of dynamo action in a forced Roberts\nflow. The behavior of the dynamo is followed as the mechanical Reynolds number\nis increased, starting from the laminar case until a turbulent regime is\nreached. The critical magnetic Reynolds for dynamo action is found, and in the\nturbulent flow it is observed to be nearly independent on the magnetic Prandtl\nnumber in the range from 0.3 to 0.1. Also the dependence of this threshold with\nthe amount of mechanical helicity in the flow is studied. For the different\nregimes found, the configuration of the magnetic and velocity fields in the\nsaturated steady state are discussed. \n\n"}
{"id": "physics/0507150", "contents": "Title: Forces between electric charges in motion: Rutherford scattering,\n  circular Keplerian orbits, action-at-a-distance and Newton's third law in\n  relativistic classical electrodynamics Abstract: Standard formulae of classical electromagnetism for the forces between\nelectric charges in motion derived from retarded potentials are compared with\nthose obtained from a recently developed relativistic classical electrodynamic\ntheory with an instantaneous inter-charge force. Problems discussed include\nsmall angle Rutherford scattering, Jackson's recent `torque paradox' and\ncircular Keplerian orbits. Results consistent with special relativity are\nobtained only with an instantaneous interaction. The impossiblity of stable\ncircular motion with retarded fields in either classical electromagnetism or\nNewtonian gravitation is demonstrated. \n\n"}
{"id": "q-alg/9502012", "contents": "Title: Characteristic Relations for Quantum Matrices Abstract: General algebraic properties of the algebras of vector fields over quantum\nlinear groups $GL_q(N)$ and $SL_q(N)$ are studied. These quantum algebras\nappears to be quite similar to the classical matrix algebra. In particular,\nquantum analogues of the characteristic polynomial and characteristic identity\nare obtained for them. The $q$-analogues of the Newton relations connecting two\ndifferent generating sets of central elements of these algebras (the\ndeterminant-like and the trace-like ones) are derived. This allows one to\nexpress the $q$-determinant of quantized vector fields in terms of their\n$q$-traces. \n\n"}
{"id": "quant-ph/0210174", "contents": "Title: The Casimir force and the quantum theory of lossy optical cavities Abstract: We present a new derivation of the Casimir force between two parallel plane\nmirrors at zero temperature. The two mirrors and the cavity they enclose are\ntreated as quantum optical networks. They are in general lossy and\ncharacterized by frequency dependent reflection amplitudes. The additional\nfluctuations accompanying losses are deduced from expressions of the optical\ntheorem. A general proof is given for the theorem relating the spectral density\ninside the cavity to the reflection amplitudes seen by the inner fields. This\ndensity determines the vacuum radiation pressure and, therefore, the Casimir\nforce. The force is obtained as an integral over the real frequencies,\nincluding the contribution of evanescent waves besides that of ordinary waves,\nand, then, as an integral over imaginary frequencies. The demonstration relies\nonly on general properties obeyed by real mirrors which also enforce general\nconstraints for the variation of the Casimir force. \n\n"}
{"id": "quant-ph/0309030", "contents": "Title: Action scales for quantum decoherence and their relation to structures\n  in phase space Abstract: A characteristic action $\\Delta S$ is defined whose magnitude determines some\nproperties of the expectation value of a general quantum displacement operator.\nThese properties are related to the capability of a given environmental\n`monitoring' system to induce decoherence in quantum systems coupled to it. We\nshow that the scale for effective decoherence is given by $\\Delta\nS\\approx\\hbar$. We relate this characteristic action with a complementary\nquantity, $\\Delta Z$, and analyse their connection with the main features of\nthe pattern of structures developed by the environmental state in different\nphase space representations. The relevance of the $\\Delta S$-action scale is\nillustrated using both a model quantum system solved numerically and a set of\nmodel quantum systems for which analytical expressions for the time-averaged\nexpectation value of the displacement operator are obtained explicitly. \n\n"}
{"id": "quant-ph/0410045", "contents": "Title: On the 'Polarized distances between quantum states and observables' Abstract: The scheme for construction of distances, presented in the previous paper\nquant-ph/0005087, v.1 (Ref. 1) is amended. The formulation of Proposition 1 of\nRef. 1 does not ensure the triangle inequality, therefore some of the\nfunctionals D(a,b) in Ref. 1 are in fact quasi-distances. In this note we\nformulate sufficient conditions for a functional D(a,b) of the (squared) form\nD(a,b)^2 = f(a)^2 + f(b)^2 - 2f(a)f(b)g(a,b) to be a distance and provide some\nexamples of such distances. A one parameter generalization of a bounded\ndistance of the (squared) form D(a,b)^2 = D_0^2 (1 - g(a,b)), which includes\nthe known Bures-Uhlmann and Hilbert-Schmidt distances between quantum states,\nis established. \n\n"}
{"id": "quant-ph/9810086", "contents": "Title: Observable Dirac Electron in Accelerated Frames Abstract: We present a new quantum algebraic description of an electron localized in\nspace-time. Positions in space and time, mass and Clifford generators are\ndefined as quantum operators. Commutation relations and relativistic shifts\nunder frame transformations are determined within a unique algebraic framework.\nRedshifts, i.e. shifts under transformations to uniformly accelerated frames,\nare evaluated and found to differ from the expressions of classical relativity. \n\n"}
