{"id": "0705.3289", "contents": "Title: Helium abundance in galaxy clusters and Sunyaev-Zeldovich effect Abstract: It has long been suggested that helium nuclei in the intracluster plasma can\nsediment in the cluster gravitational potential well. Some theoretical\nestimates for the cores of relaxed clusters predict an excess of helium\nabundance by up to a factor of a few over its primordial value. The\nintracluster helium abundance cannot be measured directly. This presents a\nsignificant source of uncertainty for cosmological tests based on the X-ray\nderived cluster quantities, such as the gas mass, total mass, and gas mass\nfraction, all of which depend on the assumed helium abundance. We point out\nthat cluster distances derived by combining the Sunyaev-Zeldovich (SZ) and\nX-ray data also depend on the helium abundance. This dependence can be used to\nmeasure the abundance, provided the distance is known independently. For\nexample, if one adopts the WMAP H_0 value, then the recent H_0 measurement by\nBonamente and collaborators, derived from SZ data on 38 clusters assuming a\nprimordial helium abundance, corresponds to an abundance excess by a factor of\n1.9+-0.8 within r~1 Mpc (using only their statistical errors). This shows that\ninteresting accuracy is within reach. We also briefly discuss how the SZ and\nX-ray cluster data can be combined to resolve the helium abundance dependence\nfor the d_a(z) cosmological test. \n\n"}
{"id": "0806.1006", "contents": "Title: The VO-Neural project: recent developments and some applications Abstract: VO-Neural is the natural evolution of the Astroneural project which was\nstarted in 1994 with the aim to implement a suite of neural tools for data\nmining in astronomical massive data sets. At a difference with its ancestor,\nwhich was implemented under Matlab, VO-Neural is written in C++, object\noriented, and it is specifically tailored to work in distributed computing\narchitectures. We discuss the current status of implementation of VO-Neural,\npresent an application to the classification of Active Galactic Nuclei, and\noutline the ongoing work to improve the functionalities of the package. \n\n"}
{"id": "0807.0201", "contents": "Title: The ESO-Spitzer Imaging extragalactic Survey (ESIS) II: VIMOS I,z wide\n  field imaging of ELAIS-S1 and selection of distant massive galaxies Abstract: (abridged) The ESIS survey is the optical follow up of the SWIRE/Spitzer in\nthe ELAIS-S1 region of the sky. In the era of observational cosmology, the main\nefforts are focused on the study of galaxy evolution and its environmental\ndependence. Wide area, multiwavelength, extragalactic surveys are needed in\norder to probe sufficiently large volumes, minimize cosmic variance and find\nsignificant numbers of rare objects. We present VIMOS I and z band imaging\nbelonging to the ESIS survey. A total of ~4 deg2 were targeted in I and ~1 deg2\nin z. More than 300000 galaxies have been detected in the I band and ~50000 in\nthe z band. Object coordinates are defined within an uncertainty of ~0.2 arcsec\nr.m.s., with respect to GSC 2.2. We reach a 90% average completeness at 23.1\nand 22.5 mag (Vega) in the I and z bands, respectively. On the basis of IRAC\ncolors, we identified galaxies having the 1.6 um stellar peak shifted to z=1-3.\nThe new I, z band data provide reliable constraints to avoid low-redshift\ninterlopers and reinforce this selection. Roughly 1000 galaxies between z=2-3\nwere identified over the ESIS ~4 deg2, at the SWIRE 5.8 um depth (25.8 uJy at\n3sigma). These are the best galaxy candidates to dominate the massive tail\n(M>1e11 Msun) of the z>2 mass function. \n\n"}
{"id": "0809.0692", "contents": "Title: How long should an astronomical paper be to increase its Impact? Abstract: Naively, one would expect longer papers to have larger impact (i.e., to be\ncited more). I tested this expectation by selecting all (~30,000) refereed\npapers from A&A, AJ, ApJ and MNRAS published between 2000 and 2004. These\nparticular years were chosen so papers analyzed would not be too \"fresh\", but\nat the same time length of each article could be obtained via ADS. I find that\nindeed longer papers published in these four major astronomy journals are on\naverage cited more, with a median number of citations increasing from 6 for\narticles 2-3 pages long to about 50 for articles ~50 pages long. I do however\nobserve a significant \"Letters effect\", i.e. ApJ and A&A articles 4 pages long\nare cited more than articles 5-10 pages long. Also, the very few longest (>80\npages) papers are actually cited less than somewhat shorter papers. For\nindividual journals, median citations per paper increase from 11 for ~9,300 A&A\npapers to 14 for ~5,300 MNRAS papers, 16 for ~2,550 AJ papers, and 20 for\n~12,850 ApJ papers (including ApJ Letters and Supplement). I conclude with some\nsemi-humorous career advice, directed especially at first-year graduate\nstudents. \n\n"}
{"id": "0812.3669", "contents": "Title: Enabling Next Generation Dark Energy and Epoch of Reionization Radio\n  Observatories with the MOFF Correlator Abstract: Proposed 21 cm cosmology observatories for studying the epoch of reionization\n(z ~6-15) and dark energy (z ~0-6) envision compact arrays with tens of\nthousands of antenna elements. Fully correlating this many elements is\ncomputationally expensive using traditional XF or FX correlators, and has led\nsome groups to reconsider direct imaging/FFT correlators. In this paper we\ndevelop a variation of the direct imaging correlator we call the MOFF\ncorrelator. The MOFF correlator shares the computational advantages of a direct\nimaging correlator, while avoiding a number of its shortcomings. In particular\nthe MOFF correlator makes no constraints on the antenna arrangement or type,\nprovides a fully calibrated output image including widefield polarimetry and\nnon-coplanar baseline effects, and can be orders-of-magnitude more efficient\nthan XF or FX correlators for compact radio cosmology arrays. \n\n"}
{"id": "0901.0239", "contents": "Title: Deep-Sea Acoustic Neutrino Detection and the AMADEUS System as a\n  Multi-Purpose Acoustic Array Abstract: The use of conventional neutrino telescope methods and technology for\ndetecting neutrinos with energies above 1 EeV from astrophysical sources would\nbe prohibitively expensive and may turn out to be technically not feasible.\nAcoustic detection is a promising alternative for future deep-sea neutrino\ntelescopes operating in this energy regime. It utilises the effect that the\nenergy deposit of the particle cascade evolving from a neutrino interaction in\nwater generates a coherently emitted sound wave with frequency components in\nthe range between about 1 and 50 kHz. The AMADEUS (Antares Modules for Acoustic\nDEtection Under the Sea) project is integrated into the ANTARES neutrino\ntelescope and aims at the investigation of techniques for acoustic particle\ndetection in sea water. The acoustic sensors of AMADEUS are using piezo\nelements and are recording a broad-band signal with frequencies ranging up to\n125 kHz. After an introduction to acoustic neutrino detection it will be shown\nhow an acoustic array similar to AMADEUS can be used for positioning as well as\nacoustic particle detection. Experience from AMADEUS and possibilities for a\nfuture large scale neutrino telescope in the Mediterranean Sea will be\ndiscussed. \n\n"}
{"id": "0901.1049", "contents": "Title: The hunt for cosmic neutrino sources with IceCube Abstract: IceCube is a cubic-kilometer neutrino telescope under construction at the\ngeographic South Pole. Once completed it will comprise 4800 optical sensors\ndeployed on 80 vertical strings at depths in the ice between 1450 and 2450\nmeters. Part of the array is already operational and data was recorded in the\nconfigurations with 9 (year 2006/2007), 22 (year 2007/2008) and 40-strings\n(year 2008/2009) respectively. Here we report preliminary results on the search\nfor point-like neutrino sources using data collected with the first 22 strings\n(IC-22). \n\n"}
{"id": "0901.2664", "contents": "Title: Neutrino Astronomy in the Ice Abstract: The South Pole is an optimal location for hosting astrophysical\nobservatories. The status of the construction of the IceCube Observatory and\nsome selected physics results will be discussed. Moreover prospects for\ndetection of Ultra-High Energy cosmogenic neutrinos and techniques that can\naddress this energy region will be considered. \n\n"}
{"id": "0901.2676", "contents": "Title: Spacetime Singularities in String and its Low Dimensional Effective\n  Theory Abstract: Spacetime singularities are studied in both the $D+d$-dimensional string\ntheory and its $D$-dimensional effective theory, obtained by the Kaluza-Klein\ncompactification. It is found that spacetime singularities in the low\ndimensional effective theory may or may not remain after lifted to the\n$D+d$-dimensional string theory, depending on particular solutions. It is also\nfound that there exist cases in which spacetime singularities appearing in\nhigh/low dimensional spacetimes do not necessarily happen on the same surfaces. \n\n"}
{"id": "0901.2834", "contents": "Title: Deep wide-field GMRT surveys at 610 MHz Abstract: The GMRT has been used to make deep, wide-field surveys of several fields at\n610 MHz, with a resolution of about 5 arcsec. These include the Spitzer\nExtragalactic First Look Survey field, where 4 square degrees were observed\nwith a r.m.s. sensitivity of about 30 microJy/beam, and several SWIRE fields\n(namely the Lockman Hole, ELAIS-N1 and N2 fields) covering more than 20 square\ndegrees with a sensitivity of about 80 microJy beam or better. The analysis of\nthese observations, and some of the science results are described. \n\n"}
{"id": "0901.3557", "contents": "Title: Optimal PSF modeling for weak lensing: complexity and sparsity Abstract: We investigate the impact of point spread function (PSF) fitting errors on\ncosmic shear measurements using the concepts of complexity and sparsity.\nComplexity, introduced in a previous paper, characterizes the number of degrees\nof freedom of the PSF. For instance, fitting an underlying PSF with a model\nwith low complexity will lead to small statistical errors on the model\nparameters, however these parameters could suffer from large biases.\nAlternatively, fitting with a large number of parameters will tend to reduce\nbiases at the expense of statistical errors. We perform an optimisation of\nscatters and biases by studying the mean squared error of a PSF model. We also\ncharacterize a model sparsity, which describes how efficiently the model is\nable to represent the underlying PSF using a limited number of free parameters.\nWe present the general case and illustrate it for a realistic example of PSF\nfitted with shapelet basis sets. We derive the relation between complexity and\nsparsity of the PSF model, signal-to-noise ratio of stars and systematic errors\non cosmological parameters. With the constraint of maintaining the systematics\nbelow the statistical uncertainties, this lead to a relation between the\nrequired number of stars to calibrate the PSF and the sparsity. We discuss the\nimpact of our results for current and future cosmic shear surveys. In the\ntypical case where the biases can be represented as a power law of the\ncomplexity, we show that current weak lensing surveys can calibrate the PSF\nwith few stars, while future surveys will require hard constraints on the\nsparsity in order to calibrate the PSF with 50 stars. \n\n"}
{"id": "0901.4464", "contents": "Title: High resolution optical spectroscopy of Praesepe white dwarfs Abstract: We present the results of a high resolution optical spectroscopic study of\nnine white dwarf candidate members of Praesepe undertaken with the VLT and\nUVES. We find, contrary to a number of previous studies, that WD0836+201\n(LB390, EG59) and WD0837+199 (LB393, EG61) are magnetic and non-magnetic white\ndwarfs respectively. Subsequently, we determine the radial velocities for the\neight non-magnetic degenerates and provide compelling evidence that WD0837+185\nis a radial velocity variable and possibly a double-degenerate system. We also\nfind that our result for WD0837+218, in conjunction with its projected spatial\nlocation and position in initial mass-final mass space, argues it is more\nlikely to be a field star than a cluster member. After eliminating these two\nwhite dwarfs, and WD0836+199 which has no clean SDSS photometry, we use the\nremaining 5 stars to substantiate modern theoretical mass-radius relations for\nwhite dwarfs. In light of our new results we re-examine the white dwarf members\nof Praesepe and use them to further constrain the initial mass-final mass\nrelation. We find a a near monotonic IFMR, which can still be adequately\nrepresented by simple linear function with only one outlier which may have\nformed from a blue straggler star. \n\n"}
{"id": "0902.1124", "contents": "Title: The Impact of Mergers on the Survival and Abundance of Disk-Dominated\n  Galaxies Abstract: We study the formation of disk-dominated galaxies in a LCDM universe. Their\nexistence is considered to be a challenge for the LCDM cosmology, because\ngalaxy mergers isotropize stellar disks and trigger angular momentum transport\nin gas disks, thus fostering the formation of central stellar spheroids. Here,\nwe postulate that the formation of stellar spheroids from gasrich disks is\ncontrolled by two parameters that characterize galaxy mergers, the mass ratio\nof merging dark matter halos, and the virial velocity of the larger merging\nhalo. We utilize merger histories generated from realizations of the\ncosmological density field to calculate the fraction of dark matter halos that\nhave avoided spheroid formation, and compare the derived statistics with the\nspheroid occupation fractions in surveys of nearby galaxies. We find, for\nexample, that the survival rate of disk-dominated galaxies in LCDM is just high\nenough to explain the observed fractional representation of disk-dominated\ngalaxies in the universe if the only mergers which lead to central spheroid\nformation are those with mass ratios M2/M1 > 0.3 and virial velocities Vvir,1 >\n55 km/s. We discuss the physical origin of this criterion, and show that the\ndependence of the disk-dominated fraction on galaxy mass provides a further\ntest of the merger hypothesis. [For additional details, see, Koda et al.\n(2009).] \n\n"}
{"id": "0902.3610", "contents": "Title: Axionic dark energy and a composite QCD axion Abstract: We discuss the idea that the model-independent (MI) axion of string theory is\nthe source of quintessential dark energy. The scenario is completed with a\ncomposite QCD axion from hidden sector squark condensation that could serve as\ndark matter candidate. The mechanism relies on the fact that the hidden sector\nanomaly contribution to the composite axion is much smaller than the QCD\nanomaly term. This intuitively surprising scenario is based on the fact that\nbelow the hidden sector scale $\\Lambda_h$ there are many light hidden sector\nquarks. Simply, by counting engineering dimensions the hidden sector instanton\npotential can be made negligible compared to the QCD anomaly term. \n\n"}
{"id": "0902.3978", "contents": "Title: Phantom evolution in power-law potentials Abstract: We investigate phantom models with power-law potentials and we extract the\nearly-time, \"tracker\", solutions under the assumption of matter domination.\nContrary to quintessence case, we find that energy positivity requires normal\npower-law potentials instead of inverse power-law ones, with the potential\nexponent being bounded by the quadratic form. In addition, we analytically\npresent the general cosmological solution at intermediate times, that is at low\nredshifts, which is the period of the transition from matter to dark-energy\ndomination. The comparison with the exact evolution, arising from numerical\nelaboration, shows that the tracker solution agrees with the later within 2%\nfor redshifts z>1.5, while the intermediate solution is accurate within 2% up\nto $z\\approx 0.5$. \n\n"}
{"id": "0902.4636", "contents": "Title: How well do STARLAB and NBODY4 compare? I: Simple models Abstract: N-body simulations are widely used to simulate the dynamical evolution of a\nvariety of systems, among them star clusters. Much of our understanding of\ntheir evolution rests on the results of such direct N-body simulations. They\nprovide insight in the structural evolution of star clusters, as well as into\nthe occurrence of stellar exotica. Although the major pure N-body codes\nSTARLAB/KIRA and NBODY4 are widely used for a range of applications, there is\nno thorough comparison study yet. Here we thoroughly compare basic quantities\nas derived from simulations performed either with STARLAB/KIRA or NBODY4.\n  We construct a large number of star cluster models for various stellar mass\nfunction settings (but without stellar/binary evolution, primordial binaries,\nexternal tidal fields etc), evolve them in parallel with STARLAB/KIRA and\nNBODY4, analyse them in a consistent way and compare the averaged results\nquantitatively. For this quantitative comparison we develop a bootstrap\nalgorithm for functional dependencies.\n  We find an overall excellent agreement between the codes, both for the\nclusters' structural and energy parameters as well as for the properties of the\ndynamically created binaries. However, we identify small differences, like in\nthe energy conservation before core collapse and the energies of escaping\nstars, which deserve further studies. Our results reassure the comparability\nand the possibility to combine results from these two major N-body codes, at\nleast for the purely dynamical models (i.e. without stellar/binary evolution)\nwe performed. (abridged) \n\n"}
{"id": "0903.0654", "contents": "Title: Unstable Helium Shell Burning on Accreting White Dwarfs Abstract: AM Canum Venaticorum (AM CVn) binaries consist of a degenerate helium donor\nand a helium, C/O, or O/Ne WD accretor, with accretion rates of Mdot = 1e-13 -\n1e-5 Msol/yr. For accretion rates < 1e-6 Msol/yr, the accreted helium ignites\nunstably, resulting in a helium flash. As the donor mass and Mdot decrease, the\nignition mass increases and eventually becomes larger than the donor mass,\nyielding a \"last-flash\" ignition mass of < 0.1 Msol. Bildsten et al. (2007)\npredicted that the largest outbursts of these systems will lead to dynamical\nburning and thermonuclear supernovae. In this paper, we study the evolution of\nthe He-burning shells in more detail. We calculate maximum achievable\ntemperatures as well as the minimum envelope masses that achieve dynamical\nburning conditions, finding that AM CVn systems with accretors > 0.8 Msol will\nundergo dynamical burning. Triple-alpha reactions during the hydrostatic\nevolution set a lower limit to the 12C mass fraction of 0.001 - 0.05 when\ndynamical burning occurs, but core dredge-up may yield 12C, 16O, and/or 20Ne\nmass fractions of ~ 0.1. Accreted 14N will likely remain 14N during the\naccretion and convective phases, but regardless of 14N's fate, the\nneutron-to-proton ratio at the beginning of convection is fixed until the onset\nof dynamical burning. During explosive burning, the 14N will undergo\n14N(a,g)18F(a,p)21Ne, liberating a proton for the subsequent\n12C(p,g)13N(a,p)16O reaction, which bypasses the relatively slow alpha-capture\nonto 12C. Future hydrodynamic simulations must include these isotopes, as the\nadditional reactions will reduce the Zel'dovich-von Neumann-Doring (ZND)\nlength, making the propagation of the detonation wave more likely. \n\n"}
{"id": "0903.0949", "contents": "Title: Study of the acoustic signature of UHE neutrino interactions in water\n  and ice Abstract: The production of acoustic signals from the interactions of ultra-high energy\n(UHE) cosmic ray neutrinos in water and ice has been studied. A new\ncomputationally fast and efficient method of deriving the signal is presented.\nThis method allows the implementation of up to date parameterisations of\nacoustic attenuation in sea water and ice that now includes the effects of\ncomplex attenuation, where appropriate. The methods presented here have been\nused to compute and study the properties of the acoustic signals which would be\nexpected from such interactions. A matrix method of parameterising the signals,\nwhich includes the expected fluctuations, is also presented. These methods are\nused to generate the expected signals that would be detected in acoustic UHE\nneutrino telescopes. \n\n"}
{"id": "0903.0975", "contents": "Title: Towards a precise measurement of the cosmic-ray positron fraction Abstract: This thesis deals with detector concepts aiming at a precise measurement of\nthe cosmic-ray positron fraction extending to an as yet unreached range of\nenergy. The indirect search for dark matter is the main motivation for this\nendeavour. \n\n"}
{"id": "0903.2068", "contents": "Title: Data boundary fitting using a generalised least-squares method Abstract: In many astronomical problems one often needs to determine the upper and/or\nlower boundary of a given data set. An automatic and objective approach\nconsists in fitting the data using a generalised least-squares method, where\nthe function to be minimized is defined to handle asymmetrically the data at\nboth sides of the boundary. In order to minimise the cost function, a numerical\napproach, based on the popular downhill simplex method, is employed. The\nprocedure is valid for any numerically computable function. Simple polynomials\nprovide good boundaries in common situations. For data exhibiting a complex\nbehaviour, the use of adaptive splines gives excellent results. Since the\ndescribed method is sensitive to extreme data points, the simultaneous\nintroduction of error weighting and the flexibility of allowing some points to\nfall outside of the fitted frontier, supplies the parameters that help to tune\nthe boundary fitting depending on the nature of the considered problem. Two\nsimple examples are presented, namely the estimation of spectra\npseudo-continuum and the segregation of scattered data into ranges. The\nnormalisation of the data ranges prior to the fitting computation typically\nreduces both the numerical errors and the number of iterations required during\nthe iterative minimisation procedure. \n\n"}
{"id": "0903.2479", "contents": "Title: Compact High-Redshift Galaxies Are the Cores of the Most Massive\n  Present-Day Spheroids Abstract: Observations suggest that effective radii of high-z massive spheroids are as\nmuch as a factor ~6 smaller than low-z galaxies of comparable mass. Given the\napparent absence of low-z counterparts, this has often been interpreted as\nindicating that the high density, compact red galaxies must be 'puffed up' by\nsome mechanism. We compare the ensemble of high-z observations with large\nsamples of well-observed low-z ellipticals. At the same physical radii, the\nstellar surface mass densities of low and high-z systems are comparable.\nMoreover, the abundance of high surface density material at low redshift is\ncomparable to or larger than that observed at z>1-2, consistent with the\ncontinuous buildup of spheroids over this time. The entire population of\ncompact, high-z red galaxies may be the progenitors of the high-density cores\nof present-day ellipticals, with no need for a decrease in stellar density from\nz=2 to z=0. The primary difference between low and high-z systems is thus the\nobserved low-density material at large radii in low-z spheroids (rather than\nthe high-density material in high-z spheroids). Such low-density material may\neither (1) assemble at z<2 or (2) be present, but not yet detected, at z>2.\nMock observations of low-z massive systems show that the high-z observations do\nnot yet probe sufficiently low surface brightness material to detect the low\nsurface density 'wings' (if present). Thus, if the high-z galaxies resemble the\nmost massive systems today, their inferred effective radii could be\nunder-estimated by factors ~2-4. This difference arises because massive systems\nat low redshift are not well-fit by single Sersic profiles. We discuss\nimplications of our results for physical models of galaxy evolution. \n\n"}
{"id": "0903.2979", "contents": "Title: ULySS: A Full Spectrum Fitting Package Abstract: Aims. We provide an easy-to-use full-spectrum fitting package and explore its\napplications to (i) the determination of the stellar atmospheric parameters and\n(ii) the study of the history of stellar populations. Methods. We developed\nULySS, a package to fit spectroscopic observations against a linear combination\nof non-linear model components convolved with a parametric line-of-sight\nvelocity distribution. The minimization can be either local or global, and\ndetermines all the parameters in a single fit. We use chi2 maps, convergence\nmaps and Monte-Carlo simulations to study the degeneracies, local minima and to\nestimate the errors. Results. We show the importance of determining the shape\nof the continuum simultaneously to the other parameters by including a\nmultiplicative polynomial in the model (without prior pseudo-continuum\ndetermination, or rectification of the spectrum). We also stress the benefice\nof using an accurate line-spread function, depending on the wavelength, so that\nthe line-shape of the models properly match the observation. For simple models,\ni. e., to measure the atmospheric parameters or the age/metallicity of a\nsingle-age stellar population, there is often a unique minimum, or when local\nminima exist they can unambiguously be recognized. For more complex models,\nMonte-Carlo simulations are required to assess the validity of the solution.\nConclusions. The ULySS package is public, simple to use and flexible. The full\nspectrum fitting makes optimal usage of the signal. \n\n"}
{"id": "0903.3411", "contents": "Title: An optical group catalogue to z = 1 from the zCOSMOS 10k sample Abstract: We present a galaxy group catalogue spanning the redshift range 0.1 <~ z <~ 1\nin the ~1.7 deg^2 COSMOS field, based on the first ~10,000 zCOSMOS spectra. The\nperformance of both the Friends-of-Friends (FOF) and Voronoi-Delaunay-Method\n(VDM) approaches to group identification has been extensively explored and\ncompared using realistic mock catalogues. We find that the performance improves\nsubstantially if groups are found by progressively optimizing the group-finding\nparameters for successively smaller groups, and that the highest fidelity\ncatalogue, in terms of completeness and purity, is obtained by combining the\nindependently created FOF and VDM catalogues. The final completeness and purity\nof this catalogue, both in terms of the groups and of individual members,\ncompares favorably with recent results in the literature. The current group\ncatalogue contains 102 groups with N >= 5 spectroscopically confirmed members,\nwith a further ~700 groups with 2 <= N <= 4. Most of the groups can be assigned\na velocity dispersion and a dark-matter mass derived from the mock catalogues,\nwith quantifiable uncertainties. The fraction of zCOSMOS galaxies in groups is\nabout 25% at low redshift and decreases toward ~15% at z ~ 0.8. The zCOSMOS\ngroup catalogue is broadly consistent with that expected from the semi-analytic\nevolution model underlying the mock catalogues. Not least, we show that the\nnumber density of groups with a given intrinsic richness increases from\nredshift z ~ 0.8 to the present, consistent with the hierarchical growth of\nstructure. \n\n"}
{"id": "0903.3895", "contents": "Title: The DMTPC project Abstract: The DMTPC detector is a low-pressure CF4 TPC with optical readout for\ndirectional detection of Dark Matter. The combination of the energy and\ndirectional tracking information allows for an efficient suppression of all\nbackgrounds. The choice of gas (CF4) makes this detector particularly sensitive\nto spin-dependent interactions. \n\n"}
{"id": "0903.5075", "contents": "Title: Astrophysical Smooth Particle Hydrodynamics Abstract: The paper presents a detailed review of the smooth particle hydrodynamics\n(SPH) method with particular focus on its astrophysical applications. We start\nby introducing the basic ideas and concepts and thereby outline all ingredients\nthat are necessary for a practical implementation of the method in a working\nSPH code. Much of SPH's success relies on its excellent conservation properties\nand therefore the numerical conservation of physical invariants receives much\nattention throughout this review. The self-consistent derivation of the SPH\nequations from the Lagrangian of an ideal fluid is the common theme of the\nremainder of the text. We derive a modern, Newtonian SPH formulation from the\nLagrangian of an ideal fluid. It accounts for changes of the local resolution\nlengths which result in corrective, so-called \"grad-h-terms\". We extend this\nstrategy to special relativity for which we derive the corresponding grad-h\nequation set. The variational approach is further applied to a\ngeneral-relativistic fluid evolving in a fixed, curved background space-time.\nParticular care is taken to explicitely derive all relevant equations in a\ncoherent way. \n\n"}
{"id": "0904.0809", "contents": "Title: Aether Unleashed Abstract: We follow a low-energy effective theory approach to identify the general\nclass of theories that describes a vector field (of unconstrained norm) coupled\nto gravity. The resulting set may be regarded as a generalization of the\nconventional vector-tensor theories, and as a high-momentum completion of\naether models. We study the conditions that a viable cosmology, Newtonian limit\nand absence of classical and quantum instabilities impose on the parameters of\nour class of models, and compare these constraints with those derived in\npreviously studied and related cases. The most stringent conditions arise from\nthe quantum stability of the theory, which allows dynamical cosmological\nsolutions only for a non-Maxwellian kinetic term. The gravitational constant in\nthe Newtonian limit turns to be scale dependent, suggesting connections to dark\nmatter and degravitation. This class of theories has a very rich gravitational\nphenomenology, and offers an ample but simple testing ground to study\nmodifications of gravity and their cosmological implications. \n\n"}
{"id": "0904.1136", "contents": "Title: Gamma-Hadron Separation in Very-High-Energy gamma-ray astronomy using a\n  multivariate analysis method Abstract: In recent years, Imaging Atmospheric Cherenkov Telescopes (IACTs) have\ndiscovered a rich diversity of very high energy (VHE, > 100 GeV) gamma-ray\nemitters in the sky. These instruments image Cherenkov light emitted by\ngamma-ray induced particle cascades in the atmosphere. Background from the much\nmore numerous cosmic-ray cascades is efficiently reduced by considering the\nshape of the shower images, and the capability to reduce this background is one\nof the key aspects that determine the sensitivity of a IACT. In this work we\napply a tree classification method to data from the High Energy Stereoscopic\nSystem (H.E.S.S.). We show the stability of the method and its capabilities to\nyield an improved background reduction compared to the H.E.S.S. Standard\nAnalysis. \n\n"}
{"id": "0904.3212", "contents": "Title: Biases on initial mass function determinations. III. Cluster masses\n  derived from unresolved photometry Abstract: It is currently common to use spatially unresolved multi-filter broad-band\nphotometry to determine the masses of individual stellar clusters (and hence\nthe cluster mass function, CMF). I analyze the stochastic effects introduced by\nthe sampling of the stellar initial mass function (SIMF) in the derivation of\nthe individual masses and the CMF and I establish that such effects are the\nlargest contributor to the observational uncertainties. An analytical solution,\nvalid in the limit where uncertainties are small, is provided to establish the\nrange of cluster masses over which the CMF slope can be obtained with a given\naccuracy. The validity of the analytical solution is extended to higher mass\nuncertainties using Monte Carlo simulations and the Gamma approximation. The\nvalue of the Poisson mass is calculated for a large range of ages and a variety\nof filters for solar-metallicity clusters measured with single-filter\nphotometry. A method that uses the code CHORIZOS is presented to simultaneously\nderive masses, ages, and extinctions. The classical method of using unweighted\nUBV photometry to simultaneously establish ages and extinctions of stellar\nclusters is found to be unreliable for clusters older than approx. 30 Ma, even\nfor relatively large cluster masses. On the other hand, augmenting the filter\nset to include longer-wavelength filters and using weights for each filter\nincreases the range of masses and ages that can be accurately measured with\nunresolved photometry. Nevertheless, a relatively large range of masses and\nages is found to be dominated by SIMF sampling effects that render the observed\nmasses useless, even when using UBVRIJHK photometry. A revision of some\nliterature results affected by these effects is presented and possible\nsolutions for future observations and analyses are suggested. \n\n"}
{"id": "0904.3623", "contents": "Title: Destriping CMB temperature and polarization maps Abstract: We study destriping as a map-making method for temperature-and-polarization\ndata for cosmic microwave background observations. We present a particular\nimplementation of destriping and study the residual error in output maps, using\nsimulated data corresponding to the 70 GHz channel of the Planck satellite, but\nassuming idealized detector and beam properties. The relevant residual map is\nthe difference between the output map and a binned map obtained from the signal\n+ white noise part of the data stream. For destriping it can be divided into\nsix components: unmodeled correlated noise, white noise reference baselines,\nreference baselines of the pixelization noise from the signal, and baseline\nerrors from correlated noise, white noise, and signal. These six components\ncontribute differently to the different angular scales in the maps. We derive\nanalytical results for the first three components. This study is related to\nPlanck LFI activities. \n\n"}
{"id": "0905.0654", "contents": "Title: Isotropic AGN Heating with Small Radio Quiet Bubbles in the NGC 5044\n  Group Abstract: (abridged) A Chandra observation of the X-ray bright group NGC 5044 shows\nthat the X-ray emitting gas has been strongly perturbed by recent outbursts\nfrom the central AGN and also by motion of the central dominant galaxy relative\nto the group gas. The NGC 5044 group hosts many small radio quiet cavities with\na nearly isotropic distribution, cool filaments, a semi-circular cold front and\na two-armed spiral shaped feature of cool gas. A GMRT observation of NGC 5044\nat 610 MHz shows the presence of extended radio emission with a \"torus-shaped\"\nmorphology. The largest X-ray filament appears to thread the radio torus,\nsuggesting that the lower entropy gas within the filament is material being\nuplifted from the center of the group. The radio emission at 235 MHz is much\nmore extended than the emission at 610 MHz, with little overlap between the two\nfrequencies. One component of the 235 MHz emission passes through the largest\nX-ray cavity and is then deflected just behind the cold front. A second\ndetached radio lobe is also detected at 235 MHz beyond the cold front. All of\nthe smaller X-ray cavities in the center of NGC 5044 are undetected in the GMRT\nobservations. Since the smaller bubbles are probably no longer momentum driven\nby the central AGN, their motion will be affected by the group \"weather\" as\nthey buoyantly rise outward. Hence, most of the enthalpy within the smaller\nbubbles will likely be deposited near the group center and isotropized by the\ngroup weather. The total mechanical power of the smaller radio quiet cavities\nis $P_c = 9.2 \\times 10^{41}$erg s$^{-1}$ which is sufficient to suppress about\none-half of the total radiative cooling within the central 10 kpc. This is\nconsistent with the presence of H$\\alpha$ emission within this region which\nshows that at least some of the gas is able to cool. \n\n"}
{"id": "0905.1121", "contents": "Title: Binary black holes' effects on electromagnetic fields Abstract: In addition to producing gravitational waves (GW), the dynamics of a binary\nblack hole system could induce emission of electromagnetic (EM) radiation by\naffecting the behavior of plasmas and electromagnetic fields in their vicinity.\nWe here study how the electromagnetic fields are affected by a pair of orbiting\nblack holes through the merger. In particular, we show how the binary's\ndynamics induce a variability in possible electromagnetically induced emissions\nas well as a possible enhancement of electromagnetic fields during the\nlate-merge and merger epochs. These time dependent features will likely leave\ntheir imprint in processes generating detectable emissions and can be exploited\nin the detection of electromagnetic counterparts of gravitational waves. \n\n"}
{"id": "0905.1965", "contents": "Title: The Synoptic All-Sky Infrared (SASIR) Survey Abstract: We are proposing to conduct a multicolor, synoptic infrared (IR) imaging\nsurvey of the Northern sky with a new, dedicated 6.5-meter telescope at San\nPedro M\\'artir (SPM) Observatory. This initiative is being developed in\npartnership with astronomy institutions in Mexico and the University of\nCalifornia. The 4-year, dedicated survey, planned to begin in 2017, will reach\nmore than 100 times deeper than 2MASS. The Synoptic All-Sky Infrared (SASIR)\nSurvey will reveal the missing sample of faint red dwarf stars in the local\nsolar neighborhood, and the unprecedented sensitivity over such a wide field\nwill result in the discovery of thousands of z ~ 7 quasars (and reaching to z >\n10), allowing detailed study (in concert with JWST and Giant Segmented Mirror\nTelescopes) of the timing and the origin(s) of reionization. As a time-domain\nsurvey, SASIR will reveal the dynamic infrared universe, opening new phase\nspace for discovery. Synoptic observations of over 10^6 supernovae and variable\nstars will provide better distance measures than optical studies alone. SASIR\nalso provides significant synergy with other major Astro2010 facilities,\nimproving the overall scientific return of community investments. Compared to\noptical-only measurements, IR colors vastly improve photometric redshifts to z\n~ 4, enhancing dark energy and dark matter surveys based on weak lensing and\nbaryon oscillations. The wide field and ToO capabilities will enable a\nconnection of the gravitational wave and neutrino universe - with events\notherwise poorly localized on the sky - to transient electromagnetic phenomena. \n\n"}
{"id": "0905.1986", "contents": "Title: Challenges facing young astrophysicists Abstract: In order to attract and retain excellent researchers and diverse individuals\nin astrophysics, we recommend action be taken in several key areas impacting\nyoung scientists: (1) Maintain balance between large collaborations and\nindividual projects through distribution of funding; encourage public releases\nof observational and simulation data for use by a broader community. (2)\nImprove the involvement of women, particularly at leading institutions. (3)\nAddress the critical shortage of child care options and design reasonable\nprofession-wide parental leave policies. (4) Streamline the job application and\nhiring process. We summarize our reasons for bringing these areas to the\nattention of the committee, and we suggest several practical steps that can be\ntaken to address them. \n\n"}
{"id": "0905.3062", "contents": "Title: An iterative filter to reconstruct planetary transit signals in the\n  presence of stellar variability Abstract: The detrending algorithms which are widely used to reduce the impact of\nstellar variability on space-based transit surveys are ill-suited for\nestimating the parameters of confirmed planets, as they unavoidably alter the\ntransit signal. We present a post-detection detrending algorithm, which filters\nout signal on other timescales than the period of the transit while preserving\nthe transit signal.\n  We compare the performance of this new filter to a well-established\npre-detection detrending algorithm, by applying both to a set of 20 simulated\nlight curves containing planetary transits, stellar variability, and\ninstrumental noise as expected for the CoRoT space mission, and performing\nanalytic fits to the transits. Compared to the pre-detection benchmark, the new\npost-detection filter systematically yields significantly reduced errors\n(median reduction in relative error over our sample of about 40%) on the\nplanet-to-star radius ratio, system scale and impact parameter. This is\nparticularly important for active stars, where errors induced by variability\ncan otherwise dominate the final error budget on the planet parameters.\n  Aside from improving planet parameter estimates, the new filter preserves all\nsignal at the orbital period of the planet, and thus could also be used to\nsearch for light reflected by the planet. \n\n"}
{"id": "0905.3702", "contents": "Title: Needlet Bispectrum Asymmetries in the WMAP 5-year Data Abstract: We apply the needlet formalism to the Wilkinson Microwave Anisotropy Probe\n5-year data, looking for evidence of non-Gaussianity in the bispectrum of the\nneedlet amplitudes. We confirm earlier findings of an asymmetry in the\nnon-Gaussianity between the northern and southern galactic hemispheres. We\nattempt to isolate which scales and geometrical configurations are most\nanomalous, and find the bispectrum is most significant on large scales and in\nthe more co-linear configurations, and also in the `squeezed' configurations.\nHowever, these anomalies do not appear to affect the estimate of the non-linear\nparameter $\\fnl$, and we see no significant difference between its value\nmeasured in the two hemispheres. \n\n"}
{"id": "0906.0981", "contents": "Title: Submillimeter Number Counts From Statistical Analysis of BLAST Maps Abstract: We describe the application of a statistical method to estimate submillimeter\ngalaxy number counts from confusion limited observations by the Balloon-borne\nLarge Aperture Submillimeter Telescope (BLAST). Our method is based on a\nmaximum likelihood fit to the pixel histogram, sometimes called 'P(D)', an\napproach which has been used before to probe faint counts, the difference being\nthat here we advocate its use even for sources with relatively high\nsignal-to-noise ratios. This method has an advantage over standard techniques\nof source extraction in providing an unbiased estimate of the counts from the\nbright end down to flux densities well below the confusion limit. We\nspecifically analyse BLAST observations of a roughly 10 sq. deg. map centered\non the Great Observatories Origins Deep Survey South (GOODS-S) field. We\nprovide estimates of number counts at the three BLAST wavelengths, 250, 350,\nand 500 microns; instead of counting sources in flux bins we estimate the\ncounts at several flux density nodes connected with power-laws. We observe a\ngenerally very steep slope for the counts of about -3.7 at 250 microns and -4.5\nat 350 and 500 microns, over the range ~0.02-0.5 Jy, breaking to a shallower\nslope below about 0.015 Jy at all three wavelengths. We also describe how to\nestimate the uncertainties and correlations in this method so that the results\ncan be used for model-fitting. This method should be well-suited for analysis\nof data from the Herschel satellite. \n\n"}
{"id": "0906.4195", "contents": "Title: SVOM: a new mission for Gamma-Ray Burst Studies Abstract: We present the SVOM (Space-based multi-band astronomical Variable Object\nMonitor) mission, that is being developed in cooperation between the Chinese\nNational Space Agency (CNSA), the Chinese Academy of Science (CAS) and the\nFrench Space Agency (CNES). Its scientific objectives include the study of the\nGRB phenomenon, GRB physics and progenitors, cosmology, and fundamental\nphysics. SVOM is designed to detect all known types of Gamma-Ray Bursts (GRBs),\nto provide fast and reliable GRB positions, to measure the broadband spectral\ncharacteristics and temporal properties of the GRB prompt emission. This will\nbe obtained in first place thanks to a set of four space flown instruments. A\nwide field (~2 sr) coded mask telescope (ECLAIRs), operating in the 4-250 keV\nenergy range, will provide the triggers and localizations, while a gamma-ray\nnon-imaging spectrometer (GRM), sensitive in the 50 keV-5 MeV domain, will\nextend the prompt emission energy coverage. After a satellite slew, in order to\nplace the GRB direction within field of view of the two narrow field\ninstruments - a soft X-ray (XIAO), and a visible telescope (VT) - the GRB\nposition will be refined and the study of the early phases of the GRB afterglow\nwill be possible. A set of three ground based dedicated instruments, two\nrobotic telescopes (GFTs) and a wide angle optical monitor (GWAC), will\ncomplement the space borne instruments. Thanks to the low energy trigger\nthreshold (~4 keV) of the ECLAIRs, SVOM is ideally suited for the detection of\nsoft, hence potentially most distant, GRBs. Its observing strategy is optimized\nto facilitate follow-up observations from the largest ground based facilities. \n\n"}
{"id": "0906.4350", "contents": "Title: Galaxies-Intergalactic Medium Interaction Calculation --I. Galaxy\n  formation as a function of large-scale environment Abstract: [Abridged] We present the first results of hydrodynamical simulations that\nfollow the formation of galaxies to z=0 in spherical regions of radius ~20\nMpc/h drawn from the Millennium Simulation. The regions have overdensities that\ndeviate by (-2, -1, 0, +1, +2)sigma from the cosmic mean, where sigma is the\nrms mass fluctuation on a scale of ~20Mpc/h at z=1.5. The simulations have mass\nresolution of up to 10^6 Msun/h, cover the entire range of large-scale\nenvironments and allow extrapolation of statistics to the entire 500 (Mpc/h)^3\nMillennium volume. They include gas cooling, photoheating from an ionising\nbackground, SNe feedback and winds, but no AGN. We find that the specific SFR\ndensity at z <~ 10 varies systematically from region to region by up to an\norder of magnitude, but the global value, averaged over all volumes, reproduces\nobservational data. Massive, compact galaxies, similar to those observed in the\nGOODS fields, form in the overdense regions as early as z=6, but do not appear\nin the underdense regions until z~3. These environmental variations are not\ncaused by a dependence of the star formation properties on environment, but\nrather by a strong variation of the halo mass function from one environment to\nanother, with more massive haloes forming preferentially in the denser regions.\nAt all epochs, stars form most efficiently in haloes of circular velocity ~ 250\nkm/s. However, the star formation history exhibits a form of \"downsizing\" (even\nin the absence of AGN): the stars comprising massive galaxies at z=0 have\nmostly formed by z=1-2, whilst those comprising smaller galaxies typically form\nat later times. However, additional feedback is required to limit star\nformation in massive galaxies at late times. \n\n"}
{"id": "0906.4772", "contents": "Title: On Adiabatic Renormalization of Inflationary Perturbations Abstract: We discuss the impact of adiabatic renormalization on the power spectrum of\nscalar and tensor perturbations from inflation. We show that adiabatic\nregularization is ambiguous as it leads to very different results, for\ndifferent adiabatic subtraction schemes, both in the range $v\\equiv k/(aH)\n\\gsim 0.1$ and in the infrared regime. All these schemes agree in the far\nultraviolet, $v\\gg 1$. Therefore, we argue that in the far infrared regime,\n$v\\ll 1$, the adiabatic expansion is no longer valid, and the unrenormalized\nspectra are the physical, measurable quantities. These findings cast some doubt\non the validity of the adiabatic subtraction at horizon exit, $v=1$, to\ndetermine the perturbation spectra from inflation which has recently advocated\nin the literature. \n\n"}
{"id": "0906.4971", "contents": "Title: Kinematic deprojection and mass inversion of spherical systems of known\n  velocity anisotropy Abstract: Traditionally, the mass / velocity anisotropy degeneracy (MAD) inherent in\nthe spherical, stationary, non-streaming Jeans equation has been handled by\nassuming a mass profile and fitting models to the observed kinematical data.\nHere, the opposite approach is considered: the equation of anisotropic\nkinematic projection is inverted for known arbitrary anisotropy to yield the\nspace radial velocity dispersion profile in terms of an integral involving the\nradial profiles of anisotropy and isotropic dynamical pressure. Then, through\nthe Jeans equation, the mass profile is derived in terms of double integrals of\nobservable quantities. Single integral formulas for both deprojection and mass\ninversion are provided for several simple anisotropy models (isotropic, radial,\ncircular, general constant, Osipkov-Merritt, Mamon-Lokas and\nDiemand-Moore-Stadel). Tests of the mass inversion on NFW models with these\nanisotropy models yield accurate results in the case of perfect observational\ndata, and typically better than 70% (in 4 cases out of 5) accurate mass\nprofiles for the sampling errors expected from current observational data on\nclusters of galaxies. For the NFW model with mildly increasing radial\nanisotropy, the mass is found to be insensitive to the adopted anisotropy\nprofile at 7 scale radii and to the adopted anisotropy radius at 3 scale radii.\nThis anisotropic mass inversion method is a useful complementary tool to\nanalyze the mass and anisotropy profiles of spherical systems. It provides the\npractical means to lift the MAD in quasi-spherical systems such as globular\nclusters, round dwarf spheroidal and elliptical galaxies, as well as groups and\nclusters of galaxies, when the anisotropy of the tracer is expected to be\nlinearly related to the slope of its density. \n\n"}
{"id": "0907.0473", "contents": "Title: Flat 3-Brane with Tension in Cascading Gravity Abstract: In the Cascading Gravity brane-world scenario, our 3-brane lies within a\nsuccession of lower-codimension branes, each with their own induced gravity\nterm, embedded into each other in a higher-dimensional space-time. In the\n6+1-dimensional version of this scenario, we show that a 3-brane with tension\nremains flat, at least for sufficiently small tension that the weak-field\napproximation is valid. The bulk solution is nowhere singular and remains in\nthe perturbative regime everywhere. \n\n"}
{"id": "0907.0675", "contents": "Title: DMTPC: A dark matter detector with directional sensitivity Abstract: By correlating nuclear recoil directions with the Earth's direction of motion\nthrough the Galaxy, a directional dark matter detector can unambiguously detect\nWeakly Interacting Massive Particles (WIMPs), even in the presence of\nbackgrounds. Here, we describe the Dark Matter Time-Projection Chamber (DMTPC)\ndetector, a TPC filled with CF4 gas at low pressure (0.1 atm). Using this\ndetector, we have measured the vector direction (head-tail) of nuclear recoils\ndown to energies of 100 keV with an angular resolution of <15 degrees. To study\nour detector backgrounds, we have operated in a basement laboratory on the MIT\ncampus for several months. We are currently building a new, high-radiopurity\ndetector for deployment underground at the Waste Isolation Pilot Plant facility\nin New Mexico. \n\n"}
{"id": "0907.1118", "contents": "Title: Transient detections and other real-time data processing from wide-field\n  chambers MASTER-VWF Abstract: At present time Robotic observatory making is of current importance. Having a\nlarge field of view and being able to point at anywhere, Robotic astronomical\nsystems are indispensable when they looking for transients like grb, supernovae\nexplosions, novae etc, as it's impossible in these cases to foresee what you\nshould point you telescope at and when. In work are described prompt GRB\nobservations received on wide-field chambers MASTER-VWF, and also methods of\nthe images analysis and transients classifications applied in real-time data\nprocessing in this experiment. For 7 months of operation 6 synchronous\nobservations of gamma-ray burst had been made by MASTER VWF in Kislovodsk and\nIrkutsk. In all cases a high upper limits have been received (see tabl \\ref\n{tab_grbwf} and fig. \\ref {allgrb}). \n\n"}
{"id": "0907.2731", "contents": "Title: Improved CMB Map from WMAP Data Abstract: The cosmic microwave background (CMB) temperature maps published by the\nWilkinson Microwave Anisotropy Probe (WMAP) team are found to be inconsistent\nwith the differential time-ordered data (TOD), from which the maps are\nreconstructed. The inconsistency indicates that there is a serious problem in\nthe map making routine of the WMAP team, and it is necessary to reprocess the\nWMAP data. We develop a self-consistent software package of map-making and\npower spectrum estimation independently of the WMAP team. Our software passes a\nvariety of tests. New CMB maps are then reconstructed, which are significantly\ndifferent from the official WMAP maps. In the new maps, the inconsistency\ndisappeared, along with the hitherto unexplained high level alignment between\nthe CMB quadrupole and octopole components detected in released WMAP maps. An\nimproved CMB cross-power spectrum is then derived from the new maps which\nbetter agrees with that of BOOMRANG. Two important results are hence obtained:\nthe CMB quadrupole drops to nearly zero, and the power in multiple moment range\nbetween 200 and 675 decreases on average by about 13%, causing the best-fit\ncosmological parameters to change considerably, e.g., the total matter density\nincreases from 0.26 up to 0.32 and the dark energy density decreases from 0.74\ndown to 0.68. These new parameters match with improved accuracy those of other\nindependent experiments. Our results indicate that there is still room for\nsignificant revision in the cosmological model parameters. \n\n"}
{"id": "0907.3768", "contents": "Title: Accelerating Dust Temperature Calculations with Graphics Processing\n  Units Abstract: When calculating the infrared spectral energy distributions (SEDs) of\ngalaxies in radiation-transfer models, the calculation of dust grain\ntemperatures is generally the most time-consuming part of the calculation.\nBecause of its highly parallel nature, this calculation is perfectly suited for\nmassively parallel general-purpose Graphics Processing Units (GPUs). This paper\npresents an implementation of the calculation of dust grain equilibrium\ntemperatures on GPUs in the Monte-Carlo radiation transfer code Sunrise, using\nthe CUDA API. The GPU can perform this calculation 69 times faster than the 8\nCPU cores, showing great potential for accelerating calculations of galaxy\nSEDs. \n\n"}
{"id": "0907.5450", "contents": "Title: Exploring intermediate and massive black-hole binaries with the Einstein\n  Telescope Abstract: We discuss the capability of a third-generation ground-based detector such as\nthe Einstein Telescope (ET) to enhance our astrophysical knowledge through\ndetections of gravitational waves emitted by binaries including\nintermediate-mass and massive black holes. The design target for such\ninstruments calls for improved sensitivity at low frequencies, specifically in\nthe ~ 1-10 Hz range. This will allow the detection of gravitational waves\ngenerated in binary systems containing black holes of intermediate mass, ~\n100-1000 solar masses. We primarily discuss two different source types --\nmergers between two intermediate mass black holes (IMBHs) of comparable mass,\nand intermediate-mass-ratio inspirals (IMRIs) of smaller compact objects with\nmass ~ 1-10 solar masses into IMBHs. IMBHs may form via two channels: (i) in\ndark matter halos at high redshift through direct collapse or the collapse of\nvery massive metal-poor Population III stars, or (ii) via runaway stellar\ncollisions in globular clusters. In this paper, we will discuss both formation\nchannels, and both classes of merger in each case. We review existing rate\nestimates where these exist in the literature, and provide some new\ncalculations for the approximate numbers of events that will be seen by a\ndetector like the Einstein Telescope. These results indicate that the ET may\nsee a few to a few thousand comparable-mass IMBH mergers and as many as several\nhundred IMRI events per year. These observations will significantly enhance our\nunderstanding of galactic black-hole growth, of the existence and properties of\nIMBHs and of the astrophysics of globular clusters. We finish our review with a\ndiscussion of some more speculative sources of gravitational waves for the ET,\nincluding hypermassive white dwarfs and eccentric stellar-mass compact-object\nbinaries. \n\n"}
{"id": "0908.0864", "contents": "Title: Point source searches with the ANTARES neutrino telescope Abstract: With the installation of its last two lines in May 2008, ANTARES is currently\nthe largest neutrino detector in the Northern Hemisphere. The detector\ncomprises 12 detection lines, carrying 884 ten-inch photomultipliers, at a\ndepth of about 2500 m in the Mediterranean Sea, about 40 km off shore Toulon in\nSouth France. Thanks to its exceptional angular resolution, better than 0.3\ndegree above 10 TeV, and its favorable location with the Galactic Center\nvisible 63% of time, ANTARES is specially suited for the search of\nastrophysical point sources. Since 2007 ANTARES has been taking data in smaller\nconfigurations with 5 and 10 lines. With only 5 lines it already has been\npossible to set the most restrictive upper limits in the Southern sky. In this\ncontribution we present the search of point sources with the 5-line data\nsample. \n\n"}
{"id": "0908.2726", "contents": "Title: The Sunyaev-Zeldovich effect in superclusters of galaxies using\n  gasdynamical simulations: the case of Corona Borealis Abstract: [Abridged] We study the thermal and kinetic Sunyaev-Zel'dovich (SZ) effect\nassociated with superclusters of galaxies using the MareNostrum Universe SPH\nsimulation. We consider superclusters similar to the Corona Borealis\nSupercluster (CrB-SC). This paper is motivated by the detection at 33GHz of a\nstrong temperature decrement in the CMB towards the core of this supercluster.\nMultifrequency observations with VSA and MITO suggest the existence of a\nthermal SZ effect component in the spectrum of this cold spot, which would\naccount for roughly 25% of the total observed decrement. We identify nine\nregions containing superclusters similar to CrB-SC, obtain the associated SZ\nmaps and calculate the probability of finding such SZ signals arising from hot\ngas within the supercluster. Our results show that WHIM produces a thermal SZ\neffect much smaller than the observed value. Neither can summing the\ncontribution of small clusters and galaxy groups in the region explain the\namplitude of the SZ signal. When we take into account the actual posterior\ndistribution from the observations, the probability that WHIM can cause a\nthermal SZ signal like the one observed is <1%, rising up to a 3.2% when the\ncontribution of small clusters and galaxy groups is included. If the\nsimulations provide a suitable description of the gas physics, then we conclude\nthat the thermal SZ component of the CrB spot most probably arises from an\nunknown galaxy cluster along the line of sight. The simulations also show that\nthe kinetic SZ signal associated with the supercluster cannot provide an\nexplanation for the remaining 75% of the observed cold spot in CrB. \n\n"}
{"id": "0908.4148", "contents": "Title: Metal-rich absorbers at high redshifts: abundance patterns Abstract: (Abbreviated) From six spectra of high-z QSOs, we select eleven metal-rich,\nZ>=Z_solar, and optically-thin to the ionizing radiation, N(HI)<10^17 cm^-2,\nabsorption systems ranging between z=1.5 and z=2.9 and revealing lines of\ndifferent ions in subsequent ionization stages. The majority of the systems (10\nfrom 11) show abundance patterns which relate them to outflows from low and\nintermediate mass stars. All systems have sub-kpc linear sizes along the\nline-of-sight with many less than 20 pc. In several systems, silicon is\ndeficient, presumably due to the depletion onto dust grains in the envelopes of\ndust-forming stars and the subsequent gas-dust separation. At any value of\n[C/H], nitrogen can be either deficient, [N/C]<0, or enhanced, [N/C]>0, which\nsupposes that the nitrogen enrichment occurs irregularly. In some cases, the\nlines of MgII 2796, 2803 appear to be shifted, probably as a result of an\nenhanced content of heavy isotopes 25Mg and 26Mg in the absorbing gas relative\nto the solar isotopic composition. Seven absorbers are characterized by low\nmean ionization parameter U, log U<-2.3, among them only one system has a\nredshift z>2 whereas all others are found at z ~= 1.8. Comparing the space\nnumber density of metal-rich absorbers with the comoving density of\nstar-forming galaxies at z ~= 2, we estimate that the circumgalactic volume of\neach galaxy is populated by 10^7 - 10^8 such absorbers with total mass\n<=1/100th of the stellar galactic mass. Possible effects of high metal content\non the peak values of star-forming and AGN activities at z~2 are discussed. \n\n"}
{"id": "0909.0654", "contents": "Title: A prototype of a directional detector for non-baryonic dark matter\n  search: MIMAC (Micro-TPC Matrix of Chambers) Abstract: We have developed a micro-tpc using a pixelized bulk micromegas coupled to\ndedicated acquisition electronics as a read-out allowing to reconstruct the\nthree dimensional track of a few keV recoils. The prototype has been tested\nwith the Amande facility at the IRSN-Cadarache providing monochromatic\nneutrons. The first results concerning discrimination of a few keV electrons\nand proton recoils are presented. \n\n"}
{"id": "0909.1747", "contents": "Title: The physics of galaxy evolution with EAGLE Abstract: One of the prominent science goal of the ELTs will be to study the physics\nand mass assembly of galaxies at very high redshifts. Here, we present the\ngalaxy evolution science case for EAGLE, which is a NIR multi-integral field\nspectrograph for the E-ELT currently under phase A study. We summarize results\nof simulations conducted to derive high-level requirements. In particular, we\nshow how we have derived the specifications for the ensquared energy that the\nAO system needs to provide to reach the scientific goals of the instrument.\nFinally, we present future strategies to conduct galaxy surveys with EAGLE. \n\n"}
{"id": "0909.2795", "contents": "Title: Data reduction strategy of the Effelsberg-Bonn HI Survey (EBHIS) Abstract: Since autumn 2008 a new L-band 7-Feed-Array receiver is used for an HI 21-cm\nline survey performed with the 100-m Effelsberg telescope. The survey will\ncover the whole northern hemisphere comprising both, the galactic and\nextragalactic sky in parallel. Using state-of-the-art FPGA based digital Fast\nFourier Transform spectrometers, superior in dynamic range and temporal\nresolution, allows to apply sophisticated radio frequency interferences (RFI)\nmitigation schemes to the survey data.\n  The EBHIS data reduction software includes the RFI mitigation, gain-curve\ncorrection, intensity calibration, stray-radiation correction, gridding, and\nsource detection. We discuss the severe degradation of radio astronomical HI\ndata by RFI signals and the gain in scientific yield when applying modern RFI\nmitigation schemes. For this aim simulations of the galaxy distribution within\nthe local volume (z<0.07) with and without RFI degradation were performed.\nThese simulations, allow us to investigate potential biases and selection\neffects introduced by the data reduction software and the applied source\nparametrization methods. \n\n"}
{"id": "0909.2797", "contents": "Title: Low-column density HVC and IVC gas in the halo of the Milky Way Abstract: Recent studies of the circumgalactic gaseous environment of the Milky Way\nhave concentrated on the distribution, chemical composition, and physical\nproperties of the most massive neutral gas clouds and the highly-ionized halo\nabsorbers. Relatively little effort has been put so far in exploring the\ncircumgalactic neutral and weakly ionized metal absorbers at low HI column\ndensities.\n  With our work we systematically study the distribution and physical\nproperties of neutral and ionised low-column density gas in the halo of the\nMilky Way. We combine CaII and NaI absorption line measurements with HI 21-cm\nemission line data. For some of the sight lines high-resolution radio synthesis\nobservations were performed allowing us to study small-scale structures that\ncannot be resolved with single dish telescopes.\n  In total 177 lines of sight were observed, providing a large\nabsorption-selected data sample for the analysis of IVC and HVC gas in the\ncircumgalactic environment of the Milky Way. The study allows us to compare the\nobserved absorption column density distribution (CDD) of gas in the Milky Way\nhalo with the overall CDD of intervening absorbers towards quasars. The\nsensitive absorption line analysis enables us to identify the neutral and\nionised gaseous structures at low column densities and small angular extent\nthat possibly remain unseen in large 21-cm all-sky surveys. If this gas cover a\nsignificant portion of the sky, it possibly has a large influence on the\nevolution of the Milky Way. \n\n"}
{"id": "0909.2830", "contents": "Title: HAWC Timing Calibration Abstract: The High-Altitude Water Cherenkov (HAWC) Experiment is a second-generation\nhighsensitivity gamma-ray and cosmic-ray detector that builds on the experience\nand technology of the Milagro observatory. Like Milagro, HAWC utilizes the\nwater Cherenkov technique to measure extensive air showers. Instead of a pond\nfilled with water (as in Milagro) an array of closely packed water tanks is\nused. The event direction will be reconstructed using the times when the PMTs\nin each tank are triggered. Therefore, the timing calibration will be crucial\nfor reaching an angular resolution as low as 0.25 degrees.We propose to use a\nlaser calibration system, patterned after the calibration system in Milagro.\nLike Milagro, the HAWC optical calibration system will use ~1 ns laser light\npulses. Unlike Milagro, the PMTs are optically isolated and require their own\noptical fiber calibration. For HAWC the laser light pulses will be directed\nthrough a series of optical fan-outs and fibers to illuminate the PMTs in\napproximately one half of the tanks on any given pulse. Time slewing\ncorrections will be made using neutraldensity filters to control the light\nintensity over 4 orders of magnitude. This system is envisioned to run\ncontinuously at a low rate and will be controlled remotely. In this paper, we\npresent the design of the calibration system and first measurements of its\nperformance. \n\n"}
{"id": "0909.3737", "contents": "Title: The orbits of open clusters in the Galaxy Abstract: We present and analyze kinematics and orbits for a sample of 488 open\nclusters in the Galaxy. The velocity ellipsoid for our present sample is\nderived as ($\\sigma_{U}$, $\\sigma_{V}$, $\\sigma_{W})$=$(28.7$, 15.8, 11.0) km\ns$^{-1}$ which represents a young thin disc population. We also confirm that\nthe velocity dispersions increase with the age of cluster subsample. The orbits\nof open clusters are calculated with three Galactic gravitational potential\nmodels. The errors of orbital parameters are also calculated considering the\nintrinsic variation of the orbital parameters and the effects of observational\nuncertainties. The observational uncertainties dominate the errors of derived\norbital parameters. The vertical motions of clusters calculated using different\nGalactic disc models are rather different. The observed radial metallicity\ngradient of clusters is derived with a slope of $b=-0.070\\pm0.011$ dex\nkpc$^{-1}$. The radial metallicity gradient of clusters based on their\napogalactic distances is also derived with a slope of $b=-0.082\\pm0.014$ dex\nkpc$^{-1}$. The distribution of derived orbital eccentricities for open\nclusters is very similar to the one derived for the field population of dwarfs\nand giants in the thin disc. \n\n"}
{"id": "0909.4164", "contents": "Title: Galaxies and Cladistics Abstract: The Hubble tuning fork diagram, based on morphology and established in the\n1930s, has always been the preferred scheme for classification of galaxies.\nHowever, the current large amount of multiwavelength data, most often spectra,\nfor objects up to very high distances, asks for more sophisticated statistical\napproaches. Interpreting formation and evolution of galaxies as a ?transmission\nwith modification' process, we have shown that the concepts and tools of\nphylogenetic systematics can be heuristically transposed to the case of\ngalaxies. This approach, which we call ?astrocladistics', has successfully been\napplied on several samples. Many difficulties still remain, some of them being\nspecific to the nature of both galaxies and their diversification processes,\nsome others being classical in cladistics, like the pertinence of the\ndescriptors in conveying any useful evolutionary information. \n\n"}
{"id": "0909.4397", "contents": "Title: Equivalence of modified gravity equation to the Clausius relation Abstract: We explicitly show that the equations of motion for modified gravity theories\nof $F(R)$-gravity, the scalar-Gauss-Bonnet gravity, $F(\\mathcal{G})$-gravity\nand the non-local gravity are equivalent to the Clausius relation in\nthermodynamics. In addition, we discuss the relation between the expression of\nthe entropy and the contribution from the modified gravity as well as the\nmatter to the definition of the energy flux (heat). \n\n"}
{"id": "0909.5044", "contents": "Title: Spectroscopic Cosmological Surveys in the Far-IR Abstract: We show the feasibility of spectroscopic cosmological surveys with the SAFARI\ninstrument onboard of SPICA. The work is done through simulations that make use\nof both empirical methods, i.e. the use of observed luminosity functions and\ntheoretical models for galaxy formation and evolution. The relations assumed\nbetween the line emission to trace AGN and star formation activity have been\nderived from the observations of local samples of galaxies. The results\nconverge to indicate the use of blind spectroscopy with the SAFARI FTS at\nvarious resolutions to study galaxy evolution from the local to the distant\n(z~3) Universe. Specifically, two different and independent galaxy evolution\nmodels predict about 7-10 sources to be spectroscopically detected in more than\none line in a 2'x 2'SAFARI field of view, down to the expected flux limits of\nSAFARI, with about 20% of sources to be detected at z>2. SPICA-SAFARI will be\ntherefore excellent at detecting high-z sources and at assessing in a direct\nway their nature (e.g whether mainly AGN or Star Formation powered) thanks to\nblind spectroscopy. \n\n"}
{"id": "0909.5439", "contents": "Title: Analysis of galaxy SEDs from far-UV to far-IR with CIGALE: Studying a\n  SINGS test sample Abstract: Photometric data of galaxies covering the rest-frame wavelength range from\nfar-UV to far-IR make it possible to derive galaxy properties with a high\nreliability by fitting the attenuated stellar emission and the related dust\nemission at the same time. For this purpose we wrote the code CIGALE (Code\nInvestigating GALaxy Emission) that uses model spectra composed of the Maraston\n(or PEGASE) stellar population models, synthetic attenuation functions based on\na modified Calzetti law, spectral line templates, the Dale & Helou dust\nemission models, and optional spectral templates of obscured AGN. Depending on\nthe input redshifts, filter fluxes are computed for the model set and compared\nto the galaxy photometry by carrying out a Bayesian-like analysis. CIGALE was\ntested by analysing 39 nearby galaxies selected from SINGS. The reliability of\nthe different model parameters was evaluated by studying the resulting\nexpectation values and their standard deviations in relation to the input model\ngrid. Moreover, the influence of the filter set and the quality of photometric\ndata on the code results was estimated. For up to 17 filters between 0.15 and\n160 mum, we find robust results for the mass, star formation rate, effective\nage of the stellar population at 4000 A, bolometric luminosity, luminosity\nabsorbed by dust, and attenuation in the far-UV. A study of the mutual\nrelations between the reliable properties confirms the dependence of star\nformation activity on morphology in the local Universe and indicates a\nsignificant drop in this activity at about 10^11 M_sol towards higher total\nstellar masses. The dustiest sample galaxies are present in the same mass\nrange. [abridged] \n\n"}
{"id": "0910.1093", "contents": "Title: Galaxy luminosities, stellar masses, sizes, velocity dispersions as a\n  function of morphological type Abstract: We provide fits to the distribution of galaxy luminosity, size, velocity\ndispersion and stellar mass as a function of concentration index C_r and\nmorphological type in the SDSS. We also quantify how estimates of the fraction\nof `early' or `late' type galaxies depend on whether the samples were cut in\ncolor, concentration or light profile shape, and compare with similar estimates\nbased on morphology. Our fits show that Es account for about 20% of the r-band\nluminosity density, rho_Lr, and 25% of the stellar mass density, rho_*;\nincluding S0s and Sas increases these numbers to 33% and 40%, and 50% and 60%,\nrespectively. Summed over all galaxy types, we find rho_* ~ 3 * 10^8 M_Sun\nMpc^{-3} at z ~ 0. This is in good agreement with expectations based on\nintegrating the star formation history. However, compared to most previous\nwork, we find an excess of objects at large masses, up to a factor of ~ 10 at\nM_* ~ 5*10^{11} M_Sun. The stellar mass density further increases at large\nmasses if we assume different IMFs for Es and spiral galaxies, as suggested by\nsome recent chemical evolution models, and results in a better agreement with\nthe dynamical mass function. We also show that the trend for ellipticity to\ndecrease with luminosity is primarily because the E/S0 ratio increases at large\nL. However, the most massive galaxies, M_* > 5 * 10^{11} M_Sun, are less\nconcentrated and not as round as expected if one extrapolates from lower L, and\nthey are not well-fit by pure deVaucouleur laws. This suggests formation\nhistories with recent radial mergers. Finally, we show that the age-size\nrelation is flat for Es of fixed dynamical mass, but, at fixed M_dyn, S0s and\nSas with large sizes tend to be younger. Explaining this difference between E\nand S0 formation is a new challenge for models of early-type galaxy formation. \n\n"}
{"id": "0910.1351", "contents": "Title: Solving the Corner-Turning Problem for Large Interferometers Abstract: The so-called corner turning problem is a major bottleneck for radio\ntelescopes with large numbers of antennas. The problem is essentially that of\nrapidly transposing a matrix that is too large to store on one single device;\nin radio interferometry, it occurs because data from each antenna needs to be\nrouted to an array of processors that will each handle a limited portion of the\ndata (a frequency range, say) but requires input from each antenna. We present\na low-cost solution allowing the correlator to transpose its data in real time,\nwithout contending for bandwidth, via a butterfly network requiring neither\nadditional RAM memory nor expensive general-purpose switching hardware. We\ndiscuss possible implementations of this using FPGA, CMOS, analog logic and\noptical technology, and conclude that the corner turner cost can be small even\nfor upcoming massive radio arrays. \n\n"}
{"id": "0910.2854", "contents": "Title: FISH: A 3D parallel MHD code for astrophysical applications Abstract: FISH is a fast and simple ideal magneto-hydrodynamics code that scales to ~10\n000 processes for a Cartesian computational domain of ~1000^3 cells. The\nsimplicity of FISH has been achieved by the rigorous application of the\noperator splitting technique, while second order accuracy is maintained by the\nsymmetric ordering of the operators. Between directional sweeps, the\nthree-dimensional data is rotated in memory so that the sweep is always\nperformed in a cache-efficient way along the direction of contiguous memory.\nHence, the code only requires a one-dimensional description of the conservation\nequations to be solved. This approach also enable an elegant novel\nparallelisation of the code that is based on persistent communications with MPI\nfor cubic domain decomposition on machines with distributed memory. This scheme\nis then combined with an additional OpenMP parallelisation of different sweeps\nthat can take advantage of clusters of shared memory. We document the detailed\nimplementation of a second order TVD advection scheme based on flux\nreconstruction. The magnetic fields are evolved by a constrained transport\nscheme. We show that the subtraction of a simple estimate of the hydrostatic\ngradient from the total gradients can significantly reduce the dissipation of\nthe advection scheme in simulations of gravitationally bound hydrostatic\nobjects. Through its simplicity and efficiency, FISH is as well-suited for\nhydrodynamics classes as for large-scale astrophysical simulations on\nhigh-performance computer clusters. In preparation for the release of a public\nversion, we demonstrate the performance of FISH in a suite of astrophysically\norientated test cases. \n\n"}
{"id": "0910.2877", "contents": "Title: On Neutral Absorption and Spectral Evolution in X-ray Binaries Abstract: Current X-ray observatories make it possible to follow the evolution of\ntransient and variable X-ray binaries across a broad range in luminosity and\nsource behavior. In such studies, it can be unclear whether evolution in the\nlow energy portion of the spectrum should be attributed to evolution in the\nsource, or instead to evolution in neutral photoelectric absorption. Dispersive\nspectrometers make it possible to address this problem. We have analyzed a\nsmall but diverse set of X-ray binaries observed with the Chandra High Energy\nTransmission Grating Spectrometer across a range in luminosity and different\nspectral states. The column density in individual photoelectric absorption\nedges remains constant with luminosity, both within and across source spectral\nstates. This finding suggests that absorption in the interstellar medium\nstrongly dominates the neutral column density observed in spectra of X-ray\nbinaries. Consequently, evolution in the low energy spectrum of X-ray binaries\nshould properly be attributed to evolution in the source spectrum. We discuss\nour results in the context of X-ray binary spectroscopy with current and future\nX-ray missions. \n\n"}
{"id": "0910.3250", "contents": "Title: Astrometry and photometry with HST-WFC3. I. Geometric distortion\n  corrections of F225W, F275W, F336W bands of the UVIS-channel Abstract: An accurate geometric distortion solution for the Hubble Space Telescope\nUVIS-channel of Wide Field Camera 3 is the first step towards its use for high\nprecision astrometry. In this work we present an average correction that\nenables a relative astrometric accuracy of ~1 mas (in each axis for well\nexposed stars) in three broad-band ultraviolet filters (F225W, F275W, and\nF336W). More data and a better understanding of the instrument are required to\nconstrain the solution to a higher level of accuracy. \n\n"}
{"id": "0910.4393", "contents": "Title: Photometric redshift estimation using Gaussian processes Abstract: We present a comparison between Gaussian processes (GPs) and artificial\nneural networks (ANNs) as methods for determining photometric redshifts for\ngalaxies, given training set data. In particular, we compare their degradation\nin performance as the training set size is degraded in ways which might be\ncaused by the observational limitations of spectroscopy. We find that\nperformance with large, complete training sets is very similar, although the\nANN achieves slightly smaller root mean square errors. If the size of the\ntraining set is reduced by random sampling, the RMS errors of both methods\nincrease, but they do so to a lesser extent and in a much smoother manner for\nthe case of GP regression. When training objects are removed at redshifts\n1.3<z<1.7, to simulate the effects of the \"redshift desert\" of optical\nspectroscopy, the GP regression is successful at interpolating across the\nredshift gap, while the ANN suffers from strong bias for test objects in this\nredshift range. Overall, GP regression has attractive properties for\nphotometric redshift estimation, particularly for deep, high-redshift surveys\nwhere it is difficult to obtain a large, complete training set. At present,\nunlike the ANN code, public GP regression codes do not take account of\ninhomogeneous measurement errors on the photometric data, and thus cannot\nestimate reliable uncertainties on the predicted redshifts. However, a better\ntreatment of errors is in principle possible, and the promising results in this\npaper suggest that such improved GP algorithms should be pursued. (abridged) \n\n"}
{"id": "0910.4623", "contents": "Title: Partial CMB maps: bias removal and optimal binning of the angular power\n  spectrum Abstract: We present a semi-analytical method to investigate the systematic effects and\nstatistical uncertainties of the calculated angular power spectrum when\nincomplete spherical maps are used. The computed power spectrum suffers in\nparticular a loss of angular frequency resolution, which can be written as\n\\delta_l ~ \\pi/\\gamma_max, where \\gamma_max is the effective maximum extent of\nthe partial spherical maps. We propose a correction algorithm to reduce\nsystematic effects on the estimated C_l, as obtained from the partial map\nprojection on the spherical harmonic Ylm(l,m) basis. We have derived near\noptimal bands and weighting functions in l-space for power spectrum calculation\nusing small maps, and a correction algorithm for partially masked spherical\nmaps that contain information on the angular correlations on all scales. \n\n"}
{"id": "0910.5280", "contents": "Title: Non-Gaussian Probability Distribution for the CMB Angular Power Spectra? Abstract: This is my contribution to Proceedings of the International Workshop on\nCosmic Structure and Evolution, September 23-25, 2009, Bielefeld, Germany. In\nmy talk I presented some non-Gaussian features of the foreground reduced WMAP\nfive year full sky temperature maps, which were recently reported in\narXiv:0906.4954 paper by V.Vanchurin. And in these notes I first discuss the\nstatistics behind this analysis in some detail. Then I describe invaluable\ninsights which I got from discussions after my talk on the Workshop. And\nfinally I explain why, in my current opinion, the signal detected in\narXiv:0906.4954 can hardly have something to do with cosmological\nperturbations, but rather it presents a fancy measurement of the Milky Way\nangular width in the microwave frequency range. \n\n"}
{"id": "0910.5723", "contents": "Title: Metal-line emission from the warm-hot intergalactic medium: I. Soft\n  X-rays Abstract: Emission lines from metals offer one of the most promising ways to detect the\nelusive warm-hot intergalactic medium (WHIM; 10^5 K<T<10^7 K), which is thought\nto contain a substantial fraction of the baryons in the low-redshift Universe.\nWe present predictions for the soft X-ray line emission from the WHIM using a\nsubset of cosmological simulations from the OverWhelmingly Large Simulations\n(OWLS) project. We use the OWLS models to test the dependence of the predicted\nemission on a range of physical prescriptions, such as cosmology, gas cooling\nand feedback from star formation and accreting black holes. Provided that\nmetal-line cooling is taken into account, the models give surprisingly similar\nresults, indicating that the predictions are robust. Soft X-ray lines trace the\nhotter part of the WHIM (T>10^6 K). We find that the OVIII 18.97A is the\nstrongest emission line, with a predicted maximum surface brightness of ~10^2\nphoton/s/cm^2/sr, but a number of other lines are only slightly weaker. All\nlines show a strong correlation between the intensity of the observed flux and\nthe density and metallicity of the gas responsible for the emission. On the\nother hand, the potentially detectable emission consistently corresponds to the\ntemperature at which the emissivity of the electronic transition peaks. The\nemission traces neither the baryonic nor the metal mass. In particular, the\nemission that is potentially detectable with proposed missions, traces\noverdense (rho>10^2rho_mean) and metal-rich (Z>0.1Z_sun) gas in and around\ngalaxies and groups. While soft X-ray line emission is therefore not a\npromising route to close the baryon budget, it does offer the exciting\npossibility to image the gas accreting onto and flowing out of galaxies. \n\n"}
{"id": "0911.0421", "contents": "Title: Axions, Inflation and the Anthropic Principle Abstract: The QCD axion is the leading solution to the strong-CP problem, a dark matter\ncandidate, and a possible result of string theory compactifications. However,\nfor axions produced before inflation, symmetry-breaking scales of $f_a \\gtrsim\n10^{12}$ GeV (which are favored in string-theoretic axion models) are ruled out\nby cosmological constraints unless both the axion misalignment angle $\\theta_0$\nand the inflationary Hubble scale $H_I$ are extremely fine-tuned. We show that\nattempting to accommodate a high-$f_a$ axion in inflationary cosmology leads to\na fine-tuning problem that is worse than the strong-CP problem the axion was\noriginally invented to solve. We also show that this problem remains unresolved\nby anthropic selection arguments commonly applied to the high-$f_a$ axion\nscenario. \n\n"}
{"id": "0911.1205", "contents": "Title: There was movement that was stationary, for the four-velocity had passed\n  around Abstract: Is the Doppler interpretation of galaxy redshifts in a\nFriedmann-Lemaitre-Robertson-Walker (FLRW) model valid in the context of the\napproach to comoving spatial sections pioneered by de Sitter, Friedmann,\nLemaitre and Robertson, i.e. according to which the 3-manifold of comoving\nspace is characterised by both its curvature and topology? Holonomy\ntransformations for flat, spherical and hyperbolic FLRW spatial sections are\nproposed. By quotienting a simply-connected FLRW spatial section by an\nappropriate group of holonomy transformations, the Doppler interpretation in a\nnon-expanding Minkowski space-time, obtained via four-velocity parallel\ntransport along a photon path, is found to imply that an inertial observer is\nreceding from herself at a speed greater than zero, implying contradictory\nworld-lines. The contradiction in the multiply-connected case occurs for\narbitrary redshifts in the flat and spherical cases, and for certain large\nredshifts in the hyperbolic case. The link between the Doppler interpretation\nof redshifts and cosmic topology can be understood physically as the link\nbetween parallel transport along a photon path and the fact that the comoving\nspatial geodesic corresponding to a photon's path can be a closed loop in an\nFLRW model of any curvature. Closed comoving spatial loops are fundamental to\ncosmic topology. \n\n"}
{"id": "0911.2448", "contents": "Title: A Comparison of X-ray and Mid-Infrared Selection of Obscured AGN Abstract: We compare the relative merits of AGN selection at X-ray and mid-infrared\nwavelengths using data from moderately deep fields observed by both Chandra and\nSpitzer. The X-ray-selected AGN sample and associated optical follow-up are\ndrawn from the SEXSI program. Mid-infrared data in these fields are derived\nfrom Spitzer imaging, and mid-infrared AGN selection is accomplished primarily\nthrough application of the IRAC color-color AGN `wedge' selection technique.\nNearly all X-ray sources in these fields which exhibit clear spectroscopic\nsignatures of AGN activity have mid-infrared colors consistent with IRAC AGN\nselection. These are predominantly the most luminous X-ray sources. X-ray\nsources that lack high-ionization and/or broad lines in their optical spectra\nare far less likely to be selected as AGN by mid-infrared color selection\ntechniques. The fraction of X-ray sources identified as AGN in the mid-infrared\nincreases monotonically as the X-ray luminosity increases. Conversely, only 22%\nof mid-infrared-selected AGN are detected at X-ray energies in the moderately\ndeep (~100 ks) Chandra data. We hypothesize that the IRAC AGN that lack X-ray\ndetections are predominantly high-luminosity AGN that are obscured and/or lie\nat high redshift. A stacking analysis of X-ray-undetected sources shows that\nobjects in the mid-infrared AGN selection wedge have average X-ray fluxes in\nthe 2-8 keV band three times higher than sources that fall outside the wedge.\nTheir X-ray spectra are also harder. It is evident from this comparative study\nthat in order to create a complete, unbiased census of supermassive black hole\ngrowth and evolution, a combination of sensitive infrared, X-ray and hard X-ray\nselection is required. We conclude by discussing what samples will be provided\nby upcoming survey missions such as WISE, eROSITA, and NuSTAR. \n\n"}
{"id": "0911.2612", "contents": "Title: The Octave (Birmingham - Sheffield Hallam) automated pipeline for\n  extracting oscillation parameters of solar-like main-sequence stars Abstract: The number of main-sequence stars for which we can observe solar-like\noscillations is expected to increase considerably with the short-cadence\nhigh-precision photometric observations from the NASA Kepler satellite. Because\nof this increase in number of stars, automated tools are needed to analyse\nthese data in a reasonable amount of time. In the framework of the asteroFLAG\nconsortium, we present an automated pipeline which extracts frequencies and\nother parameters of solar-like oscillations in main-sequence and subgiant\nstars. The pipeline uses only the timeseries data as input and does not require\nany other input information. Tests on 353 artificial stars reveal that we can\nobtain accurate frequencies and oscillation parameters for about three quarters\nof the stars. We conclude that our methods are well suited for the analysis of\nmain-sequence stars, which show mainly p-mode oscillations. \n\n"}
{"id": "0911.3500", "contents": "Title: Meaurement of Cosmic Ray elemental composition from the CAKE balloon\n  experiment Abstract: CAKE (Cosmic Abundances below Knee Energies) was a prototype balloon\nexperiment for the determination of the charge spectra and of abundances of the\nprimary cosmic-rays (CR) with Z$>$10. It was a passive instrument made of\nlayers of CR39 and Lexan nuclear track detectors; it had a geometric acceptance\nof $\\sim$0.7 m$^2$sr for Fe nuclei. Here, the scanning and analysis strategies,\nthe algorithms used for the off-line filtering and for the tracking in\nautomated mode of the primary cosmic rays are presented, together with the\nresulting CR charge distribution and their abundances. \n\n"}
{"id": "0911.3651", "contents": "Title: The age of cataclysmic variables: a kinematical study Abstract: Using available astrometric and radial velocity data, the space velocities of\ncataclysmic variables (CVs) with respect to Sun were computed and kinematical\nproperties of various sub-groups of CVs were investigated. Although\nobservational errors of systemic velocities ($\\gamma$) are high, propagated\nerrors are usually less than computed dispersions. According to the analysis of\npropagated uncertainties on the computed space velocities, available sample is\nrefined by removing the systems with the largest propagated uncertainties so\nthat the reliability of the space velocity dispersions was improved. Having a\ndispersion of $51\\pm7$ km s$^{-1}$ for the space velocities, CVs in the current\nrefined sample (159 systems) are found to have $5\\pm1$ Gyr mean kinematical\nage. After removing magnetic systems from the sample, it is found that\nnon-magnetic CVs (134 systems) have a mean kinematical age of $4\\pm1$ Gyr.\nAccording to $5\\pm1$ and $4\\pm1$ Gyr kinematical ages implied by $52\\pm8$ and\n$45\\pm7$ km s$^{-1}$ dispersions for non-magnetic systems below and above the\nperiod gap, CVs below the period gap are older than systems above the gap,\nwhich is a result in agreement with the standard evolution theory of CVs. Age\ndifference between the systems below and above the gap is smaller than that\nexpected from the standard theory, indicating a similarity of the angular\nmomentum loss time scales in systems with low-mass and high-mass secondary\nstars. Assuming an isotropic distribution, $\\gamma$ velocity dispersions of\nnon-magnetic CVs below and above the period gap are calculated\n$\\sigma_\\gamma=30\\pm5$ km s$^{-1}$ and $\\sigma_\\gamma=26\\pm4$ km s$^{-1}$. \n\n"}
{"id": "0911.4448", "contents": "Title: Tuning of Kilopixel Transition Edge Sensor Bolometer Arrays with a\n  Digital Frequency Multiplexed Readout System Abstract: A digital frequency multiplexing (DfMUX) system has been developed and used\nto tune large arrays of transition edge sensor (TES) bolometers read out with\nSQUID arrays for mm-wavelength cosmology telescopes. The DfMUX system\nmultiplexes the input bias voltages and output currents for several bolometers\non a single set of cryogenic wires. Multiplexing reduces the heat load on the\ncamera's sub-Kelvin cryogenic detector stage. In this paper we describe the\nalgorithms and software used to set up and optimize the operation of the\nbolometric camera. The algorithms are implemented on soft processors embedded\nwithin FPGA devices operating on each backend readout board. The result is a\nfully parallelized implementation for which the setup time is independent of\nthe array size. \n\n"}
{"id": "0911.4820", "contents": "Title: Constraint on Coupled Dark Energy Models from Observations Abstract: The coupled dark energy models, in which the quintessence scalar field\nnontrivially couples to the cold dark matter, have been proposed to explain the\ncoincidence problem. In this paper we study the perturbations of coupled dark\nenergy models and the effects of this interaction on the current observations.\nHere, we pay particular attention to its imprint on the late-time Integrated\nSachs-Wolfe (ISW) effect. We perform a global analysis of the constraints on\nthis interaction from the current observational data. Considering the typical\nexponential form as the interaction form, we obtain that the strength of\ninteraction between dark sectors is constrained as $\\beta<0.085$ at 95%\nconfidence level. Furthermore, we find that future measurements with smaller\nerror bars could improve the constraint on the strength of coupling by a factor\ntwo, when compared to the present constraints. \n\n"}
{"id": "0911.4858", "contents": "Title: Model independent tests of the standard cosmological model Abstract: The dark energy problem has led to speculation that not only may LCDM be\nwrong, but that the FLRW models themselves may not even provide the correct\nfamily of background models. We discuss how direct measurements of H(z) can be\nused to formulate tests of the standard paradigm in cosmology. On their own,\nsuch measurements can be used to test for deviations from flat LCDM. When\ncombined with supernovae distances, Hubble rate measurements provide a test of\nthe Copernican principle and the homogeneity assumption of the standard model,\nwhich is independent of dark energy or metric based theory of gravity. A\nmodification of this test also provides a model independent observable for\nflatness which decorrelates curvature determination from dark energy. We\ninvestigate these tests using Hubble rate measurements from age data, as well\nas from a Hubble rate inferred from recent measurements of the baryon acoustic\noscillations. While the current data is too weak to say anything significant,\nthese tests are exciting prospects for the future. \n\n"}
{"id": "0911.4956", "contents": "Title: Introducing ADAPTSMOOTH, a new code for the adaptive smoothing of\n  astronomical images Abstract: We introduce and publicly release a new code, ADAPTSMOOTH, which serves to\nsmooth astronomical images in an adaptive fashion, in order to enhance the\nsignal-to-noise ratio (S/N). The adaptive smoothing scheme allows to take full\nadvantage of the spatially resolved photometric information contained in an\nimage in that at any location the minimal smoothing is applied to reach the\nrequested S/N. Support is given to match more images on the same smoothing\nlength, such that proper estimates of local colours can be done, with a big\npotential impact on multi-wavelength studies of extended sources (galaxies,\nnebulae). Different modes to estimate local S/N are provided. In addition to\nclassical arithmetic-mean averaging mode, the code can operate in median\naveraging mode, resulting in a significant enhancement of the final image\nquality and very accurate flux conservation. To this goal also other code\noptions are implemented and discussed in this paper. Finally, we analyze in\ngreat detail the effect of the adaptive smoothing on galaxy photometry, in\nparticular in terms of surface brightness (SB) profiles and aperture\nphotometry: deviations in SB with respect to the original image can be limited\nto <0.01 mag, with flux difference in apertures of less than 0.001 mag. \n\n"}
{"id": "0911.5692", "contents": "Title: CUDAEASY - a GPU Accelerated Cosmological Lattice Program Abstract: This paper presents, to the author's knowledge, the first graphics processing\nunit (GPU) accelerated program that solves the evolution of interacting scalar\nfields in an expanding universe. We present the implementation in NVIDIA's\nCompute Unified Device Architecture (CUDA) and compare the performance to other\nsimilar programs in chaotic inflation models. We report speedups between one\nand two orders of magnitude depending on the used hardware and software while\nachieving small errors in single precision. Simulations that used to last\nroughly one day to compute can now be done in hours and this difference is\nexpected to increase in the future. The program has been written in the spirit\nof LATTICEEASY and users of the aforementioned program should find it\nrelatively easy to start using CUDAEASY in lattice simulations. The program is\navailable at http://www.physics.utu.fi/theory/particlecosmology/cudaeasy/ under\nthe GNU General Public License. \n\n"}
{"id": "0912.0170", "contents": "Title: Composite CaWO4 Detectors for the CRESST-II Experiment Abstract: CRESST-II, standing for Cryogenic Rare Events Search with Superconducting\nThermometers phase II, is an experiment searching for Dark Matter. In the LNGS\nfacility in Gran Sasso, Italy, a cryogenic detector setup is operated in order\nto detect WIMPs by elastic scattering off nuclei, generating phononic lattice\nexcitations and scintillation light. The thermometers used in the experiment\nconsist of a tungsten thin-film structure evaporated onto the CaWO4 absorber\ncrystal. The process of evaporation causes a decrease in the scintillation\nlight output. This, together with the need of a big-scale detector production\nfor the upcoming EURECA experiment lead to investigations for producing\nthermometers on smaller crystals which are glued onto the absorber crystal. In\nour Run 31 we tested composite detectors for the first time in the Gran Sasso\nsetup. They seem to produce higher light yields as hoped and could provide an\nadditional time based discrimination mechanism for low light yield clamp\nevents. \n\n"}
{"id": "0912.0186", "contents": "Title: Development of a front end ASIC for Dark Matter directional detection\n  with MIMAC Abstract: A front end ASIC (BiCMOS-SiGe 0.35 \\mum) has been developed within the\nframework of the MIMAC detector project, which aims at directional detection of\nnon-baryonic Dark Matter. This search strategy requires 3D reconstruction of\nlow energy (a few keV) tracks with a gaseous \\muTPC. The development of this\nfront end ASIC is a key point of the project, allowing the 3D track\nreconstruction. Each ASIC monitors 16 strips of pixels with charge\npreamplifiers and their time over threshold is provided in real time by current\ndiscriminators via two serializing LVDS links working at 320 MHz. The charge is\nsummed over the 16 strips and provided via a shaper. These specifications have\nbeen chosen in order to build an auto triggered electronics. An acquisition\nboard and the related software were developed in order to validate this\nmethodology on a prototype chamber. The prototype detector presents an anode\nwhere 2 x 96 strips of pixels are monitored. \n\n"}
{"id": "0912.0201", "contents": "Title: LSST Science Book, Version 2.0 Abstract: A survey that can cover the sky in optical bands over wide fields to faint\nmagnitudes with a fast cadence will enable many of the exciting science\nopportunities of the next decade. The Large Synoptic Survey Telescope (LSST)\nwill have an effective aperture of 6.7 meters and an imaging camera with field\nof view of 9.6 deg^2, and will be devoted to a ten-year imaging survey over\n20,000 deg^2 south of +15 deg. Each pointing will be imaged 2000 times with\nfifteen second exposures in six broad bands from 0.35 to 1.1 microns, to a\ntotal point-source depth of r~27.5. The LSST Science Book describes the basic\nparameters of the LSST hardware, software, and observing plans. The book\ndiscusses educational and outreach opportunities, then goes on to describe a\nbroad range of science that LSST will revolutionize: mapping the inner and\nouter Solar System, stellar populations in the Milky Way and nearby galaxies,\nthe structure of the Milky Way disk and halo and other objects in the Local\nVolume, transient and variable objects both at low and high redshift, and the\nproperties of normal and active galaxies at low and high redshift. It then\nturns to far-field cosmological topics, exploring properties of supernovae to\nz~1, strong and weak lensing, the large-scale distribution of galaxies and\nbaryon oscillations, and how these different probes may be combined to\nconstrain cosmological models and the physics of dark energy. \n\n"}
{"id": "0912.0397", "contents": "Title: Constraints on the anisotropy of dark energy Abstract: If the equation of state of dark energy is anisotropic there will be\nadditional quadrupole anisotropy in the cosmic microwave background induced by\nthe time dependent anisotropic stress quantified in terms of $\\Delta w$.\nAssuming that the entire amplitude of the observed quadrupole is due to this\nanisotropy, we conservatively impose a limit of $|\\Delta w| < 2.1\\times\n10^{-4}$ for any value of $w\\ge -1$ assuming that $\\Omega_{\\rm m}<0.5$. This is\nconsiderably tighter than that which comes from SNe. Stronger limits, upto a\nfactor of 10, are possible for specific values of $\\Omega_{\\rm m}$ and $w$.\nSince we assume this component is uncorrelated with the stochastic component\nfrom inflation, we find that both the expectation value and the sample variance\nare increased. There no improvement in the likelihood of an anomalously low\nquadrupole as suggested by previous work on an elliptical universe. \n\n"}
{"id": "0912.1345", "contents": "Title: Faint extended Lyalpha emission due to star formation at the centre of\n  high-column density QSO absorption systems Abstract: We use detailed Lyalpha radiative transfer calculations to further test the\nclaim of Rauch et al. (2008) that they have detected spatially extended faint\nLyalpha emission from the elusive host population of Damped Lyalpha Absorption\nsystems (DLAs) in their recent ultra-deep spectroscopic survey. We investigate\nthe spatial and spectral distribution of Lyalpha emission due to star-formation\nat the centre of DLAs, and its dependence on the spatial and velocity structure\nof the gas. Our model simultaneously reproduces the observed properties of DLAs\nand the faint Lyalpha emitters, including the velocity width and column density\ndistribution of DLAs and the large spatial extent of the emission of the faint\nemitters. Our modelling confirms previous suggestions that DLAs are\npredominately hosted by Dark Matter (DM) halos in the mass range\n10^{9.5}-10^{12} M_sun, and are thus of significantly lower mass than those\ninferred for L_* Lyman Break Galaxies (LBGs). Our modelling suggests that DM\nhalos hosting DLAs retain up to 20% of the cosmic baryon fraction in the form\nof neutral hydrogen, and that star formation at the centre of the halos is\nresponsible for the faint Lyalpha emission. The scattering of a significant\nfraction of the Lyalpha emission to the observed radii, which can be as large\nas 50 kpc or more, requires the amplitude of the bulk motions of the gas at the\ncentre of the halos to be moderate. The observed space density and size\ndistribution of the emitters together with the incidence rate of DLAs suggests\nthat the Lyalpha emission due to star formation has a duty cycle of ~ 25%. \n\n"}
{"id": "0912.1867", "contents": "Title: The nature of optical and near-infrared variability of BL Lacertae Abstract: Since 1997, BL Lacertae has undergone a phase of high optical activity, with\nthe occurrence of several prominent outbursts. Starting from 1999, the Whole\nEarth Blazar Telescope (WEBT) consortium has organized various multifrequency\ncampaigns on this blazar, collecting tens of thousands of data points. One of\nthe main issues in the analysis of this huge dataset has been the study of\ncolour variability. The massive amount of optical and near-infrared data\ncollected during the campaigns enables us to perform a deep analysis of\nmultiband data, with the aim of understanding the flux variability mechanisms.\nWe use a new approach for the analysis of these data, focusing on the source\nspectral evolution. We show that the overall behaviour of the BL Lacertae light\nand colour curves can be explained in terms of changing viewing angle of a\nmoving, discrete emitting region, which causes variable Doppler boosting of the\ncorresponding radiation. A fractal helical structure is suggested to be at the\norigin of the different time scales of variability. \n\n"}
{"id": "0912.2111", "contents": "Title: Tachyons in Throat Cosmology Abstract: Tachyonic 5d scalars are generically present in Randall-Sundrum-like models.\nIn particular, they are known to be part of the 5d effective description of the\nKlebanov-Strassler throat. When moving from the IR to the UV region, the 5d\nbulk profile of Kaluza-Klein excitations of tachyons decays more slowly than\nthat of massless scalars or the graviton. As a result, tachyons in many cases\ndominate the coupling between IR- and UV-localized sectors, leading to a very\nsignificant enhancement of energy-transfer or decay rates from the IR to the\nUV. This can dramatically affect the reheating of the Standard Model after\nbrane inflation and the decay of throat dark matter. \n\n"}
{"id": "0912.2317", "contents": "Title: Fitting and Comparison of Models of Radio Spectra Abstract: I describe an approach to fitting and comparison of radio spectra based on\nBayesian analysis and realised using a new implementation of the nested\nsampling algorithm. Such an approach improves on the commonly used\nmaximum-likelihood fitting of radio spectra by allowing objective model\nselection, calculation of the full probability distributions of the model\nparameters and provides a natural mechanism for including information other\nthan the measured spectra through priors. In this paper I cover the theoretical\nbackground, the algorithms used and the implementation details of the computer\ncode. I also briefly illustrate the method with some previously published data\nfor three near-by galaxies. In forthcoming papers we will present the results\nof applying this analysis larger data sets, including some new observations,\nand the physical conclusions that can be made. The computer code as well as the\noverall approach described here may also be useful for analysis of other\nmulti-chromatic broad-band observations and possibly also photometric redshift\nestimation. All of the code is publicly available, licensed under the GNU\nGeneral Public License, at\nhttp://www.mrao.cam.ac.uk/~bn204/galevol/speca/index.html \n\n"}
{"id": "0912.3421", "contents": "Title: Recent VLBA/VERA/IVS Tests of General Relativity Abstract: We report on recent VLBA/VERA/IVS observational tests of General Relativity.\nFirst, we will summarize the results from the 2005 VLBA experiment that\ndetermined gamma with an accuracy of 0.0003 by measuring the deflection of four\ncompact radio sources by the solar gravitational field. We discuss the limits\nof precision that can be obtained with VLBA experiments in the future. We\ndescribe recent experiments using the three global arrays to measure the\naberration of gravity when Jupiter and Saturn passed within a few arcmin of\nbright radio sources. These reductions are still in progress, but the\nanticipated positional accuracy of the VLBA experiment may be about 0.01 mas. \n\n"}
{"id": "0912.3448", "contents": "Title: Geometry and Morphology of the Cosmic Web: Analyzing Spatial Patterns in\n  the Universe Abstract: We review the analysis of the Cosmic Web by means of an extensive toolset\nbased on the use of Delaunay and Voronoi tessellations. The Cosmic Web is the\nsalient and pervasive foamlike pattern in which matter has organized itself on\nscales of a few up to more than a hundred Megaparsec. First, we describe the\nDelaunay Tessellation Field Estimator (DTFE). The DTFE formalism is shown to\nrecover the hierarchical nature and the anisotropic morphology of the cosmic\nmatter distribution. The Multiscale Morphology Filter (MMF) uses the DTFE\ndensity field to extract the diverse morphological elements - filaments, sheets\nand clusters - on the basis of a ScaleSpace analysis which searches for these\nmorphologies over a range of scales. Subsequently, we discuss the Watershed\nVoidfinder (WVF), which invokes the discrete watershed transform to identify\nvoids in the cosmic matter distribution. The WVF is able to determine the\nlocation, size and shape of the voids. The watershed transform is also a key\nelement in the SpineWeb analysis of the cosmic matter distribution. It allows\nthe determination of the filamentary spine and connected walls in the cosmic\nmatter density field through the identification of the singularities and\ncorresponding separatrices. Finally, we describe the concept of Alphashapes for\nassessing the topology of the cosmic matter distribution. \n\n"}
{"id": "0912.3915", "contents": "Title: Formation and evolution of planetary systems: the impact of high angular\n  resolution optical techniques Abstract: The direct images of giant extrasolar planets recently obtained around\nseveral main sequence stars represent a major step in the study of planetary\nsystems. These high-dynamic range images are among the most striking results\nobtained by the current generation of high angular resolution instruments,\nwhich will be superseded by a new generation of instruments in the coming\nyears. It is therefore an appropriate time to review the contributions of high\nangular resolution visible/infrared techniques to the rapidly growing field of\nextrasolar planetary science. During the last 20 years, the advent of the\nHubble Space Telescope, of adaptive optics on 4- to 10-m class ground-based\ntelescopes, and of long-baseline infrared stellar interferometry has opened a\nnew viewpoint on the formation and evolution of planetary systems. By spatially\nresolving the optically thick circumstellar discs of gas and dust where planets\nare forming, these instruments have considerably improved our models of early\ncircumstellar environments and have thereby provided new constraints on planet\nformation theories. High angular resolution techniques are also directly\ntracing the mechanisms governing the early evolution of planetary embryos and\nthe dispersal of optically thick material around young stars. Finally, mature\nplanetary systems are being studied with an unprecedented accuracy thanks to\nsingle-pupil imaging and interferometry, precisely locating dust populations\nand putting into light a whole new family of long-period giant extrasolar\nplanets. \n\n"}
{"id": "1001.0945", "contents": "Title: Photometric Evolution of SNe Ib/c 2004ao, 2004gk and 2006gi Abstract: Photometric observations of three core collapse supernovae (SNe 2004ao,\n2004gk and 2006gi), covering about 200 days of evolution are presented and\nanalyzed. The photometric behaviour of the three objects is consistent with\ntheir membership of the envelope-stripped type Ib/c class. Pseudo-bolometric\nlight curves are constructed. The corresponding measured $e$-folding times are\nfound to be faster compared to the $^{56}$Co decay (i.e. 111.3 d), suggesting\nthat a proportion of $\\gamma$-rays increasing with time have escaped without\nthermalization, owing to the low mass nature of the ejecta. SN 2006gi has\nalmost identical post maximum decline phase luminosities as SN 1999ex, and\nfound to be similar to both SNe 1999dn and 1999ex in terms of the\nquasi-bolometric shape, placing it among the fast decliner Ib objects. SN\n2004ao appears to fit within the slow decliner Ib SNe. SNe 2004ao and 2004gk\ndisplay almost identical luminosities in the [50-100] days time interval,\nsimilar to SN 1993J. A preliminary simplified $\\gamma -$ray deposition model is\ndescribed and applied to the computed pseudo-bolometric light curves, allowing\none to find a range in the ejecta and $^{56}$Ni masses. The optical and\nquasi-bolometric light curves, and the $B-V$ colour evolution of SN 2004gk are\nfound to show a sudden drop after day 150. Correlating this fact to dust\nformation is premature and requires further observational evidence. \n\n"}
{"id": "1001.1283", "contents": "Title: Simulation of large photomultipliers for experiments in astroparticle\n  physics Abstract: We have developed an accurate simulation model of the large 9 inch\nphotomultiplier tubes (PMT) used in water-Cherenkov detectors of cosmic-ray\ninduced extensive air-showers. This work was carried out as part of the\ndevelopment of the Offline simulation software for the Pierre Auger Observatory\nsurface array, but our findings may be relevant also for other astrophysics\nexperiments that employ similar large PMTs.\n  The implementation is realistic in terms of geometrical dimensions, optical\nprocesses at various surfaces, thin-film treatment of the photocathode, and\nphoton reflections on the inner structure of the PMT. With the quantum\nefficiency obtained for this advanced model we have calibrated a much simpler\nand a more rudimentary model of the PMT which is more practical for massive\nsimulation productions. We show that the quantum efficiency declared by\nmanufactures of the PMTs is usually determined under conditions substantially\ndifferent from those relevant for the particular experiment and thus requires\ncareful (re)interpretation when applied to the experimental data or when used\nin simulations. In principle, the effective quantum efficiency could vary\ndepending on the optical characteristics of individual events. \n\n"}
{"id": "1001.1957", "contents": "Title: Relativistic redshift effects and the Galactic-center stars Abstract: The high pericenter velocities (up to a few percent of light) of the S stars\naround the Galactic-center black hole suggest that general relativistic effects\nmay be detectable through the time variation of the redshift during pericenter\npassage. Previous work has computed post-Newtonian perturbations to the stellar\norbits. We study the additional redshift effects due to perturbations of the\nlight path (what one may call \"post-Minkowskian'' effects), a calculation that\ncan be elegantly formulated as a boundary-value problem. The post-Newtonian and\npost-Minkowskian redshift effects are comparable: both are O(beta^3) and amount\nto a few km/s at pericenter for the star S2. On the other hand, the\npost-Minkowskian redshift contribution of spin is O(beta^5) and much smaller\nthan the O(beta^4) post-Newtonian effect, which would be approximately 0.1km/s\nfor S2. \n\n"}
{"id": "1001.3037", "contents": "Title: CDMS-II to SuperCDMS: WIMP search at a zeptobarn Abstract: The Cryogenic Dark Matter search experiment (CDMS) employs low-temperature Ge\nand Si detectors to detect WIMPs via their elastic scattering of target nuclei.\nThe last analysis with an germanium exposure of 397.8 kg-days resulted in zero\nobserved candidate events, setting an upper limit on the spin-independent\nWIMP-nucleon cross-section of 6.6 x 10^{-44} cm^2 (4.6 x 10^{-44} cm^2, when\nprevious CDMS Soudan data is included) for a WIMP mass of 60 GeV. The\nimprovements in the surface event rejection capability for the current analysis\nwith an germanium exposure about a factor of 2.5 greater than used in the last\nanalysis will be discussed. To increase the sensitivity beyond the 1 x 10^{-44}\ncm^2 benchmark new 1 inch thick detectors have been developed. A first tower\nconsisting of six of these detectors has been successfully installed at the\nSoudan site. These detectors will be used in a 15 kg SuperCDMS stage with an\nexpected sensitivity on the spin-independent WIMP-nucleon elastic scattering\ncross-section of 5 x 10^{-45} cm^2. In addition, the CDMS Collaboration has\nstarted to look for signatures of non WIMP dark matter particles, which may\nexplain the annual modulation signature observed by DAMA. \n\n"}
{"id": "1001.3589", "contents": "Title: Transparent scientific usage as the key to success of the Virtual\n  Observatory Abstract: Nowadays, Virtual Observatory standards, resources, and services became\npowerful enough to help astronomers making real science on everyday basis. The\nkey to the VO success is its entire transparency for a scientific user. This\nallows an astronomer to combine \"online\" VO-enabled parts with \"offline\"\nresearch stages including dedicated data processing and analysis, observations,\nnumerical simulations; and helps to overpass one of the major issues that most\npresent-day VO studies do not go further than data mining. Here we will present\nthree VO-powered research projects combining VO and non-VO blocks, all of them\nresulted in peer-reviewed publications. \n\n"}
{"id": "1001.4456", "contents": "Title: Modeling Collapse and Accretion in Turbulent Gas Clouds: Implementation\n  and Comparison of Sink Particles in AMR and SPH Abstract: We implemented sink particles in the adaptive mesh refinement (AMR)\nhydrodynamics code FLASH. Sink particles are created in regions of local\ngravitational collapse, and their trajectories and accretion can be followed\nover many dynamical times. We perform a series of tests including the time\nintegration of circular and elliptical orbits, the collapse of a Bonnor-Ebert\nsphere and a rotating, fragmenting cloud core. We compare the collapse of a\nhighly unstable singular isothermal sphere to the theory by Shu (1977), and\nshow that the sink particle accretion rate is in excellent agreement with the\ntheoretical prediction.\n  To model eccentric orbits and close encounters of sink particles accurately,\nwe show that a very small timestep is often required, for which we implemented\nsubcycling of the N-body system. We emphasize that a sole density threshold for\nsink particle creation is insufficient in supersonic flows, if the density\nthreshold is below the opacity limit. In that case, the density can exceed the\nthreshold in strong shocks that do not necessarily lead to local collapse.\nAdditional checks for bound state, gravitational potential minimum, Jeans\ninstability and converging flows are absolutely necessary for a meaningful\ncreation of sink particles.\n  We apply our new sink particle module for FLASH to the formation of a stellar\ncluster, and compare to a smoothed particle hydrodynamics (SPH) code with sink\nparticles. Our comparison shows encouraging agreement of gas properties,\nindicated by column density distributions and radial profiles, and of sink\nparticle formation times and positions. We find excellent agreement in the\nnumber of sink particles formed, and in their accretion and mass distributions. \n\n"}
{"id": "1001.4633", "contents": "Title: Planck LFI flight model feed horns Abstract: this paper is part of the Prelaunch status LFI papers published on JINST:\nhttp://www.iop.org/EJ/journal/-page=extra.proc5/jinst The Low Frequency\nInstrument is optically interfaced with the ESA Planck telescope through 11\ncorrugated feed horns each connected to the Radiometer Chain Assembly (RCA).\nThis paper describes the design, the manufacturing and the testing of the\nflight model feed horns. They have been designed to optimize the LFI optical\ninterfaces taking into account the tight mechanical requirements imposed by the\nPlanck focal plane layout. All the eleven units have been successfully tested\nand integrated with the Ortho Mode transducers. \n\n"}
{"id": "1001.5035", "contents": "Title: The VIRUS-P Exploration of Nearby Galaxies (VENGA): Survey Design and\n  First Results Abstract: VENGA is a large-scale extragalactic IFU survey, which maps the bulges, bars\nand large parts of the outer disks of 32 nearby normal spiral galaxies. The\ntargets are chosen to span a wide range in Hubble types, star formation\nactivities, morphologies, and inclinations, at the same time of having vast\navailable multi-wavelength coverage from the far-UV to the mid-IR, and\navailable CO and 21cm mapping. The VENGA dataset will provide 2D maps of the\nSFR, stellar and gas kinematics, chemical abundances, ISM density and\nionization states, dust extinction and stellar populations for these 32\ngalaxies. The uniqueness of the VIRUS-P large field of view permits these\nlarge-scale mappings to be performed. VENGA will allow us to correlate all\nthese important quantities throughout the different environments present in\ngalactic disks, allowing the conduction of a large number of studies in star\nformation, structure assembly, galactic feedback and ISM in galaxies. \n\n"}
{"id": "1001.5385", "contents": "Title: Optical depths for gamma-rays in the radiation field of a star heated by\n  external X-ray source in LMXBs: Application to Her X-1 and Sco X-1 Abstract: The surface of a low mass star inside a compact low mass X-ray binary system\n(LMXB) can be heated by the external X-ray source which may appear due to the\naccretion process onto a companion compact object (a neutron star or a black\nhole). As a result, the surface temperature of the star can become\nsignificantly higher than it is in the normal state resulting from\nthermonuclear burning. We wonder whether high energy electrons and gamma-rays,\ninjected within the binary system, can efficiently interact with this enhanced\nradiation field. To decide this, we calculate the optical depths for the\ngamma-ray photons in the radiation field of such irradiated star as a function\nof the phase of the binary system. Based on these calculations, we conclude\nthat compact low mass X-ray binary systems may also become sources of high\nenergy gamma-rays since conditions for interaction of electrons and gamma-rays\nare quite similar to these ones observed within the high mass TeV gamma-ray\nbinaries such as LS 5039 and LSI 303 +61. However, due to differences in the\nsoft radiation field, the expected gamma-ray light curves can significantly\ndiffer between low mass and high mass X-ray binaries. As an example, we apply\nsuch calculations to two well known LMXBs: Her X-1 and Sco X-1. It is concluded\nthat electrons accelerated to high energies inside these binaries should find\nenough soft photon target from the companion star for efficient gamma-ray\nproduction. \n\n"}
{"id": "1002.0693", "contents": "Title: Controlling intrinsic-shear alignment in three-point weak lensing\n  statistics Abstract: Three-point weak lensing statistics provide cosmic information complementary\nto that of two-point statistics. However, both statistics suffer from\nintrinsic-shear alignment, which is one of their limiting systematics. The\nnulling technique is a model-independent method developed to eliminate\nintrinsic-shear alignment at the two-point level. In this paper we demonstrate\nthat the nulling technique can also be naturally generalized to the three-point\nlevel, controlling the corresponding GGI systematics. We show that under the\nassumption of exact redshift information the intrinsic-shear alignment\ncontamination can be completely eliminated. To show how well the nulling\ntechnique performs on data with limited redshift information, we apply the\nnulling technique to three-point weak lensing statistics from a fictitious\nsurvey analogous to a typical future deep imaging survey, in which the\nthree-point intrinsic-shear alignment systematics is generated from a power-law\ntoy model. Using 10 redshift bins, the nulling technique leads to a factor of\n10 suppression of the GGI/GGG ratio, and reduces the bias on cosmological\nparameters to less than the original statistical error. More detailed redshift\ninformation allowing for finer redshift bins leads to better reduction of bias.\nThe information loss during the nulling procedure doubles the statistical error\non cosmological parameters. A comparison of the nulling technique with an\nunconditioned compression of the data suggests that part of the information\nloss can be retained by considering higher-order nulling weights during the\nnulling procedure. A combined analysis of two- and three-point statistics\nconfirms that the information contained in them is of comparable size and is\ncomplementary to each other, both before and after nulling. \n\n"}
{"id": "1002.1479", "contents": "Title: The effects of charge transfer inefficiency (CTI) on galaxy shape\n  measurements Abstract: (Abridged) We examine the effects of charge transfer inefficiency (CTI)\nduring CCD readout on galaxy shape measurements required by studies of weak\ngravitational lensing. We simulate a CCD readout with CTI such as that caused\nby charged particle radiation damage. We verify our simulations on data from\nlaboratory-irradiated CCDs. Only charge traps with time constants of the same\norder as the time between row transfers during readout affect galaxy shape\nmeasurements. We characterize the effects of CTI on various galaxy populations.\nWe baseline our study around p-channel CCDs that have been shown to have charge\ntransfer efficiency up to an order of magnitude better than several models of\nn-channel CCDs designed for space applications. We predict that for galaxies\nfurthest from the readout registers, bias in the measurement of galaxy shapes,\nDelta(e), will increase at a rate of 2.65 +/- 0.02 x 10^(-4) per year at L2 for\naccumulated radiation exposure averaged over the solar cycle. If uncorrected,\nthis will consume the entire shape measurement error budget of a dark energy\nmission within about 4 years. Software mitigation techniques demonstrated\nelsewhere can reduce this by a factor of ~10, bringing the effect well below\nmission requirements. CCDs with higher CTI than the ones we studeied may not\nmeet the requirements of future dark energy missions. We discuss ways in which\nhardware could be designed to further minimize the impact of CTI. \n\n"}
{"id": "1002.1585", "contents": "Title: PROFIT: a new alternative for emission-line PROfile FITting Abstract: I briefly describe a simple routine for emission-line profiles fitting by\nGaussian curves or Gauss-Hermite series. The PROFIT (line-PROfile FITting)\nroutine represent a new alternative for use in fits data cubes, as those from\nIntegral Field Spectroscopy or Fabry-Perot Interferometry, and may be useful to\nbetter study the emission-line flux distributions and gas kinematics in\ndistinct astrophysical objects, such as the central regions of galaxies and\nstar forming regions. The PROFIT routine is written in IDL language and is\navailable at http://www.ufsm.br/rogemar/software.html.\n  The PROFIT routine was used to fit the [Fe II]1.257um emission-line profiles\nfor about 1800 spectra of the inner 350 pc of the Seyfert galaxy Mrk1066\nobtained with Gemini NIFS and shows that the line profiles are better\nreproduced by Gauss-Hermite series than by the commonly used Gaussian curves.\nThe two-dimensional map of the h_3 Gauss-Hermite moment shows its highest\nabsolute values in regions close to the edge of the radio structure. These high\nvalues may be originated in an biconical outflowing gas associated with the\nradio jet - previously observed in the optical [O III] emission. The analysis\nof this kinematic component indicates that the radio jet leaves the center of\nthe galaxy with the north-west side slightly oriented towards us and the\nsouth-east side away from us, being partially hidden by the disc of the galaxy. \n\n"}
{"id": "1002.2442", "contents": "Title: Calibration and Characterization of the IceCube Photomultiplier Tube Abstract: Over 5,000 PMTs are being deployed at the South Pole to compose the IceCube\nneutrino observatory. Many are placed deep in the ice to detect Cherenkov light\nemitted by the products of high-energy neutrino interactions, and others are\nfrozen into tanks on the surface to detect particles from atmospheric cosmic\nray showers. IceCube is using the 10-inch diameter R7081-02 made by Hamamatsu\nPhotonics. This paper describes the laboratory characterization and calibration\nof these PMTs before deployment. PMTs were illuminated with pulses ranging from\nsingle photons to saturation level. Parameterizations are given for the single\nphotoelectron charge spectrum and the saturation behavior. Time resolution,\nlate pulses and afterpulses are characterized. Because the PMTs are relatively\nlarge, the cathode sensitivity uniformity was measured. The absolute photon\ndetection efficiency was calibrated using Rayleigh-scattered photons from a\nnitrogen laser. Measured characteristics are discussed in the context of their\nrelevance to IceCube event reconstruction and simulation efforts. \n\n"}
{"id": "1002.3615", "contents": "Title: Cosmic Shears Should Not Be Measured In Conventional Ways Abstract: A long standing problem in weak lensing is about how to construct cosmic\nshear estimators from galaxy images. Conventional methods average over a single\nquantity per galaxy to estimate each shear component. We show that any such\nshear estimators must reduce to a highly nonlinear form when the galaxy image\nis described by three parameters (pure ellipse), even in the absence of the\npoint spread function (PSF). In the presence of the PSF, we argue that this\nclass of shear estimators do not likely exist. Alternatively, we propose a new\nway of measuring the cosmic shear: instead of averaging over a single value\nfrom each galaxy, we average over two numbers, and then take the ratio to\nestimate the shear component. In particular, the two numbers correspond to the\nnumerator and denominators which generate the quadrupole moments of the galaxy\nimage in Fourier space, as proposed in Zhang (2008). This yields a\nstatistically unbiased estimate of the shear component. Consequently,\nmeasurements of the n-point spatial correlations of the shear fields should\nalso be modified: one needs to take the ratio of two correlation functions to\nget the desired, unbiased shear correlation. \n\n"}
{"id": "1003.0113", "contents": "Title: The cross-spectrum experimental method Abstract: The noise of a device under test (DUT) is measured simultaneously with two\ninstruments, each of which contributes its own background. The average cross\npower spectral density converges to the DUT power spectral density. This method\nenables the extraction of the DUT noise spectrum, even if it is significantly\nlower than the background. After a snapshot on practical experiments, we go\nthrough the statistical theory and the choice of the estimator. A few\nexperimental techniques are described, with reference to phase noise and\namplitude noise in RF/microwave systems and in photonic systems. The set of\napplications of this method is wide. The final section gives a short panorama\non radioastronomy, radiometry, quantum optics, thermometry (fundamental and\napplied), semiconductor technology, metallurgy, etc. This report is intended as\na tutorial, as opposed to a report on advanced research, yet addressed to a\nbroad readership: technicians, practitioners, Ph.D. students, academics, and\nfull-time scientists. \n\n"}
{"id": "1003.3011", "contents": "Title: Delayed Reheating and the Breakdown of Coherent Oscillations Abstract: We analyze the evolution of the perturbations in the inflaton field and\nmetric following the end of inflation. We present accurate analytic\napproximations for the perturbations, showing that the coherent oscillations of\nthe post-inflationary condensate necessarily break down long before any current\nphenomenological constraints require the universe to become radiation\ndominated. Further, the breakdown occurs on length-scales equivalent to the\ncomoving post-inflationary horizon size. This work has implications for both\nthe inflationary \"matching\" problem, and the possible generation of a\nstochastic gravitational wave background in the post-inflationary universe. \n\n"}
{"id": "1003.3243", "contents": "Title: The GalMer database: Galaxy Mergers in the Virtual Observatory Abstract: We present the GalMer database, a library of galaxy merger simulations, made\navailable to users through tools compatible with the Virtual Observatory (VO)\nstandards adapted specially for this theoretical database. To investigate the\nphysics of galaxy formation through hierarchical merging, it is necessary to\nsimulate galaxy interactions varying a large number of parameters:\nmorphological types, mass ratios, orbital configurations, etc. On one side,\nthese simulations have to be run in a cosmological context, able to provide a\nlarge number of galaxy pairs, with boundary conditions given by the large-scale\nsimulations, on the other side the resolution has to be high enough at galaxy\nscales, to provide realistic physics. The GalMer database is a library of\nthousands simulations of galaxy mergers at moderate spatial resolution and it\nis a compromise between the diversity of initial conditions and the details of\nunderlying physics. We provide all coordinates and data of simulated particles\nin FITS binary tables. The main advantages of the database are VO access\ninterfaces and value-added services which allow users to compare the results of\nthe simulations directly to observations: stellar population modelling, dust\nextinction, spectra, images, visualisation using dedicated VO tools. The GalMer\nvalue-added services can be used as virtual telescope producing broadband\nimages, 1D spectra, 3D spectral datacubes, thus making our database oriented\ntowards the usage by observers. We present several examples of the GalMer\ndatabase scientific usage obtained from the analysis of simulations and\nmodelling their stellar population properties, including: (1) studies of the\nstar formation efficiency in interactions; (2) creation of old counter-rotating\ncomponents; (3) reshaping metallicity profiles in elliptical galaxies; (4)\norbital to internal angular momentum transfer; (5) reproducing observed colour\nbimodality of galaxies. \n\n"}
{"id": "1003.4860", "contents": "Title: Stellar Tidal Streams in Spiral Galaxies of the Local Volume: A Pilot\n  Survey with Modest Aperture Telescopes Abstract: [Abridged] Within the hierarchical framework for galaxy formation, minor\nmerging and tidal interactions are expected to shape all large galaxies to the\npresent day. As a consequence, most seemingly normal disk galaxies should be\nsurrounded by spatially extended stellar 'tidal features' of low surface\nbrightness. As part of a pilot survey for such interaction signatures, we have\ncarried out ultra deep, wide field imaging of 8 isolated spiral galaxies in the\nLocal Volume, with data taken at small (D=0.1-0.5m) robotic telescopes that\nprovide exquisite surface brightness sensitivity (mu_V)~28.5$ mag/arcsec^2).\nThis initial observational effort has led to the discovery of six previously\nundetected extensive (to ~30 kpc) stellar structures in the halos surrounding\nthese galaxies, likely debris from tidally disrupted satellites. In addition,\nwe confirm and clarify several enormous stellar over-densities previously\nreported in the literature, but never before interpreted as tidal streams. Even\nthis pilot sample of galaxies exhibits strikingly diverse morphological\ncharacteristics of these extended stellar features: great circle-like features\nthat resemble the Sagittarius stream surrounding the Milky Way, remote shells\nand giant clouds of presumed tidal debris far beyond the main stelar body, as\nwell as jet-like features emerging from galactic disks. A qualitative\ncomparison with available simulations set in a Lambda-Cold Dark Matter\ncosmology shows that the extraordinary variety of stellar morphologies detected\nin this pilot survey matches that seen in those simulations. The common\nexistence of these tidal features around 'normal' disk galaxies and the\nmorphological match to the simulations constitutes new evidence that these\ntheoretical models also apply to a large number of other Milky Way-mass disk\ngalaxies in the Local Volume. \n\n"}
{"id": "1003.5516", "contents": "Title: No evidence for black hole spin powering of jets in X-ray binaries Abstract: In this paper we take the reported measurements of black hole spin for black\nhole X-ray binaries, and compare them against measurements of jet power and\nspeed across all accretion states in these systems. We find no evidence for any\ncorrelation between the properties of the jets and the reported spin\nmeasurements. These constraints are strongest in the hard X-ray state, which is\nassociated with a continuous powerful jet. We are led to conclude that one or\nmore of the following is correct: (i) the calculated jet power and speed\nmeasurements are wrong, (ii) the reported spin measurements are wrong, (iii)\nthere is no strong dependence of the jet properties on black hole spin. In\naddition to this lack of observational evidence for a relation between black\nhole spin and jet properties in stellar mass black holes, we highlight the fact\nthat there appear to be at least three different ways in which the jet power\nand/or radiative efficiency from a black hole X-ray binary may vary, two of\nwhich are certainly independent of spin because they occur in the same source\non relatively short timescales, and the third which does not correlate with any\nreported measurements of black hole spin. We briefly discuss how these findings\nmay impact upon interpretations of populations of active galactic nuclei in the\ncontext of black hole spin and merger history. \n\n"}
{"id": "1004.0005", "contents": "Title: The formation of disc galaxies in a LCDM universe Abstract: We study the formation of disc galaxies in a fully cosmological framework\nusing adaptive mesh refinement simulations. We perform an extensive parameter\nstudy of the main subgrid processes that control how gas is converted into\nstars and the coupled effect of supernovae feedback. We argue that previous\nattempts to form disc galaxies have been unsuccessful because of the universal\nadoption of strong feedback combined with high star formation efficiencies.\nUnless extreme amounts of energy are injected into the interstellar medium\nduring supernovae events, these star formation parameters result in bulge\ndominated S0/Sa galaxies as star formation is too efficient at z~3. We show\nthat a low efficiency of star-formation more closely models the subparsec\nphysical processes, especially at high redshift. We highlight the successful\nformation of extended disc galaxies with scale lengths r_d=4-5 kpc, flat\nrotation curves and bulge to disc ratios of B/D~1/4. Not only do we resolve the\nformation of a Milky Way-like spiral galaxy, we also observe the secular\nevolution of the disc as it forms a pseudo-bulge. The disc properties agree\nwell with observations and are compatible with the photometric and baryonic\nTully-Fisher relations, the Kennicutt-Schmidt relation and the observed angular\nmomentum content of spiral galaxies. We conclude that underlying small-scale\nstar formation physics plays a larger role than previously considered in\nsimulations of galaxy formation. \n\n"}
{"id": "1004.0492", "contents": "Title: Revisiting the Cosmological Constraints on the Interacting Dark Energy\n  Models Abstract: In this work, we consider the cosmological constraints on the interacting\ndark energy models. We generalize the models considered previously by Guo {\\it\net al.}, Costa and Alcaniz, and try to discuss two general types of models:\ntype I models are characterized by $\\rho_{_X}/\\rho_m=f(a)$ and $f(a)$ can be\nany function of scale factor $a$, whereas type II models are characterized by\n$\\rho_m=\\rho_{m0}\\,a^{-3+\\epsilon(a)}$ and $\\epsilon(a)$ can be any function of\n$a$. We obtain the cosmological constraints on the type I and II models with\npower-law, CPL-like, logarithmic $f(a)$ and $\\epsilon(a)$ by using the latest\nobservational data. \n\n"}
{"id": "1004.0645", "contents": "Title: Constraining Sommerfeld Enhanced Annihilation Cross-sections of Dark\n  Matter via Direct Searches Abstract: In a large class of models we show that the light scalar field responsible\nfor the Sommerfeld enhancement in the annihilation of dark matter leads to\nobservable direct detection rates, due to its mixing with the standard model\nHiggs. As a result the large annihilation cross-section of dark matter at\npresent epoch, required to explain the observed cosmic ray anomalies, can be\nstrongly constrained by direct searches. In particular Sommerfeld boost factors\nof order of a few hundred are already out of the CDMS-II upper bound at 90%\nconfidence level for reasonable values of the model parameters. \n\n"}
{"id": "1004.0711", "contents": "Title: The Parameter Space of Galaxy Formation Abstract: Semi-analytic models are a powerful tool for studying the formation of\ngalaxies. However, these models inevitably involve a significant number of\npoorly constrained parameters that must be adjusted to provide an acceptable\nmatch to the observed universe. In this paper, we set out to quantify the\ndegree to which observational data-sets can constrain the model parameters. By\nrevealing degeneracies in the parameter space we can hope to better understand\nthe key physical processes probed by the data. We use novel mathematical\ntechniques to explore the parameter space of the GALFORM semi-analytic model.\nWe base our investigation on the Bower et al. 2006 version of GALFORM, adopting\nthe same methodology of selecting model parameters based on an acceptable match\nto the local bJ and K luminosity functions. The model contains 16 parameters\nthat are poorly constrained, and we investigate this parameter space using the\nModel Emulator technique, constructing a Bayesian approximation to the GALFORM\nmodel that can be rapidly evaluated at any point in parameter space. By\ncombining successive waves of emulation, we show that only 0.26% of the initial\nvolume is of interest for further exploration. However, within this region we\nshow that the Bower et al. 2006 model is only one choice from an extended\nsub-space of model parameters that can provide equally acceptable fits. We\nexplore the geometry of this region and begin to explore the physical\nconnections between parameters that are exposed by this analysis. We also\nconsider the impact of adding additional observational data to further\nconstrain the parameter space. \n\n"}
{"id": "1004.1099", "contents": "Title: Evidence of different star formation histories for high- and\n  low-luminosity radio galaxies Abstract: We present the results of our investigation into the stellar populations of\n24 radio galaxies at z~0.5 drawn from four complete, low-frequency selected\nradio surveys. We use the strength of the 4000A break as an indicator of recent\nstar formation, and compare this with radio luminosity, optical spectral\nclassification and morphological classification. We find evidence of different\nstar formation histories for high- and low-luminosity radio sources; our group\nof low radio luminosity sources (typically FRI-type sources) has systematically\nolder stellar populations than the higher radio luminosity group. Our sample is\nalso fairly well divided by optical spectral classification. We find that\ngalaxies classified as having low excitation spectra (LEGs) possess older\nstellar populations than high excitation line objects (HEGs), with the HEGs\nshowing evidence for recent star formation. We also investigate the link\nbetween radio morphology, as used by Owen & Laing (1989), and the stellar\npopulations. We find that there is a preference for the \"fat-double\" sources to\nhave older stellar populations than the \"classical double\" sources, although\nthis is also linked to these sources lying predominantly in the LEG and HEG\ncategories respectively. These results are consistent with the hypothesis that\nHEGs are powered by accretion of cold gas, which could be supplied, for\nexample, by recent mergers, secular instabilities, or filamentary cold flows.\nThese processes could also trigger star formation in the host galaxy. The host\ngalaxies of the LEGs do not show evidence for recent star formation and an\ninflux of cold gas, and are consistent with being powered by the accretion of\nthe hot phase of the inter-stellar medium. \n\n"}
{"id": "1004.3347", "contents": "Title: GALEX far-UV color selection of UV-bright high-redshift quasars Abstract: We study the small population of z>2.7 quasars detected by GALEX, whose\nfar-UV emission is not extinguished by intervening HI Lyman limit systems.\nThese quasars are of particular importance to detect intergalactic HeII\nabsorption along their sightlines. We correlate verified z>2.7 quasars to the\nGALEX GR4 source catalog, yielding 304 S/N>3 sources. However, ~50% of these\nare only detected in the GALEX NUV band, signaling the truncation of the FUV\nflux by low-redshift Lyman limit systems. We exploit the GALEX UV color to cull\nthe most promising targets for follow-up studies, with blue (red) GALEX colors\nindicating transparent (opaque) sightlines. Monte Carlo simulations indicate a\nHeII detection rate of ~60% for quasars with FUV-NUV<1 at z<3.5, a ~50%\nincrease over GALEX searches that do not include color information. We regard\n52 quasars detected at S/N>3 to be most promising for HST follow-up, with an\nadditional 114 quasars if we consider S/N>2 detections in the FUV. SDSS\nprovides just half of the NUV-bright quasars that should have been detected by\nSDSS & GALEX. We revise the SDSS quasar selection function, finding that SDSS\nsystematically misses quasars with blue u-g<2 colors at 3<z<3.5 due to overlap\nwith the stellar locus in color space. Our color-dependent SDSS selection\nfunction naturally explains the inhomogeneous u-g color distribution of SDSS\nquasars with redshift and the color difference between color-selected and\nradio-selected SDSS quasars. Moreover, it yields excellent agreement between\nthe observed and the predicted number of UV-bright SDSS quasars. We confirm our\nprevious claims that SDSS preferentially selects 3<z<3.5 quasars with\nintervening HI Lyman limit systems. Our results imply that broadband optical\ncolor surveys for 3<z<3.5 quasars have likely underestimated their space\ndensity by selecting IGM sightlines with an excess of strong HI absorbers. \n\n"}
{"id": "1004.3512", "contents": "Title: Bouncing Universe and phantom crossing in Modified Gravity and its\n  reconstruction Abstract: In this paper we consider FRW cosmology in modified gravity which contain\narbitrary functions $f(\\phi)$. It is shown that the bouncing solution appears\nin the model whereas the equation of state (EoS) parameter crosses the phantom\ndivider. The reconstruction of the model is also investigated with the aim to\nreconstruct the arbitrary functions and variables of the model. \n\n"}
{"id": "1005.1886", "contents": "Title: Towards a Resource-Centric Data Network for Astronomy Abstract: Over the past decade, astronomers have been using an increasingly larger\nnumber of web-based applications and archives to conduct their research.\nHowever, despite the early success in creating links across projects and data\ncenters, the promise of a single integrated digital library environment\nsupporting e-science in astronomy has proven elusive. While some of the issues\nhampering progress in this area are of technical nature, others are rooted in\nexisting policies which should be re-analyzed if further rapid progress is to\nbe made in this area. This paper describes a proposal that the NASA\nAstrophysics Data System project has put forth in order to improve its role as\none of the primary discovery portals for astronomers, focusing on those aspects\nwhich could benefit from an increased level of involvement from the community,\nnamely the effort to expose astronomy resources as linked data, and the\nharvesting of observational metadata. \n\n"}
{"id": "1005.2187", "contents": "Title: The HerMES SPIRE submillimeter local luminosity function Abstract: Local luminosity functions are fundamental benchmarks for high-redshift\ngalaxy formation and evolution studies as well as for models describing these\nprocesses. Determining the local luminosity function in the submillimeter range\ncan help to better constrain in particular the bolometric luminosity density in\nthe local Universe, and Herschel offers the first opportunity to do so in an\nunbiased way by imaging large sky areas at several submillimeter wavelengths.\n  We present the first Herschel measurement of the submillimeter 0<z<0.2 local\nluminosity function and infrared bolometric (8-1000 $\\mu$m) local luminosity\ndensity based on SPIRE data from the HerMES Herschel Key Program over 14.7\ndeg^2.\n  Flux measurements in the three SPIRE channels at 250, 350 and 500 \\mum are\ncombined with Spitzer photometry and archival data. We fit the observed\noptical-to-submillimeter spectral energy distribution of SPIRE sources and use\nthe 1/V_{max} estimator to provide the first constraints on the monochromatic\n250, 350 and 500 \\mum as well as on the infrared bolometric (8-1000 \\mum) local\nluminosity function based on Herschel data.\n  We compare our results with modeling predictions and find a slightly more\nabundant local submillimeter population than predicted by a number of models.\nOur measurement of the infrared bolometric (8-1000 \\mum) local luminosity\nfunction suggests a flat slope at low luminosity, and the inferred local\nluminosity density, 1.31_-0.21^+0.24 x 10^8 Lsun Mpc^-3, is consistent with the\nrange of values reported in recent literature. \n\n"}
{"id": "1006.1473", "contents": "Title: XMASS Abstract: The XMASS detector is a large single phase liquid Xenon scintillator.After\nits feasibility had been studied using a 100 kg size prototype detector, an 800\nkg size detector is being built for dark matter search with the sensitivity of\n$10^{-45} {\\rm cm}^2$ region in spin-independent cross section. The results of\nR\\&D study for 800 kg detector, especially ultra low background technologies,\nand the prospects of the experiment are described. \n\n"}
{"id": "1006.2149", "contents": "Title: Lemaitre-Tolman-Bondi dust spacetimes: Symmetry properties and some\n  extensions to the dissipative case Abstract: We consider extensions of Lemaitre-Tolman-Bondi (LTB) spacetimes to the\ndissipative case. For doing that we previously carry out a systematic study on\nLTB. This study is based on two different aspects of LTB. On the one hand, a\nsymmetry property of LTB will be presented. On the other hand, the description\nof LTB in terms of some fundamental scalar functions (structure scalars)\nappearing in the orthogonal splitting of Riemann tensor will be provided. We\nshall consider as \"natural\" generalizations of LTB (hereafter referred to as\nGLTB) either those metrics admitting some similar kind of symmetry as LTB, or\nthose sharing structure scalars with similar dependence on the metric. \n\n"}
{"id": "1006.3691", "contents": "Title: CO J=1-0 spectroscopy of four submillimeter galaxies with the\n  Zpectrometer on the Green Bank Telescope Abstract: We report detections of three z ~ 2.5 submillimeter-selected galaxies (SMGs;\nSMM J14011+0252, SMM J14009+0252, SMM J04431+0210) in the lowest rotational\ntransition of the carbon monoxide molecule (CO J = 1-0) and one nondetection\n(SMM J04433+0210). For the three galaxies we detected, we find a\nline-integrated brightness temperature ratio of the J = 3-2 and 1-0 lines of\n0.68 +/- 0.08; the 1-0 line is stronger than predicted by the frequent\nassumption of equal brightnesses in the two lines and by most single-component\nmodels. The observed ratio suggests that mass estimates for SMGs based on J =\n3-2 observations and J = 1-0 column density or mass conversion factors are low\nby a factor of 1.5. Comparison of the 1-0 line intensities with intensities of\nhigher-J transitions indicates that single-component models for the\ninterstellar media in SMGs are incomplete. The small dispersion in the ratio,\nalong with published detections of CO lines with J_upper > 3 in most of the\nsources, indicates that the emission is from multi-component interstellar media\nwith physical structures common to many classes of galaxies. This result tends\nto rule out the lowest scaling factors between CO luminosity and molecular gas\nmass, and further increases molecular mass estimates calibrated against\nobservations of galaxies in the local universe. We also describe and\ndemonstrate a statistically sound method for finding weak lines in broadband\nspectra that will find application in searches for molecular lines from sources\nat unknown redshifts. \n\n"}
{"id": "1006.4615", "contents": "Title: On Features and Nongaussianity from Inflationary Particle Production Abstract: Interactions between the inflaton and any additional fields can lead to\nisolated bursts of particle production during inflation (for example from\nparametric resonance or a phase transition). Inflationary particle production\nleaves localized features in the spectrum and bispectrum of the observable\ncosmological fluctuations, via the Infra-Red (IR) cascading mechanism. We focus\non a simple prototype interaction g^2 (\\phi-\\phi_0)^2\\chi^2 between the\ninflaton, \\phi, and iso-inflaton, \\chi; extending previous work on this model\nin two directions. First, we quantify the magnitude of the produced\nnongaussianity by extracting the moments of the probability distribution\nfunction from lattice field theory simulations. We argue that the bispectrum\nfeature from particle production might be observable for reasonable values of\nthe coupling, g^2. Second, we develop a detailed analytical theory of particle\nproduction and IR cascading during inflation, which is in excellent agreement\nwith numerical simulations. Our formalism improves significantly on previous\napproaches by consistently incorporating both the expansion of the universe and\nalso metric perturbations. We use this new formalism to estimate the shape of\nthe bispectrum from particle production, showing this to be distinguishable\nfrom other mechanisms that predict large nongaussianity. \n\n"}
{"id": "1006.5307", "contents": "Title: A systematic cross-search for radio/infrared counterparts of XMM-Newton\n  sources Abstract: We present a catalog of cross-correlated radio, infrared and X-ray sources\nusing a very restrictive selection criteria with an IDL-based code developed by\nus. The significance of the observed coincidences was evaluated through Monte\nCarlo simulations of synthetic sources following a well-tested protocol. We\nfound 3320 coincident radio/X-ray sources with a high statistical significance\ncharacterized by the sum of error-weighted coordinate differences. For 997 of\nthem, 2MASS counterparts were found. The percentage of chance coincidences is\nless than 1%. X-ray hardness ratios of well-known populations of objects were\nused to provide a crude representation of their X-ray spectrum and to make a\npreliminary diagnosis of the possible nature of unidentified X-ray sources. The\nresults support the fact that the X-ray sky is largely dominated by Active\nGalactic Nuclei at high galactic latitudes (|b| >= 10^\\circ). At low galactic\nlatitudes (|b| <= 10^\\circ) most of unidentified X-ray sources (~94%) lie at\n|b| <= 2^\\circ. This result suggests that most of the unidentified sources\nfound toward the Milky Way plane are galactic objects. Well-known and\nunidentified sources were classified in different tables with their\ncorresponding radio/infrared and X-ray properties. These tables are intended as\na useful tool for researchers interested in particular identifications. \n\n"}
{"id": "1006.5444", "contents": "Title: Positron production scenarios and the angular profile of the galactic\n  center 511-keV line Abstract: The observed angular profile of the 511-keV photon excess from the Milky Way\ngalactic center can allow us to select among combinations of various dark\nmatter and other positron production mechanisms with various models for the\ndark matter distribution. We find that a relic decay scenario gives too flat an\nangular distribution for any dark matter distribution in our survey, but that a\ndark matter-dark matter collisional scenario, or a scenario that involves\nparticles emitted from a localized central source producing positrons some\ndistance out, can match the observed galactic center angular profile if the\ndark matter distribution is neither too flat nor too cuspy. Additionally,\npositron migration or diffusion before annihilation broadens the angular\nprofile to an extent that an average migration of more than half a kiloparsec\nis not viable with most dark matter distributions. The observed angular profile\nis also consistent with the occurrence of transient events in the past,\nfollowed by isotropic positron diffusion. \n\n"}
{"id": "1006.5777", "contents": "Title: Landau Damping of Baryon Structure Formation in the Post Reionization\n  Epoch Abstract: It has been suggested by Chen and Lai that the proper description of the\nlarge scale structure formation of the universe in the post-reionization era,\nwhich is conventionally characterized via gas hydrodynamics, should include the\nplasma collective effects in the formulation. Specifically, it is the combined\npressure from the baryon thermal motions and the residual long-range\nelectrostatic potentials resulted from the imperfect Debye shielding, that\nfights against the gravitational collapse. As a result, at small-scales the\nbaryons would oscillate at the ion-acoustic, instead of the conventional\nneutral acoustic, frequency. In this paper we extend and improve the Chen-Lai\nformulation with the attention to the Landau damping of the ion-acoustic\noscillations. Since T_e \\sim T_i in the post-reionization era, the ion acoustic\noscillations would inevitably suffer the Landau damping which severely\nsuppresses the baryon density spectrum in the regimes of intermediate and high\nwavenumber k. To describe this Landau-damping phenomenon more appropriately, we\nfind it necessary to modify the filtering wavenumber k_f in our analysis. It\nwould be interesting if our predicted Landau damping of the ion-acoustic\noscillations can be observed at high redshifts. \n\n"}
{"id": "1007.1149", "contents": "Title: MILCA, a Modified Internal Linear Combination Algorithm to extract\n  astrophysical emissions from multi-frequency sky maps Abstract: The analysis of current Cosmic Microwave Background (CMB) experiments is\nbased on the interpretation of multi-frequency sky maps in terms of different\nastrophysical components and it requires specifically tailored component\nseparation algorithms. In this context, Internal Linear Combination (ILC)\nmethods have been extensively used to extract the CMB emission from the WMAP\nmulti-frequency data. We present here a Modified Internal Linear Component\nAlgorithm (MILCA) that generalizes the ILC approach to the case of multiple\nastrophysical components for which the electromagnetic spectrum is known. In\naddition MILCA corrects for the intrinsic noise bias in the standard ILC\napproach and extends it to an hybrid space-frequency representation of the\ndata. It also allows us to use external templates to minimize the contribution\nof extra components but still using only a linear combination of the input\ndata. We apply MILCA to simulations of the Planck satellite data at the HFI\nfrequency bands. We explore the possibility of reconstructing the Galactic\nmolecular CO emission on the Planck maps as well as the thermal\nSunyaev-Zeldovich effect. We conclude that MILCA is able to accurately estimate\nthose emissions and it has been successfully used for this purpose within the\nPlanck collaboration. \n\n"}
{"id": "1007.1681", "contents": "Title: Galaxy Modeling with Compound Elliptical Shapelets Abstract: Gauss-Hermite and Gauss-Laguerre (\"shapelet\") decompositions of images have\nbecome important tools in galaxy modeling, particularly for the purpose of\nextracting ellipticity and morphological information from astronomical data.\nHowever, the standard shapelet basis functions cannot compactly represent\ngalaxies with high ellipticity or large Sersic index, and the resulting\nunderfitting bias has been shown to present a serious challenge for\nweak-lensing methods based on shapelets. We present here a new convolution\nrelation and a compound \"multi-scale\" shapelet basis to address these problems,\nand provide a proof-of-concept demonstration using a small sample of nearby\ngalaxies. \n\n"}
{"id": "1007.1754", "contents": "Title: Binary neutron-star mergers with Whisky and SACRA: First quantitative\n  comparison of results from independent general-relativistic hydrodynamics\n  codes Abstract: We present the first quantitative comparison of two independent\ngeneral-relativistic hydrodynamics codes, the Whisky code and the SACRA code.\nWe compare the output of simulations starting from the same initial data and\ncarried out with the configuration (numerical methods, grid setup, resolution,\ngauges) which for each code has been found to give consistent and sufficiently\naccurate results, in particular in terms of cleanness of gravitational\nwaveforms. We focus on the quantities that should be conserved during the\nevolution (rest mass, total mass energy, and total angular momentum) and on the\ngravitational-wave amplitude and frequency. We find that the results produced\nby the two codes agree at a reasonable level, with variations in the different\nquantities but always at better than about 10%. \n\n"}
{"id": "1007.1777", "contents": "Title: Zenith distribution and flux of atmospheric muons measured with the\n  5-line ANTARES detector Abstract: The ANTARES high energy neutrino telescope is a three-dimensional array of\nabout 900 photomultipliers distributed over 12 mooring lines installed in the\nMediterranean Sea. Between February and November 2007 it acquired data in a\n5-line configuration. The zenith angular distribution of the atmospheric muon\nflux and the associated depth-intensity relation are measured and compared with\nprevious measurements and Monte Carlo expectations. An evaluation of the\nsystematic effects due to uncertainties on environmental and detector\nparameters is presented. \n\n"}
{"id": "1007.3746", "contents": "Title: Towards an improved understanding of the relative scintillation\n  efficiency of nuclear recoils in liquid xenon Abstract: Liquid xenon (LXe) particle detectors are a powerful technology in the field\nof dark matter direct detection, having shown impressive results in recent\nyears and holding strong possibility for leading the field in sensitivity to\ngalactic weakly interacting massive particles (WIMPs) in the future. The search\nfor WIMPs requires the capability to detect the recoiling nuclei that result\nwhen these particles interact with normal matter. In order to make meaningful\nstatements about an observed signal, or lack thereof, the energy scale of\nrecoiling nuclei in LXe must be known. Our understanding of this energy scale\nis contained in a quantity called the relative scintillation efficiency of\nnuclear recoils, or L_eff, and has been studied extensively in the literature,\nproducing seemingly contradictory results. I examine all the measurements of\nL_eff that exist, both direct and indirect, and extract the energy dependent\nbehavior that is statistically consistent globally with all values.\nAdditionally, I examine the measurements covering low energies (>~10 keV, where\nthe largest disagreements exist) and attempt to diagnose the systematic effects\nthat have led to the observed inconsistencies. I show that virtually all major\ndisparity arises due to efficiency roll-off of the detectors at the low\nenergies, and, when taking this into account, find that the observed behavior\nof L_eff supports a slowly and smoothly decreasing value with decreasing\nenergy. Finally, I discuss the prospects for future measurements, and derive a\npractical limit to what can be achieved. \n\n"}
{"id": "1007.4549", "contents": "Title: A molecular survey of outflow gas: velocity-dependent shock chemistry\n  and the peculiar composition of the EHV gas Abstract: (Abridged) We present a molecular survey of the outflows powered by L1448-mm\nand IRAS 04166+2706, two sources with prominent wing and extremely high\nvelocity (EHV) components in their CO spectra. The molecular composition of the\ntwo outflows presents systematic changes with velocity that we analyze by\ndividing the outflow in three chemical regimes, two of them associated with the\nwing component and the other the EHV gas. The analysis of the two wing regimes\nshows that species like H2CO and CH3OH favor the low-velocity gas, while SiO\nand HCN are more abundant in the fastest gas. We also find that the EHV regime\nis relatively rich in O-bearing species, as is not only detected in CO and SiO\n(already reported elsewhere), but also in SO, CH3OH, and H2CO (newly reported\nhere), with a tentative detection in HCO+. At the same time, the EHV regime is\nrelatively poor in C-bearing molecules like CS and HCN. We suggest that this\ndifference in composition arises from a lower C/O ratio in the EHV gas. The\ndifferent chemical compositions of the wing and EHV regimes suggest that these\ntwo outflow components have different physical origins. The wing component is\nbetter explained by shocked ambient gas, although none of the existing shock\nmodels explains all observed features. The peculiar composition of the EHV gas\nmay reflect its origin as a dense wind from the protostar or its surrounding\ndisk. \n\n"}
{"id": "1007.5100", "contents": "Title: The Golden Point of No-Scale and No-Parameter ${\\cal F}$-SU(5) Abstract: The ${\\cal F}$-lipped $SU(5)\\times U(1)_X$ Grand Unified Theory (GUT)\nsupplemented by TeV-scale vector-like particles from ${\\cal F}$-theory,\ntogether dubbed ${\\cal F}$-SU(5), offers a natural multi-phase unification\nprocess which suggests an elegant implementation of the No-Scale Supergravity\nboundary conditions at the unification scale $M_{\\cal F} \\simeq 7 \\times\n10^{17}$ GeV. Enforcing the No-Scale boundary conditions, including\n$B_\\mu(M_{\\cal F})=0$ on the Higgs bilinear soft term, with the precision\n7-year WMAP value on the dark matter relic density isolates a highly\nconstrained \"golden point\" located near $M_{1/2} = 455$ GeV and $\\tan \\beta =\n15$ in the $\\tan\\beta-M_{1/2}$ plane, which simultaneously satisfies all known\nexperiments, and moreover corresponds to an imminently observable proton decay\nrate. Because the universal gaugino mass is actually determined from\nestablished low energy data via Renormalization Group Equation (RGE) running,\nthere are no surviving arbitrary scale parameters in the present model. \n\n"}
{"id": "1008.1071", "contents": "Title: Multi-frequency, thermally coupled radiative transfer with TRAPHIC:\n  Method and tests Abstract: We present an extension of TRAPHIC, the method for radiative transfer of\nionising radiation in smoothed particle hydrodynamics simulations that we\nintroduced in Pawlik & Schaye (2008). The new version keeps all advantages of\nthe original implementation: photons are transported at the speed of light, in\na photon-conserving manner, directly on the spatially adaptive, unstructured\ngrid traced out by the particles, in a computation time that is independent of\nthe number of radiation sources, and in parallel on distributed memory\nmachines. We extend the method to include multiple frequencies, both hydrogen\nand helium, and to model the coupled evolution of the temperature and\nionisation balance. We test our methods by performing a set of simulations of\nincreasing complexity and including a small cosmological reionisation run. The\nresults are in excellent agreement with exact solutions, where available, and\nalso with results obtained with other codes if we make similar assumptions and\naccount for differences in the atomic rates used. We use the new implementation\nto illustrate the differences between simulations that compute photoheating in\nthe grey approximation and those that use multiple frequency bins. We show that\nclose to ionising sources the grey approximation asymptotes to the\nmulti-frequency result if photoheating rates are computed in the optically thin\nlimit, but that the grey approximation breaks down everywhere if, as is often\ndone, the optically thick limit is assumed. \n\n"}
{"id": "1008.2793", "contents": "Title: HST and Spitzer Observations of the HD 207129 Debris Ring Abstract: A debris ring around the star HD 207129 (G0V; d = 16.0 pc) has been imaged in\nscattered visible light with the ACS coronagraph on the Hubble Space Telescope\nand in thermal emission using MIPS on the Spitzer Space Telescope at 70 microns\n(resolved) and 160 microns (unresolved). Spitzer IRS (7-35 microns) and MIPS\n(55-90 microns) spectrographs measured disk emission at >28 microns. In the HST\nimage the disk appears as a ~30 AU wide ring with a mean radius of ~163 AU and\nis inclined by 60 degrees from pole-on. At 70 microns it appears partially\nresolved and is elongated in the same direction and with nearly the same size\nas seen with HST in scattered light. At 0.6 microns the ring shows no\nsignificant brightness asymmetry, implying little or no forward scattering by\nits constituent dust. With a mean surface brightness of V=23.7 mag per square\narcsec, it is the faintest disk imaged to date in scattered light. \n\n"}
{"id": "1008.5106", "contents": "Title: Time-division SQUID multiplexers with reduced sensitivity to external\n  magnetic fields Abstract: Time-division SQUID multiplexers are used in many applications that require\nexquisite control of systematic error. One potential source of systematic error\nis the pickup of external magnetic fields in the multiplexer. We present\nmeasurements of the field sensitivity figure of merit, effective area, for both\nthe first stage and second stage SQUID amplifiers in three NIST SQUID\nmultiplexer designs. These designs include a new variety with improved\ngradiometry that significantly reduces the effective area of both the first and\nsecond stage SQUID amplifiers. \n\n"}
{"id": "1009.1213", "contents": "Title: The UV-upturn in brightest cluster galaxies Abstract: This paper is part of a series devoted to the investigation of a large sample\nof brightest cluster galaxies (BCGs), their properties and the relationships\nbetween these and the properties of the host clusters. In this paper, we\ncompare the stellar population properties derived from high signal-to-noise,\noptical long-slit spectra with the GALEX ultraviolet (UV) colour measurements\nfor 36 nearby BCGs to understand the diversity in the most rapidly evolving\nfeature in old stellar systems, the UV-upturn. We investigate: (1) the possible\ndifferences between the UV-upturn of BCGs and those of a control sample of\nordinary ellipticals in the same mass range, as well as possible correlations\nbetween the UV-upturn and other general properties of the galaxies; (2)\npossible correlations between the UV-upturn and the properties of the host\nclusters; (3) recently proposed scenarios where helium-sedimentation in the\ncluster centre can produce an enhanced UV-upturn. We find systematic\ndifferences between the UV-colours of BCGs and ordinary ellipticals, but we do\nnot find correlations between these colours and the properties of the host\nclusters. Furthermore, the observations do not support the predictions made by\nthe helium-sedimentation model as an enhancer of the UV-upturn. \n\n"}
{"id": "1009.4483", "contents": "Title: Massive stars in the era of ELTs Abstract: Plans for the next generation of optical-infrared telescopes, the Extremely\nLarge Telescopes (ELTs), are well advanced. With primary apertures in excess of\n20m, they will revolutionise our ground-based capabilities. In this review I\nsummarise the three current ELT projects, their instrumentation plans, and\ndiscuss their science case and potential performance in the context of studies\nof massive stars. \n\n"}
{"id": "1009.5046", "contents": "Title: Channeling Effects in Direct Dark Matter Detectors Abstract: The channeling of the ion recoiling after a collision with a WIMP changes the\nionization signal in direct detection experiments, producing a larger signal\nthan otherwise expected. We give estimates of the fraction of channeled\nrecoiling ions in NaI (Tl), Si and Ge crystals using analytic models produced\nsince the 1960's and 70's to describe channeling and blocking effects. We find\nthat the channeling fraction of recoiling lattice nuclei is smaller than that\nof ions that are injected into the crystal and that it is strongly temperature\ndependent. \n\n"}
{"id": "1009.5443", "contents": "Title: Nonparametric Reconstruction of the Dark Energy Equation of State Abstract: A basic aim of ongoing and upcoming cosmological surveys is to unravel the\nmystery of dark energy. In the absence of a compelling theory to test, a\nnatural approach is to better characterize the properties of dark energy in\nsearch of clues that can lead to a more fundamental understanding. One way to\nview this characterization is the improved determination of the\nredshift-dependence of the dark energy equation of state parameter, w(z). To do\nthis requires a robust and bias-free method for reconstructing w(z) from data\nthat does not rely on restrictive expansion schemes or assumed functional forms\nfor w(z). We present a new nonparametric reconstruction method that solves for\nw(z) as a statistical inverse problem, based on a Gaussian Process\nrepresentation. This method reliably captures nontrivial behavior of w(z) and\nprovides controlled error bounds. We demonstrate the power of the method on\ndifferent sets of simulated supernova data; the approach can be easily extended\nto include diverse cosmological probes. \n\n"}
{"id": "1010.1371", "contents": "Title: Needatool: A Needlet Analysis Tool for Cosmological Data Processing Abstract: We introduce NeedATool (Needlet Analysis Tool), a software for data analysis\nbased on needlets, a wavelet rendition which is powerful for the analysis of\nfields defined on a sphere. Needlets have been applied successfully to the\ntreatment of astrophysical and cosmological observations, and in particular to\nthe analysis of cosmic microwave background (CMB) data. Usually, such analyses\nare performed in real space as well as in its dual domain, the harmonic one.\nBoth spaces have advantages and disadvantages: for example, in pixel space it\nis easier to deal with partial sky coverage and experimental noise; in harmonic\ndomain, beam treatment and comparison with theoretical predictions are more\neffective. During the last decade, however, wavelets have emerged as a useful\ntool for CMB data analysis, since they allow to combine most of the advantages\nof the two spaces, one of the main reasons being their sharp localisation. In\nthis paper, we outline the analytical properties of needlets and discuss the\nmain features of the numerical code, which should be a valuable addition to the\nCMB analyst's toolbox. \n\n"}
{"id": "1010.2071", "contents": "Title: Search for nuclearites with the ANTARES detector Abstract: ANTARES is an underwater detector located in the Mediterranean Sea, near the\nFrench city of Toulon, dedicated to the search for cosmic neutrinos. ANTARES is\noptimized to detect the Cherenkov signal from up-going relativistic particles,\nbut could also observe massive exotic objects, such as magnetic monopoles and\nnuclearites. In this article we present a search strategy for nuclearites and\ndetermine the sensitivity to nuclearites of ANTARES detector in complete\nconfiguration, using a set of data taken in 2008. \n\n"}
{"id": "1010.5035", "contents": "Title: WIDGET: System Performance and GRB Prompt Optical Observations Abstract: The WIDeField telescope for Gamma-ray burst Early Timing (WIDGET) is used for\na fully automated, ultra-wide-field survey aimed at detecting the prompt\noptical emission associated with Gamma-ray Bursts (GRBs). WIDGET surveys the\nHETE-2 and Swift/BAT pointing directions covering a total field of view of 62\ndegree x 62 degree every 10 secounds using an unfiltered system. This\nmonitoring survey allows exploration of the optical emission before the\ngamma-ray trigger. The unfiltered magnitude is well converted to the SDSS r'\nsystem at a 0.1 mag level. Since 2004, WIDGET has made a total of ten\nsimultaneous and one pre-trigger GRB observations. The efficiency of\nsynchronized observation with HETE-2 is four times better than that of Swift.\nThere has been no bright optical emission similar to that from GRB 080319B. The\nstatistical analysis implies that GRB080319B is a rare event. This paper\nsummarizes the design and operation of the WIDGET system and the simultaneous\nGRB observations obtained with this instrument. \n\n"}
{"id": "1010.5782", "contents": "Title: The first release of data from the Herschel ATLAS: the SPIRE images Abstract: We have reduced the data taken with the Spectral and Photometric Imaging\nReceiver (SPIRE) photometer on board the Herschel Space Observatory in the\nScience Demonstration Phase (SDP) of the Herschel Astrophysical Terahertz Large\nArea Survey (H-ATLAS). We describe the data reduction, which poses specific\nchallenges, both because of the sheer size of the data, and because only two\nscans are made for each region. We implement effective solutions to process the\nbolometric timelines into maps, and show that correlations among detectors are\nnegligible, and that the photometer is stable on time scales up to 250 s. This\nis longer than the time the telescope takes to cross the observed sky region,\nand it allows us to use naive binning methods for an optimal reconstruction of\nthe sky emission. The maps have equal contribution of confusion and white\ninstrumental noise, and the latter is estimated to 5.3, 6.4, and 6.7 mJy/beam\n(1-{\\sigma}), at 250, 350, and 500 \\mu{m}, respectively. This pipeline is used\nto reduce other H-ATLAS observations, as they became available, and we discuss\nhow it can be used with the optimal map maker implemented in the Herschel\nInteractive Processing Environment (HIPE), to improve computational efficiency\nand stability. The SDP dataset is available from http://www.h-atlas.org/. \n\n"}
{"id": "1011.0452", "contents": "Title: Holographic Non-Gaussianity Abstract: We investigate the non-Gaussianity of primordial cosmological perturbations\nwithin our recently proposed holographic description of inflationary universes.\nWe derive a holographic formula that determines the bispectrum of cosmological\ncurvature perturbations in terms of correlation functions of a holographically\ndual three-dimensional non-gravitational quantum field theory (QFT). This\nallows us to compute the primordial bispectrum for a universe which started in\na non-geometric holographic phase, using perturbative QFT calculations.\nStrikingly, for a class of models specified by a three-dimensional\nsuper-renormalisable QFT, the primordial bispectrum is of exactly the\nfactorisable equilateral form with f_nl^eq=5/36, irrespective of the details of\nthe dual QFT. A by-product of this investigation is a holographic formula for\nthe three-point function of the trace of the stress-energy tensor along general\nholographic RG flows, which should have applications outside the remit of this\nwork. \n\n"}
{"id": "1011.0733", "contents": "Title: A Carbon-enhanced Metal-poor Damped Lyman alpha System: Probing Gas from\n  Population III Nucleosynthesis? Abstract: We present high resolution observations of an extremely metal-poor damped\nLyman-alpha system, at z_abs = 2.3400972 in the spectrum of the QSO J0035-0918,\nexhibiting an abundance pattern consistent with model predictions for the\nsupernova yields of Population III stars. Specifically, this DLA has [Fe/H] =\n-3.04, shows a clear `odd-even' effect, and is C-rich with [C/Fe] = +1.53, a\nfactor of about 20 greater than reported in any other damped Lyman-alpha\nsystem. In analogy to the carbon-enhanced metal-poor stars in the Galactic halo\n(with [C/Fe] > +1.0), this is the first reported case of a carbon-enhanced\ndamped Lyman-alpha system. We determine an upper limit to the mass of 12C,\nM(12C) < 200 solar masses, which depends on the unknown gas density n(H); if\nn(H) > 1 atom per cubic cm (which is quite likely for this DLA given its low\nvelocity dispersion), then M(12C) < 2 solar masses, consistent with pollution\nby only a few prior supernovae. We speculate that DLAs such as the one reported\nhere may represent the `missing link' between the yields of Pop III stars and\ntheir later incorporation in the class of carbon-enhanced metal-poor stars\nwhich show no enhancement of neutron-capture elements (CEMP-no stars). \n\n"}
{"id": "1011.1028", "contents": "Title: An Early Warning System for Asteroid Impact Abstract: Earth is bombarded by meteors, occasionally by one large enough to cause a\nsignificant explosion and possible loss of life. Although the odds of a deadly\nasteroid strike in the next century are low, the most likely impact is by a\nrelatively small asteroid, and we suggest that the best mitigation strategy in\nthe near term is simply to move people out of the way. We describe an \"early\nwarning\" system that could provide a week's notice of most sizable asteroids or\ncomets on track to hit the Earth. This system, dubbed \"Asteroid\nTerrestrial-impact Last Alert System\" (ATLAS), comprises two observatories\nseparated by about 100km that simultaneously scan the visible sky twice a\nnight, and can be implemented immediately for relatively low cost. The\nsensitivity of ATLAS permits detection of 140m asteroids (100 Mton impact\nenergy) three weeks before impact, and 50m asteroids a week before arrival. An\nATLAS alarm, augmented by other observations, should result in a determination\nof impact location and time that is accurate to a few kilometers and a few\nseconds. In addition to detecting and warning of approaching asteroids, ATLAS\nwill continuously monitor the changing universe around us: most of the variable\nstars in our galaxy, many micro-lensing events from stellar alignments,\nluminous stars and novae in nearby galaxies, thousands of supernovae, nearly a\nmillion quasars and active galactic nuclei, tens of millions of galaxies, and a\nbillion stars. With two views per day ATLAS will make the variable universe as\nfamiliar to us as the sunrise and sunset. \n\n"}
{"id": "1011.1507", "contents": "Title: Constraints on the Assembly and Dynamics of Galaxies: I. Detailed\n  Rest-frame Optical Morphologies on Kiloparsec-scale of z ~ 2 Star-forming\n  Galaxies Abstract: We present deep and high-resolution HST/NIC2 F160W imaging at 1.6micron of\nsix z~2 star-forming galaxies with existing near-IR integral field spectroscopy\nfrom SINFONI at the VLT. The unique combination of rest-frame optical imaging\nand nebular emission-line maps provides simultaneous insight into morphologies\nand dynamical properties. The overall rest-frame optical emission of the\ngalaxies is characterized by shallow profiles in general (Sersic index n<1),\nwith median effective radii of ~5kpc. The morphologies are significantly clumpy\nand irregular, which we quantify through a non-parametric morphological\napproach, estimating the Gini (G), Multiplicity (Psi), and M_20 coefficients.\nThe strength of the rest-frame optical emission lines in the F160W bandpass\nindicates that the observed structure is not dominated by the morphology of\nline-emitting gas, and must reflect the underlying stellar mass distribution of\nthe galaxies. The sizes and structural parameters in the rest-frame optical\ncontinuum and Halpha emission reveal no significant differences, suggesting\nsimilar global distributions of the on-going star formation and more evolved\nstellar population. While no strong correlations are observed between stellar\npopulation parameters and morphology within the NIC2/SINFONI sample itself, a\nconsideration of the sample in the context of a broader range of z~2 galaxy\ntypes indicates that these galaxies probe the high specific star formation rate\nand low stellar mass surface density part of the massive z~2 galaxy population,\nwith correspondingly large effective radii, low Sersic indices, low G, and high\nPsi and M_20. The combined NIC2 and SINFONI dataset yields insights of\nunprecedented detail into the nature of mass accretion at high redshift.\n[Abridged] \n\n"}
{"id": "1011.2319", "contents": "Title: Preliminary results of a WIMP search with EDELWEISS-II cryogenic\n  detectors Abstract: The EDELWEISS-II experiment uses cryogenic heat-and-ionization detectors in\norder to detect the rare interactions from possible WIMP dark matter particles\non Germanium nuclei. Recently, new-generation detectors with an interleaved\nelectrode geometry were developped and validated, enabling an outstanding\nrejection of gamma-rays and surface interactions. We present here preliminary\nresults of a one-year WIMP search carried out with ten of such detectors in the\nLaboratoire Souterrain de Modane. A sensitivity to the spin-independent\nWIMP-nucleon cross-section of 5 \\times 10-8 pb was achieved using a 322 kg \n\n"}
{"id": "1011.3514", "contents": "Title: A Multi-Code Analysis Toolkit for Astrophysical Simulation Data Abstract: The analysis of complex multiphysics astrophysical simulations presents a\nunique and rapidly growing set of challenges: reproducibility, parallelization,\nand vast increases in data size and complexity chief among them. In order to\nmeet these challenges, and in order to open up new avenues for collaboration\nbetween users of multiple simulation platforms, we present yt (available at\nhttp://yt.enzotools.org/), an open source, community-developed astrophysical\nanalysis and visualization toolkit. Analysis and visualization with yt are\noriented around physically relevant quantities rather than quantities native to\nastrophysical simulation codes. While originally designed for handling Enzo's\nstructure adaptive mesh refinement (AMR) data, yt has been extended to work\nwith several different simulation methods and simulation codes including Orion,\nRAMSES, and FLASH. We report on its methods for reading, handling, and\nvisualizing data, including projections, multivariate volume rendering,\nmulti-dimensional histograms, halo finding, light cone generation and\ntopologically-connected isocontour identification. Furthermore, we discuss the\nunderlying algorithms yt uses for processing and visualizing data, and its\nmechanisms for parallelization of analysis tasks. \n\n"}
{"id": "1011.5294", "contents": "Title: Collaborative Astronomical Image Mosaics Abstract: This chapter describes how astronomical imaging survey data have become a\nvital part of modern astronomy, how these data are archived and then served to\nthe astronomical community through on-line data access portals. The Virtual\nObservatory, now under development, aims to make all these data accessible\nthrough a uniform set of interfaces. This chapter also describes the scientific\nneed for one common image processing task, that of composing individual images\ninto large scale mosaics and introduces Montage as a tool for this task.\nMontage, as distributed, can be used in four ways: as a single thread/process\non a single CPU, in parallel using MPI to distribute similar tasks across a\nparallel computer, in parallel using grid tools (Pegasus/DAGMan) to distributed\ntasks across a grid, or in parallel using a script-driven approach (Swift). An\non-request web based Montage service is available for users who do not need to\nbuild a local version. We also introduce some work on a new scripted version of\nMontage, which offers ease of customization for users. Then, we discuss various\nideas where Web 2.0 technologies can help the Montage community. \n\n"}
{"id": "1011.6439", "contents": "Title: Lowering the low-energy threshold of xenon detectors Abstract: We show that the energy threshold for nuclear recoils in the XENON10 dark\nmatter search data can be lowered to ~1 keV, by using only the ionization\nsignal. In other words, we make no requirement that a valid event contain a\nprimary scintillation signal. We therefore relinquish incident particle type\ndiscrimination, which is based on the ratio of ionization to scintillation in\nliquid xenon. This method compromises the detector's ability to precisely\ndetermine the z coordinate of a particle interaction. However, we show for the\nfirst time that it is possible to discriminate bulk events from surface events\nbased solely on the ionization signal. \n\n"}
{"id": "1012.0377", "contents": "Title: The many faces of Betelgeuse Abstract: The dynamics of the surface and inner atmosphere of the red supergiant star\nBetelgeuse are the subject of numerous high angular resolution and\nspectroscopic studies. Here, we present three-telescope interferometric data\nobtained at 11.15 microns wavelength with the Berkeley Infrared Spatial\nInterferometer (ISI), that probe the stellar surface continuum. We find\nstriking variability in the size, effective temperature, and degree of\nasymmetry of the star over the years 2006-2009. These results may indicate an\nevolving shell of optically thick material close to the stellar photosphere. \n\n"}
{"id": "1012.2383", "contents": "Title: Stellar metallicities beyond the Local Group: the potential of J-band\n  spectroscopy with extremely large telescopes Abstract: We present simulated J-band spectroscopy of red giants and supergiants with a\n42m European Extremely Large Telescope (E-ELT), using tools developed toward\nthe EAGLE Phase A instrument study. The simulated spectra are used to\ndemonstrate the validity of the 1.15-1.22 micron region to recover accurate\nstellar metallicities from Solar and metal-poor (one tenth Solar) spectral\ntemplates. From tests at spectral resolving powers of four and ten thousand, we\nrequire continuum signal-to-noise ratios in excess of 50 (per two-pixel\nresolution element) to recover the input metallicity to within 0.1 dex. We\nhighlight the potential of direct estimates of stellar metallicites (over the\nrange -1<[Fe/H]<0) of red giants with the E-ELT, reaching out to distances of\n~5 Mpc for stars near the tip of the red giant branch. The same simulations are\nalso used to illustrate the potential for quantitative spectroscopy of red\nsupergiants beyond the Local Volume to tens of Mpc. Calcium triplet\nobservations in the I-band are also simulated to provide a comparison with\ncontemporary techniques. Assuming the EAGLE instrument parameters and simulated\nperformances from adaptive optics, the J-band method is more sensitive in terms\nof recovering metallicity estimates for a given target. This appears very\npromising for ELT studies of red giants and supergiants, offering a direct\nmetallicity tracer at a wavelength which is less afffected by extinction than\nshortward diagnostics and, via adaptive optics, with better image quality. \n\n"}
{"id": "1012.3779", "contents": "Title: Detection of Periodic Variability in Simulated QSO Light Curves Abstract: Periodic light curve behavior predicted for some binary black hole systems\nmight be detected in large samples, such as the multi-million quasar sample\nexpected from the Large Synoptic Survey Telescope (LSST). We investigate the\nfalse-alarm probability for the discovery of a periodic signal in light curves\nsimulated using damped random walk (DRW) model. This model provides a good\ndescription of observed light curves, and does not include periodic behavior.\nWe used the Lomb-Scargle periodogram to search for a periodic signal in a\nmillion simulated light curves that properly sample the DRW parameter space,\nand the LSST cadence space. We find that even a very conservative threshold for\nthe false-alarm probability still yields thousands of \"good\" binary black hole\ncandidates. We conclude that the future claims for binary black holes based on\nLomb-Scargle analysis of LSST light curves will have to be interpreted with\ncaution. \n\n"}
{"id": "1012.3899", "contents": "Title: 1.2 Meter Shielded Cassegrain Antenna for Close-Packed Radio\n  Interferometer Abstract: Interferometric millimeter observations of the cosmic microwave background\nand clusters of galaxies with arcmin resolutions require antenna arrays with\nshort spacings. Having all antennas co-mounted on a single steerable platform\nsets limits to the overall weight. A 25 kg lightweight novel carbon-fiber\ndesign for a 1.2 m diameter Cassegrain antenna is presented. The finite element\nanalysis predicts excellent structural behavior under gravity, wind and thermal\nload. The primary and secondary mirror surfaces are aluminum coated with a thin\nTiO$_2$ top layer for protection. A low beam sidelobe level is achieved with a\nGaussian feed illumination pattern with edge taper, designed based on feedhorn\nantenna simulations and verified in a far field beam pattern measurement. A\nshielding baffle reduces inter-antenna coupling to below $\\sim$ -135 dB. The\noverall antenna efficiency, including a series of efficiency factors, is\nestimated to be around 60%, with major losses coming from the feed spillover\nand secondary blocking. With this new antenna, a detection rate of about 50\nclusters per year is anticipated in a 13-element array operation. \n\n"}
{"id": "1012.4011", "contents": "Title: The XMM Deep survey in the CDFS I. First results on heavily obscured AGN Abstract: We present the first results of the spectroscopy of distant, obscured AGN as\nobtained with the ultra-deep (~3.3 Ms) XMM-Newton survey in the Chandra Deep\nField South (CDFS). One of the primary goals of the project is to characterize\nthe X-ray spectral properties of obscured and heavily obscured Compton-thick\nAGN over the range of redhifts and luminosities that are relevant in terms of\ntheir contribution to the X-ray background. The ultra-deep exposure, coupled\nwith the XMM detector's spectral throughput, allowed us to accumulate good\nquality X-ray spectra for a large number of X-ray sources and, in particular,\nfor heavily obscured AGN at cosmological redshifts. Specifically we present the\nX-ray spectral properties of two high-redshift - z= 1.53 and z=3.70 - sources.\nThe XMM spectra of both are very hard, with a strong iron Kalpha line at a\nrest-frame energy of 6.4 keV. A reflection-dominated continuum provides the\nbest description of the X-ray spectrum of the z=1.53 source, while the\nintrinsic continuum of the z=3.70 AGN is obscured by a large column N_H ~ 10^24\ncm-2 of cold gas. Compton-thick absorption, or close to it, is unambiguously\ndetected in both sources. Interestingly, these sources would not be selected as\ncandidate Compton thick AGN by some multiwavelength selection criteria based on\nthe mid-infrared to optical and X-ray to optical flux ratios. \n\n"}
{"id": "1012.4125", "contents": "Title: A new sky subtraction technique for low surface brightness data Abstract: We present a new approach to the sky subtraction for long-slit spectra\nsuitable for low-surface brightness objects based on the controlled\nreconstruction of the night sky spectrum in the Fourier space using twilight or\narc-line frames as references. It can be easily adopted for FLAMINGOS-type\nmulti-slit data. Compared to existing sky subtraction algorithms, our technique\nis taking into account variations of the spectral line spread along the slit\nthus qualitatively improving the sky subtraction quality for extended targets.\nAs an example, we show how the stellar metallicity and stellar velocity\ndispersion profiles in the outer disc of the spiral galaxy NGC 5440 are\naffected by the sky subtraction quality. Our technique is used in the survey of\nearly-type galaxies carried out at the Russian 6-m telescope, and it strongly\nincreases the scientific potential of large amounts of long-slit data for\nnearby galaxies available in major data archives. \n\n"}
{"id": "1012.4430", "contents": "Title: Evidence for a correlation between the Si II 4000 width and Type Ia\n  supernova color Abstract: We study the pseudo equivalent width of the Si II 4000 feature of Type Ia\nsupernovae in the redshift range 0.0024 < z < 0.634. We find that this spectral\nindicator correlates with the lightcurve color excess (SALT2 c) as well as\npreviously defined spectroscopic subclasses (Branch types) and the evolution of\nthe Si II 6150 velocity, i.e., the so called velocity gradient. Based on our\nstudy of 55 objects from different surveys, we find indications that the Si II\n4000 spectral indicator could provide important information to improve\ncosmological distance measurements with Type Ia supernovae. \n\n"}
{"id": "1012.5202", "contents": "Title: Inflation with a Weyl term, or ghosts at work Abstract: In order to assess the role of ghosts in cosmology, we study the evolution of\nlinear cosmological perturbations during inflation when a Weyl term is added to\nthe action. Our main result is that vector perturbations can no longer be\nignored and that scalar modes diverge in the newtonian gauge but remain bounded\nin the comoving slicing. \n\n"}
{"id": "1012.5386", "contents": "Title: Conformal transformations and Nordstr\\\"om's scalar theory of gravity Abstract: As we shall briefly recall, Nordstr\\\"om's theory of gravity is\nobservationally ruled out. It is however an interesting example of non-minimal\ncoupling of matter to gravity and of the role of conformal transformations. We\nshow in particular that they could be useful to extend manifolds through\ncurvature singularities. \n\n"}
{"id": "1101.1284", "contents": "Title: The SPIRE Photometer Interactive Analysis Package SPIA Abstract: The Herschel Common Science System (HCSS) (Ott et al. 2006) (Ott & Science\nGround Segment Consortium 2010) is a substantial Java software package,\naccompanying the development of the Herschel Mission (Pilbratt et al. 2010),\nsupporting all of its phases. In particular the reduction of data from the\nscientific instruments for instrument checkout, calibration, and astronomical\nanalysis is one of its major applications. The data reduction software is split\nup in modules, called \"tasks\". Agreed-upon sequences of tasks form pipelines\nthat deliver well defined standard products for storage in a web-accessible\nHerschel Science Archive (HSA) (Leon et al. 2009). However, as astronomers and\ninstrument scientists continue to characterize instrumental effects,\nastronomers already need to publish scientific results and may not have the\ntime to acquire a sufficiently deep understanding of the system to apply\nnecessary fixes. There is a need for intermediate level analysis tools that\noffer more flexibility than rigid pipelines. The task framework within the HCSS\nand the highly versatile Herschel Interactive Processing Environment (HIPE),\ntogether with the rich set of libraries provide the necessary tools to develop\nGUI-based interactive analysis packages for the Herschel instruments. The SPIRE\nPhotometer Interactive Analysis (SPIA) package, that was demonstrated in this\nsession, proves the validity of the concept for the SPIRE instrument (Griffin\net al. 2010), breaking up the pipeline reduction into logical components,\nmaking all relevant processing parameters available in GUIs, and providing a\nmore controlled and user-friendly access to the complexities of the system. \n\n"}
{"id": "1101.2040", "contents": "Title: Planck Early Results. V. The Low Frequency Instrument data processing Abstract: We describe the processing of data from the Low Frequency Instrument (LFI)\nused in production of the Planck Early Release Compact Source Catalogue\n(ERCSC). In particular, we discuss the steps involved in reducing the data from\ntelemetry packets to cleaned, calibrated, time-ordered data (TOD) and frequency\nmaps. Data are continuously calibrated using the modulation of the temperature\nof the cosmic microwave background radiation induced by the motion of the\nspacecraft. Noise properties are estimated from TOD from which the sky signal\nhas been removed using a generalized least square map-making algorithm.\nMeasured 1/f noise knee-frequencies range from 100mHz at 30GHz to a few tens of\nmHz at 70GHz. A destriping code (Madam) is employed to combine radiometric data\nand pointing information into sky maps, minimizing the variance of correlated\nnoise. Noise covariance matrices required to compute statistical uncertainties\non LFI and Planck products are also produced. Main beams are estimated down to\nthe approx -10dB level using Jupiter transits, which are also used for\ngeometrical calibration of the focal plane. \n\n"}
{"id": "1101.2048", "contents": "Title: Planck early results. VI. The High Frequency Instrument data processing Abstract: We describe the processing of the 336 billion raw data samples from the High\nFrequency Instrument (HFI) which we performed to produce six temperature maps\nfrom the first 295 days of Planck-HFI survey data. These maps provide an\naccurate rendition of the sky emission at 100, 143, 217, 353, 545 and 857 GHz\nwith an angular resolution ranging from 9.9 to 4.4^2. The white noise level is\naround 1.5 {\\mu}K degree or less in the 3 main CMB channels (100--217GHz). The\nphotometric accuracy is better than 2% at frequencies between 100 and 353 GHz\nand around 7% at the two highest frequencies. The maps created by the HFI Data\nProcessing Centre reach our goals in terms of sensitivity, resolution, and\nphotometric accuracy. They are already sufficiently accurate and\nwell-characterised to allow scientific analyses which are presented in an\naccompanying series of early papers. At this stage, HFI data appears to be of\nhigh quality and we expect that with further refinements of the data processing\nwe should be able to achieve, or exceed, the science goals of the Planck\nproject. \n\n"}
{"id": "1101.2254", "contents": "Title: Fitting Galaxies on GPUs Abstract: Structural parameters are normally extracted from observed galaxies by\nfitting analytic light profiles to the observations. Obtaining accurate fits to\nhigh-resolution images is a computationally expensive task, requiring many\nmodel evaluations and convolutions with the imaging point spread function.\nWhile these algorithms contain high degrees of parallelism, current\nimplementations do not exploit this property. With evergrowing volumes of\nobservational data, an inability to make use of advances in computing power can\nact as a constraint on scientific outcomes. This is the motivation behind our\nwork, which aims to implement the model-fitting procedure on a graphics\nprocessing unit (GPU). We begin by analysing the algorithms involved in model\nevaluation with respect to their suitability for modern many-core computing\narchitectures like GPUs, finding them to be well-placed to take advantage of\nthe high memory bandwidth offered by this hardware. Following our analysis, we\nbriefly describe a preliminary implementation of the model fitting procedure\nusing freely-available GPU libraries. Early results suggest a speed-up of\naround 10x over a CPU implementation. We discuss the opportunities such a\nspeed-up could provide, including the ability to use more computationally\nexpensive but better-performing fitting routines to increase the quality and\nrobustness of fits. \n\n"}
{"id": "1101.2447", "contents": "Title: Fossil Groups Origins: I. RX J105453.3+552102 a very massive and relaxed\n  system at z~0.5 Abstract: The most accepted scenario for the origin of fossil groups (FGs) is that they\nare galaxy associations in which the merging rate was fast and efficient. These\nsystems have assembled half of their mass at early epoch of the Universe,\nsubsequently growing by minor mergers. They could contain a fossil record of\nthe galaxy structure formation. We have started a project in order to\ncharacterize a large sample of FGs. In this paper we present the analysis of\nthe fossil system RX J105453.3+552102. Optical deep images were used for\nstudying the properties of the brightest group galaxy and for computing the\nphotometric luminosity function of the group. We have also performed a detail\ndynamical analysis of the system based on redshift data for 116 galaxies. This\ngalaxy system is located at z=0.47, and shows a quite large line-of-sight\nvelocity dispersion \\sigma_{v}~1000 km/s. Assuming the dynamical equilibrium,\nwe estimated a virial mass of M ~ 10^{15} h_{70} M_{\\odot}. No evidence of\nsubstructure was found within 1.4 Mpc radius. We found a statistically\nsignificant departure from Gaussianity of the group members velocities in the\nmost external regions of the group. This could indicate the presence of\ngalaxies in radial orbits in the external region of the group. We also found\nthat the photometrical luminosity function is bimodal, showing a lack of M_{r}\n~ -19.5 galaxies. The brightest group galaxy shows low Sersic parameter (n~2)\nand a small peculiar velocity. Indeed, our accurate photometry shows that the\ndifference between the brightest and the second brightest galaxies is 1.9 mag\nin the r-band, while the classical definition of FGs is based on a magnitude\ngap of 2. We conclude that this fossil system does not follow the empirical\ndefinition of FGs. Nevertheless, it is a massive, old and undisturbed galaxy\nsystem with little infall of L^{*} galaxies since its initial collapse. \n\n"}
{"id": "1101.3314", "contents": "Title: The first (nearly) model-independent constraint on the neutral hydrogen\n  fraction at z~5--6 Abstract: Cosmic reionization is expected to be complex, extended and very\ninhomogeneous. Existing constraints at z~6 on the volume-averaged neutral\nhydrogen fraction, <x_HI>, are highly model-dependent and controversial.\nConstraints at z<6, suggesting that the Universe is highly ionized, are also\nmodel-dependent, but more fundamentally are invalid in the context of\ninhomogeneous reionization. As such, it has recently been pointed out that\nthere is no conclusive evidence that reionization has completed by z~5--6, a\nfact that has important ramifications on the interpretation of high-redshift\nobservations and theoretical models. We present the first direct upper limits\non <x_HI> at z~5--6 using the simple and robust statistic of the covering\nfraction of dark pixels in the Ly alpha/beta forests of high redshift quasars.\nWith a sample of 13 Keck ESI spectra we constrain <x_HI> < 0.2 at 5 < z < 5.5,\nrising to <x_HI> < 0.8 at z~6.1. We also find tentative evidence for a break in\nthe redshift evolution of the dark covering fraction at z~5.5. A subsample of\ntwo deep spectra provides a more stringent constraint of <x_HI>(z=6.1) < 0.5\nwhen combined with conservative estimates of cosmic variance. This upper limit\nis comparable to existing results at z~6 but is more robust. The results\npresented here do not rely on assumptions about the quasar continuum, IGM\ndensity, HII morphology or ionizing background fields, and thus are a good\nstarting point for future interpretation of high redshift observations. \n\n"}
{"id": "1101.3419", "contents": "Title: Time-Dependent Models for a decade of SN 1993J Abstract: A classical and a relativistic law of motion for a supernova remnant (SNR)\nare deduced assuming an inverse power law behavior for the density of the\ninterstellar medium and applying the thin layer approximation. A third equation\nof motion is found in the framework of relativistic hydrodynamics with\npressure, applying momentum conservation. These new formulas are calibrated\nagainst a decade of observations of \\snr. The existing knowledge of the\ndiffusive processes of ultrarelativistic electrons is reviewed in order to\nexplain the behavior of the `U' shaped profile of intensity versus distance\nfrom the center of SN 1993J. \n\n"}
{"id": "1101.4635", "contents": "Title: How Future Space-Based Weak Lensing Surveys Might Obtain Photometric\n  Redshifts Independently Abstract: We study how the addition of on-board optical photometric bands to future\nspace-based weak lensing instruments could affect the photometric redshift\nestimation of galaxies, and hence improve estimations of the dark energy\nparameters through weak lensing. Basing our study on the current proposed\nEuclid configuration and using a mock catalog of galaxy observations, various\non-board options are tested and compared with the use of ground-based\nobservations from the Large Synoptic Survey Telescope (LSST) and Pan-STARRS.\nComparisons are made through the use of the dark energy Figure of Merit, which\nprovides a quantifiable measure of the change in the quality of the scientific\nresults that can be obtained in each scenario. Effects of systematic offsets\nbetween LSST and Euclid photometric calibration are also studied. We find that\nadding two (U and G) or even one (U) on-board optical band-passes to the\nspace-based infrared instrument greatly improves its photometric redshift\nperformance, bringing it close to the level that would be achieved by combining\nobservations from both space-based and ground-based surveys while freeing the\nspace mission from reliance on external datasets. \n\n"}
{"id": "1101.4822", "contents": "Title: The power of Bayesian evidence in astronomy Abstract: We discuss the use of the Bayesian evidence ratio, or Bayes factor, for model\nselection in astronomy. We treat the evidence ratio as a statistic and\ninvestigate its distribution over an ensemble of experiments, considering both\nsimple analytical examples and some more realistic cases, which require\nnumerical simulation. We find that the evidence ratio is a noisy statistic, and\nthus it may not be sensible to decide to accept or reject a model based solely\non whether the evidence ratio reaches some threshold value. The odds suggested\nby the evidence ratio bear no obvious relationship to the power or Type I error\nrate of a test based on the evidence ratio. The general performance of such\ntests is strongly affected by the signal to noise ratio in the data, the\nassumed priors, and the threshold in the evidence ratio that is taken as\n`decisive'. The comprehensiveness of the model suite under consideration is\nalso very important. The usefulness of the evidence ratio approach in a given\nproblem can be assessed in advance of the experiment, using simple models and\nnumerical approximations. In many cases, this approach can be as informative as\na much more costly full-scale Bayesian analysis of a complex problem. \n\n"}
{"id": "1101.5497", "contents": "Title: Diffuse Intracluster Light at Intermediate Redshifts: ICL observations\n  in a X-ray cluster at z=0.29 Abstract: The diffuse intracluster light (ICL) contains a significant fraction of the\ntotal stellar mass in clusters of galaxies, and contributes in roughly equal\nproportion as the hot intra-cluster medium (ICM) to the total baryon content of\nclusters. Because of the potential importance of understanding the origin of\nthe ICL in the context of the formation and evolution of structure in the\nUniverse, the field has recently undergone a revival both in the quality and\nquantity of observational and theoretical investigations. Due to cosmological\ndimming, the observational work has mostly concentrated on low redshift\nclusters, but clearly observations at higher redshifts can provide interesting\nclues about the evolution of the diffuse component. In this paper we present\nthe first results of a program to characterize the ICL of intermediate redshift\nclusters. We find that at z ~ 0.3, the X-ray cluster RX J0054.0-2823 already\nhas a significant ICL and that the fraction of the total light in the ICL and\nthe brightest cluster galaxy (BCG) is comparable to that of similar clusters at\nlower redshift. We also find that the kinematics of the ICL is consistent with\nit being the remnant of tidally destroyed galaxies streaming in the central\nregions of the cluster, which has three central giant elliptical galaxies\nacting as an efficient \"grinding machine\". Our cluster has a bi-modal\nradial-velocity distribution and thus two possible values for the velocity\ndispersion. We find that the cluster fits well in the correlation between\nBCG+ICL fraction and cluster mass for a range of velocity dispersions, leading\nus to question the validity of a relevant correlation between these two\nquantities. \n\n"}
{"id": "1102.1316", "contents": "Title: The GALEX Ultraviolet Virgo Cluster Survey (GUViCS). I: The UV\n  luminosity function of the central 12 sq.deg Abstract: The GALEX Ultraviolet Virgo Cluster Survey (GUViCS) is a complete blind\nsurvey of the Virgo cluster covering about 40 sq. deg. in the far UV (FUV,\nlambda_eff=1539A, Delta-lambda=442A) and about 120 sq. deg. in the near UV\n(NUV, lambda_eff=2316A, Delta-lambda=1060A). The goal of the survey is to study\nthe ultraviolet (UV) properties of galaxies in a rich cluster environment,\nspanning a wide luminosity range from giants to dwarfs, and regardless of prior\nknowledge of their star formation activity. The UV data will be combined with\nthose in other bands (optical: NGVS; far-infrared - submm: HeViCS; HI: ALFALFA)\nand with our multizone chemo-spectrophotometric models of galaxy evolution to\nmake a complete and exhaustive study of the effects of the environment on the\nevolution of galaxies in high density regions. We present here the scientific\nobjectives of the survey, describing the observing strategy and briefly\ndiscussing different data reduction techniques. Using UV data already in-hand\nfor the central 12 sq. deg. we determine the FUV and NUV luminosity functions\nof the Virgo cluster core for all cluster members and separately for early- and\nlate-type galaxies and compare it to the one obtained in the field and other\nnearby clusters (Coma, A1367). This analysis shows that the FUV and NUV\nluminosity functions of the core of the Virgo clusters are flatter (alpha about\n-1.1) than those determined in Coma and A1367. We discuss the possible origin\nof this difference \n\n"}
{"id": "1102.1588", "contents": "Title: VST processing facility: first astronomical applications Abstract: VST--Tube is a new software package designed to process optical astronomical\nimages. It is an automated pipeline to go from the raw exposures to fully\ncalibrated co-added images, and to extract catalogs with aperture and PSF\nphotometry. A set of tools allow the data administration and the quality check\nof the intermediate and final products. VST-Tube comes with a Graphical User\nInterface to facilitate the interaction between data and user. We outline here\nthe VST--Tube architecture and show some applications enlightening some of the\ncharacteristics of the pipeline. \n\n"}
{"id": "1102.1837", "contents": "Title: A weak lensing analysis of the Abell 383 cluster Abstract: In this paper we use deep CFHT and SUBARU $uBVRIz$ archival images of the\nAbell 383 cluster (z=0.187) to estimate its mass by weak lensing. To this end,\nwe first use simulated images to check the accuracy provided by our KSB\npipeline. Such simulations include both the STEP 1 and 2 simulations, and more\nrealistic simulations of the distortion of galaxy shapes by a cluster with a\nNavarro-Frenk-White (NFW) profile. From such simulations we estimate the effect\nof noise on shear measurement and derive the correction terms. The R-band image\nis used to derive the mass by fitting the observed tangential shear profile\nwith a NFW mass profile. Photometric redshifts are computed from the uBVRIz\ncatalogs. Different methods for the foreground/background galaxy selection are\nimplemented, namely selection by magnitude, color and photometric redshifts,\nand results are compared. In particular, we developed a semi-automatic\nalgorithm to select the foreground galaxies in the color-color diagram, based\non observed colors. Using color selection or photometric redshifts improves the\ncorrection of dilution from foreground galaxies: this leads to higher signals\nin the inner parts of the cluster. We obtain a cluster mass that is ~ 20%\nhigher than previous estimates, and is more consistent the mass expected from\nX--ray data. The R-band luminosity function of the cluster is finally computed. \n\n"}
{"id": "1102.3355", "contents": "Title: Gravitational Wave Detection by Interferometry (Ground and Space) Abstract: Significant progress has been made in recent years on the development of\ngravitational wave detectors. Sources such as coalescing compact binary\nsystems, neutron stars in low-mass X-ray binaries, stellar collapses and\npulsars are all possible candidates for detection. The most promising design of\ngravitational wave detector uses test masses a long distance apart and freely\nsuspended as pendulums on Earth or in drag-free craft in space. The main theme\nof this review is a discussion of the mechanical and optical principles used in\nthe various long baseline systems in operation around the world - LIGO (USA),\nVirgo (Italy/France), TAMA300 and LCGT (Japan), and GEO600 (Germany/U.K.) - and\nin LISA, a proposed space-borne interferometer. A review of recent science runs\nfrom the current generation of ground-based detectors will be discussed, in\naddition to highlighting the astrophysical results gained thus far. Looking to\nthe future, the major upgrades to LIGO (Advanced LIGO), Virgo (Advanced Virgo),\nLCGT and GEO600 (GEO-HF) will be completed over the coming years, which will\ncreate a network of detectors with significantly improved sensitivity required\nto detect gravitational waves. Beyond this, the concept and design of possible\nfuture \"third generation\" gravitational wave detectors, such as the Einstein\nTelescope (ET), will be discussed. \n\n"}
{"id": "1102.3883", "contents": "Title: The ExaVolt Antenna: A Large-Aperture, Balloon-embedded Antenna for\n  Ultra-high Energy Particle Detection Abstract: We describe the scientific motivation, experimental basis, design\nmethodology, and simulated performance of the ExaVolt Antenna (EVA) mission,\nand planned ultra-high energy (UHE) particle observatory under development for\nNASA's suborbital super-pressure balloon program in Antarctica. EVA will\nimprove over ANITA's integrated totals - the current state-of-the-art in UHE\nsuborbital payloads - by 1-2 orders of magnitude in a single flight. The design\nis based on a novel application of toroidal reflector optics which utilizes a\nsuper-pressure balloon surface, along with a feed-array mounted on an inner\nmembrane, to create an ultra-large radio antenna system with a synoptic view of\nthe Antarctic ice sheet below it. Radio impulses arise via the Askaryan effect\nwhen UHE neutrinos interact within the ice, or via geosynchrotron emission when\nUHE cosmic rays interact in the atmosphere above the continent. EVA's\ninstantaneous antenna aperture is estimated to be several hundred square meters\nfor detection of these events within a 150-600 MHz band. For standard\ncosmogenic UHE neutrino models, EVA should detect of order 30 events per flight\nin the EeV energy regime. For UHE cosmic rays, of order 15,000 geosynchrotron\nevents would be detected in total, several hundred above 10 EeV, and of order\n60 above the GZK cutoff energy \n\n"}
{"id": "1103.0814", "contents": "Title: Deriving global structure of the Galactic Magnetic Field from Faraday\n  Rotation Measures of extragalactic sources Abstract: We made use of the two latest sets of Rotational Measures (RMs) of\nextra-galactic radio sources, namely the NRAO VLA Sky Survey otation Measures\nCatalogue, and a compilation by Kronberg&Newton-McGee(2011), to infer the\nglobal structure of the Galactic Magnetic Field (GMF). We have checked that\nthese two data sets are consistent with each other. Motivated by clear patterns\nin the observed distribution of RMs over the sky, we considered GMF models\nconsisting of the two components: disk (spiral or ring) and halo. The\nparameters of these components were determined by fitting different model field\ngeometries to the observed RMs. We found that the model consisting of a\nsymmetric (with respect to the Galactic plane) spiral disk and anti-symmetric\nhalo fits the data best, and reproduces the observed distribution of RMs over\nthe sky very well. We confirm that ring disk models are disfavored. Our results\nfavor small pitch angles around -5 degrees and an increased vertical scale of\nelectron distribution, in agreement with some previous studies. Based on our\nfits, we identify two benchmark models suitable for studies of cosmic ray\npropagation, including the ultra-high energies. \n\n"}
{"id": "1103.3689", "contents": "Title: Characterization of the QUartz Photon Intensifying Detector (QUPID) for\n  Noble Liquid Detectors Abstract: Dark Matter and Double Beta Decay experiments require extremely low\nradioactivity within the detector materials. For this purpose, the University\nof California, Los Angeles and Hamamatsu Photonics have developed the QUartz\nPhoton Intensifying Detector (QUPID), an ultra-low background photodetector\nbased on the Hybrid Avalanche Photo Diode (HAPD) and entirely made of\nultraclean synthetic fused silica. In this work we present the basic concept of\nthe QUPID and the testing measurements on QUPIDs from the first production\nline. Screening of radioactivity at the Gator facility in the Laboratori\nNazionali del Gran Sasso has shown that the QUPIDs safely fulfill the low\nradioactive contamination requirements for the next generation zero background\nexperiments set by Monte Carlo simulations. The quantum efficiency of the QUPID\nat room temperature is > 30% at the xenon scintillation wavelength. At low\ntemperatures, the QUPID shows a leakage current less than 1 nA and a global\ngain of 10^5. In these conditions, the photocathode and the anode show > 95%\nlinearity up to 1 uA for the cathode and 3 mA for the anode. The photocathode\nand collection efficiency are uniform to 80% over the entire surface. In\nparallel with single photon counting capabilities, the QUPIDs have a good\ntiming response: 1.8 +/- 0.1 ns rise time, 2.5 +/- 0.2 ns fall time, 4.20 +/-\n0.05 ns pulse width, and 160 +/- 30 ps transit time spread. The QUPIDs have\nalso been tested in a liquid xenon environment, and scintillation light from\n57Co and 210Po radioactive sources were observed. \n\n"}
{"id": "1104.1580", "contents": "Title: Proceedings of the 2011 New York Workshop on Computer, Earth and Space\n  Science Abstract: The purpose of the New York Workshop on Computer, Earth and Space Sciences is\nto bring together the New York area's finest Astronomers, Statisticians,\nComputer Scientists, Space and Earth Scientists to explore potential synergies\nbetween their respective fields. The 2011 edition (CESS2011) was a great\nsuccess, and we would like to thank all of the presenters and participants for\nattending. This year was also special as it included authors from the upcoming\nbook titled \"Advances in Machine Learning and Data Mining for Astronomy\". Over\ntwo days, the latest advanced techniques used to analyze the vast amounts of\ninformation now available for the understanding of our universe and our planet\nwere presented. These proceedings attempt to provide a small window into what\nthe current state of research is in this vast interdisciplinary field and we'd\nlike to thank the speakers who spent the time to contribute to this volume. \n\n"}
{"id": "1104.2094", "contents": "Title: Redshift Space Distortion of the 21cm Background from the Epoch of\n  Reionization I: Methodology Re-examined Abstract: The peculiar velocity of the intergalactic gas responsible for the cosmic\n21cm background from the epoch of reionization and beyond introduces an\nanisotropy in the three-dimensional power spectrum of brightness temperature\nfluctuations. Measurement of this anisotropy by future 21cm surveys is a\npromising tool for separating cosmology from 21cm astrophysics. However,\nprevious attempts to model the signal have often neglected peculiar velocity or\nonly approximated it crudely. This paper re-examines the effects of peculiar\nvelocity on the 21cm signal in detail, improving upon past treatment and\naddressing several issues for the first time. (1) We show that properly\naccounting for finite optical depth eliminates the unphysical divergence of\n21cm brightness temperature in overdense regions of the IGM found by previous\nwork that employed the usual optically-thin approximation. (2) The\napproximation made previously to circumvent the diverging brightness\ntemperature problem by capping velocity gradient can misestimate the power\nspectrum on all scales. (3) The observed power spectrum in redshift-space\nremains finite even in the optically-thin approximation if one properly\naccounts for the redshift-space distortion. However, results that take full\naccount of finite optical depth show that this approximation is only accurate\nin the limit of high spin temperature. (4) The linear theory for redshift-space\ndistortion results in ~30% error in the observationally relevant wavenumber\nrange, at the 50% ionized epoch. (5) We describe and test two numerical schemes\nto calculate the 21cm signal from reionization simulations to incorporate\npeculiar velocity effects in the optically-thin approximation accurately. One\nis particle-based, the other grid-based, and while the former is most accurate,\nwe demonstrate that the latter is computationally more efficient and can\nachieve sufficient accuracy. [Abridged] \n\n"}
{"id": "1104.2700", "contents": "Title: N-body simulation for self-gravitating collisional systems with a new\n  SIMD instruction set extension to the x86 architecture, Advanced Vector\n  eXtensions Abstract: We present a high-performance N-body code for self-gravitating collisional\nsystems accelerated with the aid of a new SIMD instruction set extension of the\nx86 architecture: Advanced Vector eXtensions (AVX), an enhanced version of the\nStreaming SIMD Extensions (SSE). With one processor core of Intel Core i7-2600\nprocessor (8 MB cache and 3.40 GHz) based on Sandy Bridge micro-architecture,\nwe implemented a fourth-order Hermite scheme with individual timestep scheme\n(Makino and Aarseth, 1992), and achieved the performance of 20 giga floating\npoint number operations per second (GFLOPS) for double-precision accuracy,\nwhich is two times and five times higher than that of the previously developed\ncode implemented with the SSE instructions (Nitadori et al., 2006b), and that\nof a code implemented without any explicit use of SIMD instructions with the\nsame processor core, respectively. We have parallelized the code by using\nso-called NINJA scheme (Nitadori et al., 2006a), and achieved 90 GFLOPS for a\nsystem containing more than N = 8192 particles with 8 MPI processes on four\ncores. We expect to achieve about 10 tera FLOPS (TFLOPS) for a self-gravitating\ncollisional system with N 105 on massively parallel systems with at most 800\ncores with Sandy Bridge micro-architecture. This performance will be comparable\nto that of Graphic Processing Unit (GPU) cluster systems, such as the one with\nabout 200 Tesla C1070 GPUs (Spurzem et al., 2010). This paper offers an\nalternative to collisional N-body simulations with GRAPEs and GPUs. \n\n"}
{"id": "1104.3676", "contents": "Title: Reflection in Seyfert Galaxies and the Unified Model of AGN Abstract: We present a deep study of the average hard X-ray spectra of Seyfert\ngalaxies. We analyzed all public INTEGRAL IBIS/ISGRI data available on all the\n165 Seyfert galaxies detected at z<0.2. Our final sample consists of 44 Seyfert\n1's, 29 Seyfert 1.5's, 78 Seyfert 2's, and 14 Narrow Line Seyfert 1's. We\nderived the average hard X-ray spectrum of each subsample in the 17-250keV\nenergy range. All classes of Seyfert galaxies show on average the same nuclear\ncontinuum, as foreseen by the zeroth order unified model, with a cut-off energy\nof Ec>200keV, and a photon index of Gamma ~1.8. Compton-thin Seyfert 2's show a\nreflection component stronger than Seyfert 1's and Seyfert 1.5's. Most of this\nreflection is due to mildly obscured (10^23 cm^-2 < NH < 10^24 cm^-2) Seyfert\n2's, which have a significantly stronger reflection component\n(R=2.2^{+4.5}_{-1.1}) than Seyfert 1's (R<=0.4), Seyfert 1.5's (R<= 0.4) and\nlightly obscured (NH < 10^23 cm^-2) Seyfert 2's (R<=0.5). This cannot be\nexplained easily by the unified model. The absorber/reflector in mildly\nobscured Seyfert 2's might cover a large fraction of the X-ray source, and have\nclumps of Compton-thick material. The large reflection found in the spectrum of\nmildly obscured Seyfert 2's reduces the amount of Compton-thick objects needed\nto explain the peak of the cosmic X-ray background. Our results are consistent\nwith the fraction of Compton-thick sources being ~10%. The spectra of Seyfert\n2's with and without polarized broad lines do not show significant differences,\nthe only difference between the two samples being the higher hard X-ray and\nbolometric luminosity of Seyfert 2's with polarized broad lines. The average\nhard X-ray spectrum of Narrow line Seyfert 1's is steeper than those of Seyfert\n1's and Seyfert 1.5's, probably due to a lower energy of the cutoff. \n\n"}
{"id": "1104.5248", "contents": "Title: The 2010 May Flaring Episode of Cygnus X-3 in Radio, X-Rays, and\n  {\\gamma}-Rays Abstract: In 2009, Cygnus X-3 (Cyg X-3) became the first microquasar to be detected in\nthe GeV {\\gamma}-ray regime, via the satellites Fermi and AGILE. The addition\nof this new band to the observational toolbox holds promise for building a more\ndetailed understanding of the relativistic jets of this and other systems. We\npresent a rich dataset of radio, hard and soft X-ray, and {\\gamma}-ray\nobservations of Cyg X-3 made during a flaring episode in 2010 May. We detect a\n~3-d softening and recovery of the X-ray emission, followed almost immediately\nby a ~1-Jy radio flare at 15 GHz, followed by a 4.3{\\sigma} {\\gamma}-ray flare\n(E > 100 MeV) ~1.5 d later. The radio sampling is sparse, but we use archival\ndata to argue that it is unlikely the {\\gamma}-ray flare was followed by any\nsignificant unobserved radio flares. In this case, the sequencing of the\nobserved events is difficult to explain in a model in which the {\\gamma}-ray\nemission is due to inverse Compton scattering of the companion star's radiation\nfield. Our observations suggest that other mechanisms may also be responsible\nfor {\\gamma}-ray emission from Cyg X-3. \n\n"}
{"id": "1105.0090", "contents": "Title: Density profile slope in Dwarfs and environment Abstract: In the present paper, we study how the dark matter density profiles of dwarfs\ngalaxies in the mass range $10^8-10^{10} M_{\\odot}$ are modified by the\ninteraction of the dwarf in study with the neighboring structures, and by\nchanging baryon fraction in dwarfs. As already shown in Del Popolo (2009), the\nslope of density profile of inner halos flattens with decreasing halo mass and\nthe profile is well approximated by a Burkert's profile. The analysis shows\nthat dwarfs who suffered a smaller tidal torquing (consequently having smaller\nangular momentum) are characterized by steeper profiles with respect to dwarfs\nsubject to higher torque, and similarly dwarfs having a smaller baryons\nfraction have also steeper profiles than those having a larger baryon fraction.\nIn the case tidal torquing is shut down and baryons are not present, the\ndensity profile is very well approximated by an Einasto profile, similarly to\ndwarfs obtained in dissipationless N-body simulations. We then apply the result\nof the previous analysis to the dark matter halo rotation curves of three\ndifferent dwarfs, namely NGC 2976, known to have a flat inner core, NGC 5949\nhaving a profile intermediate between a cored and a cuspy one, and NGC 5963\nhaving a cuspy profile. After calculating baryon fraction, which is $\\simeq\n0.1$ for the three galaxies, we fitted the rotation curves changing the value\nof angular momentum. NGC 2976, has an higher value of ordered angular momentum\n($\\lambda \\simeq 0.04$) with respect to NGC 5949 ($\\lambda \\simeq 0.025$) and\nin the case of NGC 5963 the very steep profile can be obtained with a low value\nof $\\lambda$ ($\\lambda \\simeq 0.02$) and also decreasing the value of the\nrandom angular momentum. In the case of NGC 2976 tidal interaction with M81\ncould have also influenced the inner part of the density profile. \n\n"}
{"id": "1105.1251", "contents": "Title: Measurement of night sky brightness in southern Australia Abstract: Night sky brightness is a major source of noise both for Cherenkov telescopes\nas well as for wide-angle Cherenkov detectors. Therefore, it is important to\nknow the level of night sky brightness at potential sites for future\nexperiments. The measurements of night sky brightness presented here were\ncarried out at Fowler's Gap, a research station in New South Wales, Australia,\nwhich is a potential site for the proposed TenTen Cherenkov telescope system\nand the planned wide-angle Cherenkov detector system HiSCORE.\n  A portable instrument was developed and measurements of the night sky\nbrightness were taken in February and August 2010. Brightness levels were\nmeasured for a range of different sky regions and in various spectral bands.\n  The night sky brightness in the relevant wavelength regime for\nphotomultipliers was found to be at the same level as measured in similar\ncampaigns at the established Cherenkov telescope sites of Khomas, Namibia, and\nat La Palma. The brightness of dark regions in the sky is about 2 x 10^12\nphotons/(s sr m^2) between 300 nm and 650 nm, and up to four times brighter in\nbright regions of the sky towards the galactic plane. The brightness in V band\nis 21.6 magnitudes per arcsec^2 in the dark regions. All brightness levels are\naveraged over the field of view of the instrument of about 1.3 x 10^(-3) sr.\n  The spectrum of the night sky brightness was found to be dominated by longer\nwavelengths, which allows to apply filters to separate the night sky brightness\nfrom the blue Cherenkov light. The possible gain in the signal to noise ratio\nwas found to be up to 1.2, assuming an ideal low-pass filter. \n\n"}
{"id": "1105.5991", "contents": "Title: Towards the automatic estimation of gravitational lenses' time delays Abstract: Estimation of time delays from a noisy and gapped data is one of the simplest\ndata analysis problems in astronomy by its formulation. But as history of real\nexperiments show, the work with observed data sets can be quite complex and\nevolved. By analysing in detail previous attempts to build delay estimation\nalgorithms we try to develop an automatic and robust procedure to perform the\ntask. To evaluate and compare different variants of the algorithms we use real\nobserved data sets which have been objects of past controversies. In this way\nwe hope to select the methods and procedures which have highest probability to\nsucceed in complex situations. As a result of our investigations we propose an\nestimation procedure which can be used as a method of choice in large\nphotometric experiments. We can not claim that proposed methodology works with\nany reasonably well sampled input data set. But we hope that the steps taken\nare in correct direction and developed software is truly useful for practising\nastronomers. \n\n"}
{"id": "1106.0065", "contents": "Title: Tests of Modified Gravity with Dwarf Galaxies Abstract: In modified gravity theories that seek to explain cosmic acceleration, dwarf\ngalaxies in low density environments can be subject to enhanced forces. The\nclass of scalar-tensor theories, which includes f(R) gravity, predict such a\nforce enhancement (massive galaxies like the Milky Way can evade it through a\nscreening mechanism that protects the interior of the galaxy from this \"fifth\"\nforce). We study observable deviations from GR in the disks of late-type dwarf\ngalaxies moving under gravity. The fifth-force acts on the dark matter and HI\ngas disk, but not on the stellar disk owing to the self-screening of main\nsequence stars. We find four distinct observable effects in such disk galaxies:\n1. A displacement of the stellar disk from the HI disk. 2. Warping of the\nstellar disk along the direction of the external force. 3. Enhancement of the\nrotation curve measured from the HI gas compared to that of the stellar disk.\n4. Asymmetry in the rotation curve of the stellar disk. We estimate that the\nspatial effects can be up to 1 kpc and the rotation velocity effects about 10\nkm/s in infalling dwarf galaxies. Such deviations are measurable: we expect\nthat with a careful analysis of a sample of nearby dwarf galaxies one can\nimprove astrophysical constraints on gravity theories by over three orders of\nmagnitude, and even solar system constraints by one order of magnitude. Thus\neffective tests of gravity along the lines suggested by Hui et al (2009) and\nJain (2011) can be carried out with low-redshift galaxies, though care must be\nexercised in understanding possible complications from astrophysical effects. \n\n"}
{"id": "1106.0698", "contents": "Title: The data reduction pipeline for the Hi-GAL survey Abstract: We present the data reduction pipeline for the Hi-GAL survey. Hi-GAL is a key\nproject of the Herschel satellite which is mapping the inner part of the\nGalactic plane (|l| <= 70\\cdot and |b| <= 1\\cdot), using 2 PACS and 3 SPIRE\nfrequency bands, from 70{\\mu}m to 500{\\mu}m. Our pipeline relies only partially\non the Herschel Interactive Standard Environment (HIPE) and features several\nnewly developed routines to perform data reduction, including accurate data\nculling, noise estimation and minimum variance map-making, the latter performed\nwith the ROMAGAL algorithm, a deep modification of the ROMA code already tested\non cosmological surveys. We discuss in depth the properties of the Hi-GAL\nScience Demonstration Phase (SDP) data. \n\n"}
{"id": "1106.1443", "contents": "Title: X-ray Spectral Constraints for z~2 Massive Galaxies: The Identification\n  of Reflection-Dominated Active Galactic Nuclei Abstract: We use the 4Ms CDF-S survey to place direct X-ray constraints on the ubiquity\nof z~2 heavily obscured AGNs in K<22 BzK galaxies. Forty seven of the 222 BzK\ngalaxies in the central region of the CDF-S are detected at X-ray energies, 11\nof which have hard X-ray spectral slopes (Gamma<1) indicating the presence of\nheavily obscured AGN activity. The other 36 X-ray detected BzK galaxies appear\nto be relatively unobscured AGNs and starburst galaxies; we use X-ray\nvariability analyses over a rest-frame baseline of ~3 years to further confirm\nthe presence of AGN activity in many of these systems. The majority (7 out of\n11) of the heavily obscured AGNs have excess IR emission over that expected\nfrom star formation (termed \"IR-excess galaxies\"). However, we find that X-ray\ndetected heavily obscured AGNs only comprise ~25% of the IR-excess galaxy\npopulation, which is otherwise composed of relatively unobscured AGNs and\nstarburst galaxies. We find that the typical X-ray spectrum of the heavily\nobscured AGNs is better characterized by a pure reflection model than an\nabsorbed power-law model, suggesting extreme Compton-thick absorption in some\nsystems. We verify this result by producing a composite rest-frame 2-20 keV\nspectrum, which has a similar shape as a reflection-dominated X-ray spectrum\nand reveals an emission feature at rest-frame energy ~6.4 keV, likely to be due\nto Fe K. These heavily obscured AGNs are likely to be the distant analogs of\nthe reflection-dominated AGNs recently identified at z~0 with >10 keV\nobservatories. On the basis of these analyses we estimate the space density for\ntypical (intrinsic X-ray luminosities of L_X>1E43 erg/s) heavily obscured and\nCompton-thick AGNs at z~2. Our space-density constraints are conservative lower\nlimits but they are already consistent with the range of predictions from X-ray\nbackground models. \n\n"}
{"id": "1106.2020", "contents": "Title: SCORPIO at the 6-m telescope: current state and perspectivies for\n  spectroscopy of galactic and extragalactic objects Abstract: A significant part of observations by Russian 6-m telescope is carried out\nusing SCORPIO multi-mode focal reducer. A lot of scientific data have been\ncollected using observations in direct imaging, slit spectroscopy and\nFabry-Perot interferometry modes during the past ten years. Some results of\nthese observations are considered in this review. We are also present a short\ndescription of a new generation instrument named SCORPIO-2. \n\n"}
{"id": "1106.2039", "contents": "Title: Shedding Light on the Galaxy Luminosity Function Abstract: From as early as the 1930s, astronomers have tried to quantify the\nstatistical nature of the evolution and large-scale structure of galaxies by\nstudying their luminosity distribution as a function of redshift - known as the\ngalaxy luminosity function (LF). Accurately constructing the LF remains a\npopular and yet tricky pursuit in modern observational cosmology where the\npresence of observational selection effects due to e.g. detection thresholds in\napparent magnitude, colour, surface brightness or some combination thereof can\nrender any given galaxy survey incomplete and thus introduce bias into the LF.\n  Over the last seventy years there have been numerous sophisticated\nstatistical approaches devised to tackle these issues; all have advantages --\nbut not one is perfect. This review takes a broad historical look at the key\nstatistical tools that have been developed over this period, discussing their\nrelative merits and highlighting any significant extensions and modifications.\nIn addition, the more generalised methods that have emerged within the last few\nyears are examined. These methods propose a more rigorous statistical framework\nwithin which to determine the LF compared to some of the more traditional\nmethods. I also look at how photometric redshift estimations are being\nincorporated into the LF methodology as well as considering the construction of\nbivariate LFs. Finally, I review the ongoing development of completeness\nestimators which test some of the fundamental assumptions going into LF\nestimators and can be powerful probes of any residual systematic effects\ninherent magnitude-redshift data. \n\n"}
{"id": "1106.2262", "contents": "Title: An equation of state for dark matter Abstract: Dark matter, believed to be present in many galaxies, is interpreted as a\nhydrodynamical system in interaction with the gravitational field and nothing\nelse. An equation of state determines the mass distribution and the associated\ngravitational field. Conversely, the gravitational field can be inferred from\nobservation of orbital velocities of stars in the Milky Way, in a first\napproximation in which the field is mainly due to the distribution of dark\nmatter. In this approximation, the equation of state is determined by the\ngravitational field via the equations of motion.\n  The resulting equation of state is a simple expression that accounts for the\nmain features of the galactic rotation curve over 6 orders of magnitude. \n\n"}
{"id": "1106.4546", "contents": "Title: Dynamical Dark Matter: I. Theoretical Overview Abstract: In this paper, we propose a new framework for dark-matter physics. Rather\nthan focus on one or more stable dark-matter particles, we instead consider a\nmulti-component framework in which the dark matter of the universe comprises a\nvast ensemble of interacting fields with a variety of different masses,\nmixings, and abundances. Moreover, rather than impose stability for each field\nindividually, we ensure the phenomenological viability of such a scenario by\nrequiring that those states with larger masses and Standard-Model decay widths\nhave correspondingly smaller relic abundances, and vice versa. In other words,\ndark-matter stability is not an absolute requirement in such a framework, but\nis balanced against abundance. This leads to a highly dynamical scenario in\nwhich cosmological quantities such as Omega_{CDM} experience non-trivial\ntime-dependences beyond those associated with the expansion of the universe.\nAlthough it may seem difficult to arrange an ensemble of states which have the\nrequired decay widths and relic abundances, we present one particular example\nin which this balancing act occurs naturally: an infinite tower of Kaluza-Klein\n(KK) states living in the bulk of large extra spacetime dimensions. Remarkably,\nthis remains true even if the stability of the KK tower itself is entirely\nunprotected. Thus theories with large extra dimensions --- and by extension,\ncertain limits of string theory --- naturally give rise to dynamical dark\nmatter. Such scenarios also generically give rise to a rich set of collider and\nastrophysical phenomena which transcend those usually associated with dark\nmatter. \n\n"}
{"id": "1106.5491", "contents": "Title: Automating Discovery and Classification of Transients and Variable Stars\n  in the Synoptic Survey Era Abstract: The rate of image acquisition in modern synoptic imaging surveys has already\nbegun to outpace the feasibility of keeping astronomers in the real-time\ndiscovery and classification loop. Here we present the inner workings of a\nframework, based on machine-learning algorithms, that captures expert training\nand ground-truth knowledge about the variable and transient sky to automate 1)\nthe process of discovery on image differences and, 2) the generation of\npreliminary science-type classifications of discovered sources. Since follow-up\nresources for extracting novel science from fast-changing transients are\nprecious, self-calibrating classification probabilities must be couched in\nterms of efficiencies for discovery and purity of the samples generated. We\nestimate the purity and efficiency in identifying real sources with a two-epoch\nimage-difference discovery algorithm for the Palomar Transient Factory (PTF)\nsurvey. Once given a source discovery, using machine-learned classification\ntrained on PTF data, we distinguish between transients and variable stars with\na 3.8% overall error rate (with 1.7% errors for imaging within the Sloan\nDigital Sky Survey footprint). At >96% classification efficiency, the samples\nachieve 90% purity. Initial classifications are shown to rely primarily on\ncontext-based features, determined from the data itself and external archival\ndatabases. In the ~one year since autonomous operations, this discovery and\nclassification framework has led to several significant science results, from\noutbursting young stars to subluminous Type IIP supernovae to candidate tidal\ndisruption events. We discuss future directions of this approach, including the\npossible roles of crowdsourcing and the scalability of machine learning to\nfuture surveys such a the Large Synoptical Survey Telescope (LSST). \n\n"}
{"id": "1107.1295", "contents": "Title: Studies of a three-stage dark matter and neutrino observatory based on\n  multi-ton combinations of liquid xenon and liquid argon detectors Abstract: We study a three stage dark matter and neutrino observatory based on\nmulti-ton two-phase liquid Xe and Ar detectors with sufficiently low\nbackgrounds to be sensitive to WIMP dark matter interaction cross sections down\nto 10E-47 cm^2, and to provide both identification and two independent\nmeasurements of the WIMP mass through the use of the two target elements in a\n5:1 mass ratio, giving an expected similarity of event numbers. The same\ndetection systems will also allow measurement of the pp solar neutrino\nspectrum, the neutrino flux and temperature from a Galactic supernova, and\nneutrinoless double beta decay of 136Xe to the lifetime level of 10E27 - 10E28\ny corresponding to the Majorana mass predicted from current neutrino\noscillation data. The proposed scheme would be operated in three stages G2, G3,\nG4, beginning with fiducial masses 1-ton Xe + 5-ton Ar (G2), progressing to\n10-ton Xe + 50-ton Ar (G3) then, dependent on results and performance of the\nlatter, expandable to 100-ton Xe + 500-ton Ar (G4). This method of scale-up\noffers the advantage of utilizing the Ar vessel and ancillary systems of one\nstage for the Xe detector of the succeeding stage, requiring only one new\ndetector vessel at each stage. Simulations show the feasibility of reducing or\nrejecting all external and internal background levels to a level <1 events per\nyear for each succeeding mass level, by utilizing an increasing outer thickness\nof target material as self-shielding. The system would, with increasing mass\nscale, become increasingly sensitive to annual signal modulation, the agreement\nof Xe and Ar results confirming the Galactic origin of the signal. Dark matter\nsensitivities for spin-dependent and inelastic interactions are also included,\nand we conclude with a discussion of possible further gains from the use of\nXe/Ar mixtures. \n\n"}
{"id": "1107.1728", "contents": "Title: Systematic Bias in 2MASS Galaxy Photometry Abstract: We report the discovery of a serious bias in galaxy photometry reported in\nthe 2MASS Extended Source Catalog (Jarrett et al. 2000). Due to an undetermined\nflaw in the 2MASS surface photometry routines, isophotal and total magnitudes\ncalculated by their methods underestimate the luminosity of galaxies from 10%\nto 40%. This is found to be due to incorrectly determined scalelengths and\nisophotal radii, which are used to define the aperture sizes for Kron and total\nfluxes. While 2MASS metric aperture luminosities are correct (and, thus, colors\nbased on those apertures), comparison to other filters (e.g. optical) based on\ntotal magnitudes will produce erroneous results. We use our own galaxy\nphotometry package (ARCHANGEL) to determine correct total magnitudes and colors\nusing the same 2MASS images, but with a more refined surface brightness\nreduction scheme. Our resulting colors, and color-magnitude relation, are more\nin line with model expectations and previous pointed observations. \n\n"}
{"id": "1107.2122", "contents": "Title: Searching for Saturn's Dust Swarm: Limits on the size distribution of\n  Irregular Satellites from km to micron sizes Abstract: We describe a search for dust created in collisions between the Saturnian\nirregular satellites using archival \\emph{Spitzer} MIPS observations. Although\nwe detected a degree scale Saturn-centric excess that might be attributed to an\nirregular satellite dust cloud, we attribute it to the far-field wings of the\nPSF due to nearby Saturn. The Spitzer PSF is poorly characterised at such\nradial distances, and we expect PSF characterisation to be the main issue for\nfuture observations that aim to detect such dust. The observations place an\nupper limit on the level of dust in the outer reaches of the Saturnian system,\nand constrain how the size distribution extrapolates from the smallest known\n(few km) size irregulars down to micron-size dust. Because the size\ndistribution is indicative of the strength properties of irregulars, we show\nhow our derived upper limit implies irregular satellite strengths more akin to\ncomets than asteroids. This conclusion is consistent with their presumed\ncapture from the outer regions of the Solar System. \n\n"}
{"id": "1107.4962", "contents": "Title: Isocurvature perturbations in extra radiation Abstract: Recent cosmological observations, including measurements of the CMB\nanisotropy and the primordial helium abundance, indicate the existence of an\nextra radiation component in the Universe beyond the standard three neutrino\nspecies. In this paper we explore the possibility that the extra radiation has\nisocurvatrue fluctuations. A general formalism to evaluate isocurvature\nperturbations in the extra radiation is provided in the mixed inflaton-curvaton\nsystem, where the extra radiation is produced by the decay of both scalar\nfields. We also derive constraints on the abundance of the extra radiation and\nthe amount of its isocurvature perturbation. Current observational data favors\nthe existence of an extra radiation component, but does not indicate its having\nisocurvature perturbation. These constraints are applied to some particle\nphysics motivated models. If future observations detect isocurvature\nperturbations in the extra radiation, it will give us a hint to the origin of\nthe extra radiation. \n\n"}
{"id": "1107.5040", "contents": "Title: Precision Spectrophotometry at the Level of 0.1% Abstract: Accurate relative spectrophotometry is critical for many science\napplications. Small wavelength scale residuals in the flux calibration can\nsignificantly impact the measurements of weak emission and absorption features\nin the spectra. Using Sloan Digital Sky Survey data, we demonstrate that the\naverage spectra of carefully selected red-sequence galaxies can be used as a\nspectroscopic standard to improve the relative spectrophotometry precision to\n0.1% on small wavelength scales (from a few to hundreds of Angstroms). We\nachieve this precision by comparing stacked spectra across tiny redshift\nintervals. The redshift intervals must be small enough that any systematic\nstellar population evolution is minimized and less than the spectrophotometric\nuncertainty. This purely empirical technique does not require any theoretical\nknowledge of true galaxy spectra. It can be applied to all large spectroscopic\ngalaxy redshift surveys that sample a large number of galaxies in a uniform\npopulation. \n\n"}
{"id": "1107.5165", "contents": "Title: Multi-wavelength extragalactic surveys and the role of MeerKAT and SALT Abstract: In these proceedings I discuss a range of surveys that are currently underway\nat optical, near-infrared and far-infrared wavelengths that have large\ncomponents accessible to both the Southern African Large Telescope (SALT) and\nthe Meer Karoo Array Telescope (MeerKAT). Particular attention is paid to the\nsurveys currently underway with ESO's VISTA telescope, which will provide the\nideal data from which to select targets for SALT spectroscopy whilst also\nproviding the necessary depth and photometric redshift accuracy to trace the\nuJy radio population, found through the proposed MeerKAT surveys. Such surveys\nwill lead to an accurate picture of evolution of star-formation and accretion\nactivity traced at radio wavelengths. Furthermore, SALT spectroscopy could play\na crucial role in following up Herschel surveys with its large collecting area\nand blue sensitivity which occupies a niche in instrumentation on 8- and 10-m\nclass telescopes. \n\n"}
{"id": "1109.0027", "contents": "Title: The Arecibo Legacy Fast ALFA Survey: The alpha.40 HI Source Catalog, its\n  Characteristics and their Impact on the Derivation of the HI Mass Function Abstract: We present a current catalog of 21 cm HI line sources extracted from the\nArecibo Legacy Fast Arecibo L-band Feed Array (ALFALFA) survey over ~2800\nsquare degrees of sky: the alpha.40 catalog. Covering 40% of the final survey\narea, the alpha.40 catalog contains 15855 sources in the regions 07h30m < R.A.\n< 16h30m, +04 deg < Dec. < +16 deg and +24 deg < Dec. < +28 deg and 22h < R.A.\n< 03h, +14 deg < Dec. < +16 deg and +24 deg < Dec. < +32 deg. Of those, 15041\nare certainly extragalactic, yielding a source density of 5.3 galaxies per\nsquare degree, a factor of 29 improvement over the catalog extracted from the\nHI Parkes All Sky Survey. In addition to the source centroid positions, HI line\nflux densities, recessional velocities and line widths, the catalog includes\nthe coordinates of the most probable optical counterpart of each HI line\ndetection, and a separate compilation provides a crossmatch to identifications\ngiven in the photometric and spectroscopic catalogs associated with the Sloan\nDigital Sky Survey Data Release 7. Fewer than 2% of the extragalactic HI line\nsources cannot be identified with a feasible optical counterpart; some of those\nmay be rare OH megamasers at 0.16 < z < 0.25. A detailed analysis is presented\nof the completeness, width dependent sensitivity function and bias inherent in\nthe current alpha.40 catalog. The impact of survey selection, distance errors,\ncurrent volume coverage and local large scale structure on the derivation of\nthe HI mass function is assessed. While alpha.40 does not yet provide a\ncompletely representative sampling of cosmological volume, derivations of the\nHI mass function using future data releases from ALFALFA will further improve\nboth statistical and systematic uncertainties. \n\n"}
{"id": "1109.0735", "contents": "Title: Daily Modulation of the Dark Matter Signal in Crystalline Detectors Abstract: The channeling effect in crystals refers to the orientation dependence of\ncharged ion penetration in crystals. In direct dark matter crystalline\ndetectors, a channeled ion recoiling after a collision with a WIMP gives all\nits energy to electrons. Thus channeling increases the ionization or\nscintillation signal expected from a WIMP. Channeling is a directional effect\nwhich depends on the velocity distribution of WIMPs in the dark halo of our\nGalaxy and could lead to a daily modulation of the signal. I will present\nestimates of the expected amplitude of the daily modulation in direct dark\nmatter detectors, both due to channeling and just due to the rotational\nvelocity of the Earth around itself. \n\n"}
{"id": "1109.3147", "contents": "Title: The First Stars: Mass Growth Under Protostellar Feedback Abstract: We perform three-dimensional cosmological simulations to examine the growth\nof metal-free, Population III (Pop III) stars under radiative feedback. We\nbegin our simulation at z=100 and trace the evolution of gas and dark matter\nuntil the formation of the first minihalo. We then follow the collapse of the\ngas within the minihalo up to densities of n = 10^12 cm^-3, at which point we\nreplace the high-density particles with a sink particle to represent the\ngrowing protostar. We model the effect of Lyman-Werner (LW) radiation emitted\nby the protostar, and employ a ray-tracing scheme to follow the growth of the\nsurrounding H II region over the next 5000 yr. We find that a disk assembles\naround the first protostar, and that radiative feedback will not prevent\nfurther fragmentation of the disk to form multiple Pop III stars. Ionization of\nneutral hydrogen and photodissociation of H_2 by LW radiation leads to heating\nof the dense gas to several thousand Kelvin, and this warm region expands\noutward at the gas sound speed. Once the extent of this warm region becomes\nequivalent to the size of the disk, the disk mass declines while the accretion\nrate onto the protostars is reduced by an order of magnitude. This occurs when\nthe largest sink has grown to ~ 20 M_sol while the second sink has grown to 7\nM_sol, and we estimate the main sink will approach an asymptotic value of ~ 30\nM_sol by the time it reaches the main sequence. Our simulation thus indicates\nthat the most likely outcome is a massive Pop III binary. However, we simulate\nonly one minihalo, and the statistical variation between minihaloes may be\nsubstantial. If Pop III stars were typically unable to grow to more than a few\ntens of solar masses, this would have important consequences for the occurence\nof pair-instability supernovae in the early Universe as well as the Pop III\nchemical signature in the oldest stars observable today. \n\n"}
{"id": "1109.3207", "contents": "Title: GalMass: A Smartphone Application for Estimating Galaxy Masses Abstract: This note documents the methods used by the smartphone application,\n\"GalMass,\" which has been released on the Android Market. GalMass estimates the\nhalo virial mass (Mvir), stellar mass (Mstar), gas mass (Mgas), and galaxy gas\nfraction of a central galaxy as a function of redshift (z<2), with any one of\nthe above masses as an input parameter. In order to convert between Mvir and\nMstar (in either direction), GalMass uses fitting functions that approximate\nthe abundance matching models of either Conroy & Wechsler (2009), Moster et al.\n(2010), or Behroozi et al. (2010). GalMass uses a a semi-empirical fit to\nobserved galaxy gas fractions to convert between Mstar and Mgas, as outlined in\nStewart et al. (2009). \n\n"}
{"id": "1109.4104", "contents": "Title: VOGCLUSTERS: an example of DAME web application Abstract: We present the alpha release of the VOGCLUSTERS web application, specialized\nfor data and text mining on globular clusters. It is one of the web2.0\ntechnology based services of Data Mining & Exploration (DAME) Program, devoted\nto mine and explore heterogeneous information related to globular clusters\ndata. \n\n"}
{"id": "1109.4258", "contents": "Title: Opportunity to Test non-Newtonian Gravity Using Interferometric Sensors\n  with Dynamic Gravity Field Generators Abstract: We present an experimental opportunity for the future to measure possible\nviolations to Newton's 1/r^2 law in the 0.1-10 meter range using Dynamic\ngravity Field Generators (DFG) and taking advantage of the exceptional\nsensitivity of modern interferometric techniques. The placement of a DFG in\nproximity to one of the interferometer's suspended test masses generates a\nchange in the local gravitational field that can be measured at a high signal\nto noise ratio. The use of multiple DFGs in a null experiment configuration\nallows to test composition independent non-Newtonian gravity significantly\nbeyond the present limits. Advanced and third-generation gravitational-wave\ndetectors are representing the state-of-the-art in interferometric distance\nmeasurement today, therefore we illustrate the method through their sensitivity\nto emphasize the possible scientific reach. Nevertheless, it is expected that\ndue to the technical details of gravitational-wave detectors, DFGs shall likely\nrequire dedicated custom configured interferometry. However, the sensitivity\nmeasure we derive is a solid baseline indicating that it is feasible to\nconsider probing orders of magnitude into the pristine parameter well beyond\nthe present experimental limits significantly cutting into the theoretical\nparameter space. \n\n"}
{"id": "1109.6038", "contents": "Title: Large-Scale High-Lundquist Number Reduced MHD Simulations of the Solar\n  Corona Using GPU Accelerated Machines Abstract: We have recently carried out a computational campaign to investigate a model\nof coronal heating in three-dimensions using reduced magnetohydrodynamics\n(RMHD). Our code is built on a conventional scheme using the pseudo-spectral\nmethod, and is parallelized using MPI. The current investigation requires very\nlong time integrations using high Lundquist numbers, where the formation of\nvery fine current layers challenge the resolutions achievable even on massively\nparallel machines. We present here results of a port to Nvidia CUDA (Compute\nUnified Device Architecture) for hardware acceleration using graphics\nprocessing units (GPUs). In addition to a brief discussion of our general\nstrategy, we will report code performance on several machines which span a\nvariety of hardware configurations and capabilities. These include a desktop\nworkstation with commodity hardware, a dedicated research workstation equipped\nwith four Nvidia C2050 GPUs, as well as several large-scale GPU accelerated\ndistributed memory machines: Lincoln/NCSA, Dirac/NERSC, and Keeneland/NICS. \n\n"}
{"id": "1109.6096", "contents": "Title: The Design and Performance of IceCube DeepCore Abstract: The IceCube neutrino observatory in operation at the South Pole, Antarctica,\ncomprises three distinct components: a large buried array for ultrahigh energy\nneutrino detection, a surface air shower array, and a new buried component\ncalled DeepCore. DeepCore was designed to lower the IceCube neutrino energy\nthreshold by over an order of magnitude, to energies as low as about 10 GeV.\nDeepCore is situated primarily 2100 m below the surface of the icecap at the\nSouth Pole, at the bottom center of the existing IceCube array, and began\ntaking physics data in May 2010. Its location takes advantage of the\nexceptionally clear ice at those depths and allows it to use the surrounding\nIceCube detector as a highly efficient active veto against the principal\nbackground of downward-going muons produced in cosmic-ray air showers. DeepCore\nhas a module density roughly five times higher than that of the standard\nIceCube array, and uses photomultiplier tubes with a new photocathode featuring\na quantum efficiency about 35% higher than standard IceCube PMTs. Taken\ntogether, these features of DeepCore will increase IceCube's sensitivity to\nneutrinos from WIMP dark matter annihilations, atmospheric neutrino\noscillations, galactic supernova neutrinos, and point sources of neutrinos in\nthe northern and southern skies. In this paper we describe the design and\ninitial performance of DeepCore. \n\n"}
{"id": "1109.6668", "contents": "Title: Design and tests of the hard X-ray polarimeter X-Calibur Abstract: X-ray polarimetry promises to give qualitatively new information about\nhigh-energy astrophysical sources, such as binary black hole systems,\nmicro-quasars, active galactic nuclei, and gamma-ray bursts. We designed, built\nand tested a hard X-ray polarimeter X-Calibur to be used in the focal plane of\nthe InFOCuS grazing incidence hard X-ray telescope. X-Calibur combines a low-Z\nCompton scatterer with a CZT detector assembly to measure the polarization of\n10-80 keV X-rays making use of the fact that polarized photons Compton scatter\npreferentially perpendicular to the electric field orientation. X-Calibur\nachieves a high detection efficiency of order unity. \n\n"}
{"id": "1110.0222", "contents": "Title: The DRIFT Dark Matter Experiments Abstract: The current status of the DRIFT (Directional Recoil Identification From\nTracks) experiment at Boulby Mine is presented, including the latest limits on\nthe WIMP spin-dependent cross-section from 1.5 kg days of running with a\nmixture of CS2 and CF4. Planned upgrades to DRIFT IId are detailed, along with\nongoing work towards DRIFT III, which aims to be the world's first 10 m3-scale\ndirectional Dark Matter detector. \n\n"}
{"id": "1110.1694", "contents": "Title: Shrinking the Quadratic Estimator Abstract: We study a regression characterization for the quadratic estimator of weak\nlensing, developed by Hu and Okamoto (2001,2002), for cosmic microwave\nbackground observations. This characterization motivates a modification of the\nquadratic estimator by an adaptive Wiener filter which uses the robust Bayesian\ntechniques described in Strawderman (1971) and Berger (1980). This technique\nrequires the user to propose a fiducial model for the spectral density of the\nunknown lensing potential but the resulting estimator is developed to be robust\nto misspecification of this model. The role of the fiducial spectral density is\nto give the estimator superior statistical performance in a \"neighborhood of\nthe fiducial model\" while controlling the statistical errors when the fiducial\nspectral density is drastically wrong. Our estimate also highlights some\nadvantages provided by a Bayesian analysis of the quadratic estimator. \n\n"}
{"id": "1110.2865", "contents": "Title: Cosmology with space-based gravitational-wave detectors --- dark energy\n  and primordial gravitational waves --- Abstract: Proposed space-based gravitational-wave (GW) detectors such as DECIGO and BBO\nwill detect ~10^6 neutron-star (NS) binaries and determine the luminosity\ndistances to the binaries with high precision. Combining the luminosity\ndistances with cosmologically-induced phase corrections on the GWs,\ncosmological expansion out to high redshift can be measured without the\nredshift determinations of host galaxies by electromagnetic observation and be\na unique probe for dark energy. On the other hand, such a NS-binary foreground\nshould be subtracted to detect primordial GWs produced during inflation. Thus,\nthe constraining power on dark energy and the detectability of the primordial\ngravitational waves strongly depend on the detector sensitivity and are in\nclose relation with one another. In this paper, we investigate the constraints\non the equation of state of dark energy with future space-based GW detectors\nwith/without identifying the redshifts of host galaxies. We also study the\nsensitivity to the primordial GWs, properly dealing with the residual of the NS\nbinary foreground. Based on the results, we discuss the detector sensitivity\nrequired to achieve the forementioned targeted study of cosmology. \n\n"}
{"id": "1110.3444", "contents": "Title: Simulation of the Directional Dark Matter Detector (D3) and Directional\n  Neutron Observer (DiNO) Abstract: Preliminary simulation and optimization studies of the Directional Dark\nMatter Detector and the Directional Neutron Observer are presented. These\nstudies show that the neutron interaction with the gas-target in these\ndetectors is treated correctly by GEANT4 and that by lowering the pressure, the\nsensitivity to low-mass WIMP candidates is increased. The use of negative ion\ndrift might allow us to search the WIMP mass region suggested by the results of\nthe non-directional experiments DAMA/LIBRA, CoGeNT and CRESST-II. \n\n"}
{"id": "1110.3801", "contents": "Title: Rest-frame UV--Optically Selected Galaxies at 2.3<z<3.5: Searching for\n  Dusty Star-forming and Passively-Evolving Galaxies Abstract: A new set of color selection criteria (VJL) analogous with the BzK method is\ndesigned to select both star-forming galaxies (SFGs) and passively-evolving\ngalaxies (PEGs) at 2.3<z<3.5 by using rest-frame UV--optical (V-J vs. J-L)\ncolors. The criteria are thoroughly tested with theoretical stellar population\nsynthesis models and real galaxies with spectroscopic redshifts to evaluate\ntheir efficiency and contamination. We apply the well-tested VJL criteria to\nthe HST/WFC3 Early Release Science field and study the physical properties of\nselected galaxies. The redshift distribution of selected SFGs peaks at z~2.7,\nslightly lower than that of Lyman Break Galaxies at z~3. Comparing the observed\nmid-infrared fluxes of selected galaxies with the prediction of pure stellar\nemission, we find that our VJL method is effective at selecting massive dusty\nSFGs that are missed by the Lyman Break Technique. About half of the star\nformation in massive (M_{star}>10^{10}M_{Sun}) galaxies at 2.3<z<3.5 is\ncontributed by dusty (extinction E(B-V)>0.4) SFGs, which however, only account\nfor ~20% of the number density of massive SFGs. We also use the mid-infrared\nfluxes to clean our PEG sample, and find that galaxy size can be used as a\nsecondary criterion to effectively eliminate the contamination of dusty SFGs.\nThe redshift distribution of the cleaned PEG sample peaks at z~2.5. We find 6\nPEG candidates at z>3 and discuss possible methods to distinguish them from\ndusty contamination. We conclude that at least part of our candidates are real\nPEGs at z~3, implying that this type of galaxies began to form their stars at\nz>5. We measure the integrated stellar mass density of PEGs at z~2.5 and set\nconstraints on it at z>3. We find that the integrated stellar mass density\ngrows by at least about factor of 10 in 1 Gyr at 3<z<5 and by another factor of\n10 in next 3.5 Gyr (1<z<3). \n\n"}
{"id": "1110.4170", "contents": "Title: Deep UV Luminosity Functions at the Infall Region of the Coma Cluster Abstract: We have used deep GALEX observations at the infall region of the Coma cluster\nto measure the faintest UV luminosity functions (LFs) presented for a rich\ngalaxy cluster thus far. The Coma UV LFs are measured to M_UV = -10.5 in the\nGALEX FUV and NUV bands, or 3.5 mag fainter than previous studies, and reach\nthe dwarf early-type galaxy population in Coma for the first time. The\nSchechter faint-end slopes (alpha = -1.39 in both GALEX bands) are shallower\nthan reported in previous Coma UV LF studies owing to a flatter LF at faint\nmagnitudes. A Gaussian-plus-Schechter model provides a slightly better\nparametrization of the UV LFs resulting in a faint-end slope of ~ -1.15 in both\nGALEX bands. The two-component model gives faint-end slopes shallower than -1\n(a turnover) for the LFs constructed separately for passive and star forming\ngalaxies. The UV LFs for star forming galaxies show a turnover at M_UV ~ -14\nowing to a deficit of dwarf star forming galaxies in Coma with stellar masses\nbelow M*=10^8 Msun. A similar turnover is identified in recent UV LFs measured\nfor the Virgo cluster suggesting this may be a common feature of local galaxy\nclusters, whereas the field UV LFs continue to rise at faint magnitudes. We did\nnot identify an excess of passive galaxies as would be expected if the missing\ndwarf star forming galaxies were quenched inside the cluster. In fact, the LFs\nfor both dwarf passive and star forming galaxies show the same turnover at\nfaint magnitudes. We discuss the possible origin of the missing dwarf star\nforming galaxies in Coma and their expected properties based on comparisons to\nlocal field galaxies. \n\n"}
{"id": "1110.4874", "contents": "Title: Wavemoth -- Fast spherical harmonic transforms by butterfly matrix\n  compression Abstract: We present Wavemoth, an experimental open source code for computing scalar\nspherical harmonic transforms (SHTs). Such transforms are ubiquitous in\nastronomical data analysis. Our code performs substantially better than\nexisting publicly available codes due to improvements on two fronts. First, the\ncomputational core is made more efficient by using small amounts of precomputed\ndata, as well as paying attention to CPU instruction pipelining and cache\nusage. Second, Wavemoth makes use of a fast and numerically stable algorithm\nbased on compressing a set of linear operators in a precomputation step. The\nresulting SHT scales as O(L^2 (log L)^2) for the resolution range of practical\ninterest, where L denotes the spherical harmonic truncation degree. For low and\nmedium-range resolutions, Wavemoth tends to be twice as fast as libpsht, which\nis the current state of the art implementation for the HEALPix grid. At the\nresolution of the Planck experiment, L ~ 4000, Wavemoth is between three and\nsix times faster than libpsht, depending on the computer architecture and the\nrequired precision. Due to the experimental nature of the project, only\nspherical harmonic synthesis is currently supported, although adding support or\nspherical harmonic analysis should be trivial. \n\n"}
{"id": "1110.5026", "contents": "Title: The missing matter problem: from the dark matter search to alternative\n  hypotheses Abstract: Dark matter is among the most important open problems in both astrophysics\nand particle physics. We review the status of art of dark matter search at\ntheoretical and experimental level discussing also alternative hypotheses. \n\n"}
{"id": "1110.5360", "contents": "Title: New Zealand involvement in Radio Astronomical VLBI Image Processing Abstract: With the establishment of the AUT University 12m radio telescope at\nWarkworth, New Zealand has now become a part of the international Very Long\nBaseline Interferometry (VLBI) community. A major product of VLBI observations\nare images in the radio domain of astronomical objects such as Active Galactic\nNuclei (AGN). Using large geographical separations between radio antennas, very\nhigh angular resolution can be achieved. Detailed images can be created using\nthe technique of VLBI Earth Rotation Aperture Synthesis. We review the current\nprocess of VLBI radio imaging. In addition we model VLBI configurations using\nthe Warkworth telescope, AuScope (a new array of three 12m antennas in\nAustralia) and the Australian Square Kilometre Array Pathfinder (ASKAP) array\ncurrently under construction in Western Australia, and discuss how the\nconfiguration of these arrays affects the quality of images. Recent imaging\nresults that demonstrate the modeled improvements from inclusion of the AUT and\nfirst ASKAP telescope in the Australian Long Baseline Array (LBA) are\npresented. \n\n"}
{"id": "1110.5634", "contents": "Title: Conceptual Problems in Cosmology Abstract: In this essay a critical review of present conceptual problems in current\ncosmology is provided from a more philosophical point of view. In essence, a\ndigression on how could philosophy help cosmologists in what is strictly their\nfundamental endeavor is presented. We start by recalling some examples of\nenduring confrontations among philosophers and physicists on what could be\ncontributed by the formers to the day-time striving of the second ones. Then, a\nshort review of the standard model Friedmann-Lema\\^itre-Robertson-Walter (FLRW)\nof cosmology is given. It seems apparent that cosmology is living a golden age\nwith the advent of observations of high precision. Nonetheless, a critical\nrevisiting of the direction in which it should go on appears also needed, for\nmisconcepts like \"quantum backgrounds for cosmological classical settings\" and\n\"quantum gravity unification\" have not been properly constructed up-to-date.\nThus, knowledge-building in cosmology, more than in any other field, should\nbegin with visions of the reality, then taking technical form whenever concepts\nand relations inbetween are translated into a mathematical structure. It is\nmandatory, therefore, that the meaning of such concepts be the same for all\ncosmologists, and that any relationship among all them be tested both logically\nas well as mathematically. In other words, the notorius feature of\nimprobability of our universe, as is well-known, assures to cosmologists a\npriviledged degree of freedom for formulating interpretations and theories.\nHowever, at the same time, it demands for their formulations and conclusions to\nbe considered in the light of data taken from astrophysical observations. \n\n"}
{"id": "1110.6178", "contents": "Title: Parameter Estimation with BEAMS in the presence of biases and\n  correlations Abstract: The original formulation of BEAMS - Bayesian Estimation Applied to Multiple\nSpecies - showed how to use a dataset contaminated by points of multiple\nunderlying types to perform unbiased parameter estimation. An example is\ncosmological parameter estimation from a photometric supernova sample\ncontaminated by unknown Type Ibc and II supernovae. Where other methods require\ndata cuts to increase purity, BEAMS uses all of the data points in conjunction\nwith their probabilities of being each type. Here we extend the BEAMS formalism\nto allow for correlations between the data and the type probabilities of the\nobjects as can occur in realistic cases. We show with simple simulations that\nthis extension can be crucial, providing a 50% reduction in parameter\nestimation variance when such correlations do exist. We then go on to perform\ntests to quantify the importance of the type probabilities, one of which\nillustrates the effect of biasing the probabilities in various ways. Finally, a\ngeneral presentation of the selection bias problem is given, and discussed in\nthe context of future photometric supernova surveys and BEAMS, which lead to\nspecific recommendations for future supernova surveys. \n\n"}
{"id": "1111.1566", "contents": "Title: MIMAC: A micro-tpc matrix project for directional detection of dark\n  matter Abstract: Directional detection of non-baryonic DarkMatter is a promising search\nstrategy for discriminating WIMP events from background ones. This strategy\nrequires both a measurement of the recoil energy down to a few keV and 3D\nreconstruction of tracks down to a few mm. The MIMAC project, based on a\nmicro-TPC matrix, filled with CF4 and CHF3 is being developed. The first\nresults of a chamber prototype of this matrix, on low energy nuclear recoils\n(1H and 19F) obtained with mono-energetic neutron fields are presented. The\ndiscovery potential of this search strategy is illustrated by a realistic case\naccessible to MIMAC. \n\n"}
{"id": "1111.1701", "contents": "Title: Gravitational Waves and Time Domain Astronomy Abstract: The gravitational wave window onto the universe will open in roughly five\nyears, when Advanced LIGO and Virgo achieve the first detections of high\nfrequency gravitational waves, most likely coming from compact binary mergers.\nElectromagnetic follow-up of these triggers, using radio, optical, and high\nenergy telescopes, promises exciting opportunities in multi-messenger time\ndomain astronomy. In the next decade, space-based observations of low frequency\ngravitational waves from massive black hole mergers, and their electromagnetic\ncounterparts, will open up further vistas for discovery. This two-part workshop\nat featured brief presentations and stimulating discussions on the challenges\nand opportunities presented by gravitational wave astronomy. Highlights from\nthe workshop, with the emphasis on strategies for electromagnetic follow-up,\nare presented in this report. \n\n"}
{"id": "1111.1998", "contents": "Title: FITSH -- a software package for image processing Abstract: In this paper we describe the main features of the software package named\nFITSH, intended to provide a standalone environment for analysis of data\nacquired by imaging astronomical detectors. The package provides utilities both\nfor the full pipeline of subsequent related data processing steps (incl. image\ncalibration, astrometry, source identification, photometry, differential\nanalysis, low-level arithmetic operations, multiple image combinations, spatial\ntransformations and interpolations, etc.) and for aiding the interpretation of\nthe (mainly photometric and/or astrometric) results. The package also features\na consistent implementation of photometry based on image subtraction, point\nspread function fitting and aperture photometry and provides easy-to-use\ninterfaces for comparisons and for picking the most suitable method for a\nparticular problem. This set of utilities found in the package are built on the\ntop of the commonly used UNIX/POSIX shells (hence the name of the package),\ntherefore both frequently used and well-documented tools for such environments\ncan be exploited and managing massive amount of data is rather convenient. \n\n"}
{"id": "1111.2051", "contents": "Title: Two Populations of X-ray Pulsars Produced by Two Types of Supernovae Abstract: Two types of supernova are thought to produce the overwhelming majority of\nneutron stars in the Universe. The first type, iron-core collapse supernovae,\noccurs when a high-mass star develops a degenerate iron core that exceeds the\nChandrasekhar limit. The second type, electron-capture supernovae, is\nassociated with the collapse of a lower-mass oxygen-neon-magnesium core as it\nloses pressure support owing to the sudden capture of electrons by neon and/or\nmagnesium nuclei. It has hitherto been impossible to identify the two distinct\nfamilies of neutron stars produced in these formation channels. Here we report\nthat a large, well-known class of neutron-star-hosting X-ray pulsars is\nactually composed of two distinct sub-populations with different characteristic\nspin periods, orbital periods and orbital eccentricities. This class, the\nBe/X-ray binaries, contains neutron stars that accrete material from a more\nmassive companion star. The two sub-populations are most probably associated\nwith the two distinct types of neutron-star-forming supernovae, with\nelectron-capture supernovae preferentially producing system with short spin\nperiod, short orbital periods and low eccentricity. Intriguingly, the split\nbetween the two sub-populations is clearest in the distribution of the\nlogarithm of spin period, a result that had not been predicted and which still\nremains to be explained. \n\n"}
{"id": "1111.5615", "contents": "Title: Dark Matter Assimilation into the Baryon Asymmetry Abstract: Pure singlets are typically disfavored as dark matter candidates, since they\ngenerically have a thermal relic abundance larger than the observed value. In\nthis paper, we propose a new dark matter mechanism called \"assimilation\", which\ntakes advantage of the baryon asymmetry of the universe to generate the correct\nrelic abundance of singlet dark matter. Through assimilation, dark matter\nitself is efficiently destroyed, but dark matter number is stored in new\nquasi-stable heavy states which carry the baryon asymmetry. The subsequent\nannihilation and late-time decay of these heavy states yields (symmetric) dark\nmatter as well as (asymmetric) standard model baryons. We study in detail the\ncase of pure bino dark matter by augmenting the minimal supersymmetric standard\nmodel with vector-like chiral multiplets. In the parameter range where this\nmechanism is effective, the LHC can discover long-lived charged particles which\nwere responsible for assimilating dark matter. \n\n"}
{"id": "1111.5621", "contents": "Title: The Flat Transmission Spectrum of the Super-Earth GJ1214b from Wide\n  Field Camera 3 on the Hubble Space Telescope Abstract: Capitalizing on the observational advantage offered by its tiny M dwarf host,\nwe present HST/WFC3 grism measurements of the transmission spectrum of the\nsuper-Earth exoplanet GJ1214b. These are the first published WFC3 observations\nof a transiting exoplanet atmosphere. After correcting for a ramp-like\ninstrumental systematic, we achieve nearly photon-limited precision in these\nobservations, finding the transmission spectrum of GJ1214b to be flat between\n1.1 and 1.7 microns. Inconsistent with a cloud-free solar composition\natmosphere at 8.2 sigma, the measured achromatic transit depth most likely\nimplies a large mean molecular weight for GJ1214b's outer envelope. A dense\natmosphere rules out bulk compositions for GJ1214b that explain its large\nradius by the presence of a very low density gas layer surrounding the planet.\nHigh-altitude clouds can alternatively explain the flat transmission spectrum,\nbut they would need to be optically thick up to 10 mbar or consist of particles\nwith a range of sizes approaching 1 micron in diameter. \n\n"}
{"id": "1111.6865", "contents": "Title: Scaling relations between numerical simulations and physical systems\n  they represent Abstract: The dynamical equations describing the evolution of a physical system\ngenerally have a freedom in the choice of units, where different choices\ncorrespond to different physical systems that are described by the same\nequations. Since there are three basic physical units, of mass, length and\ntime, there are up to three free parameters in such a rescaling of the units,\n$N_f \\leq 3$. In Newtonian hydrodynamics, e.g., there are indeed usually three\nfree parameters, $N_f = 3$. If, however, the dynamical equations contain a\nuniversal dimensional constant, such as the speed of light in vacuum $c$ or the\ngravitational constant $G$, then the requirement that its value remains the\nsame imposes a constraint on the rescaling, which reduces its number of free\nparameters by one, to $N_f = 2$. This is the case, for example, in\nmagneto-hydrodynamics (MHD) or special relativistic hydrodynamics, where $c$\nappears in the dynamical equations and forces the length and time units to\nscale by the same factor, or in Newtonian gravity where the gravitational\nconstant $G$ appears in the equations. More generally, when there are $N_{udc}$\nindependent (in terms of their units) universal dimensional constants, then the\nnumber of free parameters is $N_f = max(0,3-N_{udc})$. When both gravity and\nrelativity are included, there is only one free parameter ($N_f = 1$, as both\n$G$ and $c$ appear in the equations so that $N_{udc} = 2$), and the units of\nmass, length and time must all scale by the same factor. The explicit\nrescalings for different types of systems are discussed and summarized here.\nSuch rescalings of the units also hold for discrete particles, e.g. in N-body\nor particle in cell simulations. They are very useful when numerically\ninvestigating a large parameter space or when attempting to fit particular\nexperimental results, by significantly reducing the required number of\nsimulations. \n\n"}
{"id": "1111.7215", "contents": "Title: Thermal infrared properties of classical and type II Cepheids\n  Diffraction limited 10 microns imaging with VLT/VISIR Abstract: We present new thermal IR photometry and spectral energy distributions (SEDs)\nof eight classical Cepheids (type I) and three type II Cepheids, using VISIR\nthermal IR photometric measurements, supplemented with literature data. We used\nthe BURST mode of the instrument to get diffraction-limited images at 8.59,\n11.25 and 11.85 {\\mu}m. The SEDs show a IR excess at wavelengths longer than\n10{\\mu}m in ten of the eleven stars. We tentatively attribute these excesses to\ncircumstellar emission created by mass loss from the Cepheids. With some\nhypotheses for the dust composition, we estimated a total mass of the envelope\nranging from 10-10 to 10-8 M\\odot. We also detect a spatially extended emission\naround AX Cir, X Sgr, W Sgr, Y Oph and U Car while we do not resolve the\ncircumstellar envelope (CSE) for the other stars. The averaged circumstellar\nenvelope brightnesses relative to the stellar photosphere are {\\alpha}(AX Cir)\n= 13.8\\pm2.5%, {\\alpha}(X Sgr) = 7.9\\pm1.4%, {\\alpha}(W Sgr) = 3.8\\pm0.6%,\n{\\alpha}(Y Oph) = 15.1\\pm1.4% and {\\alpha}(U Car) = 16.3\\pm1.4% at 8.59 {\\mu}m.\nWith this study, we extend the number of classical Cepheids with detected CSEs\nfrom 9 to 14, confirming that at least a large fraction of all Cepheids are\nexperiencing significant mass loss. The presence of these CSEs may also impact\nthe future use of Cepheids as standard candles at near and thermal infrared\nwavelengths. \n\n"}
{"id": "1112.1565", "contents": "Title: Searching for Gravitational Waves with a Geostationary Interferometer Abstract: We analyze the sensitivities of a geostationary gravitational wave\ninterferometer mission operating in the sub-Hertz band. Because of its smaller\narmlength, in the lower part of its accessible frequency band ($10^{-4} - 2\n\\times 10^{-2}$ Hz) our proposed Earth-orbiting detector will be less\nsensitive, by a factor of about seventy, than the Laser Interferometer Space\nAntenna (LISA) mission. In the higher part of its band instead ($2 \\times\n10^{-2} - 10$ Hz), our proposed interferometer will have the capability of\nobserving super-massive black holes (SMBHs) with masses smaller than $\\sim\n10^{6}$ M$_{\\odot}$. With good event rates for these systems, a geostationary\ninterferometer will be able to accurately probe the astrophysical scenarios\nthat account for their formation. \n\n"}
{"id": "1112.3057", "contents": "Title: The Impact of the Spectral Response of an Achromatic Half-Wave Plate on\n  the Measurement of the Cosmic Microwave Background Polarization Abstract: We study the impact of the spectral dependence of the linear polarization\nrotation induced by an achromatic half-wave plate on measurements of cosmic\nmicrowave background polarization in the presence of astrophysical foregrounds.\nWe focus on the systematic effects induced on the measurement of inflationary\ngravitational waves by uncertainties in the polarization and spectral index of\nGalactic dust. We find that for the experimental configuration and noise levels\nof the balloon-borne EBEX experiment, which has three frequency bands centered\nat 150, 250, and 410 GHz, a crude dust subtraction process mitigates systematic\neffects to below detectable levels for 10% polarized dust and tensor to scalar\nratio of as low as r = 0.01. We also study the impact of uncertainties in the\nspectral response of the instrument. With a top-hat model of the spectral\nresponse for each band, characterized by band-center and band-width, and with\nthe same crude dust subtraction process, we find that these parameters need to\nbe determined to within 1 and 0.8 GHz at 150 GHz; 9 and 2.0 GHz at 250 GHz; and\n20 and 14 GHz at 410 GHz, respectively. The approach presented in this paper is\napplicable to other optical elements that exhibit polarization rotation as a\nfunction of frequency. \n\n"}
{"id": "1112.3652", "contents": "Title: Understanding better (some) astronomical data using Bayesian methods Abstract: Current analysis of astronomical data are confronted with the daunting task\nof modeling the awkward features of astronomical data, among which\nheteroscedastic (point-dependent) errors, intrinsic scatter, non-ignorable data\ncollection (selection effects), data structure, non-uniform populations (often\ncalled Malmquist bias), non-Gaussian data, and upper/lower limits. This chapter\nshows, by examples, how modeling all these features using Bayesian methods. In\nshort, one just need to formalize, using maths, the logical link between the\ninvolved quantities, how the data arise and what we already known on the\nquantities we want to study. The posterior probability distribution summarizes\nwhat we known on the studied quantities after the data, and we should not be\nafraid about their actual numerical computation, because it is left to\n(special) Monte Carlo programs such as JAGS. As examples, we show how to\npredict the mass of a new object disposing of a calibrating sample, how to\nconstraint cosmological parameters from supernovae data and how to check if the\nfitted data are in tension with the adopted fitting model. Examples are given\nwith their coding. These examples can be easily used as template for completely\ndifferent analysis, on totally unrelated astronomical objects, requiring to\nmodel the same awkward data features. \n\n"}
{"id": "1112.4217", "contents": "Title: The Cosmic Infrared Background Experiment (CIBER): The Low Resolution\n  Spectrometer Abstract: Absolute spectrophotometric measurements of diffuse radiation at 1 \\mu m to 2\n\\mu m are crucial to our understanding of the radiative content of the Universe\nfrom nucleosynthesis since the epoch of reionization, the composition and\nstructure of the Zodiacal dust cloud in our solar system, and the diffuse\ngalactic light arising from starlight scattered by interstellar dust. The Low\nResolution Spectrometer (LRS) on the rocket-borne Cosmic Infrared Background\nExperiment (CIBER) is a \\lambda / \\Delta \\lambda \\sim 15-30 absolute\nspectrophotometer designed to make precision measurements of the absolute\nnear-infrared sky brightness between 0.75 \\mu m < \\lambda < 2.1 \\mu m. This\npaper presents the optical, mechanical and electronic design of the LRS, as\nwell as the ground testing, characterization and calibration measurements\nundertaken before flight to verify its performance. The LRS is shown to work to\nspecifications, achieving the necessary optical and sensitivity performance. We\ndescribe our understanding and control of sources of systematic error for\nabsolute photometry of the near-infrared extragalactic background light. \n\n"}
{"id": "1112.4482", "contents": "Title: High-Performance Astrophysical Simulations and Analysis with Python Abstract: The usage of the high-level scripting language Python has enabled new\nmechanisms for data interrogation, discovery and visualization of scientific\ndata. We present yt, an open source, community-developed astrophysical analysis\nand visualization toolkit for data generated by high-performance computing\n(HPC) simulations of astrophysical phenomena. Through a separation of\nresponsibilities in the underlying Python code, yt allows data generated by\nincompatible, and sometimes even directly competing, astrophysical simulation\nplatforms to be analyzed in a consistent manner, focusing on physically\nrelevant quantities rather than quantities native to astrophysical simulation\ncodes. We present on its mechanisms for data access, capabilities for\nMPI-parallel analysis, and its implementation as an in situ analysis and\nvisualization tool. \n\n"}
{"id": "1112.4488", "contents": "Title: Combining High-scale Inflation with Low-energy SUSY Abstract: We propose a general scenario for moduli stabilization where low-energy\nsupersymmetry can be accommodated with a high scale of inflation. The key\ningredient is that the stabilization of the modulus field during and after\ninflation is not associated with a single, common scale, but relies on two\ndifferent mechanisms. We illustrate this general scenario in a simple example,\nwhere during inflation the modulus is stabilized with a large mass by a Kahler\npotential coupling to the field which provides the inflationary vacuum energy\nvia its F-term. After inflation, the modulus is stabilized, for instance, by a\nKKLT superpotential. \n\n"}
{"id": "1112.5094", "contents": "Title: LOFAR: opening a new window on low frequency radio astronomy Abstract: This contribution reports on the status of LOFAR (the LOw Frequency ARray) in\nits ongoing commissioning phase. The purpose is to illustrate the progress that\nis being made, often on a daily basis, and the potential of this new\ninstrument, which is the first \"next-generation\" radio telescope. Utilizing a\nnovel phased-array design, LOFAR is optimized for the largely unexplored low\nfrequency range: 10 - 240 MHz. The construction of LOFAR in the Netherlands is\nalmost complete and 8 international stations have already been deployed as\nwell. The wide field-of-view and multi-beam capabilities, in combination with\nsub-milliJansky sensitivity at arcsec (and sub-arcsec) resolution, are\nunprecedented at these frequencies. With the commissioning of LOFAR in full\nswing, we report some of the initial results, in particular those coming from\nthe testing of imaging and pulsar modes. \n\n"}
{"id": "1201.0926", "contents": "Title: BINGO: A code for the efficient computation of the scalar bi-spectrum Abstract: We present a new and accurate Fortran code, the BI-spectra and\nNon-Gaussianity Operator (BINGO), for the efficient numerical computation of\nthe scalar bi-spectrum and the non-Gaussianity parameter f_{NL} in single field\ninflationary models involving the canonical scalar field. The code can\ncalculate all the different contributions to the bi-spectrum and the parameter\nf_{NL} for an arbitrary triangular configuration of the wavevectors. Focusing\nfirstly on the equilateral limit, we illustrate the accuracy of BINGO by\ncomparing the results from the code with the spectral dependence of the\nbi-spectrum expected in power law inflation. Then, considering an arbitrary\ntriangular configuration, we contrast the numerical results with the analytical\nexpression available in the slow roll limit, for, say, the case of the\nconventional quadratic potential. Considering a non-trivial scenario involving\ndeviations from slow roll, we compare the results from the code with the\nanalytical results that have recently been obtained in the case of the\nStarobinsky model in the equilateral limit. As an immediate application, we\nutilize BINGO to examine of the power of the non-Gaussianity parameter f_{NL}\nto discriminate between various inflationary models that admit departures from\nslow roll and lead to similar features in the scalar power spectrum. We close\nwith a summary and discussion on the implications of the results we obtain. \n\n"}
{"id": "1201.1533", "contents": "Title: Merging Galaxy Clusters: Offset Between the Sunyaev-Zel'dovich Effect\n  and X-ray Peaks Abstract: Galaxy clusters, the most massive collapsed structures, have been routinely\nused to determine cosmological parameters. When using clusters for cosmology,\nthe crucial assumption is that they are relaxed. However, subarcminute\nresolution Sunyaev-Zel'dovich (SZ) effect images compared with high resolution\nX-ray images of some clusters show significant offsets between the two peaks.\nWe have carried out self-consistent N-body/hydrodynamical simulations of\nmerging galaxy clusters using FLASH to study these offsets quantitatively. We\nhave found that significant displacements result between the SZ and X-ray peaks\nfor large relative velocities for all masses used in our simulations as long as\nthe impact parameters were about 100-250 kpc. Our results suggest that the SZ\npeak coincides with the peak in the pressure times the line-of-sight\ncharacteristic length and not the pressure maximum (as it would for clusters in\nequilibrium). The peak in the X-ray emission, as expected, coincides with the\ndensity maximum of the main cluster. As a consequence, the morphology of the SZ\nsignal and therefore the offset between the SZ and X-ray peaks change with\nviewing angle. As an application, we compare the morphologies of our simulated\nimages to observed SZ and X-ray images and mass surface densities derived from\nweak lensing observations of the merging galaxy cluster CL0152-1357. We find\nthat a large relative velocity of 4800 km/s is necessary to explain these\nobservations. We conclude that an analysis of the morphologies of\nmulti-frequency observations of merging clusters can be used to put meaningful\nconstraints on the initial parameters of the progenitors. \n\n"}
{"id": "1201.2178", "contents": "Title: The Dust & Gas Properties of M83 Abstract: We examine the dust and gas properties of the nearby, barred galaxy M83,\nwhich is part of the Very Nearby Galaxy Survey. Using images from the PACS and\nSPIRE instruments of Herschel, we examine the dust temperature and dust mass\nsurface density distribution. We find that the nuclear, bar and spiral arm\nregions exhibit higher dust temperatures and masses compared to interarm\nregions. However, the distribution of dust temperature and mass are not\nspatially coincident. Assuming a trailing spiral structure, the dust\ntemperature peaks in the spiral arms lie ahead of the dust surface density\npeaks. The dust mass surface density correlates well with the distribution of\nmolecular gas as traced by CO (J=3-2) images (JCMT) and the star formation rate\nas traced by H?2 with a correction for obscured star formation using 24 micron\nemission. Using HI images from THINGS to trace the atomic gas component, we\nmake total gas mass surface density maps and calculate the gas-to-dust ratio.\nWe find a mean gas-to-dust ratio of 84 \\pm 4 with higher values in the inner\nregion assuming a constant CO-to-H2 conversion factor. We also examine the\ngas-to-dust ratio using CO-to-H2 conversion factor that varies with\nmetallicity. \n\n"}
{"id": "1201.3238", "contents": "Title: Science performance of Gaia, ESA's space-astrometry mission Abstract: Gaia is the next astrometry mission of the European Space Agency (ESA),\nfollowing up on the success of the Hipparcos mission. With a focal plane\ncontaining 106 CCD detectors, Gaia will survey the entire sky and repeatedly\nobserve the brightest 1,000 million objects, down to 20th magnitude, during its\n5-year lifetime. Gaia's science data comprises absolute astrometry, broad-band\nphotometry, and low-resolution spectro-photometry. Spectroscopic data with a\nresolving power of 11,500 will be obtained for the brightest 150 million\nsources, down to 17th magnitude. The thermo-mechanical stability of the\nspacecraft, combined with the selection of the L2 Lissajous point of the\nSun-Earth/Moon system for operations, allows stellar parallaxes to be measured\nwith standard errors less than 10 micro-arcsecond (muas) for stars brighter\nthan 12th magnitude, 25 muas for stars at 15th magnitude, and 300 muas at\nmagnitude 20. Photometric standard errors are in the milli-magnitude regime.\nThe spectroscopic data allows the measurement of radial velocities with errors\nof 15 km/s at magnitude 17. Gaia's primary science goal is to unravel the\nkinematical, dynamical, and chemical structure and evolution of the Milky Way.\nIn addition, Gaia's data will touch many other areas of science, e.g., stellar\nphysics, solar-system bodies, fundamental physics, and exo-planets. The Gaia\nspacecraft is currently in the qualification and production phase. With a\nlaunch in 2013, the final catalogue is expected in 2021. The science community\nin Europe, organised in the Data Processing and Analysis Consortium (DPAC), is\nresponsible for the processing of the data. \n\n"}
{"id": "1201.3280", "contents": "Title: Photometric and Spectroscopic Studies of Massive Binaries in the Large\n  Magellanic Cloud. I. Introduction and Orbits for Two Detached Systems:\n  Evidence for a Mass Discrepancy? Abstract: The stellar mass-luminosity relation is poorly constrained by observations\nfor high mass stars. We describe our program to find eclipsing massive binaries\nin the Magellanic Clouds using photometry of regions rich in massive stars, and\nour spectroscopic follow-up to obtain radial velocities and orbits. Our\nphotometric campaign identified 48 early-type periodic variables, of which only\n15 (31%) were found as part of the microlensing surveys. Spectroscopy is now\ncomplete for 17 of these systems, and in this paper we present analysis of the\nfirst two, LMC 172231 and ST2-28, simple detached systems of late-type O dwarfs\nof relatively modest masses. Our orbit analysis yields very precise masses (2%)\nand we use tomography to separate the components and determine effective\ntemperatures by model fitting, necessary for determining accurate (0.05-0.07\ndex) bolometric luminosities in combination with the light-curve analysis. Our\napproach allows more precise comparisons with evolutionary theory than\npreviously possible. To our considerable surprise, we find a small, but\nsignificant, systematic discrepancy: all of the stars are slightly\nunder-massive, by typically 11% (or over-luminous by 0.2 dex) compared to that\npredicted by the evolutionary models. We examine our approach for systematic\nproblems, but find no satisfactory explanation. The discrepancy is in the same\nsense as the long-discussed and elusive discrepancy between the masses measured\nfrom stellar atmosphere analysis with the stellar evolutionary models, and\nmight suggest that either increased rotation or convective overshooting is\nneeded in the models. Additional systems will be discussed in future papers of\nthis series, and will hopefully confirm or refute this trend. \n\n"}
{"id": "1201.3994", "contents": "Title: Comparison of potential ASKAP HI survey source finders Abstract: The large size of the ASKAP HI surveys DINGO and WALLABY necessitates\nautomated 3D source finding. A performance difference of a few percent\ncorresponds to a significant number of galaxies being detected or undetected.\nAs such, the performance of the automated source finding is of paramount\nimportance to both of these surveys. We have analysed the performance of\nvarious source finders to determine which will allow us to meet our survey\ngoals during the DINGO and WALLABY design studies. Here we present a comparison\nof the performance of five different methods of automated source finding. These\nsource finders are Duchamp, the Gamma-finder, CNHI, a 2D-1D Wavelet\nReconstruction and S+C finder, a sigma clipping method. Each source finder was\napplied on the same three-dimensional data cubes containing (a) point sources\nwith a Gaussian velocity profile and (b) spatially extended model-galaxies with\ninclinations and rotation profiles. We focus on the completeness and\nreliability of each algorithm when comparing the performance of the different\nsource finders. \n\n"}
{"id": "1201.4582", "contents": "Title: Technical aspects in dark matter investigations Abstract: Some theoretical and experimental aspects regarding the direct dark matter\nfield are mentioned. In particular some arguments, which play a relevant role\nin the evaluation of model dependent interpretations of experimental results\nand in comparisons, are shortly addressed. \n\n"}
{"id": "1201.5029", "contents": "Title: PyCOOL - a Cosmological Object-Oriented Lattice code written in Python Abstract: There are a number of different phenomena in the early universe that have to\nbe studied numerically with lattice simulations. This paper presents a graphics\nprocessing unit (GPU) accelerated Python program called PyCOOL that solves the\nevolution of scalar fields in a lattice with very precise symplectic\nintegrators. The program has been written with the intention to hit a sweet\nspot of speed, accuracy and user friendliness. This has been achieved by using\nthe Python language with the PyCUDA interface to make a program that is easy to\nadapt to different scalar field models. In this paper we derive the symplectic\ndynamics that govern the evolution of the system and then present the\nimplementation of the program in Python and PyCUDA. The functionality of the\nprogram is tested in a chaotic inflation preheating model, a single field\noscillon case and in a supersymmetric curvaton model which leads to Q-ball\nproduction. We have also compared the performance of a consumer graphics card\nto a professional Tesla compute card in these simulations. We find that the\nprogram is not only accurate but also very fast. To further increase the\nusefulness of the program we have equipped it with numerous post-processing\nfunctions that provide useful information about the cosmological model. These\ninclude various spectra and statistics of the fields. The program can be\nadditionally used to calculate the generated curvature perturbation. The\nprogram is publicly available under GNU General Public License at\nhttps://github.com/jtksai/PyCOOL . Some additional information can be found\nfrom http://www.physics.utu.fi/tiedostot/theory/particlecosmology/pycool/ . \n\n"}
{"id": "1201.6096", "contents": "Title: Electrodynamic effect of anisotropic expansions in the Universe Abstract: In the presence of anisotropic cosmic expansions at global or local scale the\nequations of electrodynamics in expanding space-time are modified and presented\nhere. A new effect should arise in regions of local anisotropic expansion in a\ncosmologically isotropic background. These regions should naturally exist,\nbeing connected with scales decoupling from the Hubble flow. Possible\nobservational consequences of this effect are suggested. In particular, I\npredict the appearance or variation of the polarization of electromagnetic\nradiation coming from or passing through these regions. This effect is\nobservable and possibly already observed in the polarization of quasars. \n\n"}
{"id": "1202.1426", "contents": "Title: Approximate Bayesian Computation for Astronomical Model Analysis: A Case\n  Study in Galaxy Demographics and Morphological Transformation at High\n  Redshift Abstract: \"Approximate Bayesian Computation\" (ABC) represents a powerful methodology\nfor the analysis of complex stochastic systems for which the likelihood of the\nobserved data under an arbitrary set of input parameters may be entirely\nintractable-the latter condition rendering useless the standard machinery of\ntractable likelihood-based, Bayesian statistical inference (e.g. conventional\nMarkov Chain Monte Carlo simulation; MCMC). In this article we demonstrate the\npotential of ABC for astronomical model analysis by application to a case study\nin the morphological transformation of high redshift galaxies. To this end we\ndevelop, first, a stochastic model for the competing processes of merging and\nsecular evolution in the early Universe; and second, through an ABC-based\ncomparison against the observed demographics of massive (M_gal > 10^11 M_sun)\ngalaxies (at 1.5 < z < 3) in the CANDELS/EGS dataset we derive posterior\nprobability densities for the key parameters of this model. The \"Sequential\nMonte Carlo\" (SMC) implementation of ABC exhibited herein, featuring both a\nself-generating target sequence and self-refining MCMC kernel, is amongst the\nmost efficient of contemporary approaches to this important statistical\nalgorithm. We highlight as well through our chosen case study the value of\ncareful summary statistic selection, and demonstrate two modern strategies for\nassessment and optimisation in this regard. Ultimately, our ABC analysis of the\nhigh redshift morphological mix returns tight constraints on the evolving\nmerger rate in the early Universe and favours major merging (with disc survival\nor rapid reformation) over secular evolution as the mechanism most responsible\nfor building up the first generation of bulges in early-type disks. \n\n"}
{"id": "1202.1958", "contents": "Title: The Likelihood Ratio as a tool for Radio Continuum Surveys with SKA\n  precursor telescopes Abstract: In this paper we investigate the performance of the likelihood ratio method\nas a tool for identifying optical and infrared counterparts to proposed radio\ncontinuum surveys with SKA precursor and pathfinder telescopes. We present a\ncomparison of the infrared counterparts identified by the likelihood ratio in\nthe VISTA Deep Extragalactic Observations (VIDEO) survey to radio observations\nwith 6, 10 and 15 arcsec resolution. We cross-match a deep radio catalogue\nconsisting of radio sources with peak flux density $>$ 60 $\\mu$Jy with deep\nnear-infrared data limited to $K_{\\mathrm{s}}\\lesssim$ 22.6. Comparing the\ninfrared counterparts from this procedure to those obtained when cross-matching\na set of simulated lower resolution radio catalogues indicates that degrading\nthe resolution from 6 arcsec to 10 and 15 arcsec decreases the completeness of\nthe cross-matched catalogue by approximately 3 and 7 percent respectively. When\nmatching against shallower infrared data, comparable to that achieved by the\nVISTA Hemisphere Survey, the fraction of radio sources with reliably identified\ncounterparts drops from $\\sim$89%, at $K_{\\mathrm{s}}\\lesssim$22.6, to 47% with\n$K_{\\mathrm{s}}\\lesssim$20.0. Decreasing the resolution at this shallower\ninfrared limit does not result in any further decrease in the completeness\nproduced by the likelihood ratio matching procedure. However, we note that\nradio continuum surveys with the MeerKAT and eventually the SKA, will require\nlong baselines in order to ensure that the resulting maps are not limited by\ninstrumental confusion noise. \n\n"}
{"id": "1202.1977", "contents": "Title: Recoiling black holes: electromagnetic signatures, candidates, and\n  astrophysical implications Abstract: Supermassive black holes (SMBHs) may not always reside right at the centers\nof their host galaxies. This is a prediction of numerical relativity\nsimulations, which imply that the newly formed single SMBH, after binary\ncoalescence in a galaxy merger, can receive kick velocities up to several 1000\nkm/s due to anisotropic emission of gravitational waves. Long-lived\noscillations of the SMBHs in galaxy cores, and in rare cases even SMBH\nejections from their host galaxies, are the consequence. Observationally,\naccreting recoiling SMBHs would appear as quasars spatially and/or\nkinematically off-set from their host galaxies. The presence of the \"kicks\" has\na wide range of astrophysical implications which only now are beginning to be\nexplored, including consequences for black hole and galaxy assembly at the\nepoch of structure formation, black hole feeding, and unified models of Active\nGalactic Nuclei (AGN). Here, we review the observational signatures of\nrecoiling SMBHs and the properties of the first candidates which have emerged,\nincluding follow-up studies of the candidate recoiling SMBH of\nSDSSJ092712.65+294344.0. \n\n"}
{"id": "1202.2861", "contents": "Title: Optimal filters for detecting cosmic bubble collisions Abstract: A number of well-motivated extensions of the LCDM concordance cosmological\nmodel postulate the existence of a population of sources embedded in the cosmic\nmicrowave background (CMB). One such example is the signature of cosmic bubble\ncollisions which arise in models of eternal inflation. The most unambiguous way\nto test these scenarios is to evaluate the full posterior probability\ndistribution of the global parameters defining the theory; however, a direct\nevaluation is computationally impractical on large datasets, such as those\nobtained by the Wilkinson Microwave Anisotropy Probe (WMAP) and Planck. A\nmethod to approximate the full posterior has been developed recently, which\nrequires as an input a set of candidate sources which are most likely to give\nthe largest contribution to the likelihood. In this article, we present an\nimproved algorithm for detecting candidate sources using optimal filters, and\napply it to detect candidate bubble collision signatures in WMAP 7-year\nobservations. We show both theoretically and through simulations that this\nalgorithm provides an enhancement in sensitivity over previous methods by a\nfactor of approximately two. Moreover, no other filter-based approach can\nprovide a superior enhancement of these signatures. Applying our algorithm to\nWMAP 7-year observations, we detect eight new candidate bubble collision\nsignatures for follow-up analysis. \n\n"}
{"id": "1202.3990", "contents": "Title: A Bayesian Approach to Calibrating Period-Luminosity Relations of RR\n  Lyrae Stars in the Mid-Infrared Abstract: A Bayesian approach to calibrating period-luminosity (PL) relations has\nsubstantial benefits over generic least-squares fits. In particular, the\nBayesian approach takes into account the full prior distribution of the model\nparameters, such as the a priori distances, and refits these parameters as part\nof the process of settling on the most highly-constrained final fit.\nAdditionally, the Bayesian approach can naturally ingest data from multiple\nwavebands and simultaneously fit the parameters of PL relations for each\nwaveband in a procedure that constrains the parameter posterior distributions\nso as to minimize the scatter of the final fits appropriately in all wavebands.\nHere we describe the generalized approach to Bayesian model fitting and then\nspecialize to a detailed description of applying Bayesian linear model fitting\nto the mid-infrared PL relations of RR Lyrae variable stars. For this example\napplication we quantify the improvement afforded by using a Bayesian model fit.\nWe also compare distances previously predicted in our example application to\nrecently published parallax distances measured with the Hubble Space Telescope\nand find their agreement to be a vindication of our methodology. Our intent\nwith this article is to spread awareness of the benefits and applicability of\nthis Bayesian approach and encourage future PL relation investigations to\nconsider employing this powerful analysis method. \n\n"}
{"id": "1202.4464", "contents": "Title: The Stellar Halos of Massive Elliptical Galaxies Abstract: We use the Mitchell Spectrograph (formerly VIRUS-P) on the McDonald\nObservatory 2.7m Harlan J. Smith Telescope to search for the chemical\nsignatures of massive elliptical galaxy assembly. The Mitchell Spectrograph is\nan integral-field spectrograph with a uniquely wide field of view (107x107 sq\narcsec), allowing us to achieve remarkably high signal-to-noise ratios of\n~20-70 per pixel in radial bins of 2-2.5 times the effective radii of the eight\ngalaxies in our sample. Focusing on a sample of massive elliptical galaxies\nwith stellar velocity dispersions sigma* > 150 km/s, we study the radial\ndependence in the equivalent widths (EWs) of key metal absorption lines. By\ntwice the effective radius, the Mgb EWs have dropped by ~50%, and only a weak\ncorrelation between sigma* and Mgb EW remains. The Mgb EWs at large radii are\ncomparable to those seen in the centers of elliptical galaxies that are\napproximately an order of magnitude less massive. We find that the well-known\nmetallicity gradients often observed within an effective radius continue\nsmoothly to 2.5R_e, while the abundance ratio gradients remain flat. Much like\nthe halo of the Milky Way, the stellar halos of our galaxies have low\nmetallicities and high alpha-abundance ratios, as expected for very old stars\nformed in small stellar systems. Our observations support a picture in which\nthe outer parts of massive elliptical galaxies are built by the accretion of\nmuch smaller systems whose star formation history was truncated at early times. \n\n"}
{"id": "1202.4893", "contents": "Title: Black hole perturbation in the most general scalar-tensor theory with\n  second-order field equations I: The odd-parity sector Abstract: We perform a fully relativistic analysis of odd-type linear perturbations\naround a static and spherically symmetric solution in the most general\nscalar-tensor theory with second-order field equations in four-dimensional\nspacetime. It is shown that, as in the case of general relativity, the\nquadratic action for the perturbations reduces to the one having only a single\ndynamical variable, from which concise formulas for no-ghost and no-gradient\ninstability conditions are derived. Our result is applicable to all the\ntheories of gravity with an extra scalar degree of freedom. We demonstrate how\nthe generic formulas can be applied to some particular examples such as the\nBrans-Dicke theory, $f(R)$ models, and Galileon gravity. \n\n"}
{"id": "1202.4927", "contents": "Title: Multimodality in galaxy clusters from SDSS DR8: substructure and\n  velocity distribution Abstract: We search for the presence of substructure, a non-Gaussian, asymmetrical\nvelocity distribution of galaxies, and large peculiar velocities of the main\ngalaxies in galaxy clusters with at least 50 member galaxies, drawn from the\nSDSS DR8. We employ a number of 3D, 2D, and 1D tests to analyse the\ndistribution of galaxies in clusters: 3D normal mixture modelling, the\nDressler-Shectman test, the Anderson-Darling and Shapiro-Wilk tests and others.\nWe find the peculiar velocities of the main galaxies, and use principal\ncomponent analysis to characterise our results. More than 80% of the clusters\nin our sample have substructure according to 3D normal mixture modelling, the\nDressler-Shectman (DS) test shows substructure in about 70% of the clusters.\nThe median value of the peculiar velocities of the main galaxies in clusters is\n206 km/s (41% of the rms velocity). The velocities of galaxies in more than 20%\nof the clusters show significant non-Gaussianity. While multidimensional normal\nmixture modelling is more sensitive than the DS test in resolving substructure\nin the sky distribution of cluster galaxies, the DS test determines better\nsubstructure expressed as tails in the velocity distribution of galaxies.\nRicher, larger, and more luminous clusters have larger amount of substructure\nand larger (compared to the rms velocity) peculiar velocities of the main\ngalaxies. Principal component analysis of both the substructure indicators and\nthe physical parameters of clusters shows that galaxy clusters are complicated\nobjects, the properties of which cannot be explained with a small number of\nparameters or delimited by one single test. The presence of substructure, the\nnon-Gaussian velocity distributions, as well as the large peculiar velocities\nof the main galaxies, shows that most of the clusters in our sample are\ndynamically young. \n\n"}
{"id": "1203.0012", "contents": "Title: Fast Computation of First-Order Feature-Bispectrum Corrections Abstract: Features in the inflaton potential that are traversed in much less than an\ne-fold of the expansion can produce observably large non-Gaussianity. In these\nmodels first order corrections to the curvature mode function evolution induce\neffects at second order in the slow roll parameters that are generically\ngreater than ~ 10% and can reach order unity for order unity power spectrum\nfeatures. From a complete first order expression in generalized slow-roll, we\ndevise a computationally efficient method that is as simple to evaluate as the\nleading order one and implements consistency relations in a controlled fashion.\nThis expression matches direct numerical computation for step potential models\nof the dominant bispectrum configurations to better than 1% when features are\nsmall and 10% when features are order unity. \n\n"}
{"id": "1203.0970", "contents": "Title: Infinite Shift-invariant Grouped Multi-task Learning for Gaussian\n  Processes Abstract: Multi-task learning leverages shared information among data sets to improve\nthe learning performance of individual tasks. The paper applies this framework\nfor data where each task is a phase-shifted periodic time series. In\nparticular, we develop a novel Bayesian nonparametric model capturing a mixture\nof Gaussian processes where each task is a sum of a group-specific function and\na component capturing individual variation, in addition to each task being\nphase shifted. We develop an efficient \\textsc{em} algorithm to learn the\nparameters of the model. As a special case we obtain the Gaussian mixture model\nand \\textsc{em} algorithm for phased-shifted periodic time series. Furthermore,\nwe extend the proposed model by using a Dirichlet Process prior and thereby\nleading to an infinite mixture model that is capable of doing automatic model\nselection. A Variational Bayesian approach is developed for inference in this\nmodel. Experiments in regression, classification and class discovery\ndemonstrate the performance of the proposed models using both synthetic data\nand real-world time series data from astrophysics. Our methods are particularly\nuseful when the time series are sparsely and non-synchronously sampled. \n\n"}
{"id": "1203.1576", "contents": "Title: Surface roughness interpretation of 730 kg days CRESST-II results Abstract: The analysis presented in the recent publication of the CRESST-II results\nfinds a statistically significant excess of registered events over known\nbackground contributions in the acceptance region and attributes the excess to\na possible Dark Matter signal, caused by scattering of relatively light WIMPs.\nWe propose a mechanism which explains the excess events with ion sputtering\ncaused by 206Pb recoils and alpha particles from 210Po decay, combined with\nrealistic surface roughness effects. \n\n"}
{"id": "1203.2562", "contents": "Title: The Herschel Multi-tiered Extragalactic Survey: HerMES Abstract: The Herschel Multi-tiered Extragalactic Survey, HerMES, is a legacy program\ndesigned to map a set of nested fields totalling ~380 deg^2. Fields range in\nsize from 0.01 to ~20 deg^2, using Herschel-SPIRE (at 250, 350 and 500 \\mu m),\nand Herschel-PACS (at 100 and 160 \\mu m), with an additional wider component of\n270 deg^2 with SPIRE alone. These bands cover the peak of the redshifted\nthermal spectral energy distribution from interstellar dust and thus capture\nthe re-processed optical and ultra-violet radiation from star formation that\nhas been absorbed by dust, and are critical for forming a complete\nmulti-wavelength understanding of galaxy formation and evolution.\n  The survey will detect of order 100,000 galaxies at 5\\sigma in some of the\nbest studied fields in the sky. Additionally, HerMES is closely coordinated\nwith the PACS Evolutionary Probe survey. Making maximum use of the full\nspectrum of ancillary data, from radio to X-ray wavelengths, it is designed to:\nfacilitate redshift determination; rapidly identify unusual objects; and\nunderstand the relationships between thermal emission from dust and other\nprocesses. Scientific questions HerMES will be used to answer include: the\ntotal infrared emission of galaxies; the evolution of the luminosity function;\nthe clustering properties of dusty galaxies; and the properties of populations\nof galaxies which lie below the confusion limit through lensing and statistical\ntechniques.\n  This paper defines the survey observations and data products, outlines the\nprimary scientific goals of the HerMES team, and reviews some of the early\nresults. \n\n"}
{"id": "1203.3830", "contents": "Title: Variability of Mini-BAL and BAL Outflows in Quasars Abstract: We report the results of several programs to study the variability of\nhigh-velocity (up to 0.2c) mini-\"broad absorption lines\" (mini-BALs) and BALs\nin quasar spectra, and thus to better characterize the structural and physical\nproperties of these outflows. After the report of a highly variable mini-BAL\noutflow at a speed of ~0.17c in the quasar PG0935+417, we created the first\nsystematic accounting of outflows in Sloan Digital Sky Survey (SDSS) quasar\nspectra that includes mini-BALs and extremely high velocity outflows (up to\n0.2c) to measure their frequency. Following this study, we began a monitoring\ncampaign to study the location, and dynamical and evolutionary effects of these\noutflows. This program covers a range of 0.9-3.3 years in the quasars'\nrest-frame by comparing new spectra (using facilities at the Kitt Peak National\nObservatory and MDM Observatory) with archival SDSS spectra. We find that ~57%\nof quasars with mini-BALs and BALs varied between just two observations. This\nvariability tends to occur in complex ways; however, all the variable lines\nvary in intensity and not in velocity, not finding evidence for\nacceleration/deceleration in these outflows. Due to the variations in strength,\nmini-BALs can become BALs and vice versa, suggesting they share a similar\nnature. We include as an example the discovery of the transition of a mini-BAL\ninto a BAL in the spectra of the SDSS quasar J115122+020426. \n\n"}
{"id": "1204.0975", "contents": "Title: Millimeter and sub-millimeter atmospheric performance at Dome C\n  combining radiosoundings and ATM synthetic spectra Abstract: The reliability of astronomical observations at millimeter and sub-millimeter\nwavelengths closely depends on a low vertical content of water vapor as well as\non high atmospheric emission stability. Although Concordia station at Dome C\n(Antarctica) enjoys good observing conditions in this atmospheric spectral\nwindows, as shown by preliminary site-testing campaigns at different bands and\nin, not always, time overlapped periods, a dedicated instrument able to\ncontinuously determine atmospheric performance for a wide spectral range is not\nyet planned. In the absence of such measurements, in this paper we suggest a\nsemi-empirical approach to perform an analysis of atmospheric transmission and\nemission at Dome C to compare the performance for 7 photometric bands ranging\nfrom 100 GHz to 2 THz. Radiosoundings data provided by the Routine\nMeteorological Observations (RMO) Research Project at Concordia station are\ncorrected by temperature and humidity errors and dry biases and then employed\nto feed ATM (Atmospheric Transmission at Microwaves) code to generate synthetic\nspectra in the wide spectral range from 100 GHz to 2 THz. To quantify the\natmospheric contribution in millimeter and sub-millimeter observations we are\nconsidering several photometric bands in which atmospheric quantities are\nintegrated. The observational capabilities of this site at all the selected\nspectral bands are analyzed considering monthly averaged transmissions joined\nto the corresponding fluctuations. Transmission and pwv statistics at Dome C\nderived by our semi-empirical approach are consistent with previous works. It\nis evident the decreasing of the performance at high frequencies. We propose to\nintroduce a new parameter to compare the quality of a site at different\nspectral bands, in terms of high transmission and emission stability, the Site\nPhotometric Quality Factor. \n\n"}
{"id": "1204.1762", "contents": "Title: Calibration of Nonthermal Pressure in Global Dark Matter Simulations of\n  Clusters of Galaxies Abstract: We present a new method for incorporating nonthermal pressure from bulk\nmotions of gas into an analytic model of the intracluster medium in clusters of\ngalaxies, which is based on a polytropic equation of state and hydrostatic\nequilibrium inside gravitational potential wells drawn from cosmological dark\nmatter simulations. The pressure is allowed to have thermal and nonthermal\ncomponents with different radial distributions; the overall level of nonthermal\nsupport is based on the dynamical state of the halo, such that it is lower in\nmore relaxed clusters. This level is normalized by comparison to pressure\nprofiles derived from X-ray observations, and to a high resolution\nhydrodynamical simulation. The nonthermal pressure fraction measured at r_500\nis typically in the range 10-20%, increasing with cluster mass and with\nredshift. The resulting model cluster properties are in accord with\nSunyaev-Zel'dovich (SZ) effect observations of clusters. Inclusion of\nnonthermal pressure reduces the expected angular power spectrum of SZ\nfluctuations in the microwave sky by 24%. \n\n"}
{"id": "1204.2056", "contents": "Title: New constraints on primordial black holes abundance from femtolensing of\n  gamma-ray bursts Abstract: The abundance of primordial black holes is currently significantly\nconstrained in a wide range of masses. The weakest limits are established for\nthe small mass objects, where the small intensity of the associated physical\nphenomenon provides a challenge for current experiments. We used gamma- ray\nbursts with known redshifts detected by the Fermi Gamma-ray Burst Monitor (GBM)\nto search for the femtolensing effects caused by compact objects. The lack of\nfemtolensing detection in the GBM data provides new evidence that primordial\nblack holes in the mass range 5 \\times 10^{17} - 10^{20} g do not constitute a\nmajor fraction of dark matter. \n\n"}
{"id": "1204.2570", "contents": "Title: 11-12 Gyr old White Dwarfs 30 parsecs Away Abstract: We present a detailed model atmosphere analysis of two of the oldest stars\nknown in the solar neighborhood, the high proper motion white dwarfs SDSS\nJ110217.48+411315.4 (hereafter J1102) and WD 0346+246 (hereafter WD0346). We\npresent trigonometric parallax observations of J1102, which places it at a\ndistance of only 33.7 +- 2.0 pc. Based on the state of the art model\natmospheres, optical, near-, mid-infrared photometry, and distances, we\nconstrain the temperatures, atmospheric compositions, masses, and ages for both\nstars. J1102 is an 11 Gyr old (white dwarf plus main-sequence age), 0.62 Msol\nwhite dwarf with a pure H atmosphere and Teff = 3830 K. WD0346 is an 11.5 Gyr\nold, 0.77 Msol white dwarf with a mixed H/He atmosphere and Teff = 3650 K. Both\nstars display halo kinematics and their ages agree remarkably well with the\nages of the nearest globular clusters, M4 and NGC 6397. J1102 and WD0346 are\nthe closest examples of the oldest halo stars that we know of. \n\n"}
{"id": "1204.4779", "contents": "Title: Paraiso : An Automated Tuning Framework for Explicit Solvers of Partial\n  Differential Equations Abstract: We propose Paraiso, a domain specific language embedded in functional\nprogramming language Haskell, for automated tuning of explicit solvers of\npartial differential equations (PDEs) on GPUs as well as multicore CPUs. In\nParaiso, one can describe PDE solving algorithms succinctly using tensor\nequations notation. Hydrodynamic properties, interpolation methods and other\nbuilding blocks are described in abstract, modular, re-usable and combinable\nforms, which lets us generate versatile solvers from little set of Paraiso\nsource codes.\n  We demonstrate Paraiso by implementing a compressive hydrodynamics solver. A\nsingle source code less than 500 lines can be used to generate solvers of\narbitrary dimensions, for both multicore CPUs and GPUs. We demonstrate both\nmanual annotation based tuning and evolutionary computing based automated\ntuning of the program. \n\n"}
{"id": "1204.4846", "contents": "Title: Duty Cycle and the Increasing Star Formation History of z>=6 Galaxies Abstract: We examine the duty cycle and the history of star formation (SFH) for\nhigh-redshift galaxies at z>=6 using cosmological hydrodynamic simulations. We\nfind that, even though individual galaxies have bursty SFH, the averaged SFH\nbetween z~15 to z=6 can be characterized well by either an exponentially\nincreasing functional form with characteristic time-scales of 70 Myr to 200 Myr\nfor galaxies with stellar masses Ms~10^6 Msun to >10^10 Msun respectively, or\nby a simple power-law form which exhibits a similar mass dependent time-scales.\nUsing the SFH of individual galaxies, we measure the duty cycle of star\nformation (DC_SFH); i.e., the fraction of time a galaxy of a particular mass\nspends above a star formation rate (SFR) threshold which would make it\nobservable to the Hubble Space Telescope (HST) during a given epoch. We also\nexamine the fraction of galaxies at a given redshift that are brighter than a\nrest-frame UV magnitude (Muv ~ -18), which is sufficient enough to make them\nobservable (DC_Muv). We find that both DC_SFH and DC_Muv make a sharp\ntransition from zero (for galaxies with Ms <= 10^7 Msun) to unity (for Ms >\n10^9 Msun). The measured duty cycle is also manifested in the intrinsic scatter\nin the Ms-SFR relationship (~ 1 dex) and Ms-Muv relationship (\\Delta Muv ~ +-1\nmag). We provide analytic fits to the DC as a function of Ms using a sigmoid\nfunction, which can be used to correct for catalogue incompleteness. We\nconsider the effects of duty cycle to the observational estimate of galaxy\nstellar mass functions (GSMF) and the star formation rate density (SFRD), and\nfind that it results in a much shallower low-mass end slopes of the GSMF and a\nreduction of >~ 70% of our intrinsic SFRD, making our simulation results more\ncompatible with observational estimates. \n\n"}
{"id": "1204.6024", "contents": "Title: First Large Scale Production of Low Radioactivity Argon From Underground\n  Sources Abstract: We report on the first large-scale production of low radioactivity argon from\nunderground gas wells. Low radioactivity argon is of general interest, in\nparticular for the construction of large scale WIMP dark matter searches and\ndetectors of reactor neutrinos for non-proliferation efforts. Atmospheric argon\nhas an activity of about 1 Bq/kg from the decays of 39Ar; the concentration of\n39Ar in the underground argon we are collecting is at least a factor of 100\nlower than this value. The argon is collected from a stream of gas from a CO2\nwell in southwestern Colorado with a Vacuum Pressure Swing Adsorption (VPSA)\nplant. The gas from the well contains argon at a concentration of 400-600 ppm,\nand the VPSA plant produces an output stream with an argon concentration at the\nlevel of 30,000-50,000 ppm (3-5%) in a single pass. This gas is sent for\nfurther processing to Fermilab where it is purified by cryogenic distillation.\nThe argon production rate is presently 0.5 kg/day. \n\n"}
{"id": "1204.6061", "contents": "Title: First Commissioning of a Cryogenic Distillation Column for Low\n  Radioactivity Underground Argon Abstract: We report on the performance and commissioning of a cryogenic distillation\ncolumn for low radioactivity underground argon at Fermi National Accelerator\nLaboratory. The distillation column is designed to accept a mixture of argon,\nhelium, and nitrogen and return pure argon with a nitrogen contamination less\nthan 10 ppm. In the first commissioning, we were able to run the distillation\ncolumn in a continuous mode and produce argon that is 99.9% pure. After running\nin a batch mode, the argon purity was increased to 99.95%, with 500 ppm of\nnitrogen remaining. The efficiency of collecting the argon from the gas mixture\nwas between 70% and 81%, at an argon production rate of 0.84-0.98 kg/day. \n\n"}
{"id": "1205.1799", "contents": "Title: Asymmetric velocity anisotropies in remnants of collisionless mergers Abstract: Dark matter haloes in cosmological N-body simulations are affected by\nprocesses such as mergers, accretion and the gravitational interaction with\nbaryonic matter. Typically the analysis of dark matter haloes is performed in\nspherical or elliptical bins and the velocity distributions are often assumed\nto be constant within those bins. However, the velocity anisotropy, which\ndescribes differences between the radial and tangential velocity dispersion,\nhas recently been show to have a strong dependence on direction in the triaxial\nhalos formed in cosmological simulations. In this study we derive properties of\nparticles in cones parallel or perpendicular to the collision axis of merger\nremnants. We find that the velocity anisotropy has a strong dependence on\ndirection. The finding that the direction-dependence of the velocity anisotropy\nof a halo depends on the merger history, explains the existence of such trends\nin cosmological simulations. It also explains why a large diversity is seen in\nthe velocity anisotropy profiles in the outer parts of high-resolution\nsimulations of cosmological haloes. \n\n"}
{"id": "1205.2957", "contents": "Title: Space-quality data from balloon-borne telescopes: the High Altitude\n  Lensing Observatory (HALO) Abstract: We present a method for attaining sub-arcsecond pointing stability during\nsub- orbital balloon flights, as designed for in the High Altitude Lensing\nObservatory (HALO) concept. The pointing method presented here has the\npotential to perform near-space quality optical astronomical imaging at 1-2% of\nthe cost of space-based missions. We also discuss an architecture that can\nachieve sufficient thermomechanical stability to match the pointing stability.\nThis concept is motivated by advances in the development and testing of Ultra\nLong Duration Balloon (ULDB) flights which promise to allow observation\ncampaigns lasting more than three months. The design incorporates a multi-stage\npointing architecture comprising: a gondola coarse azimuth control system, a\nmulti-axis nested gimbal frame structure with arcsecond stability, a telescope\nde-rotator to eliminate field rotation, and a fine guidance stage consisting of\nboth a telescope mounted angular rate sensor and guide CCDs in the focal plane\nto drive a fast-steering mirror. We discuss the results of pointing tests\ntogether with a preliminary thermo-mechanical analysis required for\nsub-arcsecond pointing at high altitude. Possible future applications in the\nareas of wide-field surveys and exoplanet searches are also discussed. \n\n"}
{"id": "1205.5497", "contents": "Title: MIUSCAT: extended MILES spectral coverage. II. Constraints from optical\n  photometry Abstract: In the present work we show a comprehensive comparison of our new stellar\npopulation synthesis MIUSCAT models with photometric data of globular clusters\nand early-type galaxies. The models compare remarkably well with the colours of\nMilky Way globular clusters in the optical range. Likewise, the colours of M31\nglobular clusters can also be explained by the models by assuming younger ages\nthen their Galactic counterparts. When compared with quiescent galaxies we\nreproduce the colour evolution at intermediate redshift. On the other hand we\nfind that the colour relations of nearby early-type galaxies are still a\nchallenge for present-day stellar population synthesis models. We investigate a\nnumber of possible explanations and establish the importance of alpha-enhanced\nmodels to bring down the discrepancy with observations. \n\n"}
{"id": "1205.6327", "contents": "Title: The mass distribution of the Fornax dSph: constraints from its globular\n  cluster distribution Abstract: Uniquely among the dwarf spheroidal (dSph) satellite galaxies of the Milky\nWay, Fornax hosts globular clusters. It remains a puzzle as to why dynamical\nfriction has not yet dragged any of Fornax's five globular clusters to the\ncentre, and also why there is no evidence that any similar star cluster has\nbeen in the past (for Fornax or any other dSph). We set up a suite of 2800\nN-body simulations that sample the full range of globular-cluster orbits and\nmass models consistent with all existing observational constraints for Fornax.\nIn agreement with previous work, we find that if Fornax has a large dark-matter\ncore then its globular clusters remain close to their currently observed\nlocations for long times. Furthermore, we find previously unreported behaviour\nfor clusters that start inside the core region. These are pushed out of the\ncore and gain orbital energy, a process we call 'dynamical buoyancy'. Thus a\ncored mass distribution in Fornax will naturally lead to a shell-like globular\ncluster distribution near the core radius, independent of the initial\nconditions. By contrast, CDM-type cusped mass distributions lead to the rapid\ninfall of at least one cluster within \\Delta t = 1-2Gyr, except when picking\nunlikely initial conditions for the cluster orbits (\\sim 2% probability), and\nalmost all clusters within \\Delta t = 10Gyr. Alternatively, if Fornax has only\na weakly cusped mass distribution, dynamical friction is much reduced. While\nover \\Delta t = 10Gyr this still leads to the infall of 1-4 clusters from their\npresent orbits, the infall of any cluster within \\Delta t = 1-2Gyr is much less\nlikely (with probability 0-70%, depending on \\Delta t and the strength of the\ncusp). Such a solution to the timing problem requires that in the past the\nglobular clusters were somewhat further from Fornax than today; they most\nlikely did not form within Fornax, but were accreted. \n\n"}
{"id": "1205.6416", "contents": "Title: Dark Matter and Higgs Boson in a Model with Discrete Gauge Symmetry Abstract: In view of ongoing measurements of the Higgs-like boson at the LHC and direct\nsearches for dark matter, we explore the possibility of accommodating the\npotential results in a simple new-physics model with discrete gauge symmetry as\nwell as light neutrino masses. Specifically, we study collider and\nrelic-density constraints on the new gauge coupling, predict the cross section\nof the dark matter scattering off nucleons, and compare it with current direct\nsearch data. We also discuss some of the implications if the dark matter is\nlight. The new gauge sector of the model allows it to be compatible with the\nlatest LHC information on the Higgs-like particle and simultaneously satisfy\nthe requirements in its dark matter sector. \n\n"}
{"id": "1205.6466", "contents": "Title: The First Very Long Baseline Interferometric SETI Experiment Abstract: The first Search for Extra-Terrestrial Intelligence (SETI) conducted with\nVery Long Baseline Interferometry (VLBI) is presented. By consideration of the\nbasic principles of interferometry, we show that VLBI is efficient at\ndiscriminating between SETI signals and human generated radio frequency\ninterference (RFI). The target for this study was the star Gliese 581, thought\nto have two planets within its habitable zone. On 2007 June 19, Gliese 581 was\nobserved for 8 hours at 1230-1544 with the Australian Long Baseline Array. The\ndataset was searched for signals appearing on all interferometer baselines\nabove five times the noise limit. A total of 222 potential SETI signals were\ndetected and by using automated data analysis techniques, were ruled out as\noriginating from the Gliese 581 system. From our results we place an upper\nlimit of 7 MW/Hz on the power output of any isotropic emitter located in the\nGliese 581 system, within this frequency range. This study shows that VLBI is\nideal for targeted SETI, including follow-up observations. The techniques\npresented are equally applicable to next-generation interferometers, such as\nthe long baselines of the Square Kilometre Array (SKA). \n\n"}
{"id": "1205.6492", "contents": "Title: 150 New transiting planet candidates from Kepler Q1-Q6 data Abstract: We have performed an extensive search for planet candidates in the publicly\navailable Kepler Long Cadence data from quarters Q1 through Q6. The search\nmethod consists of initial de-trending of the data, applying the trend\nfiltering algorithm, searching for transit signals with the Box Least Squares\nfitting method in three frequency domains, visual inspection of the potential\ntransit candidates, and in-depth analysis of the shortlisted candidates. In\nthis paper we present 150 new periodic planet candidates and 7 single transit\nevents, 72 of which are in multiple systems. The periods of these planet\ncandidates vary from $\\sim$0.17\\,day to $\\sim$ 440\\,day. 124 of the planet\ncandidates have radii smaller than 3 \\rearth. We recover 82.5% of the Batalha\net al. (2012) KOI catalog. We also report 40 newly identified false\npositives---systems that look like transiting planets, but are probably due to\nblended eclipsing binaries. Our search improves the statistics in the short\nperiod and small planet radii parameter ranges. \n\n"}
{"id": "1205.6637", "contents": "Title: Growth of covariant perturbations in the contracting phase of a bouncing\n  universe Abstract: In this paper we examine the validity of the linear perturbation theory near\na bounce in the covariant analysis. Some linearity parameters are defined to\nset up conditions for a linear theory. Linear evolution of density perturbation\nand gravitational waves have been computed previously. We have calculated the\nvector and scalar induced parts of the shear tensor. For radiationlike and\ndustlike single fluid dominated collapsing Friedmann-Lemaitre-Robertson-Walker\nbackground it is shown that the linearity conditions are not satisfied near a\nbounce. \n\n"}
{"id": "1206.1896", "contents": "Title: The Fermi Large Area Telescope On Orbit: Event Classification,\n  Instrument Response Functions, and Calibration Abstract: The Fermi Large Area Telescope (Fermi-LAT, hereafter LAT), the primary\ninstrument on the Fermi Gamma-ray Space Telescope (Fermi) mission, is an\nimaging, wide field-of-view, high-energy \\gamma-ray telescope, covering the\nenergy range from 20 MeV to more than 300 GeV. During the first years of the\nmission the LAT team has gained considerable insight into the in-flight\nperformance of the instrument. Accordingly, we have updated the analysis used\nto reduce LAT data for public release as well as the Instrument Response\nFunctions (IRFs), the description of the instrument performance provided for\ndata analysis. In this paper we describe the effects that motivated these\nupdates. Furthermore, we discuss how we originally derived IRFs from Monte\nCarlo simulations and later corrected those IRFs for discrepancies observed\nbetween flight and simulated data. We also give details of the validations\nperformed using flight data and quantify the residual uncertainties in the\nIRFs. Finally, we describe techniques the LAT team has developed to propagate\nthose uncertainties into estimates of the systematic errors on common\nmeasurements such as fluxes and spectra of astrophysical sources. \n\n"}
{"id": "1206.4263", "contents": "Title: The VISTA Deep Extragalactic Observations (VIDEO) Survey Abstract: In this paper we describe the first data release of the the Visible and\nInfrared Survey Telescope for Astronomy (VISTA) Deep Extragalactic Observations\n(VIDEO) survey. VIDEO is a ~12degree^2 survey in the near-infrared Z,Y,J,H and\nK_s bands, specifically designed to enable the evolution of galaxies and large\nstructures to be traced as a function of both epoch and environment from the\npresent day out to z=4, and active galactic nuclei (AGN) and the most massive\ngalaxies up to and into the epoch of reionization. With its depth and area,\nVIDEO will be able to fully explore the period in the Universe where AGN and\nstarburst activity were at their peak and the first galaxy clusters were\nbeginning to virialize. VIDEO therefore offers a unique data set with which to\ninvestigate the interplay between AGN, starbursts and environment, and the role\nof feedback at a time when it was potentially most crucial.\n  We provide data over the VIDEO-XMM3 tile, which also covers the\nCanada-France-Hawaii-Telescope Legacy Survey Deep-1 field (CFHTLS-D1). The\nreleased VIDEO data reach a 5-sigma AB-magnitude depth of Z=25.7, Y=24.5,\nJ=24.4, H=24.1 and K_s=23.8 in 2 arcsec diameter apertures (the full depth of\nY=24.6 will be reached within the full integration time in future releases).\nThe data are compared to previous surveys over this field and we find good\nastrometric agreement with the Two-Micron All Sky Survey, and source counts in\nagreement with the recently released UltraVISTA survey data. The addition of\nthe VIDEO data to the CFHTLS-D1 optical data increases the accuracy of\nphotometric redshifts and significantly reduces the fraction of catastrophic\noutliers over the redshift range 0<z<1 from 5.8 to 3.1 per cent in the absence\nof an i-band luminosity prior. (Truncated Abstract) \n\n"}
{"id": "1206.4303", "contents": "Title: The Stellar Population and Star Formation Rates of z~1.5-1.6 [O II]\n  Emitting Galaxies Selected from Narrow-Band Emission-Line Surveys Abstract: We present the first detailed study of the stellar populations of\nstar-forming galaxies at z~1.5, which are selected by their [O II] emission\nline, detected in narrow-band surveys. We identified ~1,300 [O II] emitters at\nz=1.47 and z=1.62 in the Subaru Deep Field with rest-frame EWs above 13\\AA.\nOptical and near-infrared spectroscopic observations for ~10% of our samples\nshow that our separation of [O II] from [O III] emission-line galaxies in\ntwo-color space is 99% successful. We analyze the multi-wavelength properties\nof a subset of ~1,200 galaxies with the best photometry. They have average\nrest-frame EW of 45\\AA, stellar mass of 3 x 10^9 M_sun, and stellar age of 100\nMyr. In addition, our SED fitting and broad-band colors indicate that [O II]\nemitters span the full range of galaxy populations at z~1.5. We also find that\n80% of [O II] emitters are also photometrically classified as \"BX/BM\" (UV)\ngalaxies and/or the star-forming \"BzK\" (near-IR) galaxies. Our [O II] emission\nline survey produces a far more complete, and somewhat deeper sample of z~1.5\ngalaxies than either the BX/BM or sBzK selection alone. We constructed average\nSEDs and find that higher [O II] EW galaxies have somewhat bluer continua. SED\nmodel-fitting shows that they have on average half the stellar mass of galaxies\nwith lower [O II] EW. The observed [O II] luminosity is well-correlated with\nthe far-UV continuum with a logarithmic slope slightly 0f 0.89\\pm0.22. The\nscatter of the [O II] luminosity against the far-UV continuum suggests that [O\nII] can be used as a SFR indicator with a reliability of 0.23 dex. \n\n"}
{"id": "1206.4693", "contents": "Title: Molecular and atomic line surveys of galaxies I: the dense, star-forming\n  phase as a beacon Abstract: We predict the space density of molecular gas reservoirs in the Universe, and\nplace a lower limit on the number counts of carbon monoxide (CO), hydrogen\ncyanide (HCN) molecular and [CII] atomic emission lines in blind redshift\nsurveys in the submillimeter-centimeter spectral regime. Our model uses: (a)\nrecently available HCN Spectral Line Energy Distributions (SLEDs) of local\nLuminous Infrared Galaxies (LIRGs, L_IR>10^11 L_sun), (b) a value for\nepsilon=SFR/M_dense(H_2) provided by new developments in the study of star\nformation feedback on the interstellar medium and (c) a model for the evolution\nof the infrared luminosity density. Minimal 'emergent' CO SLEDs from the dense\ngas reservoirs expected in all star-forming systems in the Universe are then\ncomputed from the HCN SLEDs since warm, HCN-bright gas will necessarily be\nCO-bright, with the dense star-forming gas phase setting an obvious minimum to\nthe total molecular gas mass of any star-forming galaxy. We include [CII] as\nthe most important of the far-infrared cooling lines. Optimal blind surveys\nwith the Atacama Large Millimeter Array (ALMA) could potentially detect very\ndistant (z~10-12) [CII] emitters in the >ULIRG galaxy class at a rate of ~0.1-1\nper hour (although this prediction is strongly dependent on the star formation\nand enrichment history at this early epoch), whereas the (high-frequency)\nSquare Kilometer Array (SKA) will be capable of blindly detecting z>3 low-J CO\nemitters at a rate of ~40-70 per hour. The [CII] line holds special promise for\nthe detection of metal-poor systems with extensive reservoirs of CO-dark\nmolecular gas where detection rates with ALMA can reach up to 2-7 per hour in\nBands 4-6. \n\n"}
{"id": "1206.5006", "contents": "Title: A General Class of Lagrangian Smoothed Particle Hydrodynamics Methods\n  and Implications for Fluid Mixing Problems Abstract: Various formulations of smooth-particle hydrodynamics (SPH) have been\nproposed, intended to resolve certain difficulties in the treatment of fluid\nmixing instabilities. Most have involved changes to the algorithm which either\nintroduce artificial correction terms or violate arguably the greatest\nadvantage of SPH over other methods: manifest conservation of energy, entropy,\nmomentum, and angular momentum. Here, we show how a class of alternative SPH\nequations of motion (EOM) can be derived self-consistently from a discrete\nparticle Lagrangian (guaranteeing manifest conservation) in a manner which\ntremendously improves treatment of instabilities and contact discontinuities.\nSaitoh & Makino recently noted that the volume element used to discretize the\nEOM does not need to explicitly invoke the mass density (as in the 'standard'\napproach); we show how this insight, and the resulting degree of freedom, can\nbe incorporated into the rigorous Lagrangian formulation that retains ideal\nconservation properties and includes the 'Grad-h' terms that account for\nvariable smoothing lengths. We derive a general EOM for any choice of volume\nelement (particle 'weights') and method of determining smoothing lengths. We\nthen specify this to a 'pressure-entropy formulation' which resolves problems\nin the traditional treatment of fluid interfaces. Implementing this in a new\nversion of the GADGET code, we show it leads to good performance in mixing\nexperiments (e.g. Kelvin-Helmholtz & blob tests). And conservation is\nmaintained even in strong shock/blastwave tests, where formulations without\nmanifest conservation produce large errors. This also improves the treatment of\nsub-sonic turbulence, and lessens the need for large kernel particle numbers.\nThe code changes are trivial and entail no additional numerical expense. This\nprovides a general framework for self-consistent derivation of different\n'flavors' of SPH. \n\n"}
{"id": "1206.5878", "contents": "Title: A Parallel Monte Carlo Code for Simulating Collisional N-body Systems Abstract: We present a new parallel code for computing the dynamical evolution of\ncollisional N-body systems with up to N~10^7 particles. Our code is based on\nthe the Henon Monte Carlo method for solving the Fokker-Planck equation, and\nmakes assumptions of spherical symmetry and dynamical equilibrium. The\nprincipal algorithmic developments involve optimizing data structures, and the\nintroduction of a parallel random number generation scheme, as well as a\nparallel sorting algorithm, required to find nearest neighbors for interactions\nand to compute the gravitational potential. The new algorithms we introduce\nalong with our choice of decomposition scheme minimize communication costs and\nensure optimal distribution of data and workload among the processing units.\nThe implementation uses the Message Passing Interface (MPI) library for\ncommunication, which makes it portable to many different supercomputing\narchitectures. We validate the code by calculating the evolution of clusters\nwith initial Plummer distribution functions up to core collapse with the number\nof stars, N, spanning three orders of magnitude, from 10^5 to 10^7. We find\nthat our results are in good agreement with self-similar core-collapse\nsolutions, and the core collapse times generally agree with expectations from\nthe literature. Also, we observe good total energy conservation, within less\nthan 0.04% throughout all simulations. We analyze the performance of the code,\nand demonstrate near-linear scaling of the runtime with the number of\nprocessors up to 64 processors for N=10^5, 128 for N=10^6 and 256 for N=10^7.\nThe runtime reaches a saturation with the addition of more processors beyond\nthese limits which is a characteristic of the parallel sorting algorithm. The\nresulting maximum speedups we achieve are approximately 60x, 100x, and 220x,\nrespectively. \n\n"}
{"id": "1206.6979", "contents": "Title: The supernovae associated with gamma-ray bursts Abstract: The connection between long GRBs and supernovae is now well established. I\nbriefly review the evidence in favor of this connection and summarise where we\nare observationally. I also use a few events to exemplify what should be done\nand what type of data are needed. I also look at what we can learn from looking\nat SNe not associated with GRBs and see how GRBs fit into the broad picture of\nstellar explosions. \n\n"}
{"id": "1207.1528", "contents": "Title: VAST: An ASKAP Survey for Variables and Slow Transients Abstract: The Australian Square Kilometre Array Pathfinder (ASKAP) will give us an\nunprecedented opportunity to investigate the transient sky at radio\nwavelengths. In this paper we present VAST, an ASKAP survey for Variables and\nSlow Transients. VAST will exploit the wide-field survey capabilities of ASKAP\nto enable the discovery and investigation of variable and transient phenomena\nfrom the local to the cosmological, including flare stars, intermittent\npulsars, X-ray binaries, magnetars, extreme scattering events, interstellar\nscintillation, radio supernovae and orphan afterglows of gamma ray bursts. In\naddition, it will allow us to probe unexplored regions of parameter space where\nnew classes of transient sources may be detected. In this paper we review the\nknown radio transient and variable populations and the current results from\nblind radio surveys. We outline a comprehensive program based on a multi-tiered\nsurvey strategy to characterise the radio transient sky through detection and\nmonitoring of transient and variable sources on the ASKAP imaging timescales of\nfive seconds and greater. We also present an analysis of the expected source\npopulations that we will be able to detect with VAST. \n\n"}
{"id": "1207.1806", "contents": "Title: An upper limit on the sulphur abundance in HE 1327-2326 Abstract: Context: Star HE 1327-2326 is a unique object, with the lowest measured iron\nabundance ([Fe/H] ~ -6) and a peculiar chemical composition that includes large\noverabundances of C, N, and O with respect to iron. One important question is\nwhether the chemical abundances in this star reflect the chemical composition\nof the gas cloud from which it was formed or if they have been severely\naffected by other processes, such as dust-gas winnowing. Aims: We measure or\nprovide an upper limit to the abundance of the volatile element sulphur, which\ncan help to discriminate between the two scenarios. Methods: We observed HE\n1327-2326 with the high resolution infra-red spectrograph CRIRES at the VLT to\nobserve the S I lines of Multiplet 3 at 1045 nm. Results: We do not detect the\nS I line. A 3sigma$upper limit on the equivalent width (EW) of any line in our\nspectrum is EW<0.66 pm. Using either one-dimensional static or\nthree-dimensional hydrodynamical model-atmospheres, this translates into a\nrobust upper limit of [S/H]<-2.6. Conclusions: This upper limit does not\nprovide conclusive evidence for or against dust-gas winnowing, and the evidence\ncoming from other elements (e.g., Na and Ti) is also inconclusive or\ncontradictory. The formation of dust in the atmosphere versus an origin of the\nmetals in a metal-poor supernova with extensive \"fall-back\" are not mutually\nexclusive. It is possible that dust formation distorts the peculiar abundance\npattern created by a supernova with fall-back, thus the abundance ratios in HE\n1327-2326 may be used to constrain the properties of the supernova(e) that\nproduced its metals, but with some caution. \n\n"}
{"id": "1207.3455", "contents": "Title: Cosmic Ray Composition and Energy Spectrum from 1-30 PeV Using the\n  40-String Configuration of IceTop and IceCube Abstract: The mass composition of high energy cosmic rays depends on their production,\nacceleration, and propagation. The study of cosmic ray composition can\ntherefore reveal hints of the origin of these particles. At the South Pole, the\nIceCube Neutrino Observatory is capable of measuring two components of cosmic\nray air showers in coincidence: the electromagnetic component at high altitude\n(2835 m) using the IceTop surface array, and the muonic component above ~1 TeV\nusing the IceCube array. This unique detector arrangement provides an\nopportunity for precision measurements of the cosmic ray energy spectrum and\ncomposition in the region of the knee and beyond. We present the results of a\nneural network analysis technique to study the cosmic ray composition and the\nenergy spectrum from 1 PeV to 30 PeV using data recorded using the\n40-string/40-station configuration of the IceCube Neutrino Observatory. \n\n"}
{"id": "1207.3802", "contents": "Title: The stretching of Hercules Abstract: We present VLT/FORS2 spectroscopy of candidate blue horizontal branch (BHB)\nstars in the vicinity of the Hercules ultrafaint dwarf galaxy. We identify\neight convincing Hercules BHB members, and a further five stars with similar\nsystemic velocities to that of Hercules, but ~ 0.5 kpc from the centre of the\ngalaxy along its major axis. It is likely that these stars once belonged to\nHercules, but have been tidally stripped and are now unbound. We emphasise the\nusefulness of looking for any gradient in the systemic velocity of this\nstretched system, which would further support our interpretation of the origin\nof its elongated and distended morphology. \n\n"}
{"id": "1207.4772", "contents": "Title: Circumstellar matter studied by spectrally-resolved interferometry Abstract: This paper describes some generalities about spectro-interferometry and the\nrole it has played in the last decade for the better understanding of\ncircumstellar matter. I provide a small history of the technique and its\norigins, and recall the basics of differential phase and its central role for\nthe recent discoveries. I finally provide a small set of simple interpretations\nof differential phases for specific astrophysical cases, and intend to provide\na \"cookbook\" for the other cases. \n\n"}
{"id": "1207.5562", "contents": "Title: The QUIET Instrument Abstract: The Q/U Imaging ExperimenT (QUIET) is designed to measure polarization in the\nCosmic Microwave Background, targeting the imprint of inflationary\ngravitational waves at large angular scales (~ 1 degree). Between 2008 October\nand 2010 December, two independent receiver arrays were deployed sequentially\non a 1.4 m side-fed Dragonian telescope. The polarimeters which form the focal\nplanes use a highly compact design based on High Electron Mobility Transistors\n(HEMTs) that provides simultaneous measurements of the Stokes parameters Q, U,\nand I in a single module. The 17-element Q-band polarimeter array, with a\ncentral frequency of 43.1 GHz, has the best sensitivity (69 uK sqrt(s)) and the\nlowest instrumental systematic errors ever achieved in this band, contributing\nto the tensor-to-scalar ratio at r < 0.1. The 84-element W-band polarimeter\narray has a sensitivity of 87 uK sqrt(s) at a central frequency of 94.5 GHz. It\nhas the lowest systematic errors to date, contributing at r < 0.01. The two\narrays together cover multipoles in the range l= 25-975. These are the largest\nHEMT-based arrays deployed to date. This article describes the design,\ncalibration, performance of, and sources of systematic error for the\ninstrument. \n\n"}
{"id": "1207.5578", "contents": "Title: Studies in Astronomical Time Series Analysis. VI. Bayesian Block\n  Representations Abstract: This paper addresses the problem of detecting and characterizing local\nvariability in time series and other forms of sequential data. The goal is to\nidentify and characterize statistically significant variations, at the same\ntime suppressing the inevitable corrupting observational errors. We present a\nsimple nonparametric modeling technique and an algorithm implementing it - an\nimproved and generalized version of Bayesian Blocks (Scargle 1998) - that finds\nthe optimal segmentation of the data in the observation interval. The structure\nof the algorithm allows it to be used in either a real-time trigger mode, or a\nretrospective mode. Maximum likelihood or marginal posterior functions to\nmeasure model fitness are presented for events, binned counts, and measurements\nat arbitrary times with known error distributions. Problems addressed include\nthose connected with data gaps, variable exposure, extension to piecewise\nlinear and piecewise exponential representations, multi-variate time series\ndata, analysis of variance, data on the circle, other data modes, and dispersed\ndata. Simulations provide evidence that the detection efficiency for weak\nsignals is close to a theoretical asymptotic limit derived by (Arias-Castro,\nDonoho and Huo 2003). In the spirit of Reproducible Research (Donoho et al.\n2008) all of the code and data necessary to reproduce all of the figures in\nthis paper are included as auxiliary material. \n\n"}
{"id": "1208.0865", "contents": "Title: PreCam, a Precursor Observational Campaign for Calibration of the Dark\n  Energy Survey Abstract: PreCam, a precursor observational campaign supporting the Dark Energy Survey\n(DES), is designed to produce a photometric and astrometric catalog of nearly a\nhundred thousand standard stars within the DES footprint, while the PreCam\ninstrument also serves as a prototype testbed for the Dark Energy Camera\n(DECam)'s hardware and software. This catalog represents a potential 100-fold\nincrease in Southern Hemisphere photometric standard stars, and therefore will\nbe an important component in the calibration of the Dark Energy Survey. We\nprovide details on the PreCam instrument's design, construction and testing, as\nwell as results from a subset of the 51 nights of PreCam survey observations on\nthe University of Michigan Department of Astronomy's Curtis-Schmidt telescope\nat Cerro Tololo Inter-American Observatory. We briefly describe the preliminary\ndata processing pipeline that has been developed for PreCam data and the\npreliminary results of the instrument performance, as well as astrometry and\nphotometry of a sample of stars previously included in other southern sky\nsurveys. \n\n"}
{"id": "1208.1523", "contents": "Title: Local cosmological effects of the order of H in the orbital motion of a\n  binary system Abstract: A two-body system hypothetically affected by an additional radial\nacceleration H v_r, where v_r is the radial velocity of the binary's proper\norbital motion, would experience long-term temporal changes of both its\nsemimajor axis a and the eccentricity e qualitatively different from any other\nstandard competing effect for them. Contrary to what one might reasonably\nexpect, the analytical expressions of such rates do not vanish in the limit\nM--> 0, where M is the mass of the primary, being independent of it. This is a\ngeneral requirement that any potentially viable physical mechanism able to\nprovide such a putative acceleration should meet. Nonetheless, if H had the\nsame value H_0 of the Hubble parameter at present epoch, such rates of change\nwould have magnitude close to the present-day level of accuracy in determining\nplanetary orbital motions in our Solar System. A tension with recent\nobservations may even be present for Mercury and Mars. However, general\nrelativity, applied to a localized gravitationally bound binary system immersed\nin an expanding Friedmann-Lemaitre-Robertson-Walker, does not predict the\nexistence of such a putative radial acceleration at Newtonian level. Instead,\nit was recently shown in literature that an acceleration of order H and\ndirected along the velocity v of the test particle occurs at post-Newtonian\nlevel. We worked out its orbital effects finding well-behaved secular rates of\nchange for both a and e proportional to the Schwarzschild radius r_s of the\nprimary. Their magnitude is quite small: the rate of change of a amounts to\njust 20 microns per century in our Solar System. Finally, we discussed certain\nbasic criteria of viability that modified models of gravity should generally\nmeet when their observable effects are calculated. \n\n"}
{"id": "1208.1966", "contents": "Title: Future Science Prospects for AMI Abstract: The Arcminute Microkelvin Imager (AMI) is a telescope specifically designed\nfor high sensitivity measurements of low-surface-brightness features at\ncm-wavelength and has unique, important capabilities. It consists of two\ninterferometer arrays operating over 13.5-18 GHz that image structures on\nscales of 0.5-10 arcmin with very low systematics. The Small Array (AMI-SA; ten\n3.7-m antennas) couples very well to Sunyaev-Zel'dovich features from galaxy\nclusters and to many Galactic features. The Large Array (AMI-LA; eight 13-m\nantennas) has a collecting area ten times that of the AMI-SA and longer\nbaselines, crucially allowing the removal of the effects of confusing radio\npoint sources from regions of low surface-brightness, extended emission.\nMoreover AMI provides fast, deep object surveying and allows monitoring of\nlarge numbers of objects. In this White Paper we review the new science - both\nGalactic and extragalactic - already achieved with AMI and outline the\nprospects for much more. \n\n"}
{"id": "1208.3206", "contents": "Title: A Novel Approach to Visualizing Dark Matter Simulations Abstract: In the last decades cosmological N-body dark matter simulations have enabled\nab initio studies of the formation of structure in the Universe. Gravity\namplified small density fluctuations generated shortly after the Big Bang,\nleading to the formation of galaxies in the cosmic web. These calculations have\nled to a growing demand for methods to analyze time-dependent particle based\nsimulations. Rendering methods for such N-body simulation data usually employ\nsome kind of splatting approach via point based rendering primitives and\napproximate the spatial distributions of physical quantities using kernel\ninterpolation techniques, common in SPH (Smoothed Particle\nHydrodynamics)-codes. This paper proposes three GPU-assisted rendering\napproaches, based on a new, more accurate method to compute the physical\ndensities of dark matter simulation data. It uses full phase-space information\nto generate a tetrahedral tessellation of the computational domain, with mesh\nvertices defined by the simulation's dark matter particle positions. Over time\nthe mesh is deformed by gravitational forces, causing the tetrahedral cells to\nwarp and overlap. The new methods are well suited to visualize the cosmic web.\nIn particular they preserve caustics, regions of high density that emerge, when\nseveral streams of dark matter particles share the same location in space,\nindicating the formation of structures like sheets, filaments and halos. We\ndemonstrate the superior image quality of the new approaches in a comparison\nwith three standard rendering techniques for N-body simulation data. \n\n"}
{"id": "1208.3564", "contents": "Title: Elliptical Weighted HOLICs for Weak Lensing Shear Measurement\n  part3:Random Count Noise Effect for Image's Moments in Weak Lensing Analysis Abstract: This is the third paper on the improvements of systematic errors in our weak\nlensing analysis using an elliptical weight function, called E-HOLICs. In the\nprevious papers we have succeeded in avoiding error which depends on\nellipticity of background image. In this paper, we investigate the systematic\nerror which depends on signal to noise ratio of background image. We find that\nthe origin of the error is the random count noise which comes from Poisson\nnoise of sky counts. Random count noise makes additional moments and centroid\nshift error, and those 1st orders are canceled in averaging, but 2nd orders are\nnot canceled. We derived the equations which corrects these effects in\nmeasuring moments and ellipticity of the image and test their validity using\nsimulation image. We find that the systematic error becomes less than 1% in the\nmeasured ellipticity for objects with $S/N>3$. \n\n"}
{"id": "1208.4866", "contents": "Title: Empirical modelling of the BLASTPol achromatic half-wave plate for\n  precision submillimetre polarimetry Abstract: A cryogenic achromatic half-wave plate (HWP) for submillimetre astronomical\npolarimetry has been designed, manufactured, tested, and deployed in the\nBalloon-borne Large-Aperture Submillimeter Telescope for Polarimetry\n(BLASTPol). The design is based on the five-slab Pancharatnam recipe and it\nworks in the wavelength range 200-600 micron, making it the broadest-band HWP\nbuilt to date at (sub)millimetre wavelengths. The frequency behaviour of the\nHWP has been fully characterised at room and cryogenic temperatures with\nincoherent radiation from a polarising Fourier transform spectrometer. We\ndevelop a novel empirical model, complementary to the physical and analytical\nones available in the literature, that allows us to recover the HWP Mueller\nmatrix and phase shift as a function of frequency and extrapolated to 4K. We\nshow that most of the HWP non-idealities can be modelled by quantifying one\nwavelength-dependent parameter, the position of the HWP equivalent axes, which\nis then readily implemented in a map-making algorithm. We derive this parameter\nfor a range of spectral signatures of input astronomical sources relevant to\nBLASTPol, and provide a benchmark example of how our method can yield improved\naccuracy on measurements of the polarisation angle on the sky at submillimetre\nwavelengths. \n\n"}
{"id": "1208.5776", "contents": "Title: Hot electron bolometer heterodyne receiver with a 4.7-THz quantum\n  cascade laser as a local oscillator Abstract: We report on a heterodyne receiver designed to observe the astrophysically\nimportant neutral atomic oxygen [OI] line at 4.7448 THz. The local oscillator\nis a third-order distributed feedback Quantum Cascade Laser operating in\ncontinuous wave mode at 4.741 THz. A quasi-optical, superconducting NbN hot\nelectron bolometer is used as the mixer. We recorded a double sideband receiver\nnoise temperature (T^DSB_rec) of 815 K, which is ~7 times the quantum noise\nlimit (h{\\nu}/2k_B) and an Allan variance time of 15 s at an effective noise\nfluctuation bandwidth of 18 MHz. Heterodyne performance was confirmed by\nmeasuring a methanol line spectrum. \n\n"}
{"id": "1209.0477", "contents": "Title: The Demographics of Broad Line Quasars in the Mass-Luminosity Plane II.\n  Black Hole Mass and Eddington Ratio Functions Abstract: We employ a flexible Bayesian technique to estimate the black hole mass and\nEddington ratio functions for Type 1 (i.e., broad line) quasars from a\nuniformly-selected data set of ~58,000 quasars from the SDSS DR7. We find that\nthe SDSS becomes significantly incomplete at M_{BH} < 3 x 10^8 M_{Sun} or L /\nL_{Edd} < 0.07, and that the number densities of Type 1 quasars continue to\nincrease down to these limits. Both the mass and Eddington ratio functions show\nevidence of downsizing, with the most massive and highest Eddington ratio black\nholes experiencing Type 1 quasar phases first, although the Eddington ratio\nnumber densities are flat at z < 2. We estimate the maximum Eddington ratio of\nType 1 quasars in the observable Universe to be L / L_{Edd} ~ 3. Consistent\nwith our results in Paper I, we do not find statistical evidence for a\nso-called \"sub-Eddington boundary\" in the mass-luminosity plane of broad line\nquasars, and demonstrate that such an apparent boundary in the observed\ndistribution can be caused by selection effect and errors in virial BH mass\nestimates. Based on the typical Eddington ratio in a given mass bin, we\nestimate typical growth times for the black holes in Type 1 quasars and find\nthat they are typically comparable to or longer than the age of the universe,\nimplying an earlier phase of accelerated (i.e., with higher Eddington ratios)\nand possibly obscured growth. The large masses probed by our sample imply that\nmost of our black holes reside in what are locally early type galaxies, and we\ninterpret our results within the context of models of self-regulated black hole\ngrowth. \n\n"}
{"id": "1209.1277", "contents": "Title: Measurement of the CMB Polarization at 95 GHz from QUIET Abstract: (Abridged) Despite the great success of precision cosmology, cosmologists\ncannot fully explain the initial conditions of the Universe. Inflation, an\nexponential expansion in the first 10^-36s, is a promising potential\nexplanation. A generic prediction of inflation is odd-parity (B-mode)\npolarization in the cosmic microwave background (CMB). The Q/U Imaging\nExperimenT (QUIET) aimed to limit or detect this polarization.\n  We built a coherent pseudo-correlation microwave polarimeter. An array of\nmass-produced modules populated the focal plane of a 1.4m telescope. Each\nmodule had a sensitivity to polarization of 756muK sqrt{s} with a bandwidth of\n10.7+/-1.1 GHz centered at 94.5+/-0.8 GHz; the combined sensitivity was\n87+/-7muK sqrt{s}. We incorporated deck rotation, an absorbing ground screen, a\nnew time-stream double-demodulation technique, and optimized optics into the\ndesign to reduce instrumental polarization. We observed with this instrument at\nthe Atacama Plateau in Chile between August 2009 and December 2010. We\ncollected 5336.9 hours of CMB observation and 1090 hours of astronomical\ncalibration.\n  This thesis describes the analysis and results of these data. We\ncharacterized the instrument using the astronomical calibration data as well as\npurpose-built artificial sources. We developed noise modeling, filtering, and\ndata selection following a blind-analysis strategy. Central to this strategy\nwas a suite of 32 null tests, each motivated by a possible instrumental problem\nor systematic effect. We also evaluated the systematic errors in the blind\nstage of the analysis before the result was known. We then calculated the CMB\npower spectra using a pseudo-Cl cross-correlation technique that suppressed\ncontamination and made the result insensitive to noise bias. \n\n"}
{"id": "1209.1284", "contents": "Title: Are 3C249.1 and 3C334 restarted quasars? Abstract: This Research Note follows up a Letter in which I posit that J1211+743 is a\nrestarted radio source. This means that its structure, where the jet points to\nthe relic lobe, is only apparently paradoxical. Here, I propose the same\nscenario and apply the same mathematical model to 3C249.1 and 3C334. The\nultimate result of my investigation is that these two well-known radio-loud\nquasars can be understood best so far if it was assumed that they, too, had\nbeen restarted. \n\n"}
{"id": "1209.2750", "contents": "Title: A Method to Extract the Angular Power Spectrum of the Epoch of\n  Reionization from Low-Frequency Radio Interferometers Abstract: The redshifted 21cm signal of neutral hydrogen from the epoch of reionization\n(EoR) is extremely weak and its first detection is therefore expected to be\nstatistical with first-generation low-frequency radio interferometers. In this\nletter we propose a method to extract the angular power spectrum of EoR from\nthe visibility correlation coefficients p_{ij}(u,v), instead of the\nvisibilities V_{ij}(u,v) measured directly by radio interferometers in\nconventional algorithm. The visibility correlation coefficients are defined as\np_{ij}(u,v)=V_{ij}(u,v)/\\sqrt{|V_{ii}||V_{jj}|} by introducing the\nauto-correlation terms V_{ii} and V_{jj} such that the angular power spectrum\nC_{\\ell} can be obtained through C_{\\ell}=4pi^2T_0^2<|p_{ij}(u,v)|^2>,\nindependently of the primary beams of antennas. This also removes partially the\ninfluence of receiver gains in the measurement of C_{\\ell} because the\namplitudes of the gains cancel each other out in the statistical average\noperation of <|p_{ij}(u,v)|^2>.We use the average system temperature T_0 as a\ncalibrator of C_{\\ell}, which is dominated by the Milky Way and extragalactic\nsources in our interested frequency range below 200 MHz. Finally we demonstrate\nthe feasibility of the novel method using the simulated sky maps as targets and\nthe 21 CentiMeter Array (21CMA) as interferometer. \n\n"}
{"id": "1209.2768", "contents": "Title: The Quest for Gravity Wave B-modes Abstract: One of the most exciting quests in all of contemporary science is to find\nhints that in the first tiny fraction of a second after the Big-Bang the\nUniverse hyper-inflated by a factor of \\sim 10^{60}. Such inflation will have\ninjected gravity waves into the fabric of spacetime which will in turn have\nleft a faint imprint in the polarization pattern of the Cosmic Microwave\nBackground. This paper describes the history of polarization measurement, the\nexperimental optimization of this latest search for the gravity wave imprint,\nand the current round of experiments and their various approaches to the\nchallenge. \n\n"}
{"id": "1210.0313", "contents": "Title: Re-calibration of SDF/SXDS Photometric Catalogs of Suprime-Cam with SDSS\n  Data Release 8 Abstract: We present photometric recalibration of the Subaru Deep Field (SDF) and\nSubaru/XMM-Newton Deep Survey (SXDS). Recently, Yamanoi et al. (2012) suggested\nthe existence of a discrepancy between the SDF and SXDS catalogs. We have used\nthe Sloan Digital Sky Survey (SDSS) Data Release 8 (DR8) catalog and compared\nstars in common between SDF/SXDS and SDSS. We confirmed that there exists a\n0.12 mag offset in B-band between the SDF and SXDS catalogs. Moreover, we found\nthat significant zero point offsets in i-band (~ 0.10 mag) and z-band (~ 0.14\nmag) need to be introduced to the SDF/SXDS catalogs to make it consistent with\nthe SDSS catalog. We report the measured zero point offsets of five filter\nbands of SDF/SXDS catalogs. We studied the potential cause of these offsets,\nbut the origins are yet to be understood. \n\n"}
{"id": "1210.1063", "contents": "Title: Discovery of an extremely gas-rich dwarf triplet near the center of the\n  Lynx-Cancer void Abstract: Giant Metrewave Radio Telescope (GMRT) HI observations, done as part of an\nongoing study of dwarf galaxies in the Lynx-Cancer void, resulted in the\ndiscovery of a triplet of extremely gas rich galaxies located near the centre\nof the void.The triplet members SDSS J0723+3621, J0723+3622 and J0723+3624 have\nabsolute magnitudes M_B of -14.2, -11.9 and -9.7 and M(HI)/L_B of \\sim 2.9, ~10\nand ~25, respectively. The gas mass fractions, as derived from the SDSS\nphotometry and the GMRT data are 0.93, 0.997, 0.997 respectively. The faintest\nmember of this triplet SDSS J0723+3624 is one of the most gas rich galaxies\nknown. We find that all three galaxies deviate significantly from the\nTully-Fisher relation, but follow the baryonic Tully-Fisher relation. All three\ngalaxies also have a baryon fraction that is significantly smaller than the\ncosmic baryon fraction. For the largest galaxy in the triplet, this is in\ncontradiction to numerical simulations. The discovery of this very unique dwarf\ntriplet lends support to the idea that the void environment is conducive to the\nformation of galaxies with unusual properties. These observations also provide\nfurther motivation to do deep searches of voids for a \"hidden\" very gas-rich\ngalaxy population with M_B > -11. \n\n"}
{"id": "1210.3489", "contents": "Title: Using Swarm Intelligence To Accelerate Pulsar Timing Analysis Abstract: We provide brief notes on a particle swarm-optimisation approach to\nconstraining the properties of a stochastic gravitational-wave background in\nthe first International Pulsar Timing Array data-challenge. The technique\nemploys many computational-agents which explore parameter space, remembering\ntheir most optimal positions and also sharing this information with all other\nagents. It is this sharing of information which accelerates the convergence of\nall agents to the global best-fit location in a very short number of\niterations. Error estimates can also be provided by fitting a multivariate\nGaussian to the recorded fitness of all visited points. \n\n"}
{"id": "1210.4373", "contents": "Title: Maser emission during post-AGB evolution Abstract: This contribution reviews recent observational results concerning\nastronomical masers toward post-AGB objects with a special attention to water\nfountain sources and the prototypical source OH231.8+4.2. These sources\nrepresent a short transition phase in the evolution between circumstellar\nenvelopes around asymptotic giant branch stars and planetary nebulae. The main\nmasing species are considered and key results are summarized. \n\n"}
{"id": "1210.4957", "contents": "Title: Towards a complete accounting of energy and momentum from stellar\n  feedback in galaxy formation simulations Abstract: Stellar feedback plays a key role in galaxy formation by regulating star\nformation, driving interstellar turbulence and generating galactic scale\noutflows. Although modern simulations of galaxy formation can resolve scales of\n10-100 pc, star formation and feedback operate on smaller, \"subgrid\" scales.\nGreat care should therefore be taken in order to properly account for the\neffect of feedback on global galaxy evolution. We investigate the momentum and\nenergy budget of feedback during different stages of stellar evolution, and\nstudy its impact on the interstellar medium using simulations of local star\nforming regions and galactic disks at the resolution affordable in modern\ncosmological zoom-in simulations. In particular, we present a novel subgrid\nmodel for the momentum injection due to radiation pressure and stellar winds\nfrom massive stars during early, pre-supernova evolutionary stages of young\nstar clusters. Early injection of momentum acts to clear out dense gas in star\nforming regions, hence limiting star formation. The reduced gas density\nmitigates radiative losses of thermal feedback energy from subsequent supernova\nexplosions, leading to an increased overall efficiency of stellar feedback. The\ndetailed impact of stellar feedback depends sensitively on the implementation\nand choice of parameters. Somewhat encouragingly, we find that implementations\nin which feedback is efficient lead to approximate self-regulation of global\nstar formation efficiency. We compare simulation results using our feedback\nimplementation to other phenomenological feedback methods, where thermal\nfeedback energy is allowed to dissipate over time scales longer than the formal\ngas cooling time. We find that simulations with maximal momentum injection\nsuppress star formation to a similar degree as is found in simulations adopting\nadiabatic thermal feedback. \n\n"}
{"id": "1210.6797", "contents": "Title: On the possibility of neutrino flavor identification at the highest\n  energies Abstract: High energy astrophysical neutrinos carry relevant information about the\norigin and propagation of cosmic rays. They can be created as a by-product of\nthe interactions of cosmic rays in the sources and during propagation of these\nhigh energy particles through the intergalactic medium. The determination of\nflavor composition in this high energy flux is important because it presents a\nunique chance to probe our understanding of neutrino flavor oscillations at\ngamma factors >10^21. In this work we develop a new statistical technique to\nstudy the flavor composition of the incident neutrino flux, which is based on\nthe multipeak structure of the longitudinal profiles of very deep electron and\ntau neutrino horizontal air showers. Although these longitudinal profiles can\nbe observed by means of fluorescence telescopes placed over the Earth's\nsurface, orbital detectors are more suitable for neutrino observations owing to\ntheir much larger aperture. Therefore, we focus on the high energy region of\nthe neutrino spectrum relevant for observations with orbital detectors like the\nplanned JEM-EUSO telescope. \n\n"}
{"id": "1210.7691", "contents": "Title: Defining a weak lensing experiment in space Abstract: This paper describes the definition of a typical next-generation space-based\nweak gravitational lensing experiment. We first adopt a set of top-level\nscience requirements from the literature, based on the scale and depth of the\ngalaxy sample, and the avoidance of systematic effects in the measurements\nwhich would bias the derived shear values. We then identify and categorise the\ncontributing factors to the systematic effects, combining them with the correct\nweighting, in such a way as to fit within the top-level requirements. We\npresent techniques which permit the performance to be evaluated and explore the\nlimits at which the contributing factors can be managed. Besides the modelling\nbiases resulting from the use of weighted moments, the main contributing\nfactors are the reconstruction of the instrument point spread function (PSF),\nwhich is derived from the stellar images on the image, and the correction of\nthe charge transfer inefficiency (CTI) in the CCD detectors caused by radiation\ndamage. \n\n"}
{"id": "1210.8451", "contents": "Title: Venus transit, aureole and solar diameter Abstract: The possibility to measure the solar diameter using the transits of Mercury\nhas been exploited to investigate the past three centuries of its evolution and\nto calibrate these measurements made with satellites. This measurement\nbasically consists to compare the ephemerides of the internal contact timings\nwith the observed timings. The transits of Venus of 2004 and 2012 gave the\npossibility to apply this method, involving a planet with atmosphere, with the\nrefraction of solar light through it creating a luminous arc all around the\ndisk of the planet. The observations of the 2012 transit made to measure the\nsolar diameter participate to the project Venus Twilight Experiment to study\nthe aureole appearing around it near the ingress/egress phases. \n\n"}
{"id": "1211.0836", "contents": "Title: The distributed Slow Control System of the XENON100 Experiment Abstract: The XENON100 experiment, in operation at the Laboratori Nazionali del Gran\nSasso (LNGS) in Italy, was designed to search for evidence of dark matter\ninteractions inside a volume of liquid xenon using a dual-phase time projection\nchamber. This paper describes the Slow Control System (SCS) of the experiment\nwith emphasis on the distributed architecture as well as on its modular and\nexpandable nature. The system software was designed according to the rules of\nObject-Oriented Programming and coded in Java, thus promoting code reusability\nand maximum flexibility during commissioning of the experiment. The SCS has\nbeen continuously monitoring the XENON100 detector since mid 2008, remotely\nrecording hundreds of parameters on a few dozen instruments in real time, and\nsetting emergency alarms for the most important variables. \n\n"}
{"id": "1211.3800", "contents": "Title: SARAS: a precision system for measurement of the Cosmic Radio Background\n  and signatures from the Epoch of Reionization Abstract: SARAS is a correlation spectrometer purpose designed for precision\nmeasurements of the cosmic radio background and faint features in the sky\nspectrum at long wavelengths that arise from redshifted 21-cm from gas in the\nreionization epoch. SARAS operates in the octave band 87.5-175 MHz. We present\nherein the system design arguing for a complex correlation spectrometer\nconcept. The SARAS design concept provides a differential measurement between\nthe antenna temperature and that of an internal reference termination, with\nmeasurements in switched system states allowing for cancellation of additive\ncontaminants from a large part of the signal flow path including the digital\nspectrometer. A switched noise injection scheme provides absolute spectral\ncalibration. Additionally, we argue for an electrically small\nfrequency-independent antenna over an absorber ground. Various critical design\nfeatures that aid in avoidance of systematics and in providing calibration\nproducts for the parametrization of other unavoidable systematics are described\nand the rationale discussed. The signal flow and processing is analyzed and the\nresponse to noise temperatures of the antenna, reference termination and\namplifiers is computed. Multi-path propagation arising from internal\nreflections are considered in the analysis, which includes a harmonic series of\ninternal reflections. We opine that the SARAS design concept is advantageous\nfor precision measurement of the absolute cosmic radio background spectrum;\ntherefore, the design features and analysis methods presented here are expected\nto serve as a basis for implementations tailored to measurements of a\nmultiplicity of features in the background sky at long wavelengths, which may\narise from events in the dark ages and subsequent reionization era. \n\n"}
{"id": "1211.5043", "contents": "Title: Chemical complexity in astrophysical simulations: optimization and\n  reduction techniques Abstract: Chemistry has a key role in the evolution of the interstellar medium (ISM),\nso it is highly desirable to follow its evolution in numerical simulations.\nHowever, it may easily dominate the computational cost when applied to large\nsystems. In this paper we discuss two approaches to reduce these costs: (i)\nbased on computational strategies, and (ii) based on the properties and on the\ntopology of the chemical network. The first methods are more robust, while the\nsecond are meant to be giving important information on the structure of large,\ncomplex networks. To this aim we first discuss the numerical solvers for\nintegrating the system of ordinary differential equations (ODE) associated with\nthe chemical network. We then propose a buffer method that decreases the\ncomputational time spent in solving the ODE system. We further discuss a\nflux-based method that allows one to determine and then cut on the fly the less\nactive reactions. In addition we also present a topological approach for\nselecting the most probable species that will be active during the chemical\nevolution, thus gaining information on the chemical network that otherwise\nwould be difficult to retrieve. This topological technique can also be used as\nan a priori reduction method for any size network. We implemented these methods\ninto a 1D Lagrangian hydrodynamical code to test their effects: both classes\nlead to large computational speed-ups, ranging from x2 to x5. We have also\ntested some hybrid approaches finding that coupling the flux method with a\nbuffer strategy gives the best trade-off between robustness and speed-up of\ncalculations. \n\n"}
{"id": "1211.5105", "contents": "Title: Improved CLEAN reconstructions for rotation measure synthesis with\n  maximum likelihood estimation Abstract: The CLEAN deconvolution algorithm has well-known limitations due to the\nrestriction of locating point source model components on a discretized grid. In\nthis letter we demonstrate that these limitations are even more pronounced when\napplying CLEAN in the case of Rotation Measure (RM) synthesis imaging. We\nsuggest a modification that uses Maximum Likelihood estimation to adjust the\nCLEAN-derived sky model. We demonstrate through the use of mock one-dimensional\nRM synthesis observations that this technique shows significant improvement\nover standard CLEAN and gives results that are independent of the chosen image\npixelization. We suggest using this simple modification to CLEAN in upcoming\npolarization sensitive sky surveys. \n\n"}
{"id": "1211.6426", "contents": "Title: Constraining Self-Interacting Dark Matter with the Milky Way's dwarf\n  spheroidals Abstract: Self-Interacting Dark Matter is an attractive alternative to the Cold Dark\nMatter paradigm only if it is able to substantially reduce the central\ndensities of dwarf-size haloes while keeping the densities and shapes of\ncluster-size haloes within current constraints. Given the seemingly stringent\nnature of the latter, it was thought for nearly a decade that SIDM would be\nviable only if the cross section for self-scattering was strongly\nvelocity-dependent. However, it has recently been suggested that a constant\ncross section per unit mass of sigma_T/m~0.1cm^2/g is sufficient to accomplish\nthe desired effect. We explicitly investigate this claim using high resolution\ncosmological simulations of a Milky-Way size halo and find that, similarly to\nthe Cold Dark Matter case, such cross section produces a population of massive\nsubhaloes that is inconsistent with the kinematics of the classical dwarf\nspheroidals, in particular with the inferred slopes of the mass profiles of\nFornax and Sculptor. This problem is resolved if sigma_T/m~1cm^2/g at the dwarf\nspheroidal scales. Since this value is likely inconsistent with the halo shapes\nof several clusters, our results leave only a small window open for a\nvelocity-independent Self-Interacting Dark Matter model to work as a distinct\nalternative to Cold Dark Matter. \n\n"}
{"id": "1211.6433", "contents": "Title: On the Star Formation Efficiency of Turbulent Magnetized Clouds Abstract: We study the star formation efficiency (SFE) in simulations and observations\nof turbulent, magnetized, molecular clouds. We find that the probability\ndensity functions (PDFs) of the density and the column density in our\nsimulations with solenoidal, mixed, and compressive forcing of the turbulence,\nsonic Mach numbers of 3-50, and magnetic fields in the super- to the\ntrans-Alfvenic regime, all develop power-law tails of flattening slope with\nincreasing SFE. The high-density tails of the PDFs are consistent with\nequivalent radial density profiles, rho ~ r^(-kappa) with kappa ~ 1.5-2.5, in\nagreement with observations. Studying velocity-size scalings, we find that all\nthe simulations are consistent with the observed v ~ l^(1/2) scaling of\nsupersonic turbulence, and seem to approach Kolmogorov turbulence with v ~\nl^(1/3) below the sonic scale. The velocity-size scaling is, however, largely\nindependent of the SFE. In contrast, the density-size and column density-size\nscalings are highly sensitive to star formation. We find that the power-law\nslope alpha of the density power spectrum, P(rho,k) ~ k^alpha, or equivalently\nthe Delta-variance spectrum of column density, DV(Sigma,l) ~ l^(-alpha),\nswitches sign from alpha < 0 for SFE ~ 0 to alpha > 0 when star formation\nproceeds (SFE > 0). We provide a relation to compute the SFE from a measurement\nof alpha. Studying the literature, we find values ranging from alpha = -1.6 to\n+1.6 in observations covering scales from the large-scale atomic medium, over\ncold molecular clouds, down to dense star-forming cores. From those alpha\nvalues, we infer SFEs and find good agreement with independent measurements\nbased on young stellar object (YSO) counts, where available. Our SFE-alpha\nrelation provides an independent estimate of the SFE based on the column\ndensity map of a cloud alone, without requiring a priori knowledge of\nstar-formation activity or YSO counts. \n\n"}
{"id": "1211.6922", "contents": "Title: The sensitivity of Cherenkov telescopes to dark matter and astrophysical\n  anisotropies in the diffuse gamma-ray background Abstract: In this article, the capability of present (H.E.S.S., MAGIC, VERITAS) and\nplanned (CTA) ground-based Cherenkov telescope systems for detecting angular\nanisotropies in the diffuse gamma-ray background is investigated. Following up\non a study of the impact of instrumental characteristics (effective area, field\nof view, angular resolution, and background rejection efficiency), the first\npart examines the influence of different observational strategies, i.e. whether\na single deep observation or a splitting over multiple shallow fields is\npreferred. In the second part, the sensitivity to anisotropies generated by\nself-annihilating dark matter is studied for different common dark matter\nmodels. We find that a relative contribution of ~10% from dark matter\nannihilation to the extra-galactic diffuse gamma-ray background can be detected\nwith planned configurations of CTA. In terms of the thermally-averaged\nself-annihilation cross section, the sensitivity of CTA corresponds to values\nbelow the thermal freeze-out expectation <sigma v> = 3 x 10-26 cm3s-1 for dark\nmatter particles lighter than ~200 GeV. We stress the importance of\nconstraining anisotropies from unresolved astrophysical sources with currently\noperating instruments already, as a novel and complementary method for\ninvestigating the properties of TeV sources. \n\n"}
{"id": "1211.7222", "contents": "Title: Direct dark matter detection: the next decade Abstract: Direct dark matter searches are promising techniques to identify the nature\nof dark matter particles. I describe the future of this field of research,\nfocussing on the question of what can be achieved in the next decade. I will\npresent the main techniques and R&D projects that will allow to build so-called\nultimate WIMP detectors, capable of probing spin-independent interactions down\nto the unimaginably low cross section of 1e-48 cm2, before the irreducible\nneutrino background takes over. If a discovery is within the reach of a\nnear-future dark matter experiment, these detectors will be able to constrain\nWIMP properties such as its mass, scattering cross section and possibly spin.\nWith input from the LHC and from indirect searches, direct detection\nexperiments will hopefully allow to determine the local density and to\nconstrain the local phase-space structure of our dark matter halo. \n\n"}
{"id": "1212.1576", "contents": "Title: Cosmology with large redshift surveys Abstract: Galaxy redshift surveys are a major tool to address the most challenging\ncosmological problems facing cosmology, like the nature of dark energy and\nproperties dark matter. The same observations are useful for a much larger\nvariety of scientific applications, from the study of small bodies in the solar\nsystem, to properties of tidal streams in the Milky Way halo, to galaxy\nformation and evolution. Here I briefly discuss what is a redshift survey and\nhow it can be used to attack astrophysical and cosmological problems. I finish\nwith a brief description of a new survey, the Javalambre Physics of the\nAccelerating Universe Astrophysical Survey (JPAS), which will use an innovative\nsystem of 56 filters to map ~8000 square degrees on the sky. JPAS photometric\nsystem, besides providing accurate photometric redshifts useful for\ncosmological parameter estimation, will deliver a low-resolution spectrum at\neach pixel on the sky, allowing for the first time an almost all-sky IFU\nscience. \n\n"}
{"id": "1212.1923", "contents": "Title: Screening Vector Field Modifications of General Relativity Abstract: A screening mechanism for conformal vector-tensor modifications of general\nrelativity is proposed. The conformal factor depends on the norm of the vector\nfield and makes the field to vanish in high dense regions, whereas drives it to\na non-null value in low density environments. Such process occurs due to a\nspontaneous symmetry breaking mechanism and gives rise to both the screening of\nfifth forces as well as Lorentz violations. The cosmology and local constraints\nare also computed. \n\n"}
{"id": "1212.2371", "contents": "Title: The Effect of Probe Dynamics on Galactic Exploration Timescales Abstract: The travel time required for one civilisation to explore the Milky Way using\nprobes is a crucial component of Fermi's Paradox. Previous attempts to estimate\nthis travel time have assumed that the probe's motion is simple, moving at a\nconstant maximum velocity, with powered flight producing the necessary change\nin velocity required at each star to complete its chosen trajectory. This\napproach ignores lessons learned from interplanetary exploration, where orbital\nslingshot maneouvres can provide significant velocity boosts at little to no\nfuel cost. It is plausible that any attempt to explore the Galaxy would utilise\nsuch economising techniques, despite there being an upper limit to these\nvelocity boosts, related to the escape velocity of the object being used to\nprovide the slingshot.\n  In order to investigate the effects of these techniques, we present multiple\nrealisations of single probes exploring a small patch of the Milky Way. We\ninvestigate 3 separate scenarios, studying the slingshot effect on trajectories\ndefined by simple heuristics. These scenarios are: i) standard powered flight\nto the nearest unvisited star without using slingshot techniques; ii) flight to\nthe nearest unvisited star using slingshot techniques, and iii) flight to the\nnext unvisited star which provides the maximal velocity boost under a slingshot\ntrajectory.\n  We find that adding slingshot velocity boosts can decrease the travel time by\nup to two orders of magnitude over simple powered flight. In the third case,\nselecting a route which maximises velocity boosts also reduces the travel time\nrelative to powered flight, but by a much reduced factor. From these\nsimulations, we suggest that adding realistic probe trajectories tends to\nstrengthen Fermi's Paradox. \n\n"}
{"id": "1212.3201", "contents": "Title: Isotropy theorem for cosmological Yang-Mills theories Abstract: We consider homogeneous non-abelian vector fields with general potential\nterms in an expanding universe. We find a mechanical analogy with a system of N\ninteracting particles (with N the dimension of the gauge group) moving in three\ndimensions under the action of a central potential. In the case of bounded and\nrapid evolution compared to the rate of expansion, we show by making use of a\ngeneralization of the virial theorem that for arbitrary potential and\npolarization pattern, the average energy-momentum tensor is always diagonal and\nisotropic despite the intrinsic anisotropic evolution of the vector field. We\nconsider also the case in which a gauge-fixing term is introduced in the action\nand show that the average equation of state does not depend on such a term.\nFinally, we extend the results to arbitrary background geometries and show that\nthe average energy-momentum tensor of a rapidly evolving Yang-Mills fields is\nalways isotropic and has the perfect fluid form for any locally inertial\nobserver. \n\n"}
{"id": "1301.0295", "contents": "Title: A new way of detecting intergalactic baryons Abstract: For each photon wave packet of extragalactic light, the dispersion by\nline-of-sight intergalactic plasma causes an increase in the envelope width and\na chirp (drift) in the carrier frequency. It is shown that for continuous\nemission of many temporally overlapping wave packets with random epoch phases,\nsuch as quasars in the radio band, this in turn leads to quasi-periodic\nvariations in the intensity of the arriving light on timescales between the\ncoherence time (defined as the reciprocal of the bandwidth of frequency\nselection, taken here as of order 0.01 GHz for radio observations) and the\nstretched envelope, with most of the fluctuation power on the latter scale\nwhich is typically in the millisecond range for intergalactic dispersion. Thus,\nby monitoring quasar light curves on such short scales, it should be possible\nto determine the line-of-sight plasma column along the many directions and\ndistances to the various quasars, affording one a 3-dimensional picture of the\nionized baryons in the near universe. \n\n"}
{"id": "1301.1292", "contents": "Title: A hybrid SPH/N-body method for star cluster simulations Abstract: We present a new hybrid Smoothed Particle Hydrodynamics (SPH)/N-body method\nfor modelling the collisional stellar dynamics of young clusters in a live gas\nbackground. By deriving the equations of motion from Lagrangian mechanics we\nobtain a formally conservative combined SPH/N-body scheme. The SPH gas\nparticles are integrated with a 2nd order Leapfrog, and the stars with a 4th\norder Hermite scheme. Our new approach is intended to bridge the divide between\nthe detailed, but expensive, full hydrodynamical simulations of star formation,\nand pure N-body simulations of gas-free star clusters. We have implemented this\nhybrid approach in the SPH code SEREN (Hubber et al. 2011) and perform a series\nof simple tests to demonstrate the fidelity of the algorithm and its\nconservation properties. We investigate and present resolution criteria to\nadequately resolve the density field and to prevent strong numerical scattering\neffects. Future developments will include a more sophisticated treatment of\nbinaries. \n\n"}
{"id": "1301.3164", "contents": "Title: SYNMAG Photometry: A Fast Tool for Catalog-Level Matched Colors of\n  Extended Sources Abstract: Obtaining reliable, matched photometry for galaxies imaged by different\nobservatories represents a key challenge in the era of wide-field surveys\nspanning more than several hundred square degrees. Methods such as flux\nfitting, profile fitting, and PSF homogenization followed by matched-aperture\nphotometry are all computationally expensive. We present an alternative\nsolution called \"synthetic aperture photometry\" that exploits galaxy profile\nfits in one band to efficiently model the observed, PSF-convolved light profile\nin other bands and predict the flux in arbitrarily sized apertures. Because\naperture magnitudes are the most widely tabulated flux measurements in survey\ncatalogs, producing synthetic aperture magnitudes (SYNMAGs) enables very fast\nmatched photometry at the catalog level, without reprocessing imaging data. We\nmake our code public and apply it to obtain matched photometry between SDSS\nugriz and UKIDSS YJHK imaging, recovering red-sequence colors and photometric\nredshifts with a scatter and accuracy as good as if not better than\nFWHM-homogenized photometry from the GAMA Survey. Finally, we list some\nspecific measurements that upcoming surveys could make available to facilitate\nand ease the use of SYNMAGs. \n\n"}
{"id": "1301.3690", "contents": "Title: Characterization of the sodium layer at Cerro Pachon, and impact on\n  laser guide star performance Abstract: Detailed knowledge of the mesopheric sodium layer characteristics is crucial\nto estimate and optimize the performance of Laser Guide Star (LGS) assisted\nAdaptive Optics (AO) systems. In this paper, we present an analysis of two sets\nof data on the mesospheric sodium layer. The first set comes from a laser\nexperiment that was carried out at Cerro Tololo to monitor the abundance and\naltitude of the mesospheric sodium in 2001, during six runs covering a period\nof one year. This data is used to derive the mesospheric sodium column density,\nthe sodium layer thickness and the temporal behavior of the sodium layer mean\naltitude. The second set of data was gathered during the first year of the\nGemini MCAO System (GeMS) commissioning and operations. GeMS uses five LGS to\nmeasure and compensate for atmospheric distortions. Analysis of the LGS\nwavefront sensor data provides information about the sodium photon return and\nthe spot elongation seen by the WFS. All these parameters show large variations\non a yearly, nightly and hourly basis, affecting the LGS brightness, shape and\nmean altitude. The sodium photon return varies by a factor of three to four\nover a year, and can change by a factor of two over a night. In addition, the\ncomparison of the photon returns obtained in 2001 with those measured a decade\nlater using GeMS shows a significant difference in laser format efficiencies.\nWe find that the temporal power spectrum of the sodium mean altitude follows a\nlinear trend, in good agreement with the results reported by Pfrommer & Hickson\n(2010). \n\n"}
{"id": "1301.4496", "contents": "Title: Panchromatic spectral energy distributions of Herschel sources Abstract: (abridged) Far-infrared Herschel photometry from the PEP and HerMES programs\nis combined with ancillary datasets in the GOODS-N, GOODS-S, and COSMOS fields.\nBased on this rich dataset, we reproduce the restframe UV to FIR ten-colors\ndistribution of galaxies using a superposition of multi-variate Gaussian modes.\nThe median SED of each mode is then fitted with a modified version of the\nMAGPHYS code that combines stellar light, emission from dust heated by stars\nand a possible warm dust contribution heated by an AGN. The defined Gaussian\ngrouping is also used to identify rare sources. The zoology of outliers\nincludes Herschel-detected ellipticals, very blue z~1 Ly-break galaxies,\nquiescent spirals, and torus-dominated AGN with star formation. Out of these\ngroups and outliers, a new template library is assembled, consisting of 32 SEDs\ndescribing the intrinsic scatter in the restframe UV-to-submm colors of\ninfrared galaxies. This library is tested against L(IR) estimates with and\nwithout Herschel data included, and compared to eight other popular methods\noften adopted in the literature. When implementing Herschel photometry, these\napproaches produce L(IR) values consistent with each other within a median\nabsolute deviation of 10-20%, the scatter being dominated more by fine tuning\nof the codes, rather than by the choice of SED templates. Finally, the library\nis used to classify 24 micron detected sources in PEP GOODS fields. AGN appear\nto be distributed in the stellar mass (M*) vs. star formation rate (SFR) space\nalong with all other galaxies, regardless of the amount of infrared luminosity\nthey are powering, with the tendency to lie on the high SFR side of the \"main\nsequence\". The incidence of warmer star-forming sources grows for objects with\nhigher specific star formation rates (sSFR), and they tend to populate the\n\"off-sequence\" region of the M*-SFR-z space. \n\n"}
{"id": "1301.5407", "contents": "Title: The catalogue of positions of optically bright extragalactic radio\n  sources OBRS-2 Abstract: It is anticipated that future space-born missions, such as Gaia, will be able\nto determine in optical domain positions of more than 100,000 bright quasars\nwith sub-mas accuracies that are comparable to very long baseline\ninterferometry (VLBI) accuracies. Comparisons of coordinate systems from\nspace-born missions and from VLBI will be very important, first for\ninvestigation of possible systematic errors, second for investigation of\npossible shift between centroids of radio and optical emissions in active\ngalaxy nuclea. In order to make such a comparison more robust, a program of\ndensification of the grid of radio sources detectable with both VLBI and Gaia\nwas launched in 2006. In the second observing campaign a set of 290 objects\nfrom the list of 398 compact extragalactic radio sources with declinations\ngreater -10 deg was observed with the VLBA+EVN in 2010-2011 with the primary\ngoal of producing their images with milliarcsecond resolution. These sources\nare brighter than 18 magnitude at V band. In this paper coordinates of observed\nsources have been derived with milliarcsecond accuracies from analysis of these\nVLBI observations following the method of absolute astrometry and their images\nwere produced. The catalogue of positions of 295 target sources and estimates\nof their correlated flux densities at 2.2 and 8.4 GHz is presented. The\naccuracies of source coordinates are in a range of 2 to 200 mas, with the\nmedian 3.2 mas. \n\n"}
{"id": "1301.6168", "contents": "Title: Evidence for a Milky Way Tidal Stream Reaching Beyond 100 kpc Abstract: We present the analysis of 1,207 RR Lyrae found in photometry taken by the\nCatalina Survey's Mount Lemmon telescope. By combining accurate distances for\nthese stars with measurements for ~14,000 type-AB RR Lyrae from the Catalina\nSchmid telescope, we reveal an extended association that reaches Galactocentric\ndistances beyond 100 kpc and overlaps the Sagittarius streams system. This\nresult confirms earlier evidence for the existence of an outer halo tidal\nstream resulting from a disrupted stellar system. By comparing the RR Lyrae\nsource density with that expected based on halo models, we find the detection\nhas ~8 sigma significance. We investigate the distances, radial velocities,\nmetallicities, and period-amplitude distribution of the RR Lyrae. We find that\nboth radial velocities and distances are inconsistent with current models of\nthe Sagittarius stream. We also find tentative evidence for a division in\nsource metallicities for the most distant sources. Following prior analyses, we\ncompare the locations and distances of the RR Lyrae with photometrically\nselected candidate horizontal branch stars and find supporting evidence that\nthis structure spans at least 60 deg of the sky. We investigate the prospects\nof an association between the stream and unusual globular cluster NGC 2419. \n\n"}
{"id": "1301.6974", "contents": "Title: The End of an Era - The Population III to Population II Transition and\n  the Near Infrared Background Abstract: There are only a few ways to constrain the Era of Reionization and the\nproperties of high redshift (z>6) stars through observations. Here, we discuss\none of these observables - the spectrum of the Near Infrared Background - and\nhow it is potentially affected by the transition from Population III to\nPopulation II stars. The stronger Lyman-alpha emission expected from massive\nPopulation III stars could result in a 'bump' in the spectrum of the Near\nInfrared Background (referred to in this work as the Lyman-alpha bump). The\nstrength and shape of this bump can reveal properties of Population III stars.\nThe Lyman-alpha bump is predicted to be higher if Population III stars are more\nmassive and present at lower redshifts. The shape of the bump is governed by\nthe star formation rate and the time it takes Population III stars to\ntransition to Population II stars. If Population III stars are indeed massive,\na bump is predicted as long as Population III stars exist at z < 15, even if\ntheir star formation rate is as low as 10^-7 M_sun yr^-1 Mpc^-3. This means\nthat there may be some observational signature in the Near Infrared Background\nof small pockets of metal-free gas forming Population III stars at z ~ 6, even\nif they are quite rare. \n\n"}
{"id": "1302.0534", "contents": "Title: A Concept for A Dark Matter Detector Using Liquid Helium-4 Abstract: Direct searches for light dark matter particles (mass $<10$ GeV) are\nespecially challenging because of the low energies transferred in elastic\nscattering to typical heavy nuclear targets. We investigate the possibility of\nusing liquid Helium-4 as a target material, taking advantage of the favorable\nkinematic matching of the Helium nucleus to light dark matter particles. Monte\nCarlo simulations are performed to calculate the charge, scintillation, and\ntriplet helium molecule signals produced by recoil He ions, for a variety of\nenergies and electric fields. We show that excellent background rejection can\nbe achieved based on the ratios between different signal channels. We also\npresent some concepts for a liquid-helium-based dark matter detector. Key to\nthe proposed approach is the use of a large electric field to extract electrons\nfrom the event site, and the amplification of this charge signal, through\nproportional scintillation, liquid electroluminescence, or roton emission. The\nsensitivity of the proposed detector to light dark matter particles is\nestimated for various electric fields and light collection efficiencies. \n\n"}
{"id": "1302.0844", "contents": "Title: On the effect of the Cosmic Microwave Background in high-redshift\n  (sub-)millimeter observations Abstract: Modern (sub-)millimeter interferometers enable the measurement of the cool\ngas and dust emission of high-redshift galaxies (z>5). However, at these\nredshifts the cosmic microwave background (CMB) temperature is higher,\napproaching, and even exceeding, the temperature of cold dust and molecular gas\nobserved in the local Universe. In this paper, we discuss the impact of the\nwarmer CMB on (sub-)millimeter observations of high-redshift galaxies. The CMB\naffects the observed (sub-)millimeter dust continuum and the line emission\n(e.g. carbon monoxide, CO) in two ways: (i) it provides an additional source of\n(both dust and gas) heating; and (ii) it is a non-negligible background against\nwhich the line and continuum emission are measured. We show that these two\ncompeting processes affect the way we interpret the dust and gas properties of\nhigh-redshift galaxies using spectral energy distribution models. We quantify\nthese effects and provide correction factors to compute what fraction of the\nintrinsic dust (and line) emission can be detected against the CMB as a\nfunction of frequency, redshift and temperature. We discuss implications on the\nderived properties of high-redshift galaxies from (sub-)millimeter data.\nSpecifically, the inferred dust and molecular gas masses can be severely\nunderestimated for cold systems if the impact of the CMB is not properly taken\ninto account. \n\n"}
{"id": "1302.1582", "contents": "Title: Evolution along the sequence of S0 Hubble types induced by dry minor\n  mergers. II - Bulge-disk coupling in the photometric relations through\n  merger-induced internal secular evolution Abstract: Galaxy mergers are considered as questionable mechanisms for the evolution of\nlenticular galaxies (S0's), on the basis that even minor ones induce structural\nchanges that are difficult to reconcile with the strong bulge-disk coupling\nobserved in the photometric scaling relations of S0's. We check if the\nevolution induced onto S0's by dry intermediate and minor mergers can reproduce\ntheir photometric scaling relations, analysing the bulge-disk decompositions of\nthe merger simulations presented in Eliche-Moral et al. (2012). The mergers\ninduce an evolution in the photometric planes compatible with the data of S0's,\neven in those ones indicating a strong bulge-disk coupling. The mergers drive\nthe formation of the observed photometric relation in some cases, whereas they\ninduce a slight dispersion compatible with data in others. Therefore, this\nevolutionary mechanism tends to preserve these scaling relations. In those\nphotometric planes where the morphological types segregate, the mergers always\ninduce evolution towards the region populated by S0's. The structural coupling\nof the bulge and the disk is preserved or reinforced because the mergers\ntrigger internal secular processes in the primary disk that induce significant\nbulge growth, even although these models do not induce bars. Intermediate and\nminor mergers can thus be considered as plausible mechanisms for the evolution\nof S0's attending to their photometric scaling relations, as they can preserve\nand even strengthen any pre-existing structural bulge-disk coupling, triggering\nsignificant internal secular evolution (even in the absence of bars or\ndissipational effects). This means that it may be difficult to isolate the\neffects of pure internal secular evolution from those of the merger-driven one\nin present-day early-type disks (abridged). \n\n"}
{"id": "1302.1721", "contents": "Title: Bayesian Model Averaging in Astrophysics: A Review Abstract: We review the use of Bayesian Model Averaging in astrophysics. We first\nintroduce the statistical basis of Bayesian Model Selection and Model\nAveraging. We discuss methods to calculate the model-averaged posteriors,\nincluding Markov Chain Monte Carlo (MCMC), nested sampling, Population Monte\nCarlo, and Reversible Jump MCMC. We then review some applications of Bayesian\nModel Averaging in astrophysics, including measurements of the dark energy and\nprimordial power spectrum parameters in cosmology, cluster weak lensing and\nSunyaev-Zel'dovich effect data, estimating distances to Cepheids, and\nclassifying variable stars. \n\n"}
{"id": "1302.1903", "contents": "Title: An Efficient Approximation to the Likelihood for Gravitational Wave\n  Stochastic Background Detection Using Pulsar Timing Data Abstract: Direct detection of gravitational waves by pulsar timing arrays will become\nfeasible over the next few years. In the low frequency regime ($10^{-7}$ Hz --\n$10^{-9}$ Hz), we expect that a superposition of gravitational waves from many\nsources will manifest itself as an isotropic stochastic gravitational wave\nbackground. Currently, a number of techniques exist to detect such a signal;\nhowever, many detection methods are computationally challenging. Here we\nintroduce an approximation to the full likelihood function for a pulsar timing\narray that results in computational savings proportional to the square of the\nnumber of pulsars in the array. Through a series of simulations we show that\nthe approximate likelihood function reproduces results obtained from the full\nlikelihood function. We further show, both analytically and through\nsimulations, that, on average, this approximate likelihood function gives\nunbiased parameter estimates for astrophysically realistic stochastic\nbackground amplitudes. \n\n"}
{"id": "1302.2963", "contents": "Title: Geant4 Applications for Modeling Molecular Transport in Complex Vacuum\n  Geometries Abstract: We discuss a novel use of the Geant4 simulation toolkit to model molecular\ntransport in a vacuum environment, in the molecular flow regime. The Geant4\ntoolkit was originally developed by the high energy physics community to\nsimulate the interactions of elementary particles within complex detector\nsystems. Here its capabilities are utilized to model molecular vacuum transport\nin geometries where other techniques are impractical. The techniques are\nverified with an application representing a simple vacuum geometry that has\nbeen studied previously both analytically and by basic Monte Carlo simulation.\nWe discuss the use of an application with a very complicated geometry, that of\nthe Large Synoptic Survey Telescope camera cryostat, to determine probabilities\nof transport of contaminant molecules to optical surfaces where control of\ncontamination is crucial. \n\n"}
{"id": "1302.6253", "contents": "Title: The Cluster and Field Galaxy AGN Fraction at z = 1 to 1.5: Evidence for\n  a Reversal of the Local Anticorrelation Between Environment and AGN Fraction Abstract: The fraction of cluster galaxies that host luminous AGN is an important probe\nof AGN fueling processes, the cold ISM at the centers of galaxies, and how\ntightly black holes and galaxies co-evolve. We present a new measurement of the\nAGN fraction in a sample of 13 clusters of galaxies (M >= 10^{14} Msun) at\n1<z<1.5 selected from the Spitzer/IRAC Shallow Cluster Survey, as well as the\nfield fraction in the immediate vicinity of these clusters, and combine these\ndata with measurements from the literature to quantify the relative evolution\nof cluster and field AGN from the present to z~3. We estimate that the cluster\nAGN fraction at 1<z<1.5 is f_A = 3.0^{+2.4}_{-1.4}% for AGN with a rest-frame,\nhard X-ray luminosity greater than L_{X,H} >= 10^{44} erg/s. This fraction is\nmeasured relative to all cluster galaxies more luminous than M*_{3.6}(z)+1,\nwhere M*_{3.6}(z) is the absolute magnitude of the break in the galaxy\nluminosity function at the cluster redshift in the IRAC 3.6um bandpass. The\ncluster AGN fraction is 30 times greater than the 3sigma upper limit on the\nvalue for AGN of similar luminosity at z~0.25, as well as more than an order of\nmagnitude greater than the AGN fraction at z~0.75. AGN with L_{X,H} >= 10^{43}\nerg/s exhibit similarly pronounced evolution with redshift. In contrast with\nthe local universe, where the luminous AGN fraction is higher in the field than\nin clusters, the X-ray and MIR-selected AGN fractions in the field and clusters\nare consistent at 1<z<1.5. This is evidence that the cluster AGN population has\nevolved more rapidly than the field population from z~1.5 to the present. This\nenvironment-dependent AGN evolution mimics the more rapid evolution of\nstar-forming galaxies in clusters relative to the field. \n\n"}
{"id": "1302.6628", "contents": "Title: Probing the mass assembly of massive nearby galaxies with deep imaging Abstract: According to a popular scenario supported by numerical models, the mass\nassembly and growth of massive galaxies, in particular the Early-Type Galaxies\n(ETGs), is, below a redshift of 1, mainly due to the accretion of multiple\ngas--poor satellites. In order to get observational evidence of the role played\nby minor dry mergers, we are obtaining extremely deep optical images of a\ncomplete volume limited sample of nearby ETGs.\n  These observations, done with the CFHT as part of the \\AD, NGVS and MATLAS\nprojects, reach a stunning 28.5)29 mag.arcsec-2 surface brightness limit in the\ng' band. They allow us to detect the relics of past collisions such as faint\nstellar tidal tails as well as the very extended stellar halos which keep the\nmemory of the last episodes of galactic accretion.\n  Images and preliminary results from this on-going survey are presented, in\nparticular a possible correlation between the fine structure index (which\nparametrizes the amount of tidal perturbation) of the ETGs, their stellar mass,\neffective radius and gas content. \n\n"}
{"id": "1303.0008", "contents": "Title: Exploring Vainshtein mechanism on adaptively refined meshes Abstract: There has been a lot of research interest in modified gravity theories which\nutilise the Vainshtein mechanism to recover standard general relativity in\nregions with high matter density, such as the Dvali-Gabadadze-Porrati and\nGalileon models. The strong nonlinearity in the field equations of these\ntheories implies that accurate theoretical predictions could only be made using\nhigh-resolution cosmological simulations. Previously, such simulations were\nusually done on regular meshes, which limits both their performance and the\naccuracy. In this paper, we report the development of a new algorithm and code,\nbased on ECOSMOG, that uses adaptive mesh refinements to improve the efficiency\nand precision in simulating the models with Vainshtein mechanism. We have made\nvarious code tests against the numerical reliability, and found consistency\nwith previous simulations. We also studied the velocity field in the\nself-accelerating branch of the DGP model. The code, parallelised using MPI, is\nsuitable for large cosmological simulations of Galileon-type modified gravity\ntheories. \n\n"}
{"id": "1303.0028", "contents": "Title: The Einstein@Home search for radio pulsars and PSR J2007+2722 discovery Abstract: Einstein@Home aggregates the computer power of hundreds of thousands of\nvolunteers from 193 countries, to search for new neutron stars using data from\nelectromagnetic and gravitational-wave detectors. This paper presents a\ndetailed description of the search for new radio pulsars using Pulsar ALFA\nsurvey data from the Arecibo Observatory. The enormous computing power allows\nthis search to cover a new region of parameter space; it can detect pulsars in\nbinary systems with orbital periods as short as 11 minutes. We also describe\nthe first Einstein@Home discovery, the 40.8 Hz isolated pulsar PSR J2007+2722,\nand provide a full timing model. PSR J2007+2722's pulse profile is remarkably\nwide with emission over almost the entire spin period. This neutron star is\nmost likely a disrupted recycled pulsar, about as old as its characteristic\nspin-down age of 404 Myr. However there is a small chance that it was born\nrecently, with a low magnetic field. If so, upper limits on the X-ray flux\nsuggest but can not prove that PSR J2007+2722 is at least ~ 100 kyr old. In the\nfuture, we expect that the massive computing power provided by volunteers\nshould enable many additional radio pulsar discoveries. \n\n"}
{"id": "1303.0897", "contents": "Title: A new technique for the determination of the initial mass function in\n  unresolved stellar populations Abstract: We present a new technique for the determination of the low-mass slope\n($\\alpha_1$; $M_* < 0.5 M_{\\odot}$) of the present day stellar mass function\n(PDMF) using the pixel space fitting of integrated light spectra. It can be\nused to constrain the initial mass function (IMF) of stellar systems with\nrelaxation timescales exceeding the Hubble time and testing the IMF\nuniversality hypothesis. We provide two versions of the technique: (1) a fully\nunconstrained determination of the age, metallicity, and $\\alpha_1$ and (2) a\nconstrained fitting by imposing the externally determined mass-to-light ratio\nof the stellar population. We have tested our approach by Monte-Carlo\nsimulations using mock spectra and conclude that: (a) age, metallicity and\n$\\alpha_1$ can be precisely determined by applying the unconstrained version of\nthe code to high signal-to-noise datasets (S/N=100, R=7000 yield $\\Delta\n\\alpha_1 \\approx 0.1$); (b) the $M/L$ constraint significantly improves the\nprecision and reduces the degeneracies, however its systematic errors will\ncause biased $\\alpha_1$ estimates; (c) standard Lick indices cannot constrain\nthe PDMF because they miss most of the mass function sensitive spectral\nfeatures; (d) the $\\alpha_1$ determination remains unaffected by the high-mass\nIMF shape ($\\alpha_3$; $M_* \\ge 1 M_{\\odot}$) variation for stellar systems\nolder than 8 Gyr, while the intermediate-mass IMF slope ($\\alpha_2$; $0.5 \\le\nM_* < 1 M_{\\odot}$) may introduce biases into the best-fitting $\\alpha_1$\nvalues if it is different from the canonical value $\\alpha_2 = 2.3$. We\nanalysed observed intermediate resolution spectra of ultracompact dwarf\ngalaxies with our technique and demonstrated its applicability to real data. \n\n"}
{"id": "1303.3871", "contents": "Title: A Measurement of Atomic X-ray Yields in Exotic Atoms and Implications\n  for an Antideuteron-Based Dark Matter Search Abstract: The General AntiParticle Spectrometer (GAPS) is a novel approach for the\nindirect dark matter search that exploits cosmic antideuterons. GAPS utilizes a\ndistinctive detection method using atomic X-rays and charged particles from the\nexotic atom as well as the timing, stopping range and dE/dX energy deposit of\nthe incoming particle, which provides excellent antideuteron identification. In\nanticipation of a future balloon experiment, an accelerator test was conducted\nin 2004 and 2005 at KEK, Japan, in order to prove the concept and to precisely\nmeasure the X-ray yields of antiprotonic exotic atoms formed with different\ntarget materials [1]. The X-ray yields of the exotic atoms with Al and S\ntargets were obtained as ~ 75%, which are higher than were previously assumed\nin [2]. A simple, but comprehensive cascade model has been developed not only\nto evaluate the measurement results but also to predict the X-ray yields of the\nexotic atoms formed with any materials in the GAPS instrument. The cascade\nmodel is extendable to any kind of exotic atom (any negatively charged\ncascading particles with any target materials), and it was compared and\nvalidated with other experimental data and cascade models for muonic and\nantiprotonic exotic atoms. The X-ray yields of the antideuteronic exotic atoms\nare predicted with a simple cascade model and the sensitivity for the GAPS\nantideuteron search was estimated for the proposed long duration balloon\nprogram [3], which suggests that GAPS has a strong potential to detect\nantideuterons as a dark matter signature. A GAPS prototype flight (pGAPS) was\nlaunched successfully from the JAXA/ISAS balloon facility in Hokkaido, Japan in\nsummer 2012 [4, 5] and a proposed GAPS science flight is to fly from Antarctica\nin the austral summer of 2017-2018. \n\n"}
{"id": "1303.4717", "contents": "Title: Gamma Rays from Top-Mediated Dark Matter Annihilations Abstract: Lines in the energy spectrum of gamma rays are a fascinating experimental\nsignal, which are often considered \"smoking gun\" evidence of dark matter\nannihilation. The current generation of gamma ray observatories are currently\nclosing in on parameter space of great interest in the context of dark matter\nwhich is a thermal relic. We consider theories in which the dark matter's\nprimary connection to the Standard Model is via the top quark, realizing strong\ngamma ray lines consistent with a thermal relic through the forbidden channel\nmechanism proposed in the Higgs in Space Model. We consider realistic\nUV-completions of the Higgs in Space and related theories, and show that a rich\nstructure of observable gamma ray lines is consistent with a thermal relic as\nwell as constraints from dark matter searches and the LHC. Particular attention\nis paid to the one loop contributions to the continuum gamma rays, which can\neasily swamp the line signals in some cases, and have been largely overlooked\nin previous literature. \n\n"}
{"id": "1303.5063", "contents": "Title: Planck 2013 results. II. Low Frequency Instrument data processing Abstract: We describe the data processing pipeline of the Planck Low Frequency\nInstrument (LFI) data processing centre (DPC) to create and characterize\nfull-sky maps based on the first 15.5 months of operations at 30, 44 and 70\nGHz. In particular, we discuss the various steps involved in reducing the data,\nstarting from telemetry packets through to the production of cleaned,\ncalibrated timelines and calibrated frequency maps. Data are continuously\ncalibrated using the modulation induced on the mean temperature of the cosmic\nmicrowave background radiation by the proper motion of the spacecraft. Sky\nsignals other than the dipole are removed by an iterative procedure based on\nsimultaneous fitting of calibration parameters and sky maps. Noise properties\nare estimated from time-ordered data after the sky signal has been removed,\nusing a generalized least square map-making algorithm. A destriping code\n(Madam) is employed to combine radiometric data and pointing information into\nsky maps, minimizing the variance of correlated noise. Noise covariance\nmatrices, required to compute statistical uncertainties on LFI and Planck\nproducts, are also produced. Main beams are estimated down to the -20 dB level\nusing Jupiter transits, which are also used for the geometrical calibration of\nthe focal plane. \n\n"}
{"id": "1303.5065", "contents": "Title: Planck 2013 results. IV. Low Frequency Instrument beams and window\n  functions Abstract: This paper presents the characterization of the in-flight beams, the beam\nwindow functions and the associated uncertainties for the Planck Low Frequency\nInstrument (LFI). Knowledge of the beam profiles is necessary for determining\nthe transfer function to go from the observed to the actual sky anisotropy\npower spectrum. The main beam distortions affect the beam window function,\ncomplicating the reconstruction of the anisotropy power spectrum at high\nmultipoles, whereas the sidelobes affect the low and intermediate multipoles.\nThe in-flight assessment of the LFI main beams relies on the measurements\nperformed during Jupiter observations. By stacking the data from multiple\nJupiter transits, the main beam profiles are measured down to -20 dB at 30 and\n44 GHz, and down to -25 dB at 70 GHz. The main beam solid angles are determined\nto better than 0.2% at each LFI frequency band. The Planck pre-launch optical\nmodel is conveniently tuned to characterize the main beams independently of any\nnoise effects. This approach provides an optical model whose beams fully\nreproduce the measurements in the main beam region, but also allows a\ndescription of the beams at power levels lower than can be achieved by the\nJupiter measurements themselves. The agreement between the simulated beams and\nthe measured beams is better than 1% at each LFI frequency band. The simulated\nbeams are used for the computation of the window functions for the effective\nbeams. The error budget for the window functions is estimated from both main\nbeam and sidelobe contributions, and accounts for the radiometer bandshapes.\nThe total uncertainties in the effective beam window functions are: 2% and 1.2%\nat 30 and 44 GHz, respectively (at $\\ell \\approx 600$), and 0.7% at 70 GHz (at\n$\\ell \\approx 1000$). \n\n"}
{"id": "1303.5066", "contents": "Title: Planck 2013 results. V. LFI calibration Abstract: We discuss the methods employed to photometrically calibrate the data\nacquired by the Low Frequency Instrument on Planck. Our calibration is based on\na combination of the Orbital Dipole plus the Solar Dipole, caused respectively\nby the motion of the Planck spacecraft with respect to the Sun and by motion of\nthe Solar System with respect to the CMB rest frame. The latter provides a\nsignal of a few mK with the same spectrum as the CMB anisotropies and is\nvisible throughout the mission. In this data release we rely on the\ncharacterization of the Solar Dipole as measured by WMAP. We also present\npreliminary results (at 44GHz only) on the study of the Orbital Dipole, which\nagree with the WMAP value of the Solar System speed within our uncertainties.\nWe compute the calibration constant for each radiometer roughly once per hour,\nin order to keep track of changes in the detectors' gain. Since non-idealities\nin the optical response of the beams proved to be important, we implemented a\nfast convolution algorithm which considers the full beam response in estimating\nthe signal generated by the dipole. Moreover, in order to further reduce the\nimpact of residual systematics due to sidelobes, we estimated time variations\nin the calibration constant of the 30GHz radiometers (the ones with the largest\nsidelobes) using the signal of a reference load. We have estimated the\ncalibration accuracy in two ways: we have run a set of simulations to assess\nthe impact of statistical errors and systematic effects in the instrument and\nin the calibration procedure, and we have performed a number of consistency\nchecks on the data and on the brightness temperature of Jupiter. Calibration\nerrors for this data release are expected to be about 0.6% at 44 and 70 GHz,\nand 0.8% at 30 GHz. (Abriged.) \n\n"}
{"id": "1303.6116", "contents": "Title: Using electromagnetic observations to aid gravitational-wave parameter\n  estimation of compact binaries observed with LISA II: The effect of knowing\n  the sky position Abstract: In this follow-up paper, we continue our study of the effect of using\nknowledge from electromagnetic observations in the gravitational wave (GW) data\nanalysis of Galactic binaries that are predicted to be observed by the new\n\\textit{Laser Interferometer Space Antenna} in the low-frequency range,\n$10^{-4} \\:\\mathrm{Hz}<f<1 \\:\\mathrm{Hz}$. In the first paper, we have shown\nthat the strong correlation between amplitude and inclination can be used for\nmildly inclined binaries to improve the uncertainty in amplitude, and that this\ncorrelation depends on the inclination of the system. In this paper we\ninvestigate the overall effect of the other orientation parameters, namely the\nsky position and the polarisation angle. We find that after the inclination,\nthe ecliptic latitude of the source has the strongest effect in determining the\nGW parameter uncertainties. We ascertain that the strong correlation we found\npreviously, only depends on the inclination of the source and not on the other\norientation parameters. We find that knowing the sky position of the source\nfrom electromagnetic data can reduce the GW parameter uncertainty up to a\nfactor of $\\sim 2$, depending on the inclination and the ecliptic latitude of\nthe system. Knowing the sky position and inclination can reduce the uncertainty\nin amplitude by a factor larger than 40. We also find that unphysical errors in\nthe inclinations, which we found when using the Fisher matrix, can affect the\ncorresponding uncertainties in the amplitudes, which need to be corrected. \n\n"}
{"id": "1304.0597", "contents": "Title: Astrophysical data mining with GPU. A case study: genetic classification\n  of globular clusters Abstract: We present a multi-purpose genetic algorithm, designed and implemented with\nGPGPU / CUDA parallel computing technology. The model was derived from our CPU\nserial implementation, named GAME (Genetic Algorithm Model Experiment). It was\nsuccessfully tested and validated on the detection of candidate Globular\nClusters in deep, wide-field, single band HST images. The GPU version of GAME\nwill be made available to the community by integrating it into the web\napplication DAMEWARE (DAta Mining Web Application REsource\n(http://dame.dsf.unina.it/beta_info.html), a public data mining service\nspecialized on massive astrophysical data. Since genetic algorithms are\ninherently parallel, the GPGPU computing paradigm leads to a speedup of a\nfactor of 200x in the training phase with respect to the CPU based version. \n\n"}
{"id": "1304.0833", "contents": "Title: A new way to explain the 511 keV signal from the center of the Galaxy\n  and experimental search for small hydrogen Abstract: The first detected gamma-ray line originating from outside the solar system\nis the 511 keV emission from the center of our Galaxy. The widely accepted\nexplanation attributes this signal to electron-positron annihilation. However,\ndespite over 30 years of extensive theoretical and observational research, the\nprimary sources of these positrons remain unidentified.\n  In this paper, we propose an alternative explanation: the observed signal\narises from atomic transitions involving a small hydrogen atom, where an\nelectron is captured into a tightly bound orbit around a proton. We review the\ncurrent status of experimental searches for small hydrogen, both in\nastrophysical data and laboratory experiments, and propose new methods for its\ndirect detection in the lab. Additionally, we explore whether small hydrogen\ncould be a candidate for dark matter. \n\n"}
{"id": "1304.1710", "contents": "Title: Design and Operation of FACT -- The First G-APD Cherenkov Telescope Abstract: The First G-APD Cherenkov Telescope (FACT) is designed to detect cosmic\ngamma-rays with energies from several hundred GeV up to about 10 TeV using the\nImaging Atmospheric Cherenkov Technique. In contrast to former or existing\ntelescopes, the camera of the FACT telescope is comprised of solid-state\nGeiger-mode Avalanche Photodiodes (G-APD) instead of photomultiplier tubes for\nphoto detection. It is the first full-scale device of its kind employing this\nnew technology. The telescope is operated at the Observatorio del Roque de los\nMuchachos (La Palma, Canary Islands, Spain) since fall 2011. This paper\ndescribes in detail the design, construction and operation of the system,\nincluding hardware and software aspects. Technical experiences gained after one\nyear of operation are discussed and conclusions with regard to future projects\nare drawn. \n\n"}
{"id": "1304.2404", "contents": "Title: DESPOTIC -- A New Software Library to Derive the Energetics and SPectra\n  of Optically Thick Interstellar Clouds Abstract: I describe DESPOTIC, a code to Derive the Energetics and SPectra of Optically\nThick Interstellar Clouds. DESPOTIC represents such clouds using a one-zone\nmodel, and can calculate line luminosities, line cooling rates, and in\nrestricted cases line profiles using an escape probability formalism. It also\nincludes approximate treatments of the dominant heating, cooling, and chemical\nprocesses for the cold interstellar medium, including cosmic ray and X-ray\nheating, grain photoelectric heating, heating of the dust by infrared and\nultraviolet radiation, thermal cooling of the dust, collisional energy exchange\nbetween dust and gas, and a simple network for carbon chemistry. Based on these\nheating, cooling, and chemical rates, DESPOTIC can calculate clouds'\nequilibrium gas and dust temperatures, equilibrium carbon chemical state, and\ntime-dependent thermal and chemical evolution. The software is intended to\nallow rapid and interactive calculation of clouds' characteristic temperatures,\nidentification of their dominant heating and cooling mechanisms, and prediction\nof their observable spectra across a wide range of interstellar environments.\nDESPOTIC is implemented as a Python package, and is released under the GNU\nGeneral Public License. \n\n"}
{"id": "1304.4592", "contents": "Title: Investigating Bar Structure of Disc Galaxies via PRIMAL: A\n  PaRtIcle-by-particle M2M ALgorithm Abstract: We have modified our particle-by-particle adaptation of the made-to-measure\n(M2M) method, with the aim of modelling the Galactic disc from upcoming\nGalactic stellar survey data. In our new particle-by-particle M2M algorithm,\nPRIMAL, the observables of the target system are compared with those of the\nmodel galaxy at the position of the target stars, i.e. particles. The mass of\nthe model particles are adjusted to reproduce the observables of the target\nsystem, and the gravitational potential is automatically adjusted by the\nchanging mass of the particles. This paper builds upon our previous work,\nintroducing likelihood-based velocity constraints in PRIMAL. In this paper we\napply PRIMAL to barred disc galaxies created by a N-body simulation in a known\ndark matter potential, with no error in the observables. This paper\ndemonstrates that PRIMAL can recover the radial profiles of the surface\ndensity, velocity dispersion in the radial and perpendicular directions, and\nthe rotational velocity of the target discs, along with the apparent bar\nstructure and pattern speed of the bar, especially when the reference frame is\nadjusted so that the bar angle of the target galaxy is aligned to that of the\nmodel galaxy at every timestep. \n\n"}
{"id": "1304.6530", "contents": "Title: Parabolic Strip Telescope Abstract: We present a proposal of a new type of telescopes using a rotating parabolic\nstrip as the primary mirror. It is the most principal modification of the\ndesign of telescopes from the times of Galileo and Newton. In order to\ndemonstrate the basic idea, the image of an artificial constellation observed\nby this kind of telescope was reconstructed using the techniques described in\nthis article. As a working model of this new telescope, we have used an\nassembly of the primary mirror---a strip of acrylic glass parabolic mirror 40\ncm long and 10 cm wid shaped as a parabolic cylinder of focal length 1 m---and\nan artificial constellation, a set of 5 apertures in a distance of 5 m\nilluminated from behind. In order to reconstruct the image, we made a series of\nsnaps, each after a rotation of the constellation by 15 degrees. Using Matlab\nwe reconstructed the image of the artificial constellation. \n\n"}
{"id": "1304.6615", "contents": "Title: Data-rich astronomy: mining synoptic sky surveys Abstract: In the last decade a new generation of telescopes and sensors has allowed the\nproduction of a very large amount of data and astronomy has become, a data-rich\nscience; this transition is often labeled as: \"data revolution\" and \"data\ntsunami\". The first locution puts emphasis on the expectations of the\nastronomers while the second stresses, instead, the dramatic problem arising\nfrom this large amount of data: which is no longer computable with traditional\napproaches to data storage, data reduction and data analysis. In a new, age new\ninstruments are necessary, as it happened in the Bronze age when mankind left\nthe old instruments made out of stone to adopt the new, better ones made with\nbronze. Everything changed, even the social structure. In a similar way, this\nnew age of Astronomy calls for a new generation of tools and, for a new\nmethodological approach to many problems, and for the acquisition of new\nskills. The attems to find a solution to this problems falls under the umbrella\nof a new discipline which originated by the intersection of astronomy,\nstatistics and computer science: Astroinformatics, (Borne, 2009; Djorgovski et\nal., 2006). \n\n"}
{"id": "1305.0262", "contents": "Title: On-sky characterisation of the VISTA NB118 narrow-band filters at 1.19\n  micron Abstract: Observations of the high redshift Universe through narrow-band filters have\nproven very successful in the last decade. The 4-meter VISTA telescope,\nequipped with the wide-field camera VIRCAM, offers a major step forward in\nwide-field near-infrared imaging, and in order to utilise VISTA's large\nfield-of-view and sensitivity, the Dark Cosmology Centre provided a set of 16\nnarrow-band filters for VIRCAM. These NB118 filters are centered at a\nwavelength near 1.19 micron in a region with few airglow emission lines. The\nfilters allow the detection of Halpha emitters at z = 0.8, Hbeta and [OIII]\nemitters at z ~ 1.4, [OII] emitters at z = 2.2, and Ly-alpha emitters at z =\n8.8. Based on guaranteed time observations of the COSMOS field we here present\na detailed description and characterization of the filters and their\nperformance. In particular we provide sky-brightness levels and depths for each\nof the 16 detector/filter sets and find that some of the filters show signs of\nsome red-leak. We identify a sample of 2 x 10^3 candidate emission-line objects\nin the data. Cross-correlating this sample with a large set of galaxies with\nknown spectroscopic redshifts we determine the \"in situ\" passbands of the\nfilters and find that they are shifted by about 3.5-4 nm (corresponding to 30%\nof the filter width) to the red compared to the expectation based on the\nlaboratory measurements. Finally, we present an algorithm to mask out\npersistence in VIRCAM data. Scientific results extracted from the data will be\npresented separately. \n\n"}
{"id": "1305.0820", "contents": "Title: Dark matter density profile and galactic metric in Eddington-inspired\n  Born-Infeld gravity Abstract: We consider the density profile of pressureless dark matter in\nEddington-inspired Born-Infeld (EiBI) gravity. The gravitational field\nequations are investigated for a spherically symmetric dark matter galactic\nhalo, by adopting a phenomenological tangential velocity profile for test\nparticles moving in stable circular orbits around the galactic center. The\ndensity profile and the mass distribution, as well as the general form of the\nmetric tensor is obtained by numerically integrating the gravitational field\nequations, and in an approximate analytical form by using the Newtonian limit\nof the theory. In the weak field limit the dark matter density distribution is\ndescribed by the Lane-Emden equation with polytropic index $n=1$, and is\nnon-singular at the galactic center. The parameter $\\kappa $ of the theory is\ndetermined so that that the theory could provide a realistic description of the\ndark matter halos. The gravitational properties of the dark matter halos are\nalso briefly discussed in the Newtonian approximation. \n\n"}
{"id": "1305.1007", "contents": "Title: Analysis techniques and performance of the Domino Ring Sampler version 4\n  based readout for the MAGIC telescopes Abstract: Recently the readout of the MAGIC telescopes has been upgraded to a new\nsystem based on the Domino Ring Sampler version 4 chip. We present the analysis\ntechniques and the signal extraction performance studies of this system. We\nstudy the behaviour of the baseline, the noise, the cross-talk, the linearity\nand the time resolution. We investigate also the optimal signal extraction. In\naddition we show some of the analysis techniques specific to the readout based\non the Domino Ring Sampler version 2 chip, previously used in the MAGIC II\ntelescope. \n\n"}
{"id": "1306.0792", "contents": "Title: Interpreting signals from astrophysical transient experiments Abstract: Time domain astronomy has come of age with astronomers now able to monitor\nthe sky at high cadence both across the electromagnetic spectrum and using\nneutrinos and gravitational waves. The advent of new observing facilities\npermits new science, but the ever increasing throughput of facilities demands\nefficient communication of coincident detections and better subsequent\ncoordination among the scientific community so as to turn detections into\nscientific discoveries. To discuss the revolution occurring in our ability to\nmonitor the Universe and the challenges it brings, on 2012 April 25-26 a group\nof scientists from observational and theoretical teams studying transients met\nwith representatives of the major international transient observing facilities\nat the Kavli Royal Society International Centre, UK. This immediately followed\nthe Royal Society Discussion meeting \"New windows on transients across the\nUniverse\" held in London. Here we present a summary of the Kavli meeting at\nwhich the participants discussed the science goals common to the transient\nastronomy community and analysed how to better meet the challenges ahead as\never more powerful observational facilities come on stream. \n\n"}
{"id": "1306.2940", "contents": "Title: The Galaxy Counterparts of the two high-metallicity DLAs at z=2.412 and\n  z=2.583 towards Q0918+1636 Abstract: The quasar Q0918+1636 (z=3.07) has two intervening high-metallicity Damped\nLyman-alpha Absorbers (DLAs) along the line of sight, at redshifts of z=2.412\nand 2.583. The z=2.583 DLA is located at a large impact parameter of 16.2 kpc,\nand despite this large impact parameter it has a very high metallicity\n(consistent with solar), a substantial fraction of H_2 molecules, and it is\ndusty as inferred from the reddened spectrum of the background QSO. The z=2.412\nDLA has a metallicity of [M/H]=-0.6 (based on ZnII and SiII). In this paper we\npresent new observations of this interesting sightline. HST/WFC3 imaging was\nobtained in the F606W, F105W and F160W bands. This is complemented by\nground-based imaging in the u-, g-bands as well as K_s observations in the\nnear-infrared (NIR). In addition, we present further spectroscopy with the\nESO/VLT X-Shooter spectrograph. Based on these observations we obtain the\nfollowing results: By fitting stellar population synthesis models to the\nphotometric SED we constrain the physical properties of the z=2.583 DLA galaxy,\nand we infer its morphology by fitting a Sersic model to its surface brightness\nprofile. We find it to be a relatively massive (M_star 10^10 M_sun), strongly\nstar-forming (SFR~30 M_sun / yr, dusty (E_(B-V)=0.4) galaxy with a disk-like\nmorphology. We detect most of the strong emission lines from the z=2.583 DLA\n[OIII],3727, [OIII],4960, [OIII],5007, Hbeta, and Halpha, albeit at low\nsignal-to-noise (SN) ratio except for the [OIII],5007 line. We also detect\n[OIII],5007 emission from the galaxy counterpart of the z=2.412 DLA at a small\nimpact parameter (<2 kpc). Overall our findings are consistent with the\nemerging picture that high-metallicity DLAs are associated with relatively\n(compared to typical DLAs) luminous and massive galaxy counterparts. \n\n"}
{"id": "1306.3204", "contents": "Title: The Heliometer of Rio de Janeiro in Operation - 2010 to 2013 Abstract: Out of the three quantities that characterize the state of an isolated\ngaseous body: pressure, temperature and volume the radius is the only one\ndirectly measurable for the Sun, what is specially true in the optical window\nand for ground base measurements. The Heliometer of Observatorio Nacional, in\nRio de Janeiro, measures the distance between two opposite limbs of the Sun in\nthe same field of view, through the reflection on a 10 cm parabolic mirror\nsplit on its half and forming an appropriate angle. This configuration is free\nfrom optical aberrations and focal variations along the measurement direction.\nThe mirrors are made on CCZ vitro-ceramic and the telescope structure is of\ncarbon steel, resulting that there is no flexion or temperature deformation.\nThe instrument is compact, and can perform hundreds of measurements per duty\nday, around all heliolatitudes. It attains an accuracy on the solar radius of\n0.01 arcsec, becoming the ideal instrument to monitor from the ground the solar\ndiameter, and to bridge satellites and astrolabes historical series of data. We\ndiscuss the first years of regular observation, with emphasis on the\ninstrumental calibrations and on the statistic study of the derived time\nseries, attitude series, and solar geometry series. On basis of these series we\nobtain how well the Heliometer and Solar Astrolabe results are matched. \n\n"}
{"id": "1306.3431", "contents": "Title: Star-forming fractions and galaxy evolution with redshift in rich\n  X-ray-selected galaxy clusters Abstract: We have compared stacked spectra of galaxies, grouped by environment and\nstellar mass, among 58 members of the redshift z = 1.24 galaxy cluster RDCS\nJ1252.9-2927 (J1252.9) and 134 galaxies in the z = 0.84 cluster RX J0152.7-1357\n(J0152.7). These two clusters are excellent laboratories to study how galaxies\nevolve from star-forming to passive at z ~ 1. We measured spectral indices and\nstar-forming fractions for our density- and mass-based stacked spectra. The\nstar-forming fraction among low-mass galaxies (< 7 x 10^10 M_sun) is higher in\nJ1252.9 than in J0152.7, at about 4 sigma significance. Thus star formation is\nbeing quenched between z = 1.24 and z = 0.84 for a substantial fraction of\nlow-mass galaxies. Star-forming fractions were also found to be higher in\nJ1252.9 in all environments, including the core. Passive galaxies in J1252.9\nhave systematically lower D_n4000 values than in J0152.7 in all density and\nmass groups, consistent with passive evolution at modestly super-solar\nmetallicities. \n\n"}
{"id": "1306.3481", "contents": "Title: Visualizing Astronomical Data with Blender Abstract: Astronomical data take on a multitude of forms -- catalogs, data cubes,\nimages, and simulations. The availability of software for rendering\nhigh-quality three-dimensional graphics lends itself to the paradigm of\nexploring the incredible parameter space afforded by the astronomical sciences.\nThe software program Blender gives astronomers a useful tool for displaying\ndata in a manner used by three-dimensional (3D) graphics specialists and\nanimators. The interface to this popular software package is introduced with\nattention to features of interest in astronomy. An overview of the steps for\ngenerating models, textures, animations, camera work, and renders is outlined.\nAn introduction is presented on the methodology for producing animations and\ngraphics with a variety of astronomical data. Examples from sub-fields of\nastronomy with different kinds of data are shown with resources provided to\nmembers of the astronomical community. An example video showcasing the outlined\nprinciples and features is provided along with scripts and files for sample\nvisualizations. \n\n"}
{"id": "1306.4153", "contents": "Title: Combining Planck with Large Scale Structure gives strong neutrino mass\n  constraint Abstract: We present the strongest current cosmological upper limit on the sum of\nneutrino masses of < 0.18 (95% confidence). It is obtained by adding\nobservations of the large-scale matter power spectrum from the WiggleZ Dark\nEnergy Survey to observations of the cosmic microwave background data from the\nPlanck surveyor, and measurements of the baryon acoustic oscillation scale. The\nlimit is highly sensitive to the priors and assumptions about the neutrino\nscenario. We explore scenarios with neutrino masses close to the upper limit\n(degenerate masses), neutrino masses close to the lower limit where the\nhierarchy plays a role, and addition of massive or massless sterile species. \n\n"}
{"id": "1307.0117", "contents": "Title: Status of the ArDM Experiment: First results from gaseous argon\n  operation in deep underground environment Abstract: The Argon Dark Matter (ArDM-1t) experiment is a ton-scale liquid argon (LAr)\ndouble-phase time projection chamber designed for direct Dark Matter searches.\nSuch a device allows to explore the low energy frontier in LAr. After\nsuccessful operation on surface at CERN, the detector has been deployed\nunderground and is presently commissioned at the Canfranc Underground\nLaboratory (LSC). In this paper, we describe the status of the installation and\npresent first results on data collected in gas phase. \n\n"}
{"id": "1307.5083", "contents": "Title: Cosmic Variance of the Spectral Index from Mode Coupling Abstract: We demonstrate that local, scale-dependent non-Gaussianity can generate\ncosmic variance uncertainty in the observed spectral index of primordial\ncurvature perturbations. In a universe much larger than our current Hubble\nvolume, locally unobservable long wavelength modes can induce a\nscale-dependence in the power spectrum of typical subvolumes, so that the\nobserved spectral index varies at a cosmologically significant level (|\\Delta\nns | ~ O(0.04)). Similarly, we show that the observed bispectrum can have an\ninduced scale dependence that varies about the global shape. If tensor modes\nare coupled to long wavelength modes of a second field, the locally observed\ntensor power and spectral index can also vary. All of these effects, which can\nbe introduced in models where the observed non-Gaussianity is consistent with\nbounds from the Planck satellite, loosen the constraints that observations\nplace on the parameters of theories of inflation with mode coupling. We suggest\nobservational constraints that future measurements could aim for to close this\nwindow of cosmic variance uncertainty. \n\n"}
{"id": "1307.5732", "contents": "Title: Pushing the limits of the Gaia space mission by analyzing galaxy\n  morphology Abstract: The ESA Gaia mission, to be launched during 2013, will observe billions of\nobjects, among which many galaxies, during its scanning of the sky. This will\nprovide a large space-based dataset with unprecedented spatial resolution.\nBecause of its natural Galactic and Astrometric priority, Gaia's observational\nstrategy was optimized for point sources. Nonetheless, it is expected that 10^6\nsources will be extragalactic, and a large portion of them will be angularly\nsmall galaxies. Although the mission was designed for point sources, a\ndedicated analysis of the raw data will allow the recovery of morphology of\nthose objects at a 0.2\" level. This may constitute a unique all-sky survey of\nsuch galaxies. We describe the conceptual design of the method we created for\nperforming the morphological analysis of these objects as well as first results\nobtained from data simulations of low-resolution, highly binned, satellite\ndata. Based on the obtained results we conclude that it is possible to push the\nlimits of the Gaia space mission by analyzing galaxy morphology. (Abridged) \n\n"}
{"id": "1308.0834", "contents": "Title: Observational constraints on non-flat dynamical dark energy cosmological\n  models Abstract: We constrain two non-flat time-evolving dark energy cosmological models by\nusing Hubble parameter data, Type Ia supernova apparent magnitude measurements,\nand baryonic acoustic oscillation peak length scale observations. The inclusion\nof space curvature as a free parameter in the analysis results in a significant\nbroadening of the allowed range of values of the parameter that governs the\ntime evolution of the dark energy density in these models. While consistent\nwith the \"standard\" spatially-flat $\\Lambda$CDM cosmological model, these data\nare also consistent with a range of mildly non-flat, slowly time-varying dark\nenergy models. After marginalizing over all other parameters, these data\nrequire the averaged magnitude of the curvature density parameter\n$|\\Omega_{k0}| \\lesssim 0.15$ at 1$\\sigma$ confidence. \n\n"}
{"id": "1308.0886", "contents": "Title: Peculiar Velocity Decomposition, Redshift Space Distortion and Velocity\n  Reconstruction in Redshift Surveys. II. Dark Matter Velocity Statistics Abstract: Massive spectroscopic redshift surveys open a promising window to accurately\nmeasure peculiar velocity at cosmological distances through redshift space\ndistortion (RSD). In paper I of this series of work we proposed to decompose\npeculiar velocity into three eigen-modes (v_\\delta, v_S and v_B) in order to\nfacilitate the RSD modeling and peculiar velocity reconstruction. In the\ncurrent paper we measure the dark matter RSD related statistics of the velocity\neigen-modes through a set of N-body simulations, including the velocity power\nspectra, correlation functions, one-point probability distribution functions,\ncumulants and the damping functions describing the Finger of God effect. (1)\nThe power spectrum measurement shows that these velocity components have\ndistinctly different spatial distribution and redshift evolution. In\nparticular, we measure the window function \\tilde{W}(k,z), which describes the\nimpact of nonlinear evolution on the v_\\delta-density relation. We confirm that\nit can induce a significant systematic error of O(10%) in RSD cosmology. We\ndemonstrate that \\tilde{W} can be accurately described by a simple fitting\nformula with one or two free parameters. (2) The correlation function\nmeasurement shows that the correlation length is O(100), O(10) and O(1) Mpc for\nv_\\delta, v_S and v_B respectively. These correlation lengths determine where\nwe can treat the velocity fields as spatially uncorrelated. (3) The velocity\nPDFs and cumulants quantify non-Gaussianities of the velocity fields. We\nconfirm speculation in paper I that v_\\delta is largely Gaussian, nevertheless\nwith non-negligible non-Gaussianity, v_B is significantly non-Gaussian. We also\nmeasure the damping functions. Despite the observed non-Gaussianities, the\ndamping functions and hence the FOG effect are all well approximated as\nGaussian ones at scales of interest. \n\n"}
{"id": "1308.1390", "contents": "Title: Photosensor Characterization for the Cherenkov Telescope Array: Silicon\n  Photomultiplier versus Multi-Anode Photomultiplier Tube Abstract: Photomultiplier tube technology has been the photodetector of choice for the\ntechnique of imaging atmospheric Cherenkov telescopes since its birth more than\n50 years ago. Recently, new types of photosensors are being contemplated for\nthe next generation Cherenkov Telescope Array. It is envisioned that the array\nwill be partly composed of telescopes using a Schwarzschild-Couder two mirror\ndesign never built before which has significantly improved optics. The camera\nof this novel optical design has a small plate scale which enables the use of\ncompact photosensors. We present an extensive and detailed study of the two\nmost promising devices being considered for this telescope design: the silicon\nphotomultiplier and the multi-anode photomultiplier tube. We evaluated their\nmost critical performance characteristics for imaging gamma-ray showers, and we\npresent our results in a cohesive manner to clearly evaluate the advantages and\ndisadvantages that both types of device have to offer in the context of GeV-TeV\ngamma-ray astronomy. \n\n"}
{"id": "1308.1512", "contents": "Title: FACT - The First G-APD Cherenkov Telescope: Status and Results Abstract: The First G-APD Cherenkov telescope (FACT) is the first telescope using\nsilicon photon detectors (G-APD aka. SiPM). It is built on the mount of the\nHEGRA CT3 telescope, still located at the Observatorio del Roque de los\nMuchachos, and it is successfully in operation since Oct. 2011. The use of\nSilicon devices promises a higher photon detection efficiency, more robustness\nand higher precision than photo-multiplier tubes. The FACT collaboration is\ninvestigating with which precision these devices can be operated on the\nlong-term. Currently, the telescope is successfully operated from remote and\nrobotic operation is under development. During the past months of operation,\nthe foreseen monitoring program of the brightest known TeV blazars has been\ncarried out, and first physics results have been obtained including a strong\nflare of Mrk501. An instantaneous flare alert system is already in a testing\nphase. This presentation will give an overview of the project and summarize its\ngoals, status and first results. \n\n"}
{"id": "1308.4686", "contents": "Title: Can the Higgs Boson Save Us From the Menace of the Boltzmann Brains? Abstract: The standard $\\Lambda$CDM model provides an excellent fit to current\ncosmological observations but suffers from a potentially serious Boltzmann\nBrain problem. If the universe enters a de Sitter vacuum phase that is truly\neternal, there will be a finite temperature in empty space and corresponding\nthermal fluctuations. Among these fluctuations will be intelligent observers,\nas well as configurations that reproduce any local region of the current\nuniverse to arbitrary precision. We discuss the possibility that the escape\nfrom this unacceptable situation may be found in known physics: vacuum\ninstability induced by the Higgs field. Avoiding Boltzmann Brains in a\nmeasure-independent way requires a decay timescale of order the current age of\nthe universe, which can be achieved if the top quark pole mass is approximately\n178 GeV. Otherwise we must invoke new physics or a particular cosmological\nmeasure before we can consider $\\Lambda$CDM to be an empirical success. \n\n"}
{"id": "1308.4806", "contents": "Title: Krypton assay in xenon at the ppq level using a gas chromatographic\n  system and mass spectrometer Abstract: We have developed a new method to measure krypton traces in xenon at\nunprecedented low concentrations. This is a mandatory task for many near-future\nlow-background particle physics detectors. Our system separates krypton from\nxenon using cryogenic gas chromatography. The amount of krypton is then\nquantified using a mass spectrometer. We demonstrate that the system has\nachieved a detection limit of 8 ppq (parts per quadrillion) and present results\nof distilled xenon with krypton concentrations below 1 ppt. \n\n"}
{"id": "1308.6414", "contents": "Title: The multi-frequency multi-temporal sky Abstract: Contemporary astronomy benefits of very large and rapidly growing amounts of\ndata in all bands of the electromagnetic spectrum, from long-wavelength radio\nwaves to high energy gamma-rays. Astronomers normally specialize in data taken\nin one particular energy window, however the advent of data centers world-wide\nand of the Virtual Observatory, which provide simple and open access to quality\ndata in all energy bands taken at different epochs, is making multi-frequency\nand multi-epoch astronomy much more affordable than in the past. New tools\ndesigned to combine and analyze these data sets are being developed with the\naim of visualizing observational results and extracting information about the\nphysical processes powering cosmic sources in ways that were not possible\nbefore. In this contribution blazars, a type of cosmic sources that emit highly\nvariable radiation at all frequencies, are used as an example to describe the\npossibilities of this type of astronomy today, and the discovery potential for\nthe near future. \n\n"}
{"id": "1308.6819", "contents": "Title: The effect of softening on dynamical simulations of galaxies Abstract: Dynamical simulations are a fundamental tool for studying the secular\nevolution of disc galaxies. Even at their maximum resolution, they still follow\na limited number of particles and typically resolve scales of the order of a\nfew tens of parsecs. Generally, the spatial resolution is defined by (some\nmultiple of) the softening length, whose value is set as a compromise between\nthe desired resolution and the need for limiting small-scale noise. Several\nworks have studied the question whether a softening scale fixed in space and\ntime provides a good enough modelling of an astrophysical system. Here we\naddress this question within the context of dynamical simulations and disc\ninstabilities. We first follow the evolution of a galaxy-like object in\nisolation and then set up a simulation of an idealised merger event. Alongside\na run using the standard fixed-softening approach, we performed simulations\nwhere the softening lengths were let to vary from particle to particle\naccording to the evolution of the local density field in space and time. Even\nthough during the most violent phases of the merging the fixed-softening\nsimulation tends to underestimate the resulting matter densities, as far as the\nevolution of the disc component is concerned we found no significant\ndifferences among the runs. We conclude that using an appropriate fixed\nsoftening scale is a safe approach to the problem of modelling an N-body,\nnon-cosmological disc galaxy system. \n\n"}
{"id": "1309.1469", "contents": "Title: Probabilistic image reconstruction for radio interferometers Abstract: We present a novel, general-purpose method for deconvolving and denoising\nimages from gridded radio interferometric visibilities using Bayesian inference\nbased on a Gaussian process model. The method automatically takes into account\nincomplete coverage of the uv-plane, signal mode coupling due to the primary\nbeam, and noise mode coupling due to uv sampling. Our method uses Gibbs\nsampling to efficiently explore the full posterior distribution of the\nunderlying signal image given the data. We use a set of widely diverse mock\nimages with a realistic interferometer setup and level of noise to assess the\nmethod. Compared to results from a proxy for point source- based CLEAN method\nwe find that in terms of RMS error and signal-to-noise ratio our approach\nperforms better than traditional deconvolution techniques, regardless of the\nstructure of the source image in our test suite. Our implementation scales as\nO(np log np), provides full statistical and uncertainty information of the\nreconstructed image, requires no supervision, and provides a robust, consistent\nframework for incorporating noise and parameter marginalizations and foreground\nremoval. \n\n"}
{"id": "1309.2157", "contents": "Title: The Gaia astrophysical parameters inference system (Apsis). Pre-launch\n  description Abstract: The Gaia satellite will survey the entire celestial sphere down to 20th\nmagnitude, obtaining astrometry, photometry, and low resolution\nspectrophotometry on one billion astronomical sources, plus radial velocities\nfor over one hundred million stars. Its main objective is to take a census of\nthe stellar content of our Galaxy, with the goal of revealing its formation and\nevolution. Gaia's unique feature is the measurement of parallaxes and proper\nmotions with hitherto unparalleled accuracy for many objects. As a survey, the\nphysical properties of most of these objects are unknown. Here we describe the\ndata analysis system put together by the Gaia consortium to classify these\nobjects and to infer their astrophysical properties using the satellite's data.\nThis system covers single stars, (unresolved) binary stars, quasars, and\ngalaxies, all covering a wide parameter space. Multiple methods are used for\nmany types of stars, producing multiple results for the end user according to\ndifferent models and assumptions. Prior to its application to real Gaia data\nthe accuracy of these methods cannot be assessed definitively. But as an\nexample of the current performance, we can attain internal accuracies (RMS\nresiduals) on F,G,K,M dwarfs and giants at G=15 (V=15-17) for a wide range of\nmetallicites and interstellar extinctions of around 100K in effective\ntemperature (Teff), 0.1mag in extinction (A0), 0.2dex in metallicity ([Fe/H]),\nand 0.25dex in surface gravity (logg). The accuracy is a strong function of the\nparameters themselves, varying by a factor of more than two up or down over\nthis parameter range. After its launch in November 2013, Gaia will nominally\nobserve for five years, during which the system we describe will continue to\nevolve in light of experience with the real data. \n\n"}
{"id": "1309.2329", "contents": "Title: Transit Timing Variation of Near-Resonance Planetary Pairs. II.\n  Confirmation of 30 planets in 15 Multiple Planet Systems Abstract: Following on from Paper I in our series (Xie 2013), we report the\nconfirmation by Transit Timing Variations (TTVs) of a further 30 planets in 15\nmultiple planet systems, using the publicly available Kepler light curves\n(Q0-Q16). All of these fifteen pairs are near first-order Mean Motion\nResonances (MMR), showing sinusoidal TTVs consistent with theoretically\npredicted periods, which demonstrate they are orbiting and interacting in the\nsame systems. Although individual masses cannot be accurately extracted based\nonly on TTVs (because of the well known degeneracy between mass and\neccentricity), the measured TTV phases and amplitudes can still place\nrelatively tight constraints on their mass ratios and upper limits on their\nmasses, which confirm their planetary nature. Some of these systems (KOI-274,\nKOI-285, KOI-370 and KOI-2672) are relatively bright and thus suitable for\nfurther follow-up observations. \n\n"}
{"id": "1309.3519", "contents": "Title: High-Angular-Resolution and High-Sensitivity Science Enabled by\n  Beamformed ALMA Abstract: An international consortium is presently constructing a beamformer for the\nAtacama Large Millimeter/submillimeter Array (ALMA) in Chile that will be\navailable as a facility instrument. The beamformer will aggregate the entire\ncollecting area of the array into a single, very large aperture. The\nextraordinary sensitivity of phased ALMA, combined with the extremely fine\nangular resolution available on baselines to the Northern Hemisphere, will\nenable transformational new very long baseline interferometry (VLBI)\nobservations in Bands 6 and 7 (1.3 and 0.8 mm) and provide substantial\nimprovements to existing VLBI arrays in Bands 1 and 3 (7 and 3 mm). The ALMA\nbeamformer will have impact on a variety of scientific topics, including\naccretion and outflow processes around black holes in active galactic nuclei\n(AGN), tests of general relativity near black holes, jet launch and collimation\nfrom AGN and microquasars, pulsar and magnetar emission processes, the chemical\nhistory of the universe and the evolution of fundamental constants across\ncosmic time, maser science, and astrometry. \n\n"}
{"id": "1309.3783", "contents": "Title: SWIFT: Fast algorithms for multi-resolution SPH on multi-core\n  architectures Abstract: This paper describes a novel approach to neighbour-finding in Smoothed\nParticle Hydrodynamics (SPH) simulations with large dynamic range in smoothing\nlength. This approach is based on hierarchical cell decompositions, sorted\ninteractions, and a task-based formulation. It is shown to be faster than\ntraditional tree-based codes, and to scale better than domain\ndecomposition-based approaches on shared-memory parallel architectures such as\nmulti-cores. \n\n"}
{"id": "1309.4834", "contents": "Title: Prospects for the Detection of Fast Radio Bursts with the Murchison\n  Widefield Array Abstract: Fast Radio Bursts (FRBs) are short timescale (<<1 s) astrophysical radio\nsignals, presumed to be a signature of cataclysmic events of extragalactic\norigin. The discovery of six high-redshift events at ~1400 MHz from the Parkes\nradio telescope suggests that FRBs may occur at a high rate across the sky. The\nMurchison Widefield Array (MWA) operates at low radio frequencies (80-300 MHz)\nand is expected to detect FRBs due to its large collecting area (~2500 m^2) and\nwide field-of-view (FOV, ~1000 square degrees at nu=200 MHz). We compute the\nexpected number of FRB detections for the MWA assuming a source population\nconsistent with the reported detections. Our formalism properly accounts for\nthe frequency-dependence of the antenna primary beam, the MWA system\ntemperature, and unknown spectral index of the source population, for three\nmodes of FRB detection: coherent; incoherent; and fast imaging. We find that\nthe MWA's sensitivity and large FOV combine to provide the expectation of\nmultiple detectable events per week in all modes, potentially making it an\nexcellent high time resolution science instrument. Deviations of the expected\nnumber of detections from actual results will provide a strong constraint on\nthe assumptions made for the underlying source population and intervening\nplasma distribution. \n\n"}
{"id": "1309.5415", "contents": "Title: Light-weight Flexible Magnetic Shields For Large-Aperture\n  Photomultiplier Tubes Abstract: Thin flexible sheets of high-permeability FINEMET foils encased in thin\nplastic layers have been used to shield various types of 20-cm-diameter\nphotomultiplier tubes from ambient magnetic fields. In the presence of the\nEarth's magnetic field this type of shielding is shown to increase the\ncollection efficiency of photoelectrons and can improve the uniformity of\nresponse of these photomultiplier tubes. \n\n"}
{"id": "1309.6366", "contents": "Title: pcigale: porting Code Investigating Galaxy Emission to Python Abstract: We present pcigale, the port to Python of CIGALE (Code Investigating Galaxy\nEmission) a Fortran spectral energy distribution (SED) fitting code developed\nat the Laboratoire d'Astrophysique de Marseille. After recalling the specifics\nof the SED fitting method, we show the gains in modularity and versatility\noffered by Python, as well as the drawbacks compared to the compiled code. \n\n"}
{"id": "1309.6435", "contents": "Title: Random time series in Astronomy Abstract: Progress in astronomy comes from interpreting the signals encoded in the\nlight received from distant objects: the distribution of light over the sky\n(images), over photon wavelength (spectrum), over polarization angle, and over\ntime (usually called light curves by astronomers). In the time domain we see\ntransient events such as supernovae, gamma-ray bursts, and other powerful\nexplosions; we see periodic phenomena such as the orbits of planets around\nnearby stars, radio pulsars, and pulsations of stars in nearby galaxies; and\npersistent aperiodic variations (`noise') from powerful systems like accreting\nblack holes. I review just a few of the recent and future challenges in the\nburgeoning area of Time Domain Astrophysics, with particular attention to\npersistently variable sources, the recovery of reliable noise power spectra\nfrom sparsely sampled time series, higher-order properties of accreting black\nholes, and time delays and correlations in multivariate time series. \n\n"}
{"id": "1309.6756", "contents": "Title: The universe dominated by oscillating scalar with non-minimal derivative\n  coupling to gravity Abstract: We study the expansion law of the universe dominated by the oscillating\nscalar field with non-minimal derivative coupling to gravity as G^{\\mu \\nu}\n\\partial_{\\mu} \\phi \\partial_{\\nu} \\phi. In this system the Hubble parameter\noscillates with a frequency of the effective mass of the scalar field, which\nformerly caused a difficulty in analyzing how the universe expands. We find an\nanalytical solution for power law potentials and interpret the solution in an\nintuitive way by using a new invariant of the system. As a result, we find\nmarginally accelerated expansion for the quadratic potential and no accelerated\nexpansion for the potential with higher power. \n\n"}
{"id": "1309.6995", "contents": "Title: XIPE: the X-ray Imaging Polarimetry Explorer Abstract: X-ray polarimetry, sometimes alone, and sometimes coupled to spectral and\ntemporal variability measurements and to imaging, allows a wealth of physical\nphenomena in astrophysics to be studied. X-ray polarimetry investigates the\nacceleration process, for example, including those typical of magnetic\nreconnection in solar flares, but also emission in the strong magnetic fields\nof neutron stars and white dwarfs. It detects scattering in asymmetric\nstructures such as accretion disks and columns, and in the so-called molecular\ntorus and ionization cones. In addition, it allows fundamental physics in\nregimes of gravity and of magnetic field intensity not accessible to\nexperiments on the Earth to be probed. Finally, models that describe\nfundamental interactions (e.g. quantum gravity and the extension of the\nStandard Model) can be tested. We describe in this paper the X-ray Imaging\nPolarimetry Explorer (XIPE), proposed in June 2012 to the first ESA call for a\nsmall mission with a launch in 2017 but not selected. XIPE is composed of two\nout of the three existing JET-X telescopes with two Gas Pixel Detectors (GPD)\nfilled with a He-DME mixture at their focus and two additional GPDs filled with\npressurized Ar-DME facing the sun. The Minimum Detectable Polarization is 14 %\nat 1 mCrab in 10E5 s (2-10 keV) and 0.6 % for an X10 class flare. The Half\nEnergy Width, measured at PANTER X-ray test facility (MPE, Germany) with JET-X\noptics is 24 arcsec. XIPE takes advantage of a low-earth equatorial orbit with\nMalindi as down-link station and of a Mission Operation Center (MOC) at INPE\n(Brazil). \n\n"}
{"id": "1309.7473", "contents": "Title: A fast map-making preconditioner for regular scanning patterns Abstract: High-resolution Maximum Likelihood map-making of the Cosmic Microwave\nBackground is usually performed using Conjugate Gradients with a preconditioner\nthat ignores noise correlations. We here present a new preconditioner that\napproximates the map noise covariance as circulant, and show that this results\nin a speedup of up to 400% for a realistic scanning pattern from the Atacama\nCosmology Telescope. The improvement is especially large for polarized maps. \n\n"}
{"id": "1310.0615", "contents": "Title: Measuring galaxy [OII] emission line doublet with future ground-based\n  wide-field spectroscopic surveys Abstract: The next generation of wide-field spectroscopic redshift surveys will map the\nlarge-scale galaxy distribution in the redshift range 0.7< z<2 to measure\nbaryonic acoustic oscillations (BAO). The primary optical signature used in\nthis redshift range comes from the [OII] emission line doublet, which provides\na unique redshift identification that can minimize confusion with other single\nemission lines. To derive the required spectrograph resolution for these\nredshift surveys, we simulate observations of the [OII] (3727,3729) doublet for\nvarious instrument resolutions, and line velocities. We foresee two strategies\nabout the choice of the resolution for future spectrographs for BAO surveys.\nFor bright [OII] emitter surveys ([OII] flux ~30.10^{-17} erg /cm2/s like\nSDSS-IV/eBOSS), a resolution of R~3300 allows the separation of 90 percent of\nthe doublets. The impact of the sky lines on the completeness in redshift is\nless than 6 percent. For faint [OII] emitter surveys ([OII] flux ~10.10^{-17}\nerg /cm2/s like DESi), the detection improves continuously with resolution, so\nwe recommend the highest possible resolution, the limit being given by the\nnumber of pixels (4k by 4k) on the detector and the number of spectroscopic\nchannels (2 or 3). \n\n"}
{"id": "1310.1238", "contents": "Title: A few cosmological implications of tensor nonlocalities Abstract: We consider nonlocal gravity theories that include tensor nonlocalities. We\nshow that in the cosmological context, the tensor nonlocalities, unlike scalar\nones, generically give rise to growing modes. An explicit example with\nquadratic curvature terms is studied in detail. Possible consequences for\nrecent nonlocal cosmological models proposed in the literature are also\ndiscussed. \n\n"}
{"id": "1310.1665", "contents": "Title: Greenland Telescope (GLT) Project: \"A Direct Confirmation of Black Hole\n  with Submillimeter VLBI\" Abstract: The GLT project is deploying a new submillimeter (submm) VLBI station in\nGreenland. Our primary scientific goal is to image a shadow of the supermassive\nblack hole (SMBH) of six billion solar masses in M87 at the center of the Virgo\ncluster of galaxies. The expected SMBH shadow size of 40-50 $\\mu$as requires\nsuperbly high angular resolution, suggesting that the submm VLBI would be the\nonly way to obtain the shadow image. The Summit station in Greenland enables us\nto establish baselines longer than 9,000 km with ALMA in Chile and SMA in\nHawaii as well as providing a unique $u$--$v$ coverage for imaging M87. Our\nVLBI network will achieve a superior angular resolution of about 20 $\\mu$as at\n350 GHz, corresponding to $\\sim2.5$ times of the Schwarzschild radius of the\nsupermassive black hole in M87. We have been monitoring the atmospheric opacity\nat 230 GHz since August. 2011; we have confirmed the value on site during the\nwinter season is comparable to the ALMA site thanks to high altitude of 3,200 m\nand low temperature of $-50\\degr$C. We will report current status and future\nplan of the GLT project towards our expected first light on 2015--2016. \n\n"}
{"id": "1310.1927", "contents": "Title: 3C273 variability at 7 mm: Evidences of shocks and precession in the jet Abstract: We report 4 years of observations of 3C273 at 7 mm obtained with the\nItapetinga Radiotelescope, in Brazil, between 2009 and 2013. We detected a\nflare in 2010 March, when the flux density increased by 50% and reached 35 Jy.\nAfter the flare, the flux density started to decrease and reached values lower\nthan 10 Jy. We suggest that the 7 mm flare is the radio counterpart of the\n$\\gamma$-ray flare observed by Fermi/LAT in 2009 September, in which the flux\ndensity at high energies reached a factor of fifty of its average value. A\ndelay of 170 days between the radio and $\\gamma$-ray flares was revealed using\nthe Discrete Correlation Function (DCF) that can be interpreted in the context\nof a shock model, in which each flare corresponds to the formation of a compact\nsuperluminal component that expands and becomes optically thin at radio\nfrequencies at latter epochs. The difference in flare intensity between\nfrequencies and at a different times, is explained as a consequence of an\nincrease in the Doppler factor $\\delta$, as predicted by the 16 year precession\nmodel proposed by Abraham & Romero, which has a large effect on boosting at\nhigh frequencies while does not affect too much the observed optically thick\nradio emission. We discuss other observable effects of the variation in\n$\\delta$, as the increase in the formation rate of superluminal components, the\nvariations in the time delay between flares and the periodic behaviour of the\nradio light curve that we found compatible with changes in the Doppler factor. \n\n"}
{"id": "1310.2301", "contents": "Title: WISE detections of known QSOs at redshifts greater than six Abstract: We present WISE All-Sky mid-infrared (IR) survey detections of 55% (17/31) of\nthe known QSOs at z>6 from a range of surveys: the SDSS, the CFHT-LS, FIRST,\nSpitzer and UKIDSS. The WISE catalog thus provides a substantial increase in\nthe quantity of IR data available for these sources: 17 are detected in the\nWISE W1 (3.4-micron) band, 16 in W2 (4.6-micron), 3 in W3 (12-micron) and 0 in\nW4 (22-micron). This is particularly important with Spitzer in its warm-mission\nphase and no faint follow-up capability at wavelengths longwards of 5 microns\nuntil the launch of JWST. WISE thus provides a useful tool for understanding\nQSOs found in forthcoming large-area optical/IR sky surveys, using PanSTARRS,\nSkyMapper, VISTA, DES and LSST. The rest-UV properties of the WISE-detected and\nthe WISE-non-detected samples differ: the detections have brighter i/z-band\nmagnitudes and redder rest-UV colors. This suggests that a more aggressive hunt\nfor very-high-redshift QSOs, by combining WISE W1 and W2 data with red observed\noptical colors could be effective at least for a subset of dusty candidate\nQSOs. Stacking the WISE images of the WISE-non-detected QSOs indicates that\nthey are on average significantly fainter than the WISE-detected examples, and\nare thus not narrowly missing detection in the WISE catalog. The WISE-catalog\ndetection of three of our sample in the W3 band indicates that their mid-IR\nflux can be detected individually, although there is no stacked W3 detection of\nsources detected in W1 but not W3. Stacking analyses of WISE data for large AGN\nsamples will be a useful tool, and high-redshift QSOs of all types will be easy\ntargets for JWST. \n\n"}
{"id": "1310.2606", "contents": "Title: Bayesian inference for pulsar timing models Abstract: The extremely regular, periodic radio emission from millisecond pulsars makes\nthem useful tools for studying neutron star astrophysics, general relativity,\nand low-frequency gravitational waves. These studies require that the observed\npulse times of arrival be fit to complex timing models that describe numerous\neffects such as the astrometry of the source, the evolution of the pulsar's\nspin, the presence of a binary companion, and the propagation of the pulses\nthrough the interstellar medium. In this paper, we discuss the benefits of\nusing Bayesian inference to obtain pulsar timing solutions. These benefits\ninclude the validation of linearized least-squares model fits when they are\ncorrect, and the proper characterization of parameter uncertainties when they\nare not; the incorporation of prior parameter information and of models of\ncorrelated noise; and the Bayesian comparison of alternative timing models. We\ndescribe our computational setup, which combines the timing models of Tempo2\nwith the nested-sampling integrator MultiNest. We compare the timing solutions\ngenerated using Bayesian inference and linearized least-squares for three\npulsars: B1953+29, J2317+1439, and J1640+2224, which demonstrate a variety of\nthe benefits that we posit. \n\n"}
{"id": "1310.3485", "contents": "Title: Gaia, counting down to launch Abstract: In this contribution I provide an overview of the the European Space Agency's\nGaia mission just ahead of its launch scheduled for November 2013. \n\n"}
{"id": "1310.3648", "contents": "Title: Fitting density models to observational data - The local Schmidt law in\n  molecular clouds Abstract: We consider the general problem of fitting a parametric density model to\ndiscrete observations, taken to follow a non-homogeneous Poisson point process.\nThis class of models is very common, and can be used to describe many\nastrophysical processes, including the distribution of protostars in molecular\nclouds. We give the expression for the likelihood of a given spatial density\ndistribution of protostars and apply it to infer the most probable dependence\nof the protostellar surface density on the gas surface density. Finally, we\napply this general technique to model the distribution of protostars in the\nOrion molecular cloud and robustly derive the local star formation scaling\n(Schmidt) law for a molecular cloud. We find that in this cloud the\nprotostellar surface density, $\\Sigma_\\mathrm{YSO}$, is directly proportional\nto the square gas column density, here expressed as infrared extinction in the\n$K$-band, $A_K$: more precisely, $\\Sigma_\\mathrm{YSO} = (1.65 \\pm 0.19)\nA_K^{(2.03 \\pm 0.15)}$ stars pc$^{-2}$. \n\n"}
{"id": "1310.3711", "contents": "Title: Modulation of CMB polarization with a warm rapidly-rotating half-wave\n  plate on the Atacama B-Mode Search (ABS) instrument Abstract: We evaluate the modulation of Cosmic Microwave Background (CMB) polarization\nusing a rapidly-rotating, half-wave plate (HWP) on the Atacama B-Mode Search\n(ABS). After demodulating the time-ordered-data (TOD), we find a significant\nreduction of atmospheric fluctuations. The demodulated TOD is stable on time\nscales of 500-1000 seconds, corresponding to frequencies of 1-2 mHz. This\nfacilitates recovery of cosmological information at large angular scales, which\nare typically available only from balloon-borne or satellite experiments. This\ntechnique also achieves a sensitive measurement of celestial polarization\nwithout differencing the TOD of paired detectors sensitive to two orthogonal\nlinear polarizations. This is the first demonstration of the ability to remove\natmospheric contamination at these levels from a ground-based platform using a\nrapidly-rotating HWP. \n\n"}
{"id": "1310.3814", "contents": "Title: Athena+: The first Deep Universe X-ray Observatory Abstract: The Advanced Telescope for High-energy Astrophysics (Athena+) is being\nproposed to ESA as the L2 mission (for a launch in 2028) and is specifically\ndesigned to answer two of the most pressing questions for astrophysics in the\nforthcoming decade: How did ordinary matter assemble into the large scale\nstructures we see today? and how do black holes grow and shape the Universe?\nFor addressing these two issues, Athena+ will provide transformational\ncapabilities in terms of angular resolution, effective area, spectral\nresolution, grasp, that will make it the most powerful X-ray observatory ever\nflown. Such an observatory, when opened to the astronomical community, will be\nused for virtually all classes of astrophysical objects, from high-z gamma-ray\nbursts to the closest planets in our solar neighborhood. In this paper, we\nbriefly review the core science objectives of Athena+, present the science\nrequirements and the foreseen implementation of the mission, and illustrate its\ntransformational capabilities compared to existing facilities. \n\n"}
{"id": "1310.3822", "contents": "Title: The dynamics of z=0.8 H-alpha-selected star-forming galaxies from\n  KMOS/CF-HiZELS Abstract: We present the spatially resolved H-alpha (Ha) dynamics of sixteen\nstar-forming galaxies at z~0.81 using the new KMOS multi-object integral field\nspectrograph on the ESO VLT. These galaxies were selected using 1.18 um\nnarrow-band imaging from the 10 deg^2 CFHT-HiZELS survey of the SA22hr field,\nare found in a ~4Mpc over-density of Ha emitters and likely reside in a\ngroup/intermediate environment, but not a cluster. We confirm and identify a\nrich group of star-forming galaxies at z=0.813+-0.003, with thirteen galaxies\nwithin 1000 km/s of each other, and 7 within a diameter of 3Mpc. All our\ngalaxies are \"typical\" star-forming galaxies at their redshift, 0.8+-0.4\nSFR*(z=0.8), spanning a range of specific star formation rate of sSFR=0.2-1.1\nGyr^-1 and have a median metallicity very close to solar of\n12+log(O/H)=8.62+-0.06. We measure the spatially resolved Ha dynamics of the\ngalaxies in our sample and show that thirteen out of sixteen galaxies can be\ndescribed by rotating disks and use the data to derive inclination corrected\nrotation speeds of 50-275 km/s. The fraction of disks within our sample is\n75+-8, consistent with previous results based on HST morphologies of Ha\nselected galaxies at z~1 and confirming that disks dominate the star formation\nrate density at z~1. Our Ha galaxies are well fitted by the z~1-2 Tully-Fisher\nrelation, confirming the evolution seen in the zero-point. Apart from having,\non average, higher stellar masses and lower sSFRs, our group galaxies at\nz=0.813 present the same mass-metallicity and TF relation as z~1 field\ngalaxies, and are all disk galaxies. \n\n"}
{"id": "1310.4830", "contents": "Title: Strong Lens Time Delay Challenge: I. Experimental Design Abstract: The time delays between point-like images in gravitational lens systems can\nbe used to measure cosmological parameters. The number of lenses with measured\ntime delays is growing rapidly; the upcoming \\emph{Large Synoptic Survey\nTelescope} (LSST) will monitor $\\sim10^3$ strongly lensed quasars. In an effort\nto assess the present capabilities of the community to accurately measure the\ntime delays, and to provide input to dedicated monitoring campaigns and future\nLSST cosmology feasibility studies, we have invited the community to take part\nin a \"Time Delay Challenge\" (TDC). The challenge is organized as a set of\n\"ladders,\" each containing a group of simulated datasets to be analyzed blindly\nby participating teams. Each rung on a ladder consists of a set of realistic\nmock observed lensed quasar light curves, with the rungs' datasets increasing\nin complexity and realism. The initial challenge described here has two\nladders, TDC0 and TDC1. TDC0 has a small number of datasets, and is designed to\nbe used as a practice set by the participating teams. The (non-mandatory)\ndeadline for completion of TDC0 was the TDC1 launch date, December 1, 2013. The\nTDC1 deadline was July 1 2014. Here we give an overview of the challenge, we\nintroduce a set of metrics that will be used to quantify the goodness-of-fit,\nefficiency, precision, and accuracy of the algorithms, and we present the\nresults of TDC0. Thirteen teams participated in TDC0 using 47 different\nmethods. Seven of those teams qualified for TDC1, which is described in the\ncompanion paper II. \n\n"}
{"id": "1310.8076", "contents": "Title: Scintillation observations of PSR B0823+26 Abstract: We present results of the analysis of interstellar scintillation in PSR\nB0823+26. Observations were conducted at a frequency of 1.7 GHz using the 32-m\nTorun Centre for Astronomy radio telescope. More than 50 observing sessions,\nlasting on average 10 h, were conducted between 2003 and 2006. We found\ninterstellar scintillation parameters by means of dynamic spectrum analysis as\nwell as structure function analysis of the flux density variations. We\nidentified two distinctive time-scales, which we believe to be the time-scales\nof diffractive and refractive scintillation. Our results show that at the given\nfrequency the diffractive time-scale in PSR B0823+26 is $\\tau_{diss} =\n19.3^{+1.7}_{-1.6}$ min, the refractive time-scale is $\\tau_{riss} = 144 \\pm\n23$ min and the decorrelation bandwidth is $B_{iss} = 81 \\pm 3$ MHz. \n\n"}
{"id": "1310.8327", "contents": "Title: Snowmass CF1 Summary: WIMP Dark Matter Direct Detection Abstract: As part of the Snowmass process, the Cosmic Frontier WIMP Direct Detection\nsubgroup (CF1) has drawn on input from the Cosmic Frontier and the broader\nParticle Physics community to produce this document. The charge to CF1 was (a)\nto summarize the current status and projected sensitivity of WIMP direct\ndetection experiments worldwide, (b) motivate WIMP dark matter searches over a\nbroad parameter space by examining a spectrum of WIMP models, (c) establish a\ncommunity consensus on the type of experimental program required to explore\nthat parameter space, and (d) identify the common infrastructure required to\npractically meet those goals. \n\n"}
{"id": "1311.2666", "contents": "Title: PyWiFeS: A Rapid Data Reduction Pipeline for the Wide Field Spectrograph\n  (WiFeS) Abstract: We present PyWiFeS, a new Python-based data reduction pipeline for the Wide\nField Spectrograph (WiFeS). PyWiFeS consists of a series of core data\nprocessing routines built on standard scientific Python packages commonly used\nin astronomical applications. Included in PyWiFeS is an implementation of a new\nglobal optical model of the spectrograph which provides wavelengths solutions\naccurate to $\\sim$0.05 \\AA\\ (RMS) across the entire detector. The core PyWiFeS\npackage is designed to be scriptable to enable batch processing of large\nquantities of data, and we present a default format for handling of observation\nmetadata and scripting of data reduction. \n\n"}
{"id": "1311.2800", "contents": "Title: Test of conformal gravity with astrophysical observations Abstract: Since it can describe the rotation curves of galaxies without dark matter and\ncan give rise to accelerated expansion, conformal gravity attracts much\nattention recently. As a theory of modified gravity, it is important to test\nconformal gravity with astrophysical observations. Here we constrain conformal\ngravity with SNIa and Hubble parameter data and investigate whether it suffers\nfrom an age problem with the age of APM~08279+5255. We find conformal gravity\ncan accommodate the age of APM~08279+5255 at 3 $\\sigma$ deviation, unlike most\nof dark energy models which suffer from an age problem. \n\n"}
{"id": "1311.5558", "contents": "Title: Fundamental stellar parameters and metallicities from Bayesian\n  spectroscopy. Application to low- and high-resolution spectra Abstract: We present a unified framework to derive fundamental stellar parameters by\ncombining all available observational and theoretical information for a star.\nThe algorithm relies on the method of Bayesian inference, which for the first\ntime directly integrates the spectroscopic analysis pipeline based on the\nglobal spectrum synthesis and allows for comprehensive and objective error\ncalculations given the priors. Arbitrary input datasets can be included into\nour analysis and other stellar quantities, in addition to stellar age,\neffective temperature, surface gravity, and metallicity, can be computed on\ndemand. We lay out the mathematical framework of the method and apply it to\nseveral observational datasets, including high- and low-resolution spectra\n(UVES, NARVAL, HARPS, SDSS/SEGUE). We find that simpler approximations for the\nspectroscopic PDF, which are inherent to past Bayesian approaches, lead to\ndeviations of several standard deviations and unreliable errors on the same\ndata. By its flexibility and the simultaneous analysis of multiple independent\nmeasurements for a star, it will be ideal to analyse and cross-calibrate the\nlarge ongoing and forthcoming surveys, like Gaia-ESO, SDSS, Gaia and LSST. \n\n"}
{"id": "1312.0919", "contents": "Title: Hierarchical Reverberation Mapping Abstract: Reverberation mapping (RM) is an important technique in studies of active\ngalactic nuclei (AGN). The key idea of RM is to measure the time lag $\\tau$\nbetween variations in the continuum emission from the accretion disc and\nsubsequent response of the broad line region (BLR). The measurement of $\\tau$\nis typically used to estimate the physical size of the BLR and is combined with\nother measurements to estimate the black hole mass $M_{\\rm BH}$. A major\ndifficulty with RM campaigns is the large amount of data needed to measure\n$\\tau$. Recently, Fine et al (2012) introduced a new approach to RM where the\nBLR light curve is sparsely sampled, but this is counteracted by observing a\nlarge sample of AGN, rather than a single system. The results are combined to\ninfer properties of the sample of AGN. In this letter we implement this method\nusing a hierarchical Bayesian model and contrast this with the results from the\nprevious stacked cross-correlation technique. We find that our inferences are\nmore precise and allow for more straightforward interpretation than the stacked\ncross-correlation results. \n\n"}
{"id": "1312.1002", "contents": "Title: Infrared-Faint Radio Sources: A New Population of High-redshift Radio\n  Galaxies Abstract: We present a sample of 1317 Infrared-Faint Radio Sources (IFRSs) that, for\nthe first time, are reliably detected in the infrared, generated by\ncross-correlating the Wide-Field Infrared Survey Explorer (WISE) all-sky survey\nwith major radio surveys. Our IFRSs are brighter in both radio and infrared\nthan the first generation IFRSs that were undetected in the infrared by the\nSpitzer Space Telescope. We present the first spectroscopic redshifts of IFRSs,\nand find that all but one of the IFRSs with spectroscopy has z > 2. We also\nreport the first X-ray counterparts of IFRSs, and present an analysis of radio\nspectra and polarization, and show that they include Gigahertz-Peaked Spectrum,\nCompact Steep Spectrum, and Ultra-Steep Spectrum sources. These results,\ntogether with their WISE infrared colours and radio morphologies, imply that\nour sample of IFRSs represents a population of radio-loud Active Galactic\nNuclei at z > 2. We conclude that our sample consists of lower-redshift\ncounterparts of the extreme first generation IFRSs, suggesting that the fainter\nIFRSs are at even higher redshift. \n\n"}
{"id": "1312.1190", "contents": "Title: Astronomical Redshifts and the Expansion of Space Abstract: In homogeneous cosmological models the wavelength $\\lambda$ of a photon\nexchanged between two fundamental observers changes in proportion to expansion\nof the space $D$ between them, so $\\Delta\\log(\\lambda / D) = 0$. This is\nexactly the same as for a pair of observers receding from each other in flat\nspace-time where the effect is purely kinematic. The interpretation of this has\nbeen the subject of considerable debate, and it has been suggested that all\nredshifts are a relative velocity effect, raising the question of whether the\nwavelength always stretches in proportion to the emitter-receiver separation.\nHere we show that, for low redshift at least, $\\Delta\\log(\\lambda / D)$\nvanishes for a photon exchanged between any two freely-falling observers in a\nspatially constant tidal field, because such a field stretches wavelengths and\nthe space between the observers identically. But in general there is a\nnon-kinematic, and essentially gravitational, component of the redshift that is\ngiven by a weighted average of the gradient of the tidal field along the photon\npath. While the redshift can always be formally expressed using the Doppler\nformula, in situations where the gravitational redshift dominates, the\n`relative velocity' is typically quite different from the rate of change of $D$\nand it is misleading to think of the redshift as being a velocity or\n`kinematic' effect. \n\n"}
{"id": "1312.4602", "contents": "Title: Very Large Array Sky Survey (VLASS) white paper: Go deep, not wide Abstract: The Karl G. Jansky Very Large Array (VLA) is currently the world's most\npowerful cm-wavelength telescope. However, within a few years this blanket\nstatement will no longer be entirely true, due to the emergence of a new breed\nof pre-SKA radio telescopes with improved surveying capabilities. This white\npaper explores a region of sensitivity-area parameter space where an investment\nof a few thousand hours through a VLA Sky Survey (VLASS) will yield a unique\ndataset with extensive scientific utility and legacy value well into the SKA\nera: a deep full-polarization L-band survey covering a few square degrees in\nA-configuration. Science that can be addressed with a deep VLASS includes\ngalaxy evolution, dark energy and dark matter using radio weak lensing, and\ncosmic magnetism. A deep VLASS performed in a field with extensive\nmultiwavelength data would also deliver a gold standard multiwavelength catalog\nto inform wider and shallower surveys such as SKA1-survey. \n\n"}
{"id": "1312.5753", "contents": "Title: SOMz: photometric redshift PDFs with self organizing maps and random\n  atlas Abstract: In this paper we explore the applicability of the unsupervised machine\nlearning technique of Self Organizing Maps (SOM) to estimate galaxy photometric\nredshift probability density functions (PDFs). This technique takes a\nspectroscopic training set, and maps the photometric attributes, but not the\nredshifts, to a two dimensional surface by using a process of competitive\nlearning where neurons compete to more closely resemble the training data\nmultidimensional space. The key feature of a SOM is that it retains the\ntopology of the input set, revealing correlations between the attributes that\nare not easily identified. We test three different 2D topological mapping:\nrectangular, hexagonal, and spherical, by using data from the DEEP2 survey. We\nalso explore different implementations and boundary conditions on the map and\nalso introduce the idea of a random atlas where a large number of different\nmaps are created and their individual predictions are aggregated to produce a\nmore robust photometric redshift PDF. We also introduced a new metric, the\n$I$-score, which efficiently incorporates different metrics, making it easier\nto compare different results (from different parameters or different\nphotometric redshift codes). We find that by using a spherical topology mapping\nwe obtain a better representation of the underlying multidimensional topology,\nwhich provides more accurate results that are comparable to other,\nstate-of-the-art machine learning algorithms. Our results illustrate that\nunsupervised approaches have great potential for many astronomical problems,\nand in particular for the computation of photometric redshifts. \n\n"}
{"id": "1401.0716", "contents": "Title: Radio Astronomy in LSST Era Abstract: A community meeting on the topic of \"Radio Astronomy in the LSST Era\" was\nhosted by the National Radio Astronomy Observatory in Charlottesville, VA (2013\nMay 6--8). The focus of the workshop was on time domain radio astronomy and sky\nsurveys. For the time domain, the extent to which radio and visible wavelength\nobservations are required to understand several classes of transients was\nstressed, but there are also classes of radio transients for which no visible\nwavelength counterpart is yet known, providing an opportunity for discovery.\nFrom the LSST perspective, the LSST is expected to generate as many as 1\nmillion alerts nightly, which will require even more selective specification\nand identification of the classes and characteristics of transients that can\nwarrant follow up, at radio or any wavelength. The LSST will also conduct a\ndeep survey of the sky, producing a catalog expected to contain over 38 billion\nobjects in it. Deep radio wavelength sky surveys will also be conducted on a\ncomparable time scale, and radio and visible wavelength observations are part\nof the multi-wavelength approach needed to classify and understand these\nobjects. Radio wavelengths are valuable because they are unaffected by dust\nobscuration and, for galaxies, contain contributions both from star formation\nand from active galactic nuclei. The workshop touched on several other topics,\non which there was consensus including the placement of other LSST \"Deep\nDrilling Fields,\" inter-operability of software tools, and the challenge of\nfiltering and exploiting the LSST data stream. There were also topics for which\nthere was insufficient time for full discussion or for which no consensus was\nreached, which included the procedures for following up on LSST observations\nand the nature for future support of researchers desiring to use LSST data\nproducts. \n\n"}
{"id": "1401.0729", "contents": "Title: The Host Galaxies of Fast-Ejecta Core-Collapse Supernovae Abstract: Spectra of broad-lined Type Ic supernovae (SN Ic-BL), the only kind of SN\nobserved at the locations of long-duration gamma-ray bursts (LGRBs), exhibit\nwide features indicative of high ejecta velocities (~0.1c). We study the host\ngalaxies of a sample of 245 low-redshift (z<0.2) core-collapse SN, including 17\nSN Ic-BL, discovered by galaxy-untargeted searches, and 15 optically luminous\nand dust-obscured z<1.2 LGRBs. We show that, in comparison with SDSS galaxies\nhaving similar stellar masses, the hosts of low-redshift SN Ic-BL and z<1.2\nLGRBs have high stellar-mass and star-formation-rate densities. Core-collapse\nSN having typical ejecta velocities, in contrast, show no preference for such\ngalaxies. Moreover, we find that the hosts of SN Ic-BL, unlike those of SN\nIb/Ic and SN II, exhibit high gas velocity dispersions for their stellar\nmasses. The patterns likely reflect variations among star-forming environments,\nand suggest that LGRBs can be used as probes of conditions in high-redshift\ngalaxies. They may be caused by efficient formation of massive binary\nprogenitors systems in densely star-forming regions, or, less probably, a\nhigher fraction of stars created with the initial masses required for a SN\nIc-BL or LGRB. Finally, we show that the preference of SN Ic-BL and LGRBs for\ngalaxies with high stellar-mass and star-formation-rate densities cannot be\nattributed to a preference for low metal abundances but must reflect the\ninfluence of a separate environmental factor. \n\n"}
{"id": "1401.1151", "contents": "Title: An improved model of Charge Transfer Inefficiency and correction\n  algorithm for the Hubble Space Telescope Abstract: Charge-Coupled Device (CCD) detectors, widely used to obtain digital imaging,\ncan be damaged by high energy radiation. Degraded images appear blurred,\nbecause of an effect known as Charge Transfer Inefficiency (CTI), which trails\nbright objects as the image is read out. It is often possible to correct most\nof the trailing during post-processing, by moving flux back to where it\nbelongs. We compare several popular algorithms for this: quantifying the effect\nof their physical assumptions and tradeoffs between speed and accuracy. We\ncombine their best elements to construct a more accurate model of damaged CCDs\nin the Hubble Space Telescope's Advanced Camera for Surveys/Wide Field Channel,\nand update it using data up to early 2013. Our algorithm now corrects 98% of\nCTI trailing in science exposures, a substantial improvement over previous\nwork. Further progress will be fundamentally limited by the presence of read\nnoise. Read noise is added after charge transfer so does not get trailed - but\nit is incorrectly untrailed during post-processing. \n\n"}
{"id": "1401.1867", "contents": "Title: Nonparametric 3D map of the IGM using the Lyman-alpha forest Abstract: Visualizing the high-redshift Universe is difficult due to the dearth of\navailable data; however, the Lyman-alpha forest provides a means to map the\nintergalactic medium at redshifts not accessible to large galaxy surveys.\nLarge-scale structure surveys, such as the Baryon Oscillation Spectroscopic\nSurvey (BOSS), have collected quasar (QSO) spectra that enable the\nreconstruction of HI density fluctuations. The data fall on a collection of\nlines defined by the lines-of-sight (LOS) of the QSO, and a major issue with\nproducing a 3D reconstruction is determining how to model the regions between\nthe LOS. We present a method that produces a 3D map of this relatively\nuncharted portion of the Universe by employing local polynomial smoothing, a\nnonparametric methodology. The performance of the method is analyzed on\nsimulated data that mimics the varying number of LOS expected in real data, and\nthen is applied to a sample region selected from BOSS. Evaluation of the\nreconstruction is assessed by considering various features of the predicted 3D\nmaps including visual comparison of slices, PDFs, counts of local minima and\nmaxima, and standardized correlation functions. This 3D reconstruction allows\nfor an initial investigation of the topology of this portion of the Universe\nusing persistent homology. \n\n"}
{"id": "1401.2109", "contents": "Title: SPIRE Map-Making Test Report Abstract: The photometer section of SPIRE is one of the key instruments on board of\nHerschel. Its legacy depends very much on how well the scanmap observations\nthat it carried out during the Herschel mission can be converted to high\nquality maps. In order to have a comprehensive assessment on the current status\nof SPIRE map-making, as well as to provide guidance for future development of\nthe SPIRE scan-map data reduction pipeline, we carried out a test campaign on\nSPIRE map-making. In this report, we present results of the tests in this\ncampaign. \n\n"}
{"id": "1401.3295", "contents": "Title: Search for An Annual Modulation in Three Years of CoGeNT Dark Matter\n  Detector Data Abstract: Weakly Interacting Massive Particles (WIMPs) are well-established dark matter\ncandidates. WIMP interactions with sensitive detectors are expected to display\na characteristic annual modulation in rate. We release a dataset spanning 3.4\nyears of operation from a low-background germanium detector, designed to search\nfor this signature. A previously reported modulation persists, concentrated in\na region of the energy spectrum populated by an exponential excess of unknown\norigin. Its phase and period agree with phenomenological expectations, but its\namplitude is a factor $\\sim$4-7 larger than predicted for a standard WIMP\ngalactic halo. We consider the possibility of a non-Maxwellian local halo\nvelocity distribution as a plausible explanation, able to help reconcile\nrecently reported WIMP search anomalies. \n\n"}
{"id": "1401.4094", "contents": "Title: Herschel-ATLAS/GAMA: SDSS cross-correlation induced by weak lensing Abstract: We report a highly significant ($>10\\sigma$) spatial correlation between\ngalaxies with $S_{350\\mu\\rm m}\\ge 30\\,$mJy detected in the equatorial fields of\nthe \\textsl{Herschel} Astrophysical Terahertz Large Area Survey (H-ATLAS) with\nestimated redshifts $\\gtrsim 1.5$, and SDSS or GAMA galaxies at $0.2\\le z\\le\n0.6$. The significance of the cross-correlation is much higher than those\nreported so far for samples with non-overlapping redshift distributions\nselected in other wavebands. Extensive, realistic simulations of clustered\nsub-mm galaxies amplified by foreground structures confirm that the\ncross-correlation is explained by weak gravitational lensing ($\\mu<2$). The\nsimulations also show that the measured amplitude and range of angular scales\nof the signal are larger than can be accounted for by galaxy-galaxy weak\nlensing. However, for scales $\\lesssim 2\\,$arcmin, the signal can be reproduced\nif SDSS/GAMA galaxies act as signposts of galaxy groups/clusters with halo\nmasses in the range $10^{13.2}$--$10^{14.5} M_{\\odot}$. The signal detected on\nlarger scales appears to reflect the clustering of such halos. \n\n"}
{"id": "1401.5864", "contents": "Title: The high-redshift star formation rate derived from GRBs: possible origin\n  and cosmic reionization Abstract: The collapsar model of long gamma-ray bursts (GRBs) indicates that they may\ntrace the star formation history. So long GRBs may be a useful tool of\nmeasuring the high-redshift star formation rate (SFR). The collapsar model\nexplains GRB formation via the collapse of a rapidly rotating massive star with\n$M> 30M_\\odot$ into a black hole, which may imply a decrease of SFR at high\nredshift. However, we find that the \\emph{Swift} GRBs during 2005-2012 are\nbiased tracing the SFR, including a factor about $(1+z)^{0.5}$, which is in\nagreement with recent results. After taking this factor, the SFR derived from\nGRBs does not show steep drop up to $z\\sim 9.4$. We consider the GRBs produced\nby rapidly rotating metal-poor stars with low masses to explain the\nhigh-redshift GRB rate excess. The chemically homogeneous evolution scenario\n(CHES) of rapidly rotating stars with mass larger than $12M_\\odot$ is\nrecognized as a promising path towards collapsars in connection with long GRBs.\nOur results indicate that the stars in the mass range $12M_\\odot<M<30M_\\odot$\nfor low enough metallicity $Z\\leq 0.004$ with the GRB efficiency factor\n$10^{-5}$ can fit the derived SFR with good accuracy. Combining these two\nfactors, we find that the conversion efficiency from massive stars to GRBs is\nenhanced by a factor of 10, which may be able to explain the excess of the\nhigh-redshift GRB rate. We also investigate the cosmic reionization history\nusing the derived SFR. The GRB-inferred SFR would be sufficient to maintain\ncosmic reionization over $6<z<10$ and reproduce the observed optical depth of\nThomson scattering to the cosmic microwave background. \n\n"}
{"id": "1401.6171", "contents": "Title: Star Formation and Substructure in Galaxy Clusters Abstract: We investigate the relationship between star formation (SF) and substructure\nin a sample of 107 nearby galaxy clusters using data from the Sloan Digital Sky\nSurvey (SDSS). Several past studies of individual galaxy clusters have\nsuggested that cluster mergers enhance cluster SF, while others find no such\nrelationship. The SF fraction in multi-component clusters (0.228 +/- 0.007) is\nhigher than that in single-component clusters (0.175 +/- 0.016) for galaxies\nwith M^0.1_r < -20.5. In both single- and multi-component clusters, the\nfraction of star-forming galaxies increases with clustercentric distance and\ndecreases with local galaxy number density, and multi-component clusters show a\nhigher SF fraction than single-component clusters at almost all clustercentric\ndistances and local densities. Comparing the SF fraction in individual clusters\nto several statistical measures of substructure, we find weak, but in most\ncases significant at greater than 2 sigma, correlations between substructure\nand SF fraction. These results could indicate that cluster mergers may cause\nweak but significant SF enhancement in clusters, or unrelaxed clusters exhibit\nslightly stronger SF due to their less evolved states relative to relaxed\nclusters. \n\n"}
{"id": "1402.3268", "contents": "Title: Properties of Submillimeter Galaxies in the CANDELS GOODS-S Field Abstract: We derive physical properties of 10 submillimeter galaxies located in the\nCANDELS coverage of the GOODS-S field. The galaxies were first identified as\nsubmillimeter sources with the LABOCA bolometer and subsequently targeted for\n870um continuum observation with ALMA. The high angular resolution of the ALMA\nimaging allows secure counterparts to be identified in the CANDELS multiband\ndataset. The CANDELS data provide deep photometric data from UV through\nnear-infrared wavelengths. Using synthetic spectral energy distributions, we\nderive photometric redshifts, stellar masses, extinction, ages, and the star\nformation history. The redshift range is z=1.65-4.76, with two of the galaxies\nlocated at z>4. Two SMG counterparts have stellar masses 2-3 orders of\nmagnitude lower than the rest. The remaining SMG counterparts have stellar\nmasses around 1x10^11 Msun. The stellar population in the SMGs is typically\nolder than the expected duration of the submillimeter phase, suggesting that\nthe star formation history of submillimeter galaxies is more complex than a\nsingle burst. Non-parametric morphology indices suggest that the SMG\ncounterparts are among the most asymmetric systems compared with galaxies of\nthe same stellar mass and redshift. The HST images shows that 3 of the SMGs are\nassociated with on-going mergers. The remaining counterparts are isolated.\nEstimating the dust and molecular gas mass from the submm fluxes, and comparing\nwith our stellar masses shows that the molecular gas mass fraction of SMGs is\n~28% and that the final stellar mass is likely to be (1-2)x10^11 Msun. \n\n"}
{"id": "1402.4427", "contents": "Title: Radio-Optical Reference Frame Link Using the US Naval Observatory\n  Astrograph and Deep CCD Imaging Abstract: Between 1997 and 2004 several observing runs were conducted mainly with the\nCTIO 0.9 m to image ICRF counterparts (mostly QSOs) in order to determine\naccurate optical positions. Contemporary to these deep CCD images the same\nfields were observed with the US Naval Observatory (USNO) astrograph in the\nsame bandpass. They provide accurate positions on the Hipparcos/Tycho-2 system\nfor stars in the 10 to 16 magnitude range used as reference stars for the deep\nCCD imaging data. Here we present final optical position results of 413 sources\nbased on reference stars obtained by dedicated astrograph observations which\nwere reduced following 2 different procedures. These optical positions are\ncompared to radio VLBI positions. The current optical system is not perfectly\naligned to the ICRF radio system with rigid body rotation angles of 3 to 5 mas\n(= 3 sigma level) found between them for all 3 axes. Furthermore,\nstatistically, the optical minus radio position differences are found to exceed\nthe total, combined, known errors in the observations. Systematic errors in the\noptical reference star positions as well as physical offsets between the\ncenters of optical and radio emissions are both identified as likely causes. A\ndetrimental, astrophysical, random noise (DARN) component is postulated to be\non about the 10 mas level. If confirmed by future observations, this could\nseverely limit the Gaia to ICRF reference frame alignment accuracy to an error\nof about 0.5 mas per coordinate axis with the current number of sources\nenvisioned to provide the link. A list of 36 ICRF sources without the detection\nof an optical counterpart to a limiting magnitude of about R=22 is provided as\nwell. \n\n"}
{"id": "1402.7180", "contents": "Title: Online classification for time-domain astronomy Abstract: The advent of synoptic sky surveys has spurred the development of techniques\nfor real-time classification of astronomical sources in order to ensure timely\nfollow-up with appropriate instruments. Previous work has focused on algorithm\nselection or improved light curve representations, and naively convert light\ncurves into structured feature sets without regard for the time span or phase\nof the light curves. In this paper, we highlight the violation of a fundamental\nmachine learning assumption that occurs when archival light curves with long\nobservational time spans are used to train classifiers that are applied to\nlight curves with fewer observations. We propose two solutions to deal with the\nmismatch in the time spans of training and test light curves. The first is the\nuse of classifier committees where each classifier is trained on light curves\nof different observational time spans. Only the committee member whose training\nset matches the test light curve time span is invoked for classification. The\nsecond solution uses hierarchical classifiers that are able to predict source\ntypes both individually and by sub-group, so that the user can trade-off an\nearlier, more robust classification with classification granularity. We test\nboth methods using light curves from the MACHO survey, and demonstrate their\nusefulness in improving performance over similar methods that naively train on\nall available archival data. \n\n"}
{"id": "1403.3539", "contents": "Title: Scintillating bolometers: a key for determining WIMP parameters Abstract: In the last decade direct detection Dark Matter (DM) experiments have\nincreased enormously their sensitivity and ton-scale setups have been proposed,\nespecially using germanium and xenon targets with double readout and background\ndiscrimination capabilities. In light of this situation, we study the prospects\nfor determining the parameters of Weakly Interacting Massive Particle (WIMP) DM\n(mass, spin-dependent (SD) and spin-independent (SI) cross section off\nnucleons) by combining the results of such experiments in the case of a\nhypothetical detection. In general, the degeneracy between the SD and SI\ncomponents of the scattering cross section can only be removed using targets\nwith different sensitivities to these components. Scintillating bolometers,\nwith particle discrimination capability, very good energy resolution and\nthreshold and a wide choice of target materials, are an excellent tool for a\nmultitarget complementary DM search. We investigate how the simultaneous use of\nscintillating targets with different SD-SI sensitivities and/or light isotopes\n(as the case of CaF2 and NaI) significantly improves the determination of the\nWIMP parameters. In order to make the analysis more realistic we include the\neffect of uncertainties in the halo model and in the spin-dependent nuclear\nstructure functions, as well as the effect of a thermal quenching different\nfrom 1. \n\n"}
{"id": "1403.4353", "contents": "Title: Detection of a faint fast-moving near-Earth asteroid using synthetic\n  tracking technique Abstract: We report a detection of a faint near-Earth asteroid (NEA), which was done\nusing our synthetic tracking technique and the CHIMERA instrument on the\nPalomar 200-inch telescope. This asteroid, with apparent magnitude of 23, was\nmoving at 5.97 degrees per day and was detected at a signal-to-noise ratio\n(SNR) of 15 using 30 sec of data taken at a 16.7 Hz frame rate. The detection\nwas confirmed by a second observation one hour later at the same SNR. The\nasteroid moved 7 arcseconds in sky over the 30 sec of integration time because\nof its high proper motion. The synthetic tracking using 16.7 Hz frames avoided\nthe trailing loss suffered by conventional techniques relying on 30-sec\nexposure, which would degrade the surface brightness of image on CCD to an\napproximate magnitude of 25. This detection was a result of our 12-hour blind\nsearch conducted on the Palomar 200-inch telescope over two nights on September\n11 and 12, 2013 scanning twice over six 5.0 deg x 0.043 deg fields. The fact\nthat we detected only one NEA, is consistent with Harris's estimation of the\nasteroid population distribution, which was used to predict the detection of\n1--2 asteroids of absolute magnitude H=28--31 per night. The design of\nexperiment, data analysis method, and algorithms for estimating astrometry are\npresented. We also demonstrate a milli-arcsecond astrometry using observations\nof two bright asteroids with the same system on Apr 3, 2013. Strategies of\nscheduling observations to detect small and fast-moving NEAs with the synthetic\ntracking technique are discussed. \n\n"}
{"id": "1403.5067", "contents": "Title: Generic inference of inflation models by non-Gaussianity and primordial\n  power spectrum reconstruction Abstract: We present a generic inference method for inflation models from observational\ndata by the usage of higher-order statistics of the curvature perturbation on\nuniform density hypersurfaces. This method is based on the calculation of the\nposterior for the primordial non-Gaussianity parameters $f_\\text{NL}$ and\n$g_\\text{NL}$, which in general depend on specific parameters of inflation and\nreheating models, and enables to discriminate among the still viable inflation\nmodels. To keep analyticity as far as possible to dispense with numerically\nexpensive sampling techniques a saddle-point approximation is introduced, whose\nprecision is validated for a numerical toy example. The mathematical\nformulation is done in a generic way so that the approach remains applicable to\ncosmic microwave background data as well as to large scale structure data.\nAdditionally, we review a few currently interesting inflation models and\npresent numerical toy examples thereof in two and three dimensions to\ndemonstrate the efficiency of the higher-order statistics method. A second\nquantity of interest is the primordial power spectrum. Here, we present two\nBayesian methods to infer it from observational data, the so called critical\nfilter and an extension thereof with smoothness prior, both allowing for a\nnon-parametric spectrum reconstruction. These methods are able to reconstruct\nthe spectra of the observed perturbations and the primordial ones of curvature\nperturbation even in case of non-Gaussianity and partial sky coverage. We argue\nthat observables like $T-$ and $B-$modes permit to measure both spectra. This\nalso allows to infer the level of non-Gaussianity generated since inflation. \n\n"}
{"id": "1404.0168", "contents": "Title: Note on Power-Law Inflation in Noncommutative Space-Time Abstract: In this paper, we propose a new method to calculate the mode functions in the\nnoncommutative power-law inflation model. In this model, all the modes created\nwhen the stringy space-time uncertainty relation is satisfied are generated\ninside the Hubble horizon during inflation. It turns out that a linear term\ndescribing the noncommutative space-time effect contributes to the power\nspectra of the scalar and tensor perturbations. Confronting this model with\nlatest results from \\textit{Planck} and BICEP2, we constrain the parameters in\nthis model and we find it is well consistent with observations. \n\n"}
{"id": "1404.1267", "contents": "Title: NANOGrav Limits on Gravitational Waves from Individual Supermassive\n  Black Hole Binaries in Circular Orbits Abstract: The North American Nanohertz Observatory for Gravitational Waves (NANOGrav)\nproject currently observes 43 pulsars using the Green Bank and Arecibo radio\ntelescopes. In this work we use a subset of 17 pulsars timed for a span of\nroughly five years (2005--2010). We analyze these data using standard pulsar\ntiming models, with the addition of time-variable dispersion measure and\nfrequency-variable pulse shape terms. Within the timing data, we perform a\nsearch for continuous gravitational waves from individual supermassive black\nhole binaries in circular orbits using robust frequentist and Bayesian\ntechniques. We find that there is no evidence for the presence of a detectable\ncontinuous gravitational wave; however, we can use these data to place the most\nconstraining upper limits to date on the strength of such gravitational waves.\nUsing the full 17 pulsar dataset we place a 95% upper limit on the sky-averaged\nstrain amplitude of $h_0\\lesssim 3.8\\times 10^{-14}$ at a frequency of 10 nHz.\nFurthermore, we place 95% \\emph{all sky} lower limits on the luminosity\ndistance to such gravitational wave sources finding that the $d_L \\gtrsim 425$\nMpc for sources at a frequency of 10 nHz and chirp mass $10^{10}{\\rm\nM}_{\\odot}$. We find that for gravitational wave sources near our best timed\npulsars in the sky, the sensitivity of the pulsar timing array is increased by\na factor of $\\sim$4 over the sky-averaged sensitivity. Finally we place limits\non the coalescence rate of the most massive supermassive black hole binaries. \n\n"}
{"id": "1404.3855", "contents": "Title: Can Self-Ordering Scalar Fields explain the BICEP2 B-mode signal? Abstract: We show that self-ordering scalar fields (SOSF), i.e. non-topological cosmic\ndefects arising after a global phase transition, cannot explain the B-mode\nsignal recently announced by BICEP2. We compute the full $C_\\ell^{B}$ angular\npower spectrum of B-modes due to the vector and tensor perturbations of SOSF,\nmodeled in the large-N limit of a spontaneous broken global O(N) symmetry. We\nconclude that the low-$\\ell$ multipoles detected by BICEP2 cannot be due mainly\nto SOSF, since they have the wrong spectrum at low multipoles. As a byproduct\nwe derive the first cosmological constraints on this model, showing that the\nBICEP2 B-mode polarization data admits at most a 2-3% contribution from SOSF in\nthe temperature anisotropies, similar to (but somewhat tighter than) the\nrecently studied case of cosmic strings. \n\n"}
{"id": "1404.5682", "contents": "Title: Assessing Pulsar Timing Array Sensitivity to Gravitational Wave Bursts\n  with Memory Abstract: Highly energetic astrophysical phenomena like supermassive black hole binary\n(SMBHB) mergers are predicted to emit prodigious amounts of gravitational waves\n(GWs). An anticipated component of the gravitational waveform known as \"memory\"\nis permanent and non-oscillatory. For SMBHB mergers, the memory is created\nprimarily during the most violent moments of the inspiral immediately preceding\nthe final plunge and ring-down when the strongest gravitational fields are at\nwork and the non-linearities of general relativity are most pronounced. The\nessentially time-domain nature of memory makes it forbiddingly difficult to\ndetect with ground based GW detectors, leaving pulsar timing array (PTA)\nexperiments as the most promising means by which it may be detected and\nstudied. In this paper, we discuss how GW bursts with memory (BWMs) influence\npulsar timing experiments and develop methods to assess how sensitive modern\ntiming efforts are to such GW events. We discuss how PTA searches for BWMs can\nbe used to constrain the rate of BWMs and how these constraints relate to\ninformation regarding the population of SMBHBs. \n\n"}
{"id": "1404.6442", "contents": "Title: Sparse Representation of Photometric Redshift PDFs: Preparing for\n  Petascale Astronomy Abstract: One of the consequences of entering the era of precision cosmology is the\nwidespread adoption of photometric redshift probability density functions\n(PDFs). Both current and future photometric surveys are expected to obtain\nimages of billions of distinct galaxies. As a result, storing and analyzing all\nof these PDFs will be non-trivial and even more severe if a survey plans to\ncompute and store multiple different PDFs. In this paper we propose the use of\na sparse basis representation to fully represent individual photo-$z$ PDFs. By\nusing an Orthogonal Matching Pursuit algorithm and a combination of Gaussian\nand Voigt basis functions, we demonstrate how our approach is superior to a\nmulti-Gaussian fitting, as we require approximately half of the parameters for\nthe same fitting accuracy with the additional advantage that an entire PDF can\nbe stored by using a 4-byte integer per basis function, and we can achieve\nbetter accuracy by increasing the number of bases. By using data from the\nCFHTLenS, we demonstrate that only ten to twenty points per galaxy are\nsufficient to reconstruct both the individual PDFs and the ensemble redshift\ndistribution, $N(z)$, to an accuracy of 99.9% when compared to the one built\nusing the original PDFs computed with a resolution of $\\delta z = 0.01$,\nreducing the required storage of two hundred original values by a factor of ten\nto twenty. Finally, we demonstrate how this basis representation can be\ndirectly extended to a cosmological analysis, thereby increasing computational\nperformance without losing resolution nor accuracy. \n\n"}
{"id": "1404.7037", "contents": "Title: Metallicity and Star Formation Activities of the Interacting System Arp\n  86 from Observation with MOS on Xinglong 2.16m Telescope Abstract: We present an analysis of the metallicity and star formation activities of\nHII regions in the interacting system Arp 86, based on the first scientific\nobservation of the multi-object spectroscopy on the 2.16m Telescope at Xinglong\nObservatory. We find that the oxygen abundance gradient in Arp 86 is flatter\nthan that in normal disk galaxies, which confirms that gas inflows caused by\ntidal forces during encounters can flatten the metallicity distributions in\ngalaxies. The companion galaxy NGC 7752 is currently experiencing a galaxy-wide\nstarburst with higher surface density of star formation rate than the main\ngalaxy NGC 7753, which can be explained that the companion galaxy is more\nsusceptible to the effects of interaction than the primary. We also find that\nthe galaxy 2MASX J23470758+2926531 has similar abundance and star formation\nproperties to NGC 7753, and may be a part of the Arp 86 system. \n\n"}
{"id": "1405.1431", "contents": "Title: Redshift evolution of the dynamical properties of massive galaxies from\n  SDSS-III/BOSS Abstract: We study the redshift evolution of the dynamical properties of ~180,000\nmassive galaxies from SDSS-III/BOSS combined with a local early-type galaxy\nsample from SDSS-II in the redshift range 0.1<z< 0.6. The typical stellar mass\nof this sample is Mstar~2x10^{11} Msun. We analyze the evolution of the galaxy\nparameters effective radius, stellar velocity dispersion, and the dynamical to\nstellar mass ratio with redshift. As the effective radii of BOSS galaxies at\nthese redshifts are not well resolved in the SDSS imaging we calibrate the SDSS\nsize measurements with HST/COSMOS photometry for a sub-sample of galaxies. We\nfurther apply a correction for progenitor bias to build a sample which consists\nof a coeval, passively evolving population. Systematic errors due to size\ncorrection and the calculation of dynamical mass, are assessed through Monte\nCarlo simulations. At fixed stellar or dynamical mass, we find moderate\nevolution in galaxy size and stellar velocity dispersion, in agreement with\nprevious studies. We show that this results in a decrease of the dynamical to\nstellar mass ratio with redshift at >2sigma significance. By combining our\nsample with high-redshift literature data we find that this evolution of the\ndynamical to stellar mass ratio continues beyond z~0.7 up to z>2 as Mdyn/Mstar~\n(1+z)^{-0.30+/- 0.12} further strengthening the evidence for an increase of\nMdyn/Mstar with cosmic time. This result is in line with recent predictions\nfrom galaxy formation simulations based on minor merger driven mass growth, in\nwhich the dark matter fraction within the half-light radius increases with\ncosmic time. \n\n"}
{"id": "1405.3590", "contents": "Title: EFTCAMB/EFTCosmoMC: Numerical Notes v3.0 Abstract: EFTCAMB/EFTCosmoMC are publicly available patches to the CAMB/CosmoMC codes\nimplementing the effective field theory approach to single scalar field dark\nenergy and modified gravity models. With the present numerical notes we provide\na guide to the technical details of the code. Moreover we reproduce, as they\nappear in the code, the complete set of the modified equations and the\nexpressions for all the other relevant quantities used to construct these\npatches. We submit these notes to the arXiv to grant full and permanent access\nto this material which provides very useful guidance to the numerical\nimplementation of the EFT framework. We will update this set of notes when\nrelevant modifications to the EFTCAMB/EFTCosmoMC codes will be released. The\npresent version is based on the version of EFTCAMB/EFTCosmoMC Sep17. \n\n"}
{"id": "1406.0559", "contents": "Title: Adventures in the microlensing cloud: large datasets, eResearch tools,\n  and GPUs Abstract: As astronomy enters the petascale data era, astronomers are faced with new\nchallenges relating to storage, access and management of data. A shift from the\ntraditional approach of combining data and analysis at the desktop to the use\nof remote services, pushing the computation to the data, is now underway. In\nthe field of cosmological gravitational microlensing, future synoptic all--sky\nsurveys are expected to bring the number of multiply imaged quasars from the\nfew tens that are currently known to a few thousands. This inflow of\nobservational data, together with computationally demanding theoretical\nmodelling via the production of microlensing magnification maps, requires a new\napproach. We present our technical solutions to supporting the GPU-Enabled,\nHigh Resolution cosmological MicroLensing parameter survey (GERLUMPH). This\nextensive dataset for cosmological microlensing modelling comprises over 70,000\nindividual magnification maps and ${\\sim}10^6$ related results. We describe our\napproaches to hosting, organizing, and serving ${\\sim}$30 Terabytes of data and\nmetadata products. We present a set of online analysis tools developed with\nPHP, JavaScript and WebGL to support access and analysis of GELRUMPH data in a\nWeb browser. We discuss our use of graphics processing units (GPUs) to\naccelerate data production, and we release the core of the GPU-D direct inverse\nray--shooting code (Thompson et al., 2010; Astrophysics Source Code Library,\nrecord ascl:1403.001) used to generate the magnification maps. All of the\nGERLUMPH data and tools are available online from http://gerlumph.swin.edu.au .\nThis project made use of gSTAR, the GPU Supercomputer for Theoretical\nAstrophysical Research. \n\n"}
{"id": "1406.1651", "contents": "Title: The insignificant evolution of the richness-mass relation of galaxy\n  clusters Abstract: We analysed the richness--mass scaling of 23 very massive clusters at\n$0.15<z<0.55$ with homogenously measured weak-lensing masses and richnesses\nwithin a fixed aperture of $0.5$ Mpc radius. We found that the richness--mass\nscaling is very tight (the scatter is $<0.09$ dex with 90 \\% probability) and\nindependent of cluster evolutionary status and morphology. This implies a close\nassociation between infall and evolution of dark matter and galaxies in the\ncentral region of clusters. We also found that the evolution of the\nrichness-mass intercept is minor at most, and, given the minor mass evolution\nacross the studied redshift range, the richness evolution of individual massive\nclusters also turns out to be very small. Finally, it was paramount to account\nfor the cluster mass function and the selection function. Ignoring them would\nled to biases larger than the (otherwise quoted) errors. Our study benefits\nfrom: a) weak-lensing masses instead of proxy-based masses thereby removing the\nambiguity between a real trend and one induced by an accounted evolution of the\nused mass proxy; b) the use of projected masses that simplify the statistical\nanalysis thereby not requiring consideration of the unknown covariance induced\nby the cluster orientation/triaxiality; c) the use of aperture masses as they\nare free of the pseudo-evolution of mass definitions anchored to the evolving\ndensity of the Universe; d) a proper accounting of the sample selection\nfunction and of the Malmquist-like effect induced by the cluster mass function;\ne) cosmological simulations for the computation of the cluster mass function,\nits evolution, and the mass growth of each individual cluster. \n\n"}
{"id": "1406.2267", "contents": "Title: Calibrating CHIME, A New Radio Interferometer to Probe Dark Energy Abstract: The Canadian Hydrogen Intensity Mapping Experiment (CHIME) is a transit\ninterferometer currently being built at the Dominion Radio Astrophysical\nObservatory (DRAO) in Penticton, BC, Canada. We will use CHIME to map neutral\nhydrogen in the frequency range 400 -- 800\\,MHz over half of the sky, producing\na measurement of baryon acoustic oscillations (BAO) at redshifts between 0.8 --\n2.5 to probe dark energy. We have deployed a pathfinder version of CHIME that\nwill yield constraints on the BAO power spectrum and provide a test-bed for our\ncalibration scheme. I will discuss the CHIME calibration requirements and\ndescribe instrumentation we are developing to meet these requirements. \n\n"}
{"id": "1406.3020", "contents": "Title: Exoplanet population inference and the abundance of Earth analogs from\n  noisy, incomplete catalogs Abstract: No true extrasolar Earth analog is known. Hundreds of planets have been found\naround Sun-like stars that are either Earth-sized but on shorter periods, or\nelse on year-long orbits but somewhat larger. Under strong assumptions,\nexoplanet catalogs have been used to make an extrapolated estimate of the rate\nat which Sun-like stars host Earth analogs. These studies are complicated by\nthe fact that every catalog is censored by non-trivial selection effects and\ndetection efficiencies, and every property (period, radius, etc.) is measured\nnoisily. Here we present a general hierarchical probabilistic framework for\nmaking justified inferences about the population of exoplanets, taking into\naccount survey completeness and, for the first time, observational\nuncertainties. We are able to make fewer assumptions about the distribution\nthan previous studies; we only require that the occurrence rate density be a\nsmooth function of period and radius (employing a Gaussian process). By\napplying our method to synthetic catalogs, we demonstrate that it produces more\naccurate estimates of the whole population than standard procedures based on\nweighting by inverse detection efficiency. We apply the method to an existing\ncatalog of small planet candidates around G dwarf stars (Petigura et al. 2013).\nWe confirm a previous result that the radius distribution changes slope near\nEarth's radius. We find that the rate density of Earth analogs is about 0.02\n(per star per natural logarithmic bin in period and radius) with large\nuncertainty. This number is much smaller than previous estimates made with the\nsame data but stronger assumptions. \n\n"}
{"id": "1406.4407", "contents": "Title: Photometric redshift analysis in the Dark Energy Survey Science\n  Verification data Abstract: We present results from a study of the photometric redshift performance of\nthe Dark Energy Survey (DES), using the early data from a Science Verification\n(SV) period of observations in late 2012 and early 2013 that provided\nscience-quality images for almost 200 sq.~deg.~at the nominal depth of the\nsurvey. We assess the photometric redshift performance using about 15000\ngalaxies with spectroscopic redshifts available from other surveys. These\ngalaxies are used, in different configurations, as a calibration sample, and\nphoto-$z$'s are obtained and studied using most of the existing photo-$z$\ncodes. A weighting method in a multi-dimensional color-magnitude space is\napplied to the spectroscopic sample in order to evaluate the photo-$z$\nperformance with sets that mimic the full DES photometric sample, which is on\naverage significantly deeper than the calibration sample due to the limited\ndepth of spectroscopic surveys. Empirical photo-$z$ methods using, for\ninstance, Artificial Neural Networks or Random Forests, yield the best\nperformance in the tests, achieving core photo-$z$ resolutions $\\sigma_{68}\n\\sim 0.08$. Moreover, the results from most of the codes, including template\nfitting methods, comfortably meet the DES requirements on photo-$z$\nperformance, therefore, providing an excellent precedent for future DES data\nsets. \n\n"}
{"id": "1406.6254", "contents": "Title: On the stability and causality of scalar-vector theories Abstract: Various extensions of standard inflationary models have been proposed\nrecently by adding vector fields. Because they are generally motivated by\nlarge-scale anomalies, and the possibility of statistical anisotropy of\nprimordial fluctuations, such models require to introduce non-standard\ncouplings between vector fields on the one hand, and either gravity or scalar\nfields on the other hand. In this article, we study models involving a vector\nfield coupled to a scalar field. We derive restrictive necessary conditions for\nthese models to be both stable (Hamiltonian bounded by below) and causal\n(hyperbolic equations of motion). \n\n"}
{"id": "1407.2527", "contents": "Title: A catalogue of photometric redshifts for the SDSS-DR9 galaxies Abstract: Accurate photometric redshifts for large samples of galaxies are among the\nmain products of modern multiband digital surveys. Over the last decade, the\nSloan Digital Sky Survey (SDSS) has become a sort of benchmark against which to\ntest the various methods. We present an application of a new method to the\nestimation of photometric redshifts for the galaxies in the SDSS Data Release 9\n(SDSS-DR9). Photometric redshifts for more than 143 million galaxies were\nproduced and made available at the URL:\nhttp://dame.dsf.unina.it/catalog/DR9PHOTOZ/. The MLPQNA (Multi Layer Perceptron\nwith Quasi Newton Algorithm) model provided within the framework of the\nDAMEWARE (DAta Mining and Exploration Web Application REsource) is an\ninterpolative method derived from machine learning models. The obtained\nredshifts have an overall uncertainty of sigma=0.023 with a very small average\nbias of about 3x10^-5, and a fraction of catastrophic outliers of about 5%.\nThis result is slightly better than what was already available in the\nliterature, particularly in terms of the smaller fraction of catastrophic\noutliers. \n\n"}
{"id": "1407.2973", "contents": "Title: SPT-3G: A Next-Generation Cosmic Microwave Background Polarization\n  Experiment on the South Pole Telescope Abstract: We describe the design of a new polarization sensitive receiver, SPT-3G, for\nthe 10-meter South Pole Telescope (SPT). The SPT-3G receiver will deliver a\nfactor of ~20 improvement in mapping speed over the current receiver, SPTpol.\nThe sensitivity of the SPT-3G receiver will enable the advance from statistical\ndetection of B-mode polarization anisotropy power to high signal-to-noise\nmeasurements of the individual modes, i.e., maps. This will lead to precise\n(~0.06 eV) constraints on the sum of neutrino masses with the potential to\ndirectly address the neutrino mass hierarchy. It will allow a separation of the\nlensing and inflationary B-mode power spectra, improving constraints on the\namplitude and shape of the primordial signal, either through SPT-3G data alone\nor in combination with BICEP-2/KECK, which is observing the same area of sky.\nThe measurement of small-scale temperature anisotropy will provide new\nconstraints on the epoch of reionization. Additional science from the SPT-3G\nsurvey will be significantly enhanced by the synergy with the ongoing optical\nDark Energy Survey (DES), including: a 1% constraint on the bias of optical\ntracers of large-scale structure, a measurement of the differential Doppler\nsignal from pairs of galaxy clusters that will test General Relativity on ~200\nMpc scales, and improved cosmological constraints from the abundance of\nclusters of galaxies. \n\n"}
{"id": "1407.3801", "contents": "Title: Combining Dark Energy Survey Science Verification Data with Near\n  Infrared Data from the ESO VISTA Hemisphere Survey Abstract: We present the combination of optical data from the Science Verification\nphase of the Dark Energy Survey (DES) with near infrared data from the ESO\nVISTA Hemisphere Survey (VHS). The deep optical detections from DES are used to\nextract fluxes and associated errors from the shallower VHS data. Joint 7-band\n($grizYJK$) photometric catalogues are produced in a single 3 sq-deg DECam\nfield centred at 02h26m$-$04d36m where the availability of ancillary\nmulti-wavelength photometry and spectroscopy allows us to test the data\nquality. Dual photometry increases the number of DES galaxies with measured VHS\nfluxes by a factor of $\\sim$4.5 relative to a simple catalogue level matching\nand results in a $\\sim$1.5 mag increase in the 80\\% completeness limit of the\nNIR data. Almost 70\\% of DES sources have useful NIR flux measurements in this\ninitial catalogue. Photometric redshifts are estimated for a subset of galaxies\nwith spectroscopic redshifts and initial results, although currently limited by\nsmall number statistics, indicate that the VHS data can help reduce the\nphotometric redshift scatter at both $z<0.5$ and $z>1$. We present example\nDES+VHS colour selection criteria for high redshift Luminous Red Galaxies\n(LRGs) at $z\\sim0.7$ as well as luminous quasars. Using spectroscopic\nobservations in this field we show that the additional VHS fluxes enable a\ncleaner selection of both populations with $<$10\\% contamination from galactic\nstars in the case of spectroscopically confirmed quasars and $<0.5\\%$\ncontamination from galactic stars in the case of spectroscopically confirmed\nLRGs. The combined DES+VHS dataset, which will eventually cover almost 5000\nsq-deg, will therefore enable a range of new science and be ideally suited for\ntarget selection for future wide-field spectroscopic surveys. \n\n"}
{"id": "1407.5125", "contents": "Title: Bulk NaI(Tl) scintillation low energy events selection with the ANAIS-0\n  module Abstract: Dark matter particles scattering off some target nuclei are expected to\ndeposit very small energies in form of nuclear recoils (below 100 keV). Because\nof the low scintillation efficiency for nuclear recoils vs. electron recoils,\nin most of the scintillating targets considered in the search for dark matter,\nthe region below 10 keVee concentrates most of the expected dark matter signal.\nFor this reason, very low energy threshold (at or below 2 keVee) and very low\nbackground are required. This is the case of the ANAIS (Annual modulation with\nNaI Scintillators) experiment. A good knowledge of the detector response\nfunction for real scintillation events, a good characterization of other\nanomalous or noise event populations contributing in that energy range, and the\ndevelopment of convenient filtering procedures for the latter are mandatory to\nachieve the required low background at such a low energy. In this work we will\npresent the specific protocols developed to select bulk scintillation events in\nNaI(Tl), and its application to data obtained with the ANAIS-0 prototype.\nSlight differences in time constants are expected in scintillation pulses\nproduced by nuclear or electron recoils in NaI(Tl), so in order to analyze the\neffect of these filtering procedures in the case of a recoil population\nattributable to dark matter, data from a neutron calibration have been used. \n\n"}
{"id": "1407.5496", "contents": "Title: Testing the mutual consistency of different supernovae surveys Abstract: It is now common practice to constrain cosmological parameters using\nsupernovae (SNe) catalogues constructed from several different surveys. Before\nperforming such a joint analysis, however, one should check that parameter\nconstraints derived from the individual SNe surveys that make up the catalogue\nare mutually consistent. We describe a statistically-robust mutual consistency\ntest, which we calibrate using simulations, and apply it to each pairwise\ncombination of the surveys making up, respectively, the UNION2 catalogue and\nthe very recent JLA compilation by Betoule et al. We find no inconsistencies in\nthe latter case, but conclusive evidence for inconsistency between some survey\npairs in the UNION2 catalogue. \n\n"}
{"id": "1407.6628", "contents": "Title: A FLUKA Study of $\\beta$-delayed Neutron Emission for the Ton-size\n  DarkSide Dark Matter Detector Abstract: In the published cosmogenic background study for a ton-sized DarkSide dark\nmatter search, only prompt neutron backgrounds coincident with cosmogenic muons\nor muon induced showers were considered, although observation of the initiating\nparticle(s) was not required. The present paper now reports an initial\ninvestigation of the magnitude of cosmogenic background from $\\beta$-delayed\nneutron emission produced by cosmogenic activity in DarkSide. The study finds a\nbackground rate for $\\beta$-delayed neutrons in the fiducial volume of the\ndetector on the order of < 0.1 event/year. However, detailed studies are\nrequired to obtain more precise estimates. The result should be compared to a\nradiogenic background event rate from the PMTs inside the DarkSide liquid\nscintillator veto of 0.2 events/year. \n\n"}
{"id": "1407.7744", "contents": "Title: Galileons and strong gravity Abstract: In the context of a cubic Galileon model in which the Vainshtein mechanism\nsuppresses the scalar field interactions with matter, we study low-density\nstars with slow rotation and static relativistic stars. We develop an expansion\nscheme to find approximated solutions inside the Vainshtein radius, and show\nthat deviations from General Relativity (GR), while considering rotation, are\nalso suppressed by the Vainshtein mechanism. In a quadratic coupling model, in\nwhich the scalarisation effect can significantly enhance deviations from GR in\nnormal scalar tensor gravity, the Galileon term successfully suppresses the\nlarge deviations away from GR. Moreover, using a realistic equation of state,\nwe construct solutions for a relativistic star, and show that deviations from\nGR are more suppressed for higher density objects. However, we found that the\nscalar field solution ceases to exist above a critical density, which roughly\ncorresponds to the maximum mass of a neutron star. This indicates that, for a\ncompact object described by a polytropic equation of state, the configuration\nthat would collapse into a black hole cannot support a non-trivial scalar\nfield. \n\n"}
{"id": "1408.4371", "contents": "Title: WIMP Dark Matter Direct-Detection Searches in Noble Gases Abstract: Cosmological observations and the dynamics of the Milky Way provide ample\nevidence for an invisible and dominant mass component. This so-called dark\nmatter could be made of new, colour and charge neutral particles, which were\nnon-relativistic when they decoupled from ordinary matter in the early\nuniverse. Such weakly interacting massive particles (WIMPs) are predicted to\nhave a non-zero coupling to baryons and could be detected via their collisions\nwith atomic nuclei in ultra-low background, deep underground detectors. Among\nthese, detectors based on liquefied noble gases have demonstrated tremendous\ndiscovery potential over the last decade. After briefly introducing the\nphenomenology of direct dark matter detection, I will review the main\nproperties of liquefied argon and xenon as WIMP targets and discuss sources of\nbackground. I will then describe existing and planned argon and xenon detectors\nthat employ the so-called single- and dual-phase detection techniques,\naddressing their complementarity and science reach. \n\n"}
{"id": "1408.6903", "contents": "Title: Hubble Frontier Fields First Complete Cluster Data: Faint Galaxies at\n  $z\\sim 5-10$ for UV Luminosity Functions and Cosmic Reionization Abstract: We present the comprehensive analyses of faint dropout galaxies up to\n$z\\sim10$ with the first full-depth data set of Abell 2744 lensing cluster and\nparallel fields observed by the Hubble Frontier Fields (HFF) program. We\nidentify $54$ dropouts at $z\\sim5-10$ in the HFF fields, and enlarge the size\nof $z\\sim9$ galaxy sample obtained to date. Although the number of highly\nmagnified ($\\mu\\sim10$) galaxies is small due to the tiny survey volume of\nstrong lensing, our study reaches the galaxies' intrinsic luminosities\ncomparable to the deepest-field HUDF studies. We derive UV luminosity functions\nwith these faint dropouts, carefully evaluating the combination of\nobservational incompleteness and lensing effects in the image plane by\nintensive simulations including magnification, distortion, and multiplication\nof images, with the evaluations of mass model dependences. Our results confirm\nthat the faint-end slope, $\\alpha$, is as steep as $-2$ at $z\\sim6-8$, and\nstrengthen the evidence of the rapid decrease of UV luminosity densities,\n$\\rho_\\mathrm{UV}$, at $z>8$ from the large $z\\sim9$ sample. We examine whether\nthe rapid $\\rho_\\mathrm{UV}$ decrease trend can reconcile with the large\nThomson scattering optical depth, $\\tau_\\mathrm{e}$, measured by CMB\nexperiments allowing a large space of free parameters such as average ionizing\nphoton escape fraction and stellar-population dependent conversion factor. No\nparameter set can reproduce both the rapid $\\rho_\\mathrm{UV}$ decrease and the\nlarge $\\tau_\\mathrm{e}$. It is possible that the $\\rho_\\mathrm{UV}$ decrease\nmoderates at $z\\gtrsim11$, that the free parameters significantly evolve\ntowards high-$z$, or that there exist additional sources of reionization such\nas X-ray binaries and faint AGNs. \n\n"}
{"id": "1409.0056", "contents": "Title: ANTARES: A Prototype Transient Broker System Abstract: The Arizona-NOAO Temporal Analysis and Response to Events System (ANTARES) is\na joint project of the National Optical Astronomy Observatory and the\nDepartment of Computer Science at the University of Arizona. The goal is to\nbuild the software infrastructure necessary to process and filter alerts\nproduced by time-domain surveys, with the ultimate source of such alerts being\nthe Large Synoptic Survey Telescope (LSST). The ANTARES broker will add value\nto alerts by annotating them with information from external sources such as\nprevious surveys from across the electromagnetic spectrum. In addition, the\ntemporal history of annotated alerts will provide further annotation for\nanalysis. These alerts will go through a cascade of filters to select\ninteresting candidates. For the prototype, `interesting' is defined as the\nrarest or most unusual alert, but future systems will accommodate multiple\nfiltering goals. The system is designed to be flexible, allowing users to\naccess the stream at multiple points throughout the process, and to insert\ncustom filters where necessary. We describe the basic architecture of ANTARES\nand the principles that will guide development and implementation. \n\n"}
{"id": "1409.0690", "contents": "Title: The important role of evolution in the Planck $Y_{SZ}$-mass calibration Abstract: In light of the tension between cosmological parameters from Planck cosmic\nmicrowave background and galaxy clusters, we revised the Planck analysis of the\n$Y_{SZ}$-mass calibration to allow evolution to be determined by the data\ninstead of being imposed as an external constraint. Our analysis uses the very\nsame data and Malmquist bias corrections as used by the Planck team in order to\nemphasize that differences in the results come from differences in the\nassumptions. The evolution derived from 71 calibrating clusters, with\n$0.05<z<0.45$, is proportional to $E^{2.5\\pm0.4}(z)$, so inconsistent with the\nself-similar evolution ($E^{2/3}$) assumed by previous analyses. When allowing\nfor evolution, the slope of $Y_{SZ}$-mass relation turns out to be\n$1.51\\pm0.07$, which is shallower by $4.8\\sigma$ than the value derived when\nassuming self-similar evolution, introducing a mass-dependent bias. The\nnon-self-similar evolution of $Y_{SZ}$ has to be accounted for in analyses\naimed to establish the biases of Planck masses. \n\n"}
{"id": "1409.1984", "contents": "Title: Effective field theory approach to modified gravity including Horndeski\n  theory and Ho\\v{r}ava-Lifshitz gravity Abstract: We review the effective field theory of modified gravity in which the\nLagrangian involves three dimensional geometric quantities appearing in the 3+1\ndecomposition of space-time. On the flat isotropic cosmological background we\nexpand a general action up to second order in the perturbations of geometric\nscalars, by taking into account spatial derivatives higher than two. Our\nanalysis covers a wide range of gravitational theories-- including Horndeski\ntheory/its recent generalizations and the projectable/non-projectable versions\nof Ho\\v{r}ava-Lifshitz gravity. We derive the equations of motion for linear\ncosmological perturbations and apply them to the calculations of inflationary\npower spectra as well as the dark energy dynamics in Galileon theories. We also\nshow that our general results conveniently recover stability conditions of\nHo\\v{r}ava-Lifshitz gravity already derived in the literature. \n\n"}
{"id": "1409.3284", "contents": "Title: Time evolution of parametric instability in large-scale\n  gravitational-wave interferometers Abstract: We present a study of three-mode parametric instability in large-scale\ngravitational-wave detectors. Previous work used a linearised model to study\nthe onset of instability. This paper presents a non-linear study of this\nphenomenon, which shows that the initial stage of exponential rise of the\namplitudes of a higher order optical mode and the mechanical internal mode of\nthe mirror is followed by a saturation phase, in which all three participating\nmodes reach a new equilibrium state with constant oscillation amplitudes.\nResults suggest that stable operation of interferometers may be possible in the\npresence of such instabilities, thereby simplifying the task of suppression. \n\n"}
{"id": "1409.3516", "contents": "Title: No role for neutrons, muons and solar neutrinos in the DAMA annual\n  modulation results Abstract: This paper summarizes in a simple and intuitive way why the neutrons, the\nmuons and the solar neutrinos cannot give any significant contribution to the\nDAMA annual modulation results. A number of these elements have already been\npresented in individual papers; they are recalled here. Afterwards, few simple\nconsiderations are summarized which already demonstrate the incorrectness of\nthe claim reported in PRL 113 (2014) 081302. \n\n"}
{"id": "1409.3852", "contents": "Title: Detecting solar chameleons through radiation pressure Abstract: Light scalar fields can drive the accelerated expansion of the universe.\nHence, they are obvious dark energy candidates. To make such models compatible\nwith tests of General Relativity in the solar system and \"fifth force\" searches\non Earth, one needs to screen them. One possibility is the so-called\n\"chameleon\" mechanism, which renders an effective mass depending on the local\nmatter density. If chameleon particles exist, they can be produced in the sun\nand detected on Earth exploiting the equivalent of a radiation pressure. Since\ntheir effective mass scales with the local matter density, chameleons can be\nreflected by a dense medium if their effective mass becomes greater than their\ntotal energy. Thus, under appropriate conditions, a flux of solar chameleons\nmay be sensed by detecting the total instantaneous momentum transferred to a\nsuitable opto-mechanical force/pressure sensor. We calculate the solar\nchameleon spectrum and the reach in the chameleon parameter space of an\nexperiment using the preliminary results from a force/pressure sensor,\ncurrently under development at INFN Trieste, to be mounted in the focal plane\nof one of the X-Ray telescopes of the CAST experiment at CERN. We show, that\nsuch an experiment signifies a pioneering effort probing uncharted chameleon\nparameter space. \n\n"}
{"id": "1409.4151", "contents": "Title: Comparison of algorithms for determination of rotation measure and\n  Faraday structure I. 1100 - 1400 MHz Abstract: (abridged) We run a Faraday structure determination data challenge to\nbenchmark the currently available algorithms including Faraday synthesis\n(previously called RM synthesis in the literature), wavelet, compressive\nsampling and $QU$-fitting. The frequency set is similar to POSSUM/GALFACTS with\na 300 MHz bandwidth from 1.1 to 1.4 GHz. We define three figures of merit\nmotivated by the underlying science: a) an average RM weighted by polarized\nintensity, RMwtd, b) the separation $\\Delta\\phi$ of two Faraday components and\nc) the reduced chi-squared. Based on the current test data of signal to noise\nratio of about 32, we find that: (1) When only one Faraday thin component is\npresent, most methods perform as expected, with occasional failures where two\ncomponents are incorrectly found; (2) For two Faraday thin components,\nQU-fitting routines perform the best, with errors close to the theoretical ones\nfor RMwtd, but with significantly higher errors for $\\Delta\\phi$. All other\nmethods including standard Faraday synthesis frequently identify only one\ncomponent when $\\Delta\\phi$ is below or near the width of the Faraday point\nspread function; (3) No methods, as currently implemented, work well for\nFaraday thick components due to the narrow bandwidth; (4) There exist\ncombinations of two Faraday components which produce a large range of\nacceptable fits and hence large uncertainties in the derived single RMs; in\nthese cases, different RMs lead to the same Q, U behavior, so no method can\nrecover a unique input model. \n\n"}
{"id": "1409.4374", "contents": "Title: FORS2/VLT survey of Milky Way globular clusters I. Description of the\n  method for derivation of metal abundances in the optical and application to\n  NGC 6528, NGC 6553, M 71, NGC 6558, NGC 6426 and Terzan 8 Abstract: (abridged) We have observed almost 1/3 of the globular clusters in the Milky\nWay, targeting distant and/or highly reddened objects, besides a few reference\nclusters. A large sample of red giant stars was observed with FORS2@VLT/ESO at\nR ~ 2,000. The method for derivation of stellar parameters is presented with\napplication to six reference clusters. We aim at deriving the stellar\nparameters effective temperature, gravity, metallicity and alpha-element\nenhancement, as well as radial velocity, for membership confirmation of\nindividual stars in each cluster. We analyse the spectra collected for the\nreference globular clusters NGC 6528, NGC 6553, M 71, NGC 6558, NGC 6426 and\nTerzan 8. They cover the full range of globular cluster metallicities, and are\nlocated in the bulge, disc and halo. Full spectrum fitting techniques are\napplied, by comparing each target spectrum with a stellar library in the\noptical region at 4560-5860 A. We employed the library of observed spectra\nMILES, and the synthetic library by Coelho et al. (2005). Validation of the\nmethod is achieved through recovery of the known atmospheric parameters for 49\nwell-studied stars that cover a wide range in the parameter space. We adopted\nas final stellar parameters (effective temperatures, gravities, metallicities)\nthe average of results using MILES and Coelho et al. libraries. We identified 4\nmember stars in NGC 6528, 13 in NGC 6553, 10 in M 71, 5 in NGC 6558, 5 in NGC\n6426 and 12 in Terzan 8. Radial velocities, Teff, log(g), [Fe/H] and\nalpha-element enhancements were derived. We derived abundances for NGC 6426\nfrom spectroscopy for the first time. The method proved to be reliable for red\ngiant stars observed with resolution R ~ 2,000, yielding results compatible\nwith high-resolution spectroscopy. The derived alpha-element abundances show\n[A/Fe] vs. [Fe/H] consistent with that of field stars at the same\nmetallicities. \n\n"}
{"id": "1409.4400", "contents": "Title: Dynamics of Robertson-Walker spacetimes with diffusion Abstract: We study the dynamics of spatially homogeneous and isotropic spacetimes\ncontaining a fluid undergoing microscopic velocity diffusion in a cosmological\nscalar field. After deriving a few exact solutions of the equations, we\ncontinue by analyzing the qualitative behavior of general solutions. To this\npurpose we recast the equations in the form of a two dimensional dynamical\nsystem and perform a global analysis of the flow. Among the admissible\nbehaviors, we find solutions that are asymptotically de-Sitter both in the past\nand future time direction and which undergo accelerated expansion at all times. \n\n"}
{"id": "1409.4690", "contents": "Title: Imaging an Event Horizon: Mitigation of Scattering Toward Sagittarius A* Abstract: The image of the emission surrounding the black hole in the center of the\nMilky Way is predicted to exhibit the imprint of general relativistic (GR)\neffects, including the existence of a shadow feature and a photon ring of\ndiameter ~50 microarcseconds. Structure on these scales can be resolved by\nmillimeter-wavelength very long baseline interferometry (VLBI). However,\nstrong-field GR features of interest will be blurred at lambda >= 1.3 mm due to\nscattering by interstellar electrons. The scattering properties are well\nunderstood over most of the relevant range of baseline lengths, suggesting that\nthe scattering may be (mostly) invertible. We simulate observations of a model\nimage of Sgr A* and demonstrate that the effects of scattering can indeed be\nmitigated by correcting the visibilities before reconstructing the image. This\ntechnique is also applicable to Sgr A* at longer wavelengths. \n\n"}
{"id": "1409.6332", "contents": "Title: Should we believe the results of UV-mm galaxy SED modelling? Abstract: Galaxy spectral energy distribution (SED) modelling is a powerful tool, but\nconstraining how well it is able to infer the true values for galaxy properties\n(e.g. the star formation rate, SFR) is difficult because independent\ndeterminations are often not available. However, galaxy simulations can provide\na means of testing SED modelling techniques. Here, we present a numerical\nexperiment in which we apply the SED modelling code MAGPHYS to ultraviolet\n(UV)--millimetre (mm) synthetic photometry generated from hydrodynamical\nsimulations of an isolated disc galaxy and a major galaxy merger by performing\nthree-dimensional dust radiative transfer. We compare the properties inferred\nfrom the SED modelling with the true values and find that MAGPHYS recovers most\nphysical parameters of the simulated galaxies well. In particular, it recovers\nconsistent parameters irrespective of the viewing angle, with smoothly varying\nresults for neighbouring time steps of the simulation, even though each viewing\nangle and time step is modelled independently. The notable exception to this\nrule occurs when we use an SMC-type intrinsic dust extinction curve in the\nradiative transfer calculations. In this case, the two-component dust model\nused by MAGPHYS is unable to effectively correct for the attenuation of the\nsimulated galaxies, which leads to potentially significant errors (although we\nobtain only marginally acceptable fits in this case). Overall, our results give\nconfidence in the ability of SED modelling to infer physical properties of\ngalaxies, albeit with some caveats. \n\n"}
{"id": "1409.6724", "contents": "Title: CO/H2, C/CO, OH/CO, and OH/O2 in Dense Interstellar Gas: From High\n  Ionization to Low Metallicity Abstract: We present numerical computations and analytic scaling relations for\ninterstellar ion-molecule gas phase chemistry down to very low metallicities ($\n10^{-3} \\times$ solar), and/or up to high driving ionization rates. Relevant\nenvironments include the cool interstellar medium (ISM) in low-metallicity\ndwarf galaxies, early enriched clouds at the reionization and Pop-II star\nformation era, and in dense cold gas exposed to intense X-ray or cosmic-ray\nsources. We focus on the behavior for H$_2$, CO, CH, OH, H$_2$O and O$_2$, at\ngas temperatures $\\sim 100$ K, characteristic of a cooled ISM at low\nmetallicities. We consider shielded or partially shielded one-zone gas parcels,\nand solve the gas phase chemical rate equations for the steady-state\n\"metal-molecule\" abundances for a wide range of ionization parameters,\n$\\zeta/n$, and metallicties, $Z'$. We find that the OH abundances are always\nmaximal near the H-to-H$_2$ conversion points, and that large OH abundances\npersist at very low metallicities even when the hydrogen is predominantly\natomic. We study the OH/O$_2$, C/CO and OH/CO abundance ratios, from large to\nsmall, as functions of $\\zeta/n$ and $Z'$. Much of the cold dense ISM for the\nPop-II generation may have been OH-dominated and atomic rather than\nCO-dominated and molecular. \n\n"}
{"id": "1409.7395", "contents": "Title: GIZMO: A New Class of Accurate, Mesh-Free Hydrodynamic Simulation\n  Methods Abstract: We present two new Lagrangian methods for hydrodynamics, in a systematic\ncomparison with moving-mesh, SPH, and stationary (non-moving) grid methods. The\nnew methods are designed to simultaneously capture advantages of both\nsmoothed-particle hydrodynamics (SPH) and grid-based/adaptive mesh refinement\n(AMR) schemes. They are based on a kernel discretization of the volume coupled\nto a high-order matrix gradient estimator and a Riemann solver acting over the\nvolume 'overlap.' We implement and test a parallel, second-order version of the\nmethod with self-gravity & cosmological integration, in the code GIZMO: this\nmaintains exact mass, energy and momentum conservation; exhibits superior\nangular momentum conservation compared to all other methods we study; does not\nrequire 'artificial diffusion' terms; and allows the fluid elements to move\nwith the flow so resolution is automatically adaptive. We consider a large\nsuite of test problems, and find that on all problems the new methods appear\ncompetitive with moving-mesh schemes, with some advantages (particularly in\nangular momentum conservation), at the cost of enhanced noise. The new methods\nhave many advantages vs. SPH: proper convergence, good capturing of\nfluid-mixing instabilities, dramatically reduced 'particle noise' & numerical\nviscosity, more accurate sub-sonic flow evolution, & sharp shock-capturing.\nAdvantages vs. non-moving meshes include: automatic adaptivity, dramatically\nreduced advection errors & numerical overmixing, velocity-independent errors,\naccurate coupling to gravity, good angular momentum conservation and\nelimination of 'grid alignment' effects. We can, for example, follow hundreds\nof orbits of gaseous disks, while AMR and SPH methods break down in a few\norbits. However, fixed meshes minimize 'grid noise.' These differences are\nimportant for a range of astrophysical problems. \n\n"}
{"id": "1410.2805", "contents": "Title: HACC: Simulating Sky Surveys on State-of-the-Art Supercomputing\n  Architectures Abstract: Current and future surveys of large-scale cosmic structure are associated\nwith a massive and complex datastream to study, characterize, and ultimately\nunderstand the physics behind the two major components of the 'Dark Universe',\ndark energy and dark matter. In addition, the surveys also probe primordial\nperturbations and carry out fundamental measurements, such as determining the\nsum of neutrino masses. Large-scale simulations of structure formation in the\nUniverse play a critical role in the interpretation of the data and extraction\nof the physics of interest. Just as survey instruments continue to grow in size\nand complexity, so do the supercomputers that enable these simulations. Here we\nreport on HACC (Hardware/Hybrid Accelerated Cosmology Code), a recently\ndeveloped and evolving cosmology N-body code framework, designed to run\nefficiently on diverse computing architectures and to scale to millions of\ncores and beyond. HACC can run on all current supercomputer architectures and\nsupports a variety of programming models and algorithms. It has been\ndemonstrated at scale on Cell- and GPU-accelerated systems, standard multi-core\nnode clusters, and Blue Gene systems. HACC's design allows for ease of\nportability, and at the same time, high levels of sustained performance on the\nfastest supercomputers available. We present a description of the design\nphilosophy of HACC, the underlying algorithms and code structure, and outline\nimplementation details for several specific architectures. We show selected\naccuracy and performance results from some of the largest high resolution\ncosmological simulations so far performed, including benchmarks evolving more\nthan 3.6 trillion particles. \n\n"}
{"id": "1410.5125", "contents": "Title: Gamma/hadron segregation for a ground based imaging atmospheric\n  Cherenkov telescope using machine learning methods: Random Forest leads Abstract: A detailed case study of $\\gamma$-hadron segregation for a ground based\natmospheric Cherenkov telescope is presented. We have evaluated and compared\nvarious supervised machine learning methods such as the Random Forest method,\nArtificial Neural Network, Linear Discriminant method, Naive Bayes\nClassifiers,Support Vector Machines as well as the conventional dynamic\nsupercut method by simulating triggering events with the Monte Carlo method and\napplied the results to a Cherenkov telescope. It is demonstrated that the\nRandom Forest method is the most sensitive machine learning method for\n$\\gamma$-hadron segregation. \n\n"}
{"id": "1410.6065", "contents": "Title: Holographic bounds and finite inflation Abstract: We compare two holographic arguments that impose especially strong bounds on\nthe amount of inflation. One comes from the de Sitter Equilibrium cosmology and\nthe other from the work of Banks and Fischler. We find that simple versions of\nthese two approaches yield the same bound on the number of e-foldings. A\ncareful examination reveals that while these pictures are similar in spirit,\nthey are not necessarily identical prescriptions. We apply the two pictures to\nspecific cosmologies which expose potentially important differences and which\nalso demonstrate ways these seemingly simple proposals can be tricky to\nimplement in practice. \n\n"}
{"id": "1410.6441", "contents": "Title: Searching for A Generic Gravitational Wave Background via Bayesian\n  Nonparametric Analysis with Pulsar Timing Arrays Abstract: Gravitational wave background results from the superposition of gravitational\nwaves generated from all sources across the Universe. Previous efforts on\ndetecting such a background with pulsar timing arrays assume it is an isotropic\nGaussian background with a power law spectrum. However, when the number of\nsources is limited, the background might be non-Gaussian or the spectrum might\nnot be a power law. Correspondingly previous analysis may not work effectively.\nHere we use a method --- Bayesian Nonparametric Analysis --- to try to detect a\ngeneric gravitational wave background, which directly sets constraints on the\nfeasible shapes of the pulsar timing signals induced by a gravitational wave\nbackground and allows more flexible forms of the background. Our Bayesian\nnonparametric analysis will infer if a gravitational wave background is present\nin the data, and also estimate the parameters that characterize the background.\nThis method will be much more effective than the conventional one assuming the\nbackground spectrum follows a power law in general cases. While the context of\nour discussion focuses on pulsar timing arrays, the analysis itself is directly\napplicable to detect and characterize any signals that arise from the\nsuperposition of a large number of astrophysical events. \n\n"}
{"id": "1410.7396", "contents": "Title: Linearized iterative least-squares (LIL): A parameter fitting algorithm\n  for component separation in multifrequency CMB experiments such as Planck Abstract: We present an efficient algorithm for the least squares parameter fitting\noptimized for component separation in multi-frequency CMB experiments. We\nsidestep some of the problems associated with non-linear optimization by taking\nadvantage of the quasi-linear nature of the foreground model. We demonstrate\nour algorithm, linearized iterative least-squares (LIL), on the publicly\navailable Planck sky model FFP6 simulations and compare our result with the\nother algorithms. We work at full Planck resolution and show that degrading the\nresolution of all channels to that of the lowest frequency channel is not\nnecessary. Finally we present results for the publicly available Planck data.\nOur algorithm is extremely fast, fitting 6 parameters to 7 lowest Planck\nchannels at full resolution (50 million pixels) in less than 160 CPU-minutes\n(or few minutes running in parallel on few tens of cores). LIL is therefore\neasily scalable to future experiments which may have even higher resolution and\nmore frequency channels. We also naturally propagate the uncertainties in\ndifferent parameters due to noise in the maps as well as degeneracies between\nthe parameters to the final errors on the parameters using Fisher matrix. One\nindirect application of LIL could be a front-end for Bayesian parameter fitting\nto find the maximum of the likelihood to be used as the starting point for the\nGibbs sampling. We show for rare components, such as the carbon-monoxide\nemission, present in small fraction of sky, the optimal approach should combine\nparameter fitting with model selection. LIL may also be useful in other\nastrophysical applications which satisfy the quasi-linearity criteria. \n\n"}
{"id": "1411.0315", "contents": "Title: Recovery of the Candidate Protoplanet HD 100546 b with Gemini/NICI and\n  Detection of Additional (Planet-Induced?) Disk Structure at Small Separations Abstract: We report the first independent, second-epoch (re-)detection of a\ndirectly-imaged protoplanet candidate. Using $L^\\prime$ high-contrast imaging\nof HD 100546 taken with the Near-Infrared Coronagraph and Imager (NICI) on\nGemini South, we recover `HD 100546 b' with a position and brightness\nconsistent with the original VLT/NaCo detection from Quanz et al, although data\nobtained after 2013 will be required to decisively demonstrate common proper\nmotion. HD 100546 b may be spatially resolved, up to $\\approx$ 12-13 AU in\ndiameter, and is embedded in a finger of thermal IR bright, polarized emission\nextending inwards to at least 0.3\". Standard hot-start models imply a mass of\n$\\approx$ 15 $M_{J}$. But if HD 100546 b is newly formed or made visible by a\ncircumplanetary disk, both of which are plausible, its mass is significantly\nlower (e.g. 1--7 $M_{J}$). Additionally, we discover a thermal IR-bright disk\nfeature, possibly a spiral density wave, at roughly the same angular separation\nas HD 100546 b but 90 degrees away. Our interpretation of this feature as a\nspiral arm is not decisive, but modeling analyses using spiral density wave\ntheory implies a wave launching point exterior to $\\approx$ 0.45\" embedded\nwithin the visible disk structure: plausibly evidence for a second, hitherto\nunseen wide-separation planet. With one confirmed protoplanet candidate and\nevidence for 1--2 others, HD 100546 is an important evolutionary precursor to\nintermediate-mass stars with multiple super-jovian planets at moderate/wide\nseparations like HR 8799. \n\n"}
{"id": "1411.1150", "contents": "Title: Direction Dependent Effects In Wide-Field Wideband Full Stokes Radio\n  Imaging Abstract: Synthesis imaging in radio astronomy is affected by instrumental and\natmospheric effects which introduce direction-dependent (DD) gains.The antenna\npower pattern varies both as a function of time and frequency. The broad band\ntime varying nature of the antenna power pattern when not corrected leads to\ngross errors in full Stokes imaging and flux estimation. In this poster we\nexplore the errors that arise in image deconvolution while not accounting for\nthe time and frequency dependence of the antenna power pattern. Simulations\nwere conducted with the wide-band full Stokes power pattern of the Karl G.\nJansky Very Large Array (VLA) antennas to demonstrate the level of errors\narising from direction-dependent gains and their non-neglegible impact on\nupcoming sky surveys such as the VLASS. DD corrections through hybrid\nprojection algorithms are computationally expensive to perform. A highly\nparallel implementation through high performance computing architectures is the\nonly feasible way of applying these corrections to the large data sizes of\nthese upcoming surveys. \n\n"}
{"id": "1411.1261", "contents": "Title: An embedded active nucleus in the OH megamaser galaxy IRAS16399-0937 Abstract: We present a multiwavelength study of the OH Megamaser galaxy (OHMG)\nIRAS16399-0937, based on new HST/ACS F814W and H$\\alpha$+[NII] images and\narchive data from HST, 2MASS, Spitzer, Herschel and the VLA. This system has a\ndouble nucleus, whose northern (IRAS16399N) and southern (IRAS16399S)\ncomponents have a projected separation of $\\sim$ 6'' (3.4 kpc) and have\npreviously been identified based on optical spectra as a Low Ionization Nuclear\nEmission Line Region (LINER) and starburst nucleus, respectively. The nuclei\nare embedded in a tidally distorted common envelope, in which star formation is\nmostly heavily obscured. The infrared spectrum is dominated by strong\npolycyclic aromatic hydrocarbon (PAH), but deep silicate and molecular\nabsorption features are also present, and are strongest in the IRAS16399N\nnucleus. The 0.435 - 500$\\mu$m SED was fitted with a model including stellar,\nISM and AGN torus components using our new MCMC code, clumpyDREAM. The results\nindicate that the IRAS16399N contains an AGN (L$_{bol} \\sim 10^{44}$ ergs/s)\ndeeply embedded in a quasi-spherical distribution of optically-thick clumps\nwith a covering fraction $\\approx1$. We suggest that these clumps are the\nsource of the OHM emission in IRAS16399-0937. The high torus covering fraction\nprecludes AGN-photoionization as the origin of the LINER spectrum, however, the\nspectrum is consistent with shocks (v $\\sim100-200$ km s$^{-1}$). We infer that\nthe $\\sim10^8$ M$_{\\odot}$ black-hole in IRAS16399N is accreting at a small\nfraction ($\\sim1$%) of its Eddington rate. The low accretion-rate and modest\nnuclear SFRs suggest that while the gas-rich major merger forming the\nIRAS16399-0937 system has triggered widespread star formation, the massive gas\ninflows expected from merger simulations have not yet fully developed. \n\n"}
{"id": "1411.3628", "contents": "Title: An improved source-subtracted and destriped 408 MHz all-sky map Abstract: The all-sky 408 MHz map of Haslam et al. is one the most important\ntotal-power radio surveys. It has been widely used to study diffuse synchrotron\nradiation from our Galaxy and as a template to remove foregrounds in cosmic\nmicrowave background data. However, there are a number of issues associated\nwith it that must be dealt with, including large-scale striations and\ncontamination from extragalactic radio sources. We have re-evaluated and\nre-processed the rawest data available to produce a new and improved 408 MHz\nall-sky map. We first quantify the positional accuracy ($\\approx 7$ arcmin) and\neffective beam ($56.0\\pm1.0$ arcmin) of the four individual surveys from which\nit was assembled. Large-scale striations associated with $1/f$ noise in the\nscan direction are reduced to a level $\\ll 1$ K using a Fourier-based filtering\ntechnique. The most important improvement results from the removal of\nextragalactic sources. We have used an iterative combination of two techniques\n-- two-dimensional Gaussian fitting and minimum curvature spline surface\ninpainting -- to remove the brightest sources ($\\gtrsim 2$ Jy), which provides\na significant improvement over previous versions of the map. We quantify the\nimpact with power spectra and a template fitting analysis of foregrounds to the\nWMAP data. The new map is publicly available and is recommended as the template\nof choice for large-scale diffuse Galactic synchrotron emission. We also\nprovide a higher resolution map with small-scale fluctuations added, assuming a\npower-law angular power spectrum down to the pixel scale (1.7 arcmin). This\nshould prove useful in simulations used for studying the feasibility of\ndetecting HI fluctuations from the Epoch of Reionization. \n\n"}
{"id": "1411.3741", "contents": "Title: Star formation in Chamaeleon I and III: a molecular line study of the\n  starless core population Abstract: The Chamaeleon clouds are excellent targets for low-mass star formation\nstudies. Cha I and II are actively forming stars while Cha III shows no sign of\nongoing star formation. We aim to determine the driving factors that have led\nto the very different levels of star formation activity in Cha I and III and\nexamine the dynamical state and possible evolution of the starless cores within\nthem. Observations were performed in various molecular transitions with APEX\nand Mopra. Five cores are gravitationally bound in Cha I and one in Cha III.\nThe infall signature is seen toward 8-17 cores in Cha I and 2-5 cores in Cha\nIII, which leads to a range of 13-28% of the cores in Cha I and 10-25% of the\ncores in Cha III that are contracting and may become prestellar. Future\ndynamical interactions between the cores will not be dynamically significant in\neither Cha I or III, but the subregion Cha I North may experience collisions\nbetween cores within ~0.7 Myr. Turbulence dissipation in the cores of both\nclouds is seen in the high-density tracers N2H+ 1-0 and HC3N 10-9. Evidence of\ndepletion in the Cha I core interiors is seen in the abundance distributions of\nC17O, C18O, and C34S. Both contraction and static chemical models indicate that\nthe HC3N to N2H+ abundance ratio is a good evolutionary indicator in the\nprestellar phase for both gravitationally bound and unbound cores. In the\nframework of these models, we find that the cores in Cha III and the southern\npart of Cha I are in a similar evolutionary stage and are less chemically\nevolved than the central region of Cha I. The measured HC3N/N2H+ abundance\nratio and the evidence for contraction motions seen towards the Cha III\nstarless cores suggest that Cha III is younger than Cha I Centre and that some\nof its cores may form stars in the future. The cores in Cha I South may on the\nother hand be transient structures. (abridged) \n\n"}
{"id": "1411.4768", "contents": "Title: Natural inflation with and without modulations in type IIB string theory Abstract: We propose a mechanism for the natural inflation with and without modulation\nin the framework of type IIB string theory on toroidal orientifold or orbifold.\nWe explicitly construct the stabilization potential of complex structure,\ndilaton and K\\\"ahler moduli, where one of the imaginary component of complex\nstructure moduli becomes light which is identified as the inflaton. The\ninflaton potential is generated by the gaugino-condensation term which receives\nthe one-loop threshold corrections determined by the field value of complex\nstructure moduli and the axion decay constant of inflaton is enhanced by the\ninverse of one-loop factor. We also find the threshold corrections can also\ninduce the modulations to the original scalar potential for the natural\ninflation. Depending on these modulations, we can predict several sizes of\ntensor-to-scalar ratio as well as the other cosmological observables reported\nby WMAP, Planck and/or BICEP2 collaborations. \n\n"}
{"id": "1411.4859", "contents": "Title: Inversion of stellar fundamental parameters from Espadons and Narval\n  high-resolution spectra Abstract: The general context of this study is the inversion of stellar fundamental\nparameters from high-resolution Echelle spectra. We aim indeed at developing a\nfast and reliable tool for the post-processing of spectra produced by Espadons\nand Narval spectropolarimeters. Our inversion tool relies on principal\ncomponent analysis. It allows reduction of dimensionality and the definition of\na specific metric for the search of nearest neighbours between an observed\nspectrum and a set of observed spectra taken from the Elodie stellar library.\nEffective temperature, surface gravity, total metallicity and projected\nrotational velocity are derived. Various tests presented in this study, and\ndone from the sole information coming from a spectral band centered around the\nMg I b-triplet and with spectra from FGK stars are very promising. \n\n"}
{"id": "1412.2751", "contents": "Title: Apodized Pupil Lyot Coronagraphs for Arbitrary Apertures. IV. Reduced\n  Inner Working Angle and Increased Robustness to Low-Order Aberrations Abstract: The Apodized Pupil Lyot Coronagraph (APLC) is a diffraction suppression\nsystem installed in the recently deployed instruments Palomar/P1640,\nGemini/GPI, and VLT/SPHERE to allow direct imaging and spectroscopy of\ncircumstellar environments. Using a prolate apodization, the current\nimplementations offer raw contrasts down to $10^{-7}$ at 0.2 arcsec from a star\nover a wide bandpass (20\\%), in the presence of central obstruction and struts,\nenabling the study of young or massive gaseous planets. Observations of older\nor lighter companions at smaller separations would require improvements in\nterms of inner working angle (IWA) and contrast, but the methods originally\nused for these designs were not able to fully explore the parameter space. We\nhere propose a novel approach to improve the APLC performance. Our method\nrelies on the linear properties of the coronagraphic electric field with the\napodization at any wavelength to develop numerical solutions producing\ncoronagraphic star images with high-contrast region in broadband light. We\nexplore the parameter space by considering different aperture geometries,\ncontrast levels, dark-zone sizes, bandpasses, and focal plane mask sizes. We\npresent an application of these solutions to the case of Gemini/GPI with a\ndesign delivering a $10^{-8}$ raw contrast at 0.19 arcsec and offering a\nsignificantly reduced sensitivity to low-order aberrations compared to the\ncurrent implementation. Optimal solutions have also been found to reach\n$10^{-10}$ contrast in broadband light regardless of the telescope aperture\nshape (in particular the central obstruction size), with effective IWA in the\n$2-3.5\\lambda/D$ range, therefore making the APLC a suitable option for the\nfuture exoplanet direct imagers on the ground or in space. \n\n"}
{"id": "1412.3091", "contents": "Title: The (black hole)-bulge mass scaling relation at low masses Abstract: Several recent papers have reported on the occurrence of active galactic\nnuclei (AGN) containing under-massive black holes relative to a linear scaling\nrelation between black hole mass (M_bh) and host spheroid stellar mass\n(M_sph,*). Dramatic revisions to the M_bh-M_sph,* and M_bh-L_sph relations,\nbased on samples containing predominantly inactive galaxies, have however\nrecently identified a new steeper relation at M_bh < (2-10)x10^8 M_Sun, roughly\ncorresponding to M_sph,* < (0.3-1)x10^{11} M_Sun. We show that this steeper,\nquadratic-like M_bh-M_sph,* relation defined by the Sersic galaxies, i.e.\ngalaxies without partially depleted cores, roughly tracks the apparent offset\nof the AGN having 10^5 < M_bh/M_Sun < 0.5x10^8. That is, these AGN are not\nrandomly offset with low black hole masses, but also follow a steeper\n(non-linear) relation. As noted by Busch et al., confirmation or rejection of a\npossible AGN offset from the steeper M_bh-M_sph,* relation defined by the\nSersic galaxies will benefit from improved stellar mass-to-light ratios for the\nspheroids hosting these AGN. Several implications for formation theories are\nnoted. Furthermore, reasons for possible under- and over-massive black holes,\nthe potential existence of intermediate mass black holes (<10^5 M_Sun), and the\nnew steep (black hole)--(nuclear star cluster) relation, M_bh ~\n(M_nc)^{2.7+/-0.7}, are also discussed. \n\n"}
{"id": "1412.3223", "contents": "Title: Intrinsic Brightness Temperatures of Compact Radio Jets as a Function of\n  Frequency Abstract: We present results of our investigation of the radio intrinsic brightness\ntemperatures of compact radio jets. The intrinsic brightness temperatures of\nabout 100 compact radio jets at 2, 5, 8, 15, and 86 GHz are estimated based on\nlarge VLBI surveys conducted in 2001-2003 (or in 1996 for the 5 GHz sample).\nThe multi-frequency intrinsic brightness temperatures of the sample of jets are\ndetermined by a statistical method relating the observed brightness\ntemperatures with the maximal apparent jet speeds, assuming one representative\nintrinsic brightness temperature for a sample of jets at each observing\nfrequency. By investigating the observed brightness temperatures at 15 GHz in\nmultiple epochs, we found that the determination of the intrinsic brightness\ntemperature for our sample is affected by the flux density variability of\nindividual jets at time scales of a few years. This implies that it is\nimportant to use contemporaneous VLBI observations for the multi-frequency\nanalysis of intrinsic brightness temperatures. Since our analysis is based on\nthe VLBI observations conducted in 2001-2003, the results are not strongly\naffected by the flux density variability. We found that the intrinsic\nbrightness temperature $T_{\\rm 0}$ increases as $T_{\\rm 0}\\propto\\nu_{\\rm\nobs}^{\\xi}$ with $\\xi=0.7$ below a critical frequency $\\nu_{\\rm c}\\approx9 {\\rm\nGHz}$ where energy losses begin to dominate the emission. Above $\\nu_{\\rm c}$,\n$T_{\\rm 0}$ decreases with $\\xi=-1.2$, supporting for the decelerating jet\nmodel or particle cascade model. We also found that the peak value of $T_{\\rm\n0}\\approx3.4\\times10^{10}$ K is close to the equipartition temperature,\nimplying that the VLBI cores observable at 2-86 GHz may be representing jet\nregions where the magnetic field energy dominates the total energy in jets. \n\n"}
{"id": "1412.3770", "contents": "Title: No Cosmic Rays from Curvature Oscillations during Structure Formation\n  with $F(R)$-gravity Abstract: The Starobinsky model of modified gravity suggested to explain dark energy\nmay be also considered in the astrophysical context. Recently it has been\npointed out that in contracting regions curvature oscillations around the GR\nvalue may lead to the production of high energy particles which contribute to\nthe cosmic ray flux. We revisit these calculations in the Einstein frame and\nshow that the continuous approximation for the matter density used in the\noriginal calculations is not valid. We show that this problem is generic in\n$F(R)$-gravity models introduced to describe the dark energy. We go beyond the\napproximation and find the rate of particle production to be negligible. \n\n"}
{"id": "1412.4418", "contents": "Title: A lunar radio experiment with the Parkes radio telescope for the LUNASKA\n  project Abstract: We describe an experiment using the Parkes radio telescope in the 1.2-1.5 GHz\nfrequency range as part of the LUNASKA project, to search for nanosecond-scale\npulses from particle cascades in the Moon, which may be triggered by\nultra-high-energy astroparticles. Through the combination of a highly sensitive\nmulti-beam radio receiver, a purpose-built backend and sophisticated\nsignal-processing techniques, we achieve sensitivity to radio pulses with a\nthreshold electric field strength of 0.0053 $\\mu$V/m/MHz, lower than previous\nexperiments by a factor of three. We observe no pulses in excess of this\nthreshold in observations with an effective duration of 127 hours. The\ntechniques we employ, including compensating for the phase, dispersion and\nspectrum of the expected pulse, are relevant for future lunar radio\nexperiments. \n\n"}
{"id": "1412.4891", "contents": "Title: On the Variation of Fourier Parameters for Galactic and LMC Cepheids at\n  Optical, Near-Infrared and Mid-Infrared Wavelengths Abstract: We present a light curve analysis of fundamental-mode Galactic and Large\nMagellanic Cloud (LMC) Cepheids based on the Fourier decomposition technique.\nWe have compiled light curve data for Galactic and LMC Cepheids in optical\n({\\it VI}), near-infrared ({\\it JHK}$_s$) and mid-infrared (3.6 $\\&$\n4.5-$\\mu$m) bands from the literature and determined the variation of their\nFourier parameters as a function of period and wavelength. We observed a\ndecrease in Fourier amplitude parameters and an increase in Fourier phase\nparameters with increasing wavelengths at a given period. We also found a\ndecrease in the skewness and acuteness parameters as a function of wavelength\nat a fixed period. We applied a binning method to analyze the progression of\nthe mean Fourier parameters with period and wavelength. We found that for\nperiods longer than about 20 days, the values of the Fourier amplitude\nparameters increase sharply for shorter wavelengths as compared to wavelengths\nlonger than the $J$-band. We observed the variation of the Hertzsprung\nprogression with wavelength. The central period of the Hertzsprung progression\nwas found to increase with wavelength in the case of the Fourier amplitude\nparameters and decrease with increasing wavelength in the case of phase\nparameters. We also observed a small variation of the central period of the\nprogression between the Galaxy and LMC, presumably related to metallicity\neffects. These results will provide useful constraints for stellar pulsation\ncodes that incorporate stellar atmosphere models to produce Cepheid light\ncurves in various bands. \n\n"}
{"id": "1501.00321", "contents": "Title: Unravelling the origin of large-scale magnetic fields in galaxy clusters\n  and beyond through Faraday Rotation Measures with the SKA Abstract: We investigate the possibility for the SKA to detect and study the magnetic\nfields in galaxy clusters and in the less dense environments surrounding them\nusing Faraday Rotation Measures. To this end, we produce 3-dimensional magnetic\nfield models for galaxy clusters of different masses and in different stages of\ntheir evolution, and derive mock rotation measure observations of background\nradiogalaxies. According to our results, already in phase I, we will be able to\ninfer the magnetic field properties in galaxy clusters as a function of the\ncluster mass, down to $10^{13}$ solar-masses. Moreover, using cosmological\nsimulations to model the gas density, we have computed the expected rotation\nmeasure through shock-fronts that occur in the intra-cluster medium during\ncluster mergers. The enhancement in the rotation measure due to the density\njump will permit to constraint the magnetic field strength and structure after\nthe shock passage. SKA observations of polarised sources located behind galaxy\nclusters will answer several questions about the magnetic field strength and\nstructure in galaxy clusters, and its evolution with cosmic time. \n\n"}
{"id": "1501.00495", "contents": "Title: The Needle in the 100 deg2 Haystack: Uncovering Afterglows of Fermi GRBs\n  with the Palomar Transient Factory Abstract: The Fermi Gamma-ray Space Telescope has greatly expanded the number and\nenergy window of observations of gamma-ray bursts (GRBs). However, the coarse\nlocalizations of tens to a hundred square degrees provided by the Fermi GRB\nMonitor instrument have posed a formidable obstacle to locating the bursts'\nhost galaxies, measuring their redshifts, and tracking their panchromatic\nafterglows. We have built a target-of-opportunity mode for the intermediate\nPalomar Transient Factory in order to perform targeted searches for Fermi\nafterglows. Here, we present the results of one year of this program: 8\nafterglow discoveries out of 35 searches. Two of the bursts with detected\nafterglows (GRBs 130702A and 140606B) were at low redshift (z=0.145 and 0.384\nrespectively) and had spectroscopically confirmed broad-line Type Ic\nsupernovae. We present our broadband follow-up including spectroscopy as well\nas X-ray, UV, optical, millimeter, and radio observations. We study possible\nselection effects in the context of the total Fermi and Swift GRB samples. We\nidentify one new outlier on the Amati relation. We find that two bursts are\nconsistent with a mildly relativistic shock breaking out from the progenitor\nstar, rather than the ultra-relativistic internal shock mechanism that powers\nstandard cosmological bursts. Finally, in the context of the Zwicky Transient\nFacility, we discuss how we will continue to expand this effort to find optical\ncounterparts of binary neutron star mergers that may soon be detected by\nAdvanced LIGO and Virgo. \n\n"}
{"id": "1501.01814", "contents": "Title: Relative distribution of dark matter and stellar mass in three massive\n  galaxy clusters Abstract: This work observationally addresses the relative distribution of total and\noptically luminous matter in galaxy clusters by computing the radial profile of\nthe stellar-to-total mass ratio. We adopt state-of-the-art accurate lensing\nmasses free from assumptions about the mass radial profile and we use extremely\ndeep multicolor wide--field optical images to distinguish star formation from\nstellar mass, to properly calculate the mass in galaxies of low mass, those\noutside the red sequence, and to allow a contribution from galaxies of low mass\nthat is clustercentric dependent. We pay special attention to issues and\ncontributions that are usually underrated, yet are major sources of\nuncertainty, and we present an approach that allows us to account for all of\nthem. Here we present the results for three very massive clusters at\n$z\\sim0.45$, MACSJ1206.2-0847, MACSJ0329.6-0211, and RXJ1347.5-1145. We find\nthat stellar mass and total matter are closely distributed on scales from about\n150 kpc to 2.5 Mpc: the stellar-to-total mass ratio is radially constant. We\nfind that the characteristic mass stays constant across clustercentric radii\nand clusters, but that the less-massive end of the galaxy mass function is\ndependent on the environment. \n\n"}
{"id": "1501.01959", "contents": "Title: An adaptively refined phase-space element method for cosmological\n  simulations and collisionless dynamics Abstract: N-body simulations are essential for understanding the formation and\nevolution of structure in the Universe. However, the discrete nature of these\nsimulations affects their accuracy when modelling collisionless systems. We\nintroduce a new approach to simulate the gravitational evolution of cold\ncollisionless fluids by solving the Vlasov-Poisson equations in terms of\nadaptively refineable \"Lagrangian phase space elements\". These geometrical\nelements are piecewise smooth maps between Lagrangian space and Eulerian phase\nspace and approximate the continuum structure of the distribution function.\nThey allow for dynamical adaptive splitting to accurately follow the evolution\neven in regions of very strong mixing. We discuss in detail various one-, two-\nand three-dimensional test problems to demonstrate the performance of our\nmethod. Its advantages compared to N-body algorithms are: i) explicit tracking\nof the fine-grained distribution function, ii) natural representation of\ncaustics, iii) intrinsically smooth gravitational potential fields, thus iv)\neliminating the need for any type of ad-hoc force softening. We show the\npotential of our method by simulating structure formation in a warm dark matter\nscenario. We discuss how spurious collisionality and large-scale discreteness\nnoise of N-body methods are both strongly suppressed, which eliminates the\nartificial fragmentation of filaments. Therefore, we argue that our new\napproach improves on the N-body method when simulating self-gravitating cold\nand collisionless fluids, and is the first method that allows to explicitly\nfollow the fine-grained evolution in six-dimensional phase space. \n\n"}
{"id": "1501.03330", "contents": "Title: The connection between radio and high energy emission in black hole\n  powered systems in the SKA era Abstract: Strong evidence exists for a highly significant correlation between the radio\nflux density and gamma-ray energy flux in blazars revealed by Fermi. However,\nthere are central issues that need to be clarified in this field: what are the\ncounterparts of the about 30% of gamma-ray sources that are as yet\nunidentified? Are they just blazars in disguise or they are something more\nexotic, possibly associated with dark matter? How would they fit in the\nradio-gamma ray connection studied so far?\n  With their superb sensitivity, SKA1-MID and SKA1-SUR will help to resolve all\nof these questions. Even more, while the radio-MeV/GeV connection has been\nfirmly established, a radio-VHE connection has been entirely elusive so far.\nThe advent of CTA in the next few years and the expected CTA-SKA1 synergy will\noffer the chance to explore this connection, even more intriguing as it\ninvolves the opposite ends of the electromagnetic spectrum and the acceleration\nof particles up to the highest energies.\n  We are already preparing to address these questions by exploiting data from\nthe various SKA pathfinders and precursors. We have obtained 18 cm European\nVLBI Network observations of E>10 GeV sources, with a detection rate of 83%.\nMoreover, we are cross correlating the Fermi catalogs with the MWA\ncommissioning survey: when faint gamma-ray sources are considered, pure\npositional coincidence is not significant enough for selecting counterparts and\nwe need an additional physical criterion to pinpoint the right object. It can\nbe radio spectral index, variability, polarization, or compactness, needing\nhigh angular resolution in SKA1-MID; timing studies can also reveal pulsars,\nwhich are often found from dedicated searches of unidentified gamma-ray\nsources. SKA will be the ideal instrument for investigating these\ncharacteristics in conjunction with CTA.\n  (abridged) \n\n"}
{"id": "1501.03765", "contents": "Title: The needle in the hundred square degree haystack: The hunt for binary\n  neutron star mergers with LIGO and Palomar Transient Factory Abstract: The Advanced LIGO and Virgo experiments are poised to detect gravitational\nwaves (GWs) directly for the first time this decade. The ultimate prize will be\njoint observation of a compact binary merger in both gravitational and\nelectromagnetic channels. However, GW sky locations that are uncertain by\nhundreds of square degrees will pose a challenge. I describe a real-time\ndetection pipeline and a rapid Bayesian parameter estimation code that will\nmake it possible to search promptly for optical counterparts in Advanced LIGO.\nHaving analyzed a comprehensive population of simulated GW sources, we describe\nthe sky localization accuracy that the GW detector network will achieve as each\ndetector comes online and progresses toward design sensitivity. Next, in\npreparation for the optical search with the intermediate Palomar Transient\nFactory (iPTF), we have developed a unique capability to detect optical\nafterglows of gamma-ray bursts (GRBs) detected by the Fermi Gamma-ray Burst\nMonitor (GBM). Its comparable error regions offer a close parallel to the\nAdvanced LIGO problem, but Fermi's unique access to MeV-GeV photons and its\nnear all-sky coverage may allow us to look at optical afterglows in a\nrelatively unexplored part of the GRB parameter space. We present the discovery\nand broadband follow-up observations of eight GBM-iPTF afterglows. Two of the\nbursts are at low redshift, are sub-luminous with respect to \"standard\"\ncosmological bursts, and have spectroscopically confirmed broad-line type Ic\nsupernovae. These two bursts are possibly consistent with mildly relativistic\nshocks breaking out from the progenitor envelopes rather than the standard\nmechanism of internal shocks within an ultra-relativistic jet. On a technical\nlevel, the GBM-iPTF effort is a prototype for locating and observing optical\ncounterparts of GW events in Advanced LIGO with the Zwicky Transient Facility. \n\n"}
{"id": "1501.03915", "contents": "Title: Feature Selection based on Machine Learning in MRIs for Hippocampal\n  Segmentation Abstract: Neurodegenerative diseases are frequently associated with structural changes\nin the brain. Magnetic Resonance Imaging (MRI) scans can show these variations\nand therefore be used as a supportive feature for a number of neurodegenerative\ndiseases. The hippocampus has been known to be a biomarker for Alzheimer\ndisease and other neurological and psychiatric diseases. However, it requires\naccurate, robust and reproducible delineation of hippocampal structures. Fully\nautomatic methods are usually the voxel based approach, for each voxel a number\nof local features were calculated. In this paper we compared four different\ntechniques for feature selection from a set of 315 features extracted for each\nvoxel: (i) filter method based on the Kolmogorov-Smirnov test; two wrapper\nmethods, respectively, (ii) Sequential Forward Selection and (iii) Sequential\nBackward Elimination; and (iv) embedded method based on the Random Forest\nClassifier on a set of 10 T1-weighted brain MRIs and tested on an independent\nset of 25 subjects. The resulting segmentations were compared with manual\nreference labelling. By using only 23 features for each voxel (sequential\nbackward elimination) we obtained comparable state of-the-art performances with\nrespect to the standard tool FreeSurfer. \n\n"}
{"id": "1501.03999", "contents": "Title: Improving resolution and depth of astronomical observations via modern\n  mathematical methods for image analysis Abstract: In the past years modern mathematical methods for image analysis have led to\na revolution in many fields, from computer vision to scientific imaging.\nHowever, some recently developed image processing techniques successfully\nexploited by other sectors have been rarely, if ever, experimented on\nastronomical observations. We present here tests of two classes of variational\nimage enhancement techniques: \"structure-texture decomposition\" and\n\"super-resolution\" showing that they are effective in improving the quality of\nobservations. Structure-texture decomposition allows to recover faint sources\npreviously hidden by the background noise, effectively increasing the depth of\navailable observations. Super-resolution yields an higher-resolution and a\nbetter sampled image out of a set of low resolution frames, thus mitigating\nproblematics in data analysis arising from the difference in\nresolution/sampling between different instruments, as in the case of EUCLID VIS\nand NIR imagers. \n\n"}
{"id": "1501.04899", "contents": "Title: Quantum cosmology: a review Abstract: In quantum cosmology, one applies quantum physics to the whole universe.\nWhile no unique version and no completely well-defined theory is available yet,\nthe framework gives rise to interesting conceptual, mathematical and physical\nquestions. This review presents quantum cosmology in a new picture that tries\nto incorporate the importance of inhomogeneity: De-emphasizing the traditional\nminisuperspace view, the dynamics is rather formulated in terms of the\ninterplay of many interacting \"microscopic\" degrees of freedom that describe\nthe space-time geometry. There is thus a close relationship with\nmore-established systems in condensed-matter and particle physics even while\nthe large set of space-time symmetries (general covariance) requires some\nadaptations and new developments. These extensions of standard methods are\nneeded both at the fundamental level and at the stage of evaluating the theory\nby effective descriptions. \n\n"}
{"id": "1501.05304", "contents": "Title: Bayesian Inference for Radio Observations Abstract: New telescopes like the Square Kilometre Array (SKA) will push into a new\nsensitivity regime and expose systematics, such as direction-dependent effects,\nthat could previously be ignored. Current methods for handling such systematics\nrely on alternating best estimates of instrumental calibration and models of\nthe underlying sky, which can lead to inadequate uncertainty estimates and\nbiased results because any correlations between parameters are ignored. These\ndeconvolution algorithms produce a single image that is assumed to be a true\nrepresentation of the sky, when in fact it is just one realization of an\ninfinite ensemble of images compatible with the noise in the data. In contrast,\nhere we report a Bayesian formalism that simultaneously infers both systematics\nand science. Our technique, Bayesian Inference for Radio Observations (BIRO),\ndetermines all parameters directly from the raw data, bypassing image-making\nentirely, by sampling from the joint posterior probability distribution. This\nenables it to derive both correlations and accurate uncertainties, making use\nof the flexible software MEQTREES to model the sky and telescope\nsimultaneously. We demonstrate BIRO with two simulated sets of Westerbork\nSynthesis Radio Telescope data sets. In the first, we perform joint estimates\nof 103 scientific (flux densities of sources) and instrumental (pointing\nerrors, beamwidth and noise) parameters. In the second example, we perform\nsource separation with BIRO. Using the Bayesian evidence, we can accurately\nselect between a single point source, two point sources and an extended\nGaussian source, allowing for 'super-resolution' on scales much smaller than\nthe synthesized beam. \n\n"}
{"id": "1501.05321", "contents": "Title: Interstellar Medium Mitigation Techniques in Pulsar Timing Arrays Abstract: Pulsar Timing Arrays use a set of millisecond pulsars in an attempt to\ndirectly detect nanohertz gravitational waves. For this purpose, high precision\ntiming of the pulsars is essential and ultimately a precision of the order of\n~100 ns is required. Propagation effects in the interstellar medium cause the\nradio emission from a pulsar to be dispersed and scattered, introducing time\nvariable delays of the pulses on their way to Earth. If these delays are not\nproperly corrected for, they may cause significant errors in the timing\nanalysis of a pulsar. These proceedings will review the effects of the\ninterstellar medium on pulse arrival times and present some of the techniques\nused to mitigate the associated time delays from the pulsar signal. Correcting\nfor these delays is essential to providing a higher timing precision and hence\nto increasing the array's sensitivity to gravitational waves. \n\n"}
{"id": "1501.05516", "contents": "Title: The Parkes multibeam pulsar survey: VII. Timing of four millisecond\n  pulsars and the underlying spin period distribution of the Galactic\n  millisecond pulsar population Abstract: We present timing observations of four millisecond pulsars discovered in the\nParkes 20-cm multibeam pulsar survey of the Galactic plane. PSRs J1552-4937 and\nJ1843-1448 are isolated objects with spin periods of 6.28 and 5.47 ms\nrespectively. PSR J1727-2946 is in a 40-day binary orbit and has a spin period\nof 27 ms. The 4.43-ms pulsar J1813-2621 is in a circular 8.16-day binary orbit\naround a low-mass companion star with a minimum companion mass of 0.2 solar\nmasses. Combining these results with detections from five other Parkes\nmultibeam surveys, gives a well-defined sample of 56 pulsars with spin periods\nbelow 20 ms. We develop a likelihood analysis to constrain the functional form\nwhich best describes the underlying distribution of spin periods for\nmillisecond pulsars. The best results were obtained with a log-normal\ndistribution. A gamma distribution is less favoured, but still compatible with\nthe observations. Uniform, power-law and Gaussian distributions are found to be\ninconsistent with the data. Galactic millisecond pulsars being found by current\nsurveys appear to be in agreement with a log-normal distribution which allows\nfor the existence of pulsars with periods below 1.5 ms. \n\n"}
{"id": "1501.05643", "contents": "Title: Stacking of SKA data: comparing uv-plane and image-plane stacking Abstract: Stacking as a tool for studying objects that are not individually detected is\nbecoming popular even for radio interferometric data, and will be widely used\nin the SKA era. Stacking is typically done using imaged data rather than\ndirectly using the visibilities (the uv-data). We have investigated and\ndeveloped a novel algorithm to do stacking using the uv-data. We have performed\nexten- sive simulations comparing to image-stacking, and summarize the results\nof these simulations. Furthermore, we disuss the implications in light of the\nvast data volume produced by the SKA. Having access to the uv-stacked data\nprovides a great advantage, as it allows the possibility to properly analyse\nthe result with respect to calibration artifacts as well as source properties\nsuch as size. For SKA the main challenge lies in archiving the uv-data. For\npurposes of robust stacking analysis, it would be strongly desirable to either\nkeep the calibrated uv-data at least in an aver- age form, or implement a\nstacking queue where stacking positions could be provided prior to the\nobservations and the uv-stacking is done almost in real time. \n\n"}
{"id": "1501.05694", "contents": "Title: ALMA Multi-line Imaging of the Nearby Starburst Galaxy NGC 253 Abstract: We present spatially resolved ($\\sim$50 pc) imaging of molecular gas species\nin the central kiloparsec of the nearby starburst galaxy NGC 253, based on\nobservations taken with the Atacama Large Millimeter/submillimeter Array\n(ALMA). A total of 50 molecular lines are detected over a 13 GHz bandwidth\nimaged in the 3 mm band. Unambiguous identifications are assigned for 27 lines.\nBased on the measured high CO/C$^{17}$O isotopic line ratio ($\\gtrsim$350), we\nshow that $^{12}$CO(1-0) has moderate optical depths. A comparison of the HCN\nand HCO$^{+}$ with their $^{13}$C-substituted isotopologues shows that the\nHCN(1-0) and HCO$^{+}$(1-0) lines have optical depths at least comparable to\nCO(1-0). H$^{13}$CN/H$^{13}$CO$^{+}$ (and H$^{13}$CN/HN$^{13}$C) line ratios\nprovide tighter constraints on dense gas properties in this starburst. SiO has\nelevated abundances across the nucleus. HNCO has the most distinctive\nmorphology of all the bright lines, with its global luminosity dominated by the\nouter parts of the central region. The dramatic variation seen in the HNCO/SiO\nline ratio suggests that some of the chemical signatures of shocked gas are\nbeing erased in the presence of dominating central radiation fields (traced by\nC$_{2}$H and CN). High density molecular gas tracers (including HCN, HCO$^+$,\nand CN) are detected at the base of the molecular outflow. We also detect\nhydrogen $\\beta$ recombination lines that, like their $\\alpha$ counterparts,\nshow compact, centrally peaked morphologies, distinct from the molecular gas\ntracers. A number of sulfur based species are mapped (CS, SO, NS, C$_{2}$S,\nH$_{2}$CS and CH$_{3}$SH) and have morphologies similar to SiO. \n\n"}
{"id": "1501.06648", "contents": "Title: Detecting very long-lived gravitational-wave transients lasting hours to\n  weeks Abstract: We explore the possibility of very long-lived gravitational-wave transients\n(and detector artifacts) lasting hours to weeks. Such very long signals are\nboth interesting in their own right and as a potential source of systematic\nerror in searches for persistent signals, e.g., from a stochastic\ngravitational-wave background. We review possible mechanisms for emission on\nthese time scales and discuss computational challenges associated with their\ndetection: namely, the substantial volume of data involved in a search for very\nlong transients can require vast computer memory and processing time. These\ncomputational difficulties can be addressed through a form of data compression\nknown as coarse-graining, in which information about short time spans is\ndiscarded in order to reduce the computational requirements of a search. Using\ndata compression, we demonstrate an efficient radiometer (cross-correlation)\nalgorithm for the detection of very long transients. In the process, we\nidentify features of a very long transient search (related to the rotation of\nthe Earth) that make it more complicated than a search for shorter transient\nsignals. We implement suitable solutions. \n\n"}
{"id": "1501.07309", "contents": "Title: Arbitrary Transform Telescopes: The Generalization of Interferometry Abstract: The basic principle of astronomical interferometry is to derive the angular\ndistribution of radiation in the sky from the Fourier transform of the electric\nfield on the ground. What is so special about the Fourier transform? Nothing,\nit turns out. I consider the possibility of performing other transforms on the\nelectric field with digital technology. The Fractional Fourier Transform (FrFT)\nis useful for interpreting observations of sources that are close to the\ninterferometer (in the atmosphere for radio interferometers). Essentially,\napplying the FrFT focuses the array somewhere nearer than infinity. Combined\nwith the other Linear Canonical Transforms, any homogeneous linear optical\nsystem with thin elements can be instantiated. The time variation of the\nelectric field can also be decomposed into other bases besides the Fourier\nmodes, which is especially useful for dispersed transients or quick pulses. I\ndiscuss why the Fourier basis is so commonly used, and suggest it is partly\nbecause most astrophysical sources vary slowly in time. \n\n"}
{"id": "1502.00008", "contents": "Title: Gravitational lens modelling in a citizen science context Abstract: We develop a method to enable collaborative modelling of gravitational lenses\nand lens candidates, that could be used by non-professional lens enthusiasts.\nIt uses an existing free-form modelling program (glass), but enables the input\nto this code to be provided in a novel way, via a user-generated diagram that\nis essentially a sketch of an arrival-time surface. We report on an\nimplementation of this method, SpaghettiLens, which has been tested in a\nmodelling challenge using 29 simulated lenses drawn from a larger set created\nfor the Space Warps citizen science strong lens search. We find that volunteers\nfrom this online community asserted the image parities and time ordering\nconsistently in some lenses, but made errors in other lenses depending on the\nimage morphology. While errors in image parity and time ordering lead to large\nerrors in the mass distribution, the enclosed mass was found to be more robust:\nthe model-derived Einstein radii found by the volunteers were consistent with\nthose produced by one of the professional team, suggesting that given the\nappropriate tools, gravitational lens modelling is a data analysis activity\nthat can be crowd-sourced to good effect. Ideas for improvement are discussed,\nthese include (a) overcoming the tendency of the models to be shallower than\nthe correct answer in test cases, leading to systematic overestimation of the\nEinstein radius by 10 per cent at present, and (b) detailed modelling of arcs. \n\n"}
{"id": "1502.00638", "contents": "Title: ANIR : Atacama Near-Infrared Camera for the 1.0-m miniTAO Telescope Abstract: We have developed a near-infrared camera called ANIR (Atacama Near-InfraRed\ncamera) for the University of Tokyo Atacama Observatory 1.0m telescope\n(miniTAO) installed at the summit of Cerro Chajnantor (5640 m above sea level)\nin northern Chile. The camera provides a field of view of 5'.1 $\\times$ 5'.1\nwith a spatial resolution of 0\".298 /pixel in the wavelength range of 0.95 to\n2.4 $\\mu$m. Taking advantage of the dry site, the camera is capable of hydrogen\nPaschen-$\\alpha$ (Pa$\\alpha$, $\\lambda=$1.8751 $\\mu$m in air) narrow-band\nimaging observations, at which wavelength ground-based observations have been\nquite difficult due to deep atmospheric absorption mainly from water vapor. We\nhave been successfully obtaining Pa$\\alpha$ images of Galactic objects and\nnearby galaxies since the first-light observation in 2009 with ANIR. The\nthroughputs at the narrow-band filters ($N1875$, $N191$) including the\natmospheric absorption show larger dispersion (~10%) than those at broad-band\nfilters (a few %), indicating that they are affected by temporal fluctuations\nin Precipitable Water Vapor (PWV) above the site. We evaluate the PWV content\nvia the atmospheric transmittance at the narrow-band filters, and derive that\nthe median and the dispersion of the distribution of the PWV are 0.40+/-0.30 mm\nfor $N1875$ and 0.37+/-0.21 mm for $N191$, which are remarkably smaller\n(49+/-38% for $N1875$ and 59+/-26% for $N191$) than radiometry measurements at\nthe base of Cerro Chajnantor (5100 m alt.). The decrease in PWV can be\nexplained by the altitude of the site when we assume that the vertical\ndistribution of the water vapor is approximated at an exponential profile with\nscale heights within 0.3-1.9 km (previously observed values at night). We thus\nconclude that miniTAO/ANIR at the summit of Cerro Chajnantor indeed provides us\nan excellent capability for a \"ground-based\" Pa$\\alpha$ observation. \n\n"}
{"id": "1502.01594", "contents": "Title: Planck 2015 results. XIX. Constraints on primordial magnetic fields Abstract: We compute and investigate four types of imprint of a stochastic background\nof primordial magnetic fields (PMFs) on the cosmic microwave background (CMB)\nanisotropies: the impact of PMFs on the CMB spectra; the effect on CMB\npolarization induced by Faraday rotation; the impact of PMFs on the ionization\nhistory; magnetically-induced non-Gaussianities; and the magnetically-induced\nbreaking of statistical isotropy. Overall, Planck data constrain the amplitude\nof PMFs to less than a few nanogauss. In particular, individual limits coming\nfrom the analysis of the CMB angular power spectra, using the Planck\nlikelihood, are $B_{1\\,\\mathrm{Mpc}}< 4.4$ nG (where $B_{1\\,\\mathrm{Mpc}}$ is\nthe comoving field amplitude at a scale of 1 Mpc) at 95% confidence level,\nassuming zero helicity, and $B_{1\\,\\mathrm{Mpc}}< 5.6$ nG for a maximally\nhelical field.For nearly scale-invariant PMFs we obtain\n$B_{1\\,\\mathrm{Mpc}}<2.0$ nG and $B_{1\\,\\mathrm{Mpc}}<0.9$ nG if the impact of\nPMFs on the ionization history of the Universe is included. From the analysis\nof magnetically-induced non-Gaussianity we obtain three different values,\ncorresponding to three applied methods, all below 5 nG. The constraint from the\nmagnetically-induced passive-tensor bispectrum is $B_{1\\,\\mathrm{Mpc}}< 2.8$\nnG. A search for preferred directions in the magnetically-induced passive\nbispectrum yields $B_{1\\,\\mathrm{Mpc}}< 4.5$ nG, whereas the the\ncompensated-scalar bispectrum gives $B_{1\\,\\mathrm{Mpc}}< 3$ nG. The analysis\nof the Faraday rotation of CMB polarization by PMFs uses the Planck power\nspectra in $EE$ and $BB$ at 70 GHz and gives $B_{1\\,\\mathrm{Mpc}}< 1380$ nG. In\nour final analysis, we consider the harmonic-space correlations produced by\nAlfv\\'en waves, finding no significant evidence for the presence of these\nwaves. Together, these results comprise a comprehensive set of constraints on\npossible PMFs with Planck data. \n\n"}
{"id": "1502.02666", "contents": "Title: Shaken, not stirred: kinetic mixing in scalar-tensor theories of gravity Abstract: Kinetic mixing between the metric and scalar degrees of freedom is an\nessential ingredient in contemporary scalar-tensor theories. This often makes\nhard to understand their physical content, especially when derivative mixing is\npresent, as it is the case for Horndeski action. In this work we develop a\nmethod that allows to write a Ricci curvature-free scalar field equation and\ndiscuss some of the advantages of such rephrasing in the study of stability\nissues in the presence of matter, the existence of an Einstein frame and the\ngeneralization of the disformal screening mechanism. For quartic Horndeski\ntheories, such procedure leaves, in general, a residual coupling to curvature,\ngiven by the Weyl tensor. This gives rise to a binary classification of\nscalar-tensor theories into stirred theories, for which the curvature can be\nsubstituted for, and shaken theories for which a residual coupling to curvature\nremains. Quite remarkably, we have found that generalized DBI Galileons belong\nto the first class. Finally, we discuss kinetic mixing in quintic theories for\nwhich non-linear mixing terms appears and in the recently proposed theories\nbeyond Horndeski which display a novel form of kinetic mixing, in which the\nfield equation is sourced by derivatives of the energy-momentum tensor. \n\n"}
{"id": "1502.03783", "contents": "Title: Transient X-ray pulsar V0332+53: pulse phase-resolved spectroscopy and\n  the reflection model Abstract: We present the results of the pulse phase- and luminosity-resolved\nspectroscopy of the transient X-ray pulsar V0332+53, performed for the first\ntime in a wide luminosity range (1-40)x10^{37} erg/s during a giant outburst\nobserved by the RXTE observatory in Dec 2004 - Feb 2005. We characterize the\nspectra quantitatively and built the detailed \"three-dimensional\" picture of\nspectral variations with pulse phase and throughout the outburst. We show that\nall spectral parameters are strongly variable with the pulse phase, and the\npattern of this variability significantly changes with luminosity directly\nreflecting the associated changes in the structure of emission regions and\ntheir beam patterns. Obtained results are qualitatively discussed in terms of\nthe recently developed reflection model for the formation of cyclotron lines in\nthe spectra of X-ray pulsars. \n\n"}
{"id": "1502.06001", "contents": "Title: Detection and localization of single-source gravitational waves with\n  pulsar timing arrays Abstract: Pulsar timing arrays (PTAs) can be used to search for very low frequency\n($10^{-9}$--$10^{-7}$ Hz) gravitational waves (GWs). In this paper we present a\ngeneral method for the detection and localization of single-source GWs using\nPTAs. We demonstrate the effectiveness of this new method for three types of\nsignals: monochromatic waves as expected from individual supermassive binary\nblack holes in circular orbits, GWs from eccentric binaries and GW bursts. We\nalso test its implementation in realistic data sets that include effects such\nas uneven sampling and heterogeneous data spans and measurement precision. It\nis shown that our method, which works in the frequency domain, performs as well\nas published time-domain methods. In particular, we find it equivalent to the\n$\\mathcal{F}_{e}$-statistic for monochromatic waves. We also discuss the\nconstruction of null streams -- data streams that have null response to GWs,\nand the prospect of using null streams as a consistency check in the case of\ndetected GW signals. Finally, we present sensitivities to individual\nsupermassive binary black holes in eccentric orbits. We find that a\nmonochromatic search that is designed for circular binaries can efficiently\ndetect eccentric binaries with both high and low eccentricities, while a\nharmonic summing technique provides greater sensitivities only for binaries\nwith moderate eccentricities. \n\n"}
{"id": "1502.07596", "contents": "Title: Foregrounds in Wide-Field Redshifted 21 cm Power Spectra Abstract: Detection of 21~cm emission of HI from the epoch of reionization, at\nredshifts z>6, is limited primarily by foreground emission. We investigate the\nsignatures of wide-field measurements and an all-sky foreground model using the\ndelay spectrum technique that maps the measurements to foreground object\nlocations through signal delays between antenna pairs. We demonstrate\ninterferometric measurements are inherently sensitive to all scales, including\nthe largest angular scales, owing to the nature of wide-field measurements.\nThese wide-field effects are generic to all observations but antenna shapes\nimpact their amplitudes substantially. A dish-shaped antenna yields the most\ndesirable features from a foreground contamination viewpoint, relative to a\ndipole or a phased array. Comparing data from recent Murchison Widefield Array\nobservations, we demonstrate that the foreground signatures that have the\nlargest impact on the HI signal arise from power received far away from the\nprimary field of view. We identify diffuse emission near the horizon as a\nsignificant contributing factor, even on wide antenna spacings that usually\nrepresent structures on small scales. For signals entering through the primary\nfield of view, compact emission dominates the foreground contamination. These\ntwo mechanisms imprint a characteristic \"pitchfork\" signature on the\n\"foreground wedge\" in Fourier delay space. Based on these results, we propose\nthat selective down-weighting of data based on antenna spacing and time can\nmitigate foreground contamination substantially by a factor ~100 with\nnegligible loss of sensitivity. \n\n"}
{"id": "1503.00346", "contents": "Title: On the detection of point sources in Planck LFI 70 GHz CMB maps based on\n  cleaned K-map Abstract: We use the Planck LFI 70GHz data to further probe point source detection\ntechnique in the sky maps of the cosmic microwave background (CMB) radiation.\nThe method developed by Tegmark et al. for foreground reduced maps and the\nKolmogorov parameter as the descriptor are adopted for the analysis of Planck\nsatellite CMB temperature data. Most of the detected points coincide with point\nsources already revealed by other methods. However, we have also found 9 source\ncandidates for which still no counterparts are known. \n\n"}
{"id": "1503.00770", "contents": "Title: GERLUMPH Data Release 2: 2.5 billion simulated microlensing light curves Abstract: In the upcoming synoptic all--sky survey era of astronomy, thousands of new\nmultiply imaged quasars are expected to be discovered and monitored regularly.\nLight curves from the images of gravitationally lensed quasars are further\naffected by superimposed variability due to microlensing. In order to\ndisentangle the microlensing from the intrinsic variability of the light\ncurves, the time delays between the multiple images have to be accurately\nmeasured. The resulting microlensing light curves can then be analyzed to\nreveal information about the background source, such as the size of the quasar\naccretion disc. In this paper we present the most extensive and coherent\ncollection of simulated microlensing light curves; we have generated $>2.5$\nbillion light curves using the GERLUMPH high resolution microlensing\nmagnification maps. Our simulations can be used to: train algorithms to measure\nlensed quasar time delays, plan future monitoring campaigns, and study light\ncurve properties throughout parameter space. Our data are openly available to\nthe community and are complemented by online eResearch tools, located at\nhttp://gerlumph.swin.edu.au . \n\n"}
{"id": "1503.01526", "contents": "Title: The LOFAR Transients Pipeline Abstract: Current and future astronomical survey facilities provide a remarkably rich\nopportunity for transient astronomy, combining unprecedented fields of view\nwith high sensitivity and the ability to access previously unexplored\nwavelength regimes. This is particularly true of LOFAR, a\nrecently-commissioned, low-frequency radio interferometer, based in the\nNetherlands and with stations across Europe. The identification of and response\nto transients is one of LOFAR's key science goals. However, the large data\nvolumes which LOFAR produces, combined with the scientific requirement for\nrapid response, make automation essential. To support this, we have developed\nthe LOFAR Transients Pipeline, or TraP. The TraP ingests multi-frequency image\ndata from LOFAR or other instruments and searches it for transients and\nvariables, providing automatic alerts of significant detections and populating\na lightcurve database for further analysis by astronomers. Here, we discuss the\nscientific goals of the TraP and how it has been designed to meet them. We\ndescribe its implementation, including both the algorithms adopted to maximize\nperformance as well as the development methodology used to ensure it is robust\nand reliable, particularly in the presence of artefacts typical of radio\nastronomy imaging. Finally, we report on a series of tests of the pipeline\ncarried out using simulated LOFAR observations with a known population of\ntransients. \n\n"}
{"id": "1503.01773", "contents": "Title: Multi-Step Cascade Annihilations of Dark Matter and the Galactic Center\n  Excess Abstract: If dark matter is embedded in a non-trivial dark sector, it may annihilate\nand decay to lighter dark-sector states which subsequently decay to the\nStandard Model. Such scenarios - with annihilation followed by cascading\ndark-sector decays - can explain the apparent excess GeV gamma-rays identified\nin the central Milky Way, while evading bounds from dark matter direct\ndetection experiments. Each 'step' in the cascade will modify the observable\nsignatures of dark matter annihilation and decay, shifting the resulting\nphotons and other final state particles to lower energies and broadening their\nspectra. We explore, in a model-independent way, the effect of multi-step\ndark-sector cascades on the preferred regions of parameter space to explain the\nGeV excess. We find that the broadening effects of multi-step cascades can\nadmit final states dominated by particles that would usually produce too\nsharply peaked photon spectra; in general, if the cascades are hierarchical\n(each particle decays to substantially lighter particles), the preferred mass\nrange for the dark matter is in all cases 20-150 GeV. Decay chains that have\nnearly-degenerate steps, where the products are close to half the mass of the\nprogenitor, can admit much higher DM masses. We map out the region of\nmass/cross-section parameter space where cascades (degenerate, hierarchical or\na combination) can fit the signal, for a range of final states. In the current\nwork, we study multi-step cascades in the context of explaining the GeV excess,\nbut many aspects of our results are general and can be extended to other\napplications. \n\n"}
{"id": "1503.02233", "contents": "Title: NebulOS: A Big Data Framework for Astrophysics Abstract: We introduce NebulOS, a Big Data platform that allows a cluster of Linux\nmachines to be treated as a single computer. With NebulOS, the process of\nwriting a massively parallel program for a datacenter is no more complicated\nthan writing a Python script for a desktop computer. The platform enables most\npre-existing data analysis software to be used, as scale, in a datacenter\nwithout modification. The shallow learning curve and compatibility with\nexisting software greatly reduces the time required to develop distributed data\nanalysis pipelines. The platform is built upon industry-standard, open-source\nBig Data technologies, from which it inherits several fault tolerance features.\nNebulOS enhances these technologies by adding an intuitive user interface,\nautomated task monitoring, and other usability features. We present a summary\nof the architecture, provide usage examples, and discuss the system's\nperformance scaling. \n\n"}
{"id": "1503.04810", "contents": "Title: Running from Features: Optimized Evaluation of Inflationary Power\n  Spectra Abstract: In models like axion monodromy, temporal features during inflation which are\nnot associated with its ending can produce scalar, and to a lesser extent,\ntensor power spectra where deviations from scale-free power law spectra can be\nas large as the deviations from scale invariance itself. Here the standard\nslow-roll approach breaks down since its parameters evolve on an efolding scale\n$\\Delta N$ much smaller than the efolds to the end of inflation. Using the\ngeneralized slow-roll approach, we show that the expansion of observables in a\nhierarchy of potential or Hubble evolution parameters comes from a Taylor\nexpansion of the features around an evaluation point that can be optimized.\nOptimization of the leading-order expression provides a sufficiently accurate\napproximation for current data as long as the power spectrum can be described\nover the well-observed few efolds by the local tilt and running. Standard\nsecond-order approaches, often used in the literature, ironically are worse\nthan leading-order approaches due to inconsistent evaluation of observables. We\ndevelop a new optimized next-order approach which predicts observables to\n$10^{-3}$ even for $\\Delta N\\sim 1$ where all parameters in the infinite\nhierarchy are of comparable magnitude. For models with $\\Delta N \\ll 1$, the\ngeneralized slow-roll approach provides integral expressions that are accurate\nto second order in the deviation from scale invariance. Their evaluation in the\nmonodromy model provides highly accurate explicit relations between the running\noscillation amplitude, frequency and phase in the curvature spectrum and\nparameters of the potential. \n\n"}
{"id": "1503.06673", "contents": "Title: Cosmic Web and Environmental Dependence of Screening: Vainshtein vs.\n  Chameleon Abstract: Theories which modify general relativity to explain the accelerated expansion\nof the Universe often use screening mechanisms to satisfy constraints on Solar\nSystem scales. We investigate the effects of the cosmic web and the local\nenvironmental density of dark matter halos on the screening properties of the\nVainshtein and chameleon screening mechanisms. We compare the cosmic web\nmorphology of dark matter particles, mass functions of dark matter halos, mass\nand radial dependence of screening, velocity dispersions and peculiar\nvelocities, and environmental dependence of screening mechanisms in $f(R)$ and\nnDGP models. Using the ORIGAMI cosmic web identification routine we find that\nthe Vainshtein mechanism depends on the cosmic web morphology of dark matter\nparticles, since these are defined according to the dimensionality of their\ncollapse, while the chameleon mechanism shows no morphology dependence. The\nchameleon screening of halos and their velocity dispersions depend on halo\nmass, and small halos and subhalos can be environmentally screened in the\nchameleon mechanism. On the other hand, the screening of halos in the\nVainshtein mechanism does not depend on mass nor environment, and their\nvelocity dispersions are suppressed. The peculiar velocities of halos in the\nVainshtein mechanism are enhanced because screened objects can still feel the\nfifth force generated by external fields, while peculiar velocities of\nchameleon halos are suppressed when the halo centers are screened. \n\n"}
{"id": "1503.06961", "contents": "Title: Recent Results from Telescope Array Abstract: The Telescope Array (TA) is an experiment to observe Ultra-High Energy Cosmic\nRays (UHECRs). TA's recent results, the energy spectrum and anisotropy based on\nthe 6-year surface array data, and the primary composition obtained from the\nshower maximum Xmax are reported. The spectrum demonstrates a clear dip and\ncutoff. The shape of the spectrum is well described by the energy loss of\nextra-galactic protons interacting with the cosmic microwave background (CMB).\nAbove the cutoff, a medium-scale (20 degrees radius) flux enhancement was\nobserved near the Ursa-Major. A chance probability of creating this hotspot\nfrom the isotropic flux is 4.0 sigma. The measured Xmax is consistent with the\nprimary being proton or light nuclei for energies 10^18.2 eV - 10^19.2 eV. \n\n"}
{"id": "1503.07504", "contents": "Title: Data Reduction Pipeline for the MMT and Magellan Infrared Spectrograph Abstract: We describe the new spectroscopic data reduction pipeline for the\nmulti-object MMT/Magellan Infrared Spectrograph. The pipeline is implemented in\nidl as a stand-alone package and is publicly available in both stable and\ndevelopment versions. We describe novel algorithms for sky subtraction and\ncorrection for telluric absorption. We demonstrate that our sky subtraction\ntechnique reaches the Poisson limit set by the photon statistics. Our telluric\ncorrection uses a hybrid approach by first computing a correction function from\nan observed stellar spectrum, and then differentially correcting it using a\ngrid of atmosphere transmission models for the target airmass value. The\npipeline provides a sufficient level of performance for real time reduction and\nthus enables data quality control during observations. We reduce an example\ndataset to demonstrate the high data reduction quality. \n\n"}
{"id": "1503.08739", "contents": "Title: Non-linear curvature inhomogeneities and backreaction for relativistic\n  viscous fluids Abstract: The non-perturbative curvature inhomogeneities induced by relativistic\nviscous fluids are not conserved in the large-scale limit. However when the\nbulk viscosity is a function of the total energy density of the plasma (or of\nthe trace of the extrinsic curvature) the relevant evolution equations develop\na further symmetry preventing the non-linear growth of curvature perturbations.\nIn this situation the fully inhomogeneous evolution can be solved to leading\norder in the gradient expansion. Over large-scales both the acceleration and\nthe curvature inhomogeneities are determined by the bulk viscosity\ncoefficients. Conversely the shear viscosity does not affect the evolution of\nthe curvature and does not produce any acceleration. The curvature modes\nanalyzed here do not depend on the choice of time hypersurfaces and are\ninvariant for infinitesimal coordinate transformations in the perturbative\nregime. \n\n"}
{"id": "1504.02779", "contents": "Title: Resonant bar detector constraints on macro dark matter Abstract: The current standard model of cosmology, $\\Lambda$CDM, requires dark matter\nto make up around $25\\%$ of the total energy budget of the Universe. Yet, quite\npuzzlingly, there appears to be no candidate particle in the current Standard\nModel of particle physics. Assuming the validity of the cold dark matter (CDM)\nparadigm, dark matter has evaded detection thus far either because it is\nintrinsically a weakly interacting substance or because its interactions are\nsuppressed by its high constituent mass and low number density. Most approaches\nto explain dark matter to date assume the former and therefore require\nbeyond-the-Standard-Model particles that have yet to be observed directly or\nindirectly. Given the dearth of evidence for this class of candidates it is\ntimely to consider the latter possibility, which allows for candidates that may\nor may not arise from the Standard Model. In this work we extend a recent study\nof this general class of so-called macro dark matter--candidates with\ncharacteristic masses of grams and geometric cross sections of cm$^2$. We\nconsider new bounds that can be set using existing data from the resonant bar\ngravitational wave detectors NAUTILUS and EXPLORER. \n\n"}
{"id": "1504.03469", "contents": "Title: Hyperbolic Inflation in the Light of Planck 2015 data Abstract: Rubano and Barrow have discussed the emergence of a dark energy, with\nlate-time cosmic acceleration arising from a self-interacting homogeneous\nscalar field with a potential of hyperbolic power type. Here, we study the\nevolution of this scalar field potential back in the inflationary era. Using\nthe hyperbolic power potential in the framework of inflation, we find that the\nmain slow-roll parameters, like the scalar spectral index, the running of the\nspectral index and the tensor-to-scalar fluctuation ratio can be computed\nanalytically. Finally, in order to test the viability of this hyperbolic scalar\nfield model at the early stages of the Universe, we compare the predictions of\nthat model against the latest observational data, namely Planck 2015. \n\n"}
{"id": "1504.03697", "contents": "Title: A dwarf galaxy's transformation and a massive galaxy's edge: autopsy of\n  kill and killer in NGC 1097 Abstract: (abridged) We present a dynamical analysis of the extended stellar stream\nencircling NGC 1097. Within a statistical framework, we model its surface\nbrightness using mock streams as in Amorisco (2015) and deep imaging data from\nthe CHART32 telescope (Stellar Tidal Stream Survey). We reconstruct the\npost-infall evolution of the progenitor, which has experienced 3 pericentric\npassages and lost more than 2 orders of magnitude in mass. At infall,\n$5.4\\pm0.6$ Gyr ago, the progenitor was a disky dwarf with mass of\n$\\log_{10}[m(<3.4\\pm1 {\\rm kpc})/ M_\\odot]=10.35\\pm0.25$. We illustrate how the\n90$^\\circ$ turn in the stream, identifying the `dog leg', is the signature of\nthe progenitor's prograde rotation. Today, the remnant is a nucleated dwarf,\nwith a LOS velocity of $v_{\\rm p, los}^{\\rm obs}=-30\\pm 30$ kms$^{-1}$, and a\nluminosity of $3.3\\times 10^7 L_{V,\\odot}$ (Galianni et al. 2010). Our\nindependent analysis predicts $v_{\\rm p, los}=-51^{-17}_{+14}$ kms$^{-1}$, and\nmeasures $\\log_{10}(m/ M_\\odot)=7.4^{+0.6}_{-0.8}$, so that the compact nucleus\nis soon becoming a low-luminosity UCD. We find that NGC 1097 has a mass of\n$M_{200}=1.8^{+0.5}_{-0.4} \\times 10^{12}\\; M_{\\odot}$, and its concentration\n$c_{200}=6.7^{+2.4}_{-1.3}$ is in agreement with LCDM. The stream is described\nalmost down to the noise in a spherical host potential, we find this would not\nbe possible if the halo was substantially triaxial at large radii. Its\nmorphology shows that the slope of the total density profile bends from an\ninner $\\gamma(r_{\\rm peri})=1.5\\pm0.15$. The progenitor's orbit reaches $r_{\\rm\napo}=150\\pm 15$ kpc, more than a half of the virial radius of the host, so\nthat, for the first time on an individual extragalactic halo, we measure the\nouter density slope, $\\gamma(0.6r_{200,c})=3.9\\pm0.5$. This demonstrates the\npromise of the newborn field of detailed, statistical modelling of\nextragalactic tidal streams. \n\n"}
{"id": "1504.04516", "contents": "Title: The Clustering Evolution of Dusty Star-Forming Galaxies Abstract: We present predictions for the clustering of galaxies selected by their\nemission at far infra-red (FIR) and sub-millimetre wavelengths. This includes\nthe first predictions for the effect of clustering biases induced by the coarse\nangular resolution of single-dish telescopes at these wavelengths. We combine a\nnew version of the GALFORM model of galaxy formation with a self-consistent\nmodel for calculating the absorption and re-emission of radiation by\ninterstellar dust. Model galaxies selected at $850$ $\\mu$m reside in dark\nmatter halos of mass $M_{\\rm halo}\\sim10^{11.5}-10^{12}$ $h^{-1}$ M$_{\\odot}$,\nindependent of redshift (for $0.2\\lesssim z\\lesssim4$) or flux (for\n$0.25\\lesssim S_{850\\mu\\rm m}\\lesssim4$ mJy). At $z\\sim2.5$, the brightest\ngalaxies ($S_{850\\mu\\rm m}>4$ mJy) exhibit a correlation length of\n$r_{0}=5.5_{-0.5}^{+0.3}$ $h^{-1}$ Mpc, consistent with observations. We show\nthat these galaxies have descendants with stellar masses $M_{\\star}\\sim10^{11}$\n$h^{-1}$ M$_{\\odot}$ occupying halos spanning a broad range in mass $M_{\\rm\nhalo}\\sim10^{12}-10^{14}$ $h^{-1}$ M$_{\\odot}$. The FIR emissivity at shorter\nwavelengths ($250$, $350$ and $500$ $\\mu$m) is also dominated by galaxies in\nthe halo mass range $M_{\\rm halo}\\sim10^{11.5}-10^{12}$ $h^{-1}$ M$_{\\odot}$,\nagain independent of redshift (for $0.5\\lesssim z\\lesssim5$). We compare our\npredictions for the angular power spectrum of cosmic infra-red background\nanisotropies at these wavelengths with observations, finding agreement to\nwithin a factor of $\\sim2$ over all scales and wavelengths, an improvement over\nearlier versions of the model. Simulating images at $850$ $\\mu$m, we show that\nconfusion effects boost the measured angular correlation function on all scales\nby a factor of $\\sim4$. This has important consequences, potentially leading to\ninferred halo masses being overestimated by an order of magnitude. \n\n"}
{"id": "1504.04660", "contents": "Title: A spectral optical flow method for determining velocities from digital\n  imagery Abstract: We present a method for determining surface flows from solar images based\nupon optical flow techniques. We apply the method to sets of images obtained by\na variety of solar imagers to assess its performance. The {\\tt opflow3d}\nprocedure is shown to extract accurate velocity estimates when provided perfect\ntest data and quickly generates results consistent with completely distinct\nmethods when applied on global scales. We also validate it in detail by\ncomparing it to an established method when applied to high-resolution datasets\nand find that it provides comparable results without the need to tune, filter\nor otherwise preprocess the images before its application. \n\n"}
{"id": "1504.05575", "contents": "Title: Derivative of the light frequency shift as a measure of spacetime\n  curvature for gravitational wave detection Abstract: The measurement of frequency shifts for light beams exchanged between two\ntest masses nearly in free fall is at the heart of gravitational wave\ndetection. It is envisaged that the derivative of the frequency shift is in\nfact limited by differential forces acting on those test masses. We calculate\nthe derivative of the frequency shift with a fully covariant, gauge-independent\nand coordinate-free method. This method is general and does not require a\ncongruence of nearby beams' null geodesics as done in previous work. We show\nthat the derivative of the parallel transport is the only means by which\ngravitational effects shows up in the frequency shift. This contribution is\ngiven as an integral of the Riemann tensor --the only physical observable of\ncurvature-- along the beam's geodesic. The remaining contributions are: the\ndifference of velocities, the difference of non-gravitational forces, and\nfinally fictitious forces, either locally at the test masses or non-locally\nintegrated along the beam's geodesic. As an application relevant to\ngravitational wave detection, we work out the frequency shift in the local\nLorentz frame of nearby geodesics. \n\n"}
{"id": "1504.05966", "contents": "Title: OGLE-IV: Fourth Phase of the Optical Gravitational Lensing Experiment Abstract: We present both the technical overview and main science drivers of the fourth\nphase of the Optical Gravitational Lensing Experiment (hereafter OGLE-IV).\nOGLE-IV is currently one of the largest sky variability surveys worldwide,\ntargeting the densest stellar regions of the sky. The survey covers over 3000\nsquare degrees in the sky and monitors regularly over a billion sources.\n  The main targets include the inner Galactic Bulge and the Magellanic System.\nTheir photometry spans the range of $12<I<21$ mag and $13<I<21.7$ mag,\nrespectively. Supplementary shallower Galaxy Variability Survey covers the\nextended Galactic bulge and 2/3 of the whole Galactic disk within the magnitude\nrange of $10<I<19$ mag. All OGLE-IV surveys provide photometry with\nmilli-magnitude accuracy at the bright end. The cadence of observations varies\nfrom 19-60 minutes in the inner Galactic bulge to 1-3 days in the remaining\nGalactic bulge fields, Magellanic System and the Galactic disk.\n  OGLE-IV provides the astronomical community with a number of real time\nservices. The Early Warning System (EWS) contains information on two thousand\ngravitational microlensing events being discovered in real time annually, the\nOGLE Transient Detection System (OTDS) delivers over 200 supernovae a year. We\nalso provide the real time photometry of unpredictable variables such as\noptical counterparts to the X-ray sources and R CrB stars.\n  Hundreds of thousands new variable stars have already been discovered and\nclassified by the OGLE survey. The number of new detections will be at least\ndoubled during the current OGLE-IV phase. The survey was designed and optimized\nprimarily to conduct the second generation microlensing survey for exoplanets.\nIt has already contributed significantly to the increase of the discovery rate\nof microlensing exoplanets and free-floating planets. \n\n"}
{"id": "1505.00502", "contents": "Title: Comparison of Strong Gravitational Lens Model Software III. Direct and\n  indirect semi-independent lens model comparisons of COSMOS J095930+023427,\n  SDSS J1320+1644, SDSSJ1430+4105 and J1000+0021 Abstract: Analysis of strong gravitational lensing data is important in this era of\nprecision cosmology. The objective of the present study is to directly compare\nthe analysis of strong gravitational lens systems using different lens model\nsoftware and similarly parameterized models to understand the differences and\nlimitations of the resulting models. The software lens model translation tool,\nHydraLens, was used to generate multiple models for four strong lens systems\nincluding COSMOS J095930+023427, SDSS J1320+1644, SDSSJ1430+4105 and\nJ1000+0021. All four lens systems were modeled with PixeLens, Lenstool, glafic,\nand Lensmodel. The input data and parameterization of each lens model was\nsimilar for the four model programs used to highlight differences in the output\nresults. The calculation of the Einstein radius and enclosed mass for each lens\nmodel was comparable. The results were more dissimilar if the masses of more\nthan one lens potential were free-parameters. The image tracing algorithms of\nthe software are different, resulting in different output image positions and\ndifferences in time delay and magnification calculations, as well as\nellipticity and position angle of the resulting lens model. In a comparison of\ndifferent software versions using identical model input files, results differed\nsignificantly when using two versions of the same software. These results\nfurther support the need for future lensing studies to include multiple lens\nmodels, use of open software, availability of lens model files use in studies,\nand computer challenges to develop new approaches. Future studies need a\nstandard nomenclature and specification of the software used to allow improved\ninterpretation, reproducibility and transparency of results. \n\n"}
{"id": "1505.01285", "contents": "Title: Equivalence principle in scalar-tensor gravity Abstract: We present a direct confirmation of the validity of the equivalence principle\nfor unstructured test bodies in scalar tensor gravity. Our analysis is\ncomplementary to previous approaches and valid for a large class of\nscalar-tensor theories of gravitation. A covariant approach is used to derive\nthe equations of motion in a systematic way and allows for the experimental\ntest of scalar-tensor theories by means of extended test bodies. \n\n"}
{"id": "1505.01883", "contents": "Title: A general reconstruction of the recent expansion history of the universe Abstract: Distance measurements are currently the most powerful tool to study the\nexpansion history of the universe without specifying its matter content nor any\ntheory of gravitation. Assuming only an isotropic, homogeneous and flat\nuniverse, in this work we introduce a model-independent method to reconstruct\ndirectly the deceleration function via a piecewise function. Including a\npenalty factor, we are able to vary continuously the complexity of the\ndeceleration function from a linear case to an arbitrary $(n+1)$-knots spline\ninterpolation. We carry out a Monte Carlo (MC) analysis to determine the best\npenalty factor, evaluating the bias-variance trade-off, given the uncertainties\nof the SDSS-II and SNLS supernova combined sample (JLA), compilations of baryon\nacoustic oscillation (BAO) and $H(z)$ data. The bias-variance analysis is done\nfor three fiducial models with different features in the deceleration curve.\nFor each fiducial model, we test different reconstructions using, in each case,\nmore than $10^4$ catalogs in a total of about $5\\times 10^5$. This\ninvestigation proved to be essential in determining the best reconstruction to\nstudy these data. We show that, evaluating a single fiducial model, the\nconclusions about the bias-variance ratio are misleading. We determine the\nreconstruction method in which the bias represents at most $10\\%$ of the total\nuncertainty. Finally, we apply the Ensemble Sampler Markov Chain Monte Carlo\n(ESMCMC) method to explore the posterior of the deceleration function up to\nredshift $1.3$ (using only JLA) and $2.3$ (JLA+BAO+$H(z)$). We obtain that the\nstandard cosmological model agrees within $3\\sigma$ level with the\nreconstructed results in the whole studied redshift intervals. Since our method\nis calibrated to minimize the bias, the error bars of the reconstructed\nfunctions are a good approximation for the total uncertainty. \n\n"}
{"id": "1505.02443", "contents": "Title: Status of ArDM-1t: First observations from operation with a full\n  ton-scale liquid argon target Abstract: ArDM-1t is the first operating ton-scale liquid argon detector for direct\nsearch of Dark Matter particles. Developed at CERN as Recognized Experiment\nRE18, the experiment has been approved in 2010 to be installed in the Spanish\nunderground site LSC (Laboratorio Subterraneo de Canfranc). Under the label of\nLSC EXP-08-2010 the ArDM detector underwent an intensive period of technical\ncompletion and safety approval until the recent filling of the target vessel\nwith almost 2 ton of liquid argon. This report describes the experimental\nachievements during commissioning of ArDM and the transition into a stage of\nfirst physics data taking in single phase operational mode. We present\npreliminary observations from this run. A first indication for the background\ndiscrimination power of LAr detectors at the ton-scale is shown. We present an\noutlook for completing the detector with the electric drift field and upgrade\nof the scintillation light readout system with novel detector modules based on\nSiPMs in order to improve the light yield. \n\n"}
{"id": "1505.04494", "contents": "Title: Simulating Astrophysical Magnetic Fields with Smoothed Particle\n  Magnetohydrodynamics Abstract: Numerical methods to improve the treatment of magnetic fields in smoothed\nfield magnetohydrodynamics (SPMHD) are developed and tested. Chapter 2 is a\nreview of SPMHD. In Chapter 3, a mixed hyperbolic/parabolic scheme is developed\nwhich cleans divergence error from the magnetic field. Average divergence error\nis an order of magnitude lower for all test cases considered, and allows for\nthe stable simulation of the gravitational collapse of magnetised molecular\ncloud cores. The effectiveness of the cleaning may be improved by explicitly\nincreasing the hyperbolic wave speed or by cycling the cleaning equations\nbetween timesteps. In the latter, it is possible to achieve DivB=0. Chapter 4\ndevelops a switch to reduce dissipation of the magnetic field from artificial\nresistivity. Compared to the existing switch in the literature, this leads to\nsharper shock profiles in shocktube tests, lower overall dissipation of\nmagnetic energy, and importantly, is able to capture magnetic shocks in the\nhighly super-Alfvenic regime. Chapter 5 compares these numerical methods\nagainst grid-based MHD methods (using the Flash code) in simulations of the\nsmall-scale dynamo amplification of a magnetic field in driven, isothermal,\nsupersonic turbulence. Both codes exponentially amplify the magnetic energy at\na constant rate, though SPMHD shows a resolution dependence that arises from\nthe scaling of the numerical dissipation terms. The time-averaged saturated\nmagnetic spectra have similar shape, and both codes have PDFs of magnetic field\nstrength that are log-normal, which become lopsided as the magnetic field\nsaturates. We conclude that SPMHD is able to reliably simulate the small-scale\ndynamo amplification of magnetic fields. Chapter 6 concludes the thesis and\npresents some preliminary work demonstrating that SPMHD can activate the\nmagneto-rotational instability in 2D shearing box tests. \n\n"}
{"id": "1505.05489", "contents": "Title: A Sparse Gaussian Process Framework for Photometric Redshift Estimation Abstract: Accurate photometric redshifts are a lynchpin for many future experiments to\npin down the cosmological model and for studies of galaxy evolution. In this\nstudy, a novel sparse regression framework for photometric redshift estimation\nis presented. Simulated and real data from SDSS DR12 were used to train and\ntest the proposed models. We show that approaches which include careful data\npreparation and model design offer a significant improvement in comparison with\nseveral competing machine learning algorithms. Standard implementations of most\nregression algorithms have as the objective the minimization of the sum of\nsquared errors. For redshift inference, however, this induces a bias in the\nposterior mean of the output distribution, which can be problematic. In this\npaper we directly target minimizing $\\Delta z = (z_\\textrm{s} -\nz_\\textrm{p})/(1+z_\\textrm{s})$ and address the bias problem via a\ndistribution-based weighting scheme, incorporated as part of the optimization\nobjective. The results are compared with other machine learning algorithms in\nthe field such as Artificial Neural Networks (ANN), Gaussian Processes (GPs)\nand sparse GPs. The proposed framework reaches a mean absolute $\\Delta z =\n0.0026(1+z_\\textrm{s})$, over the redshift range of $0 \\le z_\\textrm{s} \\le 2$\non the simulated data, and $\\Delta z = 0.0178(1+z_\\textrm{s})$ over the entire\nredshift range on the SDSS DR12 survey, outperforming the standard ANNz used in\nthe literature. We also investigate how the relative size of the training set\naffects the photometric redshift accuracy. We find that a training set of\n\\textgreater 30 per cent of total sample size, provides little additional\nconstraint on the photometric redshifts, and note that our GP formalism\nstrongly outperforms ANNz in the sparse data regime for the simulated data set. \n\n"}
{"id": "1505.06741", "contents": "Title: A principal possibility for computer investigation of evolution of\n  dynamical systems with independent on time accuracy Abstract: Extensive N-body simulations are among the key means for the study of\nnumerous astrophysical and cosmological phenomena, so various schemes are\ndeveloped for possibly higher accuracy computations. We demonstrate the\nprincipal possibility for revealing the evolution of a perturbed Hamiltonian\nsystem with an accuracy independent on time. The method is based on the Laplace\ntransform and the derivation and analytical solution of an evolution equation\nin the phase space for the resolvent and using computer algebra. \n\n"}
{"id": "1505.08022", "contents": "Title: Planck 2015 results. V. LFI calibration Abstract: We present a description of the pipeline used to calibrate the Planck Low\nFrequency Instrument (LFI) timelines into thermodynamic temperatures for the\nPlanck 2015 data release, covering four years of uninterrupted operations. As\nin the 2013 data release, our calibrator is provided by the spin-synchronous\nmodulation of the cosmic microwave background dipole, but we now use the\norbital component, rather than adopting the Wilkinson Microwave Anisotropy\nProbe (WMAP) solar dipole. This allows our 2015 LFI analysis to provide an\nindependent Solar dipole estimate, which is in excellent agreement with that of\nHFI and within $1\\sigma$ (0.3% in amplitude) of the WMAP value. This 0.3% shift\nin the peak-to-peak dipole temperature from WMAP and a global overhaul of the\niterative calibration code increases the overall level of the LFI maps by 0.45%\n(30 GHz), 0.64% (44 GHz), and 0.82% (70 GHz) in temperature with respect to the\n2013 Planck data release, thus reducing the discrepancy with the power spectrum\nmeasured by WMAP. We estimate that the LFI calibration uncertainty is now at\nthe level of 0.20% for the 70 GHz map, 0.26% for the 44 GHz map, and 0.35% for\nthe 30 GHz map. We provide a detailed description of the impact of all the\nchanges implemented in the calibration since the previous data release. \n\n"}
{"id": "1506.01611", "contents": "Title: Star Formation & Stellar Evolution: Future Surveys & Instrumentation Abstract: The next generation of multi-object spectrographs (MOS) will deliver\ncomprehensive surveys of the Galaxy, Magellanic Clouds and nearby dwarfs. These\nwill provide us with the vast samples, spanning the full extent of the\nHertzsprung-Russell diagram, that are needed to explore the chemistry, history\nand dynamics of their host systems. Further ahead, the Extremely Large\nTelescopes (ELTs) will have sufficient sensitivity and angular resolution to\nextend stellar spectroscopy well beyond the Local Group, opening-up studies of\nthe chemical evolution of galaxies across a broad range of galaxy types and\nenvironments. In this contribution I briefly reflect on current and future\nstudies of stellar populations, and introduce plans for the MOSAIC instrument\nfor the European ELT. \n\n"}
{"id": "1506.02892", "contents": "Title: Absolute Calibration of the Radio Astronomy Flux Density Scale at 22 to\n  43 GHz Using Planck Abstract: The Planck mission detected thousands of extragalactic radio sources at\nfrequencies from 28 to 857 GHz. Planck's calibration is absolute (in the sense\nthat it is based on the satellite's annual motion around the Sun and the\ntemperature of the cosmic microwave background), and its beams are well\ncharacterized at sub-percent levels. Thus Planck's flux density measurements of\ncompact sources are absolute in the same sense. We have made coordinated VLA\nand ATCA observations of 65 strong, unresolved Planck sources in order to\ntransfer Planck's calibration to ground-based instruments at 22, 28, and 43\nGHz. The results are compared to microwave flux density scales currently based\non planetary observations. Despite the scatter introduced by the variability of\nmany of the sources, the flux density scales are determined to 1-2% accuracy.\nAt 28 GHz, the flux density scale used by the VLA runs 3.6% +- 1.0% below\nPlanck values; at 43 GHz, the discrepancy increases to 6.2% +- 1.4% for both\nATCA and the VLA. \n\n"}
{"id": "1506.04157", "contents": "Title: The CALIFA survey across the Hubble sequence: Spatially resolved stellar\n  population properties in galaxies Abstract: This paper characterizes the radial structure of stellar population\nproperties of galaxies in the nearby universe, based on 300 galaxies from the\nCALIFA survey. The sample covers a wide range of Hubble types, and galaxy\nstellar mass. We apply the spectral synthesis techniques to recover the stellar\nmass surface density, stellar extinction, light and mass-weighted ages, and\nmass-weighted metallicity, for each spatial resolution element in our target\ngalaxies. To study mean trends with overall galaxy properties, the individual\nradial profiles are stacked in seven bins of galaxy morphology. We confirm that\nmore massive galaxies are more compact, older, more metal rich, and less\nreddened by dust. Additionally, we find that these trends are preserved\nspatially with the radial distance to the nucleus. Deviations from these\nrelations appear correlated with Hubble type: earlier types are more compact,\nolder, and more metal rich for a given mass, which evidences that quenching is\nrelated to morphology, but not driven by mass. Negative gradients of ages are\nconsistent with an inside-out growth of galaxies, with the largest ages\ngradients in Sb-Sbc galaxies. Further, the mean stellar ages of disks and\nbulges are correlated, with disks covering a wider range of ages, and late type\nspirals hosting younger disks. The gradients in stellar mass surface density\ndepend mostly on stellar mass, in the sense that more massive galaxies are more\ncentrally concentrated. There is a secondary correlation in the sense that at\nthe same mass early type galaxies have steeper gradients. We find mildly\nnegative metallicity gradients, shallower than predicted from models of galaxy\nevolution in isolation. The largest gradients occur in Sb galaxies. Overall we\nconclude that quenching processes act in manners that are independent of mass,\nwhile metallicity and galaxy structure are influenced by mass-dependent\nprocesses. \n\n"}
{"id": "1506.04273", "contents": "Title: Optimized Large-Scale CMB Likelihood And Quadratic Maximum Likelihood\n  Power Spectrum Estimation Abstract: We revisit the problem of exact CMB likelihood and power spectrum estimation\nwith the goal of minimizing computational cost through linear compression. This\nidea was originally proposed for CMB purposes by Tegmark et al.\\ (1997), and\nhere we develop it into a fully working computational framework for large-scale\npolarization analysis, adopting \\WMAP\\ as a worked example. We compare five\ndifferent linear bases (pixel space, harmonic space, noise covariance\neigenvectors, signal-to-noise covariance eigenvectors and signal-plus-noise\ncovariance eigenvectors) in terms of compression efficiency, and find that the\ncomputationally most efficient basis is the signal-to-noise eigenvector basis,\nwhich is closely related to the Karhunen-Loeve and Principal Component\ntransforms, in agreement with previous suggestions. For this basis, the\ninformation in 6836 unmasked \\WMAP\\ sky map pixels can be compressed into a\nsmaller set of 3102 modes, with a maximum error increase of any single\nmultipole of 3.8\\% at $\\ell\\le32$, and a maximum shift in the mean values of a\njoint distribution of an amplitude--tilt model of 0.006$\\sigma$. This\ncompression reduces the computational cost of a single likelihood evaluation by\na factor of 5, from 38 to 7.5 CPU seconds, and it also results in a more robust\nlikelihood by implicitly regularizing nearly degenerate modes. Finally, we use\nthe same compression framework to formulate a numerically stable and\ncomputationally efficient variation of the Quadratic Maximum Likelihood\nimplementation that requires less than 3 GB of memory and 2 CPU minutes per\niteration for $\\ell \\le 32$, rendering low-$\\ell$ QML CMB power spectrum\nanalysis fully tractable on a standard laptop. \n\n"}
{"id": "1506.04790", "contents": "Title: Improved Spectrophotometric Calibration of the SDSS-III BOSS Quasar\n  Sample Abstract: We present a model for spectrophotometric calibration errors in observations\nof quasars from the third generation of the Sloan Digital Sky Survey (SDSS-III)\nBaryon Oscillation Spectroscopic Survey (BOSS) and describe the correction\nprocedure we have developed and applied to this sample. Calibration errors are\nprimarily due to atmospheric differential refraction and guiding offsets during\neach exposure. The corrections potentially reduce the systematics for any\nstudies of BOSS quasars, including the measurement of baryon acoustic\noscillations using the Lyman-$\\alpha$ forest. Our model suggests that, on\naverage, the observed quasar flux in BOSS is overestimated by $\\sim 19\\%$ at\n3600 \\AA\\ and underestimated by $\\sim 24\\%$ at 10,000 \\AA. Our corrections for\nthe entire BOSS quasar sample are publicly available. \n\n"}
{"id": "1506.04827", "contents": "Title: Automated reduction of submillimetre single-dish heterodyne data from\n  the James Clerk Maxwell Telescope using ORAC-DR Abstract: With the advent of modern multi-detector heterodyne instruments that can\nresult in observations generating thousands of spectra per minute it is no\nlonger feasible to reduce these data as individual spectra. We describe the\nautomated data reduction procedure used to generate baselined data cubes from\nheterodyne data obtained at the James Clerk Maxwell Telescope. The system can\nautomatically detect baseline regions in spectra and automatically determine\nregridding parameters, all without input from a user. Additionally it can\ndetect and remove spectra suffering from transient interference effects or\nanomalous baselines. The pipeline is written as a set of recipes using the\nORAC-DR pipeline environment with the algorithmic code using Starlink software\npackages and infrastructure. The algorithms presented here can be applied to\nother heterodyne array instruments and have been applied to data from\nhistorical JCMT heterodyne instrumentation. \n\n"}
{"id": "1506.08748", "contents": "Title: Measurements of wavelength-dependent double photoelectron emission from\n  single photons in VUV-sensitive photomultiplier tubes Abstract: Measurements of double photoelectron emission (DPE) probabilities as a\nfunction of wavelength are reported for Hamamatsu R8778, R8520, and R11410\nVUV-sensitive photomultiplier tubes (PMTs). In DPE, a single photon strikes the\nPMT photocathode and produces two photoelectrons instead of a single one. It\nwas found that the fraction of detected photons that result in DPE emission is\na function of the incident photon wavelength, and manifests itself below\n$\\sim$250 nm. For the xenon scintillation wavelength of 175 nm, a DPE\nprobability of 18--24\\% was measured depending on the tube and measurement\nmethod. This wavelength-dependent single photon response has implications for\nthe energy calibration and photon counting of current and future liquid xenon\ndetectors such as LUX, LZ, XENON100/1T, Panda-X and XMASS. \n\n"}
{"id": "1507.00490", "contents": "Title: ANNz2 - photometric redshift and probability distribution function\n  estimation using machine learning Abstract: We present ANNz2, a new implementation of the public software for photometric\nredshift (photo-z) estimation of Collister and Lahav (2004), which now includes\ngeneration of full probability distribution functions (PDFs). ANNz2 utilizes\nmultiple machine learning methods, such as artificial neural networks and\nboosted decision/regression trees. The objective of the algorithm is to\noptimize the performance of the photo-z estimation, to properly derive the\nassociated uncertainties, and to produce both single-value solutions and PDFs.\nIn addition, estimators are made available, which mitigate possible problems of\nnon-representative or incomplete spectroscopic training samples. ANNz2 has\nalready been used as part of the first weak lensing analysis of the Dark Energy\nSurvey, and is included in the experiment's first public data release. Here we\nillustrate the functionality of the code using data from the tenth data release\nof the Sloan Digital Sky Survey and the Baryon Oscillation Spectroscopic\nSurvey. The code is available for download at\nhttps://github.com/IftachSadeh/ANNZ . \n\n"}
{"id": "1507.00742", "contents": "Title: The first and second data releases of the Kilo-Degree Survey Abstract: The Kilo-Degree Survey (KiDS) is an optical wide-field imaging survey carried\nout with the VLT Survey Telescope and the OmegaCAM camera. KiDS will image 1500\nsquare degrees in four filters (ugri), and together with its near-infrared\ncounterpart VIKING will produce deep photometry in nine bands. Designed for\nweak lensing shape and photometric redshift measurements, the core science\ndriver of the survey is mapping the large-scale matter distribution in the\nUniverse back to a redshift of ~0.5. Secondary science cases are manifold,\ncovering topics such as galaxy evolution, Milky Way structure, and the\ndetection of high-redshift clusters and quasars.\n  KiDS is an ESO Public Survey and dedicated to serving the astronomical\ncommunity with high-quality data products derived from the survey data, as well\nas with calibration data. Public data releases will be made on a yearly basis,\nthe first two of which are presented here. For a total of 148 survey tiles\n(~160 sq.deg.) astrometrically and photometrically calibrated, coadded ugri\nimages have been released, accompanied by weight maps, masks, source lists, and\na multi-band source catalog.\n  A dedicated pipeline and data management system based on the Astro-WISE\nsoftware system, combined with newly developed masking and source\nclassification software, is used for the data production of the data products\ndescribed here. The achieved data quality and early science projects based on\nthe data products in the first two data releases are reviewed in order to\nvalidate the survey data. Early scientific results include the detection of\nnine high-z QSOs, fifteen candidate strong gravitational lenses, high-quality\nphotometric redshifts and galaxy structural parameters for hundreds of\nthousands of galaxies. (Abridged) \n\n"}
{"id": "1507.00754", "contents": "Title: Machine Learning based photometric redshifts for the KiDS ESO DR2\n  galaxies Abstract: We estimated photometric redshifts (zphot) for more than 1.1 million galaxies\nof the ESO Public Kilo-Degree Survey (KiDS) Data Release 2. KiDS is an optical\nwide-field imaging survey carried out with the VLT Survey Telescope (VST) and\nthe OmegaCAM camera, which aims at tackling open questions in cosmology and\ngalaxy evolution, such as the origin of dark energy and the channel of galaxy\nmass growth. We present a catalogue of photometric redshifts obtained using the\nMulti Layer Perceptron with Quasi Newton Algorithm (MLPQNA) model, provided\nwithin the framework of the DAta Mining and Exploration Web Application\nREsource (DAMEWARE). These photometric redshifts are based on a spectroscopic\nknowledge base which was obtained by merging spectroscopic datasets from GAMA\n(Galaxy And Mass Assembly) data release 2 and SDSS-III data release 9. The\noverall 1 sigma uncertainty on Delta z = (zspec - zphot) / (1+ zspec) is ~\n0.03, with a very small average bias of ~ 0.001, a NMAD of ~ 0.02 and a\nfraction of catastrophic outliers (| Delta z | > 0.15) of ~0.4%. \n\n"}
{"id": "1507.01589", "contents": "Title: Teaching a machine to see: unsupervised image segmentation and\n  categorisation using growing neural gas and hierarchical clustering Abstract: We present a novel unsupervised learning approach to automatically segment\nand label images in astronomical surveys. Automation of this procedure will be\nessential as next-generation surveys enter the petabyte scale: data volumes\nwill exceed the capability of even large crowd-sourced analyses. We demonstrate\nhow a growing neural gas (GNG) can be used to encode the feature space of\nimaging data. When coupled with a technique called hierarchical clustering,\nimaging data can be automatically segmented and labelled by organising nodes in\nthe GNG. The key distinction of unsupervised learning is that these labels need\nnot be known prior to training, rather they are determined by the algorithm\nitself. Importantly, after training a network can be be presented with images\nit has never 'seen' before and provide consistent categorisation of features.\nAs a proof-of-concept we demonstrate application on data from the Hubble Space\nTelescope Frontier Fields: images of clusters of galaxies containing a mixture\nof galaxy types that would easily be recognised and classified by a human\ninspector. By training the algorithm using one field (Abell 2744) and applying\nthe result to another (MACS0416.1-2403), we show how the algorithm can cleanly\nseparate image features that a human would associate with early and late type\ngalaxies. We suggest that the algorithm has potential as a tool in the\nautomatic analysis and data mining of next-generation imaging and spectral\nsurveys, and could also find application beyond astronomy. \n\n"}
{"id": "1507.02256", "contents": "Title: The Effective Field Theory of Large Scale Structure at Two Loops: the\n  apparent scale dependence of the speed of sound Abstract: We study the Effective Field Theory of Large Scale Structure for cosmic\ndensity and momentum fields. We show that the finite part of the two-loop\ncalculation and its counterterms introduce an apparent scale dependence for the\nleading order parameter $c_\\text{s}^2$ of the EFT starting at k=0.1 h/Mpc.\nThese terms limit the range over which one can trust the one-loop EFT\ncalculation at the 1 % level to k<0.1 h/Mpc at redshift z=0. We construct a\nwell motivated one parameter ansatz to fix the relative size of the one- and\ntwo-loop counterterms using their high-k sensitivity. Although this one\nparameter model is a very restrictive choice for the counterterms, it explains\nthe apparent scale dependence of $c_\\text{s}^2$ seen in simulations. It is also\nable to capture the scale dependence of the density power spectrum up to\nk$\\approx$ 0.3 h/Mpc at the 1 % level at redshift $z=0$. Considering a simple\nscheme for the resummation of large scale motions, we find that the two loop\ncalculation reduces the need for this IR-resummation at k<0.2 h/Mpc. Finally,\nwe extend our calculation to momentum statistics and show that the same one\nparameter model can also describe density-momentum and momentum-momentum\nstatistics. \n\n"}
{"id": "1507.02313", "contents": "Title: Feature Representation in Convolutional Neural Networks Abstract: Convolutional Neural Networks (CNNs) are powerful models that achieve\nimpressive results for image classification. In addition, pre-trained CNNs are\nalso useful for other computer vision tasks as generic feature extractors. This\npaper aims to gain insight into the feature aspect of CNN and demonstrate other\nuses of CNN features. Our results show that CNN feature maps can be used with\nRandom Forests and SVM to yield classification results that outperforms the\noriginal CNN. A CNN that is less than optimal (e.g. not fully trained or\noverfitting) can also extract features for Random Forest/SVM that yield\ncompetitive classification accuracy. In contrast to the literature which uses\nthe top-layer activations as feature representation of images for other tasks,\nusing lower-layer features can yield better results for classification. \n\n"}
{"id": "1507.04365", "contents": "Title: What is the optimal way to measure the galaxy power spectrum? Abstract: Measurements of the galaxy power spectrum contain a wealth of information\nabout the Universe. Its optimal extraction is vital if we are to truly\nunderstand the micro-physical nature of dark matter and dark energy. In Smith &\nMarian (2015) we generalized the power spectrum methodology of Feldman et al.\n(1994) to take into account the key tenets of galaxy formation: galaxies form\nand reside exclusively in dark matter haloes; a given dark matter halo may host\ngalaxies of various luminosities; galaxies inherit the large-scale bias\nassociated with their host halo. In this paradigm we derived the optimal\nweighting and reconstruction scheme for maximizing the signal-to-noise on a\ngiven band power estimate. For a future all-sky flux-limited galaxy redshift\nsurvey of depth b_J ~22, we now demonstrate that the optimal weighting scheme\ndoes indeed provide improved S/N at the level of ~20% when compared to Feldman\net al. (1994) and ~60% relative to Percival et al. (2003), for scales of order\nk~0.5 Mpc/h. Using a Fisher matrix approach, we show that the cosmological\ninformation yield is also increased relative to these alternate methods --\nespecially the primordial power spectrum amplitude and dark energy equation of\nstate. \n\n"}
{"id": "1507.04622", "contents": "Title: A supervised machine learning estimator for the non-linear matter power\n  spectrum - SEMPS Abstract: In this article, we argue that models based on machine learning (ML) can be\nvery effective in estimating the non-linear matter power spectrum ($P(k)$). We\nemploy the prediction ability of the supervised ML algorithms to build an\nestimator for the $P(k)$. The estimator is trained on a set of cosmological\nmodels, and redshifts for which the $P(k)$ is known, and it learns to predict\n$P(k)$ for any other set. We review three ML algorithms -- Random Forest,\nGradient Boosting Machines, and K-Nearest Neighbours -- and investigate their\nprime parameters to optimize the prediction accuracy of the estimator. We also\ncompute an optimal size of the training set, which is realistic enough, and\nstill yields high accuracy. We find that, employing the optimal values of the\ninternal parameters, a set of $50-100$ cosmological models is enough to train\nthe estimator that can predict the $P(k)$ for a wide range of cosmological\nmodels, and redshifts. Using this configuration, we build a blackbox --\nSupervised Estimator for Matter Power Spectrum (SEMPS) -- that computes the\n$P(k)$ to 5-10$\\%$ accuracy up to $k\\sim 10 h^{-1}{\\rm Mpc}$ with respect to\nthe reference model (cosmic emulator). We also compare the estimations of SEMPS\nto that of the Halofit, and find that for the $k$-range where the cosmic\nvariance is low, SEMPS estimates are better than that of the Halofit. The\npredictions of the SEMPS are instantaneous in the sense that it can evaluate up\nto 500 $P(k)$ in less than one second, which makes it ideal for many\napplications like visualisations, weak lensing, emulations, likelihood analysis\netc.. As a supplement to this article, we provide a publicly available software\npackage. \n\n"}
{"id": "1507.07296", "contents": "Title: Accelerator measurements of magnetically-induced radio emission from\n  particle cascades with applications to cosmic-ray air showers Abstract: For fifty years, cosmic-ray air showers have been detected by their radio\nemission. We present the first laboratory measurements that validate\nelectrodynamics simulations used in air shower modeling. An experiment at SLAC\nprovides a beam test of radio-frequency (RF) radiation from charged particle\ncascades in the presence of a magnetic field, a model system of a cosmic-ray\nair shower. This experiment provides a suite of controlled laboratory\nmeasurements to compare to particle-level simulations of RF emission, which are\nrelied upon in ultra-high-energy cosmic-ray air shower detection. We compare\nsimulations to data for intensity, linearity with magnetic field, angular\ndistribution, polarization, and spectral content. In particular, we confirm\nmodern predictions that the magnetically induced emission in a dielectric forms\na cone that peaks at the Cherenkov angle and show that the simulations\nreproduce the data within systematic uncertainties. \n\n"}
{"id": "1507.07747", "contents": "Title: Exclusion of Leptophilic Dark Matter Models using XENON100 Electronic\n  Recoil Data Abstract: Laboratory experiments searching for galactic dark matter particles\nscattering off nuclei have so far not been able to establish a discovery. We\nuse data from the XENON100 experiment to search for dark matter interacting\nwith electrons. With no evidence for a signal above the low background of our\nexperiment, we exclude a variety of representative dark matter models that\nwould induce electronic recoils. For axial-vector couplings to electrons, we\nexclude cross-sections above 6x10^(-35) cm^2 for particle masses of m_chi = 2\nGeV/c^2. Independent of the dark matter halo, we exclude leptophilic models as\nexplanation for the long-standing DAMA/LIBRA signal, such as couplings to\nelectrons through axial-vector interactions at a 4.4 sigma confidence level,\nmirror dark matter at 3.6 sigma, and luminous dark matter at 4.6 sigma. \n\n"}
{"id": "1507.08786", "contents": "Title: Filaments in the Lupus molecular clouds Abstract: We have studied the filaments extracted from the column density maps of the\nnearby Lupus 1, 3, and 4 molecular clouds, derived from photometric maps\nobserved with the Herschel satellite. Filaments in the Lupus clouds have quite\nlow column densities, with a median value of $\\sim$1.5$\\times$10$^{21}$\ncm$^{-2}$ and most have masses per unit length lower than the maximum critical\nvalue for radial gravitational collapse. Indeed, no evidence of filament\ncontraction has been seen in the gas kinematics. We find that some filaments,\nthat on average are thermally subcritical, contain dense cores that may\neventually form stars. This is an indication that in the low column density\nregime, the critical condition for the formation of stars may be reached only\nlocally and this condition is not a global property of the filament. Finally,\nin Lupus we find multiple observational evidences of the key role that the\nmagnetic field plays in forming filaments, and determining their confinement\nand dynamical evolution. \n\n"}
{"id": "1508.00662", "contents": "Title: Trans-Dimensional Bayesian Inference for Gravitational Lens\n  Substructures Abstract: We introduce a Bayesian solution to the problem of inferring the density\nprofile of strong gravitational lenses when the lens galaxy may contain\nmultiple dark or faint substructures. The source and lens models are based on a\nsuperposition of an unknown number of non-negative basis functions (or \"blobs\")\nwhose form was chosen with speed as a primary criterion. The prior distribution\nfor the blobs' properties is specified hierarchically, so the mass function of\nsubstructures is a natural output of the method. We use reversible jump Markov\nChain Monte Carlo (MCMC) within Diffusive Nested Sampling (DNS) to sample the\nposterior distribution and evaluate the marginal likelihood of the model,\nincluding the summation over the unknown number of blobs in the source and the\nlens. We demonstrate the method on two simulated data sets: one with a single\nsubstructure, and one with ten. We also apply the method to the g-band image of\nthe \"Cosmic Horseshoe\" system, and find evidence for more than zero\nsubstructures. However, these have large spatial extent and probably only point\nto misspecifications in the model (such as the shape of the smooth lens\ncomponent or the point spread function), which are difficult to guard against\nin full generality. \n\n"}
{"id": "1508.02484", "contents": "Title: Exploring Photometric Redshifts as an Optimization Problem: An Ensemble\n  MCMC and Simulated Annealing-Driven Template-Fitting Approach Abstract: Using a grid of $\\sim 2$ million elements ($\\Delta z = 0.005$) adapted from\nCOSMOS photometric redshift (photo-z) searches, we investigate the general\nproperties of template-based photo-z likelihood surfaces. We find these\nsurfaces are filled with numerous local minima and large degeneracies that\ngenerally confound rapid but \"greedy\" optimization schemes, even with\nadditional stochastic sampling methods. In order to robustly and efficiently\nexplore these surfaces, we develop BAD-Z [Brisk Annealing-Driven Redshifts\n(Z)], which combines ensemble Markov Chain Monte Carlo (MCMC) sampling with\nsimulated annealing to sample arbitrarily large, pre-generated grids in\napproximately constant time. Using a mock catalog of 384,662 objects, we show\nBAD-Z samples $\\sim 40$ times more efficiently compared to a brute-force\ncounterpart while maintaining similar levels of accuracy. Our results represent\nfirst steps toward designing template-fitting photo-z approaches limited mainly\nby memory constraints rather than computation time. \n\n"}
{"id": "1508.02950", "contents": "Title: XMM-Newton Large Program on SN1006 - I: Methods and Initial Results of\n  Spatially-Resolved Spectroscopy Abstract: Based on our newly developed methods and the XMM-Newton large program of\nSN1006, we extract and analyze the spectra from 3596 tessellated regions of\nthis SNR each with 0.3-8 keV counts $>10^4$. For the first time, we map out\nmultiple physical parameters, such as the temperature ($kT$), electron density\n($n_e$), ionization parameter ($n_et$), ionization age ($t_{ion}$), metal\nabundances, as well as the radio-to-X-ray slope ($\\alpha$) and cutoff frequency\n($\\nu_{cutoff}$) of the synchrotron emission. We construct probability\ndistribution functions of $kT$ and $n_et$, and model them with several\nGaussians, in order to characterize the average thermal and ionization states\nof such an extended source. We construct equivalent width (EW) maps based on\ncontinuum interpolation with the spectral model of each regions. We then\ncompare the EW maps of OVII, OVIII, OVII K$\\delta-\\zeta$, Ne, Mg, SiXIII,\nSiXIV, and S lines constructed with this method to those constructed with\nlinear interpolation. We further extract spectra from larger regions to confirm\nthe features revealed by parameter and EW maps, which are often not directly\ndetectable on X-ray intensity images. For example, O abundance is consistent\nwith solar across the SNR, except for a low-abundance hole in the center. This\n\"O Hole\" has enhanced OVII K$\\delta-\\zeta$ and Fe emissions, indicating\nrecently reverse shocked ejecta, but also has the highest $n_et$, indicating\nforward shocked ISM. Therefore, a multi-temperature model is needed to\ndecompose these components. The asymmetric metal distributions suggest there is\neither an asymmetric explosion of the SN or an asymmetric distribution of the\nISM. \n\n"}
{"id": "1508.03100", "contents": "Title: Two Type Ia Supernovae at Redshift ~2 : Improved Classification and\n  Redshift Determination with Medium-band Infrared Imaging Abstract: We present two supernovae (SNe) discovered with the Hubble Space Telescope\n(HST) in the Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey\n(CANDELS), an HST multi-cycle treasury program. We classify both objects as\nType Ia SNe and find redshifts of z = 1.80+-0.02 and 2.26 +0.02 -0.10, the\nlatter of which is the highest redshift Type Ia SN yet seen. Using light curve\nfitting we determine luminosity distances and find that both objects are\nconsistent with a standard Lambda-CDM cosmological model. These SNe were\nobserved using the HST Wide Field Camera 3 infrared detector (WFC3-IR), with\nimaging in both wide- and medium-band filters. We demonstrate that the\nclassification and redshift estimates are significantly improved by the\ninclusion of single-epoch medium-band observations. This medium-band imaging\napproximates a very low resolution spectrum (lambda/delta lambda ~ 100) which\ncan isolate broad spectral absorption features that differentiate Type Ia SNe\nfrom their most common core collapse cousins. This medium-band method is also\ninsensitive to dust extinction and (unlike grism spectroscopy) it is not\naffected by contamination from the SN host galaxy or other nearby sources. As\nsuch, it can provide a more efficient - though less precise - alternative to IR\nspectroscopy for high-z SNe. \n\n"}
{"id": "1508.03150", "contents": "Title: ATLAS - I. Third Release of 1.4 GHz Mosaics and Component Catalogues Abstract: We present the third data release from the Australia Telescope Large Area\nSurvey (ATLAS). These data combine the observations at 1.4 GHz before and after\nupgrades to the Australia Telescope Compact Array reaching a sensitivity of 14\nmicroJy/beam in 3.6 deg^2 over the Chandra Deep Field South (CDFS) and of 17\nmicroJy/beam in 2.7 deg^2 over the European Large Area ISO Survey South 1\n(ELAIS-S1). We used a variety of array configurations to maximise the uv\ncoverage resulting in a resolution of 16 by 7 arcsec in CDFS and of 12 by 8\narcsec in ELAIS-S1. After correcting for peak bias and bandwidth smearing, we\nfind a total of 3034 radio source components above 5 sigma in CDFS, of which\n514 (17 per cent) are considered to be extended. The number of components\ndetected above 5 sigma in ELAIS-S1 is 2084, of which 392 (19 per cent) are\nclassified as extended. The catalogues include reliable spectral indices (delta\nalpha < 0.2) between 1.40 and 1.71 GHz for ~350 of the brightest components. \n\n"}
{"id": "1508.05544", "contents": "Title: The $m$-$z$ relation for Type Ia supernovae: safety in numbers or safely\n  without worry? Abstract: The $m$-$z$ relation for Type Ia supernovae is compatible with the\ncosmological concordance model if one assumes that the Universe is homogeneous,\nat least with respect to light propagation. This could be due to the density\nalong each line of sight being equal to the overall cosmological density, or to\n`safety in numbers', with variation in the density along all lines of sight\naveraging out if the sample is large enough. Statistical correlations (or lack\nthereof) between redshifts, residuals (differences between the observed\ndistance moduli and those calculated from the best-fitting cosmological model),\nand observational uncertainties suggest that the former scenario is the better\ndescription, so that one can use the traditional formula for the luminosity\ndistance safely without worry. \n\n"}
{"id": "1508.05655", "contents": "Title: An accurate and practical method for inference of weak gravitational\n  lensing from galaxy images Abstract: We demonstrate highly accurate recovery of weak gravitational lensing shear\nusing an implementation of the Bayesian Fourier Domain (BFD) method proposed by\nBernstein & Armstrong (2014, BA14), extended to correct for selection biases.\nThe BFD formalism is rigorously correct for Nyquist-sampled,\nbackground-limited, uncrowded image of background galaxies. BFD does not assign\nshapes to galaxies, instead compressing the pixel data D into a vector of\nmoments M, such that we have an analytic expression for the probability P(M|g)\nof obtaining the observations with gravitational lensing distortion g along the\nline of sight. We implement an algorithm for conducting BFD's integrations over\nthe population of unlensed source galaxies which measures ~10\ngalaxies/second/core with good scaling properties. Initial tests of this code\non ~10^9 simulated lensed galaxy images recover the simulated shear to a\nfractional accuracy of m=0.0021+-0.0004, substantially more accurate than has\nbeen demonstrated previously for any generally applicable method. Deep sky\nexposures generate a sufficiently accurate approximation to the noiseless,\nunlensed galaxy population distribution assumed as input to BFD. Potential\nextensions of the method include simultaneous measurement of magnification and\nshear; multiple-exposure, multi-band observations; and joint inference of\nphotometric redshifts and lensing tomography. \n\n"}
{"id": "1509.00186", "contents": "Title: A Real-time Coherent Dedispersion Pipeline for the Giant Metrewave Radio\n  Telescope Abstract: A fully real-time coherent dedispersion system has been developed for the\npulsar back-end at the Giant Metrewave Radio Telescope (GMRT). The dedispersion\npipeline uses the single phased array voltage beam produced by the existing\nGMRT software back-end (GSB) to produce coherently dedispersed intensity output\nin real time, for the currently operational bandwidths of 16 MHz and 32 MHz.\nProvision has also been made to coherently dedisperse voltage beam data from\nobservations recorded on disk.\n  We discuss the design and implementation of the real-time coherent\ndedispersion system, describing the steps carried out to optimise the\nperformance of the pipeline. Presently functioning on an Intel Xeon X5550 CPU\nequipped with a NVIDIA Tesla C2075 GPU, the pipeline allows dispersion free,\nhigh time resolution data to be obtained in real-time. We illustrate the\nsignificant improvements over the existing incoherent dedispersion system at\nthe GMRT, and present some preliminary results obtained from studies of pulsars\nusing this system, demonstrating its potential as a useful tool for low\nfrequency pulsar observations.\n  We describe the salient features of our implementation, comparing it with\nother recently developed real-time coherent dedispersion systems. This\nimplementation of a real-time coherent dedispersion pipeline for a large, low\nfrequency array instrument like the GMRT, will enable long-term observing\nprograms using coherent dedispersion to be carried out routinely at the\nobservatory. We also outline the possible improvements for such a pipeline,\nincluding prospects for the upgraded GMRT which will have bandwidths about ten\ntimes larger than at present. \n\n"}
{"id": "1509.00870", "contents": "Title: Assessing Galaxy Limiting Magnitudes in Large Optical Surveys Abstract: Large scale structure measurements require accurate and precise knowledge of\nthe survey depth --- typically expressed in the form of a limiting magnitude\n--- as a function of position on the sky. To date, most surveys only compute\nthe point-source limiting magnitude measured within a fixed metric aperture.\nHowever, this quantity is ill suited to describe the limiting depth of\ngalaxies, which depends on the detailed interplay of survey systematics with\ngalaxy shapes and sizes. We describe an empirical method for directly\nestimating the limiting magnitude for large photometric surveys, and apply it\nto $\\sim10,000\\,\\mathrm{deg}^{2}$ of SDSS DR8 data. Combined with deeper\nimaging from SDSS Stripe 82 and CFHTLens, we are able to use these depth maps\nto estimate the location-dependent galaxy detection completeness at any point\nwithin the full BOSS DR8 survey region. We show that these maps can be used to\nconstruct random points suitable for unbiased estimation of correlation\nfunctions for galaxies near the survey limiting magnitude. Finally, we provide\nlimiting magnitude maps for galaxies in SDSS DR8 in HEALPix format with\nNSIDE=2048. \n\n"}
{"id": "1509.00870", "contents": "Title: Assessing Galaxy Limiting Magnitudes in Large Optical Surveys Abstract: Large scale structure measurements require accurate and precise knowledge of\nthe survey depth --- typically expressed in the form of a limiting magnitude\n--- as a function of position on the sky. To date, most surveys only compute\nthe point-source limiting magnitude measured within a fixed metric aperture.\nHowever, this quantity is ill suited to describe the limiting depth of\ngalaxies, which depends on the detailed interplay of survey systematics with\ngalaxy shapes and sizes. We describe an empirical method for directly\nestimating the limiting magnitude for large photometric surveys, and apply it\nto $\\sim10,000\\,\\mathrm{deg}^{2}$ of SDSS DR8 data. Combined with deeper\nimaging from SDSS Stripe 82 and CFHTLens, we are able to use these depth maps\nto estimate the location-dependent galaxy detection completeness at any point\nwithin the full BOSS DR8 survey region. We show that these maps can be used to\nconstruct random points suitable for unbiased estimation of correlation\nfunctions for galaxies near the survey limiting magnitude. Finally, we provide\nlimiting magnitude maps for galaxies in SDSS DR8 in HEALPix format with\nNSIDE=2048. \n\n"}
{"id": "1509.01076", "contents": "Title: XMM-Newton observation of a sample of four close dSph galaxies Abstract: We present the results of the analysis of deep archival \\sat\\ observations\ntowards the dwarf spheroidal galaxies Draco, Leo I, Ursa Major II and Ursa\nMinor in the Milky Way neighbourhood. The X-ray source population is\ncharacterized and cross-correlated with available databases with the aim to\ninfer their nature. We also investigate if intermediate-mass black holes are\nhosted in the center of these galaxies. In the case of Draco, we detect 96\nhigh-energy sources, two of them being possibly local stars, while no evidence\nfor any X-ray emitting central compact object is found. Towards the Leo I and\nUMa II field of view we reveal 116 and 49 X-ray sources, respectively. None of\nthem correlates with the putative central black holes and only one is likely\nassociated with a UMa II local source. The study of the UMi dwarf galaxy shows\n54 high-energy sources and a possible association {with a source at the dSph\ncenter}. We put an upper limit to the central compact object luminosity of\n4.02$\\times$10$^{33}$ erg/s. Furthermore, via the correlation with a radio\nsource near the galactic center, we get that the putative black hole should\nhave a mass of $\\left(2.76^{+32.00}_{-2.54}\\right)\\times10^6 M_{\\odot}$ and be\nradiatively inefficient. This confirms a previous result obtained by using\nChandra data alone. \n\n"}
{"id": "1509.01411", "contents": "Title: Coronagraphic demonstration experiment using aluminum mirrors for space\n  infrared astronomical observations Abstract: For future space infrared astronomical coronagraphy, we perform experimental\nstudies on the application of aluminum mirrors to a coronagraph. Cooled\nreflective optics is required for broad-band mid-infrared observations in\nspace, while high-precision optics is required for coronagraphy. For the\ncoronagraph instrument originally proposed for the next-generation infrared\nastronomical satellite project SPICA (SCI: SPICA Coronagraph Instrument), we\nfabricated and evaluated the optics consisting of high-precision aluminum\noff-axis mirrors with diamond-turned surfaces, and conducted a coronagraphic\ndemonstration experiment using the optics with a coronagraph mask. We first\nmeasured the wave front errors (WFEs) of the aluminum mirrors with a He-Ne\nFizeau interferometer to confirm that the power spectral densities of the WFEs\nsatisfy the SCI requirements. Then we integrated the mirrors into an optical\nsystem and evaluated the overall performance of the system. As a result, we\nestimate the total WFE of the optics to be 33 nm (rms), each mirror\ncontributing 10-20 nm (rms) for the central 14 mm area of the optics, and\nobtain a contrast of 10^(-5.4) as a coronagraph in the visible light. At a\nwavelength of 5 um, the coronagraphic system is expected to achieve a contrast\nof ~10^(-7) based on our model calculation with the measured optical\nperformance. Thus our experiment demonstrates that aluminum mirror optics is\napplicable to a highly WFE-sensitive instrument such as a coronagraph in space. \n\n"}
{"id": "1509.01784", "contents": "Title: Comparison of absolute gain photometric calibration between Planck/HFI\n  and Herschel/SPIRE at 545 and 857 GHz Abstract: We compare the absolute gain photometric calibration of the Planck/HFI and\nHerschel/SPIRE instruments on diffuse emission. The absolute calibration of HFI\nand SPIRE each relies on planet flux measurements and comparison with\ntheoretical far-infrared emission models of planetary atmospheres. We measure\nthe photometric cross calibration between the instruments at two overlapping\nbands, 545 GHz / 500 $\\mu$m and 857 GHz / 350 $\\mu$m. The SPIRE maps used have\nbeen processed in the Herschel Interactive Processing Environment (Version 12)\nand the HFI data are from the 2015 Public Data Release 2. For our study we used\n15 large fields observed with SPIRE, which cover a total of about 120 deg^2. We\nhave selected these fields carefully to provide high signal-to-noise ratio,\navoid residual systematics in the SPIRE maps, and span a wide range of surface\nbrightness. The HFI maps are bandpass-corrected to match the emission observed\nby the SPIRE bandpasses. The SPIRE maps are convolved to match the HFI beam and\nput on a common pixel grid. We measure the cross-calibration relative gain\nbetween the instruments using two methods in each field, pixel-to-pixel\ncorrelation and angular power spectrum measurements. The SPIRE / HFI relative\ngains are 1.047 ($\\pm$ 0.0069) and 1.003 ($\\pm$ 0.0080) at 545 and 857 GHz,\nrespectively, indicating very good agreement between the instruments. These\nrelative gains deviate from unity by much less than the uncertainty of the\nabsolute extended emission calibration, which is about 6.4% and 9.5% for HFI\nand SPIRE, respectively, but the deviations are comparable to the values 1.4%\nand 5.5% for HFI and SPIRE if the uncertainty from models of the common\ncalibrator can be discounted. Of the 5.5% uncertainty for SPIRE, 4% arises from\nthe uncertainty of the effective beam solid angle, which impacts the adopted\nSPIRE point source to extended source unit conversion factor (Abridged) \n\n"}
{"id": "1509.01979", "contents": "Title: INFN Camera demonstrator for the Cherenkov Telescope Array Abstract: The Cherenkov Telescope Array is a world-wide project for a new generation of\nground-based Cherenkov telescopes of the Imaging class with the aim of\nexploring the highest energy region of the electromagnetic spectrum. With two\nplanned arrays, one for each hemisphere, it will guarantee a good sky coverage\nin the energy range from a few tens of GeV to hundreds of TeV, with improved\nangular resolution and a sensitivity in the TeV energy region better by one\norder of magnitude than the currently operating arrays. In order to cover this\nwide energy range, three different telescope types are envisaged, with\ndifferent mirror sizes and focal plane features. In particular, for the highest\nenergies a possible design is a dual-mirror Schwarzschild-Couder optical\nscheme, with a compact focal plane. A silicon photomultiplier (SiPM) based\ncamera is being proposed as a solution to match the dimensions of the pixel\n(angular size of ~ 0.17 degrees). INFN is developing a camera demonstrator made\nby 9 Photo Sensor Modules (PSMs, 64 pixels each, with total coverage 1/4 of the\nfocal plane) equipped with FBK (Fondazione Bruno Kessler, Italy) Near\nUltraViolet High Fill factor SiPMs and Front-End Electronics (FEE) based on a\nTarget 7 ASIC, a 16 channels fast sampler (up to 2GS/s) with deep buffer,\nself-trigger and on-demand digitization capabilities specifically developed for\nthis purpose. The pixel dimensions of $6\\times6$ mm$^2$ lead to a very compact\ndesign with challenging problems of thermal dissipation. A modular structure,\nmade by copper frames hosting one PSM and the corresponding FEE, has been\nconceived, with a water cooling system to keep the required working\ntemperature. The actual design, the adopted technical solutions and the\nachieved results for this demonstrator are presented and discussed. \n\n"}
{"id": "1509.02165", "contents": "Title: European Pulsar Timing Array Limits on Continuous Gravitational Waves\n  from Individual Supermassive Black Hole Binaries Abstract: We have searched for continuous gravitational wave (CGW) signals produced by\nindividually resolvable, circular supermassive black hole binaries (SMBHBs) in\nthe latest EPTA dataset, which consists of ultra-precise timing data on 41\nmillisecond pulsars. We develop frequentist and Bayesian detection algorithms\nto search both for monochromatic and frequency-evolving systems. None of the\nadopted algorithms show evidence for the presence of such a CGW signal,\nindicating that the data are best described by pulsar and radiometer noise\nonly. Depending on the adopted detection algorithm, the 95\\% upper limit on the\nsky-averaged strain amplitude lies in the range $6\\times\n10^{-15}<A<1.5\\times10^{-14}$ at $5{\\rm nHz}<f<7{\\rm nHz}$. This limit varies\nby a factor of five, depending on the assumed source position, and the most\nconstraining limit is achieved towards the positions of the most sensitive\npulsars in the timing array. The most robust upper limit -- obtained via a full\nBayesian analysis searching simultaneously over the signal and pulsar noise on\nthe subset of ours six best pulsars -- is $A\\approx10^{-14}$. These limits, the\nmost stringent to date at $f<10{\\rm nHz}$, exclude the presence of\nsub-centiparsec binaries with chirp mass $\\cal{M}_c>10^9$M$_\\odot$ out to a\ndistance of about 25Mpc, and with $\\cal{M}_c>10^{10}$M$_\\odot$ out to a\ndistance of about 1Gpc ($z\\approx0.2$). We show that state-of-the-art SMBHB\npopulation models predict $<1\\%$ probability of detecting a CGW with the\ncurrent EPTA dataset, consistent with the reported non-detection. We stress,\nhowever, that PTA limits on individual CGW have improved by almost an order of\nmagnitude in the last five years. The continuing advances in pulsar timing data\nacquisition and analysis techniques will allow for strong astrophysical\nconstraints on the population of nearby SMBHBs in the coming years. \n\n"}
{"id": "1509.03636", "contents": "Title: The MOSDEF Survey: Electron Density and Ionization Parameter at\n  $z\\sim2.3$ Abstract: Using observations from the MOSFIRE Deep Evolution Field (MOSDEF) survey, we\ninvestigate the physical conditions of star-forming regions in $z\\sim2.3$\ngalaxies, specifically the electron density and ionization state. From\nmeasurements of the [O II]$\\lambda\\lambda$3726,3729 and [S\nII]$\\lambda\\lambda$6716,6731 doublets, we find a median electron density of\n$\\sim250$ cm$^{-3}$ at $z\\sim2.3$, an increase of an order of magnitude\ncompared to measurements of galaxies at $z\\sim0$. While $z\\sim2.3$ galaxies are\noffset towards significantly higher O$_{32}$ values relative to local galaxies\nat fixed stellar mass, we find that the high-redshift sample follows a similar\ndistribution to the low-metallicity tail of the local distribution in the\nO$_{32}$ vs. R$_{23}$ and O3N2 diagrams. Based on these results, we propose\nthat $z\\sim2.3$ star-forming galaxies have the same ionization parameter as\nlocal galaxies at fixed metallicity. In combination with simple photoionization\nmodels, the position of local and $z\\sim2.3$ galaxies in excitation diagrams\nsuggests that there is no significant change in the hardness of the ionizing\nspectrum at fixed metallicity from $z\\sim0$ to $z\\sim2.3$. We find that\n$z\\sim2.3$ galaxies show no offset compared to low-metallicity local galaxies\nin emission line ratio diagrams involving only lines of hydrogen, oxygen, and\nsulfur, but show a systematic offset in diagrams involving [N II]$\\lambda$6584.\nWe conclude that the offset of $z\\sim2.3$ galaxies from the local star-forming\nsequence in the [N II] BPT diagram is primarily driven by elevated N/O at fixed\nO/H compared to local galaxies. These results suggest that the local gas-phase\nand stellar metallicity sets the ionization state of star-forming regions at\n$z\\sim0$ and $z\\sim2$. \n\n"}
{"id": "1509.04439", "contents": "Title: Running Non-Minimal Inflation with Stabilized Inflaton Potential Abstract: In the context of the Higgs model involving gauge and Yukawa interactions\nwith the spontaneous gauge symmetry breaking, we consider $\\lambda \\phi^4$\ninflation with non-minimal gravitational coupling, where the Higgs field is\nidentified as inflaton. Since the inflaton quartic coupling is very small, once\nquantum corrections through the gauge and Yukawa interactions are taken into\naccount, the inflaton effective potential most likely becomes unstable. In\norder to avoid this problem, we need to impose stability conditions on the\neffective inflaton potential, which lead to not only non-trivial relations\namongst the particle mass spectrum of the model, but also correlations between\nthe inflationary predictions and the mass spectrum. For concrete discussion, we\ninvestigate the minimal $B-L$ extension of the Standard Model with\nidentification of the $B-L$ Higgs field as inflaton. The stability conditions\nfor the inflaton effective potential fix the mass ratio amongst the $B-L$ gauge\nboson, the right-handed neutrinos and the inflaton. This mass ratio also\ncorrelates with the inflationary predictions. In other words, if the $B-L$\ngauge boson and the right-handed neutrinos are discovered in future, their\nobserved mass ratio provides constraints on the inflationary predictions. \n\n"}
{"id": "1509.04628", "contents": "Title: Recovery of Large Angular Scale CMB Polarization for Instruments\n  Employing Variable-delay Polarization Modulators Abstract: Variable-delay Polarization Modulators (VPMs) are currently being implemented\nin experiments designed to measure the polarization of the cosmic microwave\nbackground on large angular scales because of their capability for providing\nrapid, front-end polarization modulation and control over systematic errors.\nDespite the advantages provided by the VPM, it is important to identify and\nmitigate any time-varying effects that leak into the synchronously modulated\ncomponent of the signal. In this paper, the effect of emission from a $300$ K\nVPM on the system performance is considered and addressed. Though instrument\ndesign can greatly reduce the influence of modulated VPM emission, some\nresidual modulated signal is expected. VPM emission is treated in the presence\nof rotational misalignments and temperature variation. Simulations of\ntime-ordered data are used to evaluate the effect of these residual errors on\nthe power spectrum. The analysis and modeling in this paper guides\nexperimentalists on the critical aspects of observations using VPMs as\nfront-end modulators. By implementing the characterizations and controls as\ndescribed, front-end VPM modulation can be very powerful for mitigating $1/f$\nnoise in large angular scale polarimetric surveys. None of the systematic\nerrors studied fundamentally limit the detection and characterization of\nB-modes on large scales for a tensor-to-scalar ratio of $r=0.01$. Indeed,\n$r<0.01$ is achievable with commensurately improved characterizations and\ncontrols. \n\n"}
{"id": "1509.04658", "contents": "Title: WSPEC: A waveguide filter-bank focal plane array spectrometer for\n  millimeter wave astronomy and cosmology Abstract: Imaging and spectroscopy at (sub-)millimeter wavelengths are key frontiers in\nastronomy and cosmology. Large area spectral surveys with moderate spectral\nresolution (R=50-200) will be used to characterize large scale structure and\nstar formation through intensity mapping surveys in emission lines such as the\nCO rotational transitions. Such surveys will also be used to study the SZ\neffect, and will detect the emission lines and continuum spectrum of individual\nobjects. WSPEC is an instrument proposed to target these science goals. It is a\nchannelizing spectrometer realized in rectangular waveguide, fabricated using\nconventional high-precision metal machining. Each spectrometer is coupled to\nfree space with a machined feed horn, and the devices are tiled into a 2D array\nto fill the focal plane of the telescope. The detectors will be aluminum\nLumped-Element Kinetic Inductance Detectors (LEKIDs). To target the CO lines\nand SZ effect, we will have bands at 135-175 GHz and 190-250 GHz, each\nNyquist-sampled at R~200 resolution. Here we discuss the instrument concept and\ndesign, and successful initial testing of a WR10 (i.e. 90 GHz) prototype\nspectrometer. We recently tested a WR5 (180 GHz) prototype to verify that the\nconcept works at higher frequencies, and also designed a resonant backshort\nstructure that may further increase the optical efficiency. We are making\nprogress towards integrating a spectrometer with a LEKID array and deploying a\nprototype device to a telescope for first light. \n\n"}
{"id": "1509.05392", "contents": "Title: BFORE: The B-mode Foreground Experiment Abstract: The B-mode Foreground Experiment (BFORE) is a proposed NASA balloon project\ndesigned to make optimal use of the sub-orbital platform by concentrating on\nthree dust foreground bands (270, 350, and 600 GHz) that complement\nground-based cosmic microwave background (CMB) programs. BFORE will survey ~1/4\nof the sky with 1.7 - 3.7 arcminute resolution, enabling precise\ncharacterization of the Galactic dust that now limits constraints on inflation\nfrom CMB B-mode polarization measurements. In addition, BFORE's combination of\nfrequency coverage, large survey area, and angular resolution enables science\nfar beyond the critical goal of measuring foregrounds. BFORE will constrain the\nvelocities of thousands of galaxy clusters, provide a new window on the cosmic\ninfrared background, and probe magnetic fields in the interstellar medium. We\nreview the BFORE science case, timeline, and instrument design, which is based\non a compact off-axis telescope coupled to >10,000 superconducting detectors. \n\n"}
{"id": "1509.05420", "contents": "Title: The Apache Point Observatory Galactic Evolution Experiment (APOGEE) Abstract: The Apache Point Observatory Galactic Evolution Experiment (APOGEE), one of\nthe programs in the Sloan Digital Sky Survey III (SDSS-III), has now completed\nits systematic, homogeneous spectroscopic survey sampling all major populations\nof the Milky Way. After a three year observing campaign on the Sloan 2.5-m\nTelescope, APOGEE has collected a half million high resolution (R~22,500), high\nS/N (>100), infrared (1.51-1.70 microns) spectra for 146,000 stars, with time\nseries information via repeat visits to most of these stars. This paper\ndescribes the motivations for the survey and its overall design---hardware,\nfield placement, target selection, operations---and gives an overview of these\naspects as well as the data reduction, analysis and products. An index is also\ngiven to the complement of technical papers that describe various critical\nsurvey components in detail. Finally, we discuss the achieved survey\nperformance and illustrate the variety of potential uses of the data products\nby way of a number of science demonstrations, which span from time series\nanalysis of stellar spectral variations and radial velocity variations from\nstellar companions, to spatial maps of kinematics, metallicity and abundance\npatterns across the Galaxy and as a function of age, to new views of the\ninterstellar medium, the chemistry of star clusters, and the discovery of rare\nstellar species. As part of SDSS-III Data Release 12, all of the APOGEE data\nproducts are now publicly available. \n\n"}
{"id": "1509.06190", "contents": "Title: A Micromegas-based low-background x-ray detector coupled to a\n  slumped-glass telescope for axion research Abstract: We report on the design, construction and operation of a low background x-ray\ndetection line composed of a shielded Micromegas (micromesh gaseous structure)\ndetector of the microbulk technique. The detector is made from radiopure\nmaterials and is placed at the focal point of a $\\sim$~5 cm diameter, 1.3 m\nfocal-length, cone-approximation Wolter I x-ray telescope (XRT) comprised of\nthermally-formed (or \"slumped\") glass substrates deposited with multilayer\ncoatings. The system has been conceived as a technological pathfinder for the\nfuture International Axion Observatory (IAXO), as it combines two of the\ntechniques (optic and detector) proposed in the conceptual design of the\nproject. It is innovative for two reasons: it is the first time an x-ray optic\nhas been designed and fabricated specifically for axion research, and the first\ntime a Micromegas detector has been operated with an x-ray optic. The line has\nbeen installed at one end of the CERN Axion Solar Telescope (CAST) magnet and\nis currently looking for solar axions. The combination of the XRT and\nMicromegas detector provides the best signal-to-noise ratio obtained so far by\nany detection system of the CAST experiment with a background rate of\n5.4$\\times$10$^{-3}\\;$counts per hour in the energy region-of-interest and\nsignal spot area. \n\n"}
{"id": "1509.06404", "contents": "Title: The clustering of galaxies in the SDSS-III Baryon Oscillation\n  Spectroscopic Survey: Modeling the clustering and halo occupation\n  distribution of BOSS-CMASS galaxies in the Final Data Release Abstract: We present a study of the clustering and halo occupation distribution of BOSS\nCMASS galaxies in the redshift range 0.43 < z < 0.7 drawn from the Final\nSDSS-III Data Release. We compare the BOSS results with the predictions of a\nHalo Abundance Matching (HAM) clustering model that assigns galaxies to dark\nmatter halos selected from the large BigMultiDark $N$-body simulation of a flat\n$\\Lambda$CDM Planck cosmology. We compare the observational data with the\nsimulated ones on a light-cone constructed from 20 subsequent outputs of the\nsimulation. Observational effects such as incompleteness, geometry, veto masks\nand fiber collisions are included in the model, which reproduces within\n1-$\\sigma$ errors the observed monopole of the 2-point correlation function at\nall relevant scales: from the smallest scales, 0.5 $h^{-1}$ Mpc, up to scales\nbeyond the Baryonic Acoustic Oscillation feature. This model also agrees\nremarkably well with the BOSS galaxy power spectrum (up to $k\\sim1$ $h$\nMpc$^{-1}$), and the Three-point correlation function. The quadrupole of the\ncorrelation function presents some tensions with observations. We discuss\npossible causes that can explain this disagreement, including target selection\neffects. Overall, the standard HAM model describes remarkably well the\nclustering statistics of the CMASS sample. We compare the stellar to halo mass\nrelation for the CMASS sample measured using weak lensing in the CFHT Stripe 82\nSurvey with the prediction of our clustering model, and find a good agreement\nwithin 1-$\\sigma$. The BigMD-BOSS light-cone including properties of BOSS\ngalaxies and halo properties is made publicly available. \n\n"}
{"id": "1509.06762", "contents": "Title: Strong bimodality in the host halo mass of central galaxies from\n  galaxy-galaxy lensing Abstract: We use galaxy-galaxy lensing to study the dark matter halos surrounding a\nsample of Locally Brightest Galaxies (LBGs) selected from the Sloan Digital Sky\nSurvey. We measure mean halo mass as a function of the stellar mass and colour\nof the central galaxy. Mock catalogues constructed from semi-analytic galaxy\nformation simulations demonstrate that most LBGs are the central objects of\ntheir halos, greatly reducing interpretation uncertainties due to satellite\ncontributions to the lensing signal. Over the full stellar mass range, $10.3 <\n\\log [M_*/M_\\odot] < 11.6$, we find that passive central galaxies have halos\nthat are at least twice as massive as those of star-forming objects of the same\nstellar mass. The significance of this effect exceeds $3\\sigma$ for $\\log\n[M_*/M_\\odot] > 10.7$. Tests using the mock catalogues and on the data\nthemselves clarify the effects of LBG selection and show that it cannot\nartificially induce a systematic dependence of halo mass on LBG colour. The\nbimodality in halo mass at fixed stellar mass is reproduced by the\nastrophysical model underlying our mock catalogue, but the sign of the effect\nis inconsistent with recent, nearly parameter-free age-matching models. The\nsign and magnitude of the effect can, however, be reproduced by halo occupation\ndistribution models with a simple (few-parameter) prescription for\ntype-dependence. \n\n"}
{"id": "1509.07137", "contents": "Title: Bayesian inference on the sphere beyond statistical isotropy Abstract: We present a general method for Bayesian inference of the underlying\ncovariance structure of random fields on a sphere. We employ the Bipolar\nSpherical Harmonic (BipoSH) representation of general covariance structure on\nthe sphere. We illustrate the efficacy of the method as a principled approach\nto assess violation of statistical isotropy (SI) in the sky maps of Cosmic\nMicrowave Background (CMB) fluctuations. SI violation in observed CMB maps\narise due to known physical effects such as Doppler boost and weak lensing; yet\nunknown theoretical possibilities like cosmic topology and subtle violations of\nthe cosmological principle, as well as, expected observational artefacts of\nscanning the sky with a non-circular beam, masking, foreground residuals,\nanisotropic noise, etc. We explicitly demonstrate the recovery of the input SI\nviolation signals with their full statistics in simulated CMB maps. Our\nformalism easily adapts to exploring parametric physical models with non-SI\ncovariance, as we illustrate for the inference of the parameters of a Doppler\nboosted sky map. Our approach promises to provide a robust quantitative\nevaluation of the evidence for SI violation related anomalies in the CMB sky by\nestimating the BipoSH spectra along with their complete posterior. \n\n"}
{"id": "1509.07267", "contents": "Title: IVOA recommendation: Units in the VO Abstract: This document describes a recommended syntax for writing the string\nrepresentation of unit labels (\"VOUnits\"). In addition, it describes a set of\nrecognised and deprecated units, which is as far as possible consistent with\nother relevant standards (BIPM, ISO/IEC and the IAU). The intention is that\nunits written to conform to this specification will likely also be parsable by\nother well-known parsers. To this end, we include machine-readable grammars for\nother units syntaxes. \n\n"}
{"id": "1509.07624", "contents": "Title: Tensor calculus in polar coordinates using Jacobi polynomials Abstract: Spectral methods are an efficient way to solve partial differential equations\non domains possessing certain symmetries. The utility of a method depends\nstrongly on the choice of spectral basis. In this paper we describe a set of\nbases built out of Jacobi polynomials, and associated operators for solving\nscalar, vector, and tensor partial differential equations in polar coordinates\non a unit disk. By construction, the bases satisfy regularity conditions at r=0\nfor any tensorial field. The coordinate singularity in a disk is a prototypical\ncase for many coordinate singularities. The work presented here extends to\nother geometries. The operators represent covariant derivatives, multiplication\nby azimuthally symmetric functions, and the tensorial relationship between\nfields. These arise naturally from relations between classical orthogonal\npolynomials, and form a Heisenberg algebra. Other past work uses more specific\npolynomial bases for solving equations in polar coordinates. The main\ninnovation in this paper is to use a larger set of possible bases to achieve\nmaximum bandedness of linear operations. We provide a series of applications of\nthe methods, illustrating their ease-of-use and accuracy. \n\n"}
{"id": "1510.05006", "contents": "Title: Energy-momentum correlations for Abelian Higgs cosmic strings Abstract: We report on the energy-momentum correlators obtained with recent numerical\nsimulations of the Abelian Higgs model, essential for the computation of cosmic\nmicrowave background and matter perturbations of cosmic strings. Due to\nsignificant improvements both in raw computing power and in our parallel\nsimulation framework, the dynamical range of the simulations has increased\nfour-fold both in space and time, and for the first time we are able to\nsimulate strings with a constant physical width in both the radiation and\nmatter eras. The new simulations improve the accuracy of the measurements of\nthe correlation functions at the horizon scale and confirm the shape around the\npeak. The normalization is slightly higher in the high wave-number tails, due\nto a small increase in the string density. We study for the first time the\nbehaviour of the correlators across cosmological transitions, and discover that\nthe correlation functions evolve adiabatically, ie the network adapts quickly\nto changes in the expansion rate. We propose a new method for constructing\nsource functions for Einstein-Boltzmann integrators, comparing it with two\nother methods previously used. The new method is more consistent, easier to\nimplement, and significantly more accurate. \n\n"}
{"id": "1510.05262", "contents": "Title: Composite Inflation in the light of 2015 Planck data Abstract: In this work, we examine cosmological constraints on models of composite\ninflation based on the slow-roll approximation by using the recent Planck\nmeasurement. We compare the spectral index of curvature perturbation (and its\nrunning) and the tensor-to-scalar ratio predicted by such models with Planck\n2015 data. We find that the predictions of technicolor inflation are nicely\nconsistent with the Planck analysis. Moreover, the predictions from the second\nmodel, glueball inflation, are in good agreement with the Planck data at\n$2\\sigma$C.L. However, the final two models, super glueball inflation and\norientifold inflation, favor only the rather large value of the\ntensor-to-scalar ratio of which the predictions are in tension with the Planck\nanalysis. \n\n"}
{"id": "1510.07754", "contents": "Title: Dark Matter Search Results from the PICO-60 CF$_3$I Bubble Chamber Abstract: New data are reported from the operation of the PICO-60 dark matter detector,\na bubble chamber filled with 36.8 kg of CF$_3$I and located in the SNOLAB\nunderground laboratory. PICO-60 is the largest bubble chamber to search for\ndark matter to date. With an analyzed exposure of 92.8 livedays, PICO-60\nexhibits the same excellent background rejection observed in smaller bubble\nchambers. Alpha decays in PICO-60 exhibit frequency-dependent acoustic\ncalorimetry, similar but not identical to that reported recently in a\nC$_3$F$_8$ bubble chamber. PICO-60 also observes a large population of unknown\nbackground events, exhibiting acoustic, spatial, and timing behaviors\ninconsistent with those expected from a dark matter signal. These behaviors\nallow for analysis cuts to remove all background events while retaining\n$48.2\\%$ of the exposure. Stringent limits on weakly interacting massive\nparticles interacting via spin-dependent proton and spin-independent processes\nare set, and most interpretations of the DAMA/LIBRA modulation signal as dark\nmatter interacting with iodine nuclei are ruled out. \n\n"}
{"id": "1510.08796", "contents": "Title: Maximum Likelihood Foreground Cleaning for Cosmic Microwave Background\n  Polarimeters in the Presence of Systematic Effects Abstract: We extend a general maximum likelihood foreground estimation for cosmic\nmicrowave background polarization data to include estimation of instrumental\nsystematic effects. We focus on two particular effects: frequency band\nmeasurement uncertainty, and instrumentally induced frequency dependent\npolarization rotation. We assess the bias induced on the estimation of the\n$B$-mode polarization signal by these two systematic effects in the presence of\ninstrumental noise and uncertainties in the polarization and spectral index of\nGalactic dust. Degeneracies between uncertainties in the band and polarization\nangle calibration measurements and in the dust spectral index and polarization\nincrease the uncertainty in the extracted CMB $B$-mode power, and may give rise\nto a biased estimate. We provide a quantitative assessment of the potential\nbias and increased uncertainty in an example experimental configuration. For\nexample, we find that with 10\\% polarized dust, tensor to scalar ratio of\n$r=0.05$, and the instrumental configuration of the EBEX balloon payload, the\nestimated CMB $B$-mode power spectrum is recovered without bias when the\nfrequency band measurement has 5% uncertainty or less, and the polarization\nangle calibration has an uncertainty of up to 4$^{\\circ}$. \n\n"}
{"id": "1511.02652", "contents": "Title: Lumped element kinetic inductance detectors maturity for space-borne\n  instruments in the range between 80 and 180 GHz Abstract: This work intends to give the state-of-the-art of our knowledge of the\nperformance of LEKIDs at millimetre wavelengths (from 80 to 180~GHz). We\nevaluate their optical sensitivity under typical background conditions and\ntheir interaction with ionising particles. Two LEKID arrays, originally\ndesigned for ground-based applications and composed of a few hundred pixels\neach, operate at a central frequency of 100, and 150~GHz ($\\Delta \\nu / \\nu$\nabout 0.3). Their sensitivities have been characterised in the laboratory using\na dedicated closed-circle 100~mK dilution cryostat and a sky simulator,\nallowing for the reproduction of realistic, space-like observation conditions.\nThe impact of cosmic rays has been evaluated by exposing the LEKID arrays to\nalpha particles ($^{241}$Am) and X sources ($^{109}$Cd) with a readout sampling\nfrequency similar to the ones used for Planck HFI (about 200~Hz), and also with\na high resolution sampling level (up to 2~MHz) in order to better characterise\nand interpret the observed glitches. In parallel, we have developed an\nanalytical model to rescale the results to what would be observed by such a\nLEKID array at the second Lagrangian point. \n\n"}
{"id": "1511.02856", "contents": "Title: 'Modal-noise' in single-mode fibers: A cautionary note for high\n  precision radial velocity instruments Abstract: Exploring the use of single-mode fibers (SMFs) in high precision Doppler\nspectrometers has become increasingly attractive since the advent of\ndiffraction-limited adaptive optics systems on large-aperture telescopes.\nSpectrometers fed with these fibers can be made significantly smaller than\ntypical 'seeing-limited' instruments, greatly reducing cost and overall\ncomplexity. Importantly, classical mode interference and speckle issues\nassociated with multi-mode fibers, also known as 'modal noise', are mitigated\nwhen using SMFs, which also provide perfect radial and azimuthal image\nscrambling. However, these fibers do support multiple polarization modes, an\nissue that is generally ignored for larger-core fibers given the large number\nof propagation modes. Since diffraction gratings used in most high resolution\nastronomical instruments have dispersive properties that are sensitive to\nincident polarization changes, any birefringence variations in the fiber can\ncause variations in the efficiency profile, degrading illumination stability.\nHere we present a cautionary note outlining how the polarization properties of\nSMFs can affect the radial velocity measurement precision of high resolution\nspectrographs. This work is immediately relevant to the rapidly expanding field\nof diffraction-limited, extreme precision RV spectrographs that are currently\nbeing designed and built by a number of groups. \n\n"}
{"id": "1511.02938", "contents": "Title: Fermi-LAT Observations of High-Energy Gamma-Ray Emission Toward the\n  Galactic Center Abstract: The Fermi Large Area Telescope (LAT) has provided the most detailed view to\ndate of the emission towards the Galactic centre (GC) in high-energy\ngamma-rays. This paper describes the analysis of data taken during the first 62\nmonths of the mission in the energy range 1-100 GeV from a $15^\\circ \\times\n15^\\circ$ region about the direction of the GC, and implications for the\ninterstellar emissions produced by cosmic ray (CR) particles interacting with\nthe gas and radiation fields in the inner Galaxy and for the point sources\ndetected. Specialised interstellar emission models (IEMs) are constructed that\nenable separation of the gamma-ray emission from the inner $\\sim 1$ kpc about\nthe GC from the fore- and background emission from the Galaxy. Based on these\nmodels, the interstellar emission from CR electrons interacting with the\ninterstellar radiation field via the inverse Compton (IC) process and CR nuclei\ninelastically scattering off the gas producing gamma-rays via $\\pi^0$ decays\nfrom the inner $\\sim 1$ kpc is determined. The IC contribution is found to be\ndominant in the region and strongly enhanced compared to previous studies. A\ncatalog of point sources for the $15^\\circ \\times 15^\\circ$ region is\nself-consistently constructed using these IEMs: the First Fermi-LAT Inner\nGalaxy point source Catalog (1FIG). After subtracting the interstellar emission\nand point-source contributions from the data a residual is found that is a\nsub-dominant fraction of the total flux. If spatial templates that peak toward\nthe GC are used to model the positive residual and included in the total model\nfor the $15^\\circ \\times 15^\\circ$ region, the agreement with the data\nimproves, but none of the additional templates account for all of the residual\nstructure. The spectrum of the positive residual modelled with these templates\nhas a strong dependence on the choice of IEM. [Abridged] \n\n"}
{"id": "1511.03672", "contents": "Title: Estimating SI violation in CMB due to non-circular beam and complex scan\n  in minutes Abstract: Mild, unavoidable deviations from circular-symmetry of instrumental beams\nalong with scan strategy can give rise to measurable Statistical Isotropy (SI)\nviolation in Cosmic Microwave Background (CMB) experiments. If not accounted\nproperly, this spurious signal can complicate the extraction of other SI\nviolation signals (if any) in the data. However, estimation of this effect\nthrough exact numerical simulation is computationally intensive and time\nconsuming. A generalized analytical formalism not only provides a quick way of\nestimating this signal, but also gives a detailed understanding connecting the\nleading beam anisotropy components to a measurable BipoSH characterisation of\nSI violation. In this paper, we provide an approximate generic analytical\nmethod for estimating the SI violation generated due to a non-circular (NC)\nbeam and arbitrary scan strategy, in terms of the Bipolar Spherical Harmonic\n(BipoSH) spectra. Our analytical method can predict almost all the features\nintroduced by a NC beam in a complex scan and thus reduces the need for\nextensive numerical simulation worth tens of thousands of CPU hours into\nminutes long calculations. As an illustrative example, we use WMAP beams and\nscanning strategy to demonstrate the easability, usability and efficiency of\nour method. We test all our analytical results against that from exact\nnumerical simulations. \n\n"}
{"id": "1511.04414", "contents": "Title: Cosmology Large Angular Scale Surveyor (CLASS) Focal Plane Development Abstract: The Cosmology Large Angular Scale Surveyor (CLASS) will measure the\npolarization of the Cosmic Microwave Background to search for and characterize\nthe polarized signature of inflation. CLASS will operate from the Atacama\nDesert and observe $\\sim$70% of the sky. A variable-delay polarization\nmodulator (VPM) modulates the polarization at $\\sim$10 Hz to suppress the 1/f\nnoise of the atmosphere and enable the measurement of the large angular scale\npolarization modes. The measurement of the inflationary signal across angular\nscales that span both the recombination and reionization features allows a test\nof the predicted shape of the polarized angular power spectra in addition to a\nmeasurement of the energy scale of inflation.\n  CLASS is an array of telescopes covering frequencies of 38, 93, 148, and 217\nGHz. These frequencies straddle the foreground minimum and thus allow the\nextraction of foregrounds from the primordial signal. Each focal plane contains\nfeedhorn-coupled transition-edge sensors that simultaneously detect two\northogonal linear polarizations. The use of single-crystal silicon as the\ndielectric for the on-chip transmission lines enables both high efficiency and\nuniformity in fabrication. Integrated band definition has been implemented that\nboth controls the bandpass of the single mode transmission on the chip and\nprevents stray light from coupling to the detectors. \n\n"}
{"id": "1511.05923", "contents": "Title: Dynamical fine-tuning of initial conditions for small field inflations Abstract: Small-field inflation (SFI) is widely considered to be unnatural because an\nextreme fine-tuning of the initial condition is necessary for sufficiently\nlarge e-folding. In this paper, we show that the unnaturally-looking initial\ncondition can be dynamically realised without any fine-tuning if the SFI occurs\nafter rapid oscillations of the inflaton field and particle creations by\npreheating. In fact, if the inflaton field $\\phi$ is coupled to another scalar\nfield $\\chi$ through the interaction $g^2 \\chi^2 \\phi^2$ and the vacuum energy\nduring the small field inflation is given by $\\lambda M^4$, the initial value\ncan be dynamically set at $(\\sqrt{\\lambda}/g) M^2/M_{\\rm pl}$, which is much\nsmaller than the typical scale of the potential $M.$ This solves the initial\ncondition problem in the new inflation model or some classes of the hilltop\ninflation models. \n\n"}
{"id": "1511.05955", "contents": "Title: An information-theoretic approach to the gravitational-wave burst\n  detection problem Abstract: The observational era of gravitational-wave astronomy began in the Fall of\n2015 with the detection of GW150914. One potential type of detectable\ngravitational wave is short-duration gravitational-wave bursts, whose waveforms\ncan be difficult to predict. We present the framework for a new detection\nalgorithm for such burst events -- \\textit{oLIB} -- that can be used in\nlow-latency to identify gravitational-wave transients independently of other\nsearch algorithms. This algorithm consists of 1) an excess-power event\ngenerator based on the Q-transform -- \\textit{Omicron} --, 2) coincidence of\nthese events across a detector network, and 3) an analysis of the coincident\nevents using a Markov chain Monte Carlo Bayesian evidence calculator --\n\\textit{LALInferenceBurst}. These steps compress the full data streams into a\nset of Bayes factors for each event; through this process, we use elements from\ninformation theory to minimize the amount of information regarding the\nsignal-versus-noise hypothesis that is lost. We optimally extract this\ninformation using a likelihood-ratio test to estimate a detection significance\nfor each event. Using representative archival LIGO data, we show that the\nalgorithm can detect gravitational-wave burst events of astrophysical strength\nin realistic instrumental noise across different burst waveform morphologies.\nWe also demonstrate that the combination of Bayes factors by means of a\nlikelihood-ratio test can improve the detection efficiency of a\ngravitational-wave burst search. Finally, we show that oLIB's performance is\nrobust against the choice of gravitational-wave populations used to model the\nlikelihood-ratio test likelihoods. \n\n"}
{"id": "1511.06011", "contents": "Title: A passive THz video camera based on lumped element kinetic inductance\n  detectors Abstract: We have developed a passive 350 GHz (850 {\\mu}m) video-camera to demonstrate\nlumped element kinetic inductance detectors (LEKIDs) -- designed originally for\nfar-infrared astronomy -- as an option for general purpose terrestrial\nterahertz imaging applications. The camera currently operates at a quasi-video\nframe rate of 2 Hz with a noise equivalent temperature difference per frame of\n$\\sim$0.1 K, which is close to the background limit. The 152 element\nsuperconducting LEKID array is fabricated from a simple 40 nm aluminum film on\na silicon dielectric substrate and is read out through a single microwave\nfeedline with a cryogenic low noise amplifier and room temperature frequency\ndomain multiplexing electronics. \n\n"}
{"id": "1511.06557", "contents": "Title: A novel scenario for the possible X-ray line feature at ~3.5 keV: Charge\n  exchange with bare sulfur ions Abstract: Motivated by recent claims of a compelling ~3.5 keV emission line from nearby\ngalaxies and galaxy clusters, we investigate a novel plasma model incorporating\na charge exchange component obtained from theoretical scattering calculations.\nFitting this kind of component with a standard thermal model yields positive\nresiduals around 3.5 keV, produced mostly by S XVI transitions from principal\nquantum numbers n > 8 to the ground. Such high-n states can only be populated\nby the charge exchange process. In this scenario, the observed 3.5 keV line\nflux in clusters can be naturally explained by an interaction in an effective\nvolume of ~1 kpc^3 between a ~3 keV temperature plasma and cold dense clouds\nmoving at a few hundred km/s. The S XVI lines at ~3.5 keV also provide a unique\ndiagnostic of the charge exchange phenomenon in hot cosmic plasmas. \n\n"}
{"id": "1511.08619", "contents": "Title: Advanced Environment for Knowledge Discovery in the VIALACTEA Project Abstract: The VIALACTEA project aims at building a predictive model of star formation\nin our galaxy. We present the innovative integrated framework and the main\ntechnologies and methodologies to reach this ambitious goal. \n\n"}
{"id": "1512.00012", "contents": "Title: Wavelet-Based Techniques for the Gamma-Ray Sky Abstract: We demonstrate how the image analysis technique of wavelet decomposition can\nbe applied to the gamma-ray sky to separate emission on different angular\nscales. New structures on scales that differ from the scales of the\nconventional astrophysical foreground and background uncertainties can be\nrobustly extracted, allowing a model-independent characterization with no\npresumption of exact signal morphology. As a test case, we generate mock\ngamma-ray data to demonstrate our ability to extract extended signals without\nassuming a fixed spatial template. For some point source luminosity functions,\nour technique also allows us to differentiate a diffuse signal in gamma-rays\nfrom dark matter annihilation and extended gamma-ray point source populations\nin a data-driven way. \n\n"}
{"id": "1512.00842", "contents": "Title: ESA Sky: a new Astronomy Multi-Mission Interface Abstract: We present a science-driven discovery portal for all the ESA Astronomy\nMissions called ESA Sky that allow users to explore the multi-wavelength sky\nand to seamlessly retrieve science-ready data in all ESA Astronomy mission\narchives from a web application without prior-knowledge of any of the missions.\nThe first public beta of the service has been released, currently featuring an\ninterface for exploration of the multi-wavelength sky and for single and/or\nmultiple target searches of science-ready imaging data and catalogues. Future\nreleases will enable retrieval of spectra and will have special time-domain\nexploration features. From a technical point of view, the system offers\nprogressive multi-resolution all-sky projections of full mission datasets using\na new generation of HEALPix projections called HiPS, developed at the CDS;\ndetailed geometrical footprints to connect the all-sky mosaics to individual\nobservations; and direct access to science-ready data at the underlying\nmission-specific science archives. \n\n"}
{"id": "1512.01549", "contents": "Title: Evaluating the effect of stellar multiplicity on the PSF of space-based\n  weak lensing surveys Abstract: The next generation of space-based telescopes used for weak lensing surveys\nwill require exquisite point spread function (PSF) determination. Previously\nnegligible effects may become important in the reconstruction of the PSF, in\npart because of the improved spatial resolution. In this paper, we show that\nunresolved multiple star systems can affect the ellipticity and size of the PSF\nand that this effect is not cancelled even when using many stars in the\nreconstruction process. We estimate the error in the reconstruction of the PSF\ndue to the binaries in the star sample both analytically and with image\nsimulations for different PSFs and stellar populations. The simulations support\nour analytical finding that the error on the size of the PSF is a function of\nthe multiple stars distribution and of the intrinsic value of the size of the\nPSF, i.e. if all stars were single. Similarly, the modification of each of the\ncomplex ellipticity components (e1,e2) depends on the distribution of multiple\nstars and on the intrinsic complex ellipticity. Using image simulations, we\nalso show that the predicted error in the PSF shape is a theoretical limit that\ncan be reached only if large number of stars (up to thousands) are used\ntogether to build the PSF at any desired spatial position. For a lower number\nof stars, the PSF reconstruction is worse. Finally, we compute the effect of\nbinarity for different stellar magnitudes and show that bright stars alter the\nPSF size and ellipticity more than faint stars. This may affect the design of\nPSF calibration strategies and the choice of the related calibration fields. \n\n"}
{"id": "1512.01846", "contents": "Title: The Spatial Morphology of the Secondary Emission in the Galactic Center\n  Gamma-Ray Excess Abstract: Excess GeV gamma rays from the Galactic Center (GC) have been measured with\nthe Fermi Large Area Telescope (LAT). The presence of the GC excess (GCE)\nappears to be robust with respect to changes in the diffuse galactic background\nmodeling. The three main proposals for the GCE are an unresolved population of\nmillisecond pulsars (MSPs), outbursts of cosmic rays from the GC region, and\nself-annihilating dark matter (DM). The injection of secondary electrons and\npositrons into the interstellar medium (ISM) by an unresolved population of\nMSPs or DM annihilations can lead to observable gamma-ray emission via inverse\nCompton scattering or bremsstrahlung. Here we investigate how to determine\nwhether secondaries are important in a model for the GCE. We develop a method\nof testing model fit which accounts for the different spatial morphologies of\nthe secondary emission. We examine several models which give secondary emission\nand illustrate a case where a broadband analysis is not sufficient to determine\nthe need for secondary emission. \n\n"}
{"id": "1512.05198", "contents": "Title: Cosmology with all-sky surveys Abstract: Various aspects of cosmology require comprehensive all-sky mapping of the\ncosmic web to considerable depths. In order to probe the whole extragalactic\nsky beyond 100 Mpc, one must draw on multiwavelength datasets and\nstate-of-the-art photometric redshift techniques. Here I summarize our\ndedicated program that employs the largest photometric all-sky surveys --\n2MASS, WISE and SuperCOSMOS -- to obtain accurate redshift estimates of\nmillions of galaxies. The first outcome of these efforts -- the 2MASS\nPhotometric Redshift catalog (2MPZ) -- was publicly released in 2013 and\nincludes almost 1 million galaxies with a median redshift of z~0.1. I discuss\nhow this catalog was constructed and how it is being used for various\ncosmological tests. I also present how combining the WISE mid-infrared survey\nwith SuperCOSMOS optical data allowed us to push to depths over 1 Gpc on\nunprecedented angular scales. These photometric redshift samples, with about 20\nmillion sources in total, provide access to volumes large enough to study\nobservationally the Copernican Principle of universal homogeneity and isotropy,\nas well as to probe various aspects of dark energy and dark matter through\ncross-correlations with other data such as the cosmic microwave or gamma-ray\nbackgrounds. Last but not least, they constitute a test-bed for forthcoming\nwide-angle multi-million galaxy samples expected from such instruments as the\nSKA, Euclid, or LSST. \n\n"}
{"id": "1512.05271", "contents": "Title: Rotational spectra of isotopic species of methyl cyanide, CH$_3$CN, in\n  their $v_8 = 1$ excited vibrational states Abstract: Methyl cyanide is an important trace molecule in space, especially in\nstar-forming regions where it is one of the more common molecules used to\nderive kinetic temperatures. We want to obtain accurate spectroscopic\nparameters of minor isotopologs of methyl cyanide in their lowest excited $v_8\n= 1$ vibrational states to support astronomical observations, in particular,\nwith interferometers such as ALMA. The laboratory rotational spectrum of methyl\ncyanide in natural isotopic composition has been recorded from the millimeter\nto the terahertz regions. Transitions with good signal-to-noise ratios could be\nidentified for the three isotopic species CH$_3^{13}$CN, $^{13}$CH$_3$CN, and\nCH$_3$C(15)N up to about 1.2 THz ($J'' \\le 66$). Accurate spectroscopic\nparameters were obtained for all three species. The present data were already\ninstrumental in identifying $v_8 = 1$ lines of methyl cyanide with one $^{13}$C\nin IRAM 30 m and ALMA data toward Sagittarius B2(N). \n\n"}
{"id": "1512.05734", "contents": "Title: SN Refsdal : Photometry and Time Delay Measurements of the First\n  Einstein Cross Supernova Abstract: We present the first year of Hubble Space Telescope imaging of the unique\nsupernova (SN) 'Refsdal', a gravitationally lensed SN at z=1.488$\\pm$0.001 with\nmultiple images behind the galaxy cluster MACS J1149.6+2223. The first four\nobserved images of SN Refsdal (images S1-S4) exhibited a slow rise (over ~150\ndays) to reach a broad peak brightness around 20 April, 2015. Using a set of\nlight curve templates constructed from SN 1987A-like peculiar Type II SNe, we\nmeasure time delays for the four images relative to S1 of 4$\\pm$4 (for S2),\n2$\\pm$5 (S3), and 24$\\pm$7 days (S4). The measured magnification ratios\nrelative to S1 are 1.15$\\pm$0.05 (S2), 1.01$\\pm$0.04 (S3), and 0.34$\\pm$0.02\n(S4). None of the template light curves fully captures the photometric behavior\nof SN Refsdal, so we also derive complementary measurements for these\nparameters using polynomials to represent the intrinsic light curve shape.\nThese more flexible fits deliver fully consistent time delays of 7$\\pm$2 (S2),\n0.6$\\pm$3 (S3), and 27$\\pm$8 days (S4). The lensing magnification ratios are\nsimilarly consistent, measured as 1.17$\\pm$0.02 (S2), 1.00$\\pm$0.01 (S3), and\n0.38$\\pm$0.02 (S4). We compare these measurements against published predictions\nfrom lens models, and find that the majority of model predictions are in very\ngood agreement with our measurements. Finally, we discuss avenues for future\nimprovement of time delay measurements -- both for SN Refsdal and for other\nstrongly lensed SNe yet to come. \n\n"}
{"id": "1512.05946", "contents": "Title: White Dwarf Critical Tests for Modified Gravity Abstract: Scalar-tensor theories of gravity can lead to modifications of the\ngravitational force inside astrophysical objects. We exhibit that compact stars\nsuch as white dwarfs provide a unique set-up to test beyond Horndeski theories\nof ${\\rm G}^3$ type. We obtain stringent and independent constraints on the\nparameter $\\Upsilon$ characterizing the deviations from Newtonian gravity using\nthe mass-radius relation, the Chandrasekhar mass limit and the maximal\nrotational frequency of white dwarfs. We find that white dwarfs impose stronger\nconstraints on $\\Upsilon$ than red and brown dwarfs. \n\n"}
{"id": "1512.06745", "contents": "Title: Submillimeter Polarization Spectrum in the Vela C Molecular Cloud Abstract: Polarization maps of the Vela C molecular cloud were obtained at 250, 350,\nand 500um during the 2012 flight of the balloon-borne telescope BLASTPol. These\nmeasurements are used in conjunction with 850um data from Planck to study the\nsubmillimeter spectrum of the polarization fraction for this cloud. The\nspectrum is relatively flat and does not exhibit a pronounced minimum at\n\\lambda ~350um as suggested by previous measurements of other molecular clouds.\nThe shape of the spectrum does not depend strongly on the radiative environment\nof the dust, as quantified by the column density or the dust temperature\nobtained from Herschel data. The polarization ratios observed in Vela C are\nconsistent with a model of a porous clumpy molecular cloud being uniformly\nheated by the interstellar radiation field. \n\n"}
{"id": "1512.06820", "contents": "Title: Hamiltonian analysis of higher derivative scalar-tensor theories Abstract: We perform a Hamiltonian analysis of a large class of scalar-tensor\nLagrangians which depend quadratically on the second derivatives of a scalar\nfield. By resorting to a convenient choice of dynamical variables, we show that\nthe Hamiltonian can be written in a very simple form, where the Hamiltonian and\nthe momentum constraints are easily identified. In the case of degenerate\nLagrangians, which include the Horndeski and beyond Horndeski quartic\nLagrangians, our analysis confirms that the dimension of the physical phase\nspace is reduced by the primary and secondary constraints due to the\ndegeneracy, thus leading to the elimination of the dangerous Ostrogradski\nghost. We also present the Hamiltonian formulation for nondegenerate theories\nand find that they contain four degrees of freedom, as expected. We finally\ndiscuss the status of the unitary gauge from the Hamiltonian perspective. \n\n"}
{"id": "1512.06829", "contents": "Title: Towards Robust Gravitational Wave Detection with Pulsar Timing Arrays Abstract: Precision timing of highly stable milli-second pulsars is a promising\ntechnique for the detection of very low frequency sources of gravitational\nwaves. In any single pulsar, a stochastic gravitational wave signal appears as\nan additional source of timing noise that can be absorbed by the noise model,\nand so it is only by considering the coherent response across a network of\npulsars that the signal can be distinguished from other sources of noise. In\nthe limit where there are many gravitational wave sources in the sky, or many\npulsars in the array, the signals produce a unique tensor correlation pattern\nthat depends only on the angular separation between each pulsar pair. It is\nthis distinct fingerprint that is used to search for gravitational waves using\npulsar timing arrays. Here we consider how the prospects for detection are\ndiminished when the statistical isotropy of the timing array or the\ngravitational wave signal is broken by having a finite number of pulsars and a\nfinite number of sources. We find the standard tensor-correlation analysis to\nbe remarkably robust, with a mild impact on detectability compared to the\nisotropic limit. Only when there are very few sources and very few pulsars does\nthe standard analysis begin to fail. Having established that the tensor\ncorrelations are a robust signature for detection, we study the use of\n\"sky-scrambles\" to break the correlations as a way to increase confidence in a\ndetection. This approach is analogous to the use of \"time-slides\" in the\nanalysis of data from ground based interferometric detectors. \n\n"}
{"id": "1512.07919", "contents": "Title: Improving Software Citation and Credit Abstract: The past year has seen movement on several fronts for improving software\ncitation, including the Center for Open Science's Transparency and Openness\nPromotion (TOP) Guidelines, the Software Publishing Special Interest Group that\nwas started at January's AAS meeting in Seattle at the request of that\norganization's Working Group on Astronomical Software, a Sloan-sponsored\nmeeting at GitHub in San Francisco to begin work on a cohesive research\nsoftware citation-enabling platform, the work of Force11 to \"transform and\nimprove\" research communication, and WSSSPE's ongoing efforts that include\nsoftware publication, citation, credit, and sustainability.\n  Brief reports on these efforts were shared at the BoF, after which\nparticipants discussed ideas for improving software citation, generating a list\nof recommendations to the community of software authors, journal publishers,\nADS, and research authors. The discussion, recommendations, and feedback will\nhelp form recommendations for software citation to those publishers represented\nin the Software Publishing Special Interest Group and the broader community. \n\n"}
{"id": "1512.08730", "contents": "Title: SDSS J0159+0105: A Radio-Quiet Quasar with a Centi-Parsec Supermassive\n  Black Hole Binary Candidate Abstract: We report a candidate centi-parsec supermassive black hole binary (SMBHB) in\nthe radio-quiet quasar SDSS J0159+0105 at z=0.217. With a modified lomb-scargle\ncode GLSdeDRW and the auto-correlation analysis ACF, we detect two significant\n(at P>99%) periodic signals at ~741 day and ~1500 day from the 8.1-year\nCatalina V-band light curve of this quasar. The period ratio, which is close to\n1:2, is typical of a black-hole binary system with a mass ratio of 0.05<q<0.8\naccording to recent numerical simulations. SDSS J0159+0105 has two SDSS\nspectroscopic observations separated by ~10 years. There is a significant\nchange in the broad H-beta profile between the two epochs, which can be\nexplained by a single broad-line region (BLR) around the binary system\nilluminated by the aforementioned mini-disks, or a stream of gas flowing from\nthe circumbinary disk to one of the SMBHs. From the single BLR assumption and\nthe orbital period t_orb ~1500 day, we estimate the total virial masses of\nM_SMBHB ~ 1.3x10^8 M_sun, the average distances of BLR of ~0.04pc (~50\nlight-day, with +/-0.3 dex uncertainty), and a SMBHB separation of d=\n(0.01pc)M_{8,tot}^{1/3} (T_rest/3.3yr)^{2/3} ~ 0.013 pc (15 light-day). Based\non analytical work, the postulated circumbinary disk has an inner radius of 2d\n= 0.026 pc (30 light-day). SDSS J0159+0105 also displays unusual spectral\nenergy distribution. The unique properties of SDSS J0159+0105 are consistent\nwith it being a centi-parsec SMBHB.\n  The GLSdeDRW code link: http://butler.lab.asu.edu/qso_period/ \n\n"}
{"id": "1601.00589", "contents": "Title: Comparing Dark Energy Survey and HST-CLASH observations of the galaxy\n  cluster RXC J2248.7-4431: implications for stellar mass versus dark matter Abstract: We derive the stellar mass fraction in the galaxy cluster RXC J2248.7-4431\nobserved with the Dark Energy Survey (DES) during the Science Verification\nperiod. We compare the stellar mass results from DES (five filters) with those\nfrom the Hubble Space Telescope Cluster Lensing And Supernova Survey (CLASH; 17\nfilters). When the cluster spectroscopic redshift is assumed, we show that\nstellar masses from DES can be estimated within 25% of CLASH values. We compute\nthe stellar mass contribution coming from red and blue galaxies, and study the\nrelation between stellar mass and the underlying dark matter using weak lensing\nstudies with DES and CLASH. An analysis of the radial profiles of the DES total\nand stellar mass yields a stellar-to-total fraction of f*=(6.8+-1.7)x10^-3\nwithin a radius of r_200c~2 Mpc. Our analysis also includes a comparison of\nphotometric redshifts and star/galaxy separation efficiency for both data sets.\nWe conclude that space-based small field imaging can be used to calibrate the\ngalaxy properties in DES for the much wider field of view. The technique\ndeveloped to derive the stellar mass fraction in galaxy clusters can be applied\nto the ~100 000 clusters that will be observed within this survey and yield\nimportant information about galaxy evolution. \n\n"}
{"id": "1601.02073", "contents": "Title: CHIPS: The Cosmological HI Power Spectrum Estimator Abstract: Detection of the cosmological neutral hydrogen signal from the Epoch of\nReionization, and estimation of its basic physical parameters, is the principal\nscientific aim of many current low-frequency radio telescopes. Here we describe\nthe Cosmological HI Power Spectrum Estimator (CHIPS), an algorithm developed\nand implemented with data from the Murchison Widefield Array (MWA), to compute\nthe two-dimensional and spherically-averaged power spectrum of brightness\ntemperature fluctuations. The principal motivations for CHIPS are the\napplication of realistic instrumental and foreground models to form the optimal\nestimator, thereby maximising the likelihood of unbiased signal estimation, and\nallowing a full covariant understanding of the outputs. CHIPS employs an\ninverse-covariance weighting of the data through the maximum likelihood\nestimator, thereby allowing use of the full parameter space for signal\nestimation (\"foreground suppression\"). We describe the motivation for the\nalgorithm, implementation, application to real and simulated data, and early\noutputs. Upon application to a set of 3 hours of data, we set a 2$\\sigma$ upper\nlimit on the EoR dimensionless power at $k=0.05$~h.Mpc$^{-1}$ of\n$\\Delta_k^2<7.6\\times{10^4}$~mK$^2$ in the redshift range $z=[6.2-6.6]$,\nconsistent with previous estimates. \n\n"}
{"id": "1601.04052", "contents": "Title: Precise Astronomical Flux Calibration and its Impact on Studying the\n  Nature of Dark Energy Abstract: Measurements of the luminosity of type Ia supernovae vs. redshift provided\nthe original evidence for the accelerating expansion of the Universe and the\nexistence of dark energy. Despite substantial improvements in survey\nmethodology, systematic uncertainty in flux calibration dominates the error\nbudget for this technique, exceeding both statistics and other systematic\nuncertainties. Consequently, any further collection of type Ia supernova data\nwill fail to refine the constraints on the nature of dark energy unless we also\nimprove the state of the art in astronomical flux calibration to the order of\n1%. We describe how these systematic errors arise from calibration of\ninstrumental sensitivity, atmospheric transmission, and Galactic extinction,\nand discuss ongoing efforts to meet the 1% precision challenge using white\ndwarf stars as celestial standards, exquisitely calibrated detectors as\nfundamental metrologic standards, and real-time atmospheric monitoring. \n\n"}
{"id": "1601.05452", "contents": "Title: Multichroic TES Bolometers and Galaxy Cluster Mass Scaling Relations\n  with the South Pole Telescope Abstract: The South Pole Telescope (SPT) is a high-resolution microwave-frequency\ntelescope designed to observe the Cosmic Microwave Background (CMB). To date,\ntwo cameras have been installed on the SPT to conduct two surveys of the CMB,\nthe first in intensity only (SPT-SZ) and the second in intensity and\npolarization (SPTpol). A third-generation polarization-sensitive camera is\ncurrently in development (SPT-3G). This thesis describes work spanning all\nthree instruments on the SPT. I present my work in time-reversed order, to\nfollow the canonical narrative of instrument development, deployment, and\nanalysis. First, the development and testing of novel 3-band multichroic\nTransition Edge Sensor (TES) bolometers for the SPT-3G experiment is detailed,\nfollowed by the development and deployment of the frequency multiplexed\ncryogenic readout electronics for the SPTpol experiment, and concluding with\nthe analysis of data taken by the SPT-SZ instrument. I describe the development\nof a Bayesian likelihood based method I developed for measuring the integrated\nComptonization (Ysz) of galaxy clusters from the Sunyaev-Zel'dovich (SZ)\neffect, and constraining galaxy cluster Ysz-mass scaling relations. \n\n"}
{"id": "1601.06429", "contents": "Title: PARAVT: Parallel Voronoi Tessellation code Abstract: We present a new open source code for massive parallel computation of Voronoi\ntessellations(VT hereafter) in large data sets. The code is focused for\nastrophysical purposes where VT densities and neighbors are widely used. There\nare several serial Voronoi tessellation codes, however no open source and\nparallel implementations are available to handle the large number of\nparticles/galaxies in current N-body simulations and sky surveys.\nParallelization is implemented under MPI and VT using Qhull library. Domain\ndecomposition takes into account consistent boundary computation between tasks,\nand includes periodic conditions. In addition, the code computes neighbors\nlist, Voronoi density, Voronoi cell volume, density gradient for each particle,\nand densities on a regular grid. \n\n"}
{"id": "1601.07858", "contents": "Title: Aggregation and Linking of Observational Metadata in the ADS Abstract: We discuss current efforts behind the curation of observing proposals,\narchive bibliographies, and data links in the NASA Astrophysics Data System\n(ADS). The primary data in the ADS is the bibliographic content from scholarly\narticles in Astronomy and Physics, which ADS aggregates from publishers, arXiv\nand conference proceeding sites. This core bibliographic information is then\nfurther enriched by ADS via the generation of citations and usage data, and\nthrough the aggregation of external resources from astronomy data archives and\nlibraries. Important sources of such additional information are the metadata\ndescribing observing proposals and high level data products, which, once\ningested in ADS, become easily discoverable and citeable by the science\ncommunity. Bibliographic studies have shown that the integration of links\nbetween data archives and the ADS provides greater visibility to data products\nand increased citations to the literature associated with them. \n\n"}
{"id": "1602.01462", "contents": "Title: Bayesian Estimates of Astronomical Time Delays between Gravitationally\n  Lensed Stochastic Light Curves Abstract: The gravitational field of a galaxy can act as a lens and deflect the light\nemitted by a more distant object such as a quasar. Strong gravitational lensing\ncauses multiple images of the same quasar to appear in the sky. Since the light\nin each gravitationally lensed image traverses a different path length from the\nquasar to the Earth, fluctuations in the source brightness are observed in the\nseveral images at different times. The time delay between these fluctuations\ncan be used to constrain cosmological parameters and can be inferred from the\ntime series of brightness data or light curves of each image. To estimate the\ntime delay, we construct a model based on a state-space representation for\nirregularly observed time series generated by a latent continuous-time\nOrnstein-Uhlenbeck process. We account for microlensing, an additional source\nof independent long-term extrinsic variability, via a polynomial regression.\nOur Bayesian strategy adopts a Metropolis-Hastings within Gibbs sampler. We\nimprove the sampler by using an ancillarity-sufficiency interweaving strategy\nand adaptive Markov chain Monte Carlo. We introduce a profile likelihood of the\ntime delay as an approximation of its marginal posterior distribution. The\nBayesian and profile likelihood approaches complement each other, producing\nalmost identical results; the Bayesian method is more principled but the\nprofile likelihood is simpler to implement. We demonstrate our estimation\nstrategy using simulated data of doubly- and quadruply-lensed quasars, and\nobserved data from quasars Q0957+561 and J1029+2623. \n\n"}
{"id": "1602.02109", "contents": "Title: Large-scale magnetic fields can explain the baryon asymmetry of the\n  Universe Abstract: Helical hypermagnetic fields in the primordial Universe can produce the\nobserved amount of baryon asymmetry through the chiral anomaly without any\ningredients beyond the standard model of particle physics. While they generate\nno $B-L$ asymmetry, the generated baryon asymmetry survives the spharelon\nwashout effect, because the generating process remains active until the\nelectroweak phase transition. Solving the Boltzmann equation numerically and\nfinding an attractor solution, we show that the baryon asymmetry of our\nUniverse can be explained, if the present large-scale magnetic fields indicated\nby the blazar observations have a negative helicity and existed in the early\nUniverse before the electroweak phase transition. We also derive the upper\nbound on the strength of the helical magnetic field, which is tighter than the\ncosmic microwave background constraint, to avoid the overproduction of baryon\nasymmetry. \n\n"}
{"id": "1602.05021", "contents": "Title: Technology for the next gravitational wave detectors Abstract: This paper reviews some of the key enabling technologies for advanced and\nfuture laser interferometer gravitational wave detectors, which must combine\ntest masses with the lowest possible optical and acoustic losses, with high\nstability lasers and various techniques for suppressing noise. Sect. 1 of this\npaper presents a review of the acoustic properties of test masses. Sect. 2\nreviews the technology of the amorphous dielectric coatings which are currently\nuniversally used for the mirrors in advanced laser interferometers, but for\nwhich lower acoustic loss would be very advantageous. In sect. 3 a new\ngeneration of crystalline optical coatings that offer a substantial reduction\nin thermal noise is reviewed. The optical properties of test masses are\nreviewed in sect. 4, with special focus on the properties of silicon, an\nimportant candidate material for future detectors. Sect. 5 of this paper\npresents the very low noise, high stability laser technology that underpins all\nadvanced and next generation laser interferometers. \n\n"}
{"id": "1602.05578", "contents": "Title: $\\mu$-Distortions or Running: A Guaranteed Discovery from CMB\n  Spectrometry Abstract: We discuss the implications of a PIXIE-like experiment, which would measure\n$\\mu$-type spectral distortions of the CMB at a level of\n$\\sigma_{\\mu}=(1/n)\\times 10^{-8}$, with $n\\geq1$ representing an improved\nsensitivity (e.g. $n=10$ corresponds to PRISM). Using Planck data and\nconsidering the six-parameter $\\Lambda$CDM model, we compute the posterior for\n$\\mu_8\\equiv\\mu\\times 10^{8}$ and find $\\mu_8=1.57^{+0.11}_{-0.13}$\n($68\\%\\,\\mathrm{CL}$). This becomes $\\mu_{8} = 1.28^{+0.30}_{-0.52}$\n($68\\%\\,\\mathrm{CL}$) when the running $\\alpha_\\mathrm{s}$ of the spectral\nindex is included. We point out that a sensitivity of about $3\\times$ PIXIE\nimplies a guaranteed discovery: $\\mu$-distortion is detected or\n$\\alpha_\\mathrm{s}\\geq 0$ is excluded (both at $95\\%\\,\\mathrm{CL}$ or higher).\nThis threshold sensitivity sets a clear benchmark for CMB spectrometry. For a\ncombined analysis of PIXIE and current Planck data, we discuss the improvement\non measurements of the tilt $n_\\mathrm{s}$ and the running $\\alpha_\\mathrm{s}$\nand the dependence on the choice of the pivot. A fiducial running of\n$\\alpha_\\mathrm{s}=-0.01$ (close to the Planck best-fit) leads to a detection\nof negative running at $2\\sigma$ for $5\\times$ PIXIE. A fiducial running of\n$\\alpha_\\mathrm{s}=-0.02$, still compatible with Planck, requires $3\\times$\nPIXIE to rule out $\\alpha_\\mathrm{s} = 0$ (at $95\\%\\,\\mathrm{CL}$). We propose\na convenient and compact visualization of the improving constraints on the\ntilt, running and tensor-to-scalar ratio. \n\n"}
{"id": "1602.05836", "contents": "Title: RadioLensfit: Bayesian weak lensing measurement in the visibility domain Abstract: Observationally, weak lensing has been served so far by optical surveys due\nto the much larger number densities of background galaxies achieved, which is\ntypically by two to three orders of magnitude compared to radio. However, the\nhigh sensitivity of the new generation of radio telescopes such as the Square\nKilometre Array (SKA) will provide a density of detected galaxies that is\ncomparable to that found at optical wavelengths, and with significant source\nshape measurements to make large area radio surveys competitive for weak\nlensing studies. This will lead weak lensing to become one of the primary\nscience drivers in radio surveys too, with the advantage that they will access\nthe largest scales in the Universe going beyond optical surveys, like LSST and\nEuclid, in terms of redshifts that are probed. RadioLensfit is an adaptation to\nradio data of \"lensfit\", a model-fitting approach for galaxy shear measurement,\noriginally developed for optical weak lensing surveys. Its key advantage is\nworking directly in the visibility domain, which is the natural approach to\nadopt with radio data, avoiding systematics due to the imaging process. We\npresent results on galaxy shear measurements, including investigation of\nsensitivity to instrumental parameters such as the visibilities gridding size,\nbased on simulations of individual galaxy visibilities performed by using\nSKA1-MID baseline configuration. We get an amplitude of the shear bias in the\nmethod comparable with SKA1 requirements for a population of galaxies with\nrealistic flux and scalelength distributions estimated from the VLA SWIRE\ncatalog. \n\n"}
{"id": "1602.06259", "contents": "Title: Redundant Array Configurations for 21 cm Cosmology Abstract: Realizing the potential of 21 cm tomography to statistically probe the\nintergalactic medium before and during the Epoch of Reionization requires large\ntelescopes and precise control of systematics. Next-generation telescopes are\nnow being designed and built to meet these challenges, drawing lessons from\nfirst-generation experiments that showed the benefits of densely packed, highly\nredundant arrays--in which the same mode on the sky is sampled by many antenna\npairs--for achieving high sensitivity, precise calibration, and robust\nforeground mitigation. In this work, we focus on the Hydrogen Epoch of\nReionization Array (HERA) as an interferometer with a dense, redundant core\ndesigned following these lessons to be optimized for 21 cm cosmology. We show\nhow modestly supplementing or modifying a compact design like HERA's can still\ndeliver high sensitivity while enhancing strategies for calibration and\nforeground mitigation. In particular, we compare the imaging capability of\nseveral array configurations, both instantaneously (to address instrumental and\nionospheric effects) and with rotation synthesis (for foreground removal). We\nalso examine the effects that configuration has on calibratability using\ninstantaneous redundancy. We find that improved imaging with sub-aperture\nsampling via \"off-grid\" antennas and increased angular resolution via far-flung\n\"outrigger\" antennas is possible with a redundantly calibratable array\nconfiguration. \n\n"}
{"id": "1602.06294", "contents": "Title: Stacking for machine learning redshifts applied to SDSS galaxies Abstract: We present an analysis of a general machine learning technique called\n'stacking' for the estimation of photometric redshifts. Stacking techniques can\nfeed the photometric redshift estimate, as output by a base algorithm, back\ninto the same algorithm as an additional input feature in a subsequent learning\nround. We shown how all tested base algorithms benefit from at least one\nadditional stacking round (or layer). To demonstrate the benefit of stacking,\nwe apply the method to both unsupervised machine learning techniques based on\nself-organising maps (SOMs), and supervised machine learning methods based on\ndecision trees. We explore a range of stacking architectures, such as the\nnumber of layers and the number of base learners per layer. Finally we explore\nthe effectiveness of stacking even when using a successful algorithm such as\nAdaBoost. We observe a significant improvement of between 1.9% and 21% on all\ncomputed metrics when stacking is applied to weak learners (such as SOMs and\ndecision trees). When applied to strong learning algorithms (such as AdaBoost)\nthe ratio of improvement shrinks, but still remains positive and is between\n0.4% and 2.5% for the explored metrics and comes at almost no additional\ncomputational cost. \n\n"}
{"id": "1602.07744", "contents": "Title: Multi-mode TES bolometer optimization for the LSPE-SWIPE instrument Abstract: In this paper we explore the possibility of using transition edge sensor\n(TES) detectors in multi-mode configuration in the focal plane of the Short\nWavelength Instrument for the Polarization Explorer (SWIPE) of the\nballoon-borne polarimeter Large Scale Polarization Explorer (LSPE) for the\nCosmic Microwave Background (CMB) polarization. This study is motivated by the\nfact that maximizing the sensitivity of TES bolometers, under the augmented\nbackground due to the multi-mode design, requires a non trivial choice of\ndetector parameters. We evaluate the best parameter combination taking into\naccount scanning strategy, noise constraints, saturation power and operating\ntemperature of the cryostat during the flight. \n\n"}
{"id": "1602.08274", "contents": "Title: An exact result concerning the $1/f$ noise contribution to the\n  large-angle error in CMB temperature and polarization maps Abstract: We present an exact expression for the $1/f$ contribution to the noise of the\nCMB temperature and polarization maps for a survey in which the scan pattern is\nisotropic. The result for polarization applies likewise to surveys with and\nwithout a rotating half-wave plate. A representative range of survey parameters\nis explored and implications for the design and optimization of future surveys\nare discussed. These results are most directly applicable to space-based\nsurveys, which afford considerable freedom in the choice of the scan pattern on\nthe celestial sphere. We discuss the applicability of the methods developed\nhere to analyzing past experiments and present some conclusions pertinent to\nthe design of future experiments. The techniques developed here do not require\nthat the excess low frequency noise have exactly the $1/f$ shape and readily\ngeneralize to other functional forms for the detector noise power spectrum. In\nthe case of weakly anisotropic scanning patterns the techniques in this paper\ncan be used to find a preconditioner for solving the map making equation\nefficiently using the conjugate gradient method. \n\n"}
{"id": "1603.00607", "contents": "Title: Calibration Requirements for Detecting the 21 cm Epoch of Reionization\n  Power Spectrum and Implications for the SKA Abstract: 21 cm Epoch of Reionization observations promise to transform our\nunderstanding of galaxy formation, but these observations are impossible\nwithout unprecedented levels of instrument calibration. We present end-to-end\nsimulations of a full EoR power spectrum analysis including all of the major\ncomponents of a real data processing pipeline: models of astrophysical\nforegrounds and EoR signal, frequency-dependent instrument effects, sky-based\nantenna calibration, and the full PS analysis. This study reveals that\ntraditional sky-based per-frequency antenna calibration can only be implemented\nin EoR measurement analyses if the calibration model is unrealistically\naccurate. For reasonable levels of catalog completeness, the calibration\nintroduces contamination in otherwise foreground-free power spectrum modes,\nprecluding a PS measurement. We explore the origin of this contamination and\npotential mitigation techniques. We show that there is a strong joint\nconstraint on the precision of the calibration catalog and the inherent\nspectral smoothness of antennae, and that this has significant implications for\nthe instrumental design of the SKA and other future EoR observatories. \n\n"}
{"id": "1603.01951", "contents": "Title: SKA-Japan Pulsar Science with the Square Kilometre Array Abstract: The Square Kilometre Array will revolutionize pulsar studies with its wide\nfield-of-view, wide-band observation and high sensitivity, increasing the\nnumber of observable pulsars by more than an order of magnitude. Pulsars are of\ninterest not only for the study of neutron stars themselves but for their usage\nas tools for probing fundamental physics such as general relativity,\ngravitational waves and nuclear interaction. In this article, we summarize the\nactivity and interests of SKA-Japan Pulsar Science Working Group, focusing on\nan investigation of modified gravity theory with the supermassive black hole in\nthe Galactic Centre, gravitational-wave detection from cosmic strings and\nbinary supermassive black holes, a study of the physical state of plasma close\nto pulsars using giant radio pulses and determination of magnetic field\nstructure of Galaxy with pulsar pairs. \n\n"}
{"id": "1603.01974", "contents": "Title: Resolving 4-D Nature of Magnetism with Depolarization and Faraday\n  Tomography: Japanese SKA Cosmic Magnetism Science Abstract: Magnetic fields play essential roles in various astronomical objects. Radio\nastronomy has revealed that magnetic fields are ubiquitous in our Universe.\nHowever, the real origin and evolution of magnetic fields is poorly proven. In\norder to advance our knowledge of cosmic magnetism in coming decades, the\nSquare Kilometre Array (SKA) should have supreme sensitivity than ever before,\nwhich provides numerous observation points in the cosmic space. Furthermore,\nthe SKA should be designed to facilitate wideband polarimetry so as to allow us\nto examine sightline structures of magnetic fields by means of depolarization\nand Faraday Tomography. The SKA will be able to drive cosmic magnetism of the\ninterstellar medium, the Milky Way, galaxies, AGN, galaxy clusters, and\npotentially the cosmic web which may preserve information of the primeval\nUniverse. The Japan SKA Consortium (SKA-JP) Magnetism Science Working Group\n(SWG) proposes the project \"Resolving 4-D Nature of Magnetism with\nDepolarization and Faraday Tomography\", which contains ten scientific use\ncases. \n\n"}
{"id": "1603.02144", "contents": "Title: Coeval Observations of a Complete Sample of Blazars with Effelsberg,\n  IRAM 30m, and Planck Abstract: We present the outline and first results of a project using the synergies of\nthe long term blazar radiomillimetre monitoring program F-GAMMA, the continued\nscanning of the millimetre-submillimetre sky by the Planck satellite, together\nwith several dedicated observing programs at the Effelsberg 100m telescope, to\nobtain a data sample unprecedented in both time resolution and frequency span. \n\n"}
{"id": "1603.04988", "contents": "Title: Observational evidence for the evolution of nuclear metallicity and star\n  formation rate as the merger stage Abstract: We investigate the evolution of nuclear gas-phase oxygen abundance and star\nformation rate (SFR) of local far-infrared selected star-forming galaxies along\nthe merger sequence, as traced by their optical morphologies. The sample was\ndrawn from a cross-correlation analysis of the IRAS Point Source Catalog\nRedshift Survey and 1 Jy ultraluminous infrared galaxies sample with the Sloan\nDigital Sky Survey Data Release 7 database. The investigation is done by\ncomparing our sample to a control sample matched in the normalized redshift\ndistribution in two diagnostics, which are the nuclear gas-phase metallicity\nvs. stellar mass and the nuclear SFR vs. stellar mass diagrams. Galaxies with\ndifferent morphological types show different mass-metallicity relations (MZR).\nCompared to the MZR defined by the control sample, isolated spirals have\ncomparable metallicities with the control sample at a given stellar mass.\nSpirals in pairs and interacting galaxies with projected separations $r_{p} >$\n20 kpc show mild metallicity dilution of 0.02-0.03 dex. Interacting galaxies\nwith $r_{p} <$ 20 kpc, pre-mergers and advanced mergers are under-abundant by\n~0.06, ~0.05 and ~0.04 dex, respectively. This shows an evolutionary trend that\nthe metallicity is increasingly depressed as the merging proceeds and it is\ndiluted most dramatically when two galaxies are closely interacting.\nAfterwards, the interstellar medium (ISM) is enriched when the galaxies\ncoalesce. This is the first time that such ISM enrichment at the final\ncoalescence stage is observed, which demonstrates the importance of supernova\nexplosion in affecting the nuclear metallicity. Meanwhile the central SFR\nenhancement relative to the control sample evolves simultaneously with the\nnuclear gas-phase oxygen abundance. Our results support the predictions from\nnumerical simulations. \n\n"}
{"id": "1603.05508", "contents": "Title: Local Simulations of Instabilities Driven by Composition Gradients in\n  the ICM Abstract: The distribution of Helium in the intracluster medium (ICM) permeating galaxy\nclusters is not well constrained due to the very high plasma temperature.\nTherefore, the plasma is often assumed to be homogeneous. A non-uniform Helium\ndistribution can however lead to biases when measuring key cluster parameters.\nThis has motivated one-dimensional models that evolve the ICM composition\nassuming that the effects of magnetic fields can be parameterized or ignored.\nSuch models for non-isothermal clusters show that Helium can sediment in the\ncluster core leading to a peak in concentration offset from the cluster center.\nThe resulting profiles have recently been shown to be linearly unstable when\nthe weakly-collisional character of the magnetized plasma is considered. In\nthis paper, we present a modified version of the MHD code Athena, which makes\nit possible to evolve a weakly-collisional plasma subject to a gravitational\nfield and stratified in both temperature and composition. We thoroughly test\nour implementation and confirm excellent agreement against several analytical\nresults. In order to isolate the effects of composition, in this initial study\nwe focus our attention on isothermal plasmas. We show that plasma\ninstabilities, feeding off gradients in composition, can induce turbulent\nmixing and saturate by re-arranging magnetic field lines and alleviating the\ncomposition gradient. Composition profiles that increase with radius lead to\ninstabilities that saturate by driving the average magnetic field inclination\nto roughly $45^{\\circ}$. We speculate that this effect may alleviate the core\ninsulation observed in homogeneous settings, with potential consequences for\nthe associated cooling flow problem. \n\n"}
{"id": "1603.05976", "contents": "Title: BICEP2 / Keck Array VII: Matrix based E/B Separation applied to BICEP2\n  and the Keck Array Abstract: A linear polarization field on the sphere can be uniquely decomposed into an\nE-mode and a B-mode component. These two components are analytically defined in\nterms of spin-2 spherical harmonics. Maps that contain filtered modes on a\npartial sky can also be decomposed into E-mode and B-mode components. However,\nthe lack of full sky information prevents orthogonally separating these\ncomponents using spherical harmonics. In this paper, we present a technique for\ndecomposing an incomplete map into E and B-mode components using E and B\neigenmodes of the pixel covariance in the observed map. This method is found to\northogonally define E and B in the presence of both partial sky coverage and\nspatial filtering. This method has been applied to the BICEP2 and the Keck\nArray maps and results in reducing E to B leakage from LCDM E-modes to a level\ncorresponding to a tensor-to-scalar ratio of $r<1\\times10^{-4}$. \n\n"}
{"id": "1603.07565", "contents": "Title: Challenges and prospects for better measurements of the CMB intensity\n  spectrum Abstract: Spectral distortions of the Cosmic Microwave Background (CMB) offer the\npossibility of probing processes which occurred during the evolution of our\nUniverse going back up to Z$\\simeq 10^7$. Unfortunately all the attempts so far\ncarried out for detecting distortions failed. All of them were based on\ncomparisons among absolute measurements of the CMB temperature at different\nfrequencies. We suggest a different approach: measurements of the frequency\nderivative of the CMB temperature over large frequency intervals instead of\nobservations of the absolute temperature at few, well separated, frequencies as\nfrequently done in the past, and, direct measurements of the foregrounds which\nhinder bobservations, at the same site and with the same radiometer prepared\nfor the search of CMB distortions. We discuss therefore the perspectives of new\nobservations in the next years from the ground, at very special sites, or in\nspace as independent missions or part of other CMB projects \n\n"}
{"id": "1603.09438", "contents": "Title: MARZ: Manual and Automatic Redshifting Software Abstract: The Australian Dark Energy Survey (OzDES) is a 100-night spectroscopic survey\nunderway on the Anglo-Australian Telescope using the fibre-fed 2-degree-field\n(2dF) spectrograph. We have developed a new redshifting application Marz with\ngreater usability, flexibility, and the capacity to analyse a wider range of\nobject types than the Runz software package previously used for redshifting\nspectra from 2dF. Marz is an open-source, client-based, Javascript\nweb-application which provides an intuitive interface and powerful automatic\nmatching capabilities on spectra generated from the AAOmega spectrograph to\nproduce high quality spectroscopic redshift measurements. The software can be\nrun interactively or via the command line, and is easily adaptable to other\ninstruments and pipelines if conforming to the current FITS file standard is\nnot possible. Behind the scenes, a modified version of the Autoz\ncross-correlation algorithm is used to match input spectra against a variety of\nstellar and galaxy templates, and automatic matching performance for OzDES\nspectra has increased from 54% (Runz) to 91% (Marz). Spectra not matched\ncorrectly by the automatic algorithm can be easily redshifted manually by\ncycling automatic results, manual template comparison, or marking spectral\nfeatures. \n\n"}
{"id": "1604.00652", "contents": "Title: Galaxy Redshifts from Discrete Optimization of Correlation Functions Abstract: We propose a new method of constraining the redshifts of individual\nextragalactic sources based on celestial coordinates and their ensemble\nstatistics. Techniques from integer linear programming are utilized to optimize\nsimultaneously for the angular two-point cross- and autocorrelation functions.\nOur novel formalism introduced here not only transforms the otherwise\nhopelessly expensive, brute-force combinatorial search into a linear system\nwith integer constraints but also is readily implementable in off-the-shelf\nsolvers. We adopt Gurobi, a commercial optimization solver, and use Python to\nbuild the cost function dynamically. The preliminary results on simulated data\nshow potential for future applications to sky surveys by complementing and\nenhancing photometric redshift estimators. Our approach is the first\napplication of integer linear programming to astronomical analysis. \n\n"}
{"id": "1604.01039", "contents": "Title: p-wave Annihilating Dark Matter from a Decaying Predecessor and the\n  Galactic Center Excess Abstract: Dark matter (DM) annihilations have been widely studied as a possible\nexplanation of excess gamma rays from the galactic center seen by Fermi/LAT.\nHowever most such models are in conflict with constraints from dwarf\nspheroidals. Motivated by this tension, we show that p-wave annihilating dark\nmatter can easily accommodate both sets of observations due to the lower DM\nvelocity dispersion in dwarf galaxies. Explaining the DM relic abundance is\nthen challenging. We outline a scenario in which the usual thermal abundance is\nobtained through s-wave annihilations of a metastable particle, that eventually\ndecays into the p-wave annihilating DM of the present epoch. The couplings and\nlifetime of the decaying particle are constrained by big bang nucleosynthesis,\nthe cosmic microwave background and direct detection, but significant regions\nof parameter space are viable. A sufficiently large p-wave cross section can be\nfound by annihilation into light mediators, that also give rise to Sommerfeld\nenhancement. A prediction of the scenario is enhanced annihilations in galaxy\nclusters. \n\n"}
{"id": "1604.01226", "contents": "Title: On the nature of Hydrogen-rich Superluminous Supernovae Abstract: We present two hydrogen-rich superluminous supernovae (SLSNe), namely\nSN2013hx and PS15br. These objects, together with SN2008es are the only SLSNe\nshowing a distinct, broad Halpha feature during the photospheric phase and also\ndo not show any sign of strong interaction between fast-moving ejecta and\ncircumstellar shells in their early spectra. Despite PS15br peak luminosity is\nfainter than the other two objects, the spectrophotometric evolution is similar\nto SN2013hx and different than any other supernova in a similar luminosity\nspace. We group all of them as SLSNe II and hence distinct from the known class\nof SLSN IIn. Both transients show a strong, multi-component Halpha emission\nafter 200 days past maximum which we interpret as an indication of interaction\nof the ejecta with an asymmetric, clumpy circumstellar material. The spectra\nand photometric evolution of the two objects are similar to type II supernovae,\nalthough they have much higher luminosity and evolve on slower timescales. This\nis qualitatively similar to how SLSNe I compare with normal type Ic in that the\nformer are brighter and evolve more slowly. We apply a magnetar and an\ninteraction semi-analytical codes to fit the light curves of our two objects\nand SN2008es. The overall observational dataset would tend to favour the\nmagnetar, or central engine, model as the source of the peak luminosity\nalthough the clear signature of late-time interaction indicates that\ninteraction can play a role in the luminosity evolution of SLSNe II at some\nphases. \n\n"}
{"id": "1604.02350", "contents": "Title: The COSMOS2015 Catalog: Exploring the 1<z<6 Universe with half a million\n  galaxies Abstract: We present the COSMOS2015 catalog which contains precise photometric\nredshifts and stellar masses for more than half a million objects over the\n2deg$^{2}$ COSMOS field. Including new $YJHK_{\\rm s}$ images from the\nUltraVISTA-DR2 survey, $Y$-band from Subaru/Hyper-Suprime-Cam and infrared data\nfrom the Spitzer Large Area Survey with the Hyper-Suprime-Cam Spitzer legacy\nprogram, this near-infrared-selected catalog is highly optimized for the study\nof galaxy evolution and environments in the early Universe. To maximise catalog\ncompleteness for bluer objects and at higher redshifts, objects have been\ndetected on a $\\chi^{2}$ sum of the $YJHK_{\\rm s}$ and $z^{++}$ images. The\ncatalog contains $\\sim 6\\times 10^5$ objects in the 1.5 deg$^{2}$\nUltraVISTA-DR2 region, and $\\sim 1.5\\times 10^5$ objects are detected in the\n\"ultra-deep stripes\" (0.62 deg$^{2}$) at $K_{\\rm s}\\leq 24.7$ (3$\\sigma$, 3\",\nAB magnitude). Through a comparison with the zCOSMOS-bright spectroscopic\nredshifts, we measure a photometric redshift precision of $\\sigma_{\\Delta\nz/(1+z_s)}$ = 0.007 and a catastrophic failure fraction of $\\eta=0.5$%. At\n$3<z<6$, using the unique database of spectroscopic redshifts in COSMOS, we\nfind $\\sigma_{\\Delta z/(1+z_s)}$ = 0.021 and $\\eta=13.2\\% $. The deepest\nregions reach a 90\\% completeness limit of 10$^{10}M_\\odot$ to $z=4$. Detailed\ncomparisons of the color distributions, number counts, and clustering show\nexcellent agreement with the literature in the same mass ranges. COSMOS2015\nrepresents a unique, publicly available, valuable resource with which to\ninvestigate the evolution of galaxies within their environment back to the\nearliest stages of the history of the Universe. The COSMOS2015 catalog is\ndistributed via anonymous ftp\n(ftp://ftp.iap.fr/pub/from_users/hjmcc/COSMOS2015/) and through the usual\nastronomical archive systems (CDS, ESO Phase 3, IRSA). \n\n"}
{"id": "1604.03273", "contents": "Title: Spectral calibration requirements of radio interferometers for Epoch of\n  Reionisation science with the SKA Abstract: Spectral features introduced by instrumental chromaticity of radio\ninterferometers have the potential to negatively impact the ability to perform\nEpoch of Reionisation (EoR) and Cosmic Dawn (CD) science using the redshifted\nneutral hydrogen emission line from the early Universe. We describe instrument\ncalibration choices that influence the spectral characteristics of the science\ndata, and assess their impact on EoR statistical and tomographic experiments.\nPrincipally, we consider the intrinsic spectral response of the receiving\nantennas, embedded within a complete frequency-dependent primary beam response,\nand frequency-dependent instrument sampling. We assess different options for\nbandpass calibration. The analysis is applied to the proposed SKA1-Low EoR/CD\nexperiments. We provide tolerances on the smoothness of the SKA station primary\nbeam bandpass, to meet the scientific goals of statistical and tomographic\n(imaging) EoR programs. Two calibration strategies are tested: (1) fitting of\neach fine channel independently, and (2) fitting of an nth-order polynomial for\neach ~1~MHz coarse channel with (n+1)th-order residuals (n=2,3,4). Strategy (1)\nleads to uncorrelated power in the 2D power spectrum proportional to the\nthermal noise power, thereby reducing the overall array sensitivity. Strategy\n(2) leads to correlated residuals from the fitting, and residual signal power\nwith (n+1)th-order curvature. For the residual power to be less than the\nthermal noise, the fractional amplitude of a fourth-order term in the bandpass\nacross a single coarse channel must be <2.5% (50~MHz), <0.5% (150~MHz), <0.8%\n(200~MHz). The tomographic experiment places stringent constraints on phase\nresiduals in the bandpass. We find that the root-mean-square variability over\nall stations of the change in phase across any fine channel (4.578~kHz) should\nnot exceed 0.2 degrees. \n\n"}
{"id": "1604.06760", "contents": "Title: Cosmological Constraints on Higgs-Dilaton Inflation Abstract: We test the viability of the Higgs-dilaton model (HDM) compared to the\nevolving dark energy ($w_0 w_a$CDM) model, in which the cosmological constant\nmodel $\\Lambda$CDM is also nested, by using the latest cosmological data that\nincludes the cosmic microwave background temperature, polarization and lensing\ndata from the \\textit{Planck} satellite (2015 data release), the BICEP and Keck\nArray experiments, the Type Ia supernovae from the JLA catalog, the baryon\nacoustic oscillations from CMASS, LOWZ and 6dF, the weak lensing data from the\nCFHTLenS survey and the matter power Spectrum measurements from the SDSS (data\nrelease 7). We find that the values of all cosmological parameters allowed by\nthe Higgs-dilaton inflation model are well within the \\textit{Planck} satellite\n(2015 data release) constraints. In particular, we have that $w_0 =\n-1.0001^{+0.0072}_{-0.0074}$, $w_a = 0.00^{+0.15}_{-0.16}$, $n_s =\n0.9693^{+0.0083}_{-0.0082}$, $\\alpha_s = -0.001^{+0.013}_{-0.014}$ and\n$r_{0.05} = 0.0025^{+0.0017}_{-0.0016}$ (95.5\\%C.L.). We also place new\nstringent constraints on the couplings of the Higgs-dilaton model and we find\nthat $\\xi_{\\chi} < 0.00328$ and $\\xi_h / \\sqrt{\\lambda} =\n59200^{+30000}_{-20000}$ (95.5\\%C.L.). Furthermore, we report that the HDM is\nat a slightly better footing than the $w_0 w_a$CDM model, as they both have\npractically the same chi-square, i.e. $\\Delta \\chi^2 = \\chi^2_{w_0\nw_a\\mathrm{CDM}}-\\chi^2_{\\mathrm{HDM}}=0.18$, with the HDM model having two\nfewer parameters. Finally Bayesian evidence favors equally the two models, with\nthe HDM being preferred by the AIC and DIC information criteria. \n\n"}
{"id": "1604.07409", "contents": "Title: Substructure and galaxy formation in the Copernicus Complexio warm dark\n  matter simulations Abstract: We use the Copernicus Complexio (COCO) high resolution $N$-body simulations\nto investigate differences in the properties of small-scale structures in the\nstandard cold dark matter (CDM) model and in a model with a cutoff in the\ninitial power spectrum of density fluctuations consistent with both a thermally\nproduced warm dark matter (WDM) particle or a sterile neutrino with mass 7 keV\nand leptogenesis parameter $L_6=8.7$. The latter corresponds to the \"coldest\"\nmodel with this sterile neutrino mass compatible with the identification of the\nrecently detected 3.5 keV X-ray line as resulting from particle decay. CDM and\nWDM predict very different number densities of subhaloes with mass $\\leq\n10^9\\,h^{-1}\\,M_\\odot$ although they predict similar, nearly universal,\nnormalised subhalo radial density distributions. Haloes and subhaloes in both\nmodels have cuspy NFW profiles, but WDM subhaloes below the cutoff scale in the\npower spectrum (corresponding to maximum circular velocities\n$V_{\\mathrm{max}}^{z=0} \\leq50~\\mathrm{kms}^{-1}$) are less concentrated than\ntheir CDM counterparts. We make predictions for observable properties using the\nGALFORM semi-analytic model of galaxy formation. Both models predict Milky Way\nsatellite luminosity functions consistent with observations, although the WDM\nmodel predicts fewer very faint satellites. This model, however, predicts\nslightly more UV bright galaxies at redshift $z>7$ than CDM, but both are\nconsistent with observations. Gravitational lensing offers the best prospect of\ndistinguishing between the models. \n\n"}
{"id": "1604.07493", "contents": "Title: The 2.4 $\\mu$m Galaxy Luminosity Function as Measured Using WISE. I.\n  Measurement Techniques Abstract: The astronomy community has at its disposal a large back catalog of public\nspectroscopic galaxy redshift surveys that can be used for the measurement of\nluminosity functions. Utilizing the back catalog with new photometric surveys\nto maximum efficiency requires modeling the color selection bias imposed on\nselection of target galaxies by flux limits at multiple wavelengths. The\nlikelihood derived herein can address, in principle, all possible color\nselection biases through the use of a generalization of the luminosity\nfunction, $\\Phi(L)$, over the space of all spectra: the spectro-luminosity\nfunctional, $\\Psi[L_\\nu]$. It is, therefore, the first estimator capable of\nsimultaneously analyzing multiple redshift surveys in a consistent way. We also\npropose a new way of parametrizing the evolution of the classic Shechter\nfunction parameters, $L_\\star$ and $\\phi_\\star$, that improves both the\nphysical realism and statistical performance of the model. The techniques\nderived in this work will be used in an upcoming paper to measure the\nluminosity function of galaxies at the rest frame wavelength of\n$2.4\\operatorname{\\mu m}$ using the Widefield Infrared Survey Explorer (WISE). \n\n"}
{"id": "1605.02688", "contents": "Title: Theano: A Python framework for fast computation of mathematical\n  expressions Abstract: Theano is a Python library that allows to define, optimize, and evaluate\nmathematical expressions involving multi-dimensional arrays efficiently. Since\nits introduction, it has been one of the most used CPU and GPU mathematical\ncompilers - especially in the machine learning community - and has shown steady\nperformance improvements. Theano is being actively and continuously developed\nsince 2008, multiple frameworks have been built on top of it and it has been\nused to produce many state-of-the-art machine learning models.\n  The present article is structured as follows. Section I provides an overview\nof the Theano software and its community. Section II presents the principal\nfeatures of Theano and how to use them, and compares them with other similar\nprojects. Section III focuses on recently-introduced functionalities and\nimprovements. Section IV compares the performance of Theano against Torch7 and\nTensorFlow on several machine learning models. Section V discusses current\nlimitations of Theano and potential ways of improving it. \n\n"}
{"id": "1605.02722", "contents": "Title: The Kinematic Sunyaev-Zel'dovich Effect with Projected Fields II:\n  prospects, challenges, and comparison with simulations Abstract: The kinematic Sunyaev-Zel'dovich (kSZ) signal is a powerful probe of the\ncosmic baryon distribution. The kSZ signal is proportional to the integrated\nfree electron momentum rather than the electron pressure (which sources the\nthermal SZ signal). Since velocities should be unbiased on large scales, the\nkSZ signal is an unbiased tracer of the large-scale electron distribution, and\nthus can be used to detect the \"missing baryon\" that evade most observational\ntechniques. While most current methods for kSZ extraction rely on the\navailability of very accurate redshifts, we revisit a method that allows\nmeasurements even in the absence of redshift information for individual\nobjects. It involves cross-correlating the square of an appropriately filtered\ncosmic microwave background (CMB) temperature map with a projected density map\nconstructed from a sample of large-scale structure tracers. We show that this\nmethod will achieve high signal-to-noise when applied to the next generation of\nhigh-resolution CMB experiments, provided that component separation is\nsufficiently effective at removing foreground contamination. Considering\nstatistical errors only, we forecast that this estimator can yield $S/N \\approx\n$ 3, 120 and over 150 for Planck, Advanced ACTPol, and hypothetical Stage-IV\nCMB experiments, respectively, in combination with a galaxy catalog from WISE,\nand about 20% larger $S/N$ for a galaxy catalog from the proposed SPHEREx\nexperiment. This work serves as a companion paper to the first kSZ measurement\nwith this method, where we used CMB temperature maps constructed from Planck\nand WMAP data, together with galaxies from the WISE survey, to obtain a 3.8 -\n4.5$\\sigma$ detection of the kSZ$^2$ amplitude. \n\n"}
{"id": "1605.04242", "contents": "Title: Supplement: Going the Distance: Mapping Host Galaxies of LIGO and Virgo\n  Sources in Three Dimensions Using Local Cosmography and Targeted Follow-up Abstract: This is a supplement to the Letter of Singer et al.\n(https://arxiv.org/abs/1603.07333), in which we demonstrated a rapid algorithm\nfor obtaining joint 3D estimates of sky location and luminosity distance from\nobservations of binary neutron star mergers with Advanced LIGO and Virgo. We\nargued that combining the reconstructed volumes with positions and redshifts of\npossible host galaxies can provide large-aperture but small field of view\ninstruments with a manageable list of targets to search for optical or infrared\nemission. In this Supplement, we document the new HEALPix-based file format for\n3D localizations of gravitational-wave transients. We include Python sample\ncode to show the reader how to perform simple manipulations of the 3D sky maps\nand extract ranked lists of likely host galaxies. Finally, we include\nmathematical details of the rapid volume reconstruction algorithm. \n\n"}
{"id": "1605.05501", "contents": "Title: Clustering-based redshift estimation: application to VIPERS/CFHTLS Abstract: We explore the accuracy of the clustering-based redshift estimation proposed\nby M\\'enard et al. (2013) when applied to VIPERS and CFHTLS real data. This\nmethod enables us to reconstruct redshift distributions from measurement of the\nangular clus- tering of objects using a set of secure spectroscopic redshifts.\nWe use state of the art spectroscopic measurements with iAB < 22.5 from the\nVIMOS Public Extragalactic Redshift Survey (VIPERS) as reference population to\ninfer the redshift distribution of galaxies from the Canada-France-Hawaii\nTelescope Legacy Survey (CFHTLS) T0007 release. VIPERS provides a nearly\nrepresentative sample to the flux limit iAB < 22.5 at redshift > 0.5 which\nallows us to test the accuracy of the clustering-based red- shift\ndistributions. We show that this method enables us to reproduce the true mean\ncolor-redshift relation when both populations have the same magnitude limit. We\nalso show that this technique allows the inference of redshift distributions\nfor a population fainter than the one of reference and we give an estimate of\nthe color-redshift mapping in this case. This last point is of great interest\nfor future large redshift surveys which suffer from the need of a complete\nfaint spectroscopic sample. \n\n"}
{"id": "1605.05700", "contents": "Title: Cluster-lensing: A Python Package for Galaxy Clusters & Miscentering Abstract: We describe a new open source package for calculating properties of galaxy\nclusters, including NFW halo profiles with and without the effects of cluster\nmiscentering. This pure-Python package, cluster-lensing, provides\nwell-documented and easy-to-use classes and functions for calculating cluster\nscaling relations, including mass-richness and mass-concentration relations\nfrom the literature, as well as the surface mass density $\\Sigma(R)$ and\ndifferential surface mass density $\\Delta\\Sigma(R)$ profiles, probed by weak\nlensing magnification and shear. Galaxy cluster miscentering is especially a\nconcern for stacked weak lensing shear studies of galaxy clusters, where\noffsets between the assumed and the true underlying matter distribution can\nlead to a significant bias in the mass estimates if not accounted for. This\nsoftware has been developed and released in a public GitHub repository, and is\nlicensed under the permissive MIT license. The cluster-lensing package is\narchived on Zenodo (Ford 2016). Full documentation, source code, and\ninstallation instructions are available at\nhttp://jesford.github.io/cluster-lensing/. \n\n"}
{"id": "1605.05973", "contents": "Title: WarmAndFuzzy: the halo model beyond CDM Abstract: Cold dark matter (CDM) is a well established paradigm to describe\ncosmological structure formation, and works extraordinarily well on large,\nlinear, scales. Progressing further in dark matter physics requires being able\nto understand structure formation in the non-linear regime, both for CDM and\nits alternatives. This short note describes a calculation, and accompanying\ncode, WarmAndFuzzy, incorporating the popular models of warm and fuzzy dark\nmatter (WDM and FDM) into the standard halo model to compute the non-linear\nmatter power spectrum. The FDM halo model power spectrum has not been computed\nbefore. The FDM implementation models ultralight axions and other scalar fields\nwith $m_a\\approx 10^{-22}\\text{ eV}$. The WDM implementation models thermal WDM\nwith mass $m_X\\approx 1\\text{ keV}$. The halo model shows that differences\nbetween WDM, FDM, and CDM survive at low redshifts in the quasi-linear and\nfully non-linear regimes. The code uses analytic transfer functions for the\nlinear power spectrum, modified collapse barriers in the halo mass function,\nand a modified concentration-mass relationship for the halo density profiles.\nModified halo density profiles (for example, cores) are not included, but are\nunder development. Cores are expected to have very minor effects on the power\nspectrum on observable scales. Applications of this code to the Lyman-$\\alpha$\nforest flux power spectrum and the cosmic microwave background lensing power\nspectrum will be discussed in companion papers. \\textsc{WarmAndFuzzy} is\navailable online at \\url{https://github.com/DoddyPhysics/HMcode}, where\ncollaboration in development is welcomed. \n\n"}
{"id": "1605.06101", "contents": "Title: The SLUGGS Survey: The mass distribution in early-type galaxies within\n  five effective radii and beyond Abstract: We study mass distributions within and beyond 5~effective radii ($R_{\\rm e}$)\nin 23 early-type galaxies from the SLUGGS survey, using their globular cluster\n(GC) kinematic data. The data are obtained with Keck/DEIMOS spectrograph, and\nconsist of line-of-sight velocities for ~$3500$ GCs, measured with a high\nprecision of ~15 $\\rm km\\ s^{-1}$ per GC and extending out to $~13 R_{\\rm e}$.\nWe obtain the mass distribution in each galaxy using the tracer mass estimator\nof Watkins et al. and account for kinematic substructures, rotation of the GC\nsystems and galaxy flattening in our mass estimates.\n  The observed scatter between our mass estimates and results from the\nliterature is less than 0.2 dex. The dark matter fraction within $5R_{\\rm e}$\n($f_{\\rm DM}$) increases from ~$0.6$ to ~$0.8$ for low- and high-mass galaxies,\nrespectively, with some intermediate-mass galaxies ($M_*{\\sim}10^{11}M_\\odot$)\nhaving low $f_{\\rm DM}\\sim0.3$, which appears at odds with predictions from\nsimple galaxy models. We show that these results are independent of the adopted\norbital anisotropy, stellar mass-to-light ratio, and the assumed slope of the\ngravitational potential. However, the low $f_{\\rm DM}$ in the ~$10^{11}M_\\odot$\ngalaxies agrees with the cosmological simulations of Wu et al. where the\npristine dark matter distribution has been modified by baryons during the\ngalaxy assembly process. We find hints that these $M_*\\sim10^{11}M_\\odot$\ngalaxies with low $f_{\\rm DM}$ have very diffuse dark matter haloes, implying\nthat they assembled late. Beyond $5R_{\\rm e}$, the $M/L$ gradients are steeper\nin the more massive galaxies and shallower in both low and intermediate mass\ngalaxies. \n\n"}
{"id": "1605.09387", "contents": "Title: Planck intermediate results. XLVIII. Disentangling Galactic dust\n  emission and cosmic infrared background anisotropies Abstract: Using the Planck 2015 data release (PR2) temperature maps, we separate\nGalactic thermal dust emission from cosmic infrared background (CIB)\nanisotropies. For this purpose, we implement a specifically tailored\ncomponent-separation method, the so-called generalized needlet internal linear\ncombination (GNILC) method, which uses spatial information (the angular power\nspectra) to disentangle the Galactic dust emission and CIB anisotropies. We\nproduce significantly improved all-sky maps of Planck thermal dust emission,\nwith reduced CIB contamination, at 353, 545, and 857 GHz. By reducing the CIB\ncontamination of the thermal dust maps, we provide more accurate estimates of\nthe local dust temperature and dust spectral index over the sky with reduced\ndispersion, especially at high Galactic latitudes above $b = \\pm 20{\\deg}$. We\nfind that the dust temperature is $T = (19.4 \\pm 1.3)$ K and the dust spectral\nindex is $\\beta = 1.6 \\pm 0.1$ averaged over the whole sky, while $T = (19.4\n\\pm 1.5)$ K and $\\beta = 1.6 \\pm 0.2$ on 21 % of the sky at high latitudes.\nMoreover, subtracting the new CIB-removed thermal dust maps from the\nCMB-removed Planck maps gives access to the CIB anisotropies over 60 % of the\nsky at Galactic latitudes $|b| > 20{\\deg}$. Because they are a significant\nimprovement over previous Planck products, the GNILC maps are recommended for\nthermal dust science. The new CIB maps can be regarded as indirect tracers of\nthe dark matter and they are recommended for exploring cross-correlations with\nlensing and large-scale structure optical surveys. The reconstructed GNILC\nthermal dust and CIB maps are delivered as Planck products. \n\n"}
{"id": "1606.02310", "contents": "Title: A moving mesh unstaggered constrained transport scheme for\n  magnetohydrodynamics Abstract: We present a constrained transport (CT) algorithm for solving the 3D ideal\nmagnetohydrodynamic (MHD) equations on a moving mesh, which maintains the\ndivergence-free condition on the magnetic field to machine-precision. Our CT\nscheme uses an unstructured representation of the magnetic vector potential,\nmaking the numerical method simple and computationally efficient. The scheme is\nimplemented in the moving mesh code Arepo. We demonstrate the performance of\nthe approach with simulations of driven MHD turbulence, a magnetized disc\ngalaxy, and a cosmological volume with primordial magnetic field. We compare\nthe outcomes of these experiments to those obtained with a previously\nimplemented Powell divergence-cleaning scheme. While CT and the Powell\ntechnique yield similar results in idealized test problems, some differences\nare seen in situations more representative of astrophysical flows. In the\nturbulence simulations, the Powell cleaning scheme artificially grows the mean\nmagnetic field, while CT maintains this conserved quantity of ideal MHD. In the\ndisc simulation, CT gives slower magnetic field growth rate and saturates to\nequipartition between the turbulent kinetic energy and magnetic energy, whereas\nPowell cleaning produces a dynamically dominant magnetic field. Such difference\nhas been observed in adaptive-mesh refinement codes with CT and\nsmoothed-particle hydrodynamics codes with divergence-cleaning. In the\ncosmological simulation, both approaches give similar magnetic amplification,\nbut Powell exhibits more cell-level noise. CT methods in general are more\naccurate than divergence-cleaning techniques, and, when coupled to a moving\nmesh can exploit the advantages of automatic spatial/temporal adaptivity and\nreduced advection errors, allowing for improved astrophysical MHD simulations. \n\n"}
{"id": "1606.02620", "contents": "Title: False periodicities in quasar time-domain surveys Abstract: There have recently been several reports of apparently periodic variations in\nthe light curves of quasars, e.g. PG 1302-102 by Graham et al. (2015a). Any\nquasar showing periodic oscillations in brightness would be a strong candidate\nto be a close binary supermassive black hole and, in turn, a candidate for\ngravitational wave studies. However, normal quasars -- powered by accretion\nonto a single, supermassive black hole -- usually show stochastic variability\nover a wide range of timescales. It is therefore important to carefully assess\nthe methods for identifying periodic candidates from among a population\ndominated by stochastic variability. Using a Bayesian analysis of the light\ncurve of PG 1302-102, we find that a simple stochastic process is preferred\nover a sinusoidal variations. We then discuss some of the problems one\nencounters when searching for rare, strictly periodic signals among a large\nnumber of irregularly sampled, stochastic time series, and use simulations of\nquasar light curves to illustrate these points. From a few thousand simulations\nof steep spectrum (`red noise') stochastic processes, we find many simulations\nthat display few-cycle periodicity like that seen in PG 1302-102. We emphasise\nthe importance of calibrating the false positive rate when the number of\ntargets in a search is very large. \n\n"}
{"id": "1606.02738", "contents": "Title: SWIFT: Using task-based parallelism, fully asynchronous communication,\n  and graph partition-based domain decomposition for strong scaling on more\n  than 100,000 cores Abstract: We present a new open-source cosmological code, called SWIFT, designed to\nsolve the equations of hydrodynamics using a particle-based approach (Smooth\nParticle Hydrodynamics) on hybrid shared/distributed-memory architectures.\nSWIFT was designed from the bottom up to provide excellent strong scaling on\nboth commodity clusters (Tier-2 systems) and Top100-supercomputers (Tier-0\nsystems), without relying on architecture-specific features or specialized\naccelerator hardware. This performance is due to three main computational\napproaches: (1) Task-based parallelism for shared-memory parallelism, which\nprovides fine-grained load balancing and thus strong scaling on large numbers\nof cores. (2) Graph-based domain decomposition, which uses the task graph to\ndecompose the simulation domain such that the work, as opposed to just the\ndata, as is the case with most partitioning schemes, is equally distributed\nacross all nodes. (3) Fully dynamic and asynchronous communication, in which\ncommunication is modelled as just another task in the task-based scheme,\nsending data whenever it is ready and deferring on tasks that rely on data from\nother nodes until it arrives. In order to use these approaches, the code had to\nbe re-written from scratch, and the algorithms therein adapted to the\ntask-based paradigm. As a result, we can show upwards of 60% parallel\nefficiency for moderate-sized problems when increasing the number of cores\n512-fold, on both x86-based and Power8-based architectures. \n\n"}
{"id": "1606.03887", "contents": "Title: Fine-pitch CdTe detector for hard X-ray imaging and spectroscopy of the\n  Sun with the FOXSI rocket experiment Abstract: We have developed a fine-pitch hard X-ray (HXR) detector using a cadmium\ntelluride (CdTe) semiconductor for imaging and spectroscopy for the second\nlaunch of the Focusing Optics Solar X-ray Imager (FOXSI). FOXSI is a rocket\nexperiment to perform high sensitivity HXR observations from 4-15 keV using the\nnew technique of HXR focusing optics. The focal plane detector requires < 100\num position resolution (to take advantage of the angular resolution of the\noptics) and about 1 keV energy resolution (FWHM) for spectroscopy down to 4\nkeV, with moderate cooling (> -30 C). Double-sided silicon strip detectors were\nused for the first FOXSI flight in 2012 to meet these criteria. To improve the\ndetectors' efficiency (66 at 15 keV for the silicon detectors) and position\nresolution of 75 um for the second launch, we fabricated double-sided CdTe\nstrip detectors with a position resolution of 60 um and almost 100 % efficiency\nfor the FOXSI energy range. The sensitive area is 7.67 mm x 7.67 mm,\ncorresponding to the field of view of 791'' x 791''. An energy resolution of\nabout 1 keV (FWHM) and low energy threshold of 4 keV were achieved in\nlaboratory calibrations. The second launch of FOXSI was performed on December\n11, 2014, and images from the Sun were successfully obtained with the CdTe\ndetector. Therefore we successfully demonstrated the detector concept and the\nusefulness of this technique for future HXR observations of the Sun. \n\n"}
{"id": "1606.05337", "contents": "Title: Calibration of weak-lensing shear in the Kilo-Degree Survey Abstract: We describe and test the pipeline used to measure the weak lensing shear\nsignal from the Kilo Degree Survey (KiDS). It includes a novel method of\n`self-calibration' that partially corrects for the effect of noise bias. We\nalso discuss the `weight bias' that may arise in optimally-weighted\nmeasurements, and present a scheme to mitigate that bias. To study the residual\nbiases arising from both galaxy selection and shear measurement, and to derive\nan empirical correction to reduce the shear biases to $\\lesssim 1\\%$, we create\na suite of simulated images whose properties are close to those of the KiDS\nsurvey observations. We find that the use of `self-calibration' reduces the\nadditive and multiplicative shear biases significantly, although further\ncorrection via a calibration scheme is required, which also corrects for a\ndependence of the bias on galaxy properties. We find that the calibration\nrelation itself is biased by the use of noisy, measured galaxy properties,\nwhich may limit the final accuracy that can be achieved. We assess the accuracy\nof the calibration in the tomographic bins used for the KiDS cosmic shear\nanalysis, testing in particular the effect of possible variations in the\nuncertain distributions of galaxy size, magnitude and ellipticity, and conclude\nthat the calibration procedure is accurate at the level of multiplicative bias\n$\\lesssim 1\\%$ required for the KiDS cosmic shear analysis. \n\n"}
{"id": "1606.05338", "contents": "Title: KiDS-450: Cosmological parameter constraints from tomographic weak\n  gravitational lensing Abstract: We present cosmological parameter constraints from a tomographic weak\ngravitational lensing analysis of ~450deg$^2$ of imaging data from the Kilo\nDegree Survey (KiDS). For a flat $\\Lambda$CDM cosmology with a prior on $H_0$\nthat encompasses the most recent direct measurements, we find\n$S_8\\equiv\\sigma_8\\sqrt{\\Omega_{\\rm m}/0.3}=0.745\\pm0.039$. This result is in\ngood agreement with other low redshift probes of large scale structure,\nincluding recent cosmic shear results, along with pre-Planck cosmic microwave\nbackground constraints. A $2.3$-$\\sigma$ tension in $S_8$ and `substantial\ndiscordance' in the full parameter space is found with respect to the Planck\n2015 results. We use shear measurements for nearly 15 million galaxies,\ndetermined with a new improved `self-calibrating' version of $lens$fit\nvalidated using an extensive suite of image simulations. Four-band $ugri$\nphotometric redshifts are calibrated directly with deep spectroscopic surveys.\nThe redshift calibration is confirmed using two independent techniques based on\nangular cross-correlations and the properties of the photometric redshift\nprobability distributions. Our covariance matrix is determined using an\nanalytical approach, verified numerically with large mock galaxy catalogues. We\naccount for uncertainties in the modelling of intrinsic galaxy alignments and\nthe impact of baryon feedback on the shape of the non-linear matter power\nspectrum, in addition to the small residual uncertainties in the shear and\nredshift calibration. The cosmology analysis was performed blind. Our\nhigh-level data products, including shear correlation functions, covariance\nmatrices, redshift distributions, and Monte Carlo Markov Chains are available\nat http://kids.strw.leidenuniv.nl. \n\n"}
{"id": "1606.05790", "contents": "Title: Mathematical Foundations of the GraphBLAS Abstract: The GraphBLAS standard (GraphBlas.org) is being developed to bring the\npotential of matrix based graph algorithms to the broadest possible audience.\nMathematically the Graph- BLAS defines a core set of matrix-based graph\noperations that can be used to implement a wide class of graph algorithms in a\nwide range of programming environments. This paper provides an introduction to\nthe mathematics of the GraphBLAS. Graphs represent connections between vertices\nwith edges. Matrices can represent a wide range of graphs using adjacency\nmatrices or incidence matrices. Adjacency matrices are often easier to analyze\nwhile incidence matrices are often better for representing data. Fortunately,\nthe two are easily connected by matrix mul- tiplication. A key feature of\nmatrix mathematics is that a very small number of matrix operations can be used\nto manipulate a very wide range of graphs. This composability of small number\nof operations is the foundation of the GraphBLAS. A standard such as the\nGraphBLAS can only be effective if it has low performance overhead. Performance\nmeasurements of prototype GraphBLAS implementations indicate that the overhead\nis low. \n\n"}
{"id": "1606.06758", "contents": "Title: Comparing cosmic web classifiers using information theory Abstract: We introduce a decision scheme for optimally choosing a classifier, which\nsegments the cosmic web into different structure types (voids, sheets,\nfilaments, and clusters). Our framework, based on information theory, accounts\nfor the design aims of different classes of possible applications: (i)\nparameter inference, (ii) model selection, and (iii) prediction of new\nobservations. As an illustration, we use cosmographic maps of web-types in the\nSloan Digital Sky Survey to assess the relative performance of the classifiers\nT-web, DIVA and ORIGAMI for: (i) analyzing the morphology of the cosmic web,\n(ii) discriminating dark energy models, and (iii) predicting galaxy colors. Our\nstudy substantiates a data-supported connection between cosmic web analysis and\ninformation theory, and paves the path towards principled design of analysis\nprocedures for the next generation of galaxy surveys. We have made the cosmic\nweb maps, galaxy catalog, and analysis scripts used in this work publicly\navailable. \n\n"}
{"id": "1606.06791", "contents": "Title: Highly Luminous Supernovae associated with Gamma-Ray Bursts I.: GRB\n  111209A/SN 2011kl in the Context of Stripped-Envelope and Superluminous\n  Supernovae Abstract: GRB 111209A, one of the longest Gamma-Ray Bursts (GRBs) ever observed, is\nlinked to SN 2011kl, the most luminous GRB-Supernova (SN) detected so far,\nwhich shows evidence for being powered by a magnetar central engine. We place\nSN 2011kl into the context of large samples of SNe, addressing in more detail\nthe question of whether it could be radioactively powered, and whether it\nrepresents an extreme version of a GRB-SN or an underluminous Superluminous SN\n(SLSN). We model SN 2011kl using SN 1998bw as a template and derive a\nbolometric light curve including near-infrared data. We compare the properties\nof SN 2011kl to literature results on stripped-envelope and superluminous\nsupernovae. Comparison in the k,s context, i.e., comparing it to SN 1998bw\ntemplates in terms of luminosity and light-curve stretch, clearly shows SN\n2011kl is the most luminous GRB-SN to date, and it is spectrally very\ndissimilar to other events, being significantly bluer/hotter. Although SN\n2011kl does not reach the classical luminosity threshold of SLSNe and evolves\nfaster than any of them, it resembles SLSNe more than the classical\nGRB-associated broad-lined Type Ic SNe in several aspects. GRB 111209A was a\nvery energetic event, both at early (prompt emission) and at very late (SN)\ntimes. We have shown in a further publication that with the exception of the\nextreme duration, the GRB and afterglow parameters are in agreement with the\nknown distributions for these parameters. SN 2011kl, on the other hand, is\nexceptional both in luminosity and spectral characteristics, indicating that\nGRB 111209A was likely not powered by a standard-model collapsar central\nengine, further supporting our earlier conclusions. Instead, it reveals the\npossibility of a direct link between GRBs and SLSNe. \n\n"}
{"id": "1606.06968", "contents": "Title: Breaking Be: a sterile neutrino solution to the cosmological lithium\n  problem Abstract: The possibility that the so-called \"lithium problem\", i.e. the disagreement\nbetween the theoretical abundance predicted for primordial $^7$Li assuming\nstandard nucleosynthesis and the value inferred from astrophysical\nmeasurements, can be solved through a non-thermal BBN mechanism has been\ninvestigated by several authors. In particular, it has been shown that the\ndecay of a MeV-mass particle, like, e.g., a sterile neutrino, decaying after\nBBN not only solves the lithium problem, but also satisfies cosmological and\nlaboratory bounds, making such a scenario worth to be investigated in further\ndetail. In this paper, we constrain the parameters of the model with the\ncombination of current data, including Planck 2015 measurements of temperature\nand polarization anisotropies of the CMB, FIRAS limits on spectral distortions,\nastrophysical measurements of primordial abundances and laboratory constraints.\nWe find that a sterile neutrino with mass $M_S=4.35_{-0.17}^{+0.13}\\,MeV$ (at\n$95\\%$ c.l.), a decay time $\\tau_S=1.8_{-1.3}^{+2.5}\\cdot 10^5\\,s$ (at $95\\%$\nc.l.) and an initial density $\\bar{n}_S/\\bar{n}_{cmb}=1.7_{-0.6}^{+3.5}\\cdot\n10^{-4}$ (at $95\\%$ c.l.) in units of the number density of CMB photons,\nperfectly accounts for the difference between predicted and observed $^7$Li\nprimordial abundance. This model also predicts an increase of the effective\nnumber of relativistic degrees of freedom at the time of CMB decoupling $\\Delta\nN_{eff}^{cmb}\\equiv N_{eff}^{cmb}-3.046=0.34_{-0.14}^{+0.16}$ at $95\\%$ c.l..\nThe required abundance of sterile neutrinos is incompatible with the standard\nthermal history of the Universe, but could be realized in a low reheating\ntemperature scenario. We provide forecasts for future experiments finding that\nthe combination of measurements from the COrE+ and PIXIE missions will allow to\nsignificantly reduce the permitted region for the sterile lifetime and density. \n\n"}
{"id": "1606.07061", "contents": "Title: Large-scale retrospective relative spectro-photometric self-calibration\n  in space Abstract: We consider the application of relative self-calibration using overlap\nregions to spectroscopic galaxy surveys that use slit-less spectroscopy. This\nmethod is based on that developed for the SDSS by Padmanabhan at al. (2008) in\nthat we consider jointly fitting and marginalising over calibrator brightness,\nrather than treating these as free parameters. However, we separate the\ncalibration of the detector-to-detector from the full-focal-plane\nexposure-to-exposure calibration. To demonstrate how the calibration procedure\nwill work, we simulate the procedure for a potential implementation of the\nspectroscopic component of the wide Euclid survey. We study the change of\ncoverage and the determination of relative multiplicative errors in flux\nmeasurements for different dithering configurations. We use the new method to\nstudy the case where the flat-field across each exposure or detector is\nmeasured precisely and only exposure-to-exposure or detector-to-detector\nvariation in the flux error remains. We consider several base dither patterns\nand find that they strongly influence the ability to calibrate, using this\nmethodology. To enable self-calibration, it is important that the survey\nstrategy connects different observations with at least a minimum amount of\noverlap, and we propose an \"S\"-pattern for dithering that fulfills this\nrequirement. The final survey strategy adopted by Euclid will have to optimise\nfor a number of different science goals and requirements. The large-scale\ncalibration of the spectroscopic galaxy survey is clearly cosmologically\ncrucial, but is not the only one. \n\n"}
{"id": "1606.07345", "contents": "Title: A Communication Efficient and Scalable Distributed Data Mining for the\n  Astronomical Data Abstract: In 2020, ~60PB of archived data will be accessible to the astronomers. But to\nanalyze such a paramount data will be a challenging task. This is basically due\nto the computational model used to download the data from complex\ngeographically distributed archives to a central site and then analyzing it in\nthe local systems. Because the data has to be downloaded to the central site,\nthe network BW limitation will be a hindrance for the scientific discoveries.\nAlso analyzing this PB-scale on local machines in a centralized manner is\nchallenging. In this virtual observatory is a step towards this problem,\nhowever, it does not provide the data mining model. Adding the distributed data\nmining layer to the VO can be the solution in which the knowledge can be\ndownloaded by the astronomers instead the raw data and thereafter astronomers\ncan either reconstruct the data back from the downloaded knowledge or use the\nknowledge directly for further analysis.Therefore, in this paper, we present\nDistributed Load Balancing Principal Component Analysis for optimally\ndistributing the computation among the available nodes to minimize the\ntransmission cost and downloading cost for the end user. The experimental\nanalysis is done with Fundamental Plane(FP) data, Gadotti data and complex\nMfeat data. In terms of transmission cost, our approach performs better than\nQi. et al. and Yue.et al. The analysis shows that with the complex Mfeat data\n~90% downloading cost can be reduced for the end user with the negligible loss\nin accuracy. \n\n"}
{"id": "1607.00044", "contents": "Title: Analysis of a Custom Support Vector Machine for Photometric Redshift\n  Estimation and the Inclusion of Galaxy Shape Information Abstract: Aims: We present a custom support vector machine classification package for\nphotometric redshift estimation, including comparisons with other methods. We\nalso explore the efficacy of including galaxy shape information in redshift\nestimation. Support vector machines, a type of machine learning, utilize\noptimization theory and supervised learning algorithms to construct predictive\nmodels based on the information content of data in a way that can treat\ndifferent input features symmetrically.\n  Methods: The custom support vector machine package we have developed is\ndesignated SPIDERz and made available to the community. As test data for\nevaluating performance and comparison with other methods, we apply SPIDERz to\nfour distinct data sets: 1) the publicly available portion of the PHAT-1\ncatalog based on the GOODS-N field with spectroscopic redshifts in the range $z\n< 3.6$, 2) 14365 galaxies from the COSMOS bright survey with photometric band\nmagnitudes, morphology, and spectroscopic redshifts inside $z < 1.4$, 3) 3048\ngalaxies from the overlap of COSMOS photometry and morphology with 3D-HST\nspectroscopy extending to $z < 3.9$, and 4) 2612 galaxies with five-band\nphotometric magnitudes and morphology from the All-wavelength Extended Groth\nStrip International Survey and $z < 1.57$.\n  Results: We find that SPIDER-z achieves results competitive with other\nempirical packages on the PHAT-1 data, and performs quite well in estimating\nredshifts with the COSMOS and AEGIS data, including in the cases of a large\nredshift range ($0 < z < 3.9$). We also determine from analyses with both the\nCOSMOS and AEGIS data that the inclusion of morphological information does not\nhave a statistically significant benefit for photometric redshift estimation\nwith the techniques employed here. \n\n"}
{"id": "1607.00147", "contents": "Title: HERA Mock Observations: Looking for Closure HERA Memorandum Number 13 Abstract: We investigate the use of closure phase as a method to detect the HI 21cm\nsignal from the neutral IGM during cosmic reionzation. Closure quantities have\nthe unique advantage of being independent of antenna-based calibration terms.\nWe employ realistic, large area sky models from Sims et al. (2016). These\ninclude an estimate of the HI 21cm signal generated using 21cm FAST, plus\ncontinuum models of both the diffuse Galactic synchrotron emission and the\nextragalactic point sources. We employ the CASA simulator and adopt the\nDillon-Parsons HERA configuration to generate a uv measurement set. We then use\nAIPS to calculate the closure phases as a function of frequency ('closure\nspectra'), and python scripts for subsequent analysis. We find that the closure\nspectra for the HI signal show dramatic structure in frequency, and based on\nthermal noise alone, the redundant HERA-331 array should detect these\nfluctuations easily. Comparatively, the frequency structure in the continuum\nclosure spectra is much smoother than that seen in the HI closure spectra.\nUnfortunately, when the line and continuum signals are combined, the continuum\ndominates the visibilities at the level of 10^3 to 10^4, and the line signal is\nlost. We have investigated fitting and removing smooth curves in frequency to\nthe line plus continuum closure spectra, and find that the continuum itself\nshows enough structure in frequency in the closure spectra to preclude\nseparation of the continuum and line based on such a process. We have also\nconsidered the subtraction of the continuum from the visibilities using a sky\nmodel, prior to calculation of the closure spectra. TRUNCATED. \n\n"}
{"id": "1607.00288", "contents": "Title: Evolution of the dust-to-metals ratio in high-redshift galaxies probed\n  by GRB-DLAs Abstract: Context. Several issues regarding the nature of dust at high redshift remain\nunresolved: its composition, its production and growth mechanisms, and its\neffect on background sources. Aims. We provide a more accurate relation between\ndust depletion levels and dust-to-metals ratio (DTM), and to use the DTM to\ninvestigate the origin and evolution of dust in the high-redshift Universe via\nGamma-ray burst damped Lyman-alpha absorbers (GRB-DLAs). Methods. We use\nabsorption-line measured metal column densities for a total of 19 GRB-DLAs,\nincluding five new GRB afterglow spectra from VLT/X-shooter. We use the latest\nlinear models to calculate the dust depletion strength factor in each DLA.\nUsing these values we calculate total dust and metal column densities to\ndetermine a DTM. We explore the evolution of DTM with metallicity, and compare\nit to previous trends in DTM measured with different methods. Results. We find\nsignificant dust depletion in 16 of our 19 GRB-DLAs, yet 18 of the 19 have a\nDTM significantly lower than the Milky Way. We find that DTM is positively\ncorrelated with metallicity, which supports a dominant ISM grain-growth mode of\ndust formation. We find a substantial discrepancy between the dust content\nmeasured from depletion and that derived from the total V-band extinction,\n$A_V$ , measured by fitting the afterglow SED. We advise against using a\nmeasurement from one method to estimate that from the other until the\ndiscrepancy can be resolved. \n\n"}
{"id": "1607.00898", "contents": "Title: Finding binary active galactic nuclei candidates by the centroid shift\n  in imaging surveys II. Testing the method with SDSS J233635.75-010733.7 Abstract: In Liu (2015), we propose selecting binary active galactic nuclei (AGNs)\ncandidates using the centroid shift of the images, which is induced by the\nnon-synchronous variations of the two nuclei. In this paper, a known binary AGN\n(SDSS J233635.75-010733.7) is employed to verify the ability of this method.\nUsing 162 exposures in the $R$ band of \\textit{Palomar Transient Factory}\n(PTF), an excess of dispersion in the positional distribution of the binary AGN\nis detected, though the two nuclei cannot be resolved in the images of PTF. We\nalso propose a new method to compare the position of the binary AGN in PTF $g$\nand $R$ band and find the difference is highly significant even only with 20\nexposures. This new method is efficient for two nuclei with different spectral\nenergy distributions, e.g., type I + type II AGN or off-set AGN. Large-scale\nsurveys, e.g., the Panoramic Survey Telescope and Rapid Response System and the\nLarge Synoptic Survey Telescope, are expected to discover a large sample of\nbinary AGN candidates with these methods. \n\n"}
{"id": "1607.01182", "contents": "Title: WISE x SuperCOSMOS photometric redshift catalog: 20 million galaxies\n  over 3pi steradians Abstract: We cross-match the two currently largest all-sky photometric catalogs,\nmid-infrared WISE and SuperCOSMOS scans of UKST/POSS-II photographic plates, to\nobtain a new galaxy sample that covers 3pi steradians. In order to characterize\nand purify the extragalactic dataset, we use external GAMA and SDSS\nspectroscopic information to define quasar and star loci in multicolor space,\naiding the removal of contamination from our extended-source catalog. After\nappropriate data cleaning we obtain a deep wide-angle galaxy sample that is\napproximately 95% pure and 90% complete at high Galactic latitudes. The catalog\ncontains close to 20 million galaxies over almost 70% of the sky, outside the\nZone of Avoidance and other confused regions, with a mean surface density of\nover 650 sources per square degree. Using multiwavelength information from two\noptical and two mid-IR photometric bands, we derive photometric redshifts for\nall the galaxies in the catalog, using the ANNz framework trained on the final\nGAMA-II spectroscopic data. Our sample has a median redshift of z_{med} = 0.2\nbut with a broad dN/dz reaching up to z>0.4. The photometric redshifts have a\nmean bias of |delta_z|~10^{-3}, normalized scatter of sigma_z = 0.033 and less\nthan 3% outliers beyond 3sigma_z. Comparison with external datasets shows no\nsignificant variation of photo-z quality with sky position. Together with the\noverall statistics, we also provide a more detailed analysis of photometric\nredshift accuracy as a function of magnitudes and colors. The final catalog is\nappropriate for `all-sky' 3D cosmology to unprecedented depths, in particular\nthrough cross-correlations with other large-area surveys. It should also be\nuseful for source pre-selection and identification in forthcoming surveys such\nas TAIPAN or WALLABY. \n\n"}
{"id": "1607.04218", "contents": "Title: Self-Consistent Modeling of Reionization in Cosmological Hydrodynamical\n  Simulations Abstract: The ultraviolet background (UVB) emitted by quasars and galaxies governs the\nionization and thermal state of the intergalactic medium (IGM), regulates the\nformation of high-redshift galaxies, and is thus a key quantity for modeling\ncosmic reionization. The vast majority of cosmological hydrodynamical\nsimulations implement the UVB via a set of spatially uniform photoionization\nand photoheating rates derived from UVB synthesis models. We show that\nsimulations using canonical UVB rates reionize and, perhaps more importantly,\nspuriously heat the IGM, much earlier z ~ 15 than they should. This problem\narises because at z > 6, where observational constraints are nonexistent, the\nUVB amplitude is far too high. We introduce a new methodology to remedy this\nissue, and we generate self-consistent photoionization and photoheating rates\nto model any chosen reionization history. Following this approach, we run a\nsuite of hydrodynamical simulations of different reionization scenarios and\nexplore the impact of the timing of reionization and its concomitant heat\ninjection on the the thermal state of the IGM. We present a comprehensive study\nof the pressure smoothing scale of IGM gas, illustrating its dependence on the\ndetails of both hydrogen and helium reionization, and argue that it plays a\nfundamental role in interpreting Lyman-alpha forest statistics and the thermal\nevolution of the IGM. The premature IGM heating we have uncovered implies that\nprevious work has likely dramatically overestimated the impact of\nphotoionization feedback on galaxy formation, which sets the minimum halo mass\nable to form stars at high redshifts. We make our new UVB photoionization and\nphotoheating rates publicly available for use in future simulations. \n\n"}
{"id": "1607.04637", "contents": "Title: Inference of Unresolved Point Sources At High Galactic Latitudes Using\n  Probabilistic Catalogs Abstract: Detection of point sources in images is a fundamental operation in\nastrophysics, and is crucial for constraining population models of the\nunderlying point sources or characterizing the background emission. Standard\ntechniques fall short in the crowded-field limit, losing sensitivity to faint\nsources and failing to track their covariance with close neighbors. We\nconstruct a Bayesian framework to perform inference of faint or overlapping\npoint sources. The method involves probabilistic cataloging, where samples are\ntaken from the posterior probability distribution of catalogs consistent with\nan observed photon count map. In order to validate our method we sample random\ncatalogs of the gamma-ray sky in the direction of the North Galactic Pole (NGP)\nby binning the data in energy and Point Spread Function (PSF) classes. Using\nthree energy bins spanning $0.3 - 1$, $1 - 3$ and $3 - 10$ GeV, we identify\n$270\\substack{+30 \\\\ -10}$ point sources inside a $40^\\circ \\times 40^\\circ$\nregion around the NGP above our point-source inclusion limit of $3 \\times\n10^{-11}$/cm$^2$/s/sr/GeV at the $1-3$ GeV energy bin. Modeling the flux\ndistribution as a power law, we infer the slope to be $-1.92\\substack{+0.07 \\\\\n-0.05}$ and estimate the contribution of point sources to the total emission as\n$18\\substack{+2 \\\\ -2}$\\%. These uncertainties in the flux distribution are\nfully marginalized over the number as well as the spatial and spectral\nproperties of the unresolved point sources. This marginalization allows a\nrobust test of whether the apparently isotropic emission in an image is due to\nunresolved point sources or of truly diffuse origin. \n\n"}
{"id": "1607.05764", "contents": "Title: Search for dark matter in proton-proton collisions at 8 TeV with missing\n  transverse momentum and vector boson tagged jets Abstract: A search is presented for an excess of events with large missing transverse\nmomentum in association with at least one highly energetic jet, in a data\nsample of proton-proton collisions at a centre-of-mass energy of 8 TeV. The\ndata correspond to an integrated luminosity of 19.7 inverse femtobarns\ncollected by the CMS experiment at the LHC. The results are interpreted using a\nset of simplified models for the production of dark matter via a scalar,\npseudoscalar, vector, or axial vector mediator. Additional sensitivity is\nachieved by tagging events consistent with the jets originating from a\nhadronically decaying vector boson. This search uses jet substructure\ntechniques to identify hadronically decaying vector bosons in both\nLorentz-boosted and resolved scenarios. This analysis yields improvements of\n80% in terms of excluded signal cross sections with respect to the previous CMS\nanalysis using the same data set. No significant excess with respect to the\nstandard model expectation is observed and limits are placed on the parameter\nspace of the simplified models. Mediator masses between 80 and 400 GeV in the\nscalar and pseudoscalar models, and up to 1.5 TeV in the vector and axial\nvector models, are excluded. \n\n"}
{"id": "1607.07918", "contents": "Title: Investigating the dusty torus of Seyfert galaxies using SOFIA/FORCAST\n  photometry Abstract: We present 31.5 micron imaging photometry of 11 nearby Seyfert galaxies\nobserved from the Stratospheric Observatory For Infrared Astronomy (SOFIA)\nusing the Faint Object infraRed CAmera for the SOFIA Telescope (FORCAST). We\ntentatively detect extended 31 micron emission for the first time in our\nsample. In combination with this new data set, subarcsecond resolution 1-18\nmicron imaging and 7.5-13 micron spectroscopic observations were used to\ncompute the nuclear spectral energy distribution (SED) of each galaxy. We found\nthat the turnover of the torus emission does not occur at wavelengths <31.5\nmicron, which we interpret as a lower-limit for the wavelength of peak\nemission. We used CLUMPY torus models to fit the nuclear infrared (IR) SED and\ninfer trends in the physical parameters of the AGN torus for the galaxies in\nthe sample. Including the 31.5 micron nuclear flux in the SED 1) reduces the\nnumber of clumpy torus models compatible with the data, and 2) modifies the\nmodel output for the outer radial extent of the torus for 10 of the 11 objects.\nSpecifically, six (60%) objects show a decrease in radial extent while four\n(40%) show an increase. We find torus outer radii ranging from <1pc to 8.4 pc \n\n"}
{"id": "1607.08697", "contents": "Title: Exploring the Sensitivity of Next Generation Gravitational Wave\n  Detectors Abstract: The second-generation of gravitational-wave detectors are just starting\noperation, and have already yielding their first detections. Research is now\nconcentrated on how to maximize the scientific potential of gravitational-wave\nastronomy. To support this effort, we present here design targets for a new\ngeneration of detectors, which will be capable of observing compact binary\nsources with high signal-to-noise ratio throughout the Universe. \n\n"}
{"id": "1607.08751", "contents": "Title: Novel directed search strategy to detect continuous gravitational waves\n  from neutron stars in low- and high-eccentricity binary systems Abstract: We describe a novel, very fast and robust, directed search incoherent method\nfor periodic gravitational waves (GWs) from neutron stars in binary systems. As\ndirected search, we assume the source sky position to be known with enough\naccuracy, but all other parameters are supposed to be unknown. We exploit the\nfrequency-modulation due to source orbital motion to unveil the signal\nsignature by commencing from a collection of time and frequency peaks. We\nvalidate our pipeline adding 131 artificial continuous GW signals from pulsars\nin binary systems to simulated detector Gaussian noise, characterized by a\npower spectral density Sh = 4x10^-24 Hz^-1/2 in the frequency interval [70,\n200] Hz, which is overall commensurate with the advanced detector design\nsensitivities. The pipeline detected 128 signals, and the weakest signal\ninjected and detected has a GW strain amplitude of ~10^-24, assuming one month\nof gapless data collected by a single advanced detector. We also provide\nsensitivity estimations, which show that, for a single- detector data covering\none month of observation time, depending on the source orbital Doppler\nmodulation, we can detect signals with an amplitude of ~7x10^-25. By using\nthree detectors, and one year of data, we would easily gain more than a factor\n3 in sensitivity, translating into being able to detect weaker signals. We also\ndiscuss the parameter estimate proficiency of our method, as well as\ncomputational budget, which is extremely cheap. In fact, sifting one month of\nsingle-detector data and 131 Hz-wide frequency range takes roughly 2.4 CPU\nhours. Due to the high computational speed, the current procedure can be\nreadily applied in ally-sky schemes, sieving in parallel as many sky positions\nas permitted by the available computational power. \n\n"}
{"id": "1608.01733", "contents": "Title: The IPAC Image Subtraction and Discovery Pipeline for the intermediate\n  Palomar Transient Factory Abstract: We describe the near real-time transient-source discovery engine for the\nintermediate Palomar Transient Factory (iPTF), currently in operations at the\nInfrared Processing and Analysis Center (IPAC), Caltech. We coin this system\nthe IPAC/iPTF Discovery Engine (or IDE). We review the algorithms used for\nPSF-matching, image subtraction, detection, photometry, and machine-learned\n(ML) vetting of extracted transient candidates. We also review the performance\nof our ML classifier. For a limiting signal-to-noise ratio of 4 in relatively\nunconfused regions, \"bogus\" candidates from processing artifacts and imperfect\nimage subtractions outnumber real transients by ~ 10:1. This can be\nconsiderably higher for image data with inaccurate astrometric and/or\nPSF-matching solutions. Despite this occasionally high contamination rate, the\nML classifier is able to identify real transients with an efficiency (or\ncompleteness) of ~ 97% for a maximum tolerable false-positive rate of 1% when\nclassifying raw candidates. All subtraction-image metrics, source features, ML\nprobability-based real-bogus scores, contextual metadata from other surveys,\nand possible associations with known Solar System objects are stored in a\nrelational database for retrieval by the various science working groups. We\nreview our efforts in mitigating false-positives and our experience in\noptimizing the overall system in response to the multitude of science projects\nunderway with iPTF. \n\n"}
{"id": "1608.02013", "contents": "Title: The Thirteenth Data Release of the Sloan Digital Sky Survey: First\n  Spectroscopic Data from the SDSS-IV Survey MApping Nearby Galaxies at Apache\n  Point Observatory Abstract: The fourth generation of the Sloan Digital Sky Survey (SDSS-IV) began\nobservations in July 2014. It pursues three core programs: APOGEE-2, MaNGA, and\neBOSS. In addition, eBOSS contains two major subprograms: TDSS and SPIDERS.\nThis paper describes the first data release from SDSS-IV, Data Release 13\n(DR13), which contains new data, reanalysis of existing data sets and, like all\nSDSS data releases, is inclusive of previously released data. DR13 makes\npublicly available 1390 spatially resolved integral field unit observations of\nnearby galaxies from MaNGA, the first data released from this survey. It\nincludes new observations from eBOSS, completing SEQUELS. In addition to\ntargeting galaxies and quasars, SEQUELS also targeted variability-selected\nobjects from TDSS and X-ray selected objects from SPIDERS. DR13 includes new\nreductions of the SDSS-III BOSS data, improving the spectrophotometric\ncalibration and redshift classification. DR13 releases new reductions of the\nAPOGEE-1 data from SDSS-III, with abundances of elements not previously\nincluded and improved stellar parameters for dwarf stars and cooler stars. For\nthe SDSS imaging data, DR13 provides new, more robust and precise photometric\ncalibrations. Several value-added catalogs are being released in tandem with\nDR13, in particular target catalogs relevant for eBOSS, TDSS, and SPIDERS, and\nan updated red-clump catalog for APOGEE. This paper describes the location and\nformat of the data now publicly available, as well as providing references to\nthe important technical papers that describe the targeting, observing, and data\nreduction. The SDSS website, http://www.sdss.org, provides links to the data,\ntutorials and examples of data access, and extensive documentation of the\nreduction and analysis procedures. DR13 is the first of a scheduled set that\nwill contain new data and analyses from the planned ~6-year operations of\nSDSS-IV. \n\n"}
{"id": "1608.03578", "contents": "Title: The comptonization parameter from simulations of single-frequency,\n  single-dish, dual-beam, cm-wave observations of galaxy clusters and\n  mitigating CMB confusion using the Planck sky survey Abstract: Systematic effects in dual-beam, differential, radio observations of extended\nobjects are discussed in the context of the One Centimeter Receiver Array\n(OCRA). We use simulated samples of Sunyaev-Zel'dovich (SZ) galaxy clusters at\nlow ($z<0.4$) and intermediate ($0.4<z<1.0$) redshifts to study the\nimplications of operating at a single frequency (30 GHz) on the accuracy of\nextracting SZ flux densities and of reconstructing comptonization parameters\nwith OCRA. We analyze dependences on cluster mass, redshift, observation\nstrategy, and telescope pointing accuracy. Using $Planck$ data to make primary\ncosmic microwave background (CMB) templates, we test the feasibility of\nmitigating CMB confusion effects in observations of SZ profiles at angular\nscales larger than the separation of the receiver beams. \n\n"}
{"id": "1608.04297", "contents": "Title: A new direction for dark matter research: intermediate mass compact halo\n  objects Abstract: The failure to find evidence for elementary particles that could serve as the\nconstituents of dark matter brings to mind suggestions that dark matter might\nconsist of massive compact objects (MACHOs). In particular, it has recently\nbeen argued that MACHOs with masses > 15 solar masses may have been\nprolifically produced at the onset of the big bang. Although a variety of\nastrophysical signatures for primordial MACHOs with masses in this range have\nbeen discussed in the literature, we favor a strategy that uses the potential\nfor gravitational microlensing of stars outside our galaxy to directly detect\nthe presence of MACHOs in the halo of our galaxy. We point out that the effect\nof the motion of the Earth on the shape of the microlensing brightening curves\nprovides a promising approach to confirming over the course of next several\nyears that dark matter consists of MACHOs. \n\n"}
{"id": "1608.05423", "contents": "Title: Photometric classification of type Ia supernovae in the SuperNova Legacy\n  Survey with supervised learning Abstract: In the era of large astronomical surveys, photometric classification of\nsupernovae (SNe) has become an important research field due to limited\nspectroscopic resources for candidate follow-up and classification. In this\nwork, we present a method to photometrically classify type Ia supernovae based\non machine learning with redshifts that are derived from the SN light-curves.\nThis method is implemented on real data from the SNLS deferred pipeline, a\npurely photometric pipeline that identifies SNe Ia at high-redshifts\n($0.2<z<1.1$).\n  Our method consists of two stages: feature extraction (obtaining the SN\nredshift from photometry and estimating light-curve shape parameters) and\nmachine learning classification. We study the performance of different\nalgorithms such as Random Forest and Boosted Decision Trees. We evaluate the\nperformance using SN simulations and real data from the first 3 years of the\nSupernova Legacy Survey (SNLS), which contains large spectroscopically and\nphotometrically classified type Ia samples. Using the Area Under the Curve\n(AUC) metric, where perfect classification is given by 1, we find that our\nbest-performing classifier (Extreme Gradient Boosting Decision Tree) has an AUC\nof $0.98$.\n  We show that it is possible to obtain a large photometrically selected type\nIa SN sample with an estimated contamination of less than $5\\%$. When applied\nto data from the first three years of SNLS, we obtain 529 events. We\ninvestigate the differences between classifying simulated SNe, and real SN\nsurvey data. In particular, we find that applying a thorough set of selection\ncuts to the SN sample is essential for good classification. This work\ndemonstrates for the first time the feasibility of machine learning\nclassification in a high-$z$ SN survey with application to real SN data. \n\n"}
{"id": "1608.06262", "contents": "Title: ICE: a scalable, low-cost FPGA-based telescope signal processing and\n  networking system Abstract: We present an overview of the 'ICE' hardware and software framework that\nimplements large arrays of interconnected FPGA-based data acquisition, signal\nprocessing and networking nodes economically. The system was conceived for\napplication to radio, millimeter and sub-millimeter telescope readout systems\nthat have requirements beyond typical off-the-shelf processing systems, such as\ncareful control of interference signals produced by the digital electronics,\nand clocking of all elements in the system from a single precise\nobservatory-derived oscillator. A new generation of telescopes operating at\nthese frequency bands and designed with a vastly increased emphasis on digital\nsignal processing to support their detector multiplexing technology or\nhigh-bandwidth correlators---data rates exceeding a terabyte per second---are\nbecoming common. The ICE system is built around a custom FPGA motherboard that\nmakes use of an Xilinx Kintex-7 FPGA and ARM-based co-processor. The system is\nspecialized for specific applications through software, firmware, and custom\nmezzanine daughter boards that interface to the FPGA through the\nindustry-standard FMC specifications. For high density applications, the\nmotherboards are packaged in 16-slot crates with ICE backplanes that implement\na low-cost passive full-mesh network between the motherboards in a crate, allow\nhigh bandwidth interconnection between crates, and enable data offload to a\ncomputer cluster. A Python-based control software library automatically detects\nand operates the hardware in the array. Examples of specific telescope\napplications of the ICE framework are presented, namely the\nfrequency-multiplexed bolometer readout systems used for the SPT and Simons\nArray and the digitizer, F-engine, and networking engine for the CHIME and\nHIRAX radio interferometers. \n\n"}
{"id": "1608.08224", "contents": "Title: Long-Term X-ray Variability of Typical Active Galactic Nuclei in the\n  Distant Universe Abstract: We perform long-term ($\\approx 15$ yr, observed-frame) X-ray variability\nanalyses of the 68 brightest radio-quiet active galactic nuclei (AGNs) in the 6\nMs $Chandra$ Deep Field-South (CDF-S) survey; the majority are in the redshift\nrange of $0.6-3.1$, providing access to penetrating rest-frame X-rays up to\n$\\approx 10-30$ keV. Twenty-four of the 68 sources are optical spectral type I\nAGNs, and the rest (44) are type II AGNs. The time scales probed in this work\nare among the longest for X-ray variability studies of distant AGNs.\nPhotometric analyses reveal widespread photon-flux variability: $90\\%$ of AGNs\nare variable above a 95% confidence level, including many X-ray obscured AGNs\nand several optically classified type II quasars. We characterize the intrinsic\nX-ray luminosity ($L_{\\rm{X}}$) and absorption ($N_{\\rm{H}}$) variability via\nspectral fitting. Most (74%) sources show $L_{\\rm{X}}$ variability; the\nvariability amplitudes are generally smaller for quasars. A Compton-thick\ncandidate AGN shows variability of its high-energy X-ray flux, indicating the\nsize of reflecting material to be $\\lesssim 0.3$ pc. $L_{\\rm{X}}$ variability\nis also detected in a broad absorption line (BAL) quasar. The $N_{\\rm{H}}$\nvariability amplitude for our sample appears to rise as time separation\nincreases. About 16% of sources show $N_{\\rm{H}}$ variability. One source\ntransitions from an X-ray unobscured to obscured state while its optical\nclassification remains type I; this behavior indicates the X-ray eclipsing\nmaterial is not large enough to obscure the whole broad-line region. \n\n"}
{"id": "1608.08621", "contents": "Title: Dust-depletion sequences in damped Lyman-{\\alpha} absorbers: a unified\n  picture from low-metallicity systems to the Galaxy Abstract: We study metal depletion due to dust in the interstellar medium (ISM) to\ninfer the properties of dust grains and characterize the metal and dust content\nof galaxies, down to low metallicity and intermediate redshift z. We provide\nmetal column densities and abundances of a sample of 70 damped Lyman-{\\alpha}\nabsorbers (DLAs) towards quasars, observed at high spectral resolution with the\nVery Large Telescope (VLT) Ultraviolet and Visual Echelle Spectrograph (UVES).\nThis is the largest sample of phosphorus abundances measured in DLAs so far. We\nuse literature measurements for Galactic clouds to cover the high-metallicity\nend. We discover tight (scatter <= 0.2 dex) correlations between [Zn/Fe] and\nthe observed relative abundances from dust depletion. This implies that grain\ngrowth in the ISM is an important process of dust production. These sequences\nare continuous in [Zn/Fe] from dust-free to dusty DLAs, and to Galactic clouds,\nsuggesting that the availability of refractory metals in the ISM is crucial for\ndust production, regardless of the star formation history. We observe [S/Zn] up\nto ~ 0.25 dex in DLAs, which is broadly consistent with Galactic stellar\nabundances. Furthermore, we find a good agreement between the nucleosynthetic\npattern of Galactic halo stars and our observations of the least dusty DLAs.\nThis supports recent star formation in low-metallicity DLAs. The derived\ndepletions of Zn, O, P, S, Si, Mg, Mn, Cr, and Fe correlate with [Zn/Fe], with\nsteeper slopes for more refractory elements. P is mostly not affected by dust\ndepletion. We present canonical depletion patterns, to be used as reference in\nfuture studies of relative abundances and depletion. We derive the total\n(dust-corrected) metallicity, typically -2 <= [M/H]tot <= 0 for DLAs, and\nscattered around solar metallicity for the Galactic ISM. The dust-to-metal\nratio increases with metallicity... [abridged] \n\n"}
{"id": "1608.08632", "contents": "Title: Dark Sectors 2016 Workshop: Community Report Abstract: This report, based on the Dark Sectors workshop at SLAC in April 2016,\nsummarizes the scientific importance of searches for dark sector dark matter\nand forces at masses beneath the weak-scale, the status of this broad\ninternational field, the important milestones motivating future exploration,\nand promising experimental opportunities to reach these milestones over the\nnext 5-10 years. \n\n"}
{"id": "1608.08801", "contents": "Title: Non-Gaussianity in multi-sound-speed disformally coupled inflation Abstract: Most, if not all, scalar-tensor theories are equivalent to General Relativity\nwith a disformally coupled matter sector. In extra-dimensional theories such a\ncoupling can be understood as a result of induction of the metric on a brane\nthat matter is confined to. This article presents a first look at the\nnon-Gaussianities in disformally coupled inflation, a simple two-field model\nthat features a novel kinetic interaction. Cases with both canonical and\nDirac-Born-Infeld (DBI) kinetic terms are taken into account, the latter\nmotivated by the possible extra-dimensional origin of the disformality. The\ncomputations are carried out for the equilateral configuration in the slow-roll\nregime, wherein it is found that the non-Gaussianity is typically rather small\nand negative. This is despite the fact that the new kinetic interaction causes\nthe perturbation modes to propagate with different sounds speeds, which may\nboth significantly deviate from unity during inflation. \n\n"}
{"id": "1609.00818", "contents": "Title: Probabilistic multi-catalogue positional cross-match Abstract: We lay the foundations of a statistical framework for multi-catalogue\ncross-correlation and cross-identification based on explicit simplified\ncatalogue models. A proper identification process should rely on both\nastrometric and photometric data. Under some conditions, the astrometric part\nand the photometric part can be processed separately and merged a posteriori to\nprovide a single global probability of identification. The present paper\naddresses almost exclusively the astrometrical part and specifies the proper\nprobabilities to be merged with photometric likelihoods.\n  To select matching candidates in n catalogues, we used the Chi (or,\nindifferently, the Chi-square) test with 2(n-1) degrees of freedom. We thus\ncall this cross-match a chi-match. In order to use Bayes' formula, we\nconsidered exhaustive sets of hypotheses based on combinatorial analysis. The\nvolume of the Chi-test domain of acceptance -- a 2(n-1)-dimensional acceptance\nellipsoid -- is used to estimate the expected numbers of spurious associations.\nWe derived priors for those numbers using a frequentist approach relying on\nsimple geometrical considerations. Likelihoods are based on standard Rayleigh,\nChi and Poisson distributions that we normalized over the Chi-test acceptance\ndomain. We validated our theoretical results by generating and cross-matching\nsynthetic catalogues.\n  The results we obtain do not depend on the order used to cross-correlate the\ncatalogues. We applied the formalism described in the present paper to build\nthe multi-wavelength catalogues used for the science cases of the ARCHES\n(Astronomical Resource Cross-matching for High Energy Studies) project. Our\ncross-matching engine is publicly available through a multi-purpose web\ninterface. In a longer term, we plan to integrate this tool into the CDS XMatch\nService. \n\n"}
{"id": "1609.01714", "contents": "Title: The Effect of Fiber Collisions on the Galaxy Power Spectrum Multipole Abstract: Fiber-fed multi-object spectroscopic surveys, with their ability to collect\nan unprecedented number of redshifts, currently dominate large-scale structure\nstudies. However, physical constraints limit these surveys from successfully\ncollecting redshifts from galaxies too close to each other on the focal plane.\nThis ultimately leads to significant systematic effects on galaxy clustering\nmeasurements. Using simulated mock catalogs, we demonstrate that fiber\ncollisions have a significant impact on the power spectrum, $P(k)$, monopole\nand quadrupole that exceeds sample variance at scales smaller than\n$k\\sim0.1~h/Mpc$.\n  We present two methods to account for fiber collisions in the power spectrum.\nThe first, statistically reconstructs the clustering of fiber collided galaxy\npairs by modeling the distribution of the line-of-sight displacements between\nthem. It also properly accounts for fiber collisions in the shot-noise\ncorrection term of the $P(k)$ estimator. Using this method, we recover the true\n$P(k)$ monopole of the mock catalogs with residuals of $<0.5\\%$ at\n$k=0.3~h/Mpc$ and $<4\\%$ at $k=0.83~h/Mpc$ -- a significant improvement over\nexisting correction methods. The quadrupole, however, does not improve\nsignificantly.\n  The second method models the effect of fiber collisions on the power spectrum\nas a convolution with a configuration space top-hat function that depends on\nthe physical scale of fiber collisions. It directly computes theoretical\npredictions of the fiber-collided $P(k)$ multipoles and reduces the influence\nof smaller scales to a set of nuisance parameters. Using this method, we\nreliably model the effect of fiber collisions on the monopole and quadrupole\ndown to the scale limits of theoretical predictions. The methods we present in\nthis paper will allow us to robustly analyze galaxy power spectrum multipole\nmeasurements to much smaller scales than previously possible. \n\n"}
{"id": "1609.04172", "contents": "Title: Gaia Data Release 1. Summary of the astrometric, photometric, and survey\n  properties Abstract: At about 1000 days after the launch of Gaia we present the first Gaia data\nrelease, Gaia DR1, consisting of astrometry and photometry for over 1 billion\nsources brighter than magnitude 20.7. We summarize Gaia DR1 and provide\nillustrations of the scientific quality of the data, followed by a discussion\nof the limitations due to the preliminary nature of this release. Gaia DR1\nconsists of: a primary astrometric data set which contains the positions,\nparallaxes, and mean proper motions for about 2 million of the brightest stars\nin common with the Hipparcos and Tycho-2 catalogues and a secondary astrometric\ndata set containing the positions for an additional 1.1 billion sources. The\nsecond component is the photometric data set,consisting of mean G-band\nmagnitudes for all sources. The G-band light curves and the characteristics of\n~3000 Cepheid and RR Lyrae stars, observed at high cadence around the south\necliptic pole, form the third component. For the primary astrometric data set\nthe typical uncertainty is about 0.3 mas for the positions and parallaxes, and\nabout 1 mas/yr for the proper motions. A systematic component of ~0.3 mas\nshould be added to the parallax uncertainties. For the subset of ~94000\nHipparcos stars in the primary data set, the proper motions are much more\nprecise at about 0.06 mas/yr. For the secondary astrometric data set, the\ntypical uncertainty of the positions is ~10 mas. The median uncertainties on\nthe mean G-band magnitudes range from the mmag level to ~0.03 mag over the\nmagnitude range 5 to 20.7. Gaia DR1 represents a major advance in the mapping\nof the heavens and the availability of basic stellar data that underpin\nobservational astrophysics. Nevertheless, the very preliminary nature of this\nfirst Gaia data release does lead to a number of important limitations to the\ndata quality which should be carefully considered before drawing conclusions\nfrom the data. \n\n"}
{"id": "1609.05893", "contents": "Title: \\bf $\\delta M$ Formalism: A New Approach to Cosmological Perturbation\n  Theory in Anisotropic Inflation Abstract: We study the evolution of the metric perturbations in a Bianchi background in\nthe long-wavelength limit. By applying the gradient expansion to the equations\nof motion we exhibit a generalized \"Separate Universe\" approach to the\ncosmological perturbation theory. Having found this consistent separate\nuniverse picture, we introduce the $\\delta M $ formalism for calculating the\nevolution of the linear tensor perturbations in anisotropic inflation models in\n{\\it almost} the same way that the so-called $\\delta N$ formula is applied to\nthe super-horizon dynamics of the curvature perturbations. Similar to her twin\nformula, $\\delta N$, this new method can substantially reduce the amount of\ncalculations related to the evolution of tensor modes. However, it is not as\ngeneral as $\\delta N$, it is a \"perturbative\" formula and solves the shear only\nto linear order. In other words, it is restricted to weak shear limit. \n\n"}
{"id": "1609.05931", "contents": "Title: The Log Log Prior for the Frequency of Extraterrestrial Intelligences Abstract: It is unclear how frequently life and intelligence arise on planets. I\nconsider a Bayesian prior for the probability P(ETI) that intelligence evolves\nat a suitable site, with weight distributed evenly over ln(1 - ln P(ETI)). This\nlog log prior can handle a very wide range of P(ETI) values, from 1 to\n10^(-10^122), while remaining responsive to evidence about extraterrestrial\nsocieties. It is motivated by our uncertainty in the number of conditions that\nmust be fulfilled for intelligence to arise, and it is related to\nconsiderations of information, entropy, and state space dimensionality. After\nsetting a lower limit to P(ETI) from the number of possible genome sequences, I\ncalculate a Bayesian confidence of 18% that aliens exist within the observable\nUniverse. With different assumptions about the minimum P(ETI) and the number of\ntimes intelligence can appear on a planet, this value falls between 1.4% and\n47%. Overall, the prior leans towards our being isolated from extraterrestrial\nintelligences, but indicates that we should not be confident of this\nconclusion. I discuss the implications of the prior for the Search for\nExtraterrestrial Intelligence, concluding that searches for interstellar probes\nfrom nearby societies seem relatively effective. I also discuss the possibility\nof very small probabilities allowed by the prior for the origin of life and the\nFermi Paradox, and note that similar priors might be constructed for\ninteresting complex phenomena in general. \n\n"}
{"id": "1609.06728", "contents": "Title: ASTErIsM - Application of topometric clustering algorithms in automatic\n  galaxy detection and classification Abstract: We present a study on galaxy detection and shape classification using\ntopometric clustering algorithms. We first use the DBSCAN algorithm to extract,\nfrom CCD frames, groups of adjacent pixels with significant fluxes and we then\napply the DENCLUE algorithm to separate the contributions of overlapping\nsources. The DENCLUE separation is based on the localization of pattern of\nlocal maxima, through an iterative algorithm which associates each pixel to the\nclosest local maximum. Our main classification goal is to take apart elliptical\nfrom spiral galaxies. We introduce new sets of features derived from the\ncomputation of geometrical invariant moments of the pixel group shape and from\nthe statistics of the spatial distribution of the DENCLUE local maxima\npatterns. Ellipticals are characterized by a single group of local maxima,\nrelated to the galaxy core, while spiral galaxies have additional ones related\nto segments of spiral arms. We use two different supervised ensemble\nclassification algorithms, Random Forest, and Gradient Boosting. Using a sample\nof ~ 24000 galaxies taken from the Galaxy Zoo 2 main sample with spectroscopic\nredshifts, and we test our classification against the Galaxy Zoo 2 catalog. We\nfind that features extracted from our pipeline give on average an accuracy of ~\n93%, when testing on a test set with a size of 20% of our full data set, with\nfeatures deriving from the angular distribution of density attractor ranking at\nthe top of the discrimination power. \n\n"}
{"id": "1610.01794", "contents": "Title: Cosmic ray composition measurements and cosmic ray background free\n  gamma-ray observations with Cherenkov telescopes Abstract: Muon component of extensive air showers (EAS) initiated by cosmic ray\nparticles carries information on the primary particle identity. We show that\nthe muon content of EAS could be measured in a broad energy range from 10-100\nTeV up to ultra-high-energy cosmic ray range using wide field-of-view imaging\natmospheric Cherenkov telescopes observing strongly inclined or nearly\nhorizontal EAS from the ground of from high altitude. Cherenkov emission from\nmuons in such EAS forms a distinct component (halo or tail) of the EAS image in\nthe telescope camera. We show that detection of the muon signal could be used\nto measure composition of the cosmic ray spectrum in the energy ranges of the\nknee, the ankle and of the Galactic-to-extragalactic transition. It could also\nbe used to veto the cosmic ray background in gamma-ray observations. This\ntechnique provides a possibility for up to two orders of magnitude improvement\nof sensitivity for gamma-ray flux in the energy band above 10 PeV, compared to\nKASCADE-Grande, and an order-of-magnitude improvement of sensitivity in the\nmulti-EeV energy band, compared to Pierre Auger Observatory. \n\n"}
{"id": "1610.02899", "contents": "Title: The Medium Size Telescopes of the Cherenkov Telescope Array Abstract: The Cherenkov Telescope Array (CTA) is the planned next-generation instrument\nfor ground-based gamma-ray astronomy, covering a photon energy range of ~20 GeV\nto above 100 TeV. CTA will consist of the order of 100 telescopes of three\nsizes, installed at two sites in the Northern and Southern Hemisphere. This\ncontribution deals with the 12 meter Medium Size Telescopes (MST) having a\nsingle mirror (modified Davies-Cotton, DC) design. In the baseline design of\nthe CTA arrays, 25 MSTs in the South and 15 MSTs in the North provide the\nnecessary sensitivity for CTA in the core energy range of 100 GeV to 10 TeV.\nDC-MSTs will be equipped with photomultiplier (PMT)-based cameras. Two options\nare available for these focal plane instruments, that will be provided by the\nFlashCam and the NectarCAM sub-consortia. In this contribution, a short\nintroduction to the projects and their status is given. \n\n"}
{"id": "1610.03489", "contents": "Title: GeMS/GSAOI photometric and astrometric performance in dense stellar\n  fields Abstract: Ground-based imagers at 8m class telescopes assisted by Multi conjugate\nAdaptive Optics are primary facilities to obtain accurate photometry and proper\nmotions in dense stellar fields. We observed the central region of the globular\nclusters Liller 1 and NGC 6624 with the Gemini Multi-conjugate adaptive optics\nSystem (GeMS) feeding the Gemini South Adaptive Optics Imager (GSAOI) currently\navailable at the Gemini South telescope, under different observing conditions.\nWe characterized the stellar Point Spread Function (PSF) in terms of Full Width\nat Half Maximum (FWHM), Strehl Ratio (SR) and Encircled Energy (EE), over the\nfield of view. We found that, for sub-arcsec seeing at the observed airmass,\ndiffraction limit PSF FWHM ($\\approx$ 80 mas), SR $\\sim40\\%$ and EE $\\ge50\\%$\nwith a dispersion around $10\\%$ over the 85\" x 85\" field of view, can be\nobtained in the $K_s$ band. In the $J$ band the best images provide FWHMs\nbetween 60 and 80 mas, SR $>10\\%$ and EE $>40\\%$. For seeing at the observed\nairmass exceeding 1\", the performance worsen but it is still possible to\nperform PSF fitting photometry with $25\\%$ EE in $J$ and $40\\%$ in $K_s$. We\nalso computed the geometric distortions of GeMS/GSAOI and we obtained corrected\nimages with an astrometric accuracy of $\\sim$1 mas in a stellar field with high\ncrowding. \n\n"}
{"id": "1610.04365", "contents": "Title: Accurate Polarization Calibration at 800 MHz with the Green Bank\n  Telescope Abstract: Polarization leakage of foreground synchrotron emission is a critical issue\nin HI intensity mapping experiments. While the sought-after HI emission is\nunpolarized, polarized foregrounds such as Galactic and extragalactic\nsynchrotron radiation, if coupled with instrumental impurity, can mimic or\noverwhelm the HI signals. In this paper we present the methodology for\npolarization calibration at 700-900 MHz, applied on data obtained from the\nGreen Bank Telescope (GBT). We use astrophysical sources, both polarized and\nunpolarized sources including quasars and pulsars, as calibrators to\ncharacterize the polarization leakage and control systematic effects in our GBT\nHI intensity mapping project. The resulting fractional errors on polarization\nmeasurements on boresight are well controlled to within 0.6%-0.8% of their\ntotal intensity. The polarized beam patterns are measured by performing spider\nscans across both polarized quasars and pulsars. A dominant Stokes I to V\nleakage feature and secondary features of Stokes I to Q and I to U leakages in\nthe 700-900 MHz frequency range are identified. These characterizations are\nimportant for separating foreground polarization leakage from the HI 21 cm\nsignal. \n\n"}
{"id": "1610.04606", "contents": "Title: KiDS-450: Testing extensions to the standard cosmological model Abstract: We test extensions to the standard cosmological model with weak gravitational\nlensing tomography using 450 deg$^2$ of imaging data from the Kilo Degree\nSurvey (KiDS). In these extended cosmologies, which include massive neutrinos,\nnonzero curvature, evolving dark energy, modified gravity, and running of the\nscalar spectral index, we also examine the discordance between KiDS and cosmic\nmicrowave background measurements from Planck. The discordance between the two\ndatasets is largely unaffected by a more conservative treatment of the lensing\nsystematics and the removal of angular scales most sensitive to nonlinear\nphysics. The only extended cosmology that simultaneously alleviates the\ndiscordance with Planck and is at least moderately favored by the data includes\nevolving dark energy with a time-dependent equation of state (in the form of\nthe $w_0-w_a$ parameterization). In this model, the respective $S_8 = \\sigma_8\n\\sqrt{\\Omega_{\\rm m}/0.3}$ constraints agree at the $1\\sigma$ level, and there\nis `substantial concordance' between the KiDS and Planck datasets when\naccounting for the full parameter space. Moreover, the Planck constraint on the\nHubble constant is wider than in LCDM and in agreement with the Riess et al.\n(2016) direct measurement of $H_0$. The dark energy model is moderately favored\nas compared to LCDM when combining the KiDS and Planck measurements, and\nremains moderately favored after including an informative prior on the Hubble\nconstant. In both of these scenarios, marginalized constraints in the $w_0-w_a$\nplane are discrepant with a cosmological constant at the $3\\sigma$ level.\nMoreover, KiDS constrains the sum of neutrino masses to 4.0 eV (95% CL), finds\nno preference for time or scale dependent modifications to the metric\npotentials, and is consistent with flatness and no running of the spectral\nindex. The analysis code is public at https://github.com/sjoudaki/kids450 \n\n"}
{"id": "1610.06729", "contents": "Title: Estimate of the Fermi Large Area Telescope sensitivity to gamma-ray\n  polarization Abstract: Although not designed primarily as a polarimeter, the \\textit{Fermi}-Large\nArea Telescope (LAT) has the potential to detect high degrees of linear\npolarization from some of the brightest gamma-ray sources. To achieve the\nneeded accuracy in the reconstruction of the event geometry, low-energy\n($\\leq200$ MeV) events converting in the silicon detector layers of the LAT\ntracker have to be used. We present preliminary results of the ongoing effort\nwithin the LAT collaboration to measure gamma-ray polarization. We discuss the\nstatistical and systematic uncertainties affecting such a measurement. We show\nthat a $5\\sigma$ minimum detectable polarization (MDP) of $\\approx30-50\\%$\ncould be within reach for the brightest gamma-ray sources as the Vela and Crab\npulsars and the blazar 3C 454.3, after 10 years of observation. To estimate the\nsystematic uncertainties, we stack bright AGN, and use this stack as a test\nsource. LAT sensitivity to polarization is estimated comparing the data to a\nsimulation of the expected unpolarized emission of the stack. We measure a\n5$\\sigma$ sensitivity limit corresponding to a polarization degree of\n$\\approx37\\%$. This is in agreement with a purely statistical estimate,\nsuggesting that the systematic errors are likely to be small compared to the\nstatistical ones. \n\n"}
{"id": "1610.07604", "contents": "Title: Cosmic Microwave Background Science at Commercial Airline Altitudes Abstract: Obtaining high-sensitivity measurements of degree-scale cosmic microwave\nbackground (CMB) polarization is the most direct path to detecting primordial\ngravitational waves. Robustly recovering any primordial signal from the\ndominant foreground emission will require high-fidelity observations at\nmultiple frequencies, with excellent control of systematics. We explore the\npotential for a new platform for CMB observations, the Airlander 10 hybrid air\nvehicle, to perform this task. We show that the Airlander 10 platform,\noperating at commercial airline altitudes, is well-suited to mapping\nfrequencies above 220 GHz, which are critical for cleaning CMB maps of dust\nemission. Optimizing the distribution of detectors across frequencies, we\nforecast the ability of Airlander 10 to clean foregrounds of varying complexity\nas a function of altitude, demonstrating its complementarity with both existing\n(Planck) and ongoing (C-BASS) foreground observations. This novel platform\ncould play a key role in defining our ultimate view of the polarized microwave\nsky. \n\n"}
{"id": "1610.09121", "contents": "Title: Interferometric Monitoring of Gamma-ray Bright AGNs I: Results of\n  Single-epoch Multifrequency Observations Abstract: We present results of single-epoch very long baseline interferometry (VLBI)\nobservations of gamma-ray bright active galactic nuclei (AGNs) using the Korean\nVLBI Network (KVN) at 22, 43, 86, and 129~GHz bands, which are part of a KVN\nkey science program, Interferometric Monitoring of Gamma-ray Bright AGNs\n(iMOGABA). We selected a total of 34 radio-loud AGNs of which 30 sources are\ngamma-ray bright AGNs with flux densities of\n$>6\\times10^{-10}$~ph~cm$^{-2}$~s$^{-1}$. Single-epoch multi-frequency VLBI\nobservations of the target sources were conducted during a 24-hr session on\n2013 November 19 and 20. All observed sources were detected and imaged at all\nfrequency bands with or without a frequency phase transfer technique which\nenabled the imaging of 12 faint sources at 129~GHz, except for one source. Many\nof the target sources are resolved on milliarcsecond scales, yielding a\ncore-jet structure with the VLBI core dominating the synchrotron emission on\nthe milliarcsecond scale. CLEAN flux densities of the target sources are\n0.43-28~Jy, 0.32-21~Jy, 0.18-11~Jy, and 0.35-8.0~Jy in the 22, 43, 86, and\n129~GHz bands, respectively. \n\n"}
{"id": "1610.09591", "contents": "Title: Grackle: a Chemistry and Cooling Library for Astrophysics Abstract: We present the Grackle chemistry and cooling library for astrophysical\nsimulations and models. Grackle provides a treatment of non-equilibrium\nprimordial chemistry and cooling for H, D, and He species, including H2\nformation on dust grains; tabulated primordial and metal cooling; multiple UV\nbackground models; and support for radiation transfer and arbitrary heat\nsources. The library has an easily implementable interface for simulation codes\nwritten in C, C++, and Fortran as well as a Python interface with added\nconvenience functions for semi-analytical models. As an open-source project,\nGrackle provides a community resource for accessing and disseminating\nastrochemical data and numerical methods. We present the full details of the\ncore functionality, the simulation and Python interfaces, testing\ninfrastructure, performance, and range of applicability. Grackle is a fully\nopen-source project and new contributions are welcome. \n\n"}
{"id": "1611.00036", "contents": "Title: The DESI Experiment Part I: Science,Targeting, and Survey Design Abstract: DESI (Dark Energy Spectroscopic Instrument) is a Stage IV ground-based dark\nenergy experiment that will study baryon acoustic oscillations (BAO) and the\ngrowth of structure through redshift-space distortions with a wide-area galaxy\nand quasar redshift survey. To trace the underlying dark matter distribution,\nspectroscopic targets will be selected in four classes from imaging data. We\nwill measure luminous red galaxies up to $z=1.0$. To probe the Universe out to\neven higher redshift, DESI will target bright [O II] emission line galaxies up\nto $z=1.7$. Quasars will be targeted both as direct tracers of the underlying\ndark matter distribution and, at higher redshifts ($ 2.1 < z < 3.5$), for the\nLy-$\\alpha$ forest absorption features in their spectra, which will be used to\ntrace the distribution of neutral hydrogen. When moonlight prevents efficient\nobservations of the faint targets of the baseline survey, DESI will conduct a\nmagnitude-limited Bright Galaxy Survey comprising approximately 10 million\ngalaxies with a median $z\\approx 0.2$. In total, more than 30 million galaxy\nand quasar redshifts will be obtained to measure the BAO feature and determine\nthe matter power spectrum, including redshift space distortions. \n\n"}
{"id": "1611.00037", "contents": "Title: The DESI Experiment Part II: Instrument Design Abstract: DESI (Dark Energy Spectropic Instrument) is a Stage IV ground-based dark\nenergy experiment that will study baryon acoustic oscillations and the growth\nof structure through redshift-space distortions with a wide-area galaxy and\nquasar redshift survey. The DESI instrument is a robotically-actuated,\nfiber-fed spectrograph capable of taking up to 5,000 simultaneous spectra over\na wavelength range from 360 nm to 980 nm. The fibers feed ten three-arm\nspectrographs with resolution $R= \\lambda/\\Delta\\lambda$ between 2000 and 5500,\ndepending on wavelength. The DESI instrument will be used to conduct a\nfive-year survey designed to cover 14,000 deg$^2$. This powerful instrument\nwill be installed at prime focus on the 4-m Mayall telescope in Kitt Peak,\nArizona, along with a new optical corrector, which will provide a three-degree\ndiameter field of view. The DESI collaboration will also deliver a\nspectroscopic pipeline and data management system to reduce and archive all\ndata for eventual public use. \n\n"}
{"id": "1611.02162", "contents": "Title: METAPHOR: A machine learning based method for the probability density\n  estimation of photometric redshifts Abstract: A variety of fundamental astrophysical science topics require the\ndetermination of very accurate photometric redshifts (photo-z's). A wide\nplethora of methods have been developed, based either on template models\nfitting or on empirical explorations of the photometric parameter space.\nMachine learning based techniques are not explicitly dependent on the physical\npriors and able to produce accurate photo-z estimations within the photometric\nranges derived from the spectroscopic training set. These estimates, however,\nare not easy to characterize in terms of a photo-z Probability Density Function\n(PDF), due to the fact that the analytical relation mapping the photometric\nparameters onto the redshift space is virtually unknown. We present METAPHOR\n(Machine-learning Estimation Tool for Accurate PHOtometric Redshifts), a method\ndesigned to provide a reliable PDF of the error distribution for empirical\ntechniques. The method is implemented as a modular workflow, whose internal\nengine for photo-z estimation makes use of the MLPQNA neural network (Multi\nLayer Perceptron with Quasi Newton learning rule), with the possibility to\neasily replace the specific machine learning model chosen to predict photo-z's.\nWe present a summary of results on SDSS-DR9 galaxy data, used also to perform a\ndirect comparison with PDF's obtained by the Le Phare SED template fitting. We\nshow that METAPHOR is capable to estimate the precision and reliability of\nphotometric redshifts obtained with three different self-adaptive techniques,\ni.e. MLPQNA, Random Forest and the standard K-Nearest Neighbors models. \n\n"}
{"id": "1611.03501", "contents": "Title: The Chandra Deep Field-South Survey: 7 Ms Source Catalogs Abstract: We present X-ray source catalogs for the $\\approx7$ Ms exposure of the\nChandra Deep Field-South (CDF-S), which covers a total area of 484.2\narcmin$^2$. Utilizing WAVDETECT for initial source detection and ACIS Extract\nfor photometric extraction and significance assessment, we create a main source\ncatalog containing 1008 sources that are detected in up to three X-ray bands:\n0.5-7.0 keV, 0.5-2.0 keV, and 2-7 keV. A supplementary source catalog is also\nprovided including 47 lower-significance sources that have bright ($K_s\\le23$)\nnear-infrared counterparts. We identify multiwavelength counterparts for 992\n(98.4%) of the main-catalog sources, and we collect redshifts for 986 of these\nsources, including 653 spectroscopic redshifts and 333 photometric redshifts.\nBased on the X-ray and multiwavelength properties, we identify 711 active\ngalactic nuclei (AGNs) from the main-catalog sources. Compared to the previous\n$\\approx4$ Ms CDF-S catalogs, 291 of the main-catalog sources are new\ndetections. We have achieved unprecedented X-ray sensitivity with average flux\nlimits over the central $\\approx1$ arcmin$^2$ region of\n$\\approx1.9\\times10^{-17}$, $6.4\\times10^{-18}$, and $2.7\\times10^{-17}$ erg\ncm$^{-2}$ s$^{-1}$ in the three X-ray bands, respectively. We provide\ncumulative number-count measurements observing, for the first time, that normal\ngalaxies start to dominate the X-ray source population at the faintest 0.5-2.0\nkeV flux levels. The highest X-ray source density reaches $\\approx50\\,500$\ndeg$^{-2}$, and $47\\%\\pm4\\%$ of these sources are AGNs ($\\approx23\\,900$\ndeg$^{-2}$). \n\n"}
{"id": "1611.03866", "contents": "Title: Cluster Mass Calibration at High Redshift: HST Weak Lensing Analysis of\n  13 Distant Galaxy Clusters from the South Pole Telescope Sunyaev-Zel'dovich\n  Survey Abstract: We present an HST/ACS weak gravitational lensing analysis of 13 massive\nhigh-redshift (z_median=0.88) galaxy clusters discovered in the South Pole\nTelescope (SPT) Sunyaev-Zel'dovich Survey. This study is part of a larger\ncampaign that aims to robustly calibrate mass-observable scaling relations over\na wide range in redshift to enable improved cosmological constraints from the\nSPT cluster sample. We introduce new strategies to ensure that systematics in\nthe lensing analysis do not degrade constraints on cluster scaling relations\nsignificantly. First, we efficiently remove cluster members from the source\nsample by selecting very blue galaxies in V-I colour. Our estimate of the\nsource redshift distribution is based on CANDELS data, where we carefully mimic\nthe source selection criteria of the cluster fields. We apply a statistical\ncorrection for systematic photometric redshift errors as derived from Hubble\nUltra Deep Field data and verified through spatial cross-correlations. We\naccount for the impact of lensing magnification on the source redshift\ndistribution, finding that this is particularly relevant for shallower surveys.\nFinally, we account for biases in the mass modelling caused by miscentring and\nuncertainties in the concentration-mass relation using simulations. In\ncombination with temperature estimates from Chandra we constrain the\nnormalisation of the mass-temperature scaling relation ln(E(z) M_500c/10^14\nM_sun)=A+1.5 ln(kT/7.2keV) to A=1.81^{+0.24}_{-0.14}(stat.) +/- 0.09(sys.),\nconsistent with self-similar redshift evolution when compared to lower redshift\nsamples. Additionally, the lensing data constrain the average concentration of\nthe clusters to c_200c=5.6^{+3.7}_{-1.8}. \n\n"}
{"id": "1611.04431", "contents": "Title: C3, A Command-line Catalogue Cross-match tool for large astrophysical\n  catalogues Abstract: Modern Astrophysics is based on multi-wavelength data organized into large\nand heterogeneous catalogues. Hence, the need for efficient, reliable and\nscalable catalogue cross-matching methods plays a crucial role in the era of\nthe petabyte scale. Furthermore, multi-band data have often very different\nangular resolution, requiring the highest generality of cross-matching\nfeatures, mainly in terms of region shape and resolution. In this work we\npresent $C^{3}$ (Command-line Catalogue Cross-match), a multi-platform\napplication designed to efficiently cross-match massive catalogues. It is based\non a multi-core parallel processing paradigm and conceived to be executed as a\nstand-alone command-line process or integrated within any generic data\nreduction/analysis pipeline, providing the maximum flexibility to the end-user,\nin terms of portability, parameter configuration, catalogue formats, angular\nresolution, region shapes, coordinate units and cross-matching types. Using\nreal data, extracted from public surveys, we discuss the cross-matching\ncapabilities and computing time efficiency also through a direct comparison\nwith some publicly available tools, chosen among the most used within the\ncommunity, and representative of different interface paradigms. We verified\nthat the $C^{3}$ tool has excellent capabilities to perform an efficient and\nreliable cross-matching between large datasets. Although the elliptical\ncross-match and the parametric handling of angular orientation and offset are\nknown concepts in the astrophysical context, their availability in the\npresented command-line tool makes $C^{3}$ competitive in the context of public\nastronomical tools. \n\n"}
{"id": "1611.06965", "contents": "Title: Voxel datacubes for 3D visualization in Blender Abstract: The growth of computational astrophysics and complexity of multidimensional\ndatasets evidences the need for new versatile visualization tools for both\nanalysis and presentation of the data. In this work we show how to use the open\nsource software Blender as a 3D visualization tool to study and visualize\nnumerical simulation results, focusing on astrophysical hydrodynamic\nexperiments. With a datacube as input, the software can generate a volume\nrendering of the 3D data, show the evolution of a simulation in time, and do a\nfly-around camera animation to highlight the points of interest. We explain the\nprocess to import simulation outputs into Blender using the Voxel Data format,\nand how to set up a visualization scene in the software interface. This method\nallows scientists to perform a complementary visual analysis of their data, and\ndisplay their results in an appealing way, both for outreach and science\npresentations. \n\n"}
{"id": "1611.09614", "contents": "Title: Tunka-Rex: energy reconstruction with a single antenna station (ARENA\n  2016) Abstract: The Tunka-Radio extension (Tunka-Rex) is a radio detector for air showers in\nSiberia. From 2012 to 2014, Tunka-Rex operated exclusively together with its\nhost experiment, the air-Cherenkov array Tunka-133, which provided trigger,\ndata acquisition, and an independent air-shower reconstruction. It was shown\nthat the air-shower energy can be reconstructed by Tunka-Rex with a precision\nof 15\\% for events with signal in at least 3 antennas, using the radio\namplitude at a distance of 120\\,m from the shower axis as an energy estimator.\nUsing the reconstruction from the host experiment Tunka-133 for the air-shower\ngeometry (shower core and direction), the energy estimator can in principle\nalready be obtained with measurements from a single antenna, close to the\nreference distance. We present a method for event selection and energy\nreconstruction, requiring only one antenna, and achieving a precision of about\n20\\%. This method increases the effective detector area and lowers thresholds\nfor zenith angle and energy, resulting in three times more events than in the\nstandard reconstruction. \n\n"}
{"id": "1611.09812", "contents": "Title: Limiting the effects of earthquakes on gravitational-wave\n  interferometers Abstract: Ground-based gravitational wave interferometers such as the Laser\nInterferometer Gravitational-wave Observatory (LIGO) are susceptible to\nhigh-magnitude teleseismic events, which can interrupt their operation in\nscience mode and significantly reduce the duty cycle. It can take several hours\nfor a detector to stabilize enough to return to its nominal state for\nscientific observations. The down time can be reduced if advance warning of\nimpending shaking is received and the impact is suppressed in the isolation\nsystem with the goal of maintaining stable operation even at the expense of\nincreased instrumental noise. Here we describe an early warning system for\nmodern gravitational-wave observatories. The system relies on near real-time\nearthquake alerts provided by the U.S. Geological Survey (USGS) and the\nNational Oceanic and Atmospheric Administration (NOAA). Hypocenter and\nmagnitude information is generally available in 5 to 20 minutes of a\nsignificant earthquake depending on its magnitude and location. The alerts are\nused to estimate arrival times and ground velocities at the gravitational-wave\ndetectors. In general, 90\\% of the predictions for ground-motion amplitude are\nwithin a factor of 5 of measured values. The error in both arrival time and\nground-motion prediction introduced by using preliminary, rather than final,\nhypocenter and magnitude information is minimal. By using a machine learning\nalgorithm, we develop a prediction model that calculates the probability that a\ngiven earthquake will prevent a detector from taking data. Our initial results\nindicate that by using detector control configuration changes, we could prevent\ninterruption of operation from 40-100 earthquake events in a 6-month\ntime-period. \n\n"}
{"id": "1611.09832", "contents": "Title: The analysis of VERITAS muon images using convolutional neural networks Abstract: Imaging atmospheric Cherenkov telescopes (IACTs) are sensitive to rare\ngamma-ray photons, buried in the background of charged cosmic-ray (CR)\nparticles, the flux of which is several orders of magnitude greater. The\nability to separate gamma rays from CR particles is important, as it is\ndirectly related to the sensitivity of the instrument. This\ngamma-ray/CR-particle classification problem in IACT data analysis can be\ntreated with the rapidly-advancing machine learning algorithms, which have the\npotential to outperform the traditional box-cut methods on image parameters. We\npresent preliminary results of a precise classification of a small set of muon\nevents using a convolutional neural networks model with the raw images as input\nfeatures. We also show the possibility of using the convolutional neural\nnetworks model for regression problems, such as the radius and brightness\nmeasurement of muon events, which can be used to calibrate the throughput\nefficiency of IACTs. \n\n"}
{"id": "1611.09858", "contents": "Title: The Complete Infrared View of Active Galactic Nuclei from the 70-month\n  Swift/BAT Catalog Abstract: We systematically investigate the near- (NIR) to far-infrared (FIR)\nphotometric properties of a nearly complete sample of local active galactic\nnuclei (AGN) detected in the Swift/Burst Alert Telescope (BAT) all-sky ultra\nhard X-ray (14-195 keV) survey. Out of 606 non-blazar AGN in the Swift/BAT\n70-month catalog at high galactic latitude of $|b|>10^{\\circ}$, we obtain IR\nphotometric data of 604 objects by cross-matching the AGN positions with\ncatalogs from the WISE, AKARI, IRAS, and Herschel infrared observatories. We\nfind a good correlation between the ultra-hard X-ray and mid-IR (MIR)\nluminosities over five orders of magnitude ($41 < \\log (L_{14-195}/{\\rm\nerg}~{\\rm s}^{-1})< 46$). Informed by previous measures of the intrinsic\nspectral energy distribution of AGN, we find FIR pure-AGN candidates whose FIR\nemission is thought to be AGN-dominated with low starformation activity. We\ndemonstrate that the dust covering factor decreases with the bolometric AGN\nluminosity, confirming the luminosity-dependent unified scheme. We also show\nthat the completeness of the WISE color-color cut in selecting Swift/BAT AGN\nincreases strongly with 14-195 keV luminosity. \n\n"}
{"id": "1611.10322", "contents": "Title: Measurement of light and charge yield of low-energy electronic recoils\n  in liquid xenon Abstract: The dependence of the light and charge yield of liquid xenon on the applied\nelectric field and recoil energy is important for dark matter detectors using\nliquid xenon time projections chambers. Few measurements have been made of this\nfield dependence at recoil energies less than 10 keV. In this paper we present\nresults of such measurements using a specialized detector. Recoil energies are\ndetermined via the Compton coincidence technique at four drift fields relevant\nfor liquid xenon dark matter detectors: 0.19, 0.48, 1.02, and 2.32 kV/cm. Mean\nrecoil energies down to 1 keV were measured with unprecedented precision. We\nfind that the charge and light yield are anti-correlated above 3 keV, and that\nthe field dependence becomes negligible below 6 keV. However, below 3 keV we\nfind a charge yield significantly higher than expectation and a reconstructed\nenergy deviating from linearity. \n\n"}
{"id": "1611.10347", "contents": "Title: Wavelet-Bayesian inference of cosmic strings embedded in the cosmic\n  microwave background Abstract: Cosmic strings are a well-motivated extension to the standard cosmological\nmodel and could induce a subdominant component in the anisotropies of the\ncosmic microwave background (CMB), in addition to the standard inflationary\ncomponent. The detection of strings, while observationally challenging, would\nprovide a direct probe of physics at very high energy scales. We develop a new\nframework for cosmic string inference, constructing a Bayesian analysis in\nwavelet space where the string-induced CMB component has distinct statistical\nproperties to the standard inflationary component. Our wavelet-Bayesian\nframework provides a principled approach to compute the posterior distribution\nof the string tension $G\\mu$ and the Bayesian evidence ratio comparing the\nstring model to the standard inflationary model. Furthermore, we present a\ntechnique to recover an estimate of any string-induced CMB map embedded in\nobservational data. Using Planck-like simulations we demonstrate the\napplication of our framework and evaluate its performance. The method is\nsensitive to $G\\mu \\sim 5 \\times 10^{-7}$ for Nambu-Goto string simulations\nthat include an integrated Sachs-Wolfe (ISW) contribution only and do not\ninclude any recombination effects, before any parameters of the analysis are\noptimised. The sensitivity of the method compares favourably with other\ntechniques applied to the same simulations. \n\n"}
{"id": "1612.00839", "contents": "Title: The 2-degree Field Lensing Survey: photometric redshifts from a large\n  new training sample to r<19.5 Abstract: We present a new training set for estimating empirical photometric redshifts\nof galaxies, which was created as part of the 2dFLenS project. This training\nset is located in a 700 sq deg area of the KiDS South field and is randomly\nselected and nearly complete at r<19.5. We investigate the photometric redshift\nperformance obtained with ugriz photometry from VST-ATLAS and W1/W2 from WISE,\nbased on several empirical and template methods. The best redshift errors are\nobtained with kernel-density estimation, as are the lowest biases, which are\nconsistent with zero within statistical noise. The 68th percentiles of the\nredshift scatter for magnitude-limited samples at r<(15.5, 17.5, 19.5) are\n(0.014, 0.017, 0.028). In this magnitude range, there are no known ambiguities\nin the colour-redshift map, consistent with a small rate of redshift outliers.\nIn the fainter regime, the KDE method produces p(z) estimates per galaxy that\nrepresent unbiased and accurate redshift frequency expectations. The p(z) sum\nover any subsample is consistent with the true redshift frequency plus Poisson\nnoise. Further improvements in redshift precision at r<20 would mostly be\nexpected from filter sets with narrower passbands to increase the sensitivity\nof colours to small changes in redshift. \n\n"}
{"id": "1612.00920", "contents": "Title: Collaborative visual analytics of radio surveys in the Big Data era Abstract: Radio survey datasets comprise an increasing number of individual\nobservations stored as sets of multidimensional data. In large survey projects,\nastronomers commonly face limitations regarding: 1) interactive visual\nanalytics of sufficiently large subsets of data; 2) synchronous and\nasynchronous collaboration; and 3) documentation of the discovery workflow. To\nsupport collaborative data inquiry, we present encube, a large-scale\ncomparative visual analytics framework. Encube can utilise advanced\nvisualization environments such as the CAVE2 (a hybrid 2D and 3D virtual\nreality environment powered with a 100 Tflop/s GPU-based supercomputer and 84\nmillion pixels) for collaborative analysis of large subsets of data from radio\nsurveys. It can also run on standard desktops, providing a capable visual\nanalytics experience across the display ecology. Encube is composed of four\nprimary units enabling compute-intensive processing, advanced visualisation,\ndynamic interaction, parallel data query, along with data management. Its\nmodularity will make it simple to incorporate astronomical analysis packages\nand Virtual Observatory capabilities developed within our community. We discuss\nhow encube builds a bridge between high-end display systems (such as CAVE2) and\nthe classical desktop, preserving all traces of the work completed on either\nplatform -- allowing the research process to continue wherever you are. \n\n"}
{"id": "1612.01027", "contents": "Title: Removing biases in resolved stellar mass-maps of galaxy disks through\n  successive Bayesian marginalization Abstract: Stellar masses of galaxies are frequently obtained by fitting stellar\npopulation synthesis models to galaxy photometry or spectra. The state of the\nart method resolves spatial structures within a galaxy to assess the total\nstellar mass content. In comparison to unresolved studies, resolved methods\nyield, on average, higher fractions of stellar mass for galaxies. In this work\nwe improve the current method in order to mitigate a bias related to the\nresolved spatial distribution derived for the mass. The bias consists in an\napparent filamentary mass distribution, and a spatial coincidence between mass\nstructures and dust lanes near spiral arms. The improved method is based on\niterative Bayesian marginalization, through a new algorithm we have named\nBayesian Successive Priors (BSP). We have applied BSP to M 51, and to a pilot\nsample of 90 spiral galaxies from the Ohio State University Bright Spiral\nGalaxy Survey. By comparing quantitatively both methods, we find that the\naverage fraction of stellar mass missed by unresolved studies is only half than\npreviously thought. In contrast with the previous method, the output BSP\nmass-maps bear a better resemblance to near infrared images. \n\n"}
{"id": "1612.01102", "contents": "Title: Globally coherent short duration magnetic field transients and their\n  effect on ground based gravitational-wave detectors Abstract: It has been recognized that the magnetic fields from the Schumann resonances\ncould affect the search for a stochastic gravitational-wave background by LIGO\nand Virgo. Presented here are the observations of short duration magnetic field\ntransients that are coincident in the magnetometers at the LIGO and Virgo\nsites. Data from low-noise magnetometers in Poland and Colorado, USA, are also\nused and show short duration magnetic transients of global extent. We measure\nat least 2.3 coincident (between Poland and Colorado) magnetic transient events\nper day where one of the pulses exceeds 200 pT. Given the recently measured\nvalues of the magnetic coupling to differential arm motion for Advanced LIGO,\nthere would be a few events per day that would appear simultaneously at the\ngravitational-wave detector sites and could move the test masses of order\n$10^{-18}$ m. We confirm that in the advanced detector era short duration\ntransient gravitational-wave searches must account for correlated magnetic\nfield noise in the global detector network. \n\n"}
{"id": "1612.01262", "contents": "Title: Preheating of the early Universe by radiation from high-mass X-ray\n  binaries Abstract: Using a reliably measured intrinsic (i.e. corrected for absorption effects)\npresent-day luminosity function of high-mass X-ray binaries (HMXBs) in the\n0.25-2 keV energy band per unit star-formation rate, we estimate the preheating\nof the early Universe by soft X-rays from such systems. We find that X-ray\nirradiation, mainly executed by ultraluminous and supersoft ultraluminous X-ray\nsources with luminosity L> 10^39 erg/s, could significantly heat (T>T_cmb,\nwhere T_cmb is the temperature of the cosmic microwave background) the\nintergalactic medium by z~10 if the specific X-ray emissivity of the young\nstellar population in the early Universe was an order of magnitude higher than\nat the present epoch (which is possible due to the low metallicity of the first\ngalaxies) and the soft X-ray emission from HMXBs did not suffer strong\nabsorption within their galaxies. This makes it possible to observe the 21 cm\nline of neutral hydrogen in emission from redshifts z<10. \n\n"}
{"id": "1612.02009", "contents": "Title: Spitzer Photometry of ~1 Million Stars in M31 and 15 Other Galaxies Abstract: We present Spitzer IRAC $3.6-8 \\mu$m and MIPS $24 \\mu$m point-source catalogs\nfor M $31$ and $15$ other mostly large, star forming galaxies at distances\n$\\sim3.5-14$ Mpc including M $51$, M $83$, M $101$ and NGC $6946$. These\ncatalogs contain $\\sim1$ million sources including $\\sim859,000$ in M 31 and\n$\\sim116,000$ in the other galaxies. They were created following the procedures\ndescribed in Khan et al. (2015) through a combination of point spread function\n(PSF) fitting and aperture photometry. These data products constitute a\nresource to improve our understanding of the IR-bright ($3.6-24 \\mu$m)\npoint-source populations in crowded extragalactic stellar fields and to plan\nobservations with the James Webb Space Telescope. \n\n"}
{"id": "1612.02173", "contents": "Title: A cooperative approach among methods for photometric redshifts\n  estimation: an application to KiDS data Abstract: Photometric redshifts (photo-z's) are fundamental in galaxy surveys to\naddress different topics, from gravitational lensing and dark matter\ndistribution to galaxy evolution. The Kilo Degree Survey (KiDS), i.e. the ESO\npublic survey on the VLT Survey Telescope (VST), provides the unprecedented\nopportunity to exploit a large galaxy dataset with an exceptional image quality\nand depth in the optical wavebands. Using a KiDS subset of about 25,000\ngalaxies with measured spectroscopic redshifts, we have derived photo-z's using\ni) three different empirical methods based on supervised machine learning, ii)\nthe Bayesian Photometric Redshift model (or BPZ), and iii) a classical SED\ntemplate fitting procedure (Le Phare). We confirm that, in the regions of the\nphotometric parameter space properly sampled by the spectroscopic templates,\nmachine learning methods provide better redshift estimates, with a lower\nscatter and a smaller fraction of outliers. SED fitting techniques, however,\nprovide useful information on the galaxy spectral type which can be effectively\nused to constrain systematic errors and to better characterize potential\ncatastrophic outliers. Such classification is then used to specialize the\ntraining of regression machine learning models, by demonstrating that a hybrid\napproach, involving SED fitting and machine learning in a single collaborative\nframework, can be effectively used to improve the accuracy of photo-z\nestimates. \n\n"}
{"id": "1612.02242", "contents": "Title: The Galah Survey: Classification and diagnostics with t-SNE reduction of\n  spectral information Abstract: Galah is an ongoing high-resolution spectroscopic survey with the goal of\ndisentangling the formation history of the Milky Way, using the fossil remnants\nof disrupted star formation sites which are now dispersed around the Galaxy. It\nis targeting a randomly selected, magnitude limited ($V \\leq 14$) sample of\nstars, with the goal of observing one million objects. To date, 300,000 spectra\nhave been obtained. Not all of them are correctly processed by parameter\nestimation pipelines and we need to know about them. We present a\nsemi-automated classification scheme which identifies different types of\npeculiar spectral morphologies, in an effort to discover and flag potentially\nproblematic spectra and thus help to preserve the integrity of the survey's\nresults. To this end we employ a recently developed dimensionality reduction\ntechnique t-SNE (t-distributed Stochastic Neighbour Embedding), which enables\nus to represent the complex spectral morphology in a two-dimensional projection\nmap while still preserving the properties of the local neighbourhoods of\nspectra. We find that the majority (178,483) of the 209,533 Galah spectra\nconsidered in this study represents normal single stars, whereas 31,050\npeculiar and problematic spectra with very diverse spectral features pertaining\nto 28,579 stars are distributed into 10 classification categories: Hot stars,\nCool metal-poor giants, Molecular absorption bands, Binary stars,\nH$\\alpha$/H$\\beta$ emission, H$\\alpha$/H$\\beta$ emission superimposed on\nabsorption, H$\\alpha$/H$\\beta$ P-Cygni, H$\\alpha$/H$\\beta$ inverted P-Cygni,\nLithium absorption, and Problematic. Classified spectra with supplementary\ninformation are presented in the catalogue, indicating candidates for follow-up\nobservations and population studies of the short-lived phases of stellar\nevolution. \n\n"}
{"id": "1612.03091", "contents": "Title: Characterization of the inner disk around HD 141569 A from Keck/NIRC2\n  L-band vortex coronagraphy Abstract: HD 141569 A is a pre-main sequence B9.5 Ve star surrounded by a prominent and\ncomplex circumstellar disk, likely still in a transition stage from\nprotoplanetary to debris disk phase. Here, we present a new image of the third\ninner disk component of HD 141569 A made in the L' band (3.8 micron) during the\ncommissioning of the vector vortex coronagraph recently installed in the\nnear-infrared imager and spectrograph NIRC2 behind the W.M. Keck Observatory\nKeck II adaptive optics system. We used reference point spread function\nsubtraction, which reveals the innermost disk component from the inner working\ndistance of $\\simeq 23$ AU and up to $\\simeq 70$ AU. The spatial scale of our\ndetection roughly corresponds to the optical and near-infrared scattered light,\nthermal Q, N and 8.6 micron PAH emission reported earlier. We also see an\noutward progression in dust location from the L'-band to the H-band (VLT/SPHERE\nimage) to the visible (HST/STIS image), likely indicative of dust blowout. The\nwarm disk component is nested deep inside the two outer belts imaged by HST\nNICMOS in 1999 (respectively at 406 and 245 AU). We fit our new L'-band image\nand spectral energy distribution of HD 141569 A with the radiative transfer\ncode MCFOST. Our best-fit models favor pure olivine grains, and are consistent\nwith the composition of the outer belts. While our image shows a putative\nvery-faint point-like clump or source embedded in the inner disk, we did not\ndetect any true companion within the gap between the inner disk and the first\nouter ring, at a sensitivity of a few Jupiter masses. \n\n"}
{"id": "1612.03255", "contents": "Title: An efficient method for removing point sources from full-sky radio\n  interferometric maps Abstract: A new generation of wide-field radio interferometers designed for 21-cm\nsurveys is being built as drift scan instruments allowing them to observe large\nfractions of the sky. With large numbers of antennas and frequency channels the\nenormous instantaneous data rates of these telescopes require novel, efficient,\ndata management and analysis techniques. The $m$-mode formalism exploits the\nperiodicity of such data with the sidereal day, combined with the assumption of\nstatistical isotropy of the sky, to achieve large computational savings and\nrender optimal analysis methods computationally tractable. We present an\nextension to that work that allows us to adopt a more realistic sky model and\ntreat objects such as bright point sources. We develop a linear procedure for\ndeconvolving maps, using a Wiener filter reconstruction technique, which\nsimultaneously allows filtering of these unwanted components. We construct an\nalgorithm, based on the Sherman-Morrison-Woodbury formula, to efficiently\ninvert the data covariance matrix, as required for any optimal signal-to-noise\nweighting. The performance of our algorithm is demonstrated using simulations\nof a cylindrical transit telescope. \n\n"}
{"id": "1612.03935", "contents": "Title: Trident: a universal tool for generating synthetic absorption spectra\n  from astrophysical simulations Abstract: Hydrodynamical simulations are increasingly able to accurately model physical\nsystems on stellar, galactic, and cosmological scales, however, the utility of\nthese simulations is often limited by our ability to directly compare them with\nthe datasets produced by observers: spectra, photometry, etc. To address this\nproblem, we have created Trident}, a Python-based, open-source tool for\npost-processing hydrodynamical simulations to produce synthetic absorption\nspectra and related data. Trident} can (i) create absorption-line spectra for\nany trajectory through a simulated dataset mimicking both background quasar and\ndown-the-barrel configurations, (ii) reproduce the spectral characteristics of\ncommon instruments like the Cosmic Origins Spectrograph, (iii) operate across\nthe ultraviolet, optical and infrared using customizable absorption line lists,\n(iv) trace simulated physical structures directly to spectral features, (v)\napproximate the presence of ion species absent from the simulation outputs,\n(vi) generate column density maps for any ion, and (vii) provide support for\nall major astrophysical hydrodynamical codes. The focus of Trident's\ndevelopment is for using simulated datasets to better interpret observations of\nthe circumgalactic medium (CGM) and intergalactic medium (IGM), but it remains\na general tool applicable in other contexts. \n\n"}
{"id": "1612.04526", "contents": "Title: Astronomical image reconstruction with convolutional neural networks Abstract: State of the art methods in astronomical image reconstruction rely on the\nresolution of a regularized or constrained optimization problem. Solving this\nproblem can be computationally intensive and usually leads to a quadratic or at\nleast superlinear complexity w.r.t. the number of pixels in the image. We\ninvestigate in this work the use of convolutional neural networks for image\nreconstruction in astronomy. With neural networks, the computationally\nintensive tasks is the training step, but the prediction step has a fixed\ncomplexity per pixel, i.e. a linear complexity. Numerical experiments show that\nour approach is both computationally efficient and competitive with other state\nof the art methods in addition to being interpretable. \n\n"}
{"id": "1612.05560", "contents": "Title: The Pan-STARRS1 Surveys Abstract: Pan-STARRS1 has carried out a set of distinct synoptic imaging sky surveys\nincluding the $3\\pi$ Steradian Survey and the Medium Deep Survey in 5 bands\n($grizy_{P1}$). The mean 5$\\sigma$ point source limiting sensitivities in the\nstacked 3$\\pi$ Steradian Survey in $grizy_{P1}$ are (23.3, 23.2, 23.1, 22.3,\n21.4) respectively. The upper bound on the systematic uncertainty in the\nphotometric calibration across the sky is 7-12 millimag depending on the\nbandpass. The systematic uncertainty of the astrometric calibration using the\nGaia frame comes from a comparison of the results with Gaia: the standard\ndeviation of the mean and median residuals ($ \\Delta ra, \\Delta dec $) are\n(2.3, 1.7) milliarcsec, and (3.1, 4.8) milliarcsec respectively. The Pan-STARRS\nsystem and the design of the PS1 surveys are described and an overview of the\nresulting image and catalog data products and their basic characteristics are\ndescribed together with a summary of important results. The images, reduced\ndata products, and derived data products from the Pan-STARRS1 surveys are\navailable to the community from the Mikulski Archive for Space Telescopes\n(MAST) at STScI. \n\n"}
{"id": "1612.06592", "contents": "Title: Realtime processing of LOFAR data for the detection of nano-second\n  pulses from the Moon Abstract: The low flux of the ultra-high energy cosmic rays (UHECR) at the highest\nenergies provides a challenge to answer the long standing question about their\norigin and nature. Even lower fluxes of neutrinos with energies above $10^{22}$\neV are predicted in certain Grand-Unifying-Theories (GUTs) and e.g.\\ models for\nsuper-heavy dark matter (SHDM). The significant increase in detector volume\nrequired to detect these particles can be achieved by searching for the\nnano-second radio pulses that are emitted when a particle interacts in Earth's\nmoon with current and future radio telescopes.\n  In this contribution we present the design of an online analysis and trigger\npipeline for the detection of nano-second pulses with the LOFAR radio\ntelescope. The most important steps of the processing pipeline are digital\nfocusing of the antennas towards the Moon, correction of the signal for\nionospheric dispersion, and synthesis of the time-domain signal from the\npolyphased-filtered signal in frequency domain. The implementation of the\npipeline on a GPU/CPU cluster will be discussed together with the computing\nperformance of the prototype. \n\n"}
{"id": "1612.09013", "contents": "Title: Molecular nucleation theory of dust formation in core-collapse\n  supernovae applied to SN 1987A Abstract: We model dust formation in the core collapse supernova explosion SN 1987A by\ntreating the gas-phase formation of dust grain nuclei as a chemical process. To\ncompute the synthesis of fourteen species of grains we integrate a\nnon-equilibrium network of nucleating and related chemical reactions and follow\nthe growth of the nuclei into grains via accretion and coagulation. The effects\nof the radioactive cobalt, titanium, and sodium on the thermodynamics and\nchemistry of the ejecta are taken into account. The grain temperature, which we\nallow to differ from the gas temperature, affects the surface-tension-corrected\nevaporation rate. We also account for He$^+$, Ne$^+$, Ar$^+$, and O weathering.\nWe combine our dust synthesis model with a crude prescription for anisotropic\nradioactive nickel dredge-up into the core ejecta, the so-called `nickel\nbubbles', to compute the total dust mass and molecular-species-specific grain\nsize distribution. The total mass varies between $0.41\\,M_\\odot$ and\n$0.73\\,M_\\odot$, depending on the bubble shell density contrast. In the\ndecreasing order of abundance, the grain species produced are: magnesia,\nsilicon, forsterite, iron sulfide, carbon, silicon dioxide, alumina, and iron.\nThe combined grain size distribution is a power law $dN/da\\propto a^{-4.39}$.\nEarly ejecta compaction by expanding radioactive nickel bubbles strongly\nenhances dust synthesis. This underscores the need for improved understanding\nof hydrodynamic transport and mixing over the entire pre-homologous expansion. \n\n"}
{"id": "1701.01339", "contents": "Title: Fundamental physics with the Hubble Frontier Fields: constraining Dark\n  Matter models with the abundance of extremely faint and distant galaxies Abstract: We show that the measured abundance of ultra-faint lensed galaxies at\n$z\\approx 6$ in the Hubble Frontier Fields (HFF) provides stringent constraints\non the parameter space of i) Dark Matter models based on keV sterile neutrinos;\nii) the \"fuzzy\" wavelike Dark Matter models, based on Bose-Einstein condensate\nof ultra-light particles. For the case of the sterile neutrinos, we consider\ntwo production mechanisms: resonant production through the mixing with active\nneutrinos and the decay of scalar particles. For the former model, we derive\nconstraints for the combination of sterile neutrino mass $m_{\\nu}$ and mixing\nparameter $\\sin^2(2\\theta)$ which provide the tightest lower bounds on the\nmixing angle (and hence on the lepton asymmetry) derived so far by methods\nindependent of baryonic physics. For the latter we compute the allowed\ncombinations of the scalar mass, its coupling to the Higgs field, and the\nYukawa coupling of the scalar to the sterile neutrinos. We compare our results\nto independent, existing astrophysical bounds on sterile neutrinos in the same\nmass range. For the case of \"fuzzy\" Dark Matter, we show that the observed\nnumber density $\\approx 1/{\\rm Mpc}^3$ of high-redshift galaxies in the HFF\nsets a lower limit $m_\\psi\\geq 8\\cdot 10^{-22}$ eV (at 3-$\\sigma$ confidence\nlevel) on the particle mass, a result that strongly disfavors wavelike bosonic\nDark Matter as a viable model for structure formation. We discuss the impact on\nour results of uncertainties due to systematics in the selection of highly\nmagnified, faint galaxies at high redshifts. \n\n"}
{"id": "1701.02954", "contents": "Title: Searching for galaxy clusters in the Kilo-Degree Survey Abstract: In this paper, we present the tools used to search for galaxy clusters in the\nKilo Degree Survey (KiDS), and our first results. The cluster detection is\nbased on an implementation of the optimal filtering technique that enables us\nto identify clusters as over-densities in the distribution of galaxies using\ntheir positions on the sky, magnitudes, and photometric redshifts. The\ncontamination and completeness of the cluster catalog are derived using mock\ncatalogs based on the data themselves. The optimal signal to noise threshold\nfor the cluster detection is obtained by randomizing the galaxy positions and\nselecting the value that produces a contamination of less than 20%. Starting\nfrom a subset of clusters detected with high significance at low redshifts, we\nshift them to higher redshifts to estimate the completeness as a function of\nredshift: the average completeness is ~ 85%. An estimate of the mass of the\nclusters is derived using the richness as a proxy. We obtained 1858 candidate\nclusters with redshift 0 < z_c < 0.7 and mass 13.5 < log(M500/Msun) < 15 in an\narea of 114 sq. degrees (KiDS ESO-DR2). A comparison with publicly available\nSloan Digital Sky Survey (SDSS)-based cluster catalogs shows that we match more\nthan 50% of the clusters (77% in the case of the redMaPPer catalog). We also\ncross-matched our cluster catalog with the Abell clusters, and clusters found\nby XMM and in the Planck-SZ survey; however, only a small number of them lie\ninside the KiDS area currently available. \n\n"}
{"id": "1701.03384", "contents": "Title: Bayesian power spectrum estimation at the Epoch of Reionization Abstract: We introduce a new method for performing robust Bayesian estimation of the\nthree-dimensional spatial power spectrum at the Epoch of Reionization (EoR),\nfrom interferometric observations. The versatility of this technique allows us\nto present two approaches. First, when the observations span only a small\nnumber of independent spatial frequencies ($k$-modes) we sample directly from\nthe spherical power spectrum coefficients that describe the EoR signal\nrealisation. Second, when the number of $k$-modes to be included in the model\nbecomes large, we sample from the joint probability density of the spherical\npower spectrum and the signal coefficients, using Hamiltonian Monte Carlo\nmethods to explore this high dimensional ($\\sim$ 20000) space efficiently. This\napproach has been successfully applied to simulated observations that include\nastrophysically realistic foregrounds in a companion publication (Sims et al.\n2016). Here we focus on explaining the methodology in detail, and use simple\nforeground models to both demonstrate its efficacy, and highlight salient\nfeatures. In particular, we show that including an arbitrary flat spectrum\ncontinuum foreground that is $10^8$ times greater in power than the EoR signal\nhas no detectable impact on our parameter estimates of the EoR power spectrum\nrecovered from the data. \n\n"}
{"id": "1701.05283", "contents": "Title: Evidence for a Dusty Dark Dwarf Galaxy in the Quadruple Lens MG0414+0534 Abstract: We report the $4 \\, \\sigma$ detection of a faint object with a flux of ~ 0.3\nmJy, in the vicinity of the quadruply lensed QSO MG0414+0534 using the Atacama\nLarge Millimeter/submillimeter array (ALMA) Band 7. The object is most probably\na dusty dark dwarf galaxy, which has not been detected in either the optical,\nnear-infrared (NIR) or radio (cm) bands. An anomaly in the flux ratio of the\nlensed images observed in Band 7 and the mid-infrared (MIR) band and the\nreddening of the QSO light color can be simultaneously explained if we consider\nthe object as a lensing substructure with an ellipticity ~ 0.7 at a redshift of\n$0.5 \\lesssim z \\lesssim 1$. Using the best-fit lens models with three lenses,\nwe find that the dark matter plus baryon mass associated with the object is\n$\\sim 10^9\\, M_{\\odot}$, the dust mass is $\\sim 10^7\\,M_{\\odot}$ and the linear\nsize is $\\gtrsim 5\\,$kpc. Thus our findings suggest that the object is a dusty\ndark dwarf galaxy. A substantial portion of faint submillimeter galaxies (SMGs)\nin the universe may be attributed to such dark objects. \n\n"}
{"id": "1701.05316", "contents": "Title: A Formulation of Consistent Particle Hydrodynamics in Strong Form Abstract: In fluid dynamical simulations in astrophysics, large deformations are common\nand surface tracking is sometimes necessary. Smoothed Particle Hydrodynamics\n(SPH) method has been used in many of such simulations. Recently, however, it\nhas been shown that SPH cannot handle contact discontinuities or free surfaces\naccurately. There are several reasons for this problem. The first one is that\nSPH requires that the density is continuous and differentiable. The second one\nis that SPH does not have the consistency, and thus the accuracy is zeroth\norder in space. In addition, we cannot express accurate boundary conditions\nwith SPH. In this paper, we propose a novel, high-order scheme for\nparticle-based hydrodynamics of compress- ible fluid. Our method is based on\nkernel-weighted high-order fitting polynomial for intensive variables. With\nthis approach, we can construct a scheme which solves all of the three prob-\nlems described above. For shock capturing, we use a tensor form of\nvon-Neumann-Richtmyer artificial viscosity. We have applied our method to many\ntest problems and obtained excel- lent result. Our method is not conservative,\nsince particles do not have mass or energy, but only their densities. However,\nbecause of the Lagrangian nature of our scheme, the violation of the\nconservation laws turned out to be small. We name this method Consistent\nParticle Hydrodynamics in Strong Form (CPHSF). \n\n"}
{"id": "1701.05689", "contents": "Title: Photometric classification and redshift estimation of LSST Supernovae Abstract: Supernova (SN) classification and redshift estimation using photometric data\nonly have become very important for the Large Synoptic Survey Telescope (LSST),\ngiven the large number of SNe that LSST will observe and the impossibility of\nspectroscopically following up all the SNe. We investigate the performance of a\nSN classifier that uses SN colors to classify LSST SNe with the Random Forest\nclassification algorithm. Our classifier results in an AUC of 0.98 which\nrepresents excellent classification. We are able to obtain a photometric SN\nsample containing 99$\\%$ SNe Ia by choosing a probability threshold. We\nestimate the photometric redshifts (photo-z) of SNe in our sample by fitting\nthe SN light curves using the SALT2 model with nested sampling. We obtain a\nmean bias ($\\left<z_\\mathrm{phot}-z_\\mathrm{spec}\\right>$) of 0.012 with\n$\\sigma\\left( \\frac{z_\\mathrm{phot}-z_\\mathrm{spec}}{1+z_\\mathrm{spec}}\\right)\n= 0.0294$ without using a host-galaxy photo-z prior, and a mean bias\n($\\left<z_\\mathrm{phot}-z_\\mathrm{spec}\\right>$) of 0.0017 with $\\sigma\\left(\n\\frac{z_\\mathrm{phot}-z_\\mathrm{spec}}{1+z_\\mathrm{spec}}\\right) = 0.0116$\nusing a host-galaxy photo-z prior. Assuming a flat $\\Lambda CDM$ model with\n$\\Omega_m=0.3$, we obtain $\\Omega_m$ of $0.305\\pm0.008$ (statistical errors\nonly), using the simulated LSST sample of photometric SNe Ia (with intrinsic\nscatter $\\sigma_\\mathrm{int}=0.11$) derived using our methodology without using\nhost-galaxy photo-z prior. Our method will help boost the power of SNe from the\nLSST as cosmological probes. \n\n"}
{"id": "1701.07165", "contents": "Title: Latest results of the Tunka Radio Extension (ISVHECRI2016) Abstract: The Tunka Radio Extension (Tunka-Rex) is an antenna array consisting of 63\nantennas at the location of the TAIGA facility (Tunka Advanced Instrument for\ncosmic ray physics and Gamma Astronomy) in Eastern Siberia, nearby Lake Baikal.\nTunka-Rex is triggered by the air-Cherenkov array Tunka-133 during clear and\nmoonless winter nights and by the scintillator array Tunka-Grande during the\nremaining time. Tunka-Rex measures the radio emission from the same air-showers\nas Tunka-133 and Tunka-Grande, but with a higher threshold of about 100 PeV.\nDuring the first stages of its operation, Tunka-Rex has proven, that sparse\nradio arrays can measure air-showers with an energy resolution of better than\n15\\% and the depth of the shower maximum with a resolution of better than 40\ng/cm\\textsuperscript{2}. To improve and interpret our measurements as well as\nto study systematic uncertainties due to interaction models, we perform radio\nsimulations with CORSIKA and CoREAS. In this overview we present the setup of\nTunka-Rex, discuss the achieved results and the prospects of mass-composition\nstudies with radio arrays. \n\n"}
{"id": "1701.08165", "contents": "Title: Dynamical dark energy in light of the latest observations Abstract: A flat Friedman-Roberson-Walker universe dominated by a cosmological constant\n($\\Lambda$) and cold dark matter (CDM) has been the working model preferred by\ncosmologists since the discovery of cosmic acceleration. However, tensions of\nvarious degrees of significance are known to be present among existing datasets\nwithin the $\\Lambda$CDM framework. In particular, the Lyman-$\\alpha$ forest\nmeasurement of the Baryon Acoustic Oscillations (BAO) by the Baryon Oscillation\nSpectroscopic Survey (BOSS) prefers a smaller value of the matter density\nfraction $\\Omega_{\\rm M}$ compared to the value preferred by cosmic microwave\nbackground (CMB). Also, the recently measured value of the Hubble constant,\n$H_0=73.24\\pm1.74 \\ {\\rm km}\\ {\\rm s}^{-1} \\ {\\rm Mpc}^{-1}$, is $3.4\\sigma$\nhigher than $66.93\\pm0.62 \\ {\\rm km}\\ {\\rm s}^{-1} \\ {\\rm Mpc}^{-1}$ inferred\nfrom the Planck CMB data. In this work, we investigate if these tensions can be\ninterpreted as evidence for a non-constant dynamical dark energy (DE). Using\nthe Kullback-Leibler (KL) divergence to quantify the tension between datasets,\nwe find that the tensions are relieved by an evolving DE, with the dynamical DE\nmodel preferred at a $3.5\\sigma$ significance level based on the improvement in\nthe fit alone. While, at present, the Bayesian evidence for the dynamical DE is\ninsufficient to favour it over $\\Lambda$CDM, we show that, if the current best\nfit DE happened to be the true model, it would be decisively detected by the\nupcoming DESI survey. \n\n"}
{"id": "1701.08724", "contents": "Title: Stability of fundamental couplings: a global analysis Abstract: Astrophysical tests of the stability of fundamental couplings are becoming an\nincreasingly important probe of new physics. Motivated by the recent\navailability of new and stronger constraints we update previous works testing\nthe consistency of measurements of the fine-structure constant $\\alpha$ and the\nproton-to-electron mass ratio $\\mu=m_p/m_e$ (mostly obtained in the\noptical/ultraviolet) with combined measurements of $\\alpha$, $\\mu$ and the\nproton gyromagnetic ratio $g_p$ (mostly in the radio band). We carry out a\nglobal analysis of all available data, including the 293 archival measurements\nof {\\it Webb et al.} and 66 more recent dedicated measurements, and\nconstraining both time and spatial variations. While nominally the full\ndatasets show a slight statistical preference for variations of $\\alpha$ and\n$\\mu$ (at up to two standard deviations), we also find several inconsistencies\nbetween different sub-sets, likely due to hidden systematics and implying that\nthese statistical preferences need to be taken with caution. The statistical\nevidence for a spatial dipole in the values of $\\alpha$ is found at the 2.3\nsigma level. Forthcoming studies with facilities such as ALMA and ESPRESSO\nshould clarify these issues. \n\n"}
{"id": "1701.08803", "contents": "Title: Deceleration of high-velocity interstellar photon sails into bound\n  orbits at $\\alpha$ Centauri Abstract: At a distance of about 4.22 lightyears, it would take about 100,000 years for\nhumans to visit our closest stellar neighbor Proxima Centauri using modern\nchemical thrusters. New technologies are now being developed that involve\nhigh-power lasers firing at 1 gram solar sails in near-Earth orbits,\naccelerating them to 20% the speed of light (c) within minutes. Although such\nan interstellar probe could reach Proxima 20 years after launch, without\npropellant to slow it down it would traverse the system within hours. Here we\ndemonstrate how the stellar photon pressures of the stellar triple $\\alpha$ Cen\nA, B, and C (Proxima) can be used together with gravity assists to decelerate\nincoming solar sails from Earth. The maximum injection speed at $\\alpha$ Cen A\nto park a sail with a mass-to-surface ratio ($\\sigma$) similar to graphene\n(7.6e-4 gram/m$^{-2}$) in orbit around Proxima is about 13,800 km/s (4.6% c),\nimplying travel times from Earth to $\\alpha$ Cen A and B of about 95 years and\nanother 46 years (with a residual velocity of 1280 km/s) to Proxima. The size\nof such a low-$\\sigma$ sail required to carry a payload of 10 grams is about\n10$^5$ m$^2$ = (316 m)$^2$. Such a sail could use solar photons instead of an\nexpensive laser system to gain interstellar velocities at departure.\nPhotogravitational assists allow visits of three stellar systems and an\nEarth-sized potentially habitable planet in one shot, promising extremely high\nscientific yields. \n\n"}
{"id": "1701.09145", "contents": "Title: Electrothermal Feedback in Kinetic Inductance Detectors Abstract: In Kinetic Inductance Detectors (KIDs) and other similar applications of\nsuperconducting microresonators, both the large and small-signal behaviour of\nthe device may be affected by electrothermal feedback. Microwave power applied\nto read out the device is absorbed by and heats the superconductor\nquasiparticles, changing the superconductor conductivity and hence the readout\npower absorbed in a positive or negative feedback loop. In this work, we\nexplore numerically the implications of an extensible theoretical model of a\ngeneric superconducting microresonator device for a typical KID, incorporating\nrecent work on the power flow between superconductor quasiparticles and\nphonons. This model calculates the large-signal (changes in operating point)\nand small-signal behaviour of a device, allowing us to determine the effect of\nelectrothermal feedback on device responsivity and noise characteristics under\nvarious operating conditions. We also investigate how thermally isolating the\ndevice from the bath, for example by designing the device on a membrane only\nconnected to the bulk substrate by thin legs, affects device performance. We\nfind that at a typical device operating point, positive electrothermal feedback\nreduces the effective thermal conductance from the superconductor\nquasiparticles to the bath, and so increases responsivity to signal\n(pair-breaking) power, increases noise from temperature fluctuations, and\ndecreases the Noise Equivalent Power (NEP). Similarly, increasing the thermal\nisolation of the device while keeping the quasiparticle temperature constant\ndecreases the NEP, but also decreases the device response bandwidth. \n\n"}
{"id": "1702.00030", "contents": "Title: The optimisation of low-acceleration interstellar relativistic rocket\n  trajectories using genetic algorithms Abstract: A vast wealth of literature exists on the topic of rocket trajectory\noptimisation, particularly in the area of interplanetary trajectories due to\nits relevance today. Studies on optimising interstellar and intergalactic\ntrajectories are usually performed in flat spacetime using an analytical\napproach, with very little focus on optimising interstellar trajectories in a\ngeneral relativistic framework. This paper examines the use of low-acceleration\nrockets to reach galactic destinations in the least possible time, with a\ngenetic algorithm being employed for the optimisation process. The fuel\nrequired for each journey was calculated for various types of propulsion\nsystems to determine the viability of low-acceleration rockets to colonise the\nMilky Way. The results showed that to limit the amount of fuel carried on\nboard, an antimatter propulsion system would likely be the minimum\ntechnological requirement to reach star systems tens of thousands of light\nyears away. However, using a low-acceleration rocket would require several\nhundreds of thousands of years to reach these star systems, with minimal time\ndilation effects since maximum velocities only reached about 0.2c. Such transit\ntimes are clearly impractical, and thus, any kind of colonisation using low\nacceleration rockets would be difficult. High accelerations, on the order of\n1g, are likely required to complete interstellar journeys within a reasonable\ntime frame, though they may require prohibitively large amounts of fuel. So for\nnow, it appears that humanity's ultimate goal of a galactic empire may only be\npossible at significantly higher accelerations, though the propulsion\ntechnology requirement for a journey that uses realistic amounts of fuel\nremains to be determined. \n\n"}
{"id": "1702.00440", "contents": "Title: GraviDy, a GPU modular, parallel direct-summation $N-$body integrator:\n  Dynamics with softening Abstract: A wide variety of outstanding problems in astrophysics involve the motion of\na large number of particles ($N\\gtrsim 10^{6}$) under the force of gravity.\nThese include the global evolution of globular clusters, tidal disruptions of\nstars by a massive black hole, the formation of protoplanets and the detection\nof sources of gravitational radiation. The direct-summation of $N$\ngravitational forces is a complex problem with no analytical solution and can\nonly be tackled with approximations and numerical methods. To this end, the\nHermite scheme is a widely used integration method. With different numerical\ntechniques and special-purpose hardware, it can be used to speed up the\ncalculations. But these methods tend to be computationally slow and cumbersome\nto work with. Here we present a new GPU, direct-summation $N-$body integrator\nwritten from scratch and based on this scheme. This code has high modularity,\nallowing users to readily introduce new physics, it exploits available\nhigh-performance computing resources and will be maintained by public, regular\nupdates. The code can be used in parallel on multiple CPUs and GPUs, with a\nconsiderable speed-up benefit. The single GPU version runs about 200 times\nfaster compared to the single CPU version. A test run using 4 GPUs in parallel\nshows a speed up factor of about 3 as compared to the single GPU version. The\nconception and design of this first release is aimed at users with access to\ntraditional parallel CPU clusters or computational nodes with one or a few GPU\ncards. \n\n"}
{"id": "1702.01747", "contents": "Title: Simulations of the WFIRST Supernova Survey and Forecasts of Cosmological\n  Constraints Abstract: The Wide Field InfraRed Survey Telescope (WFIRST) was the highest ranked\nlarge space-based mission of the 2010 New Worlds, New Horizons decadal survey.\nIt is now a NASA mission in formulation with a planned launch in the mid-2020s.\nA primary mission objective is to precisely constrain the nature of dark energy\nthrough multiple probes, including Type Ia supernovae (SNe Ia). Here, we\npresent the first realistic simulations of the WFIRST SN survey based on\ncurrent hardware specifications and using open-source tools. We simulate SN\nlight curves and spectra as viewed by the WFIRST wide-field channel (WFC)\nimager and integral-field channel (IFC) spectrometer, respectively. We examine\n11 survey strategies with different time allocations between the WFC and IFC,\ntwo of which are based upon the strategy described by the WFIRST Science\nDefinition Team, which measures SN distances exclusively from IFC data. We\npropagate statistical and, crucially, systematic uncertainties to predict the\nDark Energy Task Force figure of merit (FoM) for each strategy. Of the\nstrategies investigated, we find the most successful to be WFC-focused.\nHowever, further work in constraining systematics is required to fully optimize\nthe use of the IFC. Even without improvements to other cosmological probes, the\nWFIRST SN survey has the potential to increase the FoM by more than an order of\nmagnitude from the current values. Although the survey strategies presented\nhere have not been fully optimized, these initial investigations are an\nimportant step in the development of the final hardware design and\nimplementation of the WFIRST mission. \n\n"}
{"id": "1702.01768", "contents": "Title: Broadband Millimeter-Wave Anti-Reflection Coatings on Silicon Using\n  Pyramidal Sub-Wavelength Structures Abstract: We used two novel approaches to produce sub-wavelength structure (SWS)\nanti-reflection coatings (ARC) on silicon for the millimeter and sub-millimeter\n(MSM) wave band: picosecond laser ablation and dicing with beveled saws. We\nproduced pyramidal structures with both techniques. The diced sample, machined\non only one side, had pitch and height of 350 $\\mu$m and 972 $\\mu$m. The two\nlaser ablated samples had pitch of 180 $\\mu$m and heights of 720 $\\mu$m and 580\n$\\mu$m; only one of these samples was ablated on both sides. We present\nmeasurements of shape and optical performance as well as comparisons to the\noptical performance predicted using finite element analysis and rigorous\ncoupled wave analysis. By extending the measured performance of the one-sided\ndiced sample to the two-sided case, we demonstrate 25 % band averaged\nreflectance of less than 5 % over a bandwidth of 97 % centered on 170 GHz.\nUsing the two-sided laser ablation sample, we demonstrate reflectance less than\n5 % over 83 % bandwidth centered on 346 GHz. \n\n"}
{"id": "1702.04805", "contents": "Title: Electron train backgrounds in liquid xenon dark matter search detectors\n  are indeed due to thermalization and trapping Abstract: Electron emission from liquid into gaseous xenon is a cornerstone of dark\nmatter search detectors such as ZEPLIN, XENON, LUX and LZ. The probability of\nemission is a function of the applied electric field E, and electrons which\nfail to pass from the liquid into the gas have been previously hypothesized to\nbecome thermalized and trapped. This article shows, for the first time,\nquantitative agreement between an electron emission model and existing data.\nThe model predicts that electrons in the liquid must surmount a typical\npotential barrier phi_b=0.34+-0.01 eV in order to escape into the gas. This\nvalue is a factor of about x2 smaller than has previously been calculated or\ninferred. Knowledge of phi_b allows calculation of the lifetime of thermalized,\ntrapped electrons. The value is O(10) ms, which appears to be compatible with\nXENON10 observations of electron train backgrounds. As these backgrounds limit\nthe sensitivity of dark sector dark matter searches, possible mitigations are\ndiscussed. \n\n"}
{"id": "1702.06643", "contents": "Title: Mimicking Dark Energy with the backreactions of gigaparsec\n  inhomogeneities Abstract: Spatial averaging and time evolving are non-commutative operations in General\nRelativity, which questions the reliability of the FLRW model. The long\nstanding issue of the importance of backreactions induced by cosmic\ninhomogeneities is addressed for a toy model assuming a peak in the primordial\nspectrum of density perturbations and a simple CDM cosmology. The backreactions\nof initial Hubble-size inhomogeneities are determined in a fully relativistic\nframework, from a series of simulations using the BSSN formalism of numerical\nrelativity. In the FLRW picture, these backreactions can be effectively\ndescribed by two so-called morphon scalar fields, one of them acting at late\ntime like a tiny cosmological constant. Initial density contrasts ranging from\n$10^{-2}$ down to $10^{-4}$, on scales crossing the Hubble radius between\n$z\\sim 45 $ and $z\\sim 1000$ respectively, i.e. comoving gigaparsec scales,\nmimic a Dark Energy (DE) component that can reach $\\Omega_{\\mathrm{DE}} \\approx\n0.7$ when extrapolated until today. A similar effect is not excluded for lower\ndensity contrasts but our results are then strongly contaminated by numerical\nnoise and thus hardly reliable. A potentially detectable signature of this\nscenario is a phantom-like equation of state $w< -1$, at redshifts $z\\gtrsim 4$\nfor a density contrast of $10^{-2}$ initially, relaxing slowly to $w \\approx\n-1$ today. This new class of scenarios would send the fine-tuning and\ncoincidence issues of Dark energy back to the mechanism at the origin of the\nprimordial power spectrum enhancement, possibly in the context of inflation. \n\n"}
{"id": "1702.07147", "contents": "Title: San Pedro Meeting on Wide Field Variability Surveys: Some Concluding\n  Comments Abstract: This is a written version of the closing talk at the 22nd Los Alamos Stellar\npulsation conference on wide field variability surveys. It comments on some of\nthe issues which arise from the meeting. These include the need for attention\nto photometric standardization (especially in the infrared) and the somewhat\ncontroversial problem of statistical bias in the use of parallaxes (and other\nmethods of distance determination). Some major advances in the use of pulsating\nvariables to study Galactic structure are mentioned. The paper includes a\nclarification of apparently conflicting results from classical Cepheids and RR\nLyrae stars in the inner Galaxy and bulge. The importance of understanding\nnon-periodic phenomena in variable stars,particularly AGB variables and RCB\nstars is stressed, especially for its relevance to mass-loss, in which\npulsation may only play a minor role. \n\n"}
{"id": "1702.08752", "contents": "Title: Gravitational radiation from compact binary systems in screened modified\n  gravity Abstract: Screened modified gravity (SMG) is a kind of scalar-tensor theory with\nscreening mechanisms, which can suppress the fifth force in dense regions and\nallow theories to evade the solar system and laboratory tests. In this paper,\nwe investigate how the screening mechanisms in SMG affect the gravitational\nradiation damping effects, calculate in detail the rate of the energy loss due\nto the emission of tensor and scalar gravitational radiations, and derive their\ncontributions to the change in the orbital period of the binary system. We find\nthat the scalar radiation depends on the screened parameters and the\npropagation speed of scalar waves, and the scalar dipole radiation dominates\nthe orbital decay of the binary system. For strongly self-gravitating bodies,\nall effects of scalar sector are strongly suppressed by the screening\nmechanisms in SMG. By comparing our results to observations of binary system\nPSR J1738+0333, we place the stringent constraints on the screening mechanisms\nin SMG. As an application of these results, we focus on three specific models\nof SMG (chameleon, symmetron, and dilaton), and derive the constraints on the\nmodel parameters, respectively. \n\n"}
{"id": "1703.01301", "contents": "Title: A Physical Model-based Correction for Charge Traps in the Hubble Space\n  Telescope's Wide Field Camera 3 Near-IR Detector and Applications to\n  Transiting Exoplanets and Brown Dwarfs Abstract: The Hubble Space Telescope (HST) Wide Field Camera 3 (WFC3) near-IR channel\nis extensively used in time-resolved observations, especially for transiting\nexoplanet spectroscopy and brown dwarf and directly imaged exoplanet rotational\nphase mapping. The ramp effect is the dominant source of systematics in the\nWFC3 for time-resolved observations, which limits its photometric precision.\nCurrent mitigation strategies are based on empirical fits and require\nadditional orbits \"to help the telescope reach a thermal equilibrium\". We show\nthat the ramp effect profiles can be explained and corrected with high fidelity\nusing charge trapping theories. We also present a model for this process that\ncan be used to predict and to correct charge trap systematics. Our model is\nbased on a very small number of parameters that are intrinsic to the detector.\nWe find that these parameters are very stable between the different datasets,\nand we provide best-fit values. Our model is tested with more than 120 orbits\n($\\sim40$ visits) of WFC3 observations and is proved to be able to provide near\nphoton noise limited corrections for observations made with both staring and\nscanning modes of transiting exoplanets as well as for starting-mode\nobservations of brown dwarfs. After our model correction, the light curve of\nthe first orbit in each visit has the same photometric precision as subsequent\norbits, so data from the first orbit need no longer be discarded. Near IR\narrays with the same physical characteristics (e.g., JWST/NIRCam) may also\nbenefit from the extension of this model, if similar systematic profiles are\nobserved. \n\n"}
{"id": "1703.01750", "contents": "Title: COSMOS-$e'$- soft Higgsotic attractors Abstract: In this work, we have developed an elegant algorithm to study the\ncosmological consequences from a huge class of quantum field theories (i.e.\nsuperstring theory, supergravity, extra dimensional theory, modified gravity\netc.), which are equivalently described by soft attractors in the effective\nfield theory framework. In this description we have restricted our analysis for\ntwo scalar fields - dilaton and Higgsotic fields minimally coupled with\nEinstein gravity, which can be generalized for any arbitrary number of scalar\nfield contents with generalized non-canonical and non-minimal interactions. We\nhave explicitly used $R^2$ gravity, from which we have studied the attractor\nand non-attractor phase by exactly computing two point, three point and four\npoint correlation functions from scalar fluctuations using In-In\n(Schwinger-Keldysh) and $\\delta {\\cal N}$ formalism. We have also presented\ntheoretical bounds on the amplitude, tilt and running of the primordial power\nspectrum, various shapes (equilateral, squeezed, folded kite or counter\ncollinear) of the amplitude as obtained from three and four point scalar\nfunctions, which are consistent with observed data. Also the results from two\npoint tensor fluctuations and field excursion formula are explicitly presented\nfor attractor and non-attractor phase. Further, reheating constraints, scale\ndependent behaviour of the couplings and the dynamical solution for the dilaton\nand Higgsotic fields are also presented. New sets of consistency relations\nbetween two, three and four point observables are also presented, which shows\nsignificant deviation from canonical slow roll models. Additionally, three\npossible theoretical proposals have presented to overcome the tachyonic\ninstability at the time of late time acceleration. Finally, we have also\nprovided the bulk interpretation from the three and four point scalar\ncorrelation functions for completeness. \n\n"}
{"id": "1703.01930", "contents": "Title: The SCUBA-2 Ambitious Sky Survey: a catalogue of beam-sized sources in\n  the Galactic longitude range 120 to 140 Abstract: The SCUBA-2 Ambitious Sky Survey (SASSy) is composed of shallow 850-$\\umu$m\nimaging using the Sub-millimetre Common-User Bolometer Array 2 (SCUBA-2) on the\nJames Clerk Maxwell Telescope. Here we describe the extraction of a catalogue\nof beam-sized sources from a roughly $120\\,{\\rm deg}^2$ region of the Galactic\nplane mapped uniformly (to an rms level of about 40\\,mJy), covering longitude\n120\\degr\\,$<$\\,\\textit{l}\\,$<$\\,140\\degr\\ and latitude\n$\\abs{\\textit{b}}$\\,$<$\\,2.9\\degr. We used a matched-filtering approach to\nincrease the signal-to-noise (S/N) ratio in these noisy maps and tested the\nefficiency of our extraction procedure through estimates of the false discovery\nrate, as well as by adding artificial sources to the real images. The primary\ncatalogue contains a total of 189 sources at 850\\,$\\umu$m, down to a S/N\nthreshold of approximately 4.6. Additionally, we list 136 sources detected down\nto ${\\rm S/N}=4.3$, but recognise that as we go lower in S/N, the reliability\nof the catalogue rapidly diminishes. We perform follow-up observations of some\nof our lower significance sources through small targeted SCUBA-2 images, and\nlist 265 sources detected in these maps down to ${\\rm S/N}=5$. This illustrates\nthe real power of SASSy: inspecting the shallow maps for regions of 850-$\\umu$m\nemission and then using deeper targeted images to efficiently find fainter\nsources. We also perform a comparison of the SASSy sources with the Planck\nCatalogue of Compact Sources and the \\textit{IRAS} Point Source Catalogue, to\ndetermine which sources discovered in this field might be new, and hence\npotentially cold regions at an early stage of star formation. \n\n"}
{"id": "1703.02642", "contents": "Title: CMU DeepLens: Deep Learning For Automatic Image-based Galaxy-Galaxy\n  Strong Lens Finding Abstract: Galaxy-scale strong gravitational lensing is not only a valuable probe of the\ndark matter distribution of massive galaxies, but can also provide valuable\ncosmological constraints, either by studying the population of strong lenses or\nby measuring time delays in lensed quasars. Due to the rarity of galaxy-scale\nstrongly lensed systems, fast and reliable automated lens finding methods will\nbe essential in the era of large surveys such as LSST, Euclid, and WFIRST. To\ntackle this challenge, we introduce CMU DeepLens, a new fully automated\ngalaxy-galaxy lens finding method based on Deep Learning. This supervised\nmachine learning approach does not require any tuning after the training step\nwhich only requires realistic image simulations of strongly lensed systems. We\ntrain and validate our model on a set of 20,000 LSST-like mock observations\nincluding a range of lensed systems of various sizes and signal-to-noise ratios\n(S/N). We find on our simulated data set that for a rejection rate of\nnon-lenses of 99%, a completeness of 90% can be achieved for lenses with\nEinstein radii larger than 1.4\" and S/N larger than 20 on individual $g$-band\nLSST exposures. Finally, we emphasize the importance of realistically complex\nsimulations for training such machine learning methods by demonstrating that\nthe performance of models of significantly different complexities cannot be\ndistinguished on simpler simulations. We make our code publicly available at\nhttps://github.com/McWilliamsCenter/CMUDeepLens . \n\n"}
{"id": "1703.02991", "contents": "Title: The third data release of the Kilo-Degree Survey and associated data\n  products Abstract: The Kilo-Degree Survey (KiDS) is an ongoing optical wide-field imaging survey\nwith the OmegaCAM camera at the VLT Survey Telescope. It aims to image 1500\nsquare degrees in four filters (ugri). The core science driver is mapping the\nlarge-scale matter distribution in the Universe, using weak lensing shear and\nphotometric redshift measurements. Further science cases include galaxy\nevolution, Milky Way structure, detection of high-redshift clusters, and\nfinding rare sources such as strong lenses and quasars. Here we present the\nthird public data release (DR3) and several associated data products, adding\nfurther area, homogenized photometric calibration, photometric redshifts and\nweak lensing shear measurements to the first two releases. A dedicated pipeline\nembedded in the Astro-WISE information system is used for the production of the\nmain release. Modifications with respect to earlier releases are described in\ndetail. Photometric redshifts have been derived using both Bayesian template\nfitting, and machine-learning techniques. For the weak lensing measurements,\noptimized procedures based on the THELI data reduction and lensfit shear\nmeasurement packages are used. In DR3 stacked ugri images, weight maps, masks,\nand source lists for 292 new survey tiles (~300 sq.deg) are made available. The\nmulti-band catalogue, including homogenized photometry and photometric\nredshifts, covers the combined DR1, DR2 and DR3 footprint of 440 survey tiles\n(447 sq.deg). Limiting magnitudes are typically 24.3, 25.1, 24.9, 23.8 (5 sigma\nin a 2 arcsec aperture) in ugri, respectively, and the typical r-band PSF size\nis less than 0.7 arcsec. The photometric homogenization scheme ensures accurate\ncolors and an absolute calibration stable to ~2% for gri and ~3% in u.\nSeparately released are a weak lensing shear catalogue and photometric\nredshifts based on two different machine-learning techniques. \n\n"}
{"id": "1703.09233", "contents": "Title: Mapping dark matter on the celestial sphere with weak gravitational\n  lensing Abstract: Convergence maps of the integrated matter distribution are a key science\nresult from weak gravitational lensing surveys. To date, recovering convergence\nmaps has been performed using a planar approximation of the celestial sphere.\nHowever, with the increasing area of sky covered by dark energy experiments,\nsuch as Euclid, the Large Synoptic Survey Telescope (LSST), and the Wide Field\nInfrared Survey Telescope (WFIRST), this assumption will no longer be valid. We\nrecover convergence fields on the celestial sphere using an extension of the\nKaiser-Squires estimator to the spherical setting. Through simulations we study\nthe error introduced by planar approximations. Moreover, we examine how best to\nrecover convergence maps in the planar setting, considering a variety of\ndifferent projections and defining the local rotations that are required when\nprojecting spin fields such as cosmic shear. For the sky coverages typical of\nfuture surveys, errors introduced by projection effects can be of order tens of\npercent, exceeding 50% in some cases. The stereographic projection, which is\nconformal and so preserves local angles, is the most effective planar\nprojection. In any case, these errors can be avoided entirely by recovering\nconvergence fields directly on the celestial sphere. We apply the spherical\nKaiser-Squires mass-mapping method presented to the public Dark Energy Survey\n(DES) science verification data to recover convergence maps directly on the\ncelestial sphere. \n\n"}
{"id": "1703.10732", "contents": "Title: Cosmological Constraints on Interacting Light Particles Abstract: Cosmological observations are becoming increasingly sensitive to the effects\nof light particles in the form of dark radiation (DR) at the time of\nrecombination. The conventional observable of effective neutrino number,\n$N_{\\rm eff}$, is insufficient for probing generic, interacting models of DR.\nIn this work, we perform likelihood analyses which allow both free-streaming\neffective neutrinos (parametrized by $N_{\\rm eff}$) and interacting effective\nneutrinos (parametrized by $N_{\\rm fld}$). We motivate an alternative\nparametrization of DR in terms of $N_{\\rm tot}$ (total effective number of\nneutrinos) and $f_{\\rm fs}$ (the fraction of effective neutrinos which are\nfree-streaming), which is less degenerate than using $N_{\\rm eff}$ and $N_{\\rm\nfld}$. Using the Planck 2015 likelihoods in conjunction with measurements of\nbaryon acoustic oscillations (BAO), we find constraints on the total amount of\nbeyond the Standard Model effective neutrinos (both free-streaming and\ninteracting) of $\\Delta N_{\\rm tot} < 0.39$ at 2$\\sigma$. In addition, we\nconsider the possibility that this scenario alleviates the tensions between\nearly-time and late-time cosmological observations, in particular the\nmeasurements of $\\sigma_8$ (the amplitude of matter power fluctuations at\n8$h^{-1}$ Mpc), finding a mild preference for interactions among light species.\nWe further forecast the sensitivities of a variety of future experiments,\nincluding Advanced ACTPol (a representative CMB Stage-III experiment), CMB\nStage-IV, and the Euclid satellite. This study is relevant for probing\nnon-standard neutrino physics as well as a wide variety of new particle physics\nmodels beyond the Standard Model that involve dark radiation. \n\n"}
{"id": "1704.00235", "contents": "Title: Characterizing the Circumgalactic Medium of Nearby Galaxies with HST/COS\n  and HST/STIS Absorption-Line Spectroscopy: II. Methods and Models Abstract: We present basic data and modeling for a survey of the cool, photo-ionized\nCircum-Galactic Medium (CGM) of low-redshift galaxies using far-UV QSO\nabsorption line probes. This survey consists of \"targeted\" and \"serendipitous\"\nCGM subsamples, originally described in Stocke et al. (2013, Paper 1). The\ntargeted subsample probes low-luminosity, late-type galaxies at $z<0.02$ with\nsmall impact parameters ($\\langle\\rho\\rangle = 71$ kpc), and the serendipitous\nsubsample probes higher luminosity galaxies at $z\\lesssim0.2$ with larger\nimpact parameters ($\\langle\\rho\\rangle = 222$ kpc). HST and FUSE UV\nspectroscopy of the absorbers and basic data for the associated galaxies,\nderived from ground-based imaging and spectroscopy, are presented. We find\nbroad agreement with the COS-Halos results, but our sample shows no evidence\nfor changing ionization parameter or hydrogen density with distance from the\nCGM host galaxy, probably because the COS-Halos survey probes the CGM at\nsmaller impact parameters. We find at least two passive galaxies with H I and\nmetal-line absorption, confirming the intriguing COS-Halos result that galaxies\nsometimes have cool gas halos despite no on-going star formation. Using a new\nmethodology for fitting H I absorption complexes, we confirm the CGM cool gas\nmass of Paper 1, but this value is significantly smaller than found by the\nCOS-Halos survey. We trace much of this difference to the specific values of\nthe low-$z$ meta-galactic ionization rate assumed. After accounting for this\ndifference, a best-value for the CGM cool gas mass is found by combining the\nresults of both surveys to obtain $\\log{(M/M_{\\odot})}=10.5\\pm0.3$, or ~30% of\nthe total baryon reservoir of an $L \\geq L^*$, star-forming galaxy. \n\n"}
{"id": "1704.01128", "contents": "Title: Generalized Slow Roll in the Unified Effective Field Theory of Inflation Abstract: We provide a compact and unified treatment of power spectrum observables for\nthe effective field theory (EFT) of inflation with the complete set of\noperators that lead to second-order equations of motion in metric perturbations\nin both space and time derivatives, including Horndeski and GLPV theories. We\nrelate the EFT operators in ADM form to the four additional free functions of\ntime in the scalar and tensor equations. Using the generalized slow roll\nformalism, we show that each power spectrum can be described by an integral\nover a single source that is a function of its respective sound horizon. With\nthis correspondence, existing model independent constraints on the source\nfunction can be simply reinterpreted in the more general inflationary context.\nBy expanding these sources around an optimized freeze-out epoch, we also\nprovide characterizations of these spectra in terms of five slow-roll\nhierarchies whose leading order forms are compact and accurate as long as EFT\ncoefficients vary only on timescales greater than an efold. We also clarify the\nrelationship between the unitary gauge observables employed in the EFT and the\ncomoving gauge observables of the post-inflationary universe. \n\n"}
{"id": "1704.01495", "contents": "Title: The VOICE Survey : VST Optical Imaging of the CDFS and ES1 Fields Abstract: We present the VST Optical Imaging of the CDFS and ES1 Fields (VOICE) Survey,\na VST INAF Guaranteed Time program designed to provide optical coverage of two\n4 deg$^2$ cosmic windows in the Southern hemisphere. VOICE provides the first,\nmulti-band deep optical imaging of these sky regions, thus complementing and\nenhancing the rich legacy of longer-wavelength surveys with VISTA, Spitzer,\nHerschel and ATCA available in these areas and paving the way for upcoming\nobservations with facilities such as the LSST, MeerKAT and the SKA. VOICE\nexploits VST's OmegaCAM optical imaging capabilities and completes the\nreduction of WFI data available within the ES1 fields as part of the\nESO-Spitzer Imaging Extragalactic Survey (ESIS) program providing $ugri$ and\n$uBVR$ coverage of 4 and 4 deg$^2$ areas within the CDFS and ES1 field\nrespectively. We present the survey's science rationale and observing strategy,\nthe data reduction and multi-wavelength data fusion pipeline. Survey data\nproducts and their future updates will be released at\nhttp://www.mattiavaccari.net/voice/ and on CDS/VizieR. \n\n"}
{"id": "1704.02322", "contents": "Title: Automated Lensing Learner: Automated Strong Lensing Identification with\n  a Computer Vision Technique Abstract: Forthcoming surveys such as the Large Synoptic Survey Telescope (LSST) and\nEuclid necessitate automatic and efficient identification methods of strong\nlensing systems. We present a strong lensing identification approach that\nutilizes a feature extraction method from computer vision, the Histogram of\nOriented Gradients (HOG), to capture edge patterns of arcs. We train a\nsupervised classifier model on the HOG of mock strong galaxy-galaxy lens images\nsimilar to observations from the Hubble Space Telescope (HST) and LSST. We\nassess model performance with the area under the curve (AUC) of a Receiver\nOperating Characteristic (ROC) curve. Models trained on 10,000 lens and\nnon-lens containing images images exhibit an AUC of 0.975 for an HST-like\nsample, 0.625 for one exposure of LSST, and 0.809 for 10-year mock LSST\nobservations. Performance appears to continually improve with the training set\nsize. Models trained on fewer images perform better in absence of the lens\ngalaxy light. However, with larger training data sets, information from the\nlens galaxy actually improves model performance, indicating that HOG captures\nmuch of the morphological complexity of the arc finding problem. We test our\nclassifier on data from the Sloan Lens ACS Survey and find that small scale\nimage features reduces the efficiency of our trained model. However, these\npreliminary tests indicate that some parameterizations of HOG can compensate\nfor differences between observed mock data. One example best-case\nparameterization results in an AUC of 0.6 in the F814 filter image with other\nparameterization results equivalent to random performance. \n\n"}
{"id": "1704.02704", "contents": "Title: POLOCALC: a Novel Method to Measure the Absolute Polarization\n  Orientation of the Cosmic Microwave Background Abstract: We describe a novel method to measure the absolute orientation of the\npolarization plane of the CMB with arcsecond accuracy, enabling unprecedented\nmeasurements for cosmology and fundamental physics. Existing and planned CMB\npolarization instruments looking for primordial B-mode signals need an\nindependent, experimental method for systematics control on the absolute\npolarization orientation. The lack of such a method limits the accuracy of the\ndetection of inflationary gravitational waves, the constraining power on the\nneutrino sector through measurements of gravitational lensing of the CMB, the\npossibility of detecting Cosmic Birefringence, and the ability to measure\nprimordial magnetic fields. Sky signals used for calibration and direct\nmeasurements of the detector orientation cannot provide an accuracy better than\n1 deg. Self-calibration methods provide better accuracy, but may be affected by\nforeground signals and rely heavily on model assumptions. The POLarization\nOrientation CALibrator for Cosmology, POLOCALC, will dramatically improve\ninstrumental accuracy by means of an artificial calibration source flying on\nballoons and aerial drones. A balloon-borne calibrator will provide far-field\nsource for larger telescopes, while a drone will be used for tests and smaller\npolarimeters. POLOCALC will also allow a unique method to measure the\ntelescopes' polarized beam. It will use microwave emitters between 40 and 150\nGHz coupled to precise polarizing filters. The orientation of the source\npolarization plane will be registered to sky coordinates by star cameras and\ngyroscopes with arcsecond accuracy. This project can become a rung in the\ncalibration ladder for the field: any existing or future CMB polarization\nexperiment observing our polarization calibrator will enable measurements of\nthe polarization angle for each detector with respect to absolute sky\ncoordinates. \n\n"}
{"id": "1704.02951", "contents": "Title: Real-Time Recovery Efficiencies and Performance of the Palomar Transient\n  Factory's Transient Discovery Pipeline Abstract: We present the transient source detection efficiencies of the Palomar\nTransient Factory (PTF), parameterizing the number of transients that PTF\nfound, versus the number of similar transients that occurred over the same\nperiod in the survey search area but that were missed. PTF was an optical sky\nsurvey carried out with the Palomar 48-inch telescope over 2009-2012, observing\nmore than 8000 square degrees of sky with cadences of between 1 and 5 days,\nlocating around 50,000 non-moving transient sources, and spectroscopically\nconfirming around 1900 supernovae. We assess the effectiveness with which PTF\ndetected transient sources, by inserting ~7 million artificial point sources\ninto real PTF data. We then study the efficiency with which the PTF real-time\npipeline recovered these sources as a function of the source magnitude, host\ngalaxy surface brightness, and various observing conditions (using proxies for\nseeing, sky brightness, and transparency). The product of this study is a\nmulti-dimensional recovery efficiency grid appropriate for the range of\nobserving conditions that PTF experienced, and that can then be used for\nstudies of the rates, environments, and luminosity functions of different\ntransient types using detailed Monte Carlo simulations. We illustrate the\ntechnique using the observationally well-understood class of type Ia\nsupernovae. \n\n"}
{"id": "1704.05094", "contents": "Title: Plasma Constraints on the Cosmological Abundance of Magnetic Monopoles\n  and the Origin of Cosmic Magnetic Fields Abstract: Existing theoretical and observational constraints on the abundance of\nmagnetic monopoles are limited. Here we demonstrate that an ensemble of\nmonopoles forms a plasma whose properties are well determined and whose\ncollective effects place new tight constraints on the cosmological abundance of\nmonopoles. In particular, the existence of micro-Gauss magnetic fields in\ngalaxy clusters and radio relics implies that the scales of these structures\nare below the Debye screening length, thus setting an upper limit on the\ncosmological density parameter of monopoles, $\\Omega_M\\lesssim3\\times10^{-4}$,\nwhich precludes them from being the dark matter. Future detection of Gpc-scale\ncoherent magnetic fields could improve this limit by a few orders of magnitude.\nIn addition, we predict the existence of magnetic Langmuir waves and turbulence\nwhich may appear on the sky as \"zebra patterns\" of an alternating magnetic\nfield with ${\\bf k\\cdot B}\\not=0$. We also show that magnetic monopole Langmuir\nturbulence excited near the accretion shock of galaxy clusters may be an\nefficient mechanism for generating the observed intracluster magnetic fields. \n\n"}
{"id": "1704.05336", "contents": "Title: Overview of lunar detection of ultra-high energy particles and new plans\n  for the SKA Abstract: The lunar technique is a method for maximising the collection area for\nultra-high-energy (UHE) cosmic ray and neutrino searches. The method uses\neither ground-based radio telescopes or lunar orbiters to search for Askaryan\nemission from particles cascading near the lunar surface. While experiments\nusing the technique have made important advances in the detection of\nnanosecond-scale pulses, only at the very highest energies has the lunar\ntechnique achieved competitive limits. This is expected to change with the\nadvent of the Square Kilometre Array (SKA), the low-frequency component of\nwhich (SKA-low) is predicted to be able to detect an unprecedented number of\nUHE cosmic rays.\n  In this contribution, the status of lunar particle detection is reviewed,\nwith particular attention paid to outstanding theoretical questions, and the\ntechnical challenges of using a giant radio array to search for nanosecond\npulses. The activities of SKA's High Energy Cosmic Particles Focus Group are\ndescribed, as is a roadmap by which this group plans to incorporate this\ndetection mode into SKA-low observations. Estimates for the sensitivity of\nSKA-low phases 1 and 2 to UHE particles are given, along with the achievable\nscience goals with each stage. Prospects for near-future observations with\nother instruments are also described. \n\n"}
{"id": "1704.05559", "contents": "Title: Inferring the photometric and size evolution of galaxies from image\n  simulations Abstract: Current constraints on models of galaxy evolution rely on morphometric\ncatalogs extracted from multi-band photometric surveys. However, these catalogs\nare altered by selection effects that are difficult to model, that correlate in\nnon trivial ways, and that can lead to contradictory predictions if not taken\ninto account carefully. To address this issue, we have developed a new approach\ncombining parametric Bayesian indirect likelihood (pBIL) techniques and\nempirical modeling with realistic image simulations that reproduce a large\nfraction of these selection effects. This allows us to perform a direct\ncomparison between observed and simulated images and to infer robust\nconstraints on model parameters. We use a semi-empirical forward model to\ngenerate a distribution of mock galaxies from a set of physical parameters.\nThese galaxies are passed through an image simulator reproducing the\ninstrumental characteristics of any survey and are then extracted in the same\nway as the observed data. The discrepancy between the simulated and observed\ndata is quantified, and minimized with a custom sampling process based on\nadaptive Monte Carlo Markov Chain methods. Using synthetic data matching most\nof the properties of a CFHTLS Deep field, we demonstrate the robustness and\ninternal consistency of our approach by inferring the parameters governing the\nsize and luminosity functions and their evolutions for different realistic\npopulations of galaxies. We also compare the results of our approach with those\nobtained from the classical spectral energy distribution fitting and\nphotometric redshift approach.Our pipeline infers efficiently the luminosity\nand size distribution and evolution parameters with a very limited number of\nobservables (3 photometric bands). When compared to SED fitting based on the\nsame set of observables, our method yields results that are more accurate and\nfree from systematic biases. \n\n"}
{"id": "1704.05988", "contents": "Title: Photometric Redshifts for Hyper Suprime-Cam Subaru Strategic Program\n  Data Release 1 Abstract: Photometric redshifts are a key component of many science objectives in the\nHyper Suprime-Cam Subaru Strategic Program (HSC-SSP). In this paper, we\ndescribe and compare the codes used to compute photometric redshifts for\nHSC-SSP, how we calibrate them, and the typical accuracy we achieve with the\nHSC five-band photometry (grizy). We introduce a new point estimator based on\nan improved loss function and demonstrate that it works better than other\ncommonly used estimators. We find that our photo-z's are most accurate at\n0.2<~zphot<~1.5, where we can straddle the 4000A break. We achieve\nsigma(d_zphot/(1+zphot))~0.05 and an outlier rate of about 15% for galaxies\ndown to i=25 within this redshift range. If we limit to a brighter sample of\ni<24, we achieve sigma~0.04 and ~8% outliers. Our photo-z's should thus enable\nmany science cases for HSC-SSP. We also characterize the accuracy of our\nredshift probability distribution function (PDF) and discover that some codes\nover/under-estimate the redshift uncertainties, which have implications for\nN(z) reconstruction. Our photo-z products for the entire area in the Public\nData Release 1 are publicly available, and both our catalog products (such as\npoint estimates) and full PDFs can be retrieved from the data release site,\nhttps://hsc-release.mtk.nao.ac.jp/. \n\n"}
{"id": "1704.06004", "contents": "Title: Great Optically Luminous Dropout Research Using Subaru HSC (GOLDRUSH).\n  I. UV Luminosity Functions at $z \\sim 4-7$ Derived with the Half-Million\n  Dropouts on the 100 deg$^2$ Sky Abstract: We study the UV luminosity functions (LFs) at $z\\sim 4$, $5$, $6,$ and $7$\nbased on the deep large-area optical images taken by the Hyper Suprime-Cam\n(HSC) Subaru strategic program (SSP). On the 100 deg$^2$ sky of the HSC SSP\ndata available to date, we make enormous samples consisting of a total of\n579,565 dropout candidates at $z\\sim 4-7$ by the standard color selection\ntechnique, 358 out of which are spectroscopically confirmed by our follow-up\nspectroscopy and other studies. We obtain UV LFs at $z \\sim 4-7$ that span a\nvery wide UV luminosity range of $\\sim 0.002 - 100 \\, L_{\\rm UV}^\\ast$ ($-26 <\nM_{\\rm UV} < -14$ mag) by combining LFs from our program and the ultra-deep\nHubble Space Telescope legacy surveys. We derive three parameters of the\nbest-fit Schechter function, $\\phi^\\ast$, $M_{\\rm UV}^\\ast$, and $\\alpha$, of\nthe UV LFs in the magnitude range where the AGN contribution is negligible, and\nfind that $\\alpha$ and $\\phi^\\ast$ decrease from $z\\sim 4$ to $7$ with no\nsignificant evolution of $M_{\\rm UV}^\\ast$. Because our HSC SSP data bridge the\nLFs of galaxies and AGNs with great statistical accuracy, we carefully\ninvestigate the bright end of the galaxy UV LFs that are estimated by the\nsubtraction of the AGN contribution either aided with spectroscopy or the\nbest-fit AGN UV LFs. We find that the bright end of the galaxy UV LFs cannot be\nexplained by the Schechter function fits at $> 2 \\sigma$ significance, and\nrequire either double power-law functions or modified Schechter functions that\nconsider a magnification bias due to gravitational lensing. \n\n"}
{"id": "1704.07084", "contents": "Title: Impact of correlated magnetic noise on the detection of stochastic\n  gravitational waves: Estimation based on a simple analytical model Abstract: After the first direct detection of gravitational waves (GW), detection of\nstochastic background of GWs is an important next step, and the first GW event\nsuggests that it is within the reach of the second-generation ground-based GW\ndetectors. Such a GW signal is typically tiny, and can be detected by\ncross-correlating the data from two spatially separated detectors if the\ndetector noise is uncorrelated. It has been advocated, however, that the global\nmagnetic fields in the Earth-ionosphere cavity produce the environmental\ndisturbances at low-frequency bands, known as Schumann resonances, which\npotentially couple with GW detectors. In this paper, we present a simple\nanalytical model to estimate its impact on the detection of stochastic GWs. The\nmodel crucially depends on the geometry of the detector pair through the\ndirectional coupling, and we investigate the basic properties of the correlated\nmagnetic noise based on the analytic expressions. The model reproduces the\nmajor trend of the recently measured global correlation between the GW\ndetectors via magnetometer. The estimated values of the impact of correlated\nnoise also match those obtained from the measurement. Finally, we give an\nimplication to the detection of stochastic GWs including upcoming detectors,\nKAGRA and LIGO India. The model suggests that LIGO Hanford-Virgo and\nVirgo-KAGRA pairs are possibly less sensitive to the correlated noise, and can\nachieve a better sensitivity to the stochastic GW signal in the most\npessimistic case. \n\n"}
{"id": "1704.07425", "contents": "Title: The State-of-the-Art HST Astro-Photometric Analysis of the core of\n  $\\omega$ Centauri. I. The Catalog Abstract: We have constructed the most-comprehensive catalog of photometry and proper\nmotions ever assembled for a globular cluster (GC). The core of $\\omega$Cen has\nbeen imaged over 650 times through WFC3's UVIS and IR channels for the purpose\nof detector calibration. There exist from 4 to over 60 exposures through each\nof 26 filters, stretching continuously from F225W in the UV to F160W in the\ninfrared. Furthermore, the 11-year baseline between these data and a 2002 ACS\nsurvey has allowed us to more than double the proper-motion accuracy and triple\nthe number of well-measured stars compared to our previous groundbreaking\neffort. This totally unprecedented complete spectral coverage for over 470,000\nstars within the cluster's core, from the tip of the red-giant branch down to\nthe white dwarfs, provides the best astro-photometric observational data base\nyet to understand the multiple-population phenomenon in any GC. In this first\npaper of the series we describe in detail the data-reduction processes and\ndeliver the astro-photometric catalog to the astronomical community. \n\n"}
{"id": "1704.08599", "contents": "Title: Multifractal Analysis of Pulsar Timing Residuals: Assessment of\n  Gravitational Wave Detection Abstract: We introduce a pipeline including multifractal detrended cross-correlation\nanalysis (MF-DXA) modified by either singular value decomposition or the\nadaptive method to examine the statistical properties of the pulsar timing\nresidual ($PTR$) induced by a gravitational wave (GW) signal. We propose a new\nalgorithm, the so-called irregular-MF-DXA, to deal with irregular data\nsampling. Inspired by the quadrupolar nature of the spatial cross-correlation\nfunction of a gravitational wave background, a new cross-correlation function,\n$\\bar{\\sigma}_{\\times}$, derived from irregular-MF-DXA will be introduced. We\nshow that, this measure reveals the quadrupolar signature in the $PTRs$ induced\nby stochastic GWB. We propose four strategies based on the $y$-intercept of\nfluctuation functions, the generalized Hurst exponent, and the width of the\nsingularity spectrum to determine the dimensionless amplitude and power-law\nexponent of the characteristic strain spectrum as\n$\\mathcal{H}_c(f)\\sim\\mathcal{A}_{yr}(f/f_{yr})^{\\zeta}$ for stochastic GWB.\nUsing the value of Hurst exponent, one can clarify the type of GWs. We apply\nour pipeline to explore 20 millisecond pulsars observed by Parkes Pulsar Timing\nArray. The computed scaling exponents confirm that all data are classified into\na nonstationary class implying the universality feature. The value of the Hurst\nexponent is in the range $H\\in [0.56,0.87]$. The $q$-dependency of the\ngeneralized Hurst exponent demonstrates that the observed $PTRs$ have\nmultifractal behavior, and the source of this multifractality is mainly\nattributed to the correlation of data which is another universality of the\nobserved datasets. Multifractal analysis of available $PTRs$ datasets reveals\nan upper bound on the dimensionless amplitude of the GWB, $\\mathcal{A}_{yr}<\n2.0\\times 10^{-15}$. \n\n"}
{"id": "1704.08745", "contents": "Title: Maximizing Survey Volume for Large-Area Multi-Epoch Surveys with Voronoi\n  Tessellation Abstract: The survey volume of a proper motion-limited sample is typically much smaller\nthan a magnitude-limited sample. This is because of the noisy astrometric\nmeasurements from detectors that are not dedicated for astrometric missions. In\norder to apply an empirical completeness correction, existing works limit the\nsurvey depth to the shallower parts of the sky that hamper the maximum\npotential of a survey. The number of epoch of measurement is a discrete\nquantity that cannot be interpolated across the projected plane of observation,\nso that the survey properties change in discrete steps across the sky. This\nwork proposes a method to dissect the survey into small parts with Voronoi\ntessellation using candidate objects as generating points, such that each part\ndefines a `mini-survey' that has its own properties. Coupling with a maximum\nvolume density estimator, the new method is demonstrated to be unbiased and\nrecovered {\\sim}20% more objects than the existing method in a mock catalogue\nof a white dwarf-only solar neighbourhood with Pan--STARRS 1-like\ncharacteristics. Towards the end of this work, we demonstrate one way to\nincrease the tessellation resolution with artificial generating points, which\nwould be useful for analysis of rare objects with small number counts. \n\n"}
{"id": "1704.08875", "contents": "Title: On the impact of Helium abundance on the Cepheid Period-Luminosity and\n  Wesenheit relations and the Distance Ladder Abstract: This work analyses the effect of the Helium content on synthetic\nPeriod-Luminosity Relations (PLRs) and Period-Wesenheit Relations (PWRs) of\nCepheids and the systematic uncertainties on the derived distances that a\nhidden population of He-enhanced Cepheids may generate. We use new stellar and\npulsation models to build a homogeneous and consistent framework to derive the\nCepheid features. The Cepheid populations expected in synthetic color-magnitude\ndiagrams of young stellar systems (from 20 Myr to 250 Myr) are computed in\nseveral photometric bands for Y = 0.25 and Y = 0.35, at a fixed metallicity (Z\n= 0.008). The PLRs appear to be very similar in the two cases, with negligible\neffects (few %) on distances, while PWRs differ somewhat, with systematic\nuncertainties in deriving distances as high as about 7% at log P < 1.5.\nStatistical effects due to the number of variables used to determine the\nrelations contribute to a distance systematic error of the order of few\npercent, with values decreasing from optical to near-infrared bands. The\nempirical PWRs derived from multi-wavelength datasets for the Large Magellanic\nCloud (LMC) is in a very good agreement with our theoretical PWRs obtained with\na standard He content, supporting the evidence that LMC Cepheids do not show\nany He effect. \n\n"}
{"id": "1705.02007", "contents": "Title: Accelerated Parameter Estimation with DALE$\\chi$ Abstract: We consider methods for improving the estimation of constraints on a\nhigh-dimensional parameter space with a computationally expensive likelihood\nfunction. In such cases Markov chain Monte Carlo (MCMC) can take a long time to\nconverge and concentrates on finding the maxima rather than the often-desired\nconfidence contours for accurate error estimation. We employ DALE$\\chi$ (Direct\nAnalysis of Limits via the Exterior of $\\chi^2$) for determining confidence\ncontours by minimizing a cost function parametrized to incentivize points in\nparameter space which are both on the confidence limit and far from previously\nsampled points. We compare DALE$\\chi$ to the nested sampling algorithm\nimplemented in MultiNest on a toy likelihood function that is highly\nnon-Gaussian and non-linear in the mapping between parameter values and\n$\\chi^2$. We find that in high-dimensional cases DALE$\\chi$ finds the same\nconfidence limit as MultiNest using roughly an order of magnitude fewer\nevaluations of the likelihood function. DALE$\\chi$ is open-source and available\nat https://github.com/danielsf/Dalex.git. \n\n"}
{"id": "1705.03116", "contents": "Title: Spectral performance of Square Kilometre Array Antennas II: Calibration\n  performance Abstract: We test the bandpass smoothness performance of two prototype Square Kilometre\nArray (SKA) SKA1-Low log-periodic dipole antennas, the SKALA2 and SKALA3 (`SKA\nLog-periodic Antenna'), and the current dipole from the Murchison Widefield\nArray (MWA) precursor telescope. Throughout this paper, we refer to the output\ncomplex-valued voltage response of an antenna when connected to a low noise\namplifier (LNA), as the dipole bandpass. In Paper I (de Lera Acedo et al.\n2017), the bandpass spectral response of the log-periodic antenna being\ndeveloped for the SKA1-Low was estimated using numerical electromagnetic\nsimulations and analyzed using low-order polynomial fittings and it was\ncompared with the HERA antenna against the delay spectrum metric. In this work,\nrealistic simulations of the SKA1-Low instrument, including frequency-dependent\nprimary beams and array configuration, are used with a weighted least-squares\npolynomial estimator to assess the ability of prototype antennas to perform the\nSKA Epoch of Reionisation (EoR) statistical experiments. This work complements\nthe ideal estimator tolerances computed for the proposed EoR science\nexperiments in Trott & Wayth (2016), with the realised performance of an\noptimal and standard estimation (calibration) procedure. With a sufficient sky\ncalibration model at higher frequencies, all antennas have bandpasses that are\nsufficiently smooth to meet the tolerances described in Trott & Wayth (2016) to\nperform the EoR statistical experiments, and these are primarily limited by an\nadequate sky calibration model, and the thermal noise level in the calibration\ndata. At frequencies of the Cosmic Dawn (CD), which is of principal interest to\nSKA as one of the first next-generation telescopes capable of accessing higher\nredshifts, the MWA dipole and SKALA3 antenna have adequate performance, while\nthe SKALA2 design will impede the ability to explore this era. \n\n"}
{"id": "1705.04088", "contents": "Title: Poly-instanton axion inflation Abstract: We investigate the axion inflation model derived by poly-instanton effects in\ntype II superstring theories. Poly-instanton effects are instanton effects\ncorrected by another instanton and it can generate the modulus-axion potential\nwith the double exponential function. Although the axion has a period of small\nvalue, this potential can have a flat region because its derivatives are\nexponentially suppressed by non-perturbative effects. From the view point of\nthe cosmic inflation, such potential is interesting. In this paper, we\nnumerically study the possibilities for realizing the cosmic inflation. We also\nstudy their spectral index and other cosmological observables, numerically. \n\n"}
{"id": "1705.04736", "contents": "Title: Input Comparison of Radiogenic Neutron Estimates for Ultra-low\n  Background Experiments Abstract: Ultra-low-background experiments address some of the most important open\nquestions in particle physics, cosmology and astrophysics: the nature of dark\nmatter, whether the neutrino is its own antiparticle, and does the proton\ndecay. These rare event searches require well-understood and minimized\nbackgrounds. Simulations are used to understand backgrounds caused by naturally\noccurring radioactivity in the rock and in every piece of shielding and\ndetector material used in these experiments. Most important are processes like\nspontaneous fission and ({\\alpha},n) reactions in material close to the\ndetectors that can produce neutrons. A comparison study between two dedicated\nsoftware packages is detailed. The cross section libraries, neutron yields, and\nspectra from the Mei-Zhang-Hime and the SOURCES-4A codes are presented. The\nresultant yields and spectra are used as inputs to direct dark matter detector\ntoy models in GEANT4, to study the impact of their differences on background\nestimates and fits. Although differences in neutron yield calculations up to\n50% were seen, there was no systematic difference between the Mei-Hime-Zhang\nand SOURCES-4A results. Neutron propagation simulations smooth differences in\nspectral shape and yield, and both tools were found to meet the broad\nrequirements of the low-background community. \n\n"}
{"id": "1705.05451", "contents": "Title: VICS82: the VISTA-CFHT Stripe 82 near-infrared survey Abstract: We present the VISTA-CFHT Stripe 82 (VICS82) survey: a near-infrared (J+Ks)\nsurvey covering 150 square degrees of the Sloan Digital Sky Survey (SDSS)\nequatorial Stripe 82 to an average depth of J=21.9 AB mag and Ks=21.4 AB mag\n(80% completeness limits; 5-sigma point source depths are approximately 0.5 mag\nbrighter). VICS82 contributes to the growing legacy of multi-wavelength data in\nthe Stripe 82 footprint. The addition of near-infrared photometry to the\nexisting SDSS Stripe 82 coadd ugriz photometry reduces the scatter in stellar\nmass estimates to delta log(M_stellar)~0.3 dex for galaxies with\nM_stellar>10^9M_sun at z~0.5, and offers improvement compared to optical-only\nestimates out to z~1, with stellar masses constrained within a factor of\napproximately 2.5. When combined with other multi-wavelength imaging of the\nStripe, including moderate-to-deep ultraviolet (GALEX), optical and\nmid-infrared (Spitzer IRAC) coverage, as well as tens of thousands of\nspectroscopic redshifts, VICS82 gives access to approximately 0.5 Gpc^3 of\ncomoving volume. Some of the main science drivers of VICS82 include (a)\nmeasuring the stellar mass function of L^star galaxies out to z~1; (b)\ndetecting intermediate redshift quasars at 2<z<3.5; (c) measuring the stellar\nmass function and baryon census of clusters of galaxies, and (d) performing\noptical/near-infrared-cosmic microwave background lensing cross-correlation\nexperiments linking stellar mass to large-scale dark matter structure. Here we\ndefine and describe the survey, highlight some early science results and\npresent the first public data release, which includes an SDSS-matched catalogue\nas well as the calibrated pixel data itself. \n\n"}
{"id": "1705.05620", "contents": "Title: Unsupervised feature-learning for galaxy SEDs with denoising\n  autoencoders Abstract: With the increasing number of deep multi-wavelength galaxy surveys, the\nspectral energy distribution (SED) of galaxies has become an invaluable tool\nfor studying the formation of their structures and their evolution. In this\ncontext, standard analysis relies on simple spectro-photometric selection\ncriteria based on a few SED colors. If this fully supervised classification\nalready yielded clear achievements, it is not optimal to extract relevant\ninformation from the data. In this article, we propose to employ very recent\nadvances in machine learning, and more precisely in feature learning, to derive\na data-driven diagram. We show that the proposed approach based on denoising\nautoencoders recovers the bi-modality in the galaxy population in an\nunsupervised manner, without using any prior knowledge on galaxy SED\nclassification. This technique has been compared to principal component\nanalysis (PCA) and to standard color/color representations. In addition,\npreliminary results illustrate that this enables the capturing of extra\nphysically meaningful information, such as redshift dependence, galaxy mass\nevolution and variation over the specific star formation rate. PCA also results\nin an unsupervised representation with physical properties, such as mass and\nsSFR, although this representation separates out. less other characteristics\n(bimodality, redshift evolution) than denoising autoencoders. \n\n"}
{"id": "1705.05892", "contents": "Title: Warm-hot Gas in X-ray Bright Galaxy Clusters and the H I-deficient\n  Circumgalactic Medium in Dense Environments Abstract: We analyze the intracluster medium (ICM) and circumgalactic medium (CGM) in 7\nX-ray detected galaxy clusters using spectra of background QSOs (HST-COS/STIS),\noptical spectroscopy of the cluster galaxies (MMT/Hectospec and SDSS), and\nX-ray imaging/spectroscopy (XMM-Newton and Chandra). First, we report a very\nlow covering fraction of H I absorption in the CGM of these cluster galaxies,\nf_c = 25% +25%/-15%, to stringent detection limits (log N(H I) < 13 cm^-2). As\nfield galaxies have an H I covering fraction of ~100% at similar radii, the\ndearth of CGM H I in our data indicates that the cluster environment has\neffectively stripped or overionized the gaseous halos of these cluster\ngalaxies. Second, we assess the contribution of warm-hot (10^5 - 10^6 K) gas to\nthe ICM as traced by O VI and broad Ly-alpha (BLA) absorption. Despite the high\nsignal-to-noise of our data, we do not detect O VI in any cluster, and we only\ndetect BLA features in the QSO spectrum probing one cluster. We estimate that\nthe total column density of warm-hot gas along this line of sight totals to ~3%\nof that contained in the hot T > 10^7 K X-ray emitting phase. Residing at high\nrelative velocities, these features may trace pre-shocked material outside the\ncluster. Comparing gaseous galaxy halos from the low-density 'field' to galaxy\ngroups and high-density clusters, we find that the CGM is progressively\ndepleted of H I with increasing environmental density, and the CGM is most\nseverely transformed in galaxy clusters. This CGM transformation may play a key\nrole in environmental galaxy quenching. \n\n"}
{"id": "1705.06179", "contents": "Title: Star formation in galaxies at z~4-5 from the SMUVS survey: a clear\n  starburst/main-sequence bimodality for Halpha emitters on the SFR-M* plane Abstract: We study a large galaxy sample from the Spitzer Matching Survey of the\nUltraVISTA ultra-deep Stripes (SMUVS) to search for sources with enhanced 3.6\nmicron fluxes indicative of strong Halpha emission at z=3.9-4.9. We find that\nthe percentage of \"Halpha excess\" sources reaches 37-40% for galaxies with\nstellar masses log10(M*/Msun) ~ 9-10, and decreases to <20% at log10(M*/Msun) ~\n10.7. At higher stellar masses, however, the trend reverses, although this is\nlikely due to AGN contamination. We derive star formation rates (SFR) and\nspecific SFR (sSFR) from the inferred Halpha equivalent widths (EW) of our\n\"Halpha excess\" galaxies. We show, for the first time, that the \"Halpha excess\"\ngalaxies clearly have a bimodal distribution on the SFR-M* plane: they lie on\nthe main sequence of star formation (with log10(sSFR/yr^{-1})<-8.05) or in a\nstarburst cloud (with log10(sSFR/yr^{-1}) >-7.60). The latter contains ~15% of\nall the objects in our sample and accounts for >50% of the cosmic SFR density\nat z=3.9-4.9, for which we derive a robust lower limit of 0.066 Msun yr^{-1}\nMpc^{-3}. Finally, we identify an unusual >50sigma overdensity of z=3.9-4.9\ngalaxies within a 0.20 x 0.20 sq. arcmin region. We conclude that the SMUVS\nunique combination of area and depth at mid-IR wavelengths provides an\nunprecedented level of statistics and dynamic range which are fundamental to\nreveal new aspects of galaxy evolution in the young Universe. \n\n"}
{"id": "1705.06655", "contents": "Title: First Dark Matter Search Results from the XENON1T Experiment Abstract: We report the first dark matter search results from XENON1T, a\n$\\sim$2000-kg-target-mass dual-phase (liquid-gas) xenon time projection chamber\nin operation at the Laboratori Nazionali del Gran Sasso in Italy and the first\nton-scale detector of this kind. The blinded search used 34.2 live days of data\nacquired between November 2016 and January 2017. Inside the (1042$\\pm$12) kg\nfiducial mass and in the [5, 40] $\\mathrm{keV}_{\\mathrm{nr}}$ energy range of\ninterest for WIMP dark matter searches, the electronic recoil background was\n$(1.93 \\pm 0.25) \\times 10^{-4}$ events/(kg $\\times$ day $\\times\n\\mathrm{keV}_{\\mathrm{ee}}$), the lowest ever achieved in a dark matter\ndetector. A profile likelihood analysis shows that the data is consistent with\nthe background-only hypothesis. We derive the most stringent exclusion limits\non the spin-independent WIMP-nucleon interaction cross section for WIMP masses\nabove 10 GeV/c${}^2$, with a minimum of 7.7 $\\times 10^{-47}$ cm${}^2$ for\n35-GeV/c${}^2$ WIMPs at 90% confidence level. \n\n"}
{"id": "1705.10320", "contents": "Title: Modelling ultraviolet-line diagnostics of stars, the ionized and the\n  neutral interstellar medium in star-forming galaxies Abstract: We combine state-of-the-art models for the production of stellar radiation\nand its transfer through the interstellar medium (ISM) to investigate\nultraviolet-line diagnostics of stars, the ionized and the neutral ISM in\nstar-forming galaxies. We start by assessing the reliability of our stellar\npopulation synthesis modelling by fitting absorption-line indices in the\nISM-free ultraviolet spectra of 10 Large-Magellanic-Cloud clusters. In doing\nso, we find that neglecting stochastic sampling of the stellar initial mass\nfunction in these young ($\\sim10$-100 Myr), low-mass clusters affects\nnegligibly ultraviolet-based age and metallicity estimates but can lead to\nsignificant overestimates of stellar mass. Then, we proceed and develop a\nsimple approach, based on an idealized description of the main features of the\nISM, to compute in a physically consistent way the combined influence of\nnebular emission and interstellar absorption on ultraviolet spectra of\nstar-forming galaxies. Our model accounts for the transfer of radiation through\nthe ionized interiors and outer neutral envelopes of short-lived stellar birth\nclouds, as well as for radiative transfer through a diffuse intercloud medium.\nWe use this approach to explore the entangled signatures of stars, the ionized\nand the neutral ISM in ultraviolet spectra of star-forming galaxies. We find\nthat, aside from a few notable exceptions, most standard ultraviolet indices\ndefined in the spectra of ISM-free stellar populations are prone to significant\ncontamination by the ISM, which increases with metallicity. We also identify\nseveral nebular-emission and interstellar-absorption features, which stand out\nas particularly clean tracers of the different phases of the ISM. \n\n"}
{"id": "1706.00117", "contents": "Title: Dark Matter Detection Using Helium Evaporation and Field Ionization Abstract: We describe a method for dark matter detection based on the evaporation of\nhelium atoms from a cold surface and their subsequent detection using field\nionization. When a dark matter particle scatters off a nucleus of the target\nmaterial, elementary excitations (phonons or rotons) are produced. Excitations\nwhich have an energy greater than the binding energy of helium to the surface\ncan result in the evaporation of helium atoms. We propose to detect these atoms\nby ionizing them in a strong electric field. Because the binding energy of\nhelium to surfaces can be below 1~meV, this detection scheme opens up new\npossibilities for the detection of dark matter particles in a mass range down\nto 1~MeV/c$^{2}$. \n\n"}
{"id": "1706.01202", "contents": "Title: Statistical Significance of spectral lag transition in GRB 160625B Abstract: Recently Wei et al (arXiv:1612.09425) have found evidence for a transition\nfrom positive time lags to negative time lags in the spectral lag data of GRB\n160625B. They have fit these observed lags to a sum of two components: an\nassumed functional form for intrinsic time lag due to astrophysical mechanisms\nand an energy-dependent speed of light due to quadratic and linear Loren tz\ninvariance violation (LIV) models. Here, we examine the statistical\nsignificance of the evidence for a transition to nega tive time lags. Such a\ntransition, even if present in GRB 160625B, cannot be due to an energy\ndependent speed of light as th is would contradict previous limits by some 3-4\norders of magnitude, and must therefore be of intrinsic astrophysical origin .\nWe use three different model comparison techniques: a frequentist test and two\ninformation based criteria (AIC and BIC). From the frequentist model comparison\ntest, we find that the evidence for transition in the spectral lag data is\nfavored at $3.05\\sigma$ and $3.74\\sigma$ for the linear and quadratic models\nrespectively. We find that $\\Delta$AIC and $\\Delta$BIC have values $\\gtrsim$ 10\nfor the spectral lag transition that was motivated as being due to quadratic\nLorentz invariance vio lating model pointing to \"decisive evidence\". We note\nhowever that none of the three models (including the model of intr insic\nastrophysical emission) provide a good fit to the data. \n\n"}
{"id": "1706.01629", "contents": "Title: Markov Chain Monte Carlo Methods for Bayesian Data Analysis in Astronomy Abstract: Markov Chain Monte Carlo based Bayesian data analysis has now become the\nmethod of choice for analyzing and interpreting data in almost all disciplines\nof science. In astronomy, over the last decade, we have also seen a steady\nincrease in the number of papers that employ Monte Carlo based Bayesian\nanalysis. New, efficient Monte Carlo based methods are continuously being\ndeveloped and explored. In this review, we first explain the basics of Bayesian\ntheory and discuss how to set up data analysis problems within this framework.\nNext, we provide an overview of various Monte Carlo based methods for\nperforming Bayesian data analysis. Finally, we discuss advanced ideas that\nenable us to tackle complex problems and thus hold great promise for the\nfuture. We also distribute downloadable computer software (available at\nhttps://github.com/sanjibs/bmcmc/ ) that implements some of the algorithms and\nexamples discussed here. \n\n"}
{"id": "1706.01798", "contents": "Title: Monitoring Telluric Absorption with CAMAL Abstract: Ground-based astronomical observations may be limited by telluric water vapor\nabsorption, which is highly variable in time and significantly complicates both\nspectroscopy and photometry in the near-infrared (NIR). To achieve the\nsensitivity required to detect Earth-sized exoplanets in the NIR, simultaneous\nmonitoring of precipitable water vapor (PWV) becomes necessary to mitigate the\nimpact of variable telluric lines on radial velocity measurements and transit\nlight curves. To address this issue, we present the Camera for the Automatic\nMonitoring of Atmospheric Lines (CAMAL), a stand-alone, inexpensive six-inch\naperture telescope dedicated to measuring PWV at the Fred Lawrence Whipple\nObservatory on Mount Hopkins. CAMAL utilizes three narrowband NIR filters to\ntrace the amount of atmospheric water vapor affecting simultaneous observations\nwith the MINiature Exoplanet Radial Velocity Array (MINERVA) and MINERVA-Red\ntelescopes. Here we present the current design of CAMAL, discuss our data\nanalysis methods, and show results from 11 nights of PWV measurements taken\nwith CAMAL. For seven nights of data, we have independent PWV measurements\nextracted from high-resolution stellar spectra taken with the Tillinghast\nReflector Echelle Spectrometer (TRES) also located on Mount Hopkins. We use the\nTRES spectra to calibrate the CAMAL absolute PWV scale. Comparisons between\nCAMAL and TRES PWV estimates show excellent agreement, matching to within 1 mm\nover a 10 mm range in PWV. Analysis of CAMAL's photometric precision propagates\nto PWV measurements precise to better than 0.5 mm in dry (PWV < 4 mm)\nconditions. We also find that CAMAL-derived PWVs are highly correlated with\nthose from a GPS-based water vapor monitor located approximately 90 km away at\nKitt Peak National Observatory, with a root mean square PWV difference of 0.8\nmm. \n\n"}
{"id": "1706.03556", "contents": "Title: Testing Isotropic Universe Using the Gamma-Ray Burst Data of Fermi / GBM Abstract: The sky distribution of Gamma-Ray Bursts (GRBs) has been intensively studied\nby various groups for more than two decades. Most of these studies test the\nisotropy of GRBs based on their sky number density distribution. In this work\nwe propose an approach to test the isotropy of the Universe through inspecting\nthe isotropy of the properties of GRBs such as their duration, fluences and\npeak fluxes at various energy bands and different time scales. We apply this\nmethod on the {\\em Fermi} / Gamma-ray Burst Monitor (GBM) data sample\ncontaining 1591 GRBs. The most noticeable feature we found is near the Galactic\ncoordinates $l\\approx 30^\\circ$, $b\\approx 15^\\circ$ and radius $r\\approx\n20^\\circ-40^\\circ$. The inferred probability for the occurrence of such an\nanisotropic signal (in a random isotropic sample) is derived to be less than a\npercent in some of the tests while the other tests give results consistent with\nisotropy. These are based on the comparison of the results from the real data\nwith the randomly shuffled data samples. Considering large number of statistics\nwe used in this work (which some of them are correlated to each other) we can\nanticipate that the detected feature could be result of statistical\nfluctuations. Moreover, we noticed a considerably low number of GRBs in this\nparticular patch which might be due to some instrumentation or observational\neffects that can consequently affect our statistics through some systematics.\nFurther investigation is highly desirable in order clarify about this result,\ne.g. utilizing a larger future {\\em Fermi} / GBM data sample as well as data\nsamples of other GRB missions and also looking for possible systematics. \n\n"}
{"id": "1706.03795", "contents": "Title: Interstellar communication. I. Maximized data rate for lightweight\n  space-probes Abstract: Recent technological advances could make interstellar travel possible, using\nultra-lightweight sails pushed by lasers or solar photon pressure, at speeds of\na few percent the speed of light. Obtaining remote observational data from such\nprobes is not trivial because of their minimal instrumentation (gram scale) and\nlarge distances (pc). We derive the optimal communication scheme to maximize\nthe data rate between a remote probe and home-base. he framework requires\ncoronagraphic suppression of the stellar background at the level of $10^{-9}$\nwithin a few tenths of an arcsecond of the bright star. Our work includes\nmodels for the loss of photons from diffraction, technological limitations,\ninterstellar extinction, and atmospheric transmission. Major noise sources are\natmospheric, zodiacal, stellar and instrumental. We examine the maximum\ncapacity using the \"Holevo bound\" which gives an upper limit to the amount of\ninformation (bits) that can be encoded through a quantum state (photons), which\nis a few bits per photon for optimistic signal and noise levels. This allows\nfor data rates of order bits per second per Watt from a transmitter of size 1 m\nat a distance of $\\alpha\\,$Centauri (1.3 pc) to an earth-based large receiving\ntelescope (E-ELT, 39 m). The optimal wavelength for this distance is 300 nm\n(space-based receiver) to 400 nm (earth-based) and increases with distance, due\nto extinction, to a maximum of $\\approx3\\,\\mu$m to the center of the galaxy at\n8 kpc. \n\n"}
{"id": "1706.04213", "contents": "Title: Development of a very low-noise cryogenic pre-amplifier for large-area\n  SiPM devices Abstract: Silicon Photomultipliers (SiPMs) are an excellent candidate for the\ndevelopment of large-area light sensors. Large SiPM-based detectors require\nlow-noise pre-amplifiers to maximize the signal coupling between the sensor and\nthe readout electronics. This article reports on the development of a low-noise\ntransimpedance amplifier sensitive to single-photon signals at cryogenic\ntemperature. The amplifier is used to readout a 1 cm$^{2}$ SiPM with a signal\nto noise ratio in excess of 40. \n\n"}
{"id": "1706.04220", "contents": "Title: Development of a novel single-channel, 24~cm$^2$, SiPM-based, cryogenic\n  photodetector Abstract: We report on the realization of a novel SiPM-based, cryogenic photosensor\nwith an active area of 24 cm$^2$ that operates as a single-channel analog\ndetector. The device is capable of single photon counting with a signal to\nnoise ratio better than 13, a dark rate lower than $10^{-2}$ cps/mm$^2$ and an\noverall photon detection efficiency significantly larger than traditional\nphotomultiplier tubes. This development makes SiPM-based photosensors strong\ncandidates for the next generation of dark matter and neutrino detectors, which\nwill require multiple square meters of photosensitive area, low levels of\nintrinsic radioactivity and a limited number of detector channels. \n\n"}
{"id": "1706.05112", "contents": "Title: $\\eta$ Carinae's Dusty Homunculus Nebula from Near-Infrared to\n  Submillimeter Wavelengths: Mass, Composition, and Evidence for Fading Opacity Abstract: Infrared observations of the dusty, massive Homunculus Nebula around the\nluminous blue variable $\\eta$ Carinae are crucial to characterize the mass-loss\nhistory and help constrain the mechanisms leading to the Great Eruption. We\npresent the 2.4 - 670 $\\mu$m spectral energy distribution, constructed from\nlegacy ISO observations and new spectroscopy obtained with the {\\em{Herschel\nSpace Observatory}}. Using radiative transfer modeling, we find that the two\nbest-fit dust models yield compositions which are consistent with CNO-processed\nmaterial, with iron, pyroxene and other metal-rich silicates, corundum, and\nmagnesium-iron sulfide in common. Spherical corundum grains are supported by\nthe good match to a narrow 20.2 $\\mu$m feature. Our preferred model contains\nnitrides AlN and Si$_3$N$_4$ in low abundances. Dust masses range from 0.25 to\n0.44 $M_\\odot$ but $M_{\\rm{tot}} \\ge$ 45 $M_\\odot$ in both cases due to an\nexpected high Fe gas-to-dust ratio. The bulk of dust is within a 5$\"$ $\\times$\n7$\"$ central region. An additional compact feature is detected at 390 $\\mu$m.\nWe obtain $L_{\\rm{IR}}$ = 2.96 $\\times$ 10$^6$ $L_\\odot$, a 25\\% decline from\nan average of mid-IR photometric levels observed in 1971-1977. This indicates a\nreduction in circumstellar extinction in conjunction with an increase in visual\nbrightness, allowing 25-40\\% of optical and UV radiation to escape from the\ncentral source. We also present an analysis of $^{12}$CO and $^{13}$CO $J =\n5-4$ through $9-8$ lines, showing that the abundances are consistent with\nexpectations for CNO-processed material. The [$^{12}$C~{\\sc{ii}}] line is\ndetected in absorption, which we suspect originates in foreground material at\nvery low excitation temperatures. \n\n"}
{"id": "1706.06512", "contents": "Title: Structuring metadata for the Cherenkov Telescope Array Abstract: The landscape of ground-based gamma-ray astronomy is drastically changing\nwith the perspective of the Cherenkov Telescope Array (CTA) composed of more\nthan 100 Cherenkov telescopes. For the first time in this energy domain, CTA\nwill be operated as an observatory open to the astronomy community. In this\ncontext, a structured high level data model is being developed to describe a\nCTA observation. The data model includes different classes of metadata on the\nproject definition, the configuration of the instrument, the ambient\nconditions, the data acquisition and the data processing. This last part relies\non the Provenance Data Model developed within the International Virtual\nObservatory Alliance (IVOA), for which CTA is one of the main use cases. The\nCTA data model should also be compatible with the Virtual Observatory (VO) for\ndata diffusion. We have thus developed a web-based data diffusion prototype to\ntest this requirement and ensure the compliance. \n\n"}
{"id": "1706.07798", "contents": "Title: Electromagnetic forces on a relativistic spacecraft in the interstellar\n  medium Abstract: A relativistic spacecraft of the type envisioned by the Breakthrough Starshot\ninitiative will inevitably get charged through collisions with interstellar\nparticles and UV photons. Interstellar magnetic fields would, therefore,\ndeflect the trajectory of the spacecraft. We calculate the expected deflection\nfor typical interstellar conditions. We also find that the charge distribution\nof the spacecraft is asymmetric, producing an electric dipole moment. The\ninteraction between the moving electric dipole and the interstellar magnetic\nfield is found to produce a large torque, which can result in fast oscillation\nof the spacecraft around the axis perpendicular to the direction of motion,\nwith a period of $\\sim$ 0.5 hr. We then study the spacecraft rotation arising\nfrom impulsive torques by dust bombardment. Finally, we discuss the effect of\nthe spacecraft rotation and suggest several methods to mitigate it. \n\n"}
{"id": "1706.09424", "contents": "Title: COSMOGRAIL XVI: Time delays for the quadruply imaged quasar DES\n  J0408-5354 with high-cadence photometric monitoring Abstract: We present time-delay measurements for the new quadruply imaged quasar DES\nJ0408-5354, the first quadruply imaged quasar found in the Dark Energy Survey\n(DES). Our result is made possible by implementing a new observational strategy\nusing almost daily observations with the MPIA 2.2m telescope at La Silla\nobservatory and deep exposures reaching a signal-to-noise ratio of about 1000\nper quasar image. This data quality allows us to catch small photometric\nvariations (a few mmag rms) of the quasar, acting on temporal scales much\nshorter than microlensing, hence making the time delay measurement very robust\nagainst microlensing. In only 7 months we measure very accurately one of the\ntime delays in DES J0408-5354: Dt(AB) = -112.1 +- 2.1 days (1.8%) using only\nthe MPIA 2.2m data. In combination with data taken with the 1.2m Euler Swiss\ntelescope, we also measure two delays involving the D component of the system\nDt(AD) = -155.5 +- 12.8 days (8.2%) and Dt(BD) = -42.4 +- 17.6 days (41%),\nwhere all the error bars include systematics. Turning these time delays into\ncosmological constraints will require deep HST imaging or ground-based Adaptive\nOptics (AO), and information on the velocity field of the lensing galaxy. \n\n"}
{"id": "1707.01632", "contents": "Title: Low-Mass Dark Matter Search with CDMSlite Abstract: The SuperCDMS experiment is designed to directly detect weakly interacting\nmassive particles (WIMPs) that may constitute the dark matter in our Galaxy.\nDuring its operation at the Soudan Underground Laboratory, germanium detectors\nwere run in the CDMSlite mode to gather data sets with sensitivity specifically\nfor WIMPs with masses ${<}$10 GeV/$c^2$. In this mode, a higher detector-bias\nvoltage is applied to amplify the phonon signals produced by drifting charges.\nThis paper presents studies of the experimental noise and its effect on the\nachievable energy threshold, which is demonstrated to be as low as 56\neV$_{\\text{ee}}$ (electron equivalent energy). The detector-biasing\nconfiguration is described in detail, with analysis corrections for voltage\nvariations to the level of a few percent. Detailed studies of the\nelectric-field geometry, and the resulting successful development of a fiducial\nparameter, eliminate poorly measured events, yielding an energy resolution\nranging from ${\\sim}$9 eV$_{\\text{ee}}$ at 0 keV to 101 eV$_{\\text{ee}}$ at\n${\\sim}$10 eV$_{\\text{ee}}$. New results are derived for astrophysical\nuncertainties relevant to the WIMP-search limits, specifically examining how\nthey are affected by variations in the most probable WIMP velocity and the\nGalactic escape velocity. These variations become more important for WIMP\nmasses below 10 GeV/$c^2$. Finally, new limits on spin-dependent low-mass\nWIMP-nucleon interactions are derived, with new parameter space excluded for\nWIMP masses $\\lesssim$3 GeV/$c^2$ \n\n"}
{"id": "1707.03730", "contents": "Title: Exoplanet Transits as the Foundation of an Interstellar Communications\n  Network Abstract: Two fundamental problems for extraterrestrial intelligences (ETIs) attempting\nto establish interstellar communication are timing and energy consumption.\nHumanity's study of exoplanets via their transit across the host star\nhighlights a means of solving both problems. An ETI 'A' can communicate with\nETI 'B' if B is observing transiting planets in A's star system, either by\nbuilding structures to produce artificial transits observable by B, or by\nemitting signals at B during transit, at significantly lower energy consumption\nthan typical electromagnetic transmission schemes.\n  This can produce a network of interconnected civilisations, establishing\ncontact via observing each other's transits. Assuming that civilisations reside\nin a Galactic Habitable Zone (GHZ), I conduct Monte Carlo Realisation\nsimulations of the establishment and growth of this network, and analyse its\nproperties in the context of graph theory.\n  I find that at any instant, only a few civilisations are correctly aligned to\ncommunicate via transits. However, we should expect the true network to be\ncumulative, where a \"handshake\" connection at any time guarantees connection in\nthe future via e.g. electromagnetic signals. In all our simulations, the\ncumulative network connects all civilisations together in a complete network.\nIf civilisations share knowledge of their network connections, the network can\nbe fully complete on timescales of order a hundred thousand years. Once\nestablished, this network can connect any two civilisations either directly, or\nvia intermediate civilisations, with a path much less than the dimensions of\nthe GHZ. \n\n"}
{"id": "1707.04591", "contents": "Title: US Cosmic Visions: New Ideas in Dark Matter 2017: Community Report Abstract: This white paper summarizes the workshop \"U.S. Cosmic Visions: New Ideas in\nDark Matter\" held at University of Maryland on March 23-25, 2017. \n\n"}
{"id": "1707.05335", "contents": "Title: Simulated foreground predictions for HI at z = 3.35 with the Ooty Wide\n  Field Array: I. Instrument and the foregrounds Abstract: Foreground removal is the most important step in detecting the large-scale\nredshifted HI 21-cm signal. Modelling foreground spectra is challenging and is\nfurther complicated by the chromatic response of the telescope. We present a\nmulti-frequency angular power spectrum (MAPS) estimator for use in a survey for\nredshifted HI 21-cm emission from z~3.35, and demonstrate its ability to\naccurately characterize the foregrounds. This survey will be carried out with\nthe two wide-field interferometer modes of the upgraded Ooty Radio Telescope,\ncalled the Ooty Wide Field Array (OWFA), at 326.5 MHz. We have tailored the\ntwo-visibility correlation for OWFA to estimate the MAPS and test it with\nsimulated foregrounds. In the process, we describe a software model that\nencodes the geometry and the details of the telescope, and simulates a\nrealistic model for the bright radio sky. This article presents simulations\nwhich include the full chromatic response of the telescope, in addition to the\nfrequency dependence intrinsic to the foregrounds. We find that the visibility\ncorrelation MAPS estimator recovers the input angular power spectrum\naccurately, and that the instrument response to the foregrounds dominates the\nsystematic errors in the recovered foreground power spectra. \n\n"}
{"id": "1707.07010", "contents": "Title: How To Model Supernovae in Simulations of Star and Galaxy Formation Abstract: We study the implementation of mechanical feedback from supernovae (SNe) and\nstellar mass loss in galaxy simulations, within the Feedback In Realistic\nEnvironments (FIRE) project. We present the FIRE-2 algorithm for coupling\nmechanical feedback, which can be applied to any hydrodynamics method (e.g.\nfixed-grid, moving-mesh, and mesh-less methods), and black hole as well as\nstellar feedback. This algorithm ensures manifest conservation of mass, energy,\nand momentum, and avoids imprinting 'preferred directions' on the ejecta. We\nshow that it is critical to incorporate both momentum and thermal energy of\nmechanical ejecta in a self-consistent manner, accounting for SNe cooling radii\nwhen they are not resolved. Using idealized simulations of single SN\nexplosions, we show that the FIRE-2 algorithm, independent of resolution,\nreproduces converged solutions in both energy and momentum. In contrast, common\n'fully-thermal' (energy-dump) or 'fully-kinetic' (particle-kicking) schemes in\nthe literature depend strongly on resolution: when applied at mass resolution\n>100 solar masses, they diverge by orders-of-magnitude from the converged\nsolution. In galaxy-formation simulations, this divergence leads to\norders-of-magnitude differences in galaxy properties, unless those models are\nadjusted in a resolution-dependent way. We show that all models that\nindividually time-resolve SNe converge to the FIRE-2 solution at sufficiently\nhigh resolution. However, in both idealized single-SN simulations and\ncosmological galaxy-formation simulations, the FIRE-2 algorithm converges much\nfaster than other sub-grid models without re-tuning parameters. \n\n"}
{"id": "1707.07668", "contents": "Title: Unlocking Sensitivity for Visibility-based Estimators of the 21 cm\n  Reionization Power Spectrum Abstract: Radio interferometers designed to measure the cosmological 21 cm power\nspectrum require high sensitivity. Several modern low-frequency interferometers\nfeature drift-scan antennas placed on a regular grid to maximize the number of\ninstantaneously coherent (redundant) measurements. However, even for such\nmaximum-redundancy arrays, significant sensitivity comes through partial\ncoherence between baselines. Current visibility-based power-spectrum pipelines,\nthough shown to ease control of systematics, lack the ability to make use of\nthis partial redundancy. We introduce a method to leverage partial redundancy\nin such power-spectrum pipelines for drift-scan arrays. Our method\ncross-multiplies baseline pairs at a time lag and quantifies the sensitivity\ncontributions of each pair of baselines. Using the configurations and beams of\nthe 128-element Donald C. Backer Precision Array for Probing the Epoch of\nReionization (PAPER-128) and staged deployments of the Hydrogen Epoch of\nReionization Array, we illustrate how our method applies to different arrays\nand predict the sensitivity improvements associated with pairing partially\ncoherent baselines. As the number of antennas increases, we find partial\nredundancy to be of increasing importance in unlocking the full sensitivity of\nupcoming arrays. \n\n"}
{"id": "1707.08121", "contents": "Title: An improved model of redshift-space distortions around voids:\n  application to quintessence dark energy Abstract: Using cosmic voids to probe the growth rate of cosmic structure, and hence\nthe nature of dark energy, is particularly interesting in the context of\nmodified gravity theories that rely on the screening mechanism. In this work we\nimprove the modelling of redshift-space distortions around voids in the dark\nmatter density field, and thus reduce systematic errors in the derivation of\ncosmological parameters. We also show how specific types of voids can be used\nto better probe the growth rate, using a flexible void finder. We apply our\nresults to test for a quintessence type of dark energy vs. a LCDM model, and\nfind a good agreement with the fiducial cosmology after implementing an\nanalytical correction to the radial velocity profiles around voids. We\nadditionally outline characteristic imprints of dark energy in the dark matter\nvelocity distributions around voids. \n\n"}
{"id": "1707.09551", "contents": "Title: Fermipy: An open-source Python package for analysis of Fermi-LAT Data Abstract: Fermipy is an open-source python framework that facilitates analysis of data\ncollected by the Fermi Large Area Telescope (LAT). Fermipy is built on the\nFermi Science Tools, the publicly available software suite provided by NASA for\nthe LAT mission. Fermipy provides a high-level interface for analyzing LAT data\nin a simple and reproducible way. The current feature set includes methods for\nextracting spectral energy distributions and lightcurves, generating test\nstatistic maps, finding new source candidates, and fitting source position and\nextension. Fermipy leverages functionality from other scientific python\npackages including NumPy, SciPy, Matplotlib, and Astropy and is organized as a\ncommunity-developed package following an open-source development model. We\nreview the current functionality of Fermipy and plans for future development. \n\n"}
{"id": "1708.00037", "contents": "Title: Magellan/M2FS Spectroscopy of Galaxy Clusters: Stellar Population Model\n  and Application to Abell 267 Abstract: We report the results of a pilot program to use the Magellan/M2FS\nspectrograph to survey the galactic populations and internal kinematics of\ngalaxy clusters. For this initial study, we present spectroscopic measurements\nfor $223$ quiescent galaxies observed along the line of sight to the galaxy\ncluster Abell 267 ($z\\sim0.23$). We develop a Bayesian method for modeling the\nintegrated light from each galaxy as a simple stellar population, with free\nparameters that specify redshift ($v_\\mathrm{los}/c$) and characteristic age,\nmetallicity ($\\mathrm{[Fe/H]}$), alpha-abundance ($[\\alpha/\\mathrm{Fe}]$), and\ninternal velocity dispersion ($\\sigma_\\mathrm{int}$) for individual galaxies.\nParameter estimates derived from our 1.5-hour observation of A267 have median\nrandom errors of $\\sigma_{v_\\mathrm{los}}=20\\ \\mathrm{km\\ s^{-1}}$,\n$\\sigma_{\\mathrm{Age}}=1.2\\ \\mathrm{Gyr}$, $\\sigma_{\\mathrm{[Fe/H]}}=0.11\\\n\\mathrm{dex}$, $\\sigma_{[\\alpha/\\mathrm{Fe}]}=0.07\\ \\mathrm{dex}$, and\n$\\sigma_{\\sigma_\\mathrm{int}}=20\\ \\mathrm{km\\ s^{-1}}$. In a companion paper,\nwe use these results to model the structure and internal kinematics of A267. \n\n"}
{"id": "1708.00090", "contents": "Title: A Next Generation Low Band Observatory: A Community Study Exploring Low\n  Frequency Options for ngVLA Abstract: We present a community study exploring the low frequency (5 - 800 MHz)\noptions and opportunities for the ngVLA project and its infrastructure. We\ndescribe a Next Generation LOw Band Observatory (ngLOBO) that will provide\naccess to the low frequency sky in a commensal fashion, operating independently\nfrom the ngVLA, but leveraging common infrastructure. This approach provides\ncontinuous coverage through an aperture array (called ngLOBO-Low) below 150 MHz\nand by accessing the primary focus of the ngVLA antennas (called ngLOBO-High)\nabove 150 MHz. ngLOBO preconditions include a) non-interference and b) low\nrelative cost (<5%) with respect to ngVLA.\n  ngLOBO has three primary scientific missions: (1) Radio Large Synoptic Survey\nTelescope (Radio-LSST): one naturally wide beam, commensal with ngVLA, will\nconduct a continuous synoptic survey of large swaths of the sky for both slow\nand fast transients; (2) This same commensal beam will provide complementary\nlow frequency images of all ngVLA targets and their environment {\\it when such\ndata enhances their value}. (3) Independent beams from the ngLOBO-Low aperture\narray will conduct research in astrophysics, Earth science and space weather\napplications, engaging new communities and attracting independent resources. If\nngVLA operates down to 2 GHz or lower, ngLOBO data will enhance ngVLA\ncalibration and dynamic scheduling. Finally, non-variable field sources outside\nthe ngVLA field of view can be harvested for serendipitous science, e.g.\npopulation studies for thermal and non-thermal continuum sources.\n  The ngVLA will be a superb, high frequency instrument; ngLOBO will allow it\nto participate in the worldwide renaissance in low frequency science as well. \n\n"}
{"id": "1708.01619", "contents": "Title: Hydrogen-Poor Superluminous Supernovae from the Pan-STARRS1 Medium Deep\n  Survey Abstract: We present light curves and classification spectra of 17 hydrogen-poor\nsuperluminous supernovae (SLSNe) from the Pan-STARRS1 Medium Deep Survey (PS1\nMDS). Our sample contains all objects from the PS1 MDS sample with\nspectroscopic classification that are similar to either of the prototypes\nSN2005ap or SN2007bi, without an explicit limit on luminosity. With a redshift\nrange $0.3 < z < 1.6$, PS1MDS is the first SLSN sample primarily probing the\nhigh-redshift population; our multi-filter PS1 light curves probe the\nrest-frame UV emission, and hence the peak of the spectral energy distribution.\nWe measure the temperature evolution and construct bolometric light curves, and\nfind peak luminosities of $(0.5-5) \\times 10^{44}$ erg s$^{-1}$ and lower\nlimits on the total radiated energies of $(0.3-2) \\times 10^{51}$ erg. The\nlight curve shapes are diverse, with both rise- and decline times spanning a\nfactor of $\\sim 5$, and several examples of double-peaked light curves. When\ncorrecting for the flux-limited nature of our survey, we find a median peak\nluminosity at 4000 {\\AA} of $M_{\\rm 4000} = -21.1$ mag, and a spread of $\\sigma\n= 0.7$ mag. \n\n"}
{"id": "1708.01623", "contents": "Title: Light curves of hydrogen-poor Superluminous Supernovae from the Palomar\n  Transient Factory Abstract: We investigate the light-curve properties of a sample of 26 spectroscopically\nconfirmed hydrogen-poor superluminous supernovae (SLSNe-I) in the Palomar\nTransient Factory (PTF) survey. These events are brighter than SNe Ib/c and SNe\nIc-BL, on average, by about 4 and 2~mag, respectively. The peak absolute\nmagnitudes of SLSNe-I in rest-frame $g$ band span $-22\\lesssim M_g\n\\lesssim-20$~mag, and these peaks are not powered by radioactive $^{56}$Ni,\nunless strong asymmetries are at play. The rise timescales are longer for SLSNe\nthan for normal SNe Ib/c, by roughly 10 days, for events with similar decay\ntimes. Thus, SLSNe-I can be considered as a separate population based on\nphotometric properties. After peak, SLSNe-I decay with a wide range of slopes,\nwith no obvious gap between rapidly declining and slowly declining events. The\nlatter events show more irregularities (bumps) in the light curves at all\ntimes. At late times, the SLSN-I light curves slow down and cluster around the\n$^{56}$Co radioactive decay rate. Powering the late-time light curves with\nradioactive decay would require between 1 and 10${\\rm M}_\\odot$ of Ni masses.\nAlternatively, a simple magnetar model can reasonably fit the majority of\nSLSNe-I light curves, with four exceptions, and can mimic the radioactive decay\nof $^{56}$Co, up to $\\sim400$ days from explosion. The resulting spin values do\nnot correlate with the host-galaxy metallicities. Finally, the analysis of our\nsample cannot strengthen the case for using SLSNe-I for cosmology. \n\n"}
{"id": "1708.02051", "contents": "Title: Color difference makes a difference: four planet candidates around tau\n  Ceti Abstract: The removal of noise typically correlated in time and wavelength is one of\nthe main challenges for using the radial velocity method to detect Earth\nanalogues. We analyze radial velocity data of tau Ceti and find robust evidence\nfor wavelength dependent noise. We find this noise can be modeled by a\ncombination of moving average models and \"differential radial velocities\". We\napply this noise model to various radial velocity data sets for tau Ceti, and\nfind four periodic signals at 20.0, 49.3, 160 and 642 d which we interpret as\nplanets. We identify two new signals with orbital periods of 20.0 and 49.3 d\nwhile the other two previously suspected signals around 160 and 600 d are\nquantified to a higher precision. The 20.0 d candidate is independently\ndetected in KECK data. All planets detected in this work have minimum masses\nless than 4$M_\\oplus$ with the two long period ones located around the inner\nand outer edges of the habitable zone, respectively. We find that the\ninstrumental noise gives rise to a precision limit of the HARPS around 0.2 m/s.\nWe also find correlation between the HARPS data and the central moments of the\nspectral line profile at around 0.5 m/s level, although these central moments\nmay contain both noise and signals. The signals detected in this work have\nsemi-amplitudes as low as 0.3 m/s, demonstrating the ability of the radial\nvelocity technique to detect relatively weak signals. \n\n"}
{"id": "1708.03325", "contents": "Title: Morphological estimators on Sunyaev--Zel'dovich maps of MUSIC clusters\n  of galaxies Abstract: The determination of the morphology of galaxy clusters has important\nrepercussion on their cosmological and astrophysical studies. In this paper we\naddress the morphological characterisation of synthetic maps of the\nSunyaev--Zel'dovich (SZ) effect produced for a sample of 258 massive clusters\n($M_{vir}>5\\times10^{14}h^{-1}$M$_\\odot$ at $z=0$), extracted from the MUSIC\nhydrodynamical simulations. Specifically, we apply five known morphological\nparameters, already used in X-ray, two newly introduced ones, and we combine\nthem together in a single parameter. We analyse two sets of simulations\nobtained with different prescriptions of the gas physics (non radiative and\nwith cooling, star formation and stellar feedback) at four redshifts between\n0.43 and 0.82. For each parameter we test its stability and efficiency to\ndiscriminate the true cluster dynamical state, measured by theoretical\nindicators. The combined parameter discriminates more efficiently relaxed and\ndisturbed clusters. This parameter had a mild correlation with the hydrostatic\nmass ($\\sim 0.3$) and a strong correlation ($\\sim 0.8$) with the offset between\nthe SZ centroid and the cluster centre of mass. The latter quantity results as\nthe most accessible and efficient indicator of the dynamical state for SZ\nstudies. \n\n"}
{"id": "1708.03649", "contents": "Title: An algorithm for the reconstruction of neutrino-induced showers in the\n  ANTARES neutrino telescope Abstract: Muons created by $\\nu_\\mu$ charged current (CC) interactions in the water\nsurrounding the ANTARES neutrino telescope have been almost exclusively used so\nfar in searches for cosmic neutrino sources. Due to their long range, highly\nenergetic muons inducing Cherenkov radiation in the water are reconstructed\nwith dedicated algorithms that allow the determination of the parent neutrino\ndirection with a median angular resolution of about \\unit{0.4}{\\degree} for an\n$E^{-2}$ neutrino spectrum. In this paper, an algorithm optimised for accurate\nreconstruction of energy and direction of shower events in the ANTARES detector\nis presented. Hadronic showers of electrically charged particles are produced\nby the disintegration of the nucleus both in CC and neutral current (NC)\ninteractions of neutrinos in water. In addition, electromagnetic showers result\nfrom the CC interactions of electron neutrinos while the decay of a tau lepton\nproduced in $\\nu_\\tau$ CC interactions will in most cases lead to either a\nhadronic or an electromagnetic shower. A shower can be approximated as a point\nsource of photons. With the presented method, the shower position is\nreconstructed with a precision of about \\unit{1}{\\metre}, the neutrino\ndirection is reconstructed with a median angular resolution between\n\\unit{2}{\\degree} and \\unit{3}{\\degree} in the energy range of\n\\SIrange{1}{1000}{TeV}. In this energy interval, the uncertainty on the\nreconstructed neutrino energy is about \\SIrange{5}{10}{\\%}. The increase in the\ndetector sensitivity due to the use of additional information from shower\nevents in the searches for a cosmic neutrino flux is also presented. \n\n"}
{"id": "1708.04032", "contents": "Title: HAWC High Energy Upgrade with a Sparse Outrigger Array Abstract: The High Altitude Water Cherenkov (HAWC) gamma-ray observatory consists of\n300 water Cherenkov detectors and has been fully operational since March 2015\nin central Mexico. It detects cosmic- and gamma-ray showers in the TeV energy\nrange. For multi-TeV energies, the shower reconstruction and hence the\nperformance of the detector is affected by the partial containment of the\nshowers within the array. To improve the sensitivity at the highest energies,\nHAWC is being upgraded with an outrigger array. It consists of 350 comparably\nmuch smaller water Cherenkov detectors, sparsely distributed around the HAWC\nmain array. It will increase the instrumented area by a factor of 4-5. In this\ncontribution, we will present the current status of the upgrade as well as\nsimulation results on anticipated improvements in the performance of the\nobservatory. \n\n"}
{"id": "1708.04477", "contents": "Title: Methods of Reverberation Mapping. I. Time-lag Determination by Measures\n  of Randomness Abstract: A class of methods for measuring time delays between astronomical time series\nis introduced in the context of quasar reverberation mapping, which is based on\nmeasures of randomness or complexity of the data. Several distinct statistical\nestimators are considered that do not rely on polynomial interpolations of the\nlight curves nor on their stochastic modeling, and do not require binning in\ncorrelation space. Methods based on von Neumann's mean-square\nsuccessive-difference estimator are found to be superior to those using other\nestimators. An optimized von Neumann scheme is formulated, which better handles\nsparsely sampled data and outperforms current implementations of discrete\ncorrelation function methods. This scheme is applied to existing reverberation\ndata of varying quality, and consistency with previously reported time delays\nis found. In particular, the size-luminosity relation of the broad-line region\nin quasars is recovered with a scatter comparable to that obtained by other\nworks, yet with fewer assumptions made concerning the process underlying the\nvariability. The proposed method for time-lag determination is particularly\nrelevant for irregularly sampled time series, and in cases where the process\nunderlying the variability cannot be adequately modeled. \n\n"}
{"id": "1708.04618", "contents": "Title: Spatially resolved MaNGA observations of the host galaxy of\n  superluminous supernova 2017egm Abstract: Superluminous supernovae (SLSNe) are found predominantly in dwarf galaxies,\nindicating that their progenitors have a low metallicity. However, the most\nnearby SLSN to date, SN 2017egm, occurred in the spiral galaxy NGC 3191, which\nhas a relatively high stellar mass and correspondingly high metallicity. In\nthis paper, we present detailed analysis of the nearby environment of SN\n2017egm using MaNGA IFU data, which provides spectral data on kiloparsec\nscales. From the velocity map we find no evidence that SN 2017egm occurred\nwithin some intervening satellite galaxy, and at the SN position most\nmetallicity diagnostics yield a solar and above solar metallicity (12 + log\n(O/H) = 8.8-9.1). Additionally we measure a small H-alpha equivalent width (EW)\nat the SN position of just 34 Angs, which is one of the lowest EWs measured at\nany SLSN or Gamma-Ray Burst position, and indicative of the progenitor star\nbeing comparatively old. We also compare the observed properties of NGC 3191\nwith other SLSN host galaxies. The solar-metallicity environment at the\nposition of SN 2017egm presents a challenge to our theoretical understanding,\nand our spatially resolved spectral analysis provides further constraints on\nthe progenitors of SLSNe. \n\n"}
{"id": "1708.05250", "contents": "Title: Field dynamics inference via spectral density estimation Abstract: Stochastic differential equations (SDEs) are of utmost importance in various\nscientific and industrial areas. They are the natural description of dynamical\nprocesses whose precise equations of motion are either not known or too\nexpensive to solve, e.g., when modeling Brownian motion. In some cases, the\nequations governing the dynamics of a physical system on macroscopic scales\noccur to be unknown since they typically cannot be deduced from general\nprinciples. In this work, we describe how the underlying laws of a stochastic\nprocess can be approximated by the spectral density of the corresponding\nprocess. Furthermore, we show how the density can be inferred from possibly\nvery noisy and incomplete measurements of the dynamical field. Generally,\ninverse problems like these can be tackled with the help of Information Field\nTheory (IFT). For now, we restrict to linear and autonomous processes. Though,\nthis is a non-conceptual limitation that may be omitted in future work. To\ndemonstrate its applicability we employ our reconstruction algorithm on a\ntime-series and spatio-temporal processes. \n\n"}
{"id": "1708.05642", "contents": "Title: DES Science Portal: Creating Science-Ready Catalogs Abstract: We present a novel approach for creating science-ready catalogs through a\nsoftware infrastructure developed for the Dark Energy Survey (DES). We\nintegrate the data products released by the DES Data Management and additional\nproducts created by the DES collaboration in an environment known as DES\nScience Portal. Each step involved in the creation of a science-ready catalog\nis recorded in a relational database and can be recovered at any time. We\ndescribe how the DES Science Portal automates the creation and characterization\nof lightweight catalogs for DES Year 1 Annual Release, and show its flexibility\nin creating multiple catalogs with different inputs and configurations.\nFinally, we discuss the advantages of this infrastructure for large surveys\nsuch as DES and the Large Synoptic Survey Telescope. The capability of creating\nscience-ready catalogs efficiently and with full control of the inputs and\nconfigurations used is an important asset for supporting science analysis using\ndata from large astronomical surveys. \n\n"}
{"id": "1708.07377", "contents": "Title: AutoLens: Automated Modeling of a Strong Lens's Light, Mass and Source Abstract: This work presents AutoLens, the first entirely automated modeling suite for\nthe analysis of galaxy-scale strong gravitational lenses. AutoLens\nsimultaneously models the lens galaxy's light and mass whilst reconstructing\nthe extended source galaxy on an adaptive pixel-grid. The method's approach to\nsource-plane discretization is amorphous, adapting its clustering and\nregularization to the intrinsic properties of the lensed source. The lens's\nlight is fitted using a superposition of Sersic functions, allowing AutoLens to\ncleanly deblend its light from the source. Single component mass models\nrepresenting the lens's total mass density profile are demonstrated, which in\nconjunction with light modeling can detect central images using a centrally\ncored profile. Decomposed mass modeling is also shown, which can fully decouple\na lens's light and dark matter and determine whether the two component are\ngeometrically aligned. The complexity of the light and mass models are\nautomatically chosen via Bayesian model comparison. These steps form AutoLens's\nautomated analysis pipeline, such that all results in this work are generated\nwithout any user-intervention. This is rigorously tested on a large suite of\nsimulated images, assessing its performance on a broad range of lens profiles,\nsource morphologies and lensing geometries. The method's performance is\nexcellent, with accurate light, mass and source profiles inferred for data sets\nrepresentative of both existing Hubble imaging and future Euclid wide-field\nobservations. \n\n"}
{"id": "1708.08842", "contents": "Title: Fast Automated Analysis of Strong Gravitational Lenses with\n  Convolutional Neural Networks Abstract: Quantifying image distortions caused by strong gravitational lensing and\nestimating the corresponding matter distribution in lensing galaxies has been\nprimarily performed by maximum likelihood modeling of observations. This is\ntypically a time and resource-consuming procedure, requiring sophisticated\nlensing codes, several data preparation steps, and finding the maximum\nlikelihood model parameters in a computationally expensive process with\ndownhill optimizers. Accurate analysis of a single lens can take up to a few\nweeks and requires the attention of dedicated experts. Tens of thousands of new\nlenses are expected to be discovered with the upcoming generation of ground and\nspace surveys, the analysis of which can be a challenging task. Here we report\nthe use of deep convolutional neural networks to accurately estimate lensing\nparameters in an extremely fast and automated way, circumventing the\ndifficulties faced by maximum likelihood methods. We also show that lens\nremoval can be made fast and automated using Independent Component Analysis of\nmulti-filter imaging data. Our networks can recover the parameters of the\nSingular Isothermal Ellipsoid density profile, commonly used to model strong\nlensing systems, with an accuracy comparable to the uncertainties of\nsophisticated models, but about ten million times faster: 100 systems in\napproximately 1s on a single graphics processing unit. These networks can\nprovide a way for non-experts to obtain lensing parameter estimates for large\nsamples of data. Our results suggest that neural networks can be a powerful and\nfast alternative to maximum likelihood procedures commonly used in\nastrophysics, radically transforming the traditional methods of data reduction\nand analysis. \n\n"}
{"id": "1708.08878", "contents": "Title: A Convolutional Neural Network For Cosmic String Detection in CMB\n  Temperature Maps Abstract: We present in detail the convolutional neural network used in our previous\nwork to detect cosmic strings in cosmic microwave background (CMB) temperature\nanisotropy maps. By training this neural network on numerically generated CMB\ntemperature maps, with and without cosmic strings, the network can produce\nprediction maps that locate the position of the cosmic strings and provide a\nprobabilistic estimate of the value of the string tension $G\\mu$. Supplying\nnoiseless simulations of CMB maps with arcmin resolution to the network\nresulted in the accurate determination both of string locations and string\ntension for sky maps having strings with string tension as low as\n$G\\mu=5\\times10^{-9}$. The code is publicly available online. Though we trained\nthe network with a long straight string toy model, we show the network performs\nwell with realistic Nambu-Goto simulations. \n\n"}
{"id": "1709.00283", "contents": "Title: Performance of the MAGIC telescopes under moonlight Abstract: MAGIC, a system of two imaging atmospheric Cherenkov telescopes, achieves its\nbest performance under dark conditions, i.e. in absence of moonlight or\ntwilight. Since operating the telescopes only during dark time would severely\nlimit the duty cycle, observations are also performed when the Moon is present\nin the sky. Here we present a dedicated Moon-adapted analysis and characterize\nthe performance of MAGIC under moonlight. We evaluate energy threshold, angular\nresolution and sensitivity of MAGIC under different background light levels,\nbased on Crab Nebula observations and tuned Monte Carlo simulations. This study\nincludes observations taken under non-standard hardware configurations, such as\nreducing the camera photomultiplier tubes gain by a factor $\\sim$1.7 (reduced\nHV settings) with respect to standard settings (nominal HV) or using UV-pass\nfilters to strongly reduce the amount of moonlight reaching the telescopes\ncameras. The Crab Nebula spectrum is correctly reconstructed in all the studied\nillumination levels, that reach up to 30 times brighter than under dark\nconditions. The main effect of moonlight is an increase in the analysis energy\nthreshold and in the systematic uncertainties on the flux normalization. The\nsensitivity degradation is constrained to be below 10\\%, within 15-30\\% and\nbetween 60 and 80\\% for nominal HV, reduced HV and UV-pass filter observations,\nrespectively. No worsening of the angular resolution was found. Thanks to\nobservations during moonlight, the duty cycle can be doubled, suppressing the\nneed to stop observations around full Moon. \n\n"}
{"id": "1709.01084", "contents": "Title: Solving the conundrum of intervening strong MgII absorbers towards GRBs\n  and quasars Abstract: Previous studies have shown that the incidence rate of intervening strong\nMgII absorbers towards GRBs were a factor of 2 - 4 higher than towards quasars.\nExploring the similar sized and uniformly selected legacy data sets XQ-100 and\nXSGRB, each consisting of 100 quasar and 81 GRB afterglow spectra obtained with\na single instrument (VLT/X-shooter), we demonstrate that there is no\ndisagreement in the number density of strong MgII absorbers with rest-frame\nequivalent widths $W_r^{2796} >$ 1 {\\AA} towards GRBs and quasars in the\nredshift range 0.1 < z < 5. With large and similar sample sizes, and path\nlength coverages of $\\Delta$z = 57.8 and 254.4 for GRBs and quasars,\nrespectively, the incidences of intervening absorbers are consistent within 1\nsigma uncertainty levels at all redshifts. For absorbers at z < 2.3 the\nincidence towards GRBs is a factor of 1.5$\\pm$0.4 higher than the expected\nnumber of strong MgII absorbers in SDSS quasar spectra, while for quasar\nabsorbers observed with X-shooter we find an excess factor of 1.4$\\pm$0.2\nrelative to SDSS quasars. Conversely, the incidence rates agree at all\nredshifts with reported high spectral resolution quasar data, and no excess is\nfound. The only remaining discrepancy in incidences is between SDSS MgII\ncatalogues and high spectral resolution studies. The rest-frame equivalent\nwidth distribution also agrees to within 1 sigma uncertainty levels between the\nGRB and quasar samples. Intervening strong MgII absorbers towards GRBs are\ntherefore neither unusually frequent, nor unusually strong. \n\n"}
{"id": "1709.01537", "contents": "Title: Spectral Calibration of the Fluorescence Telescopes of the Pierre Auger\n  Observatory Abstract: We present a novel method to measure precisely the relative spectral response\nof the fluorescence telescopes of the Pierre Auger Observatory. We used a\nportable light source based on a xenon flasher and a monochromator to measure\nthe relative spectral efficiencies of eight telescopes in steps of 5 nm from\n280 nm to 440 nm. Each point in a scan had approximately 2 nm FWHM out of the\nmonochromator. Different sets of telescopes in the observatory have different\noptical components, and the eight telescopes measured represent two each of the\nfour combinations of components represented in the observatory. We made an\nend-to-end measurement of the response from different combinations of optical\ncomponents, and the monochromator setup allowed for more precise and complete\nmeasurements than our previous multi-wavelength calibrations. We find an\noverall uncertainty in the calibration of the spectral response of most of the\ntelescopes of 1.5% for all wavelengths; the six oldest telescopes have larger\noverall uncertainties of about 2.2%. We also report changes in physics\nmeasureables due to the change in calibration, which are generally small. \n\n"}
{"id": "1709.02052", "contents": "Title: How do stars gain their mass? A JCMT/SCUBA-2 Transient Survey of\n  Protostars in Nearby Star Forming Regions Abstract: Most protostars have luminosities that are fainter than expected from steady\naccretion over the protostellar lifetime. The solution to this problem may lie\nin episodic mass accretion -- prolonged periods of very low accretion\npunctuated by short bursts of rapid accretion. However, the timescale and\namplitude for variability at the protostellar phase is almost entirely\nunconstrained. In \"A JCMT/SCUBA-2 Transient Survey of Protostars in Nearby Star\nForming Regions\", we are monitoring monthly with SCUBA-2 the sub-mm emission in\neight fields within nearby (<500 pc) star forming regions to measure the\naccretion variability of protostars. The total survey area of ~1.6 sq.deg.\nincludes ~105 peaks with peaks brighter than 0.5 Jy/beam (43 associated with\nembedded protostars or disks) and 237 peaks of 0.125-0.5 Jy/beam (50 with\nembedded protostars or disks). Each field has enough bright peaks for flux\ncalibration relative to other peaks in the same field, which improves upon the\nnominal flux calibration uncertainties of sub-mm observations to reach a\nprecision of ~2-3% rms, and also provides quantified confidence in any measured\nvariability. The timescales and amplitudes of any sub-mm variation will then be\nconverted into variations in accretion rate and subsequently used to infer the\nphysical causes of the variability. This survey is the first dedicated survey\nfor sub-mm variability and complements other transient surveys at optical and\nnear-IR wavelengths, which are not sensitive to accretion variability of deeply\nembedded protostars. \n\n"}
{"id": "1709.03264", "contents": "Title: Report: Performance comparison between C2075 and P100 GPU cards using\n  cosmological correlation functions Abstract: In this report, some cosmological correlation functions are used to evaluate\nthe differential performance between C2075 and P100 GPU cards. In the past, the\ncorrelation functions used in this work have been widely studied and exploited\non some previous GPU architectures. The analysis of the performance indicates\nthat a speedup in the range from 13 to 15 is achieved without any additional\noptimization process for the P100 card. \n\n"}
{"id": "1709.03992", "contents": "Title: HST Grism Observations of a Gravitationally Lensed Redshift 10 Galaxy Abstract: We present deep spectroscopic observations of a Lyman-break galaxy candidate\n(hereafter MACS1149-JD) at $z\\sim9.5$ with the $\\textit{Hubble}$ Space\nTelescope ($\\textit{HST}$) WFC3/IR grisms. The grism observations were taken at\n4 distinct position angles, totaling 34 orbits with the G141 grism, although\nonly 19 of the orbits are relatively uncontaminated along the trace of\nMACS1149-JD. We fit a 3-parameter ($z$, F160W mag, and Ly$\\alpha$ equivalent\nwidth) Lyman-break galaxy template to the three least contaminated grism\nposition angles using an MCMC approach. The grism data alone are best fit with\na redshift of $z_{\\mathrm{grism}}=9.53^{+0.39}_{-0.60}$ ($68\\%$ confidence), in\ngood agreement with our photometric estimate of\n$z_{\\mathrm{phot}}=9.51^{+0.06}_{-0.12}$ ($68\\%$ confidence). Our analysis\nrules out Lyman-alpha emission from MACS1149-JD above a $3\\sigma$ equivalent\nwidth of 21 \\AA{}, consistent with a highly neutral IGM. We explore a scenario\nwhere the red $\\textit{Spitzer}$/IRAC $[3.6] - [4.5]$ color of the galaxy\npreviously pointed out in the literature is due to strong rest-frame optical\nemission lines from a very young stellar population rather than a 4000 \\AA{}\nbreak. We find that while this can provide an explanation for the observed IRAC\ncolor, it requires a lower redshift ($z\\lesssim9.1$), which is less preferred\nby the $\\textit{HST}$ imaging data. The grism data are consistent with both\nscenarios, indicating that the red IRAC color can still be explained by a 4000\n\\AA{} break, characteristic of a relatively evolved stellar population. In this\ninterpretation, the photometry indicate that a $340^{+29}_{-35}$ Myr stellar\npopulation is already present in this galaxy only $\\sim500~\\mathrm{Myr}$ after\nthe Big Bang. \n\n"}
{"id": "1709.04205", "contents": "Title: Photometric redshifts for the Kilo-Degree Survey. Machine-learning\n  analysis with artificial neural networks Abstract: We present a machine-learning photometric redshift analysis of the\nKilo-Degree Survey Data Release 3, using two neural-network based techniques:\nANNz2 and MLPQNA. Despite limited coverage of spectroscopic training sets,\nthese ML codes provide photo-zs of quality comparable to, if not better than,\nthose from the BPZ code, at least up to zphot<0.9 and r<23.5. At the bright end\nof r<20, where very complete spectroscopic data overlapping with KiDS are\navailable, the performance of the ML photo-zs clearly surpasses that of BPZ,\ncurrently the primary photo-z method for KiDS.\n  Using the Galaxy And Mass Assembly (GAMA) spectroscopic survey as\ncalibration, we furthermore study how photo-zs improve for bright sources when\nphotometric parameters additional to magnitudes are included in the photo-z\nderivation, as well as when VIKING and WISE infrared bands are added. While the\nfiducial four-band ugri setup gives a photo-z bias $\\delta z=-2e-4$ and scatter\n$\\sigma_z<0.022$ at mean z = 0.23, combining magnitudes, colours, and galaxy\nsizes reduces the scatter by ~7% and the bias by an order of magnitude. Once\nthe ugri and IR magnitudes are joined into 12-band photometry spanning up to 12\n$\\mu$, the scatter decreases by more than 10% over the fiducial case. Finally,\nusing the 12 bands together with optical colours and linear sizes gives $\\delta\nz<4e-5$ and $\\sigma_z<0.019$.\n  This paper also serves as a reference for two public photo-z catalogues\naccompanying KiDS DR3, both obtained using the ANNz2 code. The first one, of\ngeneral purpose, includes all the 39 million KiDS sources with four-band ugri\nmeasurements in DR3. The second dataset, optimized for low-redshift studies\nsuch as galaxy-galaxy lensing, is limited to r<20, and provides photo-zs of\nmuch better quality than in the full-depth case thanks to incorporating optical\nmagnitudes, colours, and sizes in the GAMA-calibrated photo-z derivation. \n\n"}
{"id": "1709.04205", "contents": "Title: Photometric redshifts for the Kilo-Degree Survey. Machine-learning\n  analysis with artificial neural networks Abstract: We present a machine-learning photometric redshift analysis of the\nKilo-Degree Survey Data Release 3, using two neural-network based techniques:\nANNz2 and MLPQNA. Despite limited coverage of spectroscopic training sets,\nthese ML codes provide photo-zs of quality comparable to, if not better than,\nthose from the BPZ code, at least up to zphot<0.9 and r<23.5. At the bright end\nof r<20, where very complete spectroscopic data overlapping with KiDS are\navailable, the performance of the ML photo-zs clearly surpasses that of BPZ,\ncurrently the primary photo-z method for KiDS.\n  Using the Galaxy And Mass Assembly (GAMA) spectroscopic survey as\ncalibration, we furthermore study how photo-zs improve for bright sources when\nphotometric parameters additional to magnitudes are included in the photo-z\nderivation, as well as when VIKING and WISE infrared bands are added. While the\nfiducial four-band ugri setup gives a photo-z bias $\\delta z=-2e-4$ and scatter\n$\\sigma_z<0.022$ at mean z = 0.23, combining magnitudes, colours, and galaxy\nsizes reduces the scatter by ~7% and the bias by an order of magnitude. Once\nthe ugri and IR magnitudes are joined into 12-band photometry spanning up to 12\n$\\mu$, the scatter decreases by more than 10% over the fiducial case. Finally,\nusing the 12 bands together with optical colours and linear sizes gives $\\delta\nz<4e-5$ and $\\sigma_z<0.019$.\n  This paper also serves as a reference for two public photo-z catalogues\naccompanying KiDS DR3, both obtained using the ANNz2 code. The first one, of\ngeneral purpose, includes all the 39 million KiDS sources with four-band ugri\nmeasurements in DR3. The second dataset, optimized for low-redshift studies\nsuch as galaxy-galaxy lensing, is limited to r<20, and provides photo-zs of\nmuch better quality than in the full-depth case thanks to incorporating optical\nmagnitudes, colours, and sizes in the GAMA-calibrated photo-z derivation. \n\n"}
{"id": "1709.04842", "contents": "Title: Optimal strategy for polarization modulation in the LSPE-SWIPE\n  experiment Abstract: CMB B-mode experiments are required to control systematic effects with an\nunprecedented level of accuracy. Polarization modulation by a half wave plate\n(HWP) is a powerful technique able to mitigate a large number of the\ninstrumental systematics. Our goal is to optimize the polarization modulation\nstrategy of the upcoming LSPE-SWIPE balloon-borne experiment, devoted to the\naccurate measurement of CMB polarization at large angular scales. We depart\nfrom the nominal LSPE-SWIPE modulation strategy (HWP stepped every 60 s with a\ntelescope scanning at around 12 deg/s) and perform a thorough investigation of\na wide range of possible HWP schemes (either in stepped or continuously\nspinning mode and at different azimuth telescope scan-speeds) in the frequency,\nmap and angular power spectrum domain. In addition, we probe the effect of\nhigh-pass and band-pass filters of the data stream and explore the HWP response\nin the minimal case of one detector for one operation day (critical for the\nsingle-detector calibration process). We finally test the modulation\nperformance against typical HWP-induced systematics. Our analysis shows that\nsome stepped HWP schemes, either slowly rotating or combined with slow\ntelescope modulations, represent poor choices. Moreover, our results point out\nthat the nominal configuration may not be the most convenient choice. While a\nlarge class of spinning designs provides comparable results in terms of pixel\nangle coverage, map-making residuals and BB power spectrum standard deviations\nwith respect to the nominal strategy, we find that some specific configurations\n(e.g., a rapidly spinning HWP with a slow gondola modulation) allow a more\nefficient polarization recovery in more general real-case situations. Although\nour simulations are specific to the LSPE-SWIPE mission, the general outcomes of\nour analysis can be easily generalized to other CMB polarization experiments. \n\n"}
{"id": "1709.05834", "contents": "Title: An automatic taxonomy of galaxy morphology using unsupervised machine\n  learning Abstract: We present an unsupervised machine learning technique that automatically\nsegments and labels galaxies in astronomical imaging surveys using only pixel\ndata. Distinct from previous unsupervised machine learning approaches used in\nastronomy we use no pre-selection or pre-filtering of target galaxy type to\nidentify galaxies that are similar. We demonstrate the technique on the HST\nFrontier Fields. By training the algorithm using galaxies from one field (Abell\n2744) and applying the result to another (MACS0416.1-2403), we show how the\nalgorithm can cleanly separate early and late type galaxies without any form of\npre-directed training for what an 'early' or 'late' type galaxy is. We then\napply the technique to the HST CANDELS fields, creating a catalogue of\napproximately 60,000 classifications. We show how the automatic classification\ngroups galaxies of similar morphological (and photometric) type, and make the\nclassifications public via a catalogue, a visual catalogue and galaxy\nsimilarity search. We compare the CANDELS machine-based classifications to\nhuman-based classifications from the Galaxy Zoo: CANDELS project. Although\nthere is not a direct mapping between Galaxy Zoo and our hierarchical\nlabelling, we demonstrate a good level of concordance between human and machine\nclassifications. Finally, we show how the technique can be used to identify\nrarer objects and present new lensed galaxy candidates from the CANDELS\nimaging. \n\n"}
{"id": "1709.06999", "contents": "Title: GALARIO: a GPU Accelerated Library for Analysing Radio Interferometer\n  Observations Abstract: We present GALARIO, a computational library that exploits the power of modern\ngraphical processing units (GPUs) to accelerate the analysis of observations\nfrom radio interferometers like ALMA or the VLA. GALARIO speeds up the\ncomputation of synthetic visibilities from a generic 2D model image or a radial\nbrightness profile (for axisymmetric sources). On a GPU, GALARIO is 150 faster\nthan standard Python and 10 times faster than serial C++ code on a CPU. Highly\nmodular, easy to use and to adopt in existing code, GALARIO comes as two\ncompiled libraries, one for Nvidia GPUs and one for multicore CPUs, where both\nhave the same functions with identical interfaces. GALARIO comes with Python\nbindings but can also be directly used in C or C++. The versatility and the\nspeed of GALARIO open new analysis pathways that otherwise would be\nprohibitively time consuming, e.g. fitting high resolution observations of\nlarge number of objects, or entire spectral cubes of molecular gas emission. It\nis a general tool that can be applied to any field that uses radio\ninterferometer observations. The source code is available online at\nhttps://github.com/mtazzari/galario under the open source GNU Lesser General\nPublic License v3. \n\n"}
{"id": "1709.09066", "contents": "Title: Line-Intensity Mapping: 2017 Status Report Abstract: Following the first two annual intensity mapping workshops at Stanford in\nMarch 2016 and Johns Hopkins in June 2017, we report on the recent advances in\ntheory, instrumentation and observation that were presented in these meetings\nand some of the opportunities and challenges that were identified looking\nforward. With preliminary detections of CO, [CII], Lya and low-redshift 21cm,\nand a host of experiments set to go online in the next few years, the field is\nrapidly progressing on all fronts, with great anticipation for a flood of new\nexciting results. This current snapshot provides an efficient reference for\nexperts in related fields and a useful resource for nonspecialists. We begin by\nintroducing the concept of line-intensity mapping and then discuss the broad\narray of science goals that will be enabled, ranging from the history of star\nformation, reionization and galaxy evolution to measuring baryon acoustic\noscillations at high redshift and constraining theories of dark matter,\nmodified gravity and dark energy. After reviewing the first detections reported\nto date, we survey the experimental landscape, presenting the parameters and\ncapabilities of relevant instruments such as COMAP, mmIMe, AIM-CO, CCAT-p,\nTIME, CONCERTO, CHIME, HIRAX, HERA, STARFIRE, MeerKAT/SKA and SPHEREx. Finally,\nwe describe recent theoretical advances: different approaches to modeling line\nluminosity functions, several techniques to separate the desired signal from\nforegrounds, statistical methods to analyze the data, and frameworks to\ngenerate realistic intensity map simulations. \n\n"}
{"id": "1710.00460", "contents": "Title: Hidden Markov model tracking of continuous gravitational waves from\n  young supernova remnants Abstract: Searches for persistent gravitational radiation from nonpulsating neutron\nstars in young supernova remnants (SNRs) are computationally challenging\nbecause of rapid stellar braking. We describe a practical, efficient,\nsemi-coherent search based on a hidden Markov model (HMM) tracking scheme,\nsolved by the Viterbi algorithm, combined with a maximum likelihood matched\nfilter, the $\\mathcal{F}$-statistic. The scheme is well suited to analyzing\ndata from advanced detectors like the Advanced Laser Interferometer\nGravitational Wave Observatory (Advanced LIGO). It can track rapid phase\nevolution from secular stellar braking and stochastic timing noise torques\nsimultaneously without searching second- and higher-order derivatives of the\nsignal frequency, providing an economical alternative to stack-slide-based\nsemi-coherent algorithms. One implementation tracks the signal frequency alone.\nA second implementation tracks the signal frequency and its first time\nderivative. It improves the sensitivity by a factor of a few upon the first\nimplementation, but the cost increases by two to three orders of magnitude. \n\n"}
{"id": "1710.01322", "contents": "Title: Specific Frequencies and Luminosity Profiles of Cluster Galaxies and\n  Intracluster Light in Abell 1689 Abstract: We present magnitudes and profile fits for 180 galaxies in the central field\nof the massive lensing cluster Abell 1689 using very deep imaging with the\nACS/HST in the F814W bandpass. Previous work revealed an exceptionally large\nnumber of globular clusters (GCs) in A1689 and mapped their number density\ndistribution. We decompose this number density map into GCs associated with\nindividual cluster galaxies and ICGCs (intracluster globular clusters)\nassociated with the intracluster light (ICL). In all, we measure GC specific\nfrequencies $S_N$ for 33 cluster members and the ICL. The relation between\n$S_N$ and galaxy magnitude is consistent with the trend observed in Virgo,\nalthough some intermediate luminosity galaxies scatter to $S_N>10$. We estimate\nthe ICL makes up 11% of the starlight in this field, whereas the ICGCs account\nfor $\\sim\\,$35% of the GCs, both consistent with predictions from simulations.\nGalaxies with higher $S_N$ values tend to be rounder, and there is a marginally\nsignificant trend of decreasing $S_N$ with increasing specific angular momenta\n$\\lambda_R$. We also reevaluate the GC population in the A2744 Frontier Field,\nfor which fewer than one-tenth as many GCs have been detected because of its\nlarger distance. Finally, our core-S\\'ersic fit to the light profile of the\nA1689 BCG implies a break radius of 3.8kpc, among the largest known; we discuss\nimplications of the sizable core and extensive GC population for the\nsupermassive black hole in light of scaling relations. \n\n"}
{"id": "1710.02564", "contents": "Title: Detectability of Galactic Faraday Rotation in Multi-wavelength CMB\n  Observations: A Cross-Correlation Analysis of CMB and Radio Maps Abstract: We introduce a new cross-correlation method to detect and verify the\nastrophysical origin of Faraday Rotation (FR) in multiwavelength surveys. FR is\nwell studied in radio astronomy from radio point sources but the $\\lambda^{2}$\nsuppression of FR makes detecting and accounting for this effect difficult at\nmillimeter and sub-millimeter wavelengths. Therefore statistical methods are\nused to attempt to detect FR in the cosmic microwave background (CMB). Most\nestimators of the FR power spectrum rely on single frequency data. In contrast,\nwe investigate the correlation of polarized CMB maps with FR measure maps from\nradio point sources. We show a factor of $\\sim30$ increase in sensitivity over\nsingle frequency estimators and predict detections exceeding $10\\sigma$\nsignificance for a CMB-S4 like experiment. Improvements in observations of FR\nfrom current and future radio polarization surveys will greatly increase the\nusefulness of this method. \n\n"}
{"id": "1710.03251", "contents": "Title: Halo mass and weak galaxy-galaxy lensing profiles in rescaled\n  cosmological $N$-body simulations Abstract: We investigate 3D density and weak lensing profiles of dark matter haloes\npredicted by a cosmology-rescaling algorithm for $N$-body simulations. We\nextend the rescaling method of Angulo & White (2010) and Angulo & Hilbert\n(2015) to improve its performance on intra-halo scales by using models for the\nconcentration-mass-redshift relation based on excursion set theory. The\naccuracy of the method is tested with numerical simulations carried out with\ndifferent cosmological parameters. We find that predictions for median density\nprofiles are more accurate than $\\sim 5\\,\\%$ for haloes with masses of\n$10^{12.0} - 10^{14.5} h^{-1}\\,M_{\\odot}$ for radii $0.05 < r/r_{200\\text{m}} <\n0.5$, and for cosmologies with $\\Omega_\\text{m} \\in [0.15,\\,0.40]$ and\n$\\sigma_8 \\in [0.6,\\,1.0]$. For larger radii, $0.5 < r/r_{200\\text{m}} < 5$,\nthe accuracy degrades to $\\sim20\\,\\%$, due to inaccurate modelling of the\ncosmological and redshift dependence of the splashback radius. For changes in\ncosmology allowed by current data, the residuals decrease to $\\lesssim2\\,\\%$ up\nto scales twice the virial radius. We illustrate the usefulness of the method\nby estimating the mean halo mass of a mock galaxy group sample. We find that\nthe algorithm's accuracy is sufficient for current data. Improvements in the\nalgorithm, particularly in the modelling of baryons, are likely required for\ninterpreting future (dark energy task force stage IV) experiments. \n\n"}
{"id": "1710.03512", "contents": "Title: Capabilities of ACAD-OSM, an active method for the correction of\n  aperture discontinuities Abstract: The increasing complexity of the aperture geometry of the future space- and\nground based-telescopes will limit the performance of the next generation of\ncoronagraphic instruments for high contrast imaging of exoplanets. We propose\nhere a new closed-loop optimization technique using two deformable mirrors to\ncorrect for the effects of complex apertures on coronagraph performance,\nalternative to the ACAD technique previously developed by our group. This\ntechnique, ACAD-OSM, allows the use of any coronagraphs designed for continuous\napertures, with complex, segmented, apertures, maintaining high performance in\ncontrast and throughput. We show the capabilities of this technique on several\npupil geometries (segmented LUVOIR type aperture, WFIRST, ELTs) for which we\nobtained high contrast levels with several deformable mirror setups (size,\nnumber of actuators, separation between them), coronagraphs (apodized pupil\nLyot and vortex coronagraphs) and spectral bandwidths, which will help us\npresent recommendations for future coronagraphic instruments. We show that this\nactive technique handles, without any revision to the algorithm, changing or\nunknown optical aberrations or discontinuities in the pupil, including optical\ndesign misalignments, missing segments and phase errors. \n\n"}
{"id": "1710.04080", "contents": "Title: Fundamental limits to high-contrast wavefront control Abstract: The current generation of ground-based coronagraphic instruments uses\ndeformable mirrors to correct for phase errors and to improve contrast levels\nat small angular separations. Improving these techniques, several space and\nground based instruments are currently developed using two deformable mirrors\nto correct for both phase and amplitude errors. However, as wavefront control\ntechniques improve, more complex telescope pupil geome- tries (support\nstructures, segmentation) will soon be a limiting factor for these next\ngeneration coronagraphic instruments. In this paper we discuss fundamental\nlimits associated with wavefront control with deformable mirrors in high\ncontrast coronagraph. We start with an analytic prescription of wavefront\nerrors, along with their wave- length dependence, and propagate them through\ncoronagraph models. We then consider a few wavefront control architectures,\nnumber of deformable mirrors and their placement in the optical train of the\ninstrument, and algorithms that can be used to cancel the starlight scattered\nby these wavefront errors over a finite bandpass. For each configuration we\nderive the residual contrast as a function of bandwidth and of the properties\nof the incoming wavefront. This result has consequences when setting the\nwavefront requirements, along with the wavefront control architecture of future\nhigh contrast instrument both from the ground and from space. In particular we\nshow that these limits can severely affect the effective Outer Working Angle\nthat can be achieved by a given coronagraph instrument. \n\n"}
{"id": "1710.06739", "contents": "Title: Gaia Data Release 1. Cross-match with external catalogues - Algorithm\n  and results Abstract: Although the Gaia catalogue on its own will be a very powerful tool, it is\nthe combination of this highly accurate archive with other archives that will\ntruly open up amazing possibilities for astronomical research. The advanced\ninteroperation of archives is based on cross-matching, leaving the user with\nthe feeling of working with one single data archive. The data retrieval should\nwork not only across data archives, but also across wavelength domains. The\nfirst step for seamless data access is the computation of the cross-match\nbetween Gaia and external surveys. The matching of astronomical catalogues is a\ncomplex and challenging problem both scientifically and technologically\n(especially when matching large surveys like Gaia). We describe the cross-match\nalgorithm used to pre-compute the match of Gaia Data Release 1 (DR1) with a\nselected list of large publicly available optical and IR surveys. The overall\nprinciples of the adopted cross-match algorithm are outlined. Details are given\non the developed algorithm, including the methods used to account for position\nerrors, proper motions, and environment; to define the neighbours; and to\ndefine the figure of merit used to select the most probable counterpart.\nStatistics on the results are also given. The results of the cross-match are\npart of the official Gaia DR1 catalogue. \n\n"}
{"id": "1710.08456", "contents": "Title: Magnetic Sensitivity of AlMn TESes and Shielding Considerations for\n  Next-Generation CMB Surveys Abstract: In the next decade, new ground-based Cosmic Microwave Background (CMB)\nexperiments such as Simons Observatory (SO), CCAT-prime, and CMB-S4 will\nincrease the number of detectors observing the CMB by an order of magnitude or\nmore, dramatically improving our understanding of cosmology and astrophysics.\nThese projects will deploy receivers with as many as hundreds of thousands of\ntransition edge sensor (TES) bolometers coupled to Superconducting Quantum\nInterference Device (SQUID)-based readout systems. It is well known that\nsuperconducting devices such as TESes and SQUIDs are sensitive to magnetic\nfields. However, the effects of magnetic fields on TESes are not easily\npredicted due to the complex behavior of the superconducting transition, which\nmotivates direct measurements of the magnetic sensitivity of these devices. We\npresent comparative four-lead measurements of the critical temperature versus\napplied magnetic field of AlMn TESes varying in geometry, doping, and leg\nlength, including Advanced ACT (AdvACT) and POLARBEAR-2/Simons Array\nbolometers. Molybdenum-copper bilayer ACTPol TESes are also tested and are\nfound to be more sensitive to magnetic fields than the AlMn devices. We present\nan observation of weak-link-like behavior in AlMn TESes at low critical\ncurrents. We also compare measurements of magnetic sensitivity for time\ndivision multiplexing SQUIDs and frequency division multiplexing microwave\nrf-SQUIDs. We discuss the implications of our measurements on the magnetic\nshielding required for future experiments that aim to map the CMB to\nnear-fundamental limits. \n\n"}
{"id": "1710.09770", "contents": "Title: Imprints of gravitational lensing in the Planck CMB data at the location\n  of WISExSCOS galaxies Abstract: We detect weak gravitational lensing of the cosmic microwave background (CMB)\nat the location of the WISExSCOS (WxS) galaxies using the publicly available\nPlanck lensing convergence map. By stacking the lensing convergence map at the\nposition of 12.4 million galaxies in the redshift range $0.1\\le z \\le 0.345$,\nwe find the average mass of the galaxies to be M$_{200_{\\rm crit}}$ = 6.25\n$\\pm$ 0.6 $\\times 10^{12}\\ M_{\\odot}$. The null hypothesis of no-lensing is\nrejected at a significance of $17\\sigma$. We split the galaxy sample into three\nredshift slices each containing $\\sim$4.1 million objects and obtain lensing\nmasses in each slice of 4.18 $\\pm$ 0.8, 6.93 $\\pm$ 0.9, and 18.84 $\\pm$ 1.2\n$\\times\\ 10^{12}\\ \\mbox{M}_{\\odot}$. Our results suggest a redshift evolution\nof the galaxy sample masses but this apparent increase might be due to the\npreferential selection of intrinsically luminous sources at high redshifts. The\nrecovered mass of the stacked sample is reduced by 28% when we remove the\ngalaxies in the vicinity of galaxy clusters with mass M$_{200_{\\rm crit}}$ = $2\n\\times 10^{14}\\ \\mbox{M}_{\\odot}$. We forecast that upcoming CMB surveys can\nachieve 5% galaxy mass constraints over sets of 12.4 million galaxies with\nM$_{200_{\\rm crit}}$ = $1 \\times 10^{12}\\ M_{\\odot}$ at $z=1$. \n\n"}
{"id": "1710.10929", "contents": "Title: Constraints on the cosmic distance duality relation with simulated data\n  of gravitational waves from the Einstein Telescope Abstract: The cosmic distance duality relation (CDDR) has been test through several\nastronomical observations in the last years. This relation establishes a simple\nequation relating the angular diameter ($D_A$) and luminosity ($D_L$) distances\nat a redshift $z$, $D_LD_A^{-1}(1+z)^{-2}=\\eta=1$. However, only very recently\nthis relation has been observationally tested at high redshifts ($z \\approx\n3.6$) by using luminosity distances from type Ia supernovae (SNe Ia) and gamma\nray bursts (GRBs) plus angular diameter distances from strong gravitational\nlensing (SGL) observations. The results show that no significant deviation from\nthe CDDR validity has been verified. In this work, we test the potentialities\nof future luminosity distances from gravitational waves (GWs) sources to impose\nlimit on possible departures of CDDR jointly with current SGL observations. The\nbasic advantage of $D_L$ from GWs is being insensitive to non-conservation of\nthe number of photons. By simulating 600, 900 and 1200 data of GWs using the\nEinstein Telescope (ET) as reference, we derive limits on $\\eta(z)$ function\nand obtain that the results will be at least competitive with current limits\nfrom the SNe Ia $+$ GRBs $+$ SGLs analyses. \n\n"}
{"id": "1710.11220", "contents": "Title: The VLT-FLAMES Tarantula Survey Abstract: We present a number of notable results from the VLT-FLAMES Tarantula Survey\n(VFTS), an ESO Large Program during which we obtained multi-epoch\nmedium-resolution optical spectroscopy of a very large sample of over 800\nmassive stars in the 30 Doradus region of the Large Magellanic Cloud (LMC).\nThis unprecedented data-set has enabled us to address some key questions\nregarding atmospheres and winds, as well as the evolution of (very) massive\nstars. Here we focus on O-type runaways, the width of the main sequence, and\nthe mass-loss rates for (very) massive stars. We also provide indications for\nthe presence of a top-heavy initial mass function (IMF) in 30 Dor. \n\n"}
{"id": "1710.11474", "contents": "Title: Gaia-like astrometry and gravitational waves Abstract: This paper discusses the effects of gravitational waves on high-accuracy\nastrometric observations such as those delivered by Gaia. Depending on the\nfrequency of gravitational waves, two regimes for the influence of\ngravitational waves on astrometric data are identified: the regime when the\neffects of gravitational waves directly influence the derived proper motions of\nastrometric sources and the regime when those effects mostly appear in the\nresiduals of the standard astrometric solution. The paper is focused on the\nsecond regime while the known results for the first regime are briefly\nsummarized.\n  The deflection of light due to a plane gravitational wave is then discussed.\nStarting from a model for the deflection we derive the corresponding partial\nderivatives and summarize some ideas for the search strategy of such signals in\nhigh-accuracy astrometric data. In order to reduce the dimensionality of the\nparameter space the use of vector spherical harmonics is suggested and\nexplained. The explicit formulas for the VSH expansion of the astrometric\nsignal of a plain gravitational wave are derived.\n  Finally, potential sensitivity of Gaia astrometric data is discussed.\nPotential astrophysical sources of gravitational waves that can be interesting\nfor astrometric detection are identified. \n\n"}
{"id": "1711.00022", "contents": "Title: Detecting outliers and learning complex structures with large\n  spectroscopic surveys - a case study with APOGEE stars Abstract: In this work we apply and expand on a recently introduced outlier detection\nalgorithm that is based on an unsupervised random forest. We use the algorithm\nto calculate a similarity measure for stellar spectra from the Apache Point\nObservatory Galactic Evolution Experiment (APOGEE). We show that the similarity\nmeasure traces non-trivial physical properties and contains information about\ncomplex structures in the data. We use it for visualization and clustering of\nthe dataset, and discuss its ability to find groups of highly similar objects,\nincluding spectroscopic twins. Using the similarity matrix to search the\ndataset for objects allows us to find objects that are impossible to find using\ntheir best fitting model parameters. This includes extreme objects for which\nthe models fail, and rare objects that are outside the scope of the model. We\nuse the similarity measure to detect outliers in the dataset, and find a number\nof previously unknown Be-type stars, spectroscopic binaries, carbon rich stars,\nyoung stars, and a few that we cannot interpret. Our work further demonstrates\nthe potential for scientific discovery when combining machine learning methods\nwith modern survey data. \n\n"}
{"id": "1711.00975", "contents": "Title: Scalable Streaming Tools for Analyzing $N$-body Simulations: Finding\n  Halos and Investigating Excursion Sets in One Pass Abstract: Cosmological $N$-body simulations play a vital role in studying models for\nthe evolution of the Universe. To compare to observations and make a scientific\ninference, statistic analysis on large simulation datasets, e.g., finding\nhalos, obtaining multi-point correlation functions, is crucial. However,\ntraditional in-memory methods for these tasks do not scale to the datasets that\nare forbiddingly large in modern simulations. Our prior paper proposes\nmemory-efficient streaming algorithms that can find the largest halos in a\nsimulation with up to $10^9$ particles on a small server or desktop. However,\nthis approach fails when directly scaling to larger datasets. This paper\npresents a robust streaming tool that leverages state-of-the-art techniques on\nGPU boosting, sampling, and parallel I/O, to significantly improve performance\nand scalability. Our rigorous analysis of the sketch parameters improves the\nprevious results from finding the centers of the $10^3$ largest halos to $\\sim\n10^4-10^5$, and reveals the trade-offs between memory, running time and number\nof halos. Our experiments show that our tool can scale to datasets with up to\n$\\sim 10^{12}$ particles while using less than an hour of running time on a\nsingle GPU Nvidia GTX 1080. \n\n"}
{"id": "1711.01441", "contents": "Title: The International Cosmic Day - An Outreach Event for Astroparticle\n  Physics Abstract: The International Cosmic Day (ICD) is an astroparticle physics outreach event\nfor high-school students and brings together students and different physics\noutreach projects from all over the world. Groups of scientists, teachers, and\nstudents meet for one day to learn about cosmic rays and perform an experiment\nwith atmospheric muons. All participating groups investigate an identical\nquestion. The students are enabled to work together like in an international\ncollaboration, discussing their results in joint video conferences. Analyzing\ndata, comparing and discussing with other \"young scientists\" gives the students\na glimpse of how professional scientific research works. Scientists join the\nvideo conferences and give lectures to provide an insight in current\nastroparticle physics research. Several participating research experiments\nanalyze big science data tailored to the questions addressed by the students\nand present their results on equal terms with the students. To create a lasting\nevent, proceedings with measurement results of all participating groups are\npublished. Every participant receives a personal e-mail with his certificate\nand the proceedings booklet. Organized by DESY in cooperation with Netzwerk\nTeilchenwelt, IPPOG, QuarkNet, Fermilab, and national partners like INFN, the\nICD is a growing event with more and more popularity. We present the\norganization of the event and the experience from five years of ICD. \n\n"}
{"id": "1711.01496", "contents": "Title: The ANTARES Collaboration: Contributions to ICRC 2017 Part III: Searches\n  for dark matter and exotics, neutrino oscillations and detector calibration Abstract: Papers on the searches for dark matter and exotics, neutrino oscillations and\ndetector calibration, prepared for the 35th International Cosmic Ray Conference\n(ICRC 2017, Busan, South Korea) by the ANTARES Collaboration \n\n"}
{"id": "1711.01978", "contents": "Title: Radio Frequency Interference Mitigation Abstract: Radio astronomy observational facilities are under constant upgradation and\ndevelopment to achieve better capabilities including increasing the time and\nfrequency resolutions of the recorded data, and increasing the receiving and\nrecording bandwidth. As only a limited spectrum resource has been allocated to\nradio astronomy by the International Telecommunication Union, this results in\nthe radio observational instrumentation being inevitably exposed to undesirable\nradio frequency interference (RFI) signals which originate mainly from\nterrestrial human activity and are becoming stronger with time. RFIs degrade\nthe quality of astronomical data and even lead to data loss. The impact of RFIs\non scientific outcome is becoming progressively difficult to manage. In this\narticle, we motivate the requirement for RFI mitigation, and review the RFI\ncharacteristics, mitigation techniques and strategies. Mitigation strategies\nadopted at some representative observatories, telescopes and arrays are also\nintroduced. We also discuss and present advantages and shortcomings of the four\nclasses of RFI mitigation strategies, applicable at the connected causal\nstages: preventive, pre-detection, pre-correlation and post-correlation. The\nproper identification and flagging of RFI is key to the reduction of data loss\nand improvement in data quality, and is also the ultimate goal of developing\nRFI mitigation techniques. This can be achieved through a strategy involving a\ncombination of the discussed techniques in stages. Recent advances in high\nspeed digital signal processing and high performance computing allow for\nperforming RFI excision of large data volumes generated from large telescopes\nor arrays in both real time and offline modes, aiding the proposed strategy. \n\n"}
{"id": "1711.02775", "contents": "Title: Super-horizon second-order perturbations for cosmological random\n  fluctuations and the Hubble-constant problem Abstract: The super-horizon second-order density perturbations corresponding to\ncosmological random fluctuations are considered, their non-vanishing spatial\naverage is shown to be useful in solving the serious problem on the\ncosmological tension between measured Hubble constants at present and those at\nthe early stage, and the difference from previous works on the backreaction is\ndiscussed. \n\n"}
{"id": "1711.02793", "contents": "Title: Robust Statistics for Image Deconvolution Abstract: We present a blind multiframe image-deconvolution method based on robust\nstatistics. The usual shortcomings of iterative optimization of the likelihood\nfunction are alleviated by minimizing the M-scale of the residuals, which\nachieves more uniform convergence across the image. We focus on the\ndeconvolution of astronomical images, which are among the most challenging due\nto their huge dynamic ranges and the frequent presence of large noise-dominated\nregions in the images. We show that high-quality image reconstruction is\npossible even in super-resolution and without the use of traditional\nregularization terms. Using a robust \\r{ho}-function is straightforward to\nimplement in a streaming setting and, hence our method is applicable to the\nlarge volumes of astronomy images. The power of our method is demonstrated on\nobservations from the Sloan Digital Sky Survey (Stripe 82) and we briefly\ndiscuss the feasibility of a pipeline based on Graphical Processing Units for\nthe next generation of telescope surveys. \n\n"}
{"id": "1711.03173", "contents": "Title: Global 21-cm signal extraction from foreground and instrumental effects\n  I: Pattern recognition framework for separation using training sets Abstract: The sky-averaged (global) highly redshifted 21-cm spectrum from neutral\nhydrogen is expected to appear in the VHF range of $\\sim20-200$ MHz and its\nspectral shape and strength are determined by the heating properties of the\nfirst stars and black holes, by the nature and duration of reionization, and by\nthe presence or absence of exotic physics. Measurements of the global signal\nwould therefore provide us with a wealth of astrophysical and cosmological\nknowledge. However, the signal has not yet been detected because it must be\nseen through strong foregrounds weighted by a large beam, instrumental\ncalibration errors, and ionospheric, ground and radio-frequency-interference\neffects, which we collectively refer to as \"systematics\". Here, we present a\nsignal extraction method for global signal experiments which uses Singular\nValue Decomposition (SVD) of \"training sets\" to produce systematics basis\nfunctions specifically suited to each observation. Instead of requiring precise\nabsolute knowledge of the systematics, our method effectively requires precise\nknowledge of how the systematics can vary. After calculating eigenmodes for the\nsignal and systematics, we perform a weighted least square fit of the\ncorresponding coefficients and select the number of modes to include by\nminimizing an information criterion. We compare the performance of the signal\nextraction when minimizing various information criteria and find that\nminimizing the Deviance Information Criterion (DIC) most consistently yields\nunbiased fits. The methods used here are built into our widely applicable,\npublicly available Python package, $\\texttt{pylinex}$, which analytically\ncalculates constraints on signals and systematics from given data, errors, and\ntraining sets. \n\n"}
{"id": "1711.04435", "contents": "Title: Prospects for gravitational wave astronomy with next generation\n  large-scale pulsar timing arrays Abstract: Next generation radio telescopes, namely the Five-hundred-meter Aperture\nSpherical Telescope (FAST) and the Square Kilometer Array (SKA), will\nrevolutionize the pulsar timing arrays (PTAs) based gravitational wave (GW)\nsearches. We review some of the characteristics of FAST and SKA, and the\nresulting PTAs, that are pertinent to the detection of gravitational wave\nsignals from individual supermassive black hole binaries. \n\n"}
{"id": "1711.04469", "contents": "Title: Enhanced detection of high frequency gravitational waves using optically\n  diluted optomechanical filters Abstract: Detections of gravitational waves (GW) in the frequency band 35 Hz to 500 Hz\nhave led to the birth of GW astronomy. Expected signals above 500 Hz, such as\nthe quasinormal modes of lower mass black holes and neutron star mergers\nsignatures are currently not detectable due to increasing quantum shot noise at\nhigh frequencies. Squeezed vacuum injection has been shown to allow broadband\nsensitivity improvement, but this technique does not change the slope of the\nnoise at high frequency. It has been shown that white light signal recycling\nusing negative dispersion optomechanical filter cavities with strong optical\ndilution for thermal noise suppression can in principle allow broadband high\nfrequency sensitivity improvement. Here we present detailed modelling of\nAlGaAs/GaAs optomechanical filters to identify the available parameter space in\nwhich such filters can achieve the low thermal noise required to allow useful\nsensitivity improvement at high frequency. Material losses, the resolved\nsideband condition and internal acoustic modes dictate the need for resonators\nsubstantially smaller than previously suggested. We identify suitable resonator\ndimensions and show that a 30 $\\mu$m scale cat-flap resonator combined with\noptical squeezing allows 8 fold improvement of strain sensitivity at 2 kHz\ncompared with Advanced LIGO. This corresponds to a detection volume increase of\na factor of 500 for sources in this frequency range. \n\n"}
{"id": "1711.05856", "contents": "Title: Photogravimagnetic assists of light sails: a mixed blessing for\n  Breakthrough Starshot? Abstract: Upon entering a star system, light sails are subject to both gravitational\nforces and radiation pressure, and can use both in concert to modify their\ntrajectory. Moreover, stars possess significant magnetic fields, and if the\nsail is in any way charged, it will feel the Lorentz force also.\n  We investigate the dynamics of so-called \"photogravimagnetic assists\" of\nsailcraft around $\\alpha$ Centauri A, a potential first destination en route to\nProxima Centauri (the goal of the Breakthrough Starshot program). We find that\na 10m$^2$ sail with a charge-to-mass-ratio of around 10 $\\mu$C/g or higher will\nneed to take account of magnetic field effects during orbital maneouvres. The\nmagnetic field can provide an extra source of deceleration and deflection, and\nallow capture onto closer orbits around a target star.\n  However, flipping the sign of the sailcraft's charge can radically change\nresulting trajectories, resulting in complex loop-de-loops around magnetic\nfield lines and essentially random ejection from the star system. Even on\nwell-behaved trajectories, the field can generate off-axis deflections at\n$\\alpha$ Centauri that, while minor, can result in very poor targetting of the\nfinal destination (Proxima) post-assist.\n  Fortunately for Breakthrough Starshot, nanosails are less prone to charging\nen route than their heavier counterparts, but can still accrue relatively high\ncharge at both the origin and destination, when travelling at low speeds.\nPhotogravimagnetic assists are highly non-trivial, and require careful course\ncorrection to mitigate against unwanted changes in trajectory. \n\n"}
{"id": "1711.06770", "contents": "Title: The ALMA Phasing System: A Beamforming Capability for\n  Ultra-High-Resolution Science at (Sub)Millimeter Wavelengths Abstract: The Atacama Millimeter/submillimeter Array (ALMA) Phasing Project (APP) has\ndeveloped and deployed the hardware and software necessary to coherently sum\nthe signals of individual ALMA antennas and record the aggregate sum in Very\nLong Baseline Interferometry (VLBI) Data Exchange Format. These beamforming\ncapabilities allow the ALMA array to collectively function as the equivalent of\na single large aperture and participate in global VLBI arrays. The inclusion of\nphased ALMA in current VLBI networks operating at (sub)millimeter wavelengths\nprovides an order of magnitude improvement in sensitivity, as well as\nenhancements in u-v coverage and north-south angular resolution. The\navailability of a phased ALMA enables a wide range of new ultra-high angular\nresolution science applications, including the resolution of supermassive black\nholes on event horizon scales and studies of the launch and collimation of\nastrophysical jets. It also provides a high-sensitivity aperture that may be\nused for investigations such as pulsar searches at high frequencies. This paper\nprovides an overview of the ALMA Phasing System design, implementation, and\nperformance characteristics. \n\n"}
{"id": "1711.07025", "contents": "Title: Two distinct components of the delayed single electron background\n  signals in liquid xenon emission detectors Abstract: Single electron background signals with millisecond timescales are known to\nfollow ionizing events in liquid/gas xenon emission detectors. Due to the long\ntimescale, these signals can present a limiting background to the low-energy\nthreshold of dark matter searches, and prevent discovery-class searches for MeV\nscale hidden sector dark matter. A systematic study reveals a fast (tau_1) and\nslow (tau_2) component to the background. The fast component is compatible with\nelectrons which were trapped at the liquid surface, and can be reduced by\nincreasing the electric field. However, the slow component increases linearly\nwith electric field. Hypotheses for the origin of the effect are discussed, and\ntechniques for mitigation are suggested. \n\n"}
{"id": "1711.07692", "contents": "Title: First results on low-mass dark matter from the CRESST-III experiment Abstract: The CRESST experiment, located at Laboratori Nazionali del Gran Sasso in\nItaly, searches for dark matter particles via their elastic scattering off\nnuclei in a target material. The CRESST target consists of scintillating\nCaWO$_4$ crystals, which are operated as cryogenic calorimeters at millikelvin\ntemperatures. Each interaction in the CaWO$_4$ target crystal produces a phonon\nsignal and a light signal that is measured by a second cryogenic calorimeter.\nSince the CRESST-II result in 2015, the experiment is leading the field of\ndirect dark matter search for dark matter masses below 1.7\\,GeV/$c^2$,\nextending the reach of direct searches to the sub-GeV/$c^2$ mass region. For\nCRESST-III, whose Phase 1 started in July 2016, detectors have been optimized\nto reach the performance required to further probe the low-mass region with\nunprecedented sensitivity. In this contribution the achievements of the\nCRESST-III detectors will be discussed together with preliminary results and\nperspectives of Phase 1. \n\n"}
{"id": "1712.00252", "contents": "Title: Cosmological Simulations in Exascale Era Abstract: The architecture of Exascale computing facilities, which involves millions of\nheterogeneous processing units, will deeply impact on scientific applications.\nFuture astrophysical HPC applications must be designed to make such computing\nsystems exploitable. The ExaNeSt H2020 EU-funded project aims to design and\ndevelop an exascale ready prototype based on low-energy-consumption ARM64 cores\nand FPGA accelerators. We participate to the design of the platform and to the\nvalidation of the prototype with cosmological N-body and hydrodynamical codes\nsuited to perform large-scale, high-resolution numerical simulations of cosmic\nstructures formation and evolution. We discuss our activities on astrophysical\napplications to take advantage of the underlying architecture. \n\n"}
{"id": "1712.00263", "contents": "Title: EPIC - Easy Parameter Inference in Cosmology: The user's guide to the\n  MCMC sampler Abstract: Easy Parameter Inference in Cosmology (EPIC) is another Markov Chain Monte\nCarlo (MCMC) sampler for Cosmology. It is implemented in Python and provides\nBayesian parameter inference and model comparison based on the Bayesian\nevidence. The Parallel Tempering algorithm is included, which can help in the\nexploration of posterior distributions with two or more separated peaks.\nAdaptive routines for obtaining better efficiency with fine-tuned algorithms\nare being developed and will be available in future versions. In this user's\nguide, I give general instructions for installation and usage, including\nexamples, and show how to modify the code in order to add new datasets and\nmodels. \n\n"}
{"id": "1712.03970", "contents": "Title: Learning from the machine: interpreting machine learning algorithms for\n  point- and extended- source classification Abstract: We investigate star-galaxy classification for astronomical surveys in the\ncontext of four methods enabling the interpretation of black-box machine\nlearning systems. The first is outputting and exploring the decision boundaries\nas given by decision tree based methods, which enables the visualization of the\nclassification categories. Secondly, we investigate how the Mutual Information\nbased Transductive Feature Selection (MINT) algorithm can be used to perform\nfeature pre-selection. If one would like to provide only a small number of\ninput features to a machine learning classification algorithm, feature\npre-selection provides a method to determine which of the many possible input\nproperties should be selected. Third is the use of the tree-interpreter package\nto enable popular decision tree based ensemble methods to be opened,\nvisualized, and understood. This is done by additional analysis of the tree\nbased model, determining not only which features are important to the model,\nbut how important a feature is for a particular classification given its value.\nLastly, we use decision boundaries from the model to revise an already existing\nmethod of classification, essentially asking the tree based method where\ndecision boundaries are best placed and defining a new classification method.\n  We showcase these techniques by applying them to the problem of star-galaxy\nseparation using data from the Sloan Digital Sky Survey (hereafter SDSS). We\nuse the output of MINT and the ensemble methods to demonstrate how more complex\ndecision boundaries improve star-galaxy classification accuracy over the\nstandard SDSS frames approach (reducing misclassifications by up to\n$\\approx33\\%$). We then show how tree-interpreter can be used to explore how\nrelevant each photometric feature is when making a classification on an object\nby object basis. \n\n"}
{"id": "1712.04476", "contents": "Title: Photometric redshifts for the next generation of deep radio continuum\n  surveys - II. Gaussian processes and hybrid estimates Abstract: Building on the first paper in this series (Duncan et al. 2018), we present a\nstudy investigating the performance of Gaussian process photometric redshift\n(photo-z) estimates for galaxies and active galactic nuclei detected in deep\nradio continuum surveys. A Gaussian process redshift code is used to produce\nphoto-z estimates targeting specific subsets of both the AGN population -\ninfrared, X-ray and optically selected AGN - and the general galaxy population.\nThe new estimates for the AGN population are found to perform significantly\nbetter at z > 1 than the template-based photo-z estimates presented in our\nprevious study. Our new photo-z estimates are then combined with template\nestimates through hierarchical Bayesian combination to produce a hybrid\nconsensus estimate that outperforms either of the individual methods across all\nsource types. Photo-z estimates for radio sources that are X-ray sources or\noptical/IR AGN are signficantly improved in comparison to previous\ntemplate-only estimates, with outlier fractions and robust scatter reduced by\nup to a factor of ~4. The ability of our method to combine the strengths of the\ntwo input photo-z techniques and the large improvements we observe illustrate\nits potential for enabling future exploitation of deep radio continuum surveys\nfor both the study of galaxy and black hole co-evolution and for cosmological\nstudies. \n\n"}
{"id": "1712.05682", "contents": "Title: Interstellar communication. V. Introduction to photon information\n  efficiency (in bits per photon) Abstract: How many bits of information can a single photon carry? Intuition says \"one\",\nbut this is incorrect. With an alphabet based on the photon's time of arrival,\nenergy, and polarization, several bits can be encoded. In this introduction to\nphoton information efficiency, we explain how to calculate the maximum number\nof bits per photon depending on the number of encoding modes, noise, and\nlosses. \n\n"}
{"id": "1712.05834", "contents": "Title: nbodykit: an open-source, massively parallel toolkit for large-scale\n  structure Abstract: We present nbodykit, an open-source, massively parallel Python toolkit for\nanalyzing large-scale structure (LSS) data. Using Python bindings of the\nMessage Passing Interface (MPI), we provide parallel implementations of many\ncommonly used algorithms in LSS. nbodykit is both an interactive and scalable\npiece of scientific software, performing well in a supercomputing environment\nwhile still taking advantage of the interactive tools provided by the Python\necosystem. Existing functionality includes estimators of the power spectrum, 2\nand 3-point correlation functions, a Friends-of-Friends grouping algorithm,\nmock catalog creation via the halo occupation distribution technique, and\napproximate N-body simulations via the FastPM scheme. The package also provides\na set of distributed data containers, insulated from the algorithms themselves,\nthat enable nbodykit to provide a unified treatment of both simulation and\nobservational data sets. nbodykit can be easily deployed in a high performance\ncomputing environment, overcoming some of the traditional difficulties of using\nPython on supercomputers. We provide performance benchmarks illustrating the\nscalability of the software. The modular, component-based approach of nbodykit\nallows researchers to easily build complex applications using its tools. The\npackage is extensively documented at http://nbodykit.readthedocs.io, which also\nincludes an interactive set of example recipes for new users to explore. As\nopen-source software, we hope nbodykit provides a common framework for the\ncommunity to use and develop in confronting the analysis challenges of future\nLSS surveys. \n\n"}
{"id": "1712.05976", "contents": "Title: Do cosmological data rule out $f(\\mathcal{R})$ with $w\\neq-1$? Abstract: We review the Equation of State (EoS) approach to dark sector perturbations\nand apply it to $f(\\mathcal{R})$ gravity models of dark energy. We show that\nthe EoS approach is numerically stable and use it to set observational\nconstraints on designer models. Within the EoS approach we build an analytical\nunderstanding of the dynamics of cosmological perturbations for the designer\nclass of $f(\\mathcal{R})$ gravity models, characterised by the parameter $B_0$\nand the background equation of state of dark energy $w$. When we use the Planck\nCosmic Microwave Background (CMB) temperature anisotropy, polarisation and\nlensing data as well as the Baryonic Acoustic Oscillation (BAO) data from SDSS\nand WiggleZ, we find $B_0<0.006$ (95\\%CL) for the designer models with $w=-1$.\nFurthermore, we find $B_0<0.0045$ and $|w+1|<0.002$ (95\\%CL) for the designer\nmodels with $w\\neq -1$. Previous analyses found similar results for designer\nand Hu-Sawicki $f(\\mathcal{R})$ gravity models using the Effective Field Theory\n(EFT) approach (Raveri et al. 2014, Hu et al. 2016), therefore this hints for\nthe fact that generic $f(\\mathcal{R})$ models with $w\\neq-1$ can be tightly\nconstrained by current cosmological data, complementary to solar system tests\n(Brax et al. 2008, Faulkner et al. 2007). When compared to a $w$CDM fluid with\nthe same sound speed, we find that the equation of state for $f(\\mathcal{R})$\nmodels is better constrained to be close to -1 by about an order of magnitude,\ndue to the strong dependence of the perturbations on $w$. \n\n"}
{"id": "1712.06243", "contents": "Title: The Power of Simultaneous Multi-frequency Observations for mm-VLBI:\n  Beyond Frequency Phase Transfer Abstract: Atmospheric propagation effects at millimeter wavelengths can significantly\nalter the phases of radio signals and reduce the coherence time, putting tight\nconstraints on high frequency Very Long Baseline Interferometry (VLBI)\nobservations. In previous works, it has been shown that non-dispersive (e.g.\ntropospheric) effects can be calibrated with the frequency phase transfer (FPT)\ntechnique. The coherence time can thus be significantly extended. Ionospheric\neffects, which can still be significant, remain however uncalibrated after FPT\nas well as the instrumental effects. In this work, we implement a further phase\ntransfer between two FPT residuals (i.e. so-called FPT-square) to calibrate the\nionospheric effects based on their frequency dependence. We show that after\nFPT-square, the coherence time at 3 mm can be further extended beyond 8~hours,\nand the residual phase errors can be sufficiently canceled by applying the\ncalibration of another source, which can have a large angular separation from\nthe target (>20 deg) and significant temporal gaps. Calibrations for all-sky\ndistributed sources with a few calibrators are also possible after FPT-square.\nOne of the strengths and uniqueness of this calibration strategy is the\nsuitability for high-frequency all-sky survey observations including very weak\nsources. We discuss the introduction of a pulse calibration system in the\nfuture to calibrate the remaining instrumental effects and allowing the\npossibility of imaging the source structure at high frequencies with\nFPT-square, where all phases are fully calibrated without involving any\nadditional sources. \n\n"}
{"id": "1712.06381", "contents": "Title: Fast, Collimated Outflow in the Western Nucleus of Arp 220 Abstract: We present the first spatially and spectrally resolved image of the molecular\noutflow in the western nucleus of Arp\\,220. The outflow, seen in HCN~(1--0) by\nALMA, is compact and collimated, with extension $\\lesssim$ 120\\,pc. Bipolar\nmorphology emerges along the minor axis of the disk, with redshifted and\nblueshifted components reaching maximum inclination-corrected velocity of\n$\\sim\\,\\pm$\\,840\\,km\\,s$^{-1}$. The outflow is also seen in CO and continuum\nemission, the latter implying that it carries significant dust. We estimate a\ntotal mass in the outflow of $\\geqslant$\\,10$^{6}$\\,M$_{\\odot}$, a dynamical\ntime of $\\sim$\\,10$^{5}$\\,yr, and mass outflow rates of\n$\\geqslant55$\\,M$_{\\odot}$\\,yr$^{-1}$ and\n$\\geqslant\\,15$\\,M$_{\\odot}$\\,yr$^{-1}$ for the northern and southern lobes,\nrespectively. Possible driving mechanisms include supernovae energy and\nmomentum transfer, radiation pressure feedback, and a central AGN. The latter\ncould explain the collimated morphology of the HCN outflow, however we need\nmore complex theoretical models, including contribution from supernovae and\nAGN, to pinpoint the driving mechanism of this outflow. \n\n"}
{"id": "1712.07656", "contents": "Title: Resummed Photon Spectra for WIMP Annihilation Abstract: We construct an effective field theory (EFT) description of the hard photon\nspectrum for heavy WIMP annihilation. This facilitates precision predictions\nrelevant for line searches, and allows the incorporation of non-trivial energy\nresolution effects. Our framework combines techniques from non-relativistic\nEFTs and soft-collinear effective theory (SCET), as well as its multi-scale\nextensions that have been recently introduced for studying jet substructure. We\nfind a number of interesting features, including the simultaneous presence of\nSCET$_{\\text{I}}$ and SCET$_{\\text{II}}$ modes, as well as collinear-soft modes\nat the electroweak scale. We derive a factorization formula that enables both\nthe resummation of the leading large Sudakov double logarithms that appear in\nthe perturbative spectrum, and the inclusion of Sommerfeld enhancement effects.\nConsistency of this factorization is demonstrated to leading logarithmic order\nthrough explicit calculation. Our final result contains both the exclusive and\nthe inclusive limits, thereby providing a unifying description of these two\npreviously-considered approximations. We estimate the impact on experimental\nsensitivity, focusing for concreteness on an SU(2)$_{W}$ triplet fermion dark\nmatter - the pure wino - where the strongest constraints are due to a search\nfor gamma-ray lines from the Galactic Center. We find numerically significant\ncorrections compared to previous results, thereby highlighting the importance\nof accounting for the photon spectrum when interpreting data from current and\nfuture indirect detection experiments. \n\n"}
{"id": "1712.10116", "contents": "Title: A momentum conserving $N$-body scheme with individual timesteps Abstract: $N$-body simulations study the dynamics of $N$ particles under the influence\nof mutual long-distant forces such as gravity. In practice, $N$-body codes will\nviolate Newton's third law if they use either an approximate Poisson solver or\nindividual timesteps. In this study, we construct a novel $N$-body scheme by\ncombining a fast multipole method (FMM) based Poisson solver and a time\nintegrator using a hierarchical Hamiltonian splitting (HHS) technique. We test\nour implementation for collision-less systems using several problems in\ngalactic dynamics. As a result of the momentum conserving nature of these two\nkey components, the new $N$-body scheme is also momentum conserving. Moreover,\nwe can fully utilize the $\\mathcal O(\\textit N)$ complexity of FMM with the\nintegrator. With the restored force symmetry, we can improve both angular\nmomentum conservation and energy conservation substantially. The new scheme\nwill be suitable for many applications in galactic dynamics and structure\nformation. Our implementation, in the code Taichi, is publicly available at\nhttps://bitbucket.org/qirong_zhu/taichi_public/. \n\n"}
{"id": "1801.01015", "contents": "Title: An accurate centroid algorithm for PSF reconstruction Abstract: In this work, we present a novel centroiding method based on Fourier space\nPhase Fitting(FPF) for Point Spread Function(PSF) reconstruction. We generate\ntwo sets of simulations to test our method. The first set is generated by\nGalSim with elliptical Moffat profile and strong anisotropy which shifts the\ncenter of the PSF. The second set of simulation is drawn from CFHT i band\nstellar imaging data. We find non-negligible anisotropy from CFHT stellar\nimages, which leads to $\\sim$0.08 scatter in unit of pixels using polynomial\nfitting method Vakili and Hogg (2016). And we apply FPF method to estimate the\ncentroid in real space, this scatter reduces to $\\sim$0.04 in SNR=200 CFHT like\nsample. In low SNR (50 and 100) CFHT like samples, the background noise\ndominates the shifting of the centroid, therefore the scatter estimated from\ndifferent methods are similar. We compare polynomial fitting and FPF using\nGalSim simulation with optical anisotropy. We find that in all SNR$\\sim$50, 100\nand 200) samples, FPF performs better than polynomial fitting by a factor of\n$\\sim$3. In general, we suggest that in real observations there are anisotropy\nwhich shift the centroid, and FPF method is a better way to accurately locate\nit. \n\n"}
{"id": "1801.02197", "contents": "Title: Realistic Image Degradation with Measured PSF Abstract: Training autonomous vehicles requires lots of driving sequences in all\nsituations\\cite{zhao2016}. Typically a simulation environment\n(software-in-the-loop, SiL) accompanies real-world test drives to\nsystematically vary environmental parameters. A missing piece in the optical\nmodel of those SiL simulations is the sharpness, given in linear system theory\nby the point-spread function (PSF) of the optical system. We present a novel\nnumerical model for the PSF of an optical system that can efficiently model\nboth experimental measurements and lens design simulations of the PSF. The\nnumerical basis for this model is a non-linear regression of the PSF with an\nartificial neural network (ANN). The novelty lies in the portability and the\nparameterization of this model, which allows to apply this model in basically\nany conceivable optical simulation scenario, e.g. inserting a measured lens\ninto a computer game to train autonomous vehicles. We present a lens\nmeasurement series, yielding a numerical function for the PSF that depends only\non the parameters defocus, field and azimuth. By convolving existing images and\nvideos with this PSF model we apply the measured lens as a transfer function,\ntherefore generating an image as if it were seen with the measured lens itself.\nApplications of this method are in any optical scenario, but we focus on the\ncontext of autonomous driving, where quality of the detection algorithms\ndepends directly on the optical quality of the used camera system. With the\nparameterization of the optical model we present a method to validate the\nfunctional and safety limits of camera-based ADAS based on the real, measured\nlens actually used in the product. \n\n"}
{"id": "1801.02417", "contents": "Title: Sparse interferometric Stokes imaging under polarization constraint\n  (Polarized SARA) Abstract: We develop a novel algorithm for sparse Stokes parameters imaging in radio\ninterferometry under the polarization constraint. The latter is a physical\nnon-linear relation between the Stokes parameters, imposing that the\npolarization intensity is a lower bound on the total intensity. To solve the\njoint inverse Stokes imaging problem including this bound, we leverage\nepigraphical projection techniques in convex optimization and design a\nprimal-dual method offering a highly flexible and parallelizable structure. In\naddition, we propose to regularize each Stokes parameter map through an average\nsparsity prior in the context of a reweighted analysis approach (SARA). The\nresulting approach is dubbed Polarized SARA. We demonstrate on simulated\nobservations of M87 with the Event Horizon Telescope that imposing the\npolarization constraint leads to superior image quality. The results also\nconfirm that the performance of the average sparsity prior surpasses the\nalternative state-of-the-art priors for polarimetric imaging. \n\n"}
{"id": "1801.02814", "contents": "Title: Breakthrough Listen Observations of 1I/'Oumuamua with the GBT Abstract: We have conducted a search for radio emission consistent with an artificial\nsource targeting 1I/'Oumuamua with the Robert C. Byrd Green Bank Telescope\n(GBT) between 1.1 and 11.6 GHz. We searched the data for narrowband signals and\nfound none. Given the close proximity to this interstellar object, we can place\nlimits to putative transmitters with extremely low power (0.08 W). \n\n"}
{"id": "1801.04124", "contents": "Title: Optical Follow-up of Planck Cluster Candidates with Small Instruments Abstract: We report on the search for optical counterparts of Planck Sunyaev-Zel'dovich\n(SZ) cluster candidates using a 0.6 meter non-professional telescope. Among the\nobserved sources, an unconfirmed candidate, PSZ2 G156.24+22.32, is found to be\nassociated with a region of more than 100 galaxies within a 3 arcminutes radius\naround the Sunyaev-Zel'dovich maximum signal coordinates. Using 14 hours of\ncumulated exposure over the Sloan color filters g', r', i', and, z', we\nestimate the photometric redshift of these galaxies at zphot=0.29 +- 0.08.\nUsing the red-sequence galaxy method gives a photometric redshift of 0.30 +0.03\n-0.05. Combined with the Planck SZ proxy mass function, this would favor a\ncluster of 4.4 x 10^{14} solar masses. This result suggests that a dedicated\npool of observatories equipped with such instruments could collectively\ncontribute to optical follow-up programs of massive cluster candidates at\nmoderate redshifts. \n\n"}
{"id": "1801.06179", "contents": "Title: Accretion of clumpy cold gas onto massive black holes binaries: the\n  challenging formation of extended circumbinary structures Abstract: Massive black hole binaries (MBHBs) represent an unavoidable outcome of\nhierarchical galaxy formation, but their dynamical evolution at sub-parsec\nscales is poorly understood, due to a combination of uncertainties in\ntheoretical models and lack of firm observational evidence. In gas rich\nenvironments, it has been shown that a putative extended, steady circumbinary\ngaseous disc plays an important role in the MBHB evolution, facilitating its\ncoalescence. How gas on galactic scales is transported to the nuclear region to\nform and maintain such a stable structure is, however, unclear. If, following a\ngalaxy merger, turbulent gas is condenses in cold clumps and filaments that are\nrandomly scattered, gas is naturally transported on parsec scales and interacts\nwith the MBHB in discrete incoherent pockets. The aim of this work is to\ninvestigate the gaseous structures arising from this interaction. We employ a\nsuite of smoothed-particle-hydrodynamic simulations to study the formation and\nevolution of gaseous structures around a MBHB constantly perturbed by the\nincoherent infall of molecular clouds. We investigate the influence of the\ninfall rate and angular momentum distribution of the clouds on the geometry and\nstability of the arising structures. We find that the continuous supply of\nincoherent clouds is a double-edge sword, resulting in the intermittent\nformation and disruption of circumbinary structures. Anisotropic cloud\ndistributions featuring an excess of co-rotating events generate more prominent\nco-rotating circumbinary discs. Similar structures are seen when mostly\ncounter-rotating clouds are fed to the binary, even though they are more\ncompact and less stable. In general, our simulations do not show the formation\nof extended smooth and stable circumbinary discs, typically assumed in\nanalytical and numerical investigations of the the long term evolution of\nMBHBs. (Abridged) \n\n"}
{"id": "1801.06653", "contents": "Title: Measurement of the liquid argon energy response to nuclear and\n  electronic recoils Abstract: A liquid argon time projection chamber, constructed for the Argon Response to\nIonization and Scintillation (ARIS) experiment, has been exposed to the highly\ncollimated and quasi-monoenergetic LICORNE neutron beam at the Institute de\nPhysique Nuclaire Orsay in order to study the scintillation response to nuclear\nand electronic recoils. An array of liquid scintillator detectors, arranged\naround the apparatus, tag scattered neutrons and select nuclear recoil energies\nin the [7, 120] keV energy range. The relative scintillation efficiency of\nnuclear recoils was measured to high precision at null field, and the\nion-electron recombination probability was extracted for a range of applied\nelectric fields. Single Compton scattered electrons, produced by gammas emitted\nfrom the de-excitation of $^7$Li* in coincidence with the beam pulse, along\nwith calibration gamma sources, are used to extract the recombination\nprobability as a function of energy and electron drift field. The ARIS results\nhave been compared with three recombination probability parameterizations\n(Thomas-Imel, Doke-Birks, and PARIS), allowing for the definition of a fully\ncomprehensive model of the liquid argon response to nuclear and electronic\nrecoils down to a few keV range. The constraints provided by ARIS to the liquid\nargon response at low energy allow the reduction of systematics affecting the\nsensitivity of dark matter search experiments based on liquid argon \n\n"}
{"id": "1801.06660", "contents": "Title: A Dust spectral energy distribution model with hierarchical Bayesian\n  inference. I. Formalism & benchmarking Abstract: This article presents a new dust SED model, named HerBIE, aimed at\neliminating the noise-induced correlations and large scatter obtained when\nperforming least-squares fits. The originality of this code is to apply the\nhierarchical Bayesian approach to full dust models, including realistic optical\nproperties, stochastic heating and the mixing of physical conditions in the\nobserved regions. We test the performances of our model by applying it to\nsynthetic observations. We explore the impact on the recovered parameters of\nseveral effects: signal-to-noise ratio, SED shape, sample size, the presence of\nintrinsic correlations, the wavelength coverage and the use of different SED\nmodel components. We show that this method is very efficient: the recovered\nparameters are consistently distributed around their true values. We do not\nfind any clear bias, even for the most degenerate parameters, or with extreme\nsignal-to-noise ratios. \n\n"}
{"id": "1801.07323", "contents": "Title: Machine Learning-based Brokers for Real-time Classification of the LSST\n  Alert Stream Abstract: The unprecedented volume and rate of transient events that will be discovered\nby the Large Synoptic Survey Telescope (LSST) demands that the astronomical\ncommunity update its followup paradigm. Alert-brokers -- automated software\nsystem to sift through, characterize, annotate and prioritize events for\nfollowup -- will be critical tools for managing alert streams in the LSST era.\nThe Arizona-NOAO Temporal Analysis and Response to Events System (ANTARES) is\none such broker. In this work, we develop a machine learning pipeline to\ncharacterize and classify variable and transient sources only using the\navailable multiband optical photometry. We describe three illustrative stages\nof the pipeline, serving the three goals of early, intermediate and\nretrospective classification of alerts. The first takes the form of variable vs\ntransient categorization, the second, a multi-class typing of the combined\nvariable and transient dataset, and the third, a purity-driven subtyping of a\ntransient class. While several similar algorithms have proven themselves in\nsimulations, we validate their performance on real observations for the first\ntime. We quantitatively evaluate our pipeline on sparse, unevenly sampled,\nheteroskedastic data from various existing observational campaigns, and\ndemonstrate very competitive classification performance. We describe our\nprogress towards adapting the pipeline developed in this work into a real-time\nbroker working on live alert streams from time-domain surveys. \n\n"}
{"id": "1802.00441", "contents": "Title: Compact object mergers driven by gas fallback Abstract: Recently several gravitational wave detections have shown evidence for\ncompact object mergers. However, the astrophysical origin of merging binaries\nis not well understood. Stellar binaries are typically at much larger\nseparations than what is needed for the binaries to merge due to gravitational\nwave emission, which leads to the so-called final AU problem. In this letter we\npropose a new channel for mergers of compact object binaries which solves the\nfinal AU problem. We examine the binary evolution following gas expansion due\nto a weak failed supernova explosion, neutrino mass loss, core disturbance, or\nenvelope instability. In such situations the binary is possibly hardened by\nambient gas. We investigate the evolution of the binary system after a shock\nhas propagated by performing smoothed particle hydrodynamics simulations. We\nfind that significant binary hardening occurs when the gas mass bound to the\nbinary exceeds that of the compact objects. This mechanism represents a new\npossibility for the pathway to mergers for gravitational wave events. \n\n"}
{"id": "1802.02575", "contents": "Title: New variable Stars from the Photographic Archive: Semi-automated\n  Discoveries, Attempts of Automatic Classification, and the New Field 104 Her Abstract: Using 172 plates taken with the 40-cm astrograph of the Sternberg\nAstronomical Institute (Lomonosov Moscow University) in 1976-1994 and digitized\nwith the resolution of 2400 dpi, we discovered and studied 275 new variable\nstars. We present the list of our new variables with all necessary information\nconcerning their brightness variations. As in our earlier studies, the new\ndiscoveries show a rather large number of high-amplitude Delta Scuti variables,\npredicting that many stars of this type remain not detected in the whole sky.\nWe also performed automated classification of the newly discovered variable\nstars based on the Random Forest algorithm. The results of the automated\nclassification were compared to traditional classification and showed that\nautomated classification was possible even with noisy photographic data.\nHowever, further improvement of automated techniques is needed, which is\nespecially important having in mind the very large numbers of new discoveries\nexpected from all-sky surveys. \n\n"}
{"id": "1802.02581", "contents": "Title: Self-consistent redshift estimation using correlation functions without\n  a spectroscopic reference sample Abstract: We present a new method to estimate redshift distributions and galaxy-dark\nmatter bias parameters using correlation functions in a fully data driven and\nself-consistent manner. Unlike other machine learning, template, or correlation\nredshift methods, this approach does not require a reference sample with known\nredshifts. By measuring the projected cross- and auto- correlations of\ndifferent galaxy sub-samples, e.g., as chosen by simple cells in\ncolor-magnitude space, we are able to estimate the galaxy-dark matter bias\nmodel parameters, and the shape of the redshift distributions of each\nsub-sample. This method fully marginalises over a flexible parameterisation of\nthe redshift distribution and galaxy-dark matter bias parameters of sub-samples\nof galaxies, and thus provides a general Bayesian framework to incorporate\nredshift uncertainty into the cosmological analysis in a data-driven,\nconsistent, and reproducible manner. This result is improved by an order of\nmagnitude by including cross-correlations with the CMB and with galaxy-galaxy\nlensing.\n  We showcase how this method could be applied to real galaxies. By using\nidealised data vectors, in which all galaxy-dark matter model parameters and\nredshift distributions are known, this method is demonstrated to recover\nunbiased estimates on important quantities, such as the offset $\\Delta_z$\nbetween the mean of the true and estimated redshift distribution and the 68\\%\nand 95\\% and 99.5\\% widths of the redshift distribution to an accuracy required\nby current and future surveys. \n\n"}
{"id": "1802.06039", "contents": "Title: Projected WIMP sensitivity of the LUX-ZEPLIN (LZ) dark matter experiment Abstract: LUX-ZEPLIN (LZ) is a next generation dark matter direct detection experiment\nthat will operate 4850 feet underground at the Sanford Underground Research\nFacility (SURF) in Lead, South Dakota, USA. Using a two-phase xenon detector\nwith an active mass of 7~tonnes, LZ will search primarily for low-energy\ninteractions with Weakly Interacting Massive Particles (WIMPs), which are\nhypothesized to make up the dark matter in our galactic halo. In this paper,\nthe projected WIMP sensitivity of LZ is presented based on the latest\nbackground estimates and simulations of the detector. For a 1000~live day run\nusing a 5.6~tonne fiducial mass, LZ is projected to exclude at 90\\% confidence\nlevel spin-independent WIMP-nucleon cross sections above $1.4 \\times\n10^{-48}$~cm$^{2}$ for a 40~$\\mathrm{GeV}/c^{2}$ mass WIMP. Additionally, a\n$5\\sigma$ discovery potential is projected reaching cross sections below the\nexclusion limits of recent experiments. For spin-dependent\nWIMP-neutron(-proton) scattering, a sensitivity of $2.3 \\times\n10^{-43}$~cm$^{2}$ ($7.1 \\times 10^{-42}$~cm$^{2}$) for a\n40~$\\mathrm{GeV}/c^{2}$ mass WIMP is expected. With underground installation\nwell underway, LZ is on track for commissioning at SURF in 2020. \n\n"}
{"id": "1802.06280", "contents": "Title: Spatial field reconstruction with INLA: Application to IFU galaxy data Abstract: Astronomical observations of extended sources, such as cubes of integral\nfield spectroscopy (IFS), encode auto-correlated spatial structures that cannot\nbe optimally exploited by standard methodologies. This work introduces a novel\ntechnique to model IFS datasets, which treats the observed galaxy properties as\nrealizations of an unobserved Gaussian Markov random field. The method is\ncomputationally efficient, resilient to the presence of low-signal-to-noise\nregions, and uses an alternative to Markov Chain Monte Carlo for fast Bayesian\ninference, the Integrated Nested Laplace Approximation (INLA). As a case study,\nwe analyse 721 IFS data cubes of nearby galaxies from the CALIFA and PISCO\nsurveys, for which we retrieve the maps of the following physical properties:\nage, metallicity, mass and extinction. The proposed Bayesian approach, built on\na generative representation of the galaxy properties, enables the creation of\nsynthetic images, recovery of areas with bad pixels, and an increased power to\ndetect structures in datasets subject to substantial noise and/or sparsity of\nsampling. A snippet code to reproduce the analysis of this paper is available\nin the COIN toolbox, together with the field reconstructions of the CALIFA and\nPISCO samples. \n\n"}
{"id": "1802.06849", "contents": "Title: The World Space Observatory Ultraviolet (WSO-UV), as a bridge to future\n  UV astronomy Abstract: The ultraviolet (UV) astronomy is a very demanded branch of space astronomy.\nMany dozens of short-term UV-experiments in space, as well as long-term\nobservatories, have brought a very important knowledge on the physics and\nchemistry of the Universe during the last decades. Unfortunately, no large\nUV-observatories are planned to be launched by most of space agencies in the\ncoming 10 -- 15 years. Conversely, the large UVOIR observatories of the future\nwill appear not earlier than in 2030s. This paper briefly describes the\nprojects that have been proposed by various groups. We conclude that the World\nSpace Observatory -- Ultraviolet (WSO-UV) will be the only 2-m class UV\ntelescope with capabilities similar to those of the HST for the next decade.\nThe WSO-UV has been described in detail in previous publications, and this\npaper updates the main characteristics of its instruments and the current state\nof the whole project. It also addresses the major science topics that have been\nincluded in the core program of the WSO-UV, making this core program very\nrelevant to the current state of the UV-astronomy. Finally, we also present\nhere the ground segment architecture that will implement this program. \n\n"}
{"id": "1802.07371", "contents": "Title: Gravitational Wave Opacity from Gauge Field Dark Energy Abstract: We show that astrophysical gravitational waves can undergo an anomalous\nmodulation when propagating through cosmic gauge field dark energy. A\nsufficiently strong effect, dependent on the gauge field energy density, would\nappear as a redshift-dependent opacity, thereby impacting the use of\ngravitational wave standard sirens to constrain the expansion history of the\nUniverse. We investigate a particular model of cosmic gauge field dark energy\nand show that at early times it behaves like dark radiation, whereas a novel\ninteraction causes it to drive cosmic acceleration at late times. Joint\nconstraints on the cosmological scenario due to type 1a supernovae, baryon\nacoustic oscillations, and cosmic microwave background data are presented. In\nview of these constraints, we show that standard siren luminosity distances in\nthe redshift range 0.5 < z < 1.5 would systematically dim by up to 1%, which\nmay be distinguishable by third-generation gravitational wave detectors. \n\n"}
{"id": "1802.08503", "contents": "Title: The Durham Adaptive Optics Simulation Platform (DASP): Current status Abstract: The Durham Adaptive Optics Simulation Platform (DASP) is a Monte-Carlo\nmodelling tool used for the simulation of astronomical and solar adaptive\noptics systems. In recent years, this tool has been used to predict the\nexpected performance of the forthcoming extremely large telescope adaptive\noptics systems, and has seen the addition of several modules with new features,\nincluding Fresnel optics propagation and extended object wavefront sensing.\nHere, we provide an overview of the features of DASP and the situations in\nwhich it can be used. Additionally, the user tools for configuration and\ncontrol are described. \n\n"}
{"id": "1802.08639", "contents": "Title: A prototype detector for the CRESST-III low-mass dark matter search Abstract: The CRESST-III experiment which is dedicated to low-mass dark matter search\nuses scintillating CaWO$_4$ crystals operated as cryogenic particle detectors.\nBackground discrimination is achieved by exploiting the scintillating light\nsignal of CaWO$_4$ and by a novel active detector holder presented in this\npaper. In a test setup above ground, a nuclear-recoil energy threshold of\n$E_{th}=(190.6\\pm5.2)$eV is reached with a 24g prototype detector, which\ncorresponds to an estimated threshold of $\\sim$50eV when being operated in the\nlow-noise CRESST cryostat. This is the lowest threshold reported for direct\ndark matter searches. For CRESST-III phase 1, ten such detector modules were\ninstalled in the cryostat which have the potential to improve significantly the\nsensitivity to scatterings of dark matter particles with masses down to\n$\\sim$0.1GeV/c$^2$. \n\n"}
{"id": "1802.08913", "contents": "Title: Constraining the $\\bar{p}/p$ Ratio in TeV Cosmic Rays with Observations\n  of the Moon Shadow by HAWC Abstract: An indirect measurement of the antiproton flux in cosmic rays is possible as\nthe particles undergo deflection by the geomagnetic field. This effect can be\nmeasured by studying the deficit in the flux, or shadow, created by the Moon as\nit absorbs cosmic rays that are headed towards the Earth. The shadow is\ndisplaced from the actual position of the Moon due to geomagnetic deflection,\nwhich is a function of the energy and charge of the cosmic rays. The\ndisplacement provides a natural tool for momentum/charge discrimination that\ncan be used to study the composition of cosmic rays. Using 33 months of data\ncomprising more than 80 billion cosmic rays measured by the High Altitude Water\nCherenkov (HAWC) observatory, we have analyzed the Moon shadow to search for\nTeV antiprotons in cosmic rays. We present our first upper limits on the\n$\\bar{p}/p$ fraction, which in the absence of any direct measurements, provide\nthe tightest available constraints of $\\sim1\\%$ on the antiproton fraction for\nenergies between 1 and 10 TeV. \n\n"}
{"id": "1802.09450", "contents": "Title: Objective Bayesian analysis of neutrino masses and hierarchy Abstract: Given the precision of current neutrino data, priors still impact noticeably\nthe constraints on neutrino masses and their hierarchy. To avoid our\nunderstanding of neutrinos being driven by prior assumptions, we construct a\nprior that is mathematically minimally informative. Using the constructed\nuninformative prior, we find that the normal hierarchy is favoured but with\ninconclusive posterior odds of 5.1:1. Better data is hence needed before the\nneutrino masses and their hierarchy can be well constrained. We find that the\nnext decade of cosmological data should provide conclusive evidence if the\nnormal hierarchy with negligible minimum mass is correct, and if the\nuncertainty in the sum of neutrino masses drops below 0.025 eV. On the other\nhand, if neutrinos obey the inverted hierarchy, achieving strong evidence will\nbe difficult with the same uncertainties. Our uninformative prior was\nconstructed from principles of the Objective Bayesian approach. The prior is\ncalled a reference prior and is minimally informative in the specific sense\nthat the information gain after collection of data is maximised. The prior is\ncomputed for the combination of neutrino oscillation data and cosmological data\nand still applies if the data improve. \n\n"}
{"id": "1802.09536", "contents": "Title: Astrophysics with New Horizons: Making the Most of a Generational\n  Opportunity Abstract: The outer solar system provides a unique, quiet vantage point from which to\nobserve the universe around us, where measurements could enable several niche\nastrophysical science cases that are too difficult to perform near Earth.\nNASA's New Horizons mission comprises an instrument package that provides\nimaging capability from ultraviolet (UV) to near-infrared (near-IR) wavelengths\nwith moderate spectral resolution located beyond the orbit of Pluto. A\ncarefully designed survey with New Horizons can optimize the use of expendable\npropellant and the limited data telemetry bandwidth to allow several\nmeasurements, including a detailed understanding of the cosmic extragalactic\nbackground light; studies of the local and extragalactic UV background;\nmeasurements of the properties of dust and ice in the outer solar system;\nconfirmation and characterization of transiting exoplanets; determinations of\nthe mass of dark objects using gravitational microlensing; and rapid follow-up\nof transient events. New Horizons is currently in an extended mission designed\nto focus on Kuiper Belt science that will conclude in 2021. The astrophysics\ncommunity has a unique, generational opportunity to use this mission for\nastronomical observation at heliocentric distances beyond 50 au in the next\ndecade. In this paper, we discuss the potential science cases for such an\nextended mission, and provide an initial assessment of the most important\noperational requirements and observation strategies it would require. We\nconclude that New Horizons is capable of transformative science, and that it\nwould make a valuable and unique asset for astrophysical science that is\nunlikely to be replicated in the near future. \n\n"}
{"id": "1802.10105", "contents": "Title: Alignment between satellite and central galaxies in the SDSS DR7:\n  dependence on large-scale environment Abstract: The alignment between satellites and central galaxies has been studied in\ndetail both in observational and theoretical works. The widely accepted fact is\nthat the satellites preferentially reside along the major axis of their central\ngalaxy. However, the origin and large-scale environment dependence of this\nalignment are still unknown. In an attempt to figure out those, we use data\nconstructed from SDSS DR7 to investigate the large-scale environmental\ndependence of this alignment with emphasis on examining the alignments'\ndependence on the colour of the central galaxy. We find a very strong\nlarge-scale environmental dependence of the satellite-central alignment in\ngroups with blue centrals. Satellites of blue centrals in knots are\npreferentially located perpendicular to the major axis of the centrals, and the\nalignment angle decreases with environment namely when going from knots to\nvoids. The alignment angle strongly depend on the ${}^{0.1}(g-r)$ colour of\ncentrals. We suggest that the satellite-central alignment is the result of a\ncompetition between satellite accretion within large scale-structure and galaxy\nevolution inside host haloes. For groups containing red central galaxies, the\nsatellite-central alignment is mainly determined by the evolution effect, while\nfor blue central dominated groups, the effect of large-scale structure plays a\nmore important role, especially in knots. Our results provide an explanation\nfor how the satellite-central alignment forms within different large-scale\nenvironments. The perpendicular case in groups and knots with blue centrals may\nalso provide insight into understanding similar polar arrangements such the\nformation of the Milky Way and Centaurus A's satellite system. \n\n"}
{"id": "1802.10282", "contents": "Title: Weak Lensing Study in VOICE Survey I: Shear Measurement Abstract: The VST Optical Imaging of the CDFS and ES1 Fields (VOICE) Survey is a\nGuaranteed Time program carried out with the ESO/VST telescope to provide deep\noptical imaging over two 4 deg$^2$ patches of the sky centred on the CDFS and\nES1 pointings. We present the cosmic shear measurement over the 4 deg$^2$\ncovering the CDFS region in the $r$-band using LensFit. Each of the four tiles\nof 1 deg$^2$ has more than one hundred exposures, of which more than 50\nexposures passed a series of image quality selection criteria for weak lensing\nstudy. The $5\\sigma$ limiting magnitude in $r$- band is 26.1 for point sources,\nwhich is $\\sim$1 mag deeper than other weak lensing survey in the literature\n(e.g. the Kilo Degree Survey, KiDS, at VST). The photometric redshifts are\nestimated using the VOICE $u,g,r,i$ together with near-infrared VIDEO data\n$Y,J,H,K_s$. The mean redshift of the shear catalogue is 0.87, considering the\nshear weight. The effective galaxy number density is 16.35 gal/arcmin$^2$,\nwhich is nearly twice the one of KiDS. The performance of LensFit on such a\ndeep dataset was calibrated using VOICE-like mock image simulations.\nFurthermore, we have analyzed the reliability of the shear catalogue by\ncalculating the star-galaxy cross-correlations, the tomographic shear\ncorrelations of two redshift bins and the contaminations of the blended\ngalaxies. As a further sanity check, we have constrained cosmological\nparameters by exploring the parameter space with Population Monte Carlo\nsampling. For a flat $\\Lambda$CDM model we have obtained $\\Sigma_8$ =\n$\\sigma_8(\\Omega_m/0.3)^{0.5}$ = $0.68^{+0.11}_{-0.15}$. \n\n"}
{"id": "1803.00010", "contents": "Title: Tangos: the agile numerical galaxy organization system Abstract: We present Tangos, a Python framework and web interface for database-driven\nanalysis of numerical structure formation simulations. To understand the role\nthat such a tool can play, consider constructing a history for the absolute\nmagnitude of each galaxy within a simulation. The magnitudes must first be\ncalculated for all halos at all timesteps and then linked using a merger tree;\nfolding the required information into a final analysis can entail significant\neffort. Tangos is a generic solution to this information organization problem,\naiming to free users from the details of data management. At the querying\nstage, our example of gathering properties over history is reduced to a few\nclicks or a simple, single-line Python command. The framework is highly\nextensible; in particular, users are expected to define their own properties\nwhich tangos will write into the database. A variety of parallelization options\nare available and the raw simulation data can be read using existing libraries\nsuch as pynbody or yt. Finally, tangos-based databases and analysis pipelines\ncan easily be shared with collaborators or the broader community to ensure\nreproducibility. User documentation is provided separately. \n\n"}
{"id": "1803.01952", "contents": "Title: Analyzing the Gamma-ray Sky with Wavelets Abstract: We analyze the gamma-ray sky at energies of 0.5 to 50 GeV using the\nundecimated wavelet transform on the sphere. Focusing on the inner $60^{\\circ}\n\\times 60^{\\circ}$ of the sky, we identify and characterize four separate\nresiduals beyond the expected Milky Way diffuse emission. We detect the\n\\textit{Fermi} Bubbles, finding compelling evidence that they are diffuse in\nnature and contain very little small-scale structure. We detect the \"cocoon\"\ninside the Southern Bubble, and we also identify its northern counterpart above\n2 GeV. The Northern Cocoon lies along the same axis but is $\\sim 30 \\%$ dimmer\nthan the southern one. We characterize the Galactic center excess, which we\nfind extends up to $20^{\\circ}$ in $|b|$. At latitudes $|b| \\leq 5^{\\circ}$ we\nfind evidence for power in small angular scales that could be the result of\npoint-source contributions, but for $|b| \\geq 5^{\\circ}$ the Galactic center\nexcess is dominantly diffuse in its nature. Our findings show that either the\nGalactic center excess and {\\it Fermi} Bubbles connect smoothly or that the\nBubbles brighten significantly below $15^\\circ$ in latitude. We find that the\nGalactic center excess appears off-center by a few degrees towards negative\n$\\ell$. Additionally, we find and characterize two emissions along the Galactic\ndisk centered at $\\ell \\simeq +25^{\\circ}$ and $-20^{\\circ}$. These emissions\nare significantly more elongated along the Galactic disk than the Galactic\ncenter excess. \n\n"}
{"id": "1803.02601", "contents": "Title: Fast in-database cross-matching of high-cadence, high-density source\n  lists with an up-to-date sky model Abstract: Coming high-cadence wide-field optical telescopes will image hundreds of\nthousands of sources per minute. Besides inspecting the near real-time data\nstreams for transient and variability events, the accumulated data archive is a\nwealthy laboratory for making complementary scientific discoveries.\n  The goal of this work is to optimise column-oriented database techniques to\nenable the construction of a full-source and light-curve database for\nlarge-scale surveys, that is accessible by the astronomical community.\n  We adopted LOFAR's Transients Pipeline as the baseline and modified it to\nenable the processing of optical images that have much higher source densities.\nThe pipeline adds new source lists to the archive database, while\ncross-matching them with the known cataloged sources in order to build a full\nlight-curve archive. We investigated several techniques of indexing and\npartitioning the largest tables, allowing for faster positional source look-ups\nin the cross matching algorithms. We monitored all query run times in long-term\npipeline runs where we processed a subset of IPHAS data that have image source\ndensity peaks over $170,000$ per field of view ($500,000$ deg$^{-2}$).\n  Our analysis demonstrates that horizontal table partitions of declination\nwidths of one-degree control the query run times. Usage of an index strategy\nwhere the partitions are densily sorted according to source declination yields\nanother improvement. Most queries run in sublinear time and a few (<20%) run in\nlinear time, because of dependencies on input source-list and result-set size.\nWe observed that for this logical database partitioning schema the limiting\ncadence the pipeline achieved with processing IPHAS data is 25 seconds. \n\n"}
{"id": "1803.03858", "contents": "Title: Testing One Hypothesis Multiple Times: The Multidimensional Case Abstract: The identification of new rare signals in data, the detection of a sudden\nchange in a trend, and the selection of competing models, are among the most\nchallenging problems in statistical practice. These challenges can be tackled\nusing a test of hypothesis where a nuisance parameter is present only under the\nalternative, and a computationally efficient solution can be obtained by the\n\"Testing One Hypothesis Multiple times\" (TOHM) method. In the one-dimensional\nsetting, a fine discretization of the space of the non-identifiable parameter\nis specified, and a global p-value is obtained by approximating the\ndistribution of the supremum of the resulting stochastic process. In this\npaper, we propose a computationally efficient inferential tool to perform TOHM\nin the multidimensional setting. Here, the approximations of interest typically\ninvolve the expected Euler Characteristics (EC) of the excursion set of the\nunderlying random field. We introduce a simple algorithm to compute the EC in\nmultiple dimensions and for arbitrary large significance levels. This leads to\nan highly generalizable computational tool to perform inference under\nnon-standard regularity conditions. \n\n"}
{"id": "1803.06314", "contents": "Title: Potential Impact of Global Navigation Satellite Services on Total Power\n  HI Intensity Mapping Surveys Abstract: Future total-power single-dish HI intensity mapping (HI IM) surveys have the\npotential to provide unprecedented insight into late time ($z < 1$) cosmology\nthat are competitive with Stage IV dark energy surveys. However, redshifts\nbetween $0 < z < 0.2$ lie within the transmission bands of global navigation\nsatellite services (GNSS), and even at higher redshifts out-of-band leakage\nfrom GNSS satellites may be problematic. We estimate the impact of GNSS\nsatellites on future single-dish HI IM surveys using realistic estimates of\nboth the total power and spectral structure of GNSS signals convolved with a\nmodel SKA beam. Using a simulated SKA HI IM survey covering 30000 sq. deg. of\nsky and 200 dishes, we compare the integrated GNSS emission on the sky with the\nexpected HI signal. It is found that for frequencies $> 950$ MHz the emission\nfrom GNSS satellites will exceed the expected HI signal for all angular scales\nto which the SKA is sensitive when operating in single-dish mode. \n\n"}
{"id": "1803.09557", "contents": "Title: RELICS: Strong Lensing analysis of the galaxy clusters Abell S295, Abell\n  697, MACS J0025.4-1222, and MACS J0159.8-0849 Abstract: We present a strong-lensing analysis of four massive galaxy clusters imaged\nwith the Hubble Space Telescope in the Reionization Lensing Cluster Survey. We\nuse a Light-Traces-Mass technique to uncover sets of multiply images and\nconstrain the mass distribution of the clusters. These mass models are the\nfirst published for Abell S295 and MACS J0159.8-0849, and are improvements over\nprevious models for Abell 697 and MACS J0025.4-1222. Our analysis for MACS\nJ0025.4-1222 and Abell S295 shows a bimodal mass distribution supporting the\nmerger scenarios proposed for these clusters. The updated model for MACS\nJ0025.4-1222 suggests a substantially smaller critical area than previously\nestimated. For MACS J0159.8-0849 and Abell 697 we find a single peak and\nrelatively regular morphology, revealing fairly relaxed clusters. Despite being\nless prominent lenses, three of these clusters seem to have lensing strengths,\ni.e. cumulative area above certain magnification, similar to the Hubble\nFrontier Fields clusters (e.g., A($\\mu>5$) $\\sim 1-3$ arcmin$^2$, A($\\mu>10$)\n$\\sim 0.5-1.5$ arcmin$^2$), which in part can be attributed to their merging\nconfigurations. We make our lens models publicly available through the Mikulski\nArchive for Space Telescopes. Finally, using Gemini-N/GMOS spectroscopic\nobservations we detect a single emission line from a high-redshift\n$J_{125}\\simeq25.7$ galaxy candidate lensed by Abell 697. While we cannot rule\nout a lower-redshift solution, we interpret the line as Ly$\\alpha$ at\n$z=5.800\\pm 0.001$, in agreement with its photometric redshift and dropout\nnature. Within this scenario we measure a Ly$\\alpha$ rest-frame equivalent\nwidth of $52\\pm22$ \\AA, and an observed Gaussian width of $117\\pm 15$ km/s. \n\n"}
{"id": "1803.10240", "contents": "Title: An enigmatic population of luminous globular clusters in a galaxy\n  lacking dark matter Abstract: We recently found an ultra diffuse galaxy (UDG) with a half-light radius of\nR_e = 2.2 kpc and little or no dark matter. The total mass of NGC1052-DF2 was\nmeasured from the radial velocities of bright compact objects that are\nassociated with the galaxy. Here we analyze these objects using a combination\nof HST imaging and Keck spectroscopy. Their average size is <r_h> = 6.2+-0.5 pc\nand their average ellipticity is <{\\epsilon}> = 0.18+-0.02. From a stacked Keck\nspectrum we derive an age >9 Gyr and a metallicity of [Fe/H] = -1.35+-0.12.\nTheir properties are similar to {\\omega} Centauri, the brightest and largest\nglobular cluster in the Milky Way, and our results demonstrate that the\nluminosity function of metal-poor globular clusters is not universal. The\nfraction of the total stellar mass that is in the globular cluster system is\nsimilar to that in other UDGs, and consistent with \"failed galaxy\" scenarios\nwhere star formation terminated shortly after the clusters were formed.\nHowever, the galaxy is a factor of ~1000 removed from the relation between\nglobular cluster mass and total galaxy mass that has been found for other\ngalaxies, including other UDGs. We infer that a dark matter halo is not a\nprerequisite for the formation of metal-poor globular cluster-like objects in\nhigh redshift galaxies. \n\n"}
{"id": "1803.10764", "contents": "Title: On the prospect of discovering `galaxy groups' through radio\n  observations Abstract: Observed steep mass scaling of radio power from the available high mass\nclusters has ruled out the prospect of detection of 'galaxy groups'. But, the\navailable simulations and observations of thermal emissions show that the\ngroups are merger prone, thus non-virialised, indicating better visibility in\nthe radio waves. Detection of radio emissions from them would help us to\nunderstand the scale-dependent particle acceleration mechanisms also groups can\nbe a unique laboratory to test the models of cosmic magnetism and canbe the\npotential source of WHIMs. So, we have modelled radio emissions from the\nsimulated structures using {\\sc{ENZO}}. We present a model for computing\nmagnetic field and for the first time, used the electron energy spectrum from\nboth the Fermi I (DSA) and Fermi II (TRA) mechanisms to compute radio\nemissions. Computed radio power from more than 200 simulated objects, mass\nranging $\\geq 10^{13}$ to $2\\times 10^{15} M_{\\odot}$ show a new mass scaling\nof $M_{500} \\propto P_{1.4\\;GHz}^{2.17\\pm 0.08}$ and a strong correlation scale\nof $L_X \\propto P_{1.4\\;GHz}^{1.08\\pm 0.05}$. Both magnetic field and radio\npower are shown to have adequately replicated the available observations at\nhigh mass, allowing us to extend the results to further smaller masses. We\nreport that groups below $10^{14}\\;\\rm{M_{\\odot}}$ show the existence of 10s of\nnano to a sub-$\\mu$G magnetic field and about 10$^{19-23}$ W Hz$^{-1}$ of radio\npower, much higher than what existing mass scaling predicts. We found that the\ncombined radio power from TRA and DSA electrons can only fit very well to all\nthe observed `radio halos'. Finally, we have implemented this model on a real\ndata set obtained from the Sloan Digital Sky Survey (SDSS). It predicts about\n10s to 100s $\\mu$Jy/(10$\\arcsec$ beam) of radio flux in groups indicating their\ndetectability with existing and aplenty with the future radio telescopes. \n\n"}
{"id": "1804.00664", "contents": "Title: The Projected Dark and Baryonic Ellipsoidal Structure of 20 CLASH Galaxy\n  Clusters Abstract: We reconstruct the two-dimensional (2D) matter distributions in 20 high-mass\ngalaxy clusters selected from the CLASH survey by using the new approach of\nperforming a joint weak lensing analysis of 2D shear and azimuthally averaged\nmagnification measurements. This combination allows for a complete analysis of\nthe field, effectively breaking the mass-sheet degeneracy. In a Bayesian\nframework, we simultaneously constrain the mass profile and morphology of each\nindividual cluster assuming an elliptical Navarro-Frenk-White halo\ncharacterized by the mass, concentration, projected axis ratio, and position\nangle of the projected major axis.. We find that spherical mass estimates of\nthe clusters from azimuthally averaged weak-lensing measurements in previous\nwork are in excellent agreement with our results from a full 2D analysis.\nCombining all 20 clusters in our sample, we detect the elliptical shape of\nweak-lensing halos at the $5\\sigma$ significance level within a scale of\n2Mpc$/h$. The median projected axis ratio is $0.67\\pm 0.07$ at a virial mass of\n$M_\\mathrm{vir}=(15.2\\pm 2.8) \\times 10^{14} M_\\odot$, which is in agreement\nwith theoretical predictions of the standard collisionless cold dark matter\nmodel. We also study misalignment statistics of the brightest cluster galaxy,\nX-ray, thermal Sunyaev-Zel'dovich effect, and strong-lensing morphologies with\nrespect to the weak-lensing signal. Among the three baryonic tracers studied\nhere, we find that the X-ray morphology is best aligned with the weak-lensing\nmass distribution, with a median misalignment angle of $21\\pm 7$ degrees. We\nalso conduct a stacked quadrupole shear analysis assuming that the X-ray major\naxis is aligned with that of the projected mass distribution. This yields a\nconsistent axis ratio of $0.67\\pm 0.10$, suggesting again a tight alignment\nbetween the intracluster gas and dark matter. \n\n"}
{"id": "1804.01092", "contents": "Title: 21-cm Fluctuations from Charged Dark Matter Abstract: The epoch of the formation of the first stars, known as the cosmic dawn, has\nemerged as a new arena in the search for dark matter. In particular, the first\nclaimed 21-cm detection exhibits a deeper global absorption feature than\nexpected, which could be caused by a low baryonic temperature, and has been\ninterpreted as a sign for electromagnetic interactions between baryons and dark\nmatter. This hypothesis has a striking prediction: large temperature\nanisotropies sourced by the velocity-dependent cooling of the baryons. However,\nin order to remain consistent with the rest of cosmological observations, only\npart of the dark matter is allowed to be charged, and thus interactive. Here we\ncompute, for the first time, the 21-cm fluctuations caused by a charged\nsubcomponent of the dark matter, including both the pre- and post-recombination\nevolution of all fluids. We find that, for the same parameters that can explain\nthe anomalous 21-cm absorption signal, any percent-level fraction of charged\ndark matter would source novel 21-cm fluctuations with a unique acoustic\nspectrum, and with an amplitude above any other known effects. These\nfluctuations are uncorrelated with the usual adiabatic anisotropies, and would\nbe observable at high significance with interferometers such as LOFAR and HERA,\nthus providing a novel probe of dark matter at cosmic dawn. \n\n"}
{"id": "1804.01564", "contents": "Title: Optical Detection of Star Formation in a Cold Dust Cloud in the\n  Counterjet Direction of Centaurus A Abstract: We identify optical emission-line features 700\" (12 kpc) southwest of the\nnucleus of Centaurus A, roughly opposite the radio jet and well-known optical\nemission filaments associated with the northern radio structure. These regions\nare spatially associated with far-infrared emission peaks in a cold dust cloud\nidentified using Herschel and Spitzer data, and there may be a mismatch between\nthe low temperature of the dust and the expected heating effect of young stars.\nWe use integral-field optical spectroscopy to trace the ratios of strong\nemission lines. Their ratios are consistent with photoionization in normal H II\nregions, by modest numbers of OB stars; they must be obscured along our line of\nsight. The location raises the question of whether this star-forming episode\nwas enhanced or triggered by an outflow from the central parts of Centaurus A.\nOptical emission-line ratios and line widths limit the role of shocks on the\ngas, so any interaction with an outflow, either from the radio source or star\nformation in the gas-rich disk, can at most have compressed the gas weakly. We\nspeculate that the presence of similar star-forming regions on both sides of\nthe galaxy, contrasted with the difference in the character of the\nemission-line clouds, reflects the presence of a collimated radio jet to the\nnortheast and perhaps anisotropic escape of ionizing radiation from the AGN.\nStar formation on the southwestern side of Cen A could be enhanced by a broad\noutflow, distinct from the radio jet and lobes. (abridged) \n\n"}
{"id": "1804.01991", "contents": "Title: Halometry from Astrometry Abstract: Halometry---mapping out the spectrum, location, and kinematics of nonluminous\nstructures inside the Galactic halo---can be realized via variable weak\ngravitational lensing of the apparent motions of stars and other luminous\nbackground sources. Modern astrometric surveys provide unprecedented positional\nprecision along with a leap in the number of cataloged objects. Astrometry thus\noffers a new and sensitive probe of collapsed dark matter structures over a\nwide mass range, from one millionth to several million solar masses. It opens\nup a window into the spectrum of primordial curvature fluctuations with\ncomoving wavenumbers between $5~\\text{Mpc}^{-1}$ and $10^5~\\text{Mpc}^{-1}$,\nscales hitherto poorly constrained. We outline detection strategies based on\nthree classes of observables---multi-blips, templates, and correlations---that\ntake advantage of correlated effects in the motion of many background light\nsources that are produced through time-domain gravitational lensing. While\nexisting techniques based on single-source observables such as outliers and\nmono-blips are best suited for point-like lens targets, our methods offer\nparametric improvements for extended lens targets such as dark matter subhalos.\nMulti-blip lensing events may also unveil the existence, location, and mass of\nplanets in the outer reaches of the Solar System, where they would likely have\nescaped detection by direct imaging. \n\n"}
{"id": "1804.04079", "contents": "Title: All-sky RR Lyrae Stars in the Gaia Data Abstract: The second Gaia data release is expected to contain data products from about\n22 months of observation. Based on these data, we aim to provide an advance\npublication of a full-sky Gaia map of RR Lyrae stars. Although comprehensive,\nthese data still contain a significant fraction of sources which are\ninsufficiently sampled for Fourier series decomposition of the periodic light\nvariations. The challenges in the identification of RR Lyrae candidates with\n(much) fewer than 20 field-of-view transits are described. General\nconsiderations of the results, their limitations, and interpretation are\npresented together with prospects for improvement in subsequent Gaia data\nreleases. \n\n"}
{"id": "1804.05866", "contents": "Title: The Aemulus Project II: Emulating the Halo Mass Function Abstract: Existing models for the dependence of the halo mass function on cosmological\nparameters will become a limiting source of systematic uncertainty for cluster\ncosmology in the near future. We present a halo mass function emulator and\ndemonstrate improved accuracy relative to state-of-the-art analytic models. In\nthis work, mass is defined using an overdensity criteria of 200 relative to the\nmean background density. Our emulator is constructed from the AEMULUS\nsimulations, a suite of 40 N-body simulations with snapshots from z=3 to z=0.\nThese simulations cover the flat wCDM parameter space allowed by recent Cosmic\nMicrowave Background, Baryon Acoustic Oscillation and Type Ia Supernovae\nresults, varying the parameters w, Omega_m, Omega_b, sigma_8, N_{eff}, n_s, and\nH_0. We validate our emulator using five realizations of seven different\ncosmologies, for a total of 35 test simulations. These test simulations were\nnot used in constructing the emulator, and were run with fully independent\ninitial conditions. We use our test simulations to characterize the modeling\nuncertainty of the emulator, and introduce a novel way of marginalizing over\nthe associated systematic uncertainty. We confirm non-universality in our halo\nmass function emulator as a function of both cosmological parameters and\nredshift. Our emulator achieves better than 1% precision over much of the\nrelevant parameter space, and we demonstrate that the systematic uncertainty in\nour emulator will remain a negligible source of error for cluster abundance\nstudies through at least the LSST Year 1 data set. \n\n"}
{"id": "1804.06920", "contents": "Title: Errors, chaos and the collisionless limit Abstract: We simultaneously study the dynamics of the growth of errors and the question\nof the faithfulness of simulations of $N$-body systems. The errors are\nquantified through the numerical reversibility of small-$N$ spherical systems,\nand by comparing fixed-timestep runs with different stepsizes. The errors add\nrandomly, before exponential divergence sets in, with exponentiation rate\nvirtually independent of $N$, but scale saturating as $\\sim 1/\\sqrt{N}$, in\nline with theoretical estimates presented. In a third phase, the growth rate is\ninitially driven by multiplicative enhancement of errors, as in the exponential\nstage. It is then qualitatively different for the phase space variables and\nmean field conserved quantities (energy and momentum); for the former, the\nerrors grow systematically through phase mixing, for the latter they grow\ndiffusively. For energy, the $N$-variation of the `relaxation time' of error\ngrowth follows the $N$-scaling of two-body relaxation. This is also true for\nangular momentum in the fixed stepsize runs, although the associated error\nthreshold is higher and the relaxation time smaller. Due to shrinking\nsaturation scales, the information loss associated with the exponential\ninstability decreases with $N$ and the dynamical entropy vanishes at any finite\nresolution as $N \\rightarrow \\infty$. A distribution function depending on the\nintegrals of motion in the smooth potential is decreasingly affected. In this\nsense there is convergence to the collisionless limit, despite the persistence\nof exponential instability on infinitesimal scales. Nevertheless, the slow\n$N$-variation in its saturation points to the slowness of the convergence. \n\n"}
{"id": "1804.07261", "contents": "Title: MontePython 3: boosted MCMC sampler and other features Abstract: MontePython is a parameter inference package for cosmology. We present the\nlatest development of the code over the past couple of years. We explain, in\nparticular, two new ingredients both contributing to improve the performance of\nMetropolis-Hastings sampling: an adaptation algorithm for the jumping factor,\nand a calculation of the inverse Fisher matrix, which can be used as a proposal\ndensity. We present several examples to show that these features speed up\nconvergence and can save many hundreds of CPU-hours in the case of difficult\nruns, with a poor prior knowledge of the covariance matrix. We also summarise\nall the functionalities of MontePython in the current release, including new\nlikelihoods and plotting options. \n\n"}
{"id": "1804.08061", "contents": "Title: Effects of NII and H$\\alpha$ Line Blending on the WFIRST Galaxy Redshift\n  Survey Abstract: The Wide Field Infrared Survey Telescope (WFIRST) will conduct a galaxy\nredshift survey using the H$\\alpha$ emission line primarily for spectroscopic\nredshift determination. Due to the modest spectroscopic resolution of the\ngrism, the H$\\alpha$ and the neighboring [NII] lines are blended, leading to a\nredshift bias that depends on the [NII]/H$\\alpha$ ratio, which is correlated\nwith a galaxy's metallicity, hence mass and ultimately environment. We\ninvestigate how this bias propagates into the galaxy clustering and\ncosmological parameters obtained from the WFIRST. Using simulation, we explore\nthe effect of line blending on redshift-space distortion and baryon acoustic\noscillation (BAO) measurements. We measure the BAO parameters\n$\\alpha_{\\parallel}$, $\\alpha_{\\perp}$, the logarithmic growth factor $f_{v}$,\nand calculate their errors based on the correlations between the line ratio and\nlarge-scale structure. We find $\\Delta\\alpha_{\\parallel} = 0.31 \\pm 0.23 \\%$\n($0.26\\pm0.17\\%$), $\\Delta\\alpha_{\\perp} = -0.10\\pm0.10\\%$ ($-0.12 \\pm 0.11\n\\%$), and $\\Delta f_{v} = 0.17\\pm0.33\\%$ ($-0.20 \\pm 0.30\\%$) for redshift\n1.355--1.994 (0.700--1.345), which use approximately 18$\\%$, 9$\\%$, and 7$\\%$\nof the systematic error budget in a root-sum-square sense. These errors may\nalready be tolerable but further mitigations are discussed. Biases due to the\nenvironment-independent redshift error can be mitigated by measuring the\nredshift error probability distribution function. High-spectral-resolution\nre-observation of a few thousand galaxies would be required (if by direct\napproach) to reduce them to below 25$\\%$ of the error budget. Finally, we\noutline the next steps to improve the modeling of [NII]-induced blending biases\nand their interaction with other redshift error sources. \n\n"}
{"id": "1804.08581", "contents": "Title: The Radio Background Below 100 MHz Abstract: The recent detection of the \"cosmic dawn\" redshifted 21 cm signal at 78 MHz\nby the EDGES experiment differs significantly from theoretical predictions. In\nparticular, the absorption trough is roughly a factor of two stronger than the\nmost optimistic theoretical models. The early interpretations of the origin of\nthis discrepancy fall into two categories. The first is that there is increased\ncooling of the gas due to interactions with dark matter, while the second is\nthat the background radiation field includes a contribution from a component in\naddition to the cosmic microwave background. In this paper we examine the\nfeasibility of the second idea using new data from the first station of the\nLong Wavelength Array. The data span 40 to 80 MHz and provide important\nconstraints on the present-day background in a frequency range where there are\nfew surveys with absolute temperature calibration suitable for measuring the\nstrength of the radio monopole. We find support for a strong, diffuse radio\nbackground that was suggested by the ARCARDE 2 results in the 3 to 10 GHz\nrange. We find that this background is well modeled by a power law with a\nspectral index of $-$2.58$\\pm$0.05 and a temperature at the rest frame 21 cm\nfrequency of 603$^{+102}_{-92}$ mK. \n\n"}
{"id": "1804.10401", "contents": "Title: A Technique for Estimating the Absolute Gain of a Photomultiplier Tube Abstract: Detection of low-intensity light relies on the conversion of photons to\nphotoelectrons, which are then multiplied and detected as an electrical signal.\nTo measure the actual intensity of the light, one must know the factor by which\nthe photoelectrons have been multiplied. To obtain this amplification factor,\nwe have developed a procedure for estimating precisely the signal caused by a\nsingle photoelectron. The method utilizes the fact that the photoelectrons\nconform to a Poisson distribution. The average signal produced by a single\nphotoelectron can then be estimated from the number of noise events, without\nrequiring analysis of the distribution of the signal produced by a single\nphotoelectron. The signal produced by one or more photoelectrons can be\nestimated experimentally without any assumptions. This technique, and an\nexample of the analysis of a signal from a photomultiplier tube, are described\nin this study. \n\n"}
{"id": "1804.11028", "contents": "Title: IMAGINE: Testing a Bayesian pipeline for Galactic Magnetic Field model\n  optimization Abstract: This work contains the details and results of my master's project on testing\nthe IMAGINE pipeline for Galactic magnetic field estimation. The project was\ncarried out from early 2016 to early 2017. For it, an unpublished early\ndevelopment version of the IMAGINE pipeline was tested and debugged. The thesis\nreports about the kind of difficulties faced when dealing with high dimensional\ncomplex parametric Galactic magnetic field models. It was found that such\nmodels require extra caution to allow for dependencies between parameters and\nmodel implementation errors, which need to be taken into account when\nperforming a Bayesian analysis. These findings, reported here in this thesis,\nhelped to resolve such issues in the later, now published version of the\nIMAGINE pipeline. The thesis therefore documents the genesis of the pipeline\nand lessons learned during this process. This document contains original text\nof the master thesis for reference. Parts of its content therefore do not\nreflect the current state of the IMAGINE pipeline. \n\n"}
{"id": "1805.00562", "contents": "Title: Studying galaxy troughs and ridges using Weak Gravitational Lensing with\n  the Kilo-Degree Survey Abstract: We study projected underdensities in the cosmic galaxy density field known as\n'troughs', and their overdense counterparts, which we call 'ridges'. We\nidentify these regions using a bright sample of foreground galaxies from the\nphotometric Kilo-Degree Survey (KiDS), specifically selected to mimic the\nspectroscopic Galaxy And Mass Assembly survey (GAMA). Using background galaxies\nfrom KiDS, we measure the weak gravitational lensing profiles of the\ntroughs/ridges. We quantify the amplitude of their lensing strength $A$ as a\nfunction of galaxy density percentile rank $P$ and galaxy overdensity $\\delta$,\nand find that the skewness in the galaxy density distribution is reflected in\nthe total mass distribution measured by weak lensing. We interpret our results\nusing the mock galaxy catalogue from the Marenostrum Institut de Ci\\`encies de\nl'Espai (MICE) simulation, and find a good agreement with our observations.\nUsing signal-to-noise weights derived from the Scinet LIghtCone Simulations\n(SLICS) mock catalogue we optimally stack the lensing signal of KiDS troughs\nwith an angular radius $\\theta_A$ = {5,10,15,20} arcmin, resulting in\n{16.8,14.9,10.13,7.55} $\\sigma$ detections. Finally, we select troughs using a\nvolume-limited sample of galaxies, split into two redshift bins between 0.1 < z\n< 0.3. For troughs/ridges with transverse comoving radius $R_A$ = 1.9 Mpc/h, we\nfind no significant difference in the comoving Excess Surface Density as a\nfunction of $P$ and $\\delta$ between the low- and high-redshift sample. Using\nthe MICE and SLICS mocks we predict that trough and ridge evolution could be\ndetected with gravitational lensing using deeper and wider lensing surveys,\nsuch as those from the Large Synoptic Survey Telescope and Euclid. \n\n"}
{"id": "1805.04490", "contents": "Title: The C-Band All-Sky Survey (C-BASS): Design and capabilities Abstract: The C-Band All-Sky Survey (C-BASS) is an all-sky full-polarisation survey at\na frequency of 5 GHz, designed to provide complementary data to the all-sky\nsurveys of WMAP and Planck, and future CMB B-mode polarization imaging surveys.\nThe observing frequency has been chosen to provide a signal that is dominated\nby Galactic synchrotron emission, but suffers little from Faraday rotation, so\nthat the measured polarization directions provide a good template for higher\nfrequency observations, and carry direct information about the Galactic\nmagnetic field. Telescopes in both northern and southern hemispheres with\nmatched optical performance are used to provide all-sky coverage from a\nground-based experiment. A continuous-comparison radiometer and a correlation\npolarimeter on each telescope provide stable imaging properties such that all\nangular scales from the instrument resolution of 45 arcmin up to full sky are\naccurately measured. The northern instrument has completed its survey and the\nsouthern instrument has started observing. We expect that C-BASS data will\nsignificantly improve the component separation analysis of Planck and other CMB\ndata, and will provide important constraints on the properties of anomalous\nGalactic dust and the Galactic magnetic field. \n\n"}
{"id": "1805.05266", "contents": "Title: Advanced Gain Calibration Techniques in Radio Interferometry Abstract: In this lecture, we describe a number of advanced gain calibration\ntechniques. In particular, self-calibration is an important tool in\ninterferometric imaging at all wavelengths. It allows the observer to determine\nand remove residual phase and amplitude errors that remain in the data after\nnormal calibration while simultaneously producing a more accurate and more\nsensitive image of the target source. We describe the basic technique of\nself-calibration and attempt to dispel some common misconceptions. We proceed\nto give a range of useful tips, and provide continuum, spectral line, and\nmosaic self-calibration examples using ALMA data. We also discuss fast\nswitching and radiometric phase correction along with advanced phase transfer\ntechniques that can become advantageous or even essential at high frequency\nwhere the density of sufficiently bright phase calibrators becomes sparse. \n\n"}
{"id": "1805.06073", "contents": "Title: Backgrounds in the DEAP-3600 Dark Matter Experiment Abstract: The DEAP-3600 experiment, located at SNOLAB, is searching for dark matter\nwith a single phase liquid argon (LAr) target. For a background-free exposure\nof 3000 kg$\\cdot$yr, the projected sensitivity to the spin-independent\nWIMP-nucleon cross section at 100 GeV/c$^2$ WIMP mass is 10$^{-46}$ cm$^{2}$.\n  The experimental signature of dark matter interactions is keV-scale argon\nrecoils producing 128 nm LAr scintillation photons which are wavelength shifted\nand observed by 255 PMTs. To reach the large background-free exposure, a\ncombination of careful material selection, passive shielding, active vetoes,\nfiducialization and pulse shape discrimination (PSD) is used. The main concept\nof the background rejection in DEAP-3600 is the powerful PSD, employing the\nlarge difference between fast and slow components of LAr scintillation light.\nThe designed background level of DEAP-3600 is less than 0.6 events in a 3000\nkg$\\cdot$yr exposure. The experiment was filled in November 2016 and is\ncurrently taking dark matter search data. \n\n"}
{"id": "1805.06711", "contents": "Title: Estimating Sky Level Abstract: We develop an improved sky background estimator which employs optimal filters\nfor both spatial and pixel intensity distributions. It incorporates growth of\nmasks around detected objects and a statistical estimate of the flux from\nundetected faint galaxies in the remaining sky pixels. We test this algorithm\nfor underlying sky estimation and compare its performance with commonly used\nsky estimation codes on realistic simulations which include detected galaxies,\nfaint undetected galaxies, and sky noise. We then test galaxy surface\nbrightness recovery using GALFIT 3, a galaxy surface brightness profile fitting\noptimizer, yielding fits to S\\'{e}rsic profiles. This enables robust sky\nbackground estimates accurate at the 4 parts-per-million level. This background\nsky estimator is more accurate and is less affected by surface brightness\nprofiles of galaxies and the local image environment compared with other\nmethods. \n\n"}
{"id": "1805.06799", "contents": "Title: Radio Galaxy Shape Measurement with Hamiltonian Monte Carlo in the\n  Visibility Domain Abstract: Radio weak lensing, while a highly promising complementary probe to optical\nweak lensing, will require incredible precision in the measurement of galaxy\nshape parameters. In this paper, we extend the Bayesian Inference for Radio\nObservations model fitting approach to measure galaxy shapes directly from\nvisibility data of radio continuum surveys, instead of from image data. We\napply a Hamiltonian Monte Carlo (HMC) technique for sampling the posterior,\nwhich is more efficient than the standard Monte Carlo Markov Chain method when\ndealing with a large dimensional parameter space. Adopting the exponential\nprofile for galaxy model fitting allows us to analytically calculate the\nlikelihood gradient required by HMC, allowing a faster and more accurate\nsampling. The method is tested on SKA1-MID simulated observations at 1.4 GHz of\na field containing up to 1000 star-forming galaxies. It is also applied to a\nsimulated observation of the weak lensing precursor survey SuperCLASS. In both\ncases we obtain reliable measurements of the galaxies' ellipticity and size for\nall sources with SNR $\\ge 10$, and we also find relationships between the\nconvergence properties of the HMC technique and some source parameters. Direct\nshape measurement in the visibility domain achieves high accuracy at the\nexpected source number densities of the current and next SKA precursor\ncontinuum surveys. The proposed method can be easily extended for the fitting\nof other galaxy and scientific parameters, as well as simultaneously\nmarginalising over systematic and instrumental effects. \n\n"}
{"id": "1805.06807", "contents": "Title: Cosmological perturbations in conformal gravity II Abstract: In this paper we continue a study of cosmological perturbations in the\nconformal gravity theory. In previous work we had obtained a restricted set of\nsolutions to the cosmological fluctuation equations, solutions that were\nrequired to be both transverse and synchronous. Here we present the general\nsolution. We show that in a conformal invariant gravitational theory\nfluctuations around any background that is conformal to flat (backgrounds that\ninclude the cosmologically interesting Robertson-Walker and de Sitter\ngeometries) can be constructed from the (known) solutions to fluctuations\naround a flat background. For this construction to hold it is not necessary\nthat the perturbative geometry associated with the fluctuations itself be\nconformal to flat. Using this construction we show that in a conformal\nRobertson-Walker cosmology early universe fluctuations grow as $t^4$. We\npresent the scalar, vector, tensor decomposition of the fluctuations in the\nconformal theory, and compare and contrast our work with the analogous\ntreatment of fluctuations in the standard Einstein gravity theory. \n\n"}
{"id": "1805.07278", "contents": "Title: Implications of Minimum and Maximum Length Scales in Cosmology Abstract: We investigate the cosmological implications of the generalized and extended\nuncertainty principle (GEUP), and whether it could provide an explanation for\nthe dark energy. The consequence of the GEUP is the existence of a minimum and\na maximum length, which can in turn modify the entropy area law and also modify\nthe Friedmann equation. The cosmological consequences are studied by paying\nparticular attention to the role of these lengths. We find that the theory\nallows a cosmological evolution where the radiation- and matter-dominated\nepochs are followed by a long period of virtually constant dark energy, that\nclosely mimics the $\\Lambda$CDM model. The main cause of the current\nacceleration arises from the maximum length scale $\\beta$, governed by the\nrelation $\\Lambda\\sim -\\beta^{-1}W(-\\beta^{-1})$. Using recent observational\ndata (the Hubble parameters, type Ia supernovae, and baryon acoustic\noscillations, together with the Planck or WMAP 9-year data of the cosmic\nmicrowave background radiation), we estimate constraints to the minimum length\nscale $\\alpha \\lesssim 10^{81}$ and the maximum length scale $\\beta \\sim\n-10^{-2}$. \n\n"}
{"id": "1805.08379", "contents": "Title: The Effective J-Factor of the Galactic Center for Velocity-Dependent\n  Dark Matter Annihilation Abstract: We present the effective $J$-factors for the Milky Way for scenarios in which\ndark matter annihilation is p-wave or d-wave suppressed. We find that the\nvelocity suppression of dark matter annihilation can have a sizable effect on\nthe morphology of a potential dark matter annihilation signal in the Galactic\nCenter. The gamma-ray flux from the innermost region of the Galactic Center is\nin particular suppressed. We find that for dark matter density profiles with\nsteep inner slopes, the morphology of the Inner Galaxy gamma-ray emission in\np-wave models can be made similar to the morphology in standard s-wave models.\nThis similarity may suggest that model discrimination between s-wave and p-wave\nis challenging, for example, when fitting the Galactic Center excess. However,\nwe show that it is difficult to simultaneously match s- and p-wave morphologies\nat both large and small angular scales. The $J$-factors we calculate may be\nimplemented with astrophysical foreground models to self-consistently determine\nthe morphology of the excess with velocity-suppressed dark matter annihilation. \n\n"}
{"id": "1805.10001", "contents": "Title: The DAMIC experiment at SNOLAB Abstract: The DAMIC (Dark Matter in CCDs) experiment at the SNOLAB underground\nlaboratory uses fully depleted, high resistivity CCDs to search for dark matter\nparticles with masses below 10 GeV/c$^2$. An upgrade of the detector using an\narray of seven 16-Mpixel CCDs (40 g of mass) started operation in February\n2017. The new results, obtained with the current detector configuration, will\nbe presented. Future plans for DAMIC-M, with a total mass of 1kg and a\nionization threshold of 2 electrons, will be discussed. \n\n"}
{"id": "1805.12186", "contents": "Title: The relative impact of baryons and cluster shape on weak lensing mass\n  estimates of galaxy clusters Abstract: Weak gravitational lensing depends on the integrated mass along the line of\nsight. Baryons contribute to the mass distribution of galaxy clusters and the\nresulting mass estimates from lensing analysis. We use the cosmo-OWLS suite of\nhydrodynamic simulations to investigate the impact of baryonic processes on the\nbias and scatter of weak lensing mass estimates of clusters. These estimates\nare obtained by fitting NFW profiles to mock data using MCMC techniques. In\nparticular, we examine the difference in estimates between dark matter-only\nruns and those including various prescriptions for baryonic physics. We find no\nsignificant difference in the mass bias when baryonic physics is included,\nthough the overall mass estimates are suppressed when feedback from AGN is\nincluded. For lowest-mass systems for which a reliable mass can be obtained\n($M_{200} \\approx 2 \\times 10^{14}$ $M_{\\odot}$), we find a bias of $\\approx\n-10$ per cent. The magnitude of the bias tends to decrease for higher mass\nclusters, consistent with no bias for the most massive clusters which have\nmasses comparable to those found in the CLASH and HFF samples. For the lowest\nmass clusters, the mass bias is particularly sensitive to the fit radii and the\nlimits placed on the concentration prior, rendering reliable mass estimates\ndifficult. The scatter in mass estimates between the dark matter-only and the\nvarious baryonic runs is less than between different projections of individual\nclusters, highlighting the importance of triaxiality. \n\n"}
{"id": "1805.12436", "contents": "Title: KiDS-SQuaD: The KiDS Strongly lensed Quasar Detection project Abstract: New methods have been recently developed to search for strong gravitational\nlenses, in particular lensed quasars, in wide-field imaging surveys. Here, we\ncompare the performance of three different, morphology- and photometry- based\nmethods to find lens candidates over the Kilo-Degree Survey (KiDS) DR3\nfootprint (440 deg$^2$). The three methods are: i) a multiplet detection in\nKiDS-DR3 and/or Gaia-DR1, ii) direct modeling of KiDS cutouts and iii)\npositional offsets between different surveys (KiDS-vs-Gaia, Gaia-vs-2MASS),\nwith purpose-built astrometric recalibrations. The first benchmark for the\nmethods has been set by the recovery of known lenses. We are able to recover\nseven out of ten known lenses and pairs of quasars observed in the KiDS DR3\nfootprint, or eight out of ten with improved selection criteria and looser\ncolour pre-selection. This success rate reflects the combination of all methods\ntogether, which, taken individually, performed significantly worse (four lenses\neach). One movelty of our analysis is that the comparison of the performances\nof the different methods has revealed the pros and cons of the approaches and,\nmost of all, the complementarities. We finally provide a list of high-grade\ncandidates found by one or more methods, awaiting spectroscopic follow-up for\nconfirmation. Of these, KiDS 1042+0023 is to our knowledge the first confirmed\nlensed quasar from KiDS, exhibiting two quasar spectra at the same source\nredshift at either sides of a red galaxy, with uniform flux-ratio\n$f\\approx1.25$ over the wavelength range\n$0.45\\mu\\mathrm{m}<\\lambda<0.75\\mu\\mathrm{m}.$ \n\n"}
{"id": "1805.12562", "contents": "Title: Dark Matter Search Results from a One Tonne$\\times$Year Exposure of\n  XENON1T Abstract: We report on a search for Weakly Interacting Massive Particles (WIMPs) using\n278.8 days of data collected with the XENON1T experiment at LNGS. XENON1T\nutilizes a liquid xenon time projection chamber with a fiducial mass of $(1.30\n\\pm 0.01)$ t, resulting in a 1.0 t$\\times$yr exposure. The energy region of\ninterest, [1.4, 10.6] $\\mathrm{keV_{ee}}$ ([4.9, 40.9] $\\mathrm{keV_{nr}}$),\nexhibits an ultra-low electron recoil background rate of $(82\\substack{+5 \\\\\n-3}\\textrm{ (sys)}\\pm3\\textrm{ (stat)})$\nevents/$(\\mathrm{t}\\times\\mathrm{yr}\\times\\mathrm{keV_{ee}})$. No significant\nexcess over background is found and a profile likelihood analysis parameterized\nin spatial and energy dimensions excludes new parameter space for the\nWIMP-nucleon spin-independent elastic scatter cross-section for WIMP masses\nabove 6 GeV/c${}^2$, with a minimum of $4.1\\times10^{-47}$ cm$^2$ at 30\nGeV/c${}^2$ and 90% confidence level. \n\n"}
{"id": "1806.00270", "contents": "Title: A Proper Motions Study of the Globular Cluster M12 (NGC 6218) Abstract: Using astrometric techniques developed by Anderson et al., we determine\nproper motions (PMs) in 14.60 arcmin X 16.53 arcmin area of the kinematically\n\"thick-disk\" globular cluster M12. The cluster's proximity and sparse nature\nmakes it a suitable target for ground-based telescopes. Archive images with\ntime gap of 11.1 years were observed with wide-field imager (WFI) mosaic camera\nmounted on ESO 2.2 m telescope. The median value of PM error in both components\nis 0.7 mas/yr for the stars having V less than or equal to 20 mag. PMs are used\nto determine membership probabilities and to separate field stars from the\ncluster sample. In electronic form, a membership catalog of 3725 stars with\nprecise coordinates, PMs, BVRI photometry is being provided. One of the\npossible applications of the catalog was shown by gathering the membership\ninformation of the variable stars, blue stragglers and X-ray sources reported\nearlier in the cluster's region. \n\n"}
{"id": "1806.02276", "contents": "Title: Galactic planetary nebulae as probes of radial metallicity gradients and\n  other abundance patterns Abstract: We use planetary nebulae (PNe) as probes to determine the Galactic radial\noxygen gradients, and other abundance patterns. We select data homogeneously\nfrom recent data sets, including PNe at large Galactocentric distances. The\nradial oxygen gradient calculated for the general PN population, which probes\nthe region between the Galactic center and out to $\\sim$28 kpc, is shallow,\nwith slope $\\sim$-0.02 dex kpc$^{-1}$, in agreement with previous findings. We\nlooked for time evolution of the metallicity gradient using PNe with different\nage progenitors as metallicity probes. We identify PNe whose progenitor stars\nare younger than 1 Gyr (YPPNe), and those whose progenitor stars are older than\n7.5 Gyr (OPPNe), based on the comparison between evolutionary yields and\nelemental abundances of the PNe. By studying OPPNe and YPPNe separately we\nfound that: (i) The OPPNe oxygen gradient is shallower ($\\sim-0.015$ dex\nkpc$^{-1}$) than that derived from YPPNe ($\\sim-0.027$ dex kpc$^{-1}$); (ii)\nthe OPPNe inner radial distribution of oxygen is compatible with no gradient to\nthe radial extent of the thick disk population ($\\sim$10 kpc), similarly to\nwhat has been observed in thick disk stars; (iii) planetary nebulae (especially\nOPPNe) indicate that significant gradient slope is limited to Galactocentric\ndistances between $\\sim$10 to $\\sim$13.5 kpc, as observed for open clusters and\nfield stars. Outside this range, the distribution is almost flat. We found that\nthe radial oxygen gradient is steeper for a PN population closer to the\nGalactic disk, similarly to what is observed in the general stellar population\nby the SEGUE survey. We use our novel population dating to compare our results\nwith current chemical evolutionary models, and with gradients from other\nGalactic populations, for insight on galaxy chemical evolution. \n\n"}
{"id": "1806.02500", "contents": "Title: Multi-wavelength observations of cosmological phase transitions using\n  LISA and Cosmic Explorer Abstract: We reanalyze the detection possibilities for gravitational waves arising from\ncosmological first order phase transitions. We discuss the stochastic\ngravitational wave background corresponding to the three expected scenarios of\nphase transition dynamics. We then perform an analysis on the detection\npossibilities for each case using sensitivities for the next generation\nground-based detector Cosmic Explorer and the current LISA proposal, using two\nanalysis methods. We find that having both detectors allows wide detection\npossibilities over much of the parameter space, including that corresponding to\nseveral points relevant to different early Universe models. \n\n"}
{"id": "1806.05193", "contents": "Title: An ALMA survey of CO in submillimetre galaxies: companions, triggering,\n  and the environment in blended sources Abstract: We present ALMA observations of the mid-J 12CO emission from six single-dish\nselected 870-micron sources in the Extended Chandra Deep Field-South (ECDFS)\nand UKIDSS Ultra-Deep Survey (UDS) fields. These six single-dish submillimetre\nsources were selected based on previous ALMA continuum observations, which\nshowed that each comprised a blend of emission from two or more individual\nsubmillimetre galaxies (SMGs), separated on 5--10 arcsec scales. The six\nsingle-dish submillimetre sources targeted correspond to a total of 14\nindividual SMGs, of which seven have previously-measured robust\noptical/near-infrared spectroscopic redshifts, which were used to tune our ALMA\nobservations. We detect CO(3-2) or CO(4-3) at z=2.3--3.7 in seven of the 14\nSMGs, and in addition serendipitously detect line emission from three gas-rich\ncompanion galaxies, as well as identify four new 3.3-mm selected continuum\nsources in the six fields. Joint analysis of our CO spectroscopy and existing\ndata suggests that 64 \\pm 18% of the SMGs in blended submillimetre sources are\nunlikely to be physically associated. However, three of the SMG fields (50%)\ncontain new, serendipitously-detected CO-emitting (but submillimetre-faint)\nsources at similar redshifts to the 870-micron selected SMGs we targeted. These\ndata suggest that the SMGs inhabit overdense regions, but that these are not\nsufficiently overdense on ~100 kpc scales to influence the source blending\ngiven the short lifetimes of SMGs. We find that 21 \\pm 12% of SMGs have\nspatially-distinct and kinematically-close companion galaxies (~8--150 kpc and\n<~300 km/s), which may have enhanced their star-formation via gravitational\ninteractions. \n\n"}
{"id": "1806.06979", "contents": "Title: Proving the short-wavelength approximation in Pulsar Timing Array\n  gravitational-wave background searches Abstract: A low-frequency gravitational-wave background (GWB) from the cosmic merger\nhistory of supermassive black holes is expected to be detected in the next few\nyears by pulsar timing arrays. A GWB induces distinctive correlations in the\npulsar residuals --- the expected arrival time of the pulse less its actual\narrival time. Simplifying assumptions are made in order to write an analytic\nexpression for this correlation function, called the Hellings and Downs curve\nfor an isotropic GWB, which depends on the angular separation of the pulsar\npairs, the gravitational-wave frequency considered, and the distance to the\npulsars. This is called the short-wavelength approximation, which we prove here\nrigorously and analytically for the first time. \n\n"}
{"id": "1806.07390", "contents": "Title: Fornax: a Flexible Code for Multiphysics Astrophysical Simulations Abstract: This paper describes the design and implementation of our new multi-group,\nmulti-dimensional radiation hydrodynamics (RHD) code Fornax and provides a\nsuite of code tests to validate its application in a wide range of physical\nregimes. Instead of focusing exclusively on tests of neutrino radiation\nhydrodynamics relevant to the core-collapse supernova problem for which Fornax\nis primarily intended, we present here classical and rigorous demonstrations of\ncode performance relevant to a broad range of multi-dimensional hydrodynamic\nand multi-group radiation hydrodynamic problems. Our code solves the\ncomoving-frame radiation moment equations using the M1 closure, utilizes\nconservative high-order reconstruction, employs semi-explicit matter and\nradiation transport via a high-order time stepping scheme, and is suitable for\napplication to a wide range of astrophysical problems. To this end, we first\ndescribe the philosophy, algorithms, and methodologies of Fornax and then\nperform numerous stringent code tests, that collectively and vigorously\nexercise the code, demonstrate the excellent numerical fidelity with which it\ncaptures the many physical effects of radiation hydrodynamics, and show\nexcellent strong scaling well above 100k MPI tasks. \n\n"}
{"id": "1806.07394", "contents": "Title: The formation of high-mass binary star systems Abstract: We develop a semi-analytic model to investigate how accretion onto wide\nlow-mass binary stars can result in a close high-mass binary system. The key\ningredient is to allow mass accretion while limiting the gain in angular\nmomentum. We envision this process as being regulated by an external magnetic\nfield during infall. Molecular clouds are made to collapse spherically with\nmaterial either accreting onto the stars or settling in a disk. Our aim is to\ndetermine what initial conditions are needed for the resulting binary to be\nboth massive and close. Whether material accretes, and what happens to the\nbinary separation as a result, depends on the relative size of its specific\nangular momentum, compared to the specific angular momentum of the binary. When\nwe add a magnetic field we are introducing a torque to the system which is\ncapable of stripping the molecular cloud of some of its angular momentum, and\nconsequently easing the formation of high-mass binaries. Our results suggest\nthat clouds in excess of 1000 M$_\\odot$ and radii of 0.5 pc or larger, can\neasily form binary systems with masses in excess of 25 M$_\\odot$ and\nseparations of order 10 R$_\\odot$ with magnetic fields of order 100 {\\mu}G\n(mass-to-flux ratios of order 5). \n\n"}
{"id": "1806.08305", "contents": "Title: kima: Exoplanet detection in radial velocities Abstract: The radial-velocity (RV) method is one of the most successful in the\ndetection of exoplanets, but is hindered by the intrinsic RV variations of the\nstar, which can easily mimic or hide true planetary signals. kima is a package\nfor the detection and characterization of exoplanets using RV data. It fits a\nsum of Keplerian curves to a timeseries of RV measurements and calculates the\nevidence for models with a fixed number Np of Keplerian signals, or after\nmarginalising over Np. Moreover, kima can use a GP with a quasi-periodic kernel\nas a noise model, to deal with activity-induced signals. The hyperparameters of\nthe GP are inferred together with the orbital parameters. The code is written\nin C++, but includes a helper Python package, pykima, which facilitates the\nanalysis of the results. \n\n"}
{"id": "1806.09116", "contents": "Title: Testing Area of the SAGE Survey Abstract: Sky survey is one of the most important motivations to improve the\nastrophysics development, especially when using new photometric bands. We are\nperforming the SAGE (Stellar Abundance and Galactic Evolution) survey with a\nself-designed SAGE photometric system, which is composed of eight photometric\nbands. The project mainly aims to study the stellar atmospheric parameters of\n$\\sim$0.5 billion stars in the $\\sim12,000$ deg$^2$ of the northern sky, which\nmainly focuses on the Galactic sciences, as well as some extragalactic\nsciences. This work introduces the detailed data reduction process of the\ntesting field NGC\\,6791, including the data reduction of single-exposure image\nand stacking multi-exposure images, and properties of the final catalogue. \n\n"}
{"id": "1806.11360", "contents": "Title: Mapping Incoherent Gravitational Wave Backgrounds Abstract: Given the recent detection of gravitational waves from individual sources it\nis almost a certainty that some form of background of gravitational waves will\nbe detected in future. The most promising candidate for such a detection are\nbackgrounds made up of incoherent superposition of the signal of unresolved\nastrophysical or, backgrounds sourced by earlier cosmological events. Such\nbackgrounds will also contain anisotropies about an average value. The\ninformation contained in the background level and any anisotropies will be\nextremely valuable as an astrophysical and cosmological probe. As such, the\nability to reconstruct sky maps of the signal will become important as the\nsensitivity increases. We build and test a pixel--based, maximum--likelihood\nGravitational Wave Background (GWB) map-maker that uses the cross-correlation\nof sets of generalised baselines as input. The resulting maps are a\nrepresentation of the GWB power, or strain \"intensity\" on the sky. We test the\nalgorithm by reconstructing known input maps with different baseline\nconfigurations. We also apply the map-maker to a subset of the Advance LIGO\ndata. \n\n"}
{"id": "1807.00620", "contents": "Title: Strong Dynamics and Natural Inflation Abstract: We continue our investigation of the 4d effective field theory for closed\nstring axions in Type II compactifications with D-branes. The inclusion of\nSt\\\"uckelberg couplings for the axions requires the presence of chiral fermions\nat D-brane intersections, whose interactions at strong non-Abelian gauge\ncoupling induce mass terms for the axions and scalar chiral condensate\nexcitations, dubbed infladrons. The set-up allows for a realization of\nnatural-like inflation with a closed string axion as inflaton and a flattened\nscalar potential due to the back-reaction of the more massive infladrons. We\nfurther point out that this large field inflationary model is not compromised\nby axionic wormhole corrections. \n\n"}
{"id": "1807.01490", "contents": "Title: Intrinsic and observed dual AGN fractions from major mergers Abstract: A suite of 432 collisionless simulations of bound pairs of spiral galaxies\nwith mass ratios 1:1 and 3:1, and global properties consistent with the\n$\\Lambda$CDM paradigm, is used to test the conjecture that major mergers fuel\nthe dual AGN (DAGN) of the local volume. Our analysis is based on the premise\nthat the essential aspects of this scenario can be captured by replacing the\nphysics of the central BH with restrictions on their relative separation in\nphase space. We introduce several estimates of the DAGN fraction and infer\npredictions for the activity levels and resolution limits usually involved in\nsurveys of these systems, assessing their dependence on the parameters\ncontrolling the length of both mergers and nuclear activity. Given a set of\nconstraints, we find that the values adopted for some of the latter factors\noften condition the outcomes from individual experiments. Still, the results do\nnot reveal, in general, very tight correlations, being the tendency of the\nfrequencies normalized to the merger time to anticorrelate with the orbital\ncircularity the clearest effect. In agreement with other theoretical studies,\nour simulations predict intrinsic abundances of these systems that range from\n$\\sim$few to $15\\%$ depending on the maximum level of nuclear activity\nachieved. At the same time, we show that these probabilities are reduced by\nabout an order of magnitude when they are filtered with the typical constraints\napplied by observational studies of the DAGN fraction at low redshift. As a\nwhole, the results of the present work prove that the consideration of the most\ncommon limitations involved in the detection of close active pairs at optical\nwavelengths is sufficient by itself to reconcile the intrinsic frequencies\nenvisaged in a hierarchical universe with the small fractions of double-peaked\nnarrow-line systems which are often reported at kpc-scales. \n\n"}
{"id": "1807.01787", "contents": "Title: HST/WFPC2 imaging analysis and Cloudy modelling of the multiple shell\n  planetary nebulae NGC 3242, NGC 6826 and NGC 7662 Abstract: We performed a detailed photometric analysis and photoionisation modelling on\nthree high excitation multiple shell planetary nebulae: NGC 3242, NGC 6826 and\nNGC 7662. Archival HST/WFPC2 narrow band filter images were used to investigate\nshocked regions by two independent methods: using low excitation ions (via H\nalpha/[N II] vs H alpha/[S II] extended diagnostic diagrams) and by means of\nhigh excitation species looking for regions of enhanced [O III]/H alpha line\nratios. Shocked region analysis via low excitation ions shows that major\ndeviations from the general inside to outside ionisation trend correspond only\nto regions where FLIERs or LISs are located. The reduction on the SNR at the\noutskirts of the [O III]/H alpha ratio maps, made us unable to unambiguously\nidentified for an enhancement on the [O III]/H alpha line ratio as an indicator\nfor shocks. For non-shocked regions we performed a photoionisation modelling\nusing Cloudy. Fittings to the [O III] and H alpha observed radial profiles lead\nus to constrain on the free parameters of the density laws and filling factors\ntogether to temperatures and luminosities for the CSPNe. Best fit models show a\nvery well representation of the [O III] and H alpha emission. Discrepancies in\nthe model fittings to the [N II] and [S II] profiles at NGC 6826 and NGC 3242,\ncan be attributed in the former case, due to a contamination by the light of\nthe CSPN and, in the latter case, either due to gas inhomogeneities within the\nclumps or to a leaking of UV radiation. \n\n"}
{"id": "1807.02112", "contents": "Title: K-shell photoabsorption and photoionization of trace elements. III.\n  Isoelectronic sequences with electron number $19\\leq N\\leq 26$ Abstract: This is the final report of a three-paper series on the K-shell\nphotoabsorption and photoionization of trace elements, namely F, Na, P, Cl, K,\nSc, Ti, V, Cr, Mn, Co, Cu and Zn. K lines and edges from such elements are\nobserved in the X-ray spectra of supernova remnants, galaxy clusters and\naccreting black holes and neutron stars, their diagnostic potential being\nlimited by poor atomic data. We are completing the previously reported\nradiative datasets with new photoabsorption and photoionization cross sections\nfor isoelectronic sequences with electron number $19\\leq N\\leq 26$. We are also\ngiving attention to the access, integrity and usability of the whole resulting\natomic database. Target representations are obtained with the atomic structure\ncode AUTOSTRUCTURE. Where possible, cross sections for ground-configuration\nstates are computed with the Breit--Pauli $R$-matrix method (BPRM) in either\nintermediate or $LS$ coupling including damping (radiative and Auger) effects;\notherwise and more generally, they are generated in the isolated-resonance\napproximation with AUTOSTRUCTURE. Cross sections were computed with BPRM only\nfor the K ($N=19$) and Ca ($N=20$) isoelectronic sequences, the latter in $LS$\ncoupling. For the rest of the sequences ($21\\leq N \\leq 26$), AUTOSTRUCTURE was\nrun in $LS$-coupling mode taking into account damping effects. Comparisons\nbetween these two methods for K-like Zn XII and Ca-like Zn XI show that, to\nensure reasonable accuracy, the $LS$ calculations must be performed taking into\naccount the non-fine-structure relativistic corrections. \n\n"}
{"id": "1807.02845", "contents": "Title: Gaia GraL: Gaia DR2 Gravitational Lens Systems. III. A systematic blind\n  search for new lensed systems Abstract: Aims: In this work, we aim to provide a reliable list of gravitational lens\n(GL) candidates based on a search performed over the entire Gaia Data Release 2\n(Gaia DR2). We also show that the sole astrometric and photometric informations\ncoming from the Gaia satellite yield sufficient insights for supervised\nlearning methods to automatically identify GL candidates with an efficiency\nthat is comparable to methods based on image processing. Methods: We simulated\n106,623,188 lens systems composed of more than two images, based on a regular\ngrid of parameters characterizing a non-singular isothermal ellipsoid lens\nmodel in the presence of an external shear. These simulations are used as an\ninput for training and testing our supervised learning models consisting of\nExtremely Randomized Trees. The latter are finally used to assign to each of\nthe 2,129,659 clusters of celestial objects a discriminant value that reflects\nthe ability of our simulations to match the observed relative positions and\nfluxes from each cluster. Once complemented with additional constraints, these\ndiscriminant values allowed us to identify GL candidates out of the list of\nclusters. Results: We report the discovery of 15 new quadruply-imaged lens\ncandidates with angular separations less than 6\" and assess the performance of\nour approach by recovering 12 out of the 13 known quadruply-imaged systems with\nall their components detected in Gaia DR2 with a misclassification rate of\nfortuitous clusters of stars as lens systems that is below one percent.\nSimilarly, the identification capability of our method regarding\nquadruply-imaged systems where three images are detected in Gaia DR2 is\nassessed by recovering 10 out of the 13 known quadruply-imaged systems having\none of their constituting images discarded. The associated misclassification\nrate varying then between 5.8% and 20%, depending on the image we decided to\nremove. \n\n"}
{"id": "1807.04748", "contents": "Title: Blazar Flares as an Origin of High-Energy Cosmic Neutrinos? Abstract: We consider implications of high-energy neutrino emission from blazar flares,\nincluding the recent event IceCube-170922A and the 2014-2015 neutrino flare\nthat could originate from TXS 0506+056. First, we discuss their contribution to\nthe diffuse neutrino intensity taking into account various observational\nconstraints. Blazars are likely to be subdominant in the diffuse neutrino\nintensity at sub-PeV energies, and we show that blazar flares like those of TXS\n0506+056 could make <1-10 percent of the total neutrino intensity. We also\nargue that the neutrino output of blazars can be dominated by the flares in the\nstandard leptonic scenario for their gamma-ray emission, and energetic flares\nmay still be detected with a rate of <1 per year. Second, we consider\nmulti-messenger constraints on the source modeling. We show that luminous\nneutrino flares should be accompanied by luminous broadband cascade emission,\nemerging also in X-rays and gamma-rays. This implies that not only gamma-ray\ntelescopes like Fermi but also X-ray sky monitors such as Swift and MAXI are\ncritical to test the canonical picture based on the single-zone modeling. We\nalso suggest a two-zone model that can naturally satisfy the X-ray constraints\nwhile explaining the flaring neutrinos via either photomeson or hadronuclear\nprocesses. \n\n"}
{"id": "1807.05215", "contents": "Title: BFORE: A CMB Balloon Payload to Measure Reionization, Neutrino Mass, and\n  Cosmic Inflation Abstract: BFORE is a high-altitude ultra-long-duration balloon mission to map the\ncosmic microwave background (CMB). During a 28-day mid-latitude flight launched\nfrom Wanaka, New Zealand, the instrument will map half the sky to improve\nmeasurements of the optical depth to reionization tau. This will break\nparameter degeneracies needed to detect neutrino mass. BFORE will also hunt for\nthe gravitational wave B-mode signal, and map Galactic dust foregrounds. The\nmission will be the first near-space use of TES/mSQUID multichroic detectors\n(150/217 GHz and 280/353 GHz bands) with low-power readout electronics. \n\n"}
{"id": "1807.08750", "contents": "Title: The Next Generation Virgo Cluster Survey (NGVS) XXXI. The kinematics of\n  intra-cluster globular clusters in the core of the Virgo cluster Abstract: Intra-cluster (IC) populations are expected to be a natural result of the\nhierarchical assembly of clusters, yet their low space densities make them\ndifficult to detect and study. We present the first definitive kinematic\ndetection of an IC population of globular clusters (GCs) in the Virgo cluster,\naround the central galaxy, M87. This study focuses on the Virgo core for which\nthe combination of NGVS photometry and follow-up spectroscopy allows us to\nreject foreground star contamination and explore GC kinematics over the full\nVirgo dynamical range. The GC kinematics changes gradually with galactocentric\ndistance, decreasing in mean velocity and increasing in velocity dispersion,\neventually becoming indistinguishable from the kinematics of Virgo dwarf\ngalaxies at $\\mathrm{R>320\\, kpc}$. By kinematically tagging M87 halo and\nintra-cluster GCs we find that 1) the M87 halo has a smaller fraction\n($52\\pm3\\%$) of blue clusters with respect to the IC counterpart ($77\\pm10\\%$),\n2) the $(g'-r')_{0}$ vs $(i'-z')_{0}$ color-color diagrams reveal a galaxy\npopulation that is redder than the IC population that may be due to a different\ncomposition in chemical abundance and progenitor mass, and 3) the ICGC\ndistribution is shallower and more extended than the M87 GCs, yet still\ncentrally concentrated. The ICGC specific frequency,\n$S_{N,\\mathrm{ICL}}=10.2\\pm4.8$, is consistent with what is observed for the\npopulation of quenched, low-mass galaxies within 1~Mpc from the cluster's\ncenter. The IC population at Virgo's center is thus consistent with being an\naccreted component from low-mass galaxies tidally stripped or disrupted through\ninteractions, with a total mass of\n$\\mathrm{M_{ICL,tot}=10.8\\pm0.1\\times10^{11}M_{\\odot}}$. \n\n"}
{"id": "1807.10003", "contents": "Title: The MICADO first light imager for the ELT: overview, operation,\n  simulation Abstract: MICADO will enable the ELT to perform diffraction limited near-infrared\nobservations at first light. The instrument's capabilities focus on imaging\n(including astrometric and high contrast) as well as single object\nspectroscopy. This contribution looks at how requirements from the observing\nmodes have driven the instrument design and functionality. Using examples from\nspecific science cases, and making use of the data simulation tool, an outline\nis presented of what we can expect the instrument to achieve. \n\n"}
{"id": "1807.10312", "contents": "Title: PyCBC Inference: A Python-based parameter estimation toolkit for compact\n  binary coalescence signals Abstract: We introduce new modules in the open-source PyCBC gravitational- wave\nastronomy toolkit that implement Bayesian inference for compact-object binary\nmergers. We review the Bayesian inference methods implemented and describe the\nstructure of the modules. We demonstrate that the PyCBC Inference modules\nproduce unbiased estimates of the parameters of a simulated population of\nbinary black hole mergers. We show that the posterior parameter distributions\nobtained used our new code agree well with the published estimates for binary\nblack holes in the first LIGO-Virgo observing run. \n\n"}
{"id": "1807.10317", "contents": "Title: The Dark Side Properties of Galaxies Requires (viable) Modifications to\n  the Verlinde's Emergent Gravity Theory Abstract: Dark Matter is an unknown entity in the Universe. Although several fields of\nastrophysics \\& cosmology are trying to endorse this elusive matter, however,\nits nature remains an open question. Recently,\nVerlinde\\cite{verlinde2017emergent} has proposed the Emergent Gravity theory\n(EGT), which is creating severe issues for DM identity. In this work, we have\nexamined the EGT in the light of the kinematics of the spiral and elliptical\ngalaxies. Results show that the EGT predictions are in good agreement with\nlatter, though some discrepancy appears in the former. This current work calls\nfor refinement in EGT. \n\n"}
{"id": "1807.11873", "contents": "Title: Redshift inference from the combination of galaxy colors and clustering\n  in a hierarchical Bayesian model Abstract: Powerful current and future cosmological constraints using high precision\nmeasurements of the large-scale structure of galaxies and its weak\ngravitational lensing effects rely on accurate characterization of the redshift\ndistributions of the galaxy samples using only broadband imaging. We present a\nframework for constraining both the redshift probability distributions of\ngalaxy populations and the redshifts of their individual members. We use a\nhierarchical Bayesian model (HBM) which provides full posterior distributions\non those redshift probability distributions, and, for the first time, we show\nhow to combine survey photometry of single galaxies and the information\ncontained in the galaxy clustering against a well-characterized tracer\npopulation in a robust way. One critical approximation turns the HBM into a\nsystem amenable to efficient Gibbs sampling. We show that in the absence of\nphotometric information, this method reduces to commonly used clustering\nredshift estimators. Using a simple model system, we show how the incorporation\nof clustering information with photo-$z$'s tightens redshift posteriors, and\ncan overcome biases or gaps in the coverage of a spectroscopic prior. The\nmethod enables the full propagation of redshift uncertainties into cosmological\nanalyses, and uses all the information at hand to reduce those uncertainties\nand associated potential biases. \n\n"}
{"id": "1808.00011", "contents": "Title: Analyzing interferometric observations of strong gravitational lenses\n  with recurrent and convolutional neural networks Abstract: We use convolutional neural networks (CNNs) and recurrent neural networks\n(RNNs) to estimate the parameters of strong gravitational lenses from\ninterferometric observations. We explore multiple strategies and find that the\nbest results are obtained when the effects of the dirty beam are first removed\nfrom the images with a deconvolution performed with an RNN-based structure\nbefore estimating the parameters. For this purpose, we use the recurrent\ninference machine (RIM) introduced in Putzky & Welling (2017). This provides a\nfast and automated alternative to the traditional CLEAN algorithm. We obtain\nthe uncertainties of the estimated parameters using variational inference with\nBernoulli distributions. We test the performance of the networks with a\nsimulated test dataset as well as with five ALMA observations of strong lenses.\nFor the observed ALMA data we compare our estimates with values obtained from a\nmaximum-likelihood lens modeling method which operates in the visibility space\nand find consistent results. We show that we can estimate the lensing\nparameters with high accuracy using a combination of an RNN structure\nperforming image deconvolution and a CNN performing lensing analysis, with\nuncertainties less than a factor of two higher than those achieved with\nmaximum-likelihood methods. Including the deconvolution procedure performed by\nRIM, a single evaluation can be done in about a second on a single GPU,\nproviding a more than six orders of magnitude increase in analysis speed while\nusing about eight orders of magnitude less computational resources compared to\nmaximum-likelihood lens modeling in the uv-plane. We conclude that this is a\npromising method for the analysis of mm and cm interferometric data from\ncurrent facilities (e.g., ALMA, JVLA) and future large interferometric\nobservatories (e.g., SKA), where an analysis in the uv-plane could be difficult\nor unfeasible. \n\n"}
{"id": "1808.00014", "contents": "Title: NuSTAR observations of Mrk 766: distinguishing reflection from\n  absorption Abstract: We present two new NuSTAR observations of the narrow line Seyfert 1 (NLS1)\ngalaxy Mrk 766 and give constraints on the two scenarios previously proposed to\nexplain its spectrum and that of other NLS1s: relativistic reflection and\npartial covering. The NuSTAR spectra show a strong hard (>15 keV) X-ray excess,\nwhile simultaneous soft X-ray coverage of one of the observations provided by\nXMM-Newton constrains the ionised absorption in the source. The pure reflection\nmodel requires a black hole of high spin ($a>0.92$) viewed at a moderate\ninclination ($i=46^{+1}_{-4}$ degrees). The pure partial covering model\nrequires extreme parameters: the cut-off of the primary continuum is very low\n($22^{+7}_{-5}$ keV) in one observation and the intrinsic X-ray emission must\nprovide a large fraction (75%) of the bolometric luminosity. Allowing a hybrid\nmodel with both partial covering and reflection provides more reasonable\nabsorption parameters and relaxes the constraints on reflection parameters. The\nfractional variability reduces around the iron K band and at high energies\nincluding the Compton hump, suggesting that the reflected emission is less\nvariable than the continuum. \n\n"}
{"id": "1808.00468", "contents": "Title: Stellar Radiation is Critical for Regulating Star Formation and Driving\n  Outflows in Low Mass Dwarf Galaxies Abstract: Effective stellar feedback is used in models of galaxy formation to drive\nrealistic galaxy evolution. Models typically include energy injection from\nsupernovae as the dominant form of stellar feedback, often in some form of\nsub-grid recipe. However, it has been recently suggested that pre-SN feedback\n(stellar winds or radiation) is necessary in high-resolution simulations of\ngalaxy evolution to properly regulate star formation and properties of the\ninterstellar medium (ISM). Following these processes is computationally\nchallenging, so many prescriptions model this feedback approximately,\naccounting for the local destruction of dense gas clouds around newly formed\nstars in lieu of a full radiative transfer calculation. In this work we examine\nhigh resolution simulations (1.8~pc) of an isolated dwarf galaxy with detailed\nstellar feedback tracked on a star-by-star basis. By following stellar ionizing\nradiation with an adaptive ray-tracing radiative transfer method, we test its\nimportance in regulating star formation and driving outflows in this galaxy. We\nfind that including ionizing radiation reduces the star formation rate (SFR) by\nover a factor of 5, and is necessary to produce the ISM conditions needed for\nsupernovae to drive significant outflows. We find that a localized\napproximation for radiation feedback is sufficient to regulate the SFR on short\ntimescales, but does not allow significant outflows. Short and long range\nradiation effects are both important in driving the evolution of our\nlow-metallicity, low-mass dwarf galaxy. Generalizing these results to more\nmassive galaxies would be a valuable avenue of future research. \n\n"}
{"id": "1808.04493", "contents": "Title: The Simons Observatory: Instrument Overview Abstract: The Simons Observatory (SO) will make precise temperature and polarization\nmeasurements of the cosmic microwave background (CMB) using a set of telescopes\nwhich will cover angular scales between 1 arcminute and tens of degrees,\ncontain over 60,000 detectors, and observe at frequencies between 27 and 270\nGHz. SO will consist of a 6 m aperture telescope coupled to over 30,000\ntransition-edge sensor bolometers along with three 42 cm aperture refractive\ntelescopes, coupled to an additional 30,000+ detectors, all of which will be\nlocated in the Atacama Desert at an altitude of 5190 m. The powerful\ncombination of large and small apertures in a CMB observatory will allow us to\nsample a wide range of angular scales over a common survey area. SO will\nmeasure fundamental cosmological parameters of our universe, constrain\nprimordial fluctuations, find high redshift clusters via the Sunyaev-Zel`dovich\neffect, constrain properties of neutrinos, and trace the density and velocity\nof the matter in the universe over cosmic time. The complex set of technical\nand science requirements for this experiment has led to innovative\ninstrumentation solutions which we will discuss. The large aperture telescope\nwill couple to a cryogenic receiver that is 2.4 m in diameter and nearly 3 m\nlong, creating a number of technical challenges. Concurrently, we are designing\nthe array of cryogenic receivers housing the 42 cm aperture telescopes. We will\ndiscuss the sensor technology SO will use and we will give an overview of the\ndrivers for and designs of the SO telescopes and receivers, with their cold\noptical components and detector arrays. \n\n"}
{"id": "1808.05152", "contents": "Title: Studies of Systematic Uncertainties for Simons Observatory: Optical\n  Effects and Sensitivity Considerations Abstract: The Simons Observatory (SO) is a new experiment that aims to measure the\ncosmic microwave background (CMB) in temperature and polarization. SO will\nmeasure the polarized sky over a large range of microwave frequencies and\nangular scales using a combination of small ($\\sim0.5 \\, \\rm m$) and large\n($\\sim 6\\, \\rm m $) aperture telescopes and will be located in the Atacama\nDesert in Chile. This work is part of a series of papers studying calibration,\nsensitivity, and systematic errors for SO. In this paper, we discuss current\nefforts to model optical systematic effects, how these have been used to guide\nthe design of the SO instrument, and how these studies can be used to inform\ninstrument design of future experiments like CMB-S4. While optical systematics\nstudies are underway for both the small aperture and large aperture telescopes,\nwe limit the focus of this paper to the more mature large aperture telescope\ndesign for which our studies include: pointing errors, optical distortions,\nbeam ellipticity, cross-polar response, instrumental polarization rotation and\nvarious forms of sidelobe pickup. \n\n"}
{"id": "1808.06977", "contents": "Title: Searching for Sub-Second Stellar Variability with Wide-Field Star Trails\n  and Deep Learning Abstract: We present a method that enables wide field ground-based telescopes to scan\nthe sky for sub-second stellar variability. The method has operational and\nimage processing components. The operational component is to take star trail\nimages. Each trail serves as a light curve for its corresponding source and\nfacilitates sub-exposure photometry. We train a deep neural network to identify\nstellar variability in wide-field star trail images. We use the Large Synoptic\nSurvey Telescope (LSST) Photon Simulator to generate simulated star trail\nimages and include transient bursts as a proxy for variability. The network\nidentifies transient bursts on timescales down to 10 milliseconds. We argue\nthat there are multiple fields of astrophysics that can be advanced by the\nunique combination of time resolution and observing throughput that our method\noffers. \n\n"}
{"id": "1808.07327", "contents": "Title: On the charge of the Galactic centre black hole Abstract: The Galactic centre supermassive black hole (SMBH), in sharp contrast with\nits complex environment, is characterized by only three classical parameters --\nmass, spin, and electric charge. Its charge is poorly constrained. It is,\nhowever, usually assumed to be zero because of neutralization due to the\npresence of plasma. We revisit the question of the SMBH charge and put\nrealistic limits on its value, timescales of charging and discharging, and\nobservable consequences of the potential, small charge associated with the\nGalactic centre black hole. The electric charge due to classical arguments\nbased on the mass difference between protons and electrons is $\\lesssim\n10^9\\,{\\rm C}$ and is of a transient nature on the viscous time-scale. However,\nthe rotation of a black hole in magnetic field generates electric field due to\nthe twisting of magnetic field lines. This electric field can be associated\nwith induced charge, for which we estimate an upper limit of $\\lesssim\n10^{15}\\,{\\rm C}$. Moreover, this charge is most likely positive due to an\nexpected alignment between the magnetic field and the black-hole spin. Even a\nsmall charge of this order significantly shifts the position of the innermost\nstable circular orbit (ISCO) of charged particles. In addition, we propose a\nnovel observational test based on the presence of the bremsstrahlung surface\nbrightness decrease, which is more sensitive for smaller unshielded electric\ncharges than the black-hole shadow size. Based on this test, the current upper\nobservational limit on the charge of Sgr A* is $\\lesssim 3\\times 10^{8}\\,{\\rm\nC}$. \n\n"}
{"id": "1808.07348", "contents": "Title: On the Impact of Helium Content on the RR Lyrae Distance Scale Abstract: We constructed new sets of He-enhanced (Y = 0.30, Y = 0.40) nonlinear,\ntime-dependent convective hydrodynamical models of RR Lyrae (RRL) stars\ncovering a broad range in metal abundances (Z from 0.0001 to 0.02). The\nincrease in He content from the canonical value (Y = 0.245) to Y = 0.30 and\n0.40 causes a simultaneous increase in stellar luminosity and in pulsation\nperiod. To investigate the dependence of the RRL distance scale on the He\nabundance, we computed new optical (RI) and near-infrared (JHK ) period\nluminosity metallicity helium relations. Interestingly enough, the increase in\nHe content causes a minimal change in the coefficients of both period and\nmetallicity terms, since canonical and He-enhanced models obey similar PLZ\nrelations. On the contrary, the classical B and V band mean magnitude\nmetallicity relations and the R band PLZ relation display a significant\ndependence on the He content. The He enhanced models are, at fixed metal\ncontent, 0.2 to 0.5 mag brighter than canonical ones. This variation is only\nmarginally affected by evolutionary effects. The quoted distance diagnostics\nonce calibrated with trigonometric parallaxes (Gaia) will provide the\nopportunity to estimate the He content of field and cluster RRLs. Moreover, the\nuse of either spectroscopic or photometric metal abundances will pave the way\nto new empirical constraints on the universality of the helium to metal\nenrichment ratio in old stellar tracers. \n\n"}
{"id": "1808.07442", "contents": "Title: Studies of Systematic Uncertainties for Simons Observatory: Polarization\n  Modulator Related Effects Abstract: The Simons Observatory (SO) will observe the temperature and polarization\nanisotropies of the cosmic microwave background (CMB) over a wide range of\nfrequencies (27 to 270 GHz) and angular scales by using both small (0.5 m) and\nlarge (6 m) aperture telescopes. The SO small aperture telescopes will target\ndegree angular scales where the primordial B-mode polarization signal is\nexpected to peak. The incoming polarization signal of the small aperture\ntelescopes will be modulated by a cryogenic, continuously-rotating half-wave\nplate (CRHWP) to mitigate systematic effects arising from slowly varying noise\nand detector pair-differencing. In this paper, we present an assessment of some\nsystematic effects arising from using a CRHWP in the SO small aperture systems.\nWe focus on systematic effects associated with structural properties of the HWP\nand effects arising when operating a HWP, including the amplitude of the HWP\nsynchronous signal (HWPSS), and I -> P (intensity to polarization) leakage that\narises from detector non-linearity in the presence of a large HWPSS. We\ndemonstrate our ability to simulate the impact of the aforementioned systematic\neffects in the time domain. This important step will inform mitigation\nstrategies and design decisions to ensure that SO will meet its science goals. \n\n"}
{"id": "1808.09089", "contents": "Title: Semi-analytic galaxies -- III. The impact of supernova feedback on the\n  mass-metallicity relation Abstract: We use the semi-analytic model (SAM) of galaxy formation and evolution SAG\ncoupled with the MULTIDARK simulation MDPL2 to study the evolution of the\nstellar mass-gas metallicity relation of galaxies (MZR). We test several\nimplementations of the dependence of the mass loading due to supernovae (SNe).\nWe find that no evolution in the normalization of the MZR is obtained unless we\nintroduce an explicit scaling of the reheated and ejected mass with redshift as\n$(1+z)^\\beta$. The latter is in agreement with results from the FIRE\nsimulations, and it should encompass small scale properties of the interstellar\nmedium varying over time, which are not captured in SAMs, as well as other\nenergy sources in addition to SNe. Increasing $\\beta$ leads to stronger\nevolution of the MZR normalization; $\\beta = 1.9$ reproduces the observed MZR\nin the range $0 < z < 3.5$. A stronger redshift dependence of outflows reduces\nthe levels of star formation at earlier epochs with the consequent decrease of\nmetal production. This leads to a slower increase of the gas metallicity\ncompared to the stellar mass build-up. The cold gas can be contaminated either\nby receiving a direct injection of the material recycled by stellar winds and\nSNe or by gas cooling. The relative role of each process for a given stellar\nmass depends on the criterion adopted to regulate the fate of the recycled\nmaterial. However, modifying the metal loading of the outflows has mild impact\non the zero-point evolution and does not affect our conclusions. \n\n"}
{"id": "1808.09632", "contents": "Title: Direct Imaging in Reflected Light: Characterization of Older, Temperate\n  Exoplanets With 30-m Telescopes Abstract: Direct detection, also known as direct imaging, is a method for discovering\nand characterizing the atmospheres of planets at intermediate and wide\nseparations. It is the only means of obtaining spectra of non-transiting\nexoplanets. Characterizing the atmospheres of planets in the <5 AU regime,\nwhere RV surveys have revealed an abundance of other worlds, requires a\n30-m-class aperture in combination with an advanced adaptive optics system,\ncoronagraph, and suite of spectrometers and imagers - this concept underlies\nplanned instruments for both TMT (the Planetary Systems Imager, or PSI) and the\nGMT (GMagAO-X). These instruments could provide astrometry, photometry, and\nspectroscopy of an unprecedented sample of rocky planets, ice giants, and gas\ngiants. For the first time habitable zone exoplanets will become accessible to\ndirect imaging, and these instruments have the potential to detect and\ncharacterize the innermost regions of nearby M-dwarf planetary systems in\nreflected light. High-resolution spectroscopy will not only illuminate the\nphysics and chemistry of exo-atmospheres, but may also probe rocky, temperate\nworlds for signs of life in the form of atmospheric biomarkers (combinations of\nwater, oxygen and other molecular species). By completing the census of\nnon-transiting worlds at a range of separations from their host stars, these\ninstruments will provide the final pieces to the puzzle of planetary\ndemographics. This whitepaper explores the science goals of direct imaging on\n30-m telescopes and the technology development needed to achieve them. \n\n"}
{"id": "1808.10037", "contents": "Title: Simons Observatory Large Aperture Telescope Receiver Design Overview Abstract: The Simons Observatory (SO) will make precision temperature and polarization\nmeasurements of the cosmic microwave background (CMB) using a series of\ntelescopes which will cover angular scales between one arcminute and tens of\ndegrees and sample frequencies between 27 and 270 GHz. Here we present the\ncurrent design of the large aperture telescope receiver (LATR), a 2.4 m\ndiameter cryostat that will be mounted on the SO 6 m telescope and will be the\nlargest CMB receiver to date. The cryostat size was chosen to take advantage of\nthe large focal plane area having high Strehl ratios, which is inherent to the\nCross-Dragone telescope design. The LATR will be able to accommodate thirteen\noptics tubes, each having a 36 cm diameter aperture and illuminating several\nthousand transition-edge sensor (TES) bolometers. This set of equipment will\nprovide an opportunity to make measurements with unparalleled sensitivity.\nHowever, the size and complexity of the LATR also pose numerous technical\nchallenges. In the following paper, we present the design of the LATR and\ninclude how we address these challenges. The solutions we develop in the\nprocess of designing the LATR will be informative for the general CMB\ncommunity, and for future CMB experiments like CMB-S4. \n\n"}
{"id": "1808.10099", "contents": "Title: Opportunities for the Large Synoptic Survey Telescope to Find New L$_5$\n  Trojan and Hilda Lucy Encounter Targets Abstract: The Trojan clouds contain a surprisingly diverse population of objects. It is\nonly by understanding this diversity can we unravel their history. The more\nobjects Lucy visits the better we can constrain the formation and evolution of\nthe giant planets. While Lucy will visit four Trojans in the L$_4$ cloud, its\ntrajectory only passes one known Trojan system, the PM binary, in L$_5$. There\nis ample time in the Lucy timeline to possibly add additional L$_5$ targets,\nthereby maximizing the mission's science return. In the next decade, the 8.4-m\nLarge Synoptic Survey Telescope (LSST), is expected to detect nearly 300,000\nJupiter Trojans between approximately 16 and 24.5 r-band magnitudes in the\n$\\sim$18,000 deg$^2$ main survey and the expected $\\sim$4,000 deg$^2$ northern\necliptic extension. We explore potential opportunities for LSST to find new\nLucy L$_5$ fly-by targets. \n\n"}
{"id": "1809.00036", "contents": "Title: Year two instrument status of the SPT-3G cosmic microwave background\n  receiver Abstract: The South Pole Telescope (SPT) is a millimeter-wavelength telescope designed\nfor high-precision measurements of the cosmic microwave background (CMB). The\nSPT measures both the temperature and polarization of the CMB with a large\naperture, resulting in high resolution maps sensitive to signals across a wide\nrange of angular scales on the sky. With these data, the SPT has the potential\nto make a broad range of cosmological measurements. These include constraining\nthe effect of massive neutrinos on large-scale structure formation as well as\ncleaning galactic and cosmological foregrounds from CMB polarization data in\nfuture searches for inflationary gravitational waves. The SPT began observing\nin January 2017 with a new receiver (SPT-3G) containing $\\sim$16,000\npolarization-sensitive transition-edge sensor bolometers. Several key\ntechnology developments have enabled this large-format focal plane, including\nadvances in detectors, readout electronics, and large millimeter-wavelength\noptics. We discuss the implementation of these technologies in the SPT-3G\nreceiver as well as the challenges they presented. In late 2017 the\nimplementations of all three of these technologies were modified to optimize\ntotal performance. Here, we present the current instrument status of the SPT-3G\nreceiver. \n\n"}
{"id": "1809.00667", "contents": "Title: On the Verge of an Astronomy CubeSat Revolution Abstract: CubeSats are small satellites built in standard sizes and form factors, which\nhave been growing in popularity but have thus far been largely ignored within\nthe field of astronomy. When deployed as space-based telescopes, they enable\nscience experiments not possible with existing or planned large space missions,\nfilling several key gaps in astronomical research. Unlike expensive and highly\nsought-after space telescopes like the Hubble Space Telescope (HST), whose time\nmust be shared among many instruments and science programs, CubeSats can\nmonitor sources for weeks or months at time, and at wavelengths not accessible\nfrom the ground such as the ultraviolet (UV), far-infrared (far-IR) and\nlow-frequency radio. Science cases for CubeSats being developed now include a\nwide variety of astrophysical experiments, including exoplanets, stars, black\nholes and radio transients. Achieving high-impact astronomical research with\nCubeSats is becoming increasingly feasible with advances in technologies such\nas precision pointing, compact sensitive detectors, and the miniaturisation of\npropulsion systems if needed. CubeSats may also pair with the large space- and\nground-based telescopes to provide complementary data to better explain the\nphysical processes observed. \n\n"}
{"id": "1809.03337", "contents": "Title: Analysis of luminosity measurements of the pre-white dwarf PG 1159-035:\n  an approach featuring a dynamical database Abstract: In a previous work, those of the luminosity measurements of the pre-white\ndwarf PG 1159-035 which are available online yielded estimates for the optimal\nembedding dimension, for the dimensionality of the phase space reconstructed\nfrom these observations, and for the maximal Lyapunov exponent $\\lambda$: the\nresult $\\lambda = (9.2 \\pm 1.0 ({\\rm stat.}) \\pm 2.7 ({\\rm syst.})) \\cdot\n10^{-2}~\\Delta \\tau^{-1}$ ($\\Delta \\tau=10$ s is the sampling interval in the\nmeasurements) was obtained, suggesting that the physical processes, underlying\nthe variation of the luminosity of PG 1159-035, are chaotic. An improved\napproach is employed in the present work in relation to the database of\nembedding vectors: instead of assigning each of the input time-series arrays\neither to the training or to the test set, the new approach features the\ncreation of a dynamical database, i.e., of one which depends on the choice of\nthe input test file. Although the size of the database is thus increased by a\nfactor of about $2$ (compared to the previous study), the impact of this change\non the important results is found to be insignificant. The estimate of this\nwork for the maximal Lyapunov exponent ($\\lambda = (8.9 \\pm 0.7 ({\\rm stat.})\n\\pm 1.9 ({\\rm syst.})) \\cdot 10^{-2}~\\Delta \\tau^{-1}$) is in very good\nagreement with the result of the earlier study. \n\n"}
{"id": "1809.03689", "contents": "Title: Highly-multiplexed microwave SQUID readout using the SLAC Microresonator\n  Radio Frequency (SMuRF) Electronics for Future CMB and Sub-millimeter Surveys Abstract: The next generation of cryogenic CMB and submillimeter cameras under\ndevelopment require densely instrumented sensor arrays to meet their science\ngoals. The readout of large numbers ($\\sim$10,000--100,000 per camera) of\nsub-Kelvin sensors, for instance as proposed for the CMB-S4 experiment, will\nrequire substantial improvements in cold and warm readout techniques. To reduce\nthe readout cost per sensor and integration complexity, efforts are presently\nfocused on achieving higher multiplexing density while maintaining readout\nnoise subdominant to intrinsic detector noise. Highly-multiplexed cold readout\ntechnologies in active development include Microwave Kinetic Inductance Sensors\n(MKIDs) and microwave rf-SQUIDs. Both exploit the high quality factors of\nsuperconducting microwave resonators to densely channelize sub-Kelvin sensors\ninto the bandwidth of a microwave transmission line. We present advancements in\nthe development of a new warm readout system for microwave SQUID multiplexing,\nthe SLAC Superconducting Microresonator RF electronics, or SMuRF. The SMuRF\nsystem is unique in its ability to track each tone, minimizing the total RF\npower required to read out each resonator, thereby significantly reducing the\nlinearity requirements on the cold and warm readout. Here, we present\nmeasurements of the readout noise and linearity of the first full SMuRF system,\nincluding a demonstration of closed-loop tone tracking on a 528 channel\ncryogenic microwave SQUID multiplexer. SMuRF is being explored as a potential\nreadout solution for several future CMB projects including Simons Observatory,\nBICEP Array, CCAT-prime, Ali-CPT, and CMB-S4. Parallel development of the\nplatform is underway to adapt SMuRF to read out both MKID and fast X-ray TES\ncalorimeter arrays. \n\n"}
{"id": "1809.04609", "contents": "Title: Pyaneti: a fast and powerful software suite for multi-planet radial\n  velocity and transit fitting Abstract: Transiting exoplanet parameter estimation from time-series photometry and\nDoppler spectroscopy is fundamental to study planets' internal structures and\ncompositions. Here we present the code pyaneti, a powerful and user-friendly\nsoftware suite to perform multi-planet radial velocity and transit data\nfitting. The code uses a Bayesian approach combined with an MCMC sampling to\nestimate the parameters of planetary systems. We combine the numerical\nefficiency of FORTRAN, the versatility of PYTHON, and the parallelization of\nOpenMP to make pyaneti a fast and easy to use code. The package is freely\navailable at https://github.com/oscaribv/pyaneti. \n\n"}
{"id": "1809.05034", "contents": "Title: Full-sky beam convolution for cosmic microwave background applications Abstract: We introduce a publicly available full-sky beam convolution code library\nintended to inform the design of future cosmic microwave background (CMB)\ninstruments and help current experiments probe potential systematic effects.\nThe code can be used to assess the impact of optical systematics on all stages\nof data reduction for a realistic experiment, including analyses beyond power\nspectrum estimation, by generating signal timelines that may serve as input to\nfull analysis pipelines. The design and mathematical framework of the Python\ncode is discussed along with a few simple benchmarking results. We present a\nsimple two-lens refracting telescope design and use it together with the code\nto simulate a year-long dataset for 400 detectors scanning the sky on a\nsatellite instrument. The simulation results identify a number of sub-leading\noptical non-idealities and demonstrate significant B-mode residuals caused by\nextended sidelobes that are sensitive to polarized radiation from the Galaxy.\nFor the proposed design and satellite scanning strategy, we show that a full\nphysical optics beam model generates B-mode systematics that differ\nsignificantly from the simpler elliptical Gaussian model. The code is available\nat https://github.com/adrijd/beamconv \n\n"}
{"id": "1809.05089", "contents": "Title: Bounds on extra dimensions from micro black holes in the context of the\n  metastable Higgs vacuum Abstract: We estimate the rate at which collisions between ultra-high energy cosmic\nrays can form small black holes in models with extra dimensions. If recent\nconjectures about false vacuum decay catalyzed by black hole evaporation apply,\nthe lack of vacuum decay events in our past light cone may place new bounds on\nthe black hole formation rate and thus on the fundamental scale of gravity in\nthese models. For theories with fundamental scale $E_{*}$ above the Higgs\ninstability scale of the Standard Model, we find a lower bound on $E_{*}$ that\nis within about an order of magnitude of the energy where the cosmic ray\nspectrum begins to show suppression from the GZK effect. Otherwise, the\nabundant formation of semiclassical black holes with short lifetimes would\nlikely initiate vacuum decay. Assuming a Higgs instability scale at the low end\nof the range compatible with experimental data, the excluded range is\napproximately $10^{17} \\,\\text{eV} \\lesssim E_{*} \\leq 10^{18.8}\\,\\text{eV}$\nfor theories with $n=1$ extra dimension, narrowing to $10^{17}\\,\\text{eV}\n\\lesssim E_{*} \\leq 10^{18.1}\\,\\text{eV}$ for $n=6$. These bounds rule out\nregions of parameter space that are inaccessible to collider experiments,\nsmall-scale gravity tests, or estimates of Kaluza-Klein processes in neutron\nstars and supernovae. \n\n"}
{"id": "1809.07052", "contents": "Title: PlanetPack3: a radial-velocity and transit analysis tool for exoplanets Abstract: PlanetPack, initially released in 2013, is a command-line software aimed to\nfacilitate exoplanets detection, characterization, and basic dynamical $N$-body\nsimulations. This paper presents the third major release of PlanetPack that\nincorporates multiple improvements in comparison to the legacy versions.\n  The major ones include: (i) modelling noise by Gaussian processes that in\naddition to the classic white noise may optionally include multiple components\nof the red noise, modulated noise, quasiperiodic noise (to be added soon in\nminor subversions of the 3.x series); (ii) an improved pipeline for TTV\nanalysis of photometric data that includes quadratic limb-darkening model and\nautomatic red-noise detection; (iii) self-consistent joint fitting of\nphotometric + radial velocity data with full access to all the functionality\ninherited from the legacy PlanetPack; (iv) modelling of the Rossiter-McLaughlin\neffect for arbitrary eclipser/star radii ratio, and optionally including\ncorrections that take into account average characteristics of a multiline\nstellar spectrum; (v) speed improvements through multithreading and\nCPU-optimized BLAS libraries.\n  PlanetPack was written in pure C++ (standard of 2011), and is expected to be\nrun on a wide range of platforms. \n\n"}
{"id": "1809.07403", "contents": "Title: TESS in the Solar System Abstract: The Transiting Exoplanet Survey Satellite (TESS), launched successfully on\n18th of April, 2018, will observe nearly the full sky and will provide\ntime-series imaging data in ~27-day-long campaigns. TESS is equipped with 4\ncameras; each has a field-of-view of 24x24 degrees. During the first two years\nof the primary mission, one of these cameras, Camera #1, is going to observe\nfields centered at an ecliptic latitude of 18 degrees. While the ecliptic plane\nitself is not covered during the primary mission, the characteristic scale\nheight of the main asteroid belt and Kuiper belt implies that a significant\namount of small solar system bodies will cross the field-of-view of this\ncamera. Based on the comparison of the expected amount of information of TESS\nand Kepler/K2, we can compute the cumulative etendues of the two optical\nsetups. This comparison results in roughly comparable optical etendues, however\nthe net etendue is significantly larger in the case of TESS since all of the\nimaging data provided by the 30-minute cadence frames are downlinked rather\nthan the pre-selected stamps of Kepler/K2. In addition, many principles of the\ndata acquisition and optical setup are clearly different, including the level\nof confusing background sources, full-frame integration and cadence, the\nfield-of-view centroid with respect to the apparent position of the Sun, as\nwell as the differences in the duration of the campaigns. As one would expect,\nTESS will yield time-series photometry and hence rotational properties for only\nbrighter objects, but in terms of spatial and phase space coverage, this sample\nwill be more homogeneous and more complete. Here we review the main analogues\nand differences between the Kepler/K2 mission and the TESS mission, focusing on\nscientific implications and possible yields related to our Solar System. \n\n"}
{"id": "1809.08261", "contents": "Title: A Bayesian Framework for Exoplanet Direct Detection and Non-Detection Abstract: Rigorously quantifying the information in high contrast imaging data is\nimportant for informing follow-up strategies to confirm the substellar nature\nof a point source, constraining theoretical models of planet-disk interactions,\nand deriving planet occurrence rates. However, within the exoplanet direct\nimaging community, non-detections have almost exclusively been defined using a\nfrequentist detection threshold (i.e. contrast curve) and associated\ncompleteness. This can lead to conceptual inconsistencies when included in a\nBayesian framework. A Bayesian upper limit is such that the true value of a\nparameter lies below this limit with a certain probability. The associated\nprobability is the integral of the posterior distribution with the upper limit\nas the upper bound. In summary, a frequentist upper limit is a statement about\nthe detectability of planets while a Bayesian upper limit is a statement about\nthe probability of a parameter to lie in an interval given the data. The latter\nis therefore better suited for rejecting hypotheses or theoretical models based\non their predictions. In this work we emphasize that Bayesian statistics and\nupper limits are more easily interpreted and typically more constraining than\nthe frequentist approach. We illustrate the use of Bayesian analysis in two\ndifferent cases: 1) with a known planet location where we also propose to use\nmodel comparison to constrain the astrophysical nature of the point source and\n2) gap-carving planets in TW Hya. To finish, we also mention the problem of\ncombining radial velocity and direct imaging observations. \n\n"}
{"id": "1809.09666", "contents": "Title: Can we neglect relativistic temperature corrections in the Planck\n  thermal SZ analysis? Abstract: Measurements of the thermal Sunyaev-Zel'dovich (tSZ) effect have long been\nrecognized as a powerful cosmological probe. Here we assess the importance of\nrelativistic temperature corrections to the tSZ signal on the power spectrum\nanalysis of the Planck Compton-$y$ map, developing a novel formalism to account\nfor the associated effects. The amplitude of the tSZ power spectrum is found to\nbe sensitive to the effective electron temperature, $\\bar{T}_e$, of the cluster\nsample. Omitting the corresponding modifications leads to an underestimation of\nthe $yy$-power spectrum amplitude. Relativistic corrections thus add to the\nerror budget of tSZ power spectrum observables such as $\\sigma_8$. This could\nhelp alleviate the tension between various cosmological probes, with the\ncorrection scaling as $\\Delta \\sigma_8/\\sigma_8 \\simeq\n0.019\\,[k\\bar{T}_e\\,/\\,5\\,{\\rm keV}]$ for Planck. At the current level of\nprecision, this implies a systematic shift by $\\simeq 1\\sigma$, which can also\nbe interpreted as an overestimation of the hydrostatic mass bias by $\\Delta b\n\\simeq 0.046\\,(1-b)\\,[k\\bar{T}_e\\,/\\,5\\,{\\rm keV}]$, bringing it into better\nagreement with hydrodynamical simulations. It is thus time to consider\nrelativistic temperature corrections in the processing of current and future\ntSZ data. \n\n"}
{"id": "1809.09933", "contents": "Title: A possible advantage of telescopes with a non-circular pupil Abstract: Most telescope designs have a circular-shape aperture. We demonstrate that\ntelescopes with an elongated pupil have better contrast, at lower separations,\nbetween a bright central star and a faint companion. We simulate images for an\nelongated-pupil telescope and for a circular-pupil telescope of equal aperture\narea and integration time, investigating specifically what is the maximal\ncontrast for finding faint companions around bright stars as a function of\nangular separation. We show that this design gives better contrast at lower\nseparation from a bright star. This is shown for diffraction-limited (for\nperfect and imperfect optics) and seeing-limited speckle images, assuming equal\naperture area and observing time. We also show the results are robust to errors\nin measurement of the point spread function. To compensate for the wider point\nspread function of the short axis, images should be taken at different rotation\nangles, either by rotating the telescope around the optical axis or by allowing\na stationary mirror array to scan different parallactic angles with time.\nImages taken at different rotation angles are added using the proper image\ncoaddition algorithms developed by Zackay & Ofek. The final image has the same\ncontrast in all angles, rather than in specific areas of diffraction nulls. We\nobtained speckle observations with a small, ground based elongated-aperture\ntelescope and show the results are consistent with simulations. \n\n"}
{"id": "1810.01022", "contents": "Title: Extremely large telescopes for complex stellar populations around the\n  Galactic centre Abstract: The Galactic centre and its surrounding space are important in studying\ngalaxy-scale evolution, and stellar populations therein are expected to have\nimprints of the long-term evolution. Interstellar extinction, however, severely\nlimits optical observations, thereby requiring infrared observations. In\naddition, many systems from those in the proximity of the central black hole to\nforeground objects in the disc overlap in each sightline, which complicates the\ninterpretation of observations of a wide variety of objects. We discuss some\nimportant issues concerning the central regions, particularly the Galactic\nbulge and the Nuclear Stellar Disc (also known as the Central Molecular Zone).\nAn obvious advantage of Extremely Large Telescopes (ELTs) is the deeper\nlimiting magnitudes, but we emphasise the importance of the synergy between the\ndata of deep ELTs and other observational data (e.g. astrometric measurements\nand the detection of interstellar absorption lines) in order to disentangle the\ncomplex stellar populations. \n\n"}
{"id": "1810.01745", "contents": "Title: Laying the Groundwork for the Development of the Data Archive of the New\n  Robotic Telescope Abstract: The Liverpool Telescope has been in fully autonomous operation since 2004.\nThe supporting data archive facility has largely been untouched. The data\nprovision service has not been an issue although some modernisation of the\nsystem is desirable. This project is timely. Not only does it suit the upgrade\nof the current LT data archive, it is in line with the design phase of the New\nRobotic Telescope which will be online in the early-2020s; and with the\ndevelopment of a new data archive facility for a range of telescopes at the\nNational Astronomical Research Institute of Thailand. The Newton Fund enabled\nus to collaborate in designing a new versatile generic system that serves all\npurposes. In the end, we conclude that a single system would not meet the needs\nof all parties and only adopt similar front-ends while the back-ends are\nbespoke to our respective systems and data-flows. \n\n"}
{"id": "1810.02821", "contents": "Title: Fast Sampling from Wiener Posteriors for Image Data with Dataflow\n  Engines Abstract: We use Dataflow Engines (DFE) to construct an efficient Wiener filter of\nnoisy and incomplete image data, and to quickly draw probabilistic samples of\nthe compatible true underlying images from the Wiener posterior. Dataflow\ncomputing is a powerful approach using reconfigurable hardware, which can be\ndeeply pipelined and is intrinsically parallel. The unique Wiener-filtered\nimage is the minimum-variance linear estimate of the true image (if the signal\nand noise covariances are known) and the most probable true image (if the\nsignal and noise are Gaussian distributed). However, many images are compatible\nwith the data with different probabilities, given by the analytic posterior\nprobability distribution referred to as the Wiener posterior. The DFE code also\ndraws large numbers of samples of true images from this posterior, which allows\nfor further statistical analysis. Naive computation of the Wiener-filtered\nimage is impractical for large datasets, as it scales as $n^3$, where $n$ is\nthe number of pixels. We use a messenger field algorithm, which is well suited\nto a DFE implementation, to draw samples from the Wiener posterior, that is,\nwith the correct probability we draw samples of noiseless images that are\ncompatible with the observed noisy image. The Wiener-filtered image can be\nobtained by a trivial modification of the algorithm. We demonstrate a lower\nbound on the speed-up, from drawing 10$^5$ samples of a 128$^2$ image, of 11.3\n${\\pm}$ 0.8 with 8 DFEs in a 1U MPC-X box when compared with a 1U server\npresenting 32 CPU threads. We also discuss a potential application in\nastronomy, to provide better dark matter maps and improved determination of the\nparameters of the Universe. \n\n"}
{"id": "1810.02933", "contents": "Title: Super-Eddington Accretion in the WISE-Selected Extremely Luminous\n  Infrared Galaxy W2246-0526 Abstract: We use optical and near-infrared spectroscopy to observe rest-UV emission\nlines and estimate the black hole mass of WISEA J224607.56-052634.9\n(W2246-0526) at z = 4.601, the most luminous hot dust-obscured galaxy yet\ndiscovered by WISE. From the broad component of the MgII-2799A emission line,\nwe measure a black hole mass of log (M_BH/M_sun) = 9.6 +- 0.4. The broad\nCIV-1549A line is asymmetric and significantly blue-shifted. The derived M_BH\nfrom the blueshift-corrected broad CIV line width agrees with the MgII result.\nFrom direct measurement using a well-sampled SED, the bolometric luminosity is\n3.6 * 10^14 L_sun. The corresponding Eddington ratio for W2246-0526 is\nlambda_Edd = L_AGN / L_Edd = 2.8. This high Eddington ratio may reach the level\nwhere the luminosity is saturating due to photon trapping in the accretion\nflow, and be insensitive to the mass accretion rate. In this case, the M_BH\ngrowth rate in W2246-0526 would exceed the apparent accretion rate derived from\nthe observed luminosity. \n\n"}
{"id": "1810.03070", "contents": "Title: Autonomous radiodetection of air showers with the TREND50 antenna array Abstract: TREND50 is a radio detection setup of 50 self-triggered antennas working in\nthe 50-100MHz frequency range and deployed in a radio-quiet valley of the\nTianshan mountains (China). TREND50 achieved its goal: the autonomous\nradiodetection and identification of air showers. Thanks to a dedicated offine\nselection algorithm, 564 air shower candidates were indeed selected out of\n$7\\cdot10^8$ transient radio signals recorded during the 314 live days of data\ntaken during the first two years of operation of this setup (2011 and 2012).\nThis event rate, as well as the distribution of the candidate directions of\narrival, is consistent with what is expected from cosmic-ray-induced air\nshowers according to simulations, assuming an additional $\\sim$20%\ncontamination of the final sample by background events. This result is obtained\nat the cost of a reduced air shower detection efficiency, estimated to be\n$\\sim$3%. This low efficiency is mostly due to the large amount of dead time of\nthe setup. This result paves the way for the GRANDProto35 experiment, the first\nstage of the GRAND project. \n\n"}
{"id": "1810.04633", "contents": "Title: Development of Calibration Strategies for the Simons Observatory Abstract: The Simons Observatory (SO) is a set of cosmic microwave background\ninstruments that will be deployed in the Atacama Desert in Chile. The key\nscience goals include setting new constraints on cosmic inflation, measuring\nlarge scale structure with gravitational lensing, and constraining neutrino\nmasses. Meeting these science goals with SO requires high sensitivity and\nimproved calibration techniques. In this paper, we highlight a few of the most\nimportant instrument calibrations, including spectral response, gain stability,\nand polarization angle calibrations. We present their requirements for SO and\nexperimental techniques that can be employed to reach those requirements. \n\n"}
{"id": "1810.06441", "contents": "Title: Improved Photometric Classification of Supernovae using Deep Learning Abstract: We present improved photometric supernovae classification using deep\nrecurrent neural networks. The main improvements over previous work are (i) the\nintroduction of a time gate in the recurrent cell that uses the observational\ntime as an input; (ii) greatly increased data augmentation including time\ntranslation, addition of Gaussian noise and early truncation of the lightcurve.\nFor post Supernovae Photometric Classification Challenge (SPCC) data, using a\ntraining fraction of $5.2\\%$ (1103 supernovae) of a representational dataset,\nwe obtain a type Ia vs. non type Ia classification accuracy of $93.2 \\pm\n0.1\\%$, a Receiver Operating Characteristic curve AUC of $0.980 \\pm 0.002$ and\na SPCC figure-of-merit of $F_1=0.57 \\pm 0.01$. Using a representational dataset\nof $50\\%$ ($10660$ supernovae), we obtain a classification accuracy of $96.6\n\\pm 0.1\\%$, an AUC of $0.995 \\pm 0.001$ and $F_1=0.76 \\pm 0.01$. We found the\nnon-representational training set of the SPCC resulted in a large degradation\nin performance due to a lack of faint supernovae, but this can be migrated by\nthe introduction of only a small number ($\\sim 100$) of faint training samples.\nWe also outline ways in which this could be achieved using unsupervised domain\nadaptation. \n\n"}
{"id": "1810.06566", "contents": "Title: Figuring Out Gas & Galaxies in Enzo (FOGGIE). I. Resolving Simulated\n  Circumgalactic Absorption at 2 < z < 2.5 Abstract: We present simulations from the new \"Figuring Out Gas & Galaxies in Enzo\"\n(FOGGIE) project. In contrast to most extant simulations of galaxy formation,\nwhich concentrate computational resources on galactic disks and spheroids with\nfluid and particle elements of fixed mass, the FOGGIE simulations focus on\nextreme spatial and mass resolution in the circumgalactic medium (CGM)\nsurrounding galaxies. Using the Enzo code and a new refinement scheme, FOGGIE\nreaches spatial resolutions of 381 comoving $h^{-1}$ pc and resolves extremely\nlow masses ($\\lesssim 1$--$100$ Msun out to 100 comoving $h^{-1}$ kpc from the\ncentral halo. At these resolutions, cloud and filament-like structures giving\nrise to simulated absorption are smaller, and better resolved, than the same\nstructures simulated with standard density-dependent refinement. Most of the\nsimulated absorption arises in identifiable and well-resolved structures with\nmasses $\\lesssim 10^4$ Msun, well below the mass resolution of typical zoom\nsimulations. However, integrated quantities such as mass surface density and\nionic covering fractions change at only the $\\lesssim 30$% level as resolution\nis varied. This relatively small changes in projected quantities---even when\nthe sizes and distribution of absorbing clouds change dramatically---indicate\nthat commonly used observables provide only weak constraints on the physical\nstructure of the underlying gas. Comparing the simulated absorption features to\nthe KODIAQ (Keck Observatory Database of Ionized Absorption toward Quasars)\nsurvey of $z \\sim2$--$3.5$ Lyman limit systems, we show that high-resolution\nFOGGIE runs better resolve the internal kinematic structure of detected\nabsorption, and better match the observed distribution of absorber properties.\nThese results indicate that CGM resolution is key in properly testing\nsimulations of galaxy evolution with circumgalactic observations. \n\n"}
{"id": "1810.06594", "contents": "Title: Science with the Next-Generation VLA and Pulsar Timing Arrays Abstract: Pulsar timing arrays (PTAs) can be used to detect and study gravitational\nwaves in the nanohertz band (i.e., wavelengths of order light-years). This\nrequires high-precision, decades-long data sets from sensitive, instrumentally\nstable telescopes. NANOGrav and its collaborators in the International Pulsar\nTiming Array consortium are on the verge of the first detection of the\nstochastic background produced by supermassive binary black holes, which form\nvia the mergers of massive galaxies. By providing Northern hemisphere sky\ncoverage with exquisite sensitivity and higher frequency coverage compared to\nthe SKA, a Next-Generation Very Large Array (ngVLA) will be a fundamental\ncomponent in the next phase of nanohertz GW astrophysics, enabling detailed\ncharacterization of the stochastic background and the detection of individual\nsources contributing to the background, as well as detections of (or stringent\nconstraints on) cosmic strings and other exotica. Here we summarize the\nscientific goals of PTAs and the technical requirements for the ngVLA to play a\nsignificant role in the characterization of the nanohertz gravitational wave\nuniverse. \n\n"}
{"id": "1810.07163", "contents": "Title: Science with an ngVLA: Deuteration in starless and prestellar cores Abstract: In dense starless and protostellar cores, the relative abundance of\ndeuterated species to their non-deuterated counterparts can become orders of\nmagnitude greater than in the local interstellar medium. This enhancement\nproceeds through multiple pathways in the gas phase and on dust grains, where\nthe chemistry is strongly dependent on the physical conditions. In this\nChapter, we discuss how sensitive, high resolution observations with the ngVLA\nof emission from deuterated molecules will trace both the dense gas structure\nand kinematics on the compact physical scales required to track the\ngravitational collapse of star-forming cores and the subsequent formation of\nyoung protostars and circumstellar accretion regions. Simultaneously, such\nobservations will play a critical role in tracing the chemical history\nthroughout the various phases of star and planet formation. Many low-J\ntransitions of key deuterated species, along with their undeuterated\ncounterparts, lie within the 60-110 GHz frequency window, the lower end of\nwhich is largely unavailable with current facilities and instrumentation. The\ncombination of sensitivity and angular resolution provided only by the ngVLA\nwill enable unparalleled detailed studies of the physics and chemistry of the\nearliest stages of star formation. \n\n"}
{"id": "1810.08911", "contents": "Title: Higher-order modified Starobinsky inflation Abstract: An extension of the Starobinsky model is proposed. Besides the usual\nStarobinsky Lagrangian, a term proportional to the derivative of the scalar\ncurvature, $\\nabla_{\\mu}R\\nabla^{\\mu}R$, is considered. The analyzis is done in\nthe Einstein frame with the introduction of a scalar field and a vector field.\nWe show that inflation is attainable in our model, allowing for a graceful\nexit. We also build the cosmological perturbations and obtain the leading-order\ncurvature power spectrum, scalar and tensor tilts and tensor-to-scalar ratio.\nThe tensor and curvature power spectrums are compared to the most recent\nobservations from BICEP2/Keck collaboration. We verify that the\nscalar-to-tensor rate $r$ can be expected to be up to three times the values\npredicted by Starobinsky model. \n\n"}
{"id": "1810.09015", "contents": "Title: A Ground Plane Artifact that Induces an Absorption Profile in Averaged\n  Spectra from Global 21-cm Measurements - with Possible Application to EDGES Abstract: Most of the current Global 21-cm experiments include ground screens that help\nmoderate effects from the Earth. In this paper, we report on a possible\nsystematic artifact within the ground plane that may produce broad absorption\nfeatures in the spectra observed by these experiments. Using analytical\napproximations and numerical modeling, the origin of the artifact and its\nimpact on the sky-averaged spectrum are described. The publicly released EDGES\ndataset, from which a 78 MHz absorption feature was recently suggested, is used\nto probe for the potential presence of ground plane resonances. While the lack\nof a noise level for the EDGES spectrum makes traditional goodness-of-fit\nstatistics unattainable, the rms residual can be used to assess the relative\ngoodness of fits performed under similar circumstances. The fit to the EDGES\nspectrum using a model with a simple 2-term foreground and three cavity-mode\nresonances is compared to a fit to the same spectrum with a model used by the\nEDGES team consisting of a 5-term foreground and a flattened Gaussian signal.\nThe fits with the physically motivated resonance and empirical flattened\nGaussian models have rms residuals of 20.8 mK (11 parameters) and 24.5 mK (9\nparameters), respectively, allowing us to conclude that ground plane resonances\nconstitute another plausible explanation for the EDGES data. \n\n"}
{"id": "1810.09505", "contents": "Title: What Does a Successful Postdoctoral Fellowship Publication Record Look\n  Like? Abstract: Obtaining a prize postdoctoral fellowship in astronomy and astrophysics\ninvolves a number of factors, many of which cannot be quantified. One criterion\nthat can be measured is the publication record of an applicant. The publication\nrecords of past fellowship recipients may, therefore, provide some quantitative\nguidance for future prospective applicants. We investigated the publication\npatterns of recipients of the NASA prize postdoctoral fellowships in the\nHubble, Einstein, and Sagan programs from 2014 through 2017, using the NASA ADS\nreference system. We tabulated their publications at the point where fellowship\napplications were submitted, and we find that the 133 fellowship recipients in\nthat time frame had a median of 6 +/- 2 first-author publications, and 14 +/- 6\nco-authored publications. The full range of first author papers is 1 to 15, and\nfor all papers ranges from 2 to 76, indicating very diverse publication\npatterns. Thus, while fellowship recipients generally have strong publication\nrecords, the distribution of both first-author and co-authored papers is quite\nbroad; there is no apparent threshold of publications necessary to obtain these\nfellowships. We also examined the post-PhD publication rates for each of the\nthree fellowship programs, between male and female recipients, across the four\nyears of the analysis and find no consistent trends. We hope that these\nfindings will prove a useful reference to future junior scientists. \n\n"}
{"id": "1810.11500", "contents": "Title: Non-isobaric Thermal Instability Abstract: Multiphase media have very complex structure and evolution. Accurate\nnumerical simulations are necessary to make advances in our understanding of\nthis rich physics. Because simulations can capture both the linear and\nnonlinear evolution of perturbations with a relatively wide range of sizes, it\nis important to thoroughly understand the stability of condensation and\nacoustic modes between the two extreme wavelength limits of isobaric and\nisochoric instability as identified by Field (1965). Partially motivated by a\nrecent suggestion that large non-isobaric clouds can `shatter' into tiny\ncloudlets, we revisit the linear theory to survey all possible regimes of\nthermal instability. We uncover seven regimes in total, one of which allows\nthree unstable condensation modes. Using the code Athena++, we determine the\nnumerical requirements to properly evolve small amplitude perturbations of the\nentropy mode into the nonlinear regime. Our 1D numerical simulations\ndemonstrate that for a typical AGN cooling function, the nonlinear evolution of\na single eigenmode in an isobarically unstable plasma involves increasingly\nlarger amplitude oscillations in cloud size, temperature and density as the\nwavelength increases. Such oscillations are the hallmark behavior of\nnon-isobaric multiphase gas dynamics and may be observable as correlations\nbetween changes in brightness and the associated periodic redshifts and\nblueshifts in systems that can be spatially resolved. Intriguingly, we discuss\nregimes and derive characteristic cloud sizes for which the saturation process\ngiving rise to these oscillations can be so energetic that the cloud may indeed\nbreak apart. However, we dub this process `splattering' instead of\n`shattering', as it is a different fragmentation mechanism triggered when the\ncloud suddenly `lands' on the stable cold branch of the equilibrium curve. \n\n"}
{"id": "1811.00503", "contents": "Title: Fundamental parameters of isolated galaxy triplets in the local\n  Universe: Statistical study Abstract: Understanding the dynamics of galaxy triplet systems is one of the\nsignificant ways of obtaining insight into the dynamics of large galaxy\nclusters. Toward that aim, we present a detailed study of all isolated triplet\nsystems (total of 315) taken from the `SDSS-based catalogue of Isolated\nTriplets' (SIT). In addition, we compared our results with those obtained for a\nsample of triplets from the Local Supercluster (LS), SDSS-triplets, Tully's\ncatalogue, Wide (W) and Compact (K)-triplets. In addition, we performed the\ncorrelation between the dynamical parameters and the Large Scale Structure\n(LSS). Interestingly, we found that there is no correlation between both the\nmean projected separation for the triplet systems and the LSS and its dynamical\nparameters. Furthermore, we found that only 3 percent of these systems can be\nconsidered as compact since the mean harmonic separation (rh) is more than 0.4\nMpc for 97 percent of the population.Thus we may conclude that, mergers might\nnot have played a dominant role in their evolution. \n\n"}
{"id": "1811.01575", "contents": "Title: Effect of filters on the time-delay interferometry residual laser noise\n  for LISA Abstract: The Laser Interferometer Space Antenna (LISA) is a European Space Agency\nmission that aims to measure gravitational waves in the millihertz range. Laser\nfrequency noise enters the interferometric measurements and dominates the\nexpected gravitational signals by many orders of magnitude. Time-delay\ninterferometry (TDI) is a technique that reduces this laser noise by\nsynthesizing virtual equal-arm interferometric measurements. Laboratory\nexperiments and numerical simulations have confirmed that this reduction is\nsufficient to meet the scientific goals of the mission in proof-of-concept\nsetups. In this paper, we show that the on-board antialiasing filters play an\nimportant role in TDI's performance when the flexing of the constellation is\naccounted for. This coupling was neglected in previous studies. To reach an\noptimal reduction level, filters with vanishing group delays must be used on\nboard or synthesized off-line. We propose a theoretical model of the residual\nlaser noise including this flexing-filtering coupling. We also use two\nindependent simulators to produce realistic measurement signals and compute the\ncorresponding TDI Michelson variables. We show that our theoretical model\nagrees with the simulated data with exquisite precision. Using these two\ncomplementary approaches, we confirm TDI's ability to reduce laser frequency\nnoise in a more realistic mission setup. The theoretical model provides insight\non filter design and implementation. \n\n"}
{"id": "1811.03081", "contents": "Title: Forging new worlds: high-resolution synthetic galaxies with chained\n  generative adversarial networks Abstract: Astronomy of the 21st century increasingly finds itself with extreme\nquantities of data. This growth in data is ripe for modern technologies such as\ndeep image processing, which has the potential to allow astronomers to\nautomatically identify, classify, segment and deblend various astronomical\nobjects. In this paper, we explore the use of chained generative adversarial\nnetworks (GANs), a class of generative models that learn mappings from latent\nspaces to data distributions by modelling the joint distribution of the data,\nto produce physically realistic galaxy images as one use case of such models.\nIn cosmology, such datasets can aid in the calibration of shape measurements\nfor weak lensing by augmenting data with synthetic images. By measuring the\ndistributions of multiple physical properties, we show that images generated\nwith our approach closely follow the distributions of real galaxies, further\nestablishing state-of-the-art GAN architectures as a valuable tool for\nmodern-day astronomy. \n\n"}
{"id": "1811.04714", "contents": "Title: The stellar halo of isolated central galaxies in the Hyper Suprime-Cam\n  imaging survey Abstract: We study the faint stellar halo of isolated central galaxies, by stacking\ngalaxy images in the HSC survey and accounting for the residual sky background\nsampled with random points. The surface brightness profiles in HSC $r$-band are\nmeasured for a wide range of galaxy stellar masses\n($9.2<\\log_{10}M_\\ast/M_\\odot<11.4$) and out to 120 kpc. Failing to account for\nthe stellar halo below the noise level of individual images will lead to\nunderestimates of the total luminosity by $\\leq 15\\%$. Splitting galaxies\naccording to the concentration parameter of their light distributions, we find\nthat the surface brightness profiles of low concentration galaxies drop faster\nbetween 20 and 100 kpc than those of high concentration galaxies. Albeit the\nlarge galaxy-to-galaxy scatter, we find a strong self-similarity of the stellar\nhalo profiles. They show unified forms once the projected distance is scaled by\nthe halo virial radius. The colour of galaxies is redder in the centre and\nbluer outside, with high concentration galaxies having redder and more\nflattened colour profiles. There are indications of a colour minimum, beyond\nwhich the colour of the outer stellar halo turns red again. This colour\nminimum, however, is very sensitive to the completeness in masking satellite\ngalaxies. We also examine the effect of the extended PSF in the measurement of\nthe stellar halo, which is particularly important for low mass or low\nconcentration galaxies. The PSF-corrected surface brightness profile can be\nmeasured down to $\\sim$31 $\\mathrm{mag}/\\mathrm{arcsec}^2$ at 3-$\\sigma$\nsignificance. PSF also slightly flattens the measured colour profiles. \n\n"}
{"id": "1811.04917", "contents": "Title: Assessment of the Projection-induced Polarimetry Technique for\n  Constraining the Foreground Spectrum in Global 21 cm Cosmology Abstract: Detecting the cosmological sky-averaged (global) 21 cm signal as a function\nof observed frequency will provide a powerful tool to study the ionization and\nthermal history of the intergalactic medium (IGM) in the early Universe ($\\sim$\n400 million years after the Big Bang). The greatest challenge in conventional\ntotal-power global 21 cm experiments is the removal of the foreground\nsynchrotron emission ($\\sim 10^3$-$10^4$ K) to uncover the weak cosmological\nsignal (tens to hundreds of mK), especially since the intrinsic smoothness of\nthe foreground spectrum is corrupted by instrumental effects. Although the\nEDGES team has recently reported an absorption profile at 78 MHz in the\nsky-averaged spectrum, it is necessary to confirm this detection with an\nindependent approach. The projection effect from observing anisotropic\nforeground source emission with a wide-view antenna pointing at the North\nCelestial Pole (NCP) can induce a net polarization, referred as the\nProjection-Induced Polarization Effect (PIPE). Due to Earth's rotation,\nobservation centered at the circumpolar region will impose a dynamic sky\nmodulation on the net polarization's waveforms which is unique to the\nforeground component. In this study, we review the implementation practicality\nand underlying instrumental effects of this new polarimetry-based technique\nwith detailed numerical simulation and a testbed instrument, the Cosmic\nTwilight Polarimeter (CTP). In addition, we explore an SVD-based analysis\napproach for separating the foreground and instrumental effects from the\nbackground global 21 cm signal using the sky-modulated PIPE. \n\n"}
{"id": "1811.09141", "contents": "Title: Evaluating machine learning techniques for predicting power spectra from\n  reionization simulations Abstract: Upcoming experiments such as the SKA will provide huge quantities of data.\nFast modelling of the high-redshift 21cm signal will be crucial for efficiently\ncomparing these data sets with theory. The most detailed theoretical\npredictions currently come from numerical simulations and from faster but less\naccurate semi-numerical simulations. Recently, machine learning techniques have\nbeen proposed to emulate the behaviour of these semi-numerical simulations with\ndrastically reduced time and computing cost. We compare the viability of five\nsuch machine learning techniques for emulating the 21cm power spectrum of the\npublicly-available code SimFast21. Our best emulator is a multilayer perceptron\nwith three hidden layers, reproducing SimFast21 power spectra $10^8$ times\nfaster than the simulation with 4% mean squared error averaged across all\nredshifts and input parameters. The other techniques (interpolation, Gaussian\nprocesses regression, and support vector machine) have slower prediction times\nand worse prediction accuracy than the multilayer perceptron. All our emulators\ncan make predictions at any redshift and scale, which gives more flexible\npredictions but results in significantly worse prediction accuracy at lower\nredshifts. We then present a proof-of-concept technique for mapping between two\ndifferent simulations, exploiting our best emulator's fast prediction speed. We\ndemonstrate this technique to find a mapping between SimFast21 and another\npublicly-available code 21cmFAST. We observe a noticeable offset between the\nsimulations for some regions of the input space. Such techniques could\npotentially be used as a bridge between fast semi-numerical simulations and\naccurate numerical radiative transfer simulations. \n\n"}
{"id": "1811.09640", "contents": "Title: Hidden Inflaton Dark Matter Abstract: If cosmic inflation was driven by an electrically neutral scalar field stable\non cosmological time scales, the field necessarily constitutes all or part of\ndark matter (DM). We study this possibility in a scenario where the inflaton\nfield $s$ resides in a hidden sector, which is coupled to the Standard Model\nsector through the Higgs portal $\\lambda_{hs}\ns^2\\mathcal{H}^\\dagger\\mathcal{H}$ and non-minimally to gravity via $\\xi_s s^2\nR$. We study scenarios where the field $s$ first drives inflation, then reheats\nthe Universe, and later constitutes all DM. We consider two benchmark scenarios\nwhere the DM abundance is generated either by production during reheating or\nvia non-thermal freeze-in. In both cases, we take into account all production\nchannels relevant for DM in the mass range from keV to PeV scale. On the\ninflationary side, we compare the dynamics and the relevant observables in two\ndifferent but well-motivated theories of gravity (metric and Palatini), discuss\nmultifield effects in case both fields ($s$ and $h$) were dynamical during\ninflation, and take into account the non-perturbative nature of particle\nproduction during reheating. We find that, depending on the initial conditions\nfor inflation, couplings and the DM mass, the scenario works well especially\nfor large DM masses, $10^2$ GeV$\\lesssim m_{s}\\lesssim 10^6$ GeV, although\nthere are also small observationally allowed windows at the keV and MeV scales.\nWe discuss how the model can be tested through astrophysical observations. \n\n"}
{"id": "1811.10613", "contents": "Title: A machine--vision method for automatic classification of stellar halo\n  substructure Abstract: Tidal debris structures formed from disrupted satellites contain important\nclues about the assembly histories of galaxies. To date, studies of these\nstructures have been hampered by reliance on by-eye identification and\nmorphological classification which leaves their interpretation significantly\nuncertain. In this work we present a new machine-vision technique based on the\nSubspace-Constrained Mean Shift (SCMS) algorithm which can perform these tasks\nautomatically. SCMS finds the location of the high-density `ridges' that define\nsubstructure morphology. After identification, the coefficients of an\northogonal series density estimator are used to classify points on the ridges\nas part of a continuum between shell-like or stream-like debris, from which a\nglobal morphological classification can be determined. We dub this procedure\nSubspace Constrained Unsupervised Detection of Structure (SCUDS). By applying\nthis tool to controlled N--body simulations of minor mergers we demonstrate\nthat the extracted classifications correspond to the well--understood\nunderlying physics of phase mixing. The application of SCUDS to resolved\nstellar population data from near-future surveys will inform our understanding\nof the buildup of galaxies stellar halos. \n\n"}
{"id": "1812.01472", "contents": "Title: Performance of ANAIS-112 experiment after the first year of data taking Abstract: ANAIS is a direct detection dark matter experiment aiming at the study of the\nannual modulation expected in the interaction rate. It uses same target and\ntechnique than DAMA/LIBRA experiment, which reported a highly significant\npositive modulation compatible with that expected for dark matter particles\ndistributed in the galactic halo. However, other very sensitive experiments do\nnot find any hint of particles with the required properties, although\ncomparison is model dependent. In 2017, ANAIS-112 experiment was installed at\nthe Canfranc Underground Laboratory (LSC), in Spain, and after the\ncommissioning run for calibration and general assessment, ANAIS-112 started\ndata taking in dark matter mode on August 3$^{rd}$, 2017. It consists of nine\nNaI(Tl) modules, amounting 112.5 kg of mass in total. ANAIS-112 will be able to\ntest the DAMA/LIBRA result with the achieved background and threshold at three\nsigma level in five years of data taking. Here we report on the experimental\napparatus and detector performance after the first year of data taking. Total\nlive time available amounts to 341.72 days, being the corresponding exposure\n105.32 kg x yr. \n\n"}
{"id": "1812.01650", "contents": "Title: An efficient approach to extract parameters from star cluster CMDs:\n  fitCMD Abstract: This work presents an approach (fitCMD) designed to obtain a comprehensive\nset of astrophysical parameters from colour-magnitude diagrams (CMDs) of star\nclusters. Based on initial mass function (IMF) properties taken from\nisochrones, fitCMD searches for the values of total (or cluster) stellar mass,\nage, global metallicity, foreground reddening, distance modulus, and\nmagnitude-dependent photometric completeness that produce the artificial CMD\nthat best reproduces the observed one; photometric scatter is also taken into\naccount in the artificial CMDs. Inclusion of photometric completeness proves to\nbe an important feature of fitCMD, something that becomes apparent especially\nwhen luminosity functions are considered. These parameters are used to build a\nsynthetic CMD that also includes photometric scatter. Residual minimization\nbetween the observed and synthetic CMDs leads to the best-fit parameters. When\ntested against artificial star clusters, fitCMD shows to be efficient both in\nterms of computational time and ability to recover the input values. \n\n"}
{"id": "1812.03298", "contents": "Title: The Gaia-LSST Synergy: resolved stellar populations in selected Local\n  Group stellar systems Abstract: This project aims at exploiting the wide-field and limiting-magnitude\ncapabilities of the LSST to fully characterise the resolved stellar populations\nin/around six Local Group stellar systems of different morphological type at\n~30 to ~400 kpc distance from us. We selected targets that host red giant\nbranch (RGB) stars which are within the reach of Gaia and not yet (all)\nsaturated with the LSST. We will use RR Lyrae stars, Cepheids, SX Phoenicis,\ndelta Scuti stars and Long Period Variables, along with the Color Magnitude\nDiagram of the resolved stellar populations in these 6 systems to: i) trace\ntheir different stellar generations over a spatial extension and with a depth\nthat only the LSST can achieve; ii) measure their distances using variable\nstars of different type/parent stellar population and the Tip of the RGB; iii)\nmap their 3D structures up to the periphery of their halos; iv) search for\ntidal streams; and v) study their Star Formation Histories over unprecedented\nlarge fractions of their bodies. Our ultimate goals are to provide a complete\npicture of these nearby stellar systems all the way through to their periphery,\nand to directly link and cross-calibrate the Gaia and LSST projects. \n\n"}
{"id": "1812.04241", "contents": "Title: Pairwise Transverse Velocity Measurement with the Rees-Sciama Effect Abstract: We introduce a new estimator for the mean pairwise velocities of galaxy\nclusters, which is based on the measurement of the clusters'\n$\\textit{transverse}$ velocity components. The Rees-Sciama (RS) effect offers\nan opportunity to measure transverse peculiar velocities through its distinct\ndipolar signature around the halo centers in the Cosmic Microwave Background\n(CMB) temperature map. We exploit this dipolar structure to extract the\nmagnitude and direction of the transverse velocity vectors from CMB maps\nsimulated with the expected characteristics of future surveys like CMB-S4.\nAlthough in the presence of lensed CMB and instrumental noise individual\nvelocities are not reliably reconstructed, we demonstrate that the mean\npairwise velocity measurement obtained using the estimator yields a\nsignal-to-noise ratio of $5.2$ for $\\sim21,000$ halos with $M >\n7\\times10^{13}\\rm M_\\odot$ in a $40\\times40$ [deg$^2$] patch at $z=0.5$. While\nthe proposed estimator carries promising prospects for measuring pairwise\nvelocities through the RS effect in CMB stage IV experiments, its applications\nextend to any other potential probe of transverse velocities. \n\n"}
{"id": "1812.05995", "contents": "Title: Core Cosmology Library: Precision Cosmological Predictions for LSST Abstract: The Core Cosmology Library (CCL) provides routines to compute basic\ncosmological observables to a high degree of accuracy, which have been verified\nwith an extensive suite of validation tests. Predictions are provided for many\ncosmological quantities, including distances, angular power spectra,\ncorrelation functions, halo bias and the halo mass function through\nstate-of-the-art modeling prescriptions available in the literature. Fiducial\nspecifications for the expected galaxy distributions for the Large Synoptic\nSurvey Telescope (LSST) are also included, together with the capability of\ncomputing redshift distributions for a user-defined photometric redshift model.\nA rigorous validation procedure, based on comparisons between CCL and\nindependent software packages, allows us to establish a well-defined numerical\naccuracy for each predicted quantity. As a result, predictions for correlation\nfunctions of galaxy clustering, galaxy-galaxy lensing and cosmic shear are\ndemonstrated to be within a fraction of the expected statistical uncertainty of\nthe observables for the models and in the range of scales of interest to LSST.\nCCL is an open source software package written in C, with a python interface\nand publicly available at https://github.com/LSSTDESC/CCL. \n\n"}
{"id": "1901.01298", "contents": "Title: PELICAN: deeP architecturE for the LIght Curve ANalysis Abstract: We developed a deeP architecturE for the LIght Curve ANalysis (PELICAN) for\nthe characterization and the classification of light curves. It takes light\ncurves as input, without any additional features. PELICAN can deal with the\nsparsity and the irregular sampling of light curves. It is designed to remove\nthe problem of non-representativeness between the training and test databases\ncoming from the limitations of the spectroscopic follow-up. We applied our\nmethodology on different supernovae light curve databases. First, we evaluated\nPELICAN on the Supernova Photometric Classification Challenge for which we\nobtained the best performance ever achieved with a non-representative training\ndatabase, by reaching an accuracy of 0.811. Then we tested PELICAN on simulated\nlight curves of the LSST Deep Fields for which PELICAN is able to detect 87.4%\nof supernovae Ia with a precision higher than 98%, by considering a\nnon-representative training database of 2k light curves. PELICAN can be trained\non light curves of LSST Deep Fields to classify light curves of LSST main\nsurvey, that have a lower sampling rate and are more noisy. In this scenario,\nit reaches an accuracy of 96.5% with a training database of 2k light curves of\nthe Deep Fields. It constitutes a pivotal result as type Ia supernovae\ncandidates from the main survey might then be used to increase the statistics\nwithout additional spectroscopic follow-up. Finally we evaluated PELICAN on\nreal data from the Sloan Digital Sky Survey. PELICAN reaches an accuracy of\n86.8% with a training database composed of simulated data and a fraction of 10%\nof real data. The ability of PELICAN to deal with the different causes of\nnon-representativeness between the training and test databases, and its\nrobustness against survey properties and observational conditions, put it on\nthe forefront of the light curves classification tools for the LSST era. \n\n"}
{"id": "1901.01599", "contents": "Title: LSST Target of Opportunity proposal for locating a core collapse\n  supernova in our galaxy triggered by a neutrino supernova alert Abstract: A few times a century, a core collapse supernova (CCSN) occurs in our galaxy.\nWhen such galactic CCSNe happen, over 99\\% of its gravitational binding energy\nis released in the form of neutrinos. Over a period of tens of seconds, a\npowerful neutrino flux is emitted from the collapsing star. When the exploding\nshock wave finally reaches the surface of the star, optical photons escaping\nthe expanding stellar envelope leave the star and eventually arrive at Earth as\na visible brightening. Crucially, although the neutrino signal is prompt, the\ntime to the shock wave breakout can be minutes to many hours later. This means\nthat the neutrino signal will serve as an alert, warning the optical astronomy\ncommunity the light from the explosion is coming. Quickly identifying the\nlocation of the supernova on the sky and disseminating it to the all available\nground and spaced-based instruments will be critical to learn as much as\npossible about the event. Some neutrino experiments can report pointing\ninformation for these galactic CCSNe. In particular, the Super-Kamiokande\nexperiment can point to a few degrees for CCSNe near the center of our galaxy.\nA CCSN located 10 kpc from Earth is expected to result in a pointing resolution\non the order of 3 degrees. LSST's field of view (FOV) is well matched to this\ninitial search box. LSSTs depth is also uniquely suited for identifying CCSNe\neven if they fail or are obscured by the dust of the galactic plane. This is a\nproposal to, upon receipt of such an alert, prioritize the use of LSST for a\nfull day of observing to continuously monitor a pre-identified region of sky\nand, by using difference imaging, identify and announce the location of the\nsupernova. \n\n"}
{"id": "1901.02882", "contents": "Title: The Distance Measurements of Supernova Remnants in The Fourth Galactic\n  Quadrant Abstract: We take advantage of the red clump stars to build the relation of the optical\nextinction (AV) and distance in each direction of supernova remnants (SNRs)\nwith known extinction in the fourth Galactic quadrant. The distances of 9 SNRs\nare well determined by this method. Their uncertainties range from 10% to 30%,\nwhich is significantly improved for 8 SNRs, G279.0+1.1, G284.3-1.8, G296.1-0.5,\nG299.2-2.9, G308.4-1.4, G309.2-0.6, G309.8- 2.6, G332.4-0.4. In addition, SNR\nG284.3-1.8 with the new distance of 5.5 kpc is not likely associated with the\nPSR J1016-5857 at 3 kpc. \n\n"}
{"id": "1901.03885", "contents": "Title: Exploring the sensitivity of gravitational wave detectors to neutron\n  star physics Abstract: The physics of neutron stars can be studied with gravitational waves emitted\nfrom coalescing binary systems. Tidal effects become significant during the\nlast few orbits and can be visible in the gravitational-wave spectrum above 500\nHz. After the merger, the neutron star remnant oscillates at frequencies above\n1 kHz and can collapse into a black hole. Gravitational-wave detectors with a\nsensitivity of ~10^{-24} strain/sqHz at 2-4 kHz can observe these oscillations\nfrom a source which is ~100 Mpc away. The current observatories, such as LIGO\nand Virgo, are limited by shot noise at high frequencies and have a sensitivity\nof > 2 * 10^{-23} strain/sqHz at 3 kHz. In this paper, we propose an optical\nconfiguration of gravitational-wave detectors which can be set up in present\nfacilities using the current interferometer topology. This scheme has a\npotential to reach 7 * 10^{-25} strain/sqHz at 2.5 kHz without compromising the\ndetector sensitivity to black hole binaries. We argue that the proposed\ninstruments have a potential to detect similar amount of post-merger neutron\nstar oscillations as the next generation detectors, such as Cosmic Explorer and\nEinstein Telescope. We also optimise the arm length of the future detectors for\nneutron star physics and find that the optimal arm length is ~20 km. These\ninstruments have the potential to observe neutron star post-merger oscillations\nat a rate of ~30 events per year with a signal-to-noise ratio of 5 or more. \n\n"}
{"id": "1901.04636", "contents": "Title: Self-supervised Anomaly Detection for Narrowband SETI Abstract: The Search for Extra-terrestrial Intelligence (SETI) aims to find\ntechnological signals of extra-solar origin. Radio frequency SETI is\ncharacterized by large unlabeled datasets and complex interference environment.\nThe infinite possibilities of potential signal types require generalizable\nsignal processing techniques with little human supervision. We present a\ngenerative model of self-supervised deep learning that can be used for anomaly\ndetection and spatial filtering. We develop and evaluate our approach on\nspectrograms containing narrowband signals collected by Breakthrough Listen at\nthe Green Bank telescope. The proposed approach is not meant to replace current\nnarrowband searches but to demonstrate the potential to generalize to other\nsignal types. \n\n"}
{"id": "1901.06944", "contents": "Title: BBN constraints on the annihilation of MeV-scale dark matter Abstract: Thermal dark matter at the MeV scale faces stringent bounds from a variety of\ncosmological probes. Here we perform a detailed evaluation of BBN bounds on the\nannihilation cross section of dark matter with a mass $1\\,\\text{MeV} \\lesssim\nm_\\chi \\lesssim 1\\,\\text{GeV}$. For $p-wave suppressed annihilations,\nconstraints from BBN turn out to be significantly stronger than the ones from\nCMB observations, and are competitive with the strongest bounds from other\nindirect searches. We furthermore update the lower bound from BBN on the mass\nof thermal dark matter using improved determinations of primordial abundances.\nWhile being of similar strength as the corresponding bound from CMB, it is\nsignificantly more robust to changes in the particle physics model. \n\n"}
{"id": "1901.07540", "contents": "Title: Logolinear series expansions with applications to primordial cosmology Abstract: We develop a method for computing series expansions for solutions to ordinary\ndifferential equations when the asymptotic form contains both linear and\nlogarithmic terms. Such situations are common in primordial cosmology when\nconsidering series expansions out of a singularity in the equations arising\nfrom a pre-inflationary phase of the universe. We develop mathematical\ntechniques for generating these series expansions, and apply them to polynomial\nand Starobinsky inflationary potentials with kinetic initial conditions. Code\nfor analytic and numerical computation of logolinear series is provided on\nGitHub. \n\n"}
{"id": "1901.08517", "contents": "Title: Even simpler modeling of quadruply lensed quasars (and random quartets)\n  using Witt's hyperbola Abstract: Witt (1996) has shown that for an elliptical potential, the four images of a\nquadruply lensed quasar lie on a rectangular hyperbola that passes through the\nunlensed quasar position and the center of the potential as well. Wynne and\nSchechter (2018) have shown that, for the singular isothermal elliptical\npotential (SIEP), the four images also lie on an `amplitude' ellipse centered\non the quasar position with axes parallel to the hyperbola's asymptotes. Witt's\nhyperbola arises from equating the directions of both sides of the lens\nequation. The amplitude ellipse derives from equating the magnitudes. One can\nmodel any four points as an SIEP in three steps. 1. Find the rectangular\nhyperbola that passes through the points. 2. Find the aligned ellipse that also\npasses through them. 3. Find the hyperbola with asymptotes parallel to those of\nthe first that passes through the center of the ellipse and the pair of images\nclosest to each other. The second hyperbola and the ellipse give an SIEP that\npredicts the positions of the two remaining images where the curves intersect.\nPinning the model to the closest pair guarantees a four image model. Such\nmodels permit rapid discrimination between gravitationally lensed quasars and\nrandom quartets of stars. \n\n"}
{"id": "1901.08777", "contents": "Title: Sectoral r modes and periodic RV variations of Sun-like stars Abstract: Radial velocity (RV) measurements are used to search for planets orbiting\nlate-type main-sequence stars and confirm the transiting planets. The most\nadvanced spectrometers are approaching a precision of $\\sim 10$ cm/s that\nimplies the need to identify and correct for all possible sources of RV\noscillations intrinsic to the star down to this level and possibly beyond. The\nrecent discovery of global-scale equatorial Rossby waves in the Sun, also\ncalled r modes, prompted us to investigate their possible signature in stellar\nRV measurements. R modes are toroidal modes of oscillation whose restoring\nforce is the Coriolis force and propagate in the retrograde direction in a\nframe that corotates with the star. The solar r modes with azimuthal orders $3\n\\leq m \\lesssim 15$ were identified unambiguously because of their dispersion\nrelation and their long e-folding lifetimes of hundreds of days. Here we\nsimulate the RV oscillations produced by sectoral r modes with $2 \\leq m \\leq\n5$ assuming a stellar rotation period of 25.54 days and a maximum amplitude of\nthe surface velocity of each mode of 2 m/s. This amplitude is representative of\nthe solar measurements, except for the $m=2$ mode which has not yet been\nobserved. Sectoral r modes with azimuthal orders $m=2$ and $3$ would produce RV\noscillations with amplitudes of 76.4 and 19.6 cm/s and periods of 19.16 and\n10.22 days, respectively, for a star with an inclination of the rotation axis\n$i=60^{\\circ}$. Therefore, they may produce rather sharp peaks in the Fourier\nspectrum of the radial velocity time series that could lead to spurious\nplanetary detections. Sectoral r~modes may represent a source of confusion in\nthe case of slowly rotating inactive stars that are preferential targets for RV\nplanet search. The main limitation of the present investigation is the lack of\nobservational constraint on the amplitude of the $m=2$ mode on the Sun. \n\n"}
{"id": "1901.10487", "contents": "Title: Discovery of the First Low-Luminosity Quasar at z > 7 Abstract: We report the discovery of a quasar at z = 7.07, which was selected from the\ndeep multi-band imaging data collected by the Hyper Suprime-Cam (HSC) Subaru\nStrategic Program survey. This quasar, HSC J124353.93+010038.5, has an order of\nmagnitude lower luminosity than do the other known quasars at z > 7. The\nrest-frame ultraviolet absolute magnitude is M1450 = -24.13 +/- 0.08 mag and\nthe bolometric luminosity is Lbol = (1.4 +/- 0.1) x 10^{46} erg/s. Its spectrum\nin the optical to near-infrared shows strong emission lines, and shows evidence\nfor a fast gas outflow, as the C IV line is blueshifted and there is indication\nof broad absorption lines. The Mg II-based black hole mass is Mbh = (3.3 +/-\n2.0) x 10^8 Msun, thus indicating a moderate mass accretion rate with an\nEddington ratio 0.34 +/- 0.20. It is the first z > 7 quasar with sub-Eddington\naccretion, besides being the third most distant quasar, known to date. The\nluminosity and black hole mass are comparable to, or even lower than, those\nmeasured for the majority of low-z quasars discovered by the Sloan Digital Sky\nSurvey, and thus this quasar likely represents a z > 7 counterpart to quasars\ncommonly observed in the low-z universe. \n\n"}
{"id": "astro-ph/0003263", "contents": "Title: The European Large Area ISO Survey I: Goals, Definition and Observation Abstract: We describe the European Large Area ISO Survey (ELAIS). ELAIS was the largest\nsingle Open Time project conducted by ISO, mapping an area of 12 square degrees\nat 15mu with ISO-CAM and at 90mu with ISO-PHOT. Secondary surveys in other ISO\nbands were undertaken by the ELAIS team within the fields of the primary\nsurvey, with 6 square degrees being covered at 6.7mu and 1 square degree at\n175mu. This paper discusses the goals of the project and the techniques\nemployed in its construction, as well as presenting details of the observations\ncarried out, the data from which are now in the public domain. We outline the\nELAIS ``Preliminary Analysis'' which led to the detection of over 1000 sources\nfrom the 15 and 90 mu surveys (the majority selected at 15mu with a flux limit\nof ~3 mJy), to be fed into a ground-based follow-up campaign, as well as a\nprogramme of photometric observations of detected sources using both ISO-CAM\nand ISO-PHOT. We detail how the ELAIS survey complements other ISO surveys in\nterms of depth and areal coverage, and show that the extensive multi-wavelength\ncoverage of the ELAIS fields resulting from our concerted and on-going\nfollow-up programme has made these regions amongst the best studied areas of\ntheir size in the entire sky, and, therefore, natural targets for future\nsurveys. This paper accompanies the release of extremely reliable sub-sets of\nthe ``Preliminary Analysis'' products. Subsequent papers in this series will\ngive further details of our data reduction techniques, reliability &\ncompleteness estimates and present the 15 and 90 nu number counts from the\n``Preliminary Analysis'', while a further series of papers will discuss in\ndetail the results from the ELAIS ``Final Analysis'', as well as from the\nfollow-up programme. \n\n"}
{"id": "astro-ph/0009220", "contents": "Title: Models for Multiband IR Surveys Abstract: Empirical 'backward' galaxy evolution models for IR-bright galaxies are\nconstrained using multiband IR surveys. A new Monte-Carlo algorithm is\ndeveloped for this task. It exploits a large library of realistic Spectral\nEnergy Distributions (SEDs) of 837 local IR galaxies (IRAS 25$\\mu m$ selected)\nfrom the UV (1000{\\AA}) to the radio (20cm), including ISO-measured 3--13$\\mu\nm$ unidentified broad features (UIBs). The basic assumption is that the local\ncorrelation between SEDs and Mid-Infrared (MIR) luminosities can be applied to\nearlier epochs of the Universe. Three populations of IR sources are considered\nin the evolution models. These include (1) starburst galaxies, (2) normal\nlate-type galaxies, and (3) galaxies with AGN. A set of models so constructed\nare compared with data from the literature. Predictions for number counts,\nconfusion limits, redshift distributions, and color-color diagrams are made for\nmultiband surveys using the upcoming SIRTF satellite. \n\n"}
{"id": "astro-ph/0009249", "contents": "Title: Evidence for Massive Black Holes in Nearby Galactic Nuclei Abstract: Masses of black holes in nearby galactic nuclei can be measured in a variety\nof ways, using stellar and gaseous kinematics. Reliable black hole masses are\nknown for several dozen objects, so that demographic questions can start to be\naddressed with some confidence. Prospects for the near future are discussed\nbriefly. \n\n"}
{"id": "astro-ph/0204055", "contents": "Title: Stellar Masses and Star Formation Histories for 10^5 Galaxies from the\n  Sloan Digital Sky Survey Abstract: We develop a new method to constrain the star formation histories, dust\nattenuation and stellar masses of galaxies. It is based on two stellar\nabsorption line indices, the 4000 Angstrom break strength and the Balmer\nabsorption line index Hdelta_A. Together, these indices allow us to constrain\nthe mean stellar ages of galaxies and the fractional stellar mass formed in\nbursts over the past few Gyr. A comparison with broad band photometry then\nyields estimates of dust attenuation and of stellar mass. We generate a large\nlibrary of Monte Carlo realizations of different star formation histories,\nincluding starbursts of varying strength and a range of metallicities. We use\nthis library to generate median likelihood estimates of burst mass fractions,\ndust attenuation strengths, stellar masses and stellar mass-to-light ratios for\na sample of 122,208 galaxies drawn from the Sloan Digital Sky Survey. The\ntypical 95% confidence range in our estimated stellar masses is +-40%. We study\nhow the stellar mass-to-light ratios of galaxies vary as a function of absolute\nmagnitude, concentration index and photometric pass-band and how dust\nattenuation varies as a function of absolute magnitude and 4000 Angstrom break\nstrength. We also calculate how the total stellar mass of the present Universe\nis distributed over galaxies as a function of their mass, size, concentration,\ncolour, burst mass fraction and surface mass density. We find that most of the\nstellar mass in the local Universe resides in galaxies that have stellar masses\n\\~5\\times 10^10 M_sol, half light radii ~3 kpc, and half- light surface mass\ndensities ~10^9 M_sol/kpc^2. The distribution of D(4000) is strongly bimodal,\nshowing a clear division between galaxies dominated by old stellar populations\nand galaxies with more recent star formation. \n\n"}
{"id": "astro-ph/0305375", "contents": "Title: SWIRE: The SIRTF Wide-area InfraRed Extragalactic Survey Abstract: The SIRTF Wide-area InfraRed Extragalactic survey (SWIRE), the largest SIRTF\nLegacy program, is a wide-area, imaging survey to trace the evolution of dusty,\nstar-forming galaxies, evolved stellar populations, and AGN as a function of\nenvironment, from redshifts z~3 to the current epoch. SWIRE will survey 7\nhigh-latitude fields, totaling 60 - 65 sq. deg. in all 7 SIRTF bands: IRAC 3.6,\n4.5, 5.6, 8 microns and MIPS 24, 70, 160 microns. The Legacy Extragalactic\nCatalog may contain in excess of 2 million IR-selected galaxies, dominated by\n(1) ~150,000 luminous infrared galaxies (LIRGs: L{FIR}>10^11 L_sun), ~7000 of\nthese with z>2; (2) 1 million early-type galaxies, ~10,000 with z>2; and (3)\n\\~20,000 classical AGN, plus significantly more dust-obscured QSO/AGN among the\nLIRGs. SWIRE will provide an unprecedented view of the evolution of galaxies,\nstructure, and AGN. The key scientific goals of SWIRE are: (1) to determine the\nevolution of actively star-forming and passively evolving galaxies in order to\nunderstand the history of galaxy formation in the context of cosmic structure\nformation; (2) to determine the evolution of the spatial distribution and\nclustering of evolved galaxies, starbursts and AGN in the key redshift range,\n0.5<z<3, over which much of cosmic evolution has occurred; (3) to determine the\nevolutionary relationship between ``normal galaxies'' and AGN, and the\ncontribution of AGN accretion energy vs stellar nucleosynthesis to the cosmic\nbackgrounds. SWIRE's large area is important to create statistically\nsignificant population samples over enough volume cells that we can resolve the\nstar formation history as a function of epoch and environment The large volume\nis also optimised for finding rare objects. \n\n"}
{"id": "astro-ph/0308283", "contents": "Title: The European Large Area ISO Survey (ELAIS): The Final Band-merged\n  Catalogue Abstract: We present the final band-merged ELAIS catalogue at 6.7, 15, 90, and 175\n$\\mu$m, and the associated data at u,g,r,i,z,J,H,K, and 20cm. The origin of the\nsurvey, infrared and radio observations, data-reduction and optical\nidentifications are briefly reviewed, and a summary of the area covered, and\ncompleteness limit for each infrared band is given. A detailed discussion of\nthe band-merging and optical association strategy is given. The total\ncatalogues consists of 2860 sources. For extragalactic sources observed in 3 or\nmore infrared bands, colour-colour diagrams are presented and discussed in\nterms of the contributing infrared populations. Spectral energy distributions\nare shown for selected sources and compared with cirrus, M82 and Arp220\nstarburst, and AGN dust torus models.\n  Spectroscopic redshifts are tabulated, where available. For the N1 and N2\nareas, the INT ugriz Wide Field Survey, permits photometric redshifts to be\nestimated for galaxies and quasars. These agree well with the spectroscopic\nredshifts, within the uncertainty of the photometric method. The redshift\ndistribution is given for selected ELAIS bands and colour-redshift diagrams are\ndiscussed.\n  There is a high proportion of ultraluminous infrared galaxies in the ELAIS\nCatalogue ($> 10 %$ of 15 $\\mu$m sources), many with Arp220-like colours. 10\nhyperluminous infrared galaxies and 10 EROs are found in the survey. The large\nnumbers of ultraluminous galaxies imply very strong evolution in the\nstar-formation rate between z = 0 and 1. \n\n"}
{"id": "astro-ph/0312444", "contents": "Title: The VIRMOS deep imaging survey: III. ESO/WFI deep U-band imaging of the\n  0226-04 deep field Abstract: In this paper we describe the U-band imaging of the F02 deep field, one of\nthe fields in the VIRMOS Deep Imaging Survey. The observations were done at the\nESO/MPG 2.2m telescope at La Silla (Chile) using the 8k x 8k Wide-Field Imager\n(WFI). The field is centered at alpha(J2000)=02h 26m 00s and\ndelta(J2000)=-04deg 30' 00\", the total covered area is 0.9 deg**2 and the\nlimiting magnitude (50% completeness) is U(AB) ~ 25.4 mag. Reduction steps,\nincluding astrometry, photometry and catalogue extraction, are first discussed.\nThe achieved astrometric accuracy (RMS) is ~ 0.2\" with reference to the I-band\ncatalog and ~ 0.07\" internally (estimated from overlapping sources in different\nexposures). The photometric accuracy including uncertainties from photometric\ncalibration, is < 0.1 mag. Various tests are then performed as a quality\nassessment of the data. They include: (i) the color distribution of stars and\ngalaxies in the field, done together with the BVRI data available from the\nVIMOS survey; (ii) the comparison with previous published results of U-band\nmagnitude-number counts of galaxies. \n\n"}
{"id": "astro-ph/0402030", "contents": "Title: The Environmental Dependence of the Relations between Stellar Mass,\n  Structure, Star Formation and Nuclear Activity in Galaxies Abstract: We use a complete sample of galaxies drawn from the SDSS to study how\nstructure, star formation and nuclear activity depend on local density and on\nstellar mass. Local density is estimated by counting galaxies above a fixed\nabsolute magnitude limit within cylinders 2 Mpc in projected radius and +-500\nkm/s in depth. The stellar mass distribution of galaxies shifts by nearly a\nfactor of two towards higher masses between low and high density regions. At\nfixed stellar mass, both star formation and nuclear activity depend strongly on\nlocal density, while structural parameters such as size and concentration are\nalmost independent of it. The galaxy property most sensitive to environment is\nspecific star formation rate. For galaxies with stellar masses less than 3 x\n10^10 M_sun, the median SFR/M* decreases by more than a factor of 10 from low\nto high densities. This decrease is less marked for massive galaxies. At fixed\nstellar mass, twice as many galaxies host AGN with strong [OIII] emission in\nlow density regions as in high. Massive galaxies in low-density environments\nalso contain more dust. We have analyzed correlations between spectroscopic\nindicators that probe SFH on different timescales (D4000, Hdelta_A and SFR/M*).\nThe correlations do not depend on environment, suggesting that the decrease in\nstar formation has ocurred over long (>1 Gyr) timescales. Since structure does\nnot depend on environment for more massive galaxies, trends in recent SFH, dust\nand AGN for these systems cannot be driven by processes that alter structure,\ne.g. mergers. The SFH-density correlation is strongest for small scale (< 1\nMpc) estimates of local density. Finally, we highlight a striking similarity\nbetween changes in the galaxy population as a function of density and as a\nfunction of redshift and we interpret this using N-body simulations. \n\n"}
{"id": "astro-ph/0504047", "contents": "Title: Star counts in the Galaxy. Simulating from very deep to very shallow\n  photometric surveys with the TRILEGAL code Abstract: We describe TRILEGAL, a new populations synthesis code for simulating the\nstellar photometry of any Galaxy field. The code attempts to improve upon\nseveral technical aspects of star count models, by: dealing with very complete\ninput libraries of evolutionary tracks; using a stellar spectral library to\nsimulate the photometry in any broad-band system; being very versatile allowing\neasy changes in the input libraries and in the description of all of its\ningredients -- like the SFR, AMR, IMF, and geometry of Galaxy components. In a\nprevious paper (Groenewegen et al. 2002), the code was first applied to\ndescribe the very deep star counts of the CDFS stellar catalogue. Here, we\nbriefly describe its initial calibration using EIS-deep and DMS star counts,\nwhich are adequate samples to probe both the halo and the disc components of\nlargest scale heights (oldest ages). We then present the changes in the\ncalibration that were necessary to cope with some improvements in the model\ninput data, and the use of more extensive photometry datasets: the relatively\nshallower 2MASS catalogue, which probes mostly the disc at intermediate ages,\nand the immediate solar neighbourhood as sampled by Hipparcos, which contains a\nsomewhat larger fraction of younger stars than deeper surveys. Remarkably, the\nsame model calibration can reproduce well the star counts in all the\nabove-mentioned data sets, that span from the very deep magnitudes of CDFS\n(16<R<23) to the very shallow ones of Hipparcos (V<8). Significant deviations\nare found just for fields close to the Galactic Center and Plane, and for a\nsingle set of South Galactic Pole data. The TRILEGAL code is ready to use for\nthe variety of wide-angle surveys in the optical/infrared that will become\navailable in the coming years. \n\n"}
{"id": "astro-ph/0504256", "contents": "Title: The Birth of Massive Stars and Star Clusters Abstract: In the present-day universe, it appears that most, and perhaps all, massive\nstars are born in star clusters. It also appears that all star clusters contain\nstars drawn from an approximately universal initial mass function, so that\nalmost all rich young star clusters contain massive stars. In this review I\ndiscuss the physical processes associated with both massive star formation and\nwith star cluster formation. First I summarize the observed properties of\nstar-forming gas clumps, then address the following questions. How do these\nclumps emerge from giant molecular clouds? In these clustered environments, how\ndo individual stars form and gain mass? Can a forming star cluster be treated\nas an equilibrium system or is this process too rapid for equilibrium to be\nestablished? How does feedback affect the formation process? \n\n"}
{"id": "astro-ph/0511338", "contents": "Title: The broken hierarchy of galaxy formation Abstract: Recent observations of the distant Universe suggest that much of the stellar\nmass of bright galaxies was already in place at $z>1$. This presents a\nchallenge for models of galaxy formation because massive halos are assembled\nlate in hierarchical cosmologies such as cold dark matter (CDM). In this paper,\nwe discuss a new implementation of the Durham semi-analytic model in which\nfeedback due to active galactic nuclei (AGN) is assumed to quench cooling flows\nin massive halos. This mechanism naturally creates a break in the local galaxy\nluminosity function at bright magnitudes. The model is implemented within the\nMillennium N-body simulation; the accurate dark matter merger trees and large\nnumber of realizations of the galaxy formation process that the simulation\nprovides results in highly accurate statistics. After adjusting the values of\nthe physical parameters in the model by reference to the properties of local\ngalaxies, we use it to investigate the evolution of the K-band luminosity and\ngalaxy stellar mass functions. We also calculate the volume averaged star\nformation rate density of the Universe as a function of redshift and the way in\nwhich this is apportioned amongst galaxies of different mass. The model\nrobustly predicts a substantial population of massive galaxies out to redshift\n$z\\sim 5$ and a star formation rate density which rises with increasing\nredshift in objects of all masses. Although observational data on these\nproperties have been cited as evidence for ``anti-hierarchical'' galaxy\nformation, we find that when AGN feedback is taken into account, the\nfundamentally hierachical CDM model provides a very good match to these\nobservations. \n\n"}
{"id": "astro-ph/0607107", "contents": "Title: The XMM-Newton survey of the ELAIS-S1 field. I: Number counts, angular\n  correlation function and X-ray spectral properties Abstract: We have surveyed with XMM-Newton the central ~0.6 deg2 region of the ELAIS-S1\nfield down to flux limits of ~5.5X10-16 cgs (0.5-2 keV, S band), ~2X10-15 cgs\n(2-10 keV, H band), and ~4X10-15 cgs (5-10 keV, HH band). We detect a total of\n478 sources, 395 and 205 of which detected in the S and H bands respectively.\nWe identified 7 clearly extended sources and estimated their redshift through\nX-ray spectral fits with thermal models. In four cases the redshift is\nconsistent with z=0.4. We have computed the angular correlation function of the\nsources in the S and H bands, finding best fit correlation angles\ntheta_0=5.2+/-3.8 arcsec and theta_0=12.8+/-7.8 arcsec respectively. A rough\nestimate of the present-day correlation length r_0 can be obtained inverting\nthe Limber equation and assuming an appropriate redshift distribution dN/dz.\nThe results range between 12.8 and 9.8 h-1 Mpc in the S band and between 17.9\nand 13.4 h-1 Mpc in the H band, with 30-40% statistical errors, assuming either\nsmooth redshift distributions or redshift distributions with spikes accounting\nfor the presence of a structure at z=0.4. The relative density of the S band\nsources is higher near the clusters and groups at z~0.4 and extends toward East\nand toward South/West. This suggests that the structure is complex, with a size\ncomparable to the full XMM-Newton field. Conversely, the highest relative\nsource densities of the H band sources are located in the central-west region\nof the field. \n\n"}
{"id": "astro-ph/0703255", "contents": "Title: Spectral Energy Distributions of Hard X-ray selected AGNs in the XMDS\n  Survey Abstract: We present the spectral energy distributions (SEDs) of a hard X-ray selected\nsample. The sample contains 136 sources with F(2-10 keV)>10^-14 erg/cm^2/s and\n132 are AGNs. The sources are detected in a 1 square degree area of the\nXMM-Newton-Medium Deep Survey where optical data from the VVDS, CFHTLS surveys,\nand infrared data from the SWIRE survey are available. Based on a SED fitting\ntechnique we derive photometric redshifts with sigma(1+z)=0.11 and 6% of\noutliers and identify AGN signatures in 83% of the objects. This fraction is\nhigher than derived when a spectroscopic classification is available. The\nremaining 17+9-6% of AGNs shows star-forming galaxy SEDs (SF class). The\nsources with AGN signatures are divided in two classes, AGN1 (33+6-1%) and AGN2\n(50+6-11). The AGN1 and AGN2 classes include sources whose SEDs are fitted by\ntype 1 and type 2 AGN templates, respectively. On average, AGN1s show soft\nX-ray spectra, consistent with being unabsorbed, while AGN2s and SFs show hard\nX-ray spectra, consistent with being absorbed. The analysis of the average SEDs\nas a function of X-ray luminosity shows a reddening of the IR SEDs, consistent\nwith a decreasing contribution from the host galaxy at higher luminosities. The\nAGNs in the SF classes are likely obscured in the mid-infrared, as suggested by\ntheir low L(3-20micron)/Lcorr(0.5-10 keV) ratios. We confirm the previously\nfound correlation for AGNs between the radio luminosity and the X-ray and the\nmid-infrared luminosities. The X-ray-radio correlation can be used to identify\nheavily absorbed AGNs. However, the estimated radio fluxes for the missing AGN\npopulation responsible for the bulk of the background at E>10 keV are too faint\nto be detected even in the deepest current radio surveys. \n\n"}
{"id": "math/0309285", "contents": "Title: An Algorithm for Optimal Partitioning of Data on an Interval Abstract: Many signal processing problems can be solved by maximizing the fitness of a\nsegmented model over all possible partitions of the data interval. This letter\ndescribes a simple but powerful algorithm that searches the exponentially large\nspace of partitions of $N$ data points in time $O(N^2)$. The algorithm is\nguaranteed to find the exact global optimum, automatically determines the model\norder (the number of segments), has a convenient real-time mode, can be\nextended to higher dimensional data spaces, and solves a surprising variety of\nproblems in signal detection and characterization, density estimation, cluster\nanalysis and classification. \n\n"}
{"id": "physics/0703039", "contents": "Title: TMVA - Toolkit for Multivariate Data Analysis Abstract: In high-energy physics, with the search for ever smaller signals in ever\nlarger data sets, it has become essential to extract a maximum of the available\ninformation from the data. Multivariate classification methods based on machine\nlearning techniques have become a fundamental ingredient to most analyses. Also\nthe multivariate classifiers themselves have significantly evolved in recent\nyears. Statisticians have found new ways to tune and to combine classifiers to\nfurther gain in performance. Integrated into the analysis framework ROOT, TMVA\nis a toolkit which hosts a large variety of multivariate classification\nalgorithms. Training, testing, performance evaluation and application of all\navailable classifiers is carried out simultaneously via user-friendly\ninterfaces. With version 4, TMVA has been extended to multivariate regression\nof a real-valued target vector. Regression is invoked through the same user\ninterfaces as classification. TMVA 4 also features more flexible data handling\nallowing one to arbitrarily form combined MVA methods. A generalised boosting\nmethod is the first realisation benefiting from the new framework. \n\n"}
