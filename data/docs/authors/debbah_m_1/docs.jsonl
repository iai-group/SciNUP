{"id": "0704.2017", "contents": "Title: Large System Analysis of Game-Theoretic Power Control in UWB Wireless\n  Networks with Rake Receivers Abstract: This paper studies the performance of partial-Rake (PRake) receivers in\nimpulse-radio ultrawideband wireless networks when an energy-efficient power\ncontrol scheme is adopted. Due to the large bandwidth of the system, the\nmultipath channel is assumed to be frequency-selective. By using noncooperative\ngame-theoretic models and large system analysis, explicit expressions are\nderived in terms of network parameters to measure the effects of self- and\nmultiple-access interference at a receiving access point. Performance of the\nPRake is compared in terms of achieved utilities and loss to that of the\nall-Rake receiver. \n\n"}
{"id": "0705.2594", "contents": "Title: Molecular Spiders in One Dimension Abstract: Molecular spiders are synthetic bio-molecular systems which have \"legs\" made\nof short single-stranded segments of DNA. Spiders move on a surface covered\nwith single-stranded DNA segments complementary to legs. Different mappings are\nestablished between various models of spiders and simple exclusion processes.\nFor spiders with simple gait and varying number of legs we compute the\ndiffusion coefficient; when the hopping is biased we also compute their\nvelocity. \n\n"}
{"id": "0706.2906", "contents": "Title: Capacity Scaling for MIMO Two-Way Relaying Abstract: A multiple input multiple output (MIMO) two-way relay channel is considered,\nwhere two sources want to exchange messages with each other using multiple\nrelay nodes, and both the sources and relay nodes are equipped with multiple\nantennas. Both the sources are assumed to have equal number of antennas and\nhave perfect channel state information (CSI) for all the channels of the MIMO\ntwo-way relay channel, whereas, each relay node is either assumed to have CSI\nfor its transmit and receive channel (the coherent case) or no CSI for any of\nthe channels (the non-coherent case). The main results in this paper are on the\nscaling behavior of the capacity region of the MIMO two-way relay channel with\nincreasing number of relay nodes. In the coherent case, the capacity region of\nthe MIMO two-way relay channel is shown to scale linearly with the number of\nantennas at source nodes and logarithmically with the number of relay nodes. In\nthe non-coherent case, the capacity region is shown to scale linearly with the\nnumber of antennas at the source nodes and logarithmically with the signal to\nnoise ratio. \n\n"}
{"id": "0708.0386", "contents": "Title: Diversity of MIMO Multihop Relay Channels Abstract: We consider slow fading relay channels with a single multi-antenna\nsource-destination terminal pair. The source signal arrives at the destination\nvia N hops through N-1 layers of relays. We analyze the diversity of such\nchannels with fixed network size at high SNR. In the clustered case where the\nrelays within the same layer can have full cooperation, the cooperative\ndecode-and-forward (DF) scheme is shown to be optimal in terms of the\ndiversity-multiplexing tradeoff (DMT). The upper bound on the DMT, the cut-set\nbound, is attained. In the non-clustered case, we show that the naive\namplify-and-forward (AF) scheme has the maximum multiplexing gain of the\nchannel but is suboptimal in diversity, as compared to the cut-set bound. To\nimprove the diversity, space-time relay processing is introduced through the\nparallel partition of the multihop channel. The idea is to let the source\nsignal go through K different \"AF paths\" in the multihop channel. This parallel\nAF scheme creates a parallel channel in the time domain and has the maximum\ndiversity if the partition is properly designed. Since this scheme does not\nachieve the maximum multiplexing gain in general, we propose a flip-and-forward\n(FF) scheme that is built from the parallel AF scheme. It is shown that the FF\nscheme achieves both the maximum diversity and multiplexing gains in a\ndistributed multihop channel of arbitrary size. In order to realize the DMT\npromised by the relaying strategies, approximately universal coding schemes are\nalso proposed. \n\n"}
{"id": "0708.0522", "contents": "Title: Quasi-stationary distributions as centrality measures of reducible\n  graphs Abstract: Random walk can be used as a centrality measure of a directed graph. However,\nif the graph is reducible the random walk will be absorbed in some subset of\nnodes and will never visit the rest of the graph. In Google PageRank the\nproblem was solved by introduction of uniform random jumps with some\nprobability. Up to the present, there is no clear criterion for the choice this\nparameter. We propose to use parameter-free centrality measure which is based\non the notion of quasi-stationary distribution. Specifically we suggest four\nquasi-stationary based centrality measures, analyze them and conclude that they\nproduce approximately the same ranking. The new centrality measures can be\napplied in spam detection to detect ``link farms'' and in image search to find\nphoto albums. \n\n"}
{"id": "0708.0846", "contents": "Title: Cooperative game theory and the Gaussian interference channel Abstract: In this paper we discuss the use of cooperative game theory for analyzing\ninterference channels. We extend our previous work, to games with N players as\nwell as frequency selective channels and joint TDM/FDM strategies.\n  We show that the Nash bargaining solution can be computed using convex\noptimization techniques. We also show that the same results are applicable to\ninterference channels where only statistical knowledge of the channel is\navailable. Moreover, for the special case of two players $2\\times K$ frequency\nselective channel (with K frequency bins) we provide an $O(K \\log_2 K)$\ncomplexity algorithm for computing the Nash bargaining solution under mask\nconstraint and using joint FDM/TDM strategies. Simulation results are also\nprovided. \n\n"}
{"id": "0708.1859", "contents": "Title: Multiple-Description Coding by Dithered Delta-Sigma Quantization Abstract: We address the connection between the multiple-description (MD) problem and\nDelta-Sigma quantization. The inherent redundancy due to oversampling in\nDelta-Sigma quantization, and the simple linear-additive noise model resulting\nfrom dithered lattice quantization, allow us to construct a symmetric and\ntime-invariant MD coding scheme. We show that the use of a noise shaping filter\nmakes it possible to trade off central distortion for side distortion.\nAsymptotically as the dimension of the lattice vector quantizer and order of\nthe noise shaping filter approach infinity, the entropy rate of the dithered\nDelta-Sigma quantization scheme approaches the symmetric two-channel MD\nrate-distortion function for a memoryless Gaussian source and MSE fidelity\ncriterion, at any side-to-central distortion ratio and any resolution. In the\noptimal scheme, the infinite-order noise shaping filter must be minimum phase\nand have a piece-wise flat power spectrum with a single jump discontinuity. An\nimportant advantage of the proposed design is that it is symmetric in rate and\ndistortion by construction, so the coding rates of the descriptions are\nidentical and there is therefore no need for source splitting. \n\n"}
{"id": "0708.3699", "contents": "Title: Convolutional Entanglement Distillation Abstract: We develop a theory of entanglement distillation that exploits a\nconvolutional coding structure. We provide a method for converting an arbitrary\nclassical binary or quaternary convolutional code into a convolutional\nentanglement distillation protocol. The imported classical convolutional code\ndoes not have to be dual-containing or self-orthogonal. The yield and\nerror-correcting properties of such a protocol depend respectively on the rate\nand error-correcting properties of the imported classical convolutional code. A\nconvolutional entanglement distillation protocol has several other benefits.\nTwo parties sharing noisy ebits can distill noiseless ebits ``online'' as they\nacquire more noisy ebits. Distillation yield is high and decoding complexity is\nsimple for a convolutional entanglement distillation protocol. Our theory of\nconvolutional entanglement distillation reduces the problem of finding a good\nconvolutional entanglement distillation protocol to the well-established\nproblem of finding a good classical convolutional code. \n\n"}
{"id": "0709.2833", "contents": "Title: Distributed Space Time Codes with Low Decoding Complexity for\n  Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time code (DSTC) structure that admit its application in the\nproposed transmission scheme are identified and it is pointed out that the\nrecently proposed full diversity four group decodable DSTCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time codes applicable in this new transmission scheme for\npower of two number of relays are also provided. \n\n"}
{"id": "0709.3184", "contents": "Title: Distribution functions of linear combinations of lattice polynomials\n  from the uniform distribution Abstract: We give the distribution functions, the expected values, and the moments of\nlinear combinations of lattice polynomials from the uniform distribution.\nLinear combinations of lattice polynomials, which include weighted sums, linear\ncombinations of order statistics, and lattice polynomials, are actually those\ncontinuous functions that reduce to linear functions on each simplex of the\nstandard triangulation of the unit cube. They are mainly used in aggregation\ntheory, combinatorial optimization, and game theory, where they are known as\ndiscrete Choquet integrals and Lovasz extensions. \n\n"}
{"id": "0709.3921", "contents": "Title: Geographic Gossip: Efficient Averaging for Sensor Networks Abstract: Gossip algorithms for distributed computation are attractive due to their\nsimplicity, distributed nature, and robustness in noisy and uncertain\nenvironments. However, using standard gossip algorithms can lead to a\nsignificant waste in energy by repeatedly recirculating redundant information.\nFor realistic sensor network model topologies like grids and random geometric\ngraphs, the inefficiency of gossip schemes is related to the slow mixing times\nof random walks on the communication graph. We propose and analyze an\nalternative gossiping scheme that exploits geographic information. By utilizing\ngeographic routing combined with a simple resampling method, we demonstrate\nsubstantial gains over previously proposed gossip protocols. For regular graphs\nsuch as the ring or grid, our algorithm improves standard gossip by factors of\n$n$ and $\\sqrt{n}$ respectively. For the more challenging case of random\ngeometric graphs, our algorithm computes the true average to accuracy\n$\\epsilon$ using $O(\\frac{n^{1.5}}{\\sqrt{\\log n}} \\log \\epsilon^{-1})$ radio\ntransmissions, which yields a $\\sqrt{\\frac{n}{\\log n}}$ factor improvement over\nstandard gossip algorithms. We illustrate these theoretical results with\nexperimental comparisons between our algorithm and standard methods as applied\nto various classes of random fields. \n\n"}
{"id": "0711.0557", "contents": "Title: Kerdock Codes for Limited Feedback Precoded MIMO Systems Abstract: A codebook based limited feedback strategy is a practical way to obtain\npartial channel state information at the transmitter in a precoded\nmultiple-input multiple-output (MIMO) wireless system. Conventional codebook\ndesigns use Grassmannian packing, equiangular frames, vector quantization, or\nFourier based constructions. While the capacity and error rate performance of\nconventional codebook constructions have been extensively investigated,\nconstructing these codebooks is notoriously difficult relying on techniques\nsuch as nonlinear search or iterative algorithms. Further, the resulting\ncodebooks may not have a systematic structure to facilitate storage of the\ncodebook and low search complexity. In this paper, we propose a new systematic\ncodebook design based on Kerdock codes and mutually unbiased bases. The\nproposed Kerdock codebook consists of multiple mutually unbiased unitary bases\nmatrices with quaternary entries and the identity matrix. We propose to derive\nthe beamforming and precoding codebooks from this base codebook, eliminating\nthe requirement to store multiple codebooks. The propose structure requires\nlittle memory to store and, as we show, the quaternary structure facilitates\ncodeword search. We derive the chordal distance for two antenna and four\nantenna codebooks, showing that the proposed codebooks compare favorably with\nprior designs. Monte Carlo simulations are used to compare achievable rates and\nerror rates for different codebooks sizes. \n\n"}
{"id": "0711.0708", "contents": "Title: A Rank-Metric Approach to Error Control in Random Network Coding Abstract: The problem of error control in random linear network coding is addressed\nfrom a matrix perspective that is closely related to the subspace perspective\nof K\\\"otter and Kschischang. A large class of constant-dimension subspace codes\nis investigated. It is shown that codes in this class can be easily constructed\nfrom rank-metric codes, while preserving their distance properties. Moreover,\nit is shown that minimum distance decoding of such subspace codes can be\nreformulated as a generalized decoding problem for rank-metric codes where\npartial information about the error is available. This partial information may\nbe in the form of erasures (knowledge of an error location but not its value)\nand deviations (knowledge of an error value but not its location). Taking\nerasures and deviations into account (when they occur) strictly increases the\nerror correction capability of a code: if $\\mu$ erasures and $\\delta$\ndeviations occur, then errors of rank $t$ can always be corrected provided that\n$2t \\leq d - 1 + \\mu + \\delta$, where $d$ is the minimum rank distance of the\ncode. For Gabidulin codes, an important family of maximum rank distance codes,\nan efficient decoding algorithm is proposed that can properly exploit erasures\nand deviations. In a network coding application where $n$ packets of length $M$\nover $F_q$ are transmitted, the complexity of the decoding algorithm is given\nby $O(dM)$ operations in an extension field $F_{q^n}$. \n\n"}
{"id": "0711.1383", "contents": "Title: On Minimal Tree Realizations of Linear Codes Abstract: A tree decomposition of the coordinates of a code is a mapping from the\ncoordinate set to the set of vertices of a tree. A tree decomposition can be\nextended to a tree realization, i.e., a cycle-free realization of the code on\nthe underlying tree, by specifying a state space at each edge of the tree, and\na local constraint code at each vertex of the tree. The constraint complexity\nof a tree realization is the maximum dimension of any of its local constraint\ncodes. A measure of the complexity of maximum-likelihood decoding for a code is\nits treewidth, which is the least constraint complexity of any of its tree\nrealizations.\n  It is known that among all tree realizations of a code that extends a given\ntree decomposition, there exists a unique minimal realization that minimizes\nthe state space dimension at each vertex of the underlying tree. In this paper,\nwe give two new constructions of these minimal realizations. As a by-product of\nthe first construction, a generalization of the state-merging procedure for\ntrellis realizations, we obtain the fact that the minimal tree realization also\nminimizes the local constraint code dimension at each vertex of the underlying\ntree. The second construction relies on certain code decomposition techniques\nthat we develop. We further observe that the treewidth of a code is related to\na measure of graph complexity, also called treewidth. We exploit this\nconnection to resolve a conjecture of Forney's regarding the gap between the\nminimum trellis constraint complexity and the treewidth of a code. We present a\nfamily of codes for which this gap can be arbitrarily large. \n\n"}
{"id": "0801.2480", "contents": "Title: Asynchronous Iterative Waterfilling for Gaussian Frequency-Selective\n  Interference Channels Abstract: This paper considers the maximization of information rates for the Gaussian\nfrequency-selective interference channel, subject to power and spectral mask\nconstraints on each link. To derive decentralized solutions that do not require\nany cooperation among the users, the optimization problem is formulated as a\nstatic noncooperative game of complete information. To achieve the so-called\nNash equilibria of the game, we propose a new distributed algorithm called\nasynchronous iterative waterfilling algorithm. In this algorithm, the users\nupdate their power spectral density in a completely distributed and\nasynchronous way: some users may update their power allocation more frequently\nthan others and they may even use outdated measurements of the received\ninterference. The proposed algorithm represents a unified framework that\nencompasses and generalizes all known iterative waterfilling algorithms, e.g.,\nsequential and simultaneous versions. The main result of the paper consists of\na unified set of conditions that guarantee the global converge of the proposed\nalgorithm to the (unique) Nash equilibrium of the game. \n\n"}
{"id": "0801.4400", "contents": "Title: Canonical moments and random spectral measures Abstract: We study some connections between the random moment problem and the random\nmatrix theory. A uniform draw in a space of moments can be lifted into the\nspectral probability measure of the pair (A,e) where A is a random matrix from\na classical ensemble and e is a fixed unit vector. This random measure is a\nweighted sampling among the eigenvalues of A. We also study the large\ndeviations properties of this random measure when the dimension of the matrix\ngrows. The rate function for these large deviations involves the reversed\nKullback information. \n\n"}
{"id": "0802.2159", "contents": "Title: A Distributed Merge and Split Algorithm for Fair Cooperation in Wireless\n  Networks Abstract: This paper introduces a novel concept from coalitional game theory which\nallows the dynamic formation of coalitions among wireless nodes. A simple and\ndistributed merge and split algorithm for coalition formation is constructed.\nThis algorithm is applied to study the gains resulting from the cooperation\namong single antenna transmitters for virtual MIMO formation. The aim is to\nfind an ultimate transmitters coalition structure that allows cooperating users\nto maximize their utilities while accounting for the cost of coalition\nformation. Through this novel game theoretical framework, the wireless network\ntransmitters are able to self-organize and form a structured network composed\nof disjoint stable coalitions. Simulation results show that the proposed\nalgorithm can improve the average individual user utility by 26.4% as well as\ncope with the mobility of the distributed users. \n\n"}
{"id": "0804.1183", "contents": "Title: Hash Property and Fixed-rate Universal Coding Theorems Abstract: The aim of this paper is to prove the achievability of fixed-rate universal\ncoding problems by using our previously introduced notion of hash property.\nThese problems are the fixed-rate lossless universal source coding problem and\nthe fixed-rate universal channel coding problem. Since an ensemble of sparse\nmatrices satisfies the hash property requirement, it is proved that we can\nconstruct universal codes by using sparse matrices. \n\n"}
{"id": "0804.1602", "contents": "Title: Multiterminal source coding with complementary delivery Abstract: A coding problem for correlated information sources is investigated. Messages\nemitted from two correlated sources are jointly encoded, and delivered to two\ndecoders. Each decoder has access to one of the two messages to enable it to\nreproduce the other message. The rate-distortion function for the coding\nproblem and its interesting properties are clarified. \n\n"}
{"id": "0804.2310", "contents": "Title: Bounds for the loss probability in large loss queueing systems Abstract: Let $\\mathcal{G}(\\frak{g}_1,\\frak{g}_2)$ be the class of all probability\ndistribution functions of positive random variables having the given first two\nmoments $\\frak{g}_1$ and $\\frak{g}_2$. Let $G_1(x)$ and $G_2(x)$ be two\nprobability distribution functions of this class satisfying the condition\n$|G_1(x)-G_2(x)|<\\epsilon$ for some small positive value $\\epsilon$ and let\n$\\widehat{G}_1(s)$ and, respectively, $\\widehat{G}_2(s)$ denote their\nLaplace-Stieltjes transforms. For real $\\mu$ satisfying $\\mu\\frak{g}_1>1$ let\nus denote by $\\gamma_{G_1}$ and $\\gamma_{G_2}$ the least positive roots of the\nequations $z=\\widehat{G}_1(\\mu-\\mu z)$ and $z=\\widehat{G}_2(\\mu-\\mu z)$\nrespectively. In the paper, the upper bound for $|\\gamma_{G_1}-\\gamma_{G_2}|$\nis derived. This upper bound is then used to find lower and upper bounds for\nthe loss probabilities in different large loss queueing systems. \n\n"}
{"id": "0805.1209", "contents": "Title: Scaling Laws for Overlaid Wireless Networks: A Cognitive Radio Network\n  vs. a Primary Network Abstract: We study the scaling laws for the throughputs and delays of two coexisting\nwireless networks that operate in the same geographic region. The primary\nnetwork consists of Poisson distributed legacy users of density n, and the\nsecondary network consists of Poisson distributed cognitive users of density m,\nwith m>n. The primary users have a higher priority to access the spectrum\nwithout particular considerations for the secondary users, while the secondary\nusers have to act conservatively in order to limit the interference to the\nprimary users. With a practical assumption that the secondary users only know\nthe locations of the primary transmitters (not the primary receivers), we first\nshow that both networks can achieve the same throughput scaling law as what\nGupta and Kumar [1] established for a stand-alone wireless network if proper\ntransmission schemes are deployed, where a certain throughput is achievable for\neach individual secondary user (i.e., zero outage) with high probability. By\nusing a fluid model, we also show that both networks can achieve the same\ndelay-throughput tradeoff as the optimal one established by El Gamal et al. [2]\nfor a stand-alone wireless network. \n\n"}
{"id": "0807.0204", "contents": "Title: Diversity Multiplexing Tradeoff of Asynchronous Cooperative Relay\n  Networks Abstract: The assumption of nodes in a cooperative communication relay network\noperating in synchronous fashion is often unrealistic. In the present paper, we\nconsider two different models of asynchronous operation in\ncooperative-diversity networks experiencing slow fading and examine the\ncorresponding diversity-multiplexing tradeoffs (DMT). For both models, we\npropose protocols and distributed space-time codes that asymptotically achieve\nthe transmit diversity bound for all multiplexing gains and for any number of\nrelays. \n\n"}
{"id": "0807.0821", "contents": "Title: On Wiretap Networks II Abstract: We consider the problem of securing a multicast network against a wiretapper\nthat can intercept the packets on a limited number of arbitrary network links\nof his choice. We assume that the network implements network coding techniques\nto simultaneously deliver all the packets available at the source to all the\ndestinations. We show how this problem can be looked at as a network\ngeneralization of the Ozarow-Wyner Wiretap Channel of type II. In particular,\nwe show that network security can be achieved by using the Ozarow-Wyner\napproach of coset coding at the source on top of the implemented network code.\nThis way, we quickly and transparently recover some of the results available in\nthe literature on secure network coding for wiretapped networks. We also derive\nnew bounds on the required secure code alphabet size and an algorithm for code\nconstruction. \n\n"}
{"id": "0808.1495", "contents": "Title: The finite harmonic oscillator and its applications to sequences,\n  communication and radar Abstract: A novel system, called the oscillator system, consisting of order of p^3\nfunctions (signals) on the finite field F_p; with p an odd prime, is described\nand studied. The new functions are proved to satisfy good auto-correlation,\ncross-correlation and low peak-to-average power ratio properties. Moreover, the\noscillator system is closed under the operation of discrete Fourier transform.\nApplications of the oscillator system for discrete radar and digital\ncommunication theory are explained. Finally, an explicit algorithm to construct\nthe oscillator system is presented. \n\n"}
{"id": "0808.2181", "contents": "Title: Spectrum Sharing Between Cellular and Mobile Ad Hoc Networks:\n  Transmission-Capacity Trade-Off Abstract: Spectrum sharing between wireless networks improves the efficiency of\nspectrum usage, and thereby alleviates spectrum scarcity due to growing demands\nfor wireless broadband access. To improve the usual underutilization of the\ncellular uplink spectrum, this paper studies spectrum sharing between a\ncellular uplink and a mobile ad hoc networks. These networks access either all\nfrequency sub-channels or their disjoint sub-sets, called spectrum underlay and\nspectrum overlay, respectively. Given these spectrum sharing methods, the\ncapacity trade-off between the coexisting networks is analyzed based on the\ntransmission capacity of a network with Poisson distributed transmitters. This\nmetric is defined as the maximum density of transmitters subject to an outage\nconstraint for a given signal-to-interference ratio (SIR). Using tools from\nstochastic geometry, the transmission-capacity trade-off between the coexisting\nnetworks is analyzed, where both spectrum overlay and underlay as well as\nsuccessive interference cancelation (SIC) are considered. In particular, for\nsmall target outage probability, the transmission capacities of the coexisting\nnetworks are proved to satisfy a linear equation, whose coefficients depend on\nthe spectrum sharing method and whether SIC is applied. This linear equation\nshows that spectrum overlay is more efficient than spectrum underlay.\nFurthermore, this result also provides insight into the effects of different\nnetwork parameters on transmission capacities, including link diversity gains,\ntransmission distances, and the base station density. In particular, SIC is\nshown to increase transmission capacities of both coexisting networks by a\nlinear factor, which depends on the interference-power threshold for qualifying\ncanceled interferers. \n\n"}
{"id": "0809.1258", "contents": "Title: Network Protection Codes Against Link Failures Using Network Coding Abstract: Protecting against link failures in communication networks is essential to\nincrease robustness, accessibility, and reliability of data transmission.\nRecently, network coding has been proposed as a solution to provide agile and\ncost efficient network protection against link failures, which does not require\ndata rerouting, or packet retransmission. To achieve this, separate paths have\nto be provisioned to carry encoded packets, hence requiring either the addition\nof extra links, or reserving some of the resources for this purpose. In this\npaper, we propose network protection codes against a single link failure using\nnetwork coding, where a separate path using reserved links is not needed. In\nthis case portions of the link capacities are used to carry the encoded\npackets.\n  The scheme is extended to protect against multiple link failures and can be\nimplemented at an overlay layer. Although this leads to reducing the network\ncapacity, the network capacity reduction is asymptotically small in most cases\nof practical interest. We demonstrate that such network protection codes are\nequivalent to error correcting codes for erasure channels. Finally, we study\nthe encoding and decoding operations of such codes over the binary field. \n\n"}
{"id": "0809.1366", "contents": "Title: Network Coding Security: Attacks and Countermeasures Abstract: By allowing intermediate nodes to perform non-trivial operations on packets,\nsuch as mixing data from multiple streams, network coding breaks with the\nruling store and forward networking paradigm and opens a myriad of challenging\nsecurity questions. Following a brief overview of emerging network coding\nprotocols, we provide a taxonomy of their security vulnerabilities, which\nhighlights the differences between attack scenarios in which network coding is\nparticularly vulnerable and other relevant cases in which the intrinsic\nproperties of network coding allow for stronger and more efficient security\nsolutions than classical routing. Furthermore, we give practical examples where\nnetwork coding can be combined with classical cryptography both for secure\ncommunication and secret key distribution. Throughout the paper we identify a\nnumber of research challenges deemed relevant towards the applicability of\nsecure network coding in practical networks. \n\n"}
{"id": "0809.4316", "contents": "Title: A Layered Lattice Coding Scheme for a Class of Three User Gaussian\n  Interference Channels Abstract: The paper studies a class of three user Gaussian interference channels. A new\nlayered lattice coding scheme is introduced as a transmission strategy. The use\nof lattice codes allows for an \"alignment\" of the interference observed at each\nreceiver. The layered lattice coding is shown to achieve more than one degree\nof freedom for a class of interference channels and also achieves rates which\nare better than the rates obtained using the Han-Kobayashi coding scheme. \n\n"}
{"id": "0810.4112", "contents": "Title: Sums of residues on algebraic surfaces and application to coding theory Abstract: In this paper, we study residues of differential 2-forms on a smooth\nalgebraic surface over an arbitrary field and give several statements about\nsums of residues. Afterwards, using these results we construct\nalgebraic-geometric codes which are an extension to surfaces of the well-known\ndifferential codes on curves. We also study some properties of these codes and\nextend to them some known properties for codes on curves. \n\n"}
{"id": "0811.0662", "contents": "Title: Asymptotics for Kotz Type III Elliptical Distributions Abstract: In this paper we derive the tail asymptotics of a Kotz Type III elliptical\nrandom vector. As an application of our asymptotic expansion we derive an\napproximation for the conditional excess distribution. Furthermore, we discuss\nthe asymptotic dependence of Kotz Type III triangular arrays and provide some\ndetails on the estimation of conditional excess distribution and survivor\nfunction. \n\n"}
{"id": "0811.0726", "contents": "Title: Improved Capacity Scaling in Wireless Networks With Infrastructure Abstract: This paper analyzes the impact and benefits of infrastructure support in\nimproving the throughput scaling in networks of $n$ randomly located wireless\nnodes. The infrastructure uses multi-antenna base stations (BSs), in which the\nnumber of BSs and the number of antennas at each BS can scale at arbitrary\nrates relative to $n$. Under the model, capacity scaling laws are analyzed for\nboth dense and extended networks. Two BS-based routing schemes are first\nintroduced in this study: an infrastructure-supported single-hop (ISH) routing\nprotocol with multiple-access uplink and broadcast downlink and an\ninfrastructure-supported multi-hop (IMH) routing protocol. Then, their\nachievable throughput scalings are analyzed. These schemes are compared against\ntwo conventional schemes without BSs: the multi-hop (MH) transmission and\nhierarchical cooperation (HC) schemes. It is shown that a linear throughput\nscaling is achieved in dense networks, as in the case without help of BSs. In\ncontrast, the proposed BS-based routing schemes can, under realistic network\nconditions, improve the throughput scaling significantly in extended networks.\nThe gain comes from the following advantages of these BS-based protocols.\nFirst, more nodes can transmit simultaneously in the proposed scheme than in\nthe MH scheme if the number of BSs and the number of antennas are large enough.\nSecond, by improving the long-distance signal-to-noise ratio (SNR), the\nreceived signal power can be larger than that of the HC, enabling a better\nthroughput scaling under extended networks. Furthermore, by deriving the\ncorresponding information-theoretic cut-set upper bounds, it is shown under\nextended networks that a combination of four schemes IMH, ISH, MH, and HC is\norder-optimal in all operating regimes. \n\n"}
{"id": "0811.0731", "contents": "Title: Cognitive OFDM network sensing: a free probability approach Abstract: In this paper, a practical power detection scheme for OFDM terminals, based\non recent free probability tools, is proposed. The objective is for the\nreceiving terminal to determine the transmission power and the number of the\nsurrounding base stations in the network. However, thesystem dimensions of the\nnetwork model turn energy detection into an under-determined problem. The focus\nof this paper is then twofold: (i) discuss the maximum amount of information\nthat an OFDM terminal can gather from the surrounding base stations in the\nnetwork, (ii) propose a practical solution for blind cell detection using the\nfree deconvolution tool. The efficiency of this solution is measured through\nsimulations, which show better performance than the classical power detection\nmethods. \n\n"}
{"id": "0811.0778", "contents": "Title: A maximum entropy approach to OFDM channel estimation Abstract: In this work, a new Bayesian framework for OFDM channel estimation is\nproposed. Using Jaynes' maximum entropy principle to derive prior information,\nwe successively tackle the situations when only the channel delay spread is a\npriori known, then when it is not known. Exploitation of the time-frequency\ndimensions are also considered in this framework, to derive the optimal channel\nestimation associated to some performance measure under any state of knowledge.\nSimulations corroborate the optimality claim and always prove as good or better\nin performance than classical estimators. \n\n"}
{"id": "0811.1317", "contents": "Title: Secrecy in Cooperative Relay Broadcast Channels Abstract: We investigate the effects of user cooperation on the secrecy of broadcast\nchannels by considering a cooperative relay broadcast channel. We show that\nuser cooperation can increase the achievable secrecy region. We propose an\nachievable scheme that combines Marton's coding scheme for broadcast channels\nand Cover and El Gamal's compress-and-forward scheme for relay channels. We\nderive outer bounds for the rate-equivocation region using auxiliary random\nvariables for single-letterization. Finally, we consider a Gaussian channel and\nshow that both users can have positive secrecy rates, which is not possible for\nscalar Gaussian broadcast channels without cooperation. \n\n"}
{"id": "0811.1696", "contents": "Title: Measure changes with extinction Abstract: We consider a change of measure by a martingale $Z_t$ and clarify that in\ngeneral $1/Z_t$ is only a supermartingale under the changed measure. We then\ngive a necessary and sufficient condition for the event that the limit of the\nmartingale is zero to coincide with the event that the martingale hits zero in\nfinite time (up to a set of zero probability). \n\n"}
{"id": "0811.2097", "contents": "Title: A Central Limit Theorem, and related results, for a two-color randomly\n  reinforced urn Abstract: We prove a Central Limit Theorem for the sequence of random compositions of a\ntwo-color randomly reinforced urn. As a consequence, we are able to show that\nthe distribution of the urn limit composition has no point masses. \n\n"}
{"id": "0811.2733", "contents": "Title: Slow decay of Gibbs measures with heavy tails Abstract: We consider Glauber dynamics reversible with respect to Gibbs measures with\nheavy tails. Spins are unbounded. The interactions are bounded and finite\nrange. The self potential enters into two classes of measures, $\\kappa$-concave\nprobability measure and sub-exponential laws, for which it is known that no\nexponential decay can occur. We prove, using coercive inequalities, that the\nassociated infinite volume semi-group decay to equilibrium polynomially and\nstretched exponentially, respectively. Thus improving and extending previous\nresults by Bobkov and Zegarlinski. \n\n"}
{"id": "0812.1778", "contents": "Title: The Impact of QoS Constraints on the Energy Efficiency of Fixed-Rate\n  Wireless Transmissions Abstract: Transmission over wireless fading channels under quality of service (QoS)\nconstraints is studied when only the receiver has channel side information.\nBeing unaware of the channel conditions, transmitter is assumed to send the\ninformation at a fixed rate. Under these assumptions, a two-state (ON-OFF)\ntransmission model is adopted, where information is transmitted reliably at a\nfixed rate in the ON state while no reliable transmission occurs in the OFF\nstate. QoS limitations are imposed as constraints on buffer violation\nprobabilities, and effective capacity formulation is used to identify the\nmaximum throughput that a wireless channel can sustain while satisfying\nstatistical QoS constraints. Energy efficiency is investigated by obtaining the\nbit energy required at zero spectral efficiency and the wideband slope in both\nwideband and low-power regimes assuming that the receiver has perfect channel\nside information (CSI). In both wideband and low-power regimes, the increased\nenergy requirements due to the presence of QoS constraints are quantified.\nComparisons with variable-rate/fixed-power and variable-rate/variable-power\ncases are given. Energy efficiency is further analyzed in the presence of\nchannel uncertainties. The optimal fraction of power allocated to training is\nidentified under QoS constraints. It is proven that the minimum bit energy in\nthe low-power regime is attained at a certain nonzero power level below which\nbit energy increases without bound with vanishing power. \n\n"}
{"id": "0901.1936", "contents": "Title: A Lower Bound on the Capacity of Wireless Erasure Networks with Random\n  Node Locations Abstract: In this paper, a lower bound on the capacity of wireless ad hoc erasure\nnetworks is derived in closed form in the canonical case where $n$ nodes are\nuniformly and independently distributed in the unit area square. The bound\nholds almost surely and is asymptotically tight. We assume all nodes have fixed\ntransmit power and hence two nodes should be within a specified distance $r_n$\nof each other to overcome noise. In this context, interference determines\noutages, so we model each transmitter-receiver pair as an erasure channel with\na broadcast constraint, i.e. each node can transmit only one signal across all\nits outgoing links. A lower bound of $\\Theta(n r_n)$ for the capacity of this\nclass of networks is derived. If the broadcast constraint is relaxed and each\nnode can send distinct signals on distinct outgoing links, we show that the\ngain is a function of $r_n$ and the link erasure probabilities, and is at most\na constant if the link erasure probabilities grow sufficiently large with $n$.\nFinally, the case where the erasure probabilities are themselves random\nvariables, for example due to randomness in geometry or channels, is analyzed.\nWe prove somewhat surprisingly that in this setting, variability in erasure\nprobabilities increases network capacity. \n\n"}
{"id": "0901.2147", "contents": "Title: Bit Precision Analysis for Compressed Sensing Abstract: This paper studies the stability of some reconstruction algorithms for\ncompressed sensing in terms of the bit precision. Considering the fact that\npractical digital systems deal with discretized signals, we motivate the\nimportance of the total number of accurate bits needed from the measurement\noutcomes in addition to the number of measurements. It is shown that if one\nuses a $2k \\times n$ Vandermonde matrix with roots on the unit circle as the\nmeasurement matrix, $O(\\ell + k \\log(n/k))$ bits of precision per measurement\nare sufficient to reconstruct a $k$-sparse signal $x \\in \\R^n$ with dynamic\nrange (i.e., the absolute ratio between the largest and the smallest nonzero\ncoefficients) at most $2^\\ell$ within $\\ell$ bits of precision, hence\nidentifying its correct support. Finally, we obtain an upper bound on the total\nnumber of required bits when the measurement matrix satisfies a restricted\nisometry property, which is in particular the case for random Fourier and\nGaussian matrices. For very sparse signals, the upper bound on the number of\nrequired bits for Vandermonde matrices is shown to be better than this general\nupper bound. \n\n"}
{"id": "0901.4068", "contents": "Title: On the Sum Capacity of A Class of Cyclically Symmetric Deterministic\n  Interference Channels Abstract: Certain deterministic interference channels have been shown to accurately\nmodel Gaussian interference channels in the asymptotic low-noise regime.\nMotivated by this correspondence, we investigate a K user-pair, cyclically\nsymmetric, deterministic interference channel in which each receiver\nexperiences interference only from its neighboring transmitters (Wyner model).\nWe establish the sum capacity for a large set of channel parameters, thus\ngeneralizing previous results for the 2-pair case. \n\n"}
{"id": "0903.1972", "contents": "Title: On Competing Wireless Service Providers Abstract: We consider a situation where wireless service providers compete for\nheterogenous wireless users. The users differ in their willingness to pay as\nwell as in their individual channel gains. We prove existence and uniqueness of\nthe Nash equilibrium for the competition of two service providers, for a\ngeneric channel model. Interestingly, the competition of two providers leads to\na globally optimal outcome. We extend some of the results to the case where\nmore than two providers are competing. Finally, we provide numerical examples\nthat illustrate the effects of various parameters on the Nash equilibrium. \n\n"}
{"id": "0903.2174", "contents": "Title: Game theory and the frequency selective interference channel - A\n  tutorial Abstract: This paper provides a tutorial overview of game theoretic techniques used for\ncommunication over frequency selective interference channels. We discuss both\ncompetitive and cooperative techniques.\n  Keywords: Game theory, competitive games, cooperative games, Nash\nEquilibrium, Nash bargaining solution, Generalized Nash games, Spectrum\noptimization, distributed coordination, interference channel, multiple access\nchannel, iterative water-filling. \n\n"}
{"id": "0903.2174", "contents": "Title: Game theory and the frequency selective interference channel - A\n  tutorial Abstract: This paper provides a tutorial overview of game theoretic techniques used for\ncommunication over frequency selective interference channels. We discuss both\ncompetitive and cooperative techniques.\n  Keywords: Game theory, competitive games, cooperative games, Nash\nEquilibrium, Nash bargaining solution, Generalized Nash games, Spectrum\noptimization, distributed coordination, interference channel, multiple access\nchannel, iterative water-filling. \n\n"}
{"id": "0903.2352", "contents": "Title: A Mean Field Approach for Optimization in Particles Systems and\n  Applications Abstract: This paper investigates the limit behavior of Markov Decision Processes\n(MDPs) made of independent particles evolving in a common environment, when the\nnumber of particles goes to infinity. In the finite horizon case or with a\ndiscounted cost and an infinite horizon, we show that when the number of\nparticles becomes large, the optimal cost of the system converges almost surely\nto the optimal cost of a discrete deterministic system (the ``optimal mean\nfield''). Convergence also holds for optimal policies. We further provide\ninsights on the speed of convergence by proving several central limits theorems\nfor the cost and the state of the Markov decision process with explicit\nformulas for the variance of the limit Gaussian laws. Then, our framework is\napplied to a brokering problem in grid computing. The optimal policy for the\nlimit deterministic system is computed explicitly. Several simulations with\ngrowing numbers of processors are reported. They compare the performance of the\noptimal policy of the limit system used in the finite case with classical\npolicies (such as Join the Shortest Queue) by measuring its asymptotic gain as\nwell as the threshold above which it starts outperforming classical policies. \n\n"}
{"id": "0903.5066", "contents": "Title: Modified-CS: Modifying Compressive Sensing for Problems with Partially\n  Known Support Abstract: We study the problem of reconstructing a sparse signal from a limited number\nof its linear projections when a part of its support is known, although the\nknown part may contain some errors. The ``known\" part of the support, denoted\nT, may be available from prior knowledge. Alternatively, in a problem of\nrecursively reconstructing time sequences of sparse spatial signals, one may\nuse the support estimate from the previous time instant as the ``known\" part.\nThe idea of our proposed solution (modified-CS) is to solve a convex relaxation\nof the following problem: find the signal that satisfies the data constraint\nand is sparsest outside of T. We obtain sufficient conditions for exact\nreconstruction using modified-CS. These are much weaker than those needed for\ncompressive sensing (CS) when the sizes of the unknown part of the support and\nof errors in the known part are small compared to the support size. An\nimportant extension called Regularized Modified-CS (RegModCS) is developed\nwhich also uses prior signal estimate knowledge. Simulation comparisons for\nboth sparse and compressible signals are shown. \n\n"}
{"id": "0904.3356", "contents": "Title: A method for Hedging in continuous time Abstract: We present a method for hedging in continuous time. \n\n"}
{"id": "0905.0374", "contents": "Title: Interference Alignment with Limited Feedback Abstract: We consider single-antenna interference networks where M sources, each with\nan average transmit power of P/M, communicate with M destinations over\nfrequency-selective channels (with L taps each) and each destination has\nperfect knowledge of its channels from each of the sources. Assuming that there\nexist error-free non-interfering broadcast feedback links from each destination\nto all the nodes (i.e., sources and destinations) in the network, we show that\nnaive interference alignment, in conjunction with vector quantization of the\nimpulse response coefficients according to the scheme proposed in Mukkavilli et\nal., IEEE Trans. IT, 2003, achieves full spatial multiplexing gain of M/2,\nprovided that the number of feedback bits broadcast by each destination is at\nleast M(L-1) log P. \n\n"}
{"id": "0906.0744", "contents": "Title: Ergodic Fading Interference Channels: Sum-Capacity and Separability Abstract: The sum-capacity for specific sub-classes of ergodic fading Gaussian two-user\ninterference channels (IFCs) is developed under the assumption of perfect\nchannel state information at all transmitters and receivers. For the\nsub-classes of uniformly strong (every fading state is strong) and ergodic very\nstrong two-sided IFCs (a mix of strong and weak fading states satisfying\nspecific fading averaged conditions) the optimality of completely decoding the\ninterference, i.e., converting the IFC to a compound multiple access channel\n(C-MAC), is proved. It is also shown that this capacity-achieving scheme\nrequires encoding and decoding jointly across all fading states. As an\nachievable scheme and also as a topic of independent interest, the capacity\nregion and the corresponding optimal power policies for an ergodic fading C-MAC\nare developed. For the sub-class of uniformly weak IFCs (every fading state is\nweak), genie-aided outer bounds are developed. The bounds are shown to be\nachieved by treating interference as noise and by separable coding for\none-sided fading IFCs. Finally, for the sub-class of one-sided hybrid IFCs (a\nmix of weak and strong states that do not satisfy ergodic very strong\nconditions), an achievable scheme involving rate splitting and joint coding\nacross all fading states is developed and is shown to perform at least as well\nas a separable coding scheme. \n\n"}
{"id": "0906.1244", "contents": "Title: Generalised Pinsker Inequalities Abstract: We generalise the classical Pinsker inequality which relates variational\ndivergence to Kullback-Liebler divergence in two ways: we consider arbitrary\nf-divergences in place of KL divergence, and we assume knowledge of a sequence\nof values of generalised variational divergences. We then develop a best\npossible inequality for this doubly generalised situation. Specialising our\nresult to the classical case provides a new and tight explicit bound relating\nKL to variational divergence (solving a problem posed by Vajda some 40 years\nago). The solution relies on exploiting a connection between divergences and\nthe Bayes risk of a learning problem via an integral representation. \n\n"}
{"id": "0906.4353", "contents": "Title: Parameter Estimation in Diagonalizable Stochastic Hyperbolic Equations Abstract: A parameter estimation problem is considered for a linear stochastic\nhyperbolic equation driven by additive space-time Gaussian white noise. The\ndamping/amplification operator is allowed to be unbounded.\n  The estimator is of spectral type and utilizes a finite number of the spatial\nFourier coefficients of the solution. The asymptotic properties of the\nestimator are studied as the number of the Fourier coefficients increases,\nwhile the observation time and the noise intensity are fixed. \n\n"}
{"id": "0906.4541", "contents": "Title: Covariance function of vector self-similar process Abstract: The paper obtains the general form of the cross-covariance function of vector\nfractional Brownian motion with correlated components having different\nself-similarity indices. \n\n"}
{"id": "0906.4827", "contents": "Title: Physical Layer Security: Coalitional Games for Distributed Cooperation Abstract: Cooperation between wireless network nodes is a promising technique for\nimproving the physical layer security of wireless transmission, in terms of\nsecrecy capacity, in the presence of multiple eavesdroppers. While existing\nphysical layer security literature answered the question \"what are the\nlink-level secrecy capacity gains from cooperation?\", this paper attempts to\nanswer the question of \"how to achieve those gains in a practical decentralized\nwireless network and in the presence of a secrecy capacity cost for information\nexchange?\". For this purpose, we model the physical layer security cooperation\nproblem as a coalitional game with non-transferable utility and propose a\ndistributed algorithm for coalition formation. Through the proposed algorithm,\nthe wireless users can autonomously cooperate and self-organize into disjoint\nindependent coalitions, while maximizing their secrecy capacity taking into\naccount the security costs during information exchange. We analyze the\nresulting coalitional structures, discuss their properties, and study how the\nusers can self-adapt the network topology to environmental changes such as\nmobility. Simulation results show that the proposed algorithm allows the users\nto cooperate and self-organize while improving the average secrecy capacity per\nuser up to 25.32% relative to the non-cooperative case. \n\n"}
{"id": "0907.0505", "contents": "Title: Multi-User MISO Interference Channels with Single-User Detection:\n  Optimality of Beamforming and the Achievable Rate Region Abstract: For a multi-user interference channel with multi-antenna transmitters and\nsingle-antenna receivers, by restricting each transmitter to Gaussian input and\neach receiver to a single-user detector, computing the largest achievable rate\nregion amounts to solving a family of non-convex optimization problems.\nRecognizing the intrinsic connection between the signal power at the intended\nreceiver and the interference power at the unintended receiver, the original\nfamily of non-convex optimization problems is converted into a new family of\nconvex optimization problems. It is shown that, for such interference channels\nwith each receiver implementing single-user detection, transmitter beamforming\ncan achieve all boundary points of the achievable rate region. \n\n"}
{"id": "0907.1523", "contents": "Title: Theoretical Performance Analysis of Eigenvalue-based Detection Abstract: In this paper we develop a complete analytical framework based on Random\nMatrix Theory for the performance evaluation of Eigenvalue-based Detection.\nWhile, up to now, analysis was limited to false-alarm probability, we have\nobtained an analytical expression also for the probability of missed detection,\nby using the theory of spiked population models. A general scenario with\nmultiple signals present at the same time is considered. The theoretical\nresults of this paper allow to predict the error probabilities, and to set the\ndecision threshold accordingly, by means of a few mathematical formulae. In\nthis way the design of an eigenvalue-based detector is made conceptually\nidentical to that of a traditional energy detector. As additional results, the\npaper discusses the conditions of signal identifiability for single and\nmultiple sources. All the analytical results are validated through numerical\nsimulations, covering also convergence, identifiabilty and non-Gaussian\npractical modulations. \n\n"}
{"id": "0907.3387", "contents": "Title: Correcting Limited-Magnitude Errors in the Rank-Modulation Scheme Abstract: We study error-correcting codes for permutations under the infinity norm,\nmotivated by a novel storage scheme for flash memories call rank modulation. In\nthis scheme, a set of $n$ flash cells are combined to create a single virtual\nmulti-level cell. Information is stored in the permutation induced by the cell\ncharge levels. Spike errors, which are characterized by a limited-magnitude\nchange in cell charge levels, correspond to a low-distance change under the\ninfinity norm.\n  We define codes protecting against spike errors, called limited-magnitude\nrank-modulation codes (LMRM codes), and present several constructions for these\ncodes, some resulting in optimal codes. These codes admit simple recursive, and\nsometimes direct, encoding and decoding procedures.\n  We also provide lower and upper bounds on the maximal size of LMRM codes both\nin the general case, and in the case where the codes form a subgroup of the\nsymmetric group. In the asymptotic analysis, the codes we construct out-perform\nthe Gilbert-Varshamov-like bound estimate. \n\n"}
{"id": "0908.0358", "contents": "Title: Outage analysis of Block-Fading Gaussian Interference Channels Abstract: This paper considers the asymptotic behavior of two-source block-fading\nsingle-antenna Gaussian interference channels in the high-SNR regime by means\nof the diversity-multiplexing tradeoff. We consider a general setting where the\nusers and the average channel gains are not restricted to be symmetric. Our\nresults are not just extensions of previous results for symmetric networks, as\nour setting covers scenarios that are not possible under the symmetric\nassumption, such as the case of \"mixed\" interference, i.e., when difference\nsources have different distances from their intended receivers. We derive upper\nand lower bounds on the diversity. We show that for a fairly large set of\nchannel parameters the two bounds coincides. \n\n"}
{"id": "0908.2282", "contents": "Title: Real Interference Alignment: Exploiting the Potential of Single Antenna\n  Systems Abstract: In this paper, the available spatial Degrees-Of-Freedoms (DOF) in single\nantenna systems is exploited. A new coding scheme is proposed in which several\ndata streams having fractional multiplexing gains are sent by transmitters and\ninterfering streams are aligned at receivers. Viewed as a field over rational\nnumbers, a received signal has infinite fractional DOFs, allowing simultaneous\ninterference alignment of any finite number of signals at any finite number of\nreceivers. The coding scheme is backed up by a recent result in the field of\nDiophantine approximation, which states that the convergence part of the\nKhintchine-Groshev theorem holds for points on non-degenerate manifolds. The\nproposed coding scheme is proved to be optimal for three communication\nchannels, namely the Gaussian Interference Channel (GIC), the uplink channel in\ncellular systems, and the $X$ channel. It is proved that the total DOF of the\n$K$-user GIC is $\\frac{K}{2}$ almost surely, i.e. each user enjoys half of its\nmaximum DOF. Having $K$ cells and $M$ users within each cell in a cellular\nsystem, the total DOF of the uplink channel is proved to be $\\frac{KM}{M+1}$.\nFinally, the total DOF of the $X$ channel with $K$ transmitters and $M$\nreceivers is shown to be $\\frac{KM}{K+M-1}$. \n\n"}
{"id": "0908.3293", "contents": "Title: Optimal transportation and monotonic quantities on evolving manifolds Abstract: In this note we will adapt Topping's $\\mathcal{L}$-optimal transportation\ntheory for Ricci flow to a more general situation, i.e. to a closed manifold\n$(M,g_{ij}(t))$ evolving by $\\partial_tg_{ij}=-2S_{ij}$, where $S_{ij}$ is a\nsymmetric tensor field of (2,0)-type on $M$. We extend some recent results of\nTopping, Lott and Brendle, generalize the monotonicity of List's (and hence\nalso of Perelman's) $\\mathcal{W}$-entropy, and recover the monotonicity of\nM$\\ddot{u}$ller's (and hence also of Perelman's) reduced volume. \n\n"}
{"id": "0909.0641", "contents": "Title: Monotonicity, thinning and discrete versions of the Entropy Power\n  Inequality Abstract: We consider the entropy of sums of independent discrete random variables, in\nanalogy with Shannon's Entropy Power Inequality, where equality holds for\nnormals. In our case, infinite divisibility suggests that equality should hold\nfor Poisson variables. We show that some natural analogues of the Entropy Power\nInequality do not in fact hold, but propose an alternative formulation which\ndoes always hold. The key to many proofs of Shannon's Entropy Power Inequality\nis the behaviour of entropy on scaling of continuous random variables. We\nbelieve that R\\'{e}nyi's operation of thinning discrete random variables plays\na similar role to scaling, and give a sharp bound on how the entropy of ultra\nlog-concave random variables behaves on thinning. In the spirit of the\nmonotonicity results established by Artstein, Ball, Barthe and Naor, we prove a\nstronger version of concavity of entropy, which implies a strengthened form of\nour discrete Entropy Power Inequality. \n\n"}
{"id": "0909.1638", "contents": "Title: Single-generation Network Coding for Networks with Delay Abstract: A single-source network is said to be \\textit{memory-free} if all of the\ninternal nodes (those except the source and the sinks) do not employ memory but\nmerely send linear combinations of the incoming symbols (received at their\nincoming edges) on their outgoing edges. Memory-free networks with delay using\nnetwork coding are forced to do inter-generation network coding, as a result of\nwhich the problem of some or all sinks requiring a large amount of memory for\ndecoding is faced. In this work, we address this problem by utilizing memory\nelements at the internal nodes of the network also, which results in the\nreduction of the number of memory elements used at the sinks. We give an\nalgorithm which employs memory at the nodes to achieve single-generation\nnetwork coding. For fixed latency, our algorithm reduces the total number of\nmemory elements used in the network to achieve single-generation network\ncoding. We also discuss the advantages of employing single-generation network\ncoding together with convolutional network-error correction codes (CNECCs) for\nnetworks with unit-delay and illustrate the performance gain of CNECCs by using\nmemory at the intermediate nodes using simulations on an example network under\na probabilistic network error model. \n\n"}
{"id": "0909.4177", "contents": "Title: On the Degrees of Freedom of Finite State Compound Wireless Networks -\n  Settling a Conjecture by Weingarten et. al Abstract: We explore the degrees of freedom (DoF) of three classes of finite state\ncompound wireless networks in this paper. First, we study the multiple-input\nsingle-output (MISO) finite state compound broadcast channel (BC) with\narbitrary number of users and antennas at the transmitter. In prior work,\nWeingarten et. al. have found inner and outer bounds on the DoF with 2 users.\nThe bounds have a different character. While the inner bound collapses to unity\nas the number of states increases, the outer bound does not diminish with the\nincreasing number of states beyond a threshold value. It has been conjectured\nthat the outer bound is loose and the inner bound represents the actual DoF. In\nthe complex setting (all signals, noise, and channel coefficients are complex\nvariables) we solve a few cases to find that the outer bound -and not the inner\nbound- of Weingarten et. al. is tight. For the real setting (all signals, noise\nand channel coefficients are real variables) we completely characterize the\nDoF, once again proving that the outer bound of Weingarten et. al. is tight. We\nalso extend the results to arbitrary number of users. Second, we characterize\nthe DoF of finite state scalar (single antenna nodes) compound X networks with\narbitrary number of users in the real setting. Third, we characterize the DoF\nof finite state scalar compound interference networks with arbitrary number of\nusers in both the real and complex setting. The key finding is that scalar\ninterference networks and (real) X networks do not lose any DoF due to channel\nuncertainty at the transmitter in the finite state compound setting. The finite\nstate compound MISO BC does lose DoF relative to the perfect CSIT scenario.\nHowever, what is lost is only the DoF benefit of joint processing at transmit\nantennas, without which the MISO BC reduces to an X network. \n\n"}
{"id": "0910.0575", "contents": "Title: A Note on Functional Averages over Gaussian Ensembles Abstract: In this work we find a new formula for matrix averages over the Gaussian\nensemble. Let ${\\bf H}$ be an $n\\times n$ Gaussian random matrix with complex,\nindependent, and identically distributed entries of zero mean and unit\nvariance. Given an $n\\times n$ positive definite matrix ${\\bf A}$, and a\ncontinuous function $f:\\R^{+}\\to\\R$ such that $\\int_{0}^{\\infty}{e^{-\\alpha\nt}|f(t)|^2\\,dt}<\\infty$ for every $\\alpha>0$, we find a new formula for the\nexpectation $\\E[\\mathrm{Tr}(f({\\bf HAH^{*}}))]$. Taking $f(x)=\\log(1+x)$ gives\nanother formula for the capacity of the MIMO communication channel, and taking\n$f(x)=(1+x)^{-1}$ gives the MMSE achieved by a linear receiver. \n\n"}
{"id": "0910.0827", "contents": "Title: Performance of Statistical Tests for Single Source Detection using\n  Random Matrix Theory Abstract: This paper introduces a unified framework for the detection of a source with\na sensor array in the context where the noise variance and the channel between\nthe source and the sensors are unknown at the receiver. The Generalized Maximum\nLikelihood Test is studied and yields the analysis of the ratio between the\nmaximum eigenvalue of the sampled covariance matrix and its normalized trace.\nUsing recent results of random matrix theory, a practical way to evaluate the\nthreshold and the $p$-value of the test is provided in the asymptotic regime\nwhere the number $K$ of sensors and the number $N$ of observations per sensor\nare large but have the same order of magnitude. The theoretical performance of\nthe test is then analyzed in terms of Receiver Operating Characteristic (ROC)\ncurve. It is in particular proved that both Type I and Type II error\nprobabilities converge to zero exponentially as the dimensions increase at the\nsame rate, and closed-form expressions are provided for the error exponents.\nThese theoretical results rely on a precise description of the large deviations\nof the largest eigenvalue of spiked random matrix models, and establish that\nthe presented test asymptotically outperforms the popular test based on the\ncondition number of the sampled covariance matrix. \n\n"}
{"id": "0910.2263", "contents": "Title: Minimum cost mirror sites using network coding: Replication vs. coding\n  at the source nodes Abstract: Content distribution over networks is often achieved by using mirror sites\nthat hold copies of files or portions thereof to avoid congestion and delay\nissues arising from excessive demands to a single location. Accordingly, there\nare distributed storage solutions that divide the file into pieces and place\ncopies of the pieces (replication) or coded versions of the pieces (coding) at\nmultiple source nodes. We consider a network which uses network coding for\nmulticasting the file. There is a set of source nodes that contains either\nsubsets or coded versions of the pieces of the file. The cost of a given\nstorage solution is defined as the sum of the storage cost and the cost of the\nflows required to support the multicast. Our interest is in finding the storage\ncapacities and flows at minimum combined cost. We formulate the corresponding\noptimization problems by using the theory of information measures. In\nparticular, we show that when there are two source nodes, there is no loss in\nconsidering subset sources. For three source nodes, we derive a tight upper\nbound on the cost gap between the coded and uncoded cases. We also present\nalgorithms for determining the content of the source nodes. \n\n"}
{"id": "0911.4222", "contents": "Title: Message Passing Algorithms for Compressed Sensing: II. Analysis and\n  Validation Abstract: In a recent paper, the authors proposed a new class of low-complexity\niterative thresholding algorithms for reconstructing sparse signals from a\nsmall set of linear measurements \\cite{DMM}. The new algorithms are broadly\nreferred to as AMP, for approximate message passing. This is the second of two\nconference papers describing the derivation of these algorithms, connection\nwith related literature, extensions of original framework, and new empirical\nevidence.\n  This paper describes the state evolution formalism for analyzing these\nalgorithms, and some of the conclusions that can be drawn from this formalism.\nWe carried out extensive numerical simulations to confirm these predictions. We\npresent here a few representative results. \n\n"}
{"id": "0911.5509", "contents": "Title: Interference Alignment Under Limited Feedback for MIMO Interference\n  Channels Abstract: While interference alignment schemes have been employed to realize the full\nmultiplexing gain of $K$-user interference channels, the analyses performed so\nfar have predominantly focused on the case when global channel knowledge is\navailable at each node of the network. This paper considers the problem where\neach receiver knows its channels from all the transmitters and feeds back this\ninformation using a limited number of bits to all other terminals. In\nparticular, channel quantization over the composite Grassmann manifold is\nproposed and analyzed. It is shown, for $K$-user multiple-input,\nmultiple-output (MIMO) interference channels, that when the transmitters use an\ninterference alignment strategy as if the quantized channel estimates obtained\nvia this limited feedback are perfect, the full sum degrees of freedom of the\ninterference channel can be achieved as long as the feedback bit rate scales\nsufficiently fast with the signal-to-noise ratio. Moreover, this is only one\nextreme point of a continuous tradeoff between achievable degrees of freedom\nregion and user feedback rate scalings which are allowed to be non-identical.\nIt is seen that a slower scaling of feedback rate for any one user leads to\ncommensurately fewer degrees of freedom for that user alone. \n\n"}
{"id": "0911.5524", "contents": "Title: LS-CS-residual (LS-CS): Compressive Sensing on Least Squares Residual Abstract: We consider the problem of recursively and causally reconstructing time\nsequences of sparse signals (with unknown and time-varying sparsity patterns)\nfrom a limited number of noisy linear measurements. The sparsity pattern is\nassumed to change slowly with time. The idea of our proposed solution,\nLS-CS-residual (LS-CS), is to replace compressed sensing (CS) on the\nobservation by CS on the least squares (LS) residual computed using the\nprevious estimate of the support. We bound CS-residual error and show that when\nthe number of available measurements is small, the bound is much smaller than\nthat on CS error if the sparsity pattern changes slowly enough. We also obtain\nconditions for \"stability\" of LS-CS over time for a signal model that allows\nsupport additions and removals, and that allows coefficients to gradually\nincrease (decrease) until they reach a constant value (become zero). By\n\"stability\", we mean that the number of misses and extras in the support\nestimate remain bounded by time-invariant values (in turn implying a\ntime-invariant bound on LS-CS error). The concept is meaningful only if the\nbounds are small compared to the support size. Numerical experiments backing\nour claims are shown. \n\n"}
{"id": "0911.5667", "contents": "Title: End-to-End Algebraic Network Coding for Wireless TCP/IP Networks Abstract: The Transmission Control Protocol (TCP) was designed to provide reliable\ntransport services in wired networks. In such networks, packet losses mainly\noccur due to congestion. Hence, TCP was designed to apply congestion avoidance\ntechniques to cope with packet losses. Nowadays, TCP is also utilized in\nwireless networks where, besides congestion, numerous other reasons for packet\nlosses exist. This results in reduced throughput and increased transmission\nround-trip time when the state of the wireless channel is bad. We propose a new\nnetwork layer, that transparently sits below the transport layer and hides non\ncongestion-imposed packet losses from TCP. The network coding in this new layer\nis based on the well-known class of Maximum Distance Separable (MDS) codes. \n\n"}
{"id": "0912.1628", "contents": "Title: KF-CS: Compressive Sensing on Kalman Filtered Residual Abstract: We consider the problem of recursively reconstructing time sequences of\nsparse signals (with unknown and time-varying sparsity patterns) from a limited\nnumber of linear incoherent measurements with additive noise. The idea of our\nproposed solution, KF CS-residual (KF-CS) is to replace compressed sensing (CS)\non the observation by CS on the Kalman filtered (KF) observation residual\ncomputed using the previous estimate of the support. KF-CS error stability over\ntime is studied. Simulation comparisons with CS and LS-CS are shown. \n\n"}
{"id": "0912.3245", "contents": "Title: Structured Error Recovery for Codeword-Stabilized Quantum Codes Abstract: Codeword stabilized (CWS) codes are, in general, non-additive quantum codes\nthat can correct errors by an exhaustive search of different error patterns,\nsimilar to the way that we decode classical non-linear codes. For an n-qubit\nquantum code correcting errors on up to t qubits, this brute-force approach\nconsecutively tests different errors of weight t or less, and employs a\nseparate n-qubit measurement in each test. In this paper, we suggest an error\ngrouping technique that allows to simultaneously test large groups of errors in\na single measurement. This structured error recovery technique exponentially\nreduces the number of measurements by about 3^t times. While it still leaves\nexponentially many measurements for a generic CWS code, the technique is\nequivalent to syndrome-based recovery for the special case of additive CWS\ncodes. \n\n"}
{"id": "0912.3599", "contents": "Title: Robust Principal Component Analysis? Abstract: This paper is about a curious phenomenon. Suppose we have a data matrix,\nwhich is the superposition of a low-rank component and a sparse component. Can\nwe recover each component individually? We prove that under some suitable\nassumptions, it is possible to recover both the low-rank and the sparse\ncomponents exactly by solving a very convenient convex program called Principal\nComponent Pursuit; among all feasible decompositions, simply minimize a\nweighted combination of the nuclear norm and of the L1 norm. This suggests the\npossibility of a principled approach to robust principal component analysis\nsince our methodology and results assert that one can recover the principal\ncomponents of a data matrix even though a positive fraction of its entries are\narbitrarily corrupted. This extends to the situation where a fraction of the\nentries are missing as well. We discuss an algorithm for solving this\noptimization problem, and present applications in the area of video\nsurveillance, where our methodology allows for the detection of objects in a\ncluttered background, and in the area of face recognition, where it offers a\nprincipled way of removing shadows and specularities in images of faces. \n\n"}
{"id": "0912.5303", "contents": "Title: Selection models under generalized symmetry settings Abstract: An active stream of literature has followed up the idea of skew-elliptical\ndensities initiated by Azzalini and Capitanio (1999). Their original\nformulation was based on a general lemma which is however of broader\napplicability than usually perceived. This note examines new directions of its\nuse, and illustrates them with the construction of some probability\ndistributions falling outside the family of the so-called skew-symmetric\ndensities. \n\n"}
{"id": "1001.1445", "contents": "Title: Graph-Constrained Group Testing Abstract: Non-adaptive group testing involves grouping arbitrary subsets of $n$ items\ninto different pools. Each pool is then tested and defective items are\nidentified. A fundamental question involves minimizing the number of pools\nrequired to identify at most $d$ defective items. Motivated by applications in\nnetwork tomography, sensor networks and infection propagation, a variation of\ngroup testing problems on graphs is formulated. Unlike conventional group\ntesting problems, each group here must conform to the constraints imposed by a\ngraph. For instance, items can be associated with vertices and each pool is any\nset of nodes that must be path connected. In this paper, a test is associated\nwith a random walk. In this context, conventional group testing corresponds to\nthe special case of a complete graph on $n$ vertices.\n  For interesting classes of graphs a rather surprising result is obtained,\nnamely, that the number of tests required to identify $d$ defective items is\nsubstantially similar to what is required in conventional group testing\nproblems, where no such constraints on pooling is imposed. Specifically, if\nT(n) corresponds to the mixing time of the graph $G$, it is shown that with\n$m=O(d^2T^2(n)\\log(n/d))$ non-adaptive tests, one can identify the defective\nitems. Consequently, for the Erdos-Renyi random graph $G(n,p)$, as well as\nexpander graphs with constant spectral gap, it follows that $m=O(d^2\\log^3n)$\nnon-adaptive tests are sufficient to identify $d$ defective items. Next, a\nspecific scenario is considered that arises in network tomography, for which it\nis shown that $m=O(d^3\\log^3n)$ non-adaptive tests are sufficient to identify\n$d$ defective items. Noisy counterparts of the graph constrained group testing\nproblem are considered, for which parallel results are developed. We also\nbriefly discuss extensions to compressive sensing on graphs. \n\n"}
{"id": "1001.1768", "contents": "Title: On the Secure DoF of the Single-Antenna MAC Abstract: A new achievability rate region for the secure discrete memoryless\nMultiple-Access-Channel (MAC) is presented. Thereafter, a novel secure coding\nscheme is proposed to achieve a positive Secure Degrees-of-Freedom (S-DoF) in\nthe single-antenna MAC. This scheme converts the single-antenna system into a\nmultiple-dimension system with fractional dimensions. The achievability scheme\nis based on the alignment of signals into a small sub-space at the\neavesdropper, and the simultaneous separation of the signals at the intended\nreceiver. Tools from the field of Diophantine Approximation in number theory\nare used to analyze the probability of error in the coding scheme. \n\n"}
{"id": "1001.2228", "contents": "Title: Estimation with Random Linear Mixing, Belief Propagation and Compressed\n  Sensing Abstract: We apply Guo and Wang's relaxed belief propagation (BP) method to the\nestimation of a random vector from linear measurements followed by a\ncomponentwise probabilistic measurement channel. Relaxed BP uses a Gaussian\napproximation in standard BP to obtain significant computational savings for\ndense measurement matrices. The main contribution of this paper is to extend\nthe relaxed BP method and analysis to general (non-AWGN) output channels.\nSpecifically, we present detailed equations for implementing relaxed BP for\ngeneral channels and show that relaxed BP has an identical asymptotic large\nsparse limit behavior as standard BP, as predicted by the Guo and Wang's state\nevolution (SE) equations. Applications are presented to compressed sensing and\nestimation with bounded noise. \n\n"}
{"id": "1001.4684", "contents": "Title: On Beta-Product Convolutions Abstract: Let R be a positive random variable independent of S which is beta\ndistributed. In this paper we are interested on the relation between the\ndistribution function of R and that of RS. For this model we derive first some\ndistributional properties, and then investigate the lower tail asymptotics of\nRS when R is regularly varying at 0, and vice-versa. Our first application\nconcerns the asymptotic behaviour of the componentwise sample minima related to\nan elliptical distributions. Further, we derive the lower tails asymptotic of\nthe aggregated risk for bivariate polar distributions. \n\n"}
{"id": "1002.1300", "contents": "Title: Architecture for communication with a fidelity criterion in unknown\n  networks Abstract: We prove that in order to communicate independent sources (this is the\nunicast problem) between various users over an unknown medium to within various\ndistortion levels, it is sufficient to consider source-channel separation based\narchitectures: architectures which first compress the sources to within the\ncorresponding distortion levels followed by reliable communication over the\nunknown medium. We are reducing the problem of universal rate-distortion\ncommunication of independent sources over a network to the universal reliable\ncommunication problem over networks. This is a reductionist view. We are not\nsolving the reliable communication problem in networks. \n\n"}
{"id": "1002.2813", "contents": "Title: Distributed Rate Allocation for Wireless Networks Abstract: This paper develops a distributed algorithm for rate allocation in wireless\nnetworks that achieves the same throughput region as optimal centralized\nalgorithms. This cross-layer algorithm jointly performs medium access control\n(MAC) and physical-layer rate adaptation. The paper establishes that this\nalgorithm is throughput-optimal for general rate regions. In contrast to on-off\nscheduling, rate allocation enables optimal utilization of physical-layer\nschemes by scheduling multiple rate levels. The algorithm is based on local\nqueue-length information, and thus the algorithm is of significant practical\nvalue. The algorithm requires that each link can determine the global\nfeasibility of increasing its current data-rate. In many classes of networks,\nany one link's data-rate primarily impacts its neighbors and this impact decays\nwith distance. Hence, local exchanges can provide the information needed to\ndetermine feasibility. Along these lines, the paper discusses the potential use\nof existing physical-layer control messages to determine feasibility. This can\nbe considered as a technique analogous to carrier sensing in CSMA (Carrier\nSense Multiple Access) networks. An important application of this algorithm is\nin multiple-band multiple-radio throughput-optimal distributed scheduling for\nwhite-space networks. \n\n"}
{"id": "1002.3911", "contents": "Title: Parameter estimations for SPDEs with multiplicative fractional noise Abstract: We study parameter estimation problem for diagonalizable stochastic partial\ndifferential equations driven by a multiplicative fractional noise with any\nHurst parameter $H\\in(0,1)$. Two classes of estimators are investigated:\ntraditional maximum likelihood type estimators, and a new class called\nclosed-form exact estimators. Finally the general results are applied to\nstochastic heat equation driven by a fractional Brownian motion. \n\n"}
{"id": "1002.3931", "contents": "Title: Competitive Spectrum Management with Incomplete Information Abstract: This paper studies an interference interaction (game) between selfish and\nindependent wireless communication systems in the same frequency band. Each\nsystem (player) has incomplete information about the other player's channel\nconditions. A trivial Nash equilibrium point in this game is where players\nmutually full spread (FS) their transmit spectrum and interfere with each\nother. This point may lead to poor spectrum utilization from a global network\npoint of view and even for each user individually.\n  In this paper, we provide a closed form expression for a non pure-FS\nepsilon-Nash equilibrium point; i.e., an equilibrium point where players choose\nFDM for some channel realizations and FS for the others. We show that operating\nin this non pure-FS epsilon-Nash equilibrium point increases each user's\nthroughput and therefore improves the spectrum utilization, and demonstrate\nthat this performance gain can be substantial. Finally, important insights are\nprovided into the behaviour of selfish and rational wireless users as a\nfunction of the channel parameters such as fading probabilities, the\ninterference-to-signal ratio. \n\n"}
{"id": "1002.4885", "contents": "Title: Network Coding-Aware Queue Management for TCP Flows over Coded Wireless\n  Networks Abstract: We are interested in unicast traffic over wireless networks that employ\nconstructive inter-session network coding, including single-hop and multi-hop\nschemes. In this setting, TCP flows do not fully exploit the network coding\nopportunities due to their bursty behavior and due to the fact that TCP is\nagnostic to the underlying network coding. In order to improve the performance\nof TCP flows over coded wireless networks, we take the following steps. First,\nwe formulate the problem as network utility maximization and we present a\ndistributed solution. Second, mimicking the structure of the optimal solution,\nwe propose a \"network-coding aware\" queue management scheme (NCAQM) at\nintermediate nodes; we make no changes to TCP or to the MAC protocol (802.11).\nWe demonstrate, via simulation, that NCAQM significantly improves TCP\nperformance compared to TCP over baseline schemes. \n\n"}
{"id": "1003.3765", "contents": "Title: Design of Nested LDGM-LDPC Codes for Compress-and-Forward in Relay\n  Channel Abstract: A three terminal relay system with binary erasure channel (BEC) was\nconsidered, in which a source forwarded information to a destination with a\nrelay's \"assistance\". The nested LDGM (Low-density generator-matrix) -LDPC\n(low-density parity-check) was designed to realize Compress-and-forward (CF) at\nthe relay. LDGM coding compressed the received signals losslessly and LDPC\nrealized the binning for Slepian-Wolf coding. Firstly a practical coding scheme\nwas proposed to achieve the cut-set bound on the capacity of the system,\nemploying LDPC and Nested LDGM-LDPC codes at the source and relay respectively.\nThen, the degree distribution of LDGM and LDPC codes was optimized with a given\nrate bound, which ensured that the iterative belief propagation (BP) decoding\nalgorithm at the destination was convergent. Finally, simulations results show\nthat the performance achieved based on nested codes is very close to\nSlepian-Wolf theoretical limit. \n\n"}
{"id": "1003.5131", "contents": "Title: Orthogonal polynomial kernels and canonical correlations for Dirichlet\n  measures Abstract: We consider a multivariate version of the so-called Lancaster problem of\ncharacterizing canonical correlation coefficients of symmetric bivariate\ndistributions with identical marginals and orthogonal polynomial expansions.\nThe marginal distributions examined in this paper are the Dirichlet and the\nDirichlet multinomial distribution, respectively, on the continuous and the\nN-discrete d-dimensional simplex. Their infinite-dimensional limit\ndistributions, respectively, the Poisson-Dirichlet distribution and Ewens's\nsampling formula, are considered as well. We study, in particular, the\npossibility of mapping canonical correlations on the d-dimensional continuous\nsimplex (i) to canonical correlation sequences on the d+1-dimensional simplex\nand/or (ii) to canonical correlations on the discrete simplex, and vice versa.\nDriven by this motivation, the first half of the paper is devoted to providing\na full characterization and probabilistic interpretation of n-orthogonal\npolynomial kernels (i.e., sums of products of orthogonal polynomials of the\nsame degree n) with respect to the mentioned marginal distributions. We\nestablish several identities and some integral representations which are\nmultivariate extensions of important results known for the case d=2 since the\n1970s. These results, along with a common interpretation of the mentioned\nkernels in terms of dependent Polya urns, are shown to be key features leading\nto several non-trivial solutions to Lancaster's problem, many of which can be\nextended naturally to the limit as $d\\rightarrow\\infty$. \n\n"}
{"id": "1004.0402", "contents": "Title: Improved Sparse Recovery Thresholds with Two-Step Reweighted $\\ell_1$\n  Minimization Abstract: It is well known that $\\ell_1$ minimization can be used to recover\nsufficiently sparse unknown signals from compressed linear measurements. In\nfact, exact thresholds on the sparsity, as a function of the ratio between the\nsystem dimensions, so that with high probability almost all sparse signals can\nbe recovered from iid Gaussian measurements, have been computed and are\nreferred to as \"weak thresholds\" \\cite{D}. In this paper, we introduce a\nreweighted $\\ell_1$ recovery algorithm composed of two steps: a standard\n$\\ell_1$ minimization step to identify a set of entries where the signal is\nlikely to reside, and a weighted $\\ell_1$ minimization step where entries\noutside this set are penalized. For signals where the non-sparse component has\niid Gaussian entries, we prove a \"strict\" improvement in the weak recovery\nthreshold. Simulations suggest that the improvement can be quite\nimpressive-over 20% in the example we consider. \n\n"}
{"id": "1005.0855", "contents": "Title: On Capacity Scaling of Underwater Networks: An Information-Theoretic\n  Perspective Abstract: Capacity scaling laws are analyzed in an underwater acoustic network with $n$\nregularly located nodes on a square. A narrow-band model is assumed where the\ncarrier frequency is allowed to scale as a function of $n$. In the network, we\ncharacterize an attenuation parameter that depends on the frequency scaling as\nwell as the transmission distance. A cut-set upper bound on the throughput\nscaling is then derived in extended networks. Our result indicates that the\nupper bound is inversely proportional to the attenuation parameter, thus\nresulting in a highly power-limited network. Interestingly, it is seen that\nunlike the case of wireless radio networks, our upper bound is intrinsically\nrelated to the attenuation parameter but not the spreading factor. Furthermore,\nwe describe an achievable scheme based on the simple nearest neighbor multi-hop\n(MH) transmission. It is shown under extended networks that the MH scheme is\norder-optimal as the attenuation parameter scales exponentially with $\\sqrt{n}$\n(or faster). Finally, these scaling results are extended to a random network\nrealization. \n\n"}
{"id": "1005.3093", "contents": "Title: A remark about orthogonal matching pursuit algorithm Abstract: In this note, we investigate the theoretical properties of Orthogonal\nMatching Pursuit (OMP), a class of decoder to recover sparse signal in\ncompressed sensing. In particular, we show that the OMP decoder can give\n$(p,q)$ instance optimality for a large class of encoders with $1\\leq p\\leq q\n\\leq 2$ and $(p,q)\\neq (2,2)$. We also show that, if the encoding matrix is\ndrawn from an appropriate distribution, then the OMP decoder is $(2,2)$\ninstance optimal in probability. \n\n"}
{"id": "1005.4769", "contents": "Title: A Network Coding Approach to Loss Tomography Abstract: Network tomography aims at inferring internal network characteristics based\non measurements at the edge of the network. In loss tomography, in particular,\nthe characteristic of interest is the loss rate of individual links and\nmulticast and/or unicast end-to-end probes are typically used. Independently,\nrecent advances in network coding have shown that there are advantages from\nallowing intermediate nodes to process and combine, in addition to just\nforward, packets. In this paper, we study the problem of loss tomography in\nnetworks with network coding capabilities. We design a framework for estimating\nlink loss rates, which leverages network coding capabilities, and we show that\nit improves several aspects of tomography including the identifiability of\nlinks, the trade-off between estimation accuracy and bandwidth efficiency, and\nthe complexity of probe path selection. We discuss the cases of inferring link\nloss rates in a tree topology and in a general topology. In the latter case,\nthe benefits of our approach are even more pronounced compared to standard\ntechniques, but we also face novel challenges, such as dealing with cycles and\nmultiple paths between sources and receivers. Overall, this work makes the\nconnection between active network tomography and network coding. \n\n"}
{"id": "1006.1426", "contents": "Title: Classification of delocalization power of global unitary operations in\n  terms of LOCC one-piece relocalization Abstract: We study how two pieces of localized quantum information can be delocalized\nacross a composite Hilbert space when a global unitary operation is applied. We\nclassify the delocalization power of global unitary operations on quantum\ninformation by investigating the possibility of relocalizing one piece of the\nquantum information without using any global quantum resource. We show that\none-piece relocalization is possible if and only if the global unitary\noperation is local unitary equivalent of a controlled-unitary operation. The\ndelocalization power turns out to reveal different aspect of the non-local\nproperties of global unitary operations characterized by their entangling\npower. \n\n"}
{"id": "1006.1772", "contents": "Title: Analysis of a Collaborative Filter Based on Popularity Amongst Neighbors Abstract: In this paper, we analyze a collaborative filter that answers the simple\nquestion: What is popular amongst your friends? While this basic principle\nseems to be prevalent in many practical implementations, there does not appear\nto be much theoretical analysis of its performance. In this paper, we partly\nfill this gap. While recent works on this topic, such as the low-rank matrix\ncompletion literature, consider the probability of error in recovering the\nentire rating matrix, we consider probability of an error in an individual\nrecommendation (bit error rate (BER)). For a mathematical model introduced in\n[1],[2], we identify three regimes of operation for our algorithm (named\nPopularity Amongst Friends (PAF)) in the limit as the matrix size grows to\ninfinity. In a regime characterized by large number of samples and small\ndegrees of freedom (defined precisely for the model in the paper), the\nasymptotic BER is zero; in a regime characterized by large number of samples\nand large degrees of freedom, the asymptotic BER is bounded away from 0 and 1/2\n(and is identified exactly except for a special case); and in a regime\ncharacterized by a small number of samples, the algorithm fails. We also\npresent numerical results for the MovieLens and Netflix datasets. We discuss\nthe empirical performance in light of our theoretical results and compare with\nan approach based on low-rank matrix completion. \n\n"}
{"id": "1007.0563", "contents": "Title: Graphical Models as Block-Tree Graphs Abstract: We introduce block-tree graphs as a framework for deriving efficient\nalgorithms on graphical models. We define block-tree graphs as a\ntree-structured graph where each node is a cluster of nodes such that the\nclusters in the graph are disjoint. This differs from junction-trees, where two\nclusters connected by an edge always have at least one common node. When\ncompared to junction-trees, we show that constructing block-tree graphs is\nfaster, and finding optimal block-tree graphs has a much smaller search space.\nApplying our block-tree graph framework to graphical models, we show that, for\nsome graphs, e.g., grid graphs, using block-tree graphs for inference is\ncomputationally more efficient than using junction-trees. For graphical models\nwith boundary conditions, the block-tree graph framework transforms the\nboundary valued problem into an initial value problem. For Gaussian graphical\nmodels, the block-tree graph framework leads to a linear state-space\nrepresentation. Since exact inference in graphical models can be\ncomputationally intractable, we propose to use spanning block-trees to derive\napproximate inference algorithms. Experimental results show the improved\nperformance in using spanning block-trees versus using spanning trees for\napproximate estimation over Gaussian graphical models. \n\n"}
{"id": "1007.0571", "contents": "Title: Quickest Detection with Social Learning: Interaction of local and global\n  decision makers Abstract: We consider how local and global decision policies interact in stopping time\nproblems such as quickest time change detection. Individual agents make myopic\nlocal decisions via social learning, that is, each agent records a private\nobservation of a noisy underlying state process, selfishly optimizes its local\nutility and then broadcasts its local decision. Given these local decisions,\nhow can a global decision maker achieve quickest time change detection when the\nunderlying state changes according to a phase-type distribution? The paper\npresents four results. First, using Blackwell dominance of measures, it is\nshown that the optimal cost incurred in social learning based quickest\ndetection is always larger than that of classical quickest detection. Second,\nit is shown that in general the optimal decision policy for social learning\nbased quickest detection is characterized by multiple thresholds within the\nspace of Bayesian distributions. Third, using lattice programming and\nstochastic dominance, sufficient conditions are given for the optimal decision\npolicy to consist of a single linear hyperplane, or, more generally, a\nthreshold curve. Estimation of the optimal linear approximation to this\nthreshold curve is formulated as a simulation-based stochastic optimization\nproblem. Finally, the paper shows that in multi-agent sensor management with\nquickest detection, where each agent views the world according to its prior,\nthe optimal policy has a similar structure to social learning. \n\n"}
{"id": "1007.4801", "contents": "Title: MIMO Wiretap Channels with Arbitrarily Varying Eavesdropper Channel\n  States Abstract: In this work, a class of information theoretic secrecy problems is addressed\nwhere the eavesdropper channel states are completely unknown to the legitimate\nparties. In particular, MIMO wiretap channel models are considered where the\nchannel of the eavesdropper is arbitrarily varying over time. Assuming that the\nnumber of antennas of the eavesdropper is limited, the secrecy rate of the MIMO\nwiretap channel in the sense of strong secrecy is derived, and shown to match\nwith the converse in secure degrees of freedom. It is proved that there exists\na universal coding scheme that secures the confidential message against any\nsequence of channel states experienced by the eavesdropper. This yields the\nconclusion that secure communication is possible regardless of the location or\nchannel states of (potentially infinite number of) eavesdroppers. Additionally,\nit is observed that, the present setting renders the secrecy capacity problems\nfor multi-terminal wiretap-type channels more tractable as compared the case\nwith full or partial knowledge of eavesdropper channel states. To demonstrate\nthis observation, secure degrees of freedom regions are derived for the\nGaussian MIMO multiple access wiretap channel (MIMO MAC-WT) and the Gaussian\nMIMO broadcast wiretap channel (MIMO BC-WT) where the transmitter(s) and the\nintended receiver(s) have the same number of antennas. \n\n"}
{"id": "1008.0420", "contents": "Title: Modeling Network Coded TCP Throughput: A Simple Model and its Validation Abstract: We analyze the performance of TCP and TCP with network coding (TCP/NC) in\nlossy wireless networks. We build upon the simple framework introduced by\nPadhye et al. and characterize the throughput behavior of classical TCP as well\nas TCP/NC as a function of erasure rate, round-trip time, maximum window size,\nand duration of the connection. Our analytical results show that network coding\nmasks erasures and losses from TCP, thus preventing TCP's performance\ndegradation in lossy networks, such as wireless networks. It is further seen\nthat TCP/NC has significant throughput gains over TCP. In addition, we simulate\nTCP and TCP/NC to verify our analysis of the average throughput and the window\nevolution. Our analysis and simulation results show very close concordance and\nsupport that TCP/NC is robust against erasures. TCP/NC is not only able to\nincrease its window size faster but also to maintain a large window size\ndespite losses within the network, whereas TCP experiences window closing\nessentially because losses are mistakenly attributed to congestion. \n\n"}
{"id": "1008.0919", "contents": "Title: Compressive Sensing over Graphs Abstract: In this paper, motivated by network inference and tomography applications, we\nstudy the problem of compressive sensing for sparse signal vectors over graphs.\nIn particular, we are interested in recovering sparse vectors representing the\nproperties of the edges from a graph. Unlike existing compressive sensing\nresults, the collective additive measurements we are allowed to take must\nfollow connected paths over the underlying graph. For a sufficiently connected\ngraph with $n$ nodes, it is shown that, using $O(k \\log(n))$ path measurements,\nwe are able to recover any $k$-sparse link vector (with no more than $k$\nnonzero elements), even though the measurements have to follow the graph path\nconstraints. We further show that the computationally efficient $\\ell_1$\nminimization can provide theoretical guarantees for inferring such $k$-sparse\nvectors with $O(k \\log(n))$ path measurements from the graph. \n\n"}
{"id": "1008.2147", "contents": "Title: Quantum Tagging: Authenticating Location via Quantum Information and\n  Relativistic Signalling Constraints Abstract: We define the task of {\\it quantum tagging}, that is, authenticating the\nclassical location of a classical tagging device by sending and receiving\nquantum signals from suitably located distant sites, in an environment\ncontrolled by an adversary whose quantum information processing and\ntransmitting power is unbounded. We define simple security models for this task\nand briefly discuss alternatives.\n  We illustrate the pitfalls of naive quantum cryptographic reasoning in this\ncontext by describing several protocols which at first sight appear\nunconditionally secure but which, as we show, can in fact be broken by\nteleportation-based attacks. We also describe some protocols which cannot be\nbroken by these specific attacks, but do not prove they are unconditionally\nsecure.\n  We review the history of quantum tagging protocols, which we first discussed\nin 2002 and described in a 2006 patent (for an insecure protocol). The\npossibility has recently been reconsidered by other authors. All the more\nrecently discussed protocols of which we are aware were either previously\nconsidered by us in 2002-3 or are variants of schemes then considered, and all\nare provably insecure. \n\n"}
{"id": "1008.3035", "contents": "Title: Achievable Rates in Two-user Interference Channels with Finite Inputs\n  and (Very) Strong Interference Abstract: For two-user interference channels, the capacity is known for the case where\ninterference is stronger than the desired signal. Moreover, it is known that if\nthe interference is above a certain level, it does not reduce the capacity at\nall. To achieve this capacity, the channel inputs need to be Gaussian\ndistributed. However, Gaussian signals are continuous and unbounded. Thus, they\nare not well suited for practical applications. In this paper, we investigate\nthe achievable rates if the channel inputs are restricted to finite\nconstellations. Moreover, we will show by numerical simulations that rotating\none of these input alphabets in the complex plane can increase the achievable\nrate region. Finally, we show that the threshold at which the single-user rates\nare achieved also depends on this rotation. \n\n"}
{"id": "1008.3295", "contents": "Title: Optimal relay location and power allocation for low SNR broadcast relay\n  channels Abstract: We consider the broadcast relay channel (BRC), where a single source\ntransmits to multiple destinations with the help of a relay, in the limit of a\nlarge bandwidth. We address the problem of optimal relay positioning and power\nallocations at source and relay, to maximize the multicast rate from source to\nall destinations. To solve such a network planning problem, we develop a\nthree-faceted approach based on an underlying information theoretic model,\ncomputational geometric aspects, and network optimization tools. Firstly,\nassuming superposition coding and frequency division between the source and the\nrelay, the information theoretic framework yields a hypergraph model of the\nwideband BRC, which captures the dependency of achievable rate-tuples on the\nnetwork topology. As the relay position varies, so does the set of hyperarcs\nconstituting the hypergraph, rendering the combinatorial nature of optimization\nproblem. We show that the convex hull C of all nodes in the 2-D plane can be\ndivided into disjoint regions corresponding to distinct hyperarcs sets. These\nsets are obtained by superimposing all k-th order Voronoi tessellation of C. We\npropose an easy and efficient algorithm to compute all hyperarc sets, and prove\nthey are polynomially bounded. Using the switched hypergraph approach, we model\nthe original problem as a continuous yet non-convex network optimization\nprogram. Ultimately, availing on the techniques of geometric programming and\n$p$-norm surrogate approximation, we derive a good convex approximation. We\nprovide a detailed characterization of the problem for collinearly located\ndestinations, and then give a generalization for arbitrarily located\ndestinations. Finally, we show strong gains for the optimal relay positioning\ncompared to seemingly interesting positions. \n\n"}
{"id": "1008.4177", "contents": "Title: LDPC Codes from Latin Squares Free of Small Trapping Sets Abstract: This paper is concerned with the construction of low-density parity-check\n(LDPC) codes with low error floors. Two main contributions are made. First, a\nnew class of structured LDPC codes is introduced. The parity check matrices of\nthese codes are arrays of permutation matrices which are obtained from Latin\nsquares and form a finite field under some matrix operations. Second, a method\nto construct LDPC codes with low error floors on the binary symmetric channel\n(BSC) is presented. Codes are constructed so that their Tanner graphs are free\nof certain small trapping sets. These trapping sets are selected from the\nTrapping Set Ontology for the Gallager A/B decoder. They are selected based on\ntheir relative harmfulness for a given decoding algorithm. We evaluate the\nrelative harmfulness of different trapping sets for the sum product algorithm\n(SPA) by using the topological relations among them and by analyzing the\ndecoding failures on one trapping set in the presence or absence of other\ntrapping sets. \n\n"}
{"id": "1008.5393", "contents": "Title: Increased Capacity per Unit-Cost by Oversampling Abstract: It is demonstrated that doubling the sampling rate recovers some of the loss\nin capacity incurred on the bandlimited Gaussian channel with a one-bit output\nquantizer. \n\n"}
{"id": "1010.0011", "contents": "Title: Deterministic Compressed Sensing Matrices from Additive Character\n  Sequences Abstract: Compressed sensing is a novel technique where one can recover sparse signals\nfrom the undersampled measurements. In this correspondence, a $K \\times N$\nmeasurement matrix for compressed sensing is deterministically constructed via\nadditive character sequences. The Weil bound is then used to show that the\nmatrix has asymptotically optimal coherence for $N=K^2$, and to present a\nsufficient condition on the sparsity level for unique sparse recovery. Also,\nthe restricted isometry property (RIP) is statistically studied for the\ndeterministic matrix. Using additive character sequences with small alphabets,\nthe compressed sensing matrix can be efficiently implemented by linear feedback\nshift registers. Numerical results show that the deterministic compressed\nsensing matrix guarantees reliable matching pursuit recovery performance for\nboth noiseless and noisy measurements. \n\n"}
{"id": "1010.0344", "contents": "Title: Alternating-Offer Bargaining Games over the Gaussian Interference\n  Channel Abstract: This paper tackles the problem of how two selfish users jointly determine the\noperating point in the achievable rate region of a two-user Gaussian\ninterference channel through bargaining. In previous work, incentive conditions\nfor two users to cooperate using a simple version of Han-Kobayashi scheme was\nstudied and the Nash bargaining solution (NBS) was used to obtain a fair\noperating point. Here a noncooperative bargaining game of alternating offers is\nadopted to model the bargaining process and rates resulting from the\nequilibrium outcome are analyzed. In particular, it is shown that the operating\npoint resulting from the formulated bargaining game depends on the cost of\ndelay in bargaining and how bargaining proceeds. If the associated bargaining\nproblem is regular, a unique perfect equilibrium exists and lies on the\nindividual rational efficient frontier of the achievable rate region. Besides,\nthe equilibrium outcome approaches the NBS if the bargaining costs of both\nusers are negligible. \n\n"}
{"id": "1010.0558", "contents": "Title: Analyzing Network Coding Gossip Made Easy Abstract: We give a new technique to analyze the stopping time of gossip protocols that\nare based on random linear network coding (RLNC). Our analysis drastically\nsimplifies, extends and strengthens previous results. We analyze RLNC gossip in\na general framework for network and communication models that encompasses and\nunifies the models used previously in this context. We show, in most settings\nfor the first time, that it converges with high probability in the\ninformation-theoretically optimal time. Most stopping times are of the form O(k\n+ T) where k is the number of messages to be distributed and T is the time it\ntakes to disseminate one message. This means RLNC gossip achieves \"perfect\npipelining\". Our analysis directly extends to highly dynamic networks in which\nthe topology can change completely at any time. This remains true even if the\nnetwork dynamics are controlled by a fully adaptive adversary that knows the\ncomplete network state. Virtually nothing besides simple O(kT) sequential\nflooding protocols was previously known for such a setting. While RLNC gossip\nworks in this wide variety of networks its analysis remains the same and\nextremely simple. This contrasts with more complex proofs that were put forward\nto give less strong results for various special cases. \n\n"}
{"id": "1010.2667", "contents": "Title: Virtual Full-Duplex Wireless Communication via Rapid On-Off-Division\n  Duplex Abstract: This paper introduces a novel paradigm for design- ing the physical and\nmedium access control (MAC) layers of mobile ad hoc or peer-to-peer networks\nformed by half-duplex radios. A node equipped with such a radio cannot\nsimultaneously transmit and receive useful signals at the same frequency.\nUnlike in conventional designs, where a node's transmission frames are\nscheduled away from its reception, each node transmits its signal through a\nrandomly generated on-off duplex mask (or signature) over every frame interval,\nand receive a signal through each of its own off-slots. This is called rapid\non-off- division duplex (RODD). Over the period of a single frame, every node\ncan transmit a message to some or all of its peers, and may simultaneously\nreceive a message from each peer. Thus RODD achieves virtual full-duplex\ncommunication using half-duplex radios and can simplify the design of higher\nlayers of a network protocol stack significantly. The throughput of RODD is\nevaluated under some general settings, which is significantly larger than that\nof ALOHA. RODD is especially efficient in case the dominant traffic is\nsimultaneous broadcast from nodes to their one-hop peers, such as in\nspontaneous wireless social networks, emergency situations or on battlefield.\nImportant design issues of peer discovery, distribution of on-off signatures,\nsynchronization and error-control coding are also addressed. \n\n"}
{"id": "1010.3566", "contents": "Title: Perturbation of matrices and non-negative rank with a view toward\n  statistical models Abstract: In this paper we study how perturbing a matrix changes its non-negative rank.\nWe prove that the non-negative rank is upper-semicontinuos and we describe some\nspecial families of perturbations. We show how our results relate to Statistics\nin terms of the study of Maximum Likelihood Estimation for mixture models. \n\n"}
{"id": "1010.5416", "contents": "Title: Capacity of Fading Gaussian Channel with an Energy Harvesting Sensor\n  Node Abstract: Network life time maximization is becoming an important design goal in\nwireless sensor networks. Energy harvesting has recently become a preferred\nchoice for achieving this goal as it provides near perpetual operation. We\nstudy such a sensor node with an energy harvesting source and compare various\narchitectures by which the harvested energy is used. We find its Shannon\ncapacity when it is transmitting its observations over a fading AWGN channel\nwith perfect/no channel state information provided at the transmitter. We\nobtain an achievable rate when there are inefficiencies in energy storage and\nthe capacity when energy is spent in activities other than transmission. \n\n"}
{"id": "1010.5506", "contents": "Title: Dualities and Identities for Entanglement-Assisted Quantum Codes Abstract: The dual of an entanglement-assisted quantum error-correcting (EAQEC) code is\nthe code resulting from exchanging the original code's information qubits with\nits ebits. To introduce this notion, we show how entanglement-assisted (EA)\nrepetition codes and accumulator codes are dual to each other, much like their\nclassical counterparts, and we give an explicit, general quantum shift-register\ncircuit that encodes both classes of codes.We later show that our constructions\nare optimal, and this result completes our understanding of these dual classes\nof codes. We also establish the Gilbert-Varshamov bound and the Plotkin bound\nfor EAQEC codes, and we use these to examine the existence of some EAQEC codes.\nFinally, we provide upper bounds on the block error probability when\ntransmitting maximal-entanglement EAQEC codes over the depolarizing channel,\nand we derive variations of the hashing bound for EAQEC codes, which is a lower\nbound on the maximum rate at which reliable communication over Pauli channels\nis possible with the use of pre-shared entanglement. \n\n"}
{"id": "1011.2196", "contents": "Title: Degrees of Freedom Regions of Two-User MIMO Z and Full Interference\n  Channels: The Benefit of Reconfigurable Antennas Abstract: We study the degrees of freedom (DoF) regions of two-user multiple-input\nmultiple-output (MIMO) Z and full interference channels in this paper. We\nassume that the receivers always have perfect channel state information. We\nfirst derive the DoF region of Z interference channel with channel state\ninformation at transmitter (CSIT). For full interference channel without CSIT,\nthe DoF region has been fully characterized recently and it is shown that the\npreviously known outer bound is not achievable. In this work, we investigate\nthe no-CSIT case further by assuming that the transmitter has the ability of\nantenna mode switching. We obtain the DoF region as a function of the number of\navailable antenna modes and reveal the incremental gain in DoF that each extra\nantenna mode can bring. It is shown that in certain cases the reconfigurable\nantennas can bring extra DoF gains. In these cases, the DoF region is maximized\nwhen the number of modes is at least equal to the number of receive antennas at\nthe corresponding receiver, in which case the previously outer bound is\nachieved. In all cases, we propose systematic constructions of the beamforming\nand nulling matrices for achieving the DoF region. The constructions bear an\ninteresting space-frequency interpretation. \n\n"}
{"id": "1011.2797", "contents": "Title: When are microcircuits well-modeled by maximum entropy methods? Abstract: Describing the collective activity of neural populations is a daunting task:\nthe number of possible patterns grows exponentially with the number of cells,\nresulting in practically unlimited complexity. Recent empirical studies,\nhowever, suggest a vast simplification in how multi-neuron spiking occurs: the\nactivity patterns of some circuits are nearly completely captured by pairwise\ninteractions among neurons. Why are such pairwise models so successful in some\ninstances, but insufficient in others? Here, we study the emergence of\nhigher-order interactions in simple circuits with different architectures and\ninputs. We quantify the impact of higher-order interactions by comparing the\nresponses of mechanistic circuit models vs. \"null\" descriptions in which all\nhigher-than-pairwise correlations have been accounted for by lower order\nstatistics, known as pairwise maximum entropy models.\n  We find that bimodal input signals produce larger deviations from pairwise\npredictions than unimodal inputs for circuits with local and global\nconnectivity. Moreover, recurrent coupling can accentuate these deviations, if\ncoupling strengths are neither too weak nor too strong. A circuit model based\non intracellular recordings from ON parasol retinal ganglion cells shows that a\nbroad range of light signals induce unimodal inputs to spike generators, and\nthat coupling strengths produce weak effects on higher-order interactions. This\nprovides a novel explanation for the success of pairwise models in this system.\nOverall, our findings identify circuit-level mechanisms that produce and fail\nto produce higher-order spiking statistics in neural ensembles. \n\n"}
{"id": "1011.3754", "contents": "Title: Principles of Physical Layer Security in Multiuser Wireless Networks: A\n  Survey Abstract: This paper provides a comprehensive review of the domain of physical layer\nsecurity in multiuser wireless networks. The essential premise of\nphysical-layer security is to enable the exchange of confidential messages over\na wireless medium in the presence of unauthorized eavesdroppers without relying\non higher-layer encryption. This can be achieved primarily in two ways: without\nthe need for a secret key by intelligently designing transmit coding\nstrategies, or by exploiting the wireless communication medium to develop\nsecret keys over public channels. The survey begins with an overview of the\nfoundations dating back to the pioneering work of Shannon and Wyner on\ninformation-theoretic security. We then describe the evolution of secure\ntransmission strategies from point-to-point channels to multiple-antenna\nsystems, followed by generalizations to multiuser broadcast, multiple-access,\ninterference, and relay networks. Secret-key generation and establishment\nprotocols based on physical layer mechanisms are subsequently covered.\nApproaches for secrecy based on channel coding design are then examined, along\nwith a description of inter-disciplinary approaches based on game theory and\nstochastic geometry. The associated problem of physical-layer message\nauthentication is also introduced briefly. The survey concludes with\nobservations on potential research directions in this area. \n\n"}
{"id": "1011.3754", "contents": "Title: Principles of Physical Layer Security in Multiuser Wireless Networks: A\n  Survey Abstract: This paper provides a comprehensive review of the domain of physical layer\nsecurity in multiuser wireless networks. The essential premise of\nphysical-layer security is to enable the exchange of confidential messages over\na wireless medium in the presence of unauthorized eavesdroppers without relying\non higher-layer encryption. This can be achieved primarily in two ways: without\nthe need for a secret key by intelligently designing transmit coding\nstrategies, or by exploiting the wireless communication medium to develop\nsecret keys over public channels. The survey begins with an overview of the\nfoundations dating back to the pioneering work of Shannon and Wyner on\ninformation-theoretic security. We then describe the evolution of secure\ntransmission strategies from point-to-point channels to multiple-antenna\nsystems, followed by generalizations to multiuser broadcast, multiple-access,\ninterference, and relay networks. Secret-key generation and establishment\nprotocols based on physical layer mechanisms are subsequently covered.\nApproaches for secrecy based on channel coding design are then examined, along\nwith a description of inter-disciplinary approaches based on game theory and\nstochastic geometry. The associated problem of physical-layer message\nauthentication is also introduced briefly. The survey concludes with\nobservations on potential research directions in this area. \n\n"}
{"id": "1011.5039", "contents": "Title: Information and Interpretation of Quantum Mechanics Abstract: This work is a discussion on the concept of information. We define here\ninformation as an abstraction that is able to be copied. We consider the\nconnection between the process of copying information in quantum systems and\nthe emergence of the so-called classical realism. The problem of interpretation\nof quantum mechanics in this context is discussed as well. \n\n"}
{"id": "1011.6218", "contents": "Title: Coordinated Transmissions to Direct and Relayed Users in Wireless\n  Cellular Systems Abstract: The ideas of wireless network coding at the physical layer promise high\nthroughput gains in wireless systems with relays and multi-way traffic flows.\nThis gain can be ascribed to two principles: (1) joint transmission of multiple\ncommunication flows and (2) usage of \\emph{a priori} information to cancel the\ninterference. In this paper we use these principles to devise new transmission\nschemes in wireless cellular systems that feature both users served directly by\nthe base stations (direct users) and users served through relays (relayed\nusers). We present four different schemes for \\emph{coordinated transmission}\nof uplink and downlink traffic in which one direct and one relayed user are\nserved. These schemes are then used as building blocks in multi-user scenarios,\nwhere we present several schemes for scheduling pairs of users for coordinated\ntransmissions. The optimal scheme involves exhaustive search of the best user\npair in terms of overall rate. We propose several suboptimal scheduling\nschemes, which perform closely to the optimal scheme. The numerical results\nshow a substantial increase in the system--level rate with respect to the\nsystems with non--coordinated transmissions. \n\n"}
{"id": "1101.0302", "contents": "Title: Mutual Information, Relative Entropy, and Estimation in the Poisson\n  Channel Abstract: Let $X$ be a non-negative random variable and let the conditional\ndistribution of a random variable $Y$, given $X$, be ${Poisson}(\\gamma \\cdot\nX)$, for a parameter $\\gamma \\geq 0$. We identify a natural loss function such\nthat: 1) The derivative of the mutual information between $X$ and $Y$ with\nrespect to $\\gamma$ is equal to the \\emph{minimum} mean loss in estimating $X$\nbased on $Y$, regardless of the distribution of $X$. 2) When $X \\sim P$ is\nestimated based on $Y$ by a mismatched estimator that would have minimized the\nexpected loss had $X \\sim Q$, the integral over all values of $\\gamma$ of the\nexcess mean loss is equal to the relative entropy between $P$ and $Q$.\n  For a continuous time setting where $X^T = \\{X_t, 0 \\leq t \\leq T \\}$ is a\nnon-negative stochastic process and the conditional law of $Y^T=\\{Y_t, 0\\le\nt\\le T\\}$, given $X^T$, is that of a non-homogeneous Poisson process with\nintensity function $\\gamma \\cdot X^T$, under the same loss function: 1) The\nminimum mean loss in \\emph{causal} filtering when $\\gamma = \\gamma_0$ is equal\nto the expected value of the minimum mean loss in \\emph{non-causal} filtering\n(smoothing) achieved with a channel whose parameter $\\gamma$ is uniformly\ndistributed between 0 and $\\gamma_0$. Bridging the two quantities is the mutual\ninformation between $X^T$ and $Y^T$. 2) This relationship between the mean\nlosses in causal and non-causal filtering holds also in the case where the\nfilters employed are mismatched, i.e., optimized assuming a law on $X^T$ which\nis not the true one. Bridging the two quantities in this case is the sum of the\nmutual information and the relative entropy between the true and the mismatched\ndistribution of $Y^T$. Thus, relative entropy quantifies the excess estimation\nloss due to mismatch in this setting.\n  These results parallel those recently found for the Gaussian channel. \n\n"}
{"id": "1101.4435", "contents": "Title: Solutions for the MIMO Gaussian Wiretap Channel with a Cooperative\n  Jammer Abstract: We study the Gaussian MIMO wiretap channel with a transmitter, a legitimate\nreceiver, an eavesdropper and an external helper, each equipped with multiple\nantennas. The transmitter sends confidential messages to its intended receiver,\nwhile the helper transmits jamming signals independent of the source message to\nconfuse the eavesdropper. The jamming signal is assumed to be treated as noise\nat both the intended receiver and the eavesdropper. We obtain a closed-form\nexpression for the structure of the artificial noise covariance matrix that\nguarantees no decrease in the secrecy capacity of the wiretap channel. We also\ndescribe how to find specific realizations of this covariance matrix expression\nthat provide good secrecy rate performance, even when there is no non-trivial\nnull space between the helper and the intended receiver. Unlike prior work, our\napproach considers the general MIMO case, and is not restricted to SISO or MISO\nscenarios. \n\n"}
{"id": "1101.4999", "contents": "Title: List decoding of a class of affine variety codes Abstract: Consider a polynomial $F$ in $m$ variables and a finite point ensemble $S=S_1\n\\times ... \\times S_m$. When given the leading monomial of $F$ with respect to\na lexicographic ordering we derive improved information on the possible number\nof zeros of $F$ of multiplicity at least $r$ from $S$. We then use this\ninformation to design a list decoding algorithm for a large class of affine\nvariety codes. \n\n"}
{"id": "1101.6033", "contents": "Title: Some More Functions That Are Not APN Infinitely Often. The Case of\n  Kasami exponents Abstract: We prove a necessary condition for some polynomials of Kasami degree to be\nAPN over F_{q^n} for large n. \n\n"}
{"id": "1102.0964", "contents": "Title: Structured interference-mitigation in two-hop networks Abstract: We consider two-hop S-R-D Gaussian networks with a source (S), a relay (R)\nand a destination (D), some of which experience additive interference. This\nadditive interference, which renders the channels state-dependent, is either a)\nexperienced at the destination D and known non-causally at the source S, or b)\nexperienced at the relay R and known at the destination D. In both cases, one\nwould hope to exploit this knowledge of the channel state at some of the nodes\nto obtain \"clean\" or interference-free channels, just as Costa's dirty-paper\ncoding does for one-hop channels with state non-causally known to the\ntransmitter. We demonstrate a scheme which achieves to within 0.5 bit of a\n\"clean\" channel. This novel scheme is based on nested-lattice code and a\nDecode-and-Forward (DF) relay. Intuitively, this strategy uses the structure\nprovided by nested lattice codes to cancel the \"integer\" (or lattice quantized)\npart of the interference and treats the \"residual\" (or quantization noise) as\nnoise. \n\n"}
{"id": "1102.1115", "contents": "Title: Adaptive Resource Allocation in Jamming Teams Using Game Theory Abstract: In this work, we study the problem of power allocation and adaptive\nmodulation in teams of decision makers. We consider the special case of two\nteams with each team consisting of two mobile agents. Agents belonging to the\nsame team communicate over wireless ad hoc networks, and they try to split\ntheir available power between the tasks of communication and jamming the nodes\nof the other team. The agents have constraints on their total energy and\ninstantaneous power usage. The cost function adopted is the difference between\nthe rates of erroneously transmitted bits of each team. We model the adaptive\nmodulation problem as a zero-sum matrix game which in turn gives rise to a a\ncontinuous kernel game to handle power control. Based on the communications\nmodel, we present sufficient conditions on the physical parameters of the\nagents for the existence of a pure strategy saddle-point equilibrium (PSSPE). \n\n"}
{"id": "1102.1247", "contents": "Title: Randomness and dependencies extraction via polarization, with\n  applications to Slepian-Wolf coding and secrecy Abstract: The polarization phenomenon for a single source is extended to a framework\nwith multiple correlated sources. It is shown in addition to extracting the\nrandomness of the source, the polar transforms takes the original arbitrary\ndependencies to extremal dependencies. Polar coding schemes for the\nSlepian-Wolf problem and for secret key generations are then proposed based on\nthis phenomenon. In particular, constructions of secret keys achieving the\nsecrecy capacity and compression schemes achieving the Slepian-Wolf capacity\nregion are obtained with a complexity of $O(n \\log (n))$. \n\n"}
{"id": "1102.1466", "contents": "Title: Distributed Throughput-optimal Scheduling in Ad Hoc Wireless Networks Abstract: In this paper, we propose a distributed throughput-optimal ad hoc wireless\nnetwork scheduling algorithm, which is motivated by the celebrated simplex\nalgorithm for solving linear programming (LP) problems. The scheduler stores a\nsparse set of basic schedules, and chooses the max-weight basic schedule for\ntransmission in each time slot. At the same time, the scheduler tries to update\nthe set of basic schedules by searching for a new basic schedule in a\nthroughput increasing direction. We show that both of the above procedures can\nbe achieved in a distributed manner. Specifically, we propose an average\nconsensus based link contending algorithm to implement the distributed max\nweight scheduling. Further, we show that the basic schedule update can be\nimplemented using CSMA mechanisms, which is similar to the one proposed by\nJiang et al. Compared to the optimal distributed scheduler in Jiang's paper,\nwhere schedules change in a random walk fashion, our algorithm has a better\ndelay performance by achieving faster schedule transitions in the steady state.\nThe performance of the algorithm is finally confirmed by simulation results. \n\n"}
{"id": "1102.3617", "contents": "Title: Wireless Secrecy in Large-Scale Networks Abstract: The ability to exchange secret information is critical to many commercial,\ngovernmental, and military networks. The intrinsically secure communications\ngraph (iS-graph) is a random graph which describes the connections that can be\nsecurely established over a large-scale network, by exploiting the physical\nproperties of the wireless medium. This paper provides an overview of the main\nproperties of this new class of random graphs. We first analyze the local\nproperties of the iS-graph, namely the degree distributions and their\ndependence on fading, target secrecy rate, and eavesdropper collusion. To\nmitigate the effect of the eavesdroppers, we propose two techniques that\nimprove secure connectivity. Then, we analyze the global properties of the\niS-graph, namely percolation on the infinite plane, and full connectivity on a\nfinite region. These results help clarify how the presence of eavesdroppers can\ncompromise secure communication in a large-scale network. \n\n"}
{"id": "1102.5138", "contents": "Title: Low-Complexity Near-Optimal Codes for Gaussian Relay Networks Abstract: We consider the problem of information flow over Gaussian relay networks.\nSimilar to the recent work by Avestimehr \\emph{et al.} [1], we propose network\ncodes that achieve up to a constant gap from the capacity of such networks.\nHowever, our proposed codes are also computationally tractable. Our main\ntechnique is to use the codes of Avestimehr \\emph{et al.} as inner codes in a\nconcatenated coding scheme. \n\n"}
{"id": "1102.5253", "contents": "Title: On the Szeg\\\"o-Asymptotics for Doubly-Dispersive Gaussian Channels Abstract: We consider the time-continuous doubly-dispersive channel with additive\nGaussian noise and establish a capacity formula for the case where the channel\ncorrelation operator is represented by a symbol which is periodic in time and\nfulfills some further integrability and smoothness conditions. The key to this\nresult is a new Szeg\\\"o formula for certain pseudo-differential operators. The\nformula justifies the water-filling principle along time and frequency in terms\nof the time--continuous time-varying transfer function (the symbol). \n\n"}
{"id": "1102.5689", "contents": "Title: Matrix probing and its conditioning Abstract: When a matrix A with n columns is known to be well approximated by a linear\ncombination of basis matrices B_1,..., B_p, we can apply A to a random vector\nand solve a linear system to recover this linear combination. The same\ntechnique can be used to recover an approximation to A^-1. A basic question is\nwhether this linear system is invertible and well-conditioned. In this paper,\nwe show that if the Gram matrix of the B_j's is sufficiently well-conditioned\nand each B_j has a high numerical rank, then n {proportional} p log^2 n will\nensure that the linear system is well-conditioned with high probability. Our\nmain application is probing linear operators with smooth pseudodifferential\nsymbols such as the wave equation Hessian in seismic imaging. We demonstrate\nnumerically that matrix probing can also produce good preconditioners for\ninverting elliptic operators in variable media. \n\n"}
{"id": "1103.0135", "contents": "Title: Capacity results for compound wiretap channels Abstract: We derive a lower bound on the secrecy capacity of the compound wiretap\nchannel with channel state information at the transmitter which matches the\ngeneral upper bound on the secrecy capacity of general compound wiretap\nchannels given by Liang et al. and thus establishing a full coding theorem in\nthis case. We achieve this with a quite strong secrecy criterion and with a\ndecoder that is robust against the effect of randomisation in the encoding.\nThis relieves us from the need of decoding the randomisation parameter which is\nin general not possible within this model. Moreover we prove a lower bound on\nthe secrecy capacity of the compound wiretap channel without channel state\ninformation. \n\n"}
{"id": "1103.2046", "contents": "Title: Wireless Network Simplification: the Gaussian N-Relay Diamond Network Abstract: We consider the Gaussian N-relay diamond network, where a source wants to\ncommunicate to a destination node through a layer of N-relay nodes. We\ninvestigate the following question: what fraction of the capacity can we\nmaintain by using only k out of the N available relays? We show that\nindependent of the channel configurations and the operating SNR, we can always\nfind a subset of k relays which alone provide a rate (kC/(k+1))-G, where C is\nthe information theoretic cutset upper bound on the capacity of the whole\nnetwork and G is a constant that depends only on N and k (logarithmic in N and\nlinear in k). In particular, for k = 1, this means that half of the capacity of\nany N-relay diamond network can be approximately achieved by routing\ninformation over a single relay. We also show that this fraction is tight:\nthere are configurations of the N-relay diamond network where every subset of k\nrelays alone can at most provide approximately a fraction k/(k+1) of the total\ncapacity. These high-capacity k-relay subnetworks can be also discovered\nefficiently. We propose an algorithm that computes a constant gap approximation\nto the capacity of the Gaussian N-relay diamond network in O(N log N) running\ntime and discovers a high-capacity k-relay subnetwork in O(kN) running time.\n  This result also provides a new approximation to the capacity of the Gaussian\nN-relay diamond network which is hybrid in nature: it has both multiplicative\nand additive gaps. In the intermediate SNR regime, this hybrid approximation is\ntighter than existing purely additive or purely multiplicative approximations\nto the capacity of this network. \n\n"}
{"id": "1103.2240", "contents": "Title: Price-Based Resource Allocation for Spectrum-Sharing Femtocell Networks:\n  A Stackelberg Game Approach Abstract: This paper investigates the price-based resource allocation strategies for\nthe uplink transmission of a spectrum-sharing femtocell network, in which a\ncentral macrocell is underlaid with distributed femtocells, all operating over\nthe same frequency band as the macrocell. Assuming that the macrocell base\nstation (MBS) protects itself by pricing the interference from the femtocell\nusers, a Stackelberg game is formulated to study the joint utility maximization\nof the macrocell and the femtocells subject to a maximum tolerable interference\npower constraint at the MBS. Especially, two practical femtocell channel\nmodels: sparsely deployed scenario for rural areas and densely deployed\nscenario for urban areas, are investigated. For each scenario, two pricing\nschemes: uniform pricing and non-uniform pricing, are proposed. Then, the\nStackelberg equilibriums for these proposed games are studied, and an effective\ndistributed interference price bargaining algorithm with guaranteed convergence\nis proposed for the uniform-pricing case. Finally, numerical examples are\npresented to verify the proposed studies. It is shown that the proposed\nalgorithms are effective in resource allocation and macrocell protection\nrequiring minimal network overhead for spectrum-sharing-based two-tier\nfemtocell networks. \n\n"}
{"id": "1103.2897", "contents": "Title: Constructing test instances for Basis Pursuit Denoising Abstract: The number of available algorithms for the so-called Basis Pursuit Denoising\nproblem (or the related LASSO-problem) is large and keeps growing. Similarly,\nthe number of experiments to evaluate and compare these algorithms on different\ninstances is growing.\n  In this note, we present a method to produce instances with exact solutions\nwhich is based on a simple observation which is related to the so called source\ncondition from sparse regularization. \n\n"}
{"id": "1103.4438", "contents": "Title: Anytime Reliable Codes for Stabilizing Plants over Erasure Channels Abstract: The problem of stabilizing an unstable plant over a noisy communication link\nis an increasingly important one that arises in problems of distributed control\nand networked control systems. Although the work of Schulman and Sahai over the\npast two decades, and their development of the notions of \"tree codes\" and\n\"anytime capacity\", provides the theoretical framework for studying such\nproblems, there has been scant practical progress in this area because explicit\nconstructions of tree codes with efficient encoding and decoding did not exist.\nTo stabilize an unstable plant driven by bounded noise over a noisy channel one\nneeds real-time encoding and real-time decoding and a reliability which\nincreases exponentially with delay, which is what tree codes guarantee. We\nprove the existence of linear tree codes with high probability and, for erasure\nchannels, give an explicit construction with an expected encoding and decoding\ncomplexity that is constant per time instant. We give sufficient conditions on\nthe rate and reliability required of the tree codes to stabilize vector plants\nand argue that they are asymptotically tight. This work takes a major step\ntowards controlling plants over noisy channels, and we demonstrate the efficacy\nof the method through several examples. \n\n"}
{"id": "1103.5610", "contents": "Title: Polynomial deviation bounds for recurrent Harris processes having\n  general state space Abstract: Consider a strong Markov process in continuous time, taking values in some\nPolish state space. Recently, Douc, Fort and Guillin (2009) introduced\nverifiable conditions in terms of a supermartingale property implying an\nexplicit control of modulated moments of hitting times. We show how this\ncontrol can be translated into a control of polynomial moments of abstract\nregeneration times which are obtained by using the regeneration method of\nNummelin, extended to the time-continuous context.\n  As a consequence, if a $p-$th moment of the regeneration times exists, we\nobtain non asymptotic deviation bounds of the form\n$$P_{\\nu}(|\\frac1t\\int_0^tf(X_s)ds-\\mu(f)|\\geq\\ge)\\leq K(p)\\frac1{t^{p-\n1}}\\frac 1{\\ge^{2(p-1)}}\\|f\\|_\\infty^{2(p-1)}, p \\geq 2. $$ Here, $f$ is a\nbounded function and $\\mu$ is the invariant measure of the process. We give\nseveral examples, including elliptic stochastic differential equations and\nstochastic differential equations driven by a jump noise. \n\n"}
{"id": "1104.1227", "contents": "Title: Intervention in Power Control Games With Selfish Users Abstract: We study the power control problem in wireless ad hoc networks with selfish\nusers. Without incentive schemes, selfish users tend to transmit at their\nmaximum power levels, causing significant interference to each other. In this\npaper, we study a class of incentive schemes based on intervention to induce\nselfish users to transmit at desired power levels. An intervention scheme can\nbe implemented by introducing an intervention device that can monitor the power\nlevels of users and then transmit power to cause interference to users. We\nmainly consider first-order intervention rules based on individual transmit\npowers. We derive conditions on design parameters and the intervention\ncapability to achieve a desired outcome as a (unique) Nash equilibrium and\npropose a dynamic adjustment process that the designer can use to guide users\nand the intervention device to the desired outcome. The effect of using\nintervention rules based on aggregate receive power is also analyzed. Our\nresults show that with perfect monitoring intervention schemes can be designed\nto achieve any positive power profile while using interference from the\nintervention device only as a threat. We also analyze the case of imperfect\nmonitoring and show that a performance loss can occur. Lastly, simulation\nresults are presented to illustrate the performance improvement from using\nintervention rules and compare the performances of different intervention\nrules. \n\n"}
{"id": "1104.4302", "contents": "Title: Rank Minimization over Finite Fields: Fundamental Limits and\n  Coding-Theoretic Interpretations Abstract: This paper establishes information-theoretic limits in estimating a finite\nfield low-rank matrix given random linear measurements of it. These linear\nmeasurements are obtained by taking inner products of the low-rank matrix with\nrandom sensing matrices. Necessary and sufficient conditions on the number of\nmeasurements required are provided. It is shown that these conditions are sharp\nand the minimum-rank decoder is asymptotically optimal. The reliability\nfunction of this decoder is also derived by appealing to de Caen's lower bound\non the probability of a union. The sufficient condition also holds when the\nsensing matrices are sparse - a scenario that may be amenable to efficient\ndecoding. More precisely, it is shown that if the n\\times n-sensing matrices\ncontain, on average, \\Omega(nlog n) entries, the number of measurements\nrequired is the same as that when the sensing matrices are dense and contain\nentries drawn uniformly at random from the field. Analogies are drawn between\nthe above results and rank-metric codes in the coding theory literature. In\nfact, we are also strongly motivated by understanding when minimum rank\ndistance decoding of random rank-metric codes succeeds. To this end, we derive\ndistance properties of equiprobable and sparse rank-metric codes. These\ndistance properties provide a precise geometric interpretation of the fact that\nthe sparse ensemble requires as few measurements as the dense one. Finally, we\nprovide a non-exhaustive procedure to search for the unknown low-rank matrix. \n\n"}
{"id": "1105.2858", "contents": "Title: A Reconstruction Method for Band-Limited Signals on the Hyperbolic Plane Abstract: A notion of band limited functions is considered in the case of the\nhyperbolic plane in its Poincare upper half-plane $\\mathbb{H}$ realization. The\nconcept of band-limitedness is based on the existence of the Helgason-Fourier\ntransform on $\\mathbb{H}$. An iterative algorithm is presented, which allows to\nreconstruct band-limited functions from some countable sets of their values. It\nis shown that for sufficiently dense metric lattices a geometric rate of\nconvergence can be guaranteed as long as the sampling density is high enough\ncompared to the band-width of the sampled function. \n\n"}
{"id": "1105.6150", "contents": "Title: A Strictly Improved Achievable Region for Multiple Descriptions Using\n  Combinatorial Message Sharing Abstract: We recently proposed a new coding scheme for the L-channel multiple\ndescriptions (MD) problem for general sources and distortion measures involving\n`Combinatorial Message Sharing' (CMS) [7] leading to a new achievable\nrate-distortion region. Our objective in this paper is to establish that this\ncoding scheme strictly subsumes the most popular region for this problem due to\nVenkataramani, Kramer and Goyal (VKG) [3]. In particular, we show that for a\nbinary symmetric source under Hamming distortion measure, the CMS scheme\nprovides a strictly larger region for all L>2. The principle of the CMS coding\nscheme is to include a common message in every subset of the descriptions,\nunlike the VKG scheme which sends a single common message in all the\ndescriptions. In essence, we show that allowing for a common codeword in every\nsubset of descriptions provides better freedom in coordinating the messages\nwhich can be exploited constructively to achieve points outside the VKG region. \n\n"}
{"id": "1106.0027", "contents": "Title: On the geometry of wireless network multicast in 2-D Abstract: We provide a geometric solution to the problem of optimal relay positioning\nto maximize the multicast rate for low-SNR networks. The networks we consider,\nconsist of a single source, multiple receivers and the only intermediate and\nlocatable node as the relay. We construct network the hypergraph of the system\nnodes from the underlying information theoretic model of low-SNR regime that\noperates using superposition coding and FDMA in conjunction (which we call the\n\"achievable hypergraph model\"). We make the following contributions. 1) We show\nthat the problem of optimal relay positioning maximizing the multicast rate can\nbe completely decoupled from the flow optimization by noticing and exploiting\ngeometric properties of multicast flow. 2) All the flow maximizing the\nmulticast rate is sent over at most two paths, in succession. The relay\nposition is dependent only on one path (out of the two), irrespective of the\nnumber of receiver nodes in the system. Subsequently, we propose simple and\nefficient geometric algorithms to compute the optimal relay position. 3)\nFinally, we show that in our model at the optimal relay position, the\ndifference between the maximized multicast rate and the cut-set bound is\nminimum. We solve the problem for all (Ps,Pr) pairs of source and relay\ntransmit powers and the path loss exponent \\alpha greater than 2. \n\n"}
{"id": "1106.5295", "contents": "Title: Two-sided random walks conditioned to have no intersections Abstract: Let $S^{1},S^{2}$ be independent simple random walks in $\\mathbb{Z}^{d}$\n($d=2,3$) started at the origin. We construct two-sided random walk paths\nconditioned that $S^{1}[0,\\infty) \\cap S^{2}[1, \\infty) = \\emptyset$. \n\n"}
{"id": "1106.5367", "contents": "Title: Partial Interference Alignment for K-user MIMO Interference Channels Abstract: In this paper, we consider a Partial Interference Alignment and Interference\nDetection (PIAID) design for $K$-user quasi-static MIMO interference channels\nwith discrete constellation inputs. Each transmitter has M antennas and\ntransmits L independent data streams to the desired receiver with N receive\nantennas. We focus on the case where not all K-1 interfering transmitters can\nbe aligned at every receiver. As a result, there will be residual interference\nat each receiver that cannot be aligned. Each receiver detects and cancels the\nresidual interference based on the constellation map. However, there is a\nwindow of unfavorable interference profile at the receiver for Interference\nDetection (ID). In this paper, we propose a low complexity Partial Interference\nAlignment scheme in which we dynamically select the user set for IA so as to\ncreate a favorable interference profile for ID at each receiver. We first\nderive the average symbol error rate (SER) by taking into account of the\nnon-Guassian residual interference due to discrete constellation. Using graph\ntheory, we then devise a low complexity user set selection algorithm for the\nPIAID scheme,which minimizes the asymptotically tight bound for the average\nend-to-end SER performance. Moreover, we substantially simplify interference\ndetection at the receiver using Semi-Definite Relaxation (SDR) techniques. It\nis shown that the SER performance of the proposed PIAID scheme has significant\ngain compared with various conventional baseline solutions. \n\n"}
{"id": "1106.5387", "contents": "Title: Subspace Properties of Network Coding and their Applications Abstract: Systems that employ network coding for content distribution convey to the\nreceivers linear combinations of the source packets. If we assume randomized\nnetwork coding, during this process the network nodes collect random subspaces\nof the space spanned by the source packets. We establish several fundamental\nproperties of the random subspaces induced in such a system, and show that\nthese subspaces implicitly carry topological information about the network and\nits state that can be passively collected and inferred. We leverage this\ninformation towards a number of applications that are interesting in their own\nright, such as topology inference, bottleneck discovery in peer-to-peer systems\nand locating Byzantine attackers. We thus argue that, randomized network\ncoding, apart from its better known properties for improving information\ndelivery rate, can additionally facilitate network management and control. \n\n"}
{"id": "1106.6224", "contents": "Title: Structured Compressed Sensing: From Theory to Applications Abstract: Compressed sensing (CS) is an emerging field that has attracted considerable\nresearch interest over the past few years. Previous review articles in CS limit\ntheir scope to standard discrete-to-discrete measurement architectures using\nmatrices of randomized nature and signal models based on standard sparsity. In\nrecent years, CS has worked its way into several new application areas. This,\nin turn, necessitates a fresh look on many of the basics of CS. The random\nmatrix measurement operator must be replaced by more structured sensing\narchitectures that correspond to the characteristics of feasible acquisition\nhardware. The standard sparsity prior has to be extended to include a much\nricher class of signals and to encode broader data models, including\ncontinuous-time signals. In our overview, the theme is exploiting signal and\nmeasurement structure in compressive sensing. The prime focus is bridging\ntheory and practice; that is, to pinpoint the potential of structured CS\nstrategies to emerge from the math to the hardware. Our summary highlights new\ndirections as well as relations to more traditional CS, with the hope of\nserving both as a review to practitioners wanting to join this emerging field,\nand as a reference for researchers that attempts to put some of the existing\nideas in perspective of practical applications. \n\n"}
{"id": "1107.2972", "contents": "Title: An MCMC Approach to Universal Lossy Compression of Analog Sources Abstract: Motivated by the Markov chain Monte Carlo (MCMC) approach to the compression\nof discrete sources developed by Jalali and Weissman, we propose a lossy\ncompression algorithm for analog sources that relies on a finite reproduction\nalphabet, which grows with the input length. The algorithm achieves, in an\nappropriate asymptotic sense, the optimum Shannon theoretic tradeoff between\nrate and distortion, universally for stationary ergodic continuous amplitude\nsources. We further propose an MCMC-based algorithm that resorts to a reduced\nreproduction alphabet when such reduction does not prevent achieving the\nShannon limit. The latter algorithm is advantageous due to its reduced\ncomplexity and improved rates of convergence when employed on sources with a\nfinite and small optimum reproduction alphabet. \n\n"}
{"id": "1107.4623", "contents": "Title: A Unifying Analysis of Projected Gradient Descent for\n  $\\ell_p$-constrained Least Squares Abstract: In this paper we study the performance of the Projected Gradient Descent(PGD)\nalgorithm for $\\ell_{p}$-constrained least squares problems that arise in the\nframework of Compressed Sensing. Relying on the Restricted Isometry Property,\nwe provide convergence guarantees for this algorithm for the entire range of\n$0\\leq p\\leq1$, that include and generalize the existing results for the\nIterative Hard Thresholding algorithm and provide a new accuracy guarantee for\nthe Iterative Soft Thresholding algorithm as special cases. Our results suggest\nthat in this group of algorithms, as $p$ increases from zero to one, conditions\nrequired to guarantee accuracy become stricter and robustness to noise\ndeteriorates. \n\n"}
{"id": "1108.0477", "contents": "Title: Asymptotic Analysis of Complex LASSO via Complex Approximate Message\n  Passing (CAMP) Abstract: Recovering a sparse signal from an undersampled set of random linear\nmeasurements is the main problem of interest in compressed sensing. In this\npaper, we consider the case where both the signal and the measurements are\ncomplex. We study the popular reconstruction method of $\\ell_1$-regularized\nleast squares or LASSO. While several studies have shown that the LASSO\nalgorithm offers desirable solutions under certain conditions, the precise\nasymptotic performance of this algorithm in the complex setting is not yet\nknown. In this paper, we extend the approximate message passing (AMP) algorithm\nto the complex signals and measurements and obtain the complex approximate\nmessage passing algorithm (CAMP). We then generalize the state evolution\nframework recently introduced for the analysis of AMP, to the complex setting.\nUsing the state evolution, we derive accurate formulas for the phase transition\nand noise sensitivity of both LASSO and CAMP. \n\n"}
{"id": "1108.5025", "contents": "Title: Robust Stackelberg game in communication systems Abstract: This paper studies multi-user communication systems with two groups of users:\nleaders which possess system information, and followers which have no system\ninformation using the formulation of Stackelberg games. In such games, the\nleaders play and choose their actions based on their information about the\nsystem and the followers choose their actions myopically according to their\nobservations of the aggregate impact of other users. However, obtaining the\nexact value of these parameters is not practical in communication systems. To\nstudy the effect of uncertainty and preserve the players' utilities in these\nconditions, we introduce a robust equilibrium for Stackelberg games. In this\nframework, the leaders' information and the followers' observations are\nuncertain parameters, and the leaders and the followers choose their actions by\nsolving the worst-case robust optimizations. We show that the followers'\nuncertain parameters always increase the leaders' utilities and decrease the\nfollowers' utilities. Conversely, the leaders' uncertain information reduces\nthe leaders' utilities and increases the followers' utilities. We illustrate\nour theoretical results with the numerical results obtained based on the power\ncontrol games in the interference channels. \n\n"}
{"id": "1108.5881", "contents": "Title: Spread Decoding in Extension Fields Abstract: A spread code is a set of vector spaces of a fixed dimension over a finite\nfield Fq with certain properties used for random network coding. It can be\nconstructed in different ways which lead to different decoding algorithms. In\nthis work we present a new representation of spread codes with a minimum\ndistance decoding algorithm which is efficient when the codewords, the received\nspace and the error space have small dimension. \n\n"}
{"id": "1109.1255", "contents": "Title: Interference Mitigation in Large Random Wireless Networks Abstract: A central problem in the operation of large wireless networks is how to deal\nwith interference -- the unwanted signals being sent by transmitters that a\nreceiver is not interested in. This thesis looks at ways of combating such\ninterference.\n  In Chapters 1 and 2, we outline the necessary information and communication\ntheory background, including the concept of capacity. We also include an\noverview of a new set of schemes for dealing with interference known as\ninterference alignment, paying special attention to a channel-state-based\nstrategy called ergodic interference alignment.\n  In Chapter 3, we consider the operation of large regular and random networks\nby treating interference as background noise. We consider the local performance\nof a single node, and the global performance of a very large network.\n  In Chapter 4, we use ergodic interference alignment to derive the asymptotic\nsum-capacity of large random dense networks. These networks are derived from a\nphysical model of node placement where signal strength decays over the distance\nbetween transmitters and receivers. (See also arXiv:1002.0235 and\narXiv:0907.5165.)\n  In Chapter 5, we look at methods of reducing the long time delays incurred by\nergodic interference alignment. We analyse the tradeoff between reducing delay\nand lowering the communication rate. (See also arXiv:1004.0208.)\n  In Chapter 6, we outline a problem that is equivalent to the problem of\npooled group testing for defective items. We then present some new work that\nuses information theoretic techniques to attack group testing. We introduce for\nthe first time the concept of the group testing channel, which allows for\nmodelling of a wide range of statistical error models for testing. We derive\nnew results on the number of tests required to accurately detect defective\nitems, including when using sequential `adaptive' tests. \n\n"}
{"id": "1109.2560", "contents": "Title: Moment-Based Evidence for Simple Rational-Valued Hilbert-Schmidt Generic\n  2 x 2 Separability Probabilities Abstract: Employing Hilbert-Schmidt measure, we explicitly compute and analyze a number\nof determinantal product (bivariate) moments |rho|^k |rho^{PT}|^n,\nk,n=0,1,2,3,..., PT denoting partial transpose, for both generic\n(9-dimensional) two-rebit (alpha = 1/2) and generic (15-dimensional) two-qubit\n(alpha=1) density matrices rho. The results are, then, incorporated by Dunkl\ninto a general formula (Appendix D6), parameterized by k, n and alpha, with the\ncase alpha=2, presumptively corresponding to generic (27-dimensional)\nquaternionic systems. Holding the Dyson-index-like parameter alpha fixed, the\ninduced univariate moments (|rho| |rho^{PT}|)^n and |rho^{PT}|^n are inputted\ninto a Legendre-polynomial-based (least-squares) probability-distribution\nreconstruction algorithm of Provost (Mathematica J., 9, 727 (2005)), yielding\nalpha-specific separability probability estimates. Since, as the number of\ninputted moments grows, estimates based on |rho| |rho^{PT}| strongly decrease,\nwhile ones employing |rho^{PT}| strongly increase (and converge faster), the\ngaps between upper and lower estimates diminish, yielding sharper and sharper\nbounds. Remarkably, for alpha = 2, with the use of 2,325 moments, a\nseparability-probability lower-bound 0.999999987 as large as 26/323 = 0.0804954\nis found. For alpha=1, based on 2,415 moments, a lower bound results that is\n0.999997066 times as large as 8/33 = 0.242424, a (simpler still) fractional\nvalue that had previously been conjectured (J. Phys. A, 40, 14279 (2007)).\nFurthermore, for alpha = 1/2, employing 3,310 moments, the lower bound is\n0.999955 times as large as 29/64 = 0.453125, a rational value previously\nconsidered (J. Phys. A, 43, 195302 (2010)). \n\n"}
{"id": "1109.2992", "contents": "Title: Downlink Capacity and Base Station Density in Cellular Networks Abstract: There have been a bulk of analytic results about the performance of cellular\nnetworks where base stations are regularly located on a hexagonal or square\nlattice. This regular model cannot reflect the reality, and tends to\noverestimate the network performance. Moreover, tractable analysis can be\nperformed only for a fixed location user (e.g., cell center or edge user). In\nthis paper, we use the stochastic geometry approach, where base stations can be\nmodeled as a homogeneous Poisson point process. We also consider the user\ndensity, and derive the user outage probability that an arbitrary user is under\noutage owing to low signal-to-interference-plus-noise ratio or high congestion\nby multiple users. Using the result, we calculate the density of success\ntransmissions in the downlink cellular network. An interesting observation is\nthat the success transmission density increases with the base station density,\nbut the increasing rate diminishes. This means that the number of base stations\ninstalled should be more than $n$-times to increase the network capacity by a\nfactor of $n$. Our results will provide a framework for performance analysis of\nthe wireless infrastructure with a high density of access points, which will\nsignificantly reduce the burden of network-level simulations. \n\n"}
{"id": "1109.3195", "contents": "Title: Efficient Quantum Polar Coding Abstract: Polar coding, introduced 2008 by Arikan, is the first (very) efficiently\nencodable and decodable coding scheme whose information transmission rate\nprovably achieves the Shannon bound for classical discrete memoryless channels\nin the asymptotic limit of large block sizes. Here we study the use of polar\ncodes for the transmission of quantum information. Focusing on the case of\nqubit Pauli channels and qubit erasure channels, we use classical polar codes\nto construct a coding scheme which, using some pre-shared entanglement,\nasymptotically achieves a net transmission rate equal to the coherent\ninformation using efficient encoding and decoding operations and code\nconstruction. Furthermore, for channels with sufficiently low noise level, we\ndemonstrate that the rate of preshared entanglement required is zero. \n\n"}
{"id": "1109.4074", "contents": "Title: Secure Multiplex Coding Over Interference Channel with Confidential\n  Messages Abstract: In this paper, inner and outer bounds on the capacity region of two-user\ninterference channels with two confidential messages have been proposed. By\nadding secure multiplex coding to the error correction method in [15] which\nachieves the best achievable capacity region for interference channel up to\nnow, we have shown that the improved secure capacity region compared with [2]\nnow is the whole Han-Kobayashi region. In addition, this construction not only\nremoves the rate loss incurred by adding dummy messages to achieve security,\nbut also change the original weak security condition in [2] to strong security.\nThen the equivocation rate for a collection of secret messages has also been\nevaluated, when the length of the message is finite or the information rate is\nhigh, our result provides a good approximation for bounding the worst case\nequivocation rate. Our results can be readily extended to the Gaussian\ninterference channel with little efforts. \n\n"}
{"id": "1109.4179", "contents": "Title: FemtoCaching: Wireless Video Content Delivery through Distributed\n  Caching Helpers Abstract: Video on-demand streaming from Internet-based servers is becoming one of the\nmost important services offered by wireless networks today. In order to improve\nthe area spectral efficiency of video transmission in cellular systems, small\ncells heterogeneous architectures (e.g., femtocells, WiFi off-loading) are\nbeing proposed, such that video traffic to nomadic users can be handled by\nshort-range links to the nearest small cell access points (referred to as\n\"helpers\"). As the helper deployment density increases, the backhaul capacity\nbecomes the system bottleneck. In order to alleviate such bottleneck we propose\na system where helpers with low-rate backhaul but high storage capacity cache\npopular video files. Files not available from helpers are transmitted by the\ncellular base station. We analyze the optimum way of assigning files to the\nhelpers, in order to minimize the expected downloading time for files. We\ndistinguish between the uncoded case (where only complete files are stored) and\nthe coded case, where segments of Fountain-encoded versions of the video files\nare stored at helpers. We show that the uncoded optimum file assignment is\nNP-hard, and develop a greedy strategy that is provably within a factor 2 of\nthe optimum. Further, for a special case we provide an efficient algorithm\nachieving a provably better approximation ratio of $1-(1-1/d)^d$, where $d$ is\nthe maximum number of helpers a user can be connected to. We also show that the\ncoded optimum cache assignment problem is convex that can be further reduced to\na linear program. We present numerical results comparing the proposed schemes. \n\n"}
{"id": "1109.5779", "contents": "Title: The Degrees of Freedom Region of the MIMO Interference Channel with\n  Shannon Feedback Abstract: The two-user multiple-input multiple-output (MIMO) fast-fading interference\nchannel (IC) with an arbitrary number of antennas at each of the four terminals\nis studied under the settings of Shannon feedback, limited Shannon feedback,\nand output feedback, wherein all or certain channel matrices and outputs, or\njust the channel outputs, respectively, are available to the transmitters with\na finite delay. While for most numbers of antennas at the four terminals, it is\nshown that the DoF regions with Shannon feedback and for the limited Shannon\nfeedback settings considered here are identical, and equal to the DoF region\nwith just delayed channel state information (CSIT), it is shown that this is\nnot always the case. For a specific class of MIMO ICs characterized by a\ncertain relationship between the numbers of antennas at the four nodes, the DoF\nregions with Shannon and the limited Shannon feedback settings, while again\nbeing identical, are strictly bigger than the DoF region with just delayed\nCSIT. To realize these DoF gains with Shannon or limited Shannon feedback, a\nnew retrospective interference alignment scheme is developed wherein\ntransmitter cooperation made possible by output feedback in addition to delayed\nCSIT is employed to effect a more efficient form of interference alignment than\nis feasible with previously known schemes that use just delayed CSIT. The DoF\nregion for just output feedback, in which each transmitter has delayed\nknowledge of only the receivers' outputs, is also obtained for all but a class\nof MIMO ICs that satisfy one of two inequalities involving the numbers of\nantennas. \n\n"}
{"id": "1110.1237", "contents": "Title: Free Deterministic Equivalents, Rectangular Random Matrix Models, and\n  Operator-Valued Free Probability Theory Abstract: Motivated by the asymptotic collective behavior of random and deterministic\nmatrices, we propose an approximation (called \"free deterministic equivalent\")\nto quite general random matrix models, by replacing the matrices with operators\nsatisfying certain freeness relations. We comment on the relation between our\nfree deterministic equivalent and deterministic equivalents considered in the\nengineering literature. We do not only consider the case of square matrices,\nbut also show how rectangular matrices can be treated. Furthermore, we\nemphasize how operator-valued free probability techniques can be used to solve\nour free deterministic equivalents.\n  As an illustration of our methods we consider a random matrix model studied\nfirst by R. Couillet, J. Hoydis, and M. Debbah. We show how its free\ndeterministic equivalent can be treated and we thus recover in a conceptual way\ntheir result.\n  On a technical level, we generalize a result from scalar valued free\nprobability, by showing that randomly rotated deterministic matrices of\ndifferent sizes are asymptotically free from deterministic rectangular\nmatrices, with amalgamation over a certain algebra of projections.\n  In the Appendix, we show how estimates for differences between Cauchy\ntransforms can be extended from a neighborhood of infinity to a region close to\nthe real axis. This is of some relevance if one wants to compare the original\nrandom matrix problem with its free deterministic equivalent. \n\n"}
{"id": "1110.3559", "contents": "Title: Separation of source-network coding and channel coding in wireline\n  networks Abstract: In this paper we prove the separation of source-network coding and channel\ncoding in wireline networks. For the purposes of this work, a wireline network\nis any network of independent, memoryless, point-to-point, finite-alphabet\nchannels used to transmit dependent sources either losslessly or subject to a\ndistortion constraint. In deriving this result, we also prove that in a general\nmemoryless network with dependent sources, lossless and zero-distortion\nreconstruction are equivalent provided that the conditional entropy of each\nsource given the other sources is non-zero. Furthermore, we extend the\nseparation result to the case of continuous-alphabet, point-to-point channels\nsuch as additive white Gaussian noise (AWGN) channels. \n\n"}
{"id": "1110.5176", "contents": "Title: Demodulating Subsampled Direct Sequence Spread Spectrum Signals using\n  Compressive Signal Processing Abstract: We show that to lower the sampling rate in a spread spectrum communication\nsystem using Direct Sequence Spread Spectrum (DSSS), compressive signal\nprocessing can be applied to demodulate the received signal. This may lead to a\ndecrease in the power consumption or the manufacturing price of wireless\nreceivers using spread spectrum technology. The main novelty of this paper is\nthe discovery that in spread spectrum systems it is possible to apply\ncompressive sensing with a much simpler hardware architecture than in other\nsystems, making the implementation both simpler and more energy efficient. Our\ntheoretical work is exemplified with a numerical experiment using the IEEE\n802.15.4 standard's 2.4 GHz band specification. The numerical results support\nour theoretical findings and indicate that compressive sensing may be used\nsuccessfully in spread spectrum communication systems. The results obtained\nhere may also be applicable in other spread spectrum technologies, such as Code\nDivision Multiple Access (CDMA) systems. \n\n"}
{"id": "1111.2251", "contents": "Title: On the Optimal Transmission Scheme to Maximize Local Capacity in\n  Wireless Networks Abstract: We study the optimal transmission scheme that maximizes the local capacity in\ntwo-dimensional (2D) wireless networks. Local capacity is defined as the\naverage information rate received by a node randomly located in the network.\nUsing analysis based on analytical and numerical methods, we show that maximum\nlocal capacity can be obtained if simultaneous emitters are positioned in a\ngrid pattern based on equilateral triangles. We also compare this maximum local\ncapacity with the local capacity of slotted ALOHA scheme and our results show\nthat slotted ALOHA can achieve at least half of the maximum local capacity in\nwireless networks. \n\n"}
{"id": "1111.2456", "contents": "Title: Repeated Games With Intervention: Theory and Applications in\n  Communications Abstract: In communication systems where users share common resources, users' selfish\nbehavior usually results in suboptimal resource utilization. There have been\nextensive works that model communication systems with selfish users as one-shot\ngames and propose incentive schemes to achieve Pareto optimal action profiles\nas non-cooperative equilibria. However, in many communication systems, due to\nstrong negative externalities among users, the sets of feasible payoffs in\none-shot games are nonconvex. Thus, it is possible to expand the set of\nfeasible payoffs by having users choose convex combinations of different\npayoffs. In this paper, we propose a repeated game model generalized by\nintervention. First, we use repeated games to convexify the set of feasible\npayoffs in one-shot games. Second, we combine conventional repeated games with\nintervention, originally proposed for one-shot games, to achieve a larger set\nof equilibrium payoffs and loosen requirements for users' patience to achieve\nit. We study the problem of maximizing a welfare function defined on users'\nequilibrium payoffs, subject to minimum payoff guarantees. Given the optimal\nequilibrium payoff, we derive the minimum intervention capability required and\ndesign corresponding equilibrium strategies. The proposed generalized repeated\ngame model applies to various communication systems, such as power control and\nflow control. \n\n"}
{"id": "1111.2637", "contents": "Title: Some Extremal Self-Dual Codes and Unimodular Lattices in Dimension 40 Abstract: In this paper, binary extremal singly even self-dual codes of length 40 and\nextremal odd unimodular lattices in dimension 40 are studied. We give a\nclassification of extremal singly even self-dual codes of length 40. We also\ngive a classification of extremal odd unimodular lattices in dimension 40 with\nshadows having 80 vectors of norm 2 through their relationships with extremal\ndoubly even self-dual codes of length 40. \n\n"}
{"id": "1111.3274", "contents": "Title: Pilotless Recovery of Clipped OFDM Signals by Compressive Sensing over\n  Reliable Data Carriers Abstract: In this paper we propose a novel form of clipping mitigation in OFDM using\ncompressive sensing that completely avoids tone reservation and hence rate loss\nfor this purpose. The method builds on selecting the most reliable\nperturbations from the constellation lattice upon decoding at the receiver, and\nperforms compressive sensing over these observations in order to completely\nrecover the temporally sparse nonlinear distortion. As such, the method\nprovides a unique practical solution to the problem of initial erroneous\ndecoding decisions in iterative ML methods, offering both the ability to\naugment these techniques and to solely recover the distorted signal in one\nshot. \n\n"}
{"id": "1111.4596", "contents": "Title: Grassmannian Differential Limited Feedback for Interference Alignment Abstract: Channel state information (CSI) in the interference channel can be used to\nprecode, align, and reduce the dimension of interference at the receivers, to\nachieve the channel's maximum multiplexing gain, through what is known as\ninterference alignment. Most interference alignment algorithms require\nknowledge of all the interfering channels to compute the alignment precoders.\nCSI, considered available at the receivers, can be shared with the transmitters\nvia limited feedback. When alignment is done by coding over frequency\nextensions in a single antenna system, the required CSI lies on the\nGrassmannian manifold and its structure can be exploited in feedback.\nUnfortunately, the number of channels to be shared grows with the square of the\nnumber of users, creating too much overhead with conventional feedback methods.\nThis paper proposes Grassmannian differential feedback to reduce feedback\noverhead by exploiting both the channel's temporal correlation and Grassmannian\nstructure. The performance of the proposed algorithm is characterized both\nanalytically and numerically as a function of channel length, mobility, and the\nnumber of feedback bits. The main conclusions are that the proposed feedback\nstrategy allows interference alignment to perform well over a wide range of\nDoppler spreads, and to approach perfect CSI performance in slowly varying\nchannels. Numerical results highlight the trade-off between the frequency of\nfeedback and the accuracy of individual feedback updates. \n\n"}
{"id": "1111.5950", "contents": "Title: Non-Linear Transformations of Gaussians and Gaussian-Mixtures with\n  implications on Estimation and Information Theory Abstract: This paper investigates the statistical properties of non-linear\ntransformations (NLT) of random variables, in order to establish useful tools\nfor estimation and information theory. Specifically, the paper focuses on\nlinear regression analysis of the NLT output and derives sufficient general\nconditions to establish when the input-output regression coefficient is equal\nto the \\emph{partial} regression coefficient of the output with respect to a\n(additive) part of the input. A special case is represented by zero-mean\nGaussian inputs, obtained as the sum of other zero-mean Gaussian random\nvariables. The paper shows how this property can be generalized to the\nregression coefficient of non-linear transformations of Gaussian-mixtures. Due\nto its generality, and the wide use of Gaussians and Gaussian-mixtures to\nstatistically model several phenomena, this theoretical framework can find\napplications in multiple disciplines, such as communication, estimation, and\ninformation theory, when part of the nonlinear transformation input is the\nquantity of interest and the other part is the noise. In particular, the paper\nshows how the said properties can be exploited to simplify closed-form\ncomputation of the signal-to-noise ratio (SNR), the estimation mean-squared\nerror (MSE), and bounds on the mutual information in additive non-Gaussian\n(possibly non-linear) channels, also establishing relationships among them. \n\n"}
{"id": "1112.0674", "contents": "Title: Analytical Evaluation of Fractional Frequency Reuse for Heterogeneous\n  Cellular Networks Abstract: Interference management techniques are critical to the performance of\nheterogeneous cellular networks, which will have dense and overlapping coverage\nareas, and experience high levels of interference. Fractional frequency reuse\n(FFR) is an attractive interference management technique due to its low\ncomplexity and overhead, and significant coverage improvement for\nlow-percentile (cell-edge) users. Instead of relying on system simulations\nbased on deterministic access point locations, this paper instead proposes an\nanalytical model for evaluating Strict FFR and Soft Frequency Reuse (SFR)\ndeployments based on the spatial Poisson point process. Our results both\ncapture the non-uniformity of heterogeneous deployments and produce tractable\nexpressions which can be used for system design with Strict FFR and SFR. We\nobserve that the use of Strict FFR bands reserved for the users of each tier\nwith the lowest average SINR provides the highest gains in terms of coverage\nand rate, while the use of SFR allows for more efficient use of shared spectrum\nbetween the tiers, while still mitigating much of the interference.\nAdditionally, in the context of multi-tier networks with closed access in some\ntiers, the proposed framework shows the impact of cross-tier interference on\nclosed access FFR, and informs the selection of key FFR parameters in open\naccess. \n\n"}
{"id": "1112.0789", "contents": "Title: On the error of estimating the sparsest solution of underdetermined\n  linear systems Abstract: Let A be an n by m matrix with m>n, and suppose that the underdetermined\nlinear system As=x admits a sparse solution s0 for which ||s0||_0 < 1/2\nspark(A). Such a sparse solution is unique due to a well-known uniqueness\ntheorem. Suppose now that we have somehow a solution s_hat as an estimation of\ns0, and suppose that s_hat is only `approximately sparse', that is, many of its\ncomponents are very small and nearly zero, but not mathematically equal to\nzero. Is such a solution necessarily close to the true sparsest solution? More\ngenerally, is it possible to construct an upper bound on the estimation error\n||s_hat-s0||_2 without knowing s0? The answer is positive, and in this paper we\nconstruct such a bound based on minimal singular values of submatrices of A. We\nwill also state a tight bound, which is more complicated, but besides being\ntight, enables us to study the case of random dictionaries and obtain\nprobabilistic upper bounds. We will also study the noisy case, that is, where\nx=As+n. Moreover, we will see that where ||s0||_0 grows, to obtain a\npredetermined guaranty on the maximum of ||s_hat-s0||_2, s_hat is needed to be\nsparse with a better approximation. This can be seen as an explanation to the\nfact that the estimation quality of sparse recovery algorithms degrades where\n||s0||_0 grows. \n\n"}
{"id": "1112.1762", "contents": "Title: Heegard-Berger and Cascade Source Coding Problems with Common\n  Reconstruction Constraints Abstract: For the HB problem with the CR constraint, the rate-distortion function is\nderived under the assumption that the side information sequences are\n(stochastically) degraded. The rate-distortion function is also calculated\nexplicitly for three examples, namely Gaussian source and side information with\nquadratic distortion metric, and binary source and side information with\nerasure and Hamming distortion metrics. The rate-distortion function is then\ncharacterized for the HB problem with cooperating decoders and (physically)\ndegraded side information. For the cascade problem with the CR constraint, the\nrate-distortion region is obtained under the assumption that side information\nat the final node is physically degraded with respect to that at the\nintermediate node. For the latter two cases, it is worth emphasizing that the\ncorresponding problem without the CR constraint is still open. Outer and inner\nbounds on the rate-distortion region are also obtained for the cascade problem\nunder the assumption that the side information at the intermediate node is\nphysically degraded with respect to that at the final node. For the three\nexamples mentioned above, the bounds are shown to coincide. Finally, for the HB\nproblem, the rate-distortion function is obtained under the more general\nrequirement of constrained reconstruction, whereby the decoder's estimate must\nbe recovered at the encoder only within some distortion. \n\n"}
{"id": "1112.2493", "contents": "Title: Symbolic transfer entropy rate is equal to transfer entropy rate for\n  bivariate finite-alphabet stationary ergodic Markov processes Abstract: Transfer entropy is a measure of the magnitude and the direction of\ninformation flow between jointly distributed stochastic processes. In recent\nyears, its permutation analogues are considered in the literature to estimate\nthe transfer entropy by counting the number of occurrences of orderings of\nvalues, not the values themselves. It has been suggested that the method of\npermutation is easy to implement, computationally low cost and robust to noise\nwhen applying to real world time series data. In this paper, we initiate a\ntheoretical treatment of the corresponding rates. In particular, we consider\nthe transfer entropy rate and its permutation analogue, the symbolic transfer\nentropy rate, and show that they are equal for any bivariate finite-alphabet\nstationary ergodic Markov process. This result is an illustration of the\nduality method introduced in [T. Haruna and K. Nakajima, Physica D 240, 1370\n(2011)]. We also discuss the relationship among the transfer entropy rate, the\ntime-delayed mutual information rate and their permutation analogues. \n\n"}
{"id": "1112.5767", "contents": "Title: Optimal Resource Allocation and Relay Selection in Bandwidth Exchange\n  Based Cooperative Forwarding Abstract: In this paper, we investigate joint optimal relay selection and resource\nallocation under bandwidth exchange (BE) enabled incentivized cooperative\nforwarding in wireless networks. We consider an autonomous network where N\nnodes transmit data in the uplink to an access point (AP) / base station (BS).\nWe consider the scenario where each node gets an initial amount (equal, optimal\nbased on direct path or arbitrary) of bandwidth, and uses this bandwidth as a\nflexible incentive for two hop relaying. We focus on alpha-fair network utility\nmaximization (NUM) and outage reduction in this environment. Our contribution\nis two-fold. First, we propose an incentivized forwarding based resource\nallocation algorithm which maximizes the global utility while preserving the\ninitial utility of each cooperative node. Second, defining the link weight of\neach relay pair as the utility gain due to cooperation (over noncooperation),\nwe show that the optimal relay selection in alpha-fair NUM reduces to the\nmaximum weighted matching (MWM) problem in a non-bipartite graph. Numerical\nresults show that the proposed algorithms provide 20- 25% gain in spectral\nefficiency and 90-98% reduction in outage probability. \n\n"}
{"id": "1201.6465", "contents": "Title: An Information-Spectrum Approach to the Capacity Region of General\n  Interference Channel Abstract: This paper is concerned with general interference channels characterized by a\nsequence of transition (conditional) probabilities. We present a general\nformula for the capacity region of the interference channel with two pairs of\nusers. The formula shows that the capacity region is the union of a family of\nrectangles, where each rectangle is determined by a pair of spectral inf-mutual\ninformation rates. Although the presented formula is usually difficult to\ncompute, it provides us useful insights into the interference channels. For\nexample, the formula suggests us that the simplest inner bounds (obtained by\ntreating the interference as noise) could be improved by taking into account\nthe structure of the interference processes. This is verified numerically by\ncomputing the mutual information rates for Gaussian interference channels with\nembedded convolutional codes. \n\n"}
{"id": "1202.0307", "contents": "Title: Protocol Coding through Reordering of User Resources, Part I: Capacity\n  Results Abstract: The vast existing wireless infrastructure features a variety of systems and\nstandards. It is of significant practical value to introduce new features and\ndevices without changing the physical layer/hardware infrastructure, but\nupgrade it only in software. A way to achieve it is to apply protocol coding:\nencode information in the actions taken by a certain (existing) communication\nprotocol. In this work we investigate strategies for protocol coding via\ncombinatorial ordering of the labelled user resources (packets, channels) in an\nexisting, primary system. Such a protocol coding introduces a new secondary\ncommunication channel in the existing system, which has been considered in the\nprior work exclusively in a steganographic context. Instead, we focus on the\nuse of secondary channel for reliable communication with newly introduced\nsecondary devices, that are low-complexity versions of the primary devices,\ncapable only to decode the robustly encoded header information in the primary\nsignals. We introduce a suitable communication model, capable to capture the\nconstraints that the primary system operation puts on protocol coding. We have\nderived the capacity of the secondary channel under arbitrary error models. The\ninsights from the information-theoretic analysis are used in Part II of this\nwork to design practical error-correcting mechanisms for secondary channels\nwith protocol coding. \n\n"}
{"id": "1202.0325", "contents": "Title: Quantum wiretap channel with non-uniform random number and its exponent\n  and equivocation rate of leaked information Abstract: A usual code for quantum wiretap channel requires an auxiliary random\nvariable subject to the perfect uniform distribution. However, it is difficult\nto prepare such an auxiliary random variable. We propose a code that requires\nonly an auxiliary random variable subject to a non-uniform distribution instead\nof the perfect uniform distribution. Further, we evaluate the exponential\ndecreasing rate of leaked information and derive its equivocation rate. For\npractical constructions, we also discuss the security when our code consists of\na linear error correcting code. \n\n"}
{"id": "1202.0690", "contents": "Title: Minimization of Transmission Duration of Data Packets over an Energy\n  Harvesting Fading Channel Abstract: The offline problem of transmission completion time minimization for an\nenergy harvesting transmitter under fading is extended to allow packet arrivals\nduring transmission. A method for computing an optimal power and rate\nallocation (i.e., an optimal offline schedule) is developed and studied. \n\n"}
{"id": "1202.1909", "contents": "Title: On the Degrees of Freedom of time correlated MISO broadcast channel with\n  delayed CSIT Abstract: We consider the time correlated MISO broadcast channel where the transmitter\nhas partial knowledge on the current channel state, in addition to delayed\nchannel state information (CSI). Rather than exploiting only the current CSI,\nas the zero-forcing precoding, or only the delayed CSI, as the Maddah-Ali-Tse\n(MAT) scheme, we propose a seamless strategy that takes advantage of both. The\nachievable degrees of freedom of the proposed scheme is characterized in terms\nof the quality of the current channel knowledge. \n\n"}
{"id": "1202.2561", "contents": "Title: On the Diversity Gain Region of the Z-interference Channels Abstract: In this work, we analyze the diversity gain region (DGR) of the\nsingle-antenna Rayleigh fading Z-Interference channel (ZIC). More specifically,\nwe characterize the achievable DGR of the fixed-power split Han-Kobayashi (HK)\napproach under these assumptions. Our characterization comes in a closed form\nand demonstrates that the HK scheme with only a common message is a singular\ncase, which achieves the best DGR among all HK schemes for certain multiplexing\ngains. Finally, we show that generalized time sharing, with variable rate and\npower assignments for the common and private messages, does not improve the\nachievable DGR. \n\n"}
{"id": "1202.2875", "contents": "Title: Uplink Performance Analysis of Multicell MU-MIMO Systems with ZF\n  Receivers Abstract: We consider the uplink of a multicell multiuser multiple-input\nmultiple-output system where the channel experiences both small and large-scale\nfading. The data detection is done by using the linear zero-forcing technique,\nassuming the base station (BS) has perfect channel state information. We derive\nnew, exact closed-form expressions for the uplink rate, symbol error rate, and\noutage probability per user, as well as a lower bound on the achievable rate.\nThis bound is very tight and becomes exact in the large-number-of-antennas\nlimit. We further study the asymptotic system performance in the regimes of\nhigh signal-to-noise ratio (SNR), large number of antennas, and large number of\nusers per cell. We show that at high SNRs, the system is interference-limited\nand hence, we cannot improve the system performance by increasing the transmit\npower of each user. Instead, by increasing the number of BS antennas, the\neffects of interference and noise can be reduced, thereby improving the system\nperformance. We demonstrate that, with very large antenna arrays at the BS, the\ntransmit power of each user can be made inversely proportional to the number of\nBS antennas while maintaining a desired quality-of-service. Numerical results\nare presented to verify our analysis. \n\n"}
{"id": "1202.5945", "contents": "Title: A Note on Interference in Random Point Sets Abstract: The (maximum receiver-centric) interference of a geometric graph (von\nRickenbach etal (2005)) is studied. It is shown that, with high probability,\nthe following results hold for a set, V, of n points independently and\nuniformly distributed in the unit d-cube, for constant dimension d: (1) there\nexists a connected graph with vertex set V that has interference O((log\nn)^{1/3}); (2) no connected graph with vertex set V has interference o((log\nn)^{1/4}); and (3) the minimum spanning tree of $V$ has interference\nTheta((\\log n)^{1/2}). \n\n"}
{"id": "1203.0695", "contents": "Title: Cooperative Compute-and-Forward Abstract: We examine the benefits of user cooperation under compute-and-forward. Much\nlike in network coding, receivers in a compute-and-forward network recover\nfinite-field linear combinations of transmitters' messages. Recovery is enabled\nby linear codes: transmitters map messages to a linear codebook, and receivers\nattempt to decode the incoming superposition of signals to an integer\ncombination of codewords. However, the achievable computation rates are low if\nchannel gains do not correspond to a suitable linear combination. In response\nto this challenge, we propose a cooperative approach to compute-and-forward. We\ndevise a lattice-coding approach to block Markov encoding with which we\nconstruct a decode-and-forward style computation strategy. Transmitters\nbroadcast lattice codewords, decode each other's messages, and then\ncooperatively transmit resolution information to aid receivers in decoding the\ninteger combinations. Using our strategy, we show that cooperation offers a\nsignificant improvement both in the achievable computation rate and in the\ndiversity-multiplexing tradeoff. \n\n"}
{"id": "1203.1304", "contents": "Title: Analytical Modeling of Uplink Cellular Networks Abstract: Cellular uplink analysis has typically been undertaken by either a simple\napproach that lumps all interference into a single deterministic or random\nparameter in a Wyner-type model, or via complex system level simulations that\noften do not provide insight into why various trends are observed. This paper\nproposes a novel middle way using point processes that is both accurate and\nalso results in easy-to-evaluate integral expressions based on the Laplace\ntransform of the interference. We assume mobiles and base stations are randomly\nplaced in the network with each mobile pairing up to its closest base station.\nCompared to related recent work on downlink analysis, the proposed uplink model\ndiffers in two key features. First, dependence is considered between user and\nbase station point processes to make sure each base station serves a single\nmobile in the given resource block. Second, per-mobile power control is\nincluded, which further couples the transmission of mobiles due to\nlocation-dependent channel inversion. Nevertheless, we succeed in deriving the\ncoverage (equivalently outage) probability of a typical link in the network.\nThis model can be used to address a wide variety of system design questions in\nthe future. In this paper we focus on the implications for power control and\nsee that partial channel inversion should be used at low\nsignal-to-interference-plus-noise ratio (SINR), while full power transmission\nis optimal at higher SINR. \n\n"}
{"id": "1203.1570", "contents": "Title: In-network Sparsity-regularized Rank Minimization: Algorithms and\n  Applications Abstract: Given a limited number of entries from the superposition of a low-rank matrix\nplus the product of a known fat compression matrix times a sparse matrix,\nrecovery of the low-rank and sparse components is a fundamental task subsuming\ncompressed sensing, matrix completion, and principal components pursuit. This\npaper develops algorithms for distributed sparsity-regularized rank\nminimization over networks, when the nuclear- and $\\ell_1$-norm are used as\nsurrogates to the rank and nonzero entry counts of the sought matrices,\nrespectively. While nuclear-norm minimization has well-documented merits when\ncentralized processing is viable, non-separability of the singular-value sum\nchallenges its distributed minimization. To overcome this limitation, an\nalternative characterization of the nuclear norm is adopted which leads to a\nseparable, yet non-convex cost minimized via the alternating-direction method\nof multipliers. The novel distributed iterations entail reduced-complexity\nper-node tasks, and affordable message passing among single-hop neighbors.\nInterestingly, upon convergence the distributed (non-convex) estimator provably\nattains the global optimum of its centralized counterpart, regardless of\ninitialization. Several application domains are outlined to highlight the\ngenerality and impact of the proposed framework. These include unveiling\ntraffic anomalies in backbone networks, predicting networkwide path latencies,\nand mapping the RF ambiance using wireless cognitive radios. Simulations with\nsynthetic and real network data corroborate the convergence of the novel\ndistributed algorithm, and its centralized performance guarantees. \n\n"}
{"id": "1203.1905", "contents": "Title: Local heuristic for the refinement of multi-path routing in wireless\n  mesh networks Abstract: We consider wireless mesh networks and the problem of routing end-to-end\ntraffic over multiple paths for the same origin-destination pair with minimal\ninterference. We introduce a heuristic for path determination with two\ndistinguishing characteristics. First, it works by refining an extant set of\npaths, determined previously by a single- or multi-path routing algorithm.\nSecond, it is totally local, in the sense that it can be run by each of the\norigins on information that is available no farther than the node's immediate\nneighborhood. We have conducted extensive computational experiments with the\nnew heuristic, using AODV and OLSR, as well as their multi-path variants, as\nunderlying routing methods. For two different CSMA settings (as implemented by\n802.11) and one TDMA setting running a path-oriented link scheduling algorithm,\nwe have demonstrated that the new heuristic is capable of improving the average\nthroughput network-wide. When working from the paths generated by the\nmulti-path routing algorithms, the heuristic is also capable to provide a more\nevenly distributed traffic pattern. \n\n"}
{"id": "1203.2316", "contents": "Title: Near-optimal quantization and linear network coding for relay networks Abstract: We introduce a discrete network corresponding to any Gaussian wireless\nnetwork that is obtained by simply quantizing the received signals and\nrestricting the transmitted signals to a finite precision. Since signals in the\ndiscrete network are obtained from those of a Gaussian network, the Gaussian\nnetwork can be operated on the quantization-based digital interface defined by\nthe discrete network. We prove that this digital interface is near-optimal for\nGaussian relay networks and the capacities of the Gaussian and the discrete\nnetworks are within a bounded gap of O(M^2) bits, where M is the number of\nnodes.\n  We prove that any near-optimal coding strategy for the discrete network can\nbe naturally transformed into a near-optimal coding strategy for the Gaussian\nnetwork merely by quantization. We exploit this by designing a linear coding\nstrategy for the case of layered discrete relay networks. The linear coding\nstrategy is near-optimal for Gaussian and discrete networks and achieves rates\nwithin O(M^2) bits of the capacity, independent of channel gains or SNR. The\nlinear code is robust and the relays need not know the channel gains. The\ntransmit and receive signals at all relays are simply quantized to binary\ntuples of the same length $n$ . The linear network code requires all the relay\nnodes to collect the received binary tuples into a long binary vector and apply\na linear transformation on the long vector. The resulting binary vector is\nsplit into smaller binary tuples for transmission by the relays. The\nquantization requirements of the linear network code are completely defined by\nthe parameter $n$, which also determines the resolution of the\nanalog-to-digital and digital-to-analog convertors for operating the network\nwithin a bounded gap of the network's capacity. The linear network code\nexplicitly connects network coding for wireline networks with codes for\nGaussian networks. \n\n"}
{"id": "1203.3659", "contents": "Title: Cognitive Wyner Networks with Clustered Decoding Abstract: We study an interference network where equally-numbered transmitters and\nreceivers lie on two parallel lines, each transmitter opposite its intended\nreceiver. We consider two short-range interference models: the \"asymmetric\nnetwork,\" where the signal sent by each transmitter is interfered only by the\nsignal sent by its left neighbor (if present), and a \"symmetric network,\" where\nit is interfered by both its left and its right neighbors. Each transmitter is\ncognizant of its own message, the messages of the $t_\\ell$ transmitters to its\nleft, and the messages of the $t_r$ transmitters to its right. Each receiver\ndecodes its message based on the signals received at its own antenna, at the\n$r_\\ell$ receive antennas to its left, and the $r_r$ receive antennas to its\nright. For such networks we provide upper and lower bounds on the multiplexing\ngain, i.e., on the high-SNR asymptotic logarithmic growth of the sum-rate\ncapacity. In some cases our bounds meet, e.g., for the asymmetric network. Our\nresults exhibit an equivalence between the transmitter side-information\nparameters $t_\\ell, t_r$ and the receiver side-information parameters $r_\\ell,\nr_r$ in the sense that increasing/decreasing $t_\\ell$ or $t_r$ by a positive\ninteger $\\delta$ has the same effect on the multiplexing gain as\nincreasing/decreasing $r_\\ell$ or $r_r$ by $\\delta$. Moreover---even in\nasymmetric networks---there is an equivalence between the left side-information\nparameters $t_\\ell, r_\\ell$ and the right side-information parameters $t_r,\nr_r$. \n\n"}
{"id": "1203.6233", "contents": "Title: Information Theory of DNA Shotgun Sequencing Abstract: DNA sequencing is the basic workhorse of modern day biology and medicine.\nShotgun sequencing is the dominant technique used: many randomly located short\nfragments called reads are extracted from the DNA sequence, and these reads are\nassembled to reconstruct the original sequence. A basic question is: given a\nsequencing technology and the statistics of the DNA sequence, what is the\nminimum number of reads required for reliable reconstruction? This number\nprovides a fundamental limit to the performance of {\\em any} assembly\nalgorithm. For a simple statistical model of the DNA sequence and the read\nprocess, we show that the answer admits a critical phenomena in the asymptotic\nlimit of long DNA sequences: if the read length is below a threshold,\nreconstruction is impossible no matter how many reads are observed, and if the\nread length is above the threshold, having enough reads to cover the DNA\nsequence is sufficient to reconstruct. The threshold is computed in terms of\nthe Renyi entropy rate of the DNA sequence. We also study the impact of noise\nin the read process on the performance. \n\n"}
{"id": "1204.0839", "contents": "Title: A Constrained Random Demodulator for Sub-Nyquist Sampling Abstract: This paper presents a significant modification to the Random Demodulator (RD)\nof Tropp et al. for sub-Nyquist sampling of frequency-sparse signals. The\nmodification, termed constrained random demodulator, involves replacing the\nrandom waveform, essential to the operation of the RD, with a constrained\nrandom waveform that has limits on its switching rate because fast switching\nwaveforms may be hard to generate cleanly. The result is a relaxation on the\nhardware requirements with a slight, but manageable, decrease in the recovery\nguarantees. The paper also establishes the importance of properly choosing the\nstatistics of the constrained random waveform. If the power spectrum of the\nrandom waveform matches the distribution on the tones of the input signal\n(i.e., the distribution is proportional to the power spectrum), then recovery\nof the input signal tones is improved. The theoretical guarantees provided in\nthe paper are validated through extensive numerical simulations and phase\ntransition plots. \n\n"}
{"id": "1204.3097", "contents": "Title: Technical Report: Observability of a Linear System under Sparsity\n  Constraints Abstract: Consider an n-dimensional linear system where it is known that there are at\nmost k<n non-zero components in the initial state. The observability problem,\nthat is the recovery of the initial state, for such a system is considered. We\nobtain sufficient conditions on the number of the available observations to be\nable to recover the initial state exactly for such a system. Both deterministic\nand stochastic setups are considered for system dynamics. In the former\nsetting, the system matrices are known deterministically, whereas in the latter\nsetting, all of the matrices are picked from a randomized class of matrices.\nThe main message is that, one does not need to obtain full n observations to be\nable to uniquely identify the initial state of the linear system, even when the\nobservations are picked randomly, when the initial condition is known to be\nsparse. \n\n"}
{"id": "1204.4840", "contents": "Title: Energy-Delay Tradeoff and Dynamic Sleep Switching for Bluetooth-Like\n  Body-Area Sensor Networks Abstract: Wireless technology enables novel approaches to healthcare, in particular the\nremote monitoring of vital signs and other parameters indicative of people's\nhealth. This paper considers a system scenario relevant to such applications,\nwhere a smart-phone acts as a data-collecting hub, gathering data from a number\nof wireless-capable body sensors, and relaying them to a healthcare provider\nhost through standard existing cellular networks. Delay of critical data and\nsensors' energy efficiency are both relevant and conflicting issues. Therefore,\nit is important to operate the wireless body-area sensor network at some\ndesired point close to the optimal energy-delay tradeoff curve. This tradeoff\ncurve is a function of the employed physical-layer protocol: in particular, it\ndepends on the multiple-access scheme and on the coding and modulation schemes\navailable. In this work, we consider a protocol closely inspired by the\nwidely-used Bluetooth standard. First, we consider the calculation of the\nminimum energy function, i.e., the minimum sum energy per symbol that\nguarantees the stability of all transmission queues in the network. Then, we\napply the general theory developed by Neely to develop a dynamic scheduling\npolicy that approaches the optimal energy-delay tradeoff for the network at\nhand. Finally, we examine the queue dynamics and propose a novel policy that\nadaptively switches between connected and disconnected (sleeping) modes. We\ndemonstrate that the proposed policy can achieve significant gains in the\nrealistic case where the control \"NULL\" packets necessary to maintain the\nconnection alive, have a non-zero energy cost, and the data arrival statistics\ncorresponding to the sensed physical process are bursty. \n\n"}
{"id": "1204.5136", "contents": "Title: Analysis and Design of Irregular Graphs for Node-Based\n  Verification-Based Recovery Algorithms in Compressed Sensing Abstract: In this paper, we present a probabilistic analysis of iterative node-based\nverification-based (NB-VB) recovery algorithms over irregular graphs in the\ncontext of compressed sensing. Verification-based algorithms are particularly\ninteresting due to their low complexity (linear in the signal dimension $n$).\nThe analysis predicts the average fraction of unverified signal elements at\neach iteration $\\ell$ where the average is taken over the ensembles of input\nsignals and sensing matrices. The analysis is asymptotic ($n \\rightarrow\n\\infty$) and is similar in nature to the well-known density evolution technique\ncommonly used to analyze iterative decoding algorithms. Compared to the\nexisting technique for the analysis of NB-VB algorithms, which is based on\nnumerically solving a large system of coupled differential equations, the\nproposed method is much simpler and more accurate. This allows us to design\nirregular sensing graphs for such recovery algorithms. The designed irregular\ngraphs outperform the corresponding regular graphs substantially. For example,\nfor the same recovery complexity per iteration, we design irregular graphs that\ncan recover up to about 40% more non-zero signal elements compared to the\nregular graphs. Simulation results are also provided which demonstrate that the\nproposed asymptotic analysis matches the performance of recovery algorithms for\nlarge but finite values of $n$. \n\n"}
{"id": "1205.4144", "contents": "Title: Information Theoretic cutting of a cake Abstract: Cutting a cake is a metaphor for the problem of dividing a resource (cake)\namong several agents. The problem becomes non-trivial when the agents have\ndifferent valuations for different parts of the cake (i.e. one agent may like\nchocolate while the other may like cream). A fair division of the cake is one\nthat takes into account the individual valuations of agents and partitions the\ncake based on some fairness criterion. Fair division may be accomplished in a\ndistributed or centralized way. Due to its natural and practical appeal, it has\nbeen a subject of study in economics. To best of our knowledge the role of\npartial information in fair division has not been studied so far from an\ninformation theoretic perspective. In this paper we study two important\nalgorithms in fair division, namely \"divide and choose\" and \"adjusted winner\"\nfor the case of two agents. We quantify the benefit of negotiation in the\ndivide and choose algorithm, and its use in tricking the adjusted winner\nalgorithm. Also we analyze the role of implicit information transmission\nthrough actions for the repeated divide and choose problem by finding a\ntrembling hand perfect equilibrium for an specific setup. Lastly we consider a\ncentralized algorithm for maximizing the overall welfare of the agents under\nthe Nash collective utility function (CUF). This corresponds to a clustering\nproblem of the type traditionally studied in data mining and machine learning.\nDrawing a conceptual link between this problem and the portfolio selection\nproblem in stock markets, we prove an upper bound on the increase of the Nash\nCUF for a clustering refinement. \n\n"}
{"id": "1205.4510", "contents": "Title: On the exponential ergodicity for L\\'{e}vy driven Ornstein-Uhlenbeck\n  processes Abstract: Based on the explicit coupling property, the ergodicity and the exponential\nergodicity of L\\'{e}vy driven Ornstein-Uhlenbeck processes are established. \n\n"}
{"id": "1205.4856", "contents": "Title: Bounds on Minimum Number of Anchors for Iterative Localization and its\n  Connections to Bootstrap Percolation Abstract: Iterated localization is considered where each node of a network needs to get\nlocalized (find its location on 2-D plane), when initially only a subset of\nnodes have their location information. The iterated localization process\nproceeds as follows. Starting with a subset of nodes that have their location\ninformation, possibly using global positioning system (GPS) devices, any other\nnode gets localized if it has three or more localized nodes in its radio range.\nThe newly localized nodes are included in the subset of nodes that have their\nlocation information for the next iteration. This process is allowed to\ncontinue, until no new node can be localized. The problem is to find the\nminimum size of the initially localized subset to start with so that the whole\nnetwork is localized with high probability. There are intimate connections\nbetween iterated localization and bootstrap percolation, that is well studied\nin statistical physics. Using results known in bootstrap percolation, we find a\nsufficient condition on the size of the initially localized subset that\nguarantees the localization of all nodes in the network with high probability. \n\n"}
{"id": "1205.4876", "contents": "Title: Selective Coding Strategy for Unicast Composite Networks Abstract: Consider a composite unicast relay network where the channel statistic is\nrandomly drawn from a set of conditional distributions indexed by a random\nvariable, which is assumed to be unknown at the source, fully known at the\ndestination and only partly known at the relays. Commonly, the coding strategy\nat each relay is fixed regardless of its channel measurement. A novel coding\nfor unicast composite networks with multiple relays is introduced. This enables\nthe relays to select dynamically --based on its channel measurement-- the best\ncoding scheme between compress-and-forward (CF) and decode-and-forward (DF). As\na part of the main result, a generalization of Noisy Network Coding is shown\nfor the case of unicast general networks where the relays are divided between\nthose using DF and CF coding. Furthermore, the relays using DF scheme can\nexploit the help of those based on CF scheme via offset coding. It is\ndemonstrated via numerical results that this novel coding, referred to as\nSelective Coding Strategy (SCS), outperforms conventional coding schemes. \n\n"}
{"id": "1206.0725", "contents": "Title: The Hausdorff dimension of the CLE gasket Abstract: The conformal loop ensemble $\\mathrm{CLE}_{\\kappa}$ is the canonical\nconformally invariant probability measure on noncrossing loops in a proper\nsimply connected domain in the complex plane. The parameter $\\kappa$ varies\nbetween $8/3$ and $8$; $\\mathrm{CLE}_{8/3}$ is empty while $\\mathrm {CLE}_8$ is\na single space-filling loop. In this work, we study the geometry of the\n$\\mathrm{CLE}$ gasket, the set of points not surrounded by any loop of the\n$\\mathrm{CLE}$. We show that the almost sure Hausdorff dimension of the gasket\nis bounded from below by $2-(8-\\kappa)(3\\kappa-8)/(32\\kappa)$ when\n$4<\\kappa<8$. Together with the work of Schramm-Sheffield-Wilson [Comm. Math.\nPhys. 288 (2009) 43-53] giving the upper bound for all $\\kappa$ and the work of\nNacu-Werner [J. Lond. Math. Soc. (2) 83 (2011) 789-809] giving the matching\nlower bound for $\\kappa\\le4$, this completes the determination of the\n$\\mathrm{CLE}_{\\kappa}$ gasket dimension for all values of $\\kappa$ for which\nit is defined. The dimension agrees with the prediction of Duplantier-Saleur\n[Phys. Rev. Lett. 63 (1989) 2536-2537] for the FK gasket. \n\n"}
{"id": "1206.2961", "contents": "Title: Epistemic view of quantum states and communication complexity of quantum\n  channels Abstract: The communication complexity of a quantum channel is the minimal amount of\nclassical communication required for classically simulating a process of state\npreparation, transmission through the channel and subsequent measurement. It\nestablishes a limit on the power of quantum communication in terms of classical\nresources. We show that classical simulations employing a finite amount of\ncommunication can be derived from a special class of hidden variable theories\nwhere quantum states represent statistical knowledge about the classical state\nand not an element of reality. This special class has attracted strong interest\nvery recently. The communication cost of each derived simulation is given by\nthe mutual information between the quantum state and the classical state of the\nparent hidden variable theory. Finally, we find that the communication\ncomplexity for single qubits is smaller than 1.28 bits. The previous known\nupper bound was 1.85 bits. \n\n"}
{"id": "1206.4389", "contents": "Title: Improving Two-Way Selective Decode-and-forward Wireless Relaying with\n  Energy-Efficient One-bit Soft Forwarding Abstract: Motivated by applications such as battery-operated wireless sensor networks\n(WSN), we propose an easy-to-implement energy-efficient two-way relaying\nscheme. In particular, we address the challenge of improving the standard\ntwo-way selective decode-and-forward protocol (TW-SDF) in terms of\nblock-error-rate (BLER) with minor additional complexity and energy\nconsumption. By following the principle of soft relaying, our solution is the\ntwo-way one-bit soft forwarding (TW-1bSF) protocol in which the relay forwards\nthe one-bit quantization of a posterior information metric about the\ntransmitted bits, associated with an appropriately designed reliability\nparameter.\n  In WSN-related standards (such as IEEE802.15.6 and Bluetooth), block codes\nare adopted instead of convolutional and other sophisticated codes, due to\ntheir efficient decoder hardware implementation. As the second main\ncontribution, we derive tight upper bounds on the BLER performance for both\nTW-SDF and TW-1bSF, when the two-way relaying network employs block codes and\nhard decoding. The error probability analysis confirms the superiority of\nTW-1bSF. Moreover, we derive the asymptotic performance gain of TW-1bSF over\nTW-SDF, which further suggests that the proposed protocol is a good choice,\nespecially when long block codes are used. \n\n"}
{"id": "1206.4767", "contents": "Title: On the Secrecy Rate Region of a Fading Multiple-Antenna Gaussian\n  Broadcast Channel with Confidential Messages and Partial CSIT Abstract: In this paper we consider the secure transmission over the fast fading\nmultiple antenna Gaussian broadcast channels with confidential messages\n(FMGBC-CM), where a multiple-antenna transmitter sends independent confidential\nmessages to two users with information theoretic secrecy and only the\nstatistics of the receivers' channel state information are known at the\ntransmitter. We first use the same marginal property of the FMGBC-CM to\nclassify the non-trivial cases, i.e., those not degraded to the common wiretap\nchannels. We then derive the achievable rate region for the FMGBC-CM by solving\nthe channel input covariance matrices and the inflation factor. Due to the\ncomplicated rate region formulae, we resort to low SNR analysis to investigate\nthe characteristics of the channel. Finally, the numerical examples show that\nunder the information-theoretic secrecy requirement both users can achieve\npositive rates simultaneously. \n\n"}
{"id": "1207.0229", "contents": "Title: Variable-rate Retransmissions for Incremental Redundancy Hybrid ARQ Abstract: The throughput achievable in truncated Hybrid ARQ protocol (HARQ) using\nincremental redundancy (IR) in analyzed when transmitting over a block-fading\nchannel whose state is unknown at the transmitter. We allow the transmission\nlengths to vary, optimize them efficiently via dynamic programming, and show\nthat such a variable-rate HARQ-IR provides gains with respect to a fixed-rate\ntransmission in terms of increased throughput and decreased average number of\ntransmissions, reducing at the same time the outage probability. \n\n"}
{"id": "1207.2829", "contents": "Title: Sparse Recovery with Graph Constraints Abstract: Sparse recovery can recover sparse signals from a set of underdetermined\nlinear measurements. Motivated by the need to monitor large-scale networks from\na limited number of measurements, this paper addresses the problem of\nrecovering sparse signals in the presence of network topological constraints.\nUnlike conventional sparse recovery where a measurement can contain any subset\nof the unknown variables, we use a graph to characterize the topological\nconstraints and allow an additive measurement over nodes (unknown variables)\nonly if they induce a connected subgraph. We provide explicit measurement\nconstructions for several special graphs, and the number of measurements by our\nconstruction is less than that needed by existing random constructions.\nMoreover, our construction for a line network is provably optimal in the sense\nthat it requires the minimum number of measurements. A measurement construction\nalgorithm for general graphs is also proposed and evaluated. For any given\ngraph $G$ with $n$ nodes, we derive bounds of the minimum number of\nmeasurements needed to recover any $k$-sparse vector over $G$ ($M^G_{k,n}$).\nUsing the Erd\\H{o}s-R\\'enyi random graph as an example, we characterize the\ndependence of $M^G_{k,n}$ on the graph structure. \n\n"}
{"id": "1207.4104", "contents": "Title: Outliers and Random Noises in System Identification: a Compressed\n  Sensing Approach Abstract: In this paper, we consider robust system identification under sparse outliers\nand random noises. In this problem, system parameters are observed through a\nToeplitz matrix. All observations are subject to random noises and a few are\ncorrupted with outliers. We reduce this problem of system identification to a\nsparse error correcting problem using a Toeplitz structured real-numbered\ncoding matrix. We prove the performance guarantee of Toeplitz structured matrix\nin sparse error correction. Thresholds on the percentage of correctable errors\nfor Toeplitz structured matrices are established. When both outliers and\nobservation noise are present, we have shown that the estimation error goes to\n0 asymptotically as long as the probability density function for observation\nnoise is not \"vanishing\" around 0. No probabilistic assumptions are imposed on\nthe outliers. \n\n"}
{"id": "1207.5063", "contents": "Title: Secrecy Sum-Rates for Multi-User MIMO Regularized Channel Inversion\n  Precoding Abstract: In this paper, we propose a linear precoder for the downlink of a multi-user\nMIMO system with multiple users that potentially act as eavesdroppers. The\nproposed precoder is based on regularized channel inversion (RCI) with a\nregularization parameter $\\alpha$ and power allocation vector chosen in such a\nway that the achievable secrecy sum-rate is maximized. We consider the\nworst-case scenario for the multi-user MIMO system, where the transmitter\nassumes users cooperate to eavesdrop on other users. We derive the achievable\nsecrecy sum-rate and obtain the closed-form expression for the optimal\nregularization parameter $\\alpha_{\\mathrm{LS}}$ of the precoder using\nlarge-system analysis. We show that the RCI precoder with\n$\\alpha_{\\mathrm{LS}}$ outperforms several other linear precoding schemes, and\nit achieves a secrecy sum-rate that has same scaling factor as the sum-rate\nachieved by the optimum RCI precoder without secrecy requirements. We propose a\npower allocation algorithm to maximize the secrecy sum-rate for fixed $\\alpha$.\nWe then extend our algorithm to maximize the secrecy sum-rate by jointly\noptimizing $\\alpha$ and the power allocation vector. The jointly optimized\nprecoder outperforms RCI with $\\alpha_{\\mathrm{LS}}$ and equal power allocation\nby up to 20 percent at practical values of the signal-to-noise ratio and for 4\nusers and 4 transmit antennas. \n\n"}
{"id": "1207.6174", "contents": "Title: A++ Random Access for Two-way Relaying in Wireless Networks Abstract: Two-way relaying can significantly improve performance of next generation\nwireless networks. However, due to its dependence on multi-node cooperation and\ntransmission coordination, applying this technique to a wireless network in an\neffective and scalable manner poses a challenging problem. To tackle this\nproblem without relying on complicated scheduling or network optimization\nalgorithms, we propose a scalable random access scheme that takes measures in\nboth the physical layer and the medium access control layer. Specifically, we\npropose a two-way relaying technique that supports fully asynchronous\ntransmission and is modulation-independent. It also assumes no priori knowledge\nof channel conditions. On the top of this new physical layer technique, a\nrandom access MAC protocol is designed to dynamically form two-way relaying\ncooperation in a wireless network. To evaluate the scalable random access\nscheme, both theoretical analysis and simulations are carried out. Performance\nresults illustrate that our scheme has achieved the goal of scalable two-way\nrelaying in a wireless network and significantly outperforms CSMA/CA protocol. \n\n"}
{"id": "1207.7321", "contents": "Title: Universality in polytope phase transitions and message passing\n  algorithms Abstract: We consider a class of nonlinear mappings $\\mathsf{F}_{A,N}$ in\n$\\mathbb{R}^N$ indexed by symmetric random matrices $A\\in\\mathbb{R}^{N\\times\nN}$ with independent entries. Within spin glass theory, special cases of these\nmappings correspond to iterating the TAP equations and were studied by\nBolthausen [Comm. Math. Phys. 325 (2014) 333-366]. Within information theory,\nthey are known as \"approximate message passing\" algorithms. We study the\nhigh-dimensional (large $N$) behavior of the iterates of $\\mathsf{F}$ for\npolynomial functions $\\mathsf{F}$, and prove that it is universal; that is, it\ndepends only on the first two moments of the entries of $A$, under a\nsub-Gaussian tail condition. As an application, we prove the universality of a\ncertain phase transition arising in polytope geometry and compressed sensing.\nThis solves, for a broad class of random projections, a conjecture by David\nDonoho and Jared Tanner. \n\n"}
{"id": "1208.2787", "contents": "Title: Analysis and Construction of Functional Regenerating Codes with Uncoded\n  Repair for Distributed Storage Systems Abstract: Modern distributed storage systems apply redundancy coding techniques to\nstored data. One form of redundancy is based on regenerating codes, which can\nminimize the repair bandwidth, i.e., the amount of data transferred when\nrepairing a failed storage node. Existing regenerating codes mainly require\nsurviving storage nodes encode data during repair. In this paper, we study\nfunctional minimum storage regenerating (FMSR) codes, which enable uncoded\nrepair without the encoding requirement in surviving nodes, while preserving\nthe minimum repair bandwidth guarantees and also minimizing disk reads. Under\ndouble-fault tolerance settings, we formally prove the existence of FMSR codes,\nand provide a deterministic FMSR code construction that can significantly speed\nup the repair process. We further implement and evaluate our deterministic FMSR\ncodes to show the benefits. Our work is built atop a practical cloud storage\nsystem that implements FMSR codes, and we provide theoretical validation to\njustify the practicality of FMSR codes. \n\n"}
{"id": "1209.1679", "contents": "Title: Bayesian Quantized Network Coding via Belief Propagation Abstract: In this paper, we propose an alternative for routing based packet forwarding,\nwhich uses network coding to increase transmission efficiency, in terms of both\ncompression and error resilience. This non-adaptive encoding is called\nquantized network coding, which involves random linear mapping in the real\nfield, followed by quantization to cope with the finite capacity of the links.\nAt the gateway node, which collects received quantized network coder packets,\nminimum mean squared error decoding is performed, by using belief propagation\nin the factor graph representation. Our simulation results show a significant\nimprovement, in terms of the number of required packets to recover the\nmessages, which can be interpreted as an embedded distributed source coding for\ncorrelated messages. \n\n"}
{"id": "1209.1716", "contents": "Title: Classification of binary systematic codes of small defect Abstract: In this paper non-trivial non-linear binary systematic AMDS codes are\nclassified in terms of their weight distributions, employing only elementary\ntechniques. In particular, we show that their length and minimum distance\ncompletely determine the weight distribution. \n\n"}
{"id": "1209.5656", "contents": "Title: Learning Price-Elasticity of Smart Consumers in Power Distribution\n  Systems Abstract: Demand Response is an emerging technology which will transform the power grid\nof tomorrow. It is revolutionary, not only because it will enable peak load\nshaving and will add resources to manage large distribution systems, but mainly\nbecause it will tap into an almost unexplored and extremely powerful pool of\nresources comprised of many small individual consumers on distribution grids.\nHowever, to utilize these resources effectively, the methods used to engage\nthese resources must yield accurate and reliable control. A diversity of\nmethods have been proposed to engage these new resources. As opposed to direct\nload control, many methods rely on consumers and/or loads responding to\nexogenous signals, typically in the form of energy pricing, originating from\nthe utility or system operator. Here, we propose an open loop\ncommunication-lite method for estimating the price elasticity of many customers\ncomprising a distribution system. We utilize a sparse linear regression method\nthat relies on operator-controlled, inhomogeneous minor price variations, which\nwill be fair to all the consumers. Our numerical experiments show that reliable\nestimation of individual and thus aggregated instantaneous elasticities is\npossible. We describe the limits of the reliable reconstruction as functions of\nthe three key parameters of the system: (i) ratio of the number of\ncommunication slots (time units) per number of engaged consumers; (ii) level of\nsparsity (in consumer response); and (iii) signal-to-noise ratio. \n\n"}
{"id": "1209.6419", "contents": "Title: Partial Gaussian Graphical Model Estimation Abstract: This paper studies the partial estimation of Gaussian graphical models from\nhigh-dimensional empirical observations. We derive a convex formulation for\nthis problem using $\\ell_1$-regularized maximum-likelihood estimation, which\ncan be solved via a block coordinate descent algorithm. Statistical estimation\nperformance can be established for our method. The proposed approach has\ncompetitive empirical performance compared to existing methods, as demonstrated\nby various experiments on synthetic and real datasets. \n\n"}
{"id": "1210.5424", "contents": "Title: Implementation of Distributed Time Exchange Based Cooperative Forwarding Abstract: In this paper, we design and implement time exchange (TE) based cooperative\nforwarding where nodes use transmission time slots as incentives for relaying.\nWe focus on distributed joint time slot exchange and relay selection in the sum\ngoodput maximization of the overall network. We formulate the design objective\nas a mixed integer nonlinear programming (MINLP) problem and provide a\npolynomial time distributed solution of the MINLP. We implement the designed\nalgorithm in the software defined radio enabled USRP nodes of the ORBIT indoor\nwireless testbed. The ORBIT grid is used as a global control plane for exchange\nof control information between the USRP nodes. Experimental results suggest\nthat TE can significantly increase the sum goodput of the network. We also\ndemonstrate the performance of a goodput optimization algorithm that is\nproportionally fair. \n\n"}
{"id": "1210.6962", "contents": "Title: Quantum-to-classical rate distortion coding Abstract: We establish a theory of quantum-to-classical rate distortion coding. In this\nsetting, a sender Alice has many copies of a quantum information source. Her\ngoal is to transmit classical information about the source, obtained by\nperforming a measurement on it, to a receiver Bob, up to some specified level\nof distortion. We derive a single-letter formula for the minimum rate of\nclassical communication needed for this task. We also evaluate this rate in the\ncase in which Bob has some quantum side information about the source. Our\nresults imply that, in general, Alice's best strategy is a non-classical one,\nin which she performs a collective measurement on successive outputs of the\nsource. \n\n"}
{"id": "1210.8338", "contents": "Title: On the Power of Conditional Samples in Distribution Testing Abstract: In this paper we define and examine the power of the {\\em\nconditional-sampling} oracle in the context of distribution-property testing.\nThe conditional-sampling oracle for a discrete distribution $\\mu$ takes as\ninput a subset $S \\subset [n]$ of the domain, and outputs a random sample $i\n\\in S$ drawn according to $\\mu$, conditioned on $S$ (and independently of all\nprior samples). The conditional-sampling oracle is a natural generalization of\nthe ordinary sampling oracle in which $S$ always equals $[n]$.\n  We show that with the conditional-sampling oracle, testing uniformity,\ntesting identity to a known distribution, and testing any label-invariant\nproperty of distributions is easier than with the ordinary sampling oracle. On\nthe other hand, we also show that for some distribution properties the\nsample-complexity remains near-maximal even with conditional sampling. \n\n"}
{"id": "1211.0834", "contents": "Title: On Hidden Markov Processes with Infinite Excess Entropy Abstract: We investigate stationary hidden Markov processes for which mutual\ninformation between the past and the future is infinite. It is assumed that the\nnumber of observable states is finite and the number of hidden states is\ncountably infinite. Under this assumption, we show that the block mutual\ninformation of a hidden Markov process is upper bounded by a power law\ndetermined by the tail index of the hidden state distribution. Moreover, we\nexhibit three examples of processes. The first example, considered previously,\nis nonergodic and the mutual information between the blocks is bounded by the\nlogarithm of the block length. The second example is also nonergodic but the\nmutual information between the blocks obeys a power law. The third example\nobeys the power law and is ergodic. \n\n"}
{"id": "1211.3729", "contents": "Title: Data-Efficient Quickest Change Detection in Minimax Settings Abstract: The classical problem of quickest change detection is studied with an\nadditional constraint on the cost of observations used in the detection\nprocess. The change point is modeled as an unknown constant, and minimax\nformulations are proposed for the problem. The objective in these formulations\nis to find a stopping time and an on-off observation control policy for the\nobservation sequence, to minimize a version of the worst possible average\ndelay, subject to constraints on the false alarm rate and the fraction of time\nobservations are taken before change. An algorithm called DE-CuSum is proposed\nand is shown to be asymptotically optimal for the proposed formulations, as the\nfalse alarm rate goes to zero. Numerical results are used to show that the\nDE-CuSum algorithm has good trade-off curves and performs significantly better\nthan the approach of fractional sampling, in which the observations are skipped\nusing the outcome of a sequence of coin tosses, independent of the observation\nprocess. This work is guided by the insights gained from an earlier study of a\nBayesian version of this problem. \n\n"}
{"id": "1211.4174", "contents": "Title: Energy-Efficient Nonstationary Spectrum Sharing Abstract: We develop a novel design framework for energy-efficient spectrum sharing\namong autonomous users who aim to minimize their energy consumptions subject to\nminimum throughput requirements. Most existing works proposed stationary\nspectrum sharing policies, in which users transmit at fixed power levels. Since\nusers transmit simultaneously under stationary policies, to fulfill minimum\nthroughput requirements, they need to transmit at high power levels to overcome\ninterference. To improve energy efficiency, we construct nonstationary spectrum\nsharing policies, in which the users transmit at time-varying power levels.\nSpecifically, we focus on TDMA (time-division multiple access) policies in\nwhich one user transmits at each time (but not in a round-robin fashion). The\nproposed policy can be implemented by each user running a low-complexity\nalgorithm in a decentralized manner. It achieves high energy efficiency even\nwhen the users have erroneous and binary feedback about their interference\nlevels. Moreover, it can adapt to the dynamic entry and exit of users. The\nproposed policy is also deviation-proof, namely autonomous users will find it\nin their self-interests to follow it. Compared to existing policies, the\nproposed policy can achieve an energy saving of up to 90% when the number of\nusers is high. \n\n"}
{"id": "1211.4213", "contents": "Title: On the Pareto-Optimal Beam Structure and Design for Multi-User MIMO\n  Interference Channels Abstract: In this paper, the Pareto-optimal beam structure for multi-user\nmultiple-input multiple-output (MIMO) interference channels is investigated and\na necessary condition for any Pareto-optimal transmit signal covariance matrix\nis presented for the K-pair Gaussian (N,M_1,...,M_K) interference channel. It\nis shown that any Pareto-optimal transmit signal covariance matrix at a\ntransmitter should have its column space contained in the union of the\neigen-spaces of the channel matrices from the transmitter to all receivers.\nBased on this necessary condition, an efficient parameterization for the beam\nsearch space is proposed. The proposed parameterization is given by the product\nmanifold of a Stiefel manifold and a subset of a hyperplane and enables us to\nconstruct a very efficient beam design algorithm by exploiting its rich\ngeometrical structure and existing tools for optimization on Stiefel manifolds.\nReduction in the beam search space dimension and computational complexity by\nthe proposed parameterization and the proposed beam design approach is\nsignificant when the number of transmit antennas is larger than the sum of the\nnumbers of receive antennas, as in upcoming cellular networks adopting massive\nMIMO technologies. Numerical results validate the proposed parameterization and\nthe proposed cooperative beam design method based on the parameterization for\nMIMO interference channels. \n\n"}
{"id": "1211.4392", "contents": "Title: Cost Efficient High Capacity Indoor Wireless Access: Denser Wi-Fi or\n  Coordinated Pico-cellular? Abstract: Rapidly increasing traffic demand has forced indoor operators to deploy more\nand more Wi-Fi access points (APs). As AP density increases, inter-AP\ninterference rises and may limit the capacity. Alternatively, cellular\ntechnologies using centralized interference coordination can provide the same\ncapacity with the fewer number of APs at the price of more expensive equipment\nand installation cost. It is still not obvious at what demand level more\nsophisticated coordination pays off in terms of total system cost. To make this\ncomparison, we assess the required AP density of three candidate systems for a\ngiven average demand: a Wi-Fi network, a conventional pico-cellular network\nwith frequency planning, and an advanced system employing multi-cell joint\nprocessing. Numerical results show that dense Wi-Fi is the cheapest solution at\na relatively low demand level. However, the AP density grows quickly at a\ncritical demand level regardless of propagation conditions. Beyond this Wi-Fi\nnetwork limit, the conventional pico-cellular network works and is cheaper than\nthe joint processing in obstructed environments, e.g., furnished offices with\nwalls. In line of sight condition such as stadiums, the joint processing\nbecomes the most viable solution. The drawback is that extremely accurate\nchannel state information at transmitters is needed. \n\n"}
{"id": "1211.5164", "contents": "Title: State Evolution for General Approximate Message Passing Algorithms, with\n  Applications to Spatial Coupling Abstract: We consider a class of approximated message passing (AMP) algorithms and\ncharacterize their high-dimensional behavior in terms of a suitable state\nevolution recursion. Our proof applies to Gaussian matrices with independent\nbut not necessarily identically distributed entries. It covers --in\nparticular-- the analysis of generalized AMP, introduced by Rangan, and of AMP\nreconstruction in compressed sensing with spatially coupled sensing matrices.\nThe proof technique builds on the one of [BM11], while simplifying and\ngeneralizing several steps. \n\n"}
{"id": "1211.6395", "contents": "Title: Shift-minimal groups, fixed price 1, and the unique trace property Abstract: A countable group \\Gamma is called shift-minimal if every non-trivial measure\npreserving action of \\Gamma weakly contained in the Bernoulli shift of \\Gamma\non ([0,1]^\\Gamma ,\\lambda ^\\Gamma) is free. We show that any group \\Gamma whose\nreduced C^*-algebra admits a unique tracial state is shift-minimal, and that\nany group \\Gamma admitting a free measure preserving action of cost>1 contains\na finite normal subgroup N such that \\Gamma /N is shift-minimal. Any\nshift-minimal group in turn is shown to have trivial amenable radical.\nRecurrence arguments are used in studying invariant random subgroups of a wide\nvariety of shift-minimal groups. We also examine continuity properties of cost\nin the context of infinitely generated groups and equivalence relations. A\nnumber of open questions are discussed which concern cost, shift-minimality,\nC^*-simplicity, and uniqueness of tracial state on C^*_r(\\Gamma). \n\n"}
{"id": "1211.7221", "contents": "Title: On the spectral norm of large heavy-tailed random matrices with strongly\n  dependent rows and columns Abstract: We study a new random matrix ensemble $X$ which is constructed by an\napplication of a two dimensional linear filter to a matrix of iid random\nvariables with infinite fourth moments. Our result gives asymptotic lower and\nupper bounds for the spectral norm of the (centered) sample covariance matrix\n$XX^\\T$ when the number of columns as well es the number of rows of $X$ tend to\ninfinity. \n\n"}
{"id": "1212.1283", "contents": "Title: A Tractable Framework for Exact Probability of Node Isolation and\n  Minimum Node Degree Distribution in Finite Multi-hop Networks Abstract: This paper presents a tractable analytical framework for the exact\ncalculation of probability of node isolation and minimum node degree\ndistribution when $N$ sensor nodes are independently and uniformly distributed\ninside a finite square region. The proposed framework can accurately account\nfor the boundary effects by partitioning the square into subregions, based on\nthe transmission range and the node location. We show that for each subregion,\nthe probability that a random node falls inside a disk centered at an arbitrary\nnode located in that subregion can be expressed analytically in closed-form.\nUsing the results for the different subregions, we obtain the exact probability\nof node isolation and minimum node degree distribution that serves as an upper\nbound for the probability of $k$-connectivity. Our theoretical framework is\nvalidated by comparison with the simulation results and shows that the minimum\nnode degree distribution serves as a tight upper bound for the probability of\n$k$-connectivity. The proposed framework provides a very useful tool to\naccurately account for the boundary effects in the design of finite wireless\nnetworks. \n\n"}
{"id": "1212.3170", "contents": "Title: Improving Macrocell - Small Cell Coexistence through Adaptive\n  Interference Draining Abstract: The deployment of underlay small base stations (SBSs) is expected to\nsignificantly boost the spectrum efficiency and the coverage of next-generation\ncellular networks. However, the coexistence of SBSs underlaid to an existing\nmacro-cellular network faces important challenges, notably in terms of spectrum\nsharing and interference management. In this paper, we propose a novel\ngame-theoretic model that enables the SBSs to optimize their transmission rates\nby making decisions on the resource occupation jointly in the frequency and\nspatial domains. This procedure, known as interference draining, is performed\namong cooperative SBSs and allows to drastically reduce the interference\nexperienced by both macro- and small cell users. At the macrocell side, we\nconsider a modified water-filling policy for the power allocation that allows\neach macrocell user (MUE) to focus the transmissions on the degrees of freedom\nover which the MUE experiences the best channel and interference conditions.\nThis approach not only represents an effective way to decrease the received\ninterference at the MUEs but also grants the SBSs tier additional transmission\nopportunities and allows for a more agile interference management. Simulation\nresults show that the proposed approach yields significant gains at both\nmacrocell and small cell tiers, in terms of average achievable rate per user,\nreaching up to 37%, relative to the non-cooperative case, for a network with\n150 MUEs and 200 SBSs. \n\n"}
{"id": "1212.3376", "contents": "Title: Linearly Reconfigurable Kalman Filtering for a Vector Process Abstract: In this paper, we consider a dynamic linear system in state-space form where\nthe observation equation depends linearly on a set of parameters. We address\nthe problem of how to dynamically calculate these parameters in order to\nminimize the mean-squared error (MSE) of the state estimate achieved by a\nKalman filter. We formulate and solve two kinds of problems under a quadratic\nconstraint on the observation parameters: minimizing the sum MSE (Min-Sum-MSE)\nor minimizing the maximum MSE (Min-Max-MSE). In each case, the optimization\nproblem is divided into two sub-problems for which optimal solutions can be\nfound: a semidefinite programming (SDP) problem followed by a constrained\nleast-squares minimization. A more direct solution is shown to exist for the\nspecial case of a scalar observation; in particular, the Min-Sum-MSE solution\ncan be found directly using a generalized eigendecomposition, and is optimally\nsolved utilizing Rayleigh quotient, and the Min-Max-MSE problem reduces to an\nSDP feasibility test that can be solved via the bisection method. \n\n"}
{"id": "1212.3621", "contents": "Title: Local Irreducibility of Tail-Biting Trellises Abstract: This paper investigates tail-biting trellis realizations for linear block\ncodes. Intrinsic trellis properties are used to characterize irreducibility on\ngiven intervals of the time axis. It proves beneficial to always consider the\ntrellis and its dual simultaneously. A major role is played by trellis\nproperties that amount to observability and controllability for fragments of\nthe trellis of various lengths. For fragments of length less than the minimum\nspan length of the code it is shown that fragment observability and fragment\ncontrollability are equivalent to irreducibility. For reducible trellises, a\nconstructive reduction procedure is presented. The considerations also lead to\na characterization for when the dual of a trellis allows a product\nfactorization into elementary (\"atomic\") trellises. \n\n"}
{"id": "1212.5701", "contents": "Title: ADADELTA: An Adaptive Learning Rate Method Abstract: We present a novel per-dimension learning rate method for gradient descent\ncalled ADADELTA. The method dynamically adapts over time using only first order\ninformation and has minimal computational overhead beyond vanilla stochastic\ngradient descent. The method requires no manual tuning of a learning rate and\nappears robust to noisy gradient information, different model architecture\nchoices, various data modalities and selection of hyperparameters. We show\npromising results compared to other methods on the MNIST digit classification\ntask using a single machine and on a large scale voice dataset in a distributed\ncluster environment. \n\n"}
{"id": "1212.6027", "contents": "Title: Belief propagation for optimal edge cover in the random complete graph Abstract: We apply the objective method of Aldous to the problem of finding the\nminimum-cost edge cover of the complete graph with random independent and\nidentically distributed edge costs. The limit, as the number of vertices goes\nto infinity, of the expected minimum cost for this problem is known via a\ncombinatorial approach of Hessler and W\\\"{a}stlund. We provide a proof of this\nresult using the machinery of the objective method and local weak convergence,\nwhich was used to prove the $\\zeta(2)$ limit of the random assignment problem.\nA proof via the objective method is useful because it provides us with more\ninformation on the nature of the edge's incident on a typical root in the\nminimum-cost edge cover. We further show that a belief propagation algorithm\nconverges asymptotically to the optimal solution. This can be applied in a\ncomputational linguistics problem of semantic projection. The belief\npropagation algorithm yields a near optimal solution with lesser complexity\nthan the known best algorithms designed for optimality in worst-case settings. \n\n"}
{"id": "1301.0926", "contents": "Title: Source Coding with in-Block Memory and Causally Controllable Side\n  Information Abstract: The recently proposed set-up of source coding with a side information\n\"vending machine\" allows the decoder to select actions in order to control the\nquality of the side information. The actions can depend on the message received\nfrom the encoder and on the previously measured samples of the side\ninformation, and are cost constrained. Moreover, the final estimate of the\nsource by the decoder is a function of the encoder's message and depends\ncausally on the side information sequence. Previous work by Permuter and\nWeissman has characterized the rate-distortion-cost function in the special\ncase in which the source and the \"vending machine\" are memoryless. In this\nwork, motivated by the related channel coding model introduced by Kramer, the\nrate-distortion-cost function characterization is extended to a model with\nin-block memory. Various special cases are studied including block-feedforward\nand side information repeat request models. \n\n"}
{"id": "1301.3021", "contents": "Title: Accurate detection of moving targets via random sensor arrays and\n  Kerdock codes Abstract: The detection and parameter estimation of moving targets is one of the most\nimportant tasks in radar. Arrays of randomly distributed antennas have been\npopular for this purpose for about half a century. Yet, surprisingly little\nrigorous mathematical theory exists for random arrays that addresses\nfundamental question such as how many targets can be recovered, at what\nresolution, at which noise level, and with which algorithm. In a different line\nof research in radar, mathematicians and engineers have invested significant\neffort into the design of radar transmission waveforms which satisfy various\ndesirable properties. In this paper we bring these two seemingly unrelated\nareas together. Using tools from compressive sensing we derive a theoretical\nframework for the recovery of targets in the azimuth-range-Doppler domain via\nrandom antennas arrays. In one manifestation of our theory we use Kerdock codes\nas transmission waveforms and exploit some of their peculiar properties in our\nanalysis. Our paper provides two main contributions: (i) We derive the first\nrigorous mathematical theory for the detection of moving targets using random\nsensor arrays. (ii) The transmitted waveforms satisfy a variety of properties\nthat are very desirable and important from a practical viewpoint. Thus our\napproach does not just lead to useful theoretical insights, but is also of\npractical importance. Various extensions of our results are derived and\nnumerical simulations confirming our theory are presented. \n\n"}
{"id": "1301.4646", "contents": "Title: Physical Layer Network Coding for Two-Way Relaying with QAM Abstract: The design of modulation schemes for the physical layer network-coded two way\nrelaying scenario was studied in [1], [3], [4] and [5]. In [7] it was shown\nthat every network coding map that satisfies the exclusive law is representable\nby a Latin Square and conversely, and this relationship can be used to get the\nnetwork coding maps satisfying the exclusive law. But, only the scenario in\nwhich the end nodes use $M$-PSK signal sets is addressed in [7] and [8]. In\nthis paper, we address the case in which the end nodes use $M$-QAM signal sets.\nIn a fading scenario, for certain channel conditions $\\gamma e^{j \\theta}$,\ntermed singular fade states, the MA phase performance is greatly reduced. By\nformulating a procedure for finding the exact number of singular fade states\nfor QAM, we show that square QAM signal sets give lesser number of singular\nfade states compared to PSK signal sets. This results in superior performance\nof $M$-QAM over $M$-PSK. It is shown that the criterion for partitioning the\ncomplex plane, for the purpose of using a particular network code for a\nparticular fade state, is different from that used for $M$-PSK. Using a\nmodified criterion, we describe a procedure to analytically partition the\ncomplex plane representing the channel condition. We show that when $M$-QAM ($M\n>4$) signal set is used, the conventional XOR network mapping fails to remove\nthe ill effects of $\\gamma e^{j \\theta}=1$, which is a singular fade state for\nall signal sets of arbitrary size. We show that a doubly block circulant Latin\nSquare removes this singular fade state for $M$-QAM. \n\n"}
{"id": "1301.5033", "contents": "Title: On the Distribution of MIMO Mutual Information: An In-Depth Painlev\\'{e}\n  Based Characterization Abstract: This paper builds upon our recent work which computed the moment generating\nfunction of the MIMO mutual information exactly in terms of a Painlev\\'{e} V\ndifferential equation. By exploiting this key analytical tool, we provide an\nin-depth characterization of the mutual information distribution for\nsufficiently large (but finite) antenna numbers. In particular, we derive\nsystematic closed-form expansions for the high order cumulants. These results\nyield considerable new insight, such as providing a technical explanation as to\nwhy the well known Gaussian approximation is quite robust to large SNR for the\ncase of unequal antenna arrays, whilst it deviates strongly for equal antenna\narrays. In addition, by drawing upon our high order cumulant expansions, we\nemploy the Edgeworth expansion technique to propose a refined Gaussian\napproximation which is shown to give a very accurate closed-form\ncharacterization of the mutual information distribution, both around the mean\nand for moderate deviations into the tails (where the Gaussian approximation\nfails remarkably). For stronger deviations where the Edgeworth expansion\nbecomes unwieldy, we employ the saddle point method and asymptotic integration\ntools to establish new analytical characterizations which are shown to be very\nsimple and accurate. Based on these results we also recover key well\nestablished properties of the tail distribution, including the\ndiversity-multiplexing-tradeoff. \n\n"}
{"id": "1301.5258", "contents": "Title: Extremality Properties for the Basic Polarization Transformations Abstract: We study the extremality of the BEC and the BSC for Gallager's reliability\nfunction $E_0$ evaluated under the uniform input distribution for binary input\nDMCs from the aspect of channel polarization. In particular, we show that\namongst all B-DMCs of a given $E_0(\\rho)$ value, for a fixed $\\rho \\geq 0$, the\nBEC and BSC are extremal in the evolution of $E_0$ under the one-step\npolarization transformations. \n\n"}
{"id": "1301.5334", "contents": "Title: Generalized Cut-Set Bounds for Broadcast Networks Abstract: A broadcast network is a classical network with all source messages\ncollocated at a single source node. For broadcast networks, the standard\ncut-set bounds, which are known to be loose in general, are closely related to\nunion as a specific set operation to combine the basic cuts of the network.\nThis paper provides a new set of network coding bounds for general broadcast\nnetworks. These bounds combine the basic cuts of the network via a variety of\nset operations (not just the union) and are established via only the\nsubmodularity of Shannon entropy. The tightness of these bounds are\ndemonstrated via applications to combination networks. \n\n"}
{"id": "1301.5848", "contents": "Title: Decentralized Coded Caching Attains Order-Optimal Memory-Rate Tradeoff Abstract: Replicating or caching popular content in memories distributed across the\nnetwork is a technique to reduce peak network loads. Conventionally, the main\nperformance gain of this caching was thought to result from making part of the\nrequested data available closer to end users. Instead, we recently showed that\na much more significant gain can be achieved by using caches to create\ncoded-multicasting opportunities, even for users with different demands,\nthrough coding across data streams. These coded-multicasting opportunities are\nenabled by careful content overlap at the various caches in the network,\ncreated by a central coordinating server.\n  In many scenarios, such a central coordinating server may not be available,\nraising the question if this multicasting gain can still be achieved in a more\ndecentralized setting. In this paper, we propose an efficient caching scheme,\nin which the content placement is performed in a decentralized manner. In other\nwords, no coordination is required for the content placement. Despite this lack\nof coordination, the proposed scheme is nevertheless able to create\ncoded-multicasting opportunities and achieves a rate close to the optimal\ncentralized scheme. \n\n"}
{"id": "1301.6295", "contents": "Title: Fixed Points of Generalized Approximate Message Passing with Arbitrary\n  Matrices Abstract: The estimation of a random vector with independent components passed through\na linear transform followed by a componentwise (possibly nonlinear) output map\narises in a range of applications. Approximate message passing (AMP) methods,\nbased on Gaussian approximations of loopy belief propagation, have recently\nattracted considerable attention for such problems. For large random\ntransforms, these methods exhibit fast convergence and admit precise analytic\ncharacterizations with testable conditions for optimality, even for certain\nnon-convex problem instances. However, the behavior of AMP under general\ntransforms is not fully understood. In this paper, we consider the generalized\nAMP (GAMP) algorithm and relate the method to more common optimization\ntechniques. This analysis enables a precise characterization of the GAMP\nalgorithm fixed-points that applies to arbitrary transforms. In particular, we\nshow that the fixed points of the so-called max-sum GAMP algorithm for MAP\nestimation are critical points of a constrained maximization of the posterior\ndensity. The fixed-points of the sum-product GAMP algorithm for estimation of\nthe posterior marginals can be interpreted as critical points of a certain free\nenergy. \n\n"}
{"id": "1301.6363", "contents": "Title: Towards An Exact Combinatorial Algorithm for LP Decoding of Turbo Codes Abstract: We present a novel algorithm that solves the turbo code LP decoding problem\nin a fininte number of steps by Euclidean distance minimizations, which in turn\nrely on repeated shortest path computations in the trellis graph representing\nthe turbo code. Previous attempts to exploit the combinatorial graph structure\nonly led to algorithms which are either of heuristic nature or do not guarantee\nfinite convergence. A numerical study shows that our algorithm clearly beats\nthe running time, up to a factor of 100, of generic commercial LP solvers for\nmedium-sized codes, especially for high SNR values. \n\n"}
{"id": "1302.1094", "contents": "Title: Analysis Based Blind Compressive Sensing Abstract: In this work we address the problem of blindly reconstructing compressively\nsensed signals by exploiting the co-sparse analysis model. In the analysis\nmodel it is assumed that a signal multiplied by an analysis operator results in\na sparse vector. We propose an algorithm that learns the operator adaptively\nduring the reconstruction process. The arising optimization problem is tackled\nvia a geometric conjugate gradient approach. Different types of sampling noise\nare handled by simply exchanging the data fidelity term. Numerical experiments\nare performed for measurements corrupted with Gaussian as well as impulsive\nnoise to show the effectiveness of our method. \n\n"}
{"id": "1302.1258", "contents": "Title: A Comparison of Superposition Coding Schemes Abstract: There are two variants of superposition coding schemes. Cover's original\nsuperposition coding scheme has code clouds of the identical shape, while\nBergmans's superposition coding scheme has code clouds of independently\ngenerated shapes. These two schemes yield identical achievable rate regions in\nseveral scenarios, such as the capacity region for degraded broadcast channels.\nThis paper shows that under the optimal maximum likelihood decoding, these two\nsuperposition coding schemes can result in different rate regions. In\nparticular, it is shown that for the two-receiver broadcast channel, Cover's\nsuperposition coding scheme can achieve rates strictly larger than Bergmans's\nscheme. \n\n"}
{"id": "1302.2702", "contents": "Title: On the Capacity of Channels with Timing Synchronization Errors Abstract: We consider a new formulation of a class of synchronization error channels\nand derive analytical bounds and numerical estimates for the capacity of these\nchannels. For the binary channel with only deletions, we obtain an expression\nfor the symmetric information rate in terms of subsequence weights which\nreduces to a tight lower bound for small deletion probabilities. We are also\nable to exactly characterize the Markov-1 rate for the binary channel with only\nreplications. For a channel that introduces deletions as well as replications\nof input symbols, we design approximating channels that parameterize the state\nspace and show that the information rates of these approximate channels\napproach that of the deletion-replication channel as the state space grows. For\nthe case of the channel where deletions and replications occur with the same\nprobabilities, a stronger result in the convergence of mutual information rates\nis shown. The numerous advantages this new formulation presents are explored. \n\n"}
{"id": "1303.1915", "contents": "Title: Spatially Selective Artificial-Noise Aided Transmit Optimization for\n  MISO Multi-Eves Secrecy Rate Maximization Abstract: Consider an MISO channel overheard by multiple eavesdroppers. Our goal is to\ndesign an artificial noise (AN)-aided transmit strategy, such that the\nachievable secrecy rate is maximized subject to the sum power constraint.\nAN-aided secure transmission has recently been found to be a promising approach\nfor blocking eavesdropping attempts. In many existing studies, the confidential\ninformation transmit covariance and the AN covariance are not simultaneously\noptimized. In particular, for design convenience, it is common to prefix the AN\ncovariance as a specific kind of spatially isotropic covariance. This paper\nconsiders joint optimization of the transmit and AN covariances for secrecy\nrate maximization (SRM), with a design flexibility that the AN can take any\nspatial pattern. Hence, the proposed design has potential in jamming the\neavesdroppers more effectively, based upon the channel state information (CSI).\nWe derive an optimization approach to the SRM problem through both analysis and\nconvex conic optimization machinery. We show that the SRM problem can be recast\nas a single-variable optimization problem, and that resultant problem can be\nefficiently handled by solving a sequence of semidefinite programs. Our\nframework deals with a general setup of multiple multi-antenna eavesdroppers,\nand can cater for additional constraints arising from specific application\nscenarios, such as interference temperature constraints in interference\nnetworks. We also generalize the framework to an imperfect CSI case where a\nworst-case robust SRM formulation is considered. A suboptimal but safe solution\nto the outage-constrained robust SRM design is also investigated. Simulation\nresults show that the proposed AN-aided SRM design yields significant secrecy\nrate gains over an optimal no-AN design and the isotropic AN design, especially\nwhen there are more eavesdroppers. \n\n"}
{"id": "1303.2636", "contents": "Title: Energy Cooperation in Energy Harvesting Communications Abstract: In energy harvesting communications, users transmit messages using energy\nharvested from nature during the course of communication. With an optimum\ntransmit policy, the performance of the system depends only on the energy\narrival profiles. In this paper, we introduce the concept of energy\ncooperation, where a user wirelessly transmits a portion of its energy to\nanother energy harvesting user. This enables shaping and optimization of the\nenergy arrivals at the energy-receiving node, and improves the overall system\nperformance, despite the loss incurred in energy transfer. We consider several\nbasic multi-user network structures with energy harvesting and wireless energy\ntransfer capabilities: relay channel, two-way channel and multiple access\nchannel. We determine energy management policies that maximize the system\nthroughput within a given duration using a Lagrangian formulation and the\nresulting KKT optimality conditions. We develop a two-dimensional directional\nwater-filling algorithm which optimally controls the flow of harvested energy\nin two dimensions: in time (from past to future) and among users (from\nenergy-transferring to energy-receiving) and show that a generalized version of\nthis algorithm achieves the boundary of the capacity region of the two-way\nchannel. \n\n"}
{"id": "1303.2952", "contents": "Title: Traffic Congestion in Expanders, $(p,\\delta)$--Hyperbolic Spaces and\n  Product of Trees Abstract: In this paper we define the notion of $(p,\\delta)$--Gromov hyperbolic space\nwhere we relax Gromov's {\\it slimness} condition to allow that not all but a\npositive fraction of all triangles are $\\delta$--slim. Furthermore, we study\nmaximum vertex congestion under geodesic routing and show that it scales as\n$\\Omega(p^2n^2/D_n^2)$ where $D_n$ is the diameter of the graph. We also\nconstruct a constant degree family of expanders with congestion $\\Theta(n^2)$\nin contrast with random regular graphs that have congestion $O(n\\log^{3}(n))$.\nFinally, we study traffic congestion on graphs defined as product of trees. \n\n"}
{"id": "1303.3165", "contents": "Title: Joint Optimization of Throughput and Packet Drop Rate for Delay\n  Sensitive Applications in TDD Satellite Network Coded Systems Abstract: In this paper, we consider the issue of throughput and packet drop rate (PDR)\noptimization as two performance metrics for delay sensitive applications in\nnetwork coded time division duplex (TDD) satellite systems with large round\ntrip times (RTT). We adopt random linear network coding (RLNC) under two\ndifferent scenarios, feedback-less and with feedback, and our goal is to\njointly optimize the mean throughputs and PDRs of users in the system. For this\npurpose, we propose a systematic framework and start with formulating and\noptimizing these performance metrics for the single-user case. This framework\nenables us to analytically compare the performance metrics under different\nsystem parameters and settings. By comparing RLNC schemes under feedback-less\nand feedback scenarios for different RTTs, we show that the feedback-less\nschemes outperform the schemes with feedback in TDD systems with large RTTs.\nThen, we extend the study of feedback-less RLNC schemes to the multi-user\nbroadcast case. Here, we consider a number of different broadcast scenarios and\noptimize the system parameters such that the best overall performance is\nachieved. Furthermore, the complicated interplay of the mean throughputs and\nPDRs of different users with different packet erasure conditions in each of the\nconsidered broadcast scenarios is discussed. \n\n"}
{"id": "1303.3235", "contents": "Title: On the Entropy of Couplings Abstract: In this paper, some general properties of Shannon information measures are\ninvestigated over sets of probability distributions with restricted marginals.\nCertain optimization problems associated with these functionals are shown to be\nNP-hard, and their special cases are found to be essentially\ninformation-theoretic restatements of well-known computational problems, such\nas the SUBSET SUM and the 3-PARTITION. The notion of minimum entropy coupling\nis introduced and its relevance is demonstrated in information-theoretic,\ncomputational, and statistical contexts. Finally, a family of pseudometrics (on\nthe space of discrete probability distributions) defined by these couplings is\nstudied, in particular their relation to the total variation distance, and a\nnew characterization of the conditional entropy is given. \n\n"}
{"id": "1304.0004", "contents": "Title: Linear under-determined systems with sparse solutions: Redirecting a\n  challenge? Abstract: Seminal works \\cite{CRT,DonohoUnsigned,DonohoPol} generated a massive\ninterest in studying linear under-determined systems with sparse solutions. In\nthis paper we give a short mathematical overview of what was accomplished in\nlast 10 years in a particular direction of such a studying. We then discuss\nwhat we consider were the main challenges in last 10 years and give our own\nview as to what are the main challenges that lie ahead. Through the\npresentation we arrive to a point where the following natural rhetoric question\narises: is it a time to redirect the main challenges? While we can not provide\nthe answer to such a question we hope that our small discussion will stimulate\nfurther considerations in this direction. \n\n"}
{"id": "1304.3850", "contents": "Title: Polar Coding for Fading Channels Abstract: A polar coding scheme for fading channels is proposed in this paper. More\nspecifically, the focus is Gaussian fading channel with a BPSK modulation\ntechnique, where the equivalent channel could be modeled as a binary symmetric\nchannel with varying cross-over probabilities. To deal with variable channel\nstates, a coding scheme of hierarchically utilizing polar codes is proposed. In\nparticular, by observing the polarization of different binary symmetric\nchannels over different fading blocks, each channel use corresponding to a\ndifferent polarization is modeled as a binary erasure channel such that polar\ncodes could be adopted to encode over blocks. It is shown that the proposed\ncoding scheme, without instantaneous channel state information at the\ntransmitter, achieves the capacity of the corresponding fading binary symmetric\nchannel, which is constructed from the underlying fading AWGN channel through\nthe modulation scheme. \n\n"}
{"id": "1304.4529", "contents": "Title: Random polynomials and pluripotential-theoretic extremal functions Abstract: There is a natural pluripotential-theoretic extremal function V_{K,Q}\nassociated to a closed subset K of C^m and a real-valued, continuous function Q\non K. We define random polynomials H_n whose coefficients with respect to a\nrelated orthonormal basis are independent, identically distributed\ncomplex-valued random variables having a very general distribution (which\nincludes both normalized complex and real Gaussian distributions) and we prove\nresults on a.s. convergence of a sequence 1/n log |H_n| pointwise and in\nL^1_{loc}(C^m) to V_{K,Q}. In addition we obtain results on a.s. convergence of\na sequence of normalized zero currents dd^c [1/n log |H_n|] to dd^c V_{K,Q} as\nwell as asymptotics of expectations of these currents. All these results extend\nto random polynomial mappings and to a more general setting of positive\nholomorphic line bundles over a compact Kahler manifold. \n\n"}
{"id": "1304.5357", "contents": "Title: Exact-Regenerating Codes between MBR and MSR Points Abstract: In this paper we study distributed storage systems with exact repair. We give\na construction for regenerating codes between the minimum storage regenerating\n(MSR) and the minimum bandwidth regenerating (MBR) points and show that in the\ncase that the parameters n, k, and d are close to each other our constructions\nare close to optimal when comparing to the known capacity when only functional\nrepair is required. We do this by showing that when the distances of the\nparameters n, k, and d are fixed but the actual values approach to infinity,\nthe fraction of the performance of our codes with exact repair and the known\ncapacity of codes with functional repair approaches to one. \n\n"}
{"id": "1304.5690", "contents": "Title: Universality for the largest eigenvalue of sample covariance matrices\n  with general population Abstract: This paper is aimed at deriving the universality of the largest eigenvalue of\na class of high-dimensional real or complex sample covariance matrices of the\nform $\\mathcal{W}_N=\\Sigma^{1/2}XX^*\\Sigma ^{1/2}$. Here, $X=(x_{ij})_{M,N}$ is\nan $M\\times N$ random matrix with independent entries $x_{ij},1\\leq i\\leq\nM,1\\leq j\\leq N$ such that $\\mathbb{E}x_{ij}=0$, $\\mathbb{E}|x_{ij}|^2=1/N$. On\ndimensionality, we assume that $M=M(N)$ and $N/M\\rightarrow d\\in(0,\\infty)$ as\n$N\\rightarrow\\infty$. For a class of general deterministic positive-definite\n$M\\times M$ matrices $\\Sigma$, under some additional assumptions on the\ndistribution of $x_{ij}$'s, we show that the limiting behavior of the largest\neigenvalue of $\\mathcal{W}_N$ is universal, via pursuing a Green function\ncomparison strategy raised in [Probab. Theory Related Fields 154 (2012)\n341-407, Adv. Math. 229 (2012) 1435-1515] by Erd\\H{o}s, Yau and Yin for Wigner\nmatrices and extended by Pillai and Yin [Ann. Appl. Probab. 24 (2014) 935-1001]\nto sample covariance matrices in the null case ($\\Sigma=I$). Consequently, in\nthe standard complex case ($\\mathbb{E}x_{ij}^2=0$), combing this universality\nproperty and the results known for Gaussian matrices obtained by El Karoui in\n[Ann. Probab. 35 (2007) 663-714] (nonsingular case) and Onatski in [Ann. Appl.\nProbab. 18 (2008) 470-490] (singular case), we show that after an appropriate\nnormalization the largest eigenvalue of $\\mathcal{W}_N$ converges weakly to the\ntype 2 Tracy-Widom distribution $\\mathrm{TW}_2$. Moreover, in the real case, we\nshow that when $\\Sigma$ is spiked with a fixed number of subcritical spikes,\nthe type 1 Tracy-Widom limit $\\mathrm{TW}_1$ holds for the normalized largest\neigenvalue of $\\mathcal {W}_N$, which extends a result of F\\'{e}ral and\nP\\'{e}ch\\'{e} in [J. Math. Phys. 50 (2009) 073302] to the scenario of\nnondiagonal $\\Sigma$ and more generally distributed $X$. \n\n"}
{"id": "1304.7047", "contents": "Title: Finding Hidden Cliques of Size \\sqrt{N/e} in Nearly Linear Time Abstract: Consider an Erd\\\"os-Renyi random graph in which each edge is present\nindependently with probability 1/2, except for a subset $\\sC_N$ of the vertices\nthat form a clique (a completely connected subgraph). We consider the problem\nof identifying the clique, given a realization of such a random graph.\n  The best known algorithm provably finds the clique in linear time with high\nprobability, provided $|\\sC_N|\\ge 1.261\\sqrt{N}$ \\cite{dekel2011finding}.\nSpectral methods can be shown to fail on cliques smaller than $\\sqrt{N}$. In\nthis paper we describe a nearly linear time algorithm that succeeds with high\nprobability for $|\\sC_N|\\ge (1+\\eps)\\sqrt{N/e}$ for any $\\eps>0$. This is the\nfirst algorithm that provably improves over spectral methods.\n  We further generalize the hidden clique problem to other background graphs\n(the standard case corresponding to the complete graph on $N$ vertices). For\nlarge girth regular graphs of degree $(\\Delta+1)$ we prove that `local'\nalgorithms succeed if $|\\sC_N|\\ge (1+\\eps)N/\\sqrt{e\\Delta}$ and fail if\n$|\\sC_N|\\le(1-\\eps)N/\\sqrt{e\\Delta}$. \n\n"}
{"id": "1304.7308", "contents": "Title: Improved Capacity Approximations for Gaussian Relay Networks Abstract: Consider a Gaussian relay network where a number of sources communicate to a\ndestination with the help of several layers of relays. Recent work has shown\nthat a compress-and-forward based strategy at the relays can achieve the\ncapacity of this network within an additive gap. In this strategy, the relays\nquantize their observations at the noise level and map it to a random Gaussian\ncodebook. The resultant capacity gap is independent of the SNR's of the\nchannels in the network but linear in the total number of nodes.\n  In this paper, we show that if the relays quantize their signals at a\nresolution decreasing with the number of nodes in the network, the additive gap\nto capacity can be made logarithmic in the number of nodes for a class of\nlayered, time-varying wireless relay networks. This suggests that the\nrule-of-thumb to quantize the received signals at the noise level used for\ncompress-and-forward in the current literature can be highly suboptimal. \n\n"}
{"id": "1305.0848", "contents": "Title: Bound entangled states with a private key and their classical\n  counterpart Abstract: Entanglement is a fundamental resource for quantum information processing. In\nits pure form, it allows quantum teleportation and sharing classical secrets.\nRealistic quantum states are noisy and their usefulness is only partially\nunderstood. Bound-entangled states are central to this question---they have no\ndistillable entanglement, yet sometimes still have a private classical key. We\npresent a construction of bound-entangled states with private key based on\nclassical probability distributions. From this emerge states possessing a new\nclassical analogue of bound entanglement, distinct from the long-sought bound\ninformation. We also find states of smaller dimensions and higher key rates\nthan previously known. Our construction has implications for classical\ncryptography: we show that existing protocols are insufficient for extracting\nprivate key from our distributions due to their \"bound-entangled\" nature. We\npropose a simple extension of existing protocols that can extract key from\nthem. \n\n"}
{"id": "1305.1490", "contents": "Title: Degrees of Freedom of Certain Interference Alignment Schemes with\n  Distributed CSIT Abstract: In this work, we consider the use of interference alignment (IA) in a MIMO\ninterference channel (IC) under the assumption that each transmitter (TX) has\naccess to channel state information (CSI) that generally differs from that\navailable to other TXs. This setting is referred to as distributed CSIT. In a\nsetting where CSI accuracy is controlled by a set of power exponents, we show\nthat in the static 3-user MIMO square IC, the number of degrees-of-freedom\n(DoF) that can be achieved with distributed CSIT is at least equal to the DoF\nachieved with the worst accuracy taken across the TXs and across the\ninterfering links. We conjecture further that this represents exactly the DoF\nachieved. This result is in strong contrast with the centralized CSIT\nconfiguration usually studied (where all the TXs share the same, possibly\nimperfect, channel estimate) for which it was shown that the DoF achieved at\nreceiver (RX) i is solely limited by the quality of its own feedback. This\nshows the critical impact of CSI discrepancies between the TXs, and highlights\nthe price paid by distributed precoding. \n\n"}
{"id": "1305.2714", "contents": "Title: Sharp MSE Bounds for Proximal Denoising Abstract: Denoising has to do with estimating a signal $x_0$ from its noisy\nobservations $y=x_0+z$. In this paper, we focus on the \"structured denoising\nproblem\", where the signal $x_0$ possesses a certain structure and $z$ has\nindependent normally distributed entries with mean zero and variance\n$\\sigma^2$. We employ a structure-inducing convex function $f(\\cdot)$ and solve\n$\\min_x\\{\\frac{1}{2}\\|y-x\\|_2^2+\\sigma\\lambda f(x)\\}$ to estimate $x_0$, for\nsome $\\lambda>0$. Common choices for $f(\\cdot)$ include the $\\ell_1$ norm for\nsparse vectors, the $\\ell_1-\\ell_2$ norm for block-sparse signals and the\nnuclear norm for low-rank matrices. The metric we use to evaluate the\nperformance of an estimate $x^*$ is the normalized mean-squared-error\n$\\text{NMSE}(\\sigma)=\\frac{\\mathbb{E}\\|x^*-x_0\\|_2^2}{\\sigma^2}$. We show that\nNMSE is maximized as $\\sigma\\rightarrow 0$ and we find the \\emph{exact} worst\ncase NMSE, which has a simple geometric interpretation: the\nmean-squared-distance of a standard normal vector to the $\\lambda$-scaled\nsubdifferential $\\lambda\\partial f(x_0)$. When $\\lambda$ is optimally tuned to\nminimize the worst-case NMSE, our results can be related to the constrained\ndenoising problem $\\min_{f(x)\\leq f(x_0)}\\{\\|y-x\\|_2\\}$. The paper also\nconnects these results to the generalized LASSO problem, in which, one solves\n$\\min_{f(x)\\leq f(x_0)}\\{\\|y-Ax\\|_2\\}$ to estimate $x_0$ from noisy linear\nobservations $y=Ax_0+z$. We show that certain properties of the LASSO problem\nare closely related to the denoising problem. In particular, we characterize\nthe normalized LASSO cost and show that it exhibits a \"phase transition\" as a\nfunction of number of observations. Our results are significant in two ways.\nFirst, we find a simple formula for the performance of a general convex\nestimator. Secondly, we establish a connection between the denoising and linear\ninverse problems. \n\n"}
{"id": "1305.5469", "contents": "Title: Fourth Moment Theorems for Markov Diffusion Generators Abstract: Inspired by the insightful article arXiv:1210.7587, we revisit the\nNualart-Peccati-criterion arXiv:math/0503598 (now known as the Fourth Moment\nTheorem) from the point of view of spectral theory of general Markov diffusion\ngenerators. We are not only able to drastically simplify all of its previous\nproofs, but also to provide new settings of diffusive generators (Laguerre,\nJacobi) where such a criterion holds. Convergence towards gamma and beta\ndistributions under moment conditions is also discussed. \n\n"}
{"id": "1305.6021", "contents": "Title: On the $\\ell_1$-Norm Invariant Convex k-Sparse Decomposition of Signals Abstract: Inspired by an interesting idea of Cai and Zhang, we formulate and prove the\nconvex $k$-sparse decomposition of vectors which is invariant with respect to\n$\\ell_1$ norm. This result fits well in discussing compressed sensing problems\nunder RIP, but we believe it also has independent interest. As an application,\na simple derivation of the RIP recovery condition $\\delta_k+\\theta_{k,k} < 1$\nis presented. \n\n"}
{"id": "1305.7294", "contents": "Title: A Note on Cyclic Codes from APN Functions Abstract: Cyclic codes, as linear block error-correcting codes in coding theory, play a\nvital role and have wide applications. Ding in \\cite{D} constructed a number of\nclasses of cyclic codes from almost perfect nonlinear (APN) functions and\nplanar functions over finite fields and presented ten open problems on cyclic\ncodes from highly nonlinear functions. In this paper, we consider two open\nproblems involving the inverse APN functions $f(x)=x^{q^m-2}$ and the Dobbertin\nAPN function $f(x)=x^{2^{4i}+2^{3i}+2^{2i}+2^{i}-1}$. From the calculation of\nlinear spans and the minimal polynomials of two sequences generated by these\ntwo classes of APN functions, the dimensions of the corresponding cyclic codes\nare determined and lower bounds on the minimum weight of these cyclic codes are\npresented. Actually, we present a framework for the minimal polynomial and\nlinear span of the sequence $s^{\\infty}$ defined by $s_t=Tr((1+\\alpha^t)^e)$,\nwhere $\\alpha$ is a primitive element in $GF(q)$. These techniques can also be\napplied into other open problems in \\cite{D}. \n\n"}
{"id": "1305.7323", "contents": "Title: Sub-Stream Fairness and Numerical Correctness in MIMO Interference\n  Channels Abstract: Signal-to-interference plus noise ratio (SINR) and rate fairness in a system\nare substantial quality-of-service (QoS) metrics. The acclaimed SINR\nmaximization (max-SINR) algorithm does not achieve fairness between user's\nstreams, i.e., sub-stream fairness is not achieved. To this end, we propose a\ndistributed power control algorithm to render sub-stream fairness in the\nsystem. Sub-stream fairness is a less restrictive design metric than stream\nfairness (i.e., fairness between all streams) thus sum-rate degradation is\nmilder. Algorithmic parameters can significantly differentiate the results of\nnumerical algorithms. A complete picture for comparison of algorithms can only\nbe depicted by varying these parameters. For example, a predetermined iteration\nnumber or a negligible increment in the sum-rate can be the stopping criteria\nof an algorithm. While the distributed interference alignment (DIA) can\nreasonably achieve sub-stream fairness for the later, the imbalance between\nsub-streams increases as the preset iteration number decreases. Thus comparison\nof max-SINR and DIA with a low preset iteration number can only depict a part\nof the picture. We analyze such important parameters and their effects on SINR\nand rate metrics to exhibit numerical correctness in executing the benchmarks.\nFinally, we propose group filtering schemes that jointly design the streams of\na user in contrast to max-SINR scheme that designs each stream of a user\nseparately. \n\n"}
{"id": "1306.1556", "contents": "Title: Diversity Polynomials for the Analysis of Temporal Correlations in\n  Wireless Networks Abstract: The interference in wireless networks is temporally correlated, since the\nnode or user locations are correlated over time and the interfering\ntransmitters are a subset of these nodes. For a wireless network where\n(potential) interferers form a Poisson point process and use ALOHA for channel\naccess, we calculate the joint success and outage probabilities of n\ntransmissions over a reference link. The results are based on the diversity\npolynomial, which captures the temporal interference correlation. The joint\noutage probability is used to determine the diversity gain (as the SIR goes to\ninfinity), and it turns out that there is no diversity gain in simple\nretransmission schemes, even with independent Rayleigh fading over all links.\nWe also determine the complete joint SIR distribution for two transmissions and\nthe distribution of the local delay, which is the time until a repeated\ntransmission over the reference link succeeds. \n\n"}
{"id": "1306.3609", "contents": "Title: Volume Ratio, Sparsity, and Minimaxity under Unitarily Invariant Norms Abstract: The current paper presents a novel machinery for studying non-asymptotic\nminimax estimation of high-dimensional matrices, which yields tight minimax\nrates for a large collection of loss functions in a variety of problems.\n  Based on the convex geometry of finite-dimensional Banach spaces, we first\ndevelop a volume ratio approach for determining minimax estimation rates of\nunconstrained normal mean matrices under all squared unitarily invariant norm\nlosses. In addition, we establish the minimax rates for estimating mean\nmatrices with submatrix sparsity, where the sparsity constraint introduces an\nadditional term in the rate whose dependence on the norm differs completely\nfrom the rate of the unconstrained problem. Moreover, the approach is\napplicable to the matrix completion problem under the low-rank constraint.\n  The new method also extends beyond the normal mean model. In particular, it\nyields tight rates in covariance matrix estimation and Poisson rate matrix\nestimation problems for all unitarily invariant norms. \n\n"}
{"id": "1306.3779", "contents": "Title: Bounds on restricted isometry constants of random matrices Abstract: In this paper we look at isometry properties of random matrices. During the\nlast decade these properties gained a lot attention in a field called\ncompressed sensing in first place due to their initial use in \\cite{CRT,CT}.\nNamely, in \\cite{CRT,CT} these quantities were used as a critical tool in\nproviding a rigorous analysis of $\\ell_1$ optimization's ability to solve an\nunder-determined system of linear equations with sparse solutions. In such a\nframework a particular type of isometry, called restricted isometry, plays a\nkey role. One then typically introduces a couple of quantities, called upper\nand lower restricted isometry constants to characterize the isometry properties\nof random matrices. Those constants are then usually viewed as mathematical\nobjects of interest and their a precise characterization is desirable. The\nfirst estimates of these quantities within compressed sensing were given in\n\\cite{CRT,CT}. As the need for precisely estimating them grew further a finer\nimprovements of these initial estimates were obtained in e.g.\n\\cite{BCTsharp09,BT10}. These are typically obtained through a combination of\nunion-bounding strategy and powerful tail estimates of extreme eigenvalues of\nWishart (Gaussian) matrices (see, e.g. \\cite{Edelman88}). In this paper we\nattempt to circumvent such an approach and provide an alternative way to obtain\nsimilar estimates. \n\n"}
{"id": "1306.3976", "contents": "Title: Lifting $\\ell_q$-optimization thresholds Abstract: In this paper we look at a connection between the $\\ell_q,0\\leq q\\leq 1$,\noptimization and under-determined linear systems of equations with sparse\nsolutions. The case $q=1$, or in other words $\\ell_1$ optimization and its a\nconnection with linear systems has been thoroughly studied in last several\ndecades; in fact, especially so during the last decade after the seminal works\n\\cite{CRT,DOnoho06CS} appeared. While current understanding of $\\ell_1$\noptimization-linear systems connection is fairly known, much less so is the\ncase with a general $\\ell_q,0<q<1$, optimization. In our recent work\n\\cite{StojnicLqThrBnds10} we provided a study in this direction. As a result we\nwere able to obtain a collection of lower bounds on various $\\ell_q,0\\leq q\\leq\n1$, optimization thresholds. In this paper, we provide a substantial conceptual\nimprovement of the methodology presented in \\cite{StojnicLqThrBnds10}.\nMoreover, the practical results in terms of achievable thresholds are also\nencouraging. As is usually the case with these and similar problems, the\nmethodology we developed emphasizes their a combinatorial nature and attempts\nto somehow handle it. Although our results' main contributions should be on a\nconceptual level, they already give a very strong suggestion that $\\ell_q$\noptimization can in fact provide a better performance than $\\ell_1$, a fact\nlong believed to be true due to a tighter optimization relaxation it provides\nto the original $\\ell_0$ sparsity finding oriented original problem\nformulation. As such, they in a way give a solid boost to further exploration\nof the design of the algorithms that would be able to handle $\\ell_q,0<q<1$,\noptimization in a reasonable (if not polynomial) time. \n\n"}
{"id": "1306.5776", "contents": "Title: Two-Part Reconstruction in Compressed Sensing Abstract: Two-part reconstruction is a framework for signal recovery in compressed\nsensing (CS), in which the advantages of two different algorithms are combined.\nOur framework allows to accelerate the reconstruction procedure without\ncompromising the reconstruction quality. To illustrate the efficacy of our\ntwo-part approach, we extend the author's previous Sudocodes algorithm and make\nit robust to measurement noise. In a 1-bit CS setting, promising numerical\nresults indicate that our algorithm offers both a reduction in run-time and\nimprovement in reconstruction quality. \n\n"}
{"id": "1306.6288", "contents": "Title: Information Spectrum Approach to the Source Channel Separation Theorem Abstract: A source-channel separation theorem for a general channel has recently been\nshown by Aggrawal et. al. This theorem states that if there exist a coding\nscheme that achieves a maximum distortion level d_{max} over a general channel\nW, then reliable communication can be accomplished over this channel at rates\nless then R(d_{max}), where R(.) is the rate distortion function of the source.\nThe source, however, is essentially constrained to be discrete and memoryless\n(DMS). In this work we prove a stronger claim where the source is general,\nsatisfying only a \"sphere packing optimality\" feature, and the channel is\ncompletely general. Furthermore, we show that if the channel satisfies the\nstrong converse property as define by Han & verdu, then the same statement can\nbe made with d_{avg}, the average distortion level, replacing d_{max}. Unlike\nthe proofs there, we use information spectrum methods to prove the statements\nand the results can be quite easily extended to other situations. \n\n"}
{"id": "1307.2799", "contents": "Title: Polar Coded Modulation with Optimal Constellation Labeling Abstract: A practical $2^m$-ary polar coded modulation (PCM) scheme with optimal\nconstellation labeling is proposed. To efficiently find the optimal labeling\nrule, the search space is reduced by exploiting the symmetry properties of the\nchannels. Simulation results show that the proposed PCM scheme can outperform\nthe bit-interleaved turbo coded modulation scheme used in the WCDMA (Wideband\nCode Division Multiple Access) mobile communication systems by up to 1.5dB. \n\n"}
{"id": "1307.3796", "contents": "Title: Self-Interference Cancellation with Nonlinear Distortion Suppression for\n  Full-Duplex Systems Abstract: In full-duplex systems, due to the strong self-interference signal, system\nnonlinearities become a significant limiting factor that bounds the possible\ncancellable self-interference power. In this paper, a self-interference\ncancellation scheme for full-duplex orthogonal frequency division multiplexing\nsystems is proposed. The proposed scheme increases the amount of cancellable\nself-interference power by suppressing the distortion caused by the transmitter\nand receiver nonlinearities. An iterative technique is used to jointly estimate\nthe self-interference channel and the nonlinearity coefficients required to\nsuppress the distortion signal. The performance is numerically investigated\nshowing that the proposed scheme achieves a performance that is less than 0.5dB\noff the performance of a linear full-duplex system. \n\n"}
{"id": "1307.4149", "contents": "Title: Self-Interference Cancellation with Phase Noise Induced ICI Suppression\n  for Full-Duplex Systems Abstract: One of the main bottlenecks in practical full-duplex systems is the\noscillator phase noise, which bounds the possible cancellable self-interference\npower. In this paper, a digitaldomain self-interference cancellation scheme for\nfull-duplex orthogonal frequency division multiplexing systems is proposed. The\nproposed scheme increases the amount of cancellable selfinterference power by\nsuppressing the effect of both transmitter and receiver oscillator phase noise.\nThe proposed scheme consists of two main phases, an estimation phase and a\ncancellation phase. In the estimation phase, the minimum mean square error\nestimator is used to jointly estimate the transmitter and receiver phase noise\nassociated with the incoming self-interference signal. In the cancellation\nphase, the estimated phase noise is used to suppress the intercarrier\ninterference caused by the phase noise associated with the incoming\nself-interference signal. The performance of the proposed scheme is numerically\ninvestigated under different operating conditions. It is demonstrated that the\nproposed scheme could achieve up to 9dB more self-interference cancellation\nthan the existing digital-domain cancellation schemes that ignore the\nintercarrier interference suppression. \n\n"}
{"id": "1307.7447", "contents": "Title: Wireless Information and Power Transfer in Two-Way Amplify-and-Forward\n  Relaying Channels Abstract: The various wireless networks have made the ambient radio frequency signals\naround the world. Wireless information and power transfer enables the devices\nto recycle energy from these ambient radio frequency signals and process\ninformation simultaneously. In this paper, we develop a wireless information\nand power transfer protocol in two-way amplify-and-forward relaying channels,\nwhere two sources exchange information via an energy harvesting relay node. The\nrelay node collects energy from the received signals and uses it to provide the\ntransmission power to forward the received signals. We analytically derive the\nexact expressions of the outage probability, the ergodic capacity and the\nfinite-SNR diversity-multiplexing trade-off (DMT). Furthermore, the tight\nclosed-form upper and lower bounds of the outage probability and the ergodic\ncapacity are then developed. Moreover, the impact of the power splitting ratio\nis also evaluated and analyzed. Finally, we show that compared to the\nnon-cooperative relaying scheme, the proposed protocol is a green solution to\noffer higher transmission rate and more reliable communication without\nconsuming additional resource. \n\n"}
{"id": "1308.4077", "contents": "Title: Support Recovery for the Drift Coefficient of High-Dimensional\n  Diffusions Abstract: Consider the problem of learning the drift coefficient of a $p$-dimensional\nstochastic differential equation from a sample path of length $T$. We assume\nthat the drift is parametrized by a high-dimensional vector, and study the\nsupport recovery problem when both $p$ and $T$ can tend to infinity. In\nparticular, we prove a general lower bound on the sample-complexity $T$ by\nusing a characterization of mutual information as a time integral of\nconditional variance, due to Kadota, Zakai, and Ziv. For linear stochastic\ndifferential equations, the drift coefficient is parametrized by a $p\\times p$\nmatrix which describes which degrees of freedom interact under the dynamics. In\nthis case, we analyze a $\\ell_1$-regularized least squares estimator and prove\nan upper bound on $T$ that nearly matches the lower bound on specific classes\nof sparse matrices. \n\n"}
{"id": "1308.4769", "contents": "Title: The transition probability and the probability for the left-most\n  particle's position of the q-TAZRP Abstract: We treat the $N$-particle ZRP whose jumping rates satisfy a certain\ncondition. This condition is required to use the Bethe ansatz and the resulting\nmodel is the $q$-boson model that appeared in [J. Phys. A, \\textbf{31}\n6057--6071 (1998)] by Sasamoto and Wadati or the $q$-TAZRP in \\textit{MacDonald\nprocesses} by Borodin and Corwin. We find the explicit formula of the\ntransition probability of the $q$-TAZRP via the Bethe ansatz. By using the\ntransition probability we find the probability distribution of the left-most\nparticle's position at time $t$. To find the probability for the left-most\nparticle's position we find a new identity corresponding to Tracy and Widom's\nidentity for the ASEP in [Commun. Math. Phys., \\textbf{279} 815--844 (2008)].\nFor the initial state that all particles occupy a single site, the probability\ndistribution of the left-most particle's position at time $t$ is represented by\nthe contour integral of a determinant. \n\n"}
{"id": "1308.5096", "contents": "Title: On the spectral gap of the kac walk and other binary collision processes\n  on $d$-dimensional lattice Abstract: We give a lower bound on the spectral gap for a class of binary collision\nprocesses. In 2008, Caputo showed that, for a class of binary collision\nprocesses given by simple averages on the complete graph, the analysis of the\nspectral gap of an $N$-component system is reduced to that of the same system\nfor N=3 In this paper, we give a comparison technique to reduce the analysis of\nthe spectral gap of binary collision processes given by simple averages on\n$d$-dimensional lattice to that on the complete graph. We also give a\ncomparison technique to reduce the analysis of the spectral gap of binary\ncollision processes which are not given by simple averages to that given by\nsimple averages. Combining them with Caputo's result, we give a new and\nelementary method to obtain spectral gap estimates. The method applies to a\nnumber of binary collision processes on the complete graph and also on\nd-dimensional lattice, including a class of energy exchange models which was\nrecently introduced in by Grigo et al., and zero-range processes. \n\n"}
{"id": "1308.6481", "contents": "Title: Nonparametric Decentralized Sequential Detection via Universal Source\n  Coding Abstract: We consider nonparametric or universal sequential hypothesis testing problem\nwhen the distribution under the null hypothesis is fully known but the\nalternate hypothesis corresponds to some other unknown distribution. These\nalgorithms are primarily motivated from spectrum sensing in Cognitive Radios\nand intruder detection in wireless sensor networks. We use easily implementable\nuniversal lossless source codes to propose simple algorithms for such a setup.\nThe algorithms are first proposed for discrete alphabet. Their performance and\nasymptotic properties are studied theoretically. Later these are extended to\ncontinuous alphabets. Their performance with two well known universal source\ncodes, Lempel-Ziv code and Krichevsky-Trofimov estimator with Arithmetic\nEncoder are compared. These algorithms are also compared with the tests using\nvarious other nonparametric estimators. Finally a decentralized version\nutilizing spatial diversity is also proposed. Its performance is analysed and\nasymptotic properties are proved. \n\n"}
{"id": "1308.6570", "contents": "Title: Stick-breaking PG(\\alpha,\\zeta)-Generalized Gamma Processes Abstract: This work centers around results related to Proposition 21 of Pitman and\nYor's (1997) paper on the two parameter Poisson Dirichlet distribution indexed\nby (\\alpha,\\theta) for 0<\\alpha<1, also \\alpha=0, and \\theta>-\\alpha, denoted\nPD(\\alpha,\\theta). We develop explicit stick-breaking representations for a\nclass that contains the PD(\\alpha,\\theta) for the range \\theta=0, and \\theta>0,\nwe call PG(\\alpha,\\zeta). We also construct a larger class, EPG(\\alpha,\\zeta),\ncontaining the entire range. These classes are indexed by \\alpha, and an\narbitrary non-negative random variable \\zeta. The bulk of this work focuses on\ninvestigating various properties of this larger class, EPG(\\alpha,\\zeta), which\nlead to connections to other work in the literature. In particular, we develop\ncompletely explicit stick-breaking representations for this entire class via\nsize biased sampling as described in Perman, Pitman and Yor (1992). This\nrepresents the first case outside of the PD(\\alpha,\\theta) where one obtains\nexplicit results for the entire range of \\alpha, the EPG are within the larger\nclass of mass partitions generated by conditioning on the total mass of an\n\\alpha-stable subordinator. Furthermore Markov chains are derived which\nestablish links between Markov chains derived from\nstick-breaking(insertion/deletion), as described in Perman, Pitman and Yor and\nMarkov chains derived from successive usage of dual coagulation fragmentation\noperators described in Bertoin and Goldschmidt and Dong, Goldschmidt and\nMartin. Which have connections to certain types of fragmentation trees and\ncoalescents appearing in the recent literature. Our results are also suggestive\nof new models and tools, for applications in Bayesian Nonparametrics/Machine\nLearning, where PD(\\alpha,\\theta) bridges are often referred to as Pitman-Yor\nprocesses. \n\n"}
{"id": "1309.2643", "contents": "Title: Noisy Interactive Quantum Communication Abstract: We study the problem of simulating protocols in a quantum communication\nsetting over noisy channels. This problem falls at the intersection of quantum\ninformation theory and quantum communication complexity, and it will be of\nimportance for eventual real-world applications of interactive quantum\nprotocols, which can be proved to have exponentially lower communication costs\nthan their classical counterparts for some problems. These are the first\nresults concerning the quantum version of this problem, originally studied by\nSchulman in a classical setting (FOCS '92, STOC '93). We simulate a length $N$\nquantum communication protocol by a length $O(N)$ protocol with arbitrarily\nsmall error. Under adversarial noise, our strategy can withstand, for\narbitrarily small $\\epsilon > 0$, error rates as high as $1/2 -\\epsilon$ when\nparties pre-share perfect entanglement, but the classical channel is noisy. We\nshow that this is optimal. We provide extension of these results in several\nother models of communication, including when also the entanglement is noisy,\nand when there is no pre-shared entanglement but communication is quantum and\nnoisy. We also study the case of random noise, for which we provide simulation\nprotocols with positive communication rates and no pre-shared entanglement over\nsome quantum channels with quantum capacity $C_Q=0$, proving that $C_Q$ is in\ngeneral not the right characterization of a channel's capacity for interactive\nquantum communication. Our results are stated for a general quantum\ncommunication protocol in which Alice and Bob collaborate, and these results\nhold in particular in the quantum communication complexity settings of the Yao\nand Cleve--Buhrman models. \n\n"}
{"id": "1309.2819", "contents": "Title: Stochastic processes with random contexts: a characterization, and\n  adaptive estimators for the transition probabilities Abstract: This paper introduces the concept of random context representations for the\ntransition probabilities of a finite-alphabet stochastic process. Processes\nwith these representations generalize context tree processes (a.k.a. variable\nlength Markov chains), and are proven to coincide with processes whose\ntransition probabilities are almost surely continuous functions of the\n(infinite) past. This is similar to a classical result by Kalikow about\ncontinuous transition probabilities. Existence and uniqueness of a minimal\nrandom context representation are proven, and an estimator of the transition\nprobabilities based on this representation is shown to have very good \"pastwise\nadaptativity\" properties. In particular, it achieves minimax performance, up to\nlogarithmic factors, for binary renewal processes with bounded $2+\\gamma$\nmoments. \n\n"}
{"id": "1309.3901", "contents": "Title: A new design criterion for spherically-shaped division algebra-based\n  space-time codes Abstract: This work considers normalized inverse determinant sums as a tool for\nanalyzing the performance of division algebra based space-time codes for\nmultiple antenna wireless systems. A general union bound based code design\ncriterion is obtained as a main result. In our previous work, the behavior of\ninverse determinant sums was analyzed using point counting techniques for Lie\ngroups; it was shown that the asymptotic growth exponents of these sums\ncorrectly describe the diversity-multiplexing gain trade-off of the space-time\ncode for some multiplexing gain ranges. This paper focuses on the constant\nterms of the inverse determinant sums, which capture the coding gain behavior.\nPursuing the Lie group approach, a tighter asymptotic bound is derived,\nallowing to compute the constant terms for several classes of space-time codes\nappearing in the literature. The resulting design criterion suggests that the\nperformance of division algebra based codes depends on several fundamental\nalgebraic invariants of the underlying algebra. \n\n"}
{"id": "1310.0720", "contents": "Title: A Survey on Device-to-Device Communication in Cellular Networks Abstract: Device-to-Device (D2D) communication was initially proposed in cellular\nnetworks as a new paradigm to enhance network performance. The emergence of new\napplications such as content distribution and location-aware advertisement\nintroduced new use-cases for D2D communications in cellular networks. The\ninitial studies showed that D2D communication has advantages such as increased\nspectral efficiency and reduced communication delay. However, this\ncommunication mode introduces complications in terms of interference control\noverhead and protocols that are still open research problems. The feasibility\nof D2D communications in LTE-A is being studied by academia, industry, and the\nstandardization bodies. To date, there are more than 100 papers available on\nD2D communications in cellular networks and, there is no survey on this field.\nIn this article, we provide a taxonomy based on the D2D communicating spectrum\nand review the available literature extensively under the proposed taxonomy.\nMoreover, we provide new insights to the over-explored and under-explored areas\nwhich lead us to identify open research problems of D2D communication in\ncellular networks. \n\n"}
{"id": "1310.1419", "contents": "Title: On Association Cells in Random Heterogeneous Networks Abstract: Characterizing user to access point (AP) association strategies in\nheterogeneous cellular networks (HetNets) is critical for their performance\nanalysis, as it directly influences the load across the network. In this\nletter, we introduce and analyze a class of association strategies, which we\nterm stationary association, and the resulting association cells. For random\nHetNets, where APs are distributed according to a stationary point process, the\narea of the resulting association cells are shown to be the marks of the\ncorresponding point process. Addressing the need of quantifying the load\nexperienced by a typical user, a \"Feller-paradox\" like relationship is\nestablished between the area of the association cell containing origin and that\nof a typical association cell. For the specific case of Poisson point process\nand max power/SINR association, the mean association area of each tier is\nderived and shown to increase with channel gain variance and decrease in the\npath loss exponents of the corresponding tier. \n\n"}
{"id": "1310.2773", "contents": "Title: Relay-assisted Multiple Access with Full-duplex Multi-Packet Reception Abstract: The effect of full-duplex cooperative relaying in a random access multiuser\nnetwork is investigated here. First, we model the self-interference incurred\ndue to full-duplex operation, assuming multi-packet reception capabilities for\nboth the relay and the destination node. Traffic at the source nodes is\nconsidered saturated and the cooperative relay, which does not have packets of\nits own, stores a source packet that it receives successfully in its queue when\nthe transmission to the destination has failed. We obtain analytical\nexpressions for key performance metrics at the relay, such as arrival and\nservice rates, stability conditions, and average queue length, as functions of\nthe transmission probabilities, the self interference coefficient, and the\nlinks' outage probabilities. Furthermore, we study the impact of the relay node\nand the self-interference coefficient on the per-user and aggregate throughput,\nand the average delay per packet. We show that perfect self-interference\ncancelation plays a crucial role when the SINR threshold is small, since it may\nresult to worse performance in throughput and delay comparing with the\nhalf-duplex case. This is because perfect self-interference cancelation can\ncause an unstable queue at the relay under some conditions. \n\n"}
{"id": "1310.3843", "contents": "Title: Designing Multi-User MIMO for Energy Efficiency: When is Massive MIMO\n  the Answer? Abstract: Assume that a multi-user multiple-input multiple-output (MIMO) communication\nsystem must be designed to cover a given area with maximal energy efficiency\n(bit/Joule). What are the optimal values for the number of antennas, active\nusers, and transmit power? By using a new model that describes how these three\nparameters affect the total energy efficiency of the system, this work provides\nclosed-form expressions for their optimal values and interactions. In sharp\ncontrast to common belief, the transmit power is found to increase (not\ndecrease) with the number of antennas. This implies that energy efficient\nsystems can operate at high signal-to-noise ratio (SNR) regimes in which the\nuse of interference-suppressing precoding schemes is essential. Numerical\nresults show that the maximal energy efficiency is achieved by a massive MIMO\nsetup wherein hundreds of antennas are deployed to serve relatively many users\nusing interference-suppressing regularized zero-forcing precoding. \n\n"}
{"id": "1310.3843", "contents": "Title: Designing Multi-User MIMO for Energy Efficiency: When is Massive MIMO\n  the Answer? Abstract: Assume that a multi-user multiple-input multiple-output (MIMO) communication\nsystem must be designed to cover a given area with maximal energy efficiency\n(bit/Joule). What are the optimal values for the number of antennas, active\nusers, and transmit power? By using a new model that describes how these three\nparameters affect the total energy efficiency of the system, this work provides\nclosed-form expressions for their optimal values and interactions. In sharp\ncontrast to common belief, the transmit power is found to increase (not\ndecrease) with the number of antennas. This implies that energy efficient\nsystems can operate at high signal-to-noise ratio (SNR) regimes in which the\nuse of interference-suppressing precoding schemes is essential. Numerical\nresults show that the maximal energy efficiency is achieved by a massive MIMO\nsetup wherein hundreds of antennas are deployed to serve relatively many users\nusing interference-suppressing regularized zero-forcing precoding. \n\n"}
{"id": "1310.4393", "contents": "Title: An algorithm for variable density sampling with block-constrained\n  acquisition Abstract: Reducing acquisition time is of fundamental importance in various imaging\nmodalities. The concept of variable density sampling provides a nice framework\nto achieve this. It was justified recently from a theoretical point of view in\nthe compressed sensing (CS) literature. Unfortunately, the sampling schemes\nsuggested by current CS theories may not be relevant since they do not take the\nacquisition constraints into account (for example, continuity of the\nacquisition trajectory in Magnetic Resonance Imaging - MRI). In this paper, we\npropose a numerical method to perform variable density sampling with block\nconstraints. Our main contribution is to propose a new way to draw the blocks\nin order to mimic CS strategies based on isolated measurements. The basic idea\nis to minimize a tailored dissimilarity measure between a probability\ndistribution defined on the set of isolated measurements and a probability\ndistribution defined on a set of blocks of measurements. This problem turns out\nto be convex and solvable in high dimension. Our second contribution is to\ndefine an efficient minimization algorithm based on Nesterov's accelerated\ngradient descent in metric spaces. We study carefully the choice of the metrics\nand of the prox function. We show that the optimal choice may depend on the\ntype of blocks under consideration. Finally, we show that we can obtain better\nMRI reconstruction results using our sampling schemes than standard strategies\nsuch as equiangularly distributed radial lines. \n\n"}
{"id": "1310.4907", "contents": "Title: Message and time efficient multi-broadcast schemes Abstract: We consider message and time efficient broadcasting and multi-broadcasting in\nwireless ad-hoc networks, where a subset of nodes, each with a unique rumor,\nwish to broadcast their rumors to all destinations while minimizing the total\nnumber of transmissions and total time until all rumors arrive to their\ndestination. Under centralized settings, we introduce a novel approximation\nalgorithm that provides almost optimal results with respect to the number of\ntransmissions and total time, separately. Later on, we show how to efficiently\nimplement this algorithm under distributed settings, where the nodes have only\nlocal information about their surroundings. In addition, we show multiple\napproximation techniques based on the network collision detection capabilities\nand explain how to calibrate the algorithms' parameters to produce optimal\nresults for time and messages. \n\n"}
{"id": "1310.6795", "contents": "Title: Downlink Multi-Antenna Heterogeneous Cellular Network with Load\n  Balancing Abstract: We model and analyze heterogeneous cellular networks with multiple antenna\nBSs (multi-antenna HetNets) with K classes or tiers of base stations (BSs),\nwhich may differ in terms of transmit power, deployment density, number of\ntransmit antennas, number of users served, transmission scheme, and path loss\nexponent. We show that the cell selection rules in multi-antenna HetNets may\ndiffer significantly from the single-antenna HetNets due to the possible\ndifferences in multi-antenna transmission schemes across tiers. While it is\nchallenging to derive exact cell selection rules even for maximizing\nsignal-to-interferenceplus-noise-ratio (SINR) at the receiver, we show that\nadding an appropriately chosen tier-dependent cell selection bias in the\nreceived power yields a close approximation. Assuming arbitrary selection bias\nfor each tier, simple expressions for downlink coverage and rate are derived.\nFor coverage maximization, the required selection bias for each tier is given\nin closed form. Due to this connection with biasing, multi-antenna HetNets may\nbalance load more naturally across tiers in certain regimes compared to\nsingle-antenna HetNets, where a large cell selection bias is often needed to\noffload traffic to small cells. \n\n"}
{"id": "1310.6817", "contents": "Title: Systematic Error-Correcting Codes for Rank Modulation Abstract: The rank-modulation scheme has been recently proposed for efficiently storing\ndata in nonvolatile memories. Error-correcting codes are essential for rank\nmodulation, however, existing results have been limited. In this work we\nexplore a new approach, \\emph{systematic error-correcting codes for rank\nmodulation}. Systematic codes have the benefits of enabling efficient\ninformation retrieval and potentially supporting more efficient encoding and\ndecoding procedures. We study systematic codes for rank modulation under\nKendall's $\\tau$-metric as well as under the $\\ell_\\infty$-metric.\n  In Kendall's $\\tau$-metric we present $[k+2,k,3]$-systematic codes for\ncorrecting one error, which have optimal rates, unless systematic perfect codes\nexist. We also study the design of multi-error-correcting codes, and provide\ntwo explicit constructions, one resulting in $[n+1,k+1,2t+2]$ systematic codes\nwith redundancy at most $2t+1$. We use non-constructive arguments to show the\nexistence of $[n,k,n-k]$-systematic codes for general parameters. Furthermore,\nwe prove that for rank modulation, systematic codes achieve the same capacity\nas general error-correcting codes.\n  Finally, in the $\\ell_\\infty$-metric we construct two $[n,k,d]$ systematic\nmulti-error-correcting codes, the first for the case of $d=O(1)$, and the\nsecond for $d=\\Theta(n)$. In the latter case, the codes have the same\nasymptotic rate as the best codes currently known in this metric. \n\n"}
{"id": "1310.7158", "contents": "Title: Outage Constrained Robust Secure Transmission for MISO Wiretap Channels Abstract: In this paper we consider the robust secure beamformer design for MISO\nwiretap channels. Assume that the eavesdroppers' channels are only partially\navailable at the transmitter, we seek to maximize the secrecy rate under the\ntransmit power and secrecy rate outage probability constraint. The outage\nprobability constraint requires that the secrecy rate exceeds certain threshold\nwith high probability. Therefore including such constraint in the design\nnaturally ensures the desired robustness. Unfortunately, the presence of the\nprobabilistic constraints makes the problem non-convex and hence difficult to\nsolve. In this paper, we investigate the outage probability constrained secrecy\nrate maximization problem using a novel two-step approach. Under a wide range\nof uncertainty models, our developed algorithms can obtain high-quality\nsolutions, sometimes even exact global solutions, for the robust secure\nbeamformer design problem. Simulation results are presented to verify the\neffectiveness and robustness of the proposed algorithms. \n\n"}
{"id": "1311.3141", "contents": "Title: Cloud Compute-and-Forward with Relay Cooperation Abstract: We study a cloud network with M distributed receiving antennas and L users,\nwhich transmit their messages towards a centralized decoder (CD), where M>=L.\nWe consider that the cloud network applies the Compute-and-Forward (C&F)\nprotocol, where L antennas/relays are selected to decode integer equations of\nthe transmitted messages. In this work, we focus on the best relay selection\nand the optimization of the Physical-Layer Network Coding (PNC) at the relays,\naiming at the throughput maximization of the network. Existing literature\noptimizes PNC with respect to the maximization of the minimum rate among users.\nThe proposed strategy maximizes the sum rate of the users allowing nonsymmetric\nrates, while the optimal solution is explored with the aid of the Pareto\nfrontier. The problem of relay selection is matched to a coalition formation\ngame, where the relays and the CD cooperate in order to maximize their profit.\nEfficient coalition formation algorithms are proposed, which perform joint\nrelay selection and PNC optimization. Simulation results show that a\nconsiderable improvement is achieved compared to existing results, both in\nterms of the network sum rate and the players' profits. \n\n"}
{"id": "1311.3895", "contents": "Title: Inverse problems in multifractal analysis Abstract: Multifractal formalism is designed to describe the distribution at small\nscales of the elements of $\\mathcal M^+_c(\\R^d)$, the set of positive, finite\nand compactly supported Borel measures on $\\R^d$. It is valid for such a\nmeasure $\\mu$ when its Hausdorff spectrum is the upper semi-continuous function\ngiven by the concave Legendre-Fenchel transform of the free energy function\n$\\tau_\\mu$ associated with $\\mu$; this is the case for fundamental classes of\nexact dimensional measures.\n  For any function $\\tau$ candidate to be the free energy function of some\n$\\mu\\in \\mathcal M^+_c(\\R^d)$, we build such a measure, exact dimensional, and\nobeying the multifractal formalism. This result is extended to a refined\nformalism considering jointly Hausdorff and packing spectra. Also, for any\nupper semi-continuous function candidate to be the lower Hausdorff spectrum of\nsome exact dimensional $\\mu\\in\\mathcal M^+_c(\\R^d)$, we build such a measure.\n  Our results transfer to the analoguous inverse problems in multifractal\nanalysis of H\\\"older continuous functions. \n\n"}
{"id": "1311.4601", "contents": "Title: Achievable Rate Regions for Network Coding Abstract: Determining the achievable rate region for networks using routing, linear\ncoding, or non-linear coding is thought to be a difficult task in general, and\nfew are known. We describe the achievable rate regions for four interesting\nnetworks (completely for three and partially for the fourth). In addition to\nthe known matrix-computation method for proving outer bounds for linear coding,\nwe present a new method which yields actual characteristic-dependent linear\nrank inequalities from which the desired bounds follow immediately. \n\n"}
{"id": "1311.6635", "contents": "Title: Multiuser Random Coding Techniques for Mismatched Decoding Abstract: This paper studies multiuser random coding techniques for channel coding with\na given (possibly suboptimal) decoding rule. For the mismatched discrete\nmemoryless multiple-access channel, an error exponent is obtained that is tight\nwith respect to the ensemble average, and positive within the interior of\nLapidoth's achievable rate region. This exponent proves the ensemble tightness\nof the exponent of Liu and Hughes in the case of maximum-likelihood decoding.\nAn equivalent dual form of Lapidoth's achievable rate region is given, and the\nlatter is shown to extend immediately to channels with infinite and continuous\nalphabets. In the setting of single-user mismatched decoding, similar analysis\ntechniques are applied to a refined version of superposition coding, which is\nshown to achieve rates at least as high as standard superposition coding for\nany set of random-coding parameters. \n\n"}
{"id": "1311.7442", "contents": "Title: Irreducibility is Minimum Synergy Among Parts Abstract: For readers already familiar with Partial Information Decomposition (PID), we\nshow that PID's definition of synergy enables quantifying at least four\ndifferent notions of irreducibility. First, we show four common notions of\n\"parts\" give rise to a spectrum of four distinct measures of irreducibility.\nSecond, we introduce a nonnegative expression based on PID for each notion of\nirreducibility. Third, we delineate these four notions of irreducibility with\nexemplary binary circuits. This work will become more useful once the\ncomplexity community has converged on a palatable $\\operatorname{I}_{\\cap}$ or\n$\\operatorname{I}_{\\cup}$ measure. \n\n"}
{"id": "1312.0522", "contents": "Title: Analog Baseband Cancellation for Full-Duplex: An Experiment Driven\n  Analysis Abstract: Recent wireless testbed implementations have proven that full-duplex\ncommunication is in fact possible and can outperform half-duplex systems. Many\nof these implementations modify existing half-duplex systems to operate in\nfull-duplex. To realize the full potential of full-duplex, radios need to be\ndesigned with self-interference in mind. In our work, we use a novel patch\nantenna prototype in an experimental setup to characterize the\nself-interference channel between transmit and receive radios. We derive an\nequivalent analytical baseband model and propose analog baseband cancellation\ntechniques to complement the RF cancellation provided by the patch antenna\nprototype. Our results show that a wide bandwidth, moderate isolation scheme\nachieves up to 2.4 bps/Hz higher achievable rate than a narrow bandwidth, high\nisolation scheme. Furthermore, the analog baseband cancellation yields a\n10-10,000 improvement in BER over RF only cancellation. \n\n"}
{"id": "1312.2183", "contents": "Title: Maximum Likelihood Estimation from Sign Measurements with Sensing Matrix\n  Perturbation Abstract: The problem of estimating an unknown deterministic parameter vector from sign\nmeasurements with a perturbed sensing matrix is studied in this paper. We\nanalyze the best achievable mean square error (MSE) performance by exploring\nthe corresponding Cram\\'{e}r-Rao Lower Bound (CRLB). To estimate the parameter,\nthe maximum likelihood (ML) estimator is utilized and its consistency is\nproved. We show that the perturbation on the sensing matrix exacerbates the\nperformance of ML estimator in most cases. However, suitable perturbation may\nimprove the performance in some special cases. Then we reformulate the original\nML estimation problem as a convex optimization problem, which can be solved\nefficiently. Furthermore, theoretical analysis implies that the\nperturbation-ignored estimation is a scaled version with the same direction of\nthe ML estimation. Finally, numerical simulations are performed to validate our\ntheoretical analysis. \n\n"}
{"id": "1312.2315", "contents": "Title: Noisy Bayesian Active Learning Abstract: We consider the problem of noisy Bayesian active learning, where we are given\na finite set of functions $\\mathcal{H}$, a sample space $\\mathcal{X}$, and a\nlabel set $\\mathcal{L}$. One of the functions in $\\mathcal{H}$ assigns labels\nto samples in $\\mathcal{X}$. The goal is to identify the function that\ngenerates the labels even though the result of a label query on a sample is\ncorrupted by independent noise. More precisely, the objective is to declare one\nof the functions in $\\mathcal{H}$ as the true label generating function with\nhigh confidence using as few label queries as possible, by selecting the\nqueries adaptively and in a strategic manner.\n  Previous work in Bayesian active learning considers Generalized Binary\nSearch, and its variants for the noisy case, and analyzes the number of queries\nrequired by these sampling strategies. In this paper, we show that these\nschemes are, in general, suboptimal. Instead we propose and analyze an\nalternative strategy for sample collection. Our sampling strategy is motivated\nby a connection between Bayesian active learning and active hypothesis testing,\nand is based on querying the label of a sample which maximizes the Extrinsic\nJensen-Shannon divergence at each step. We provide upper and lower bounds on\nthe performance of this sampling strategy, and show that these bounds are\nbetter than previous bounds. \n\n"}
{"id": "1312.2903", "contents": "Title: The lower tail of random quadratic forms, with applications to ordinary\n  least squares and restricted eigenvalue properties Abstract: Finite sample properties of random covariance-type matrices have been the\nsubject of much research. In this paper we focus on the \"lower tail\" of such a\nmatrix, and prove that it is subgaussian under a simple fourth moment\nassumption on the one-dimensional marginals of the random vectors. A similar\nresult holds for more general sums of random positive semidefinite matrices,\nand the (relatively simple) proof uses a variant of the so-called PAC-Bayesian\nmethod for bounding empirical processes.\n  We give two applications of the main result. In the first one we obtain a new\nfinite-sample bound for ordinary least squares estimator in linear regression\nwith random design. Our result is model-free, requires fairly weak moment\nassumptions and is almost optimal. Our second application is to bounding\nrestricted eigenvalue constants of certain random ensembles with \"heavy tails\".\nThese constants are important in the analysis of problems in Compressed Sensing\nand High Dimensional Statistics, where one recovers a sparse vector from a\nsmall umber of linear measurements. Our result implies that heavy tails still\nallow for the fast recovery rates found in efficient methods such as the LASSO\nand the Dantzig selector. Along the way we strengthen, with a fairly short\nargument, a recent result of Rudelson and Zhou on the restricted eigenvalue\nproperty. \n\n"}
{"id": "1312.5276", "contents": "Title: Integration by parts and representation of information functionals Abstract: We introduce a new formalism for computing expectations of functionals of\narbitrary random vectors, by using generalised integration by parts formulae.\nIn doing so we extend recent representation formulae for the score function\nintroduced in Nourdin, Peccati and Swan (JFA, to appear) and also provide a new\nproof of a central identity first discovered in Guo, Shamai, and Verd{\\'u}\n(IEEE Trans. Information Theory, 2005). We derive a representation for the\nstandardized Fisher information of sums of i.i.d. random vectors which use our\nidentities to provide rates of convergence in information theoretic central\nlimit theorems (both in Fisher information distance and in relative entropy). \n\n"}
{"id": "1312.5486", "contents": "Title: Molecular communication networks with general molecular circuit\n  receivers Abstract: In a molecular communication network, transmitters may encode information in\nconcentration or frequency of signalling molecules. When the signalling\nmolecules reach the receivers, they react, via a set of chemical reactions or a\nmolecular circuit, to produce output molecules. The counts of output molecules\nover time is the output signal of the receiver. The aim of this paper is to\ninvestigate the impact of different reaction types on the information\ntransmission capacity of molecular communication networks. We realise this aim\nby using a general molecular circuit model. We derive general expressions of\nmean receiver output, and signal and noise spectra. We use these expressions to\ninvestigate the information transmission capacities of a number of molecular\ncircuits. \n\n"}
{"id": "1312.7135", "contents": "Title: Multihop Backhaul Compression for the Uplink of Cloud Radio Access\n  Networks Abstract: In cloud radio access networks (C-RANs), the baseband processing of the radio\nunits (RUs) is migrated to remote control units (CUs). This is made possible by\na network of backhaul links that connects RUs and CUs and that carries\ncompressed baseband signals. While prior work has focused mostly on single-hop\nbackhaul networks, this paper investigates efficient backhaul compression\nstrategies for the uplink of C-RANs with a general multihop backhaul topology.\nA baseline multiplex-and-forward (MF) scheme is first studied in which each RU\nforwards the bit streams received from the connected RUs without any\nprocessing. It is observed that this strategy may cause significant performance\ndegradation in the presence of a dense deployment of RUs with a well connected\nbackhaul network. To obviate this problem, a scheme is proposed in which each\nRU decompresses the received bit streams and performs linear in-network\nprocessing of the decompressed signals. For both the MF and the\ndecompress-process-and-recompress (DPR) backhaul schemes, the optimal design is\naddressed with the aim of maximizing the sum-rate under the backhaul capacity\nconstraints. Recognizing the significant demands of the optimal solution of the\nDPR scheme in terms of channel state information (CSI) at the RUs,\ndecentralized optimization algorithms are proposed under the assumption of\nlimited CSI at the RUs. Numerical results are provided to compare the\nperformance of the MF and DPR schemes, highlighting the potential advantage of\nin-network processing and the impact of CSI limitations. \n\n"}
{"id": "1312.7642", "contents": "Title: On simultaneous min-entropy smoothing Abstract: In the context of network information theory, one often needs a multiparty\nprobability distribution to be typical in several ways simultaneously. When\nconsidering quantum states instead of classical ones, it is in general\ndifficult to prove the existence of a state that is jointly typical. Such a\ndifficulty was recently emphasized and conjectures on the existence of such\nstates were formulated. In this paper, we consider a one-shot multiparty\ntypicality conjecture. The question can then be stated easily: is it possible\nto smooth the largest eigenvalues of all the marginals of a multipartite state\n{\\rho} simultaneously while staying close to {\\rho}? We prove the answer is yes\nwhenever the marginals of the state commute. In the general quantum case, we\nprove that simultaneous smoothing is possible if the number of parties is two\nor more generally if the marginals to optimize satisfy some non-overlap\nproperty. \n\n"}
{"id": "1401.0978", "contents": "Title: A Principled Infotheoretic \\phi-like Measure Abstract: Integrated information theory is a mathematical, quantifiable theory of\nconscious experience. The linchpin of this theory, the $\\phi$ measure,\nquantifies a system's irreducibility to disjoint parts. Purely as a measure of\nirreducibility, we pinpoint three concerns about $\\phi$ and propose a revised\nmeasure, $\\psi$, which addresses them. Our measure $\\psi$ is rigorously\ngrounded in Partial Information Decomposition and is faster to compute than\n$\\phi$. \n\n"}
{"id": "1401.2693", "contents": "Title: On List-decodability of Random Rank Metric Codes Abstract: In the present paper, we consider list decoding for both random rank metric\ncodes and random linear rank metric codes. Firstly, we show that, for arbitrary\n$0<R<1$ and $\\epsilon>0$ ($\\epsilon$ and $R$ are independent), if\n$0<\\frac{n}{m}\\leq \\epsilon$, then with high probability a random rank metric\ncode in $F_{q}^{m\\times n}$ of rate $R$ can be list-decoded up to a fraction\n$(1-R-\\epsilon)$ of rank errors with constant list size $L$ satisfying $L\\leq\nO(1/\\epsilon)$. Moreover, if $\\frac{n}{m}\\geq\\Theta_R(\\epsilon)$, any rank\nmetric code in $F_{q}^{m\\times n}$ with rate $R$ and decoding radius\n$\\rho=1-R-\\epsilon$ can not be list decoded in ${\\rm poly}(n)$ time. Secondly,\nwe show that if $\\frac{n}{m}$ tends to a constant $b\\leq 1$, then every\n$F_q$-linear rank metric code in $F_{q}^{m\\times n}$ with rate $R$ and list\ndecoding radius $\\rho$ satisfies the Gilbert-Varsharmov bound, i.e., $R\\leq\n(1-\\rho)(1-b\\rho)$. Furthermore, for arbitrary $\\epsilon>0$ and any $0<\\rho<1$,\nwith high probability a random $F_q$-linear rank metric codes with rate\n$R=(1-\\rho)(1-b\\rho)-\\epsilon$ can be list decoded up to a fraction $\\rho$ of\nrank errors with constant list size $L$ satisfying $L\\leq O(\\exp(1/\\epsilon))$. \n\n"}
{"id": "1401.2794", "contents": "Title: On Binomial Ideals associated to Linear Codes Abstract: Recently, it was shown that a binary linear code can be associated to a\nbinomial ideal given as the sum of a toric ideal and a non-prime ideal. Since\nthen two different generalizations have been provided which coincide for the\nbinary case. In this paper, we establish some connections between the two\napproaches. In particular, we show that the corresponding code ideals are\nrelated by elimination. Finally, a new heuristic decoding method for linear\ncodes over prime fields is discussed using Gr\\\"obner bases. \n\n"}
{"id": "1401.3420", "contents": "Title: Democratic Representations Abstract: Minimization of the $\\ell_{\\infty}$ (or maximum) norm subject to a constraint\nthat imposes consistency to an underdetermined system of linear equations finds\nuse in a large number of practical applications, including vector quantization,\napproximate nearest neighbor search, peak-to-average power ratio (or \"crest\nfactor\") reduction in communication systems, and peak force minimization in\nrobotics and control. This paper analyzes the fundamental properties of signal\nrepresentations obtained by solving such a convex optimization problem. We\ndevelop bounds on the maximum magnitude of such representations using the\nuncertainty principle (UP) introduced by Lyubarskii and Vershynin, and study\nthe efficacy of $\\ell_{\\infty}$-norm-based dynamic range reduction. Our\nanalysis shows that matrices satisfying the UP, such as randomly subsampled\nFourier or i.i.d. Gaussian matrices, enable the computation of what we call\ndemocratic representations, whose entries all have small and similar magnitude,\nas well as low dynamic range. To compute democratic representations at low\ncomputational complexity, we present two new, efficient convex optimization\nalgorithms. We finally demonstrate the efficacy of democratic representations\nfor dynamic range reduction in a DVB-T2-based broadcast system. \n\n"}
{"id": "1401.4633", "contents": "Title: Efficient Codes for Adversarial Wiretap Channels Abstract: In [13] we proposed a ({\\rho}_r , {\\rho}_w )-adversarial wiretap channel\nmodel (AWTP) in which the adversary can adaptively choose to see a fraction\n{\\rho}_r of the codeword sent over the channel, and modify a fraction {\\rho}_w\nof the codeword by adding arbitrary noise values to them. In this paper we give\nthe first efficient construction of a capacity achieving code family that\nprovides perfect secrecy for this channel. \n\n"}
{"id": "1401.5194", "contents": "Title: Fundamental Finite Key Limits for One-Way Information Reconciliation in\n  Quantum Key Distribution Abstract: The security of quantum key distribution protocols is guaranteed by the laws\nof quantum mechanics. However, a precise analysis of the security properties\nrequires tools from both classical cryptography and information theory. Here,\nwe employ recent results in non-asymptotic classical information theory to show\nthat one-way information reconciliation imposes fundamental limitations on the\namount of secret key that can be extracted in the finite key regime. In\nparticular, we find that an often used approximation for the information\nleakage during information reconciliation is not generally valid. We propose an\nimproved approximation that takes into account finite key effects and\nnumerically test it against codes for two probability distributions, that we\ncall binary-binary and binary-Gaussian, that typically appear in quantum key\ndistribution protocols. \n\n"}
{"id": "1401.5676", "contents": "Title: A Novel Proof for the DoF Region of the MIMO Broadcast Channel with No\n  CSIT Abstract: In this paper, a new proof for the degrees of freedom (DoF) region of the\nK-user multiple-input multiple-output (MIMO) broadcast channel (BC) with no\nchannel state information at the transmitter (CSIT) and perfect channel state\ninformation at the receivers (CSIR) is provided. Based on this proof, the\ncapacity region of a certain class of MIMO BC with channel distribution\ninformation at the transmitter (CDIT) and perfect CSIR is derived. Finally, an\nouter bound for the DoF region of the MIMO interference channel (IC) with no\nCSIT is provided. \n\n"}
{"id": "1401.6145", "contents": "Title: On Stochastic Geometry Modeling of Cellular Uplink Transmission with\n  Truncated Channel Inversion Power Control Abstract: Using stochastic geometry, we develop a tractable uplink modeling paradigm\nfor outage probability and spectral efficiency in both single and multi-tier\ncellular wireless networks. The analysis accounts for per user equipment (UE)\npower control as well as the maximum power limitations for UEs. More\nspecifically, for interference mitigation and robust uplink communication, each\nUE is required to control its transmit power such that the average received\nsignal power at its serving base station (BS) is equal to a certain threshold\n$\\rho_o$. Due to the limited transmit power, the UEs employ a truncated channel\ninversion power control policy with a cutoff threshold of $\\rho_o$. We show\nthat there exists a transfer point in the uplink system performance that\ndepends on the tuple: BS intensity ($\\lambda$), maximum transmit power of UEs\n($P_u$), and $\\rho_o$. That is, when $P_u$ is a tight operational constraint\nwith respect to [w.r.t.] $\\lambda$ and $\\rho_o$, the uplink outage probability\nand spectral efficiency highly depend on the values of $\\lambda$ and $\\rho_o$.\nIn this case, there exists an optimal cutoff threshold $\\rho^*_o$, which\ndepends on the system parameters, that minimizes the outage probability. On the\nother hand, when $P_u$ is not a binding operational constraint w.r.t. $\\lambda$\nand $\\rho_o$, the uplink outage probability and spectral efficiency become\nindependent of $\\lambda$ and $\\rho_o$. We obtain approximate yet accurate\nsimple expressions for outage probability and spectral efficiency which reduce\nto closed-forms in some special cases. \n\n"}
{"id": "1401.7006", "contents": "Title: Polar Codes for Some Multi-terminal Communications Problems Abstract: It is shown that polar coding schemes achieve the known achievable rate\nregions for several multi-terminal communications problems including lossy\ndistributed source coding, multiple access channels and multiple descriptions\ncoding. The results are valid for arbitrary alphabet sizes (binary or\nnonbinary) and arbitrary distributions (symmetric or asymmetric). \n\n"}
{"id": "1401.7114", "contents": "Title: Fundamental Limits in Correlated Fading MIMO Broadcast Channels:\n  Benefits of Transmit Correlation Diversity Abstract: We investigate asymptotic capacity limits of the Gaussian MIMO broadcast\nchannel (BC) with spatially correlated fading to understand when and how much\ntransmit correlation helps the capacity. By imposing a structure on channel\ncovariances (equivalently, transmit correlations at the transmitter side) of\nusers, also referred to as \\emph{transmit correlation diversity}, the impact of\ntransmit correlation on the power gain of MIMO BCs is characterized in several\nregimes of system parameters, with a particular interest in the large-scale\narray (or massive MIMO) regime. Taking the cost for downlink training into\naccount, we provide asymptotic capacity bounds of multiuser MIMO downlink\nsystems to see how transmit correlation diversity affects the system\nmultiplexing gain. We make use of the notion of joint spatial division and\nmultiplexing (JSDM) to derive the capacity bounds. It is advocated in this\npaper that transmit correlation diversity may be of use to significantly\nincrease multiplexing gain as well as power gain in multiuser MIMO systems. In\nparticular, the new type of diversity in wireless communications is shown to\nimprove the system multiplexing gain up to by a factor of the number of degrees\nof such diversity. Finally, performance limits of conventional large-scale MIMO\nsystems not exploiting transmit correlation are also characterized. \n\n"}
{"id": "1402.1572", "contents": "Title: New Outer Bounds for the Interference Channel with Unilateral Source\n  Cooperation Abstract: This paper studies the two-user interference channel with unilateral source\ncooperation, which consists of two source-destination pairs that share the same\nchannel and where one full-duplex source can overhear the other source through\na noisy in-band link. Novel outer bounds of the type 2Rp+Rc/Rp+2Rc are\ndeveloped for the class of injective semi-deterministic channels with\nindependent noises at the different source-destination pairs. The bounds are\nthen specialized to the Gaussian noise case. Interesting insights are provided\nabout when these types of bounds are active, or in other words, when unilateral\ncooperation is too weak and leaves \"holes\" in the system resources. \n\n"}
{"id": "1402.1605", "contents": "Title: Fast Numerical Nonlinear Fourier Transforms Abstract: The nonlinear Fourier transform, which is also known as the forward\nscattering transform, decomposes a periodic signal into nonlinearly interacting\nwaves. In contrast to the common Fourier transform, these waves no longer have\nto be sinusoidal. Physically relevant waveforms are often available for the\nanalysis instead. The details of the transform depend on the waveforms\nunderlying the analysis, which in turn are specified through the implicit\nassumption that the signal is governed by a certain evolution equation. For\nexample, water waves generated by the Korteweg-de Vries equation can be\nexpressed in terms of cnoidal waves. Light waves in optical fiber governed by\nthe nonlinear Schr\\\"odinger equation (NSE) are another example. Nonlinear\nanalogs of classic problems such as spectral analysis and filtering arise in\nmany applications, with information transmission in optical fiber, as proposed\nby Yousefi and Kschischang, being a very recent one. The nonlinear Fourier\ntransform is eminently suited to address them -- at least from a theoretical\npoint of view. Although numerical algorithms are available for computing the\ntransform, a \"fast\" nonlinear Fourier transform that is similarly effective as\nthe fast Fourier transform is for computing the common Fourier transform has\nnot been available so far. The goal of this paper is to address this problem.\nTwo fast numerical methods for computing the nonlinear Fourier transform with\nrespect to the NSE are presented. The first method achieves a runtime of\n$O(D^2)$ floating point operations, where $D$ is the number of sample points.\nThe second method applies only to the case where the NSE is defocusing, but it\nachieves an $O(D\\log^2D)$ runtime. Extensions of the results to other evolution\nequations are discussed as well. \n\n"}
{"id": "1402.1761", "contents": "Title: On Scalability of Wireless Networks: A Practical Primer for Large Scale\n  Cooperation Abstract: An intuitive overview of the scalability of a variety of types of wireless\nnetworks is presented. Simple heuris- tic arguments are demonstrated here for\nscaling laws presented in other works, as well as for conditions not previously\nconsidered in the literature. Unicast and multicast messages, topology,\nhierarchy, and effects of reliability protocols are discussed. We show how two\nkey factors, bottlenecks and erasures, can often domi- nate the network scaling\nbehavior. Scaling of through- put or delay with the number of transmitting\nnodes, the number of receiving nodes, and the file size is described. \n\n"}
{"id": "1402.2343", "contents": "Title: New Codes and Inner Bounds for Exact Repair in Distributed Storage\n  Systems Abstract: We study the exact-repair tradeoff between storage and repair bandwidth in\ndistributed storage systems (DSS). We give new inner bounds for the tradeoff\nregion and provide code constructions that achieve these bounds. \n\n"}
{"id": "1402.2637", "contents": "Title: Identifiability Scaling Laws in Bilinear Inverse Problems Abstract: A number of ill-posed inverse problems in signal processing, like blind\ndeconvolution, matrix factorization, dictionary learning and blind source\nseparation share the common characteristic of being bilinear inverse problems\n(BIPs), i.e. the observation model is a function of two variables and\nconditioned on one variable being known, the observation is a linear function\nof the other variable. A key issue that arises for such inverse problems is\nthat of identifiability, i.e. whether the observation is sufficient to\nunambiguously determine the pair of inputs that generated the observation.\nIdentifiability is a key concern for applications like blind equalization in\nwireless communications and data mining in machine learning. Herein, a unifying\nand flexible approach to identifiability analysis for general conic prior\nconstrained BIPs is presented, exploiting a connection to low-rank matrix\nrecovery via lifting. We develop deterministic identifiability conditions on\nthe input signals and examine their satisfiability in practice for three\nclasses of signal distributions, viz. dependent but uncorrelated, independent\nGaussian, and independent Bernoulli. In each case, scaling laws are developed\nthat trade-off probability of robust identifiability with the complexity of the\nrank two null space. An added appeal of our approach is that the rank two null\nspace can be partly or fully characterized for many bilinear problems of\ninterest (e.g. blind deconvolution). We present numerical experiments involving\nvariations on the blind deconvolution problem that exploit a characterization\nof the rank two null space and demonstrate that the scaling laws offer good\nestimates of identifiability. \n\n"}
{"id": "1402.2936", "contents": "Title: R-dimensional ESPRIT-type algorithms for strictly second-order\n  non-circular sources and their performance analysis Abstract: High-resolution parameter estimation algorithms designed to exploit the prior\nknowledge about incident signals from strictly second-order (SO) non-circular\n(NC) sources allow for a lower estimation error and can resolve twice as many\nsources. In this paper, we derive the R-D NC Standard ESPRIT and the R-D NC\nUnitary ESPRIT algorithms that provide a significantly better performance\ncompared to their original versions for arbitrary source signals. They are\napplicable to shift-invariant R-D antenna arrays and do not require a\ncentrosymmetric array structure. Moreover, we present a first-order asymptotic\nperformance analysis of the proposed algorithms, which is based on the error in\nthe signal subspace estimate arising from the noise perturbation. The derived\nexpressions for the resulting parameter estimation error are explicit in the\nnoise realizations and asymptotic in the effective signal-to-noise ratio (SNR),\ni.e., the results become exact for either high SNRs or a large sample size. We\nalso provide mean squared error (MSE) expressions, where only the assumptions\nof a zero mean and finite SO moments of the noise are required, but no\nassumptions about its statistics are necessary. As a main result, we\nanalytically prove that the asymptotic performance of both R-D NC ESPRIT-type\nalgorithms is identical in the high effective SNR regime. Finally, a case study\nshows that no improvement from strictly non-circular sources can be achieved in\nthe special case of a single source. \n\n"}
{"id": "1402.3074", "contents": "Title: Scheduling Advantages of Network Coded Storage in Point-to-Multipoint\n  Networks Abstract: We consider scheduling strategies for point-to-multipoint (PMP) storage area\nnetworks (SANs) that use network coded storage (NCS). In particular, we present\na simple SAN system model, two server scheduling algorithms for PMP networks,\nand analytical expressions for internal and external blocking probability. We\npoint to select scheduling advantages in NCS systems under normal operating\nconditions, where content requests can be temporarily denied owing to finite\nsystem capacity from drive I/O access or storage redundancy limitations. NCS\ncan lead to improvements in throughput and blocking probability due to\nincreased immediate scheduling options, and complements other well documented\nNCS advantages such as regeneration, and can be used as a guide for future\nstorage system design. \n\n"}
{"id": "1402.3225", "contents": "Title: Market-Based Power Allocation for a Differentially Priced FDMA System Abstract: In this paper, we study the problem of differential pricing and QoS\nassignment by a broadband data provider. In our model, the broadband data\nprovider decides on the power allocated to an end-user not only based on\nparameters of the transmission medium, but also based on the price the user is\nwilling to pay. In addition, end-users bid the price that they are willing to\npay to the BTS based on their channel condition, the throughput they require,\nand their belief about other users' parameters. We will characterize the\noptimum power allocation by the BTS which turns out to be a modification of the\nsolution to the well-known water-filling problem. We also characterize the\noptimum bidding strategy of end-users using the belief of each user about the\ncell condition. \n\n"}
{"id": "1402.5196", "contents": "Title: Synchronization-Free Delay Tomography Based on Compressed Sensing Abstract: Delay tomography has so far burdened source and receiver measurement nodes in\na network with two requirements such as path establishment and clock\nsynchronization between them. In this letter, we focus on the clock\nsynchronization problem in delay tomography and propose a synchronization-free\ndelay tomography scheme. The proposed scheme selects a path between source and\nreceiver measurement nodes as a reference path, which results in a loss of\nequation in a conventional delay tomography problem. However, by utilizing\ncompressed sensing, the proposed scheme becomes robust to the loss. Simulation\nexperiments confirm that the proposed scheme works comparable to a conventional\ndelay tomography scheme in networks with no clock synchronization between\nsource and receiver measurement nodes. \n\n"}
{"id": "1402.6286", "contents": "Title: Improved Recovery Guarantees for Phase Retrieval from Coded Diffraction\n  Patterns Abstract: In this work we analyze the problem of phase retrieval from Fourier\nmeasurements with random diffraction patterns. To this end, we consider the\nrecently introduced PhaseLift algorithm, which expresses the problem in the\nlanguage of convex optimization. We provide recovery guarantees which require\nO(log^2 d) different diffraction patterns, thus improving on recent results by\nCandes et al. [arXiv:1310.3240], which require O(log^4 d) different patterns. \n\n"}
{"id": "1402.7170", "contents": "Title: Improving the Finite-Length Performance of Spatially Coupled LDPC Codes\n  by Connecting Multiple Code Chains Abstract: In this paper, we analyze the finite-length performance of codes on graphs\nconstructed by connecting spatially coupled low-density parity-check (SC-LDPC)\ncode chains. Successive (peeling) decoding is considered for the binary erasure\nchannel (BEC). The evolution of the undecoded portion of the bipartite graph\nremaining after each iteration is analyzed as a dynamical system. When\nconnecting short SC-LDPC chains, we show that, in addition to superior\niterative decoding thresholds, connected chain ensembles have better\nfinite-length performance than single chain ensembles of the same rate and\nlength. In addition, we present a novel encoding/transmission scheme to improve\nthe performance of a system using long SC-LDPC chains, where, instead of\ntransmitting codewords corresponding to a single SC-LDPC chain independently,\nwe connect consecutive chains in a multi-layer format to form a connected chain\nensemble. We refer to such a transmission scheme to as continuous chain (CC)\ntransmission of SC-LDPC codes. We show that CC transmission can be implemented\nwith no significant increase in encoding/decoding complexity or decoding delay\nwith respect a system using a single SC-LDPC code chain for encoding. \n\n"}
{"id": "1403.1023", "contents": "Title: Active Hypothesis Testing for Quickest Anomaly Detection Abstract: The problem of quickest detection of an anomalous process among M processes\nis considered. At each time, a subset of the processes can be observed, and the\nobservations from each chosen process follow two different distributions,\ndepending on whether the process is normal or abnormal. The objective is a\nsequential search strategy that minimizes the expected detection time subject\nto an error probability constraint. This problem can be considered as a special\ncase of active hypothesis testing first considered by Chernoff in 1959 where a\nrandomized strategy, referred to as the Chernoff test, was proposed and shown\nto be asymptotically (as the error probability approaches zero) optimal. For\nthe special case considered in this paper, we show that a simple deterministic\ntest achieves asymptotic optimality and offers better performance in the finite\nregime. We further extend the problem to the case where multiple anomalous\nprocesses are present. In particular, we examine the case where only an upper\nbound on the number of anomalous processes is known. \n\n"}
{"id": "1403.1596", "contents": "Title: Energy Consumption in multi-user MIMO systems: Impact of user mobility Abstract: In this work, we consider the downlink of a single-cell multi-user\nmultiple-input multiple-output system in which zero-forcing precoding is used\nat the base station (BS) to serve a certain number of user equipments (UEs). A\nfixed data rate is guaranteed at each UE. The UEs move around in the cell\naccording to a Brownian motion, thus the path losses change over time and the\nenergy consumption fluctuates accordingly. We aim at determining the\ndistribution of the energy consumption. To this end, we analyze the asymptotic\nregime where the number of antennas at the BS and the number of UEs grow large\nwith a given ratio. It turns out that the energy consumption is asymptotically\na Gaussian random variable whose mean and variance are derived analytically.\nThese results can, for example, be used to approximate the probability that a\nbattery-powered BS runs out of energy within a certain time period. \n\n"}
{"id": "1403.1757", "contents": "Title: Hilberg Exponents: New Measures of Long Memory in the Process Abstract: The paper concerns the rates of power-law growth of mutual information\ncomputed for a stationary measure or for a universal code. The rates are called\nHilberg exponents and four such quantities are defined for each measure and\neach code: two random exponents and two expected exponents. A particularly\ninteresting case arises for conditional algorithmic mutual information. In this\ncase, the random Hilberg exponents are almost surely constant on ergodic\nsources and are bounded by the expected Hilberg exponents. This property is a\n\"second-order\" analogue of the Shannon-McMillan-Breiman theorem, proved without\ninvoking the ergodic theorem. It carries over to Hilberg exponents for the\nunderlying probability measure via Shannon-Fano coding and Barron inequality.\nMoreover, the expected Hilberg exponents can be linked for different universal\ncodes. Namely, if one code dominates another, the expected Hilberg exponents\nare greater for the former than for the latter. The paper is concluded by an\nevaluation of Hilberg exponents for certain sources such as the mixture\nBernoulli process and the Santa Fe processes. \n\n"}
{"id": "1403.2239", "contents": "Title: Super-Resolution from Short-Time Fourier Transform Measurements Abstract: While spike trains are obviously not band-limited, the theory of\nsuper-resolution tells us that perfect recovery of unknown spike locations and\nweights from low-pass Fourier transform measurements is possible provided that\nthe minimum spacing, $\\Delta$, between spikes is not too small. Specifically,\nfor a cutoff frequency of $f_c$, Donoho [2] shows that exact recovery is\npossible if $\\Delta > 1/f_c$, but does not specify a corresponding recovery\nmethod. On the other hand, Cand\\`es and Fernandez-Granda [3] provide a recovery\nmethod based on convex optimization, which provably succeeds as long as $\\Delta\n> 2/f_c$. In practical applications one often has access to windowed Fourier\ntransform measurements, i.e., short-time Fourier transform (STFT) measurements,\nonly. In this paper, we develop a theory of super-resolution from STFT\nmeasurements, and we propose a method that provably succeeds in recovering\nspike trains from STFT measurements provided that $\\Delta > 1/f_c$. \n\n"}
{"id": "1403.2301", "contents": "Title: Phase Retrieval using Lipschitz Continuous Maps Abstract: In this note we prove that reconstruction from magnitudes of frame\ncoefficients (the so called \"phase retrieval problem\") can be performed using\nLipschitz continuous maps. Specifically we show that when the nonlinear\nanalysis map $\\alpha:{\\mathcal H}\\rightarrow\\mathbb{R}^m$ is injective, with\n$(\\alpha(x))_k=|<x,f_k>|^2$, where $\\{f_1,\\ldots,f_m\\}$ is a frame for the\nHilbert space ${\\mathcal H}$, then there exists a left inverse map\n$\\omega:\\mathbb{R}^m\\rightarrow {\\mathcal H}$ that is Lipschitz continuous.\nAdditionally we obtain the Lipschitz constant of this inverse map in terms of\nthe lower Lipschitz constant of $\\alpha$. Surprisingly the increase in\nLipschitz constant is independent of the space dimension or frame redundancy. \n\n"}
{"id": "1403.3369", "contents": "Title: Controlling Recurrent Neural Networks by Conceptors Abstract: The human brain is a dynamical system whose extremely complex sensor-driven\nneural processes give rise to conceptual, logical cognition. Understanding the\ninterplay between nonlinear neural dynamics and concept-level cognition remains\na major scientific challenge. Here I propose a mechanism of neurodynamical\norganization, called conceptors, which unites nonlinear dynamics with basic\nprinciples of conceptual abstraction and logic. It becomes possible to learn,\nstore, abstract, focus, morph, generalize, de-noise and recognize a large\nnumber of dynamical patterns within a single neural system; novel patterns can\nbe added without interfering with previously acquired ones; neural noise is\nautomatically filtered. Conceptors help explaining how conceptual-level\ninformation processing emerges naturally and robustly in neural systems, and\nremove a number of roadblocks in the theory and applications of recurrent\nneural networks. \n\n"}
{"id": "1403.4452", "contents": "Title: The Homogeneous Weight Partition and its Character-Theoretic Dual Abstract: The values of the normalized homogeneous weight are determined for arbitrary\nfinite Frobenius rings and expressed in a form that is independent from a\ngenerating character and the M\\\"obius function on the ring. The weight\nnaturally induces a partition of the ring, which is invariant under left or\nright multiplication by units. It is shown that the character-theoretic\nleft-sided dual of this partition coincides with the right-sided dual, and even\nmore, the left- and right-sided Krawtchouk coefficients coincide. An example is\nprovided showing that this is not the case for general invariant partitions if\nthe ring is not semisimple. \n\n"}
{"id": "1403.4847", "contents": "Title: Massive MIMO Systems with Hardware-Constrained Base Stations Abstract: Massive multiple-input multiple-output (MIMO) systems are cellular networks\nwhere the base stations (BSs) are equipped with unconventionally many antennas.\nSuch large antenna arrays offer huge spatial degrees-of-freedom for\ntransmission optimization; in particular, great signal gains, resilience to\nimperfect channel knowledge, and small inter-user interference are all\nachievable without extensive inter-cell coordination. The key to cost-efficient\ndeployment of large arrays is the use of hardware-constrained base stations\nwith low-cost antenna elements, as compared to today's expensive and\npower-hungry BSs. Low-cost transceivers are prone to hardware imperfections,\nbut it has been conjectured that the excessive degrees-of-freedom of massive\nMIMO would bring robustness to such imperfections. We herein prove this claim\nfor an uplink channel with multiplicative phase-drift, additive distortion\nnoise, and noise amplification. Specifically, we derive a closed-form scaling\nlaw that shows how fast the imperfections increase with the number of antennas. \n\n"}
{"id": "1403.5969", "contents": "Title: Random Matrices and Erasure Robust Frames Abstract: Data erasure can often occur in communication. Guarding against erasures\ninvolves redundancy in data representation. Mathematically this may be achieved\nby redundancy through the use of frames. One way to measure the robustness of a\nframe against erasures is to examine the worst case condition number of the\nframe with a certain number of vectors erased from the frame. The term {\\em\nnumerically erasure-robust frames (NERFs)} was introduced in \\cite{FicMix12} to\ngive a more precise characterization of erasure robustness of frames. In the\npaper the authors established that random frames whose entries are drawn\nindependently from the standard normal distribution can be robust against up to\napproximately 15\\% erasures, and asked whether there exist frames that are\nrobust against erasures of more than 50\\%. In this paper we show that with very\nhigh probability random frames are, independent of the dimension, robust\nagainst any amount of erasures as long as the number of remaining vectors is at\nleast $1+\\delta$ times the dimension for some $\\delta_0>0$. This is the best\npossible result, and it also implies that the proportion of erasures can\narbitrarily close to 1 while still maintaining robustness. Our result depends\ncrucially on a new estimate for the smallest singular value of a rectangular\nrandom matrix with independent standard normal entries. \n\n"}
{"id": "1403.6931", "contents": "Title: A New Approach to User Scheduling in Massive Multi-User MIMO Broadcast\n  Channels Abstract: In this paper, a new user-scheduling-and-beamforming method is proposed for\nmulti-user massive multiple-input multiple-output (massive MIMO) broadcast\nchannels in the context of two-stage beamforming. The key ideas of the proposed\nscheduling method are 1) to use a set of orthogonal reference beams and\nconstruct a double cone around each reference beam to select `nearly-optimal'\nsemi-orthogonal users based only on channel quality indicator (CQI) feedback\nand 2) to apply post-user-selection beam refinement with zero-forcing\nbeamforming (ZFBF) based on channel state information (CSI) feedback only from\nthe selected users. It is proved that the proposed scheduling-and-beamforming\nmethod is asymptotically optimal as the number of users increases. Furthermore,\nthe proposed scheduling-and-beamforming method almost achieves the performance\nof the existing semi-orthogonal user selection with ZFBF (SUS-ZFBF) that\nrequires full CSI feedback from all users, with significantly reduced feedback\noverhead which is even less than that required by random beamforming. \n\n"}
{"id": "1403.7720", "contents": "Title: Irregular Fractional Repetition Code Optimization for Heterogeneous\n  Cloud Storage Abstract: This paper presents a flexible irregular model for heterogeneous cloud\nstorage systems and investigates how the cost of repairing failed nodes can be\nminimized. The fractional repetition code, originally designed for minimizing\nrepair bandwidth for homogeneous storage systems, is generalized to the\nirregular fractional repetition code, which is adaptable to heterogeneous\nenvironments. The code structure and the associated storage allocation can be\nobtained by solving an integer linear programming problem. For moderate sized\nnetworks, a heuristic algorithm is proposed and shown to be near-optimal by\ncomputer simulations. \n\n"}
{"id": "1404.0760", "contents": "Title: Information Flow Decomposition in Feedback Systems: General Case Study Abstract: We derive three fundamental decompositions on relevant information quantities\nin feedback systems. The feedback systems considered in this paper are only\nrestricted to be causal in time domain and the channels are allowed to be\nsubject to arbitrary distribution. These decompositions comprise the well-known\nmutual information and the directed information, and indicate a law of\nconservation of information flows in the closed-loop network. \n\n"}
{"id": "1404.3997", "contents": "Title: Lossless Coding of Correlated Sources with Actions Abstract: This work studies the problem of distributed compression of correlated\nsources with an action-dependent joint distribution. This class of problems is,\nin fact, an extension of the Slepian-Wolf model, but where cost-constrained\nactions taken by the encoder or the decoder affect the generation of one of the\nsources. The purpose of this work is to study the implications of actions on\nthe achievable rates.\n  In particular, two cases where transmission occurs over a rate-limited link\nare studied; case A for actions taken at the decoder and case B where actions\nare taken at the encoder. A complete single-letter characterization of the set\nof achievable rates is given in both cases. Furthermore, a network coding setup\nis investigated for the case where actions are taken at the encoder. The\nsources are generated at different nodes of the network and are required at a\nset of terminal nodes, yet transmission occurs over a general, acyclic,\ndirected network. For this setup, generalized cut-set bounds are derived, and a\nfull characterization of the set of achievable rates using single-letter\nexpressions is provided. For this scenario, random linear network coding is\nproved to be optimal, even though this is not a classical multicast problem.\nAdditionally, two binary examples are investigated and demonstrate how actions\ntaken at different nodes of the system have a significant affect on the\nachievable rate region in comparison to a naive time-sharing strategy. \n\n"}
{"id": "1404.4420", "contents": "Title: Random Matrix Systems with Block-Based Behavior and Operator-Valued\n  Models Abstract: A model to estimate the asymptotic isotropic mutual information of a\nmultiantenna channel is considered. Using a block-based dynamics and the angle\ndiversity of the system, we derived what may be thought of as the\noperator-valued version of the Kronecker correlation model. This model turns\nout to be more flexible than the classical version, as it incorporates both an\narbitrary channel correlation and the correlation produced by the asymptotic\nantenna patterns. A method to calculate the asymptotic isotropic mutual\ninformation of the system is established using operator-valued free probability\ntools. A particular case is considered in which we start with explicit Cauchy\ntransforms and all the computations are done with diagonal matrices, which make\nthe implementation simpler and more efficient. \n\n"}
{"id": "1404.5412", "contents": "Title: Analytical Assessment of Coordinated Overlay D2D Communications Abstract: In this paper, analytical assessment of overlay-inband device-to-device (D2D)\ncommunications is investigated, under cellular-network-assisted (coordinated)\nscheduling. To this end, a simple scheduling scheme is assumed that takes into\naccount only local (per cell) topological information of the D2D links.\nStochastic geometry tools are utilized in order to obtain analytical\nexpressions for the interferers density as well as the D2D link\nsignal-to-interference-ratio distribution. The analytical results accuracy is\nvalidated by comparison with simulations. In addition, the analytical\nexpressions are employed for efficiently optimizing the parameters of a\ncellular system with overlay D2D communications. It is shown that coordinated\nscheduling of D2D transmissions enhances system performance both in terms of\naverage user rate as well as maximum allowable D2D link distance. \n\n"}
{"id": "1404.6000", "contents": "Title: Robust and computationally feasible community detection in the presence\n  of arbitrary outlier nodes Abstract: Community detection, which aims to cluster $N$ nodes in a given graph into\n$r$ distinct groups based on the observed undirected edges, is an important\nproblem in network data analysis. In this paper, the popular stochastic block\nmodel (SBM) is extended to the generalized stochastic block model (GSBM) that\nallows for adversarial outlier nodes, which are connected with the other nodes\nin the graph in an arbitrary way. Under this model, we introduce a procedure\nusing convex optimization followed by $k$-means algorithm with $k=r$. Both\ntheoretical and numerical properties of the method are analyzed. A theoretical\nguarantee is given for the procedure to accurately detect the communities with\nsmall misclassification rate under the setting where the number of clusters can\ngrow with $N$. This theoretical result admits to the best-known result in the\nliterature of computationally feasible community detection in SBM without\noutliers. Numerical results show that our method is both computationally fast\nand robust to different kinds of outliers, while some popular computationally\nfast community detection algorithms, such as spectral clustering applied to\nadjacency matrices or graph Laplacians, may fail to retrieve the major clusters\ndue to a small portion of outliers. We apply a slight modification of our\nmethod to a political blogs data set, showing that our method is competent in\npractice and comparable to existing computationally feasible methods in the\nliterature. To the best of the authors' knowledge, our result is the first in\nthe literature in terms of clustering communities with fast growing numbers\nunder the GSBM where a portion of arbitrary outlier nodes exist. \n\n"}
{"id": "1404.6512", "contents": "Title: Cellular Interference Alignment: Omni-Directional Antennas and\n  Asymmetric Configurations Abstract: Although interference alignment (IA) can theoretically achieve the optimal\ndegrees of freedom (DoFs) in the $K$-user Gaussian interference channel, its\ndirect application comes at the prohibitive cost of precoding over\nexponentially-many signaling dimensions. On the other hand, it is known that\npractical \"one-shot\" IA precoding (i.e., linear schemes without symbol\nexpansion) provides a vanishing DoFs gain in large fully-connected networks\nwith generic channel coefficients. In our previous work, we introduced the\nconcept of \"Cellular IA\" for a network topology induced by hexagonal cells with\nsectors and nearest-neighbor interference. Assuming that neighboring sectors\ncan exchange decoded messages (and not received signal samples) in the uplink,\nwe showed that linear one-shot IA precoding over $M$ transmit/receive antennas\ncan achieve the optimal $M/2$ DoFs per user. In this paper we extend this\nframework to networks with omni-directional (non-sectorized) cells and consider\nthe practical scenario where users have $2$ antennas, and base-stations have\n$2$, $3$ or $4$ antennas. In particular, we provide linear one-shot IA schemes\nfor the $2\\times 2$, $2\\times3$ and $2\\times 4$ cases, and show the\nachievability of $3/4$, $1$ and $7/6$ DoFs per user, respectively. DoFs\nconverses for one-shot schemes require the solution of a discrete optimization\nproblem over a number of variables that grows with the network size. We develop\na new approach to transform such challenging optimization problem into a\ntractable linear program (LP) with significantly fewer variables. This approach\nis used to show that the achievable $3/4$ DoFs per user are indeed optimal for\na large (extended) cellular network with $2\\times 2$ links. \n\n"}
{"id": "1405.0931", "contents": "Title: Universal Memcomputing Machines Abstract: We introduce the notion of universal memcomputing machines (UMMs): a class of\nbrain-inspired general-purpose computing machines based on systems with memory,\nwhereby processing and storing of information occur on the same physical\nlocation. We analytically prove that the memory properties of UMMs endow them\nwith universal computing power - they are Turing-complete -, intrinsic\nparallelism, functional polymorphism, and information overhead, namely their\ncollective states can support exponential data compression directly in memory.\nWe also demonstrate that a UMM has the same computational power as a\nnon-deterministic Turing machine, namely it can solve NP--complete problems in\npolynomial time. However, by virtue of its information overhead, a UMM needs\nonly an amount of memory cells (memprocessors) that grows polynomially with the\nproblem size. As an example we provide the polynomial-time solution of the\nsubset-sum problem and a simple hardware implementation of the same. Even\nthough these results do not prove the statement NP=P within the Turing\nparadigm, the practical realization of these UMMs would represent a paradigm\nshift from present von Neumann architectures bringing us closer to brain-like\nneural computation. \n\n"}
{"id": "1405.1143", "contents": "Title: Approximate Capacity Region of the Two-User MISO Broadcast Channels with\n  Delayed CSIT Abstract: We consider the problem of multiple-input single-output Broadcast Channels\nwith Rayleigh fading where the transmitter has access to delayed knowledge of\nthe channel state information. We first characterize the capacity region of\nthis channel with two users to within constant number of bits for all values of\nthe transmit power. The proposed signaling strategy utilizes the delayed\nknowledge of the channel state information and the previously transmitted\nsignals, in order to create a signal of common interest for both receivers.\nThis signal would be the quantized version of the summation of the previously\ntransmitted signals. A challenge that arises in deriving the result for finite\nsignal-to-noise ratio regimes is the correlation that exists between the\nquantization noise and the signal. To guarantee the independence of\nquantization noise and signal, we extend the framework of lattice quantizers\nwith dither together with an interleaving step. For converse, we use the fact\nthat the capacity region of this problem is upper-bounded by the capacity\nregion of a physically degraded broadcast channel with no channel state\ninformation where one receiver has two antennas. Then, we derive an outer-bound\non the capacity region of this degraded broadcast channel. Finally, we show how\nto extend our results to obtain the approximate capacity of the $K$-user\nmultiple-input single-output Broadcast Channel with delayed knowledge of the\nchannel state information at the transmitter to within $2 \\log_2 \\left( K + 2\n\\right)$ bits/s/Hz. \n\n"}
{"id": "1405.1773", "contents": "Title: On Tensor Completion via Nuclear Norm Minimization Abstract: Many problems can be formulated as recovering a low-rank tensor. Although an\nincreasingly common task, tensor recovery remains a challenging problem because\nof the delicacy associated with the decomposition of higher order tensors. To\novercome these difficulties, existing approaches often proceed by unfolding\ntensors into matrices and then apply techniques for matrix completion. We show\nhere that such matricization fails to exploit the tensor structure and may lead\nto suboptimal procedure. More specifically, we investigate a convex\noptimization approach to tensor completion by directly minimizing a tensor\nnuclear norm and prove that this leads to an improved sample size requirement.\nTo establish our results, we develop a series of algebraic and probabilistic\ntechniques such as characterization of subdifferetial for tensor nuclear norm\nand concentration inequalities for tensor martingales, which may be of\nindependent interests and could be useful in other tensor related problems. \n\n"}
{"id": "1405.4098", "contents": "Title: Optimal Index Policies for Anomaly Localization in Resource-Constrained\n  Cyber Systems Abstract: The problem of anomaly localization in a resource-constrained cyber system is\nconsidered. Each anomalous component of the system incurs a cost per unit time\nuntil its anomaly is identified and fixed. Different anomalous components may\nincur different costs depending on their criticality to the system. Due to\nresource constraints, only one component can be probed at each given time. The\nobservations from a probed component are realizations drawn from two different\ndistributions depending on whether the component is normal or anomalous. The\nobjective is a probing strategy that minimizes the total expected cost,\nincurred by all the components during the detection process, under reliability\nconstraints. We consider both independent and exclusive models. In the former,\neach component can be abnormal with a certain probability independent of other\ncomponents. In the latter, one and only one component is abnormal. We develop\noptimal simple index policies under both models. The proposed index policies\napply to a more general case where a subset (more than one) of the components\ncan be probed simultaneously and have strong performance as demonstrated by\nsimulation examples. The problem under study also finds applications in\nspectrum scanning in cognitive radio networks and event detection in sensor\nnetworks. \n\n"}
{"id": "1405.4608", "contents": "Title: Two-Tier Precoding for FDD Multi-cell Massive MIMO Time-Varying\n  Interference Networks (Full Version) Abstract: Massive MIMO is a promising technology in future wireless communication\nnetworks. However, it raises a lot of implementation challenges, for example,\nthe huge pilot symbols and feedback overhead, requirement of real-time global\nCSI, large number of RF chains needed and high computational complexity. We\nconsider a two-tier precoding strategy for multi-cell massive MIMO interference\nnetworks, with an outer precoder for inter-cell/inter-cluster interference\ncancellation, and an inner precoder for intra-cell multiplexing. In particular,\nto combat with the computational complexity issue of the outer precoding, we\npropose a low complexity online iterative algorithm to track the outer precoder\nunder time-varying channels. We follow an optimization technique and formulate\nthe problem on the Grassmann manifold. We develop a low complexity iterative\nalgorithm, which converges to the global optimal solution under static\nchannels. In time-varying channels, we propose a compensation technique to\noffset the variation of the time-varying optimal solution. We show with our\ntheoretical result that, under some mild conditions, perfect tracking of the\ntarget outer precoder using the proposed algorithm is possible. Numerical\nresults demonstrate that the two-tier precoding with the proposed iterative\ncompensation algorithm can achieve a good performance with a significant\ncomplexity reduction compared with the conventional two-tier precoding\ntechniques in the literature. \n\n"}
{"id": "1405.4623", "contents": "Title: Training-Based SWIPT: Optimal Power Splitting at the Receiver Abstract: We consider a point-to-point system with simultaneous wireless information\nand power transfer (SWIPT) over a block fading channel. Each transmission block\nconsists of a training phase and a data transmission phase. Pilot symbols are\ntransmitted during the training phase for channel estimation at the receiver.\nTo enable SWIPT, the receiver adopts a power-splitting design, such that a\nportion of the received signal is used for channel estimation or data\ndetection, while the remaining is used for energy harvesting. We optimally\ndesign the power-splitting ratios for both training and data phases to achieve\nthe best ergodic capacity performance while maintaining a required energy\nharvesting rate. Our result shows how a power-splitting receiver can make the\nbest use of the received pilot and data signals to obtain the optimal SWIPT\nperformance. \n\n"}
{"id": "1405.4957", "contents": "Title: Symbol-Based Successive Cancellation List Decoder for Polar Codes Abstract: Polar codes is promising because they can provably achieve the channel\ncapacity while having an explicit construction method. Lots of work have been\ndone for the bit-based decoding algorithm for polar codes. In this paper,\ngeneralized symbol-based successive cancellation (SC) and SC list decoding\nalgorithms are discussed. A symbol-based recursive channel combination\nrelationship is proposed to calculate the symbol-based channel transition\nprobability. This proposed method needs less additions than the\nmaximum-likelihood decoder used by the existing symbol-based polar decoding\nalgorithm. In addition, a two-stage list pruning network is proposed to\nsimplify the list pruning network for the symbol-based SC list decoding\nalgorithm. \n\n"}
{"id": "1405.5083", "contents": "Title: On State Dependent Broadcast Channels with Cooperation Abstract: In this paper, we investigate problems of communication over physically\ndegraded, state-dependent broadcast channels (BCs) with cooperating decoders.\nTwo different setups are considered and their capacity regions are\ncharacterized. First, we study a setting in which one decoder can use a finite\ncapacity link to send the other decoder information regarding the messages or\nthe channel states. In this scenario we analyze two cases: one where noncausal\nstate information is available to the encoder and the strong decoder and the\nother where state information is available only to the encoder in a causal\nmanner. Second, we examine a setting in which the cooperation between the\ndecoders is limited to taking place before the outputs of the channel are\ngiven. In this case, one decoder, which is informed of the state sequence\nnoncausally, can cooperate only to send the other decoder rate-limited\ninformation about the state sequence. The proofs of the capacity regions\nintroduce a new method of coding for channels with cooperation between\ndifferent users, where we exploit the link between the decoders for\nmultiple-binning. Finally, we discuss the optimality of using rate splitting\ntechniques when coding for cooperative BCs. In particular, we show that rate\nsplitting is not necessarily optimal when coding for cooperative BCs by solving\nan example in which our method of coding outperforms rate splitting. \n\n"}
{"id": "1405.6157", "contents": "Title: Fractional Repetition and Erasure Batch Codes Abstract: Batch codes are a family of codes that represent a distributed storage system\n(DSS) of $n$ nodes so that any batch of $t$ data symbols can be retrieved by\nreading at most one symbol from each node. Fractional repetition codes are a\nfamily of codes for DSS that enable efficient uncoded repairs of failed nodes.\nIn this work these two families of codes are combined to obtain fractional\nrepetition batch (FRB) codes which provide both uncoded repairs and parallel\nreads of subsets of stored symbols. In addition, new batch codes which can\ntolerate node failures are considered. This new family of batch codes is called\nerasure combinatorial batch codes (ECBCs). Some properties of FRB codes and\nECBCs and examples of their constructions based on transversal designs and\naffine planes are presented. \n\n"}
{"id": "1405.6286", "contents": "Title: Exploiting User Mobility for Wireless Content Delivery Abstract: We consider the problem of storing segments of encoded versions of content\nfiles in a set of base stations located in a communication cell. These base\nstations work in conjunction with the main base station of the cell. Users move\nrandomly across the space based on a discrete-time Markov chain model. At each\ntime slot each user accesses a single base station based on it's current\nposition and it can download only a part of the content stored in it, depending\non the time slot duration. We assume that file requests must be satisfied\nwithin a given time deadline in order to be successful. If the amount of the\ndownloaded (encoded) data by the accessed base stations when the time deadline\nexpires does not suffice to recover the requested file, the main base station\nof the cell serves the request. Our aim is to find the storage allocation that\nminimizes the probability of using the main base station for file delivery.\nThis problem is intractable in general. However, we show that the optimal\nsolution of the problem can be efficiently attained in case that the time\ndeadline is small. To tackle the general case, we propose a distributed\napproximation algorithm based on large deviation inequalities. Systematic\nexperiments on a real world data set demonstrate the effectiveness of our\nproposed algorithms. Index Terms: Mobility-aware Caching, Markov Chain, MDS\nCoding, Small-cell Networks \n\n"}
{"id": "1406.2255", "contents": "Title: Energy-Efficient Cooperative Cognitive Relaying Schemes for Cognitive\n  Radio Networks Abstract: We investigate a cognitive radio network in which a primary user (PU) may\ncooperate with a cognitive radio user (i.e., a secondary user (SU)) for\ntransmissions of its data packets. The PU is assumed to be a buffered node\noperating in a time-slotted fashion where the time is partitioned into\nequal-length slots. We develop two schemes which involve cooperation between\nprimary and secondary users. To satisfy certain quality of service (QoS)\nrequirements, users share time slot duration and channel frequency bandwidth.\nMoreover, the SU may leverage the primary feedback message to further increase\nboth its data rate and satisfy the PU QoS requirements. The proposed\ncooperative schemes are designed such that the SU data rate is maximized under\nthe constraint that the PU average queueing delay is maintained less than the\naverage queueing delay in case of non-cooperative PU. In addition, the proposed\nschemes guarantee the stability of the PU queue and maintain the average energy\nemitted by the SU below a certain value. The proposed schemes also provide more\nrobust and potentially continuous service for SUs compared to the conventional\npractice in cognitive networks where SUs transmit in the spectrum holes and\nsilence sessions of the PUs. We include primary source burstiness, sensing\nerrors, and feedback decoding errors to the analysis of our proposed\ncooperative schemes. The optimization problems are solved offline and require a\nsimple 2-dimensional grid-based search over the optimization variables.\nNumerical results show the beneficial gains of the cooperative schemes in terms\nof SU data rate and PU throughput, average PU queueing delay, and average PU\nenergy savings. \n\n"}
{"id": "1406.2738", "contents": "Title: Wireless Backhaul Networks: Capacity Bound, Scalability Analysis and\n  Design Guidelines Abstract: This paper studies the scalability of a wireless backhaul network modeled as\na random extended network with multi-antenna base stations (BSs), where the\nnumber of antennas per BS is allowed to scale as a function of the network\nsize. The antenna scaling is justified by the current trend towards the use of\nhigher carrier frequencies, which allows to pack large number of antennas in\nsmall form factors. The main goal is to study the per-BS antenna requirement\nthat ensures scalability of this network, i.e., its ability to deliver\nnon-vanishing rate to each source-destination pair. We first derive an\ninformation theoretic upper bound on the capacity of this network under a\ngeneral propagation model, which provides a lower bound on the per-BS antenna\nrequirement. Then, we characterize the scalability requirements for two\ncompeting strategies of interest: (i) long hop: each source-destination pair\nminimizes the number of hops by sacrificing multiplexing gain while achieving\nfull beamforming (power) gain over each hop, and (ii) short hop: each\nsource-destination pair communicates through a series of short hops, each\nachieving full multiplexing gain. While long hop may seem more intuitive in the\ncontext of massive multiple-input multiple-output (MIMO) transmission, we show\nthat the short hop strategy is significantly more efficient in terms of per-BS\nantenna requirement for throughput scalability. As a part of the proof, we\nconstruct a scalable short hop strategy and show that it does not violate any\nfundamental limits on the spatial degrees of freedom (DoFs). \n\n"}
{"id": "1406.3454", "contents": "Title: The Degrees-of-Freedom of Multi-way Device-to-Device Communications is\n  Limited by 2 Abstract: A 3-user device-to-device (D2D) communications scenario is studied where each\nuser wants to send and receive a message from each other user. This scenario\nresembles a 3-way communication channel. The capacity of this channel is\nunknown in general. In this paper, a sum-capacity upper bound that\ncharacterizes the degrees-of-freedom of the channel is derived by using\ngenie-aided arguments. It is further shown that the derived upper bound is\nachievable within a gap of 2 bits, thus leading to an approximate sum-capacity\ncharacterization for the 3-way channel. As a by-product, interesting analogies\nbetween multi-way communications and multi-way relay communications are\nconcluded. \n\n"}
{"id": "1406.4178", "contents": "Title: On asymptotic structure in compressed sensing Abstract: This paper demonstrates how new principles of compressed sensing, namely\nasymptotic incoherence, asymptotic sparsity and multilevel sampling, can be\nutilised to better understand underlying phenomena in practical compressed\nsensing and improve results in real-world applications. The contribution of the\npaper is fourfold:\n  First, it explains how the sampling strategy depends not only on the signal\nsparsity but also on its structure, and shows how to design effective sampling\nstrategies utilising this.\n  Second, it demonstrates that the optimal sampling strategy and the efficiency\nof compressed sensing also depends on the resolution of the problem, and shows\nhow this phenomenon markedly affects compressed sensing results and how to\nexploit it.\n  Third, as the new framework also fits analog (infinite dimensional) models\nthat govern many inverse problems in practice, the paper describes how it can\nbe used to yield substantial improvements.\n  Fourth, by using multilevel sampling, which exploits the structure of the\nsignal, the paper explains how one can outperform random Gaussian/Bernoulli\nsampling even when the classical $l^1$ recovery algorithm is replaced by\nmodified algorithms which aim to exploit structure such as model based or\nBayesian compressed sensing or approximate message passaging. This final\nobservation raises the question whether universality is desirable even when\nsuch matrices are applicable.\n  Examples of practical applications investigated in this paper include\nMagnetic Resonance Imaging (MRI), Electron Microscopy (EM), Compressive Imaging\n(CI) and Fluorescence Microscopy (FM). For the latter, a new compressed sensing\napproach is also presented. \n\n"}
{"id": "1406.5988", "contents": "Title: Large System Analysis of the Energy Consumption Distribution in\n  Multi-User MIMO Systems with Mobility Abstract: In this work, we consider the downlink of a single-cell multi-user MIMO\nsystem in which the base station (BS) makes use of $N$ antennas to communicate\nwith $K$ single-antenna user equipments (UEs). The UEs move around in the cell\naccording to a random walk mobility model. We aim at determining the energy\nconsumption distribution when different linear precoding techniques are used at\nthe BS to guarantee target rates within a finite time interval $T$. The\nanalysis is conducted in the asymptotic regime where $N$ and $K$ grow large\nwith fixed ratio under the assumption of perfect channel state information\n(CSI). Both recent and standard results from large system analysis are used to\nprovide concise formulae for the asymptotic transmit powers and beamforming\nvectors for all considered schemes. These results are eventually used to\nprovide a deterministic approximation of the energy consumption and to study\nits fluctuations around this value in the form of a central limit theorem.\nClosed-form expressions for the asymptotic means and variances are given.\nNumerical results are used to validate the accuracy of the theoretical analysis\nand to make comparisons. We show how the results can be used to approximate the\nprobability that a battery-powered BS runs out of energy and also to design the\ncell radius for minimizing the energy consumption per unit area. The imperfect\nCSI case is also briefly considered. \n\n"}
{"id": "1407.1497", "contents": "Title: Content-Aware Network Coding over Device-to-Device Networks Abstract: Consider a scenario of broadcasting a common content to a group of\ncooperating mobile devices that are within proximity of each other. Devices in\nthis group may receive partial content from the source due to packet losses\nover wireless broadcast links. We further consider that packet losses are\ndifferent for different devices. The remaining missing content at each device\ncan then be recovered, thanks to cooperation among the devices by exploiting\ndevice-to-device (D2D) connections. In this context, the minimum amount of time\nthat can guarantee a complete acquisition of the common content at every device\nis referred to as the \"completion time\". It has been shown that instantly\ndecodable network coding (IDNC) reduces the completion time as compared to no\nnetwork coding in this scenario. Yet, for applications such as video streaming,\nnot all packets have the same importance and not all devices are interested in\nthe same quality of content. This problem is even more interesting when\nadditional, but realistic constraints, such as strict deadline, bandwidth, or\nlimited energy are added in the problem formulation. We assert that direct\napplication of IDNC in such a scenario yields poor performance in terms of\ncontent quality and completion time. In this paper, we propose a novel Content\nand Loss-Aware IDNC scheme that improves content quality and network coding\nopportunities jointly by taking into account importance of each packet towards\nthe desired quality of service (QoS) as well as the channel losses over D2D\nlinks. Our proposed Content and Loss-Aware IDNC (i) maximizes the quality under\nthe completion time constraint, and (ii) minimizes the completion time under\nthe quality constraint. We demonstrate the benefits of Content and Loss-Aware\nIDNC through simulations. \n\n"}
{"id": "1407.2283", "contents": "Title: Optimal Nested Test Plan for Combinatorial Quantitative Group Testing Abstract: We consider the quantitative group testing problem where the objective is to\nidentify defective items in a given population based on results of tests\nperformed on subsets of the population. Under the quantitative group testing\nmodel, the result of each test reveals the number of defective items in the\ntested group. The minimum number of tests achievable by nested test plans was\nestablished by Aigner and Schughart in 1985 within a minimax framework. The\noptimal nested test plan offering this performance, however, was not obtained.\nIn this work, we establish the optimal nested test plan in closed form. This\noptimal nested test plan is also order optimal among all test plans as the\npopulation size approaches infinity. Using heavy-hitter detection as a case\nstudy, we show via simulation examples orders of magnitude improvement of the\ngroup testing approach over two prevailing sampling-based approaches in\ndetection accuracy and counter consumption. Other applications include anomaly\ndetection and wideband spectrum sensing in cognitive radio systems. \n\n"}
{"id": "1407.3257", "contents": "Title: Demystifying the Information Reconciliation Protocol Cascade Abstract: Cascade is an information reconciliation protocol proposed in the context of\nsecret key agreement in quantum cryptography. This protocol allows removing\ndiscrepancies in two partially correlated sequences that belong to distant\nparties, connected through a public noiseless channel. It is highly\ninteractive, thus requiring a large number of channel communications between\nthe parties to proceed and, although its efficiency is not optimal, it has\nbecome the de-facto standard for practical implementations of information\nreconciliation in quantum key distribution. The aim of this work is to analyze\nthe performance of Cascade, to discuss its strengths, weaknesses and\noptimization possibilities, comparing with some of the modified versions that\nhave been proposed in the literature. When looking at all design trade-offs, a\nnew view emerges that allows to put forward a number of guidelines and propose\nnear optimal parameters for the practical implementation of Cascade improving\nperformance significantly in comparison with all previous proposals. \n\n"}
{"id": "1407.5716", "contents": "Title: Massive-MIMO Meets HetNet: Interference Coordination Through Spatial\n  Blanking Abstract: In this paper, we study the downlink performance of a heterogeneous cellular\nnetwork (HetNet) where both macro and small cells share the same spectrum and\nhence interfere with each other. We assume that the users are concentrated at\ncertain areas in the cell, i.e., they form hotspots. While some of the hotspots\nare assumed to have a small cell in their vicinity, the others are directly\nserved by the macrocell. Due to a relatively small area of each hotspot, the\nusers lying in a particular hotspot appear to be almost co-located to the\nmacrocells, which are typically deployed at some elevation. Assuming large\nnumber of antennas at the macrocell, we exploit this directionality in the\nchannel vectors to obtain spatial blanking, i.e., concentrating transmission\nenergy only in certain directions while creating transmission opportunities for\nthe small cells lying in the other directions. In addition to this inherent\ninterference suppression, we also develop three low-complexity interference\ncoordination strategies: (i) turn off small cells based on the amount of\ncross-tier interference they receive or cause to the scheduled macrocell\nhotspots, (ii) schedule hotspots such that treating interference as noise is\napproximately optimal for the resulting Gaussian interference channel, and\n(iii) offload some of the macrocell hotspots to nearby small cells in order to\nimprove throughput fairness across all hotspots. For all these schemes, we\nstudy the relative merits and demerits of uniform deployment of small cells vs.\ndeploying more small cells towards the cell center or the cell edge. \n\n"}
{"id": "1407.6481", "contents": "Title: Interference Management in 5G Reverse TDD HetNets with Wireless\n  Backhaul: A Large System Analysis Abstract: This work analyzes a heterogeneous network (HetNet), which comprises a macro\nbase station (BS) equipped with a large number of antennas and an overlaid\ndense tier of small cell access points (SCAs) using a wireless backhaul for\ndata traffic. The static and low mobility user equipment terminals (UEs) are\nassociated with the SCAs while those with medium-to-high mobility are served by\nthe macro BS. A reverse time division duplexing (TDD) protocol is used by the\ntwo tiers, which allows the BS to locally estimate both the intra-tier and\ninter-tier channels. This knowledge is then used at the BS either in the uplink\n(UL) or in the downlink (DL) to simultaneously serve the macro UEs (MUEs) and\nto provide the wireless backhaul to SCAs. A geographical separation of\nco-channel SCAs is proposed to limit the interference coming from the UL\nsignals of MUEs. A concatenated linear precoding technique employing either\nzero-forcing (ZF) or regularized ZF is used at the BS to simultaneously serve\nMUEs and SCAs in DL while nulling interference toward those SCAs in UL. We\nevaluate and characterize the performance of the system through the power\nconsumption of UL and DL transmissions under the assumption that target rates\nmust be satisfied and imperfect channel state information is available for\nMUEs. The analysis is conducted in the asymptotic regime where the number of BS\nantennas and the network size (MUEs and SCAs) grow large with fixed ratios.\nResults from large system analysis are used to provide concise formulae for the\nasymptotic UL and DL transmit powers and precoding vectors under the above\nassumptions. Numerical results are used to validate the analysis in different\nsettings and to make comparisons with alternative network architectures. \n\n"}
{"id": "1407.7267", "contents": "Title: On Spectrum Sharing Between Energy Harvesting Cognitive Radio Users and\n  Primary Users Abstract: This paper investigates the maximum secondary throughput for a rechargeable\nsecondary user (SU) sharing the spectrum with a primary user (PU) plugged to a\nreliable power supply. The SU maintains a finite energy queue and harvests\nenergy from natural resources and primary radio frequency (RF) transmissions.\nWe propose a power allocation policy at the PU and analyze its effect on the\nthroughput of both the PU and SU. Furthermore, we study the impact of the\nbursty arrivals at the PU on the energy harvested by the SU from RF\ntransmissions. Moreover, we investigate the impact of the rate of energy\nharvesting from natural resources on the SU throughput. We assume fading\nchannels and compute exact closed-form expressions for the energy harvested by\nthe SU under fading. Results reveal that the proposed power allocation policy\nalong with the implemented RF energy harvesting at the SU enhance the\nthroughput of both primary and secondary links. \n\n"}
{"id": "1407.8409", "contents": "Title: Joint Network and Gelfand-Pinsker Coding for 3-Receiver Gaussian\n  Broadcast Channels with Receiver Message Side Information Abstract: The problem of characterizing the capacity region for Gaussian broadcast\nchannels with receiver message side information appears difficult and remains\nopen for N >= 3 receivers. This paper proposes a joint network and\nGelfand-Pinsker coding method for 3-receiver cases. Using the method, we\nestablish a unified inner bound on the capacity region of 3-receiver Gaussian\nbroadcast channels under general message side information configuration. The\nachievability proof of the inner bound uses an idea of joint interference\ncancelation, where interference is canceled by using both dirty-paper coding at\nthe encoder and successive decoding at some of the decoders. We show that the\ninner bound is larger than that achieved by state of the art coding schemes. An\nouter bound is also established and shown to be tight in 46 out of all 64\npossible cases. \n\n"}
{"id": "1408.3469", "contents": "Title: Properties of an Aloha-like stability region Abstract: A well-known inner bound on the stability region of the finite-user slotted\nAloha protocol is the set of all arrival rates for which there exists some\nchoice of the contention probabilities such that the associated worst-case\nservice rate for each user exceeds the user's arrival rate, denoted $\\Lambda$.\nAlthough testing membership in $\\Lambda$ of a given arrival rate can be posed\nas a convex program, it is nonetheless of interest to understand the properties\nof this set. In this paper we develop new results of this nature, including\n$i)$ an equivalence between membership in $\\Lambda$ and the existence of a\npositive root of a given polynomial, $ii)$ a method to construct a vector of\ncontention probabilities to stabilize any stabilizable arrival rate vector,\n$iii)$ the volume of $\\Lambda$, $iv)$ explicit polyhedral, spherical, and\nellipsoid inner and outer bounds on $\\Lambda$, and $v)$ characterization of the\ngeneralized convexity properties of a natural ``excess rate'' function\nassociated with $\\Lambda$, including the convexity of the set of contention\nprobabilities that stabilize a given arrival rate vector. \n\n"}
{"id": "1408.3661", "contents": "Title: Overhead Performance Tradeoffs - A Resource Allocation Perspective Abstract: A key aspect of many resource allocation problems is the need for the\nresource controller to compute a function, such as the max or arg max, of the\ncompeting users metrics. Information must be exchanged between the competing\nusers and the resource controller in order for this function to be computed. In\nmany practical resource controllers the competing users' metrics are\ncommunicated to the resource controller, which then computes the desired\nextremization function. However, in this paper it is shown that information\nrate savings can be obtained by recognizing that controller only needs to\ndetermine the result of this extremization function. If the extremization\nfunction is to be computed losslessly, the rate savings are shown in most cases\nto be at most 2 bits independent of the number of competing users. Motivated by\nthe small savings in the lossless case, simple achievable schemes for both the\nlossy and interactive variants of this problem are considered. It is shown that\nboth of these approaches have the potential to realize large rate savings,\nespecially in the case where the number of competing users is large. For the\nlossy variant, it is shown that the proposed simple achievable schemes are in\nfact close to the fundamental limit given by the rate distortion function. \n\n"}
{"id": "1408.5971", "contents": "Title: A Dichotomy of Functions in Distributed Coding: An Information Spectral\n  Approach Abstract: The problem of distributed data compression for function computation is\nconsidered, where (i) the function to be computed is not necessarily\nsymbol-wise function and (ii) the information source has memory and may not be\nstationary nor ergodic. We introduce the class of smooth sources and give a\nsufficient condition on functions so that the achievable rate region for\ncomputing coincides with the Slepian-Wolf region (i.e., the rate region for\nreproducing the entire source) for any smooth sources. Moreover, for\nsymbol-wise functions, the necessary and sufficient condition for the\ncoincidence is established. Our result for the full side-information case is a\ngeneralization of the result by Ahlswede and Csiszar to sources with memory;\nour dichotomy theorem is different from Han and Kobayashi's dichotomy theorem,\nwhich reveals an effect of memory in distributed function computation. All\nresults are given not only for fixed-length coding but also for variable-length\ncoding in a unified manner. Furthermore, for the full side-information case,\nthe error probability in the moderate deviation regime is also investigated. \n\n"}
{"id": "1409.0979", "contents": "Title: Inter-session Network Coding for Transmitting Multiple Layered Streams\n  over Single-hop Wireless Networks Abstract: This paper studies the problem of transmitting multiple independent layered\nvideo streams over single-hop wireless networks using network coding (NC). We\ncombine feedback-free random linear NC (RLNC) with unequal error protection\n(UEP) and our goal is to investigate the benefits of coding across streams,\ni.e. inter session NC. To this end, we present a transmission scheme that in\naddition to mixing packets of different layers of each stream (intra-session\nNC), mixes packets of different streams as well. Then, we propose the\nanalytical formulation of the layer decoding probabilities for each user and\nutilize it to define a theoretical performance metric. Assessing this\nperformance metric under various scenarios, it is observed that inter-session\nNC improves the trade-off among the performances of users. Furthermore, the\nanalytical results show that the throughput gain of inter-session NC over\nintra-session NC increases with the number of independent streams and also by\nincreasing packet error rate, but degrades as network becomes more\nheterogeneous. \n\n"}
{"id": "1409.4338", "contents": "Title: Smooth Entropy Bounds on One-Shot Quantum State Redistribution Abstract: In quantum state redistribution as introduced in [Luo and Devetak (2009)] and\n[Devetak and Yard (2008)], there are four systems of interest: the $A$ system\nheld by Alice, the $B$ system held by Bob, the $C$ system that is to be\ntransmitted from Alice to Bob, and the $R$ system that holds a purification of\nthe state in the $ABC$ registers. We give upper and lower bounds on the amount\nof quantum communication and entanglement required to perform the task of\nquantum state redistribution in a one-shot setting. Our bounds are in terms of\nthe smooth conditional min- and max-entropy, and the smooth max-information.\nThe protocol for the upper bound has a clear structure, building on the work\n[Oppenheim (2008)]: it decomposes the quantum state redistribution task into\ntwo simpler quantum state merging tasks by introducing a coherent relay. In the\nindependent and identical (iid) asymptotic limit our bounds for the quantum\ncommunication cost converge to the quantum conditional mutual information\n$I(C:R|B)$, and our bounds for the total cost converge to the conditional\nentropy $H(C|B)$. This yields an alternative proof of optimality of these rates\nfor quantum state redistribution in the iid asymptotic limit. In particular, we\nobtain a strong converse for quantum state redistribution, which even holds\nwhen allowing for feedback. \n\n"}
{"id": "1409.4979", "contents": "Title: Tracy-Widom Distribution for the Largest Eigenvalue of Real Sample\n  Covariance Matrices with General Population Abstract: We consider sample covariance matrices of the form\n$\\mathcal{Q}=(\\Sigma^{1/2}X)(\\Sigma^{1/2} X)^*$, where the sample $X$ is an\n$M\\times N$ random matrix whose entries are real independent random variables\nwith variance $1/N$ and where $\\Sigma$ is an $M\\times M$ positive-definite\ndeterministic matrix. We analyze the asymptotic fluctuations of the largest\nrescaled eigenvalue of $\\mathcal{Q}$ when both $M$ and $N$ tend to infinity\nwith $N/M\\to d\\in(0,\\infty)$. For a large class of populations $\\Sigma$ in the\nsub-critical regime, we show that the distribution of the largest rescaled\neigenvalue of $\\mathcal{Q}$ is given by the type-1 Tracy-Widom distribution\nunder the additional assumptions that (1) either the entries of $X$ are i.i.d.\nGaussians or (2) that $\\Sigma$ is diagonal and that the entries of $X$ have a\nsubexponential decay. \n\n"}
{"id": "1409.5505", "contents": "Title: Low-Dimensional Topology of Information Fusion Abstract: We provide an axiomatic characterization of information fusion, on the basis\nof which we define an information fusion network. Our construction is\nreminiscent of tangle diagrams in low dimensional topology. Information fusion\nnetworks come equipped with a natural notion of equivalence. Equivalent\nnetworks `contain the same information', but differ locally. When fusing\nstreams of information, an information fusion network may adaptively optimize\nitself inside its equivalence class. This provides a fault tolerance mechanism\nfor such networks. \n\n"}
{"id": "1409.7433", "contents": "Title: Throughput Analysis for Wireless Networks with Full-Duplex Radios Abstract: This paper investigates the throughput for wireless network with full-duplex\nradios using stochastic geometry. Full-duplex (FD) radios can exchange data\nsimultaneously with each other. On the other hand, the downside of FD\ntransmission is that it will inevitably cause extra interference to the network\ncompared to half-duplex (HD) transmission. In this paper, we focus on a\nwireless network of nodes with both HD and FD capabilities and derive and\noptimize the throughput in such a network. Our analytical result shows that if\nthe network is adapting an ALOHA protocol, the maximal throughput is always\nachieved by scheduling all concurrently transmitting nodes to work in FD mode\ninstead of a mixed FD/HD mode or HD mode regardless of the network\nconfigurations. Moreover, the throughput gain of using FD transmission over HD\ntransmission is analytically lower and upper bounded. \n\n"}
{"id": "1409.7551", "contents": "Title: Algorithms for Stochastic Games on Interference Channels Abstract: We consider a wireless channel shared by multiple transmitter-receiver pairs.\nTheir transmissions interfere with each other. Each transmitter-receiver pair\naims to maximize its long-term average transmission rate subject to an average\npower constraint. This scenario is modeled as a stochastic game. We provide\nsufficient conditions for existence and uniqueness of a Nash equilibrium (NE).\nWe then formulate the problem of finding NE as a variational inequality (VI)\nproblem and present an algorithm to solve the VI using regularization. We also\nprovide distributed algorithms to compute Pareto optimal solutions for the\nproposed game. \n\n"}
{"id": "1410.4252", "contents": "Title: Joint Channel Parameter Estimation via Diffusive Molecular Communication Abstract: The design and analysis of diffusive molecular communication systems\ngenerally requires knowledge of the environment's physical and chemical\nproperties. Furthermore, prospective applications might rely on the timely\ndetection of changes in the local system parameters. This paper studies the\nlocal estimation of channel parameters for diffusive molecular communication\nwhen a transmitter releases molecules that are observed by a receiver. The\nFisher information matrix of the joint parameter estimation problem is derived\nso that the Cramer-Rao lower bound on the variance of locally unbiased\nestimation can be found. The joint estimation problem can be reduced to the\nestimation of any subset of the channel parameters. Maximum likelihood\nestimation leads to closed-form solutions for some single-parameter estimation\nproblems and can otherwise be determined numerically. Peak-based estimators are\nproposed for low-complexity estimation of a single unknown parameter. \n\n"}
{"id": "1410.5028", "contents": "Title: Diffraction Patterns of Layered Close-packed Structures from Hidden\n  Markov Models Abstract: We recently derived analytical expressions for the pairwise (auto)correlation\nfunctions (CFs) between modular layers (MLs) in close-packed structures (CPSs)\nfor the wide class of stacking processes describable as hidden Markov models\n(HMMs) [Riechers \\etal, (2014), Acta Crystallogr.~A, XX 000-000]. We now use\nthese results to calculate diffraction patterns (DPs) directly from HMMs,\ndiscovering that the relationship between the HMMs and DPs is both simple and\nfundamental in nature. We show that in the limit of large crystals, the DP is a\nfunction of parameters that specify the HMM. We give three elementary but\nimportant examples that demonstrate this result, deriving expressions for the\nDP of CPSs stacked (i) independently, (ii) as infinite-Markov-order randomly\nfaulted 2H and 3C stacking structures over the entire range of growth and\ndeformation faulting probabilities, and (iii) as a HMM that models\nShockley-Frank stacking faults in 6H-SiC. While applied here to planar faulting\nin CPSs, extending the methods and results to planar disorder in other layered\nmaterials is straightforward. In this way, we effectively solve the broad\nproblem of calculating a DP---either analytically or numerically---for any\nstacking structure---ordered or disordered---where the stacking process can be\nexpressed as a HMM. \n\n"}
{"id": "1410.5341", "contents": "Title: On obtaining simple identities for overshoots of spectrally negative\n  L\\'evy processes Abstract: For a (killed) spectrally negative L\\'evy process we provide an analytic\nexpression for the distribution of its overshoot over a fixed level in terms of\nthe infinitesimal generator and the scale function of the process. Our identity\ninvolves an auxiliary function and the simplicity of the identity depends very\nmuch on the choice of this function. In particular, for specific choices one\nrecovers various previous established formulas in the literature. We review\nseveral applications and also show that one can get in a similar way identities\nof overshoots for reflected and refracted spectrally negative L\\'evy processes. \n\n"}
{"id": "1410.5509", "contents": "Title: On the feasibility of beamforming in millimeter wave communication\n  systems with multiple antenna arrays Abstract: The use of the millimeter (mm) wave spectrum for next generation (5G) mobile\ncommunication has gained significant attention recently. The small carrier\nwavelengths at mmwave frequencies enable synthesis of compact antenna arrays,\nproviding beamforming gains that compensate the increased propagation losses.\nIn this work, we investigate the feasibility of employing multiple antenna\narrays to obtain diversity/multiplexing gains in mmwave systems, where each of\nthe arrays is capable of beamforming independently. Considering a codebook\nbased beamforming system (e.g., to facilitate limited feedback), we observe\nthat the complexity of \\emph{jointly} optimizing the beamforming directions\nacross the multiple arrays is highly prohibitive, even for very reasonable\nsystem parameters. To overcome this bottleneck, we develop reduced complexity\nalgorithms for optimizing the choice of beamforming directions, premised on the\nsparse multipath structure of the mmwave channel. Specifically, we reduce the\ncardinality of the joint beamforming search space, by restricting attention to\na small set of dominant candidate directions. To obtain the set of dominant\ndirections, we develop two complementary approaches: (a) based on computation\nof a novel spatial power metric; a detailed analysis of this metric shows that,\nin the limit of large antenna arrays, the selected candidate directions\napproach the channel's dominant angles of arrival and departure, and (b)\nprecise estimation of the channel's (long-term) dominant angles of arrival,\nexploiting the correlations of the signals received across the different\nreceiver subarrays. Our methods enable a drastic reduction of the optimization\nsearch space (a factor of 100 reduction), while delivering close to optimal\nperformance, thereby indicating the potential feasibility of achieving\ndiversity and multiplexing gains in mmwave systems. \n\n"}
{"id": "1410.6339", "contents": "Title: Constructions and Properties of Linear Locally Repairable Codes Abstract: In this paper, locally repairable codes with all-symbol locality are studied.\nMethods to modify already existing codes are presented. Also, it is shown that\nwith high probability, a random matrix with a few extra columns guaranteeing\nthe locality property, is a generator matrix for a locally repairable code with\na good minimum distance. The proof of this also gives a constructive method to\nfind locally repairable codes. Constructions are given of three infinite\nclasses of optimal vector-linear locally repairable codes over an alphabet of\nsmall size, not depending on the size of the code. \n\n"}
{"id": "1410.6457", "contents": "Title: A conditional construction of restricted isometries Abstract: We study the restricted isometry property of a matrix that is built from the\ndiscrete Fourier transform matrix by collecting rows indexed by quadratic\nresidues. We find an $\\epsilon>0$ such that, conditioned on a folklore\nconjecture in number theory, this matrix satisfies the restricted isometry\nproperty with sparsity parameter $K=\\Omega(M^{1/2+\\epsilon})$, where $M$ is the\nnumber of rows. \n\n"}
{"id": "1410.6513", "contents": "Title: Matching Theory for Future Wireless Networks: Fundamentals and\n  Applications Abstract: The emergence of novel wireless networking paradigms such as small cell and\ncognitive radio networks has forever transformed the way in which wireless\nsystems are operated. In particular, the need for self-organizing solutions to\nmanage the scarce spectral resources has become a prevalent theme in many\nemerging wireless systems. In this paper, the first comprehensive tutorial on\nthe use of matching theory, a Nobelprize winning framework, for resource\nmanagement in wireless networks is developed. To cater for the unique features\nof emerging wireless networks, a novel, wireless-oriented classification of\nmatching theory is proposed. Then, the key solution concepts and algorithmic\nimplementations of this framework are exposed. Then, the developed concepts are\napplied in three important wireless networking areas in order to demonstrate\nthe usefulness of this analytical tool. Results show how matching theory can\neffectively improve the performance of resource allocation in all three\napplications discussed. \n\n"}
{"id": "1410.6913", "contents": "Title: Low rank matrix recovery from rank one measurements Abstract: We study the recovery of Hermitian low rank matrices $X \\in \\mathbb{C}^{n\n\\times n}$ from undersampled measurements via nuclear norm minimization. We\nconsider the particular scenario where the measurements are Frobenius inner\nproducts with random rank-one matrices of the form $a_j a_j^*$ for some\nmeasurement vectors $a_1,...,a_m$, i.e., the measurements are given by $y_j =\n\\mathrm{tr}(X a_j a_j^*)$. The case where the matrix $X=x x^*$ to be recovered\nis of rank one reduces to the problem of phaseless estimation (from\nmeasurements, $y_j = |\\langle x,a_j\\rangle|^2$ via the PhaseLift approach,\nwhich has been introduced recently. We derive bounds for the number $m$ of\nmeasurements that guarantee successful uniform recovery of Hermitian rank $r$\nmatrices, either for the vectors $a_j$, $j=1,...,m$, being chosen independently\nat random according to a standard Gaussian distribution, or $a_j$ being sampled\nindependently from an (approximate) complex projective $t$-design with $t=4$.\nIn the Gaussian case, we require $m \\geq C r n$ measurements, while in the case\nof $4$-designs we need $m \\geq Cr n \\log(n)$. Our results are uniform in the\nsense that one random choice of the measurement vectors $a_j$ guarantees\nrecovery of all rank $r$-matrices simultaneously with high probability.\nMoreover, we prove robustness of recovery under perturbation of the\nmeasurements by noise. The result for approximate $4$-designs generalizes and\nimproves a recent bound on phase retrieval due to Gross, Kueng and Krahmer. In\naddition, it has applications in quantum state tomography. Our proofs employ\nthe so-called bowling scheme which is based on recent ideas by Mendelson and\nKoltchinskii. \n\n"}
{"id": "1410.8805", "contents": "Title: Correlated Source Coded Sequences with Compromised Channel and Source\n  Symbols using Shannon's Cipher System Abstract: Correlated sources are present in communication systems where protocols\nensure that there is some predetermined information for sources to transmit.\nHere, two correlated sources across a channel with eavesdroppers are\ninvestigated, and conditions for perfect secrecy when some channel information\nand some source data symbols (the predetermined information) have been\nwiretapped are determined. The adversary in this situation has access to more\ninformation than if a link is wiretapped only and can thus determine more about\na particular source. This scenario caters for an application where the\neavesdropper has access to some preexisting information. We provide bounds for\nthe channel and key rates for this scenario. Further, we provide a method to\nreduce the key lengths required for perfect secrecy. \n\n"}
{"id": "1410.8853", "contents": "Title: Demonstrating Continuous Variable EPR Steering in spite of Finite\n  Experimental Capabilities using Fano Steering Bounds Abstract: We show how one can demonstrate continuous-variable Einstein-Podolsky-Rosen\n(EPR) steering without needing to characterize entire measurement probability\ndistributions. To do this, we develop a modified Fano inequality useful for\ndiscrete measurements of continuous variables, and use it to bound the\nconditional uncertainties in continuous-variable entropic EPR-steering\ninequalities. With these bounds, we show how one can hedge against experimental\nlimitations including a finite detector size, dead space between pixels, and\nany such factors that impose an incomplete sampling of the true measurement\nprobability distribution. Furthermore, we use experimental data from the\nposition and momentum statistics of entangled photon pairs in parametric\ndownconversion to show that this method is sufficiently sensitive for practical\nuse. \n\n"}
{"id": "1411.1076", "contents": "Title: A statistical model for tensor PCA Abstract: We consider the Principal Component Analysis problem for large tensors of\narbitrary order $k$ under a single-spike (or rank-one plus noise) model. On the\none hand, we use information theory, and recent results in probability theory,\nto establish necessary and sufficient conditions under which the principal\ncomponent can be estimated using unbounded computational resources. It turns\nout that this is possible as soon as the signal-to-noise ratio $\\beta$ becomes\nlarger than $C\\sqrt{k\\log k}$ (and in particular $\\beta$ can remain bounded as\nthe problem dimensions increase).\n  On the other hand, we analyze several polynomial-time estimation algorithms,\nbased on tensor unfolding, power iteration and message passing ideas from\ngraphical models. We show that, unless the signal-to-noise ratio diverges in\nthe system dimensions, none of these approaches succeeds. This is possibly\nrelated to a fundamental limitation of computationally tractable estimators for\nthis problem.\n  We discuss various initializations for tensor power iteration, and show that\na tractable initialization based on the spectrum of the matricized tensor\noutperforms significantly baseline methods, statistically and computationally.\nFinally, we consider the case in which additional side information is available\nabout the unknown signal. We characterize the amount of side information that\nallows the iterative algorithms to converge to a good estimate. \n\n"}
{"id": "1411.1608", "contents": "Title: Device-to-Device Data Storage with Regenerating Codes Abstract: Caching data files directly on mobile user devices combined with\ndevice-to-device (D2D) communications has recently been suggested to improve\nthe capacity of wireless net6works. We investigate the performance of\nregenerating codes in terms of the total energy consumption of a cellular\nnetwork. We show that regenerating codes can offer large performance gains. It\nturns out that using redundancy against storage node failures is only\nbeneficial if the popularity of the data is between certain thresholds. As our\nmajor contribution, we investigate under which circumstances regenerating codes\nwith multiple redundant data fragments outdo uncoded caching. \n\n"}
{"id": "1411.1784", "contents": "Title: Conditional Generative Adversarial Nets Abstract: Generative Adversarial Nets [8] were recently introduced as a novel way to\ntrain generative models. In this work we introduce the conditional version of\ngenerative adversarial nets, which can be constructed by simply feeding the\ndata, y, we wish to condition on to both the generator and discriminator. We\nshow that this model can generate MNIST digits conditioned on class labels. We\nalso illustrate how this model could be used to learn a multi-modal model, and\nprovide preliminary examples of an application to image tagging in which we\ndemonstrate how this approach can generate descriptive tags which are not part\nof training labels. \n\n"}
{"id": "1411.2045", "contents": "Title: Multivariate f-Divergence Estimation With Confidence Abstract: The problem of f-divergence estimation is important in the fields of machine\nlearning, information theory, and statistics. While several nonparametric\ndivergence estimators exist, relatively few have known convergence properties.\nIn particular, even for those estimators whose MSE convergence rates are known,\nthe asymptotic distributions are unknown. We establish the asymptotic normality\nof a recently proposed ensemble estimator of f-divergence between two\ndistributions from a finite number of samples. This estimator has MSE\nconvergence rate of O(1/T), is simple to implement, and performs well in high\ndimensions. This theory enables us to perform divergence-based inference tasks\nsuch as testing equality of pairs of distributions based on empirical samples.\nWe experimentally validate our theoretical results and, as an illustration, use\nthem to empirically bound the best achievable classification error. \n\n"}
{"id": "1411.4144", "contents": "Title: Coordinated Scheduling for the Downlink of Cloud Radio-Access Networks Abstract: This paper addresses the coordinated scheduling problem in cloud-enabled\nnetworks. Consider the downlink of a cloud-radio access network (C-RAN), where\nthe cloud is only responsible for the scheduling policy and the synchronization\nof the transmit frames across the connected base-stations (BS). The transmitted\nframe of every BS consists of several time/frequency blocks, called power-zones\n(PZ), maintained at fixed transmit power. The paper considers the problem of\nscheduling users to PZs and BSs in a coordinated fashion across the network, by\nmaximizing a network-wide utility under the practical constraint that each user\ncannot be served by more than one base-station, but can be served by one or\nmore power-zone within each base-station frame. The paper solves the problem\nusing a graph theoretical approach by introducing the scheduling graph in which\neach vertex represents an association of users, PZs and BSs. The problem is\nformulated as a maximum weight clique, in which the weight of each vertex is\nthe benefit of the association represented by that vertex. The paper further\npresents heuristic algorithms with low computational complexity. Simulation\nresults show the performance of the proposed algorithms and suggest that the\nheuristics perform near optimal in low shadowing environments \n\n"}
{"id": "1411.4253", "contents": "Title: Energy-efficient Decoders for Compressive Sensing: Fundamental Limits\n  and Implementations Abstract: The fundamental problem considered in this paper is \"What is the\n\\textit{energy} consumed for the implementation of a \\emph{compressive sensing}\ndecoding algorithm on a circuit?\". Using the \"information-friction\" framework,\nwe examine the smallest amount of \\textit{bit-meters} as a measure for the\nenergy consumed by a circuit. We derive a fundamental lower bound for the\nimplementation of compressive sensing decoding algorithms on a circuit. In the\nsetting where the number of measurements scales linearly with the sparsity and\nthe sparsity is sub-linear with the length of the signal, we show that the\n\\textit{bit-meters} consumption for these algorithms is order-tight, i.e., it\nmatches the lower bound asymptotically up to a constant factor. Our\nimplementations yield interesting insights into design of energy-efficient\ncircuits that are not captured by the notion of computational efficiency alone. \n\n"}
{"id": "1411.4305", "contents": "Title: Supercritical behavior of asymmetric zero-range process with sitewise\n  disorder Abstract: We establish necessary and sufficient conditions for weak convergence to the\nupper invariant measure for asymmetric nearest neighbour zero range processes\nwith non homogeneous jump rates. The class of environments considered is close\nto that considered by Andjel, Ferrari, Guiol and Landim, while our class of\nprocesses is broader. We also give a simpler proof of a result of Ferrari and\nSisko with weaker assumptions. \n\n"}
{"id": "1411.6137", "contents": "Title: Enhanced Multi-Parameter Cognitive Architecture for Future Wireless\n  Communications Abstract: The very original concept of cognitive radio (CR) raised by Mitola targets at\nall the environment parameters, including those in physical layer, MAC layer,\napplication layer as well as the information extracted from reasoning. Hence\nthe first CR is also referred to as \"full cognitive radio\". However, due to its\ndifficult implementation, FCC and Simon Haykin separately proposed a much more\nsimplified definition, in which CR mainly detects one single parameter, i.e.,\nspectrum occupancy, and is also called as \"spectrum sensing cognitive radio\".\nWith the rapid development of wireless communication, the infrastructure of a\nwireless system becomes much more complicated while the functionality at every\nnode is desired to be as intelligent as possible, say the self-organized\ncapability in the approaching 5G cellular networks. It is then interesting to\nre-look into Mitola's definition and think whether one could, besides obtaining\nthe \"on/off\" status of the licensed user only, achieve more parameters in a\ncognitive way. In this article, we propose a new cognitive architecture\ntargeting at multiple parameters in future cellular networks, which is a one\nstep further towards the \"full cognition\" compared to the most existing CR\nresearch. The new architecture is elaborated in detailed stages, and three\nrepresentative examples are provided based on the recent research progress to\nillustrate the feasibility as well as the validity of the proposed\narchitecture. \n\n"}
{"id": "1411.7346", "contents": "Title: A Chasm Between Identity and Equivalence Testing with Conditional\n  Queries Abstract: A recent model for property testing of probability distributions (Chakraborty\net al., ITCS 2013, Canonne et al., SICOMP 2015) enables tremendous savings in\nthe sample complexity of testing algorithms, by allowing them to condition the\nsampling on subsets of the domain. In particular, Canonne, Ron, and Servedio\n(SICOMP 2015) showed that, in this setting, testing identity of an unknown\ndistribution $D$ (whether $D=D^\\ast$ for an explicitly known $D^\\ast$) can be\ndone with a constant number of queries, independent of the support size $n$ --\nin contrast to the required $\\Omega(\\sqrt{n})$ in the standard sampling model.\nIt was unclear whether the same stark contrast exists for the case of testing\nequivalence, where both distributions are unknown. While Canonne et al.\nestablished a $\\mathrm{poly}(\\log n)$-query upper bound for equivalence\ntesting, very recently brought down to $\\tilde O(\\log\\log n)$ by Falahatgar et\nal. (COLT 2015), whether a dependence on the domain size $n$ is necessary was\nstill open, and explicitly posed by Fischer at the Bertinoro Workshop on\nSublinear Algorithms (2014). We show that any testing algorithm for equivalence\nmust make $\\Omega(\\sqrt{\\log\\log n})$ queries in the conditional sampling\nmodel. This demonstrates a gap between identity and equivalence testing, absent\nin the standard sampling model (where both problems have sampling complexity\n$n^{\\Theta(1)}$).\n  We also obtain results on the query complexity of uniformity testing and\nsupport-size estimation with conditional samples. We answer a question of\nChakraborty et al. (ITCS 2013) showing that non-adaptive uniformity testing\nindeed requires $\\Omega(\\log n)$ queries in the conditional model. For the\nrelated problem of support-size estimation, we provide both adaptive and\nnon-adaptive algorithms, with query complexities $\\mathrm{poly}(\\log\\log n)$\nand $\\mathrm{poly}(\\log n)$, respectively. \n\n"}
{"id": "1411.7666", "contents": "Title: No Quantum Brooks' Theorem Abstract: First, I introduce quantum graph theory. I also discuss a known lower bound\non the independence numbers and derive from it an upper bound on the chromatic\nnumbers of quantum graphs. Then, I construct a family of quantum graphs that\ncan be described as tropical, cyclical, and commutative. I also define a step\nlogarithm function and express with it the bounds on quantum graph invariants\nin closed form. Finally, I obtain an upper bound on the independence numbers\nand a lower bound on the chromatic numbers of the constructed quantum graphs\nthat are similar in form to the existing bounds. I also show that the\nconstructed family contains graphs of any valence with arbitrarily high\nchromatic numbers and conclude by it that quantum graph colorings are quite\ndifferent from classical graph colorings. \n\n"}
{"id": "1412.4261", "contents": "Title: Re-proving Channel Polarization Theorems: An Extremality and Robustness\n  Analysis Abstract: The general subject considered in this thesis is a recently discovered coding\ntechnique, polar coding, which is used to construct a class of error correction\ncodes with unique properties. In his ground-breaking work, Ar{\\i}kan proved\nthat this class of codes, called polar codes, achieve the symmetric capacity\n--- the mutual information evaluated at the uniform input distribution ---of\nany stationary binary discrete memoryless channel with low complexity encoders\nand decoders requiring in the order of $O(N\\log N)$ operations in the\nblock-length $N$. This discovery settled the long standing open problem left by\nShannon of finding low complexity codes achieving the channel capacity.\n  Polar coding settled an open problem in information theory, yet opened plenty\nof challenging problems that need to be addressed. A significant part of this\nthesis is dedicated to advancing the knowledge about this technique in two\ndirections. The first one provides a better understanding of polar coding by\ngeneralizing some of the existing results and discussing their implications,\nand the second one studies the robustness of the theory over communication\nmodels introducing various forms of uncertainty or variations into the\nprobabilistic model of the channel. \n\n"}
{"id": "1412.4958", "contents": "Title: Universal Hashing for Information Theoretic Security Abstract: The information theoretic approach to security entails harnessing the\ncorrelated randomness available in nature to establish security. It uses tools\nfrom information theory and coding and yields provable security, even against\nan adversary with unbounded computational power. However, the feasibility of\nthis approach in practice depends on the development of efficiently\nimplementable schemes. In this article, we review a special class of practical\nschemes for information theoretic security that are based on 2-universal hash\nfamilies. Specific cases of secret key agreement and wiretap coding are\nconsidered, and general themes are identified. The scheme presented for wiretap\ncoding is modular and can be implemented easily by including an extra\npre-processing layer over the existing transmission codes. \n\n"}
{"id": "1412.6558", "contents": "Title: Random Walk Initialization for Training Very Deep Feedforward Networks Abstract: Training very deep networks is an important open problem in machine learning.\nOne of many difficulties is that the norm of the back-propagated error gradient\ncan grow or decay exponentially. Here we show that training very deep\nfeed-forward networks (FFNs) is not as difficult as previously thought. Unlike\nwhen back-propagation is applied to a recurrent network, application to an FFN\namounts to multiplying the error gradient by a different random matrix at each\nlayer. We show that the successive application of correctly scaled random\nmatrices to an initial vector results in a random walk of the log of the norm\nof the resulting vectors, and we compute the scaling that makes this walk\nunbiased. The variance of the random walk grows only linearly with network\ndepth and is inversely proportional to the size of each layer. Practically,\nthis implies a gradient whose log-norm scales with the square root of the\nnetwork depth and shows that the vanishing gradient problem can be mitigated by\nincreasing the width of the layers. Mathematical analyses and experimental\nresults using stochastic gradient descent to optimize tasks related to the\nMNIST and TIMIT datasets are provided to support these claims. Equations for\nthe optimal matrix scaling are provided for the linear and ReLU cases. \n\n"}
{"id": "1412.6677", "contents": "Title: System Architecture and Key Technologies for 5G Heterogeneous Cloud\n  Radio Access Networks Abstract: Compared with the fourth generation (4G) cellular systems, the fifth\ngeneration wireless communication systems (5G) are anticipated to provide\nspectral and energy efficiency growth by a factor of at least 10, and the area\nthroughput growth by a factor of at least 25. To achieve these goals, a\nheterogeneous cloud radio access network (H-CRAN) is presented in this article\nas the advanced wireless access network paradigm, where cloud computing is used\nto fulfill the centralized large-scale cooperative processing for suppressing\nco-channel interferences. The state-of-the-art research achievements in aspects\nof system architecture and key technologies for H-CRANs are surveyed.\nParticularly, Node C as a new communication entity is defined to converge the\nexisting ancestral base stations and act as the base band unit (BBU) pool to\nmanage all accessed remote radio heads (RRHs), and the software-defined H-CRAN\nsystem architecture is presented to be compatible with software-defined\nnetworks (SDN). The principles, performance gains and open issues of key\ntechnologies including adaptive large-scale cooperative spatial signal\nprocessing, cooperative radio resource management, network function\nvirtualization, and self-organization are summarized. The major challenges in\nterms of fronthaul constrained resource allocation optimization and energy\nharvesting that may affect the promotion of H-CRANs are discussed as well. \n\n"}
{"id": "1412.6980", "contents": "Title: Adam: A Method for Stochastic Optimization Abstract: We introduce Adam, an algorithm for first-order gradient-based optimization\nof stochastic objective functions, based on adaptive estimates of lower-order\nmoments. The method is straightforward to implement, is computationally\nefficient, has little memory requirements, is invariant to diagonal rescaling\nof the gradients, and is well suited for problems that are large in terms of\ndata and/or parameters. The method is also appropriate for non-stationary\nobjectives and problems with very noisy and/or sparse gradients. The\nhyper-parameters have intuitive interpretations and typically require little\ntuning. Some connections to related algorithms, on which Adam was inspired, are\ndiscussed. We also analyze the theoretical convergence properties of the\nalgorithm and provide a regret bound on the convergence rate that is comparable\nto the best known results under the online convex optimization framework.\nEmpirical results demonstrate that Adam works well in practice and compares\nfavorably to other stochastic optimization methods. Finally, we discuss AdaMax,\na variant of Adam based on the infinity norm. \n\n"}
{"id": "1412.8416", "contents": "Title: Joint Optimization of Radio and Computational Resources for Multicell\n  Mobile-Edge Computing Abstract: Migrating computational intensive tasks from mobile devices to more\nresourceful cloud servers is a promising technique to increase the\ncomputational capacity of mobile devices while saving their battery energy. In\nthis paper, we consider a MIMO multicell system where multiple mobile users\n(MUs) ask for computation offloading to a common cloud server. We formulate the\noffloading problem as the joint optimization of the radio resources-the\ntransmit precoding matrices of the MUs-and the computational resources-the CPU\ncycles/second assigned by the cloud to each MU-in order to minimize the overall\nusers' energy consumption, while meeting latency constraints. The resulting\noptimization problem is nonconvex (in the objective function and constraints).\nNevertheless, in the single-user case, we are able to express the global\noptimal solution in closed form. In the more challenging multiuser scenario, we\npropose an iterative algorithm, based on a novel successive convex\napproximation technique, converging to a local optimal solution of the original\nnonconvex problem. Then, we reformulate the algorithm in a distributed and\nparallel implementation across the radio access points, requiring only a\nlimited coordination/signaling with the cloud. Numerical results show that the\nproposed schemes outperform disjoint optimization algorithms. \n\n"}
{"id": "1501.01742", "contents": "Title: LDPC Coded Modulation with Probabilistic Shaping for Optical Fiber\n  Systems Abstract: An LDPC coded modulation scheme with probabilistic shaping, optimized\ninterleavers and noniterative demapping is proposed. Full-field simulations\nshow an increase in transmission distance by 8% compared to uniformly\ndistributed input. \n\n"}
{"id": "1501.01773", "contents": "Title: Estimates for the growth of inverse determinant sums of quasi-orthogonal\n  and number field lattices Abstract: Inverse determinant sums appear naturally as a tool for analyzing performance\nof space-time codes in Rayleigh fading channels. This work will analyze the\ngrowth of inverse determinant sums of a family of quasi-orthogonal codes and\nwill show that the growths are in logarithmic class. This is considerably lower\nthan that of comparable number field codes. \n\n"}
{"id": "1501.01825", "contents": "Title: Unified Convex Optimization Approach to Super-Resolution Based on\n  Localized Kernels Abstract: The problem of resolving the fine details of a signal from its coarse scale\nmeasurements or, as it is commonly referred to in the literature, the\nsuper-resolution problem arises naturally in engineering and physics in a\nvariety of settings. We suggest a unified convex optimization approach for\nsuper-resolution. The key is the construction of an interpolating polynomial\nbased on localized kernels. We also show that the localized kernels act as the\nconnecting thread to another wide-spread problem of stream of pulses. \n\n"}
{"id": "1501.03717", "contents": "Title: Examples of random fields that can be represented as space-domain scaled\n  stationary Ornstein-Uhlenbeck fields Abstract: We give some examples of random fields that can be represented as\nspace-domain scaled stationary Ornstein-Uhlenbeck fields defined on the plane.\nNamely, we study a tied-down Wiener bridge, tied-down scaled Wiener bridges, a\nKiefer process and so called (F,G)-Wiener bridges. \n\n"}
{"id": "1501.04478", "contents": "Title: Information Leakage of Heterogeneous Encoded Correlated Sequences over\n  Eavesdropped Channel Abstract: Correlated sources are present in communication systems where protocols\nensure that there is some predetermined information for sources. Here\ncorrelated sources across an eavesdropped channel that incorporate a\nheterogeneous encoding scheme and their effect on the information leakage when\nsome channel information and a source have been wiretapped is investigated. The\ninformation leakage bounds for the Slepian-Wolf scenario are provided.\nThereafter, the Shannon cipher system approach is presented. Further, an\nimplementation method using a matrix partition approach is described. \n\n"}
{"id": "1501.04490", "contents": "Title: On The Capacity of Broadcast Channels With Degraded Message Sets and\n  Message Cognition Under Different Secrecy Constraints Abstract: This paper considers a three-receiver broadcast channel with degraded message\nsets and message cognition. The model consists of a common message for all\nthree receivers, a private common message for only two receivers and two\nadditional private messages for these two receivers, such that each receiver is\nonly interested in one message, while being fully cognizant of the other one.\nFirst, this model is investigated without any secrecy constraints, where the\ncapacity region is established, showing that the straightforward extension of\nthe K\\\"orner and Marton inner bound to the investigated scenario is optimal. In\nparticular, this agrees with Nair and Wang's result, which states that the idea\nof indirect decoding - introduced to improve the K\\\"orner and Marton inner\nbound - does not provide a better region for this scenario. Further, some\nsecrecy constraints are introduced by letting the private messages to be\nconfidential ones. Two different secrecy criteria are considered: joint secrecy\nand individual secrecy. For both criteria, a general achievable rate region is\nprovided. Moreover, the joint and individual secrecy capacity regions are\nestablished, if the two legitimate receivers are more capable than the\neavesdropper. The established capacity regions indicate that the individual\nsecrecy criterion can provide a larger capacity region as compared to the joint\none, because each cognizant message can be used as a secret key for the other\nindividual message. Further, the joint secrecy capacity is established for a\nmore general class of more capable channels, where only one of the two\nlegitimate receivers is more capable than the eavesdropper. This was done by\nshowing that principle of indirect decoding introduced by Nair and El Gamal is\noptimal for this class of channels. This result is in contrast with the\nnonsecrecy case, where the indirect decoding does not provide any gain. \n\n"}
{"id": "1501.04703", "contents": "Title: Graph-based Framework for Flexible Baseband Function Splitting and\n  Placement in C-RAN Abstract: The baseband-up centralization architecture of radio access networks (C-RAN)\nhas recently been proposed to support efficient cooperative communications and\nreduce deployment and operational costs. However, the massive fronthaul\nbandwidth required to aggregate baseband samples from remote radio heads (RRHs)\nto the central office incurs huge fronthauling cost, and existing baseband\ncompression algorithms can hardly solve this issue. In this paper, we propose a\ngraphbased framework to effectively reduce fronthauling cost through properly\nsplitting and placing baseband processing functions in the network. Baseband\ntransceiver structures are represented with directed graphs, in which nodes\ncorrespond to baseband functions, and edges to the information flows between\nfunctions. By mapping graph weighs to computational and fronthauling costs, we\ntransform the problem of finding the optimum location to place some baseband\nfunctions into the problem of finding the optimum clustering scheme for graph\nnodes. We then solve this problem using a genetic algorithm with customized\nfitness function and mutation module. Simulation results show that proper\nsplitting and placement schemes can significantly reduce fronthauling cost at\nthe expense of increased computational cost. We also find that cooperative\nprocessing structures and stringent delay requirements will increase the\npossibility of centralized placement. \n\n"}
{"id": "1501.07033", "contents": "Title: Error Correction for Differential Linear Network Coding in\n  Slowly-Varying Networks Abstract: Differential linear network coding (DLNC) is a precoding scheme for\ninformation transmission over random linear networks. By using differential\nencoding and decoding, the conventional approach of lifting, required for\ninherent channel sounding, can be omitted and in turn higher transmission rates\nare supported. However, the scheme is sensitive to variations in the network\ntopology. In this paper, we derive an extended DLNC channel model which\nincludes slow network changes. Based on this, we propose and analyze a suitable\nchannel coding scheme matched to the situation at hand using rank-metric\nconvolutional codes. \n\n"}
{"id": "1501.07072", "contents": "Title: On the stability of asynchronous Random Access Schemes Abstract: Slotted Aloha-based Random Access (RA) techniques have recently regained\nattention in light of the use of Interference Cancellation (IC) as a mean to\nexploit diversity created through the transmission of multiple burst copies per\npacket content (CRDSA). Subsequently, the same concept has been extended to\npure ALOHA-based techniques in order to boost the performance also in case of\nasynchronous RA schemes. In this paper, throughput as well as packet delay and\nrelated stability for asynchronous ALOHA techniques under geometrically\ndistributed retransmissions are analyzed both in case of finite and infinite\npopulation size. Moreover, a comparison between pure ALOHA, its evolution\n(known as CRA) and CRDSA techniques is presented, in order to give a measure of\nthe achievable gain that can be reached in a closed-loop scenario with respect\nto the previous state of the art. \n\n"}
{"id": "1502.00079", "contents": "Title: EXIT Chart Analysis of Block Markov Superposition Transmission of Short\n  Codes Abstract: In this paper, a modified extrinsic information transfer (EXIT) chart\nanalysis that takes into account the relation between mutual information (MI)\nand bit-error-rate (BER) is presented to study the convergence behavior of\nblock Markov superposition transmission (BMST) of short codes (referred to as\nbasic codes). We show that the threshold curve of BMST codes using an iterative\nsliding window decoding algorithm with a fixed decoding delay achieves a lower\nbound in the high signal-to-noise ratio (SNR) region, while in the low SNR\nregion, due to error propagation, the thresholds of BMST codes become slightly\nworse as the encoding memory increases. We also demonstrate that the threshold\nresults are consistent with finite-length performance simulations. \n\n"}
{"id": "1502.05516", "contents": "Title: Outage Capacity of Rayleigh Product Channels: a Free Probability\n  Approach Abstract: The Rayleigh product channel model is useful in capturing the performance\ndegradation due to rank deficiency of MIMO channels. In this paper, such a\nperformance degradation is investigated via the channel outage probability\nassuming slowly varying channel with delay-constrained decoding. Using\ntechniques of free probability theory, the asymptotic variance of channel\ncapacity is derived when the dimensions of the channel matrices approach\ninfinity. In this asymptotic regime, the channel capacity is rigorously proven\nto be Gaussian distributed. Using the obtained results, a fundamental tradeoff\nbetween multiplexing gain and diversity gain of Rayleigh product channels can\nbe characterized by closed-form expression at any finite signal-to-noise ratio.\nNumerical results are provided to compare the relative outage performance\nbetween Rayleigh product channels and conventional Rayleigh MIMO channels. \n\n"}
{"id": "1502.06321", "contents": "Title: A Linear Network Code Construction for General Integer Connections Based\n  on the Constraint Satisfaction Problem Abstract: The problem of finding network codes for general connections is inherently\ndifficult in capacity constrained networks. Resource minimization for general\nconnections with network coding is further complicated. Existing methods for\nidentifying solutions mainly rely on highly restricted classes of network\ncodes, and are almost all centralized. In this paper, we introduce linear\nnetwork mixing coefficients for code constructions of general connections that\ngeneralize random linear network coding (RLNC) for multicast connections. For\nsuch code constructions, we pose the problem of cost minimization for the\nsubgraph involved in the coding solution and relate this minimization to a\npath-based Constraint Satisfaction Problem (CSP) and an edge-based CSP. While\nCSPs are NP-complete in general, we present a path-based probabilistic\ndistributed algorithm and an edge-based probabilistic distributed algorithm\nwith almost sure convergence in finite time by applying Communication Free\nLearning (CFL). Our approach allows fairly general coding across flows,\nguarantees no greater cost than routing, and shows a possible distributed\nimplementation. Numerical results illustrate the performance improvement of our\napproach over existing methods. \n\n"}
{"id": "1503.00879", "contents": "Title: Stabilizer quantum codes from $J$-affine variety codes and a new\n  Steane-like enlargement Abstract: New stabilizer codes with parameters better than the ones available in the\nliterature are provided in this work, in particular quantum codes with\nparameters $[[127,63, \\geq 12]]_2$ and $[[63,45, \\geq 6]]_4$ that are records.\nThese codes are constructed with a new generalization of the Steane's\nenlargement procedure and by considering orthogonal subfield-subcodes --with\nrespect to the Euclidean and Hermitian inner product-- of a new family of\nlinear codes, the $J$-affine variety codes. \n\n"}
{"id": "1503.01056", "contents": "Title: Secrecy Transmit Beamforming for Heterogeneous Networks Abstract: In this paper, we pioneer the study of physical-layer security in\nheterogeneous networks (HetNets). We investigate secure communications in a\ntwo-tier downlink HetNet, which comprises one macrocell and several femtocells.\nEach cell has multiple users and an eavesdropper attempts to wiretap the\nintended macrocell user. Firstly, we consider an orthogonal spectrum allocation\nstrategy to eliminate co-channel interference, and propose the secrecy transmit\nbeamforming only operating in the macrocell (STB-OM) as a partial solution for\nsecure communication in HetNet. Next, we consider a secrecy-oriented\nnon-orthogonal spectrum allocation strategy and propose two cooperative STBs\nwhich rely on the collaboration amongst the macrocell base station (MBS) and\nthe adjacent femtocell base stations (FBSs). Our first cooperative STB is the\nSTB sequentially operating in the macrocell and femtocells (STB-SMF), where the\ncooperative FBSs individually design their STB matrices and then feed their\nperformance metrics to the MBS for guiding the STB in the macrocell. Aiming to\nimprove the performance of STB-SMF, we further propose the STB jointly designed\nin the macrocell and femtocells (STB-JMF), where all cooperative FBSs feed\nchannel state information to the MBS for designing the joint STB. Unlike\nconventional STBs conceived for broadcasting or interference channels, the\nthree proposed STB schemes all entail relatively sophisticated optimizations\ndue to QoS constraints of the legitimate users. In order to efficiently use\nthese STB schemes, the original optimization problems are reformulated and\nconvex optimization techniques, such as second-order cone programming and\nsemidefinite programming, are invoked to obtain the optimal solutions.\nNumerical results demonstrate that the proposed STB schemes are highly\neffective in improving the secrecy rate performance of HetNet. \n\n"}
{"id": "1503.01250", "contents": "Title: A new method on deterministic construction of the measurement matrix in\n  compressed sensing Abstract: Construction on the measurement matrix $A$ is a central problem in compressed\nsensing. Although using random matrices is proven optimal and successful in\nboth theory and applications. A deterministic construction on the measurement\nmatrix is still very important and interesting. In fact, it is still an open\nproblem proposed by T. Tao. In this paper, we shall provide a new deterministic\nconstruction method and prove it is optimal with regard to the mutual\nincoherence. \n\n"}
{"id": "1503.02406", "contents": "Title: Deep Learning and the Information Bottleneck Principle Abstract: Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the\ninformation bottleneck (IB) principle. We first show that any DNN can be\nquantified by the mutual information between the layers and the input and\noutput variables. Using this representation we can calculate the optimal\ninformation theoretic limits of the DNN and obtain finite sample generalization\nbounds. The advantage of getting closer to the theoretical limit is\nquantifiable both by the generalization bound and by the network's simplicity.\nWe argue that both the optimal architecture, number of layers and\nfeatures/connections at each layer, are related to the bifurcation points of\nthe information bottleneck tradeoff, namely, relevant compression of the input\nlayer with respect to the output layer. The hierarchical representations at the\nlayered network naturally correspond to the structural phase transitions along\nthe information curve. We believe that this new insight can lead to new\noptimality bounds and deep learning algorithms. \n\n"}
{"id": "1503.02779", "contents": "Title: On metric properties of maps between Hamming spaces and related graph\n  homomorphisms Abstract: A mapping of $k$-bit strings into $n$-bit strings is called an\n$(\\alpha,\\beta)$-map if $k$-bit strings which are more than $\\alpha k$ apart\nare mapped to $n$-bit strings that are more than $\\beta n$ apart. This is a\nrelaxation of the classical problem of constructing error-correcting codes,\nwhich corresponds to $\\alpha=0$. Existence of an $(\\alpha,\\beta)$-map is\nequivalent to existence of a graph homomorphism $\\bar H(k,\\alpha k)\\to \\bar\nH(n,\\beta n)$, where $H(n,d)$ is a Hamming graph with vertex set $\\{0,1\\}^n$\nand edges connecting vertices differing in $d$ or fewer entries.\n  This paper proves impossibility results on achievable parameters\n$(\\alpha,\\beta)$ in the regime of $n,k\\to\\infty$ with a fixed ratio ${n\\over\nk}= \\rho$. This is done by developing a general criterion for existence of\ngraph-homomorphism based on the semi-definite relaxation of the independence\nnumber of a graph (known as the Schrijver's $\\theta$-function). The criterion\nis then evaluated using some known and some new results from coding theory\nconcerning the $\\theta$-function of Hamming graphs. As an example, it is shown\nthat if $\\beta>1/2$ and $n\\over k$ -- integer, the ${n\\over k}$-fold repetition\nmap achieving $\\alpha=\\beta$ is asymptotically optimal.\n  Finally, constraints on configurations of points and hyperplanes in\nprojective spaces over $\\mathbb{F}_2$ are derived. \n\n"}
{"id": "1503.04030", "contents": "Title: Totally Distributed Energy-Efficient Transmission in MIMO Interference\n  Channels Abstract: In this paper, we consider the problem of maximizing the energy efficiency\n(EE) for multi-input multi-output (MIMO) interference channels, subject to the\nper-link power constraint. To avoid extensive information exchange among all\nlinks, the optimization problem is formulated as a noncooperative game, where\neach link maximizes its own EE. We show that this game always admits a Nash\nequilibrium (NE) and the sufficient condition for the uniqueness of the NE is\nderived for the case of arbitrary channel matrices, which can be checked in\npractice. To reach the NE of this game, we develop a totally distributed EE\nalgorithm, in which each link updates its own transmit covariance matrix in a\ncompletely distributed and asynchronous way: Some players may update their\nsolutions more frequently than others or even use the outdated interference\ninformation. The sufficient conditions that guarantee the global convergence of\nthe proposed algorithm to the NE of the game have been given as well. We also\nstudy the impact of the circuit power consumption on the sum-EE performance of\nthe proposed algorithm in the case when the links are separated sufficiently\nfar away. Moreover, the tradeoff between the sum-EE and the sum-spectral\nefficiency (SE) is investigated with the proposed algorithm under two special\ncases: 1) low transmit power constraint regime; 2) high transmit power\nconstraint regime. Finally, extensive simulations are conducted to evaluate the\nimpact of various system parameters on the system performance. \n\n"}
{"id": "1503.05225", "contents": "Title: Sketching, Embedding, and Dimensionality Reduction for Information\n  Spaces Abstract: Information distances like the Hellinger distance and the Jensen-Shannon\ndivergence have deep roots in information theory and machine learning. They are\nused extensively in data analysis especially when the objects being compared\nare high dimensional empirical probability distributions built from data.\nHowever, we lack common tools needed to actually use information distances in\napplications efficiently and at scale with any kind of provable guarantees. We\ncan't sketch these distances easily, or embed them in better behaved spaces, or\neven reduce the dimensionality of the space while maintaining the probability\nstructure of the data.\n  In this paper, we build these tools for information distances---both for the\nHellinger distance and Jensen--Shannon divergence, as well as related measures,\nlike the $\\chi^2$ divergence. We first show that they can be sketched\nefficiently (i.e. up to multiplicative error in sublinear space) in the\naggregate streaming model. This result is exponentially stronger than known\nupper bounds for sketching these distances in the strict turnstile streaming\nmodel. Second, we show a finite dimensionality embedding result for the\nJensen-Shannon and $\\chi^2$ divergences that preserves pair wise distances.\nFinally we prove a dimensionality reduction result for the Hellinger,\nJensen--Shannon, and $\\chi^2$ divergences that preserves the information\ngeometry of the distributions (specifically, by retaining the simplex structure\nof the space). While our second result above already implies that these\ndivergences can be explicitly embedded in Euclidean space, retaining the\nsimplex structure is important because it allows us to continue doing inference\nin the reduced space. In essence, we preserve not just the distance structure\nbut the underlying geometry of the space. \n\n"}
{"id": "1503.05365", "contents": "Title: Caching at the Edge: a Green Perspective for 5G Networks Abstract: Endowed with context-awareness and proactive capabilities, caching users'\ncontent locally at the edge of the network is able to cope with increasing data\ntraffic demand in 5G wireless networks. In this work, we focus on the energy\nconsumption aspects of cache-enabled wireless cellular networks, specifically\nin terms of area power consumption (APC) and energy efficiency (EE). We assume\nthat both base stations (BSs) and mobile users are distributed according to\nhomogeneous Poisson point processes (PPPs) and we introduce a detailed power\nmodel that takes into account caching. We study the conditions under which the\narea power consumption is minimized with respect to BS transmit power, while\nensuring a certain quality of service (QoS) in terms of coverage probability.\nFurthermore, we provide the optimal BS transmit power that maximizes the area\nspectral efficiency per unit total power spent. The main takeaway of this paper\nis that caching seems to be an energy efficient solution. \n\n"}
{"id": "1503.08889", "contents": "Title: Interference Prediction in Mobile Ad Hoc Networks with a General\n  Mobility Model Abstract: In a mobile ad hoc network (MANET), effective prediction of time-varying\ninterferences can enable adaptive transmission designs and therefore improve\nthe communication performance. This paper investigates interference prediction\nin MANETs with a finite number of nodes by proposing and using a general-order\nlinear model for node mobility. The proposed mobility model can well\napproximate node dynamics of practical MANETs. In contrast to previous studies\non interference statistics, we are able through this model to give a best\nestimate of the time-varying interference at any time rather than long-term\naverage effects. Specifically, we propose a compound Gaussian point process\nfunctional as a general framework to obtain analytical results on the mean\nvalue and moment-generating function of the interference prediction. With a\nseries form of this functional, we give the necessary and sufficient condition\nfor when the prediction is essentially equivalent to that from a Binomial Point\nProcess (BPP) network in the limit as time goes to infinity. These conditions\npermit one to rigorously determine when the commonly used BPP approximations\nare valid. Finally, our simulation results corroborate the effectiveness and\naccuracy of the analytical results on interference prediction and also show the\nadvantages of our method in dealing with complex mobilities. \n\n"}
{"id": "1503.09002", "contents": "Title: Compressed Channel Feedback for Correlated Massive MIMO Systems Abstract: Massive multiple-input multiple-output (MIMO) is a promising approach for\ncellular communication due to its energy efficiency and high achievable data\nrate. These advantages, however, can be realized only when channel state\ninformation (CSI) is available at the transmitter. Since there are many\nantennas, CSI is too large to feed back without compression. To compress CSI,\nprior work has applied compressive sensing (CS) techniques and the fact that\nCSI can be sparsified. The adopted sparsifying bases fail, however, to reflect\nthe spatial correlation and channel conditions or to be feasible in practice.\nIn this paper, we propose a new sparsifying basis that reflects the long-term\ncharacteristics of the channel, and needs no change as long as the spatial\ncorrelation model does not change. We propose a new reconstruction algorithm\nfor CS, and also suggest dimensionality reduction as a compression method. To\nfeed back compressed CSI in practice, we propose a new codebook for the\ncompressed channel quantization assuming no other-cell interference. Numerical\nresults confirm that the proposed channel feedback mechanisms show better\nperformance in point-to-point (single-user) and point-to-multi-point\n(multi-user) scenarios. \n\n"}
{"id": "1504.00953", "contents": "Title: Outage Analysis of Full-Duplex Architectures in Cellular Networks Abstract: The implementation of full-duplex (FD) radio in wireless communications is a\npotential approach for achieving higher spectral efficiency. A possible\napplication is its employment in the next generation of cellular networks.\nHowever, the performance of large-scale FD multiuser networks is an area mostly\nunexplored. Most of the related work focuses on the performance analysis of\nsmall-scale networks or on loop interference cancellation schemes. In this\npaper, we derive the outage probability performance of large-scale FD cellular\nnetworks in the context of two architectures: two-node and three-node. We show\nhow the performance is affected with respect to the model's parameters and\nprovide a comparison between the two architectures. \n\n"}
{"id": "1504.01123", "contents": "Title: Coded Caching with Heterogenous Cache Sizes Abstract: We investigate the coded caching scheme under heterogenous cache sizes. \n\n"}
{"id": "1504.01218", "contents": "Title: Instantly Decodable Network Coding for Real-Time Scalable Video\n  Broadcast over Wireless Networks Abstract: In this paper, we study a real-time scalable video broadcast over wireless\nnetworks in instantly decodable network coded (IDNC) systems. Such real-time\nscalable video has a hard deadline and imposes a decoding order on the video\nlayers.We first derive the upper bound on the probability that the individual\ncompletion times of all receivers meet the deadline. Using this probability, we\ndesign two prioritized IDNC algorithms, namely the expanding window IDNC\n(EW-IDNC) algorithm and the non-overlapping window IDNC (NOW-IDNC) algorithm.\nThese algorithms provide a high level of protection to the most important video\nlayer before considering additional video layers in coding decisions. Moreover,\nin these algorithms, we select an appropriate packet combination over a given\nnumber of video layers so that these video layers are decoded by the maximum\nnumber of receivers before the deadline. We formulate this packet selection\nproblem as a two-stage maximal clique selection problem over an IDNC graph.\nSimulation results over a real scalable video stream show that our proposed\nEW-IDNC and NOW-IDNC algorithms improve the received video quality compared to\nthe existing IDNC algorithms. \n\n"}
{"id": "1504.02923", "contents": "Title: Compressed Sensing Recovery via Nonconvex Shrinkage Penalties Abstract: The $\\ell^0$ minimization of compressed sensing is often relaxed to $\\ell^1$,\nwhich yields easy computation using the shrinkage mapping known as soft\nthresholding, and can be shown to recover the original solution under certain\nhypotheses. Recent work has derived a general class of shrinkages and\nassociated nonconvex penalties that better approximate the original $\\ell^0$\npenalty and empirically can recover the original solution from fewer\nmeasurements. We specifically examine p-shrinkage and firm thresholding. In\nthis work, we prove that given data and a measurement matrix from a broad class\nof matrices, one can choose parameters for these classes of shrinkages to\nguarantee exact recovery of the sparsest solution. We further prove convergence\nof the algorithm iterative p-shrinkage (IPS) for solving one such relaxed\nproblem. \n\n"}
{"id": "1504.03048", "contents": "Title: The weight distributions of two classes of p ary cyclic codes with few\n  weights Abstract: Cyclic codes have attracted a lot of research interest for decades as they\nhave efficient encoding and decoding algorithms.\n  In this paper, for an odd prime $p$, the weight distributions of two classes\nof $p$-ary cyclic codes are completely determined. We show that both codes have\nat most five nonzero weights. \n\n"}
{"id": "1504.03903", "contents": "Title: Learning to be green: robust energy efficiency maximization in dynamic\n  MIMO-OFDM systems Abstract: In this paper, we examine the maximization of energy efficiency (EE) in\nnext-generation multi-user MIMO-OFDM networks that evolve dynamically over time\n- e.g. due to user mobility, fluctuations in the wireless medium, modulations\nin the users' load, etc. Contrary to the static/stationary regime, the system\nmay evolve in an arbitrary manner so, targeting a fixed optimum state (either\nstatic or in the mean) becomes obsolete; instead, users must adjust to changes\nin the system \"on the fly\", without being able to predict the state of the\nsystem in advance. To tackle these issues, we propose a simple and distributed\nonline optimization policy that leads to no regret, i.e. it allows users to\nmatch (and typically outperform) even the best fixed transmit policy in\nhindsight, irrespective of how the system varies with time. Moreover, to\naccount for the scarcity of perfect channel state information (CSI) in massive\nMIMO systems, we also study the algorithm's robustness in the presence of\nmeasurement errors and observation noise. Importantly, the proposed policy\nretains its no-regret properties under very mild assumptions on the error\nstatistics and, on average, it enjoys the same performance guarantees as in the\nnoiseless, deterministic case. Our analysis is supplemented by extensive\nnumerical simulations which show that, in realistic network environments, users\ntrack their individually optimum transmit profile even under rapidly changing\nchannel conditions, achieving gains of up to 600% in energy efficiency over\nuniform power allocation policies. \n\n"}
{"id": "1504.04080", "contents": "Title: Coordinated Multicasting with Opportunistic User Selection in Multicell\n  Wireless Systems Abstract: Physical layer multicasting with opportunistic user selection (OUS) is\nexamined for multicell multi-antenna wireless systems. By adopting a two-layer\nencoding scheme, a rate-adaptive channel code is applied in each fading block\nto enable successful decoding by a chosen subset of users (which varies over\ndifferent blocks) and an application layer erasure code is employed across\nmultiple blocks to ensure that every user is able to recover the message after\ndecoding successfully in a sufficient number of blocks. The transmit signal and\ncode-rate in each block determine opportunistically the subset of users that\nare able to successfully decode and can be chosen to maximize the long-term\nmulticast efficiency. The employment of OUS not only helps avoid\nrate-limitations caused by the user with the worst channel, but also helps\ncoordinate interference among different cells and multicast groups. In this\nwork, efficient algorithms are proposed for the design of the transmit\ncovariance matrices, the physical layer code-rates, and the target user subsets\nin each block. In the single group scenario, the system parameters are\ndetermined by maximizing the group-rate, defined as the physical layer\ncode-rate times the fraction of users that can successfully decode in each\nblock. In the multi-group scenario, the system parameters are determined by\nconsidering a group-rate balancing optimization problem, which is solved by a\nsuccessive convex approximation (SCA) approach. To further reduce the feedback\noverhead, we also consider the case where only part of the users feed back\ntheir channel vectors in each block and propose a design based on the balancing\nof the expected group-rates. In addition to SCA, a sample average approximation\ntechnique is also introduced to handle the probabilistic terms arising in this\nproblem. The effectiveness of the proposed schemes is demonstrated by computer\nsimulations. \n\n"}
{"id": "1504.05376", "contents": "Title: A Minimax Converse for Quantum Channel Coding Abstract: We prove a one-shot \"minimax\" converse bound for quantum channel coding\nassisted by positive partial transpose channels between sender and receiver.\nThe bound is similar in spirit to the converse by Polyanskiy, Poor, and Verdu\n[IEEE Trans. Info. Theory 56, 2307-2359 (2010)] for classical channel coding,\nand also enjoys the saddle point property enabling the order of optimizations\nto be interchanged. Equivalently, the bound can be formulated as a semidefinite\nprogram satisfying strong duality. The convex nature of the bound implies\nchannel symmetries can substantially simplify the optimization, enabling us to\nexplicitly compute the finite blocklength behavior for several simple qubit\nchannels. In particular, we find that finite blocklength converse statements\nfor the classical erasure channel apply to the assisted quantum erasure\nchannel, while bounds for the classical binary symmetric channel apply to both\nthe assisted dephasing and depolarizing channels. This implies that these qubit\nchannels inherit statements regarding the asymptotic limit of large\nblocklength, such as the strong converse or second-order converse rates, from\ntheir classical counterparts. Moreover, for the dephasing channel, the finite\nblocklength bounds are as tight as those for the classical binary symmetric\nchannel, since coding for classical phase errors yields equivalently-performing\nunassisted quantum codes. \n\n"}
{"id": "1504.05999", "contents": "Title: Securing Data against Limited-Knowledge Adversaries in Distributed\n  Storage Systems Abstract: We study the problem of constructing secure regenerating codes that protect\ndata integrity in distributed storage systems (DSS) in which some nodes may be\ncompromised by a malicious adversary. The adversary can corrupt the data stored\non and transmitted by the nodes under its control. The \"damage\" incurred by the\nactions of the adversary depends on how much information it knows about the\ndata in the whole DSS. We focus on the limited-knowledge model in which the\nadversary knows only the data on the nodes under its control. The only secure\ncapacity-achieving codes known in the literature for this model are for the\nbandwidth-limited regime and repair degree $d=n-1$, i.e., when a node fails in\na DSS with $n$ nodes all the remaining $n-1$ nodes are contacted for repair. We\nextend these results to the more general case of $d\\leq n-1$ in the\nbandwidth-limited regime. Our capacity-achieving scheme is based on the use of\nproduct-matrix codes with special hashing functions and allow the\nidentification of the compromised nodes and their elimination from the DSS\nwhile preserving the data integrity. \n\n"}
{"id": "1504.06046", "contents": "Title: On the One-Shot Zero-Error Classical Capacity of Classical-Quantum\n  Channels Assisted by Quantum Non-signalling Correlations Abstract: Duan and Winter studied the one-shot zero-error classical capacity of a\nquantum channel assisted by quantum non-signalling correlations, and formulated\nthis problem as a semidefinite program depending only on the Kraus operator\nspace of the channel. For the class of classical-quantum channels, they showed\nthat the asymptotic zero-error classical capacity assisted by quantum\nnon-signalling correlations, minimized over all classical-quantum channels with\na confusability graph $G$, is exactly $\\log \\vartheta(G)$, where $\\vartheta(G)$\nis the celebrated Lov\\'{a}sz theta function. In this paper, we show that the\none-shot capacity for a classical-quantum channel, induced from a circulant\ngraph $G$ defined by equal-sized cyclotomic cosets, is $\\log \\lfloor\n\\vartheta(G) \\rfloor$, which further implies that its asymptotic capacity is\n$\\log \\vartheta(G)$. This type of graphs include the cycle graphs of odd\nlength, the Paley graphs of prime vertices, and the cubit residue graphs of\nprime vertices. Examples of other graphs are also discussed. This endows the\nLov\\'{a}sz $\\theta$ function with a more straightforward operational meaning. \n\n"}
{"id": "1504.06136", "contents": "Title: Broadcast Channels with Privacy Leakage Constraints Abstract: The broadcast channel (BC) with one common and two private messages with\nleakage constraints is studied, where leakage rate refers to the normalized\nmutual information between a message and a channel symbol string. Each private\nmessage is destined for a different user and the leakage rate to the other\nreceiver must satisfy a constraint. This model captures several scenarios\nconcerning secrecy, i.e., when both, either or neither of the private messages\nare secret. Inner and outer bounds on the leakage-capacity region are derived\nwhen the eavesdropper knows the codebook. The inner bound relies on a\nMarton-like code construction and the likelihood encoder. A Uniform\nApproximation Lemma is established that states that the marginal distribution\ninduced by the encoder on each of the bins in the Marton codebook is\napproximately uniform. Without leakage constraints the inner bound recovers\nMarton's region and the outer bound reduces to the UVW-outer bound. The bounds\nmatch for semi-deterministic (SD) and physically degraded (PD) BCs, as well as\nfor BCs with a degraded message set. The leakage-capacity regions of the SD-BC\nand the BC with a degraded message set recover past results for different\nsecrecy scenarios. A Blackwell BC example illustrates the results and shows how\nits leakage-capacity region changes from the capacity region without secrecy to\nthe secrecy-capacity regions for different secrecy scenarios. \n\n"}
{"id": "1504.06249", "contents": "Title: Quantifying Loss of Information in Network-based Dimensionality\n  Reduction Techniques Abstract: To cope with the complexity of large networks, a number of dimensionality\nreduction techniques for graphs have been developed. However, the extent to\nwhich information is lost or preserved when these techniques are employed has\nnot yet been clear. Here we develop a framework, based on algorithmic\ninformation theory, to quantify the extent to which information is preserved\nwhen network motif analysis, graph spectra and spectral sparsification methods\nare applied to over twenty different biological and artificial networks. We\nfind that the spectral sparsification is highly sensitive to high number of\nedge deletion, leading to significant inconsistencies, and that graph spectral\nmethods are the most irregular, capturing algebraic information in a condensed\nfashion but largely losing most of the information content of the original\nnetworks. However, the approach shows that network motif analysis excels at\npreserving the relative algorithmic information content of a network, hence\nvalidating and generalizing the remarkable fact that despite their inherent\ncombinatorial possibilities, local regularities preserve information to such an\nextent that essential properties are fully recoverable across different\nnetworks to determine their family group to which they belong to (eg genetic vs\nsocial network). Our algorithmic information methodology thus provides a\nrigorous framework enabling a fundamental assessment and comparison between\ndifferent data dimensionality reduction methods thereby facilitating the\nidentification and evaluation of the capabilities of old and new methods. \n\n"}
{"id": "1504.07566", "contents": "Title: Designing Wireless Broadband Access for Energy Efficiency: Are Small\n  Cells the Only Answer? Abstract: The main usage of cellular networks has changed from voice to data traffic,\nmostly requested by static users. In this paper, we analyze how a cellular\nnetwork should be designed to provide such wireless broadband access with\nmaximal energy efficiency (EE). Using stochastic geometry and a detailed power\nconsumption model, we optimize the density of access points (APs), number of\nantennas and users per AP, and transmission power for maximal EE. Small cells\nare of course a key technology in this direction, but the analysis shows that\nthe EE improvement of a small-cell network saturates quickly with the AP\ndensity and then \"massive MIMO\" techniques can further improve the EE. \n\n"}
{"id": "1504.08070", "contents": "Title: Universal Compression of Power-Law Distributions Abstract: English words and the outputs of many other natural processes are well-known\nto follow a Zipf distribution. Yet this thoroughly-established property has\nnever been shown to help compress or predict these important processes. We show\nthat the expected redundancy of Zipf distributions of order $\\alpha>1$ is\nroughly the $1/\\alpha$ power of the expected redundancy of unrestricted\ndistributions. Hence for these orders, Zipf distributions can be better\ncompressed and predicted than was previously known. Unlike the expected case,\nwe show that worst-case redundancy is roughly the same for Zipf and for\nunrestricted distributions. Hence Zipf distributions have significantly\ndifferent worst-case and expected redundancies, making them the first natural\ndistribution class shown to have such a difference. \n\n"}
{"id": "1505.00484", "contents": "Title: Limited Feedback in Multiple-Antenna Systems with One-Bit Quantization Abstract: Communication systems with low-resolution analog-to-digital-converters (ADCs)\ncan exploit channel state information at the transmitter (CSIT) and receiver.\nThis paper presents initial results on codebook design and performance analysis\nfor limited feedback systems with one-bit ADCs. Different from the\nhigh-resolution case, the absolute phase at the receiver is important to align\nthe phase of the received signals when the received signal is sliced by one-bit\nADCs. A new codebook design for the beamforming case is proposed that\nseparately quantizes the channel direction and the residual phase. \n\n"}
{"id": "1505.00769", "contents": "Title: On Non-Interactive Simulation of Joint Distributions Abstract: We consider the following non-interactive simulation problem: Alice and Bob\nobserve sequences $X^n$ and $Y^n$ respectively where $\\{(X_i, Y_i)\\}_{i=1}^n$\nare drawn i.i.d. from $P(x,y),$ and they output $U$ and $V$ respectively which\nis required to have a joint law that is close in total variation to a specified\n$Q(u,v).$ It is known that the maximal correlation of $U$ and $V$ must\nnecessarily be no bigger than that of $X$ and $Y$ if this is to be possible.\nOur main contribution is to bring hypercontractivity to bear as a tool on this\nproblem. In particular, we show that if $P(x,y)$ is the doubly symmetric binary\nsource, then hypercontractivity provides stronger impossibility results than\nmaximal correlation. Finally, we extend these tools to provide impossibility\nresults for the $k$-agent version of this problem. \n\n"}
{"id": "1505.00810", "contents": "Title: Optimizing Data Aggregation for Uplink Machine-to-Machine Communication\n  Networks Abstract: Machine-to-machine (M2M) communication's severe power limitations challenge\nthe interconnectivity, access management, and reliable communication of data.\nIn densely deployed M2M networks, controlling and aggregating the generated\ndata is critical. We propose an energy efficient data aggregation scheme for a\nhierarchical M2M network. We develop a coverage probability-based optimal data\naggregation scheme for M2M devices to minimize the average total energy\nexpenditure per unit area per unit time or simply the {\\em energy density} of\nan M2M communication network. Our analysis exposes the key tradeoffs between\nthe energy density of the M2M network and the coverage characteristics for\nsuccessive and parallel transmission schemes that can be either half-duplex or\nfull-duplex. Comparing the rate and energy performances of the transmission\nmodels, we observe that successive mode and half-duplex parallel mode have\nbetter coverage characteristics compared to full-duplex parallel scheme.\nSimulation results show that the uplink coverage characteristics dominate the\ntrend of the energy consumption for both successive and parallel schemes. \n\n"}
{"id": "1505.01016", "contents": "Title: Joint Cache-Channel Coding over Erasure Broadcast Channels Abstract: We consider a cache-aided communications system in which a transmitter\ncommunicates with many receivers over an erasure broadcast channel. The system\nserves as a basic model for communicating on-demand content during periods of\nhigh network congestion, where some content can be pre-placed in local caches\nnear the receivers. We formulate the cache-aided communications problem as a\njoint cache-channel coding problem, and characterise some information-theoretic\ntradeoffs between reliable communications rates and cache sizes. We show that\nif the receivers experience different channel qualities, then using unequal\ncache sizes and joint cache-channel coding improves system efficiency. \n\n"}
{"id": "1505.01110", "contents": "Title: Zero Error Coordination Abstract: In this paper, we consider a zero error coordination problem wherein the\nnodes of a network exchange messages to be able to perfectly coordinate their\nactions with the individual observations of each other. While previous works on\ncoordination commonly assume an asymptotically vanishing error, we assume\nexact, zero error coordination. Furthermore, unlike previous works that employ\nthe empirical or strong notions of coordination, we define and use a notion of\nset coordination. This notion of coordination bears similarities with the\nempirical notion of coordination. We observe that set coordination, in its\nspecial case of two nodes with a one-way communication link is equivalent with\nthe \"Hide and Seek\" source coding problem of McEliece and Posner. The Hide and\nSeek problem has known intimate connections with graph entropy, rate distortion\ntheory, Renyi mutual information and even error exponents. Other special cases\nof the set coordination problem relate to Witsenhausen's zero error rate and\nthe distributed computation problem. These connections motivate a better\nunderstanding of set coordination, its connections with empirical coordination,\nand its study in more general setups. This paper takes a first step in this\ndirection by proving new results for two node networks. \n\n"}
{"id": "1506.00598", "contents": "Title: Energy Efficiency and Sum Rate Tradeoffs for Massive MIMO Systems with\n  Underlaid Device-to-Device Communications Abstract: In this paper, we investigate the coexistence of two technologies that have\nbeen put forward for the fifth generation (5G) of cellular networks, namely,\nnetwork-assisted device-to-device (D2D) communications and massive MIMO\n(multiple-input multiple-output). Potential benefits of both technologies are\nknown individually, but the tradeoffs resulting from their coexistence have not\nbeen adequately addressed. To this end, we assume that D2D users reuse the\ndownlink resources of cellular networks in an underlay fashion. In addition,\nmultiple antennas at the BS are used in order to obtain precoding gains and\nsimultaneously support multiple cellular users using multiuser or massive MIMO\ntechnique. Two metrics are considered, namely the average sum rate (ASR) and\nenergy efficiency (EE). We derive tractable and directly computable expressions\nand study the tradeoffs between the ASR and EE as functions of the number of BS\nantennas, the number of cellular users and the density of D2D users within a\ngiven coverage area. Our results show that both the ASR and EE behave\ndifferently in scenarios with low and high density of D2D users, and that\ncoexistence of underlay D2D communications and massive MIMO is mainly\nbeneficial in low densities of D2D users. \n\n"}
{"id": "1506.02420", "contents": "Title: On the Feasibility of Wireless Energy Transfer Using Massive Antenna\n  Arrays Abstract: We illustrate potential benefits of using massive antenna arrays for wireless\nenergy transfer (WET). Specifically, we analyze probability of outage in WET\nover fading channels when a base station (BS) with multiple antennas beamforms\nenergy to a wireless sensor node (WSN). Our analytical results show that by\nusing massive antenna arrays, the range of WET can be increased for a given\ntarget outage probability. We prove that by using multiple-antenna arrays at\nthe BS, a lower downlink energy is required to get the same outage performance,\nresulting into savings of radiated energy. We show that for energy levels used\nin WET, the outage performance with least-squares or minimum mean-square error\nchannel estimates is same as that obtained based on perfect channel estimates.\nWe observe that a strong line-of-sight component between the BS and WSN lowers\noutage probability. Furthermore, by deploying more antennas at the BS, a larger\nenergy can be transferred reliably to the WSN at a given target outage\nperformance for the sensor to be able to perform its main tasks. In our\nnumerical examples, the RF power received at the input of the sensor is assumed\nto be on the order of a mW, such that the rectenna operates at an efficiency in\nthe order of 50 %. \n\n"}
{"id": "1506.02677", "contents": "Title: Convex Optimization Approach for Stable Decomposition of Stream of\n  Pulses Abstract: This paper deals with the problem of estimating the delays and amplitudes of\na weighted superposition of pulses, called stream of pulses. This problem is\nmotivated by a variety of applications, such as ultrasound and radar. This\npaper shows that the recovery error of a tractable convex optimization problem\nis proportional to the noise level. Additionally, the estimated delays are\nclustered around the true delays. This holds provided that the pulse meets a\nfew mild localization properties and that a separation condition holds. If the\namplitudes are known to be positive, the separation is unnecessary. In this\ncase, the recovery error is proportional to the noise level and depends on the\nmaximal number of delays within a resolution cell. \n\n"}
{"id": "1506.02792", "contents": "Title: Capacity of the AWGN Channel with Random Battery Recharges Abstract: We consider communication over the AWGN channel with a transmitter whose\nbattery is recharged with RF energy transfer at random times known to the\nreceiver. We assume that the recharging process is i.i.d. Bernoulli. We\ncharacterize the capacity of this channel as the limit of an $n$-letter maximum\nmutual information rate under both causal and noncausal transmitter knowledge\nof the battery recharges. With noncausal knowledge, it is possible to\nexplicitly identify the maximizing input distribution, which we use to\ndemonstrate that the capacity with noncausal knowledge of the battery recharges\nis strictly larger than that with causal knowledge. We then proceed to derive\nexplicit upper and lower bounds on the capacity, which are within 1.05\nbits/s/Hz of each other for all parameter values. \n\n"}
{"id": "1506.03144", "contents": "Title: Superresolution without Separation Abstract: This paper provides a theoretical analysis of diffraction-limited\nsuperresolution, demonstrating that arbitrarily close point sources can be\nresolved in ideal situations. Precisely, we assume that the incoming signal is\na linear combination of M shifted copies of a known waveform with unknown\nshifts and amplitudes, and one only observes a finite collection of evaluations\nof this signal. We characterize properties of the base waveform such that the\nexact translations and amplitudes can be recovered from 2M + 1 observations.\nThis recovery is achieved by solving a a weighted version of basis pursuit over\na continuous dictionary. Our methods combine classical polynomial interpolation\ntechniques with contemporary tools from compressed sensing. \n\n"}
{"id": "1506.03324", "contents": "Title: On the High-SNR Capacity of the Gaussian Interference Channel and New\n  Capacity Bounds Abstract: The best outer bound on the capacity region of the two-user Gaussian\nInterference Channel (GIC) is known to be the intersection of regions of\nvarious bounds including genie-aided outer bounds, in which a genie provides\nnoisy input signals to the intended receiver. The Han and Kobayashi (HK) scheme\nprovides the best known inner bound. The rate difference between the best known\nlower and upper bounds on the sum capacity remains as large as 1 bit per\nchannel use especially around $g^2=P^{-1/3}$, where $P$ is the symmetric power\nconstraint and $g$ is the symmetric real cross-channel coefficient. In this\npaper, we pay attention to the \\emph{moderate interference regime} where\n$g^2\\in (\\max(0.086, P^{-1/3}),1)$. We propose a new upper-bounding technique\nthat utilizes noisy observation of interfering signals as genie signals and\napplies time sharing to the genie signals at the receivers. A conditional\nversion of the worst additive noise lemma is also introduced to derive new\ncapacity bounds. The resulting upper (outer) bounds on the sum capacity\n(capacity region) are shown to be tighter than the existing bounds in a certain\nrange of the moderate interference regime. Using the new upper bounds and the\nHK lower bound, we show that $R_\\text{sym}^*=\\frac{1}{2}\\log\n\\big(|g|P+|g|^{-1}(P+1)\\big)$ characterizes the capacity of the symmetric real\nGIC to within $0.104$ bit per channel use in the moderate interference regime\nat any signal-to-noise ratio (SNR). We further establish a high-SNR\ncharacterization of the symmetric real GIC, where the proposed upper bound is\nat most $0.1$ bit far from a certain HK achievable scheme with Gaussian\nsignaling and time sharing for $g^2\\in (0,1]$. In particular, $R_\\text{sym}^*$\nis achievable at high SNR by the proposed HK scheme and turns out to be the\nhigh-SNR capacity at least at $g^2=0.25, 0.5$. \n\n"}
{"id": "1506.04583", "contents": "Title: On the Benefits of Edge Caching for MIMO Interference Alignment Abstract: In this contribution, we jointly investigate the benefits of caching and\ninterference alignment (IA) in multiple-input multiple-output (MIMO)\ninterference channel under limited backhaul capacity. In particular, total\naverage transmission rate is derived as a function of various system parameters\nsuch as backhaul link capacity, cache size, number of active\ntransmitter-receiver pairs as well as the quantization bits for channel state\ninformation (CSI). Given the fact that base stations are equipped both with\ncaching and IA capabilities and have knowledge of content popularity profile,\nwe then characterize an operational regime where the caching is beneficial.\nSubsequently, we find the optimal number of transmitter-receiver pairs that\nmaximizes the total average transmission rate. When the popularity profile of\nrequested contents falls into the operational regime, it turns out that caching\nsubstantially improves the throughput as it mitigates the backhaul usage and\nallows IA methods to take benefit of such limited backhaul. \n\n"}
{"id": "1506.04830", "contents": "Title: Maximizing the Link Throughput between Smart-meters and Aggregators as\n  Secondary Users under Power and Outage Constraints Abstract: This paper assesses the communication link from smart meters to aggregators\nas (unlicensed) secondary users that transmit their data over the (licensed)\nprimary uplink channel. The proposed scenario assumes: (i) meters' and\naggregators' positions are fixed so highly directional antennas are employed,\n(ii) secondary users transmit with limited power in relation to the primary,\n(iii) meters' transmissions are coordinated to avoid packet collisions, and\n(iv) the secondary links' robustness is guaranteed by an outage constraint.\nUnder these assumptions, the interference caused by secondary users in both\nprimary (base-stations) and other secondary users can be neglected. As\nunlicensed users, however, meter-aggregator links do experience interference\nfrom the mobile users of the primary network, whose positions and traffic\nactivity are unknown. To cope with this uncertainty, we model the mobile users\nspatial distribution as a Poisson point process. We then derive a closed-form\nsolution for the maximum achievable throughput with respect to a reference\nsecondary link subject to transmit power and outage constraints. Our numerical\nresults illustrate the effects of such constraints on the optimal throughput,\nevincing that more frequent outage events improve the system performance in the\nscenario under study. We also show that relatively high outage probabilities\nhave little effect on the reconstruction of the average power demand curve that\nis transmitted from the smart-meter to the aggregator. \n\n"}
{"id": "1506.06484", "contents": "Title: Cross-layer estimation and control for Cognitive Radio: Exploiting\n  Sparse Network Dynamics Abstract: In this paper, a cross-layer framework to jointly optimize spectrum sensing\nand scheduling in resource constrained agile wireless networks is presented. A\nnetwork of secondary users (SUs) accesses portions of the spectrum left unused\nby a network of licensed primary users (PUs). A central controller (CC)\nschedules the traffic of the SUs, based on distributed compressed measurements\ncollected by the SUs. Sensing and scheduling are jointly controlled to maximize\nthe SU throughput, with constraints on PU throughput degradation and SU cost.\nThe sparsity in the spectrum dynamics is exploited: leveraging a prior spectrum\noccupancy estimate, the CC needs to estimate only a residual uncertainty vector\nvia sparse recovery techniques. The high complexity entailed by the POMDP\nformulation is reduced by a low-dimensional belief representation via\nminimization of the Kullback-Leibler divergence. It is proved that the\noptimization of sensing and scheduling can be decoupled. A partially myopic\nscheduling strategy is proposed for which structural properties can be proved\nshowing that the myopic scheme allocates SU traffic to likely idle spectral\nbands. Simulation results show that this framework balances optimally the\nresources between spectrum sensing and data transmission. This framework\ndefines sensing-scheduling schemes most informative for network control,\nyielding energy efficient resource utilization. \n\n"}
{"id": "1506.07196", "contents": "Title: Bounds on the Parameters of Locally Recoverable Codes Abstract: A locally recoverable code (LRC code) is a code over a finite alphabet such\nthat every symbol in the encoding is a function of a small number of other\nsymbols that form a recovering set. In this paper we derive new finite-length\nand asymptotic bounds on the parameters of LRC codes. For LRC codes with a\nsingle recovering set for every coordinate, we derive an asymptotic\nGilbert-Varshamov type bound for LRC codes and find the maximum attainable\nrelative distance of asymptotically good LRC codes. Similar results are\nestablished for LRC codes with two disjoint recovering sets for every\ncoordinate. For the case of multiple recovering sets we derive a lower bound on\nthe parameters using expander graph arguments. Finally, we also derive\nfinite-length upper bounds on the rate and distance of LRC codes with multiple\nrecovering sets. \n\n"}
{"id": "1506.07331", "contents": "Title: On the Design of Channel Shortening Demodulators for Iterative Receivers\n  in MIMO and ISI Channels Abstract: We consider the problem of designing demodulators for linear vector channels\nwith memory that use reduced-size trellis descriptions for the received signal.\nWe assume an overall iterative receiver, and for the parts of the signal not\ncovered by the trellis description, we use interference cancelation based on\nthe soft information provided by the outer decoder. In order to reach a trellis\ndescription, a linear filter is applied as front-end to compress the signal\nstructure into a small trellis. This process requires three parameters to be\ndesigned: (i) the front-end filter, (ii) the feedback filter through which the\ninterference cancelation is done, and (iii) a target response which specifies\nthe trellis. Demodulators of this form have been studied before under then name\nchannel shortening (CS), but the interplay between CS and interference\ncancelation has not been adequately addressed in the literature. In this paper,\nwe analyze two types of CS demodulators that are based on the Forney and\nUngerboeck detection models, respectively. The parameters are jointly optimized\nbased on a generalized mutual information (GMI) function. We also introduce a\nthird type of CS demodulator that is in general suboptimal but has closed form\nsolutions for all parameters. Moreover, signal to noise ratio (SNR) asymptotic\nproperties are analyzed and we show that the third CS demodulator\nasymptotically converges to the optimal CS demodulator in the sense of\nmaximizing the GMI. \n\n"}
{"id": "1506.08269", "contents": "Title: Construction $\\pi_A$ and $\\pi_D$ Lattices: Construction, Goodness, and\n  Decoding Algorithms Abstract: A novel construction of lattices is proposed. This construction can be\nthought of as a special class of Construction A from codes over finite rings\nthat can be represented as the Cartesian product of $L$ linear codes over\n$\\mathbb{F}_{p_1},\\ldots,\\mathbb{F}_{p_L}$, respectively, and hence is referred\nto as Construction $\\pi_A$. The existence of a sequence of such lattices that\nis good for channel coding (i.e., Poltyrev-limit achieving) under multistage\ndecoding is shown. A new family of multilevel nested lattice codes based on\nConstruction $\\pi_A$ lattices is proposed and its achievable rate for the\nadditive white Gaussian channel is analyzed. A generalization named\nConstruction $\\pi_D$ is also investigated which subsumes Construction A with\ncodes over prime fields, Construction D, and Construction $\\pi_A$ as special\ncases. \n\n"}
{"id": "1507.01234", "contents": "Title: Estimating the Directed Information and Testing for Causality Abstract: The problem of estimating the directed information rate between two discrete\nprocesses $\\{X_n\\}$ and $\\{Y_n\\}$ via the plug-in (or maximum-likelihood)\nestimator is considered. When the joint process $\\{(X_n,Y_n)\\}$ is a Markov\nchain of a given memory length, the plug-in estimator is shown to be\nasymptotically Gaussian and to converge at the optimal rate $O(1/\\sqrt{n})$\nunder appropriate conditions; this is the first estimator that has been shown\nto achieve this rate. An important connection is drawn between the problem of\nestimating the directed information rate and that of performing a hypothesis\ntest for the presence of causal influence between the two processes. Under\nfairly general conditions, the null hypothesis, which corresponds to the\nabsence of causal influence, is equivalent to the requirement that the directed\ninformation rate be equal to zero. In that case a finer result is established,\nshowing that the plug-in converges at the faster rate $O(1/n)$ and that it is\nasymptotically $\\chi^2$-distributed. This is proved by showing that this\nestimator is equal to (a scalar multiple of) the classical likelihood ratio\nstatistic for the above hypothesis test. Finally it is noted that these results\nfacilitate the design of an actual likelihood ratio test for the presence or\nabsence of causal influence. \n\n"}
{"id": "1507.01248", "contents": "Title: Compressive Hyperspectral Imaging via Approximate Message Passing Abstract: We consider a compressive hyperspectral imaging reconstruction problem, where\nthree-dimensional spatio-spectral information about a scene is sensed by a\ncoded aperture snapshot spectral imager (CASSI). The CASSI imaging process can\nbe modeled as suppressing three-dimensional coded and shifted voxels and\nprojecting these onto a two-dimensional plane, such that the number of acquired\nmeasurements is greatly reduced. On the other hand, because the measurements\nare highly compressive, the reconstruction process becomes challenging. We\npreviously proposed a compressive imaging reconstruction algorithm that is\napplied to two-dimensional images based on the approximate message passing\n(AMP) framework. AMP is an iterative algorithm that can be used in signal and\nimage reconstruction by performing denoising at each iteration. We employed an\nadaptive Wiener filter as the image denoiser, and called our algorithm\n\"AMP-Wiener.\" In this paper, we extend AMP-Wiener to three-dimensional\nhyperspectral image reconstruction, and call it \"AMP-3D-Wiener.\" Applying the\nAMP framework to the CASSI system is challenging, because the matrix that\nmodels the CASSI system is highly sparse, and such a matrix is not suitable to\nAMP and makes it difficult for AMP to converge. Therefore, we modify the\nadaptive Wiener filter and employ a technique called damping to solve for the\ndivergence issue of AMP. Our approach is applied in nature, and the numerical\nexperiments show that AMP-3D-Wiener outperforms existing widely-used algorithms\nsuch as gradient projection for sparse reconstruction (GPSR) and two-step\niterative shrinkage/thresholding (TwIST) given a similar amount of runtime.\nMoreover, in contrast to GPSR and TwIST, AMP-3D-Wiener need not tune any\nparameters, which simplifies the reconstruction process. \n\n"}
{"id": "1507.01308", "contents": "Title: Identifiability and Stability in Blind Deconvolution under Minimal\n  Assumptions Abstract: Blind deconvolution (BD) arises in many applications. Without assumptions on\nthe signal and the filter, BD does not admit a unique solution. In practice,\nsubspace or sparsity assumptions have shown the ability to reduce the search\nspace and yield the unique solution. However, existing theoretical analysis on\nuniqueness in BD is rather limited. In an earlier paper, we provided the first\nalgebraic sample complexities for BD that hold for almost all bases or frames.\nWe showed that for BD of a pair of vectors in $\\mathbb{C}^n$, with subspace\nconstraints of dimensions $m_1$ and $m_2$, respectively, a sample complexity of\n$n\\geq m_1m_2$ is sufficient. This result is suboptimal, since the number of\ndegrees of freedom is merely $m_1+m_2-1$. We provided analogus results, with\nsimilar suboptimality, for BD with sparsity or mixed subspace and sparsity\nconstraints. In this paper, taking advantage of the recent progress on the\ninformation-theoretic limits of unique low-rank matrix recovery, we finally\nbridge this gap, and derive an optimal sample complexity result for BD with\ngeneric bases or frames. We show that for BD of an arbitrary pair (resp. all\npairs) of vectors in $\\mathbb{C}^n$, with sparsity constraints of sparsity\nlevels $s_1$ and $s_2$, a sample complexity of $n > s_1+s_2$ (resp. $n >\n2(s_1+s_2)$) is sufficient. We also present analogous results for BD with\nsubspace constraints or mixed constraints, with the subspace dimension\nreplacing the sparsity level. Last but not least, in all the above scenarios,\nif the bases or frames follow a probabilistic distribution specified in the\npaper, the recovery is not only unique, but also stable against small\nperturbations in the measurements, under the same sample complexities. \n\n"}
{"id": "1507.05352", "contents": "Title: I/Q-Imbalance Self-Interference Coordination Abstract: In this paper, we present a novel low-complexity scheme, which improves the\nperformance of single-antenna multi-carrier communication systems, suffering\nfrom in-phase and quadrature (I/Q)-imbalance (IQI) at the receiver. We refer to\nthe proposed scheme as I/Q-imbalance self-interference coordination (IQSC).\nIQSC does not only mitigate the detrimental effects of IQI, but, through\nappropriate signal processing, also coordinates the self-interference terms\nproduced by IQI in order to achieve second-order frequency diversity. However,\nthese benefits come at the expense of a reduction in transmission rate. More\nspecifically, IQSC is a simple transmit diversity scheme that improves the\nsignal quality at the receiver by elementary signal processing operations\nacross symmetric (mirror) pairs of subcarriers. Thereby, the proposed\ntransmission protocol has a similar complexity as Alamouti's space-time block\ncoding scheme and does not require extra transmit power nor any feedback. To\nevaluate the performance of IQSC, we derive closed-form expressions for the\nresulting outage probability and symbol error rate. Interestingly, IQSC\noutperforms not only existing IQI compensation schemes but also the ideal\nsystem without IQI for the same spectral efficiency and practical target error\nrates, while it achieves almost the same performance as ideal (i.e., IQI-free)\nequal-rate repetition coding. Our findings reveal that IQSC is a promising\nlow-complexity technique for significantly increasing the reliability of\nlow-cost devices that suffer from high levels of IQI. \n\n"}
{"id": "1507.07419", "contents": "Title: A Tractable Metric for Evaluating Base Station Geometries in Cellular\n  Network Localization Abstract: In this letter, we present a new metric for characterizing the geometric\nconditions encountered in cellular positioning based on the angular spread of\nthe base stations (BSs). The metric is shown to be closely related to the\ngeometric-dilution-of-precision (GDOP), yet has the benefit of being\ncharacterizable in terms of the network parameters for BS layouts modeled\naccording to a Poisson point process (PPP). As an additional benefit, the\nmetric is shown to immediately yield a device's probability of being inside or\noutside the convex hull of the BSs, which localization researchers will\nwidely-recognize as being a strong indicator of localization performance. \n\n"}
{"id": "1508.00140", "contents": "Title: Resilient Backhaul Network Design Using Hybrid Radio/Free-Space Optical\n  Technology Abstract: The radio-frequency (RF) technology is a scalable solution for the backhaul\nplanning. However, its performance is limited in terms of data rate and\nlatency. Free Space Optical (FSO) backhaul, on the other hand, offers a higher\ndata rate but is sensitive to weather conditions. To combine the advantages of\nRF and FSO backhauls, this paper proposes a cost-efficient backhaul network\nusing the hybrid RF/FSO technology. To ensure a resilient backhaul, the paper\nimposes a given degree of redundancy by connecting each node through $K$\nlink-disjoint paths so as to cope with potential link failures. Hence, the\nnetwork planning problem considered in this paper is the one of minimizing the\ntotal deployment cost by choosing the appropriate link type, i.e., either\nhybrid RF/FSO or optical fiber (OF), between each couple of base-stations while\nguaranteeing $K$ link-disjoint connections, a data rate target, and a\nreliability threshold. The paper solves the problem using graph theory\ntechniques. It reformulates the problem as a maximum weight clique problem in\nthe planning graph, under a specified realistic assumption about the cost of OF\nand hybrid RF/FSO links. Simulation results show the cost of the different\nplanning and suggest that the proposed heuristic solution has a\nclose-to-optimal performance for a significant gain in computation complexity. \n\n"}
{"id": "1508.00522", "contents": "Title: Explicit Frames for Deterministic Phase Retrieval via PhaseLift Abstract: We explicitly give a frame of cardinality $5n-6$ such that every signal in\n$\\mathbb{C}^n$ can be recovered up to a phase from its associated intensity\nmeasurements via the PhaseLift approach. Furthermore, we give explicit linear\nmeasurements with $4r(n-r)+n-2r$ outcomes that enable the recovery of every\npositive semidefinite $n\\times n$ matrix of rank at most $r$. \n\n"}
{"id": "1508.00527", "contents": "Title: On the Base Station Association Problem in HetSNets Abstract: The dense deployment of small-cell base stations in HetSNets requires\nefficient resource allocation techniques. More precisely, the problem of\nassociating users to SBSs must be revised and carefully studied. This problem\nis NP-hard and requires solving an integer optimization problem. In order to\nefficiently solve this problem, we model it using non-cooperative game theory.\nFirst, we design two non-cooperative games to solve the problem and show the\nexistence of pure Nash equilibria (PNE) in both games. These equilibria are\nshown to be far from the social optimum. Hence, we propose a better game design\nin order to approach this optimum. This new game is proved to have no PNE in\ngeneral. However, simulations show, for Rayleigh fading channels, that a PNE\nalways exists for all instances of the game. In addition, we show that its\nprices of anarchy and stability are close to one. We propose a best response\ndynamics (BRD) algorithm that converges to a PNE when it exists. Because of the\nhigh information exchange of BRD, a completely distributed algorithm, based on\nthe theory of learning, is proposed. Simulations show that this algorithm has\ntight-to-optimal performance and further it converges to a PNE (when existing)\nwith high probability. \n\n"}
{"id": "1508.01617", "contents": "Title: Distributed and Optimal Resource Allocation for Power Beacon-Assisted\n  Wireless-Powered Communications Abstract: In this paper, we investigate optimal resource allocation in a power\nbeacon-assisted wireless-powered communication network (PB-WPCN), which\nconsists of a set of hybrid access point (AP)-source pairs and a power beacon\n(PB). Each source, which has no embedded power supply, first harvests energy\nfrom its associated AP and/or the PB in the downlink (DL) and then uses the\nharvested energy to transmit information to its AP in the uplink (UL). We\nconsider both cooperative and non-cooperative scenarios based on whether the PB\nis cooperative with the APs or not. For the cooperative scenario, we formulate\na social welfare maximization problem to maximize the weighted sum-throughput\nof all AP-source pairs, which is subsequently solved by a water-filling based\ndistributed algorithm. In the non-cooperative scenario, all the APs and the PB\nare assumed to be rational and self-interested such that incentives from each\nAP are needed for the PB to provide wireless charging service. We then\nformulate an auction game and propose an auction based distributed algorithm by\nconsidering the PB as the auctioneer and the APs as the bidders. Finally,\nnumerical results are performed to validate the convergence of both the\nproposed algorithms and demonstrate the impacts of various system parameters. \n\n"}
{"id": "1508.01773", "contents": "Title: Capacity and Power Scaling Laws for Finite Antenna MIMO\n  Amplify-and-Forward Relay Networks Abstract: In this paper, we present a novel framework that can be used to study the\ncapacity and power scaling properties of linear multiple-input multiple-output\n(MIMO) $d\\times d$ antenna amplify-and-forward (AF) relay networks. In\nparticular, we model these networks as random dynamical systems (RDS) and\ncalculate their $d$ Lyapunov exponents. Our analysis can be applied to systems\nwith any per-hop channel fading distribution, although in this contribution we\nfocus on Rayleigh fading. Our main results are twofold: 1) the total transmit\npower at the $n$th node will follow a deterministic trajectory through the\nnetwork governed by the network's maximum Lyapunov exponent, 2) the capacity of\nthe $i$th eigenchannel at the $n$th node will follow a deterministic trajectory\nthrough the network governed by the network's $i$th Lyapunov exponent. Before\nconcluding, we concentrate on some applications of our results. In particular,\nwe show how the Lyapunov exponents are intimately related to the rate at which\nthe eigenchannel capacities diverge from each other, and how this relates to\nthe amplification strategy and number of antennas at each relay. We also use\nthem to determine the extra cost in power associated with each extra\nmultiplexed data stream. \n\n"}
{"id": "1508.02556", "contents": "Title: Assessment of LTE Wireless Access for Monitoring of Energy Distribution\n  in the Smart Grid Abstract: While LTE is becoming widely rolled out for human-type services, it is also a\npromising solution for cost-efficient connectivity of the smart grid monitoring\nequipment. This is a type of machine-to-machine (M2M) traffic that consists\nmainly of sporadic uplink transmissions. In such a setting, the amount of\ntraffic that can be served in a cell is not constrained by the data capacity,\nbut rather by the signaling constraints in the random access channel and\ncontrol channel. In this paper we explore these limitations using a detailed\nsimulation of the LTE access reservation protocol (ARP). We find that 1)\nassigning more random access opportunities may actually worsen performance; and\n2) the additional signaling that follows the ARP has very large impact on the\ncapacity in terms of the number of supported devices; we observed a reduction\nin the capacity by almost a factor of 3. This suggests that a lightweight\naccess method, with a reduced number of signaling messages, needs to be\nconsidered in standardization for M2M applications. Additionally we propose a\ntractable analytical model to calculate the outage that can be rapidly\nimplemented and evaluated. The model accounts for the features of the random\naccess, control channel and uplink and downlink data channels, as well as\nretransmissions. \n\n"}
{"id": "1508.04720", "contents": "Title: Quickest Detection for Changes in Maximal kNN Coherence of Random\n  Matrices Abstract: This paper addresses the problem of quickest detection of a change in the\nmaximal coherence between columns of a $n\\times p$ random matrix based on a\nsequence of matrix observations having a single unknown change point. The\nrandom matrix is assumed to have identically distributed rows and the maximal\ncoherence is defined as the largest of the $p \\choose 2$ correlation\ncoefficients associated with any row. Likewise, the $k$ nearest neighbor (kNN)\ncoherence is defined as the $k$-th largest of these correlation coefficients.\nThe forms of the pre- and post-change distributions of the observed matrices\nare assumed to belong to the family of elliptically contoured densities with\nsparse dispersion matrices but are otherwise unknown. A non-parametric stopping\nrule is proposed that is based on the maximal k-nearest neighbor sample\ncoherence between columns of each observed random matrix. This is a summary\nstatistic that is related to a test of the existence of a hub vertex in a\nsample correlation graph having a degree at least $k$. Performance bounds on\nthe delay and false alarm performance of the proposed stopping rule are\nobtained in the purely high dimensional regime where $p\\rightarrow \\infty$ and\n$n$ is fixed. When the pre-change dispersion matrix is diagonal it is shown\nthat, among all functions of the proposed summary statistic, the proposed\nstopping rule is asymptotically optimal under a minimax quickest change\ndetection (QCD) model as the stopping threshold approaches infinity. The theory\ndeveloped also applies to sequential hypothesis testing and fixed sample size\ntests. \n\n"}
{"id": "1508.04742", "contents": "Title: A short note on estimation of WCRE and WCE Abstract: In this note the author uses order statistics to estimate WCRE and WCE in\nterms of empirical and survival functions. An example in both cases normal and\nexponential WFs is analyzed. \n\n"}
{"id": "1508.05542", "contents": "Title: Proportional Fair Traffic Splitting and Aggregation in Heterogeneous\n  Wireless Networks Abstract: Traffic load balancing and resource allocation is set to play a crucial role\nin leveraging the dense and increasingly heterogeneous deployment of\nmulti-radio wireless networks. Traffic aggregation across different access\npoints (APs)/radio access technologies (RATs) has become an important feature\nof recently introduced cellular standards on LTE dual connectivity and LTE-WLAN\naggregation (LWA). Low complexity traffic splitting solutions for scenarios\nwhere the APs are not necessarily collocated are of great interest for\noperators. In this paper, we consider a scenario, where traffic for each user\nmay be split across macrocell and an LTE or WiFi small cells connected by\nnon-ideal backhaul links, and develop a closed form solution for optimal\naggregation accounting for the backhaul delay. The optimal solution lends\nitself to a \"water-filling\" based interpretation, where the fraction of user's\ntraffic sent over macrocell is proportional to ratio of user's peak capacity on\nthat macrocell and its throughput on the small cell. Using comprehensive system\nlevel simulations, the developed optimal solution is shown to provide\nsubstantial edge and median throughput gain over algorithms representative of\ncurrent 3GPP-WLAN interworking solutions. The achievable performance benefits\nhold promise for operators expecting to introduce aggregation solutions with\ntheir existing WLAN deployments. \n\n"}
{"id": "1508.06093", "contents": "Title: Energy Group-Buying with Loading Sharing for Green Cellular Networks Abstract: In the emerging hybrid electricity market, mobile network operators (MNOs) of\ncellular networks can make day-ahead energy purchase commitments at low prices\nand real-time flexible energy purchase at high prices. To minimize electricity\nbills, it is essential for MNOs to jointly optimize the day-ahead and real-time\nenergy purchase based on their time-varying wireless traffic load. In this\npaper, we consider two different MNOs coexisting in the same area, and exploit\ntheir collaboration in both energy purchase and wireless load sharing for\nenergy cost saving. Specifically, we propose a new approach named energy group\nbuying with load sharing, in which the two MNOs are aggregated as a single\ngroup to make the day-ahead and real-time energy purchase, and their base\nstations (BSs) share the wireless traffic to maximally turn lightly-loaded BSs\ninto sleep mode. When the two MNOs belong to the same entity and aim to\nminimize their total energy cost, we use the two-stage stochastic programming\nto obtain the optimal day-ahead and real-time energy group buying jointly with\nwireless load sharing. When the two MNOs belong to different entities and are\nself-interested in minimizing their individual energy costs, we propose a novel\nrepeated Nash bargaining scheme for them to negotiate and share their energy\ncosts under energy group buying and load sharing. Our proposed repeated Nash\nbargaining scheme is shown to achieve Pareto-optimal and fair energy cost\nreductions for both MNOs. \n\n"}
{"id": "1508.06307", "contents": "Title: Joint User-Association and Resource-Allocation in Virtualized Wireless\n  Networks Abstract: In this paper, we consider a down-link transmission of multicell virtualized\nwireless networks (VWNs) where users of different service providers (slices)\nwithin a specific region are served by a set of base stations (BSs) through\northogonal frequency division multiple access (OFDMA). In particular, we\ndevelop a joint BS assignment, sub-carrier and power allocation algorithm to\nmaximize the network throughput, while satisfying the minimum required rate of\neach slice. Under the assumption that each user at each transmission instance\ncan connect to no more than one BS, we introduce the user-association factor\n(UAF) to represent the joint sub-carrier and BS assignment as the optimization\nvariable vector in the mathematical problem formulation. Sub-carrier reuse is\nallowed in different cells, but not within one cell. As the proposed\noptimization problem is inherently non-convex and NP-hard, by applying the\nsuccessive convex approximation (SCA) and complementary geometric programming\n(CGP), we develop an efficient two-step iterative approach with low\ncomputational complexity to solve the proposed problem. For a given\npower-allocation, Step 1 derives the optimum userassociation and subsequently,\nfor an obtained user-association, Step 2 find the optimum power-allocation.\nSimulation results demonstrate that the proposed iterative algorithm\noutperforms the traditional approach in which each user is assigned to the BS\nwith the largest average value of signal strength, and then, joint sub-carrier\nand power allocation is obtained for the assigned users of each cell.\nEspecially, for the cell-edge users, simulation results reveal a coverage\nimprovement up to 57% and 71% for uniform and non-uniform users distribution,\nrespectively leading to more reliable transmission and higher spectrum\nefficiency for VWN. \n\n"}
{"id": "1508.06369", "contents": "Title: Wireless Communications in the Era of Big Data Abstract: The rapidly growing wave of wireless data service is pushing against the\nboundary of our communication network's processing power. The pervasive and\nexponentially increasing data traffic present imminent challenges to all the\naspects of the wireless system design, such as spectrum efficiency, computing\ncapabilities and fronthaul/backhaul link capacity. In this article, we discuss\nthe challenges and opportunities in the design of scalable wireless systems to\nembrace such a \"bigdata\" era. On one hand, we review the state-of-the-art\nnetworking architectures and signal processing techniques adaptable for\nmanaging the bigdata traffic in wireless networks. On the other hand, instead\nof viewing mobile bigdata as a unwanted burden, we introduce methods to\ncapitalize from the vast data traffic, for building a bigdata-aware wireless\nnetwork with better wireless service quality and new mobile applications. We\nhighlight several promising future research directions for wireless\ncommunications in the mobile bigdata era. \n\n"}
{"id": "1508.06395", "contents": "Title: On the Role of Shared Randomness in Simultaneous Communication Abstract: Two parties wish to carry out certain distributed computational tasks, and\nthey are given access to a source of correlated random bits. It allows the\nparties to act in a correlated manner, which can be quite useful. But what\nhappens if the shared randomness is not perfect? In this work, we initiate the\nstudy of the power of different sources of shared randomness in communication\ncomplexity. This is done in the setting of simultaneous message passing (SMP)\nmodel of communication complexity, which is one of the most suitable models for\nstudying the resource of shared randomness. Toward characterising the power of\nvarious sources of shared randomness, we introduce a measure for the quality of\na source - we call it collision complexity. Our results show that the collision\ncomplexity tightly characterises the power of a (shared) randomness resource in\nthe SMP model.\n  Of independent interest is our demonstration that even the weakest sources of\nshared randomness can in some cases increase the power of SMP substantially:\nthe equality function can be solved very efficiently with virtually any\nnontrivial shared randomness. \n\n"}
{"id": "1508.07590", "contents": "Title: New Classes of Permutation Binomials and Permutation Trinomials over\n  Finite Fields Abstract: Permutation polynomials over finite fields play important roles in finite\nfields theory. They also have wide applications in many areas of science and\nengineering such as coding theory, cryptography, combinatorial design,\ncommunication theory and so on. Permutation binomials and trinomials attract\npeople's interest due to their simple algebraic form and additional\nextraordinary properties. In this paper, several new classes of permutation\nbinomials and permutation trinomials are constructed. Some of these permutation\npolynomials are generalizations of known ones. \n\n"}
{"id": "1509.00539", "contents": "Title: Leveraging One-hop Information in Massive MIMO Full-Duplex Wireless\n  Systems Abstract: We consider a single-cell massive MIMO full-duplex wireless communication\nsystem, where the base-station (BS) is equipped with a large number of\nantennas. We consider the setup where the single-antenna mobile users operate\nin half- duplex, while each antenna at the BS is capable of full-duplex\ntransmissions, i.e., it can transmit and receive simultaneously using the same\nfrequency spectrum. The fundamental challenge in this system is intra-cell\ninter-node interference, generated by the transmissions of uplink users to the\nreceptions at the downlink users. The key operational challenge is estimating\nand aggregating inter-mobile channel estimates, which can potentially overwhelm\nany gains from full-duplex operation.\n  In this work, we propose a scalable and distributed scheme to optimally\nmanage the inter-node interference by utilizing a \"one- hop information\narchitecture\". In this architecture, the BS only needs to know the\nsignal-to-interference-plus-noise ratio (SINR) from the downlink users. Each\nuplink user needs its own SINR, along with a weighted signal-plus-noise metric\nfrom its one-hop neighboring downlink users, which are the downlink users that\nit interferes with. The proposed one-hop information architecture does not\nrequire any network devices to comprehensively gather the vast inter-node\ninterference channel knowledge, and hence significantly reduces the overhead.\nBased on the one-hop information architecture, we design a distributed power\ncontrol algorithm and implement such architecture using overheard feedback\ninformation. We show that, in typical asymptotic regimes with many users and\nantennas, the proposed distributed power control scheme improves the overall\nnetwork utility and reduces the transmission power of the uplink users. \n\n"}
{"id": "1509.01187", "contents": "Title: Unmanned Aerial Vehicle with Underlaid Device-to-Device Communications:\n  Performance and Tradeoffs Abstract: In this paper, the deployment of an unmanned aerial vehicle (UAV) as a flying\nbase station used to provide on the fly wireless communications to a given\ngeographical area is analyzed. In particular, the co-existence between the UAV,\nthat is transmitting data in the downlink, and an underlaid device-todevice\n(D2D) communication network is considered. For this model, a tractable\nanalytical framework for the coverage and rate analysis is derived. Two\nscenarios are considered: a static UAV and a mobile UAV. In the first scenario,\nthe average coverage probability and the system sum-rate for the users in the\narea are derived as a function of the UAV altitude and the number of D2D users.\nIn the second scenario, using the disk covering problem, the minimum number of\nstop points that the UAV needs to visit in order to completely cover the area\nis computed. Furthermore, considering multiple retransmissions for the UAV and\nD2D users, the overall outage probability of the D2D users is derived.\nSimulation and analytical results show that, depending on the density of D2D\nusers, optimal values for the UAV altitude exist for which the system sum-rate\nand the coverage probability are maximized. Moreover, our results also show\nthat, by enabling the UAV to intelligently move over the target area, the total\nrequired transmit power of UAV while covering the entire area, is minimized.\nFinally, in order to provide a full coverage for the area of interest, the\ntradeoff between the coverage and delay, in terms of the number of stop points,\nis discussed. \n\n"}
{"id": "1509.01332", "contents": "Title: Lattice Codes Achieve the Capacity of Common Message Gaussian Broadcast\n  Channels with Coded Side Information Abstract: Lattices possess elegant mathematical properties which have been previously\nused in the literature to show that structured codes can be efficient in a\nvariety of communication scenarios, including coding for the additive white\nGaussian noise (AWGN) channel, dirty-paper channel, Wyner-Ziv coding, coding\nfor relay networks and so forth. We consider the family of single-transmitter\nmultiple-receiver Gaussian channels where the source transmits a set of common\nmessages to all the receivers (multicast scenario), and each receiver has\n'coded side information', i.e., prior information in the form of linear\ncombinations of the messages. This channel model is motivated by applications\nto multi-terminal networks where the nodes may have access to coded versions of\nthe messages from previous signal hops or through orthogonal channels. The\ncapacity of this channel is known and follows from the work of Tuncel (2006),\nwhich is based on random coding arguments. In this paper, following the\napproach of Erez and Zamir, we design lattice codes for this family of channels\nwhen the source messages are symbols from a finite field 'Fp' of prime size.\nOur coding scheme utilizes Construction A lattices designed over the same prime\nfield 'Fp', and uses algebraic binning at the decoders to expurgate the channel\ncode and obtain good lattice subcodes, for every possible set of linear\ncombinations available as side information. The achievable rate of our coding\nscheme is a function of the size 'p' of underlying prime field, and approaches\nthe capacity as 'p' tends to infinity. \n\n"}
{"id": "1509.02427", "contents": "Title: Approximate Message Passing in Coded Aperture Snapshot Spectral Imaging Abstract: We consider a compressive hyperspectral imaging reconstruction problem, where\nthree-dimensional spatio-spectral information about a scene is sensed by a\ncoded aperture snapshot spectral imager (CASSI). The approximate message\npassing (AMP) framework is utilized to reconstruct hyperspectral images from\nCASSI measurements, and an adaptive Wiener filter is employed as a\nthree-dimensional image denoiser within AMP. We call our algorithm\n\"AMP-3D-Wiener.\" The simulation results show that AMP-3D-Wiener outperforms\nexisting widely-used algorithms such as gradient projection for sparse\nreconstruction (GPSR) and two-step iterative shrinkage/thresholding (TwIST)\ngiven the same amount of runtime. Moreover, in contrast to GPSR and TwIST,\nAMP-3D-Wiener need not tune any parameters, which simplifies the reconstruction\nprocess. \n\n"}
{"id": "1509.03327", "contents": "Title: Optimal Strategy in \"Guess Who?\": Beyond Binary Search Abstract: \"Guess Who?\" is a popular two player game where players ask \"Yes\"/\"No\"\nquestions to search for their opponent's secret identity from a pool of\npossible candidates. This is modeled as a simple stochastic game. Using this\nmodel, the optimal strategy is explicitly found. Contrary to popular belief,\nperforming a binary search is \\emph{not} always optimal. Instead, the optimal\nstrategy for the player who trails is to make certain bold plays in an attempt\ncatch up. This is discovered by first analyzing a continuous version of the\ngame where players play indefinitely and the winner is never decided after\nfinitely many rounds. \n\n"}
{"id": "1509.06611", "contents": "Title: Stochastic Content-Centric Multicast Scheduling for Cache-Enabled\n  Heterogeneous Cellular Networks Abstract: Caching at small base stations (SBSs) has demonstrated significant benefits\nin alleviating the backhaul requirement in heterogeneous cellular networks\n(HetNets). While many existing works focus on what contents to cache at each\nSBS, an equally important problem is what contents to deliver so as to satisfy\ndynamic user demands given the cache status. In this paper, we study optimal\ncontent delivery in cache-enabled HetNets by taking into account the inherent\nmulticast capability of wireless medium. We consider stochastic content\nmulticast scheduling to jointly minimize the average network delay and power\ncosts under a multiple access constraint. We establish a content-centric\nrequest queue model and formulate this stochastic optimization problem as an\ninfinite horizon average cost Markov decision process (MDP). By using\n\\emph{relative value iteration} and special properties of the request queue\ndynamics, we characterize some properties of the value function of the MDP.\nBased on these properties, we show that the optimal multicast scheduling policy\nis of threshold type. Then, we propose a structure-aware optimal algorithm to\nobtain the optimal policy. We also propose a low-complexity suboptimal policy,\nwhich possesses similar structural properties to the optimal policy, and\ndevelop a low-complexity algorithm to obtain this policy. \n\n"}
{"id": "1509.08451", "contents": "Title: Phase Retrieval Using Feasible Point Pursuit: Algorithms and\n  Cram\\'er-Rao Bound Abstract: Reconstructing a signal from squared linear (rank-one quadratic) measurements\nis a challenging problem with important applications in optics and imaging,\nwhere it is known as phase retrieval. This paper proposes two new phase\nretrieval algorithms based on non-convex quadratically constrained quadratic\nprogramming (QCQP) formulations, and a recently proposed approximation\ntechnique dubbed feasible point pursuit (FPP). The first is designed for\nuniformly distributed bounded measurement errors, such as those arising from\nhigh-rate quantization (B-FPP). The second is designed for Gaussian measurement\nerrors, using a least squares criterion (LS-FPP). Their performance is measured\nagainst state-of-the-art algorithms and the Cram\\'er-Rao bound (CRB), which is\nalso derived here. Simulations show that LS-FPP outperforms the state-of-art\nand operates close to the CRB. Compact CRB expressions, properties, and\ninsights are obtained by explicitly computing the CRB in various special cases\n-- including when the signal of interest admits a sparse parametrization, using\nharmonic retrieval as an example. \n\n"}
{"id": "1509.08892", "contents": "Title: A data-dependent weighted LASSO under Poisson noise Abstract: Sparse linear inverse problems appear in a variety of settings, but often the\nnoise contaminating observations cannot accurately be described as bounded by\nor arising from a Gaussian distribution. Poisson observations in particular are\na feature of several real-world applications. Previous work on sparse Poisson\ninverse problems encountered several limiting technical hurdles. This paper\ndescribes a novel alternative analysis approach for sparse Poisson inverse\nproblems that (a) sidesteps the technical challenges in previous work, (b)\nadmits estimators that can readily be computed using off-the-shelf LASSO\nalgorithms, and (c) hints at a general framework for broad classes of noise in\nsparse linear inverse problems. At the heart of this new approach lies a\nweighted LASSO estimator for which data-dependent weights are based on Poisson\nconcentration inequalities. Unlike previous analyses of the weighted LASSO, the\nproposed analysis depends on conditions which can be checked or shown to hold\nin general settings with high probability. \n\n"}
{"id": "1509.09222", "contents": "Title: On Jamming Against Wireless Networks Abstract: In this paper, we study jamming attacks against wireless networks.\nSpecifically, we consider a network of base stations (BS) or access points (AP)\nand investigate the impact of a fixed number of jammers that are randomly\ndeployed according to a Binomial point process. We shed light on the network\nperformance in terms of a) the outage probability and b) the error probability\nof a victim receiver in the downlink of this wireless network. We derive\nanalytical expressions for both these metrics and discuss in detail how the\njammer network must adapt to the various wireless network parameters in order\nto effectively attack the victim receivers. For instance, we will show that\nwith only 1 jammer per BS/AP a) the outage probability of the wireless network\ncan be increased from 1% (as seen in the non-jamming case) to 80% and b) when\nretransmissions are used, the jammers cause the effective network activity\nfactor (and hence the interference among the BSs) to be doubled. Furthermore,\nwe show that the behavior of the jammer network as a function of the BS/AP\ndensity is not obvious. In particular, an interesting concave-type behavior is\nseen which indicates that the number of jammers required to attack the wireless\nnetwork must scale with the BS density only until a certain value beyond which\nit decreases. In the context of error probability of the victim receiver, we\nstudy whether or not some recent results related to jamming in the\npoint-to-point link scenario can be extended to the case of jamming against\nwireless networks. Numerical results are presented to validate the theoretical\ninferences presented. \n\n"}
{"id": "1510.00149", "contents": "Title: Deep Compression: Compressing Deep Neural Networks with Pruning, Trained\n  Quantization and Huffman Coding Abstract: Neural networks are both computationally intensive and memory intensive,\nmaking them difficult to deploy on embedded systems with limited hardware\nresources. To address this limitation, we introduce \"deep compression\", a three\nstage pipeline: pruning, trained quantization and Huffman coding, that work\ntogether to reduce the storage requirement of neural networks by 35x to 49x\nwithout affecting their accuracy. Our method first prunes the network by\nlearning only the important connections. Next, we quantize the weights to\nenforce weight sharing, finally, we apply Huffman coding. After the first two\nsteps we retrain the network to fine tune the remaining connections and the\nquantized centroids. Pruning, reduces the number of connections by 9x to 13x;\nQuantization then reduces the number of bits that represent each connection\nfrom 32 to 5. On the ImageNet dataset, our method reduced the storage required\nby AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method\nreduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of\naccuracy. This allows fitting the model into on-chip SRAM cache rather than\noff-chip DRAM memory. Our compression method also facilitates the use of\ncomplex neural networks in mobile applications where application size and\ndownload bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU,\ncompressed network has 3x to 4x layerwise speedup and 3x to 7x better energy\nefficiency. \n\n"}
{"id": "1510.00252", "contents": "Title: RF Lens-Embedded Massive MIMO Systems: Fabrication Issues and Codebook\n  Design Abstract: In this paper, we investigate a radio frequency (RF) lens-embedded massive\nmultiple-input multiple-output (MIMO) system and evaluate the system\nperformance of limited feedback by utilizing a technique for generating a\nsuitable codebook for the system. We fabricate an RF lens that operates on a 77\nGHz (mmWave) band. Experimental results show a proper value of amplitude gain\nand an appropriate focusing property. In addition, using a simple numerical\ntechnique--beam propagation method (BPM)--we estimate the power profile of the\nRF lens and verify its accordance with experimental results. We also design a\ncodebook--multi-variance codebook quantization (MVCQ)--for limited feedback by\nconsidering the characteristics of the RF lens antenna for massive MIMO\nsystems. Numerical results confirm that the proposed system shows significant\nperformance enhancement over a conventional massive MIMO system without an RF\nlens. \n\n"}
{"id": "1510.00764", "contents": "Title: Information-Theoretic Approach to Strategic Communication as a\n  Hierarchical Game Abstract: This paper analyzes the information disclosure problems originated in\neconomics through the lens of information theory. Such problems are radically\ndifferent from the conventional communication paradigms in information theory\nsince they involve different objectives for the encoder and the decoder, which\nare aware of this mismatch and act accordingly. This leads, in our setting, to\na hierarchical communication game, where the transmitter announces an encoding\nstrategy with full commitment, and its distortion measure depends on a private\ninformation sequence whose realization is available at the transmitter. The\nreceiver decides on its decoding strategy that minimizes its own distortion\nbased on the announced encoding map and the statistics. Three problem settings\nare considered, focusing on the quadratic distortion measures, and jointly\nGaussian source and private information: compression, communication, and the\nsimple equilibrium conditions without any compression or communication. The\nequilibrium strategies and associated costs are characterized. The analysis is\nthen extended to the receiver side information setting and the major changes in\nthe structure of optimal strategies are identified. Finally, an extension of\nthe results to the broader context of decentralized stochastic control is\npresented. \n\n"}
{"id": "1510.00843", "contents": "Title: The Bruss-Robertson Inequality: Elaborations, Extensions, and\n  Applications Abstract: The Bruss-Robertson inequality gives a bound on the maximal number of\nelements of a random sample whose sum is less than a specified value, and the\nextension of that inequality which is given here neither requires the\nindependence of the summands nor requires the equality of their marginal\ndistributions. A review is also given of the applications of the\nBruss-Robertson inequality, especially the applications to problems of\ncombinatorial optimization such as the sequential knapsack problem and the\nsequential monotone subsequence selection problem. \n\n"}
{"id": "1510.01434", "contents": "Title: Multi-Objective Resource Allocation in Full-Duplex SWIPT Systems Abstract: In this paper, we investigate the resource allocation algorithm design for\nfull-duplex simultaneous wireless information and power transfer (FD-SWIPT)\nsystems. The considered system comprises a FD radio base station, multiple\nsingle-antenna half-duplex (HD) users, and multiple energy harvesters equipped\nwith multiple antennas. We propose a multi-objective optimization framework to\nstudy the trade-off between uplink transmit power minimization, downlink\ntransmit power minimization, and total harvested energy maximization. The\nconsidered optimization framework takes into account heterogeneous quality of\nservice requirements for uplink and downlink communication and wireless power\ntransfer. The non-convex multi-objective optimization problem is transformed\ninto an equivalent rank-constrained semidefinite program (SDP) and solved\noptimally by SDP relaxation. The solution of the proposed framework results in\na set of Pareto optimal resource allocation policies. Numerical results unveil\nan interesting trade-off between the considered conflicting system design\nobjectives and reveal the improved power efficiency facilitated by FD in SWIPT\nsystems compared to traditional HD systems. \n\n"}
{"id": "1510.01948", "contents": "Title: An Optimal Transport Formulation of the Linear Feedback Particle Filter Abstract: Feedback particle filter (FPF) is an algorithm to numerically approximate the\nsolution of the nonlinear filtering problem in continuous time. The algorithm\nimplements a feedback control law for a system of particles such that the\nempirical distribution of particles approximates the posterior distribution.\nHowever, it has been noted in the literature that the feedback control law is\nnot unique. To find a unique control law, the filtering task is formulated here\nas an optimal transportation problem between the prior and the posterior\ndistributions. Based on this formulation, a time stepping optimization\nprocedure is proposed for the optimal control design. A key difference between\nthe optimal control law and the one in the original FPF, is the replacement of\nnoise term with a deterministic term. This difference serves to decreases the\nsimulation variance, as illustrated with a simple numerical example. \n\n"}
{"id": "1510.03495", "contents": "Title: Privacy Constrained Information Processing Abstract: This paper studies communication scenarios where the transmitter and the\nreceiver have different objectives due to privacy concerns, in the context of a\nvariation of the strategic information transfer (SIT) model of Sobel and\nCrawford. We first formulate the problem as the minimization of a common\ndistortion by the transmitter and the receiver subject to a privacy constrained\ntransmitter. We show the equivalence of this formulation to a Stackelberg\nequilibrium of the SIT problem. Assuming an entropy based privacy measure, a\nquadratic distortion measure and jointly Gaussian variables, we characterize\nthe Stackelberg equilibrium. Next, we consider asymptotically optimal\ncompression at the transmitter which inherently provides some level of privacy,\nand study equilibrium conditions. We finally analyze the impact of the presence\nof an average power constrained Gaussian communication channel between the\ntransmitter and the receiver on the equilibrium conditions. \n\n"}
{"id": "1510.04467", "contents": "Title: From Microscopic Heterogeneity to Macroscopic Complexity in the\n  Contrarian Voter Model Abstract: An analytical treatment of a simple opinion model with contrarian behavior is\npresented. The focus is on the stationary dynamics of the model and in\nparticular on the effect of inhomogeneities in the interaction topology on the\nstationary behavior. We start from a micro-level Markov chain description of\nthe model. Markov chain aggregation is then used to derive a macro chain for\nthe complete graph as well as a meso-level description for the two-community\ngraph composed of two (weakly) coupled sub-communities. In both cases, a\ndetailed understanding of the model behavior is possible using Markov chain\ntools. More importantly, however, this setting provides an analytical scenario\nto study the discrepancy between the homogeneous mixing case and the model on a\nslightly more complex topology. We show that memory effects are introduced at\nthe macro level when we aggregate over agent attributes without sensitivity to\nthe microscopic details and quantify these effects using concepts from\ninformation theory. In this way, the method facilitates the analysis of the\nrelation between microscopic processes and a their aggregation to a macroscopic\nlevel of description and informs about the complexity of a system introduced by\nheterogeneous interaction relations. \n\n"}
{"id": "1510.04747", "contents": "Title: Tensor vs Matrix Methods: Robust Tensor Decomposition under Block Sparse\n  Perturbations Abstract: Robust tensor CP decomposition involves decomposing a tensor into low rank\nand sparse components. We propose a novel non-convex iterative algorithm with\nguaranteed recovery. It alternates between low-rank CP decomposition through\ngradient ascent (a variant of the tensor power method), and hard thresholding\nof the residual. We prove convergence to the globally optimal solution under\nnatural incoherence conditions on the low rank component, and bounded level of\nsparse perturbations. We compare our method with natural baselines which apply\nrobust matrix PCA either to the {\\em flattened} tensor, or to the matrix slices\nof the tensor. Our method can provably handle a far greater level of\nperturbation when the sparse tensor is block-structured. This naturally occurs\nin many applications such as the activity detection task in videos. Our\nexperiments validate these findings. Thus, we establish that tensor methods can\ntolerate a higher level of gross corruptions compared to matrix methods. \n\n"}
{"id": "1510.04820", "contents": "Title: Error-Correcting Functional Index Codes, Generalized Exclusive Laws and\n  Graph Coloring Abstract: We consider the \\emph{functional index coding problem} over an error-free\nbroadcast network in which a source generates a set of messages and there are\nmultiple receivers, each holding a set of functions of source messages in its\ncache, called the \\emph{Has-set}, and demands to know another set of functions\nof messages, called the \\emph{Want-set}. Cognizant of the receivers'\n\\emph{Has-sets}, the source aims to satisfy the demands of each receiver by\nmaking coded transmissions, called a \\emph{functional index code}. The\nobjective is to minimize the number of such transmissions required. The\nrestriction a receiver's demands pose on the code is represented via a\nconstraint called the \\emph{generalized exclusive law} and obtain a code using\nthe \\emph{confusion graph} constructed using these constraints. Bounds on the\nsize of an optimal code based on the parameters of the confusion graph are\npresented. Next, we consider the case of erroneous transmissions and provide a\nnecessary and sufficient condition that an FIC must satisfy for correct\ndecoding of desired functions at each receiver and obtain a lower bound on the\nlength of an error-correcting FIC. \n\n"}
{"id": "1510.06121", "contents": "Title: Cache-Aided Interference Channels Abstract: Over the past decade, the bulk of wireless traffic has shifted from speech to\ncontent. This shift creates the opportunity to cache part of the content in\nmemories closer to the end users, for example in base stations. Most of the\nprior literature focuses on the reduction of load in the backhaul and core\nnetworks due to caching, i.e., on the benefits caching offers for the wireline\ncommunication link between the origin server and the caches. In this paper, we\nare instead interested in the benefits caching can offer for the wireless\ncommunication link between the caches and the end users.\n  To quantify the gains of caching for this wireless link, we consider an\ninterference channel in which each transmitter is equipped with an isolated\ncache memory. Communication takes place in two phases, a content placement\nphase followed by a content delivery phase. The objective is to design both the\nplacement and the delivery phases to maximize the rate in the delivery phase in\nresponse to any possible user demands. Focusing on the three-user case, we show\nthat through careful joint design of these phases, we can reap three distinct\nbenefits from caching: a load balancing gain, an interference cancellation\ngain, and an interference alignment gain. In our proposed scheme, load\nbalancing is achieved through a specific file splitting and placement,\nproducing a particular pattern of content overlap at the caches. This overlap\nallows to implement interference cancellation. Further, it allows us to create\nseveral virtual transmitters, each transmitting a part of the requested\ncontent, which increases interference-alignment possibilities. \n\n"}
{"id": "1510.06623", "contents": "Title: Commitment and Oblivious Transfer in the Bounded Storage Model with\n  Errors Abstract: The bounded storage model restricts the memory of an adversary in a\ncryptographic protocol, rather than restricting its computational power, making\ninformation theoretically secure protocols feasible. We present the first\nprotocols for commitment and oblivious transfer in the bounded storage model\nwith errors, i.e., the model where the public random sources available to the\ntwo parties are not exactly the same, but instead are only required to have a\nsmall Hamming distance between themselves. Commitment and oblivious transfer\nprotocols were known previously only for the error-free variant of the bounded\nstorage model, which is harder to realize. \n\n"}
{"id": "1510.07176", "contents": "Title: On the Effect of Fronthaul Latency on ARQ in C-RAN Systems Abstract: In the Cloud Radio Access Network (C-RAN) architecture, a Control Unit (CU)\nimplements the baseband processing functionalities of a cluster of Base\nStations (BSs), which are connected to it through a fronthaul network. This\narchitecture enables centralized processing at the CU, and hence the\nimplementation of enhanced interference mitigation strategies, but it also\nentails an increased decoding latency due to the transport on the fronthaul\nnetwork. The fronthaul latency may offset the benefits of centralized\nprocessing when considering the performance of protocols at layer 2 and above.\nThis letter studies the impact of fronthaul latency on the performance of\nstandard Automatic Retransmission reQuest (ARQ) protocols, namely Stop and\nWait, Go-Back-N and Selective Repeat. The performance of the C-RAN architecture\nin terms of throughput and efficiency is compared to the that of a conventional\ncellular system with local processing, as well as with that of a proposed\nhybrid C-RAN system in which BSs can perform decoding. The dynamics of the\nsystem are modeled as a multi-dimensional Markov process that includes\nsub-chains to capture the temporal correlation of interference and channel\ngains. Numerical results yield insights into the impact of system parameters\nsuch as fronthaul latency and signal-to-interference ratio on different ARQ\nprotocols. \n\n"}
{"id": "1511.00562", "contents": "Title: Distance Spectrum of Fixed-Rate Raptor Codes with Linear Random\n  Precoders Abstract: Raptor code ensembles with linear random outer codes in a fixed-rate setting\nare considered. An expression for the average distance spectrum is derived and\nthis expression is used to obtain the asymptotic exponent of the weight\ndistribution. The asymptotic growth rate analysis is then exploited to develop\na necessary and sufficient condition under which the fixed-rate Raptor code\nensemble exhibits a strictly positive typical minimum distance. The condition\ninvolves the rate of the outer code, the rate of the inner fixed-rate Luby\nTransform (LT) code and the LT code degree distribution. Additionally, it is\nshown that for ensembles fulfilling this condition, the minimum distance of a\ncode randomly drawn from the ensemble has a linear growth with the block\nlength. The analytical results can be used to make accurate predictions of the\nperformance of finite length Raptor codes. These results are particularly\nuseful for fixed-rate Raptor codes under maximum likelihood erasure decoding,\nwhose performance is driven by their weight distribution. \n\n"}
{"id": "1511.01195", "contents": "Title: Small scale equidistribution of random eigenbases Abstract: We investigate small scale equidistribution of random orthonormal bases of\neigenfunctions (i.e. eigenbases) on a compact manifold M. Assume that the group\nof isometries acts transitively on M and the multiplicity of eigenfrequency\ntends to infinity at least logarithmically. We prove that, with respect to the\nnatural probability measure on the space of eigenbases, almost surely a random\neigenbasis is equidistributed at small scales; furthermore, the scales depend\non the growth rate of multiplicity. In particular, this implies that almost\nsurely random eigenbases on the n-dimensional sphere (n>=2) and the\nn-dimensional tori (n>=5) are equidistributed at polynomial scales. \n\n"}
{"id": "1511.02307", "contents": "Title: On the Capacity Achieving Probability Measures for Molecular Receivers Abstract: In this paper, diffusion-based molecular commu- nication with ligand receptor\nreceivers is studied. Information messages are assumed to be encoded via\nvariations of the con- centration of molecules. The randomness in the ligand\nreception process induces uncertainty in the communication; limiting the rate\nof information decoding. We model the ligand receptor receiver by a set of\nfinite-state Markov channels and study the general capacity of such a receiver.\nFurthermore, the i.i.d. capacity of the receiver is characterized as a lower\nbound for the general capacity. It is also proved that a finite support\nprobability measure can achieve the i.i.d. capacity of the receiver. Moreover,\na bound on the number of points in the support of the probability measure is\nobtained. \n\n"}
{"id": "1511.06483", "contents": "Title: Directional Initial Access for Millimeter Wave Cellular Systems Abstract: The millimeter wave (mmWave) bands have recently attracted considerable\ninterest for next-generation cellular systems due to the massive available\nbandwidths at these frequencies. However, a key challenge in designing mmWave\ncellular systems is initial access -- the procedure by which a mobile\nestablishes an initial link-layer connection to a base station cell. MmWave\ncommunication relies on highly directional transmissions and the initial access\nprocedure must thus provide a mechanism by which initial transmission\ndirections can be searched in a potentially large angular space. Design options\nare compared considering different scanning and signaling procedures to\nevaluate access delay and system overhead. The channel structure and multiple\naccess issues are also considered. The analysis demonstrates significant\nbenefits of low-resolution fully digital architectures in comparison to single\nstream analog beamforming. \n\n"}
{"id": "1511.06518", "contents": "Title: Enhanced Transmit Antenna Selection Scheme for Secure Throughput\n  Maximization Without CSI at the Transmitter and its Applications on Smart\n  Grids Abstract: This paper addresses the establishment of secure communication links between\nsmart-meters (Alice) and an aggregator (Bob) in the presence of an eavesdropper\n(Eve). The proposed scenario assumes: (i) MIMOME wiretap channel; (ii) transmit\nantenna selection at the Alice; (iii) no channel state information at the\ntransmitter; (iv) fixed Wyner codes; and (v) guarantee of secure throughput by\nboth quality of service and secrecy outage constraints. We propose a simple\nprotocol to enhance security via transmit antenna selection, and then assess\nits performance in closed-form by means of secrecy outage and successful\ntransmission probabilities. We assume these probabilities are our constraints\nand then maximize the secure throughput, establishing a security-reliability\ntrade-off for the proposed scenario. Our numerical results illustrate the\neffect of this trade-off on the secure throughput as well as on the number of\nantennas at Alice, Bob and Eve. Interestingly, a small sacrifice in reliability\nallows secrecy enhancement in terms of secure bps/Hz. We apply this idea in our\nsmart grid application to exemplify that, although Eve may acquire some samples\nof the average power demand of a household, it is not enough to properly\nreconstruct such curve. \n\n"}
{"id": "1512.00156", "contents": "Title: Covariance-domain Dictionary Learning for Overcomplete EEG Source\n  Identification Abstract: We propose an algorithm targeting the identification of more sources than\nchannels for electroencephalography (EEG). Our overcomplete source\nidentification algorithm, Cov-DL, leverages dictionary learning methods applied\nin the covariance-domain. Assuming that EEG sources are uncorrelated within\nmoving time-windows and the scalp mixing is linear, the forward problem can be\ntransferred to the covariance domain which has higher dimensionality than the\noriginal EEG channel domain. This allows for learning the overcomplete mixing\nmatrix that generates the scalp EEG even when there may be more sources than\nsensors active at any time segment, i.e. when there are non-sparse sources.\nThis is contrary to straight-forward dictionary learning methods that are based\non the assumption of sparsity, which is not a satisfied condition in the case\nof low-density EEG systems. We present two different learning strategies for\nCov-DL, determined by the size of the target mixing matrix. We demonstrate that\nCov-DL outperforms existing overcomplete ICA algorithms under various scenarios\nof EEG simulations and real EEG experiments. \n\n"}
{"id": "1512.00411", "contents": "Title: Linear Large-Scale MIMO Data Detection for 5G Multi-Carrier Waveform\n  Candidates Abstract: Fifth generation (5G) wireless systems are expected to combine emerging\ntransmission technologies, such as large-scale multiple-input multiple-output\n(MIMO) and non-orthogonal multi-carrier waveforms, to improve the spectral\nefficiency and to reduce out-of-band (OOB) emissions. This paper investigates\nthe efficacy of two promising multi-carrier waveforms that reduce OOB emissions\nin combination with large-scale MIMO, namely filter bank multi-carrier (FBMC)\nand generalized frequency division multiplexing (GFDM). We develop novel,\nlow-complexity data detection algorithms for both of these waveforms. We\ninvestigate the associated performance/complexity trade-offs in the context of\nlarge-scale MIMO, and we study the peak-to-average power ratio (PAPR). Our\nresults show that reducing the OOB emissions with FBMC and GFDM leads to higher\ncomputational complexity and PAPR compared to that of orthogonal\nfrequency-division multiplexing (OFDM) and single-carrier frequency division\nmultiple access (SC-FDMA). \n\n"}
{"id": "1512.02990", "contents": "Title: Staircase Codes for Secret Sharing with Optimal Communication and Read\n  Overheads Abstract: We study the communication efficient secret sharing (CESS) problem introduced\nby Huang, Langberg, Kliewer and Bruck. A classical threshold secret sharing\nscheme randomly encodes a secret into $n$ shares given to $n$ parties, such\nthat any set of at least $t$, $t<n$, parties can reconstruct the secret, and\nany set of at most $z$, $z<t$, parties cannot obtain any information about the\nsecret. Recently, Huang et al. characterized the achievable minimum\ncommunication overhead (CO) necessary for a legitimate user to decode the\nsecret when contacting $d\\geq t$ parties and presented explicit code\nconstructions achieving minimum CO for $d=n$. The intuition behind the possible\nsavings on CO is that the user is only interested in decoding the secret and\ndoes not have to decode the random keys involved in the encoding process. In\nthis paper, we introduce a new class of linear CESS codes called Staircase\nCodes over any field $GF(q)$, for any prime power $q> n$. We describe two\nexplicit constructions of Staircase codes that achieve minimum communication\nand read overheads respectively for a fixed $d$, and universally for all\npossible values of $d, t\\leq d\\leq n$. \n\n"}
{"id": "1512.06697", "contents": "Title: Random Tessellations, Restricted Isometric Embeddings, and One Bit\n  Sensing Abstract: We obtain mproved bounds for one bit sensing. For instance, let $ K_s$ denote\nthe set of $ s$-sparse unit vectors in the sphere $ \\mathbb S ^{n}$ in\ndimension $ n+1$ with sparsity parameter $ 0 < s < n+1$ and assume that $ 0 <\n\\delta < 1$. We show that for $ m \\gtrsim \\delta ^{-2} s \\log \\frac ns$, the\none-bit map $$ x \\mapsto \\bigl[ {sgn} \\langle x,g_j \\rangle \\bigr] _{j=1} ^{m},\n$$ where $ g_j$ are iid gaussian vectors on $ \\mathbb R ^{n+1}$, with high\nprobability has $ \\delta $-RIP from $ K_s$ into the $ m$-dimensional Hamming\ncube. These bounds match the bounds for the {linear} $ \\delta $-RIP given by $\nx \\mapsto \\frac 1m[\\langle x,g_j \\rangle ] _{j=1} ^{m} $, from the sparse\nvectors in $ \\mathbb R ^{n}$ into $ \\ell ^{1}$. In other words, the one bit and\nlinear RIPs are equally effective. There are corresponding improvements for\nother one-bit properties, such as the sign-product RIP property. \n\n"}
{"id": "1512.07016", "contents": "Title: Comparison of quantum channels and statistical experiments Abstract: For a pair of quantum channels with the same input space, we show that the\npossibility of approximation of one channel by post-processings of the other\nchannel can be characterized by comparing the success probabilities for the two\nensembles obtained as outputs for any ensemble on the input space coupled with\nan ancilla. This provides an operational interpretation to a natural extension\nof Le Cam's deficiency to quantum channels. In particular, we obtain a version\nof the randomization criterion for quantum statistical experiments. The proofs\nare based on some properties of the diamond norm and its dual, which are of\nindependent interest. \n\n"}
{"id": "1512.07856", "contents": "Title: Cache Aided Wireless Networks: Tradeoffs between Storage and Latency Abstract: We investigate the fundamental information theoretic limits of cache-aided\nwireless networks, in which edge nodes (or transmitters) are endowed with\ncaches that can store popular content, such as multimedia files. This\narchitecture aims to localize popular multimedia content by proactively pushing\nit closer to the edge of the wireless network, thereby alleviating backhaul\nload. An information theoretic model of such networks is presented, that\nincludes the introduction of a new metric, namely normalized delivery time\n(NDT), which captures the worst case time to deliver any requested content to\nthe users. We present new results on the trade-off between latency, measured\nvia the NDT, and the cache storage capacity of the edge nodes. In particular, a\nnovel information theoretic lower bound on NDT is presented for cache aided\nnetworks. The optimality of this bound is shown for several system parameters. \n\n"}
{"id": "1601.02882", "contents": "Title: On Hidden States in Quantum Random Walks Abstract: It was recently pointed out that identifiability of quantum random walks and\nhidden Markov processes underlie the same principles. This analogy immediately\nraises questions on the existence of hidden states also in quantum random walks\nand their relationship with earlier debates on hidden states in quantum\nmechanics. The overarching insight was that not only hidden Markov processes,\nbut also quantum random walks are finitary processes. Since finitary processes\nenjoy nice asymptotic properties, this also encourages to further investigate\nthe asymptotic properties of quantum random walks. Here, answers to all these\nquestions are given. Quantum random walks, hidden Markov processes and finitary\nprocesses are put into a unifying model context. In this context, quantum\nrandom walks are seen to not only enjoy nice ergodic properties in general, but\nalso intuitive quantum-style asymptotic properties. It is also pointed out how\nhidden states arising from our framework relate to hidden states in earlier,\nprominent treatments on topics such as the EPR paradoxon or Bell's\ninequalities. \n\n"}
{"id": "1601.03830", "contents": "Title: Ultra-Reliable Cloud Mobile Computing with Service Composition and\n  Superposition Coding Abstract: An emerging requirement for 5G systems is the ability to provide wireless\nultra-reliable communication (URC) services with close-to-full availability for\ncloud-based applications. Among such applications, a prominent role is expected\nto be played by mobile cloud computing (MCC), that is, by the offloading of\ncomputationally intensive tasks from mobile devices to the cloud. MCC allows\nbattery-limited devices to run sophisticated applications, such as for gaming\nor for the \"tactile\" internet. This paper proposes to apply the framework of\nreliable service composition to the problem of optimal task offloading in MCC\nover fading channels, with the aim of providing layered, or composable,\nservices at differentiated reliability levels. Inter-layer optimization\nproblems, encompassing offloading decisions and communication resources, are\nformulated and addressed by means of successive convex approximation methods.\nThe numerical results demonstrate the energy savings that can be obtained by a\njoint allocation of computing and communication resources, as well as the\nadvantages of layered coding at the physical layer and the impact of channel\nconditions on the offloading decisions. \n\n"}
{"id": "1601.04884", "contents": "Title: Z2-Triple cyclic codes and their duals Abstract: A Z2-triple cyclic code of block length (r,s,t) is a binary code of length\nr+s+t such that the code is partitioned into three parts of lengthsr,s andt\nsuch that each of the three parts is invariant under the cyclic shifts of the\ncoordinates. Such a code can be viewed as Z2[x]-submodules of\nZ_2[x]/<x^r-1>xZ_2[x]/<x^s-1>xZ_2[x]/<x^t-1>, in polynomial representation. In\nthis paper, we determine the structure of these codes. We have obtained the\nform of the generators for such codes. Further, a minimal generating set for\nsuch a code is obtained. Also, we study the structure of the duals of these\ncodes via the generators of the codes. \n\n"}
{"id": "1601.05516", "contents": "Title: A Deterministic Algorithm for Pliable Index Coding Abstract: Pliable index coding considers a server with m messages, and n clients where\neach has as side information a subset of the messages. We seek to minimize the\nnumber of transmissions the server should make, so that each client receives\n(any) one message she does not already have. Previous work has shown that the\nserver can achieve this using O(\\log^2(n)) transmissions and needs at least\n\\Omega(log(n)) transmissions in the worst case, but finding a code of optimal\nlength is NP-hard. In this paper, we propose a deterministic algorithm that we\nprove achieves this upper bound, that is, in an order almost as the worst-case\noptimal code length. We also establish a connection between the pliable index\ncoding problem and the minrank problem over a family of mixed matrices. \n\n"}
{"id": "1601.05839", "contents": "Title: The Impact of Unlicensed Access on Small-Cell Resource Allocation Abstract: Small cells deployed in licensed spectrum and unlicensed access via WiFi\nprovide different ways of expanding wireless services to low mobility users.\nThat reduces the demand for conventional macro-cellular networks, which are\nbetter suited for wide-area mobile coverage. The mix of these technologies seen\nin practice depends in part on the decisions made by wireless service providers\nthat seek to maximize revenue, and allocations of licensed and unlicensed\nspectrum by regulators. To understand these interactions we present a model in\nwhich a service provider allocates available licensed spectrum across two\nseparate bands, one for macro- and one for small-cells, in order to serve two\ntypes of users: mobile and fixed. We assume a service model in which the\nproviders can charge a (different) price per unit rate for each type of service\n(macro- or small-cell); unlicensed access is free. With this setup we study how\nthe addition of unlicensed spectrum affects prices and the optimal allocation\nof bandwidth across macro-/small-cells. We also characterize the optimal\nfraction of unlicensed spectrum when new bandwidth becomes available. \n\n"}
{"id": "1601.05875", "contents": "Title: Distributed Simulation of Continuous Random Variables Abstract: We establish the first known upper bound on the exact and Wyner's common\ninformation of $n$ continuous random variables in terms of the dual total\ncorrelation between them (which is a generalization of mutual information). In\nparticular, we show that when the pdf of the random variables is log-concave,\nthere is a constant gap of $n^{2}\\log e+9n\\log n$ between this upper bound and\nthe dual total correlation lower bound that does not depend on the\ndistribution. The upper bound is obtained using a computationally efficient\ndyadic decomposition scheme for constructing a discrete common randomness\nvariable $W$ from which the $n$ random variables can be simulated in a\ndistributed manner. We then bound the entropy of $W$ using a new measure, which\nwe refer to as the erosion entropy. \n\n"}
{"id": "1601.06014", "contents": "Title: Consistency of the Plug-In Estimator of the Entropy Rate for Ergodic\n  Processes Abstract: A plug-in estimator of entropy is the entropy of the distribution where\nprobabilities of symbols or blocks have been replaced with their relative\nfrequencies in the sample. Consistency and asymptotic unbiasedness of the\nplug-in estimator can be easily demonstrated in the IID case. In this paper, we\nask whether the plug-in estimator can be used for consistent estimation of the\nentropy rate $h$ of a stationary ergodic process. The answer is positive if, to\nestimate block entropy of order $k$, we use a sample longer than\n$2^{k(h+\\epsilon)}$, whereas it is negative if we use a sample shorter than\n$2^{k(h-\\epsilon)}$. In particular, if we do not know the entropy rate $h$, it\nis sufficient to use a sample of length $(|X|+\\epsilon)^{k}$ where $|X|$ is the\nalphabet size. The result is derived using $k$-block coding. As a by-product of\nour technique, we also show that the block entropy of a stationary process is\nbounded above by a nonlinear function of the average block entropy of its\nergodic components. This inequality can be used for an alternative proof of the\nknown fact that the entropy rate a stationary process equals the average\nentropy rate of its ergodic components. \n\n"}
{"id": "1601.06280", "contents": "Title: Sub-Quadratic Decoding of Gabidulin Codes Abstract: This paper shows how to decode errors and erasures with Gabidulin codes in\nsub-quadratic time in the code length, improving previous algorithms which had\nat least quadratic complexity. The complexity reduction is achieved by\naccelerating operations on linearized polynomials. In particular, we present\nfast algorithms for division, multi-point evaluation and interpolation of\nlinearized polynomials and show how to efficiently compute minimal subspace\npolynomials. \n\n"}
{"id": "1601.06383", "contents": "Title: On Caching with More Users than Files Abstract: Caching appears to be an efficient way to reduce peak hour network traffic\ncongestion by storing some content at the user's cache without knowledge of\nlater demands. Recently, Maddah-Ali and Niesen proposed a two-phase, placement\nand delivery phase, coded caching strategy for centralized systems (where\ncoordination among users is possible in the placement phase), and for\ndecentralized systems. This paper investigates the same setup under the further\nassumption that the number of users is larger than the number of files. By\nusing the same uncoded placement strategy of Maddah-Ali and Niesen, a novel\ncoded delivery strategy is proposed to profit from the multicasting\nopportunities that arise because a file may be demanded by multiple users. The\nproposed delivery method is proved to be optimal under the constraint of\nuncoded placement for centralized systems with two files, moreover it is shown\nto outperform known caching strategies for both centralized and decentralized\nsystems. \n\n"}
{"id": "1601.06810", "contents": "Title: Variational formulas for the power of the binary hypothesis testing\n  problem with applications Abstract: Two variational formulas for the power of the binary hypothesis testing\nproblem are derived. The first is given as the Legendre transform of a certain\nfunction and the second, induced from the first, is given in terms of the\nCumulative Distribution Function (CDF) of the log-likelihood ratio. One\napplication of the first formula is an upper bound on the power of the binary\nhypothesis testing problem in terms of the Re'nyi divergence. The second\nformula provide a general framework for proving asymptotic and non-asymptotic\nexpressions for the power of the test utilizing corresponding expressions for\nthe CDF of the log-likelihood. The framework is demonstrated in the central\nlimit regime (i.e., for non-vanishing type I error) and in the large deviations\nregime. \n\n"}
{"id": "1601.06899", "contents": "Title: Coded Compressive Sensing: A Compute-and-Recover Approach Abstract: In this paper, we propose \\textit{coded compressive sensing} that recovers an\n$n$-dimensional integer sparse signal vector from a noisy and quantized\nmeasurement vector whose dimension $m$ is far-fewer than $n$. The core idea of\ncoded compressive sensing is to construct a linear sensing matrix whose columns\nconsist of lattice codes. We present a two-stage decoding method named\n\\textit{compute-and-recover} to detect the sparse signal from the noisy and\nquantized measurements. In the first stage, we transform such measurements into\nnoiseless finite-field measurements using the linearity of lattice codewords.\nIn the second stage, syndrome decoding is applied over the finite-field to\nreconstruct the sparse signal vector. A sufficient condition of a perfect\nrecovery is derived. Our theoretical result demonstrates an interplay among the\nquantization level $p$, the sparsity level $k$, the signal dimension $n$, and\nthe number of measurements $m$ for the perfect recovery. Considering 1-bit\ncompressive sensing as a special case, we show that the proposed algorithm\nempirically outperforms an existing greedy recovery algorithm. \n\n"}
{"id": "1601.06993", "contents": "Title: Rank equivalent and rank degenerate skew cyclic codes Abstract: Two skew cyclic codes can be equivalent for the Hamming metric only if they\nhave the same length, and only the zero code is degenerate. The situation is\ncompletely different for the rank metric, where lengths of codes correspond to\nthe number of outgoing links from the source when applying the code on a\nnetwork. We study rank equivalences between skew cyclic codes of different\nlengths and, with the aim of finding the skew cyclic code of smallest length\nthat is rank equivalent to a given one, we define different types of length for\na given skew cyclic code, relate them and compute them in most cases. We give\ndifferent characterizations of rank degenerate skew cyclic codes using\nconventional polynomials and linearized polynomials. Some known results on the\nrank weight hierarchy of cyclic codes for some lengths are obtained as\nparticular cases and extended to all lengths and to all skew cyclic codes.\nFinally, we prove that the smallest length of a linear code that is rank\nequivalent to a given skew cyclic code can be attained by a pseudo-skew cyclic\ncode. Throughout the paper, we find new relations between linear skew cyclic\ncodes and their Galois closures. \n\n"}
{"id": "1601.07223", "contents": "Title: Gram Schmidt Based Greedy Hybrid Precoding for Frequency Selective\n  Millimeter Wave MIMO Systems Abstract: Hybrid analog/digital precoding allows millimeter wave MIMO systems to\nleverage large antenna array gains while permitting low cost and power\nconsumption hardware. Most prior work has focused on hybrid precoding for\nnarrow-band mmWave systems. MmWave systems, however, will likely operate on\nwideband channels with frequency selectivity. Therefore, this paper considers\nfrequency selective hybrid precoding with RF beamforming vectors taken from a\nquantized codebook. For this system, a low-complexity yet near-optimal greedy\nalgorithm is developed for the design of the hybrid analog/digital precoders.\nThe proposed algorithm greedily selects the RF beamforming vectors using\nGram-Schmidt orthogonalization. Simulation results show that the developed\nprecoding design algorithm achieves very good performance compared with the\nunconstrained solutions while requiring less complexity. \n\n"}
{"id": "1601.08132", "contents": "Title: Interference Management in Heterogeneous Networks with Blind\n  Transmitters Abstract: Future multi-tier communication networks will require enhanced network\ncapacity and reduced overhead. In the absence of Channel State Information\n(CSI) at the transmitters, Blind Interference Alignment (BIA) and Topological\nInterference Management (TIM) can achieve optimal Degrees of Freedom (DoF),\nminimising network's overhead. In addition, Non-Orthogonal Multiple Access\n(NOMA) can increase the sum rate of the network, compared to orthogonal radio\naccess techniques currently adopted by 4G networks. Our contribution is two\ninterference management schemes, BIA and a hybrid TIM-NOMA scheme, employed in\nheterogeneous networks by applying user-pairing and Kronecker Product\nrepresentation. BIA manages inter- and intra-cell interference by antenna\nselection and appropriate message scheduling. The hybrid scheme manages\nintra-cell interference based on NOMA and inter-cell interference based on TIM.\nWe show that both schemes achieve at least double the rate of TDMA. The hybrid\nscheme always outperforms TDMA and BIA in terms of Degrees of Freedom (DoF).\nComparing the two proposed schemes, BIA achieves more DoF than TDMA under\ncertain restrictions, and provides better Bit-Error-Rate (BER) and sum rate\nperformance to macrocell users, whereas the hybrid scheme improves the\nperformance of femtocell users. \n\n"}
{"id": "1602.00508", "contents": "Title: A Bayesian view of Single-Qubit Clocks, and an Energy versus Accuracy\n  tradeoff Abstract: We bring a Bayesian approach to the analysis of clocks. Using exponential\ndistributions as priors for clocks, we analyze how well one can keep time with\na single qubit freely precessing under a magnetic field. We find that, at least\nwith a single qubit, quantum mechanics does not allow exact timekeeping, in\ncontrast to classical mechanics which does. We find the design of the\nsingle-qubit clock that leads to maximum accuracy. Further, we find an energy\nversus accuracy tradeoff --- the energy cost is at least $k_BT$ times the\nimprovement in accuracy as measured by the entropy reduction in going from the\nprior distribution to the posterior distribution. We propose a physical\nrealization of the single qubit clock using charge transport across a\ncapacitively-coupled quantum dot. \n\n"}
{"id": "1602.01532", "contents": "Title: Optimal Transport Theory for Power-Efficient Deployment of Unmanned\n  Aerial Vehicles Abstract: In this paper, the optimal deployment of multiple unmanned aerial vehicles\n(UAVs) acting as flying base stations is investigated. Considering the downlink\nscenario, the goal is to minimize the total required transmit power of UAVs\nwhile satisfying the users' rate requirements. To this end, the optimal\nlocations of UAVs as well as the cell boundaries of their coverage areas are\ndetermined. To find those optimal parameters, the problem is divided into two\nsub-problems that are solved iteratively. In the first sub-problem, given the\ncell boundaries corresponding to each UAV, the optimal locations of the UAVs\nare derived using the facility location framework. In the second sub-problem,\nthe locations of UAVs are assumed to be fixed, and the optimal cell boundaries\nare obtained using tools from optimal transport theory. The analytical results\nshow that the total required transmit power is significantly reduced by\ndetermining the optimal coverage areas for UAVs. These results also show that,\nmoving the UAVs based on users' distribution, and adjusting their altitudes can\nlead to a minimum power consumption. Finally, it is shown that the proposed\ndeployment approach, can improve the system's power efficiency by a factor of\n20 compared to the classical Voronoi cell association technique with fixed UAVs\nlocations. \n\n"}
{"id": "1602.02036", "contents": "Title: Classical capacities of quantum channels with environment assistance Abstract: A quantum channel physically is a unitary interaction between the information\ncarrying system and an environment, which is initialized in a pure state before\nthe interaction. Conventionally, this state, as also the parameters of the\ninteraction, is assumed to be fixed and known to the sender and receiver. Here,\nfollowing the model introduced by us earlier [Karumanchi et al.,\narXiv[quant-ph]:1407.8160], we consider a benevolent third party, i.e. a\nhelper, controlling the environment state, and how the helper's presence\nchanges the communication game. In particular, we define and study the\nclassical capacity of a unitary interaction with helper, indeed two variants,\none where the helper can only prepare separable states across many channel\nuses, and one without this restriction. Furthermore, the two even more powerful\nscenarios of pre-shared entanglement between helper and receiver, and of\nclassical communication between sender and helper (making them conferencing\nencoders) are considered. \n\n"}
{"id": "1602.02366", "contents": "Title: On the Degrees-of-Freedom of the Large-Scale Interfering Two-Way Relay\n  Network Abstract: Achievable degrees-of-freedom (DoF) of the large-scale interfering two-way\nrelay network is investigated. The network consists of $K$ pairs of\ncommunication nodes (CNs) and $N$ relay nodes (RNs). It is assumed that $K\\ll\nN$ and each pair of CNs communicates with each other through one of the $N$\nrelay nodes without a direct link between them. Interference among RNs is also\nconsidered. Assuming local channel state information (CSI) at each RN, a\ndistributed and opportunistic RN selection technique is proposed for the\nfollowing three promising relaying protocols: amplify--forward,\ndecode--forward, and compute--forward. As a main result, the asymptotically\nachievable DoF is characterized as $N$ increases for the three relaying\nprotocols. In particular, a sufficient condition on $N$ required to achieve the\ncertain DoF of the network is analyzed. Through extensive simulations, it is\nshown that the proposed RN selection techniques outperform conventional schemes\nin terms of achievable rate even in practical communication scenarios. Note\nthat the proposed technique operates with a distributed manner and requires\nonly local CSI, leading to easy implementation for practical wireless systems. \n\n"}
{"id": "1602.02390", "contents": "Title: Lower Bounds for Interactive Function Computation via Wyner Common\n  Information Abstract: The question of how much communication is required between collaborating\nparties to compute a function of their data is of fundamental importance in the\nfields of theoretical computer science and information theory. In this work,\nthe focus is on coming up with lower bounds on this. The information cost of a\nprotocol is the amount of information the protocol reveals to Alice and Bob\nabout each others inputs, and the information complexity of a function is the\ninfimum of information costs over all valid protocols. For the amortized case,\nit is known that the optimal rate for the computation is equal to the\ninformation complexity. Exactly computing this information complexity is not\nstraight forward however. In this work we lower bound information complexity\nfor independent inputs in terms of the Wyner common information of a certain\npair of random variables. We show a structural property for the optimal\nauxiliary random variable of Wyner common information and exploit this to\nexactly compute the Wyner common information in certain cases. The lower bound\nobtained through this technique is shown to be tight for a non-trivial example\n- equality (EQ) for the ternary alphabet. We also give an example to show that\nthe lower bound may, in general, not be tight. \n\n"}
{"id": "1602.02612", "contents": "Title: Sign-Compute-Resolve for Tree Splitting Random Access Abstract: We present a framework for random access that is based on three elements:\nphysical-layer network coding (PLNC), signature codes and tree splitting. In\npresence of a collision, physical-layer network coding enables the receiver to\ndecode, i.e. compute, the sum of the packets that were transmitted by the\nindividual users. For each user, the packet consists of the user's signature,\nas well as the data that the user wants to communicate. As long as no more than\nK users collide, their identities can be recovered from the sum of their\nsignatures. This framework for creating and transmitting packets can be used as\na fundamental building block in random access algorithms, since it helps to\ndeal efficiently with the uncertainty of the set of contending terminals. In\nthis paper we show how to apply the framework in conjunction with a\ntree-splitting algorithm, which is required to deal with the case that more\nthan K users collide. We demonstrate that our approach achieves throughput that\ntends to 1 rapidly as K increases. We also present results on net data-rate of\nthe system, showing the impact of the overheads of the constituent elements of\nthe proposed protocol. We compare the performance of our scheme with an upper\nbound that is obtained under the assumption that the active users are a priori\nknown. Also, we consider an upper bound on the net data-rate for any PLNC based\nstrategy in which one linear equation per slot is decoded. We show that already\nat modest packet lengths, the net data-rate of our scheme becomes close to the\nsecond upper bound, i.e. the overhead of the contention resolution algorithm\nand the signature codes vanishes. \n\n"}
{"id": "1602.05448", "contents": "Title: Optimal measurements for nonlocal correlations Abstract: A problem in quantum information theory is to find the experimental setup\nthat maximizes the nonlocality of correlations with respect to some suitable\nmeasure such as the violation of Bell inequalities. The latter has however some\ndrawbacks. First and foremost it is unfeasible to determine the whole set of\nBell inequalities already for a few measurements and thus unfeasible to find\nthe experimental setup maximizing their violation. Second, the Bell violation\nsuffers from an ambiguity stemming from the choice of the normalization of the\nBell coefficients. An alternative measure of nonlocality with a direct\ninformation-theoretic interpretation is the minimal amount of classical\ncommunication required for simulating nonlocal correlations. In the case of\nmany instances simulated in parallel, the minimal communication cost per\ninstance is called nonlocal capacity, and its computation can be reduced to a\nconvex-optimization problem. This quantity can be computed for a higher number\nof measurements and turns out to be useful for finding the optimal experimental\nsetup. Focusing on the bipartite case, in this paper, we present a simple\nmethod for maximizing the nonlocal capacity over a given configuration space\nand, in particular, over a set of possible measurements, yielding the\ncorresponding optimal setup. Furthermore, we show that there is a functional\nrelationship between Bell violation and nonlocal capacity. The method is\nillustrated with numerical tests and compared with the maximization of the\nviolation of CGLMP-type Bell inequalities on the basis of entangled two-qubit\nas well as two-qutrit states. Remarkably, the anomaly of nonlocality displayed\nby qutrits turns out to be even stronger if the nonlocal capacity is employed\nas a measure of nonlocality. \n\n"}
{"id": "1602.05629", "contents": "Title: Communication-Efficient Learning of Deep Networks from Decentralized\n  Data Abstract: Modern mobile devices have access to a wealth of data suitable for learning\nmodels, which in turn can greatly improve the user experience on the device.\nFor example, language models can improve speech recognition and text entry, and\nimage models can automatically select good photos. However, this rich data is\noften privacy sensitive, large in quantity, or both, which may preclude logging\nto the data center and training there using conventional approaches. We\nadvocate an alternative that leaves the training data distributed on the mobile\ndevices, and learns a shared model by aggregating locally-computed updates. We\nterm this decentralized approach Federated Learning.\n  We present a practical method for the federated learning of deep networks\nbased on iterative model averaging, and conduct an extensive empirical\nevaluation, considering five different model architectures and four datasets.\nThese experiments demonstrate the approach is robust to the unbalanced and\nnon-IID data distributions that are a defining characteristic of this setting.\nCommunication costs are the principal constraint, and we show a reduction in\nrequired communication rounds by 10-100x as compared to synchronized stochastic\ngradient descent. \n\n"}
{"id": "1602.06063", "contents": "Title: Pricing and Resource Allocation via Game Theory for a Small-Cell Video\n  Caching System Abstract: Evidence indicates that downloading on-demand videos accounts for a dramatic\nincrease in data traffic over cellular networks. Caching popular videos in the\nstorage of small-cell base stations (SBS), namely, small-cell caching, is an\nefficient technology for reducing the transmission latency whilst mitigating\nthe redundant transmissions of popular videos over back-haul channels. In this\npaper, we consider a commercialized small-cell caching system consisting of a\nnetwork service provider (NSP), several video retailers (VR), and mobile users\n(MU). The NSP leases its SBSs to the VRs for the purpose of making profits, and\nthe VRs, after storing popular videos in the rented SBSs, can provide faster\nlocal video transmissions to the MUs, thereby gaining more profits. We conceive\nthis system within the framework of Stackelberg game by treating the SBSs as a\nspecific type of resources. We first model the MUs and SBSs as two independent\nPoisson point processes, and develop, via stochastic geometry theory, the\nprobability of the specific event that an MU obtains the video of its choice\ndirectly from the memory of an SBS. Then, based on the probability derived, we\nformulate a Stackelberg game to jointly maximize the average profit of both the\nNSP and the VRs. Also, we investigate the Stackelberg equilibrium by solving a\nnon-convex optimization problem. With the aid of this game theoretic framework,\nwe shed light on the relationship between four important factors: the optimal\npricing of leasing an SBS, the SBSs allocation among the VRs, the storage size\nof the SBSs, and the popularity distribution of the VRs. Monte-Carlo\nsimulations show that our stochastic geometry-based analytical results closely\nmatch the empirical ones. Numerical results are also provided for quantifying\nthe proposed game-theoretic framework by showing its efficiency on pricing and\nresource allocation. \n\n"}
{"id": "1602.06155", "contents": "Title: Multiscale Analysis of Information Dynamics for Linear Multivariate\n  Processes Abstract: In the study of complex physical and physiological systems represented by\nmultivariate time series, an issue of great interest is the description of the\nsystem dynamics over a range of different temporal scales. While\ninformation-theoretic approaches to the multiscale analysis of complex dynamics\nare being increasingly used, the theoretical properties of the applied measures\nare poorly understood. This study introduces for the first time a framework for\nthe analytical computation of information dynamics for linear multivariate\nstochastic processes explored at different time scales. After showing that the\nmultiscale processing of a vector autoregressive (VAR) process introduces a\nmoving average (MA) component, we describe how to represent the resulting VARMA\nprocess using state-space (SS) models and how to exploit the SS model\nparameters to compute analytical measures of information storage and\ninformation transfer for the original and rescaled processes. The framework is\nthen used to quantify multiscale information dynamics for simulated\nunidirectionally and bidirectionally coupled VAR processes, showing that\nrescaling may lead to insightful patterns of information storage and transfer\nbut also to potentially misleading behaviors. \n\n"}
{"id": "1602.06215", "contents": "Title: Big Data Meets Telcos: A Proactive Caching Perspective Abstract: Mobile cellular networks are becoming increasingly complex to manage while\nclassical deployment/optimization techniques and current solutions (i.e., cell\ndensification, acquiring more spectrum, etc.) are cost-ineffective and thus\nseen as stopgaps. This calls for development of novel approaches that leverage\nrecent advances in storage/memory, context-awareness, edge/cloud computing, and\nfalls into framework of big data. However, the big data by itself is yet\nanother complex phenomena to handle and comes with its notorious 4V: velocity,\nvoracity, volume and variety. In this work, we address these issues in\noptimization of 5G wireless networks via the notion of proactive caching at the\nbase stations. In particular, we investigate the gains of proactive caching in\nterms of backhaul offloadings and request satisfactions, while tackling the\nlarge-amount of available data for content popularity estimation. In order to\nestimate the content popularity, we first collect users' mobile traffic data\nfrom a Turkish telecom operator from several base stations in hours of time\ninterval. Then, an analysis is carried out locally on a big data platform and\nthe gains of proactive caching at the base stations are investigated via\nnumerical simulations. It turns out that several gains are possible depending\non the level of available information and storage size. For instance, with 10%\nof content ratings and 15.4 Gbyte of storage size (87% of total catalog size),\nproactive caching achieves 100% of request satisfaction and offloads 98% of the\nbackhaul when considering 16 base stations. \n\n"}
{"id": "1602.06217", "contents": "Title: Synchronization and functional central limit theorems for interacting\n  reinforced random walks Abstract: We obtain Central Limit Theorems in Functional form for a class of\ntime-inhomogeneous interacting random walks on the simplex of probability\nmeasures over a finite set. Due to a reinforcement mechanism, the increments of\nthe walks are correlated, forcing their convergence to the same, possibly\nrandom, limit. Random walks of this form have been introduced in the context of\nurn models and in stochastic approximation. We also propose an application to\nopinion dynamics in a random network evolving via preferential attachment. We\nstudy, in particular, random walks interacting through a mean-field rule and\ncompare the rate they converge to their limit with the rate of synchronization,\ni.e. the rate at which their mutual distances converge to zero. Under certain\nconditions, synchronization is faster than convergence. \n\n"}
{"id": "1602.07731", "contents": "Title: Initial Access in 5G mm-Wave Cellular Networks Abstract: The massive amounts of bandwidth available at millimeter-wave frequencies\n(roughly above 10 GHz) have the potential to greatly increase the capacity of\nfifth generation cellular wireless systems. However, to overcome the high\nisotropic pathloss experienced at these frequencies, high directionality will\nbe required at both the base station and the mobile user equipment to establish\nsufficient link budget in wide area networks. This reliance on directionality\nhas important implications for control layer procedures. Initial access in\nparticular can be significantly delayed due to the need for the base station\nand the user to find the proper alignment for directional transmission and\nreception. This paper provides a survey of several recently proposed techniques\nfor this purpose. A coverage and delay analysis is performed to compare various\ntechniques including exhaustive and iterative search, and Context Information\nbased algorithms. We show that the best strategy depends on the target SNR\nregime, and provide guidelines to characterize the optimal choice as a function\nof the system parameters. \n\n"}
{"id": "1602.09001", "contents": "Title: Strong Coordination over Multi-hop Line Networks Abstract: We analyze the problem of strong coordination over a multi-hop line network\nin which the node initiating the coordination is a terminal network node. We\nassume that each node has access to a certain amount of randomness that is\nlocal to the node, and that the nodes share some common randomness, which are\nused together with explicit hop-by-hop communication to achieve strong\ncoordination. We derive the trade-offs among the required rates of\ncommunication on the network links, the rates of local randomness available to\nnetwork nodes, and the rate of common randomness to realize strong\ncoordination. We present an achievable coding scheme built using multiple\nlayers of channel resolvability codes, and establish several settings in which\nthis scheme is proven to offer the best possible trade-offs. \n\n"}
{"id": "1603.01921", "contents": "Title: Optimal Geographic Caching in Finite Wireless Networks Abstract: Cache-enabled device-to-device (D2D) networks turn memory of the devices at\nthe network edge, such as smart phones and tablets, into bandwidth by enabling\nasynchronous content sharing directly between proximate devices. Limited\nstorage capacity of the mobile devices necessitates the determination of\noptimal set of contents to be cached on each device. In order to study the\nproblem of optimal cache placement, we model the locations of devices in a\nfinite region (e.g., coffee shop, sports bar, library) as a uniform binomial\npoint process (BPP). For this setup, we first develop a generic framework to\nanalyze the coverage probability of the target receiver (target-Rx) when the\nrequested content is available at the $k^{th}$ closest device to it. Using this\ncoverage probability result, we evaluate optimal caching probability of the\npopular content to maximize the total hit probability. Our analysis concretely\ndemonstrates that optimal caching probability strongly depends on the number of\nsimultaneously active devices in the network. \n\n"}
{"id": "1603.02863", "contents": "Title: LDA Lattices Without Dithering Achieve Capacity on the Gaussian Channel Abstract: This paper deals with Low-Density Construction-A (LDA) lattices, which are\nobtained via Construction A from non-binary Low-Density Parity-Check codes.\nMore precisely, a proof is provided that Voronoi constellations of LDA lattices\nachieve the capacity of the AWGN channel under lattice encoding and decoding.\nThis is obtained after showing the same result for more general Construction-A\nlattice constellations. The theoretical analysis is carried out in a way that\nallows to describe how the prime number underlying Construction A behaves as a\nfunction of the lattice dimension. Moreover, no dithering is required in the\ntransmission scheme, simplifying some previous solutions of the problem.\nRemarkably, capacity is achievable with LDA lattice codes whose parity-check\nmatrices have constant row and column Hamming weights. Some expansion\nproperties of random bipartite graphs constitute an extremely important tool\nfor dealing with sparse matrices and allow to find a lower bound of the minimum\nEuclidean distance of LDA lattices in our ensemble. \n\n"}
{"id": "1603.04174", "contents": "Title: On Nyquist-Shannon Theorem with one-sided half of sampling sequence Abstract: The classical sampling Nyquist-Shannon-Kotelnikov theorem states that a\nband-limited continuous time function can be uniquely recovered without error\nfrom a infinite two-sided sampling series taken with a sufficient frequency.\nThis short note shows that the function can be recovered from any one-sided\nsemi-infinite half of any oversampling series, with the same boundary for\nadmissible frequencies as in the classical theorem. \n\n"}
{"id": "1603.06006", "contents": "Title: Polynomial Time Relatively Computable Triangular Arrays in a Multinomial\n  Setting Abstract: We extend the methods and results of [arXiv 1603.04896] to the setting of\nmultinomial distributions satisfying certain properties. These include all the\nmultinomial distributions arising from the direct proof of the Central Limit\nTheorem given in [arXiv: 1507.00357], which, by results of that paper,\nconstitutes essentially full generality for the situations in which the Central\nLimit Theorem holds. \n\n"}
{"id": "1603.07052", "contents": "Title: Cluster Content Caching: An Energy-Efficient Approach to Improve Quality\n  of Service in Cloud Radio Access Networks Abstract: In cloud radio access networks (C-RANs), a substantial amount of data must be\nexchanged in both backhaul and fronthaul links, which causes high power\nconsumption and poor quality of service (QoS) experience for real-time\nservices. To solve this problem, a cluster content caching structure is\nproposed in this paper, which takes full advantage of distributed caching and\ncentralized signal processing. In particular, redundant traffic on the backhaul\ncan be reduced because the cluster content cache provides a part of required\ncontent objects for remote radio heads (RRHs) connected to a common edge cloud.\nTractable expressions for both effective capacity and energy efficiency\nperformance are derived, which show that the proposed structure can improve QoS\nguarantees with a lower power cost of local storage. Furthermore, to fully\nexplore the potential of the proposed cluster content caching structure, the\njoint design of resource allocation and RRH association is optimized, and two\ndistributed algorithms are accordingly proposed. Simulation results verify the\naccuracy of the analytical results and show the performance gains achieved by\ncluster content caching in C-RANs. \n\n"}
{"id": "1603.07377", "contents": "Title: Overcoming The Limitations of Phase Transition by Higher Order Analysis\n  of Regularization Techniques Abstract: We study the problem of estimating $\\beta \\in \\mathbb{R}^p$ from its noisy\nlinear observations $y= X\\beta+ w$, where $w \\sim N(0, \\sigma_w^2 I_{n\\times\nn})$, under the following high-dimensional asymptotic regime: given a fixed\nnumber $\\delta$, $p \\rightarrow \\infty$, while $n/p \\rightarrow \\delta$. We\nconsider the popular class of $\\ell_q$-regularized least squares (LQLS)\nestimators, a.k.a. bridge, given by the optimization problem: \\begin{equation*}\n\\hat{\\beta} (\\lambda, q ) \\in \\arg\\min_\\beta \\frac{1}{2} \\|y-X\\beta\\|_2^2+\n\\lambda \\|\\beta\\|_q^q, \\end{equation*} and characterize the almost sure limit\nof $\\frac{1}{p} \\|\\hat{\\beta} (\\lambda, q )- \\beta\\|_2^2$. The expression we\nderive for this limit does not have explicit forms and hence are not useful in\ncomparing different algorithms, or providing information in evaluating the\neffect of $\\delta$ or sparsity level of $\\beta$. To simplify the expressions,\nresearchers have considered the ideal \"no-noise\" regime and have characterized\nthe values of $\\delta$ for which the almost sure limit is zero. This is known\nas the phase transition analysis.\n  In this paper, we first perform the phase transition analysis of LQLS. Our\nresults reveal some of the limitations and misleading features of the phase\ntransition analysis. To overcome these limitations, we propose the study of\nthese algorithms under the low noise regime. Our new analysis framework not\nonly sheds light on the results of the phase transition analysis, but also\nmakes an accurate comparison of different regularizers possible. \n\n"}
{"id": "1603.08080", "contents": "Title: On the Performance of Millimeter Wave-based RF-FSO Links with HARQ\n  Feedback Abstract: This paper studies the performance of hybrid radio-frequency (RF) and\nfree-space optical (FSO) links in the cases with and without hybrid automatic\nrepeat request (HARQ). Considering millimeter wave (mmwave) characteristics in\nthe RF link and pointing errors in the FSO link, we derive closed-form\nexpressions for the message decoding probabilities as well as the throughput\nand the outage probability of the RF-FSO setups. We also evaluate the effect of\nvarious parameters such as power amplifiers efficiency, different transmission\ntechniques in the FSO link, pointing errors in the FSO link as well as\ndifferent coherence times/symbol rates of the RF and the FSO links on the\nthroughput and outage probability. The results show the efficiency of the\nRF-FSO links in different conditions. Moreover, the HARQ can effectively\nimprove the outage probability/energy efficiency, and compensate the effect of\nhardware impairments in RF-FSO links. \n\n"}
{"id": "1603.08387", "contents": "Title: Post-processing procedure for industrial quantum key distribution\n  systems Abstract: We present algorithmic solutions aimed on post-processing for industrial\nquantum key distribution systems with hardware sifting. The main steps of the\nprocedure are error correction, parameter estimation, and privacy\namplification. Authentication of a classical public communication channel is\nalso considered. \n\n"}
{"id": "1603.08885", "contents": "Title: On the Performance of Delay Aware Shared Access with Priorities Abstract: In this paper, we analyze a shared access network with a fixed primary node\nand randomly distributed secondary nodes whose distribution follows a Poisson\npoint process (PPP). The secondaries use a random access protocol allowing them\nto access the channel with probabilities that depend on the queue size of the\nprimary. Assuming a system with multipacket reception (MPR) receivers having\nbursty packet arrivals at the primary and saturation at the secondaries, our\nprotocol can be tuned to alleviate congestion at the primary. We study the\nthroughput of the secondary network and the primary average delay, as well as\nthe impact of the secondary node access probability and transmit power. We\nformulate an optimization problem to maximize the throughput of the secondary\nnetwork under delay constraints for the primary node, which in the case that no\ncongestion control is performed has a closed form expression providing the\noptimal access probability. Our numerical results illustrate the impact of\nnetwork operating parameters on the performance of the proposed priority-based\nshared access protocol. \n\n"}
{"id": "1603.09601", "contents": "Title: Joint Millimeter-Wave Fronthaul and OFDMA Resource Allocation in\n  Ultra-Dense CRAN Abstract: Ultra-dense (UD) wireless networks and cloud radio access networks (CRAN) are\ntwo promising network architectures for the emerging fifth-generation (5G)\nwireless communication systems. By jointly employing them, a new appealing\nnetwork solution is proposed in this paper, termed UD-CRAN. In a UD-CRAN,\nmillimeter-wave (mmWave) wireless fronthaul is preferred for information\nexchange between the central processor and the distributed remote radio heads\n(RRHs), due to its lower cost and higher flexibility in deployment, compared to\nfixed optical links. This motivates our study in this paper on the downlink\ntransmission in a mmWave fronthaul enabled, orthogonal frequency division\nmultiple access (OFDMA) based UD-CRAN. In particular, the fronthaul is shared\namong the RRHs via time division multiple access (TDMA), while the RRHs jointly\ntransmit to the users on orthogonal frequency subchannels using OFDMA. The\njoint resource allocation over the TDMA-based mmWave fronthaul and OFDMA-based\nwireless transmission is investigated to maximize the weighted sum rate of all\nusers. Although the problem is non-convex, we propose a Lagrange duality based\nsolution, which can be efficiently computed with good accuracy. To further\nreduce the complexity, we also propose a greedy search based heuristic, which\nachieves close to optimal performance under practical setups. Finally, we show\nthe significant throughput gains of the proposed joint resource allocation\napproach compared to other benchmark schemes by simulations. \n\n"}
{"id": "1604.00565", "contents": "Title: A Statistical Block Fading Channel Model for Multiuser Massive MIMO\n  System Abstract: This paper presents a statistical block fading channel model for multiuser\nmassive MIMO system. The proposed channel model is evolved from correlation\nbased stochastic channel model (CBSCM) but in addition to the properties of\nCBSCM, it has capability of capturing channel variations along time or\nfrequency and along space simultaneously. It has a simplified analytical\nexpression, still being able to simulate underlying physical phenomena which\notherwise need a complex geometry based stochastic channel model (GBSCM). The\nchannel model is verified with reported measurement data of channel for massive\nMIMO. Spatial determinism in channel, the basic cause of unfavorable\npropagation, is modeled into controlling parameters of channel model. Channel\nmodel uses only three controlling parameters; one parameter describes variation\nin channel along resource block (along time or frequency) and remaining two\nparameters describe spatial variation in channel. Modeling of simultaneous\nvariation along time and space belongs to a very common scenario where mobility\nof mobile terminal and angular power distribution at base station receiver, are\nkey parameters. Additionally, simulation results reveal the hidden advantages\nof spatial determinism in channel for multiuser massive MIMO. \n\n"}
{"id": "1604.00786", "contents": "Title: A Survey of Energy-Efficient Techniques for 5G Networks and Challenges\n  Ahead Abstract: After about a decade of intense research, spurred by both economic and\noperational considerations, and by environmental concerns, energy efficiency\nhas now become a key pillar in the design of communication networks. With the\nadvent of the fifth generation of wireless networks, with millions more base\nstations and billions of connected devices, the need for energy-efficient\nsystem design and operation will be even more compelling. This survey provides\nan overview of energy-efficient wireless communications, reviews seminal and\nrecent contribution to the state-of-the-art, including the papers published in\nthis special issue, and discusses the most relevant research challenges to be\naddressed in the future. \n\n"}
{"id": "1604.01653", "contents": "Title: Optimal DoF of the K-User Broadcast Channel with Delayed and Imperfect\n  Current CSIT Abstract: This work studies the optimal Degrees-of-Freedom (DoF) of the $K$-User MISO\nBroadcast Channel (BC) with delayed Channel-State Information at the\nTransmitter (CSIT) and with additional current noisy CSIT where the current\nchannel estimation error scales in~$P^{-\\alpha}$ for $\\alpha\\in[0,1]$. This\npapers establishes for the first time the optimal DoF in this setting thanks to\na new transmission scheme which achieves the elusive DoF-optimal combining of\nthe Maddah-Ali and Tse scheme (MAT) introduced in their seminal work in $2010$\nwith Zero-Forcing (ZF) for an arbitrary number of users. The derived sum DoF\ntakes the surprisingly simple form $(1-\\alpha) K/H_K+\\alpha K$ where\n$H_K\\triangleq \\sum_{k=1}^K \\frac{1}{k}$ is the sum-DoF achieved using solely\nMAT. \n\n"}
{"id": "1604.01835", "contents": "Title: Exploiting Full-duplex Receivers for Achieving Secret Communications in\n  Multiuser MISO Networks Abstract: We consider a broadcast channel, in which a multi-antenna transmitter (Alice)\nsends $K$ confidential information signals to $K$ legitimate users (Bobs) in\nthe presence of $L$ eavesdroppers (Eves). Alice uses MIMO precoding to generate\nthe information signals along with her own (Tx-based) friendly jamming.\nInterference at each Bob is removed by MIMO zero-forcing. This, however, leaves\na \"vulnerability region\" around each Bob, which can be exploited by a nearby\nEve. We address this problem by augmenting Tx-based friendly jamming (TxFJ)\nwith Rx-based friendly jamming (RxFJ), generated by each Bob. Specifically,\neach Bob uses self-interference suppression (SIS) to transmit a friendly\njamming signal while simultaneously receiving an information signal over the\nsame channel. We minimize the powers allocated to the information, TxFJ, and\nRxFJ signals under given guarantees on the individual secrecy rate for each\nBob. The problem is solved for the cases when the eavesdropper's channel state\ninformation is known/unknown. Simulations show the effectiveness of the\nproposed solution. Furthermore, we discuss how to schedule transmissions when\nthe rate requirements need to be satisfied on average rather than\ninstantaneously. Under special cases, a scheduling algorithm that serves only\nthe strongest receivers is shown to outperform the one that schedules all\nreceivers. \n\n"}
{"id": "1604.02442", "contents": "Title: On the Secrecy Capacity Region of the 2-user Z Interference Channel with\n  Unidirectional Transmitter Cooperation Abstract: In this work, the role of unidirectional limited rate transmitter cooperation\nis studied in the case of the 2-user Z interference channel (Z-IC) with secrecy\nconstraints at the receivers, on achieving two conflicting goals\nsimultaneously: mitigating interference and ensuring secrecy. First, the\nproblem is studied under the linear deterministic model. The achievable schemes\nfor the deterministic model use a fusion of cooperative precoding and\ntransmission of a jamming signal. The optimality of the proposed scheme is\nestablished for the deterministic model for all possible parameter settings\nusing the outer bounds derived by the authors in a previous work. Using the\ninsights obtained from the deterministic model, a lower bound on the secrecy\ncapacity region of the 2-user Gaussian Z-IC are obtained. The achievable scheme\nin this case uses stochastic encoding in addition to cooperative precoding and\ntransmission of a jamming signal. The secure sum generalized degrees of freedom\n(GDOF) is characterized and shown to be optimal for the weak/moderate\ninterference regime. It is also shown that the secure sum capacity lies within\n2 bits/s/Hz of the outer bound for the weak/moderate interference regime for\nall values of the capacity of the cooperative link. Interestingly, in case of\nthe deterministic model, it is found that there is no penalty on the capacity\nregion of the Z-IC due to the secrecy constraints at the receivers in the\nweak/moderate interference regimes. Similarly, it is found that there is no\nloss in the secure sum GDOF for the Gaussian case due to the secrecy constraint\nat the receiver, in the weak/moderate interference regimes. The results\nhighlight the importance of cooperation in facilitating secure communication\nover the Z-IC. \n\n"}
{"id": "1604.02730", "contents": "Title: Construction methods for generalized bent functions Abstract: Generalized bent (gbent) functions is a class of functions $f: \\mathbb{Z}_2^n\n\\rightarrow \\mathbb{Z}_q$, where $q \\geq 2$ is a positive integer, that\ngeneralizes a concept of classical bent functions through their co-domain\nextension. A lot of research has recently been devoted towards derivation of\nthe necessary and sufficient conditions when $f$ is represented as a collection\nof Boolean functions. Nevertheless, apart from the necessary conditions that\nthese component functions are bent when $n$ is even (respectively semi-bent\nwhen $n$ is odd), no general construction method has been proposed yet for $n$\nodd case. In this article, based on the use of the well-known\nMaiorana-McFarland (MM) class of functions, we give an explicit construction\nmethod of gbent functions, for any even $q >2$ when $n$ is even and for any $q$\nof the form $q=2^r$ (for $r>1$) when $n$ is odd. Thus, a long-term open problem\nof providing a general construction method of gbent functions, for odd $n$, has\nbeen solved. The method for odd $n$ employs a large class of disjoint spectra\nsemi-bent functions with certain additional properties which may be useful in\nother cryptographic applications. \n\n"}
{"id": "1604.05823", "contents": "Title: On New Quantum Codes From Matrix Product Codes Abstract: In this paper, by using matrix product codes, several classes of new quantum\ncodes are obtained. Moreover, some of them have better parameters than the\nprevious quantum codes available. \n\n"}
{"id": "1604.06567", "contents": "Title: Concurrent Regenerating Codes and Scalable Application in Network\n  Storage Abstract: To recover simultaneous multiple failures in erasure coded storage systems,\nPatrick Lee et al introduce concurrent repair based minimal storage\nregenerating codes to reduce repair traffic. The architecture of this approach\nis simpler and more practical than that of the cooperative mechanism in\nnon-fully distributed environment, hence this paper unifies such class of\nregenerating codes as concurrent regenerating codes and further studies its\ncharacteristics by analyzing cut-based information flow graph in the\nmultiple-node recovery model. We present a general storage-bandwidth tradeoff\nand give closed-form expressions for the points on the curve, including\nconcurrent repair mechanism based on minimal bandwidth regenerating codes. We\nshow that the general concurrent regenerating codes can be constructed by\nreforming the existing single-node regenerating codes or multiplenode\ncooperative regenerating codes. Moreover, a connection to strong-MDS is also\nanalyzed. On the other respect, the application of RGC is hardly limited to\n\"repairing\". It is of great significance for \"scaling\", a scenario where we\nneed to increase(decrease) nodes to upgrade(degrade) redundancy and\nreliability. Thus, by clarifying the similarities and differences, we integrate\nthem into a unified model to adjust to the dynamic storage network. \n\n"}
{"id": "1604.08231", "contents": "Title: When Can Helper Node Selection Improve Regenerating Codes? Part I:\n  Graph-Based Analysis Abstract: Regenerating codes (RCs) can significantly reduce the repair-bandwidth of\ndistributed storage networks. Initially, the analysis of RCs was based on the\nassumption that during the repair process, the newcomer does not distinguish\n(among all surviving nodes) which nodes to access, i.e., the newcomer is\noblivious to the set of helpers being used. Such a scheme is termed the blind\nhelper selection (BHS) scheme. Nonetheless, it is intuitive in practice that\nthe newcomer should choose to access only those \"good\" helpers. In this\ntwo-part paper, a new characterization of the effect of choosing the helper\nnodes in terms of the storage-bandwidth tradeoff is given. Specifically, the\nanswer to the following fundamental question is provided: Under what condition\ndoes proactively choosing the helper nodes improve the storage-bandwidth\ntradeoff?\n  Through a graph-based analysis, this Part I paper answers this question by\nproviding a necessary and sufficient condition under which optimally choosing\ngood helpers strictly improves the storage-bandwidth tradeoff. A low-complexity\nhelper selection solution, termed the family helper selection (FHS) scheme, is\nproposed and the corresponding storage/repair-bandwidth curve is characterized.\nThis Part I paper also proves that under some design parameters, the FHS scheme\nis indeed optimal among all helper selection schemes. In the Part II paper, an\nexplicit construction of an exact-repair code is proposed that achieves the\nminimum-bandwidth-regenerating (MBR) point of the FHS scheme. The new\nexact-repair code can be viewed as a generalization of the existing fractional\nrepetition code. \n\n"}
{"id": "1604.08937", "contents": "Title: User Selection and Power Allocation in Full Duplex Multi-Cell Networks Abstract: Full duplex (FD) communications has the potential to double the capacity of a\nhalf duplex (HD) system at the link level. However, in a cellular network, FD\noperation is not a straightforward extension of half duplex operations. The\nincreased interference due to a large number of simultaneous transmissions in\nFD operation and realtime traffic conditions limits the capacity improvement.\nRealizing the potential of FD requires careful coordination of resource\nallocation among the cells as well as within the cell. In this paper, we\npropose a distributed resource allocation, i.e., joint user selection and power\nallocation for a FD multi-cell system, assuming FD base stations (BSs) and HD\nuser equipment (UEs). Due to the complexity of finding the globally optimum\nsolution, a sub-optimal solution for UE selection, and a novel geometric\nprogramming based solution for power allocation, are proposed. The proposed\ndistributed approach converges quickly and performs almost as well as a\ncentralized solution, but with much lower signaling overhead. It provides a\nhybrid scheduling policy which allows FD operations whenever it is\nadvantageous, but otherwise defaults to HD operation. We focus on small cell\nsystems because they are more suitable for FD operation, given practical\nself-interference cancellation limits.With practical self-interference\ncancellation, it is shown that the proposed hybrid FD system achieves nearly\ntwo times throughput improvement for an indoor multi-cell scenario, and about\n65% improvement for an outdoor multi-cell scenario compared to the HD system. \n\n"}
{"id": "1605.00019", "contents": "Title: Sharp Bounds Between Two R\\'enyi Entropies of Distinct Positive Orders Abstract: Many axiomatic definitions of entropy, such as the R\\'enyi entropy, of a\nrandom variable are closely related to the $\\ell_{\\alpha}$-norm of its\nprobability distribution. This study considers probability distributions on\nfinite sets, and examines the sharp bounds of the $\\ell_{\\beta}$-norm with a\nfixed $\\ell_{\\alpha}$-norm, $\\alpha \\neq \\beta$, for $n$-dimensional\nprobability vectors with an integer $n \\ge 2$. From the results, we derive the\nsharp bounds of the R\\'enyi entropy of positive order $\\beta$ with a fixed\nR\\'enyi entropy of another positive order $\\alpha$. As applications, we\ninvestigate sharp bounds of Ariomoto's mutual information of order $\\alpha$ and\nGallager's random coding exponents for uniformly focusing channels under the\nuniform input distribution. \n\n"}
{"id": "1605.01105", "contents": "Title: Communication Cost for Updating Linear Functions when Message Updates\n  are Sparse: Connections to Maximally Recoverable Codes Abstract: We consider a communication problem in which an update of the source message\nneeds to be conveyed to one or more distant receivers that are interested in\nmaintaining specific linear functions of the source message. The setting is one\nin which the updates are sparse in nature, and where neither the source nor the\nreceiver(s) is aware of the exact {\\em difference vector}, but only know the\namount of sparsity that is present in the difference-vector. Under this\nsetting, we are interested in devising linear encoding and decoding schemes\nthat minimize the communication cost involved. We show that the optimal\nsolution to this problem is closely related to the notion of maximally\nrecoverable codes (MRCs), which were originally introduced in the context of\ncoding for storage systems. In the context of storage, MRCs guarantee optimal\nerasure protection when the system is partially constrained to have local\nparity relations among the storage nodes. In our problem, we show that optimal\nsolutions exist if and only if MRCs of certain kind (identified by the desired\nlinear functions) exist. We consider point-to-point and broadcast versions of\nthe problem, and identify connections to MRCs under both these settings. For\nthe point-to-point setting, we show that our linear-encoder based achievable\nscheme is optimal even when non-linear encoding is permitted. The theory is\nillustrated in the context of updating erasure coded storage nodes. We present\nexamples based on modern storage codes such as the minimum bandwidth\nregenerating codes. \n\n"}
{"id": "1605.01191", "contents": "Title: Waveform Optimization for Large-Scale Multi-Antenna Multi-Sine Wireless\n  Power Transfer Abstract: Wireless power transfer (WPT) is expected to be a technology reshaping the\nlandscape of low-power applications such as the Internet of Things,\nmachine-to-machine communications and radio frequency identification networks.\nAlthough there has been some progress towards multi-antenna multi-sine WPT\ndesign, the large-scale design of WPT, reminiscent of massive multiple-input\nmultiple-output (MIMO) in communications, remains an open problem. Considering\nthe nonlinear rectifier model, a multiuser waveform optimization algorithm is\nderived based on successive convex approximation (SCA). A lower-complexity\nalgorithm is derived based on asymptotic analysis and sequential approximation\n(SA). It is shown that the difference between the average output voltage\nachieved by the two algorithms can be negligible provided the number of\nantennas is large enough. The performance gain of the nonlinear model based\ndesign over the linear model based design can be large, in the presence of a\nlarge number of tones. \n\n"}
{"id": "1605.01589", "contents": "Title: On Barnes Beta Distributions and Applications to the Maximum\n  Distribution of the 2D Gaussian Free Field Abstract: A new family of Barnes beta distributions on $(0, \\infty)$ is introduced and\nits infinite divisibility, moment determinacy, scaling, and factorization\nproperties are established. The Morris integral probability distribution is\nconstructed from Barnes beta distributions of types $(1,0)$ and $(2,2),$ and\nits moment determinacy and involution invariance properties are established.\nFor application, the maximum distributions of the 2D gaussian free field on the\nunit interval and circle with a non-random logarithmic potential are\nconjecturally related to the critical Selberg and Morris integral probability\ndistributions, respectively, and expressed in terms of sums of Barnes beta\ndistributions of types $(1,0)$ and $(2,2).$ \n\n"}
{"id": "1605.01690", "contents": "Title: Fog-Aided Wireless Networks for Content Delivery: Fundamental Latency\n  Trade-Offs Abstract: A fog-aided wireless network architecture is studied in which edge-nodes\n(ENs), such as base stations, are connected to a cloud processor via dedicated\nfronthaul links, while also being endowed with caches. Cloud processing enables\nthe centralized implementation of cooperative transmission strategies at the\nENs, albeit at the cost of an increased latency due to fronthaul transfer. In\ncontrast, the proactive caching of popular content at the ENs allows for the\nlow-latency delivery of the cached files, but with generally limited\nopportunities for cooperative transmission among the ENs. The interplay between\ncloud processing and edge caching is addressed from an information-theoretic\nviewpoint by investigating the fundamental limits of a high\nSignal-to-Noise-Ratio (SNR) metric, termed normalized delivery time (NDT),\nwhich captures the worst-case coding latency for delivering any requested\ncontent to the users. The NDT is defined under the assumptions of either serial\nor pipelined fronthaul-edge transmission, and is studied as a function of\nfronthaul and cache capacity constraints. Placement and delivery strategies\nacross both fronthaul and wireless, or edge, segments are proposed with the aim\nof minimizing the NDT. Information-theoretic lower bounds on the NDT are also\nderived. Achievability arguments and lower bounds are leveraged to characterize\nthe minimal NDT in a number of important special cases, including systems with\nno caching capabilities, as well as to prove that the proposed schemes achieve\noptimality within a constant multiplicative factor of 2 for all values of the\nproblem parameters. \n\n"}
{"id": "1605.01930", "contents": "Title: Context Information Based Initial Cell Search for Millimeter Wave 5G\n  Cellular Networks Abstract: Millimeter wave (mmWave) communication is envisioned as a cornerstone to\nfulfill the data rate requirements for fifth generation (5G) cellular networks.\nIn mmWave communication, beamforming is considered as a key technology to\ncombat the high path-loss, and unlike in conventional microwave communication,\nbeamforming may be necessary even during initial access/cell search. Among the\nproposed beamforming schemes for initial cell search, analog beamforming is a\npower efficient approach but suffers from its inherent search delay during\ninitial access. In this work, we argue that analog beamforming can still be a\nviable choice when context information about mmWave base stations (BS) is\navailable at the mobile station (MS). We then study how the performance of\nanalog beamforming degrades in case of angular errors in the available context\ninformation. Finally, we present an analog beamforming receiver architecture\nthat uses multiple arrays of Phase Shifters and a single RF chain to combat the\neffect of angular errors, showing that it can achieve the same performance as\nhybrid beamforming. \n\n"}
{"id": "1605.02077", "contents": "Title: Function-Specific Mixing Times and Concentration Away from Equilibrium Abstract: Slow mixing is the central hurdle when working with Markov chains, especially\nthose used for Monte Carlo approximations (MCMC). In many applications, it is\nonly of interest to estimate the stationary expectations of a small set of\nfunctions, and so the usual definition of mixing based on total variation\nconvergence may be too conservative. Accordingly, we introduce\nfunction-specific analogs of mixing times and spectral gaps, and use them to\nprove Hoeffding-like function-specific concentration inequalities. These\nresults show that it is possible for empirical expectations of functions to\nconcentrate long before the underlying chain has mixed in the classical sense,\nand we show that the concentration rates we achieve are optimal up to\nconstants. We use our techniques to derive confidence intervals that are\nsharper than those implied by both classical Markov chain Hoeffding bounds and\nBerry-Esseen-corrected CLT bounds. For applications that require testing,\nrather than point estimation, we show similar improvements over recent\nsequential testing results for MCMC. We conclude by applying our framework to\nreal data examples of MCMC, providing evidence that our theory is both accurate\nand relevant to practice. \n\n"}
{"id": "1605.02597", "contents": "Title: Fundamental Limits of Spectrum Sharing Full-Duplex Multicell Networks Abstract: This paper studies the degrees of freedom of full-duplex multicell networks\nthat share the spectrum among multiple cells in a non-orthogonal setting. In\nthe considered network, we assume that {\\em full-duplex} base stations with\nmultiple transmit and receive antennas communicate with multiple single-antenna\nmobile users. By spectrum sharing among multiple cells and (simultaneously)\nenabling full-duplex radio, the network can utilize the spectrum more flexibly,\nbut, at the same time, the network is subject to multiple sources of\ninterference compared to a network with separately dedicated bands for distinct\ncells and uplink--downlink traffic. Consequently, to take advantage of the\nadditional freedom in utilizing the spectrum, interference management is a\ncrucial ingredient. In this work, we propose a novel strategy based on\ninterference alignment which takes into account inter-cell interference and\nintra-cell interference caused by spectrum sharing and full-duplex to establish\na general achievability result on the sum degrees of freedom of the considered\nnetwork. Paired with an upper bound on the sum degrees of freedom, which is\ntight under certain conditions, we demonstrate how spectrum sharing and\nfull-duplex can significantly improve the throughput over conventional cellular\nnetworks, especially for a network with large number of users and/or cells. \n\n"}
{"id": "1605.02615", "contents": "Title: A Non-Convex Blind Calibration Method for Randomised Sensing Strategies Abstract: The implementation of computational sensing strategies often faces\ncalibration problems typically solved by means of multiple, accurately chosen\ntraining signals, an approach that can be resource-consuming and cumbersome.\nConversely, blind calibration does not require any training, but corresponds to\na bilinear inverse problem whose algorithmic solution is an open issue. We here\naddress blind calibration as a non-convex problem for linear random sensing\nmodels in which we aim to recover an unknown signal from its projections on\nsub-Gaussian random vectors, each of which is subject to an unknown\nmultiplicative factor (gain). To solve this optimisation problem we resort to\nprojected gradient descent starting from a suitable initialisation. An analysis\nof this algorithm allows us to show that it converges to the global optimum\nprovided a sample complexity requirement is met, i.e., relating convergence to\nthe amount of information collected during the sensing process. Finally, we\npresent some numerical experiments in which our algorithm allows for a simple\nsolution to blind calibration of sensor gains in computational sensing\napplications. \n\n"}
{"id": "1605.02928", "contents": "Title: Achievable Degrees of Freedom of the K-user MISO Broadcast Channel with\n  Alternating CSIT via Interference Creation-Resurrection Abstract: Channel state information at the transmitter affects the degrees of freedom\nof the wireless networks. In this paper, we analyze the DoF for the K-user\nmultiple-input single-output (MISO) broadcast channel (BC) with synergistic\nalternating channel state information at the transmitter (CSIT). Specifically,\nthe CSIT of each user alternates between three states, namely, perfect CSIT\n(P), delayed CSIT (D) and no CSIT (N) among different time slots. For the\nK-user MISO BC, we show that the total achievable degrees of freedom (DoF) are\ngiven by $\\frac{K^{2}}{2K-1}$ through utilizing the synergistic benefits of\nCSIT patterns. We compare the achievable DoF with results reported previously\nin the literature in the case of delayed CSIT and hybrid CSIT models. \n\n"}
{"id": "1605.03518", "contents": "Title: Relaying Strategies for Wireless-Powered MIMO Relay Networks Abstract: This paper investigates relaying schemes in an amplify-and-forward\nmultiple-input multiple-output relay network, where an energy-constrained relay\nharvests wireless power from the source information flow and can be further\naided by an energy flow (EF) in the form of a wireless power transfer at the\ndestination. However, the joint optimization of the relay matrix and the source\nprecoder for the energy-flow-assisted (EFA) and the non-EFA (NEFA) schemes is\nintractable. The original rate maximization problem is transformed into an\nequivalent weighted mean square error minimization problem and optimized\niteratively, where the global optimum of the nonconvex source precoder\nsubproblem is achieved by semidefinite relaxation and rank reduction. The\niterative algorithm finally converges. Then, the simplified EFA and NEFA\nschemes are proposed based on channel diagonalization, such that the matrices\noptimizations can be simplified to power optimizations. Closed-form solutions\ncan be achieved. Simulation results reveal that the EFA schemes can outperform\nthe NEFA schemes. Additionally, deploying more antennas at the relay increases\nthe dimension of the signal space at the relay. Exploiting the additional\ndimension, the EF leakage in the information detecting block can be nearly\nseparated from the information signal, such that the EF leakage can be\namplified with a small coefficient. \n\n"}
{"id": "1605.04184", "contents": "Title: Scalable Information Inequalities for Uncertainty Quantification Abstract: In this paper we demonstrate the only available scalable information bounds\nfor quantities of interest of high dimensional probabilistic models.\nScalability of inequalities allows us to (a) obtain uncertainty quantification\nbounds for quantities of interest in the large degree of freedom limit and/or\nat long time regimes; (b) assess the impact of large model perturbations as in\nnonlinear response regimes in statistical mechanics; (c) address model-form\nuncertainty, i.e. compare different extended models and corresponding\nquantities of interest. We demonstrate some of these properties by deriving\nrobust uncertainty quantification bounds for phase diagrams in statistical\nmechanics models. \n\n"}
{"id": "1605.04989", "contents": "Title: Architecture-aware Coding for Distributed Storage: Repairable Block\n  Failure Resilient Codes Abstract: In large scale distributed storage systems (DSS) deployed in cloud computing,\ncorrelated failures resulting in simultaneous failure (or, unavailability) of\nblocks of nodes are common. In such scenarios, the stored data or a content of\na failed node can only be reconstructed from the available live nodes belonging\nto the available blocks. To analyze the resilience of the system against such\nblock failures, this work introduces the framework of Block Failure Resilient\n(BFR) codes, wherein the data (e.g., a file in DSS) can be decoded by reading\nout from a same number of codeword symbols (nodes) from a subset of available\nblocks of the underlying codeword. Further, repairable BFR codes are\nintroduced, wherein any codeword symbol in a failed block can be repaired by\ncontacting a subset of remaining blocks in the system. File size bounds for\nrepairable BFR codes are derived, and the trade-off between per node storage\nand repair bandwidth is analyzed, and the corresponding minimum storage\nregenerating (BFR-MSR) and minimum bandwidth regenerating (BFR-MBR) points are\nderived. Explicit codes achieving the two operating points for a special case\nof parameters are constructed, wherein the underlying regenerating codewords\nare distributed to BFR codeword symbols according to combinatorial designs.\nFinally, BFR locally repairable codes (BFR-LRC) are introduced, an upper bound\non the resilience is derived and optimal code construction are provided by a\nconcatenation of Gabidulin and MDS codes. Repair efficiency of BFR-LRC is\nfurther studied via the use of BFR-MSR/MBR codes as local codes. Code\nconstructions achieving optimal resilience for BFR-MSR/MBR-LRCs are provided\nfor certain parameter regimes. Overall, this work introduces the framework of\nblock failures along with optimal code constructions, and the study of\narchitecture-aware coding for distributed storage systems. \n\n"}
{"id": "1605.05227", "contents": "Title: Revisiting XOR-based Network Coding for Energy Efficient Broadcasting in\n  Mobile Ad Hoc Networks Abstract: Network coding is commonly used to improve the energy efficiency of\nnetwork-wide broadcasting in wireless multi-hop networks. In this work, we\nfocus on XOR-based broadcasting in mobile ad hoc networks with multiple\nsources. We make the observation that the common approach, which is to benefit\nfrom the synergy of XOR network coding with a CDS-based broadcast algorithm,\nsuffers performance breakdowns. After delving into the details of this synergy,\nwe attribute this behavior to an important mechanism of the underlying\nbroadcast algorithm, known as the \"termination criterion\". To tackle the\nproblem, we propose a termination criterion that is fully compatible with XOR\ncoding. In addition to that, we revisit the internals of XOR coding. We first\nenhance the synergy of XOR coding with the underlying broadcast algorithm by\nallowing each mechanism to benefit from information available by the other. In\nthis way, we manage to improve the pruning efficiency of the CDS-based\nalgorithm while at the same time we come up with a method for detecting coding\nopportunities that has minimal storage and processing requirements compared to\ncurrent approaches. Then, for the first time, we use XOR coding as a mechanism\nnot only for enhancing energy efficiency but also for reducing the\nend-to-end-delay. We validate the effectiveness of our proposed algorithm\nthrough extensive simulations on a diverse set of scenarios. \n\n"}
{"id": "1605.06216", "contents": "Title: New Permutation Trinomials Constructed from Fractional Polynomials Abstract: Permutation trinomials over finite fields consititute an active research due\nto their simple algebraic form, additional extraordinary properties and their\nwide applications in many areas of science and engineering. In the present\npaper, six new classes of permutation trinomials over finite fields of even\ncharacteristic are constructed from six fractional polynomials. Further, three\nclasses of permutation trinomials over finite fields of characteristic three\nare raised. Distinct from most of the known permutation trinomials which are\nwith fixed exponents, our results are some general classes of permutation\ntrinomials with one parameter in the exponents. Finally, we propose a few\nconjectures. \n\n"}
{"id": "1605.08630", "contents": "Title: Explicit constructions of optimal-access MDS codes with nearly optimal\n  sub-packetization Abstract: An $(n,k,l)$ MDS array code of length $n,$ dimension $k=n-r$ and\nsub-packetization $l$ is formed of $l\\times n$ matrices over a finite field\n$F,$ with every column of the matrix stored on a separate node in a distributed\nstorage system and viewed as a coordinate of the codeword. Repair of a failed\nnode can be performed by accessing a set of $d\\le n-1$ helper nodes. The code\nis said to have the optimal access property if the amount of data accessed at\neach of the helper nodes meets a lower bound on this quantity. For\noptimal-access MDS codes with $d=n-1,$ the sub-packetization $l$ satisfies the\nbound $l\\ge r^{(k-1)/r}.$ In our previous work, for any $n$ and $r,$ we\npresented an explicit construction of optimal-access MDS codes with\nsub-packetization $l=r^{n-1}.$ In this paper we take up the question of\nreducing the sub-packetization value $l$ to make it approach the lower bound.\nWe construct an explicit family of optimal-access codes with $l=r^{\\lceil\nn/r\\rceil},$ which differs from the optimal value by at most a factor of $r^2.$\nThese codes can be constructed over any finite field $F$ as long as $|F|\\ge\nr\\lceil n/r\\rceil,$ and afford low-complexity encoding and decoding procedures.\nWe also define a version of the repair problem that bridges the context of\nregenerating codes and codes with locality constraints (LRC codes), calling it\ngroup repair with optimal access. In this variation, we assume that the set of\n$n=sm$ nodes is partitioned into $m$ repair groups of size $s,$ and require\nthat the amount of accessed data for repair is the smallest possible whenever\nthe $d$ helper nodes include all the other $s-1$ nodes from the same group as\nthe failed node. For this problem, we construct a family of codes with the\ngroup optimal access property. These codes can be constructed over any field\n$F$ of size $|F|\\ge n,$ and also afford low-complexity encoding and decoding\nprocedures. \n\n"}
{"id": "1605.08998", "contents": "Title: Optimal Scalar Linear Index Codes for One-Sided Neighboring\n  Side-Information Problems Abstract: The capacity of symmetric instance of the multiple unicast index coding\nproblem with neighboring antidotes (side-information) with number of messages\nequal to the number of receivers was given by Maleki \\textit{et al.} In this\npaper, we construct matrices of size $ m \\times n (m \\geq n)$ over $F_q$ such\nthat any $n$ adjacent rows of the matrix are linearly independent. By using\nsuch matrices, we give an optimal scalar linear index codes over $F_q$ for the\nsymmetric one-sided antidote problems considered by Maleki \\textit{et al.} for\nany given number of messages and one-sided antidotes. The constructed codes are\nindependent of field size and hence works over every field. \n\n"}
{"id": "1605.09350", "contents": "Title: Computing backup forwarding rules in Software-Defined Networks Abstract: The past century of telecommunications has shown that failures in networks\nare prevalent. Although much has been done to prevent failures, network nodes\nand links are bound to fail eventually. Failure recovery processes are\ntherefore needed. Failure recovery is mainly influenced by (1) detection of the\nfailure, and (2) circumvention of the detected failure. However, especially in\nSDNs where controllers recompute network state reactively, this leads to high\ndelays. Hence, next to primary rules, backup rules should be installed in the\nswitches to quickly detour traffic once a failure occurs. In this work, we\npropose algorithms for computing an all-to-all primary and backup network\nforwarding configuration that is capable of circumventing link and node\nfailures. Omitting the high delay invoked by controller recomputation through\npreconfiguration, our proposal's recovery delay is close to the detection time\nwhich is significantly below the 50 ms rule of thumb. After initial recovery,\nwe recompute network configuration to guarantee protection from future\nfailures. Our algorithms use packet-labeling to guarantee correct and shortest\ndetour forwarding. The algorithms and labeling technique allow packets to\nreturn to the primary path and are able to discriminate between link and node\nfailures. The computational complexity of our solution is comparable to that of\nall-to-all-shortest paths computations. Our experimental evaluation on both\nreal and generated networks shows that network configuration complexity highly\ndecreases compared to classic disjoint paths computations. Finally, we provide\na proof-of-concept OpenFlow controller in which our proposed configuration is\nimplemented, demonstrating that it readily can be applied in production\nnetworks. \n\n"}
{"id": "1605.09519", "contents": "Title: Optimal caching placement for wireless femto-caching network Abstract: This paper investigates optimal caching placement for wireless femto-caching\nnetwork. The average bit error rate (BER) is formulated as a function of\ncaching placement under wireless fading. To minimize the average BER, we\npropose a greedy algorithm finding optimal caching placement with low\ncomputational complexity. Exploiting the property of the optimal caching\nplacement which we derive, the proposed algorithm can be performed over\nconsiderably reduced search space. Contrary to the optimal caching placement\nwithout consideration of wireless fading aspects, we reveal that optimal\ncaching placement can be reached by balancing a tradeoff between two different\ngains: file diversity gain and channel diversity gain. Moreover, we also\nidentify the conditions that the optimal placement can be found without running\nthe proposed greedy algorithm and derive the corresponding optimal caching\nplacement in closed form. \n\n"}
{"id": "1606.00191", "contents": "Title: A Survey of Anticipatory Mobile Networking: Context-Based\n  Classification, Prediction Methodologies, and Optimization Techniques Abstract: A growing trend for information technology is to not just react to changes,\nbut anticipate them as much as possible. This paradigm made modern solutions,\nsuch as recommendation systems, a ubiquitous presence in today's digital\ntransactions. Anticipatory networking extends the idea to communication\ntechnologies by studying patterns and periodicity in human behavior and network\ndynamics to optimize network performance. This survey collects and analyzes\nrecent papers leveraging context information to forecast the evolution of\nnetwork conditions and, in turn, to improve network performance. In particular,\nwe identify the main prediction and optimization tools adopted in this body of\nwork and link them with objectives and constraints of the typical applications\nand scenarios. Finally, we consider open challenges and research directions to\nmake anticipatory networking part of next generation networks. \n\n"}
{"id": "1606.00531", "contents": "Title: Fast and Robust Compressive Phase Retrieval with Sparse-Graph Codes Abstract: In this paper, we tackle the compressive phase retrieval problem in the\npresence of noise. The noisy compressive phase retrieval problem is to recover\na $K$-sparse complex signal $s \\in \\mathbb{C}^n$, from a set of $m$ noisy\nquadratic measurements: $ y_i=| a_i^H s |^2+w_i$, where $a_i^H\\in\\mathbb{C}^n$\nis the $i$th row of the measurement matrix $A\\in\\mathbb{C}^{m\\times n}$, and\n$w_i$ is the additive noise to the $i$th measurement. We consider the regime\nwhere $K=\\beta n^\\delta$, with constants $\\beta>0$ and $\\delta\\in(0,1)$. We use\nthe architecture of PhaseCode algorithm, and robustify it using two schemes:\nthe almost-linear scheme and the sublinear scheme. We prove that with high\nprobability, the almost-linear scheme recovers $s$ with sample complexity\n$\\Theta(K \\log(n))$ and computational complexity $\\Theta(n \\log(n))$, and the\nsublinear scheme recovers $s$ with sample complexity $\\Theta(K\\log^3(n))$ and\ncomputational complexity $\\Theta(K\\log^3(n))$. To the best of our knowledge,\nthis is the first scheme that achieves sublinear computational complexity for\ncompressive phase retrieval problem. Finally, we provide simulation results\nthat support our theoretical contributions. \n\n"}
{"id": "1606.01374", "contents": "Title: Cut-Set Bound Is Loose for Gaussian Relay Networks Abstract: The cut-set bound developed by Cover and El Gamal in 1979 has since remained\nthe best known upper bound on the capacity of the Gaussian relay channel. We\ndevelop a new upper bound on the capacity of the Gaussian primitive relay\nchannel which is tighter than the cut-set bound. Our proof is based on\ntypicality arguments and concentration of Gaussian measure. Combined with a\nsimple tensorization argument proposed by Courtade and Ozgur in 2015, our\nresult also implies that the current capacity approximations for Gaussian relay\nnetworks, which have linear gap to the cut-set bound in the number of nodes,\nare order-optimal and leads to a lower bound on the pre-constant. \n\n"}
{"id": "1606.01768", "contents": "Title: Classical - Quantum Arbitrarily Varying Wiretap Channel: Common\n  Randomness Assisted Code and Continuity Abstract: We determine the secrecy capacities under common randomness assisted coding\nof arbitrarily varying classical-quantum wiretap channels.Furthermore, we\ndetermine the secrecy capacity of a mixed channel model which is compound from\nthe sender to the legal receiver and varies arbitrarily from the sender to the\neavesdropper. As an application we examine when the secrecy capacity is a\ncontinuous function of the system parameters and show that resources, i.e.,\nhaving access to a perfect copy of the outcome of a random experiment. are\nhelpful for channel stability. \n\n"}
{"id": "1606.01962", "contents": "Title: Efficient Deployment of Multiple Unmanned Aerial Vehicles for Optimal\n  Wireless Coverage Abstract: In this paper, the efficient deployment of multiple unmanned aerial vehicles\n(UAVs) with directional antennas acting as wireless base stations that provide\ncoverage for ground users is analyzed. First, the downlink coverage probability\nfor UAVs as a function of the altitude and the antenna gain is derived. Next,\nusing circle packing theory, the three-dimensional locations of the UAVs is\ndetermined in a way that the total coverage area is maximized while maximizing\nthe coverage lifetime of the UAVs. Our results show that, in order to mitigate\ninterference, the altitude of the UAVs must be properly adjusted based on the\nbeamwidth of the directional antenna as well as coverage requirements.\nFurthermore, the minimum number of UAVs needed to guarantee a target coverage\nprobability for a given geographical area is determined. Numerical results\nevaluate the various tradeoffs involved in various UAV deployment scenarios. \n\n"}
{"id": "1606.02033", "contents": "Title: User Cooperation for Enhanced Throughput Fairness in Wireless Powered\n  Communication Networks Abstract: This paper studies a novel user cooperation method in a wireless powered\ncommunication network (WPCN), where a pair of distributed terminal users first\nharvest wireless energy broadcasted by one energy node (EN) and then use the\nharvested energy to transmit information cooperatively to a destination node\n(DN). In particular, the two cooperating users exchange their independent\ninformation with each other to form a virtual antenna array and transmit\njointly to the DN. By allowing each user to allocate part of its harvested\nenergy to transmit the other's information, the proposed cooperation can\neffectively mitigate the user unfairness problem in WPCNs, where a user may\nsuffer from very low data rate due to the poor energy harvesting performance\nand high data transmission consumptions. We derive the maximum common\nthroughput achieved by the cooperation scheme through optimizing the time\nallocation on wireless energy transfer, user message exchange, and joint\ninformation transmissions. Through comparing with some representative benchmark\nschemes, our results demonstrate the effectiveness of the proposed user\ncooperation in enhancing the throughput performance under different setups. \n\n"}
{"id": "1606.02087", "contents": "Title: Continuous Transmission of Spatially-Coupled LDPC Code Chains Abstract: We propose a novel encoding/transmission scheme called continuous chain (CC)\ntransmission that is able to improve the finite-length performance of a system\nusing spatially-coupled low-density parity-check (SC-LDPC) codes. In CC\ntransmission, instead of transmitting a sequence of independent codewords from\na terminated SC-LDPC code chain, we connect multiple chains in a layered\nformat, where encoding, transmission, and decoding are now performed in a\ncontinuous fashion. The connections between chains are created at specific\npoints, chosen to improve the finite-length performance of the code structure\nunder iterative decoding. We describe the design of CC schemes for different\nSC-LDPC code ensembles constructed from protographs: a (J,K)-regular SC-LDPC\ncode chain, a spatially-coupled repeat-accumulate (SC-RA) code, and a\nspatially-coupled accumulate-repeat-jagged-accumulate (SC- ARJA) code. In all\ncases, significant performance improvements are reported and, in addition, it\nis shown that using CC transmission only requires a small increase in decoding\ncomplexity and decoding delay with respect to a system employing a single\nSC-LDPC code chain for transmission. \n\n"}
{"id": "1606.02337", "contents": "Title: Random Access in C-RAN for User Activity Detection with Limited-Capacity\n  Fronthaul Abstract: Cloud-Radio Access Network (C-RAN) is characterized by a hierarchical\nstructure in which the baseband processing functionalities of remote radio\nheads (RRHs) are implemented by means of cloud computing at a Central Unit\n(CU). A key limitation of C-RANs is given by the capacity constraints of the\nfronthaul links connecting RRHs to the CU. In this letter, the impact of this\narchitectural constraint is investigated for the fundamental functions of\nrandom access and active User Equipment (UE) identification in the presence of\na potentially massive number of UEs. In particular, the standard C-RAN approach\nbased on quantize-and-forward and centralized detection is compared to a scheme\nbased on an alternative CU-RRH functional split that enables local detection.\nBoth techniques leverage Bayesian sparse detection. Numerical results\nillustrate the relative merits of the two schemes as a function of the system\nparameters. \n\n"}
{"id": "1606.03504", "contents": "Title: Incoherent Tensor Norms and Their Applications in Higher Order Tensor\n  Completion Abstract: In this paper, we investigate the sample size requirement for a general class\nof nuclear norm minimization methods for higher order tensor completion. We\nintroduce a class of tensor norms by allowing for different levels of\ncoherence, which allows us to leverage the incoherence of a tensor. In\nparticular, we show that a $k$th order tensor of rank $r$ and dimension\n$d\\times\\cdots\\times d$ can be recovered perfectly from as few as\n$O((r^{(k-1)/2}d^{3/2}+r^{k-1}d)(\\log(d))^2)$ uniformly sampled entries through\nan appropriate incoherent nuclear norm minimization. Our results demonstrate\nsome key differences between completing a matrix and a higher order tensor:\nThey not only point to potential room for improvement over the usual nuclear\nnorm minimization but also highlight the importance of explicitly accounting\nfor incoherence, when dealing with higher order tensors. \n\n"}
{"id": "1606.04405", "contents": "Title: Fundamentals of Modeling Finite Wireless Networks using Binomial Point\n  Process Abstract: Modeling the locations of nodes as a uniform binomial point process (BPP), we\npresent a generic mathematical framework to characterize the performance of an\narbitrarily-located reference receiver in a finite wireless network. Different\nfrom most of the prior works where the serving transmitter (TX) node is located\nat the fixed distance from the reference receiver, we consider two general\nTX-selection policies: i) uniform TX-selection: the serving node is chosen\nuniformly at random amongst transmitting nodes, and ii) k-closest TX-selection:\nthe serving node is the k-th closest node out of transmitting nodes to the\nreference receiver. The key intermediate step in our analysis is the derivation\nof a new set of distance distributions that lead not only to the tractable\nanalysis of coverage probability but also enable the analyses of wide range of\nclassical and currently trending problems in wireless networks. Using this new\nset of distance distributions, we first investigate the diversity loss due to\nSIR correlation in a finite network. We then obtain the optimal number of links\nthat can be simultaneously activated to maximize network spectral efficiency.\nFinally, we evaluate optimal caching probability to maximize the total hit\nprobability in cache-enabled finite networks. \n\n"}
{"id": "1606.05332", "contents": "Title: Spatio-temporal Interference Correlation and Joint Coverage in Cellular\n  Networks Abstract: This paper provides an analytical framework with foundations in stochastic\ngeometry to characterize the spatio-temporal interference correlation as well\nas the joint coverage probability at two spatial locations in a cellular\nnetwork. In particular, modeling the locations of cellular base stations (BSs)\nas a Poisson Point Process (PPP), we study interference correlation at two\nspatial locations $\\ell_1$ and $\\ell_2$ separated by a distance $v$, when the\nuser follows \\emph{closest BS association policy} at both spatial locations and\nmoves from $\\ell_1$ to $\\ell_2$. With this user displacement, two scenarios can\noccur: i) the user is handed off to a new serving BS at $\\ell_2$, or ii) no\nhandoff occurs and the user is served by the same BS at both locations. After\nproviding intermediate results such as probability of handoff and distance\ndistributions of the serving BS at the two user locations, we use them to\nderive exact expressions for spatio-temporal interference correlation\ncoefficient and joint coverage probability for any distance separation $v$. We\nalso study two different handoff strategies: i) \\emph{handoff skipping}, and\nii) \\emph{conventional handoffs}, and derive the expressions of joint coverage\nprobability for both strategies. The exact analysis is not straightforward and\ninvolves a careful treatment of the neighborhood of the two spatial locations\nand the resulting handoff scenarios. To provide analytical insights, we also\nprovide easy-to-use expressions for two special cases: i) static user ($v =0$)\nand ii) highly mobile user ($v \\rightarrow \\infty)$. As expected, our analysis\nshows that the interference correlation and joint coverage probability decrease\nwith increasing $v$, with $v \\rightarrow \\infty$ corresponding to a completely\nuncorrelated scenario. \n\n"}
{"id": "1606.05825", "contents": "Title: Wireless network signals with moderately correlated shadowing still\n  appear Poisson Abstract: We consider the point process of signal strengths emitted from transmitters\nin a wireless network and observed at a fixed position. In our model,\ntransmitters are placed deterministically or randomly according to a hard core\nor Poisson point process and signals are subjected to power law path loss and\nrandom propagation effects that may be correlated between transmitters.\n  We provide bounds on the distance between the point process of signal\nstrengths and a Poisson process with the same mean measure, assuming correlated\nlog-normal shadowing. For \"strong shadowing\" and moderate correlations, we find\nthat the signal strengths are close to a Poisson process, generalizing a\nrecently shown analogous result for independent shadowing. \n\n"}
{"id": "1606.06223", "contents": "Title: Enriched K-Tier HetNet Model to Enable the Analysis of User-Centric\n  Small Cell Deployments Abstract: One of the principal underlying assumptions of current approaches to the\nanalysis of heterogeneous cellular networks (HetNets) with random spatial\nmodels is the uniform distribution of users independent of the base station\n(BS) locations. This assumption is not quite accurate, especially for\nuser-centric capacity-driven small cell deployments where low-power BSs are\ndeployed in the areas of high user density, thus inducing a natural correlation\nin the BS and user locations. In order to capture this correlation, we enrich\nthe existing K-tier Poisson Point Process (PPP) HetNet model by considering\nuser locations as Poisson Cluster Process (PCP) with the BSs at the cluster\ncenters. In particular, we provide the formal analysis of the downlink coverage\nprobability in terms of a general density functions describing the locations of\nusers around the BSs. The derived results are specialized for two cases of\ninterest: (i) Thomas cluster process, where the locations of the users around\nBSs are Gaussian distributed, and (ii) Mat\\'ern cluster process, where the\nusers are uniformly distributed inside a disc of a given radius. Tight\nclosed-form bounds for the coverage probability in these two cases are also\nderived. Our results demonstrate that the coverage probability decreases as the\nsize of user clusters around BSs increases, ultimately collapsing to the result\nobtained under the assumption of PPP distribution of users independent of the\nBS locations when the cluster size goes to infinity. Using these results, we\nalso handle mixed user distributions consisting of two types of users: (i)\nuniformly distributed, and (ii) clustered around certain tiers. \n\n"}
{"id": "1606.07198", "contents": "Title: On Improving Capacity of Full-Duplex Small Cells with D2D Abstract: The recent developments in full duplex (FD) communication promise doubling\nthe capacity of cellular networks using self interference cancellation (SIC)\ntechniques. FD small cells with device-to-device (D2D) communication links\ncould achieve the expected capacity of the future cellular networks (5G). In\nthis work, we consider joint scheduling and dynamic power algorithm (DPA) for a\nsingle cell FD small cell network with D2D links (D2DLs). We formulate the\noptimal user selection and power control as a non-linear programming (NLP)\noptimization problem to get the optimal user scheduling and transmission power\nin a given TTI. Our numerical results show that using DPA gives better overall\nthroughput performance than full power transmission algorithm (FPA). Also,\nsimultaneous transmissions (combination of uplink (UL), downlink (DL), and D2D\noccur 80% of the time thereby increasing the spectral efficiency and network\ncapacity. \n\n"}
{"id": "1606.08971", "contents": "Title: Joint Millimeter Wave and Microwave Resources Allocation in Cellular\n  Networks with Dual-Mode Base Stations Abstract: In this paper, a novel dual-mode scheduling framework is proposed that\njointly performs user applications (UA) selection and scheduling over microwave\n($\\mu$W) and millimeter wave (mmW) bands. The proposed scheduling framework\nutilizes a set of context information, including the channel state information,\nthe delay tolerance and required load per UA, and the uncertainty of mmW\nchannels, to maximize the quality-of-service (QoS) per UA. The scheduling\nproblem is formulated as an optimization with minimum unsatisfied relations\n(min-UR) problem which is shown to be challenging to solve. Consequently, a\nlong-term scheduling framework, consisting of two stages, is proposed. Within\nthis framework, first, the scheduling over $\\mu$W band is formulated as a\nmatching game and to solve this problem, a novel algorithm is proposed and\nshown to yield a two-sided stable resource allocation. Second, over the mmW\nband, the scheduling problem is formulated as a 0-1 Knapsack problem and a\nnovel algorithm is proposed to solve it. Furthermore, it is shown that the\nproposed framework can find an effective scheduling solution, over both $\\mu$W\nand mmW, in polynomial time. Simulation results show that, compared with\nconventional scheduling schemes, the proposed approach significantly increases\nthe number of satisfied UAs and enhances the users' quality-of-experience. \n\n"}
{"id": "1606.09552", "contents": "Title: Proximity Operators of Discrete Information Divergences Abstract: Information divergences allow one to assess how close two distributions are\nfrom each other. Among the large panel of available measures, a special\nattention has been paid to convex $\\varphi$-divergences, such as\nKullback-Leibler, Jeffreys-Kullback, Hellinger, Chi-Square, Renyi, and\nI$_{\\alpha}$ divergences. While $\\varphi$-divergences have been extensively\nstudied in convex analysis, their use in optimization problems often remains\nchallenging. In this regard, one of the main shortcomings of existing methods\nis that the minimization of $\\varphi$-divergences is usually performed with\nrespect to one of their arguments, possibly within alternating optimization\ntechniques. In this paper, we overcome this limitation by deriving new\nclosed-form expressions for the proximity operator of such two-variable\nfunctions. This makes it possible to employ standard proximal methods for\nefficiently solving a wide range of convex optimization problems involving\n$\\varphi$-divergences. In addition, we show that these proximity operators are\nuseful to compute the epigraphical projection of several functions of practical\ninterest. The proposed proximal tools are numerically validated in the context\nof optimal query execution within database management systems, where the\nproblem of selectivity estimation plays a central role. Experiments are carried\nout on small to large scale scenarios. \n\n"}
{"id": "1607.00934", "contents": "Title: A Multi-Game Framework for Harmonized LTE-U and WiFi Coexistence over\n  Unlicensed Bands Abstract: The introduction of LTE over unlicensed bands (LTE-U) will enable LTE base\nstations (BSs) to boost their capacity and offload their traffic by exploiting\nthe underused unlicensed bands. However, to reap the benefits of LTE-U, it is\nnecessary to address various new challenges associated with LTE-U and WiFi\ncoexistence. In particular, new resource management techniques must be\ndeveloped to optimize the usage of the network resources while handling the\ninterdependence between WiFi and LTE users and ensuring that WiFi users are not\njeopardized. To this end, in this paper, a new game theoretic tool, dubbed as\n\\emph{multi-game} framework is proposed as a promising approach for modeling\nresource allocation problems in LTE-U. In such a framework, multiple,\nco-existing and coupled games across heterogeneous channels can be formulated\nto capture the specific characteristics of LTE-U. Such games can be of\ndifferent properties and types but their outcomes are largely interdependent.\nAfter introducing the basics of the multi-game framework, two classes of\nalgorithms are outlined to achieve the new solution concepts of multi-games.\nSimulation results are then conducted to show how such a multi-game can\neffectively capture the specific properties of LTE-U and make of it a\n\"friendly\" neighbor to WiFi. \n\n"}
{"id": "1607.01872", "contents": "Title: Downlink Cell Association and Load Balancing for Joint Millimeter\n  Wave-Microwave Cellular Networks Abstract: The integration of millimeter-wave base stations (mmW-BSs) with conventional\nmicrowave base stations ($\\mu$W-BSs) is a promising solution for enhancing the\nquality-of-service (QoS) of emerging 5G networks. However, the significant\ndifferences in the signal propagation characteristics over the mmW and $\\mu$W\nfrequency bands will require novel cell association schemes cognizant of both\nmmW and $\\mu$W systems. In this paper, a novel cell association framework is\nproposed that considers both the blockage probability and the achievable rate\nto assign user equipments (UEs) to mmW-BSs or $\\mu$W-BSs. The problem is\nformulated as a one-to-many matching problem with minimum quota constraints for\nthe BSs that provides an efficient way to balance the load over the mmW and\n$\\mu$W frequency bands. To solve the problem, a distributed algorithm is\nproposed that is guaranteed to yield a Pareto optimal and two-sided stable\nsolution. Simulation results show that the proposed matching with minimum quota\n(MMQ) algorithm outperforms the conventional max-RSSI and max-SINR cell\nassociation schemes. In addition, it is shown that the proposed MMQ algorithm\ncan effectively balance the number of UEs associated with the $\\mu$W-BSs and\nmmW-BSs and achieve further gains, in terms of the average sum rate. \n\n"}
{"id": "1607.01908", "contents": "Title: Downlink Power Control for Massive MIMO Cellular Systems with Optimal\n  User Association Abstract: This paper aims to minimize the total transmit power consumption for Massive\nMIMO (multiple-input multiple-output) downlink cellular systems when each user\nis served by the optimized subset of the base stations (BSs). We derive a lower\nbound on the ergodic spectral efficiency (SE) for Rayleigh fading channels and\nmaximum ratio transmission (MRT) when the BSs cooperate using non-coherent\njoint transmission. We solve the joint user association and downlink transmit\npower minimization problem optimally under fixed SE constraints. Furthermore,\nwe solve a max-min fairness problem with user specific weights that maximizes\nthe worst SE among the users. The optimal BS-user association rule is derived,\nwhich is different from maximum signal-to-noise-ratio (max-SNR) association.\nSimulation results manifest that the proposed methods can provide good SE for\nthe users using less transmit power than in small-scale systems and that the\noptimal user association can effectively balance the load between BSs when\nneeded. \n\n"}
{"id": "1607.02298", "contents": "Title: On Channel Resolvability in Presence of Feedback Abstract: We study the problem of generating an approximately i.i.d. string at the\noutput of a discrete memoryless channel using a limited amount of randomness at\nits input in presence of causal noiseless feedback. Feedback does not decrease\nthe channel resolution, the minimum entropy rate required to achieve an\naccurate approximation of an i.i.d. output string. However, we show that, at\nleast over a binary symmetric channel, a significantly larger resolvability\nexponent (the exponential decay rate of the divergence between the output\ndistribution and product measure), compared to the best known achievable\nresolvability exponent in a system without feedback, is possible. We show that\nby employing a variable-length resolvability scheme and using an average number\nof coin-flips per channel use, the average divergence between the distribution\nof the output sequence and product measure decays exponentially fast in the\naverage length of output sequence with an exponent equal to $[R-I(U;V)]^+$\nwhere $I(U;V)$ is the mutual information developed across the channel. \n\n"}
{"id": "1607.03132", "contents": "Title: Density of Spherically-Embedded Stiefel and Grassmann Codes Abstract: The density of a code is the fraction of the coding space covered by packing\nballs centered around the codewords. This paper investigates the density of\ncodes in the complex Stiefel and Grassmann manifolds equipped with the chordal\ndistance. The choice of distance enables the treatment of the manifolds as\nsubspaces of Euclidean hyperspheres. In this geometry, the densest packings are\nnot necessarily equivalent to maximum-minimum-distance codes. Computing a\ncode's density follows from computing: i) the normalized volume of a metric\nball and ii) the kissing radius, the radius of the largest balls one can pack\naround the codewords without overlapping. First, the normalized volume of a\nmetric ball is evaluated by asymptotic approximations. The volume of a small\nball can be well-approximated by the volume of a locally-equivalent tangential\nball. In order to properly normalize this approximation, the precise volumes of\nthe manifolds induced by their spherical embedding are computed. For larger\nballs, a hyperspherical cap approximation is used, which is justified by a\nvolume comparison theorem showing that the normalized volume of a ball in the\nStiefel or Grassmann manifold is asymptotically equal to the normalized volume\nof a ball in its embedding sphere as the dimension grows to infinity. Then,\nbounds on the kissing radius are derived alongside corresponding bounds on the\ndensity. Unlike spherical codes or codes in flat spaces, the kissing radius of\nGrassmann or Stiefel codes cannot be exactly determined from its minimum\ndistance. It is nonetheless possible to derive bounds on density as functions\nof the minimum distance. Stiefel and Grassmann codes have larger density than\ntheir image spherical codes when dimensions tend to infinity. Finally, the\nbounds on density lead to refinements of the standard Hamming bounds for\nStiefel and Grassmann codes. \n\n"}
{"id": "1607.03270", "contents": "Title: Enhanced VIP Algorithms for Forwarding, Caching, and Congestion Control\n  in Named Data Networks Abstract: Emerging Information-Centric Networking (ICN) architectures seek to optimally\nutilize both bandwidth and storage for efficient content distribution over the\nnetwork. The Virtual Interest Packet (VIP) framework has been proposed to\nenable joint design of forwarding, caching, and congestion control strategies\nwithin the Named Data Networking (NDN) architecture. While the existing VIP\nalgorithms exhibit good performance, they are primarily focused on maximizing\nnetwork throughput and utility, and do not explicitly consider user delay. In\nthis paper, we develop a new class of enhanced algorithms for joint dynamic\nforwarding, caching and congestion control within the VIP framework. These\nenhanced VIP algorithms adaptively stabilize the network and maximize network\nutility, while improving the delay performance by intelligently making use of\nVIP information beyond one hop. Generalizing Lyapunov drift techniques, we\nprove the throughput optimality and characterize the utility-delay tradeoff of\nthe enhanced VIP algorithms. Numerical experiments demonstrate the superior\nperformance of the resulting enhanced algorithms for handling Interest Packets\nand Data Packets within the actual plane, in terms of low network delay and\nhigh network utility. \n\n"}
{"id": "1607.03683", "contents": "Title: Breaking the Economic Barrier of Caching in Cellular Networks:\n  Incentives and Contracts Abstract: In this paper, a novel approach for providing incentives for caching in small\ncell networks (SCNs) is proposed based on the economics framework of contract\ntheory. In this model, a mobile network operator (MNO) designs contracts that\nwill be offered to a number of content providers (CPs) to motivate them to\ncache their content at the MNO's small base stations (SBSs). A practical model\nin which information about the traffic generated by the CPs' users is not known\nto the MNO is considered. Under such asymmetric information, the incentive\ncontract between the MNO and each CP is properly designed so as to determine\nthe amount of allocated storage to the CP and the charged price by the MNO. The\ncontracts are derived by the MNO in a way to maximize the global benefit of the\nCPs and prevent them from using their private information to manipulate the\noutcome of the caching process. For this interdependent contract model, the\nclosed-form expressions of the price and the allocated storage space to each CP\nare derived. This proposed mechanism is shown to satisfy the sufficient and\nnecessary conditions for the feasibility of a contract. Moreover, it is shown\nthat the proposed pricing model is budget balanced, enabling the MNO to cover\nall the caching expenses via the prices charged to the CPs. Simulation results\nshow that none of the CPs will have an incentive to choose a contract designed\nfor CPs with different traffic loads. \n\n"}
{"id": "1607.04330", "contents": "Title: Performance Comparison of Dual Connectivity and Hard Handover for LTE-5G\n  Tight Integration in mmWave Cellular Networks Abstract: MmWave communications are expected to play a major role in the Fifth\ngeneration of mobile networks. They offer a potential multi-gigabit throughput\nand an ultra-low radio latency, but at the same time suffer from high isotropic\npathloss, and a coverage area much smaller than the one of LTE macrocells. In\norder to address these issues, highly directional beamforming and a very\nhigh-density deployment of mmWave base stations were proposed. This Thesis aims\nto improve the reliability and performance of the 5G network by studying its\ntight and seamless integration with the current LTE cellular network. In\nparticular, the LTE base stations can provide a coverage layer for 5G mobile\nterminals, because they operate on microWave frequencies, which are less\nsensitive to blockage and have a lower pathloss. This document is a copy of the\nMaster's Thesis carried out by Mr. Michele Polese under the supervision of Dr.\nMarco Mezzavilla and Prof. Michele Zorzi. It will propose an LTE-5G tight\nintegration architecture, based on mobile terminals' dual connectivity to LTE\nand 5G radio access networks, and will evaluate which are the new network\nprocedures that will be needed to support it. Moreover, this new architecture\nwill be implemented in the ns-3 simulator, and a thorough simulation campaign\nwill be conducted in order to evaluate its performance, with respect to the\nbaseline of handover between LTE and 5G. \n\n"}
{"id": "1607.04849", "contents": "Title: Secure Group Testing Abstract: The principal goal of Group Testing (GT) is to identify a small subset of\n\"defective\" items from a large population, by grouping items into as few test\npools as possible. The test outcome of a pool is positive if it contains at\nleast one defective item, and is negative otherwise. GT algorithms are utilized\nin numerous applications, and in many of them maintaining the privacy of the\ntested items, namely, keeping secret whether they are defective or not, is\ncritical.\n  In this paper, we consider a scenario where there is an eavesdropper (Eve)\nwho is able to observe a subset of the GT outcomes (pools). We propose a new\nnon-adaptive Secure Group Testing (SGT) scheme based on information-theoretic\nprinciples. The new proposed test design keeps the eavesdropper ignorant\nregarding the items' status. Specifically, when the fraction of tests observed\nby Eve is $0 \\leq \\delta <1$, we prove that with the naive Maximum Likelihood\n(ML) decoding algorithm the number of tests required for both correct\nreconstruction at the legitimate user (with high probability) and negligible\ninformation leakage to Eve is $\\frac{1}{1-\\delta}$ times the number of tests\nrequired with no secrecy constraint for the fixed $K$ regime. By a matching\nconverse, we completely characterize the Secure GT capacity. Moreover, we\nconsider the Definitely Non-Defective (DND) computationally efficient decoding\nalgorithm, proposed in the literature for non-secure GT. We prove that with the\nnew secure test design, for $\\delta < 1/2$, the number of tests required,\nwithout any constraint on $K$, is at most $\\frac{1}{1/2-\\delta}$ times the\nnumber of tests required with no secrecy constraint. \n\n"}
{"id": "1607.06313", "contents": "Title: On Optimal Heterogeneous Regenerating Codes Abstract: Heterogeneous Distributed Storage Systems (DSSs) are close to the real world\napplications for data storage. Each node of the considered DSS, may store\ndifferent number of packets and each having different repair bandwidth with\nuniform repair traffic. For such heterogeneous DSS, a failed node can be\nrepaired with the help of some specific nodes. In this work, a family of codes\nbased on graph theory, is constructed which achieves the fundamental bound on\nfile size for the particular heterogeneous DSS. \n\n"}
{"id": "1607.07252", "contents": "Title: Topological Interference Management with User Admission Control via\n  Riemannian Optimization Abstract: Topological interference management (TIM) provides a promising way to manage\ninterference only based on the network connectivity information. Previous works\non the TIM problem mainly focus on using the index coding approach and graph\ntheory to establish conditions of network topologies to achieve the feasibility\nof topological interference management. In this paper, we propose a novel user\nadmission control approach via sparse and low-rank optimization to maximize the\nnumber of admitted users for achieving the feasibility of topological\ninterference management. To assist efficient algorithms design for the\nformulated rank-constrained (i.e., degrees-of-freedom (DoF) allocation) l0-norm\nmaximization (i.e., user capacity maximization) problem, we propose a\nregularized smoothed l1- norm minimization approach to induce sparsity pattern,\nthereby guiding the user selection. We further develop a Riemannian\ntrust-region algorithm to solve the resulting rank-constrained smooth\noptimization problem via exploiting the quotient manifold of fixed-rank\nmatrices. Simulation results demonstrate the effectiveness and near-optimal\nperformance of the proposed Riemannian algorithm to maximize the number of\nadmitted users for topological interference management. \n\n"}
{"id": "1607.07674", "contents": "Title: Secret Key Generation Through a Relay Abstract: We consider problems of two-user secret key generation through an\nintermediate relay. Each user observes correlated source sequences and\ncommunicates to the relay over rate-limited noiseless links. The relay\nprocesses and broadcasts information to the two users over another rate-limited\nlink. The users then generate a common secret key based on their sources and\ninformation from the relay. In the untrusted relay setting, the goal is to\nestablish key agreement between the two users at the highest key rate without\nleaking information about the key to the relay. We characterize inner and outer\nbounds to the optimal tradeoff between communication and key rates. The inner\nbound is based on the scheme which involves a combination of binning, network\ncoding, and key aggregation techniques. For the trusted relay setting with a\npublic broadcast link, the optimal communication-key rate tradeoff is provided\nfor a special case where the two sources are available losslessly at the relay.\nThe results can be relevant for cloud-based secret key generation services. \n\n"}
{"id": "1607.08742", "contents": "Title: Fixed points of 321-avoiding permutations Abstract: We describe the distribution of the number and location of the fixed points\nof permu- tations that avoid the pattern 321 via a bijection with rooted plane\ntrees on n + 1 vertices. Using the local limit theorem for Galton-Watson trees,\nwe are able to give an explicit description of the limit of this distribution. \n\n"}
{"id": "1608.03180", "contents": "Title: Cyclical Multiple Access in UAV-Aided Communications: A Throughput-Delay\n  Tradeoff Abstract: This letter studies a wireless system consisting of distributed ground\nterminals (GTs) communicating with an unmanned aerial vehicle (UAV) that serves\nas a mobile base station (BS). The UAV flies cyclically above the GTs at a\nfixed altitude, which results in a cyclical pattern of the strength of the\nUAV-GT channels. To exploit such periodic channel variations, we propose a new\ncyclical multiple access (CMA) scheme to schedule the communications between\nthe UAV and GTs in a cyclical time-division manner based on the flying UAV's\nposition. The time allocations to different GTs are optimized to maximize their\nminimum throughput. It is revealed that there is a fundamental tradeoff between\nthroughput and access delay in the proposed CMA. Simulation results show\nsignificant throughput gains over the case of a static UAV BS in delay-tolerant\napplications. \n\n"}
{"id": "1608.03215", "contents": "Title: On quasi-cyclic subspace codes Abstract: Construction of subspace codes with good parameters is one of the most\nimportant problems in random network coding. In this paper we present first a\ngeneralization of the concept of cyclic subspaces codes and further we show\nthat the usual methods for constructing cyclic subspace codes over finite\nfields works for m-quasi cyclic codes, namely the subspaces polynomials and\nFrobenius mappings. \n\n"}
{"id": "1608.05467", "contents": "Title: Channel Estimation and Uplink Achievable Rates in One-Bit Massive MIMO\n  Systems Abstract: This paper considers channel estimation and achievable rates for the uplink\nof a massive multiple-input multiple-output (MIMO) system where the base\nstation is equipped with one-bit analog-to-digital converters (ADCs). By\nrewriting the nonlinear one-bit quantization using a linear expression, we\nfirst derive a simple and insightful expression for the linear minimum\nmean-square-error (LMMSE) channel estimator. Then employing this channel\nestimator, we derive a closed-form expression for the lower bound of the\nachievable rate for the maximum ratio combiner (MRC) receiver. Numerical\nresults are presented to verify our analysis and show that our proposed LMMSE\nchannel estimator outperforms the near maximum likelihood (nML) estimator\nproposed previously. \n\n"}
{"id": "1608.06409", "contents": "Title: Learning to Communicate: Channel Auto-encoders, Domain Specific\n  Regularizers, and Attention Abstract: We address the problem of learning efficient and adaptive ways to communicate\nbinary information over an impaired channel. We treat the problem as\nreconstruction optimization through impairment layers in a channel autoencoder\nand introduce several new domain-specific regularizing layers to emulate common\nchannel impairments. We also apply a radio transformer network based attention\nmodel on the input of the decoder to help recover canonical signal\nrepresentations. We demonstrate some promising initial capacity results from\nthis architecture and address several remaining challenges before such a system\ncould become practical. \n\n"}
{"id": "1608.07358", "contents": "Title: Cloud Radio Access Networks: Uplink Channel Estimation and Downlink\n  Precoding Abstract: The gains afforded by cloud radio access network (C-RAN) in terms of savings\nin capital and operating expenses, flexibility, interference management and\nnetwork densification rely on the presence of high-capacity low-latency\nfronthaul connectivity between remote radio heads (RRHs) and baseband unit\n(BBU). In light of the non-uniform and limited availability of fiber optics\ncables, the bandwidth constraints on the fronthaul network call, on the one\nhand, for the development of advanced baseband compression strategies and, on\nthe other hand, for a closer investigation of the optimal functional split\nbetween RRHs and BBU. In this chapter, after a brief introduction to signal\nprocessing challenges in C-RAN, this optimal function split is studied at the\nphysical (PHY) layer as it pertains to two key baseband signal processing\nsteps, namely channel estimation in the uplink and channel encoding/ linear\nprecoding in the downlink. Joint optimization of baseband fronthaul compression\nand of baseband signal processing is tackled under different PHY functional\nsplits, whereby uplink channel estimation and downlink channel encoding/ linear\nprecoding are carried out either at the RRHs or at the BBU. The analysis, based\non information-theoretical arguments, and numerical results yields insight into\nthe configurations of network architecture and fronthaul capacities in which\ndifferent functional splits are advantageous. The treatment also emphasizes the\nversatility of deterministic and stochastic successive convex approximation\nstrategies for the optimization of C-RANs. \n\n"}
{"id": "1608.07989", "contents": "Title: MIMO Cellular Networks with Simultaneous Wireless Information and Power\n  Transfer Abstract: In this paper, we introduce a mathematical approach for system-level analysis\nand optimization of densely deployed multiple-antenna cellular networks, where\nlow-energy devices are capable of decoding information data and harvesting\npower simultaneously. The base stations are assumed to be deployed according to\na Poisson point process and tools from stochastic geometry are exploited to\nquantify the trade-off in terms of information rate and harvested power. It is\nshown that multiple-antenna transmission is capable of increasing information\nrate and harvested power at the same time. \n\n"}
{"id": "1608.08313", "contents": "Title: Sub-channel Assignment, Power Allocation and User Scheduling for\n  Non-Orthogonal Multiple Access Networks Abstract: In this paper, we study the resource allocation and user scheduling problem\nfor a downlink nonorthogonal multiple access network where the base station\nallocates spectrum and power resources to a set of users. We aim to jointly\noptimize the sub-channel assignment and power allocation to maximize the\nweighted total sum-rate while taking into account user fairness. We formulate\nthe sub-channel allocation problem as equivalent to a many-to-many two-sided\nuser-subchannel matching game in which the set of users and sub-channels are\nconsidered as two sets of players pursuing their own interests. We then propose\na matching algorithm which converges to a two-side exchange stable matching\nafter a limited number of iterations. A joint solution is thus provided to\nsolve the sub-channel assignment and power allocation problems iteratively.\nSimulation results show that the proposed algorithm greatly outperforms the\northogonal multiple access scheme and a previous non-orthogonal multiple access\nscheme. \n\n"}
{"id": "1609.00361", "contents": "Title: Autonomous driving challenge: To Infer the property of a dynamic object\n  based on its motion pattern using recurrent neural network Abstract: In autonomous driving applications a critical challenge is to identify action\nto take to avoid an obstacle on collision course. For example, when a heavy\nobject is suddenly encountered it is critical to stop the vehicle or change the\nlane even if it causes other traffic disruptions. However,there are situations\nwhen it is preferable to collide with the object rather than take an action\nthat would result in a much more serious accident than collision with the\nobject. For example, a heavy object which falls from a truck should be avoided\nwhereas a bouncing ball or a soft target such as a foam box need not be.We\npresent a novel method to discriminate between the motion characteristics of\nthese types of objects based on their physical properties such as bounciness,\nelasticity, etc.In this preliminary work, we use recurrent neural net-work with\nLSTM cells to train a classifier to classify objects based on their motion\ntrajectories. We test the algorithm on synthetic data, and, as a proof of\nconcept, demonstrate its effectiveness on a limited set of real-world data. \n\n"}
{"id": "1609.00419", "contents": "Title: Spatially Correlated Content Caching for Device-to-Device Communications Abstract: We study optimal geographic content placement for device-to-device (D2D)\nnetworks in which each file's popularity follows the Zipf distribution. The\nlocations of the D2D users (caches) are modeled by a Poisson point process\n(PPP) and have limited communication range and finite storage. Inspired by the\nMat\\'{e}rn hard-core (type II) point process that captures pairwise\ninteractions between nodes, we devise a novel spatially correlated caching\nstrategy called {\\em hard-core placement} (HCP) such that the D2D nodes caching\nthe same file are never closer to each other than the {\\em exclusion radius}.\nThe exclusion radius plays the role of a substitute for caching probability. We\nderive and optimize the exclusion radii to maximize the {\\em hit probability},\nwhich is the probability that a given D2D node can find a desired file at\nanother node's cache within its communication range. Contrasting it with\nindependent content placement, which is used in most prior work, our HCP\nstrategy often yields a significantly higher cache hit probability. We further\ndemonstrate that the HCP strategy is effective for small cache sizes and a\nsmall communication radius, which are likely conditions for D2D. \n\n"}
{"id": "1609.01856", "contents": "Title: A Survey of Downlink Non-orthogonal Multiple Access for 5G Wireless\n  Communication Networks Abstract: Non-orthogonal multiple access (NOMA) has been recognized as a promising\nmultiple access technique for the next generation cellular communication\nnetworks. In this paper, we first discuss a simple NOMA model with two users\nserved by a single-carrier simultaneously to illustrate its basic principles.\nThen, a more general model with multicarrier serving an arbitrary number of\nusers on each subcarrier is also discussed. An overview of existing works on\nperformance analysis, resource allocation, and multiple-input multiple-output\nNOMA are summarized and discussed. Furthermore, we discuss the key features of\nNOMA and its potential research challenges. \n\n"}
{"id": "1609.02318", "contents": "Title: Capacity Lower Bounds of the Noncentral Chi-Channel with Applications to\n  Soliton Amplitude Modulation Abstract: The channel law for amplitude-modulated solitons transmitted through a\nnonlinear optical fibre with ideal distributed amplification and a receiver\nbased on the nonlinear Fourier transform is a noncentral chi-distribution with\n$2n$ degrees of freedom, where $n=2$ and $n=3$ correspond to the single- and\ndual-polarisation cases, respectively. In this paper, we study capacity lower\nbounds of this channel under an average power constraint in bits per channel\nuse. We develop an asymptotic semi-analytic approximation for a capacity lower\nbound for arbitrary $n$ and a Rayleigh input distribution. It is shown that\nthis lower bound grows logarithmically with signal-to-noise ratio (SNR),\nindependently of the value of $n$. Numerical results for other continuous input\ndistributions are also provided. A half-Gaussian input distribution is shown to\ngive larger rates than a Rayleigh input distribution for $n=1,2,3$. At an SNR\nof $25$ dB, the best lower bounds we developed are approximately $3.68$ bit per\nchannel use. The practically relevant case of amplitude shift-keying (ASK)\nconstellations is also numerically analysed. For the same SNR of $25$ dB, a\n$16$-ASK constellation yields a rate of approximately $3.45$ bit per channel\nuse. \n\n"}
{"id": "1609.02411", "contents": "Title: Velocity-Aware Handover Management in Two-Tier Cellular Networks Abstract: While network densification is considered an important solution to cater the\never-increasing capacity demand, its effect on the handover (HO) rate is\noverlooked. In dense 5G networks, HO delays may neutralize or even negate the\ngains offered by network densification. Hence, user mobility imposes a\nnontrivial challenge to harvest capacity gains via network densification. In\nthis paper, we propose a velocity-aware HO management scheme for two-tier\ndownlink cellular network to mitigate the HO effect on the foreseen\ndensification throughput gains. The proposed HO scheme sacrifices the best BS\nconnectivity, by skipping HO to some BSs along the user's trajectory, to\nmaintain longer connection durations and reduce HO rates. Furthermore, the\nproposed scheme enables cooperative BS service and strongest interference\ncancellation to compensate for skipping the best connectivity. To this end, we\nconsider different HO skipping scenarios and develop a velocity-aware\nmathematical model, via stochastic geometry, to quantify the performance of the\nproposed HO scheme in terms of the coverage probability and user throughput.\nThe results highlight the HO rate problem in dense cellular environments and\nshow the importance of the proposed HO schemes. Finally, the value of BS\ncooperation along with handover skipping is quantified for different user\nmobility profiles. \n\n"}
{"id": "1609.02596", "contents": "Title: A Stackelberg Game for Incentive Proactive Caching Mechanisms in\n  Wireless Networks Abstract: In this paper, an incentive proactive cache mechanism in cache-enabled small\ncell networks (SCNs) is proposed, in order to motivate the content providers\n(CPs) to participate in the caching procedure. A network composed of a single\nmobile network operator (MNO) and multiple CPs is considered. The MNO aims to\ndefine the price it charges the CPs to maximize its revenue while the CPs\ncompete to determine the number of files they cache at the MNO's small base\nstations (SBSs) to improve the quality of service (QoS) of their users. This\nproblem is formulated as a Stackelberg game where a single MNO is considered as\nthe leader and the multiple CPs willing to cache files are the followers. The\nfollowers game is modeled as a non-cooperative game and both the existence and\nuniqueness of a Nash equilibrium (NE) are proved. The closed-form expression of\nthe NE which corresponds to the amount of storage each CP requests from the MNO\nis derived. An optimization problem is formulated at the MNO side to determine\nthe optimal price that the MNO should charge the CPs. Simulation results show\nthat at the equilibrium, the MNO and CPs can all achieve a utility that is up\nto 50% higher than the cases in which the prices and storage quantities are\nrequested arbitrarily. \n\n"}
{"id": "1609.04747", "contents": "Title: An overview of gradient descent optimization algorithms Abstract: Gradient descent optimization algorithms, while increasingly popular, are\noften used as black-box optimizers, as practical explanations of their\nstrengths and weaknesses are hard to come by. This article aims to provide the\nreader with intuitions with regard to the behaviour of different algorithms\nthat will allow her to put them to use. In the course of this overview, we look\nat different variants of gradient descent, summarize challenges, introduce the\nmost common optimization algorithms, review architectures in a parallel and\ndistributed setting, and investigate additional strategies for optimizing\ngradient descent. \n\n"}
{"id": "1609.05078", "contents": "Title: Hybrid Beamforming for Massive MIMO - A Survey Abstract: Hybrid multiple-antenna transceivers, which combine large-dimensional analog\npre/postprocessing with lower-dimensional digital processing, are the most\npromising approach for reducing the hardware cost and training overhead in\nmassive MIMO systems. This paper provides a comprehensive survey of the various\nincarnations of such structures that have been proposed in the literature. We\nprovide a taxonomy in terms of the required channel state information (CSI),\nnamely whether the processing adapts to the instantaneous or the average\n(second-order) CSI; while the former provides somewhat better signal-to-noise\nand interference ratio (SNIR), the latter has much lower overhead for CSI\nacquisition. We furthermore distinguish hardware structures of different\ncomplexities. Finally, we point out the special design aspects for operation at\nmillimeter-wave frequencies. \n\n"}
{"id": "1609.05362", "contents": "Title: Mobile Edge Computing via a UAV-Mounted Cloudlet: Optimization of Bit\n  Allocation and Path Planning Abstract: Unmanned Aerial Vehicles (UAVs) have been recently considered as means to\nprovide enhanced coverage or relaying services to mobile users (MUs) in\nwireless systems with limited or no infrastructure. In this paper, a UAV-based\nmobile cloud computing system is studied in which a moving UAV is endowed with\ncomputing capabilities to offer computation offloading opportunities to MUs\nwith limited local processing capabilities. The system aims at minimizing the\ntotal mobile energy consumption while satisfying quality of service\nrequirements of the offloaded mobile application. Offloading is enabled by\nuplink and downlink communications between the mobile devices and the UAV that\ntake place by means of frequency division duplex (FDD) via orthogonal or\nnon-orthogonal multiple access (NOMA) schemes. The problem of jointly\noptimizing the bit allocation for uplink and downlink communication as well as\nfor computing at the UAV, along with the cloudlet's trajectory under latency\nand UAV's energy budget constraints is formulated and addressed by leveraging\nsuccessive convex approximation (SCA) strategies. Numerical results demonstrate\nthe significant energy savings that can be accrued by means of the proposed\njoint optimization of bit allocation and cloudlet's trajectory as compared to\nlocal mobile execution as well as to partial optimization approaches that\ndesign only the bit allocation or the cloudlet's trajectory. \n\n"}
{"id": "1609.05649", "contents": "Title: Complementary Dual Algebraic Geometry Codes Abstract: Linear complementary dual (LCD) codes is a class of linear codes introduced\nby Massey in 1964. LCD codes have been extensively studied in literature\nrecently. In addition to their applications in data storage, communications\nsystems, and consumer electronics, LCD codes have been employed in\ncryptography. More specifically, it has been shown that LCD codes can also help\nimprove the security of the information processed by sensitive devices,\nespecially against so-called side-channel attacks (SCA) and fault non-invasive\nattacks. In this paper, we are interested in the construction of particular\nalgebraic geometry (AG) LCD codes which could be good candidates to be\nresistant against SCA. We firstly provide a construction scheme for obtaining\nLCD codes from elliptic curves. Then, some explicit LCD codes from elliptic\ncurve are presented. MDS codes are of the most importance in coding theory due\nto their theoretical significance and practical interests. In this paper, all\nthe constructed LCD codes from elliptic curves are MDS or almost MDS. Some\ninfinite classes of LCD codes from elliptic curves are optimal due to the\nGriesmer bound. Finally, we introduce a construction mechanism for obtaining\nLCD codes from any algebraic curve and derive some explicit LCD codes from\nhyperelliptic curves and Hermitian curves. \n\n"}
{"id": "1609.05670", "contents": "Title: Load-aware Performance Analysis of Cell Center/Edge Users in Random\n  HetNets Abstract: For real-time traffic, the link quality and call blocking probability (both\nderived from coverage probability) are realized to be poor for cell edge users\n(CEUs) compared to cell center users (CCUs) as the signal reception in the cell\ncenter region is better compared to the cell edge region. In heterogeneous\nnetworks (HetNets), the uncoordinated channel access by different types of base\nstations determine the interference statistics that further arbitrates the\ncoverage probability. Thus, the spectrum allocation techniques have major\nimpact on the performance of CCU and CEU. In this paper, the performance of\nCCUs and CEUs in a random two-tier network is studied for two spectrum\nallocation techniques namely: 1) co-channel (CSA), and 2) shared (SSA). For\nperformance analysis, the widely accepted conception of modeling the tiers of\nHetNet using independent homogeneous Poisson point process (PPP) is considered\nto accommodate the spatial randomness in location of BSs. To incorporate the\nspatial randomness in the arrival of service and to aid the load-aware\nanalysis, the cellular traffic is modeled using spatio-temporal PPP. Under this\nscenario, we have developed an analytical framework to evaluate the load-aware\nperformance, including coverage and blocking probabilities, of CCUs and CEUs\nunder both spectrum allocation techniques. Further, we provide insight into\nachievable area energy efficiency for SSA and CSA. The developed analytical\nframework is validated through extensive simulations. Next, we demonstrate the\nimpact of traffic load and femto access points density on the performance of\nCCUs/CEUs under CSA and SSA. \n\n"}
{"id": "1609.07666", "contents": "Title: Well-Rounded Lattices for Coset Coding in MIMO Wiretap Channels Abstract: The concept of well-rounded lattices has recently found important\napplications in the setting of a fading single-input single-output (SISO)\nwiretap channel. It has been shown that, under this setup, the property of\nbeing well-rounded is critical for minimizing the eavesdropper's probability of\ncorrect decoding in lower SNR regimes. The superior performance of coset codes\nconstructed from well-rounded lattices has been illustrated in several\nsimulations.\n  In the present article, this work is extended to fading multiple-input\nmultiple-output (MIMO) wiretap channels, and similar design criteria as in the\nSISO case are derived. Further, explicit coset codes for Rayleigh fading MIMO\nwiretap channels are designed. In particular, it is shown through extensive\nsimulations that sublattices of the well-known Alamouti code and Golden code\nwhich meet our design criteria perform better than scalar multiples of the code\nlattice for the same parameters. \n\n"}
{"id": "1609.08199", "contents": "Title: Least squares estimator of fractional Ornstein Uhlenbeck processes with\n  periodic mean Abstract: We first study the drift parameter estimation of the fractional\nOrnstein-Uhlenbeck process (fOU) with periodic mean for every\n$\\frac{1}{2}<H<1$. More precisely, we extend the consistency proved in\n\\cite{DFW} for $\\frac{1}{2}<H<\\frac{3}{4}$ to the strong consistency for any\n$\\frac{1}{2}<H<1$ on the one hand, and on the other, we also discuss the\nasymptotic normality given in \\cite{DFW}. In the second main part of the paper,\nwe study the strong consistency and the asymptotic normality of the fOU of the\nsecond kind with periodic mean for any $\\frac{1}{2}<H<1$. \n\n"}
{"id": "1609.09358", "contents": "Title: Combining Belief Propagation and Successive Cancellation List Decoding\n  of Polar Codes on a GPU Platform Abstract: The decoding performance of polar codes strongly depends on the decoding\nalgorithm used, while also the decoder throughput and its latency mainly depend\non the decoding algorithm. In this work, we implement the powerful successive\ncancellation list (SCL) decoder on a GPU and identify the bottlenecks of this\nalgorithm with respect to parallel computing and its difficulties. The inherent\nserial decoding property of the SCL algorithm naturally limits the achievable\nspeed-up gains on GPUs when compared to CPU implementations. In order to\nincrease the decoding throughput, we use a hybrid decoding scheme based on the\nbelief propagation (BP) decoder, which can be intra and inter-frame\nparallelized. The proposed scheme combines excellent decoding performance and\nhigh throughput within the signal-to-noise ratio (SNR) region of interest. \n\n"}
{"id": "1610.00906", "contents": "Title: Next-to-leading order corrections to capacity for nondispersive\n  nonlinear optical fiber channel in intermediate power region Abstract: We consider the optical fiber channel modelled by the nonlinear\nShr\\\"{o}dinger equation with zero dispersion and additive Gaussian noise. Using\nFeynman path-integral approach for the model we find corrections to conditional\nprobability density function, output signal distribution, conditional and\noutput signal entropies, and the channel capacity at large signal-to-noise\nratio. We demonstrate that the correction to the channel capacity is positive\nfor large signal power. Therefore, this correction increases the earlier\ncalculated capacity for a nondispersive nonlinear optical fiber channel in the\nintermediate power region. \n\n"}
{"id": "1610.01287", "contents": "Title: Sufficiently Myopic Adversaries are Blind Abstract: In this work we consider a communication problem in which a sender, Alice,\nwishes to communicate with a receiver, Bob, over a channel controlled by an\nadversarial jammer, James, who is {\\em myopic}. Roughly speaking, for\nblocklength $n$, the codeword $X^n$ transmitted by Alice is corrupted by James\nwho must base his adversarial decisions (of which locations of $X^n$ to corrupt\nand how to corrupt them) not on the codeword $X^n$ but on $Z^n$, an image of\n$X^n$ through a noisy memoryless channel. More specifically, our communication\nmodel may be described by two channels. A memoryless channel $p(z|x)$ from\nAlice to James, and an {\\it Arbitrarily Varying Channel} from Alice to Bob,\n$p(y|x,s)$ governed by a state $X^n$ determined by James. In standard\nadversarial channels the states $S^n$ may depend on the codeword $X^n$, but in\nour setting $S^n$ depends only on James's view $Z^n$.\n  The myopic channel captures a broad range of channels and bridges between the\nstandard models of memoryless and adversarial (zero-error) channels. In this\nwork we present upper and lower bounds on the capacity of myopic channels. For\na number of special cases of interest we show that our bounds are tight. We\nextend our results to the setting of {\\em secure} communication in which we\nrequire that the transmitted message remain secret from James. For example, we\nshow that if (i) James may flip at most a $p$ fraction of the bits communicated\nbetween Alice and Bob, and (ii) James views $X^n$ through a binary symmetric\nchannel with parameter $q$, then once James is \"sufficiently myopic\" (in this\ncase, when $q>p$), then the optimal communication rate is that of an adversary\nwho is \"blind\" (that is, an adversary that does not see $X^n$ at all), which is\n$1-H(p)$ for standard communication, and $H(q)-H(p)$ for secure communication.\nA similar phenomenon exists for our general model of communication. \n\n"}
{"id": "1610.01586", "contents": "Title: Learning How to Communicate in the Internet of Things: Finite Resources\n  and Heterogeneity Abstract: For a seamless deployment of the Internet of Things (IoT), there is a need\nfor self-organizing solutions to overcome key IoT challenges that include data\nprocessing, resource management, coexistence with existing wireless networks,\nand improved IoT-wide event detection. One of the most promising solutions to\naddress these challenges is via the use of innovative learning frameworks that\nwill enable the IoT devices to operate autonomously in a dynamic environment.\nHowever, developing learning mechanisms for the IoT requires coping with unique\nIoT properties in terms of resource constraints, heterogeneity, and strict\nquality-of-service requirements. In this paper, a number of emerging learning\nframeworks suitable for IoT applications are presented. In particular, the\nadvantages, limitations, IoT applications, and key results pertaining to\nmachine learning, sequential learning, and reinforcement learning are studied.\nFor each type of learning, the computational complexity, required information,\nand learning performance are discussed. Then, to handle the heterogeneity of\nthe IoT, a new framework based on the powerful tools of cognitive hierarchy\ntheory is introduced. This framework is shown to efficiently capture the\ndifferent IoT device types and varying levels of available resources among the\nIoT devices. In particular, the different resource capabilities of IoT devices\nare mapped to different levels of rationality in cognitive hierarchy theory,\nthus enabling the IoT devices to use different learning frameworks depending on\ntheir available resources. Finally, key results on the use of cognitive\nhierarchy theory in the IoT are presented. \n\n"}
{"id": "1610.01982", "contents": "Title: Quantum Game Theory for Beam Alignment in Millimeter Wave\n  Device-to-Device Communications Abstract: In this paper, the problem of optimized beam alignment for wearable\ndevice-to-device (D2D) communications over millimeter wave (mmW) frequencies is\nstudied. In particular, a noncooperative game is formulated between wearable\ncommunication pairs that engage in D2D communications. In this game, wearable\ndevices acting as transmitters autonomously select the directions of their\nbeams so as to maximize the data rate to their receivers. To solve the game, an\nalgorithm based on best response dynamics is proposed that allows the\ntransmitters to reach a Nash equilibrium in a distributed manner. To further\nimprove the performance of mmW D2D communications, a novel quantum game model\nis formulated to enable the wearable devices to exploit new quantum directions\nduring their beam alignment so as to further enhance their data rate.\nSimulation results show that the proposed game-theoretic approach improves the\nperformance, in terms of data rate, of about 75% compared to a uniform beam\nalignment. The results also show that the quantum game model can further yield\nup to 20% improvement in data rates, relative to the classical game approach. \n\n"}
{"id": "1610.02527", "contents": "Title: Federated Optimization: Distributed Machine Learning for On-Device\n  Intelligence Abstract: We introduce a new and increasingly relevant setting for distributed\noptimization in machine learning, where the data defining the optimization are\nunevenly distributed over an extremely large number of nodes. The goal is to\ntrain a high-quality centralized model. We refer to this setting as Federated\nOptimization. In this setting, communication efficiency is of the utmost\nimportance and minimizing the number of rounds of communication is the\nprincipal goal.\n  A motivating example arises when we keep the training data locally on users'\nmobile devices instead of logging it to a data center for training. In\nfederated optimziation, the devices are used as compute nodes performing\ncomputation on their local data in order to update a global model. We suppose\nthat we have extremely large number of devices in the network --- as many as\nthe number of users of a given service, each of which has only a tiny fraction\nof the total data available. In particular, we expect the number of data points\navailable locally to be much smaller than the number of devices. Additionally,\nsince different users generate data with different patterns, it is reasonable\nto assume that no device has a representative sample of the overall\ndistribution.\n  We show that existing algorithms are not suitable for this setting, and\npropose a new algorithm which shows encouraging experimental results for sparse\nconvex problems. This work also sets a path for future research needed in the\ncontext of \\federated optimization. \n\n"}
{"id": "1610.03082", "contents": "Title: Vector Approximate Message Passing Abstract: The standard linear regression (SLR) problem is to recover a vector\n$\\mathbf{x}^0$ from noisy linear observations\n$\\mathbf{y}=\\mathbf{Ax}^0+\\mathbf{w}$. The approximate message passing (AMP)\nalgorithm recently proposed by Donoho, Maleki, and Montanari is a\ncomputationally efficient iterative approach to SLR that has a remarkable\nproperty: for large i.i.d.\\ sub-Gaussian matrices $\\mathbf{A}$, its\nper-iteration behavior is rigorously characterized by a scalar state-evolution\nwhose fixed points, when unique, are Bayes optimal. The AMP algorithm, however,\nis fragile in that even small deviations from the i.i.d.\\ sub-Gaussian model\ncan cause the algorithm to diverge. This paper considers a \"vector AMP\" (VAMP)\nalgorithm and shows that VAMP has a rigorous scalar state-evolution that holds\nunder a much broader class of large random matrices $\\mathbf{A}$: those that\nare right-orthogonally invariant. After performing an initial singular value\ndecomposition (SVD) of $\\mathbf{A}$, the per-iteration complexity of VAMP can\nbe made similar to that of AMP. In addition, the fixed points of VAMP's state\nevolution are consistent with the replica prediction of the minimum\nmean-squared error recently derived by Tulino, Caire, Verd\\'u, and Shamai.\nNumerical experiments are used to confirm the effectiveness of VAMP and its\nconsistency with state-evolution predictions. \n\n"}
{"id": "1610.04714", "contents": "Title: A New Perspective on Randomized Gossip Algorithms Abstract: In this short note we propose a new approach for the design and analysis of\nrandomized gossip algorithms which can be used to solve the average consensus\nproblem. We show how that Randomized Block Kaczmarz (RBK) method - a method for\nsolving linear systems - works as gossip algorithm when applied to a special\nsystem encoding the underlying network. The famous pairwise gossip algorithm\narises as a special case. Subsequently, we reveal a hidden duality of\nrandomized gossip algorithms, with the dual iterative process maintaining a set\nof numbers attached to the edges as opposed to nodes of the network. We prove\nthat RBK obtains a superlinear speedup in the size of the block, and\ndemonstrate this effect through experiments. \n\n"}
{"id": "1610.04983", "contents": "Title: Improved bounds for sparse recovery from subsampled random convolutions Abstract: We study the recovery of sparse vectors from subsampled random convolutions\nvia $\\ell_1$-minimization. We consider the setup in which both the subsampling\nlocations as well as the generating vector are chosen at random. For a\nsubgaussian generator with independent entries, we improve previously known\nestimates: if the sparsity $s$ is small enough, i.e., $s \\lesssim\n\\sqrt{n/\\log(n)}$, we show that $m \\gtrsim s \\log(en/s)$ measurements are\nsufficient to recover $s$-sparse vectors in dimension $n$ with high\nprobability, matching the well-known condition for recovery from standard\nGaussian measurements. If $s$ is larger, then essentially $m \\geq s \\log^2(s)\n\\log(\\log(s)) \\log(n)$ measurements are sufficient, again improving over\nprevious estimates. Our results are shown via the so-called robust null space\nproperty which is weaker than the standard restricted isometry property. Our\nmethod of proof involves a novel combination of small ball estimates with\nchaining techniques {which should be of independent interest. \n\n"}
{"id": "1610.05492", "contents": "Title: Federated Learning: Strategies for Improving Communication Efficiency Abstract: Federated Learning is a machine learning setting where the goal is to train a\nhigh-quality centralized model while training data remains distributed over a\nlarge number of clients each with unreliable and relatively slow network\nconnections. We consider learning algorithms for this setting where on each\nround, each client independently computes an update to the current model based\non its local data, and communicates this update to a central server, where the\nclient-side updates are aggregated to compute a new global model. The typical\nclients in this setting are mobile phones, and communication efficiency is of\nthe utmost importance.\n  In this paper, we propose two ways to reduce the uplink communication costs:\nstructured updates, where we directly learn an update from a restricted space\nparametrized using a smaller number of variables, e.g. either low-rank or a\nrandom mask; and sketched updates, where we learn a full model update and then\ncompress it using a combination of quantization, random rotations, and\nsubsampling before sending it to the server. Experiments on both convolutional\nand recurrent networks show that the proposed methods can reduce the\ncommunication cost by two orders of magnitude. \n\n"}
{"id": "1610.06995", "contents": "Title: Modeling and Analysis of Uplink Non-Orthogonal Multiple Access (NOMA) in\n  Large-Scale Cellular Networks Using Poisson Cluster Processes Abstract: Non-orthogonal multiple access (NOMA) serves multiple users by superposing\ntheir distinct message signals. The desired message signal is decoded at the\nreceiver by applying successive interference cancellation (SIC). Using the\ntheory of Poisson cluster process (PCP), we provide a framework to analyze\nmulti-cell uplink NOMA systems. Specifically, we characterize the rate coverage\nprobability of a NOMA user who is at rank $m$ (in terms of the distance from\nits serving BS) among all users in a cell and the mean rate coverage\nprobability of all users in a cell. Since the signal-to-interference-plus-noise\nratio (SINR) of $m$-th user relies on efficient SIC, we consider three\nscenarios, i.e., perfect SIC (in which the signals of $m-1$ interferers who are\nstronger than $m$-th user are decoded successfully), imperfect SIC (in which\nthe signals of of $m-1$ interferers who are stronger than $m$-th user may or\nmay not be decoded successfully), and imperfect worst case SIC (in which the\ndecoding of the signal of $m$-th user is always unsuccessful whenever the\ndecoding of its relative $m-1$ stronger users is unsuccessful). The derived\nexpressions are customized to capture the performance of a user at rank $m$ in\nan equivalent orthogonal multiple access (OMA) system. Finally, numerical\nresults are presented to validate the derived expressions. \n\n"}
{"id": "1610.08070", "contents": "Title: Low rank matrix recovery from Clifford orbits Abstract: We prove that low-rank matrices can be recovered efficiently from a small\nnumber of measurements that are sampled from orbits of a certain matrix group.\nAs a special case, our theory makes statements about the phase retrieval\nproblem. Here, the task is to recover a vector given only the amplitudes of its\ninner product with a small number of vectors from an orbit. Variants of the\ngroup in question have appeared under different names in many areas of\nmathematics. In coding theory and quantum information, it is the complex\nClifford group; in time-frequency analysis the oscillator group; and in\nmathematical physics the metaplectic group. It affords one particularly small\nand highly structured orbit that includes and generalizes the discrete Fourier\nbasis: While the Fourier vectors have coefficients of constant modulus and\nphases that depend linearly on their index, the vectors in said orbit have\nphases with a quadratic dependence. In quantum information, the orbit is used\nextensively and is known as the set of stabilizer states. We argue that due to\ntheir rich geometric structure and their near-optimal recovery properties,\nstabilizer states form an ideal model for structured measurements for phase\nretrieval. Our results hold for $m\\geq C \\kappa_r r d \\log(d)$ measurements,\nwhere the oversampling factor k varies between $\\kappa_r=1$ and $\\kappa_r =\nr^2$ depending on the orbit. The reconstruction is stable towards both additive\nnoise and deviations from the assumption of low rank. If the matrices of\ninterest are in addition positive semidefinite, reconstruction may be performed\nby a simple constrained least squares regression. Our proof methods could be\nadapted to cover orbits of other groups. \n\n"}
{"id": "1610.09110", "contents": "Title: $f$-Divergence Inequalities via Functional Domination Abstract: This paper considers derivation of $f$-divergence inequalities via the\napproach of functional domination. Bounds on an $f$-divergence based on one or\nseveral other $f$-divergences are introduced, dealing with pairs of probability\nmeasures defined on arbitrary alphabets. In addition, a variety of bounds are\nshown to hold under boundedness assumptions on the relative information. The\njournal paper, which includes more approaches for the derivation of\nf-divergence inequalities and proofs, is available on the arXiv at\nhttps://arxiv.org/abs/1508.00335, and it has been published in the IEEE Trans.\non Information Theory, vol. 62, no. 11, pp. 5973-6006, November 2016. \n\n"}
{"id": "1610.09650", "contents": "Title: Deep Model Compression: Distilling Knowledge from Noisy Teachers Abstract: The remarkable successes of deep learning models across various applications\nhave resulted in the design of deeper networks that can solve complex problems.\nHowever, the increasing depth of such models also results in a higher storage\nand runtime complexity, which restricts the deployability of such very deep\nmodels on mobile and portable devices, which have limited storage and battery\ncapacity. While many methods have been proposed for deep model compression in\nrecent years, almost all of them have focused on reducing storage complexity.\nIn this work, we extend the teacher-student framework for deep model\ncompression, since it has the potential to address runtime and train time\ncomplexity too. We propose a simple methodology to include a noise-based\nregularizer while training the student from the teacher, which provides a\nhealthy improvement in the performance of the student network. Our experiments\non the CIFAR-10, SVHN and MNIST datasets show promising improvement, with the\nbest performance on the CIFAR-10 dataset. We also conduct a comprehensive\nempirical evaluation of the proposed method under related settings on the\nCIFAR-10 dataset to show the promise of the proposed approach. \n\n"}
{"id": "1611.00991", "contents": "Title: Mesoscopic fluctuations for the thinned Circular Unitary Ensemble Abstract: In this paper we study the asymptotic behavior of mesoscopic fluctuations for\nthe thinned Circular Unitary Ensemble. The effect of thinning is that the\neigenvalues start to decorrelate. The decorrelation is stronger on the larger\nscales than on the smaller scales. We investigate this behavior by studying\nmesoscopic linear statistics. There are two regimes depending on the scale\nparameter and the thinning parameter. In one regime we obtain a CLT of a\nclassical type and in the other regime we retrieve the CLT for CUE. The two\nregimes are separated by a critical line. On the critical line the limiting\nfluctuations are no longer Gaussian, but described by infinitely divisible\nlaws. We argue that this transition phenomenon is universal by showing that the\nsame transition and their laws appear for fluctuations of the thinned sine\nprocess in a growing box. The proofs are based on a Riemann-Hilbert problem for\nintegrable operators. \n\n"}
{"id": "1611.01030", "contents": "Title: Sparse Support Recovery with Non-smooth Loss Functions Abstract: In this paper, we study the support recovery guarantees of underdetermined\nsparse regression using the $\\ell_1$-norm as a regularizer and a non-smooth\nloss function for data fidelity. More precisely, we focus in detail on the\ncases of $\\ell_1$ and $\\ell_\\infty$ losses, and contrast them with the usual\n$\\ell_2$ loss. While these losses are routinely used to account for either\nsparse ($\\ell_1$ loss) or uniform ($\\ell_\\infty$ loss) noise models, a\ntheoretical analysis of their performance is still lacking. In this article, we\nextend the existing theory from the smooth $\\ell_2$ case to these non-smooth\ncases. We derive a sharp condition which ensures that the support of the vector\nto recover is stable to small additive noise in the observations, as long as\nthe loss constraint size is tuned proportionally to the noise level. A\ndistinctive feature of our theory is that it also explains what happens when\nthe support is unstable. While the support is not stable anymore, we identify\nan \"extended support\" and show that this extended support is stable to small\nadditive noise. To exemplify the usefulness of our theory, we give a detailed\nnumerical analysis of the support stability/instability of compressed sensing\nrecovery with these different losses. This highlights different parameter\nregimes, ranging from total support stability to progressively increasing\nsupport instability. \n\n"}
{"id": "1611.01704", "contents": "Title: End-to-end Optimized Image Compression Abstract: We describe an image compression method, consisting of a nonlinear analysis\ntransformation, a uniform quantizer, and a nonlinear synthesis transformation.\nThe transforms are constructed in three successive stages of convolutional\nlinear filters and nonlinear activation functions. Unlike most convolutional\nneural networks, the joint nonlinearity is chosen to implement a form of local\ngain control, inspired by those used to model biological neurons. Using a\nvariant of stochastic gradient descent, we jointly optimize the entire model\nfor rate-distortion performance over a database of training images, introducing\na continuous proxy for the discontinuous loss function arising from the\nquantizer. Under certain conditions, the relaxed loss function may be\ninterpreted as the log likelihood of a generative model, as implemented by a\nvariational autoencoder. Unlike these models, however, the compression model\nmust operate at any given point along the rate-distortion curve, as specified\nby a trade-off parameter. Across an independent set of test images, we find\nthat the optimized method generally exhibits better rate-distortion performance\nthan the standard JPEG and JPEG 2000 compression methods. More importantly, we\nobserve a dramatic improvement in visual quality for all images at all bit\nrates, which is supported by objective quality estimates using MS-SSIM. \n\n"}
{"id": "1611.01886", "contents": "Title: An Information-Theoretic Framework for Fast and Robust Unsupervised\n  Learning via Neural Population Infomax Abstract: A framework is presented for unsupervised learning of representations based\non infomax principle for large-scale neural populations. We use an asymptotic\napproximation to the Shannon's mutual information for a large neural population\nto demonstrate that a good initial approximation to the global\ninformation-theoretic optimum can be obtained by a hierarchical infomax method.\nStarting from the initial solution, an efficient algorithm based on gradient\ndescent of the final objective function is proposed to learn representations\nfrom the input datasets, and the method works for complete, overcomplete, and\nundercomplete bases. As confirmed by numerical experiments, our method is\nrobust and highly efficient for extracting salient features from input\ndatasets. Compared with the main existing methods, our algorithm has a distinct\nadvantage in both the training speed and the robustness of unsupervised\nrepresentation learning. Furthermore, the proposed method is easily extended to\nthe supervised or unsupervised model for training deep structure networks. \n\n"}
{"id": "1611.02010", "contents": "Title: Convergence Analysis of Distributed Inference with Vector-Valued\n  Gaussian Belief Propagation Abstract: This paper considers inference over distributed linear Gaussian models using\nfactor graphs and Gaussian belief propagation (BP). The distributed inference\nalgorithm involves only local computation of the information matrix and of the\nmean vector, and message passing between neighbors. Under broad conditions, it\nis shown that the message information matrix converges to a unique positive\ndefinite limit matrix for arbitrary positive semidefinite initialization, and\nit approaches an arbitrarily small neighborhood of this limit matrix at a\ndoubly exponential rate. A necessary and sufficient convergence condition for\nthe belief mean vector to converge to the optimal centralized estimator is\nprovided under the assumption that the message information matrix is\ninitialized as a positive semidefinite matrix. Further, it is shown that\nGaussian BP always converges when the underlying factor graph is given by the\nunion of a forest and a single loop. The proposed convergence condition in the\nsetup of distributed linear Gaussian models is shown to be strictly weaker than\nother existing convergence conditions and requirements, including the Gaussian\nMarkov random field based walk-summability condition, and applicable to a large\nclass of scenarios. \n\n"}
{"id": "1611.02828", "contents": "Title: What Is the True Value of Dynamic TDD: A MAC Layer Perspective Abstract: Small cell networks (SCNs) are envisioned to embrace dynamic time division\nduplexing (TDD) in order to tailor downlink (DL)/uplink (UL) subframe resources\nto quick variations and burstiness of DL/UL traffic. The study of dynamic TDD\nis particularly important because it provides valuable insights on the full\nduplex transmission technology, which has been identified as one of the\ncandidate technologies for the 5th-generation (5G) networks. Up to now, the\nexisting works on dynamic TDD have shown that the UL of dynamic TDD suffers\nfrom severe performance degradation due to the strong DL-to-UL interference in\nthe physical (PHY) layer. This conclusion raises a fundamental question:\nDespite such obvious technology disadvantage, what is the true value of dynamic\nTDD? In this paper, we answer this question from a media access control (MAC)\nlayer viewpoint and present analytical results on the DL/UL time resource\nutilization (TRU) of synchronous dynamic TDD, which has been widely adopted in\nthe existing 4th-generation (4G) systems. Our analytical results shed new light\non the dynamic TDD in future synchronous 5G networks. \n\n"}
{"id": "1611.04692", "contents": "Title: The norm of the Fourier transform on compact or discrete abelian groups Abstract: We calculate the norm of the Fourier operator from $L^p(X)$ to $L^q(\\hat{X})$\nwhen $X$ is an infinite locally compact abelian group that is, furthermore,\ncompact or discrete. This subsumes the sharp Hausdorff-Young inequality on such\ngroups. In particular, we identify the region in $(p,q)$-space where the norm\nis infinite, generalizing a result of Fournier, and setting up a contrast with\nthe case of finite abelian groups, where the norm was determined by Gilbert and\nRzeszotnik. As an application, uncertainty principles on such groups expressed\nin terms of R\\'enyi entropies are discussed. \n\n"}
{"id": "1611.05653", "contents": "Title: Iterative Channel Estimation Using LSE and Sparse Message Passing for\n  MmWave MIMO Systems Abstract: We propose an iterative channel estimation algorithm based on the Least\nSquare Estimation (LSE) and Sparse Message Passing (SMP) algorithm for the\nMillimeter Wave (mmWave) MIMO systems. The channel coefficients of the mmWave\nMIMO are approximately modeled as a Bernoulli-Gaussian distribution and the\nchannel matrix is sparse with only a few non-zero entries. By leveraging the\nadvantage of sparseness, we propose an algorithm that iteratively detects the\nexact locations and values of non-zero entries of the sparse channel matrix. At\neach iteration, the locations are detected by the SMP, and values are estimated\nwith the LSE. We also analyze the Cram\\'er-Rao Lower Bound (CLRB), and show\nthat the proposed algorithm is a minimum variance unbiased estimator under the\nassumption that we have the partial priori knowledge of the channel.\nFurthermore, we employ the Gaussian approximation for message densities under\ndensity evolution to simplify the analysis of the algorithm, which provides a\nsimple method to predict the performance of the proposed algorithm. Numerical\nexperiments show that the proposed algorithm has much better performance than\nthe existing sparse estimators, especially when the channel is sparse. In\naddition, our proposed algorithm converges to the CRLB of the genie-aided\nestimation of sparse channels with only five turbo iterations. \n\n"}
{"id": "1611.07216", "contents": "Title: What to Expect When You Are Expecting on the Grassmannian Abstract: Consider an incoming sequence of vectors, all belonging to an unknown\nsubspace $\\operatorname{S}$, and each with many missing entries. In order to\nestimate $\\operatorname{S}$, it is common to partition the data into blocks and\niteratively update the estimate of $\\operatorname{S}$ with each new incoming\nmeasurement block.\n  In this paper, we investigate a rather basic question: Is it possible to\nidentify $\\operatorname{S}$ by averaging the column span of the partially\nobserved incoming measurement blocks on the Grassmannian?\n  We show that in general the span of the incoming blocks is in fact a biased\nestimator of $\\operatorname{S}$ when data suffers from erasures, and we find an\nupper bound for this bias. We reach this conclusion by examining the defining\noptimization program for the Fr\\'{e}chet expectation on the Grassmannian, and\nwith the aid of a sharp perturbation bound and standard large deviation\nresults. \n\n"}
{"id": "1611.07641", "contents": "Title: Sparse Phase Retrieval via Truncated Amplitude Flow Abstract: This paper develops a novel algorithm, termed \\emph{SPARse Truncated\nAmplitude flow} (SPARTA), to reconstruct a sparse signal from a small number of\nmagnitude-only measurements. It deals with what is also known as sparse phase\nretrieval (PR), which is \\emph{NP-hard} in general and emerges in many science\nand engineering applications. Upon formulating sparse PR as an amplitude-based\nnonconvex optimization task, SPARTA works iteratively in two stages: In stage\none, the support of the underlying sparse signal is recovered using an\nanalytically well-justified rule, and subsequently, a sparse\northogonality-promoting initialization is obtained via power iterations\nrestricted on the support; and, in the second stage, the initialization is\nsuccessively refined by means of hard thresholding based gradient-type\niterations. SPARTA is a simple yet effective, scalable, and fast sparse PR\nsolver. On the theoretical side, for any $n$-dimensional $k$-sparse ($k\\ll n$)\nsignal $\\bm{x}$ with minimum (in modulus) nonzero entries on the order of\n$(1/\\sqrt{k})\\|\\bm{x}\\|_2$, SPARTA recovers the signal exactly (up to a global\nunimodular constant) from about $k^2\\log n$ random Gaussian measurements with\nhigh probability. Furthermore, SPARTA incurs computational complexity on the\norder of $k^2n\\log n$ with total runtime proportional to the time required to\nread the data, which improves upon the state-of-the-art by at least a factor of\n$k$. Finally, SPARTA is robust against additive noise of bounded support.\nExtensive numerical tests corroborate markedly improved recovery performance\nand speedups of SPARTA relative to existing alternatives. \n\n"}
{"id": "1611.08761", "contents": "Title: Ergodicity and Accuracy of Optimal Particle Filters for Bayesian Data\n  Assimilation Abstract: For particle filters and ensemble Kalman filters it is of practical\nimportance to understand how and why data assimilation methods can be effective\nwhen used with a fixed small number of particles, since for many large-scale\napplications it is not practical to deploy algorithms close to the large\nparticle limit asymptotic. In this paper we address this question for particle\nfilters and, in particular, study their accuracy (in the small noise limit) and\nergodicity (for noisy signal and observation) without appealing to the large\nparticle number limit. We first overview the accuracy and minorization\nproperties for the true filtering distribution, working in the setting of\nconditional Gaussianity for the dynamics-observation model. We then show that\nthese properties are inherited by optimal particle filters for any fixed number\nof particles, and use the minorization to establish ergodicity of the filters.\nFor completeness we also prove large particle number consistency results for\nthe optimal particle filters, by writing the update equations for the\nunderlying distributions as recursions. In addition to looking at the optimal\nparticle filter with standard resampling, we derive all the above results for\n(what we term) the Gaussianized optimal particle filter and show that the\ntheoretical properties are favorable for this method, when compared to the\nstandard optimal particle filter. \n\n"}
{"id": "1611.08946", "contents": "Title: Exponential Separation of Quantum Communication and Classical\n  Information Abstract: We exhibit a Boolean function for which the quantum communication complexity\nis exponentially larger than the classical information complexity. An\nexponential separation in the other direction was already known from the work\nof Kerenidis et. al. [SICOMP 44, pp. 1550-1572], hence our work implies that\nthese two complexity measures are incomparable. As classical information\ncomplexity is an upper bound on quantum information complexity, which in turn\nis equal to amortized quantum communication complexity, our work implies that a\ntight direct sum result for distributional quantum communication complexity\ncannot hold. The function we use to present such a separation is the Symmetric\nk-ary Pointer Jumping function introduced by Rao and Sinha [ECCC TR15-057],\nwhose classical communication complexity is exponentially larger than its\nclassical information complexity. In this paper, we show that the quantum\ncommunication complexity of this function is polynomially equivalent to its\nclassical communication complexity. The high-level idea behind our proof is\narguably the simplest so far for such an exponential separation between\ninformation and communication, driven by a sequence of round-elimination\narguments, allowing us to simplify further the approach of Rao and Sinha.\n  As another application of the techniques that we develop, we give a simple\nproof for an optimal trade-off between Alice's and Bob's communication while\ncomputing the related Greater-Than function on n bits: say Bob communicates at\nmost b bits, then Alice must send n/exp(O(b)) bits to Bob. This holds even when\nallowing pre-shared entanglement. We also present a classical protocol\nachieving this bound. \n\n"}
{"id": "1611.08959", "contents": "Title: Searching with Measurement Dependent Noise Abstract: Consider a target moving at a constant velocity on a unit-circumference\ncircle, starting at an arbitrary location. To acquire the target, any region of\nthe circle can be probed to obtain a noisy measurement of the target's\npresence, where the noise level increases with the size of the probed region.\nWe are interested in the expected time required to find the target to within\nsome given resolution and error probability. For a known velocity, we\ncharacterize the optimal tradeoff between time and resolution, and show that in\ncontrast to the well studied case of constant measurement noise, measurement\ndependent noise incurs a multiplicative gap in the targeting rate between\nadaptive and non-adaptive search strategies. Moreover, our adaptive strategy\nattains the optimal rate-reliability tradeoff. We further show that for optimal\nnon-adaptive search, accounting for an unknown velocity incurs a factor of at\nleast two in the targeting rate. \n\n"}
{"id": "1611.09152", "contents": "Title: Pilot Contamination is Not a Fundamental Asymptotic Limitation in\n  Massive MIMO Abstract: Massive MIMO (multiple-input multiple-output) provides great improvements in\nspectral efficiency over legacy cellular networks, by coherent combining of the\nsignals over a large antenna array and by spatial multiplexing of many users.\nSince its inception, the coherent interference caused by pilot contamination\nhas been believed to be an impairment that does not vanish, even with an\nunlimited number of antennas. In this work, we show that this belief is\nincorrect and an artifact from using simplistic channel models and suboptimal\nsignal processing schemes. We focus on the uplink and prove that with multicell\nMMSE combining, the spectral efficiency grows without bound as the number of\nantennas increases, even under pilot contamination, under a condition of linear\nindependence between the channel covariance matrices. This condition is\ngenerally satisfied, except in special cases that are hardly found in practice. \n\n"}
{"id": "1612.00130", "contents": "Title: Secure Polar Coding for the Two-Way Wiretap Channel Abstract: We consider the problem of polar coding for secure communications over the\ntwo-way wiretap channel, where two legitimate users communicate with each other\nsimultaneously while a passive eavesdropper overhears a combination of their\nexchanged signals. The legitimate users wish to design a cooperative jamming\ncode such that the interference between their codewords can jam the\neavesdropper. In this paper, we design a polar coded cooperative jamming scheme\nthat achieves the whole secrecy rate region of the general two-way wiretap\nchannel under the strong secrecy criterion. The chaining method is used to make\nproper alignment of polar indices. The randomness required to be shared between\ntwo legitimate users is treated as a limited resource and we show that its rate\ncan be made negligible by increasing the blocklength and the number of chained\nblocks. For the special case when the eavesdropper channel is degraded with\nrespect to the legitimate ones, a simplified scheme is proposed which can\nsimultaneously ensure reliability and weak secrecy within a single transmission\nblock. An example of the binary erasure channel case is given to demonstrate\nthe performance of our scheme. \n\n"}
{"id": "1612.01459", "contents": "Title: Approximate Support Recovery of Atomic Line Spectral Estimation: A Tale\n  of Resolution and Precision Abstract: This work investigates the parameter estimation performance of\nsuper-resolution line spectral estimation using atomic norm minimization. The\nfocus is on analyzing the algorithm's accuracy of inferring the frequencies and\ncomplex magnitudes from noisy observations. When the Signal-to-Noise Ratio is\nreasonably high and the true frequencies are separated by $O(\\frac{1}{n})$, the\natomic norm estimator is shown to localize the correct number of frequencies,\neach within a neighborhood of size $O(\\sqrt{{\\log n}/{n^3}} \\sigma)$ of one of\nthe true frequencies. Here $n$ is half the number of temporal samples and\n$\\sigma^2$ is the Gaussian noise variance. The analysis is based on a\nprimal-dual witness construction procedure. The obtained error bound matches\nthe Cram\\'er-Rao lower bound up to a logarithmic factor. The relationship\nbetween resolution (separation of frequencies) and precision or accuracy of the\nestimator is highlighted. Our analysis also reveals that the atomic norm\nminimization can be viewed as a convex way to solve a $\\ell_1$-norm\nregularized, nonlinear and nonconvex least-squares problem to global\noptimality. \n\n"}
{"id": "1612.05506", "contents": "Title: Cache-Enabled Heterogeneous Cellular Networks: Optimal Tier-Level\n  Content Placement Abstract: Caching popular contents at base stations (BSs) of a heterogeneous cellular\nnetwork (HCN) avoids frequent information passage from content providers to the\nnetwork edge, thereby reducing latency and alleviating traffic congestion in\nbackhaul links. In general, the optimal strategies for content placement in\nHCNs remain largely unknown and deriving them forms the theme of this paper. To\nthis end, we adopt the popular random HCN model where $K$ tiers of BSs are\nmodelled as independent Poisson point processes distributed in the plane with\ndifferent densities. Further, the random caching scheme is considered where\neach of a given set of $M$ files with corresponding popularity measures is\nplaced at each BS of a particular tier with a corresponding probability, called\nplacement probability. The probabilities are identical for all BSs in the same\ntier but vary over tiers, giving the name tier-level content placement. We\nconsider the network performance metric, hit probability, defined as the\nprobability that a file requested by the typical user is delivered successfully\nto the user. We maximize the hit probability over content placement\nprobabilities, which yields the optimal tier-level placement policies. For the\ncase of uniform received signal-to-interference thresholds for successful\ntransmissions for BSs in different tiers, the policy is in closed-form where\nthe placement probability for a particular file is proportional to the\nsquare-root of the corresponding popularity measure with an offset depending on\nBS caching capacities. For the general case of non-uniform SIR thresholds, the\noptimization problem is non-convex and a sub-optimal placement policy is\ndesigned by approximation, which has a similar structure as in the case of\nuniform SIR thresholds and shown by simulation to be close-to-optimal. \n\n"}
{"id": "1612.06835", "contents": "Title: Box constrained $\\ell_1$ optimization in random linear systems --\n  asymptotics Abstract: In this paper we consider box constrained adaptations of $\\ell_1$\noptimization heuristic when applied for solving random linear systems. These\nare typically employed when on top of being sparse the systems' solutions are\nalso known to be confined in a specific way to an interval on the real axis.\nTwo particular $\\ell_1$ adaptations (to which we will refer as the\n\\emph{binary} $\\ell_1$ and \\emph{box} $\\ell_1$) will be discussed in great\ndetail. Many of their properties will be addressed with a special emphasis on\nthe so-called phase transitions (PT) phenomena and the large deviation\nprinciples (LDP). We will fully characterize these through two different\nmathematical approaches, the first one that is purely probabilistic in nature\nand the second one that connects to high-dimensional geometry. Of particular\ninterest we will find that for many fairly hard mathematical problems a\ncollection of pretty elegant characterizations of their final solutions will\nturn out to exist. \n\n"}
{"id": "1612.07285", "contents": "Title: Poisson Cluster Process Based Analysis of HetNets with Correlated User\n  and Base Station Locations Abstract: This paper develops a new approach to the modeling and analysis of HetNets\nthat accurately incorporates coupling across the locations of users and base\nstations, which exists due to the deployment of small cell base stations (SBSs)\nat the places of high user density (termed user hotspots in this paper).\nModeling the locations of the geographical centers of user hotspots as a\nhomogeneous Poisson Point Process (PPP), we assume that the users and SBSs are\nclustered around each user hotspot center independently with two different\ndistributions. The macrocell base station (BS) locations are modeled by an\nindependent PPP. This model is consistent with the user and SBS configurations\nconsidered by 3GPP. Using this model, we study the performance of a typical\nuser in terms of coverage probability and throughput for two association\npolicies: i) Policy 1, under which a typical user is served by the open-access\nBS that provides maximum averaged received power, and ii) Policy 2, under which\nthe typical user is served by the small cell tier if the maximum averaged\nreceived power from the open-access SBSs is greater than a certain power\nthreshold; and macro tier otherwise. A key intermediate step in our analysis is\nthe derivation of distance distributions from a typical user to the open-access\nand closed-access interfering SBSs. Our analysis demonstrates that as the\nnumber of SBSs reusing the same resource block increases, coverage probability\ndecreases whereas throughput increases. Therefore, contrary to the usual\nassumption of orthogonal channelization, it is reasonable to assign the same\nresource block to multiple SBSs in a given cluster as long as the coverage\nprobability remains acceptable. This approach to HetNet modeling and analysis\nsignificantly generalizes the state-of-the-art approaches that are based on\nmodeling the locations of BSs and users by independent PPPs. \n\n"}
{"id": "1612.07289", "contents": "Title: Full-Duplex MIMO Small-Cell Networks with Interference Cancellation Abstract: Full-duplex (FD) technology is envisaged as a key component for future mobile\nbroadband networks due to its ability to boost the spectral efficiency. FD\nsystems can transmit and receive simultaneously on the same frequency at the\nexpense of residual self-interference (SI) and additional interference to the\nnetwork compared with half-duplex (HD) transmission. This paper analyzes the\nperformance of wireless networks with FD multi-antenna base stations (BSs) and\nHD user equipments (UEs) using stochastic geometry. Our analytical results\nquantify the success probability and the achievable spectral efficiency and\nindicate the amount of SI cancellation needed for beneficial FD operation. The\nadvantages of multi-antenna BSs/UEs are shown and the performance gains\nachieved by balancing desired signal power increase and interference\ncancellation are derived. The proposed framework aims at shedding light on the\nsystem-level gains of FD mode with respect to HD mode in terms of network\nthroughput, and provides design guidelines for the practical implementation of\nFD technology in large small-cell networks. \n\n"}
{"id": "1612.07436", "contents": "Title: Partial $\\ell_1$ optimization in random linear systems -- finite\n  dimensions Abstract: In this paper we provide a complementary set of results to those we present\nin our companion work \\cite{Stojnicl1HidParasymldp} regarding the behavior of\nthe so-called partial $\\ell_1$ (a variant of the standard $\\ell_1$ heuristic\noften employed for solving under-determined systems of linear equations). As is\nwell known through our earlier works\n\\cite{StojnicICASSP10knownsupp,StojnicTowBettCompSens13}, the partial $\\ell_1$\nalso exhibits the phase-transition (PT) phenomenon, discovered and well\nunderstood in the context of the standard $\\ell_1$ through Donoho's and our own\nworks \\cite{DonohoPol,DonohoUnsigned,StojnicCSetam09,StojnicUpper10}.\n\\cite{Stojnicl1HidParasymldp} goes much further though and, in addition to the\ndetermination of the partial $\\ell_1$'s phase-transition curves (PT curves)\n(which had already been done in\n\\cite{StojnicICASSP10knownsupp,StojnicTowBettCompSens13}), provides a\nsubstantially deeper understanding of the PT phenomena through a study of the\nunderlying large deviations principles (LDPs). As the PT and LDP phenomena are\nby their definitions related to large dimensional settings, both sets of our\nworks, \\cite{StojnicICASSP10knownsupp,StojnicTowBettCompSens13} and\n\\cite{Stojnicl1HidParasymldp}, consider what is typically called the asymptotic\nregime. In this paper we move things in a different direction and consider\nfinite dimensional scenarios. Basically, we provide explicit performance\ncharacterizations for any given collection of systems/parameters dimensions. We\ndo so for two different variants of the partial $\\ell_1$, one that we call\nexactly the partial $\\ell_1$ and another one, possibly a bit more practical,\nthat we call the hidden partial $\\ell_1$. \n\n"}
{"id": "1612.08506", "contents": "Title: Generic and lifted probabilistic comparisons -- max replaces minmax Abstract: In this paper we introduce a collection of powerful statistical comparison\nresults. We first present the results that we obtained while developing a\ngeneral comparison concept. After that we introduce a separate lifting\nprocedure that is a comparison concept on its own. We then show how in certain\nscenarios the lifting procedure basically represents a substantial upgrade over\nthe general strategy. We complement the introduced results with a fairly large\ncollection of numerical experiments that are in an overwhelming agreement with\nwhat the theory predicts. We also show how many well known comparison results\n(e.g. Slepian's max and Gordon's minmax principle) can be obtained as special\ncases. Moreover, it turns out that the minmax principle can be viewed as a\nsingle max principle as well. The range of applications is enormous. It starts\nwith revisiting many of the results we created in recent years in various\nmathematical fields and recognizing that they are fully self-contained as their\nstarting blocks are specialized variants of the concepts introduced here.\nFurther upgrades relate to core comparison extensions on the one side and more\npractically oriented modifications on the other. Those that we deem the most\nimportant we discuss in several separate companion papers to ensure preserving\nthe introductory elegance and simplicity of what is presented here. \n\n"}
{"id": "1612.08516", "contents": "Title: Fully bilinear generic and lifted random processes comparisons Abstract: In our companion paper \\cite{Stojnicgscomp16} we introduce a collection of\nfairly powerful statistical comparison results. They relate to a general\ncomparison concept and its an upgrade that we call lifting procedure. Here we\nprovide a different generic principle (which we call fully bilinear) that in\ncertain cases turns out to be stronger than the corresponding one from\n\\cite{Stojnicgscomp16}. Moreover, we also show how the principle that we\nintroduce here can also be pushed through the lifting machinery of\n\\cite{Stojnicgscomp16}. Finally, as was the case in \\cite{Stojnicgscomp16},\nhere we also show how the well known Slepian's max and Gordon's minmax\ncomparison principles can be obtained as special cases of the mechanisms that\nwe present here. We also create their lifted upgrades which happen to be\nstronger than the corresponding ones in \\cite{Stojnicgscomp16}. A fairly large\ncollection of results obtained through numerical experiments is also provided.\nIt is observed that these results are in an excellent agreement with what the\ntheory predicts. \n\n"}
{"id": "1612.08823", "contents": "Title: Several Classes of Permutation Trinomials From Niho Exponents Abstract: Motivated by recent results on the constructions of permutation polynomials\nwith few terms over the finite field $\\mathbb{F}_{2^n}$, where $n$ is a\npositive even integer, we focus on the construction of permutation trinomials\nover $\\mathbb{F}_{2^n}$ from Niho exponents. As a consequence, several new\nclasses of permutation trinomials over $\\mathbb{F}_{2^n}$ are constructed from\nNiho exponents based on some subtle manipulation of solving equations with low\ndegrees over finite fields. \n\n"}
{"id": "1701.01007", "contents": "Title: Single Letter Expression of Capacity for a Class of Channels with Memory Abstract: We study finite alphabet channels with Unit Memory on the previous Channel\nOutputs called UMCO channels. We identify necessary and sufficient conditions,\nto test whether the capacity achieving channel input distributions with\nfeedback are time-invariant, and whether feedback capacity is characterized by\nsingle letter, expressions, similar to that of memoryless channels. The method\nis based on showing that a certain dynamic programming equation, which in\ngeneral, is a nested optimization problem over the sequence of channel input\ndistributions, reduces to a non-nested optimization problem. Moreover, for UMCO\nchannels, we give a simple expression for the ML error exponent, and we\nidentify sufficient conditions to test whether feedback does not increase\ncapacity. We derive similar results, when transmission cost constraints are\nimposed. We apply the results to a special class of the UMCO channels, the\nBinary State Symmetric Channel (BSSC) with and without transmission cost\nconstraints, to show that the optimization problem of feedback capacity is\nnon-nested, the capacity achieving channel input distribution and the\ncorresponding channel output transition probability distribution are\ntime-invariant, and feedback capacity is characterized by a single letter\nformulae, precisely as Shannon's single letter characterization of capacity of\nmemoryless channels. Then we derive closed form expressions for the capacity\nachieving channel input distribution and feedback capacity. We use the closed\nform expressions to evaluate an error exponent for ML decoding. \n\n"}
{"id": "1701.01212", "contents": "Title: Downlink Coverage Analysis for a Finite 3D Wireless Network of Unmanned\n  Aerial Vehicles Abstract: In this paper, we consider a finite network of unmanned aerial vehicles\n(UAVs) serving a given region. Modeling this network as a uniform binomial\npoint process (BPP), we derive the downlink coverage probability of a reference\nreceiver located at an arbitrary position on the ground assuming Nakagami-$m$\nfading for all wireless links. The reference receiver is assumed to connect to\nits closest transmitting node as is usually the case in cellular systems. After\nderiving the distribution of distances from the reference receiver to the\nserving and interfering nodes, we derive an exact expression for downlink\ncoverage probability in terms of the derivative of Laplace transform of\ninterference power distribution. In the downlink of this system, it is not\nunusual to encounter scenarios in which the line-of-sight (LOS) component is\nsignificantly stronger than the reflected multipath components. To emulate such\nscenarios, we also derive the coverage probability in the absence of fading\nfrom the results of Nakagami-$m$ fading by taking the limit $m \\to \\infty$.\nUsing asymptotic expansion of incomplete gamma function, we concretely show\nthat this limit reduces to a redundant condition. Consequently, we derive an\naccurate coverage probability approximation for this case using dominant\ninterferer-based approach in which the effect of dominant interferer is exactly\ncaptured and the residual interference from other interferers is carefully\napproximated. We then derive the bounds of the approximate coverage probability\nusing Berry-Esseen theorem. Our analyses reveal several useful trends in\ncoverage probability as a function of height of the transmitting nodes and the\nlocation of reference receiver on the ground. \n\n"}
{"id": "1701.01212", "contents": "Title: Downlink Coverage Analysis for a Finite 3D Wireless Network of Unmanned\n  Aerial Vehicles Abstract: In this paper, we consider a finite network of unmanned aerial vehicles\n(UAVs) serving a given region. Modeling this network as a uniform binomial\npoint process (BPP), we derive the downlink coverage probability of a reference\nreceiver located at an arbitrary position on the ground assuming Nakagami-$m$\nfading for all wireless links. The reference receiver is assumed to connect to\nits closest transmitting node as is usually the case in cellular systems. After\nderiving the distribution of distances from the reference receiver to the\nserving and interfering nodes, we derive an exact expression for downlink\ncoverage probability in terms of the derivative of Laplace transform of\ninterference power distribution. In the downlink of this system, it is not\nunusual to encounter scenarios in which the line-of-sight (LOS) component is\nsignificantly stronger than the reflected multipath components. To emulate such\nscenarios, we also derive the coverage probability in the absence of fading\nfrom the results of Nakagami-$m$ fading by taking the limit $m \\to \\infty$.\nUsing asymptotic expansion of incomplete gamma function, we concretely show\nthat this limit reduces to a redundant condition. Consequently, we derive an\naccurate coverage probability approximation for this case using dominant\ninterferer-based approach in which the effect of dominant interferer is exactly\ncaptured and the residual interference from other interferers is carefully\napproximated. We then derive the bounds of the approximate coverage probability\nusing Berry-Esseen theorem. Our analyses reveal several useful trends in\ncoverage probability as a function of height of the transmitting nodes and the\nlocation of reference receiver on the ground. \n\n"}
{"id": "1701.01974", "contents": "Title: Arimoto-R\\'enyi Conditional Entropy and Bayesian $M$-ary Hypothesis\n  Testing Abstract: This paper gives upper and lower bounds on the minimum error probability of\nBayesian $M$-ary hypothesis testing in terms of the Arimoto-R\\'enyi conditional\nentropy of an arbitrary order $\\alpha$. The improved tightness of these bounds\nover their specialized versions with the Shannon conditional entropy\n($\\alpha=1$) is demonstrated. In particular, in the case where $M$ is finite,\nwe show how to generalize Fano's inequality under both the conventional and\nlist-decision settings. As a counterpart to the generalized Fano's inequality,\nallowing $M$ to be infinite, a lower bound on the Arimoto-R\\'enyi conditional\nentropy is derived as a function of the minimum error probability. Explicit\nupper and lower bounds on the minimum error probability are obtained as a\nfunction of the Arimoto-R\\'enyi conditional entropy for both positive and\nnegative $\\alpha$. Furthermore, we give upper bounds on the minimum error\nprobability as functions of the R\\'enyi divergence. In the setup of discrete\nmemoryless channels, we analyze the exponentially vanishing decay of the\nArimoto-R\\'enyi conditional entropy of the transmitted codeword given the\nchannel output when averaged over a random coding ensemble. \n\n"}
{"id": "1701.03759", "contents": "Title: The Velocity of the Propagating Wave for General Coupled Scalar Systems Abstract: We consider spatially coupled systems governed by a set of scalar density\nevolution equations. Such equations track the behavior of message-passing\nalgorithms used, for example, in coding, sparse sensing, or\nconstraint-satisfaction problems. Assuming that the \"profile\" describing the\naverage state of the algorithm exhibits a solitonic wave-like behavior after\ninitial transient iterations, we derive a formula for the propagation velocity\nof the wave. We illustrate the formula with two applications, namely\nGeneralized LDPC codes and compressive sensing. \n\n"}
{"id": "1701.05943", "contents": "Title: Structure of optimal strategies for remote estimation over\n  Gilbert-Elliott channel with feedback Abstract: We investigate remote estimation over a Gilbert-Elliot channel with feedback.\nWe assume that the channel state is observed by the receiver and fed back to\nthe transmitter with one unit delay. In addition, the transmitter gets ACK/NACK\nfeedback for successful/unsuccessful transmission. Using ideas from team\ntheory, we establish the structure of optimal transmission and estimation\nstrategies and identify a dynamic program to determine optimal strategies with\nthat structure. We then consider first-order autoregressive sources where the\nnoise process has unimodal and symmetric distribution. Using ideas from\nmajorization theory, we show that the optimal transmission strategy has a\nthreshold structure and the optimal estimation strategy is Kalman-like. \n\n"}
{"id": "1701.06303", "contents": "Title: Delivery Latency Trade-Offs of Heterogeneous Contents in Fog Radio\n  Access Networks Abstract: A Fog Radio Access Network (F-RAN) is a cellular wireless system that enables\ncontent delivery via the caching of popular content at edge nodes (ENs) and\ncloud processing. The existing information-theoretic analyses of F-RAN systems,\nand special cases thereof, make the assumption that all requests should be\nguaranteed the same delivery latency, which results in identical latency for\nall files in the content library. In practice, however, contents may have\nheterogeneous timeliness requirements depending on the applications that\noperate on them. Given per-EN cache capacity constraint, there exists a\nfundamental trade-off among the delivery latencies of different users'\nrequests, since contents that are allocated more cache space generally enjoy\nlower delivery latencies. For the case with two ENs and two users, the optimal\nlatency trade-off is characterized in the high-SNR regime in terms of the\nNormalized Delivery Time (NDT) metric. The main results are illustrated by\nnumerical examples. \n\n"}
{"id": "1701.06458", "contents": "Title: Low-Complexity Puncturing and Shortening of Polar Codes Abstract: In this work, we address the low-complexity construction of shortened and\npunctured polar codes from a unified view. While several independent puncturing\nand shortening designs were attempted in the literature, our goal is a unique,\nlow-complexity construction encompassing both techniques in order to achieve\nany code length and rate. We observe that our solution significantly reduces\nthe construction complexity as compared to state-of-the-art solutions while\nproviding a block error rate performance comparable to constructions that are\nhighly optimized for specific lengths and rates. This makes the constructed\npolar codes highly suitable for practical application in future communication\nsystems requiring a large set of polar codes with different lengths and rates. \n\n"}
{"id": "1701.07274", "contents": "Title: Deep Reinforcement Learning: An Overview Abstract: We give an overview of recent exciting achievements of deep reinforcement\nlearning (RL). We discuss six core elements, six important mechanisms, and\ntwelve applications. We start with background of machine learning, deep\nlearning and reinforcement learning. Next we discuss core RL elements,\nincluding value function, in particular, Deep Q-Network (DQN), policy, reward,\nmodel, planning, and exploration. After that, we discuss important mechanisms\nfor RL, including attention and memory, unsupervised learning, transfer\nlearning, multi-agent RL, hierarchical RL, and learning to learn. Then we\ndiscuss various applications of RL, including games, in particular, AlphaGo,\nrobotics, natural language processing, including dialogue systems, machine\ntranslation, and text generation, computer vision, neural architecture design,\nbusiness management, finance, healthcare, Industry 4.0, smart grid, intelligent\ntransportation systems, and computer systems. We mention topics not reviewed\nyet, and list a collection of RL resources. After presenting a brief summary,\nwe close with discussions.\n  Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant\nupdate. \n\n"}
{"id": "1701.07579", "contents": "Title: Explicit Constructions and Bounds for Batch Codes with Restricted Size\n  of Reconstruction Sets Abstract: Linear batch codes and codes for private information retrieval (PIR) with a\nquery size $t$ and a restricted size $r$ of the reconstruction sets are\nstudied. New bounds on the parameters of such codes are derived for small\nvalues of $t$ or of $r$ by providing corresponding constructions. By building\non the ideas of Cadambe and Mazumdar, a new bound in a recursive form is\nderived for batch codes and PIR codes. \n\n"}
{"id": "1701.07730", "contents": "Title: Alpha Fair Coded Caching Abstract: The performance of existing \\emph{coded caching} schemes is sensitive to\nworst channel quality, a problem which is exacerbated when communicating over\nfading channels. In this paper we address this limitation in the following\nmanner: \\emph{in short-term}, we allow transmissions to subsets of users with\ngood channel quality, avoiding users with fades, while \\emph{in long-term} we\nensure fairness across the different users.Our online scheme combines (i) joint\nscheduling and power control for the broadcast channel with fading, and (ii)\ncongestion control for ensuring the optimal long-term average performance. We\nrestrict the caching operations to the decentralized scheme of\n\\cite{maddah2013decentralized}, and subject to this restriction we prove that\nour scheme has near-optimal overall performance with respect to the convex\nalpha-fairness coded caching optimization. By tuning the coefficient alpha, the\noperator can differentiate user performance with respect to video delivery\nrates achievable by coded caching.\n  We demonstrate via simulations our scheme's superiority over legacy coded\ncaching and unicast opportunistic scheduling, which are identified as special\ncases of our general framework. \n\n"}
{"id": "1701.07875", "contents": "Title: Wasserstein GAN Abstract: We introduce a new algorithm named WGAN, an alternative to traditional GAN\ntraining. In this new model, we show that we can improve the stability of\nlearning, get rid of problems like mode collapse, and provide meaningful\nlearning curves useful for debugging and hyperparameter searches. Furthermore,\nwe show that the corresponding optimization problem is sound, and provide\nextensive theoretical work highlighting the deep connections to other distances\nbetween distributions. \n\n"}
{"id": "1701.07964", "contents": "Title: On the Performance of Practical Ultra-Dense Networks: The Major and\n  Minor Factors Abstract: In this paper, we conduct performance evaluation for Ultra-Dense Networks\n(UDNs), and identify which modelling factors play major roles and minor roles.\nFrom our study, we draw the following conclusions. First, there are 3\nfactors/models that have a major impact on the performance of UDNs, and they\nshould be considered when performing theoretical analyses: i) a multi-piece\npath loss model with line-of-sight (LoS) and non-lineof- sight (NLoS)\ntransmissions; ii) a non-zero antenna height difference between base stations\n(BSs) and user equipments (UEs); iii) a finite BS/UE density. Second, there are\n4 factors/models that have a minor impact on the performance of UDNs, i.e.,\nchanging the results quantitatively but not qualitatively, and thus their\nincorporation into theoretical analyses is less urgent: i) a general multi-path\nfading model based on Rician fading; ii) a correlated shadow fading model; iii)\na BS density dependent transmission power; iv) a deterministic BS/user density.\nFinally, there are 5 factors/models for future study: i) a BS vertical antenna\npattern; ii) multi-antenna and/or multi-BS joint transmissions; iii) a\nproportional fair BS scheduler; iv) a non-uniform distribution of BSs; v) a\ndynamic time division duplex (TDD) or full duplex (FD) network. Our conclusions\ncan guide researchers to downselect the assumptions in their theoretical\nanalyses, so as to avoid unnecessarily complicated results, while still\ncapturing the fundamentals of UDNs in a meaningful way. \n\n"}
{"id": "1701.07981", "contents": "Title: Design Aspects of Multi-Soliton Pulses for Optical Fiber Transmission Abstract: We explain how to optimize the nonlinear spectrum of multi-soliton pulses by\nconsidering the practical constraints of transmitter, receiver, and\nlumped-amplified link. The optimization is applied for the experimental\ntransmission of 2ns soliton pulses with independent on-off keying of 10\neigenvalues over 2000 km of NZ-DSF fiber spans. \n\n"}
{"id": "1702.00160", "contents": "Title: Short-Message Communication and FIR System Identification using Huffman\n  Sequences Abstract: Providing short-message communication and simultaneous channel estimation for\nsporadic and fast fading scenarios is a challenge for future wireless networks.\nIn this work we propose a novel blind communication and deconvolution scheme by\nusing Huffman sequences, which allows to solve three important tasks in one\nstep: (i) determination of the transmit power (ii) identification of the\ndiscrete-time FIR channel by providing a maximum delay of less than $L/2$ and\n(iii) simultaneously communicating $L-1$ bits of information. Our signal\nreconstruction uses a recent semi-definite program that can recover two unknown\nsignals from their auto-correlations and cross-correlations. This convex\nalgorithm is stable and operates fully deterministic without any further\nchannel assumptions. \n\n"}
{"id": "1702.00606", "contents": "Title: Joint Offloading and Computing Optimization in Wireless Powered\n  Mobile-Edge Computing Systems Abstract: Mobile-edge computing (MEC) and wireless power transfer (WPT) have been\nrecognized as promising techniques in the Internet of Things (IoT) era to\nprovide massive low-power wireless devices with enhanced computation capability\nand sustainable energy supply. In this paper, we propose a unified MEC-WPT\ndesign by considering a wireless powered multiuser MEC system, where a\nmulti-antenna access point (AP) (integrated with an MEC server) broadcasts\nwireless power to charge multiple users and each user node relies on the\nharvested energy to execute computation tasks. With MEC, these users can\nexecute their respective tasks locally by themselves or offload all or part of\nthem to the AP based on a time division multiple access (TDMA) protocol.\nBuilding on the proposed model, we develop an innovative framework to improve\nthe MEC performance, by jointly optimizing the energy transmit beamformer at\nthe AP, the central processing unit (CPU) frequencies and the numbers of\noffloaded bits at the users, as well as the time allocation among users. Under\nthis framework, we address a practical scenario where latency-limited\ncomputation is required. In this case, we develop an optimal resource\nallocation scheme that minimizes the AP's total energy consumption subject to\nthe users' individual computation latency constraints. Leveraging the\nstate-of-the-art optimization techniques, we derive the optimal solution in a\nsemi-closed form. Numerical results demonstrate the merits of the proposed\ndesign over alternative benchmark schemes. \n\n"}
{"id": "1702.00832", "contents": "Title: An Introduction to Deep Learning for the Physical Layer Abstract: We present and discuss several novel applications of deep learning for the\nphysical layer. By interpreting a communications system as an autoencoder, we\ndevelop a fundamental new way to think about communications system design as an\nend-to-end reconstruction task that seeks to jointly optimize transmitter and\nreceiver components in a single process. We show how this idea can be extended\nto networks of multiple transmitters and receivers and present the concept of\nradio transformer networks as a means to incorporate expert domain knowledge in\nthe machine learning model. Lastly, we demonstrate the application of\nconvolutional neural networks on raw IQ samples for modulation classification\nwhich achieves competitive accuracy with respect to traditional schemes relying\non expert features. The paper is concluded with a discussion of open challenges\nand areas for future investigation. \n\n"}
{"id": "1702.01864", "contents": "Title: The Meta Distribution of the SIR for Cellular Networks with Power\n  Control Abstract: The meta distribution of the signal-to-interference ratio (SIR) provides\nfine-grained information about the performance of individual links in a\nwireless network. This paper focuses on the analysis of the meta distribution\nof the SIR for both the cellular network uplink and downlink with fractional\npower control. For the uplink scenario, an approximation of the interfering\nuser point process with a non-homogeneous Poisson point process is used. The\nmoments of the meta distribution for both scenarios are calculated. Some\nbounds, the analytical expression, the mean local delay, and the beta\napproximation of the meta distribution are provided. The results give\ninteresting insights into the effect of the power control in both the uplink\nand downlink. Detailed simulations show that the approximations made in the\nanalysis are well justified. \n\n"}
{"id": "1702.03750", "contents": "Title: Globally convergent Jacobi-type algorithms for simultaneous orthogonal\n  symmetric tensor diagonalization Abstract: In this paper, we consider a family of Jacobi-type algorithms for\nsimultaneous orthogonal diagonalization problem of symmetric tensors. For the\nJacobi-based algorithm of [SIAM J. Matrix Anal. Appl., 2(34):651--672, 2013],\nwe prove its global convergence for simultaneous orthogonal diagonalization of\nsymmetric matrices and 3rd-order tensors. We also propose a new Jacobi-based\nalgorithm in the general setting and prove its global convergence for\nsufficiently smooth functions. \n\n"}
{"id": "1702.05064", "contents": "Title: Cache-Aided Full-Duplex Small Cells Abstract: Caching popular contents at the edge of the network can positively impact the\nperformance and future sustainability of wireless networks in several ways,\ne.g., end-to-end access delay reduction and peak rate increase. In this paper,\nwe aim at showing that non-negligible performance enhancements can be observed\nin terms of network interference footprint as well. To this end, we consider a\nfull-duplex small-cell network consisting of non-cooperative cache-aided base\nstations, which communicate simultaneously with both downlink users and\nwireless backhaul nodes. We propose a novel caching model seeking to mimic a\ngeographical policy based on local files popularity and calculate the\ncorresponding cache hit probability. Subsequently we study the performance of\nthe considered network in terms of throughput gain with respect to its\ncache-free half-duplex counterpart. Numerical results corroborate our\ntheoretical findings and highlight remarkable performance gains when moving\nfrom cache-free to cache-aided full-duplex small-cell networks. \n\n"}
{"id": "1702.05679", "contents": "Title: Scalable Spectrum Allocation for Large Networks Based on Sparse\n  Optimization Abstract: Joint allocation of spectrum and user association is considered for a large\ncellular network. The objective is to optimize a network utility function such\nas average delay given traffic statistics collected over a slow timescale. A\nkey challenge is scalability: given $n$ Access Points (APs), there are $O(2^n)$\nways in which the APs can share the spectrum. The number of variables is\nreduced from $O(2^n)$ to $O(nk)$, where $k$ is the number of users, by\noptimizing over local overlapping neighborhoods, defined by interference\nconditions, and by exploiting the existence of sparse solutions in which the\nspectrum is divided into $k+1$ segments. We reformulate the problem by\noptimizing the assignment of subsets of active APs to those segments. An\n$\\ell_0$ constraint enforces a one-to-one mapping of subsets to spectrum, and\nan iterative (reweighted $\\ell_1$) algorithm is used to find an approximate\nsolution. Numerical results for a network with 100 APs serving several hundred\nusers show the proposed method achieves a substantial increase in total\nthroughput relative to benchmark schemes. \n\n"}
{"id": "1702.06226", "contents": "Title: Noise Models in the Nonlinear Spectral Domain for Optical Fibre\n  Communications Abstract: Existing works on building a soliton transmission system only encode\ninformation using the imaginary part of the eigenvalue, which fails to make\nfull use of the signal degree-of-freedoms. Motivated by this observation, we\nmake the first step of encoding information using (discrete) spectral\namplitudes by proposing analytical noise models for the spectral amplitudes of\n$N$-solitons ($N\\geq 1$). To our best knowledge, this is the first work in\nbuilding an analytical noise model for spectral amplitudes, which leads to many\ninteresting information theoretic questions, such as channel capacity analysis,\nand has a potential of increasing the transmission rate. The noise statistics\nof the spectral amplitude of a soliton are also obtained without the Gaussian\napproximation. \n\n"}
{"id": "1702.06772", "contents": "Title: Efficient CSMA using Regional Free Energy Approximations Abstract: CSMA (Carrier Sense Multiple Access) algorithms based on Gibbs sampling can\nachieve throughput optimality if certain parameters called the fugacities are\nappropriately chosen. However, the problem of computing these fugacities is\nNP-hard. In this work, we derive estimates of the fugacities by using a\nframework called the regional free energy approximations. In particular, we\nderive explicit expressions for approximate fugacities corresponding to any\nfeasible service rate vector. We further prove that our approximate fugacities\nare exact for the class of chordal graphs. A distinguishing feature of our work\nis that the regional approximations that we propose are tailored to conflict\ngraphs with small cycles, which is a typical characteristic of wireless\nnetworks. Numerical results indicate that the fugacities obtained by the\nproposed method are quite accurate and significantly outperform the existing\nBethe approximation based techniques. \n\n"}
{"id": "1702.06878", "contents": "Title: $M$-QAM Precoder Design for MIMO Directional Modulation Transceivers Abstract: Spectrally efficient multi-antenna wireless communication systems are a key\nchallenge as service demands continue to increase. At the same time, powering\nup radio access networks is facing environmental and regulation limitations. In\norder to achieve more power efficiency, we design a directional modulation\nprecoder by considering an $M$-QAM constellation, particularly with\n$M=4,8,16,32$. First, extended detection regions are defined for desired\nconstellations using analytical geometry. Then, constellation points are placed\nin the optimal positions of these regions while the minimum Euclidean distance\nto adjacent constellation points and detection region boundaries is kept as in\nthe conventional $M$-QAM modulation. For further power efficiency and symbol\nerror rate similar to that of fixed design in high SNR, relaxed detection\nregions are modeled for inner points of $M=16,32$ constellations. The modeled\nextended and relaxed detection regions as well as the modulation\ncharacteristics are utilized to formulate symbol-level precoder design problems\nfor directional modulation to minimize the transmission power while preserving\nthe minimum required SNR at the destination. In addition, the extended and\nrelaxed detection regions are used for precoder design to minimize the output\nof each power amplifier. We transform the design problems into convex ones and\ndevise an interior point path-following iterative algorithm to solve the\nmentioned problems and provide details on finding the initial values of the\nparameters and the starting point. Results show that compared to the benchmark\nschemes, the proposed method performs better in terms of power and peak power\nreduction as well as symbol error rate reduction for a wide range of SNRs. \n\n"}
{"id": "1702.07031", "contents": "Title: Proactive Resource Management for LTE in Unlicensed Spectrum: A Deep\n  Learning Perspective Abstract: LTE in unlicensed spectrum using licensed assisted access LTE (LTE-LAA) is a\npromising approach to overcome the wireless spectrum scarcity. However, to reap\nthe benefits of LTE-LAA, a fair coexistence mechanism with other incumbent WiFi\ndeployments is required. In this paper, a novel deep learning approach is\nproposed for modeling the resource allocation problem of LTE-LAA small base\nstations (SBSs). The proposed approach enables multiple SBSs to proactively\nperform dynamic channel selection, carrier aggregation, and fractional spectrum\naccess while guaranteeing fairness with existing WiFi networks and other\nLTE-LAA operators. Adopting a proactive coexistence mechanism enables future\ndelay-tolerant LTE-LAA data demands to be served within a given prediction\nwindow ahead of their actual arrival time thus avoiding the underutilization of\nthe unlicensed spectrum during off-peak hours while maximizing the total served\nLTE-LAA traffic load. To this end, a noncooperative game model is formulated in\nwhich SBSs are modeled as Homo Egualis agents that aim at predicting a sequence\nof future actions and thus achieving long-term equal weighted fairness with\nWLAN and other LTE-LAA operators over a given time horizon. The proposed deep\nlearning algorithm is then shown to reach a mixed-strategy Nash equilibrium\n(NE), when it converges. Simulation results using real data traces show that\nthe proposed scheme can yield up to 28% and 11% gains over a conventional\nreactive approach and a proportional fair coexistence mechanism, respectively.\nThe results also show that the proposed framework prevents WiFi performance\ndegradation for a densely deployed LTE-LAA network. \n\n"}
{"id": "1702.07265", "contents": "Title: A Novel Index Coding Scheme and its Application to Coded Caching Abstract: This paper proposes a novel achievable scheme for the index problem and\napplies it to the caching problem. Index coding and caching are noiseless\nbroadcast channel problems where receivers have message side information.In the\nindex coding problem the side information sets are fixed, while in the caching\nproblem the side information sets correspond the cache contents, which are\nunder the control of the system designer. The proposed index coding scheme,\nbased on distributed source coding and non-unique decoding,is shown to strictly\nenlarge the rate region achievable by composite coding.The novel index coding\nscheme applied to the caching problem is then shown to match an outer bound\n(previously proposed by the authors and also based on known results for the\nindex coding problem) under the assumption of uncoded cache\nplacement/prefetching. \n\n"}
{"id": "1702.08735", "contents": "Title: On relaxed stochastic optimal control for stochastic differential\n  equations driven by G-Brownian motion Abstract: In the G-framework, we establish existence of an optimal stochastic relaxed\ncontrol for stochastic differential equations driven by a G-Brownian motion. \n\n"}
{"id": "1703.00810", "contents": "Title: Opening the Black Box of Deep Neural Networks via Information Abstract: Despite their great success, there is still no comprehensive theoretical\nunderstanding of learning with Deep Neural Networks (DNNs) or their inner\norganization. Previous work proposed to analyze DNNs in the \\textit{Information\nPlane}; i.e., the plane of the Mutual Information values that each layer\npreserves on the input and output variables. They suggested that the goal of\nthe network is to optimize the Information Bottleneck (IB) tradeoff between\ncompression and prediction, successively, for each layer.\n  In this work we follow up on this idea and demonstrate the effectiveness of\nthe Information-Plane visualization of DNNs. Our main results are: (i) most of\nthe training epochs in standard DL are spent on {\\emph compression} of the\ninput to efficient representation and not on fitting the training labels. (ii)\nThe representation compression phase begins when the training errors becomes\nsmall and the Stochastic Gradient Decent (SGD) epochs change from a fast drift\nto smaller training error into a stochastic relaxation, or random diffusion,\nconstrained by the training error value. (iii) The converged layers lie on or\nvery close to the Information Bottleneck (IB) theoretical bound, and the maps\nfrom the input to any hidden layer and from this hidden layer to the output\nsatisfy the IB self-consistent equations. This generalization through noise\nmechanism is unique to Deep Neural Networks and absent in one layer networks.\n(iv) The training time is dramatically reduced when adding more hidden layers.\nThus the main advantage of the hidden layers is computational. This can be\nexplained by the reduced relaxation time, as this it scales super-linearly\n(exponentially for simple diffusion) with the information compression from the\nprevious layer. \n\n"}
{"id": "1703.01279", "contents": "Title: Downlink Cellular Network Analysis with LOS/NLOS Propagation and\n  Elevated Base Stations Abstract: In this paper, we investigate the downlink performance of dense cellular\nnetworks with elevated base stations (BSs) using a channel model that\nincorporates line-of-sight (LOS)/non-line-of-sight (NLOS) propagation in both\nsmall-scale and large-scale fading. Modeling LOS fading with Nakagami-$m$\nfading, we provide a unified framework based on stochastic geometry that\nencompasses both closest and strongest BS association. Our study is\nparticularized to two distance-dependent LOS/NLOS models of practical interest.\nConsidering the effect of LOS propagation alone, we derive closed-form\nexpressions for the coverage probability with Nakagami-$m$ fading, showing that\nthe performance for strongest BS association is the same as in the case of\nRayleigh fading, whereas for closest BS association it monotonically increases\nwith the shape parameter $m$. Then, focusing on the effect of elevated BSs, we\nshow that network densification eventually leads to near-universal outage even\nfor moderately low BS densities: in particular, the maximum area spectral\nefficiency is proportional to the inverse of the squared BS height. \n\n"}
{"id": "1703.04209", "contents": "Title: Virtual Reality over Wireless Networks: Quality-of-Service Model and\n  Learning-Based Resource Management Abstract: In this paper, the problem of resource management is studied for a network of\nwireless virtual reality (VR) users communicating over small cell networks\n(SCNs). In order to capture the VR users' quality-of-service (QoS) in SCNs, a\nnovel VR model, based on multi-attribute utility theory, is proposed. This\nmodel jointly accounts for VR metrics such as tracking accuracy, processing\ndelay, and transmission delay. In this model, the small base stations (SBSs)\nact as the VR control centers that collect the tracking information from VR\nusers over the cellular uplink. Once this information is collected, the SBSs\nwill then send the three dimensional images and accompanying surround stereo\naudio to the VR users over the downlink. Therefore, the resource allocation\nproblem in VR wireless networks must jointly consider both the uplink and\ndownlink. This problem is then formulated as a noncooperative game and a\ndistributed algorithm based on the machine learning framework of echo state\nnetworks (ESNs) is proposed to find the solution of this game. The use of the\nproposed ESN algorithm enables the SBSs to predict the VR QoS of each SBS and\nguarantees the convergence to a mixed-strategy Nash equilibrium. The analytical\nresult shows that each user's VR QoS jointly depends on both VR tracking\naccuracy and wireless resource allocation. Simulation results show that the\nproposed algorithm yields significant gains, in terms of total utility value of\nVR QoS, that reach up to 22.2% and 37.5%, respectively, compared to Q-learning\nand a baseline proportional fair algorithm. The results also show that the\nproposed algorithm has a faster convergence time than Q-learning and can\nguarantee low delays for VR services. \n\n"}
{"id": "1703.04346", "contents": "Title: Linear codes over Fq which are equivalent to LCD codes Abstract: Linear codes with complementary duals (abbreviated LCD) are linear codes\nwhose intersection with their dual are trivial. When they are binary, they play\nan important role in armoring implementations against side-channel attacks and\nfault injection attacks. Non-binary LCD codes in characteristic 2 can be\ntransformed into binary LCD codes by expansion. In this paper, we introduce a\ngeneral construction of LCD codes from any linear codes. Further, we show that\nany linear code over $\\mathbb F_{q} (q>3)$ is equivalent to an Euclidean LCD\ncode and any linear code over $\\mathbb F_{q^2} (q>2)$ is equivalent to a\nHermitian LCD code. Consequently an $[n,k,d]$-linear Euclidean LCD code over\n$\\mathbb F_q$ with $q>3$ exists if there is an $[n,k,d]$-linear code over\n$\\mathbb F_q$ and an $[n,k,d]$-linear Hermitian LCD code over $\\mathbb F_{q^2}$\nwith $q>2$ exists if there is an $[n,k,d]$-linear code over $\\mathbb F_{q^2}$.\nHence, when $q>3$ (resp.$q>2$) $q$-ary Euclidean (resp. $q^2$-ary Hermitian)\nLCD codes possess the same asymptotical bound as $q$-ary linear codes (resp.\n$q^2$-ary linear codes). Finally, we present an approach of constructing LCD\ncodes by extending linear codes. \n\n"}
{"id": "1703.04930", "contents": "Title: On the Support Recovery of Jointly Sparse Gaussian Sources using Sparse\n  Bayesian Learning Abstract: In this work, we provide non-asymptotic, probabilistic guarantees for\nsuccessful recovery of the common nonzero support of jointly sparse Gaussian\nsources in the multiple measurement vector (MMV) problem. The support recovery\nproblem is formulated as the marginalized maximum likelihood (or type-II ML)\nestimation of the variance hyperparameters of a joint sparsity inducing\nGaussian prior on the source signals. We derive conditions under which the\nresulting nonconvex constrained optimization perfectly recovers the nonzero\nsupport of a joint-sparse Gaussian source ensemble with arbitrarily high\nprobability. The support error probability decays exponentially with the number\nof MMVs at a rate that depends on the smallest restricted singular value and\nthe nonnegative null space property of the self Khatri-Rao product of the\nsensing matrix. Our analysis confirms that nonzero supports of size as high as\nO($m^2$) are recoverable from $m$ measurements per sparse vector. Our derived\nsufficient conditions for support consistency of the proposed constrained\ntype-II ML solution also guarantee the support consistency of any global\nsolution of the multiple sparse Bayesian learning (M-SBL) optimization whose\nnonzero coefficients lie inside a bounded interval. For the case of noiseless\nmeasurements, we further show that a single MMV is sufficient for perfect\nrecovery of the $k$-sparse support by M-SBL, provided all subsets of $k + 1$\ncolumns of the sensing matrix are linearly independent. \n\n"}
{"id": "1703.05401", "contents": "Title: Mobile Unmanned Aerial Vehicles (UAVs) for Energy-Efficient Internet of\n  Things Communications Abstract: In this paper, the efficient deployment and mobility of multiple unmanned\naerial vehicles (UAVs), used as aerial base stations to collect data from\nground Internet of Things (IoT) devices, is investigated. In particular, to\nenable reliable uplink communications for IoT devices with a minimum total\ntransmit power, a novel framework is proposed for jointly optimizing the\nthree-dimensional (3D) placement and mobility of the UAVs, device-UAV\nassociation, and uplink power control. First, given the locations of active IoT\ndevices at each time instant, the optimal UAVs' locations and associations are\ndetermined. Next, to dynamically serve the IoT devices in a time-varying\nnetwork, the optimal mobility patterns of the UAVs are analyzed. To this end,\nbased on the activation process of the IoT devices, the time instances at which\nthe UAVs must update their locations are derived. Moreover, the optimal 3D\ntrajectory of each UAV is obtained in a way that the total energy used for the\nmobility of the UAVs is minimized while serving the IoT devices. Simulation\nresults show that, using the proposed approach, the total transmit power of the\nIoT devices is reduced by 45% compared to a case in which stationary aerial\nbase stations are deployed. In addition, the proposed approach can yield a\nmaximum of 28% enhanced system reliability compared to the stationary case. The\nresults also reveal an inherent tradeoff between the number of update times,\nthe mobility of the UAVs, and the transmit power of the IoT devices. In\nessence, a higher number of updates can lead to lower transmit powers for the\nIoT devices at the cost of an increased mobility for the UAVs. \n\n"}
{"id": "1703.07035", "contents": "Title: Pattern Division Multiple Access with Large-scale Antenna Array Abstract: In this paper, pattern division multiple access with large-scale antenna\narray (LSA-PDMA) is proposed as a novel non-orthogonal multiple access (NOMA)\nscheme. In the proposed scheme, pattern is designed in both beam domain and\npower domain in a joint manner. At the transmitter, pattern mapping utilizes\npower allocation to improve the system sum rate and beam allocation to enhance\nthe access connectivity and realize the integration of LSA into multiple access\nspontaneously. At the receiver, hybrid detection of spatial filter (SF) and\nsuccessive interference cancellation (SIC) is employed to separate the\nsuperposed multiple-domain signals. Furthermore, we formulate the sum rate\nmaximization problem to obtain the optimal pattern mapping policy, and the\noptimization problem is proved to be convex through proper mathematical\nmanipulations. Simulation results show that the proposed LSA-PDMA scheme\nachieves significant performance gain on system sum rate compared to both the\northogonal multiple access scheme and the power-domain NOMA scheme. \n\n"}
{"id": "1703.08206", "contents": "Title: Understand Your Chains: Towards Performance Profile-based Network\n  Service Management Abstract: Allocating resources to virtualized network functions and services to meet\nservice level agreements is a challenging task for NFV management and\norchestration systems. This becomes even more challenging when agile\ndevelopment methodologies, like DevOps, are applied. In such scenarios,\nmanagement and orchestration systems are continuously facing new versions of\nfunctions and services which makes it hard to decide how much resources have to\nbe allocated to them to provide the expected service performance. One solution\nfor this problem is to support resource allocation decisions with performance\nbehavior information obtained by profiling techniques applied to such network\nfunctions and services.\n  In this position paper, we analyze and discuss the components needed to\ngenerate such performance behavior information within the NFV DevOps workflow.\nWe also outline research questions that identify open issues and missing pieces\nfor a fully integrated NFV profiling solution. Further, we introduce a novel\nprofiling mechanism that is able to profile virtualized network functions and\nentire network service chains under different resource constraints before they\nare deployed on production infrastructure. \n\n"}
{"id": "1703.09481", "contents": "Title: Metastable Markov chains: from the convergence of the trace to the\n  convergence of the finite-dimensional distributions Abstract: We consider continuous-time Markov chains which display a family of wells at\nthe same depth. We provide sufficient conditions which entail the convergence\nof the finite-dimensional distributions of the order parameter to the ones of a\nfinite state Markov chain. We also show that the state of the process can be\nrepresented as a time-dependent convex combination of metastable states, each\nof which is supported on one well. \n\n"}
{"id": "1703.10516", "contents": "Title: Real-Time Dispersion Code Multiple Access (DCMA) for High-Speed Wireless\n  Communications Abstract: We model, demonstrate and characterize Dispersion Code Multiple Access (DCMA)\nand hence show the applicability of this purely analog and real-time multiple\naccess scheme to high-speed wireless communications. We first mathematically\ndescribe DCMA and show the appropriateness of Chebyshev dispersion coding in\nthis technology. We next provide an experimental proof-of-concept in a 2 X 2\nDCMA system. Finally,we statistically characterize DCMA in terms of bandwidth,\ndispersive group delay swing, system dimension and signal-to-noise ratio. \n\n"}
{"id": "1704.00623", "contents": "Title: Massive MIMO Performance - TDD Versus FDD: What Do Measurements Say? Abstract: Downlink beamforming in Massive MIMO either relies on uplink pilot\nmeasurements - exploiting reciprocity and TDD operation, or on the use of a\npredetermined grid of beams with user equipments reporting their preferred\nbeams, mostly in FDD operation. Massive MIMO in its originally conceived form\nuses the first strategy, with uplink pilots, whereas there is currently\nsignificant commercial interest in the second, grid-of-beams. It has been\nanalytically shown that in isotropic scattering (independent Rayleigh fading)\nthe first approach outperforms the second. Nevertheless there remains\ncontroversy regarding their relative performance in practice. In this\ncontribution, the performances of these two strategies are compared using\nmeasured channel data at 2.6 GHz. \n\n"}
{"id": "1704.00651", "contents": "Title: Fast Encoding and Decoding of Flexible-Rate and Flexible-Length Polar\n  Codes Abstract: This work is on fast encoding and decoding of polar codes. We propose and\ndetail 8-bit and 16-bit parallel decoders that can be used to reduce the\ndecoding latency of the successive-cancellation decoder. These decoders are\nuniversal and can decode flexible-rate and flexible-length polar codes. We also\npresent fast encoders that can be used to increase the throughput of\nserially-implemented polar encoders. \n\n"}
{"id": "1704.01177", "contents": "Title: Combinatorial Entropy Power Inequalities: A Preliminary Study of the\n  Stam region Abstract: We initiate the study of the Stam region, defined as the subset of the\npositive orthant in $\\mathbb{R}^{2^n-1}$ that arises from considering entropy\npowers of subset sums of $n$ independent random vectors in a Euclidean space of\nfinite dimension. We show that the class of fractionally superadditive set\nfunctions provides an outer bound to the Stam region, resolving a conjecture of\nA. R. Barron and the first author. On the other hand, the entropy power of a\nsum of independent random vectors is not supermodular in any dimension. We also\ndevelop some qualitative properties of the Stam region, showing for instance\nthat its closure is a logarithmically convex cone. \n\n"}
{"id": "1704.01765", "contents": "Title: Joint Trajectory and Communication Design for UAV-Enabled Multiple\n  Access Abstract: Unmanned aerial vehicles (UAVs) have attracted significant interest recently\nin wireless communication due to their high maneuverability, flexible\ndeployment, and low cost. This paper studies a UAV-enabled wireless network\nwhere the UAV is employed as an aerial mobile base station (BS) to serve a\ngroup of users on the ground. To achieve fair performance among users, we\nmaximize the minimum throughput over all ground users by jointly optimizing the\nmultiuser communication scheduling and UAV trajectory over a finite horizon.\nThe formulated problem is shown to be a mixed integer non-convex optimization\nproblem that is difficult to solve in general. We thus propose an efficient\niterative algorithm by applying the block coordinate descent and successive\nconvex optimization techniques, which is guaranteed to converge to at least a\nlocally optimal solution. To achieve fast convergence and stable throughput, we\nfurther propose a low-complexity initialization scheme for the UAV trajectory\ndesign based on the simple circular trajectory. Extensive simulation results\nare provided which show significant throughput gains of the proposed design as\ncompared to other benchmark schemes. \n\n"}
{"id": "1704.01799", "contents": "Title: Prototyping and Experimentation of a Closed-Loop Wireless Power\n  Transmission with Channel Acquisition and Waveform Optimization Abstract: A systematic design of adaptive waveform for Wireless Power Transfer (WPT)\nhas recently been proposed and shown through simulations to lead to significant\nperformance benefits compared to traditional non-adaptive and heuristic\nwaveforms. In this study, we design the first prototype of a closed-loop\nwireless power transfer system with adaptive waveform optimization based on\nChannel State Information acquisition. The prototype consists of three\nimportant blocks, namely the channel estimator, the waveform optimizer, and the\nenergy harvester. Software Defined Radio (SDR) prototyping tools are used to\nimplement a wireless power transmitter and a channel estimator, and a voltage\ndoubler rectenna is designed to work as an energy harvester. A channel adaptive\nwaveform with 8 sinewaves is shown through experiments to improve the average\nharvested DC power at the rectenna output by 9.8% to 36.8% over a non-adaptive\ndesign with the same number of sinewaves. \n\n"}
{"id": "1704.03287", "contents": "Title: Uplink Multiuser Massive MIMO Systems with Low-Resolution ADCs: A\n  Coding-Theoretic Approach Abstract: This paper considers an uplink multiuser massive\nmultiple-input-multiple-output (MIMO) system with low-resolution\nanalog-to-digital converters (ADCs), in which K users with a single-antenna\ncommunicate with one base station (BS) with Nr antennas. In this system, we\npresent a novel multiuser MIMO detection framework that is inspired by coding\ntheory. The key idea of the proposed framework is to create a code C of length\n2Nr over a spatial domain. This code is constructed by a so-called\nauto-encoding function that is not designable but is completely described by a\nchannel transformation followed by a quantization function of the ADCs. From\nthis point of view, we convert a multiuser MIMO detection problem into an\nequivalent channel coding problem, in which a codeword of C corresponding to\nusers' messages is sent over 2Nr parallel channels, each with different channel\nreliability. To the resulting problem, we propose a novel weighted minimum\ndistance decoding (wMDD) that appropriately exploits the unequal channel\nreliabilities. It is shown that the proposed wMDD yields a non-trivial gain\nover the conventional minimum distance decoding (MDD). From coding-theoretic\nviewpoint, we identify that bit-error-rate (BER) exponentially decreases with\nthe minimum distance of the code C, which plays a similar role with a condition\nnumber in conventional MIMO systems. Furthermore, we develop the communication\nmethod that uses the wMDD for practical scenarios where the BS has no knowledge\nof channel state information. Finally, numerical results are provided to verify\nthe superiority of the proposed method. \n\n"}
{"id": "1704.04194", "contents": "Title: Ultrametrics in the genetic code and the genome Abstract: Ultrametric approach to the genetic code and the genome is considered and\ndeveloped. $p$-Adic degeneracy of the genetic code is pointed out. Ultrametric\ntree of the codon space is presented. It is shown that codons and amino acids\ncan be treated as $p$-adic ultrametric networks. Ultrametric modification of\nthe Hamming distance is defined and noted how it can be useful. Ultrametric\napproach with $p$-adic distance is an attractive and promising trend towards\ninvestigation of bioinformation. \n\n"}
{"id": "1704.04465", "contents": "Title: A Low-Complexity Approach to Distributed Cooperative Caching with\n  Geographic Constraints Abstract: We consider caching in cellular networks in which each base station is\nequipped with a cache that can store a limited number of files. The popularity\nof the files is known and the goal is to place files in the caches such that\nthe probability that a user at an arbitrary location in the plane will find the\nfile that she requires in one of the covering caches is maximized.\n  We develop distributed asynchronous algorithms for deciding which contents to\nstore in which cache. Such cooperative algorithms require communication only\nbetween caches with overlapping coverage areas and can operate in asynchronous\nmanner. The development of the algorithms is principally based on an\nobservation that the problem can be viewed as a potential game. Our basic\nalgorithm is derived from the best response dynamics. We demonstrate that the\ncomplexity of each best response step is independent of the number of files,\nlinear in the cache capacity and linear in the maximum number of base stations\nthat cover a certain area. Then, we show that the overall algorithm complexity\nfor a discrete cache placement is polynomial in both network size and catalog\nsize. In practical examples, the algorithm converges in just a few iterations.\nAlso, in most cases of interest, the basic algorithm finds the best Nash\nequilibrium corresponding to the global optimum. We provide two extensions of\nour basic algorithm based on stochastic and deterministic simulated annealing\nwhich find the global optimum.\n  Finally, we demonstrate the hit probability evolution on real and synthetic\nnetworks numerically and show that our distributed caching algorithm performs\nsignificantly better than storing the most popular content, probabilistic\ncontent placement policy and Multi-LRU caching policies. \n\n"}
{"id": "1704.04813", "contents": "Title: Wireless Communication using Unmanned Aerial Vehicles (UAVs): Optimal\n  Transport Theory for Hover Time Optimization Abstract: In this paper, the effective use of flight-time constrained unmanned aerial\nvehicles (UAVs) as flying base stations that can provide wireless service to\nground users is investigated. In particular, a novel framework for optimizing\nthe performance of such UAV-based wireless systems in terms of the average\nnumber of bits (data service) transmitted to users as well as UAVs' hover\nduration (i.e. flight time) is proposed. In the considered model, UAVs hover\nover a given geographical area to serve ground users that are distributed\nwithin the area based on an arbitrary spatial distribution function. In this\ncase, two practical scenarios are considered. In the first scenario, based on\nthe maximum possible hover times of UAVs, the average data service delivered to\nthe users under a fair resource allocation scheme is maximized by finding the\noptimal cell partitions associated to the UAVs. Using the mathematical\nframework of optimal transport theory, a gradient-based algorithm is proposed\nfor optimally partitioning the geographical area based on the users'\ndistribution, hover times, and locations of the UAVs. In the second scenario,\ngiven the load requirements of ground users, the minimum average hover time\nthat the UAVs need for completely servicing their ground users is derived. To\nthis end, first, an optimal bandwidth allocation scheme for serving the users\nis proposed. Then, given this optimal bandwidth allocation, the optimal cell\npartitions associated with the UAVs are derived by exploiting the optimal\ntransport theory. Results show that our proposed cell partitioning approach\nleads to a significantly higher fairness among the users compared to the\nclassical weighted Voronoi diagram. In addition, our results reveal an inherent\ntradeoff between the hover time of UAVs and bandwidth efficiency while serving\nthe ground users. \n\n"}
{"id": "1704.05296", "contents": "Title: Coverage and Rate of Downlink Sequence Transmissions with Reliability\n  Guarantees Abstract: Real-time distributed control is a promising application of 5G in which\ncommunication links should satisfy certain reliability guarantees. In this\nletter, we derive closed-form maximum average rate when a device (e.g.\nindustrial machine) downloads a sequence of n operational commands through\ncellular connection, while guaranteeing a certain signal-to-interference ratio\n(SIR) coverage for all n messages. The result is based on novel closed-form\nn-successive SIR coverage bounds. The proposed bounds provide simple\napproximations that are increasingly accurate in the high reliability region. \n\n"}
{"id": "1704.05296", "contents": "Title: Coverage and Rate of Downlink Sequence Transmissions with Reliability\n  Guarantees Abstract: Real-time distributed control is a promising application of 5G in which\ncommunication links should satisfy certain reliability guarantees. In this\nletter, we derive closed-form maximum average rate when a device (e.g.\nindustrial machine) downloads a sequence of n operational commands through\ncellular connection, while guaranteeing a certain signal-to-interference ratio\n(SIR) coverage for all n messages. The result is based on novel closed-form\nn-successive SIR coverage bounds. The proposed bounds provide simple\napproximations that are increasingly accurate in the high reliability region. \n\n"}
{"id": "1704.05614", "contents": "Title: A Novel Receiver Design with Joint Coherent and Non-Coherent Processing Abstract: In this paper, we propose a novel splitting receiver, which involves joint\nprocessing of coherently and non-coherently received signals. Using a passive\nRF power splitter, the received signal at each receiver antenna is split into\ntwo streams which are then processed by a conventional coherent detection (CD)\ncircuit and a power-detection (PD) circuit, respectively. The streams of the\nsignals from all the receiver antennas are then jointly used for information\ndetection. We show that the splitting receiver creates a three-dimensional\nreceived signal space, due to the joint coherent and non-coherent processing.\nWe analyze the achievable rate of a splitting receiver, which shows that the\nsplitting receiver provides a rate gain of $3/2$ compared to either the\nconventional (CD-based) coherent receiver or the PD-based non-coherent receiver\nin the high SNR regime. We also analyze the symbol error rate (SER) for\npractical modulation schemes, which shows that the splitting receiver achieves\nasymptotic SER reduction by a factor of at least $\\sqrt{M}-1$ for $M$-QAM\ncompared to either the conventional (CD-based) coherent receiver or the\nPD-based non-coherent receiver. \n\n"}
{"id": "1704.06525", "contents": "Title: Nonlinear Precoders for Massive MIMO Systems with General Constraints Abstract: We introduce a class of nonlinear least square error precoders with a general\npenalty function for multiuser massive MIMO systems. The generality of the\npenalty function allows us to consider several hardware limitations including\ntransmitters with a predefined constellation and restricted number of active\nantennas. The large-system performance is then investigated via the replica\nmethod under the assumption of replica symmetry. It is shown that the least\nsquare precoders exhibit the \"marginal decoupling property\" meaning that the\nmarginal distributions of all precoded symbols converge to a deterministic\ndistribution. As a result, the asymptotic performance of the precoders is\ndescribed by an equivalent single-user system. To address some applications of\nthe results, we further study the asymptotic performance of the precoders when\nboth the peak-to-average power ratio and number of active transmit antennas are\nconstrained. Our numerical investigations show that for a desired distortion at\nthe receiver side, proposed forms of the least square precoders need to employ\naround %35\\%$ fewer number of active antennas compared to cases with random\ntransmit antenna selection. \n\n"}
{"id": "1704.06684", "contents": "Title: A hybrid exact-ACO algorithm for the joint scheduling, power and cluster\n  assignment in cooperative wireless networks Abstract: Base station cooperation (BSC) has recently arisen as a promising way to\nincrease the capacity of a wireless network. Implementing BSC adds a new design\ndimension to the classical wireless network design problem: how to define the\nsubset of base stations (clusters) that coordinate to serve a user. Though the\nproblem of forming clusters has been extensively discussed from a technical\npoint of view, there is still a lack of effective optimization models for its\nrepresentation and algorithms for its solution. In this work, we make a further\nstep towards filling such gap: 1) we generalize the classical network design\nproblem by adding cooperation as an additional decision dimension; 2) we\ndevelop a strong formulation for the resulting problem; 3) we define a new\nhybrid solution algorithm that combines exact large neighborhood search and ant\ncolony optimization. Finally, we assess the performance of our new model and\nalgorithm on a set of realistic instances of a WiMAX network. \n\n"}
{"id": "1704.06764", "contents": "Title: Multiuser Millimeter Wave MIMO Channel Estimation with Hybrid\n  Beamforming Abstract: This paper focuses on multiuser MIMO channel estimation and data transmission\nat millimeter wave (mmWave) frequencies. The proposed approach relies on the\ntime-division-duplex (TDD) protocol and is based on two distinct phases. First\nof all, the Base Station (BS) sends a suitable probing signal so that all the\nMobile Stations (MSs), using a subspace tracking algorithm, can estimate the\ndominant left singular vectors of their BS-to-MS propagation channel. Then,\neach MS, using the estimated dominant left singular vectors as pre-coding\nbeamformers, sends a suitable pilot sequence so that the BS can estimate the\ncorresponding right dominant channel singular vectors and the corresponding\neigenvalues. The low-complexity projection approximation subspace tracking with\ndeflation (PASTd) algorithm is used at the MSs for dominant subspace\nestimation, while pilot-matched (PM) and zero-forcing (ZF) reception is used at\nthe BS. The proposed algorithms can be used in conjuction with an analog RF\nbeamformer and are shown to exhibit very good performance. \n\n"}
{"id": "1704.06864", "contents": "Title: On the Trade-Off between Computational Load and Reliability for Network\n  Function Virtualization Abstract: Network Function Virtualization (NFV) enables the \"softwarization\" of network\nfunctions, which are implemented on virtual machines hosted on Commercial\noff-the-shelf (COTS) servers. Both the composition of the virtual network\nfunctions (VNFs) into a forwarding graph (FG) at the logical layer and the\nembedding of the FG on the servers need to take into account the\nless-than-carrier-grade reliability of COTS components. This work investigates\nthe trade-off between end-to-end reliability and computational load per server\nvia the joint design of VNF chain composition (CC) and FG embedding (FGE) under\nthe assumption of a bipartite FG that consists of controller and regular VNFs.\nEvaluating the reliability criterion within a probabilistic model, analytical\ninsights are first provided for a simplified disconnected FG. Then, a block\ncoordinate descent method based on mixed-integer linear programming is proposed\nto tackle the joint optimization of CC and FGE. Via simulation results, it is\nobserved that a joint design of CC and FGE leads to substantial performance\ngains compared to separate optimization approaches. \n\n"}
{"id": "1704.07059", "contents": "Title: $H(X)$ vs. $H(f(X))$ Abstract: It is well known that the entropy $H(X)$ of a finite random variable is\nalways greater or equal to the entropy $H(f(X))$ of a function $f$ of $X$, with\nequality if and only if $f$ is one-to-one. In this paper, we give tights bounds\non $H(f(X))$ when the function $f$ is not one-to-one, and we illustrate a few\nscenarios where this matters. As an intermediate step towards our main result,\nwe prove a lower bound on the entropy of a probability distribution, when only\na bound on the ratio between the maximum and the minimum probability is known.\nOur lower bound improves previous results in the literature, and it could find\napplications outside the present scenario. \n\n"}
{"id": "1704.08771", "contents": "Title: Strong Coordination over Noisy Channels: Is Separation Sufficient? Abstract: We study the problem of strong coordination of actions of two agents $X$ and\n$Y$ that communicate over a noisy communication channel such that the actions\nfollow a given joint probability distribution. We propose two novel schemes for\nthis noisy strong coordination problem, and derive inner bounds for the\nunderlying strong coordination capacity region. The first scheme is a joint\ncoordination-channel coding scheme that utilizes the randomness provided by the\ncommunication channel to reduce the local randomness required in generating the\naction sequence at agent $Y$. The second scheme exploits separate coordination\nand channel coding where local randomness is extracted from the channel after\ndecoding. Finally, we present an example in which the joint scheme is able to\noutperform the separate scheme in terms of coordination rate. \n\n"}
{"id": "1705.00385", "contents": "Title: A Generalized Probabilistic Version of Modus Ponens Abstract: Modus ponens (\\emph{from $A$ and \"if $A$ then $C$\" infer $C$}, short: MP) is\none of the most basic inference rules. The probabilistic MP allows for managing\nuncertainty by transmitting assigned uncertainties from the premises to the\nconclusion (i.e., from $P(A)$ and $P(C|A)$ infer $P(C)$). In this paper, we\ngeneralize the probabilistic MP by replacing $A$ by the conditional event\n$A|H$. The resulting inference rule involves iterated conditionals (formalized\nby conditional random quantities) and propagates previsions from the premises\nto the conclusion. Interestingly, the propagation rules for the lower and the\nupper bounds on the conclusion of the generalized probabilistic MP coincide\nwith the respective bounds on the conclusion for the (non-nested) probabilistic\nMP. \n\n"}
{"id": "1705.01473", "contents": "Title: Randomness cost of symmetric twirling Abstract: We study random unitary channels which reproduce the action of the twirling\nchannel corresponding to the representation of the symmetric groupon an n-fold\ntensor product. We derive upper andlower bounds on the randomness cost of\nimplementing such a map which depend exponentially on the number of systems.\nConsequently, symmetrictwirling can be regarded as a reasonable Shannon\ntheoretic protocol. On the other hand, such protocols are disqualified by their\nresource-inefficiency in situations where randomness is a costly resource. \n\n"}
{"id": "1705.02723", "contents": "Title: Joint Trajectory and Communication Design for Multi-UAV Enabled Wireless\n  Networks Abstract: Unmanned aerial vehicles (UAVs) have attracted significant interest recently\nin assisting wireless communication due to their high maneuverability, flexible\ndeployment, and low cost. This paper considers a multi-UAV enabled wireless\ncommunication system, where multiple UAV-mounted aerial base stations (BSs) are\nemployed to serve a group of users on the ground. To achieve fair performance\namong users, we maximize the minimum throughput over all ground users in the\ndownlink communication by optimizing the multiuser communication scheduling and\nassociation jointly with the UAVs' trajectory and power control. The formulated\nproblem is a mixed integer non-convex optimization problem that is challenging\nto solve. As such, we propose an efficient iterative algorithm for solving it\nby applying the block coordinate descent and successive convex optimization\ntechniques. Specifically, the user scheduling and association, UAV trajectory,\nand transmit power are alternately optimized in each iteration. In particular,\nfor the non-convex UAV trajectory and transmit power optimization problems, two\napproximate convex optimization problems are solved, respectively. We further\nshow that the proposed algorithm is guaranteed to converge to at least a\nlocally optimal solution. To speed up the algorithm convergence and achieve\ngood throughput, a low-complexity and systematic initialization scheme is also\nproposed for the UAV trajectory design based on the simple circular trajectory\nand the circle packing scheme. Extensive simulation results are provided to\ndemonstrate the significant throughput gains of the proposed design as compared\nto other benchmark schemes. \n\n"}
{"id": "1705.03549", "contents": "Title: Ergodicity of Sublinear Markovian Semigroups Abstract: In this paper, we study the ergodicity of invariant sublinear expectation of\nsublinear Markovian semigroup. For this, we first develop an ergodic theory of\nan expectation-preserving map on a sublinear expectation space. Ergodicity is\ndefined as any invariant set either has $0$ capacity itself or its complement\nhas $0$ capacity. We prove, under a general sublinear expectation space\nsetting, the equivalent relation between ergodicity and the corresponding\ntransformation operator having simple eigenvalue $1$, and also with Birkhoff\ntype strong law of large numbers if the sublinear expectation is regular. For\nsublinear Markov process, we prove that its ergodicity is equivalent to the\nMarkovian semigroup having eigenvalue $1$ and it is simple in the space of\nbounded measurable functions. As an example we show that $G$-Brownian motion\n$\\{B_t\\}_{t\\geq 0}$ on the unit circle has an invariant expectation and is\nergodic if and only if ${\\mathbb E}(-(B_1)^2)<0$. Moreover, it is also proved\nin this case that the invariant expectation is regular and the canonical\nstationary process has no mean-uncertainty under the invariant expectation. \n\n"}
{"id": "1705.06040", "contents": "Title: Information Geometry Approach to Parameter Estimation in Hidden Markov\n  Models Abstract: We consider the estimation of the transition matrix of a hidden Markovian\nprocess by using information geometry with respect to transition matrices. In\nthis paper, only the histogram of $k$-memory data is used for the estimation.\nTo establish our method, we focus on a partial observation model with the\nMarkovian process and we propose an efficient estimator whose asymptotic\nestimation error is given as the inverse of projective Fisher information of\ntransition matrices. This estimator is applied to the estimation of the\ntransition matrix of the hidden Markovian process. In this application, we\ncarefully discuss the equivalence problem for hidden Markovian process on the\ntangent space. \n\n"}
{"id": "1705.07809", "contents": "Title: Information-theoretic analysis of generalization capability of learning\n  algorithms Abstract: We derive upper bounds on the generalization error of a learning algorithm in\nterms of the mutual information between its input and output. The bounds\nprovide an information-theoretic understanding of generalization in learning\nproblems, and give theoretical guidelines for striking the right balance\nbetween data fit and generalization by controlling the input-output mutual\ninformation. We propose a number of methods for this purpose, among which are\nalgorithms that regularize the ERM algorithm with relative entropy or with\nrandom noise. Our work extends and leads to nontrivial improvements on the\nrecent results of Russo and Zou. \n\n"}
{"id": "1705.08617", "contents": "Title: Which bridge estimator is optimal for variable selection? Abstract: We study the problem of variable selection for linear models under the\nhigh-dimensional asymptotic setting, where the number of observations $n$ grows\nat the same rate as the number of predictors $p$. We consider two-stage\nvariable selection techniques (TVS) in which the first stage uses bridge\nestimators to obtain an estimate of the regression coefficients, and the second\nstage simply thresholds this estimate to select the \"important\" predictors. The\nasymptotic false discovery proportion (AFDP) and true positive proportion\n(ATPP) of these TVS are evaluated. We prove that for a fixed ATPP, in order to\nobtain a smaller AFDP, one should pick a bridge estimator with smaller\nasymptotic mean square error in the first stage of TVS. Based on such\nprincipled discovery, we present a sharp comparison of different TVS, via an\nin-depth investigation of the estimation properties of bridge estimators.\nRather than \"order-wise\" error bounds with loose constants, our analysis\nfocuses on precise error characterization. Various interesting signal-to-noise\nratio and sparsity settings are studied. Our results offer new and thorough\ninsights into high-dimensional variable selection. For instance, we prove that\na TVS with Ridge in its first stage outperforms TVS with other bridge\nestimators in large noise settings; two-stage LASSO becomes inferior when the\nsignal is rare and weak. As a by-product, we show that two-stage methods\noutperform some standard variable selection techniques, such as LASSO and Sure\nIndependence Screening, under certain conditions. \n\n"}
{"id": "1705.09412", "contents": "Title: Learning to Optimize: Training Deep Neural Networks for Wireless\n  Resource Management Abstract: For the past couple of decades, numerical optimization has played a central\nrole in addressing wireless resource management problems such as power control\nand beamformer design. However, optimization algorithms often entail\nconsiderable complexity, which creates a serious gap between theoretical\ndesign/analysis and real-time processing. To address this challenge, we propose\na new learning-based approach. The key idea is to treat the input and output of\na resource allocation algorithm as an unknown non-linear mapping and use a deep\nneural network (DNN) to approximate it. If the non-linear mapping can be\nlearned accurately by a DNN of moderate size, then resource allocation can be\ndone in almost real time -- since passing the input through a DNN only requires\na small number of simple operations.\n  In this work, we address both the thereotical and practical aspects of\nDNN-based algorithm approximation with applications to wireless resource\nmanagement. We first pin down a class of optimization algorithms that are\n`learnable' in theory by a fully connected DNN. Then, we focus on DNN-based\napproximation to a popular power allocation algorithm named WMMSE (Shi {\\it et\nal} 2011). We show that using a DNN to approximate WMMSE can be fairly accurate\n-- the approximation error $\\epsilon$ depends mildly [in the order of\n$\\log(1/\\epsilon)$] on the numbers of neurons and layers of the DNN. On the\nimplementation side, we use extensive numerical simulations to demonstrate that\nDNNs can achieve orders of magnitude speedup in computational time compared to\nstate-of-the-art power allocation algorithms based on optimization. \n\n"}
{"id": "1705.09429", "contents": "Title: Equivalences Between Network Codes With Link Errors and Index Codes With\n  Side Information Errors Abstract: In this paper, new equivalence relationships between a network code with link\nerrors (NCLE) and an index code with side information errors (ICSIE) are\nstudied. First, for a given network coding instance, the equivalent index\ncoding instance is derived, where an NCLE is converted to the corresponding\nICSIE and vice versa. Next, for a given index coding instance, the equivalent\nnetwork coding instance is also derived, where an ICSIE is converted to the\ncorresponding NCLE and vice versa if a pair of encoding functions of an\noriginal link and the duplicated link are functionally related in the network\ncode. Finally, several properties of an NCLE are derived from those of the\nequivalent ICSIE using the fact that the NCLE and the ICSIE are equivalent. \n\n"}
{"id": "1705.09634", "contents": "Title: Near-linear time approximation algorithms for optimal transport via\n  Sinkhorn iteration Abstract: Computing optimal transport distances such as the earth mover's distance is a\nfundamental problem in machine learning, statistics, and computer vision.\nDespite the recent introduction of several algorithms with good empirical\nperformance, it is unknown whether general optimal transport distances can be\napproximated in near-linear time. This paper demonstrates that this ambitious\ngoal is in fact achieved by Cuturi's Sinkhorn Distances. This result relies on\na new analysis of Sinkhorn iteration, which also directly suggests a new greedy\ncoordinate descent algorithm, Greenkhorn, with the same theoretical guarantees.\nNumerical simulations illustrate that Greenkhorn significantly outperforms the\nclassical Sinkhorn algorithm in practice. \n\n"}
{"id": "1705.10104", "contents": "Title: Universal Framework for Wireless Scheduling Problems Abstract: An overarching issue in resource management of wireless networks is assessing\ntheir capacity: How much communication can be achieved in a network, utilizing\nall the tools available: power control, scheduling, routing, channel assignment\nand rate adjustment? We propose the first framework for approximation\nalgorithms in the physical model that addresses these questions in full,\nincluding rate control. The approximations obtained are doubly logarithmic in\nthe link length and rate diversity. Where previous bounds are known, this gives\nan exponential improvement.\n  A key contribution is showing that the complex interference relationship of\nthe physical model can be simplified into a novel type of amenable conflict\ngraphs, at a small cost. We also show that the approximation obtained is\nprovably the best possible for any conflict graph formulation. \n\n"}
{"id": "1705.10299", "contents": "Title: Robustness to unknown error in sparse regularization Abstract: Quadratically-constrained basis pursuit has become a popular device in sparse\nregularization; in particular, in the context of compressed sensing. However,\nthe majority of theoretical error estimates for this regularizer assume an a\npriori bound on the noise level, which is usually lacking in practice. In this\npaper, we develop stability and robustness estimates which remove this\nassumption. First, we introduce an abstract framework and show that robust\ninstance optimality of any decoder in the noise-aware setting implies stability\nand robustness in the noise-blind setting. This is based on certain sup-inf\nconstants referred to as quotients, strictly related to the quotient property\nof compressed sensing. We then apply this theory to prove the robustness of\nquadratically-constrained basis pursuit under unknown error in the cases of\nrandom Gaussian matrices and of random matrices with heavy-tailed rows, such as\nrandom sampling matrices from bounded orthonormal systems. We illustrate our\nresults in several cases of practical importance, including subsampled Fourier\nmeasurements and recovery of sparse polynomial expansions. \n\n"}
{"id": "1705.10595", "contents": "Title: (Quantum) Min-Entropy Resources Abstract: We model (interactive) resources that provide Alice with a string $X$ and a\nguarantee that any Eve interacting with her interface of the resource obtains a\n(quantum) system $E$ such that the conditional (smooth) min-entropy of $X$\ngiven $E$ is lower bounded by some $k$. This (abstract) resource specification\nencompasses any setting that results in the honest players holding such a\nstring (or aborting). For example, it could be constructed from, e.g., noisy\nchannels, quantum key distribution (QKD), or a violation of Bell inequalities,\nwhich all may be used to derive bounds on the min-entropy of $X$.\n  As a first application, we use this min-entropy resource to modularize key\ndistribution (KD) schemes by dividing them in two parts, which may be analyzed\nseparately. In the first part, a KD protocol constructs a min-entropy resource\ngiven the (physical) resources available in the specific setting considered. In\nthe second, it distills secret key from the min-entropy resource---i.e., it\nconstructs a secret key resource. We prove security for a generic key\ndistillation protocol that may use any min-entropy resource. Since the notion\nof resource construction is composable---security of a composed protocol\nfollows from the security of its parts--- this reduces proving security of a KD\nprotocol (e.g., QKD) to proving that it constructs a min-entropy resource.\n  As a second application, we provide a composable security proof for the\nrecent Fehr-Salvail protocol [EUROCRYPT 2017] that authenticates classical\nmessages with a quantum message authentication code (Q-MAC), and recycles all\nthe key upon successfully verifying the authenticity of the message. This\nprotocol uses (and recycles) a non-uniform key, which we model as consuming and\nconstructing a min-entropy resource. \n\n"}
{"id": "1706.00061", "contents": "Title: The Sample Complexity of Online One-Class Collaborative Filtering Abstract: We consider the online one-class collaborative filtering (CF) problem that\nconsists of recommending items to users over time in an online fashion based on\npositive ratings only. This problem arises when users respond only occasionally\nto a recommendation with a positive rating, and never with a negative one. We\nstudy the impact of the probability of a user responding to a recommendation,\np_f, on the sample complexity, i.e., the number of ratings required to make\n`good' recommendations, and ask whether receiving positive and negative\nratings, instead of positive ratings only, improves the sample complexity. Both\nquestions arise in the design of recommender systems. We introduce a simple\nprobabilistic user model, and analyze the performance of an online user-based\nCF algorithm. We prove that after an initial cold start phase, where\nrecommendations are invested in exploring the user's preferences, this\nalgorithm makes---up to a fraction of the recommendations required for updating\nthe user's preferences---perfect recommendations. The number of ratings\nrequired for the cold start phase is nearly proportional to 1/p_f, and that for\nupdating the user's preferences is essentially independent of p_f. As a\nconsequence we find that, receiving positive and negative ratings instead of\nonly positive ones improves the number of ratings required for initial\nexploration by a factor of 1/p_f, which can be significant. \n\n"}
{"id": "1706.00307", "contents": "Title: Energy Harvesting Networks with General Utility Functions: Near Optimal\n  Online Policies Abstract: We consider online scheduling policies for single-user energy harvesting\ncommunication systems, where the goal is to characterize online policies that\nmaximize the long term average utility, for some general concave and\nmonotonically increasing utility function. In our setting, the transmitter\nrelies on energy harvested from nature to send its messages to the receiver,\nand is equipped with a finite-sized battery to store its energy. Energy packets\nare independent and identically distributed (i.i.d.) over time slots, and are\nrevealed causally to the transmitter. Only the average arrival rate is known a\npriori. We first characterize the optimal solution for the case of Bernoulli\narrivals. Then, for general i.i.d. arrivals, we first show that fixed fraction\npolicies [Shaviv-Ozgur] are within a constant multiplicative gap from the\noptimal solution for all energy arrivals and battery sizes. We then derive a\nset of sufficient conditions on the utility function to guarantee that fixed\nfraction policies are within a constant additive gap as well from the optimal\nsolution. \n\n"}
{"id": "1706.00313", "contents": "Title: Multi-point Codes from the GGS Curves Abstract: This paper is concerned with the construction of algebraic geometric codes\ndefined from GGS curves. It is of significant use to describe bases for the\nRiemann-Roch spaces associated with totally ramified places, which enables us\nto study multi-point AG codes. Along this line, we characterize explicitly the\nWeierstrass semigroups and pure gaps. Additionally, we determine the floor of a\ncertain type of divisor and investigate the properties of AG codes from GGS\ncurves. Finally, we apply these results to find multi-point codes with\nexcellent parameters. As one of the examples, a presented code with parameters\n$ [216,190,\\geqslant 18] $ over $ \\mathbb{F}_{64} $ yields a new record. \n\n"}
{"id": "1706.01151", "contents": "Title: Deep MIMO Detection Abstract: In this paper, we consider the use of deep neural networks in the context of\nMultiple-Input-Multiple-Output (MIMO) detection. We give a brief introduction\nto deep learning and propose a modern neural network architecture suitable for\nthis detection task. First, we consider the case in which the MIMO channel is\nconstant, and we learn a detector for a specific system. Next, we consider the\nharder case in which the parameters are known yet changing and a single\ndetector must be learned for all multiple varying channels. We demonstrate the\nperformance of our deep MIMO detector using numerical simulations in comparison\nto competing methods including approximate message passing and semidefinite\nrelaxation. The results show that deep networks can achieve state of the art\naccuracy with significantly lower complexity while providing robustness against\nill conditioned channels and mis-specified noise variance. \n\n"}
{"id": "1706.05360", "contents": "Title: Phaseless Reconstruction from Space-Time Samples Abstract: Phaseless reconstruction from space-time samples is a nonlinear problem of\nrecovering a function $x$ in a Hilbert space $\\mathcal{H}$ from the modulus of\nlinear measurements $\\{\\lvert \\langle x, \\phi_i\\rangle \\rvert$, $ \\ldots$,\n$\\lvert \\langle A^{L_i}x, \\phi_i \\rangle \\rvert : i \\in\\mathscr I\\}$, where\n$\\{\\phi_i; i \\in\\mathscr I\\}\\subset \\mathcal{H}$ is a set of functionals on\n$\\mathcal{H}$, and $A$ is a bounded operator on $\\mathcal{H}$ that acts as an\nevolution operator. In this paper, we provide various sufficient or necessary\nconditions for solving this problem, which has connections to $X$-ray\ncrystallography, the scattering transform, and deep learning. \n\n"}
{"id": "1706.05583", "contents": "Title: Resource Optimization and Power Allocation in In-band Full Duplex\n  (IBFD)-Enabled Non-Orthogonal Multiple Access Networks Abstract: In this paper, the problem of uplink (UL) and downlink (DL) resource\noptimization, mode selection and power allocation is studied for wireless\ncellular networks under the assumption of in-band full duplex (IBFD) base\nstations, non-orthogonal multiple access (NOMA) operation, and queue stability\nconstraints. The problem is formulated as a network utility maximization\nproblem for which a Lyapunov framework is used to decompose it into two\ndisjoint subproblems of auxiliary variable selection and rate maximization. The\nlatter is further decoupled into a user association and mode selection (UAMS)\nproblem and a UL/DL power optimization (UDPO) problem that are solved\nconcurrently. The UAMS problem is modeled as a many-to-one matching problem to\nassociate users to small cell base stations (SBSs) and select transmission mode\n(half/full-duplex and orthogonal/non-orthogonal multiple access), and an\nalgorithm is proposed to solve the problem converging to a pairwise stable\nmatching. Subsequently, the UDPO problem is formulated as a sequence of convex\nproblems and is solved using the concave-convex procedure. Simulation results\ndemonstrate the effectiveness of the proposed scheme to allocate UL and DL\npower levels after dynamically selecting the operating mode and the served\nusers, under different traffic intensity conditions, network density, and\nself-interference cancellation capability. The proposed scheme is shown to\nachieve up to 63% and 73% of gains in UL and DL packet throughput, and 21% and\n17% in UL and DL cell edge throughput, respectively, compared to existing\nbaseline schemes. \n\n"}
{"id": "1706.06976", "contents": "Title: The effect of the spatial domain in FANOVA models with ARH(1) error term Abstract: Functional Analysis of Variance (FANOVA) from Hilbert-valued correlated data\nwith spatial rectangular or circular supports is analyzed, when Dirichlet\nconditions are assumed on the boundary. Specifically, a Hilbert-valued fixed\neffect model with error term defined from an Autoregressive Hilbertian process\nof order one (ARH(1) process) is considered, extending the formulation given in\nRuiz-Medina (2016). A new statistical test is also derived to contrast the\nsignificance of the functional fixed effect parameters. The Dirichlet\nconditions established at the boundary affect the dependence range of the\ncorrelated error term. While the rate of convergence to zero of the eigenvalues\nof the covariance kernels, characterizing the Gaussian functional error\ncomponents, directly affects the stability of the generalized least-squares\nparameter estimation problem. A simulation study and a real-data application\nrelated to fMRI analysis are undertaken to illustrate the performance of the\nparameter estimator and statistical test derived. \n\n"}
{"id": "1706.07043", "contents": "Title: Deep Learning Methods for Improved Decoding of Linear Codes Abstract: The problem of low complexity, close to optimal, channel decoding of linear\ncodes with short to moderate block length is considered. It is shown that deep\nlearning methods can be used to improve a standard belief propagation decoder,\ndespite the large example space. Similar improvements are obtained for the\nmin-sum algorithm. It is also shown that tying the parameters of the decoders\nacross iterations, so as to form a recurrent neural network architecture, can\nbe implemented with comparable results. The advantage is that significantly\nless parameters are required. We also introduce a recurrent neural decoder\narchitecture based on the method of successive relaxation. Improvements over\nstandard belief propagation are also observed on sparser Tanner graph\nrepresentations of the codes. Furthermore, we demonstrate that the neural\nbelief propagation decoder can be used to improve the performance, or\nalternatively reduce the computational complexity, of a close to optimal\ndecoder of short BCH codes. \n\n"}
{"id": "1706.08192", "contents": "Title: Dickman approximation in simulation, summations and perpetuities Abstract: The generalized Dickman distribution ${\\cal D}_\\theta$ with parameter\n$\\theta>0$ is the unique solution to the distributional equality $W=_d W^*$,\nwhere \\begin{eqnarray} W^*=_d U^{1/\\theta}(W+1) \\qquad (1) \\end{eqnarray} with\n$W$ non-negative with probability one, $U \\sim {\\cal U}[0,1]$ independent of\n$W$, and $=_d$ denoting equality in distribution. Members of this family appear\nin number theory, stochastic geometry, perpetuities and the study of\nalgorithms. We obtain bounds in Wasserstein type distances between ${\\cal\nD}_\\theta$ and \\begin{eqnarray} W_n= \\frac{1}{n} \\sum_{i=1}^n Y_k B_k \\qquad\n(2) \\end{eqnarray} where $B_1,\\ldots,B_n, Y_1, \\ldots, Y_n$ are independent\nwith $B_k \\sim {\\rm Ber}(1/k), E[Y_k]=k, {\\rm Var}(Y_k)=\\sigma_k^2$ and provide\nan application to the minimal directed spanning tree in $\\mathbb{R}^2$, and\nalso obtain such bounds when the Bernoulli variables in $(2)$ are replaced by\nPoissons. We also give simple proofs and provide bounds with optimal rates for\nthe Dickman convergence of the weighted sums, arising in probabilistic number\ntheory, of the form \\begin{eqnarray} S_n=\\frac{1}{\\log(p_n)} \\sum_{k=1}^n X_k\n\\log(p_k) \\end{eqnarray} where $(p_k)_{k \\ge 1}$ is an enumeration of the prime\nnumbers in increasing order and $X_k$ is Geometric with parameter $(1-1/p_k)$,\nBernoulli with success probability $1/(1+p_k)$ or Poisson with mean\n$\\lambda_k$.\n  In addition, we broaden the class of generalized Dickman distributions by\nstudying the fixed points of the transformation \\begin{eqnarray*} s(W^*)=_d\nU^{1/\\theta}s(W+1) \\end{eqnarray*} generalizing $(1)$, that allows the use of\nnon-identity utility functions $s(\\cdot)$ in Vervaat perpetuities. We obtain\ndistributional bounds for recursive methods that can be used to simulate from\nthis family. \n\n"}
{"id": "1706.09087", "contents": "Title: Uniform Recovery Bounds for Structured Random Matrices in Corrupted\n  Compressed Sensing Abstract: We study the problem of recovering an $s$-sparse signal\n$\\mathbf{x}^{\\star}\\in\\mathbb{C}^n$ from corrupted measurements $\\mathbf{y} =\n\\mathbf{A}\\mathbf{x}^{\\star}+\\mathbf{z}^{\\star}+\\mathbf{w}$, where\n$\\mathbf{z}^{\\star}\\in\\mathbb{C}^m$ is a $k$-sparse corruption vector whose\nnonzero entries may be arbitrarily large and $\\mathbf{w}\\in\\mathbb{C}^m$ is a\ndense noise with bounded energy. The aim is to exactly and stably recover the\nsparse signal with tractable optimization programs. In this paper, we prove the\nuniform recovery guarantee of this problem for two classes of structured\nsensing matrices. The first class can be expressed as the product of a\nunit-norm tight frame (UTF), a random diagonal matrix and a bounded columnwise\northonormal matrix (e.g., partial random circulant matrix). When the UTF is\nbounded (i.e. $\\mu(\\mathbf{U})\\sim1/\\sqrt{m}$), we prove that with high\nprobability, one can recover an $s$-sparse signal exactly and stably by $l_1$\nminimization programs even if the measurements are corrupted by a sparse\nvector, provided $m = \\mathcal{O}(s \\log^2 s \\log^2 n)$ and the sparsity level\n$k$ of the corruption is a constant fraction of the total number of\nmeasurements. The second class considers randomly sub-sampled orthogonal matrix\n(e.g., random Fourier matrix). We prove the uniform recovery guarantee provided\nthat the corruption is sparse on certain sparsifying domain. Numerous\nsimulation results are also presented to verify and complement the theoretical\nresults. \n\n"}
{"id": "1706.09615", "contents": "Title: Recovery of signals by a weighted $\\ell_2/\\ell_1$ minimization under\n  arbitrary prior support information Abstract: In this paper, we introduce a weighted $\\ell_2/\\ell_1$ minimization to\nrecover block sparse signals with arbitrary prior support information. When\npartial prior support information is available, a sufficient condition based on\nthe high order block RIP is derived to guarantee stable and robust recovery of\nblock sparse signals via the weighted $\\ell_2/\\ell_1$ minimization. We then\nshow if the accuracy of arbitrary prior block support estimate is at least\n$50\\%$, the sufficient recovery condition by the weighted $\\ell_2/\\ell_{1}$\nminimization is weaker than that by the $\\ell_2/\\ell_{1}$ minimization, and the\nweighted $\\ell_2/\\ell_{1}$ minimization provides better upper bounds on the\nrecovery error in terms of the measurement noise and the compressibility of the\nsignal. Moreover, we illustrate the advantages of the weighted $\\ell_2/\\ell_1$\nminimization approach in the recovery performance of block sparse signals under\nuniform and non-uniform prior information by extensive numerical experiments.\nThe significance of the results lies in the facts that making explicit use of\nblock sparsity and partial support information of block sparse signals can\nachieve better recovery performance than handling the signals as being in the\nconventional sense, thereby ignoring the additional structure and prior support\ninformation in the problem. \n\n"}
{"id": "1706.09993", "contents": "Title: Phase Retrieval via Randomized Kaczmarz: Theoretical Guarantees Abstract: We consider the problem of phase retrieval, i.e. that of solving systems of\nquadratic equations. A simple variant of the randomized Kaczmarz method was\nrecently proposed for phase retrieval, and it was shown numerically to have a\ncomputational edge over state-of-the-art Wirtinger flow methods. In this paper,\nwe provide the first theoretical guarantee for the convergence of the\nrandomized Kaczmarz method for phase retrieval. We show that it is sufficient\nto have as many Gaussian measurements as the dimension, up to a constant\nfactor. Along the way, we introduce a sufficient condition on measurement sets\nfor which the randomized Kaczmarz method is guaranteed to work. We show that\nGaussian sampling vectors satisfy this property with high probability; this is\nproved using a chaining argument coupled with bounds on VC dimension and metric\nentropy. \n\n"}
{"id": "1706.10239", "contents": "Title: Towards Understanding Generalization of Deep Learning: Perspective of\n  Loss Landscapes Abstract: It is widely observed that deep learning models with learned parameters\ngeneralize well, even with much more model parameters than the number of\ntraining samples. We systematically investigate the underlying reasons why deep\nneural networks often generalize well, and reveal the difference between the\nminima (with the same training error) that generalize well and those they\ndon't. We show that it is the characteristics the landscape of the loss\nfunction that explains the good generalization capability. For the landscape of\nloss function for deep networks, the volume of basin of attraction of good\nminima dominates over that of poor minima, which guarantees optimization\nmethods with random initialization to converge to good minima. We theoretically\njustify our findings through analyzing 2-layer neural networks; and show that\nthe low-complexity solutions have a small norm of Hessian matrix with respect\nto model parameters. For deeper networks, extensive numerical evidence helps to\nsupport our arguments. \n\n"}
{"id": "1707.02329", "contents": "Title: Deep Q-Learning for Self-Organizing Networks Fault Management and Radio\n  Performance Improvement Abstract: We propose an algorithm to automate fault management in an outdoor cellular\nnetwork using deep reinforcement learning (RL) against wireless impairments.\nThis algorithm enables the cellular network cluster to self-heal by allowing RL\nto learn how to improve the downlink signal to interference plus noise ratio\nthrough exploration and exploitation of various alarm corrective actions. The\nmain contributions of this paper are to 1) introduce a deep RL-based fault\nhandling algorithm which self-organizing networks can implement in a polynomial\nruntime and 2) show that this fault management method can improve the radio\nlink performance in a realistic network setup. Simulation results show that our\nproposed algorithm learns an action sequence to clear alarms and improve the\nperformance in the cellular cluster better than existing algorithms, even\nagainst the randomness of the network fault occurrences and user movements. \n\n"}
{"id": "1707.04875", "contents": "Title: Coding sets with asymmetric information Abstract: We study the following one-way asymmetric transmission problem, also a\nvariant of model-based compressed sensing: a resource-limited encoder has to\nreport a small set $S$ from a universe of $N$ items to a more powerful decoder\n(server). The distinguishing feature is asymmetric information: the subset $S$\nis comprised of i.i.d. samples from a prior distribution $\\mu$, and $\\mu$ is\nonly known to the decoder. The goal for the encoder is to encode $S$\nobliviously, while achieving the information-theoretic bound of $|S| \\cdot\nH(\\mu)$, i.e., the Shannon entropy bound.\n  We first show that any such compression scheme must be {\\em randomized}, if\nit gains non-trivially from the prior $\\mu$. This stands in contrast to the\nsymmetric case (when both the encoder and decoder know $\\mu$), where the\nHuffman code provides a near-optimal deterministic solution. On the other hand,\na rather simple argument shows that, when $|S|=k$, a random linear code\nachieves near-optimal communication rate of about $k\\cdot H(\\mu)$ bits. Alas,\nthe resulting scheme has prohibitive decoding time: about ${N\\choose k} \\approx\n(N/k)^k$.\n  Our main result is a computationally efficient and linear coding scheme,\nwhich achieves an $O(\\lg\\lg N)$-competitive communication ratio compared to the\noptimal benchmark, and runs in $\\text{poly}(N,k)$ time. Our \"multi-level\"\ncoding scheme uses a combination of hashing and syndrome-decoding of\nReed-Solomon codes, and relies on viewing the (unknown) prior $\\mu$ as a rather\nsmall convex combination of uniform (\"flat\") distributions. \n\n"}
{"id": "1707.05674", "contents": "Title: Learning the MMSE Channel Estimator Abstract: We present a method for estimating conditionally Gaussian random vectors with\nrandom covariance matrices, which uses techniques from the field of machine\nlearning. Such models are typical in communication systems, where the\ncovariance matrix of the channel vector depends on random parameters, e.g.,\nangles of propagation paths. If the covariance matrices exhibit certain\nToeplitz and shift-invariance structures, the complexity of the MMSE channel\nestimator can be reduced to O(M log M) floating point operations, where M is\nthe channel dimension. While in the absence of structure the complexity is much\nhigher, we obtain a similarly efficient (but suboptimal) estimator by using the\nMMSE estimator of the structured model as a blueprint for the architecture of a\nneural network. This network learns the MMSE estimator for the unstructured\nmodel, but only within the given class of estimators that contains the MMSE\nestimator for the structured model. Numerical simulations with typical spatial\nchannel models demonstrate the generalization properties of the chosen class of\nestimators to realistic channel models. \n\n"}
{"id": "1707.05697", "contents": "Title: An Iterative BP-CNN Architecture for Channel Decoding Abstract: Inspired by recent advances in deep learning, we propose a novel iterative\nBP-CNN architecture for channel decoding under correlated noise. This\narchitecture concatenates a trained convolutional neural network (CNN) with a\nstandard belief-propagation (BP) decoder. The standard BP decoder is used to\nestimate the coded bits, followed by a CNN to remove the estimation errors of\nthe BP decoder and obtain a more accurate estimation of the channel noise.\nIterating between BP and CNN will gradually improve the decoding SNR and hence\nresult in better decoding performance. To train a well-behaved CNN model, we\ndefine a new loss function which involves not only the accuracy of the noise\nestimation but also the normality test for the estimation errors, i.e., to\nmeasure how likely the estimation errors follow a Gaussian distribution. The\nintroduction of the normality test to the CNN training shapes the residual\nnoise distribution and further reduces the BER of the iterative decoding,\ncompared to using the standard quadratic loss function. We carry out extensive\nexperiments to analyze and verify the proposed framework. The iterative BP-CNN\ndecoder has better BER performance with lower complexity, is suitable for\nparallel implementation, does not rely on any specific channel model or\nencoding method, and is robust against training mismatches. All of these\nfeatures make it a good candidate for decoding modern channel codes. \n\n"}
{"id": "1707.05944", "contents": "Title: Codes with Locality in the Rank and Subspace Metrics Abstract: We extend the notion of locality from the Hamming metric to the rank and\nsubspace metrics. Our main contribution is to construct a class of array codes\nwith locality constraints in the rank metric. Our motivation for constructing\nsuch codes stems from designing codes for efficient data recovery from\ncorrelated and/or mixed (i.e., complete and partial) failures in distributed\nstorage systems. Specifically, the proposed local rank-metric codes can recover\nlocally from 'crisscross errors and erasures', which affect a limited number of\nrows and/or columns of the storage system. We also derive a Singleton-like\nupper bound on the minimum rank distance of (linear) codes with 'rank-locality'\nconstraints. Our proposed construction achieves this bound for a broad range of\nparameters. The construction builds upon Tamo and Barg's method for\nconstructing locally repairable codes with optimal minimum Hamming distance.\nFinally, we construct a class of constant-dimension subspace codes (also known\nas Grassmannian codes) with locality constraints in the subspace metric. The\nkey idea is to show that a Grassmannian code with locality can be easily\nconstructed from a rank-metric code with locality by using the lifting method\nproposed by Silva et al. We present an application of such codes for\ndistributed storage systems, wherein nodes are connected over a network that\ncan introduce errors and erasures. \n\n"}
{"id": "1707.06260", "contents": "Title: Learning Approximate Neural Estimators for Wireless Channel State\n  Information Abstract: Estimation is a critical component of synchronization in wireless and signal\nprocessing systems. There is a rich body of work on estimator derivation,\noptimization, and statistical characterization from analytic system models\nwhich are used pervasively today. We explore an alternative approach to\nbuilding estimators which relies principally on approximate regression using\nlarge datasets and large computationally efficient artificial neural network\nmodels capable of learning non-linear function mappings which provide compact\nand accurate estimates. For single carrier PSK modulation, we explore the\naccuracy and computational complexity of such estimators compared with the\ncurrent gold-standard analytically derived alternatives. We compare performance\nin various wireless operating conditions and consider the trade offs between\nthe two different classes of systems. Our results show the learned estimators\ncan provide improvements in areas such as short-time estimation and estimation\nunder non-trivial real world channel conditions such as fading or other\nnon-linear hardware or propagation effects. \n\n"}
{"id": "1707.07980", "contents": "Title: Deep Learning Based MIMO Communications Abstract: We introduce a novel physical layer scheme for single user Multiple-Input\nMultiple-Output (MIMO) communications based on unsupervised deep learning using\nan autoencoder. This method extends prior work on the joint optimization of\nphysical layer representation and encoding and decoding processes as a single\nend-to-end task by expanding transmitter and receivers to the multi-antenna\ncase. We introduce a widely used domain appropriate wireless channel impairment\nmodel (Rayleigh fading channel), into the autoencoder optimization problem in\norder to directly learn a system which optimizes for it. We considered both\nspatial diversity and spatial multiplexing techniques in our implementation.\nOur deep learning-based approach demonstrates significant potential for\nlearning schemes which approach and exceed the performance of the methods which\nare widely used in existing wireless MIMO systems. We discuss how the proposed\nscheme can be easily adapted for open-loop and closed-loop operation in spatial\ndiversity and multiplexing modes and extended use with only compact binary\nchannel state information (CSI) as feedback. \n\n"}
{"id": "1707.08089", "contents": "Title: Delay Performance of MISO Wireless Communications Abstract: Ultra-reliable, low latency communications (URLLC) are currently attracting\nsignificant attention due to the emergence of mission-critical applications and\ndevice-centric communication. URLLC will entail a fundamental paradigm shift\nfrom throughput-oriented system design towards holistic designs for guaranteed\nand reliable end-to-end latency. A deep understanding of the delay performance\nof wireless networks is essential for efficient URLLC systems. In this paper,\nwe investigate the network layer performance of multiple-input, single-output\n(MISO) systems under statistical delay constraints. We provide closed-form\nexpressions for MISO diversity-oriented service process and derive\nprobabilistic delay bounds using tools from stochastic network calculus. In\nparticular, we analyze transmit beamforming with perfect and imperfect channel\nknowledge and compare it with orthogonal space-time codes and antenna\nselection. The effect of transmit power, number of antennas, and finite\nblocklength channel coding on the delay distribution is also investigated. Our\nhigher layer performance results reveal key insights of MISO channels and\nprovide useful guidelines for the design of ultra-reliable communication\nsystems that can guarantee the stringent URLLC latency requirements. \n\n"}
{"id": "1707.09132", "contents": "Title: Network Formation in the Sky: Unmanned Aerial Vehicles for Multi-hop\n  Wireless Backhauling Abstract: To reap the benefits of dense small base station (SBS) deployment, innovative\nbackhaul solutions are needed in order to manage scenarios in which high-speed\nground backhaul links are either unavailable or limited in capacity. In this\npaper, a novel backhaul scheme that utilizes unmanned aerial vehicles (UAVs) as\nan on-demand flying network linking ground SBSs and the core network is\nproposed. The design of the aerial backhaul scheme is formulated as a network\nformation game among UAVs that seek to form a multi-hop backhaul network in the\nair. To solve this game, a myopic network formation algorithm which reaches a\npairwise stable network upon convergence, is introduced. The proposed network\nformation algorithm enables the UAVs to form the necessary multi-hop backhaul\nnetwork in a decentralized manner thus adapting the backhaul architecture to\nthe dynamics of the network. Simulation results show that the proposed network\nformation algorithm achieves substantial performance gains in terms of both\nrate and delay reaching, respectively, up to 40% and 41% compared to the\nformation of direct communication links with the gateway node (for a network\nwith 15 UAVs). \n\n"}
{"id": "1707.09132", "contents": "Title: Network Formation in the Sky: Unmanned Aerial Vehicles for Multi-hop\n  Wireless Backhauling Abstract: To reap the benefits of dense small base station (SBS) deployment, innovative\nbackhaul solutions are needed in order to manage scenarios in which high-speed\nground backhaul links are either unavailable or limited in capacity. In this\npaper, a novel backhaul scheme that utilizes unmanned aerial vehicles (UAVs) as\nan on-demand flying network linking ground SBSs and the core network is\nproposed. The design of the aerial backhaul scheme is formulated as a network\nformation game among UAVs that seek to form a multi-hop backhaul network in the\nair. To solve this game, a myopic network formation algorithm which reaches a\npairwise stable network upon convergence, is introduced. The proposed network\nformation algorithm enables the UAVs to form the necessary multi-hop backhaul\nnetwork in a decentralized manner thus adapting the backhaul architecture to\nthe dynamics of the network. Simulation results show that the proposed network\nformation algorithm achieves substantial performance gains in terms of both\nrate and delay reaching, respectively, up to 40% and 41% compared to the\nformation of direct communication links with the gateway node (for a network\nwith 15 UAVs). \n\n"}
{"id": "1708.01398", "contents": "Title: Signal Recovery in Perturbed Fourier Compressed Sensing Abstract: In many applications in compressed sensing, the measurement matrix is a\nFourier matrix, i.e., it measures the Fourier transform of the underlying\nsignal at some specified `base' frequencies $\\{u_i\\}_{i=1}^M$, where $M$ is the\nnumber of measurements. However due to system calibration errors, the system\nmay measure the Fourier transform at frequencies $\\{u_i + \\delta_i\\}_{i=1}^M$\nthat are different from the base frequencies and where $\\{\\delta_i\\}_{i=1}^M$\nare unknown. Ignoring perturbations of this nature can lead to major errors in\nsignal recovery. In this paper, we present a simple but effective alternating\nminimization algorithm to recover the perturbations in the frequencies \\emph{in\nsitu} with the signal, which we assume is sparse or compressible in some known\nbasis. In many cases, the perturbations $\\{\\delta_i\\}_{i=1}^M$ can be expressed\nin terms of a small number of unique parameters $P \\ll M$. We demonstrate that\nin such cases, the method leads to excellent quality results that are several\ntimes better than baseline algorithms (which are based on existing off-grid\nmethods in the recent literature on direction of arrival (DOA) estimation,\nmodified to suit the computational problem in this paper). Our results are also\nrobust to noise in the measurement values. We also provide theoretical results\nfor (1) the convergence of our algorithm, and (2) the uniqueness of its\nsolution under some restrictions. \n\n"}
{"id": "1708.02556", "contents": "Title: Multi-Generator Generative Adversarial Nets Abstract: We propose a new approach to train the Generative Adversarial Nets (GANs)\nwith a mixture of generators to overcome the mode collapsing problem. The main\nintuition is to employ multiple generators, instead of using a single one as in\nthe original GAN. The idea is simple, yet proven to be extremely effective at\ncovering diverse data modes, easily overcoming the mode collapse and delivering\nstate-of-the-art results. A minimax formulation is able to establish among a\nclassifier, a discriminator, and a set of generators in a similar spirit with\nGAN. Generators create samples that are intended to come from the same\ndistribution as the training data, whilst the discriminator determines whether\nsamples are true data or generated by generators, and the classifier specifies\nwhich generator a sample comes from. The distinguishing feature is that\ninternal samples are created from multiple generators, and then one of them\nwill be randomly selected as final output similar to the mechanism of a\nprobabilistic mixture model. We term our method Mixture GAN (MGAN). We develop\ntheoretical analysis to prove that, at the equilibrium, the Jensen-Shannon\ndivergence (JSD) between the mixture of generators' distributions and the\nempirical data distribution is minimal, whilst the JSD among generators'\ndistributions is maximal, hence effectively avoiding the mode collapse. By\nutilizing parameter sharing, our proposed model adds minimal computational cost\nto the standard GAN, and thus can also efficiently scale to large-scale\ndatasets. We conduct extensive experiments on synthetic 2D data and natural\nimage databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior\nperformance of our MGAN in achieving state-of-the-art Inception scores over\nlatest baselines, generating diverse and appealing recognizable objects at\ndifferent resolutions, and specializing in capturing different types of objects\nby generators. \n\n"}
{"id": "1708.02557", "contents": "Title: Overview of Millimeter Wave Communications for Fifth-Generation (5G)\n  Wireless Networks-with a focus on Propagation Models Abstract: This paper provides an overview of the features of fifth generation (5G)\nwireless communication systems now being developed for use in the millimeter\nwave (mmWave) frequency bands. Early results and key concepts of 5G networks\nare presented, and the channel modeling efforts of many international groups\nfor both licensed and unlicensed applications are described here. Propagation\nparameters and channel models for understanding mmWave propagation, such as\nline-of-sight (LOS) probabilities, large-scale path loss, and building\npenetration loss, as modeled by various standardization bodies, are compared\nover the 0.5-100 GHz range. \n\n"}
{"id": "1708.02691", "contents": "Title: Universal Function Approximation by Deep Neural Nets with Bounded Width\n  and ReLU Activations Abstract: This article concerns the expressive power of depth in neural nets with ReLU\nactivations and bounded width. We are particularly interested in the following\nquestions: what is the minimal width $w_{\\text{min}}(d)$ so that ReLU nets of\nwidth $w_{\\text{min}}(d)$ (and arbitrary depth) can approximate any continuous\nfunction on the unit cube $[0,1]^d$ aribitrarily well? For ReLU nets near this\nminimal width, what can one say about the depth necessary to approximate a\ngiven function? Our approach to this paper is based on the observation that,\ndue to the convexity of the ReLU activation, ReLU nets are particularly\nwell-suited for representing convex functions. In particular, we prove that\nReLU nets with width $d+1$ can approximate any continuous convex function of\n$d$ variables arbitrarily well. These results then give quantitative depth\nestimates for the rate of approximation of any continuous scalar function on\nthe $d$-dimensional cube $[0,1]^d$ by ReLU nets with width $d+3.$ \n\n"}
{"id": "1708.03066", "contents": "Title: Design and Optimization of VoD schemes with Client Caching in Wireless\n  Multicast Networks Abstract: Due to the explosive growth in multimedia traffic, the scalability of\nvideo-on-demand (VoD) services becomes increasingly important. By exploiting\nthe potential cache ability at the client side, the performance of VoD\nmulticast delivery can be improved through video segment pre-caching. In this\npaper, we address the performance limits of client caching enabled VoD schemes\nin wireless multicast networks with asynchronous requests. Both reactive and\nproactive systems are investigated. Specifically, for the reactive system where\nvideos are transmitted on demand, we propose a joint cache allocation and\nmulticast delivery scheme to minimize the average bandwidth consumption under\nthe zero-delay constraint. For the proactive system where videos are\nperiodically broadcasted, a joint design of the cache-bandwidth allocation\nalgorithm and the delivery mechanism is developed to minimize the average\nwaiting time under the total bandwidth constraint. In addition to the full\naccess pattern where clients view videos in their entirety, we further consider\nthe access patterns with random endpoints, fixed-size intervals and downloading\ndemand, respectively. The impacts of different access patterns on the\nresource-allocation algorithm and the delivery mechanism are elaborated.\nSimulation results validate the accuracy of the analytical results and also\nprovide useful insights in designing VoD networks with client caching. \n\n"}
{"id": "1708.03309", "contents": "Title: Systematic Testing of Convolutional Neural Networks for Autonomous\n  Driving Abstract: We present a framework to systematically analyze convolutional neural\nnetworks (CNNs) used in classification of cars in autonomous vehicles. Our\nanalysis procedure comprises an image generator that produces synthetic\npictures by sampling in a lower dimension image modification subspace and a\nsuite of visualization tools. The image generator produces images which can be\nused to test the CNN and hence expose its vulnerabilities. The presented\nframework can be used to extract insights of the CNN classifier, compare across\nclassification models, or generate training and validation datasets. \n\n"}
{"id": "1708.05673", "contents": "Title: Linear Symmetric Private Information Retrieval for MDS Coded Distributed\n  Storage with Colluding Servers Abstract: The problem of symmetric private information retrieval (SPIR) from a coded\ndatabase which is distributively stored among colluding servers is studied.\nSpecifically, the database comprises $K$ files, which are stored among $N$\nservers using an $(N,M)$-MDS storage code. A user wants to retrieve one file\nfrom the database by communicating with the $N$ servers, without revealing the\nidentity of the desired file to any server. Furthermore, the user shall learn\nnothing about the other $K-1$ files in the database. In the $T$-colluding SPIR\nproblem (hence called TSPIR), any $T$ out of $N$ servers may collude, that is,\nthey may communicate their interactions with the user to guess the identity of\nthe requested file. We show that for linear schemes, the information-theoretic\ncapacity of the MDS-TSPIR problem, defined as the maximum number of information\nbits of the desired file retrieved per downloaded bit, equals\n$1-\\frac{M+T-1}{N}$, if the servers share common randomness (unavailable at the\nuser) with amount at least $\\frac{M+T-1}{N-M-T+1}$ times the file size.\nOtherwise, the capacity equals zero. We conjecture that our capacity holds also\nfor general MDS-TSPIR schemes. \n\n"}
{"id": "1708.06235", "contents": "Title: Deep Convolutional Neural Networks for Massive MIMO Fingerprint-Based\n  Positioning Abstract: This paper provides an initial investigation on the application of\nconvolutional neural networks (CNNs) for fingerprint-based positioning using\nmeasured massive MIMO channels. When represented in appropriate domains,\nmassive MIMO channels have a sparse structure which can be efficiently learned\nby CNNs for positioning purposes. We evaluate the positioning accuracy of\nstate-of-the-art CNNs with channel fingerprints generated from a channel model\nwith a rich clustered structure: the COST 2100 channel model. We find that\nmoderately deep CNNs can achieve fractional-wavelength positioning accuracies,\nprovided that an enough representative data set is available for training. \n\n"}
{"id": "1708.06394", "contents": "Title: Expressions for the Entropy of Binomial-Type Distributions Abstract: We develop a general method for computing logarithmic and log-gamma\nexpectations of distributions. As a result, we derive series expansions and\nintegral representations of the entropy for several fundamental distributions,\nincluding the Poisson, binomial, beta-binomial, negative binomial, and\nhypergeometric distributions. Our results also establish connections between\nthe entropy functions and to the Riemann zeta function and its generalizations. \n\n"}
{"id": "1708.06478", "contents": "Title: Trajectory Optimization for Completion Time Minimization in UAV-Enabled\n  Multicasting Abstract: This paper studies an unmanned aerial vehicle (UAV)-enabled multicasting\nsystem, where a UAV is dispatched to disseminate a common file to a number of\ngeographically distributed ground terminals (GTs). Our objective is to design\nthe UAV trajectory to minimize its mission completion time, while ensuring that\neach GT is able to successfully recover the file with a high probability\nrequired. We consider the use of practical random linear network coding (RLNC)\nfor UAV multicasting, so that each GT is able to recover the file as long as it\nreceives a sufficiently large number of coded packets. However, the formulated\nUAV trajectory optimization problem is non-convex and difficult to be directly\nsolved. To tackle this issue, we first derive an analytical lower bound for the\nsuccess probability of each GT's file recovery. Based on this result, we then\nreformulate the problem into a more tractable form, where the UAV trajectory\nonly needs to be designed to meet a set of constraints each on the minimum\nconnection time with a GT, during which their distance is below a designed\nthreshold. We show that the optimal UAV trajectory only needs to constitute\nconnected line segments, thus it can be obtained by determining first the\noptimal set of waypoints and then UAV speed along the lines connecting the\nwaypoints. We propose practical schemes for the waypoints design based on a\nnovel concept of virtual base station (VBS) placement and by applying convex\noptimization techniques. Furthermore, for given set of waypoints, we obtain the\noptimal UAV speed over the resulting path efficiently by solving a linear\nprogramming (LP) problem. Numerical results show that the proposed UAV-enabled\nmulticasting with optimized trajectory design achieves significant performance\ngains as compared to benchmark schemes. \n\n"}
{"id": "1708.07451", "contents": "Title: Recovering Structured Data From Superimposed Non-Linear Measurements Abstract: This work deals with the problem of distributed data acquisition under\nnon-linear communication constraints. More specifically, we consider a model\nsetup where $M$ distributed nodes take individual measurements of an unknown\nstructured source vector $x_0 \\in \\mathbb{R}^n$, communicating their readings\nsimultaneously to a central receiver. Since this procedure involves collisions\nand is usually imperfect, the receiver measures a superposition of non-linearly\ndistorted signals. In a first step, we will show that an $s$-sparse vector\n$x_0$ can be successfully recovered from $O(s \\cdot\\log(2n/s))$ of such\nsuperimposed measurements, using a traditional Lasso estimator that does not\nrely on any knowledge about the non-linear corruptions. This direct method\nhowever fails to work for several \"uncalibrated\" system configurations. These\nblind reconstruction tasks can be easily handled with the\n$\\ell^{1,2}$-Group-Lasso, but coming along with an increased sampling rate of\n$O(s\\cdot \\max\\{M, \\log(2n/s) \\})$ observations - in fact, the purpose of this\nlifting strategy is to extend a certain class of bilinear inverse problems to\nnon-linear acquisition. Our two algorithmic approaches are a special instance\nof a more abstract framework which includes sub-Gaussian measurement designs as\nwell as general (convex) structural constraints. These results are of\nindependent interest for various recovery and learning tasks, as they apply to\narbitrary non-linear observation models. Finally, to illustrate the practical\nscope of our theoretical findings, an application to wireless sensor networks\nis discussed, which actually serves as the prototypical example of our\nmethodology. \n\n"}
{"id": "1708.07862", "contents": "Title: Wireless Access for Ultra-Reliable Low-Latency Communication (URLLC):\n  Principles and Building Blocks Abstract: Ultra-reliable low latency communication (URLLC) is an important new feature\nbrought by 5G, with a potential to support a vast set of applications that rely\non mission-critical links. In this article, we first discuss the principles for\nsupporting URLLC from the perspective of the traditional assumptions and models\napplied in communication/information theory. We then discuss how these\nprinciples are applied in various elements of the system design, such as use of\nvarious diversity sources, design of packets and access protocols. The\nimportant messages are that there is a need to optimize the transmission of\nsignaling information, as well as a need for a lean use of various sources of\ndiversity. \n\n"}
{"id": "1708.08438", "contents": "Title: Nearest-Neighbor and Contact Distance Distributions for Matern Cluster\n  Process Abstract: In this letter, we derive the cumulative density function (CDF) of the\nnearest neighbor and contact distance distributions of the Matern cluster\nprocess (MCP) in R2. These results will be useful in the performance analysis\nof many real-world wireless networks that exhibit inter-node attraction. Using\nthese results, we concretely demonstrate that the contact distance of the MCP\nstochastically dominates its nearest-neighbor distance as well as the contact\ndistance of the homogeneous Poisson point process (PPP) with the same density. \n\n"}
{"id": "1708.09410", "contents": "Title: Secure Communications for the Two-user Broadcast Channel with Random\n  Traffic Abstract: In this work, we study the stability region of the two-user broadcast channel\n(BC) with bursty data arrivals and security constraints. We consider the\nscenario, where one of the receivers has a secrecy constraint and its packets\nneed to be kept secret from the other receiver. This is achieved by employing\nfull-duplexing at the receiver with the secrecy constraint, so that it\ntransmits a jamming signal to impede the reception of the other receiver. In\nthis context, the stability region of the two-user BC is characterized for the\ngeneral decoding case. Then, assuming two different decoding schemes the\nrespective stability regions are derived. The effect of self-interference due\nto the full-duplex operation on the stability region is also investigated. The\nstability region of the BC with a secrecy constraint, where the receivers do\nnot have full duplex capability can be obtained as a special case of the\nresults derived in this paper. In addition, the paper considers the problem of\nmaximizing the saturated throughput of the queue, whose packets does not\nrequire to be kept secret under minimum service guarantees for the other queue.\nThe results provide new insights on the effect of the secrecy constraint on the\nstability region of the BC. In particular, it is shown that the stability\nregion with secrecy constraint is sensitive to the coefficient of\nself-interference cancelation under certain cases. \n\n"}
{"id": "1709.01440", "contents": "Title: Locality-Aware Hybrid Coded MapReduce for Server-Rack Architecture Abstract: MapReduce is a widely used framework for distributed computing. Data\nshuffling between the Map phase and Reduce phase of a job involves a large\namount of data transfer across servers, which in turn accounts for increase in\njob completion time. Recently, Coded MapReduce has been proposed to offer\nsavings with respect to the communication cost incurred in data shuffling. This\nis achieved by creating coded multicast opportunities for shuffling through\nrepeating Map tasks at multiple servers. We consider a server-rack architecture\nfor MapReduce and in this architecture, propose to divide the total\ncommunication cost into two: intra-rack communication cost and cross-rack\ncommunication cost. Having noted that cross-rack data transfer operates at\nlower speed as compared to intra-rack data transfer, we present a scheme termed\nas Hybrid Coded MapReduce which results in lower cross-rack communication than\nCoded MapReduce at the cost of increase in intra-rack communication. In\naddition, we pose the problem of assigning Map tasks to servers to maximize\ndata locality in the framework of Hybrid Coded MapReduce as a constrained\ninteger optimization problem. We show through simulations that data locality\ncan be improved considerably by using the solution of optimization to assign\nMap tasks to servers. \n\n"}
{"id": "1709.01447", "contents": "Title: Conditional independence testing based on a nearest-neighbor estimator\n  of conditional mutual information Abstract: Conditional independence testing is a fundamental problem underlying causal\ndiscovery and a particularly challenging task in the presence of nonlinear and\nhigh-dimensional dependencies. Here a fully non-parametric test for continuous\ndata based on conditional mutual information combined with a local permutation\nscheme is presented. Through a nearest neighbor approach, the test efficiently\nadapts also to non-smooth distributions due to strongly nonlinear dependencies.\nNumerical experiments demonstrate that the test reliably simulates the null\ndistribution even for small sample sizes and with high-dimensional conditioning\nsets. The test is better calibrated than kernel-based tests utilizing an\nanalytical approximation of the null distribution, especially for non-smooth\ndensities, and reaches the same or higher power levels. Combining the local\npermutation scheme with the kernel tests leads to better calibration, but\nsuffers in power. For smaller sample sizes and lower dimensions, the test is\nfaster than random fourier feature-based kernel tests if the permutation scheme\nis (embarrassingly) parallelized, but the runtime increases more sharply with\nsample size and dimensionality. Thus, more theoretical research to analytically\napproximate the null distribution and speed up the estimation for larger sample\nsizes is desirable. \n\n"}
{"id": "1709.02427", "contents": "Title: Status Updates Through Multicast Networks Abstract: Using age of information as the freshness metric, we examine a multicast\nnetwork in which real-time status updates are generated by the source and sent\nto a group of $n$ interested receivers. We show that in order to keep the\ninformation freshness at each receiver, the source should terminate the\ntransmission of the current update and start sending a new update packet as\nsoon as it receives the acknowledgements back from any $k$ out of $n$ nodes. As\nthe source stopping threshold $k$ increases, a node is more likely to get the\nlatest generated update, but the age of the most recent update is more likely\nto become outdated. We derive the age minimized stopping threshold $k$ that\nbalances the likelihood of getting the latest update and the freshness of the\nlatest update for shifted exponential link delay. Through numerical evaluations\nfor different stopping strategies, we find that waiting for the\nacknowledgements from the earliest $k$ out of $n$ nodes leads to lower average\nage than waiting for a pre-selected group of $k$ nodes. We also observe that a\nproperly chosen threshold $k$ can prevent information staleness for increasing\nnumber of nodes $n$ in the multicast network. \n\n"}
{"id": "1709.06762", "contents": "Title: Transfer learning from synthetic to real images using variational\n  autoencoders for robotic applications Abstract: Robotic learning in simulation environments provides a faster, more scalable,\nand safer training methodology than learning directly with physical robots.\nAlso, synthesizing images in a simulation environment for collecting\nlarge-scale image data is easy, whereas capturing camera images in the real\nworld is time consuming and expensive. However, learning from only synthetic\nimages may not achieve the desired performance in real environments due to the\ngap between synthetic and real images. We thus propose a method that transfers\nlearned capability of detecting object position from a simulation environment\nto the real world. Our method enables us to use only a very limited dataset of\nreal images while leveraging a large dataset of synthetic images using multiple\nvariational autoencoders. It detects object positions 6 to 7 times more\nprecisely than the baseline of directly learning from the dataset of the real\nimages. Object position estimation under varying environmental conditions forms\none of the underlying requirement for standard robotic manipulation tasks. We\nshow that the proposed method performs robustly in different lighting\nconditions or with other distractor objects present for this requirement. Using\nthis detected object position, we transfer pick-and-place or reaching tasks\nlearned in a simulation environment to an actual physical robot without\nre-training. \n\n"}
{"id": "1709.08223", "contents": "Title: Numerical solution of stochastic master equations using stochastic\n  interacting wave functions Abstract: We develop a new approach for solving stochastic quantum master equations\nwith mixed initial states. First, we obtain that the solution of the\njump-diffusion stochastic master equation is represented by a mixture of pure\nstates satisfying a system of stochastic differential equations of\nSchr\\\"odinger type. Then, we design three exponential schemes for these coupled\nstochastic Schr\\\"odinger equations, which are driven by Brownian motions and\njump processes. Hence, we have constructed efficient numerical methods for the\nstochastic master equations based on quantum trajectories. The good performance\nof the new numerical integrators is illustrated by simulations of two quantum\nmeasurement processes. \n\n"}
{"id": "1709.08265", "contents": "Title: Any strongly controllable group system or group shift or any linear\n  block code is a linear system whose input is a generator group Abstract: Consider any sequence of finite groups $A^t$, where $t$ takes values in an\ninteger index set $\\mathbf{Z}$. A group system $A$ is a set of sequences with\ncomponents in $A^t$ that forms a group under componentwise addition in $A^t$,\nfor each $t\\in\\mathbf{Z}$. In the setting of group systems, a natural\ndefinition of a linear system is a homomorphism from a group of inputs to an\noutput group system $A$. We show that any group can be the input group of a\nlinear system and some group system. In general the kernel of the homomorphism\nis nontrivial. We show that any $\\ell$-controllable complete group system $A$\nis a linear system whose input group is a generator group\n$({\\mathcal{U}},\\circ)$, deduced from $A$, and then the kernel is always\ntrivial. The input set ${\\mathcal{U}}$ is a set of tensors, a double Cartesian\nproduct space of sets $R_{0,k}^t$, with indices $k$, for $0\\le k\\le\\ell$, and\ntime $t$, for $t\\in\\mathbf{Z}$. $R_{0,k}^t$ is a set of unique generator labels\nfor the generators in $A$ with nontrivial span for the time interval $[t,t+k]$.\nWe show the generator group contains an elementary system, an infinite\ncollection of elementary groups, one for each $k$ and $t$, defined on small\nsubsets of ${\\mathcal{U}}$, in the shape of triangles, which form a tile like\nstructure over ${\\mathcal{U}}$. There is a homomorphism from each elementary\ngroup to any elementary group defined on smaller tiles of the former group. Any\nelementary system is sufficient to define a unique generator group up to\nisomorphism, and therefore is sufficient to construct a linear system and group\nsystem as well. Any linear block code is a strongly controllable group system.\nThen we can obtain new results on the structure of block codes using the\ngenerator group. There is a harmonic theory of group systems which we study\nusing the generator group. \n\n"}
{"id": "1709.08577", "contents": "Title: Coverage Analysis of a Vehicular Network Modeled as Cox Process Driven\n  by Poisson Line Process Abstract: In this paper, we consider a vehicular network in which the wireless nodes\nare located on a system of roads. We model the roadways, which are\npredominantly straight and randomly oriented, by a Poisson line process (PLP)\nand the locations of nodes on each road as a homogeneous 1D Poisson point\nprocess (PPP). Assuming that each node transmits independently, the locations\nof transmitting and receiving nodes are given by two Cox processes driven by\nthe same PLP. For this setup, we derive the coverage probability of a typical\nreceiver, which is an arbitrarily chosen receiving node, assuming independent\nNakagami-$m$ fading over all wireless channels. Assuming that the typical\nreceiver connects to its closest transmitting node in the network, we first\nderive the distribution of the distance between the typical receiver and the\nserving node to characterize the desired signal power. We then characterize\ncoverage probability for this setup, which involves two key technical\nchallenges. First, we need to handle several cases as the serving node can\npossibly be located on any line in the network and the corresponding\ninterference experienced at the typical receiver is different in each case.\nSecond, conditioning on the serving node imposes constraints on the spatial\nconfiguration of lines, which require careful analysis of the conditional\ndistribution of the lines. We address these challenges in order to accurately\ncharacterize the interference experienced at the typical receiver. We then\nderive an exact expression for coverage probability in terms of the derivative\nof Laplace transform of interference power distribution. We analyze the trends\nin coverage probability as a function of the network parameters: line density\nand node density. We also study the asymptotic behavior of this model and\ncompare the coverage performance with that of a homogeneous 2D PPP model with\nthe same node density. \n\n"}
{"id": "1710.00395", "contents": "Title: Channel Hardening and Favorable Propagation in Cell-Free Massive MIMO\n  with Stochastic Geometry Abstract: Cell-Free (CF) Massive MIMO is an alternative topology for future wireless\nnetworks, where a large number of single-antenna access points (APs) are\ndistributed over the coverage area. There are no cells but all users are\njointly served by the APs using network MIMO methods. Prior works have claimed\nthat CF Massive MIMO inherits the basic properties of cellular Massive MIMO,\nnamely channel hardening and favorable propagation. In this paper, we evaluate\nif one can rely on these properties when having a realistic stochastic AP\ndeployment. Our results show that channel hardening only appears in special\ncases, for example, when the pathloss exponent is small. However, by using\n5--10 antennas per AP, instead of one, we can substantially improve the\nhardening. Only spatially well-separated users will exhibit favorable\npropagation, but when adding more antennas and/or reducing the pathloss\nexponent, it becomes more likely for favorable propagation to occur. The\nconclusion is that we cannot rely on channel hardening and favorable\npropagation when analyzing and designing CF Massive MIMO networks, but we need\nto use achievable rate expressions and resource allocation schemes that work\nwell also in the absence of these properties. Some options are reviewed in this\npaper. \n\n"}
{"id": "1710.01381", "contents": "Title: Generalized Colonel Blotto Game Abstract: Competitive resource allocation between adversarial decision makers arises in\na wide spectrum of real-world applications such as in communication systems,\ncyber-physical systems security, as well as financial, political, and electoral\ncompetition. As such, developing analytical tools to model and analyze\ncompetitive resource allocation is crucial for devising optimal allocation\nstrategies and anticipating the potential outcomes of the competition. To this\nend, the Colonel Blotto game is one of the most popular game-theoretic\nframeworks for modeling and analyzing such competitive resource allocation\nproblems. However, in many real-world competitive situations, the Colonel\nBlotto game does not admit solutions in deterministic strategies and, hence,\none must rely on analytically complex mixed-strategies with their associated\ntractability, applicability, and practicality challenges. In this paper, a\ngeneralization of the Colonel Blotto game which enables the derivation of\ndeterministic, practical, and implementable equilibrium strategies is proposed\nwhile accounting for the heterogeneity of the battlefields. In addition, the\nproposed generalized game enables accounting for the consumed resources in each\nbattlefield, a feature that is not considered in the classical Blotto game. For\nthe generalized game, the existence of a Nash equilibrium in pure-strategies is\nshown. Then, closed-form analytical expressions of the equilibrium strategies,\nare derived and the outcome of the game is characterized; based on the number\nof resources of each player as well as the valuation of each battlefield. The\ngenerated results provide invaluable insights on the outcome of the\ncompetition. For example, the results show that, when both players are fully\nrational, the more resourceful player can achieve a better total payoff at the\nNash equilibrium, a result that is not mimicked in the classical Blotto game. \n\n"}
{"id": "1710.01767", "contents": "Title: Eigenspace-Based Minimum Variance Adaptive Beamformer Combined with\n  Delay Multiply and Sum: Experimental Study Abstract: Delay and sum (DAS) is the most common beamforming algorithm in linear-array\nphotoacoustic imaging (PAI) as a result of its simple implementation. However,\nit leads to a low resolution and high sidelobes. Delay multiply and sum (DMAS)\nwas used to address the incapabilities of DAS, providing a higher image\nquality. However, the resolution improvement is not well enough compared to\neigenspace-based minimum variance (EIBMV). In this paper, the EIBMV beamformer\nhas been combined with DMAS algebra, called EIBMV-DMAS, using the expansion of\nDMAS algorithm. The proposed method is used as the reconstruction algorithm in\nlinear-array PAI. EIBMV-DMAS is experimentally evaluated where the quantitative\nand qualitative results show that it outperforms DAS, DMAS and EIBMV. The\nproposed method degrades the sidelobes for about 365 %, 221 % and 40 %,\ncompared to DAS, DMAS and EIBMV, respectively. Moreover, EIBMV-DMAS improves\nthe SNR about 158 %, 63 % and 20 %, respectively. \n\n"}
{"id": "1710.01816", "contents": "Title: Source Coding Optimization for Distributed Average Consensus Abstract: Consensus is a common method for computing a function of the data distributed\namong the nodes of a network. Of particular interest is distributed average\nconsensus, whereby the nodes iteratively compute the sample average of the data\nstored at all the nodes of the network using only near-neighbor communications.\nIn real-world scenarios, these communications must undergo quantization, which\nintroduces distortion to the internode messages. In this thesis, a model for\nthe evolution of the network state statistics at each iteration is developed\nunder the assumptions of Gaussian data and additive quantization error. It is\nshown that minimization of the communication load in terms of aggregate source\ncoding rate can be posed as a generalized geometric program, for which an\nequivalent convex optimization can efficiently solve for the global minimum.\nOptimization procedures are developed for rate-distortion-optimal vector\nquantization, uniform entropy-coded scalar quantization, and fixed-rate uniform\nquantization. Numerical results demonstrate the performance of these\napproaches. For small numbers of iterations, the fixed-rate optimizations are\nverified using exhaustive search. Comparison to the prior art suggests\ncompetitive performance under certain circumstances but strongly motivates the\nincorporation of more sophisticated coding strategies, such as differential,\npredictive, or Wyner-Ziv coding. \n\n"}
{"id": "1710.02849", "contents": "Title: Fast Polarization for Processes with Memory Abstract: Fast polarization is crucial for the performance guarantees of polar codes.\nIn the memoryless setting, the rate of polarization is known to be exponential\nin the square root of the block length. A complete characterization of the rate\nof polarization for models with memory has been missing. Namely, previous works\nhave not addressed fast polarization of the high entropy set under memory. We\nconsider polar codes for processes with memory that are characterized by an\nunderlying ergodic finite-state Markov chain. We show that the rate of\npolarization for these processes is the same as in the memoryless setting, both\nfor the high and for the low entropy sets. \n\n"}
{"id": "1710.02913", "contents": "Title: Artificial Neural Networks-Based Machine Learning for Wireless Networks:\n  A Tutorial Abstract: Next-generation wireless networks must support ultra-reliable, low-latency\ncommunication and intelligently manage a massive number of Internet of Things\n(IoT) devices in real-time, within a highly dynamic environment. This need for\nstringent communication quality-of-service (QoS) requirements as well as mobile\nedge and core intelligence can only be realized by integrating fundamental\nnotions of artificial intelligence (AI) and machine learning across the\nwireless infrastructure and end-user devices. In this context, this paper\nprovides a comprehensive tutorial that introduces the main concepts of machine\nlearning, in general, and artificial neural networks (ANNs), in particular, and\ntheir potential applications in wireless communications. For this purpose, we\npresent a comprehensive overview on a number of key types of neural networks\nthat include feed-forward, recurrent, spiking, and deep neural networks. For\neach type of neural network, we present the basic architecture and training\nprocedure, as well as the associated challenges and opportunities. Then, we\nprovide an in-depth overview on the variety of wireless communication problems\nthat can be addressed using ANNs, ranging from communication using unmanned\naerial vehicles to virtual reality and edge caching.For each individual\napplication, we present the main motivation for using ANNs along with the\nassociated challenges while also providing a detailed example for a use case\nscenario and outlining future works that can be addressed using ANNs. In a\nnutshell, this article constitutes one of the first holistic tutorials on the\ndevelopment of machine learning techniques tailored to the needs of future\nwireless networks. \n\n"}
{"id": "1710.03287", "contents": "Title: One-bit compressed sensing with partial Gaussian circulant matrices Abstract: In this paper we consider memoryless one-bit compressed sensing with randomly\nsubsampled Gaussian circulant matrices. We show that in a small sparsity regime\nand for small enough accuracy $\\delta$, $m\\sim \\delta^{-4} s\\log(N/s\\delta)$\nmeasurements suffice to reconstruct the direction of any $s$-sparse vector up\nto accuracy $\\delta$ via an efficient program. We derive this result by proving\nthat partial Gaussian circulant matrices satisfy an $\\ell_1/\\ell_2$\nRIP-property. Under a slightly worse dependence on $\\delta$, we establish\nstability with respect to approximate sparsity, as well as full vector recovery\nresults. \n\n"}
{"id": "1710.05136", "contents": "Title: Probabilistic representation of weak solutions to a parabolic boundary\n  value problem on a non-smooth domain Abstract: The probabilistic representation of weak solutions to a parabolic boundary\nvalue problem is established in the following framework. The boundary value\nproblem consists of a second order parabolic equation defined on a time-varying\nLipschitz domain in a Euclidean space and of a mixed boundary condition\ncomposed of a Robin and the homogeneous Dirichlet conditions. It is assumed\nthat the time-varying domain is included in a fixed smooth domain and that a\ncertain part of the boundary of the time-varying domain is also included in the\nboundary of the fixed domain, say the fixed boundary. The Robin condition is\nimposed on a part of the boundary included in the fixed one and the Dirichlet\ncondition on the rest of the boundary. Such a parabolic boundary value problem\nalways has a unique weak solution for given data; however it does not possess a\nclassical or strong solution in general, even in the case of equations with\nconstant coefficients. The stochastic solution to the boundary value problem is\nalso considered and, by showing the equality between both the solutions, it is\nobtained the probabilistic representation for the weak solution. Furthermore,\nit is ensured that, for the weak solution, the stochastic solution gives a\nversion which is continuous up to the lateral boundary of the domain except the\nborder of the adjoining place imposed each of the boundary conditions. As an\napplication, it is shown the continuity property of a functional (cost\nfunction) related to an optimal stopping problem motivated by an inverse\nproblem determining the shape of a domain. \n\n"}
{"id": "1710.05234", "contents": "Title: Phase Retrieval via Linear Programming: Fundamental Limits and\n  Algorithmic Improvements Abstract: A recently proposed convex formulation of the phase retrieval problem\nestimates the unknown signal by solving a simple linear program. This new\nscheme, known as PhaseMax, is computationally efficient compared to standard\nconvex relaxation methods based on lifting techniques. In this paper, we\npresent an exact performance analysis of PhaseMax under Gaussian measurements\nin the large system limit. In contrast to previously known performance bounds\nin the literature, our results are asymptotically exact and they also reveal a\nsharp phase transition phenomenon. Furthermore, the geometrical insights gained\nfrom our analysis led us to a novel nonconvex formulation of the phase\nretrieval problem and an accompanying iterative algorithm based on successive\nlinearization and maximization over a polytope. This new algorithm, which we\ncall PhaseLamp, has provably superior recovery performance over the original\nPhaseMax method. \n\n"}
{"id": "1710.06451", "contents": "Title: A Bayesian Perspective on Generalization and Stochastic Gradient Descent Abstract: We consider two questions at the heart of machine learning; how can we\npredict if a minimum will generalize to the test set, and why does stochastic\ngradient descent find minima that generalize well? Our work responds to Zhang\net al. (2016), who showed deep neural networks can easily memorize randomly\nlabeled training data, despite generalizing well on real labels of the same\ninputs. We show that the same phenomenon occurs in small linear models. These\nobservations are explained by the Bayesian evidence, which penalizes sharp\nminima but is invariant to model parameterization. We also demonstrate that,\nwhen one holds the learning rate fixed, there is an optimum batch size which\nmaximizes the test set accuracy. We propose that the noise introduced by small\nmini-batches drives the parameters towards minima whose evidence is large.\nInterpreting stochastic gradient descent as a stochastic differential equation,\nwe identify the \"noise scale\" $g = \\epsilon (\\frac{N}{B} - 1) \\approx \\epsilon\nN/B$, where $\\epsilon$ is the learning rate, $N$ the training set size and $B$\nthe batch size. Consequently the optimum batch size is proportional to both the\nlearning rate and the size of the training set, $B_{opt} \\propto \\epsilon N$.\nWe verify these predictions empirically. \n\n"}
{"id": "1710.08214", "contents": "Title: Parametric channel estimation for massive MIMO Abstract: Channel state information is crucial to achieving the capacity of\nmulti-antenna (MIMO) wireless communication systems. It requires estimating the\nchannel matrix. This estimation task is studied, considering a sparse channel\nmodel particularly suited to millimeter wave propagation, as well as a general\nmeasurement model taking into account hybrid architectures. The contribution is\ntwofold. First, the Cram{\\'e}r-Rao bound in this context is derived. Second,\ninterpretation of the Fisher Information Matrix structure allows to assess the\nrole of system parameters, as well as to propose asymptotically optimal and\ncomputationally efficient estimation algorithms. \n\n"}
{"id": "1710.09275", "contents": "Title: On the Capacity of Cloud Radio Access Networks with Oblivious Relaying Abstract: We study the transmission over a network in which users send information to a\nremote destination through relay nodes that are connected to the destination\nvia finite-capacity error-free links, i.e., a cloud radio access network. The\nrelays are constrained to operate without knowledge of the users' codebooks,\ni.e., they perform oblivious processing. The destination, or central processor,\nhowever, is informed about the users' codebooks. We establish a single-letter\ncharacterization of the capacity region of this model for a class of discrete\nmemoryless channels in which the outputs at the relay nodes are independent\ngiven the users' inputs. We show that both relaying \\`a-la Cover-El Gamal,\ni.e., compress-and-forward with joint decompression and decoding, and \"noisy\nnetwork coding\", are optimal. The proof of the converse part establishes, and\nutilizes, connections with the Chief Executive Officer (CEO) source coding\nproblem under logarithmic loss distortion measure. Extensions to general\ndiscrete memoryless channels are also investigated. In this case, we establish\ninner and outer bounds on the capacity region. For memoryless Gaussian channels\nwithin the studied class of channels, we characterize the capacity region when\nthe users are constrained to time-share among Gaussian codebooks. Furthermore,\nwe also discuss the suboptimality of separate decompression-decoding and the\nrole of time-sharing. \n\n"}
{"id": "1710.10389", "contents": "Title: Blocking Probability and Spatial Throughput Characterization for\n  Cellular-Enabled UAV Network with Directional Antenna Abstract: The past few years have witnessed a tremendous increase on the use of\nunmanned aerial vehicles (UAVs) in civilian applications, which call for\nhigh-performance communication between UAVs and their ground clients,\nespecially when they are densely deployed. To achieve this goal, cellular base\nstations (BSs) can be leveraged to provide a new and promising solution to\nsupport massive UAV communications simultaneously in a cost-effective way.\nHowever, different from terrestrial communication channels, UAV-to-BS channels\nare usually dominated by the light-of-sight (LoS) link, which aggravates the\nco-channel interference and renders the spatial frequency reuse in existing\ncellular networks ineffective. In this paper, we consider the use of a\ndirectional antenna at each UAV to confine the interference to/from other UAV\nusers within a limited region and hence improve the spatial reuse of the\nspectrum. Under this model, a UAV user may be temporarily blocked from\ncommunication if it cannot find any BS in its antenna main-lobe, or it finds\nthat all BSs under its main-lobe are simultaneously covered by those of some\nother UAVs and hence suffer from strong co-channel interference. Assuming\nindependent homogeneous Poisson point processes (HPPPs) for the UAVs' and\nground BSs' locations respectively, we first analytically derive a closed-form\nupper bound for the UAV blocking probability and then characterize the\nachievable average spatial throughput of the cellular-enabled UAV communication\nnetwork, in terms of various key parameters including the BS/UAV densities as\nwell as the UAV's flying altitude and antenna beamwidth. Simulation results\nverify that the derived bound is practically tight, and further show that\nadaptively adjusting the UAV altitude and/or beamwidth with different BS/UAV\ndensities can significantly reduce the UAV blocking probability and hence\nimprove the network spatial throughput. \n\n"}
{"id": "1710.11404", "contents": "Title: Reshaping Cellular Networks for the Sky: Major Factors and Feasibility Abstract: This paper studies the feasibility of supporting drone operations using\nexistent cellular infrastructure. We propose an analytical framework that\nincludes the effects of base station (BS) height and antenna radiation pattern,\ndrone antenna directivity and various propagation environments. With this\nframework, we derive an exact expression for the coverage probability of ground\nand drone users through a practical cell association strategy. Our results show\nthat a carefully designed network can control the radiated interference that is\nreceived by the drones, and therefore guarantees a satisfactory quality of\nservice. Moreover, as the network density grows the increasing level of\ninterference can be partially managed by lowering the drone flying altitude.\nHowever, even at optimal conditions the drone coverage performance converges to\nzero considerably fast, suggesting that ultra-dense networks might be poor\ncandidates for serving aerial users. \n\n"}
{"id": "1711.00625", "contents": "Title: Decentralized Deep Scheduling for Interference Channels Abstract: In this paper, we study the problem of decentralized scheduling in\nInterference Channels (IC). In this setting, each Transmitter (TX) receives an\narbitrary amount of feedback regarding the global multi-user channel state\nbased on which it decides whether to transmit or to stay silent without any\nform of communication with the other TXs. While many methods have been proposed\nto tackle the problem of link scheduling in the presence of reliable Channel\nState Information (CSI), finding the optimally robust transmission strategy in\nthe presence of arbitrary channel uncertainties at each TX has remained elusive\nfor the past years. In this work, we recast the link scheduling problem as a\ndecentralized classification problem and we propose the use of Collaborative\nDeep Neural Networks (C-DNNs) to solve this problem. After adequate training,\nthe scheduling obtained using the C-DNNs flexibly adapts to the decentralized\nCSI configuration to outperform other scheduling algorithms. \n\n"}
{"id": "1711.01007", "contents": "Title: Wireless Network Simplification: The Performance of Routing Abstract: Consider a wireless Gaussian network where a source wishes to communicate\nwith a destination with the help of N full-duplex relay nodes. Most practical\nsystems today route information from the source to the destination using the\nbest path that connects them. In this paper, we show that routing can in the\nworst case result in an unbounded gap from the network capacity - or reversely,\nphysical layer cooperation can offer unbounded gains over routing. More\nspecifically, we show that for $N$-relay Gaussian networks with an arbitrary\ntopology, routing can in the worst case guarantee an approximate fraction\n$\\frac{1}{\\left\\lfloor N/2 \\right\\rfloor + 1}$ of the capacity of the full\nnetwork, independently of the SNR regime. We prove that this guarantee is\nfundamental, i.e., it is the highest worst-case guarantee that we can provide\nfor routing in relay networks. Next, we consider how these guarantees are\nrefined for Gaussian layered relay networks with $L$ layers and $N_L$ relays\nper layer. We prove that for arbitrary $L$ and $N_L$, there always exists a\nroute in the network that approximately achieves at least $\\frac{2}{(L-1)N_L +\n4}$ $\\left(\\mbox{resp.}\\frac{2}{LN_L+2}\\right)$ of the network capacity for odd\n$L$ (resp. even $L$), and there exist networks where the best routes exactly\nachieve these fractions. These results are formulated within the network\nsimplification framework, that asks what fraction of the capacity we can\nachieve by using a subnetwork (in our case, a single path). A fundamental step\nin our proof is a simplification result for MIMO antenna selection that may\nalso be of independent interest. To the best of our knowledge, this is the\nfirst result that characterizes, for general wireless network topologies, what\nis the performance of routing with respect to physical layer cooperation\ntechniques that approximately achieve the network capacity. \n\n"}
{"id": "1711.03364", "contents": "Title: Multi-antenna Interference Management for Coded Caching Abstract: A multi-antenna broadcast channel scenario is considered where a base station\ndelivers contents to cache-enabled user terminals. A joint design of coded\ncaching (CC) and multigroup multicast beamforming is proposed to benefit from\nspatial multiplexing gain, improved interference management and the global CC\ngain, simultaneously. The developed general content delivery strategies utilize\nthe multiantenna multicasting opportunities provided by the CC technique while\noptimally balancing the detrimental impact of both noise and inter-stream\ninterference from coded messages transmitted in parallel. Flexible resource\nallocation schemes for CC are introduced where the multicast beamformer design\nand the receiver complexity are controlled by varying the size of the subset of\nusers served during a given time interval, and the overlap among the multicast\nmessages transmitted in parallel, indicated by parameters $\\alpha$ and $\\beta$,\nrespectively. Degrees of freedom (DoF) analysis is provided showing that the\nDoF only depends on $\\alpha$ while it is independent of $\\beta$. The proposed\nschemes are shown to provide the same degrees-of-freedom at high\nsignal-to-noise ratio (SNR) as the state-of-art methods and, in general, to\nperform significantly better, especially in the finite SNR regime, than several\nbaseline schemes. \n\n"}
{"id": "1711.03784", "contents": "Title: Z2Z4-Additive Cyclic Codes: Kernel and Rank Abstract: A Z2Z4-additive code C subset of Z_2^alpha x Z_4^beta is called cyclic if the\nset of coordinates can be partitioned into two subsets, the set of Z_2 and the\nset of Z_4 coordinates, such that any cyclic shift of the coordinates of both\nsubsets leaves the code invariant. Let Phi(C) be the binary Gray image of C. We\nstudy the rank and the dimension of the kernel of a Z2Z4-additive cyclic code\nC, that is, the dimensions of the binary linear codes <Phi(C)> and ker(Phi(C)).\nWe give upper and lower bounds for these parameters. It is known that the codes\n<Phi(C)> and ker(Phi(C)) are binary images of Z2Z4-additive codes R(C) and\nK(C), respectively. Moreover, we show that R(C) and K(C) are also cyclic and we\ndetermine the generator polynomials of these codes in terms of the generator\npolynomials of the code C. \n\n"}
{"id": "1711.04819", "contents": "Title: Uncertainty quantification for radio interferometric imaging: II. MAP\n  estimation Abstract: Uncertainty quantification is a critical missing component in radio\ninterferometric imaging that will only become increasingly important as the\nbig-data era of radio interferometry emerges. Statistical sampling approaches\nto perform Bayesian inference, like Markov Chain Monte Carlo (MCMC) sampling,\ncan in principle recover the full posterior distribution of the image, from\nwhich uncertainties can then be quantified. However, for massive data sizes,\nlike those anticipated from the Square Kilometre Array (SKA), it will be\ndifficult if not impossible to apply any MCMC technique due to its inherent\ncomputational cost. We formulate Bayesian inference problems with\nsparsity-promoting priors (motivated by compressive sensing), for which we\nrecover maximum a posteriori (MAP) point estimators of radio interferometric\nimages by convex optimisation. Exploiting recent developments in the theory of\nprobability concentration, we quantify uncertainties by post-processing the\nrecovered MAP estimate. Three strategies to quantify uncertainties are\ndeveloped: (i) highest posterior density credible regions; (ii) local credible\nintervals (cf. error bars) for individual pixels and superpixels; and (iii)\nhypothesis testing of image structure. These forms of uncertainty\nquantification provide rich information for analysing radio interferometric\nobservations in a statistically robust manner. Our MAP-based methods are\napproximately $10^5$ times faster computationally than state-of-the-art MCMC\nmethods and, in addition, support highly distributed and parallelised\nalgorithmic structures. For the first time, our MAP-based techniques provide a\nmeans of quantifying uncertainties for radio interferometric imaging for\nrealistic data volumes and practical use, and scale to the emerging big-data\nera of radio astronomy. \n\n"}
{"id": "1711.05969", "contents": "Title: Physical-Layer Schemes for Wireless Coded Caching Abstract: We investigate the potentials of applying the coded caching paradigm in\nwireless networks. In order to do this, we investigate physical layer schemes\nfor downlink transmission from a multiantenna transmitter to several\ncache-enabled users. As the baseline scheme we consider employing coded caching\non top of max-min fair multicasting, which is shown to be far from optimal at\nhigh SNR values. Our first proposed scheme, which is near-optimal in terms of\nDoF, is the natural extension of multiserver coded caching to Gaussian\nchannels. As we demonstrate, its finite SNR performance is not satisfactory,\nand thus we propose a new scheme in which the linear combination of messages is\nimplemented in the finite field domain, and the one-shot precoding for the MISO\ndownlink is implemented in the complex field. While this modification results\nin the same near-optimal DoF performance, we show that this leads to\nsignificant performance improvement at finite SNR. Finally, we extend our\nscheme to the previously considered cache-enabled interference channels, and\nmoreover, we provide an Ergodic rate analysis of our scheme. Our results convey\nthe important message that although directly translating schemes from the\nnetwork coding ideas to wireless networks may work well at high SNR values,\ncareful modifications need to be considered for acceptable finite SNR\nperformance. \n\n"}
{"id": "1711.06447", "contents": "Title: Renormalization of local times of super-Brownian motion Abstract: For the local time $L_t^x$ of super-Brownian motion $X$ starting from\n$\\delta_0$, we study its asymptotic behavior as $x\\to 0$. In $d=3$, we find a\nnormalization $\\psi(x)=(1/(2\\pi^2) \\log (1/|x|))^{1/2}$ such that\n$(L_t^x-1/(2\\pi|x|))/\\psi(x)$ converges in distribution to standard normal as\n$x\\to 0$. In $d=2$, we show that $L_t^x-(1/\\pi)\\log (1/|x|)$ converges a.s. as\n$x\\to 0$. We also consider general initial conditions and get similar\nrenormalization results. The behavior of the local time allows us to derive a\nsecond order term in the asymptotic behavior of a related semilinear elliptic\nequation. \n\n"}
{"id": "1711.07956", "contents": "Title: Time-Limited Toeplitz Operators on Abelian Groups: Applications in\n  Information Theory and Subspace Approximation Abstract: Toeplitz operators are fundamental and ubiquitous in signal processing and\ninformation theory as models for linear, time-invariant (LTI) systems. Due to\nthe fact that any practical system can access only signals of finite duration,\ntime-limited restrictions of Toeplitz operators are naturally of interest. To\nprovide a unifying treatment of such systems working on different signal\ndomains, we consider time-limited Toeplitz operators on locally compact abelian\ngroups with the aid of the Fourier transform on these groups. In particular, we\nsurvey existing results concerning the relationship between the spectrum of a\ntime-limited Toeplitz operator and the spectrum of the corresponding\nnon-time-limited Toeplitz operator. We also develop new results specifically\nconcerning the eigenvalues of time-frequency limiting operators on locally\ncompact abelian groups. Applications of our unifying treatment are discussed in\nrelation to channel capacity and in relation to representation and\napproximation of signals. \n\n"}
{"id": "1711.09777", "contents": "Title: PhasePack User Guide Abstract: \"Phase retrieval\" refers to the recovery of signals from the magnitudes (and\nnot the phases) of linear measurements. While there has been a recent explosion\nin development of phase retrieval methods, the lack of a common interface has\nmade it difficult to compare new methods against the current state-of-the-art.\nPhasePack is a software library that creates a common interface for a wide\nrange of phase retrieval schemes. PhasePack also provides a test bed for phase\nretrieval methods using both synthetic data and publicly available empirical\ndatasets. \n\n"}
{"id": "1711.10064", "contents": "Title: Phase Noise Compensation Using Limited Reference Symbols in 3GPP LTE\n  Downlink Abstract: It is known that phase noise (PN) can cause link performance to degrade\nseverely in orthogonal frequency division multiplexing (OFDM) systems, such as\nIEEE 802.11, 3GPP LTE and 5G. As opposed to prior PN mitigation schemes that\nassume perfect channel information and/or abundant reference symbols (e.g., in\n802.11), the proposed PN compensation technique applies to LTE and 5G downlink\nwith a limited number of reference symbols. Specifically, in this work, we\npropose an efficient PN mitigation algorithm where the PN statistics are used\nto obtain more accurate channel estimates. Based on LTE downlink subframe\nstructure, numerical results corroborate the effectiveness of the proposed\nalgorithm. \n\n"}
{"id": "1711.10299", "contents": "Title: Expurgated Bounds for the Asymmetric Broadcast Channel Abstract: This work contains two main contributions concerning the expurgation of\nhierarchical ensembles for the asymmetric broadcast channel. The first is an\nanalysis of the optimal maximum likelihood (ML) decoders for the weak and\nstrong user. Two different methods of code expurgation will be used, that will\nprovide two competing error exponents. The second is the derivation of\nexpurgated exponents under the generalized stochastic likelihood decoder (GLD).\nWe prove that the GLD exponents are at least as tight as the maximum between\nthe random coding error exponents derived in an earlier work by Averbuch and\nMerhav (2017) and one of our ML-based expurgated exponents. By that, we\nactually prove the existence of hierarchical codebooks that achieve the best of\nthe random coding exponent and the expurgated exponent simultaneously for both\nusers. \n\n"}
{"id": "1711.11193", "contents": "Title: Design of Non-orthogonal Multiple Access Enhanced Backscatter\n  Communication Abstract: Backscatter communication (BackCom), which allows a backscatter node (BN) to\ncommunicate with the reader by modulating and reflecting the incident\ncontinuous wave from the reader, is considered as a promising solution to power\nthe future Internet-of-Things. In this paper, we consider a single BackCom\nsystem, where multiple BNs are served by a reader. We propose to use the\npower-domain non-orthogonal multiple access (NOMA), i.e., multiplexing the BNs\nin different regions or with different backscattered power levels, to enhance\nthe spectrum efficiency of the BackCom system. To better exploit power-domain\nNOMA, we propose to set the reflection coefficients for multiplexed BNs to be\ndifferent. Based on this considered model, we develop the reflection\ncoefficient selection criteria. To illustrate the enhanced system with the\nproposed criteria, we analyze the performance of BackCom system in terms of the\naverage number of bits that can be successfully decoded by the reader for\ntwo-node pairing case and the average number of successful BNs for the general\nmultiplexing case. Our results shows that NOMA achieves much better performance\ngain in the BackCom system as compared to its performance gain in the\nconventional system, which highlights the importance of applying NOMA to the\nBackCom system. \n\n"}
{"id": "1712.00205", "contents": "Title: Tensors, Learning, and 'Kolmogorov Extension' for Finite-alphabet Random\n  Vectors Abstract: Estimating the joint probability mass function (PMF) of a set of random\nvariables lies at the heart of statistical learning and signal processing.\nWithout structural assumptions, such as modeling the variables as a Markov\nchain, tree, or other graphical model, joint PMF estimation is often considered\nmission impossible - the number of unknowns grows exponentially with the number\nof variables. But who gives us the structural model? Is there a generic,\n`non-parametric' way to control joint PMF complexity without relying on a\npriori structural assumptions regarding the underlying probability model? Is it\npossible to discover the operational structure without biasing the analysis up\nfront? What if we only observe random subsets of the variables, can we still\nreliably estimate the joint PMF of all? This paper shows, perhaps surprisingly,\nthat if the joint PMF of any three variables can be estimated, then the joint\nPMF of all the variables can be provably recovered under relatively mild\nconditions. The result is reminiscent of Kolmogorov's extension theorem -\nconsistent specification of lower-dimensional distributions induces a unique\nprobability measure for the entire process. The difference is that for\nprocesses of limited complexity (rank of the high-dimensional PMF) it is\npossible to obtain complete characterization from only three-dimensional\ndistributions. In fact not all three-dimensional PMFs are needed; and under\nmore stringent conditions even two-dimensional will do. Exploiting multilinear\nalgebra, this paper proves that such higher-dimensional PMF completion can be\nguaranteed - several pertinent identifiability results are derived. It also\nprovides a practical and efficient algorithm to carry out the recovery task.\nJudiciously designed simulations and real-data experiments on movie\nrecommendation and data classification are presented to showcase the\neffectiveness of the approach. \n\n"}
{"id": "1712.01249", "contents": "Title: On Out-of-Band Emissions of Quantized Precoding in Massive MU-MIMO-OFDM Abstract: We analyze out-of-band (OOB) emissions in the massive multi-user (MU)\nmultiple-input multiple-output (MIMO) downlink. We focus on systems in which\nthe base station (BS) is equipped with low-resolution digital-to-analog\nconverters (DACs) and orthogonal frequency-division multiplexing (OFDM) is used\nto communicate to the user equipments (UEs) over frequency-selective channels.\nWe demonstrate that analog filtering in combination with simple\nfrequency-domain digital predistortion (DPD) at the BS enables a significant\nreduction of OOB emissions, but degrades the\nsignal-to-interference-noise-and-distortion ratio (SINDR) at the UEs and\nincreases the peak-to-average power ratio (PAR) at the BS. We use Bussgang's\ntheorem to characterize the tradeoffs between OOB emissions, SINDR, and PAR,\nand to study the impact of analog filters and DPD on the error-rate performance\nof the massive MU-MIMO-OFDM downlink. Our results show that by carefully tuning\nthe parameters of the analog filters, one can achieve a significant reduction\nin OOB emissions with only a moderate degradation of error-rate performance and\nPAR. \n\n"}
{"id": "1712.01990", "contents": "Title: A Scalable Deep Neural Network Architecture for Multi-Building and\n  Multi-Floor Indoor Localization Based on Wi-Fi Fingerprinting Abstract: One of the key technologies for future large-scale location-aware services\ncovering a complex of multi-story buildings --- e.g., a big shopping mall and a\nuniversity campus --- is a scalable indoor localization technique. In this\npaper, we report the current status of our investigation on the use of deep\nneural networks (DNNs) for scalable building/floor classification and\nfloor-level position estimation based on Wi-Fi fingerprinting. Exploiting the\nhierarchical nature of the building/floor estimation and floor-level\ncoordinates estimation of a location, we propose a new DNN architecture\nconsisting of a stacked autoencoder for the reduction of feature space\ndimension and a feed-forward classifier for multi-label classification of\nbuilding/floor/location, on which the multi-building and multi-floor indoor\nlocalization system based on Wi-Fi fingerprinting is built. Experimental\nresults for the performance of building/floor estimation and floor-level\ncoordinates estimation of a given location demonstrate the feasibility of the\nproposed DNN-based indoor localization system, which can provide near\nstate-of-the-art performance using a single DNN, for the implementation with\nlower complexity and energy consumption at mobile devices. \n\n"}
{"id": "1712.02951", "contents": "Title: Software Defined Applications in Cellular and Optical Networks Abstract: Small wireless cells have the potential to overcome bottlenecks in wireless\naccess through the sharing of spectrum resources. A novel access backhaul\nnetwork architecture based on a Smart Gateway (Sm-GW) between the small cell\nbase stations, e.g., LTE eNBs, and the conventional backhaul gateways, e.g.,\nLTE Servicing/Packet Gateways (S/P-GWs) has been introduced to address the\nbottleneck. The Sm-GW flexibly schedules uplink transmissions for the eNBs.\nBased on software defined networking (SDN) a management mechanism that allows\nmultiple operator to flexibly inter-operate via multiple Sm-GWs with a\nmultitude of small cells has been proposed. This dissertation also\ncomprehensively survey the studies that examine the SDN paradigm in optical\nnetworks. Along with the PHY functional split improvements, the performance of\nDistributed Converged Cable Access Platform (DCCAP) in the cable architectures\nespecially for the Remote-PHY and Remote-MACPHY nodes has been evaluated. In\nthe PHY functional split, in addition to the re-use of infrastructure with a\ncommon FFT module for multiple technologies, a novel cross functional split\ninteraction to cache the repetitive QAM symbols across time at the remote node\nto reduce the transmission rate requirement of the fronthaul link has been\nproposed. \n\n"}
{"id": "1712.03610", "contents": "Title: Logarithmic divergences from optimal transport and R\\'enyi geometry Abstract: Divergences, also known as contrast functions, are distance-like quantities\ndefined on manifolds of non-negative or probability measures. Using the duality\nin optimal transport, we introduce and study the one-parameter family of\n$L^{(\\pm \\alpha)}$-divergences. It includes the Bregman divergence\ncorresponding to the Euclidean quadratic cost, and the $L$-divergence\nintroduced by Pal and the author in connection with portfolio theory and a\nlogarithmic cost function. They admit natural generalizations of exponential\nfamily that are closely related to the $\\alpha$-family and $q$-exponential\nfamily. In particular, the $L^{(\\pm \\alpha)}$-divergences of the corresponding\npotential functions are R\\'{e}nyi divergences. Using this unified framework we\nprove that the induced geometries are dually projectively flat with constant\nsectional curvatures, and a generalized Pythagorean theorem holds true.\nConversely, we show that if a statistical manifold is dually projectively flat\nwith constant curvature $\\pm \\alpha$ with $\\alpha > 0$, then it is locally\ninduced by an $L^{(\\mp \\alpha)}$-divergence. We define in this context a\ncanonical divergence which extends the one for dually flat manifolds. \n\n"}
{"id": "1712.04201", "contents": "Title: On the Energy-Efficient Deployment for Ultra-Dense Heterogeneous\n  Networks with NLoS and LoS Transmissions Abstract: We investigate network performance of ultra-dense heterogeneous networks\n(HetNets) and study the maximum energy-efficient base station (BS) deployment\nincorporating probabilistic non-line-of-sight (NLoS) and line-of-sight (LoS)\ntransmissions. First, we develop an analytical framework with the maximum\ninstantaneous received power (MIRP) and the maximum average received power\n(MARP) association schemes to model the coverage probability and related\nperformance metrics, e.g., the potential throughput (PT) and the energy\nefficiency (EE). Second, we formulate two optimization problems to achieve the\nmaximum energy-efficient deployment solution with specific service criteria.\nSimulation results show that there are tradeoffs among the coverage\nprobability, the total power consumption, and the EE. To be specific, the\nmaximum coverage probability with ideal power consumption is superior to that\nwith practical power consumption when the total power constraint is small and\ninferior to that with practical power consumption when the total power\nconstraint becomes large. Moreover, the maximum EE is a decreasing function\nwith respect to the coverage probability constraint. \n\n"}
{"id": "1712.04687", "contents": "Title: Can Balloons Produce Li-Fi? A Disaster Management Perspective Abstract: Natural calamities and disasters disrupt the conventional communication\nsetups and the wireless bandwidth becomes constrained. A safe and\ncost-effective solution for communication and data access in such scenarios is\nlong needed. Light-Fidelity (Li-Fi) which promises wireless access to data at\nhigh speeds using visible light can be a good option. Visible light being safe\nto use for wireless access in such affected environments also provides\nillumination. Importantly, when a Li-Fi unit is attached to an air balloon and\na network of such Li-Fi balloons are coordinated to form a Li-Fi balloon\nnetwork, data can be accessed anytime and anywhere required and hence many\nlives can be tracked and saved. We propose this idea of a Li-Fi balloon and\ngive an overview of its design using the Philips Li-Fi hardware. Further, we\npropose the concept of a balloon network and coin it with an acronym, the\nLiBNet. We consider the balloons to be arranged as a homogeneous Poisson point\nprocess in the LiBNet and we derive the mean co-channel interference for such\nan arrangement. \n\n"}
{"id": "1712.05004", "contents": "Title: Power Control in UAV-Supported Ultra Dense Networks: Communications,\n  Caching, and Energy Transfer Abstract: By means of network densification, ultra dense networks (UDNs) can\nefficiently broaden the network coverage and enhance the system throughput. In\nparallel, unmanned aerial vehicles (UAVs) communications and networking have\nattracted increasing attention recently due to their high agility and numerous\napplications. In this article, we present a vision of UAV-supported UDNs.\nFirstly, we present four representative scenarios to show the broad\napplications of UAV-supported UDNs in communications, caching and energy\ntransfer. Then, we highlight the efficient power control in UAV-supported UDNs\nby discussing the main design considerations and methods in a comprehensive\nmanner. Furthermore, we demonstrate the performance superiority of\nUAV-supported UDNs via case study simulations, compared to traditional fixed\ninfrastructure based networks. In addition, we discuss the dominating technical\nchallenges and open issues ahead. \n\n"}
{"id": "1712.07365", "contents": "Title: Intelligent Power Control for Spectrum Sharing in Cognitive Radios: A\n  Deep Reinforcement Learning Approach Abstract: We consider the problem of spectrum sharing in a cognitive radio system\nconsisting of a primary user and a secondary user. The primary user and the\nsecondary user work in a non-cooperative manner. Specifically, the primary user\nis assumed to update its transmit power based on a pre-defined power control\npolicy. The secondary user does not have any knowledge about the primary user's\ntransmit power, or its power control strategy. The objective of this paper is\nto develop a learning-based power control method for the secondary user in\norder to share the common spectrum with the primary user. To assist the\nsecondary user, a set of sensor nodes are spatially deployed to collect the\nreceived signal strength information at different locations in the wireless\nenvironment. We develop a deep reinforcement learning-based method, which the\nsecondary user can use to intelligently adjust its transmit power such that\nafter a few rounds of interaction with the primary user, both users can\ntransmit their own data successfully with required qualities of service. Our\nexperimental results show that the secondary user can interact with the primary\nuser efficiently to reach a goal state (defined as a state in which both users\ncan successfully transmit their data) from any initial states within a few\nnumber of steps. \n\n"}
{"id": "1712.09232", "contents": "Title: Clustering in Block Markov Chains Abstract: This paper considers cluster detection in Block Markov Chains (BMCs). These\nMarkov chains are characterized by a block structure in their transition\nmatrix. More precisely, the $n$ possible states are divided into a finite\nnumber of $K$ groups or clusters, such that states in the same cluster exhibit\nthe same transition rates to other states. One observes a trajectory of the\nMarkov chain, and the objective is to recover, from this observation only, the\n(initially unknown) clusters. In this paper we devise a clustering procedure\nthat accurately, efficiently, and provably detects the clusters. We first\nderive a fundamental information-theoretical lower bound on the detection error\nrate satisfied under any clustering algorithm. This bound identifies the\nparameters of the BMC, and trajectory lengths, for which it is possible to\naccurately detect the clusters. We next develop two clustering algorithms that\ncan together accurately recover the cluster structure from the shortest\npossible trajectories, whenever the parameters allow detection. These\nalgorithms thus reach the fundamental detectability limit, and are optimal in\nthat sense. \n\n"}
{"id": "1712.09913", "contents": "Title: Visualizing the Loss Landscape of Neural Nets Abstract: Neural network training relies on our ability to find \"good\" minimizers of\nhighly non-convex loss functions. It is well-known that certain network\narchitecture designs (e.g., skip connections) produce loss functions that train\neasier, and well-chosen training parameters (batch size, learning rate,\noptimizer) produce minimizers that generalize better. However, the reasons for\nthese differences, and their effects on the underlying loss landscape, are not\nwell understood. In this paper, we explore the structure of neural loss\nfunctions, and the effect of loss landscapes on generalization, using a range\nof visualization methods. First, we introduce a simple \"filter normalization\"\nmethod that helps us visualize loss function curvature and make meaningful\nside-by-side comparisons between loss functions. Then, using a variety of\nvisualizations, we explore how network architecture affects the loss landscape,\nand how training parameters affect the shape of minimizers. \n\n"}
{"id": "1712.10291", "contents": "Title: Communications and Control for Wireless Drone-Based Antenna Array Abstract: In this paper, the effective use of multiple quadrotor drones as an aerial\nantenna array that provides wireless service to ground users is investigated.\nIn particular, under the goal of minimizing the airborne service time needed\nfor communicating with ground users, a novel framework for deploying and\noperating a drone-based antenna array system whose elements are single-antenna\ndrones is proposed. In the considered model, the service time is minimized by\nminimizing the wireless transmission time as well as the control time that is\nneeded for movement and stabilization of the drones. To minimize the\ntransmission time, first, the antenna array gain is maximized by optimizing the\ndrone spacing within the array. In this case, using perturbation techniques,\nthe drone spacing optimization problem is addressed by solving successive,\nperturbed convex optimization problems. Then, the optimal locations of the\ndrones around the array's center are derived such that the transmission time\nfor the user is minimized. Given the determined optimal locations of drones,\nthe drones must spend a control time to adjust their positions dynamically so\nas to serve multiple users. To minimize this control time of the quadrotor\ndrones, the speed of rotors is optimally adjusted based on both the\ndestinations of the drones and external forces (e.g., wind and gravity). In\nparticular, using bang-bang control theory, the optimal rotors' speeds as well\nas the minimum control time are derived in closed-form. Simulation results show\nthat the proposed approach can significantly reduce the service time to ground\nusers compared to a fixed-array case in which the same number of drones form a\nfixed uniform antenna array. The results also show that, in comparison with the\nfixed-array case, the network's spectral efficiency can be improved by 32%\nwhile leveraging the drone antenna array system. \n\n"}
{"id": "1801.00443", "contents": "Title: Capacity Characterization of UAV-Enabled Two-User Broadcast Channel Abstract: Although prior works have exploited the UAV's mobility to enhance the\nwireless communication performance under different setups, the fundamental\ncapacity limits of UAV-enabled/aided multiuser communication systems have not\nyet been characterized. To fill this gap, we consider in this paper a\nUAV-enabled two-user broadcast channel (BC), where a UAV flying at a constant\naltitude is deployed to send independent information to two users at different\nfixed locations on the ground. We aim to characterize the capacity region of\nthis new type of BC over a given UAV flight duration, by jointly optimizing the\nUAV's trajectory and transmit power/rate allocations over time, subject to the\nUAV's maximum speed and maximum transmit power constraints. First, to draw\nessential insights, we consider two special cases with asymptotically large/low\nUAV flight duration/speed, respectively. For the former case, it is shown that\na simple hover-fly-hover (HFH) UAV trajectory with time division multiple\naccess (TDMA) based orthogonal multiuser transmission is capacity-achieving,\nwhile in the latter case, the UAV should hover at a fixed location that is\nnearer to the user with larger achievable rate and in general superposition\ncoding (SC) based non-orthogonal transmission with interference cancellation at\nthe receiver of the nearer user is required. Next, we consider the general case\nwith finite UAV speed and flight duration. We show that the optimal UAV\ntrajectory should follow a general HFH structure, i.e., the UAV successively\nhovers at a pair of initial and final locations above the line segment of the\ntwo users each with a certain amount of time and flies unidirectionally between\nthem at the maximum speed, and SC is generally needed. \n\n"}
{"id": "1801.00444", "contents": "Title: Common Throughput Maximization in UAV-Enabled OFDMA Systems with Delay\n  Consideration Abstract: The use of unmanned aerial vehicles (UAVs) as communication platforms is of\ngreat practical significance in future wireless networks, especially for\non-demand deployment in temporary events and emergency situations. Although\nprior works have shown the performance improvement by exploiting the UAV's\nmobility, they mainly focus on delay-tolerant applications. As delay\nrequirements fundamentally limit the UAV's mobility, it remains unknown whether\nthe UAV is able to provide any performance gain in delay-constrained\ncommunication scenarios. Motivated by this, we study in this paper a\nUAV-enabled orthogonal frequency division multiple access (OFDMA) network where\na UAV is dispatched as a mobile base station (BS) to serve a group of users on\nthe ground. We consider a minimum-rate ratio (MRR) for each user, defined as\nthe minimum instantaneous rate required over the average achievable throughput,\nto flexibly adjust the percentage of its delay-constrained data traffic. Under\na given set of constraints on the users' MRRs, we aim to maximize the minimum\naverage throughput of all users by jointly optimizing the UAV trajectory and\nOFDMA resource allocation. First, we show that the max-min throughput in\ngeneral decreases as the users' MRR constraints become more stringent, which\nreveals a fundamental throughput-delay tradeoff in UAV-enabled communications.\nNext, we propose an iterative parameter-assisted block coordinate descent\nmethod to optimize the UAV trajectory and OFDMA resource allocation\nalternately, by applying the successive convex optimization and the Lagrange\nduality, respectively. Furthermore, an efficient and systematic UAV trajectory\ninitialization scheme is proposed based on a simple circular trajectory.\nFinally, simulation results are provided to verify our theoretical findings and\ndemonstrate the effectiveness of our proposed designs. \n\n"}
{"id": "1801.00940", "contents": "Title: Secure communication over fully quantum Gel'fand-Pinsker wiretap channel Abstract: In this work we study the problem of secure communication over a fully\nquantum Gel'fand-Pinsker channel. The best known achievability rate for this\nchannel model in the classical case was proven by Goldfeld, Cuff and Permuter\nin [Goldfeld, Cuff, Permuter, 2016]. We generalize the result of [Goldfeld,\nCuff, Permuter, 2016]. One key feature of the results obtained in this work is\nthat all the bounds obtained are in terms of error exponent. We obtain our\nachievability result via the technique of simultaneous pinching. This in turn\nallows us to show the existence of a simultaneous decoder. Further, to obtain\nour encoding technique and to prove the security feature of our coding scheme\nwe prove a bivariate classical-quantum channel resolvability lemma and a\nconditional classical-quantum channel resolvability lemma. As a by product of\nthe achievability result obtained in this work, we also obtain an achievable\nrate for a fully quantum Gel'fand-Pinsker channel in the absence of Eve. The\nform of this achievable rate matches with its classical counterpart. The\nGel'fand-Pinsker channel model had earlier only been studied for the\nclassical-quantum case and in the case where Alice (the sender) and Bob (the\nreceiver) have shared entanglement between them. \n\n"}
{"id": "1801.01270", "contents": "Title: Ultra-Reliable and Low-Latency Wireless Communication: Tail, Risk and\n  Scale Abstract: Ensuring ultra-reliable and low-latency communication (URLLC) for 5G wireless\nnetworks and beyond is of capital importance and is currently receiving\ntremendous attention in academia and industry. At its core, URLLC mandates a\ndeparture from expected utility-based network design approaches, in which\nrelying on average quantities (e.g., average throughput, average delay and\naverage response time) is no longer an option but a necessity. Instead, a\nprincipled and scalable framework which takes into account delay, reliability,\npacket size, network architecture, and topology (across access, edge, and core)\nand decision-making under uncertainty is sorely lacking. The overarching goal\nof this article is a first step to fill this void. Towards this vision, after\nproviding definitions of latency and reliability, we closely examine various\nenablers of URLLC and their inherent tradeoffs. Subsequently, we focus our\nattention on a plethora of techniques and methodologies pertaining to the\nrequirements of ultra-reliable and low-latency communication, as well as their\napplications through selected use cases. These results provide crisp insights\nfor the design of low-latency and high-reliable wireless networks. \n\n"}
{"id": "1801.01656", "contents": "Title: A Survey of Air-to-Ground Propagation Channel Modeling for Unmanned\n  Aerial Vehicles Abstract: In recent years, there has been a dramatic increase in the use of unmanned\naerial vehicles (UAVs), particularly for small UAVs, due to their affordable\nprices, ease of availability, and ease of operability. Existing and future\napplications of UAVs include remote surveillance and monitoring, relief\noperations, package delivery, and communication backhaul infrastructure.\nAdditionally, UAVs are envisioned as an important component of 5G wireless\ntechnology and beyond. The unique application scenarios for UAVs necessitate\naccurate air-to-ground (AG) propagation channel models for designing and\nevaluating UAV communication links for control/non-payload as well as payload\ndata transmissions. These AG propagation models have not been investigated in\ndetail when compared to terrestrial propagation models. In this paper, a\ncomprehensive survey is provided on available AG channel measurement campaigns,\nlarge and small scale fading channel models, their limitations, and future\nresearch directions for UAV communication scenarios. \n\n"}
{"id": "1801.02609", "contents": "Title: Secure Beamforming in Full-Duplex SWIPT Systems With Loopback\n  Self-Interference Cancellation Abstract: Security is a critical issue in full duplex (FD) communication systems due to\nthe broadcast nature of wireless channels. In this paper, joint design of\ninformation and artificial noise beamforming vectors is proposed for the FD\nsimultaneous wireless information and power transferring (FD-SWIPT) systems\nwith loopback self-interference cancellation. To guarantee high security and\nenergy harvesting performance of the FD-SWIPT system, the proposed design is\nformulated as a secrecy rate maximization problem under energy transfer rate\nconstraints. Although the secrecy rate maximization problem is non-convex, we\nsolve it via semidefinite relaxation and a two-dimensional search. We prove the\noptimality of our proposed algorithm and demonstrate its performance via\nsimulations. \n\n"}
{"id": "1801.05500", "contents": "Title: Cellular-Connected UAVs over 5G: Deep Reinforcement Learning for\n  Interference Management Abstract: In this paper, an interference-aware path planning scheme for a network of\ncellular-connected unmanned aerial vehicles (UAVs) is proposed. In particular,\neach UAV aims at achieving a tradeoff between maximizing energy efficiency and\nminimizing both wireless latency and the interference level caused on the\nground network along its path. The problem is cast as a dynamic game among\nUAVs. To solve this game, a deep reinforcement learning algorithm, based on\necho state network (ESN) cells, is proposed. The introduced deep ESN\narchitecture is trained to allow each UAV to map each observation of the\nnetwork state to an action, with the goal of minimizing a sequence of\ntime-dependent utility functions. Each UAV uses ESN to learn its optimal path,\ntransmission power level, and cell association vector at different locations\nalong its path. The proposed algorithm is shown to reach a subgame perfect Nash\nequilibrium (SPNE) upon convergence. Moreover, an upper and lower bound for the\naltitude of the UAVs is derived thus reducing the computational complexity of\nthe proposed algorithm. Simulation results show that the proposed scheme\nachieves better wireless latency per UAV and rate per ground user (UE) while\nrequiring a number of steps that is comparable to a heuristic baseline that\nconsiders moving via the shortest distance towards the corresponding\ndestinations. The results also show that the optimal altitude of the UAVs\nvaries based on the ground network density and the UE data rate requirements\nand plays a vital role in minimizing the interference level on the ground UEs\nas well as the wireless transmission delay of the UAV. \n\n"}
{"id": "1801.05567", "contents": "Title: Exploiting Diversity in Molecular Timing Channels via Order Statistics Abstract: We study diversity in one-shot communication over molecular timing channels.\nWe consider a channel model where the transmitter simultaneously releases a\nlarge number of information particles, while the information is encoded in the\ntime of release. The receiver decodes the information based on the random time\nof arrival of the information particles. The random propagation is\ncharacterized by the general class of right-sided unimodal densities. We\ncharacterize the asymptotic exponential decrease rate of the probability of\nerror as a function of the number of released particles, and denote this\nquantity as the system diversity gain. Four types of detectors are considered:\nthe maximum-likelihood (ML) detector, a linear detector, a detector that is\nbased on the first arrival (FA) among all the transmitted particles, and a\ndetector based on the last arrival (LA). When the density characterizing the\nrandom propagation is supported over a large interval, we show that the simple\nFA detector achieves a diversity gain very close to that of the ML detector. On\nthe other hand, when the density characterizing the random propagation is\nsupported over a small interval, we show that the simple LA detector achieves a\ndiversity gain very close to that of the ML detector. \n\n"}
{"id": "1801.05787", "contents": "Title: Faster gaze prediction with dense networks and Fisher pruning Abstract: Predicting human fixations from images has recently seen large improvements\nby leveraging deep representations which were pretrained for object\nrecognition. However, as we show in this paper, these networks are highly\noverparameterized for the task of fixation prediction. We first present a\nsimple yet principled greedy pruning method which we call Fisher pruning.\nThrough a combination of knowledge distillation and Fisher pruning, we obtain\nmuch more runtime-efficient architectures for saliency prediction, achieving a\n10x speedup for the same AUC performance as a state of the art network on the\nCAT2000 dataset. Speeding up single-image gaze prediction is important for many\nreal-world applications, but it is also a crucial step in the development of\nvideo saliency models, where the amount of data to be processed is\nsubstantially larger. \n\n"}
{"id": "1801.07367", "contents": "Title: Mean-Field Game Theoretic Edge Caching in Ultra-Dense Networks Abstract: This paper investigates a cellular edge caching problem under a very large\nnumber of small base stations (SBSs) and users. In this ultra-dense edge\ncaching network (UDCN), conventional caching algorithms are inapplicable as\ntheir complexity increases with the number of small base stations (SBSs).\nFurthermore, the performance of UDCN is highly sensitive to the dynamics of\nuser demand and inter-SBS interference. To overcome such difficulties, we\npropose a distributed caching algorithm under a stochastic geometric network\nmodel, as well as a spatio-temporal user demand model that characterizes the\ncontent popularity dynamics. By exploiting mean-field game (MFG) theory, the\ncomplexity of the proposed UDCN caching algorithm becomes independent of the\nnumber of SBSs. Numerical evaluations validate that the proposed caching\nalgorithm reduces not only the long run average cost of the network but also\nthe redundant cached data respectively by 24% and 42%, compared to a baseline\ncaching algorithm. The simulation results also show that the proposed caching\nalgorithm is robust to imperfect popularity information, while ensuring a low\ncomputational complexity. \n\n"}
{"id": "1801.07419", "contents": "Title: Optimality of Simple Layered Superposition Coding in the 3 User MISO BC\n  with Finite Precision CSIT Abstract: We study the $K=3$ user multiple input single output (MISO) broadcast channel\n(BC) with $M=3$ antennas at the transmitter and $1$ antenna at each receiver,\nfrom the generalized degrees of freedom (GDoF) perspective, under the\nassumption that the channel state information at the transmitter (CSIT) is\nlimited to finite precision. In particular, our goal is to identify a parameter\nregime where a simple layered superposition (SLS) coding scheme achieves the\nentire GDoF region. With $\\alpha_{ij}$ representing the channel strength\nparameter for the link from the $j^{th}$ antenna of the transmitter to the\n$i^{th}$ receiver, we prove that SLS is GDoF optimal without the need for\ntime-sharing if $\\max(\\alpha_{ki},\\alpha_{im})\\leq\\alpha_{ii}$ and\n$\\alpha_{ki}+\\alpha_{im}\\le\\alpha_{ii}+\\alpha_{km}$ for all\n$i,k\\in[3],m\\in[M]$. The GDoF region under this condition is a convex\npolyhedron. The result generalizes to arbitrary $M\\geq 3$. \n\n"}
{"id": "1801.08620", "contents": "Title: Queue-Aware Joint Dynamic Interference Coordination and Heterogeneous\n  QoS Provisioning in OFDMA Networks Abstract: We propose algorithms for cloud radio access networks that not only provide\nheterogeneous quality of-service (QoS) for rate- and, importantly,\ndelay-sensitive applications, but also jointly optimize the frequency reuse\npattern. Importantly, unlike related works, we account for random arrivals,\nthrough queue awareness and, unlike majority of works focusing on a single\nframe only, we consider QoS measures averaged over multiple frames involving a\nset of closed loop controls. We model this problem as multi-cell optimization\nto maximize a sum utility subject to the QoS constraints, expressed as minimum\nmean-rate or maximum mean-delay. Since we consider dynamic interference\ncoordination jointly with dynamic user association, the problem is not convex,\neven after integer relaxation. We translate the problem into an optimization of\nframe rates, amenable to a decomposition into intertwined primal and dual\nproblems. The solution to this optimization problem provides joint decisions on\nscheduling, dynamic interference coordination, and, importantly, unlike most\nworks in this area, on dynamic user association. Additionally, we propose a\nnovel method to manage infeasible loads. Extensive simulations confirm that the\ndesign responds to instantaneous loads, heterogeneous user and AP locations,\nchannel conditions, and QoS constraints while, if required, keeping outage low\nwhen dealing with infeasible loads. Comparisons to the baseline proportional\nfair scheme illustrate the gains achieved. \n\n"}
{"id": "1801.09339", "contents": "Title: Liquid State Machine Learning for Resource and Cache Management in LTE-U\n  Unmanned Aerial Vehicle (UAV) Networks Abstract: In this paper, the problem of joint caching and resource allocation is\ninvestigated for a network of cache-enabled unmanned aerial vehicles (UAVs)\nthat service wireless ground users over the LTE licensed and unlicensed (LTE-U)\nbands. The considered model focuses on users that can access both licensed and\nunlicensed bands while receiving contents from either the cache units at the\nUAVs directly or via content server-UAV-user links. This problem is formulated\nas an optimization problem which jointly incorporates user association,\nspectrum allocation, and content caching. To solve this problem, a distributed\nalgorithm based on the machine learning framework of liquid state machine (LSM)\nis proposed. Using the proposed LSM algorithm, the cloud can predict the users'\ncontent request distribution while having only limited information on the\nnetwork's and users' states. The proposed algorithm also enables the UAVs to\nautonomously choose the optimal resource allocation strategies that maximize\nthe number of users with stable queues depending on the network states. Based\non the users' association and content request distributions, the optimal\ncontents that need to be cached at UAVs as well as the optimal resource\nallocation are derived. Simulation results using real datasets show that the\nproposed approach yields up to 33.3% and 50.3% gains, respectively, in terms of\nthe number of users that have stable queues compared to two baseline\nalgorithms: Q-learning with cache and Q-learning without cache. The results\nalso show that LSM significantly improves the convergence time of up to 33.3%\ncompared to conventional learning algorithms such as Q-learning. \n\n"}
{"id": "1801.10500", "contents": "Title: Analysis of Coded Selective-Repeat ARQ via Matrix Signal-Flow Graphs Abstract: We propose two schemes for selective-repeat ARQ protocols over packet erasure\nchannels with unreliable feedback: (i) a hybrid ARQ protocol with soft\ncombining at the receiver, and (ii) a coded ARQ protocol, by building on the\nuncoded baseline scheme for ARQ, developed by Ausavapattanakun and Nosratinia.\nOur method leverages discrete-time queuing and coding theory to analyze the\nperformance of the proposed data transmission methods. We incorporate forward\nerror-correction to reduce in-order delivery delay, and exploit a matrix\nsignal-flow graph approach to analyze the throughput and delay of the\nprotocols. We demonstrate and contrast the performance of the coded protocols\nwith that of the uncoded scheme, illustrating the benefits of coded\ntransmissions. \n\n"}
{"id": "1801.10578", "contents": "Title: Evaluating the Robustness of Neural Networks: An Extreme Value Theory\n  Approach Abstract: The robustness of neural networks to adversarial examples has received great\nattention due to security implications. Despite various attack approaches to\ncrafting visually imperceptible adversarial examples, little has been developed\ntowards a comprehensive measure of robustness. In this paper, we provide a\ntheoretical justification for converting robustness analysis into a local\nLipschitz constant estimation problem, and propose to use the Extreme Value\nTheory for efficient evaluation. Our analysis yields a novel robustness metric\ncalled CLEVER, which is short for Cross Lipschitz Extreme Value for nEtwork\nRobustness. The proposed CLEVER score is attack-agnostic and computationally\nfeasible for large neural networks. Experimental results on various networks,\nincluding ResNet, Inception-v3 and MobileNet, show that (i) CLEVER is aligned\nwith the robustness indication measured by the $\\ell_2$ and $\\ell_\\infty$ norms\nof adversarial examples from powerful attacks, and (ii) defended networks using\ndefensive distillation or bounded ReLU indeed achieve better CLEVER scores. To\nthe best of our knowledge, CLEVER is the first attack-independent robustness\nmetric that can be applied to any neural network classifier. \n\n"}
{"id": "1802.01223", "contents": "Title: Learning Compact Neural Networks with Regularization Abstract: Proper regularization is critical for speeding up training, improving\ngeneralization performance, and learning compact models that are cost\nefficient. We propose and analyze regularized gradient descent algorithms for\nlearning shallow neural networks. Our framework is general and covers\nweight-sharing (convolutional networks), sparsity (network pruning), and\nlow-rank constraints among others. We first introduce covering dimension to\nquantify the complexity of the constraint set and provide insights on the\ngeneralization properties. Then, we show that proposed algorithms become\nwell-behaved and local linear convergence occurs once the amount of data\nexceeds the covering dimension. Overall, our results demonstrate that\nnear-optimal sample complexity is sufficient for efficient learning and\nillustrate how regularization can be beneficial to learn over-parameterized\nnetworks. \n\n"}
{"id": "1802.02667", "contents": "Title: Generalized Degrees of Freedom of Noncoherent Diamond Networks Abstract: We study the generalized degrees of freedom (gDoF) of the block-fading\nnoncoherent diamond (parallel relay) wireless network with asymmetric\ndistributions of link strengths, and a coherence time of T symbol duration. We\nfirst derive an outer bound for this channel and then derive the optimal\nsignaling structure for this outer bound. Using the optimal signaling structure\nwe solve the outer bound optimization problem in terms of its gDoF. Using\ninsights from our outer bound signaling solution, we devise an achievability\nstrategy based on a novel scheme that we call train-scale quantize-map-forward\n(TS-QMF). This uses training in the links from the source to the relays,\nscaling and quantizing at the relays combined with nontraining-based schemes.\nWe show the optimality of this scheme with respect to the outer bound in terms\nof the gDoF. In noncoherent point-to-point multiple-input-multiple-output\n(MIMO) channels, where the fading channel is unknown to transmitter and\nreceiver, an important tradeoff between communication and channel learning was\nrevealed by Zheng and Tse, by demonstrating that not all the available antennas\nmight be used, as it is suboptimal to learn all their channel parameters. Our\nresults in this paper for the diamond network demonstrates that in certain\nregimes the optimal scheme uses a subnetwork, demonstrating a tradeoff between\nchannel learning and communications. In some regimes, it is gDoF optimal to do\nrelay selection, i.e, use a part of the network. In the other regimes, even\nwhen it is essential to use the entire network, it is suboptimal to learn the\nchannel states for all the links in the network, i.e, traditional\ntraining-based schemes are suboptimal in these regimes. \n\n"}
{"id": "1802.03837", "contents": "Title: Integrated Millimeter Wave and Sub-6 GHz Wireless Networks: A Roadmap\n  for Joint Mobile Broadband and Ultra-Reliable Low-Latency Communications Abstract: Next-generation wireless networks must enable emerging technologies such as\naugmented reality and connected autonomous vehicles via wide range of wireless\nservices that span enhanced mobile broadband (eMBB), as well as ultra-reliable\nlow-latency communication (URLLC). Existing wireless systems that solely rely\non the scarce sub-6 GHz, microwave ($\\mu$W) frequency bands will be unable to\nmeet such stringent and mixed service requirements for future wireless services\ndue to spectrum scarcity. Meanwhile, operating at high-frequency millimeter\nwave (mmWave) bands is seen as an attractive solution, primarily due to the\nbandwidth availability and possibility of large-scale multi-antenna\ncommunication. However, mmWave communication is inherently unreliable due to\nits susceptibility to blockage, high path loss, and channel uncertainty. Hence,\nto provide URLLC and high-speed wireless access, it is desirable to seamlessly\nintegrate the reliability of $\\mu$W networks with the high capacity of mmWave\nnetworks. To this end, in this paper, the first comprehensive tutorial for\n\\emph{integrated mmWave-$\\mu$W} communications is introduced. This envisioned\nintegrated design will enable wireless networks to achieve URLLC along with\neMBB by leveraging the best of two worlds: reliable, long-range communications\nat the $\\mu$W bands and directional high-speed communications at the mmWave\nfrequencies. To achieve this goal, key solution concepts are discussed that\ninclude new architectures for the radio interface, URLLC-aware frame structure\nand resource allocation methods along with mobility management, to realize the\npotential of integrated mmWave-$\\mu$W communications. The opportunities and\nchallenges of each proposed scheme are discussed and key results are presented\nto show the merits of the developed integrated mmWave-$\\mu$W framework. \n\n"}
{"id": "1802.03906", "contents": "Title: UAV-Enabled Mobile Edge Computing: Offloading Optimization and\n  Trajectory Design Abstract: With the emergence of diverse mobile applications (such as augmented\nreality), the quality of experience of mobile users is greatly limited by their\ncomputation capacity and finite battery lifetime. Mobile edge computing (MEC)\nand wireless power transfer are promising to address this issue. However, these\ntwo techniques are susceptible to propagation delay and loss. Motivated by the\nchance of short-distance line-of-sight achieved by leveraging unmanned aerial\nvehicle (UAV) communications, an UAV-enabled wireless powered MEC system is\nstudied. A power minimization problem is formulated subject to the constraints\non the number of the computation bits and energy harvesting causality. The\nproblem is non-convex and challenging to tackle. An alternative optimization\nalgorithm is proposed based on sequential convex optimization. Simulation\nresults show that our proposed design is superior to other benchmark schemes\nand the proposed algorithm is efficient in terms of the convergence. \n\n"}
{"id": "1802.04705", "contents": "Title: Hadamard Response: Estimating Distributions Privately, Efficiently, and\n  with Little Communication Abstract: We study the problem of estimating $k$-ary distributions under\n$\\varepsilon$-local differential privacy. $n$ samples are distributed across\nusers who send privatized versions of their sample to a central server. All\npreviously known sample optimal algorithms require linear (in $k$)\ncommunication from each user in the high privacy regime $(\\varepsilon=O(1))$,\nand run in time that grows as $n\\cdot k$, which can be prohibitive for large\ndomain size $k$.\n  We propose Hadamard Response (HR}, a local privatization scheme that requires\nno shared randomness and is symmetric with respect to the users. Our scheme has\norder optimal sample complexity for all $\\varepsilon$, a communication of at\nmost $\\log k+2$ bits per user, and nearly linear running time of $\\tilde{O}(n +\nk)$.\n  Our encoding and decoding are based on Hadamard matrices, and are simple to\nimplement. The statistical performance relies on the coding theoretic aspects\nof Hadamard matrices, ie, the large Hamming distance between the rows. An\nefficient implementation of the algorithm using the Fast Walsh-Hadamard\ntransform gives the computational gains.\n  We compare our approach with Randomized Response (RR), RAPPOR, and\nsubset-selection mechanisms (SS), both theoretically, and experimentally. For\n$k=10000$, our algorithm runs about 100x faster than SS, and RAPPOR. \n\n"}
{"id": "1802.05146", "contents": "Title: Channel Reconstruction-Based Hybrid Precoding for Millimeter Wave\n  Multi-User MIMO Systems Abstract: The focus of this paper is on multi-user MIMO transmissions for millimeter\nwave systems with a hybrid precoding architecture at the base-station. To\nenable multi-user transmissions, the base-station uses a cell-specific codebook\nof beamforming vectors over an initial beam alignment phase. Each user uses a\nuser-specific codebook of beamforming vectors to learn the top-P (where P >= 1)\nbeam pairs in terms of the observed SNR in a single-user setting. The top-P\nbeam indices along with their SNRs are fed back from each user and the\nbase-station leverages this information to generate beam weights for\nsimultaneous transmissions. A typical method to generate the beam weights is to\nuse only the best beam for each user and either steer energy along this beam,\nor to utilize this information to reduce multi-user interference. The other\nbeams are used as fall back options to address blockage or mobility. Such an\napproach completely discards information learned about the channel condition(s)\neven though each user feeds back this information. With this background, this\nwork develops an advanced directional precoding structure for simultaneous\ntransmissions at the cost of an additional marginal feedback overhead. This\nconstruction relies on three main innovations: 1) Additional feedback to allow\nthe base-station to reconstruct a rank-P approximation of the channel matrix\nbetween it and each user, 2) A zeroforcing structure that leverages this\ninformation to combat multi-user interference by remaining agnostic of the\nreceiver beam knowledge in the precoder design, and 3) A hybrid precoding\narchitecture that allows both amplitude and phase control at low-complexity and\ncost to allow the implementation of the zeroforcing structure. Numerical\nstudies show that the proposed scheme results in a significant sum rate\nperformance improvement over naive schemes even with a coarse initial beam\nalignment codebook. \n\n"}
{"id": "1802.06450", "contents": "Title: Reducing Initial Cell-search Latency in mmWave Networks Abstract: Millimeter-wave (mmWave) networks rely on directional transmissions, in both\ncontrol plane and data plane, to overcome severe path-loss. Nevertheless, the\nuse of narrow beams complicates the initial cell-search procedure where we lack\nsufficient information for beamforming. In this paper, we investigate the\nfeasibility of random beamforming for cell-search. We develop a stochastic\ngeometry framework to analyze the performance in terms of failure probability\nand expected latency of cell-search. Meanwhile, we compare our results with the\nnaive, but heavily used, exhaustive search scheme. Numerical results show that,\nfor a given discovery failure probability, random beamforming can substantially\nreduce the latency of exhaustive search, especially in dense networks. Our work\ndemonstrates that developing complex cell-discovery algorithms may be\nunnecessary in dense mmWave networks and thus shed new lights on mmWave system\ndesign. \n\n"}
{"id": "1802.06512", "contents": "Title: Asymmetric Modulation Design for Wireless Information and Power Transfer\n  with Nonlinear Energy Harvesting Abstract: Far-field wireless power transfer (WPT) and simultaneous wireless information\nand power transfer (SWIPT) have become increasingly important in radio\nfrequency (RF) and communication communities recently. The problem of\nmodulation design for SWIPT has however been scarcely addressed. In this paper,\na modulation scheme based on asymmetric phase-shift keying (PSK) is considered,\nwhich improves the SWIPT rate-energy tradeoff region significantly. The\nnonlinear rectifier model, which accurately models the energy harvester, is\nadopted for evaluating the output direct current (DC) power at the receiver.\nThe harvested DC power is maximized under an average power constraint at the\ntransmitter and a constraint on the rate of information transmitted via a\nmulti-carrier signal over a flat fading channel. As a consequence of the\nrectifier nonlinearity, this work highlights that asymmetric PSK modulation\nprovides benefits over conventional symmetric PSK modulation in SWIPT and opens\nthe door to systematic modulation design tailored for SWIPT. \n\n"}
{"id": "1802.08417", "contents": "Title: Geometric Lower Bounds for Distributed Parameter Estimation under\n  Communication Constraints Abstract: We consider parameter estimation in distributed networks, where each sensor\nin the network observes an independent sample from an underlying distribution\nand has $k$ bits to communicate its sample to a centralized processor which\ncomputes an estimate of a desired parameter. We develop lower bounds for the\nminimax risk of estimating the underlying parameter for a large class of losses\nand distributions. Our results show that under mild regularity conditions, the\ncommunication constraint reduces the effective sample size by a factor of $d$\nwhen $k$ is small, where $d$ is the dimension of the estimated parameter.\nFurthermore, this penalty reduces at most exponentially with increasing $k$,\nwhich is the case for some models, e.g., estimating high-dimensional\ndistributions. For other models however, we show that the sample size reduction\nis re-mediated only linearly with increasing $k$, e.g. when some sub-Gaussian\nstructure is available. We apply our results to the distributed setting with\nproduct Bernoulli model, multinomial model, Gaussian location models, and\nlogistic regression which recover or strengthen existing results.\n  Our approach significantly deviates from existing approaches for developing\ninformation-theoretic lower bounds for communication-efficient estimation. We\ncircumvent the need for strong data processing inequalities used in prior work\nand develop a geometric approach which builds on a new representation of the\ncommunication constraint. This approach allows us to strengthen and generalize\nexisting results with simpler and more transparent proofs. \n\n"}
{"id": "1802.08439", "contents": "Title: Ratio ergodic theorems: From Hopf to Birkhoff and Kingman Abstract: Hopf's ratio ergodic theorem has an inherent symmetry which we exploit to\nprovide a simplification of standard proofs of Hopf's and Birkhoff's ergodic\ntheorems. We also present a ratio ergodic theorem for conservative\ntransformations on a $\\sigma$-finite measure space, generalizing Kingman's\nergodic theorem for subadditive sequences and generalizing previous results by\nAkcoglu and Sucheston. \n\n"}
{"id": "1802.08898", "contents": "Title: Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo Abstract: Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from\nhigh-dimensional distributions in Statistics and Machine learning. HMC is known\nto run very efficiently in practice and its popular second-order \"leapfrog\"\nimplementation has long been conjectured to run in $d^{1/4}$ gradient\nevaluations. Here we show that this conjecture is true when sampling from\nstrongly log-concave target distributions that satisfy a weak third-order\nregularity property associated with the input data. Our regularity condition is\nweaker than the Lipschitz Hessian property and allows us to show faster\nconvergence bounds for a much larger class of distributions than would be\npossible with the usual Lipschitz Hessian constant alone. Important\ndistributions that satisfy our regularity condition include posterior\ndistributions used in Bayesian logistic regression for which the data satisfies\nan \"incoherence\" property. Our result compares favorably with the best\navailable bounds for the class of strongly log-concave distributions, which\ngrow like $d^{{1}/{2}}$ gradient evaluations with the dimension. Moreover, our\nsimulations on synthetic data suggest that, when our regularity condition is\nsatisfied, leapfrog HMC performs better than its competitors -- both in terms\nof accuracy and in terms of the number of gradient evaluations it requires. \n\n"}
{"id": "1802.09766", "contents": "Title: Learning Representations for Neural Network-Based Classification Using\n  the Information Bottleneck Principle Abstract: In this theory paper, we investigate training deep neural networks (DNNs) for\nclassification via minimizing the information bottleneck (IB) functional. We\nshow that the resulting optimization problem suffers from two severe issues:\nFirst, for deterministic DNNs, either the IB functional is infinite for almost\nall values of network parameters, making the optimization problem ill-posed, or\nit is piecewise constant, hence not admitting gradient-based optimization\nmethods. Second, the invariance of the IB functional under bijections prevents\nit from capturing properties of the learned representation that are desirable\nfor classification, such as robustness and simplicity. We argue that these\nissues are partly resolved for stochastic DNNs, DNNs that include a (hard or\nsoft) decision rule, or by replacing the IB functional with related, but more\nwell-behaved cost functions. We conclude that recent successes reported about\ntraining DNNs using the IB framework must be attributed to such solutions. As a\nside effect, our results indicate limitations of the IB framework for the\nanalysis of DNNs. We also note that rather than trying to repair the inherent\nproblems in the IB functional, a better approach may be to design regularizers\non latent representation enforcing the desired properties directly. \n\n"}
{"id": "1802.09941", "contents": "Title: Demystifying Parallel and Distributed Deep Learning: An In-Depth\n  Concurrency Analysis Abstract: Deep Neural Networks (DNNs) are becoming an important tool in modern\ncomputing applications. Accelerating their training is a major challenge and\ntechniques range from distributed algorithms to low-level circuit design. In\nthis survey, we describe the problem from a theoretical perspective, followed\nby approaches for its parallelization. We present trends in DNN architectures\nand the resulting implications on parallelization strategies. We then review\nand model the different types of concurrency in DNNs: from the single operator,\nthrough parallelism in network inference and training, to distributed deep\nlearning. We discuss asynchronous stochastic optimization, distributed system\narchitectures, communication schemes, and neural architecture search. Based on\nthose approaches, we extrapolate potential directions for parallelism in deep\nlearning. \n\n"}
{"id": "1803.00168", "contents": "Title: On the Performance of Network NOMA in Uplink CoMP Systems: A Stochastic\n  Geometry Approach Abstract: To improve the system throughput, this paper proposes a network\nnon-orthogonal multiple access (N-NOMA) technique for the uplink coordinated\nmulti-point transmission (CoMP). In the considered scenario, multiple base\nstations collaborate with each other to serve a single user, referred to as the\nCoMP user, which is the same as for conventional CoMP. However, unlike\nconventional CoMP, each base station in N-NOMA opportunistically serves an\nextra user, referred to as the NOMA user, while serving the CoMP user at the\nsame bandwidth. The CoMP user is typically located at the cell-edge, whereas\nusers close to the base stations are scheduled as NOMA users. Hence, the\nchannel conditions of the two kind of users are very distinctive, which\nfacilitates the implementation of NOMA. Compared to the conventional orthogonal\nmultiple access based CoMP scheme, where multiple base stations serve a single\nCoMP user only, the proposed N-NOMA scheme can support larger connectivity by\nserving the extra NOMA users, and improve the spectral efficiency by avoiding\nthe CoMP user solely occupying the spectrum. A stochastic geometry approach is\napplied to model the considered N-NOMA scenario as a Poisson cluster process,\nbased on which closed-form analytical expressions for outage probabilities and\nergodic rates are obtained. Numerical results are presented to show the\naccuracy of the analytical results and also demonstrate the superior\nperformance of the proposed N-NOMA scheme. \n\n"}
{"id": "1803.00443", "contents": "Title: Knowledge Transfer with Jacobian Matching Abstract: Classical distillation methods transfer representations from a \"teacher\"\nneural network to a \"student\" network by matching their output activations.\nRecent methods also match the Jacobians, or the gradient of output activations\nwith the input. However, this involves making some ad hoc decisions, in\nparticular, the choice of the loss function.\n  In this paper, we first establish an equivalence between Jacobian matching\nand distillation with input noise, from which we derive appropriate loss\nfunctions for Jacobian matching. We then rely on this analysis to apply\nJacobian matching to transfer learning by establishing equivalence of a recent\ntransfer learning procedure to distillation.\n  We then show experimentally on standard image datasets that Jacobian-based\npenalties improve distillation, robustness to noisy inputs, and transfer\nlearning. \n\n"}
{"id": "1803.00567", "contents": "Title: Computational Optimal Transport Abstract: Optimal transport (OT) theory can be informally described using the words of\nthe French mathematician Gaspard Monge (1746-1818): A worker with a shovel in\nhand has to move a large pile of sand lying on a construction site. The goal of\nthe worker is to erect with all that sand a target pile with a prescribed shape\n(for example, that of a giant sand castle). Naturally, the worker wishes to\nminimize her total effort, quantified for instance as the total distance or\ntime spent carrying shovelfuls of sand. Mathematicians interested in OT cast\nthat problem as that of comparing two probability distributions, two different\npiles of sand of the same volume. They consider all of the many possible ways\nto morph, transport or reshape the first pile into the second, and associate a\n\"global\" cost to every such transport, using the \"local\" consideration of how\nmuch it costs to move a grain of sand from one place to another. Recent years\nhave witnessed the spread of OT in several fields, thanks to the emergence of\napproximate solvers that can scale to sizes and dimensions that are relevant to\ndata sciences. Thanks to this newfound scalability, OT is being increasingly\nused to unlock various problems in imaging sciences (such as color or texture\nprocessing), computer vision and graphics (for shape manipulation) or machine\nlearning (for regression, classification and density fitting). This short book\nreviews OT with a bias toward numerical methods and their applications in data\nsciences, and sheds lights on the theoretical properties of OT that make it\nparticularly useful for some of these applications. \n\n"}
{"id": "1803.00680", "contents": "Title: A Tutorial on UAVs for Wireless Networks: Applications, Challenges, and\n  Open Problems Abstract: The use of flying platforms such as unmanned aerial vehicles (UAVs),\npopularly known as drones, is rapidly growing. In particular, with their\ninherent attributes such as mobility, flexibility, and adaptive altitude, UAVs\nadmit several key potential applications in wireless systems. On the one hand,\nUAVs can be used as aerial base stations to enhance coverage, capacity,\nreliability, and energy efficiency of wireless networks. On the other hand,\nUAVs can operate as flying mobile terminals within a cellular network. Such\ncellular-connected UAVs can enable several applications ranging from real-time\nvideo streaming to item delivery. In this paper, a comprehensive tutorial on\nthe potential benefits and applications of UAVs in wireless communications is\npresented. Moreover, the important challenges and the fundamental tradeoffs in\nUAV-enabled wireless networks are thoroughly investigated. In particular, the\nkey UAV challenges such as three-dimensional deployment, performance analysis,\nchannel modeling, and energy efficiency are explored along with representative\nresults. Then, open problems and potential research directions pertaining to\nUAV communications are introduced. Finally, various analytical frameworks and\nmathematical tools such as optimization theory, machine learning, stochastic\ngeometry, transport theory, and game theory are described. The use of such\ntools for addressing unique UAV problems is also presented. In a nutshell, this\ntutorial provides key guidelines on how to analyze, optimize, and design\nUAV-based wireless communication systems. \n\n"}
{"id": "1803.02186", "contents": "Title: Symmetry and Algorithmic Complexity of Polyominoes and Polyhedral Graphs Abstract: We introduce a definition of algorithmic symmetry able to capture essential\naspects of geometric symmetry. We review, study and apply a method for\napproximating the algorithmic complexity (also known as Kolmogorov-Chaitin\ncomplexity) of graphs and networks based on the concept of Algorithmic\nProbability (AP). AP is a concept (and method) capable of recursively\nenumeration all properties of computable (causal) nature beyond statistical\nregularities. We explore the connections of algorithmic complexity---both\ntheoretical and numerical---with geometric properties mainly symmetry and\ntopology from an (algorithmic) information-theoretic perspective. We show that\napproximations to algorithmic complexity by lossless compression and an\nAlgorithmic Probability-based method can characterize properties of\npolyominoes, polytopes, regular and quasi-regular polyhedra as well as\npolyhedral networks, thereby demonstrating its profiling capabilities. \n\n"}
{"id": "1803.03285", "contents": "Title: Massive UAV-to-Ground Communication and its Stable Movement Control: A\n  Mean-Field Approach Abstract: This paper proposes a real-time movement control algorithm for massive\nunmanned aerial vehicles (UAVs) that provide emergency cellular connections in\nan urban disaster site. While avoiding the inter-UAV collision under temporal\nwind dynamics, the proposed algorithm minimizes each UAV's energy consumption\nper unit downlink rate. By means of a mean-field game theoretic flocking\napproach, the velocity control of each UAV only requires its own location and\nchannel states. Numerical results validate the performance of the algorithm in\nterms of the number of collisions and energy consumption per data rate, under a\nrealistic 3GPP UAV channel model. \n\n"}
{"id": "1803.03383", "contents": "Title: High-Accuracy Low-Precision Training Abstract: Low-precision computation is often used to lower the time and energy cost of\nmachine learning, and recently hardware accelerators have been developed to\nsupport it. Still, it has been used primarily for inference - not training.\nPrevious low-precision training algorithms suffered from a fundamental\ntradeoff: as the number of bits of precision is lowered, quantization noise is\nadded to the model, which limits statistical accuracy. To address this issue,\nwe describe a simple low-precision stochastic gradient descent variant called\nHALP. HALP converges at the same theoretical rate as full-precision algorithms\ndespite the noise introduced by using low precision throughout execution. The\nkey idea is to use SVRG to reduce gradient variance, and to combine this with a\nnovel technique called bit centering to reduce quantization error. We show that\non the CPU, HALP can run up to $4 \\times$ faster than full-precision SVRG and\ncan match its convergence trajectory. We implemented HALP in TensorQuant, and\nshow that it exceeds the validation performance of plain low-precision SGD on\ntwo deep learning tasks. \n\n"}
{"id": "1803.04783", "contents": "Title: A Scalable Near-Memory Architecture for Training Deep Neural Networks on\n  Large In-Memory Datasets Abstract: Most investigations into near-memory hardware accelerators for deep neural\nnetworks have primarily focused on inference, while the potential of\naccelerating training has received relatively little attention so far. Based on\nan in-depth analysis of the key computational patterns in state-of-the-art\ngradient-based training methods, we propose an efficient near-memory\nacceleration engine called NTX that can be used to train state-of-the-art deep\nconvolutional neural networks at scale. Our main contributions are: (i) a loose\ncoupling of RISC-V cores and NTX co-processors reducing offloading overhead by\n7x over previously published results; (ii) an optimized IEEE754 compliant data\npath for fast high-precision convolutions and gradient propagation; (iii)\nevaluation of near-memory computing with NTX embedded into residual area on the\nLogic Base die of a Hybrid Memory Cube; and (iv) a scaling analysis to meshes\nof HMCs in a data center scenario. We demonstrate a 2.7x energy efficiency\nimprovement of NTX over contemporary GPUs at 4.4x less silicon area, and a\ncompute performance of 1.2 Tflop/s for training large state-of-the-art networks\nwith full floating-point precision. At the data center scale, a mesh of NTX\nachieves above 95% parallel and energy efficiency, while providing 2.1x energy\nsavings or 3.1x performance improvement over a GPU-based system. \n\n"}
{"id": "1803.06299", "contents": "Title: On the existence of a scalar pressure field in the Br\\\"odinger problem Abstract: This work deals with the entropic regularization of the Brenier problem for\nperfect incompressible fluids introduced by Arnaudon, Cruzeiro, L\\'eonard and\nZambrini. We show that as in the original setting, there exists a scalar\npressure field which is interpreted as the Lagrange multiplier associated to\nthe incompressibility constraint. The proof goes through a reformulation of the\nproblem in PDE terms. \n\n"}
{"id": "1803.06361", "contents": "Title: Halving the bounds for the Markov, Chebyshev, and Chernoff Inequalities\n  using smoothing Abstract: The Markov, Chebyshev, and Chernoff inequalities are some of the most widely\nused methods for bounding the tail probabilities of random variables. In all\nthree cases, the bounds are tight in the sense that there exists easy examples\nwhere the inequalities become equality. Here we will show that through a simple\nsmoothing using auxiliary randomness, that each of the three bounds can be cut\nin half. In many common cases, the halving can be achieved without the need for\nthe auxiliary randomness. \n\n"}
{"id": "1803.07937", "contents": "Title: The Augustin Capacity and Center Abstract: For any channel, the existence of a unique Augustin mean is established for\nany positive order and probability mass function on the input set. The Augustin\nmean is shown to be the unique fixed point of an operator defined in terms of\nthe order and the input distribution. The Augustin information is shown to be\ncontinuously differentiable in the order. For any channel and convex constraint\nset with finite Augustin capacity, the existence of a unique Augustin center\nand the associated van Erven-Harremoes bound are established. The\nAugustin-Legendre (A-L) information, capacity, center, and radius are\nintroduced and the latter three are proved to be equal to the corresponding\nRenyi-Gallager quantities. The equality of the A-L capacity to the A-L radius\nfor arbitrary channels and the existence of a unique A-L center for channels\nwith finite A-L capacity are established. For all interior points of the\nfeasible set of cost constraints, the cost constrained Augustin capacity and\ncenter are expressed in terms of the A-L capacity and center. Certain shift\ninvariant families of probabilities and certain Gaussian channels are analyzed\nas examples. \n\n"}
{"id": "1803.08189", "contents": "Title: Can Decentralized Status Update Achieve Universally Near-Optimal\n  Age-of-Information in Wireless Multiaccess Channels? Abstract: In an Internet-of-Things system where status data are collected from sensors\nand actuators for time-critical applications, the freshness of data is vital\nand can be quantified by the recently proposed age-of-information (AoI) metric.\nIn this paper, we first consider a general scenario where multiple terminals\nshare a common channel to transmit or receive randomly generated status\npackets. The optimal scheduling problem to minimize AoI is formulated as a\nrestless multi-armed bandit problem. To solve the problem efficiently, we\nderive the Whittle's index in closed-form and establish the indexability\nthereof. Compared with existing work, we extend the index policy for AoI\noptimization to incorporate stochastic packet arrivals and optimal packet\nmanagement (buffering the latest packet). Inspired by the index policy which\nhas near-optimal performance but is centralized by nature, a decentralized\nstatus update scheme, i.e., the index-prioritized random access policy (IPRA),\nis further proposed, achieving universally near-optimal AoI performance and\noutperforming state-of-the-arts in the literature. \n\n"}
{"id": "1803.10623", "contents": "Title: Stability and Dynamic Control of Underlay Mobile Edge Networks Abstract: This paper studies the stability and dynamic control of underlay mobile edge\nnetworks. First, the stability region for a multiuser edge network is obtained\nunder the assumption of full channel state information. This result provides a\nbenchmark figure for comparing performance of the proposed algorithms. Second,\na centralized joint flow control and scheduling algorithm is proposed to\nstabilize the queues of edge devices while respecting the average and\ninstantaneous interference power constraints at the core access point. This\nalgorithm is proven to converge to a utility point arbitrarily close to the\nmaximum achievable utility within the stability region. Finally, more practical\nimplementation issues such as distributed scheduling are examined by designing\nefficient scheduling algorithms taking advantage of communications diversity.\nThe proposed distributed solutions utilize mini slots for contention resolution\nand achieve a certain fraction of the utility optimal point. The performance\nlower bounds for distributed algorithms are determined analytically. The\ndetailed simulation study is performed to pinpoint the cost of distributed\ncontrol for mobile edge networks with respect to centralized control. \n\n"}
{"id": "1803.10994", "contents": "Title: Hierarchical Sparse Channel Estimation for Massive MIMO Abstract: The problem of wideband massive MIMO channel estimation is considered.\nTargeting for low complexity algorithms as well as small training overhead, a\ncompressive sensing (CS) approach is pursued. Unfortunately, due to the\nKronecker-type sensing (measurement) matrix corresponding to this setup,\napplication of standard CS algorithms and analysis methodology does not apply.\nBy recognizing that the channel possesses a special structure, termed\nhierarchical sparsity, we propose an efficient algorithm that explicitly takes\ninto account this property. In addition, by extending the standard CS analysis\nmethodology to hierarchical sparse vectors, we provide a rigorous analysis of\nthe algorithm performance in terms of estimation error as well as number of\npilot subcarriers required to achieve it. Small training overhead, in turn,\nmeans higher number of supported users in a cell and potentially improved pilot\ndecontamination. We believe, that this is the first paper that draws a rigorous\nconnection between the hierarchical framework and Kronecker measurements.\nNumerical results verify the advantage of employing the proposed approach in\nthis setting instead of standard CS algorithms. \n\n"}
{"id": "1804.00567", "contents": "Title: Asymptotic normality and analysis of variance of log-likelihood ratios\n  in spiked random matrix models Abstract: The present manuscript studies signal detection by likelihood ratio tests in\na number of spiked random matrix models, including but not limited to Gaussian\nmixtures and spiked Wishart covariance matrices. We work directly with\nmulti-spiked cases in these models and with flexible priors on the signal\ncomponent that allow dependence across spikes. We derive asymptotic normality\nfor the log-likelihood ratios when the signal-to- noise ratios are below\ncertain thresholds. In addition, we show that the variances of the\nlog-likelihood ratios can be asymptotically decomposed as the sums of those of\na collection of statistics which we call bipartite signed cycles. \n\n"}
{"id": "1804.00742", "contents": "Title: Minimizing Content Staleness in Dynamo-Style Replicated Storage Systems Abstract: Consistency in data storage systems requires any read operation to return the\nmost recent written version of the content. In replicated storage systems,\nconsistency comes at the price of delay due to large-scale write and read\noperations. Many applications with low latency requirements tolerate data\nstaleness in order to provide high availability and low operation latency.\nUsing age of information as the staleness metric, we examine a data updating\nsystem in which real-time content updates are replicated and stored in a\nDynamo-style quorum- based distributed system. A source sends updates to all\nthe nodes in the system and waits for acknowledgements from the earliest subset\nof nodes, known as a write quorum. An interested client fetches the update from\nanother set of nodes, defined as a read quorum. We analyze the staleness-delay\ntradeoff in replicated storage by varying the write quorum size. With a larger\nwrite quorum, an instantaneous read is more likely to get the latest update\nwritten by the source. However, the age of the content written to the system is\nmore likely to become stale as the write quorum size increases. For shifted\nexponential distributed write delay, we derive the age optimized write quorum\nsize that balances the likelihood of reading the latest update and the\nfreshness of the latest update written by the source. \n\n"}
{"id": "1804.02238", "contents": "Title: Energy Minimization for Wireless Communication with Rotary-Wing UAV Abstract: This paper studies unmanned aerial vehicle (UAV) enabled wireless\ncommunication, where a rotarywing UAV is dispatched to send/collect data\nto/from multiple ground nodes (GNs). We aim to minimize the total UAV energy\nconsumption, including both propulsion energy and communication related energy,\nwhile satisfying the communication throughput requirement of each GN. To this\nend, we first derive an analytical propulsion power consumption model for\nrotary-wing UAVs, and then formulate the energy minimization problem by jointly\noptimizing the UAV trajectory and communication time allocation among GNs, as\nwell as the total mission completion time. The problem is difficult to be\noptimally solved, as it is non-convex and involves infinitely many variables\nover time. To tackle this problem, we first consider the simple\nfly-hover-communicate design, where the UAV successively visits a set of\nhovering locations and communicates with one corresponding GN when hovering at\neach location. For this design, we propose an efficient algorithm to optimize\nthe hovering locations and durations, as well as the flying trajectory\nconnecting these hovering locations, by leveraging the travelling salesman\nproblem (TSP) and convex optimization techniques. Next, we consider the general\ncase where the UAV communicates also when flying. We propose a new path\ndiscretization method to transform the original problem into a discretized\nequivalent with a finite number of optimization variables, for which we obtain\na locally optimal solution by applying the successive convex approximation\n(SCA) technique. Numerical results show the significant performance gains of\nthe proposed designs over benchmark schemes, in achieving energy-efficient\ncommunication with rotary-wing UAVs. \n\n"}
{"id": "1804.02254", "contents": "Title: On the sample autocovariance of a L\\'evy driven moving average process\n  when sampled at a renewal sequence Abstract: We consider a L\\'evy driven continuous time moving average process $X$\nsampled at random times which follow a renewal structure independent of $X$.\nAsymptotic normality of the sample mean, the sample autocovariance, and the\nsample autocorrelation is established under certain conditions on the kernel\nand the random times. We compare our results to a classical non-random\nequidistant sampling method and give an application to parameter estimation of\nthe L\\'evy driven Ornstein-Uhlenbeck process. \n\n"}
{"id": "1804.03235", "contents": "Title: Large scale distributed neural network training through online\n  distillation Abstract: Techniques such as ensembling and distillation promise model quality\nimprovements when paired with almost any base model. However, due to increased\ntest-time cost (for ensembles) and increased complexity of the training\npipeline (for distillation), these techniques are challenging to use in\nindustrial settings. In this paper we explore a variant of distillation which\nis relatively straightforward to use as it does not require a complicated\nmulti-stage setup or many new hyperparameters. Our first claim is that online\ndistillation enables us to use extra parallelism to fit very large datasets\nabout twice as fast. Crucially, we can still speed up training even after we\nhave already reached the point at which additional parallelism provides no\nbenefit for synchronous or asynchronous stochastic gradient descent. Two neural\nnetworks trained on disjoint subsets of the data can share knowledge by\nencouraging each model to agree with the predictions the other model would have\nmade. These predictions can come from a stale version of the other model so\nthey can be safely computed using weights that only rarely get transmitted. Our\nsecond claim is that online distillation is a cost-effective way to make the\nexact predictions of a model dramatically more reproducible. We support our\nclaims using experiments on the Criteo Display Ad Challenge dataset, ImageNet,\nand the largest to-date dataset used for neural language modeling, containing\n$6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data. \n\n"}
{"id": "1804.04580", "contents": "Title: On The Efficiency of Widely Linear Precoding and Symbol Extension in\n  Cellular Uplink Abstract: We investigate Gaussian widely linear precoding known as improper Gaussian\nsignaling for the cellular uplink with inter-cell interference, known as\ninterference multiple access channel (IMAC). This transmission scheme provides\nextra degrees of freedom by treating the real and imaginary components of the\ncomplex Gaussian signal differently. Since current standards mainly utilize\nlinear beamforming for waveform generation, we highlight the benefits of widely\nlinear beamforming over multiple temporal dimensions (symbol extension in time)\nin the IMAC. This scheme achieves significantly higher information rates\ncompared to conventional proper Gaussian signaling at the expense of extra\ncomplexity at the transmission phase. We study the sum-power minimization\nproblem under rate constraints. This problem is a difference of concave\nfunctions (DC) program, hence, a non-convex problem. By numerical simulations,\nwe observe the benefits of improper Gaussian signaling alongside symbol\nextension in power consumption for both single-antenna and multi-antenna base\nstations. Interestingly, we observe that at strong interference scenarios, the\nefficiency of improper Gaussian signaling outperforms conventional proper\nGaussian signaling at low rate demands. Moreover, in such scenarios the\nsum-power required for achieving particular rate demands is significantly\nreduced. \n\n"}
{"id": "1804.05057", "contents": "Title: 5G Wireless Network Slicing for eMBB, URLLC, and mMTC: A\n  Communication-Theoretic View Abstract: The grand objective of 5G wireless technology is to support three generic\nservices with vastly heterogeneous requirements: enhanced mobile broadband\n(eMBB), massive machine-type communications (mMTC), and ultra-reliable\nlow-latency communications (URLLC). Service heterogeneity can be accommodated\nby network slicing, through which each service is allocated resources to\nprovide performance guarantees and isolation from the other services. Slicing\nof the Radio Access Network (RAN) is typically done by means of orthogonal\nresource allocation among the services. This work studies the potential\nadvantages of allowing for non-orthogonal sharing of RAN resources in uplink\ncommunications from a set of eMBB, mMTC and URLLC devices to a common base\nstation. The approach is referred to as Heterogeneous Non-Orthogonal Multiple\nAccess (H-NOMA), in contrast to the conventional NOMA techniques that involve\nusers with homogeneous requirements and hence can be investigated through a\nstandard multiple access channel. The study devises a communication-theoretic\nmodel that accounts for the heterogeneous requirements and characteristics of\nthe three services. The concept of reliability diversity is introduced as a\ndesign principle that leverages the different reliability requirements across\nthe services in order to ensure performance guarantees with non-orthogonal RAN\nslicing. This study reveals that H-NOMA can lead, in some regimes, to\nsignificant gains in terms of performance trade-offs among the three generic\nservices as compared to orthogonal slicing. \n\n"}
{"id": "1804.05057", "contents": "Title: 5G Wireless Network Slicing for eMBB, URLLC, and mMTC: A\n  Communication-Theoretic View Abstract: The grand objective of 5G wireless technology is to support three generic\nservices with vastly heterogeneous requirements: enhanced mobile broadband\n(eMBB), massive machine-type communications (mMTC), and ultra-reliable\nlow-latency communications (URLLC). Service heterogeneity can be accommodated\nby network slicing, through which each service is allocated resources to\nprovide performance guarantees and isolation from the other services. Slicing\nof the Radio Access Network (RAN) is typically done by means of orthogonal\nresource allocation among the services. This work studies the potential\nadvantages of allowing for non-orthogonal sharing of RAN resources in uplink\ncommunications from a set of eMBB, mMTC and URLLC devices to a common base\nstation. The approach is referred to as Heterogeneous Non-Orthogonal Multiple\nAccess (H-NOMA), in contrast to the conventional NOMA techniques that involve\nusers with homogeneous requirements and hence can be investigated through a\nstandard multiple access channel. The study devises a communication-theoretic\nmodel that accounts for the heterogeneous requirements and characteristics of\nthe three services. The concept of reliability diversity is introduced as a\ndesign principle that leverages the different reliability requirements across\nthe services in order to ensure performance guarantees with non-orthogonal RAN\nslicing. This study reveals that H-NOMA can lead, in some regimes, to\nsignificant gains in terms of performance trade-offs among the three generic\nservices as compared to orthogonal slicing. \n\n"}
{"id": "1804.05290", "contents": "Title: Joint Communication and Control for Wireless Autonomous Vehicular\n  Platoon Systems Abstract: Autonomous vehicular platoons will play an important role in improving\non-road safety in tomorrow's smart cities. Vehicles in an autonomous platoon\ncan exploit vehicle-to-vehicle (V2V) communications to collect information,\nsuch as velocity and acceleration, from surrounding vehicles so as to maintain\nthe target velocity and inter-vehicle distance. However, due to the dynamic\non-vehicle data processing rate and the uncertainty of the wireless channel,\nV2V communications within a platoon will experience a delay. Such delay can\nimpair the vehicles' ability to stabilize the operation of the platoon. In this\npaper, a novel framework is proposed to optimize a platoon's operation while\njointly consider the delay of the wireless network and the stability of the\nvehicle's control system. First, stability analysis for the control system is\nperformed and the maximum wireless system delay requirements which can prevent\nthe instability of the control system are derived. Then, delay analysis is\nconducted to determine the end-to-end delay, including queuing, processing, and\ntransmission delay for the V2V link in the wireless network. Subsequently,\nusing the derived delay, a lower bound and an approximated expression of the\nreliability for the wireless system, defined as the probability that the\nwireless system meets the control system's delay needs, are derived. Then, the\ncontrol parameters are optimized to maximize the derived wireless system\nreliability. Simulation results corroborate the analytical derivations and\nstudy the impact of parameters, such as the platoon size, on the reliability\nperformance of the vehicular platoon. More importantly, the simulation results\ndisclose the benefits of integrating control system and wireless network design\nwhile providing guidelines for designing autonomous platoons so as to realize\nthe required wireless network reliability and control system stability. \n\n"}
{"id": "1804.06372", "contents": "Title: The Sphere Packing Bound For Memoryless Channels Abstract: Sphere packing bounds (SPBs) ---with prefactors that are polynomial in the\nblock length--- are derived for codes on two families of memoryless channels\nusing Augustin's method: (possibly non-stationary) memoryless channels with\n(possibly multiple) additive cost constraints and stationary memoryless\nchannels with convex constraints on the composition (i.e. empirical\ndistribution, type) of the input codewords. A variant of Gallager's bound is\nderived in order to show that these sphere packing bounds are tight in terms of\nthe exponential decay rate of the error probability with the block length under\nmild hypotheses. \n\n"}
{"id": "1804.06454", "contents": "Title: Efficient Search of Compact QC-LDPC and SC-LDPC Convolutional Codes with\n  Large Girth Abstract: We propose a low-complexity method to find quasi-cyclic low-density\nparity-check block codes with girth 10 or 12 and shorter length than those\ndesigned through classical approaches. The method is extended to time-invariant\nspatially coupled low-density parity-check convolutional codes, permitting to\nachieve small syndrome former constraint lengths. Several numerical examples\nare given to show its effectiveness. \n\n"}
{"id": "1804.06543", "contents": "Title: Average Peak Age-of-Information Minimization in UAV-assisted IoT\n  Networks Abstract: Motivated by the need to ensure timely delivery of information (e.g., status\nupdates) in the Internet-of-things (IoT) paradigm, this paper investigates the\nrole of an Unmanned aerial vehicle (UAV) as a mobile relay to minimize the\naverage Peak Age-of-information (PAoI) for a source-destination pair. For this\nsetup, we formulate an optimization problem to jointly optimize the UAV's\nflight trajectory as well as energy and service time allocations for packet\ntransmissions. In order to solve this non-convex problem, we propose an\nefficient iterative algorithm and establish its convergence analytically.\nClosed-form solutions for some sub-problems are also provided. One of the\nsub-problems we solve in this procedure is to jointly optimize the energy and\nservice time allocations for a given trajectory of the UAV. This problem is of\ninterest on its own right because in some cases we may not be able to alter the\nUAV's trajectory based on the locations of the IoT devices (especially when its\nprimary mission is something else). Our numerical results quantify the gains\nthat can be achieved by additionally optimizing the UAV's trajectory. \n\n"}
{"id": "1804.07394", "contents": "Title: QoS Provisioning in Large Wireless Networks Abstract: Quality of service (QoS) provisioning in next-generation mobile\ncommunications systems entails a deep understanding of the delay performance.\nThe delay in wireless networks is strongly affected by the traffic arrival\nprocess and the service process, which in turn depends on the medium access\nprotocol and the signal-to-interference-plus-noise ratio (SINR) distribution.\nIn this work, we characterize the conditional distribution of the service\nprocess given the point process in Poisson bipolar networks. We then provide an\nupper bound on the delay violation probability combining tools from stochastic\nnetwork calculus and stochastic geometry. Furthermore, we analyze the delay\nperformance under statistical queueing constraints using the effective capacity\nformulation. The impact of QoS requirements, network geometry and link distance\non the delay performance is identified. Our results provide useful insights for\nguaranteeing stringent delay requirements in large wireless networks. \n\n"}
{"id": "1804.07642", "contents": "Title: On the Effects of Subpacketization in Content-Centric Mobile Networks Abstract: A large-scale content-centric mobile ad hoc network employing\nsubpacketization is studied in which each mobile node having finite-size cache\nmoves according to the reshuffling mobility model and requests a content object\nfrom the library independently at random according to the Zipf popularity\ndistribution. Instead of assuming that one content object is transferred in a\nsingle time slot, we consider a more challenging scenario where the size of\neach content object is considerably large and thus only a subpacket of a file\ncan be delivered during one time slot, which is motivated by a fast mobility\nscenario. Under our mobility model, we consider a single-hop-based content\ndelivery and characterize the fundamental trade-offs between throughput and\ndelay. The order-optimal throughput-delay trade-off is analyzed by presenting\nthe following two content reception strategies: the sequential reception for\nuncoded caching and the random reception for maximum distance separable\n(MDS)-coded caching. We also perform numerical evaluation to validate our\nanalytical results. In particular, we conduct performance comparisons between\nthe uncoded caching and the MDS-coded caching strategies by identifying the\nregimes in which the performance difference between the two caching strategies\nbecomes prominent with respect to system parameters such as the Zipf exponent\nand the number of subpackets. In addition, we extend our study to the random\nwalk mobility scenario and show that our main results are essentially the same\nas those in the reshuffling mobility model. \n\n"}
{"id": "1804.08101", "contents": "Title: Rician $K$-Factor-Based Analysis of XLOS Service Probability in 5G\n  Outdoor Ultra-Dense Networks Abstract: In this report, we introduce the concept of Rician $K$-factor-based radio\nresource and mobility management for fifth generation (5G) ultra-dense networks\n(UDN), where the information on the gradual visibility between the new radio\nnode B (gNB) and the user equipment (UE)---dubbed X-line-of-sight\n(XLOS)---would be required. We therefore start by presenting the XLOS service\nprobability as a new performance indicator; taking into account both the UE\nserving and neighbor cells. By relying on a lognormal $K$-factor model, a\nclosed-form expression of the XLOS service probability in a 5G outdoor UDN is\nderived in terms of the multivariate Fox H-function; wherefore we develop a\nGPU-enabled MATLAB routine and automate the definition of the underlying\nMellin-Barnes contour via linear optimization. Residue theory is then applied\nto infer the relevant asymptotic behavior and show its practical implications.\nFinally, numerical results are provided for various network configurations, and\nunderpinned by extensive Monte-Carlo simulations. \n\n"}
{"id": "1804.08303", "contents": "Title: A Multi-Beam NOMA Framework for Hybrid mmWave Systems Abstract: In this paper, we propose a multi-beam non-orthogonal multiple access (NOMA)\nframework for hybrid millimeter wave (mmWave) systems. The proposed framework\nenables the use of a limited number of radio frequency (RF) chains in hybrid\nmmWave systems to accommodate multiple users with various angles of departures\n(AODs). A beam splitting technique is introduced to generate multiple analog\nbeams to facilitate NOMA transmission. We analyze the performance of a system\nwhen there are sufficient numbers of antennas driven by a single RF chain at\neach transceiver. Furthermore, we derive the sufficient and necessary\nconditions of antenna allocation, which guarantees that the proposed multi-beam\nNOMA scheme outperforms the conventional time division multiple access (TDMA)\nscheme in terms of system sum-rate. The numerical results confirm the accuracy\nof the developed analysis and unveil the performance gain achieved by the\nproposed multi-beam NOMA scheme over the single-beam NOMA scheme. \n\n"}
{"id": "1804.08333", "contents": "Title: Client Selection for Federated Learning with Heterogeneous Resources in\n  Mobile Edge Abstract: We envision a mobile edge computing (MEC) framework for machine learning (ML)\ntechnologies, which leverages distributed client data and computation resources\nfor training high-performance ML models while preserving client privacy. Toward\nthis future goal, this work aims to extend Federated Learning (FL), a\ndecentralized learning framework that enables privacy-preserving training of\nmodels, to work with heterogeneous clients in a practical cellular network. The\nFL protocol iteratively asks random clients to download a trainable model from\na server, update it with own data, and upload the updated model to the server,\nwhile asking the server to aggregate multiple client updates to further improve\nthe model. While clients in this protocol are free from disclosing own private\ndata, the overall training process can become inefficient when some clients are\nwith limited computational resources (i.e. requiring longer update time) or\nunder poor wireless channel conditions (longer upload time). Our new FL\nprotocol, which we refer to as FedCS, mitigates this problem and performs FL\nefficiently while actively managing clients based on their resource conditions.\nSpecifically, FedCS solves a client selection problem with resource\nconstraints, which allows the server to aggregate as many client updates as\npossible and to accelerate performance improvement in ML models. We conducted\nan experimental evaluation using publicly-available large-scale image datasets\nto train deep neural networks on MEC environment simulations. The experimental\nresults show that FedCS is able to complete its training process in a\nsignificantly shorter time compared to the original FL protocol. \n\n"}
{"id": "1804.09220", "contents": "Title: A Useful Version of the Central Limit Theorem for a General Class of\n  Markov Chains Abstract: In the paper we propose certain conditions, relatively easy to verify, which\nensure the central limit theorem for some general class of Markov chains. To\njustify the usefulness of our criterion, we further verify it for a particular\ndiscrete-time Markov dynamical system. From the application point of view, the\nexamined system provides a useful tool in analysing the stochastic dynamics of\ngene expression in prokaryotes. \n\n"}
{"id": "1804.10334", "contents": "Title: Deep Learning Coordinated Beamforming for Highly-Mobile Millimeter Wave\n  Systems Abstract: Supporting high mobility in millimeter wave (mmWave) systems enables a wide\nrange of important applications such as vehicular communications and wireless\nvirtual/augmented reality. Realizing this in practice, though, requires\novercoming several challenges. First, the use of narrow beams and the\nsensitivity of mmWave signals to blockage greatly impact the coverage and\nreliability of highly-mobile links. Second, highly-mobile users in dense mmWave\ndeployments need to frequently hand-off between base stations (BSs), which is\nassociated with critical control and latency overhead. Further, identifying the\noptimal beamforming vectors in large antenna array mmWave systems requires\nconsiderable training overhead, which significantly affects the efficiency of\nthese mobile systems. In this paper, a novel integrated machine learning and\ncoordinated beamforming solution is developed to overcome these challenges and\nenable highly-mobile mmWave applications. In the proposed solution, a number of\ndistributed yet coordinating BSs simultaneously serve a mobile user. This user\nideally needs to transmit only one uplink training pilot sequence that will be\njointly received at the coordinating BSs using omni or quasi-omni beam\npatterns. These received signals draw a defining signature not only for the\nuser location, but also for its interaction with the surrounding environment.\nThe developed solution then leverages a deep learning model that learns how to\nuse these signatures to predict the beamforming vectors at the BSs. This\nrenders a comprehensive solution that supports highly-mobile mmWave\napplications with reliable coverage, low latency, and negligible training\noverhead. Simulation results show that the proposed deep-learning coordinated\nbeamforming strategy approaches the achievable rate of the genie-aided solution\nthat knows the optimal beamforming vectors with no training overhead. \n\n"}
{"id": "1804.10334", "contents": "Title: Deep Learning Coordinated Beamforming for Highly-Mobile Millimeter Wave\n  Systems Abstract: Supporting high mobility in millimeter wave (mmWave) systems enables a wide\nrange of important applications such as vehicular communications and wireless\nvirtual/augmented reality. Realizing this in practice, though, requires\novercoming several challenges. First, the use of narrow beams and the\nsensitivity of mmWave signals to blockage greatly impact the coverage and\nreliability of highly-mobile links. Second, highly-mobile users in dense mmWave\ndeployments need to frequently hand-off between base stations (BSs), which is\nassociated with critical control and latency overhead. Further, identifying the\noptimal beamforming vectors in large antenna array mmWave systems requires\nconsiderable training overhead, which significantly affects the efficiency of\nthese mobile systems. In this paper, a novel integrated machine learning and\ncoordinated beamforming solution is developed to overcome these challenges and\nenable highly-mobile mmWave applications. In the proposed solution, a number of\ndistributed yet coordinating BSs simultaneously serve a mobile user. This user\nideally needs to transmit only one uplink training pilot sequence that will be\njointly received at the coordinating BSs using omni or quasi-omni beam\npatterns. These received signals draw a defining signature not only for the\nuser location, but also for its interaction with the surrounding environment.\nThe developed solution then leverages a deep learning model that learns how to\nuse these signatures to predict the beamforming vectors at the BSs. This\nrenders a comprehensive solution that supports highly-mobile mmWave\napplications with reliable coverage, low latency, and negligible training\noverhead. Simulation results show that the proposed deep-learning coordinated\nbeamforming strategy approaches the achievable rate of the genie-aided solution\nthat knows the optimal beamforming vectors with no training overhead. \n\n"}
{"id": "1804.10778", "contents": "Title: Hidden Vehicle Sensing via Asynchronous V2V Transmission: A\n  Multi-Path-Geometry Approach Abstract: Accurate vehicular sensing is a basic and important operation in autonomous\ndriving. Unfortunately, the existing techniques have their own limitations. For\ninstance, the communication-based approach (e.g., transmission of GPS\ninformation) has high latency and low reliability while the reflection-based\napproach (e.g., RADAR) is incapable of detecting hidden vehicles (HVs) without\nline-of-sight. This is arguably the reason behind some recent fatal accidents\ninvolving autonomous vehicles. To address this issue, this paper presents a\nnovel HV-sensing technology that exploits multi-path transmission from a HV to\na sensing vehicle (SV). The powerful technology enables the SV to detect\nmultiple HV-state parameters including position, orientation of driving\ndirection, and size. Its implementation does not even require\ntransmitter-receiver synchronization like conventional mobile positioning\ntechniques. Our design approach leverages estimated information on multi-path\n(AoA/AoD/ToA) and their geometric relations. As a result, a complex system of\nequations or optimization problems, where the desired HV-state parameters are\nvariables, can be formulated for different channel-noise conditions. The\ndevelopment of intelligent solution methods ranging from least-square estimator\nto disk/box minimization yields a set of practical HV-sensing techniques. We\nstudy their feasibility conditions in terms of the required number of paths.\nFurthermore, practical solutions, including sequential path combining and\nrandom directional beamforming, are proposed to enable HV-sensing given\ninsufficient paths. Last, realistic simulation of driving in both highway and\nrural scenarios demonstrates the effectiveness of the proposed techniques. In\nsummary, the proposed technique will enhance the capabilities of existing\nvehicular sensing technologies by enabling HV-sensing. \n\n"}
{"id": "1805.00061", "contents": "Title: Machine Learning for Predictive On-Demand Deployment of UAVs for\n  Wireless Communications Abstract: In this paper, a novel machine learning (ML) framework is proposed for\nenabling a predictive, efficient deployment of unmanned aerial vehicles (UAVs),\nacting as aerial base stations (BSs), to provide on-demand wireless service to\ncellular users. In order to have a comprehensive analysis of cellular traffic,\nan ML framework based on a Gaussian mixture model (GMM) and a weighted\nexpectation maximization (WEM) algorithm is introduced to predict the potential\nnetwork congestion. Then, the optimal deployment of UAVs is studied to minimize\nthe transmit power needed to satisfy the communication demand of users in the\ndownlink, while also minimizing the power needed for UAV mobility, based on the\npredicted cellular traffic. To this end, first, the optimal partition of\nservice areas of each UAV is derived, based on a fairness principle. Next, the\noptimal location of each UAV that minimizes the total power consumption is\nderived. Simulation results show that the proposed ML approach can reduce the\nrequired downlink transmit power and improve the power efficiency by over 20%,\ncompared with an optimal deployment of UAVs with no ML prediction. \n\n"}
{"id": "1805.00225", "contents": "Title: Elevation Beamforming with Full Dimension MIMO Architectures in 5G\n  Systems: A Tutorial Abstract: Full dimension (FD) multiple-input multiple-output (MIMO) technology has\nattracted substantial research attention from both wireless industry and\nacademia in the last few years as a promising technique for next-generation\nwireless communication networks. FD-MIMO scenarios utilize a planar\ntwo-dimensional active antenna system (AAS) that not only allows a large number\nof antenna elements to be placed within feasible base station (BS) form\nfactors, but also provides the ability of adaptive electronic beam control over\nboth the elevation and the traditional azimuth dimensions. This paper presents\na tutorial on elevation beamforming analysis for cellular networks utilizing FD\nMassive MIMO antenna arrays. In contrast to existing works that focus on the\nstandardization of FD-MIMO in the 3rd Generation Partnership Project (3GPP),\nthis tutorial is distinguished by its depth with respect to the theoretical\naspects of antenna array and 3D channel modeling. In an attempt to bridge the\ngap between industry and academia, this preliminary tutorial introduces the\nrelevant array and transceiver architecture designs proposed in the 3GPP\nRelease 13 that enable elevation beamforming. Then it presents and compares two\ndifferent 3D channel modeling approaches that can be utilized for the\nperformance analysis of elevation beamforming techniques. The spatial\ncorrelation in FD-MIMO arrays is characterized and compared based on both\nchannel modeling approaches and some insights into the impact of different\nchannel and array parameters on the correlation are drawn. All these aspects\nare put together to provide a mathematical framework for the design of\nelevation beamforming schemes in single-cell and multi-cell scenarios.\nSimulation examples associated with comparisons and discussions are also\npresented. To this end, this paper highlights the state-of-the-art research and\npoints out future research directions. \n\n"}
{"id": "1805.01808", "contents": "Title: Stochastic Geometry-based Uplink Analysis of Massive MIMO Systems with\n  Fractional Pilot Reuse Abstract: In this work, we analyze the performance of the uplink (UL) of a massive MIMO\nnetwork considering an asymptotically large number of antennas at base stations\n(BSs). We model the locations of BSs as a homogeneous Poisson point process\n(PPP) and assume that their service regions are limited to their respective\nPoisson-Voronoi cells (PVCs). Further, for each PVC, based on a threshold\nradius, we model the cell center (CC) region as the Johnson-Mehl (JM) cell of\nits BS while rest of the PVC is deemed as the cell edge (CE) region. The CC and\nCE users are located uniformly at random independently of each other in the JM\ncell and CE region, respectively. In addition, we consider a fractional pilot\nreuse (FPR) scheme where two different sets of pilot sequences are used for CC\nand CE users with the objective of reducing the interference due to pilot\ncontamination for CE users. Based on the above system model, we derive\nanalytical expressions for the UL signal-to-interference-and-noise ratio (SINR)\ncoverage probability and average spectral efficiency (SE) for randomly selected\nCC and CE users. In addition, we present an approximate expression for the\naverage cell SE. One of the key intermediate results in our analysis is the\napproximate but accurate characterization of the distributions of the CC and CE\nareas of a typical cell. Another key intermediate step is the accurate\ncharacterization of the pair correlation functions of the point processes\nformed by the interfering CC and CE users that subsequently enables the\ncoverage probability analysis. From our system analysis, we present a\npartitioning rule for the number of pilot sequences to be used for CC and CE\nusers as a function of threshold radius that improves the average CE user SE\nwhile achieving similar CC user SE with respect to unity pilot reuse. \n\n"}
{"id": "1805.05906", "contents": "Title: Joint Computation and Communication Cooperation for Energy-Efficient\n  Mobile Edge Computing Abstract: This paper proposes a novel user cooperation approach in both computation and\ncommunication for mobile edge computing (MEC) systems to improve the energy\nefficiency for latency-constrained computation. We consider a basic three-node\nMEC system consisting of a user node, a helper node, and an access point (AP)\nnode attached with an MEC server, in which the user has latency-constrained and\ncomputation-intensive tasks to be executed. We consider two different\ncomputation offloading models, namely the partial and binary offloading,\nrespectively. Under this setup, we focus on a particular finite time block and\ndevelop an efficient four-slot transmission protocol to enable the joint\ncomputation and communication cooperation. Besides the local task computing\nover the whole block, the user can offload some computation tasks to the helper\nin the first slot, and the helper cooperatively computes these tasks in the\nremaining time; while in the second and third slots, the helper works as a\ncooperative relay to help the user offload some other tasks to the AP for\nremote execution in the fourth slot. For both cases with partial and binary\noffloading, we jointly optimize the computation and communication resources\nallocation at both the user and the helper (i.e., the time and transmit power\nallocations for offloading, and the CPU frequencies for computing), so as to\nminimize their total energy consumption while satisfying the user's computation\nlatency constraint. Although the two problems are non-convex in general, we\npropose efficient algorithms to solve them optimally. Numerical results show\nthat the proposed joint computation and communication cooperation approach\nsignificantly improves the computation capacity and energy efficiency at the\nuser and helper nodes, as compared to other benchmark schemes without such a\njoint design. \n\n"}
{"id": "1805.06046", "contents": "Title: Coded Iterative Computing using Substitute Decoding Abstract: In this paper, we propose a new coded computing technique called \"substitute\ndecoding\" for general iterative distributed computation tasks. In the first\npart of the paper, we use PageRank as a simple example to show that substitute\ndecoding can make the computation of power iterations solving PageRank on\nsparse matrices robust to erasures in distributed systems. For these sparse\nmatrices, codes with dense generator matrices can significantly increase\nstorage costs and codes with low-density generator matrices (LDGM) are\npreferred. Surprisingly, we show through both theoretical analysis and\nsimulations that when substitute decoding is used, coded iterative computing\nwith extremely low-density codes (2 or 3 non-zeros in each row of the generator\nmatrix) can achieve almost the same convergence rate as noiseless techniques,\ndespite the poor error-correction ability of LDGM codes. In the second part of\nthe paper, we discuss applications of substitute decoding beyond solving linear\nsystems and PageRank. These applications include (1) computing eigenvectors,\n(2) computing the truncated singular value decomposition (SVD), and (3)\ngradient descent. These examples show that the substitute decoding algorithm is\nuseful in a wide range of applications. \n\n"}
{"id": "1805.06532", "contents": "Title: Beyond 5G with UAVs: Foundations of a 3D Wireless Cellular Network Abstract: In this paper, a novel concept of three-dimensional (3D) cellular networks,\nthat integrate drone base stations (drone-BS) and cellular-connected drone\nusers (drone-UEs), is introduced. For this new 3D cellular architecture, a\nnovel framework for network planning for drone-BSs as well as latency-minimal\ncell association for drone-UEs is proposed. For network planning, a tractable\nmethod for drone-BSs' deployment based on the notion of truncated octahedron\nshapes is proposed that ensures full coverage for a given space with minimum\nnumber of drone-BSs. In addition, to characterize frequency planning in such 3D\nwireless networks, an analytical expression for the feasible integer frequency\nreuse factors is derived. Subsequently, an optimal 3D cell association scheme\nis developed for which the drone-UEs' latency, considering transmission,\ncomputation, and backhaul delays, is minimized. To this end, first, the spatial\ndistribution of the drone-UEs is estimated using a kernel density estimation\nmethod, and the parameters of the estimator are obtained using a\ncross-validation method. Then, according to the spatial distribution of\ndrone-UEs and the locations of drone-BSs, the latency-minimal 3D cell\nassociation for drone-UEs is derived by exploiting tools from optimal transport\ntheory. Simulation results show that the proposed approach reduces the latency\nof drone-UEs compared to the classical cell association approach that uses a\nsignal-to-interference-plus-noise ratio (SINR) criterion. In particular, the\nproposed approach yields a reduction of up to 46% in the average latency\ncompared to the SINR-based association. The results also show that the proposed\nlatency-optimal cell association improves the spectral efficiency of a 3D\nwireless cellular network of drones. \n\n"}
{"id": "1805.06586", "contents": "Title: $W^{2,p}$-solutions of parabolic SPDEs in general domains Abstract: The Dirichlet problem for a class of stochastic partial differential\nequations is studied in Sobolev spaces. The existence and uniqueness result is\nproved under certain compatibility conditions that ensure the finiteness of\n$L^{p}(\\Omega\\times(0,T),W^{2,p}(G))$-norms of solutions. The H\\\"older\ncontinuity of solutions and their derivatives is also obtained by embedding. \n\n"}
{"id": "1805.06982", "contents": "Title: A spin glass model for reconstructing nonlinearly encrypted signals\n  corrupted by noise Abstract: An encryption of a signal ${\\bf s}\\in\\mathbb{R^N}$ is a random mapping ${\\bf\ns}\\mapsto \\textbf{y}=(y_1,\\ldots,y_M)^T\\in \\mathbb{R}^M$ which can be corrupted\nby an additive noise. Given the Encryption Redundancy Parameter (ERP)\n$\\mu=M/N\\ge 1$, the signal strength parameter $R=\\sqrt{\\sum_i s_i^2/N}$, and\nthe ('bare') noise-to-signal ratio (NSR) $\\gamma\\ge 0$, we consider the problem\nof reconstructing ${\\bf s}$ from its corrupted image by a Least Square Scheme\nfor a certain class of random Gaussian mappings. The problem is equivalent to\nfinding the configuration of minimal energy in a certain version of spherical\nspin glass model, with squared Gaussian-distributed random potential. We use\nthe Parisi replica symmetry breaking scheme to evaluate the mean overlap\n$p_{\\infty}\\in [0,1]$ between the original signal and its recovered image\n(known as 'estimator') as $N\\to \\infty$, which is a measure of the quality of\nthe signal reconstruction. We explicitly analyze the general case of\nlinear-quadratic family of random mappings and discuss the full $p_{\\infty}\n(\\gamma)$ curve. When nonlinearity exceeds a certain threshold but redundancy\nis not yet too big, the replica symmetric solution is necessarily broken in\nsome interval of NSR. We show that encryptions with a nonvanishing linear\ncomponent permit reconstructions with $p_{\\infty}>0$ for any $\\mu>1$ and any\n$\\gamma<\\infty$, with $p_{\\infty}\\sim \\gamma^{-1/2}$ as $\\gamma\\to \\infty$. In\ncontrast, for the case of purely quadratic nonlinearity, for any ERP $\\mu>1$\nthere exists a threshold NSR value $\\gamma_c(\\mu)$ such that $p_{\\infty}=0$ for\n$\\gamma>\\gamma_c(\\mu)$ making the reconstruction impossible. The behaviour\nclose to the threshold is given by $p_{\\infty}\\sim (\\gamma_c-\\gamma)^{3/4}$ and\nis controlled by the replica symmetry breaking mechanism. \n\n"}
{"id": "1805.07132", "contents": "Title: Cooperative Multi-Bitrate Video Caching and Transcoding in Multicarrier\n  NOMA-Assisted Heterogeneous Virtualized MEC Networks Abstract: Cooperative video caching and transcoding in mobile edge computing (MEC)\nnetworks is a new paradigm for future wireless networks, e.g., 5G and 5G\nbeyond, to reduce scarce and expensive backhaul resource usage by prefetching\nvideo files within radio access networks (RANs). Integration of this technique\nwith other advent technologies, such as wireless network virtualization and\nmulticarrier non-orthogonal multiple access (MC-NOMA), provides more flexible\nvideo delivery opportunities, which leads to enhancements both for the\nnetwork's revenue and for the end-users' service experience. In this regard, we\npropose a two-phase RAF for a parallel cooperative joint multi-bitrate video\ncaching and transcoding in heterogeneous virtualized MEC networks. In the cache\nplacement phase, we propose novel proactive delivery-aware cache placement\nstrategies (DACPSs) by jointly allocating physical and radio resources based on\nnetwork stochastic information to exploit flexible delivery opportunities.\nThen, for the delivery phase, we propose a delivery policy based on the user\nrequests and network channel conditions. The optimization problems\ncorresponding to both phases aim to maximize the total revenue of network\nslices, i.e., virtual networks. Both problems are non-convex and suffer from\nhigh-computational complexities. For each phase, we show how the problem can be\nsolved efficiently. We also propose a low-complexity RAF in which the\ncomplexity of the delivery algorithm is significantly reduced. A Delivery-aware\ncache refreshment strategy (DACRS) in the delivery phase is also proposed to\ntackle the dynamically changes of network stochastic information. Extensive\nnumerical assessments demonstrate a performance improvement of up to 30% for\nour proposed DACPSs and DACRS over traditional approaches. \n\n"}
{"id": "1805.07972", "contents": "Title: Massive MIMO with Spatially Correlated Rician Fading Channels Abstract: This paper considers multi-cell Massive MIMO (multiple-input multiple-output)\nsystems where the channels are spatially correlated Rician fading. The channel\nmodel is composed of a deterministic line-of-sight (LoS) path and a stochastic\nnon-line-of-sight (NLoS) component describing a practical spatially correlated\nmultipath environment. We derive the statistical properties of the minimum mean\nsquared error (MMSE), element-wise MMSE (EW-MMSE), and least-square (LS)\nchannel estimates for this model. Using these estimates for maximum ratio (MR)\ncombining and precoding, rigorous closed-form uplink (UL) and downlink (DL)\nspectral efficiency (SE) expressions are derived and analyzed. The asymptotic\nSE behavior when using the different channel estimators are also analyzed.\nNumerical results show that the SE is higher when using the MMSE estimator than\nthe other estimators, and the performance gap increases with the number of\nantennas. \n\n"}
{"id": "1805.08993", "contents": "Title: Eigenvector correlations in the complex Ginibre ensemble Abstract: The complex Ginibre ensemble is an $N\\times N$ non-Hermitian random matrix\nover $\\mathbb{C}$ with i.i.d. complex Gaussian entries normalized to have mean\nzero and variance $1/N$. Unlike the Gaussian unitary ensemble, for which the\neigenvectors are distributed according to Haar measure on the compact group\n$U(N)$, independently of the eigenvalues, the geometry of the eigenbases of the\nGinibre ensemble are not particularly well understood. In this paper we\nsystematically study properties of eigenvector correlations in this matrix\nensemble. In particular, we uncover an extended algebraic structure which\ndescribes their asymptotic behavior (as $N$ goes to infinity). Our work extends\nprevious results of Chalker and Mehlig [CM98], in which the correlation for\npairs of eigenvectors was computed. \n\n"}
{"id": "1805.09066", "contents": "Title: Asymptotic Performance Analysis of GSVD-NOMA Systems with a Large-Scale\n  Antenna Array Abstract: This paper considers a multiple-input multiple-output (MIMO) downlink\ncommunication scenario with one base station and two users, where each user is\nequipped with m antennas and the base station is equipped with n antennas. To\nefficiently exploit the spectrum resources, we propose a transmission protocol\nwhich combines generalized singular value decomposition (GSVD) and\nnon-orthogonal multiple access (NOMA). The average data rates achieved by the\ntwo users are adopted as performance metrics for evaluation of the proposed\nGSVD-NOMA scheme. In particular, we first characterize the limiting\ndistribution of the squared generalized singular values of the two users'\nchannel matrices for the asymptotic case where the numbers of transmit and\nreceive antennas approach infinity. Then, we calculate the normalized average\nindividual rates of the users in the considered asymptotic regime. Furthermore,\nwe extend the proposed GSVD-NOMA scheme to the MIMO downlink communication\nscenario with more than two users by using a hybrid multiple access (MA)\napproach, where the base station first divides the users into different groups,\nthen the proposed GSVD-NOMA scheme is implemented within each group, and\ndifferent groups are allocated with orthogonal bandwidth resources. Finally,\nnumerical results are provided to validate the effectiveness of the proposed\nGSVD-NOMA protocol, and the accuracy of the developed analytical results. \n\n"}
{"id": "1805.09253", "contents": "Title: Federated Learning for Ultra-Reliable Low-Latency V2V Communications Abstract: In this paper, a novel joint transmit power and resource allocation approach\nfor enabling ultra-reliable low-latency communication (URLLC) in vehicular\nnetworks is proposed. The objective is to minimize the network-wide power\nconsumption of vehicular users (VUEs) while ensuring high reliability in terms\nof probabilistic queuing delays. In particular, a reliability measure is\ndefined to characterize extreme events (i.e., when vehicles' queue lengths\nexceed a predefined threshold with non-negligible probability) using extreme\nvalue theory (EVT). Leveraging principles from federated learning (FL), the\ndistribution of these extreme events corresponding to the tail distribution of\nqueues is estimated by VUEs in a decentralized manner. Finally, Lyapunov\noptimization is used to find the joint transmit power and resource allocation\npolicies for each VUE in a distributed manner. The proposed solution is\nvalidated via extensive simulations using a Manhattan mobility model. It is\nshown that FL enables the proposed distributed method to estimate the tail\ndistribution of queues with an accuracy that is very close to a centralized\nsolution with up to 79\\% reductions in the amount of data that need to be\nexchanged. Furthermore, the proposed method yields up to 60\\% reductions of\nVUEs with large queue lengths, without an additional power consumption,\ncompared to an average queue-based baseline. Compared to systems with fixed\npower consumption and focusing on queue stability while minimizing average\npower consumption, the reduction in extreme events of the proposed method is\nabout two orders of magnitude. \n\n"}
{"id": "1805.09753", "contents": "Title: Reliable Communication over Arbitrarily Varying Channels under\n  Block-Restricted Jamming Abstract: We study reliable communication in uncoordinated vehicular communication from\nthe perspective of Shannon theory. Our system model for the information\ntransmission is that of an Arbitrarily Varying Channel (AVC): One\nsender-receiver pair wants to communicate reliably, no matter what the input of\na second sender is. The second sender is assumed to be uncoordinated and\ninterfering, but is supposed to follow the rational goal of transmitting\ninformation otherwise. We prove that repetition coding can increase the\ncapacity of such a system by relating the notion of symmetrizability of an\narbitrarily varying channel to invertibility of the corresponding channel\nmatrix. Explicit upper bounds on the number of repetitions needed to prevent\nsystem breakdown through diversity are provided. Further we introduce the\nnotion of block-restricted jamming and present a lower and an upper bound on\nthe maximum error capacity of the corresponding restricted AVC. \n\n"}
{"id": "1805.11915", "contents": "Title: Iterative Antenna Selection for Secrecy Enhancement in Massive MIMO\n  Wiretap Channels Abstract: The growth of interest in massive MIMO systems is accompanied with hardware\ncost and computational complexity. Antenna selection is an efficient approach\nto overcome this cost-plus-complexity issue which also enhances the secrecy\nperformance in wiretap settings. Optimal antenna selection requires exhaustive\nsearch which is computationally infeasible for settings with large dimensions.\nThis paper develops an iterative algorithm for antenna selection in massive\nmultiuser MIMO wiretap settings. The algorithm takes a stepwise approach to\nfind a suitable subset of transmit antennas. Numerical investigations depict a\nsignificant enhancement in the secrecy performance. \n\n"}
{"id": "1805.12333", "contents": "Title: False-Accept/False-Reject Trade-offs in Biometric Authentication Systems Abstract: Biometric authentication systems, based on secret key generation, work as\nfollows. In the enrollment stage, an individual provides a biometric signal\nthat is mapped into a secret key and a helper message, the former being\nprepared to become available to the system at a later time (for\nauthentication), and the latter is stored in a public database. When an\nauthorized user requests authentication, claiming his/her identity as one of\nthe subscribers, he/she has to provide a biometric signal again, and then the\nsystem, which retrieves also the helper message of the claimed subscriber,\nproduces an estimate of the secret key, that is finally compared to the secret\nkey of the claimed user. In case of a match, the authentication request is\napproved, otherwise, it is rejected.\n  Evidently, there is an inherent tension between two desired, but conflicting,\nproperties of the helper message encoder: on the one hand, the encoding should\nbe informative enough concerning the identity of the real subscriber, in order\nto approve him/her in the authentication stage, but on the other hand, it\nshould not be too informative, as otherwise, unauthorized imposters could\neasily fool the system and gain access. A good encoder should then trade off\nthe two kinds of errors: the false reject (FR) error and the false accept (FA)\nerror.\n  In this work, we investigate trade-offs between the random coding FR error\nexponent and the best achievable FA error exponent. We compare two types of\nensembles of codes: fixed-rate codes and variable-rate codes, and we show that\nthe latter class of codes offers considerable improvement compared to the\nformer. In doing this, we characterize the optimal rate functions for both\ntypes of codes. We also examine privacy leakage constraints for both fixed-rate\ncodes and variable-rate codes. \n\n"}
{"id": "1805.12345", "contents": "Title: Optimal cyclic $(r,\\delta)$ locally repairable codes with unbounded\n  length Abstract: Locally repairable codes with locality $r$ ($r$-LRCs for short) were\nintroduced by Gopalan et al. \\cite{1} to recover a failed node of the code from\nat most other $r$ available nodes. And then $(r,\\delta)$ locally repairable\ncodes ($(r,\\delta)$-LRCs for short) were produced by Prakash et al. \\cite{2}\nfor tolerating multiple failed nodes. An $r$-LRC can be viewed as an\n$(r,2)$-LRC. An $(r,\\delta)$-LRC is called optimal if it achieves the\nSingleton-type bound. It has been a great challenge to construct $q$-ary\noptimal $(r,\\delta)$-LRCs with length much larger than $q$. Surprisingly, Luo\net al. \\cite{3} presented a construction of $q$-ary optimal $r$-LRCs of minimum\ndistances 3 and 4 with unbounded lengths (i.e., lengths of these codes are\nindependent of $q$) via cyclic codes.\n  In this paper, inspired by the work of \\cite{3}, we firstly construct two\nclasses of optimal cyclic $(r,\\delta)$-LRCs with unbounded lengths and minimum\ndistances $\\delta+1$ or $\\delta+2$, which generalize the results about the\n$\\delta=2$ case given in \\cite{3}. Secondly, with a slightly stronger\ncondition, we present a construction of optimal cyclic $(r,\\delta)$-LRCs with\nunbounded length and larger minimum distance $2\\delta$. Furthermore, when\n$\\delta=3$, we give another class of optimal cyclic $(r,3)$-LRCs with unbounded\nlength and minimum distance $6$. \n\n"}
{"id": "1806.00118", "contents": "Title: Statistical Problems with Planted Structures: Information-Theoretical\n  and Computational Limits Abstract: Over the past few years, insights from computer science, statistical physics,\nand information theory have revealed phase transitions in a wide array of\nhigh-dimensional statistical problems at two distinct thresholds: One is the\ninformation-theoretical (IT) threshold below which the observation is too noisy\nso that inference of the ground truth structure is impossible regardless of the\ncomputational cost; the other is the computational threshold above which\ninference can be performed efficiently, i.e., in time that is polynomial in the\ninput size. In the intermediate regime, inference is information-theoretically\npossible, but conjectured to be computationally hard.\n  This article provides a survey of the common techniques for determining the\nsharp IT and computational limits, using community detection and submatrix\ndetection as illustrating examples. For IT limits, we discuss tools including\nthe first and second moment method for analyzing the maximum likelihood\nestimator, information-theoretic methods for proving impossibility results\nusing mutual information and rate-distortion theory, and methods originated\nfrom statistical physics such as interpolation method. To investigate\ncomputational limits, we describe a common recipe to construct a randomized\npolynomial-time reduction scheme that approximately maps instances of the\nplanted clique problem to the problem of interest in total variation distance. \n\n"}
{"id": "1806.00582", "contents": "Title: Federated Learning with Non-IID Data Abstract: Federated learning enables resource-constrained edge compute devices, such as\nmobile phones and IoT devices, to learn a shared model for prediction, while\nkeeping the training data local. This decentralized approach to train models\nprovides privacy, security, regulatory and economic benefits. In this work, we\nfocus on the statistical challenge of federated learning when local data is\nnon-IID. We first show that the accuracy of federated learning reduces\nsignificantly, by up to 55% for neural networks trained for highly skewed\nnon-IID data, where each client device trains only on a single class of data.\nWe further show that this accuracy reduction can be explained by the weight\ndivergence, which can be quantified by the earth mover's distance (EMD) between\nthe distribution over classes on each device and the population distribution.\nAs a solution, we propose a strategy to improve training on non-IID data by\ncreating a small subset of data which is globally shared between all the edge\ndevices. Experiments show that accuracy can be increased by 30% for the\nCIFAR-10 dataset with only 5% globally shared data. \n\n"}
{"id": "1806.00813", "contents": "Title: Wideband Massive MIMO Channel Estimation via Sequential Atomic Norm\n  Minimization Abstract: The recently introduced atomic norm minimization (ANM) framework for\nparameter estimation is a promising candidate towards low overhead channel\nestimation in wireless communications. However, previous works on ANM-based\nchannel estimation evaluated performance on channels with artificially imposed\nchannel path separability, which cannot be guaranteed in practice. In addition,\ndirect application of the ANM framework for massive MIMO channel estimation is\ncomputationally infeasible due to the large dimensions. In this paper, a\nlow-complexity ANM-based channel estimator for wideband massive MIMO is\nproposed, consisting of two sequential steps, the first estimating the channel\nover the spatial and the second over the frequency dimension. Its mean squared\nerror performance is analytically characterized in terms of tight lower bounds.\nIt is shown that the proposed algorithm achieves excellent performance that is\nclose to the best that can be achieved by any unbiased channel estimator in the\nregime of low to moderate number of channel paths, without any restrictions on\ntheir separability. \n\n"}
{"id": "1806.02405", "contents": "Title: Polar Code Moderate Deviation: Recovering the Scaling Exponent Abstract: In 2008 Arikan proposed polar coding [arXiv:0807.3917] which we summarize as\nfollows: (a) From the root channel $W$ synthesize recursively a series of\nchannels $W_N^{(1)},\\dotsc,W_N^{(N)}$. (b) Select sophisticatedly a subset $A$\nof synthetic channels. (c) Transmit information using synthetic channels\nindexed by $A$ and freeze the remaining synthetic channels.\n  Arikan gives each synthetic channel a score (called the Bhattacharyya\nparameter) that determines whether it should be selected or frozen. As $N$\ngrows, a majority of the scores are either very high or very low, i.e., they\npolarize. By characterizing how fast they polarize, Arikan showed that polar\ncoding is able to produce a series of codes that achieve capacity on symmetric\nbinary-input memoryless channels.\n  In measuring how the scores polarize the relation among block length, gap to\ncapacity, and block error probability are studied. In particular, the error\nexponent regime fixes the gap to capacity and varies the other two. The scaling\nexponent regime fixes the block error probability and varies the other two. The\nmoderate deviation regime varies all three factors at once.\n  The latest result [arxiv:1501.02444, Theorem 7] in the moderate deviation\nregime does not imply the scaling exponent regime as a special case. We give a\nresult that does. (See Corollary 8.) \n\n"}
{"id": "1806.03227", "contents": "Title: An Information-Percolation Bound for Spin Synchronization on General\n  Graphs Abstract: This paper considers the problem of reconstructing $n$ independent uniform\nspins $X_1,\\dots,X_n$ living on the vertices of an $n$-vertex graph $G$, by\nobserving their interactions on the edges of the graph. This captures instances\nof models such as (i) broadcasting on trees, (ii) block models, (iii)\nsynchronization on grids, (iv) spiked Wigner models. The paper gives an\nupper-bound on the mutual information between two vertices in terms of a bond\npercolation estimate. Namely, the information between two vertices' spins is\nbounded by the probability that these vertices are connected in a bond\npercolation model, where edges are opened with a probability that \"emulates\"\nthe edge-information. Both the information and the open-probability are based\non the Chi-squared mutual information. The main results allow us to re-derive\nknown results for information-theoretic non-reconstruction in models (i)-(iv),\nwith more direct or improved bounds in some cases, and to obtain new results,\nsuch as for a spiked Wigner model on grids. The main result also implies a new\nsubadditivity property for the Chi-squared mutual information for symmetric\nchannels and general graphs, extending the subadditivity property obtained by\nEvans-Kenyon-Peres-Schulman [EKPS00] for trees. \n\n"}
{"id": "1806.03803", "contents": "Title: Chaining Mutual Information and Tightening Generalization Bounds Abstract: Bounding the generalization error of learning algorithms has a long history,\nwhich yet falls short in explaining various generalization successes including\nthose of deep learning. Two important difficulties are (i) exploiting the\ndependencies between the hypotheses, (ii) exploiting the dependence between the\nalgorithm's input and output. Progress on the first point was made with the\nchaining method, originating from the work of Kolmogorov, and used in the\nVC-dimension bound. More recently, progress on the second point was made with\nthe mutual information method by Russo and Zou '15. Yet, these two methods are\ncurrently disjoint. In this paper, we introduce a technique to combine the\nchaining and mutual information methods, to obtain a generalization bound that\nis both algorithm-dependent and that exploits the dependencies between the\nhypotheses. We provide an example in which our bound significantly outperforms\nboth the chaining and the mutual information bounds. As a corollary, we tighten\nDudley's inequality when the learning algorithm chooses its output from a small\nsubset of hypotheses with high probability. \n\n"}
{"id": "1806.04193", "contents": "Title: Stochastic Geometric Coverage Analysis in mmWave Cellular Networks with\n  Realistic Channel and Antenna Radiation Models Abstract: Millimeter-wave (mmWave) bands will play an important role in 5G wireless\nsystems. The system performance can be assessed by using models from stochastic\ngeometry that cater for the directivity in the desired signal transmissions as\nwell as the interference, and by calculating the\nsignal-to-interference-plus-noise ratio (SINR) coverage. Nonetheless, the\ncorrectness of the existing coverage expressions derived through stochastic\ngeometry may be questioned, as it is not clear whether they capture the impact\nof the detailed mmWave channel and antenna features. In this study, we propose\nan SINR coverage analysis framework that includes realistic channel model (from\nNYU) and antenna element radiation patterns (with isotropic/directional\nradiation). We first introduce two parameters, aligned gain and misaligned\ngain, associated with the desired signal beam and the interfering signal beam,\nrespectively. We provide the distributions of the aligned and misaligned gains\nthrough curve fitting of system-simulation results. The distribution of these\ngains is used to determine the distribution of the SINR. We compare the\nobtained analytical SINR coverage with the corresponding SINR coverage\ncalculated via system-level simulations. The results show that both aligned and\nmisaligned gains can be modeled as exponential-logarithmically distributed\nrandom variables with the highest accuracy, and can further be approximated as\nexponentially distributed random variables with reasonable accuracy. These\napproximations are thus expected to be useful to evaluate the system\nperformance under ultra-reliable and low-latency communication (URLLC) and\nevolved mobile broadband (eMBB) scenarios, respectively. \n\n"}
{"id": "1806.04343", "contents": "Title: Phase transitions in spiked matrix estimation: information-theoretic\n  analysis Abstract: We study here the so-called spiked Wigner and Wishart models, where one\nobserves a low-rank matrix perturbed by some Gaussian noise. These models\nencompass many classical statistical tasks such as sparse PCA, submatrix\nlocalization, community detection or Gaussian mixture clustering. The goal of\nthese notes is to present in a unified manner recent results (as well as new\ndevelopments) on the information-theoretic limits of these spiked matrix\nmodels. We compute the minimal mean squared error for the estimation of the\nlow-rank signal and compare it to the performance of spectral estimators and\nmessage passing algorithms. Phase transition phenomena are observed: depending\non the noise level it is either impossible, easy (i.e. using polynomial-time\nestimators) or hard (information-theoretically possible, but no efficient\nalgorithm is known to succeed) to recover the signal. \n\n"}
{"id": "1806.05776", "contents": "Title: Tiny Codes for Guaranteeable Delay Abstract: Future 5G systems will need to support ultra-reliable low-latency\ncommunications scenarios. From a latency-reliability viewpoint, it is\ninefficient to rely on average utility-based system design. Therefore, we\nintroduce the notion of guaranteeable delay which is the average delay plus\nthree standard deviations of the mean. We investigate the trade-off between\nguaranteeable delay and throughput for point-to-point wireless erasure links\nwith unreliable and delayed feedback, by bringing together signal flow\ntechniques to the area of coding. We use tiny codes, i.e. sliding window by\ncoding with just 2 packets, and design three variations of selective-repeat ARQ\nprotocols, by building on the baseline scheme, i.e. uncoded ARQ, developed by\nAusavapattanakun and Nosratinia: (i) Hybrid ARQ with soft combining at the\nreceiver; (ii) cumulative feedback-based ARQ without rate adaptation; and (iii)\nCoded ARQ with rate adaptation based on the cumulative feedback. Contrasting\nthe performance of these protocols with uncoded ARQ, we demonstrate that HARQ\nperforms only slightly better, cumulative feedback-based ARQ does not provide\nsignificant throughput while it has better average delay, and Coded ARQ can\nprovide gains up to about 40% in terms of throughput. Coded ARQ also provides\ndelay guarantees, and is robust to various challenges such as imperfect and\ndelayed feedback, burst erasures, and round-trip time fluctuations. This\nfeature may be preferable for meeting the strict end-to-end latency and\nreliability requirements of future use cases of ultra-reliable low-latency\ncommunications in 5G, such as mission-critical communications and industrial\ncontrol for critical control messaging. \n\n"}
{"id": "1806.05852", "contents": "Title: Coupled conditional backward sampling particle filter Abstract: The conditional particle filter (CPF) is a promising algorithm for general\nhidden Markov model smoothing. Empirical evidence suggests that the variant of\nCPF with backward sampling (CBPF) performs well even with long time series.\nPrevious theoretical results have not been able to demonstrate the improvement\nbrought by backward sampling, whereas we provide rates showing that CBPF can\nremain effective with a fixed number of particles independent of the time\nhorizon. Our result is based on analysis of a new coupling of two CBPFs, the\ncoupled conditional backward sampling particle filter (CCBPF). We show that\nCCBPF has good stability properties in the sense that with fixed number of\nparticles, the coupling time in terms of iterations increases only linearly\nwith respect to the time horizon under a general (strong mixing) condition. The\nCCBPF is useful not only as a theoretical tool, but also as a practical method\nthat allows for unbiased estimation of smoothing expectations, following the\nrecent developments by Jacob et al. (to appear). Unbiased estimation has many\nadvantages, such as enabling the construction of asymptotically exact\nconfidence intervals and straightforward parallelisation. \n\n"}
{"id": "1806.06370", "contents": "Title: Age Dependent Hawkes Process Abstract: In the last decade, Hawkes processes have received a lot of attention as good\nmodels for functional connectivity in neural spiking networks. In this paper we\nconsider a variant of this process, the Age Dependent Hawkes process, which\nincorporates individual post-jump behaviour into the framework of the usual\nHawkes model. This allows to model recovery properties such as refractory\nperiods, where the effects of the network are momentarily being suppressed or\naltered. We show how classical stability results for Hawkes processes can be\nimproved by introducing age into the system. In particular, we neither need to\na priori bound the intensities nor to impose any conditions on the Lipschitz\nconstants. When the interactions between neurons are of mean field type, we\nstudy large network limits and establish the propagation of chaos property of\nthe system. \n\n"}
{"id": "1806.06680", "contents": "Title: Asymmetric Hopfield neural network and twisted tetrahedron equation Abstract: We generalize the approach of arXiv:1805.04138 for the case of the Hopfield\nneural network in the recall stage on a triangular lattice with isotropic\nweights. It appears that some properties of this model, in particular the\nprobability of passing a trajectory in time dynamics, obeys the Gibbs\ndistribution with a partition function having a vertex realization. Moreover\nthe corresponding weight matrix satisfies the TTE - some deformation of the\nZamolodchikov tetrahedron equation, the latter playing the role analogous to\nthe Yang-Baxter equation in 3-dimensional statistical models. \n\n"}
{"id": "1806.07366", "contents": "Title: Neural Ordinary Differential Equations Abstract: We introduce a new family of deep neural network models. Instead of\nspecifying a discrete sequence of hidden layers, we parameterize the derivative\nof the hidden state using a neural network. The output of the network is\ncomputed using a black-box differential equation solver. These continuous-depth\nmodels have constant memory cost, adapt their evaluation strategy to each\ninput, and can explicitly trade numerical precision for speed. We demonstrate\nthese properties in continuous-depth residual networks and continuous-time\nlatent variable models. We also construct continuous normalizing flows, a\ngenerative model that can train by maximum likelihood, without partitioning or\nordering the data dimensions. For training, we show how to scalably\nbackpropagate through any ODE solver, without access to its internal\noperations. This allows end-to-end training of ODEs within larger models. \n\n"}
{"id": "1806.09589", "contents": "Title: Analyticity of Entropy Rates of Continuous-State Hidden Markov Models Abstract: The analyticity of the entropy and relative entropy rates of continuous-state\nhidden Markov models is studied here. Using the analytic continuation principle\nand the stability properties of the optimal filter, the analyticity of these\nrates is shown for analytically parameterized models. The obtained results hold\nunder relatively mild conditions and cover several classes of hidden Markov\nmodels met in practice. These results are relevant for several (theoretically\nand practically) important problems arising in statistical inference, system\nidentification and information theory. \n\n"}
{"id": "1806.09619", "contents": "Title: Novel Decentralized Coded Caching through Coded Prefetching Abstract: We propose a new decentralized coded caching scheme for a two-phase caching\nnetwork, where the data placed in user caches in the prefetching phase are\nrandom portions of a maximal distance separable (MDS) coded version of the\noriginal files. The proposed scheme achieves a better rate memory trade-off by\nutilizing the reconstruction property of MDS codes which reduces the number of\ntransmissions that are useful only for a small subset of users in the delivery\nphase. Unlike the previously available coded prefetching schemes, the proposed\nscheme does not require to have more users than files. The proposed scheme can\nbe viewed as a generalization of the original uncoded prefetching based\ndecentralized coded caching scheme, and likewise, is applicable to various\nnetwork topologies. \n\n"}
{"id": "1806.10661", "contents": "Title: Limit theorems for invariant distributions Abstract: A distributional symmetry is invariance of a distribution under a group of\ntransformations. Exchangeability and stationarity are examples. We explain that\na result of ergodic theory provides a law of large numbers: If the group\nsatisfies suitable conditions, expectations can be estimated by averaging over\nsubsets of transformations, and these estimators are strongly consistent. We\nshow that, if a mixing condition holds, the averages also satisfy a central\nlimit theorem, a Berry-Esseen bound, and concentration. These are extended\nfurther to apply to triangular arrays, to randomly subsampled averages, and to\na generalization of U-statistics. As applications, we obtain new results on\nexchangeability, random fields, network models, and a class of marked point\nprocesses. We also establish asymptotic normality of the empirical entropy for\na large class of processes. Some known results are recovered as special cases,\nand can hence be interpreted as an outcome of symmetry. The proofs adapt\nStein's method. \n\n"}
{"id": "1807.00447", "contents": "Title: Channel Agnostic End-to-End Learning based Communication Systems with\n  Conditional GAN Abstract: In this article, we use deep neural networks (DNNs) to develop a wireless\nend-to-end communication system, in which DNNs are employed for all\nsignal-related functionalities, such as encoding, decoding, modulation, and\nequalization. However, accurate instantaneous channel transfer function,\n\\emph{i.e.}, the channel state information (CSI), is necessary to compute the\ngradient of the DNN representing. In many communication systems, the channel\ntransfer function is hard to obtain in advance and varies with time and\nlocation. In this article, this constraint is released by developing a channel\nagnostic end-to-end system that does not rely on any prior information about\nthe channel. We use a conditional generative adversarial net (GAN) to represent\nthe channel effects, where the encoded signal of the transmitter will serve as\nthe conditioning information. In addition, in order to deal with the\ntime-varying channel, the received signal corresponding to the pilot data can\nalso be added as a part of the conditioning information. From the simulation\nresults, the proposed method is effective on additive white Gaussian noise\n(AWGN) and Rayleigh fading channels, which opens a new door for building\ndata-driven communication systems. \n\n"}
{"id": "1807.01246", "contents": "Title: The Concatenated Structure of Quasi-Abelian Codes Abstract: The decomposition of a quasi-abelian code into shorter linear codes over\nlarger alphabets was given in (Jitman, Ling, (2015)), extending the analogous\nChinese remainder decomposition of quasi-cyclic codes (Ling, Sol\\'e, (2001)).\nWe give a concatenated decomposition of quasi-abelian codes and show, as in the\nquasi-cyclic case, that the two decompositions are equivalent. The concatenated\ndecomposition allows us to give a general minimum distance bound for\nquasi-abelian codes and to construct some optimal codes. Moreover, we show by\nexamples that the minimum distance bound is sharp in some cases. In addition,\nexamples of large strictly quasi-abelian codes of about a half rate are given.\nThe concatenated structure also enables us to conclude that strictly\nquasi-abelian linear complementary dual codes over any finite field are\nasymptotically good. \n\n"}
{"id": "1807.02009", "contents": "Title: On-Demand Deployment of Multiple Aerial Base Stations for Traffic\n  Offloading and Network Recovery Abstract: Unmanned aerial vehicles (UAVs) are being utilized for a wide spectrum of\napplications in wireless networks leading to attractive business opportunities.\nIn the case of abrupt disruption to existing cellular network operation or\ninfrastructure, e.g., due to an unexpected surge in user demand or a natural\ndisaster, UAVs can be deployed to provide instant recovery via temporary\nwireless coverage in designated areas. A major challenge is to determine\nefficiently how many UAVs are needed and where to position them in a relatively\nlarge 3D search space. To this end, we formulate the problem of 3D deployment\nof a fleet of UAVs as a mixed integer linear program, and present a greedy\napproach that mimics the optimal behavior assuming a grid composed of a finite\nset of possible UAV locations. In addition, we propose and evaluate a novel low\ncomplexity algorithm for multiple UAV deployment in a continuous 3D space,\nbased on an unsupervised learning technique that relies on the notion of\nelectrostatics with repulsion and attraction forces. We present performance\nresults for the proposed algorithm as a function of various system parameters\nand demonstrate its effectiveness compared to the close-to-optimal greedy\napproach and its superiority compared to recent related work from the\nliterature. \n\n"}
{"id": "1807.02723", "contents": "Title: Machine Learning for Reliable mmWave Systems: Blockage Prediction and\n  Proactive Handoff Abstract: The sensitivity of millimeter wave (mmWave) signals to blockages is a\nfundamental challenge for mobile mmWave communication systems. The sudden\nblockage of the line-of-sight (LOS) link between the base station and the\nmobile user normally leads to disconnecting the communication session, which\nhighly impacts the system reliability. Further, reconnecting the user to\nanother LOS base station incurs high beam training overhead and critical\nlatency problems. In this paper, we leverage machine learning tools and propose\na novel solution for these reliability and latency challenges in mmWave MIMO\nsystems. In the developed solution, the base stations learn how to predict that\na certain link will experience blockage in the next few time frames using their\npast observations of adopted beamforming vectors. This allows the serving base\nstation to proactively hand-over the user to another base station with a highly\nprobable LOS link. Simulation results show that the developed deep learning\nbased strategy successfully predicts blockage/hand-off in close to 95% of the\ntimes. This reduces the probability of communication session disconnection,\nwhich ensures high reliability and low latency in mobile mmWave systems. \n\n"}
{"id": "1807.02728", "contents": "Title: Abnormality Detection inside Blood Vessels with Mobile Nanomachines Abstract: Motivated by the numerous healthcare applications of molecular communication\nwithin Internet of Bio-Nano Things (IoBNT), this work addresses the problem of\nabnormality detection in a blood vessel using multiple biological embedded\ncomputing devices called cooperative biological nanomachines (CNs), and a\ncommon receiver called the fusion center (FC). Due to blood flow inside a\nvessel, each CN and the FC are assumed to be mobile. In this work, each of the\nCNs perform abnormality detection with certain probabilities of detection and\nfalse alarm by counting the number of molecules received from a source, e.g.,\ninfected tissue. These CNs subsequently report their local decisions to a FC\nover a diffusion-advection blood flow channel using different types of\nmolecules in the presence of inter-symbol interference, multi-source\ninterference, and counting errors. Due to limited computational capability at\nthe FC, OR and AND logic based fusion rules are employed to make the final\ndecision after obtaining each local decision based on the optimal likelihood\nratio test. For the aforementioned system, probabilities of detection and false\nalarm at the FC are derived for OR and AND fusion rules. Finally, simulation\nresults are presented to validate the derived analytical results, which provide\nimportant insights. \n\n"}
{"id": "1807.04356", "contents": "Title: Joint Status Sampling and Updating for Minimizing Age of Information in\n  the Internet of Things Abstract: The effective operation of time-critical Internet of things (IoT)\napplications requires real-time reporting of fresh status information of\nunderlying physical processes. In this paper, a real-time IoT monitoring system\nis considered, in which the IoT devices sample a physical process with a\nsampling cost and send the status packet to a given destination with an\nupdating cost. This joint status sampling and updating process is designed to\nminimize the average age of information (AoI) at the destination node under an\naverage energy cost constraint at each device. This is formulated as an\ninfinite horizon average cost constrained Markov decision process (CMDP) and\ntransformed into an unconstrained MDP using a Lagrangian method. For the single\nIoT device case, the optimal policy for the CMDP is shown to be a randomized\nmixture of two deterministic policies for the unconstrained MDP, which is of\nthreshold type. Then, a structure-aware optimal algorithm to obtain the optimal\npolicy of the CMDP is proposed and the impact of the wireless channel dynamics\nis studied while demonstrating that channels having a larger mean channel gain\nand less scattering can achieve better AoI performance. For the case of\nmultiple IoT devices, a low-complexity distributed suboptimal policy is\nproposed with the updating control at the destination and the sampling control\nat each device. Then, an online learning algorithm is developed to obtain this\npolicy, which can be implemented at each IoT device and requires only the local\nknowledge and small signaling from the destination. The proposed learning\nalgorithm is shown to converge almost surely to the suboptimal policy.\nSimulation results show the structural properties of the optimal policy for the\nsingle IoT device case; and show that the proposed policy for multiple IoT\ndevices outperforms a zero-wait baseline policy, with average AoI reductions\nreaching up to 33%. \n\n"}
{"id": "1807.05306", "contents": "Title: Generative Adversarial Privacy Abstract: We present a data-driven framework called generative adversarial privacy\n(GAP). Inspired by recent advancements in generative adversarial networks\n(GANs), GAP allows the data holder to learn the privatization mechanism\ndirectly from the data. Under GAP, finding the optimal privacy mechanism is\nformulated as a constrained minimax game between a privatizer and an adversary.\nWe show that for appropriately chosen adversarial loss functions, GAP provides\nprivacy guarantees against strong information-theoretic adversaries. We also\nevaluate GAP's performance on the GENKI face database. \n\n"}
{"id": "1807.06306", "contents": "Title: Joint Power and Time Allocation for NOMA-MEC Offloading Abstract: This paper considers non-orthogonal multiple access (NOMA) assisted mobile\nedge computing (MEC), where the power and time allocation is jointly optimized\nto reduce the energy consumption of offloading. Closed-form expressions for the\noptimal power and time allocation solutions are obtained and used to establish\nthe conditions for determining whether conventional orthogonal multiple access\n(OMA), pure NOMA or hybrid NOMA should be used for MEC offloading. \n\n"}
{"id": "1807.08127", "contents": "Title: Distributed Federated Learning for Ultra-Reliable Low-Latency Vehicular\n  Communications Abstract: In this paper, the problem of joint power and resource allocation (JPRA) for\nultra-reliable low-latency communication (URLLC) in vehicular networks is\nstudied. Therein, the network-wide power consumption of vehicular users (VUEs)\nis minimized subject to high reliability in terms of probabilistic queuing\ndelays. Using extreme value theory, a new reliability measure is defined to\ncharacterize extreme events pertaining to vehicles' queue lengths exceeding a\npredefined threshold. To learn these extreme events, assuming they are\nindependently and identically distributed over VUEs, a novel distributed\napproach based on federated learning (FL) is proposed to estimate the tail\ndistribution of the queue lengths. Considering the communication delays\nincurred by FL over wireless links, Lyapunov optimization is used to derive the\nJPRA policies enabling URLLC for each VUE in a distributed manner. The proposed\nsolution is then validated via extensive simulations using a Manhattan mobility\nmodel. Simulation results show that FL enables the proposed method to estimate\nthe tail distribution of queues with an accuracy that is close to a centralized\nsolution with up to 79% reductions in the amount of exchanged data.\nFurthermore, the proposed method yields up to 60% reductions of VUEs with large\nqueue lengths, while reducing the average power consumption by two folds,\ncompared to an average queue-based baseline. \n\n"}
{"id": "1807.08305", "contents": "Title: Hardware-Limited Task-Based Quantization Abstract: Quantization plays a critical role in digital signal processing systems.\nQuantizers are typically designed to obtain an accurate digital representation\nof the input signal, operating independently of the system task, and are\ncommonly implemented using serial scalar analog-to-digital converters (ADCs).\nIn this work, we study hardware-limited task-based quantization, where a system\nutilizing a serial scalar ADC is designed to provide a suitable representation\nin order to allow the recovery of a parameter vector underlying the input\nsignal. We propose hardware-limited task-based quantization systems for a fixed\nand finite quantization resolution, and characterize their achievable\ndistortion. We then apply the analysis to the practical setups of channel\nestimation and eigen-spectrum recovery from quantized measurements. Our results\nillustrate that properly designed hardware-limited systems can approach the\noptimal performance achievable with vector quantizers, and that by taking the\nunderlying task into account, the quantization error can be made negligible\nwith a relatively small number of bits. \n\n"}
{"id": "1807.08887", "contents": "Title: Supporting Very Large Models using Automatic Dataflow Graph Partitioning Abstract: This paper presents Tofu, a system that partitions very large DNN models\nacross multiple GPU devices to reduce per-GPU memory footprint. Tofu is\ndesigned to partition a dataflow graph of fine-grained tensor operators in\norder to work transparently with a general-purpose deep learning platform like\nMXNet. In order to automatically partition each operator, we propose to\ndescribe the semantics of an operator in a simple language which represents\ntensors as lambda functions mapping from tensor coordinates to values. To\noptimally partition different operators in a dataflow graph, Tofu uses a\nrecursive search algorithm that minimizes the total communication cost. Our\nexperiments on an 8-GPU machine show that Tofu enables the training of very\nlarge CNN and RNN models. It also achieves 25% - 400% speedup over alternative\napproaches to train very large models. \n\n"}
{"id": "1807.09260", "contents": "Title: Time Correlation Exponents in Last Passage Percolation Abstract: For directed last passage percolation on $\\mathbb{Z}^2$ with exponential\npassage times on the vertices, let $T_{n}$ denote the last passage time from\n$(0,0)$ to $(n,n)$. We consider asymptotic two point correlation functions of\nthe sequence $T_{n}$. In particular we consider ${\\rm Corr}(T_{n}, T_{r})$ for\n$r\\le n$ where $r,n\\to \\infty$ with $r\\ll n$ or $n-r \\ll n$. We show that in\nthe former case ${\\rm Corr}(T_{n}, T_{r})=\\Theta((\\frac{r}{n})^{1/3})$ whereas\nin the latter case $1-{\\rm Corr}(T_{n}, T_{r})=\\Theta ((\\frac{n-r}{n})^{2/3})$.\nThe argument revolves around finer understanding of polymer geometry and is\nexpected to go through for a larger class of integrable models of last passage\npercolation. As by-products of the proof, we also get a couple of other results\nof independent interest: Quantitative estimates for locally Brownian nature of\npre-limits of Airy$_2$ process coming from exponential LPP, and precise\nvariance estimates for lengths of polymers constrained to be inside thin\nrectangles at the transversal fluctuation scale. \n\n"}
{"id": "1807.10025", "contents": "Title: Towards Optimal Power Control via Ensembling Deep Neural Networks Abstract: A deep neural network (DNN) based power control method is proposed, which\naims at solving the non-convex optimization problem of maximizing the sum rate\nof a multi-user interference channel. Towards this end, we first present PCNet,\nwhich is a multi-layer fully connected neural network that is specifically\ndesigned for the power control problem. PCNet takes the channel coefficients as\ninput and outputs the transmit power of all users. A key challenge in training\na DNN for the power control problem is the lack of ground truth, i.e., the\noptimal power allocation is unknown. To address this issue, PCNet leverages the\nunsupervised learning strategy and directly maximizes the sum rate in the\ntraining phase. Observing that a single PCNet does not globally outperform the\nexisting solutions, we further propose ePCNet, a network ensemble with multiple\nPCNets trained independently. Simulation results show that for the standard\nsymmetric multi-user Gaussian interference channel, ePCNet can outperform all\nstate-of-the-art power control methods by 1.2%-4.6% under a variety of system\nconfigurations. Furthermore, the performance improvement of ePCNet comes with a\nreduced computational complexity. \n\n"}
{"id": "1807.11317", "contents": "Title: Utility-Optimized Local Differential Privacy Mechanisms for Distribution\n  Estimation Abstract: LDP (Local Differential Privacy) has been widely studied to estimate\nstatistics of personal data (e.g., distribution underlying the data) while\nprotecting users' privacy. Although LDP does not require a trusted third party,\nit regards all personal data equally sensitive, which causes excessive\nobfuscation hence the loss of utility. In this paper, we introduce the notion\nof ULDP (Utility-optimized LDP), which provides a privacy guarantee equivalent\nto LDP only for sensitive data. We first consider the setting where all users\nuse the same obfuscation mechanism, and propose two mechanisms providing ULDP:\nutility-optimized randomized response and utility-optimized RAPPOR. We then\nconsider the setting where the distinction between sensitive and non-sensitive\ndata can be different from user to user. For this setting, we propose a\npersonalized ULDP mechanism with semantic tags to estimate the distribution of\npersonal data with high utility while keeping secret what is sensitive for each\nuser. We show theoretically and experimentally that our mechanisms provide much\nhigher utility than the existing LDP mechanisms when there are a lot of\nnon-sensitive data. We also show that when most of the data are non-sensitive,\nour mechanisms even provide almost the same utility as non-private mechanisms\nin the low privacy regime. \n\n"}
{"id": "1807.11939", "contents": "Title: Entanglement cost and quantum channel simulation Abstract: This paper proposes a revised definition for the entanglement cost of a\nquantum channel $\\mathcal{N}$. In particular, it is defined here to be the\nsmallest rate at which entanglement is required, in addition to free classical\ncommunication, in order to simulate $n$ calls to $\\mathcal{N}$, such that the\nmost general discriminator cannot distinguish the $n$ calls to $\\mathcal{N}$\nfrom the simulation. The most general discriminator is one who tests the\nchannels in a sequential manner, one after the other, and this discriminator is\nknown as a quantum tester [Chiribella et al., Phys. Rev. Lett., 101, 060401\n(2008)] or one who is implementing a quantum co-strategy [Gutoski et al., Symp.\nTh. Comp., 565 (2007)]. As such, the proposed revised definition of\nentanglement cost of a quantum channel leads to a rate that cannot be smaller\nthan the previous notion of a channel's entanglement cost [Berta et al., IEEE\nTrans. Inf. Theory, 59, 6779 (2013)], in which the discriminator is limited to\ndistinguishing parallel uses of the channel from the simulation. Under this\nrevised notion, I prove that the entanglement cost of certain\nteleportation-simulable channels is equal to the entanglement cost of their\nunderlying resource states. Then I find single-letter formulas for the\nentanglement cost of some fundamental channel models, including dephasing,\nerasure, three-dimensional Werner--Holevo channels, epolarizing channels\n(complements of depolarizing channels), as well as single-mode pure-loss and\npure-amplifier bosonic Gaussian channels. These examples demonstrate that the\nresource theory of entanglement for quantum channels is not reversible.\nFinally, I discuss how to generalize the basic notions to arbitrary resource\ntheories. \n\n"}
{"id": "1808.00408", "contents": "Title: Geometry of energy landscapes and the optimizability of deep neural\n  networks Abstract: Deep neural networks are workhorse models in machine learning with multiple\nlayers of non-linear functions composed in series. Their loss function is\nhighly non-convex, yet empirically even gradient descent minimisation is\nsufficient to arrive at accurate and predictive models. It is hitherto unknown\nwhy are deep neural networks easily optimizable. We analyze the energy\nlandscape of a spin glass model of deep neural networks using random matrix\ntheory and algebraic geometry. We analytically show that the multilayered\nstructure holds the key to optimizability: Fixing the number of parameters and\nincreasing network depth, the number of stationary points in the loss function\ndecreases, minima become more clustered in parameter space, and the tradeoff\nbetween the depth and width of minima becomes less severe. Our analytical\nresults are numerically verified through comparison with neural networks\ntrained on a set of classical benchmark datasets. Our model uncovers generic\ndesign principles of machine learning models. \n\n"}
{"id": "1808.00490", "contents": "Title: Multi-Agent Deep Reinforcement Learning for Dynamic Power Allocation in\n  Wireless Networks Abstract: This work demonstrates the potential of deep reinforcement learning\ntechniques for transmit power control in wireless networks. Existing techniques\ntypically find near-optimal power allocations by solving a challenging\noptimization problem. Most of these algorithms are not scalable to large\nnetworks in real-world scenarios because of their computational complexity and\ninstantaneous cross-cell channel state information (CSI) requirement. In this\npaper, a distributively executed dynamic power allocation scheme is developed\nbased on model-free deep reinforcement learning. Each transmitter collects CSI\nand quality of service (QoS) information from several neighbors and adapts its\nown transmit power accordingly. The objective is to maximize a weighted\nsum-rate utility function, which can be particularized to achieve maximum\nsum-rate or proportionally fair scheduling. Both random variations and delays\nin the CSI are inherently addressed using deep Q-learning. For a typical\nnetwork architecture, the proposed algorithm is shown to achieve near-optimal\npower allocation in real time based on delayed CSI measurements available to\nthe agents. The proposed scheme is especially suitable for practical scenarios\nwhere the system model is inaccurate and CSI delay is non-negligible. \n\n"}
{"id": "1808.00591", "contents": "Title: Impact of Beam Misalignment on Hybrid Beamforming NOMA for mmWave\n  Communications Abstract: This paper studies hybrid beamforming (HB)-based non-orthogonal multiple\naccess (NOMA) in multiuser millimeter wave (mmWave) communications. HB offers\npower-efficient and low-complexity precoding for downlink multiuser mmWave\nsystems which increases multiplexing gain and spectral efficiency of the\nsystem. Applying NOMA to HB-based systems, called HB-NOMA, can scale the number\nof users while offering a high spectral efficiency. However, an imperfect\ncorrelation between the effective channels of users in each NOMA cluster\nseriously degrades the achievable rate of HB-NOMA. In this paper, first a\nsum-rate maximization problem is formulated for HB-NOMA, and an algorithm is\nproposed to solve it effectively. It is then shown that the relationship\nbetween the effective channels of the users in each NOMA cluster can be\napproximated by a correlation factor. Next, the effect of imperfect correlation\nis analyzed, and a lower bound on the achievable rate of the users is derived\nfor both perfect and imperfect correlation. Finally, the rate gap resulting\nfrom an imperfect correlation is evaluated and a tight upper bound is derived\nfor that. Simulation results show that low correlation degrades the achievable\nrate of users. The lower bounds are tight in the large dimensional regime and\nin single-path channels. \n\n"}
{"id": "1808.01486", "contents": "Title: Spatial Deep Learning for Wireless Scheduling Abstract: The optimal scheduling of interfering links in a dense wireless network with\nfull frequency reuse is a challenging task. The traditional method involves\nfirst estimating all the interfering channel strengths then optimizing the\nscheduling based on the model. This model-based method is however resource\nintensive and computationally hard because channel estimation is expensive in\ndense networks; furthermore, finding even a locally optimal solution of the\nresulting optimization problem may be computationally complex. This paper shows\nthat by using a deep learning approach, it is possible to bypass the channel\nestimation and to schedule links efficiently based solely on the geographic\nlocations of the transmitters and the receivers, due to the fact that in many\npropagation environments, the wireless channel strength is largely a function\nof the distance dependent path-loss. This is accomplished by unsupervised\ntraining over randomly deployed networks, and by using a novel neural network\narchitecture that computes the geographic spatial convolutions of the\ninterfering or interfered neighboring nodes along with subsequent multiple\nfeedback stages to learn the optimum solution. The resulting neural network\ngives near-optimal performance for sum-rate maximization and is capable of\ngeneralizing to larger deployment areas and to deployments of different link\ndensities. Moreover, to provide fairness, this paper proposes a novel\nscheduling approach that utilizes the sum-rate optimal scheduling algorithm\nover judiciously chosen subsets of links for maximizing a proportional fairness\nobjective over the network. The proposed approach shows highly competitive and\ngeneralizable network utility maximization results. \n\n"}
{"id": "1808.01672", "contents": "Title: Model-Aided Wireless Artificial Intelligence: Embedding Expert Knowledge\n  in Deep Neural Networks Towards Wireless Systems Optimization Abstract: Deep learning based on artificial neural networks is a powerful machine\nlearning method that, in the last few years, has been successfully used to\nrealize tasks, e.g., image classification, speech recognition, translation of\nlanguages, etc., that are usually simple to execute by human beings but\nextremely difficult to perform by machines. This is one of the reasons why deep\nlearning is considered to be one of the main enablers to realize the notion of\nartificial intelligence. In order to identify the best architecture of an\nartificial neural network that allows one to fit input-output data pairs, the\ncurrent methodology in deep learning methods consists of employing a\ndata-driven approach. Once the artificial neural network is trained, it is\ncapable of responding to never-observed inputs by providing the optimum output\nbased on past acquired knowledge. In this context, a recent trend in the deep\nlearning community is to complement pure data-driven approaches with prior\ninformation based on expert knowledge. In this work, we describe two methods\nthat implement this strategy, which aim at optimizing wireless communication\nnetworks. In addition, we illustrate numerical results in order to assess the\nperformance of the proposed approaches compared with pure data-driven\nimplementations. \n\n"}
{"id": "1808.01750", "contents": "Title: Beyond the Central Limit Theorem: Universal and Non-universal\n  Simulations of Random Variables by General Mappings Abstract: Motivated by the Central Limit Theorem, in this paper, we study both\nuniversal and non-universal simulations of random variables with an arbitrary\ntarget distribution $Q_{Y}$ by general mappings, not limited to linear ones (as\nin the Central Limit Theorem). We derive the fastest convergence rate of the\napproximation errors for such problems. Interestingly, we show that for\ndiscontinuous or absolutely continuous $P_{X}$, the approximation error for the\nuniversal simulation is almost as small as that for the non-universal one; and\nmoreover, for both universal and non-universal simulations, the approximation\nerrors by general mappings are strictly smaller than those by linear mappings.\nFurthermore, we also generalize these results to simulation from Markov\nprocesses, and simulation of random elements (or general random variables). \n\n"}
{"id": "1808.02208", "contents": "Title: Generative Adversarial Estimation of Channel Covariance in Vehicular\n  Millimeter Wave Systems Abstract: Enabling highly-mobile millimeter wave (mmWave) systems is challenging\nbecause of the huge training overhead associated with acquiring the channel\nknowledge or designing the narrow beams. Current mmWave beam training and\nchannel estimation techniques do not normally make use of the prior beam\ntraining or channel estimation observations. Intuitively, though, the channel\nmatrices are functions of the various elements of the environment. Learning\nthese functions can dramatically reduce the training overhead needed to obtain\nthe channel knowledge. In this paper, a novel solution that exploits machine\nlearning tools, namely conditional generative adversarial networks (GAN), is\ndeveloped to learn these functions between the environment and the channel\ncovariance matrices. More specifically, the proposed machine learning model\ntreats the covariance matrices as 2D images and learns the mapping function\nrelating the uplink received pilots, which act as RF signatures of the\nenvironment, and these images. Simulation results show that the developed\nstrategy efficiently predicts the covariance matrices of the large-dimensional\nmmWave channels with negligible training overhead. \n\n"}
{"id": "1808.04512", "contents": "Title: Multicast Triangular Semilattice Network Abstract: We investigate the structure of the code graph of a multicast network that\nhas a characteristic shape of an inverted equilateral triangle. We provide a\ncriterion that determines the validity of a receiver placement within the code\ngraph, present invariance properties of the determinants corresponding to\nreceiver placements under symmetries, and provide a complete study of these\nnetworks' receivers and required field sizes up to a network of 4 sources. We\nalso improve on various definitions related to code graphs. \n\n"}
{"id": "1808.06015", "contents": "Title: Ultra Reliable, Low Latency Vehicle-to-Infrastructure Wireless\n  Communications with Edge Computing Abstract: Ultra reliable, low latency vehicle-to-infrastructure (V2I) communications is\na key requirement for seamless operation of autonomous vehicles (AVs) in future\nsmart cities. To this end, cellular small base stations (SBSs) with edge\ncomputing capabilities can reduce the end-to-end (E2E) service delay by\nprocessing requested tasks from AVs locally, without forwarding the tasks to a\nremote cloud server. Nonetheless, due to the limited computational capabilities\nof the SBSs, coupled with the scarcity of the wireless bandwidth resources,\nminimizing the E2E latency for AVs and achieving a reliable V2I network is\nchallenging. In this paper, a novel algorithm is proposed to jointly optimize\nAVs-to-SBSs association and bandwidth allocation to maximize the reliability of\nthe V2I network. By using tools from labor matching markets, the proposed\nframework can effectively perform distributed association of AVs to SBSs, while\naccounting for the latency needs of AVs as well as the limited computational\nand bandwidth resources of SBSs. Moreover, the convergence of the proposed\nalgorithm to a core allocation between AVs and SBSs is proved and its ability\nto capture interdependent computational and transmission latencies for AVs in a\nV2I network is characterized. Simulation results show that by optimizing the\nE2E latency, the proposed algorithm substantially outperforms conventional cell\nassociation schemes, in terms of service reliability and latency. \n\n"}
{"id": "1808.07576", "contents": "Title: Cooperative SGD: A unified Framework for the Design and Analysis of\n  Communication-Efficient SGD Algorithms Abstract: Communication-efficient SGD algorithms, which allow nodes to perform local\nupdates and periodically synchronize local models, are highly effective in\nimproving the speed and scalability of distributed SGD. However, a rigorous\nconvergence analysis and comparative study of different communication-reduction\nstrategies remains a largely open problem. This paper presents a unified\nframework called Cooperative SGD that subsumes existing communication-efficient\nSGD algorithms such as periodic-averaging, elastic-averaging and decentralized\nSGD. By analyzing Cooperative SGD, we provide novel convergence guarantees for\nexisting algorithms. Moreover, this framework enables us to design new\ncommunication-efficient SGD algorithms that strike the best balance between\nreducing communication overhead and achieving fast error convergence with low\nerror floor. \n\n"}
{"id": "1808.07593", "contents": "Title: Caveats for information bottleneck in deterministic scenarios Abstract: Information bottleneck (IB) is a method for extracting information from one\nrandom variable $X$ that is relevant for predicting another random variable\n$Y$. To do so, IB identifies an intermediate \"bottleneck\" variable $T$ that has\nlow mutual information $I(X;T)$ and high mutual information $I(Y;T)$. The \"IB\ncurve\" characterizes the set of bottleneck variables that achieve maximal\n$I(Y;T)$ for a given $I(X;T)$, and is typically explored by maximizing the \"IB\nLagrangian\", $I(Y;T) - \\beta I(X;T)$. In some cases, $Y$ is a deterministic\nfunction of $X$, including many classification problems in supervised learning\nwhere the output class $Y$ is a deterministic function of the input $X$. We\ndemonstrate three caveats when using IB in any situation where $Y$ is a\ndeterministic function of $X$: (1) the IB curve cannot be recovered by\nmaximizing the IB Lagrangian for different values of $\\beta$; (2) there are\n\"uninteresting\" trivial solutions at all points of the IB curve; and (3) for\nmulti-layer classifiers that achieve low prediction error, different layers\ncannot exhibit a strict trade-off between compression and prediction, contrary\nto a recent proposal. We also show that when $Y$ is a small perturbation away\nfrom being a deterministic function of $X$, these three caveats arise in an\napproximate way. To address problem (1), we propose a functional that, unlike\nthe IB Lagrangian, can recover the IB curve in all cases. We demonstrate the\nthree caveats on the MNIST dataset. \n\n"}
{"id": "1808.08360", "contents": "Title: Embedded Pilot-Aided Channel Estimation for OTFS in Delay-Doppler\n  Channels Abstract: Orthogonal time frequency space (OTFS) modulation was shown to provide\nsignificant error performance advantages over orthogonal frequency division\nmultiplexing (OFDM) in delay--Doppler channels. In order to detect OTFS\nmodulated data, the channel impulse response needs to be known at the receiver.\nIn this paper, we propose embedded pilot-aided channel estimation schemes for\nOTFS. In each OTFS frame, we arrange pilot, guard, and data symbols in the\ndelay--Doppler plane to suitably avoid interference between pilot and data\nsymbols at the receiver. We develop such symbol arrangements for OTFS over\nmultipath channels with integer and fractional Doppler shifts, respectively. At\nthe receiver, channel estimation is performed based on a threshold method and\nthe estimated channel information is used for data detection via a message\npassing (MP) algorithm. Thanks to our specific embedded symbol arrangements,\nboth channel estimation and data detection are performed within the same OTFS\nframe with a minimum overhead. We compare by simulations the error performance\nof OTFS using the proposed channel estimation and OTFS with ideally known\nchannel information and observe only a marginal performance loss. We also\ndemonstrate that the proposed channel estimation in OTFS significantly\noutperforms OFDM with known channel information. Finally, we present extensions\nof the proposed schemes to MIMO and multi-user uplink/downlink. \n\n"}
{"id": "1808.09360", "contents": "Title: Polar Codes with Integrated Probabilistic Shaping for 5G New Radio Abstract: A modification to 5G New Radio (NR) polar code is proposed, which improves\nthe error correction performance with higher order modulation through\nprobabilistic shaping. The presented scheme mainly re-uses existing hardware at\nthe transmitter, and modifications at the receiver are small. Simulation\nresults show that the presented approach can improve the performance by up to\n1dB for 256-QAM on AWGN channels \n\n"}
{"id": "1808.10612", "contents": "Title: The Limiting Behavior of the FTASEP with Product Bernoulli Initial\n  Distribution Abstract: We study the facilitated totally asymmetric exclusion process on the one\ndimensional integer lattice. We investigate the invariant measures and the\nlimiting behavior of the process. We mainly derive the limiting distribution of\nthe process when the initial distribution is the Bernoulli product measure with\ndensity $1/2$. We also prove that in the low density regime, the system finally\nconverges to an absorbing state. \n\n"}
{"id": "1809.01399", "contents": "Title: Non-Orthogonal Multiplexing of Ultra-Reliable and Broadband Services in\n  Fog-Radio Architectures Abstract: The fifth generation (5G) of cellular systems is introducing Ultra-Reliable\nLow-Latency Communications (URLLC) services alongside more conventional\nenhanced Mobile BroadBand (eMBB) traffic. Furthermore, the 5G cellular\narchitecture is evolving from a base station-centric deployment to a fog-like\nset-up that accommodates a flexible functional split between cloud and edge. In\nthis paper, a novel solution is proposed that enables the non-orthogonal\ncoexistence of URLLC and eMBB services by processing URLLC traffic at the Edge\nNodes (ENs), while eMBB communications are handled centrally at a cloud\nprocessor as in a Cloud-Radio Access Network (C-RAN) system. This solution\nguarantees the low-latency requirements of the URLLC service by means of edge\nprocessing, e.g., for vehicle-to-cellular use cases, as well as the high\nspectral efficiency for eMBB traffic via centralized baseband processing. Both\nuplink and downlink are analyzed by accounting for the heterogeneous\nperformance requirements of eMBB and URLLC traffic and by considering practical\naspects such as fading, lack of channel state information for URLLC\ntransmitters, rate adaptation for eMBB transmitters, finite fronthaul capacity,\nand different coexistence strategies, such as puncturing. \n\n"}
{"id": "1809.01423", "contents": "Title: Intelligent Reflecting Surface Enhanced Wireless Network: Joint Active\n  and Passive Beamforming Design Abstract: Intelligent reflecting surface (IRS) is envisioned to have abundant\napplications in future wireless networks by smartly reconfiguring the signal\npropagation for performance enhancement. Specifically, an IRS consists of a\nlarge number of low-cost passive elements each reflecting the incident signal\nwith a certain phase shift to collaboratively achieve beamforming and suppress\ninterference at one or more designated receivers. In this paper, we study an\nIRS-enhanced point-to-point multiple-input single-output (MISO) wireless system\nwhere one IRS is deployed to assist in the communication from a multi-antenna\naccess point (AP) to a single-antenna user. As a result, the user\nsimultaneously receives the signal sent directly from the AP as well as that\nreflected by the IRS. We aim to maximize the total received signal power at the\nuser by jointly optimizing the (active) transmit beamforming at the AP and\n(passive) reflect beamforming by the phase shifters at the IRS. We first\npropose a centralized algorithm based on the technique of semidefinite\nrelaxation (SDR) by assuming the global channel state information (CSI)\navailable at the IRS. Since the centralized implementation requires excessive\nchannel estimation and signal exchange overheads, we further propose a\nlow-complexity distributed algorithm where the AP and IRS independently adjust\nthe transmit beamforming and the phase shifts in an alternating manner until\nthe convergence is reached. Simulation results show that significant\nperformance gains can be achieved by the proposed algorithms as compared to\nbenchmark schemes. Moreover, it is verified that the IRS is able to drastically\nenhance the link quality and/or coverage over the conventional setup without\nthe IRS. \n\n"}
{"id": "1809.01752", "contents": "Title: Survey on UAV Cellular Communications: Practical Aspects,\n  Standardization Advancements, Regulation, and Security Challenges Abstract: The rapid growth of consumer Unmanned Aerial Vehicles (UAVs) is creating\npromising new business opportunities for cellular operators. On the one hand,\nUAVs can be connected to cellular networks as new types of user equipment,\ntherefore generating significant revenues for the operators that can guarantee\ntheir stringent service requirements. On the other hand, UAVs offer the\nunprecedented opportunity to realize UAV-mounted flying base stations that can\ndynamically reposition themselves to boost coverage, spectral efficiency, and\nuser quality of experience. Indeed, the standardization bodies are currently\nexploring possibilities for serving commercial UAVs with cellular networks.\nIndustries are beginning to trial early prototypes of flying base stations or\nuser equipments, while academia is in full swing researching mathematical and\nalgorithmic solutions to address interesting new problems arising from flying\nnodes in cellular networks. In this article, we provide a comprehensive survey\nof all of these developments promoting smooth integration of UAVs into cellular\nnetworks. Specifically, we survey (i) the types of consumer UAVs currently\navailable off-the-shelf, (ii) the interference issues and potential solutions\naddressed by standardization bodies for serving aerial users with the existing\nterrestrial base stations, (iii) the challenges and opportunities for assisting\ncellular communications with UAV-based flying relays and base stations, (iv)\nthe ongoing prototyping and test bed activities, (v) the new regulations being\ndeveloped to manage the commercial use of UAVs, and (vi) the cyber-physical\nsecurity of UAV-assisted cellular communications. \n\n"}
{"id": "1809.02011", "contents": "Title: A proof of Sznitman's conjecture about ballistic RWRE Abstract: We consider a random walk in a uniformly elliptic i.i.d. random environment\nin $\\mathbb Z^d$ for $d\\ge 2$. It is believed that whenever the random walk is\ntransient in a given direction it is necessarily ballistic. In order to\nquantify the gap which would be needed to prove this equivalence, several\nballisticity conditions have been introduced. In particular, in 2001 and 2002,\nSznitman defined the so called conditions $(T)$ and $(T')$. The first one is\nthe requirement that certain unlikely exit probabilities from a set of slabs\ndecay exponentially fast with their width $L$. The second one is the\nrequirement that for all $\\gamma\\in (0,1)$ condition $(T)_\\gamma$ is satisfied,\nwhich in turn is defined as the requirement that the decay is like\n$e^{-CL^\\gamma}$ for some $C>0$. In this article we prove a conjecture of\nSznitman of 2002, stating that $(T)$ and $(T')$ are equivalent. Hence, this\ncloses the circle proving the equivalence of conditions $(T)$, $(T')$ and\n$(T)_\\gamma$ for some $\\gamma\\in (0,1)$ as conjectured by Sznitman, and also of\neach of these ballisticity conditions with the polynomial condition $(P)_M$ for\n$M\\ge 15d+5$ introduced by Berger, Drewitz and Ramirez in 2014. \n\n"}
{"id": "1809.04176", "contents": "Title: Phaseless Subspace Tracking Abstract: This work takes the first steps towards solving the \"phaseless subspace\ntracking\" (PST) problem. PST involves recovering a time sequence of signals (or\nimages) from phaseless linear projections of each signal under the following\nstructural assumption: the signal sequence is generated from a much lower\ndimensional subspace (than the signal dimension) and this subspace can change\nover time, albeit gradually. It can be simply understood as a dynamic\n(time-varying subspace) extension of the low-rank phase retrieval problem\nstudied in recent work. \n\n"}
{"id": "1809.05397", "contents": "Title: Energy Efficient Multi-User MISO Communication using Low Resolution\n  Large Intelligent Surfaces Abstract: We consider a multi-user Multiple-Input Single-Output (MISO) communication\nsystem comprising of a multi-antenna base station communicating in the downlink\nsimultaneously with multiple single-antenna mobile users. This communication is\nassumed to be assisted by a Large Intelligent Surface (LIS) that consists of\nmany nearly passive antenna elements, whose parameters can be tuned according\nto desired objectives. The latest design advances on these surfaces suggest\ncheap elements effectively acting as low resolution (even $1$-bit resolution)\nphase shifters, whose joint configuration affects the electromagnetic behavior\nof the wireless propagation channel. In this paper, we investigate the\nsuitability of LIS for green communications in terms of Energy Efficiency (EE),\nwhich is expressed as the number of bits per Joule. In particular, for the\nconsidered multi-user MISO system, we design the transmit powers per user and\nthe values for the surface elements that jointly maximize the system's EE\nperformance. Our representative simulation results show that LIS-assisted\ncommunication, even with nearly passive $1$-bit resolution antenna elements,\nprovides significant EE gains compared to conventional relay-assisted\ncommunication. \n\n"}
{"id": "1809.05515", "contents": "Title: A Statistical Learning Approach to Ultra-Reliable Low Latency\n  Communication Abstract: Mission-critical applications require Ultra-Reliable Low Latency (URLLC)\nwireless connections, where the packet error rate (PER) goes down to $10^{-9}$.\nFulfillment of the bold reliability figures becomes meaningful only if it can\nbe related to a statistical model in which the URLLC system operates. However,\nthis model is generally not known and needs to be learned by sampling the\nwireless environment. In this paper we treat this fundamental problem in the\nsimplest possible communication-theoretic setting: selecting a transmission\nrate over a dynamic wireless channel in order to guarantee high transmission\nreliability. We introduce a novel statistical framework for design and\nassessment of URLLC systems, consisting of three key components: (i) channel\nmodel selection; (ii) learning the model using training; (3) selecting the\ntransmission rate to satisfy the required reliability. As it is insufficient to\nspecify the URLLC requirements only through PER, two types of statistical\nconstraints are introduced, Averaged Reliability (AR) and Probably Correct\nReliability (PCR). The analysis and the evaluations show that adequate model\nselection and learning are indispensable for designing consistent physical\nlayer that asymptotically behaves as if the channel was known perfectly, while\nmaintaining the reliability requirements in URLLC systems. \n\n"}
{"id": "1809.05821", "contents": "Title: Sequence-Subset Distance and Coding for Error Control in DNA-based Data\n  Storage Abstract: The process of DNA-based data storage (DNA storage for short) can be\nmathematically modelled as a communication channel, termed DNA storage channel,\nwhose inputs and outputs are sets of unordered sequences. To design error\ncorrecting codes for DNA storage channel, a new metric, termed the\nsequence-subset distance, is introduced, which generalizes the Hamming distance\nto a distance function defined between any two sets of unordered vectors and\nhelps to establish a uniform framework to design error correcting codes for DNA\nstorage channel. We further introduce a family of error correcting codes,\nreferred to as \\emph{sequence-subset codes}, for DNA storage and show that the\nerror-correcting ability of such codes is completely determined by their\nminimum distance. We derive some upper bounds on the size of the\nsequence-subset codes including a tight bound for a special case, a\nSingleton-like bound and a Plotkin-like bound. We also propose some\nconstructions, including an optimal construction for that special case, which\nimply lower bounds on the size of such codes. \n\n"}
{"id": "1809.07857", "contents": "Title: In-Edge AI: Intelligentizing Mobile Edge Computing, Caching and\n  Communication by Federated Learning Abstract: Recently, along with the rapid development of mobile communication\ntechnology, edge computing theory and techniques have been attracting more and\nmore attentions from global researchers and engineers, which can significantly\nbridge the capacity of cloud and requirement of devices by the network edges,\nand thus can accelerate the content deliveries and improve the quality of\nmobile services. In order to bring more intelligence to the edge systems,\ncompared to traditional optimization methodology, and driven by the current\ndeep learning techniques, we propose to integrate the Deep Reinforcement\nLearning techniques and Federated Learning framework with the mobile edge\nsystems, for optimizing the mobile edge computing, caching and communication.\nAnd thus, we design the \"In-Edge AI\" framework in order to intelligently\nutilize the collaboration among devices and edge nodes to exchange the learning\nparameters for a better training and inference of the models, and thus to carry\nout dynamic system-level optimization and application-level enhancement while\nreducing the unnecessary system communication load. \"In-Edge AI\" is evaluated\nand proved to have near-optimal performance but relatively low overhead of\nlearning, while the system is cognitive and adaptive to the mobile\ncommunication systems. Finally, we discuss several related challenges and\nopportunities for unveiling a promising upcoming future of \"In-Edge AI\". \n\n"}
{"id": "1809.08053", "contents": "Title: Galois Hulls of Linear Codes over Finite Fields Abstract: The $\\ell$-Galois hull $h_{\\ell}(C)$ of an $[n,k]$ linear code $C$ over a\nfinite field $\\mathbb{F}_q$ is the intersection of $C$ and $C^{{\\bot}_{\\ell}}$,\nwhere $C^{\\bot_{\\ell}}$ denotes the $\\ell$-Galois dual of $C$ which introduced\nby Fan and Zhang (2017). The $\\ell$- Galois LCD code is a linear code $C$ with\n$h_{\\ell}(C) = 0$. In this paper, we show that the dimension of the\n$\\ell$-Galois hull of a linear code is invariant under permutation equivalence\nand we provide a method to calculate the dimension of the $\\ell$-Galois hull by\nthe generator matrix of the code. Moreover, we obtain that the dimension of the\n$\\ell$-Galois hulls of ternary codes are also invariant under monomial\nequivalence. %The dimension of $l$-Galois hull of a code is not invariant under\nmonomial equivalence if $q>4$. We show that every $[n,k]$ linear code over\n$\\mathbb F_{q}$ is monomial equivalent to an $\\ell$-Galois LCD code for any\n$q>4$. We conclude that if there exists an $[n,k]$ linear code over $\\mathbb\nF_{q}$ for any $q>4$, then there exists an $\\ell$-Galois LCD code with the same\nparameters for any $0\\le \\ell\\le e-1$, where $q=p^e$ for some prime $p$. As an\napplication, we characterize the $\\ell$-Galois hull of matrix product codes\nover finite fields. \n\n"}
{"id": "1809.09281", "contents": "Title: Knowledge-Aided Normalized Iterative Hard Thresholding Algorithms and\n  Applications to Sparse Reconstruction Abstract: This paper deals with the problem of sparse recovery often found in\ncompressive sensing applications exploiting a priori knowledge. In particular,\nwe present a knowledge-aided normalized iterative hard thresholding (KA-NIHT)\nalgorithm that exploits information about the probabilities of nonzero entries.\nWe also develop a strategy to update the probabilities using a recursive\nKA-NIHT (RKA-NIHT) algorithm, which results in improved recovery. Simulation\nresults illustrate and compare the performance of the proposed and existing\nalgorithms. \n\n"}
{"id": "1809.10272", "contents": "Title: Multi-variate correlation and mixtures of product measures Abstract: Total correlation (`TC') and dual total correlation (`DTC') are two classical\nways to quantify the correlation among an $n$-tuple of random variables. They\nboth reduce to mutual information when $n=2$.\n  The first part of this paper sets up the theory of TC and DTC for general\nrandom variables, not necessarily finite-valued. This generality has not been\nexposed in the literature before.\n  The second part considers the structural implications when a joint\ndistribution $\\mu$ has small TC or DTC. If $\\mathrm{TC}(\\mu) = o(n)$, then\n$\\mu$ is close to a product measure according to a suitable transportation\nmetric: this follows directly from Marton's classical transportation-entropy\ninequality. If $\\mathrm{DTC}(\\mu) = o(n)$, then the structural consequence is\nmore complicated: $\\mu$ is a mixture of a controlled number of terms, most of\nthem close to product measures in the transportation metric. This is the main\nnew result of the paper. \n\n"}
{"id": "1810.00469", "contents": "Title: Optimization of Bit Mapping and Quantized Decoding for Off-the-Shelf\n  Protograph LDPC Codes with Application to IEEE 802.3ca Abstract: Protograph-based, off-the-shelf low-density parity-check (LDPC) codes are\noptimized for higher-order modulation and quantized sum-product decoders. As an\nexample, for the recently proposed LDPC code from the upcoming IEEE 802.3ca\nstandard for passive optical networks (PONs), an optimized mapping of the bit\nchannels originating from bit-metric decoding to the protograph variable nodes\ngains 0.4 dB and 0.3 dB at a bit-error rate of 1e-6 for shaped and uniform\nsignaling, respectively. Furthermore, the clipping value for a quantized\nsum-product LDPC decoder is optimized via discretized density evolution. \n\n"}
{"id": "1810.05561", "contents": "Title: Optimal Source Codes for Timely Updates Abstract: A transmitter observing a sequence of independent and identically distributed\nrandom variables seeks to keep a receiver updated about its latest\nobservations. The receiver need not be apprised about each symbol seen by the\ntransmitter, but needs to output a symbol at each time instant $t$. If at time\n$t$ the receiver outputs the symbol seen by the transmitter at time $U(t)\\leq\nt$, the age of information at the receiver at time $t$ is $t-U(t)$. We study\nthe design of lossless source codes that enable transmission with minimum\naverage age at the receiver. We show that the asymptotic minimum average age\ncan be attained up to a constant gap by the Shannon codes for a tilted version\nof the original pmf generating the symbols, which can be computed easily by\nsolving an optimization problem. Furthermore, we exhibit an example with\nalphabet $\\X$ where Shannon codes for the original pmf incur an asymptotic\naverage age of a factor $O(\\sqrt{\\log |\\X|})$ more than that achieved by our\ncodes. Underlying our prescription for optimal codes is a new variational\nformula for integer moments of random variables, which may be of independent\ninterest. Also, we discuss possible extensions of our formulation to randomized\nschemes and to the erasure channel, and include a treatment of the related\nproblem of source coding for minimum average queuing delay. \n\n"}
{"id": "1810.07117", "contents": "Title: Universal Uhrig dynamical decoupling for bosonic systems Abstract: We construct efficient deterministic dynamical decoupling schemes protecting\ncontinuous variable degrees of freedom. Our schemes target decoherence induced\nby quadratic system-bath interactions with analytic time-dependence. We show\nhow to suppress such interactions to $N$-th order using only $N$ pulses.\nFurthermore, we show to homogenize a $2^m$-mode bosonic system using only\n$(N+1)^{2m+1}$ pulses, yielding - up to $N$-th order - an effective evolution\ndescribed by non-interacting harmonic oscillators with identical frequencies.\nThe decoupled and homogenized system provides natural decoherence-free\nsubspaces for encoding quantum information. Our schemes only require pulses\nwhich are tensor products of single-mode passive Gaussian unitaries and SWAP\ngates between pairs of modes. \n\n"}
{"id": "1810.07181", "contents": "Title: Deep-Waveform: A Learned OFDM Receiver Based on Deep Complex-valued\n  Convolutional Networks Abstract: The (inverse) discrete Fourier transform (DFT/IDFT) is often perceived as\nessential to orthogonal frequency-division multiplexing (OFDM) systems. In this\npaper, a deep complex-valued convolutional network (DCCN) is developed to\nrecover bits from time-domain OFDM signals without relying on any explicit\nDFT/IDFT. The DCCN can exploit the cyclic prefix (CP) of OFDM waveform for\nincreased SNR by replacing DFT with a learned linear transform, and has the\nadvantage of combining CP-exploitation, channel estimation, and intersymbol\ninterference (ISI) mitigation, with a complexity of $\\mathcal{O}(N^2)$.\nNumerical tests show that the DCCN receiver can outperform the legacy channel\nestimators based on ideal and approximate linear minimum mean square error\n(LMMSE) estimation and a conventional CP-enhanced technique in Rayleigh fading\nchannels with various delay spreads and mobility. The proposed approach\nbenefits from the expressive nature of complex-valued neural networks, which,\nhowever, currently lack support from popular deep learning platforms. In\nresponse, guidelines of exact and approximate implementations of a\ncomplex-valued convolutional layer are provided for the design and analysis of\nconvolutional networks for wireless PHY. Furthermore, a suite of novel training\ntechniques are developed to improve the convergence and generalizability of the\ntrained model in fading channels. This work demonstrates the capability of deep\nneural networks in processing OFDM waveforms and the results suggest that the\nFFT processor in OFDM receivers can be replaced by a hardware AI accelerator. \n\n"}
{"id": "1810.07563", "contents": "Title: Algorithms and Fundamental Limits for Unlabeled Detection using Types Abstract: Emerging applications of sensor networks for detection sometimes suggest that\nclassical problems ought be revisited under new assumptions. This is the case\nof binary hypothesis testing with independent - but not necessarily identically\ndistributed - observations under the two hypotheses, a formalism so orthodox\nthat it is used as an opening example in many detection classes. However, let\nus insert a new element, and address an issue perhaps with impact on strategies\nto deal with \"big data\" applications: What would happen if the structure were\nstreamlined such that data flowed freely throughout the system without\nprovenance? How much information (for detection) is contained in the sample\nvalues, and how much in their labels? How should decision-making proceed in\nthis case? The theoretical contribution of this work is to answer these\nquestions by establishing the fundamental limits, in terms of error exponents,\nof the aforementioned binary hypothesis test with unlabeled observations drawn\nfrom a finite alphabet. Then, we focus on practical algorithms. A\nlow-complexity detector - called ULR - solves the detection problem without\nattempting to estimate the labels. A modified version of the auction algorithm\nis then considered, and two new greedy algorithms with ${\\cal O}(n^2)$\nworst-case complexity are presented, where $n$ is the number of observations.\nThe detection operational characteristics of these detectors are investigated\nby computer experiments. \n\n"}
{"id": "1810.07906", "contents": "Title: Deep Learning for Encrypted Traffic Classification: An Overview Abstract: Traffic classification has been studied for two decades and applied to a wide\nrange of applications from QoS provisioning and billing in ISPs to\nsecurity-related applications in firewalls and intrusion detection systems.\nPort-based, data packet inspection, and classical machine learning methods have\nbeen used extensively in the past, but their accuracy have been declined due to\nthe dramatic changes in the Internet traffic, particularly the increase in\nencrypted traffic. With the proliferation of deep learning methods, researchers\nhave recently investigated these methods for traffic classification task and\nreported high accuracy. In this article, we introduce a general framework for\ndeep-learning-based traffic classification. We present commonly used deep\nlearning methods and their application in traffic classification tasks. Then,\nwe discuss open problems and their challenges, as well as opportunities for\ntraffic classification. \n\n"}
{"id": "1810.08711", "contents": "Title: Stability conditions for a decentralised medium access algorithm:\n  single- and multi-hop networks Abstract: We consider a decentralised multi-access algorithm, motivated primarily by\nthe control of transmissions in a wireless network. For a finite single-hop\nnetwork with arbitrary interference constraints we prove stochastic stability\nunder the natural conditions. For infinite and finite single-hop networks, we\nobtain broad rate-stability conditions. We also consider symmetric finite\nmulti-hop networks and show that the natural condition is sufficient for\nstochastic stability. \n\n"}
{"id": "1810.09070", "contents": "Title: On the Conditional Smooth Renyi Entropy and its Applications in Guessing\n  and Source Coding Abstract: A novel definition of the conditional smooth Renyi entropy, which is\ndifferent from that of Renner and Wolf, is introduced. It is shown that our\ndefinition of the conditional smooth Renyi entropy is appropriate to give lower\nand upper bounds on the optimal guessing moment in a guessing problem where the\nguesser is allowed to stop guessing and declare an error. Further a general\nformula for the optimal guessing exponent is given. In particular, a\nsingle-letterized formula for mixture of i.i.d. sources is obtained. Another\napplication in the problem of source coding with the common side-information\navailable at the encoder and decoder is also demonstrated. \n\n"}
{"id": "1810.10983", "contents": "Title: Stochastic Control with Stale Information--Part I: Fully Observable\n  Systems Abstract: In this study, we adopt age of information as a measure of the staleness of\ninformation, and take initial steps towards analyzing the control performance\nof stochastic systems with stale information. Our goals are to cast light on a\nfundamental limit on the information staleness that is required for a certain\nlevel of the control performance and to specify the corresponding stalest\ninformation pattern. In the asymptotic regime, such a limit asserts a critical\ninformation staleness that is required for stabilization. We achieve these\ngoals by formulating the problem as a stochastic optimization problem and\ncharacterizing the associated optimal solutions. These solutions are in fact a\ncontrol policy, which specifies the control inputs of the plant, and a queuing\npolicy, which specifies the staleness of information at the controller. \n\n"}
{"id": "1811.00971", "contents": "Title: One-Bit OFDM Receivers via Deep Learning Abstract: This paper develops novel deep learning-based architectures and design\nmethodologies for an orthogonal frequency division multiplexing (OFDM) receiver\nunder the constraint of one-bit complex quantization. Single bit quantization\ngreatly reduces complexity and power consumption, but makes accurate channel\nestimation and data detection difficult. This is particularly true for\nmulticarrier waveforms, which have high peak-to-average ratio in the time\ndomain and fragile subcarrier orthogonality in the frequency domain. The severe\ndistortion for one-bit quantization typically results in an error floor even at\nmoderately low signal-to-noise-ratio (SNR) such as 5 dB. For channel estimation\n(using pilots), we design a novel generative supervised deep neural network\n(DNN) that can be trained with a reasonable number of pilots. After channel\nestimation, a neural network-based receiver -- specifically, an autoencoder --\njointly learns a precoder and decoder for data symbol detection. Since\nquantization prevents end-to-end training, we propose a two-step sequential\ntraining policy for this model. With synthetic data, our deep learning-based\nchannel estimation can outperform least squares (LS) channel estimation for\nunquantized (full-resolution) OFDM at average SNRs up to 14 dB. For data\ndetection, our proposed design achieves lower bit error rate (BER) in fading\nthan unquantized OFDM at average SNRs up to 10 dB. \n\n"}
{"id": "1811.01498", "contents": "Title: DSIC: Deep Learning based Self-Interference Cancellation for In-Band\n  Full Duplex Wireless Abstract: In-band full duplex wireless is of utmost interest to future wireless\ncommunication and networking due to great potentials of spectrum efficiency.\nIBFD wireless, however, is throttled by its key challenge, namely\nself-interference. Therefore, effective self-interference cancellation is the\nkey to enable IBFD wireless. This paper proposes a real-time non-linear\nself-interference cancellation solution based on deep learning. In this\nsolution, a self-interference channel is modeled by a deep neural network\n(DNN). Synchronized self-interference channel data is first collected to train\nthe DNN of the self-interference channel. Afterwards, the trained DNN is used\nto cancel the self-interference at a wireless node. This solution has been\nimplemented on a USRP SDR testbed and evaluated in real world in multiple\nscenarios with various modulations in transmitting information including\nnumbers, texts as well as images. It results in the performance of 17dB in\ndigital cancellation, which is very close to the self-interference power and\nnearly cancels the self-interference at a SDR node in the testbed. The solution\nyields an average of 8.5% bit error rate (BER) over many scenarios and\ndifferent modulation schemes. \n\n"}
{"id": "1811.03410", "contents": "Title: Quantifying Link Stability in Ad Hoc Wireless Networks Subject to\n  Ornstein-Uhlenbeck Mobility Abstract: The performance of mobile ad hoc networks in general and that of the routing\nalgorithm, in particular, can be heavily affected by the intrinsic dynamic\nnature of the underlying topology. In this paper, we build a new\nanalytical/numerical framework that characterizes nodes' mobility and the\nevolution of links between them. This formulation is based on a stationary\nMarkov chain representation of link connectivity. The existence of a link\nbetween two nodes depends on their distance, which is governed by the mobility\nmodel. In our analysis, nodes move randomly according to an Ornstein-Uhlenbeck\nprocess using one tuning parameter to obtain different levels of randomness in\nthe mobility pattern. Finally, we propose an entropy-rate-based metric that\nquantifies link uncertainty and evaluates its stability. Numerical results show\nthat the proposed approach can accurately reflect the random mobility in the\nnetwork and fully captures the link dynamics. It may thus be considered a\nvaluable performance metric for the evaluation of the link stability and\nconnectivity in these networks. \n\n"}
{"id": "1811.03850", "contents": "Title: MD-GAN: Multi-Discriminator Generative Adversarial Networks for\n  Distributed Datasets Abstract: A recent technical breakthrough in the domain of machine learning is the\ndiscovery and the multiple applications of Generative Adversarial Networks\n(GANs). Those generative models are computationally demanding, as a GAN is\ncomposed of two deep neural networks, and because it trains on large datasets.\nA GAN is generally trained on a single server.\n  In this paper, we address the problem of distributing GANs so that they are\nable to train over datasets that are spread on multiple workers. MD-GAN is\nexposed as the first solution for this problem: we propose a novel learning\nprocedure for GANs so that they fit this distributed setup. We then compare the\nperformance of MD-GAN to an adapted version of Federated Learning to GANs,\nusing the MNIST and CIFAR10 datasets. MD-GAN exhibits a reduction by a factor\nof two of the learning complexity on each worker node, while providing better\nperformances than federated learning on both datasets. We finally discuss the\npractical implications of distributing GANs. \n\n"}
{"id": "1811.03918", "contents": "Title: On Conditional Correlations Abstract: The Pearson correlation, correlation ratio, and maximal correlation have been\nwell-studied in the literature. In this paper, we study the conditional\nversions of these quantities. We extend the most important properties of the\nunconditional versions to the conditional versions, and also derive some new\nproperties. Based on the conditional maximal correlation, we define an\ninformation-correlation function of two arbitrary random variables, and use it\nto derive an impossibility result for the problem of the non-interactive\nsimulation of random variables. \n\n"}
{"id": "1811.04067", "contents": "Title: Benefits of Coded Placement for Networks with Heterogeneous Cache Sizes Abstract: In this work, we study coded placement in caching systems where the users\nhave unequal cache sizes and demonstrate its performance advantage. In\nparticular, we propose a caching scheme with coded placement for three-user\nsystems that outperforms the best caching scheme with uncoded placement. In our\nproposed scheme, users cache both uncoded and coded pieces of the files, and\nthe coded pieces at the users with large memories are decoded using the\nunicast/multicast signals intended to serve users with smaller memories.\nFurthermore, we extend the proposed scheme to larger systems and show the\nreduction in delivery load with coded placement compared to uncoded placement. \n\n"}
{"id": "1811.04908", "contents": "Title: Nonexistence of Bigeodesics in Integrable Models of Last Passage\n  Percolation Abstract: Bi-infinite geodesics are fundamental objects of interest in planar first\npassage percolation. A longstanding conjecture states that under mild\nconditions there are almost surely no bigeodesics, however the result has not\nbeen proved in any case. For the exactly solvable model of directed last\npassage percolation on $\\mathbb{Z}^2$ with i.i.d. exponential passage times, we\nstudy the corresponding question and show that almost surely the only\nbigeodesics are the trivial ones, i.e., the horizontal and vertical lines. The\nproof makes use of estimates for last passage time available from the\nintegrable probability literature to study coalescence structure of finite\ngeodesics, thereby making rigorous a heuristic argument due to Newman. \n\n"}
{"id": "1811.05173", "contents": "Title: Optimal extension to Sobolev rough paths Abstract: We show that every $\\mathbb{R}^d$-valued Sobolev path with regularity\n$\\alpha$ and integrability $p$ can be lifted to a Sobolev rough path in the\nsense of T. Lyons provided $\\alpha >1/p>0$. Moreover, we prove the existence of\nunique rough path lifts which are optimal w.r.t. strictly convex functionals\namong all possible rough path lifts given a Sobolev path. As examples, we\nconsider the rough path lift with minimal Sobolev norm and characterize the\nStratonovich rough path lift of a Brownian motion as optimal lift w.r.t. to a\nsuitable convex functional. Generalizations of the results to Besov spaces are\nbriefly discussed. \n\n"}
{"id": "1811.09652", "contents": "Title: Generalised Entropies and Metric-Invariant Optimal Countermeasures for\n  Information Leakage under Symmetric Constraints Abstract: We introduce a novel generalization of entropy and conditional entropy from\nwhich most definitions from the literature can be derived as particular cases.\nWithin this general framework, we investigate the problem of designing\ncountermeasures for information leakage. In particular, we seek\nmetric-invariant solutions, i.e., they are robust against the choice of entropy\nfor quantifying the leakage. The problem can be modelled as an information\nchannel from the system to an adversary, and the countermeasures can be seen as\nmodifying this channel in order to minimise the amount of information that the\noutputs reveal about the inputs. Our main result is to fully solve the problem\nunder the highly symmetrical design constraint that the number of inputs that\ncan produce the same output is capped. Our proof is constructive and the\noptimal channels and the minimum leakage are derived in closed form. \n\n"}
{"id": "1811.09695", "contents": "Title: Multilevel-Coded Pulse-Position Modulation for Covert Communications\n  over Binary-Input Discrete Memoryless Channels Abstract: We develop a low-complexity coding scheme to achieve covert communications\nover binary-input discrete memoryless channels (BI-DMCs). We circumvent the\nimpossibility of covert communication with linear codes by introducing\nnon-linearity through the use of pulse position modulation (PPM) and multilevel\ncoding (MLC). We show that the MLC-PPM scheme exhibits many appealing\nproperties; in particular, the channel at a given index level remains\nstationary as the number of level increases, which allows one to use families\nof channel capacity- and channel resolvability-achieving codes to concretely\ninstantiate the covert communication scheme. \n\n"}
{"id": "1811.11479", "contents": "Title: Communication-Efficient On-Device Machine Learning: Federated\n  Distillation and Augmentation under Non-IID Private Data Abstract: On-device machine learning (ML) enables the training process to exploit a\nmassive amount of user-generated private data samples. To enjoy this benefit,\ninter-device communication overhead should be minimized. With this end, we\npropose federated distillation (FD), a distributed model training algorithm\nwhose communication payload size is much smaller than a benchmark scheme,\nfederated learning (FL), particularly when the model size is large. Moreover,\nuser-generated data samples are likely to become non-IID across devices, which\ncommonly degrades the performance compared to the case with an IID dataset. To\ncope with this, we propose federated augmentation (FAug), where each device\ncollectively trains a generative model, and thereby augments its local data\ntowards yielding an IID dataset. Empirical studies demonstrate that FD with\nFAug yields around 26x less communication overhead while achieving 95-98% test\naccuracy compared to FL. \n\n"}
{"id": "1812.01830", "contents": "Title: Unified Analysis of HetNets using Poisson Cluster Process under\n  Max-Power Association Abstract: Owing to its flexibility in modeling real-world spatial configurations of\nusers and base stations (BSs), the Poisson cluster process (PCP) has recently\nemerged as an appealing way to model and analyze heterogeneous cellular\nnetworks (HetNets). Despite its undisputed relevance to HetNets -- corroborated\nby the models used in industry -- the PCP's use in performance analysis has\nbeen limited. This is primarily because of the lack of analytical tools to\ncharacterize performance metrics such as the coverage probability of a user\nconnected to the strongest BS. In this paper, we develop an analytical\nframework for the evaluation of the coverage probability, or equivalently the\ncomplementary cumulative density function (CCDF) of\nsignal-to-interference-and-noise-ratio (SINR), of a typical user in a K-tier\nHetNet under a max power-based association strategy, where the BS locations of\neach tier follow either a Poisson point process (PPP) or a PCP. The key\nenabling step involves conditioning on the parent PPPs of all the PCPs which\nallows us to express the coverage probability as a product of sum-product and\nprobability generating functionals (PGFLs) of the parent PPPs. In addition to\nseveral useful insights, our analysis provides a rigorous way to study the\nimpact of the cluster size on the SINR distribution, which was not possible\nusing existing PPP-based models. \n\n"}
{"id": "1812.02709", "contents": "Title: On stochastic gradient Langevin dynamics with dependent data streams in\n  the logconcave case Abstract: We study the problem of sampling from a probability distribution $\\pi$ on\n$\\rset^d$ which has a density \\wrt\\ the Lebesgue measure known up to a\nnormalization factor $x \\mapsto \\rme^{-U(x)} / \\int_{\\rset^d} \\rme^{-U(y)} \\rmd\ny$. We analyze a sampling method based on the Euler discretization of the\nLangevin stochastic differential equations under the assumptions that the\npotential $U$ is continuously differentiable, $\\nabla U$ is Lipschitz, and $U$\nis strongly concave. We focus on the case where the gradient of the log-density\ncannot be directly computed but unbiased estimates of the gradient from\npossibly dependent observations are available. This setting can be seen as a\ncombination of a stochastic approximation (here stochastic gradient) type\nalgorithms with discretized Langevin dynamics. We obtain an upper bound of the\nWasserstein-2 distance between the law of the iterates of this algorithm and\nthe target distribution $\\pi$ with constants depending explicitly on the\nLipschitz and strong convexity constants of the potential and the dimension of\nthe space. Finally, under weaker assumptions on $U$ and its gradient but in the\npresence of independent observations, we obtain analogous results in\nWasserstein-2 distance. \n\n"}
{"id": "1812.04420", "contents": "Title: Blended smoothing splines on Riemannian manifolds Abstract: We present a method to compute a fitting curve B to a set of data points\nd0,...,dm lying on a manifold M. That curve is obtained by blending together\nEuclidean B\\'ezier curves obtained on different tangent spaces. The method\nguarantees several properties among which B is C1 and is the natural cubic\nsmoothing spline when M is the Euclidean space. We show examples on the sphere\nS2 as a proof of concept. \n\n"}
{"id": "1812.05670", "contents": "Title: When to Preempt? Age of Information Minimization under Link Capacity\n  Constraint Abstract: In this paper, we consider a scenario where a source continuously monitors an\nobject and sends time-stamped status updates to a destination through a\nrate-limited link. We assume updates arrive randomly at the source according to\na Bernoulli process. Due to the link capacity constraint, it takes multiple\ntime slots for the source to complete the transmission of an update. Therefore,\nwhen a new update arrives at the source during the transmission of another\nupdate, the source needs to decide whether to skip the new arrival or to switch\nto it, in order to minimize the expected average age of information (AoI) at\nthe destination. We start with the setting where all updates are of the same\nsize, and prove that within a broadly defined class of online policies, the\noptimal policy should be a renewal policy, and has a sequential switching\nproperty. We then show that the optimal decision of the source in any time slot\nhas threshold structures, and only depends on the age of the update being\ntransmitted and the AoI at the destination. We then consider the setting where\nupdates are of different sizes, and show that the optimal Markovian policy also\nhas a multiple-threshold structure. For each of the settings, we explicitly\nidentify the thresholds by formulating the problem as a Markov Decision Process\n(MDP), and solve it through value iteration. Special structural properties of\nthe corresponding optimal policy are utilized to reduce the computational\ncomplexity of the value iteration algorithm. \n\n"}
{"id": "1812.08286", "contents": "Title: On the Role of Age of Information in the Internet of Things Abstract: In this article, we provide an accessible introduction to the emerging idea\nof Age of Information (AoI) that quantifies freshness of information and\nexplore its possible role in the efficient design of freshness-aware Internet\nof Things (IoT). We start by summarizing the concept of AoI and its variants\nwith emphasis on the differences between AoI and other well-known performance\nmetrics in the literature, such as throughput and delay. Building on this, we\nexplore freshness-aware IoT design for a network in which IoT devices sense\npotentially different physical processes and are supposed to frequently update\nthe status of these processes at a destination node (such as a cellular base\nstation). Inspired by the recent interest, we also assume that these IoT\ndevices are powered by wireless energy transfer by the destination node. For\nthis setting, we investigate the optimal sampling policy that jointly optimizes\nwireless energy transfer and scheduling of update packet transmissions from IoT\ndevices with the goal of minimizing long-term weighted sum-AoI. Using this, we\ncharacterize the achievable AoI region. We also compare this AoI-optimal policy\nwith the one that maximizes average throughput (throughput-optimal policy), and\ndemonstrate the impact of system state on their structures. Several promising\ndirections for future research are also presented. \n\n"}
{"id": "1901.00963", "contents": "Title: Integrating Sub-6 GHz and Millimeter Wave to Combat Blockage:\n  Delay-Optimal Scheduling Abstract: Millimeter wave (mmWave) technologies have the potential to achieve very high\ndata rates, but suffer from intermittent connectivity. In this paper, we\nprovision an architecture to integrate sub-6 GHz and mmWave technologies, where\nwe incorporate the sub-6 GHz interface as a fallback data transfer mechanism to\ncombat blockage and intermittent connectivity of the mmWave communications. To\nthis end, we investigate the problem of scheduling data packets across the\nmmWave and sub-6 GHz interfaces such that the average delay of system is\nminimized. This problem can be formulated as Markov Decision Process. We first\ninvestigate the problem of discounted delay minimization, and prove that the\noptimal policy is of the threshold-type, i.e., data packets should always be\nrouted to the mmWave interface as long as the number of packets in the system\nis smaller than a threshold. Then, we show that the results of the discounted\ndelay problem hold for the average delay problem as well. Through numerical\nresults, we demonstrate that under heavy traffic, integrating sub-6 GHz with\nmmWave can reduce the average delay by up to 70%. Further, our scheduling\npolicy substantially reduces the delay over the celebrated MaxWeight policy. \n\n"}
{"id": "1901.01573", "contents": "Title: Optimal Age over Erasure Channels Abstract: Previous works on age of information and erasure channels have dealt with\nspecific models and computed the average age or average peak age for certain\nsettings. In this paper, given a source that produces a letter every $T_s$\nseconds and an erasure channel that can be used every $T_c$ seconds, we ask\nwhat is the coding strategy that minimizes the time-average age of information\nthat an observer of the channel output incurs. We first analyze the case where\nthe source alphabet and the channel-input alphabet have the same size. We show\nthat a trivial coding strategy is optimal and a closed form expression for the\nage can be derived. We then analyze the case where the alphabets have different\nsizes. We use a random coding argument to bound the average age and show that\nthe average age achieved using random codes converges to the optimal average\nage of linear block codes as the source alphabet becomes large. \n\n"}
{"id": "1901.01740", "contents": "Title: SWIPT Signalling over Frequency-Selective Channels with a Nonlinear\n  Energy Harvester: Non-Zero Mean and Asymmetric Inputs Abstract: Simultaneous Wireless Information and Power Transfer (SWIPT) over a\npoint-to-point frequency-selective Additive White Gaussian Noise (AWGN) channel\nis studied. Considering an approximation of the nonlinearity of the harvester,\na general form of delivered power in terms of system baseband parameters is\nderived, which demonstrates the dependency of the delivered power on higher\norder moment of the baseband channel input distribution. The optimization\nproblem of maximizing Rate-Power (RP) region is studied. Assuming that the\nChannel State Information (CSI) is available at both the receiver and the\ntransmitter, and constraining to non-zero mean Gaussian input distributions, an\noptimization algorithm for power allocation among different subchannels is\nstudied. As a special case, optimality conditions for zero mean Gaussian inputs\nare derived. Results obtained from numerical optimization demonstrate the\nsuperiority of non-zero mean Gaussian inputs (with asymmetric power allocation\nin each complex subchannel) in yielding a larger RP region compared to their\nzero mean and non-zero mean (with symmetric power allocation in each complex\nsubchannel) counterparts. This severely contrasts with SWIPT design under\nlinear energy harvesting, for which circularly symmetric Gaussian inputs are\noptimal. \n\n"}
{"id": "1901.01863", "contents": "Title: Beyond socket options: making the Linux TCP stack truly extensible Abstract: The Transmission Control Protocol (TCP) is one of the most important\nprotocols in today's Internet. Its specification and implementations have been\nrefined for almost forty years. The Linux TCP stack is one of the most widely\nused TCP stacks given its utilisation on servers and Android smartphones and\ntablets. However, TCP and its implementations evolve very slowly. In this\npaper, we demonstrate how to leverage the eBPF virtual machine that is part of\nthe recent versions of the Linux kernel to make the TCP stack easier to extend.\n  We demonstrate a variety of use cases where the eBPF code is injected inside\na running kernel to update or tune the TCP implementation. We first implement\nthe TCP User Timeout Option. Then we propose a new option that enables a client\nto request a server to use a specific congestion control scheme. Our third\nextension is a TCP option that sets the initial congestion window. We then\ndemonstrate how eBPF code can be used to tune the acknowledgment strategy. \n\n"}
{"id": "1901.03377", "contents": "Title: Broadcasting Information subject to State Masking over a MIMO State\n  Dependent Gaussian Channel Abstract: The problem of channel coding over the Gaussian multiple-input\nmultiple-output (MIMO) broadcast channel (BC) with additive independent\nGaussian states is considered. The states are known in a noncausal manner to\nthe encoder, and it wishes to minimize the amount of information that the\nreceivers can learn from the channel outputs about the state sequence. The\nstate leakage rate is measured as a normalized blockwise mutual information\nbetween the state sequence and the channel outputs' sequences. We employ a new\nversion of a state-dependent extremal inequality and show that Gaussian input\nmaximizes the state-dependent version of Marton's outer bound. Further we show\nthat our inner bound coincides with the outer bound. Our result generalizes\npreviously studied scalar Gaussian BC with state and MIMO BC without state. \n\n"}
{"id": "1901.04167", "contents": "Title: Age-Delay Tradeoffs in Single Server Systems Abstract: Information freshness and low latency communication is important to many\nemerging applications. While Age of Information (AoI) serves as a metric of\ninformation freshness, packet delay is a traditional metric of communication\nlatency. We prove that there is a natural tradeoff between the AoI and packet\ndelay. We consider a single server system, in which at most one update packet\ncan be serviced at a time. The system designer controls the order in which the\npackets get serviced and the service time distribution, with a given service\nrate. We analyze two tradeoff problems that minimize packet delay and the\nvariance in packet delay, respectively, subject to an average age constraint.\nWe prove a strong age-delay and age-delay variance tradeoff, wherein, as the\naverage age approaches its minimum, the delay and its variance approach\ninfinity. We show that the service time distribution that mininizes average\nage, must necessarily have an unbounded-second moment. \n\n"}
{"id": "1901.04419", "contents": "Title: Explicit constructions of MSR codes for clustered distributed storage:\n  The rack-aware storage model Abstract: The paper is devoted to the problem of erasure coding in distributed storage.\nWe consider a model of storage that assumes that nodes are organized into\nequally sized groups, called racks, that within each group the nodes can\ncommunicate freely without taxing the system bandwidth, and that the only\ninformation transmission that counts is the one between the racks. This\nassumption implies that the nodes within each of the racks can collaborate\nbefore providing information to the failed node. The main emphasis of the paper\nis on code construction for this storage model. We present an explicit family\nof MDS array codes that support recovery of a single failed node from any\nnumber of helper racks using the minimum possible amount of inter-rack\ncommunication (such codes are said to provide optimal repair). The codes are\nconstructed over finite fields of size comparable to the code length.\n  We also derive a bound on the number of symbols accessed at helper nodes for\nthe purposes of repair, and construct a code family that approaches this bound,\nwhile still maintaining the optimal repair property.\n  Finally, we present a construction of scalar Reed-Solomon codes that support\noptimal repair for the rack-oriented storage model. \n\n"}
{"id": "1901.05096", "contents": "Title: Status from a Random Field: How Densely Should One Update? Abstract: In many applications, status information of a general spatial process, in\ncontrast to a point information source, is of interest. In this paper, we\nconsider a system where status information is drawn from a random field and\ntransmitted to a fusion center through a wireless multiaccess channel. The\noptimal density of spatial sampling points to minimize the remote status\nestimation error is investigated. Assuming a one-dimensional Gauss Markov\nrandom field and an exponential correlation function, closed-form expressions\nof remote estimation error are obtained for First-Come First-Served (FCFS) and\nLast-Come First-Served (LCFS) service disciplines. The optimal spatial sampling\ndensity for the LCFS case is given explicitly. Simulation results are presented\nwhich agree with our analysis. \n\n"}
{"id": "1901.05428", "contents": "Title: Relative Age of Information: A New Metric for Status Update Systems Abstract: In this paper, we introduce a new data freshness metric, relative Age of\nInformation (rAoI), and examine it in a single server system with various\npacket management schemes. The (classical) AoI metric was introduced to measure\nthe staleness of status updates at the receiving end with respect to their\ngeneration at the source. This metric addresses systems where the timings of\nupdate generation at the source are absolute and can be designed separately or\njointly with the transmission schedules. In many decentralized applications,\ntransmission schedules are blind to update generation timing, and the\ntransmitter can know the timing of an update packet only after it arrives. As\nsuch, an update becomes stale after a new one arrives. The rAoI metric measures\nhow fresh the data is at the receiver with respect to the data at the\ntransmitter. It introduces a particularly explicit dependence on the arrival\nprocess in the evaluation of age. We investigate several queuing disciplines\nand provide closed form expressions for rAoI and numerical comparisons. \n\n"}
{"id": "1901.05747", "contents": "Title: On Multi-Cell Uplink-Downlink Duality with Treating Inter-Cell\n  Interference as Noise Abstract: We consider the information-theoretic optimality of treating inter-cell\ninterference as noise in downlink cellular networks modeled as Gaussian\ninterfering broadcast channels. Establishing a new uplink-downlink duality, we\ncast the problem in Gaussian interfering broadcast channels to that in Gaussian\ninterfering multiple access channels, and characterize an achievable GDoF\nregion under power control and treating inter-cell interference as (Gaussian)\nnoise. We then identify conditions under which this achievable GDoF region is\noptimal. \n\n"}
{"id": "1901.06336", "contents": "Title: On Epsilon-MSCR Codes for Two Erasures Abstract: Cooperative regenerating codes are regenerating codes designed to tradeoff\nstorage for repair bandwidth in case of multiple node failures. Minimum storage\ncooperative regenerating (MSCR) codes are a class of cooperative regenerating\ncodes which achieve the minimum storage point of the tradeoff. Recently, these\ncodes have been constructed for all possible parameters $(n,k,d,h)$, where $h$\nerasures are repaired by contacting any $d$ surviving nodes. However, these\nconstructions have very large sub-packetization. $\\epsilon$-MSR codes are a\nclass of codes introduced to tradeoff subpacketization level for a slight\nincrease in the repair bandwidth for the case of single node failures. We\nintroduce the framework of $\\epsilon$-MSCR codes which allow for a similar\ntradeoff for the case of multiple node failures. We present a construction of\n$\\epsilon$-MSCR codes, which can recover from two node failures, by\nconcatenating a class of MSCR codes and scalar linear codes. We give a repair\nprocedure to repair the $\\epsilon$-MSCR codes in the event of two node failures\nand calculate the repair bandwidth for the same. We characterize the increase\nin repair bandwidth incurred by the method in comparison with the optimal\nrepair bandwidth given by the cut-set bound. Finally, we show the\nsubpacketization level of $\\epsilon$-MSCR codes scales logarithmically in the\nnumber of nodes. \n\n"}
{"id": "1901.06368", "contents": "Title: Outage in Motorway Multi-Lane VANETs with Hardcore Headway Distance\n  Using Synthetic Traces Abstract: In this paper we analyze synthetic mobility traces generated for three-lane\nunidirectional motorway traffic to find that the locations of vehicles along a\nlane are better modeled by a hardcore point process instead of the\nwidely-accepted Poisson point process (PPP). In order to capture the repulsion\nbetween successive vehicles while maintaining a level of analytical\ntractability, we make a simple extension to PPP: We model the inter-vehicle\ndistance along a lane equal to the sum of a constant hardcore distance and an\nexponentially distributed random variable. We calculate the J-function and the\nRipley's K-function for this hardcore point process. We fit its parameters to\nthe available traces, and we illustrate that the higher the average speed along\na lane, the more prominent the hardcore component becomes. In addition, we\nconsider a transmitter-receiver link on the same lane, and we generate simple\nformulae for the moments of interference under reduced Palm measure for that\nlane, and without conditioning for other lanes. We illustrate that under\nRayleigh fading a shifted-gamma approximation for the distribution of\ninterference per lane provides a very good fit to the simulated outage\nprobability using the synthetic traces, while the fit using the PPP is poor. \n\n"}
{"id": "1901.07793", "contents": "Title: A Fundamental Storage-Communication Tradeoff for Distributed Computing\n  with Straggling Nodes Abstract: Placement delivery arrays for distributed computing (Comp-PDAs) have recently\nbeen proposed as a framework to construct universal computing schemes for\nMapReduce-like systems. In this work, we extend this concept to systems with\nstraggling nodes, i.e., to systems where a subset of the nodes cannot\naccomplish the assigned map computations in due time. Unlike most previous\nworks that focused on computing linear functions, our results are universal and\napply for arbitrary map and reduce functions. Our contributions are as follows.\nFirstly, we show how to construct a universal coded computing scheme for\nMapReduce-like systems with straggling nodes from any given Comp-PDA. We also\ncharacterize the storage and communication loads of the resulting scheme in\nterms of the Comp-PDA parameters. Then, we prove an information-theoretic\nconverse bound on the storage-communication (SC) tradeoff achieved by universal\ncomputing schemes with straggling nodes. We show that the information-theoretic\nbound matches the performance achieved by the coded computing schemes with\nstraggling nodes corresponding to the Maddah-Ali and Niesen (MAN) PDAs, i.e.,\nto the Comp-PDAs describing Maddah-Ali and Niesen's coded caching scheme.\nInterestingly, the same Comp-PDAs (the MAN-PDAs) are optimal for any number of\nstraggling nodes, which implies that the map phase of optimal coded computing\nschemes does not need to be adapted to the number of stragglers in the system.\nWe finally prove that while the points that lie exactly on the fundamental SC\ntradeoff cannot be achieved with Comp-PDAs that require smaller number of files\nthan the MAN-PDAs, this is possible for some of the points that lie close to\nthe SC tradeoff. For these latter points, the decrease in the requested number\nof files can be exponential in the number of nodes of the system. \n\n"}
{"id": "1901.08763", "contents": "Title: Continuous Analog Channel Estimation Aided Beamforming for Massive MIMO\n  Systems Abstract: Analog beamforming greatly reduces the implementation cost of massive antenna\ntransceivers by using only one up/down-conversion chain. However, it incurs a\nlarge pilot overhead when used with conventional channel estimation (CE)\ntechniques. This is because these CE techniques involve digital processing,\nrequiring the up/down-conversion chain to be time-multiplexed across the\nantenna dimensions. This paper introduces a novel CE technique, called\ncontinuous analog channel estimation (CACE), that avoids digital processing,\nenables analog beamforming at the receiver and additionally provides resilience\nagainst oscillator phase-noise. By avoiding time-multiplexing of\nup/down-conversion chains, the CE overhead is reduced significantly and\nfurthermore becomes independent of the number of antenna elements. In CACE, a\nreference tone is transmitted continuously with the data signals, and the\nreceiver uses the received reference signal as a matched filter for combining\nthe data signals, albeit via analog processing. We propose a receiver\narchitecture for CACE, analyze its performance in the presence of oscillator\nphase-noise, and derive near-optimal system parameters and power allocation.\nTransmit beamforming and initial access procedure with CACE are also discussed.\nSimulations confirm that, in comparison to conventional CE, CACE provides\nphase-noise resilience and a significant reduction in the CE overhead, while\nsuffering only a small loss in signal-to-interference-plus-noise-ratio. \n\n"}
{"id": "1901.09339", "contents": "Title: Heterogeneity-aware Gradient Coding for Straggler Tolerance Abstract: Gradient descent algorithms are widely used in machine learning. In order to\ndeal with huge volume of data, we consider the implementation of gradient\ndescent algorithms in a distributed computing setting where multiple workers\ncompute the gradient over some partial data and the master node aggregates\ntheir results to obtain the gradient over the whole data. However, its\nperformance can be severely affected by straggler workers. Recently, some\ncoding-based approaches are introduced to mitigate the straggler problem, but\nthey are efficient only when the workers are homogeneous, i.e., having the same\ncomputation capabilities. In this paper, we consider that the workers are\nheterogeneous which are common in modern distributed systems. We propose a\nnovel heterogeneity-aware gradient coding scheme which can not only tolerate a\npredetermined number of stragglers but also fully utilize the computation\ncapabilities of heterogeneous workers. We show that this scheme is optimal when\nthe computation capabilities of workers are estimated accurately. A variant of\nthis scheme is further proposed to improve the performance when the estimations\nof the computation capabilities are not so accurate. We conduct our schemes for\ngradient descent based image classification on QingCloud clusters. Evaluation\nresults show that our schemes can reduce the whole computation time by up to\n$3\\times$ compared with a state-of-the-art coding scheme. \n\n"}
{"id": "1901.09740", "contents": "Title: Closed-form performance analysis of linear MIMO receivers in general\n  fading scenarios Abstract: Linear precoding and post-processing schemes are ubiquitous in wireless\nmulti-input-multi-output (MIMO) settings, due to their reduced complexity with\nrespect to optimal strategies. Despite their popularity, the performance\nanalysis of linear MIMO receivers is mostly not available in closed form, apart\nfor the canonical (uncorrelated Rayleigh fading) case, while for more general\nfading conditions only bounds are provided. This lack of results is motivated\nby the complex dependence of the output signal-to-interference and noise ratio\n(SINR) at each branch of the receiving filter on both the squared singular\nvalues as well as the (typically right) singular vectors of the channel matrix.\nWhile the explicit knowledge of the statistics of the SINR can be circumvented\nfor some fading types in the analysis of the linear Minimum Mean-Squared Error\n(MMSE) receiver, this does not apply to the less complex and widely adopted\nZero-Forcing (ZF) scheme. This work provides the first-to-date closed-form\nexpression of the probability density function (pdf) of the output ZF and MMSE\nSINR, for a wide range of fading laws, encompassing, in particular,\ncorrelations and multiple scattering effects typical of practically relevant\nchannel models. \n\n"}
{"id": "1901.09807", "contents": "Title: Capacity-Achieving MIMO-NOMA: Iterative LMMSE Detection Abstract: This paper considers a low-complexity iterative Linear Minimum Mean Square\nError (LMMSE) multi-user detector for the Multiple-Input and Multiple-Output\nsystem with Non-Orthogonal Multiple Access (MIMO-NOMA), where multiple\nsingle-antenna users simultaneously communicate with a multiple-antenna base\nstation (BS). While LMMSE being a linear detector has a low complexity, it has\nsuboptimal performance in multi-user detection scenario due to the mismatch\nbetween LMMSE detection and multi-user decoding. Therefore, in this paper, we\nprovide the matching conditions between the detector and decoders for\nMIMO-NOMA, which are then used to derive the achievable rate of the iterative\ndetection. We prove that a matched iterative LMMSE detector can achieve (i) the\noptimal capacity of symmetric MIMO-NOMA with any number of users, (ii) the\noptimal sum capacity of asymmetric MIMO-NOMA with any number of users, (iii)\nall the maximal extreme points in the capacity region of asymmetric MIMO-NOMA\nwith any number of users, (iv) all points in the capacity region of two-user\nand three-user asymmetric MIMO-NOMA systems. In addition, a kind of practical\nlow-complexity error-correcting multiuser code, called irregular\nrepeat-accumulate code, is designed to match the LMMSE detector. Numerical\nresults shows that the bit error rate performance of the proposed iterative\nLMMSE detection outperforms the state-of-art methods and is within 0.8dB from\nthe associated capacity limit. \n\n"}
{"id": "1901.10471", "contents": "Title: Non Binary Polar Codes with Equidistant Transform for Transmission over\n  the AWGN Channel Abstract: Finding fast polarizing transforms is an important problem as polar codes\nsuffer from slow finitelength performance. This paper considers non binary\npolar codes for transmission over the AWGN channel and designs polarizing\ntransforms with better distance characteristics using a simple procedure for\nsignal sets. The main idea of the paper is to define Equidistant Polarizing\nTransforms and show that they achieve the best distance spectrum bound. We\nprovides an example of such transform for q = 5. In this case PSK-type signal\nset is used. Finally, we show performance gains and some comparison with other\nmethods. \n\n"}
{"id": "cond-mat/0403233", "contents": "Title: Artificial Sequences and Complexity Measures Abstract: In this paper we exploit concepts of information theory to address the\nfundamental problem of identifying and defining the most suitable tools to\nextract, in a automatic and agnostic way, information from a generic string of\ncharacters. We introduce in particular a class of methods which use in a\ncrucial way data compression techniques in order to define a measure of\nremoteness and distance between pairs of sequences of characters (e.g. texts)\nbased on their relative information content. We also discuss in detail how\nspecific features of data compression techniques could be used to introduce the\nnotion of dictionary of a given sequence and of Artificial Text and we show how\nthese new tools can be used for information extraction purposes. We point out\nthe versatility and generality of our method that applies to any kind of\ncorpora of character strings independently of the type of coding behind them.\nWe consider as a case study linguistic motivated problems and we present\nresults for automatic language recognition, authorship attribution and self\nconsistent-classification. \n\n"}
{"id": "cond-mat/0506652", "contents": "Title: The theoretical capacity of the Parity Source Coder Abstract: The Parity Source Coder is a protocol for data compression which is based on\na set of parity checks organized in a sparse random network. We consider here\nthe case of memoryless unbiased binary sources. We show that the theoretical\ncapacity saturate the Shannon limit at large K. We also find that the first\ncorrections to the leading behavior are exponentially small, so that the\nbehavior at finite K is very close to the optimal one. \n\n"}
{"id": "cs/0411014", "contents": "Title: Rate Distortion and Denoising of Individual Data Using Kolmogorov\n  complexity Abstract: We examine the structure of families of distortion balls from the perspective\nof Kolmogorov complexity. Special attention is paid to the canonical\nrate-distortion function of a source word which returns the minimal Kolmogorov\ncomplexity of all distortion balls containing that word subject to a bound on\ntheir cardinality. This canonical rate-distortion function is related to the\nmore standard algorithmic rate-distortion function for the given distortion\nmeasure. Examples are given of list distortion, Hamming distortion, and\nEuclidean distortion. The algorithmic rate-distortion function can behave\ndifferently from Shannon's rate-distortion function. To this end, we show that\nthe canonical rate-distortion function can and does assume a wide class of\nshapes (unlike Shannon's); we relate low algorithmic mutual information to low\nKolmogorov complexity (and consequently suggest that certain aspects of the\nmutual information formulation of Shannon's rate-distortion function behave\ndifferently than would an analogous formulation using algorithmic mutual\ninformation); we explore the notion that low Kolmogorov complexity distortion\nballs containing a given word capture the interesting properties of that word\n(which is hard to formalize in Shannon's theory) and this suggests an approach\nto denoising; and, finally, we show that the different behavior of the\nrate-distortion curves of individual source words to some extent disappears\nafter averaging over the source words. \n\n"}
{"id": "cs/0412108", "contents": "Title: Mutual Information and Minimum Mean-square Error in Gaussian Channels Abstract: This paper deals with arbitrarily distributed finite-power input signals\nobserved through an additive Gaussian noise channel. It shows a new formula\nthat connects the input-output mutual information and the minimum mean-square\nerror (MMSE) achievable by optimal estimation of the input given the output.\nThat is, the derivative of the mutual information (nats) with respect to the\nsignal-to-noise ratio (SNR) is equal to half the MMSE, regardless of the input\nstatistics. This relationship holds for both scalar and vector signals, as well\nas for discrete-time and continuous-time noncausal MMSE estimation. This\nfundamental information-theoretic result has an unexpected consequence in\ncontinuous-time nonlinear estimation: For any input signal with finite power,\nthe causal filtering MMSE achieved at SNR is equal to the average value of the\nnoncausal smoothing MMSE achieved with a channel whose signal-to-noise ratio is\nchosen uniformly distributed between 0 and SNR. \n\n"}
{"id": "cs/0501082", "contents": "Title: A Group-Theoretic Approach to the WSSUS Pulse Design Problem Abstract: We consider the pulse design problem in multicarrier transmission where the\npulse shapes are adapted to the second order statistics of the WSSUS channel.\nEven though the problem has been addressed by many authors analytical insights\nare rather limited. First we show that the problem is equivalent to the pure\nstate channel fidelity in quantum information theory. Next we present a new\napproach where the original optimization functional is related to an eigenvalue\nproblem for a pseudo differential operator by utilizing unitary representations\nof the Weyl--Heisenberg group.A local approximation of the operator for\nunderspread channels is derived which implicitly covers the concepts of pulse\nscaling and optimal phase space displacement. The problem is reformulated as a\ndifferential equation and the optimal pulses occur as eigenstates of the\nharmonic oscillator Hamiltonian. Furthermore this operator--algebraic approach\nis extended to provide exact solutions for different classes of scattering\nenvironments. \n\n"}
{"id": "cs/0511103", "contents": "Title: An Infeasibility Result for the Multiterminal Source-Coding Problem Abstract: We prove a new outer bound on the rate-distortion region for the\nmultiterminal source-coding problem. This bound subsumes the best outer bound\nin the literature and improves upon it strictly in some cases. The improved\nbound enables us to obtain a new, conclusive result for the binary erasure\nversion of the \"CEO problem.\" The bound recovers many of the converse results\nthat have been established for special cases of the problem, including the\nrecent one for the Gaussian version of the CEO problem. \n\n"}
{"id": "cs/0512078", "contents": "Title: Graph-Cover Decoding and Finite-Length Analysis of Message-Passing\n  Iterative Decoding of LDPC Codes Abstract: The goal of the present paper is the derivation of a framework for the\nfinite-length analysis of message-passing iterative decoding of low-density\nparity-check codes. To this end we introduce the concept of graph-cover\ndecoding. Whereas in maximum-likelihood decoding all codewords in a code are\ncompeting to be the best explanation of the received vector, under graph-cover\ndecoding all codewords in all finite covers of a Tanner graph representation of\nthe code are competing to be the best explanation. We are interested in\ngraph-cover decoding because it is a theoretical tool that can be used to show\nconnections between linear programming decoding and message-passing iterative\ndecoding. Namely, on the one hand it turns out that graph-cover decoding is\nessentially equivalent to linear programming decoding. On the other hand,\nbecause iterative, locally operating decoding algorithms like message-passing\niterative decoding cannot distinguish the underlying Tanner graph from any\ncovering graph, graph-cover decoding can serve as a model to explain the\nbehavior of message-passing iterative decoding. Understanding the behavior of\ngraph-cover decoding is tantamount to understanding the so-called fundamental\npolytope. Therefore, we give some characterizations of this polytope and\nexplain its relation to earlier concepts that were introduced to understand the\nbehavior of message-passing iterative decoding for finite-length codes. \n\n"}
{"id": "cs/0603059", "contents": "Title: Derivatives of Entropy Rate in Special Families of Hidden Markov Chains Abstract: Consider a hidden Markov chain obtained as the observation process of an\nordinary Markov chain corrupted by noise. Zuk, et. al. [13], [14] showed how,\nin principle, one can explicitly compute the derivatives of the entropy rate of\nat extreme values of the noise. Namely, they showed that the derivatives of\nstandard upper approximations to the entropy rate actually stabilize at an\nexplicit finite time. We generalize this result to a natural class of hidden\nMarkov chains called ``Black Holes.'' We also discuss in depth special cases of\nbinary Markov chains observed in binary symmetric noise, and give an abstract\nformula for the first derivative in terms of a measure on the simplex due to\nBlackwell. \n\n"}
{"id": "cs/0604033", "contents": "Title: Statistical Properties of Eigen-Modes and Instantaneous Mutual\n  Information in MIMO Time-Varying Rayleigh Channels Abstract: In this paper, we study two important metrics in multiple-input\nmultiple-output (MIMO) time-varying Rayleigh flat fading channels. One is the\neigen-mode, and the other is the instantaneous mutual information (IMI). Their\nsecond-order statistics, such as the correlation coefficient, level crossing\nrate (LCR), and average fade/outage duration, are investigated, assuming a\ngeneral nonisotropic scattering environment. Exact closed-form expressions are\nderived and Monte Carlo simulations are provided to verify the accuracy of the\nanalytical results. For the eigen-modes, we found they tend to be\nspatio-temporally uncorrelated in large MIMO systems. For the IMI, the results\nshow that its correlation coefficient can be well approximated by the squared\namplitude of the correlation coefficient of the channel, under certain\nconditions. Moreover, we also found the LCR of IMI is much more sensitive to\nthe scattering environment than that of each eigen-mode. \n\n"}
{"id": "cs/0605067", "contents": "Title: Efficient Operation of Coded Packet Networks Abstract: A fundamental problem faced in the design of almost all packet networks is\nthat of efficient operation--of reliably communicating given messages among\nnodes at minimum cost in resource usage. We present a solution to the efficient\noperation problem for coded packet networks, i.e., packet networks where the\ncontents of outgoing packets are arbitrary, causal functions of the contents of\nreceived packets. Such networks are in contrast to conventional, routed packet\nnetworks, where outgoing packets are restricted to being copies of received\npackets and where reliability is provided by the use of retransmissions.\n  This thesis introduces four considerations to coded packet networks: 1.\nefficiency, 2. the lack of synchronization in packet networks, 3. the\npossibility of broadcast links, and 4. packet loss. We take these\nconsiderations and give a prescription for operation that is novel and general,\nyet simple, useful, and extensible. \n\n"}
{"id": "cs/0610045", "contents": "Title: Spectra of large block matrices Abstract: In a frequency selective slow-fading channel in a MIMO system, the channel\nmatrix is of the form of a block matrix. This paper proposes a method to\ncalculate the limit of the eigenvalue distribution of block matrices if the\nsize of the blocks tends to infinity. While it considers random matrices, it\ntakes an operator-valued free probability approach to achieve this goal. Using\nthis method, one derives a system of equations, which can be solved numerically\nto compute the desired eigenvalue distribution. The paper initially tackles the\nproblem for square block matrices, then extends the solution to rectangular\nblock matrices. Finally, it deals with Wishart type block matrices. For two\nspecial cases, the results of our approach are compared with results from\nsimulations. The first scenario investigates the limit eigenvalue distribution\nof block Toeplitz matrices. The second scenario deals with the distribution of\nWishart type block matrices for a frequency selective slow-fading channel in a\nMIMO system for two different cases of $n_R=n_T$ and $n_R=2n_T$. Using this\nmethod, one may calculate the capacity and the Signal-to-Interference-and-Noise\nRatio in large MIMO systems. \n\n"}
{"id": "cs/0702035", "contents": "Title: New Models for the Correlation in Sensor Data Abstract: In this paper, we propose two new models of spatial correlations in sensor\ndata in a data-gathering sensor network. A particular property of these models\nis that if a sensor node knows in \\textit{how many} bits it needs to transmit\nits data, then it also knows \\textit{which} bits of its data it needs to\ntransmit. \n\n"}
{"id": "cs/0702070", "contents": "Title: A Practical Approach to Lossy Joint Source-Channel Coding Abstract: This work is devoted to practical joint source channel coding. Although the\nproposed approach has more general scope, for the sake of clarity we focus on a\nspecific application example, namely, the transmission of digital images over\nnoisy binary-input output-symmetric channels. The basic building blocks of most\nstate-of the art source coders are: 1) a linear transformation; 2) scalar\nquantization of the transform coefficients; 3) probability modeling of the\nsequence of quantization indices; 4) an entropy coding stage. We identify the\nweakness of the conventional separated source-channel coding approach in the\ncatastrophic behavior of the entropy coding stage. Hence, we replace this stage\nwith linear coding, that maps directly the sequence of redundant quantizer\noutput symbols into a channel codeword. We show that this approach does not\nentail any loss of optimality in the asymptotic regime of large block length.\nHowever, in the practical regime of finite block length and low decoding\ncomplexity our approach yields very significant improvements. Furthermore, our\nscheme allows to retain the transform, quantization and probability modeling of\ncurrent state-of the art source coders, that are carefully matched to the\nfeatures of specific classes of sources. In our working example, we make use of\n``bit-planes'' and ``contexts'' model defined by the JPEG2000 standard and we\nre-interpret the underlying probability model as a sequence of conditionally\nMarkov sources. The Markov structure allows to derive a simple successive\ncoding and decoding scheme, where the latter is based on iterative Belief\nPropagation. We provide a construction example of the proposed scheme based on\npunctured Turbo Codes and we demonstrate the gain over a conventional separated\nscheme by running extensive numerical experiments on test images. \n\n"}
{"id": "cs/0702162", "contents": "Title: Distributed Power Allocation with Rate Constraints in Gaussian Parallel\n  Interference Channels Abstract: This paper considers the minimization of transmit power in Gaussian parallel\ninterference channels, subject to a rate constraint for each user. To derive\ndecentralized solutions that do not require any cooperation among the users, we\nformulate this power control problem as a (generalized) Nash equilibrium game.\nWe obtain sufficient conditions that guarantee the existence and nonemptiness\nof the solution set to our problem. Then, to compute the solutions of the game,\nwe propose two distributed algorithms based on the single user waterfilling\nsolution: The \\emph{sequential} and the \\emph{simultaneous} iterative\nwaterfilling algorithms, wherein the users update their own strategies\nsequentially and simultaneously, respectively. We derive a unified set of\nsufficient conditions that guarantee the uniqueness of the solution and global\nconvergence of both algorithms. Our results are applicable to all practical\ndistributed multipoint-to-multipoint interference systems, either wired or\nwireless, where a quality of service in terms of information rate must be\nguaranteed for each link. \n\n"}
{"id": "cs/0703005", "contents": "Title: State Amplification Abstract: We consider the problem of transmitting data at rate R over a state dependent\nchannel p(y|x,s) with the state information available at the sender and at the\nsame time conveying the information about the channel state itself to the\nreceiver. The amount of state information that can be learned at the receiver\nis captured by the mutual information I(S^n; Y^n) between the state sequence\nS^n and the channel output Y^n. The optimal tradeoff is characterized between\nthe information transmission rate R and the state uncertainty reduction rate\n\\Delta, when the state information is either causally or noncausally available\nat the sender. This result is closely related and in a sense dual to a recent\nstudy by Merhav and Shamai, which solves the problem of masking the state\ninformation from the receiver rather than conveying it. \n\n"}
{"id": "math/0209160", "contents": "Title: Large deviations for Brownian motion in a random scenery Abstract: We prove large deviations principles in large time, for the Brownian\noccupation time in random scenery. The random scenery is constant on unit\ncubes, and consist of i.i.d. bounded variables, independent of the Brownian\nmotion. This model is a time-continuous version of Kesten and Spitzer's random\nwalk in random scenery. We prove large deviations principles in ``quenched''\nand ``annealed'' settings. \n\n"}
{"id": "math/0401045", "contents": "Title: Unitary Space Time Constellation Analysis: An Upper Bound for the\n  Diversity Abstract: The diversity product and the diversity sum are two very important parameters\nfor a good-performing unitary space time constellation. A basic question is\nwhat the maximal diversity product (or sum) is. In this paper we are going to\nderive general upper bounds on the diversity sum and the diversity product for\nunitary constellations of any dimension $n$ and any size $m$ using packing\ntechniques on the compact Lie group U(n). \n\n"}
{"id": "math/0411277", "contents": "Title: Alpha-Pfaffian, pfaffian point process and shifted Schur measure Abstract: For any complex number $\\alpha$ and any even-size skew-symmetric matrix $B$,\nwe define a generalization $\\pfa{\\alpha}(B)$ of the pfaffian $\\pf(B)$ which we\ncall the $\\alpha$-pfaffian. The $\\alpha$-pfaffian is a pfaffian analogue of the\n$\\alpha$-determinant. It gives the pfaffian at $\\alpha=-1$. We give some\nformulas for $\\alpha$-pfaffians and study the positivity. Further we define\npoint processes determined by the $\\alpha$-pfaffian. Also we provide a linear\nalgebraic proof of the explicit pfaffian expression for the correlation\nfunction of the shifted Schur measure. \n\n"}
{"id": "math/0504606", "contents": "Title: Painleve formulas of the limiting distributions for non-null complex\n  sample covariance matrices Abstract: In a recent study of large non-null sample covariance matrices, a new\nsequence of functions generalizing the GUE Tracy-Widom distribution of random\nmatrix theory was obtained. This paper derives Painlev\\'e formulas of these\nfunctions and use them to prove that they are indeed distribution functions.\nApplications of these new distribution functions to last passage percolation,\nqueues in tandem and totally asymmetric simple exclusion process are also\ndiscussed. As a part of the proof, a representation of orthogonal polynomials\non the unit circle in terms of an operator on a discrete set is presented. \n\n"}
{"id": "math/0507021", "contents": "Title: A New Efficient Algorithm for Construction of LLS Models Abstract: We present a new efficient algortithm for construction of linear latent\nstructure (LLS) models. This algorithm reduces a problem of estimation of model\nparameters to a sequence of problems of linear algebra, which assures a low\ncomputational complexity and ability to handle on desktop computers data that\ninvolve up to thousands of variables. \n\n"}
{"id": "math/0511562", "contents": "Title: On constrained annealed bounds for pinning and wetting models Abstract: The free energy of quenched disordered systems is bounded above by the free\nenergy of the corresponding annealed system. This bound may be improved by\napplying the annealing procedure, which is just Jensen inequality, after having\nmodified the Hamiltonian in a way that the quenched expressions are left\nunchanged. This procedure is often viewed as a partial annealing or as a\nconstrained annealing, in the sense that the term that is added may be\ninterpreted as a Lagrange multiplier on the disorder variables.\n  In this note we point out that, for a family of models, some of which have\nattracted much attention, the multipliers of the form of empirical averages of\nlocal functions cannot improve on the basic annealed bound from the viewpoint\nof characterizing the phase diagram. This class of multipliers is the one that\nis suitable for computations and it is often believed that in this class one\ncan approximate arbitrarily well the quenched free energy. \n\n"}
{"id": "math/0607044", "contents": "Title: High-frequency asymptotics for subordinated isotropic fields on an\n  Abelian compact group Abstract: Let T* be a random field indexed by an Abelian compact group G, and suppose\nthat T* has the form T* = F(T(g)), where T is Gaussian and isotropic. The aim\nof this paper is to establish high-frequency central limit theorems for the\nFourier coefficients associated to T*. The proofs of our main results involve\nrecently established criteria for the weak convergence of multiple\nWiener-It\\^{o} integrals. Our research is motivated by physical applications,\nmainly related to the probabilistic modelization of the Cosmic Microwave\nBackground radiation. In this connection, the case of the n-dimensional torus\nis analyzed in detail. \n\n"}
{"id": "quant-ph/0307191", "contents": "Title: On Quantum Statistical Inference, II Abstract: Interest in problems of statistical inference connected to measurements of\nquantum systems has recently increased substantially, in step with dramatic new\ndevelopments in experimental techniques for studying small quantum systems.\nFurthermore, theoretical developments in the theory of quantum measurements\nhave brought the basic mathematical framework for the probability calculations\nmuch closer to that of classical probability theory. The present paper reviews\nthis field and proposes and interrelates a number of new concepts for an\nextension of classical statistical inference to the quantum context. \n\n"}
