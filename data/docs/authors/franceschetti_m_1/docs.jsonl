{"id": "0707.1739", "contents": "Title: On slow-fading non-separable correlation MIMO systems Abstract: In a frequency selective slow-fading channel in a MIMO system, the channel\nmatrix is of the form of a block matrix. We propose a method to calculate the\nlimit of the eigenvalue distribution of block matrices if the size of the\nblocks tends to infinity. We will also calculate the asymptotic eigenvalue\ndistribution of $HH^*$, where the entries of $H$ are jointly Gaussian, with a\ncorrelation of the form $E[h_{pj}\\bar h_{qk}]= \\sum_{s=1}^t\n\\Psi^{(s)}_{jk}\\hat\\Psi^{(s)}_{pq}$ (where $t$ is fixed and does not increase\nwith the size of the matrix). We will use an operator-valued free probability\napproach to achieve this goal. Using this method, we derive a system of\nequations, which can be solved numerically to compute the desired eigenvalue\ndistribution. \n\n"}
{"id": "0708.3699", "contents": "Title: Convolutional Entanglement Distillation Abstract: We develop a theory of entanglement distillation that exploits a\nconvolutional coding structure. We provide a method for converting an arbitrary\nclassical binary or quaternary convolutional code into a convolutional\nentanglement distillation protocol. The imported classical convolutional code\ndoes not have to be dual-containing or self-orthogonal. The yield and\nerror-correcting properties of such a protocol depend respectively on the rate\nand error-correcting properties of the imported classical convolutional code. A\nconvolutional entanglement distillation protocol has several other benefits.\nTwo parties sharing noisy ebits can distill noiseless ebits ``online'' as they\nacquire more noisy ebits. Distillation yield is high and decoding complexity is\nsimple for a convolutional entanglement distillation protocol. Our theory of\nconvolutional entanglement distillation reduces the problem of finding a good\nconvolutional entanglement distillation protocol to the well-established\nproblem of finding a good classical convolutional code. \n\n"}
{"id": "0709.2833", "contents": "Title: Distributed Space Time Codes with Low Decoding Complexity for\n  Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time code (DSTC) structure that admit its application in the\nproposed transmission scheme are identified and it is pointed out that the\nrecently proposed full diversity four group decodable DSTCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time codes applicable in this new transmission scheme for\npower of two number of relays are also provided. \n\n"}
{"id": "0712.3823", "contents": "Title: Multidimensional reconciliation for continuous-variable quantum key\n  distribution Abstract: We propose a method for extracting an errorless secret key in a\ncontinuous-variable quantum key distribution protocol, which is based on\nGaussian modulation of coherent states and homodyne detection. The crucial\nfeature is an eight-dimensional reconciliation method, based on the algebraic\nproperties of octonions. Since the protocol does not use any postselection, it\ncan be proven secure against arbitrary collective attacks, by using\nwell-established theorems on the optimality of Gaussian attacks. By using this\nnew coding scheme with an appropriate signal to noise ratio, the distance for\nsecure continuous-variable quantum key distribution can be significantly\nextended. \n\n"}
{"id": "0802.3570", "contents": "Title: Asymptotic Behaviour of Random Vandermonde Matrices with Entries on the\n  Unit Circle Abstract: Analytical methods for finding moments of random Vandermonde matrices with\nentries on the unit circle are developed. Vandermonde Matrices play an\nimportant role in signal processing and wireless applications such as direction\nof arrival estimation, precoding, and sparse sampling theory, just to name a\nfew. Within this framework, we extend classical freeness results on random\nmatrices with independent, identically distributed (i.i.d.) entries and show\nthat Vandermonde structured matrices can be treated in the same vein with\ndifferent tools. We focus on various types of matrices, such as Vandermonde\nmatrices with and without uniform phase distributions, as well as generalized\nVandermonde matrices. In each case, we provide explicit expressions of the\nmoments of the associated Gram matrix, as well as more advanced models\ninvolving the Vandermonde matrix. Comparisons with classical i.i.d. random\nmatrix theory are provided, and deconvolution results are discussed. We review\nsome applications of the results to the fields of signal processing and\nwireless communications. \n\n"}
{"id": "0804.0686", "contents": "Title: Discrimination of two channels by adaptive methods and its application\n  to quantum system Abstract: The optimal exponential error rate for adaptive discrimination of two\nchannels is discussed. In this problem, adaptive choice of input signal is\nallowed. This problem is discussed in various settings. It is proved that\nadaptive choice does not improve the exponential error rate in these settings.\nThese results are applied to quantum state discrimination. \n\n"}
{"id": "0804.0980", "contents": "Title: Large MIMO Detection: A Low-Complexity Detector at High Spectral\n  Efficiencies Abstract: We consider large MIMO systems, where by `{\\em large}' we mean number of\ntransmit and receive antennas of the order of tens to hundreds. Such large MIMO\nsystems will be of immense interest because of the very high spectral\nefficiencies possible in such systems. We present a low-complexity detector\nwhich achieves uncoded near-exponential diversity performance for hundreds of\nantennas (i.e., achieves near SISO AWGN performance in a large MIMO fading\nenvironment) with an average per-bit complexity of just $O(N_tN_r)$, where\n$N_t$ and $N_r$ denote the number of transmit and receive antennas,\nrespectively. With an outer turbo code, the proposed detector achieves good\ncoded bit error performance as well. For example, in a 600 transmit and 600\nreceive antennas V-BLAST system with a high spectral efficiency of 200 bps/Hz\n(using BPSK and rate-1/3 turbo code), our simulation results show that the\nproposed detector performs close to within about 4.6 dB from theoretical\ncapacity. We also adopt the proposed detector for the low-complexity decoding\nof high-rate non-orthogonal space-time block codes (STBC) from division\nalgebras (DA). For example, we have decoded the $16\\times 16$ full-rate\nnon-orthogonal STBC from DA using the proposed detector and show that it\nperforms close to within about 5.5 dB of the capacity using 4-QAM and rate-3/4\nturbo code at a spectral efficiency of 24 bps/Hz. The practical feasibility of\nthe proposed high-performance low-complexity detector could potentially trigger\nwide interest in the implementation of large MIMO systems. In large MC-CDMA\nsystems with hundreds of users, the proposed detector is shown to achieve near\nsingle-user performance at an average per-bit complexity linear in number of\nusers, which is quite appealing for its use in practical CDMA systems. \n\n"}
{"id": "0806.2533", "contents": "Title: Asymptotic Analysis of the Performance of LAS Algorithm for Large-MIMO\n  Detection Abstract: In our recent work, we reported an exhaustive study on the simulated bit\nerror rate (BER) performance of a low-complexity likelihood ascent search (LAS)\nalgorithm for detection in large multiple-input multiple-output (MIMO) systems\nwith large number of antennas that achieve high spectral efficiencies. Though\nthe algorithm was shown to achieve increasingly closer to near\nmaximum-likelihood (ML) performance through simulations, no BER analysis was\nreported. Here, we extend our work on LAS and report an asymptotic BER analysis\nof the LAS algorithm in the large system limit, where $N_t,N_r \\to \\infty$ with\n$N_t=N_r$, where $N_t$ and $N_r$ are the number of transmit and receive\nantennas. We prove that the error performance of the LAS detector in V-BLAST\nwith 4-QAM in i.i.d. Rayleigh fading converges to that of the ML detector as\n$N_t,N_r \\to \\infty$. \n\n"}
{"id": "0806.4168", "contents": "Title: Established Clustering Procedures for Network Analysis Abstract: In light of the burgeoning interest in network analysis in the new millenium,\nwe bring to the attention of contemporary network theorists, a two-stage\ndouble-standarization and hierarchical clustering (single-linkage-like)\nprocedure devised in 1974. In its many applications over the next\ndecade--primarily to the migration flows between geographic subdivisions within\nnations--the presence was often revealed of ``hubs''. These are, typically,\n``cosmopolitan/non-provincial'' areas--such as the French capital, Paris--which\nsend and receive people relatively broadly across their respective nations.\nAdditionally, this two-stage procedure--which ``might very well be the most\nsuccessful application of cluster analysis'' (R. C. Dubes)--has detected many\n(physically or socially) isolated groups (regions) of areas, such as those\nforming the southern islands, Shikoku and Kyushu, of Japan, the Italian islands\nof Sardinia and Sicily, and the New England region of the United States.\nFurther, we discuss a (complementary) approach developed in 1976, involving the\napplication of the max-flow/min-cut theorem to raw/non-standardized flows. \n\n"}
{"id": "0806.4200", "contents": "Title: The Secrecy Rate Region of the Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers, while a wire-tapper\nalso receives the transmitted signal. This model is motivated by wireless\ncommunications, where individual secure messages are broadcast over open media\nand can be received by any illegitimate receiver. The secrecy level is measured\nby equivocation rate at the eavesdropper. We first study the general\n(non-degraded) broadcast channel with confidential messages. We present an\ninner bound on the secrecy capacity region for this model. The inner bound\ncoding scheme is based on a combination of random binning and the\nGelfand-Pinsker bining. This scheme matches the Marton's inner bound on the\nbroadcast channel without confidentiality constraint. We further study the\nsituation where the channels are degraded. For the degraded broadcast channel\nwith confidential messages, we present the secrecy capacity region. Our\nachievable coding scheme is based on Cover's superposition scheme and random\nbinning. We refer to this scheme as Secret Superposition Scheme. In this\nscheme, we show that randomization in the first layer increases the secrecy\nrate of the second layer. This capacity region matches the capacity region of\nthe degraded broadcast channel without security constraint. It also matches the\nsecrecy capacity for the conventional wire-tap channel. Our converse proof is\nbased on a combination of the converse proof of the conventional degraded\nbroadcast channel and Csiszar lemma. Finally, we assume that the channels are\nAdditive White Gaussian Noise (AWGN) and show that secret superposition scheme\nwith Gaussian codebook is optimal. The converse proof is based on the\ngeneralized entropy power inequality. \n\n"}
{"id": "0807.1253", "contents": "Title: Informed Traders Abstract: An asymmetric information model is introduced for the situation in which\nthere is a small agent who is more susceptible to the flow of information in\nthe market than the general market participant, and who tries to implement\nstrategies based on the additional information. In this model market\nparticipants have access to a stream of noisy information concerning the future\nreturn of an asset, whereas the informed trader has access to a further\ninformation source which is obscured by an additional noise that may be\ncorrelated with the market noise. The informed trader uses the extraneous\ninformation source to seek statistical arbitrage opportunities, while at the\nsame time accommodating the additional risk. The amount of information\navailable to the general market participant concerning the asset return is\nmeasured by the mutual information of the asset price and the associated cash\nflow. The worth of the additional information source is then measured in terms\nof the difference of mutual information between the general market participant\nand the informed trader. This difference is shown to be nonnegative when the\nsignal-to-noise ratio of the information flow is known in advance. Explicit\ntrading strategies leading to statistical arbitrage opportunities, taking\nadvantage of the additional information, are constructed, illustrating how\nexcess information can be translated into profit. \n\n"}
{"id": "0807.1550", "contents": "Title: Discernment of Hubs and Clusters in Socioeconomic Networks Abstract: Interest in the analysis of networks has grown rapidly in the new millennium.\nConsequently, we promote renewed attention to a certain methodological approach\nintroduced in 1974. Over the succeeding decade, this\ntwo-stage--double-standardization and hierarchical clustering\n(single-linkage-like)--procedure was applied to a wide variety of weighted,\ndirected networks of a socioeconomic nature, frequently revealing the presence\nof ``hubs''. These were, typically--in the numerous instances studied of\nmigration flows between geographic subdivisions within\nnations--``cosmopolitan/non-provincial'' areas, a prototypical example being\nthe French capital, Paris. Such locations emit and absorb people broadly across\ntheir respective nations. Additionally, the two-stage procedure--which ``might\nvery well be the most successful application of cluster analysis'' (R. C.\nDubes, 1985)--detected many (physically or socially) isolated, functional\ngroups (regions) of areas, such as the southern islands, Shikoku and Kyushu, of\nJapan, the Italian islands of Sardinia and Sicily, and the New England region\nof the United States. Further, we discuss a (complementary) approach developed\nin 1976, in which the max-flow/min-cut theorem was applied to\nraw/non-standardized (interindustry, as well as migration) flows. \n\n"}
{"id": "0807.3803", "contents": "Title: Quantum Convolutional Coding with Shared Entanglement: General Structure Abstract: We present a general theory of entanglement-assisted quantum convolutional\ncoding. The codes have a convolutional or memory structure, they assume that\nthe sender and receiver share noiseless entanglement prior to quantum\ncommunication, and they are not restricted to possess the\nCalderbank-Shor-Steane structure as in previous work. We provide two\nsignificant advances for quantum convolutional coding theory. We first show how\nto \"expand\" a given set of quantum convolutional generators. This expansion\nstep acts as a preprocessor for a polynomial symplectic Gram-Schmidt\northogonalization procedure that simplifies the commutation relations of the\nexpanded generators to be the same as those of entangled Bell states (ebits)\nand ancilla qubits. The above two steps produce a set of generators with\nequivalent error-correcting properties to those of the original generators. We\nthen demonstrate how to perform online encoding and decoding for a stream of\ninformation qubits, halves of ebits, and ancilla qubits. The upshot of our\ntheory is that the quantum code designer can engineer quantum convolutional\ncodes with desirable error-correcting properties without having to worry about\nthe commutation relations of these generators. \n\n"}
{"id": "0808.2073", "contents": "Title: Lower Bounds on the Rate-Distortion Function of LDGM Codes Abstract: A recent line of work has focused on the use of low-density generator matrix\n(LDGM) codes for lossy source coding. In this paper, wedevelop a generic\ntechnique for deriving lower bounds on the rate-distortion functions of binary\nlinear codes, with particular interest on the effect of bounded degrees. The\nunderlying ideas can be viewing as the source coding analog of the classical\nresult of Gallager, providing bounds for channel coding over the binary\nsymmetric channel using bounded degree LDPC codes. We illustrate this method\nfor different random ensembles of LDGM codes, including the check-regular\nensemble and bit-check-regular ensembles, by deriving explicit lower bounds on\ntheir rate-distortion performance as a function of the degrees. \n\n"}
{"id": "0809.1398", "contents": "Title: Stability of Maximum likelihood based clustering methods: exploring the\n  backbone of classifications (Who is keeping you in that community?) Abstract: Components of complex systems are often classified according to the way they\ninteract with each other. In graph theory such groups are known as clusters or\ncommunities. Many different techniques have been recently proposed to detect\nthem, some of which involve inference methods using either Bayesian or Maximum\nLikelihood approaches. In this article, we study a statistical model designed\nfor detecting clusters based on connection similarity. The basic assumption of\nthe model is that the graph was generated by a certain grouping of the nodes\nand an Expectation Maximization algorithm is employed to infer that grouping.\nWe show that the method admits further development to yield a stability\nanalysis of the groupings that quantifies the extent to which each node\ninfluences its neighbors group membership. Our approach naturally allows for\nthe identification of the key elements responsible for the grouping and their\nresilience to changes in the network. Given the generality of the assumptions\nunderlying the statistical model, such nodes are likely to play special roles\nin the original system. We illustrate this point by analyzing several empirical\nnetworks for which further information about the properties of the nodes is\navailable. The search and identification of stabilizing nodes constitutes thus\na novel technique to characterize the relevance of nodes in complex networks. \n\n"}
{"id": "0809.2546", "contents": "Title: Depth as Randomness Deficiency Abstract: Depth of an object concerns a tradeoff between computation time and excess of\nprogram length over the shortest program length required to obtain the object.\nIt gives an unconditional lower bound on the computation time from a given\nprogram in absence of auxiliary information. Variants known as logical depth\nand computational depth are expressed in Kolmogorov complexity theory.\n  We derive quantitative relation between logical depth and computational depth\nand unify the different depth notions by relating them to A. Kolmogorov and L.\nLevin's fruitful notion of randomness deficiency. Subsequently, we revisit the\ncomputational depth of infinite strings, introducing the notion of super deep\nsequences and relate it with other approaches. \n\n"}
{"id": "0809.2768", "contents": "Title: Hubs and Clusters in the Evolving U. S. Internal Migration Network Abstract: Most nations of the world periodically publish N x N origin-destination\ntables, recording the number of people who lived in geographic subdivision i at\ntime t and j at t+1. We have developed and widely applied to such national\ntables and other analogous (weighted, directed) socioeconomic networks, a\ntwo-stage--double-standardization and (strong component) hierarchical\nclustering--procedure. Previous applications of this methodology and related\nanalytical issues are discussed. Its use is illustrated in a large-scale study,\nemploying recorded United States internal migration flows between the 3,000+\ncounty-level units of the nation for the periods 1965-1970 and 1995-2000.\nProminent, important features--such as ''cosmopolitan hubs'' and ``functional\nregions''--are extracted from master dendrograms. The extent to which such\ncharacteristics have varied over the intervening thirty years is evaluated. \n\n"}
{"id": "0809.3540", "contents": "Title: A Note on the Equivalence of Gibbs Free Energy and Information Theoretic\n  Capacity Abstract: The minimization of Gibbs free energy is based on the changes in work and\nfree energy that occur in a physical or chemical system. The maximization of\nmutual information, the capacity, of a noisy channel is determined based on the\nmarginal probabilities and conditional entropies associated with a\ncommunications system. As different as the procedures might first appear,\nthrough the exploration of a simple, \"dual use\" Ising model, it is seen that\nthe two concepts are in fact the same. In particular, the case of a binary\nsymmetric channel is calculated in detail. \n\n"}
{"id": "0810.3900", "contents": "Title: On the Capacity and Diversity-Multiplexing Tradeoff of the Two-Way Relay\n  Channel Abstract: This paper considers a multiple input multiple output (MIMO) two-way relay\nchannel, where two nodes want to exchange data with each other using multiple\nrelays. An iterative algorithm is proposed to achieve the optimal achievable\nrate region, when each relay employs an amplify and forward (AF) strategy.\n  The iterative algorithm solves a power minimization problem at every step,\nsubject to minimum signal-to-interference-and-noise ratio constraints, which is\nnon-convex, however, for which the Karush Kuhn Tuker conditions are sufficient\nfor optimality. The optimal AF strategy assumes global channel state\ninformation (CSI) at each relay. To simplify the CSI requirements, a simple\namplify and forward strategy, called dual channel matching, is also proposed,\nthat requires only local channel state information, and whose achievable rate\nregion is close to that of the optimal AF strategy. In the asymptotic regime of\nlarge number of relays, we show that the achievable rate region of the dual\nchannel matching and an upper bound differ by only a constant term and\nestablish the capacity scaling law of the two-way relay channel. Relay\nstrategies achieving optimal diversity-multiplexing tradeoff are also\nconsidered with a single relay node. A compress and forward strategy is shown\nto be optimal for achieving diversity multiplexing tradeoff for the full-duplex\ncase, in general, and for the half-duplex case in some cases. \n\n"}
{"id": "0810.4658", "contents": "Title: Indexability of Restless Bandit Problems and Optimality of Whittle's\n  Index for Dynamic Multichannel Access Abstract: We consider a class of restless multi-armed bandit problems (RMBP) that\narises in dynamic multichannel access, user/server scheduling, and optimal\nactivation in multi-agent systems. For this class of RMBP, we establish the\nindexability and obtain Whittle's index in closed-form for both discounted and\naverage reward criteria. These results lead to a direct implementation of\nWhittle's index policy with remarkably low complexity. When these Markov chains\nare stochastically identical, we show that Whittle's index policy is optimal\nunder certain conditions. Furthermore, it has a semi-universal structure that\nobviates the need to know the Markov transition probabilities. The optimality\nand the semi-universal structure result from the equivalency between Whittle's\nindex policy and the myopic policy established in this work. For non-identical\nchannels, we develop efficient algorithms for computing a performance upper\nbound given by Lagrangian relaxation. The tightness of the upper bound and the\nnear-optimal performance of Whittle's index policy are illustrated with\nsimulation examples. \n\n"}
{"id": "0811.0196", "contents": "Title: Reduced-Complexity Reed--Solomon Decoders Based on Cyclotomic FFTs Abstract: In this paper, we reduce the computational complexities of partial and dual\npartial cyclotomic FFTs (CFFTs), which are discrete Fourier transforms where\nspectral and temporal components are constrained, based on their properties as\nwell as a common subexpression elimination algorithm. Our partial CFFTs achieve\nsmaller computational complexities than previously proposed partial CFFTs.\nUtilizing our CFFTs in both transform- and time-domain Reed--Solomon decoders,\nwe achieve significant complexity reductions. \n\n"}
{"id": "0812.2454", "contents": "Title: On the statistical physics of directed polymers in a random medium and\n  their relation to tree codes Abstract: Using well-known results from statistical physics, concerning the almost-sure\nbehavior of the free energy of directed polymers in a random medium, we prove\nthat random tree codes achieve the distortion-rate function almost surely under\na certain symmetry condition. \n\n"}
{"id": "0901.1821", "contents": "Title: Semidefinite representation of convex hulls of rational varieties Abstract: Using elementary duality properties of positive semidefinite moment matrices\nand polynomial sum-of-squares decompositions, we prove that the convex hull of\nrationally parameterized algebraic varieties is semidefinite representable\n(that is, it can be represented as a projection of an affine section of the\ncone of positive semidefinite matrices) in the case of (a) curves; (b)\nhypersurfaces parameterized by quadratics; and (c) hypersurfaces parameterized\nby bivariate quartics; all in an ambient space of arbitrary dimension. \n\n"}
{"id": "0901.1869", "contents": "Title: Low-Complexity Near-ML Decoding of Large Non-Orthogonal STBCs Using PDA Abstract: Non-orthogonal space-time block codes (STBC) from cyclic division algebras\n(CDA) having large dimensions are attractive because they can simultaneously\nachieve both high spectral efficiencies (same spectral efficiency as in V-BLAST\nfor a given number of transmit antennas) {\\em as well as} full transmit\ndiversity. Decoding of non-orthogonal STBCs with hundreds of dimensions has\nbeen a challenge. In this paper, we present a probabilistic data association\n(PDA) based algorithm for decoding non-orthogonal STBCs with large dimensions.\nOur simulation results show that the proposed PDA-based algorithm achieves near\nSISO AWGN uncoded BER as well as near-capacity coded BER (within about 5 dB of\nthe theoretical capacity) for large non-orthogonal STBCs from CDA. We study the\neffect of spatial correlation on the BER, and show that the performance loss\ndue to spatial correlation can be alleviated by providing more receive spatial\ndimensions. We report good BER performance when a training-based iterative\ndecoding/channel estimation is used (instead of assuming perfect channel\nknowledge) in channels with large coherence times. A comparison of the\nperformances of the PDA algorithm and the likelihood ascent search (LAS)\nalgorithm (reported in our recent work) is also presented. \n\n"}
{"id": "0901.2160", "contents": "Title: Analysis of Uncoordinated Opportunistic Two-Hop Wireless Ad Hoc Systems Abstract: We consider a time-slotted two-hop wireless system in which the sources\ntransmit to the relays in the even time slots (first hop) and the relays\nforward the packets to the destinations in the odd time slots (second hop).\nEach source may connect to multiple relays in the first hop. In the presence of\ninterference and without tight coordination of the relays, it is not clear\nwhich relays should transmit the packet. We propose four decentralized methods\nof relay selection, some based on location information and others based on the\nreceived signal strength (RSS). We provide a complete analytical\ncharacterization of these methods using tools from stochastic geometry. We use\nsimulation results to compare these methods in terms of end-to-end success\nprobability. \n\n"}
{"id": "0903.3623", "contents": "Title: Matrix plots of reordered bistochastized transaction flow tables: A\n  United States intercounty migration example Abstract: We present a number of variously rearranged matrix plots of the $3, 107\n\\times 3, 107$ 1995-2000 (asymmetric) intercounty migration table for the\nUnited States, principally in its bistochasticized form (all 3,107 row and\ncolumn sums iteratively proportionally fitted to equal 1). In one set of plots,\nthe counties are seriated on the bases of the subdominant (left and right)\neigenvectors of the bistochastic matrix. In another set, we use the ordering of\ncounties in the dendrogram generated by the associated strong component\nhierarchical clustering. Interesting, diverse features of U. S. intercounty\nmigration emerge--such as a contrast in centralized, hub-like\n(cosmopolitan/provincial) properties between cosmopolitan \"Sunbelt\" and\nprovincial \"Black Belt\" counties. The methodologies employed should also be\ninsightful for the many other diverse forms of interesting transaction\nflow-type data--interjournal citations being an obvious, much-studied example,\nwhere one might expect that the journals Science, Nature and PNAS would display\n\"cosmopolitan\" characteristics. \n\n"}
{"id": "0904.4863", "contents": "Title: A two-stage algorithm for extracting the multiscale backbone of complex\n  weighted networks Abstract: The central problem of concern to Serrano, Boguna and Vespignani (\"Extracting\nthe multiscale backbone of complex weighted networks\", Proc Natl Acad Sci\n106:6483-6488 [2009]) can be effectively and elegantly addressed using a\nwell-established two-stage algorithm that has been applied to internal\nmigration flows for numerous nations and several other forms of \"transaction\nflow data\". \n\n"}
{"id": "0905.3407", "contents": "Title: Throughput and Delay Scaling in Supportive Two-Tier Networks Abstract: Consider a wireless network that has two tiers with different priorities: a\nprimary tier vs. a secondary tier, which is an emerging network scenario with\nthe advancement of cognitive radio technologies. The primary tier consists of\nrandomly distributed legacy nodes of density $n$, which have an absolute\npriority to access the spectrum. The secondary tier consists of randomly\ndistributed cognitive nodes of density $m=n^\\beta$ with $\\beta\\geq 2$, which\ncan only access the spectrum opportunistically to limit the interference to the\nprimary tier. Based on the assumption that the secondary tier is allowed to\nroute the packets for the primary tier, we investigate the throughput and delay\nscaling laws of the two tiers in the following two scenarios: i) the primary\nand secondary nodes are all static; ii) the primary nodes are static while the\nsecondary nodes are mobile. With the proposed protocols for the two tiers, we\nshow that the primary tier can achieve a per-node throughput scaling of\n$\\lambda_p(n)=\\Theta(1/\\log n)$ in the above two scenarios. In the associated\ndelay analysis for the first scenario, we show that the primary tier can\nachieve a delay scaling of $D_p(n)=\\Theta(\\sqrt{n^\\beta\\log n}\\lambda_p(n))$\nwith $\\lambda_p(n)=O(1/\\log n)$. In the second scenario, with two mobility\nmodels considered for the secondary nodes: an i.i.d. mobility model and a\nrandom walk model, we show that the primary tier can achieve delay scaling laws\nof $\\Theta(1)$ and $\\Theta(1/S)$, respectively, where $S$ is the random walk\nstep size. The throughput and delay scaling laws for the secondary tier are\nalso established, which are the same as those for a stand-alone network. \n\n"}
{"id": "0905.4757", "contents": "Title: Stochastic Optimization for Markov Modulated Networks with Application\n  to Delay Constrained Wireless Scheduling Abstract: We consider a wireless system with a small number of delay constrained users\nand a larger number of users without delay constraints. We develop a scheduling\nalgorithm that reacts to time varying channels and maximizes throughput utility\n(to within a desired proximity), stabilizes all queues, and satisfies the delay\nconstraints. The problem is solved by reducing the constrained optimization to\na set of weighted stochastic shortest path problems, which act as natural\ngeneralizations of max-weight policies to Markov decision networks. We also\npresent approximation results for the corresponding shortest path problems, and\ndiscuss the additional complexity and delay incurred as compared to systems\nwithout delay constraints. The solution technique is general and applies to\nother constrained stochastic decision problems. \n\n"}
{"id": "0906.0060", "contents": "Title: A Walk in Facebook: Uniform Sampling of Users in Online Social Networks Abstract: Our goal in this paper is to develop a practical framework for obtaining a\nuniform sample of users in an online social network (OSN) by crawling its\nsocial graph. Such a sample allows to estimate any user property and some\ntopological properties as well. To this end, first, we consider and compare\nseveral candidate crawling techniques. Two approaches that can produce\napproximately uniform samples are the Metropolis-Hasting random walk (MHRW) and\na re-weighted random walk (RWRW). Both have pros and cons, which we demonstrate\nthrough a comparison to each other as well as to the \"ground truth.\" In\ncontrast, using Breadth-First-Search (BFS) or an unadjusted Random Walk (RW)\nleads to substantially biased results. Second, and in addition to offline\nperformance assessment, we introduce online formal convergence diagnostics to\nassess sample quality during the data collection process. We show how these\ndiagnostics can be used to effectively determine when a random walk sample is\nof adequate size and quality. Third, as a case study, we apply the above\nmethods to Facebook and we collect the first, to the best of our knowledge,\nrepresentative sample of Facebook users. We make it publicly available and\nemploy it to characterize several key properties of Facebook. \n\n"}
{"id": "0906.0690", "contents": "Title: Thinning, Entropy and the Law of Thin Numbers Abstract: Renyi's \"thinning\" operation on a discrete random variable is a natural\ndiscrete analog of the scaling operation for continuous random variables. The\nproperties of thinning are investigated in an information-theoretic context,\nespecially in connection with information-theoretic inequalities related to\nPoisson approximation results. The classical Binomial-to-Poisson convergence\n(sometimes referred to as the \"law of small numbers\" is seen to be a special\ncase of a thinning limit theorem for convolutions of discrete distributions. A\nrate of convergence is provided for this limit, and nonasymptotic bounds are\nalso established. This development parallels, in part, the development of\nGaussian inequalities leading to the information-theoretic version of the\ncentral limit theorem. In particular, a \"thinning Markov chain\" is introduced,\nand it is shown to play a role analogous to that of the Ornstein-Uhlenbeck\nprocess in connection to the entropy power inequality. \n\n"}
{"id": "0906.1565", "contents": "Title: Correcting a Fraction of Errors in Nonbinary Expander Codes with Linear\n  Programming Abstract: A linear-programming decoder for \\emph{nonbinary} expander codes is\npresented. It is shown that the proposed decoder has the maximum-likelihood\ncertificate properties. It is also shown that this decoder corrects any pattern\nof errors of a relative weight up to approximately 1/4 \\delta_A \\delta_B (where\n\\delta_A and \\delta_B are the relative minimum distances of the constituent\ncodes). \n\n"}
{"id": "0906.3200", "contents": "Title: On the Compound MIMO Broadcast Channels with Confidential Messages Abstract: We study the compound multi-input multi-output (MIMO) broadcast channel with\nconfidential messages (BCC), where one transmitter sends a common message to\ntwo receivers and two confidential messages respectively to each receiver. The\nchannel state may take one of a finite set of states, and the transmitter knows\nthe state set but does not know the realization of the state. We study\nachievable rates with perfect secrecy in the high SNR regime by characterizing\nan achievable secrecy degree of freedom (s.d.o.f.) region for two models, the\nGaussian MIMO-BCC and the ergodic fading multi-input single-output (MISO)-BCC\nwithout a common message. We show that by exploiting an additional temporal\ndimension due to state variation in the ergodic fading model, the achievable\ns.d.o.f. region can be significantly improved compared to the Gaussian model\nwith a constant state, although at the price of a larger delay. \n\n"}
{"id": "0906.4675", "contents": "Title: Competition for Popularity in Bipartite Networks Abstract: We present a dynamical model for rewiring and attachment in bipartite\nnetworks in which edges are added between nodes that belong to catalogs that\ncan either be fixed in size or growing in size. The model is motivated by an\nempirical study of data from the video rental service Netflix, which invites\nits users to give ratings to the videos available in its catalog. We find that\nthe distribution of the number of ratings given by users and that of the number\nof ratings received by videos both follow a power law with an exponential\ncutoff. We also examine the activity patterns of Netflix users and find bursts\nof intense video-rating activity followed by long periods of inactivity. We\nderive ordinary differential equations to model the acquisition of edges by the\nnodes over time and obtain the corresponding time-dependent degree\ndistributions. We then compare our results with the Netflix data and find good\nagreement. We conclude with a discussion of how catalog models can be used to\nstudy systems in which agents are forced to choose, rate, or prioritize their\ninteractions from a very large set of options. \n\n"}
{"id": "0907.0002", "contents": "Title: On the binary codes with parameters of doubly-shortened 1-perfect codes Abstract: We show that any binary $(n=2^m-3, 2^{n-m}, 3)$ code $C_1$ is a part of an\nequitable partition (perfect coloring) $\\{C_1,C_2,C_3,C_4\\}$ of the $n$-cube\nwith the parameters $((0,1,n-1,0)(1,0,n-1,0)(1,1,n-4,2)(0,0,n-1,1))$. Now the\npossibility to lengthen the code $C_1$ to a 1-perfect code of length $n+2$ is\nequivalent to the possibility to split the part $C_4$ into two distance-3 codes\nor, equivalently, to the biparticity of the graph of distances 1 and 2 of\n$C_4$. In any case, $C_1$ is uniquely embeddable in a twofold 1-perfect code of\nlength $n+2$ with some structural restrictions, where by a twofold 1-perfect\ncode we mean that any vertex of the space is within radius 1 from exactly two\ncodewords. \n\n"}
{"id": "0907.0472", "contents": "Title: Capacity Regions and Sum-Rate Capacities of Vector Gaussian Interference\n  Channels Abstract: The capacity regions of vector, or multiple-input multiple-output, Gaussian\ninterference channels are established for very strong interference and aligned\nstrong interference. Furthermore, the sum-rate capacities are established for Z\ninterference, noisy interference, and mixed (aligned weak/intermediate and\naligned strong) interference. These results generalize known results for scalar\nGaussian interference channels. \n\n"}
{"id": "0907.2393", "contents": "Title: Multiscale Network Reduction Methodologies: Bistochastic and Disparity\n  Filtering of Human Migration Flows between 3,000+ U. S. Counties Abstract: To control for multiscale effects in networks, one can transform the matrix\nof (in general) weighted, directed internodal flows to bistochastic\n(doubly-stochastic) form, using the iterative proportional fitting\n(Sinkhorn-Knopp) procedure, which alternatively scales row and column sums to\nall equal 1. The dominant entries in the bistochasticized table can then be\nemployed for network reduction, using strong component hierarchical clustering.\nWe illustrate various facets of this well-established, widely-applied two-stage\nalgorithm with the 3, 107 x 3, 107 (asymmetric) 1995-2000 intercounty migration\nflow table for the United States. We compare the results obtained with ones\nusing the disparity filter, for \"extracting the \"multiscale backbone of complex\nweighted networks\", recently put forth by Serrano, Boguna and Vespignani (SBV)\n(Proc. Natl. Acad. Sci. 106 [2009], 6483), upon which we have briefly commented\n(Proc. Natl. Acad. Sci. 106 [2009], E66). The performance of the bistochastic\nfilter appears to be superior-at least in this specific case-in two respects:\n(1) it requires far fewer links to complete a stongly-connected network\nbackbone; and (2) it \"belittles\" small flows and nodes less-a principal\ndesideratum of SBV-in the sense that the correlations of the nonzero raw flows\nare considerably weaker with the corresponding bistochastized links than with\nthe significance levels yielded by the disparity filter. Additional comparative\nstudies--as called for by SBV-of these two filtering procedures, in particular\nas regards their topological properties, should be of considerable interest.\nRelatedly, in its many geographic applications, the two-stage procedure\nhas--with rare exceptions-clustered contiguous areas, often reconstructing\ntraditional regions (islands, for example), even though no contiguity\nconstraints, at all, are imposed beforehand. \n\n"}
{"id": "0908.1071", "contents": "Title: Optimal Joint Target Detection and Parameter Estimation By MIMO Radar Abstract: We consider multiple-input multiple-output (MIMO) radar systems with\nwidely-spaced antennas. Such antenna configuration facilitates capturing the\ninherent diversity gain due to independent signal dispersion by the target\nscatterers. We consider a new MIMO radar framework for detecting a target that\nlies in an unknown location. This is in contrast with conventional MIMO radars\nwhich break the space into small cells and aim at detecting the presence of a\ntarget in a specified cell. We treat this problem through offering a novel\ncomposite hypothesis testing framework for target detection when (i) one or\nmore parameters of the target are unknown and we are interested in estimating\nthem, and (ii) only a finite number of observations are available. The test\noffered optimizes a metric which accounts for both detection and estimation\naccuracies. In this paper as the parameter of interest we focus on the vector\nof time-delays that the waveforms undergo from being emitted by the transmit\nantennas until being observed by the receive antennas. The analytical and\nempirical results establish that for the proposed joint target detection and\ntime-delay estimation framework, MIMO radars exhibit significant gains over\nphased-array radars for extended targets which consist of multiple independent\nscatterers. For point targets modeled as single scatterers, however, the\ndetection/estimation accuracies of MIMO and phased-array radars for this\nspecific setup (joint target detection and time-delay estimation) are\ncomparable. \n\n"}
{"id": "0909.1344", "contents": "Title: Multiuser MISO Transmitter Optimization for Inter-Cell Interference\n  Mitigation Abstract: The transmitter optimization (i.e., steering vectors and power allocation)\nfor a MISO Broadcast Channel (MISO-BC) subject to general linear constraints is\nconsidered. Such constraints include, as special cases, the sum power, the\nper-antenna or per-group-of-antennas power, and \"forbidden interference\ndirection\" constraints. We consider both the optimal dirty-paper coding and the\nsimple suboptimal linear zero-forcing beamforming strategies, and provide\nnumerically efficient algorithms that solve the problem in its most general\nform. As an application, we consider a multi-cell scenario with partial cell\ncooperation, where each cell optimizes its precoder by taking into account\ninterference constraints on specific users in adjacent cells. The effectiveness\nof the proposed methods is evaluated in a simple system scenario including two\nadjacent cells, under different fairness criteria that emphasize the bottleneck\nrole of users near the cell \"boundary\". Our results show that \"active\"\nInter-Cell Interference (ICI) mitigation outperforms the conventional \"static\"\nICI mitigation based on fractional frequency reuse. \n\n"}
{"id": "0909.5119", "contents": "Title: Random Access Transport Capacity Abstract: We develop a new metric for quantifying end-to-end throughput in multihop\nwireless networks, which we term random access transport capacity, since the\ninterference model presumes uncoordinated transmissions. The metric quantifies\nthe average maximum rate of successful end-to-end transmissions, multiplied by\nthe communication distance, and normalized by the network area. We show that a\nsimple upper bound on this quantity is computable in closed-form in terms of\nkey network parameters when the number of retransmissions is not restricted and\nthe hops are assumed to be equally spaced on a line between the source and\ndestination. We also derive the optimum number of hops and optimal per hop\nsuccess probability and show that our result follows the well-known square root\nscaling law while providing exact expressions for the preconstants as well.\nNumerical results demonstrate that the upper bound is accurate for the purpose\nof determining the optimal hop count and success (or outage) probability. \n\n"}
{"id": "0910.2066", "contents": "Title: A Lossless Fuzzy Binary AND/OR Compressor Abstract: In this report, a new fuzzy 2bit-AND parallel-to-OR, or simply, a fuzzy\nbinary AND/OR (FBAR) text data compression model as an algorithm is suggested\nfor bettering spatial locality limits on nodes during database transactions.\nThe current model incorporates a four-layer application technique:\nstring-to-AND/OR pairwise binary bit + fuzzy quantum with noise conversions.\nThis technique promotes a lossless data compression ratio of 2:1 up to values\napproximately = 3:1, generating a spatially-efficient compressed data file\ncompared to nowadays data compressors. Data decompression/specific data\nreconstruction initiates an AND/OR pattern match technique in respect of fuzzy\nquantum indicators in the binary function field. The reconstruction of data\noccurs in the 4th layer using encryption methods. It is hypothesized that\nsignificant data compression ratio of 2n:1 for n>3:1 ratios, e.g., 32~64:1 are\nachievable via fuzzy qubit indexing over classical byte blocks for every bit\nposition fragmented into a (1/2 upper +1/2 lower)-bit noise frequency parallel\nto its counterpart signal comprised of AND/ORed-bit polarity orientation, ready\nfor an identical data decompression. \n\n"}
{"id": "0910.3033", "contents": "Title: Degraded Compound Multi-receiver Wiretap Channels Abstract: In this paper, we study the degraded compound multi-receiver wiretap channel.\nThe degraded compound multi-receiver wiretap channel consists of two groups of\nusers and a group of eavesdroppers, where, if we pick an arbitrary user from\neach group of users and an arbitrary eavesdropper, they satisfy a certain\nMarkov chain. We study two different communication scenarios for this channel.\nIn the first scenario, the transmitter wants to send a confidential message to\nusers in the first (stronger) group and a different confidential message to\nusers in the second (weaker) group, where both messages need to be kept\nconfidential from the eavesdroppers. For this scenario, we assume that there is\nonly one eavesdropper. We obtain the secrecy capacity region for the general\ndiscrete memoryless channel model, the parallel channel model, and the Gaussian\nparallel channel model. For the Gaussian multiple-input multiple-output (MIMO)\nchannel model, we obtain the secrecy capacity region when there is only one\nuser in the second group. In the second scenario we study, the transmitter\nsends a confidential message to users in the first group which needs to be kept\nconfidential from the second group of users and the eavesdroppers. Furthermore,\nthe transmitter sends a different confidential message to users in the second\ngroup which needs to be kept confidential only from the eavesdroppers. For this\nscenario, we do not put any restriction on the number of eavesdroppers. As in\nthe first scenario, we obtain the secrecy capacity region for the general\ndiscrete memoryless channel model, the parallel channel model, and the Gaussian\nparallel channel model. For the Gaussian MIMO channel model, we establish the\nsecrecy capacity region when there is only one user in the second group. \n\n"}
{"id": "0910.4686", "contents": "Title: Moderate Deviations of the Random Riccati Equation Abstract: We characterize the invariant filtering measures resulting from Kalman\nfiltering with intermittent observations (\\cite{Bruno}), where the observation\narrival is modeled as a Bernoulli process. In \\cite{Riccati-weakconv}, it was\nshown that there exists a $\\overline{\\gamma}^{\\{\\scriptsize{sb}}}>0$ such that\nfor every observation packet arrival probability $\\overline{\\gamma}$,\n$\\overline{\\gamma}>\\overline{\\gamma}^{\\{\\scriptsize{sb}}}>0$, the sequence of\nrandom conditional error covariance matrices converges in distribution to a\nunique invariant distribution $\\mathbb{\\mu}^{\\overline{\\gamma}}$ (independent\nof the filter initialization.) In this paper, we prove that, for controllable\nand observable systems, $\\overline{\\gamma}^{\\{\\scriptsize{sb}}}=0$ and that, as\n$\\overline{\\gamma}\\uparrow 1$, the family\n$\\{\\mathbb{\\mu}^{\\overline{\\gamma}}\\}_{\\overline{\\gamma}>0}$ of invariant\ndistributions satisfies a moderate deviations principle (MDP) with a good rate\nfunction $I$. The rate function $I$ is explicitly identified. In particular,\nour results show: \n\n"}
{"id": "0910.5673", "contents": "Title: Synchronization and Transient Stability in Power Networks and\n  Non-Uniform Kuramoto Oscillators Abstract: Motivated by recent interest for multi-agent systems and smart power grid\narchitectures, we discuss the synchronization problem for the network-reduced\nmodel of a power system with non-trivial transfer conductances. Our key insight\nis to exploit the relationship between the power network model and a\nfirst-order model of coupled oscillators. Assuming overdamped generators\n(possibly due to local excitation controllers), a singular perturbation\nanalysis shows the equivalence between the classic swing equations and a\nnon-uniform Kuramoto model. Here, non-uniform Kuramoto oscillators are\ncharacterized by multiple time constants, non-homogeneous coupling, and\nnon-uniform phase shifts. Extending methods from transient stability,\nsynchronization theory, and consensus protocols, we establish sufficient\nconditions for synchronization of non-uniform Kuramoto oscillators. These\nconditions reduce to and improve upon previously-available tests for the\nstandard Kuramoto model. Combining our singular perturbation and Kuramoto\nanalyses, we derive concise and purely algebraic conditions that relate\nsynchronization and transient stability of a power network to the underlying\nsystem parameters and initial conditions. \n\n"}
{"id": "0911.3256", "contents": "Title: Enumerative Coding for Grassmannian Space Abstract: The Grassmannian space $\\Gr$ is the set of all $k-$dimensional subspaces of\nthe vector space~\\smash{$\\F_q^n$}. Recently, codes in the Grassmannian have\nfound an application in network coding. The main goal of this paper is to\npresent efficient enumerative encoding and decoding techniques for the\nGrassmannian. These coding techniques are based on two different orders for the\nGrassmannian induced by different representations of $k$-dimensional subspaces\nof $\\F_q^n$. One enumerative coding method is based on a Ferrers diagram\nrepresentation and on an order for $\\Gr$ based on this representation. The\ncomplexity of this enumerative coding is $O(k^{5/2} (n-k)^{5/2})$ digit\noperations. Another order of the Grassmannian is based on a combination of an\nidentifying vector and a reduced row echelon form representation of subspaces.\nThe complexity of the enumerative coding, based on this order, is\n$O(nk(n-k)\\log n\\log\\log n)$ digits operations. A combination of the two\nmethods reduces the complexity on average by a constant factor. \n\n"}
{"id": "0912.0581", "contents": "Title: Log-concavity, ultra-log-concavity, and a maximum entropy property of\n  discrete compound Poisson measures Abstract: Sufficient conditions are developed, under which the compound Poisson\ndistribution has maximal entropy within a natural class of probability measures\non the nonnegative integers. Recently, one of the authors [O. Johnson, {\\em\nStoch. Proc. Appl.}, 2007] used a semigroup approach to show that the Poisson\nhas maximal entropy among all ultra-log-concave distributions with fixed mean.\nWe show via a non-trivial extension of this semigroup approach that the natural\nanalog of the Poisson maximum entropy property remains valid if the compound\nPoisson distributions under consideration are log-concave, but that it fails in\ngeneral. A parallel maximum entropy result is established for the family of\ncompound binomial measures. Sufficient conditions for compound distributions to\nbe log-concave are discussed and applications to combinatorics are examined;\nnew bounds are derived on the entropy of the cardinality of a random\nindependent set in a claw-free graph, and a connection is drawn to Mason's\nconjecture for matroids. The present results are primarily motivated by the\ndesire to provide an information-theoretic foundation for compound Poisson\napproximation and associated limit theorems, analogous to the corresponding\ndevelopments for the central limit theorem and for Poisson approximation. Our\nresults also demonstrate new links between some probabilistic methods and the\ncombinatorial notions of log-concavity and ultra-log-concavity, and they add to\nthe growing body of work exploring the applications of maximum entropy\ncharacterizations to problems in discrete mathematics. \n\n"}
{"id": "0912.1987", "contents": "Title: Training and Feedback Optimization for Multiuser MIMO Downlink Abstract: We consider a MIMO fading broadcast channel where the fading channel\ncoefficients are constant over time-frequency blocks that span a coherent time\n$\\times$ a coherence bandwidth. In closed-loop systems, channel state\ninformation at transmitter (CSIT) is acquired by the downlink training sent by\nthe base station and an explicit feedback from each user terminal. In open-loop\nsystems, CSIT is obtained by exploiting uplink training and channel\nreciprocity. We use a tight closed-form lower bound on the ergodic achievable\nrate in the presence of CSIT errors in order to optimize the overall system\nthroughput, by taking explicitly into account the overhead due to channel\nestimation and channel state feedback. Based on three time-frequency block\nmodels inspired by actual systems, we provide some useful guidelines for the\noverall system optimization. In particular, digital (quantized) feedback is\nfound to offer a substantial advantage over analog (unquantized) feedback. \n\n"}
{"id": "1001.2892", "contents": "Title: On the Capacity of Causal Cognitive Interference Channel With Delay Abstract: In this paper, we introduce the Causal Cognitive Interference Channel With\nDelay (CC-IFC-WD) in which the cognitive user transmission can depend on $L$\nfuture received symbols as well as the past ones. Taking the effect of the link\ndelays into account, CC-IFC-WD fills the gap between the genie-aided and causal\n1cognitive radio channels. We study three special cases: 1) Classical CC-IFC\n(L=0), 2) CC-IFC without delay (L=1) and 3) CC-IFC with a block length delay\n(L=n). In each case, we obtain an inner bound on the capacity region. Our\ncoding schemes make use of cooperative strategy by generalized block Markov\nsuperposition coding, collaborative strategy by rate splitting, and\nGel'fand-Pinsker coding in order to pre-cancel part of the interference.\nMoreover, instantaneous relaying and non-causal partial Decode-and-Forward\nstrategies are employed in the second and third cases, respectively. The\nderived regions under special conditions, reduce to several previously known\nresults. Moreover, we show that the coding strategy which we use to derive\nachievable rate region for the classical CC-IFC achieves capacity for a special\ncase of this channel. Furthermore, we extend our achievable rate regions to\nGaussian case. Providing a numerical example for Gaussian CC-IFC-WD, we\ninvestigate the rate gain of the cognitive link for different delay values. \n\n"}
{"id": "1001.3705", "contents": "Title: Secret Key Agreement from Correlated Gaussian Sources by Rate Limited\n  Public Communication Abstract: We investigate the secret key agreement from correlated Gaussian sources in\nwhich the legitimate parties can use the public communication with limited\nrate. For the class of protocols with the one-way public communication, we show\na closed form expression of the optimal trade-off between the rate of key\ngeneration and the rate of the public communication. Our results clarify an\nessential difference between the key agreement from discrete sources and that\nfrom continuous sources. \n\n"}
{"id": "1001.4295", "contents": "Title: \"Compressed\" Compressed Sensing Abstract: The field of compressed sensing has shown that a sparse but otherwise\narbitrary vector can be recovered exactly from a small number of randomly\nconstructed linear projections (or samples). The question addressed in this\npaper is whether an even smaller number of samples is sufficient when there\nexists prior knowledge about the distribution of the unknown vector, or when\nonly partial recovery is needed. An information-theoretic lower bound with\nconnections to free probability theory and an upper bound corresponding to a\ncomputationally simple thresholding estimator are derived. It is shown that in\ncertain cases (e.g. discrete valued vectors or large distortions) the number of\nsamples can be decreased. Interestingly though, it is also shown that in many\ncases no reduction is possible. \n\n"}
{"id": "1001.4548", "contents": "Title: On the BICM Capacity Abstract: Optimal binary labelings, input distributions, and input alphabets are\nanalyzed for the so-called bit-interleaved coded modulation (BICM) capacity,\npaying special attention to the low signal-to-noise ratio (SNR) regime. For\n8-ary pulse amplitude modulation (PAM) and for 0.75 bit/symbol, the folded\nbinary code results in a higher capacity than the binary reflected gray code\n(BRGC) and the natural binary code (NBC). The 1 dB gap between the additive\nwhite Gaussian noise (AWGN) capacity and the BICM capacity with the BRGC can be\nalmost completely removed if the input symbol distribution is properly\nselected. First-order asymptotics of the BICM capacity for arbitrary input\nalphabets and distributions, dimensions, mean, variance, and binary labeling\nare developed. These asymptotics are used to define first-order optimal (FOO)\nconstellations for BICM, i.e. constellations that make BICM achieve the Shannon\nlimit $-1.59 \\tr{dB}$. It is shown that the $\\Eb/N_0$ required for reliable\ntransmission at asymptotically low rates in BICM can be as high as infinity,\nthat for uniform input distributions and 8-PAM there are only 72 classes of\nbinary labelings with a different first-order asymptotic behavior, and that\nthis number is reduced to only 26 for 8-ary phase shift keying (PSK). A general\nanswer to the question of FOO constellations for BICM is also given: using the\nHadamard transform, it is found that for uniform input distributions, a\nconstellation for BICM is FOO if and only if it is a linear projection of a\nhypercube. A constellation based on PAM or quadrature amplitude modulation\ninput alphabets is FOO if and only if they are labeled by the NBC; if the\nconstellation is based on PSK input alphabets instead, it can never be FOO if\nthe input alphabet has more than four points, regardless of the labeling. \n\n"}
{"id": "1002.2488", "contents": "Title: Entanglement-assisted zero-error capacity is upper bounded by the Lovasz\n  theta function Abstract: The zero-error capacity of a classical channel is expressed in terms of the\nindependence number of some graph and its tensor powers. This quantity is hard\nto compute even for small graphs such as the cycle of length seven, so upper\nbounds such as the Lovasz theta function play an important role in zero-error\ncommunication. In this paper, we show that the Lovasz theta function is an\nupper bound on the zero-error capacity even in the presence of entanglement\nbetween the sender and receiver. \n\n"}
{"id": "1003.2941", "contents": "Title: Universal Regularizers For Robust Sparse Coding and Modeling Abstract: Sparse data models, where data is assumed to be well represented as a linear\ncombination of a few elements from a dictionary, have gained considerable\nattention in recent years, and their use has led to state-of-the-art results in\nmany signal and image processing tasks. It is now well understood that the\nchoice of the sparsity regularization term is critical in the success of such\nmodels. Based on a codelength minimization interpretation of sparse coding, and\nusing tools from universal coding theory, we propose a framework for designing\nsparsity regularization terms which have theoretical and practical advantages\nwhen compared to the more standard l0 or l1 ones. The presentation of the\nframework and theoretical foundations is complemented with examples that show\nits practical advantages in image denoising, zooming and classification. \n\n"}
{"id": "1004.0381", "contents": "Title: Gossip and Distributed Kalman Filtering: Weak Consensus under Weak\n  Detectability Abstract: The paper presents the gossip interactive Kalman filter (GIKF) for\ndistributed Kalman filtering for networked systems and sensor networks, where\ninter-sensor communication and observations occur at the same time-scale. The\ncommunication among sensors is random; each sensor occasionally exchanges its\nfiltering state information with a neighbor depending on the availability of\nthe appropriate network link. We show that under a weak distributed\ndetectability condition:\n  1. the GIKF error process remains stochastically bounded, irrespective of the\ninstability properties of the random process dynamics; and\n  2. the network achieves \\emph{weak consensus}, i.e., the conditional\nestimation error covariance at a (uniformly) randomly selected sensor converges\nin distribution to a unique invariant measure on the space of positive\nsemi-definite matrices (independent of the initial state.)\n  To prove these results, we interpret the filtered states (estimates and error\ncovariances) at each node in the GIKF as stochastic particles with local\ninteractions. We analyze the asymptotic properties of the error process by\nstudying as a random dynamical system the associated switched (random) Riccati\nequation, the switching being dictated by a non-stationary Markov chain on the\nnetwork graph. \n\n"}
{"id": "1004.0557", "contents": "Title: Applications of Lindeberg Principle in Communications and Statistical\n  Learning Abstract: We use a generalization of the Lindeberg principle developed by Sourav\nChatterjee to prove universality properties for various problems in\ncommunications, statistical learning and random matrix theory. We also show\nthat these systems can be viewed as the limiting case of a properly defined\nsparse system. The latter result is useful when the sparse systems are easier\nto analyze than their dense counterparts. The list of problems we consider is\nby no means exhaustive. We believe that the ideas can be used in many other\nproblems relevant for information theory. \n\n"}
{"id": "1004.5189", "contents": "Title: Rate-distortion function via minimum mean square error estimation Abstract: We derive a simple general parametric representation of the rate-distortion\nfunction of a memoryless source, where both the rate and the distortion are\ngiven by integrals whose integrands include the minimum mean square error\n(MMSE) of the distortion $\\Delta=d(X,Y)$ based on the source symbol $X$, with\nrespect to a certain joint distribution of these two random variables. At first\nglance, these relations may seem somewhat similar to the I-MMSE relations due\nto Guo, Shamai and Verd\\'u, but they are, in fact, quite different. The new\nrelations among rate, distortion, and MMSE are discussed from several aspects,\nand more importantly, it is demonstrated that they can sometimes be rather\nuseful for obtaining non-trivial upper and lower bounds on the rate-distortion\nfunction, as well as for determining the exact asymptotic behavior for very low\nand for very large distortion. Analogous MMSE relations hold for channel\ncapacity as well. \n\n"}
{"id": "1005.1284", "contents": "Title: Approximately achieving Gaussian relay network capacity with lattice\n  codes Abstract: Recently, it has been shown that a quantize-map-and-forward scheme\napproximately achieves (within a constant number of bits) the Gaussian relay\nnetwork capacity for arbitrary topologies. This was established using Gaussian\ncodebooks for transmission and random mappings at the relays. In this paper, we\nshow that the same approximation result can be established by using lattices\nfor transmission and quantization along with structured mappings at the relays. \n\n"}
{"id": "1005.1715", "contents": "Title: Degrees of Freedom Region of a Class of Multi-source Gaussian Relay\n  Networks Abstract: We study a layered $K$-user $M$-hop Gaussian relay network consisting of\n$K_m$ nodes in the $m^{\\operatorname{th}}$ layer, where $M\\geq2$ and\n$K=K_1=K_{M+1}$. We observe that the time-varying nature of wireless channels\nor fading can be exploited to mitigate the inter-user interference. The\nproposed amplify-and-forward relaying scheme exploits such channel variations\nand works for a wide class of channel distributions including Rayleigh fading.\nWe show a general achievable degrees of freedom (DoF) region for this class of\nGaussian relay networks. Specifically, the set of all $(d_1,..., d_K)$ such\nthat $d_i\\leq 1$ for all $i$ and $\\sum_{i=1}^K d_i\\leq K_{\\Sigma}$ is\nachievable, where $d_i$ is the DoF of the $i^{\\operatorname{th}}$\nsource--destination pair and $K_{\\Sigma}$ is the maximum integer such that\n$K_{\\Sigma}\\leq \\min_m\\{K_m\\}$ and $M/K_{\\Sigma}$ is an integer. We show that\nsurprisingly the achievable DoF region coincides with the cut-set outer bound\nif $M/\\min_m\\{K_m\\}$ is an integer, thus interference-free communication is\npossible in terms of DoF. We further characterize an achievable DoF region\nassuming multi-antenna nodes and general message set, which again coincides\nwith the cut-set outer bound for a certain class of networks. \n\n"}
{"id": "1006.0619", "contents": "Title: Spectrum Sharing in Cognitive Radio with Quantized Channel Information Abstract: We consider a wideband spectrum sharing system where a secondary user can\nshare a number of orthogonal frequency bands where each band is licensed to an\nindividual primary user. We address the problem of optimum secondary transmit\npower allocation for its ergodic capacity maximization subject to an average\nsum (across the bands) transmit power constraint and individual average\ninterference constraints on the primary users. The major contribution of our\nwork lies in considering quantized channel state information (CSI)(for the\nvector channel space consisting of all secondary-to-secondary and\nsecondary-to-primary channels) at the secondary transmitter. It is assumed that\na band manager or a cognitive radio service provider has access to the full CSI\ninformation from the secondary and primary receivers and designs (offline) an\noptimal power codebook based on the statistical information (channel\ndistributions) of the channels and feeds back the index of the codebook to the\nsecondary transmitter for every channel realization in real-time, via a\ndelay-free noiseless limited feedback channel. A modified Generalized\nLloyds-type algorithm (GLA) is designed for deriving the optimal power\ncodebook. An approximate quantized power allocation (AQPA) algorithm is also\npresented, that performs very close to its GLA based counterpart for large\nnumber of feedback bits and is significantly faster. We also present an\nextension of the modified GLA based quantized power codebook design algorithm\nfor the case when the feedback channel is noisy. Numerical studies illustrate\nthat with only 3-4 bits of feedback, the modified GLA based algorithms provide\nsecondary ergodic capacity very close to that achieved by full CSI and with\nonly as little as 4 bits of feedback, AQPA provides a comparable performance,\nthus making it an attractive choice for practical implementation. \n\n"}
{"id": "1006.2086", "contents": "Title: A Geometric Approach to Low-Rank Matrix Completion Abstract: The low-rank matrix completion problem can be succinctly stated as follows:\ngiven a subset of the entries of a matrix, find a low-rank matrix consistent\nwith the observations. While several low-complexity algorithms for matrix\ncompletion have been proposed so far, it remains an open problem to devise\nsearch procedures with provable performance guarantees for a broad class of\nmatrix models. The standard approach to the problem, which involves the\nminimization of an objective function defined using the Frobenius metric, has\ninherent difficulties: the objective function is not continuous and the\nsolution set is not closed. To address this problem, we consider an\noptimization procedure that searches for a column (or row) space that is\ngeometrically consistent with the partial observations. The geometric objective\nfunction is continuous everywhere and the solution set is the closure of the\nsolution set of the Frobenius metric. We also preclude the existence of local\nminimizers, and hence establish strong performance guarantees, for special\ncompletion scenarios, which do not require matrix incoherence or large matrix\nsize. \n\n"}
{"id": "1006.3959", "contents": "Title: Molecular Communication Using Brownian Motion with Drift Abstract: Inspired by biological communication systems, molecular communication has\nbeen proposed as a viable scheme to communicate between nano-sized devices\nseparated by a very short distance. Here, molecules are released by the\ntransmitter into the medium, which are then sensed by the receiver. This paper\ndevelops a preliminary version of such a communication system focusing on the\nrelease of either one or two molecules into a fluid medium with drift. We\nanalyze the mutual information between transmitter and the receiver when\ninformation is encoded in the time of release of the molecule. Simplifying\nassumptions are required in order to calculate the mutual information, and\ntheoretical results are provided to show that these calculations are upper\nbounds on the true mutual information. Furthermore, optimized degree\ndistributions are provided, which suggest transmission strategies for a variety\nof drift velocities. \n\n"}
{"id": "1007.0404", "contents": "Title: Quasi-Cyclic Asymptotically Regular LDPC Codes Abstract: Families of \"asymptotically regular\" LDPC block code ensembles can be formed\nby terminating (J,K)-regular protograph-based LDPC convolutional codes. By\nvarying the termination length, we obtain a large selection of LDPC block code\nensembles with varying code rates, minimum distance that grows linearly with\nblock length, and capacity approaching iterative decoding thresholds, despite\nthe fact that the terminated ensembles are almost regular. In this paper, we\ninvestigate the properties of the quasi-cyclic (QC) members of such an\nensemble. We show that an upper bound on the minimum Hamming distance of\nmembers of the QC sub-ensemble can be improved by careful choice of the\ncomponent protographs used in the code construction. Further, we show that the\nupper bound on the minimum distance can be improved by using arrays of\ncirculants in a graph cover of the protograph. \n\n"}
{"id": "1007.1209", "contents": "Title: Prime Factor Cyclotomic Fourier Transforms with Reduced Complexity over\n  Finite Fields Abstract: Discrete Fourier transforms~(DFTs) over finite fields have widespread\napplications in error correction coding. Hence, reducing the computational\ncomplexities of DFTs is of great significance, especially for long DFTs as\nincreasingly longer error control codes are chosen for digital communication\nand storage systems. Since DFTs involve both multiplications and additions over\nfinite fields and multiplications are much more complex than additions,\nrecently proposed cyclotomic fast Fourier transforms (CFFTs) are promising due\nto their low multiplicative complexity. Unfortunately, they have very high\nadditive complexity. Techniques such as common subexpression elimination (CSE)\ncan be used to reduce the additive complexity of CFFTs, but their effectiveness\nfor long DFTs is limited by their complexity. In this paper, we propose prime\nfactor cyclotomic Fourier transforms (PFCFTs), which use CFFTs as sub-DFTs via\nthe prime factor algorithm. When the length of DFTs is prime, our PFCFTs reduce\nto CFFTs. When the length has co-prime factors, since the sub-DFTs have much\nshorter lengths, this allows us to use CSE to significantly reduce their\nadditive complexity. In comparison to previously proposed fast Fourier\ntransforms, our PFCFTs achieve reduced overall complexity when the length of\nDFTs is at least 255, and the improvement significantly increases as the length\ngrows. This approach also enables us to propose efficient DFTs with very long\nlength (e.g., 4095-point), first efficient DFTs of such lengths in the\nliterature. Finally, our PFCFTs are also advantageous for hardware\nimplementation due to their regular structure. \n\n"}
{"id": "1007.3315", "contents": "Title: Multi-Source Transmission for Wireless Relay Networks with Linear\n  Complexity Abstract: This paper considers transmission schemes in multi-access relay networks\n(MARNs) where $J$ single-antenna sources send independent information to one\n$N$-antenna destination through one $M$-antenna relay. For complexity\nconsiderations, we propose a linear framework, where the relay linearly\ntransforms its received signals to generate the forwarded signals without\ndecoding and the destination uses its multi-antennas to fully decouple signals\nfrom different sources before decoding, by which the decoding complexity is\nlinear in the number of sources. To achieve a high symbol rate, we first\npropose a scheme called DSTC-ICRec in which all sources' information streams\nare concurrently transmitted in both the source-relay link and the\nrelay-destination link. In this scheme, distributed space-time coding (DSTC) is\napplied at the relay, which satisfies the linear constraint. DSTC also allows\nthe destination to conduct the zero-forcing interference cancellation (IC)\nscheme originally proposed for multi-antenna systems to fully decouple signals\nfrom different sources. Our analysis shows that the symbol rate of DSTC-ICRec\nis $1/2$ symbols/source/channel use and the diversity gain of the scheme is\nupperbounded by $M-J+1$. To achieve a higher diversity gain, we propose another\nscheme called TDMA-ICRec in which the sources time-share the source-relay link.\nThe relay coherently combines the signals on its antennas to maximize the\nsignal-to-noise ratio (SNR) of each source, then concurrently forwards all\nsources' information. The destination performs zero-forcing IC. It is shown\nthrough both analysis and simulation that when $N \\ge 2J-1$, TDMA-ICRec\nachieves the same maximum diversity gain as the full TDMA scheme in which the\ninformation stream from each source is assigned to an orthogonal channel in\nboth links, but with a higher symbol rate. \n\n"}
{"id": "1007.4418", "contents": "Title: Distributed Source Coding of Correlated Gaussian Sources Abstract: We consider the distributed source coding system of $L$ correlated Gaussian\nsources $Y_i,i=1,2,...,L$ which are noisy observations of correlated Gaussian\nremote sources $X_k, k=1,2,...,K$. We assume that $Y^{L}={}^{\\rm t}(Y_1,Y_2,$\n$..., Y_L)$ is an observation of the source vector $X^K={}^{\\rm t}(X_1,X_2,...,\nX_K)$, having the form $Y^L=AX^K+N^L$, where $A$ is a $L\\times K$ matrix and\n$N^L={}^{\\rm t}(N_1,N_2,...,N_L)$ is a vector of $L$ independent Gaussian\nrandom variables also independent of $X^K$. In this system $L$ correlated\nGaussian observations are separately compressed by $L$ encoders and sent to the\ninformation processing center. We study the remote source coding problem where\nthe decoder at the center attempts to reconstruct the remote source $X^K$. We\nconsider three distortion criteria based on the covariance matrix of the\nestimation error on $X^K$. For each of those three criteria we derive explicit\ninner and outer bounds of the rate distortion region. Next, in the case of\n$K=L$ and $A=I_L$, we study the multiterminal source coding problem where the\ndecoder wishes to reconstruct the observation $Y^L=X^L+N^L$. To investigate\nthis problem we shall establish a result which provides a strong connection\nbetween the remote source coding problem and the multiterminal source coding\nproblem. Using this result, we drive several new partial solutions to the\nmultiterminal source coding problem. \n\n"}
{"id": "1008.2972", "contents": "Title: Algebraic Signal Processing Theory: Cooley-Tukey Type Algorithms for\n  Polynomial Transforms Based on Induction Abstract: A polynomial transform is the multiplication of an input vector $x\\in\\C^n$ by\na matrix $\\PT_{b,\\alpha}\\in\\C^{n\\times n},$ whose $(k,\\ell)$-th element is\ndefined as $p_\\ell(\\alpha_k)$ for polynomials $p_\\ell(x)\\in\\C[x]$ from a list\n$b=\\{p_0(x),\\dots,p_{n-1}(x)\\}$ and sample points $\\alpha_k\\in\\C$ from a list\n$\\alpha=\\{\\alpha_0,\\dots,\\alpha_{n-1}\\}$. Such transforms find applications in\nthe areas of signal processing, data compression, and function interpolation.\nImportant examples include the discrete Fourier and cosine transforms. In this\npaper we introduce a novel technique to derive fast algorithms for polynomial\ntransforms. The technique uses the relationship between polynomial transforms\nand the representation theory of polynomial algebras. Specifically, we derive\nalgorithms by decomposing the regular modules of these algebras as a stepwise\ninduction. As an application, we derive novel $O(n\\log{n})$ general-radix\nalgorithms for the discrete Fourier transform and the discrete cosine transform\nof type 4. \n\n"}
{"id": "1008.4177", "contents": "Title: LDPC Codes from Latin Squares Free of Small Trapping Sets Abstract: This paper is concerned with the construction of low-density parity-check\n(LDPC) codes with low error floors. Two main contributions are made. First, a\nnew class of structured LDPC codes is introduced. The parity check matrices of\nthese codes are arrays of permutation matrices which are obtained from Latin\nsquares and form a finite field under some matrix operations. Second, a method\nto construct LDPC codes with low error floors on the binary symmetric channel\n(BSC) is presented. Codes are constructed so that their Tanner graphs are free\nof certain small trapping sets. These trapping sets are selected from the\nTrapping Set Ontology for the Gallager A/B decoder. They are selected based on\ntheir relative harmfulness for a given decoding algorithm. We evaluate the\nrelative harmfulness of different trapping sets for the sum product algorithm\n(SPA) by using the topological relations among them and by analyzing the\ndecoding failures on one trapping set in the presence or absence of other\ntrapping sets. \n\n"}
{"id": "1008.4895", "contents": "Title: LIFO-Backpressure Achieves Near Optimal Utility-Delay Tradeoff Abstract: There has been considerable recent work developing a new stochastic network\nutility maximization framework using Backpressure algorithms, also known as\nMaxWeight. A key open problem has been the development of utility-optimal\nalgorithms that are also delay efficient. In this paper, we show that the\nBackpressure algorithm, when combined with the LIFO queueing discipline (called\nLIFO-Backpressure), is able to achieve a utility that is within $O(1/V)$ of the\noptimal value, while maintaining an average delay of $O([\\log(V)]^2)$ for all\nbut a tiny fraction of the network traffic. This result holds for general\nstochastic network optimization problems and general Markovian dynamics.\nRemarkably, the performance of LIFO-Backpressure can be achieved by simply\nchanging the queueing discipline; it requires no other modifications of the\noriginal Backpressure algorithm. We validate the results through empirical\nmeasurements from a sensor network testbed, which show good match between\ntheory and practice. \n\n"}
{"id": "1009.0638", "contents": "Title: Clique Graphs and Overlapping Communities Abstract: It is shown how to construct a clique graph in which properties of cliques of\na fixed order in a given graph are represented by vertices in a weighted graph.\nVarious definitions and motivations for these weights are given. The detection\nof communities or clusters is used to illustrate how a clique graph may be\nexploited. In particular a benchmark network is shown where clique graphs find\nthe overlapping communities accurately while vertex partition methods fail. \n\n"}
{"id": "1009.1128", "contents": "Title: Distributed Basis Pursuit Abstract: We propose a distributed algorithm for solving the optimization problem Basis\nPursuit (BP). BP finds the least L1-norm solution of the underdetermined linear\nsystem Ax = b and is used, for example, in compressed sensing for\nreconstruction. Our algorithm solves BP on a distributed platform such as a\nsensor network, and is designed to minimize the communication between nodes.\nThe algorithm only requires the network to be connected, has no notion of a\ncentral processing node, and no node has access to the entire matrix A at any\ntime. We consider two scenarios in which either the columns or the rows of A\nare distributed among the compute nodes. Our algorithm, named D-ADMM, is a\ndecentralized implementation of the alternating direction method of\nmultipliers. We show through numerical simulation that our algorithm requires\nconsiderably less communications between the nodes than the state-of-the-art\nalgorithms. \n\n"}
{"id": "1010.1037", "contents": "Title: Stratified economic exchange on networks Abstract: We investigate a model of stratified economic interactions between agents\nwhen the notion of spatial location is introduced. The agents are placed on a\nnetwork with near-neighbor connections. Interactions between neighbors can\noccur only if the difference in their wealth is less than a threshold value\nthat defines the width of the economic classes. By employing concepts from\nspatiotemporal dynamical systems, three types of patterns can be identified in\nthe system as parameters are varied: laminar, intermittent and turbulent\nstates. The transition from the laminar state to the turbulent state is\ncharacterized by the activity of the system, a quantity that measures the\naverage exchange of wealth over long times. The degree of inequality in the\nwealth distribution for different parameter values is characterized by the Gini\nCoefficient. High levels of activity are associated to low values of the Gini\ncoefficient. It is found that the topological properties of the network have\nlittle effect on the activity of the system, but the Gini coefficient increases\nwhen the clustering coefficient of the network is increased. \n\n"}
{"id": "1010.1862", "contents": "Title: Utility Optimal Scheduling in Processing Networks Abstract: We consider the problem of utility optimal scheduling in general\n\\emph{processing networks} with random arrivals and network conditions. These\nare generalizations of traditional data networks where commodities in one or\nmore queues can be combined to produce new commodities that are delivered to\nother parts of the network. This can be used to model problems such as\nin-network data fusion, stream processing, and grid computing. Scheduling\nactions are complicated by the \\emph{underflow problem} that arises when some\nqueues with required components go empty. In this paper, we develop the\nPerturbed Max-Weight algorithm (PMW) to achieve optimal utility. The idea of\nPMW is to perturb the weights used by the usual Max-Weight algorithm to\n``push'' queue levels towards non-zero values (avoiding underflows). We show\nthat when the perturbations are carefully chosen, PMW is able to achieve a\nutility that is within $O(1/V)$ of the optimal value for any $V\\geq1$, while\nensuring an average network backlog of $O(V)$. \n\n"}
{"id": "1010.2160", "contents": "Title: Robustness of interdependent networks under targeted attack Abstract: When an initial failure of nodes occurs in interdependent networks, a cascade\nof failure between the networks occurs. Earlier studies focused on random\ninitial failures. Here we study the robustness of interdependent networks under\ntargeted attack on high or low degree nodes. We introduce a general technique\nand show that the {\\it targeted-attack} problem in interdependent networks can\nbe mapped to the {\\it random-attack} problem in a transformed pair of\ninterdependent networks. We find that when the highly connected nodes are\nprotected and have lower probability to fail, in contrast to single scale free\n(SF) networks where the percolation threshold $p_c=0$, coupled SF networks are\nsignificantly more vulnerable with $p_c$ significantly larger than zero. The\nresult implies that interdependent networks are difficult to defend by\nstrategies such as protecting the high degree nodes that have been found useful\nto significantly improve robustness of single networks. \n\n"}
{"id": "1010.2787", "contents": "Title: Interference Alignment with Analog Channel State Feedback Abstract: Interference alignment (IA) is a multiplexing gain optimal transmission\nstrategy for the interference channel. While the achieved sum rate with IA is\nmuch higher than previously thought possible, the improvement often comes at\nthe cost of requiring network channel state information at the transmitters.\nThis can be achieved by explicit feedback, a flexible yet potentially costly\napproach that incurs large overhead. In this paper we propose analog feedback\nas an alternative to limited feedback or reciprocity based alignment. We show\nthat the full multiplexing gain observed with perfect channel knowledge is\npreserved by analog feedback and that the mean loss in sum rate is bounded by a\nconstant when signal-to-noise ratio is comparable in both forward and feedback\nchannels. When signal-to-noise ratios are not quite symmetric, a fraction of\nthe multiplexing gain is achieved. We consider the overhead of training and\nfeedback and use this framework to optimize the system's effective throughput.\nWe present simulation results to demonstrate the performance of IA with analog\nfeedback, verify our theoretical analysis, and extend our conclusions on\noptimal training and feedback length. \n\n"}
{"id": "1010.3757", "contents": "Title: Community Structure in the United Nations General Assembly Abstract: We study the community structure of networks representing voting on\nresolutions in the United Nations General Assembly. We construct networks from\nthe voting records of the separate annual sessions between 1946 and 2008 in\nthree different ways: (1) by considering voting similarities as weighted\nunipartite networks; (2) by considering voting similarities as weighted, signed\nunipartite networks; and (3) by examining signed bipartite networks in which\ncountries are connected to resolutions. For each formulation, we detect\ncommunities by optimizing network modularity using an appropriate null model.\nWe compare and contrast the results that we obtain for these three different\nnetwork representations. In so doing, we illustrate the need to consider\nmultiple resolution parameters and explore the effectiveness of each network\nrepresentation for identifying voting groups amidst the large amount of\nagreement typical in General Assembly votes. \n\n"}
{"id": "1010.4237", "contents": "Title: Robust PCA via Outlier Pursuit Abstract: Singular Value Decomposition (and Principal Component Analysis) is one of the\nmost widely used techniques for dimensionality reduction: successful and\nefficiently computable, it is nevertheless plagued by a well-known,\nwell-documented sensitivity to outliers. Recent work has considered the setting\nwhere each point has a few arbitrarily corrupted components. Yet, in\napplications of SVD or PCA such as robust collaborative filtering or\nbioinformatics, malicious agents, defective genes, or simply corrupted or\ncontaminated experiments may effectively yield entire points that are\ncompletely corrupted.\n  We present an efficient convex optimization-based algorithm we call Outlier\nPursuit, that under some mild assumptions on the uncorrupted points (satisfied,\ne.g., by the standard generative assumption in PCA problems) recovers the exact\noptimal low-dimensional subspace, and identifies the corrupted points. Such\nidentification of corrupted points that do not conform to the low-dimensional\napproximation, is of paramount interest in bioinformatics and financial\napplications, and beyond. Our techniques involve matrix decomposition using\nnuclear norm minimization, however, our results, setup, and approach,\nnecessarily differ considerably from the existing line of work in matrix\ncompletion and matrix decomposition, since we develop an approach to recover\nthe correct column space of the uncorrupted matrix, rather than the exact\nmatrix itself. In any problem where one seeks to recover a structure rather\nthan the exact initial matrices, techniques developed thus far relying on\ncertificates of optimality, will fail. We present an important extension of\nthese methods, that allows the treatment of such problems. \n\n"}
{"id": "1010.4858", "contents": "Title: S-MATE: Secure Coding-based Multipath Adaptive Traffic Engineering Abstract: There have been several approaches to provisioning traffic between core\nnetwork nodes in Internet Service Provider (ISP) networks. Such approaches aim\nto minimize network delay, increase network capacity, and enhance network\nsecurity services. MATE (Multipath Adaptive Traffic Engineering) protocol has\nbeen proposed for multipath adaptive traffic engineering between an ingress\nnode (source) and an egress node (destination). Its novel idea is to avoid\nnetwork congestion and attacks that might exist in edge and node disjoint paths\nbetween two core network nodes.\n  This paper builds an adaptive, robust, and reliable traffic engineering\nscheme for better performance of communication network operations. This will\nalso provision quality of service (QoS) and protection of traffic engineering\nto maximize network efficiency. Specifically, we present a new approach, S-MATE\n(secure MATE) is developed to protect the network traffic between two core\nnodes (routers or switches) in a cloud network. S-MATE secures against a single\nlink attack/failure by adding redundancy in one of the operational paths\nbetween the sender and receiver. The proposed scheme can be built to secure\ncore networks such as optical and IP networks. \n\n"}
{"id": "1010.5806", "contents": "Title: Inner and Outer Bounds for the Gaussian Cognitive Interference Channel\n  and New Capacity Results Abstract: The capacity of the Gaussian cognitive interference channel, a variation of\nthe classical two-user interference channel where one of the transmitters\n(referred to as cognitive) has knowledge of both messages, is known in several\nparameter regimes but remains unknown in general. In this paper we provide a\ncomparative overview of this channel model as we proceed through our\ncontributions: we present a new outer bound based on the idea of a broadcast\nchannel with degraded message sets, and another series of outer bounds obtained\nby transforming the cognitive channel into channels with known capacity. We\nspecialize the largest known inner bound derived for the discrete memoryless\nchannel to the Gaussian noise channel and present several simplified schemes\nevaluated for Gaussian inputs in closed form which we use to prove a number of\nresults. These include a new set of capacity results for the a) \"primary\ndecodes cognitive\" regime, a subset of the \"strong interference\" regime that is\nnot included in the \"very strong interference\" regime for which capacity was\nknown, and for the b) \"S-channel\" in which the primary transmitter does not\ninterfere with the cognitive receiver. Next, for a general Gaussian cognitive\ninterference channel, we determine the capacity to within one bit/s/Hz and to\nwithin a factor two regardless of channel parameters, thus establishing rate\nperformance guarantees at high and low SNR, respectively. We also show how\ndifferent simplified transmission schemes achieve a constant gap between inner\nand outer bound for specific channels. Finally, we numerically evaluate and\ncompare the various simplified achievable rate regions and outer bounds in\nparameter regimes where capacity is unknown, leading to further insight on the\ncapacity region of the Gaussian cognitive interference channel. \n\n"}
{"id": "1010.6148", "contents": "Title: On a small-gain approach to distributed event-triggered control Abstract: In this paper the problem of stabilizing large-scale systems by distributed\ncontrollers, where the controllers exchange information via a shared limited\ncommunication medium is addressed. Event-triggered sampling schemes are\nproposed, where each system decides when to transmit new information across the\nnetwork based on the crossing of some error thresholds. Stability of the\ninterconnected large-scale system is inferred by applying a generalized\nsmall-gain theorem. Two variations of the event-triggered controllers which\nprevent the occurrence of the Zeno phenomenon are also discussed. \n\n"}
{"id": "1011.1040", "contents": "Title: A parametric approach to list decoding of Reed-Solomon codes using\n  interpolation Abstract: In this paper we present a minimal list decoding algorithm for Reed-Solomon\n(RS) codes. Minimal list decoding for a code $C$ refers to list decoding with\nradius $L$, where $L$ is the minimum of the distances between the received word\n$\\mathbf{r}$ and any codeword in $C$. We consider the problem of determining\nthe value of $L$ as well as determining all the codewords at distance $L$. Our\napproach involves a parametrization of interpolating polynomials of a minimal\nGr\\\"obner basis $G$. We present two efficient ways to compute $G$. We also show\nthat so-called re-encoding can be used to further reduce the complexity. We\nthen demonstrate how our parametric approach can be solved by a computationally\nfeasible rational curve fitting solution from a recent paper by Wu. Besides, we\npresent an algorithm to compute the minimum multiplicity as well as the optimal\nvalues of the parameters associated with this multiplicity which results in\noverall savings in both memory and computation. \n\n"}
{"id": "1011.1607", "contents": "Title: To Feed or Not to Feed Back Abstract: We study the communication over Finite State Channels (FSCs), where the\nencoder and the decoder can control the availability or the quality of the\nnoise-free feedback. Specifically, the instantaneous feedback is a function of\nan action taken by the encoder, an action taken by the decoder, and the channel\noutput. Encoder and decoder actions take values in finite alphabets, and may be\nsubject to average cost constraints. We prove capacity results for such a\nsetting by constructing a sequence of achievable rates, using a simple scheme\nbased on 'code tree' generation, that generates channel input symbols along\nwith encoder and decoder actions. We prove that the limit of this sequence\nexists. For a given block length and probability of error, we give an upper\nbound on the maximum achievable rate. Our upper and lower bounds coincide and\nhence yield the capacity for the case where the probability of initial state is\npositive for all states. Further, for stationary indecomposable channels\nwithout intersymbol interference (ISI), the capacity is given as the limit of\nnormalized directed information between the input and output sequence,\nmaximized over an appropriate set of causally conditioned distributions. As an\nimportant special case, we consider the framework of 'to feed or not to feed\nback' where either the encoder or the decoder takes binary actions, which\ndetermine whether current channel output will be fed back to the encoder, with\na constraint on the fraction of channel outputs that are fed back. As another\nspecial case of our framework, we characterize the capacity of 'coding on the\nbackward link' in FSCs, i.e. when the decoder sends limited-rate instantaneous\ncoded noise-free feedback on the backward link. Finally, we propose an\nextension of the Blahut-Arimoto algorithm for evaluating the capacity when\nactions can be cost constrained, and demonstrate its application on a few\nexamples. \n\n"}
{"id": "1011.1677", "contents": "Title: Convergence Rate Analysis of Distributed Gossip (Linear Parameter)\n  Estimation: Fundamental Limits and Tradeoffs Abstract: The paper considers gossip distributed estimation of a (static) distributed\nrandom field (a.k.a., large scale unknown parameter vector) observed by\nsparsely interconnected sensors, each of which only observes a small fraction\nof the field. We consider linear distributed estimators whose structure\ncombines the information \\emph{flow} among sensors (the \\emph{consensus} term\nresulting from the local gossiping exchange among sensors when they are able to\ncommunicate) and the information \\emph{gathering} measured by the sensors (the\n\\emph{sensing} or \\emph{innovations} term.) This leads to mixed time scale\nalgorithms--one time scale associated with the consensus and the other with the\ninnovations. The paper establishes a distributed observability condition\n(global observability plus mean connectedness) under which the distributed\nestimates are consistent and asymptotically normal. We introduce the\ndistributed notion equivalent to the (centralized) Fisher information rate,\nwhich is a bound on the mean square error reduction rate of any distributed\nestimator; we show that under the appropriate modeling and structural network\ncommunication conditions (gossip protocol) the distributed gossip estimator\nattains this distributed Fisher information rate, asymptotically achieving the\nperformance of the optimal centralized estimator. Finally, we study the\nbehavior of the distributed gossip estimator when the measurements fade (noise\nvariance grows) with time; in particular, we consider the maximum rate at which\nthe noise variance can grow and still the distributed estimator being\nconsistent, by showing that, as long as the centralized estimator is\nconsistent, the distributed estimator remains consistent. \n\n"}
{"id": "1011.3571", "contents": "Title: A Framework for Quantitative Analysis of Cascades on Networks Abstract: How does information flow in online social networks? How does the structure\nand size of the information cascade evolve in time? How can we efficiently mine\nthe information contained in cascade dynamics? We approach these questions\nempirically and present an efficient and scalable mathematical framework for\nquantitative analysis of cascades on networks. We define a cascade generating\nfunction that captures the details of the microscopic dynamics of the cascades.\nWe show that this function can also be used to compute the macroscopic\nproperties of cascades, such as their size, spread, diameter, number of paths,\nand average path length. We present an algorithm to efficiently compute cascade\ngenerating function and demonstrate that while significantly compressing\ninformation within a cascade, it nevertheless allows us to accurately\nreconstruct its structure. We use this framework to study information dynamics\non the social network of Digg. Digg allows users to post and vote on stories,\nand easily see the stories that friends have voted on. As a story spreads on\nDigg through voting, it generates cascades. We extract cascades of more than\n3,500 Digg stories and calculate their macroscopic and microscopic properties.\nWe identify several trends in cascade dynamics: spreading via chaining,\nbranching and community. We discuss how these affect the spread of the story\nthrough the Digg social network. Our computational framework is general and\noffers a practical solution to quantitative analysis of the microscopic\nstructure of even very large cascades. \n\n"}
{"id": "1011.4161", "contents": "Title: Community characterization of heterogeneous complex systems Abstract: We introduce an analytical statistical method to characterize the communities\ndetected in heterogeneous complex systems. By posing a suitable null\nhypothesis, our method makes use of the hypergeometric distribution to assess\nthe probability that a given property is over-expressed in the elements of a\ncommunity with respect to all the elements of the investigated set. We apply\nour method to two specific complex networks, namely a network of world movies\nand a network of physics preprints. The characterization of the elements and of\nthe communities is done in terms of languages and countries for the movie\nnetwork and of journals and subject categories for papers. We find that our\nmethod is able to characterize clearly the identified communities. Moreover our\nmethod works well both for large and for small communities. \n\n"}
{"id": "1011.5950", "contents": "Title: Networks and the Epidemiology of Infectious Disease Abstract: The science of networks has revolutionised research into the dynamics of\ninteracting elements. It could be argued that epidemiology in particular has\nembraced the potential of network theory more than any other discipline. Here\nwe review the growing body of research concerning the spread of infectious\ndiseases on networks, focusing on the interplay between network theory and\nepidemiology. The review is split into four main sections, which examine: the\ntypes of network relevant to epidemiology; the multitude of ways these networks\ncan be characterised; the statistical methods that can be applied to infer the\nepidemiological parameters on a realised network; and finally simulation and\nanalytical methods to determine epidemic dynamics on a given network. Given the\nbreadth of areas covered and the ever-expanding number of publications, a\ncomprehensive review of all work is impossible. Instead, we provide a\npersonalised overview into the areas of network epidemiology that have seen the\ngreatest progress in recent years or have the greatest potential to provide\nnovel insights. As such, considerable importance is placed on analytical\napproaches and statistical methods which are both rapidly expanding fields.\nThroughout this review we restrict our attention to epidemiological issues. \n\n"}
{"id": "1011.6639", "contents": "Title: Multiple Access Channels with States Causally Known at Transmitters Abstract: It has been recently shown by Lapidoth and Steinberg that strictly causal\nstate information can be beneficial in multiple access channels (MACs).\nSpecifically, it was proved that the capacity region of a two-user MAC with\nindependent states, each known strictly causally to one encoder, can be\nenlarged by letting the encoders send compressed past state information to the\ndecoder. In this work, a generalization of the said strategy is proposed\nwhereby the encoders compress also the past transmitted codewords along with\nthe past state sequences. The proposed scheme uses a combination of\nlong-message encoding, compression of the past state sequences and codewords\nwithout binning, and joint decoding over all transmission blocks. The proposed\nstrategy has been recently shown by Lapidoth and Steinberg to strictly improve\nupon the original one. Capacity results are then derived for a class of\nchannels that include two-user modulo-additive state-dependent MACs. Moreover,\nthe proposed scheme is extended to state-dependent MACs with an arbitrary\nnumber of users. Finally, output feedback is introduced and an example is\nprovided to illustrate the interplay between feedback and availability of\nstrictly causal state information in enlarging the capacity region. \n\n"}
{"id": "1012.0081", "contents": "Title: Molecular communication in fluid media: The additive inverse Gaussian\n  noise channel Abstract: We consider molecular communication, with information conveyed in the time of\nrelease of molecules. The main contribution of this paper is the development of\na theoretical foundation for such a communication system. Specifically, we\ndevelop the additive inverse Gaussian (IG) noise channel model: a channel in\nwhich the information is corrupted by noise with an inverse Gaussian\ndistribution. We show that such a channel model is appropriate for molecular\ncommunication in fluid media - when propagation between transmitter and\nreceiver is governed by Brownian motion and when there is positive drift from\ntransmitter to receiver. Taking advantage of the available literature on the IG\ndistribution, upper and lower bounds on channel capacity are developed, and a\nmaximum likelihood receiver is derived. Theory and simulation results are\npresented which show that such a channel does not have a single quality measure\nanalogous to signal-to-noise ratio in the AWGN channel. It is also shown that\nthe use of multiple molecules leads to reduced error rate in a manner akin to\ndiversity order in wireless communications. Finally, we discuss some open\nproblems in molecular communications that arise from the IG system model. \n\n"}
{"id": "1012.0602", "contents": "Title: LDPC Codes for Compressed Sensing Abstract: We present a mathematical connection between channel coding and compressed\nsensing. In particular, we link, on the one hand, \\emph{channel coding linear\nprogramming decoding (CC-LPD)}, which is a well-known relaxation o\nmaximum-likelihood channel decoding for binary linear codes, and, on the other\nhand, \\emph{compressed sensing linear programming decoding (CS-LPD)}, also\nknown as basis pursuit, which is a widely used linear programming relaxation\nfor the problem of finding the sparsest solution of an under-determined system\nof linear equations. More specifically, we establis a tight connection between\nCS-LPD based on a zero-one measurement matrix over the reals and CC-LPD of the\nbinary linear channel code that is obtained by viewing this measurement matrix\nas a binary parity-check matrix. This connection allows the translation of\nperformance guarantees from one setup to the other. The main message of this\npaper is that parity-check matrices of \"good\" channel codes can be used as\nprovably \"good\" measurement matrices under basis pursuit. In particular, we\nprovide the first deterministic construction of compressed sensing measurement\nmatrices with an order-optimal number of rows using high-girth low-density\nparity-check (LDPC) codes constructed by Gallager. \n\n"}
{"id": "1012.2363", "contents": "Title: Finding statistically significant communities in networks Abstract: Community structure is one of the main structural features of networks,\nrevealing both their internal organization and the similarity of their\nelementary units. Despite the large variety of methods proposed to detect\ncommunities in graphs, there is a big need for multi-purpose techniques, able\nto handle different types of datasets and the subtleties of community\nstructure. In this paper we present OSLOM (Order Statistics Local Optimization\nMethod), the first method capable to detect clusters in networks accounting for\nedge directions, edge weights, overlapping communities, hierarchies and\ncommunity dynamics. It is based on the local optimization of a fitness function\nexpressing the statistical significance of clusters with respect to random\nfluctuations, which is estimated with tools of Extreme and Order Statistics.\nOSLOM can be used alone or as a refinement procedure of partitions/covers\ndelivered by other techniques. We have also implemented sequential algorithms\ncombining OSLOM with other fast techniques, so that the community structure of\nvery large networks can be uncovered. Our method has a comparable performance\nas the best existing algorithms on artificial benchmark graphs. Several\napplications on real networks are shown as well. OSLOM is implemented in a\nfreely available software (http://www.oslom.org), and we believe it will be a\nvaluable tool in the analysis of networks. \n\n"}
{"id": "1012.3201", "contents": "Title: Cyclic and Quasi-Cyclic LDPC Codes on Row and Column Constrained\n  Parity-Check Matrices and Their Trapping Sets Abstract: This paper is concerned with construction and structural analysis of both\ncyclic and quasi-cyclic codes, particularly LDPC codes. It consists of three\nparts. The first part shows that a cyclic code given by a parity-check matrix\nin circulant form can be decomposed into descendant cyclic and quasi-cyclic\ncodes of various lengths and rates. Some fundamental structural properties of\nthese descendant codes are developed, including the characterizations of the\nroots of the generator polynomial of a cyclic descendant code. The second part\nof the paper shows that cyclic and quasi-cyclic descendant LDPC codes can be\nderived from cyclic finite geometry LDPC codes using the results developed in\nfirst part of the paper. This enlarges the repertoire of cyclic LDPC codes. The\nthird part of the paper analyzes the trapping sets of regular LDPC codes whose\nparity-check matrices satisfy a certain constraint on their rows and columns.\nSeveral classes of finite geometry and finite field cyclic and quasi-cyclic\nLDPC codes with large minimum weights are shown to have no harmful trapping\nsets with size smaller than their minimum weights. Consequently, their\nperformance error-floors are dominated by their minimum weights. \n\n"}
{"id": "1012.5174", "contents": "Title: SNEED: Enhancing Network Security Services Using Network Coding and\n  Joint Capacity Abstract: Traditional network security protocols depend mainly on developing\ncryptographic schemes and on using biometric methods. These have led to several\nnetwork security protocols that are unbreakable based on difficulty of solving\nuntractable mathematical problems such as factoring large integers.\n  In this paper, Security of Networks Employing Encoding and Decoding (SNEED)\nis developed to mitigate single and multiple link attacks. Network coding and\nshared capacity among the working paths are used to provide data protection and\ndata integrity against network attackers and eavesdroppers.\n  SNEED can be incorporated into various applications in on-demand TV,\nsatellite communications and multimedia security. Finally, It is shown that\nSNEED can be implemented easily where there are k edge disjoint paths between\ntwo core nodes (routers or switches) in an enterprize network. \n\n"}
{"id": "1012.5913", "contents": "Title: All liaisons are dangerous when all your friends are known to us Abstract: Online Social Networks (OSNs) are used by millions of users worldwide.\nAcademically speaking, there is little doubt about the usefulness of\ndemographic studies conducted on OSNs and, hence, methods to label unknown\nusers from small labeled samples are very useful. However, from the general\npublic point of view, this can be a serious privacy concern. Thus, both topics\nare tackled in this paper: First, a new algorithm to perform user profiling in\nsocial networks is described, and its performance is reported and discussed.\nSecondly, the experiments --conducted on information usually considered\nsensitive-- reveal that by just publicizing one's contacts privacy is at risk\nand, thus, measures to minimize privacy leaks due to social graph data mining\nare outlined. \n\n"}
{"id": "1012.6012", "contents": "Title: On the Capacity of the Discrete Memoryless Broadcast Channel with\n  Feedback Abstract: A coding scheme for the discrete memoryless broadcast channel with\n{noiseless, noisy, generalized} feedback is proposed, and the associated\nachievable region derived. The scheme is based on a block-Markov strategy\ncombining the Marton scheme and a lossy version of the Gray-Wyner scheme with\nside-information. In each block the transmitter sends fresh data and update\ninformation that allows the receivers to improve the channel outputs observed\nin the previous block. For a generalization of Dueck's broadcast channel our\nscheme achieves the noiseless-feedback capacity, which is strictly larger than\nthe no-feedback capacity. For a generalization of Blackwell's channel and when\nthe feedback is noiseless our new scheme achieves rate points that are outside\nthe no-feedback capacity region. It follows by a simple continuity argument\nthat for both these channels and when the feedback noise is sufficiently low,\nour scheme improves on the no-feedback capacity even when the feedback is\nnoisy. \n\n"}
{"id": "1101.0085", "contents": "Title: Linear Codes, Target Function Classes, and Network Computing Capacity Abstract: We study the use of linear codes for network computing in single-receiver\nnetworks with various classes of target functions of the source messages. Such\nclasses include reducible, injective, semi-injective, and linear target\nfunctions over finite fields. Computing capacity bounds and achievability are\ngiven with respect to these target function classes for network codes that use\nrouting, linear coding, or nonlinear coding. \n\n"}
{"id": "1101.0302", "contents": "Title: Mutual Information, Relative Entropy, and Estimation in the Poisson\n  Channel Abstract: Let $X$ be a non-negative random variable and let the conditional\ndistribution of a random variable $Y$, given $X$, be ${Poisson}(\\gamma \\cdot\nX)$, for a parameter $\\gamma \\geq 0$. We identify a natural loss function such\nthat: 1) The derivative of the mutual information between $X$ and $Y$ with\nrespect to $\\gamma$ is equal to the \\emph{minimum} mean loss in estimating $X$\nbased on $Y$, regardless of the distribution of $X$. 2) When $X \\sim P$ is\nestimated based on $Y$ by a mismatched estimator that would have minimized the\nexpected loss had $X \\sim Q$, the integral over all values of $\\gamma$ of the\nexcess mean loss is equal to the relative entropy between $P$ and $Q$.\n  For a continuous time setting where $X^T = \\{X_t, 0 \\leq t \\leq T \\}$ is a\nnon-negative stochastic process and the conditional law of $Y^T=\\{Y_t, 0\\le\nt\\le T\\}$, given $X^T$, is that of a non-homogeneous Poisson process with\nintensity function $\\gamma \\cdot X^T$, under the same loss function: 1) The\nminimum mean loss in \\emph{causal} filtering when $\\gamma = \\gamma_0$ is equal\nto the expected value of the minimum mean loss in \\emph{non-causal} filtering\n(smoothing) achieved with a channel whose parameter $\\gamma$ is uniformly\ndistributed between 0 and $\\gamma_0$. Bridging the two quantities is the mutual\ninformation between $X^T$ and $Y^T$. 2) This relationship between the mean\nlosses in causal and non-causal filtering holds also in the case where the\nfilters employed are mismatched, i.e., optimized assuming a law on $X^T$ which\nis not the true one. Bridging the two quantities in this case is the sum of the\nmutual information and the relative entropy between the true and the mismatched\ndistribution of $Y^T$. Thus, relative entropy quantifies the excess estimation\nloss due to mismatch in this setting.\n  These results parallel those recently found for the Gaussian channel. \n\n"}
{"id": "1101.2182", "contents": "Title: The Degrees of Freedom of Compute-and-Forward Abstract: We analyze the asymptotic behavior of compute-and-forward relay networks in\nthe regime of high signal-to-noise ratios. We consider a section of such a\nnetwork consisting of K transmitters and K relays. The aim of the relays is to\nreliably decode an invertible function of the messages sent by the\ntransmitters. An upper bound on the capacity of this system can be obtained by\nallowing full cooperation among the transmitters and among the relays,\ntransforming the network into a K times K multiple-input multiple-output (MIMO)\nchannel. The number of degrees of freedom of compute-and-forward is hence at\nmost K. In this paper, we analyze the degrees of freedom achieved by the\nlattice coding implementation of compute-and-forward proposed recently by Nazer\nand Gastpar. We show that this lattice implementation achieves at most\n2/(1+1/K)\\leq 2 degrees of freedom, thus exhibiting a very different asymptotic\nbehavior than the MIMO upper bound. This raises the question if this gap of the\nlattice implementation to the MIMO upper bound is inherent to\ncompute-and-forward in general. We answer this question in the negative by\nproposing a novel compute-and-forward implementation achieving K degrees of\nfreedom. \n\n"}
{"id": "1101.3085", "contents": "Title: Simulating Opinion Dynamics in Heterogeneous Communication Abstract: Since the information available is fundamental for our perceptions and\nopinions, we are interested in understanding the conditions allowing for a good\ninformation to be disseminated. This paper explores opinion dynamics by means\nof multi-agent based simulations when agents get informed by different sources\nof information. The scenario implemented includes three main streams of\ninformation acquisition, differing in both the contents and the perceived\nreliability of the messages spread. Agents' internal opinion is updated either\nby accessing one of the information sources, namely media and experts, or by\nexchanging information with one another. They are also endowed with cognitive\nmechanisms to accept, reject or partially consider the acquired information. We\nexpect that peer-to--peer communication and reliable information sources are\nable both to reduce biased perceptions and to inhibit information cheating,\npossibly performed by the media as stated by the agenda-setting theory. In the\npaper, after having shortly presented both the hypotheses and the model, the\nsimulation design will be specified and results will be discussed with respect\nto the hypotheses. Some considerations and ideas for future studies will\nconclude the paper. \n\n"}
{"id": "1101.4313", "contents": "Title: A weak spectral condition for the controllability of the bilinear\n  Schr\\\"odinger equation with application to the control of a rotating planar\n  molecule Abstract: In this paper we prove an approximate controllability result for the bilinear\nSchr\\\"odinger equation. This result requires less restrictive non-resonance\nhypotheses on the spectrum of the uncontrolled Schr\\\"odinger operator than\nthose present in the literature. The control operator is not required to be\nbounded and we are able to extend the controllability result to the density\nmatrices. The proof is based on fine controllability properties of the finite\ndimensional Galerkin approximations and allows to get estimates for the $L^{1}$\nnorm of the control. The general controllability result is applied to the\nproblem of controlling the rotation of a bipolar rigid molecule confined on a\nplane by means of two orthogonal external fields. \n\n"}
{"id": "1101.5716", "contents": "Title: Zero-Delay Joint Source-Channel Coding for a Bivariate Gaussian on a\n  Gaussian MAC Abstract: In this paper, delay-free, low complexity, joint source-channel coding (JSCC)\nfor transmission of two correlated Gaussian memoryless sources over a Gaussian\nMultiple Access Channel (GMAC) is considered. The main contributions of the\npaper are two distributed JSCC schemes: one discrete scheme based on nested\nscalar quantization, and one hybrid discrete-analog scheme based on a scalar\nquantizer and a linear continuous mapping. The proposed schemes show promising\nperformance which improve with increasing correlation and are robust against\nvariations in noise level. Both schemes exhibit a constant gap to the\nperformance upper bound when the channel signal-to-noise ratio gets large. \n\n"}
{"id": "1102.0651", "contents": "Title: Wikipedia information flow analysis reveals the scale-free architecture\n  of the Semantic Space Abstract: In this paper we extract the topology of the semantic space in its\nencyclopedic acception, measuring the semantic flow between the different\nentries of the largest modern encyclopedia, Wikipedia, and thus creating a\ndirected complex network of semantic flows. Notably at the percolation\nthreshold the semantic space is characterised by scale-free behaviour at\ndifferent levels of complexity and this relates the semantic space to a wide\nrange of biological, social and linguistics phenomena. In particular we find\nthat the cluster size distribution, representing the size of different semantic\nareas, is scale-free. Moreover the topology of the resulting semantic space is\nscale-free in the connectivity distribution and displays small-world\nproperties. However its statistical properties do not allow a classical\ninterpretation via a generative model based on a simple multiplicative process.\nAfter giving a detailed description and interpretation of the topological\nproperties of the semantic space, we introduce a stochastic model of\ncontent-based network, based on a copy and mutation algorithm and on the Heaps'\nlaw, that is able to capture the main statistical properties of the analysed\nsemantic space, including the Zipf's law for the word frequency distribution. \n\n"}
{"id": "1102.0987", "contents": "Title: Propagation on networks: an exact alternative perspective Abstract: By generating the specifics of a network structure only when needed\n(on-the-fly), we derive a simple stochastic process that exactly models the\ntime evolution of susceptible-infectious dynamics on finite-size networks. The\nsmall number of dynamical variables of this birth-death Markov process greatly\nsimplifies analytical calculations. We show how a dual analytical description,\ntreating large scale epidemics with a Gaussian approximations and small\noutbreaks with a branching process, provides an accurate approximation of the\ndistribution even for rather small networks. The approach also offers important\ncomputational advantages and generalizes to a vast class of systems. \n\n"}
{"id": "1102.1963", "contents": "Title: On quantum limit of optical communications: concatenated codes and\n  joint-detection receivers Abstract: When classical information is sent over a channel with quantum-state\nmodulation alphabet, such as the free-space optical (FSO) channel, attaining\nthe ultimate (Holevo) limit to channel capacity requires the receiver to make\njoint measurements over long codeword blocks. In recent work, we showed a\nreceiver for a pure-state channel that can attain the ultimate capacity by\napplying a single-shot optical (unitary) transformation on the received\ncodeword state followed by simultaneous (but separable) projective measurements\non the single-modulation-symbol state spaces. In this paper, we study the\nultimate tradeoff between photon efficiency and spectral efficiency for the FSO\nchannel. Based on our general results for the pure-state quantum channel, we\nshow some of the first concrete examples of codes and laboratory-realizable\njoint-detection optical receivers that can achieve fundamentally higher\n(superadditive) channel capacity than receivers that physically detect each\nmodulation symbol one at a time, as is done by all conventional (coherent or\ndirect-detection) optical receivers. \n\n"}
{"id": "1102.2203", "contents": "Title: Some applications of quasi-velocities in optimal control Abstract: In this paper we study optimal control problems for nonholonomic systems\ndefined on Lie algebroids by using quasi-velocities. We consider both\nkinematic, i.e. systems whose cost functional depends only on position and\nvelocities, and dynamic optimal control problems, i.e. systems whose cost\nfunctional depends also on accelerations. The formulation of the problem\ndirectly at the level of Lie algebroids turns out to be the correct framework\nto explain in detail similar results appeared recently (Maruskin and Bloch,\n2007). We also provide several examples to illustrate our construction. \n\n"}
{"id": "1102.3214", "contents": "Title: LQG Control Approach to Gaussian Broadcast Channels with Feedback Abstract: A code for communication over the k-receiver additive white Gaussian noise\nbroadcast channel with feedback is presented and analyzed using tools from the\ntheory of linear quadratic Gaussian optimal control. It is shown that the\nperformance of this code depends on the noise correlation at the receivers and\nit is related to the solution of a discrete algebraic Riccati equation. For the\ncase of independent noises, the sum rate achieved by the proposed code,\nsatisfying average power constraint P, is characterized as 1/2 log (1+P*phi),\nwhere the coefficient \"phi\" in the interval [1,k] quantifies the power gain due\nto the presence of feedback. When specialized to the case of two receivers,\nthis includes a previous result by Elia and strictly improves upon the code of\nOzarow and Leung. When the noises are correlated, the pre-log of the\nsum-capacity of the broadcast channel with feedback can be strictly greater\nthan one. It is established that for all noise covariance matrices of rank r\nthe pre-log of the sum capacity is at most k-r+1 and, conversely, there exists\na noise covariance matrix of rank r for which the proposed code achieves this\nupper bound. This generalizes a previous result by Gastpar and Wigger for the\ntwo-receiver broadcast channel. \n\n"}
{"id": "1102.4652", "contents": "Title: Optimal Quantization for Compressive Sensing under Message Passing\n  Reconstruction Abstract: We consider the optimal quantization of compressive sensing measurements\nfollowing the work on generalization of relaxed belief propagation (BP) for\narbitrary measurement channels. Relaxed BP is an iterative reconstruction\nscheme inspired by message passing algorithms on bipartite graphs. Its\nasymptotic error performance can be accurately predicted and tracked through\nthe state evolution formalism. We utilize these results to design mean-square\noptimal scalar quantizers for relaxed BP signal reconstruction and empirically\ndemonstrate the superior error performance of the resulting quantizers. \n\n"}
{"id": "1102.4825", "contents": "Title: Computing linear functions by linear coding over networks Abstract: We consider the scenario in which a set of sources generate messages in a\nnetwork and a receiver node demands an arbitrary linear function of these\nmessages. We formulate an algebraic test to determine whether an arbitrary\nnetwork can compute linear functions using linear codes. We identify a class of\nlinear functions that can be computed using linear codes in every network that\nsatisfies a natural cut-based condition. Conversely, for another class of\nlinear functions, we show that the cut-based condition does not guarantee the\nexistence of a linear coding solution. For linear functions over the binary\nfield, the two classes are complements of each other. \n\n"}
{"id": "1102.4930", "contents": "Title: Short-Message Quantize-Forward Network Coding Abstract: Recent work for single-relay channels shows that quantize-forward (QF) with\nlong-message encoding achieves the same reliable rates as compress-forward (CF)\nwith short-message encoding. It is shown that short-message QF with backward or\npipelined (sliding-window) decoding also achieves the same rates. Similarly,\nfor many relays and sources, short-message QF with backward decoding achieves\nthe same rates as long-message QF. Several practical advantages of\nshort-message encoding are pointed out, e.g., reduced delay and simpler\nmodulation. Furthermore, short-message encoding lets relays use decode-forward\n(DF) if their channel quality is good, thereby enabling multiinput,\nmulti-output (MIMO) gains that are not possible with long-message encoding.\nFinally, one may combine the advantages of long- and short-message encoding by\nhashing a long message to short messages. \n\n"}
{"id": "1103.1130", "contents": "Title: Periodic excitations of bilinear quantum systems Abstract: A well-known method of transferring the population of a quantum system from\nan eigenspace of the free Hamiltonian to another is to use a periodic control\nlaw with an angular frequency equal to the difference of the eigenvalues. For\nfinite dimensional quantum systems, the classical theory of averaging provides\na rigorous explanation of this experimentally validated result. This paper\nextends this finite dimensional result, known as the Rotating Wave\nApproximation, to infinite dimensional systems and provides explicit\nconvergence estimates. \n\n"}
{"id": "1103.1178", "contents": "Title: A Simplified Approach to Recovery Conditions for Low Rank Matrices Abstract: Recovering sparse vectors and low-rank matrices from noisy linear\nmeasurements has been the focus of much recent research. Various reconstruction\nalgorithms have been studied, including $\\ell_1$ and nuclear norm minimization\nas well as $\\ell_p$ minimization with $p<1$. These algorithms are known to\nsucceed if certain conditions on the measurement map are satisfied. Proofs of\nrobust recovery for matrices have so far been much more involved than in the\nvector case.\n  In this paper, we show how several robust classes of recovery conditions can\nbe extended from vectors to matrices in a simple and transparent way, leading\nto the best known restricted isometry and nullspace conditions for matrix\nrecovery. Our results rely on the ability to \"vectorize\" matrices through the\nuse of a key singular value inequality. \n\n"}
{"id": "1103.1343", "contents": "Title: Realization theory of discrete-time linear switched systems Abstract: The paper presents realization theory of discrete-time linear switched\nsystems. A discrete-time linear switched system is a hybrid system, such that\nthe continuous sub-system associated with each discrete state is linear. In\nthis paper we present necessary and sufficient conditions for an input-output\nmap to admit a discrete-time linear switched state-space realization. The\nconditions are formulated as finite rank conditions of a generalized\nHankel-matrix. In addition, we present a characterization of minimality of\ndiscrete-time linear switched systems in terms of reachability and\nobservable.Further, we prove that minimal realizations are unique up to\nisomorphism. We also discuss procedures for converting a linear switched system\nto a minimal one and we present an algorithm for constructing a state-space\nrepresentation from input-output data.The paper uses the theory rational formal\npower series in non-commutative variables. The latter theory was successfully\napplied to bilinear and state-affine systems in the past. \n\n"}
{"id": "1103.1365", "contents": "Title: Design of Strict Control-Lyapunov Functions for Quantum Systems with QND\n  Measurements Abstract: We consider discrete-time quantum systems subject to Quantum Non-Demolition\n(QND) measurements and controlled by an adjustable unitary evolution between\ntwo successive QND measures. In open-loop, such QND measurements provide a\nnon-deterministic preparation tool exploiting the back-action of the\nmeasurement on the quantum state. We propose here a systematic method based on\nelementary graph theory and inversion of Laplacian matrices to construct strict\ncontrol-Lyapunov functions. This yields an appropriate feedback law that\nstabilizes globally the system towards a chosen target state among the\nopen-loop stable ones, and that makes in closed-loop this preparation\ndeterministic. We illustrate such feedback laws through simulations\ncorresponding to an experimental setup with QND photon counting. \n\n"}
{"id": "1103.1401", "contents": "Title: Opportunistic Cooperation in Cognitive Femtocell Networks Abstract: We investigate opportunistic cooperation between unlicensed secondary users\nand legacy primary users in a cognitive radio network. Specifically, we\nconsider a model of a cognitive network where a secondary user can\ncooperatively transmit with the primary user in order to improve the latter's\neffective transmission rate. In return, the secondary user gets more\nopportunities for transmitting its own data when the primary user is idle. This\nkind of interaction between the primary and secondary users is different from\nthe traditional dynamic spectrum access model in which the secondary users try\nto avoid interfering with the primary users while seeking transmission\nopportunities on vacant primary channels. In our model, the secondary users\nneed to balance the desire to cooperate more (to create more transmission\nopportunities) with the need for maintaining sufficient energy levels for their\nown transmissions. Such a model is applicable in the emerging area of cognitive\nfemtocell networks. We formulate the problem of maximizing the secondary user\nthroughput subject to a time average power constraint under these settings.\nThis is a constrained Markov Decision Problem and conventional solution\ntechniques based on dynamic programming require either extensive knowledge of\nthe system dynamics or learning based approaches that suffer from large\nconvergence times. However, using the technique of Lyapunov optimization, we\ndesign a novel greedy and online control algorithm that overcomes these\nchallenges and is provably optimal. \n\n"}
{"id": "1103.1529", "contents": "Title: Algorithmic tests and randomness with respect to a class of measures Abstract: The paper considers quantitative versions of different randomness notions:\nalgorithmic test measures the amount of non-randomness (and is infinite for\nnon-random sequences). We start with computable measures on Cantor space (and\nMartin-Lof randomness), then consider uniform randomness (test is a function of\na sequence and a measure, not necessarily computable) and arbitrary\nconstructive metric spaces. We also consider tests for classes of measures, in\nparticular Bernoulli measures on Cantor space, and show how they are related to\nuniform tests and original Martin-Lof definition. We show that Hyppocratic\n(blind, oracle-free) randomness is equivalent to uniform randomness for\nmeasures in an effectively orthogonal effectively compact class. We also\nconsider the notions of sparse set and on-line randomness and show how they can\nbe expressed in our framework. \n\n"}
{"id": "1103.1732", "contents": "Title: Semi-Global Approximate stabilization of an infinite dimensional quantum\n  stochastic system Abstract: In this paper we study the semi-global (approximate) state feedback\nstabilization of an infinite dimensional quantum stochastic system towards a\ntarget state. A discrete-time Markov chain on an infinite-dimensional Hilbert\nspace is used to model the dynamics of a quantum optical cavity. We can choose\nan (unbounded) strict Lyapunov function that is minimized at each time-step in\norder to prove (weak-$\\ast$) convergence of probability measures to a final\nstate that is concentrated on the target state with (a pre-specified)\nprobability that may be made arbitrarily close to 1. The feedback parameters\nand the Lyapunov function are chosen so that the stochastic flow that describes\nthe Markov process may be shown to be tight (concentrated on a compact set with\nprobability arbitrarily close to 1). We then use Prohorov's theorem and\nproperties of the Lyapunov function to prove the desired convergence result. \n\n"}
{"id": "1103.2593", "contents": "Title: Unfolding communities in large complex networks: Combining defensive and\n  offensive label propagation for core extraction Abstract: Label propagation has proven to be a fast method for detecting communities in\nlarge complex networks. Recent developments have also improved the accuracy of\nthe approach, however, a general algorithm is still an open issue. We present\nan advanced label propagation algorithm that combines two unique strategies of\ncommunity formation, namely, defensive preservation and offensive expansion of\ncommunities. Two strategies are combined in a hierarchical manner, to\nrecursively extract the core of the network, and to identify whisker\ncommunities. The algorithm was evaluated on two classes of benchmark networks\nwith planted partition and on almost 25 real-world networks ranging from\nnetworks with tens of nodes to networks with several tens of millions of edges.\nIt is shown to be comparable to the current state-of-the-art community\ndetection algorithms and superior to all previous label propagation algorithms,\nwith comparable time complexity. In particular, analysis on real-world networks\nhas proven that the algorithm has almost linear complexity,\n$\\mathcal{O}(m^{1.19})$, and scales even better than basic label propagation\nalgorithm ($m$ is the number of edges in the network). \n\n"}
{"id": "1103.2596", "contents": "Title: Unfolding network communities by combining defensive and offensive label\n  propagation Abstract: Label propagation has proven to be a fast method for detecting communities in\ncomplex networks. Recent work has also improved the accuracy and stability of\nthe basic algorithm, however, a general approach is still an open issue. We\npropose different label propagation algorithms that convey two unique\nstrategies of community formation, namely, defensive preservation and offensive\nexpansion of communities. Furthermore, the strategies are combined in an\nadvanced label propagation algorithm that retains the advantages of both\napproaches; and are enhanced with hierarchical community extraction, prominent\nfor the use on larger networks. The proposed algorithms were empirically\nevaluated on different benchmarks networks with planted partition and on over\n30 real-world networks of various types and sizes. The results confirm the\nadequacy of the propositions and give promising grounds for future analysis of\n(large) complex networks. Nevertheless, the main contribution of this work is\nin showing that different types of networks (with different topological\nproperties) favor different strategies of community formation. \n\n"}
{"id": "1103.2897", "contents": "Title: Constructing test instances for Basis Pursuit Denoising Abstract: The number of available algorithms for the so-called Basis Pursuit Denoising\nproblem (or the related LASSO-problem) is large and keeps growing. Similarly,\nthe number of experiments to evaluate and compare these algorithms on different\ninstances is growing.\n  In this note, we present a method to produce instances with exact solutions\nwhich is based on a simple observation which is related to the so called source\ncondition from sparse regularization. \n\n"}
{"id": "1103.3843", "contents": "Title: A Simple Sampling Method for Metric Measure Spaces Abstract: We introduce a new, simple metric method of sampling metric measure spaces,\nbased on a well-known \"snowflakeing operator\" and we show that, as a\nconsequence of a classical result of Assouad, the sampling of doubling metric\nspaces is bilipschitz equivalent to that of subsets of some $\\mathbb{R}^N$.\nMoreover, we compare this new method with two other approaches, in particular\nto one that represents a direct application of our triangulation method of\nmetric measure spaces satisfying a generalized Ricci curvature condition. \n\n"}
{"id": "1103.4438", "contents": "Title: Anytime Reliable Codes for Stabilizing Plants over Erasure Channels Abstract: The problem of stabilizing an unstable plant over a noisy communication link\nis an increasingly important one that arises in problems of distributed control\nand networked control systems. Although the work of Schulman and Sahai over the\npast two decades, and their development of the notions of \"tree codes\" and\n\"anytime capacity\", provides the theoretical framework for studying such\nproblems, there has been scant practical progress in this area because explicit\nconstructions of tree codes with efficient encoding and decoding did not exist.\nTo stabilize an unstable plant driven by bounded noise over a noisy channel one\nneeds real-time encoding and real-time decoding and a reliability which\nincreases exponentially with delay, which is what tree codes guarantee. We\nprove the existence of linear tree codes with high probability and, for erasure\nchannels, give an explicit construction with an expected encoding and decoding\ncomplexity that is constant per time instant. We give sufficient conditions on\nthe rate and reliability required of the tree codes to stabilize vector plants\nand argue that they are asymptotically tight. This work takes a major step\ntowards controlling plants over noisy channels, and we demonstrate the efficacy\nof the method through several examples. \n\n"}
{"id": "1103.4787", "contents": "Title: Energy Management Policies for Energy-Neutral Source-Channel Coding Abstract: In cyber-physical systems where sensors measure the temporal evolution of a\ngiven phenomenon of interest and radio communication takes place over short\ndistances, the energy spent for source acquisition and compression may be\ncomparable with that used for transmission. Additionally, in order to avoid\nlimited lifetime issues, sensors may be powered via energy harvesting and thus\ncollect all the energy they need from the environment. This work addresses the\nproblem of energy allocation over source acquisition/compression and\ntransmission for energy-harvesting sensors. At first, focusing on a\nsingle-sensor, energy management policies are identified that guarantee a\nmaximal average distortion while at the same time ensuring the stability of the\nqueue connecting source and channel encoders. It is shown that the identified\nclass of policies is optimal in the sense that it stabilizes the queue whenever\nthis is feasible by any other technique that satisfies the same average\ndistortion constraint. Moreover, this class of policies performs an independent\nresource optimization for the source and channel encoders. Analog transmission\ntechniques as well as suboptimal strategies that do not use the energy buffer\n(battery) or use it only for adapting either source or channel encoder energy\nallocation are also studied for performance comparison. The problem of\noptimizing the desired trade-off between average distortion and delay is then\nformulated and solved via dynamic programming tools. Finally, a system with\nmultiple sensors is considered and time-division scheduling strategies are\nderived that are able to maintain the stability of all data queues and to meet\nthe average distortion constraints at all sensors whenever it is feasible. \n\n"}
{"id": "1103.5258", "contents": "Title: Controllability of rolling without twisting or slipping in higher\n  dimensions Abstract: We describe how the dynamical system of rolling two $n$-dimensional\nconnected, oriented Riemannian manifolds $M$ and $\\hat M$ without twisting or\nslipping, can be lifted to a nonholonomic system of elements in the product of\nthe oriented orthonormal frame bundles belonging to the manifolds. By\nconsidering the lifted problem and using properties of the elements in the\nrespective principal Ehresmann connections, we obtain sufficient conditions for\nthe local controllability of the system in terms of the curvature tensors and\nthe sectional curvatures of the manifolds involved. We also give some results\nfor the particular cases when $M$ and $\\hat M$ are locally symmetric or\ncomplete. \n\n"}
{"id": "1103.5431", "contents": "Title: Identification of Nonlinear Systems with Stable Limit Cycles via Convex\n  Optimization Abstract: We propose a convex optimization procedure for black-box identification of\nnonlinear state-space models for systems that exhibit stable limit cycles\n(unforced periodic solutions). It extends the \"robust identification error\"\nframework in which a convex upper bound on simulation error is optimized to fit\nrational polynomial models with a strong stability guarantee. In this work, we\nrelax the stability constraint using the concepts of transverse dynamics and\norbital stability, thus allowing systems with autonomous oscillations to be\nidentified. The resulting optimization problem is convex, and can be formulated\nas a semidefinite program. A simulation-error bound is proved without assuming\nthat the true system is in the model class, or that the number of measurements\ngoes to infinity. Conditions which guarantee existence of a unique limit cycle\nof the model are proved and related to the model class that we search over. The\nmethod is illustrated by identifying a high-fidelity model from experimental\nrecordings of a live rat hippocampal neuron in culture. \n\n"}
{"id": "1104.0599", "contents": "Title: Near concavity of the growth rate for coupled LDPC chains Abstract: Convolutional Low-Density-Parity-Check (LDPC) ensembles have excellent\nperformance. Their iterative threshold increases with their average degree, or\nwith the size of the coupling window in randomized constructions. In the later\ncase, as the window size grows, the Belief Propagation (BP) threshold attains\nthe maximum-a-posteriori (MAP) threshold of the underlying ensemble. In this\ncontribution we show that a similar phenomenon happens for the growth rate of\ncoupled ensembles. Loosely speaking, we observe that as the coupling strength\ngrows, the growth rate of the coupled ensemble comes close to the concave hull\nof the underlying ensemble's growth rate. For ensembles randomly coupled across\na window the growth rate actually tends to the concave hull of the underlying\none as the window size increases. Our observations are supported by the\ncalculations of the combinatorial growth rate, and that of the growth rate\nderived from the replica method. The observed concavity is a general feature of\ncoupled mean field graphical models and is already present at the level of\ncoupled Curie-Weiss models. There, the canonical free energy of the coupled\nsystem tends to the concave hull of the underlying one. As we explain, the\nbehavior of the growth rate of coupled ensembles is exactly analogous. \n\n"}
{"id": "1104.3179", "contents": "Title: Heterogeneity and Allometric Growth of Human Collaborative Tagging\n  Behavior Abstract: Allometric growth is found in many tagging systems online. That is, the\nnumber of new tags (T) is a power law function of the active population (P), or\nT P^gamma (gamma!=1). According to previous studies, it is the heterogeneity in\nindividual tagging behavior that gives rise to allometric growth. These studies\nconsider the power-law distribution model with an exponent beta, regarding\n1/beta as an index for heterogeneity. However, they did not discuss whether\npower-law is the only distribution that leads to allometric growth, or\nequivalently, whether the positive correlation between heterogeneity and\nallometric growth holds in systems of distributions other than power-law. In\nthis paper, the authors systematically examine the growth pattern of systems of\nsix different distributions, and find that both power-law distribution and\nlog-normal distribution lead to allometric growth. Furthermore, by introducing\nShannon entropy as an indicator for heterogeneity instead of 1/beta, the\nauthors confirm that the positive relationship between heterogeneity and\nallometric growth exists in both cases of power-law and log-normal\ndistributions. \n\n"}
{"id": "1104.3833", "contents": "Title: Noise Folding in Compressed Sensing Abstract: The literature on compressed sensing has focused almost entirely on settings\nwhere the signal is noiseless and the measurements are contaminated by noise.\nIn practice, however, the signal itself is often subject to random noise prior\nto measurement. We briefly study this setting and show that, for the vast\nmajority of measurement schemes employed in compressed sensing, the two models\nare equivalent with the important difference that the signal-to-noise ratio is\ndivided by a factor proportional to p/n, where p is the dimension of the signal\nand n is the number of observations. Since p/n is often large, this leads to\nnoise folding which can have a severe impact on the SNR. \n\n"}
{"id": "1104.5183", "contents": "Title: Direct search methods for an open problem of optimization in systems and\n  control Abstract: The motivation of this work is to illustrate the efficiency of some often\noverlooked alternatives to deal with optimization problems in systems and\ncontrol. In particular, we will consider a problem for which an iterative\nlinear matrix inequality algorithm (ILMI) has been proposed recently. As it\noften happens, this algorithm does not have guaranteed global convergence and\ntherefore many methods may perform better. We will put forward how some general\npurpose optimization solvers are more suited than the ILMI. This is illustrated\nwith the considered problem and example, but the general observations remain\nvalid for many similar situations in the literature. \n\n"}
{"id": "1104.5186", "contents": "Title: Finding Dense Clusters via \"Low Rank + Sparse\" Decomposition Abstract: Finding \"densely connected clusters\" in a graph is in general an important\nand well studied problem in the literature \\cite{Schaeffer}. It has various\napplications in pattern recognition, social networking and data mining\n\\cite{Duda,Mishra}. Recently, Ames and Vavasis have suggested a novel method\nfor finding cliques in a graph by using convex optimization over the adjacency\nmatrix of the graph \\cite{Ames, Ames2}. Also, there has been recent advances in\ndecomposing a given matrix into its \"low rank\" and \"sparse\" components\n\\cite{Candes, Chandra}. In this paper, inspired by these results, we view\n\"densely connected clusters\" as imperfect cliques, where imperfections\ncorrespond missing edges, which are relatively sparse. We analyze the problem\nin a probabilistic setting and aim to detect disjointly planted clusters. Our\nmain result basically suggests that, one can find \\emph{dense} clusters in a\ngraph, as long as the clusters are sufficiently large. We conclude by\ndiscussing possible extensions and future research directions. \n\n"}
{"id": "1105.0442", "contents": "Title: On State Estimation with Bad Data Detection Abstract: In this paper, we consider the problem of state estimation through\nobservations possibly corrupted with both bad data and additive observation\nnoises. A mixed $\\ell_1$ and $\\ell_2$ convex programming is used to separate\nboth sparse bad data and additive noises from the observations. Through using\nthe almost Euclidean property for a linear subspace, we derive a new\nperformance bound for the state estimation error under sparse bad data and\nadditive observation noises. Our main contribution is to provide sharp bounds\non the almost Euclidean property of a linear subspace, using the\n\"escape-through-a-mesh\" theorem from geometric functional analysis. We also\npropose and numerically evaluate an iterative convex programming approach to\nperforming bad data detections in nonlinear electrical power networks problems. \n\n"}
{"id": "1105.1058", "contents": "Title: Formal vs self-organised knowledge systems: a network approach Abstract: In this work we consider the topological analysis of symbolic formal systems\nin the framework of network theory. In particular we analyse the network\nextracted by Principia Mathematica of B. Russell and A.N. Whitehead, where the\nvertices are the statements and two statements are connected with a directed\nlink if one statement is used to demonstrate the other one. We compare the\nobtained network with other directed acyclic graphs, such as a scientific\ncitation network and a stochastic model. We also introduce a novel topological\nordering for directed acyclic graphs and we discuss its properties in respect\nto the classical one. The main result is the observation that formal systems of\nknowledge topologically behave similarly to self-organised systems. \n\n"}
{"id": "1105.2311", "contents": "Title: An Achievable Rate Region for the Broadcast Channel with Feedback Abstract: A single-letter achievable rate region is proposed for the two-receiver\ndiscrete memoryless broadcast channel with generalized feedback. The coding\nstrategy involves block-Markov superposition coding, using Marton's coding\nscheme for the broadcast channel without feedback as the starting point. If the\nmessage rates in the Marton scheme are too high to be decoded at the end of a\nblock, each receiver is left with a list of messages compatible with its\noutput. Resolution information is sent in the following block to enable each\nreceiver to resolve its list. The key observation is that the resolution\ninformation of the first receiver is correlated with that of the second. This\ncorrelated information is efficiently transmitted via joint source-channel\ncoding, using ideas similar to the Han-Costa coding scheme. Using the result,\nwe obtain an achievable rate region for the stochastically degraded AWGN\nbroadcast channel with noisy feedback from only one receiver. It is shown that\nthis region is strictly larger than the no-feedback capacity region. \n\n"}
{"id": "1105.4005", "contents": "Title: Link prediction in complex networks: a local na\\\"{\\i}ve Bayes model Abstract: Common-neighbor-based method is simple yet effective to predict missing\nlinks, which assume that two nodes are more likely to be connected if they have\nmore common neighbors. In such method, each common neighbor of two nodes\ncontributes equally to the connection likelihood. In this Letter, we argue that\ndifferent common neighbors may play different roles and thus lead to different\ncontributions, and propose a local na\\\"{\\i}ve Bayes model accordingly.\nExtensive experiments were carried out on eight real networks. Compared with\nthe common-neighbor-based methods, the present method can provide more accurate\npredictions. Finally, we gave a detailed case study on the US air\ntransportation network. \n\n"}
{"id": "1105.4965", "contents": "Title: Evolution of scaling emergence in large-scale spatial epidemic spreading Abstract: Background: Zipf's law and Heaps' law are two representatives of the scaling\nconcepts, which play a significant role in the study of complexity science. The\ncoexistence of the Zipf's law and the Heaps' law motivates different\nunderstandings on the dependence between these two scalings, which is still\nhardly been clarified.\n  Methodology/Principal Findings: In this article, we observe an evolution\nprocess of the scalings: the Zipf's law and the Heaps' law are naturally shaped\nto coexist at the initial time, while the crossover comes with the emergence of\ntheir inconsistency at the larger time before reaching a stable state, where\nthe Heaps' law still exists with the disappearance of strict Zipf's law. Such\nfindings are illustrated with a scenario of large-scale spatial epidemic\nspreading, and the empirical results of pandemic disease support a universal\nanalysis of the relation between the two laws regardless of the biological\ndetails of disease. Employing the United States(U.S.) domestic air\ntransportation and demographic data to construct a metapopulation model for\nsimulating the pandemic spread at the U.S. country level, we uncover that the\nbroad heterogeneity of the infrastructure plays a key role in the evolution of\nscaling emergence.\n  Conclusions/Significance: The analyses of large-scale spatial epidemic\nspreading help understand the temporal evolution of scalings, indicating the\ncoexistence of the Zipf's law and the Heaps' law depends on the collective\ndynamics of epidemic processes, and the heterogeneity of epidemic spread\nindicates the significance of performing targeted containment strategies at the\nearly time of a pandemic disease. \n\n"}
{"id": "1105.5344", "contents": "Title: Partitioning Breaks Communities Abstract: Considering a clique as a conservative definition of community structure, we\nexamine how graph partitioning algorithms interact with cliques. Many popular\ncommunity-finding algorithms partition the entire graph into non-overlapping\ncommunities. We show that on a wide range of empirical networks, from different\ndomains, significant numbers of cliques are split across the separate\npartitions produced by these algorithms. We then examine the largest connected\ncomponent of the subgraph formed by retaining only edges in cliques, and apply\npartitioning strategies that explicitly minimise the number of cliques split.\nWe further examine several modern overlapping community finding algorithms, in\nterms of the interaction between cliques and the communities they find, and in\nterms of the global overlap of the sets of communities they find. We conclude\nthat, due to the connectedness of many networks, any community finding\nalgorithm that produces partitions must fail to find at least some significant\nstructures. Moreover, contrary to traditional intuition, in some empirical\nnetworks, strong ties and cliques frequently do cross community boundaries;\nmuch community structure is fundamentally overlapping and unpartitionable in\nnature. \n\n"}
{"id": "1106.2819", "contents": "Title: Optimizing Constellations for Single-Subcarrier Intensity-Modulated\n  Optical Systems Abstract: We optimize modulation formats for the additive white Gaussian noise channel\nwith nonnegative input, also known as the intensity-modulated direct-detection\nchannel, with and without confining them to a lattice structure. Our\noptimization criteria are the average electrical, average optical, and peak\npower. The nonnegative constraint on the input to the channel is translated\ninto a conical constraint in signal space, and modulation formats are designed\nby sphere packing inside this cone. Some dense packings are found, which yield\nmore power-efficient modulation formats than previously known. For example, at\na spectral efficiency of 1.5 bit/s/Hz, the modulation format optimized for\naverage electrical power has a 2.55 dB average electrical power gain over the\nbest known format to achieve a symbol error rate of 10^-6. The corresponding\ngains for formats optimized for average and peak optical power are 1.35 and\n1.72 dB, respectively. Using modulation formats optimized for peak power in\naverage-power limited systems results in a smaller power penalty than when\nusing formats optimized for average power in peak-power limited systems. We\nalso evaluate the modulation formats in terms of their mutual information to\npredict their performance in the presence of capacity-achieving error-\ncorrecting codes, and finally show numerically and analytically that the\noptimal modulation formats for reliable transmission in the wideband regime\nhave only one nonzero point. \n\n"}
{"id": "1106.3276", "contents": "Title: Sufficient Conditions for Low-rank Matrix Recovery, Translated from\n  Sparse Signal Recovery Abstract: The low-rank matrix recovery (LMR) is a rank minimization problem subject to\nlinear equality constraints, and it arises in many fields such as signal and\nimage processing, statistics, computer vision, system identification and\ncontrol. This class of optimization problems is $\\N\\P$-hard and a popular\napproach replaces the rank function with the nuclear norm of the matrix\nvariable. In this paper, we extend the concept of $s$-goodness for a sensing\nmatrix in sparse signal recovery (proposed by Juditsky and Nemirovski [Math\nProgram, 2011]) to linear transformations in LMR. Then, we give\ncharacterizations of $s$-goodness in the context of LMR. Using the two\ncharacteristic $s$-goodness constants, ${\\gamma}_s$ and $\\hat{\\gamma}_s$, of a\nlinear transformation, not only do we derive necessary and sufficient\nconditions for a linear transformation to be $s$-good, but also provide\nsufficient conditions for exact and stable $s$-rank matrix recovery via the\nnuclear norm minimization under mild assumptions. Moreover, we give computable\nupper bounds for one of the $s$-goodness characteristics which leads to\nverifiable sufficient conditions for exact low-rank matrix recovery. \n\n"}
{"id": "1106.5301", "contents": "Title: Optimizing and controlling functions of complex networks by manipulating\n  rich-club connections Abstract: Traditionally, there is no evidence suggesting that there are strong ties\nbetween the rich-club property and the function of complex networks. In this\nstudy, we find that whether a very small portion of rich nodes connected to\neach other or not can strongly affect the frequency of occurrence of basic\nbuilding blocks (motif) within networks, and therefore the function, of a\nheterogeneous network. Conversely whether a homogeneous network has a rich-club\nproperty or not generally has no significant effect on its structure and\nfunction. These findings open the possibility to optimize and control the\nfunction of complex networks by manipulating rich-club connections.\nFurthermore, based on the subgraph ratio profile, we develop a more rigorous\napproach to judge whether a network has a rich-club or not. The new method does\nnot calculate how many links there are among rich nodes but depends on how the\nlinks among rich nodes can affect the overall structure as well as function of\na given network. These results can also help us to understand the evolution of\ndynamical networks and design new models for characterizing real-world\nnetworks. \n\n"}
{"id": "1106.5413", "contents": "Title: Accelerated Linearized Bregman Method Abstract: In this paper, we propose and analyze an accelerated linearized Bregman (ALB)\nmethod for solving the basis pursuit and related sparse optimization problems.\nThis accelerated algorithm is based on the fact that the linearized Bregman\n(LB) algorithm is equivalent to a gradient descent method applied to a certain\ndual formulation. We show that the LB method requires $O(1/\\epsilon)$\niterations to obtain an $\\epsilon$-optimal solution and the ALB algorithm\nreduces this iteration complexity to $O(1/\\sqrt{\\epsilon})$ while requiring\nalmost the same computational effort on each iteration. Numerical results on\ncompressed sensing and matrix completion problems are presented that\ndemonstrate that the ALB method can be significantly faster than the LB method. \n\n"}
{"id": "1106.5714", "contents": "Title: Non-parametric change-point detection using string matching algorithms Abstract: Given the output of a data source taking values in a finite alphabet, we wish\nto detect change-points, that is times when the statistical properties of the\nsource change. Motivated by ideas of match lengths in information theory, we\nintroduce a novel non-parametric estimator which we call CRECHE (CRossings\nEnumeration CHange Estimator). We present simulation evidence that this\nestimator performs well, both for simulated sources and for real data formed by\nconcatenating text sources. For example, we show that we can accurately detect\nthe point at which a source changes from a Markov chain to an IID source with\nthe same stationary distribution. Our estimator requires no assumptions about\nthe form of the source distribution, and avoids the need to estimate its\nprobabilities. Further, we establish consistency of the CRECHE estimator under\na related toy model, by establishing a fluid limit and using martingale\narguments. \n\n"}
{"id": "1106.5930", "contents": "Title: An Algorithm for Classification of Binary Self-Dual Codes Abstract: An efficient algorithm for classification of binary self-dual codes is\npresented. As an application, a complete classification of the self-dual codes\nof length 38 is given. \n\n"}
{"id": "1107.0429", "contents": "Title: Small world yields the most effective information spreading Abstract: Spreading dynamics of information and diseases are usually analyzed by using\na unified framework and analogous models. In this paper, we propose a model to\nemphasize the essential difference between information spreading and epidemic\nspreading, where the memory effects, the social reinforcement and the\nnon-redundancy of contacts are taken into account. Under certain conditions,\nthe information spreads faster and broader in regular networks than in random\nnetworks, which to some extent supports the recent experimental observation of\nspreading in online society [D. Centola, Science {\\bf 329}, 1194 (2010)]. At\nthe same time, simulation result indicates that the random networks tend to be\nfavorable for effective spreading when the network size increases. This\nchallenges the validity of the above-mentioned experiment for large-scale\nsystems. More significantly, we show that the spreading effectiveness can be\nsharply enhanced by introducing a little randomness into the regular structure,\nnamely the small-world networks yield the most effective information spreading.\nOur work provides insights to the understanding of the role of local clustering\nin information spreading. \n\n"}
{"id": "1107.1900", "contents": "Title: Behavior patterns of online users and the effect on information\n  filtering Abstract: Understanding the structure and evolution of web-based user-object bipartite\nnetworks is an important task since they play a fundamental role in online\ninformation filtering. In this paper, we focus on investigating the patterns of\nonline users' behavior and the effect on recommendation process. Empirical\nanalysis on the e-commercial systems show that users have significant taste\ndiversity and their interests for niche items highly overlap. Additionally,\nrecommendation process are investigated on both the real networks and the\nreshuffled networks in which real users' behavior patterns can be gradually\ndestroyed. Our results shows that the performance of personalized\nrecommendation methods is strongly related to the real network structure.\nDetail study on each item shows that recommendation accuracy for hot items is\nalmost maximum and quite robust to the reshuffling process. However, niche\nitems cannot be accurately recommended after removing users' behavior patterns.\nOur work also is meaningful in practical sense since it reveals an effective\ndirection to improve the accuracy and the robustness of the existing\nrecommender systems. \n\n"}
{"id": "1107.4652", "contents": "Title: On the Achievability of Interference Alignment for Three-Cell Constant\n  Cellular Interfering Networks Abstract: For a three-cell constant cellular interfering network, a new property of\nalignment is identified, i.e., interference alignment (IA) solution obtained in\nan user-cooperation scenario can also be applied in a non-cooperation\nenvironment. By using this property, an algorithm is proposed by jointly\ndesigning transmit and receive beamforming matrices. Analysis and numerical\nresults show that more degree of freedom (DoF) can be achieved compared with\nconventional schemes in most cases. \n\n"}
{"id": "1107.5646", "contents": "Title: Temporal motifs in time-dependent networks Abstract: Temporal networks are commonly used to represent systems where connections\nbetween elements are active only for restricted periods of time, such as\nnetworks of telecommunication, neural signal processing, biochemical reactions\nand human social interactions. We introduce the framework of temporal motifs to\nstudy the mesoscale topological-temporal structure of temporal networks in\nwhich the events of nodes do not overlap in time. Temporal motifs are classes\nof similar event sequences, where the similarity refers not only to topology\nbut also to the temporal order of the events. We provide a mapping from event\nsequences to colored directed graphs that enables an efficient algorithm for\nidentifying temporal motifs. We discuss some aspects of temporal motifs,\nincluding causality and null models, and present basic statistics of temporal\nmotifs in a large mobile call network. \n\n"}
{"id": "1107.5841", "contents": "Title: Sequential Convex Programming Methods for Solving Nonlinear Optimization\n  Problems with DC constraints Abstract: This paper investigates the relation between sequential convex programming\n(SCP) as, e.g., defined in [24] and DC (difference of two convex functions)\nprogramming. We first present an SCP algorithm for solving nonlinear\noptimization problems with DC constraints and prove its convergence. Then we\ncombine the proposed algorithm with a relaxation technique to handle\ninconsistent linearizations. Numerical tests are performed to investigate the\nbehaviour of the class of algorithms. \n\n"}
{"id": "1108.3130", "contents": "Title: Localizations on Complex Networks Abstract: We study the structural characteristics of complex networks using the\nrepresentative eigenvectors of the adjacent matrix. The probability\ndistribution function of the components of the representative eigenvectors are\nproposed to describe the localization on networks where the Euclidean distance\nis invalid. Several quantities are used to describe the localization properties\nof the representative states, such as the participation ratio, the structural\nentropy, and the probability distribution function of the nearest neighbor\nlevel spacings for spectra of complex networks. Whole-cell networks in the real\nworld and the Watts-Strogatz small-world and Barabasi-Albert scale-free\nnetworks are considered. The networks have nontrivial localization properties\ndue to the nontrivial topological structures. It is found that the\nascending-order-ranked series of the occurrence probabilities at the nodes\nbehave generally multifractally. This characteristic can be used as a\nstructural measure of complex networks. \n\n"}
{"id": "1109.2766", "contents": "Title: Secure Broadcasting With Side-Information Abstract: In this paper, we derive information-theoretic performance limits for secure\nand reliable communications over the general two-user discrete memoryless\nbroadcast channel with side-information at the transmitter. The sender wishes\nto broadcast two independent messages to two receivers, under the constraint\nthat each message should be kept confidential from the unintended receiver.\nFurthermore, the encoder has side-information - for example, fading in the\nwireless medium, interference caused by neighboring nodes in the network, etc.\n- provided to it in a noncausal manner, i.e., before the process of\ntransmission. We derive an inner bound on the capacity region of this channel,\nby employing an extension of Marton's coding technique used for the classical\ntwo-user broadcast channel, in conjunction with a stochastic encoder to satisfy\nconfidentiality constraints. Based on previously known results, we discuss a\nprocedure to present a schematic of the achievable rate region. The\nrate-penalties for dealing with side-information and confidentiality\nconstraints make the achievable region for this channel strictly smaller than\nthe rate regions of those channels where one or both of these constraints are\nrelaxed. \n\n"}
{"id": "1109.3510", "contents": "Title: Diversity Analysis of Bit-Interleaved Coded Multiple Beamforming with\n  Orthogonal Frequency Division Multiplexing Abstract: For broadband wireless communication systems, Orthogonal Frequency Division\nMultiplexing (OFDM) has been combined with Multi-Input Multi-Output (MIMO)\ntechniques. Bit-Interleaved Coded Multiple Beamforming (BICMB) can achieve both\nspatial diversity and spatial multiplexing for flat fading MIMO channels. For\nfrequency selective fading MIMO channels, BICMB with OFDM (BICMB-OFDM) can be\napplied to achieve both spatial diversity and multipath diversity, making it an\nimportant technique. However, analyzing the diversity of BICMB-OFDM is a\nchallenging problem. In this paper, the diversity analysis of BICMB-OFDM is\ncarried out. First, the maximum achievable diversity is derived and a full\ndiversity condition RcSL <= 1 is proved, where Rc, S, and L are the code rate,\nthe number of parallel steams transmitted at each subcarrier, and the number of\nchannel taps, respectively. Then, the performance degradation due to the\ncorrelation among subcarriers is investigated. Finally, the subcarrier grouping\ntechnique is employed to combat the performance degradation and provide\nmulti-user compatibility. \n\n"}
{"id": "1109.3714", "contents": "Title: High-dimensional regression with noisy and missing data: Provable\n  guarantees with nonconvexity Abstract: Although the standard formulations of prediction problems involve\nfully-observed and noiseless data drawn in an i.i.d. manner, many applications\ninvolve noisy and/or missing data, possibly involving dependence, as well. We\nstudy these issues in the context of high-dimensional sparse linear regression,\nand propose novel estimators for the cases of noisy, missing and/or dependent\ndata. Many standard approaches to noisy or missing data, such as those using\nthe EM algorithm, lead to optimization problems that are inherently nonconvex,\nand it is difficult to establish theoretical guarantees on practical\nalgorithms. While our approach also involves optimizing nonconvex programs, we\nare able to both analyze the statistical error associated with any global\noptimum, and more surprisingly, to prove that a simple algorithm based on\nprojected gradient descent will converge in polynomial time to a small\nneighborhood of the set of all global minimizers. On the statistical side, we\nprovide nonasymptotic bounds that hold with high probability for the cases of\nnoisy, missing and/or dependent data. On the computational side, we prove that\nunder the same types of conditions required for statistical consistency, the\nprojected gradient descent algorithm is guaranteed to converge at a geometric\nrate to a near-global minimizer. We illustrate these theoretical predictions\nwith simulations, showing close agreement with the predicted scalings. \n\n"}
{"id": "1109.3841", "contents": "Title: Limits on the Benefits of Energy Storage for Renewable Integration Abstract: The high variability of renewable energy resources presents significant\nchallenges to the operation of the electric power grid. Conventional generators\ncan be used to mitigate this variability but are costly to operate and produce\ncarbon emissions. Energy storage provides a more environmentally friendly\nalternative, but is costly to deploy in large amounts. This paper studies the\nlimits on the benefits of energy storage to renewable energy: How effective is\nstorage at mitigating the adverse effects of renewable energy variability? How\nmuch storage is needed? What are the optimal control policies for operating\nstorage? To provide answers to these questions, we first formulate the power\nflow in a single-bus power system with storage as an infinite horizon\nstochastic program. We find the optimal policies for arbitrary net renewable\ngeneration process when the cost function is the average conventional\ngeneration (environmental cost) and when it is the average loss of load\nprobability (reliability cost). We obtain more refined results by considering\nthe multi-timescale operation of the power system. We view the power flow in\neach timescale as the superposition of a predicted (deterministic) component\nand an prediction error (residual) component and formulate the residual power\nflow problem as an infinite horizon dynamic program. Assuming that the net\ngeneration prediction error is an IID process, we quantify the asymptotic\nbenefits of storage. With the additional assumption of Laplace distributed\nprediction error, we obtain closed form expressions for the stationary\ndistribution of storage and conventional generation. Finally, we propose a\ntwo-threshold policy that trades off conventional generation saving with loss\nof load probability. We illustrate our results and corroborate the IID and\nLaplace assumptions numerically using datasets from CAISO and NREL. \n\n"}
{"id": "1109.4457", "contents": "Title: Nonlinear Robust Tracking Control of a Quadrotor UAV on SE(3) Abstract: This paper provides nonlinear tracking control systems for a quadrotor\nunmanned aerial vehicle (UAV) that are robust to bounded uncertainties. A\nmathematical model of a quadrotor UAV is defined on the special Euclidean\ngroup, and nonlinear output-tracking controllers are developed to follow (1) an\nattitude command, and (2) a position command for the vehicle center of mass.\nThe controlled system has the desirable properties that the tracking errors are\nuniformly ultimately bounded, and the size of the ultimate bound can be\narbitrarily reduced by control system parameters. Numerical examples\nillustrating complex maneuvers are provided. \n\n"}
{"id": "1109.5415", "contents": "Title: Shannon Meets Nyquist: Capacity of Sampled Gaussian Channels Abstract: We explore two fundamental questions at the intersection of sampling theory\nand information theory: how channel capacity is affected by sampling below the\nchannel's Nyquist rate, and what sub-Nyquist sampling strategy should be\nemployed to maximize capacity. In particular, we derive the capacity of sampled\nanalog channels for three prevalent sampling strategies: sampling with\nfiltering, sampling with filter banks, and sampling with modulation and filter\nbanks. These sampling mechanisms subsume most nonuniform sampling techniques\napplied in practice. Our analyses illuminate interesting connections between\nunder-sampled channels and multiple-input multiple-output channels. The optimal\nsampling structures are shown to extract out the frequencies with the highest\nSNR from each aliased frequency set, while suppressing aliasing and out-of-band\nnoise. We also highlight connections between undersampled channel capacity and\nminimum mean-squared error (MSE) estimation from sampled data. In particular,\nwe show that the filters maximizing capacity and the ones minimizing MSE are\nequivalent under both filtering and filter-bank sampling strategies. These\nresults demonstrate the effect upon channel capacity of sub-Nyquist sampling\ntechniques, and characterize the tradeoff between information rate and sampling\nrate. \n\n"}
{"id": "1110.3854", "contents": "Title: Consistency of community detection in networks under degree-corrected\n  stochastic block models Abstract: Community detection is a fundamental problem in network analysis, with\napplications in many diverse areas. The stochastic block model is a common tool\nfor model-based community detection, and asymptotic tools for checking\nconsistency of community detection under the block model have been recently\ndeveloped. However, the block model is limited by its assumption that all nodes\nwithin a community are stochastically equivalent, and provides a poor fit to\nnetworks with hubs or highly varying node degrees within communities, which are\ncommon in practice. The degree-corrected stochastic block model was proposed to\naddress this shortcoming and allows variation in node degrees within a\ncommunity while preserving the overall block community structure. In this paper\nwe establish general theory for checking consistency of community detection\nunder the degree-corrected stochastic block model and compare several community\ndetection criteria under both the standard and the degree-corrected models. We\nshow which criteria are consistent under which models and constraints, as well\nas compare their relative performance in practice. We find that methods based\non the degree-corrected block model, which includes the standard block model as\na special case, are consistent under a wider class of models and that\nmodularity-type methods require parameter constraints for consistency, whereas\nlikelihood-based methods do not. On the other hand, in practice, the degree\ncorrection involves estimating many more parameters, and empirically we find it\nis only worth doing if the node degrees within communities are indeed highly\nvariable. We illustrate the methods on simulated networks and on a network of\npolitical blogs. \n\n"}
{"id": "1110.6916", "contents": "Title: Multi-Terminal Source Coding With Action Dependent Side Information Abstract: We consider multi-terminal source coding with a single encoder and multiple\ndecoders where either the encoder or the decoders can take cost constrained\nactions which affect the quality of the side information present at the\ndecoders. For the scenario where decoders take actions, we characterize the\nrate-cost trade-off region for lossless source coding, and give an\nachievability scheme for lossy source coding for two decoders which is optimum\nfor a variety of special cases of interest. For the case where the encoder\ntakes actions, we characterize the rate-cost trade-off for a class of lossless\nsource coding scenarios with multiple decoders. Finally, we also consider\nextensions to other multi-terminal source coding settings with actions, and\ncharacterize the rate -distortion-cost tradeoff for a case of successive\nrefinement with actions. \n\n"}
{"id": "1112.0736", "contents": "Title: Measurement-induced nonlocality based on the relative entropy Abstract: We quantify the measurement-induced nonlocality [Luo and Fu, Phys. Rev. Lett.\n106, 120401 (2011)] from the perspective of the relative entropy. This\nquantification leads to an operational interpretation for the\nmeasurementinduced nonlocality, namely, it is the maximal entropy increase\nafter the locally invariant measurements. The relative entropy of nonlocality\nis upper bounded by the entropy of the measured subsystem. We establish a\nrelationship between the relative entropy of nonlocality and the geometric\nnonlocality based on the Hilbert- Schmidt norm, and show that it is equal to\nthe maximal distillable entanglement. Several trade-off relations are obtained\nfor tripartite pure states. We also give explicit expressions for the relative\nentropy of nonlocality for Bell-diagonal states. \n\n"}
{"id": "1112.1220", "contents": "Title: Understanding mobility in a social petri dish Abstract: Despite the recent availability of large data sets on human movements, a full\nunderstanding of the rules governing motion within social systems is still\nmissing, due to incomplete information on the socio-economic factors and to\noften limited spatio-temporal resolutions. Here we study an entire society of\nindividuals, the players of an online-game, with complete information on their\nmovements in a network-shaped universe and on their social and economic\ninteractions. Such a \"socio-economic laboratory\" allows to unveil the intricate\ninterplay of spatial constraints, social and economic factors, and patterns of\nmobility. We find that the motion of individuals is not only constrained by\nphysical distances, but also strongly shaped by the presence of socio-economic\nareas. These regions can be recovered perfectly by community detection methods\nsolely based on the measured human dynamics. Moreover, we uncover that\nlong-term memory in the time-order of visited locations is the essential\ningredient for modeling the trajectories. \n\n"}
{"id": "1112.3471", "contents": "Title: A Nonstochastic Information Theory for Communication and State\n  Estimation Abstract: In communications, unknown variables are usually modelled as random\nvariables, and concepts such as independence, entropy and information are\ndefined in terms of the underlying probability distributions. In contrast,\ncontrol theory often treats uncertainties and disturbances as bounded unknowns\nhaving no statistical structure. The area of networked control combines both\nfields, raising the question of whether it is possible to construct meaningful\nanalogues of stochastic concepts such as independence, Markovness, entropy and\ninformation without assuming a probability space. This paper introduces a\nframework for doing so, leading to the construction of a maximin information\nfunctional for nonstochastic variables. It is shown that the largest maximin\ninformation rate through a memoryless, error-prone channel in this framework\ncoincides with the block-coding zero-error capacity of the channel. Maximin\ninformation is then used to derive tight conditions for uniformly estimating\nthe state of a linear time-invariant system over such a channel, paralleling\nrecent results of Matveev and Savkin. \n\n"}
{"id": "1112.4236", "contents": "Title: Error Correcting Codes for Distributed Control Abstract: The problem of stabilizing an unstable plant over a noisy communication link\nis an increasingly important one that arises in applications of networked\ncontrol systems. Although the work of Schulman and Sahai over the past two\ndecades, and their development of the notions of \"tree codes\"\\phantom{} and\n\"anytime capacity\", provides the theoretical framework for studying such\nproblems, there has been scant practical progress in this area because explicit\nconstructions of tree codes with efficient encoding and decoding did not exist.\nTo stabilize an unstable plant driven by bounded noise over a noisy channel one\nneeds real-time encoding and real-time decoding and a reliability which\nincreases exponentially with decoding delay, which is what tree codes\nguarantee. We prove that linear tree codes occur with high probability and, for\nerasure channels, give an explicit construction with an expected decoding\ncomplexity that is constant per time instant. We give novel sufficient\nconditions on the rate and reliability required of the tree codes to stabilize\nvector plants and argue that they are asymptotically tight. This work takes an\nimportant step towards controlling plants over noisy channels, and we\ndemonstrate the efficacy of the method through several examples. \n\n"}
{"id": "1112.4312", "contents": "Title: Multiscale Analysis of Spreading in a Large Communication Network Abstract: In temporal networks, both the topology of the underlying network and the\ntimings of interaction events can be crucial in determining how some dynamic\nprocess mediated by the network unfolds. We have explored the limiting case of\nthe speed of spreading in the SI model, set up such that an event between an\ninfectious and susceptible individual always transmits the infection. The speed\nof this process sets an upper bound for the speed of any dynamic process that\nis mediated through the interaction events of the network. With the help of\ntemporal networks derived from large scale time-stamped data on mobile phone\ncalls, we extend earlier results that point out the slowing-down effects of\nburstiness and temporal inhomogeneities. In such networks, links are not\npermanently active, but dynamic processes are mediated by recurrent events\ntaking place on the links at specific points in time. We perform a multi-scale\nanalysis and pinpoint the importance of the timings of event sequences on\nindividual links, their correlations with neighboring sequences, and the\ntemporal pathways taken by the network-scale spreading process. This is\nachieved by studying empirically and analytically different characteristic\nrelay times of links, relevant to the respective scales, and a set of temporal\nreference models that allow for removing selected time-domain correlations one\nby one. \n\n"}
{"id": "1201.0745", "contents": "Title: Communities and bottlenecks: Trees and treelike networks have high\n  modularity Abstract: Much effort has gone into understanding the modular nature of complex\nnetworks. Communities, also known as clusters or modules, are typically\nconsidered to be densely interconnected groups of nodes that are only sparsely\nconnected to other groups in the network. Discovering high quality communities\nis a difficult and important problem in a number of areas. The most popular\napproach is the objective function known as modularity, used both to discover\ncommunities and to measure their strength. To understand the modular structure\nof networks it is then crucial to know how such functions evaluate different\ntopologies, what features they account for, and what implicit assumptions they\nmay make. We show that trees and treelike networks can have unexpectedly and\noften arbitrarily high values of modularity. This is surprising since trees are\nmaximally sparse connected graphs and are not typically considered to possess\nmodular structure, yet the nonlocal null model used by modularity assigns low\nprobabilities, and thus high significance, to the densities of these sparse\ntree communities. We further study the practical performance of popular methods\non model trees and on a genealogical data set and find that the discovered\ncommunities also have very high modularity, often approaching its maximum\nvalue. Statistical tests reveal the communities in trees to be significant, in\ncontrast with known results for partitions of sparse, random graphs. \n\n"}
{"id": "1201.1507", "contents": "Title: Sampling properties of directed networks Abstract: For many real-world networks only a small \"sampled\" version of the original\nnetwork may be investigated; those results are then used to draw conclusions\nabout the actual system. Variants of breadth-first search (BFS) sampling, which\nare based on epidemic processes, are widely used. Although it is well\nestablished that BFS sampling fails, in most cases, to capture the\nIN-component(s) of directed networks, a description of the effects of BFS\nsampling on other topological properties are all but absent from the\nliterature. To systematically study the effects of sampling biases on directed\nnetworks, we compare BFS sampling to random sampling on complete large-scale\ndirected networks. We present new results and a thorough analysis of the\ntopological properties of seven different complete directed networks (prior to\nsampling), including three versions of Wikipedia, three different sources of\nsampled World Wide Web data, and an Internet-based social network. We detail\nthe differences that sampling method and coverage can make to the structural\nproperties of sampled versions of these seven networks. Most notably, we find\nthat sampling method and coverage affect both the bow-tie structure, as well as\nthe number and structure of strongly connected components in sampled networks.\nIn addition, at low sampling coverage (i.e. less than 40%), the values of\naverage degree, variance of out-degree, degree auto-correlation, and link\nreciprocity are overestimated by 30% or more in BFS-sampled networks, and only\nattain values within 10% of the corresponding values in the complete networks\nwhen sampling coverage is in excess of 65%. These results may cause us to\nrethink what we know about the structure, function, and evolution of real-world\ndirected networks. \n\n"}
{"id": "1201.1588", "contents": "Title: Upper Bound on the Capacity of Gaussian Channels with Noisy Feedback Abstract: We consider an additive Gaussian channel with additive Gaussian noise\nfeedback. We derive an upper bound on the n-block capacity (defined by Cover\n[1]). It is shown that this upper bound can be obtained by solving a convex\noptimization problem. With stationarity assumptions on Gaussian noise\nprocesses, we characterize the limit of the n-block upper bound and prove that\nthis limit is the upper bound of the noisy feedback (shannon) capacity. \n\n"}
{"id": "1201.3278", "contents": "Title: Capacity Region of Multiple Access Channel with States Known Noncausally\n  at One Encoder and Only Strictly Causally at the Other Encoder Abstract: We consider a two-user state-dependent multiaccess channel in which the\nstates of the channel are known non-causally to one of the encoders and only\nstrictly causally to the other encoder. Both encoders transmit a common message\nand, in addition, the encoder that knows the states non-causally transmits an\nindividual message. We find explicit characterizations of the capacity region\nof this communication model in both discrete memoryless (DM) and memoryless\nGaussian cases. In particular the capacity region analysis demonstrates the\nutility of the knowledge of the states only strictly causally at the encoder\nthat sends only the common message in general. More specifically, in the DM\nsetting we show that such a knowledge is beneficial and increases the capacity\nregion in general. In the Gaussian setting, we show that such a knowledge does\nnot help, and the capacity is same as if the states were completely unknown at\nthe encoder that sends only the common message. The analysis also reveals\noptimal ways of exploiting the knowledge of the state only strictly causally at\nthe encoder that sends only the common message when such a knowledge is\nbeneficial. The encoders collaborate to convey to the decoder a lossy version\nof the state, in addition to transmitting the information messages through a\ngeneralized Gel'fand-Pinsker binning. Particularly important in this problem\nare the questions of 1) optimal ways of performing the state compression and 2)\nwhether or not the compression indices should be decoded uniquely. We show that\nboth compression \\`a-la noisy network coding, i.e., with no binning and\nnon-unique decoding, and compression using Wyner-Ziv binning with backward\ndecoding and non-unique or unique decoding are optimal. \n\n"}
{"id": "1201.4615", "contents": "Title: Augmented L1 and Nuclear-Norm Models with a Globally Linearly Convergent\n  Algorithm Abstract: This paper studies the long-existing idea of adding a nice smooth function to\n\"smooth\" a non-differentiable objective function in the context of sparse\noptimization, in particular, the minimization of\n$||x||_1+1/(2\\alpha)||x||_2^2$, where $x$ is a vector, as well as the\nminimization of $||X||_*+1/(2\\alpha)||X||_F^2$, where $X$ is a matrix and\n$||X||_*$ and $||X||_F$ are the nuclear and Frobenius norms of $X$,\nrespectively. We show that they can efficiently recover sparse vectors and\nlow-rank matrices. In particular, they enjoy exact and stable recovery\nguarantees similar to those known for minimizing $||x||_1$ and $||X||_*$ under\nthe conditions on the sensing operator such as its null-space property,\nrestricted isometry property, spherical section property, or RIPless property.\nTo recover a (nearly) sparse vector $x^0$, minimizing\n$||x||_1+1/(2\\alpha)||x||_2^2$ returns (nearly) the same solution as minimizing\n$||x||_1$ almost whenever $\\alpha\\ge 10||x^0||_\\infty$. The same relation also\nholds between minimizing $||X||_*+1/(2\\alpha)||X||_F^2$ and minimizing\n$||X||_*$ for recovering a (nearly) low-rank matrix $X^0$, if $\\alpha\\ge\n10||X^0||_2$. Furthermore, we show that the linearized Bregman algorithm for\nminimizing $||x||_1+1/(2\\alpha)||x||_2^2$ subject to $Ax=b$ enjoys global\nlinear convergence as long as a nonzero solution exists, and we give an\nexplicit rate of convergence. The convergence property does not require a\nsolution solution or any properties on $A$. To our knowledge, this is the best\nknown global convergence result for first-order sparse optimization algorithms. \n\n"}
{"id": "1201.4787", "contents": "Title: PageRank and rank-reversal dependence on the damping factor Abstract: PageRank (PR) is an algorithm originally developed by Google to evaluate the\nimportance of web pages. Considering how deeply rooted Google's PR algorithm is\nto gathering relevant information or to the success of modern businesses, the\nquestion of rank-stability and choice of the damping factor (a parameter in the\nalgorithm) is clearly important. We investigate PR as a function of the damping\nfactor d on a network obtained from a domain of the World Wide Web, finding\nthat rank-reversal happens frequently over a broad range of PR (and of d). We\nuse three different correlation measures, Pearson, Spearman, and Kendall, to\nstudy rank-reversal as d changes, and show that the correlation of PR vectors\ndrops rapidly as d changes from its frequently cited value, $d_0=0.85$.\nRank-reversal is also observed by measuring the Spearman and Kendall rank\ncorrelation, which evaluate relative ranks rather than absolute PR.\nRank-reversal happens not only in directed networks containing rank-sinks but\nalso in a single strongly connected component, which by definition does not\ncontain any sinks. We relate rank-reversals to rank-pockets and bottlenecks in\nthe directed network structure. For the network studied, the relative rank is\nmore stable by our measures around $d=0.65$ than at $d=d_0$. \n\n"}
{"id": "1201.6034", "contents": "Title: A Novel MCMC Based Receiver for Large-Scale Uplink Multiuser MIMO\n  Systems Abstract: In this paper, we propose low complexity algorithms based on Markov chain\nMonte Carlo (MCMC) technique for signal detection and channel estimation on the\nuplink in large scale multiuser multiple input multiple output (MIMO) systems\nwith tens to hundreds of antennas at the base station (BS) and similar number\nof uplink users. A BS receiver that employs a randomized sampling method (which\nmakes a probabilistic choice between Gibbs sampling and random sampling in each\niteration) for detection and a Gibbs sampling based method for channel\nestimation is proposed. The algorithm proposed for detection alleviates the\nstalling problem encountered at high SNRs in conventional MCMC algorithm and\nachieves near-optimal performance in large systems. A novel ingredient in the\ndetection algorithm that is responsible for achieving near-optimal performance\nat low complexities is the joint use of a {\\it randomized MCMC (R-MCMC)\nstrategy} coupled with a {\\it multiple restart strategy} with an efficient\nrestart criterion. Near-optimal detection performance is demonstrated for large\nnumber of BS antennas and users (e.g., 64, 128, 256 BS antennas/users). The\nproposed MCMC based channel estimation algorithm refines an initial estimate of\nthe channel obtained during pilot phase through iterations with R-MCMC\ndetection during data phase. In time division duplex (TDD) systems where\nchannel reciprocity holds, these channel estimates can be used for multiuser\nMIMO precoding on the downlink. Further, we employ this receiver architecture\nin the frequency domain for receiving cyclic prefixed single carrier (CPSC)\nsignals on frequency selective fading between users and the BS. The proposed\nreceiver achieves performance that is near optimal and close to that achieved\nwith perfect channel knowledge. \n\n"}
{"id": "1202.0607", "contents": "Title: On the Alternative Relaying Diamond Channel with Conferencing Links Abstract: In this paper, the diamond relay channel is considered, which consists of one\nsource-destination pair and two relay nodes connected with rate-limited\nout-of-band conferencing links. In particular, we focus on the half-duplex\nalternative relaying strategy, in which the two relays operate alternatively\nover time. With different amounts of delay, two conferencing strategies are\nproposed, each of which can be implemented by either a general two-side\nconferencing scheme (for which both of the two conferencing links are used) or\na special-case one-side conferencing scheme (for which only one of the two\nconferencing links is used). Based on the most general two-side conferencing\nscheme, we derive the achievable rates by using the decode-and-forward (DF) and\namplify-and-forward (AF) relaying schemes, and show that these rate\nmaximization problems are convex. By further exploiting the properties of the\noptimal solutions, the simpler one-side conferencing is shown to be equally\ngood as the two-side conferencing in term of the achievable rates under\narbitrary channel conditions. Based on this, the DF rate in closed-form is\nobtained, and the principle to use which one of the two conferencing links for\none-side conferencing is also established. Moreover, the DF scheme is shown to\nbe capacity-achieving under certain conditions with even one-side conferencing.\nFor the AF relaying scheme, one-side conferencing is shown to be sub-optimal in\ngeneral. Finally, numerical results are provided to validate our analysis. \n\n"}
{"id": "1202.0876", "contents": "Title: A Coding Theoretic Approach for Evaluating Accumulate Distribution on\n  Minimum Cut Capacity of Weighted Random Graphs Abstract: The multicast capacity of a directed network is closely related to the\n$s$-$t$ maximum flow, which is equal to the $s$-$t$ minimum cut capacity due to\nthe max-flow min-cut theorem. If the topology of a network (or link capacities)\nis dynamically changing or have stochastic nature, it is not so trivial to\npredict statistical properties on the maximum flow. In this paper, we present a\ncoding theoretic approach for evaluating the accumulate distribution of the\nminimum cut capacity of weighted random graphs. The main feature of our\napproach is to utilize the correspondence between the cut space of a graph and\na binary LDGM (low-density generator-matrix) code with column weight 2. The\ngraph ensemble treated in the paper is a weighted version of\nErd\\H{o}s-R\\'{e}nyi random graph ensemble. The main contribution of our work is\na combinatorial lower bound for the accumulate distribution of the minimum cut\ncapacity. From some computer experiments, it is observed that the lower bound\nderived here reflects the actual statistical behavior of the minimum cut\ncapacity. \n\n"}
{"id": "1202.3643", "contents": "Title: Dynamics of conflicts in Wikipedia Abstract: In this work we study the dynamical features of editorial wars in Wikipedia\n(WP). Based on our previously established algorithm, we build up samples of\ncontroversial and peaceful articles and analyze the temporal characteristics of\nthe activity in these samples. On short time scales, we show that there is a\nclear correspondence between conflict and burstiness of activity patterns, and\nthat memory effects play an important role in controversies. On long time\nscales, we identify three distinct developmental patterns for the overall\nbehavior of the articles. We are able to distinguish cases eventually leading\nto consensus from those cases where a compromise is far from achievable.\nFinally, we analyze discussion networks and conclude that edit wars are mainly\nfought by few editors only. \n\n"}
{"id": "1202.4707", "contents": "Title: A para-model agent for dynamical systems Abstract: Consider a dynamical system $u \\mapsto x, \\dot{x} = f_{nl}(x,u)$ where\n$f_{nl}$ is a nonlinear (convex or nonconvex) function, or a combination of\nnonlinear functions that can eventually switch. We present, in this preliminary\nwork, a generalization of the standard model-free control, that can either\ncontrol the dynamical system, given an output reference trajectory, or optimize\nthe dynamical system as a derivative-free optimization based \"extremum-seeking\"\nprocedure. Multiple applications are presented and the robustness of the\nproposed method is studied in simulation. \n\n"}
{"id": "1202.6144", "contents": "Title: Attack Detection and Identification in Cyber-Physical Systems -- Part I:\n  Models and Fundamental Limitations Abstract: Cyber-physical systems integrate computation, communication, and physical\ncapabilities to interact with the physical world and humans. Besides failures\nof components, cyber-physical systems are prone to malignant attacks, and\nspecific analysis tools as well as monitoring mechanisms need to be developed\nto enforce system security and reliability. This paper proposes a unified\nframework to analyze the resilience of cyber-physical systems against attacks\ncast by an omniscient adversary. We model cyber-physical systems as linear\ndescriptor systems, and attacks as exogenous unknown inputs. Despite its\nsimplicity, our model captures various real-world cyber-physical systems, and\nit includes and generalizes many prototypical attacks, including stealth,\n(dynamic) false-data injection and replay attacks. First, we characterize\nfundamental limitations of static, dynamic, and active monitors for attack\ndetection and identification. Second, we provide constructive algebraic\nconditions to cast undetectable and unidentifiable attacks. Third, by using the\nsystem interconnection structure, we describe graph-theoretic conditions for\nthe existence of undetectable and unidentifiable attacks. Finally, we validate\nour findings through some illustrative examples with different cyber-physical\nsystems, such as a municipal water supply network and two electrical power\ngrids. \n\n"}
{"id": "1203.0029", "contents": "Title: Assortativity Decreases the Robustness of Interdependent Networks Abstract: It was recently recognized that interdependencies among different networks\ncan play a crucial role in triggering cascading failures and hence system-wide\ndisasters. A recent model shows how pairs of interdependent networks can\nexhibit an abrupt percolation transition as failures accumulate. We report on\nthe effects of topology on failure propagation for a model system consisting of\ntwo interdependent networks. We find that the internal node correlations in\neach of the two interdependent networks significantly changes the critical\ndensity of failures that triggers the total disruption of the two-network\nsystem. Specifically, we find that the assortativity (i.e. the likelihood of\nnodes with similar degree to be connected) within a single network decreases\nthe robustness of the entire system. The results of this study on the influence\nof assortativity may provide insights into ways of improving the robustness of\nnetwork architecture, and thus enhances the level of protection of critical\ninfrastructures. \n\n"}
{"id": "1203.0695", "contents": "Title: Cooperative Compute-and-Forward Abstract: We examine the benefits of user cooperation under compute-and-forward. Much\nlike in network coding, receivers in a compute-and-forward network recover\nfinite-field linear combinations of transmitters' messages. Recovery is enabled\nby linear codes: transmitters map messages to a linear codebook, and receivers\nattempt to decode the incoming superposition of signals to an integer\ncombination of codewords. However, the achievable computation rates are low if\nchannel gains do not correspond to a suitable linear combination. In response\nto this challenge, we propose a cooperative approach to compute-and-forward. We\ndevise a lattice-coding approach to block Markov encoding with which we\nconstruct a decode-and-forward style computation strategy. Transmitters\nbroadcast lattice codewords, decode each other's messages, and then\ncooperatively transmit resolution information to aid receivers in decoding the\ninteger combinations. Using our strategy, we show that cooperation offers a\nsignificant improvement both in the achievable computation rate and in the\ndiversity-multiplexing tradeoff. \n\n"}
{"id": "1203.1276", "contents": "Title: Optimal Control Design under Limited Model Information for Discrete-Time\n  Linear Systems with Stochastically-Varying Parameters Abstract: The value of plant model information available in the control design process\nis discussed. We design optimal state-feedback controllers for interconnected\ndiscrete-time linear systems with stochastically-varying parameters. The\nparameters are assumed to be independently and identically distributed random\nvariables in time. The design of each controller relies only on (i) exact local\nplant model information and (ii) statistical beliefs about the model of the\nrest of the system. We consider both finite-horizon and infinite-horizon\nquadratic cost functions. The optimal state-feedback controller is derived in\nboth cases. The optimal controller is shown to be linear in the state and to\ndepend on the model parameters and their statistics in a particular way.\nFurthermore, we study the value of model information in optimal control design\nusing the performance degradation ratio which is defined as the supremum (over\nall possible initial conditions) of the ratio of the cost of the optimal\ncontroller with limited model information scaled by the cost of the optimal\ncontroller with full model information. An upper bound for the performance\ndegradation ratio is presented for the case of fully-actuated subsystems.\nComparisons are made between designs based on limited, statistical, and full\nmodel information. Throughout the paper, we use a power network example to\nillustrate concepts and results. \n\n"}
{"id": "1203.1406", "contents": "Title: Communication over Individual Channels -- a general framework Abstract: We consider the problem of communicating over a channel for which no\nmathematical model is specified, and the achievable rates are determined as a\nfunction of the channel input and output sequences known a-posteriori, without\nassuming any a-priori relation between them. In a previous paper we have shown\nthat the empirical mutual information between the input and output sequences is\nachievable without specifying the channel model, by using feedback and common\nrandomness, and a similar result for real-valued input and output alphabets. In\nthis paper, we present a unifying framework which includes the two previous\nresults as particular cases. We characterize the region of rate functions which\nare achievable, and show that asymptotically the rate function is equivalent to\na conditional distribution of the channel input given the output. We present a\nscheme that achieves these rates with asymptotically vanishing overheads. \n\n"}
{"id": "1203.3269", "contents": "Title: Physical Layer Network Coding for Two-Way Relaying with QAM and Latin\n  Squares Abstract: The design of modulation schemes for the physical layer network-coded two way\nrelaying scenario has been extensively studied recently with the protocol which\nemploys two phases: Multiple access (MA) Phase and Broadcast (BC) Phase. It was\nobserved by Koike-Akino et al. that adaptively changing the network coding map\nused at the relay according to the channel conditions greatly reduces the\nimpact of multiple access interference which occurs at the relay during the MA\nPhase and all these network coding maps should satisfy a requirement called the\nexclusive law. Only the scenario in which the end nodes use M-PSK signal sets\nis extensively studied in \\cite{NVR} using Latin Sqaures. In this paper, we\naddress the case in which the end nodes use M-QAM signal sets (where M is of\nthe form $2^{2\\lambda}$, $\\lambda$ being any positive integer). In a fading\nscenario, for certain channel conditions $\\gamma e^{j \\theta}$, termed singular\nfade states, the MA phase performance is greatly reduced. We show that the\nsquare QAM signal sets give lesser number of singular fade states compared to\nPSK signal sets. Because of this, the complexity at the relay is enormously\nreduced. Moreover, lesser number of overhead bits are required in the BC phase.\nThe fade state $\\gamma e^{j \\theta}=1$ is singular for all constellations of\narbitrary size including PSK and QAM. For arbitrary PSK constellation it is\nwell known that the Latin Square obtained by bit-wise XOR mapping removes this\nsingularity. We show that XOR mapping fails to remove this singularity for QAM\nof size more greater than 4 and show that a doubly block circulant Latin Square\nremoves this singularity. Simulation results are presented to show the\nsuperiority of QAM over PSK. \n\n"}
{"id": "1203.3621", "contents": "Title: Robustness of correlated networks against propagating attacks Abstract: We investigate robustness of correlated networks against propagating attacks\nmodeled by a susceptible-infected-removed model. By Monte-Carlo simulations, we\nnumerically determine the first critical infection rate, above which a global\noutbreak of disease occurs, and the second critical infection rate, above which\ndisease disintegrates the network. Our result shows that correlated networks\nare robust compared to the uncorrelated ones, regardless of whether they are\nassortative or disassortative, when a fraction of infected nodes in an initial\nstate is not too large. For large initial fraction, disassortative network\nbecomes fragile while assortative network holds robustness. This behavior is\nrelated to the layered network structure inevitably generated by a rewiring\nprocedure we adopt to realize correlated networks. \n\n"}
{"id": "1203.4870", "contents": "Title: Variational Bayesian algorithm for quantized compressed sensing Abstract: Compressed sensing (CS) is on recovery of high dimensional signals from their\nlow dimensional linear measurements under a sparsity prior and digital\nquantization of the measurement data is inevitable in practical implementation\nof CS algorithms. In the existing literature, the quantization error is modeled\ntypically as additive noise and the multi-bit and 1-bit quantized CS problems\nare dealt with separately using different treatments and procedures. In this\npaper, a novel variational Bayesian inference based CS algorithm is presented,\nwhich unifies the multi- and 1-bit CS processing and is applicable to various\ncases of noiseless/noisy environment and unsaturated/saturated quantizer. By\ndecoupling the quantization error from the measurement noise, the quantization\nerror is modeled as a random variable and estimated jointly with the signal\nbeing recovered. Such a novel characterization of the quantization error\nresults in superior performance of the algorithm which is demonstrated by\nextensive simulations in comparison with state-of-the-art methods for both\nmulti-bit and 1-bit CS problems. \n\n"}
{"id": "1204.0521", "contents": "Title: Explicit receivers for pure-interference bosonic multiple access\n  channels Abstract: The pure-interference bosonic multiple access channel has two senders and one\nreceiver, such that the senders each communicate with multiple temporal modes\nof a single spatial mode of light. The channel mixes the input modes from the\ntwo users pairwise on a lossless beamsplitter, and the receiver has access to\none of the two output ports. In prior work, Yen and Shapiro found the capacity\nregion of this channel if encodings consist of coherent-state preparations.\nHere, we demonstrate how to achieve the coherent-state Yen-Shapiro region (for\na range of parameters) using a sequential decoding strategy, and we show that\nour strategy outperforms the rate regions achievable using conventional\nreceivers. Our receiver performs binary-outcome quantum measurements for every\ncodeword pair in the senders' codebooks. A crucial component of this scheme is\na non-destructive \"vacuum-or-not\" measurement that projects an n-symbol\nmodulated codeword onto the n-fold vacuum state or its orthogonal complement,\nsuch that the post-measurement state is either the n-fold vacuum or has the\nvacuum removed from the support of the n symbols' joint quantum state. This\nreceiver requires the additional ability to perform multimode optical\nphase-space displacements which are realizable using a beamsplitter and a\nlaser. \n\n"}
{"id": "1204.0556", "contents": "Title: Decomposition Methods for Large Scale LP Decoding Abstract: When binary linear error-correcting codes are used over symmetric channels, a\nrelaxed version of the maximum likelihood decoding problem can be stated as a\nlinear program (LP). This LP decoder can be used to decode error-correcting\ncodes at bit-error-rates comparable to state-of-the-art belief propagation (BP)\ndecoders, but with significantly stronger theoretical guarantees. However, LP\ndecoding when implemented with standard LP solvers does not easily scale to the\nblock lengths of modern error correcting codes. In this paper we draw on\ndecomposition methods from optimization theory, specifically the Alternating\nDirections Method of Multipliers (ADMM), to develop efficient distributed\nalgorithms for LP decoding.\n  The key enabling technical result is a \"two-slice\" characterization of the\ngeometry of the parity polytope, which is the convex hull of all codewords of a\nsingle parity check code. This new characterization simplifies the\nrepresentation of points in the polytope. Using this simplification, we develop\nan efficient algorithm for Euclidean norm projection onto the parity polytope.\nThis projection is required by ADMM and allows us to use LP decoding, with all\nits theoretical guarantees, to decode large-scale error correcting codes\nefficiently.\n  We present numerical results for LDPC codes of lengths more than 1000. The\nwaterfall region of LP decoding is seen to initiate at a slightly higher\nsignal-to-noise ratio than for sum-product BP, however an error floor is not\nobserved for LP decoding, which is not the case for BP. Our implementation of\nLP decoding using ADMM executes as fast as our baseline sum-product BP decoder,\nis fully parallelizable, and can be seen to implement a type of message-passing\nwith a particularly simple schedule. \n\n"}
{"id": "1204.1091", "contents": "Title: Load-Aware Modeling and Analysis of Heterogeneous Cellular Networks Abstract: Random spatial models are attractive for modeling heterogeneous cellular\nnetworks (HCNs) due to their realism, tractability, and scalability. A major\nlimitation of such models to date in the context of HCNs is the neglect of\nnetwork traffic and load: all base stations (BSs) have typically been assumed\nto always be transmitting. Small cells in particular will have a lighter load\nthan macrocells, and so their contribution to the network interference may be\nsignificantly overstated in a fully loaded model. This paper incorporates a\nflexible notion of BS load by introducing a new idea of conditionally thinning\nthe interference field. For a K-tier HCN where BSs across tiers differ in terms\nof transmit power, supported data rate, deployment density, and now load, we\nderive the coverage probability for a typical mobile, which connects to the\nstrongest BS signal. Conditioned on this connection, the interfering BSs of the\n$i^{th}$ tier are assumed to transmit independently with probability $p_i$,\nwhich models the load. Assuming - reasonably - that smaller cells are more\nlightly loaded than macrocells, the analysis shows that adding such access\npoints to the network always increases the coverage probability. We also\nobserve that fully loaded models are quite pessimistic in terms of coverage. \n\n"}
{"id": "1204.5046", "contents": "Title: Instantaneous Relaying: Optimal Strategies and Interference\n  Neutralization Abstract: In a multi-user wireless network equipped with multiple relay nodes, some\nrelays are more intelligent than other relay nodes. The intelligent relays are\nable to gather channel state information, perform linear processing and forward\nsignals whereas the dumb relays is only able to serve as amplifiers. As the\ndumb relays are oblivious to the source and destination nodes, the wireless\nnetwork can be modeled as a relay network with *smart instantaneous relay*\nonly: the signals of source-destination arrive at the same time as\nsource-relay-destination. Recently, instantaneous relaying is shown to improve\nthe degrees-of-freedom of the network as compared to classical cut-set bound.\nIn this paper, we study an achievable rate region and its boundary of the\ninstantaneous interference relay channel in the scenario of (a) uninformed\nnon-cooperative source-destination nodes (source and destination nodes are not\naware of the existence of the relay and are non-cooperative) and (b) informed\nand cooperative source-destination nodes. Further, we examine the performance\nof interference neutralization: a relay strategy which is able to cancel\ninterference signals at each destination node in the air. We observe that\ninterference neutralization, although promise to achieve desired\ndegrees-of-freedom, may not be feasible if relay has limited power. Simulation\nresults show that the optimal relay strategies improve the achievable rate\nregion and provide better user-fairness in both uninformed non-cooperative and\ninformed cooperative scenarios. \n\n"}
{"id": "1204.5136", "contents": "Title: Analysis and Design of Irregular Graphs for Node-Based\n  Verification-Based Recovery Algorithms in Compressed Sensing Abstract: In this paper, we present a probabilistic analysis of iterative node-based\nverification-based (NB-VB) recovery algorithms over irregular graphs in the\ncontext of compressed sensing. Verification-based algorithms are particularly\ninteresting due to their low complexity (linear in the signal dimension $n$).\nThe analysis predicts the average fraction of unverified signal elements at\neach iteration $\\ell$ where the average is taken over the ensembles of input\nsignals and sensing matrices. The analysis is asymptotic ($n \\rightarrow\n\\infty$) and is similar in nature to the well-known density evolution technique\ncommonly used to analyze iterative decoding algorithms. Compared to the\nexisting technique for the analysis of NB-VB algorithms, which is based on\nnumerically solving a large system of coupled differential equations, the\nproposed method is much simpler and more accurate. This allows us to design\nirregular sensing graphs for such recovery algorithms. The designed irregular\ngraphs outperform the corresponding regular graphs substantially. For example,\nfor the same recovery complexity per iteration, we design irregular graphs that\ncan recover up to about 40% more non-zero signal elements compared to the\nregular graphs. Simulation results are also provided which demonstrate that the\nproposed asymptotic analysis matches the performance of recovery algorithms for\nlarge but finite values of $n$. \n\n"}
{"id": "1204.5226", "contents": "Title: An Optimal and Distributed Method for Voltage Regulation in Power\n  Distribution Systems Abstract: This paper addresses the problem of voltage regulation in power distribution\nnetworks with deep-penetration of distributed energy resources, e.g.,\nrenewable-based generation, and storage-capable loads such as plug-in hybrid\nelectric vehicles. We cast the problem as an optimization program, where the\nobjective is to minimize the losses in the network subject to constraints on\nbus voltage magnitudes, limits on active and reactive power injections,\ntransmission line thermal limits and losses. We provide sufficient conditions\nunder which the optimization problem can be solved via its convex relaxation.\nUsing data from existing networks, we show that these sufficient conditions are\nexpected to be satisfied by most networks. We also provide an efficient\ndistributed algorithm to solve the problem. The algorithm adheres to a\ncommunication topology described by a graph that is the same as the graph that\ndescribes the electrical network topology. We illustrate the operation of the\nalgorithm, including its robustness against communication link failures,\nthrough several case studies involving 5-, 34-, and 123-bus power distribution\nsystems. \n\n"}
{"id": "1204.5636", "contents": "Title: Social Networks with Competing Products Abstract: We introduce a new threshold model of social networks, in which the nodes\ninfluenced by their neighbours can adopt one out of several alternatives. We\ncharacterize social networks for which adoption of a product by the whole\nnetwork is possible (respectively necessary) and the ones for which a unique\noutcome is guaranteed. These characterizations directly yield polynomial time\nalgorithms that allow us to determine whether a given social network satisfies\none of the above properties.\n  We also study algorithmic questions for networks without unique outcomes. We\nshow that the problem of determining whether a final network exists in which\nall nodes adopted some product is NP-complete. In turn, the problems of\ndetermining whether a given node adopts some (respectively, a given) product in\nsome (respectively, all) network(s) are either co-NP complete or can be solved\nin polynomial time.\n  Further, we show that the problem of computing the minimum possible spread of\na product is NP-hard to approximate with an approximation ratio better than\n$\\Omega(n)$, in contrast to the maximum spread, which is efficiently\ncomputable. Finally, we clarify that some of the above problems can be solved\nin polynomial time when there are only two products. \n\n"}
{"id": "1204.6093", "contents": "Title: Linear Consensus Algorithms Based on Balanced Asymmetric Chains Abstract: Multi agent consensus algorithms with update steps based on so-called\nbalanced asymmetric chains, are analyzed. For such algorithms it is shown that\n(i) the set of accumulation points of states is finite, (ii) the asymptotic\nunconditional occurrence of single consensus or multiple consensuses is\ndirectly related to the property of absolute infinite flow for the underlying\nupdate chain. The results are applied to well known consensus models. \n\n"}
{"id": "1204.6098", "contents": "Title: On Locality in Distributed Storage Systems Abstract: This paper studies the design of codes for distributed storage systems (DSS)\nthat enable local repair in the event of node failure. This paper presents\nlocally repairable codes based on low degree multivariate polynomials. Its code\nconstruction mechanism extends work on Noisy Interpolating Set by Dvir et al.\n\\cite{dvir2011}. The paper presents two classes of codes that allow node repair\nto be performed by contacting 2 and 3 surviving nodes respectively. It further\nshows that both classes are good in terms of their rate and minimum distance,\nand allow their rate to be bartered for greater flexibility in the repair\nprocess. \n\n"}
{"id": "1204.6174", "contents": "Title: Efficient Computations of a Security Index for False Data Attacks in\n  Power Networks Abstract: The resilience of Supervisory Control and Data Acquisition (SCADA) systems\nfor electric power networks for certain cyber-attacks is considered. We analyze\nthe vulnerability of the measurement system to false data attack on\ncommunicated measurements. The vulnerability analysis problem is shown to be\nNP-hard, meaning that unless $P = NP$ there is no polynomial time algorithm to\nanalyze the vulnerability of the system. Nevertheless, we identify situations,\nsuch as the full measurement case, where it can be solved efficiently. In such\ncases, we show indeed that the problem can be cast as a generalization of the\nminimum cut problem involving costly nodes. We further show that it can be\nreformulated as a standard minimum cut problem (without costly nodes) on a\nmodified graph of proportional size. An important consequence of this result is\nthat our approach provides the first exact efficient algorithm for the\nvulnerability analysis problem under the full measurement assumption.\nFurthermore, our approach also provides an efficient heuristic algorithm for\nthe general NP-hard problem. Our results are illustrated by numerical studies\non benchmark systems including the IEEE 118-bus system. \n\n"}
{"id": "1205.0537", "contents": "Title: A greedy-navigator approach to navigable city plans Abstract: We use a set of four theoretical navigability indices for street maps to\ninvestigate the shape of the resulting street networks, if they are grown by\noptimizing these indices. The indices compare the performance of simulated\nnavigators (having a partial information about the surroundings, like humans in\nmany real situations) to the performance of optimally navigating individuals.\nWe show that our simple greedy shortcut construction strategy generates the\nemerging structures that are different from real road network, but not\ninconceivable. The resulting city plans, for all navigation indices, share\ncommon qualitative properties such as the tendency for triangular blocks to\nappear, while the more quantitative features, such as degree distributions and\nclustering, are characteristically different depending on the type of metrics\nand routing strategies. We show that it is the type of metrics used which\ndetermines the overall shapes characterized by structural heterogeneity, but\nthe routing schemes contribute to more subtle details of locality, which is\nmore emphasized in case of unrestricted connections when the edge crossing is\nallowed. \n\n"}
{"id": "1205.1650", "contents": "Title: Compressed Sensing with Nonlinear Observations and Related Nonlinear\n  Optimisation Problems Abstract: Non-convex constraints have recently proven a valuable tool in many\noptimisation problems. In particular sparsity constraints have had a\nsignificant impact on sampling theory, where they are used in Compressed\nSensing and allow structured signals to be sampled far below the rate\ntraditionally prescribed.\n  Nearly all of the theory developed for Compressed Sensing signal recovery\nassumes that samples are taken using linear measurements. In this paper we\ninstead address the Compressed Sensing recovery problem in a setting where the\nobservations are non-linear. We show that, under conditions similar to those\nrequired in the linear setting, the Iterative Hard Thresholding algorithm can\nbe used to accurately recover sparse or structured signals from few non-linear\nobservations.\n  Similar ideas can also be developed in a more general non-linear optimisation\nframework. In the second part of this paper we therefore present related result\nthat show how this can be done under sparsity and union of subspaces\nconstraints, whenever a generalisation of the Restricted Isometry Property\ntraditionally imposed on the Compressed Sensing system holds. \n\n"}
{"id": "1205.1712", "contents": "Title: On the strong converses for the quantum channel capacity theorems Abstract: A unified approach to prove the converses for the quantum channel capacity\ntheorems is presented. These converses include the strong converse theorems for\nclassical or quantum information transfer with error exponents and novel\nexplicit upper bounds on the fidelity measures reminiscent of the Wolfowitz\nstrong converse for the classical channel capacity theorems. We provide a new\nproof for the error exponents for the classical information transfer. A long\nstanding problem in quantum information theory has been to find out the strong\nconverse for the channel capacity theorem when quantum information is sent\nacross the channel. We give the quantum error exponent thereby giving a\none-shot exponential upper bound on the fidelity. We then apply our results to\nshow that the strong converse holds for the quantum information transfer across\nan erasure channel for maximally entangled channel inputs. \n\n"}
{"id": "1205.3272", "contents": "Title: Capacity and Spectral Efficiency of Interference Avoiding Cognitive\n  Radio with Imperfect Detection Abstract: In this paper, we consider a model in which the unlicensed or the Secondary\nUser (SU) equipped with a Cognitive Radio (CR) (together referred to as CR)\ninterweaves its transmission with that of the licensed or the Primary User\n(PU). In this model, when the CR detects the PU to be (i) busy it does not\ntransmit and; (ii) PU to be idle it transmits. Two situations based on CR's\ndetection of PU are considered, where the CR detects PU (i) perfectly -\nreferred to as the \"ideal case\" and; (ii) imperfectly - referred to as \"non\nideal case\". For both the cases we bring out the rate region, sum capacity of\nPU and CR and spectral efficiency factor - the ratio of sum capacity of PU and\nCR to the capacity of PU without CR. We consider the Rayleigh fading channel to\nprovide insight to our results. For the ideal case we study the effect of PU\noccupancy on spectral efficiency factor. For the non ideal case, in addition to\nthe effect of occupancy, we study the effect of false alarm and missed\ndetection on the rate region and spectral efficiency factor. We characterize\nthe set of values of false alarm and missed detection probabilities for which\nthe system benefits, in the form of admissible regions. We show that false\nalarm has a more profound effect on the spectral efficiency factor than missed\ndetection. We also show that when PU occupancy is small, the effects of both\nfalse alarm and missed detection decrease. Finally, for the standard detection\ntechniques viz. energy detection, matched filter and magnitude squared\ncoherence, we show that that the matched filter performs best followed by\nmagnitude squared coherence followed by energy detection with respect to\nspectral efficiency factor. \n\n"}
{"id": "1205.4683", "contents": "Title: How women organize social networks different from men Abstract: Superpositions of social networks, such as communication, friendship, or\ntrade networks, are called multiplex networks, forming the structural backbone\nof human societies. Novel datasets now allow quantification and exploration of\nmultiplex networks. Here we study gender-specific differences of a multiplex\nnetwork from a complete behavioral dataset of an online-game society of about\n300,000 players. On the individual level females perform better economically\nand are less risk-taking than males. Males reciprocate friendship requests from\nfemales faster than vice versa and hesitate to reciprocate hostile actions of\nfemales. On the network level females have more communication partners, who are\nless connected than partners of males. We find a strong homophily effect for\nfemales and higher clustering coefficients of females in trade and attack\nnetworks. Cooperative links between males are under-represented, reflecting\ncompetition for resources among males. These results confirm quantitatively\nthat females and males manage their social networks in substantially different\nways. \n\n"}
{"id": "1205.5823", "contents": "Title: Foreword: A Computable Universe, Understanding Computation and Exploring\n  Nature As Computation Abstract: I am most honoured to have the privilege to present the Foreword to this\nfascinating and wonderfully varied collection of contributions, concerning the\nnature of computation and of its deep connection with the operation of those\nbasic laws, known or yet unknown, governing the universe in which we live.\nFundamentally deep questions are indeed being grappled with here, and the fact\nthat we find so many different viewpoints is something to be expected, since,\nin truth, we know little about the foundational nature and origins of these\nbasic laws, despite the immense precision that we so often find revealed in\nthem. Accordingly, it is not surprising that within the viewpoints expressed\nhere is some unabashed speculation, occasionally bordering on just partially\njustified guesswork, while elsewhere we find a good deal of precise reasoning,\nsome in the form of rigorous mathematical theorems. Both of these are as should\nbe, for without some inspired guesswork we cannot have new ideas as to where\nlook in order to make genuinely new progress, and without precise mathematical\nreasoning, no less than in precise observation, we cannot know when we are\nright -- or, more usually, when we are wrong. \n\n"}
{"id": "1206.0981", "contents": "Title: An Informed Model of Personal Information Release in Social Networking\n  Sites Abstract: The emergence of online social networks and the growing popularity of digital\ncommunication has resulted in an increasingly amount of information about\nindividuals available on the Internet. Social network users are given the\nfreedom to create complex digital identities, and enrich them with truthful or\neven fake personal information. However, this freedom has led to serious\nsecurity and privacy incidents, due to the role users' identities play in\nestablishing social and privacy settings.\n  In this paper, we take a step toward a better understanding of online\ninformation exposure. Based on the detailed analysis of a sample of real-world\ndata, we develop a deception model for online users. The model uses a game\ntheoretic approach to characterizing a user's willingness to release, withhold\nor lie about information depending on the behavior of individuals within the\nuser's circle of friends. In the model, we take into account both the\nheterogeneous nature of users and their different attitudes, as well as the\ndifferent types of information they may expose online. \n\n"}
{"id": "1206.1405", "contents": "Title: Recovery of Sparse 1-D Signals from the Magnitudes of their Fourier\n  Transform Abstract: The problem of signal recovery from the autocorrelation, or equivalently, the\nmagnitudes of the Fourier transform, is of paramount importance in various\nfields of engineering. In this work, for one-dimensional signals, we give\nconditions, which when satisfied, allow unique recovery from the\nautocorrelation with very high probability. In particular, for sparse signals,\nwe develop two non-iterative recovery algorithms. One of them is based on\ncombinatorial analysis, which we prove can recover signals upto sparsity\n$o(n^{1/3})$ with very high probability, and the other is developed using a\nconvex optimization based framework, which numerical simulations suggest can\nrecover signals upto sparsity $o(n^{1/2})$ with very high probability. \n\n"}
{"id": "1206.1973", "contents": "Title: Communications-Inspired Projection Design with Application to\n  Compressive Sensing Abstract: We consider the recovery of an underlying signal x \\in C^m based on\nprojection measurements of the form y=Mx+w, where y \\in C^l and w is\nmeasurement noise; we are interested in the case l < m. It is assumed that the\nsignal model p(x) is known, and w CN(w;0,S_w), for known S_W. The objective is\nto design a projection matrix M \\in C^(l x m) to maximize key\ninformation-theoretic quantities with operational significance, including the\nmutual information between the signal and the projections I(x;y) or the Renyi\nentropy of the projections h_a(y) (Shannon entropy is a special case). By\ncapitalizing on explicit characterizations of the gradients of the information\nmeasures with respect to the projections matrix, where we also partially extend\nthe well-known results of Palomar and Verdu from the mutual information to the\nRenyi entropy domain, we unveil the key operations carried out by the optimal\nprojections designs: mode exposure and mode alignment. Experiments are\nconsidered for the case of compressive sensing (CS) applied to imagery. In this\ncontext, we provide a demonstration of the performance improvement possible\nthrough the application of the novel projection designs in relation to\nconventional ones, as well as justification for a fast online projections\ndesign method with which state-of-the-art adaptive CS signal recovery is\nachieved. \n\n"}
{"id": "1206.2599", "contents": "Title: A tale of two cities. Vulnerabilities of the London and Paris transit\n  networks Abstract: This paper analyses the impact of random failure or attack on the public\ntransit networks of London and Paris in a comparative study. In particular we\nanalyze how the dysfunction or removal of sets of stations or links (rails,\nroads, etc.) affects the connectivity properties within these networks. We show\nhow accumulating dysfunction leads to emergent phenomena that cause the\ntransportation system to break down as a whole. Simulating different directed\nattack strategies, we find minimal strategies with high impact and identify\na-priory criteria that correlate with the resilience of these networks. To\ndemonstrate our approach, we choose the London and Paris public transit\nnetworks. Our quantitative analysis is performed in the frames of the complex\nnetwork theory - a methodological tool that has emerged recently as an\ninterdisciplinary approach joining methods and concepts of the theory of random\ngraphs, percolation, and statistical physics. In conclusion we demonstrate that\ntaking into account cascading effects the network integrity is controlled for\nboth networks by less than 0.5 % of the stations i.e. 19 for Paris and 34 for\nLondon. \n\n"}
{"id": "1206.3065", "contents": "Title: Stability Analysis and Controller Design for a Linear System with Duhem\n  Hysteresis Nonlinearity Abstract: In this paper, we investigate the stability of a feedback interconnection\nbetween a linear system and a Duhem hysteresis operator, where the linear\nsystem and the Duhem hysteresis operator satisfy either the counter-clockwise\n(CCW) or clockwise (CW) input-output dynamics. More precisely, we present\nsufficient conditions for the stability of the interconnected system that\ndepend on the CW or CCW properties of the linear system and the Duhem operator.\nBased on these results we introduce a control design methodology for\nstabilizing a linear plant with a hysteretic actuator or sensor without\nrequiring precise information on the hysteresis operator. \n\n"}
{"id": "1206.4226", "contents": "Title: Three-User Cognitive Interference Channel: Capacity Region with Strong\n  Interference Abstract: This study investigates the capacity region of a three-user cognitive radio\nnetwork with two primary users and one cognitive user. A three-user Cognitive\nInterference Channel (C-IFC) is proposed by considering a three-user\nInterference Channel (IFC) where one of the transmitters has cognitive\ncapabilities and knows the messages of the other two transmitters in a\nnon-causal manner. First, two inner bounds on the capacity region of the\nthree-user C-IFC are obtained based on using the schemes which allow all\nreceivers to decode all messages with two different orders. Next, two sets of\nconditions are derived, under which the capacity region of the proposed model\ncoincides with the capacity region of a three-user C-IFC in which all three\nmessages are required at all receivers. Under these conditions, referred to as\nstrong interference conditions, the capacity regions for the proposed\nthree-user C-IFC are characterized. Moreover, the Gaussian three-user C-IFC is\nconsidered and the capacity results are derived for the Gaussian case. Some\nnumerical examples are also provided. \n\n"}
{"id": "1206.4358", "contents": "Title: Robust Detection of Dynamic Community Structure in Networks Abstract: We describe techniques for the robust detection of community structure in\nsome classes of time-dependent networks. Specifically, we consider the use of\nstatistical null models for facilitating the principled identification of\nstructural modules in semi-decomposable systems. Null models play an important\nrole both in the optimization of quality functions such as modularity and in\nthe subsequent assessment of the statistical validity of identified community\nstructure. We examine the sensitivity of such methods to model parameters and\nshow how comparisons to null models can help identify system scales. By\nconsidering a large number of optimizations, we quantify the variance of\nnetwork diagnostics over optimizations (`optimization variance') and over\nrandomizations of network structure (`randomization variance'). Because the\nmodularity quality function typically has a large number of nearly-degenerate\nlocal optima for networks constructed using real data, we develop a method to\nconstruct representative partitions that uses a null model to correct for\nstatistical noise in sets of partitions. To illustrate our results, we employ\nensembles of time-dependent networks extracted from both nonlinear oscillators\nand empirical neuroscience data. \n\n"}
{"id": "1206.4389", "contents": "Title: Improving Two-Way Selective Decode-and-forward Wireless Relaying with\n  Energy-Efficient One-bit Soft Forwarding Abstract: Motivated by applications such as battery-operated wireless sensor networks\n(WSN), we propose an easy-to-implement energy-efficient two-way relaying\nscheme. In particular, we address the challenge of improving the standard\ntwo-way selective decode-and-forward protocol (TW-SDF) in terms of\nblock-error-rate (BLER) with minor additional complexity and energy\nconsumption. By following the principle of soft relaying, our solution is the\ntwo-way one-bit soft forwarding (TW-1bSF) protocol in which the relay forwards\nthe one-bit quantization of a posterior information metric about the\ntransmitted bits, associated with an appropriately designed reliability\nparameter.\n  In WSN-related standards (such as IEEE802.15.6 and Bluetooth), block codes\nare adopted instead of convolutional and other sophisticated codes, due to\ntheir efficient decoder hardware implementation. As the second main\ncontribution, we derive tight upper bounds on the BLER performance for both\nTW-SDF and TW-1bSF, when the two-way relaying network employs block codes and\nhard decoding. The error probability analysis confirms the superiority of\nTW-1bSF. Moreover, we derive the asymptotic performance gain of TW-1bSF over\nTW-SDF, which further suggests that the proposed protocol is a good choice,\nespecially when long block codes are used. \n\n"}
{"id": "1206.4835", "contents": "Title: Complex Network Analysis in Cricket : Community structure, player's role\n  and performance index Abstract: This paper describes the applications of network methods for understanding\ninteraction within members of sport teams.We analyze the interaction of batsmen\nin International Cricket matches. We generate batting partnership network (BPN)\nfor different teams and determine the exact values of clustering coefficient,\naverage degree, average shortest path length of the networks and compare them\nwith the Erd\\text{\\\"{o}}s-R\\text{\\'{e}}nyi model. We observe that the networks\ndisplay small-world behavior and are disassortative in nature. We find that\nmost connected batsman is not necessarily the most central and most central\nplayers are not necessarily the one with high batting averages. We study the\ncommunity structure of the BPNs and identify each player's role based on\ninter-community and intra-community links. We observe that {\\it Sir DG\nBradman}, regarded as the best batsman in Cricket history does not occupy the\ncentral position in the network $-$ the so-called connector hub. We extend our\nanalysis to quantify the performance, relative importance and effect of\nremoving a player from the team, based on different centrality scores. \n\n"}
{"id": "1207.0865", "contents": "Title: Asymptotic normality of maximum likelihood and its variational\n  approximation for stochastic blockmodels Abstract: Variational methods for parameter estimation are an active research area,\npotentially offering computationally tractable heuristics with theoretical\nperformance bounds. We build on recent work that applies such methods to\nnetwork data, and establish asymptotic normality rates for parameter estimates\nof stochastic blockmodel data, by either maximum likelihood or variational\nestimation. The result also applies to various sub-models of the stochastic\nblockmodel found in the literature. \n\n"}
{"id": "1207.1497", "contents": "Title: Hidden Markov models for the activity profile of terrorist groups Abstract: The main focus of this work is on developing models for the activity profile\nof a terrorist group, detecting sudden spurts and downfalls in this profile,\nand, in general, tracking it over a period of time. Toward this goal, a\n$d$-state hidden Markov model (HMM) that captures the latent states underlying\nthe dynamics of the group and thus its activity profile is developed. The\nsimplest setting of $d=2$ corresponds to the case where the dynamics are\ncoarsely quantized as Active and Inactive, respectively. A state estimation\nstrategy that exploits the underlying HMM structure is then developed for spurt\ndetection and tracking. This strategy is shown to track even nonpersistent\nchanges that last only for a short duration at the cost of learning the\nunderlying model. Case studies with real terrorism data from open-source\ndatabases are provided to illustrate the performance of the proposed\nmethodology. \n\n"}
{"id": "1207.3745", "contents": "Title: Influence of opinion dynamics on the evolution of games Abstract: Under certain circumstances such as lack of information or bounded\nrationality, human players can take decisions on which strategy to choose in a\ngame on the basis of simple opinions. These opinions can be modified after each\nround by observing own or others payoff results but can be also modified after\ninterchanging impressions with other players. In this way, the update of the\nstrategies can become a question that goes beyond simple evolutionary rules\nbased on fitness and become a social issue. In this work, we explore this\nscenario by coupling a game with an opinion dynamics model. The opinion is\nrepresented by a continuous variable that corresponds to the certainty of the\nagents respect to which strategy is best. The opinions transform into actions\nby making the selection of an strategy a stochastic event with a probability\nregulated by the opinion. A certain regard for the previous round payoff is\nincluded but the main update rules of the opinion are given by a model inspired\nin social interchanges. We find that the dynamics fixed points of the coupled\nmodel is different from those of the evolutionary game or the opinion models\nalone. Furthermore, new features emerge such as the resilience of the fraction\nof cooperators to the topology of the social interaction network or to the\npresence of a small fraction of extremist players. \n\n"}
{"id": "1207.4567", "contents": "Title: Efficient Core Maintenance in Large Dynamic Graphs Abstract: The $k$-core decomposition in a graph is a fundamental problem for social\nnetwork analysis. The problem of $k$-core decomposition is to calculate the\ncore number for every node in a graph. Previous studies mainly focus on\n$k$-core decomposition in a static graph. There exists a linear time algorithm\nfor $k$-core decomposition in a static graph. However, in many real-world\napplications such as online social networks and the Internet, the graph\ntypically evolves over time. Under such applications, a key issue is to\nmaintain the core number of nodes given the graph changes over time. A simple\nimplementation is to perform the linear time algorithm to recompute the core\nnumber for every node after the graph is updated. Such simple implementation is\nexpensive when the graph is very large. In this paper, we propose a new\nefficient algorithm to maintain the core number for every node in a dynamic\ngraph. Our main result is that only certain nodes need to update their core\nnumber given the graph is changed by inserting/deleting an edge. We devise an\nefficient algorithm to identify and recompute the core number of such nodes.\nThe complexity of our algorithm is independent of the graph size. In addition,\nto further accelerate the algorithm, we develop two pruning strategies by\nexploiting the lower and upper bounds of the core number. Finally, we conduct\nextensive experiments over both real-world and synthetic datasets, and the\nresults demonstrate the efficiency of the proposed algorithm. \n\n"}
{"id": "1207.4587", "contents": "Title: Causal relay networks Abstract: In this paper, we study causal discrete-memoryless relay networks (DMRNs).\nThe network consists of multiple nodes, each of which can be a source, relay,\nand/or destination. In the network, there are two types of relays, i.e., relays\nwith one sample delay (strictly causal) and relays without delay (causal) whose\ntransmit signal depends not only on the past received symbols but also on the\ncurrent received symbol. For this network, we derive two new cut-set bounds,\none when the causal relays have their own messages and the other when not.\nUsing examples of a causal vector Gaussian two-way relay channel and a causal\nvector Gaussian relay channel, we show that the new cut-set bounds can be\nachieved by a simple amplify-and-forward type relaying. Our result for the\ncausal relay channel strengthens the previously known capacity result for the\nsame channel by El Gamal, Hassanpour, and Mammen. \n\n"}
{"id": "1207.7261", "contents": "Title: Dynamical phase transition due to preferential cluster growth of\n  collective emotions in online communities Abstract: We consider a preferential cluster growth in a one-dimensional stochastic\nmodel describing the dynamics of a binary chain with long-range memory. The\nmodel is driven by data corresponding to emotional patterns observed during\nonline communities' discussions. The system undergoes a dynamical phase\ntransition. For low values of the preference exponent, both states are observed\nduring the string evolution in the majority of simulated discussion threads.\nWhen the exponent crosses a critical value, in the majority of threads an\nordered phase emerges, i.e. from a certain time moment only one state is\nrepresented. The transition becomes discontinuous in the thermodynamical limit\nwhen the discussions are infinitely long and even an infinitely small\npreference exponent leads to the ordering behavior in every discussion thread.\nNumerical simulations are in a good agreement with approximated analytical\nformula. \n\n"}
{"id": "1208.2900", "contents": "Title: On Achievable Degrees of Freedom for MIMO X Channels Abstract: In this paper, the achievable DoF of MIMO X channels for constant channel\ncoefficients with $M_t$ antennas at transmitter $t$ and $N_r$ antennas at\nreceiver $r$ ($t,r=1,2$) is studied. A spatial interference alignment and\ncancelation scheme is proposed to achieve the maximum DoF of the MIMO X\nchannels. The scenario of $M_1\\geq M_2\\geq N_1\\geq N_2$ is first considered and\ndivided into 3 cases, $3N_2<M_1+M_2<2N_1+N_2$ (Case $A$), $M_1+M_2\\geq2N_1+N_2$\n(Case $B$), and $M_1+M_2\\leq3N_2$ (Case $C$). With the proposed scheme, it is\nshown that in Case $A$, the outer-bound $\\frac{M_1+M_2+N_2}{2}$ is achievable;\nin Case $B$, the achievable DoF equals the outer-bound $N_1+N_2$ if $M_2>N_1$,\notherwise it is 1/2 or 1 less than the outer-bound; in Case $C$, the achievable\nDoF is equal to the outer-bound $2/3(M_1+M_2)$ if $(3N_2-M_1-M_2)\\mod 3=0$, and\nit is 1/3 or 1/6 less than the outer-bound if $(3N_2-M_1-M_2)\\mod 3=1\n\\mathrm{or} 2$. In the scenario of $M_t\\leq N_r$, the exact symmetrical results\nof DoF can be obtained. \n\n"}
{"id": "1208.4651", "contents": "Title: Throughput Maximization for an Energy Harvesting Communication System\n  with Processing Cost Abstract: In wireless networks, energy consumed for communication includes both the\ntransmission and the processing energy. In this paper, point-to-point\ncommunication over a fading channel with an energy harvesting transmitter is\nstudied considering jointly the energy costs of transmission and processing.\nUnder the assumption of known energy arrival and fading profiles, optimal\ntransmission policy for throughput maximization is investigated. Assuming that\nthe transmitter has sufficient amount of data in its buffer at the beginning of\nthe transmission period, the average throughput by a given deadline is\nmaximized. Furthermore, a \"directional glue pouring algorithm\" that computes\nthe optimal transmission policy is described. \n\n"}
{"id": "1209.2486", "contents": "Title: On sampling social networking services Abstract: This article aims at summarizing the existing methods for sampling social\nnetworking services and proposing a faster confidence interval for related\nsampling methods. It also includes comparisons of common network sampling\ntechniques. \n\n"}
{"id": "1209.3505", "contents": "Title: Cognitive Energy Harvesting and Transmission from a Network Perspective Abstract: Wireless networks can be self-sustaining by harvesting energy from\nradio-frequency (RF) signals. Building on classic cognitive radio networks, we\npropose a novel method for network coexisting where mobiles from a secondary\nnetwork, called secondary transmitters (STs), either harvest energy from\ntransmissions by nearby transmitters from a primary network, called primary\ntransmitters (PTs), or transmit information if PTs are sufficiently far away;\nSTs store harvested energy in rechargeable batteries with finite capacity and\nuse all available energy for subsequent transmission when batteries are fully\ncharged. In this model, each PT is centered at a guard zone and a harvesting\nzone that are disks with given radiuses; a ST harvests energy if it lies in\nsome harvesting zone, transmits fixed-power signals if it is outside all guard\nzones or else idles. Based on this model, the spatial throughput of the\nsecondary network is maximized using a stochastic-geometry model where PTs and\nSTs are modeled as independent homogeneous Poisson point processes (HPPPs),\nunder the outage constraints for coexisting networks and obtained in a simple\nclosed-form. It is observed from the result that the maximum secondary\nthroughput decreases linearly with the growing PT density, and the optimal ST\ndensity is inversely proportional to the derived transmission probability for\nSTs. \n\n"}
{"id": "1209.5779", "contents": "Title: Chance Constrained Optimal Power Flow: Risk-Aware Network Control under\n  Uncertainty Abstract: When uncontrollable resources fluctuate, Optimum Power Flow (OPF), routinely\nused by the electric power industry to re-dispatch hourly controllable\ngeneration (coal, gas and hydro plants) over control areas of transmission\nnetworks, can result in grid instability, and, potentially, cascading outages.\nThis risk arises because OPF dispatch is computed without awareness of major\nuncertainty, in particular fluctuations in renewable output. As a result, grid\noperation under OPF with renewable variability can lead to frequent conditions\nwhere power line flow ratings are significantly exceeded. Such a condition,\nwhich is borne by simulations of real grids, would likely resulting in\nautomatic line tripping to protect lines from thermal stress, a risky and\nundesirable outcome which compromises stability. Smart grid goals include a\ncommitment to large penetration of highly fluctuating renewables, thus calling\nto reconsider current practices, in particular the use of standard OPF. Our\nChance Constrained (CC) OPF corrects the problem and mitigates dangerous\nrenewable fluctuations with minimal changes in the current operational\nprocedure. Assuming availability of a reliable wind forecast parameterizing the\ndistribution function of the uncertain generation, our CC-OPF satisfies all the\nconstraints with high probability while simultaneously minimizing the cost of\neconomic re-dispatch. CC-OPF allows efficient implementation, e.g. solving a\ntypical instance over the 2746-bus Polish network in 20 seconds on a standard\nlaptop. \n\n"}
{"id": "1210.1266", "contents": "Title: Nonanticipative Rate Distortion Function and Relations to Filtering\n  Theory Abstract: The relation between nonanticipative Rate Distortion Function (RDF) and\nfiltering theory is discussed on abstract spaces. The relation is established\nby imposing a realizability constraint on the reconstruction conditional\ndistribution of the classical RDF. Existence of the extremum solution of the\nnonanticipative RDF is shown using weak$^*$-convergence on appropriate\ntopology. The extremum reconstruction conditional distribution is derived in\nclosed form, for the case of stationary processes. The realization of the\nreconstruction conditional distribution which achieves the infimum of the\nnonanticipative RDF is described. Finally, an example is presented to\nillustrate the concepts. \n\n"}
{"id": "1210.1892", "contents": "Title: On Constant Gaps for the Two-way Gaussian Interference Channel Abstract: We introduce the two-way Gaussian interference channel in which there are\nfour nodes with four independent messages: two-messages to be transmitted over\na Gaussian interference channel in the $\\rightarrow$ direction, simultaneously\nwith two-messages to be transmitted over an interference channel (in-band,\nfull-duplex) in the $\\leftarrow$ direction. In such a two-way network, all\nnodes are transmitters and receivers of messages, allowing them to adapt\ncurrent channel inputs to previously received channel outputs. We propose two\nnew outer bounds on the symmetric sum-rate for the two-way Gaussian\ninterference channel with complex channel gains: one under full adaptation (all\n4 nodes are permitted to adapt inputs to previous outputs), and one under\npartial adaptation (only 2 nodes are permitted to adapt, the other 2 are\nrestricted). We show that simple non-adaptive schemes such as the Han and\nKobayashi scheme, where inputs are functions of messages only and not past\noutputs, utilized in each direction are sufficient to achieve within a constant\ngap of these fully or partially adaptive outer bounds for all channel regimes. \n\n"}
{"id": "1210.3101", "contents": "Title: Unique Decoding of General AG Codes Abstract: A unique decoding algorithm for general AG codes, namely multipoint\nevaluation codes on algebraic curves, is presented. It is a natural\ngeneralization of the previous decoding algorithm which was only for one-point\nAG codes. As such, it retains the same advantages of fast speed and regular\nstructure with the previous algorithm. Compared with other known decoding\nalgorithms for general AG codes, it is much simpler in its description and\nimplementation. \n\n"}
{"id": "1210.3563", "contents": "Title: Degrees of Freedom of Multi-hop MIMO Broadcast Networks with Delayed\n  CSIT Abstract: We study the sum degrees of freedom (DoF) of a class of multi-layer\nrelay-aided MIMO broadcast networks with delayed channel state information at\ntransmitters (CSIT). In the assumed network a K-antenna source intends to\ncommunicate to K single-antenna destinations, with the help of N-2 layers of K\nfull-duplex single-antenna relays. We consider two practical delayed CSIT\nfeedback scenarios. If the source can obtain the CSI feedback signals from all\nlayers, we prove the optimal sum DoF of the network to be K/(1+1/2+...+1/K). If\nthe CSI feedback is only within each hop, we show that when K=2 the optimal sum\nDoF is 4/3, and when K >= 3 the sum DoF 3/2 is achievable. Our results reveal\nthat the sum DoF performance in the considered class of N-layer MIMO broadcast\nnetworks with delayed CSIT may depend not on N, the number of layers in the\nnetwork, but only on K, the number of antennas/terminals in each layer. \n\n"}
{"id": "1210.4301", "contents": "Title: Reputation Aggregation in Peer-to-Peer Network Using Differential Gossip\n  Algorithm Abstract: Reputation aggregation in peer to peer networks is generally a very time and\nresource consuming process. Moreover, most of the methods consider that a node\nwill have same reputation with all the nodes in the network, which is not true.\nThis paper proposes a reputation aggregation algorithm that uses a variant of\ngossip algorithm called differential gossip. In this paper, estimate of\nreputation is considered to be having two parts, one common component which is\nsame with every node, and the other one is information received from immediate\nneighbours based on the neighbours' direct interaction with the node. The\ndifferential gossip is fast and requires less amount of resources. This\nmechanism allows computation of independent reputation value by a node, of\nevery other node in the network, for each node. The differential gossip trust\nhas been investigated for a power law network formed using preferential\nattachment \\emph{(PA)} Model. The reputation computed using differential gossip\ntrust shows good amount of immunity to the collusion. We have verified the\nperformance of the algorithm on the power law networks of different sizes\nranging from 100 nodes to 50,000 nodes. \n\n"}
{"id": "1210.4700", "contents": "Title: Optimal Lempel-Ziv based lossy compression for memoryless data: how to\n  make the right mistakes Abstract: Compression refers to encoding data using bits, so that the representation\nuses as few bits as possible. Compression could be lossless: i.e. encoded data\ncan be recovered exactly from its representation) or lossy where the data is\ncompressed more than the lossless case, but can still be recovered to within\nprespecified distortion metric. In this paper, we prove the optimality of\nCodelet Parsing, a quasi-linear time algorithm for lossy compression of\nsequences of bits that are independently and identically distributed (\\iid) and\nHamming distortion. Codelet Parsing extends the lossless Lempel Ziv algorithm\nto the lossy case---a task that has been a focus of the source coding\nliterature for better part of two decades now. Given \\iid sequences $\\x$, the\nexpected length of the shortest lossy representation such that $\\x$ can be\nreconstructed to within distortion $\\dist$ is given by the rate distortion\nfunction, $\\rd$. We prove the optimality of the Codelet Parsing algorithm for\nlossy compression of memoryless bit sequences. It splits the input sequence\nnaturally into phrases, representing each phrase by a codelet, a potentially\ndistorted phrase of the same length. The codelets in the lossy representation\nof a length-$n$ string ${\\x}$ have length roughly $(\\log n)/\\rd$, and like the\nlossless Lempel Ziv algorithm, Codelet Parsing constructs codebooks logarithmic\nin the sequence length. \n\n"}
{"id": "1210.6044", "contents": "Title: Multistable binary decision making on networks Abstract: We propose a simple model for a binary decision making process on a graph,\nmotivated by modeling social decision making with cooperative individuals. The\nmodel is similar to a random field Ising model or fiber bundle model, but with\nkey differences on heterogeneous networks. For many types of disorder and\ninteractions between the nodes, we predict discontinuous phase transitions with\nmean field theory which are largely independent of network structure. We show\nhow these phase transitions can also be understood by studying microscopic\navalanches, and describe how network structure enhances fluctuations in the\ndistribution of avalanches. We suggest theoretically the existence of a\n\"glassy\" spectrum of equilibria associated with a typical phase, even on\ninfinite graphs, so long as the first moment of the degree distribution is\nfinite. This behavior implies that the model is robust against noise below a\ncertain scale, and also that phase transitions can switch from discontinuous to\ncontinuous on networks with too few edges. Numerical simulations suggest that\nour theory is accurate. \n\n"}
{"id": "1210.6508", "contents": "Title: An algebraic approach to project schedule development under precedence\n  constraints Abstract: An approach to schedule development in project management is developed within\nthe framework of idempotent algebra. The approach offers a way to represent\nprecedence relationships among activities in projects as linear vector\nequations in terms of an idempotent semiring. As a result, many issues in\nproject scheduling reduce to solving computational problems in the idempotent\nalgebra setting, including linear equations and eigenvalue-eigenvector\nproblems. The solutions to the problems are given in a compact vector form that\nprovides the basis for the development of efficient computation procedures and\nrelated software applications. \n\n"}
{"id": "1210.7335", "contents": "Title: Professional diversity and the productivity of cities Abstract: The relationships between diversity, productivity and scale determine much of\nthe structure and robustness of complex biological and social systems. While\narguments for the link between specialization and productivity are common,\ndiversity has often been invoked as a hedging strategy, allowing systems to\nevolve in response to environmental change. Despite their general appeal, these\narguments have not typically produced quantitative predictions for optimal\nlevels of functional diversity consistent with observations. One important\nreason why these relationships have resisted formalization is the idiosyncratic\nnature of diversity measures, which depend on given classification schemes.\nHere, we address these issues by analyzing the statistics of professions in\ncities and show how their probability distribution takes a universal\nscale-invariant form, common to all cities, obtained in the limit of infinite\nresolution of given taxonomies. We propose a model that generates the form and\nparameters of this distribution via the introduction of new occupations at a\nrate leading to individual specialization subject to the preservation of access\nto overall function via their ego social networks. This perspective unifies\nideas about the importance of network structure in ecology and of innovation as\na recombinatory process with economic concepts of productivity gains obtained\nthrough the division and coordination of labor, stimulated by scale. \n\n"}
{"id": "1210.7711", "contents": "Title: Refined support and entropic uncertainty inequalities Abstract: Generalized versions of the entropic (Hirschman-Beckner) and support\n(Elad-Bruckstein) uncertainty principle are presented for frames\nrepresentations. Moreover, a sharpened version of the support inequality has\nbeen obtained by introducing a generalization of the coherence. In the finite\ndimensional case and under certain conditions, minimizers of this inequalities\nare given as constant functions on their support. In addition, $\\ell^p$-norms\ninequalities are introduced as byproducts of the entropic inequalities. \n\n"}
{"id": "1211.0169", "contents": "Title: Multi-Stratum Networks: toward a unified model of on-line identities Abstract: One of the reasons behind the success of Social Network Analysis is its\nsimple and general graph model made of nodes (representing individuals) and\nties. However, when we focus on our daily on-line experience we must confront a\nmore complex scenario: people inhabitate several on-line spaces interacting to\nseveral communities active on various technological infrastructures like\nTwitter, Facebook, YouTube or FourSquare and with distinct social objectives.\nThis constitutes a complex network of interconnected networks where users'\nidentities are spread and where information propagates navigating through\ndifferent communities and social platforms. In this article we introduce a\nmodel for this layered scenario that we call multi-stratum network. Through a\ntheoretical discussion and the analysis of real-world data we show how not only\nfocusing on a single network may provide a very partial understanding of the\nrole of its users, but also that considering all the networks separately may\nnot reveal the information contained in the whole multi-stratum model. \n\n"}
{"id": "1211.1138", "contents": "Title: Motion Planning for Continuous Time Stochastic Processes: A Dynamic\n  Programming Approach Abstract: We study stochastic motion planning problems which involve a controlled\nprocess, with possibly discontinuous sample paths, visiting certain subsets of\nthe state-space while avoiding others in a sequential fashion. For this\npurpose, we first introduce two basic notions of motion planning, and then\nestablish a connection to a class of stochastic optimal control problems\nconcerned with sequential stopping times. A weak dynamic programming principle\n(DPP) is then proposed, which characterizes the set of initial states that\nadmit a control enabling the process to execute the desired maneuver with\nprobability no less than some pre-specified value. The proposed DPP comprises\nauxiliary value functions defined in terms of discontinuous payoff functions. A\nconcrete instance of the use of this novel DPP in the case of diffusion\nprocesses is also presented. In this case, we establish that the aforementioned\nset of initial states can be characterized as the level set of a discontinuous\nviscosity solution to a sequence of partial differential equations, for which\nthe first one has a known boundary condition, while the boundary conditions of\nthe subsequent ones are determined by the solutions to the preceding steps.\nFinally, the generality and flexibility of the theoretical results are\nillustrated on an example involving biological switches. \n\n"}
{"id": "1211.2874", "contents": "Title: Diversity of individual mobility patterns and emergence of aggregated\n  scaling laws Abstract: Uncovering human mobility patterns is of fundamental importance to the\nunderstanding of epidemic spreading, urban transportation and other\nsocioeconomic dynamics embodying spatiality and human travel. According to the\ndirect travel diaries of volunteers, we show the absence of scaling properties\nin the displacement distribution at the individual level,while the aggregated\ndisplacement distribution follows a power law with an exponential cutoff. Given\nthe constraint on total travelling cost, this aggregated scaling law can be\nanalytically predicted by the mixture nature of human travel under the\nprinciple of maximum entropy. A direct corollary of such theory is that the\ndisplacement distribution of a single mode of transportation should follow an\nexponential law, which also gets supportive evidences in known data. We thus\nconclude that the travelling cost shapes the displacement distribution at the\naggregated level. \n\n"}
{"id": "1211.3729", "contents": "Title: Data-Efficient Quickest Change Detection in Minimax Settings Abstract: The classical problem of quickest change detection is studied with an\nadditional constraint on the cost of observations used in the detection\nprocess. The change point is modeled as an unknown constant, and minimax\nformulations are proposed for the problem. The objective in these formulations\nis to find a stopping time and an on-off observation control policy for the\nobservation sequence, to minimize a version of the worst possible average\ndelay, subject to constraints on the false alarm rate and the fraction of time\nobservations are taken before change. An algorithm called DE-CuSum is proposed\nand is shown to be asymptotically optimal for the proposed formulations, as the\nfalse alarm rate goes to zero. Numerical results are used to show that the\nDE-CuSum algorithm has good trade-off curves and performs significantly better\nthan the approach of fractional sampling, in which the observations are skipped\nusing the outcome of a sequence of coin tosses, independent of the observation\nprocess. This work is guided by the insights gained from an earlier study of a\nBayesian version of this problem. \n\n"}
{"id": "1211.5484", "contents": "Title: Ranking the Importance of Nodes of Complex Networks by the Equivalence\n  Classes Approach Abstract: Identifying the importance of nodes of complex networks is of interest to the\nresearch of Social Networks, Biological Networks etc.. Current researchers have\nproposed several measures or algorithms, such as betweenness, PageRank and HITS\netc., to identify the node importance. However, these measures are based on\ndifferent aspects of properties of nodes, and often conflict with the others. A\nreasonable, fair standard is needed for evaluating and comparing these\nalgorithms. This paper develops a framework as the standard for ranking the\nimportance of nodes. Four intuitive rules are suggested to measure the node\nimportance, and the equivalence classes approach is employed to resolve the\nconflicts and aggregate the results of the rules. To quantitatively compare the\nalgorithms, the performance indicators are also proposed based on a similarity\nmeasure. Three widely used real-world networks are used as the test-beds. The\nexperimental results illustrate the feasibility of this framework and show that\nboth algorithms, PageRank and HITS, perform well with bias when dealing with\nthe tested networks. Furthermore, this paper uses the proposed approach to\nanalyze the structure of the Internet, and draws out the kernel of the Internet\nwith dense links. \n\n"}
{"id": "1211.5611", "contents": "Title: Distributed Random Projection Algorithm for Convex Optimization Abstract: Random projection algorithm is an iterative gradient method with random\nprojections. Such an algorithm is of interest for constrained optimization when\nthe constraint set is not known in advance or the projection operation on the\nwhole constraint set is computationally prohibitive. This paper presents a\ndistributed random projection (DRP) algorithm for fully distributed constrained\nconvex optimization problems that can be used by multiple agents connected over\na time-varying network, where each agent has its own objective function and its\nown constrained set. With reasonable assumptions, we prove that the iterates of\nall agents converge to the same point in the optimal set almost surely. In\naddition, we consider a variant of the method that uses a mini-batch of\nconsecutive random projections and establish its convergence in almost sure\nsense. Experiments on distributed support vector machines demonstrate fast\nconvergence of the algorithm. It actually shows that the number of iteration\nrequired until convergence is much smaller than scanning over all training\nsamples just once. \n\n"}
{"id": "1211.6496", "contents": "Title: TwitterPaul: Extracting and Aggregating Twitter Predictions Abstract: This paper introduces TwitterPaul, a system designed to make use of Social\nMedia data to help to predict game outcomes for the 2010 FIFA World Cup\ntournament. To this end, we extracted over 538K mentions to football games from\na large sample of tweets that occurred during the World Cup, and we classified\ninto different types with a precision of up to 88%. The different mentions were\naggregated in order to make predictions about the outcomes of the actual games.\nWe attempt to learn which Twitter users are accurate predictors and explore\nseveral techniques in order to exploit this information to make more accurate\npredictions. We compare our results to strong baselines and against the betting\nline (prediction market) and found that the quality of extractions is more\nimportant than the quantity, suggesting that high precision methods working on\na medium-sized dataset are preferable over low precision methods that use a\nlarger amount of data. Finally, by aggregating some classes of predictions, the\nsystem performance is close to the one of the betting line. Furthermore, we\nbelieve that this domain independent framework can help to predict other\nsports, elections, product release dates and other future events that people\ntalk about in social media. \n\n"}
{"id": "1212.0895", "contents": "Title: The max-plus algebra approach in modelling of queueing networks Abstract: A class of queueing networks which consist of single-server fork-join nodes\nwith infinite buffers is examined to derive a representation of the network\ndynamics in terms of max-plus algebra. For the networks, we present a common\ndynamic state equation which relates the departure epochs of customers from the\nnetwork nodes in an explicit vector form determined by a state transition\nmatrix. We show how the matrix may be calculated from the service time of\ncustomers in the general case, and give examples of matrices inherent in\nparticular networks. \n\n"}
{"id": "1212.1061", "contents": "Title: Study of a Market Model with Conservative Exchanges on Complex Networks Abstract: Many models of market dynamics make use of the idea of conservative wealth\nexchanges among economic agents. A few years ago an exchange model using\nextremal dynamics was developed and a very interesting result was obtained: a\nself-generated minimum wealth or poverty line. On the other hand, the wealth\ndistribution exhibited an exponential shape as a function of the square of the\nwealth. These results have been obtained both considering exchanges between\nnearest neighbors or in a mean field scheme. In the present paper we study the\neffect of distributing the agents on a complex network. We have considered\narchetypical complex networks: Erd\\\"{o}s-R\\'enyi random networks and scale-free\nnetworks. The presence of a poverty line with finite wealth is preserved but\nspatial correlations are important, particularly between the degree of the node\nand the wealth. We present a detailed study of the correlations, as well as the\nchanges in the Gini coefficient, that measures the inequality, as a function of\nthe type and average degree of the considered networks. \n\n"}
{"id": "1212.2142", "contents": "Title: Universality in voting behavior: an empirical analysis Abstract: Election data represent a precious source of information to study human\nbehavior at a large scale. In proportional elections with open lists, the\nnumber of votes received by a candidate, rescaled by the average performance of\nall competitors in the same party list, has the same distribution regardless of\nthe country and the year of the election. Here we provide the first thorough\nassessment of this claim. We analyzed election datasets of 15 countries with\nproportional systems. We confirm that a class of nations with similar election\nrules fulfill the universality claim. Discrepancies from this trend in other\ncountries with open-lists elections are always associated with peculiar\ndifferences in the election rules, which matter more than differences between\ncountries and historical periods. Our analysis shows that the role of parties\nin the electoral performance of candidates is crucial: alternative scalings not\ntaking into account party affiliations lead to poor results. \n\n"}
{"id": "1212.3376", "contents": "Title: Linearly Reconfigurable Kalman Filtering for a Vector Process Abstract: In this paper, we consider a dynamic linear system in state-space form where\nthe observation equation depends linearly on a set of parameters. We address\nthe problem of how to dynamically calculate these parameters in order to\nminimize the mean-squared error (MSE) of the state estimate achieved by a\nKalman filter. We formulate and solve two kinds of problems under a quadratic\nconstraint on the observation parameters: minimizing the sum MSE (Min-Sum-MSE)\nor minimizing the maximum MSE (Min-Max-MSE). In each case, the optimization\nproblem is divided into two sub-problems for which optimal solutions can be\nfound: a semidefinite programming (SDP) problem followed by a constrained\nleast-squares minimization. A more direct solution is shown to exist for the\nspecial case of a scalar observation; in particular, the Min-Sum-MSE solution\ncan be found directly using a generalized eigendecomposition, and is optimally\nsolved utilizing Rayleigh quotient, and the Min-Max-MSE problem reduces to an\nSDP feasibility test that can be solved via the bisection method. \n\n"}
{"id": "1212.3621", "contents": "Title: Local Irreducibility of Tail-Biting Trellises Abstract: This paper investigates tail-biting trellis realizations for linear block\ncodes. Intrinsic trellis properties are used to characterize irreducibility on\ngiven intervals of the time axis. It proves beneficial to always consider the\ntrellis and its dual simultaneously. A major role is played by trellis\nproperties that amount to observability and controllability for fragments of\nthe trellis of various lengths. For fragments of length less than the minimum\nspan length of the code it is shown that fragment observability and fragment\ncontrollability are equivalent to irreducibility. For reducible trellises, a\nconstructive reduction procedure is presented. The considerations also lead to\na characterization for when the dual of a trellis allows a product\nfactorization into elementary (\"atomic\") trellises. \n\n"}
{"id": "1212.6009", "contents": "Title: Distributed Sparse Signal Recovery For Sensor Networks Abstract: We propose a distributed algorithm for sparse signal recovery in sensor\nnetworks based on Iterative Hard Thresholding (IHT). Every agent has a set of\nmeasurements of a signal x, and the objective is for the agents to recover x\nfrom their collective measurements at a minimal communication cost and with low\ncomputational complexity. A naive distributed implementation of IHT would\nrequire global communication of every agent's full state in each iteration. We\nfind that we can dramatically reduce this communication cost by leveraging\nsolutions to the distributed top-K problem in the database literature.\nEvaluations show that our algorithm requires up to three orders of magnitude\nless total bandwidth than the best-known distributed basis pursuit method. \n\n"}
{"id": "1212.6079", "contents": "Title: Evaluation of the Lyapunov exponent for generalized linear second-order\n  exponential systems Abstract: We consider generalized linear stochastic dynamical systems with second-order\nstate transition matrices. The entries of the matrix are assumed to be either\nindependent and exponentially distributed or equal to zero. We give an overview\nof new results on evaluation of asymptotic growth rate of the system state\nvector, which is called the Lyapunov exponent of the system. \n\n"}
{"id": "1301.0954", "contents": "Title: Cellular Systems with Many Antennas: Large System Analysis under Pilot\n  Contamination Abstract: Base stations with a large number of transmit antennas have the potential to\nserve a large number of users simultaneously at higher rates. They also promise\na lower power consumption due to coherent combining at the receiver. However,\nthe receiver processing in the uplink relies on the channel estimates which are\nknown to suffer from pilot interference. In this work, we perform an uplink\nlarge system analysis of multi-cell multi-antenna system when the receiver\nemploys a matched filtering with a pilot contaminated estimate. We find the\nasymptotic Signal to Interference plus Noise Ratio (SINR) as the number of\nantennas and number of users per base station grow large while maintaining a\nfixed ratio. To do this, we make use of the similarity of the uplink received\nsignal in a multi-antenna system to the representation of the received signal\nin CDMA systems. The asymptotic SINR expression explicitly captures the effect\nof pilot contamination and that of interference averaging. This also explains\nthe SINR performance of receiver processing schemes at different regimes such\nas instances when the number of antennas are comparable to number of users as\nwell as when antennas exceed greatly the number of users. Finally, we also\npropose that the adaptive MMSE symbol detection scheme, which does not require\nthe explicit channel knowledge, can be employed for cellular systems with large\nnumber of antennas. \n\n"}
{"id": "1301.2138", "contents": "Title: On the Degrees of Freedom of the K-User Time Correlated Broadcast\n  Channel with Delayed CSIT Abstract: The Degrees of Freedom (DoF) of a K-User MISO Broadcast Channel (BC) is\nstudied when the Transmitter (TX) has access to a delayed channel estimate in\naddition to an imperfect estimate of the current channel. The current estimate\ncould be for example obtained from prediction applied on past estimates, in the\ncase where feedback delay is within the coherence time. Building on previous\nrecent works on this setting with two users, the estimation error of the\ncurrent channel is characterized by its scaling as P at the exponent \\alpha,\nwhere \\alpha=1 (resp. \\alpha=0) corresponds to an estimate being essentially\nperfect (resp. useless) in terms of DoF. In this work, we contribute to the\ncharacterization of the DoF region in such a setting by deriving an outerbound\nfor the DoF region and by providing an achievable DoF region. The achievable\nDoF is obtained by developing a new alignment scheme, called the K\\alpha-MAT\nscheme, which builds upon both the principle of the MAT alignment scheme from\nMaddah-Ali and Tse and Zero-Forcing to achieve a larger DoF when the delayed\nCSIT received is correlated with the instantaneous channel state. \n\n"}
{"id": "1301.2464", "contents": "Title: Time as a limited resource: Communication Strategy in Mobile Phone\n  Networks Abstract: We used a large database of 9 billion calls from 20 million mobile users to\nexamine the relationships between aggregated time spent on the phone, personal\nnetwork size, tie strength and the way in which users distributed their limited\ntime across their network (disparity). Compared to those with smaller networks,\nthose with large networks did not devote proportionally more time to\ncommunication and had on average weaker ties (as measured by time spent\ncommunicating). Further, there were not substantially different levels of\ndisparity between individuals, in that mobile users tend to distribute their\ntime very unevenly across their network, with a large proportion of calls going\nto a small number of individuals. Together, these results suggest that there\nare time constraints which limit tie strength in large personal networks, and\nthat even high levels of mobile communication do not fundamentally alter the\ndisparity of time allocation across networks. \n\n"}
{"id": "1301.2603", "contents": "Title: Robust subspace clustering Abstract: Subspace clustering refers to the task of finding a multi-subspace\nrepresentation that best fits a collection of points taken from a\nhigh-dimensional space. This paper introduces an algorithm inspired by sparse\nsubspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern\nRecognition, CVPR (2009) 2790-2797] to cluster noisy data, and develops some\nnovel theory demonstrating its correctness. In particular, the theory uses\nideas from geometric functional analysis to show that the algorithm can\naccurately recover the underlying subspaces under minimal requirements on their\norientation, and on the number of samples per subspace. Synthetic as well as\nreal data experiments complement our theoretical study, illustrating our\napproach and demonstrating its effectiveness. \n\n"}
{"id": "1301.2995", "contents": "Title: Measuring Cultural Dynamics Through the Eurovision Song Contest Abstract: Measuring culture and its dynamics through surveys has important limitations,\nbut the emerging field of computational social science allows us to overcome\nthem by analyzing large-scale datasets. In this article, we study cultural\ndynamics through the votes in the Eurovision song contest, which are decided by\na crowd-based scheme in which viewers vote through mobile phone messages.\nTaking into account asymmetries and imperfect perception of culture, we measure\ncultural relations among European countries in terms of cultural affinity. We\npropose the Friend-or-Foe coefficient, a metric to measure voting biases among\nparticipants of a Eurovision contest. We validate how this metric represents\ncultural affinity through its relation with known cultural distances, and\nthrough numerical analysis of biased Eurovision contests. We apply this metric\nto the historical set of Eurovision contests from 1975 to 2012, finding new\npatterns of stronger modularity than using votes alone. Furthermore, we define\na measure of polarization that, when applied to empirical data, shows a sharp\nincrease within EU countries during 2010 and 2011. We empirically validate the\nrelation between this polarization and economic indicators in the EU, showing\nhow political decisions influence both the economy and the way citizens relate\nto the culture of other EU members. \n\n"}
{"id": "1301.3676", "contents": "Title: Duality and Network Theory in Passivity-based Cooperative Control Abstract: This paper presents a class of passivity-based cooperative control problems\nthat have an explicit connection to convex network optimization problems. The\nnew notion of maximal equilibrium independent passivity is introduced and it is\nshown that networks of systems possessing this property asymptotically approach\nthe solutions of a dual pair of network optimization problems, namely an\noptimal potential and an optimal flow problem. This connection leads to an\ninterpretation of the dynamic variables, such as system inputs and outputs, to\nvariables in a network optimization framework, such as divergences and\npotentials, and reveals that several duality relations known in convex network\noptimization theory translate directly to passivity-based cooperative control\nproblems. The presented results establish a strong and explicit connection\nbetween passivity-based cooperative control theory on the one side and network\noptimization theory on the other, and they provide a unifying framework for\nnetwork analysis and optimal design. The results are illustrated on a nonlinear\ntraffic dynamics model that is shown to be asymptotically clustering. \n\n"}
{"id": "1301.4927", "contents": "Title: \"Pretty strong\" converse for the quantum capacity of degradable channels Abstract: We exhibit a possible road towards a strong converse for the quantum capacity\nof degradable channels. In particular, we show that all degradable channels\nobey what we call a \"pretty strong\" converse: When the code rate increases\nabove the quantum capacity, the fidelity makes a discontinuous jump from 1 to\nat most 0.707, asymptotically. A similar result can be shown for the private\n(classical) capacity. Furthermore, we can show that if the strong converse\nholds for symmetric channels (which have quantum capacity zero), then\ndegradable channels obey the strong converse: The above-mentioned asymptotic\njump of the fidelity at the quantum capacity is then from 1 down to 0. \n\n"}
{"id": "1301.5047", "contents": "Title: Asymptotically Efficient Distributed Estimation With Exponential Family\n  Statistics Abstract: The paper studies the problem of distributed parameter estimation in\nmulti-agent networks with exponential family observation statistics. A\ncertainty-equivalence type distributed estimator of the consensus + innovations\nform is proposed in which, at each each observation sampling epoch agents\nupdate their local parameter estimates by appropriately combining the data\nreceived from their neighbors and the locally sensed new information\n(innovation). Under global observability of the networked sensing model, i.e.,\nthe ability to distinguish between different instances of the parameter value\nbased on the joint observation statistics, and mean connectivity of the\ninter-agent communication network, the proposed estimator is shown to yield\nconsistent parameter estimates at each network agent. Further, it is shown that\nthe distributed estimator is asymptotically efficient, in that, the asymptotic\ncovariances of the agent estimates coincide with that of the optimal\ncentralized estimator, i.e., the inverse of the centralized Fisher information\nrate. From a technical viewpoint, the proposed distributed estimator leads to\nnon-Markovian mixed timescale stochastic recursions and the analytical methods\ndeveloped in the paper contribute to the general theory of distributed\nstochastic approximation. \n\n"}
{"id": "1301.5109", "contents": "Title: Constrained Source Coding with Side Information Abstract: The source-coding problem with side information at the decoder is studied\nsubject to a constraint that the encoder---to whom the side information is\nunavailable---be able to compute the decoder's reconstruction sequence to\nwithin some distortion. For discrete memoryless sources and finite\nsingle-letter distortion measures, an expression is given for the minimal\ndescription rate as a function of the joint law of the source and side\ninformation and of the allowed distortions at the encoder and at the decoder.\nThe minimal description rate is also computed for a memoryless Gaussian source\nwith squared-error distortion measures. A solution is also provided to a more\ngeneral problem where there are more than two distortion constraints and each\ndistortion function may be a function of three arguments: the source symbol,\nthe encoder's reconstruction symbol, and the decoder's reconstruction symbol. \n\n"}
{"id": "1301.5701", "contents": "Title: Sequential and Decentralized Estimation of Linear Regression Parameters\n  in Wireless Sensor Networks Abstract: Sequential estimation of a vector of linear regression coefficients is\nconsidered under both centralized and decentralized setups. In sequential\nestimation, the number of observations used for estimation is determined by the\nobserved samples, hence is random, as opposed to fixed-sample-size estimation.\nSpecifically, after receiving a new sample, if a target accuracy level is\nreached, we stop and estimate using the samples collected so far; otherwise we\ncontinue to receive another sample. It is known that finding an optimum\nsequential estimator, which minimizes the average sample number for a given\ntarget accuracy level, is an intractable problem with a general stopping rule\nthat depends on the complete observation history. By properly restricting the\nsearch space to stopping rules that depend on a specific subset of the complete\nobservation history, we derive the optimum sequential estimator in the\ncentralized case via optimal stopping theory. However, finding the optimum\nstopping rule in this case requires numerical computations that {\\em\nquadratically} scales with the number of parameters to be estimated. For the\ndecentralized setup with stringent energy constraints, under an alternative\nproblem formulation that is conditional on the observed regressors, we first\nderive a simple optimum scheme whose computational complexity is {\\em constant}\nwith respect to the number of parameters. Then, following this simple optimum\nscheme we propose a decentralized sequential estimator whose computational\ncomplexity and energy consumption scales {\\em linearly} with the number of\nparameters. Specifically, in the proposed decentralized scheme a\nclose-to-optimum average stopping time performance is achieved by infrequently\ntransmitting a single pulse with very short duration. \n\n"}
{"id": "1301.6236", "contents": "Title: Multi-Trial Guruswami--Sudan Decoding for Generalised Reed--Solomon\n  Codes Abstract: An iterated refinement procedure for the Guruswami--Sudan list decoding\nalgorithm for Generalised Reed--Solomon codes based on Alekhnovich's module\nminimisation is proposed. The method is parametrisable and allows variants of\nthe usual list decoding approach. In particular, finding the list of\n\\emph{closest} codewords within an intermediate radius can be performed with\nimproved average-case complexity while retaining the worst-case complexity. \n\n"}
{"id": "1301.6302", "contents": "Title: Simultaneous Information and Energy Transfer: A Two-User MISO\n  Interference Channel Case Abstract: This paper considers the sum rate maximization problem of a two-user\nmultiple-input single-output interference channel with receivers that can\nscavenge energy from the radio signals transmitted by the transmitters. We\nfirst study the optimal transmission strategy for an ideal scenario where the\ntwo receivers can simultaneously decode the information signal and harvest\nenergy. Then, considering the limitations of the current circuit technology, we\npropose two practical schemes based on TDMA, where, at each time slot, the\nreceiver either operates in the energy harvesting mode or in the information\ndetection mode. Optimal transmission strategies for the two practical schemes\nare respectively investigated. Simulation results show that the three schemes\nexhibit interesting tradeoff between achievable sum rate and energy harvesting\nrequirement, and do not dominate each other in terms of maximum achievable sum\nrate. \n\n"}
{"id": "1301.7693", "contents": "Title: Optimal Locally Repairable Codes and Connections to Matroid Theory Abstract: Petabyte-scale distributed storage systems are currently transitioning to\nerasure codes to achieve higher storage efficiency. Classical codes like\nReed-Solomon are highly sub-optimal for distributed environments due to their\nhigh overhead in single-failure events. Locally Repairable Codes (LRCs) form a\nnew family of codes that are repair efficient. In particular, LRCs minimize the\nnumber of nodes participating in single node repairs during which they generate\nsmall network traffic. Two large-scale distributed storage systems have already\nimplemented different types of LRCs: Windows Azure Storage and the Hadoop\nDistributed File System RAID used by Facebook. The fundamental bounds for LRCs,\nnamely the best possible distance for a given code locality, were recently\ndiscovered, but few explicit constructions exist. In this work, we present an\nexplicit and optimal LRCs that are simple to construct. Our construction is\nbased on grouping Reed-Solomon (RS) coded symbols to obtain RS coded symbols\nover a larger finite field. We then partition these RS symbols in small groups,\nand re-encode them using a simple local code that offers low repair locality.\nFor the analysis of the optimality of the code, we derive a new result on the\nmatroid represented by the code generator matrix. \n\n"}
{"id": "1302.0081", "contents": "Title: Robust Compressive Phase Retrieval via L1 Minimization With Application\n  to Image Reconstruction Abstract: Phase retrieval refers to a classical nonconvex problem of recovering a\nsignal from its Fourier magnitude measurements. Inspired by the compressed\nsensing technique, signal sparsity is exploited in recent studies of phase\nretrieval to reduce the required number of measurements, known as compressive\nphase retrieval (CPR). In this paper, l1 minimization problems are formulated\nfor CPR to exploit the signal sparsity and alternating direction algorithms are\npresented for problem solving. For real-valued, nonnegative image\nreconstruction, the image of interest is shown to be an optimal solution of the\nformulated l1 minimization in the noise free case. Numerical simulations\ndemonstrate that the proposed approach is fast, accurate and robust to\nmeasurements noises. \n\n"}
{"id": "1302.2187", "contents": "Title: Linear Precoding and Equalization for Network MIMO with Partial\n  Cooperation Abstract: A cellular multiple-input multiple-output (MIMO) downlink system is studied\nin which each base station (BS) transmits to some of the users, so that each\nuser receives its intended signal from a subset of the BSs. This scenario is\nreferred to as network MIMO with partial cooperation, since only a subset of\nthe BSs are able to coordinate their transmission towards any user. The focus\nof this paper is on the optimization of linear beamforming strategies at the\nBSs and at the users for network MIMO with partial cooperation. Individual\npower constraints at the BSs are enforced, along with constraints on the number\nof streams per user. It is first shown that the system is equivalent to a MIMO\ninterference channel with generalized linear constraints (MIMO-IFC-GC). The\nproblems of maximizing the sum-rate(SR) and minimizing the weighted sum mean\nsquare error (WSMSE) of the data estimates are non-convex, and suboptimal\nsolutions with reasonable complexity need to be devised. Based on this,\nsuboptimal techniques that aim at maximizing the sum-rate for the MIMO-IFC-GC\nare reviewed from recent literature and extended to the MIMO-IFC-GC where\nnecessary. Novel designs that aim at minimizing the WSMSE are then proposed.\nExtensive numerical simulations are provided to compare the performance of the\nconsidered schemes for realistic cellular systems. \n\n"}
{"id": "1302.4099", "contents": "Title: Identification of Literary Movements Using Complex Networks to Represent\n  Texts Abstract: The use of statistical methods to analyze large databases of text has been\nuseful to unveil patterns of human behavior and establish historical links\nbetween cultures and languages. In this study, we identify literary movements\nby treating books published from 1590 to 1922 as complex networks, whose\nmetrics were analyzed with multivariate techniques to generate six clusters of\nbooks. The latter correspond to time periods coinciding with relevant literary\nmovements over the last 5 centuries. The most important factor contributing to\nthe distinction between different literary styles was {the average shortest\npath length (particularly, the asymmetry of the distribution)}. Furthermore,\nover time there has been a trend toward larger average shortest path lengths,\nwhich is correlated with increased syntactic complexity, and a more uniform use\nof the words reflected in a smaller power-law coefficient for the distribution\nof word frequency. Changes in literary style were also found to be driven by\nopposition to earlier writing styles, as revealed by the analysis performed\nwith geometrical concepts. The approaches adopted here are generic and may be\nextended to analyze a number of features of languages and cultures. \n\n"}
{"id": "1302.4755", "contents": "Title: Channel-Aware Random Access in the Presence of Channel Estimation Errors Abstract: In this work, we consider the random access of nodes adapting their\ntransmission probability based on the local channel state information (CSI) in\na decentralized manner, which is called CARA. The CSI is not directly available\nto each node but estimated with some errors in our scenario. Thus, the impact\nof imperfect CSI on the performance of CARA is our main concern. Specifically,\nan exact stability analysis is carried out when a pair of bursty sources are\ncompeting for a common receiver and, thereby, have interdependent services. The\nanalysis also takes into account the compound effects of the multipacket\nreception (MPR) capability at the receiver. The contributions in this paper are\ntwofold: first, we obtain the exact stability region of CARA in the presence of\nchannel estimation errors; such an assessment is necessary as the errors in\nchannel estimation are inevitable in the practical situation. Secondly, we\ncompare the performance of CARA to that achieved by the class of stationary\nscheduling policies that make decisions in a centralized manner based on the\nCSI feedback. It is shown that the stability region of CARA is not necessarily\na subset of that of centralized schedulers as the MPR capability improves. \n\n"}
{"id": "1303.0089", "contents": "Title: Estimating Thematic Similarity of Scholarly Papers with Their Resistance\n  Distance in an Electric Network Model Abstract: We calculate resistance distances between papers in a nearly bipartite\ncitation network of 492 papers and the sources cited by them. We validate that\nthis is a realistic measure of thematic distance if each citation link has an\nelectric resistance equal to the geometric mean of the number of the paper's\nreferences and the citation number of the cited source. \n\n"}
{"id": "1303.0484", "contents": "Title: Onomastics 2.0 - The Power of Social Co-Occurrences Abstract: Onomastics is \"the science or study of the origin and forms of proper names\nof persons or places.\" [\"Onomastics\". Merriam-Webster.com, 2013.\nhttp://www.merriam-webster.com (11 February 2013)]. Especially personal names\nplay an important role in daily life, as all over the world future parents are\nfacing the task of finding a suitable given name for their child. This choice\nis influenced by different factors, such as the social context, language,\ncultural background and, in particular, personal taste.\n  With the rise of the Social Web and its applications, users more and more\ninteract digitally and participate in the creation of heterogeneous,\ndistributed, collaborative data collections. These sources of data also reflect\ncurrent and new naming trends as well as new emerging interrelations among\nnames.\n  The present work shows, how basic approaches from the field of social network\nanalysis and information retrieval can be applied for discovering relations\namong names, thus extending Onomastics by data mining techniques. The\nconsidered approach starts with building co-occurrence graphs relative to data\nfrom the Social Web, respectively for given names and city names. As a main\nresult, correlations between semantically grounded similarities among names\n(e.g., geographical distance for city names) and structural graph based\nsimilarities are observed.\n  The discovered relations among given names are the foundation of \"nameling\"\n[http://nameling.net], a search engine and academic research platform for given\nnames which attracted more than 30,000 users within four months,\nunderpinningthe relevance of the proposed methodology. \n\n"}
{"id": "1303.2147", "contents": "Title: On Influence, Stable Behavior, and the Most Influential Individuals in\n  Networks: A Game-Theoretic Approach Abstract: We introduce a new approach to the study of influence in strategic settings\nwhere the action of an individual depends on that of others in a\nnetwork-structured way. We propose \\emph{influence games} as a\n\\emph{game-theoretic} model of the behavior of a large but finite networked\npopulation. Influence games allow \\emph{both} positive and negative\n\\emph{influence factors}, permitting reversals in behavioral choices. We\nembrace \\emph{pure-strategy Nash equilibrium (PSNE)}, an important solution\nconcept in non-cooperative game theory, to formally define the \\emph{stable\noutcomes} of an influence game and to predict potential outcomes without\nexplicitly considering intricate dynamics. We address an important problem in\nnetwork influence, the identification of the \\emph{most influential\nindividuals}, and approach it algorithmically using PSNE computation.\n\\emph{Computationally}, we provide (a) complexity characterizations of various\nproblems on influence games; (b) efficient algorithms for several special cases\nand heuristics for hard cases; and (c) approximation algorithms, with provable\nguarantees, for the problem of identifying the most influential individuals.\n\\emph{Experimentally}, we evaluate our approach using both synthetic influence\ngames as well as several real-world settings of general interest, each\ncorresponding to a separate branch of the U.S. Government.\n\\emph{Mathematically,} we connect influence games to important game-theoretic\nmodels: \\emph{potential and polymatrix games}. \n\n"}
{"id": "1303.2221", "contents": "Title: Clustering on Multi-Layer Graphs via Subspace Analysis on Grassmann\n  Manifolds Abstract: Relationships between entities in datasets are often of multiple nature, like\ngeographical distance, social relationships, or common interests among people\nin a social network, for example. This information can naturally be modeled by\na set of weighted and undirected graphs that form a global multilayer graph,\nwhere the common vertex set represents the entities and the edges on different\nlayers capture the similarities of the entities in term of the different\nmodalities. In this paper, we address the problem of analyzing multi-layer\ngraphs and propose methods for clustering the vertices by efficiently merging\nthe information provided by the multiple modalities. To this end, we propose to\ncombine the characteristics of individual graph layers using tools from\nsubspace analysis on a Grassmann manifold. The resulting combination can then\nbe viewed as a low dimensional representation of the original data which\npreserves the most important information from diverse relationships between\nentities. We use this information in new clustering methods and test our\nalgorithm on several synthetic and real world datasets where we demonstrate\nsuperior or competitive performances compared to baseline and state-of-the-art\ntechniques. Our generic framework further extends to numerous analysis and\nlearning problems that involve different types of information on graphs. \n\n"}
{"id": "1303.3049", "contents": "Title: On Optimal Jamming Over an Additive Noise Channel Abstract: This paper considers the problem of optimal zero-delay jamming over an\nadditive noise channel. Early work had already solved this problem for a\nGaussian source and channel. Building on a sequence of recent results on\nconditions for linearity of optimal estimation, and of optimal mappings in\nsource-channel coding, we derive the saddle-point solution to the jamming\nproblem for general sources and channels, without recourse to Gaussian\nassumptions. We show that linearity conditions play a pivotal role in jamming,\nin the sense that the optimal jamming strategy is to effectively force both\ntransmitter and receiver to default to linear mappings, i.e., the jammer\nensures, whenever possible, that the transmitter and receiver cannot benefit\nfrom non-linear strategies. This result is shown to subsume the known result\nfor Gaussian source and channel. We analyze conditions and general settings\nwhere such unbeatable strategy can indeed be achieved by the jammer. Moreover,\nwe provide the procedure to approximate optimal jamming in the remaining\n(source-channel) cases where the jammer cannot impose linearity on the\ntransmitter and the receiver. \n\n"}
{"id": "1303.3245", "contents": "Title: Flow Motifs Reveal Limitations of the Static Framework to Represent\n  Human interactions Abstract: Networks are commonly used to define underlying interaction structures where\ninfections, information, or other quantities may spread. Although the standard\napproach has been to aggregate all links into a static structure, some studies\nsuggest that the time order in which the links are established may alter the\ndynamics of spreading. In this paper, we study the impact of the time ordering\nin the limits of flow on various empirical temporal networks. By using a random\nwalk dynamics, we estimate the flow on links and convert the original\nundirected network (temporal and static) into a directed flow network. We then\nintroduce the concept of flow motifs and quantify the divergence in the\nrepresentativity of motifs when using the temporal and static frameworks. We\nfind that the regularity of contacts and persistence of vertices (common in\nemail communication and face-to-face interactions) result on little differences\nin the limits of flow for both frameworks. On the other hand, in the case of\ncommunication within a dating site (and of a sexual network), the flow between\nvertices changes significantly in the temporal framework such that the static\napproximation poorly represents the structure of contacts. We have also\nobserved that cliques with 3 and 4 vertices con- taining only low-flow links\nare more represented than the same cliques with all high-flow links. The\nrepresentativity of these low-flow cliques is higher in the temporal framework.\nOur results suggest that the flow between vertices connected in cliques depend\non the topological context in which they are placed and in the time sequence in\nwhich the links are established. The structure of the clique alone does not\ncompletely characterize the potential of flow between the vertices. \n\n"}
{"id": "1303.3250", "contents": "Title: Reconstruction of Directed Networks from Consensus Dynamics Abstract: This paper addresses the problem of identifying the topology of an unknown,\nweighted, directed network running a consensus dynamics. We propose a\nmethodology to reconstruct the network topology from the dynamic response when\nthe system is stimulated by a wide-sense stationary noise of unknown power\nspectral density. The method is based on a node-knockout, or grounding,\nprocedure wherein the grounded node broadcasts zero without being eliminated\nfrom the network. In this direction, we measure the empirical cross-power\nspectral densities of the outputs between every pair of nodes for both grounded\nand ungrounded consensus to reconstruct the unknown topology of the network. We\nalso establish that in the special cases of undirected or purely unidirectional\nnetworks, the reconstruction does not need grounding. Finally, we extend our\nresults to the case of a directed network assuming a general dynamics, and\nprove that the developed method can detect edges and their direction. \n\n"}
{"id": "1303.4128", "contents": "Title: Sparse Phase Retrieval: Convex Algorithms and Limitations Abstract: We consider the problem of recovering signals from their power spectral\ndensity. This is a classical problem referred to in literature as the phase\nretrieval problem, and is of paramount importance in many fields of applied\nsciences. In general, additional prior information about the signal is required\nto guarantee unique recovery as the mapping from signals to power spectral\ndensity is not one-to-one. In this paper, we assume that the underlying signals\nare sparse. Recently, semidefinite programming (SDP) based approaches were\nexplored by various researchers. Simulations of these algorithms strongly\nsuggest that signals upto $o(\\sqrt{n})$ sparsity can be recovered by this\ntechnique. In this work, we develop a tractable algorithm based on reweighted\n$l_1$-minimization that recovers a sparse signal from its power spectral\ndensity for significantly higher sparsities, which is unprecedented.\n  We discuss the square-root bottleneck of the existing convex algorithms and\nshow that a $k$-sparse signal can be efficiently recovered using $O(k^2logn)$\nphaseless Fourier measurements. We also show that a $k$-sparse signal can be\nrecovered using only $O(k log n)$ phaseless measurements if we are allowed to\ndesign the measurement matrices. \n\n"}
{"id": "1303.4352", "contents": "Title: Optimal DoF Region of the Two-User MISO-BC with General Alternating CSIT Abstract: In the setting of the time-selective two-user multiple-input single-output\n(MISO) broadcast channel (BC), recent work by Tandon et al. considered the case\nwhere - in the presence of error-free delayed channel state information at the\ntransmitter (delayed CSIT) - the current CSIT for the channel of user 1 and of\nuser 2, alternate between the two extreme states of perfect current CSIT and of\nno current CSIT.\n  Motivated by the problem of having limited-capacity feedback links which may\nnot allow for perfect CSIT, as well as by the need to utilize any available\npartial CSIT, we here deviate from this `all-or-nothing' approach and proceed -\nagain in the presence of error-free delayed CSIT - to consider the general\nsetting where current CSIT now alternates between any two qualities.\nSpecifically for $I_1$ and $I_2$ denoting the high-SNR asymptotic\nrates-of-decay of the mean-square error of the CSIT estimates for the channel\nof user~1 and of user~2 respectively, we consider the case where $I_1,I_2\n\\in\\{\\gamma,\\alpha\\}$ for any two positive current-CSIT quality exponents\n$\\gamma,\\alpha$. In a fast-fading setting where we consider communication over\nany number of coherence periods, and where each CSIT state $I_1I_2$ is present\nfor a fraction $\\lambda_{I_1I_2}$ of this total duration, we focus on the\nsymmetric case of $\\lambda_{\\alpha\\gamma}=\\lambda_{\\gamma\\alpha}$, and derive\nthe optimal degrees-of-freedom (DoF) region. The result, which is supported by\nnovel communication protocols, naturally incorporates the aforementioned\n`Perfect current' vs. `No current' setting by limiting $I_1,I_2\\in\\{0,1\\}$.\n  Finally, motivated by recent interest in frequency correlated channels with\nunmatched CSIT, we also analyze the setting where there is no delayed CSIT. \n\n"}
{"id": "1303.4458", "contents": "Title: Phase retrieval from power spectra of masked signals Abstract: In diffraction imaging, one is tasked with reconstructing a signal from its\npower spectrum. To resolve the ambiguity in this inverse problem, one might\ninvoke prior knowledge about the signal, but phase retrieval algorithms in this\nvein have found limited success. One alternative is to create redundancy in the\nmeasurement process by illuminating the signal multiple times, distorting the\nsignal each time with a different mask. Despite several recent advances in\nphase retrieval, the community has yet to construct an ensemble of masks which\nuniquely determines all signals and admits an efficient reconstruction\nalgorithm. In this paper, we leverage the recently proposed polarization method\nto construct such an ensemble. We also present numerical simulations to\nillustrate the stability of the polarization method in this setting. In\ncomparison to a state-of-the-art phase retrieval algorithm known as PhaseLift,\nwe find that polarization is much faster with comparable stability. \n\n"}
{"id": "1303.5097", "contents": "Title: On the optimality of a L1/L1 solver for sparse signal recovery from\n  sparsely corrupted compressive measurements Abstract: This short note proves the $\\ell_2-\\ell_1$ instance optimality of a\n$\\ell_1/\\ell_1$ solver, i.e a variant of \\emph{basis pursuit denoising} with a\n$\\ell_1$ fidelity constraint, when applied to the estimation of sparse (or\ncompressible) signals observed by sparsely corrupted compressive measurements.\nThe approach simply combines two known results due to Y. Plan, R. Vershynin and\nE. Cand\\`es. \n\n"}
{"id": "1303.5457", "contents": "Title: Explicit solution of a tropical optimization problem with application to\n  project scheduling Abstract: A new multidimensional optimization problem is considered in the tropical\nmathematics setting. The problem is to minimize a nonlinear function defined on\na finite-dimensional semimodule over an idempotent semifield and given by a\nconjugate transposition operator. A special case of the problem, which arises\nin just-in-time scheduling, serves as a motivation for the study. To solve the\ngeneral problem, we derive a sharp lower bound for the objective function and\nthen find vectors that yield the bound. Under general conditions, an explicit\nsolution is obtained in a compact vector form. This result is applied to\nprovide new solutions for scheduling problems under consideration. To\nillustrate, numerical examples are also presented. \n\n"}
{"id": "1303.6271", "contents": "Title: Preferential Attachment in Online Networks: Measurement and Explanations Abstract: We perform an empirical study of the preferential attachment phenomenon in\ntemporal networks and show that on the Web, networks follow a nonlinear\npreferential attachment model in which the exponent depends on the type of\nnetwork considered. The classical preferential attachment model for networks by\nBarab\\'asi and Albert (1999) assumes a linear relationship between the number\nof neighbors of a node in a network and the probability of attachment. Although\nthis assumption is widely made in Web Science and related fields, the\nunderlying linearity is rarely measured. To fill this gap, this paper performs\nan empirical longitudinal (time-based) study on forty-seven diverse Web network\ndatasets from seven network categories and including directed, undirected and\nbipartite networks. We show that contrary to the usual assumption, preferential\nattachment is nonlinear in the networks under consideration. Furthermore, we\nobserve that the deviation from linearity is dependent on the type of network,\ngiving sublinear attachment in certain types of networks, and superlinear\nattachment in others. Thus, we introduce the preferential attachment exponent\n$\\beta$ as a novel numerical network measure that can be used to discriminate\ndifferent types of networks. We propose explanations for the behavior of that\nnetwork measure, based on the mechanisms that underly the growth of the network\nin question. \n\n"}
{"id": "1303.6544", "contents": "Title: Sketching Sparse Matrices Abstract: This paper considers the problem of recovering an unknown sparse p\\times p\nmatrix X from an m\\times m matrix Y=AXB^T, where A and B are known m \\times p\nmatrices with m << p.\n  The main result shows that there exist constructions of the \"sketching\"\nmatrices A and B so that even if X has O(p) non-zeros, it can be recovered\nexactly and efficiently using a convex program as long as these non-zeros are\nnot concentrated in any single row/column of X. Furthermore, it suffices for\nthe size of Y (the sketch dimension) to scale as m = O(\\sqrt{# nonzeros in X}\n\\times log p). The results also show that the recovery is robust and stable in\nthe sense that if X is equal to a sparse matrix plus a perturbation, then the\nconvex program we propose produces an approximation with accuracy proportional\nto the size of the perturbation. Unlike traditional results on sparse recovery,\nwhere the sensing matrix produces independent measurements, our sensing\noperator is highly constrained (it assumes a tensor product structure).\nTherefore, proving recovery guarantees require non-standard techniques. Indeed\nour approach relies on a novel result concerning tensor products of bipartite\ngraphs, which may be of independent interest.\n  This problem is motivated by the following application, among others.\nConsider a p\\times n data matrix D, consisting of n observations of p\nvariables. Assume that the correlation matrix X:=DD^{T} is (approximately)\nsparse in the sense that each of the p variables is significantly correlated\nwith only a few others. Our results show that these significant correlations\ncan be detected even if we have access to only a sketch of the data S=AD with A\n\\in R^{m\\times p}. \n\n"}
{"id": "1303.7291", "contents": "Title: A framework to characterize performance of LASSO algorithms Abstract: In this paper we consider solving \\emph{noisy} under-determined systems of\nlinear equations with sparse solutions. A noiseless equivalent attracted\nenormous attention in recent years, above all, due to work of\n\\cite{CRT,CanRomTao06,DonohoPol} where it was shown in a statistical and large\ndimensional context that a sparse unknown vector (of sparsity proportional to\nthe length of the vector) can be recovered from an under-determined system via\na simple polynomial $\\ell_1$-optimization algorithm. \\cite{CanRomTao06} further\nestablished that even when the equations are \\emph{noisy}, one can, through an\nSOCP noisy equivalent of $\\ell_1$, obtain an approximate solution that is (in\nan $\\ell_2$-norm sense) no further than a constant times the noise from the\nsparse unknown vector. In our recent works\n\\cite{StojnicCSetam09,StojnicUpper10}, we created a powerful mechanism that\nhelped us characterize exactly the performance of $\\ell_1$ optimization in the\nnoiseless case (as shown in \\cite{StojnicEquiv10} and as it must be if the\naxioms of mathematics are well set, the results of\n\\cite{StojnicCSetam09,StojnicUpper10} are in an absolute agreement with the\ncorresponding exact ones from \\cite{DonohoPol}). In this paper we design a\nmechanism, as powerful as those from \\cite{StojnicCSetam09,StojnicUpper10},\nthat can handle the analysis of a LASSO type of algorithm (and many others)\nthat can be (or typically are) used for \"solving\" noisy under-determined\nsystems. Using the mechanism we then, in a statistical context, compute the\nexact worst-case $\\ell_2$ norm distance between the unknown sparse vector and\nthe approximate one obtained through such a LASSO. The obtained results match\nthe corresponding exact ones obtained in \\cite{BayMon10,DonMalMon10}. Moreover,\nas a by-product of our analysis framework we recognize existence of an SOCP\ntype of algorithm that achieves the same performance. \n\n"}
{"id": "1303.7460", "contents": "Title: Some results related to the conjecture by Belfiore and Sol\\'e Abstract: In the first part of the paper, we consider the relation between kissing\nnumber and the secrecy gain. We show that on an $n=24m+8k$-dimensional even\nunimodular lattice, if the shortest vector length is $\\geq 2m$, then as the\nnumber of vectors of length $2m$ decreases, the secrecy gain increases. We will\nalso prove a similar result on general unimodular lattices. We will also\nconsider the situations with shorter vectors. Furthermore, assuming the\nconjecture by Belfiore and Sol\\'e, we will calculate the difference between\ninverses of secrecy gains as the number of vectors varies. We will show by an\nexample that there exist two lattices in the same dimension with the same\nshortest vector length and the same kissing number, but different secrecy\ngains. Finally, we consider some cases of a question by Elkies by providing an\nanswer for a special class of lattices assuming the conjecture of Belfiore and\nSol\\'e. We will also get a conditional improvement on some Gaulter's results\nconcerning the conjecture. \n\n"}
{"id": "1304.0002", "contents": "Title: A performance analysis framework for SOCP algorithms in noisy compressed\n  sensing Abstract: Solving under-determined systems of linear equations with sparse solutions\nattracted enormous amount of attention in recent years, above all, due to work\nof \\cite{CRT,CanRomTao06,DonohoPol}. In \\cite{CRT,CanRomTao06,DonohoPol} it was\nrigorously shown for the first time that in a statistical and large dimensional\ncontext a linear sparsity can be recovered from an under-determined system via\na simple polynomial $\\ell_1$-optimization algorithm. \\cite{CanRomTao06} went\neven further and established that in \\emph{noisy} systems for any linear level\nof under-determinedness there is again a linear sparsity that can be\n\\emph{approximately} recovered through an SOCP (second order cone programming)\nnoisy equivalent to $\\ell_1$. Moreover, the approximate solution is (in an\n$\\ell_2$-norm sense) guaranteed to be no further from the sparse unknown vector\nthan a constant times the noise. In this paper we will also consider solving\n\\emph{noisy} linear systems and present an alternative statistical framework\nthat can be used for their analysis. To demonstrate how the framework works we\nwill show how one can use it to precisely characterize the approximation error\nof a wide class of SOCP algorithms. We will also show that our theoretical\npredictions are in a solid agrement with the results one can get through\nnumerical simulations. \n\n"}
{"id": "1304.0004", "contents": "Title: Linear under-determined systems with sparse solutions: Redirecting a\n  challenge? Abstract: Seminal works \\cite{CRT,DonohoUnsigned,DonohoPol} generated a massive\ninterest in studying linear under-determined systems with sparse solutions. In\nthis paper we give a short mathematical overview of what was accomplished in\nlast 10 years in a particular direction of such a studying. We then discuss\nwhat we consider were the main challenges in last 10 years and give our own\nview as to what are the main challenges that lie ahead. Through the\npresentation we arrive to a point where the following natural rhetoric question\narises: is it a time to redirect the main challenges? While we can not provide\nthe answer to such a question we hope that our small discussion will stimulate\nfurther considerations in this direction. \n\n"}
{"id": "1304.1039", "contents": "Title: Environmental structure and competitive scoring advantages in team\n  competitions Abstract: In most professional sports, the structure of the environment is kept neutral\nso that scoring imbalances may be attributed to differences in team skill. It\nthus remains unknown what impact structural heterogeneities can have on scoring\ndynamics and producing competitive advantages. Applying a generative model of\nscoring dynamics to roughly 10 million team competitions drawn from an online\ngame, we quantify the relationship between a competition's structure and its\nscoring dynamics. Despite wide structural variations, we find the same\nthree-phase pattern in the tempo of events observed in many sports. Tempo and\nbalance are highly predictable from a competition's structural features alone\nand teams exploit environmental heterogeneities for sustained competitive\nadvantage. The most balanced competitions are associated with specific\nenvironmental heterogeneities, not from equally skilled teams. These results\nshed new light on the principles of balanced competition, and illustrate the\npotential of online game data for investigating social dynamics and\ncompetition. \n\n"}
{"id": "1304.1692", "contents": "Title: Short Message Noisy Network Coding with a Decode-Forward Option Abstract: Short message noisy network coding (SNNC) differs from long message noisy\nnetwork coding (LNNC) in that one transmits many short messages in blocks\nrather than using one long message with repetitive encoding. Several properties\nof SNNC are developed. First, SNNC with backward decoding achieves the same\nrates as SNNC with offset encoding and sliding window decoding for memoryless\nnetworks where each node transmits a multicast message. The rates are the same\nas LNNC with joint decoding. Second, SNNC enables early decoding if the channel\nquality happens to be good. This leads to mixed strategies that unify the\nadvantages of decode-forward and noisy network coding. Third, the best decoders\nsometimes treat other nodes' signals as noise and an iterative method is given\nto find the set of nodes that a given node should treat as noise sources. \n\n"}
{"id": "1304.2809", "contents": "Title: On partial sparse recovery Abstract: We consider the problem of recovering a partially sparse solution of an\nunderdetermined system of linear equations by minimizing the $\\ell_1$-norm of\nthe part of the solution vector which is known to be sparse. Such a problem is\nclosely related to a classical problem in Compressed Sensing where the\n$\\ell_1$-norm of the whole solution vector is minimized. We introduce analogues\nof restricted isometry and null space properties for the recovery of partially\nsparse vectors and show that these new properties are implied by their original\ncounterparts. We show also how to extend recovery under noisy measurements to\nthe partially sparse case. \n\n"}
{"id": "1304.3071", "contents": "Title: Minimal Controllability Problems Abstract: Given a linear system, we consider the problem of finding a small set of\nvariables to affect with an input so that the resulting system is controllable.\nWe show that this problem is NP-hard; indeed, we show that even approximating\nthe minimum number of variables that need to be affected within a\nmultiplicative factor of $c \\log n$ is NP-hard for some positive $c$. On the\npositive side, we show it is possible to find sets of variables matching this\ninapproximability barrier in polynomial time. This can be done by a simple\ngreedy heuristic which sequentially picks variables to maximize the rank\nincrease of the controllability matrix. Experiments on Erdos-Renyi random\ngraphs demonstrate this heuristic almost always succeeds at findings the\nminimum number of variables. \n\n"}
{"id": "1304.3518", "contents": "Title: Trust in the CODA model: Opinion Dynamics and the reliability of other\n  agents Abstract: A model for the joint evolution of opinions and how much the agents trust\neach other is presented. The model is built using the framework of the\nContinuous Opinions and Discrete Actions (CODA) model. Instead of a fixed\nprobability that the other agents will decide in the favor of the best choice,\neach agent considers that other agents might be one one of two types:\ntrustworthy or useless. Trustworthy agents are considered more likely to be\nright than wrong, while the opposite holds for useless ones. Together with the\nopinion about the discussed issue, each agent also updates that probability for\neach one of the other agents it interacts withe probability each one it\ninteracts with is of one type or the other. The dynamics of opinions and the\nevolution of the trust between the agents are studied. Clear evidences of the\nexistence of two phases, one where strong polarization is observed and the\nother where a clear division is permanent and reinforced are observed. The\ntransition seems signs of being a first-order transition, with a location\ndependent on both the parameters of the model and the initial conditions. This\nhappens despite the fact that the trust network evolves much slower than the\nopinion on the central issue. \n\n"}
{"id": "1304.3553", "contents": "Title: On the Reliability Function of the Discrete Memoryless Relay Channel Abstract: Bounds on the reliability function for the discrete memoryless relay channel\nare derived using the method of types. Two achievable error exponents are\nderived based on partial decode-forward and compress-forward which are\nwell-known superposition block-Markov coding schemes. The derivations require\ncombinations of the techniques involved in the proofs of\nCsisz\\'ar-K\\\"orner-Marton's packing lemma for the error exponent of channel\ncoding and Marton's type covering lemma for the error exponent of source coding\nwith a fidelity criterion. The decode-forward error exponent is evaluated on\nSato's relay channel. From this example, it is noted that to obtain the fastest\npossible decay in the error probability for a fixed effective coding rate, one\nought to optimize the number of blocks in the block-Markov coding scheme\nassuming the blocklength within each block is large. An upper bound on the\nreliability function is also derived using ideas from Haroutunian's lower bound\non the error probability for point-to-point channel coding with feedback. \n\n"}
{"id": "1304.4181", "contents": "Title: Rate-Distortion-Based Physical Layer Secrecy with Applications to\n  Multimode Fiber Abstract: Optical networks are vulnerable to physical layer attacks; wiretappers can\nimproperly receive messages intended for legitimate recipients. Our work\nconsiders an aspect of this security problem within the domain of multimode\nfiber (MMF) transmission. MMF transmission can be modeled via a broadcast\nchannel in which both the legitimate receiver's and wiretapper's channels are\nmultiple-input-multiple-output complex Gaussian channels. Source-channel coding\nanalyses based on the use of distortion as the metric for secrecy are\ndeveloped. Alice has a source sequence to be encoded and transmitted over this\nbroadcast channel so that the legitimate user Bob can reliably decode while\nforcing the distortion of wiretapper, or eavesdropper, Eve's estimate as high\nas possible. Tradeoffs between transmission rate and distortion under two\nextreme scenarios are examined: the best case where Eve has only her channel\noutput and the worst case where she also knows the past realization of the\nsource. It is shown that under the best case, an operationally separate\nsource-channel coding scheme guarantees maximum distortion at the same rate as\nneeded for reliable transmission. Theoretical bounds are given, and\nparticularized for MMF. Numerical results showing the rate distortion tradeoff\nare presented and compared with corresponding results for the perfect secrecy\ncase. \n\n"}
{"id": "1304.5038", "contents": "Title: One condition for solution uniqueness and robustness of both\n  l1-synthesis and l1-analysis minimizations Abstract: The $\\ell_1$-synthesis model and the $\\ell_1$-analysis model recover\nstructured signals from their undersampled measurements. The solution of former\nis a sparse sum of dictionary atoms, and that of the latter makes sparse\ncorrelations with dictionary atoms. This paper addresses the question: when can\nwe trust these models to recover specific signals? We answer the question with\na condition that is both necessary and sufficient to guarantee the recovery to\nbe unique and exact and, in presence of measurement noise, to be robust. The\ncondition is one--for--all in the sense that it applies to both of the\n$\\ell_1$-synthesis and $\\ell_1$-analysis models, to both of their constrained\nand unconstrained formulations, and to both the exact recovery and robust\nrecovery cases. Furthermore, a convex infinity--norm program is introduced for\nnumerically verifying the condition. A comprehensive comparison with related\nexisting conditions are included. \n\n"}
{"id": "1304.6172", "contents": "Title: Outage Probability in Arbitrarily-Shaped Finite Wireless Networks Abstract: This paper analyzes the outage performance in finite wireless networks.\nUnlike most prior works, which either assumed a specific network shape or\nconsidered a special location of the reference receiver, we propose two general\nframeworks for analytically computing the outage probability at any arbitrary\nlocation of an arbitrarily-shaped finite wireless network: (i) a moment\ngenerating function-based framework which is based on the numerical inversion\nof the Laplace transform of a cumulative distribution and (ii) a reference link\npower gain-based framework which exploits the distribution of the fading power\ngain between the reference transmitter and receiver. The outage probability is\nspatially averaged over both the fading distribution and the possible locations\nof the interferers. The boundary effects are accurately accounted for using the\nprobability distribution function of the distance of a random node from the\nreference receiver. For the case of the node locations modeled by a Binomial\npoint process and Nakagami-$m$ fading channel, we demonstrate the use of the\nproposed frameworks to evaluate the outage probability at any location inside\neither a disk or polygon region. The analysis illustrates the location\ndependent performance in finite wireless networks and highlights the importance\nof accurately modeling the boundary effects. \n\n"}
{"id": "1304.6528", "contents": "Title: Nonanticipative Rate Distortion Function for General Source-Channel\n  Matching Abstract: In this paper we invoke a nonanticipative information Rate Distortion\nFunction (RDF) for sources with memory, and we analyze its importance in\nprobabilistic matching of the source to the channel so that transmission of a\nsymbol-by-symbol code with memory without anticipation is optimal, with respect\nto an average distortion and excess distortion probability. We show\nachievability of the symbol-by-symbol code with memory without anticipation,\nand we evaluate the probabilistic performance of the code for a Markov source. \n\n"}
{"id": "1304.6589", "contents": "Title: Partitions of Frobenius Rings Induced by the Homogeneous Weight Abstract: The values of the homogeneous weight are determined for finite Frobenius\nrings that are a direct product of local Frobenius rings. This is used to\ninvestigate the partition induced by this weight and its dual partition under\ncharacter-theoretic dualization. A characterization is given of those rings for\nwhich the induced partition is reflexive or even self-dual. \n\n"}
{"id": "1304.6627", "contents": "Title: Robust 1-bit Compressive Sensing via Gradient Support Pursuit Abstract: This paper studies a formulation of 1-bit Compressed Sensing (CS) problem\nbased on the maximum likelihood estimation framework. In order to solve the\nproblem we apply the recently proposed Gradient Support Pursuit algorithm, with\na minor modification. Assuming the proposed objective function has a Stable\nRestricted Hessian, the algorithm is shown to accurately solve the 1-bit CS\nproblem. Furthermore, the algorithm is compared to the state-of-the-art 1-bit\nCS algorithms through numerical simulations. The results suggest that the\nproposed method is robust to noise and at mid to low input SNR regime it\nachieves the best reconstruction SNR vs. execution time trade-off. \n\n"}
{"id": "1305.0507", "contents": "Title: Hub-Accelerator: Fast and Exact Shortest Path Computation in Large\n  Social Networks Abstract: Shortest path computation is one of the most fundamental operations for\nmanaging and analyzing large social networks. Though existing techniques are\nquite effective for finding the shortest path on large but sparse road\nnetworks, social graphs have quite different characteristics: they are\ngenerally non-spatial, non-weighted, scale-free, and they exhibit small-world\nproperties in addition to their massive size. In particular, the existence of\nhubs, those vertices with a large number of connections, explodes the search\nspace, making the shortest path computation surprisingly challenging. In this\npaper, we introduce a set of novel techniques centered around hubs,\ncollectively referred to as the Hub-Accelerator framework, to compute the\nk-degree shortest path (finding the shortest path between two vertices if their\ndistance is within k). These techniques enable us to significantly reduce the\nsearch space by either greatly limiting the expansion scope of hubs (using the\nnovel distance- preserving Hub-Network concept) or completely pruning away the\nhubs in the online search (using the Hub2-Labeling approach). The\nHub-Accelerator approaches are more than two orders of magnitude faster than\nBFS and the state-of-the-art approximate shortest path method Sketch for the\nshortest path computation. The Hub- Network approach does not introduce\nadditional index cost with light pre-computation cost; the index size and index\nconstruction cost of Hub2-Labeling are also moderate and better than or\ncomparable to the approximation indexing Sketch method. \n\n"}
{"id": "1305.0868", "contents": "Title: Precoding-Based Network Alignment For Three Unicast Sessions Abstract: We consider the problem of network coding across three unicast sessions over\na directed acyclic graph, where each sender and the receiver is connected to\nthe network via a single edge of unit capacity. We consider a network model in\nwhich the middle of the network only performs random linear network coding, and\nrestrict our approaches to precoding-based linear schemes, where the senders\nuse precoding matrices to encode source symbols. We adapt a precoding-based\ninterference alignment technique, originally developed for the wireless\ninterference channel, to construct a precoding-based linear scheme, which we\nrefer to as as a {\\em precoding-based network alignment scheme (PBNA)}. A\nprimary difference between this setting and the wireless interference channel\nis that the network topology can introduce dependencies between elements of the\ntransfer matrix, which we refer to as coupling relations, and can potentially\naffect the achievable rate of PBNA. We identify all possible such coupling\nrelations, and interpret these coupling relations in terms of network topology\nand present polynomial-time algorithms to check the presence of these coupling\nrelations. Finally, we show that, depending on the coupling relations present\nin the network, the optimal symmetric rate achieved by precoding-based linear\nscheme can take only three possible values, all of which can be achieved by\nPBNA. \n\n"}
{"id": "1305.0909", "contents": "Title: An Asymptotically Efficient Backlog Estimate for Dynamic Frame Aloha Abstract: In this paper we investigate backlog estimation procedures for Dynamic Frame\nAloha (DFA) in Radio Frequency Identification (RFID) environment. In\nparticular, we address the tag identification efficiency with any tag number\n$N$, including $N\\rightarrow\\infty$. Although in the latter case efficiency\n$e^{-1}$ is possible, none of the solution proposed in the literature has been\nshown to reach such value. We analyze Schoute's backlog estimate, which is very\nattractive for its simplicity, and formally show that its asymptotic efficiency\nis 0.311. Leveraging the analysis, we propose the Asymptotic Efficient backlog\nEstimate (AE$^2$) an improvement of the Schoute's backlog estimate, whose\nefficiency reaches $e^{-1}$ asymptotically. We further show that AE$^2$ can be\noptimized in order to present an efficiency very close to $e^{-1}$ for\npractically any value of the population size. We also evaluate the loss of\nefficiency when the frame size is constrained to be a power of two, as required\nby RFID standards for DFA, and theoretically show that the asymptotic\nefficiency becomes 0.356. \n\n"}
{"id": "1305.1729", "contents": "Title: A Simple Technique for the Converse of Finite Blocklength Multiple\n  Access Channels Abstract: A converse for the Discrete Memoryless Multiple Access Channel is given. The\nresult in [13] is refined, and the third order term is obtained. Moreover, our\nproof is much simpler than [13]. With little modification, the region can be\nfurther improved. \n\n"}
{"id": "1305.2524", "contents": "Title: Corrupted Sensing: Novel Guarantees for Separating Structured Signals Abstract: We study the problem of corrupted sensing, a generalization of compressed\nsensing in which one aims to recover a signal from a collection of corrupted or\nunreliable measurements. While an arbitrary signal cannot be recovered in the\nface of arbitrary corruption, tractable recovery is possible when both signal\nand corruption are suitably structured. We quantify the relationship between\nsignal recovery and two geometric measures of structure, the Gaussian\ncomplexity of a tangent cone and the Gaussian distance to a subdifferential. We\ntake a convex programming approach to disentangling signal and corruption,\nanalyzing both penalized programs that trade off between signal and corruption\ncomplexity, and constrained programs that bound the complexity of signal or\ncorruption when prior information is available. In each case, we provide\nconditions for exact signal recovery from structured corruption and stable\nsignal recovery from structured corruption with added unstructured noise. Our\nsimulations demonstrate close agreement between our theoretical recovery bounds\nand the sharp phase transitions observed in practice. In addition, we provide\nnew interpretable bounds for the Gaussian complexity of sparse vectors,\nblock-sparse vectors, and low-rank matrices, which lead to sharper guarantees\nof recovery when combined with our results and those in the literature. \n\n"}
{"id": "1305.2714", "contents": "Title: Sharp MSE Bounds for Proximal Denoising Abstract: Denoising has to do with estimating a signal $x_0$ from its noisy\nobservations $y=x_0+z$. In this paper, we focus on the \"structured denoising\nproblem\", where the signal $x_0$ possesses a certain structure and $z$ has\nindependent normally distributed entries with mean zero and variance\n$\\sigma^2$. We employ a structure-inducing convex function $f(\\cdot)$ and solve\n$\\min_x\\{\\frac{1}{2}\\|y-x\\|_2^2+\\sigma\\lambda f(x)\\}$ to estimate $x_0$, for\nsome $\\lambda>0$. Common choices for $f(\\cdot)$ include the $\\ell_1$ norm for\nsparse vectors, the $\\ell_1-\\ell_2$ norm for block-sparse signals and the\nnuclear norm for low-rank matrices. The metric we use to evaluate the\nperformance of an estimate $x^*$ is the normalized mean-squared-error\n$\\text{NMSE}(\\sigma)=\\frac{\\mathbb{E}\\|x^*-x_0\\|_2^2}{\\sigma^2}$. We show that\nNMSE is maximized as $\\sigma\\rightarrow 0$ and we find the \\emph{exact} worst\ncase NMSE, which has a simple geometric interpretation: the\nmean-squared-distance of a standard normal vector to the $\\lambda$-scaled\nsubdifferential $\\lambda\\partial f(x_0)$. When $\\lambda$ is optimally tuned to\nminimize the worst-case NMSE, our results can be related to the constrained\ndenoising problem $\\min_{f(x)\\leq f(x_0)}\\{\\|y-x\\|_2\\}$. The paper also\nconnects these results to the generalized LASSO problem, in which, one solves\n$\\min_{f(x)\\leq f(x_0)}\\{\\|y-Ax\\|_2\\}$ to estimate $x_0$ from noisy linear\nobservations $y=Ax_0+z$. We show that certain properties of the LASSO problem\nare closely related to the denoising problem. In particular, we characterize\nthe normalized LASSO cost and show that it exhibits a \"phase transition\" as a\nfunction of number of observations. Our results are significant in two ways.\nFirst, we find a simple formula for the performance of a general convex\nestimator. Secondly, we establish a connection between the denoising and linear\ninverse problems. \n\n"}
{"id": "1305.4446", "contents": "Title: An analysis of block sampling strategies in compressed sensing Abstract: Compressed sensing is a theory which guarantees the exact recovery of sparse\nsignals from a small number of linear projections. The sampling schemes\nsuggested by current compressed sensing theories are often of little practical\nrelevance since they cannot be implemented on real acquisition systems. In this\npaper, we study a new random sampling approach that consists in projecting the\nsignal over blocks of sensing vectors. A typical example is the case of blocks\nmade of horizontal lines in the 2D Fourier plane. We provide theoretical\nresults on the number of blocks that are required for exact sparse signal\nreconstruction. This number depends on two properties named intra and\ninter-support block coherence. We then show through a series of examples\nincluding Gaussian measurements, isolated measurements or blocks in\ntime-frequency bases, that the main result is sharp in the sense that the\nminimum amount of blocks necessary to reconstruct sparse signals cannot be\nimproved up to a multiplicative logarithmic factor. The proposed results\nprovide a good insight on the possibilities and limits of block compressed\nsensing in imaging devices such as magnetic resonance imaging,\nradio-interferometry or ultra-sound imaging. \n\n"}
{"id": "1305.5764", "contents": "Title: Replication based storage systems with local repair Abstract: We consider the design of regenerating codes for distributed storage systems\nthat enjoy the property of local, exact and uncoded repair, i.e., (a) upon\nfailure, a node can be regenerated by simply downloading packets from the\nsurviving nodes and (b) the number of surviving nodes contacted is strictly\nsmaller than the number of nodes that need to be contacted for reconstructing\nthe stored file.\n  Our codes consist of an outer MDS code and an inner fractional repetition\ncode that specifies the placement of the encoded symbols on the storage nodes.\nFor our class of codes, we identify the tradeoff between the local repair\nproperty and the minimum distance. We present codes based on graphs of high\ngirth, affine resolvable designs and projective planes that meet the minimum\ndistance bound for specific choices of file sizes. \n\n"}
{"id": "1306.0992", "contents": "Title: Any network codes comes from an algebraic curve taking osculating spaces Abstract: In this note we prove that every network code over $\\mathbb {F}_q$ may be\nrealized taking some of the osculating spaces of a smooth projective curve. \n\n"}
{"id": "1306.1102", "contents": "Title: Detectability of communities in heterogeneous networks Abstract: Communities are fundamental entities for the characterization of the\nstructure of real networks. The standard approach to the identification of\ncommunities in networks is based on the optimization of a quality function\nknown as \"modularity\". Although modularity has been at the center of an intense\nresearch activity and many methods for its maximization have been proposed, not\nmuch it is yet known about the necessary conditions that communities need to\nsatisfy in order to be detectable with modularity maximization methods. Here,\nwe develop a simple theory to establish these conditions, and we successfully\napply it to various classes of network models. Our main result is that\nheterogeneity in the degree distribution helps modularity to correctly recover\nthe community structure of a network and that, in the realistic case of\nscale-free networks with degree exponent $\\gamma < 2.5$, modularity is always\nable to detect the presence of communities. \n\n"}
{"id": "1306.3093", "contents": "Title: Multi-user Scheduling Schemes for Simultaneous Wireless Information and\n  Power Transfer Abstract: In this paper, we study the downlink multi-user scheduling problem for a\ntime-slotted system with simultaneous wireless information and power transfer.\nIn particular, in each time slot, a single user is scheduled to receive\ninformation, while the remaining users opportunistically harvest the ambient\nradio frequency (RF) energy. We devise novel scheduling schemes in which the\ntradeoff between the users' ergodic capacities and their average amount of\nharvested energy can be controlled. To this end, we modify two fair scheduling\nschemes used in information-only transfer systems. First, proportionally fair\nmaximum normalized signal-to-noise ratio (N-SNR) scheduling is modified by\nscheduling the user having the jth ascendingly ordered (rather than the\nmaximum) N-SNR. We refer to this scheme as order-based N-SNR scheduling.\nSecond, conventional equal-throughput (ET) fair scheduling is modified by\nscheduling the user having the minimum moving average throughput among the set\nof users whose N-SNR orders fall into a certain set of allowed orders Sa\n(rather than the set of all users). We refer to this scheme as order-based ET\nscheduling. The feasibility conditions required for the users to achieve ET\nwith this scheme are also derived. We show that the smaller the selection order\nj for the order-based N-SNR scheme, and the lower the orders in Sa for the\norder-based ET scheme, the higher the average amount of energy harvested by the\nusers at the expense of a reduction in their ergodic capacities. We analyze the\nperformance of the considered scheduling schemes for independent and\nnon-identically distributed (i.n.d.) Ricean fading channels, and provide\nclosed-form results for the special case of i.n.d. Rayleigh fading. \n\n"}
{"id": "1306.3770", "contents": "Title: Lifting $\\ell_1$-optimization strong and sectional thresholds Abstract: In this paper we revisit under-determined linear systems of equations with\nsparse solutions. As is well known, these systems are among core mathematical\nproblems of a very popular compressed sensing field. The popularity of the\nfield as well as a substantial academic interest in linear systems with sparse\nsolutions are in a significant part due to seminal results\n\\cite{CRT,DonohoPol}. Namely, working in a statistical scenario,\n\\cite{CRT,DonohoPol} provided substantial mathematical progress in\ncharacterizing relation between the dimensions of the systems and the sparsity\nof unknown vectors recoverable through a particular polynomial technique called\n$\\ell_1$-minimization. In our own series of work\n\\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} we also provided a\ncollection of mathematical results related to these problems. While, Donoho's\nwork \\cite{DonohoPol,DonohoUnsigned} established (and our own work\n\\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} reaffirmed) the typical or\nthe so-called \\emph{weak threshold} behavior of $\\ell_1$-minimization many\nimportant questions remain unanswered. Among the most important ones are those\nthat relate to non-typical or the so-called \\emph{strong threshold} behavior.\nThese questions are usually combinatorial in nature and known techniques come\nup short of providing the exact answers. In this paper we provide a powerful\nmechanism that that can be used to attack the \"tough\" scenario, i.e. the\n\\emph{strong threshold} (and its a similar form called \\emph{sectional\nthreshold}) of $\\ell_1$-minimization. \n\n"}
{"id": "1306.3774", "contents": "Title: Under-determined linear systems and $\\ell_q$-optimization thresholds Abstract: Recent studies of under-determined linear systems of equations with sparse\nsolutions showed a great practical and theoretical efficiency of a particular\ntechnique called $\\ell_1$-optimization. Seminal works \\cite{CRT,DOnoho06CS}\nrigorously confirmed it for the first time. Namely, \\cite{CRT,DOnoho06CS}\nshowed, in a statistical context, that $\\ell_1$ technique can recover sparse\nsolutions of under-determined systems even when the sparsity is linearly\nproportional to the dimension of the system. A followup \\cite{DonohoPol} then\nprecisely characterized such a linearity through a geometric approach and a\nseries of work\\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} reaffirmed\nstatements of \\cite{DonohoPol} through a purely probabilistic approach. A\ntheoretically interesting alternative to $\\ell_1$ is a more general version\ncalled $\\ell_q$ (with an essentially arbitrary $q$). While $\\ell_1$ is\ntypically considered as a first available convex relaxation of sparsity norm\n$\\ell_0$, $\\ell_q,0\\leq q\\leq 1$, albeit non-convex, should technically be a\ntighter relaxation of $\\ell_0$. Even though developing polynomial (or close to\nbe polynomial) algorithms for non-convex problems is still in its initial\nphases one may wonder what would be the limits of an $\\ell_q,0\\leq q\\leq 1$,\nrelaxation even if at some point one can develop algorithms that could handle\nits non-convexity. A collection of answers to this and a few realted questions\nis precisely what we present in this paper. \n\n"}
{"id": "1306.3778", "contents": "Title: Upper-bounding $\\ell_1$-optimization sectional thresholds Abstract: In this paper we look at a particular problem related to under-determined\nlinear systems of equations with sparse solutions. $\\ell_1$-minimization is a\nfairly successful polynomial technique that can in certain statistical\nscenarios find sparse enough solutions of such systems. Barriers of $\\ell_1$\nperformance are typically referred to as its thresholds. Depending if one is\ninterested in a typical or worst case behavior one then distinguishes between\nthe \\emph{weak} thresholds that relate to a typical behavior on one side and\nthe \\emph{sectional} and \\emph{strong} thresholds that relate to the worst case\nbehavior on the other side. Starting with seminal works\n\\cite{CRT,DonohoPol,DOnoho06CS} a substantial progress has been achieved in\ntheoretical characterization of $\\ell_1$-minimization statistical thresholds.\nMore precisely, \\cite{CRT,DOnoho06CS} presented for the first time linear lower\nbounds on all of these thresholds. Donoho's work \\cite{DonohoPol} (and our own\n\\cite{StojnicCSetam09,StojnicUpper10}) went a bit further and essentially\nsettled the $\\ell_1$'s \\emph{weak} thresholds. At the same time they also\nprovided fairly good lower bounds on the values on the \\emph{sectional} and\n\\emph{strong} thresholds. In this paper, we revisit the \\emph{sectional}\nthresholds and present a simple mechanism that can be used to create solid\nupper bounds as well. The method we present relies on a seemingly simple but\nsubstantial progress we made in studying Hopfield models in\n\\cite{StojnicHopBnds10}. \n\n"}
{"id": "1306.3801", "contents": "Title: Towards a better compressed sensing Abstract: In this paper we look at a well known linear inverse problem that is one of\nthe mathematical cornerstones of the compressed sensing field. In seminal works\n\\cite{CRT,DOnoho06CS} $\\ell_1$ optimization and its success when used for\nrecovering sparse solutions of linear inverse problems was considered.\nMoreover, \\cite{CRT,DOnoho06CS} established for the first time in a statistical\ncontext that an unknown vector of linear sparsity can be recovered as a known\nexisting solution of an under-determined linear system through $\\ell_1$\noptimization. In \\cite{DonohoPol,DonohoUnsigned} (and later in\n\\cite{StojnicCSetam09,StojnicUpper10}) the precise values of the linear\nproportionality were established as well. While the typical $\\ell_1$\noptimization behavior has been essentially settled through the work of\n\\cite{DonohoPol,DonohoUnsigned,StojnicCSetam09,StojnicUpper10}, we in this\npaper look at possible upgrades of $\\ell_1$ optimization. Namely, we look at a\ncouple of algorithms that turn out to be capable of recovering a substantially\nhigher sparsity than the $\\ell_1$. However, these algorithms assume a bit of\n\"feedback\" to be able to work at full strength. This in turn then translates\nthe original problem of improving upon $\\ell_1$ to designing algorithms that\nwould be able to provide output needed to feed the $\\ell_1$ upgrades considered\nin this papers. \n\n"}
{"id": "1306.3976", "contents": "Title: Lifting $\\ell_q$-optimization thresholds Abstract: In this paper we look at a connection between the $\\ell_q,0\\leq q\\leq 1$,\noptimization and under-determined linear systems of equations with sparse\nsolutions. The case $q=1$, or in other words $\\ell_1$ optimization and its a\nconnection with linear systems has been thoroughly studied in last several\ndecades; in fact, especially so during the last decade after the seminal works\n\\cite{CRT,DOnoho06CS} appeared. While current understanding of $\\ell_1$\noptimization-linear systems connection is fairly known, much less so is the\ncase with a general $\\ell_q,0<q<1$, optimization. In our recent work\n\\cite{StojnicLqThrBnds10} we provided a study in this direction. As a result we\nwere able to obtain a collection of lower bounds on various $\\ell_q,0\\leq q\\leq\n1$, optimization thresholds. In this paper, we provide a substantial conceptual\nimprovement of the methodology presented in \\cite{StojnicLqThrBnds10}.\nMoreover, the practical results in terms of achievable thresholds are also\nencouraging. As is usually the case with these and similar problems, the\nmethodology we developed emphasizes their a combinatorial nature and attempts\nto somehow handle it. Although our results' main contributions should be on a\nconceptual level, they already give a very strong suggestion that $\\ell_q$\noptimization can in fact provide a better performance than $\\ell_1$, a fact\nlong believed to be true due to a tighter optimization relaxation it provides\nto the original $\\ell_0$ sparsity finding oriented original problem\nformulation. As such, they in a way give a solid boost to further exploration\nof the design of the algorithms that would be able to handle $\\ell_q,0<q<1$,\noptimization in a reasonable (if not polynomial) time. \n\n"}
{"id": "1306.3977", "contents": "Title: Compressed sensing of block-sparse positive vectors Abstract: In this paper we revisit one of the classical problems of compressed sensing.\nNamely, we consider linear under-determined systems with sparse solutions. A\nsubstantial success in mathematical characterization of an $\\ell_1$\noptimization technique typically used for solving such systems has been\nachieved during the last decade. Seminal works \\cite{CRT,DOnoho06CS} showed\nthat the $\\ell_1$ can recover a so-called linear sparsity (i.e. solve systems\neven when the solution has a sparsity linearly proportional to the length of\nthe unknown vector). Later considerations \\cite{DonohoPol,DonohoUnsigned} (as\nwell as our own ones \\cite{StojnicCSetam09,StojnicUpper10}) provided the\nprecise characterization of this linearity. In this paper we consider the\nso-called structured version of the above sparsity driven problem. Namely, we\nview a special case of sparse solutions, the so-called block-sparse solutions.\nTypically one employs $\\ell_2/\\ell_1$-optimization as a variant of the standard\n$\\ell_1$ to handle block-sparse case of sparse solution systems. We considered\nsystems with block-sparse solutions in a series of work\n\\cite{StojnicCSetamBlock09,StojnicUpperBlock10,StojnicICASSP09block,StojnicJSTSP09}\nwhere we were able to provide precise performance characterizations if the\n$\\ell_2/\\ell_1$-optimization similar to those obtained for the standard\n$\\ell_1$ optimization in \\cite{StojnicCSetam09,StojnicUpper10}. Here we look at\na similar class of systems where on top of being block-sparse the unknown\nvectors are also known to have components of the same sign. In this paper we\nslightly adjust $\\ell_2/\\ell_1$-optimization to account for the known signs and\nprovide a precise performance characterization of such an adjustment. \n\n"}
{"id": "1306.5961", "contents": "Title: Gender homophily from spatial behavior in a primary school: a\n  sociometric study Abstract: We investigate gender homophily in the spatial proximity of children (6 to 12\nyears old) in a French primary school, using time-resolved data on face-to-face\nproximity recorded by means of wearable sensors. For strong ties, i.e., for\npairs of children who interact more than a defined threshold, we find\nstatistical evidence of gender preference that increases with grade. For weak\nties, conversely, gender homophily is negatively correlated with grade for\ngirls, and positively correlated with grade for boys. This different evolution\nwith grade of weak and strong ties exposes a contrasted picture of gender\nhomophily. \n\n"}
{"id": "1307.1630", "contents": "Title: Power Allocation Strategies in Energy Harvesting Wireless Cooperative\n  Networks Abstract: In this paper, a wireless cooperative network is considered, in which\nmultiple source-destination pairs communicate with each other via an energy\nharvesting relay. The focus of this paper is on the relay's strategies to\ndistribute the harvested energy among the multiple users and their impact on\nthe system performance. Specifically, a non-cooperative strategy is to use the\nenergy harvested from the i-th source as the relay transmission power to the\ni-th destination, to which asymptotic results show that its outage performance\ndecays as logSNR over SNR. A faster decaying rate, 1 over SNR, can be achieved\nby the two centralized strategies proposed this the paper, where the water\nfilling based one can achieve optimal performance with respect to several\ncriteria, with a price of high complexity. An auction based power allocation\nscheme is also proposed to achieve a better tradeoff between the system\nperformance and complexity. Simulation results are provided to confirm the\naccuracy of the developed analytical results and facilitate a better\nperformance comparison. \n\n"}
{"id": "1307.1940", "contents": "Title: Reinforcing Power Grid Transmission with FACTS Devices Abstract: We explore optimization methods for planning the placement, sizing and\noperations of Flexible Alternating Current Transmission System (FACTS) devices\ninstalled into the grid to relieve congestion created by load growth or\nfluctuations of intermittent renewable generation. We limit our selection of\nFACTS devices to those that can be represented by modification of the\ninductance of the transmission lines. Our master optimization problem minimizes\nthe $l_1$ norm of the FACTS-associated inductance correction subject to\nconstraints enforcing that no line of the system exceeds its thermal limit. We\ndevelop off-line heuristics that reduce this non-convex optimization to a\nsuccession of Linear Programs (LP) where at each step the constraints are\nlinearized analytically around the current operating point. The algorithm is\naccelerated further with a version of the cutting plane method greatly reducing\nthe number of active constraints during the optimization, while checking\nfeasibility of the non-active constraints post-factum. This hybrid algorithm\nsolves a typical single-contingency problem over the MathPower Polish Grid\nmodel (3299 lines and 2746 nodes) in 40 seconds per iteration on a standard\nlaptop---a speed up that allows the sizing and placement of a family of FACTS\ndevices to correct a large set of anticipated contingencies. From testing of\nmultiple examples, we observe that our algorithm finds feasible solutions that\nare always sparse, i.e., FACTS devices are placed on only a few lines. The\noptimal FACTS are not always placed on the originally congested lines, however\ntypically the correction(s) is made at line(s) positioned in a relative\nproximity of the overload line(s). \n\n"}
{"id": "1307.1961", "contents": "Title: Optimal Locally Repairable Linear Codes Abstract: Linear erasure codes with local repairability are desirable for distributed\ndata storage systems. An [n, k, d] code having all-symbol (r,\n\\delta})-locality, denoted as (r, {\\delta})a, is considered optimal if it also\nmeets the minimum Hamming distance bound. The existing results on the existence\nand the construction of optimal (r, {\\delta})a codes are limited to only the\nspecial case of {\\delta} = 2, and to only two small regions within this special\ncase, namely, m = 0 or m >= (v+{\\delta}-1) > ({\\delta}-1), where m = n mod\n(r+{\\delta}-1) and v = k mod r. This paper investigates the existence\nconditions and presents deterministic constructive algorithms for optimal (r,\n{\\delta})a codes with general r and {\\delta}. First, a structure theorem is\nderived for general optimal (r, {\\delta})a codes which helps illuminate some of\ntheir structure properties. Next, the entire problem space with arbitrary n, k,\nr and {\\delta} is divided into eight different cases (regions) with regard to\nthe specific relations of these parameters. For two cases, it is rigorously\nproved that no optimal (r, {\\delta})a could exist. For four other cases the\noptimal (r, {\\delta})a codes are shown to exist, deterministic constructions\nare proposed and the lower bound on the required field size for these\nalgorithms to work is provided. Our new constructive algorithms not only cover\nmore cases, but for the same cases where previous algorithms exist, the new\nconstructions require a considerably smaller field, which translates to\npotentially lower computational complexity. Our findings substantially enriches\nthe knowledge on (r, {\\delta})a codes, leaving only two cases in which the\nexistence of optimal codes are yet to be determined. \n\n"}
{"id": "1307.2090", "contents": "Title: Spectral properties of the Laplacian of multiplex networks Abstract: One of the more challenging tasks in the understanding of dynamical\nproperties of models on top of complex networks is to capture the precise role\nof multiplex topologies. In a recent paper, Gomez et al. [Phys. Rev. Lett. 101,\n028701 (2013)] proposed a framework for the study of diffusion processes in\nsuch networks. Here, we extend the previous framework to deal with general\nconfigurations in several layers of networks, and analyze the behavior of the\nspectrum of the Laplacian of the full multiplex. We derive an interesting\ndecoupling of the problem that allow us to unravel the role played by the\ninterconnections of the multiplex in the dynamical processes on top of them.\nCapitalizing on this decoupling we perform an asymptotic analysis that allow us\nto derive analytical expressions for the full spectrum of eigenvalues. This\nspectrum is used to gain insight into physical phenomena on top of multiplex,\nspecifically, diffusion processes and synchronizability. \n\n"}
{"id": "1307.2967", "contents": "Title: Layer-switching cost and optimality in information spreading on\n  multiplex networks Abstract: We study a model of information spreading on multiplex networks, in which\nagents interact through multiple interaction channels (layers), say online vs.\\\noffline communication layers, subject to layer-switching cost for transmissions\nacross different interaction layers. The model is characterized by the\nlayer-wise path-dependent transmissibility over a contact, that is dynamically\ndetermined dependently on both incoming and outgoing transmission layers. We\nformulate an analytical framework to deal with such path-dependent\ntransmissibility and demonstrate the nontrivial interplay between the\nmultiplexity and spreading dynamics, including optimality. It is shown that the\nepidemic threshold and prevalence respond to the layer-switching cost\nnon-monotonically and that the optimal conditions can change in abrupt\nnon-analytic ways, depending also on the densities of network layers and the\ntype of seed infections. Our results elucidate the essential role of\nmultiplexity that its explicit consideration should be crucial for realistic\nmodeling and prediction of spreading phenomena on multiplex social networks in\nan era of ever-diversifying social interaction layers. \n\n"}
{"id": "1307.3107", "contents": "Title: An improvement of the Feng-Rao bound for primary codes Abstract: We present a new bound for the minimum distance of a general primary linear\ncode. For affine variety codes defined from generalised C_{ab} curves the new\nbound often improves dramatically on the Feng-Rao bound for primary codes. The\nmethod does not only work for the minimum distance but can be applied to any\ngeneralised Hamming weight \n\n"}
{"id": "1307.3701", "contents": "Title: Exploiting Spatial Interference Alignment and Opportunistic Scheduling\n  in the Downlink of Interference Limited Systems Abstract: In this paper we analyze the performance of single stream and multi-stream\nspatial multiplexing (SM) systems employing opportunistic scheduling in the\npresence of interference. In the proposed downlink framework, every active user\nreports the post-processing signal-to-interference-plus-noise-power-ratio\n(post-SINR) or the receiver specific mutual information (MI) to its own\ntransmitter using a feedback channel. The combination of scheduling and\nmulti-antenna receiver processing leads to substantial interference suppression\ngain. Specifically, we show that opportunistic scheduling exploits spatial\ninterference alignment (SIA) property inherent to a multi-user system for\neffective interference mitigation. We obtain bounds for the outage probability\nand the sum outage capacity for single stream and multi stream SM employing\nreal or complex encoding for a symmetric interference channel model.\n  The techniques considered in this paper are optimal in different operating\nregimes. We show that the sum outage capacity can be maximized by reducing the\nSM rate to a value less than the maximum allowed value. The optimum SM rate\ndepends on the number of interferers and the number of available active users.\nIn particular, we show that the generalized multi-user SM (MU SM) method\nemploying real-valued encoding provides a performance that is either\ncomparable, or significantly higher than that of MU SM employing complex\nencoding. A combination of analysis and simulation is used to describe the\ntrade-off between the multiplexing rate and sum outage capacity for different\nantenna configurations. \n\n"}
{"id": "1307.5942", "contents": "Title: A unified modeling approach for the static-dynamic uncertainty strategy\n  in stochastic lot-sizing Abstract: In this paper, we develop mixed integer linear programming models to compute\nnear-optimal policy parameters for the non-stationary stochastic lot sizing\nproblem under Bookbinder and Tan's static-dynamic uncertainty strategy. Our\nmodels build on piecewise linear upper and lower bounds of the first order loss\nfunction. We discuss different formulations of the stochastic lot sizing\nproblem, in which the quality of service is captured by means of backorder\npenalty costs, non-stockout probability, or fill rate constraints. These models\ncan be easily adapted to operate in settings in which unmet demand is\nbackordered or lost. The proposed approach has a number of advantages with\nrespect to existing methods in the literature: it enables seamless modelling of\ndifferent variants of the above problem, which have been previously tackled via\nad-hoc solution methods; and it produces an accurate estimation of the expected\ntotal cost, expressed in terms of upper and lower bounds. Our computational\nstudy demonstrates the effectiveness and flexibility of our models. \n\n"}
{"id": "1307.6864", "contents": "Title: Convex recovery from interferometric measurements Abstract: This note formulates a deterministic recovery result for vectors $x$ from\nquadratic measurements of the form $(Ax)_i \\overline{(Ax)_j}$ for some\nleft-invertible $A$. Recovery is exact, or stable in the noisy case, when the\ncouples $(i,j)$ are chosen as edges of a well-connected graph. One possible way\nof obtaining the solution is as a feasible point of a simple semidefinite\nprogram. Furthermore, we show how the proportionality constant in the error\nestimate depends on the spectral gap of a data-weighted graph Laplacian. Such\nquadratic measurements have found applications in phase retrieval, angular\nsynchronization, and more recently interferometric waveform inversion. \n\n"}
{"id": "1307.7176", "contents": "Title: Phase retrieval from very few measurements Abstract: In many applications, signals are measured according to a linear process, but\nthe phases of these measurements are often unreliable or not available. To\nreconstruct the signal, one must perform a process known as phase retrieval.\nThis paper focuses on completely determining signals with as few intensity\nmeasurements as possible, and on efficient phase retrieval algorithms from such\nmeasurements. For the case of complex M-dimensional signals, we construct a\nmeasurement ensemble of size 4M-4 which yields injective intensity\nmeasurements; this is conjectured to be the smallest such ensemble. For the\ncase of real signals, we devise a theory of \"almost\" injective intensity\nmeasurements, and we characterize such ensembles. Later, we show that phase\nretrieval from M+1 almost injective intensity measurements is NP-hard,\nindicating that computationally efficient phase retrieval must come at the\nprice of measurement redundancy. \n\n"}
{"id": "1307.7249", "contents": "Title: Access Point Density and Bandwidth Partitioning in Ultra Dense Wireless\n  Networks Abstract: This paper examines the impact of system parameters such as access point\ndensity and bandwidth partitioning on the performance of randomly deployed,\ninterference-limited, dense wireless networks. While much progress has been\nachieved in analyzing randomly deployed networks via tools from stochastic\ngeometry, most existing works either assume a very large user density compared\nto that of access points which does not hold in a dense network, and/or\nconsider only the user signal-to-interference-ratio as the system figure of\nmerit which provides only partial insight on user rate, as the effect of\nmultiple access is ignored. In this paper, the user rate distribution is\nobtained analytically, taking into account the effects of multiple access as\nwell as the SIR outage. It is shown that user rate outage probability is\ndependent on the number of bandwidth partitions (subchannels) and the way they\nare utilized by the multiple access scheme. The optimal number of partitions is\nlower bounded for the case of large access point density. In addition, an upper\nbound of the minimum access point density required to provide an asymptotically\nsmall rate outage probability is provided in closed form. \n\n"}
{"id": "1308.1418", "contents": "Title: A Latent Social Approach to YouTube Popularity Prediction Abstract: Current works on Information Centric Networking assume the spectrum of\ncaching strategies under the Least Recently/ Frequently Used (LRFU) scheme as\nthe de-facto standard, due to the ease of implementation and easier analysis of\nsuch strategies. In this paper we predict the popularity distribution of\nYouTube videos within a campus network. We explore two broad approaches in\npredicting the popularity of videos in the network: consensus approaches based\non aggregate behavior in the network, and social approaches based on the\ninformation diffusion over an implicit network. We measure the performance of\nour approaches under a simple caching framework by picking the k most popular\nvideos according to our predicted distribution and calculating the hit rate on\nthe cache. We develop our approach by first incorporating video inter-arrival\ntime (based on the power-law distribution governing the transmission time\nbetween two receivers of the same message in scale-free networks) to the\nbaseline (LRFU), then combining with an information diffusion model over the\ninferred latent social graph that governs diffusion of videos in the network.\nWe apply techniques from latent social network inference to learn the sharing\nprobabilities between users in the network and apply a virus propagation model\nborrowed from mathematical epidemiology to estimate the number of times a video\nwill be accessed in the future. Our approach gives rise to a 14% hit rate\nimprovement over the baseline. \n\n"}
{"id": "1308.2144", "contents": "Title: In-Core Computation of Geometric Centralities with HyperBall: A Hundred\n  Billion Nodes and Beyond Abstract: Given a social network, which of its nodes are more central? This question\nhas been asked many times in sociology, psychology and computer science, and a\nwhole plethora of centrality measures (a.k.a. centrality indices, or rankings)\nwere proposed to account for the importance of the nodes of a network. In this\npaper, we approach the problem of computing geometric centralities, such as\ncloseness and harmonic centrality, on very large graphs; traditionally this\ntask requires an all-pairs shortest-path computation in the exact case, or a\nnumber of breadth-first traversals for approximated computations, but these\ntechniques yield very weak statistical guarantees on highly disconnected\ngraphs. We rather assume that the graph is accessed in a semi-streaming\nfashion, that is, that adjacency lists are scanned almost sequentially, and\nthat a very small amount of memory (in the order of a dozen bytes) per node is\navailable in core memory. We leverage the newly discovered algorithms based on\nHyperLogLog counters, making it possible to approximate a number of geometric\ncentralities at a very high speed and with high accuracy. While the application\nof similar algorithms for the approximation of closeness was attempted in the\nMapReduce framework, our exploitation of HyperLogLog counters reduces\nexponentially the memory footprint, paving the way for in-core processing of\nnetworks with a hundred billion nodes using \"just\" 2TiB of RAM. Moreover, the\ncomputations we describe are inherently parallelizable, and scale linearly with\nthe number of available cores. \n\n"}
{"id": "1308.3521", "contents": "Title: A New Distributed DC-Programming Method and its Applications Abstract: We propose a novel decomposition framework for the distributed optimization\nof Difference Convex (DC)-type nonseparable sum-utility functions subject to\ncoupling convex constraints. A major contribution of the paper is to develop\nfor the first time a class of (inexact) best-response-like algorithms with\nprovable convergence, where a suitably convexified version of the original DC\nprogram is iteratively solved. The main feature of the proposed successive\nconvex approximation method is its decomposability structure across the users,\nwhich leads naturally to distributed algorithms in the primal and/or dual\ndomain. The proposed framework is applicable to a variety of multiuser DC\nproblems in different areas, ranging from signal processing, to communications\nand networking. As a case study, in the second part of the paper we focus on\ntwo examples, namely: i) a novel resource allocation problem in the emerging\narea of cooperative physical layer security; ii) and the renowned sum-rate\nmaximization of MIMO Cognitive Radio networks. Our contribution in this context\nis to devise a class of easy-to-implement distributed algorithms with provable\nconvergence to stationary solution of such problems. Numerical results show\nthat the proposed distributed schemes reach performance close to (and sometimes\nbetter than) that of centralized methods. \n\n"}
{"id": "1308.3600", "contents": "Title: Random Walks on Directed Networks: Inference and Respondent-driven\n  Sampling Abstract: Respondent driven sampling (RDS) is a method often used to estimate\npopulation properties (e.g. sexual risk behavior) in hard-to-reach populations.\nIt combines an effective modified snowball sampling methodology with an\nestimation procedure that yields unbiased population estimates under the\nassumption that the sampling process behaves like a random walk on the social\nnetwork of the population. Current RDS estimation methodology assumes that the\nsocial network is undirected, i.e. that all edges are reciprocal. However,\nempirical social networks in general also have non-reciprocated edges. To\naccount for this fact, we develop a new estimation method for RDS in the\npresence of directed edges on the basis of random walks on directed networks.\nWe distinguish directed and undirected edges and consider the possibility that\nthe random walk returns to its current position in two steps through an\nundirected edge. We derive estimators of the selection probabilities of\nindividuals as a function of the number of outgoing edges of sampled\nindividuals. We evaluate the performance of the proposed estimators on\nartificial and empirical networks to show that they generally perform better\nthan existing methods. This is in particular the case when the fraction of\ndirected edges in the network is large. \n\n"}
{"id": "1308.3892", "contents": "Title: Do the rich get richer? An empirical analysis of the BitCoin transaction\n  network Abstract: The possibility to analyze everyday monetary transactions is limited by the\nscarcity of available data, as this kind of information is usually considered\nhighly sensitive. Present econophysics models are usually employed on presumed\nrandom networks of interacting agents, and only macroscopic properties (e.g.\nthe resulting wealth distribution) are compared to real-world data. In this\npaper, we analyze BitCoin, which is a novel digital currency system, where the\ncomplete list of transactions is publicly available. Using this dataset, we\nreconstruct the network of transactions, and extract the time and amount of\neach payment. We analyze the structure of the transaction network by measuring\nnetwork characteristics over time, such as the degree distribution, degree\ncorrelations and clustering. We find that linear preferential attachment drives\nthe growth of the network. We also study the dynamics taking place on the\ntransaction network, i.e. the flow of money. We measure temporal patterns and\nthe wealth accumulation. Investigating the microscopic statistics of money\nmovement, we find that sublinear preferential attachment governs the evolution\nof the wealth distribution. We report a scaling relation between the degree and\nwealth associated to individual nodes. \n\n"}
{"id": "1308.6075", "contents": "Title: Measuring the dimension of partially embedded networks Abstract: Scaling phenomena have been intensively studied during the past decade in the\ncontext of complex networks. As part of these works, recently novel methods\nhave appeared to measure the dimension of abstract and spatially embedded\nnetworks. In this paper we propose a new dimension measurement method for\nnetworks, which does not require global knowledge on the embedding of the\nnodes, instead it exploits link-wise information (link lengths, link delays or\nother physical quantities). Our method can be regarded as a generalization of\nthe spectral dimension, that grasps the network's large-scale structure through\nlocal observations made by a random walker while traversing the links. We apply\nthe presented method to synthetic and real-world networks, including road maps,\nthe Internet infrastructure and the Gowalla geosocial network. We analyze the\ntheoretically and empirically designated case when the length distribution of\nthe links has the form P(r) ~ 1/r. We show that while previous dimension\nconcepts are not applicable in this case, the new dimension measure still\nexhibits scaling with two distinct scaling regimes. Our observations suggest\nthat the link length distribution is not sufficient in itself to entirely\ncontrol the dimensionality of complex networks, and we show that the proposed\nmeasure provides information that complements other known measures. \n\n"}
{"id": "1309.0707", "contents": "Title: Feedback Communication Systems with Limitations on Incremental\n  Redundancy Abstract: This paper explores feedback systems using incremental redundancy (IR) with\nnoiseless transmitter confirmation (NTC). For IR-NTC systems based on {\\em\nfinite-length} codes (with blocklength $N$) and decoding attempts only at {\\em\ncertain specified decoding times}, this paper presents the asymptotic expansion\nachieved by random coding, provides rate-compatible sphere-packing (RCSP)\nperformance approximations, and presents simulation results of tail-biting\nconvolutional codes.\n  The information-theoretic analysis shows that values of $N$ relatively close\nto the expected latency yield the same random-coding achievability expansion as\nwith $N = \\infty$. However, the penalty introduced in the expansion by limiting\ndecoding times is linear in the interval between decoding times. For binary\nsymmetric channels, the RCSP approximation provides an efficiently-computed\napproximation of performance that shows excellent agreement with a family of\nrate-compatible, tail-biting convolutional codes in the short-latency regime.\nFor the additive white Gaussian noise channel, bounded-distance decoding\nsimplifies the computation of the marginal RCSP approximation and produces\nsimilar results as analysis based on maximum-likelihood decoding for latencies\ngreater than 200. The efficiency of the marginal RCSP approximation facilitates\noptimization of the lengths of incremental transmissions when the number of\nincremental transmissions is constrained to be small or the length of the\nincremental transmissions is constrained to be uniform after the first\ntransmission. Finally, an RCSP-based decoding error trajectory is introduced\nthat provides target error rates for the design of rate-compatible code\nfamilies for use in feedback communication systems. \n\n"}
{"id": "1309.3522", "contents": "Title: Tail bounds via generic chaining Abstract: We modify Talagrand's generic chaining method to obtain upper bounds for all\np-th moments of the supremum of a stochastic process. These bounds lead to an\nestimate for the upper tail of the supremum with optimal deviation parameters.\nWe apply our procedure to improve and extend some known deviation inequalities\nfor suprema of unbounded empirical processes and chaos processes. As an\napplication we give a significantly simplified proof of the restricted isometry\nproperty of the subsampled discrete Fourier transform. \n\n"}
{"id": "1309.3959", "contents": "Title: Bounded Confidence Opinion Dynamics in a Social Network of Bayesian\n  Decision Makers Abstract: Bounded confidence opinion dynamics model the propagation of information in\nsocial networks. However in the existing literature, opinions are only viewed\nas abstract quantities without semantics rather than as part of a\ndecision-making system. In this work, opinion dynamics are examined when agents\nare Bayesian decision makers that perform hypothesis testing or signal\ndetection, and the dynamics are applied to prior probabilities of hypotheses.\nBounded confidence is defined on prior probabilities through Bayes risk error\ndivergence, the appropriate measure between priors in hypothesis testing. This\ndefinition contrasts with the measure used between opinions in standard models:\nabsolute error. It is shown that the rapid convergence of prior probabilities\nto a small number of limiting values is similar to that seen in the standard\nKrause-Hegselmann model. The most interesting finding in this work is that the\nnumber of these limiting values and the time to convergence changes with the\nsignal-to-noise ratio in the detection task. The number of final values or\nclusters is maximal at intermediate signal-to-noise ratios, suggesting that the\nmost contentious issues lead to the largest number of factions. It is at these\nsame intermediate signal-to-noise ratios at which the degradation in detection\nperformance of the aggregate vote of the decision makers is greatest in\ncomparison to the Bayes optimal detection performance. \n\n"}
{"id": "1309.5126", "contents": "Title: The third-order term in the normal approximation for singular channels Abstract: For a singular and symmetric discrete memoryless channel with positive\ndispersion, the third-order term in the normal approximation is shown to be\nupper bounded by a constant. This finding completes the characterization of the\nthird-order term for symmetric discrete memoryless channels. The proof method\nis extended to asymmetric and singular channels with constant composition\ncodes, and its connection to existing results, as well as its limitation in the\nerror exponents regime, are discussed. \n\n"}
{"id": "1309.5440", "contents": "Title: Capacity of a POST Channel with and without Feedback Abstract: We consider finite state channels where the state of the channel is its\nprevious output. We refer to these as POST (Previous Output is the STate)\nchannels. We first focus on POST($\\alpha$) channels. These channels have binary\ninputs and outputs, where the state determines if the channel behaves as a $Z$\nor an $S$ channel, both with parameter $\\alpha$. %with parameter $\\alpha.$ We\nshow that the non feedback capacity of the POST($\\alpha$) channel equals its\nfeedback capacity, despite the memory of the channel. The proof of this\nsurprising result is based on showing that the induced output distribution,\nwhen maximizing the directed information in the presence of feedback, can also\nbe achieved by an input distribution that does not utilize of the feedback. We\nshow that this is a sufficient condition for the feedback capacity to equal the\nnon feedback capacity for any finite state channel. We show that the result\ncarries over from the POST($\\alpha$) channel to a binary POST channel where the\nprevious output determines whether the current channel will be binary with\nparameters $(a,b)$ or $(b,a)$. Finally, we show that, in general, feedback may\nincrease the capacity of a POST channel. \n\n"}
{"id": "1309.6129", "contents": "Title: Partition-Merge: Distributed Inference and Modularity Optimization Abstract: This paper presents a novel meta algorithm, Partition-Merge (PM), which takes\nexisting centralized algorithms for graph computation and makes them\ndistributed and faster. In a nutshell, PM divides the graph into small\nsubgraphs using our novel randomized partitioning scheme, runs the centralized\nalgorithm on each partition separately, and then stitches the resulting\nsolutions to produce a global solution. We demonstrate the efficiency of the PM\nalgorithm on two popular problems: computation of Maximum A Posteriori (MAP)\nassignment in an arbitrary pairwise Markov Random Field (MRF), and modularity\noptimization for community detection. We show that the resulting distributed\nalgorithms for these problems essentially run in time linear in the number of\nnodes in the graph, and perform as well -- or even better -- than the original\ncentralized algorithm as long as the graph has geometric structures. Here we\nsay a graph has geometric structures, or polynomial growth property, when the\nnumber of nodes within distance r of any given node grows no faster than a\npolynomial function of r. More precisely, if the centralized algorithm is a\nC-factor approximation with constant C \\ge 1, the resulting distributed\nalgorithm is a (C+\\delta)-factor approximation for any small \\delta>0; but if\nthe centralized algorithm is a non-constant (e.g. logarithmic) factor\napproximation, then the resulting distributed algorithm becomes a constant\nfactor approximation. For general graphs, we compute explicit bounds on the\nloss of performance of the resulting distributed algorithm with respect to the\ncentralized algorithm. \n\n"}
{"id": "1309.6270", "contents": "Title: Optimal Resource Allocation for Network Protection Against Spreading\n  Processes Abstract: We study the problem of containing spreading processes in arbitrary directed\nnetworks by distributing protection resources throughout the nodes of the\nnetwork. We consider two types of protection resources are available: (i)\nPreventive resources able to defend nodes against the spreading (such as\nvaccines in a viral infection process), and (ii) corrective resources able to\nneutralize the spreading after it has reached a node (such as antidotes). We\nassume that both preventive and corrective resources have an associated cost\nand study the problem of finding the cost-optimal distribution of resources\nthroughout the nodes of the network. We analyze these questions in the context\nof viral spreading processes in directed networks. We study the following two\nproblems: (i) Given a fixed budget, find the optimal allocation of preventive\nand corrective resources in the network to achieve the highest level of\ncontainment, and (ii) when a budget is not specified, find the minimum budget\nrequired to control the spreading process. We show that both resource\nallocation problems can be solved in polynomial time using Geometric\nProgramming (GP) for arbitrary directed graphs of nonidentical nodes and a wide\nclass of cost functions. Furthermore, our approach allows to optimize\nsimultaneously over both preventive and corrective resources, even in the case\nof cost functions being node-dependent. We illustrate our approach by designing\noptimal protection strategies to contain an epidemic outbreak that propagates\nthrough an air transportation network. \n\n"}
{"id": "1309.7478", "contents": "Title: The achievable performance of convex demixing Abstract: Demixing is the problem of identifying multiple structured signals from a\nsuperimposed, undersampled, and noisy observation. This work analyzes a general\nframework, based on convex optimization, for solving demixing problems. When\nthe constituent signals follow a generic incoherence model, this analysis leads\nto precise recovery guarantees. These results admit an attractive\ninterpretation: each signal possesses an intrinsic degrees-of-freedom\nparameter, and demixing can succeed if and only if the dimension of the\nobservation exceeds the total degrees of freedom present in the observation. \n\n"}
{"id": "1309.7528", "contents": "Title: Finite-Length Analyses for Source and Channel Coding on Markov Chains Abstract: We study finite-length bounds for source coding with side information for\nMarkov sources and channel coding for channels with conditional Markovian\nadditive noise. For this purpose, we propose two criteria for finite-length\nbounds. One is the asymptotic optimality and the other is the efficient\ncomputability of the bound. Then, we derive finite-length upper and lower\nbounds for coding length in both settings so that their computational\ncomplexity is efficient. To discuss the first criterion, we derive the large\ndeviation bounds, the moderate deviation bounds, and second order bounds for\nthese two topics, and show that these finite-length bounds achieves the\nasymptotic optimality in these senses. For this discussion, we introduce\nseveral kinds of information measure for transition matrices. \n\n"}
{"id": "1309.7843", "contents": "Title: Energy Efficient Telemonitoring of Physiological Signals via Compressed\n  Sensing: A Fast Algorithm and Power Consumption Evaluation Abstract: Wireless telemonitoring of physiological signals is an important topic in\neHealth. In order to reduce on-chip energy consumption and extend sensor life,\nrecorded signals are usually compressed before transmission. In this paper, we\nadopt compressed sensing (CS) as a low-power compression framework, and propose\na fast block sparse Bayesian learning (BSBL) algorithm to reconstruct original\nsignals. Experiments on real-world fetal ECG signals and epilepsy EEG signals\nshowed that the proposed algorithm has good balance between speed and data\nreconstruction fidelity when compared to state-of-the-art CS algorithms.\nFurther, we implemented the CS-based compression procedure and a low-power\ncompression procedure based on a wavelet transform in Filed Programmable Gate\nArray (FPGA), showing that the CS-based compression can largely save energy and\nother on-chip computing resources. \n\n"}
{"id": "1310.1806", "contents": "Title: Linear Precoding Based on Polynomial Expansion: Reducing Complexity in\n  Massive MIMO Abstract: Large-scale multi-user multiple-input multiple-output (MIMO) techniques have\nthe potential to bring tremendous improvements for future communication\nsystems. Counter-intuitively, the practical issues of having uncertain channel\nknowledge, high propagation losses, and implementing optimal non-linear\nprecoding are solved more-or-less automatically by enlarging system dimensions.\nHowever, the computational precoding complexity grows with the system\ndimensions. For example, the close-to-optimal regularized zero-forcing (RZF)\nprecoding is very complicated to implement in practice, since it requires fast\ninversions of large matrices in every coherence period. Motivated by the high\nperformance of RZF, we propose to replace the matrix inversion by a truncated\npolynomial expansion (TPE), thereby obtaining the new TPE precoding scheme\nwhich is more suitable for real-time hardware implementation. The degree of the\nmatrix polynomial can be adapted to the available hardware resources and\nenables smooth transition between simple maximum ratio transmission (MRT) and\nmore advanced RZF.\n  By deriving new random matrix results, we obtain a deterministic expression\nfor the asymptotic signal-to-interference-and-noise ratio (SINR) achieved by\nTPE precoding in large-scale MIMO systems. Furthermore, we provide a\nclosed-form expression for the polynomial coefficients that maximizes this\nSINR. To maintain a fixed per-user rate loss as compared to RZF, the polynomial\ndegree does not need to scale with the system, but it should be increased with\nthe quality of the channel knowledge and the signal-to-noise ratio (SNR). \n\n"}
{"id": "1310.3716", "contents": "Title: The Relation Between Global Migration and Trade Networks Abstract: In this paper we develop a methodology to analyze and compare multiple global\nnetworks. We focus our analysis on the relation between human migration and\ntrade. First, we identify the subset of products for which the presence of a\ncommunity of migrants significantly increases trade intensity. To assure\ncomparability across networks, we apply a hypergeometric filter to identify\nlinks for which migration and trade intensity are both significantly higher\nthan expected. Next we develop an econometric methodology, inspired by spatial\neconometrics, to measure the effect of migration on international trade while\ncontrolling for network interdependencies. Overall, we find that migration\nsignificantly boosts trade across sectors and we are able to identify product\ncategories for which this effect is particularly strong. \n\n"}
{"id": "1310.4393", "contents": "Title: An algorithm for variable density sampling with block-constrained\n  acquisition Abstract: Reducing acquisition time is of fundamental importance in various imaging\nmodalities. The concept of variable density sampling provides a nice framework\nto achieve this. It was justified recently from a theoretical point of view in\nthe compressed sensing (CS) literature. Unfortunately, the sampling schemes\nsuggested by current CS theories may not be relevant since they do not take the\nacquisition constraints into account (for example, continuity of the\nacquisition trajectory in Magnetic Resonance Imaging - MRI). In this paper, we\npropose a numerical method to perform variable density sampling with block\nconstraints. Our main contribution is to propose a new way to draw the blocks\nin order to mimic CS strategies based on isolated measurements. The basic idea\nis to minimize a tailored dissimilarity measure between a probability\ndistribution defined on the set of isolated measurements and a probability\ndistribution defined on a set of blocks of measurements. This problem turns out\nto be convex and solvable in high dimension. Our second contribution is to\ndefine an efficient minimization algorithm based on Nesterov's accelerated\ngradient descent in metric spaces. We study carefully the choice of the metrics\nand of the prox function. We show that the optimal choice may depend on the\ntype of blocks under consideration. Finally, we show that we can obtain better\nMRI reconstruction results using our sampling schemes than standard strategies\nsuch as equiangularly distributed radial lines. \n\n"}
{"id": "1310.6870", "contents": "Title: Joint Wireless Information and Energy Transfer in a K-User MIMO\n  Interference Channel Abstract: Recently, joint wireless information and energy transfer (JWIET) methods have\nbeen proposed to relieve the battery limitation of wireless devices. However,\nthe JWIET in a general K-user MIMO interference channel (IFC) has been\nunexplored so far. In this paper, we investigate for the first time the JWIET\nin K-user MIMO IFC, in which receivers either decode the incoming information\ndata (information decoding, ID) or harvest the RF energy (energy harvesting,\nEH). In the K-user IFC, we consider three different scenarios according to the\nreceiver mode -- i) multiple EH receivers and a single ID receiver, ii)\nmultiple IDs and a single EH, and iii) multiple IDs and multiple EHs. For all\nscenarios, we have found a common necessary condition of the optimal\ntransmission strategy and, accordingly, developed the transmission strategy\nthat satisfies the common necessary condition, in which all the transmitters\ntransferring energy exploit a rank-one energy beamforming. Furthermore, we have\nalso proposed an iterative algorithm to optimize the covariance matrices of the\ntransmitters that transfer information and the powers of the energy beamforming\ntransmitters simultaneously, and identified the corresponding achievable\nrate-energy tradeoff region. Finally, we have shown that by selecting EH\nreceivers according to their signal-to-leakage-and-harvested energy-ratio\n(SLER), we can improve the achievable rate-energy region further. \n\n"}
{"id": "1310.7158", "contents": "Title: Outage Constrained Robust Secure Transmission for MISO Wiretap Channels Abstract: In this paper we consider the robust secure beamformer design for MISO\nwiretap channels. Assume that the eavesdroppers' channels are only partially\navailable at the transmitter, we seek to maximize the secrecy rate under the\ntransmit power and secrecy rate outage probability constraint. The outage\nprobability constraint requires that the secrecy rate exceeds certain threshold\nwith high probability. Therefore including such constraint in the design\nnaturally ensures the desired robustness. Unfortunately, the presence of the\nprobabilistic constraints makes the problem non-convex and hence difficult to\nsolve. In this paper, we investigate the outage probability constrained secrecy\nrate maximization problem using a novel two-step approach. Under a wide range\nof uncertainty models, our developed algorithms can obtain high-quality\nsolutions, sometimes even exact global solutions, for the robust secure\nbeamformer design problem. Simulation results are presented to verify the\neffectiveness and robustness of the proposed algorithms. \n\n"}
{"id": "1310.7799", "contents": "Title: Backhaul Limited Asymmetric Cooperation for MIMO Cellular Networks via\n  Semidefinite Relaxation Abstract: Multicell cooperation has recently attracted tremendous attention because of\nits ability to eliminate intercell interference and increase spectral\nefficiency. However, the enormous amount of information being exchanged,\nincluding channel state information and user data, over backhaul links may\ndeteriorate the network performance in a realistic system. This paper adopts a\nbackhaul cost metric that considers the number of active directional\ncooperation links, which gives a first order measurement of the backhaul\nloading required in asymmetric Multiple-Input Multiple-Output (MIMO)\ncooperation. We focus on a downlink scenario for multi-antenna base stations\nand single-antenna mobile stations. The design problem is minimizing the number\nof active directional cooperation links and jointly optimizing the beamforming\nvectors among the cooperative BSs subject to\nsignal-to-interference-and-noise-ratio (SINR) constraints at the mobile\nstation. This problem is non-convex and solving it requires combinatorial\nsearch. A practical algorithm based on smooth approximation and semidefinite\nrelaxation is proposed to solve the combinatorial problem efficiently. We show\nthat semidefinite relaxation is tight with probability 1 in our algorithm and\nstationary convergence is guaranteed. Simulation results show the saving of\nbackhaul cost and power consumption is notable compared with several baseline\nschemes and its effectiveness is demonstrated. \n\n"}
{"id": "1310.8224", "contents": "Title: Transitive Reduction of Citation Networks Abstract: In many complex networks the vertices are ordered in time, and edges\nrepresent causal connections. We propose methods of analysing such directed\nacyclic graphs taking into account the constraints of causality and\nhighlighting the causal structure. We illustrate our approach using citation\nnetworks formed from academic papers, patents, and US Supreme Court verdicts.\nWe show how transitive reduction reveals fundamental differences in the\ncitation practices of different areas, how it highlights particularly\ninteresting work, and how it can correct for the effect that the age of a\ndocument has on its citation count. Finally, we transitively reduce null models\nof citation networks with similar degree distributions and show the difference\nin degree distributions after transitive reduction to illustrate the lack of\ncausal structure in such models. \n\n"}
{"id": "1311.2008", "contents": "Title: Statistical validation of high-dimensional models of growing networks Abstract: The abundance of models of complex networks and the current insufficient\nvalidation standards make it difficult to judge which models are strongly\nsupported by data and which are not. We focus here on likelihood maximization\nmethods for models of growing networks with many parameters and compare their\nperformance on artificial and real datasets. While high dimensionality of the\nparameter space harms the performance of direct likelihood maximization on\nartificial data, this can be improved by introducing a suitable penalization\nterm. Likelihood maximization on real data shows that the presented approach is\nable to discriminate among available network models. To make large-scale\ndatasets accessible to this kind of analysis, we propose a subset sampling\ntechnique and show that it yields substantial model evidence in a fraction of\ntime necessary for the analysis of the complete data. \n\n"}
{"id": "1311.2669", "contents": "Title: Distance-based and continuum Fano inequalities with applications to\n  statistical estimation Abstract: In this technical note, we give two extensions of the classical Fano\ninequality in information theory. The first extends Fano's inequality to the\nsetting of estimation, providing lower bounds on the probability that an\nestimator of a discrete quantity is within some distance $t$ of the quantity.\nThe second inequality extends our bound to a continuum setting and provides a\nvolume-based bound. We illustrate how these inequalities lead to direct and\nsimple proofs of several statistical minimax lower bounds. \n\n"}
{"id": "1311.2795", "contents": "Title: Complete solution of a constrained tropical optimization problem with\n  application to location analysis Abstract: We present a multidimensional optimization problem that is formulated and\nsolved in the tropical mathematics setting. The problem consists of minimizing\na nonlinear objective function defined on vectors over an idempotent semifield\nby means of a conjugate transposition operator, subject to constraints in the\nform of linear vector inequalities. A complete direct solution to the problem\nunder fairly general assumptions is given in a compact vector form suitable for\nboth further analysis and practical implementation. We apply the result to\nsolve a multidimensional minimax single facility location problem with\nChebyshev distance and with inequality constraints imposed on the feasible\nlocation area. \n\n"}
{"id": "1311.5064", "contents": "Title: Graph measures and network robustness Abstract: Network robustness research aims at finding a measure to quantify network\nrobustness. Once such a measure has been established, we will be able to\ncompare networks, to improve existing networks and to design new networks that\nare able to continue to perform well when it is subject to failures or attacks.\nIn this paper we survey a large amount of robustness measures on simple,\nundirected and unweighted graphs, in order to offer a tool for network\nadministrators to evaluate and improve the robustness of their network. The\nmeasures discussed in this paper are based on the concepts of connectivity\n(including reliability polynomials), distance, betweenness and clustering. Some\nother measures are notions from spectral graph theory, more precisely, they are\nfunctions of the Laplacian eigenvalues. In addition to surveying these graph\nmeasures, the paper also contains a discussion of their functionality as a\nmeasure for topological network robustness. \n\n"}
{"id": "1312.0485", "contents": "Title: Precise Semidefinite Programming Formulation of Atomic Norm Minimization\n  for Recovering d-Dimensional ($d\\geq 2$) Off-the-Grid Frequencies Abstract: Recent research in off-the-grid compressed sensing (CS) has demonstrated\nthat, under certain conditions, one can successfully recover a spectrally\nsparse signal from a few time-domain samples even though the dictionary is\ncontinuous. In particular, atomic norm minimization was proposed in\n\\cite{tang2012csotg} to recover $1$-dimensional spectrally sparse signal.\nHowever, in spite of existing research efforts \\cite{chi2013compressive}, it\nwas still an open problem how to formulate an equivalent positive semidefinite\nprogram for atomic norm minimization in recovering signals with $d$-dimensional\n($d\\geq 2$) off-the-grid frequencies. In this paper, we settle this problem by\nproposing equivalent semidefinite programming formulations of atomic norm\nminimization to recover signals with $d$-dimensional ($d\\geq 2$) off-the-grid\nfrequencies. \n\n"}
{"id": "1312.0641", "contents": "Title: Simple Bounds for Noisy Linear Inverse Problems with Exact Side\n  Information Abstract: This paper considers the linear inverse problem where we wish to estimate a\nstructured signal $x$ from its corrupted observations. When the problem is\nill-posed, it is natural to make use of a convex function $f(\\cdot)$ that\nexploits the structure of the signal. For example, $\\ell_1$ norm can be used\nfor sparse signals. To carry out the estimation, we consider two well-known\nconvex programs: 1) Second order cone program (SOCP), and, 2) Lasso. Assuming\nGaussian measurements, we show that, if precise information about the value\n$f(x)$ or the $\\ell_2$-norm of the noise is available, one can do a\nparticularly good job at estimation. In particular, the reconstruction error\nbecomes proportional to the \"sparsity\" of the signal rather than the ambient\ndimension of the noise vector. We connect our results to existing works and\nprovide a discussion on the relation of our results to the standard\nleast-squares problem. Our error bounds are non-asymptotic and sharp, they\napply to arbitrary convex functions and do not assume any distribution on the\nnoise. \n\n"}
{"id": "1312.3418", "contents": "Title: One-Bit Compressed Sensing by Greedy Algorithms Abstract: Sign truncated matching pursuit (STrMP) algorithm is presented in this paper.\nSTrMP is a new greedy algorithm for the recovery of sparse signals from the\nsign measurement, which combines the principle of consistent reconstruction\nwith orthogonal matching pursuit (OMP). The main part of STrMP is as concise as\nOMP and hence STrMP is simple to implement. In contrast to previous greedy\nalgorithms for one-bit compressed sensing, STrMP only need to solve a convex\nand unconstraint subproblem at each iteration. Numerical experiments show that\nSTrMP is fast and accurate for one-bit compressed sensing compared with other\nalgorithms. \n\n"}
{"id": "1312.4716", "contents": "Title: More Classes of Complete Permutation Polynomials over $\\F_q$ Abstract: In this paper, by using a powerful criterion for permutation polynomials\ngiven by Zieve, we give several classes of complete permutation monomials over\n$\\F_{q^r}$. In addition, we present a class of complete permutation\nmultinomials, which is a generalization of recent work. \n\n"}
{"id": "1312.5276", "contents": "Title: Integration by parts and representation of information functionals Abstract: We introduce a new formalism for computing expectations of functionals of\narbitrary random vectors, by using generalised integration by parts formulae.\nIn doing so we extend recent representation formulae for the score function\nintroduced in Nourdin, Peccati and Swan (JFA, to appear) and also provide a new\nproof of a central identity first discovered in Guo, Shamai, and Verd{\\'u}\n(IEEE Trans. Information Theory, 2005). We derive a representation for the\nstandardized Fisher information of sums of i.i.d. random vectors which use our\nidentities to provide rates of convergence in information theoretic central\nlimit theorems (both in Fisher information distance and in relative entropy). \n\n"}
{"id": "1312.5765", "contents": "Title: Multi-Branch Matching Pursuit with applications to MIMO radar Abstract: We present an algorithm, dubbed Multi-Branch Matching Pursuit (MBMP), to\nsolve the sparse recovery problem over redundant dictionaries. MBMP combines\nthree different paradigms: being a greedy method, it performs iterative signal\nsupport estimation; as a rank-aware method, it is able to exploit signal\nsubspace information when multiple snapshots are available; and, as its name\nforetells, it leverages a multi-branch (i.e., tree-search) strategy that allows\nus to trade-off hardware complexity (e.g. measurements) for computational\ncomplexity. We derive a sufficient condition under which MBMP can recover a\nsparse signal from noiseless measurements. This condition, named MB-coherence,\nis met when the dictionary is sufficiently incoherent. It incorporates the\nnumber of branches of MBMP and it requires fewer measurements than other\nconditions (e.g. the Neuman ERC or the cumulative coherence). As such,\nsuccessful recovery with MBMP is guaranteed for dictionaries that do not\nsatisfy previously known conditions. \n\n"}
{"id": "1312.6720", "contents": "Title: Weighted Multiplex Networks Abstract: One of the most important challenges in network science is to quantify the\ninformation encoded in complex network structures. Disentangling randomness\nfrom organizational principles is even more demanding when networks have a\nmultiplex nature. Multiplex networks are multilayer systems of $N$ nodes that\ncan be linked in multiple interacting and co-evolving layers. In these\nnetworks, relevant information might not be captured if the single layers were\nanalyzed separately. Here we demonstrate that such partial analysis of layers\nfails to capture significant correlations between weights and topology of\ncomplex multiplex networks. To this end, we study two weighted multiplex\nco-authorship and citation networks involving the authors included in the\nAmerican Physical Society. We show that in these networks weights are strongly\ncorrelated with multiplex structure, and provide empirical evidence in favor of\nthe advantage of studying weighted measures of multiplex networks, such as\nmultistrength and the inverse multiparticipation ratio. Finally, we introduce a\ntheoretical framework based on the entropy of multiplex ensembles to quantify\nthe information stored in multiplex networks that would remain undetected if\nthe single layers were analyzed in isolation. \n\n"}
{"id": "1401.3215", "contents": "Title: Constructions of Pure Asymmetric Quantum Alternant Codes Based on\n  Subclasses of Alternant Codes Abstract: In this paper, we construct asymmetric quantum error-correcting codes(AQCs)\nbased on subclasses of Alternant codes. Firstly, We propose a new subclass of\nAlternant codes which can attain the classical Gilbert-Varshamov bound to\nconstruct AQCs. It is shown that when $d_x=2$, $Z$-parts of the AQCs can attain\nthe classical Gilbert-Varshamov bound. Then we construct AQCs based on a famous\nsubclass of Alternant codes called Goppa codes. As an illustrative example, we\nget three $[[55,6,19/4]],[[55,10,19/3]],[[55,15,19/2]]$ AQCs from the well\nknown $[55,16,19]$ binary Goppa code. At last, we get asymptotically good\nbinary expansions of asymmetric quantum GRS codes, which are quantum\ngeneralizations of Retter's classical results. All the AQCs constructed in this\npaper are pure. \n\n"}
{"id": "1401.3617", "contents": "Title: Power Allocation in MIMO Wiretap Channel with Statistical CSI and\n  Finite-Alphabet Input Abstract: In this paper, we consider the problem of power allocation in MIMO wiretap\nchannel for secrecy in the presence of multiple eavesdroppers. Perfect\nknowledge of the destination channel state information (CSI) and only the\nstatistical knowledge of the eavesdroppers CSI are assumed. We first consider\nthe MIMO wiretap channel with Gaussian input. Using Jensen's inequality, we\ntransform the secrecy rate max-min optimization problem to a single\nmaximization problem. We use generalized singular value decomposition and\ntransform the problem to a concave maximization problem which maximizes the sum\nsecrecy rate of scalar wiretap channels subject to linear constraints on the\ntransmit covariance matrix. We then consider the MIMO wiretap channel with\nfinite-alphabet input. We show that the transmit covariance matrix obtained for\nthe case of Gaussian input, when used in the MIMO wiretap channel with\nfinite-alphabet input, can lead to zero secrecy rate at high transmit powers.\nWe then propose a power allocation scheme with an additional power constraint\nwhich alleviates this secrecy rate loss problem, and gives non-zero secrecy\nrates at high transmit powers. \n\n"}
{"id": "1401.4657", "contents": "Title: Power Control Factor Selection in Uplink OFDMA Cellular Networks Abstract: Uplink power control plays a key role on the performance of uplink cellular\nnetwork. In this work, the power control factor ($\\in[0,1]$) is evaluated based\non three parameters namely: average transmit power, coverage probability and\naverage rate. In other words, we evaluate power control factor such that\naverage transmit power should be low, coverage probability of cell-edge users\nshould be high and also average rate over all the uplink users should be high.\nWe show through numerical studies that the power control factor should be close\nto $0.5$ in order to achieve an acceptable trade-off between these three\nparameters. \n\n"}
{"id": "1401.5828", "contents": "Title: Applications of Information Nonanticipative Rate Distortion Function Abstract: The objective of this paper is to further investigate various applications of\ninformation Nonanticipative Rate Distortion Function (NRDF) by discussing two\nworking examples, the Binary Symmetric Markov Source with parameter $p$\n(BSMS($p$)) with Hamming distance distortion, and the multidimensional\npartially observed Gaussian-Markov source. For the BSMS($p$), we give the\nsolution to the NRDF, and we use it to compute the Rate Loss (RL) of causal\ncodes with respect to noncausal codes. For the multidimensional Gaussian-Markov\nsource, we give the solution to the NRDF, we show its operational meaning via\njoint source-channel matching over a vector of parallel Gaussian channels, and\nwe compute the RL of causal and zero-delay codes with respect to noncausal\ncodes. \n\n"}
{"id": "1401.6023", "contents": "Title: A Unified Approach for Network Information Theory Abstract: In this paper, we take a unified approach for network information theory and\nprove a coding theorem, which can recover most of the achievability results in\nnetwork information theory that are based on random coding. The final\nsingle-letter expression has a very simple form, which was made possible by\nmany novel elements such as a unified framework that represents various network\nproblems in a simple and unified way, a unified coding strategy that consists\nof a few basic ingredients but can emulate many known coding techniques if\nneeded, and new proof techniques beyond the use of standard covering and\npacking lemmas. For example, in our framework, sources, channels, states and\nside information are treated in a unified way and various constraints such as\ncost and distortion constraints are unified as a single joint-typicality\nconstraint.\n  Our theorem can be useful in proving many new achievability results easily\nand in some cases gives simpler rate expressions than those obtained using\nconventional approaches. Furthermore, our unified coding can strictly\noutperform existing schemes. For example, we obtain a generalized\ndecode-compress-amplify-and-forward bound as a simple corollary of our main\ntheorem and show it strictly outperforms previously known coding schemes. Using\nour unified framework, we formally define and characterize three types of\nnetwork duality based on channel input-output reversal and network flow\nreversal combined with packing-covering duality. \n\n"}
{"id": "1401.6853", "contents": "Title: Computing the Kullback-Leibler Divergence between two Generalized Gamma\n  Distributions Abstract: We derive a closed form solution for the Kullback-Leibler divergence between\ntwo generalized gamma distributions. These notes are meant as a reference and\nprovide a guided tour towards a result of practical interest that is rarely\nexplicated in the literature. \n\n"}
{"id": "1401.7085", "contents": "Title: Reverse Edge Cut-Set Bounds for Secure Network Coding Abstract: We consider the problem of secure communication over a network in the\npresence of wiretappers. We give a new cut-set bound on secrecy capacity which\ntakes into account the contribution of both forward and backward edges crossing\nthe cut, and the connectivity between their endpoints in the rest of the\nnetwork. We show the bound is tight on a class of networks, which demonstrates\nthat it is not possible to find a tighter bound by considering only cut set\nedges and their connectivity. \n\n"}
{"id": "1402.0916", "contents": "Title: Bounds on Locally Recoverable Codes with Multiple Recovering Sets Abstract: A locally recoverable code (LRC code) is a code over a finite alphabet such\nthat every symbol in the encoding is a function of a small number of other\nsymbols that form a recovering set. Bounds on the rate and distance of such\ncodes have been extensively studied in the literature. In this paper we derive\nupper bounds on the rate and distance of codes in which every symbol has $t\\geq\n1$ disjoint recovering sets. \n\n"}
{"id": "1402.1213", "contents": "Title: A Statistical Modelling Approach to Detecting Community in Networks Abstract: There has been considerable recent interest in algorithms for finding\ncommunities in networks - groups of vertex within which connections are dense\n(frequent), but between which connections are sparser (rare). Most of the\ncurrent literature advocates an heuristic approach to the removal of the edges\n(i.e., removing the links that are less significant using a well-designed\nfunction). In this article, we will investigate a technique for uncovering\nlatent communities using a new modelling approach, based on how information\nspread within a network. It will prove to be easy to use, robust and scalable.\nIt makes supplementary information related to the network/community structure\n(different communications, consecutive observations) easier to integrate. We\nwill demonstrate the efficiency of our approach by providing some illustrating\nreal-world applications, like the famous Zachary karate club, or the Amazon\npolitical books buyers network. \n\n"}
{"id": "1402.1473", "contents": "Title: Near-Optimal Joint Object Matching via Convex Relaxation Abstract: Joint matching over a collection of objects aims at aggregating information\nfrom a large collection of similar instances (e.g. images, graphs, shapes) to\nimprove maps between pairs of them. Given multiple matches computed between a\nfew object pairs in isolation, the goal is to recover an entire collection of\nmaps that are (1) globally consistent, and (2) close to the provided maps ---\nand under certain conditions provably the ground-truth maps. Despite recent\nadvances on this problem, the best-known recovery guarantees are limited to a\nsmall constant barrier --- none of the existing methods find theoretical\nsupport when more than $50\\%$ of input correspondences are corrupted. Moreover,\nprior approaches focus mostly on fully similar objects, while it is practically\nmore demanding to match instances that are only partially similar to each\nother.\n  In this paper, we develop an algorithm to jointly match multiple objects that\nexhibit only partial similarities, given a few pairwise matches that are\ndensely corrupted. Specifically, we propose to recover the ground-truth maps\nvia a parameter-free convex program called MatchLift, following a spectral\nmethod that pre-estimates the total number of distinct elements to be matched.\nEncouragingly, MatchLift exhibits near-optimal error-correction ability, i.e.\nin the asymptotic regime it is guaranteed to work even when a dominant fraction\n$1-\\Theta\\left(\\frac{\\log^{2}n}{\\sqrt{n}}\\right)$ of the input maps behave like\nrandom outliers. Furthermore, MatchLift succeeds with minimal input complexity,\nnamely, perfect matching can be achieved as soon as the provided maps form a\nconnected map graph. We evaluate the proposed algorithm on various benchmark\ndata sets including synthetic examples and real-world examples, all of which\nconfirm the practical applicability of MatchLift. \n\n"}
{"id": "1402.1617", "contents": "Title: Asynchronous Transmission over Single-User State-Dependent Channels Abstract: Several channels with asynchronous side information are introduced. We first\nconsider single-user state-dependent channels with asynchronous side\ninformation at the transmitter. It is assumed that the state information\nsequence is a possibly delayed version of the state sequence, and that the\nencoder and the decoder are aware of the fact that the state information might\nbe delayed. It is additionally assumed that an upper bound on the delay is\nknown to both encoder and decoder, but other than that, they are ignorant of\nthe actual delay. We consider both the causal and the noncausal cases and\npresent achievable rates for these channels, and the corresponding coding\nschemes. We find the capacity of the asynchronous Gel'fand-Pinsker channel with\nfeedback. Finally, we consider a memoryless state dependent channel with\nasynchronous side information at both the transmitter and receiver, and\nestablish a single-letter expression for its capacity. \n\n"}
{"id": "1402.5310", "contents": "Title: Toward automatic censorship detection in microblogs Abstract: Social media is an area where users often experience censorship through a\nvariety of means such as the restriction of search terms or active and\nretroactive deletion of messages. In this paper we examine the feasibility of\nautomatically detecting censorship of microblogs. We use a network growing\nmodel to simulate discussion over a microblog follow network and compare two\ncensorship strategies to simulate varying levels of message deletion. Using\ntopological features extracted from the resulting graphs, a classifier is\ntrained to detect whether or not a given communication graph has been censored.\nThe results show that censorship detection is feasible under empirically\nmeasured levels of message deletion. The proposed framework can enable\nautomated censorship measurement and tracking, which, when combined with\naggregated citizen reports of censorship, can allow users to make informed\ndecisions about online communication habits. \n\n"}
{"id": "1403.1023", "contents": "Title: Active Hypothesis Testing for Quickest Anomaly Detection Abstract: The problem of quickest detection of an anomalous process among M processes\nis considered. At each time, a subset of the processes can be observed, and the\nobservations from each chosen process follow two different distributions,\ndepending on whether the process is normal or abnormal. The objective is a\nsequential search strategy that minimizes the expected detection time subject\nto an error probability constraint. This problem can be considered as a special\ncase of active hypothesis testing first considered by Chernoff in 1959 where a\nrandomized strategy, referred to as the Chernoff test, was proposed and shown\nto be asymptotically (as the error probability approaches zero) optimal. For\nthe special case considered in this paper, we show that a simple deterministic\ntest achieves asymptotic optimality and offers better performance in the finite\nregime. We further extend the problem to the case where multiple anomalous\nprocesses are present. In particular, we examine the case where only an upper\nbound on the number of anomalous processes is known. \n\n"}
{"id": "1403.2732", "contents": "Title: The Bursty Dynamics of the Twitter Information Network Abstract: In online social media systems users are not only posting, consuming, and\nresharing content, but also creating new and destroying existing connections in\nthe underlying social network. While each of these two types of dynamics has\nindividually been studied in the past, much less is known about the connection\nbetween the two. How does user information posting and seeking behavior\ninteract with the evolution of the underlying social network structure?\n  Here, we study ways in which network structure reacts to users posting and\nsharing content. We examine the complete dynamics of the Twitter information\nnetwork, where users post and reshare information while they also create and\ndestroy connections. We find that the dynamics of network structure can be\ncharacterized by steady rates of change, interrupted by sudden bursts.\nInformation diffusion in the form of cascades of post re-sharing often creates\nsuch sudden bursts of new connections, which significantly change users' local\nnetwork structure. These bursts transform users' networks of followers to\nbecome structurally more cohesive as well as more homogenous in terms of\nfollower interests. We also explore the effect of the information content on\nthe dynamics of the network and find evidence that the appearance of new topics\nand real-world events can lead to significant changes in edge creations and\ndeletions. Lastly, we develop a model that quantifies the dynamics of the\nnetwork and the occurrence of these bursts as a function of the information\nspreading through the network. The model can successfully predict which\ninformation diffusion events will lead to bursts in network dynamics. \n\n"}
{"id": "1403.4583", "contents": "Title: An Achievable rate region for the $3-$user interference channel based on\n  coset codes Abstract: We consider the problem of communication over a three user discrete\nmemoryless interference channel ($3-$IC). The current known coding techniques\nfor communicating over an arbitrary $3-$IC are based on message splitting,\nsuperposition coding and binning using independent and identically distributed\n(iid) random codebooks. In this work, we propose a new ensemble of codes -\npartitioned coset codes (PCC) - that possess an appropriate mix of empirical\nand algebraic closure properties. We develop coding techniques that exploit\nalgebraic closure property of PCC to enable efficient communication over\n$3-$IC. We analyze the performance of the proposed coding technique to derive\nan achievable rate region for the general discrete $3-$IC. Additive and\nnon-additive examples are identified for which the derived achievable rate\nregion is the capacity, and moreover, strictly larger than current known\nlargest achievable rate regions based on iid random codebooks. \n\n"}
{"id": "1403.4879", "contents": "Title: A Compressive Sensing Based Approach to Sparse Wideband Array Design Abstract: Sparse wideband sensor array design for sensor location optimisation is\nhighly nonlinear and it is traditionally solved by genetic algorithms,\nsimulated annealing or other similar optimization methods. However, this is an\nextremely time-consuming process and more efficient solutions are needed. In\nthis work, this problem is studied from the viewpoint of compressive sensing\nand a formulation based on a modified $l_1$ norm is derived. As there are\nmultiple coefficients associated with each sensor, the key is to make sure that\nthese coefficients are simultaneously minimized in order to discard the\ncorresponding sensor locations. Design examples are provided to verify the\neffectiveness of the proposed methods. \n\n"}
{"id": "1403.5315", "contents": "Title: A Deterministic Annealing Optimization Approach for Witsenhausen's and\n  Related Decentralized Control Settings Abstract: This paper studies the problem of mapping optimization in decentralized\ncontrol problems. A global optimization algorithm is proposed based on the\nideas of ``deterministic annealing\" - a powerful non-convex optimization\nframework derived from information theoretic principles with analogies to\nstatistical physics. The key idea is to randomize the mappings and control the\nShannon entropy of the system during optimization. The entropy constraint is\ngradually relaxed in a deterministic annealing process while tracking the\nminimum, to obtain the ultimate deterministic mappings. Deterministic annealing\nhas been successfully employed in several problems including clustering, vector\nquantization, regression, as well as the Witsenhausen's counterexample in our\nrecent work[1]. We extend our method to a more involved setting, a variation of\nWitsenhausen's counterexample, where there is a side channel between the two\ncontrollers. The problem can be viewed as a two stage cancellation problem. We\ndemonstrate that there exist complex strategies that can exploit the side\nchannel efficiently, obtaining significant gains over the best affine and known\nnon-linear strategies. \n\n"}
{"id": "1403.5874", "contents": "Title: On Compressive Sensing in Coding Problems: A Rigorous Approach Abstract: We take an information theoretic perspective on a classical sparse-sampling\nnoisy linear model and present an analytical expression for the mutual\ninformation, which plays central role in a variety of communications/processing\nproblems. Such an expression was addressed previously either by bounds, by\nsimulations and by the (non-rigorous) replica method. The expression of the\nmutual information is based on techniques used in [1], addressing the minimum\nmean square error (MMSE) analysis. Using these expressions, we study\nspecifically a variety of sparse linear communications models which include\ncoding in different settings, accounting also for multiple access channels and\ndifferent wiretap problems. For those, we provide single-letter expressions and\nderive achievable rates, capturing the communications/processing features of\nthese timely models. \n\n"}
{"id": "1403.7543", "contents": "Title: A sparse Kaczmarz solver and a linearized Bregman method for online\n  compressed sensing Abstract: An algorithmic framework to compute sparse or minimal-TV solutions of linear\nsystems is proposed. The framework includes both the Kaczmarz method and the\nlinearized Bregman method as special cases and also several new methods such as\na sparse Kaczmarz solver. The algorithmic framework has a variety of\napplications and is especially useful for problems in which the linear\nmeasurements are slow and expensive to obtain. We present examples for online\ncompressed sensing, TV tomographic reconstruction and radio interferometry. \n\n"}
{"id": "1403.7682", "contents": "Title: Downlink Analysis for a Heterogeneous Cellular Network Abstract: In this paper, a comprehensive study of the the downlink performance in a\nheterogeneous cellular network (or hetnet) is conducted. A general hetnet model\nis considered consisting of an arbitrary number of open-access and\nclosed-access tier of base stations (BSs) arranged according to independent\nhomogeneous Poisson point processes. The BSs of each tier have a constant\ntransmission power, random fading coefficient with an arbitrary distribution\nand arbitrary path-loss exponent of the power-law path-loss model. For such a\nsystem, analytical characterizations for the coverage probability and average\nrate at an arbitrary mobile-station (MS), and average per-tier load are derived\nfor both the max-SINR connectivity and nearest-BS connectivity models. Using\nstochastic ordering, interesting properties and simplifications for the hetnet\ndownlink performance are derived by relating these two connectivity models to\nthe maximum instantaneous received power (MIRP) connectivity model and the\nmaximum biased received power (MBRP) connectivity models, respectively,\nproviding good insights about the hetnets and the downlink performance in these\ncomplex networks. Furthermore, the results also demonstrate the effectiveness\nand analytical tractability of the stochastic geometric approach to study the\nhetnet performance. \n\n"}
{"id": "1404.0333", "contents": "Title: Cross-checking different sources of mobility information Abstract: The pervasive use of new mobile devices has allowed a better characterization\nin space and time of human concentrations and mobility in general. Besides its\ntheoretical interest, describing mobility is of great importance for a number\nof practical applications ranging from the forecast of disease spreading to the\ndesign of new spaces in urban environments. While classical data sources, such\nas surveys or census, have a limited level of geographical resolution (e.g.,\ndistricts, municipalities, counties are typically used) or are restricted to\ngeneric workdays or weekends, the data coming from mobile devices can be\nprecisely located both in time and space. Most previous works have used a\nsingle data source to study human mobility patterns. Here we perform instead a\ncross-check analysis by comparing results obtained with data collected from\nthree different sources: Twitter, census and cell phones. The analysis is\nfocused on the urban areas of Barcelona and Madrid, for which data of the three\ntypes is available. We assess the correlation between the datasets on different\naspects: the spatial distribution of people concentration, the temporal\nevolution of people density and the mobility patterns of individuals. Our\nresults show that the three data sources are providing comparable information.\nEven though the representativeness of Twitter geolocated data is lower than\nthat of mobile phone and census data, the correlations between the population\ndensity profiles and mobility patterns detected by the three datasets are close\nto one in a grid with cells of 2x2 and 1x1 square kilometers. This level of\ncorrelation supports the feasibility of interchanging the three data sources at\nthe spatio-temporal scales considered. \n\n"}
{"id": "1404.1486", "contents": "Title: MIMO Multiway Relaying with Clustered Full Data Exchange: Signal Space\n  Alignment and Degrees of Freedom Abstract: We investigate achievable degrees of freedom (DoF) for a multiple-input\nmultiple-output (MIMO) multiway relay channel (mRC) with $L$ clusters and $K$\nusers per cluster. Each user is equipped with $M$ antennas and the relay with\n$N$ antennas. We assume a new data exchange model, termed \\emph{clustered full\ndata exchange}, i.e., each user in a cluster wants to learn the messages of all\nthe other users in the same cluster. Novel signal alignment techniques are\ndeveloped to systematically construct the beamforming matrices at the users and\nthe relay for efficient physical-layer network coding. Based on that, we derive\nan achievable DoF of the MIMO mRC with an arbitrary network configuration of\n$L$ and $K$, as well as with an arbitrary antenna configuration of $M$ and $N$.\nWe show that our proposed scheme achieves the DoF capacity when $\\frac{M}{N}\n\\leq \\frac{1}{LK-1}$ and $\\frac{M}{N} \\geq \\frac{(K-1)L+1}{KL}$. \n\n"}
{"id": "1404.3010", "contents": "Title: On the Energy-Spectral Efficiency Trade-off of the MRC Receiver in\n  Massive MIMO Systems with Transceiver Power Consumption Abstract: We consider the uplink of a multiuser massive MIMO system wherein a base\nstation (BS) having $M$ antennas communicates coherently with $K$ single\nantenna user terminals (UTs). We study the energy efficiency of this system\nwhile taking the transceiver power consumption at the UTs and the BS into\nconsideration. For a given spectral efficiency $R$ and fixed transceiver power\nconsumption parameters, we propose and analyze the problem of maximizing the\nenergy efficiency as a function of $(M,K)$. For the maximum ratio combining\n(MRC) detector at the BS we show that with increasing $R$, $(M,K)$ can be\nadaptively increased in such a way that the energy efficiency converges to a\npositive constant as $R \\rightarrow \\infty$ ($(M,K)$ is increased in such a way\nthat a constant per-user spectral efficiency $R/K$ is maintained). This is in\ncontrast to the fixed $(M,K)$ scenario where the energy efficiency is known to\nconverge to zero as $R \\rightarrow \\infty$. We also observe that for large $R$,\nthe optimal $(M,K)$ maximizing the energy efficiency is such that, the total\npower consumed by the power amplifiers (PA) in all the $K$ UTs is a small\nfraction of the total system power consumption. \n\n"}
{"id": "1404.3033", "contents": "Title: How to go Viral: Cheaply and Quickly Abstract: Given a social network represented by a graph $G$, we consider the problem of\nfinding a bounded cardinality set of nodes $S$ with the property that the\ninfluence spreading from $S$ in $G$ is as large as possible. The dynamics that\ngovern the spread of influence is the following: initially only elements in $S$\nare influenced; subsequently at each round, the set of influenced elements is\naugmented by all nodes in the network that have a sufficiently large number of\nalready influenced neighbors. While it is known that the general problem is\nhard to solve --- even in the approximate sense --- we present exact polynomial\ntime algorithms for trees, paths, cycles, and complete graphs. \n\n"}
{"id": "1404.3078", "contents": "Title: Distributed Compressed Sensing for Sensor Networks with Packet Erasures Abstract: We study two approaches to distributed compressed sensing for in-network data\ncompression and signal reconstruction at a sink in a wireless sensor network\nwhere sensors are placed on a straight line. Communication to the sink is\nconsidered to be bandwidth-constrained due to the large number of devices. By\nusing distributed compressed sensing for compression of the data in the\nnetwork, the communication cost (bandwith usage) to the sink can be decreased\nat the expense of delay induced by the local communication necessary for\ncompression. We investigate the relation between cost and delay given a certain\nreconstruction performance requirement when using basis pursuit denoising for\nreconstruction. Moreover, we analyze and compare the performance degradation\ndue to erased packets sent to the sink of the two approaches. \n\n"}
{"id": "1404.4975", "contents": "Title: Joint Latency and Cost Optimization for Erasure-coded Data Center\n  Storage Abstract: Modern distributed storage systems offer large capacity to satisfy the\nexponentially increasing need of storage space. They often use erasure codes to\nprotect against disk and node failures to increase reliability, while trying to\nmeet the latency requirements of the applications and clients. This paper\nprovides an insightful upper bound on the average service delay of such\nerasure-coded storage with arbitrary service time distribution and consisting\nof multiple heterogeneous files. Not only does the result supersede known delay\nbounds that only work for a single file or homogeneous files, it also enables a\nnovel problem of joint latency and storage cost minimization over three\ndimensions: selecting the erasure code, placement of encoded chunks, and\noptimizing scheduling policy. The problem is efficiently solved via the\ncomputation of a sequence of convex approximations with provable convergence.\nWe further prototype our solution in an open-source, cloud storage deployment\nover three geographically distributed data centers. Experimental results\nvalidate our theoretical delay analysis and show significant latency reduction,\nproviding valuable insights into the proposed latency-cost tradeoff in\nerasure-coded storage. \n\n"}
{"id": "1404.6000", "contents": "Title: Robust and computationally feasible community detection in the presence\n  of arbitrary outlier nodes Abstract: Community detection, which aims to cluster $N$ nodes in a given graph into\n$r$ distinct groups based on the observed undirected edges, is an important\nproblem in network data analysis. In this paper, the popular stochastic block\nmodel (SBM) is extended to the generalized stochastic block model (GSBM) that\nallows for adversarial outlier nodes, which are connected with the other nodes\nin the graph in an arbitrary way. Under this model, we introduce a procedure\nusing convex optimization followed by $k$-means algorithm with $k=r$. Both\ntheoretical and numerical properties of the method are analyzed. A theoretical\nguarantee is given for the procedure to accurately detect the communities with\nsmall misclassification rate under the setting where the number of clusters can\ngrow with $N$. This theoretical result admits to the best-known result in the\nliterature of computationally feasible community detection in SBM without\noutliers. Numerical results show that our method is both computationally fast\nand robust to different kinds of outliers, while some popular computationally\nfast community detection algorithms, such as spectral clustering applied to\nadjacency matrices or graph Laplacians, may fail to retrieve the major clusters\ndue to a small portion of outliers. We apply a slight modification of our\nmethod to a political blogs data set, showing that our method is competent in\npractice and comparable to existing computationally feasible methods in the\nliterature. To the best of the authors' knowledge, our result is the first in\nthe literature in terms of clustering communities with fast growing numbers\nunder the GSBM where a portion of arbitrary outlier nodes exist. \n\n"}
{"id": "1404.6247", "contents": "Title: Career on the Move: Geography, Stratification, and Scientific Impact Abstract: Changing institutions is an integral part of an academic life. Yet little is\nknown about the mobility patterns of scientists at an institutional level and\nhow these career choices affect scientific outcomes. Here, we examine over\n420,000 papers, to track the affiliation information of individual scientists,\nallowing us to reconstruct their career trajectories over decades. We find that\ncareer movements are not only temporally and spatially localized, but also\ncharacterized by a high degree of stratification in institutional ranking. When\ncross-group movement occurs, we find that while going from elite to lower-rank\ninstitutions on average associates with modest decrease in scientific\nperformance, transitioning into elite institutions does not result in\nsubsequent performance gain. These results offer empirical evidence on\ninstitutional level career choices and movements and have potential\nimplications for science policy. \n\n"}
{"id": "1404.6348", "contents": "Title: A DoF-Optimal Scheme for the two-user X-channel with Synergistic\n  Alternating CSIT Abstract: In this paper, the degrees of freedom (DoF) of the two-user single input\nsingle output (SISO) X-channel are investigated. Three cases are considered for\nthe availability of channel state information at the transmitters (CSIT);\nperfect, delayed, and no-CSIT. A new achievable scheme is proposed to elucidate\nthe potency of interference creation-resurrection (IRC) when the available CSIT\nalternates between these three cases. For some patterns of alternating CSIT,\nthe proposed scheme achieves $4/3$ DoF, and hence, coincides with the\ninformation theoretic upper bound on the DoF of the two-user X-channel with\nperfect and instantaneous CSIT. The CSIT alternation patterns are investigated\nwhere the patterns that provide extraordinary synergistic gain and dissociative\nones are identified. \n\n"}
{"id": "1404.6472", "contents": "Title: Parallel Gaussian Networks with a Common State-Cognitive Helper Abstract: A class of state-dependent parallel networks with a common state-cognitive\nhelper, in which $K$ transmitters wish to send $K$ messages to their\ncorresponding receivers over $K$ state-corrupted parallel channels, and a\nhelper who knows the state information noncausally wishes to assist these\nreceivers to cancel state interference. Furthermore, the helper also has its\nown message to be sent simultaneously to its corresponding receiver. Since the\nstate information is known only to the helper, but not to the corresponding\ntransmitters $1,\\dots,K$, transmitter-side state cognition and receiver-side\nstate interference are mismatched. Our focus is on the high state power regime,\ni.e., the state power goes to infinity. Three (sub)models are studied. Model I\nserves as a basic model, which consists of only one transmitter-receiver (with\nstate corruption) pair in addition to a helper that assists the receiver to\ncancel state in addition to transmitting its own message. Model II consists of\ntwo transmitter-receiver pairs in addition to a helper, and only one receiver\nis interfered by a state sequence. Model III generalizes model I include\nmultiple transmitter-receiver pairs with each receiver corrupted by independent\nstate. For all models, inner and outer bounds on the capacity region are\nderived, and comparison of the two bounds leads to characterization of either\nfull or partial boundary of the capacity region under various channel\nparameters. \n\n"}
{"id": "1404.6635", "contents": "Title: Greedy Block Coordinate Descent (GBCD) Method for High Dimensional\n  Quadratic Programs Abstract: High dimensional unconstrained quadratic programs (UQPs) involving massive\ndatasets are now common in application areas such as web, social networks, etc.\nUnless computational resources that match up to these datasets are available,\nsolving such problems using classical UQP methods is very difficult. This paper\ndiscusses alternatives. We first define high dimensional compliant (HDC)\nmethods for UQPs---methods that can solve high dimensional UQPs by adapting to\navailable computational resources. We then show that the class of block\nKaczmarz and block coordinate descent (BCD) are the only existing methods that\ncan be made HDC. As a possible answer to the question of the `best' amongst BCD\nmethods for UQP, we propose a novel greedy BCD (GBCD) method with serial,\nparallel and distributed variants. Convergence rates and numerical tests\nconfirm that the GBCD is indeed an effective method to solve high dimensional\nUQPs. In fact, it sometimes beats even the conjugate gradient. \n\n"}
{"id": "1404.6723", "contents": "Title: Subspace Codes based on Graph Matchings, Ferrers Diagrams and Pending\n  Blocks Abstract: This paper provides new constructions and lower bounds for subspace codes,\nusing Ferrers diagram rank-metric codes from matchings of the complete graph\nand pending blocks. We present different constructions for constant dimension\ncodes with minimum injection distance $2$ or $k-1$, where $k$ is the constant\ndimension. Furthermore, we present a construction of new codes from old codes\nfor any minimum distance. Then we construct non-constant dimension codes from\nthese codes. The examples of codes obtained by these constructions are the\nlargest known codes for the given parameters. \n\n"}
{"id": "1404.7022", "contents": "Title: Scaling Laws for Infrastructure Single and Multihop Wireless Networks in\n  Wideband Regimes Abstract: With millimeter wave bands emerging as a strong candidate for 5G cellular\nnetworks, next-generation systems may be in a unique position where spectrum is\nplentiful. To assess the potential value of this spectrum, this paper derives\nscaling laws on the per mobile downlink feasible rate with large bandwidth and\nnumber of nodes, for both Infrastructure Single Hop (ISH) and Infrastructure\nMulti-Hop (IMH) architectures. It is shown that, for both cases, there exist\n\\emph{critical bandwidth scalings} above which increasing the bandwidth no\nlonger increases the feasible rate per node. These critical thresholds coincide\nexactly with the bandwidths where, for each architecture, the network\ntransitions from being degrees-of-freedom-limited to power-limited. For ISH,\nthis critical bandwidth threshold is lower than IMH when the number of users\nper base station grows with network size. This result suggests that multi-hop\ntransmissions may be necessary to fully exploit large bandwidth degrees of\nfreedom in deployments with growing number of users per cell. \n\n"}
{"id": "1404.7041", "contents": "Title: Super-resolution Line Spectrum Estimation with Block Priors Abstract: We address the problem of super-resolution line spectrum estimation of an\nundersampled signal with block prior information. The component frequencies of\nthe signal are assumed to take arbitrary continuous values in known frequency\nblocks. We formulate a general semidefinite program to recover these\ncontinuous-valued frequencies using theories of positive trigonometric\npolynomials. The proposed semidefinite program achieves super-resolution\nfrequency recovery by taking advantage of known structures of frequency blocks.\nNumerical experiments show great performance enhancements using our method. \n\n"}
{"id": "1405.0599", "contents": "Title: Multipodal Structure and Phase Transitions in Large Constrained Graphs Abstract: We study the asymptotics of large, simple, labeled graphs constrained by the\ndensities of edges and of $k$-star subgraphs, $k\\ge 2$ fixed. We prove that\nunder such constraints graphs are \"multipodal\": asymptotically in the number of\nvertices there is a partition of the vertices into $M < \\infty$ subsets $V_1,\nV_2, \\ldots, V_M$, and a set of well-defined probabilities $g_{ij}$ of an edge\nbetween any $v_i \\in V_i$ and $v_j \\in V_j$. For $2\\le k\\le 30$ we determine\nthe phase space: the combinations of edge and $k$-star densities achievable\nasymptotically. For these models there are special points on the boundary of\nthe phase space with nonunique asymptotic (graphon) structure; for the 2-star\nmodel we prove that the nonuniqueness extends to entropy maximizers in the\ninterior of the phase space. \n\n"}
{"id": "1405.0814", "contents": "Title: Convex Relaxation of Optimal Power Flow, Part II: Exactness Abstract: This tutorial summarizes recent advances in the convex relaxation of the\noptimal power flow (OPF) problem, focusing on structural properties rather than\nalgorithms. Part I presents two power flow models, formulates OPF and their\nrelaxations in each model, and proves equivalence relations among them. Part II\npresents sufficient conditions under which the convex relaxations are exact. \n\n"}
{"id": "1405.2458", "contents": "Title: Quasi-linear Network Coding Abstract: We present a heuristic for designing vector non-linear network codes for\nnon-multicast networks, which we call quasi-linear network codes. The method\npresented has two phases: finding an approximate linear network code over the\nreals, and then quantizing it to a vector non-linear network code using a\nfixed-point representation. Apart from describing the method, we draw some\nlinks between some network parameters and the rate of the resulting code. \n\n"}
{"id": "1405.4429", "contents": "Title: Compressive Imaging via Approximate Message Passing with Image Denoising Abstract: We consider compressive imaging problems, where images are reconstructed from\na reduced number of linear measurements. Our objective is to improve over\nexisting compressive imaging algorithms in terms of both reconstruction error\nand runtime. To pursue our objective, we propose compressive imaging algorithms\nthat employ the approximate message passing (AMP) framework. AMP is an\niterative signal reconstruction algorithm that performs scalar denoising at\neach iteration; in order for AMP to reconstruct the original input signal well,\na good denoiser must be used. We apply two wavelet based image denoisers within\nAMP. The first denoiser is the \"amplitude-scaleinvariant Bayes estimator\"\n(ABE), and the second is an adaptive Wiener filter; we call our AMP based\nalgorithms for compressive imaging AMP-ABE and AMP-Wiener. Numerical results\nshow that both AMP-ABE and AMP-Wiener significantly improve over the state of\nthe art in terms of runtime. In terms of reconstruction quality, AMP-Wiener\noffers lower mean square error (MSE) than existing compressive imaging\nalgorithms. In contrast, AMP-ABE has higher MSE, because ABE does not denoise\nas well as the adaptive Wiener filter. \n\n"}
{"id": "1405.7096", "contents": "Title: Influence Spread in Social Networks: A Study via a Fluid Limit of the\n  Linear Threshold Model Abstract: Threshold based models have been widely used in characterizing collective\nbehavior on social networks. An individual's threshold indicates the minimum\nlevel of influence that must be exerted, by other members of the population\nengaged in some activity, before the individual will join the activity. In this\nwork, we begin with a homogeneous version of the Linear Threshold model\nproposed by Kempe et al. in the context of viral marketing, and generalize this\nmodel to arbitrary threshold distributions. We show that the evolution can be\nmodeled as a discrete time Markov chain, and, by using a certain scaling, we\nobtain a fluid limit that provides an ordinary differential equation model\n(o.d.e.). We find that the threshold distribution appears in the o.d.e. via its\nhazard rate function. We demonstrate the accuracy of the o.d.e. approximation\nand derive explicit expressions for the trajectory of influence under the\nuniform threshold distribution. Also, for an exponentially distributed\nthreshold, we show that the fluid dynamics are equivalent to the well-known SIR\nmodel in epidemiology. We also numerically study how other hazard functions\n(obtained from the Weibull and loglogistic distributions) provide qualitative\ndifferent characteristics of the influence evolution, compared to traditional\nepidemic models, even in a homogeneous setting. We finally show how the model\ncan be extended to a setting with multiple communities and conclude with\npossible future directions. \n\n"}
{"id": "1406.0267", "contents": "Title: Joint density of eigenvalues in spiked multivariate models Abstract: The classical methods of multivariate analysis are based on the eigenvalues\nof one or two sample covariance matrices. In many applications of these\nmethods, for example to high dimensional data, it is natural to consider\nalternative hypotheses which are a low rank departure from the null hypothesis.\nFor rank one alternatives, this note provides a representation for the joint\neigenvalue density in terms of a single contour integral. This will be of use\nfor deriving approximate distributions for likelihood ratios and linear\nstatistics used in testing. \n\n"}
{"id": "1406.2017", "contents": "Title: Anticipating Activity in Social Media Spikes Abstract: We propose a novel mathematical model for the activity of microbloggers\nduring an external, event-driven spike. The model leads to a testable\nprediction of who would become most active if a spike were to take place. This\ntype of information is of great interest to commercial organisations,\ngovernments and charities, as it identifies key players who can be targeted\nwith information in real time when the network is most receptive. The model\ntakes account of the fact that dynamic interactions evolve over an underlying,\nstatic network that records who listens to whom. The model is based on the\nassumption that, in the case where the entire community has become aware of an\nexternal news event, a key driver of activity is the motivation to participate\nby responding to incoming messages. We test the model on a large scale Twitter\nconversation concerning the appointment of a UK Premier League football club\nmanager. We also present further results for a Bundesliga football match, a\nmarketing event and a television programme. In each case we find that\nexploiting the underlying connectivity structure improves the prediction of who\nwill be active during a spike. We also show how the half-life of a spike in\nactivity can be quantified in terms of the network size and the typical\nresponse rate. \n\n"}
{"id": "1406.2075", "contents": "Title: Stochastic Gradient-Push for Strongly Convex Functions on Time-Varying\n  Directed Graphs Abstract: We investigate the convergence rate of the recently proposed subgradient-push\nmethod for distributed optimization over time-varying directed graphs. The\nsubgradient-push method can be implemented in a distributed way without\nrequiring knowledge of either the number of agents or the graph sequence; each\nnode is only required to know its out-degree at each time. Our main result is a\nconvergence rate of $O \\left((\\ln t)/t \\right)$ for strongly convex functions\nwith Lipschitz gradients even if only stochastic gradient samples are\navailable; this is asymptotically faster than the $O \\left((\\ln t)/\\sqrt{t}\n\\right)$ rate previously known for (general) convex functions. \n\n"}
{"id": "1406.2785", "contents": "Title: A New Class of Multiple-rate Codes Based on Block Markov Superposition\n  Transmission Abstract: Hadamard transform~(HT) as over the binary field provides a natural way to\nimplement multiple-rate codes~(referred to as {\\em HT-coset codes}), where the\ncode length $N=2^p$ is fixed but the code dimension $K$ can be varied from $1$\nto $N-1$ by adjusting the set of frozen bits. The HT-coset codes, including\nReed-Muller~(RM) codes and polar codes as typical examples, can share a pair of\nencoder and decoder with implementation complexity of order $O(N \\log N)$.\nHowever, to guarantee that all codes with designated rates perform well,\nHT-coset coding usually requires a sufficiently large code length, which in\nturn causes difficulties in the determination of which bits are better for\nbeing frozen. In this paper, we propose to transmit short HT-coset codes in the\nso-called block Markov superposition transmission~(BMST) manner. At the\ntransmitter, signals are spatially coupled via superposition, resulting in long\ncodes. At the receiver, these coupled signals are recovered by a sliding-window\niterative soft successive cancellation decoding algorithm. Most importantly,\nthe performance around or below the bit-error-rate~(BER) of $10^{-5}$ can be\npredicted by a simple genie-aided lower bound. Both these bounds and simulation\nresults show that the BMST of short HT-coset codes performs well~(within one dB\naway from the corresponding Shannon limits) in a wide range of code rates. \n\n"}
{"id": "1406.4600", "contents": "Title: Gr\\\"obner Bases for Linearized Polynomials Abstract: In this work we develop the theory of Gr\\\"obner bases for modules over the\nring of univariate linearized polynomials with coefficients from a finite\nfield. \n\n"}
{"id": "1406.6470", "contents": "Title: Wireless Networks with RF Energy Harvesting: A Contemporary Survey Abstract: Radio frequency (RF) energy transfer and harvesting techniques have recently\nbecome alternative methods to power the next generation wireless networks. As\nthis emerging technology enables proactive energy replenishment of wireless\ndevices, it is advantageous in supporting applications with quality of service\n(QoS) requirement. In this paper, we present an extensive literature review on\nthe research progresses in wireless networks with RF energy harvesting\ncapability, referred to as RF energy harvesting networks (RF-EHNs). First, we\npresent an overview of the RF-EHNs including system architecture, RF energy\nharvesting techniques and existing applications. Then, we present the\nbackground in circuit design as well as the state-of-the-art circuitry\nimplementations, and review the communication protocols specially designed for\nRF-EHNs. We also explore various key design issues in the development of\nRF-EHNs according to the network types, i.e., single-hop network, multi-antenna\nnetwork, relay network and cognitive radio network. Finally, we envision some\nopen research directions. \n\n"}
{"id": "1407.0913", "contents": "Title: Voting Behavior, Coalitions and Government Strength through a Complex\n  Network Analysis Abstract: We analyze the network of relations between parliament members according to\ntheir voting behavior. In particular, we examine the emergent community\nstructure with respect to political coalitions and government alliances. We\nrely on tools developed in the Complex Network literature to explore the core\nof these communities and use their topological features to develop new metrics\nfor party polarization, internal coalition cohesiveness and government\nstrength. As a case study, we focus on the Chamber of Deputies of the Italian\nParliament, for which we are able to characterize the heterogeneity of the\nruling coalition as well as parties specific contributions to the stability of\nthe government over time. We find sharp contrast in the political debate which\nsurprisingly does not imply a relevant structure based on establised parties.\nWe take a closer look to changes in the community structure after parties split\nup and their effect on the position of single deputies within communities.\nFinally, we introduce a way to track the stability of the government coalition\nover time that is able to discern the contribution of each member along with\nthe impact of its possible defection. While our case study relies on the\nItalian parliament, whose relevance has come into the international spotlight\nin the present economic downturn, the methods developed here are entirely\ngeneral and can therefore be applied to a multitude of other scenarios. \n\n"}
{"id": "1407.1255", "contents": "Title: Dynamic message-passing equations for models with unidirectional\n  dynamics Abstract: Understanding and quantifying the dynamics of disordered out-of-equilibrium\nmodels is an important problem in many branches of science. Using the dynamic\ncavity method on time trajectories, we construct a general procedure for\nderiving the dynamic message-passing equations for a large class of models with\nunidirectional dynamics, which includes the zero-temperature random field Ising\nmodel, the susceptible-infected-recovered model, and rumor spreading models. We\nshow that unidirectionality of the dynamics is the key ingredient that makes\nthe problem solvable. These equations are applicable to single instances of the\ncorresponding problems with arbitrary initial conditions, and are\nasymptotically exact for problems defined on locally tree-like graphs. When\napplied to real-world networks, they generically provide a good analytic\napproximation of the real dynamics. \n\n"}
{"id": "1407.1569", "contents": "Title: Joint Centrality Distinguishes Optimal Leaders in Noisy Networks Abstract: We study the performance of a network of agents tasked with tracking an\nexternal unknown signal in the presence of stochastic disturbances and under\nthe condition that only a limited subset of agents, known as leaders, can\nmeasure the signal directly. We investigate the optimal leader selection\nproblem for a prescribed maximum number of leaders, where the optimal leader\nset minimizes total system error defined as steady-state variance about the\nexternal signal. In contrast to previously established greedy algorithms for\noptimal leader selection, our results rely on an expression of total system\nerror in terms of properties of the underlying network graph. We demonstrate\nthat the performance of any given set of leaders depends on their influence as\ndetermined by a new graph measure of centrality of a set. We define the $joint\n\\; centrality$ of a set of nodes in a network graph such that a leader set with\nmaximal joint centrality is an optimal leader set. In the case of a single\nleader, we prove that the optimal leader is the node with maximal information\ncentrality. In the case of multiple leaders, we show that the nodes in the\noptimal leader set balance high information centrality with a coverage of the\ngraph. For special cases of graphs, we solve explicitly for optimal leader\nsets. We illustrate with examples. \n\n"}
{"id": "1407.5442", "contents": "Title: Cooperative Game Theoretic Solution Concepts for top-$k$ Problems Abstract: The problem of finding the $k$ most critical nodes, referred to as the\n$top\\text{-}k$ problem, is a very important one in several contexts such as\ninformation diffusion and preference aggregation in social networks, clustering\nof data points, etc. It has been observed in the literature that the value\nallotted to a node by most of the popular cooperative game theoretic solution\nconcepts, acts as a good measure of appropriateness of that node (or a data\npoint) to be included in the $top\\text{-}k$ set, by itself. However, in\ngeneral, nodes having the highest $k$ values are not the desirable\n$top\\text{-}k$ nodes, because the appropriateness of a node to be a part of the\n$top\\text{-}k$ set depends on other nodes in the set. As this is not explicitly\ncaptured by cooperative game theoretic solution concepts, it is necessary to\npost-process the obtained values in order to output the suitable $top\\text{-}k$\nnodes. In this paper, we propose several such post-processing methods and give\nreasoning behind each of them, and also propose a standalone algorithm that\ncombines cooperative game theoretic solution concepts with the popular greedy\nhill-climbing algorithm. \n\n"}
{"id": "1407.6560", "contents": "Title: Combining subspace codes with classical linear error-correcting codes Abstract: We discuss how subspace codes can be used to simultaneously correct errors\nand erasures when the network performs random linear network coding and the\nedges are noisy channels. This is done by combining the subspace code with a\nclassical linear error-correcting code. The classical code then takes care of\nthe errors and the subspace codes takes care of the erasures. \n\n"}
{"id": "1407.7629", "contents": "Title: Efficient Approximation of Channel Capacities Abstract: We propose an iterative method for approximately computing the capacity of\ndiscrete memoryless channels, possibly under additional constraints on the\ninput distribution. Based on duality of convex programming, we derive explicit\nupper and lower bounds for the capacity. The presented method requires $O(M^2 N\n\\sqrt{\\log N}/\\varepsilon)$ to provide an estimate of the capacity to within\n$\\varepsilon$, where $N$ and $M$ denote the input and output alphabet size; a\nsingle iteration has a complexity $O(M N)$. We also show how to approximately\ncompute the capacity of memoryless channels having a bounded continuous input\nalphabet and a countable output alphabet under some mild assumptions on the\ndecay rate of the channel's tail. It is shown that discrete-time Poisson\nchannels fall into this problem class. As an example, we compute sharp upper\nand lower bounds for the capacity of a discrete-time Poisson channel with a\npeak-power input constraint. \n\n"}
{"id": "1408.0063", "contents": "Title: Epidemic spreading driven by biased random walks Abstract: Random walk is one of the basic mechanisms found in many network\napplications. We study the epidemic spreading dynamics driven by biased random\nwalks on complex networks. In our epidemic model, each time infected nodes\nconstantly spread some infected packets by biased random walks to their\nneighbor nodes causing the infection of the susceptible nodes that receive the\npackets. An infected node get recovered from infection with a fixed\nprobability. Simulation and analytical results on model and real-world networks\nshow that the epidemic spreading becomes intense and wide with the increase of\ndelivery capacity of infected nodes, average node degree, homogeneity of node\ndegree distribution. Furthermore, there are corresponding optimal parameters\nsuch that the infected nodes have instantaneously the largest population, and\nthe epidemic spreading process covers the largest part of a network. \n\n"}
{"id": "1408.0313", "contents": "Title: Tropical optimization problems Abstract: We consider optimization problems that are formulated and solved in the\nframework of tropical mathematics. The problems consist in minimizing or\nmaximizing functionals defined on vectors of finite-dimensional semimodules\nover idempotent semifields, and may involve constraints in the form of linear\nequations and inequalities. The objective function can be either a linear\nfunction or nonlinear function calculated by means of multiplicative conjugate\ntransposition of vectors. We start with an overview of known tropical\noptimization problems and solution methods. Then, we formulate certain new\nproblems and present direct solutions to the problems in a closed compact\nvector form suitable for further analysis and applications. For many problems,\nthe results obtained are complete solutions. \n\n"}
{"id": "1408.0549", "contents": "Title: Downlink Cellular Network Analysis with Multi-slope Path Loss Models Abstract: Existing cellular network analyses, and even simulations, typically use the\nstandard path loss model where received power decays like $\\|x\\|^{-\\alpha}$\nover a distance $\\|x\\|$. This standard path loss model is quite idealized, and\nin most scenarios the path loss exponent $\\alpha$ is itself a function of\n$\\|x\\|$, typically an increasing one. Enforcing a single path loss exponent can\nlead to orders of magnitude differences in average received and interference\npowers versus the true values. In this paper we study \\emph{multi-slope} path\nloss models, where different distance ranges are subject to different path loss\nexponents. We focus on the dual-slope path loss function, which is a piece-wise\npower law and continuous and accurately approximates many practical scenarios.\nWe derive the distributions of SIR, SNR, and finally SINR before finding the\npotential throughput scaling, which provides insight on the observed\ncell-splitting rate gain. The exact mathematical results show that the SIR\nmonotonically decreases with network density, while the converse is true for\nSNR, and thus the network coverage probability in terms of SINR is maximized at\nsome finite density. With ultra-densification (network density goes to\ninfinity), there exists a \\emph{phase transition} in the near-field path loss\nexponent $\\alpha_0$: if $\\alpha_0 >1$ unbounded potential throughput can be\nachieved asymptotically; if $\\alpha_0 <1$, ultra-densification leads in the\nextreme case to zero throughput. \n\n"}
{"id": "1408.1119", "contents": "Title: Second-Order Asymptotics for the Discrete Memoryless MAC with Degraded\n  Message Sets Abstract: This paper studies the second-order asymptotics of the discrete memoryless\nmultiple-access channel with degraded message sets. For a fixed average error\nprobability $\\epsilon\\in(0,1)$ and an arbitrary point on the boundary of the\ncapacity region, we characterize the speed of convergence of rate pairs that\nconverge to that point for codes that have asymptotic error probability no\nlarger than $\\epsilon$, thus complementing an analogous result given previously\nfor the Gaussian setting. \n\n"}
{"id": "1408.1494", "contents": "Title: The digital traces of bubbles: feedback cycles between socio-economic\n  signals in the Bitcoin economy Abstract: What is the role of social interactions in the creation of price bubbles?\nAnswering this question requires obtaining collective behavioural traces\ngenerated by the activity of a large number of actors. Digital currencies offer\na unique possibility to measure socio-economic signals from such digital\ntraces. Here, we focus on Bitcoin, the most popular cryptocurrency. Bitcoin has\nexperienced periods of rapid increase in exchange rates (price) followed by\nsharp decline; we hypothesise that these fluctuations are largely driven by the\ninterplay between different social phenomena. We thus quantify four\nsocio-economic signals about Bitcoin from large data sets: price on on-line\nexchanges, volume of word-of-mouth communication in on-line social media,\nvolume of information search, and user base growth. By using vector\nautoregression, we identify two positive feedback loops that lead to price\nbubbles in the absence of exogenous stimuli: one driven by word of mouth, and\nthe other by new Bitcoin adopters. We also observe that spikes in information\nsearch, presumably linked to external events, precede drastic price declines.\nUnderstanding the interplay between the socio-economic signals we measured can\nlead to applications beyond cryptocurrencies to other phenomena which leave\ndigital footprints, such as on-line social network usage. \n\n"}
{"id": "1408.1560", "contents": "Title: MacWilliams identities for poset level weight enumerators of linear\n  codes Abstract: Codes over various metrics such as Rosenbloom-Tsfasman (RT), Lee, etc. have\nbeen considered. Recently, codes over poset metrics have been studied. Poset\nmetric is a great generalization of many metrics especially the well-known ones\nsuch as the RT and the Hamming metrics. Poset metric can be realized on the\nchannels with localized error occurrences. It has been shown that MacWilliams\nidentities are not admissible for codes over poset metrics in general [Kim and\nOh, 2005]. Lately, to overcome this problem some further studies on MacWilliams\nidentities over poset metrics has been presented. In this paper, we introduce\nnew poset level weight enumerators of linear codes over Frobenius commutative\nrings. We derive MacWilliams-type identities for each of the given enumerators\nwhich generalize in great deal the previous results discussed in the\nliterature. Most of the weight enumerators in the literature such as Hamming,\nRosenbloom-Tsfasman and complete m-spotty weight enumerators follow as\ncorollaries to these identities especially. \n\n"}
{"id": "1408.1774", "contents": "Title: Beyond description. Comment on \"Approaching human language with complex\n  networks\" by Cong & Liu Abstract: Comment on \"Approaching human language with complex networks\" by Cong & Liu \n\n"}
{"id": "1408.2621", "contents": "Title: Performance Comparison of LDPC Block and Spatially Coupled Codes over\n  GF(q) Abstract: In this paper, we compare the finite-length performance of protograph-based\nspatially coupled low-density parity-check (SC-LDPC) codes and LDPC block codes\n(LDPC-BCs) over GF(q). In order to reduce computational complexity and latency,\na sliding window decoder with a stopping rule based on a soft bit-error-rate\n(BER) estimate is used for the q-ary SC-LDPC codes. Two regimes are considered:\none when the constraint length of q-ary SC-LDPC codes is equal to the block\nlength of q-ary LDPC-BCs and the other when the two decoding latencies are\nequal. Simulation results confirm that, in both regimes, (3,6)-, (3,9)-, and\n(3,12)-regular non-binary SC-LDPC codes can significantly outperform both\nbinary and non-binary LDPC-BCs and binary SC-LDPC codes. Finally, we present a\ncomputational complexity comparison of q-ary SC-LDPC codes and q-ary LDPC-BCs\nunder equal decoding latency and equal decoding performance assumptions. \n\n"}
{"id": "1408.3206", "contents": "Title: Distributed Power Splitting for SWIPT in Relay Interference Channels\n  using Game Theory Abstract: In this paper, we consider simultaneous wireless information and power\ntransfer (SWIPT) in relay interference channels, where multiple\nsource-destination pairs communicate through their dedicated energy harvesting\nrelays. Each relay needs to split its received signal from sources into two\nstreams: one for information forwarding and the other for energy harvesting. We\ndevelop a distributed power splitting framework using game theory to derive a\nprofile of power splitting ratios for all relays that can achieve a good\nnetwork-wide performance. Specifically, non-cooperative games are respectively\nformulated for pure amplify-and-forward (AF) and decode-and-forward (DF)\nnetworks, in which each link is modeled as a strategic player who aims to\nmaximize its own achievable rate. The existence and uniqueness for the Nash\nequilibriums (NEs) of the formulated games are analyzed and a distributed\nalgorithm with provable convergence to achieve the NEs is also developed.\nSubsequently, the developed framework is extended to the more general network\nsetting with mixed AF and DF relays. All the theoretical analyses are validated\nby extensive numerical results. Simulation results show that the proposed\ngame-theoretical approach can achieve a near-optimal network-wide performance\non average, especially for the scenarios with relatively low and moderate\ninterference. \n\n"}
{"id": "1408.4910", "contents": "Title: Explaining the Power-law Distribution of Human Mobility Through\n  Transportation Modality Decomposition Abstract: Human mobility has been empirically observed to exhibit Levy flight\ncharacteristics and behaviour with power-law distributed jump size. The\nfundamental mechanisms behind this behaviour has not yet been fully explained.\nIn this paper, we analyze urban human mobility and we propose to explain the\nLevy walk behaviour observed in human mobility patterns by decomposing them\ninto different classes according to the different transportation modes, such as\nWalk/Run, Bicycle, Train/Subway or Car/Taxi/Bus. Our analysis is based on two\nreal-life GPS datasets containing approximately 10 and 20 million GPS samples\nwith transportation mode information. We show that human mobility can be\nmodelled as a mixture of different transportation modes, and that these single\nmovement patterns can be approximated by a lognormal distribution rather than a\npower-law distribution. Then, we demonstrate that the mixture of the decomposed\nlognormal flight distributions associated with each modality is a power-law\ndistribution, providing an explanation to the emergence of Levy Walk patterns\nthat characterize human mobility patterns. \n\n"}
{"id": "1408.5468", "contents": "Title: A Sytematic Piggybacking Design for Minimum Storage Regenerating Codes Abstract: Piggybacking is an efficient method to decrease the repair bandwidth of\nMaximum Distance Separable (MDS) codes or Minimum Storage Regenerating (MSR)\ncodes. In this paper, for minimizing the repair bandwidth of parity nodes of\nthe known MSR codes with high rate, which is usually the whole size of the\noriginal data, i.e., the maximal, a new systematic piggybacking design is\nproposed through an in-depth analysis of the design of piggybacking. As a\nresult, new MSR codes are obtained with almost optimal repair bandwidth of\nparity nodes while retaining the optimal repair bandwidth of systematic nodes.\nFurthermore, MSR codes with balanced download during node repair process are\npresented based on the new piggybacking design. \n\n"}
{"id": "1408.5782", "contents": "Title: A Construction of MDS Quantum Convolutional Codes Abstract: In this paper, two new families of MDS quantum convolutional codes are\nconstructed. The first one can be regarded as a generalization of \\cite[Theorem\n6.5]{GGGlinear}, in the sense that we do not assume that $q\\equiv1\\pmod{4}$.\nMore specifically, we obtain two classes of MDS quantum convolutional codes\nwith parameters: {\\rm (i)}~ $[(q^2+1, q^2-4i+3,1;2,2i+2)]_q$, where $q\\geq5$ is\nan odd prime power and $2\\leq i\\leq(q-1)/2$; {\\rm (ii)}~\n$[(\\frac{q^2+1}{10},\\frac{q^2+1}{10}-4i,1;2,2i+3)]_q$, where $q$ is an odd\nprime power with the form\n  $q=10m+3$ or $10m+7$ ($m\\geq2$), and $2\\leq i\\leq2m-1$. \n\n"}
{"id": "1408.5971", "contents": "Title: A Dichotomy of Functions in Distributed Coding: An Information Spectral\n  Approach Abstract: The problem of distributed data compression for function computation is\nconsidered, where (i) the function to be computed is not necessarily\nsymbol-wise function and (ii) the information source has memory and may not be\nstationary nor ergodic. We introduce the class of smooth sources and give a\nsufficient condition on functions so that the achievable rate region for\ncomputing coincides with the Slepian-Wolf region (i.e., the rate region for\nreproducing the entire source) for any smooth sources. Moreover, for\nsymbol-wise functions, the necessary and sufficient condition for the\ncoincidence is established. Our result for the full side-information case is a\ngeneralization of the result by Ahlswede and Csiszar to sources with memory;\nour dichotomy theorem is different from Han and Kobayashi's dichotomy theorem,\nwhich reveals an effect of memory in distributed function computation. All\nresults are given not only for fixed-length coding but also for variable-length\ncoding in a unified manner. Furthermore, for the full side-information case,\nthe error probability in the moderate deviation regime is also investigated. \n\n"}
{"id": "1408.6801", "contents": "Title: Optimal control theory with arbitrary superpositions of waveforms Abstract: Standard optimal control methods perform optimization in the time domain.\nHowever, many experimental settings demand the expression of the control signal\nas a superposition of given waveforms, a case that cannot easily be\naccommodated using time-local constraints. Previous approaches [1,2] have\ncircumvented this difficulty by performing optimization in a parameter space,\nusing the chain rule to make a connection to the time domain. In this paper, we\npresent an extension to Optimal Control Theory which allows gradient-based\noptimization for superpositions of arbitrary waveforms directly in a\ntime-domain subspace. Its key is the use of the Moore-Penrose pseudoinverse as\nan efficient means of transforming between a time-local and waveform-based\ndescriptions. To illustrate this optimization technique, we study the\nparametrically driven harmonic oscillator as model system and reduce its\nenergy, considering both Hamiltonian dynamics and stochastic dynamics under the\ninfluence of a thermal reservoir. We demonstrate the viability and efficiency\nof the method for these test cases and find significant advantages in the case\nof waveforms which do not form an orthogonal basis. \n\n"}
{"id": "1408.6959", "contents": "Title: Heterogeneous Recovery Rates against SIS Epidemics in Directed Networks Abstract: The nodes in communication networks are possibly and most likely equipped\nwith different recovery resources, which allow them to recover from a virus\nwith different rates. In this paper, we aim to understand know how to allocate\nthe limited recovery resources to efficiently prevent the spreading of\nepidemics. We study the susceptible-infected-susceptible (SIS) epidemic model\non directed scale-free networks. In the classic SIS model, a susceptible node\ncan be infected by an infected neighbor with the infection rate $\\beta$ and an\ninfected node can be recovered to be susceptible again with the recovery rate\n$\\delta$. In the steady state a fraction $y_\\infty$ of nodes are infected,\nwhich shows how severely the network is infected. We propose to allocate the\nrecovery rate $\\delta_i$ for node $i$ according to its indegree and\noutdegree-$\\delta_i\\scriptsize{\\sim}k_{i,in}^{\\alpha_{in}}k_{i,out}^{\\alpha_{out}}$,\ngiven the finite average recovery rate $\\langle\\delta\\rangle$ representing the\nlimited recovery resources over the whole network. We find that, by tuning the\ntwo scaling exponents $\\alpha_{in}$ and $\\alpha_{out}$, we can always reduce\nthe infection fraction $y_\\infty$ thus reducing the extent of infections,\ncomparing to the homogeneous recovery rates allocation. Moreover, we can find\nour optimal strategy via the optimal choice of the exponent $\\alpha_{in}$ and\n$\\alpha_{out}$. Our optimal strategy indicates that when the recovery resources\nare sufficient, more resources should be allocated to the nodes with a larger\nindegree or outdegree, but when the recovery resource is very limited, only the\nnodes with a larger outdegree should be equipped with more resources. We also\nfind that our optimal strategy works better when the recovery resources are\nsufficient but not yet able to make the epidemic die out, and when the indegree\noutdegree correlation is small. \n\n"}
{"id": "1409.1184", "contents": "Title: Spectral Efficiency of the Cellular Two-Way Relaying with Large Antenna\n  Arrays Abstract: This paper considers a multiuser cellular two-way relay network (cTWRN) where\nmultiple users exchange information with a base station (BS) via a relay\nstation (RS). Each user is equipped with a single antenna, while both the BS\nand the RS are equipped with a very large antenna array. We investigate the\nperformance of the cTWRN with amplify-and-forward (AF) based physical-layer\nnetwork coding, and derive closed-form expression for the asymptotic spectral\nefficiency when both the number of antennas at the BS and the RS grow large. It\nis shown that the noise propagation of the non-regenerative relaying protocol\ncan be greatly suppressed, and the AF relaying scheme can approach the cut-set\nbound under certain conditions. We also investigate the performance of the AF\nrelaying scheme under two power-scaling cases, and show that the transmit power\nof the BS and each user can be made inversely proportional to the number of\nrelay antennas while maintaining a given quality-of-service. Numerical results\nare presented to verify the analytical results. \n\n"}
{"id": "1409.5253", "contents": "Title: Multiplexity versus correlation: the role of local constraints in real\n  multiplexes Abstract: Several real-world systems can be represented as multi-layer complex\nnetworks, i.e. in terms of a superposition of various graphs, each related to a\ndifferent mode of connection between nodes. Hence, the definition of proper\nmathematical quantities aiming at capturing the level of complexity of those\nsystems is required. Various attempts have been made to measure the empirical\ndependencies between the layers of a multiplex, for both binary and weighted\nnetworks. In the simplest case, such dependencies are measured via\ncorrelation-based metrics: we show that this is equivalent to the use of\ncompletely homogeneous benchmarks specifying only global constraints, such as\nthe total number of links in each layer. However, these approaches do not take\ninto account the heterogeneity in the degree and strength distributions, which\nare instead a fundamental feature of real-world multiplexes. In this work, we\ncompare the observed dependencies between layers with the expected values\nobtained from reference models that appropriately control for the observed\nheterogeneity in the degree and strength distributions. This leads to novel\nmultiplexity measures that we test on different datasets, i.e. the\nInternational Trade Network (ITN) and the European Airport Network (EAN). Our\nfindings confirm that the use of homogeneous benchmarks can lead to misleading\nresults, and furthermore highlight the important role played by the\ndistribution of hubs across layers. \n\n"}
{"id": "1409.5532", "contents": "Title: Linear Degrees of Freedom of MIMO Broadcast Channels with Reconfigurable\n  Antennas in the Absence of CSIT Abstract: The K-user multiple-input and multiple-output (MIMO) broadcast channel (BC)\nwith no channel state information at the transmitter (CSIT) is considered,\nwhere each receiver is assumed to be equipped with reconfigurable antennas\ncapable of choosing a subset of receiving modes from several preset modes.\nUnder general antenna configurations, the sum linear degrees of freedom (LDoF)\nof the K-user MIMO BC with reconfigurable antennas is completely characterized,\nwhich corresponds to the maximum sum DoF achievable by linear coding\nstrategies. The LDoF region is further characterized for a class of antenna\nconfigurations. Similar analysis is extended to the K-user MIMO interference\nchannels with reconfigurable antennas and the sum LDoF is characterized for a\nclass of antenna configurations. \n\n"}
{"id": "1409.6022", "contents": "Title: Exact Analysis of k-Connectivity in Secure Sensor Networks with\n  Unreliable Links Abstract: The Eschenauer--Gligor (EG) random key predistribution scheme has been widely\nrecognized as a typical approach to secure communications in wireless sensor\nnetworks (WSNs). However, there is a lack of precise probability analysis on\nthe reliable connectivity of WSNs under the EG scheme. To address this, we\nrigorously derive the asymptotically exact probability of $k$-connectivity in\nWSNs employing the EG scheme with unreliable links represented by independent\non/off channels, where $k$-connectivity ensures that the network remains\nconnected despite the failure of any $(k-1)$ sensors or links. Our analytical\nresults are confirmed via numerical experiments, and they provide precise\nguidelines for the design of secure WSNs that exhibit a desired level of\nreliability against node and link failures. \n\n"}
{"id": "1409.6197", "contents": "Title: Online Privacy as a Collective Phenomenon Abstract: The problem of online privacy is often reduced to individual decisions to\nhide or reveal personal information in online social networks (OSNs). However,\nwith the increasing use of OSNs, it becomes more important to understand the\nrole of the social network in disclosing personal information that a user has\nnot revealed voluntarily: How much of our private information do our friends\ndisclose about us, and how much of our privacy is lost simply because of online\nsocial interaction? Without strong technical effort, an OSN may be able to\nexploit the assortativity of human private features, this way constructing\nshadow profiles with information that users chose not to share. Furthermore,\nbecause many users share their phone and email contact lists, this allows an\nOSN to create full shadow profiles for people who do not even have an account\nfor this OSN.\n  We empirically test the feasibility of constructing shadow profiles of sexual\norientation for users and non-users, using data from more than 3 Million\naccounts of a single OSN. We quantify a lower bound for the predictive power\nderived from the social network of a user, to demonstrate how the\npredictability of sexual orientation increases with the size of this network\nand the tendency to share personal information. This allows us to define a\nprivacy leak factor that links individual privacy loss with the decision of\nother individuals to disclose information. Our statistical analysis reveals\nthat some individuals are at a higher risk of privacy loss, as prediction\naccuracy increases for users with a larger and more homogeneous first- and\nsecond-order neighborhood of their social network. While we do not provide\nevidence that shadow profiles exist at all, our results show that disclosing of\nprivate information is not restricted to an individual choice, but becomes a\ncollective decision that has implications for policy and privacy regulation. \n\n"}
{"id": "1409.6758", "contents": "Title: Stochastic Reactive Power Management in Microgrids with Renewables Abstract: Distribution microgrids are being challenged by reverse power flows and\nvoltage fluctuations due to renewable generation, demand response, and electric\nvehicles. Advances in photovoltaic (PV) inverters offer new opportunities for\nreactive power management provided PV owners have the right investment\nincentives. In this context, reactive power compensation is considered here as\nan ancillary service. Accounting for the increasing time-variability of\ndistributed generation and demand, a stochastic reactive power compensation\nscheme is developed. Given uncertain active power injections, an online\nreactive control scheme is devised. This scheme is distribution-free and relies\nsolely on power injection data. Reactive injections are updated using the\nLagrange multipliers of a second-order cone program. Numerical tests on an\nindustrial 47-bus microgrid and the residential IEEE 123-bus feeder corroborate\nthe reactive power management efficiency of the novel stochastic scheme over\nits deterministic alternative, as well as its capability to track variations in\nsolar generation and household demand. \n\n"}
{"id": "1409.7458", "contents": "Title: Beyond Maximum Likelihood: from Theory to Practice Abstract: Maximum likelihood is the most widely used statistical estimation technique.\nRecent work by the authors introduced a general methodology for the\nconstruction of estimators for functionals in parametric models, and\ndemonstrated improvements - both in theory and in practice - over the maximum\nlikelihood estimator (MLE), particularly in high dimensional scenarios\ninvolving parameter dimension comparable to or larger than the number of\nsamples. This approach to estimation, building on results from approximation\ntheory, is shown to yield minimax rate-optimal estimators for a wide class of\nfunctionals, implementable with modest computational requirements. In a\nnutshell, a message of this recent work is that, for a wide class of\nfunctionals, the performance of these essentially optimal estimators with $n$\nsamples is comparable to that of the MLE with $n \\ln n$ samples.\n  In the present paper, we highlight the applicability of the aforementioned\nmethodology to statistical problems beyond functional estimation, and show that\nit can yield substantial gains. For example, we demonstrate that for learning\ntree-structured graphical models, our approach achieves a significant reduction\nof the required data size compared with the classical Chow--Liu algorithm,\nwhich is an implementation of the MLE, to achieve the same accuracy. The key\nstep in improving the Chow--Liu algorithm is to replace the empirical mutual\ninformation with the estimator for mutual information proposed by the authors.\nFurther, applying the same replacement approach to classical Bayesian network\nclassification, the resulting classifiers uniformly outperform the previous\nclassifiers on 26 widely used datasets. \n\n"}
{"id": "1409.8196", "contents": "Title: Hyperbolicity, degeneracy, and expansion of random intersection graphs Abstract: We establish the conditions under which several algorithmically exploitable\nstructural features hold for random intersection graphs, a natural model for\nmany real-world networks where edges correspond to shared attributes.\nSpecifically, we fully characterize the degeneracy of random intersection\ngraphs, and prove that the model asymptotically almost surely produces graphs\nwith hyperbolicity at least $\\log{n}$. Further, we prove that in the parametric\nregime where random intersection graphs are degenerate an even stronger notion\nof sparseness, so called bounded expansion, holds with high probability. We\nsupplement our theoretical findings with experimental evaluations of the\nrelevant statistics. \n\n"}
{"id": "1410.0586", "contents": "Title: Generalized Friendship Paradox: An Analytical Approach Abstract: The friendship paradox refers to the sociological observation that, while the\npeople's assessment of their own popularity is typically self-aggrandizing, in\nreality they are less popular than their friends. The generalized friendship\nparadox is the average alter superiority observed empirically in social\nsettings, scientific collaboration networks, as well as online social media. We\nposit a quality-based network growth model in which the chance for a node to\nreceive new links depends both on its degree and a quality parameter. Nodes are\nassigned qualities the first time they join the network, and these do not\nchange over time. We analyse the model theoretically, finding expressions for\nthe joint degree-quality distribution and nearest-neighbor distribution. We\nthen demonstrate that this model exhibits both the friendship paradox and the\ngeneralized friendship paradox at the network level, regardless of the\ndistribution of qualities. We also show that, in the proposed model, the degree\nand quality of each node are positively correlated regardless of how node\nqualities are distributed. \n\n"}
{"id": "1410.1710", "contents": "Title: A Cost / Speed / Reliability Trade-off to Erasing Abstract: We present a KL-control treatment of the fundamental problem of erasing a\nbit. We introduce notions of \"reliability\" of information storage via a\nreliability timescale $\\tau_r$, and \"speed\" of erasing via an erasing timescale\n$\\tau_e$. Our problem formulation captures the tradeoff between speed,\nreliability, and the Kullback-Leibler (KL) cost required to erase a bit. We\nshow that rapid erasing of a reliable bit costs at least $\\log 2 - \\log\\left(1\n- \\operatorname{e}^{-\\frac{\\tau_e}{\\tau_r}}\\right) > \\log 2$, which goes to\n$\\frac{1}{2} \\log\\frac{2\\tau_r}{\\tau_e}$ when $\\tau_r>>\\tau_e$. \n\n"}
{"id": "1410.2405", "contents": "Title: Guessing Games on Triangle-free Graphs Abstract: The guessing game introduced by Riis is a variant of the \"guessing your own\nhats\" game and can be played on any simple directed graph G on n vertices. For\neach digraph G, it is proved that there exists a unique guessing number gn(G)\nassociated to the guessing game played on G. When we consider the directed edge\nto be bidirected, in other words, the graph G is undirected, Christofides and\nMarkstr\u007fom introduced a method to bound the value of the guessing number from\nbelow using the fractional clique number Kf(G). In particular they showed gn(G)\n>= |V(G)| - Kf(G). Moreover, it is pointed out that equality holds in this\nbound if the underlying undirected graph G falls into one of the following\ncategories: perfect graphs, cycle graphs or their complement. In this paper, we\nshow that there are triangle-free graphs that have guessing numbers which do\nnot meet the fractional clique cover bound. In particular, the famous\ntriangle-free Higman-Sims graph has guessing number at least 77 and at most 78,\nwhile the bound given by fractional clique cover is 50. \n\n"}
{"id": "1410.2724", "contents": "Title: Compressed Sensing With Side Information: Geometrical Interpretation and\n  Performance Bounds Abstract: We address the problem of Compressed Sensing (CS) with side information.\nNamely, when reconstructing a target CS signal, we assume access to a similar\nsignal. This additional knowledge, the side information, is integrated into CS\nvia L1-L1 and L1-L2 minimization. We then provide lower bounds on the number of\nmeasurements that these problems require for successful reconstruction of the\ntarget signal. If the side information has good quality, the number of\nmeasurements is significantly reduced via L1-L1 minimization, but not so much\nvia L1-L2 minimization. We provide geometrical interpretations and experimental\nresults illustrating our findings. \n\n"}
{"id": "1410.2757", "contents": "Title: Linearly-Coupled Fountain Codes Abstract: Network-coded multiple access (NCMA) is a communication scheme for wireless\nmultiple-access networks where physical-layer network coding (PNC) is employed.\nIn NCMA, a user encodes and spreads its message into multiple packets. Time is\nslotted and multiple users transmit packets (one packet each) simultaneously in\neach timeslot. A sink node aims to decode the messages of all the users from\nthe sequence of receptions over successive timeslots. For each timeslot, the\nNCMA receiver recovers multiple linear combinations of the packets transmitted\nin that timeslot, forming a system of linear equations. Different systems of\nlinear equations are recovered in different timeslots. A message decoder then\nrecovers the original messages of all the users by jointly solving multiple\nsystems of linear equations obtained over different timeslots. We propose a\nlow-complexity digital fountain approach for this coding problem, where each\nsource node encodes its message into a sequence of packets using a fountain\ncode. The aforementioned systems of linear equations recovered by the NCMA\nreceiver effectively couple these fountain codes together. We refer to the\ncoupling of the fountain codes as a linearly-coupled (LC) fountain code. The\nordinary belief propagation (BP) decoding algorithm for conventional fountain\ncodes is not optimal for LC fountain codes. We propose a batched BP decoding\nalgorithm and analyze the convergence of the algorithm for general LC fountain\ncodes. We demonstrate how to optimize the degree distributions and show by\nnumerical results that the achievable rate region is nearly optimal. Our\napproach significantly reduces the decoding complexity compared with the\nprevious NCMA schemes based on Reed-Solomon codes and random linear codes, and\nhence has the potential to increase throughput and decrease delay in\ncomputation-limited NCMA systems. \n\n"}
{"id": "1410.3214", "contents": "Title: Secure Erasure Codes With Partial Decodability Abstract: The MDS property (aka the $k$-out-of-$n$ property) requires that if a file is\nsplit into several symbols and subsequently encoded into $n$ coded symbols,\neach being stored in one storage node of a distributed storage system (DSS),\nthen an user can recover the file by accessing any $k$ nodes. We study the\nso-called $p$-decodable $\\mu$-secure erasure coding scheme $(1 \\leq p \\leq k -\n\\mu, 0 \\leq \\mu < k, p | (k-\\mu))$, which satisfies the MDS property and the\nfollowing additional properties:\n  (P1) strongly secure up to a threshold: an adversary which eavesdrops at most\n$\\mu$ storage nodes gains no information (in Shannon's sense) about the stored\nfile,\n  (P2) partially decodable: a legitimate user can recover a subset of $p$ file\nsymbols by accessing some $\\mu + p$ storage nodes.\n  The scheme is perfectly $p$-decodable $\\mu$-secure if it satisfies the\nfollowing additional property:\n  (P3) weakly secure up to a threshold: an adversary which eavesdrops more than\n$\\mu$ but less than $\\mu+p$ storage nodes cannot reconstruct any part of the\nfile.\n  Most of the related work in the literature only focused on the case $p = k -\n\\mu$. In other words, no partial decodability is provided: an user cannot\nretrieve any part of the file by accessing less than $k$ nodes.\n  We provide an explicit construction of $p$-decodable $\\mu$-secure coding\nschemes over small fields for all $\\mu$ and $p$. That construction also\nproduces perfectly $p$-decodable $\\mu$-secure schemes over small fields when $p\n= 1$ (for every $\\mu$), and when $\\mu = 0, 1$ (for every $p$). We establish\nthat perfect schemes exist over \\emph{sufficiently large} fields for almost all\n$\\mu$ and $p$. \n\n"}
{"id": "1410.3340", "contents": "Title: Evidence of spatial embedding in the IPv4 router-level Internet network Abstract: Much interest has been taken in understanding the global routing structure of\nthe Internet, both to model and protect the current structures and to modify\nthe structure to improve resilience. These studies rely on trace-routes and\nalgorithmic inference to resolve individual IP addresses into connected\nrouters, yielding a network of routers. Using WHOIS registries, parsing of DNS\nregistries, as well as simple latency-based triangulation, these routers can\noften be geolocated to at least their country of origin, if not specific\nregions. In this work, we use node subgraph summary statistics to present\nevidence that the router-level (IPv4) network is spatially embedded, with the\nsimilarity (or dissimilarity) of a node from it's neighbor strongly correlating\nwith the attributes of other routers residing in the same country or region. We\ndiscuss these results in context of the recently proposed gravity models of the\nInternet, as well as the potential application to geolocation inferrence. \n\n"}
{"id": "1410.4535", "contents": "Title: Stochastic Nonlinear Model Predictive Control with Efficient Sample\n  Approximation of Chance Constraints Abstract: This paper presents a stochastic model predictive control approach for\nnonlinear systems subject to time-invariant probabilistic uncertainties in\nmodel parameters and initial conditions. The stochastic optimal control problem\nentails a cost function in terms of expected values and higher moments of the\nstates, and chance constraints that ensure probabilistic constraint\nsatisfaction. The generalized polynomial chaos framework is used to propagate\nthe time-invariant stochastic uncertainties through the nonlinear system\ndynamics, and to efficiently sample from the probability densities of the\nstates to approximate the satisfaction probability of the chance constraints.\nTo increase computational efficiency by avoiding excessive sampling, a\nstatistical analysis is proposed to systematically determine a-priori the least\nconservative constraint tightening required at a given sample size to guarantee\na desired feasibility probability of the sample-approximated chance constraint\noptimization problem. In addition, a method is presented for sample-based\napproximation of the analytic gradients of the chance constraints, which\nincreases the optimization efficiency significantly. The proposed stochastic\nnonlinear model predictive control approach is applicable to a broad class of\nnonlinear systems with the sufficient condition that each term is analytic with\nrespect to the states, and separable with respect to the inputs, states and\nparameters. The closed-loop performance of the proposed approach is evaluated\nusing the Williams-Otto reactor with seven states, and ten uncertain parameters\nand initial conditions. The results demonstrate the efficiency of the approach\nfor real-time stochastic model predictive control and its capability to\nsystematically account for probabilistic uncertainties in contrast to a\nnonlinear model predictive control approaches. \n\n"}
{"id": "1410.6569", "contents": "Title: Lattice Index Coding Abstract: The index coding problem involves a sender with K messages to be transmitted\nacross a broadcast channel, and a set of receivers each of which demands a\nsubset of the K messages while having prior knowledge of a different subset as\nside information. We consider the specific case of noisy index coding where the\nbroadcast channel is Gaussian and every receiver demands all the messages from\nthe source. Instances of this communication problem arise in wireless relay\nnetworks, sensor networks, and retransmissions in broadcast channels. We\nconstruct 'lattice index codes' for this channel by encoding the K messages\nindividually using K modulo lattice constellations and transmitting their sum\nmodulo a coarse lattice. We introduce a design metric called 'side information\ngain' that measures the advantage of a code in utilizing the side information\nat the receivers, and hence its goodness as an index code. Based on the Chinese\nremainder theorem, we then construct lattice index codes with large side\ninformation gains using lattices over the following principal ideal domains:\nrational integers, Gaussian integers, Eisenstein integers, and the Hurwitz\nquaternions. Among all lattice index codes constructed using any densest\nlattice of a given dimension, our codes achieve the maximum side information\ngain. Finally, using an example, we illustrate how the proposed lattice index\ncodes can benefit Gaussian broadcast channels with more general message\ndemands. \n\n"}
{"id": "1410.6836", "contents": "Title: Reducing Cascading Failure Risk by Increasing Infrastructure Network\n  Interdependency Abstract: Increased coupling between critical infrastructure networks, such as power\nand communication systems, will have important implications for the reliability\nand security of these systems. To understand the effects of power-communication\ncoupling, several have studied interdependent network models and reported that\nincreased coupling can increase system vulnerability. However, these results\ncome from models that have substantially different mechanisms of cascading,\nrelative to those found in actual power and communication networks. This paper\nreports on two sets of experiments that compare the network vulnerability\nimplications resulting from simple topological models and models that more\naccurately capture the dynamics of cascading in power systems. First, we\ncompare a simple model of topological contagion to a model of cascading in\npower systems and find that the power grid shows a much higher level of\nvulnerability, relative to the contagion model. Second, we compare a model of\ntopological cascades in coupled networks to three different physics-based\nmodels of power grids coupled to communication networks. Again, the more\naccurate models suggest very different conclusions. In all but the most extreme\ncase, the physics-based power grid models indicate that increased\npower-communication coupling decreases vulnerability. This is opposite from\nwhat one would conclude from the coupled topological model, in which zero\ncoupling is optimal. Finally, an extreme case in which communication failures\nimmediately cause grid failures, suggests that if systems are poorly designed,\nincreased coupling can be harmful. Together these results suggest design\nstrategies for reducing the risk of cascades in interdependent infrastructure\nsystems. \n\n"}
{"id": "1410.7357", "contents": "Title: Statistical models for cores decomposition of an undirected random graph Abstract: The $k$-core decomposition is a widely studied summary statistic that\ndescribes a graph's global connectivity structure. In this paper, we move\nbeyond using $k$-core decomposition as a tool to summarize a graph and propose\nusing $k$-core decomposition as a tool to model random graphs. We propose using\nthe shell distribution vector, a way of summarizing the decomposition, as a\nsufficient statistic for a family of exponential random graph models. We study\nthe properties and behavior of the model family, implement a Markov chain Monte\nCarlo algorithm for simulating graphs from the model, implement a direct\nsampler from the set of graphs with a given shell distribution, and explore the\nsampling distributions of some of the commonly used complementary statistics as\ngood candidates for heuristic model fitting. These algorithms provide first\nfundamental steps necessary for solving the following problems: parameter\nestimation in this ERGM, extending the model to its Bayesian relative, and\ndeveloping a rigorous methodology for testing goodness of fit of the model and\nmodel selection. The methods are applied to a synthetic network as well as the\nwell-known Sampson monks dataset. \n\n"}
{"id": "1410.8349", "contents": "Title: Graph Guessing Games and non-Shannon Information Inequalities Abstract: Guessing games for directed graphs were introduced by Riis for studying\nmultiple unicast network coding problems. In a guessing game, the players toss\ngeneralised dice and can see some of the other outcomes depending on the\nstructure of an underlying digraph. They later guess simultaneously the outcome\nof their own die. Their objective is to find a strategy which maximises the\nprobability that they all guess correctly. The performance of the optimal\nstrategy for a graph is measured by the guessing number of the digraph.\n  Christofides and Markstr\\\"om studied guessing numbers of undirected graphs\nand defined a strategy which they conjectured to be optimal. One of the main\nresults of this paper is a disproof of this conjecture.\n  The main tool so far for computing guessing numbers of graphs is information\ntheoretic inequalities. In the paper we show that Shannon's information\ninequalities, which work particularly well for a wide range of graph classes,\nare not sufficient for computing the guessing number.\n  Finally we pose a few more interesting questions some of which we can answer\nand some which we leave as open problems. \n\n"}
{"id": "1411.0724", "contents": "Title: Bounds for complexity of syndrome decoding for poset metrics Abstract: In this work we show how to decompose a linear code relatively to any given\nposet metric. We prove that the complexity of syndrome decoding is determined\nby a maximal (primary) such decomposition and then show that a refinement of a\npartial order leads to a refinement of the primary decomposition. Using this\nand considering already known results about hierarchical posets, we can\nestablish upper and lower bounds for the complexity of syndrome decoding\nrelatively to a poset metric. \n\n"}
{"id": "1411.3140", "contents": "Title: Social media fingerprints of unemployment Abstract: Recent wide-spread adoption of electronic and pervasive technologies has\nenabled the study of human behavior at an unprecedented level, uncovering\nuniversal patterns underlying human activity, mobility, and inter-personal\ncommunication. In the present work, we investigate whether deviations from\nthese universal patterns may reveal information about the socio-economical\nstatus of geographical regions. We quantify the extent to which deviations in\ndiurnal rhythm, mobility patterns, and communication styles across regions\nrelate to their unemployment incidence. For this we examine a country-scale\npublicly articulated social media dataset, where we quantify individual\nbehavioral features from over 145 million geo-located messages distributed\namong more than 340 different Spanish economic regions, inferred by computing\ncommunities of cohesive mobility fluxes. We find that regions exhibiting more\ndiverse mobility fluxes, earlier diurnal rhythms, and more correct grammatical\nstyles display lower unemployment rates. As a result, we provide a simple model\nable to produce accurate, easily interpretable reconstruction of regional\nunemployment incidence from their social-media digital fingerprints alone. Our\nresults show that cost-effective economical indicators can be built based on\npublicly-available social media datasets. \n\n"}
{"id": "1411.4253", "contents": "Title: Energy-efficient Decoders for Compressive Sensing: Fundamental Limits\n  and Implementations Abstract: The fundamental problem considered in this paper is \"What is the\n\\textit{energy} consumed for the implementation of a \\emph{compressive sensing}\ndecoding algorithm on a circuit?\". Using the \"information-friction\" framework,\nwe examine the smallest amount of \\textit{bit-meters} as a measure for the\nenergy consumed by a circuit. We derive a fundamental lower bound for the\nimplementation of compressive sensing decoding algorithms on a circuit. In the\nsetting where the number of measurements scales linearly with the sparsity and\nthe sparsity is sub-linear with the length of the signal, we show that the\n\\textit{bit-meters} consumption for these algorithms is order-tight, i.e., it\nmatches the lower bound asymptotically up to a constant factor. Our\nimplementations yield interesting insights into design of energy-efficient\ncircuits that are not captured by the notion of computational efficiency alone. \n\n"}
{"id": "1411.4590", "contents": "Title: Reed-Muller codes for random erasures and errors Abstract: This paper studies the parameters for which Reed-Muller (RM) codes over\n$GF(2)$ can correct random erasures and random errors with high probability,\nand in particular when can they achieve capacity for these two classical\nchannels. Necessarily, the paper also studies properties of evaluations of\nmulti-variate $GF(2)$ polynomials on random sets of inputs.\n  For erasures, we prove that RM codes achieve capacity both for very high rate\nand very low rate regimes. For errors, we prove that RM codes achieve capacity\nfor very low rate regimes, and for very high rates, we show that they can\nuniquely decode at about square root of the number of errors at capacity.\n  The proofs of these four results are based on different techniques, which we\nfind interesting in their own right. In particular, we study the following\nquestions about $E(m,r)$, the matrix whose rows are truth tables of all\nmonomials of degree $\\leq r$ in $m$ variables. What is the most (resp. least)\nnumber of random columns in $E(m,r)$ that define a submatrix having full column\nrank (resp. full row rank) with high probability? We obtain tight bounds for\nvery small (resp. very large) degrees $r$, which we use to show that RM codes\nachieve capacity for erasures in these regimes.\n  Our decoding from random errors follows from the following novel reduction.\nFor every linear code $C$ of sufficiently high rate we construct a new code\n$C'$, also of very high rate, such that for every subset $S$ of coordinates, if\n$C$ can recover from erasures in $S$, then $C'$ can recover from errors in $S$.\nSpecializing this to RM codes and using our results for erasures imply our\nresult on unique decoding of RM codes at high rate.\n  Finally, two of our capacity achieving results require tight bounds on the\nweight distribution of RM codes. We obtain such bounds extending the recent\n\\cite{KLP} bounds from constant degree to linear degree polynomials. \n\n"}
{"id": "1411.4942", "contents": "Title: Path Sampling: A Fast and Provable Method for Estimating 4-Vertex\n  Subgraph Counts Abstract: Counting the frequency of small subgraphs is a fundamental technique in\nnetwork analysis across various domains, most notably in bioinformatics and\nsocial networks. The special case of triangle counting has received much\nattention. Getting results for 4-vertex patterns is highly challenging, and\nthere are few practical results known that can scale to massive sizes. Indeed,\neven a highly tuned enumeration code takes more than a day on a graph with\nmillions of edges. Most previous work that runs for truly massive graphs employ\nclusters and massive parallelization.\n  We provide a sampling algorithm that provably and accurately approximates the\nfrequencies of all 4-vertex pattern subgraphs. Our algorithm is based on a\nnovel technique of 3-path sampling and a special pruning scheme to decrease the\nvariance in estimates. We provide theoretical proofs for the accuracy of our\nalgorithm, and give formal bounds for the error and confidence of our\nestimates. We perform a detailed empirical study and show that our algorithm\nprovides estimates within 1% relative error for all subpatterns (over a large\nclass of test graphs), while being orders of magnitude faster than enumeration\nand other sampling based algorithms. Our algorithm takes less than a minute (on\na single commodity machine) to process an Orkut social network with 300 million\nedges. \n\n"}
{"id": "1411.6057", "contents": "Title: Mesoscopic analysis of online social networks - The role of negative\n  ties Abstract: A class of networks are those with both positive and negative links. In this\nmanuscript, we studied the interplay between positive and negative ties on\nmesoscopic level of these networks, i.e., their community structure. A\ncommunity is considered as a tightly interconnected group of actors; therefore,\nit does not borrow any assumption from balance theory and merely uses the\nwell-known assumption in the community detection literature. We found that if\none detects the communities based on only positive relations (by ignoring the\nnegative ones), the majority of negative relations are already placed between\nthe communities. In other words, negative ties do not have a major role in\ndetecting communities of studied signed networks. Moreover, regarding the\ninternal negative ties, we proved that most unbalanced communities are\nmaximally balanced, and hence they cannot be partitioned into k nonempty\nsub-clusters with higher balancedness (k >= 2). Furthermore, we showed that\nalthough the mediator triad ++- (hostile-mediator-hostile) is underrepresented,\nit constitutes a considerable portion of triadic relations among communities.\nHence, mediator triads should not be ignored by community detection and\nclustering algorithms. As a result, if one uses a clustering algorithm that\noperates merely based on social balance, mesoscopic structure of signed\nnetworks significantly remains hidden. \n\n"}
{"id": "1411.6871", "contents": "Title: Tail-scope: Using friends to estimate heavy tails of degree\n  distributions in large-scale complex networks Abstract: Many complex networks in natural and social phenomena have often been\ncharacterized by heavy-tailed degree distributions. However, due to rapidly\ngrowing size of network data and concerns on privacy issues about using these\ndata, it becomes more difficult to analyze complete data sets. Thus, it is\ncrucial to devise effective and efficient estimation methods for heavy tails of\ndegree distributions in large-scale networks only using local information of a\nsmall fraction of sampled nodes. Here we propose a tail-scope method based on\nlocal observational bias of the friendship paradox. We show that the tail-scope\nmethod outperforms the uniform node sampling for estimating heavy tails of\ndegree distributions, while the opposite tendency is observed in the range of\nsmall degrees. In order to take advantages of both sampling methods, we devise\nthe hybrid method that successfully recovers the whole range of degree\ndistributions. Our tail-scope method shows how structural heterogeneities of\nlarge-scale complex networks can be used to effectively reveal the network\nstructure only with limited local information. \n\n"}
{"id": "1411.7086", "contents": "Title: Discrete Sampling: A graph theoretic approach to Orthogonal\n  Interpolation Abstract: We study the problem of finding unitary submatrices of the $N \\times N$\ndiscrete Fourier transform matrix, in the context of interpolating a discrete\nbandlimited signal using an orthogonal basis. This problem is related to a\ndiverse set of questions on idempotents on $\\mathbb{Z}_N$ and tiling\n$\\mathbb{Z}_N$. In this work, we establish a graph-theoretic approach and\nconnections to the problem of finding maximum cliques. We identify the key\nproperties of these graphs that make the interpolation problem tractable when\n$N$ is a prime power, and we identify the challenges in generalizing to\narbitrary $N$. Finally, we investigate some connections between graph\nproperties and the spectral-tile direction of the Fuglede conjecture. \n\n"}
{"id": "1411.7121", "contents": "Title: Two-Stage Beamformer Design for Massive MIMO Downlink By Trace Quotient\n  Formulation Abstract: In this paper, the problem of outer beamformer design based only on channel\nstatistic information is considered for two-stage beamforming for multi-user\nmassive MIMO downlink, and the problem is approached based on\nsignal-to-leakage-plus-noise ratio (SLNR). To eliminate the dependence on the\ninstantaneous channel state information, a lower bound on the average SLNR is\nderived by assuming zero-forcing (ZF) inner beamforming, and an outer\nbeamformer design method that maximizes the lower bound on the average SLNR is\nproposed. It is shown that the proposed SLNR-based outer beamformer design\nproblem reduces to a trace quotient problem (TQP), which is often encountered\nin the field of machine learning. An iterative algorithm is presented to obtain\nan optimal solution to the proposed TQP. The proposed method has the capability\nof optimally controlling the weighting factor between the signal power to the\ndesired user and the interference leakage power to undesired users according to\ndifferent channel statistics. Numerical results show that the proposed outer\nbeamformer design method yields significant performance gain over existing\nmethods. \n\n"}
{"id": "1411.7231", "contents": "Title: Risk-Sensitive Mean-Field Type Control under Partial Observation Abstract: We establish a stochastic maximum principle (SMP) for control problems of\npartially observed diffusions of mean-field type with risk-sensitive\nperformance functionals. \n\n"}
{"id": "1412.1565", "contents": "Title: Recovery Analysis for Weighted $\\ell_1$-Minimization Using a Null Space\n  Property Abstract: We study the recovery of sparse signals from underdetermined linear\nmeasurements when a potentially erroneous support estimate is available. Our\nresults are twofold. First, we derive necessary and sufficient conditions for\nsignal recovery from compressively sampled measurements using weighted\n$\\ell_1$-norm minimization. These conditions, which depend on the choice of\nweights as well as the size and accuracy of the support estimate, are on the\nnull space of the measurement matrix. They can guarantee recovery even when\nstandard $\\ell_1$ minimization fails. Second, we derive bounds on the number of\nGaussian measurements for these conditions to be satisfied, i.e., for weighted\n$\\ell_1$ minimization to successfully recover all sparse signals whose support\nhas been estimated sufficiently accurately. Our bounds show that weighted\n$\\ell_1$ minimization requires significantly fewer measurements than standard\n$\\ell_1$ minimization when the support estimate is relatively accurate. \n\n"}
{"id": "1412.1695", "contents": "Title: Convolutional codes from unit schemes Abstract: Convolutional codes are constructed, designed and analysed using row and/or\nblock structures of unit algebraic schemes. Infinite series of such codes and\nof codes with specific properties are derived. Properties are shown\nalgebraically and algebraic decoding methods are derived. For a given rate and\ngiven error-correction capability at each component, convolutional codes with\nthese specifications and with efficient decoding algorithms are constructed.\nExplicit prototype examples are given but in general large lengths and large\nerror capability are achievable. Convolutional codes with efficient decoding\nalgorithms at or near the maximum free distances attainable for the parameters\nare constructible. Unit memory convolutional codes of maximum possible free\ndistance are designed with practical algebraic decoding algorithms.\n  LDPC (low density parity check) convolutional codes with efficient decoding\nschemes are constructed and analysed by the methods. Self-dual and\ndual-containing convolutional codes may also be designed by the methods;\ndual-containing codes enables the construction of quantum codes. \n\n"}
{"id": "1412.3124", "contents": "Title: Percolation of localized attack on complex networks Abstract: The robustness of complex networks against node failure and malicious attack\nhas been of interest for decades, while most of the research has focused on\nrandom attack or hub-targeted attack. In many real-world scenarios, however,\nattacks are neither random nor hub-targeted, but localized, where a group of\nneighboring nodes in a network are attacked and fail. In this paper we develop\na percolation framework to analytically and numerically study the robustness of\ncomplex networks against such localized attack. In particular, we investigate\nthis robustness in Erd\\H{o}s-R\\'{e}nyi networks, random-regular networks, and\nscale-free networks. Our results provide insight into how to better protect\nnetworks, enhance cybersecurity, and facilitate the design of more robust\ninfrastructures. \n\n"}
{"id": "1412.3731", "contents": "Title: High-Dimensional Change-Point Estimation: Combining Filtering with\n  Convex Optimization Abstract: We consider change-point estimation in a sequence of high-dimensional signals\ngiven noisy observations. Classical approaches to this problem such as the\nfiltered derivative method are useful for sequences of scalar-valued signals,\nbut they have undesirable scaling behavior in the high-dimensional setting.\nHowever, many high-dimensional signals encountered in practice frequently\npossess latent low-dimensional structure. Motivated by this observation, we\npropose a technique for high-dimensional change-point estimation that combines\nthe filtered derivative approach from previous work with convex optimization\nmethods based on atomic norm regularization, which are useful for exploiting\nstructure in high-dimensional data. Our algorithm is applicable in online\nsettings as it operates on small portions of the sequence of observations at a\ntime, and it is well-suited to the high-dimensional setting both in terms of\ncomputational scalability and of statistical efficiency. The main result of\nthis paper shows that our method performs change-point estimation reliably as\nlong as the product of the smallest-sized change (the Euclidean-norm-squared of\nthe difference between signals at a change-point) and the smallest distance\nbetween change-points (number of time instances) is larger than a Gaussian\nwidth parameter that characterizes the low-dimensional complexity of the\nunderlying signal sequence. \n\n"}
{"id": "1412.4813", "contents": "Title: Opportunistic Relaying without CSI: Optimizing Variable-Rate HARQ Abstract: We analyze the opportunistic relaying based on HARQ transmission over the\nblock-fading channel with absence of channel state information (CSI) at the\ntransmitter nodes. We assume that both the source and the relay are allowed to\nvary their transmission rate between the HARQ transmission rounds. We solve the\nproblem of throughput maximization with respect to the transmission rates using\ndouble-recursive Dynamic Programming. Simplifications are also proposed to\ndiminish the complexity of the optimization. The numerical results confirm that\nthe variable-rate HARQ can increase the throughput significantly comparing to\nits fixed-rate counterpart. \n\n"}
{"id": "1412.5731", "contents": "Title: Optimizing User Association and Spectrum Allocation in HetNets: A\n  Utility Perspective Abstract: The joint user association and spectrum allocation problem is studied for\nmulti-tier heterogeneous networks (HetNets) in both downlink and uplink in the\ninterference-limited regime. Users are associated with base-stations (BSs)\nbased on the biased downlink received power. Spectrum is either shared or\northogonally partitioned among the tiers. This paper models the placement of\nBSs in different tiers as spatial point processes and adopts stochastic\ngeometry to derive the theoretical mean proportionally fair utility of the\nnetwork based on the coverage rate. By formulating and solving the network\nutility maximization problem, the optimal user association bias factors and\nspectrum partition ratios are analytically obtained for the multi-tier network.\nThe resulting analysis reveals that the downlink and uplink user associations\ndo not have to be symmetric. For uplink under spectrum sharing, if all tiers\nhave the same target signal-to-interference ratio (SIR), distance-based user\nassociation is shown to be optimal under a variety of path loss and power\ncontrol settings. For both downlink and uplink, under orthogonal spectrum\npartition, it is shown that the optimal proportion of spectrum allocated to\neach tier should match the proportion of users associated with that tier.\nSimulations validate the analytical results. Under typical system parameters,\nsimulation results suggest that spectrum partition performs better for downlink\nin terms of utility, while spectrum sharing performs better for uplink with\npower control. \n\n"}
{"id": "1412.7367", "contents": "Title: A framework for evaluating complex networks measurements Abstract: A good deal of current research in complex networks involves the\ncharacterization and/or classification of the topological properties of given\nstructures, which has motivated several respective measurements. This letter\nproposes a framework for evaluating the quality of complex network measurements\nin terms of their effective resolution, degree of degeneracy and\ndiscriminability. The potential of the suggested approach is illustrated with\nrespect to comparing the characterization of several model and real-world\nnetworks by using concentric and symmetry measurements. The results indicate a\nmarkedly superior performance for the latter type of mapping. \n\n"}
{"id": "1412.8388", "contents": "Title: Estimating inter-event time distributions from finite observation\n  periods in communication networks Abstract: A diverse variety of processes --- including recurrent disease episodes,\nneuron firing, and communication patterns among humans --- can be described\nusing inter-event time (IET) distributions. Many such processes are ongoing,\nalthough event sequences are only available during a finite observation window.\nBecause the observation time window is more likely to begin or end during long\nIETs than during short ones, the analysis of such data is susceptible to a bias\ninduced by the finite observation period. In this paper, we illustrate how this\nlength bias is born and how it can be corrected without assuming any particular\nshape for the IET distribution. To do this, we model event sequences using\nstationary renewal processes, and we formulate simple heuristics for\ndetermining the severity of the bias. To illustrate our results, we focus on\nthe example of empirical communication networks, which are temporal networks\nthat are constructed from communication events. The IET distributions of such\nsystems guide efforts to build models of human behavior, and the variance of\nIETs is very important for estimating the spreading rate of information in\nnetworks of temporal interactions. We analyze several well-known data sets from\nthe literature, and we find that the resulting bias can lead to systematic\nunderestimates of the variance in the IET distributions and that correcting for\nthe bias can lead to qualitatively different results for the tails of the IET\ndistributions. \n\n"}
{"id": "1501.01676", "contents": "Title: Clustering attributed graphs: models, measures and methods Abstract: Clustering a graph, i.e., assigning its nodes to groups, is an important\noperation whose best known application is the discovery of communities in\nsocial networks. Graph clustering and community detection have traditionally\nfocused on graphs without attributes, with the notable exception of edge\nweights. However, these models only provide a partial representation of real\nsocial systems, that are thus often described using node attributes,\nrepresenting features of the actors, and edge attributes, representing\ndifferent kinds of relationships among them. We refer to these models as\nattributed graphs. Consequently, existing graph clustering methods have been\nrecently extended to deal with node and edge attributes. This article is a\nliterature survey on this topic, organizing and presenting recent research\nresults in a uniform way, characterizing the main existing clustering methods\nand highlighting their conceptual differences. We also cover the important\ntopic of clustering evaluation and identify current open problems. \n\n"}
{"id": "1501.01742", "contents": "Title: LDPC Coded Modulation with Probabilistic Shaping for Optical Fiber\n  Systems Abstract: An LDPC coded modulation scheme with probabilistic shaping, optimized\ninterleavers and noniterative demapping is proposed. Full-field simulations\nshow an increase in transmission distance by 8% compared to uniformly\ndistributed input. \n\n"}
{"id": "1501.01829", "contents": "Title: Performance Analysis and Optimal Filter Design for Sigma-Delta\n  Modulation via Duality with DPCM Abstract: Sampling above the Nyquist rate is at the heart of sigma-delta modulation,\nwhere the increase in sampling rate is translated to a reduction in the overall\n(mean-squared-error) reconstruction distortion. This is attained by using a\nfeedback filter at the encoder, in conjunction with a low-pass filter at the\ndecoder. The goal of this work is to characterize the optimal trade-off between\nthe per-sample quantization rate and the resulting mean-squared-error\ndistortion, under various restrictions on the feedback filter. To this end, we\nestablish a duality relation between the performance of sigma-delta modulation,\nand that of differential pulse-code modulation when applied to (discrete-time)\nband-limited inputs. As the optimal trade-off for the latter scheme is fully\nunderstood, the full characterization for sigma-delta modulation, as well as\nthe optimal feedback filters, immediately follow. \n\n"}
{"id": "1501.04527", "contents": "Title: Social Networking by Proxy: A Case Study of Catster, Dogster and\n  Hamsterster Abstract: The proliferation of online social networks in the last decade has not\nstopped short of pets, and many different online platforms now exist catering\nto owners of various pets such as cats and dogs. These online pet social\nnetworks provide a unique opportunity to study an online social network in\nwhich a single user manages multiple user profiles, i.e. one for each pet they\nown. These types of multi-profile networks allow us to investigate two\nquestions: (1) What is the relationship between the pet-level and human-level\nnetwork, and (2) what is the relationship between friendship links and family\nties? Concretely, we study the online social pet networks Catster, Dogster and\nHamsterster, the first two of which are the two largest online pet networks in\nexistence. We show how the networks on the two levels interact, and perform\nexperiments to find out whether knowledge about friendships on a profile-level\nalone can be used to predict which users are behind which profile. In order to\ndo so, we introduce the concept of multi-profile social network, extend a\npreviously defined spectral test of diagonality to multi-profile networks,\ndefine two new homophily measures for multi-profile social networks, perform a\ntwo-level social network analysis, and present an algorithm for predicting\nwhether two profiles were created by the same user. As a result, we are able to\npredict with very high precision whether two profiles were created by a same\nuser. Our work is thus relevant for the analysis of other online communities in\nwhich users may use multiple profiles. \n\n"}
{"id": "1501.04764", "contents": "Title: Optimized Uplink Transmission in Multi-Antenna C-RAN with Spatial\n  Compression and Forward Abstract: Massive MIMO and C-RAN are two promising techniques for implementing future\nwireless communication systems, where a large number of antennas are deployed\neither being co-located at the base station (BS) or totally distributed at\nseparate sites called remote radio heads (RRHs). In this paper, we consider a\ngeneral antenna deployment design for wireless networks, termed multi-antenna\nC-RAN, where a flexible number of antennas can be equipped at each RRH to more\neffectively balance the performance and fronthaul complexity trade-off beyond\nthe conventional massive MIMO and single-antenna C-RAN. Under the uplink\ncommunication setup, we propose a new \"spatial-compression-and-forward (SCF)\"\nscheme, where each RRH first performs a linear spatial filtering to denoise and\nmaximally compress its received signals from multiple users to a reduced number\nof dimensions, then conducts uniform scalar quantization over each of the\nresulting dimensions in parallel, and finally sends the total quantized bits to\nthe baseband unit (BBU) via a finite-rate fronthaul link for joint information\ndecoding. Under this scheme, we maximize the minimum\nsignal-to-interference-plus-noise ratio (SINR) of all users at the BBU by a\njoint resource allocation over the wireless transmission and fronthaul links.\nSpecifically, each RRH determines its own spatial filtering solution in a\ndistributed manner to reduce the signalling overhead with the BBU, while the\nBBU jointly optimizes the users' transmit power, the RRHs' fronthaul bits\nallocation, and the BBU's receive beamforming with fixed spatial filters at\nindividual RRHs. Through numerical results, it is shown that given a total\nnumber of antennas to be deployed, multi-antenna C-RAN with the proposed SCF\nand joint optimization significantly outperforms both massive MIMO and\nsingle-antenna C-RAN under practical fronthaul capacity constraints. \n\n"}
{"id": "1501.05198", "contents": "Title: Memory and burstiness in dynamic networks Abstract: A discrete-time random process is described which can generate bursty\nsequences of events. A Bernoulli process, where the probability of an event\noccurring at time $t$ is given by a fixed probability $x$, is modified to\ninclude a memory effect where the event probability is increased proportionally\nto the number of events which occurred within a given amount of time preceding\n$t$. For small values of $x$ the inter-event time distribution follows a\npower-law with exponent $-2-x$. We consider a dynamic network where each node\nforms, and breaks connections according to this process. The value of $x$ for\neach node depends on the fitness distribution, $\\rho(x)$, from which it is\ndrawn; we find exact solutions for the expectation of the degree distribution\nfor a variety of possible fitness distributions, and for both cases where the\nmemory effect either is, or is not present. This work can potentially lead to\nmethods to uncover hidden fitness distributions from fast changing, temporal\nnetwork data such as online social communications and fMRI scans. \n\n"}
{"id": "1501.05994", "contents": "Title: On MMSE Properties of Codes for the Gaussian Broadcast and Wiretap\n  Channels Abstract: This work concerns the behavior of \"good\" (capacity achieving) codes in\nseveral multi-user settings in the Gaussian regime, in terms of their minimum\nmean-square error (MMSE) behavior. The settings investigated in this context\ninclude the Gaussian wiretap channel, the Gaussian broadcast channel (BC) and\nthe Gaussian BC with confidential messages (BCC). In particular this work\naddresses the effects of transmitting such codes on unintended receivers, that\nis, receivers that neither require reliable decoding of the transmitted\nmessages nor are they eavesdroppers that must be kept ignorant, to some extent,\nof the transmitted message. This work also examines the effect on the capacity\nregion that occurs when we limit the allowed disturbance in terms of MMSE on\nsome unintended receiver. This trade-off between the capacity region and the\ndisturbance constraint is given explicitly for the Gaussian BC and the secrecy\ncapacity region of the Gaussian BCC. \n\n"}
{"id": "1501.07417", "contents": "Title: An improved rate region for the classical-quantum broadcast channel Abstract: We present a new achievable rate region for the two-user binary-input\nclassical-quantum broadcast channel. The result is a generalization of the\nclassical Marton-Gelfand-Pinsker region and is provably larger than the best\npreviously known rate region for classical-quantum broadcast channels. The\nproof of achievability is based on the recently introduced polar coding scheme\nand its generalization to quantum network information theory. \n\n"}
{"id": "1502.00033", "contents": "Title: Analyzing Interference from Static Cellular Cooperation using the\n  Nearest Neighbour Model Abstract: The problem of base station cooperation has recently been set within the\nframework of Stochastic Geometry. Existing works consider that a user\ndynamically chooses the set of stations that cooperate for his/her service.\nHowever, this assumption often does not hold. Cooperation groups could be\npredefined and static, with nodes connected by fixed infrastructure. To analyse\nsuch a potential network, in this work we propose a grouping method based on\nproximity. It is a variation of the so called Nearest Neighbour Model. We\nrestrict ourselves to the simplest case where only singles and pairs of base\nstations are allowed to be formed. For this, two new point processes are\ndefined from the dependent thinning of a Poisson Point Process, one for the\nsingles and one for the pairs. Structural characteristics for the two are\nprovided, including their density, Voronoi surface, nearest neighbour, empty\nspace and J-function. We further make use of these results to analyse their\ninterference fields and give explicit formulas to their expected value and\ntheir Laplace transform. The results constitute a novel toolbox towards the\nperformance evaluation of networks with static cooperation. \n\n"}
{"id": "1502.00079", "contents": "Title: EXIT Chart Analysis of Block Markov Superposition Transmission of Short\n  Codes Abstract: In this paper, a modified extrinsic information transfer (EXIT) chart\nanalysis that takes into account the relation between mutual information (MI)\nand bit-error-rate (BER) is presented to study the convergence behavior of\nblock Markov superposition transmission (BMST) of short codes (referred to as\nbasic codes). We show that the threshold curve of BMST codes using an iterative\nsliding window decoding algorithm with a fixed decoding delay achieves a lower\nbound in the high signal-to-noise ratio (SNR) region, while in the low SNR\nregion, due to error propagation, the thresholds of BMST codes become slightly\nworse as the encoding memory increases. We also demonstrate that the threshold\nresults are consistent with finite-length performance simulations. \n\n"}
{"id": "1502.00166", "contents": "Title: Modelling of trends in Twitter using retweet graph dynamics Abstract: In this paper we model user behaviour in Twitter to capture the emergence of\ntrending topics. For this purpose, we first extensively analyse tweet datasets\nof several different events. In particular, for these datasets, we construct\nand investigate the retweet graphs. We find that the retweet graph for a\ntrending topic has a relatively dense largest connected component (LCC). Next,\nbased on the insights obtained from the analyses of the datasets, we design a\nmathematical model that describes the evolution of a retweet graph by three\nmain parameters. We then quantify, analytically and by simulation, the\ninfluence of the model parameters on the basic characteristics of the retweet\ngraph, such as the density of edges and the size and density of the LCC.\nFinally, we put the model in practice, estimate its parameters and compare the\nresulting behavior of the model to our datasets. \n\n"}
{"id": "1502.01414", "contents": "Title: Cyclic LRC Codes and their Subfield Subcodes Abstract: We consider linear cyclic codes with the locality property, or locally\nrecoverable codes (LRC codes). A family of LRC codes that generalizes the\nclassical construction of Reed-Solomon codes was constructed in a recent paper\nby I. Tamo and A. Barg (IEEE Transactions on Information Theory, no. 8, 2014;\narXiv:1311.3284). In this paper we focus on the optimal cyclic codes that arise\nfrom the general construction. We give a characterization of these codes in\nterms of their zeros, and observe that there are many equivalent ways of\nconstructing optimal cyclic LRC codes over a given field. We also study\nsubfield subcodes of cyclic LRC codes (BCH-like LRC codes) and establish\nseveral results about their locality and minimum distance. \n\n"}
{"id": "1502.01885", "contents": "Title: Linearized Reed-Solomon codes and linearized Wenger graphs Abstract: A codeword is associated to a linearized polynomial. The weight distribution\nof the codewords is determined as the linearized polynomial varies in a family\nof fixed degree. There is a corresponding result on Wenger graphs from\nlinearized polynomials. \n\n"}
{"id": "1502.02436", "contents": "Title: Exact solutions to Super Resolution on semi-algebraic domains in higher\n  dimensions Abstract: We investigate the multi-dimensional Super Resolution problem on closed\nsemi-algebraic domains for various sampling schemes such as Fourier or moments.\nWe present a new semidefinite programming (SDP) formulation of the 1\n-minimization in the space of Radon measures in the multi-dimensional frame on\nsemi-algebraic sets. While standard approaches have focused on SDP relaxations\nof the dual program (a popular approach is based on Gram matrix\nrepresentations), this paper introduces an exact formulation of the primal 1\n-minimization exact recovery problem of Super Resolution that unleashes\nstandard techniques (such as moment-sum-of-squares hier-archies) to overcome\nintrinsic limitations of previous works in the literature. Notably, we show\nthat one can exactly solve the Super Resolution problem in dimension greater\nthan 2 and for a large family of domains described by semi-algebraic sets. \n\n"}
{"id": "1502.03124", "contents": "Title: Order-Optimal Rate of Caching and Coded Multicasting with Random Demands Abstract: We consider the canonical {\\em shared link network} formed by a source node,\nhosting a library of $m$ information messages (files), connected via a\nnoiseless common link to $n$ destination nodes (users), each with a cache of\nsize M files. Users request files at random and independently, according to a\ngiven a-priori demand distribution $\\qv$. A coding scheme for this network\nconsists of a caching placement (i.e., a mapping of the library files into the\nuser caches) and delivery scheme (i.e., a mapping for the library files and\nuser demands into a common multicast codeword) such that, after the codeword\ntransmission, all users can retrieve their requested file. The rate of the\nscheme is defined as the {\\em average} codeword length normalized with respect\nto the length of one file, where expectation is taken over the random user\ndemands. For the same shared link network, in the case of deterministic\ndemands, the optimal min-max rate has been characterized within a uniform\nbound, independent of the network parameters. In particular, fractional caching\n(i.e., storing file segments) and using linear network coding has been shown to\nprovide a min-max rate reduction proportional to 1/M with respect to standard\nschemes such as unicasting or \"naive\" uncoded multicasting. The case of random\ndemands was previously considered by applying the same order-optimal min-max\nscheme separately within groups of files requested with similar probability.\nHowever, no order-optimal guarantee was provided for random demands under the\naverage rate performance criterion. In this paper, we consider the random\ndemand setting and provide general achievability and converse results. In\nparticular, we consider a family of schemes that combine random fractional\ncaching according to a probability distribution $\\pv$ that depends on the\ndemand distribution $\\qv$, with a linear coded delivery scheme based on ... \n\n"}
{"id": "1502.03496", "contents": "Title: Spectral Sparsification of Random-Walk Matrix Polynomials Abstract: We consider a fundamental algorithmic question in spectral graph theory:\nCompute a spectral sparsifier of random-walk matrix-polynomial\n$$L_\\alpha(G)=D-\\sum_{r=1}^d\\alpha_rD(D^{-1}A)^r$$ where $A$ is the adjacency\nmatrix of a weighted, undirected graph, $D$ is the diagonal matrix of weighted\ndegrees, and $\\alpha=(\\alpha_1...\\alpha_d)$ are nonnegative coefficients with\n$\\sum_{r=1}^d\\alpha_r=1$. Recall that $D^{-1}A$ is the transition matrix of\nrandom walks on the graph. The sparsification of $L_\\alpha(G)$ appears to be\nalgorithmically challenging as the matrix power $(D^{-1}A)^r$ is defined by all\npaths of length $r$, whose precise calculation would be prohibitively\nexpensive.\n  In this paper, we develop the first nearly linear time algorithm for this\nsparsification problem: For any $G$ with $n$ vertices and $m$ edges, $d$\ncoefficients $\\alpha$, and $\\epsilon > 0$, our algorithm runs in time\n$O(d^2m\\log^2n/\\epsilon^{2})$ to construct a Laplacian matrix\n$\\tilde{L}=D-\\tilde{A}$ with $O(n\\log n/\\epsilon^{2})$ non-zeros such that\n$\\tilde{L}\\approx_{\\epsilon}L_\\alpha(G)$.\n  Matrix polynomials arise in mathematical analysis of matrix functions as well\nas numerical solutions of matrix equations. Our work is particularly motivated\nby the algorithmic problems for speeding up the classic Newton's method in\napplications such as computing the inverse square-root of the precision matrix\nof a Gaussian random field, as well as computing the $q$th-root transition (for\n$q\\geq1$) in a time-reversible Markov model. The key algorithmic step for both\napplications is the construction of a spectral sparsifier of a constant degree\nrandom-walk matrix-polynomials introduced by Newton's method. Our algorithm can\nalso be used to build efficient data structures for effective resistances for\nmulti-step time-reversible Markov models, and we anticipate that it could be\nuseful for other tasks in network analysis. \n\n"}
{"id": "1502.05267", "contents": "Title: Quantum MDS Codes over Small Fields Abstract: We consider quantum MDS (QMDS) codes for quantum systems of dimension $q$\nwith lengths up to $q^2+2$ and minimum distances up to $q+1$. We show how\nstarting from QMDS codes of length $q^2+1$ based on cyclic and constacyclic\ncodes, new QMDS codes can be obtained by shortening. We provide numerical\nevidence for our conjecture that almost all admissible lengths, from a lower\nbound $n_0(q,d)$ on, are achievable by shortening. Some additional codes that\nfill gaps in the list of achievable lengths are presented as well along with a\nconstruction of a family of QMDS codes of length $q^2+2$, where $q=2^m$, that\nappears to be new. \n\n"}
{"id": "1502.06149", "contents": "Title: Efficient Algorithms for the Data Exchange Problem Abstract: In this paper we study the data exchange problem where a set of users is\ninterested in gaining access to a common file, but where each has only partial\nknowledge about it as side-information. Assuming that the file is broken into\npackets, the side-information considered is in the form of linear combinations\nof the file packets. Given that the collective information of all the users is\nsufficient to allow recovery of the entire file, the goal is for each user to\ngain access to the file while minimizing some communication cost. We assume\nthat users can communicate over a noiseless broadcast channel, and that the\ncommunication cost is a sum of each user's cost function over the number of\nbits it transmits. For instance, the communication cost could simply be the\ntotal number of bits that needs to be transmitted. In the most general case\nstudied in this paper, each user can have any arbitrary convex cost function.\nWe provide deterministic, polynomial-time algorithms (in the number of users\nand packets) which find an optimal communication scheme that minimizes the\ncommunication cost. To further lower the complexity, we also propose a simple\nrandomized algorithm inspired by our deterministic algorithm which is based on\na random linear network coding scheme. \n\n"}
{"id": "1502.06222", "contents": "Title: Tropical optimization problems in time-constrained project scheduling Abstract: We consider a project that consists of activities to be performed in parallel\nunder various temporal constraints, which include start-start, start-finish and\nfinish-start precedence relationships, release times, deadlines, and due dates.\nScheduling problems are formulated to find optimal schedules for the project\nwith respect to different objective functions to be minimized, such as the\nproject makespan, the maximum deviation from the due dates, the maximum\nflow-time, and the maximum deviation of finish times. We represent these\nproblems as optimization problems in terms of tropical mathematics, and then\nsolve them by applying direct solution methods of tropical optimization. As a\nresult, new direct solutions of the scheduling problems are obtained in a\ncompact vector form, which is ready for further analysis and practical\nimplementation. The solutions are illustrated by simple numerical examples. \n\n"}
{"id": "1502.06321", "contents": "Title: A Linear Network Code Construction for General Integer Connections Based\n  on the Constraint Satisfaction Problem Abstract: The problem of finding network codes for general connections is inherently\ndifficult in capacity constrained networks. Resource minimization for general\nconnections with network coding is further complicated. Existing methods for\nidentifying solutions mainly rely on highly restricted classes of network\ncodes, and are almost all centralized. In this paper, we introduce linear\nnetwork mixing coefficients for code constructions of general connections that\ngeneralize random linear network coding (RLNC) for multicast connections. For\nsuch code constructions, we pose the problem of cost minimization for the\nsubgraph involved in the coding solution and relate this minimization to a\npath-based Constraint Satisfaction Problem (CSP) and an edge-based CSP. While\nCSPs are NP-complete in general, we present a path-based probabilistic\ndistributed algorithm and an edge-based probabilistic distributed algorithm\nwith almost sure convergence in finite time by applying Communication Free\nLearning (CFL). Our approach allows fairly general coding across flows,\nguarantees no greater cost than routing, and shows a possible distributed\nimplementation. Numerical results illustrate the performance improvement of our\napproach over existing methods. \n\n"}
{"id": "1503.03165", "contents": "Title: Iterative Merging Algorithm for Cooperative Data Exchange Abstract: We consider the problem of finding the minimum sum-rate strategy in\ncooperative data exchange systems that do not allow packet-splitting (NPS-CDE).\nIn an NPS-CDE system, there are a number of geographically close cooperative\nclients who send packets to help the others recover a packet set. A minimum\nsum-rate strategy is the strategy that achieves universal recovery (the\nsituation when all the clients recover the whole packet set) with the the\nminimal sum-rate (the total number of transmissions). We propose an iterative\nmerging (IM) algorithm that recursively merges client sets based on a lower\nestimate of the minimum sum-rate and updates to the value of the minimum\nsum-rate. We also show that a minimum sum-rate strategy can be learned by\nallocating rates for the local recovery in each merged client set in the IM\nalgorithm. We run an experiment to show that the complexity of the IM algorithm\nis lower than that of the existing deterministic algorithm when the number of\nclients is lower than $94$. \n\n"}
{"id": "1503.04003", "contents": "Title: Using tropical optimization techniques to evaluate alternatives via\n  pairwise comparisons Abstract: We describe a new approach based on tropical optimization techniques to solve\nthe problem of rating alternatives from pairwise comparison data. The problem\nis formulated to approximate, in the log-Chebyshev sense, pairwise comparison\nmatrices by reciprocal matrices of unit rank, and then represented in general\nterms of tropical mathematics as a tropical optimization problem. The\noptimization problem takes a common, unified form for both multiplicative and\nadditive comparison scales. We apply recent results in tropical optimization to\noffer new complete solutions to the rating problems under various assumptions\nabout the pairwise comparison matrices. The solutions are given in a compact\nvector form, which extends known solutions and involves modest computational\nefforts. The results obtained are illustrated with numerical examples.\nSpecifically, we show by example that the partial solution known before may\nmiss better results provided by the new complete solution. An example to\ndemonstrate a tropical analogue of the analytical hierarchy process decision\nscheme is also given. \n\n"}
{"id": "1503.04251", "contents": "Title: Performance Impact of LoS and NLoS Transmissions in Dense Cellular\n  Networks Abstract: In this paper, we introduce a sophisticated path loss model incorporating\nboth line-of-sight (LoS) and non-line-of-sight (NLoS) transmissions to study\ntheir impact on the performance of dense small cell networks (SCNs). Analytical\nresults are obtained for the coverage probability and the area spectral\nefficiency (ASE), assuming both a general path loss model and a special case\nwith a linear LoS probability function. The performance impact of LoS and NLoS\ntransmissions in dense SCNs in terms of the coverage probability and the ASE is\nsignificant, both quantitatively and qualitatively, compared with the previous\nwork that does not differentiate LoS and NLoS transmissions. Our analysis\ndemonstrates that the network coverage probability first increases with the\nincrease of the base station (BS) density, and then decreases as the SCN\nbecomes denser. This decrease further makes the ASE suffer from a slow growth\nor even a decrease with network densification. The ASE will grow almost\nlinearly as the BS density goes ultra dense. For practical regime of the BS\ndensity, the performance results derived from our analysis are distinctively\ndifferent from previous results, and thus shed new insights on the design and\ndeployment of future dense SCNs. \n\n"}
{"id": "1503.04609", "contents": "Title: Energy-Efficient Power Control: A Look at 5G Wireless Technologies Abstract: This work develops power control algorithms for energy efficiency (EE)\nmaximization (measured in bit/Joule) in wireless networks. Unlike previous\nrelated works, minimum-rate constraints are imposed and the\nsignal-to-interference-plus-noise ratio takes a more general expression, which\nallows one to encompass some of the most promising 5G candidate technologies.\nBoth network-centric and user-centric EE maximizations are considered. In the\nnetwork-centric scenario, the maximization of the global EE and the minimum EE\nof the network are performed. Unlike previous contributions, we develop\ncentralized algorithms that are guaranteed to converge, with affordable\ncomputational complexity, to a Karush-Kuhn-Tucker point of the considered\nnon-convex optimization problems. Moreover, closed-form feasibility conditions\nare derived. In the user-centric scenario, game theory is used to study the\nequilibria of the network and to derive convergent power control algorithms,\nwhich can be implemented in a fully decentralized fashion. Both scenarios above\nare studied under the assumption that single or multiple resource blocks are\nemployed for data transmission. Numerical results assess the performance of the\nproposed solutions, analyzing the impact of minimum-rate constraints, and\ncomparing the network-centric and user-centric approaches. \n\n"}
{"id": "1503.04885", "contents": "Title: Optimal control of the state statistics for a linear stochastic system Abstract: We consider a variant of the classical linear quadratic Gaussian regulator\n(LQG) in which penalties on the endpoint state are replaced by the\nspecification of the terminal state distribution. The resulting theory\nconsiderably differs from LQG as well as from formulations that bound the\nprobability of violating state constraints. We develop results for optimal\nstate-feedback control in the two cases where i) steering of the state\ndistribution is to take place over a finite window of time with minimum energy,\nand ii) the goal is to maintain the state at a stationary distribution over an\ninfinite horizon with minimum power. For both problems the distribution of\nnoise and state are Gaussian. In the first case, we show that provided the\nsystem is controllable, the state can be steered to any terminal Gaussian\ndistribution over any specified finite time-interval. In the second case, we\ncharacterize explicitly the covariance of admissible stationary state\ndistributions that can be maintained with constant state-feedback control. The\nconditions for optimality are expressed in terms of a system of dynamically\ncoupled Riccati equations in the finite horizon case and in terms of algebraic\nconditions for the stationary case. In the case where the noise and control\nshare identical input channels, the Riccati equations for finite-horizon\nsteering become homogeneous and can be solved in closed form. The present paper\nis largely based on our recent work in arxiv.org/abs/1408.2222,\narxiv.org/abs/1410.3447 and presents an overview of certain key results. \n\n"}
{"id": "1503.05314", "contents": "Title: On the Performance of Turbo Signal Recovery with Partial DFT Sensing\n  Matrices Abstract: This letter is on the performance of the turbo signal recovery (TSR)\nalgorithm for partial discrete Fourier transform (DFT) matrices based\ncompressed sensing. Based on state evolution analysis, we prove that TSR with a\npartial DFT sensing matrix outperforms the well-known approximate message\npassing (AMP) algorithm with an independent identically distributed (IID)\nsensing matrix. \n\n"}
{"id": "1503.06014", "contents": "Title: Optimal estimation with missing observations via balanced time-symmetric\n  stochastic models Abstract: We consider data fusion for the purpose of smoothing and interpolation based\non observation records with missing data. Stochastic processes are generated by\nlinear stochastic models. The paper begins by drawing a connection between time\nreversal in stochastic systems and all-pass extensions. A particular\nnormalization (choice of basis) between the two time-directions allows the two\nto share the same orthonormalized state process and simplifies the mathematics\nof data fusion. In this framework we derive symmetric and balanced\nMayne-Fraser-like formulas that apply simultaneously to smoothing and\ninterpolation. \n\n"}
{"id": "1503.06575", "contents": "Title: Unveiling Spatial Epidemiology of HIV with Mobile Phone Data Abstract: An increasing amount of geo-referenced mobile phone data enables the\nidentification of behavioral patterns, habits and movements of people. With\nthis data, we can extract the knowledge potentially useful for many\napplications including the one tackled in this study - understanding spatial\nvariation of epidemics. We explored the datasets collected by a cell phone\nservice provider and linked them to spatial HIV prevalence rates estimated from\npublicly available surveys. For that purpose, 224 features were extracted from\nmobility and connectivity traces and related to the level of HIV epidemic in 50\nIvory Coast departments. By means of regression models, we evaluated predictive\nability of extracted features. Several models predicted HIV prevalence that are\nhighly correlated (>0.7) with actual values. Through contribution analysis we\nidentified key elements that impact the rate of infections. Our findings\nindicate that night connectivity and activity, spatial area covered by users\nand overall migrations are strongly linked to HIV. By visualizing the\ncommunication and mobility flows, we strived to explain the spatial structure\nof epidemics. We discovered that strong ties and hubs in communication and\nmobility align with HIV hot spots. \n\n"}
{"id": "1503.07652", "contents": "Title: Upper Bound on the Capacity of a Cascade of Nonlinear and Noisy Channels Abstract: An upper bound on the capacity of a cascade of nonlinear and noisy channels\nis presented. The cascade mimics the split-step Fourier method for computing\nwaveform propagation governed by the stochastic generalized nonlinear\nSchroedinger equation. It is shown that the spectral efficiency of the cascade\nis at most log(1+SNR), where SNR is the receiver signal-to-noise ratio. The\nresults may be applied to optical fiber channels. However, the definition of\nbandwidth is subtle and leaves open interpretations of the bound. Some of these\ninterpretations are discussed. \n\n"}
{"id": "1504.00057", "contents": "Title: Optimal Power Flow with Weighted Chance Constraints and General Policies\n  for Generation Control Abstract: Due to the increasing amount of electricity generated from renewable sources,\nuncertainty in power system operation will grow. This has implications for\ntools such as Optimal Power Flow (OPF), an optimization problem widely used in\npower system operations and planning, which should be adjusted to account for\nthis uncertainty. One way to handle the uncertainty is to formulate a Chance\nConstrained OPF (CC-OPF) which limits the probability of constraint violation\nto a predefined value. However, existing CC-OPF formulations and solutions are\nnot immune to drawbacks. On one hand, they only consider affine policies for\ngeneration control, which are not always realistic and may be sub-optimal. On\nthe other hand, the standard CC-OPF formulations do not distinguish between\nlarge and small violations, although those might carry significantly different\nrisk. In this paper, we introduce the Weighted CC-OPF (WCC-OPF) that can handle\ngeneral control policies while preserving convexity and allowing for efficient\ncomputation. The weighted chance constraints account for the size of violations\nthrough a weighting function, which assigns a higher risk to a higher\noverloads. We prove that the problem remains convex for any convex weighting\nfunction, and for very general generation control policies. In a case study, we\ncompare the performance of the new WCC-OPF and the standard CC-OPF and\ndemonstrate that WCC-OPF effectively reduces the number of severe overloads.\nFurthermore, we compare an affine generation control policy with a more general\npolicy, and show that the additional flexibility allow for a lower cost while\nmaintaining the same level of risk. \n\n"}
{"id": "1504.00086", "contents": "Title: A remark on weaken restricted isometry property in compressed sensing Abstract: The restricted isometry property (RIP) has become well-known in the\ncompressed sensing community. Recently, a weaken version of RIP was proposed\nfor exact sparse recovery under weak moment assumptions. In this note, we prove\nthat the weaken RIP is also sufficient for \\textsl{stable and robust} sparse\nrecovery by linking it with a recently introduced robust width property in\ncompressed sensing. Moreover, we show that it can be widely apply to other\ncompressed sensing instances as well. \n\n"}
{"id": "1504.00532", "contents": "Title: A general framework for compressed sensing and parallel MRI using\n  annihilating filter based low-rank Hankel matrix Abstract: Parallel MRI (pMRI) and compressed sensing MRI (CS-MRI) have been considered\nas two distinct reconstruction problems. Inspired by recent k-space\ninterpolation methods, an annihilating filter based low-rank Hankel matrix\napproach (ALOHA) is proposed as a general framework for sparsity-driven k-space\ninterpolation method which unifies pMRI and CS-MRI. Specifically, our framework\nis based on the fundamental duality between the transform domain sparsity in\nthe primary space and the low-rankness of weighted Hankel matrix in the\nreciprocal space, which converts pMRI and CS-MRI to a k-space interpolation\nproblem using structured matrix completion. Using theoretical results from the\nlatest compressed sensing literatures, we showed that the required sampling\nrates for ALOHA may achieve the optimal rate. Experimental results with in vivo\ndata for single/multi-coil imaging as well as dynamic imaging confirmed that\nthe proposed method outperforms the state-of-the-art pMRI and CS-MRI. \n\n"}
{"id": "1504.00770", "contents": "Title: Joint Power Splitting and Secure Beamforming Design in the\n  Wireless-powered Untrusted Relay Networks Abstract: In this work, we maximize the secrecy rate of the wireless-powered untrusted\nrelay network by jointly designing power splitting (PS) ratio and relay\nbeamforming with the proposed global optimal algorithm (GOA) and local optimal\nalgorithm (LOA). Different from the literature, artificial noise (AN) sent by\nthe destination not only degrades the channel condition of the eavesdropper to\nimprove the secrecy rate, but also becomes a new source of energy powering the\nuntrusted relay based on PS. Hence, it is of high economic benefits and\nefficiency to take advantage of AN compared with the literature. Simulation\nresults show that LOA can achieve satisfactory secrecy rate performance\ncompared with that of GOA, but with less computation time. \n\n"}
{"id": "1504.00874", "contents": "Title: Steering state statistics with output feedback Abstract: Consider a linear stochastic system whose initial state is a random vector\nwith a specified Gaussian distribution. Such a distribution may represent a\ncollection of particles abiding by the specified system dynamics. In recent\npublications, we have shown that, provided the system is controllable, it is\nalways possible to steer the state covariance to any specified terminal\nGaussian distribution using state feedback. The purpose of the present work is\nto show that, in the case where only partial state observation is available, a\nnecessary and sufficient condition for being able to steer the system to a\nspecified terminal Gaussian distribution for the state vector is that the\nterminal state covariance be greater (in the positive-definite sense) than the\nerror covariance of a corresponding Kalman filter. \n\n"}
{"id": "1504.00931", "contents": "Title: Facial Reduction and SDP Methods for Systems of Polynomial Equations Abstract: The real radical ideal of a system of polynomials with finitely many complex\nroots is generated by a system of real polynomials having only real roots and\nfree of multiplicities. It is a central object in computational real algebraic\ngeometry and important as a preconditioner for numerical solvers. Lasserre and\nco-workers have shown that the real radical ideal of real polynomial systems\nwith finitely many real solutions can be determined by a combination of\nsemi-definite programming (SDP) and geometric involution techniques. A\nconjectured extension of such methods to positive dimensional polynomial\nsystems has been given recently by Ma, Wang and Zhi.\n  We show that regularity in the form of the Slater constraint qualification\n(strict feasibility) fails for the resulting SDP feasibility problems. Facial\nreduction is then a popular technique whereby SDP problems that fail strict\nfeasibility can be regularized by projecting onto a face of the convex cone of\nsemi-definite problems.\n  In this paper we introduce a framework for combining facial reduction with\nsuch SDP methods for analyzing $0$ and positive dimensional real ideals of real\npolynomial systems. The SDP methods are implemented in MATLAB and our geometric\ninvolutive form is implemented in Maple. We use two approaches to find a\nfeasible moment matrix. We use an interior point method within the CVX package\nfor MATLAB and also the Douglas-Rachford (DR) projection-reflection method.\n  Illustrative examples show the advantages of the DR approach for some\nproblems over standard interior point methods. We also see the advantage of\nfacial reduction both in regularizing the problem and also in reducing the\ndimension of the moment matrices. Problems requiring more than one facial\nreduction are also presented. \n\n"}
{"id": "1504.03728", "contents": "Title: Robustness of power systems under a democratic fiber bundle-like model Abstract: We consider a power system with $N$ transmission lines whose initial loads\n(i.e., power flows) $L_1, \\ldots, L_N$ are independent and identically\ndistributed with $P_L(x)$. The capacity $C_i$ defines the maximum flow allowed\non line $i$, and is assumed to be given by $C_i=(1+\\alpha)L_i$, with\n$\\alpha>0$. We study the robustness of this power system against random attacks\n(or, failures) that target a $p$-{\\em fraction} of the lines, under a\ndemocratic fiber bundle-like model. Namely, when a line fails, the load it was\ncarrying is redistributed equally among the remaining lines. Our contributions\nare as follows: i) we show analytically that the final breakdown of the system\nalways takes place through a first-order transition at the critical attack size\n$p^{\\star}=1-\\frac{E[L]}{\\max\\{P(L>x)(\\alpha x + E[L ~|~ L>x])\\}}~~~$; ii) we\nderive conditions on the distribution $P_L(x)$ for which the first order break\ndown of the system occurs abruptly without any preceding diverging rate of\nfailure; iii) we provide a detailed analysis of the robustness of the system\nunder three specific load distributions: Uniform, Pareto, and Weibull, showing\nthat with the minimum load $L_{\\textrm{min}}$ and mean load $E[L]$ fixed,\nPareto distribution is the worst (in terms of robustness) among the three,\nwhereas Weibull distribution is the best with shape parameter selected\nrelatively large; iv) we provide numerical results that confirm our mean-field\nanalysis; and v) we show that $p^{\\star}$ is maximized when the load\ndistribution is a Dirac delta function centered at $E[L]$, i.e., when all lines\ncarry the same load; we also show that optimal $p^{\\star}$ equals\n$\\frac{\\alpha}{\\alpha+1}$. This last finding is particularly surprising given\nthat heterogeneity is known to lead to high robustness against random failures\nin many other systems. \n\n"}
{"id": "1504.04357", "contents": "Title: DEFENDER: Detecting and Forecasting Epidemics using Novel Data-analytics\n  for Enhanced Response Abstract: In recent years social and news media have increasingly been used to explain\npatterns in disease activity and progression. Social media data, principally\nfrom the Twitter network, has been shown to correlate well with official\ndisease case counts. This fact has been exploited to provide advance warning of\noutbreak detection, tracking of disease levels and the ability to predict the\nlikelihood of individuals developing symptoms. In this paper we introduce\nDEFENDER, a software system that integrates data from social and news media and\nincorporates algorithms for outbreak detection, situational awareness,\nsyndromic case tracking and forecasting. As part of this system we have\ndeveloped a technique for creating a location network for any country or region\nbased purely on Twitter data. We also present a disease count tracking approach\nwhich leverages counts from multiple symptoms, which was found to improve the\ntracking of diseases by 37 percent over a model that used only previous case\ndata. Finally we attempt to forecast future levels of symptom activity based on\nobserved user movement on Twitter, finding a moderate gain of 5 percent over a\ntime series forecasting model. \n\n"}
{"id": "1504.04553", "contents": "Title: Some constructions of cyclic and quasi-cyclic subspaces codes Abstract: In this paper we construct, using GAP System for Computational Discrete\nAlgebra, some cyclic subspace codes, specially an optimal code over the finite\nfield F_{2^{10}}. Further we present a definition and an example of the\n$q$-analogous of a $m$-quasi-cyclic subspace code over F_{2^{8}}. \n\n"}
{"id": "1504.06249", "contents": "Title: Quantifying Loss of Information in Network-based Dimensionality\n  Reduction Techniques Abstract: To cope with the complexity of large networks, a number of dimensionality\nreduction techniques for graphs have been developed. However, the extent to\nwhich information is lost or preserved when these techniques are employed has\nnot yet been clear. Here we develop a framework, based on algorithmic\ninformation theory, to quantify the extent to which information is preserved\nwhen network motif analysis, graph spectra and spectral sparsification methods\nare applied to over twenty different biological and artificial networks. We\nfind that the spectral sparsification is highly sensitive to high number of\nedge deletion, leading to significant inconsistencies, and that graph spectral\nmethods are the most irregular, capturing algebraic information in a condensed\nfashion but largely losing most of the information content of the original\nnetworks. However, the approach shows that network motif analysis excels at\npreserving the relative algorithmic information content of a network, hence\nvalidating and generalizing the remarkable fact that despite their inherent\ncombinatorial possibilities, local regularities preserve information to such an\nextent that essential properties are fully recoverable across different\nnetworks to determine their family group to which they belong to (eg genetic vs\nsocial network). Our algorithmic information methodology thus provides a\nrigorous framework enabling a fundamental assessment and comparison between\ndifferent data dimensionality reduction methods thereby facilitating the\nidentification and evaluation of the capabilities of old and new methods. \n\n"}
{"id": "1504.06593", "contents": "Title: LP formulations for secrecy over erasure networks with feedback Abstract: We design polynomial time schemes for secure message transmission over\narbitrary networks, in the presence of an eavesdropper, and where each edge\ncorresponds to an erasure channel with public feedback. Our schemes are\ndescribed through linear programming (LP) formulations, that explicitly select\n(possibly different) sets of paths for key-generation and message sending.\nAlthough our LPs are not always capacity-achieving, they outperform the best\nknown alternatives in the literature, and extend to incorporate several\ninteresting scenaria. \n\n"}
{"id": "1504.06861", "contents": "Title: Twitter-based analysis of the dynamics of collective attention to\n  political parties Abstract: Large-scale data from social media have a significant potential to describe\ncomplex phenomena in real world and to anticipate collective behaviors such as\ninformation spreading and social trends. One specific case of study is\nrepresented by the collective attention to the action of political parties. Not\nsurprisingly, researchers and stakeholders tried to correlate parties' presence\non social media with their performances in elections. Despite the many efforts,\nresults are still inconclusive since this kind of data is often very noisy and\nsignificant signals could be covered by (largely unknown) statistical\nfluctuations. In this paper we consider the number of tweets (tweet volume) of\na party as a proxy of collective attention to the party, identify the dynamics\nof the volume, and show that this quantity has some information on the\nelections outcome. We find that the distribution of the tweet volume for each\nparty follows a log-normal distribution with a positive autocorrelation of the\nvolume over short terms, which indicates the volume has large fluctuations of\nthe log-normal distribution yet with a short-term tendency. Furthermore, by\nmeasuring the ratio of two consecutive daily tweet volumes, we find that the\nevolution of the daily volume of a party can be described by means of a\ngeometric Brownian motion (i.e., the logarithm of the volume moves randomly\nwith a trend). Finally, we determine the optimal period of averaging tweet\nvolume for reducing fluctuations and extracting short-term tendencies. We\nconclude that the tweet volume is a good indicator of parties' success in the\nelections when considered over an optimal time window. Our study identifies the\nstatistical nature of collective attention to political issues and sheds light\non how to model the dynamics of collective attention in social media. \n\n"}
{"id": "1504.07751", "contents": "Title: NOMA: An Information Theoretic Perspective Abstract: In this letter, the performance of non-orthogonal multiple access (NOMA) is\ninvestigated from an information theoretic perspective. The relationships among\nthe capacity region of broadcast channels and two rate regions achieved by NOMA\nand time-division multiple access (TDMA) are illustrated first. Then, the\nperformance of NOMA is evaluated by considering TDMA as the benchmark, where\nboth the sum rate and the individual user rates are used as the criteria. In a\nwireless downlink scenario with user pairing, the developed analytical results\nshow that NOMA can outperform TDMA not only for the sum rate but also for each\nuser's individual rate, particularly when the difference between the users'\nchannels is large. \n\n"}
{"id": "1504.08096", "contents": "Title: On Some Classes of $\\mathbb{Z}_{2}\\mathbb{Z}_{4}-$Linear Codes and their\n  Covering Radius Abstract: In this paper we define $\\mathbb{Z}_{2}\\mathbb{Z}_{4}-$Simplex and MacDonald\nCodes of type $\\alpha $ and $\\beta $ and we give the covering radius of these\ncodes. \n\n"}
{"id": "1505.02651", "contents": "Title: Additive monotones for resource theories of parallel-combinable\n  processes with discarding Abstract: A partitioned process theory, as defined by Coecke, Fritz, and Spekkens, is a\nsymmetric monoidal category together with an all-object-including symmetric\nmonoidal subcategory. We think of the morphisms of this category as processes,\nand the morphisms of the subcategory as those processes that are freely\nexecutable. Via a construction we refer to as parallel-combinable processes\nwith discarding, we obtain from this data a partially ordered monoid on the set\nof processes, with f > g if one can use the free processes to construct g from\nf. The structure of this partial order can then be probed using additive\nmonotones: order-preserving monoid homomorphisms with values in the real\nnumbers under addition. We first characterise these additive monotones in terms\nof the corresponding partitioned process theory.\n  Given enough monotones, we might hope to be able to reconstruct the order on\nthe monoid. If so, we say that we have a complete family of monotones. In\ngeneral, however, when we require our monotones to be additive monotones, such\nfamilies do not exist or are hard to compute. We show the existence of complete\nfamilies of additive monotones for various partitioned process theories based\non the category of finite sets, in order to shed light on the way such families\ncan be constructed. \n\n"}
{"id": "1505.05123", "contents": "Title: Reed-Muller Codes Achieve Capacity on Erasure Channels Abstract: This paper introduces a new approach to proving that a sequence of\ndeterministic linear codes achieves capacity on an erasure channel under\nmaximum a posteriori decoding. Rather than relying on the precise structure of\nthe codes, this method requires only that the codes are highly symmetric. In\nparticular, the technique applies to any sequence of linear codes where the\nblocklengths are strictly increasing, the code rates converge to a number\nbetween 0 and 1, and the permutation group of each code is doubly transitive.\nThis also provides a rare example in information theory where symmetry alone\nimplies near-optimal performance.\n  An important consequence of this result is that a sequence of Reed-Muller\ncodes with increasing blocklength achieves capacity if its code rate converges\nto a number between 0 and 1. This possibility has been suggested previously in\nthe literature but it has only been proven for cases where the limiting code\nrate is 0 or 1. Moreover, these results extend naturally to affine-invariant\ncodes and, thus, to all extended primitive narrow-sense BCH codes. The primary\ntools used in the proof are the sharp threshold property for monotone boolean\nfunctions and the area theorem for extrinsic information transfer functions. \n\n"}
{"id": "1505.06476", "contents": "Title: Emergence of bimodality in controlling complex networks Abstract: Our ability to control complex systems is a fundamental challenge of\ncontemporary science. Recently introduced tools to identify the driver nodes,\nnodes through which we can achieve full control, predict the existence of\nmultiple control configurations, prompting us to classify each node in a\nnetwork based on their role in control. Accordingly a node is critical,\nintermittent or redundant if it acts as a driver node in all, some or none of\nthe control configurations. Here we develop an analytical framework to identify\nthe category of each node, leading to the discovery of two distinct control\nmodes in complex systems: centralized vs distributed control. We predict the\ncontrol mode for an arbitrary network and show that one can alter it through\nsmall structural perturbations. The uncovered bimodality has implications from\nnetwork security to organizational research and offers new insights into the\ndynamics and control of complex systems. \n\n"}
{"id": "1505.07206", "contents": "Title: Uplink Downlink Rate Balancing in Cooperating Cellular Networks Abstract: Broadcast MIMO techniques can significantly increase the throughput in the\ndownlink of cellular networks, at the price of channel state information (CSI)\nfeedback from the mobiles, sent over the uplink. Thus, it creates a mechanism\nthat can tradeoff some uplink capacity for increased downlink capacity. In this\nwork we quantify this tradeoff and study the exchange ratio between the\nfeedback rate (over the uplink) and the downlink rate. We study both finite and\ninfinite networks, and show that for high enough (but finite) SNR, the uplink\nrate can be exchanged for increased downlink rate with a favorable exchange\nratio. This exchange ratio is an increasing function of the channel coherence\ntime, and a decreasing function of the number of measured base stations. We\nalso show that devoting a constant fraction of the uplink to CSI feedback can\nincrease the downlink multiplexing gain continuously from 0 to 1, in finite\nnetworks. On the other hand, in infinite networks (with infinite connectivity)\nour bounds can only show doubly logarithmic scaling of the rate with SNR. The\npresented results prove that the adaptation of the feedback rate can control\nthe balance between the uplink and downlink rates. This capability is very\nimportant in modern cellular networks, where the operators need to respond to\ncontinuously changing user demands. \n\n"}
{"id": "1505.07283", "contents": "Title: Index Codes for the Gaussian Broadcast Channel using Quadrature\n  Amplitude Modulation Abstract: We propose index codes, based on multidimensional QAM constellations, for the\nGaussian broadcast channel, where every receiver demands all the messages from\nthe source. The efficiency with which an index code exploits receiver side\ninformation in this broadcast channel is characterised by a code design metric\ncalled \"side information gain\". The known index codes for this broadcast\nchannel enjoy large side information gains, but do not encode all the source\nmessages at the same rate, and do not admit message sizes that are powers of\ntwo. The index codes proposed in this letter, which are based on linear codes\nover integer rings, overcome both these drawbacks and yet provide large values\nof side information gain. With the aid of a computer search, we obtain QAM\nindex codes for encoding up to 5 messages with message sizes 2^m, m <= 6. We\nalso present the simulated performance of a new 16-QAM index code, concatenated\nwith an off-the-shelf LDPC code, which is observed to operate within 4.3 dB of\nthe broadcast channel capacity. \n\n"}
{"id": "1505.07478", "contents": "Title: Generalized communities in networks Abstract: A substantial volume of research has been devoted to studies of community\nstructure in networks, but communities are not the only possible form of\nlarge-scale network structure. Here we describe a broad extension of community\nstructure that encompasses traditional communities but includes a wide range of\ngeneralized structural patterns as well. We describe a principled method for\ndetecting this generalized structure in empirical network data and demonstrate\nwith real-world examples how it can be used to learn new things about the shape\nand meaning of networks. \n\n"}
{"id": "1505.08159", "contents": "Title: Dynamic Patterns of Academic Forum Activities Abstract: A mass of traces of human activities show rich dynamic patterns. In this\narticle, we comprehensively investigate the dynamic patterns of 50 thousands of\nresearchers' activities in Sciencenet, the largest multi-disciplinary academic\ncommunity in China. Through statistical analyses, we found that (i) there\nexists a power-law scaling between the frequency of visits to an academic forum\nand the number of corresponding visitors, with the exponent being about 1.33;\n(ii) the expansion process of academic forums obeys the Heaps' law, namely the\nnumber of distinct visited forums to the number of visits grows in a power-law\nform with exponent being about 0.54; (iii) the probability distributions of\ntime intervals and the number of visits taken to revisit the same academic\nforum both follow power-laws, indicating the existence of memory effect in\nacademic forum activities. On the basis of these empirical results, we propose\na dynamic model that incorporates the exploration, preferential return and\nmemory effect, which can well reproduce the observed scaling laws. \n\n"}
{"id": "1506.00194", "contents": "Title: Secure Cascade Channel Synthesis Abstract: We consider the problem of generating correlated random variables in a\ndistributed fashion, where communication is constrained to a cascade network.\nThe first node in the cascade observes an i.i.d. sequence $X^n$ locally before\ninitiating communication along the cascade. All nodes share bits of common\nrandomness that are independent of $X^n$. We consider secure synthesis - random\nvariables produced by the system appear to be appropriately correlated and\ni.i.d. even to an eavesdropper who is cognizant of the communication\ntransmissions. We characterize the optimal tradeoff between the amount of\ncommon randomness used and the required rates of communication. We find that\nnot only does common randomness help, its usage exceeds the communication rate\nrequirements. The most efficient scheme is based on a superposition codebook,\nwith the first node selecting messages for all downstream nodes. We also\nprovide a fleeting view of related problems, demonstrating how the optimal rate\nregion may shrink or expand. \n\n"}
{"id": "1506.00300", "contents": "Title: How To Tame Your Sparsity Constraints Abstract: We show that designing sparse $H_\\infty$ controllers, in a discrete (LTI)\nsetting, is easy when the controller is assumed to be an FIR filter. In this\ncase, the problem reduces to a static output feedback problem with equality\nconstraints. We show how to obtain an initial guess, for the controller, and\nthen provide a simple algorithm that alternates between two (convex)\nfeasibility programs until converging, when the problem is feasible, to a\nsuboptimal $H_\\infty$ controller that is automatically stable. As FIR filters\ncontain the information of their impulse response in their coefficients, it is\neasy to see that our results provide a path of least resistance to designing\nsparse robust controllers for continuous-time plants, via system identification\nmethods. \n\n"}
{"id": "1506.03324", "contents": "Title: On the High-SNR Capacity of the Gaussian Interference Channel and New\n  Capacity Bounds Abstract: The best outer bound on the capacity region of the two-user Gaussian\nInterference Channel (GIC) is known to be the intersection of regions of\nvarious bounds including genie-aided outer bounds, in which a genie provides\nnoisy input signals to the intended receiver. The Han and Kobayashi (HK) scheme\nprovides the best known inner bound. The rate difference between the best known\nlower and upper bounds on the sum capacity remains as large as 1 bit per\nchannel use especially around $g^2=P^{-1/3}$, where $P$ is the symmetric power\nconstraint and $g$ is the symmetric real cross-channel coefficient. In this\npaper, we pay attention to the \\emph{moderate interference regime} where\n$g^2\\in (\\max(0.086, P^{-1/3}),1)$. We propose a new upper-bounding technique\nthat utilizes noisy observation of interfering signals as genie signals and\napplies time sharing to the genie signals at the receivers. A conditional\nversion of the worst additive noise lemma is also introduced to derive new\ncapacity bounds. The resulting upper (outer) bounds on the sum capacity\n(capacity region) are shown to be tighter than the existing bounds in a certain\nrange of the moderate interference regime. Using the new upper bounds and the\nHK lower bound, we show that $R_\\text{sym}^*=\\frac{1}{2}\\log\n\\big(|g|P+|g|^{-1}(P+1)\\big)$ characterizes the capacity of the symmetric real\nGIC to within $0.104$ bit per channel use in the moderate interference regime\nat any signal-to-noise ratio (SNR). We further establish a high-SNR\ncharacterization of the symmetric real GIC, where the proposed upper bound is\nat most $0.1$ bit far from a certain HK achievable scheme with Gaussian\nsignaling and time sharing for $g^2\\in (0,1]$. In particular, $R_\\text{sym}^*$\nis achievable at high SNR by the proposed HK scheme and turns out to be the\nhigh-SNR capacity at least at $g^2=0.25, 0.5$. \n\n"}
{"id": "1506.04255", "contents": "Title: Entropic and displacement interpolation: a computational approach using\n  the Hilbert metric Abstract: Monge-Kantorovich optimal mass transport (OMT) provides a blueprint for\ngeometries in the space of positive densities -- it quantifies the cost of\ntransporting a mass distribution into another. In particular, it provides\nnatural options for interpolation of distributions (displacement interpolation)\nand for modeling flows. As such it has been the cornerstone of recent\ndevelopments in physics, probability theory, image processing, time-series\nanalysis, and several other fields. In spite of extensive work and theoretical\ndevelopments, the computation of OMT for large scale problems has remained a\nchallenging task. An alternative framework for interpolating distributions,\nrooted in statistical mechanics and large deviations, is that of Schroedinger\nbridges (entropic interpolation). This may be seen as a stochastic\nregularization of OMT and can be cast as the stochastic control problem of\nsteering the probability density of the state-vector of a dynamical system\nbetween two marginals. In this approach, however, the actual computation of\nflows had hardly received any attention. In recent work on Schroedinger bridges\nfor Markov chains and quantum evolutions, we noted that the solution can be\nefficiently obtained from the fixed-point of a map which is contractive in the\nHilbert metric. Thus, the purpose of this paper is to show that a similar\napproach can be taken in the context of diffusion processes which i) leads to a\nnew proof of a classical result on Schroedinger bridges and ii) provides an\nefficient computational scheme for both, Schroedinger bridges and OMT. We\nillustrate this new computational approach by obtaining interpolation of\ndensities in representative examples such as interpolation of images. \n\n"}
{"id": "1506.04773", "contents": "Title: DistFlow Extensions for AC Transmission Systems Abstract: Convex relaxations of the power flow equations and, in particular, the\nSemi-Definite Programming (SDP), Second-Order Cone (SOC), and Convex DistFlow\n(CDF) relaxations, have attracted significant interest in recent years. Thus\nfar, studies of the CDF model and its connection to the other relaxations have\nbeen limited to power distribution systems, which omit several parameters\nnecessary for modeling transmission systems. To increase the applicability of\nthe CDF relaxation, this paper develops an extended CDF model that is suitable\nfor transmission systems by incorporating bus shunts, line charging, and\ntransformers. Additionally, a theoretical result shows that the established\nequivalence of the SOC and CDF models for distribution systems also holds in\nthis transmission system extension. \n\n"}
{"id": "1506.04830", "contents": "Title: Maximizing the Link Throughput between Smart-meters and Aggregators as\n  Secondary Users under Power and Outage Constraints Abstract: This paper assesses the communication link from smart meters to aggregators\nas (unlicensed) secondary users that transmit their data over the (licensed)\nprimary uplink channel. The proposed scenario assumes: (i) meters' and\naggregators' positions are fixed so highly directional antennas are employed,\n(ii) secondary users transmit with limited power in relation to the primary,\n(iii) meters' transmissions are coordinated to avoid packet collisions, and\n(iv) the secondary links' robustness is guaranteed by an outage constraint.\nUnder these assumptions, the interference caused by secondary users in both\nprimary (base-stations) and other secondary users can be neglected. As\nunlicensed users, however, meter-aggregator links do experience interference\nfrom the mobile users of the primary network, whose positions and traffic\nactivity are unknown. To cope with this uncertainty, we model the mobile users\nspatial distribution as a Poisson point process. We then derive a closed-form\nsolution for the maximum achievable throughput with respect to a reference\nsecondary link subject to transmit power and outage constraints. Our numerical\nresults illustrate the effects of such constraints on the optimal throughput,\nevincing that more frequent outage events improve the system performance in the\nscenario under study. We also show that relatively high outage probabilities\nhave little effect on the reconstruction of the average power demand curve that\nis transmitted from the smart-meter to the aggregator. \n\n"}
{"id": "1506.07165", "contents": "Title: Random walk centrality in interconnected multilayer networks Abstract: Real-world complex systems exhibit multiple levels of relationships. In many\ncases they require to be modeled as interconnected multilayer networks,\ncharacterizing interactions of several types simultaneously. It is of crucial\nimportance in many fields, from economics to biology and from urban planning to\nsocial sciences, to identify the most (or the less) influential nodes in a\nnetwork using centrality measures. However, defining the centrality of actors\nin interconnected complex networks is not trivial. In this paper, we rely on\nthe tensorial formalism recently proposed to characterize and investigate this\nkind of complex topologies, and extend two well known random walk centrality\nmeasures, the random walk betweenness and closeness centrality, to\ninterconnected multilayer networks. For each of the measures we provide\nanalytical expressions that completely agree with numerically results. \n\n"}
{"id": "1506.08159", "contents": "Title: Near-Optimal Estimation of Simultaneously Sparse and Low-Rank Matrices\n  from Nested Linear Measurements Abstract: In this paper we consider the problem of estimating simultaneously low-rank\nand row-wise sparse matrices from nested linear measurements where the linear\noperator consists of the product of a linear operator $\\mathcal{W}$ and a\nmatrix $\\mathbf{\\varPsi}$. Leveraging the nested structure of the measurement\noperator, we propose a computationally efficient two-stage algorithm for\nestimating the simultaneously structured target matrix. Assuming that\n$\\mathcal{W}$ is a restricted isometry for low-rank matrices and\n$\\mathbf{\\varPsi}$ is a restricted isometry for row-wise sparse matrices, we\nestablish an accuracy guarantee that holds uniformly for all sufficiently\nlow-rank and row-wise sparse matrices with high probability. Furthermore, using\nstandard tools from information theory, we establish a minimax lower bound for\nestimation of simultaneously low-rank and row-wise sparse matrices from linear\nmeasurements that need not be nested. The accuracy bounds established for the\nalgorithm, that also serve as a minimax upper bound, differ from the derived\nminimax lower bound merely by a polylogarithmic factor of the dimensions.\nTherefore, the proposed algorithm is nearly minimax optimal. We also discuss\nsome applications of the proposed observation model and evaluate our algorithm\nthrough numerical simulation. \n\n"}
{"id": "1506.08291", "contents": "Title: Generalized Space and Frequency Index Modulation Abstract: Unlike in conventional modulation where information bits are conveyed only\nthrough symbols from modulation alphabets defined in the complex plane (e.g.,\nquadrature amplitude modulation (QAM), phase shift keying (PSK)), in index\nmodulation (IM), additional information bits are conveyed through indices of\ncertain transmit entities that get involved in the transmission. Transmit\nantennas in multi-antenna systems and subcarriers in multi-carrier systems are\nexamples of such transmit entities that can be used to convey additional\ninformation bits through indexing. In this paper, we introduce {\\em generalized\nspace and frequency index modulation}, where the indices of active transmit\nantennas and subcarriers convey information bits. We first introduce index\nmodulation in the spatial domain, referred to as generalized spatial index\nmodulation (GSIM). For GSIM, where bits are indexed only in the spatial domain,\nwe derive the expression for achievable rate as well as easy-to-compute upper\nand lower bounds on this rate. We show that the achievable rate in GSIM can be\nmore than that in spatial multiplexing, and analytically establish the\ncondition under which this can happen. It is noted that GSIM achieves this\nhigher rate using fewer transmit radio frequency (RF) chains compared to\nspatial multiplexing. We also propose a Gibbs sampling based detection\nalgorithm for GSIM and show that GSIM can achieve better bit error rate (BER)\nperformance than spatial multiplexing. For generalized space-frequency index\nmodulation (GSFIM), where bits are encoded through indexing in both active\nantennas as well as subcarriers, we derive the achievable rate expression.\nNumerical results show that GSFIM can achieve higher rates compared to\nconventional MIMO-OFDM. Also, BER results show the potential for GSFIM\nperforming better than MIMO-OFDM. \n\n"}
{"id": "1507.00695", "contents": "Title: A new framework for dynamical models on multiplex networks Abstract: Many complex systems have natural representations as multi-layer networks.\nWhile these formulations retain more information than standard single-layer\nnetwork models, there is not yet a fully developed theory for computing network\nmetrics and statistics on these objects. We introduce a family of models of\nmultiplex processes motivated by dynamical applications and investigate the\nproperties of their spectra both theoretically and computationally. We study\nspecial cases of multiplex diffusion and Markov dynamics, using the spectral\nresults to compute their rates of convergence. We use our framework to define a\nversion of multiplex eigenvector centrality, which generalizes some existing\nnotions in the literature. Last, we compare our operator to\nstructurally-derived models on synthetic and real-world networks, helping\ndelineate the contexts in which the different frameworks are appropriate. \n\n"}
{"id": "1507.01699", "contents": "Title: Millimeter Wave MIMO with Lens Antenna Array: A New Path Division\n  Multiplexing Paradigm Abstract: Millimeter wave (mmWave) communication is a promising technology for 5G\ncellular systems. To compensate for the severe path loss in mmWave systems,\nlarge antenna arrays are generally used to achieve significant beamforming\ngains. However, due to the high hardware and power consumption cost associated\nwith radio frequency (RF) chains, it is desirable to achieve the large-antenna\ngains, but with only limited number of RF chains for mmWave communications. To\nthis end, we study in this paper a new lens antenna array enabled mmWave MIMO\ncommunication system. We first show that the array response of the proposed\nlens antenna array at the receiver/transmitter follows a \"sinc\" function, where\nthe antenna with the peak response is determined by the angle of arrival\n(AoA)/departure (AoD) of the received/transmitted signal. By exploiting this\nunique property of lens antenna arrays along with the multi-path sparsity of\nmmWave channels, we propose a novel low-cost and capacity-achieving MIMO\ntransmission scheme, termed \\emph{orthogonal path division multiplexing\n(OPDM)}. For channels with insufficiently separated AoAs and/or AoDs, we also\npropose a simple \\emph{path grouping} technique with group-based small-scale\nMIMO processing to mitigate the inter-path interference. Numerical results are\nprovided to compare the performance of the proposed lens antenna arrays for\nmmWave MIMO system against that of conventional arrays, under different\npractical setups. It is shown that the proposed system achieves significant\nthroughput gain as well as complexity and hardware cost reduction, both making\nit an appealing new paradigm for mmWave MIMO communications. \n\n"}
{"id": "1507.01716", "contents": "Title: Temporal-varying failures of nodes in networks Abstract: We consider networks in which random walkers are removed because of the\nfailure of specific nodes. We interpret the rate of loss as a measure of the\nimportance of nodes, a notion we denote as failure-centrality. We show that the\ndegree of the node is not sufficient to determine this measure and that, in a\nfirst approximation, the shortest loops through the node have to be taken into\naccount. We propose approximations of the failure-centrality which are valid\nfor temporal-varying failures and we dwell on the possibility of externally\nchanging the relative importance of nodes in a given network, by exploiting the\ninterference between the loops of a node and the cycles of the temporal pattern\nof failures. In the limit of long failure cycles we show analytically that the\nescape in a node is larger than the one estimated from a stochastic failure\nwith the same failure probability. We test our general formalism in two\nreal-world networks (air-transportation and e-mail users) and show how\ncommunities lead to deviations from predictions for failures in hubs. \n\n"}
{"id": "1507.05367", "contents": "Title: Structured Sparsity: Discrete and Convex approaches Abstract: Compressive sensing (CS) exploits sparsity to recover sparse or compressible\nsignals from dimensionality reducing, non-adaptive sensing mechanisms. Sparsity\nis also used to enhance interpretability in machine learning and statistics\napplications: While the ambient dimension is vast in modern data analysis\nproblems, the relevant information therein typically resides in a much lower\ndimensional space. However, many solutions proposed nowadays do not leverage\nthe true underlying structure. Recent results in CS extend the simple sparsity\nidea to more sophisticated {\\em structured} sparsity models, which describe the\ninterdependency between the nonzero components of a signal, allowing to\nincrease the interpretability of the results and lead to better recovery\nperformance. In order to better understand the impact of structured sparsity,\nin this chapter we analyze the connections between the discrete models and\ntheir convex relaxations, highlighting their relative advantages. We start with\nthe general group sparse model and then elaborate on two important special\ncases: the dispersive and the hierarchical models. For each, we present the\nmodels in their discrete nature, discuss how to solve the ensuing discrete\nproblems and then describe convex relaxations. We also consider more general\nstructures as defined by set functions and present their convex proxies.\nFurther, we discuss efficient optimization solutions for structured sparsity\nproblems and illustrate structured sparsity in action via three applications. \n\n"}
{"id": "1507.08696", "contents": "Title: Sampling motif-constrained ensembles of networks Abstract: The statistical significance of network properties is conditioned on null\nmodels which satisfy spec- ified properties but that are otherwise random.\nExponential random graph models are a principled theoretical framework to\ngenerate such constrained ensembles, but which often fail in practice, either\ndue to model inconsistency, or due to the impossibility to sample networks from\nthem. These problems affect the important case of networks with prescribed\nclustering coefficient or number of small connected subgraphs (motifs). In this\npaper we use the Wang-Landau method to obtain a multicanonical sampling that\novercomes both these problems. We sample, in polynomial time, net- works with\narbitrary degree sequences from ensembles with imposed motifs counts. Applying\nthis method to social networks, we investigate the relation between\ntransitivity and homophily, and we quantify the correlation between different\ntypes of motifs, finding that single motifs can explain up to 60% of the\nvariation of motif profiles. \n\n"}
{"id": "1508.01892", "contents": "Title: An Adaptive Transmission Protocol for Wireless-Powered Cooperative\n  Communications Abstract: In this paper, we consider a wireless-powered cooperative communication\nnetwork, which consists of one hybrid access point (AP), one source and one\nrelay to assist information transmission. Unlike conventional cooperative\nnetworks, the source and relay are assumed to have no embedded energy supplies\nin the considered system. Hence, they need to first harvest energy from the\nradio-frequency (RF) signals radiated by the AP in the downlink (DL) before\ninformation transmission in the uplink (UL). Inspired by the recently proposed\nharvest-then-transmit (HTT) and harvest-then-cooperate (HTC) protocols, we\ndevelop a new adaptive transmission (AT) protocol. In the proposed protocol, at\nthe beginning of each transmission block, the AP charges the source. AP and\nsource then perform channel estimation to acquire the channel state information\n(CSI) between them. Based on the CSI estimate, the AP adaptively chooses the\nsource to perform UL information transmission either directly or cooperatively\nwith the relay. We derive an approximate closed-form expression for the average\nthroughput of the proposed AT protocol over Nakagami-m fading channels. The\nanalysis is then verified by Monte Carlo simulations. Results show that the\nproposed AT protocol considerably outperforms both the HTT and HTC protocols. \n\n"}
{"id": "1508.05764", "contents": "Title: The 'who' and 'what' of #diabetes on Twitter Abstract: Social media are being increasingly used for health promotion, yet the\nlandscape of users, messages and interactions in such fora is poorly\nunderstood. Studies of social media and diabetes have focused mostly on\npatients, or public agencies addressing it, but have not looked broadly at all\nthe participants or the diversity of content they contribute. We study Twitter\nconversations about diabetes through the systematic analysis of 2.5 million\ntweets collected over 8 months and the interactions between their authors. We\naddress three questions: (1) what themes arise in these tweets?, (2) who are\nthe most influential users?, (3) which type of users contribute to which\nthemes? We answer these questions using a mixed-methods approach, integrating\ntechniques from anthropology, network science and information retrieval such as\nthematic coding, temporal network analysis, and community and topic detection.\nDiabetes-related tweets fall within broad thematic groups: health information,\nnews, social interaction, and commercial. At the same time, humorous messages\nand references to popular culture appear consistently, more than any other type\nof tweet. We classify authors according to their temporal 'hub' and 'authority'\nscores. Whereas the hub landscape is diffuse and fluid over time, top\nauthorities are highly persistent across time and comprise bloggers, advocacy\ngroups and NGOs related to diabetes, as well as for-profit entities without\nspecific diabetes expertise. Top authorities fall into seven interest\ncommunities as derived from their Twitter follower network. Our findings have\nimplications for public health professionals and policy makers who seek to use\nsocial media as an engagement tool and to inform policy design. \n\n"}
{"id": "1508.06021", "contents": "Title: Symbol Detection for Frame-Based Faster-than-Nyquist Signaling via\n  Sum-of-Absolute-Values Optimization Abstract: In this letter, we propose a new symbol detection method for\nfaster-than-Nyquist signaling (FTNS) systems. Based on frame theory, we\nformulate a symbol detection problem as a under-determined linear equation on a\nfinite set. The problem is reformulated as a sum-of-absolute-values (SOAV)\noptimization that can be efficiently solved by the fast iterative shrinkage\nthresholding algorithm (FISTA). The proximity operator for the convex\noptimization is derived analytically. Simulation results are given to show that\nthe proposed method can successfully detect symbols in faster-than-Nyquist\nsignaling systems and has lower complexity in terms of computation time. \n\n"}
{"id": "1508.06467", "contents": "Title: Higher-Order Aggregate Networks in the Analysis of Temporal Networks:\n  Path structures and centralities Abstract: Recent research on temporal networks has highlighted the limitations of a\nstatic network perspective for our understanding of complex systems with\ndynamic topologies. In particular, recent works have shown that i) the specific\norder in which links occur in real-world temporal networks affects causality\nstructures and thus the evolution of dynamical processes, and ii) higher-order\naggregate representations of temporal networks can be used to analytically\nstudy the effect of these order correlations on dynamical processes. In this\narticle we analyze the effect of order correlations on path-based centrality\nmeasures in real-world temporal networks. Analyzing temporal equivalents of\nbetweenness, closeness and reach centrality in six empirical temporal networks,\nwe first show that an analysis of the commonly used static, time-aggregated\nrepresentation can give misleading results about the actual importance of\nnodes. We further study higher-order time-aggregated networks, a recently\nproposed generalization of the commonly applied static, time-aggregated\nrepresentation of temporal networks. Here, we particularly define path-based\ncentrality measures based on second-order aggregate networks, empirically\nvalidating that node centralities calculated in this way better capture the\ntrue temporal centralities of nodes than node centralities calculated based on\nthe commonly used static (first-order) representation. Apart from providing a\nsimple and practical method for the approximation of path-based centralities in\ntemporal networks, our results highlight interesting perspectives for the use\nof higher-order aggregate networks in the analysis of time-stamped network\ndata. \n\n"}
{"id": "1508.06496", "contents": "Title: Approximations of Stochastic Hybrid Systems: A Compositional Approach Abstract: In this paper we propose a compositional framework for the construction of\napproximations of the interconnection of a class of stochastic hybrid systems.\nAs special cases, this class of systems includes both jump linear stochastic\nsystems and linear stochastic hybrid automata. In the proposed framework, an\napproximation is itself a stochastic hybrid system, which can be used as a\nreplacement of the original stochastic hybrid system in a controller design\nprocess. We employ a notion of so-called stochastic simulation function to\nquantify the error between the approximation and the original system. In the\nfirst part of the paper, we derive sufficient conditions which facilitate the\ncompositional quantification of the error between the interconnection of\nstochastic hybrid subsystems and that of their approximations using the\nquantified error between the stochastic hybrid subsystems and their\ncorresponding approximations. In particular, we show how to construct\nstochastic simulation functions for approximations of interconnected stochastic\nhybrid systems using the stochastic simulation function for the approximation\nof each component. In the second part of the paper, we focus on a specific\nclass of stochastic hybrid systems, namely, jump linear stochastic systems, and\npropose a constructive scheme to determine approximations together with their\nstochastic simulation functions for this class of systems. Finally, we\nillustrate the effectiveness of the proposed results by constructing an\napproximation of the interconnection of four jump linear stochastic subsystems\nin a compositional way. \n\n"}
{"id": "1508.06746", "contents": "Title: A New Energy Efficient Beamforming Strategy for MISO Interfering\n  Broadcast Channels based on Large Systems Analysis Abstract: In this paper, we propose a new beamforming design to maximize energy\nefficiency (EE) for multiple input single output interfering broadcast channels\n(IFBC). Under this model, the EE problem is non-convex in general due to the\ncoupled interference and its fractional form, and thus it is difficult to solve\nthe problem. Conventional algorithms which address this problem have adopted an\niterative method for each channel realization, which requires high\ncomputational complexity. In order to reduce the computational complexity, we\nparameterize the beamforming vector by scalar parameters related to beam\ndirection and power. Then, by employing asymptotic results of random matrix\ntheory with this parametrization, we identify the optimal parameters to\nmaximize the EE in the large system limit assuming that the number of transmit\nantennas and users are large with a fixed ratio. In the asymptotic regime, our\nsolutions depend only on the second order channel statistics, which yields\nsignificantly reduced computational complexity and system overhead compared to\nthe conventional approaches. Hence, the beamforming vector to maximize the EE\nperformance can be determined with local channel state information and the\noptimized parameters. Based on the asymptotic results, the proposed scheme can\nprovide insights on the average EE performance, and a simple yet efficient\nbeamforming strategy is introduced for the finite system case. Numerical\nresults confirm that the proposed scheme shows a negligible performance loss\ncompared to the best result achieved by the conventional approaches even with\nsmall system dimensions, with much reduced system complexity. \n\n"}
{"id": "1509.01047", "contents": "Title: A Theory of Super-Resolution from Short-Time Fourier Transform\n  Measurements Abstract: While spike trains are obviously not band-limited, the theory of\nsuper-resolution tells us that perfect recovery of unknown spike locations and\nweights from low-pass Fourier transform measurements is possible provided that\nthe minimum spacing, $\\Delta$, between spikes is not too small. Specifically,\nfor a measurement cutoff frequency of $f_c$, Donoho [2] showed that exact\nrecovery is possible if the spikes (on $\\mathbb{R}$) lie on a lattice and\n$\\Delta > 1/f_c$, but does not specify a corresponding recovery method.\nCand$\\text{\\`e}$s and Fernandez-Granda [3, 4] provide a convex programming\nmethod for the recovery of periodic spike trains (i.e., spike trains on the\ntorus $\\mathbb{T}$), which succeeds provably if $\\Delta > 2/f_c$ and $f_c \\geq\n128$ or if $\\Delta > 1.26/f_c$ and $f_c \\geq 10^3$, and does not need the\nspikes within the fundamental period to lie on a lattice. In this paper, we\ndevelop a theory of super-resolution from short-time Fourier transform (STFT)\nmeasurements. Specifically, we present a recovery method similar in spirit to\nthe one in [3] for pure Fourier measurements. For a STFT Gaussian window\nfunction of width $\\sigma = 1/(4f_c)$ this method succeeds provably if $\\Delta\n> 1/f_c$, without restrictions on $f_c$. Our theory is based on a\nmeasure-theoretic formulation of the recovery problem, which leads to\nconsiderable generality in the sense of the results being grid-free and\napplying to spike trains on both $\\mathbb{R}$ and $\\mathbb{T}$. The case of\nspike trains on $\\mathbb{R}$ comes with significant technical challenges. For\nrecovery of spike trains on $\\mathbb{T}$ we prove that the correct solution can\nbe approximated---in weak-* topology---by solving a sequence of\nfinite-dimensional convex programming problems. \n\n"}
{"id": "1509.03002", "contents": "Title: The robustness of multiplex networks under layer node-based attack Abstract: From transportation networks to complex infrastructures, and to social and\neconomic networks, a large variety of systems can be described in terms of\nmultiplex networks formed by a set of nodes interacting through different\nnetwork layers. Network robustness, as one of the most successful application\nareas of complex networks, has also attracted great interest in both\ntheoretical and empirical researches. However, the vast majority of existing\nresearches mainly focus on the robustness of single-layer networks an\ninterdependent networks, how multiplex networks respond to potential attack is\nstill short of further exploration. Here we study the robustness of multiplex\nnetworks under two attack strategies: layer node-based random attack and layer\nnode-based targeted attack. A theoretical analysis framework is proposed to\ncalculate the critical threshold and the size of giant component of multiplex\nnetworks when a fraction of layer nodes are removed randomly or intentionally.\nVia numerous simulations, it is unveiled that the theoretical method can\naccurately predict the threshold and the size of giant component, irrespective\nof attack strategies. Moreover, we also compare the robustness of multiplex\nnetworks under multiplex node-based attack and layer node-based attack, and\nfind that layer node-based attack makes multiplex networks more vulnerable,\nregardless of average degree and underlying topology. Our finding may shed new\nlight on the protection of multiplex networks. \n\n"}
{"id": "1509.03503", "contents": "Title: NoSPaM Manual - A Tool for Node-Specific Triad Pattern Mining Abstract: The detection of triadic subgraph motifs is a common methodology in\ncomplex-networks research. The procedure usually applied in order to detect\nmotifs evaluates whether a certain subgraph pattern is overrepresented in a\nnetwork as a whole. However, motifs do not necessarily appear frequently in\nevery region of a graph. For this reason, we recently introduced the framework\nof Node-Specific Pattern Mining (NoSPaM). This work is a manual for an\nimplementation of NoSPaM which can be downloaded from www.mwinkler.eu. \n\n"}
{"id": "1509.03909", "contents": "Title: Information Propagation in Clustered Multilayer Networks Abstract: In today's world, individuals interact with each other in more complicated\npatterns than ever. Some individuals engage through online social networks\n(e.g., Facebook, Twitter), while some communicate only through conventional\nways (e.g., face-to-face). Therefore, understanding the dynamics of information\npropagation among humans calls for a multi-layer network model where an online\nsocial network is conjoined with a physical network. In this work, we initiate\na study of information diffusion in a clustered multi-layer network model,\nwhere all constituent layers are random networks with high clustering. We\nassume that information propagates according to the SIR model and with\ndifferent information transmissibility across the networks. We give results for\nthe conditions, probability, and size of information epidemics, i.e., cases\nwhere information starts from a single individual and reaches a positive\nfraction of the population. We show that increasing the level of clustering in\neither one of the layers increases the epidemic threshold and decreases the\nfinal epidemic size in the whole system. An interesting finding is that\ninformation with low transmissibility spreads more effectively with a small but\ndensely connected social network, whereas highly transmissible information\nspreads better with the help of a large but loosely connected social network. \n\n"}
{"id": "1509.04492", "contents": "Title: Perpetual Codes for Network Coding Abstract: Random Linear Network Coding (RLNC) provides a theoretically efficient method\nfor coding. Some of its practical drawbacks are the complexity of decoding and\nthe overhead due to the coding vectors. For computationally weak and\nbattery-driven platforms, these challenges are particular important. In this\nwork, we consider the coding variant Perpetual codes which are sparse,\nnon-uniform and the coding vectors have a compact representation. The sparsity\nallows for fast encoding and decoding, and the non-uniform protection of\nsymbols enables recoding where the produced symbols are indistinguishable from\nthose encoded at the source. The presented results show that the approach can\nprovide a coding overhead arbitrarily close to that of RLNC, but at reduced\ncomputational load. The achieved gain over RLNC grows with the generation size,\nand both encoding and decoding throughput is approximately one order of\nmagnitude higher compared to RLNC at a generation size of 2048. Additionally,\nthe approach allows for easy adjustment between coding throughput and code\noverhead, which makes it suitable for a broad range of platforms and\napplications. \n\n"}
{"id": "1509.05196", "contents": "Title: A Class of Prediction-Correction Methods for Time-Varying Convex\n  Optimization Abstract: This paper considers unconstrained convex optimization problems with\ntime-varying objective functions. We propose algorithms with a discrete\ntime-sampling scheme to find and track the solution trajectory based on\nprediction and correction steps, while sampling the problem data at a constant\nrate of $1/h$, where $h$ is the length of the sampling interval. The prediction\nstep is derived by analyzing the iso-residual dynamics of the optimality\nconditions. The correction step adjusts for the distance between the current\nprediction and the optimizer at each time step, and consists either of one or\nmultiple gradient steps or Newton steps, which respectively correspond to the\ngradient trajectory tracking (GTT) or Newton trajectory tracking (NTT)\nalgorithms. Under suitable conditions, we establish that the asymptotic error\nincurred by both proposed methods behaves as $O(h^2)$, and in some cases as\n$O(h^4)$, which outperforms the state-of-the-art error bound of $O(h)$ for\ncorrection-only methods in the gradient-correction step. Moreover, when the\ncharacteristics of the objective function variation are not available, we\npropose approximate gradient and Newton tracking algorithms (AGT and ANT,\nrespectively) that still attain these asymptotical error bounds. Numerical\nsimulations demonstrate the practical utility of the proposed methods and that\nthey improve upon existing techniques by several orders of magnitude. \n\n"}
{"id": "1509.05370", "contents": "Title: Bipodal structure in oversaturated random graphs Abstract: We study the asymptotics of large simple graphs constrained by the limiting\ndensity of edges and the limiting subgraph density of an arbitrary fixed graph\n$H$. We prove that, for all but finitely many values of the edge density, if\nthe density of $H$ is constrained to be slightly higher than that for the\ncorresponding Erd\\H{o}s-R\\'enyi graph, the typical large graph is bipodal with\nparameters varying analytically with the densities. Asymptotically, the\nparameters depend only on the degree sequence of $H$. \n\n"}
{"id": "1509.05642", "contents": "Title: Subgraph-based filterbanks for graph signals Abstract: We design a critically-sampled compact-support biorthogonal transform for\ngraph signals, via graph filterbanks. Instead of partitioning the nodes in two\nsets so as to remove one every two nodes in the filterbank downsampling\noperations, the design is based on a partition of the graph in connected\nsubgraphs. Coarsening is achieved by defining one \"supernode\" for each subgraph\nand the edges for this coarsened graph derives from the connectivity between\nthe subgraphs. Unlike the \"one every two nodes\" downsampling on bipartite\ngraphs, this coarsening operation does not have an exact formulation in the\ngraph Fourier domain. Instead, we rely on the local Fourier bases of each\nsubgraph to define filtering operations. We apply successfully this method to\ndecompose graph signals, and show promising performance on compression and\ndenoising. \n\n"}
{"id": "1509.07859", "contents": "Title: Information Limits for Recovering a Hidden Community Abstract: We study the problem of recovering a hidden community of cardinality $K$ from\nan $n \\times n$ symmetric data matrix $A$, where for distinct indices $i,j$,\n$A_{ij} \\sim P$ if $i, j$ both belong to the community and $A_{ij} \\sim Q$\notherwise, for two known probability distributions $P$ and $Q$ depending on\n$n$. If $P={\\rm Bern}(p)$ and $Q={\\rm Bern}(q)$ with $p>q$, it reduces to the\nproblem of finding a densely-connected $K$-subgraph planted in a large\nErd\\\"os-R\\'enyi graph; if $P=\\mathcal{N}(\\mu,1)$ and $Q=\\mathcal{N}(0,1)$ with\n$\\mu>0$, it corresponds to the problem of locating a $K \\times K$ principal\nsubmatrix of elevated means in a large Gaussian random matrix. We focus on two\ntypes of asymptotic recovery guarantees as $n \\to \\infty$: (1) weak recovery:\nexpected number of classification errors is $o(K)$; (2) exact recovery:\nprobability of classifying all indices correctly converges to one. Under mild\nassumptions on $P$ and $Q$, and allowing the community size to scale\nsublinearly with $n$, we derive a set of sufficient conditions and a set of\nnecessary conditions for recovery, which are asymptotically tight with sharp\nconstants. The results hold in particular for the Gaussian case, and for the\ncase of bounded log likelihood ratio, including the Bernoulli case whenever\n$\\frac{p}{q}$ and $\\frac{1-p}{1-q}$ are bounded away from zero and infinity. An\nimportant algorithmic implication is that, whenever exact recovery is\ninformation theoretically possible, any algorithm that provides weak recovery\nwhen the community size is concentrated near $K$ can be upgraded to achieve\nexact recovery in linear additional time by a simple voting procedure. \n\n"}
{"id": "1509.08368", "contents": "Title: Limits of Friendship Networks in Predicting Epidemic Risk Abstract: The spread of an infection on a real-world social network is determined by\nthe interplay of two processes: the dynamics of the network, whose structure\nchanges over time according to the encounters between individuals, and the\ndynamics on the network, whose nodes can infect each other after an encounter.\nPhysical encounter is the most common vehicle for the spread of infectious\ndiseases, but detailed information about encounters is often unavailable\nbecause expensive, unpractical to collect or privacy sensitive. We asks whether\nthe friendship ties between the individuals in a social network successfully\npredict who is at risk. Using a dataset from a popular online review service,\nwe build a time-varying network that is a proxy of physical encounter between\nusers and a static network based on reported friendship. Through computer\nsimulations, we compare infection processes on the resulting networks and show\nthat, whereas distance on the friendship network is correlated to epidemic\nrisk, friendship provides a poor identification of the individuals at risk if\nthe infection is driven by physical encounter. Such limit is not due to the\nrandomness of the infection, but to the structural differences of the two\nnetworks. In contrast to the macroscopic similarity between processes spreading\non different networks, the differences in local connectivity determined by the\ntwo definitions of edges result in striking differences between the dynamics at\na microscopic level. Despite the limits highlighted, we show that periodical\nand relatively infrequent monitoring of the real infection on the encounter\nnetwork allows to correct the predicted infection on the friendship network and\nto achieve satisfactory prediction accuracy. In addition, the friendship\nnetwork contains valuable information to effectively contain epidemic outbreaks\nwhen a limited budget is available for immunization. \n\n"}
{"id": "1510.01429", "contents": "Title: Distance-2 MDS codes and latin colorings in the Doob graphs Abstract: The maximum independent sets in the Doob graphs D(m,n) are analogs of the\ndistance-2 MDS codes in Hamming graphs and of the latin hypercubes. We prove\nthe characterization of these sets stating that every such set is semilinear or\nreducible. As related objects, we study vertex sets with maximum cut (edge\nboundary) in D(m,n) and prove some facts on their structure. We show that the\nconsidered two classes (the maximum independent sets and the maximum-cut sets)\ncan be defined as classes of completely regular sets with specified 2-by-2\nquotient matrices. It is notable that for a set from the considered classes,\nthe eigenvalues of the quotient matrix are the maximum and the minimum\neigenvalues of the graph. For D(m,0), we show the existence of a third,\nintermediate, class of completely regular sets with the same property. \n\n"}
{"id": "1510.04455", "contents": "Title: A unified framework for information integration based on information\n  geometry Abstract: We propose a unified theoretical framework for quantifying spatio-temporal\ninteractions in a stochastic dynamical system based on information geometry. In\nthe proposed framework, the degree of interactions is quantified by the\ndivergence between the actual probability distribution of the system and a\nconstrained probability distribution where the interactions of interest are\ndisconnected. This framework provides novel geometric interpretations of\nvarious information theoretic measures of interactions, such as mutual\ninformation, transfer entropy, and stochastic interaction in terms of how\ninteractions are disconnected. The framework therefore provides an intuitive\nunderstanding of the relationships between the various quantities. By extending\nthe concept of transfer entropy, we propose a novel measure of integrated\ninformation which measures causal interactions between parts of a system.\nIntegrated information quantifies the extent to which the whole is more than\nthe sum of the parts and can be potentially used as a biological measure of the\nlevels of consciousness. \n\n"}
{"id": "1510.04728", "contents": "Title: Row Reduction Applied to Decoding of Rank Metric and Subspace Codes Abstract: We show that decoding of $\\ell$-Interleaved Gabidulin codes, as well as\nlist-$\\ell$ decoding of Mahdavifar--Vardy codes can be performed by row\nreducing skew polynomial matrices. Inspired by row reduction of $\\F[x]$\nmatrices, we develop a general and flexible approach of transforming matrices\nover skew polynomial rings into a certain reduced form. We apply this to solve\ngeneralised shift register problems over skew polynomial rings which occur in\ndecoding $\\ell$-Interleaved Gabidulin codes. We obtain an algorithm with\ncomplexity $O(\\ell \\mu^2)$ where $\\mu$ measures the size of the input problem\nand is proportional to the code length $n$ in the case of decoding. Further, we\nshow how to perform the interpolation step of list-$\\ell$-decoding\nMahdavifar--Vardy codes in complexity $O(\\ell n^2)$, where $n$ is the number of\ninterpolation constraints. \n\n"}
{"id": "1510.05784", "contents": "Title: Structured Projection-Based Model Reduction with Application to\n  Stochastic Biochemical Networks Abstract: The Chemical Master Equation (CME) is well known to provide the highest\nresolution models of a biochemical reaction network. Unfortunately, even\nsimulating the CME can be a challenging task. For this reason more simple\napproximations to the CME have been proposed. In this work we focus on one such\nmodel, the Linear Noise Approximation. Specifically, we consider implications\nof a recently proposed LNA time-scale separation method. We show that the\nreduced order LNA converges to the full order model in the mean square sense.\nUsing this as motivation we derive a network structure preserving reduction\nalgorithm based on structured projections. We present convex optimisation\nalgorithms that describe how such projections can be computed and we discuss\nwhen structured solutions exits. We also show that for a certain class of\nsystems, structured projections can be found using basic linear algebra and no\noptimisation is necessary. The algorithms are then applied to a linearised\nstochastic LNA model of the yeast glycolysis pathway. \n\n"}
{"id": "1510.05862", "contents": "Title: Chaotic, informational and synchronous behaviour of multiplex networks Abstract: The understanding of the relationship between topology and behaviour in\ninterconnected networks would allow to characterise and predict behaviour in\nmany real complex networks since both are usually not simultaneously known.\nMost previous studies have focused on the relationship between topology and\nsynchronisation. In this work, we provide analytical formulas that shows how\ntopology drives complex behaviour: chaos, information, and weak or strong\nsynchronisation; in multiplex networks with constant Jacobian. We also study\nthis relationship numerically in multiplex networks of Hindmarsh-Rose neurons.\nWhereas behaviour in the analytically tractable network is a direct but not\ntrivial consequence of the spectra of eigenvalues of the Laplacian matrix,\nwhere behaviour may strongly depend on the break of symmetry in the topology of\ninterconnections, in Hindmarsh-Rose neural networks the nonlinear nature of the\nchemical synapses breaks the elegant mathematical connection between the\nspectra of eigenvalues of the Laplacian matrix and the behaviour of the\nnetwork, creating networks whose behaviour strongly depends on the nature\n(chemical or electrical) of the inter synapses. \n\n"}
{"id": "1510.06095", "contents": "Title: Optimality of Large MIMO Detection via Approximate Message Passing Abstract: Optimal data detection in multiple-input multiple-output (MIMO) communication\nsystems with a large number of antennas at both ends of the wireless link\nentails prohibitive computational complexity. In order to reduce the\ncomputational complexity, a variety of sub-optimal detection algorithms have\nbeen proposed in the literature. In this paper, we analyze the optimality of a\nnovel data-detection method for large MIMO systems that relies on approximate\nmessage passing (AMP). We show that our algorithm, referred to as\nindividually-optimal (IO) large-MIMO AMP (short IO-LAMA), is able to perform IO\ndata detection given certain conditions on the MIMO system and the\nconstellation set (e.g., QAM or PSK) are met. \n\n"}
{"id": "1510.07461", "contents": "Title: Results on the solutions of maximum weighted Renyi entropy problems Abstract: In this paper, following standard arguments, the maximum Renyi entropy\nproblem for the weighted case is analyzed. We verify that under some constrains\non weight function, the Student-r and Student-t distributions maximize the\nweighted Renyi entropy. Furthermore, an extended version of the Hadamard\ninequality is derived. \n\n"}
{"id": "1510.08999", "contents": "Title: Mean Square Stabilization of Vector LTI Systems over Power Constrained\n  Lossy Channels Abstract: This paper studies the mean square stabilization problem of vector LTI\nsystems over power constrained lossy channels. The communication channel is\nwith packet dropouts, additive noises and input power constraints. To overcome\nthe difficulty of optimally allocating channel resources among different\nsub-dynamics, schedulers are designed with time division multiplexing of\nchannels. An adaptive TDMA (Time Division Multiple Access) scheduler is\nproposed first, which is shown to be able to achieve a larger stabilizability\nregion than the conventional TDMA scheduler, and is optimal under some special\ncases. In particular, for two-dimensional systems, an optimal scheduler is\ndesigned, which provides the necessary and sufficient condition for mean square\nstabilization. \n\n"}
{"id": "1511.00856", "contents": "Title: Designing dedicated data compression for physics experiments within FPGA\n  already used for data acquisition Abstract: Physics experiments produce enormous amount of raw data, counted in petabytes\nper day. Hence, there is large effort to reduce this amount, mainly by using\nsome filters. The situation can be improved by additionally applying some data\ncompression techniques: removing redundancy and optimally encoding the actual\ninformation. Preferably, both filtering and data compression should fit in FPGA\nalready used for data acquisition - reducing requirements of both data storage\nand networking architecture.\n  We will briefly explain and discuss some basic techniques, for a better focus\napplied to design a dedicated data compression system basing on a sample data\nfrom a prototype of a tracking detector: 10000 events for 48 channels. We will\nfocus on the time data here, which after neglecting the headers and applying\ndata filtering, requires on average 1170 bits/event using the current coding.\nEncoding relative times (differences) and grouping data by channels, reduces\nthis number to 798 bits/channel, still using fixed length coding: a fixed\nnumber of bits used for a given value. Using variable length Huffman coding to\nencode numbers of digital pulses for a channel and the most significant bits of\nvalues (simple binning) reduces further this number to 552 bits/event. Using\nadaptive binning: denser for frequent values, and an accurate entropy coder we\nget further down to 455 bits/event - this option can easily fit unused\nresources of FPGA currently used for data acquisition. Finally, using separate\nprobability distributions for different channels, what could be done by a\nsoftware compressor, leads to 437bits/event, what is 2.67 times less than the\noriginal 1170 bits/event. \n\n"}
{"id": "1511.01017", "contents": "Title: Consistent Parameter Estimation for LASSO and Approximate Message\n  Passing Abstract: We consider the problem of recovering a vector $\\beta_o \\in \\mathbb{R}^p$\nfrom $n$ random and noisy linear observations $y= X\\beta_o + w$, where $X$ is\nthe measurement matrix and $w$ is noise. The LASSO estimate is given by the\nsolution to the optimization problem $\\hat{\\beta}_{\\lambda} = \\arg \\min_{\\beta}\n\\frac{1}{2} \\|y-X\\beta\\|_2^2 + \\lambda \\| \\beta \\|_1$. Among the iterative\nalgorithms that have been proposed for solving this optimization problem,\napproximate message passing (AMP) has attracted attention for its fast\nconvergence. Despite significant progress in the theoretical analysis of the\nestimates of LASSO and AMP, little is known about their behavior as a function\nof the regularization parameter $\\lambda$, or the thereshold parameters\n$\\tau^t$. For instance the following basic questions have not yet been studied\nin the literature: (i) How does the size of the active set\n$\\|\\hat{\\beta}^\\lambda\\|_0/p$ behave as a function of $\\lambda$? (ii) How does\nthe mean square error $\\|\\hat{\\beta}_{\\lambda} - \\beta_o\\|_2^2/p$ behave as a\nfunction of $\\lambda$? (iii) How does $\\|\\beta^t - \\beta_o \\|_2^2/p$ behave as\na function of $\\tau^1, \\ldots, \\tau^{t-1}$? Answering these questions will help\nin addressing practical challenges regarding the optimal tuning of $\\lambda$ or\n$\\tau^1, \\tau^2, \\ldots$. This paper answers these questions in the asymptotic\nsetting and shows how these results can be employed in deriving simple and\ntheoretically optimal approaches for tuning the parameters $\\tau^1, \\ldots,\n\\tau^t$ for AMP or $\\lambda$ for LASSO. It also explores the connection between\nthe optimal tuning of the parameters of AMP and the optimal tuning of LASSO. \n\n"}
{"id": "1511.01969", "contents": "Title: Energy Efficient Resource Allocation for Control Data Separation\n  Architecture based H-CRAN with Heterogeneous Fronthaul Abstract: Control data separation architecture (CDSA) is a more efficient architecture\nto overcome the overhead issue than the conventional cellular networks,\nespecially for the huge bursty traffic like Internet of Things, and\nover-the-top (OTT) content service. In this paper, we study the optimization\nissue of network energy efficiency of the CDSA-based heterogeneous cloud radio\naccess networks (H-CRAN) networks, which has heterogeneous fronthaul between\ncontrol base station (CBS) and data base stations (DBSs). We first present a\nmodified power consumption model for the CDSA-based H-CRAN, and then formulate\nthe optimization problem with constraint of overall capacity of wireless\nfronthaul. We work out the resource assignment and power allocation by the\nconvex relaxation approach Using fractional programming method and Lagrangian\ndual decomposition method, we derive the close-form optimal solution and verify\nit by comprehensive system-level simulation. The simulation results show that\nour proposed algorithm has 8% EE gain compared to the static algorithm, and the\nCDSA-based H-CRAN networks can achieve up to 16% EE gain compared to the\nconventional network even under strict fronthaul capacity limit. \n\n"}
{"id": "1511.02562", "contents": "Title: Modeling the Interplay Between Individual Behavior and Network\n  Distributions Abstract: It is well-known that many networks follow a power-law degree distribution;\nhowever, the factors that influence the formation of their distributions are\nstill unclear. How can one model the connection between individual actions and\nnetwork distributions? How can one explain the formation of group phenomena and\ntheir evolutionary patterns?\n  In this paper, we propose a unified framework, M3D, to model human dynamics\nin social networks from three perspectives: macro, meso, and micro. At the\nmicro-level, we seek to capture the way in which an individual user decides\nwhether to perform an action. At the meso-level, we study how group behavior\ndevelops and evolves over time, based on individual actions. At the\nmacro-level, we try to understand how network distributions such as power-law\n(or heavy-tailed phenomena) can be explained by group behavior. We provide\ntheoretical analysis for the proposed framework, and discuss the connection of\nour framework with existing work.\n  The framework offers a new, flexible way to explain the interplay between\nindividual user actions and network distributions, and can benefit many\napplications. To model heavy-tailed distributions from partially observed\nindividual actions and to predict the formation of group behaviors, we apply\nM3D to three different genres of networks: Tencent Weibo, Citation, and Flickr.\nWe also use information-burst prediction as a particular application to\nquantitatively evaluate the predictive power of the proposed framework. Our\nresults on the Weibo indicate that M3D's prediction performance exceeds that of\nseveral alternative methods by up to 30\\%. \n\n"}
{"id": "1511.06729", "contents": "Title: Simple and efficient self-healing strategy for damaged complex networks Abstract: The process of destroying a complex network through node removal has been the\nsubject of extensive interest and research. Node loss typically leaves the\nnetwork disintegrated into many small and isolated clusters. Here we show that\nthese clusters typically remain close to each other and we suggest a simple\nalgorithm that is able to reverse the inflicted damage by restoring the\nnetwork's functionality. After damage, each node decides independently whether\nto create a new link depending on the fraction of neighbors it has lost. In\naddition to relying only on local information, where nodes do not need\nknowledge of the global network status, we impose the additional constraint\nthat new links should be as short as possible (i.e. that the new edge completes\na shortest possible new cycle). We demonstrate that this self-healing method\noperates very efficiently, both in model and real networks. For example, after\nremoving the most connected airports in USA, the self-healing algorithm\nre-joined almost 90\\% of the surviving airports. \n\n"}
{"id": "1511.06858", "contents": "Title: Applying Social Media Intelligence for Predicting and Identifying\n  On-line Radicalization and Civil Unrest Oriented Threats Abstract: Research shows that various social media platforms on Internet such as\nTwitter, Tumblr (micro-blogging websites), Facebook (a popular social\nnetworking website), YouTube (largest video sharing and hosting website), Blogs\nand discussion forums are being misused by extremist groups for spreading their\nbeliefs and ideologies, promoting radicalization, recruiting members and\ncreating online virtual communities sharing a common agenda. Popular\nmicroblogging websites such as Twitter are being used as a real-time platform\nfor information sharing and communication during planning and mobilization if\ncivil unrest related events. Applying social media intelligence for predicting\nand identifying online radicalization and civil unrest oriented threats is an\narea that has attracted several researchers' attention over past 10 years.\nThere are several algorithms, techniques and tools that have been proposed in\nexisting literature to counter and combat cyber-extremism and predicting\nprotest related events in much advance. In this paper, we conduct a literature\nreview of all these existing techniques and do a comprehensive analysis to\nunderstand state-of-the-art, trends and research gaps. We present a one class\nclassification approach to collect scholarly articles targeting the topics and\nsubtopics of our research scope. We perform characterization, classification\nand an in-depth meta analysis meta-anlaysis of about 100 conference and journal\npapers to gain a better understanding of existing literature. \n\n"}
{"id": "1511.07549", "contents": "Title: Using tropical optimization to solve constrained minimax single-facility\n  location problems with rectilinear distance Abstract: The aim of this paper is twofold: first, to extend the area of applications\nof tropical optimization by solving new constrained location problems, and\nsecond, to offer new closed-form solutions to general problems that are of\ninterest to location analysis. We consider a constrained minimax\nsingle-facility location problem with addends on the plane with rectilinear\ndistance. The solution commences with the representation of the problem in a\nstandard form, and then in terms of tropical mathematics, as a constrained\noptimization problem. We use a transformation technique, which can act as a\ntemplate to handle optimization problems in other application areas, and hence\nis of independent interest. To solve the constrained optimization problem, we\napply methods and results of tropical optimization, which provide direct,\nexplicit solutions. The results obtained serve to derive new solutions of the\nlocation problem, and of its special cases with reduced sets of constraints, in\na closed form, ready for practical implementation and immediate computation. As\nillustrations, numerical solutions of example problems and their graphical\nrepresentation are given. We conclude with an application of the results to\noptimal location of the central monitoring facility in an indoor video\nsurveillance system in a multi-floor building environment. \n\n"}
{"id": "1512.00156", "contents": "Title: Covariance-domain Dictionary Learning for Overcomplete EEG Source\n  Identification Abstract: We propose an algorithm targeting the identification of more sources than\nchannels for electroencephalography (EEG). Our overcomplete source\nidentification algorithm, Cov-DL, leverages dictionary learning methods applied\nin the covariance-domain. Assuming that EEG sources are uncorrelated within\nmoving time-windows and the scalp mixing is linear, the forward problem can be\ntransferred to the covariance domain which has higher dimensionality than the\noriginal EEG channel domain. This allows for learning the overcomplete mixing\nmatrix that generates the scalp EEG even when there may be more sources than\nsensors active at any time segment, i.e. when there are non-sparse sources.\nThis is contrary to straight-forward dictionary learning methods that are based\non the assumption of sparsity, which is not a satisfied condition in the case\nof low-density EEG systems. We present two different learning strategies for\nCov-DL, determined by the size of the target mixing matrix. We demonstrate that\nCov-DL outperforms existing overcomplete ICA algorithms under various scenarios\nof EEG simulations and real EEG experiments. \n\n"}
{"id": "1512.00894", "contents": "Title: Untangling Performance from Success Abstract: Fame, popularity and celebrity status, frequently used tokens of success, are\noften loosely related to, or even divorced from professional performance. This\ndichotomy is partly rooted in the difficulty to distinguish performance, an\nindividual measure that captures the actions of a performer, from success, a\ncollective measure that captures a community's reactions to these actions. Yet,\nfinding the relationship between the two measures is essential for all areas\nthat aim to objectively reward excellence, from science to business. Here we\nquantify the relationship between performance and success by focusing on\ntennis, an individual sport where the two quantities can be independently\nmeasured. We show that a predictive model, relying only on a tennis player's\nperformance in tournaments, can accurately predict an athlete's popularity,\nboth during a player's active years and after retirement. Hence the model\nestablishes a direct link between performance and momentary popularity. The\nagreement between the performance-driven and observed popularity suggests that\nin most areas of human achievement exceptional visibility may be rooted in\ndetectable performance measures. \n\n"}
{"id": "1512.01764", "contents": "Title: Fast Algorithms for Game-Theoretic Centrality Measures Abstract: In this dissertation, we analyze the computational properties of\ngame-theoretic centrality measures. The key idea behind game-theoretic approach\nto network analysis is to treat nodes as players in a cooperative game, where\nthe value of each coalition of nodes is determined by certain graph properties.\nNext, the centrality of any individual node is determined by a chosen\ngame-theoretic solution concept (notably, the Shapley value) in the same way as\nthe payoff of a player in a cooperative game. On one hand, the advantage of\ngame-theoretic centrality measures is that nodes are ranked not only according\nto their individual roles but also according to how they contribute to the role\nplayed by all possible subsets of nodes. On the other hand, the disadvantage is\nthat the game-theoretic solution concepts are typically computationally\nchallenging. The main contribution of this dissertation is that we show that a\nwide variety of game-theoretic solution concepts on networks can be computed in\npolynomial time. Our focus is on centralities based on the Shapley value and\nits various extensions, such as the Semivalues and Coalitional Semivalues.\nFurthermore, we prove #P-hardness of computing the Shapley value in\nconnectivity games and propose an algorithm to compute it. Finally, we analyse\ncomputational properties of generalized version of cooperative games in which\norder of player matters. We propose a new representation for such games, called\ngeneralized marginal contribution networks, that allows for polynomial\ncomputation in the size of the representation of two dedicated extensions of\nthe Shapley value to this class of games. \n\n"}
{"id": "1512.04987", "contents": "Title: On the Network Topology Dependent Solution Count of the Algebraic Load\n  Flow Equations Abstract: A large amount of research activity in power systems areas has focused on\ndeveloping computational methods to solve load flow equations where a key\nquestion is the maximum number of isolated solutions.Though several concrete\nupper bounds exist, recent studies have hinted that much sharper upper bounds\nthat depend the topology of underlying power networks may exist. This paper\nestablishes such a topology dependent solution bound which is actually the best\npossible bound in the sense that it is always attainable. We also develop a\ngeometric construction called adjacency polytope which accurately captures the\ntopology of the underlying power network and is immensely useful in the\ncomputation of the solution bound. Finally we highlight the significant\nimplications of the development of such solution bound in solving load flow\nequations. \n\n"}
{"id": "1512.06348", "contents": "Title: Link prediction based on path entropy Abstract: Information theory has been taken as a prospective tool for quantifying the\ncomplexity of complex networks. In this paper, we first study the information\nentropy or uncertainty of a path using the information theory. Then we apply\nthe path entropy to the link prediction problem in real-world networks.\nSpecifically, we propose a new similarity index, namely Path Entropy (PE)\nindex, which considers the information entropies of shortest paths between node\npairs with penalization to long paths. Empirical experiments demonstrate that\nPE index outperforms the mainstream link predictors. \n\n"}
{"id": "1512.06457", "contents": "Title: Classification of weighted networks through mesoscale homological\n  features Abstract: As complex networks find applications in a growing range of disciplines, the\ndiversity of naturally occurring and model networks being studied is exploding.\nThe adoption of a well-developed collection of network taxonomies is a natural\nmethod for both organizing this data and understanding deeper relationships\nbetween networks. Most existing metrics for network structure rely on classical\ngraph-theoretic measures, extracting characteristics primarily related to\nindividual vertices or paths between them, and thus classify networks from the\nperspective of local features. Here, we describe an alternative approach to\nstudying structure in networks that relies on an algebraic-topological metric\ncalled persistent homology, which studies intrinsically mesoscale structures\ncalled cycles, constructed from cliques in the network. We present a\nclassification of 14 commonly studied weighted network models into four groups\nor classes, and discuss the structural themes arising in each class. Finally,\nwe compute the persistent homology of two real-world networks and one network\nconstructed by a common dynamical systems model, and we compare the results\nwith the three classes to obtain a better understanding of those networks. \n\n"}
{"id": "1512.07347", "contents": "Title: Galois Self-Dual Constacyclic Codes Abstract: Generalizing Euclidean inner product and Hermitian inner product, we\nintroduce Galois inner products, and study the Galois self-dual constacyclic\ncodes in a very general setting by a uniform method. The conditions for\nexistence of Galois self-dual and isometrically Galois self-dual constacyclic\ncodes are obtained. As consequences, the results on self-dual, iso-dual and\nHermitian self-dual constacyclic codes are derived. \n\n"}
{"id": "1512.08949", "contents": "Title: Simple, Robust and Optimal Ranking from Pairwise Comparisons Abstract: We consider data in the form of pairwise comparisons of n items, with the\ngoal of precisely identifying the top k items for some value of k < n, or\nalternatively, recovering a ranking of all the items. We analyze the Copeland\ncounting algorithm that ranks the items in order of the number of pairwise\ncomparisons won, and show it has three attractive features: (a) its\ncomputational efficiency leads to speed-ups of several orders of magnitude in\ncomputation time as compared to prior work; (b) it is robust in that\ntheoretical guarantees impose no conditions on the underlying matrix of\npairwise-comparison probabilities, in contrast to some prior work that applies\nonly to the BTL parametric model; and (c) it is an optimal method up to\nconstant factors, meaning that it achieves the information-theoretic limits for\nrecovering the top k-subset. We extend our results to obtain sharp guarantees\nfor approximate recovery under the Hamming distortion metric, and more\ngenerally, to any arbitrary error requirement that satisfies a simple and\nnatural monotonicity condition. \n\n"}
{"id": "1601.00246", "contents": "Title: Hierarchical-distributed optimized coordination of intersection traffic Abstract: This paper considers the problem of coordinating the vehicular traffic at an\nintersection and on the branches leading to it for minimizing a combination of\ntotal travel time and energy consumption. We propose a provably safe\nhierarchical-distributed solution to balance computational complexity and\noptimality of the system operation. In our design, a central intersection\nmanager communicates with vehicles heading towards the intersection, groups\nthem into clusters (termed bubbles) as they appear, and determines an optimal\nschedule of passage through the intersection for each bubble. The vehicles in\neach bubble receive their schedule and implement local distributed control to\nensure system-wide inter-vehicular safety while respecting speed and\nacceleration limits, conforming to the assigned schedule, and seeking to\noptimize their individual trajectories. Our analysis rigorously establishes\nthat the different aspects of the hierarchical design operate in concert and\nthat the safety guarantees provided by the proposed design are satisfied. We\nillustrate its execution in a suite of simulations and compare its performance\nto traditional signal-based coordination over a wide range of system\nparameters. \n\n"}
{"id": "1601.00549", "contents": "Title: A Novel Family of Boosted Online Regression Algorithms with Strong\n  Theoretical Bounds Abstract: We investigate boosted online regression and propose a novel family of\nregression algorithms with strong theoretical bounds. In addition, we implement\nseveral variants of the proposed generic algorithm. We specifically provide\ntheoretical bounds for the performance of our proposed algorithms that hold in\na strong mathematical sense. We achieve guaranteed performance improvement over\nthe conventional online regression methods without any statistical assumptions\non the desired data or feature vectors. We demonstrate an intrinsic\nrelationship, in terms of boosting, between the adaptive mixture-of-experts and\ndata reuse algorithms. Furthermore, we introduce a boosting algorithm based on\nrandom updates that is significantly faster than the conventional boosting\nmethods and other variants of our proposed algorithms while achieving an\nenhanced performance gain. Hence, the random updates method is specifically\napplicable to the fast and high dimensional streaming data. Specifically, we\ninvestigate Newton Method-based and Stochastic Gradient Descent-based linear\nregression algorithms in a mixture-of-experts setting and provide several\nvariants of these well-known adaptation methods. However, the proposed\nalgorithms can be extended to other base learners, e.g., nonlinear, tree-based\npiecewise linear. Furthermore, we provide theoretical bounds for the\ncomputational complexity of our proposed algorithms. We demonstrate substantial\nperformance gains in terms of mean square error over the base learners through\nan extensive set of benchmark real data sets and simulated examples. \n\n"}
{"id": "1601.01363", "contents": "Title: Convergence Analysis of the Gaussian Regularized Shannon Sampling\n  Formula Abstract: We consider the reconstruction of a bandlimited function from its finite\nlocalized sample data. Truncating the classical Shannon sampling series results\nin an unsatisfactory convergence rate due to the slow decayness of the sinc\nfunction. To overcome this drawback, a simple and highly effective method,\ncalled the Gaussian regularization of the Shannon series, was proposed in the\nengineering and has received remarkable attention. It works by multiplying the\nsinc function in the Shannon series with a regularized Gaussian function. L.\nQian (Proc. Amer. Math. Soc., 2003) established the convergence rate of\n$O(\\sqrt{n}\\exp(-\\frac{\\pi-\\delta}2n))$ for this method, where $\\delta<\\pi$ is\nthe bandwidth and $n$ is the number of sample data. C. Micchelli {\\it et al.}\n(J. Complexity, 2009) proposed a different regularized method and obtained the\ncorresponding convergence rate of\n$O(\\frac1{\\sqrt{n}}\\exp(-\\frac{\\pi-\\delta}2n))$. This latter rate is by far the\nbest among all regularized methods for the Shannon series. However, their\nregularized method involves the solving of a linear system and is implicit and\nmore complicated. The main objective of this note is to show that the Gaussian\nregularization of the Shannon series can also achieve the same best convergence\nrate as that by C. Micchelli {\\it et al}. We also show that the Gaussian\nregularization method can improve the convergence rate for the useful average\nsampling. Finally, the outstanding performance of numerical experiments\njustifies our results. \n\n"}
{"id": "1601.02284", "contents": "Title: Update or Wait: How to Keep Your Data Fresh Abstract: In this work, we study how to optimally manage the freshness of information\nupdates sent from a source node to a destination via a channel. A proper metric\nfor data freshness at the destination is the age-of-information, or simply age,\nwhich is defined as how old the freshest received update is since the moment\nthat this update was generated at the source node (e.g., a sensor). A\nreasonable update policy is the zero-wait policy, i.e., the source node submits\na fresh update once the previous update is delivered and the channel becomes\nfree, which achieves the maximum throughput and the minimum delay.\nSurprisingly, this zero-wait policy does not always minimize the age. This\ncounter-intuitive phenomenon motivates us to study how to optimally control\ninformation updates to keep the data fresh and to understand when the zero-wait\npolicy is optimal. We introduce a general age penalty function to characterize\nthe level of dissatisfaction on data staleness and formulate the average age\npenalty minimization problem as a constrained semi-Markov decision problem\n(SMDP) with an uncountable state space. We develop efficient algorithms to find\nthe optimal update policy among all causal policies, and establish sufficient\nand necessary conditions for the optimality of the zero-wait policy. Our\ninvestigation shows that the zero-wait policy is far from the optimum if (i)\nthe age penalty function grows quickly with respect to the age, (ii) the packet\ntransmission times over the channel are positively correlated over time, or\n(iii) the packet transmission times are highly random (e.g., following a\nheavy-tail distribution). \n\n"}
{"id": "1601.02904", "contents": "Title: Social Network Extraction: Superficial Method and Information Retrieval Abstract: Social network has become one of the themes of government issues, mainly\ndealing with the chaos. The use of web is steadily gaining ground in these\nissues. However, most of the web documents are unstructured and lack of\nsemantic. In this paper we proposed an Information Retrieval driven method for\ndealing with heterogeneity of features in the web. The proposed solution is to\ncompare some approaches have shown the capacity to extract social relation:\nstrength relations and relations based on online academic database. \n\n"}
{"id": "1601.03290", "contents": "Title: Coordination of Multi-Agent Systems under Switching Topologies via\n  Disturbance Observer Based Approach Abstract: In this paper, a leader-following coordination problem of heterogeneous\nmulti-agent systems is considered under switching topologies where each agent\nis subject to some local (unbounded) disturbances. While these unknown\ndisturbances may disrupt the performance of agents, a disturbance observer\nbased approach is employed to estimate and reject them. Varying communication\ntopologies are also taken into consideration, and their byproduct difficulties\nare overcome by using common Lyapunov function techniques. According to the\navailable information in difference cases, two disturbance observer based\nprotocols are proposed to solve this problem. Their effectiveness is verified\nby simulations. \n\n"}
{"id": "1601.04071", "contents": "Title: Hidden geometric correlations in real multiplex networks Abstract: Real networks often form interacting parts of larger and more complex\nsystems. Examples can be found in different domains, ranging from the Internet\nto structural and functional brain networks. Here, we show that these multiplex\nsystems are not random combinations of single network layers. Instead, they are\norganized in specific ways dictated by hidden geometric correlations between\nthe individual layers. We find that these correlations are strong in different\nreal multiplexes, and form a key framework for answering many important\nquestions. Specifically, we show that these geometric correlations facilitate:\n(i) the definition and detection of multidimensional communities, which are\nsets of nodes that are simultaneously similar in multiple layers; (ii) accurate\ntrans-layer link prediction, where connections in one layer can be predicted by\nobserving the hidden geometric space of another layer; and (iii) efficient\ntargeted navigation in the multilayer system using only local knowledge, which\noutperforms navigation in the single layers only if the geometric correlations\nare sufficiently strong. Our findings uncover fundamental organizing principles\nbehind real multiplexes and can have important applications in diverse domains. \n\n"}
{"id": "1601.04884", "contents": "Title: Z2-Triple cyclic codes and their duals Abstract: A Z2-triple cyclic code of block length (r,s,t) is a binary code of length\nr+s+t such that the code is partitioned into three parts of lengthsr,s andt\nsuch that each of the three parts is invariant under the cyclic shifts of the\ncoordinates. Such a code can be viewed as Z2[x]-submodules of\nZ_2[x]/<x^r-1>xZ_2[x]/<x^s-1>xZ_2[x]/<x^t-1>, in polynomial representation. In\nthis paper, we determine the structure of these codes. We have obtained the\nform of the generators for such codes. Further, a minimal generating set for\nsuch a code is obtained. Also, we study the structure of the duals of these\ncodes via the generators of the codes. \n\n"}
{"id": "1601.05516", "contents": "Title: A Deterministic Algorithm for Pliable Index Coding Abstract: Pliable index coding considers a server with m messages, and n clients where\neach has as side information a subset of the messages. We seek to minimize the\nnumber of transmissions the server should make, so that each client receives\n(any) one message she does not already have. Previous work has shown that the\nserver can achieve this using O(\\log^2(n)) transmissions and needs at least\n\\Omega(log(n)) transmissions in the worst case, but finding a code of optimal\nlength is NP-hard. In this paper, we propose a deterministic algorithm that we\nprove achieves this upper bound, that is, in an order almost as the worst-case\noptimal code length. We also establish a connection between the pliable index\ncoding problem and the minrank problem over a family of mixed matrices. \n\n"}
{"id": "1601.05563", "contents": "Title: Unconstrained distillation capacities of a pure-loss bosonic broadcast\n  channel Abstract: Bosonic channels are important in practice as they form a simple model for\nfree-space or fiber-optic communication. Here we consider a single-sender\ntwo-receiver pure-loss bosonic broadcast channel and determine the\nunconstrained capacity region for the distillation of bipartite entanglement\nand secret key between the sender and each receiver, whenever they are allowed\narbitrary public classical communication. We show how the state merging\nprotocol leads to achievable rates in this setting, giving an inner bound on\nthe capacity region. We also evaluate an outer bound on the region by using the\nrelative entropy of entanglement and a `reduction by teleportation' technique.\nThe outer bounds match the inner bounds in the infinite-energy limit, thereby\nestablishing the unconstrained capacity region for such channels. Our result\ncould provide a useful benchmark for implementing a broadcasting of\nentanglement and secret key through such channels. An important open question\nrelevant to practice is to determine the capacity region in both this setting\nand the single-sender single-receiver case when there is an energy constraint\non the transmitter. \n\n"}
{"id": "1601.05873", "contents": "Title: Asymptotic Optimality of Massive MIMO Systems Using Densely Spaced\n  Transmit Antennas Abstract: This paper investigates the performance of a massive multiple-input\nmultiple-output (MIMO) system that uses a large transmit antenna array with\nantenna elements spaced densely. Under the assumption of idealized uniform\nlinear antenna arrays without mutual coupling, precoded quadrature phase-shift\nkeying (QPSK) transmission is proved to achieve the channel capacity of the\nmassive MIMO system when the transmit antenna separation tends to zero. This\nasymptotic optimality is analogous to that of QPSK faster-than-Nyquist\nsignaling. \n\n"}
{"id": "1601.06035", "contents": "Title: Recommender systems inspired by the structure of quantum theory Abstract: Physicists use quantum models to describe the behavior of physical systems.\nQuantum models owe their success to their interpretability, to their relation\nto probabilistic models (quantization of classical models) and to their high\npredictive power. Beyond physics, these properties are valuable in general data\nscience. This motivates the use of quantum models to analyze general\nnonphysical datasets. Here we provide both empirical and theoretical insights\ninto the application of quantum models in data science. In the theoretical part\nof this paper, we firstly show that quantum models can be exponentially more\nefficient than probabilistic models because there exist datasets that admit\nlow-dimensional quantum models and only exponentially high-dimensional\nprobabilistic models. Secondly, we explain in what sense quantum models realize\na useful relaxation of compressed probabilistic models. Thirdly, we show that\nsparse datasets admit low-dimensional quantum models and finally, we introduce\na method to compute hierarchical orderings of properties of users (e.g.,\npersonality traits) and items (e.g., genres of movies). In the empirical part\nof the paper, we evaluate quantum models in item recommendation and observe\nthat the predictive power of quantum-inspired recommender systems can compete\nwith state-of-the-art recommender systems like SVD++ and PureSVD. Furthermore,\nwe make use of the interpretability of quantum models by computing hierarchical\norderings of properties of users and items. This work establishes a connection\nbetween data science (item recommendation), information theory (communication\ncomplexity), mathematical programming (positive semidefinite factorizations)\nand physics (quantum models). \n\n"}
{"id": "1601.06422", "contents": "Title: An overview of low-rank matrix recovery from incomplete observations Abstract: Low-rank matrices play a fundamental role in modeling and computational\nmethods for signal processing and machine learning. In many applications where\nlow-rank matrices arise, these matrices cannot be fully sampled or directly\nobserved, and one encounters the problem of recovering the matrix given only\nincomplete and indirect observations. This paper provides an overview of modern\ntechniques for exploiting low-rank structure to perform matrix recovery in\nthese settings, providing a survey of recent advances in this\nrapidly-developing field. Specific attention is paid to the algorithms most\ncommonly used in practice, the existing theoretical guarantees for these\nalgorithms, and representative practical applications of these techniques. \n\n"}
{"id": "1602.02390", "contents": "Title: Lower Bounds for Interactive Function Computation via Wyner Common\n  Information Abstract: The question of how much communication is required between collaborating\nparties to compute a function of their data is of fundamental importance in the\nfields of theoretical computer science and information theory. In this work,\nthe focus is on coming up with lower bounds on this. The information cost of a\nprotocol is the amount of information the protocol reveals to Alice and Bob\nabout each others inputs, and the information complexity of a function is the\ninfimum of information costs over all valid protocols. For the amortized case,\nit is known that the optimal rate for the computation is equal to the\ninformation complexity. Exactly computing this information complexity is not\nstraight forward however. In this work we lower bound information complexity\nfor independent inputs in terms of the Wyner common information of a certain\npair of random variables. We show a structural property for the optimal\nauxiliary random variable of Wyner common information and exploit this to\nexactly compute the Wyner common information in certain cases. The lower bound\nobtained through this technique is shown to be tight for a non-trivial example\n- equality (EQ) for the ternary alphabet. We also give an example to show that\nthe lower bound may, in general, not be tight. \n\n"}
{"id": "1602.03508", "contents": "Title: Energy Management in Heterogeneous Networks with Cell Activation, User\n  Association and Interference Coordination Abstract: The densification and expansion of wireless network pose new challenges on\ninterference management and reducing energy consumption. This paper studies\nenergy-efficient resource management in heterogeneous networks by jointly\noptimizing cell activation, user association and multicell multiuser channel\nassignment, according to the long-term average traffic and channel conditions.\nThe proposed framework is built on characterizing the interference coupling by\npre-defined interference patterns, and performing resource allocation among\nthese patterns. In this way, the interference fluctuation caused by\n(de)activating cells is explicitly taken into account when calculating the user\nachievable rates. A tailored algorithm is developed to solve the formulated\nproblem in the dual domain by exploiting the problem structure, which gives a\nsignificant complexity saving. Numerical results show a huge improvement in\nenergy saving achieved by the proposed scheme. The user association derived\nfrom the proposed joint resource optimization is mapped to standard-compliant\ncell selection biasing. This mapping reveals that the cell-specific biasing for\nenergy saving is quite different from that for load balancing investigated in\nthe literature. \n\n"}
{"id": "1602.04207", "contents": "Title: Fundamental Limits of Cache-Aided Interference Management Abstract: We consider a system comprising a library of $N$ files (e.g., movies) and a\nwireless network with $K_T$ transmitters, each equipped with a local cache of\nsize of $M_T$ files, and $K_R$ receivers, each equipped with a local cache of\nsize of $M_R$ files. Each receiver will ask for one of the $N$ files in the\nlibrary, which needs to be delivered. The objective is to design the cache\nplacement (without prior knowledge of receivers' future requests) and the\ncommunication scheme to maximize the throughput of the delivery. In this\nsetting, we show that the sum degrees-of-freedom (sum-DoF) of\n$\\min\\left\\{\\frac{K_T M_T+K_R M_R}{N},K_R\\right\\}$ is achievable, and this is\nwithin a factor of 2 of the optimum, under one-shot linear schemes. This result\nshows that (i) the one-shot sum-DoF scales linearly with the aggregate cache\nsize in the network (i.e., the cumulative memory available at all nodes), (ii)\nthe transmitters' and receivers' caches contribute equally in the one-shot\nsum-DoF, and (iii) caching can offer a throughput gain that scales linearly\nwith the size of the network.\n  To prove the result, we propose an achievable scheme that exploits the\nredundancy of the content at transmitters' caches to cooperatively zero-force\nsome outgoing interference and availability of the unintended content at\nreceivers' caches to cancel (subtract) some of the incoming interference. We\ndevelop a particular pattern for cache placement that maximizes the overall\ngains of cache-aided transmit and receive interference cancellations. For the\nconverse, we present an integer optimization problem which minimizes the number\nof communication blocks needed to deliver any set of requested files to the\nreceivers. We then provide a lower bound on the value of this optimization\nproblem, hence leading to an upper bound on the linear one-shot sum-DoF of the\nnetwork, which is within a factor of 2 of the achievable sum-DoF. \n\n"}
{"id": "1602.05536", "contents": "Title: Backhaul Traffic Balancing and Dynamic Content-Centric Clustering for\n  the Downlink of Fog Radio Access Network Abstract: Recently, an evolution of the Cloud Radio Access Network (C-RAN) has been\nproposed, named as Fog Radio Access Network (F-RAN). Compared to C-RAN, the\nRadio Units (RUs) in F-CAN are equipped with local caches, which can store some\nfrequently requested files. In the downlink, users requesting the same file\nform a multicast group, and are cooperatively served by a cluster of RUs. The\nrequested file is either available locally in the cache of this cluster or\nfetched from the Central Processor (CP) via backhauls. Thus caching some\nfrequently requested files can greatly reduce the burden on backhaul links.\nWhether a specific RU should be involved in a cluster to serve a multicast\ngroup depends on its backhaul capacity, requested files, cached files and the\nchannel. Therefore it is subject to optimization. In this paper we investigate\nthe joint design of multicast beamforming, dynamic clustering and backhaul\ntraffic balancing. Beamforming and clustering are jointly optimized in order to\nminimize the power consumed, while QoS of each user is to be met and the\ntraffic on each backhaul link is balanced according to its capacity. \n\n"}
{"id": "1602.06209", "contents": "Title: Cooperative Channel Estimation for Coordinated Transmission with Limited\n  Backhaul Abstract: Obtaining accurate global channel state information (CSI) at multiple\ntransmitter devices is critical to the performance of many coordinated\ntransmission schemes. Practical CSI local feedback often leads to noisy and\npartial CSI estimates at each transmitter. With rate-limited bi-directional\nbackhaul, transmitters have the opportunity to exchange few CSI-related bits to\nestablish global channel state information at transmitter (CSIT). This work\ninvestigates possible strategies towards this goal. We propose a novel\ndecentralized algorithm that produces minimum mean square error (MMSE)-optimal\nglobal channel estimates at each device from combining local feedback and\ninformation exchanged through backhauls. The method adapts to arbitrary initial\ninformation topologies and feedback noise statistics and can do that with a\ncombination of closed-form and convex approaches. Simulations for coordinated\nmulti-point (CoMP) transmission systems with two or three transmitters exhibit\nthe advantage of the proposed algorithm over conventional CSI exchange\nmechanisms when the coordination backhauls are limited. \n\n"}
{"id": "1602.06664", "contents": "Title: A Geometric Analysis of Phase Retrieval Abstract: Can we recover a complex signal from its Fourier magnitudes? More generally,\ngiven a set of $m$ measurements, $y_k = |\\mathbf a_k^* \\mathbf x|$ for $k = 1,\n\\dots, m$, is it possible to recover $\\mathbf x \\in \\mathbb{C}^n$ (i.e.,\nlength-$n$ complex vector)? This **generalized phase retrieval** (GPR) problem\nis a fundamental task in various disciplines, and has been the subject of much\nrecent investigation. Natural nonconvex heuristics often work remarkably well\nfor GPR in practice, but lack clear theoretical explanations. In this paper, we\ntake a step towards bridging this gap. We prove that when the measurement\nvectors $\\mathbf a_k$'s are generic (i.i.d. complex Gaussian) and the number of\nmeasurements is large enough ($m \\ge C n \\log^3 n$), with high probability, a\nnatural least-squares formulation for GPR has the following benign geometric\nstructure: (1) there are no spurious local minimizers, and all global\nminimizers are equal to the target signal $\\mathbf x$, up to a global phase;\nand (2) the objective function has a negative curvature around each saddle\npoint. This structure allows a number of iterative optimization methods to\nefficiently find a global minimizer, without special initialization. To\ncorroborate the claim, we describe and analyze a second-order trust-region\nalgorithm. \n\n"}
{"id": "1602.07763", "contents": "Title: Optimizing the robustness of electrical power systems against cascading\n  failures Abstract: Electrical power systems are one of the most important infrastructures that\nsupport our society. However, their vulnerabilities have raised great concern\nrecently due to several large-scale blackouts around the world. In this paper,\nwe investigate the robustness of power systems against cascading failures\ninitiated by a random attack. This is done under a simple yet useful model\nbased on global and equal redistribution of load upon failures. We provide a\ncomplete understanding of system robustness by i) deriving an expression for\nthe final system size as a function of the size of initial attacks; ii)\nderiving the critical attack size after which system breaks down completely;\niii) showing that complete system breakdown takes place through a first-order\n(i.e., discontinuous) transition in terms of the attack size; and iv)\nestablishing the optimal load-capacity distribution that maximizes robustness.\nIn particular, we show that robustness is maximized when the difference between\nthe capacity and initial load is the same for all lines; i.e., when all lines\nhave the same redundant space regardless of their initial load. This is in\ncontrast with the intuitive and commonly used setting where capacity of a line\nis a fixed factor of its initial load. \n\n"}
{"id": "1602.08114", "contents": "Title: Bayesian Inference of Diffusion Networks with Unknown Infection Times Abstract: The analysis of diffusion processes in real-world propagation scenarios often\ninvolves estimating variables that are not directly observed. These hidden\nvariables include parental relationships, the strengths of connections between\nnodes, and the moments of time that infection occurs. In this paper, we propose\na framework in which all three sets of parameters are assumed to be hidden and\nwe develop a Bayesian approach to infer them. After justifying the model\nassumptions, we evaluate the performance efficiency of our proposed approach\nthrough numerical simulations on synthetic datasets and real-world diffusion\nprocesses. \n\n"}
{"id": "1602.08156", "contents": "Title: Capacitated Kinetic Clustering in Mobile Networks by Optimal\n  Transportation Theory Abstract: We consider the problem of capacitated kinetic clustering in which $n$ mobile\nterminals and $k$ base stations with respective operating capacities are given.\nThe task is to assign the mobile terminals to the base stations such that the\ntotal squared distance from each terminal to its assigned base station is\nminimized and the capacity constraints are satisfied. This paper focuses on the\ndevelopment of \\emph{distributed} and computationally efficient algorithms that\nadapt to the motion of both terminals and base stations. Suggested by the\noptimal transportation theory, we exploit the structural property of the\noptimal solution, which can be represented by a power diagram on the base\nstations such that the total usage of nodes within each power cell equals the\ncapacity of the corresponding base station. We show by using the kinetic data\nstructure framework the first analytical upper bound on the number of changes\nin the optimal solution, i.e., its stability. On the algorithm side, using the\npower diagram formulation we show that the solution can be represented in size\nproportional to the number of base stations and can be solved by an iterative,\nlocal algorithm. In particular, this algorithm can naturally exploit the\ncontinuity of motion and has orders of magnitude faster than existing solutions\nusing min-cost matching and linear programming, and thus is able to handle\nlarge scale data under mobility. \n\n"}
{"id": "1603.00621", "contents": "Title: Incompatibility boundaries for properties of community partitions Abstract: We prove the incompatibility of certain desirable properties of community\npartition quality functions. Our results generalize the impossibility result of\n[Kleinberg 2003] by considering sets of weaker properties. In particular, we\nuse an alternative notion to solve the central issue of the consistency\nproperty. (The latter means that modifying the graph in a way consistent with a\npartition should not have counterintuitive effects). Our results clearly show\nthat community partition methods should not be expected to perfectly satisfy\nall ideally desired properties.\n  We then proceed to show that this incompatibility no longer holds when\nslightly relaxed versions of the properties are considered, and we provide in\nfact examples of simple quality functions satisfying these relaxed properties.\nAn experimental study of these quality functions shows a behavior comparable to\nestablished methods in some situations, but more debatable results in others.\nThis suggests that defining a notion of good partition in communities probably\nrequires imposing additional properties. \n\n"}
{"id": "1603.04079", "contents": "Title: Indoor 5G 3GPP-like Channel Models for Office and Shopping Mall\n  Environments Abstract: Future mobile communications systems are likely to be very different to those\nof today with new service innovations driven by increasing data traffic demand,\nincreasing processing power of smart devices and new innovative applications.\nTo meet these service demands the telecommunications industry is converging on\na common set of 5G requirements which includes network speeds as high as 10\nGbps, cell edge rate greater than 100 Mbps, and latency of less than 1 msec. To\nreach these 5G requirements the industry is looking at new spectrum bands in\nthe range up to 100 GHz where there is spectrum availability for wide bandwidth\nchannels. For the development of new 5G systems to operate in bands up to 100\nGHz there is a need for accurate radio propagation models which are not\naddressed by existing channel models developed for bands below 6 GHz. This\npaper presents a preliminary overview of the 5G channel models for bands up to\n100 GHz in indoor offices and shopping malls, derived from extensive\nmeasurements across a multitude of bands. These studies have found some\nextensibility of the existing 3GPP models to the higher frequency bands up to\n100 GHz. The measurements indicate that the smaller wavelengths introduce an\nincreased sensitivity of the propagation models to the scale of the environment\nand show some frequency dependence of the path loss as well as increased\noccurrence of blockage. Further, the penetration loss is highly dependent on\nthe material and tends to increase with frequency. The small-scale\ncharacteristics of the channel such as delay spread and angular spread and the\nmultipath richness is somewhat similar over the frequency range, which is\nencouraging for extending the existing 3GPP models to the wider frequency\nrange. Further work will be carried out to complete these models, but this\npaper presents the first steps for an initial basis for the model development. \n\n"}
{"id": "1603.04222", "contents": "Title: Multiple seed structure and disconnected networks in respondent-driven\n  sampling Abstract: Respondent-driven sampling (RDS) is a link-tracing sampling method that is\nespecially suitable for sampling hidden populations. RDS combines an efficient\nsnowball-type sampling scheme with inferential procedures that yield unbiased\npopulation estimates under some assumptions about the sampling procedure and\npopulation structure. Several seed individuals are typically used to initiate\nRDS recruitment. However, standard RDS estimation theory assume that all\nsampled individuals originate from only one seed. We present an estimator,\nbased on a random walk with teleportation, which accounts for the multiple seed\nstructure of RDS. The new estimator can also be used on populations with\ndisconnected social networks. We numerically evaluate our estimator by\nsimulations on artificial and real networks. Our estimator outperforms previous\nestimators, especially when the proportion of seeds in the sample is large. We\nrecommend our new estimator to be used in RDS studies, in particular when the\nnumber of seeds is large or the social network of the population is\ndisconnected. \n\n"}
{"id": "1603.04389", "contents": "Title: Linear and Nonlinear Frequency-Division Multiplexing Abstract: Two signal multiplexing schemes for optical fiber communication are\nconsidered: Wavelength-division multiplexing (WDM) and nonlinear\nfrequency-division multiplexing (NFDM), based on the nonlinear Fourier\ntransform (NFT). Achievable information rates (AIRs) of NFDM and WDM are\ncompared in a network scenario with an ideal lossless model of the optical\nfiber in the defocusing regime. It is shown that the NFDM AIR is greater than\nthe WDM AIR subject to a bandwidth and average power constraint, in a\nrepresentative system with one symbol per user. The improvement results from\nnonlinear signal multiplexing. \n\n"}
{"id": "1603.05215", "contents": "Title: Phase Retrieval from 1D Fourier Measurements: Convexity, Uniqueness, and\n  Algorithms Abstract: This paper considers phase retrieval from the magnitude of 1D over-sampled\nFourier measurements, a classical problem that has challenged researchers in\nvarious fields of science and engineering. We show that an optimal vector in a\nleast-squares sense can be found by solving a convex problem, thus establishing\na hidden convexity in Fourier phase retrieval. We also show that the standard\nsemidefinite relaxation approach yields the optimal cost function value (albeit\nnot necessarily an optimal solution) in this case. A method is then derived to\nretrieve an optimal minimum phase solution in polynomial time. Using these\nresults, a new measuring technique is proposed which guarantees uniqueness of\nthe solution, along with an efficient algorithm that can solve large-scale\nFourier phase retrieval problems with uniqueness and optimality guarantees. \n\n"}
{"id": "1603.05368", "contents": "Title: A Survey on High-Speed Railway Communications: A Radio Resource\n  Management Perspective Abstract: High-speed railway (HSR) communications will become a key feature supported\nby intelligent transportation communication systems. The increasing demand for\nHSR communications leads to significant attention on the study of radio\nresource management (RRM), which enables efficient resource utilization and\nimproved system performance. RRM design is a challenging problem due to\nheterogenous quality of service (QoS) requirements and dynamic characteristics\nof HSR wireless communications. The objective of this paper is to provide an\noverview on the key issues that arise in the RRM design for HSR wireless\ncommunications. A detailed description of HSR communication systems is first\npresented, followed by an introduction on HSR channel models and\ncharacteristics, which are vital to the cross-layer RRM design. Then we provide\na literature survey on state-of-the-art RRM schemes for HSR wireless\ncommunications, with an in-depth discussion on various RRM aspects including\nadmission control, mobility management, power control and resource allocation.\nFinally, this paper outlines the current challenges and open issues in the area\nof RRM design for HSR wireless communications. \n\n"}
{"id": "1603.05680", "contents": "Title: Semidefinite Relaxation and Approximation Analysis of a Beamformed\n  Alamouti Scheme for Relay Beamforming Networks Abstract: In this paper, we study the amplify-and-forward (AF) schemes in two-hop\none-way relay networks. In particular, we consider the multigroup multicast\ntransmission between long-distance users. Given that perfect channel state\ninformation is perceived, our goal is to design the AF process so that the\nmax-min-fair (MMF) signal-to-interference-plus-noise ratio (SINR) is optimized\nsubject to generalized power constraints. We propose a rank-two beamformed\nAlamouti (BFA) AF scheme and formulate the corresponding AF design problem as a\n\\emph{two-variable} fractional quadratically-constrained quadratic program\n(QCQP), which is further tackled by the semidefinite relaxation (SDR)\ntechnique. We analyze the approximation quality of two-variable fractional SDRs\nunder the Gaussian randomization algorithm. These results are fundamentally new\nand reveal that the proposed BFA AF scheme can outperform the traditional BF AF\nscheme, especially when there are many users in the system or many generalized\npower constraints in the problem formulation. From a practical perspective, the\nBFA AF scheme offers two degrees of freedom (DoFs) in beamformer design, as\nopposed to the one DoF offered by the BF AF scheme, to improve the receivers'\nSINR. In the latter part of this paper, we demonstrate how this extra DoF leads\nto provable performance gains by considering two special cases of multicasting,\nwhere the AF process is shown to employ a special structure. The numerical\nsimulations further validate that the proposed BFA AF scheme outperforms the BF\nAF scheme and works well for large-scale relay systems. \n\n"}
{"id": "1603.05843", "contents": "Title: Graphlet characteristics in directed networks Abstract: A number of network structural characteristics have recently been the subject\nof particularly intense research, including degree distributions, community\nstructure, and various measures of vertex centrality, to mention only a few.\nVertices may have attributes associated with them; for example, properties of\nproteins in protein-protein interaction networks, users' social network\nprofiles, or authors' publication histories in co-authorship networks. In a\nnetwork, two vertices might be considered similar if they have similar\nattributes (features, properties), or they can be considered similar based\nsolely on the network structure. Similarity of this type is called structural\nsimilarity, to distinguish it from properties similarity, social similarity,\ntextual similarity, functional similarity or other similarity types found in\nnetworks. Here we focus on the similarity problem by computing (1) for each\nvertex a vector of structural features, called signature vector, based on the\nnumber of graphlets associated with the vertex, and (2) for the network its\ngraphlet correlation matrix, measuring graphlets dependencies and hence\nrevealing unknown organizational principles of the network. We found that\nreal-world networks generally have very different structural characteristics\nresulting in different graphlet correlation matrices. In particular, the\ngraphlet correlation matrix of the brain effective network is computed for 40\nhealthy subjects and common (present in more than 70 percent subjects)\ndependencies are raveled. Thus, negative correlations are found for 2-node\ngraphlets and 3-node graphlets that are wedges and positive correlations are\nfound only for 3-node graphlets that are triangles. Graphlets characteristics\nin directed networks could further significantly increase our understanding of\nreal-world networks. \n\n"}
{"id": "1603.05970", "contents": "Title: Coherent-state constellations and polar codes for thermal Gaussian\n  channels Abstract: Optical communication channels are ultimately quantum-mechanical in nature,\nand we must therefore look beyond classical information theory to determine\ntheir communication capacity as well as to find efficient encoding and decoding\nschemes of the highest rates. Thermal channels, which arise from linear\ncoupling of the field to a thermal environment, are of particular practical\nrelevance; their classical capacity has been recently established, but their\nquantum capacity remains unknown. While the capacity sets the ultimate limit on\nreliable communication rates, it does not promise that such rates are\nachievable by practical means. Here we construct efficiently encodable codes\nfor thermal channels which achieve the classical capacity and the so-called\nGaussian coherent information for transmission of classical and quantum\ninformation, respectively. Our codes are based on combining polar codes with a\ndiscretization of the channel input into a finite \"constellation\" of coherent\nstates. Encoding of classical information can be done using linear optics. \n\n"}
{"id": "1603.06306", "contents": "Title: Distributed Semi-Stochastic Optimization with Quantization Refinement Abstract: We consider the problem of regularized regression in a network of\ncommunication-constrained devices. Each node has local data and objectives, and\nthe goal is for the nodes to optimize a global objective. We develop a\ndistributed optimization algorithm that is based on recent work on\nsemi-stochastic proximal gradient methods. Our algorithm employs iteratively\nrefined quantization to limit message size. We present theoretical analysis and\nconditions for the algorithm to achieve a linear convergence rate. Finally, we\ndemonstrate the performance of our algorithm through numerical simulations. \n\n"}
{"id": "1604.00073", "contents": "Title: Immunization and targeted destruction of networks using explosive\n  percolation Abstract: A new method (`explosive immunization' (EI)) is proposed for immunization and\ntargeted destruction of networks. It combines the explosive percolation (EP)\nparadigm with the idea of maintaining a fragmented distribution of clusters.\nThe ability of each node to block the spread of an infection (or to prevent the\nexistence of a large cluster of connected nodes) is estimated by a score. The\nalgorithm proceeds by first identifying low score nodes that should not be\nvaccinated/destroyed, analogously to the links selected in EP if they do not\nlead to large clusters. As in EP, this is done by selecting the worst node\n(weakest blocker) from a finite set of randomly chosen `candidates'. Tests on\nseveral real-world and model networks suggest that the method is more efficient\nand faster than any existing immunization strategy. Due to the latter property\nit can deal with very large networks. \n\n"}
{"id": "1604.00691", "contents": "Title: Event excitation for event-driven control and optimization of\n  multi-agent systems Abstract: We consider event-driven methods in a general framework for the control and\noptimization of multi-agent systems, viewing them as stochastic hybrid systems.\nSuch systems often have feasible realizations in which the events needed to\nexcite an on-line event-driven controller cannot occur, rendering the use of\nsuch controllers ineffective. We show that this commonly happens in\nenvironments which contain discrete points of interest which the agents must\nvisit. To address this problem in event-driven gradient-based optimization\nproblems, we propose a new metric for the objective function which creates a\npotential field guaranteeing that gradient values are non-zero when no events\nare present and which results in eventual event excitation. We apply this\napproach to the class of cooperative multi-agent data collection problems using\nthe event-driven Infinitesimal Perturbation Analysis (IPA) methodology and\ninclude numerical examples illustrating its effectiveness. \n\n"}
{"id": "1604.00762", "contents": "Title: Statistical properties of fluctuations of time series representing the\n  appearance of words in nationwide blog data and their applications: An\n  example of observations and the modelling of fluctuation scalings of\n  nonstationary time series Abstract: To elucidate the non-trivial empirical statistical properties of fluctuations\nof a typical non-steady time series representing the appearance of words in\nblogs, we investigated approximately five billion Japanese blogs over a period\nof six years and analyse some corresponding mathematical models. First, we\nintroduce a solvable non-steady extension of the random diffusion model, which\ncan be deduced by modelling the behaviour of heterogeneous random bloggers.\nNext, we deduce theoretical expressions for both the temporal and ensemble\nfluctuation scalings of this model, and demonstrate that these expressions can\nreproduce all empirical scalings over eight orders of magnitude. Furthermore,\nwe show that the model can reproduce other statistical properties of time\nseries representing the appearance of words in blogs, such as functional forms\nof the probability density and correlations in the total number of blogs. As an\napplication, we quantify the abnormality of special nationwide events by\nmeasuring the fluctuation scalings of 1771 basic adjectives. \n\n"}
{"id": "1604.00873", "contents": "Title: A spin glass approach to the directed feedback vertex set problem Abstract: A directed graph (digraph) is formed by vertices and arcs (directed edges)\nfrom one vertex to another. A feedback vertex set (FVS) is a set of vertices\nthat contains at least one vertex of every directed cycle in this digraph. The\ndirected feedback vertex set problem aims at constructing a FVS of minimum\ncardinality. This is a fundamental cycle-constrained hard combinatorial\noptimization problem with wide practical applications. In this paper we\nconstruct a spin glass model for the directed FVS problem by converting the\nglobal cycle constraints into local arc constraints, and study this model\nthrough the replica-symmetric (RS) mean field theory of statistical physics. We\nthen implement a belief propagation-guided decimation (BPD) algorithm for\nsingle digraph instances. The BPD algorithm slightly outperforms the simulated\nannealing algorithm on large random graph instances. The predictions of the RS\nmean field theory are noticeably lower than the BPD results, possibly due to\nits neglect of cycle-caused long range correlations. \n\n"}
{"id": "1604.01575", "contents": "Title: Clustering implies geometry in networks Abstract: Network models with latent geometry have been used successfully in many\napplications in network science and other disciplines, yet it is usually\nimpossible to tell if a given real network is geometric, meaning if it is a\ntypical element in an ensemble of random geometric graphs. Here we identify\nstructural properties of networks that guarantee that random graphs having\nthese properties are geometric. Specifically we show that random graphs in\nwhich expected degree and clustering of every node are fixed to some constants\nare equivalent to random geometric graphs on the real line, if clustering is\nsufficiently strong. Large numbers of triangles, homogeneously distributed\nacross all nodes as in real networks, are thus a consequence of network\ngeometricity. The methods we use to prove this are quite general and applicable\nto other network ensembles, geometric or not, and to certain problems in\nquantum gravity. \n\n"}
{"id": "1604.02333", "contents": "Title: Information Theoretic Caching: The Multi-User Case Abstract: In this paper, we consider a cache aided network in which each user is\nassumed to have individual caches, while upon users' requests, an update\nmessage is sent though a common link to all users. First, we formulate a\ngeneral information theoretic setting that represents the database as a\ndiscrete memoryless source, and the users' requests as side information that is\navailable everywhere except at the cache encoder. The decoders' objective is to\nrecover a function of the source and the side information. By viewing cache\naided networks in terms of a general distributed source coding problem and\nthrough information theoretic arguments, we present inner and outer bounds on\nthe fundamental tradeoff of cache memory size and update rate. Then, we\nspecialize our general inner and outer bounds to a specific model of content\ndelivery networks: File selection networks, in which the database is a\ncollection of independent equal-size files and each user requests one of the\nfiles independently. For file selection networks, we provide an outer bound and\ntwo inner bounds (for centralized and decentralized caching strategies). For\nthe case when the user request information is uniformly distributed, we\ncharacterize the rate vs. cache size tradeoff to within a multiplicative gap of\n4. By further extending our arguments to the framework of Maddah-Ali and\nNiesen, we also establish a new outer bound and two new inner bounds in which\nit is shown to recover the centralized and decentralized strategies, previously\nestablished by Maddah-Ali and Niesen. Finally, in terms of rate vs. cache size\ntradeoff, we improve the previous multiplicative gap of 72 to 4.7 for the\naverage case with uniform requests. \n\n"}
{"id": "1604.03159", "contents": "Title: Phase Transitions and a Model Order Selection Criterion for Spectral\n  Graph Clustering Abstract: One of the longstanding open problems in spectral graph clustering (SGC) is\nthe so-called model order selection problem: automated selection of the correct\nnumber of clusters. This is equivalent to the problem of finding the number of\nconnected components or communities in an undirected graph. We propose\nautomated model order selection (AMOS), a solution to the SGC model selection\nproblem under a random interconnection model (RIM) using a novel selection\ncriterion that is based on an asymptotic phase transition analysis. AMOS can\nmore generally be applied to discovering hidden block diagonal structure in\nsymmetric non-negative matrices. Numerical experiments on simulated graphs\nvalidate the phase transition analysis, and real-world network data is used to\nvalidate the performance of the proposed model selection procedure. \n\n"}
{"id": "1604.06961", "contents": "Title: Sparse p-Adic Data Coding for Computationally Efficient and Effective\n  Big Data Analytics Abstract: We develop the theory and practical implementation of p-adic sparse coding of\ndata. Rather than the standard, sparsifying criterion that uses the $L_0$\npseudo-norm, we use the p-adic norm. We require that the hierarchy or tree be\nnode-ranked, as is standard practice in agglomerative and other hierarchical\nclustering, but not necessarily with decision trees. In order to structure the\ndata, all computational processing operations are direct reading of the data,\nor are bounded by a constant number of direct readings of the data, implying\nlinear computational time. Through p-adic sparse data coding, efficient storage\nresults, and for bounded p-adic norm stored data, search and retrieval are\nconstant time operations. Examples show the effectiveness of this new approach\nto content-driven encoding and displaying of data. \n\n"}
{"id": "1604.07924", "contents": "Title: Iterative $\\ell_1$ minimization for non-convex compressed sensing Abstract: An algorithmic framework, based on the difference of convex functions\nalgorithm (DCA), is proposed for minimizing a class of concave sparse metrics\nfor compressed sensing problems. The resulting algorithm iterates a sequence of\n$\\ell_1$ minimization problems. An exact sparse recovery theory is established\nto show that the proposed framework always improves on the basis pursuit\n($\\ell_1$ minimization) and inherits robustness from it. Numerical examples on\nsuccess rates of sparse solution recovery illustrate further that, unlike most\nexisting non-convex compressed sensing solvers in the literature, our method\nalways out-performs basis pursuit, no matter how ill-conditioned the\nmeasurement matrix is. Moreover, the iterative $\\ell_1$ (IL$_1$) algorithm lead\nby a wide margin the state-of-the-art algorithms on $\\ell_{1/2}$ and\nlogarithimic minimizations in the strongly coherent (highly ill-conditioned)\nregime, despite the same objective functions. Last but not least, in the\napplication of magnetic resonance imaging (MRI), IL$_1$ algorithm easily\nrecovers the phantom image with just 7 line projections. \n\n"}
{"id": "1605.00695", "contents": "Title: Cyclone Codes Abstract: We introduce Cyclone codes which are rateless erasure resilient codes. They\ncombine Pair codes with Luby Transform (LT) codes by computing a code symbol\nfrom a random set of data symbols using bitwise XOR and cyclic shift\noperations. The number of data symbols is chosen according to the Robust\nSoliton distribution. XOR and cyclic shift operations establish a unitary\ncommutative ring if data symbols have a length of $p-1$ bits, for some prime\nnumber $p$. We consider the graph given by code symbols combining two data\nsymbols. If $n/2$ such random pairs are given for $n$ data symbols, then a\ngiant component appears, which can be resolved in linear time. We can extend\nCyclone codes to data symbols of arbitrary even length, provided the Goldbach\nconjecture holds.\n  Applying results for this giant component, it follows that Cyclone codes have\nthe same encoding and decoding time complexity as LT codes, while the overhead\nis upper-bounded by those of LT codes. Simulations indicate that Cyclone codes\nsignificantly decreases the overhead of extra coding symbols. \n\n"}
{"id": "1605.01191", "contents": "Title: Waveform Optimization for Large-Scale Multi-Antenna Multi-Sine Wireless\n  Power Transfer Abstract: Wireless power transfer (WPT) is expected to be a technology reshaping the\nlandscape of low-power applications such as the Internet of Things,\nmachine-to-machine communications and radio frequency identification networks.\nAlthough there has been some progress towards multi-antenna multi-sine WPT\ndesign, the large-scale design of WPT, reminiscent of massive multiple-input\nmultiple-output (MIMO) in communications, remains an open problem. Considering\nthe nonlinear rectifier model, a multiuser waveform optimization algorithm is\nderived based on successive convex approximation (SCA). A lower-complexity\nalgorithm is derived based on asymptotic analysis and sequential approximation\n(SA). It is shown that the difference between the average output voltage\nachieved by the two algorithms can be negligible provided the number of\nantennas is large enough. The performance gain of the nonlinear model based\ndesign over the linear model based design can be large, in the presence of a\nlarge number of tones. \n\n"}
{"id": "1605.02856", "contents": "Title: Asymptotic Analysis of Multicell Massive MIMO over Rician Fading\n  Channels Abstract: This work considers the downlink of a multicell massive MIMO system in which\n$L$ base stations (BSs) of $N$ antennas each communicate with $K$\nsingle-antenna user equipments randomly positioned in the coverage area. Within\nthis setting, we are interested in evaluating the sum rate of the system when\nMRT and RZF are employed under the assumption that each intracell link forms a\nMIMO Rician fading channel. The analysis is conducted assuming that $N$ and $K$\ngrow large with a non-trivial ratio $N/K$ under the assumption that the data\ntransmission in each cell is affected by channel estimation errors, pilot\ncontamination, and an arbitrary large scale attenuation. Numerical results are\nused to validate the asymptotic analysis in the finite system regime and to\nevaluate the network performance under different settings. The asymptotic\nresults are also instrumental to get insights into the interplay among system\nparameters. \n\n"}
{"id": "1605.02968", "contents": "Title: On cyclic DNA codes over the rings Z_{4}+wZ_{4} and\n  Z_{4}+wZ_{4}+vZ_{4}+wvZ_{4} Abstract: The structures of cyclic DNA codes of odd length over the finite rings\nR=Z_{4}+wZ_{4}, w^{2}=2 and S=Z_{4}+wZ_{4}+vZ_{4}+wvZ_{4},w^{2}=2,v^{2}=v,wv=vw\nare studied. The links between the elements of the rings R, S and 16 and 256\ncodons are established, respectively. Cyclic codes of odd length over the\nfinite ring R satisfies reverse complement constraint and cyclic codes of odd\nlength over the finite ring S satisfy reverse constraint and reverse complement\nconstraint are studied. Binary images of the cyclic DNA codes over the finite\nrings R and S are determined. Moreover, a family of DNA skew cyclic codes over\nR is constructed, its property of being reverse complement is studied. \n\n"}
{"id": "1605.04814", "contents": "Title: Smart Meter Privacy with Renewable Energy and a Finite Capacity Battery Abstract: We address the smart meter (SM) privacy problem by considering the\navailability of a renewable energy source (RES) and a battery which can be\nexploited by a consumer to partially hide the consumption pattern from the\nutility provider (UP). Privacy is measured by the mutual information rate\nbetween the consumer's energy consumption and the renewable energy generation\nprocess, and the energy received from the grid, where the latter is known by\nthe UP through the SM readings, and the former two are to be kept private. By\nexpressing the information leakage as an additive quantity, we cast the problem\nas a stochastic control problem, and formulate the corresponding Bellman\nequations. \n\n"}
{"id": "1605.05054", "contents": "Title: HARRISON: A Benchmark on HAshtag Recommendation for Real-world Images in\n  Social Networks Abstract: Simple, short, and compact hashtags cover a wide range of information on\nsocial networks. Although many works in the field of natural language\nprocessing (NLP) have demonstrated the importance of hashtag recommendation,\nhashtag recommendation for images has barely been studied. In this paper, we\nintroduce the HARRISON dataset, a benchmark on hashtag recommendation for real\nworld images in social networks. The HARRISON dataset is a realistic dataset,\ncomposed of 57,383 photos from Instagram and an average of 4.5 associated\nhashtags for each photo. To evaluate our dataset, we design a baseline\nframework consisting of visual feature extractor based on convolutional neural\nnetwork (CNN) and multi-label classifier based on neural network. Based on this\nframework, two single feature-based models, object-based and scene-based model,\nand an integrated model of them are evaluated on the HARRISON dataset. Our\ndataset shows that hashtag recommendation task requires a wide and contextual\nunderstanding of the situation conveyed in the image. As far as we know, this\nwork is the first vision-only attempt at hashtag recommendation for real world\nimages in social networks. We expect this benchmark to accelerate the\nadvancement of hashtag recommendation. \n\n"}
{"id": "1605.05785", "contents": "Title: Efficient Nonparametric Smoothness Estimation Abstract: Sobolev quantities (norms, inner products, and distances) of probability\ndensity functions are important in the theory of nonparametric statistics, but\nhave rarely been used in practice, partly due to a lack of practical\nestimators. They also include, as special cases, $L^2$ quantities which are\nused in many applications. We propose and analyze a family of estimators for\nSobolev quantities of unknown probability density functions. We bound the bias\nand variance of our estimators over finite samples, finding that they are\ngenerally minimax rate-optimal. Our estimators are significantly more\ncomputationally tractable than previous estimators, and exhibit a\nstatistical/computational trade-off allowing them to adapt to computational\nconstraints. We also draw theoretical connections to recent work on fast\ntwo-sample testing. Finally, we empirically validate our estimators on\nsynthetic data. \n\n"}
{"id": "1605.05870", "contents": "Title: Interests Diffusion on a Semantic Multiplex Abstract: Exploiting the information about members of a Social Network (SN) represents\none of the most attractive and dwelling subjects for both academic and applied\nscientists. The community of Complexity Science and especially those\nresearchers working on multiplex social systems are devoting increasing efforts\nto outline general laws, models, and theories, to the purpose of predicting\nemergent phenomena in SN's (e.g. success of a product). On the other side the\nsemantic web community aims at engineering a new generation of advanced\nservices tailored to specific people needs. This implies defining constructs,\nmodels and methods for handling the semantic layer of SNs. We combined models\nand techniques from both the former fields to provide a hybrid approach to\nunderstand a basic (yet complex) phenomenon: the propagation of individual\ninterests along the social networks. Since information may move along different\nsocial networks, one should take into account a multiplex structure. Therefore\nwe introduced the notion of \"Semantic Multiplex\". In this paper we analyse two\ndifferent semantic social networks represented by authors publishing in the\nComputer Science and those in the American Physical Society Journals. The\ncomparison allows to outline common and specific features \n\n"}
{"id": "1605.07057", "contents": "Title: Bayesian Model Selection of Stochastic Block Models Abstract: A central problem in analyzing networks is partitioning them into modules or\ncommunities. One of the best tools for this is the stochastic block model,\nwhich clusters vertices into blocks with statistically homogeneous pattern of\nlinks. Despite its flexibility and popularity, there has been a lack of\nprincipled statistical model selection criteria for the stochastic block model.\nHere we propose a Bayesian framework for choosing the number of blocks as well\nas comparing it to the more elaborate degree- corrected block models,\nultimately leading to a universal model selection framework capable of\ncomparing multiple modeling combinations. We will also investigate its\nconnection to the minimum description length principle. \n\n"}
{"id": "1605.07098", "contents": "Title: Free Deterministic Equivalents for the Analysis of MIMO Multiple Access\n  Channel Abstract: In this paper, a free deterministic equivalent is proposed for the capacity\nanalysis of the multi-input multi-output (MIMO) multiple access channel (MAC)\nwith a more general channel model compared to previous works. Specifically, a\nMIMO MAC with one base station (BS) equipped with several distributed antenna\nsets is considered. Each link between a user and a BS antenna set forms a\njointly correlated Rician fading channel. The analysis is based on\noperator-valued free probability theory, which broadens the range of\napplicability of free probability techniques tremendously. By replacing\nindependent Gaussian random matrices with operator-valued random variables\nsatisfying certain operator-valued freeness relations, the free deterministic\nequivalent of the considered channel Gram matrix is obtained. The Shannon\ntransform of the free deterministic equivalent is derived, which provides an\napproximate expression for the ergodic input-output mutual information of the\nchannel. The sum-rate capacity achieving input covariance matrices are also\nderived based on the approximate ergodic input-output mutual information. The\nfree deterministic equivalent results are easy to compute, and simulation\nresults show that these approximations are numerically accurate and\ncomputationally efficient. \n\n"}
{"id": "1605.08285", "contents": "Title: Solving Systems of Random Quadratic Equations via Truncated Amplitude\n  Flow Abstract: This paper presents a new algorithm, termed \\emph{truncated amplitude flow}\n(TAF), to recover an unknown vector $\\bm{x}$ from a system of quadratic\nequations of the form $y_i=|\\langle\\bm{a}_i,\\bm{x}\\rangle|^2$, where\n$\\bm{a}_i$'s are given random measurement vectors. This problem is known to be\n\\emph{NP-hard} in general. We prove that as soon as the number of equations is\non the order of the number of unknowns, TAF recovers the solution exactly (up\nto a global unimodular constant) with high probability and complexity growing\nlinearly with both the number of unknowns and the number of equations. Our TAF\napproach adopts the \\emph{amplitude-based} empirical loss function, and\nproceeds in two stages. In the first stage, we introduce an\n\\emph{orthogonality-promoting} initialization that can be obtained with a few\npower iterations. Stage two refines the initial estimate by successive updates\nof scalable \\emph{truncated generalized gradient iterations}, which are able to\nhandle the rather challenging nonconvex and nonsmooth amplitude-based objective\nfunction. In particular, when vectors $\\bm{x}$ and $\\bm{a}_i$'s are\nreal-valued, our gradient truncation rule provably eliminates erroneously\nestimated signs with high probability to markedly improve upon its untruncated\nversion. Numerical tests using synthetic data and real images demonstrate that\nour initialization returns more accurate and robust estimates relative to\nspectral initializations. Furthermore, even under the same initialization, the\nproposed amplitude-based refinement outperforms existing Wirtinger flow\nvariants, corroborating the superior performance of TAF over state-of-the-art\nalgorithms. \n\n"}
{"id": "1605.08311", "contents": "Title: 3D Stochastic Geometry Model for Large-Scale Molecular Communication\n  Systems Abstract: Information delivery using chemical molecules is an integral part of biology\nat multiple distance scales and has attracted recent interest in bioengineering\nand communication. The collective signal strength at the receiver (i.e., the\nexpected number of observed molecules inside the receiver), resulting from a\nlarge number of transmitters at random distances (e.g., due to mobility), can\nhave a major impact on the reliability and efficiency of the molecular\ncommunication system. Modeling the collective signal from multiple diffusion\nsources can be computationally and analytically challenging. In this paper, we\npresent the first tractable analytical model for the collective signal strength\ndue to randomly-placed transmitters, whose positions are modelled as a\nhomogeneous Poisson point process in three-dimensional (3D) space. By applying\nstochastic geometry, we derive analytical expressions for the expected number\nof observed molecules at a fully absorbing receiver and a passive receiver. Our\nresults reveal that the collective signal strength at both types of receivers\nincreases proportionally with increasing transmitter density. The proposed\nframework dramatically simplifies the analysis of large-scale molecular systems\nin both communication and biological applications. \n\n"}
{"id": "1605.08515", "contents": "Title: Uplink Spectral Efficiency Analysis of Decoupled Access in Multiuser\n  MIMO Communications Abstract: In a heterogeneous network consisting of macro base stations (MBSs) and small\nbase stations (SBSs), the traditional cell association policy, i.e., coupled\naccess (CA), is far from optimal, due to the significant difference between the\ncoverage and transmit powers of MBSs and SBSs. Hence, users may choose to\nassociate with different types of BSs in downlink (DL) and uplink (UL), i.e.,\ndecoupled access (DA), to enhance spectral efficiency. In this paper, DA in\nmultiuser MIMO communications is investigated in terms of UL spectral\nefficiency. Firstly, we obtain the UL association probabilities. In contrast to\nthe CA scenario, association probabilities for DA scenario only depend on the\ndensities of BSs. Hence, DA allows UL and DL to be totally independent.\nSecondly, we derive lower bounds on the spectral efficiency. The lower bounds\nshow that, different from CA, the UL spectral efficiency for DA scenario is\nirrelative with the transmit powers of BSs, which implies DA allows users to\nassociate with any BSs that can achieve the highest UL spectral efficiency.\nFinally, the spectral efficiencies for DA and CA scenarios are compared via\nsimulation results, where it can be concluded that the spectral efficiency in\nmultiuser MIMO systems is improved by DA. \n\n"}
{"id": "1605.08961", "contents": "Title: A simple and provable algorithm for sparse diagonal CCA Abstract: Given two sets of variables, derived from a common set of samples, sparse\nCanonical Correlation Analysis (CCA) seeks linear combinations of a small\nnumber of variables in each set, such that the induced canonical variables are\nmaximally correlated. Sparse CCA is NP-hard.\n  We propose a novel combinatorial algorithm for sparse diagonal CCA, i.e.,\nsparse CCA under the additional assumption that variables within each set are\nstandardized and uncorrelated. Our algorithm operates on a low rank\napproximation of the input data and its computational complexity scales\nlinearly with the number of input variables. It is simple to implement, and\nparallelizable. In contrast to most existing approaches, our algorithm\nadministers precise control on the sparsity of the extracted canonical vectors,\nand comes with theoretical data-dependent global approximation guarantees, that\nhinge on the spectrum of the input data. Finally, it can be straightforwardly\nadapted to other constrained variants of CCA enforcing structure beyond\nsparsity.\n  We empirically evaluate the proposed scheme and apply it on a real\nneuroimaging dataset to investigate associations between brain activity and\nbehavior measurements. \n\n"}
{"id": "1605.08998", "contents": "Title: Optimal Scalar Linear Index Codes for One-Sided Neighboring\n  Side-Information Problems Abstract: The capacity of symmetric instance of the multiple unicast index coding\nproblem with neighboring antidotes (side-information) with number of messages\nequal to the number of receivers was given by Maleki \\textit{et al.} In this\npaper, we construct matrices of size $ m \\times n (m \\geq n)$ over $F_q$ such\nthat any $n$ adjacent rows of the matrix are linearly independent. By using\nsuch matrices, we give an optimal scalar linear index codes over $F_q$ for the\nsymmetric one-sided antidote problems considered by Maleki \\textit{et al.} for\nany given number of messages and one-sided antidotes. The constructed codes are\nindependent of field size and hence works over every field. \n\n"}
{"id": "1605.09519", "contents": "Title: Optimal caching placement for wireless femto-caching network Abstract: This paper investigates optimal caching placement for wireless femto-caching\nnetwork. The average bit error rate (BER) is formulated as a function of\ncaching placement under wireless fading. To minimize the average BER, we\npropose a greedy algorithm finding optimal caching placement with low\ncomputational complexity. Exploiting the property of the optimal caching\nplacement which we derive, the proposed algorithm can be performed over\nconsiderably reduced search space. Contrary to the optimal caching placement\nwithout consideration of wireless fading aspects, we reveal that optimal\ncaching placement can be reached by balancing a tradeoff between two different\ngains: file diversity gain and channel diversity gain. Moreover, we also\nidentify the conditions that the optimal placement can be found without running\nthe proposed greedy algorithm and derive the corresponding optimal caching\nplacement in closed form. \n\n"}
{"id": "1606.01840", "contents": "Title: Temporal Correlation of Interference in Bounded Mobile Ad Hoc Networks\n  with Blockage Abstract: In mobile wireless networks with blockage, different users, and/or a single\nuser at different time slots, may be blocked by some common obstacles.\nTherefore the temporal correlation of interference does not depend only on the\nuser displacement law but also on the spatial correlation introduced by the\nobstacles. In this letter, we show that in mobile networks with a high density\nof users, blockage increases the temporal correlation of interference, while in\nsparse networks blockage has the opposite effect. \n\n"}
{"id": "1606.03175", "contents": "Title: Degrees of Freedom of Cache-Aided Wireless Interference Networks Abstract: We study the role of caches in wireless interference networks. We focus on\ncontent caching and delivery across a Gaussian interference network, where both\ntransmitters and receivers are equipped with caches. We provide a\nconstant-factor approximation of the system's degrees of freedom (DoF), for\narbitrary number of transmitters, number of receivers, content library size,\nreceiver cache size, and transmitter cache size (as long as the transmitters\ncombined can store the entire content library among them). We demonstrate\napproximate optimality with respect to information-theoretic bounds that do not\nimpose any restrictions on the caching and delivery strategies. Our\ncharacterization reveals three key insights. First, the approximate DoF is\nachieved using a strategy that separates the physical and network layers. This\nseparation architecture is thus approximately optimal. Second, we show that\nincreasing transmitter cache memory beyond what is needed to exactly store the\nentire library between all transmitters does not provide more than a\nconstant-factor benefit to the DoF. A consequence is that transmit zero-forcing\nis not needed for approximate optimality. Third, we derive an interesting\ntrade-off between the receiver memory and the number of transmitters needed for\napproximately maximal performance. In particular, if each receiver can store a\nconstant fraction of the content library, then only a constant number of\ntransmitters are needed. Our solution to the caching problem requires\nformulating and solving a new communication problem, the symmetric multiple\nmulticast X-channel, for which we provide an exact DoF characterization. \n\n"}
{"id": "1606.03504", "contents": "Title: Incoherent Tensor Norms and Their Applications in Higher Order Tensor\n  Completion Abstract: In this paper, we investigate the sample size requirement for a general class\nof nuclear norm minimization methods for higher order tensor completion. We\nintroduce a class of tensor norms by allowing for different levels of\ncoherence, which allows us to leverage the incoherence of a tensor. In\nparticular, we show that a $k$th order tensor of rank $r$ and dimension\n$d\\times\\cdots\\times d$ can be recovered perfectly from as few as\n$O((r^{(k-1)/2}d^{3/2}+r^{k-1}d)(\\log(d))^2)$ uniformly sampled entries through\nan appropriate incoherent nuclear norm minimization. Our results demonstrate\nsome key differences between completing a matrix and a higher order tensor:\nThey not only point to potential room for improvement over the usual nuclear\nnorm minimization but also highlight the importance of explicitly accounting\nfor incoherence, when dealing with higher order tensors. \n\n"}
{"id": "1606.04535", "contents": "Title: Efficient adaptation of complex-valued noiselet sensing matrices for\n  compressed single-pixel imaging Abstract: Minimal mutual coherence of discrete noiselets and Haar wavelets makes this\npair of bases an essential choice for the measurement and compression matrices\nin compressed-sensing-based single-pixel detectors. In this paper we propose an\nefficient way of using complex-valued and non-binary noiselet functions for\nobject sampling in single-pixel cameras with binary spatial light modulators\nand incoherent illumination. The proposed method allows to determine m complex\nnoiselet coefficients from m+1 binary sampling measurements. Further, we\nintroduce a modification to the complex fast noiselet transform, which enables\ncomputationally-efficient real-time generation of the binary noiselet-based\npatterns using efficient integer calculations on bundled patterns. The proposed\nmethod is verified experimentally with a single-pixel camera system using a\nbinary spatial light modulator. \n\n"}
{"id": "1606.04760", "contents": "Title: Adapting to unknown noise level in sparse deconvolution Abstract: In this paper, we study sparse spike deconvolution over the space of\ncomplex-valued measures when the input measure is a finite sum of Dirac masses.\nWe introduce a modified version of the Beurling Lasso (BLasso), a semi-definite\nprogram that we refer to as the Concomitant Beurling Lasso (CBLasso). This new\nprocedure estimates the target measure and the unknown noise level\nsimultaneously. Contrary to previous estimators in the literature, theory holds\nfor a tuning parameter that depends only on the sample size, so that it can be\nused for unknown noise level problems. Consistent noise level estimation is\nstandardly proved. As for Radon measure estimation, theoretical guarantees\nmatch the previous state-of-the-art results in Super-Resolution regarding\nminimax prediction and localization. The proofs are based on a bound on the\nnoise level given by a new tail estimate of the supremum of a stationary\nnon-Gaussian process through the Rice method. \n\n"}
{"id": "1606.05834", "contents": "Title: Convergence of Nonlinear Observers on R^n with a Riemannian Metric (Part\n  II) Abstract: In [1], it is established that a convergent observer with an infinite gain\nmargin can be designed for a given nonlinear system when a Riemannian metric\nshowing that the system is differentially detectable (i.e., the Lie derivative\nof the Riemannian metric along the system vector field is negative in the space\ntangent to the output function level sets) and the level sets of the output\nfunction are geodesically convex is available. In this paper, we propose\ntechniques for designing a Riemannian metric satisfying the first property in\nthe case where the system is strongly infinitesimally observable (i.e., each\ntime-varying linear system resulting from the linearization along a solution to\nthe system satisfies a uniform observability property) or where it is strongly\ndifferentially observable (i.e. the mapping state to output derivatives is an\ninjective immersion) or where it is Lagrangian. Also, we give results that are\ncomplementary to those in [1]. In particular, we provide a locally convergent\nobserver and make a link to the existence of a reduced order observer. Examples\nillustrating the results are presented. \n\n"}
{"id": "1606.09632", "contents": "Title: A Permutation-based Model for Crowd Labeling: Optimal Estimation and\n  Robustness Abstract: The task of aggregating and denoising crowd-labeled data has gained increased\nsignificance with the advent of crowdsourcing platforms and massive datasets.\nWe propose a permutation-based model for crowd labeled data that is a\nsignificant generalization of the classical Dawid-Skene model, and introduce a\nnew error metric by which to compare different estimators. We derive global\nminimax rates for the permutation-based model that are sharp up to logarithmic\nfactors, and match the minimax lower bounds derived under the simpler\nDawid-Skene model. We then design two computationally-efficient estimators: the\nWAN estimator for the setting where the ordering of workers in terms of their\nabilities is approximately known, and the OBI-WAN estimator where that is not\nknown. For each of these estimators, we provide non-asymptotic bounds on their\nperformance. We conduct synthetic simulations and experiments on real-world\ncrowdsourcing data, and the experimental results corroborate our theoretical\nfindings. \n\n"}
{"id": "1607.00356", "contents": "Title: Design of Robust, Protograph Based LDPC Codes for Rate-Adaptation via\n  Probabilistic Shaping Abstract: In this work, the design of robust, protograph-based low-density parity-check\n(LDPC) codes for rate-adaptive communication via probabilistic shaping is\nconsidered. Recently, probabilistic amplitude shaping (PAS) by B\\\"ocherer et\nal. has been introduced for capacity approaching and rate-adaptive\ncommunication with a bitwise-demapper and binary decoder. Previous work by the\nauthors considered the optimization of protograph based LDPC codes for PAS and\nspecific spectral efficiencies (SEs) to jointly optimize the LDPC code node\ndegrees and the mapping of the coded bits to the bit-interleaved coded\nmodulation (BICM) bit-channels. We show that these codes tend to perform poor\nwhen operated at other rates and propose the design of robust LDPC codes by\nemploying a min-max approach in the search for good protograph ensembles via\ndifferential evolution. The considered design uses a single 16\namplitude-shift-keying (ASK) constellation and a robust 13/16 rate LDPC code to\noperate between 0.7 to 2.7 bits per channel use. For a blocklength of 16224\nbits and a target frame error rate of 1e-3 the proposed code operates within\n1.32 dB of continuous AWGN capacity for 0.7 to 1.3 bpcu and within 1.05 dB for\n1.3 bpcu to 2.7 bpcu. \n\n"}
{"id": "1607.01796", "contents": "Title: Entropy accumulation Abstract: We ask the question whether entropy accumulates, in the sense that the\noperationally relevant total uncertainty about an $n$-partite system $A = (A_1,\n\\ldots A_n)$ corresponds to the sum of the entropies of its parts $A_i$. The\nAsymptotic Equipartition Property implies that this is indeed the case to first\norder in $n$, under the assumption that the parts $A_i$ are identical and\nindependent of each other. Here we show that entropy accumulation occurs more\ngenerally, i.e., without an independence assumption, provided one quantifies\nthe uncertainty about the individual systems $A_i$ by the von Neumann entropy\nof suitably chosen conditional states. The analysis of a large system can hence\nbe reduced to the study of its parts. This is relevant for applications. In\ndevice-independent cryptography, for instance, the approach yields essentially\noptimal security bounds valid for general attacks, as shown by Arnon-Friedman\net al. \n\n"}
{"id": "1607.02481", "contents": "Title: Inferring monopartite projections of bipartite networks: an\n  entropy-based approach Abstract: Bipartite networks are currently regarded as providing a major insight into\nthe organization of many real-world systems, unveiling the mechanisms driving\nthe interactions occurring between distinct groups of nodes. One of the most\nimportant issues encountered when modeling bipartite networks is devising a way\nto obtain a (monopartite) projection on the layer of interest, which preserves\nas much as possible the information encoded into the original bipartite\nstructure. In the present paper we propose an algorithm to obtain\nstatistically-validated projections of bipartite networks, according to which\nany two nodes sharing a statistically-significant number of neighbors are\nlinked. Since assessing the statistical significance of nodes similarity\nrequires a proper statistical benchmark, here we consider a set of four null\nmodels, defined within the exponential random graph framework. Our algorithm\noutputs a matrix of link-specific p-values, from which a validated projection\nis straightforwardly obtainable, upon running a multiple hypothesis testing\nprocedure. Finally, we test our method on an economic network (i.e. the\ncountries-products World Trade Web representation) and a social network (i.e.\nMovieLens, collecting the users' ratings of a list of movies). In both cases\nnon-trivial communities are detected: while projecting the World Trade Web on\nthe countries layer reveals modules of similarly-industrialized nations,\nprojecting it on the products layer allows communities characterized by an\nincreasing level of complexity to be detected; in the second case, projecting\nMovieLens on the films layer allows clusters of movies whose affinity cannot be\nfully accounted for by genre similarity to be individuated. \n\n"}
{"id": "1607.02817", "contents": "Title: Binary Codes with Locality for Four Erasures Abstract: In this paper, codes with locality for four erasures are considered. An upper\nbound on the rate of codes with locality with sequential recovery from four\nerasures is derived. The rate bound derived here is field independent. An\noptimal construction for binary codes meeting this rate bound is also provided.\nThe construction is based on regular graphs of girth $6$ and employs the\nsequential approach of locally recovering from multiple erasures. An extension\nof this construction that generates codes which can sequentially recover from\nfive erasures is also presented. \n\n"}
{"id": "1607.05332", "contents": "Title: Detecting Byzantine Attacks Without Clean Reference Abstract: We consider an amplify-and-forward relay network composed of a source, two\nrelays, and a destination. In this network, the two relays are untrusted in the\nsense that they may perform Byzantine attacks by forwarding altered symbols to\nthe destination. Note that every symbol received by the destination may be\naltered, and hence no clean reference observation is available to the\ndestination. For this network, we identify a large family of Byzantine attacks\nthat can be detected in the physical layer. We further investigate how the\nchannel conditions impact the detection against this family of attacks. In\nparticular, we prove that all Byzantine attacks in this family can be detected\nwith asymptotically small miss detection and false alarm probabilities by using\na sufficiently large number of channel observations \\emph{if and only if} the\nnetwork satisfies a non-manipulability condition. No pre-shared secret or\nsecret transmission is needed for the detection of these attacks, demonstrating\nthe value of this physical-layer security technique for counteracting Byzantine\nattacks. \n\n"}
{"id": "1607.05838", "contents": "Title: On the dimension of twisted centralizer codes Abstract: Given a field $F$, a scalar $\\lambda\\in F$ and a matrix $A\\in F^{n\\times n}$,\nthe twisted centralizer code $C_F(A,\\lambda):=\\{B\\in F^{n\\times n}\\mid\nAB-\\lambda BA=0\\}$ is a linear code of length $n^2$. When $A$ is cyclic and\n$\\lambda\\ne0$ we prove that $\\dim\nC_F(A,\\lambda)=\\mathrm{deg}(\\gcd(c_A(t),\\lambda^n c_A(\\lambda^{-1}t)))$ where\n$c_A(t)$ denotes the characteristic polynomial of $A$. We also show how\n$C_F(A,\\lambda)$ decomposes, and we estimate the probability that\n$C_F(A,\\lambda)$ is nonzero when $|F|$ is finite. Finally, we prove $\\dim\nC_F(A,\\lambda)\\leqslant n^2/2$ for $\\lambda\\not\\in\\{0,1\\}$ and `almost all'\nmatrices $A$. \n\n"}
{"id": "1607.07335", "contents": "Title: An Explicit, Coupled-Layer Construction of a High-Rate MSR Code with Low\n  Sub-Packetization Level, Small Field Size and All-Node Repair Abstract: This paper presents an explicit construction for an $((n,k,d=n-1),\n(\\alpha,\\beta))$ regenerating code over a field $\\mathbb{F}_Q$ operating at the\nMinimum Storage Regeneration (MSR) point. The MSR code can be constructed to\nhave rate $k/n$ as close to $1$ as desired, sub-packetization given by\n$r^{\\frac{n}{r}}$, for $r=(n-k)$, field size no larger than $n$ and where all\ncode symbols can be repaired with the same minimum data download. The\nconstruction modifies a prior construction by Sasidharan et. al. which required\nfar larger field-size. A building block appearing in the construction is a\nscalar MDS code of block length $n$. The code has a simple layered structure\nwith coupling across layers, that allows both node repair and data recovery to\nbe carried out by making multiple calls to a decoder for the scalar MDS code.\nWhile this work was carried out independently, there is considerable overlap\nwith a prior construction by Ye and Barg.\n  It is shown here that essentially the same architecture can be employed to\nconstruct MSR codes using vector binary MDS codes as building blocks in place\nof scalar MDS codes. The advantage here is that computations can now be carried\nout over a field of smaller size potentially even over the binary field as we\ndemonstrate in an example. Further, we show how the construction can be\nextended to handle the case of $d<(n-1)$ under a mild restriction on the choice\nof helper nodes. \n\n"}
{"id": "1607.07514", "contents": "Title: Tweet2Vec: Learning Tweet Embeddings Using Character-level CNN-LSTM\n  Encoder-Decoder Abstract: We present Tweet2Vec, a novel method for generating general-purpose vector\nrepresentation of tweets. The model learns tweet embeddings using\ncharacter-level CNN-LSTM encoder-decoder. We trained our model on 3 million,\nrandomly selected English-language tweets. The model was evaluated using two\nmethods: tweet semantic similarity and tweet sentiment categorization,\noutperforming the previous state-of-the-art in both tasks. The evaluations\ndemonstrate the power of the tweet embeddings generated by our model for\nvarious tweet categorization tasks. The vector representations generated by our\nmodel are generic, and hence can be applied to a variety of tasks. Though the\nmodel presented in this paper is trained on English-language tweets, the method\npresented can be used to learn tweet embeddings for different languages. \n\n"}
{"id": "1608.00269", "contents": "Title: Enhanced Cellular Coverage and Throughput using Rateless Codes Abstract: Rateless codes have been shown to provide robust error correction over a wide\nrange of binary and noisy channels. Using a stochastic geometry model, this\npaper studies the performance of rateless codes in the cellular downlink and\ncompares it with the performance of fixed-rate codes. For the case of Rayleigh\nfading, an accurate approximation is proposed for the distribution of the\npacket transmission time of $K$-bit information packets using rateless codes.\nThe two types of channel coding schemes are compared by evaluating the typical\nuser and per-user success probability and the rate. Based on both the\nanalytical results and simulations, the paper shows that rateless coding\nprovides a significant throughput gain relative to fixed-rate coding. Moreover\nthe benefit is not restricted to the typical user but applies to all users in\nthe cellular network. \n\n"}
{"id": "1608.02424", "contents": "Title: The Renyi Capacity and Center Abstract: Renyi's information measures ---the Renyi information, mean, capacity,\nradius, and center--- are analyzed relying on the elementary properties of the\nRenyi divergence and the power means. The van Erven-Harremoes conjecture is\nproved for any positive order and for any set of probability measures on a\ngiven measurable space and a generalization of it is established for the\nconstrained variant of the problem. The finiteness of the order $\\alpha$ Renyi\ncapacity is shown to imply the continuity of the Renyi capacity on $(0,\\alpha]$\nand the uniform equicontinuity of the Renyi information, both as a family of\nfunctions of the order indexed by the priors and as a family of functions of\nthe prior indexed by the orders. The Renyi capacities and centers of various\nfamilies of Poisson processes are derived as examples. \n\n"}
{"id": "1608.02666", "contents": "Title: Methods of tropical optimization in rating alternatives based on\n  pairwise comparisons Abstract: We apply methods of tropical optimization to handle problems of rating\nalternatives on the basis of the log-Chebyshev approximation of pairwise\ncomparison matrices. We derive a direct solution in a closed form, and\ninvestigate the obtained solution when it is not unique. Provided the\napproximation problem yields a set of score vectors, rather than a unique (up\nto a constant factor) one, we find those vectors in the set, which least and\nmost differentiate between the alternatives with the highest and lowest scores,\nand thus can be representative of the entire solution. \n\n"}
{"id": "1608.03798", "contents": "Title: Exponential convergence under distributed averaging integral frequency\n  control Abstract: We investigate the performance and robustness of distributed averaging\nintegral controllers used in the optimal frequency regulation of power\nnetworks. We construct a strict Lyapunov function that allows us to quantify\nthe exponential convergence rate of the closed-loop system. As an application,\nwe study the stability of the system in the presence of disruptions to the\ncontrollers' communication network, and investigate how the convergence rate is\naffected by these disruptions. \n\n"}
{"id": "1608.04079", "contents": "Title: Twisted Centralizer Codes Abstract: Given an $n\\times n$ matrix $A$ over a field $F$ and a scalar $a\\in F$, we\nconsider the linear codes $C(A,a):=\\{B\\in F^{n\\times n}\\mid \\,AB=aBA\\}$ of\nlength $n^2$. We call $C(A,a)$ a twisted centralizer code. We investigate\nproperties of these codes including their dimensions, minimum distances,\nparity-check matrices, syndromes, and automorphism groups. The minimal distance\nof a centralizer code (when $a=1$) is at most $n$, however for $a\\ne 0,1$ the\nminimal distance can be much larger, as large as $n^2$. \n\n"}
{"id": "1608.04271", "contents": "Title: Nonuniform probability modulation for reducing energy consumption of\n  remote sensors Abstract: One of the main goals of 5G wireless telecommunication technology is\nimproving energy efficiency, especially of remote sensors which should be able\nfor example to transmit on average 1bit/s for 10 years from a single AAA\nbattery. There will be discussed using modulation with nonuniform probability\ndistribution of symbols for improving energy efficiency of transmission at cost\nof reduced throughput. While the zero-signal (silence) has zero energy cost to\nemit, it can carry information if used alongside other symbols. If used more\nfrequently than others, for example for majority of time slots or OFDM\nsubcarriers, the number of bits transmitted per energy unit can be\nsignificantly increased. For example for hexagonal modulation and zero noise,\nthis amount of bits per energy unit can be doubled by reducing throughput 2.7\ntimes, thanks to using the zero-signal with probability $\\approx$ 0.84. There\nwill be discussed models and methods for such nonuniform probability\nmodulations (NPM). \n\n"}
{"id": "1608.08237", "contents": "Title: Clustering determines the dynamics of complex contagions in multiplex\n  networks Abstract: We present the mathematical analysis of generalized complex contagions in\nclustered multiplex networks for susceptible-infected-recovered (SIR)-like\ndynamics. The model is intended to understand diffusion of influence, or any\nother spreading process implying a threshold dynamics, in setups of\ninterconnected networks with significant clustering. The contagion is assumed\nto be general enough to account for a content-dependent linear threshold model,\nwhere each link type has a different weight (for spreading influence) that may\ndepend on the content (e.g., product, rumor, political view) that is being\nspread. Using the generating functions formalism, we determine the conditions,\nprobability, and expected size of the emergent global cascades. This analysis\nprovides a generalization of previous approaches and is specially useful in\nproblems related to spreading and percolation. The results present non trivial\ndependencies between the clustering coefficient of the networks and its average\ndegree. In particular, several phase transitions are shown to occur depending\non these descriptors. Generally speaking, our findings reveal that increasing\nclustering decreases the probability of having global cascades and their size,\nhowever this tendency changes with the average degree. There exists a certain\naverage degree from which on clustering favours the probability and size of the\ncontagion. By comparing the dynamics of complex contagions over multiplex\nnetworks and their monoplex projections, we demonstrate that ignoring link\ntypes and aggregating network layers may lead to inaccurate conclusions about\ncontagion dynamics, particularly when the correlation of degrees between layers\nis high. \n\n"}
{"id": "1608.08313", "contents": "Title: Sub-channel Assignment, Power Allocation and User Scheduling for\n  Non-Orthogonal Multiple Access Networks Abstract: In this paper, we study the resource allocation and user scheduling problem\nfor a downlink nonorthogonal multiple access network where the base station\nallocates spectrum and power resources to a set of users. We aim to jointly\noptimize the sub-channel assignment and power allocation to maximize the\nweighted total sum-rate while taking into account user fairness. We formulate\nthe sub-channel allocation problem as equivalent to a many-to-many two-sided\nuser-subchannel matching game in which the set of users and sub-channels are\nconsidered as two sets of players pursuing their own interests. We then propose\na matching algorithm which converges to a two-side exchange stable matching\nafter a limited number of iterations. A joint solution is thus provided to\nsolve the sub-channel assignment and power allocation problems iteratively.\nSimulation results show that the proposed algorithm greatly outperforms the\northogonal multiple access scheme and a previous non-orthogonal multiple access\nscheme. \n\n"}
{"id": "1609.03142", "contents": "Title: Exact Dimensionality Reduction for Partial Line Spectra Estimation\n  Problems Abstract: Line spectral estimation theory aims to estimate the off-the-grid spectral\ncomponents of a time signal with optimal precision. Recent results have shown\nthat it is possible to recover signals having sparse line spectra from few\ntemporal observations via the use of convex programming. However, the\ncomputational cost of such approaches remains the major flaw to their\napplication to practical systems. This work investigates the recovery of\nspectrally sparse signal from low-dimensional partial measurements. It is shown\nin the first part of this paper that, under a light assumption on the\nsub-sampling matrix, the partial line spectral estimation problems can be\nrelaxed into a low-dimensional semidefinite program. The proof technique relies\non a novel extension of the Gram parametrization to subspaces of trigonometric\npolynomials.\n  The second part of this work focuses on the analysis of two particular\nsub-sampling patterns: multirate sampling and random selection sampling. It is\nshown that those sampling patterns guarantee perfect recovery of the line\nspectra, and that the reconstruction can be achieved in a poly-logarithmic time\nwith respect to the full observation case. Moreover, the sub-Nyquist recovery\ncapabilities of such sampling patterns are highlighted. The atomic soft\nthresholding method is adapted in the presented framework to estimate sparse\nspectra in noisy environments, and a scalable algorithm for its resolution is\nproposed. \n\n"}
{"id": "1609.05043", "contents": "Title: Linear representations of convolutional codes over rings Abstract: In this paper we extend the relation between convolutional codes and linear\nsystems over finite fields to certain commutative rings through first order\nrepresentations . We introduce the definition of rings with representations as\nthose for which these representations always exist, and we show that finite\nproducts of finite fields belong to this class. We develop the\ninput/state/output representations for convolutional codes over these rings,\nand we show how to use them to construct observable convolutional codes as in\nthe classical case. \n\n"}
{"id": "1609.05334", "contents": "Title: What makes people bond?: A study on social interactions and common life\n  points on Facebook Abstract: In this paper we aim at understanding if and how, by analysing people's\nprofile and historical data (such as data available on Facebook profiles and\ninteractions, or collected explicitly) we can motivate two persons to interact\nand eventually create long-term bonds. We do this by exploring the relationship\nbetween connectedness, social interactions and common life points on Facebook.\nThe results are of particular importance for the development of technology that\naims at reducing social isolation for people with less chances to interact,\nsuch as older adults. \n\n"}
{"id": "1609.07866", "contents": "Title: Role of Interference Alignment in Wireless Cellular Network Optimization Abstract: The emergence of interference alignment (IA) as a degrees-of-freedom optimal\nstrategy motivates the need to investigate whether IA can be leveraged to aid\nconventional network optimization algorithms that are only capable of finding\nlocally optimal solutions. To test the usefulness of IA in this context, this\npaper proposes a two-stage optimization framework for the downlink of a\n$G$-cell multi-antenna network with $K$ users/cell. The first stage of the\nproposed framework focuses on nulling interference from a set of dominant\ninterferers using IA, while the second stage optimizes transmit and receive\nbeamformers to maximize a network-wide utility using the IA solution as the\ninitial condition. Further, this paper establishes a set of new feasibility\nresults for partial IA that can be used to guide the number of dominant\ninterferers to be nulled in the first stage. Through simulations on specific\ntopologies of a cluster of base-stations, it is observed that the impact of IA\ndepends on the choice of the utility function and the presence of\nout-of-cluster interference. In the absence of out-of-cluster interference, the\nproposed framework outperforms straightforward optimization when maximizing the\nminimum rate, while providing marginal gains when maximizing sum-rate. However,\nthe benefit of IA is greatly diminished in the presence of significant\nout-of-cluster interference. \n\n"}
{"id": "1609.09530", "contents": "Title: Fast L1-L2 minimization via a proximal operator Abstract: This paper aims to develop new and fast algorithms for recovering a sparse\nvector from a small number of measurements, which is a fundamental problem in\nthe field of compressive sensing (CS). Currently, CS favors incoherent systems,\nin which any two measurements are as little correlated as possible. In reality,\nhowever, many problems are coherent, and conventional methods such as $L_1$\nminimization do not work well. Recently, the difference of the $L_1$ and $L_2$\nnorms, denoted as $L_1$-$L_2$, is shown to have superior performance over the\nclassic $L_1$ method, but it is computationally expensive. We derive an\nanalytical solution for the proximal operator of the $L_1$-$L_2$ metric, and it\nmakes some fast $L_1$ solvers such as forward-backward splitting (FBS) and\nalternating direction method of multipliers (ADMM) applicable for $L_1$-$L_2$.\nWe describe in details how to incorporate the proximal operator into FBS and\nADMM and show that the resulting algorithms are convergent under mild\nconditions. Both algorithms are shown to be much more efficient than the\noriginal implementation of $L_1$-$L_2$ based on a difference-of-convex approach\nin the numerical experiments. \n\n"}
{"id": "1610.00647", "contents": "Title: Secure Massive MIMO Systems with Limited RF Chains Abstract: In future practical deployments of massive multi-input multi-output (MIMO)\nsystems, the number of radio frequency (RF) chains at the base stations (BSs)\nmay be much smaller than the number of BS antennas to reduce the overall\nexpenditure. In this paper, we propose a novel design framework for joint data\nand artificial noise (AN) precoding in a multiuser massive MIMO system with\nlimited number of RF chains, which improves the wireless security performance.\nWith imperfect channel state information (CSI), we analytically derive an\nachievable lower bound on the ergodic secrecy rate of any mobile terminal (MT),\nfor both analog and hybrid precoding schemes. The closed-form lower bound is\nused to determine optimal power splitting between data and AN that maximizes\nthe secrecy rate through simple one-dimensional search. Analytical and\nnumerical results together reveal that the proposed hybrid precoder, although\nsuffers from reduced secrecy rate compared with theoretical full-dimensional\nprecoder, is free of the high computational complexity of large-scale matrix\ninversion and null-space calculations, and largely reduces the hardware cost. \n\n"}
{"id": "1610.02620", "contents": "Title: Reconstruction of signals from their autocorrelation and\n  cross-correlation vectors, with applications to phase retrieval and blind\n  channel estimation Abstract: We consider the problem of reconstructing two signals from the\nautocorrelation and cross-correlation measurements. This inverse problem is a\nfundamental one in signal processing, and arises in many applications,\nincluding phase retrieval and blind channel estimation. In a typical phase\nretrieval setup, only the autocorrelation measurements are obtainable. We show\nthat, when the measurements are obtained using three simple \"masks\", phase\nretrieval reduces to the aforementioned reconstruction problem.\n  The classic solution to this problem is based on finding common factors\nbetween the $z$-transforms of the autocorrelation and cross-correlation\nvectors. This solution has enjoyed limited practical success, mainly due to the\nfact that it is not sufficiently stable in the noisy setting. In this work,\ninspired by the success of convex programming in provably and stably solving\nvarious quadratic constrained problems, we develop a semidefinite\nprogramming-based algorithm and provide theoretical guarantees. In particular,\nwe show that almost all signals can be uniquely recovered by this algorithm (up\nto a global phase). Comparative numerical studies demonstrate that the proposed\nmethod significantly outperforms the classic method in the noisy setting. \n\n"}
{"id": "1610.02680", "contents": "Title: Minimax Optimality of Shiryaev-Roberts Procedure for Quickest Drift\n  Change Detection of a Brownian motion Abstract: The problem of detecting a change in the drift of a Brownian motion is\nconsidered. The change point is assumed to have a modified exponential prior\ndistribution with unknown parameters. A worst-case analysis with respect to\nthese parameters is adopted leading to a min-max problem formulation.\nAnalytical and numerical justifications are provided towards establishing that\nthe Shiryaev-Roberts procedure with a specially designed starting point is\nexactly optimal for the proposed mathematical setup. \n\n"}
{"id": "1610.04714", "contents": "Title: A New Perspective on Randomized Gossip Algorithms Abstract: In this short note we propose a new approach for the design and analysis of\nrandomized gossip algorithms which can be used to solve the average consensus\nproblem. We show how that Randomized Block Kaczmarz (RBK) method - a method for\nsolving linear systems - works as gossip algorithm when applied to a special\nsystem encoding the underlying network. The famous pairwise gossip algorithm\narises as a special case. Subsequently, we reveal a hidden duality of\nrandomized gossip algorithms, with the dual iterative process maintaining a set\nof numbers attached to the edges as opposed to nodes of the network. We prove\nthat RBK obtains a superlinear speedup in the size of the block, and\ndemonstrate this effect through experiments. \n\n"}
{"id": "1610.04804", "contents": "Title: Dynamic Stacked Generalization for Node Classification on Networks Abstract: We propose a novel stacked generalization (stacking) method as a dynamic\nensemble technique using a pool of heterogeneous classifiers for node label\nclassification on networks. The proposed method assigns component models a set\nof functional coefficients, which can vary smoothly with certain topological\nfeatures of a node. Compared to the traditional stacking model, the proposed\nmethod can dynamically adjust the weights of individual models as we move\nacross the graph and provide a more versatile and significantly more accurate\nstacking model for label prediction on a network. We demonstrate the benefits\nof the proposed model using both a simulation study and real data analysis. \n\n"}
{"id": "1610.05045", "contents": "Title: Validation of community robustness Abstract: The large amount of work on community detection and its applications leaves\nunaddressed one important question: the statistical validation of the results.\nIn this paper we present a methodology able to clearly detect if the community\nstructure found by some algorithms is statistically significant or is a result\nof chance, merely due to edge positions in the network. Given a community\ndetection method and a network of interest, our proposal examines the stability\nof the partition recovered against random perturbations of the original graph\nstructure. To address this issue, we specify a perturbation strategy and a null\nmodel to build a set of procedures based on a special measure of clustering\ndistance, namely Variation of Information, using tools set up for functional\ndata analysis. The procedures determine whether the obtained clustering departs\nsignificantly from the null model. This strongly supports the robustness\nagainst perturbation of the algorithm used to identify the community structure.\nWe show the results obtained with the proposed technique on simulated and real\ndatasets. \n\n"}
{"id": "1610.05210", "contents": "Title: Achieving Perfect Location Privacy in Wireless Devices Using\n  Anonymization Abstract: The popularity of mobile devices and location-based services (LBS) has\ncreated great concern regarding the location privacy of their users.\nAnonymization is a common technique that is often used to protect the location\nprivacy of LBS users. Here, we present an information-theoretic approach to\ndefine the notion of perfect location privacy. We show how LBS's should use the\nanonymization method to ensure that their users can achieve perfect location\nprivacy. First, we assume that a user's current location is independent from\nher past locations. Using this i.i.d model, we show that if the pseudonym of\nthe user is changed before $O(n^{\\frac{2}{r-1}})$ observations are made by the\nadversary for that user, then the user has perfect location privacy. Here, n is\nthe number of the users in the network and r is the number of all possible\nlocations that users can go to. Next, we model users' movements using Markov\nchains to better model real-world movement patterns. We show that perfect\nlocation privacy is achievable for a user if the user's pseudonym is changed\nbefore $O(n^{\\frac{2}{|E|-r}})$ observations are collected by the adversary for\nthe user, where |E| is the number of edges in the user's Markov chain model. \n\n"}
{"id": "1610.05516", "contents": "Title: Active Network Alignment: A Matching-Based Approach Abstract: Network alignment is the problem of matching the nodes of two graphs,\nmaximizing the similarity of the matched nodes and the edges between them. This\nproblem is encountered in a wide array of applications-from biological networks\nto social networks to ontologies-where multiple networked data sources need to\nbe integrated. Due to the difficulty of the task, an accurate alignment can\nrarely be found without human assistance. Thus, it is of great practical\nimportance to develop network alignment algorithms that can optimally leverage\nexperts who are able to provide the correct alignment for a small number of\nnodes. Yet, only a handful of existing works address this active network\nalignment setting.\n  The majority of the existing active methods focus on absolute queries (\"are\nnodes $a$ and $b$ the same or not?\"), whereas we argue that it is generally\neasier for a human expert to answer relative queries (\"which node in the set\n$\\{b_1, \\ldots, b_n\\}$ is the most similar to node $a$?\"). This paper\nintroduces two novel relative-query strategies, TopMatchings and\nGibbsMatchings, which can be applied on top of any network alignment method\nthat constructs and solves a bipartite matching problem. Our methods identify\nthe most informative nodes to query by sampling the matchings of the bipartite\ngraph associated to the network-alignment instance.\n  We compare the proposed approaches to several commonly-used query strategies\nand perform experiments on both synthetic and real-world datasets. Our\nsampling-based strategies yield the highest overall performance, outperforming\nall the baseline methods by more than 15 percentage points in some cases. In\nterms of accuracy, TopMatchings and GibbsMatchings perform comparably. However,\nGibbsMatchings is significantly more scalable, but it also requires\nhyperparameter tuning for a temperature parameter. \n\n"}
{"id": "1610.05932", "contents": "Title: An algorithmic approach using multivariate polynomials for the\n  nonlinearity of Boolean functions Abstract: The nonlinearity of a Boolean function is a key property in deciding its\nsuitability for cryptographic purposes, e.g. as a combining function in stream\nciphers, and so the nonlinearity computation is an important problem for\napplications. Traditional methods to compute the nonlinearity are based on\ntransforms, such as the Fast Walsh Transform. In 2007 Simonetti proposed a\nmethod to solve the above problem seen as a decision problem on the existence\nof solutions for some multivariate polynomial systems. Although novel as\napproach, her algorithm suffered from a direct application of Groebner bases\nand was thus impractical. We now propose two more practical approaches, one\nthat determines the existence of solutions for Simonetti's systems in a faster\nway and another that writes similar systems but over fields with a different\ncharacteristics. For our algorithms we provide an efficient implementation in\nthe software package MAGMA. \n\n"}
{"id": "1610.06363", "contents": "Title: Improved constructions of nested code pairs Abstract: Two new constructions of linear code pairs $C_2 \\subset C_1$ are given for\nwhich the codimension and the relative minimum distances $M_1(C_1,C_2)$,\n$M_1(C_2^\\perp,C_1^\\perp)$ are good. By this we mean that for any two out of\nthe three parameters the third parameter of the constructed code pair is large.\nSuch pairs of nested codes are indispensable for the determination of good\nlinear ramp secret sharing schemes [35]. They can also be used to ensure\nreliable communication over asymmetric quantum channels [47]. The new\nconstructions result from carefully applying the Feng-Rao bounds [18,27] to a\nfamily of codes defined from multivariate polynomials and Cartesian product\npoint sets. \n\n"}
{"id": "1610.07108", "contents": "Title: Fast and Reliable Parameter Estimation from Nonlinear Observations Abstract: In this paper we study the problem of recovering a structured but unknown\nparameter ${\\bf{\\theta}}^*$ from $n$ nonlinear observations of the form\n$y_i=f(\\langle {\\bf{x}}_i,{\\bf{\\theta}}^*\\rangle)$ for $i=1,2,\\ldots,n$. We\ndevelop a framework for characterizing time-data tradeoffs for a variety of\nparameter estimation algorithms when the nonlinear function $f$ is unknown.\nThis framework includes many popular heuristics such as projected/proximal\ngradient descent and stochastic schemes. For example, we show that a projected\ngradient descent scheme converges at a linear rate to a reliable solution with\na near minimal number of samples. We provide a sharp characterization of the\nconvergence rate of such algorithms as a function of sample size, amount of\na-prior knowledge available about the parameter and a measure of the\nnonlinearity of the function $f$. These results provide a precise understanding\nof the various tradeoffs involved between statistical and computational\nresources as well as a-prior side information available for such nonlinear\nparameter estimation problems. \n\n"}
{"id": "1610.07304", "contents": "Title: A Rate-Distortion Approach to Caching Abstract: This paper takes a rate-distortion approach to understanding the\ninformation-theoretic laws governing cache-aided communications systems.\nSpecifically, we characterise the optimal tradeoffs between the delivery rate,\ncache capacity and reconstruction distortions for a single-user problem and\nsome special cases of a two-user problem. Our analysis considers discrete\nmemoryless sources, expected- and excess-distortion constraints, and separable\nand f-separable distortion functions. We also establish a strong converse for\nseparable-distortion functions, and we show that lossy versions of common\ninformation (G\\'{a}cs-K\\\"{o}rner and Wyner) play an important role in caching.\nFinally, we illustrate and explicitly evaluate these laws for multivariate\nGaussian sources and binary symmetric sources. \n\n"}
{"id": "1610.07531", "contents": "Title: PhaseMax: Convex Phase Retrieval via Basis Pursuit Abstract: We consider the recovery of a (real- or complex-valued) signal from\nmagnitude-only measurements, known as phase retrieval. We formulate phase\nretrieval as a convex optimization problem, which we call PhaseMax. Unlike\nother convex methods that use semidefinite relaxation and lift the phase\nretrieval problem to a higher dimension, PhaseMax is a \"non-lifting\" relaxation\nthat operates in the original signal dimension. We show that the dual problem\nto PhaseMax is Basis Pursuit, which implies that phase retrieval can be\nperformed using algorithms initially designed for sparse signal recovery. We\ndevelop sharp lower bounds on the success probability of PhaseMax for a broad\nrange of random measurement ensembles, and we analyze the impact of measurement\nnoise on the solution accuracy. We use numerical results to demonstrate the\naccuracy of our recovery guarantees, and we showcase the efficacy and limits of\nPhaseMax in practice. \n\n"}
{"id": "1610.07578", "contents": "Title: On capacity of optical communications over a lossy bosonic channel with\n  a receiver employing the most general coherent electro-optic feedback control Abstract: We study the problem of designing optical receivers to discriminate between\nmultiple coherent states using coherent processing receivers---i.e., one that\nuses arbitrary coherent feedback control and quantum-noise-limited direct\ndetection---which was shown by Dolinar to achieve the minimum error probability\nin discriminating any two coherent states. We first derive and re-interpret\nDolinar's binary-hypothesis minimum-probability-of-error receiver as the one\nthat optimizes the information efficiency at each time instant, based on\nrecursive Bayesian updates within the receiver. Using this viewpoint, we\npropose a natural generalization of Dolinar's receiver design to discriminate\n$M$ coherent states each of which could now be a codeword, i.e., a sequence of\n$N$ coherent states each drawn from a modulation alphabet. We analyze the\nchannel capacity of the pure-loss optical channel with a general\ncoherent-processing receiver in the low-photon number regime and compare it\nwith the capacity achievable with direct detection and the Holevo limit\n(achieving the latter would require a quantum joint-detection receiver). We\nshow compelling evidence that despite the optimal performance of Dolinar's\nreceiver for the binary coherent-state hypothesis test (either in error\nprobability or mutual information), the asymptotic communication rate\nachievable by such a coherent-processing receiver is only as good as direct\ndetection. This suggests that in the infinitely-long codeword limit, all\npotential benefits of coherent processing at the receiver can be obtained by\ndesigning a good code and direct detection, with no feedback within the\nreceiver. \n\n"}
{"id": "1610.08004", "contents": "Title: On Fractional Linear Network Coding Solution of Multiple-Unicast\n  Networks Abstract: It is known that there exists a multiple-unicast network which has a rate $1$\nlinear network coding solution if and only if the characteristic of the finite\nfield belongs to a given finite or co-finite set of primes. In this paper, we\nshow that for any non-zero positive rational number $\\frac{k}{n}$, there exists\na multiple-unicast network which has a rate $\\frac{k}{n}$ fractional linear\nnetwork coding solution if and only if the characteristic of the finite field\nbelongs to a given finite or co-finite set of primes. \n\n"}
{"id": "1610.09486", "contents": "Title: Evangelism in Social Networks: Algorithms and Complexity Abstract: We consider a population of interconnected individuals that, with respect to\na piece of information, at each time instant can be subdivided into three\n(time-dependent) categories: agnostics, influenced, and evangelists. A\ndynamical process of information diffusion evolves among the individuals of the\npopulation according to the following rules. Initially, all individuals are\nagnostic. Then, a set of people is chosen from the outside and convinced to\nstart evangelizing, i.e., to start spreading the information. When a number of\nevangelists, greater than a given threshold, communicate with a node v, the\nnode v becomes influenced, whereas, as soon as the individual v is contacted by\na sufficiently much larger number of evangelists, it is itself converted into\nan evangelist and consequently it starts spreading the information. The\nquestion is: How to choose a bounded cardinality initial set of evangelists so\nas to maximize the final number of influenced individuals? We prove that the\nproblem is hard to solve, even in an approximate sense. On the positive side,\nwe present exact polynomial time algorithms for trees and complete graphs. For\ngeneral graphs, we derive exact parameterized algorithms. We also investigate\nthe problem when the objective is to select a minimum number of evangelists\ncapable of influencing the whole network. Our motivations to study these\nproblems come from the areas of Viral Marketing and the analysis of\nquantitative models of spreading of influence in social networks. \n\n"}
{"id": "1610.09540", "contents": "Title: Solving Large-scale Systems of Random Quadratic Equations via Stochastic\n  Truncated Amplitude Flow Abstract: A novel approach termed \\emph{stochastic truncated amplitude flow} (STAF) is\ndeveloped to reconstruct an unknown $n$-dimensional real-/complex-valued signal\n$\\bm{x}$ from $m$ `phaseless' quadratic equations of the form\n$\\psi_i=|\\langle\\bm{a}_i,\\bm{x}\\rangle|$. This problem, also known as phase\nretrieval from magnitude-only information, is \\emph{NP-hard} in general.\nAdopting an amplitude-based nonconvex formulation, STAF leads to an iterative\nsolver comprising two stages: s1) Orthogonality-promoting initialization\nthrough a stochastic variance reduced gradient algorithm; and, s2) A series of\niterative refinements of the initialization using stochastic truncated gradient\niterations. Both stages involve a single equation per iteration, thus rendering\nSTAF a simple, scalable, and fast approach amenable to large-scale\nimplementations that is useful when $n$ is large. When $\\{\\bm{a}_i\\}_{i=1}^m$\nare independent Gaussian, STAF provably recovers exactly any\n$\\bm{x}\\in\\mathbb{R}^n$ exponentially fast based on order of $n$ quadratic\nequations. STAF is also robust in the presence of additive noise of bounded\nsupport. Simulated tests involving real Gaussian $\\{\\bm{a}_i\\}$ vectors\ndemonstrate that STAF empirically reconstructs any $\\bm{x}\\in\\mathbb{R}^n$\nexactly from about $2.3n$ magnitude-only measurements, outperforming\nstate-of-the-art approaches and narrowing the gap from the\ninformation-theoretic number of equations $m=2n-1$. Extensive experiments using\nsynthetic data and real images corroborate markedly improved performance of\nSTAF over existing alternatives. \n\n"}
{"id": "1611.00254", "contents": "Title: Community Detection in Complex Networks using Link Prediction Abstract: Community detection and link prediction are both of great significance in\nnetwork analysis, which provide very valuable insights into topological\nstructures of the network from different perspectives. In this paper, we\npropose a novel community detection algorithm with inclusion of link\nprediction, motivated by the question whether link prediction can be devoted to\nimproving the accuracy of community partition. For link prediction, we propose\ntwo novel indices to compute the similarity between each pair of nodes, one of\nwhich aims to add missing links, and the other tries to remove spurious edges.\nExtensive experiments are conducted on benchmark data sets, and the results of\nour proposed algorithm are compared with two classes of baseline. In\nconclusion, our proposed algorithm is competitive, revealing that link\nprediction does improve the precision of community detection. \n\n"}
{"id": "1611.01335", "contents": "Title: Phi-Entropic Measures of Correlation Abstract: A measure of correlation is said to have the tensorization property if it is\nunchanged when computed for i.i.d.\\ copies. More precisely, a measure of\ncorrelation between two random variables $(X, Y)$ denoted by $\\rho(X, Y)$, has\nthe tensorization property if $\\rho(X^n, Y^n)=\\rho(X, Y)$ where $(X^n, Y^n)$ is\n$n$ i.i.d.\\ copies of $(X, Y)$.Two well-known examples of such measures are the\nmaximal correlation and the hypercontractivity ribbon (HC~ribbon). We show that\nthe maximal correlation and HC ribbons are special cases of $\\Phi$-ribbon,\ndefined in this paper for any function $\\Phi$ from a class of convex functions\n($\\Phi$-ribbon reduces to HC~ribbon and the maximal correlation for special\nchoices of $\\Phi$). Any $\\Phi$-ribbon is shown to be a measures of correlation\nwith the tensorization property. We show that the $\\Phi$-ribbon also\ncharacterizes the $\\Phi$-strong data processing inequality constant introduced\nby Raginsky. We further study the $\\Phi$-ribbon for the choice of $\\Phi(t)=t^2$\nand introduce an equivalent characterization of this ribbon. \n\n"}
{"id": "1611.01546", "contents": "Title: Scalable Holistic Analysis of Multi-Source, Data-Intensive Problems\n  Using Multilayered Networks Abstract: Holistic analysis of many real-world problems are based on data collected\nfrom multiple sources contributing to some aspect of that problem. The word\nfusion has also been used in the literature for such problems involving\ndisparate data types. Holistically understanding traffic patterns, causes of\naccidents, bombings, terrorist planning and many natural phenomenon such as\nstorms, earthquakes fall into this category. Some may have real-time\nrequirements and some may need to be analyzed after the fact (post-mortem or\nforensic analysis.) What is common for all these problems is that the amount\nand types of data associated with the event. Data may also be incomplete and\ntrustworthiness of sources may also vary. Currently, manual and ad-hoc\napproaches are used in aggregating data in different ways for analyzing and\nunderstanding these problems.\n  In this paper, we approach this problem in a novel way using multilayered\nnetworks. We identify features of a central event and propose a network layer\nfor each feature. This approach allows us to study the effect of each feature\nindependently and its impact on the event. We also establish that the proposed\napproach allows us to compose these features in arbitrary ways (without loss of\ninformation) to analyze their combined effect. Additionally, formulation of\nrelationships (e.g., distance measure for a single feature instead of several\nat the same time) is simpler. Further, computations can be done once on each\nlayer in this approach and reused for mixing and matching the features for\naggregate impacts and \"what if\" scenarios to understand the problem\nholistically. This has been demonstrated by recreating the communities for the\nAND-Composed network by using the communities of the individual layers.\n  We believe that techniques proposed here make an important contribution to\nthe nascent yet fast growing area of data fusion. \n\n"}
{"id": "1611.01607", "contents": "Title: Non-Orthogonal Multiple Access in Multi-Cell Networks: Theory,\n  Performance, and Practical Challenges Abstract: Non-orthogonal multiple access (NOMA) is a potential enabler for the\ndevelopment of 5G and beyond wireless networks. By allowing multiple users to\nshare the same time and frequency, NOMA can scale up the number of served\nusers, increase the spectral efficiency, and improve user-fairness compared to\nexisting orthogonal multiple access (OMA) techniques. While single-cell NOMA\nhas drawn significant attention recently, much less attention has been given to\nmulti-cell NOMA. This article discusses the opportunities and challenges of\nNOMA in a multi-cell environment. As the density of base stations and devices\nincreases, inter-cell interference becomes a major obstacle in multi-cell\nnetworks. As such, identifying techniques that combine interference management\napproaches with NOMA is of great significance. After discussing the theory\nbehind NOMA, this paper provides an overview of the current literature and\ndiscusses key implementation and research challenges, with an emphasis on\nmulti-cell NOMA. \n\n"}
{"id": "1611.03060", "contents": "Title: The Non-convex Geometry of Low-rank Matrix Optimization Abstract: This work considers two popular minimization problems: (i) the minimization\nof a general convex function $f(\\mathbf{X})$ with the domain being positive\nsemi-definite matrices; (ii) the minimization of a general convex function\n$f(\\mathbf{X})$ regularized by the matrix nuclear norm $\\|\\mathbf{X}\\|_*$ with\nthe domain being general matrices. Despite their optimal statistical\nperformance in the literature, these two optimization problems have a high\ncomputational complexity even when solved using tailored fast convex solvers.\nTo develop faster and more scalable algorithms, we follow the proposal of Burer\nand Monteiro to factor the low-rank variable $\\mathbf{X} =\n\\mathbf{U}\\mathbf{U}^\\top $ (for semi-definite matrices) or\n$\\mathbf{X}=\\mathbf{U}\\mathbf{V}^\\top $ (for general matrices) and also replace\nthe nuclear norm $\\|\\mathbf{X}\\|_*$ with\n$(\\|\\mathbf{U}\\|_F^2+\\|\\mathbf{V}\\|_F^2)/2$. In spite of the non-convexity of\nthe resulting factored formulations, we prove that each critical point either\ncorresponds to the global optimum of the original convex problems or is a\nstrict saddle where the Hessian matrix has a strictly negative eigenvalue. Such\na nice geometric structure of the factored formulations allows many local\nsearch algorithms to find a global optimizer even with random initializations. \n\n"}
{"id": "1611.03206", "contents": "Title: Probabilistic Energy Management for Building Climate Comfort in Smart\n  Thermal Grids with Seasonal Storage Systems Abstract: This paper presents an energy management framework for building climate\ncomfort (BCC) systems interconnected in a grid via aquifer thermal energy\nstorage (ATES) systems in the presence of two types of uncertainty (private and\ncommon). ATES can be used either as a heat source (hot well) or sink (cold\nwell) depending on the season. We consider the uncertain thermal energy demand\nof individual buildings as a private uncertainty source and the uncertain\ncommon resource pool (ATES) between neighbors as a common uncertainty source.\nWe develop a large-scale stochastic hybrid dynamical model to predict the\nthermal energy imbalance in a network of interconnected BCC systems together\nwith mutual interactions between their local ATES. We formulate a\nfinite-horizon mixed-integer quadratic optimization problem with multiple\nchance constraints at each sampling time, which is in general a non-convex\nproblem and difficult to solve. We then provide a computationally tractable\nframework by extending the so-called robust randomized approach and offering a\nless conservative solution for a problem with multiple chance constraints. A\nsimulation study is provided to compare completely decoupled, centralized and\nmove-blocking centralized solutions. We also present a numerical study using a\ngeohydrological simulation environment (MODFLOW) to illustrate the advantages\nof our proposed framework. \n\n"}
{"id": "1611.04417", "contents": "Title: Leech Constellations of Construction-A Lattices Abstract: The problem of communicating over the additive white Gaussian noise (AWGN)\nchannel with lattice codes is addressed in this paper. Theoretically, Voronoi\nconstellations have proved to yield very powerful lattice codes when the\nfine/coding lattice is AWGN-good and the coarse/shaping lattice has an optimal\nshaping gain. However, achieving Shannon capacity with these premises and\npractically implementable encoding algorithms is in general not an easy task.\nIn this work, a new way to encode and demap Construction-A Voronoi lattice\ncodes is presented. As a meaningful application of this scheme, the second part\nof the paper is focused on Leech constellations of low-density Construction-A\n(LDA) lattices: LDA Voronoi lattice codes are presented whose numerically\nmeasured waterfall region is situated at less than 0.8 dB from Shannon\ncapacity. These LDA lattice codes are based on dual-diagonal nonbinary\nlow-density parity-check codes. With this choice, encoding, iterative decoding,\nand demapping have all linear complexity in the blocklength. \n\n"}
{"id": "1611.05985", "contents": "Title: Compressed Sensing from Phaseless Gaussian Measurements via Linear\n  Programming in the Natural Parameter Space Abstract: We consider faithfully combining phase retrieval with classical compressed\nsensing. Inspired by the recent novel formulation for phase retrieval called\nPhaseMax, we present and analyze SparsePhaseMax, a linear program for phaseless\ncompressed sensing in the natural parameter space. We establish that when\nprovided with an initialization that correlates with an arbitrary $k$-sparse\n$n$-vector, SparsePhaseMax recovers this vector up to global sign with high\nprobability from $O(k \\log \\frac{n}{k})$ magnitude measurements against i.i.d.\nGaussian random vectors. Our proof of this fact exploits a curious newfound\nconnection between phaseless and 1-bit compressed sensing. This is the first\nresult to establish bootstrapped compressed sensing from phaseless Gaussian\nmeasurements under optimal sample complexity. \n\n"}
{"id": "1611.06008", "contents": "Title: Multi-User Millimeter Wave MIMO with Full-Dimensional Lens Antenna Array Abstract: Millimeter wave (mmWave) communication by utilizing lens antenna arrays is a\npromising technique for realizing cost-effective 5G wireless systems with large\nMIMO (multiple-input multiple-output) but only limited radio frequency (RF)\nchains. This paper studies an uplink multi-user mmWave single-sided lens MIMO\nsystem, where only the base station (BS) is equipped with a full-dimensional\n(FD) lens antenna array with both elevation and azimuth angle resolution\ncapabilities, and each mobile station (MS) employs the conventional uniform\nplanar array (UPA) without the lens. By exploiting the angle-dependent energy\nfocusing property of the lens antenna array at the BS as well as the multi-path\nsparsity of mmWave channels, we propose a low-complexity path division multiple\naccess (PDMA) scheme, which enables virtually interference-free multi-user\ncommunications when the angle of arrivals (AoAs) of all MS multi-path signals\nare sufficiently separable at the BS. To this end, a new technique called path\ndelay compensation is proposed at the BS to effectively transform the\nmulti-user frequency-selective MIMO channels to parallel frequency-flat\nsmall-size MIMO channels for different MSs, for each of which the\nlow-complexity single-carrier(SC) transmission is applied. For general\nscenarios with insufficient AoA separations, analog beamforming at the MSs and\ndigital combining at the BS are jointly designed to maximize the achievable\nsum-rate of the MSs based on their effective MIMO channels resulting from path\ndelay compensation. In addition, we propose a new and efficient channel\nestimation scheme tailored for PDMA, which requires negligible training\noverhead in practical mmWave systems and yet leads to comparable performance as\nthat based on perfect channel state information (CSI). \n\n"}
{"id": "1611.07641", "contents": "Title: Sparse Phase Retrieval via Truncated Amplitude Flow Abstract: This paper develops a novel algorithm, termed \\emph{SPARse Truncated\nAmplitude flow} (SPARTA), to reconstruct a sparse signal from a small number of\nmagnitude-only measurements. It deals with what is also known as sparse phase\nretrieval (PR), which is \\emph{NP-hard} in general and emerges in many science\nand engineering applications. Upon formulating sparse PR as an amplitude-based\nnonconvex optimization task, SPARTA works iteratively in two stages: In stage\none, the support of the underlying sparse signal is recovered using an\nanalytically well-justified rule, and subsequently, a sparse\northogonality-promoting initialization is obtained via power iterations\nrestricted on the support; and, in the second stage, the initialization is\nsuccessively refined by means of hard thresholding based gradient-type\niterations. SPARTA is a simple yet effective, scalable, and fast sparse PR\nsolver. On the theoretical side, for any $n$-dimensional $k$-sparse ($k\\ll n$)\nsignal $\\bm{x}$ with minimum (in modulus) nonzero entries on the order of\n$(1/\\sqrt{k})\\|\\bm{x}\\|_2$, SPARTA recovers the signal exactly (up to a global\nunimodular constant) from about $k^2\\log n$ random Gaussian measurements with\nhigh probability. Furthermore, SPARTA incurs computational complexity on the\norder of $k^2n\\log n$ with total runtime proportional to the time required to\nread the data, which improves upon the state-of-the-art by at least a factor of\n$k$. Finally, SPARTA is robust against additive noise of bounded support.\nExtensive numerical tests corroborate markedly improved recovery performance\nand speedups of SPARTA relative to existing alternatives. \n\n"}
{"id": "1612.00128", "contents": "Title: Trace Codes with Few Weights over $\\mathbb{F}_p+u\\mathbb{F}_p$ Abstract: We construct an infinite family of two-Lee-weight and three-Lee-weight codes\nover the chain ring $\\mathbb{F}_p+u\\mathbb{F}_p.$ They have the algebraic\nstructure of abelian codes. Their Lee weight distribution is computed by using\nGauss sums. Then by using a linear Gray map, we obtain an infinite family of\nabelian codes with few weights over $\\mathbb{F}_p$. In particular, we obtain an\ninfinite family of two-weight codes which meets the Griesmer bound with\nequality. Finally, an application to secret sharing schemes is given. \n\n"}
{"id": "1612.01361", "contents": "Title: Repairing Reed-Solomon Codes With Multiple Erasures Abstract: Despite their exceptional error-correcting properties, Reed-Solomon codes\nhave been overlooked in distributed storage applications due to the common\nbelief that they have poor repair bandwidth: A naive repair approach would\nrequire the whole file to be reconstructed in order to recover a single erased\ncodeword symbol. In a recent work, Guruswami and Wootters (STOC'16) proposed a\nsingle-erasure repair method for Reed-Solomon codes that achieves the optimal\nrepair bandwidth amongst all linear encoding schemes. Their key idea is to\nrecover the erased symbol by collecting a sufficiently large number of its\ntraces, each of which can be constructed from a number of traces of other\nsymbols. We extend the trace collection technique to cope with two and three\nerasures. \n\n"}
{"id": "1612.01459", "contents": "Title: Approximate Support Recovery of Atomic Line Spectral Estimation: A Tale\n  of Resolution and Precision Abstract: This work investigates the parameter estimation performance of\nsuper-resolution line spectral estimation using atomic norm minimization. The\nfocus is on analyzing the algorithm's accuracy of inferring the frequencies and\ncomplex magnitudes from noisy observations. When the Signal-to-Noise Ratio is\nreasonably high and the true frequencies are separated by $O(\\frac{1}{n})$, the\natomic norm estimator is shown to localize the correct number of frequencies,\neach within a neighborhood of size $O(\\sqrt{{\\log n}/{n^3}} \\sigma)$ of one of\nthe true frequencies. Here $n$ is half the number of temporal samples and\n$\\sigma^2$ is the Gaussian noise variance. The analysis is based on a\nprimal-dual witness construction procedure. The obtained error bound matches\nthe Cram\\'er-Rao lower bound up to a logarithmic factor. The relationship\nbetween resolution (separation of frequencies) and precision or accuracy of the\nestimator is highlighted. Our analysis also reveals that the atomic norm\nminimization can be viewed as a convex way to solve a $\\ell_1$-norm\nregularized, nonlinear and nonconvex least-squares problem to global\noptimality. \n\n"}
{"id": "1612.02213", "contents": "Title: On Counting Subring-Subcodes of Free Linear Codes Over Finite Principal\n  Ideal Rings Abstract: Let $R$ be a finite principal ideal ring and $S$ the Galois extension of $R$\nof degree $m$. For $k$ and $k_0$, positive integers we determine the number of\nfree $S$-linear codes $B$ of length $l$ with the property $k = rank_S(B)$ and\n$k_0 = rank_R (B\\cap R^l)$. This corrects a wrong result which was given in the\ncase of finite fields. \n\n"}
{"id": "1612.02463", "contents": "Title: Community detection by label propagation with compression of flow Abstract: The label propagation algorithm (LPA) has been proved to be a fast and\neffective method for detecting communities in large complex networks. However,\nits performance is subject to the non-stable and trivial solutions of the\nproblem. In this paper, we propose a modified label propagation algorithm LPAf\nto efficiently detect community structures in networks. Instead of the majority\nvoting rule of the basic LPA, LPAf updates the label of a node by considering\nthe compression of a description of random walks on a network. A multi-step\ngreedy agglomerative strategy is employed to enable LPAf to escape the local\noptimum. Furthermore, an incomplete update condition is also adopted to speed\nup the convergence. Experimental results on both synthetic and real-world\nnetworks confirm the effectiveness of our algorithm. \n\n"}
{"id": "1612.02574", "contents": "Title: Optimal Pilot and Payload Power Control in Single-Cell Massive MIMO\n  Systems Abstract: This paper considers the jointly optimal pilot and data power allocation in\nsingle-cell uplink massive multiple-input-multiple-output (MIMO) systems. Using\nthe spectral efficiency (SE) as performance metric and setting a total energy\nbudget per coherence interval, the power control is formulated as optimization\nproblems for two different objective functions: the weighted minimum SE among\nthe users and the weighted sum SE. A closed form solution for the optimal\nlength of the pilot sequence is derived. The optimal power control policy for\nthe former problem is found by solving a simple equation with a single\nvariable. Utilizing the special structure arising from imperfect channel\nestimation, a convex reformulation is found to solve the latter problem to\nglobal optimality in polynomial time. The gain of the optimal joint power\ncontrol is theoretically justified, and is proved to be large in the low SNR\nregime. Simulation results also show the advantage of optimizing the power\ncontrol over both pilot and data power, as compared to the cases of using full\npower and of only optimizing the data powers as done in previous work. \n\n"}
{"id": "1612.03115", "contents": "Title: Constraints and Entropy in a Model of Network Evolution Abstract: Barab\\'asi-Albert's `Scale Free' model is the starting point for much of the\naccepted theory of the evolution of real world communication networks. Careful\ncomparison of the theory with a wide range of real world networks, however,\nindicates that the model is in some cases, only a rough approximation to the\ndynamical evolution of real networks. In particular, the exponent $\\gamma$ of\nthe power law distribution of degree is predicted by the model to be exactly 3,\nwhereas in a number of real world networks it has values between 1.2 and 2.9.\nIn addition, the degree distributions of real networks exhibit cut offs at high\nnode degree, which indicates the existence of maximal node degrees for these\nnetworks. In this paper we propose a simple extension to the `Scale Free'\nmodel, which offers better agreement with the experimental data. This\nimprovement is satisfying, but the model still does not explain \\emph{why} the\nattachment probabilities should favor high degree nodes, or indeed how\nconstraints arrive in non-physical networks. Using recent advances in the\nanalysis of the entropy of graphs at the node level we propose a first\nprinciples derivation for the `Scale Free' and `constraints' model from\nthermodynamic principles, and demonstrate that both preferential attachment and\nconstraints could arise as a natural consequence of the second law of\nthermodynamics. \n\n"}
{"id": "1612.03547", "contents": "Title: Corruption Robust Phase Retrieval via Linear Programming Abstract: We consider the problem of phase retrieval from corrupted magnitude\nobservations. In particular we show that a fixed $x_0 \\in \\mathbb{R}^n$ can be\nrecovered exactly from corrupted magnitude measurements $|\\langle a_i, x_0\n\\rangle | + \\eta_i, \\quad i =1,2\\ldots m$ with high probability for $m = O(n)$,\nwhere $a_i \\in \\mathbb{R}^n$ are i.i.d standard Gaussian and $\\eta \\in\n\\mathbb{R}^m$ has fixed sparse support and is otherwise arbitrary, by using a\nversion of the PhaseMax algorithm augmented with slack variables subject to a\npenalty. This linear programming formulation, which we call RobustPhaseMax,\noperates in the natural parameter space, and our proofs rely on a direct\nanalysis of the optimality conditions using concentration inequalities. \n\n"}
{"id": "1612.04432", "contents": "Title: An argumentative agent-based model of scientific inquiry Abstract: In this paper we present an agent-based model (ABM) of scientific inquiry\naimed at investigating how different social networks impact the efficiency of\nscientists in acquiring knowledge. As such, the ABM is a computational tool for\ntackling issues in the domain of scientific methodology and science policy. In\ncontrast to existing ABMs of science, our model aims to represent the\nargumentative dynamics that underlies scientific practice. To this end we\nemploy abstract argumentation theory as the core design feature of the model.\nThis helps to avoid a number of problematic idealizations which are present in\nother ABMs of science and which impede their relevance for actual scientific\npractice. \n\n"}
{"id": "1612.04775", "contents": "Title: Operating Massive MIMO in Unlicensed Bands for Enhanced Coexistence and\n  Spatial Reuse Abstract: We propose to operate massive multiple-input multiple output (MIMO) cellular\nbase stations (BSs) in unlicensed bands. We denote such system as massive MIMO\nunlicensed (mMIMO-U). We design the key procedures required at a cellular BS to\nguarantee coexistence with nearby Wi-Fi devices operating in the same band. In\nparticular, spatial reuse is enhanced by actively suppressing interference\ntowards neighboring Wi-Fi devices. Wi-Fi interference rejection is also\nperformed during an enhanced listen-before-talk (LBT) phase. These operations\nenable Wi-Fi devices to access the channel as though no cellular BSs were\ntransmitting, and vice versa. Under concurrent Wi-Fi and BS transmissions, the\ndownlink rates attainable by cellular user equipment (UEs) are degraded by the\nWi-Fi-generated interference. To mitigate this effect, we select a suitable set\nof UEs to be served in the unlicensed band accounting for a measure of the\nWi-Fi/UE proximity. Our results show that the so-designed mMIMO-U allows\nsimultaneous cellular and Wi-Fi transmissions by keeping their mutual\ninterference below the regulatory threshold. Compared to a system without\ninterference suppression, Wi-Fi devices enjoy a median interference power\nreduction of between 3 dB with 16 antennas and 18 dB with 128 antennas. With\nmMIMO-U, cellular BSs can also achieve large data rates without significantly\ndegrading the performance of Wi-Fi networks deployed within their coverage\narea. \n\n"}
{"id": "1612.05743", "contents": "Title: Improper Signaling in Two-Path Relay Channels Abstract: Inter-relay interference (IRI) challenges the operation of two-path relaying\nsystems. Furthermore, the unavailability of the channel state information (CSI)\nat the source and the limited detection capabilities at the relays prevent\nneither eliminating the interference nor adopting joint detection at the relays\nnodes. Improper signaling is a powerful signaling scheme that has the\ncapability to reduce the interference impact at the receiver side and improves\nthe achievable rate performance. Therefore, improper signaling is adopted at\nboth relays, which have access to the global CSI. Then, improper signal\ncharacteristics are designed to maximize the total end-to-end achievable rate\nat the relays. To this end, both the power and the circularity coefficient, a\nmeasure of the impropriety degree of the signal, are optimized at the relays.\nAlthough the optimization problem is not convex, optimal power allocation for\nboth relays for a fixed circularity coefficient is obtained. Moreover, the\ncircularity coefficient is tuned to maximize the rate for a given power\nallocation. Finally, a joint solution of the optimization problem is proposed\nusing a coordinate descent method based on alternate optimization. The\nsimulation results show that employing improper signaling improves the\nachievable rate at medium and high IRI. \n\n"}
{"id": "1612.06835", "contents": "Title: Box constrained $\\ell_1$ optimization in random linear systems --\n  asymptotics Abstract: In this paper we consider box constrained adaptations of $\\ell_1$\noptimization heuristic when applied for solving random linear systems. These\nare typically employed when on top of being sparse the systems' solutions are\nalso known to be confined in a specific way to an interval on the real axis.\nTwo particular $\\ell_1$ adaptations (to which we will refer as the\n\\emph{binary} $\\ell_1$ and \\emph{box} $\\ell_1$) will be discussed in great\ndetail. Many of their properties will be addressed with a special emphasis on\nthe so-called phase transitions (PT) phenomena and the large deviation\nprinciples (LDP). We will fully characterize these through two different\nmathematical approaches, the first one that is purely probabilistic in nature\nand the second one that connects to high-dimensional geometry. Of particular\ninterest we will find that for many fairly hard mathematical problems a\ncollection of pretty elegant characterizations of their final solutions will\nturn out to exist. \n\n"}
{"id": "1612.07636", "contents": "Title: ScienceWISE: Topic Modeling over Scientific Literature Networks Abstract: We provide an up-to-date view on the knowledge management system ScienceWISE\n(SW) and address issues related to the automatic assignment of articles to\nresearch topics. So far, SW has been proven to be an effective platform for\nmanaging large volumes of technical articles by means of ontological\nconcept-based browsing. However, as the publication of research articles\naccelerates, the expressivity and the richness of the SW ontology turns into a\ndouble-edged sword: a more fine-grained characterization of articles is\npossible, but at the cost of introducing more spurious relations among them. In\nthis context, the challenge of continuously recommending relevant articles to\nusers lies in tackling a network partitioning problem, where nodes represent\narticles and co-occurring concepts create edges between them. In this paper, we\ndiscuss the three research directions we have taken for solving this issue: i)\nthe identification of generic concepts to reinforce inter-article similarities;\nii) the adoption of a bipartite network representation to improve scalability;\niii) the design of a clustering algorithm to identify concepts for\ncross-disciplinary articles and obtain fine-grained topics for all articles. \n\n"}
{"id": "1701.00210", "contents": "Title: Construction and Encoding of QC-LDPC Codes Using Group Rings Abstract: Quasi-cyclic (QC) low-density parity-check (LDPC) codes which are known as\nQC-LDPC codes, have many applications due to their simple encoding\nimplementation by means of cyclic shift registers. In this paper, we construct\nQC-LDPC codes from group rings. A group ring is a free module (at the same time\na ring) constructed in a natural way from any given ring and any given group.\nWe present a structure based on the elements of a group ring for constructing\nQC-LDPC codes. Some of the previously addressed methods for constructing\nQC-LDPC codes based on finite fields are special cases of the proposed\nconstruction method. The constructed QC-LDPC codes perform very well over the\nadditive white Gaussian noise (AWGN) channel with iterative decoding in terms\nof bit-error probability and block-error probability. Simulation results\ndemonstrate that the proposed codes have competitive performance in comparison\nwith the similar existing LDPC codes. Finally, we propose a new encoding method\nfor the proposed group ring based QC-LDPC codes that can be implemented faster\nthan the current encoding methods. The encoding complexity of the proposed\nmethod is analyzed mathematically, and indicates a significate reduction in the\nrequired number of operations, even when compared to the available efficient\nencoding methods that have linear time and space complexities. \n\n"}
{"id": "1701.01974", "contents": "Title: Arimoto-R\\'enyi Conditional Entropy and Bayesian $M$-ary Hypothesis\n  Testing Abstract: This paper gives upper and lower bounds on the minimum error probability of\nBayesian $M$-ary hypothesis testing in terms of the Arimoto-R\\'enyi conditional\nentropy of an arbitrary order $\\alpha$. The improved tightness of these bounds\nover their specialized versions with the Shannon conditional entropy\n($\\alpha=1$) is demonstrated. In particular, in the case where $M$ is finite,\nwe show how to generalize Fano's inequality under both the conventional and\nlist-decision settings. As a counterpart to the generalized Fano's inequality,\nallowing $M$ to be infinite, a lower bound on the Arimoto-R\\'enyi conditional\nentropy is derived as a function of the minimum error probability. Explicit\nupper and lower bounds on the minimum error probability are obtained as a\nfunction of the Arimoto-R\\'enyi conditional entropy for both positive and\nnegative $\\alpha$. Furthermore, we give upper bounds on the minimum error\nprobability as functions of the R\\'enyi divergence. In the setup of discrete\nmemoryless channels, we analyze the exponentially vanishing decay of the\nArimoto-R\\'enyi conditional entropy of the transmitted codeword given the\nchannel output when averaged over a random coding ensemble. \n\n"}
{"id": "1701.02957", "contents": "Title: Sphere-Packing Bound for Symmetric Classical-Quantum Channels Abstract: We provide a sphere-packing lower bound for the optimal error probability in\nfinite blocklengths when coding over a symmetric classical-quantum channel. Our\nresult shows that the pre-factor can be significantly improved from the order\nof the subexponential to the polynomial. The established pre-factor is\nessentially optimal because it matches the best known random coding upper bound\nin the classical case. Our approaches rely on a sharp concentration inequality\nin strong large deviation theory and crucial properties of the error-exponent\nfunction. \n\n"}
{"id": "1701.03590", "contents": "Title: Generalized Approximate Message-Passing Decoder for Universal Sparse\n  Superposition Codes Abstract: Sparse superposition (SS) codes were originally proposed as a\ncapacity-achieving communication scheme over the additive white Gaussian noise\nchannel (AWGNC) [1]. Very recently, it was discovered that these codes are\nuniversal, in the sense that they achieve capacity over any memoryless channel\nunder generalized approximate message-passing (GAMP) decoding [2], although\nthis decoder has never been stated for SS codes. In this contribution we\nintroduce the GAMP decoder for SS codes, we confirm empirically the\nuniversality of this communication scheme through its study on various channels\nand we provide the main analysis tools: state evolution and potential. We also\ncompare the performance of GAMP with the Bayes-optimal MMSE decoder. We\nempirically illustrate that despite the presence of a phase transition\npreventing GAMP to reach the optimal performance, spatial coupling allows to\nboost the performance that eventually tends to capacity in a proper limit. We\nalso prove that, in contrast with the AWGNC case, SS codes for binary input\nchannels have a vanishing error floor in the limit of large codewords.\nMoreover, the performance of Hadamard-based encoders is assessed for practical\nimplementations. \n\n"}
{"id": "1701.04439", "contents": "Title: Dandelion: Redesigning the Bitcoin Network for Anonymity Abstract: Bitcoin and other cryptocurrencies have surged in popularity over the last\ndecade. Although Bitcoin does not claim to provide anonymity for its users, it\nenjoys a public perception of being a `privacy-preserving' financial system. In\nreality, cryptocurrencies publish users' entire transaction histories in\nplaintext, albeit under a pseudonym; this is required for transaction\nvalidation. Therefore, if a user's pseudonym can be linked to their human\nidentity, the privacy fallout can be significant. Recently, researchers have\ndemonstrated deanonymization attacks that exploit weaknesses in the Bitcoin\nnetwork's peer-to-peer (P2P) networking protocols. In particular, the P2P\nnetwork currently forwards content in a structured way that allows observers to\ndeanonymize users. In this work, we redesign the P2P network from first\nprinciples with the goal of providing strong, provable anonymity guarantees. We\npropose a simple networking policy called Dandelion, which achieves\nnearly-optimal anonymity guarantees at minimal cost to the network's utility.\nWe also provide a practical implementation of Dandelion. \n\n"}
{"id": "1701.04984", "contents": "Title: Control Capacity of Partially Observable Dynamic Systems in Continuous\n  Time Abstract: Stochastic dynamic control systems relate in a prob- abilistic fashion the\nspace of control signals to the space of corresponding future states.\nConsequently, stochastic dynamic systems can be interpreted as an information\nchannel between the control space and the state space. In this work we study\nthis control-to-state informartion capacity of stochastic dynamic systems in\ncontinuous-time, when the states are observed only partially. The\ncontrol-to-state capacity, known as empowerment, was shown in the past to be\nuseful in solving various Artificial Intelligence & Control benchmarks, and was\nused to replace problem-specific utilities. The higher the value of empowerment\nis, the more optional future states an agent may reach by using its controls\ninside a given time horizon. The contribution of this work is that we derive an\nefficient solution for computing the control-to-state information capacity for\na linear, partially-observed Gaussian dynamic control system in continuous\ntime, and discover new relationships between control-theoretic and\ninformation-theoretic properties of dynamic systems. Particularly, using the\nderived method, we demonstrate that the capacity between the control signal and\nthe system output does not grow without limits with the length of the control\nsignal. This means that only the near-past window of the control signal\ncontributes effectively to the control-to-state capacity, while most of the\ninformation beyond this window is irrelevant for the future state of the\ndynamic system. We show that empowerment depends on a time constant of a\ndynamic system. \n\n"}
{"id": "1701.05523", "contents": "Title: Capacity and Normalized Optimal Detection Error in Gaussian Channels Abstract: For vector Gaussian channels, a precise differential connection between\nchannel capacity and a quantity termed normalized optimal detection error\n(NODE) is presented. Then, this C-NODE relationship is extended to\ncontinuous-time Gaussian channels drawing on a waterfilling characterization\nrecently found for the capacity of continuous-time linear time-varying\nchannels. In the latter case, the C-NODE relationship becomes asymptotic in\nnature. In either case, the C-NODE relationship is compared with the I-MMSE\nrelationship due to Guo et al. connecting mutual information in Gaussian\nchannels with the minimum mean-square error (MMSE) of estimation theory. \n\n"}
{"id": "1701.05943", "contents": "Title: Structure of optimal strategies for remote estimation over\n  Gilbert-Elliott channel with feedback Abstract: We investigate remote estimation over a Gilbert-Elliot channel with feedback.\nWe assume that the channel state is observed by the receiver and fed back to\nthe transmitter with one unit delay. In addition, the transmitter gets ACK/NACK\nfeedback for successful/unsuccessful transmission. Using ideas from team\ntheory, we establish the structure of optimal transmission and estimation\nstrategies and identify a dynamic program to determine optimal strategies with\nthat structure. We then consider first-order autoregressive sources where the\nnoise process has unimodal and symmetric distribution. Using ideas from\nmajorization theory, we show that the optimal transmission strategy has a\nthreshold structure and the optimal estimation strategy is Kalman-like. \n\n"}
{"id": "1701.06241", "contents": "Title: Dual Sub-6 GHz -- Millimeter Wave Beamforming and Communications to\n  Achieve Low Latency and High Energy Efficiency in 5G Systems Abstract: We propose a hybrid architecture that integrates RF (i.e., sub-6 GHz) and\nmillimeter wave (mmWave) technologies for 5G cellular systems. In particular,\ncommunications in the mmWave band faces significant challenges due to variable\nchannels, intermittent connectivity, and high energy usage. On the other hand,\nspeeds for electronic processing of data is of the same order as typical rates\nfor mmWave interfaces which makes the use of complex algorithms for tracking\nchannel variations and adjusting resources accordingly impractical. Our\nproposed architecture integrates the RF and mmWave interfaces for beamforming\nand data transfer, and exploits the spatio-temporal correlations between the\ninterfaces. Based on extensive experimentation in indoor and outdoor settings,\nwe demonstrate that an integrated RF/mmWave signaling and channel estimation\nscheme can remedy the problem of high energy usage and delay associated with\nmmWave beamforming. In addition, cooperation between two interfaces at the\nhigher layers effectively addresses the high delays caused by highly\nintermittent mmWave connectivity. We design a scheduler that fully exploits the\nmmWave bandwidth, while the RF link acts as a fallback mechanism to prevent\nhigh delay. To this end, we formulate an optimal scheduling problem over the RF\nand mmWave interfaces where the goal is to maximize the delay-constrained\nthroughput of the mmWave interface. We prove using subadditivity analysis that\nthe optimal scheduling policy is based on a single threshold that can be easily\nadopted despite high link variations. \n\n"}
{"id": "1701.06731", "contents": "Title: Weak Adaptive Submodularity and Group-Based Active Diagnosis with\n  Applications to State Estimation with Persistent Sensor Faults Abstract: In this paper, we consider adaptive decision-making problems for stochastic\nstate estimation with partial observations. First, we introduce the concept of\nweak adaptive submodularity, a generalization of adaptive submodularity, which\nhas found great success in solving challenging adaptive state estimation\nproblems. Then, for the problem of active diagnosis, i.e., discrete state\nestimation via active sensing, we show that an adaptive greedy policy has a\nnear-optimal performance guarantee when the reward function possesses this\nproperty. We further show that the reward function for group-based active\ndiagnosis, which arises in applications such as medical diagnosis and state\nestimation with persistent sensor faults, is also weakly adaptive submodular.\nFinally, in experiments of state estimation for an aircraft electrical system\nwith persistent sensor faults, we observe that an adaptive greedy policy\nperforms equally well as an exhaustive search. \n\n"}
{"id": "1701.06927", "contents": "Title: Age and Value of Information: Non-linear Age Case Abstract: We consider a real-time status update system consisting of a\nsource-destination network. A stochastic process is observed at the source, and\nsamples, so called status updates, are extracted at random time instances, and\ndelivered to the destination. In this paper, we expand the concept of\ninformation ageing by introducing the Cost of Update Delay (CoUD) metric to\ncharacterize the cost of having stale information at the destination. We\nintroduce the Value of Information of Update (VoIU) metric that captures the\nreduction of CoUD upon reception of an update. The importance of the VoIU\nmetric lies on its tractability which enables the minimization of the average\nCoUD. \n\n"}
{"id": "1701.07447", "contents": "Title: An Explicit, Coupled-Layer Construction of a High-Rate Regenerating Code\n  with Low Sub-Packetization Level, Small Field Size and $d< (n-1)$ Abstract: This paper presents an explicit construction for an\n$((n=2qt,k=2q(t-1),d=n-(q+1)), (\\alpha = q(2q)^{t-1},\\beta =\n\\frac{\\alpha}{q}))$ regenerating code (RGC) over a field $\\mathbb{F}_Q$ having\nrate $\\geq \\frac{t-2}{t}$. The RGC code can be constructed to have rate $k/n$\nas close to $1$ as desired, sub-packetization level $\\alpha \\leq\nr^{\\frac{n}{r}}$ for $r=(n-k)$, field size $Q$ no larger than $n$ and where all\ncode symbols can be repaired with the same minimum data download. \n\n"}
{"id": "1701.07872", "contents": "Title: Cooling Codes: Thermal-Management Coding for High-Performance\n  Interconnects Abstract: High temperatures have dramatic negative effects on interconnect performance\nand, hence, numerous techniques have been proposed to reduce the power\nconsumption of on-chip buses. However, existing methods fall short of fully\naddressing the thermal challenges posed by high-performance interconnects. In\nthis paper, we introduce new efficient coding schemes that make it possible to\ndirectly control the peak temperature of a bus by effectively cooling its\nhottest wires. This is achieved by avoiding state transitions on the hottest\nwires for as long as necessary until their temperature drops off. We also\nreduce the average power consumption by making sure that the total number of\nstate transitions on all the wires is below a prescribed threshold. We show how\neach of these two features can be coded for separately or, alternatively, how\nboth can be achieved at the same time. In addition, error-correction for the\ntransmitted information can be provided while controlling the peak temperature\nand/or the average power consumption.\n  In general, our cooling codes use $n > k$ wires to encode a given $k$-bit\nbus. One of our goals herein is to determine the minimum possible number of\nwires $n$ needed to encode $k$ bits while satisfying any combination of the\nthree desired properties. We provide full theoretical analysis in each case. In\nparticular, we show that $n = k+t+1$ suffices to cool the $t$ hottest wires,\nand this is the best possible. Moreover, although the proposed coding schemes\nmake use of sophisticated tools from combinatorics, discrete geometry, linear\nalgebra, and coding theory, the resulting encoders and decoders are fully\npractical. They do not require significant computational overhead and can be\nimplemented without sacrificing a large circuit area. \n\n"}
{"id": "1701.08174", "contents": "Title: Rotated Eigenstructure Analysis for Source Localization without\n  Energy-decay Models Abstract: Herein, the problem of simultaneous localization of two sources given a\nmodest number of samples is examined. In particular, the strategy does not\nrequire knowledge of the target signatures of the sources a priori, nor does it\nexploit classical methods based on a particular decay rate of the energy\nemitted from the sources as a function of range. General structural properties\nof the signatures such as unimodality are exploited. The algorithm localizes\ntargets based on the rotated eigenstructure of a reconstructed observation\nmatrix. In particular, the optimal rotation can be found by maximizing the\nratio of the dominant singular value of the observation matrix over the nuclear\nnorm of the optimally rotated observation matrix. It is shown that this ratio\nhas a unique local maximum leading to computationally efficient search\nalgorithms. Moreover, analytical results are developed to show that the squared\nlocalization error decreases at a rate faster than the baseline scheme. \n\n"}
{"id": "1702.00160", "contents": "Title: Short-Message Communication and FIR System Identification using Huffman\n  Sequences Abstract: Providing short-message communication and simultaneous channel estimation for\nsporadic and fast fading scenarios is a challenge for future wireless networks.\nIn this work we propose a novel blind communication and deconvolution scheme by\nusing Huffman sequences, which allows to solve three important tasks in one\nstep: (i) determination of the transmit power (ii) identification of the\ndiscrete-time FIR channel by providing a maximum delay of less than $L/2$ and\n(iii) simultaneously communicating $L-1$ bits of information. Our signal\nreconstruction uses a recent semi-definite program that can recover two unknown\nsignals from their auto-correlations and cross-correlations. This convex\nalgorithm is stable and operates fully deterministic without any further\nchannel assumptions. \n\n"}
{"id": "1702.01112", "contents": "Title: Optimal Input Design for Affine Model Discrimination with Applications\n  in Intention-Aware Vehicles Abstract: This paper considers the optimal design of input signals for the purpose of\ndiscriminating among a finite number of affine models with uncontrolled inputs\nand noise. Each affine model represents a different system operating mode,\ncorresponding to unobserved intents of other drivers or robots, or to fault\ntypes or attack strategies, etc. The input design problem aims to find optimal\nseparating/discriminating (controlled) inputs such that the output trajectories\nof all the affine models are guaranteed to be distinguishable from each other,\ndespite uncertainty in the initial condition and uncontrolled inputs as well as\nthe presence of process and measurement noise. We propose a novel formulation\nto solve this problem, with an emphasis on guarantees for model discrimination\nand optimality, in contrast to a previously proposed conservative formulation\nusing robust optimization. This new formulation can be recast as a bilevel\noptimization problem and further reformulated as a mixed-integer linear program\n(MILP). Moreover, our fairly general problem setting allows the incorporation\nof objectives and/or responsibilities among rational agents. For instance, each\ndriver has to obey traffic rules, while simultaneously optimizing for safety,\ncomfort and energy efficiency. Finally, we demonstrate the effectiveness of our\napproach for identifying the intention of other vehicles in several driving\nscenarios. \n\n"}
{"id": "1702.01225", "contents": "Title: Quickest Hub Discovery in Correlation Graphs Abstract: A sequential test is proposed for detection and isolation of hubs in a\ncorrelation graph. Hubs in a correlation graph of a random vector are variables\n(nodes) that have a strong correlation edge. It is assumed that the random\nvectors are high-dimensional and are multivariate Gaussian distributed. The\ntest employs a family of novel local and global summary statistics generated\nfrom small samples of the random vectors. Delay and false alarm analysis of the\ntest is obtained and numerical results are provided to show that the test is\nconsistent in identifying hubs, as the false alarm rate goes to zero. \n\n"}
{"id": "1702.01670", "contents": "Title: Single Anchor Localization and Orientation Performance Limits using\n  Massive Arrays: MIMO vs. Beamforming Abstract: Next generation cellular networks will experience the combination of\nfemtocells, millimeter-wave (mm-wave) communications and massive antenna\narrays. Thanks to the beamforming capability as well as the high angular\nresolution provided by massive arrays, only one single access point (AP) acting\nas an anchor node could be used for localization estimation, thus avoiding\nover-sized infrastructures dedicated to positioning. In this context, our paper\naims at investigating the localization and orientation performance limits\nemploying massive arrays both at the AP and mobile side. Thus, we first\nasymptotically demonstrate the tightness of the Cramer-Rao bound (CRB) in\nmassive array regime, and in the presence or not of multipath. Successively, we\npropose a comparison between MIMO and beamforming in terms of array structure,\ntime synchronization error and multipath components. Among different array\nconfigurations, we consider also random weighting as a trade-off between the\nhigh diversity gain of MIMO and the high directivity guaranteed by phased\narrays. By evaluating the CRB for the different array configurations, results\nshow the interplay between diversity and beamforming gain as well as the\nbenefits achievable by varying the number of array elements in terms of\nlocalization accuracy. \n\n"}
{"id": "1702.01679", "contents": "Title: Downlink and Uplink Decoupling in Two-Tier Heterogeneous Networks with\n  Multi-Antenna Base Stations Abstract: In order to improve the uplink performance of future cellular networks, the\nidea to decouple the downlink (DL) and uplink (UL) association has recently\nbeen shown to provide significant gain in terms of both coverage and rate\nperformance. However, all the work is limited to SISO network. Therefore, to\nstudy the gain provided by the DL and UL decoupling in multi-antenna base\nstations (BSs) setup, we study a two tier heterogeneous network consisting of\nmulti-antenna BSs, and single antenna user equipments (UEs). We use maximal\nratio combining (MRC) as a linear receiver at the BSs and using tools from\nstochastic geometry, we derive tractable expressions for both signal to\ninterference ratio (SIR) coverage probability and rate coverage probability. We\nobserve that as the disparity in the beamforming gain of both tiers increases,\nthe gain in term of SIR coverage probability provided by the decoupled\nassociation over non-decoupled association decreases. We further observe that\nwhen there is asymmetry in the number of antennas of both tier, then we need\nfurther biasing towards femto-tier on the top of decoupled association to\nbalance the load and get optimal rate coverage probability. \n\n"}
{"id": "1702.03483", "contents": "Title: Classical-Quantum Arbitrarily Varying Wiretap Channel: Secret Message\n  Transmission under Jamming Attacks Abstract: We analyze arbitrarily varying classical-quantum wiretap channels.These\nchannels are subject to two attacks at the same time: one passive\n(eavesdropping), and one active (jamming). We progress on previous works by\nintroducing a reduced class of allowed codes that fulfills a more stringent\nsecrecy requirement than earlier definitions. In addition, we prove that\nnon-symmetrizability of the legal link is suficient for equality of the\ndeterministic and the common randomness assisted secrecy capacities. At last,\nwe focus on analytic properties of both secrecy capacities: We completely\ncharacterize their discontinuity points, and their super-activation properties. \n\n"}
{"id": "1702.03750", "contents": "Title: Globally convergent Jacobi-type algorithms for simultaneous orthogonal\n  symmetric tensor diagonalization Abstract: In this paper, we consider a family of Jacobi-type algorithms for\nsimultaneous orthogonal diagonalization problem of symmetric tensors. For the\nJacobi-based algorithm of [SIAM J. Matrix Anal. Appl., 2(34):651--672, 2013],\nwe prove its global convergence for simultaneous orthogonal diagonalization of\nsymmetric matrices and 3rd-order tensors. We also propose a new Jacobi-based\nalgorithm in the general setting and prove its global convergence for\nsufficiently smooth functions. \n\n"}
{"id": "1702.04342", "contents": "Title: BranchHull: Convex bilinear inversion from the entrywise product of\n  signals with known signs Abstract: We consider the bilinear inverse problem of recovering two vectors, $x$ and\n$w$, in $\\mathbb{R}^L$ from their entrywise product. For the case where the\nvectors have known signs and belong to known subspaces, we introduce the convex\nprogram BranchHull, which is posed in the natural parameter space that does not\nrequire an approximate solution or initialization in order to be stated or\nsolved. Under the structural assumptions that $x$ and $w$ are members of known\n$K$ and $N$ dimensional random subspaces, we present a recovery guarantee for\nthe noiseless case and a noisy case. In the noiseless case, we prove that the\nBranchHull recovers $x$ and $w$ up to the inherent scaling ambiguity with high\nprobability when $L\\ \\gg\\ 2(K+N)$. The analysis provides a precise upper bound\non the coefficient for the sample complexity. In a noisy case, we show that\nwith high probability the BranchHull is robust to small dense noise when $L =\n\\Omega(K+N)$. BranchHull is motivated by the sweep distortion removal task in\ndielectric imaging, where one of the signals is a nonnegative reflectivity, and\nthe other signal lives in a known wavelet subspace. Additional potential\napplications are blind deconvolution and self-calibration. \n\n"}
{"id": "1702.04563", "contents": "Title: Characterizing the Rate-Memory Tradeoff in Cache Networks within a\n  Factor of 2 Abstract: We consider a basic caching system, where a single server with a database of\n$N$ files (e.g. movies) is connected to a set of $K$ users through a shared\nbottleneck link. Each user has a local cache memory with a size of $M$ files.\nThe system operates in two phases: a placement phase, where each cache memory\nis populated up to its size from the database, and a following delivery phase,\nwhere each user requests a file from the database, and the server is\nresponsible for delivering the requested contents. The objective is to design\nthe two phases to minimize the load (peak or average) of the bottleneck link.\nWe characterize the rate-memory tradeoff of the above caching system within a\nfactor of $2.00884$ for both the peak rate and the average rate (under uniform\nfile popularity), improving state of the arts that are within a factor of $4$\nand $4.7$ respectively. Moreover, in a practically important case where the\nnumber of files ($N$) is large, we exactly characterize the tradeoff for\nsystems with no more than $5$ users, and characterize the tradeoff within a\nfactor of $2$ otherwise. To establish these results, we develop two new\nconverse bounds that improve over the state of the art. \n\n"}
{"id": "1702.04834", "contents": "Title: Improved Converses and Gap Results for Coded Caching Abstract: Improved lower bounds on the average and the worst-case rate-memory tradeoffs\nfor the Maddah-Ali&Niesen coded caching scenario are presented. For any number\nof users and files and for arbitrary cache sizes, the multiplicative gap\nbetween the exact rate-memory tradeoff and the new lower bound is less than\n2.315 in the worst-case scenario and less than 2.507 in the average-case\nscenario. \n\n"}
{"id": "1702.05197", "contents": "Title: Throughput-Optimal Broadcast in Wireless Networks with\n  Point-to-Multipoint Transmissions Abstract: We consider the problem of efficient packet dissemination in wireless\nnetworks with point-to-multi-point wireless broadcast channels. We propose a\ndynamic policy, which achieves the broadcast capacity of the network. This\npolicy is obtained by first transforming the original multi-hop network into a\nprecedence-relaxed virtual single-hop network and then finding an optimal\nbroadcast policy for the relaxed network. The resulting policy is shown to be\nthroughput-optimal for the original wireless network using a sample-path\nargument. We also prove the NP-completeness of the finite-horizon broadcast\nproblem, which is in contrast with the polynomial time solvability of the\nproblem with point-to-point channels. Illustrative simulation results\ndemonstrate the efficacy of the proposed broadcast policy in achieving the full\nbroadcast capacity with low delay. \n\n"}
{"id": "1702.05952", "contents": "Title: Interplay between social influence and competitive strategical games in\n  multiplex networks Abstract: We present a model that takes into account the coupling between evolutionary\ngame dynamics and social influence. Importantly, social influence and game\ndynamics take place in different domains, which we model as different layers of\na multiplex network. We show that the coupling between these dynamical\nprocesses can lead to cooperation in scenarios where the pure game dynamics\npredicts defection. In addition, we show that the structure of the network\nlayers and the relation between them can further increase cooperation.\nRemarkably, if the layers are related in a certain way, the system can reach a\npolarized metastable state.These findings could explain the prevalence of\npolarization observed in many social dilemmas. \n\n"}
{"id": "1702.06318", "contents": "Title: Is Saki #delicious? The Food Perception Gap on Instagram and Its\n  Relation to Health Abstract: Food is an integral part of our life and what and how much we eat crucially\naffects our health. Our food choices largely depend on how we perceive certain\ncharacteristics of food, such as whether it is healthy, delicious or if it\nqualifies as a salad. But these perceptions differ from person to person and\none person's \"single lettuce leaf\" might be another person's \"side salad\".\nStudying how food is perceived in relation to what it actually is typically\ninvolves a laboratory setup. Here we propose to use recent advances in image\nrecognition to tackle this problem. Concretely, we use data for 1.9 million\nimages from Instagram from the US to look at systematic differences in how a\nmachine would objectively label an image compared to how a human subjectively\ndoes. We show that this difference, which we call the \"perception gap\", relates\nto a number of health outcomes observed at the county level. To the best of our\nknowledge, this is the first time that image recognition is being used to study\nthe \"misalignment\" of how people describe food images vs. what they actually\ndepict. \n\n"}
{"id": "1702.06363", "contents": "Title: Stochastic graph Voronoi tessellation reveals community structure Abstract: Given a network, the statistical ensemble of its graph-Voronoi diagrams with\nrandomly chosen cell centers exhibits properties convertible into information\non the network's large scale structures. We define a node-pair level measure\ncalled {\\it Voronoi cohesion} which describes the probability for sharing the\nsame Voronoi cell, when randomly choosing $g$ centers in the network. This\nmeasure provides information based on the global context (the network in its\nentirety) a type of information that is not carried by other similarity\nmeasures. We explore the mathematical background of this phenomenon and several\nof its potential applications. A special focus is laid on the possibilities and\nlimitations pertaining to the exploitation of the phenomenon for community\ndetection purposes. \n\n"}
{"id": "1702.06677", "contents": "Title: Discussion quality diffuses in the digital public square Abstract: Studies of online social influence have demonstrated that friends have\nimportant effects on many types of behavior in a wide variety of settings.\nHowever, we know much less about how influence works among relative strangers\nin digital public squares, despite important conversations happening in such\nspaces. We present the results of a study on large public Facebook pages where\nwe randomly used two different methods--most recent and social feedback--to\norder comments on posts. We find that the social feedback condition results in\nhigher quality viewed comments and response comments. After measuring the\naverage quality of comments written by users before the study, we find that\nsocial feedback has a positive effect on response quality for both low and high\nquality commenters. We draw on a theoretical framework of social norms to\nexplain this empirical result. In order to examine the influence mechanism\nfurther, we measure the similarity between comments viewed and written during\nthe study, finding that similarity increases for the highest quality\ncontributors under the social feedback condition. This suggests that, in\naddition to norms, some individuals may respond with increased relevance to\nhigh-quality comments. \n\n"}
{"id": "1702.07241", "contents": "Title: Kalman Filter and its Modern Extensions for the Continuous-time\n  Nonlinear Filtering Problem Abstract: This paper is concerned with the filtering problem in continuous-time. Three\nalgorithmic solution approaches for this problem are reviewed: (i) the\nclassical Kalman-Bucy filter which provides an exact solution for the linear\nGaussian problem, (ii) the ensemble Kalman-Bucy filter (EnKBF) which is an\napproximate filter and represents an extension of the Kalman-Bucy filter to\nnonlinear problems, and (iii) the feedback particle filter (FPF) which\nrepresents an extension of the EnKBF and furthermore provides for an consistent\nsolution in the general nonlinear, non-Gaussian case. The common feature of the\nthree algorithms is the gain times error formula to implement the update step\n(to account for conditioning due to the observations) in the filter. In\ncontrast to the commonly used sequential Monte Carlo methods, the EnKBF and FPF\navoid the resampling of the particles in the importance sampling update step.\nMoreover, the feedback control structure provides for error correction\npotentially leading to smaller simulation variance and improved stability\nproperties. The paper also discusses the issue of non-uniqueness of the filter\nupdate formula and formulates a novel approximation algorithm based on ideas\nfrom optimal transport and coupling of measures. Performance of this and other\nalgorithms is illustrated for a numerical example. \n\n"}
{"id": "1702.07444", "contents": "Title: Bandits with Movement Costs and Adaptive Pricing Abstract: We extend the model of Multi-armed Bandit with unit switching cost to\nincorporate a metric between the actions. We consider the case where the metric\nover the actions can be modeled by a complete binary tree, and the distance\nbetween two leaves is the size of the subtree of their least common ancestor,\nwhich abstracts the case that the actions are points on the continuous interval\n$[0,1]$ and the switching cost is their distance. In this setting, we give a\nnew algorithm that establishes a regret of $\\widetilde{O}(\\sqrt{kT} + T/k)$,\nwhere $k$ is the number of actions and $T$ is the time horizon. When the set of\nactions corresponds to whole $[0,1]$ interval we can exploit our method for the\ntask of bandit learning with Lipschitz loss functions, where our algorithm\nachieves an optimal regret rate of $\\widetilde{\\Theta}(T^{2/3})$, which is the\nsame rate one obtains when there is no penalty for movements. As our main\napplication, we use our new algorithm to solve an adaptive pricing problem.\nSpecifically, we consider the case of a single seller faced with a stream of\npatient buyers. Each buyer has a private value and a window of time in which\nthey are interested in buying, and they buy at the lowest price in the window,\nif it is below their value. We show that with an appropriate discretization of\nthe prices, the seller can achieve a regret of $\\widetilde{O}(T^{2/3})$\ncompared to the best fixed price in hindsight, which outperform the previous\nregret bound of $\\widetilde{O}(T^{3/4})$ for the problem. \n\n"}
{"id": "1702.07784", "contents": "Title: Measuring #GamerGate: A Tale of Hate, Sexism, and Bullying Abstract: Over the past few years, online aggression and abusive behaviors have\noccurred in many different forms and on a variety of platforms. In extreme\ncases, these incidents have evolved into hate, discrimination, and bullying,\nand even materialized into real-world threats and attacks against individuals\nor groups. In this paper, we study the Gamergate controversy. Started in August\n2014 in the online gaming world, it quickly spread across various social\nnetworking platforms, ultimately leading to many incidents of cyberbullying and\ncyberaggression. We focus on Twitter, presenting a measurement study of a\ndataset of 340k unique users and 1.6M tweets to study the properties of these\nusers, the content they post, and how they differ from random Twitter users. We\nfind that users involved in this \"Twitter war\" tend to have more friends and\nfollowers, are generally more engaged and post tweets with negative sentiment,\nless joy, and more hate than random users. We also perform preliminary\nmeasurements on how the Twitter suspension mechanism deals with such abusive\nbehaviors. While we focus on Gamergate, our methodology to collect and analyze\ntweets related to aggressive and bullying activities is of independent\ninterest. \n\n"}
{"id": "1702.07939", "contents": "Title: Upper bounds on the smallest size of a saturating set in projective\n  planes and spaces of even dimension Abstract: In a projective plane $\\Pi_{q}$ (not necessarily Desarguesian) of order $q$,\na point subset $\\mathcal{S}$ is saturating (or dense) if any point of\n$\\Pi_{q}\\setminus \\mathcal{S}$ is collinear with two points in $\\mathcal{S}$.\nModifying an approach of [31], we proved the following upper bound on the\nsmallest size $s(2,q)$ of a saturating set in $\\Pi_{q}$: \\begin{equation*}\ns(2,q)\\leq \\sqrt{(q+1)\\left(3\\ln q+\\ln\\ln q\n+\\ln\\frac{3}{4}\\right)}+\\sqrt{\\frac{q}{3\\ln q}}+3. \\end{equation*} The bound\nholds for all q, not necessarily large.\n  By using inductive constructions, upper bounds on the smallest size of a\nsaturating set in the projective space $\\mathrm{PG}(N,q)$ with even dimension\n$N$ are obtained.\n  All the results are also stated in terms of linear covering codes. \n\n"}
{"id": "1702.08339", "contents": "Title: On Fienup Methods for Regularized Phase Retrieval Abstract: Alternating minimization, or Fienup methods, have a long history in phase\nretrieval. We provide new insights related to the empirical and theoretical\nanalysis of these algorithms when used with Fourier measurements and combined\nwith convex priors. In particular, we show that Fienup methods can be viewed as\nperforming alternating minimization on a regularized nonconvex least-squares\nproblem with respect to amplitude measurements. We then prove that under mild\nadditional structural assumptions on the prior (semi-algebraicity), the\nsequence of signal estimates has a smooth convergent behaviour towards a\ncritical point of the nonconvex regularized least-squares objective. Finally,\nwe propose an extension to Fienup techniques, based on a projected gradient\ndescent interpretation and acceleration using inertial terms. We demonstrate\nexperimentally that this modification combined with an $\\ell_1$ prior\nconstitutes a competitive approach for sparse phase retrieval. \n\n"}
{"id": "1702.08791", "contents": "Title: Robust Budget Allocation via Continuous Submodular Functions Abstract: The optimal allocation of resources for maximizing influence, spread of\ninformation or coverage, has gained attention in the past years, in particular\nin machine learning and data mining. But in applications, the parameters of the\nproblem are rarely known exactly, and using wrong parameters can lead to\nundesirable outcomes. We hence revisit a continuous version of the Budget\nAllocation or Bipartite Influence Maximization problem introduced by Alon et\nal. (2012) from a robust optimization perspective, where an adversary may\nchoose the least favorable parameters within a confidence set. The resulting\nproblem is a nonconvex-concave saddle point problem (or game). We show that\nthis nonconvex problem can be solved exactly by leveraging connections to\ncontinuous submodular functions, and by solving a constrained submodular\nminimization problem. Although constrained submodular minimization is hard in\ngeneral, here, we establish conditions under which such a problem can be solved\nto arbitrary precision $\\epsilon$. \n\n"}
{"id": "1703.04064", "contents": "Title: An Improved Diversity Combining Receiver for Layered ACO-FOFDM in IM/DD\n  Systems Abstract: In this paper, an improved receiver based on diversity combining is proposed\nto improve the bit error rate (BER) performance of layered asymmetrically\nclipped optical fast orthogonal frequency division multiplexing (ACO-FOFDM) for\nintensity-modulated and direct-detected (IM/DD) optical transmission systems.\nLayered ACO-FOFDM can compensate the weakness of traditional ACO-FOFDM in low\nspectral efficiency, the utilization of discrete cosine transform in FOFDM\nsystem instead of fast Fourier transform in OFDM system can reduce the\ncomputational complexity without any influence on BER performance. The BER\nperformances of layered ACO-FOFDM system with improved receiver based on\ndiversity combining and DC-offset FOFDM (DCO-FOFDM) system with optimal DC-bias\nare compared at the same spectral efficiency. Simulation results show that\nunder different optical bit energy to noise power ratios, layered ACO-FOFDM\nsystem with improved receiver has 2.86dB, 5.26dB and 5.72dB BER performance\nadvantages at forward error correction limit over DCO-FOFDM system when the\nspectral efficiencies are 1 bit/s/Hz, 2 bits/s/Hz and 3 bits/s/Hz,\nrespectively. Layered ACO-FOFDM system with improved receiver based on\ndiversity combining is suitable for application in the adaptive IM/DD systems\nwith zero DC-bias. \n\n"}
{"id": "1703.05038", "contents": "Title: Harmonic Mean Iteratively Reweighted Least Squares for Low-Rank Matrix\n  Recovery Abstract: We propose a new iteratively reweighted least squares (IRLS) algorithm for\nthe recovery of a matrix $X \\in \\mathbb{C}^{d_1\\times d_2}$ of rank $r\n\\ll\\min(d_1,d_2)$ from incomplete linear observations, solving a sequence of\nlow complexity linear problems. The easily implementable algorithm, which we\ncall harmonic mean iteratively reweighted least squares (HM-IRLS), optimizes a\nnon-convex Schatten-$p$ quasi-norm penalization to promote low-rankness and\ncarries three major strengths, in particular for the matrix completion setting.\nFirst, we observe a remarkable global convergence behavior of the algorithm's\niterates to the low-rank matrix for relevant, interesting cases, for which any\nother state-of-the-art optimization approach fails the recovery. Secondly,\nHM-IRLS exhibits an empirical recovery probability close to $1$ even for a\nnumber of measurements very close to the theoretical lower bound $r (d_1 +d_2\n-r)$, i.e., already for significantly fewer linear observations than any other\ntractable approach in the literature. Thirdly, HM-IRLS exhibits a locally\nsuperlinear rate of convergence (of order $2-p$) if the linear observations\nfulfill a suitable null space property. While for the first two properties we\nhave so far only strong empirical evidence, we prove the third property as our\nmain theoretical result. \n\n"}
{"id": "1703.05644", "contents": "Title: Ranking influential spreaders is an ill-defined problem Abstract: Finding influential spreaders of information and disease in networks is an\nimportant theoretical problem, and one of considerable recent interest. It has\nbeen almost exclusively formulated as a node-ranking problem -- methods for\nidentifying influential spreaders rank nodes according to how influential they\nare. In this work, we show that the ranking approach does not necessarily work:\nthe set of most influential nodes depends on the number of nodes in the set.\nTherefore, the set of $n$ most important nodes to vaccinate does not need to\nhave any node in common with the set of $n+1$ most important nodes. We propose\na method for quantifying the extent and impact of this phenomenon, and show\nthat it is common in both empirical and model networks. \n\n"}
{"id": "1703.06227", "contents": "Title: Discriminative Distance-Based Network Indices with Application to Link\n  Prediction Abstract: In large networks, using the length of shortest paths as the distance measure\nhas shortcomings. A well-studied shortcoming is that extending it to\ndisconnected graphs and directed graphs is controversial. The second\nshortcoming is that a huge number of vertices may have exactly the same score.\nThe third shortcoming is that in many applications, the distance between two\nvertices not only depends on the length of shortest paths, but also on the\nnumber of shortest paths. In this paper, first we develop a new distance\nmeasure between vertices of a graph that yields discriminative distance-based\ncentrality indices. This measure is proportional to the length of shortest\npaths and inversely proportional to the number of shortest paths. We present\nalgorithms for exact computation of the proposed discriminative indices.\nSecond, we develop randomized algorithms that precisely estimate average\ndiscriminative path length and average discriminative eccentricity and show\nthat they give $(\\epsilon,\\delta)$-approximations of these indices. Third, we\nperform extensive experiments over several real-world networks from different\ndomains. In our experiments, we first show that compared to the traditional\nindices, discriminative indices have usually much more discriminability. Then,\nwe show that our randomized algorithms can very precisely estimate average\ndiscriminative path length and average discriminative eccentricity, using only\nfew samples. Then, we show that real-world networks have usually a tiny average\ndiscriminative path length, bounded by a constant (e.g., 2). Fourth, in order\nto better motivate the usefulness of our proposed distance measure, we present\na novel link prediction method, that uses discriminative distance to decide\nwhich vertices are more likely to form a link in future, and show its superior\nperformance compared to the well-known existing measures. \n\n"}
{"id": "1703.07539", "contents": "Title: On a frame theoretic measure of quality of LTI systems Abstract: It is of practical significance to define the notion of a measure of quality\nof a control system, i.e., a quantitative extension of the classical notion of\ncontrollability. In this article we demonstrate that the three standard\nmeasures of quality involving the trace, minimum eigenvalue, and the\ndeterminant of the controllability grammian achieve their optimum values when\nthe columns of the controllability matrix from a tight frame. Motivated by\nthis, and in view of some recent developments in frame theoretic signal\nprocessing, we provide a measure of quality for LTI systems based on a measure\nof tightness of the columns of the reachability matrix . \n\n"}
{"id": "1703.07912", "contents": "Title: Toward Traffic Patterns in High-speed Railway Communication Systems:\n  Power Allocation and Antenna Selection Abstract: In high-speed railway (HSR) communication systems, distributed antenna is\nusually employed to support frequent handover and enhance the signal to noise\nratio to user equipments. In this case, dynamic time-domain power allocation\nand antenna selection (PAWAS) could be jointly optimized to improve the system\nperformances. This paper consider this problem in such a simple way where\ndynamic switching between multiple-input-multiple-output (MIMO) and\nsingle-input-multiple-output (SIMO) is allowed and exclusively utilized, while\nthe channel states and traffic demand are taken into account. The channel\nstates includes sparse and rich scattering terrains, and the traffic patterns\nincludes delay-sensitive and delay-insensitive as well as hybrid. Some\nimportant results are obtained in theory. In sparse scattering terrains, for\ndelay-sensitive traffic, the PAWAS can be viewed as the generalization of\nchannel-inversion associated with transmit antenna selection. On the contrary,\nfor delay-insensitive traffic, the power allocation with MIMO can be viewed as\nchannel-inversion, but with SIMO, it is traditional water-filling. For the\nhybrid traffic, the PAWAS can be partitioned as delay-sensitive and\ndelay-insensitive parts by some specific strategies. In rich scattering\nterrains, the corresponding PAWAS is derived by some amendments in sparse\nscattering terrains and similar results are then presented. \n\n"}
{"id": "1703.09028", "contents": "Title: De-anonymization of Social Networks with Communities: When\n  Quantifications Meet Algorithms Abstract: A crucial privacy-driven issue nowadays is re-identifying anonymized social\nnetworks by mapping them to correlated cross-domain auxiliary networks. Prior\nworks are typically based on modeling social networks as random graphs\nrepresenting users and their relations, and subsequently quantify the quality\nof mappings through cost functions that are proposed without sufficient\nrationale. Also, it remains unknown how to algorithmically meet the demand of\nsuch quantifications, i.e., to find the minimizer of the cost functions. We\naddress those concerns in a more realistic social network modeling\nparameterized by community structures that can be leveraged as side information\nfor de-anonymization. By Maximum A Posteriori (MAP) estimation, our first\ncontribution is new and well justified cost functions, which, when minimized,\nenjoy superiority to previous ones in finding the correct mapping with the\nhighest probability. The feasibility of the cost functions is then for the\nfirst time algorithmically characterized. While proving the general\nmultiplicative inapproximability, we are able to propose two algorithms, which,\nrespectively, enjoy an \\epsilon-additive approximation and a conditional\noptimality in carrying out successful user re-identification. Our theoretical\nfindings are empirically validated, with a notable dataset extracted from rare\ntrue cross-domain networks that reproduce genuine social network\nde-anonymization. Both theoretical and empirical observations also manifest the\nimportance of community information in enhancing privacy inferencing. \n\n"}
{"id": "1703.10744", "contents": "Title: Time-triggering versus event-triggering control over communication\n  channels Abstract: Time-triggered and event-triggered control strategies for stabilization of an\nunstable plant over a rate-limited communication channel subject to unknown,\nbounded delay are studied and compared. Event triggering carries implicit\ninformation, revealing the state of the plant. However, the delay in the\ncommunication channel causes information loss, as it makes the state\ninformation out of date. There is a critical delay value, when the loss of\ninformation due to the communication delay perfectly compensates the implicit\ninformation carried by the triggering events. This occurs when the maximum\ndelay equals the inverse of the entropy rate of the plant. In this context,\nextensions of our previous results for event triggering strategies are\npresented for vector systems and are compared with the data-rate theorem for\ntime-triggered control, that is extended here to a setting with unknown delay. \n\n"}
{"id": "1704.00386", "contents": "Title: Local Algorithms for Hierarchical Dense Subgraph Discovery Abstract: Finding the dense regions of a graph and relations among them is a\nfundamental problem in network analysis. Core and truss decompositions reveal\ndense subgraphs with hierarchical relations. The incremental nature of\nalgorithms for computing these decompositions and the need for global\ninformation at each step of the algorithm hinders scalable parallelization and\napproximations since the densest regions are not revealed until the end. In a\nprevious work, Lu et al. proposed to iteratively compute the $h$-indices of\nneighbor vertex degrees to obtain the core numbers and prove that the\nconvergence is obtained after a finite number of iterations. This work\ngeneralizes the iterative $h$-index computation for truss decomposition as well\nas nucleus decomposition which leverages higher-order structures to generalize\ncore and truss decompositions. In addition, we prove convergence bounds on the\nnumber of iterations. We present a framework of local algorithms to obtain the\ncore, truss, and nucleus decompositions. Our algorithms are local, parallel,\noffer high scalability, and enable approximations to explore time and quality\ntrade-offs. Our shared-memory implementation verifies the efficiency,\nscalability, and effectiveness of our local algorithms on real-world networks. \n\n"}
{"id": "1704.00387", "contents": "Title: Identifying networks with common organizational principles Abstract: Many complex systems can be represented as networks, and the problem of\nnetwork comparison is becoming increasingly relevant. There are many techniques\nfor network comparison, from simply comparing network summary statistics to\nsophisticated but computationally costly alignment-based approaches. Yet it\nremains challenging to accurately cluster networks that are of a different size\nand density, but hypothesized to be structurally similar. In this paper, we\naddress this problem by introducing a new network comparison methodology that\nis aimed at identifying common organizational principles in networks. The\nmethodology is simple, intuitive and applicable in a wide variety of settings\nranging from the functional classification of proteins to tracking the\nevolution of a world trade network. \n\n"}
{"id": "1704.00455", "contents": "Title: Joint Design of Digital and Analog Processing for Downlink C-RAN with\n  Large-Scale Antenna Arrays Abstract: In millimeter-wave communication systems with large-scale antenna arrays,\nconventional digital beamforming may not be cost-effective. A promising\nsolution is the implementation of hybrid beamforming techniques, which consist\nof low-dimensional digital beamforming followed by analog radio frequency (RF)\nbeamforming. This work studies the optimization of hybrid beamforming in the\ncontext of a cloud radio access network (C-RAN) architecture. In a C-RAN\nsystem, digital baseband signal processing functionalities are migrated from\nremote radio heads (RRHs) to a baseband processing unit (BBU) in the \"cloud\" by\nmeans of finite-capacity fronthaul links. Specifically, this work tackles the\nproblem of jointly optimizing digital beamforming and fronthaul quantization\nstrategies at the BBU, as well as RF beamforming at the RRHs, with the goal of\nmaximizing the weighted downlink sum-rate. Fronthaul capacity and per-RRH power\nconstraints are enforced along with constant modulus constraints on the RF\nbeamforming matrices. An iterative algorithm is proposed that is based on\nsuccessive convex approximation and on the relaxation of the constant modulus\nconstraint. The effectiveness of the proposed scheme is validated by numerical\nsimulation results. \n\n"}
{"id": "1704.00715", "contents": "Title: Convolutional Polar Codes Abstract: Arikan's Polar codes attracted much attention as the first efficiently\ndecodable and capacity achieving codes. Furthermore, Polar codes exhibit an\nexponentially decreasing block error probability with an asymptotic error\nexponent upper bounded by 1/2. Since their discovery, many attempts have been\nmade to improve the error exponent and the finite block-length performance,\nwhile keeping the bloc-structured kernel. Recently, two of us introduced a new\nfamily of efficiently decodable error-correction codes based on a recently\ndiscovered efficiently-contractible tensor network family in quantum many-body\nphysics, called branching MERA. These codes, called branching MERA codes,\ninclude Polar codes and also extend them in a non-trivial way by substituting\nthe bloc-structured kernel by a convolutional structure. Here, we perform an\nin-depth study of a particular example that can be thought of as a direct\nextension to Arikan's Polar code, which we therefore name Convolutional Polar\ncodes. We prove that these codes polarize and exponentially suppress the\nchannel's error probability, with an asymptotic error exponent log_2(3)/2 which\nis provably better than for Polar codes under successive cancellation decoding.\nWe also perform finite block-size numerical simulations which display improved\nerror-correcting capability with only a minor impact on decoding complexity. \n\n"}
{"id": "1704.01524", "contents": "Title: Core of communities in bipartite networks Abstract: We use the information present in a bipartite network to detect cores of\ncommunities of each set of the bipartite system. Cores of communities are found\nby investigating statistically validated projected networks obtained using\ninformation present in the bipartite network. Cores of communities are highly\ninformative and robust with respect to the presence of errors or missing\nentries in the bipartite network. We assess the statistical robustness of cores\nby investigating an artificial benchmark network, the co-authorship network,\nand the actor-movie network. The accuracy and precision of the partition\nobtained with respect to the reference partition are measured in terms of the\nadjusted Rand index and of the adjusted Wallace index respectively. The\ndetection of cores is highly precise although the accuracy of the methodology\ncan be limited in some cases. \n\n"}
{"id": "1704.02732", "contents": "Title: Degrees of Freedom and Achievable Rate of Wide-Band Multi-cell Multiple\n  Access Channels With No CSIT Abstract: This paper considers a $K$-cell multiple access channel with inter-symbol\ninterference. The primary finding of this paper is that, without instantaneous\nchannel state information at the transmitters (CSIT), the sum\ndegrees-of-freedom (DoF) of the considered channel is $\\frac{\\beta -1}{\\beta}K$\nwith $\\beta \\geq 2$ when the number of users per cell is sufficiently large,\nwhere $\\beta$ is the ratio of the maximum channel-impulse-response (CIR) length\nof desired links to that of interfering links in each cell. Our finding implies\nthat even without instantaneous CSIT, \\textit{interference-free DoF per cell}\nis achievable as $\\beta$ approaches infinity with a sufficiently large number\nof users per cell. This achievability is shown by a blind interference\nmanagement method that exploits the relativity in delay spreads between desired\nand interfering links. In this method, all inter-cell-interference signals are\naligned to the same direction by using a discrete-Fourier-transform-based\nprecoding with cyclic prefix that only depends on the number of CIR taps. Using\nthis method, we also characterize the achievable sum rate of the considered\nchannel, in a closed-form expression. \n\n"}
{"id": "1704.04707", "contents": "Title: Structure and Randomness of Continuous-Time Discrete-Event Processes Abstract: Loosely speaking, the Shannon entropy rate is used to gauge a stochastic\nprocess' intrinsic randomness; the statistical complexity gives the cost of\npredicting the process. We calculate, for the first time, the entropy rate and\nstatistical complexity of stochastic processes generated by finite unifilar\nhidden semi-Markov models---memoryful, state-dependent versions of renewal\nprocesses. Calculating these quantities requires introducing novel mathematical\nobjects ({\\epsilon}-machines of hidden semi-Markov processes) and new\ninformation-theoretic methods to stochastic processes. \n\n"}
{"id": "1704.06333", "contents": "Title: Rate-Splitting to Mitigate Residual Transceiver Hardware Impairments in\n  Massive MIMO Systems Abstract: Rate-Splitting (RS) has recently been shown to provide significant\nperformance benefits in various multi-user transmission scenarios. In parallel,\nthe huge degrees-of-freedom provided by the appealing massive Multiple-Input\nMultiple-Output (MIMO) necessitate the employment of inexpensive hardware,\nbeing more prone to hardware imperfections, in order to be a cost-efficient\ntechnology. Hence, in this work, we focus on a realistic massive Multiple-Input\nSingle-Output (MISO) Broadcast Channel (BC) hampered by the inevitable hardware\nimpairments. We consider a general experimentally validated model of hardware\nimpairments, accounting for the presence of \\textit{multiplicative distortion}\ndue to phase noise, \\textit{additive distortion noise} and \\textit{thermal\nnoise amplification}. Under both scenarios with perfect and imperfect channel\nstate information at the transmitter (CSIT), we analyze the potential\nrobustness of RS to each separate hardware imperfection. We analytically assess\nthe sum-rate degradation due to hardware imperfections. Interestingly, in the\ncase of imperfect CSIT, we demonstrate that RS is a robust strategy for\nmultiuser MIMO in the presence of phase and amplified thermal noise, since its\nsum-rate does not saturate at high signal-to-noise ratio (SNR), contrary to\nconventional techniques. On the other hand, the additive impairments always\nlead to a sum-rate saturation at high SNR, even after the application of RS.\nHowever, RS still enhances the performance. Furthermore, as the number of users\nincreases, the gains provided by RS decrease not only in ideal conditions, but\nin practical conditions with RTHIs as well. \n\n"}
{"id": "1704.08197", "contents": "Title: Character Networks and Book Genre Classification Abstract: We compare the social character networks of biographical, legendary and\nfictional texts, in search for marks of genre differentiation. We examine the\ndegree distribution of character appearance and find a power law that does not\ndepend on the literary genre or historical content. We also analyze local and\nglobal complex networks measures, in particular, correlation plots between the\nrecently introduced Lobby (or Hirsh $H(1)$) index and Degree, Betweenness and\nCloseness centralities. Assortativity plots, which previous literature claims\nto separate fictional from real social networks, were also studied. We've found\nno relevant differences in the books for these network measures and we give a\nplausible explanation why the previous assortativity result is not correct. \n\n"}
{"id": "1705.00763", "contents": "Title: Improved Bounds for Universal One-Bit Compressive Sensing Abstract: Unlike compressive sensing where the measurement outputs are assumed to be\nreal-valued and have infinite precision, in \"one-bit compressive sensing\",\nmeasurements are quantized to one bit, their signs. In this work, we show how\nto recover the support of sparse high-dimensional vectors in the one-bit\ncompressive sensing framework with an asymptotically near-optimal number of\nmeasurements. We also improve the bounds on the number of measurements for\napproximately recovering vectors from one-bit compressive sensing measurements.\nOur results are universal, namely the same measurement scheme works\nsimultaneously for all sparse vectors.\n  Our proof of optimality for support recovery is obtained by showing an\nequivalence between the task of support recovery using 1-bit compressive\nsensing and a well-studied combinatorial object known as Union Free Families. \n\n"}
{"id": "1705.00770", "contents": "Title: Galois LCD Codes over Finite Fields Abstract: In this paper, we study the complementary dual codes in more general setting\n(which are called Galois LCD codes) by a uniform method. A necessary and\nsufficient condition for linear codes to be Galois LCD codes is determined, and\nconstacyclic codes to be Galois LCD codes are characterized. Some illustrative\nexamples which constacyclic codes are Galois LCD MDS codes are provided as\nwell. In particular, we study Hermitian LCD constacyclic codes. Finally, we\npresent a construction of a class of Hermitian LCD codes which are also MDS\ncodes. \n\n"}
{"id": "1705.01640", "contents": "Title: State-Dependent Gaussian Multiple Access Channels: New Outer Bounds and\n  Capacity Results Abstract: This paper studies a two-user state-dependent Gaussian multiple-access\nchannel (MAC) with state noncausally known at one encoder. Two scenarios are\nconsidered: i) each user wishes to communicate an independent message to the\ncommon receiver, and ii) the two encoders send a common message to the receiver\nand the non-cognitive encoder (i.e., the encoder that does not know the state)\nsends an independent individual message (this model is also known as the MAC\nwith degraded message sets). For both scenarios, new outer bounds on the\ncapacity region are derived, which improve uniformly over the best known outer\nbounds. In the first scenario, the two corner points of the capacity region as\nwell as the sum rate capacity are established, and it is shown that a\nsingle-letter solution is adequate to achieve both the corner points and the\nsum rate capacity. Furthermore, the full capacity region is characterized in\nsituations in which the sum rate capacity is equal to the capacity of the\nhelper problem. The proof exploits the optimal-transportation idea of\nPolyanskiy and Wu (which was used previously to establish an outer bound on the\ncapacity region of the interference channel) and the worst-case Gaussian noise\nresult for the case in which the input and the noise are dependent. \n\n"}
{"id": "1705.02305", "contents": "Title: Case studies in network community detection Abstract: Community structure describes the organization of a network into subgraphs\nthat contain a prevalence of edges within each subgraph and relatively few\nedges across boundaries between subgraphs. The development of\ncommunity-detection methods has occurred across disciplines, with numerous and\nvaried algorithms proposed to find communities. As we present in this Chapter\nvia several case studies, community detection is not just an \"end game\" unto\nitself, but rather a step in the analysis of network data which is then useful\nfor furthering research in the disciplinary domain of interest. These\ncase-study examples arise from diverse applications, ranging from social and\npolitical science to neuroscience and genetics, and we have chosen them to\ndemonstrate key aspects of community detection and to highlight that community\ndetection, in practice, should be directed by the application at hand. \n\n"}
{"id": "1705.02356", "contents": "Title: Solving (most) of a set of quadratic equalities: Composite optimization\n  for robust phase retrieval Abstract: We develop procedures, based on minimization of the composition $f(x) =\nh(c(x))$ of a convex function $h$ and smooth function $c$, for solving random\ncollections of quadratic equalities, applying our methodology to phase\nretrieval problems. We show that the prox-linear algorithm we develop can solve\nphase retrieval problems---even with adversarially faulty measurements---with\nhigh probability as soon as the number of measurements $m$ is a constant factor\nlarger than the dimension $n$ of the signal to be recovered. The algorithm\nrequires essentially no tuning---it consists of solving a sequence of convex\nproblems---and it is implementable without any particular assumptions on the\nmeasurements taken. We provide substantial experiments investigating our\nmethods, indicating the practical effectiveness of the procedures and showing\nthat they succeed with high probability as soon as $m / n \\ge 2$ when the\nsignal is real-valued. \n\n"}
{"id": "1705.02723", "contents": "Title: Joint Trajectory and Communication Design for Multi-UAV Enabled Wireless\n  Networks Abstract: Unmanned aerial vehicles (UAVs) have attracted significant interest recently\nin assisting wireless communication due to their high maneuverability, flexible\ndeployment, and low cost. This paper considers a multi-UAV enabled wireless\ncommunication system, where multiple UAV-mounted aerial base stations (BSs) are\nemployed to serve a group of users on the ground. To achieve fair performance\namong users, we maximize the minimum throughput over all ground users in the\ndownlink communication by optimizing the multiuser communication scheduling and\nassociation jointly with the UAVs' trajectory and power control. The formulated\nproblem is a mixed integer non-convex optimization problem that is challenging\nto solve. As such, we propose an efficient iterative algorithm for solving it\nby applying the block coordinate descent and successive convex optimization\ntechniques. Specifically, the user scheduling and association, UAV trajectory,\nand transmit power are alternately optimized in each iteration. In particular,\nfor the non-convex UAV trajectory and transmit power optimization problems, two\napproximate convex optimization problems are solved, respectively. We further\nshow that the proposed algorithm is guaranteed to converge to at least a\nlocally optimal solution. To speed up the algorithm convergence and achieve\ngood throughput, a low-complexity and systematic initialization scheme is also\nproposed for the UAV trajectory design based on the simple circular trajectory\nand the circle packing scheme. Extensive simulation results are provided to\ndemonstrate the significant throughput gains of the proposed design as compared\nto other benchmark schemes. \n\n"}
{"id": "1705.03822", "contents": "Title: Context-Aware Hierarchical Online Learning for Performance Maximization\n  in Mobile Crowdsourcing Abstract: In mobile crowdsourcing (MCS), mobile users accomplish outsourced human\nintelligence tasks. MCS requires an appropriate task assignment strategy, since\ndifferent workers may have different performance in terms of acceptance rate\nand quality. Task assignment is challenging, since a worker's performance (i)\nmay fluctuate, depending on both the worker's current personal context and the\ntask context, (ii) is not known a priori, but has to be learned over time.\nMoreover, learning context-specific worker performance requires access to\ncontext information, which may not be available at a central entity due to\ncommunication overhead or privacy concerns. Additionally, evaluating worker\nperformance might require costly quality assessments. In this paper, we propose\na context-aware hierarchical online learning algorithm addressing the problem\nof performance maximization in MCS. In our algorithm, a local controller (LC)\nin the mobile device of a worker regularly observes the worker's context,\nher/his decisions to accept or decline tasks and the quality in completing\ntasks. Based on these observations, the LC regularly estimates the worker's\ncontext-specific performance. The mobile crowdsourcing platform (MCSP) then\nselects workers based on performance estimates received from the LCs. This\nhierarchical approach enables the LCs to learn context-specific worker\nperformance and it enables the MCSP to select suitable workers. In addition,\nour algorithm preserves worker context locally, and it keeps the number of\nrequired quality assessments low. We prove that our algorithm converges to the\noptimal task assignment strategy. Moreover, the algorithm outperforms simpler\ntask assignment strategies in experiments based on synthetic and real data. \n\n"}
{"id": "1705.05058", "contents": "Title: Learning-aided Stochastic Network Optimization with Imperfect State\n  Prediction Abstract: We investigate the problem of stochastic network optimization in the presence\nof imperfect state prediction and non-stationarity. Based on a novel\ndistribution-accuracy curve prediction model, we develop the predictive\nlearning-aided control (PLC) algorithm, which jointly utilizes historic and\npredicted network state information for decision making. PLC is an online\nalgorithm that requires zero a-prior system statistical information, and\nconsists of three key components, namely sequential distribution estimation and\nchange detection, dual learning, and online queue-based control.\n  Specifically, we show that PLC simultaneously achieves good long-term\nperformance, short-term queue size reduction, accurate change detection, and\nfast algorithm convergence. In particular, for stationary networks, PLC\nachieves a near-optimal $[O(\\epsilon)$, $O(\\log(1/\\epsilon)^2)]$ utility-delay\ntradeoff. For non-stationary networks, \\plc{} obtains an $[O(\\epsilon),\nO(\\log^2(1/\\epsilon)$ $+ \\min(\\epsilon^{c/2-1}, e_w/\\epsilon))]$\nutility-backlog tradeoff for distributions that last\n$\\Theta(\\frac{\\max(\\epsilon^{-c}, e_w^{-2})}{\\epsilon^{1+a}})$ time, where\n$e_w$ is the prediction accuracy and $a=\\Theta(1)>0$ is a constant (the\nBackpressue algorithm \\cite{neelynowbook} requires an $O(\\epsilon^{-2})$ length\nfor the same utility performance with a larger backlog). Moreover, PLC detects\ndistribution change $O(w)$ slots faster with high probability ($w$ is the\nprediction size) and achieves an $O(\\min(\\epsilon^{-1+c/2},\ne_w/\\epsilon)+\\log^2(1/\\epsilon))$ convergence time. Our results demonstrate\nthat state prediction (even imperfect) can help (i) achieve faster detection\nand convergence, and (ii) obtain better utility-delay tradeoffs. \n\n"}
{"id": "1705.05060", "contents": "Title: Capacity of Some Index Coding Problems with Symmetric Neighboring\n  Interference Abstract: A single unicast index coding problem (SUICP) with symmetric neighboring\ninterference (SNI) has equal number of $K$ messages and $K$ receivers, the\n$k$th receiver $R_{k}$ wanting the $k$th message $x_{k}$ and having the\nside-information $\\mathcal{K}_{k}=(\\mathcal{I}_{k} \\cup x_{k})^c,$ where\n${I}_k= \\{x_{k-U},\\dots,x_{k-2},x_{k-1}\\}\\cup\\{x_{k+1},\nx_{k+2},\\dots,x_{k+D}\\}$ is the interference with $D$ messages after and $U$\nmessages before its desired message. Maleki, Cadambe and Jafar obtained the\ncapacity of this symmetric neighboring interference single unicast index coding\nproblem (SNI-SUICP) with $(K)$ tending to infinity and Blasiak, Kleinberg and\nLubetzky for the special case of $(D=U=1)$ with $K$ being finite. In this work,\nfor any finite $K$ and arbitrary $D$ we obtain the capacity for the case\n$U=gcd(K,D+1)-1.$ Our proof is constructive, i.e., we give an explicit\nconstruction of a linear index code achieving the capacity. \n\n"}
{"id": "1705.05649", "contents": "Title: Super-resolution channel estimation for mmWave massive MIMO with hybrid\n  precoding Abstract: Channel estimation is challenging for millimeter-wave (mmWave) massive MIMO\nwith hybrid precoding, since the number of radio frequency (RF) chains is much\nsmaller than that of antennas. Conventional compressive sensing based channel\nestimation schemes suffer from severe resolution loss due to the channel angle\nquantization. To improve the channel estimation accuracy, we propose an\niterative reweight (IR)-based super-resolution channel estimation scheme in\nthis paper. By optimizing an objective function through the gradient descent\nmethod, the proposed scheme can iteratively move the estimated angle of\narrivals/departures (AoAs/AoDs) towards the optimal solutions, and finally\nrealize the super-resolution channel estimation. In the optimization, a weight\nparameter is used to control the tradeoff between the sparsity and the data\nfitting error. In addition, a singular value decomposition (SVD)-based\npreconditioning is developed to reduce the computational complexity of the\nproposed scheme. Simulation results verify the better performance of the\nproposed scheme than conventional solutions. \n\n"}
{"id": "1705.06782", "contents": "Title: Comprehensive Modeling of Three-Phase Distribution Systems via the Bus\n  Admittance Matrix Abstract: The theme of this paper is three-phase distribution system modeling suitable\nfor the Z-Bus load-flow. Detailed models of wye and delta constant-power,\nconstant-current, and constant-impedance loads are presented. Models of\ntransmission lines, voltage regulators, and transformers that build the bus\nadmittance matrix (Y-Bus) are laid out. The Z-Bus load-flow is then reviewed\nand the singularity of the Y-Bus in case of certain transformer connections is\nrigorously discussed. Based on realistic assumptions and conventional\nmodifications, the invertibility of the Y-Bus is proved. Last but not least,\nthe MATLAB scripts that construct the detailed component models for the IEEE\n37-bus, IEEE 123-bus, and 8500-node feeders as well as the European 906-bus\nlow-voltage feeder are provided. \n\n"}
{"id": "1705.07256", "contents": "Title: Learning Feature Nonlinearities with Non-Convex Regularized Binned\n  Regression Abstract: For various applications, the relations between the dependent and independent\nvariables are highly nonlinear. Consequently, for large scale complex problems,\nneural networks and regression trees are commonly preferred over linear models\nsuch as Lasso. This work proposes learning the feature nonlinearities by\nbinning feature values and finding the best fit in each quantile using\nnon-convex regularized linear regression. The algorithm first captures the\ndependence between neighboring quantiles by enforcing smoothness via\npiecewise-constant/linear approximation and then selects a sparse subset of\ngood features. We prove that the proposed algorithm is statistically and\ncomputationally efficient. In particular, it achieves linear rate of\nconvergence while requiring near-minimal number of samples. Evaluations on\nsynthetic and real datasets demonstrate that algorithm is competitive with\ncurrent state-of-the-art and accurately learns feature nonlinearities. Finally,\nwe explore an interesting connection between the binning stage of our algorithm\nand sparse Johnson-Lindenstrauss matrices. \n\n"}
{"id": "1705.08110", "contents": "Title: Combinatorial Semi-Bandits with Knapsacks Abstract: We unify two prominent lines of work on multi-armed bandits: bandits with\nknapsacks (BwK) and combinatorial semi-bandits. The former concerns limited\n\"resources\" consumed by the algorithm, e.g., limited supply in dynamic pricing.\nThe latter allows a huge number of actions but assumes combinatorial structure\nand additional feedback to make the problem tractable. We define a common\ngeneralization, support it with several motivating examples, and design an\nalgorithm for it. Our regret bounds are comparable with those for BwK and\ncombinatorial semi- bandits. \n\n"}
{"id": "1705.08148", "contents": "Title: Capacity Outer Bound and Degrees of Freedom of Wiener Phase Noise\n  Channels with Oversampling Abstract: The discrete-time Wiener phase noise channel with an integrate-and-dump\nmulti-sample receiver is studied.\n  A novel outer bound on the capacity with an average input power constraint is\nderived as a function of the oversampling factor.\n  This outer bound yields the degrees of freedom for the scenario in which the\noversampling factor grows with the transmit power $P$ as $P^{\\alpha}$.\n  The result shows, perhaps surprisingly, that the largest pre-log that can be\nattained with phase modulation at high signal-to-noise ratio is at most $1/4$. \n\n"}
{"id": "1705.08473", "contents": "Title: New methods to generate massive synthetic networks Abstract: One of the biggest needs in network science research is access to large\nrealistic datasets. As data analytics methods permeate a range of diverse\ndisciplines---e.g., computational epidemiology, sustainability, social media\nanalytics, biology, and transportation--- network datasets that can exhibit\ncharacteristics encountered in each of these disciplines becomes paramount. The\nkey technical issue is to be able to generate synthetic topologies with\npre-specified, arbitrary, degree distributions. Existing methods are limited in\ntheir ability to faithfully reproduce macro-level characteristics of networks\nwhile at the same time respecting particular degree distributions. We present a\nsuite of three algorithms that exploit the principle of residual degree\nattenuation to generate synthetic topologies that adhere to macro-level\nreal-world characteristics. By evaluating these algorithms w.r.t. several\nreal-world datasets we demonstrate their ability to faithfully reproduce\nnetwork characteristics such as node degree, clustering coefficient, hop\nlength, and k-core structure distributions. \n\n"}
{"id": "1705.09076", "contents": "Title: Wireless Powered Communications with Finite Battery and Finite\n  Blocklength Abstract: We analyze a wireless communication system with finite block length and\nfinite battery energy, under quasi-static Nakagami-m fading. Wireless energy\ntransfer is carried out in the downlink while information transfer occurs in\nthe uplink. Transmission strategies for scenarios with/without energy\naccumulation between transmission rounds are characterized in terms of error\nprobability and energy consumption. A power control protocol for the energy\naccumulation scenario is proposed and results show the enormous impact on\nimproving the system performance, in terms of error probability and energy\nconsumption. The numerical results corroborate the existence and uniqueness of\nan optimum target error probability, while showing that a relatively small\nbattery could be a limiting factor for some setups, specially when using the\nenergy accumulation strategy. \n\n"}
{"id": "1705.09590", "contents": "Title: Fourier Phase Retrieval: Uniqueness and Algorithms Abstract: The problem of recovering a signal from its phaseless Fourier transform\nmeasurements, called Fourier phase retrieval, arises in many applications in\nengineering and science. Fourier phase retrieval poses fundamental theoretical\nand algorithmic challenges. In general, there is no unique mapping between a\none-dimensional signal and its Fourier magnitude and therefore the problem is\nill-posed. Additionally, while almost all multidimensional signals are uniquely\nmapped to their Fourier magnitude, the performance of existing algorithms is\ngenerally not well-understood. In this chapter we survey methods to guarantee\nuniqueness in Fourier phase retrieval. We then present different algorithmic\napproaches to retrieve the signal in practice. We conclude by outlining some of\nthe main open questions in this field. \n\n"}
{"id": "1705.10261", "contents": "Title: Sparse Maximum-Entropy Random Graphs with a Given Power-Law Degree\n  Distribution Abstract: Even though power-law or close-to-power-law degree distributions are\nubiquitously observed in a great variety of large real networks, the\nmathematically satisfactory treatment of random power-law graphs satisfying\nbasic statistical requirements of realism is still lacking. These requirements\nare: sparsity, exchangeability, projectivity, and unbiasedness. The last\nrequirement states that entropy of the graph ensemble must be maximized under\nthe degree distribution constraints. Here we prove that the hypersoft\nconfiguration model (HSCM), belonging to the class of random graphs with latent\nhyperparameters, also known as inhomogeneous random graphs or $W$-random\ngraphs, is an ensemble of random power-law graphs that are sparse, unbiased,\nand either exchangeable or projective. The proof of their unbiasedness relies\non generalized graphons, and on mapping the problem of maximization of the\nnormalized Gibbs entropy of a random graph ensemble, to the graphon entropy\nmaximization problem, showing that the two entropies converge to each other in\nthe large-graph limit. \n\n"}
{"id": "1705.10407", "contents": "Title: Solving Almost all Systems of Random Quadratic Equations Abstract: This paper deals with finding an $n$-dimensional solution $x$ to a system of\nquadratic equations of the form $y_i=|\\langle{a}_i,x\\rangle|^2$ for $1\\le i \\le\nm$, which is also known as phase retrieval and is NP-hard in general. We put\nforth a novel procedure for minimizing the amplitude-based least-squares\nempirical loss, that starts with a weighted maximal correlation initialization\nobtainable with a few power or Lanczos iterations, followed by successive\nrefinements based upon a sequence of iteratively reweighted (generalized)\ngradient iterations. The two (both the initialization and gradient flow) stages\ndistinguish themselves from prior contributions by the inclusion of a fresh\n(re)weighting regularization technique. The overall algorithm is conceptually\nsimple, numerically scalable, and easy-to-implement. For certain random\nmeasurement models, the novel procedure is shown capable of finding the true\nsolution $x$ in time proportional to reading the data $\\{(a_i;y_i)\\}_{1\\le i\n\\le m}$. This holds with high probability and without extra assumption on the\nsignal $x$ to be recovered, provided that the number $m$ of equations is some\nconstant $c>0$ times the number $n$ of unknowns in the signal vector, namely,\n$m>cn$. Empirically, the upshots of this contribution are: i) (almost) $100\\%$\nperfect signal recovery in the high-dimensional (say e.g., $n\\ge 2,000$) regime\ngiven only an information-theoretic limit number of noiseless equations,\nnamely, $m=2n-1$ in the real-valued Gaussian case; and, ii) (nearly) optimal\nstatistical accuracy in the presence of additive noise of bounded support.\nFinally, substantial numerical tests using both synthetic data and real images\ncorroborate markedly improved signal recovery performance and computational\nefficiency of our novel procedure relative to state-of-the-art approaches. \n\n"}
{"id": "1705.11154", "contents": "Title: Models and information-theoretic bounds for nanopore sequencing Abstract: Nanopore sequencing is an emerging new technology for sequencing DNA, which\ncan read long fragments of DNA (~50,000 bases) in contrast to most current\nshort-read sequencing technologies which can only read hundreds of bases. While\nnanopore sequencers can acquire long reads, the high error rates (20%-30%) pose\na technical challenge. In a nanopore sequencer, a DNA is migrated through a\nnanopore and current variations are measured. The DNA sequence is inferred from\nthis observed current pattern using an algorithm called a base-caller. In this\npaper, we propose a mathematical model for the \"channel\" from the input DNA\nsequence to the observed current, and calculate bounds on the information\nextraction capacity of the nanopore sequencer. This model incorporates\nimpairments like (non-linear) inter-symbol interference, deletions, as well as\nrandom response. These information bounds have two-fold application: (1) The\ndecoding rate with a uniform input distribution can be used to calculate the\naverage size of the plausible list of DNA sequences given an observed current\ntrace. This bound can be used to benchmark existing base-calling algorithms, as\nwell as serving a performance objective to design better nanopores. (2) When\nthe nanopore sequencer is used as a reader in a DNA storage system, the storage\ncapacity is quantified by our bounds. \n\n"}
{"id": "1706.03205", "contents": "Title: Item Silk Road: Recommending Items from Information Domains to Social\n  Users Abstract: Online platforms can be divided into information-oriented and social-oriented\ndomains. The former refers to forums or E-commerce sites that emphasize\nuser-item interactions, like Trip.com and Amazon; whereas the latter refers to\nsocial networking services (SNSs) that have rich user-user connections, such as\nFacebook and Twitter. Despite their heterogeneity, these two domains can be\nbridged by a few overlapping users, dubbed as bridge users. In this work, we\naddress the problem of cross-domain social recommendation, i.e., recommending\nrelevant items of information domains to potential users of social networks. To\nour knowledge, this is a new problem that has rarely been studied before.\n  Existing cross-domain recommender systems are unsuitable for this task since\nthey have either focused on homogeneous information domains or assumed that\nusers are fully overlapped. Towards this end, we present a novel Neural Social\nCollaborative Ranking (NSCR) approach, which seamlessly sews up the user-item\ninteractions in information domains and user-user connections in SNSs. In the\ninformation domain part, the attributes of users and items are leveraged to\nstrengthen the embedding learning of users and items. In the SNS part, the\nembeddings of bridge users are propagated to learn the embeddings of other\nnon-bridge users. Extensive experiments on two real-world datasets demonstrate\nthe effectiveness and rationality of our NSCR method. \n\n"}
{"id": "1706.03342", "contents": "Title: Explicit Lower Bounds on the Outage Probability of Integer Forcing over\n  Nrx2 Channels Abstract: The performance of integer-forcing equalization for communication over the\ncompound multiple-input multipleoutput channel is investigated. An upper bound\non the resulting outage probability as a function of the gap to capacity has\nbeen derived previously, assuming a random precoding matrix drawn from the\ncircular unitary ensemble is applied prior to transmission. In the present work\na simple and explicit lower bound on the worst-case outage probability is\nderived for the case of a system with two transmit antennas and two or more\nreceive antennas, leveraging the properties of the Jacobi ensemble. The derived\nlower bound is also extended to random space-time precoding, and may serve as a\nuseful benchmark for assessing the relative merits of various algebraic\nspace-time precoding schemes. We further show that the lower bound may be\nadapted to the case of a $1 \\times N_t$ system. As an application of this, we\nderive closed-form bounds for the symmetric-rate capacity of the Rayleigh\nfading multiple-access channel where all terminals are equipped with a single\nantenna. Lastly, we demonstrate that the integer-forcing equalization coupled\nwith distributed space-time coding is able to approach these bounds. \n\n"}
{"id": "1706.04147", "contents": "Title: Layer Communities in Multiplex Networks Abstract: Multiplex networks are a type of multilayer network in which entities are\nconnected to each other via multiple types of connections. We propose a method,\nbased on computing pairwise similarities between layers and then doing\ncommunity detection, for grouping structurally similar layers in multiplex\nnetworks. We illustrate our approach using both synthetic and empirical\nnetworks, and we are able to find meaningful groups of layers in both cases.\nFor example, we find that airlines that are based in similar geographic\nlocations tend to be grouped together in an airline multiplex network and that\nrelated research areas in physics tend to be grouped together in an multiplex\ncollaboration network. \n\n"}
{"id": "1706.05120", "contents": "Title: On Structural Controllability of Symmetric (Brain) Networks Abstract: The question of controllability of natural and man-made network systems has\nrecently received considerable attention. In the context of the human brain,\nthe study of controllability may not only shed light into the organization and\nfunction of different neural circuits, but also inform the design and\nimplementation of minimally invasive yet effective intervention protocols to\ntreat neurological disorders. While the characterization of brain\ncontrollability is still in its infancy, some results have recently appeared\nand given rise to scientific debate. Among these, [1] has numerically shown\nthat a class of brain networks constructed from DSI/DTI imaging data are\ncontrollable from one brain region. That is, a single brain region is\ntheoretically capable of moving the whole brain network towards any desired\ntarget state. In this note we provide evidence supporting controllability of\nbrain networks from a single region as discussed in [1], thus contradicting the\nmain conclusion and methods developed in [2]. \n\n"}
{"id": "1706.05572", "contents": "Title: Information Structure Design in Team Decision Problems Abstract: We consider a problem of information structure design in team decision\nproblems and team games. We propose simple, scalable greedy algorithms for\nadding a set of extra information links to optimize team performance and\nresilience to non-cooperative and adversarial agents. We show via a simple\ncounterexample that the set function mapping additional information links to\nteam performance is in general not supermodular. Although this implies that the\ngreedy algorithm is not accompanied by worst-case performance guarantees, we\nillustrate through numerical experiments that it can produce effective and\noften optimal or near optimal information structure modifications. \n\n"}
{"id": "1706.05626", "contents": "Title: Buildings-to-Grid Integration Framework Abstract: This paper puts forth a mathematical framework for Buildings-to-Grid (BtG)\nintegration in smart cities. The framework explicitly couples power grid and\nbuilding's control actions and operational decisions, and can be utilized by\nbuildings and power grids operators to simultaneously optimize their\nperformance. Simplified dynamics of building clusters and building-integrated\npower networks with algebraic equations are presented---both operating at\ndifferent time-scales. A model predictive control (MPC)-based algorithm that\nformulates the BtG integration and accounts for the time-scale discrepancy is\ndeveloped. The formulation captures dynamic and algebraic power flow\nconstraints of power networks and is shown to be numerically advantageous. The\npaper analytically establishes that the BtG integration yields a reduced total\nsystem cost in comparison with decoupled designs where grid and building\noperators determine their controls separately. The developed framework is\ntested on standard power networks that include thousands of buildings modeled\nusing industrial data. Case studies demonstrate building energy savings and\nsignificant frequency regulation, while these findings carry over in network\nsimulations with nonlinear power flows and mismatch in building model\nparameters. Finally, simulations indicate that the performance does not\nsignificantly worsen when there is uncertainty in the forecasted weather and\nbase load conditions. \n\n"}
{"id": "1706.07181", "contents": "Title: Equilibria, information and frustration in heterogeneous network games\n  with conflicting preferences Abstract: Interactions between people are the basis on which the structure of our\nsociety arises as a complex system and, at the same time, are the starting\npoint of any physical description of it. In the last few years, much\ntheoretical research has addressed this issue by combining the physics of\ncomplex networks with a description of interactions in terms of evolutionary\ngame theory. We here take this research a step further by introducing a most\nsalient societal factor such as the individuals' preferences, a characteristic\nthat is key to understand much of the social phenomenology these days. We\nconsider a heterogeneous, agent-based model in which agents interact\nstrategically with their neighbors but their preferences and payoffs for the\npossible actions differ. We study how such a heterogeneous network behaves\nunder evolutionary dynamics and different strategic interactions, namely\ncoordination games and best shot games. With this model we study the emergence\nof the equilibria predicted analytically in random graphs under best response\ndynamics, and we extend this test to unexplored contexts like proportional\nimitation and scale free networks. We show that some theoretically predicted\nequilibria do not arise in simulations with incomplete Information, and we\ndemonstrate the importance of the graph topology and the payoff function\nparameters for some games. Finally, we discuss our results with available\nexperimental evidence on coordination games, showing that our model agrees\nbetter with the experiment that standard economic theories, and draw hints as\nto how to maximize social efficiency in situations of conflicting preferences. \n\n"}
{"id": "1706.07401", "contents": "Title: A Geometric Analysis of Power System Loadability Regions Abstract: Understanding the feasible power flow region is of central importance to\npower system analysis. In this paper, we propose a geometric view of the power\nsystem loadability problem. By using rectangular coordinates for complex\nvoltages, we provide an integrated geometric understanding of active and\nreactive power flow equations on loadability boundaries. Based on such an\nunderstanding, we develop a linear programming framework to 1) verify if an\noperating point is on the loadability boundary, 2) compute the margin of an\noperating point to the loadability boundary, and 3) calculate a loadability\nboundary point of any direction. The proposed method is computationally more\nefficient than existing methods since it does not require solving nonlinear\noptimization problems or calculating the eigenvalues of the power flow\nJacobian. Standard IEEE test cases demonstrate the capability of the new method\ncompared to the current state-of-the-art methods. \n\n"}
{"id": "1706.07523", "contents": "Title: Communication-Aware Computing for Edge Processing Abstract: We consider a mobile edge computing problem, in which mobile users offload\ntheir computation tasks to computing nodes (e.g., base stations) at the network\nedge. The edge nodes compute the requested functions and communicate the\ncomputed results to the users via wireless links. For this problem, we propose\na Universal Coded Edge Computing (UCEC) scheme for linear functions to\nsimultaneously minimize the load of computation at the edge nodes, and maximize\nthe physical-layer communication efficiency towards the mobile users. In the\nproposed UCEC scheme, edge nodes create coded inputs of the users, from which\nthey compute coded output results. Then, the edge nodes utilize the computed\ncoded results to create communication messages that zero-force all the\ninterference signals over the air at each user. Specifically, the proposed\nscheme is universal since the coded computations performed at the edge nodes\nare oblivious of the channel states during the communication process from the\nedge nodes to the users. \n\n"}
{"id": "1706.08021", "contents": "Title: Online Power Control for Block i.i.d. Energy Harvesting Channels Abstract: We study the problem of online power control for energy harvesting\ncommunication nodes with random energy arrivals and a finite battery. We assume\na block i.i.d. stochastic model for the energy arrivals, in which the energy\narrivals are constant for a fixed duration $T$, but are independent across\ndifferent blocks, drawn from an arbitrary distribution. This model serves as a\nsimple approximation to a random process with coherence time $T$. We propose a\nsimple online power control policy, and prove that its performance gap to the\noptimal throughput is bounded by a constant which is independent of the\nparameters of the problem. This also yields a simple formula for the\napproximately optimal long-term average throughput, which sheds some light on\nthe qualitative behavior of the throughput and how it depends on the coherence\ntime of the energy arrival process. Our results show that, perhaps\ncounter-intuitively, for a fixed mean energy arrival rate the throughput\ndecreases with increasing coherence time $T$ of the energy arrival process. In\nparticular, the battery size needed to approach the AWGN capacity of the\nchannel increases linearly with the coherence time of the process. Finally, we\nshow that our results can provide an approximation to the information-theoretic\ncapacity of the same channel. \n\n"}
{"id": "1706.10291", "contents": "Title: Convergence of the randomized Kaczmarz method for phase retrieval Abstract: The classical Kaczmarz iteration and its randomized variants are popular\ntools for fast inversion of linear overdetermined systems. This method extends\nnaturally to the setting of the phase retrieval problem via substituting at\neach iteration the phase of any measurement of the available approximate\nsolution for the unknown phase of the measurement of the true solution. Despite\nthe simplicity of the method, rigorous convergence guarantees that are\navailable for the classical linear setting have not been established so far for\nthe phase retrieval setting. In this short note, we provide a convergence\nresult for the randomized Kaczmarz method for phase retrieval in\n$\\mathbb{R}^d$. We show that with high probability a random measurement system\nof size $m \\asymp d$ will be admissible for this method in the sense that\nconvergence in the mean square sense is guaranteed with any prescribed\nprobability. The convergence is exponential and comparable to the linear\nsetting. \n\n"}
{"id": "1707.00735", "contents": "Title: Polar Codes for SCMA Systems Abstract: In this paper, we design and compare multilevel polar coding (MLPC) and\nbit-interleaved polar coded modulation (BIPCM) for uplink sparse code multiple\naccess (SCMA) systems that operate over fast and block fading channels. Both\nsuccessive cancellation (SC) and successive cancellation list (SCL) decoding\nalgorithms are considered. Simulation results show that, with either decoder,\nBIPCM performs better than its MLPC counterpart. Also, both BIPCM and MLPC\nexhibit a performance advantage over LTE turbo-coded and WiMAX LDPC SCMA\nsystems when the SCL technique is used for decoding. \n\n"}
{"id": "1707.01134", "contents": "Title: Achievable Rates for Probabilistic Shaping Abstract: For a layered probabilistic shaping (PS) scheme with a general decoding\nmetric, an achievable rate is derived using Gallager's error exponent approach\nand the concept of achievable code rates is introduced. Several instances for\nspecific decoding metrics are discussed, including bit-metric decoding,\ninterleaved coded modulation, and hard-decision decoding. It is shown that\nimportant previously known achievable rates can also be achieved by layered PS.\nA practical instance of layered PS is the recently proposed probabilistic\namplitude shaping (PAS). \n\n"}
{"id": "1707.01401", "contents": "Title: Optimal percolation on multiplex networks Abstract: Optimal percolation is the problem of finding the minimal set of nodes such\nthat if the members of this set are removed from a network, the network is\nfragmented into non-extensive disconnected clusters. The solution of the\noptimal percolation problem has direct applicability in strategies of\nimmunization in disease spreading processes, and influence maximization for\ncertain classes of opinion dynamical models. In this paper, we consider the\nproblem of optimal percolation on multiplex networks. The multiplex scenario\nserves to realistically model various technological, biological, and social\nnetworks. We find that the multilayer nature of these systems, and more\nprecisely multiplex characteristics such as edge overlap and interlayer\ndegree-degree correlation, profoundly changes the properties of the set of\nnodes identified as the solution of the optimal percolation problem. \n\n"}
{"id": "1707.01846", "contents": "Title: On User Pairing in NOMA Uplink Abstract: User pairing in Non-Orthogonal Multiple-Access (NOMA) uplink based on channel\nstate information is investigated considering some predefined power allocation\nschemes. The base station divides the set of users into disjunct pairs and\nassigns the available resources to these pairs. The combinatorial problem of\nuser pairing to achieve the maximum sum rate is analyzed in the large system\nlimit for various scenarios, and some optimum and sub-optimum algorithms with a\npolynomial-time complexity are proposed. In the first scenario, $2M$ users and\nthe base station have a single-antenna and communicate over $M$ subcarriers.\nThe performance of optimum pairing is derived for $M\\rightarrow \\infty$ and\nshown to be superior to random pairing and orthogonal multiple access\ntechniques. In the second setting, a novel NOMA scheme for a multi-antenna base\nstation and single carrier communication is proposed. In this case, the users\nneed not be aware of the pairing strategy. Furthermore, the proposed NOMA\nscheme is generalized to multi-antenna users. It is shown that random and\noptimum user pairing perform similarly in the large system limit, but optimum\npairing is significantly better in finite dimensions. It is shown that the\nproposed NOMA scheme outperforms a previously proposed NOMA scheme with signal\nalignment. \n\n"}
{"id": "1707.02108", "contents": "Title: Sampling of Temporal Networks: Methods and Biases Abstract: Temporal networks have been increasingly used to model a diversity of systems\nthat evolve in time; for example human contact structures over which dynamic\nprocesses such as epidemics take place. A fundamental aspect of real-life\nnetworks is that they are sampled within temporal and spatial frames.\nFurthermore, one might wish to subsample networks to reduce their size for\nbetter visualization or to perform computationally intensive simulations. The\nsampling method may affect the network structure and thus caution is necessary\nto generalize results based on samples. In this paper, we study four sampling\nstrategies applied to a variety of real-life temporal networks. We quantify the\nbiases generated by each sampling strategy on a number of relevant statistics\nsuch as link activity, temporal paths and epidemic spread. We find that some\nbiases are common in a variety of networks and statistics, but one strategy,\nuniform sampling of nodes, shows improved performance in most scenarios. Our\nresults help researchers to better design network data collection protocols and\nto understand the limitations of sampled temporal network data. \n\n"}
{"id": "1707.03378", "contents": "Title: Sensor Calibration for Off-the-Grid Spectral Estimation Abstract: This paper studies sensor calibration in spectral estimation where the true\nfrequencies are located on a continuous domain. We consider a uniform array of\nsensors that collects measurements whose spectrum is composed of a finite\nnumber of frequencies, where each sensor has an unknown calibration parameter.\nOur goal is to recover the spectrum and the calibration parameters\nsimultaneously from multiple snapshots of the measurements. In the noiseless\ncase with an infinite number of snapshots, we prove uniqueness of this problem\nup to certain trivial, inevitable ambiguities based on an algebraic method, as\nlong as there are more sensors than frequencies. We then analyze the\nsensitivity of this algebraic technique with respect to the number of snapshots\nand noise.\n  We next propose an optimization approach that makes full use of the\nmeasurements by minimizing a non-convex objective which is non-negative and\ncontinuously differentiable over all calibration parameters and Toeplitz\nmatrices. We prove that, in the case of infinite snapshots and noiseless\nmeasurements, the objective vanishes only at equivalent solutions to the true\ncalibration parameters and the measurement covariance matrix. The objective is\nminimized using Wirtinger gradient descent which is proven to converge to a\ncritical point. We show empirically that this critical point provides a good\napproximation of the true calibration parameters and the underlying\nfrequencies. \n\n"}
{"id": "1707.03815", "contents": "Title: Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via\n  Ranking Abstract: Methods that learn representations of nodes in a graph play a critical role\nin network analysis since they enable many downstream learning tasks. We\npropose Graph2Gauss - an approach that can efficiently learn versatile node\nembeddings on large scale (attributed) graphs that show strong performance on\ntasks such as link prediction and node classification. Unlike most approaches\nthat represent nodes as point vectors in a low-dimensional continuous space, we\nembed each node as a Gaussian distribution, allowing us to capture uncertainty\nabout the representation. Furthermore, we propose an unsupervised method that\nhandles inductive learning scenarios and is applicable to different types of\ngraphs: plain/attributed, directed/undirected. By leveraging both the network\nstructure and the associated node attributes, we are able to generalize to\nunseen nodes without additional training. To learn the embeddings we adopt a\npersonalized ranking formulation w.r.t. the node distances that exploits the\nnatural ordering of the nodes imposed by the network structure. Experiments on\nreal world networks demonstrate the high performance of our approach,\noutperforming state-of-the-art network embedding methods on several different\ntasks. Additionally, we demonstrate the benefits of modeling uncertainty - by\nanalyzing it we can estimate neighborhood diversity and detect the intrinsic\nlatent dimensionality of a graph. \n\n"}
{"id": "1707.04926", "contents": "Title: Theoretical insights into the optimization landscape of\n  over-parameterized shallow neural networks Abstract: In this paper we study the problem of learning a shallow artificial neural\nnetwork that best fits a training data set. We study this problem in the\nover-parameterized regime where the number of observations are fewer than the\nnumber of parameters in the model. We show that with quadratic activations the\noptimization landscape of training such shallow neural networks has certain\nfavorable characteristics that allow globally optimal models to be found\nefficiently using a variety of local search heuristics. This result holds for\nan arbitrary training data of input/output pairs. For differentiable activation\nfunctions we also show that gradient descent, when suitably initialized,\nconverges at a linear rate to a globally optimal model. This result focuses on\na realizable model where the inputs are chosen i.i.d. from a Gaussian\ndistribution and the labels are generated according to planted weight\ncoefficients. \n\n"}
{"id": "1707.06271", "contents": "Title: Optimal Beamforming for Gaussian MIMO Wiretap Channels with Two Transmit\n  Antennas Abstract: A Gaussian multiple-input multiple-output wiretap channel in which the\neavesdropper and legitimate receiver are equipped with arbitrary numbers of\nantennas and the transmitter has two antennas is studied in this paper. Under\nan average power constraint, the optimal input covariance to obtain the secrecy\ncapacity of this channel is unknown, in general. In this paper, the input\ncovariance matrix required to achieve the capacity is determined. It is shown\nthat the secrecy capacity of this channel can be achieved by linear precoding.\nThe optimal precoding and power allocation schemes that maximize the achievable\nsecrecy rate, and thus achieve the capacity, are developed subsequently. The\nsecrecy capacity is then compared with the achievable secrecy rate of\ngeneralized singular value decomposition (GSVD)-based precoding, which is the\nbest previously proposed technique for this problem. Numerical results\ndemonstrate that substantial gain can be obtained in secrecy rate between the\nproposed and GSVD-based precodings. \n\n"}
{"id": "1707.07041", "contents": "Title: Sensitive and Nonlinear Far Field RF Energy Harvesting in Wireless\n  Communications Abstract: This work studies both limited sensitivity and nonlinearity of far field RF\nenergy harvesting observed in reality and quantifies their effect, attempting\nto fill a major hole in the simultaneous wireless information and power\ntransfer (SWIPT) literature. RF harvested power is modeled as an arbitrary\nnonlinear, continuous, and non-decreasing function of received power, taking\ninto account limited sensitivity and saturation effects. RF harvester's\nsensitivity may be several dBs worse than communications receiver's\nsensitivity, potentially rendering RF information signals useless for energy\nharvesting purposes. Given finite number of datapoint pairs of harvested\n(output) power and corresponding input power, a piecewise linear approximation\nis applied and the statistics of the harvested power are offered, as a function\nof the wireless channel fading statistics. Limited number of datapoints are\nneeded and accuracy analysis is also provided. Case studies include duty-cycled\n(non-continuous), as well as continuous SWIPT, comparing with industry-level,\nRF harvesting. The proposed approximation, even though simple, offers accurate\nperformance for all studied metrics. On the other hand, linear models or\nnonlinear-unlimited sensitivity harvesting models deviate from reality,\nespecially in the low input power regime. The proposed methodology can be\nutilized in current and future SWIPT research. \n\n"}
{"id": "1707.07349", "contents": "Title: Stability and instability in saddle point dynamics -- Part I Abstract: We consider the problem of convergence to a saddle point of a concave-convex\nfunction via gradient dynamics. Since first introduced by Arrow, Hurwicz and\nUzawa in [1] such dynamics have been extensively used in diverse areas, there\nare, however, features that render their analysis non trivial. These include\nthe lack of convergence guarantees when the function considered is not strictly\nconcave-convex and also the non-smoothness of subgradient dynamics. Our aim in\nthis two part paper is to provide an explicit characterization to the\nasymptotic behaviour of general gradient and subgradient dynamics applied to a\ngeneral concave-convex function. We show that despite the nonlinearity and\nnon-smoothness of these dynamics their $\\omega$-limit set is comprised of\ntrajectories that solve only explicit linear ODEs that are characterized within\nthe paper.\n  More precisely, in Part I an exact characterization is provided to the\nasymptotic behaviour of unconstrained gradient dynamics. We also show that when\nconvergence to a saddle point is not guaranteed then the system behaviour can\nbe problematic, with arbitrarily small noise leading to an unbounded variance.\nIn Part II we consider a general class of subgradient dynamics that restrict\ntrajectories in an arbitrary convex domain, and show that when an equilibrium\npoint exists their limiting trajectories are solutions of subgradient dynamics\non only affine subspaces. The latter is a smooth class of dynamics with an\nasymptotic behaviour exactly characterized in Part I, as solutions to explicit\nlinear ODEs. These results are used to formulate corresponding convergence\ncriteria and are demonstrated with several examples and applications presented\nin Part II. \n\n"}
{"id": "1707.08204", "contents": "Title: Power Control for Multi-Cell Networks with Non-Orthogonal Multiple\n  Access Abstract: In this paper, we investigate the problems of sum power minimization and sum\nrate maximization for multi-cell networks with non-orthogonal multiple access.\nConsidering the sum power minimization, we obtain closed-form solutions to the\noptimal power allocation strategy and then successfully transform the original\nproblem to a linear one with a much smaller size, which can be optimally solved\nby using the standard interference function. To solve the nonconvex sum rate\nmaximization problem, we first prove that the power allocation problem for a\nsingle cell is a convex problem. By analyzing the Karush-Kuhn-Tucker\nconditions, the optimal power allocation for users in a single cell is derived\nin closed form. Based on the optimal solution in each cell, a distributed\nalgorithm is accordingly proposed to acquire efficient solutions. Numerical\nresults verify our theoretical findings showing the superiority of our\nsolutions compared to the orthogonal frequency division multiple access and\nbroadcast channel. \n\n"}
{"id": "1707.08462", "contents": "Title: An Optimal Control Formulation of Pulse-Based Control Using Koopman\n  Operator Abstract: In many applications, and in systems/synthetic biology, in particular, it is\ndesirable to compute control policies that force the trajectory of a bistable\nsystem from one equilibrium (the initial point) to another equilibrium (the\ntarget point), or in other words to solve the switching problem. It was\nrecently shown that, for monotone bistable systems, this problem admits\neasy-to-implement open-loop solutions in terms of temporal pulses (i.e., step\nfunctions of fixed length and fixed magnitude). In this paper, we develop this\nidea further and formulate a problem of convergence to an equilibrium from an\narbitrary initial point. We show that this problem can be solved using a static\noptimization problem in the case of monotone systems. Changing the initial\npoint to an arbitrary state allows to build closed-loop, event-based or\nopen-loop policies for the switching/convergence problems. In our derivations\nwe exploit the Koopman operator, which offers a linear infinite-dimensional\nrepresentation of an autonomous nonlinear system. One of the main advantages of\nusing the Koopman operator is the powerful computational tools developed for\nthis framework. Besides the presence of numerical solutions, the\nswitching/convergence problem can also serve as a building block for solving\nmore complicated control problems and can potentially be applied to\nnon-monotone systems. We illustrate this argument on the problem of\nsynchronizing cardiac cells by defibrillation. Potentially, our approach can be\nextended to problems with different parametrizations of control signals since\nthe only fundamental limitation is the finite time application of the control\nsignal. \n\n"}
{"id": "1707.09302", "contents": "Title: Multi-point Gaussian states, quadratic-exponential cost functionals, and\n  large deviations estimates for linear quantum stochastic systems Abstract: This paper is concerned with risk-sensitive performance analysis for linear\nquantum stochastic systems interacting with external bosonic fields. We\nconsider a cost functional in the form of the exponential moment of the\nintegral of a quadratic polynomial of the system variables over a bounded time\ninterval. An integro-differential equation is obtained for the time evolution\nof this quadratic-exponential functional, which is compared with the original\nquantum risk-sensitive performance criterion employed previously for\nmeasurement-based quantum control and filtering problems. Using multi-point\nGaussian quantum states for the past history of the system variables and their\nfirst four moments, we discuss a quartic approximation of the cost functional\nand its infinite-horizon asymptotic behaviour. The computation of the\nasymptotic growth rate of this approximation is reduced to solving two\nalgebraic Lyapunov equations. We also outline further approximations of the\ncost functional, based on higher-order cumulants and their growth rates,\ntogether with large deviations estimates. For comparison, an auxiliary\nclassical Gaussian Markov diffusion process is considered in a complex\nEuclidean space which reproduces the quantum system variables at the level of\ncovariances but has different higher-order moments relevant to the\nrisk-sensitive criteria. The results of the paper are also demonstrated by a\nnumerical example and may find applications to coherent quantum risk-sensitive\ncontrol problems, where the plant and controller form a fully quantum\nclosed-loop system, and other settings with nonquadratic cost functionals. \n\n"}
{"id": "1707.09916", "contents": "Title: Robust Private Information Retrieval on Coded Data Abstract: We consider the problem of designing PIR scheme on coded data when certain\nnodes are unresponsive. We provide the construction of $\\nu$-robust PIR schemes\nthat can tolerate up to $\\nu$ unresponsive nodes. These schemes are adaptive\nand universally optimal in the sense of achieving (asymptotically) optimal\ndownload cost for any number of unresponsive nodes up to $\\nu$. \n\n"}
{"id": "1708.00316", "contents": "Title: A Unified Framework for Sampling, Clustering and Embedding Data Points\n  in Semi-Metric Spaces Abstract: In this paper, we propose a unified framework for sampling, clustering and\nembedding data points in semi-metric spaces. For a set of data points\n$\\Omega=\\{x_1, x_2, \\ldots, x_n\\}$ in a semi-metric space, we consider a\ncomplete graph with $n$ nodes and $n$ self edges and then map each data point\nin $\\Omega$ to a node in the graph with the edge weight between two nodes being\nthe distance between the corresponding two points in $\\Omega$. By doing so,\nseveral well-known sampling techniques can be applied for clustering data\npoints in a semi-metric space. One particularly interesting sampling technique\nis the exponentially twisted sampling in which one can specify the desired\naverage distance from the sampling distribution to detect clusters with various\nresolutions.\n  We also propose a softmax clustering algorithm that can perform a clustering\nand embed data points in a semi-metric space to a low dimensional Euclidean\nspace. Our experimental results show that after a certain number of iterations\nof \"training\", our softmax algorithm can reveal the \"topology\" of the data from\na high dimensional Euclidean. We also show that the eigendecomposition of a\ncovariance matrix is equivalent to the principal component analysis (PCA).\n  To deal with the hierarchical structure of clusters, our softmax clustering\nalgorithm can also be used with a hierarchical clustering algorithm. For this,\nwe propose a partitional-hierarchical algorithm, called $i$PHD, in this paper.\nOur experimental results show that those algorithms based on the maximization\nof normalized modularity tend to balance the sizes of detected clusters and\nthus do not perform well when the ground-truth clusters are different in sizes.\nAlso, using a metric is better than using a semi-metric as the triangular\ninequality is not satisfied for a semi-metric and that is more prone to\nclustering errors. \n\n"}
{"id": "1708.04813", "contents": "Title: Energy-Efficient Resource Allocation for Cache-Assisted Mobile Edge\n  Computing Abstract: In this paper, we jointly consider communication, caching and computation in\na multi-user cache-assisted mobile edge computing (MEC) system, consisting of\none base station (BS) of caching and computing capabilities and multiple users\nwith computation-intensive and latency-sensitive applications. We propose a\njoint caching and offloading mechanism which involves task uploading and\nexecuting for tasks with uncached computation results as well as computation\nresult downloading for all tasks at the BS, and efficiently utilizes multi-user\ndiversity and multicasting opportunities. Then, we formulate the average total\nenergy minimization problem subject to the caching and deadline constraints to\noptimally allocate the storage resource at the BS for caching computation\nresults as well as the uploading and downloading time durations. The problem is\na challenging mixed discrete-continuous optimization problem. We show that\nstrong duality holds, and obtain an optimal solution using a dual method. To\nreduce the computational complexity, we further propose a low-complexity\nsuboptimal solution. Finally, numerical results show that the proposed\nsuboptimal solution outperforms existing comparison schemes. \n\n"}
{"id": "1708.05690", "contents": "Title: Modeling Spread of Preferences in Social Networks for Sampling-based\n  Preference Aggregation Abstract: Given a large population, it is an intensive task to gather individual\npreferences over a set of alternatives and arrive at an aggregate or collective\npreference of the population. We show that social network underlying the\npopulation can be harnessed to accomplish this task effectively, by sampling\npreferences of a small subset of representative nodes. We first develop a\nFacebook app to create a dataset consisting of preferences of nodes and the\nunderlying social network, using which, we develop models that capture how\npreferences are distributed among nodes in a typical social network. We hence\npropose an appropriate objective function for the problem of selecting best\nrepresentative nodes. We devise two algorithms, namely, Greedy-min which\nprovides a performance guarantee for a wide class of popular voting rules, and\nGreedy-sum which exhibits excellent performance in practice. We compare the\nperformance of these proposed algorithms against random-polling and popular\ncentrality measures, and provide a detailed analysis of the obtained results.\nOur analysis suggests that selecting representatives using social network\ninformation is advantageous for aggregating preferences related to personal\ntopics (e.g., lifestyle), while random polling with a reasonable sample size is\ngood enough for aggregating preferences related to social topics (e.g.,\ngovernment policies). \n\n"}
{"id": "1708.06873", "contents": "Title: A Resistance Distance-Based Approach for Optimal Leader Selection in\n  Noisy Consensus Networks Abstract: We study the performance of leader-follower noisy consensus networks, and in\nparticular, the relationship between this performance and the locations of the\nleader nodes. Two types of dynamics are considered (1) noise-free leaders, in\nwhich leaders dictate the trajectory exactly and followers are subject to\nexternal disturbances, and (2) noise-corrupted leaders, in which both leaders\nand followers are subject to external perturbations. We measure the performance\nof a network by its coherence, an $H_2$ norm that quantifies how closely the\nfollowers track the leaders' trajectory. For both dynamics, we show a\nrelationship between the coherence and resistance distances in an a electrical\nnetwork. Using this relationship, we derive closed-form expressions for\ncoherence as a function of the locations of the leaders. Further, we give\nanalytical solutions to the optimal leader selection problem for several\nspecial classes of graphs. \n\n"}
{"id": "1708.07451", "contents": "Title: Recovering Structured Data From Superimposed Non-Linear Measurements Abstract: This work deals with the problem of distributed data acquisition under\nnon-linear communication constraints. More specifically, we consider a model\nsetup where $M$ distributed nodes take individual measurements of an unknown\nstructured source vector $x_0 \\in \\mathbb{R}^n$, communicating their readings\nsimultaneously to a central receiver. Since this procedure involves collisions\nand is usually imperfect, the receiver measures a superposition of non-linearly\ndistorted signals. In a first step, we will show that an $s$-sparse vector\n$x_0$ can be successfully recovered from $O(s \\cdot\\log(2n/s))$ of such\nsuperimposed measurements, using a traditional Lasso estimator that does not\nrely on any knowledge about the non-linear corruptions. This direct method\nhowever fails to work for several \"uncalibrated\" system configurations. These\nblind reconstruction tasks can be easily handled with the\n$\\ell^{1,2}$-Group-Lasso, but coming along with an increased sampling rate of\n$O(s\\cdot \\max\\{M, \\log(2n/s) \\})$ observations - in fact, the purpose of this\nlifting strategy is to extend a certain class of bilinear inverse problems to\nnon-linear acquisition. Our two algorithmic approaches are a special instance\nof a more abstract framework which includes sub-Gaussian measurement designs as\nwell as general (convex) structural constraints. These results are of\nindependent interest for various recovery and learning tasks, as they apply to\narbitrary non-linear observation models. Finally, to illustrate the practical\nscope of our theoretical findings, an application to wireless sensor networks\nis discussed, which actually serves as the prototypical example of our\nmethodology. \n\n"}
{"id": "1708.08221", "contents": "Title: walk2friends: Inferring Social Links from Mobility Profiles Abstract: The development of positioning technologies has resulted in an increasing\namount of mobility data being available. While bringing a lot of convenience to\npeople's life, such availability also raises serious concerns about privacy. In\nthis paper, we concentrate on one of the most sensitive information that can be\ninferred from mobility data, namely social relationships. We propose a novel\nsocial relation inference attack that relies on an advanced feature learning\ntechnique to automatically summarize users' mobility features. Compared to\nexisting approaches, our attack is able to predict any two individuals' social\nrelation, and it does not require the adversary to have any prior knowledge on\nexisting social relations. These advantages significantly increase the\napplicability of our attack and the scope of the privacy assessment. Extensive\nexperiments conducted on a large dataset demonstrate that our inference attack\nis effective, and achieves between 13% to 20% improvement over the best\nstate-of-the-art scheme. We propose three defense mechanisms -- hiding,\nreplacement and generalization -- and evaluate their effectiveness for\nmitigating the social link privacy risks stemming from mobility data sharing.\nOur experimental results show that both hiding and replacement mechanisms\noutperform generalization. Moreover, hiding and replacement achieve a\ncomparable trade-off between utility and privacy, the former preserving better\nutility and the latter providing better privacy. \n\n"}
{"id": "1709.01317", "contents": "Title: A Unification and Generalization of Exact Distributed First Order\n  Methods Abstract: Recently, there has been significant progress in the development of\ndistributed first order methods. (At least) two different types of methods,\ndesigned from very different perspectives, have been proposed that achieve both\nexact and linear convergence when a constant step size is used -- a favorable\nfeature that was not achievable by most prior methods. In this paper, we unify,\ngeneralize, and improve convergence speed of these exact distributed first\norder methods. We first carry out a novel unifying analysis that sheds light on\nhow the different existing methods compare. The analysis reveals that a major\ndifference between the methods is on how a past dual gradient of an associated\naugmented Lagrangian dual function is weighted. We then capitalize on the\ninsights from the analysis to derive a novel method -- with a tuned past\ngradient weighting -- that improves upon the existing methods. We establish for\nthe proposed generalized method global R-linear convergence rate under strongly\nconvex costs with Lipschitz continuous gradients. \n\n"}
{"id": "1709.01447", "contents": "Title: Conditional independence testing based on a nearest-neighbor estimator\n  of conditional mutual information Abstract: Conditional independence testing is a fundamental problem underlying causal\ndiscovery and a particularly challenging task in the presence of nonlinear and\nhigh-dimensional dependencies. Here a fully non-parametric test for continuous\ndata based on conditional mutual information combined with a local permutation\nscheme is presented. Through a nearest neighbor approach, the test efficiently\nadapts also to non-smooth distributions due to strongly nonlinear dependencies.\nNumerical experiments demonstrate that the test reliably simulates the null\ndistribution even for small sample sizes and with high-dimensional conditioning\nsets. The test is better calibrated than kernel-based tests utilizing an\nanalytical approximation of the null distribution, especially for non-smooth\ndensities, and reaches the same or higher power levels. Combining the local\npermutation scheme with the kernel tests leads to better calibration, but\nsuffers in power. For smaller sample sizes and lower dimensions, the test is\nfaster than random fourier feature-based kernel tests if the permutation scheme\nis (embarrassingly) parallelized, but the runtime increases more sharply with\nsample size and dimensionality. Thus, more theoretical research to analytically\napproximate the null distribution and speed up the estimation for larger sample\nsizes is desirable. \n\n"}
{"id": "1709.01746", "contents": "Title: Information-theoretic analysis of the directional influence between\n  cellular processes Abstract: Inferring the directionality of interactions between cellular processes is a\nmajor challenge in systems biology. Time-lagged correlations allow to\ndiscriminate between alternative models, but they still rely on assumed\nunderlying interactions. Here, we use the transfer entropy (TE), an\ninformation-theoretic quantity that quantifies the directional influence\nbetween fluctuating variables in a model-free way. We present a theoretical\napproach to compute the transfer entropy, even when the noise has an extrinsic\ncomponent or in the presence of feedback. We re-analyze the experimental data\nfrom Kiviet et al. (2014) where fluctuations in gene expression of metabolic\nenzymes and growth rate have been measured in single cells of E. coli. We\nconfirm the formerly detected modes between growth and gene expression, while\nprescribing more stringent conditions on the structure of noise sources. We\nfurthermore point out practical requirements in terms of length of time series\nand sampling time which must be satisfied in order to infer optimally transfer\nentropy from times series of fluctuations. \n\n"}
{"id": "1709.02003", "contents": "Title: Koopman-based lifting techniques for nonlinear systems identification Abstract: We develop a novel lifting technique for nonlinear system identification\nbased on the framework of the Koopman operator. The key idea is to identify the\nlinear (infinitedimensional) Koopman operator in the lifted space of\nobservables, instead of identifying the nonlinear system in the state space, a\nprocess which results in a linear method for nonlinear systems identification.\nThe proposed lifting technique is an indirect method that does not require to\ncompute time derivatives and is therefore well-suited to low-sampling rate\ndatasets.\n  Considering different finite-dimensional subspaces to approximate and\nidentify the Koopman operator, we propose two numerical schemes: the main\nmethod and the dual method. The main method is a parametric identification\ntechnique that can accurately reconstruct the vector field of a broad class of\nsystems (including unstable, chaotic, and system with inputs). The dual method\nprovides estimates of the vector field at the data points and is well-suited to\nidentify high-dimensional systems with small datasets. The present paper\ndescribes the two methods, provide theoretical convergence results, and\nillustrate the lifting techniques with several examples. \n\n"}
{"id": "1709.02510", "contents": "Title: \"Breaking\" Disasters: Predicting and Characterizing the Global News\n  Value of Natural and Man-made Disasters Abstract: Due to their often unexpected nature, natural and man-made disasters are\ndifficult to monitor and detect for journalists and disaster management\nresponse teams. Journalists are increasingly relying on signals from social\nmedia to detect such stories in their early stage of development. Twitter,\nwhich features a vast network of local news outlets, is a major source of early\nsignal for disaster detection. Journalists who work for global desks often\nfollow these sources via Twitter's lists, but have to comb through thousands of\nsmall-scale or low-impact stories to find events that may be globally relevant.\nThese are events that have a large scope, high impact, or potential\ngeo-political relevance. We propose a model for automatically identifying\nevents from local news sources that may break on a global scale within the next\n24 hours. The results are promising and can be used in a predictive setting to\nhelp journalists manage their sources more effectively, or in a descriptive\nmanner to analyze media coverage of disasters. Through the feature evaluation\nprocess, we also address the question: \"what makes a disaster event newsworthy\non a global scale?\" As part of our data collection process, we have created a\nlist of local sources of disaster/accident news on Twitter, which we have made\npublicly available. \n\n"}
{"id": "1709.02969", "contents": "Title: Optimization of Massive Full-Dimensional MIMO for Positioning and\n  Communication Abstract: Massive Full-Dimensional multiple-input multiple-output (FD-MIMO) base\nstations (BSs) have the potential to bring multiplexing and coverage gains by\nmeans of three-dimensional (3D) beamforming. Key technical challenges for their\ndeployment include the presence of limited-resolution front ends and the\nacquisition of channel state information (CSI) at the BSs. This paper\ninvestigates the use of FD-MIMO BSs to provide simultaneously high-rate data\ncommunication and mobile 3D positioning in the downlink. The analysis\nconcentrates on the problem of beamforming design by accounting for imperfect\nCSI acquisition via Time Division Duplex (TDD)-based training and for the\nfinite resolution of analog-to-digital converter (ADC) and digital-to-analog\nconverter (DAC) at the BSs. Both \\textit{unstructured beamforming} and a\nlow-complexity \\textit{Kronecker beamforming} solution are considered, where\nfor the latter the beamforming vectors are decomposed into separate azimuth and\nelevation components. The proposed algorithmic solutions are based on Bussgang\ntheorem, rank-relaxation and successive convex approximation (SCA) methods.\nComprehensive numerical results demonstrate that the proposed schemes can\neffectively cater to both data communication and positioning services,\nproviding only minor performance degradations as compared to the more\nconventional cases in which either function is implemented. Moreover, the\nproposed low-complexity Kronecker beamforming solutions are seen to guarantee a\nlimited performance loss in the presence of a large number of BS antennas. \n\n"}
{"id": "1709.03551", "contents": "Title: Principled Multilayer Network Embedding Abstract: Multilayer network analysis has become a vital tool for understanding\ndifferent relationships and their interactions in a complex system, where each\nlayer in a multilayer network depicts the topological structure of a group of\nnodes corresponding to a particular relationship. The interactions among\ndifferent layers imply how the interplay of different relations on the topology\nof each layer. For a single-layer network, network embedding methods have been\nproposed to project the nodes in a network into a continuous vector space with\na relatively small number of dimensions, where the space embeds the social\nrepresentations among nodes. These algorithms have been proved to have a better\nperformance on a variety of regular graph analysis tasks, such as link\nprediction, or multi-label classification. In this paper, by extending a\nstandard graph mining into multilayer network, we have proposed three methods\n(\"network aggregation,\" \"results aggregation\" and \"layer co-analysis\") to\nproject a multilayer network into a continuous vector space. From the\nevaluation, we have proved that comparing with regular link prediction methods,\n\"layer co-analysis\" achieved the best performance on most of the datasets,\nwhile \"network aggregation\" and \"results aggregation\" also have better\nperformance than regular link prediction methods. \n\n"}
{"id": "1709.03965", "contents": "Title: An Online Optimization Algorithm for Alleviating Contingencies in\n  Transmission Networks Abstract: Power systems are increasingly operated in corrective rather than preventive\nsecurity mode, which means that appropriate control actions must be taken\nimmediately after a contingency has occurred. This paper proposes an online\nalgorithm for automatically alleviating contingencies such as voltage limit\nviolations and line overloads. Unlike previously proposed approaches, the\nnetwork itself serves as a natural solver of the power flow equations. This\nmakes it possible to start the implementation immediately and avoids problems\ncaused by modeling errors. Every time the controller receives measurements from\nthe grid, it evaluates the presence of contingencies and computes the optimal\ncorrective actions that can be implemented before the next sampling period,\nsubject to ramping constraints of the generators. These corrective actions are\nimplemented through the standard Automatic Generation Control. Finding the\noptimal incremental corrective actions is fast because this problem is\nlinearized. The effectiveness of this algorithm at correcting both line\noverloads and voltage violations is demonstrated using the IEEE-118 Bus test\nsystem. \n\n"}
{"id": "1709.04530", "contents": "Title: State-Secrecy Codes for Networked Linear Systems Abstract: In this paper, we study the problem of remote state estimation, in the\npresence of a passive eavesdropper. An authorized user estimates the state of\nan unstable linear plant, based on the packets received from a sensor, while\nthe packets may also be intercepted by the eavesdropper. Our goal is to design\na coding scheme at the sensor, which encodes the state information, in order to\nimpair the eavesdropper's estimation performance, while enabling the user to\nsuccessfully decode the sent messages. We introduce a novel class of codes,\ntermed State-Secrecy Codes, which use acknowledgment signals from the user and\napply linear time-varying transformations to the current and previously\nreceived states. By exploiting the properties of the system's process noise,\nthe channel physical model and the dynamics, these codes manage to be fast,\nefficient and, thus, suitable for real-time dynamical systems. We prove that\nunder minimal conditions, State-Secrecy Codes achieve perfect secrecy, namely\nthe eavesdropper's estimation error grows unbounded almost surely, while the\nuser's estimation performance is optimal. These conditions only require that at\nleast once, the user receives the corresponding packet while the eavesdropper\nfails to intercept it. Even one occurrence of this event renders the\neavesdropper's error unbounded with asymptotically optimal rate of increase.\nState-Secrecy Codes are provided and studied for two cases, i) when direct\nstate measurements are available, and ii) when we only have output\nmeasurements. The theoretical results are illustrated in simulations. \n\n"}
{"id": "1709.04846", "contents": "Title: Linear Precoding with Low-Resolution DACs for Massive MU-MIMO-OFDM\n  Downlink Abstract: We consider the downlink of a massive multiuser (MU) multiple-input\nmultiple-output (MIMO) system in which the base station (BS) is equipped with\nlow-resolution digital-to-analog converters (DACs). In contrast to most\nexisting results, we assume that the system operates over a frequency-selective\nwideband channel and uses orthogonal frequency division multiplexing (OFDM) to\nsimplify equalization at the user equipments (UEs). Furthermore, we consider\nthe practically relevant case of oversampling DACs. We theoretically analyze\nthe uncoded bit error rate (BER) performance with linear precoders (e.g., zero\nforcing) and quadrature phase-shift keying using Bussgang's theorem. We also\ndevelop a lower bound on the information-theoretic sum-rate throughput\nachievable with Gaussian inputs, which can be evaluated in closed form for the\ncase of 1-bit DACs. For the case of multi-bit DACs, we derive approximate, yet\naccurate, expressions for the distortion caused by low-precision DACs, which\ncan be used to establish lower bounds on the corresponding sum-rate throughput.\nOur results demonstrate that, for a massive MU-MIMO-OFDM system with a\n128-antenna BS serving 16 UEs, only 3--4 DAC bits are required to achieve an\nuncoded BER of 10^-4 with a negligible performance loss compared to the\ninfinite-resolution case at the cost of additional out-of-band emissions.\nFurthermore, our results highlight the importance of taking into account the\ninherent spatial and temporal correlations caused by low-precision DACs. \n\n"}
{"id": "1709.05907", "contents": "Title: A Generalized Framework for Kullback-Leibler Markov Aggregation Abstract: This paper proposes an information-theoretic cost function for aggregating a\nMarkov chain via a (possibly stochastic) mapping. The cost function is\nmotivated by two objectives: 1) The process obtained by observing the Markov\nchain through the mapping should be close to a Markov chain, and 2) the\naggregated Markov chain should retain as much of the temporal dependence\nstructure of the original Markov chain as possible. We discuss properties of\nthis parameterized cost function and show that it contains the cost functions\npreviously proposed by Deng et al., Xu et al., and Geiger et al. as special\ncases. We moreover discuss these special cases providing a better understanding\nand highlighting potential shortcomings: For example, the cost function\nproposed by Geiger et al. is tightly connected to approximate probabilistic\nbisimulation, but leads to trivial solutions if optimized without\nregularization. We furthermore propose a simple heuristic to optimize our cost\nfunction for deterministic aggregations and illustrate its performance on a set\nof synthetic examples. \n\n"}
{"id": "1709.07253", "contents": "Title: Revisiting Resolution and Inter-Layer Coupling Factors in Modularity for\n  Multilayer Networks Abstract: Modularity for multilayer networks, also called multislice modularity, is\nparametric to a resolution factor and an inter-layer coupling factor. The\nformer is useful to express layer-specific relevance and the latter quantifies\nthe strength of node linkage across the layers of a network. However, such\nparameters can be set arbitrarily, thus discarding any structure information at\ngraph or community level. Other issues are related to the inability of properly\nmodeling order relations over the layers, which is required for dynamic\nnetworks.\n  In this paper we propose a new definition of modularity for multilayer\nnetworks that aims to overcome major issues of existing multislice modularity.\nWe revise the role and semantics of the layer-specific resolution and\ninter-layer coupling terms, and define parameter-free unsupervised approaches\nfor their computation, by using information from the within-layer and\ninter-layer structures of the communities. Moreover, our formulation of\nmultilayer modularity is general enough to account for an available ordering of\nthe layers and relating constraints on layer coupling. Experimental evaluation\nwas conducted using three state-of-the-art methods for multilayer community\ndetection and nine real-world multilayer networks. Results have shown the\nsignificance of our modularity, disclosing the effects of different\ncombinations of the resolution and inter-layer coupling functions. This work\ncan pave the way for the development of new optimization methods for\ndiscovering community structures in multilayer networks. \n\n"}
{"id": "1709.07308", "contents": "Title: Predicting Positive and Negative Links with Noisy Queries: Theory &\n  Practice Abstract: Social networks involve both positive and negative relationships, which can\nbe captured in signed graphs. The {\\em edge sign prediction problem} aims to\npredict whether an interaction between a pair of nodes will be positive or\nnegative. We provide theoretical results for this problem that motivate natural\nimprovements to recent heuristics.\n  The edge sign prediction problem is related to correlation clustering; a\npositive relationship means being in the same cluster. We consider the\nfollowing model for two clusters: we are allowed to query any pair of nodes\nwhether they belong to the same cluster or not, but the answer to the query is\ncorrupted with some probability $0<q<\\frac{1}{2}$. Let $\\delta=1-2q$ be the\nbias. We provide an algorithm that recovers all signs correctly with high\nprobability in the presence of noise with $O(\\frac{n\\log\nn}{\\delta^2}+\\frac{\\log^2 n}{\\delta^6})$ queries. This is the best known result\nfor this problem for all but tiny $\\delta$, improving on the recent work of\nMazumdar and Saha \\cite{mazumdar2017clustering}. We also provide an algorithm\nthat performs $O(\\frac{n\\log n}{\\delta^4})$ queries, and uses breadth first\nsearch as its main algorithmic primitive. While both the running time and the\nnumber of queries for this algorithm are sub-optimal, our result relies on\nnovel theoretical techniques, and naturally suggests the use of edge-disjoint\npaths as a feature for predicting signs in online social networks.\nCorrespondingly, we experiment with using edge disjoint $s-t$ paths of short\nlength as a feature for predicting the sign of edge $(s,t)$ in real-world\nsigned networks. Empirical findings suggest that the use of such paths improves\nthe classification accuracy, especially for pairs of nodes with no common\nneighbors. \n\n"}
{"id": "1709.08350", "contents": "Title: DynaMo: Dynamic Community Detection by Incrementally Maximizing\n  Modularity Abstract: Community detection is of great importance for online social network\nanalysis. The volume, variety and velocity of data generated by today's online\nsocial networks are advancing the way researchers analyze those networks. For\ninstance, real-world networks, such as Facebook, LinkedIn and Twitter, are\ninherently growing rapidly and expanding aggressively over time. However, most\nof the studies so far have been focusing on detecting communities on the static\nnetworks. It is computationally expensive to directly employ a well-studied\nstatic algorithm repeatedly on the network snapshots of the dynamic networks.\nWe propose DynaMo, a novel modularity-based dynamic community detection\nalgorithm, aiming to detect communities of dynamic networks as effective as\nrepeatedly applying static algorithms but in a more efficient way. DynaMo is an\nadaptive and incremental algorithm, which is designed for incrementally\nmaximizing the modularity gain while updating the community structure of\ndynamic networks. In the experimental evaluation, a comprehensive comparison\nhas been made among DynaMo, Louvain (static) and 5 other dynamic algorithms.\nExtensive experiments have been conducted on 6 real-world networks and 10,000\nsynthetic networks. Our results show that DynaMo outperforms all the other 5\ndynamic algorithms in terms of the effectiveness, and is 2 to 5 times (by\naverage) faster than Louvain algorithm. \n\n"}
{"id": "1709.10203", "contents": "Title: On the Approximation of Toeplitz Operators for Nonparametric\n  $\\mathcal{H}_\\infty$-norm Estimation Abstract: Given a stable SISO LTI system $G$, we investigate the problem of estimating\nthe $\\mathcal{H}_\\infty$-norm of $G$, denoted $||G||_\\infty$, when $G$ is only\naccessible via noisy observations. Wahlberg et al. recently proposed a\nnonparametric algorithm based on the power method for estimating the top\neigenvalue of a matrix. In particular, by applying a clever time-reversal\ntrick, Wahlberg et al. implement the power method on the top left $n \\times n$\ncorner $T_n$ of the Toeplitz (convolution) operator associated with $G$. In\nthis paper, we prove sharp non-asymptotic bounds on the necessary length $n$\nneeded so that $||T_n||$ is an $\\varepsilon$-additive approximation of\n$||G||_\\infty$. Furthermore, in the process of demonstrating the sharpness of\nour bounds, we construct a simple family of finite impulse response (FIR)\nfilters where the number of timesteps needed for the power method is\narbitrarily worse than the number of timesteps needed for parametric FIR\nidentification via least-squares to achieve the same $\\varepsilon$-additive\napproximation. \n\n"}
{"id": "1710.00800", "contents": "Title: On the entropy power inequality for the R\\'enyi entropy of order [0,1] Abstract: Using a sharp version of the reverse Young inequality, and a R\\'enyi entropy\ncomparison result due to Fradelizi, Madiman, and Wang, the authors are able to\nderive R\\'enyi entropy power inequalities for log-concave random vectors when\nR\\'enyi parameters belong to $(0,1)$. Furthermore, the estimates are shown to\nbe sharp up to absolute constants. \n\n"}
{"id": "1710.00980", "contents": "Title: Energy-Efficient Power and Bandwidth Allocation in an Integrated Sub-6\n  GHz -- Millimeter Wave System Abstract: In mobile millimeter wave (mmWave) systems, energy is a scarce resource due\nto the large losses in the channel and high energy usage by analog-to-digital\nconverters (ADC), which scales with bandwidth. In this paper, we consider a\ncommunication architecture that integrates the sub-6 GHz and mmWave\ntechnologies in 5G cellular systems. In order to mitigate the energy scarcity\nin mmWave systems, we investigate the rate-optimal and energy-efficient\nphysical layer resource allocation jointly across the sub-6 GHz and mmWave\ninterfaces. First, we formulate an optimization problem in which the objective\nis to maximize the achievable sum rate under power constraints at the\ntransmitter and receiver. Our formulation explicitly takes into account the\nenergy consumption in integrated-circuit components, and assigns the optimal\npower and bandwidth across the interfaces. We consider the settings with no\nchannel state information and partial channel state information at the\ntransmitter and under high and low SNR scenarios. Second, we investigate the\nenergy efficiency (EE) defined as the ratio between the amount of data\ntransmitted and the corresponding incurred cost in terms of power. We use\nfractional programming and Dinkelbach's algorithm to solve the EE optimization\nproblem. Our results prove that despite the availability of huge bandwidths at\nthe mmWave interface, it may be optimal (in terms of achievable sum rate and\nenergy efficiency) to utilize it partially. Moreover, depending on the sub-6\nGHz and mmWave channel conditions and total power budget, it may be optimal to\nactivate only one of the interfaces. \n\n"}
{"id": "1710.01529", "contents": "Title: Joint optimization of transmission and propulsion in aerial\n  communication networks Abstract: Communication energy in a wireless network of mobile autonomous agents should\nbe considered as the sum of transmission energy and propulsion energy used to\nfacilitate the transfer of information. Accordingly, communication-theoretic\nand Newtonian dynamic models are developed to model the communication and\nlocomotion expenditures of each node. These are subsequently used to formulate\na novel nonlinear optimal control problem (OCP) over a network of autonomous\nnodes. It is then shown that, under certain conditions, the OCP can be\ntransformed into an equivalent convex form. Numerical results for a single link\nbetween a node and access point allow for comparison with known solutions\nbefore the framework is applied to a multiple-node UAV network, for which\nprevious results are not readily extended. Simulations show that transmission\nenergy can be of the same order of magnitude as propulsion energy allowing for\npossible savings, whilst also exemplifying how speed adaptations together with\npower control may increase the network throughput. \n\n"}
{"id": "1710.01816", "contents": "Title: Source Coding Optimization for Distributed Average Consensus Abstract: Consensus is a common method for computing a function of the data distributed\namong the nodes of a network. Of particular interest is distributed average\nconsensus, whereby the nodes iteratively compute the sample average of the data\nstored at all the nodes of the network using only near-neighbor communications.\nIn real-world scenarios, these communications must undergo quantization, which\nintroduces distortion to the internode messages. In this thesis, a model for\nthe evolution of the network state statistics at each iteration is developed\nunder the assumptions of Gaussian data and additive quantization error. It is\nshown that minimization of the communication load in terms of aggregate source\ncoding rate can be posed as a generalized geometric program, for which an\nequivalent convex optimization can efficiently solve for the global minimum.\nOptimization procedures are developed for rate-distortion-optimal vector\nquantization, uniform entropy-coded scalar quantization, and fixed-rate uniform\nquantization. Numerical results demonstrate the performance of these\napproaches. For small numbers of iterations, the fixed-rate optimizations are\nverified using exhaustive search. Comparison to the prior art suggests\ncompetitive performance under certain circumstances but strongly motivates the\nincorporation of more sophisticated coding strategies, such as differential,\npredictive, or Wyner-Ziv coding. \n\n"}
{"id": "1710.02651", "contents": "Title: Modeling Collective Behavior of Posting Microblog by Stochastic\n  Differential Equation with Jump Abstract: The characterization and understanding of online social network behavior is\nof importance from both the points of view of fundamental research and\nrealistic utilization. In this manuscript, we propose a stochastic differential\nequation to describe the online microblogging behavior. Our analysis is based\non the microblog data collected from Sina Weibo which is one of the most\npopular microblogging platforms in China. Especially, we focus on the\ncollective nature of the microblogging behavior reflecting itself in the\nanalyzed data as the characters of the periodic pattern, the stochastic\nfluctuation around the baseline, and the extraordinary jumps. Compared with\nexisting works, we use in our model time dependent parameters to facilitate the\nperiodic feature of the microblogging behavior and incorporate a compound\nPoisson process to describe the extraordinary spikes in the Sina Weibo volume.\nSuch distinct merits lead to significant improvement in the prediction\nperformance, thus justifying the validity of our model. This work may offer\npotential application in the future detection of the anomalous behavior in\nonline social network platforms. \n\n"}
{"id": "1710.04983", "contents": "Title: Estimating savings in parking demand using shared vehicles for home-work\n  commuting Abstract: The increasing availability and adoption of shared vehicles as an alternative\nto personally-owned cars presents ample opportunities for achieving more\nefficient transportation in cities. With private cars spending on the average\nover 95\\% of the time parked, one of the possible benefits of shared mobility\nis the reduced need for parking space. While widely discussed, a systematic\nquantification of these benefits as a function of mobility demand and sharing\nmodels is still mostly lacking in the literature. As a first step in this\ndirection, this paper focuses on a type of private mobility which, although\nspecific, is a major contributor to traffic congestion and parking needs,\nnamely, home-work commuting. We develop a data-driven methodology for\nestimating commuter parking needs in different shared mobility models,\nincluding a model where self-driving vehicles are used to partially compensate\nflow imbalance typical of commuting, and further reduce parking infrastructure\nat the expense of increased traveled kilometers. We consider the city of\nSingapore as a case study, and produce very encouraging results showing that\nthe gradual transition to shared mobility models will bring tangible reductions\nin parking infrastructure. In the future-looking, self-driving vehicle\nscenario, our analysis suggests that up to 50\\% reduction in parking needs can\nbe achieved at the expense of increasing total traveled kilometers of less than\n2\\%. \n\n"}
{"id": "1710.07716", "contents": "Title: A Statistical Characterization of Localization Performance in Wireless\n  Networks Abstract: Localization performance in wireless networks has been traditionally\nbenchmarked using the Cramer-Rao lower bound (CRLB), given a fixed geometry of\nanchor nodes and a target. However, by endowing the target and anchor locations\nwith distributions, this paper recasts this traditional, scalar benchmark as a\nrandom variable. The goal of this work is to derive an analytical expression\nfor the distribution of this now random CRLB, in the context of\nTime-of-Arrival-based positioning.\n  To derive this distribution, this work first analyzes how the CRLB is\naffected by the order statistics of the angles between consecutive\nparticipating anchors (i.e., internodal angles). This analysis reveals an\nintimate connection between the second largest internodal angle and the CRLB,\nwhich leads to an accurate approximation of the CRLB. Using this approximation,\na closed-form expression for the distribution of the CRLB, conditioned on the\nnumber of participating anchors, is obtained.\n  Next, this conditioning is eliminated to derive an analytical expression for\nthe marginal CRLB distribution. Since this marginal distribution accounts for\nall target and anchor positions, across all numbers of participating anchors,\nit therefore statistically characterizes localization error throughout an\nentire wireless network. This paper concludes with a comprehensive analysis of\nthis new network-wide-CRLB paradigm. \n\n"}
{"id": "1710.07873", "contents": "Title: Fast Analog Beam Tracking in Phased Antenna Arrays: Theory and\n  Performance Abstract: The directionality of millimeter-wave (mmWave) communications introduces a\nsignificant challenge in serving fast-rotating/moving terminals, e.g., mobile\nAR/VR, high-speed vehicles, trains, UAVs.This challenge is exacerbated in\nmmWave systems using analog beamforming, because of the inherent non-convexity\nin the analog beam tracking problem. In this paper, we obtain the Cram\\'er-Rao\nlower bound (CRLB) of beam tracking and optimize the analog beamforming vectors\nto get the minimum CRLB. Then, we develop a low complexity analog beam tracking\nalgorithm that simultaneously optimizes the analog beamforming vector and the\nestimate of beam direction. Finally, by establishing a new basic theory, we\nprovide the theoretical convergence analysis of the proposed analog beam\ntracking algorithm, which proves that the minimum CRLB of the MSE is achievable\nwith high probability. Our simulations show that this algorithm can achieve\nfaster tracking speed, higher tracking accuracy and higher data rate than\nseveral state-of-the-art algorithms. The key analytical tools used in our\nalgorithm design are stochastic approximation and recursive estimation with a\ncontrol parameter. \n\n"}
{"id": "1710.09041", "contents": "Title: Generalized Geometric Programming for Rate Allocation in Consensus Abstract: Distributed averaging, or distributed average consensus, is a common method\nfor computing the sample mean of the data dispersed among the nodes of a\nnetwork in a decentralized manner. By iteratively exchanging messages with\nneighbors, the nodes of the network can converge to an agreement on the sample\nmean of their initial states. In real-world scenarios, these messages are\nsubject to bandwidth and power constraints, which motivates the design of a\nlossy compression strategy. Few prior works consider the rate allocation\nproblem from the perspective of constrained optimization, which provides a\nprincipled method for the design of lossy compression schemes, allows for the\nrelaxation of certain assumptions, and offers performance guarantees. We show\nfor Gaussian-distributed initial states with entropy-coded scalar quantization\nand vector quantization that the coding rates for distributed averaging can be\noptimized through generalized geometric programming. In the absence of side\ninformation from past states, this approach finds a rate allocation over nodes\nand iterations that minimizes the aggregate coding rate required to achieve a\ntarget mean square error within a finite run time. Our rate allocation is\ncompared to some of the prior art through numerical simulations. The results\nmotivate the incorporation of side-information through differential or\npredictive coding to improve rate-distortion performance. \n\n"}
{"id": "1710.09076", "contents": "Title: Emergence of Leadership in Communication Abstract: We study a neuro-inspired model that mimics a discussion (or information\ndissemination) process in a network of agents. During their interaction, agents\nredistribute activity and network weights, resulting in emergence of leader(s).\nThe model is able to reproduce the basic scenarios of leadership known in\nnature and society: laissez-faire (irregular activity, weak leadership, sizable\ninter-follower interaction, autonomous sub-leaders); participative or\ndemocratic (strong leadership, but with feedback from followers); and\nautocratic (no feedback, one-way influence). Several pertinent aspects of these\nscenarios are found as well---e.g., hidden leadership (a hidden clique of\nagents driving the official autocratic leader), and successive leadership (two\nleaders influence followers by turns). We study how these scenarios emerge from\ninter-agent dynamics and how they depend on behavior rules of agents---in\nparticular, on their inertia against state changes. \n\n"}
{"id": "1710.10811", "contents": "Title: Reliable Communication under the Influence of a State-Constrained\n  Jammer: A Novel Perspective on Receive Diversity Abstract: The question of robust direct communication in vehicular networks is\ndiscussed. In most state-of-the-art approaches, there is no central entity\ncontrolling channel access, so there may be arbitrary interference from other\nparties. Thus, a suitable channel model for Vehicle-to-X (V2X) communication is\nthe Arbitrarily Varying Channel (AVC). Employing multiple antennas on a vehicle\nor sending over multiple frequencies to make use of diversity are promising\napproaches to combat interference. In this setup, an important question about\ndiversity is how many antennas or orthogonal carrier frequencies are necessary\nin order to avoid system breakdown due to unknown interference in AVCs. For\nBinary Symmetric AVCs (AVBSC) and a physically meaningful identical\nstate-constrained jammer, the deployment of a third, uncorrelated receiving\nantenna or the parallel transmission over three different orthogonal\nfrequencies avoids symmetrizability and thus ensures positivity of the capacity\nof the overall communication channel. Furthermore, the capacity of the\nidentical state-constrained composite AVBSC is continuous and shows\nsuper-activation, a phenomenon which was hitherto deemed impossible for\nclassical communication without secrecy constraints. Subsuming, spatial and\nfrequency diversity are enablers for reliable communication over communication\nchannels with arbitrarily varying interference. \n\n"}
{"id": "1710.10829", "contents": "Title: Generalized gradient optimization over lossy networks for\n  partition-based estimation Abstract: We address the problem of distributed convex unconstrained optimization over\nnetworks characterized by asynchronous and possibly lossy communications. We\nanalyze the case where the global cost function is the sum of locally coupled\nlocal strictly convex cost functions. As discussed in detail in a motivating\nexample, this class of optimization objectives is, for example, typical in\nlocalization problems and in partition-based state estimation. Inspired by a\ngeneralized gradient descent strategy, namely the block Jacobi iteration, we\npropose a novel solution which is amenable for a distributed implementation and\nwhich, under a suitable condition on the step size, is provably locally\nresilient to communication failures. The theoretical analysis relies on the\nseparation of time scales and Lyapunov theory. In addition, to show the\nflexibility of the proposed algorithm, we derive a resilient gradient descent\niteration and a resilient generalized gradient for quadratic programming as two\nnatural particularizations of our strategy. In this second case, global\nrobustness is provided. Finally, the proposed algorithm is numerically tested\non the IEEE 123 nodes distribution feeder in the context of partition-based\nsmart grid robust state estimation in the presence of measurements outliers. \n\n"}
{"id": "1711.00326", "contents": "Title: The quoter model: a paradigmatic model of the social flow of written\n  information Abstract: We propose a model for the social flow of information in the form of text\ndata, which simulates the posting and sharing of short social media posts.\nNodes in a graph representing a social network take turns generating words,\nleading to a symbolic time series associated with each node. Information\npropagates over the graph via a quoting mechanism, where nodes randomly copy\nshort segments of text from each other. We characterize information flows from\nthese text via information-theoretic estimators, and we derive analytic\nrelationships between model parameters and the values of these estimators. We\nexplore and validate the model with simulations on small network motifs and\nlarger random graphs. Tractable models such as ours that generate symbolic data\nwhile controlling the information flow allow us to test and compare measures of\ninformation flow applicable to real social media data. In particular, by\nchoosing different network structures, we can develop test scenarios to\ndetermine whether or not measures of information flow can distinguish between\ntrue and spurious interactions, and how topological network properties relate\nto information flow. \n\n"}
{"id": "1711.01082", "contents": "Title: On the Capacity of SWIPT Systems with a Nonlinear Energy Harvesting\n  Circuit Abstract: In this paper, we study information-theoretic limits for simultaneous\nwireless information and power transfer (SWIPT) systems employing a practical\nnonlinear radio frequency (RF) energy harvesting (EH) receiver. In particular,\nwe consider a three-node system with one transmitter that broadcasts a common\nsignal to separated information decoding (ID) and EH receivers. Owing to the\nnonlinearity of the EH receiver circuit, the efficiency of wireless power\ntransfer depends significantly on the waveform of the transmitted signal. In\nthis paper, we aim to answer the following fundamental question: What is the\noptimal input distribution of the transmit waveform that maximizes the rate of\nthe ID receiver for a given required harvested power at the EH receiver? In\nparticular, we study the capacity of a SWIPT system impaired by additive white\nGaussian noise (AWGN) under average-power (AP) and peak-power (PP) constraints\nat the transmitter and an EH constraint at the EH receiver. Using Hermite\npolynomial bases, we prove that the optimal capacity-achieving input\ndistribution that maximizes the rate-energy region is unique and discrete with\na finite number of mass points. Furthermore, we show that the optimal input\ndistribution for the same problem without PP constraint is discrete whenever\nthe EH constraint is active and continuous zero-mean Gaussian, otherwise. Our\nnumerical results show that the rate-energy region is enlarged for a larger PP\nconstraint and that the rate loss of the considered SWIPT system compared to\nthe AWGN channel without EH receiver is reduced by increasing the AP budget. \n\n"}
{"id": "1711.01888", "contents": "Title: Information capacity of direct detection optical transmission systems Abstract: We show that the spectral efficiency of a direct detection transmission\nsystem is at most 1 bit/s/Hz less than the spectral efficiency of a system\nemploying coherent detection with the same modulation format. Correspondingly,\nthe capacity per complex degree of freedom in systems using direct detection is\nlower by at most 1 bit. \n\n"}
{"id": "1711.02348", "contents": "Title: Multi-mode Tracking of a Group of Mobile Agents Abstract: We consider the problem of tracking a group of mobile nodes with limited\navailable computational and energy resources given noisy RSSI measurements and\nposition estimates from group members. The multilateration solutions are known\nfor energy efficiency. However, these solutions are not directly applicable to\ndynamic grouping scenarios where neighbourhoods and resource availability may\nfrequently change. Existing algorithms such as cluster-based GPS duty-cycling,\nindividual-based tracking, and multilateration-based tracking can only\npartially deal with the challenges of dynamic grouping scenarios. To cope with\nthese challenges in an effective manner, we propose a new group-based\nmulti-mode tracking algorithm. The proposed algorithm takes the topological\nstructure of the group as well as the availability of the resources into\nconsideration and decides the best solution at any particular time instance. We\nconsider a clustering approach where a cluster head coordinates the usage of\nresources among the cluster members. We evaluate the energy-accuracy trade-off\nof the proposed algorithm for various fixed sampling intervals. The evaluation\nis based on the 2D position tracks of 40 nodes generated using Reynolds'\nflocking model. For a given energy budget, the proposed algorithm reduces the\nmean tracking error by up to $20\\%$ in comparison to the existing\nenergy-efficient cooperative algorithms. Moreover, the proposed algorithm is as\naccurate as the individual-based tracking while using almost half the energy. \n\n"}
{"id": "1711.06600", "contents": "Title: On optimal coding of non-linear dynamical systems Abstract: We consider the problem of zero-delay coding of a dynamical system over a\ndiscrete noiseless channel under three estimation criteria concerned with the\nlow-distortion regime. For these three criteria, formulated stochastically in\nterms of a probability distribution for the initial state, we characterize the\nsmallest channel capacities above which the estimation objectives can be\nachieved. The results establish further connections between topological and\nmetric entropy of dynamical systems and information theory. \n\n"}
{"id": "1711.08398", "contents": "Title: Identifying user habits through data mining on call data records Abstract: In this paper we propose a framework for identifying patterns and\nregularities in the pseudo-anonymized Call Data Records (CDR) pertaining a\ngeneric subscriber of a mobile operator. We face the challenging task of\nautomatically deriving meaningful information from the available data, by using\nan unsupervised procedure of cluster analysis and without including in the\nmodel any \\textit{a-priori} knowledge on the applicative context. Clusters\nmining results are employed for understanding users' habits and to draw their\ncharacterizing profiles. We propose two implementations of the data mining\nprocedure; the first is based on a novel system for clusters and knowledge\ndiscovery called LD-ABCD, capable of retrieving clusters and, at the same time,\nto automatically discover for each returned cluster the most appropriate\ndissimilarity measure (local metric). The second approach instead is based on\nPROCLUS, the well-know subclustering algorithm. The dataset under analysis\ncontains records characterized only by few features and, consequently, we show\nhow to generate additional fields which describe implicit information hidden in\ndata. Finally, we propose an effective graphical representation of the results\nof the data-mining procedure, which can be easily understood and employed by\nanalysts for practical applications. \n\n"}
{"id": "1711.10467", "contents": "Title: Implicit Regularization in Nonconvex Statistical Estimation: Gradient\n  Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind\n  Deconvolution Abstract: Recent years have seen a flurry of activities in designing provably efficient\nnonconvex procedures for solving statistical estimation problems. Due to the\nhighly nonconvex nature of the empirical loss, state-of-the-art procedures\noften require proper regularization (e.g. trimming, regularized cost,\nprojection) in order to guarantee fast convergence. For vanilla procedures such\nas gradient descent, however, prior theory either recommends highly\nconservative learning rates to avoid overshooting, or completely lacks\nperformance guarantees.\n  This paper uncovers a striking phenomenon in nonconvex optimization: even in\nthe absence of explicit regularization, gradient descent enforces proper\nregularization implicitly under various statistical models. In fact, gradient\ndescent follows a trajectory staying within a basin that enjoys nice geometry,\nconsisting of points incoherent with the sampling mechanism. This \"implicit\nregularization\" feature allows gradient descent to proceed in a far more\naggressive fashion without overshooting, which in turn results in substantial\ncomputational savings. Focusing on three fundamental statistical estimation\nproblems, i.e. phase retrieval, low-rank matrix completion, and blind\ndeconvolution, we establish that gradient descent achieves near-optimal\nstatistical and computational guarantees without explicit regularization. In\nparticular, by marrying statistical modeling with generic optimization theory,\nwe develop a general recipe for analyzing the trajectories of iterative\nalgorithms via a leave-one-out perturbation argument. As a byproduct, for noisy\nmatrix completion, we demonstrate that gradient descent achieves near-optimal\nerror control --- measured entrywise and by the spectral norm --- which might\nbe of independent interest. \n\n"}
{"id": "1711.10694", "contents": "Title: Backscatter Multiplicative Multiple-Access Systems: Fundamental Limits\n  and Practical Design Abstract: In this paper, we consider a novel ambient backscatter multiple-access\nsystem, where a receiver (Rx) simultaneously detects the signals transmitted\nfrom an active transmitter (Tx) and a backscatter Tag. Specifically, the\ninformation-carrying signal sent by the Tx arrives at the Rx through two\nwireless channels: the direct channel from the Tx to the Rx, and the\nbackscatter channel from the Tx to the Tag and then to the Rx. The received\nsignal from the backscatter channel also carries the Tag's information because\nof the multiplicative backscatter operation at the Tag. This multiple-access\nsystem introduces a new channel model, referred to as multiplicative\nmultiple-access channel (M-MAC). We analyze the achievable rate region of the\nM-MAC, and prove that its region is strictly larger than that of the\nconventional time-division multiple-access scheme in many cases, including,\ne.g., the high SNR regime and the case when the direct channel is much stronger\nthan the backscatter channel. Hence, the multiplicative multiple-access scheme\nis an attractive technique to improve the throughput for ambient backscatter\ncommunication systems. Moreover, we analyze the detection error rates for\ncoherent and noncoherent modulation schemes adopted by the Tx and the Tag,\nrespectively, in both synchronous and asynchronous scenarios, which further\nbring interesting insights for practical system design. \n\n"}
{"id": "1711.10783", "contents": "Title: Partial Consensus and Conservative Fusion of Gaussian Mixtures for\n  Distributed PHD Fusion Abstract: We propose a novel consensus notion, called \"partial consensus\", for\ndistributed GM-PHD (Gaussian mixture probability hypothesis density) fusion\nbased on a peer-to-peer (P2P) sensor network, in which only highly-weighted\nposterior Gaussian components (GCs) are disseminated in the P2P communication\nfor fusion while the insignificant GCs are not involved. The partial consensus\ndoes not only enjoy high efficiency in both network communication and local\nfusion computation, but also significantly reduces the affect of potential\nfalse data (clutter) to the filter, leading to increased signal-to-noise ratio\nat local sensors. Two \"conservative\" mixture reduction schemes are advocated\nfor fusing the shared GCs in a fully distributed manner. One is given by\npairwise averaging GCs between sensors based on Hungarian assignment and the\nother is merging close GCs based a new GM merging scheme. The proposed\napproaches have a close connection to the conservative fusion approaches known\nas covariance union and arithmetic mean density. In parallel, average consensus\nis sought on the cardinality distribution (namely the GM weight sum) among\nsensors. Simulations for tracking either a single target or multiple targets\nthat simultaneously appear are presented based on a sensor network where each\nsensor operates a GM-PHD filter, in order to compare our approaches with the\nbenchmark generalized covariance intersection approach. The results demonstrate\nthat the partial, arithmetic average, consensus outperforms the complete,\ngeometric average, consensus. \n\n"}
{"id": "1712.00298", "contents": "Title: A generalised significance test for individual communities in networks Abstract: Many empirical networks have community structure, in which nodes are densely\ninterconnected within each community (i.e., a group of nodes) and sparsely\nacross different communities. Like other local and meso-scale structure of\nnetworks, communities are generally heterogeneous in various aspects such as\nthe size, density of edges, connectivity to other communities and significance.\nIn the present study, we propose a method to statistically test the\nsignificance of individual communities in a given network. Compared to the\nprevious methods, the present algorithm is unique in that it accepts different\ncommunity-detection algorithms and the corresponding quality function for\nsingle communities. The present method requires that a quality of each\ncommunity can be quantified and that community detection is performed as\noptimisation of such a quality function summed over the communities. Various\ncommunity detection algorithms including modularity maximisation and graph\npartitioning meet this criterion. Our method estimates a distribution of the\nquality function for randomised networks to calculate a likelihood of each\ncommunity in the given network. We illustrate our algorithm by synthetic and\nempirical networks. \n\n"}
{"id": "1712.02426", "contents": "Title: Compressive Phase Retrieval via Reweighted Amplitude Flow Abstract: The problem of reconstructing a sparse signal vector from magnitude-only\nmeasurements (a.k.a., compressive phase retrieval), emerges naturally in\ndiverse applications, but it is NP-hard in general. Building on recent advances\nin nonconvex optimization, this paper puts forth a new algorithm that is termed\ncompressive reweighted amplitude flow and abbreviated as CRAF, for compressive\nphase retrieval. Specifically, CRAF operates in two stages. The first stage\nseeks a sparse initial guess via a new spectral procedure. In the second stage,\nCRAF implements a few hard thresholding based iterations using reweighted\ngradients. When there are sufficient measurements, CRAF provably recovers the\nunderlying signal vector exactly with high probability under suitable\nconditions. Moreover, its sample complexity coincides with that of the\nstate-of-the-art procedures. Finally, substantial simulated tests showcase\nremarkable performance of the new spectral initialization, as well as improved\nexact recovery relative to competing alternatives. \n\n"}
{"id": "1712.02770", "contents": "Title: A Wavelet Plancherel Theory with Application to Multipliers and Sparse\n  Approximations Abstract: We introduce an extension of continuous wavelet theory that enables an\nefficient implementation of multiplicative operators in the coefficient space.\nIn the new theory, the signal space is embedded in a larger abstract signal\nspace -- the so called window-signal space. There is a canonical extension of\nthe wavelet transform to an isometric isomorphism between the window-signal\nspace and the coefficient space. Hence, the new framework is called a\nwavelet-Plancherel theory, and the extended wavelet transform is called the\nwavelet-Plancherel transform. Since the wavelet-Plancherel transform is an\nisometric isomorphism, any operation in the coefficient space can be\npulled-back to an operation in the window-signal space. It is then possible to\nimprove the computational complexity of methods that involve a multiplicative\noperator in the coefficient space, by performing all computations directly in\nthe window-signal space. As one example application, we show how continuous\nwavelet multipliers (also called Calder\\'{o}n-Toeplitz Operators), with\npolynomial symbols, can be implemented with linear complexity in the resolution\nof the 1D signal. As another example, we develop a framework for efficiently\ncomputing greedy sparse approximations to signals based on elements of\ncontinuous wavelet systems. \n\n"}
{"id": "1712.04086", "contents": "Title: PacGAN: The power of two samples in generative adversarial networks Abstract: Generative adversarial networks (GANs) are innovative techniques for learning\ngenerative models of complex data distributions from samples. Despite\nremarkable recent improvements in generating realistic images, one of their\nmajor shortcomings is the fact that in practice, they tend to produce samples\nwith little diversity, even when trained on diverse datasets. This phenomenon,\nknown as mode collapse, has been the main focus of several recent advances in\nGANs. Yet there is little understanding of why mode collapse happens and why\nexisting approaches are able to mitigate mode collapse. We propose a principled\napproach to handling mode collapse, which we call packing. The main idea is to\nmodify the discriminator to make decisions based on multiple samples from the\nsame class, either real or artificially generated. We borrow analysis tools\nfrom binary hypothesis testing---in particular the seminal result of Blackwell\n[Bla53]---to prove a fundamental connection between packing and mode collapse.\nWe show that packing naturally penalizes generators with mode collapse, thereby\nfavoring generator distributions with less mode collapse during the training\nprocess. Numerical experiments on benchmark datasets suggests that packing\nprovides significant improvements in practice as well. \n\n"}
{"id": "1712.04122", "contents": "Title: Performance guarantees for greedy maximization of non-submodular\n  controllability metrics Abstract: A key problem in emerging complex cyber-physical networks is the design of\ninformation and control topologies, including sensor and actuator selection and\ncommunication network design. These problems can be posed as combinatorial set\nfunction optimization problems to maximize a dynamic performance metric for the\nnetwork. Some systems and control metrics feature a property called\nsubmodularity, which allows simple greedy algorithms to obtain provably\nnear-optimal topology designs. However, many important metrics lack\nsubmodularity and therefore lack provable guarantees for using a greedy\noptimization approach. Here we show that performance guarantees can be obtained\nfor greedy maximization of certain non-submodular functions of the\ncontrollability and observability Gramians. Our results are based on two key\nquantities: the submodularity ratio, which quantifies how far a set function is\nfrom being submodular, and the curvature, which quantifies how far a set\nfunction is from being supermodular. \n\n"}
{"id": "1712.06866", "contents": "Title: The Error Probability of Sparse Superposition Codes with Approximate\n  Message Passing Decoding Abstract: Sparse superposition codes, or sparse regression codes (SPARCs), are a recent\nclass of codes for reliable communication over the AWGN channel at rates\napproaching the channel capacity. Approximate message passing (AMP) decoding, a\ncomputationally efficient technique for decoding SPARCs, has been proven to be\nasymptotically capacity-achieving for the AWGN channel. In this paper, we\nrefine the asymptotic result by deriving a large deviations bound on the\nprobability of AMP decoding error. This bound gives insight into the error\nperformance of the AMP decoder for large but finite problem sizes, giving an\nerror exponent as well as guidance on how the code parameters should be chosen\nat finite block lengths. For an appropriate choice of code parameters, we show\nthat for any fixed rate less than the channel capacity, the decoding error\nprobability decays exponentially in $n/(\\log n)^{2T}$, where $T$, the number of\nAMP iterations required for successful decoding, is bounded in terms of the gap\nfrom capacity. \n\n"}
{"id": "1712.07807", "contents": "Title: Fault Tolerance of Random Graphs with respect to Connectivity:\n  Mean-field Approximation for Semi-dense Random Graphs Abstract: The fault tolerance of random graphs with unbounded degrees with respect to\nconnectivity is investigated, which relates to the reliability of wireless\nsensor networks with unreliable relay nodes. The model evaluates the network\nbreakdown probability that a graph is disconnected after stochastic node\nremoval. To establish a mean-field approximation for the model, we propose the\ncavity method for finite systems. The analysis enables us to obtain an\napproximation formula for random graphs with any number of nodes and an\narbitrary degree distribution. In addition, its asymptotic analysis reveals\nthat the phase transition occurs in semi-dense random graphs whose average\ndegree grows logarithmically. These results, which are supported by numerical\nsimulations, coincide with the mathematical results, indicating successful\npredictions by mean-field approximation for unbounded but not dense random\ngraphs. \n\n"}
{"id": "1712.08113", "contents": "Title: Optimal Error Correcting Delivery Scheme for Coded Caching with\n  Symmetric Batch Prefetching Abstract: Coded caching is used to reduce network congestion during peak hours. A\nsingle server is connected to a set of users through a bottleneck link, which\ngenerally is assumed to be error-free. During non-peak hours, all the users\nhave full access to the files and they fill their local cache with portions of\nthe files available. During delivery phase, each user requests a file and the\nserver delivers coded transmissions to meet the demands taking into\nconsideration their cache contents. In this paper we assume that the shared\nlink is error prone. A new delivery scheme is required to meet the demands of\neach user even after receiving finite number of transmissions in error. We\ncharacterize the minimum average rate and minimum peak rate for this problem.\nWe find closed form expressions of these rates for a particular caching scheme\nnamely \\textit{symmetric batch prefetching}. We also propose an optimal error\ncorrecting delivery scheme for coded caching problem with symmetric batch\nprefetching. \n\n"}
{"id": "1712.08212", "contents": "Title: Submodular Optimization for Consensus Networks with Noise-Corrupted\n  Leaders Abstract: We consider the leader selection problem in a network with consensus dynamics\nwhere both leader and follower agents are subject to stochastic external\ndisturbances. The performance of the system is quantified by the total\nsteady-state variance of the node states, and the goal is to identify the set\nof leaders that minimizes this variance. We first show that this performance\nmeasure can be expressed as a submodular set function over the nodes in the\nnetwork. We then use this result to analyze the performance of two greedy,\npolynomial-time algorithms for leader selection, showing that the leader sets\nproduced by the greedy algorithms are within provable bounds of optimal. \n\n"}
{"id": "1712.10163", "contents": "Title: Estimation under group actions: recovering orbits from invariants Abstract: We study a class of orbit recovery problems in which we observe independent\ncopies of an unknown element of $\\mathbb{R}^p$, each linearly acted upon by a\nrandom element of some group (such as $\\mathbb{Z}/p$ or $\\mathrm{SO}(3)$) and\nthen corrupted by additive Gaussian noise. We prove matching upper and lower\nbounds on the number of samples required to approximately recover the group\norbit of this unknown element with high probability. These bounds, based on\nquantitative techniques in invariant theory, give a precise correspondence\nbetween the statistical difficulty of the estimation problem and algebraic\nproperties of the group. Furthermore, we give computer-assisted procedures to\ncertify these properties that are computationally efficient in many cases of\ninterest.\n  The model is motivated by geometric problems in signal processing, computer\nvision, and structural biology, and applies to the reconstruction problem in\ncryo-electron microscopy (cryo-EM), a problem of significant practical\ninterest. Our results allow us to verify (for a given problem size) that if\ncryo-EM images are corrupted by noise with variance $\\sigma^2$, the number of\nimages required to recover the molecule structure scales as $\\sigma^6$. We\nmatch this bound with a novel (albeit computationally expensive) algorithm for\nab initio reconstruction in cryo-EM, based on invariant features of degree at\nmost 3. We further discuss how to recover multiple molecular structures from\nmixed (or heterogeneous) cryo-EM samples. \n\n"}
{"id": "1801.00965", "contents": "Title: Phase Transition of Convex Programs for Linear Inverse Problems with\n  Multiple Prior Constraints Abstract: A sharp phase transition emerges in convex programs when solving the linear\ninverse problem, which aims to recover a structured signal from its linear\nmeasurements. This paper studies this phenomenon in theory under Gaussian\nrandom measurements. Different from previous studies, in this paper, we\nconsider convex programs with multiple prior constraints. These programs are\nencountered in many cases, for example, when the signal is sparse and its\n$\\ell_2$ norm is known beforehand, or when the signal is sparse and\nnon-negative simultaneously. Given such a convex program, to analyze its phase\ntransition, we introduce a new set and a new cone, called the prior restricted\nset and prior restricted cone, respectively. Our results reveal that the phase\ntransition of a convex problem occurs at the statistical dimension of its prior\nrestricted cone. Moreover, to apply our theoretical results in practice, we\npresent two recipes to accurately estimate the statistical dimension of the\nprior restricted cone. These two recipes work under different conditions, and\nwe give a detailed analysis for them. To further illustrate our results, we\napply our theoretical results and the estimation recipes to study the phase\ntransition of two specific problems, and obtain computable formulas for the\nstatistical dimension and related error bounds. Simulations are provided to\ndemonstrate our results. \n\n"}
{"id": "1801.02287", "contents": "Title: Explicit Constructions of MBR and MSR Codes for Clustered Distributed\n  Storage Abstract: This paper considers capacity-achieving coding for the clustered form of\ndistributed storage that reflects practical storage networks. To reflect the\nclustered structure with limited cross-cluster communication bandwidths, nodes\nin the same cluster are set to communicate $\\beta_I$ symbols, while nodes in\nother clusters can communicate $\\beta_c \\leq \\beta_I$ symbols with one another.\nWe provide two types of exact regenerating codes which achieve the capacity of\nclustered distributed storage: the minimum-bandwidth-regenerating (MBR) codes\nand the minimum-storage-regenerating (MSR) codes. First, we construct MBR codes\nfor general parameter settings of clustered distributed storage. The suggested\nMBR code is a generalization of an existing code proposed by Rashmi et al., for\nscenarios where storage nodes are dispersed into L > 1 clusters. The proposed\nMBR code for the $\\beta_c = 0$ case requires a much smaller field size compared\nto existing local MBR codes. Secondly, we devise MSR codes for clustered\ndistributed storage. Focus is given on two important cases:$\\epsilon=0$ and\n$\\epsilon \\in [1/(n-k), 1]$, where $\\epsilon=\\beta_c/\\beta_I$ is the ratio of\nthe available cross- to intra-cluster repair bandwidths, n is the total number\nof distributed nodes and k is the number of contact nodes in data retrieval.\nThe former represents the scenario where cross-cluster communication is not\nallowed, while the latter corresponds to the case of minimum node storage\noverhead. For $\\epsilon=0$, two existing locally repairable codes are proven to\nbe MSR codes for the clustered model. For $\\epsilon \\in [1/(n-k), 1]$, existing\nMSR codes for the non-clustered model are applicable to clustered scenarios\nwith a simple modification. \n\n"}
{"id": "1801.02743", "contents": "Title: Enhancing Performance of Random Caching in Large-Scale Wireless Networks\n  with Multiple Receive Antennas Abstract: To improve signal-to-interference ratio (SIR) and make better use of file\ndiversity provided by random caching, we consider two types of linear\nreceivers, i.e., maximal ratio combining (MRC) receiver and partial zero\nforcing (PZF) receiver, at users in a large-scale cache-enabled single-input\nmulti-output (SIMO) network. First, for each receiver, by utilizing tools from\nstochastic geometry, we derive a tractable expression and a tight upper bound\nfor the successful transmission probability (STP). In the case of the MRC\nreceiver, we also derive a closed-form expression for the asymptotic outage\nprobability in the low SIR threshold regime. Then, for each receiver, we\nmaximize the STP. In the case of the MRC receiver, we consider the maximization\nof the tight upper bound on the STP by optimizing the caching distribution,\nwhich is a non-convex problem. We obtain a stationary point, by solving an\nequivalent difference of convex (DC) programming problem using concave-convex\nprocedure (CCCP). We also obtain a closed-form asymptotically optimal solution\nin the low SIR threshold regime. In the case of the PZF receiver, we consider\nthe maximization of the tight upper bound on the STP by optimizing the caching\ndistribution and the degrees of freedom (DoF) allocation (for boosting the\nsignal power), which is a mixed discrete-continuous problem. Based on\nstructural properties, we obtain a low-complexity near optimal solution by\nusing an alternating optimization approach. The analysis and optimization\nresults reveal the impact of antenna resource at users on random caching.\nFinally, by numerical results, we show that the random caching design with the\nPZF receiver achieves significant performance gains over the random caching\ndesign with the MRC receiver and some baseline caching designs. \n\n"}
{"id": "1801.02781", "contents": "Title: Minimum Throughput Maximization in UAV-Aided Wireless Powered\n  Communication Networks Abstract: This paper investigates unmanned aerial vehicle (UAV)-aided wireless powered\ncommunication network (WPCN) systems where a mobile access point (AP) at the\nUAV serves multiple energy-constrained ground terminals (GTs). Specifically,\nthe UAVs first charge the GTs by transmitting the wireless energy transfer\n(WET) signals in the downlink. Then, by utilizing the harvested wireless energy\nfrom the UAVs, the GTs send their uplink wireless information transmission\n(WIT) signals to the UAVs. In this paper, depending on the operations of the\nUAVs, we adopt two different scenarios, namely integrated UAV and separated UAV\nWPCNs. First, in the integrated UAV WPCN, a UAV acts as a hybrid AP in which\nboth energy transfer and information reception are processed at a single UAV.\nIn contrast, for the separated UAV WPCN, we consider two UAVs each of which\nbehaves as an energy AP and an information AP independently, and thus the\nenergy transfer and the information decoding are separately performed at two\ndifferent UAVs. For both systems, we jointly optimize the trajectories of the\nUAVs, the uplink power control, and the time resource allocation for the WET\nand the WIT to maximize the minimum throughput of the GTs. Since the formulated\nproblems are non-convex, we apply the concave-convex procedure by deriving\nappropriate convex bounds for non-convex constraints. As a result, we propose\niterative algorithms which efficiently identify a local optimal solution for\nthe minimum throughput maximization problems. Simulation results verify the\nefficiency of the proposed algorithms compared to conventional schemes. \n\n"}
{"id": "1801.03400", "contents": "Title: Scale-free networks are rare Abstract: A central claim in modern network science is that real-world networks are\ntypically \"scale free,\" meaning that the fraction of nodes with degree $k$\nfollows a power law, decaying like $k^{-\\alpha}$, often with $2 < \\alpha < 3$.\nHowever, empirical evidence for this belief derives from a relatively small\nnumber of real-world networks. We test the universality of scale-free structure\nby applying state-of-the-art statistical tools to a large corpus of nearly 1000\nnetwork data sets drawn from social, biological, technological, and\ninformational sources. We fit the power-law model to each degree distribution,\ntest its statistical plausibility, and compare it via a likelihood ratio test\nto alternative, non-scale-free models, e.g., the log-normal. Across domains, we\nfind that scale-free networks are rare, with only 4% exhibiting the\nstrongest-possible evidence of scale-free structure and 52% exhibiting the\nweakest-possible evidence. Furthermore, evidence of scale-free structure is not\nuniformly distributed across sources: social networks are at best weakly scale\nfree, while a handful of technological and biological networks can be called\nstrongly scale free. These results undermine the universality of scale-free\nnetworks and reveal that real-world networks exhibit a rich structural\ndiversity that will likely require new ideas and mechanisms to explain. \n\n"}
{"id": "1801.04686", "contents": "Title: Hierarchical Coding for Distributed Computing Abstract: Coding for distributed computing supports low-latency computation by\nrelieving the burden of straggling workers. While most existing works assume a\nsimple master-worker model, we consider a hierarchical computational structure\nconsisting of groups of workers, motivated by the need to reflect the\narchitectures of real-world distributed computing systems. In this work, we\npropose a hierarchical coding scheme for this model, as well as analyze its\ndecoding cost and expected computation time. Specifically, we first provide\nupper and lower bounds on the expected computing time of the proposed scheme.\nWe also show that our scheme enables efficient parallel decoding, thus reducing\ndecoding costs by orders of magnitude over non-hierarchical schemes. When\nconsidering both decoding cost and computing time, the proposed hierarchical\ncoding is shown to outperform existing schemes in many practical scenarios. \n\n"}
{"id": "1801.05681", "contents": "Title: Mixed Delay Constraints in Wyner's Soft-Handoff Network Abstract: Wyner's soft-handoff network with mixed delay constraints is considered when\nneighbouring receivers can cooperate over rate-limited links. Each source\nmessage is a combination of independent \"fast\" and \"slow\" bits, where the\nformer are subject to a stringent decoding delay. Inner and outer bounds on the\ncapacity region are derived, and the multiplexing gain region is characterized\nwhen only transmitters or only receivers cooperate. \n\n"}
{"id": "1801.06022", "contents": "Title: Reconstruction Codes for DNA Sequences with Uniform Tandem-Duplication\n  Errors Abstract: DNA as a data storage medium has several advantages, including far greater\ndata density compared to electronic media. We propose that schemes for data\nstorage in the DNA of living organisms may benefit from studying the\nreconstruction problem, which is applicable whenever multiple reads of noisy\ndata are available. This strategy is uniquely suited to the medium, which\ninherently replicates stored data in multiple distinct ways, caused by\nmutations. We consider noise introduced solely by uniform tandem-duplication,\nand utilize the relation to constant-weight integer codes in the Manhattan\nmetric. By bounding the intersection of the cross-polytope with hyperplanes, we\nprove the existence of reconstruction codes with greater capacity than known\nerror-correcting codes, which we can determine analytically for any set of\nparameters. \n\n"}
{"id": "1801.06623", "contents": "Title: Promises and Caveats of Uplink IoT Ultra-Dense Networks Abstract: In this paper, by means of simulations, we evaluate the uplink (UL)\nperformance of an Internet of Things (IoT) capable ultra-dense network (UDN) in\nterms of the coverage probability and the density of reliably working user\nequipments (UEs). From our study, we show the benefits and challenges that UL\nIoT UDNs will bring about in the future. In more detail, for a low-reliability\ncriterion, such as achieving a UL signal-to-interference-plus-noise ratio\n(SINR) above 0 dB, the density of reliably working UEs grows quickly with the\nnetwork densification, showing the potential of UL IoT UDNs. In contrast, for a\nhigh-reliability criterion, such as achieving a UL SINR above 10 dB, the\ndensity of reliably working UEs remains to be low in UDNs due to excessive\ninter-cell interference, which should be considered when operating UL IoT UDNs.\nMoreover, considering the existence of a non-zero antenna height difference\nbetween base stations (BSs) and UEs, the density of reliably working UEs could\neven decrease as we deploy more BSs. This calls for the usage of sophisticated\ninterference management schemes and/or beam steering/shaping technologies in UL\nIoT UDNs. \n\n"}
{"id": "1801.07695", "contents": "Title: Homologous Codes for Multiple Access Channels Abstract: Building on recent development by Padakandla and Pradhan, and by Lim, Feng,\nPastore, Nazer, and Gastpar, this paper studies the potential of structured\nnested coset coding as a complete replacement for random coding in network\ninformation theory. The roles of two techniques used in nested coset coding to\ngenerate nonuniform codewords, namely, shaping and channel transformation, are\nclarified and illustrated via the simple example of the two-sender multiple\naccess channel. While individually deficient, the optimal combination of\nshaping and channel transformation is shown to achieve the same performance as\ntraditional random codes for the general two-sender multiple access channel.\nThe achievability proof of the capacity region is extended to the multiple\naccess channels with more than two senders, and with one or more receivers. A\nquantization argument consistent with the construction of nested coset codes is\npresented to prove achievability for their Gaussian counterparts. These results\nopen up new possibilities of utilizing nested coset codes with the same\ngenerator matrix for a broader class of applications. \n\n"}
{"id": "1801.08102", "contents": "Title: Energy-constrained two-way assisted private and quantum capacities of\n  quantum channels Abstract: With the rapid growth of quantum technologies, knowing the fundamental\ncharacteristics of quantum systems and protocols is essential for their\neffective implementation. A particular communication setting that has received\nincreased focus is related to quantum key distribution and distributed quantum\ncomputation. In this setting, a quantum channel connects a sender to a\nreceiver, and their goal is to distill either a secret key or entanglement,\nalong with the help of arbitrary local operations and classical communication\n(LOCC). In this work, we establish a general theory of energy-constrained,\nLOCC-assisted private and quantum capacities of quantum channels, which are the\nmaximum rates at which an LOCC-assisted quantum channel can reliably establish\nsecret key or entanglement, respectively, subject to an energy constraint on\nthe channel input states. We prove that the energy-constrained squashed\nentanglement of a channel is an upper bound on these capacities. We also\nexplicitly prove that a thermal state maximizes a relaxation of the squashed\nentanglement of all phase-insensitive, single-mode input bosonic Gaussian\nchannels, generalizing results from prior work. After doing so, we prove that a\nvariation of the method introduced in [Goodenough et al., New J. Phys. 18,\n063005 (2016)] leads to improved upper bounds on the energy-constrained\nsecret-key-agreement capacity of a bosonic thermal channel. We then consider a\nmultipartite setting and prove that two known multipartite generalizations of\nthe squashed entanglement are in fact equal. We finally show that the\nenergy-constrained, multipartite squashed entanglement plays a role in bounding\nthe energy-constrained LOCC-assisted private and quantum capacity regions of\nquantum broadcast channels. \n\n"}
{"id": "1801.08704", "contents": "Title: Event-triggered stabilization of disturbed linear systems over digital\n  channels Abstract: We present an event-triggered control strategy for stabilizing a scalar,\ncontinuous-time, time-invariant, linear system over a digital communication\nchannel having bounded delay, and in the presence of bounded system\ndisturbance. We propose an encoding-decoding scheme, and determine lower bounds\non the packet size and on the information transmission rate which are\nsufficient for stabilization. We show that for small values of the delay, the\ntiming information implicit in the triggering events is enough to stabilize the\nsystem with any positive rate. In contrast, when the delay increases beyond a\ncritical threshold, the timing information alone is not enough to stabilize the\nsystem and the transmission rate begins to increase. Finally, large values of\nthe delay require transmission rates higher than what prescribed by the classic\ndata-rate theorem. The results are numerically validated using a linearized\nmodel of an inverted pendulum. \n\n"}
{"id": "1801.08704", "contents": "Title: Event-triggered stabilization of disturbed linear systems over digital\n  channels Abstract: We present an event-triggered control strategy for stabilizing a scalar,\ncontinuous-time, time-invariant, linear system over a digital communication\nchannel having bounded delay, and in the presence of bounded system\ndisturbance. We propose an encoding-decoding scheme, and determine lower bounds\non the packet size and on the information transmission rate which are\nsufficient for stabilization. We show that for small values of the delay, the\ntiming information implicit in the triggering events is enough to stabilize the\nsystem with any positive rate. In contrast, when the delay increases beyond a\ncritical threshold, the timing information alone is not enough to stabilize the\nsystem and the transmission rate begins to increase. Finally, large values of\nthe delay require transmission rates higher than what prescribed by the classic\ndata-rate theorem. The results are numerically validated using a linearized\nmodel of an inverted pendulum. \n\n"}
{"id": "1802.00202", "contents": "Title: Network construction: A learning framework through localizing principal\n  eigenvector Abstract: Information of localization properties of eigenvectors of the complex network\nhas applicability in many different areas which include networks centrality\nmeasures, spectral partitioning, development of approximation algorithms, and\ndisease spreading phenomenon. For linear dynamical process localization of\nprincipal eigenvector (PEV) of adjacency matrices infers condensation of the\ninformation in the smaller section of the network. For a network, an\neigenvector is said to be localized when most of its components are near to\nzero with few taking very high values. Here, we provide three different\nrandom-sampling-based algorithms which, by using the edge rewiring method, can\nevolve a random network having a delocalized PEV to a network having a highly\nlocalized PEV. In other words, we develop a learning framework to explore the\nlocalization of PEV through a random sampling-based optimization method. We\ndiscuss the drawbacks and advantages of these algorithms. Additionally, we show\nthat the construction of such networks corresponding to the highly localized\nPEV is a non-convex optimization problem when the objective function is the\ninverse participation ratio. This framework is also relevant to construct a\nnetwork structure for other lower-order eigenvectors. \n\n"}
{"id": "1802.00396", "contents": "Title: Disunited Nations? A Multiplex Network Approach to Detecting Preference\n  Affinity Blocs using Texts and Votes Abstract: This paper contributes to an emerging literature that models votes and text\nin tandem to better understand polarization of expressed preferences. It\nintroduces a new approach to estimate preference polarization in\nmultidimensional settings, such as international relations, based on\ndevelopments in the natural language processing and network science literatures\n-- namely word embeddings, which retain valuable syntactical qualities of human\nlanguage, and community detection in multilayer networks, which locates densely\nconnected actors across multiple, complex networks. We find that the employment\nof these tools in tandem helps to better estimate states' foreign policy\npreferences expressed in UN votes and speeches beyond that permitted by votes\nalone. The utility of these located affinity blocs is demonstrated through an\napplication to conflict onset in International Relations, though these tools\nwill be of interest to all scholars faced with the measurement of preferences\nand polarization in multidimensional settings. \n\n"}
{"id": "1802.00609", "contents": "Title: An LMI Approach to Stability Analysis of Coupled Parabolic Systems Abstract: We analyze the exponential stability of distributed parameter systems. The\nsystem we consider is described by a coupled parabolic partial differential\nequation with spatially varying coefficients. We approximate the coefficients\nby splitting space domains but take into account approximation errors during\nstability analysis. Using a quadratic Lyapunov function, we obtain sufficient\nconditions for exponential stability in terms of linear matrix inequalities. \n\n"}
{"id": "1802.01049", "contents": "Title: Blind Joint MIMO Channel Estimation and Decoding Abstract: We propose a method for MIMO decoding when channel state information (CSI) is\nunknown to both the transmitter and receiver. The proposed method requires some\nstructure in the transmitted signal for the decoding to be effective, in\nparticular that the underlying sources are drawn from a hypercubic space. Our\nproposed technique fits a minimum volume parallelepiped to the received\nsamples. This problem can be expressed as a non-convex optimization problem\nthat can be solved with high probability by gradient descent. Our blind\ndecoding algorithm can be used when communicating over unknown MIMO wireless\nchannels using either BPSK or MPAM modulation. We apply our technique to\njointly estimate MIMO channel gain matrices and decode the underlying\ntransmissions with only knowledge of the transmitted constellation and without\nthe use of pilot symbols. Our results provide theoretical guarantees that the\nproposed algorithm is correct when applied to small MIMO systems. Empirical\nresults show small sample size requirements, making this algorithm suitable for\nblock-fading channels with coherence times typically seen in practice. Our\napproach has a loss of less than 3dB compared to zero-forcing with perfect CSI,\nimposing a similar performance penalty as space-time coding techniques without\nthe loss of rate incurred by those techniques. \n\n"}
{"id": "1802.01527", "contents": "Title: Supporting UAV Cellular Communications through Massive MIMO Abstract: In this article, we provide a much-needed study of UAV cellular\ncommunications, focusing on the rates achievable for the UAV downlink command\nand control (C&C) channel. For this key performance indicator, we perform a\nrealistic comparison between existing deployments operating in single-user mode\nand next-generation multi-user massive MIMO systems. We find that in\nsingle-user deployments under heavy data traffic, UAVs flying at 50 m, 150 m,\nand 300 m achieve the C&C target rate of 100 kbps -- as set by the 3GPP -- in a\nmere 35%, 2%, and 1% of the cases, respectively. Owing to mitigated\ninterference, a stronger carrier signal, and a spatial multiplexing gain,\nmassive MIMO time division duplex systems can dramatically increase such\nprobability. Indeed, we show that for UAV heights up to 300 m the target rate\nis met with massive MIMO in 74% and 96% of the cases with and without uplink\npilot reuse for channel state information (CSI) acquisition, respectively. On\nthe other hand, the presence of UAVs can significantly degrade the performance\nof ground users, whose pilot signals are vulnerable to UAV-generated\ncontamination and require protection through uplink power control. \n\n"}
{"id": "1802.02049", "contents": "Title: A Distance Between Channels: the average error of mismatched channels Abstract: Two channels are equivalent if their maximum likelihood (ML) decoders\ncoincide for every code. We show that this equivalence relation partitions the\nspace of channels into a generalized hyperplane arrangement. With this, we\ndefine a coding distance between channels in terms of their ML-decoders which\nis meaningful from the decoding point of view, in the sense that the closer two\nchannels are, the larger is the probability of them sharing the same\nML-decoder. We give explicit formulas for these probabilities. \n\n"}
{"id": "1802.02640", "contents": "Title: Minimizing Latency for Secure Coded Computing Using Secret Sharing via\n  Staircase Codes Abstract: We consider the setting of a Master server, M, who possesses confidential\ndata (e.g., personal, genomic or medical data) and wants to run intensive\ncomputations on it, as part of a machine learning algorithm for example. The\nMaster wants to distribute these computations to untrusted workers who have\nvolunteered or are incentivized to help with this task. However, the data must\nbe kept private and not revealed to the individual workers. Some of the workers\nmay be stragglers, e.g., slow or busy, and will take a random time to finish\nthe task assigned to them. We are interested in reducing the delays experienced\nby the Master. We focus on linear computations as an essential operation in\nmany iterative algorithms such as principal component analysis, support vector\nmachines and other gradient-descent based algorithms. A classical solution is\nto use a linear secret sharing scheme, such as Shamir's scheme, to divide the\ndata into secret shares on which the workers can perform linear computations.\nHowever, classical codes can provide straggler mitigation assuming a worst-case\nscenario of a fixed number of stragglers. We propose a solution based on new\nsecure codes, called Staircase codes, introduced previously by two of the\nauthors. Staircase codes allow flexibility in the number of stragglers up to a\ngiven maximum, and universally achieve the information theoretic limit on the\ndownload cost by the Master, leading to latency reduction. Under the shifted\nexponential model, we find upper and lower bounds on the Master's mean waiting\ntime. We derive the distribution of the Master's waiting time, and its mean,\nfor systems with up to two stragglers. For systems with any number of\nstragglers, we derive an expression that can give the exact distribution, and\nthe mean, of the waiting time of the Master. We show that Staircase codes\nalways outperform classical secret sharing codes. \n\n"}
{"id": "1802.03049", "contents": "Title: Leveraging Coding Techniques for Speeding up Distributed Computing Abstract: Large scale clusters leveraging distributed computing frameworks such as\nMapReduce routinely process data that are on the orders of petabytes or more.\nThe sheer size of the data precludes the processing of the data on a single\ncomputer. The philosophy in these methods is to partition the overall job into\nsmaller tasks that are executed on different servers; this is called the map\nphase. This is followed by a data shuffling phase where appropriate data is\nexchanged between the servers. The final so-called reduce phase, completes the\ncomputation.\n  One potential approach, explored in prior work for reducing the overall\nexecution time is to operate on a natural tradeoff between computation and\ncommunication. Specifically, the idea is to run redundant copies of map tasks\nthat are placed on judiciously chosen servers. The shuffle phase exploits the\nlocation of the nodes and utilizes coded transmission. The main drawback of\nthis approach is that it requires the original job to be split into a number of\nmap tasks that grows exponentially in the system parameters. This is\nproblematic, as we demonstrate that splitting jobs too finely can in fact\nadversely affect the overall execution time.\n  In this work we show that one can simultaneously obtain low communication\nloads while ensuring that jobs do not need to be split too finely. Our approach\nuncovers a deep relationship between this problem and a class of combinatorial\nstructures called resolvable designs. Appropriate interpretation of resolvable\ndesigns can allow for the development of coded distributed computing schemes\nwhere the splitting levels are exponentially lower than prior work. We present\nexperimental results obtained on Amazon EC2 clusters for a widely known\ndistributed algorithm, namely TeraSort. We obtain over 4.69$\\times$ improvement\nin speedup over the baseline approach and more than 2.6$\\times$ over current\nstate of the art. \n\n"}
{"id": "1802.03372", "contents": "Title: Synergistic interactions promote behavior spreading and alter phase\n  transition on multiplex networks Abstract: Synergistic interactions are ubiquitous in the real world. Recent studies\nhave revealed that, for a single-layer network, synergy can enhance spreading\nand even induce an explosive contagion. There is at the present a growing\ninterest in behavior spreading dynamics on multiplex networks. What is the role\nof synergistic interactions in behavior spreading in such networked systems? To\naddress this question, we articulate a synergistic behavior spreading model on\na double layer network, where the key manifestation of the synergistic\ninteractions is that the adoption of one behavior by a node in one layer\nenhances its probability of adopting the behavior in the other layer. A general\nresult is that synergistic interactions can greatly enhance the spreading of\nthe behaviors in both layers. A remarkable phenomenon is that the interactions\ncan alter the nature of the phase transition associated with behavior adoption\nor spreading dynamics. In particular, depending on the transmission rate of one\nbehavior in a network layer, synergistic interactions can lead to a\ndiscontinuous (first-order) or a continuous (second-order) transition in the\nadoption scope of the other behavior with respect to its transmission rate. A\nsurprising two-stage spreading process can arise: due to synergy, nodes having\nadopted one behavior in one layer adopt the other behavior in the other layer\nand then prompt the remaining nodes in this layer to quickly adopt the\nbehavior. Analytically, we develop an edge-based compartmental theory and\nperform a bifurcation analysis to fully understand, in the weak synergistic\ninteraction regime where the dynamical correlation between the network layers\nis negligible, the role of the interactions in promoting the social behavioral\nspreading dynamics in the whole system. \n\n"}
{"id": "1802.04036", "contents": "Title: Inferring the time-varying functional connectivity of large-scale\n  computer networks from emitted events Abstract: We consider the problem of inferring the functional connectivity of a\nlarge-scale computer network from sparse time series of events emitted by its\nnodes. We do so under the following three domain-specific constraints: (a)\nnon-stationarity of the functional connectivity due to unknown temporal changes\nin the network, (b) sparsity of the time-series of events that limits the\neffectiveness of classical correlation-based analysis, and (c) lack of an\nexplicit model describing how events propagate through the network. Under the\nassumption that the probability of two nodes being functionally connected\ncorrelates with the mean delay between their respective events, we develop an\ninference method whose output is an undirected weighted network where the\nweight of an edge between two nodes denotes the probability of these nodes\nbeing functionally connected. Using a combination of windowing and convolution\nto calculate at each time window a score quantifying the likelihood of a pair\nof nodes emitting events in quick succession, we develop a model of\ntime-varying connectivity whose parameters are determined by maximising the\nmodel's predictive power from one time window to the next. To assess the\neffectiveness of our inference method, we construct synthetic data for which\nground truth is available and use these data to benchmark our approach against\nthree state-of-the-art inference methods. We conclude by discussing its\napplication to data from a real-world large-scale computer network. \n\n"}
{"id": "1802.04122", "contents": "Title: Tagvisor: A Privacy Advisor for Sharing Hashtags Abstract: Hashtag has emerged as a widely used concept of popular culture and\ncampaigns, but its implications on people's privacy have not been investigated\nso far. In this paper, we present the first systematic analysis of privacy\nissues induced by hashtags. We concentrate in particular on location, which is\nrecognized as one of the key privacy concerns in the Internet era. By relying\non a random forest model, we show that we can infer a user's precise location\nfrom hashtags with accuracy of 70\\% to 76\\%, depending on the city. To remedy\nthis situation, we introduce a system called Tagvisor that systematically\nsuggests alternative hashtags if the user-selected ones constitute a threat to\nlocation privacy. Tagvisor realizes this by means of three conceptually\ndifferent obfuscation techniques and a semantics-based metric for measuring the\nconsequent utility loss. Our findings show that obfuscating as little as two\nhashtags already provides a near-optimal trade-off between privacy and utility\nin our dataset. This in particular renders Tagvisor highly time-efficient, and\nthus, practical in real-world settings. \n\n"}
{"id": "1802.05843", "contents": "Title: Minimal Algorithmic Information Loss Methods for Dimension Reduction,\n  Feature Selection and Network Sparsification Abstract: We present a novel, domain-agnostic, model-independent, unsupervised, and\nuniversally applicable approach for data summarization. Specifically, we focus\non addressing the challenge of reducing certain dimensionality aspects, such as\nthe number of edges in a network, while retaining essential features of\ninterest. These features include preserving crucial network properties like\ndegree distribution, clustering coefficient, edge betweenness, and degree and\neigenvector centralities. Our approach outperforms state-of-the-art network\nreduction techniques by achieving an average improvement in feature\npreservation. Previous methods grounded in statistics or classical information\ntheory have been limited in their ability to capture more intricate patterns\nand features, particularly nonlinear patterns stemming from deterministic\ncomputable processes. Moreover, these approaches heavily rely on a priori\nfeature selection, demanding constant supervision. Our findings demonstrate the\neffectiveness of the algorithms proposed in this study in overcoming these\nlimitations, all while maintaining a time-efficient computational profile. In\nmany instances, our approach not only matches but also surpasses the\nperformance of established network reduction algorithms. Furthermore, we extend\nthe applicability of our method to lossy compression tasks involving images or\nany bi-dimensional data. This highlights the versatility and broad utility of\nour approach in various domains. \n\n"}
{"id": "1802.05856", "contents": "Title: Algorithmic Complexity and Reprogrammability of Chemical Structure\n  Networks Abstract: Here we address the challenge of profiling causal properties and tracking the\ntransformation of chemical compounds from an algorithmic perspective. We\nexplore the potential of applying a computational interventional calculus based\non the principles of algorithmic probability to chemical structure networks. We\nprofile the sensitivity of the elements and covalent bonds in a chemical\nstructure network algorithmically, asking whether reprogrammability affords\ninformation about thermodynamic and chemical processes involved in the\ntransformation of different compound classes. We arrive at numerical results\nsuggesting a correspondence between some physical, structural and functional\nproperties. Our methods are capable of separating chemical classes that reflect\nfunctional and natural differences without considering any information about\natomic and molecular properties. We conclude that these methods, with their\nlinks to chemoinformatics via algorithmic, probability hold promise for future\nresearch. \n\n"}
{"id": "1802.06538", "contents": "Title: Link Selection for Secure Cooperative Networks with Buffer-Aided\n  Relaying Abstract: This paper investigates the secure communication in a two-hop cooperative\nwireless network, where a buffer-aided relay is utilized to forward data from\nthe source to destination, and a passive eavesdropper attempts to intercept\ndata transmission from both the source and relay. Depending on the availability\nof instantaneous channel state information of the source, two cases of\ntransmission mechanisms, i.e., adaptive-rate transmission and fixed-rate\ntransmission are considered. To enhance the security of the system, novel link\nselection policies are proposed for both cases to select source-to-relay,\nrelay-to-destination, or no link transmission based on the channels qualities.\nClosed-form expressions are derived for the end-to-end secrecy outage\nprobability (SOP), secrecy outage capacity (SOC), and exact secrecy throughput\n(EST), respectively. Furthermore, we prove the condition that EST reaches its\nmaximum, and explore how to minimize the SOP and maximize the SOC by optimizing\nthe link selection parameters. Finally, simulations are conducted to\ndemonstrate the validity of our theoretical performance evaluation, and\nextensive numerical results are provided to illustrate the efficiency of the\nproposed link selection polices for the secure communication in two-hop\ncooperative networks. \n\n"}
{"id": "1803.00558", "contents": "Title: VLSI Design of a 3-bit Constant-Modulus Precoder for Massive MU-MIMO Abstract: Fifth-generation (5G) cellular systems will build on massive multi-user (MU)\nmultiple-input multiple-output (MIMO) technology to attain high spectral\nefficiency. However, having hundreds of antennas and radio-frequency (RF)\nchains at the base station (BS) entails prohibitively high hardware costs and\npower consumption. This paper proposes a novel nonlinear precoding algorithm\nfor the massive MU-MIMO downlink in which each RF chain contains an 8-phase\n(3-bit) constant-modulus transmitter, enabling the use of low-cost and\npower-efficient analog hardware. We present a high-throughput VLSI architecture\nand show implementation results on a Xilinx Virtex-7 FPGA. Compared to a\nrecently-reported nonlinear precoder for BS designs that use two 1-bit\ndigital-to-analog converters per RF chain, our design enables up to 3.75 dB\ntransmit power reduction at no more than a 2.7x increase in FPGA resources. \n\n"}
{"id": "1803.01616", "contents": "Title: Tensorial and bipartite block models for link prediction in layered\n  networks and temporal networks Abstract: Many real-world complex systems are well represented as multilayer networks;\npredicting interactions in those systems is one of the most pressing problems\nin predictive network science. To address this challenge, we introduce two\nstochastic block models for multilayer and temporal networks; one of them uses\nnodes as its fundamental unit, whereas the other focuses on links. We also\ndevelop scalable algorithms for inferring the parameters of these models.\nBecause our models describe all layers simultaneously, our approach takes full\nadvantage of the information contained in the whole network when making\npredictions about any particular layer. We illustrate the potential of our\napproach by analyzing two empirical datasets---a temporal network of email\ncommunications, and a network of drug interactions for treating different\ncancer types. We find that modeling all layers simultaneously does result, in\ngeneral, in more accurate link prediction. However, the most predictive model\ndepends on the dataset under consideration; whereas the node-based model is\nmore appropriate for predicting drug interactions, the link-based model is more\nappropriate for predicting email communication. \n\n"}
{"id": "1803.02580", "contents": "Title: Bursty Human Dynamics Abstract: Bursty dynamics is a common temporal property of various complex systems in\nNature but it also characterises the dynamics of human actions and\ninteractions. At the phenomenological level it is a feature of all systems that\nevolve heterogeneously over time by alternating between periods of low and high\nevent frequencies. In such systems, bursts are identified as periods in which\nthe events occur with a rapid pace within a short time-interval while these\nperiods are separated by long periods of time with low frequency of events. As\nsuch dynamical patterns occur in a wide range of natural phenomena, their\nobservation, characterisation, and modelling have been a long standing\nchallenge in several fields of research. However, due to some recent\ndevelopments in communication and data collection techniques it has become\npossible to follow digital traces of actions and interactions of humans from\nthe individual up to the societal level. This led to several new observations\nof bursty phenomena in the new but largely unexplored area of human dynamics,\nwhich called for the renaissance to study these systems using research concepts\nand methodologies, including data analytics and modelling. As a result, a large\namount of new insight and knowledge as well as innovations have been\naccumulated in the field, which provided us a timely opportunity to write this\nbrief monograph to make an up-to-date review and summary of the observations,\nappropriate measures, modelling, and applications of heterogeneous bursty\npatterns occurring in the dynamics of human behaviour. \n\n"}
{"id": "1803.02791", "contents": "Title: Facebook (A)Live? Are live social broadcasts really broadcasts? Abstract: The era of live-broadcast is back but with two major changes. First, unlike\ntraditional TV broadcasts, content is now streamed over the Internet enabling\nit to reach a wider audience. Second, due to various user-generated content\nplatforms it has become possible for anyone to get involved, streaming their\nown content to the world. This emerging trend of going live usually happens via\nsocial platforms, where users perform live social broadcasts predominantly from\ntheir mobile devices, allowing their friends (and the general public) to engage\nwith the stream in real-time. With the growing popularity of such platforms,\nthe burden on the current Internet infrastructure is therefore expected to\nmultiply. With this in mind, we explore one such prominent platform - Facebook\nLive. We gather 3TB of data, representing one month of global activity and\nexplore the characteristics of live social broadcast. From this, we derive\nsimple yet effective principles which can decrease the network burden. We then\ndissect global and hyper-local properties of the video while on-air, by\ncapturing the geography of the broadcasters or the users who produce the video\nand the viewers or the users who interact with it. Finally, we study the social\nengagement while the video is live and distinguish the key aspects when the\nsame video goes on-demand. A common theme throughout the paper is that, despite\nits name, many attributes of Facebook Live deviate from both the concepts of\nlive and broadcast. \n\n"}
{"id": "1803.03346", "contents": "Title: Positivity Bias in Customer Satisfaction Ratings Abstract: Customer ratings are valuable sources to understand their satisfaction and\nare critical for designing better customer experiences and recommendations. The\nmajority of customers, however, do not respond to rating surveys, which makes\nthe result less representative. To understand overall satisfaction, this paper\naims to investigate how likely customers without responses had satisfactory\nexperiences compared to those respondents. To infer customer satisfaction of\nsuch unlabeled sessions, we propose models using recurrent neural networks\n(RNNs) that learn continuous representations of unstructured text conversation.\nBy analyzing online chat logs of over 170,000 sessions from Samsung's customer\nservice department, we make a novel finding that while labeled sessions\ncontributed by a small fraction of customers received overwhelmingly positive\nreviews, the majority of unlabeled sessions would have received lower ratings\nby customers. The data analytics presented in this paper not only have\npractical implications for helping detect dissatisfied customers on live chat\nservices but also make theoretical contributions on discovering the level of\nbiases in online rating platforms. \n\n"}
{"id": "1803.04633", "contents": "Title: Tight Piecewise Convex Relaxations for Global Optimization of Optimal\n  Power Flow Abstract: Since the alternating current optimal power flow (ACOPF) problem was\nintroduced in 1962, developing efficient solution algorithms for the problem\nhas been an active field of research. In recent years, there has been\nincreasing interest in convex relaxations-based solution approaches that are\noften tight in practice. Based on these approaches, we develop tight piecewise\nconvex relaxations with convex-hull representations, an adaptive, multivariate\npartitioning algorithm with bound tightening that progressively improves these\nrelaxations and, given sufficient time, converges to the globally optimal\nsolution. We illustrate the strengths of our algorithm using benchmark ACOPF\ntest cases from the literature. Computational results show that our novel\nalgorithm reduces the best-known optimality gaps for some hard ACOPF cases. \n\n"}
{"id": "1803.06087", "contents": "Title: A Globally Asymptotically Stable Polynomial Vector Field with Rational\n  Coefficients and no Local Polynomial Lyapunov Function Abstract: We give an explicit example of a two-dimensional polynomial vector field of\ndegree seven that has rational coefficients, is globally asymptotically stable,\nbut does not admit an analytic Lyapunov function even locally. \n\n"}
{"id": "1803.06497", "contents": "Title: Variational Bayesian Line Spectral Estimation with Multiple Measurement\n  Vectors Abstract: In this paper, the line spectral estimation (LSE) problem with multiple\nmeasurement vectors (MMVs) is studied utilizing the Bayesian methods. Motivated\nby the recently proposed variational line spectral estimation (VALSE) method,\nwe develop the multisnapshot VALSE (MVALSE) for multi snapshot scenarios, which\nis especially important in array signal processing. The MVALSE shares the\nadvantages of the VALSE method, such as automatically estimating the model\norder, noise variance, weight variance, and providing the uncertain degrees of\nthe frequency estimates. It is shown that the MVALSE can be viewed as applying\nthe VALSE with single measurement vector (SMV) to each snapshot, and combining\nthe intermediate data appropriately. Furthermore, the Seq-MVALSE is developed\nto perform sequential estimation. Finally, numerical results are conducted to\ndemonstrate the effectiveness of the MVALSE method, compared to the\nstate-of-the-art methods in the MMVs setting. \n\n"}
{"id": "1803.07395", "contents": "Title: Max-Min Fairness User Scheduling and Power Allocation in Full-Duplex\n  OFDMA Systems Abstract: In a full-duplex (FD) multi-user network, the system performance is not only\nlimited by the self-interference but also by the co-channel interference due to\nthe simultaneous uplink and downlink transmissions. Joint design of the\nuplink/downlink transmission direction of users and the power allocation is\ncrucial for achieving high system performance in the FD multi-user network. In\nthis paper, we investigate the joint uplink/downlink transmission direction\nassignment (TDA), user paring (UP) and power allocation problem for maximizing\nthe system max-min fairness (MMF) rate in a FD multi-user orthogonal frequency\ndivision multiple access (OFDMA) system. The problem is formulated with a\ntwo-time-scale structure where the TDA and the UP variables are for optimizing\na long-term MMF rate while the power allocation is for optimizing an\ninstantaneous MMF rate during each channel coherence interval. We show that the\nstudied joint MMF rate maximization problem is NP-hard in general. To obtain\nhigh-quality suboptimal solutions, we propose efficient methods based on simple\nrelaxation and greedy rounding techniques. Simulation results are presented to\nshow that the proposed algorithms are effective and achieve higher MMF rates\nthan the existing heuristic methods. \n\n"}
{"id": "1803.08178", "contents": "Title: Boosted Density Estimation Remastered Abstract: There has recently been a steady increase in the number iterative approaches\nto density estimation. However, an accompanying burst of formal convergence\nguarantees has not followed; all results pay the price of heavy assumptions\nwhich are often unrealistic or hard to check. The Generative Adversarial\nNetwork (GAN) literature --- seemingly orthogonal to the aforementioned pursuit\n--- has had the side effect of a renewed interest in variational divergence\nminimisation (notably $f$-GAN). We show that by introducing a weak learning\nassumption (in the sense of the classical boosting framework) we are able to\nimport some recent results from the GAN literature to develop an iterative\nboosted density estimation algorithm, including formal convergence results with\nrates, that does not suffer the shortcomings other approaches. We show that the\ndensity fit is an exponential family, and as part of our analysis obtain an\nimproved variational characterisation of $f$-GAN. \n\n"}
{"id": "1803.08277", "contents": "Title: Synchronization of Coupled Oscillators: The Taylor Expansion of the\n  Inverse Kuramoto Map Abstract: Synchronization in the networks of coupled oscillators is a widely studied\ntopic in different areas. It is well-known that synchronization occurs if the\nconnectivity of the network dominates heterogeneity of the oscillators. Despite\nextensive study on this topic, the quest for sharp closed-form synchronization\ntests is still in vain. In this paper, we present an algorithm for finding the\nTaylor expansion of the inverse Kuramoto map. We show that this Taylor series\ncan be used to obtain a hierarchy of increasingly accurate approximate tests\nwith low computational complexity. These approximate tests are then used to\nestimate the threshold of synchronization as well as the position of the\nsynchronization manifold of the network. \n\n"}
{"id": "1803.08491", "contents": "Title: Influence of fake news in Twitter during the 2016 US presidential\n  election Abstract: The dynamics and influence of fake news on Twitter during the 2016 US\npresidential election remains to be clarified. Here, we use a dataset of 171\nmillion tweets in the five months preceding the election day to identify 30\nmillion tweets, from 2.2 million users, which contain a link to news outlets.\nBased on a classification of news outlets curated by www.opensources.co, we\nfind that 25% of these tweets spread either fake or extremely biased news. We\ncharacterize the networks of information flow to find the most influential\nspreaders of fake and traditional news and use causal modeling to uncover how\nfake news influenced the presidential election. We find that, while top\ninfluencers spreading traditional center and left leaning news largely\ninfluence the activity of Clinton supporters, this causality is reversed for\nthe fake news: the activity of Trump supporters influences the dynamics of the\ntop fake news spreaders. \n\n"}
{"id": "1804.00108", "contents": "Title: Learning tensors from partial binary measurements Abstract: In this paper we generalize the 1-bit matrix completion problem to higher\norder tensors. We prove that when $r=O(1)$ a bounded rank-$r$, order-$d$ tensor\n$T$ in $\\mathbb{R}^{N} \\times \\mathbb{R}^{N} \\times \\cdots \\times\n\\mathbb{R}^{N}$ can be estimated efficiently by only $m=O(Nd)$ binary\nmeasurements by regularizing its max-qnorm and M-norm as surrogates for its\nrank. We prove that similar to the matrix case, i.e., when $d=2$, the sample\ncomplexity of recovering a low-rank tensor from 1-bit measurements of a subset\nof its entries is the same as recovering it from unquantized measurements.\nMoreover, we show the advantage of using 1-bit tensor completion over\nmatricization both theoretically and numerically. Specifically, we show how the\n1-bit measurement model can be used for context-aware recommender systems. \n\n"}
{"id": "1804.00240", "contents": "Title: Missing Data as Part of the Social Behavior in Real-World Financial\n  Complex Systems Abstract: Many real-world networks are known to exhibit facts that counter our\nknowledge prescribed by the theories on network creation and communication\npatterns. A common prerequisite in network analysis is that information on\nnodes and links will be complete because network topologies are extremely\nsensitive to missing information of this kind. Therefore, many real-world\nnetworks that fail to meet this criterion under random sampling may be\ndiscarded.\n  In this paper we offer a framework for interpreting the missing observations\nin network data under the hypothesis that these observations are not missing at\nrandom. We demonstrate the methodology with a case study of a financial trade\nnetwork, where the awareness of agents to the data collection procedure by a\nself-interested observer may result in strategic revealing or withholding of\ninformation. The non-random missingness has been overlooked despite the\npossibility of this being an important feature of the processes by which the\nnetwork is generated. The analysis demonstrates that strategic information\nwithholding may be a valid general phenomenon in complex systems. The evidence\nis sufficient to support the existence of an influential observer and to offer\na compelling dynamic mechanism for the creation of the network. \n\n"}
{"id": "1804.00351", "contents": "Title: Stabilizing a linear system using phone calls: when time is information Abstract: We consider the problem of stabilizing an undisturbed, scalar, linear system\nover a \"timing\" channel, namely a channel where information is communicated\nthrough the timestamps of the transmitted symbols. Each symbol transmitted from\na sensor to a controller in a closed-loop system is received subject to some to\nrandom delay. The sensor can encode messages in the waiting times between\nsuccessive transmissions and the controller must decode them from the\ninter-reception times of successive symbols. This set-up is analogous to a\ntelephone system where a transmitter signals a phone call to a receiver through\na \"ring\" and, after the random delay required to establish the connection; the\nreceiver is aware of the \"ring\" being received. Since there is no data payload\nexchange between the sensor and the controller, this set-up provides an\nabstraction for performing event-triggering control with zero-payload rate. We\nshow the following requirement for stabilization: for the state of the system\nto converge to zero in probability, the timing capacity of the channel should\nbe, essentially, at least as large as the entropy rate of the system.\nConversely, in the case the symbol delays are exponentially distributed, we\nshow an \"almost\" tight sufficient condition using a coding strategy that\nrefines the estimate of the decoded message every time a new symbol is\nreceived. Our results generalize previous zero-payload event-triggering control\nstrategies, revealing a fundamental limit in using timing information for\nstabilization, independent of any transmission strategy. \n\n"}
{"id": "1804.00358", "contents": "Title: Evolution and Limiting Configuration of a Long-Range Schelling-Type Spin\n  System Abstract: We consider a long-range interacting particle system in which binary\nparticles -- whose initial states are chosen uniformly at random -- are located\nat the nodes of a flat torus $(\\mathbb{Z}/h\\mathbb{Z})^2$. Each node of the\ntorus is connected to all the nodes located in an $l_\\infty$-ball of radius $w$\nin the toroidal space centered at itself and we assume that $h$ is\nexponentially larger than $w^2$. Based on the states of the neighboring\nparticles and on the value of a common intolerance threshold $\\tau$, every\nparticle is labeled \"stable,\" or \"unstable.\" Every unstable particle that can\nbecome stable by flipping its state is labeled \"p-stable.\" Finally, unstable\nparticles that remained p-stable for a random, independent and identically\ndistributed waiting time, flip their state and become stable. When the waiting\ntimes have an exponential distribution and $\\tau \\le 1/2$, this model is\nequivalent to a Schelling model of self-organized segregation in an open\nsystem, a zero-temperature Ising model with Glauber dynamics, or an\nAsynchronous Cellular Automaton (ACA) with extended Moore neighborhoods. We\nfirst prove a shape theorem for the spreading of the \"affected\" nodes of a\ngiven state -- namely nodes on which a particle of a given state would be\np-stable. As $w \\rightarrow \\infty$, this spreading starts with high\nprobability (w.h.p.) from any $l_\\infty$-ball in the torus having radius $w/2$\nand containing only affected nodes, and continues for a time that is at least\nexponential in the cardinalilty of the neighborhood of interaction $N =\n(2w+1)^2$. Second, we show that when the process reaches a limiting\nconfiguration and no more state changes occur, for all ${\\tau \\in\n(\\tau^*,1-\\tau^*) \\setminus \\{1/2\\}}$ where ${\\tau^* \\approx 0.488}$, w.h.p.\nany particle is contained in a large \"monochromatic ball\" of cardinality\nexponential in $N$. \n\n"}
{"id": "1804.02710", "contents": "Title: Meta Distribution of the SIR in Large-Scale Uplink and Downlink NOMA\n  Networks Abstract: We develop an analytical framework to derive the meta distribution and\nmoments of the conditional success probability (CSP), which is defined as\n{success probability for a given realization of the transmitters}, in\nlarge-scale co-channel uplink and downlink non-orthogonal multiple access\n(NOMA) networks with one NOMA cluster per cell. The moments of CSP translate to\nvarious network performance metrics such as the standard success or\nsignal-to-interference ratio (SIR) coverage probability (which is the $1$-st\nmoment), the mean local delay (which is the $-1$-st moment in a static network\nsetting), and the meta distribution (which is the complementary cumulative\ndistribution function of the conditional success probability and can be\napproximated by using the $1$-st and $2$-nd moments). For uplink NOMA, to make\nthe framework tractable, we propose two point process models for the spatial\nlocations of the interferers by utilizing the base station (BS)/user pair\ncorrelation function. We validate the proposed models by comparing the second\nmoment measure of each model with that of the actual point process for the\ninter-cluster (or inter-cell) interferers obtained via simulations. For\ndownlink NOMA, we derive closed-form solutions for the moments of the CSP,\nsuccess (or coverage) probability, average local delay, and meta distribution\nfor the users. As an application of the developed analytical framework, we use\nthe closed-form expressions to optimize the power allocations for downlink NOMA\nusers in order to maximize the success probability of a given NOMA user with\nand without latency constraints. Closed-form optimal solutions for the transmit\npowers are obtained for two-user NOMA scenario. We note that maximizing the\nsuccess probability with latency constraints can significantly impact the\noptimal power solutions for low SIR thresholds and favour orthogonal multiple\naccess (OMA). \n\n"}
{"id": "1804.02711", "contents": "Title: Decomposition and Completion of Sum-of-Squares Matrices Abstract: This paper introduces a notion of decomposition and completion of\nsum-of-squares (SOS) matrices. We show that a subset of sparse SOS matrices\nwith chordal sparsity patterns can be equivalently decomposed into a sum of\nmultiple SOS matrices that are nonzero only on a principal submatrix. Also, the\ncompletion of an SOS matrix is equivalent to a set of SOS conditions on its\nprincipal submatrices and a consistency condition on the Gram representation of\nthe principal submatrices. These results are partial extensions of chordal\ndecomposition and completion of scalar matrices to matrices with polynomial\nentries. We apply the SOS decomposition result to exploit sparsity in\nmatrix-valued SOS programs. Numerical results demonstrate the high potential of\nthis approach for solving large-scale sparse matrix-valued SOS programs. \n\n"}
{"id": "1804.03295", "contents": "Title: MmWave MU-MIMO for Aerial Networks Abstract: Millimeter wave offers high bandwidth for air-to-air (A2A) communication. In\nthis paper, we evaluate the rate performance of a multiuser MIMO (MU-MIMO)\nconfiguration where several aircraft communicate with a central hub. We\nconsider a hybrid subarray architecture, single path channels, and realistic\natmospheric attenuation effects. We propose a mathematical framework for the\nanalysis of millimeter wave (mmWave) MU-MIMO networks. Via Monte Carlo\nsimulation, we demonstrate that mmWave is a promising technology for delivering\ngigabit connectivity in next-generation aerial networks. \n\n"}
{"id": "1804.04464", "contents": "Title: Social Promoter Score (SPS) and Review Network: A Method and a Tool for\n  Predicting Financial Health of an Online Shopping Brand Abstract: The conventional way of summarizing ratings or sentiment of reviews of\ncustomers on products of an online shopping brand are not sufficient to\nevaluate the financial health of that brand. It overlooks the social standing\nand influence of individual customers. In this paper, we have proposed a tool\nnamed as Review Network for measuring the influence of customers in online\nmerchandise sites like Amazon.com. Using this measured influence, we have\nproposed a method that evaluates loyalty of customers of a brand based on their\nratings and sentiments of their reviews collected from online merchandise\nsites. Review network of a brand is built from all the reviews of all the\nproducts from that brand where nodes are customers and an edge is created if a\ncustomer becomes a potential reader of a review written by another customer.\nThe centrality of a customer in that review network represents her influence.\nOur proposed method named as Social Promoter Score combines loyalty and\ncentrality of all customers of a brand. We have compared our method with a\nbaseline approach based on the concept of Net Promoter Score . We have applied\nSocial Promoter Score on Amazon.com review data set of some well-known brands.\nResults show that Social Promoter Score predicts financial health of a brand in\nterms of future sales much better than baseline method. We have noticed that in\ngeneral effects of Social Promoter Score reflect on the product sales in one to\nfive months. \n\n"}
{"id": "1804.04529", "contents": "Title: Online convex optimization and no-regret learning: Algorithms,\n  guarantees and applications Abstract: Spurred by the enthusiasm surrounding the \"Big Data\" paradigm, the\nmathematical and algorithmic tools of online optimization have found widespread\nuse in problems where the trade-off between data exploration and exploitation\nplays a predominant role. This trade-off is of particular importance to several\nbranches and applications of signal processing, such as data mining,\nstatistical inference, multimedia indexing and wireless communications (to name\nbut a few). With this in mind, the aim of this tutorial paper is to provide a\ngentle introduction to online optimization and learning algorithms that are\nasymptotically optimal in hindsight - i.e., they approach the performance of a\nvirtual algorithm with unlimited computational power and full knowledge of the\nfuture, a property known as no-regret. Particular attention is devoted to\nidentifying the algorithms' theoretical performance guarantees and to establish\nlinks with classic optimization paradigms (both static and stochastic). To\nallow a better understanding of this toolbox, we provide several examples\nthroughout the tutorial ranging from metric learning to wireless resource\nallocation problems. \n\n"}
{"id": "1804.04846", "contents": "Title: Robust 1-Bit Compressed Sensing via Hinge Loss Minimization Abstract: This work theoretically studies the problem of estimating a structured\nhigh-dimensional signal $x_0 \\in \\mathbb{R}^n$ from noisy $1$-bit Gaussian\nmeasurements. Our recovery approach is based on a simple convex program which\nuses the hinge loss function as data fidelity term. While such a risk\nminimization strategy is very natural to learn binary output models, such as in\nclassification, its capacity to estimate a specific signal vector is largely\nunexplored. A major difficulty is that the hinge loss is just piecewise linear,\nso that its \"curvature energy\" is concentrated in a single point. This is\nsubstantially different from other popular loss functions considered in signal\nestimation, e.g., the square or logistic loss, which are at least locally\nstrongly convex. It is therefore somewhat unexpected that we can still prove\nvery similar types of recovery guarantees for the hinge loss estimator, even in\nthe presence of strong noise. More specifically, our non-asymptotic error\nbounds show that stable and robust reconstruction of $x_0$ can be achieved with\nthe optimal oversampling rate $O(m^{-1/2})$ in terms of the number of\nmeasurements $m$. Moreover, we permit a wide class of structural assumptions on\nthe ground truth signal, in the sense that $x_0$ can belong to an arbitrary\nbounded convex set $K \\subset \\mathbb{R}^n$. The proofs of our main results\nrely on some recent advances in statistical learning theory due to Mendelson.\nIn particular, we invoke an adapted version of Mendelson's small ball method\nthat allows us to establish a quadratic lower bound on the error of the first\norder Taylor approximation of the empirical hinge loss function. \n\n"}
{"id": "1804.06653", "contents": "Title: Consensus Community Detection in Multilayer Networks using\n  Parameter-free Graph Pruning Abstract: The clustering ensemble paradigm has emerged as an effective tool for\ncommunity detection in multilayer networks, which allows for producing\nconsensus solutions that are designed to be more robust to the algorithmic\nselection and configuration bias. However, one limitation is related to the\ndependency on a co-association threshold that controls the degree of consensus\nin the community structure solution. The goal of this work is to overcome this\nlimitation with a new framework of ensemble-based multilayer community\ndetection, which features parameter-free identification of consensus\ncommunities based on generative models of graph pruning that are able to filter\nout noisy co-associations. We also present an enhanced version of the\nmodularity-driven ensemble-based multilayer community detection method, in\nwhich community memberships of nodes are reconsidered to optimize the\nmultilayer modularity of the consensus solution. Experimental evidence on\nreal-world networks confirms the beneficial effect of using model-based\nfiltering methods and also shows the superiority of the proposed method on\nstate-of-the-art multilayer community detection. \n\n"}
{"id": "1804.07368", "contents": "Title: Connectivity of Ad Hoc Wireless Networks with Node Faults Abstract: Connectivity of wireless sensor networks (WSNs) is a fundamental global\nproperty expected to be maintained even though some sensor nodes are at fault.\nIn this paper, we investigate the connectivity of random geometric graphs\n(RGGs) in the node fault model as an abstract model of ad hoc WSNs with\nunreliable nodes. In the model, each node is assumed to be stochastically at\nfault, i.e., removed from a graph. As a measure of reliability, the network\nbreakdown probability is then defined as the average probability that a\nresulting survival graph is disconnected over RGGs. We examine RGGs with\ngeneral connection functions as an extension of a conventional RGG model and\nprovide two mathematical analyses: the asymptotic analysis for infinite RGGs\nthat reveals the phase transition thresholds of connectivity, and the\nnon-asymptotic analysis for finite RGGs that provides a useful approximation\nformula. Those analyses are supported by numerical simulations in the Rayleigh\nSISO model reflecting a practical wireless channel. \n\n"}
{"id": "1804.07533", "contents": "Title: In defence of the simple: Euclidean distance for comparing complex\n  networks Abstract: To improve our understanding of connected systems, different tools derived\nfrom statistics, signal processing, information theory and statistical physics\nhave been developed in the last decade. Here, we will focus on the graph\ncomparison problem. Although different estimates exist to quantify how\ndifferent two networks are, an appropriate metric has not been proposed. Within\nthis framework we compare the performances of different networks distances (a\ntopological descriptor and a kernel-based approach) with the simple Euclidean\nmetric. We define the performance of metrics as the efficiency of distinguish\ntwo network's groups and the computing time. We evaluate these frameworks on\nsynthetic and real-world networks (functional connectomes from Alzheimer\npatients and healthy subjects), and we show that the Euclidean distance is the\none that efficiently captures networks differences in comparison to other\nproposals. We conclude that the operational use of complicated methods can be\njustified only by showing that they out-perform well-understood traditional\nstatistics, such as Euclidean metrics. \n\n"}
{"id": "1804.11136", "contents": "Title: Proof of spending in block-chain systems Abstract: We introduce proof of spending in a block-chain system. In this system the\nprobability for a node to create a legal block is proportional to the total\namount of coins it has spent in history. \n\n"}
{"id": "1805.00061", "contents": "Title: Machine Learning for Predictive On-Demand Deployment of UAVs for\n  Wireless Communications Abstract: In this paper, a novel machine learning (ML) framework is proposed for\nenabling a predictive, efficient deployment of unmanned aerial vehicles (UAVs),\nacting as aerial base stations (BSs), to provide on-demand wireless service to\ncellular users. In order to have a comprehensive analysis of cellular traffic,\nan ML framework based on a Gaussian mixture model (GMM) and a weighted\nexpectation maximization (WEM) algorithm is introduced to predict the potential\nnetwork congestion. Then, the optimal deployment of UAVs is studied to minimize\nthe transmit power needed to satisfy the communication demand of users in the\ndownlink, while also minimizing the power needed for UAV mobility, based on the\npredicted cellular traffic. To this end, first, the optimal partition of\nservice areas of each UAV is derived, based on a fairness principle. Next, the\noptimal location of each UAV that minimizes the total power consumption is\nderived. Simulation results show that the proposed ML approach can reduce the\nrequired downlink transmit power and improve the power efficiency by over 20%,\ncompared with an optimal deployment of UAVs with no ML prediction. \n\n"}
{"id": "1805.01219", "contents": "Title: Secure Routing with Power Optimization for Ad-hoc Networks Abstract: In this paper, we consider the problem of joint secure routing and transmit\npower optimization for a multi-hop ad-hoc network under the existence of\nrandomly distributed eavesdroppers following a Poisson point process (PPP).\nSecrecy messages are delivered from a source to a destination through a\nmulti-hop route connected by multiple legitimate relays in the network. Our\ngoal is to minimize the end-to-end connection outage probability (COP) under\nthe constraint of a secrecy outage probability (SOP) threshold, by optimizing\nthe routing path and the transmit power of each hop jointly. We show that the\nglobally optimal solution could be obtained by a two-step procedure where the\noptimal transmit power has a closed-form and the optimal routing path can be\nfound by Dijkstra's algorithm. Then a friendly jammer with multiple antennas is\napplied to enhance the secrecy performance further, and the optimal transmit\npower of the jammer and each hop of the selected route is investigated. This\nproblem can be solved optimally via an iterative outer polyblock approximation\nwith one-dimension search algorithm. Furthermore, suboptimal transmit powers\ncan be derived using the successive convex approximation (SCA) method with a\nlower complexity. Simulation results show the performance improvement of the\nproposed algorithms for both non-jamming and jamming scenarios, and also reveal\na non-trivial trade-off between the numbers of hops and the transmit power of\neach hop for secure routing. \n\n"}
{"id": "1805.01419", "contents": "Title: Dynamic Structural Similarity on Graphs Abstract: One way of characterizing the topological and structural properties of\nvertices and edges in a graph is by using structural similarity measures.\nMeasures like Cosine, Jaccard and Dice compute the similarities restricted to\nthe immediate neighborhood of the vertices, bypassing important structural\nproperties beyond the locality. Others measures, such as the generalized edge\nclustering coefficient, go beyond the locality but with high computational\ncomplexity, making them impractical in large-scale scenarios. In this paper we\npropose a novel similarity measure that determines the structural similarity by\ndynamically diffusing and capturing information beyond the locality. This new\nsimilarity is modeled as an iterated function that can be solved by fixed point\niteration in super-linear time and memory complexity, so it is able to analyze\nlarge-scale graphs. In order to show the advantages of the proposed similarity\nin the community detection task, we replace the local structural similarity\nused in the SCAN algorithm with the proposed similarity measure, improving the\nquality of the detected community structure and also reducing the sensitivity\nto the parameter $\\epsilon$ of the SCAN algorithm. \n\n"}
{"id": "1805.01892", "contents": "Title: Opinion modeling on social media and marketing aspects Abstract: We introduce and discuss kinetic models of opinion formation on social\nnetworks in which the distribution function depends on both the opinion and the\nconnectivity of the agents. The opinion formation model is subsequently coupled\nwith a kinetic model describing the spreading of popularity of a product on the\nweb through a social network. Numerical experiments on the underlying kinetic\nmodels show a good qualitative agreement with some measured trends of hashtags\non social media websites and illustrate how companies can take advantage of the\nnetwork structure to obtain at best the advertisement of their products. \n\n"}
{"id": "1805.02396", "contents": "Title: Billion-scale Network Embedding with Iterative Random Projection Abstract: Network embedding, which learns low-dimensional vector representation for\nnodes in the network, has attracted considerable research attention recently.\nHowever, the existing methods are incapable of handling billion-scale networks,\nbecause they are computationally expensive and, at the same time, difficult to\nbe accelerated by distributed computing schemes. To address these problems, we\npropose RandNE (Iterative Random Projection Network Embedding), a novel and\nsimple billion-scale network embedding method. Specifically, we propose a\nGaussian random projection approach to map the network into a low-dimensional\nembedding space while preserving the high-order proximities between nodes. To\nreduce the time complexity, we design an iterative projection procedure to\navoid the explicit calculation of the high-order proximities. Theoretical\nanalysis shows that our method is extremely efficient, and friendly to\ndistributed computing schemes without any communication cost in the\ncalculation. We also design a dynamic updating procedure which can efficiently\nincorporate the dynamic changes of the networks without error aggregation.\nExtensive experimental results demonstrate the efficiency and efficacy of\nRandNE over state-of-the-art methods in several tasks including network\nreconstruction, link prediction and node classification on multiple datasets\nwith different scales, ranging from thousands to billions of nodes and edges. \n\n"}
{"id": "1805.03260", "contents": "Title: Analysis of Relaxation Time in Random Walk with Jumps Abstract: We study the relaxation time in the random walk with jumps. The random walk\nwith jumps combines random walk based sampling with uniform node sampling and\nimproves the performance of network analysis and learning tasks. We derive\nvarious conditions under which the relaxation time decreases with the\nintroduction of jumps. \n\n"}
{"id": "1805.04920", "contents": "Title: Community Detection by Information Flow Simulation Abstract: Community detection remains an important problem in data mining, owing to the\nlack of scalable algorithms that exploit all aspects of available data - namely\nthe directionality of flow of information and the dynamics thereof. Most\nexisting methods use measures of connectedness in the graphical structure. In\nthis paper, we present a fast, scalable algorithm to detect communities in\ndirected, weighted graph representations of social networks by simulating flow\nof information through them. By design, our algorithm naturally handles\nundirected or unweighted networks as well. Our algorithm runs in\n$\\mathcal{O}(|E|)$ time, which is better than most existing work and uses\n$\\mathcal{O}(|E|)$ space and hence scales easily to very large datasets.\nFinally, we show that our algorithm outperforms the state-of-the-art Markov\nClustering Algorithm (MCL) in both accuracy and scalability on ground truth\ndata (in a number of cases, we can find communities in graphs too large for\nMCL). \n\n"}
{"id": "1805.05878", "contents": "Title: Naive Bayesian Learning in Social Networks Abstract: The DeGroot model of naive social learning assumes that agents only\ncommunicate scalar opinions. In practice, agents communicate not only their\nopinions, but their confidence in such opinions. We propose a model that\ncaptures this aspect of communication by incorporating signal informativeness\ninto the naive social learning scenario. Our proposed model captures aspects of\nboth Bayesian and naive learning. Agents in our model combine their neighbors'\nbeliefs using Bayes' rule, but the agents naively assume that their neighbors'\nbeliefs are independent. Depending on the initial beliefs, agents in our model\nmay not reach a consensus, but we show that the agents will reach a consensus\nunder mild continuity and boundedness assumptions on initial beliefs. This\neventual consensus can be explicitly computed in terms of each agent's\ncentrality and signal informativeness, allowing joint effects to be precisely\nunderstood. We apply our theory to adoption of new technology. In contrast to\nBanerjee et al. [2018], we show that information about a new technology can be\nseeded initially in a tightly clustered group without information loss, but\nonly if agents can expressively communicate their beliefs. \n\n"}
{"id": "1805.07038", "contents": "Title: Fundamental Tradeoffs in Communication and Trajectory Design for\n  UAV-Enabled Wireless Network Abstract: The use of unmanned aerial vehicles (UAVs) as aerial communication platforms\nis of high practical value for future wireless systems such as 5G, especially\nfor swift and on-demand deployment in temporary events and emergency\nsituations. Compared to traditional terrestrial base stations (BSs) in cellular\nnetwork, UAV-mounted aerial BSs possess stronger line-of-sight (LoS) links with\nthe ground users due to their high altitude as well as high and flexible\nmobility in three-dimensional (3D) space, which can be exploited to enhance the\ncommunication performance. On the other hand, unlike terrestrial BSs that have\nreliable power supply, aerial BSs in practice have limited on-board energy, but\nrequire significant propulsion energy to stay airborne and support high\nmobility. Motivated by the above new considerations, this article aims to\nrevisit some fundamental tradeoffs in UAV-enabled communication and trajectory\ndesign. Specifically, it is shown that communication throughput, delay, and\n(propulsion) energy consumption can be traded off among each other by adopting\ndifferent UAV trajectory designs, which sheds new light on their traditional\ntradeoffs in terrestrial communication. Promising directions for future\nresearch are also discussed. \n\n"}
{"id": "1805.08144", "contents": "Title: On Universally Good Flower Codes Abstract: For a Distributed Storage System (DSS), the \\textit{Fractional Repetition}\n(FR) code is a class in which replicas of encoded data packets are stored on\ndistributed chunk servers, where the encoding is done using the Maximum\nDistance Separable (MDS) code. The FR codes allow for exact uncoded repair with\nminimum repair bandwidth. In this paper, FR codes are constructed using finite\nbinary sequences. The condition for universally good FR codes is calculated on\nsuch sequences. For some sequences, the universally good FR codes are explored. \n\n"}
{"id": "1805.09315", "contents": "Title: A Graphical Measure of Aggregate Flexibility for Energy-Constrained\n  Distributed Resources Abstract: We consider the problem of dispatching a fleet of heterogeneous energy\nstorage units to provide grid support. Under the restriction that recharging is\nnot possible during the time frame of interest, we develop an aggregate measure\nof fleet flexibility with an intuitive graphical interpretation. This\nanalytical expression summarises the full set of demand traces that the fleet\ncan satisfy, and can be used for immediate and straightforward determination of\nthe feasibility of any service request. This representation therefore\nfacilitates a wide range of capability assessments, such as flexibility\ncomparisons between fleets or the determination of a fleet's ability to deliver\nancillary services. Examples are shown of applications to fleet flexibility\ncomparisons, signal feasibility assessment and the optimisation of ancillary\nservice provision. \n\n"}
{"id": "1805.09785", "contents": "Title: Entropy and mutual information in models of deep neural networks Abstract: We examine a class of deep learning models with a tractable method to compute\ninformation-theoretic quantities. Our contributions are three-fold: (i) We show\nhow entropies and mutual informations can be derived from heuristic statistical\nphysics methods, under the assumption that weight matrices are independent and\northogonally-invariant. (ii) We extend particular cases in which this result is\nknown to be rigorously exact by providing a proof for two-layers networks with\nGaussian random weights, using the recently introduced adaptive interpolation\nmethod. (iii) We propose an experiment framework with generative models of\nsynthetic datasets, on which we train deep neural networks with a weight\nconstraint designed so that the assumption in (i) is verified during learning.\nWe study the behavior of entropies and mutual informations throughout learning\nand conclude that, in the proposed setting, the relationship between\ncompression and generalization remains elusive. \n\n"}
{"id": "1805.12204", "contents": "Title: Contextual Centrality: Going Beyond Network Structures Abstract: Centrality is a fundamental network property which ranks nodes by their\nstructural importance. However, structural importance may not suffice to\npredict successful diffusions in a wide range of applications, such as\nword-of-mouth marketing and political campaigns. In particular, nodes with high\nstructural importance may contribute negatively to the objective of the\ndiffusion. To address this problem, we propose contextual centrality, which\nintegrates structural positions, the diffusion process, and, most importantly,\nnodal contributions to the objective of the diffusion. We perform an empirical\nanalysis of the adoption of microfinance in Indian villages and weather\ninsurance in Chinese villages. Results show that contextual centrality of the\nfirst-informed individuals has higher predictive power towards the eventual\nadoption outcomes than other standard centrality measures. Interestingly, when\nthe product of diffusion rate $p$ and the largest eigenvalue $\\lambda_1$ is\nlarger than one and diffusion period is long, contextual centrality linearly\nscales with eigenvector centrality. This approximation reveals that contextual\ncentrality identifies scenarios where a higher diffusion rate of individuals\nmay negatively influence the cascade payoff. Further simulations on the\nsynthetic and real-world networks show that contextual centrality has the\nadvantage of selecting an individual whose local neighborhood generates a high\ncascade payoff when $p \\lambda_1 < 1$. Under this condition, stronger homophily\nleads to higher cascade payoff. Our results suggest that contextual centrality\ncaptures more complicated dynamics on networks and has significant implications\nfor applications, such as information diffusion, viral marketing, and political\ncampaigns. \n\n"}
{"id": "1806.03204", "contents": "Title: Low-Complexity Multiuser QAM Detection for Uplink 1-bit Massive MIMO Abstract: This work studies multiuser detection for one-bit massive multiple-input\nmultiple-output (MIMO) systems in order to diminish the power consumption at\nthe base station (BS). A low-complexity near-maximum-likelihood (nML) multiuser\ndetection algorithm is designed, assuming that each BS antenna port is\nconnected with a pair of single-bit resolution analog-to-digital converters\n(ADCs) and each user equipment (UE) transmits symbols from a quadrature\namplitude modulation (QAM) constellation. First, a novel convex program is\nformulated as a convex surrogate of the ML detector and subsequently solved\nthrough an accelerated first-order method. Then, the solution of the convex\noptimization problem is harnessed to solve a refined combinatorial problem with\nreduced search space, requiring non-exponential complexity on the number of the\nUEs. Judicious simulation study corroborates the efficacy of the resulting\ntwo-phase detection algorithm. The proposed two-phase algorithm can achieve\nsymbol error rate (SER) performance close to the ML detector, with\nsignificantly reduced computation cost compared to the nML detection schemes in\nprior art. \n\n"}
{"id": "1806.03227", "contents": "Title: An Information-Percolation Bound for Spin Synchronization on General\n  Graphs Abstract: This paper considers the problem of reconstructing $n$ independent uniform\nspins $X_1,\\dots,X_n$ living on the vertices of an $n$-vertex graph $G$, by\nobserving their interactions on the edges of the graph. This captures instances\nof models such as (i) broadcasting on trees, (ii) block models, (iii)\nsynchronization on grids, (iv) spiked Wigner models. The paper gives an\nupper-bound on the mutual information between two vertices in terms of a bond\npercolation estimate. Namely, the information between two vertices' spins is\nbounded by the probability that these vertices are connected in a bond\npercolation model, where edges are opened with a probability that \"emulates\"\nthe edge-information. Both the information and the open-probability are based\non the Chi-squared mutual information. The main results allow us to re-derive\nknown results for information-theoretic non-reconstruction in models (i)-(iv),\nwith more direct or improved bounds in some cases, and to obtain new results,\nsuch as for a spiked Wigner model on grids. The main result also implies a new\nsubadditivity property for the Chi-squared mutual information for symmetric\nchannels and general graphs, extending the subadditivity property obtained by\nEvans-Kenyon-Peres-Schulman [EKPS00] for trees. \n\n"}
{"id": "1806.03364", "contents": "Title: Kronecker weights for instability analysis of Markov jump linear systems Abstract: In this paper, we analyze the instability of continuous-time Markov jump\nlinear systems. Although there exist several effective criteria for the\nstability of Markov jump linear systems, there is a lack of methodologies for\nverifying their instability. In this paper, we present a novel criterion for\nthe exponential mean instability of Markov jump linear systems. The main tool\nof our analysis is an auxiliary Markov jump linear system, which results from\ntaking the Kronecker products of the given system matrices and a set of\nappropriate matrix weights. We furthermore show that the problem of finding\nmatrix weights for tighter instability analysis can be transformed to the\nspectral optimization of an affine matrix family, which can be efficiently\nperformed by gradient-based non-smooth optimization algorithms. We confirm the\neffectiveness of the proposed methods by numerical examples. \n\n"}
{"id": "1806.04295", "contents": "Title: Integrated Semi-definite Relaxation Receiver for LDPC-Coded MIMO Systems Abstract: Semi-definite relaxation (SDR) detector has been demonstrated to be\nsuccessful in approaching maximum likelihood (ML) performance while the time\ncomplexity is only polynomial. We propose a new receiver jointly utilizing the\nforward error correction (FEC) code information in the SDR detection process.\nStrengthened by code constraints, the joint SDR detector substantially improves\nthe overall receiver performance. For further performance boost, the ML-SDR\ndetector is adapted to MAP-SDR detector by incorporating a priori information\nin the cost function. Under turbo principle, MAP-SDR detector takes in soft\ninformation from decoder and outputs extrinsic information with much improved\nreliability. We also propose a simplified SDR turbo receiver that solves only\none SDR per codeword instead of solving multiple SDRs in the iterative turbo\nprocessing. This scheme significantly reduces the time complexity of SDR turbo\nreceiver, while the error performance remains similar as before. In fact, our\nsimplified scheme is generic and it can be applied to any list-based iterative\nreceivers. \n\n"}
{"id": "1806.04367", "contents": "Title: Reversible Codes and Its Application to Reversible DNA Codes over\n  $F_{4^k}$ Abstract: Coterm polynomials are introduced by Oztas et al. [a novel approach for\nconstructing reversible codes and applications to DNA codes over the ring\n$F_2[u]/(u^{2k}-1)$, Finite Fields and Their Applications 46 (2017).pp.\n217-234.], which generate reversible codes. In this paper, we generalize the\ncoterm polynomials and construct some reversible codes which are optimal codes\nby using $m$-quasi-reciprocal polynomials. Moreover, we give a map from DNA\n$k$-bases to the elements of $F_{4^k}$, and construct reversible DNA codes over\n$F_{4^k}$ by DNA-$m$-quasi-reciprocal polynomials. \n\n"}
{"id": "1806.04753", "contents": "Title: On Coding for Cache-Aided Delivery of Dynamic Correlated Content Abstract: Cache-aided coded multicast leverages side information at wireless edge\ncaches to efficiently serve multiple unicast demands via common multicast\ntransmissions, leading to load reductions that are proportional to the\naggregate cache size. However, the increasingly dynamic, unpredictable, and\npersonalized nature of the content that users consume challenges the efficiency\nof existing caching-based solutions in which only exact content reuse is\nexplored. This paper generalizes the cache-aided coded multicast problem to\nspecifically account for the correlation among content files, such as, for\nexample, the one between updated versions of dynamic data. It is shown that (i)\ncaching content pieces based on their correlation with the rest of the library,\nand (ii) jointly compressing requested files using cached information as\nreferences during delivery, can provide load reductions that go beyond those\nachieved with existing schemes. This is accomplished via the design of a class\nof correlation-aware achievable schemes, shown to significantly outperform\nstate-of-the-art correlation-unaware solutions. Our results show that as we\nmove towards real-time and/or personalized media dominated services, where\nexact cache hits are almost non-existent but updates can exhibit high levels of\ncorrelation, network cached information can still be useful as references for\nnetwork compression. \n\n"}
{"id": "1806.06396", "contents": "Title: Robust Trajectory and Transmit Power Design for Secure UAV\n  Communications Abstract: Unmanned aerial vehicles (UAVs) are anticipated to be widely deployed in\nfuture wireless communications, due to their advantages of high mobility and\neasy deployment. However, the broadcast nature of air-to-ground line-of-sight\nwireless chan- nels brings a new challenge to the information security of UAV-\nground communication. This paper tackles such a challenge in the physical layer\nby exploiting the mobility of UAV via its trajectory design. We consider a\nUAV-ground communication system with multiple potential eavesdroppers on the\nground, where the information on the locations of the eavesdroppers is\nimperfect. We formulate an optimization problem which maximizes the average\nworst-case secrecy rate of the system by jointly designing the robust\ntrajectory and transmit power of the UAV over a given flight duration. The\nnon-convexity of the optimization problem and the imperfect location\ninformation of the eavesdroppers make the problem difficult to be solved\noptimally. We propose an iterative suboptimal algorithm to solve this problem\nefficiently by applying the block coordinate descent method, S-procedure, and\nsuccessive convex optimization method. Simulation results show that the\nproposed algorithm can improve the average worst-case secrecy rate\nsignificantly, as compared to two other benchmark algorithms without robust\ndesign. \n\n"}
{"id": "1806.07508", "contents": "Title: Reducibility and Computational Lower Bounds for Problems with Planted\n  Sparse Structure Abstract: The prototypical high-dimensional statistics problem entails finding a\nstructured signal in noise. Many of these problems exhibit an intriguing\nphenomenon: the amount of data needed by all known computationally efficient\nalgorithms far exceeds what is needed for inefficient algorithms that search\nover all possible structures. A line of work initiated by Berthet and Rigollet\nin 2013 has aimed to explain these statistical-computational gaps by reducing\nfrom conjecturally hard average-case problems in computer science. However, the\ndelicate nature of average-case reductions has limited the applicability of\nthis approach. In this work we introduce several new techniques to give a web\nof average-case reductions showing strong computational lower bounds based on\nthe planted clique conjecture using natural problems as intermediates. These\ninclude tight lower bounds for Planted Independent Set, Planted Dense Subgraph,\nSparse Spiked Wigner, Sparse PCA, a subgraph variant of the Stochastic Block\nModel and a biased variant of Sparse PCA. We also give algorithms matching our\nlower bounds and identify the information-theoretic limits of the models we\nconsider. \n\n"}
{"id": "1806.10903", "contents": "Title: On Low-Complexity Decoding of Product Codes for High-Throughput\n  Fiber-Optic Systems Abstract: We study low-complexity iterative decoding algorithms for product codes. We\nrevisit two algorithms recently proposed by the authors based on bounded\ndistance decoding (BDD) of the component codes that improve the performance of\nconventional iterative BDD (iBDD). We then propose a novel decoding algorithm\nthat is based on generalized minimum distance decoding of the component codes.\nThe proposed algorithm closes over 50% of the performance gap between iBDD and\nturbo product decoding (TPD) based on the Chase-Pyndiah algorithm. Moreover,\nthe algorithm only leads to a limited increase in complexity with respect to\niBDD and has significantly lower complexity than TPD. The studied algorithms\nare particularly interesting for high-throughput fiber-optic communications. \n\n"}
{"id": "1806.11416", "contents": "Title: Bounds on the Approximation Power of Feedforward Neural Networks Abstract: The approximation power of general feedforward neural networks with piecewise\nlinear activation functions is investigated. First, lower bounds on the size of\na network are established in terms of the approximation error and network depth\nand width. These bounds improve upon state-of-the-art bounds for certain\nclasses of functions, such as strongly convex functions. Second, an upper bound\nis established on the difference of two neural networks with identical weights\nbut different activation functions. \n\n"}
{"id": "1807.00698", "contents": "Title: A simple proof of the discrete time geometric Pontryagin maximum\n  principle on smooth manifolds Abstract: We establish a geometric Pontryagin maximum principle for discrete time\noptimal control problems on finite dimensional smooth manifolds under the\nfollowing three types of constraints: a) constraints on the states pointwise in\ntime, b) constraints on the control actions pointwise in time, c) constraints\non the frequency spectrum of the optimal control trajectories. Our proof\nfollows, in spirit, the path to establish geometric versions of the Pontryagin\nmaximum principle on smooth manifolds indicated in [Cha11] in the context of\ncontinuous-time optimal control. \n\n"}
{"id": "1807.01251", "contents": "Title: Training behavior of deep neural network in frequency domain Abstract: Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization. \n\n"}
{"id": "1807.04848", "contents": "Title: Modeling and Analysis of D2D Millimeter-Wave Networks with Poisson\n  Cluster Processes Abstract: This paper investigates the performance of millimeter wave (mmWave)\ncommunications in clustered device-to-device (D2D) networks. The locations of\nD2D transceivers are modeled as a Poisson Cluster Process (PCP). In each\ncluster, devices are equipped with multiple antennas, and the active D2D\ntransmitter (D2D-Tx) utilizes mmWave to serve one of the proximate D2D\nreceivers (D2D-Rxs). Specifically, we introduce three user association\nstrategies: 1) Uniformly distributed D2D-Tx model; 2) Nearest D2D-Tx model; 3)\nClosest line-of-site (LOS) D2D-Tx model. To characterize the performance of the\nconsidered scenarios, we derive new analytical expressions for the coverage\nprobability and area spectral efficiency (ASE). Additionally, in order to\nefficiently illustrating the general trends of our system, a closed-form lower\nbound for the special case interfered by intra-cluster LOS links is derived. We\nprovide Monte Carlo simulations to corroborate the theoretical results and show\nthat: 1) The coverage probability is mainly affected by the intra-cluster\ninterference with LOS links; 2) There exists an optimum number of\nsimultaneously active D2D-Txs in each cluster for maximizing ASE; and 3)\nClosest LOS model outperforms the other two scenarios but at the cost of extra\nsystem overhead. \n\n"}
{"id": "1807.05306", "contents": "Title: Generative Adversarial Privacy Abstract: We present a data-driven framework called generative adversarial privacy\n(GAP). Inspired by recent advancements in generative adversarial networks\n(GANs), GAP allows the data holder to learn the privatization mechanism\ndirectly from the data. Under GAP, finding the optimal privacy mechanism is\nformulated as a constrained minimax game between a privatizer and an adversary.\nWe show that for appropriately chosen adversarial loss functions, GAP provides\nprivacy guarantees against strong information-theoretic adversaries. We also\nevaluate GAP's performance on the GENKI face database. \n\n"}
{"id": "1807.06143", "contents": "Title: Quickest Detection of Dynamic Events in Networks Abstract: The problem of quickest detection of dynamic events in networks is studied.\nAt some unknown time, an event occurs, and a number of nodes in the network are\naffected by the event, in that they undergo a change in the statistics of their\nobservations. It is assumed that the event is dynamic, in that it can propagate\nalong the edges in the network, and affect more and more nodes with time. The\nevent propagation dynamics is assumed to be unknown. The goal is to design a\nsequential algorithm that can detect a \"significant\" event, i.e., when the\nevent has affected no fewer than $\\eta$ nodes, as quickly as possible, while\ncontrolling the false alarm rate. Fully connected networks are studied first,\nand the results are then extended to arbitrarily connected networks. The\ndesigned algorithms are shown to be adaptive to the unknown propagation\ndynamics, and their first-order asymptotic optimality is demonstrated as the\nfalse alarm rate goes to zero. The algorithms can be implemented with linear\ncomputational complexity in the network size at each time step, which is\ncritical for online implementation. Numerical simulations are provided to\nvalidate the theoretical results. \n\n"}
{"id": "1807.10617", "contents": "Title: Temporal connectivity in finite networks with non-uniform measures Abstract: Soft Random Geometric Graphs (SRGGs) have been widely applied to various\nmodels including those of wireless sensor, communication, social and neural\nnetworks. SRGGs are constructed by randomly placing nodes in some space and\nmaking pairwise links probabilistically using a connection function that is\nsystem specific and usually decays with distance. In this paper we focus on the\napplication of SRGGs to wireless communication networks where information is\nrelayed in a multi hop fashion, although the analysis is more general and can\nbe applied elsewhere by using different distributions of nodes and/or\nconnection functions. We adopt a general non-uniform density which can model\nthe stationary distribution of different mobility models, with the interesting\ncase being when the density goes to zero along the boundaries. The global\nconnectivity properties of these non-uniform networks are likely to be\ndetermined by highly isolated nodes, where isolation can be caused by the\nspatial distribution or the local geometry (boundaries). We extend the analysis\nto temporal-spatial networks where we fix the underlying non-uniform\ndistribution of points and the dynamics are caused by the temporal variations\nin the link set, and explore the probability a node near the corner is isolated\nat time $T$. This work allows for insight into how non-uniformity (caused by\nmobility) and boundaries impact the connectivity features of temporal-spatial\nnetworks. We provide a simple method for approximating these probabilities for\na range of different connection functions and verify them against simulations.\nBoundary nodes are numerically shown to dominate the connectivity properties of\nthese finite networks with non-uniform measure. \n\n"}
{"id": "1808.00554", "contents": "Title: Traj2User: exploiting embeddings for computing similarity of users\n  mobile behavior Abstract: Semantic trajectories are high level representations of user movements where\nseveral aspects related to the movement context are represented as\nheterogeneous textual labels. With the objective of finding a meaningful\nsimilarity measure for semantically enriched trajectories, we propose\nTraj2User, a Word2Vec-inspired method for the generation of a vector\nrepresentation of user movements as user embeddings. Traj2User uses simple\nrepresentations of trajectories and delegates the definition of the similarity\nmodel to the learning process of the network. Preliminary results show that\nTraj2User is able to generate effective user embeddings. \n\n"}
{"id": "1808.00714", "contents": "Title: Improved Quantum Information Set Decoding Abstract: In this paper we present quantum information set decoding (ISD) algorithms\nfor binary linear codes. First, we give an alternative view on the quantum walk\nbased algorithms proposed by Kachigar and Tillich (PQCrypto'17). It is more\ngeneral and allows to consider any ISD algorithm that has certain properties.\nThe algorithms of May-Meuer-Thomae and Becker-Jeux-May-Meuer satisfy these\nproperties. Second, we translate May-Ozerov Near Neighbour technique\n(Eurocrypt'15) to an `update-and-query' language more suitable for the quantum\nwalk framework. First, this re-interpretation makes possible to analyse a\nbroader class of algorithms and, second, allows us to combine Near Neighbour\nsearch with the quantum walk framework and use both techniques to give a\nquantum version of Dumer's ISD with Near Neighbour. \n\n"}
{"id": "1808.00810", "contents": "Title: Identifying exogenous and endogenous activity in social media Abstract: The occurrence of new events in a system is typically driven by external\ncauses and by previous events taking place inside the system. This is a general\nstatement, applying to a range of situations including, more recently, to the\nactivity of users in Online social networks (OSNs). Here we develop a method\nfor extracting from a series of posting times the relative contributions of\nexogenous, e.g. news media, and endogenous, e.g. information cascade. The\nmethod is based on the fitting of a generalized linear model (GLM) equipped\nwith a self-excitation mechanism. We test the method with synthetic data\ngenerated by a nonlinear Hawkes process, and apply it to a real time series of\ntweets with a given hashtag. In the empirical dataset, the estimated\ncontributions of exogenous and endogenous volumes are close to the amounts of\noriginal tweets and retweets respectively. We conclude by discussing the\npossible applications of the method, for instance in online marketing. \n\n"}
{"id": "1808.00857", "contents": "Title: Mobile Positioning in Multipath Environments: a Pseudo Maximum\n  Likelihood approach Abstract: The problem of mobile position estimation in multipath scenarios is\naddressed. A low-complexity, fully-adaptive algorithm is proposed, based on the\npseudo maximum likelihood approach. The processing is done exclusively on-board\nat the mobile node by exploiting narrowband downlink radio signals. The\nproposed algorithm is able to estimate via adaptive beamforming (with spatial\nsmoothing) the optimal projection matrices that maximize the likelihood; in\naddition, it can associate the line-of-sight over the trajectory, hence\nachieving an integration gain. The performance assessment shows that the\nproposed algorithm is very effective in (even severe) multipath conditions,\noutperforming natural competitors also when the number of antennas and\nsnapshots is kept at the theoretical minimum. \n\n"}
{"id": "1808.01013", "contents": "Title: Two-Stage Analog Combining in Hybrid Beamforming Systems with\n  Low-Resolution ADCs Abstract: In this paper, we investigate hybrid analog/digital beamforming for\nmultiple-input multiple-output (MIMO) systems with low-resolution\nanalog-to-digital converters (ADCs) for millimeter wave (mmWave)\ncommunications. In the receiver, we propose to split the analog combining\nsubsystem into a channel gain aggregation stage followed by a spreading stage.\nBoth stages use phase shifters. Our goal is to design the two-stage analog\ncombiner to optimize mutual information (MI) between the transmitted and\nquantized signals by effectively managing quantization error. To this end, we\nformulate an unconstrained MI maximization problem without a constant modulus\nconstraint on analog combiners, and derive a two-stage analog combining\nsolution. The solution achieves the optimal scaling law with respect to the\nnumber of radio frequency chains and maximizes the MI for homogeneous singular\nvalues of a MIMO channel. We further develop a two-stage analog combining\nalgorithm to implement the derived solution for mmWave channels. By decoupling\nchannel gain aggregation and spreading functions from the derived solution, the\nproposed algorithm implements the two functions by using array response vectors\nand a discrete Fourier transform matrix under the constant modulus constraint\non each matrix element. Therefore, the proposed algorithm provides a near\noptimal solution for the unconstrained problem, whereas conventional hybrid\napproaches offer a near optimal solution only for a constrained problem. The\nclosed-form approximation of the ergodic rate is derived for the algorithm,\nshowing that a practical digital combiner with two-stage analog combining also\nachieves the optimal scaling law. Simulation results validate the algorithm\nperformance and the derived ergodic rate. \n\n"}
{"id": "1808.02243", "contents": "Title: Modularity of Erd\\H{o}s-R\\'enyi random graphs Abstract: For a given graph $G$, each partition of the vertices has a modularity score,\nwith higher values indicating that the partition better captures community\nstructure in $G$. The modularity $q^*(G)$ of the graph $G$ is defined to be the\nmaximum over all vertex partitions of the modularity score, and satisfies\n$0\\leq q^*(G) < 1$. Modularity is at the heart of the most popular algorithms\nfor community detection.\n  We investigate the behaviour of the modularity of the Erd\\H{o}s-R\\'enyi\nrandom graph $G_{n,p}$ with $n$ vertices and edge-probability $p$. Two key\nfindings are that the modularity is $1+o(1)$ with high probability (whp) for\n$np$ up to $1+o(1)$ and no further; and when $np \\geq 1$ and $p$ is bounded\nbelow 1, it has order $(np)^{-1/2}$ whp, in accord with a conjecture by\nReichardt and Bornholdt in 2006.\n  We also show that the modularity of a graph is robust to changes in a few\nedges, in contrast to the sensitivity of optimal vertex partitions. \n\n"}
{"id": "1808.03929", "contents": "Title: Discrete-time Risk-sensitive Mean-field Games Abstract: In this paper, we study a class of discrete-time mean-field games under the\ninfinite-horizon risk-sensitive discounted-cost optimality criterion.\nRisk-sensitivity is introduced for each agent (player) via an exponential\nutility function. In this game model, each agent is coupled with the rest of\nthe population through the empirical distribution of the states, which affects\nboth the agent's individual cost and its state dynamics. Under mild\nassumptions, we establish the existence of a mean-field equilibrium in the\ninfinite-population limit as the number of agents ($N$) goes to infinity, and\nthen show that the policy obtained from the mean-field equilibrium constitutes\nan approximate Nash equilibrium when $N$ is sufficiently large. \n\n"}
{"id": "1808.05035", "contents": "Title: Structural transition in social networks: The role of homophily Abstract: We introduce a model for the formation of social networks, which takes into\naccount the homophily or the tendency of individuals to associate and bond with\nsimilar others, and the mechanisms of global and local attachment as well as\ntie reinforcement due to social interactions between people. We generalize the\nweighted social network model such that the nodes or individuals have $F$\nfeatures and each feature can have $q$ different values. Here the tendency for\nthe tie formation between two individuals due to the overlap in their features\nrepresents homophily. We find a phase transition as a function of $F$ or $q$,\nresulting in a phase diagram. For fixed $q$ and as a function of $F$ the system\nshows two phases separated at $F_c$. For $F{<}F_c$ large, homogeneous, and well\nseparated communities can be identified within which the features match almost\nperfectly (segregated phase). When $F$ becomes larger than $F_c$, the nodes\nstart to belong to several communities and within a community the features\nmatch only partially (overlapping phase). Several quantities reflect this\ntransition, including the average degree, clustering coefficient, feature\noverlap, and the number of communities per node. We also make an attempt to\ninterpret these results in terms of observations on social behavior of humans. \n\n"}
{"id": "1808.05859", "contents": "Title: Efficient sampling of spreading processes on complex networks using a\n  composition and rejection algorithm Abstract: Efficient stochastic simulation algorithms are of paramount importance to the\nstudy of spreading phenomena on complex networks. Using insights and analytical\nresults from network science, we discuss how the structure of contacts affects\nthe efficiency of current algorithms. We show that algorithms believed to\nrequire $\\mathcal{O}(\\log N)$ or even $\\mathcal{O}(1)$ operations per\nupdate---where $N$ is the number of nodes---display instead a polynomial\nscaling for networks that are either dense or sparse and heterogeneous. This\nsignificantly affects the required computation time for simulations on large\nnetworks. To circumvent the issue, we propose a node-based method combined with\na composition and rejection algorithm, a sampling scheme that has an\naverage-case complexity of $\\mathcal{O} [\\log(\\log N)]$ per update for general\nnetworks. This systematic approach is first set-up for Markovian dynamics, but\ncan also be adapted to a number of non-Markovian processes and can enhance\nconsiderably the study of a wide range of dynamics on networks. \n\n"}
{"id": "1808.06509", "contents": "Title: Optimized Rate-Adaptive Protograph-Based LDPC Codes for Source Coding\n  with Side Information Abstract: This paper considers the problem of source coding with side information at\nthe decoder, also called Slepian-Wolf source coding scheme. In practical\napplications of this coding scheme, the statistical relation between the source\nand the side information can vary from one data transmission to another, and\nthere is a need to adapt the coding rate depending on the current statistical\nrelation. In this paper, we propose a novel rate-adaptive code construction\nbased on LDPC codes for the Slepian-Wolf source coding scheme. The proposed\ncode design method allows to optimize the code degree distributions at all the\nconsidered rates, while minimizing the amount of short cycles in the parity\ncheck matrices at all rates. Simulation results show that the proposed method\ngreatly reduces the source coding rate compared to the standard LDPCA solution. \n\n"}
{"id": "1808.07857", "contents": "Title: Probabilistic Multilayer Networks Abstract: Here we introduce probabilistic weighted and unweighted multilayer networks\nas derived from information theoretical correlation measures on large\nmultidimensional datasets. We present the fundamentals of the formal\napplication of probabilistic inference on problems embedded in multilayered\nenvironments, providing examples taken from the analysis of biological and\nsocial systems: cancer genomics and drug-related violence. \n\n"}
{"id": "1808.07859", "contents": "Title: Entanglement Availability Differentiation Service for the Quantum\n  Internet Abstract: A fundamental concept of the quantum Internet is quantum entanglement. In a\nquantum Internet scenario where the legal users of the network have different\npriority levels or where a differentiation of entanglement availability between\nthe users is a necessity, an entanglement availability service is essential.\nHere we define the entanglement availability differentiation (EAD) service for\nthe quantum Internet. In the proposed EAD framework, the differentiation is\neither made in the amount of entanglement with respect to the relative entropy\nof entanglement associated with the legal users, or in the time domain with\nrespect to the amount of time that is required to establish a maximally\nentangled system between the legal parties. The framework provides an efficient\nand easily-implementable solution for the differentiation of entanglement\navailability in experimental quantum networking scenarios. \n\n"}
{"id": "1808.08627", "contents": "Title: Multi-Level Network Embedding with Boosted Low-Rank Matrix Approximation Abstract: As opposed to manual feature engineering which is tedious and difficult to\nscale, network representation learning has attracted a surge of research\ninterests as it automates the process of feature learning on graphs. The\nlearned low-dimensional node vector representation is generalizable and eases\nthe knowledge discovery process on graphs by enabling various off-the-shelf\nmachine learning tools to be directly applied. Recent research has shown that\nthe past decade of network embedding approaches either explicitly factorize a\ncarefully designed matrix to obtain the low-dimensional node vector\nrepresentation or are closely related to implicit matrix factorization, with\nthe fundamental assumption that the factorized node connectivity matrix is\nlow-rank. Nonetheless, the global low-rank assumption does not necessarily hold\nespecially when the factorized matrix encodes complex node interactions, and\nthe resultant single low-rank embedding matrix is insufficient to capture all\nthe observed connectivity patterns. In this regard, we propose a novel\nmulti-level network embedding framework BoostNE, which can learn multiple\nnetwork embedding representations of different granularity from coarse to fine\nwithout imposing the prevalent global low-rank assumption. The proposed BoostNE\nmethod is also in line with the successful gradient boosting method in ensemble\nlearning as multiple weak embeddings lead to a stronger and more effective one.\nWe assess the effectiveness of the proposed BoostNE framework by comparing it\nwith existing state-of-the-art network embedding methods on various datasets,\nand the experimental results corroborate the superiority of the proposed\nBoostNE network embedding framework. \n\n"}
{"id": "1808.09376", "contents": "Title: Mining (maximal) span-cores from temporal networks Abstract: When analyzing temporal networks, a fundamental task is the identification of\ndense structures (i.e., groups of vertices that exhibit a large number of\nlinks), together with their temporal span (i.e., the period of time for which\nthe high density holds). We tackle this task by introducing a notion of\ntemporal core decomposition where each core is associated with its span: we\ncall such cores span-cores.\n  As the total number of time intervals is quadratic in the size of the\ntemporal domain $T$ under analysis, the total number of span-cores is quadratic\nin $|T|$ as well. Our first contribution is an algorithm that, by exploiting\ncontainment properties among span-cores, computes all the span-cores\nefficiently. Then, we focus on the problem of finding only the maximal\nspan-cores, i.e., span-cores that are not dominated by any other span-core by\nboth the coreness property and the span. We devise a very efficient algorithm\nthat exploits theoretical findings on the maximality condition to directly\ncompute the maximal ones without computing all span-cores.\n  Experimentation on several real-world temporal networks confirms the\nefficiency and scalability of our methods. Applications on temporal networks,\ngathered by a proximity-sensing infrastructure recording face-to-face\ninteractions in schools, highlight the relevance of the notion of (maximal)\nspan-core in analyzing social dynamics and detecting/correcting anomalies in\nthe data. \n\n"}
{"id": "1808.09633", "contents": "Title: Improved Semantic-Aware Network Embedding with Fine-Grained Word\n  Alignment Abstract: Network embeddings, which learn low-dimensional representations for each\nvertex in a large-scale network, have received considerable attention in recent\nyears. For a wide range of applications, vertices in a network are typically\naccompanied by rich textual information such as user profiles, paper abstracts,\netc. We propose to incorporate semantic features into network embeddings by\nmatching important words between text sequences for all pairs of vertices. We\nintroduce a word-by-word alignment framework that measures the compatibility of\nembeddings between word pairs, and then adaptively accumulates these alignment\nfeatures with a simple yet effective aggregation function. In experiments, we\nevaluate the proposed framework on three real-world benchmarks for downstream\ntasks, including link prediction and multi-label vertex classification. Results\ndemonstrate that our model outperforms state-of-the-art network embedding\nmethods by a large margin. \n\n"}
{"id": "1808.09775", "contents": "Title: Optimal Linear Broadcast Rates of the Two-Sender Unicast Index Coding\n  Problem with Fully-Participated Interactions Abstract: The two-sender unicast index coding problem consists of finding optimal coded\ntransmissions from the two senders which collectively know the messages\ndemanded by all the receivers. Each receiver demands a unique message. One\nimportant class of this problem consists of the message sets at the senders and\nthe side-information at the receivers satisfying \\emph{fully-participated\ninteractions}. This paper provides optimal linear broadcast rates and\ncorresponding code constructions for all the possible cases of the two-sender\nunicast index coding problem with fully-participated interactions. The optimal\nlinear broadcast rate and the corresponding code for the two-sender problem are\ngiven in terms of those of the three single-sender unicast problems associated\nwith the two-sender problem. Optimal linear broadcast rates of two-sender\nproblems with fully-participated interactions provide lower bounds for the\noptimal linear broadcast rates of many related two-sender problems with\n\\emph{partially-participated interactions}. Proof techniques used to obtain the\nresults for the two-sender problem are shown to be useful in obtaining the\nresults for some cases of the multi-sender unicast index coding problem. \n\n"}
{"id": "1808.10716", "contents": "Title: Influence Dynamics and Consensus in an Opinion-Neighborhood based\n  Modified Vicsek-like Social Network Abstract: We propose a modified Vicsek-like model to study influence dynamics and\nopinion formation in social networks. We work on the premise that opinions of\nmembers of a group may be considered to be analogous to the direction of motion\nof a particle in space. The opinions are susceptible to change under the\ninfluence of familiar individuals who maintain similar beliefs. This is unlike\nthe bounded-confidence models which solely rely on interactions based on\ncloseness of opinions. The influence network evolves either when similar-minded\nindividuals acquaint or when they fall out over their beliefs. This yields an\nadaptive network to which are assigned dynamic centrality scores and varying\ninfluence strengths. A mix of individuals - rigid and flexible - is assumed to\nconstitute groups - liberal and conservative. We analyse emergent group\nbehaviours subject to different initial conditions, agent types, their\ndensities and tolerances. The model accurately predicts the role of rigid\nagents in hampering consensus. Also, a few structural properties of the dynamic\nnetwork, which result as a consequence of the proposed model have been\nestablished. \n\n"}
{"id": "1809.00409", "contents": "Title: Global Network Prediction from Local Node Dynamics Abstract: The study of dynamical systems on networks, describing complex interactive\nprocesses, provides insight into how network structure affects global\nbehaviour. Yet many methods for network dynamics fail to cope with large or\npartially-known networks, a ubiquitous situation in real-world applications.\nHere we propose a localised method, applicable to a broad class of dynamical\nmodels on networks, whereby individual nodes monitor and store the evolution of\ntheir own state and use these values to approximate, via a simple computation,\ntheir own steady state solution. Hence the nodes predict their own final state\nwithout actually reaching it. Furthermore, the localised formulation enables\nnodes to compute global network metrics without knowledge of the full network\nstructure. The method can be used to compute global rankings in the network\nfrom local information; to detect community detection from fast, local\ntransient dynamics; and to identify key nodes that compute global network\nmetrics ahead of others. We illustrate some of the applications of the\nalgorithm by efficiently performing web-page ranking for a large internet\nnetwork and identifying the dynamic roles of inter-neurons in the C. Elegans\nneural network. The mathematical formulation is simple, widely applicable and\neasily scalable to real-world datasets suggesting how local computation can\nprovide an approach to the study of large-scale network dynamics. \n\n"}
{"id": "1809.00781", "contents": "Title: Matrix Infinitely Divisible Series: Tail Inequalities and Their\n  Applications Abstract: In this paper, we study tail inequalities of the largest eigenvalue of a\nmatrix infinitely divisible (i.d.) series, which is a finite sum of fixed\nmatrices weighted by i.d. random variables. We obtain several types of tail\ninequalities, including Bennett-type and Bernstein-type inequalities. This\nallows us to further bound the expectation of the spectral norm of a matrix\ni.d. series. Moreover, by developing a new lower-bound function for\n$Q(s)=(s+1)\\log(s+1)-s$ that appears in the Bennett-type inequality, we derive\na tighter tail inequality of the largest eigenvalue of the matrix i.d. series\nthan the Bernstein-type inequality when the matrix dimension is high. The\nresulting lower-bound function is of independent interest and can improve any\nBennett-type concentration inequality that involves the function $Q(s)$. The\nclass of i.d. probability distributions is large and includes Gaussian and\nPoisson distributions, among many others. Therefore, our results encompass the\nexisting work \\cite{tropp2012user} on matrix Gaussian series as a special case.\nLastly, we show that the tail inequalities of a matrix i.d. series have\napplications in several optimization problems including the chance constrained\noptimization problem and the quadratic optimization problem with orthogonality\nconstraints. In addition, we also use the resulting tail bounds to show that\nrandom matrices constructed from i.d. random variables satisfy the restricted\nisometry property (RIP) when it acts as a measurement matrix in compressed\nsensing. \n\n"}
{"id": "1809.01286", "contents": "Title: FakeNewsNet: A Data Repository with News Content, Social Context and\n  Spatialtemporal Information for Studying Fake News on Social Media Abstract: Social media has become a popular means for people to consume news.\nMeanwhile, it also enables the wide dissemination of fake news, i.e., news with\nintentionally false information, which brings significant negative effects to\nthe society. Thus, fake news detection is attracting increasing attention.\nHowever, fake news detection is a non-trivial task, which requires multi-source\ninformation such as news content, social context, and dynamic information.\nFirst, fake news is written to fool people, which makes it difficult to detect\nfake news simply based on news contents. In addition to news contents, we need\nto explore social contexts such as user engagements and social behaviors. For\nexample, a credible user's comment that \"this is a fake news\" is a strong\nsignal for detecting fake news. Second, dynamic information such as how fake\nnews and true news propagate and how users' opinions toward news pieces are\nvery important for extracting useful patterns for (early) fake news detection\nand intervention. Thus, comprehensive datasets which contain news content,\nsocial context, and dynamic information could facilitate fake news propagation,\ndetection, and mitigation; while to the best of our knowledge, existing\ndatasets only contains one or two aspects. Therefore, in this paper, to\nfacilitate fake news related researches, we provide a fake news data repository\nFakeNewsNet, which contains two comprehensive datasets that includes news\ncontent, social context, and dynamic information. We present a comprehensive\ndescription of datasets collection, demonstrate an exploratory analysis of this\ndata repository from different perspectives, and discuss the benefits of\nFakeNewsNet for potential applications on fake news study on social media. \n\n"}
{"id": "1809.01323", "contents": "Title: Joint Trajectory and Resource Allocation Design for UAV Communication\n  Systems Abstract: In this paper, we investigate resource allocation design for unmanned aerial\nvehicle (UAV)-enabled communication systems, where a UAV is dispatched to\nprovide communications to multiple user nodes. Our objective is to maximize the\ncommunication system throughput by jointly optimizing the subcarrier allocation\npolicy and the trajectory of the UAV, while taking into account the minimum\nrequired data rate for each user node, no-fly zones (NFZs), the maximum UAV\ncruising speed, and initial/final UAV locations. The design is formulated as a\nmixed integer non-convex optimization problem which is generally intractable.\nSubsequently, a computationally-efficient iterative algorithm is proposed to\nobtain a locally optimal solution. Simulation results illustrate that the\nperformance of the proposed iterative algorithm approaches closely to that of\nthe system without NFZ. In addition, the proposed algorithm can achieve a\nsignificant throughput gain compared to various benchmark schemes. \n\n"}
{"id": "1809.01423", "contents": "Title: Intelligent Reflecting Surface Enhanced Wireless Network: Joint Active\n  and Passive Beamforming Design Abstract: Intelligent reflecting surface (IRS) is envisioned to have abundant\napplications in future wireless networks by smartly reconfiguring the signal\npropagation for performance enhancement. Specifically, an IRS consists of a\nlarge number of low-cost passive elements each reflecting the incident signal\nwith a certain phase shift to collaboratively achieve beamforming and suppress\ninterference at one or more designated receivers. In this paper, we study an\nIRS-enhanced point-to-point multiple-input single-output (MISO) wireless system\nwhere one IRS is deployed to assist in the communication from a multi-antenna\naccess point (AP) to a single-antenna user. As a result, the user\nsimultaneously receives the signal sent directly from the AP as well as that\nreflected by the IRS. We aim to maximize the total received signal power at the\nuser by jointly optimizing the (active) transmit beamforming at the AP and\n(passive) reflect beamforming by the phase shifters at the IRS. We first\npropose a centralized algorithm based on the technique of semidefinite\nrelaxation (SDR) by assuming the global channel state information (CSI)\navailable at the IRS. Since the centralized implementation requires excessive\nchannel estimation and signal exchange overheads, we further propose a\nlow-complexity distributed algorithm where the AP and IRS independently adjust\nthe transmit beamforming and the phase shifts in an alternating manner until\nthe convergence is reached. Simulation results show that significant\nperformance gains can be achieved by the proposed algorithms as compared to\nbenchmark schemes. Moreover, it is verified that the IRS is able to drastically\nenhance the link quality and/or coverage over the conventional setup without\nthe IRS. \n\n"}
{"id": "1809.03608", "contents": "Title: Optimal Strategies for Disjunctive Sensing and Control Abstract: A disjunctive sensing and actuation problem is considered in which the\nactuators and sensors are prevented from operating together over any given time\nstep. This problem is motivated by practical applications in the area of\nspacecraft control. Assuming a linear system model with stochastic process\ndisturbance and measurement noise, a procedure to construct a periodic sequence\nthat ensures bounded states and estimation error covariance is described along\nwith supporting analysis results. The procedure is also extended to ensure\neventual satisfaction of probabilistic chance constraints on the state. The\nproposed scheme demonstrates good performance in simulations for spacecraft\nrelative motion control. \n\n"}
{"id": "1809.03898", "contents": "Title: Geometric Surface-Based Tracking Control of a Quadrotor UAV under\n  Actuator Constraints Abstract: This paper presents contributions on nonlinear tracking control systems for a\nquadrotor unmanned micro aerial vehicle. New controllers are proposed based on\nnonlinear surfaces composed by tracking errors that evolve directly on the\nnonlinear configuration manifold thus inherently including in the control\ndesign the nonlinear characteristics of the SE(3) configuration space. In\nparticular geometric surface-based controllers are developed, and through\nrigorous stability proofs they are shown to have desirable closed loop\nproperties that are almost global. A region of attraction, independent of the\nposition error, is produced and its effects are analyzed. A strategy allowing\nthe quadrotor to achieve precise attitude tracking while simultaneously\nfollowing a desired position command and complying to actuator constraints in a\ncomputationally inexpensive manner is derived. This important contribution\ndifferentiates this work from existing Geometric Nonlinear Control System\nsolutions (GNCSs) since the commanded thrusts can be realized by the majority\nof quadrotors produced by the industry. The new features of the proposed GNCSs\nare illustrated by numerical simulations of aggressive maneuvers and a\ncomparison with a GNCSs from the bibliography. \n\n"}
{"id": "1809.04565", "contents": "Title: Optimization-Based Bound Tightening using a Strengthened QC-Relaxation\n  of the Optimal Power Flow Problem Abstract: This article develops a strengthened convex quadratic convex (QC) relaxation\nof the AC Optimal Power Flow (AC-OPF) problem and presents an\noptimization-based bound-tightening (OBBT) algorithm to compute tight, feasible\nbounds on the voltage magnitude variables for each bus and the phase angle\ndifference variables for each branch in the network. Theoretical properties of\nthe strengthened QC relaxation that show its dominance over the other variants\nof the QC relaxation studied in the literature are also derived. The\neffectiveness of the strengthened QC relaxation is corroborated via extensive\nnumerical results on benchmark AC-OPF test networks. In particular, the results\ndemonstrate that the proposed relaxation consistently provides the tightest\nvariable bounds and optimality gaps with negligible impacts on runtime\nperformance. \n\n"}
{"id": "1809.04943", "contents": "Title: Optimal timescale for community detection in growing networks Abstract: Time-stamped data are increasingly available for many social, economic, and\ninformation systems that can be represented as networks growing with time. The\nWorld Wide Web, social contact networks, and citation networks of scientific\npapers and online news articles, for example, are of this kind. Static methods\ncan be inadequate for the analysis of growing networks as they miss essential\ninformation on the system's dynamics. At the same time, time-aware methods\nrequire the choice of an observation timescale, yet we lack principled ways to\ndetermine it. We focus on the popular community detection problem which aims to\npartition a network's nodes into meaningful groups. We use a multi-layer\nquality function to show, on both synthetic and real datasets, that the\nobservation timescale that leads to optimal communities is tightly related to\nthe system's intrinsic aging timescale that can be inferred from the\ntime-stamped network data. The use of temporal information leads to drastically\ndifferent conclusions on the community structure of real information networks,\nwhich challenges the current understanding of the large-scale organization of\ngrowing networks. Our findings indicate that before attempting to assess\nstructural patterns of evolving networks, it is vital to uncover the timescales\nof the dynamical processes that generated them. \n\n"}
{"id": "1809.08359", "contents": "Title: A convex program for bilinear inversion of sparse vectors Abstract: We consider the bilinear inverse problem of recovering two vectors,\n$\\boldsymbol{x}\\in\\mathbb{R}^L$ and $\\boldsymbol{w}\\in\\mathbb{R}^L$, from their\nentrywise product. We consider the case where $\\boldsymbol{x}$ and\n$\\boldsymbol{w}$ have known signs and are sparse with respect to known\ndictionaries of size $K$ and $N$, respectively. Here, $K$ and $N$ may be larger\nthan, smaller than, or equal to $L$. We introduce $\\ell_1$-BranchHull, which is\na convex program posed in the natural parameter space and does not require an\napproximate solution or initialization in order to be stated or solved. We\nstudy the case where $\\boldsymbol{x}$ and $\\boldsymbol{w}$ are $S_1$- and\n$S_2$-sparse with respect to a random dictionary and present a recovery\nguarantee that only depends on the number of measurements as\n$L\\geq\\Omega(S_1+S_2)\\log^{2}(K+N)$. Numerical experiments verify that the\nscaling constant in the theorem is not too large. One application of this\nproblem is the sweep distortion removal task in dielectric imaging, where one\nof the signals is a nonnegative reflectivity, and the other signal lives in a\nknown subspace, for example that given by dominant wavelet coefficients. We\nalso introduce a variants of $\\ell_1$-BranchHull for the purposes of tolerating\nnoise and outliers, and for the purpose of recovering piecewise constant\nsignals. We provide an ADMM implementation of these variants and show they can\nextract piecewise constant behavior from real images. \n\n"}
{"id": "1809.09231", "contents": "Title: Tunable Measures for Information Leakage and Applications to\n  Privacy-Utility Tradeoffs Abstract: We introduce a tunable measure for information leakage called maximal\nalpha-leakage. This measure quantifies the maximal gain of an adversary in\ninferring any (potentially random) function of a dataset from a release of the\ndata. The inferential capability of the adversary is, in turn, quantified by a\nclass of adversarial loss functions that we introduce as $\\alpha$-loss,\n$\\alpha\\in[1,\\infty]$. The choice of $\\alpha$ determines the specific\nadversarial action and ranges from refining a belief (about any function of the\ndata) for $\\alpha=1$ to guessing the most likely value for $\\alpha=\\infty$\nwhile refining the $\\alpha^{th}$ moment of the belief for $\\alpha$ in between.\nMaximal alpha-leakage then quantifies the adversarial gain under $\\alpha$-loss\nover all possible functions of the data. In particular, for the extremal values\nof $\\alpha=1$ and $\\alpha=\\infty$, maximal alpha-leakage simplifies to mutual\ninformation and maximal leakage, respectively. For $\\alpha\\in(1,\\infty)$ this\nmeasure is shown to be the Arimoto channel capacity of order $\\alpha$. We show\nthat maximal alpha-leakage satisfies data processing inequalities and a\nsub-additivity property thereby allowing for a weak composition result.\nBuilding upon these properties, we use maximal alpha-leakage as the privacy\nmeasure and study the problem of data publishing with privacy guarantees,\nwherein the utility of the released data is ensured via a hard distortion\nconstraint. Unlike average distortion, hard distortion provides a deterministic\nguarantee of fidelity. We show that under a hard distortion constraint, for\n$\\alpha>1$ the optimal mechanism is independent of $\\alpha$, and therefore, the\nresulting optimal tradeoff is the same for all values of $\\alpha>1$. Finally,\nthe tunability of maximal alpha-leakage as a privacy measure is also\nillustrated for binary data with average Hamming distortion as the utility\nmeasure. \n\n"}
{"id": "1810.00257", "contents": "Title: Computational Convergence Analysis of Distributed Gradient Tracking for\n  Smooth Convex Optimization Using Dissipativity Theory Abstract: We present a computational analysis that establishes the $O(1/K)$ convergence\nof the distributed gradient tracking method when the objective function is\nsmooth and convex but not strongly convex. The analysis is inspired by recent\nwork on applying dissipativity theory to the analysis of centralized\noptimization algorithms, in which convergence is proved by searching for a\nnumerical certificate consisting of a storage function and a supply rate. We\nderive a base supply rate that can be used to analyze distributed optimization\nwith non-strongly convex objective functions. The base supply rate is then used\nto create a class of supply rates by combining with integral quadratic\nconstraints. Provided that the class of supply rates is rich enough, a\nnumerical certificate of convergence can be automatically generated following a\nstandard procedure that involves solving a linear matrix inequality. Our\ncomputational analysis is found capable of certifying convergence under a\nbroader range of step sizes than what is given by the original analytic result. \n\n"}
{"id": "1810.00774", "contents": "Title: Geometric Constellation Shaping for Fiber Optic Communication Systems\n  via End-to-end Learning Abstract: In this paper, an unsupervised machine learning method for geometric\nconstellation shaping is investigated. By embedding a differentiable fiber\nchannel model within two neural networks, the learning algorithm is optimizing\nfor a geometric constellation shape. The learned constellations yield improved\nperformance to state-of-the-art geometrically shaped constellations, and\ninclude an implicit trade-off between amplification noise and nonlinear\neffects. Further, the method allows joint optimization of system parameters,\nsuch as the optimal launch power, simultaneously with the constellation shape.\nAn experimental demonstration validates the findings. Improved performances are\nreported, up to 0.13 bit/4D in simulation and experimentally up to 0.12 bit/4D. \n\n"}
{"id": "1810.01137", "contents": "Title: Avoiding Burst-like Error Patterns in Windowed Decoding of Spatially\n  Coupled LDPC Codes Abstract: In this work, we analyze efficient window shift schemes for windowed decoding\nof spatially coupled low-density parity-check (SC-LDPC) codes, which is known\nto yield close-tooptimal decoding results when compared to full belief\npropagation (BP) decoding. However, a drawback of windowed decoding is that\neither a significant amount of window updates are required leading to\nunnecessary high decoding complexity or the decoder suffers from sporadic\nburst-like error patterns, causing a decoder stall. To tackle this effect and,\nthus, to reduce the average decoding complexity, the basic idea is to enable\nadaptive window shifts based on a bit error rate (BER) prediction, which\nreduces the amount of unnecessary updates. As the decoder stall does not occur\nin analytical investigations such as the density evolution (DE), we examine\ndifferent schemes on a fixed test-set and exhaustive monte-carlo simulations\nbased on our graphic processing unit (GPU) simulation framework. As a result,\nwe can reduce the average decoding complexity of the naive windowed decoder\nwhile improving the BER performance when compared to a non-adaptive windowed\ndecoding scheme. Furthermore, we show that a foresightful stall prediction does\nnot significantly outperform a retrospective stall detection which is much\neasier to implement in practice. \n\n"}
{"id": "1810.04494", "contents": "Title: Dynamic attitude planning for trajectory tracking in underactuated VTOL\n  UAVs Abstract: This paper addresses the trajectory tracking control problem for\nunderactuated VTOL UAVs. According to the different actuation mechanisms, the\nmost common UAV platforms can achieve only a partial decoupling of attitude and\nposition tasks. Since position tracking is of utmost importance for\napplications involving aerial vehicles, we propose a control scheme in which\nposition tracking is the primary objective. To this end, this work introduces\nthe concept of attitude planner, a dynamical system through which the desired\nattitude reference is processed to guarantee the satisfaction of the primary\nobjective: the attitude tracking task is considered as a secondary objective\nwhich can be realized as long as the desired trajectory satisfies specific\ntrackability conditions. Two numerical simulations are performed by applying\nthe proposed control law to a hexacopter with and without tilted propellers,\nwhich accounts for unmodeled dynamics and external disturbances not included in\nthe control design model. \n\n"}
{"id": "1810.06425", "contents": "Title: Modelling of temporal fluctuation scaling in online news network with\n  independent cascade model Abstract: We show that activity of online news outlets follows a temporal fluctuation\nscaling law and we recover this feature using an independent cascade model\naugmented with a varying hype parameter representing a viral potential of an\noriginal article. We use the Event Registry platform to track activity of over\n10,000 news outlets in 11 different topics in the course of the year 2016.\nAnalyzing over 22,000,000 articles, we found that fluctuation scaling exponents\n$\\alpha$ depend on time window size $\\Delta$ in a characteristic way for all\nthe considered topics -- news outlets activities are partially synchronized for\n$\\Delta>15\\mathrm{min}$ with a cross-over for $\\Delta=1\\mathrm{day}$. The\nproposed model was run on several synthetic network models as well as on a\nnetwork extracted from the real data. Our approach discards timestamps as not\nfully reliable observables and focuses on co-occurrences of publishers in\ncascades of similarly phrased news items. We make use of the Event Registry\nnews clustering feature to find correlations between content published by news\noutlets in order to uncover common information propagation paths in published\narticles and to estimate weights of edges in the independent cascade model.\nWhile the independent cascade model follows the fluctuation scaling law with a\ntrivial exponent $\\alpha=0.5$, we argue that besides the topology of the\nunderlying cooperation network a temporal clustering of articles with similar\nhypes is necessary to qualitatively reproduce the fluctuation scaling observed\nin the data. \n\n"}
{"id": "1810.06495", "contents": "Title: Generalised hypergeometric ensembles of random graphs: the configuration\n  model as an urn problem Abstract: We introduce a broad class of random graph models: the generalised\nhypergeometric ensemble (GHypEG). This class enables to solve some long\nstanding problems in random graph theory. First, GHypEG provides an elegant and\ncompact formulation of the well-known configuration model in terms of an urn\nproblem. Second, GHypEG allows to incorporate arbitrary tendencies to connect\ndifferent vertex pairs. Third, we present the closed-form expressions of the\nassociated probability distribution ensures the analytical tractability of our\nformulation. This is in stark contrast with the previous state-of-the-art,\nwhich is to implement the configuration model by means of computationally\nexpensive procedures. \n\n"}
{"id": "1810.07117", "contents": "Title: Universal Uhrig dynamical decoupling for bosonic systems Abstract: We construct efficient deterministic dynamical decoupling schemes protecting\ncontinuous variable degrees of freedom. Our schemes target decoherence induced\nby quadratic system-bath interactions with analytic time-dependence. We show\nhow to suppress such interactions to $N$-th order using only $N$ pulses.\nFurthermore, we show to homogenize a $2^m$-mode bosonic system using only\n$(N+1)^{2m+1}$ pulses, yielding - up to $N$-th order - an effective evolution\ndescribed by non-interacting harmonic oscillators with identical frequencies.\nThe decoupled and homogenized system provides natural decoherence-free\nsubspaces for encoding quantum information. Our schemes only require pulses\nwhich are tensor products of single-mode passive Gaussian unitaries and SWAP\ngates between pairs of modes. \n\n"}
{"id": "1810.07390", "contents": "Title: The rank of random matrices over finite fields Abstract: We determine the rank of a random matrix A over a finite field with\nprescribed numbers of non-zero entries in each row and column. As an\napplication we obtain a formula for the rate of low-density parity check codes.\nThis formula verifies a conjecture of Lelarge [Proc. IEEE Information Theory\nWorkshop 2013]. The proofs are based on coupling arguments and the\ninterpolation method from mathematical physics. \n\n"}
{"id": "1810.08711", "contents": "Title: Stability conditions for a decentralised medium access algorithm:\n  single- and multi-hop networks Abstract: We consider a decentralised multi-access algorithm, motivated primarily by\nthe control of transmissions in a wireless network. For a finite single-hop\nnetwork with arbitrary interference constraints we prove stochastic stability\nunder the natural conditions. For infinite and finite single-hop networks, we\nobtain broad rate-stability conditions. We also consider symmetric finite\nmulti-hop networks and show that the natural condition is sufficient for\nstochastic stability. \n\n"}
{"id": "1810.10983", "contents": "Title: Stochastic Control with Stale Information--Part I: Fully Observable\n  Systems Abstract: In this study, we adopt age of information as a measure of the staleness of\ninformation, and take initial steps towards analyzing the control performance\nof stochastic systems with stale information. Our goals are to cast light on a\nfundamental limit on the information staleness that is required for a certain\nlevel of the control performance and to specify the corresponding stalest\ninformation pattern. In the asymptotic regime, such a limit asserts a critical\ninformation staleness that is required for stabilization. We achieve these\ngoals by formulating the problem as a stochastic optimization problem and\ncharacterizing the associated optimal solutions. These solutions are in fact a\ncontrol policy, which specifies the control inputs of the plant, and a queuing\npolicy, which specifies the staleness of information at the controller. \n\n"}
{"id": "1810.11831", "contents": "Title: Latency-Reliability Tradeoffs for State Estimation Abstract: The emerging interest in low-latency high-reliability applications, such as\nconnected vehicles, necessitates a new abstraction between communication and\ncontrol. Thanks to advances in cyber-physical systems over the past decades, we\nunderstand this interface for classical bit-rate models of channels as well as\npacket-loss-type channels. This work proposes a new abstraction characterized\nas a tradeoff curve between latency, reliability and rate. Our aim is to\nunderstand: Do we (control engineers) prefer faster but less reliable\ncommunications (with shorter codes), or slower but more reliable communications\n(with longer codes)? In this paper we examine the tradeoffs between latency and\nreliability for the problem of estimating dynamical systems over communication\nchannels. Employing different latency-reliability curves derived from practical\ncoding schemes, we develop a co-design methodology, i.e., select the code\nlength depending on the system dynamics to optimize system performance. \n\n"}
{"id": "1810.12825", "contents": "Title: Sizing the length of complex networks Abstract: Among all characteristics exhibited by natural and man-made networks the\nsmall-world phenomenon is surely the most relevant and popular. But despite its\nsignificance, a reliable and comparable quantification of the question `how\nsmall is a small-world network and how does it compare to others' has remained\na difficult challenge to answer. Here we establish a new synoptic\nrepresentation that allows for a complete and accurate interpretation of the\npathlength (and efficiency) of complex networks. We frame every network\nindividually, based on how its length deviates from the shortest and the\nlongest values it could possibly take. For that, we first had to uncover the\nupper and the lower limits for the pathlength and efficiency, which indeed\ndepend on the specific number of nodes and links. These limits are given by\nfamilies of singular configurations that we name as ultra-short and ultra-long\nnetworks. The representation here introduced frees network comparison from the\nneed to rely on the choice of reference graph models (e.g., random graphs and\nring lattices), a common practice that is prone to yield biased interpretations\nas we show. Application to empirical examples of three categories (neural,\nsocial and transportation) evidences that, while most real networks display a\npathlength comparable to that of random graphs, when contrasted against the\nabsolute boundaries, only the cortical connectomes prove to be ultra-short. \n\n"}
{"id": "1810.13161", "contents": "Title: Fully-Connected vs. Sub-Connected Hybrid Precoding Architectures for\n  mmWave MU-MIMO Abstract: Hybrid digital analog (HDA) beamforming has attracted considerable attention\nin practical implementation of millimeter wave (mmWave) multiuser\nmultiple-input multiple-output (MU-MIMO) systems due to its low power\nconsumption with respect to its digital baseband counterpart. The\nimplementation cost, performance, and power efficiency of HDA beamforming\ndepends on the level of connectivity and reconfigurability of the analog\nbeamforming network. In this paper, we investigate the performance of two\ntypical architectures for HDA MU-MIMO, i.e., the fully-connected (FC)\narchitecture where each RF antenna port is connected to all antenna elements of\nthe array, and the one-stream-per-subarray (OSPS) architecture where the RF\nantenna ports are connected to disjoint subarrays. We jointly consider the\ninitial beam acquisition phase and data communication phase, such that the\nlatter takes place by using the beam direction information obtained in the\nformer phase. For each phase, we propose our own BA and precoding schemes that\noutperform the counterparts in the literature. We also evaluate the power\nefficiency of the two HDA architectures taking into account the practical\nhardware impairments, e.g., the power dissipation at different hardware\ncomponents as well as the potential power backoff under typical power amplifier\n(PA) constraints. Numerical results show that the two architectures achieve\nsimilar sum spectral efficiency, but the OSPS architecture outperforms the FC\ncase in terms of hardware complexity and power efficiency, only at the cost of\na slightly longer time of initial beam acquisition. \n\n"}
{"id": "1811.02071", "contents": "Title: Scale-free Networks Well Done Abstract: We bring rigor to the vibrant activity of detecting power laws in empirical\ndegree distributions in real-world networks. We first provide a rigorous\ndefinition of power-law distributions, equivalent to the definition of\nregularly varying distributions that are widely used in statistics and other\nfields. This definition allows the distribution to deviate from a pure power\nlaw arbitrarily but without affecting the power-law tail exponent. We then\nidentify three estimators of these exponents that are proven to be\nstatistically consistent -- that is, converging to the true value of the\nexponent for any regularly varying distribution -- and that satisfy some\nadditional niceness requirements. In contrast to estimators that are currently\npopular in network science, the estimators considered here are based on\nfundamental results in extreme value theory, and so are the proofs of their\nconsistency. Finally, we apply these estimators to a representative collection\nof synthetic and real-world data. According to their estimates, real-world\nscale-free networks are definitely not as rare as one would conclude based on\nthe popular but unrealistic assumption that real-world data comes from power\nlaws of pristine purity, void of noise and deviations. \n\n"}
{"id": "1811.03220", "contents": "Title: Secrecy Outage Analysis for Cooperative NOMA Systems with Relay\n  Selection Scheme Abstract: This paper considers the secrecy outage performance of a multiple-relay\nassisted non-orthogonal multiple access (NOMA) network over Nakagami-$m$ fading\nchannels. Two slots are utilized to transmit signals from the base station to\ndestination. At the first slot, the base station broadcasts the superposition\nsignal of the two users to all decode-and-forward relays by message mapping\nstrategy. Then the selected relay transmits superposition signal to the two\nusers via power-domain NOMA technology. Three relay selection (RS) schemes,\ni.e., optimal single relay selection (OSRS) scheme, two-step single relay\nselection (TSRS) scheme, and optimal dual relay selection (ODRS) scheme, are\nproposed and the secrecy outage performance are analyzed. As a benchmark, we\nalso examine the secrecy outage performance of the NOMA systems with\ntraditional multiple relays combining (TMRC) scheme in which all the relay that\nsuccessfully decode signals from the source forward signals to the NOMA users\nwith equal power. Considering the correlation between the secrecy capacity of\ntwo users and different secrecy requirement for two NOMA users, the closed-form\nexpressions for the security outage probability (SOP) of the proposed OSRS,\nTSRS, and ODRS schemes along with the TMRC scheme are derived and validated via\nsimulations. To get more insights, we also derive the closed-form expressions\nfor the asymptotic SOP for all the schemes with fixed and dynamic power\nallocations. Furthermore, the secrecy diversity order (SDO) of cooperative NOMA\nsystems is obtained. The results demonstrate that our proposed schemes can\nsignificantly enhance the secrecy performance compared to the TMRC scheme and\nthat all the RS schemes with fixed power allocation obtain zero SDO and the\nOSRS scheme with dynamic power allocation obtains the same SDO as TMRC. \n\n"}
{"id": "1811.04331", "contents": "Title: Coverage Centrality Maximization in Undirected Networks Abstract: Centrality metrics are among the main tools in social network analysis. Being\ncentral for a user of a network leads to several benefits to the user: central\nusers are highly influential and play key roles within the network. Therefore,\nthe optimization problem of increasing the centrality of a network user\nrecently received considerable attention. Given a network and a target user\n$v$, the centrality maximization problem consists in creating $k$ new links\nincident to $v$ in such a way that the centrality of $v$ is maximized,\naccording to some centrality metric. Most of the algorithms proposed in the\nliterature are based on showing that a given centrality metric is monotone and\nsubmodular with respect to link addition. However, this property does not hold\nfor several shortest-path based centrality metrics if the links are undirected.\nIn this paper we study the centrality maximization problem in undirected\nnetworks for one of the most important shortest-path based centrality measures,\nthe coverage centrality. We provide several hardness and approximation results.\nWe first show that the problem cannot be approximated within a factor greater\nthan $1-1/e$, unless $P=NP$, and, under the stronger gap-ETH hypothesis, the\nproblem cannot be approximated within a factor better than $1/n^{o(1)}$, where\n$n$ is the number of users. We then propose two greedy approximation\nalgorithms, and show that, by suitably combining them, we can guarantee an\napproximation factor of $\\Omega(1/\\sqrt{n})$. We experimentally compare the\nsolutions provided by our approximation algorithm with optimal solutions\ncomputed by means of an exact IP formulation. We show that our algorithm\nproduces solutions that are very close to the optimum. \n\n"}
{"id": "1811.05397", "contents": "Title: Algorithms for Optimal AC Power Flow in the Presence of Renewable\n  Sources Abstract: This chapter presents recent solutions to the optimal power flow (OPF)\nproblem in the presence of renewable energy sources (RES), {such} as solar\nphoto-voltaic and wind generation. After introducing the original formulation\nof the problem, arising from the combination of economic dispatch and power\nflow, we provide a brief overview of the different solution methods proposed in\nthe literature to solve it. Then, we explain the main difficulties arising from\nthe increasing RES penetration, and the ensuing necessity of deriving robust\nsolutions. Finally, we present the state-of-the-art techniques, with a special\nfocus on recent methods we developed, based on the application on\nrandomization-based methodologies. \n\n"}
{"id": "1811.06110", "contents": "Title: Layered Belief Propagation for Low-complexity Large MIMO Detection Based\n  on Statistical Beams Abstract: This paper proposes a novel layered belief propagation (BP) detector with a\nconcatenated structure of two different BP layers for low-complexity large\nmulti-user multi-input multi-output (MU-MIMO) detection based on statistical\nbeams. To reduce the computational burden and the circuit scale on the base\nstation (BS) side, the two-stage signal processing consisting of slow varying\nouter beamformer (OBF) and group-specific MU detection (MUD) for fast channel\nvariations is effective. However, the dimensionality reduction of the\nequivalent channel based on the OBF results in significant performance\ndegradation in subsequent spatial filtering detection. To compensate for the\ndrawback, the proposed layered BP detector, which is designed for improving the\ndetection capability by suppressing the intra- and inter-group interference in\nstages, is introduced as the post-stage processing of the OBF. Finally, we\ndemonstrate the validity of our proposed method in terms of the bit error rate\n(BER) performance and the computational complexity. \n\n"}
{"id": "1811.06693", "contents": "Title: Exploring Media Bias and Toxicity in South Asian Political Discourse Abstract: Media outlets and political campaigners recognise social media as a means for\nwidely disseminating news and opinions. In particular, Twitter is used by\npolitical groups all over the world to spread political messages, engage their\nsupporters, drive election campaigns, and challenge their critics. Further,\nnews agencies, many of which aim to give an impression of balance, are often of\na particular political persuasion which is reflected in the content they\nproduce. Driven by the potential for political and media organisations to\ninfluence public opinion, our aim is to quantify the nature of political\ndiscourse by these organisations through their use of social media. In this\nstudy, we analyse the sentiments, toxicity, and bias exhibited by the most\nprominent Pakistani and Indian political parties and media houses, and the\npattern by which these political parties utilise Twitter. We found that media\nbias and toxicity exist in the political discourse of these two developing\nnations. \n\n"}
{"id": "1811.07655", "contents": "Title: An Influence-based Clustering Model on Twitter Abstract: This paper introduces a temporal framework for detecting and clustering\nemergent and viral topics on social networks. Endogenous and exogenous\ninfluence on developing viral content is explored using a clustering method\nbased on the a user's behavior on social network and a dataset from Twitter\nAPI. Results are discussed by introducing metrics such as popularity,\nburstiness, and relevance score. The results show clear distinction in\ncharacteristics of developed content by the two classes of users. \n\n"}
{"id": "1811.09188", "contents": "Title: Ergodicity analysis and antithetic integral control of a class of\n  stochastic reaction networks with delays Abstract: Delays are an important phenomenon arising in a wide variety of real world\nsystems. They occur in biological models because of diffusion effects or as\nsimplifying modeling elements. We propose here to consider delayed stochastic\nreaction networks. The difficulty here lies in the fact that the state-space of\na delayed reaction network is infinite-dimensional, which makes their analysis\nmore involved. We demonstrate here that a particular class of stochastic\ntime-varying delays, namely those that follow a phase-type distribution, can be\nexactly implemented in terms of a chemical reaction network. Hence, any\ndelay-free network can be augmented to incorporate those delays through the\naddition of delay-species and delay-reactions. Hence, for this class of\nstochastic delays, which can be used to approximate any delay distribution\narbitrarily accurately, the state-space remains finite-dimensional and,\ntherefore, standard tools developed for standard reaction network still apply.\nIn particular, we demonstrate that for unimolecular mass-action reaction\nnetworks that the delayed stochastic reaction network is ergodic if and only if\nthe non-delayed network is ergodic as well. Bimolecular reactions are more\ndifficult to consider but an analogous result is also obtained. These results\ntell us that delays that are phase-type distributed, regardless of their\ndistribution, are not harmful to the ergodicity property of reaction networks.\nWe also prove that the presence of those delays adds convolution terms in the\nmoment equation but does not change the value of the stationary means compared\nto the delay-free case. Finally, the control of a certain class of delayed\nstochastic reaction network using a delayed antithetic integral controller is\nconsidered. It is proven that this controller achieves its goal provided that\nthe delay-free network satisfy the conditions of ergodicity and\noutput-controllability. \n\n"}
{"id": "1811.09458", "contents": "Title: Quantifying Filter Bubbles: Analyzing Surprise in Elections Abstract: This work analyses surprising elections, and attempts to quantify the notion\nof surprise in elections. A voter is surprised if their estimate of the winner\n(assumed to be based on a combination of the preferences of their social\nconnections and popular media predictions) is different from the true winner. A\nvoter's social connections are assumed to consist of contacts on social media\nand geographically proximate people. We propose a simple mathematical model for\ncombining the global information (traditional media) as well as the local\ninformation (local neighbourhood) of a voter in the case of a two-candidate\nelection. We show that an unbiased, influential media can nullify the effect of\nfilter bubbles and result in a less surprised populace. Surprisingly, an\ninfluential media source biased towards the winners of the election also\nresults in a less surprised populace. Our model shows that elections will be\nunsurprising for all of the voters with a high probability under certain\nassumptions on the social connection model in the presence of an influential,\nunbiased traditional media source. Our experiments with the UK-EU referendum\n(popularly known as Brexit) dataset support our theoretical predictions. Since\nsurprising elections can lead to significant economic movements, it is a\nworthwhile endeavour to figure out the causes of surprising elections. \n\n"}
{"id": "1811.10337", "contents": "Title: Multiple Partitioning of Multiplex Signed Networks: Application to\n  European Parliament Votes Abstract: For more than a decade, graphs have been used to model the voting behavior\ntaking place in parliaments. However, the methods described in the literature\nsuffer from several limitations. The two main ones are that 1) they rely on\nsome temporal integration of the raw data, which causes some information loss,\nand/or 2) they identify groups of antagonistic voters, but not the context\nassociated to their occurrence. In this article, we propose a novel method\ntaking advantage of multiplex signed graphs to solve both these issues. It\nconsists in first partitioning separately each layer, before grouping these\npartitions by similarity. We show the interest of our approach by applying it\nto a European Parliament dataset. \n\n"}
{"id": "1811.10585", "contents": "Title: Base-Stations Up in the Air: Multi-UAV Trajectory Control for Min-Rate\n  Maximization in Uplink C-RAN Abstract: In this paper we study the impact of unmanned aerial vehicles (UAVs)\ntrajectories on terrestrial users' spectral efficiency (SE). Assuming a strong\nline of sight path to the users, the distance from all users to all UAVs\ninfluence the outcome of an online trajectory optimization. The trajectory\nshould be designed in a way that the fairness rate is maximized over time. That\nmeans, the UAVs travel in the directions that maximize the minimum of the\nusers' SE. From the free-space path-loss channel model, a data-rate gradient is\ncalculated and used to direct the UAVs in a long-term perspective towards the\nlocal optimal solution on the two-dimensional spatial grid. Therefore, a\ncontrol system implementation is designed. Thereby, the UAVs follow the\ndata-rate gradient direction while having a more smooth trajectory compared\nwith a gradient method. The system can react to changes of the user locations\nonline; this system design captures the interaction between multiple UAV\ntrajectories by joint processing at the central unit, e.g., a ground base\nstation. Because of the wide spread of user locations, the UAVs end up in\noptimal locations widely apart from each other. Besides, the SE expectancy is\nenhancing continuously while moving along this trajectory. \n\n"}
{"id": "1811.10804", "contents": "Title: Movie Recommendation System using Sentiment Analysis from Microblogging\n  Data Abstract: Recommendation systems are important intelligent systems that play a vital\nrole in providing selective information to users. Traditional approaches in\nrecommendation systems include collaborative filtering and content-based\nfiltering. However, these approaches have certain limitations like the\nnecessity of prior user history and habits for performing the task of\nrecommendation. In order to reduce the effect of such dependencies, this paper\nproposes a hybrid recommendation system which combines the collaborative\nfiltering, content-based filtering with sentiment analysis of movie tweets. The\nmovie tweets have been collected from microblogging websites to understand the\ncurrent trends and user response of the movie. Experiments conducted on public\ndatabase produce promising results. \n\n"}
{"id": "1811.11099", "contents": "Title: Cooperative Transmission and Probabilistic Caching for Clustered D2D\n  Networks Abstract: In this paper, we aim at maximizing the cache offloading gain for a clustered\n\\ac{D2D} caching network by exploiting probabilistic caching and cooperative\ntransmission among the cluster devices. Devices with surplus memory\nprobabilistically cache a content from a known library. A requested content is\neither brought from the device's local cache, cooperatively transmitted from\ncatering devices, or downloaded from the macro base station as a last resort.\nUsing stochastic geometry, we derive a closed-form expression for the\noffloading gain and formulate the offloading maximization problem. In order to\nsimplify the objective function and obtain analytically tractable expressions,\nwe derive a lower bound on the offloading gain, for which a suboptimal solution\nis obtained when considering a special case. Results reveal that the obtained\nsuboptimal solution can achieve up to 12% increase in the offloading gain\ncompared to the Zipf's caching technique. Besides, we show that the spatial\nscaling parameters of the network, e.g., the density of clusters and distance\nbetween devices in the same cluster, play a crucial role in identifying the\ntradeoff between the content diversity gain and the cooperative transmission\ngain. \n\n"}
{"id": "1811.11344", "contents": "Title: Constructions of involutions over finite fields Abstract: An involution over finite fields is a permutation polynomial whose inverse is\nitself. Owing to this property, involutions over finite fields have been widely\nused in applications such as cryptography and coding theory. As far as we know,\nthere are not many involutions, and there isn't a general way to construct\ninvolutions over finite fields. This paper gives a necessary and sufficient\ncondition for the polynomials of the form $x^rh(x^s)\\in \\bF_q[x]$ to be\ninvolutions over the finite field~$\\bF_q$, where $r\\geq 1$ and $s\\,|\\, (q-1)$.\nBy using this criterion we propose a general method to construct involutions of\nthe form $x^rh(x^s)$ over $\\bF_q$ from given involutions over the corresponding\nsubgroup of $\\bF_q^*$. Then, many classes of explicit involutions of the form\n$x^rh(x^s)$ over $\\bF_q$ are obtained. \n\n"}
{"id": "1811.11728", "contents": "Title: Attributed Network Embedding for Incomplete Attributed Networks Abstract: Attributed networks are ubiquitous since a network often comes with auxiliary\nattribute information e.g. a social network with user profiles. Attributed\nNetwork Embedding (ANE) has recently attracted considerable attention, which\naims to learn unified low dimensional node embeddings while preserving both\nstructural and attribute information. The resulting node embeddings can then\nfacilitate various network downstream tasks e.g. link prediction. Although\nthere are several ANE methods, most of them cannot deal with incomplete\nattributed networks with missing links and/or missing node attributes, which\noften occur in real-world scenarios. To address this issue, we propose a robust\nANE method, the general idea of which is to reconstruct a unified denser\nnetwork by fusing two sources of information for information enhancement, and\nthen employ a random walks based network embedding method for learning node\nembeddings. The experiments of link prediction, node classification,\nvisualization, and parameter sensitivity analysis on six real-world datasets\nvalidate the effectiveness of our method to incomplete attributed networks. \n\n"}
{"id": "1811.12183", "contents": "Title: Analyzing and provably improving fixed budget ranking and selection\n  algorithms Abstract: This paper studies the fixed budget formulation of the Ranking and Selection\n(R&S) problem with independent normal samples, where the goal is to investigate\ndifferent algorithms' convergence rate in terms of their resulting probability\nof false selection (PFS). First, we reveal that for the well-known Optimal\nComputing Budget Allocation (OCBA) algorithm and its two variants, a constant\ninitial sample size (independent of the total budget) only amounts to a\nsub-exponential (or even polynomial) convergence rate. After that, a\nmodification is proposed to achieve an exponential convergence rate, where the\nimprovement is shown by a finite-sample bound on the PFS as well as numerical\nresults. Finally, we focus on a more tractable two-design case and explicitly\ncharacterize the large deviations rate of PFS for some simplified algorithms.\nOur analysis not only develops insights into the algorithms' properties, but\nalso highlights several useful techniques for analyzing the convergence rate of\nfixed budget R\\&S algorithms. \n\n"}
{"id": "1812.01693", "contents": "Title: Spread of hate speech in online social media Abstract: The present online social media platform is afflicted with several issues,\nwith hate speech being on the predominant forefront. The prevalence of online\nhate speech has fueled horrific real-world hate-crime such as the mass-genocide\nof Rohingya Muslims, communal violence in Colombo and the recent massacre in\nthe Pittsburgh synagogue. Consequently, It is imperative to understand the\ndiffusion of such hateful content in an online setting. We conduct the first\nstudy that analyses the flow and dynamics of posts generated by hateful and\nnon-hateful users on Gab (gab.com) over a massive dataset of 341K users and 21M\nposts. Our observations confirms that hateful content diffuse farther, wider\nand faster and have a greater outreach than those of non-hateful users. A\ndeeper inspection into the profiles and network of hateful and non-hateful\nusers reveals that the former are more influential, popular and cohesive. Thus,\nour research explores the interesting facets of diffusion dynamics of hateful\nusers and broadens our understanding of hate speech in the online world. \n\n"}
{"id": "1812.03528", "contents": "Title: On uniform exponential ergodicity of Markovian multiclass many-server\n  queues in the Halfin-Whitt regime Abstract: We study ergodic properties of Markovian multiclass many-server queues which\nare uniform over scheduling policies, as well as the size n of the system. The\nsystem is heavily loaded in the Halfin-Whitt regime, and the scheduling\npolicies are work-conserving and preemptive. We provide a unified approach via\na Lyapunov function method that establishes Foster-Lyapunov equations for both\nthe limiting diffusion and the prelimit diffusion-scaled queueing processes\nsimultaneously.\n  We first study the limiting controlled diffusion, and we show that if the\nspare capacity (safety staffing) parameter is positive, then the diffusion is\nexponentially ergodic uniformly over all stationary Markov controls, and the\ninvariant probability measures have uniform exponential tails. This result is\nsharp, since when there is no abandonment and the spare capacity parameter is\nnegative, then the controlled diffusion is transient under any Markov control.\nIn addition, we show that if all the abandonment rates are positive, the\ninvariant probability measures have sub-Gaussian tails, regardless whether the\nspare capacity parameter is positive or negative.\n  Using the above results, we proceed to establish the corresponding ergodic\nproperties for the diffusion-scaled queueing processes. In addition to\nproviding a simpler proof of the results in Gamarnik and Stolyar [Queueing Syst\n(2012) 71:25-51], we extend these results to the multiclass models with renewal\narrival processes, albeit under the assumption that the mean residual life\nfunctions are bounded. For the Markovian model with Poisson arrivals, we obtain\nstronger results and show that the convergence to the stationary distribution\nis at an exponential rate uniformly over all work-conserving stationary Markov\nscheduling policies. \n\n"}
{"id": "1812.05138", "contents": "Title: Consensus and Disagreement of Heterogeneous Belief Systems in Influence\n  Networks Abstract: Recently, an opinion dynamics model has been proposed to describe a network\nof individuals discussing a set of logically interdependent topics. For each\nindividual, the set of topics and the logical interdependencies between the\ntopics (captured by a logic matrix) form a belief system. We investigate the\nrole the logic matrix and its structure plays in determining the final\nopinions, including existence of the limiting opinions, of a strongly connected\nnetwork of individuals. We provide a set of results that, given a set of\nindividuals' belief systems, allow a systematic determination of which topics\nwill reach a consensus, and which topics will disagreement in arise. For\nirreducible logic matrices, each topic reaches a consensus. For reducible logic\nmatrices, which indicates a cascade interdependence relationship, conditions\nare given on whether a topic will reach a consensus or not. It turns out that\nheterogeneity among the individuals' logic matrices, including especially\ndifferences in the signs of the off-diagonal entries, can be a key determining\nfactor. This paper thus attributes, for the first time, a strong diversity of\nlimiting opinions to heterogeneity of belief systems in influence networks, in\naddition to the more typical explanation that strong diversity arises from\nindividual stubbornness. \n\n"}
{"id": "1812.06337", "contents": "Title: Origraph: Interactive Network Wrangling Abstract: Networks are a natural way of thinking about many datasets. The data on which\na network is based, however, is rarely collected in a form that suits the\nanalysis process, making it necessary to create and reshape networks. Data\nwrangling is widely acknowledged to be a critical part of the data analysis\npipeline, yet interactive network wrangling has received little attention in\nthe visualization research community. In this paper, we discuss a set of\noperations that are important for wrangling network datasets and introduce a\nvisual data wrangling tool, Origraph, that enables analysts to apply these\noperations to their datasets. Key operations include creating a network from\nsource data such as tables, reshaping a network by introducing new node or edge\nclasses, filtering nodes or edges, and deriving new node or edge attributes.\nOur tool, Origraph, enables analysts to execute these operations with little to\nno programming, and to immediately visualize the results. Origraph provides\nviews to investigate the network model, a sample of the network, and node and\nedge attributes. In addition, we introduce interfaces designed to aid analysts\nin specifying arguments for sensible network wrangling operations. We\ndemonstrate the usefulness of Origraph in two Use Cases: first, we investigate\ngender bias in the film industry, and then the influence of money on the\npolitical support for the war in Yemen. \n\n"}
{"id": "1812.09710", "contents": "Title: Elites Tweet? Characterizing the Twitter Verified User Network Abstract: Social network and publishing platforms, such as Twitter, support the concept\nof verification. Verified accounts are deemed worthy of platform-wide public\ninterest and are separately authenticated by the platform itself. There have\nbeen repeated assertions by these platforms about verification not being\ntantamount to endorsement. However, a significant body of prior work suggests\nthat possessing a verified status symbolizes enhanced credibility in the eyes\nof the platform audience. As a result, such a status is highly coveted among\npublic figures and influencers. Hence, we attempt to characterize the network\nof verified users on Twitter and compare the results to similar analysis\nperformed for the entire Twitter network. We extracted the entire network of\nverified users on Twitter (as of July 2018) and obtained 231,246 user profiles\nand 79,213,811 connections. Subsequently in the network analysis, we found that\nthe sub-graph of verified users mirrors the full Twitter users graph in some\naspects such as possessing a short diameter. However, our findings contrast\nwith earlier findings on multiple aspects, such as the possession of a power\nlaw out-degree distribution, slight dissortativity and a significantly higher\nreciprocity rate, as elucidated in the paper. Moreover, we attempt to gauge the\npresence of salient components within this sub-graph and detect the absence of\nhomophily with respect to popularity, which again is in stark contrast to the\nfull Twitter graph. Finally, we demonstrate stationarity in the time series of\nverified user activity levels. To the best of our knowledge, this work\nrepresents the first quantitative attempt at characterizing verified users on\nTwitter. \n\n"}
{"id": "1901.00172", "contents": "Title: Supervised Multiscale Dimension Reduction for Spatial Interaction\n  Networks Abstract: We introduce a multiscale supervised dimension reduction method for SPatial\nInteraction Network (SPIN) data, which consist of a collection of spatially\ncoordinated interactions. This type of predictor arises when the sampling unit\nof data is composed of a collection of primitive variables, each of them being\nessentially unique, so that it becomes necessary to group the variables in\norder to simplify the representation and enhance interpretability. In this\npaper, we introduce an empirical Bayes approach called spinlets, which first\nconstructs a partitioning tree to guide the reduction over multiple spatial\ngranularities, and then refines the representation of predictors according to\nthe relevance to the response. We consider an inverse Poisson regression model\nand propose a new multiscale generalized double Pareto prior, which is induced\nvia a tree-structured parameter expansion scheme. Our approach is motivated by\nan application in soccer analytics, in which we obtain compact vectorial\nrepresentations and readily interpretable visualizations of the complex network\nobjects, supervised by the response of interest. \n\n"}
{"id": "1901.00304", "contents": "Title: Normal Approximation and Confidence Region of Singular Subspaces Abstract: This paper is on the normal approximation of singular subspaces when the\nnoise matrix has i.i.d. entries. Our contributions are three-fold. First, we\nderive an explicit representation formula of the empirical spectral projectors.\nThe formula is neat and holds for deterministic matrix perturbations. Second,\nwe calculate the expected projection distance between the empirical singular\nsubspaces and true singular subspaces. Our method allows obtaining arbitrary\n$k$-th order approximation of the expected projection distance. Third, we prove\nthe non-asymptotical normal approximation of the projection distance with\ndifferent levels of bias corrections. By the $\\lceil \\log(d_1+d_2)\\rceil$-th\norder bias corrections, the asymptotical normality holds under optimal\nsignal-to-noise ration (SNR) condition where $d_1$ and $d_2$ denote the matrix\nsizes. In addition, it shows that higher order approximations are unnecessary\nwhen $|d_1-d_2|=O((d_1+d_2)^{1/2})$. Finally, we provide comprehensive\nsimulation results to merit our theoretic discoveries.\n  Unlike the existing results, our approach is non-asymptotical and the\nconvergence rates are established. Our method allows the rank $r$ to diverge as\nfast as $o((d_1+d_2)^{1/3})$. Moreover, our method requires no eigen-gap\ncondition (except the SNR) and no constraints between $d_1$ and $d_2$. \n\n"}
{"id": "1901.02044", "contents": "Title: Covert Secret Key Generation with an Active Warden Abstract: We investigate the problem of covert and secret key generation over a\nstate-dependent discrete memoryless channel with one-way public discussion in\nwhich an adversary, the warden, may arbitrarily choose the channel state. We\ndevelop an adaptive protocol that, under conditions that we explicitly specify,\nnot only allows the transmitter and the legitimate receiver to exchange a\nsecret key but also conceals from the active warden whether the protocol is\nbeing run. When specialized to passive adversaries that do not control the\nchannel state, we partially characterize the covert secret key capacity. In\nparticular, the covert secret key capacity is sometimes equal to the covert\ncapacity of the channel, so that secrecy comes \"for free.\" \n\n"}
{"id": "1901.02073", "contents": "Title: Locally Repairable Convolutional Codes with Sliding Window Repair Abstract: Locally repairable convolutional codes (LRCCs) for distributed storage\nsystems (DSSs) are introduced in this work. They enable local repair, for a\nsingle node erasure (or more generally, $ \\partial - 1 $ erasures per local\ngroup), and sliding-window global repair, which can correct erasure patterns\nwith up to $ {\\rm d}^c_j - 1 $ erasures in every window of $ j+1 $ consecutive\nblocks of $ n $ nodes, where $ {\\rm d}^c_j $ is the $ j $th column distance of\nthe code. The parameter $ j $ can be adjusted, for a fixed LRCC, according to\ndifferent catastrophic erasure patterns, requiring only to contact $ n(j+1) -\n{\\rm d}^c_j + 1 $ nodes, plus less than $ \\mu n $ other nodes, in the storage\nsystem, where $ \\mu $ is the memory of the code. A Singleton-type bound is\nprovided for $ {\\rm d}^c_j $. If it attains such a bound, an LRCC can correct\nthe same number of catastrophic erasures in a window of length $ n(j+1) $ as an\noptimal locally repairable block code of the same rate and locality, and with\nblock length $ n(j+1) $. In addition, the LRCC is able to perform the flexible\nand somehow local sliding-window repair by adjusting $ j $. Furthermore, by\nadjusting and/or sliding the window, the LRCC can potentially correct more\nerasures in the original window of $ n(j+1) $ nodes than an optimal locally\nrepairable block code of the same rate and locality, and length $ n(j+1) $.\nFinally, the concept of partial maximum distance profile (partial MDP) codes is\nintroduced. Partial MDP codes can correct all information-theoretically\ncorrectable erasure patterns for a given locality, local distance and\ninformation rate. An explicit construction of partial MDP codes whose column\ndistances attain the provided Singleton-type bound, up to certain parameter $\nj=L $, is obtained based on known maximum sum-rank distance convolutional\ncodes. \n\n"}
{"id": "1901.02782", "contents": "Title: On the design of new classes of fixed-time stable systems with\n  predefined upper bound for the settling time Abstract: This paper aims to provide a methodology for generating autonomous and\nnon-autonomous systems with a fixed-time stable equilibrium point where an\nUpper Bound of the Settling Time (UBST) is set a priori as a parameter of the\nsystem. In addition, some conditions for such an upper bound to be the least\none are provided. This construction procedure is a relevant contribution when\ncompared with traditional methodologies for generating fixed-time algorithms\nsatisfying time constraints since current estimates of an UBST may be too\nconservative. The proposed methodology is based on time-scale transformations\nand Lyapunov analysis. It allows the presentation of a broad class of\nfixed-time stable systems with predefined UBST, placing them under a common\nframework with existing methods using time-varying gains. To illustrate the\neffectiveness of our approach, we generate novel, autonomous and\nnon-autonomous, fixed-time stable algorithms with predefined least UBST. \n\n"}
{"id": "1901.04241", "contents": "Title: Linear complementary dual, maximum distance separable codes Abstract: Linear complementary dual (LCD) maximum distance separable (MDS) codes are\nconstructed to given specifications. For given $n$ and $r<n$, with $n$ or $r$\n(or both) odd, MDS LCD $(n,r)$ codes are constructed over finite fields whose\ncharacteristic does not divide $n$. Series of LCD MDS codes are constructed to\nrequired rate and required error-correcting capability. Given the field $GF(q)$\nand $n/(q-1)$, LCD MDS codes of length $n$ and dimension $r$ are explicitly\nconstructed over $GF(q)$ for all $r<n$ when $n$ is odd and for all odd $r<n$\nwhen $n$ is even. For given dimension and given error-correcting capability LCD\nMDS codes are constructed to these specifications with smallest possible\nlength. Series of asymptotically good LCD MDS codes are explicitly constructed.\nEfficient encoding and decoding algorithms exist for all the constructed codes.\n  Linear complementary dual codes have importance in data storage,\ncommunications' systems and security. \n\n"}
{"id": "1901.05772", "contents": "Title: A Capacity-Achieving $T$-PIR Scheme Based On MDS Array Codes Abstract: Suppose a database containing $M$ records is replicated in each of $N$\nservers, and a user wants to privately retrieve one record by accessing the\nservers such that identity of the retrieved record is secret against any up to\n$T$ servers. A scheme designed for this purpose is called a $T$-private\ninformation retrieval ($T$-PIR) scheme.\n  In this paper we focus on the field size of $T$-PIR schemes. We design a\ngeneralcapacity-achieving $T$-PIR scheme whose queries are generated by using\nsome {\\rm MDS } array codes. It only requires field size $q\\geq\\sqrt[\\ell]{N}$,\nwhere $\\ell=\\min\\{t^{M-2},(n-t)^{M-2}\\}$, $~t=T/{\\rm gcd}(N,T)$,$~n=N/{\\rm\ngcd}(N,T)$ and has the optimal sub-packetization $Nn^{M-2}$. Comparing with\nexisting capacity-achieving $T$-PIR schemes, our scheme has the following\nadvantage, that is, its field size monotonically decreases as the number of\nrecords $M$ grows. In particular, the binary field is sufficient for building a\ncapacity-achieving T-PIR scheme as long as $M\\geq\n2+\\lceil\\log_\\mu\\log_2N\\rceil$, where $\\mu=\\min\\{t,n-t\\}>1$. \n\n"}
{"id": "1901.05908", "contents": "Title: Locality in Index Coding for Large Min-Rank Abstract: An index code is said to be locally decodable if each receiver can decode its\ndemand using its side information and by querying only a subset of the\ntransmitted codeword symbols instead of observing the entire codeword. Local\ndecodability can be a beneficial feature in some communication scenarios, such\nas when the receivers can afford to listen to only a part of the transmissions\nbecause of limited availability of power. The locality of an index code is the\nratio of the maximum number of codeword symbols queried by a receiver to the\nmessage length. In this paper we analyze the optimum locality of linear codes\nfor the family of index coding problems whose min-rank is one less than the\nnumber of receivers in the network. We first derive the optimal trade-off\nbetween the index coding rate and locality with vector linear coding when the\nside information graph is a directed cycle. We then provide the optimal\ntrade-off achieved by scalar linear coding for a larger family of problems,\nviz., problems where the min-rank is only one less than the number of\nreceivers. While the arguments used for achievability are based on known coding\ntechniques, the converse arguments rely on new results on the structure of\nlocally decodable index codes. \n\n"}
{"id": "1901.06341", "contents": "Title: On Distance Properties of Convolutional Polar Codes Abstract: A lower bound on minimum distance of convolutional polar codes is provided.\nThe bound is obtained from the minimum weight of generalized cosets of the\ncodes generated by bottom rows of the polarizing matrix. Moreover, a\nconstruction of convolutional polar subcodes is proposed, which provides\nimproved performance under successive cancellation list decoding. For\nsufficiently large list size, the decoding complexity of convolutional polar\nsubcodes appears to be lower compared to Arikan polar subcodes with the same\nperformance. The error probability of successive cancellation list decoding of\nconvolutional polar subcodes is lower than that of Arikan polar subcodes with\nthe same list size. \n\n"}
{"id": "1901.07377", "contents": "Title: Data assimilation and online optimization with performance guarantees Abstract: This paper considers a class of real-time stochastic optimization problems\ndependent on an unknown probability distribution. In the considered scenario,\ndata is streaming frequently while trying to reach a decision. Thus, we aim to\ndevise a procedure that incorporates samples (data) of the distribution\nsequentially and adjusts decisions accordingly. We approach this problem in a\ndistributionally robust optimization framework and propose a novel Online Data\nAssimilation Algorithm (ONDA Algorithm) for this purpose. This algorithm\nguarantees out-of-sample performance of decisions with high probability, and\ngradually improves the quality of the decisions by incorporating the streaming\ndata. We show that the ONDA Algorithm converges under a sufficiently slow data\nstreaming rate, and provide a criteria for its termination after certain number\nof data have been collected. Simulations illustrate the results. \n\n"}
{"id": "1901.07933", "contents": "Title: Extracting significant signal of news consumption from social networks:\n  the case of Twitter in Italian political elections Abstract: According to the Eurobarometer report about EU media use of May 2018, the\nnumber of European citizens who consult on-line social networks for accessing\ninformation is considerably increasing. In this work we analyze approximately\n$10^6$ tweets exchanged during the last Italian elections. By using an\nentropy-based null model discounting the activity of the users, we first\nidentify potential political alliances within the group of verified accounts:\nif two verified users are retweeted more than expected by the non-verified\nones, they are likely to be related. Then, we derive the users' affiliation to\na coalition measuring the polarization of unverified accounts. Finally, we\nstudy the bipartite directed representation of the tweets and retweets network,\nin which tweets and users are collected on the two layers. Users with the\nhighest out-degree identify the most popular ones, whereas highest out-degree\nposts are the most \"viral\". We identify significant content spreaders by\nstatistically validating the connections that cannot be explained by users'\ntweeting activity and posts' virality by using an entropy-based null model as\nbenchmark. The analysis of the directed network of validated retweets reveals\nsignals of the alliances formed after the elections, highlighting commonalities\nof interests before the event of the national elections. \n\n"}
{"id": "1901.09671", "contents": "Title: ErasureHead: Distributed Gradient Descent without Delays Using\n  Approximate Gradient Coding Abstract: We present ErasureHead, a new approach for distributed gradient descent (GD)\nthat mitigates system delays by employing approximate gradient coding. Gradient\ncoded distributed GD uses redundancy to exactly recover the gradient at each\niteration from a subset of compute nodes. ErasureHead instead uses approximate\ngradient codes to recover an inexact gradient at each iteration, but with\nhigher delay tolerance. Unlike prior work on gradient coding, we provide a\nperformance analysis that combines both delay and convergence guarantees. We\nestablish that down to a small noise floor, ErasureHead converges as quickly as\ndistributed GD and has faster overall runtime under a probabilistic delay\nmodel. We conduct extensive experiments on real world datasets and distributed\nclusters and demonstrate that our method can lead to significant speedups over\nboth standard and gradient coded GD. \n\n"}
{"id": "cs/0510009", "contents": "Title: Tree-Based Construction of LDPC Codes Having Good Pseudocodeword Weights Abstract: We present a tree-based construction of LDPC codes that have minimum\npseudocodeword weight equal to or almost equal to the minimum distance, and\nperform well with iterative decoding. The construction involves enumerating a\n$d$-regular tree for a fixed number of layers and employing a connection\nalgorithm based on permutations or mutually orthogonal Latin squares to close\nthe tree. Methods are presented for degrees $d=p^s$ and $d = p^s+1$, for $p$ a\nprime. One class corresponds to the well-known finite-geometry and finite\ngeneralized quadrangle LDPC codes; the other codes presented are new. We also\npresent some bounds on pseudocodeword weight for $p$-ary LDPC codes. Treating\nthese codes as $p$-ary LDPC codes rather than binary LDPC codes improves their\nrates, minimum distances, and pseudocodeword weights, thereby giving a new\nimportance to the finite geometry LDPC codes where $p > 2$. \n\n"}
{"id": "cs/0510055", "contents": "Title: Degrees of Freedom in Multiuser MIMO Abstract: We explore the available degrees of freedom for various multiuser MIMO\ncommunication scenarios such as the multiple access, broadcast, interference,\nrelay, X and Z channels. For the two user MIMO interference channel, we find a\ngeneral inner bound and a genie-aided outer bound that give us the exact number\nof degrees of freedom in many cases. We also study a share-and-transmit scheme\nfor transmitter cooperation. For the share-and-transmit scheme, we show how the\ngains of transmitter cooperation are entirely offset by the cost of enabling\nthat cooperation so that the available degrees of freedom are not increased. \n\n"}
{"id": "cs/0511039", "contents": "Title: The Generalized Area Theorem and Some of its Consequences Abstract: There is a fundamental relationship between belief propagation and maximum a\nposteriori decoding. The case of transmission over the binary erasure channel\nwas investigated in detail in a companion paper. This paper investigates the\nextension to general memoryless channels (paying special attention to the\nbinary case). An area theorem for transmission over general memoryless channels\nis introduced and some of its many consequences are discussed. We show that\nthis area theorem gives rise to an upper-bound on the maximum a posteriori\nthreshold for sparse graph codes. In situations where this bound is tight, the\nextrinsic soft bit estimates delivered by the belief propagation decoder\ncoincide with the correct a posteriori probabilities above the maximum a\nposteriori threshold. More generally, it is conjectured that the fundamental\nrelationship between the maximum a posteriori and the belief propagation\ndecoder which was observed for transmission over the binary erasure channel\ncarries over to the general case. We finally demonstrate that in order for the\ndesign rate of an ensemble to approach the capacity under belief propagation\ndecoding the component codes have to be perfectly matched, a statement which is\nwell known for the special case of transmission over the binary erasure\nchannel. \n\n"}
{"id": "cs/0602054", "contents": "Title: Explicit Space-Time Codes Achieving The Diversity-Multiplexing Gain\n  Tradeoff Abstract: A recent result of Zheng and Tse states that over a quasi-static channel,\nthere exists a fundamental tradeoff, referred to as the diversity-multiplexing\ngain (D-MG) tradeoff, between the spatial multiplexing gain and the diversity\ngain that can be simultaneously achieved by a space-time (ST) block code. This\ntradeoff is precisely known in the case of i.i.d. Rayleigh-fading, for T>=\nn_t+n_r-1 where T is the number of time slots over which coding takes place and\nn_t,n_r are the number of transmit and receive antennas respectively. For T <\nn_t+n_r-1, only upper and lower bounds on the D-MG tradeoff are available.\n  In this paper, we present a complete solution to the problem of explicitly\nconstructing D-MG optimal ST codes, i.e., codes that achieve the D-MG tradeoff\nfor any number of receive antennas. We do this by showing that for the square\nminimum-delay case when T=n_t=n, cyclic-division-algebra (CDA) based ST codes\nhaving the non-vanishing determinant property are D-MG optimal. While\nconstructions of such codes were previously known for restricted values of n,\nwe provide here a construction for such codes that is valid for all n.\n  For the rectangular, T > n_t case, we present two general techniques for\nbuilding D-MG-optimal rectangular ST codes from their square counterparts. A\nbyproduct of our results establishes that the D-MG tradeoff for all T>= n_t is\nthe same as that previously known to hold for T >= n_t + n_r -1. \n\n"}
{"id": "cs/0602071", "contents": "Title: Geographic Gossip: Efficient Aggregation for Sensor Networks Abstract: Gossip algorithms for aggregation have recently received significant\nattention for sensor network applications because of their simplicity and\nrobustness in noisy and uncertain environments. However, gossip algorithms can\nwaste significant energy by essentially passing around redundant information\nmultiple times. For realistic sensor network model topologies like grids and\nrandom geometric graphs, the inefficiency of gossip schemes is caused by slow\nmixing times of random walks on those graphs. We propose and analyze an\nalternative gossiping scheme that exploits geographic information. By utilizing\na simple resampling method, we can demonstrate substantial gains over\npreviously proposed gossip protocols. In particular, for random geometric\ngraphs, our algorithm computes the true average to accuracy $1/n^a$ using\n$O(n^{1.5}\\sqrt{\\log n})$ radio transmissions, which reduces the energy\nconsumption by a $\\sqrt{\\frac{n}{\\log n}}$ factor over standard gossip\nalgorithms. \n\n"}
{"id": "cs/0607095", "contents": "Title: Gallager's Exponent for MIMO Channels: A Reliability-Rate Tradeoff Abstract: In this paper, we derive Gallager's random coding error exponent for\nmultiple-input multiple-output (MIMO) channels, assuming no channel-state\ninformation (CSI) at the transmitter and perfect CSI at the receiver. This\nmeasure gives insight into a fundamental tradeoff between the communication\nreliability and information rate of MIMO channels, enabling to determine the\nrequired codeword length to achieve a prescribed error probability at a given\nrate below the channel capacity. We quantify the effects of the number of\nantennas, channel coherence time, and spatial fading correlation on the MIMO\nexponent. In addition, general formulae for the ergodic capacity and the cutoff\nrate in the presence of spatial correlation are deduced from the exponent\nexpressions. These formulae are applicable to arbitrary structures of transmit\nand receive correlation, encompassing all the previously known results as\nspecial cases of our expressions. \n\n"}
{"id": "cs/0610047", "contents": "Title: Capacity of the Trapdoor Channel with Feedback Abstract: We establish that the feedback capacity of the trapdoor channel is the\nlogarithm of the golden ratio and provide a simple communication scheme that\nachieves capacity. As part of the analysis, we formulate a class of dynamic\nprograms that characterize capacities of unifilar finite-state channels. The\ntrapdoor channel is an instance that admits a simple analytic solution. \n\n"}
{"id": "cs/0610077", "contents": "Title: MIMO Broadcast Channels with Block Diagonalization and Finite Rate\n  Feedback Abstract: Block diagonalization is a linear precoding technique for the multiple\nantenna broadcast (downlink) channel that involves transmission of multiple\ndata streams to each receiver such that no multi-user interference is\nexperienced at any of the receivers. This low-complexity scheme operates only a\nfew dB away from capacity but does require very accurate channel knowledge at\nthe transmitter, which can be very difficult to obtain in fading scenarios. We\nconsider a limited feedback system where each receiver knows its channel\nperfectly, but the transmitter is only provided with a finite number of channel\nfeedback bits from each receiver. Using a random vector quantization argument,\nwe quantify the throughput loss due to imperfect channel knowledge as a\nfunction of the feedback level. The quality of channel knowledge must improve\nproportional to the SNR in order to prevent interference-limitations, and we\nshow that scaling the number of feedback bits linearly with the system SNR is\nsufficient to maintain a bounded rate loss. Finally, we investigate a simple\nscalar quantization scheme that is seen to achieve the same scaling behavior as\nvector quantization. \n\n"}
{"id": "cs/0702018", "contents": "Title: Estimation of the Rate-Distortion Function Abstract: Motivated by questions in lossy data compression and by theoretical\nconsiderations, we examine the problem of estimating the rate-distortion\nfunction of an unknown (not necessarily discrete-valued) source from empirical\ndata. Our focus is the behavior of the so-called \"plug-in\" estimator, which is\nsimply the rate-distortion function of the empirical distribution of the\nobserved data. Sufficient conditions are given for its consistency, and\nexamples are provided to demonstrate that in certain cases it fails to converge\nto the true rate-distortion function. The analysis of its performance is\ncomplicated by the fact that the rate-distortion function is not continuous in\nthe source distribution; the underlying mathematical problem is closely related\nto the classical problem of establishing the consistency of maximum likelihood\nestimators. General consistency results are given for the plug-in estimator\napplied to a broad class of sources, including all stationary and ergodic ones.\nA more general class of estimation problems is also considered, arising in the\ncontext of lossy data compression when the allowed class of coding\ndistributions is restricted; analogous results are developed for the plug-in\nestimator in that case. Finally, consistency theorems are formulated for\nmodified (e.g., penalized) versions of the plug-in, and for estimating the\noptimal reproduction distribution. \n\n"}
{"id": "cs/0702070", "contents": "Title: A Practical Approach to Lossy Joint Source-Channel Coding Abstract: This work is devoted to practical joint source channel coding. Although the\nproposed approach has more general scope, for the sake of clarity we focus on a\nspecific application example, namely, the transmission of digital images over\nnoisy binary-input output-symmetric channels. The basic building blocks of most\nstate-of the art source coders are: 1) a linear transformation; 2) scalar\nquantization of the transform coefficients; 3) probability modeling of the\nsequence of quantization indices; 4) an entropy coding stage. We identify the\nweakness of the conventional separated source-channel coding approach in the\ncatastrophic behavior of the entropy coding stage. Hence, we replace this stage\nwith linear coding, that maps directly the sequence of redundant quantizer\noutput symbols into a channel codeword. We show that this approach does not\nentail any loss of optimality in the asymptotic regime of large block length.\nHowever, in the practical regime of finite block length and low decoding\ncomplexity our approach yields very significant improvements. Furthermore, our\nscheme allows to retain the transform, quantization and probability modeling of\ncurrent state-of the art source coders, that are carefully matched to the\nfeatures of specific classes of sources. In our working example, we make use of\n``bit-planes'' and ``contexts'' model defined by the JPEG2000 standard and we\nre-interpret the underlying probability model as a sequence of conditionally\nMarkov sources. The Markov structure allows to derive a simple successive\ncoding and decoding scheme, where the latter is based on iterative Belief\nPropagation. We provide a construction example of the proposed scheme based on\npunctured Turbo Codes and we demonstrate the gain over a conventional separated\nscheme by running extensive numerical experiments on test images. \n\n"}
{"id": "cs/0702101", "contents": "Title: An identity of Chernoff bounds with an interpretation in statistical\n  physics and applications in information theory Abstract: An identity between two versions of the Chernoff bound on the probability a\ncertain large deviations event, is established. This identity has an\ninterpretation in statistical physics, namely, an isothermal equilibrium of a\ncomposite system that consists of multiple subsystems of particles. Several\ninformation--theoretic application examples, where the analysis of this large\ndeviations probability naturally arises, are then described from the viewpoint\nof this statistical mechanical interpretation. This results in several\nrelationships between information theory and statistical physics, which we\nhope, the reader will find insightful. \n\n"}
{"id": "math/0302172", "contents": "Title: Results on zeta functions for codes Abstract: We give a new and short proof of the Mallows-Sloane upper bound for self-dual\ncodes. We formulate a version of Greene's theorem for normalized weight\nenumerators. We relate normalized rank-generating polynomials to two-variable\nzeta functions. And we show that a self-dual code has the Clifford property,\nbut that the same property does not hold in general for formally self-dual\ncodes. \n\n"}
{"id": "math/0404325", "contents": "Title: Asymptotic Improvement of the Gilbert-Varshamov Bound on the Size of\n  Binary Codes Abstract: Given positive integers $n$ and $d$, let $A_2(n,d)$ denote the maximum size\nof a binary code of length $n$ and minimum distance $d$. The well-known\nGilbert-Varshamov bound asserts that $A_2(n,d) \\geq 2^n/V(n,d-1)$, where\n$V(n,d) = \\sum_{i=0}^{d} {n \\choose i}$ is the volume of a Hamming sphere of\nradius $d$. We show that, in fact, there exists a positive constant $c$ such\nthat $$ A_2(n,d) \\geq c \\frac{2^n}{V(n,d-1)} \\log_2 V(n,d-1) $$ whenever $d/n\n\\le 0.499$. The result follows by recasting the Gilbert- Varshamov bound into a\ngraph-theoretic framework and using the fact that the corresponding graph is\nlocally sparse. Generalizations and extensions of this result are briefly\ndiscussed. \n\n"}
{"id": "math/0606734", "contents": "Title: Codes in spherical caps Abstract: We consider bounds on codes in spherical caps and related problems in\ngeometry and coding theory. An extension of the Delsarte method is presented\nthat relates upper bounds on the size of spherical codes to upper bounds on\ncodes in caps. Several new upper bounds on codes in caps are derived.\nApplications of these bounds to estimates of the kissing numbers and one-sided\nkissing numbers are considered.\n  It is proved that the maximum size of codes in spherical caps for large\ndimensions is determined by the maximum size of spherical codes, so these\nproblems are asymptotically equivalent. \n\n"}
{"id": "quant-ph/0612052", "contents": "Title: Deciding whether a quantum state has secret correlations is an\n  NP-complete problem Abstract: From the NP-hardness of the quantum separability problem and the relation\nbetween bipartite entanglement and the secret key correlations, it is shown\nthat the problem deciding whether a given quantum state has secret correlations\nin it or not is in NP-complete. \n\n"}
