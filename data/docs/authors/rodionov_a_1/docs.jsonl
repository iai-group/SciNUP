{"id": "0704.0022", "contents": "Title: Stochastic Lie group integrators Abstract: We present Lie group integrators for nonlinear stochastic differential\nequations with non-commutative vector fields whose solution evolves on a smooth\nfinite dimensional manifold. Given a Lie group action that generates transport\nalong the manifold, we pull back the stochastic flow on the manifold to the Lie\ngroup via the action, and subsequently pull back the flow to the corresponding\nLie algebra via the exponential map. We construct an approximation to the\nstochastic flow in the Lie algebra via closed operations and then push back to\nthe Lie group and then to the manifold, thus ensuring our approximation lies in\nthe manifold. We call such schemes stochastic Munthe-Kaas methods after their\ndeterministic counterparts. We also present stochastic Lie group integration\nschemes based on Castell--Gaines methods. These involve using an underlying\nordinary differential integrator to approximate the flow generated by a\ntruncated stochastic exponential Lie series. They become stochastic Lie group\nintegrator schemes if we use Munthe-Kaas methods as the underlying ordinary\ndifferential integrator. Further, we show that some Castell--Gaines methods are\nuniformly more accurate than the corresponding stochastic Taylor schemes.\nLastly we demonstrate our methods by simulating the dynamics of a free rigid\nbody such as a satellite and an autonomous underwater vehicle both perturbed by\ntwo independent multiplicative stochastic noise processes. \n\n"}
{"id": "0704.2548", "contents": "Title: Triggering at High Luminosity Colliders Abstract: This article discusses the techniques used to select online promising events\nat high energy and high luminosity colliders. After a brief introduction,\nexplaining some general aspects of triggering, the more specific implementation\noptions for well established machines like the Tevatron and Large Hadron\nCollider are presented. An outlook on what difficulties need to be met is given\nwhen designing trigger systems at the Super Large Hadron Collider, or at the\nInternational Linear Collider \n\n"}
{"id": "0705.4448", "contents": "Title: On partial polynomial interpolation Abstract: The Alexander-Hirschowitz theorem says that a general collection of $k$\ndouble points in ${\\bf P}^n$ imposes independent conditions on homogeneous\npolynomials of degree $d$ with a well known list of exceptions. We generalize\nthis theorem to arbitrary zero-dimensional schemes contained in a general union\nof double points. We work in the polynomial interpolation setting. In this\nframework our main result says that the affine space of polynomials of degree\n$\\le d$ in $n$ variables, with assigned values of any number of general linear\ncombinations of first partial derivatives, has the expected dimension if $d\\neq\n2$ with only five exceptional cases. If $d=2$ the exceptional cases are fully\ndescribed. \n\n"}
{"id": "0707.0729", "contents": "Title: Pair production of the heavy leptons in future high energy linear\n  e^{+}e^{-} colliders Abstract: The littlest Higgs model with T-parity predicts the existence of the T-odd\nparticles, which can only be produced in pair. We consider pair production of\nthe T-odd leptons in future high energy linear $e^{+}e^{-}$ collider ($ILC$).\nOur numerical results show that, as long as the T-odd leptons are not too\nheavy, they can be copiously produced and their possible signals might be\ndetected via the processes $e^{+}e^{-}\\to \\bar{L}_{i}L_{j}$ in future $ILC$\nexperiments. \n\n"}
{"id": "0707.0841", "contents": "Title: Neutrino masses, mixing and leptogenesis in TeV scale B-L extension of\n  the standard model Abstract: We address the issue of the neutrino masses and mixing in TeV scale $B-L$\nextension of the Standard Model. We show that if Dirac neutrino masses are of\norder $10^{-4}$ Gev, then the measured neutrino masses are correctly obtained.\nWe propose a mass relation between quarks and leptons that may account for such\nsmall Dirac neutrino masses. We analyze the leptogenesis in this type of models\nand provide analytical expressions for the new contributions due to the\npredicted extra Higgs and extra neutral gauge boson. We find that thermal\nleptogenesis, with a resonant enhancement due to nearly degenerate right-handed\nneutrinos, can yield sufficient baryon asymmetry. Finally, we comment on a\npossible scheme for non-thermal leptogenesis, which is due to the decay of\nextra Higgs into right-handed neutrino. \n\n"}
{"id": "0708.1347", "contents": "Title: Quantized Non-Abelian Monopoles on S^3 Abstract: A possible electric-magnetic duality suggests that the confinement of\nnon-Abelian electric charges manifests itself as a perturbative quantum effect\nfor the dual magnetic charges. Motivated by this possibility, we study vacuum\nfluctuations around a non-Abelian monopole-antimonopole pair treated as point\nobjects with charges g=\\pm n/2 (n=1,2,...), and placed on the antipodes of a\nthree sphere of radius R. We explicitly find all the fluctuation modes by\nlinearizing and solving the Yang-Mills equations about this background field on\na three sphere. We recover, generalize and extend earlier results, including\nthose on the stability analysis of non-Abelian magnetic monopoles. We find that\nfor g \\ge 1 monopoles there is an unstable mode that tends to squeeze magnetic\nflux in the angular directions. We sum the vacuum energy contributions of the\nfluctuation modes for the g=1/2 case and find oscillatory dependence on the\ncutoff scale. Subject to certain assumptions, we find that the contribution of\nthe fluctuation modes to the quantum zero point energy behaves as -R^{-2/3} and\nhence decays more slowly than the classical -R^{-1} Coulomb potential for large\nR. However, this correction to the zero point energy does not agree with the\nlinear growth expected if the monopoles are confined. \n\n"}
{"id": "0709.0497", "contents": "Title: Hard spectator interactions in B to pi pi at order alpha_s^2 Abstract: In the present thesis I discuss the hard spectator interaction amplitude in\n$B\\to\\pi\\pi$ at NLO i.e. at $\\mathcal{O}(\\alpha_s^2)$. This special part of the\namplitude, whose LO starts at $\\mathcal{O}(\\alpha_s)$, is defined in the\nframework of QCD factorization. QCD factorization allows to separate the short-\nand the long-distance physics in leading power in an expansion in $\\lqcd/m_b$,\nwhere the short-distance physics can be calculated in a perturbative expansion\nin $\\alpha_s$. Compared to other parts of the amplitude hard spectator\ninteractions are formally enhanced by the hard collinear scale $\\sqrt{\\lqcd\nm_b}$, which occurs next to the $m_b$-scale and leads to an enhancement of\n$\\alpha_s$.\n  From a technical point of view the main challenges of this calculation are\ndue to the fact that we have to deal with Feynman integrals that come with up\nto five external legs and with three independent ratios of scales. These\nFeynman integrals have to be expanded in powers of $\\lqcd/m_b$. I will discuss\nintegration by parts identities to reduce the number of master integrals and\ndifferential equations techniques to get their power expansions. A concrete\nimplementation of integration by parts identities in a computer algebra system\nis given in the appendix.\n  Finally I discuss numerical issues like scale dependence of the amplitudes\nand branching ratios. It will turn out that the NLO contributions of the hard\nspectator interactions are important but small enough for perturbation theory\nto be valid \n\n"}
{"id": "0709.0739", "contents": "Title: Reply to Comment on the paper ``Energy Loss of Charm Quarks in the\n  Quark-Gluon Plasma: Collisional vs Radiative'' by Mishra et al Abstract: The comments raised in Ref. [1] by Mishra et al aim at two papers contained\nin Ref. [2]. We show that those comments on Ref. [2] pointed out by Mishra et\nal in Ref.[1] are not relevant and the concept used in Ref.[2] is consistent\nand in compliance with the classical approximation of the transport\ncoefficients [3]. We would also like to note that most of the comments in Ref.\n[1] were meant for light quarks, but are not even appropriate for heavy quarks. \n\n"}
{"id": "0709.4119", "contents": "Title: Idempotent and tropical mathematics and problems of mathematical physics\n  (Volume II) Abstract: This volume contains the proceedings of an International Workshop on\nIdempotent and Tropical Mathematics and Problems of Mathematical Physics, held\nat the Independent University of Moscow, Russia, on August 25-30, 2007. \n\n"}
{"id": "0710.3387", "contents": "Title: Energy Dependence of the Delta Resonance: Chiral Dynamics in Action Abstract: There is an important connection between the low energy theorems of QCD and\nthe energy dependence of the Delta resonance in pi-N scattering, as well as the\nclosely related gamma^{*} N -> pi N reaction. The resonance shape is due not\nonly to the strong pi-N interaction in the p wave but the small interaction in\nthe s wave; the latter is due to spontaneous chiral symmetry breaking in QCD\n(i.e. the Nambu-Goldstone nature of the pion). A brief overview of experimental\ntests of chiral perturbation theory and chiral based models is presented \n\n"}
{"id": "0710.5699", "contents": "Title: Leptoquarks: Neutrino masses and accelerator phenomenology Abstract: Leptoquark-Higgs interactions induce mixing between leptoquark states with\ndifferent chiralities once the electro-weak symmetry is broken. In such LQ\nmodels Majorana neutrino masses are generated at 1-loop order. Here we\ncalculate the neutrino mass matrix and explore the constraints on the parameter\nspace enforced by the assumption that LQ-loops explain current neutrino\noscillation data. LQs will be produced at the LHC, if their masses are at or\nbelow the TeV scale. Since the fermionic decays of LQs are governed by the same\nYukawa couplings, which are responsible for the non-trivial neutrino mass\nmatrix, several decay branching ratios of LQ states can be predicted from\nmeasured neutrino data. Especially interesting is that large lepton flavour\nviolating rates in muon and tau final states are expected. In addition, the\nmodel predicts that, if kinematically possible, heavier LQs decay into lighter\nones plus either a standard model Higgs boson or a $Z^0/W^{\\pm}$ gauge boson.\nThus, experiments at the LHC might be able to exclude the LQ mechanism as\nexplanation of neutrino data. \n\n"}
{"id": "0711.2014", "contents": "Title: AdS-QCD quark-antiquark potential, meson spectrum and tetraquarks Abstract: AdS/QCD correspondence predicts the structure of quark-antiquark potential in\nthe static limit. We use this piece of information together with the Salpeter\nequation (Schr\\\"odinger equation with relativistic kinematics) and a short\nrange hyperfine splitting potential to determine quark masses and the quark\npotential parameters from the meson spectrum. The agreement between theory and\nexperimental data is satisfactory provided one considers only mesons comprising\nat least one heavy quark. We use the same potential (in the one-gluon-exchange\napproximation) and these data to estimate constituent diquark masses. Using\nthese results as an input we compute tetraquark masses using a\ndiquark-antidiquark model. The masses of the states X(3872) or Y(3940) are\npredicted rather accurately. We also compute tetraquark masses with open charm\nand strangeness. Our result is that tetraquark candidates such as D_s(2317),\nD_s(2457) or X(2632) can hardly be interpreted as diquark-antidiquark states\nwithin the present approach. \n\n"}
{"id": "0711.2020", "contents": "Title: CP-violating Loop Effects in the Higgs Sector of the MSSM Abstract: CP-violating effects in the Higgs sector of the Minimal Supersymmetric\nStandard Model with complex parameters (cMSSM) are induced by potentially large\nhigher-order corrections. As a consequence, all three neutral Higgs bosons can\nmix with each other. Recent results for loop corrections in the Higgs sector of\nthe cMSSM are reviewed. Results for propagator-type corrections of O(alpha_t\nalpha_s) and complete one-loop results for Higgs cascade decays of the kind h_a\n-> h_b h_c are summarised, and the proper treatment of external Higgs bosons in\nHiggs-boson production and decay processes is discussed. \n\n"}
{"id": "0712.3759", "contents": "Title: Third Family Corrections to Quark and Lepton Mixing in SUSY Models with\n  non-Abelian Family Symmetry Abstract: We re-analyse the effect of corrections from canonical normalisation of\nkinetic terms on the quark and lepton mixing angles. This type of corrections\nemerges, for example, from effective higher-dimensional Kahler potential\noperators in the context of locally supersymmetric models of flavour. In\ncontrast to previous studies we find that the necessary procedure of redefining\nthe fields in order to restore canonically normalised kinetic terms, i.e.\ncanonical normalisation, can lead to significant corrections to the fermion\nmixing angles (as determined from the superpotential). Such potentially large\neffects are characteristic of flavour models based on non-Abelian family\nsymmetries, where some of the possible Kahler potential (and superpotential)\noperators, in particular those associated with the third family, are only\nmildly suppressed. We investigate under which conditions the messenger sector\nof such flavour models generates such Kahler potential operators for which the\ncanonical normalisation effects are sizeable, and under which conditions these\noperators may be absent and canonical normalisation effects are small. As\nexplicit examples for potentially relevant CN effects, we will discuss the\ncorrections to the CKM matrix element |V_{cb}| as well as corrections to\ntri-bimaximal neutrino mixing. \n\n"}
{"id": "0712.4129", "contents": "Title: Detectors and flux instrumentation for future neutrino facilities Abstract: This report summarises the conclusions from the detector group of the\nInternational Scoping Study of a future Neutrino Factory and Super-Beam\nneutrino facility. The baseline detector options for each possible neutrino\nbeam are defined as follows:\n  1. A very massive (Megaton) water Cherenkov detector is the baseline option\nfor a sub-GeV Beta Beam and Super Beam facility.\n  2. There are a number of possibilities for either a Beta Beam or Super Beam\n(SB) medium energy facility between 1-5 GeV. These include a totally active\nscintillating detector (TASD), a liquid argon TPC or a water Cherenkov\ndetector.\n  3. A 100 kton magnetized iron neutrino detector (MIND) is the baseline to\ndetect the wrong sign muon final states (golden channel) at a high energy\n(20-50 GeV) neutrino factory from muon decay. A 10 kton hybrid neutrino\nmagnetic emulsion cloud chamber detector for wrong sign tau detection (silver\nchannel) is a possible complement to MIND, if one needs to resolve degeneracies\nthat appear in the $\\delta$-$\\theta_{13}$ parameter space. \n\n"}
{"id": "0801.2157", "contents": "Title: ISS-flation Abstract: Inflation may occur while rolling into the metastable supersymmetry-breaking\nvacuum of massive supersymmetric QCD. We explore the range of parameters in\nwhich slow-roll inflation and long-lived metastable supersymmetry breaking may\nbe simultaneously realized. The end of slow-roll inflation in this context\ncoincides with the spontaneous breaking of a global symmetry, which may give\nrise to significant curvature perturbations via inhomogenous preheating. Such\nspontaneous symmetry breaking at the end of inflation may give rise to\nobservable non-gaussianities, distinguishing this scenario from more\nconventional models of supersymmetric hybrid inflation. \n\n"}
{"id": "0803.0246", "contents": "Title: Unraveling duality violations in hadronic tau decays Abstract: There are some indications from recent determinations of the strong coupling\nconstant alpha_s and the gluon condensate that the Operator Product Expansion\nmay not be accurate enough to describe non-perturbative effects in hadronic tau\ndecays. This breakdown of the Operator Product Expansion is usually referred to\nas being due to ``Duality Violations.'' With the help of a physically motivated\nmodel, we investigate these duality violations. Based on this model, we argue\nhow they may introduce a non-negligible systematic error in the current\nanalysis, which employs finite-energy sum rules with pinched weights. In\nparticular, this systematic effect might affect the precision determination of\nalpha_s from tau decays. With a view to a possible future application to real\ndata, we present an alternative method for determining the OPE coefficients\nthat might help estimating, and possibly even reducing, this systematic error. \n\n"}
{"id": "0803.1400", "contents": "Title: Tops from Light Quarks: Full Mass Dependence at Two-Loops in QCD Abstract: I present the two-loop QCD corrections to the production of a massive\nquark-anti-quark pair in the massless quark-anti-quark annihilation channel.\nThe result is obtained as a combination of a deep expansion in the mass around\nthe high energy limit and of a numerical integration of a system of\ndifferential equations. The primary application of the outcome and developed\nmethods is top quark pair production at the Large Hadron Collider. \n\n"}
{"id": "0804.2295", "contents": "Title: Charmed Scalar Resonances Abstract: It is pointed out that assigning D_{s0}^+(2317) to an iso-triplet tetra-quark\nmeson is favored by experiments. It also is discussed why its neutral and\ndoubly charged partners have never been observed in inclusive e^+e^-\nannihilation. To search for them, hadronic weak decays of B mesons would be\nbetter, and their production rates, Br(B_u^+ -> D^-D_{s0}^{++}(2317)) and\nBr(B_d^0 ->antiD^0D_{s0}^{0}(2317)), would be around 10^{-3}. \n\n"}
{"id": "0804.2549", "contents": "Title: Simulations of light scalar mesons on the lattice and related\n  difficulties Abstract: I review the lattice simulations of light scalar mesons with quark-antiquark\nand tetraquark interpolating fields. Several difficulties which complicate the\nextraction of scalar meson masses from the scalar correlators are pointed out.\nOne of the major difficulties is the presence of the two-pseudoscalar\nscattering states, which often dominate the correlator at light quark masses.\nIn the simulations with unphysical approximations such scattering contributions\nare even more disturbing since they are often large and sometimes negative.\nTechniques which allow extraction of scalar meson masses in presence of\nscattering states are listed. Preliminary results of various lattice\ncollaborations are presented. \n\n"}
{"id": "0804.3239", "contents": "Title: The economical SU(3)_C X SU(3)_L X U(1)_X model Abstract: In this report the SU(3)_C X SU(3)_L X U(1)_X gauge model with minimal scalar\nsector, two Higgs triplets, is presented in detail. One of the vacuum\nexpectation values $u$ is a source of lepton-number violations and a reason for\nmixing among charged gauge bosons--the standard model W^\\pm and the bilepton\ngauge bosons Y^\\pm as well as among the neutral non-Hermitian bilepton X^0 and\nneutral gauge bosons--the Z and the new Z'. An exact diagonalization of the\nneutral gauge boson sector is derived and bilepton mass splitting is also\ngiven. Because of these mixings, the lepton-number violating interactions exist\nin both charged and neutral gauge boson sectors. Constraints on vacuum\nexpectation values of the model are estimated and u \\simeq O(1) GeV, v \\simeq\nv_weak = 246 GeV, and \\omega \\simeq O(1) TeV. In this model there are three\nphysical scalars, two neutral and one charged, and eight Goldstone bosons--the\nneeded number for massive gauge bosons. The minimal scalar sector can provide\nall fermions including quarks and neutrinos consistent masses in which some of\nthem require one-loop radiative corrections. \n\n"}
{"id": "0804.3490", "contents": "Title: An Approach towards a Constituent Quark Model on the Light Cone Abstract: We use the vacuum expectation value of a Wegner-Wilson loop representing a\nfast moving quark-antiquark pair to derive the light cone Hamiltonian for a\n$q\\bar q$ meson. We solve the corresponding Schr\\\"odinger equation for various\ntrial wave functions. The result shows how confinement determines the meson\nmass and wave function for valence quarks on the light cone. We also\nparametrize the effect of the spin-dependent splitting for a light meson and\ncharmonium. The correct chiral-symmetry breaking pattern for the pion mass is\nobtained due to the self-energy of the quark. \n\n"}
{"id": "0805.4642", "contents": "Title: Macroscopic Strings and \"Quirks\" at Colliders Abstract: We consider extensions of the standard model containing additional heavy\nparticles (\"quirks\") charged under a new unbroken non-abelian gauge group as\nwell as the standard model. We assume that the quirk mass m is in the\nphenomenologically interesting range 100 GeV--TeV, and that the new gauge group\ngets strong at a scale Lambda < m. In this case breaking of strings is\nexponentially suppressed, and quirk production results in strings that are long\ncompared to 1/Lambda. The existence of these long stable strings leads to\nhighly exotic events at colliders. For 100 eV < Lambda < keV the strings are\nmacroscopic, giving rise to events with two separated quirk tracks with\nmeasurable curvature toward each other due to the string interaction. For keV <\nLambda < MeV the typical strings are mesoscopic: too small to resolve in the\ndetector, but large compared to atomic scales. In this case, the bound state\nappears as a single particle, but its mass is the invariant mass of a quirk\npair, which has an event-by-event distribution. For MeV < Lambda < m the\nstrings are microscopic, and the quirks annihilate promptly within the\ndetector. For colored quirks, this can lead to hadronic fireball events with\n10^3 hadrons with energy of order GeV emitted in conjunction with hard decay\nproducts from the final annihilation. \n\n"}
{"id": "0806.3698", "contents": "Title: Scalar Meson Photoproduction Abstract: The light-quark non-strange scalar mesons a0(980), f0(980), f0(1370),\na0(1450), f0(1500) and f0(1710) are of great interest as there is no generally\naccepted view of their structure which can encompass q-q-qbar-qbar, molecular,\nq-qbar and glueball states in various combinations. It has been shown\npreviously that the radiative decays of the scalar mesons to rho and omega are\na good probe of their structure and provide good discrimination among models.\nScalar meson photoproduction is proposed as an alternative to measuring\nradiative decays and it is shown that it is a feasible proposition. \n\n"}
{"id": "0806.4172", "contents": "Title: Prediction of a Photon Peak in Heavy Ion Collisions Abstract: We show that if a flavour-less vector meson remains bound after\ndeconfinement, and if its limiting velocity in the quark-gluon plasma is\nsubluminal, then this meson produces a distinct peak in the spectrum of thermal\nphotons emitted by the plasma. We also demonstrate that this effect is a\nuniversal property of all strongly coupled, large-Nc plasmas with a gravity\ndual. For the J/psi the corresponding peak lies between 3 and 5 GeV and could\nbe observed at LHC. \n\n"}
{"id": "0807.1138", "contents": "Title: Spectral Analysis of Gluonic Pole Matrix Elements Abstract: We use a spectator framework to investigate the spectral properties of\nquark-quark-gluon correlators and use this to study gluonic pole matrix\nelements. Such matrix elements appear in principle both for distribution\nfunctions such as the Sivers function and fragmentation functions such as the\nCollins function. We find that the contribution of the gluonic pole matrix\nelement in fragmentation functions vanishes. This outcome is important in the\nstudy of universality for fragmentation functions. \n\n"}
{"id": "0808.1142", "contents": "Title: Electroweak corrections to $t\\bar{t}$ production at hadron colliders Abstract: We report on our recent work on electroweak corrections to $t\\bar{t}$\nproduction at hadron colliders. Specifically, we discuss the weak-interaction\ncontributions to the top quark transverse momentum and $t \\bar{t}$ invariant\nmass distributions and an induced parity-violating top-spin asymmetry. \n\n"}
{"id": "0808.2886", "contents": "Title: Transversity Asymmetries Abstract: Ways to access transversity through asymmetry measurements are reviewed. The\nrecent first extraction and possible near future extractions are discussed. \n\n"}
{"id": "0809.3875", "contents": "Title: On spectral minimal partitions II, the case of the rectangle Abstract: In continuation of \\cite{HHOT}, we discuss the question of spectral minimal\n3-partitions for the rectangle $]-\\frac a2,\\frac a2[\\times ] -\\frac b2,\\frac\nb2[ $, with $0< a\\leq b$. It has been observed in \\cite{HHOT} that when\n$0<\\frac ab < \\sqrt{\\frac 38}$ the minimal 3-partition is obtained by the three\nnodal domains of the third eigenfunction corresponding to the three rectangles\n$]-\\frac a2,\\frac a2[\\times ] -\\frac b2,-\\frac b6[$, $]-\\frac a2,\\frac\na2[\\times ] -\\frac b6,\\frac b6[$ and $]-\\frac a2,\\frac a2[\\times ] \\frac b6,\n\\frac b2[$. We will describe a possible mechanism of transition for increasing\n$\\frac ab$ between these nodal minimal 3-partitions and non nodal minimal\n3-partitions at the value $ \\sqrt{\\frac 38}$ and discuss the existence of\nsymmetric candidates for giving minimal 3-partitions when $ \\sqrt{\\frac\n38}<\\frac ab \\leq 1$. Numerical analysis leads very naturally to nice questions\nof isospectrality which are solved by introducing Aharonov-Bohm Hamiltonians or\nby going on the double covering of the punctured rectangle. \n\n"}
{"id": "0810.2906", "contents": "Title: Screening of light mesons and charmonia at high temperature Abstract: We present lattice QCD results for the screening masses of light mesons and\ncharmonia. The lattice computations were performed with 2+1 flavors of improved\nstaggered quarks using quark masses which correspond to realistic pion and kaon\nmasses at zero temperature. For the light quark sector we have found that the\nscreening masses in the pseudo-scalar and the isovector scalar channels do not\nbecome degenerate at the chiral crossover temperature indicating an effective\nnon-restoration of the axial symmetry. Also the splitting between the vector\nand the pseudo-scalar screening masses persists even in the limit of zero\nlattice spacing and at a moderately high temperature around 420 MeV. In the\ncharmonium sector our investigation shows that the screening masses of the\npseudo-scalar and the vector charmonia are almost (within a few percent) equal\nto their zero temperature masses for temperatures less than 300 MeV. We also\npresent results for the charmonium screening masses using periodic boundary\nconditions along the temporal direction and discuss their implications. \n\n"}
{"id": "0810.4225", "contents": "Title: Nonnegative Factorization and The Maximum Edge Biclique Problem Abstract: Nonnegative Matrix Factorization (NMF) is a data analysis technique which\nallows compression and interpretation of nonnegative data. NMF became widely\nstudied after the publication of the seminal paper by Lee and Seung (Learning\nthe Parts of Objects by Nonnegative Matrix Factorization, Nature, 1999, vol.\n401, pp. 788--791), which introduced an algorithm based on Multiplicative\nUpdates (MU). More recently, another class of methods called Hierarchical\nAlternating Least Squares (HALS) was introduced that seems to be much more\nefficient in practice.\n  In this paper, we consider the problem of approximating a not necessarily\nnonnegative matrix with the product of two nonnegative matrices, which we refer\nto as Nonnegative Factorization (NF); this is the subproblem that HALS methods\nimplicitly try to solve at each iteration. We prove that NF is NP-hard for any\nfixed factorization rank, using a reduction to the maximum edge biclique\nproblem.\n  We also generalize the multiplicative updates to NF, which allows us to shed\nsome light on the differences between the MU and HALS algorithms for NMF and\ngive an explanation for the better performance of HALS. Finally, we link\nstationary points of NF with feasible solutions of the biclique problem to\nobtain a new type of biclique finding algorithm (based on MU) whose iterations\nhave an algorithmic complexity proportional to the number of edges in the\ngraph, and show that it performs better than comparable existing methods. \n\n"}
{"id": "0810.5467", "contents": "Title: Design of a Nanometer Beam Size Monitor for ATF2 Abstract: We developed an electron beam size monitor for extremely small beam sizes. It\nuses a laser interference fringe for a scattering target with the electron\nbeam. Our target performance is < 2 nm systematic error for 37 nm beam size and\n< 10% statistical error in a measurement using 90 electron bunches for 25 -\n6000 nm beam size. A precise laser interference fringe control system using an\nactive feedback function is incorporated to the monitor to achieve the target\nperformance. We describe an overall design, implementations, and performance\nestimations of the monitor. \n\n"}
{"id": "0810.5667", "contents": "Title: QCD plasma equilibration, elliptic flow and jet-quenching - phenomena of\n  common origin Abstract: Fast thermalization, a subsequent strong buildup of elliptic flow of QCD\nmatter and jet-quenching as found at the Relativistic Heavy Ion Collider (RHIC)\nare understood as the consequence of perturbative QCD (pQCD) interactions\nwithin the 3+1 dimensional parton cascade BAMPS. The main contributions stem\nfrom pQCD inspired bremsstrahlung. Comparisons to Au+Au data of the flow\nparameter v_2 as a function of participation number as well as the gluonic\ncontribution to the nuclear modification factor R_AA for most central\ncollisions are given. Also the shear viscosity to entropy ratio is dynamically\nextracted, which lies in the range of 0.08-0.15, depending on the chosen\ncoupling constant. \n\n"}
{"id": "0811.0064", "contents": "Title: Calculation of the Norm of the Error Functional of Optimal Quadrature\n  Formulas in the Space $W_2^{(2,1)}(0,1)$ Abstract: In this paper in the space $W_2^{(2,1)}(0,1)$ square of the norm of the error\nfunctional of a optimal quadrature formula is calculated. \n\n"}
{"id": "0811.2478", "contents": "Title: High Order Phase Fitted Multistep Integrators for the Schr\\\"odinger\n  Equation with Improved Frequency Tolerance Abstract: In this work we introduce a new family of 14-steps linear multistep methods\nfor the integration of the Schr\\\"odinger equation. The new methods are phase\nfitted but they are designed in order to improve the frequency tolerance. This\nis achieved by eliminating the first derivatives of the phase lag function at\nthe fitted frequency forcing the phase lag function to be '\\textit{flat}'\nenough in the neighbor of the fitted frequency. The efficiency of the new\nfamily of methods is proved via error analysis and numerical applications. \n\n"}
{"id": "0811.2712", "contents": "Title: Nucleon distribution amplitudes and proton decay matrix elements on the\n  lattice Abstract: Baryon distribution amplitudes (DAs) are crucial for the theory of hard\nexclusive reactions. We present a calculation of the first few moments of the\nleading-twist nucleon DA within lattice QCD. In addition we deal with the\nnormalization of the next-to-leading (twist-four) DAs. The matrix elements\ndetermining the latter quantities are also responsible for proton decay in\nGrand Unified Theories. Our lattice evaluation makes use of gauge field\nconfigurations generated with two flavors of clover fermions. The relevant\noperators are renormalized nonperturbatively with the final results given in\nthe MSbar scheme. We find that the deviation of the leading-twist nucleon DA\nfrom its asymptotic form is less pronounced than sometimes claimed in the\nliterature. \n\n"}
{"id": "0812.0461", "contents": "Title: Optimal distribution of measurement time in single channel measurements Abstract: Single channel measurements play a minor role in today physics, but they are\nsometimes unavoidable. Comparing to multichannel measurements, there is\ndistribution of measurement time to be chosen in an experiment design. A method\nto optimize distribution of measurement time is given, where optimal\ndistribution minimizes standard deviation of a selected fit parameter. As an\nexample, the method is applied to electron spectroscopy experiments. \n\n"}
{"id": "0812.1347", "contents": "Title: Spontaneous magnetization in QCD and non-Fermi-liquid effects Abstract: Magnetic properties of quark matter at finite temperature are discussed by\nevaluating the magnetic susceptibility. Combining the microscopic calculation\nof the self-energy for quarks as well as the screening effects for gluons with\nFermi-liquid theory in a consistent way, we study the temperature dependence of\nthe magnetic susceptibility. The longitudinal gluons have the static screening\ngiven by the Debye mass, and have a standard temperature dependence of\n$O(T^2)$. An anomalous $T^2\\ln T$ term arises in the magnetic susceptibility as\na novel non-Fermi-liquid effect due to the anomalous self-energy for quarks\ngiven by the dynamic screening for transverse gluons. We then extract the\ncritical(Curie) temperature and present the magnetic phase diagram on the\ndensity-temperature plane. \n\n"}
{"id": "0812.3368", "contents": "Title: An explanation of the $\\Delta_{5/2^{-}}(1930)$ as a $\\rho\\Delta$ bound\n  state Abstract: We use the $\\rho\\Delta$ interaction in the hidden gauge formalism to\ndynamically generate $N^{\\ast}$ and $\\Delta^{\\ast}$ resonances. We show,\nthrough a comparison of the results from this analysis and from a quark model\nstudy with data, that the $\\Delta_{5/2^{-}}(1930),$ $\\Delta_{3/2^{-}}(1940)$\nand $\\Delta_{1/2^{-}}(1900)$ resonances can be assigned to $\\rho\\Delta$ bound\nstates. More precisely the $\\Delta_{5/2^{-}}(1930)$ can be interpreted as a\n$\\rho\\Delta$ bound state whereas the $\\Delta_{3/2^{-}}(1940)$ and\n$\\Delta_{1/2^{-}}(1900)$ may contain an important $\\rho\\Delta$ component. This\ninterpretation allows for a solution of a long-standing puzzle concerning the\ndescription of these resonances in constituent quark models. In addition we\nalso obtain degenerate $J^{P}=1/2^{-},3/2^{-},5/2^{-}$ $N^{*}$ states but their\nassignment to experimental resonances is more uncertain. \n\n"}
{"id": "0812.4323", "contents": "Title: Quantum Process Tomography via L1-norm Minimization Abstract: For an initially well designed but imperfect quantum information system, the\nprocess matrix is almost sparse in an appropriate basis. Existing theory and\nassociated computational methods (L1-norm minimization) for reconstructing\nsparse signals establish conditions under which the sparse signal can be\nperfectly reconstructed from a very limited number of measurements (resources).\nAlthough a direct extension to quantum process tomography of the L1-norm\nminimization theory has not yet emerged, the numerical examples presented here,\nwhich apply L1-norm minimization to quantum process tomography, show a\nsignificant reduction in resources to achieve a desired estimation accuracy\nover existing methods. \n\n"}
{"id": "0901.0266", "contents": "Title: Implications of the Higgs Discovery in the MSSM Golden Region Abstract: If the lightest CP-even Higgs boson in the MSSM is discovered at the LHC, two\nmeasurements could be made simultaneously: the Higgs mass m_h and the event\nrate Bs(gg -> h -> gamma gamma). We study to what extent the combination of\nthese two measurements would allow us to extract parameters in the stop mass\nmatrix, including the off-diagonal mixing term, with a focus on the MSSM golden\nregion where the stops are light and the mixing is large. Even though both the\nproduction cross-section and the decay amplitude are not sensitive to\nsupersymmetric parameters outside of the stop sector, the branching ratio\ndepends on the total decay width, which is dominated by the Higgs decay to b\nquarks and sensitive to both the pseudo-scalar mass m_A and the supersymmetric\nHiggs mass \\mu. In the end we find m_A is an important input in extracting the\nstop mass parameters, while a fair estimate of the off-diagonal mixing term\ncould be obtained without prior knowledge of \\mu. \n\n"}
{"id": "0901.0496", "contents": "Title: Extra Electroweak Phase Transitions from Strong Dynamics Abstract: We show that models of dynamical electroweak symmetry breaking can possess an\nextremely rich finite temperature phase diagram. We suggest that early-universe\nextra electroweak phase transitions can appear in these models. \n\n"}
{"id": "0901.2228", "contents": "Title: Test Beam Requirements for the ILC Tracking and Vertex Detectors Abstract: In this report the test beam requirements for the vertex detector and the\ntracking detector for ILC are discussed. It focuses on the infrastructure needs\nof the different subsystems. In the second part of this summary the ideas about\nfuture infrastructure above the immediate needs are summarised. \n\n"}
{"id": "0902.0441", "contents": "Title: Study of the Top Quark FCNC Abstract: We study the one-loop contribution of the effective flavor changing neutral\ncouplings (FCNC) $tcZ$ to the charm quark electric dipole moment. Using the\nknown limits on the top and charm quarks electric dipole moments, we place\nlimits on these FCNC anomalous couplings. \n\n"}
{"id": "0902.2801", "contents": "Title: Sensor/ROIC Integration using Oxide Bonding Abstract: We explore the Ziptronix Direct Bond Interconnect technology for the\nintegration of sensors and readout integrated circuits (ROICs) for high energy\nphysics. The technology utilizes an oxide bond to form a robust mechanical\nconnection between layers which serves to assist with the formation of metallic\ninterlayer connections. We report on testing results of sample sensors bonded\nto ROICs and thinned to 100 microns. \n\n"}
{"id": "0902.3205", "contents": "Title: Detector Optimization for SiD using PFA Abstract: A summary of the optimization of the SiD detector is given. To optimize its\nperformance in terms of Particle Flow Algorithms (PFA), five basic detector\nparameters have been varied and the impact on the obtained energy resolution\nusing Particle Flow Algorithms has been studied using di-jets events. Finally\nthe optimized detector used for the Letter of Intent (LoI) is briefly\nsummarized as a result from these studies. \n\n"}
{"id": "0903.2255", "contents": "Title: Energy and momentum deposited into a QCD medium by a jet shower Abstract: Hard partons moving through a dense QCD medium lose energy by radiative\nemissions and elastic scatterings. Deposition of the radiative contribution\ninto the medium requires rescattering of the radiated gluons. We compute the\ntotal energy loss and its deposition into the medium self-consistently within\nthe same formalism, assuming perturbative interaction between probe and medium.\nThe same transport coefficients that control energy loss of the hard parton\ndetermine how the energy is deposited into the medium; this allows a parameter\nfree calculation of the latter once the former have been computed or extracted\nfrom experimental energy loss data. We compute them for a perturbative medium\nin hard thermal loop (HTL) approximation. Assuming that the deposited\nenergy-momentum is equilibrated after a short relaxation time, we compute the\nmedium's hydrodynamical response and obtain a conical pattern that is strongly\nenhanced by showering. \n\n"}
{"id": "0903.3116", "contents": "Title: Phenomenology of Dark Matter annihilation into a long-lived intermediate\n  state Abstract: We propose a scenario where Dark Matter (DM) annihilates into an intermediate\nstate which travels a distance $\\lambda \\equiv v/\\Gamma$ on the order of\ngalactic scales and then decays to Standard Model (SM) particles. The long\nlifetime disperses the production zone of the SM particles away from the\ngalactic center and hence, relaxes constraints from gamma ray observations on\ncanonical annihilation scenarios. We utilize this set up to explain the\nelectron and positron excesses observed recently by PAMELA, ATIC, and FERMI.\nWhile an explanation in terms of usual DM annihilations seems to conflict with\ngamma ray observations, we show that within the proposed scenario, the\nPAMELA/ATIC/FERMI results are consistent with the gamma ray data. The\ndistinction from decay scenarios is discsussed and we comment on the prospects\nfor DM production at LHC. The typical decay length $\\lambda \\gtrsim 10$ kpc of\nthe intermediate state can have its origin from a dimension six operator\nsuppressed by a scale $\\Lambda \\sim 10^{13}$ GeV, which is roughly the seesaw\nscale for neutrino masses. \n\n"}
{"id": "0903.3643", "contents": "Title: Dielectron widths of the S-, D-vector bottomonium states Abstract: The dielectron widths of $\\Upsilon(nS) (n=1,...,7)$ and vector decay\nconstants are calculated using the Relativistic String Hamiltonian with a\nuniversal interaction. For $\\Upsilon(nS) (n=1,2,3)$ the dielectron widths and\ntheir ratios are obtained in full agreement with the latest CLEO data. For\n$\\Upsilon(10580)$ and $\\Upsilon(11020)$ a good agreement with experiment is\nreached only if the 4S--3D mixing (with a mixing angle $\\theta=27^\\circ\\pm\n4^\\circ$) and 6S--5D mixing (with $\\theta=40^\\circ\\pm 5^\\circ$) are taken into\naccount. The possibility to observe higher \"mixed $D$-wave\" resonances,\n$\\tilde\\Upsilon(n {}^3D_1)$ with $n=3,4,5$ is discussed. In particular,\n$\\tilde\\Upsilon(\\approx 11120)$, originating from the pure $5 {}^3D_1$ state,\ncan acquire a rather large dielectron width, $\\sim 130$ eV, so that this\nresonance may become manifest in the $e^+e^-$ experiments. On the contrary, the\nwidths of pure $D$-wave states are very small, $\\Gamma_{ee}(n{}^3 D_1) \\leq 2$\neV. \n\n"}
{"id": "0905.2485", "contents": "Title: Minimizing Communication in Linear Algebra Abstract: In 1981 Hong and Kung proved a lower bound on the amount of communication\nneeded to perform dense, matrix-multiplication using the conventional $O(n^3)$\nalgorithm, where the input matrices were too large to fit in the small, fast\nmemory. In 2004 Irony, Toledo and Tiskin gave a new proof of this result and\nextended it to the parallel case. In both cases the lower bound may be\nexpressed as $\\Omega$(#arithmetic operations / $\\sqrt{M}$), where M is the size\nof the fast memory (or local memory in the parallel case). Here we generalize\nthese results to a much wider variety of algorithms, including LU\nfactorization, Cholesky factorization, $LDL^T$ factorization, QR factorization,\nalgorithms for eigenvalues and singular values, i.e., essentially all direct\nmethods of linear algebra. The proof works for dense or sparse matrices, and\nfor sequential or parallel algorithms. In addition to lower bounds on the\namount of data moved (bandwidth) we get lower bounds on the number of messages\nrequired to move it (latency). We illustrate how to extend our lower bound\ntechnique to compositions of linear algebra operations (like computing powers\nof a matrix), to decide whether it is enough to call a sequence of simpler\noptimal algorithms (like matrix multiplication) to minimize communication, or\nif we can do better. We give examples of both. We also show how to extend our\nlower bounds to certain graph theoretic problems.\n  We point out recently designed algorithms for dense LU, Cholesky, QR,\neigenvalue and the SVD problems that attain these lower bounds; implementations\nof LU and QR show large speedups over conventional linear algebra algorithms in\nstandard libraries like LAPACK and ScaLAPACK. Many open problems remain. \n\n"}
{"id": "0905.3246", "contents": "Title: Characterization of large area photomutipliers under low magnetic\n  fields: design and performances of the magnetic shielding for the Double\n  Chooz neutrino experiment Abstract: This paper describes the characterization studies under low magnetic fields\nof the Hamamatsu R7081 photomultipliers that are being used in the Double Chooz\nexperiment. The design and performances of the magnetic shielding that has been\ndeveloped for these photomultipliers are also reported. \n\n"}
{"id": "0905.4946", "contents": "Title: The hp-BEM with quasi-uniform meshes for the electric field integral\n  equation on polyhedral surfaces: a priori error analysis Abstract: This paper presents an a priori error analysis of the hp-version of the\nboundary element method for the electric field integral equation on a piecewise\nplane (open or closed) Lipschitz surface. We use H(div)-conforming\ndiscretisations with Raviart-Thomas elements on a sequence of quasi-uniform\nmeshes of triangles and/or parallelograms. Assuming the regularity of the\nsolution to the electric field integral equation in terms of Sobolev spaces of\ntangential vector fields, we prove an a priori error estimate of the method in\nthe energy norm. This estimate proves the expected rate of convergence with\nrespect to the mesh parameter h and the polynomial degree p. \n\n"}
{"id": "0906.2129", "contents": "Title: Convergence rates of the splitting scheme for parabolic linear\n  stochastic Cauchy problems Abstract: We study the splitting scheme associated with the linear stochastic Cauchy\nproblem dU(t) = AU(t) dt + dW(t), where A is the generator of an analytic\nC_0-semigroup S={S(t)} on a Banach space E and W={W(t)} is a Brownian motion\nwith values in a fractional domain space E_\\b associated with A. We prove that\nif \\a,\\b,\\g,\\th \\ge 0 are such that \\g + \\th < 1 and max[0,(\\a-\\b+\\th)] + \\g <\n1/2, then the approximate solutions U_n (where n is the number of time steps)\nconverge to the solution U in the Holder space C^\\g([0,T];E_\\a), both in\nL^p-means and almost surely, with rate 1/n^\\th. \n\n"}
{"id": "0907.4029", "contents": "Title: Cosmic Ray Muons Timing in the ATLAS Detector Abstract: In this talk I discuss the use of calorimeter timing both for detector\ncommissioning and in searches for new physics. In particular I present real and\nsimulated cosmic ray muons data results for the ATLAS Tile Calorimeter system.\nThe analysis shows that several detector errors such as imperfect calibrations\ncan be uncovered. I also demonstrate the use of ATLAS Tile Calorimeters\nexcellent timing resolution in suppressing cosmic ray fake missing transverse\nenergy in searches for supersymmetry. \n\n"}
{"id": "0909.1464", "contents": "Title: Numerical analysis of the planewave discretization of orbital-free and\n  Kohn-Sham models Part I: The Thomas-Fermi-von Weizacker model Abstract: We provide {\\it a priori} error estimates for the spectral and pseudospectral\nFourier (also called planewave) discretizations of the periodic\nThomas-Fermi-von Weizs\\\"acker (TFW) model and of the Kohn-Sham model, within\nthe local density approximation (LDA). These models allow to compute\napproximations of the ground state energy and density of molecular systems in\nthe condensed phase. The TFW model is stricly convex with respect to the\nelectronic density, and allows for a comprehensive analysis (Part I). This is\nnot the case for the Kohn-Sham LDA model, for which the uniqueness of the\nground state electronic density is not guaranteed. Under a coercivity\nassumption on the second order optimality condition, we prove in Part II that\nfor large enough energy cut-offs, the discretized Kohn-Sham LDA problem has a\nminimizer in the vicinity of any Kohn-Sham ground state, and that this\nminimizer is unique up to unitary transform. We then derive optimal {\\it a\npriori} error estimates for both the spectral and the pseudospectral\ndiscretization methods. \n\n"}
{"id": "0909.3523", "contents": "Title: Higgs Boson Decays to Neutralinos in Low-Scale Gauge Mediation Abstract: We study the decays of a standard model-like MSSM Higgs boson to pairs of\nneutralinos, each of which subsequently decays promptly to a photon and a\ngravitino. Such decays can arise in supersymmetric scenarios where\nsupersymmetry breaking is mediated to us by gauge interactions with a\nrelatively light gauge messenger sector (M_{mess} < 100 TeV). This process\ngives rise to a collider signal consisting of a pair of photons and missing\nenergy. In the present work we investigate the bounds on this scenario within\nthe minimal supersymmetric standard model from existing collider data. We also\nstudy the prospects for discovering the Higgs boson through this decay mode\nwith upcoming data from the Tevatron and the LHC. \n\n"}
{"id": "0910.2092", "contents": "Title: Finite Elements for a Beam System With Nonlinear Contact Under Periodic\n  Excitation Abstract: Solar arrays are structures which are connected to satellites; during launch,\nthey are in a folded position and submitted to high vibrations. In order to\nsave mass, the flexibility of the panels is not negligible and they may strike\neach other; this may damage the structure. To prevent this, rubber snubbers are\nmounted at well chosen points of the structure; a prestress is applied to the\nsnubber; but it is quite difficult to check the amount of prestress and the\nsnubber may act only on one side; they will be modeled as one sided springs\n(see figure 2). In this article, some analysis for responses (displacements) in\nboth time and frequency domains for a clamped-clamped Euler-Bernoulli beam\nmodel with a spring are presented. This spring can be unilateral or bilateral\nfixed at a point. The mounting (beam +spring) is fixed on a rigid support which\nhas a sinusoidal motion of constant frequency. The system is also studied in\nthe frequency domain by sweeping frequencies between two fixed values, in order\nto save the maximum of displacements corresponding to each frequency. Numerical\nresults are compared with exact solutions in particular cases which already\nexist in the literature. On the other hand, a numerical and theoretical\ninvestigation of nonlinear normal mode (NNM) can be a new method to describe\nnonlinear behaviors, this work is in progress. \n\n"}
{"id": "0910.2650", "contents": "Title: ArgoNeuT, a liquid argon time projection chamber in a low energy\n  neutrino beam Abstract: ArgoNeuT (Argon Neutrino Test), a NSF/DOE project at Fermilab, is the first\nLArTPC to go in a low energy neutrino beam and just the second LArTPC to go in\na neutrino beam ever. ArgoNeuT sits just upstream of the on-axis MINOS near\ndetector in the NuMI beamline, about 1 km from the target station and 100 m\nunderground. The detector features a 47X40X90 cm (169 L) active volume TPC with\na fully contained recirculation and purification system. Among other physics,\nArgoNeuT will measure the charged-current quasi-elastic (anti-) neutrino cross\nsection on argon at an energy of ~3 GeV. \n\n"}
{"id": "0910.3381", "contents": "Title: Conformal Anomalies and the Gravitational Effective Action: The $TJJ$\n  Correlator for a Dirac Fermion Abstract: We compute in linearized gravity all the contributions to the gravitational\neffective action due to a virtual Dirac fermion, related to the conformal\nanomaly. This requires, in perturbation theory, the identification of the\ngauge-gauge-graviton vertex off mass shell, involving the correlator of the\nenergy-momentum tensor and two vector currents ($TJJ$), which is responsible\nfor the generation of the gauge contributions to the conformal anomaly in\ngravity. We also present the anomalous effective action in the inverse mass of\nthe fermion as in the Euler-Heisenberg case. \n\n"}
{"id": "0910.5192", "contents": "Title: Study of the $f_2(1270)$, $f_2'(1525)$, $f_0(1370)$ and $f_0(1710)$ in\n  the $J/\\psi$ radiative decays Abstract: In this paper we present an approach to study the radiative decay modes of\nthe $J/\\psi$ into a photon and one of the tensor mesons $f_2(1270)$,\n$f'_2(1525)$, as well as the scalar ones $f_0(1370)$ and $f_0(1710)$.\nEspecially we compare predictions that emerge from a scheme where the states\nappear dynamically in the solution of vector meson--vector meson scattering\namplitudes to those from a (admittedly naive) quark model. We provide evidence\nthat it might be possible to distinguish amongst the two scenarios, once\nimproved data are available. \n\n"}
{"id": "0911.0248", "contents": "Title: Reply to the Comment of X. Ji on \"Do gluons carry half of the nucleon\n  momentum?\" [PRL 103:062001 (2009)] Abstract: We affirm that the proper momentum defined in [PRL 103:062001 (2009)] does\nrespect exact gauge symmetry and is as measurable as the kinetic momentum. The\nphysical part of the gauge field is also as measurable as the electromagnetic\nfield. The Comment of Ji [arXiv:0910.5022] is due to a misunderstanding of our\nwork, and a typical confusion of our gauge-invariant formalism with the\nspecific Coulomb-gauge calculation. \n\n"}
{"id": "0911.5125", "contents": "Title: Interpolations Among NAHE-based Supersymmetric and Nonsupersymmetric\n  String Vacua Abstract: The quasi-realistic free fermionic heterotic-string models provide some of\nthe most detailed examples to explore the phenomenology of string unification.\nWhile providing a powerful tool to generate models and their spectra,\nunderstanding the realisation of the free fermion models in a bosonic formalism\nwill provide important insight into their basic properties away from the free\nfermion point. In this paper we elucidate bosonic equivalent of the basic\nsymmetry breaking pattern in the free fermion models from E8XE8 to\nSO(16)XSO(16) and exhibit the connection of the free fermion models with\ncorresponding non--supersymmetric vacua by interpolations. \n\n"}
{"id": "0911.5295", "contents": "Title: String Theory on Thin Semiconductors: Holographic Realization of Fermi\n  Points and Surfaces Abstract: I make a novel contact between string theory and degenerate fermion dynamics\nin thin semiconductors. Utilizing AdS/CFT correspondence in string theory and\ntunability of coupling parameters in condensed matter systems, I focus on the\npossibilities testing string theory from tabletop experiments. I first discuss\nthe observation that stability of Fermi surface is classifiable according to\nK-theory. I then elaborate two concrete realization of Fermi surfaces of zero\nand two dimensions. Both are realized by complex of D3-branes and D7-branes of\nrelative codimension 6 and 4, respectively. The setup with Fermi point models\ngauge dynamics of multiply stacked graphenes at half-filling. I show that\nstring theory predicts dynamical generation of mass gap and metal-insulator\nquantum phase transition at zero temperature. I emphasize that conformally\ninvariant gauge theory dynamics of the setup plays a crucial role, leading to\nnovel conformal phase transition. The setup with Fermi surface is in\ncollaboration with Dongsu Bak and is based on charged black hole and models\nrelativistic Fermi liquid. We find positive evidence for this identification\nfrom both equilibrium thermodynamics at or near zero temperature and\nout-of-equilibrium linear response and transport properties. I argue that\nfluctuation of black hole horizon provides holographic realization consistent\nwith Fermi liquid for thermodynamics and interesting departures therefrom in\ntransport properties. \n\n"}
{"id": "0912.3376", "contents": "Title: Convergence rates to deflation of simple shift strategies Abstract: The computation of eigenvalues of real symmetric tridiagonal matrices\nfrequently proceeds by a sequence of QR steps with shifts. We introduce simple\nshift strategies, functions sigma satisfying natural conditions, taking each n\nx n matrix T to a real number sigma(T). The strategy specifies the shift to be\napplied by the QR step at T. Rayleigh and Wilkinson's are examples of simple\nshift strategies. We show that if sigma is continuous then there exist initial\nconditions for which deflation does not occur, i.e., subdiagonal entries do not\ntend to zero. In case of deflation, we consider the rate of convergence to zero\nof the (n, n-1) entry: for simple shift strategies this is always at least\nquadratic. If the function sigma is smooth in a suitable region and the\nspectrum of T does not include three consecutive eigenvalues in arithmetic\nprogression then convergence is cubic. This implies cubic convergence to\ndeflation of Wilkinson's shift for generic spectra. The study of the algorithm\nnear deflation uses tubular coordinates, under which QR steps with shifts are\ngiven by a simple formula. \n\n"}
{"id": "0912.3905", "contents": "Title: Dark matter detection in the BMSSM Abstract: The addition of non-renormalizable terms involving the Higgs fields to the\nMSSM (BMSSM) ameliorates the little hierarchy problem of the MSSM. For\nneutralino dark matter, new regions for which the relic abundance of the LSP is\nconsistent with WMAP (as the bulk region and the stop coannihilation region)\nare now permitted. In this framework, we analyze in detail the direct dark\nmatter detection prospects in a Xenon-like experiment. On the other hand, we\nstudy the capability of detecting gamma-rays, antiprotons and positrons\nproduced in the annihilation of neutralino LSPs in the Fermi and oncoming\nAMS-02 experiments. \n\n"}
{"id": "0912.4417", "contents": "Title: R&D for Future 100 kton Scale Liquid Argon Detectors Abstract: Large liquid argon (LAr) detectors, up to 100 kton scale, are presently being\nconsidered for proton decay searches and neutrino astrophysics as well as far\ndetectors for the next generation of long baseline neutrino oscillation\nexperiments, aiming at neutrino mass hierarchy determination and CP violation\nsearches in the leptonic sector. These detectors rely on the possibility of\nmaintaining large LAr masses stably at cryogenic conditions with low thermal\nlosses and of achieving long drifts of the ionization charge, so to minimize\nthe number of readout channels per unit volume. Many R&D initiatives are being\nundertaken throughout the world, following somewhat different concepts for the\nfinal detector design, but with many common basic R&D issues. \n\n"}
{"id": "1001.0149", "contents": "Title: Fast construction of hierarchical matrix representation from\n  matrix-vector multiplication Abstract: We develop a hierarchical matrix construction algorithm using matrix-vector\nmultiplications, based on the randomized singular value decomposition of\nlow-rank matrices. The algorithm uses $\\mathcal{O}(\\log n)$ applications of the\nmatrix on structured random test vectors and $\\mathcal{O}(n \\log n)$ extra\ncomputational cost, where $n$ is the dimension of the unknown matrix. Numerical\nexamples on constructing Green's functions for elliptic operators in two\ndimensions show efficiency and accuracy of the proposed algorithm. \n\n"}
{"id": "1001.2219", "contents": "Title: Asymptotic zero distribution of complex orthogonal polynomials\n  associated with Gaussian quadrature Abstract: In this paper we study the asymptotic behavior of a family of polynomials\nwhich are orthogonal with respect to an exponential weight on certain contours\nof the complex plane. The zeros of these polynomials are the nodes for complex\nGaussian quadrature of an oscillatory integral on the real axis with a high\norder stationary point, and their limit distribution is also analyzed. We show\nthat the zeros accumulate along a contour in the complex plane that has the\nS-property in an external field. In addition, the strong asymptotics of the\northogonal polynomials is obtained by applying the nonlinear Deift--Zhou\nsteepest descent method to the corresponding Riemann--Hilbert problem. \n\n"}
{"id": "1001.2954", "contents": "Title: Jet and W/Z Production at Hadron Colliders Abstract: The start of the physics program at the LHC has added great impetus in the\ndevelopment of powerful theoretical tools to meet the many challenges that this\ncollider brings. The production of jets and weak vector bosons is at the center\nof most analyses, from machine performance to new physics searches. In this\ntalk we review some recent advances in the study of jets, in the computation of\nquantum corrections to processes with large jet multiplicity and their impact\nin W/Z+jets and W/Z+b-jets production at the Tevatron and the LHC. \n\n"}
{"id": "1001.3128", "contents": "Title: Stochastic perturbation of sweeping process and a convergence result for\n  an associated numerical scheme Abstract: Here we present well-posedness results for first order stochastic\ndifferential inclusions, more precisely for sweeping process with a stochastic\nperturbation. These results are provided in combining both deterministic\nsweeping process theory and methods concerning the reflection of a Brownian\nmotion. In addition, we prove convergence results for a Euler scheme,\ndiscretizing theses stochastic differential inclusions. \n\n"}
{"id": "1002.0887", "contents": "Title: Convergence and Optimal Complexity of Adaptive Finite Element Methods Abstract: In this paper, we study adaptive finite element approximations in a\nperturbation framework, which makes use of the existing adaptive finite element\nanalysis of a linear symmetric elliptic problem. We prove the convergence and\ncomplexity of adaptive finite element methods for a class of elliptic partial\ndifferential equations. For illustration, we apply the general approach to\nobtain the convergence and complexity of adaptive finite element methods for a\nnonsymmetric problem, a nonlinear problem as well as an unbounded coefficient\neigenvalue problem. \n\n"}
{"id": "1002.2950", "contents": "Title: Kinetic relations for undercompressive shock waves. Physical,\n  mathematical, and numerical issues Abstract: Kinetic relations are required in order to characterize nonclassical\nundercompressive shock waves and formulate a well-posed initial value problem\nfor nonlinear hyperbolic systems of conservation laws. Such nonclassical waves\narise in weak solutions of a large variety of physical models: phase\ntransitions, thin liquid films, magnetohydrodynamics, Camassa-Holm model,\nmartensite-austenite materials, semi-conductors, combustion theory, etc. This\nreview presents the research done in the last fifteen years which led the\ndevelopment of the theory of kinetic relations for undercompressive shocks and\nhas now covered many physical, mathematical, and numerical issues. The main\ndifficulty overcome here in our analysis of nonclassical entropy solutions\ncomes from their lack of monotonicity with respect to initial data.\nUndercompressive shocks of hyperbolic conservation laws turn out to exhibit\nfeatures that are very similar to shocks of nonconservative hyperbolic systems,\nwho were investigated earlier by the author. \n\n"}
{"id": "1002.3119", "contents": "Title: The quark-gluon-plasma phase transition diagram, Hagedorn matter and\n  quark-gluon liquid Abstract: In order to study the nuclear matter in the relativistic heavy ion collisions\nand the compact stars, we need the hadronic density of states for the entire\n($\\mu_B-T$) phase transition diagram. We present a model for the continuous\nhigh-lying mass (and volume) spectrum density of states that fits the Hagedorn\nmass spectrum. This model explains the origin of the tri-critical point besides\nvarious phenomena such as the quarkyonic matter and the quark-gluon liquid. The\nHagedorn mass spectrum is derived for the color-singlet quark-gluon bag with\nvarious internal structures such as the unimodular unitary, orthogonal and\ncolor-flavor locked symplectic symmetry groups. The continuous high-lying\nhadronic mass spectrum is populated at first by the unitary Hagedorn states.\nThen the spectrum turns to be dominated by the colorless orthogonal states as\nthe dilute system is heated up. Subsequently, the liquid/gas of orthogonal\nHagedorn states undergoes higher order deconfinement phase transition to\nquark-gluon plasma. Under the deconfinement phase transition process, the\ncolor-singlet states is broken badly to form the colored $SU(N_c)$ symmetry\ngroup. On the other hand, when the hadronic matter is compressed to larger\n$\\mu_{B}$ and heated up, the colorless unitary states undergoes first order\nphase transition to explosive quark-gluon plasma. The tri-critical point\nemerges as a change in the characteristic behaviour of the matter and as an\nintersection among various phases with different internal symmetries. When the\nsaturated hadronic matter is cooled down and compressed to higher density, it\nturns to be dominated by the colorless symplectic states. This matter exhibits\nthe first order phase transition to quark-gluon plasma when it is heated up to\nhigher temperature. The role of chiral phase transition is also discussed. \n\n"}
{"id": "1002.4189", "contents": "Title: Drift Time Measurement in the ATLAS Liquid Argon Electromagnetic\n  Calorimeter using Cosmic Muons Abstract: The ionization signals in the liquid argon of the ATLAS electromagnetic\ncalorimeter are studied in detail using cosmic muons. In particular, the drift\ntime of the ionization electrons is measured and used to assess the intrinsic\nuniformity of the calorimeter gaps and estimate its impact on the constant term\nof the energy resolution. The drift times of electrons in the cells of the\nsecond layer of the calorimeter are uniform at the level of 1.3 % in the barrel\nand 2.8 % in the endcaps. This leads to an estimated contribution to the\nconstant term of (0.29 +0.05 -0.04) % in the barrel and (0.54 +0.06 -0.04) % in\nthe endcaps. The same data are used to measure the drift velocity of ionization\nelectrons in liquid argon, which is found to be 4.61 +- 0.07 mm/\\mu s at 88.5 K\nand 1 kV/mm. \n\n"}
{"id": "1002.4628", "contents": "Title: Holographic metastability Abstract: We show how supersymmetric QCD in a slice of AdS can naturally acquire\nmetastable vacua. The formulation closely follows that of Intriligator, Seiberg\nand Shih (ISS), with an \"electric\" sector on the UV brane and a \"magnetic\"\nsector on the IR brane. However the 't Hooft anomaly matching that constrains\nthe Seiberg duality central to ISS is replaced by anomaly inflow and\ncancellation, and the source of strong coupling is the CFT to which the theory\ncouples rather than the gauge groups. The theory contains an anomaly free\nR-symmetry that, when broken by UV effects, leads to an O'Raifeartaigh model on\nthe IR brane. In contrast to ISS, the R-symmetry breaking in the UV can be\nmaximal, and yet the R-symmetry breaking in the IR theory remains under strict\ncontrol: there is no need for retrofitting of small parameters. \n\n"}
{"id": "1003.3819", "contents": "Title: Gravitino Dark Matter and the ILC Abstract: We review the case of gravitino Dark Matter for stop, neutralino and\nsneutrino Next-to-Lightest Supersymmetric Particles and discuss prospects to\ninvestigate such scenarios at LHC and a Linear Collider. \n\n"}
{"id": "1004.1375", "contents": "Title: Holst action and Dynamical Electroweak symmetry breaking Abstract: We consider Poincare gravity coupled in a nonminimal way to spinors. The\ngravitational action is considered that contains both Palatini and Holst terms.\nDue to torsion the effective four - fermion interactions appear that may lead\nto the left - right asymmetry and the condensation of fermions. When the mass\nparameter entering the mentioned terms of the gravitational action is at a Tev\nscale the given construction may provide the dynamical Electroweak symmetry\nbreaking. This is achieved via an arrangement of all Standard Model fermions in\nthe left - handed Dirac spinors while the right - handed spinors are reserved\nfor the technifermions. Due to the gravitational action the technifermions are\ncondensed and, therefore, cause the appearance of gauge boson masses. \n\n"}
{"id": "1004.5113", "contents": "Title: Inside looking out: probing JIMWLK with BFKL calculations Abstract: We investigate the relation between the eigenvalues and eigenfunctions of the\nBFKL and JIMWLK/KLWMIJ Hamiltonians. We show that the eigenvalues of the BFKL\nHamiltonians are also {\\it exact} eigenvalues of the KLWMIJ (and JIMWLK)\nHamiltonian, albeit corresponding to possibly non normalizable eigenfunctions.\nThe question whether a given eigenfunction of BFKL corresponds to a\nnormalizable eigenfunction of KLWMIJ is rather complicated, except in some\nobvious cases, and requires independent investigation. As an example to\nillustrate this relation we concentrate on the color octet exchange in the\nframework of KLWMIJ Hamiltonian. We show that it corresponds to the reggeized\ngluon exchange of BFKL, and find first correction to the BFKL wave function,\nwhich has the meaning of the impact factor for shadowing correction to the\nreggeized gluon. We also show that the bootstrap condition in the KLWMIJ\nframework is satisfied automatically and does not carry any additional\ninformation to that contained in the second quantized structure of the KLWMIJ\nHamiltonian. This is an example of how the bootstrap condition inherent in the\nt-channel unitarity, arises in the s-channel picture. \n\n"}
{"id": "1005.1070", "contents": "Title: Solving the mu problem with a heavy Higgs boson Abstract: We discuss the generation of the mu-term in a class of supersymmetric models\ncharacterized by a low energy effective superpotential containing a term lambda\nS H_1 H_2 with a large coupling lambda~2. These models generically predict a\nlightest Higgs boson well above the LEP limit of 114 GeV and have been shown to\nbe compatible with the unification of gauge couplings. Here we discuss a\nspecific example where the superpotential has no dimensionful parameters and we\npoint out the relation between the generated mu-term and the mass of the\nlightest Higgs boson. We discuss the fine-tuning of the model and we find that\nthe generation of a phenomenologically viable mu-term fits very well with a\nheavy lightest Higgs boson and a low degree of fine-tuning. We discuss\nexperimental constraints from collider direct searches, precision data, thermal\nrelic dark matter abundance, and WIMP searches finding that the most natural\nregion of the parameter space is still allowed by current experiments. We\nanalyse bounds on the masses of the superpartners coming from Naturalness\narguments and discuss the main signatures of the model for the LHC and future\nWIMP searches. \n\n"}
{"id": "1005.1252", "contents": "Title: Universal algorithms, mathematics of semirings and parallel computations Abstract: This is a survey paper on applications of mathematics of semirings to\nnumerical analysis and computing. Concepts of universal algorithm and generic\nprogram are discussed. Relations between these concepts and mathematics of\nsemirings are examined. A very brief introduction to mathematics of semirings\n(including idempotent and tropical mathematics) is presented. Concrete\napplications to optimization problems, idempotent linear algebra and interval\nanalysis are indicated. It is known that some nonlinear problems (and\nespecially optimization problems) become linear over appropriate semirings with\nidempotent addition (the so-called idempotent superposition principle). This\nlinearity over semirings is convenient for parallel computations. \n\n"}
{"id": "1005.1252", "contents": "Title: Universal algorithms, mathematics of semirings and parallel computations Abstract: This is a survey paper on applications of mathematics of semirings to\nnumerical analysis and computing. Concepts of universal algorithm and generic\nprogram are discussed. Relations between these concepts and mathematics of\nsemirings are examined. A very brief introduction to mathematics of semirings\n(including idempotent and tropical mathematics) is presented. Concrete\napplications to optimization problems, idempotent linear algebra and interval\nanalysis are indicated. It is known that some nonlinear problems (and\nespecially optimization problems) become linear over appropriate semirings with\nidempotent addition (the so-called idempotent superposition principle). This\nlinearity over semirings is convenient for parallel computations. \n\n"}
{"id": "1005.3457", "contents": "Title: Tuning Monte Carlo Generators: The Perugia Tunes Abstract: We present 9 new tunes of the pT-ordered shower and underlying-event model in\nPYTHIA 6.4. These \"Perugia\" tunes update and supersede the older \"S0\" family.\nThe data sets used to constrain the models include hadronic Z0 decays at LEP,\nTevatron minimum-bias data at 630, 1800, and 1960 GeV, Tevatron Drell-Yan data\nat 1800 and 1960 GeV, and SPS min-bias data at 200, 546, and 900 GeV. In\naddition to the central parameter set, called \"Perugia 0\", we introduce a set\nof 8 related \"Perugia Variations\" that attempt to systematically explore soft,\nhard, parton density, and colour structure variations in the theoretical\nparameters. Based on these variations, a best-guess prediction of the charged\ntrack multiplicity in inelastic, nondiffractive minimum-bias events at the LHC\nis made. Note that these tunes can only be used with PYTHIA 6, not with PYTHIA\n8. Note: this report was updated in March 2011 with a new set of variations,\ncollectively labeled \"Perugia 2011\", that are optimized for matching\napplications and which also take into account some lessons from the early LHC\ndata. In order not to break the original text, these are described separately\nin Appendix B. Note 2: a subsequent \"Perugia 2012\" update is described in\nAppendix C. \n\n"}
{"id": "1005.4568", "contents": "Title: The ATLAS Simulation Infrastructure Abstract: The simulation software for the ATLAS Experiment at the Large Hadron Collider\nis being used for large-scale production of events on the LHC Computing Grid.\nThis simulation requires many components, from the generators that simulate\nparticle collisions, through packages simulating the response of the various\ndetectors and triggers. All of these components come together under the ATLAS\nsimulation infrastructure. In this paper, that infrastructure is discussed,\nincluding that supporting the detector description, interfacing the event\ngeneration, and combining the GEANT4 simulation of the response of the\nindividual detectors. Also described are the tools allowing the software\nvalidation, performance testing, and the validation of the simulated output\nagainst known physics processes. \n\n"}
{"id": "1005.5652", "contents": "Title: Non-extensivity Parameter of Thermodynamical Model of Hadronic\n  Interactions at LHC energies Abstract: The LHC measurements above SPS and Tevatron energies give the opportunity to\ntest predictions of non-extensive thermodynamical picture of hadronic\ninteraction to examine measured transverse momenta distributions for new\ninteraction energy range. We determined Tsallis model non-extensivity parameter\nfor the hadronization process before short-lived particles decayed and distort\nthe initial p_t distribution. We have shown that it follows exactly smooth rise\ndetermined at lower energies below present LHC record. The shape of the q\nparameter energy dependence is consistent with expectations and the evidence of\nthe asymptotic limit may be seen. \n\n"}
{"id": "1006.3662", "contents": "Title: Monte Carlo Studies of the CALICE AHCAL Tiles Gaps and Non-uniformities Abstract: The CALICE analog HCAL is a highly granular calorimeter, proposed for the\nInternational Linear Collider. It is based on scintillator tiles, read out by\nsilicon photomultipliers (SiPMs). The effects of gaps between the calorimeter\ntiles, as well as the non-uniform response of the tiles, in view of the impact\non the energy resolution, are studied in Monte Carlo events. It is shown that\nthese type of effects do not have a significant influence on the measurement of\nhadron showers. \n\n"}
{"id": "1006.3734", "contents": "Title: Track Segments within Hadronic Showers using the CALICE AHCal Abstract: Using the high granular CALICE analog hadron calorimeter (AHCal) a tracking\nalgorithm capable of identifying MIP-like tracks within hadronic showers is\npresented. Such an algorithm provides excellent tools for detector calibration\nand for studies of the substructure of hadronic showers. The properties of the\nidentified tracks are used as observables for a Monte-Carlo to data comparison. \n\n"}
{"id": "1006.5252", "contents": "Title: Decomposition Approach for Low-rank Matrix Completion Abstract: In this paper, we describe a low-rank matrix completion method based on\nmatrix decomposition. An incomplete matrix is decomposed into submatrices which\nare filled with a proposed trimming step and then are recombined to form a\nlow-rank completed matrix. The divide-and-conquer approach can significantly\nreduce computation complexity and storage requirement. Moreover, the proposed\ndecomposition method can be naturally incorporated into any existing matrix\ncompletion methods to attain further gain. Unlike most existing approaches, the\nproposed method is not based on norm minimization nor SVD decomposition. This\nmakes it possible to be applied beyond real domain and can be used in arbitrary\nfields including finite fields. \n\n"}
{"id": "1007.0964", "contents": "Title: 1/Nc expansion and the spin-flavor structure of the quark interaction in\n  the constituent quark model Abstract: We study the hierarchy of the coefficients in the 1/Nc expansion for the\nnegative parity L=1 excited baryons from the perspective of the constituent\nquark model. This is related to the problem of determining the spin-flavor\nstructure of the quark interaction. The most general two-body scalar\ninteraction between quarks contains the spin-flavor structures $t_1^a t_2^a,\n\\vec s_1\\cdot \\vec s_2$ and $ \\vec s_1\\cdot \\vec s_2 t_1^a t_2^a$. We show that\nin the limit of a zero range interaction all these structures are matched onto\nthe same hadronic mass operator $S_c^2$, which gives a possible explanation for\nthe dominance of this operator in the 1/Nc expansion for the L=1 states and\nimplies that in this limit it is impossible to distinguish between these\ndifferent spin-flavor structures. Modeling a finite range interaction through\nthe exchange of a vector and pseudoscalar meson, we propose a test for the\nspin-flavor dependence of the quark forces. For the scalar part of the quark\ninteraction we find that both pion exchange and gluon exchange are compatible\nwith data. \n\n"}
{"id": "1007.2825", "contents": "Title: Scattered Data Interpolation on Embedded Submanifolds with Restricted\n  Positive Definite Kernels: Sobolev Error Estimates Abstract: In this paper we investigate the approximation properties of kernel\ninterpolants on manifolds. The kernels we consider will be obtained by the\nrestriction of positive definite kernels on $\\R^d$, such as radial basis\nfunctions (RBFs), to a smooth, compact embedded submanifold $\\M\\subset \\R^d$.\nFor restricted kernels having finite smoothness, we provide a complete\ncharacterization of the native space on $\\M$. After this and some preliminary\nsetup, we present Sobolev-type error estimates for the interpolation problem.\nNumerical results verifying the theory are also presented for a one-dimensional\ncurve embedded in $\\R^3$ and a two-dimensional torus. \n\n"}
{"id": "1007.3140", "contents": "Title: Analysis of recent eta photoproduction data Abstract: Recent data on eta-meson photoproduction off a proton target in the energy\nrange 2 < sqrt{s} < 3 GeV are analyzed with regard to their overall\nconsistency. Results from the ELSA and CLAS measurements are compared with\npredictions of a Regge model whose reaction amplitude was fixed via a global\nfit to pre-2000 measurements of differential cross sections and polarization\nobservables for gamma p -> eta p at higher energies. We find that all recent\nexperimental results on differential cross sections for eta-meson\nphotoproduction are in good agreement with each other, except for the CLAS data\nfrom 2009. However, the latter can be made consistent with the other data at\nthe expense of introducing an energy-dependent renormalization factor. We point\nout that there indications in the data for a possible excitation of baryon\nresonances with masses around 2.1 and 2.4 GeV. \n\n"}
{"id": "1007.3612", "contents": "Title: Deformed Mittag-Leffler Polynomials Abstract: The starting point of this paper are the Mittag-Leffler polynomials\nintroduced by H. Bateman [1]. Based on generalized integer powers of real\nnumbers and deformed exponential function, we introduce deformed Mittag-Leffler\npolynomials defined by appropriate generating function. We investigate their\nrecurrence relations, differential properties and orthogonality. Since they\nhave all zeros on imaginary axes, we also consider real polynomials with real\nzeros associated to them. \n\n"}
{"id": "1007.4277", "contents": "Title: Scale-dependent non-Gaussianity probes inflationary physics Abstract: We calculate the scale dependence of the bispectrum and trispectrum in\n(quasi) local models of non-Gaussian primordial density perturbations, and\ncharacterize this scale dependence in terms of new observable parameters. They\ncan help to discriminate between models of inflation, since they are sensitive\nto properties of the inflationary physics that are not probed by the standard\nobservables. We find consistency relations between these parameters in certain\nclasses of models. We apply our results to a scenario of modulated reheating,\nshowing that the scale dependence of non-Gaussianity can be significant. We\nalso discuss the scale dependence of the bispectrum and trispectrum, in cases\nwhere one varies the shape as well as the overall scale of the figure under\nconsideration. We conclude providing a formulation of the curvature\nperturbation in real space, which generalises the standard local form by\ndropping the assumption that f_NL and g_NL are constants. \n\n"}
{"id": "1008.0029", "contents": "Title: Evidence for Observation of Virtual Radio Cherenkov Fields Abstract: We present evidence for observation of virtual electromagnetic fields in the\nradio domain from experiment T926 at the Fermilab Meson Test Beam Facility.\nRelativistic protons with 120 GeV energy traversed a sealed electromagnetic\ncavity and were observed in the radio regime of 200MHz-GHz. Closely related to\nordinary Cherenkov radiation, which we also measured, the virtual fields\nrequire no acceleration for their existence. The experiment is also the first\nobservation of fields from hadronic showers, an independent and new\nconfirmation of coherent radio emission from ultra-relativistic particles.\nConditions of very low signal to noise were overcome by a novel and unbiased\nfiltering strategy that exploits exhaustive studies of correlations in the\nnoise backgrounds. Linear scaling of the signal region with the number of beam\nparticles provides evidence of coherence. Extrapolation to measurement of the\nfield of a single relativistic proton charge is consistent within errors. Our\nstudy also illustrates new data processing methods that may be applied broadly\nin conditions of extremely low signal to noise. \n\n"}
{"id": "1008.3895", "contents": "Title: Discrete gradient algorithms of high order for one-dimensional systems Abstract: We show how to increase the order of one-dimensional discrete gradient\nnumerical integrator without losing its advantages, such as exceptional\nstability, exact conservation of the energy integral and exact preservation of\nthe trajectories in the phase space. The accuracy of our integrators is higher\nby several orders of magnitude as compared with the standard discrete gradient\nscheme (modified midpoint rule) and, what is more, our schemes have very high\naccuracy even for large time steps. \n\n"}
{"id": "1008.4361", "contents": "Title: Anomaly Mediation in Superstring Theory Abstract: We study anomaly mediated supersymmetry breaking in type IIB string theory\nand use our results to test the supergravity formula for anomaly mediated\ngaugino masses. We compute 1-loop gaugino masses for models of D3-branes on\norbifold singularities with 3-form fluxes by calculating the annulus correlator\nof 3-form flux and two gauginos in the zero momentum limit. Consistent with\nsupergravity expectations we find both anomalous and running contributions to\n1-loop gaugino masses. For background Neveu-Schwarz H-flux we find an exact\nmatch with the supergravity formula. For Ramond-Ramond flux there is an\noff-shell ambiguity that precludes a full matching. The anomaly mediated\ngaugino masses, while determined by the infrared spectrum, arise from an\nexplicit sum over UV open string winding modes. We also calculate\nbrane-to-brane tree-level gravity mediated gaugino masses and show that there\nare two contributions coming from the dilaton and from the twisted modes, which\nare suppressed by the full T^6 volume and the untwisted T^2 volume\nrespectively. \n\n"}
{"id": "1009.1781", "contents": "Title: A fresh look at eta2(1645), eta2(1870), eta2(2030) and f2(1910) in\n  pbar-p -> eta + 3pizero Abstract: There is a large discrepancy between results of Crystal Barrel and WA102 for\nthe branching ratio R = BR[eta2(1870)->a2(1320)pi]/\nBR[eta2(1870)->f2(1270)eta]. An extensive re-analysis of the Crystal Barrel\ndata redetermines branching ratios for decays of eta2(1870), eta2(1645),\neta2(2030) and f2(1910). This re-analysis confirms a small value for R of\n1.60+-0.39, inconsistent with the value 32.6+-12.6 of WA102. The likely origin\nof the discrepancy is that the WA102 data contain a strong f2(1910)->a2-pi\nsignal as well as eta2(1870). There is strong evidence that the eta2(1870) has\nresonant phase variation. A peak in f2(1270)a0(980) confirms closely the\nparameters of the a2(2255) resonance observed previously. A peak in\neta2(2030)-pi is interpreted naturally in terms of pi2(2245) with reduced\nerrors for mass and width M=2285+-20(stat)+-25(syst) MeV,\nGamma=250+-20(stat)+-25(syst) MeV. \n\n"}
{"id": "1009.2065", "contents": "Title: Templates for Convex Cone Problems with Applications to Sparse Signal\n  Recovery Abstract: This paper develops a general framework for solving a variety of convex cone\nproblems that frequently arise in signal processing, machine learning,\nstatistics, and other fields. The approach works as follows: first, determine a\nconic formulation of the problem; second, determine its dual; third, apply\nsmoothing; and fourth, solve using an optimal first-order method. A merit of\nthis approach is its flexibility: for example, all compressed sensing problems\ncan be solved via this approach. These include models with objective\nfunctionals such as the total-variation norm, ||Wx||_1 where W is arbitrary, or\na combination thereof. In addition, the paper also introduces a number of\ntechnical contributions such as a novel continuation scheme, a novel approach\nfor controlling the step size, and some new results showing that the smooth and\nunsmoothed problems are sometimes formally equivalent. Combined with our\nframework, these lead to novel, stable and computationally efficient\nalgorithms. For instance, our general implementation is competitive with\nstate-of-the-art methods for solving intensively studied problems such as the\nLASSO. Further, numerical experiments show that one can solve the Dantzig\nselector problem, for which no efficient large-scale solvers exist, in a few\nhundred iterations. Finally, the paper is accompanied with a software release.\nThis software is not a single, monolithic solver; rather, it is a suite of\nprograms and routines designed to serve as building blocks for constructing\ncomplete algorithms. \n\n"}
{"id": "1009.2400", "contents": "Title: Linking the hydrodynamic and kinetic description of a dissipative\n  relativistic conformal theory Abstract: We use the entropy production variational method to associate a one particle\ndistribution function to the assumed known energy-momentum and entropy currents\ndescribing a relativistic conformal fluid. Assuming a simple form for the\ncollision operator we find this one particle distribution function explicitly,\nand show that this method of linking the hydro and kinetic description is a non\ntrivial generalization of Grad's ansatz. The resulting constitutive relations\nare the same as in the conformal dissipative type theories discussed in J.\nPeralta-Ramos and E. Calzetta, Phys. Rev. D {\\bfseries 80}, 126002 (2009). Our\nresults may prove useful in the description of freeze-out in ultrarelativistic\nheavy-ion collisions. \n\n"}
{"id": "1009.2588", "contents": "Title: Evolution of plane curves with a curvature adjusted tangential velocity Abstract: We study evolution of a closed embedded plane curve with the normal velocity\ndepending on the curvature, the orientation and the position of the curve. We\npropose a new method of tangential redistribution of points by curvature\nadjusted control in the tangential motion of evolving curves. The tangential\nvelocity distributes grid points along the curve not only uniform but also lead\nto a suitable concentration and/or dispersion depending on the curvature. Our\nstudy is based on solutions to the governing system of nonlinear parabolic\nequations for the position vector, tangent angle and curvature of a curve. We\nfurthermore present a semi-implicit numerical discretization scheme based on\nthe flowing finite volume method. Several numerical examples illustrating\ncapability of the new tangential redistribution method are also presented in\nthis paper. \n\n"}
{"id": "1009.2773", "contents": "Title: sigma and f_0(980) substructures from gamma-gamma to pi-pi, J/psi, phi\n  radiative and D_s semi-leptonic decays Abstract: Using an improved \"analytic K-matrix model\", we reconsider the extraction of\nthe sigma/f_0(600) and f_0(980) gamma-gamma widths from gamma-gamma to pi-pi\nscatterings data of Crystal Ball and Belle. Our main results are summarized in\nTables 3 and 4. The averaged sigma \"direct width\" to gamma-gamma is 0.16(3) keV\nwhich confirms a previous result of [1] and which does neither favour a large\nfour-quark (diquark-antidiquark) nor a molecule nor a pure \\bar qq component.\nThe \"direct width\" of the f_0(980) of 0.28(2) keV is much larger than the\nfour-quark expectation but can be compatible with a \\bar ss or gluonium\ncomponent. We also found that the rescattering part of the amplitude is\nrelatively large indicating an important contribution of the meson loops in the\ndetermination of the gamma-gamma total widths. This is mainly due to the large\ncouplings of the sigma and f_0(980) to pi-pi and/or \\bar KK, which can also be\ndue to a light scalar gluonium with large OZI violating couplings but not\nnecessary to a four-quark or molecule state. Our average results for the total\n(direct+rescattering) gamma-gamma widths: Gamma_sigma^{tot}= 3.08(82) keV,\nGamma_{f_0}^{tot}= 0.16(1) keV} are comparable with the ones from dispersion\nrelations and PDG values. Using the parameters from QCD spectral sum rules, we\ncomplete our analysis by showing that the production rates of unmixed scalar\ngluonia sigma_B(1) and G (1.5-1.6) agree with the data from J/\\psi, phi\nradiative and D_s semi-leptonic decays. \n\n"}
{"id": "1009.3165", "contents": "Title: A unifying framework for the derivation and analysis of effective\n  classes of one-step methods for ODEs Abstract: In this paper, we provide a simple framework to derive and analyse several\nclasses of effective one-step methods. The framework consists in the\ndiscretization of a local Fourier expansion of the continuous problem.\nDifferent choices of the basis lead to different classes of methods, even\nthough we shall here consider only the case of an orthonormal polynomial basis,\nfrom which a large subclass of Runge-Kutta methods is derived. The obtained\nresults are then applied to prove, in a simplified way, the order and stability\nproperties of Hamiltonian BVMs (HBVMs), a recently introduced class of energy\npreserving methods for canonical Hamiltonian systems. A few numerical tests\nwith such methods are also included, in order to confirm the effectiveness of\nthe methods. \n\n"}
{"id": "1009.5379", "contents": "Title: Color Sextet Vector Bosons and Same-Sign Top Quark Pairs at the LHC Abstract: We investigate the production of beyond-the-standard-model color-sextet\nvector bosons at the Large Hadron Collider and their decay into a pair of\nsame-sign top quarks. We demonstrate that the energy of the charged lepton from\nthe top quark semi-leptonic decay serves as a good measure of the top-quark\npolarization, which, in turn determines the quantum numbers of the boson and\ndistinguishes vector bosons from scalars. \n\n"}
{"id": "1010.2745", "contents": "Title: High-order quantum algorithm for solving linear differential equations Abstract: Linear differential equations are ubiquitous in science and engineering.\nQuantum computers can simulate quantum systems, which are described by a\nrestricted type of linear differential equations. Here we extend quantum\nsimulation algorithms to general inhomogeneous sparse linear differential\nequations, which describe many classical physical systems. We examine the use\nof high-order methods to improve the efficiency. These provide scaling close to\n$\\Delta t^2$ in the evolution time $\\Delta t$. As with other algorithms of this\ntype, the solution is encoded in amplitudes of the quantum state, and it is\npossible to extract global features of the solution. \n\n"}
{"id": "1010.4711", "contents": "Title: End-point behavior of the pion distribution amplitude Abstract: We discuss the end-point behavior of the pion distribution amplitude (DA) and\ncalculate its slope using QCD sum rules with nonlocal condensates. This is done\nin terms of the standard derivative and also with the help of an \"integral\nderivative\", recently obtained by us. Our approach favors a value of the slope\nof the order (or less) of the asymptotic DA and is in clear disagreement with\nflat-type pion DAs. \n\n"}
{"id": "1011.3519", "contents": "Title: Proton size anomaly Abstract: A measurement of the Lamb shift in muonic hydrogen yields a charge radius of\nthe proton that is smaller than the CODATA value by about 5 standard\ndeviations. We explore the possibility that new scalar, pseudoscalar, vector,\nand tensor flavor-conserving nonuniversal interactions may be responsible for\nthe discrepancy. We consider exotic particles that among leptons, couple\npreferentially to muons, and mediate an attractive nucleon-muon interaction. We\nfind that the many constraints from low energy data disfavor new spin-0, spin-1\nand spin-2 particles as an explanation. \n\n"}
{"id": "1011.5969", "contents": "Title: Performance of Glass Resistive Plate Chambers for a high granularity\n  semi-digital calorimeter Abstract: A new design of highly granular hadronic calorimeter using Glass Resistive\nPlate Chambers (GRPCs) with embedded electronics has been proposed for the\nfuture International Linear Collider (ILC) experiments. It features a 2-bit\nthreshold semi-digital read-out. Several GRPC prototypes with their electronics\nhave been successfully built and tested in pion beams. The design of these\ndetectors is presented along with the test results on efficiency, pad\nmultiplicity, stability and reproducibility. \n\n"}
{"id": "1011.6665", "contents": "Title: Studies of the performance of the ATLAS detector using cosmic-ray muons Abstract: Muons from cosmic-ray interactions in the atmosphere provide a\nhigh-statistics source of particles that can be used to study the performance\nand calibration of the ATLAS detector. Cosmic-ray muons can penetrate to the\ncavern and deposit energy in all detector subsystems. Such events have played\nan important role in the commissioning of the detector since the start of the\ninstallation phase in 2005 and were particularly important for understanding\nthe detector performance in the time prior to the arrival of the first LHC\nbeams. Global cosmic-ray runs were undertaken in both 2008 and 2009 and these\ndata have been used through to the early phases of collision data-taking as a\ntool for calibration, alignment and detector monitoring. These large datasets\nhave also been used for detector performance studies, including investigations\nthat rely on the combined performance of different subsystems. This paper\npresents the results of performance studies related to combined tracking,\nlepton identification and the reconstruction of jets and missing transverse\nenergy. Results are compared to expectations based on a cosmic-ray event\ngenerator and a full simulation of the detector response. \n\n"}
{"id": "1012.0067", "contents": "Title: A Model For Late Dark Matter Decay Abstract: The standard cold dark matter cosmological model, while successful in\nexplaining the observed large scale structure of the Universe, tends to\noverpredict structure on small scales. It has been proposed this problem may be\nalleviated in a class of late-decaying dark matter models, in which the parent\ndark matter particle decays to an almost degenerate daughter, plus a\nrelativistic final state. We construct explicit particle physics models that\nrealize this goal while obeying observational constraints. To achieve this, we\nintroduce a pair of fermionic dark matter candidates and a new scalar field,\nwhich obey either a Z4 or a U(1) symmetry. Through the spontaneous breaking of\nthese symmetries, and coupling of the new fields to standard model particles,\nwe demonstrate that the desired decay process may be obtained. We also discuss\nthe dark matter production processes in these models. \n\n"}
{"id": "1012.1082", "contents": "Title: Cosmology: Neutrinos as the Only Final Dark Matter Abstract: Even though neutrinos and antineutrinos are everywhere in the Universe, their\ncritical importance might be overlooked, especially because that at least one\nspecies of neutrinos has the mass 0.058 eV, far larger than the cosmic\nthermalization temperature 1.9^\\circ K. The non-zero mass makes neutrinos\nparticipate the galaxy formation from the very beginning, in view of the\nprocess of clustering. Unlike the cosmic microwave background (CMB), the cosmic\nbackground neutrinos (CB\\nu) cannot be uniform. Thus, we wish to examine the\nquestions such as: Is there some new source for neutrinos or antineutrinos,\nthat might be detectible experimentally? Is there some new interaction of\nneutrinos with the visible world, that may be of numerical importance at, e.g.,\nthe ultra high energies (\\ge 10^{13} eV)? One major conclusion is that, on the\nbasis of the Standard Model, neutrinos would eventually become the {\\it only}\ndark-matter species left in our Universe.\n  Our Cosmos is limited in energy for various particles, electrons or photons\nwithout threshold, while protons or neutrinos having the following hurdles to\novercome in reaching extreme energies such as 10^{18} eV. In an electron-rich\nmedium, the threshold is 10^{15} eV for an ultra high energy (UHECR) proton,\ndue to p + e^- \\to n + \\nu_e. On the other hand, the cosmic background\nneutrinos would cut off UHECR neutrinos of greater than 10^{13} eV if at least\none kind of neutrinos has the mass 0.05 eV (as suggested by the experimental\nvalue of 0.058 eV), due to \\nu +{\\bar \\nu}_{CB} \\to e^- + e^+; this, plus the\nclustering due to mass, gives us some hope that this effect might be\ndetectible. \n\n"}
{"id": "1012.1316", "contents": "Title: SUSY Digs up a Buried Higgs Abstract: The Higgs boson may dominantly decay to 4 light jets through a light\npseudo-scalar intermediary: h -> 2 eta -> 4j, making reconstruction at the LHC\nparticularly challenging. We explore the phenomenology of such \"Buried Higgs\"\nscenarios in which the primary discovery channel of the Higgs is in cascade\ndecays of superpartners. QCD backgrounds that would otherwise overwhelm the\nHiggs decay are suppressed by the requirement of high p_T jets and large\nmissing transverse momentum that are the typical signatures of TeV scale\nsupersymmetry. Utilizing jet substructure techniques, we find that for buried\nHiggses in the 100-120 GeV range, a 5-sigma discovery can be expected with\nroughly 10-25 inverse fb of data at E_CM = 14 TeV. For lighter Higgs bosons,\nthe signal is contaminated by hadronically decaying W bosons, and discovery\nremains an unsolved challenge. \n\n"}
{"id": "1012.2323", "contents": "Title: A note on the efficient implementation of Hamiltonian BVMs Abstract: We discuss the efficient implementation of Hamiltonian BVMs (HBVMs), a\nrecently introduced class of energy preserving methods for canonical\nHamiltonian systems, via their blended formulation. We also discuss the case of\nseparable problems, for which the structure of the problem can be exploited to\ngain efficiency. \n\n"}
{"id": "1101.1179", "contents": "Title: Soft topological objects in topological media Abstract: Topological invariants in terms of the Green's function in momentum and real\nspace determine properties of smooth textures within topological media. In\nspace dimension D=1 the topological invariant N_3 in terms of the Green's\nfunction G(\\omega,k_x,x) determines the fermion number of the 1D soliton, while\nin space dimension D=3 the topological invariant N_5 in terms of the Green's\nfunction G(\\omega,k_x,k_y,k_z,z) determines quantization of Hall conductivity\nin the soliton plane within the topological insulators. \n\n"}
{"id": "1101.1624", "contents": "Title: The Conformal Anomaly and the Neutral Currents Sector of the Standard\n  Model Abstract: We elaborate on the structure of the graviton-gauge-gauge vertex in the\nelectroweak theory, obtained by the insertion of the complete energy-momentum\ntensor ($T$) on 2-point functions of neutral gauge currents ($VV'$). The vertex\ndefines the leading contribution to the effective action which accounts for the\nconformal anomaly and related interaction between the Standard Model and\ngravity. The energy momentum tensor is derived from the curved spacetime\nLagrangian in the linearized gravitational limit, and with the inclusion of the\nterm of improvement of a conformally coupled Higgs sector. As in the previous\ncases of QED and QCD, we find that the conformal anomaly induces an effective\nmassless scalar interaction between gravity and the neutral currents in each\ngauge invariant component of the vertex. This is described by the exchange of\nan anomaly pole. We show that for a spontaneously broken theory the anomaly can\nbe entirely attributed to the poles only for a conformally coupled Higgs\nscalar. In the exchange of a graviton, the trace part of the corresponding\ninteraction can be interpreted as due to an effective dilaton, using a local\nversion of the effective action. We discuss the implications of the anomalous\nWard identity for the $TVV'$ correlator for the structure of the gauge/gauge/\neffective dilaton vertex in the effective action. The analogy between these\neffective interactions and those related to the radion in theories with large\nextra dimensions is pointed out. \n\n"}
{"id": "1101.5546", "contents": "Title: Solvability by semigroup : Application to seismic imaging with complex\n  decomposition of wave equations and migration operators with idempotents Abstract: The classical approach of solvability using group theory is well known and\none original motivation is to solve polynomials by radicals. Radicals are\nsquare, cube, square root, cube root etc of the original coefficients for the\npolynomial. A polynomial is solvable by radicals if the permutation group is\nsolvable. This is exact solvability via group theory. With modern computers, we\nmight need to relax our definition of exact solvability and move towards\npractical solvability. We will address seismic imaging as an example of\npractical solvability by semigroup theory. The difference between semigroup and\ngroup is that the semigroup operators do not have to be invertible as in group\noperators. Using the metaphor of complex decomposition, we will decompose an\noperator into simple part and complex part. The simple part of the operator is\nsolvable by numerical methods. The complex part of the operator is\ninterpretable but not numerically solvable. It is sometimes called the\nevanescent energy in geophysics. \n\n"}
{"id": "1102.3263", "contents": "Title: Roles of axial anomaly on neutral quark matter with color\n  superconducting phase Abstract: We investigate effects of the axial anomaly term with a chiral-diquark\ncoupling on the phase diagram within a two-plus-one-flavor Nambu-Jona-Lasinio\n(NJL) model under the charge-neutrality and $\\beta$-equilibrium constraints. We\nfind that when such constraints are imposed, the new anomaly term plays a quite\nsimilar role as the vector interaction does on the phase diagram, which the\npresent authors clarified in a previous work. Thus, there appear several types\nof phase structures with multiple critical points at low temperature $T$,\nalthough the phase diagrams with intermediate-$T$ critical point(s) are never\nrealized without these constraints even within the same model Lagrangian. This\ndrastic change is attributed to an enhanced interplay between the chiral and\ndiquark condensates due to the anomaly term at finite temperature; the u-d\ndiquark coupling is strengthened by the relatively large chiral condensate of\nthe strange quark through the anomaly term, which in turn definitely leads to\nthe abnormal behavior of the diquark condensate at finite $T$, inherent to the\nasymmetric quark matter. We note that the critical point from which the\ncrossover region extends to zero temperature appears only when the strength of\nthe vector interaction is larger than a critical value. We also show that the\nchromomagnetic instability of the neutral asymmetric homogenous two-flavor\ncolor superconducting(2CSC) phase is suppressed and can be even completely\ncured by the enhanced diquark coupling due to the anomaly term and/or by the\nvector interaction. \n\n"}
{"id": "1102.3753", "contents": "Title: Possibility of QCD critical point sweep during black hole formation Abstract: We discuss the possibility to probe the QCD critical point during the\ndynamical black hole formation from a gravitational collapse of a massive star,\nwhere the temperature and the baryon chemical potential become as high as T ~\n90 MeV and $\\mu_B$ ~ 1300 MeV. Comparison with the phase boundary in chiral\neffective models suggests that quark matter is likely to be formed before the\nhorizon is formed. Furthermore, the QCD critical point may be probed during the\nblack hole formation. The critical point is found to move in the lower\ntemperature direction in asymmetric nuclear matter, and in some of the chiral\nmodels it is found to be in the reachable region during the black hole\nformation processes. \n\n"}
{"id": "1102.3997", "contents": "Title: Conformal Completion of the Standard Model with a Fourth Generation Abstract: We study dynamical electroweak symmetry breaking with a fourth generation\nwithin the $Z_n$ orbifolded $AdS_5\\otimes S^5$ framework. A realistic $Z_7$\nexample is discussed. The initial theory reduces dynamically, due to the\ninduced condensates, to a four-family trinification near a TeV-scale conformal\nfixed point where the gauge hierarchy problem does not exist. We predict new\ngauge bosons and bifundamental fermions and scalars accessible by the LHC. \n\n"}
{"id": "1103.1948", "contents": "Title: Nucleon properties in nuclear matter Abstract: We present recent studies on the effective mass of the nucleon in infinite\nand homogeneous nuclear matter and its relation to nuclear matter properties\nwithin the framework of the in-medium modified Skyrme model. Medium\nmodifications are achieved by introducing optical potential for pion fields and\nparametrization of the Skyrme parameter in nuclear medium. The present approach\nis phenomenologically well justified by pion physics in nuclear matter and\ndescribe successfully bulk nuclear matter properties. \n\n"}
{"id": "1103.2948", "contents": "Title: Full analysis of the Green's function for a singularly perturbed\n  convection-diffusion problem in three dimensions Abstract: A linear singularly perturbed convection-diffusion problem with\ncharacteristic layers is considered in three dimensions. Sharp bounds for the\nassociated Green's function and its derivatives are established in the $L_1$\nnorm. The dependence of these bounds on the small perturbation parameter is\nshown explicitly. The obtained estimates will be used in a forthcoming\nnumerical analysis of the considered problem.\n  The present article is a more detailed version of our recent paper [7]. \n\n"}
{"id": "1103.4645", "contents": "Title: Variational and linearly-implicit integrators, with applications Abstract: We show that symplectic and linearly-implicit integrators proposed by [Zhang\nand Skeel, 1997] are variational linearizations of Newmark methods. When used\nin conjunction with penalty methods (i.e., methods that replace constraints by\nstiff potentials), these integrators permit coarse time-stepping of\nholonomically constrained mechanical systems and bypass the resolution of\nnonlinear systems. Although penalty methods are widely employed, an explicit\nlink to Lagrange multiplier approaches appears to be lacking; such a link is\nnow provided (in the context of two-scale flow convergence [Tao, Owhadi and\nMarsden, 2010]). The variational formulation also allows efficient simulations\nof mechanical systems on Lie groups. \n\n"}
{"id": "1104.2365", "contents": "Title: Instantaneous frequency and wave shape functions (I) Abstract: Although one can formulate an intuitive notion of instantaneous frequency,\ngeneralizing \"frequency\" as we understand it in e.g. the Fourier transform, a\nrigorous mathematical definition is lacking. In this paper, we consider a class\nof functions composed of waveforms that repeat nearly periodically, and for\nwhich the instantaneous frequency can be given a rigorous meaning. We show that\nSynchrosqueezing can be used to determine the instantaneous frequency of\nfunctions in this class, even if the waveform is not harmonic, thus\ngeneralizing earlier results for cosine wave functions. We also provide\nreal-life examples and discuss the advantages, for these examples, of\nconsidering such non-harmonic waveforms. \n\n"}
{"id": "1104.3819", "contents": "Title: Wave functions and decay constants of $B$ and $D$ mesons in the\n  relativistic potential model Abstract: With the decay constants of $D$ and $D_s$ mesons measured in experiment\nrecently, we revisit the study of the bound states of quark and antiquark in\n$B$ and $D$ mesons in the relativistic potential model. The relativistic bound\nstate wave equation is solved numerically. The masses, decay constants and wave\nfunctions of $B$ and $D$ mesons are obtained. Both the masses and decay\nconstants obtained here can be consistent with the experimental data. The wave\nfunctions can be used in the study of $B$ and $D$ meson decays. \n\n"}
{"id": "1104.5389", "contents": "Title: Anomaly Puzzle, Curved-Spacetime Spinor Hamiltonian, and String\n  Phenomenology Abstract: In the first part of this dissertation, we study two different aspects of\nstring phenomenology. First we discuss the complementary signals of low mass\nsuperstrings at the proposed electron-positron facilities (ILC and CLIC), in\ne+e- and {\\gamma} {\\gamma} collisions. We examine all relevant four-particle\namplitudes evaluated at the center of mass energies near the mass of lightest\nRegge excitations and extract the corresponding pole terms. Secondly, we\nconsider string realizations of the Randall-Sundrum effective theory and\nexplore the search for the lowest massive Regge excitation of the gluon and of\nthe extra (color singlet) gauge boson inherent of D-brane constructions. We\nalso study the ratio of dijet mass spectra at small and large scattering\nangles. We show that with the first fb-1 such a ratio can probe lowest-lying\nRegge states for masses ~3.0 TeV. Finally, we propose that the 3.2$\\sigma$\nexcess at about $140 {\\rm GeV}$ in the dijet mass spectrum of $W$ + jets\nreproted by the CDF Collaboration originates in the decay of a leptophobic $Z'$\nthat can be related to the U(1) symmetries inherent of D-brane models. In the\nremaining parts of this dissertation, we discuss several points that may help\nto clarify some questions that remain about the anomaly puzzle in N=1\nsupersymmetric Yang-Mills theory and we investigate the issue that the Dirac\nHamiltonian of a spin-1/2 particle in a curved background appears to be\nnon-hermitian. \n\n"}
{"id": "1105.0298", "contents": "Title: Analysis and correction of the magnetic field effects in the Hybrid\n  Photo-Detectors of the RICH2 Ring Imaging Cherenkov detector of LHCb Abstract: The Ring Imaging Cherenkov detectors of the LHCb experiment at the Large\nHadron Collider at CERN are equipped with Hybrid Photo-Detectors. These vacuum\nphoto-detectors are affected by the stray magnetic field of the LHCb magnet,\nwhich degrades their imaging properties. This effect increases the error on the\nCherenkov angle measurement and would reduce the particle identification\ncapabilities of LHCb. A system has been developed for the RICH2 Ring Imaging\nCherenkov detector to perform a detailed characterisation of the magnetic\ndistortion effects. It is described, along with the methods implemented to\ncorrect for these effects, restoring the optimal resolution. \n\n"}
{"id": "1105.3021", "contents": "Title: Widths of embeddings of 2-microlocal Besov spaces Abstract: We consider the asymptotic behaviour of the approximation, Gelfand and\nKolmogorov numbers of compact embeddings between 2-microlocal Besov spaces with\nweights defined in terms of the distance to a $d$-set $U\\subset \\mathbb{R}^n$.\nThe sharp estimates are shown in most cases, where the quasi-Banach setting is\nincluded. \n\n"}
{"id": "1106.0598", "contents": "Title: A Two Step, Fourth Order, Nearly-Linear Method with Energy Preserving\n  Properties Abstract: We introduce a family of fourth order two-step methods that preserve the\nenergy function of canonical polynomial Hamiltonian systems. Each method in the\nfamily may be viewed as a correction of a linear two-step method, where the\ncorrection term is O(h^5) (h is the stepsize of integration). The key tools the\nnew methods are based upon are the line integral associated with a conservative\nvector field (such as the one defined by a Hamiltonian dynamical system) and\nits discretization obtained by the aid of a quadrature formula. Energy\nconservation is equivalent to the requirement that the quadrature is exact,\nwhich turns out to be always the case in the event that the Hamiltonian\nfunction is a polynomial and the degree of precision of the quadrature formula\nis high enough. The non-polynomial case is also discussed and a number of test\nproblems are finally presented in order to compare the behavior of the new\nmethods to the theoretical results. \n\n"}
{"id": "1106.0694", "contents": "Title: Nuclear recoil scintillation and ionisation yields in liquid xenon from\n  ZEPLIN-III data Abstract: Scintillation and ionisation yields for nuclear recoils in liquid xenon above\n10 keVnr (nuclear recoil energy) are deduced from data acquired using broadband\nAm-Be neutron sources. The nuclear recoil data from several exposures to two\nsources were compared to detailed simulations. Energy-dependent scintillation\nand ionisation yields giving acceptable fits to the data were derived.\nEfficiency and resolution effects are treated using a light collection Monte\nCarlo, measured photomultiplier response profiles and hardware trigger studies.\nA gradual fall in scintillation yield below ~40 keVnr is found, together with a\nrising ionisation yield; both are in good agreement with the latest independent\nmeasurements. The analysis method is applied to both the most recent ZEPLIN-III\ndata, acquired with a significantly upgraded detector and a\nprecision-calibrated Am-Be source, as well as to the earlier data from the\nfirst run in 2008. A new method for deriving the recoil scintillation yield,\nwhich includes sub-threshold S1 events, is also presented which confirms the\nmain analysis. \n\n"}
{"id": "1106.3209", "contents": "Title: High-energy physics with particles carrying non-zero orbital angular\n  momentum Abstract: Thanks to progress in optics in the past two decades, it is possible to\ncreate photons carrying well-defined non-zero orbital angular momentum (OAM).\nBoosting these photons into high-energy range preserving their OAM seems\nfeasible. Intermediate energy electrons with OAM have also been produced\nrecently. One can, therefore, view OAM as a new degree of freedom in\nhigh-energy collisions and ask what novel insights into particles' structure\nand interactions it can bring. Here we discuss generic features of scattering\nprocesses involving particles with OAM in the initial state. We show that they\nmake it possible to perform a Fourier analysis of a plane wave cross section\nwith respect to the azimuthal angles of the initial particles, and to probe the\nautocorrelation function of the amplitude, a quantity inaccessible in plane\nwave collisions. \n\n"}
{"id": "1106.3630", "contents": "Title: The NEXT-100 experiment for neutrinoless double beta decay searches\n  (Conceptual Design Report) Abstract: We propose an EASY (Electroluminescent ApparatuS of high Yield) and SOFT\n(Separated Optimized FuncTion) time-projection chamber for the NEXT experiment,\nthat will search for neutrinoless double beta decay (bb0nu) in Xe-136. Our\nexperiment must be competitive with the new generation of bb0nu searches\nalready in operation or in construction. This requires a detector with very\ngood energy resolution (<1%), very low background con- tamination (1E-4\ncounts/(keV \\bullet kg \\bullet y)) and large target mass. In addition, it needs\nto be operational as soon as possible. The design described here optimizes\nenergy resolution thanks to the use of proportional electroluminescent\namplification (EL); it is compact, as the Xe gas is under high pressure; and it\nallows the measurement of the topological signature of the event to further\nreduce the background contamination. The SOFT design uses different sensors for\ntracking and calorimetry. We propose the use of SiPMs (MPPCs) coated with a\nsuitable wavelength shifter for the tracking, and the use of radiopure\nphotomultipliers for the measurement of the energy and the primary\nscintillation needed to estimate the t0. This design provides the best possible\nenergy resolution compared with other NEXT designs based on avalanche gain\ndevices. The baseline design is an Asymmetric Neutrino Gas EL apparatus\n(ANGEL), which was already outlined in the NEXT LOI. ANGEL is conceived to be\neasy to fabricate. It requires very little R&D and most of the proposed\nsolutions have already been tested in the NEXT-1 prototypes. Therefore, the\ndetector can be ready by 2013. In this Conceptual Design Report (CDR) we\ndiscuss first the physics case, present a full design of the detector, describe\nthe NEXT-1 EL prototypes and their initial results, and outline a project to\nbuild a detector with 100 kg of enriched xenon to be installed in the Canfranc\nUnderground Laboratory in 2013. \n\n"}
{"id": "1106.6014", "contents": "Title: On the expected number of zeros of nonlinear equations Abstract: This paper investigates the expected number of complex roots of nonlinear\nequations. Those equations are assumed to be analytic, and to belong to certain\ninner product spaces. Those spaces are then endowed with the Gaussian\nprobability distribution.\n  The root count on a given domain is proved to be `additive' with respect to a\nproduct operation of functional spaces. This allows to deduce a general theorem\nrelating the expected number of roots for unmixed and mixed systems. Examples\nof root counts for equations that are not polynomials nor exponential sums are\ngiven at the end. \n\n"}
{"id": "1107.0245", "contents": "Title: Higgs Boson Self-Coupling at High Energy $\\gamma \\gamma$ Collider Abstract: We analyzed the double production and the triple self-coupling of the\nstandard model Higgs boson at future $\\gamma \\gamma$ collider energies, with\nthe reactions $\\gamma\\gamma \\rightarrow f \\bar f HH$ $(f=b, t)$. We evaluated\nthe total cross section for $f\\bar fHH$ and calculated the total number of\nevents considering the complete set of Feynman diagrams at tree-level and for\ndifferent values of the triple coupling $\\kappa\\lambda_{HHH}$. We have also\nanalyzed the sensitivity for the considered reaction and we show the results as\n95% C.L. regions in the $\\kappa-M_H$ plane for different values of the center\nof mass energy and different levels of background. The numerical computation\nwas done for the energies which are expected to be available at a possible\nFuture Linear $\\gamma\\gamma$ Collider with a center-of-mass energy 500-3000\n$GeV$ and luminosities of 1 and $5 ab^{-1}$. We found that the number of events\nfor the process $\\gamma\\gamma \\rightarrow t \\bar t HH$, taking into account the\ndecay products of both $t$ and $H$, is small but enough to obtain information\non the triple Higgs boson self-coupling in a independent way, complementing\nother studies on the triple vertex. \n\n"}
{"id": "1107.0443", "contents": "Title: What do the radiative decays of X(3872) tell us Abstract: Since the discovery of X(3872), its structure has been in ceaseless dispute.\nThe data of $X(3872)\\rightarrow \\pi^+\\pi^-\\pi^0 J/\\psi$ suggest that X(3872)\nmay be a high-spin charmonium-like of $2^{-+}$. In terms of the light front\nquark model (LFQM) we calculate the rates of the radiative decays\n$X(3872)\\rightarrow J/\\psi(\\psi')\\gamma$ supposing X(3872) to be a $2^{-+}$\ncharmonium. Within this framework, our theoretical prediction on\n$\\mathcal{BR}(X(3872)\\rightarrow\\psi(1S)\\gamma)$ is at order of $10^{-3}$ which\nis slightly lower than the Babar's data but close to the Belle's. Our\nprediction on $\\mathcal{BR}(X(3872)\\rightarrow\\psi'\\gamma)$ is at order of\n$10^{-5}$ if $\\psi'$ is a pure 2S state or $10^{-4}$ if $\\psi'$ is a $2S-1D$\nmixture, which does not conflict with the upper bound set by the Belle\ncollaboration, but is much lower than the Babar's data. Thus if the future\nmeasurement decides the branching ratio of\n$\\mathcal{BR}(X(3872)\\rightarrow\\psi'\\gamma)$ to be much larger than $10^{-4}$,\nthe $2^{-+}$ assignment for X(3872) should be ruled out. \n\n"}
{"id": "1107.3317", "contents": "Title: Fluctuation Probes of Early-Time Correlations in Nuclear Collisions Abstract: Correlation measurements imply that anisotropic flow in nuclear collisions\nincludes a novel triangular component along with the more familiar\nelliptic-flow contribution. Triangular flow has been attributed to event-wise\nfluctuations in the initial shape of the collision volume. We ask two\nquestions: 1) How do these shape fluctuations impact other event-by-event\nobservables? 2) Can we disentangle fundamental information on the early time\nfluctuations from the complex flow that results? We study correlation and\nfluctuation observables in a framework in which flux tubes in an early Glasma\nstage later produce hydrodynamic flow. Calculated multiplicity and transverse\nmomentum fluctuations are in excellent agreement with data from 62.4 GeV Au+Au\nup to 2.76 TeV Pb+Pb. \n\n"}
{"id": "1108.1128", "contents": "Title: Cosmic-ray antiproton constraints on light singlino-like dark matter\n  candidates Abstract: The CoGeNT experiment, dedicated to direct detection of dark matter, has\nrecently released excess events that could be interpreted as elastic collisions\nof $\\sim$10 GeV dark matter particles, which might simultaneously explain the\nstill mysterious DAMA/LIBRA modulation signals, while in conflict with results\nfrom other experiments such as CDMS, XENON-100 and SIMPLE. It was shown that\n5-15 GeV singlino-like dark matter candidates arising in singlet extensions of\nminimal supersymmetric scenarios can fit these data; annihilation then mostly\nproceeds into light singlet-dominated Higgs (pseudo)scalar fields. We develop\nan effective Lagrangian approach to confront these models with the existing\ndata on cosmic-ray antiprotons, including the latest PAMELA data. Focusing on a\nparameter space consistent with the CoGeNT region, we show that the predicted\nantiproton flux is generically in tension with the data whenever the produced\n(pseudo)scalars can decay into quarks energetic enough to produce antiprotons,\nprovided the annihilation S-wave is significant at freeze out in the early\nuniverse. In this regime, a bound on the singlino annihilation cross section is\nobtained, $\\sigv\\lesssim 10^{-26}\\,{\\rm cm^3/s}$, assuming a dynamically\nconstrained halo density profile with a local value of $\\rho_\\odot = 0.4\\,{\\rm\nGeV/cm^3}$. Finally, we provide indications on how PAMELA or AMS-02 could\nfurther constrain or detect those configurations producing antiprotons which\nare not yet excluded. \n\n"}
{"id": "1108.5409", "contents": "Title: An efficient second order in time scheme for approximating long time\n  statistical properties of the two dimensional Navier-Stokes equations Abstract: We investigate the long tim behavior of the following efficient second order\nin time scheme for the 2D Navier-Stokes equation in a periodic box: $$\n\\frac{3\\omega^{n+1}-4\\omega^n+\\omega^{n-1}}{2k} +\n\\nabla^\\perp(2\\psi^n-\\psi^{n-1})\\cdot\\nabla(2\\omega^n-\\omega^{n-1}) -\n\\nu\\Delta\\omega^{n+1} = f^{n+1}, \\quad -\\Delta \\psi^n = \\om^n. $$ The scheme is\na combination of a 2nd order in time backward-differentiation (BDF) and a\nspecial explicit Adams-Bashforth treatment of the advection term. Therefore\nonly a linear constant coefficient Poisson type problem needs to be solved at\neach time step. We prove uniform in time bounds on this scheme in $\\dL2$,\n$\\dH1$ and $\\dot{H}^2_{per}$ provided that the time-step is sufficiently small.\nThese time uniform estimates further lead to the convergence of long time\nstatistics (stationary statistical properties) of the scheme to that of the NSE\nitself at vanishing time-step. Fully discrete schemes with either Galerkin\nFourier or collocation Fourier spectral method are also discussed. \n\n"}
{"id": "1109.1703", "contents": "Title: On the origin and acceleration of cosmic rays: Cooling flow clusters and\n  AGN hosts Abstract: We are looking for radio `relics' and `halos' in an X-ray selected sample of\nclusters of galaxies. These radio features are not a product of the Active\nGalactic Nuclei (AGN)-mechanism, but more likely are associated with past\ncluster merger events. AGN hosts of cooling flow clusters contain particle\nbubbles that show non-thermal radio emission. These bubbles could explain the\npresence of radio relics and halos if they can restrict cosmic rays\nefficiently. Intracluster magnetic fields and cluster environments can reveal\nthe acceleration mechanisms of cosmic rays. Using radio/X-ray data and\nanalytical methods we examine three AGN hosts out of our 70 clusters, namely\nHercules A, 3C310 and 3C388. We found that none of these clusters contain\nrelics and/or halos. \n\n"}
{"id": "1109.2979", "contents": "Title: The DarkSide Program at LNGS Abstract: DarkSide is a direct detection dark matter program based on two phase time\nprojection chambers with depleted argon targets. The DarkSide detectors are\ndesigned, using novel low background techniques and active shielding, to be\ncapable of demonstrating in situ a very low level of residual background. This\nmeans that each detector in the DarkSide program should have the ability to\nmake a convincing claim of dark matter detection based on the observation of a\nfew nuclear recoil events. The collaboration is currently operating a 10 kg\nprototype detector, DarkSide-10, in Laboratori Nazionali del Gran Sasso, Italy,\nwhile the first physics detector in the program, DarkSide-50, is expected to be\ndeployed at LNGS at the end of 2012. \n\n"}
{"id": "1109.4577", "contents": "Title: Non-relativistic bound states in a finite volume Abstract: We derive general results for the mass shift of bound states with angular\nmomentum l >= 1 in a periodic cubic box in two and three spatial dimensions.\nOur results have applications to lattice simulations of hadronic molecules,\nhalo nuclei, and Feshbach molecules. The sign of the mass shift can be related\nto the symmetry properties of the state under consideration. We verify our\nanalytical results with explicit numerical calculations. Moreover, we comment\non the relations connecting the effective range parameter, the binding momentum\nof a given state and the asymptotic normalization coefficient of the\ncorresponding wave function. We give explicit expressions for this relation in\nthe shallow binding limit. \n\n"}
{"id": "1110.4564", "contents": "Title: Z-matrix equations in max algebra, nonnegative linear algebra and other\n  semirings Abstract: We study the max-algebraic analogue of equations involving Z-matrices and\nM-matrices, with an outlook to a more general algebraic setting. We show that\nthese equations can be solved using the Frobenius trace down method in a way\nsimilar to that in non-negative linear algebra, characterizing the solvability\nin terms of supports and access relations. We give a description of the\nsolution set as combination of the least solution and the eigenspace of the\nmatrix, and provide a general algebraic setting in which this result holds. \n\n"}
{"id": "1110.6243", "contents": "Title: Test of CDF dijet anomaly within the standard model Abstract: Dijet anomaly reported by the CDF (Collider Detector at Fermilab)\ncollaboration in 1.96 TeV p-pbar collisions is investigated within the standard\nmodel by considering effects of parton distribution functions on various\nprocesses: W+dijet, Z+dijet, WW, ZW, and top production. Since the anomalous\npeak exists in the dijet-mass region of 140 GeV with the p-pbar center-of-mass\nenergy sqrt{s}=1.96 TeV, a relevant momentum fraction x of partons is roughly\n0.1. In this x region, recent HERMES semi-inclusive charged-lepton scattering\nexperiment indicated that the strange-quark distribution could be very\ndifferent from a conventional one, which has been used for many years, based on\nopposite-sign dimuon measurements in neutrino-induced deep inelastic\nscattering. We investigated effects of such variations in the strange-quark\ndistribution s(x) on the anomaly. We found that distributions of W+dijets and\nother process are affected by the strange-quark modifications in wide\ndijet-mass regions including the 140 GeV one. Since the CDF anomaly was\nobserved in the shoulder region of the dijet-mass distribution, a slight\nmodification of the distribution shape could explain at least partially the CDF\nexcess. Therefore, it is important to consider such effects within the standard\nmodel for judging whether the CDF anomaly indicates new physics beyond the\nstandard model. We also show modification effects of the strange-quark\ndistribution in the LHC (Large Hadron Collider) kinematics, where cross\nsections are sensitive to a smaller-x region of s(x). \n\n"}
{"id": "1111.2580", "contents": "Title: Dilaton at the LHC Abstract: The dilaton, a pseudo-Nambu-Goldstone boson appearing in spontaneous scale\nsymmetry breaking at a TeV scale f, may be found in Higgs boson searches. The\ndilaton couples to standard model fermions and weak bosons with the same\nstructure as the Higgs boson except for the overall strength. Additionally, the\ndilaton couples to a Higgs boson pair. The couplings of the dilaton to a gluon\npair and a photon pair, appearing at loop level, are largely enhanced compared\nto the corresponding Higgs couplings. We present regions of the mass and VEV of\nthe dilaton allowed by WW, ZZ, and gammagamma limits from the LHC at 7 TeV with\n1.0-2.3 fb-1 integrated luminosity. A scale of f less than 1 TeV is nearly\nexcluded. We discuss how the dilaton chi can be distinguished from the Higgs\nboson h by observation of the decays chi -> gammagamma and chi -> hh ->\n(WW)(WW). \n\n"}
{"id": "1111.4008", "contents": "Title: Solving the Hierarchy Problem with a Light Singlet and Supersymmetric\n  Mass Terms Abstract: A generalization of the Next-to-Minimal Supersymmetric Model (NMSSM) is\nstudied in which an explicit \\mu-term as well as a small supersymmetric mass\nterm for the singlet superfield are incorporated. We study the possibility of\nraising the Standard Model-like Higgs mass at tree level through its mixing\nwith a light, mostly-singlet, CP-even scalar. We are able to generate Higgs\nboson masses up to 145 GeV with top squarks below 1.1 TeV and without the need\nto fine tune parameters in the scalar potential. This model yields light\nsinglet-like scalars and pseudoscalars passing all collider constraints. \n\n"}
{"id": "1111.4544", "contents": "Title: Study of the Higgs-Yukawa theory in the strong-Yukawa coupling regime Abstract: In this article, we present an ongoing lattice study of the Higgs-Yukawa\nmodel, in the regime of strong-Yukawa coupling, using overlap fermions. We\ninvestigated the phase structure in this regime by computing the Higgs vacuum\nexpectation value, and by exploring the finite-size scaling behaviour of the\nsusceptibility corresponding to the magnetisation. Our preliminary results\nindicate the existence of a second-order phase transition when the Yukawa\ncoupling becomes large enough, at which the Higgs vacuum expectation value\nvanishes and the susceptibility diverges. \n\n"}
{"id": "1111.5471", "contents": "Title: D semileptonic form factors and |V_cs(d)| from 2+1 flavor lattice QCD Abstract: The measured partial widths of the semileptonic decays D to K l nu and D to\npi l nu can be combined with the form factors calculated on the lattice to\nextract the CKM matrix elements |V_cs| and |V_cd|. The lattice calculations can\nbe checked by comparing the form factor shapes from the lattice and experiment.\nWe have generated a sizable data set by using heavy clover quarks with the\nFermilab interpretation for charm and asqtad staggered light quarks on 2+1\nflavor MILC ensembles with lattice spacings of approximately 0.12, 0.09, 0.06,\nand 0.045 fm. Preliminary fits to staggered chiral perturbation theory suggest\nthat we can reduce the uncertainties in the form factors at zero invariant mass\nto below 5%. \n\n"}
{"id": "1111.6974", "contents": "Title: Weak lensing predictions for coupled dark energy cosmologies at\n  non-linear scales Abstract: We present non-linear weak lensing predictions for coupled dark energy models\nusing the CoDECS simulations. We calculate the shear correlation function and\nerror covariance expected for these models, for forthcoming ground-based (such\nas DES) and space-based (Euclid) weak lensing surveys. We obtain predictions\nfor the discriminatory power of a ground-based survey similar to DES and a\nspace-based survey such as Euclid in distinguishing between $\\Lambda$CDM and\ncoupled dark energy models; we show that using the non-linear lensing signal we\ncould discriminate between $\\Lambda$CDM and exponential constant coupling\nmodels with $\\beta_0\\geq0.1$ at $4\\sigma$ confidence level with a DES-like\nsurvey, and $\\beta_0\\geq0.05$ at $5\\sigma$ confidence level with Euclid. We\nalso demonstrate that estimating the coupled dark energy models' non-linear\npower spectrum, using the $\\Lambda$CDM Halofit fitting formula, results in\nbiases in the shear correlation function that exceed the survey errors. \n\n"}
{"id": "1112.3625", "contents": "Title: B-meson Semi-inclusive Decay to $2^{-+}$ Charmonium in NRQCD and X(3872) Abstract: The semi-inclusive B-meson decay into spin-singlet D-wave $2^{-+}$\ncharmonium, $B\\to \\eta_{c2}+X$, is studied in nonrelativistic QCD (NRQCD). Both\ncolor-singlet and color-octet contributions are calculated at next-to-leading\norder (NLO) in the strong coupling constant $\\alpha_s$. The non-perturbative\nlong-distance matrix elements are evaluated using operator evolution equations.\nIt is found that the color-singlet $^1D_2$ contribution is tiny, while the\ncolor-octet channels make dominant contributions. The estimated branching ratio\n$B(B\\to \\eta_{c2}+X)$ is about $0.41\\,\\times10^{-4}$ in the Naive Dimensional\nRegularization (NDR) scheme and $1.24\\,\\times10^{-4}$ in the t'Hooft-Veltman\n(HV) scheme, with renormalization scale $\\mu=m_b=4.8$\\,GeV. The\nscheme-sensitivity of these numerical results is due to cancelation between\n${}^1S_0^{[8]}$ and ${}^1P_1^{[8]}$ contributions. The $\\mu$-dependence curves\nof NLO branching ratios in both schemes are also shown, with $\\mu$ varying from\n$\\frac{m_b}{2}$ to $2m_b$ and the NRQCD factorization or renormalization scale\n$\\mu_{\\Lambda}$ taken to be $2m_c$. Comparison of the estimated branching ratio\nof $B\\to \\eta_{c2}+X$ with the observed branching ratio of $B \\to X(3872)+K$\nmay lead to the conclusion that X(3872) is unlikely to be the $2^{-+}$\ncharmonium state $\\eta_{c2}$. \n\n"}
{"id": "1112.4379", "contents": "Title: Calculating Determinants of Block Matrices Abstract: This paper presents a method for expressing the determinant of an N {\\times}\nN complex block matrix in terms of its constituent blocks. The result allows\none to reduce the determinant of a matrix with N^2 blocks to the product of the\ndeterminants of N distinct combinations of single blocks. This procedure proves\nuseful in the analytic description of physical systems with multiple discrete\nvariables, as it provides a systematic method for evaluating determinants which\nmight otherwise be analytically intractable. \n\n"}
{"id": "1201.0327", "contents": "Title: Local Linear Regression on Manifolds and its Geometric Interpretation Abstract: High-dimensional data analysis has been an active area, and the main focuses\nhave been variable selection and dimension reduction. In practice, it occurs\noften that the variables are located on an unknown, lower-dimensional nonlinear\nmanifold. Under this manifold assumption, one purpose of this paper is\nregression and gradient estimation on the manifold, and another is developing a\nnew tool for manifold learning. To the first aim, we suggest directly reducing\nthe dimensionality to the intrinsic dimension $d$ of the manifold, and\nperforming the popular local linear regression (LLR) on a tangent plane\nestimate. An immediate consequence is a dramatic reduction in the computation\ntime when the ambient space dimension $p\\gg d$. We provide rigorous theoretical\njustification of the convergence of the proposed regression and gradient\nestimators by carefully analyzing the curvature, boundary, and non-uniform\nsampling effects. A bandwidth selector that can handle heteroscedastic errors\nis proposed. To the second aim, we analyze carefully the behavior of our\nregression estimator both in the interior and near the boundary of the\nmanifold, and make explicit its relationship with manifold learning, in\nparticular estimating the Laplace-Beltrami operator of the manifold. In this\ncontext, we also make clear that it is important to use a smaller bandwidth in\nthe tangent plane estimation than in the LLR. Simulation studies and the Isomap\nface data example are used to illustrate the computational speed and estimation\naccuracy of our methods. \n\n"}
{"id": "1201.0693", "contents": "Title: Interacting hadron resonance gas meets lattice QCD Abstract: We present, in the framework of the interacting hadron resonance gas, an\nevaluation of thermodynamical quantities. The interaction is modelled via a\ncorrection for the finite size of the hadrons. We investigate the sensitivity\nof the model calculations on the radius of the hadrons, which is a parameter of\nthe model. Our calculations for thermodynamical quantities as energy and\nentropy densities and pressure are confronted with predictions using the\nlattice Quantum Chromodynamics (QCD) formalism. \n\n"}
{"id": "1201.1486", "contents": "Title: Parton Energy Loss in Two-Stream Plasma System Abstract: The energy loss of a fast parton scattering elastically in a weakly coupled\nquark-gluon plasma is formulated as an initial value problem. The approach is\ndesigned to study an unstable plasma, but it also reproduces the well known\nresult of energy loss in an equilibrium plasma. A two-stream system, which is\nunstable due to longitudinal chromoelectric modes, is discussed here some\ndetail. In particular, a strong time and directional dependence of the energy\nloss is demonstrated. \n\n"}
{"id": "1201.2691", "contents": "Title: Search for Dark Matter Satellites using the FERMI-LAT Abstract: Numerical simulations based on the Lambda-CDM model of cosmology predict a\nlarge number of as yet unobserved Galactic dark matter satellites. We report\nthe results of a Large Area Telescope (LAT) search for these satellites via the\ngamma-ray emission expected from the annihilation of weakly interacting massive\nparticle (WIMP) dark matter. Some dark matter satellites are expected to have\nhard gamma-ray spectra, finite angular extents, and a lack of counterparts at\nother wavelengths. We sought to identify LAT sources with these\ncharacteristics, focusing on gamma-ray spectra consistent with WIMP\nannihilation through the $b \\bar b$ channel. We found no viable dark matter\nsatellite candidates using one year of data, and we present a framework for\ninterpreting this result in the context of numerical simulations to constrain\nthe velocity-averaged annihilation cross section for a conventional 100 GeV\nWIMP annihilating through the $b \\bar b$ channel. \n\n"}
{"id": "1201.4465", "contents": "Title: Pathwise Holder convergence of the implicit Euler scheme for semi-linear\n  SPDEs with multiplicative noise Abstract: In this article we prove pathwise Holder convergence with optimal rates of\nthe implicit Euler scheme for semi-linear parabolic stochastic differential\nequations with multiplicative noise, set in a UMD Banach space X. We assume the\nnon-linearities to satisfy appropriate (local) Lipschitz conditions. The\nconvergence results are obtained by first proving corresponding results for the\nsplitting scheme. The results are applied to a class of second order parabolic\nSPDEs driven by multiplicative space-time white noise. \n\n"}
{"id": "1201.6302", "contents": "Title: Dark Matter from the Inflaton Field Abstract: We present a model where inflation and Dark Matter takes place via a single\nscalar field phi. Without introducing any new parameters we are able unify\ninflation and Dark Matter using a scalar field phi that accounts for inflation\nat an early epoch while it gives a Dark Matter WIMP particle at low energies.\nAfter inflation our universe must be reheated and we must have a long period of\nradiation dominated before the epoch of Dark Matter. Typically the inflaton\ndecays while it oscillates around the minimum of its potential. If the inflaton\ndecay is not complete or sufficient then the remaining energy density of the\ninflaton after reheating must be fine tuned to give the correct amount of Dark\nMatter. An essential feature here, is that Dark Matter-Inflaton particle is\nproduced at low energies without fine tuning or new parameters. This process\nuses the same coupling g as for the inflaton decay. Once the field phi becomes\nnon-relativistic it will decouple as any WIMP particle, since n_phi is\nexponentially suppressed. The correct amount of Dark Matter determines the\ncross section and we have a constraint between the coupling $g$ and the mass\n$m_o$ of phi. The unification scheme we present here has four free parameters,\ntwo for the scalar potential V(phi) given by the inflation parameter lambda of\nthe quartic term and the mass m_o. The other two parameters are the coupling\n$g$ between the inflaton phi and a scalar filed varphi and the coupling h\nbetween varphi with standard model particles psi or chi. These four parameters\nare already present in models of inflation and reheating process, without\nconsidering Dark Matter. Therefore, our unification scheme does not increase\nthe number of parameters and it accomplishes the desired unification between\nthe inflaton and Dark Matter for free. \n\n"}
{"id": "1201.6438", "contents": "Title: Weak Galerkin Methods for Second Order Elliptic Interface Problems Abstract: Weak Galerkin methods refer to general finite element methods for PDEs in\nwhich differential operators are approximated by their weak forms as\ndistributions. Such weak forms give rise to desirable flexibilities in\nenforcing boundary and interface conditions. A weak Galerkin finite element\nmethod (WG-FEM) is developed in this paper for solving elliptic partial\ndifferential equations (PDEs) with discontinuous coefficients and interfaces.\nThe paper also presents many numerical tests for validating the WG-FEM for\nsolving second order elliptic interface problems. For such interface problems,\nthe solution possesses a certain singularity due to the nonsmoothness of the\ninterface. A challenge in research is to design high order numerical methods\nthat work well for problems with low regularity in the solution. The best known\nnumerical scheme in the literature is of order one for the solution itself in\n$L_\\infty$ norm. It is demonstrated that the WG-FEM of lowest order is capable\nof delivering numerical approximations that are of order 1.75 in the usual\n$L_\\infty$ norm for $C^1$ or Lipschitz continuous interfaces associated with a\n$C^1$ or $H^2$ continuous solutions. Theoretically, it is proved that high\norder of numerical schemes can be designed by using the WG-FEM with polynomials\nof high order on each element. \n\n"}
{"id": "1202.0624", "contents": "Title: Recent results of Micromegas sDHCAL with a new readout chip Abstract: Calorimetry at future linear colliders could be based on a particle flow\napproach where granularity is the key to high jet energy resolution. Among\ndifferent technologies, Micromegas chambers with 1 cm2 pad segmentation are\nstudied for the active medium of a hadronic calorimeter. A chamber of 1 m2 with\n9216 channels read out by a low noise front-end ASIC called MICROROC has\nrecently been constructed and tested. Chamber design, ASIC circuitry and\npreliminary test beam results are reported. \n\n"}
{"id": "1202.5443", "contents": "Title: Divided Differences of Implicit Functions Abstract: Under general conditions, the equation $g(x,y) = 0$ implicitly defines $y$\nlocally as a function of $x$. In this article, we express divided differences\nof $y$ in terms of bivariate divided differences of $g$, generalizing a recent\nresult on divided differences of inverse functions. \n\n"}
{"id": "1202.5621", "contents": "Title: Data-Driven Time-Frequency Analysis Abstract: In this paper, we introduce a new adaptive data analysis method to study\ntrend and instantaneous frequency of nonlinear and non-stationary data. This\nmethod is inspired by the Empirical Mode Decomposition method (EMD) and the\nrecently developed compressed (compressive) sensing theory. The main idea is to\nlook for the sparsest representation of multiscale data within the largest\npossible dictionary consisting of intrinsic mode functions of the form $\\{a(t)\n\\cos(\\theta(t))\\}$, where $a \\in V(\\theta)$, $V(\\theta)$ consists of the\nfunctions smoother than $\\cos(\\theta(t))$ and $\\theta'\\ge 0$. This problem can\nbe formulated as a nonlinear $L^0$ optimization problem. In order to solve this\noptimization problem, we propose a nonlinear matching pursuit method by\ngeneralizing the classical matching pursuit for the $L^0$ optimization problem.\nOne important advantage of this nonlinear matching pursuit method is it can be\nimplemented very efficiently and is very stable to noise. Further, we provide a\nconvergence analysis of our nonlinear matching pursuit method under certain\nscale separation assumptions. Extensive numerical examples will be given to\ndemonstrate the robustness of our method and comparison will be made with the\nEMD/EEMD method. We also apply our method to study data without scale\nseparation, data with intra-wave frequency modulation, and data with incomplete\nor under-sampled data. \n\n"}
{"id": "1202.6181", "contents": "Title: A side-by-side comparison of Daya Bay antineutrino detectors Abstract: The Daya Bay Reactor Neutrino Experiment is designed to determine precisely\nthe neutrino mixing angle $\\theta_{13}$ with a sensitivity better than 0.01 in\nthe parameter sin$^22\\theta_{13}$ at the 90% confidence level. To achieve this\ngoal, the collaboration will build eight functionally identical antineutrino\ndetectors. The first two detectors have been constructed, installed and\ncommissioned in Experimental Hall 1, with steady data-taking beginning\nSeptember 23, 2011. A comparison of the data collected over the subsequent\nthree months indicates that the detectors are functionally identical, and that\ndetector-related systematic uncertainties exceed requirements. \n\n"}
{"id": "1203.0217", "contents": "Title: SGV 3.0 - a fast detector simulation Abstract: The need for fast simulation programs is emphasised, both in terms of the\nneed for \"rapid response\" to new results - in particular from the LHC - and new\ntheoretical ideas, and in terms of how to cope with multi-billion simulated\nevent samples. The latter would arise both from the need to be able to simulate\nsignificantly more events than expected in the real data, also for high\ncross-section processes, and the need to scan multi-parameter theories.\n  The {\\it Simulation \\`a Grande Vitesse}, SGV, is presented, and is shown to\nbe able to address these issues. The tracking performance of SGV is shown to\nreproduce very closely that of the full simulation and reconstruction of the\nILD concept. Preliminary results on how to also closely emulate the\ncalorimetric performance from full simulation is presented. The procedure is\nparametric, with no the need to simulate the detailed shower development, and\npromises to be many orders of magnitude faster than such approaches. Contrary\nto what is often the case with fast simulation programs, the procedure gives a\nsomewhat {\\it pessimistic} result, compared to the full simulation and\nreconstruction. \n\n"}
{"id": "1203.3750", "contents": "Title: Development of CMOS Pixel Sensors fully adapted to the ILD Vertex\n  Detector Requirements Abstract: CMOS Pixel Sensors are making steady progress towards the specifications of\nthe ILD vertex detector. Recent developments are summarised, which show that\nthese devices are close to comply with all major requirements, in particular\nthe read-out speed needed to cope with the beam related background. This\nachievement is grounded on the double- sided ladder concept, which allows\ncombining signals generated by a single particle in two different sensors, one\ndevoted to spatial resolution and the other to time stamp, both assembled on\nthe same mechanical support. The status of the development is overviewed as\nwell as the plans to finalise it using an advanced CMOS process. \n\n"}
{"id": "1203.5976", "contents": "Title: The MRPC-based ALICE Time-Of-Flight detector: status and performance Abstract: The large Time-Of-Flight (TOF) array is one of the main detectors devoted to\ncharged hadron identification in the mid-rapidity region of the ALICE\nexperiment at the LHC. It allows separation among pions, kaons and protons up\nto a few GeV/c, covering the full azimuthal angle and -0.9 < eta < 0.9. The TOF\nexploits the innovative MRPC technology capable of an intrinsic time resolution\nbetter than 50 ps with an efficiency close to 100% and a large operational\nplateau; the full array consists of 1593 MRPCs covering a cylindrical surface\nof 141 m2. The TOF detector has been efficiently taking data since the first pp\ncollisions recorded in ALICE in December 2009. In this report, the status of\nthe TOF detector and the performance achieved for both pp and Pb--Pb collisions\nare described. \n\n"}
{"id": "1203.6030", "contents": "Title: Revisiting the D-iteration method: from theoretical to practical\n  computation cost Abstract: In this paper, we revisit the D-iteration algorithm in order to better\nexplain its connection to the Gauss-Seidel method and different performance\nresults that were observed. In particular, we study here the practical\ncomputation cost based on the execution runtime compared to the theoretical\nnumber of iterations. We also propose an exact formula of the error for\nPageRank class of equations. \n\n"}
{"id": "1204.2317", "contents": "Title: Search for the Top Partner at the LHC using Multi-b-Jet Channels Abstract: Vector-like quarks are introduced in various new physics models beyond the\nstandard model (SM) at the TeV scale. We especially consider the case that the\nquark is singlet (triplet) under the SU(2)$_L$ (SU(3)$_c$) gauge group and\ncouples only to the third generation quarks of the SM. The vector-like quark of\nthis kind is often called a top partner. The top partoner $t_p$ decays into\n$bW, tZ$ and $th$. In the ATLAS and CMS collaborations, the top partner has\nbeen searched in the final states of $bW$ and $tZ$, while the search based on\nthe decay mode $t_p\\to th$ has not been started yet. However, the decay into\n$th$ is important since it is significantly enhanced if some strong dynamics\nexists in the TeV scale. In the presence of a light higgs boson, the decay mode\n$t_p\\to th$ followed by $h\\to b\\bar{b}$ produces three bottom quarks. We study\nthe sensitivity for the top partner using multi-b-jet events at the 8 TeV run\nof the LHC experiment. The multi-b-jet eventss turn out to play a complementary\nrole to the existing $t_p\\rightarrow bW$ and $tZ$ searches by the ATLAS and CMS\ncollaborations. \n\n"}
{"id": "1204.3500", "contents": "Title: Low-Background Monitoring Cameras for the Daya Bay Antineutrino\n  Detectors Abstract: The Daya Bay Reactor Neutrino Experiment is designed to measure the neutrino\nmixing angle theta13 to world-leading precision. The experiment deploys\nidentical antineutrino detectors at distances of 400-1900m from six reactors in\nDaya Bay, China. Each detector incorporates two general-purpose monitoring\ncameras to ensure their safe construction, transportation and operation. The\ncameras must meet usage goals while satisfying stringent constraints on\nradioactivity, materials compatibility, interference and reliability. This\narticle describes the system design, integration, operation and performance. \n\n"}
{"id": "1205.4133", "contents": "Title: Constrained Overcomplete Analysis Operator Learning for Cosparse Signal\n  Modelling Abstract: We consider the problem of learning a low-dimensional signal model from a\ncollection of training samples. The mainstream approach would be to learn an\novercomplete dictionary to provide good approximations of the training samples\nusing sparse synthesis coefficients. This famous sparse model has a less well\nknown counterpart, in analysis form, called the cosparse analysis model. In\nthis new model, signals are characterised by their parsimony in a transformed\ndomain using an overcomplete (linear) analysis operator. We propose to learn an\nanalysis operator from a training corpus using a constrained optimisation\nframework based on L1 optimisation. The reason for introducing a constraint in\nthe optimisation framework is to exclude trivial solutions. Although there is\nno final answer here for which constraint is the most relevant constraint, we\ninvestigate some conventional constraints in the model adaptation field and use\nthe uniformly normalised tight frame (UNTF) for this purpose. We then derive a\npractical learning algorithm, based on projected subgradients and\nDouglas-Rachford splitting technique, and demonstrate its ability to robustly\nrecover a ground truth analysis operator, when provided with a clean training\nset, of sufficient size. We also find an analysis operator for images, using\nsome noisy cosparse signals, which is indeed a more realistic experiment. As\nthe derived optimisation problem is not a convex program, we often find a local\nminimum using such variational methods. Some local optimality conditions are\nderived for two different settings, providing preliminary theoretical support\nfor the well-posedness of the learning problem under appropriate conditions. \n\n"}
{"id": "1206.1479", "contents": "Title: Multilevel Monte Carlo methods for highly heterogeneous media Abstract: We discuss the application of multilevel Monte Carlo methods to elliptic\npartial differential equations with random coefficients. Such problems arise,\nfor example, in uncertainty quantification in subsurface flow modeling. We give\na brief review of recent advances in the numerical analysis of the multilevel\nalgorithm under minimal assumptions on the random coefficient, and extend the\nanalysis to cover also tensor--valued coefficients, as well as point\nevaluations. Our analysis includes as an example log--normal random\ncoefficients, which are frequently used in applications. \n\n"}
{"id": "1206.3442", "contents": "Title: Planar Pixel Sensors for the ATLAS tracker upgrade at HL-LHC Abstract: The ATLAS Planar Pixel Sensor R&D Project is a collaboration of 17 institutes\nand more than 80 scientists. Their goal is to explore the operation of planar\npixel sensors for the tracker upgrade at the High Luminosity-Large Hadron\nCollider (HL-LHC). This work will give a summary of the achievements on\nradiation studies with n-in-n and n-in-p pixel sensors, bump-bonded to ATLAS\nFE-I3 and FE-I4 readout chips. The summary includes results from tests with\nradioactive sources and tracking efficiencies extracted from test beam\nmeasurements. Analysis results of ${2\\cdot10^{16}}\n\\text{n}_{\\text{eq}}\\text{cm}^{-2}$ and ${1\\cdot10^{16}}\n\\text{n}_{\\text{eq}}\\text{cm}^{-2}$ ($1 \\text{MeV}$ neutron equivalent)\nirradiated n-in-n and n-in-p modules confirm the operation of planar pixel\nsensors for future applications. \n\n"}
{"id": "1206.4068", "contents": "Title: The H1 Forward Track Detector at HERA II Abstract: In order to maintain efficient tracking in the forward region of H1 after the\nluminosity upgrade of the HERA machine, the H1 Forward Track Detector was also\nupgraded. While much of the original software and techniques used for the HERA\nI phase could be reused, the software for pattern recognition was completely\nrewritten. This, along with several other improvements in hit finding and\nhigh-level track reconstruction, are described in detail together with a\nsummary of the performance of the detector. \n\n"}
{"id": "1206.4541", "contents": "Title: Certain upper bounds on the eigenvalues associated with prolate\n  spheroidal wave functions Abstract: Prolate spheroidal wave functions (PSWFs) play an important role in various\nareas, from physics (e.g. wave phenomena, fluid dynamics) to engineering (e.g.\nsignal processing, filter design). One of the principal reasons for the\nimportance of PSWFs is that they are a natural and efficient tool for computing\nwith bandlimited functions, that frequently occur in the abovementioned areas.\nThis is due to the fact that PSWFs are the eigenfunctions of the integral\noperator, that represents timelimiting followed by lowpassing.\n  Needless to say, the behavior of this operator is governed by the decay rate\nof its eigenvalues. Therefore, investigation of this decay rate plays a crucial\nrole in the related theory and applications - for example, in construction of\nquadratures, interpolation, filter design, etc.\n  The significance of PSWFs and, in particular, of the decay rate of the\neigenvalues of the associated integral operator, was realized at least half a\ncentury ago. Nevertheless, perhaps surprisingly, despite vast numerical\nexperience and existence of several asymptotic expansions, a non-trivial\nexplicit upper bound on the magnitude of the eigenvalues has been missing for\ndecades.\n  The principal goal of this paper is to close this gap in the theory of PSWFs.\nWe analyze the integral operator associated with PSWFs, to derive fairly tight\nnon-asymptotic upper bounds on the magnitude of its eigenvalues. Our results\nare illustrated via several numerical experiments. \n\n"}
{"id": "1206.4908", "contents": "Title: SecDec: A tool for numerical multi-loop calculations Abstract: The version 2.0 of the program SecDec is described, which can be used for the\nextraction of poles within dimensional regularisation from multi-loop integrals\nas well as phase space integrals. The numerical evaluation of the resulting\nfinite functions is also done by the program in an automated way, with no\nrestriction on the kinematics in the case of loop integrals. \n\n"}
{"id": "1206.5860", "contents": "Title: Multiscale reaction-diffusion algorithms: PDE-assisted Brownian dynamics Abstract: Two algorithms that combine Brownian dynamics (BD) simulations with\nmean-field partial differential equations (PDEs) are presented. This\nPDE-assisted Brownian dynamics (PBD) methodology provides exact particle\ntracking data in parts of the domain, whilst making use of a mean-field\nreaction-diffusion PDE description elsewhere. The first PBD algorithm couples\nBD simulations with PDEs by randomly creating new particles close to the\ninterface which partitions the domain and by reincorporating particles into the\ncontinuum PDE-description when they cross the interface. The second PBD\nalgorithm introduces an overlap region, where both descriptions exist in\nparallel. It is shown that to accurately compute variances using the PBD\nsimulation requires the overlap region. Advantages of both PBD approaches are\ndiscussed and illustrative numerical examples are presented. \n\n"}
{"id": "1206.6537", "contents": "Title: A T-Matrix Calculation for in-Medium Heavy-Quark Gluon Scattering Abstract: The interactions of charm and bottom quarks in a Quark-Gluon Plasma (QGP) are\nevaluated using a thermodynamic 2-body T-matrix. We specifically focus on\nheavy-quark (HQ) interactions with thermal gluons with an input potential\nmotivated by lattice-QCD computations of the HQ free energy. The latter is\nimplemented into a field-theoretic ansatz for color-Coulomb and (remnants of)\nconfining interactions. This, in particular, enables to discuss corrections to\nthe potential approach, specifically hard-thermal-loop corrections to the\nvertices, relativistic corrections deduced from pertinent Feynman diagrams, and\na suitable projection on transverse thermal gluons. The resulting potentials\nare applied to compute scattering amplitudes in different color channels and\nutilized for a calculation of the corresponding HQ drag coefficient in the QGP.\nA factor of ~2-3 enhancement over perturbative results is obtained, mainly\ndriven by the resummation in the attractive color-channels. \n\n"}
{"id": "1206.7082", "contents": "Title: Target Mass Monitoring and Instrumentation in the Daya Bay Antineutrino\n  Detectors Abstract: The Daya Bay experiment measures sin^2 2{\\theta}_13 using functionally\nidentical antineutrino detectors located at distances of 300 to 2000 meters\nfrom the Daya Bay nuclear power complex. Each detector consists of three nested\nfluid volumes surrounded by photomultiplier tubes. These volumes are coupled to\noverflow tanks on top of the detector to allow for thermal expansion of the\nliquid. Antineutrinos are detected through the inverse beta decay reaction on\nthe proton-rich scintillator target. A precise and continuous measurement of\nthe detector's central target mass is achieved by monitoring the the fluid\nlevel in the overflow tanks with cameras and ultrasonic and capacitive sensors.\nIn addition, the monitoring system records detector temperature and levelness\nat multiple positions. This monitoring information allows the precise\ndetermination of the detectors' effective number of target protons during data\ntaking. We present the design, calibration, installation and in-situ tests of\nthe Daya Bay real-time antineutrino detector monitoring sensors and readout\nelectronics. \n\n"}
{"id": "1207.1708", "contents": "Title: Estimators for Archimedean copulas in high dimensions Abstract: The performance of known and new parametric estimators for Archimedean\ncopulas is investigated, with special focus on large dimensions and numerical\ndifficulties. In particular, method-of-moments-like estimators based on\npairwise Kendall's tau, a multivariate extension of Blomqvist's beta, minimum\ndistance estimators, the maximum-likelihood estimator, a simulated\nmaximum-likelihood estimator, and a maximum-likelihood estimator based on the\ncopula diagonal are studied. Their performance is compared in a large-scale\nsimulation study both under known and unknown margins (pseudo-observations), in\nsmall and high dimensions, under small and large dependencies, various\ndifferent Archimedean families and sample sizes. High dimensions up to one\nhundred are considered for the first time and computational problems arising\nfrom such large dimensions are addressed in detail. All methods are implemented\nin the open source \\R{} package \\pkg{copula} and can thus be easily accessed\nand studied. \n\n"}
{"id": "1207.2012", "contents": "Title: Second order finite difference approximations for the two-dimensional\n  time-space Caputo-Riesz fractional diffusion equation Abstract: In this paper, we discuss the time-space Caputo-Riesz fractional diffusion\nequation with variable coefficients on a finite domain. The finite difference\nschemes for this equation are provided. We theoretically prove and numerically\nverify that the implicit finite difference scheme is unconditionally stable\n(the explicit scheme is conditionally stable with the stability condition\n$\\frac{\\tau^{\\gamma}}{(\\Delta x)^{\\alpha}}+\\frac{\\tau^{\\gamma}}{(\\Delta\ny)^{\\beta}} <C$) and 2nd order convergent in space direction, and\n$(2-\\gamma)$-th order convergent in time direction, where $\\gamma \\in(0,1]$. \n\n"}
{"id": "1207.2292", "contents": "Title: Liquid noble gas detectors for low energy particle physics Abstract: We review the current status of liquid noble gas radiation detectors with\nenergy threshold in the keV range, wich are of interest for direct dark matter\nsearches, measurement of coherent neutrino scattering and other low energy\nparticle physics experiments. Emphasis is given to the operation principles and\nthe most important instrumentation aspects of these detectors, principally of\nthose operated in the double-phase mode. Recent technological advances and\nrelevant developments in photon detection and charge readout are discussed in\nthe context of their applicability to those experiments. \n\n"}
{"id": "1207.3221", "contents": "Title: Generalized universality of higher transverse moments of quark\n  transverse momentum dependent correlators Abstract: The color gauge-invariant transverse momentum dependent (TMD) quark\ncorrelators contain process dependent gauge links in the bilocal matrix\nelements. In this paper, we split these process dependent correlators into\nuniversal TMD correlators, which in turn can be parametrized in universal TMD\ndistribution functions. The process dependence is contained in gluonic pole\nfactors, of which the value is determined by the gauge link. The operator\nstructures of the universal TMD correlators are identified using transverse\nmoments. In this paper, specific results for double transverse weighting of\nquark TMDs are given. In particular, we show that for a spin 1/2 target one has\nthree universal time-reversal even leading `pretzelocity distributions', two of\nwhich involve double gluonic pole matrix elements and come with process\ndependent gluonic pole factors. We generalize the results for single and double\nweighting to TMD correlators of any specific rank, illustrating it for\nunpolarized, spin 1/2 and spin 1 targets. \n\n"}
{"id": "1207.6737", "contents": "Title: Solving integral equations on piecewise smooth boundaries using the RCIP\n  method: a tutorial Abstract: Recursively compressed inverse preconditioning (RCIP) is a kernel-independent\nand purely numerical method for solving Fredholm second kind boundary integral\nequations in situations where the boundary shape induces a non-smooth behavior\nin the solution. The method originated in 2008 within a scheme for Laplace's\nequation in two-dimensional domains with corners. In a series of subsequent\npapers the method was then refined and extended as to apply to integral\nequation formulations of a broad range of boundary value problems in physics\nand engineering. The purpose of the present tutorial is threefold: First, to\nreview the RCIP method in a simple setting. Second, to show how easily the\nmethod can be implemented in Matlab. Third, to present new applications. \n\n"}
{"id": "1208.3267", "contents": "Title: QMC designs: optimal order Quasi Monte Carlo Integration schemes on the\n  sphere Abstract: We study equal weight numerical integration, or Quasi Monte Carlo (QMC)\nrules, for functions in a Sobolev space $H^s(S^d)$ with smoothness parameter\n$s>d/2$ defined over the unit sphere $S^d$ in $R^{d+1}$. Focusing on $N$-point\nsets that achieve optimal order QMC error bounds (as is the case for efficient\nspherical designs), we are led to introduce the concept of QMC designs: these\nare sequences of $N$-point node sets $X_N$ on $S^d$ such that the worst-case\nerror of the corresponding QMC rules satisfy a bound of order $O(N^{-s/d})$ as\n$N\\to\\infty$ with an implied constant that depends on the $H^s(S^d)$-norm.\n  We provide methods for generation and numerical testing of QMC designs. As a\nconsequence of a recent result of Bondarenko et al. on the existence of\nspherical designs with appropriate number of points, we show that minimizers of\nthe $N$-point energy for the reproducing kernel for $H^s(S^d)$, $s>d/2$, form a\nsequence of QMC designs for $H^s(S^d)$. Furthermore, without appealing to the\nBondarenko et al. result, we prove that point sets that maximize the sum of\nsuitable powers of the Euclidean distance between pairs of points form a\nsequence of QMC designs for $H^s(S^d)$ with $s\\in(d/2,d/2+1)$.\n  Numerical experiments suggest that many familiar sequences of point sets on\nthe sphere (equal area, spiral, minimal [Coulomb or log.] energy, and Fekete\npoints) are QMC designs for appropriate values of $s$. For comparison purposes\nwe show that sets of random points that are independently and uniformly\ndistributed on the sphere do not constitute QMC designs for any $s>d/2$.\n  If $(X_N)$ is a sequence of QMC designs for $H^s(S^d)$, we prove that it is\nalso a sequence of QMC designs for $\\mathbb{H}^{s'}(S^d)$ for all\n$s'\\in(d/2,s)$. This leads to the question of determining the supremum of such\n$s$, for which we provide estimates based on computations for the\naforementioned sequences. \n\n"}
{"id": "1208.3805", "contents": "Title: Paved with Good Intentions: Analysis of a Randomized Block Kaczmarz\n  Method Abstract: The block Kaczmarz method is an iterative scheme for solving overdetermined\nleast-squares problems. At each step, the algorithm projects the current\niterate onto the solution space of a subset of the constraints. This paper\ndescribes a block Kaczmarz algorithm that uses a randomized control scheme to\nchoose the subset at each step. This algorithm is the first block Kaczmarz\nmethod with an (expected) linear rate of convergence that can be expressed in\nterms of the geometric properties of the matrix and its submatrices. The\nanalysis reveals that the algorithm is most effective when it is given a good\nrow paving of the matrix, a partition of the rows into well-conditioned blocks.\nThe operator theory literature provides detailed information about the\nexistence and construction of good row pavings. Together, these results yield\nan efficient block Kaczmarz scheme that applies to many overdetermined\nleast-squares problem. \n\n"}
{"id": "1208.6062", "contents": "Title: Natural gauge mediation with a bino NLSP at the LHC Abstract: Natural models of supersymmetry with a gravitino LSP provide distinctive\nsignatures at the LHC. For a neutralino NLSP, sparticles can decay to two high\nenergy photons plus missing energy. We use the ATLAS diphoton search with 4.8\nfb^{-1} of data to place limits in both the stop-gluino and neutralino-chargino\nmass planes for this scenario. If the neutralino is heavier than 50 GeV, the\nlightest stop must be heavier than 580 GeV, the gluino heavier than 1100 GeV\nand charginos must be heavier than approximately 300-470 GeV. This provides the\nfirst nontrivial constraints in natural gauge mediation models with a\nneutralino NLSP decaying to photons, and implies a fine tuning of at least a\nfew percent in such models. \n\n"}
{"id": "1209.1979", "contents": "Title: The Upgrade of the CMS RPC System during the First LHC Long Shutdown Abstract: The CMS muon system includes in both the barrel and endcap region Resistive\nPlate Chambers (RPC). They mainly serve as trigger detectors and also improve\nthe reconstruction of muon parameters. Over the years, the instantaneous\nluminosity of the Large Hadron Collider gradually increases. During the LHC\nPhase 1 (~first 10 years of operation) an ultimate luminosity is expected above\nits design value of 10^34/cm^2/s at 14 TeV. To prepare the machine and also the\nexperiments for this, two long shutdown periods are scheduled for 2013-2014 and\n2018-2019. The CMS Collaboration is planning several detector upgrades during\nthese long shutdowns. In particular, the muon detection system should be able\nto maintain a low-pT threshold for an efficient Level-1 Muon Trigger at high\nparticle rates. One of the measures to ensure this, is to extend the present\nRPC system with the addition of a 4th layer in both endcap regions. During the\nfirst long shutdown, these two new stations will be equipped in the region\n|eta|<1.6 with 144 High Pressure Laminate (HPL) double-gap RPCs operating in\navalanche mode, with a similar design as the existing CMS endcap chambers.\nHere, we present the upgrade plans for the CMS RPC system for the fist long\nshutdown, including trigger simulation studies for the extended system, and\ndetails on the new HPL production, the chamber assembly and the quality control\nprocedures. \n\n"}
{"id": "1209.4219", "contents": "Title: Pion production by neutrinos in the delta resonance region and possible\n  application to CP searches Abstract: We present the results of extensive calculations for charged and neutral\ncurrent reactions of neutrinos and antineutrinos in the small\n$Q^2\\lsim\\unit[0.20]{GeV^2}$ region. The results include single $\\frac{\\d\n\\sigma}{\\d Q^2}$ and double $\\frac{\\d \\sigma^{(A)}}{\\d Q^2 \\d E_\\pi}$\ndifferential cross sections at energies relevant for oscillation experiments.\nWe include nuclear corrections in the Adler-Nussinov-Paschos model and point\nout that on isoscalar nuclear targets there are charge symmetry relations that\nhold in extended kinematic regions. We discuss how the results can be used in\nlong baseline experiments in order to study oscillation parameters and search\nfor CP asymmetries. \n\n"}
{"id": "1210.0341", "contents": "Title: NEXT, high-pressure xenon gas experiments for ultimate sensitivity to\n  Majorana neutrinos Abstract: In this paper we describe an innovative type of Time Projection Chamber\n(TPC), which uses high-pressure xenon gas (HPXe) and electroluminescence\namplification of the ionization charge as the basis of an apparatus capable of\nfully reconstructing the energy and topological signature of rare events. We\nwill discuss a specific design of such HPXe TPC, the NEXT-100 detector, that\nwill search for neutrinoless double beta decay events using 100-150 kg of xenon\nenriched in the isotope Xe-136. NEXT-100 is currently under construction, after\ncompletion of an accelerated and very successful R&D period. It will be\ninstalled at the Laboratorio Subterr\\'aneo de Canfranc (LSC), in Spain. The\ncommissioning run is expected for late 2013 or early 2014. We will also present\nphysics arguments that suggest that the HPXe technology can be extrapolated to\nthe next-to-next generation (e.g, a fiducial mass of 1 ton of target), which\nwill fully explore the Majorana nature of the neutrino if the mass hierarchy is\ninverse. \n\n"}
{"id": "1210.4223", "contents": "Title: Infinite-Dimensional Integration in Weighted Hilbert Spaces: Anchored\n  Decompositions, Optimal Deterministic Algorithms, and Higher Order\n  Convergence Abstract: We study numerical integration of functions depending on an infinite number\nof variables. We provide lower error bounds for general deterministic linear\nalgorithms and provide matching upper error bounds with the help of suitable\nmultilevel algorithms and changing dimension algorithms.\n  More precisely, the spaces of integrands we consider are weighted reproducing\nkernel Hilbert spaces with norms induced by an underlying anchored function\nspace decomposition. Here the weights model the relative importance of\ndifferent groups of variables. The error criterion used is the deterministic\nworst case error. We study two cost models for function evaluation which depend\non the number of active variables of the chosen sample points, and two classes\nof weights, namely product and order-dependent (POD) weights and the newly\nintroduced weights with finite active dimension. We show for these classes of\nweights that multilevel algorithms achieve the optimal rate of convergence in\nthe first cost model while changing dimension algorithms achieve the optimal\nconvergence rate in the second model.\n  As an illustrative example, we discuss the anchored Sobolev space with\nsmoothness parameter $\\alpha$ and provide new optimal quasi-Monte Carlo\nmultilevel algorithms and quasi-Monte Carlo changing dimension algorithms based\non higher-order polynomial lattice rules. \n\n"}
{"id": "1210.7445", "contents": "Title: Recursive equations based models of queueing systems Abstract: An overview of the recursive equations based models and their applications in\nsimulation based analysis and optimization of queueing systems is given. These\nmodels provide a variety of systems with a convenient and unified\nrepresentation in terms of recursions for arrival and departure times of\ncustomers, which involves only the operations of maximum, minimum, and\naddition. \n\n"}
{"id": "1211.3444", "contents": "Title: Spectral Clustering: An empirical study of Approximation Algorithms and\n  its Application to the Attrition Problem Abstract: Clustering is the problem of separating a set of objects into groups (called\nclusters) so that objects within the same cluster are more similar to each\nother than to those in different clusters. Spectral clustering is a now\nwell-known method for clustering which utilizes the spectrum of the data\nsimilarity matrix to perform this separation. Since the method relies on\nsolving an eigenvector problem, it is computationally expensive for large\ndatasets. To overcome this constraint, approximation methods have been\ndeveloped which aim to reduce running time while maintaining accurate\nclassification. In this article, we summarize and experimentally evaluate\nseveral approximation methods for spectral clustering. From an applications\nstandpoint, we employ spectral clustering to solve the so-called attrition\nproblem, where one aims to identify from a set of employees those who are\nlikely to voluntarily leave the company from those who are not. Our study sheds\nlight on the empirical performance of existing approximate spectral clustering\nmethods and shows the applicability of these methods in an important business\noptimization related problem. \n\n"}
{"id": "1211.3796", "contents": "Title: CANDECOMP/PARAFAC Decomposition of High-order Tensors Through Tensor\n  Reshaping Abstract: In general, algorithms for order-3 CANDECOMP/-PARAFAC (CP), also coined\ncanonical polyadic decomposition (CPD), are easily to implement and can be\nextended to higher order CPD. Unfortunately, the algorithms become\ncomputationally demanding, and they are often not applicable to higher order\nand relatively large scale tensors. In this paper, by exploiting the uniqueness\nof CPD and the relation of a tensor in Kruskal form and its unfolded tensor, we\npropose a fast approach to deal with this problem. Instead of directly\nfactorizing the high order data tensor, the method decomposes an unfolded\ntensor with lower order, e.g., order-3 tensor. On basis of the order-3\nestimated tensor, a structured Kruskal tensor of the same dimension as the data\ntensor is then generated, and decomposed to find the final solution using fast\nalgorithms for the structured CPD. In addition, strategies to unfold tensors\nare suggested and practically verified in the paper. \n\n"}
{"id": "1211.7150", "contents": "Title: Photodegradation Mechanisms of Tetraphenyl Butadiene Coatings for Liquid\n  Argon Detectors Abstract: We report on studies of degradation mechanisms of tetraphenyl butadiene (TPB)\ncoatings of the type used in neutrino and dark matter liquid argon experiments.\nUsing gas chromatography coupled to mass spectrometry we have detected the\nultraviolet-blocking impurity benzophenone (BP). We monitored the drop in\nperformance and increase of benzophenone concentration in TPB plates with\nexposure to ultraviolet (UV) light, and demonstrate the correlation between\nthese two variables. Based on the presence and initially exponential increase\nin the concentration of benzophenone observed, we propose that TPB degradation\nis a free radical-mediated photooxidation reaction, which is subsequently\nconfirmed by displaying delayed degradation using a free radical inhibitor.\nFinally we show that the performance of wavelength-shifting coatings of the\ntype envisioned for the LBNE experiment can be improved by 10-20%, with\nsignificantly delayed UV degradation, by using a 20% admixture of\n4-tert-Butylcatechol. \n\n"}
{"id": "1212.3519", "contents": "Title: Invariance Properties of Generalized Polarization Tensors and Design of\n  Shape Descriptors in Three Dimensions Abstract: We derive transformation formulas for the generalized polarization tensors\nunder rigid motions and scaling in three dimensions, and use them to construct\nan infinite number of invariants under those transformations. These invariants\ncan be used as shape descriptors for dictionary matching. \n\n"}
{"id": "1212.3544", "contents": "Title: Tracking of a Mobile Target Using Generalized Polarization Tensors Abstract: In this paper we apply an extended Kalman filter to track both the location\nand the orientation of a mobile target from multistatic response measurements.\nWe also analyze the effect of the limited-view aspect on the stability and the\nefficiency of our tracking approach. Our algorithm is based on the use of the\ngeneralized polarization tensors, which can be reconstructed from the\nmultistatic response measurements by solving a linear system. The system has\nthe remarkable property that low order generalized polarization tensors are not\naffected by the error caused by the instability of higher orders in the\npresence of measurement noise. \n\n"}
{"id": "1212.4891", "contents": "Title: Studies of Nucleon Resonance Structure in Exclusive Meson\n  Electroproduction Abstract: Studies of the structure of excited baryons are key to the N* program at\nJefferson Lab. Within the first year of data taking with the Hall B CLAS12\ndetector following the 12 GeV upgrade, a dedicated experiment will aim to\nextract the N* electrocouplings at high photon virtualities Q2. This experiment\nwill allow exploration of the structure of N* resonances at the highest photon\nvirtualities ever yet achieved, with a kinematic reach up to Q2 = 12 GeV2. This\nhigh-Q2 reach will make it possible to probe the excited nucleon structures at\ndistance scales ranging from where effective degrees of freedom, such as\nconstituent quarks, are dominant through the transition to where nearly\nmassless bare-quark degrees of freedom are relevant. In this document, we\npresent a detailed description of the physics that can be addressed through N*\nstructure studies in exclusive meson electroproduction. The discussion includes\nrecent advances in reaction theory for extracting N* electrocouplings from\nmeson electroproduction off protons, along with QCD-based approaches to the\ntheoretical interpretation of these fundamental quantities. This program will\nafford access to the dynamics of the non-perturbative strong interaction\nresponsible for resonance formation, and will be crucial in understanding the\nnature of confinement and dynamical chiral symmetry breaking in baryons, and\nhow excited nucleons emerge from QCD. \n\n"}
{"id": "1212.5127", "contents": "Title: Calorimetry for Lepton Collider Experiments - CALICE results and\n  activities Abstract: The CALICE collaboration conducts calorimeter R&D for highly granular\ncalorimeters, mainly for their application in detectors for a future lepton\ncollider at the TeV scale. The activities ranges from generic R&D with small\ndevices up to extensive beam tests with prototypes comprising up to several\n100000 calorimeter cells. CALICE has validated the performance of particle flow\nalgorithms with test beam data and delivers the proof of principle that highly\ngranular calorimeters can be built, operated and understood. The successes\nachieved in the past years allows the step from prototypes to calorimeter\nsystems for particle physics detectors to be addressed. \n\n"}
{"id": "1212.5564", "contents": "Title: Weak convergence for a spatial approximation of the nonlinear stochastic\n  heat equation Abstract: We find the weak rate of convergence of the spatially semidiscrete finite\nelement approximation of the nonlinear stochastic heat equation. Both\nmultiplicative and additive noise is considered under different assumptions.\nThis extends an earlier result of Debussche in which time discretization is\nconsidered for the stochastic heat equation perturbed by white noise. It is\nknown that this equation has a solution only in one space dimension. In order\nto obtain results for higher dimensions, colored noise is considered here,\nbesides white noise in one dimension. Integration by parts in the Malliavin\nsense is used in the proof. The rate of weak convergence is, as expected,\nessentially twice the rate of strong convergence. \n\n"}
{"id": "1212.5723", "contents": "Title: Passing the boundary between the parity breaking medium and vacuum by\n  vector particles Abstract: The electrodynamics supplemented with a Chern-Simons (CS) action\n(Carrol-Field-Jackiw electrodynamics) in a half space is studied. The passage\nof photons and/or massive vector mesons through a boundary between the CS\nmedium and the vacuum of conventional Maxwell electrodynamics is investigated.\nEffects of reflection from a boundary (up to the total one) are revealed when\nvector particles escape to vacuum and income from vacuum passing the boundary.\nBoth the space-like and time-like CS vectors are considered. \n\n"}
{"id": "1212.5898", "contents": "Title: A puzzle of the pion-photon transition form factor - resolved? Abstract: By means of QCD sum rules in local-duality limit, we analyze the behaviour of\nthe form factors for the transitions of a real and a virtual photon to some\npseudoscalar meson as functions of the involved momentum transfer. Except for\nthe findings of BaBar for the neutral-pion form factor, the experimental data\nfor all these transition form factors are compatible with saturation for large\nmomentum transfer predicted by pQCD factorization. For light pseudoscalar\nmesons, saturation is observed already at relatively small momentum transfer,\nwhereas for the eta-c meson it sets in only at larger momentum transfer. A\nrecent measurement of the neutral-pion transition form factor by Belle seems to\nresolve this disturbing puzzle as its outcome is compatible with both\nsaturation for relatively small momentum transfer and the behaviour of the eta\nand eta' transition form factors at large momentum transfer. \n\n"}
{"id": "1212.6007", "contents": "Title: Dark Radiation and interacting scenarios Abstract: An extra dark radiation component can be present in the universe in the form\nof sterile neutrinos, axions or other very light degrees of freedom which may\ninteract with the dark matter sector. We derive here the cosmological\nconstraints on the dark radiation abundance, on its effective velocity and on\nits viscosity parameter from current data in dark radiation-dark matter coupled\nmodels. The cosmological bounds on the number of extra dark radiation species\ndo not change significantly when considering interacting schemes. We also find\nthat the constraints on the dark radiation effective velocity are degraded by\nan order of magnitude while the errors on the viscosity parameter are a factor\nof two larger when considering interacting scenarios. If future Cosmic\nMicrowave Background data are analysed assuming a non interacting model but the\ndark radiation and the dark matter sectors interact in nature, the\nreconstructed values for the effective velocity and for the viscosity parameter\nwill be shifted from their standard 1/3 expectation, namely ceff=0.34 (+0.006\n-0.003) and cvis=0.29 (+0.002 -0.001) at 95% CL for the future COrE mission\ndata. \n\n"}
{"id": "1301.0908", "contents": "Title: Low-complexity computation of plate eigenmodes with Vekua approximations\n  and the Method of Particular Solutions Abstract: This paper extends the Method of Particular Solutions (MPS) to the\ncomputation of eigenfrequencies and eigenmodes of plates. Specific\napproximation schemes are developed, with plane waves (MPS-PW) or\nFourier-Bessel functions (MPS-FB). This framework also requires a suitable\nformulation of the boundary conditions. Numerical tests, on two plates with\nvarious boundary conditions, demonstrate that the proposed approach provides\ncompetitive results with standard numerical schemes such as the Finite Element\nMethod, at reduced complexity, and with large flexibility in the implementation\nchoices. \n\n"}
{"id": "1301.2367", "contents": "Title: LINE INTEGRAL METHODS and their application to the numerical solution of\n  conservative problems Abstract: These are the lecture notes of a course given by the first author on December\n27, 2012 - January 4, 2013, held at the Academy of Mathematics and Systems\nScience Chinese Academy of Sciences in Beijing. \n\n"}
{"id": "1301.3067", "contents": "Title: Low energy analysis of $\\pi N$ scattering and the pion-nucleon sigma\n  term with covariant baryon chiral perturbation theory Abstract: The pion-nucleon sigma term ($\\sigma_{\\pi N}$) is an observable of\nfundamental importance because embodies information about the internal scalar\nstructure of the nucleon. Nowadays this quantity has triggered renewed interest\nbecause it is a key input for a reliable estimation of the dark matter-nucleon\nspin independent elastic scattering cross section. In this proceeding we\npresent how this quantity can be reliably extracted by employing only\nexperimental information with the use covariant baryon chiral perturbation\ntheory. We also contrast our extraction with updated phenomenology related to\n$\\sigma_{\\pi N}$ and show how this phenomenology favours a relatively large\nvalue of $\\sigma_{\\pi N}$. Finally, we extract a value of $\\sigma_{\\pi\nN}=59(7)$ MeV from modern partial wave analyses data. \n\n"}
{"id": "1301.3750", "contents": "Title: Neutron and proton tests of different technologies for the upgrade of\n  the cold readout electronics of the ATLAS Hadronic End-cap Calorimeter Abstract: The expected increase of total integrated luminosity by a factor ten at the\nHL-LHC compared to the design goals for LHC essentially eliminates the safety\nfactor for radiation hardness realized at the current cold amplifiers of the\nATLAS Hadronic End-cap Calorimeter (HEC). New more radiation hard technologies\nhave been studied: SiGe bipolar, Si CMOS FET and GaAs FET transistors have been\nirradiated with neutrons up to an integrated fluence of 2.2 x 10^{16} n/cm^2\nand with 200 MeV protons up to an integrated fluence of 2.6 x 10^{14} p/cm^2.\nComparisons of transistor parameters such as the gain for both types of\nirradiations are presented. \n\n"}
{"id": "1302.3210", "contents": "Title: Characterization of protonated and deuterated Tetra-Phenyl Butadiene\n  Film in a Polystyrene Matrix Abstract: We study the effect of deuteration and annealing on the fluorescence spectrum\nshape and VUV to visible conversion efficiency of TPB films in a polystyrene\nmatrix with input light from 120 to 220 nm. We observed no discernible\ndifference in the fluorescence spectrum shape between any of the films. The\ndeuterated film performed equally well compared to the standard one in terms of\nconversion efficiency, but annealing seems to degrade this efficiency to\nroughly 75% of its non annealed value at all wavelengths studied. \n\n"}
{"id": "1302.4317", "contents": "Title: Introducing One Step Back Iterative Approach to Solve Linear and Non\n  Linear Fixed Point Problem Abstract: In this paper, we introduce a new iterative method which we call one step\nback approach: the main idea is to anticipate the consequence of the iterative\ncomputation per coordinate and to optimize on the choice of the sequence of the\ncoordinates on which the iterative update computations are done. The method\nrequires the increase of the size of the state vectors and one iteration step\nloss from the initial vector. We illustrate the approach in linear and non\nlinear iterative equations. \n\n"}
{"id": "1302.7240", "contents": "Title: Bounds on the compactification scale of two universal extra dimensions\n  from exclusive $b \\to s \\gamma$ decays Abstract: The exclusive radiative $B \\to K^* \\gamma$, $B \\to K^*_2 \\gamma$, $B_s \\to\n\\phi \\gamma$ and $\\Lambda_b \\to \\Lambda \\gamma$ decays are studied in a new\nphysics scenario with two universal extra dimensions compactified on a chiral\nsquare. The computed branching fractions depend on the size $R$ of the extra\ndimensions, and a comparison with the available measurements allows us to put\nbounds on such a fundamental parameter. From the mode $B^0 \\to K^{*0} \\gamma$\nwe obtain the most stringent bound: $1 \\over R>710$ GeV. \n\n"}
{"id": "1303.0607", "contents": "Title: Sterile Neutrino Search Using China Advanced Research Reactor Abstract: We study the feasibility of a sterile neutrino search at the China Advanced\nResearch Reactor by measuring $\\bar {\\nu}_e$ survival probability with a\nbaseline of less than 15 m. Both hydrogen and deuteron have been considered as\npotential targets. The sensitivity to sterile-to-regular neutrino mixing is\ninvestigated under the \"3(active)+1(sterile)\" framework. We find that the\nmixing parameter $\\sin^2(2\\theta_{14})$ can be severely constrained by such\nmeasurement if the mass square difference $\\Delta m_{14}^2$ is of the order of\n$\\sim$1 eV$^2$. \n\n"}
{"id": "1303.1211", "contents": "Title: Three Family SU(5) GUT and Inverted Neutrino Mass Hierarchy Abstract: Supersymmetric SU(5) GUT augmented with anomaly free U(1)_F flavor symmetry\nis presented. Very economical field content and U(1)_F charge assignment are\nobtained by specific construction. In particular, three families of 10+5*\nchiral matter, along the SU(5) singlet states (some of which serve as right\nhanded neutrinos) are obtained. Appealing texture zero Yukawa matrices provide\nnatural understanding of hierarchies between charged fermion masses and\nmixings. The model predicts inverted hierarchical neutrino mass scenario with\ninteresting implications. \n\n"}
{"id": "1303.3590", "contents": "Title: Higgs production in gluon fusion beyond NNLO Abstract: We construct an approximate expression for the cross section for Higgs\nproduction in gluon fusion at next-to-next-to-next-to-leading order (N$^3$LO)\nin $\\alpha_s$ with finite top mass. We argue that an accurate approximation can\nbe constructed by exploiting the analiticity of the Mellin space cross section,\nand the information on its singularity structure coming from large N (soft\ngluon, Sudakov) and small N (high energy, BFKL) all order resummations. We\nsupport our argument with an explicit comparison of the approximate and the\nexact expressions up to the highest (NNLO) order at which the latter are\navailable. We find that the approximate N$^3$LO result amounts to a correction\nof 16% to the NNLO QCD cross section for production of a 125 GeV Higgs at the\nLHC (8 TeV), larger than previously estimated, and it significantly reduces the\nscale dependence of the NNLO result. \n\n"}
{"id": "1303.3759", "contents": "Title: Druid, event display for the linear collider Abstract: Druid is a dedicated event display designed for the future electron positron\nlinear colliders. Druid takes standard linear collider data files and detector\ngeometry description files as input, it can visualize both physics event and\ndetector geometry. Many displaying options are provided by Druid, giving easy\naccess to different information. As a versatile event display, Druid supports\nall the latest linear collider detector models, Silicon Detector and\nInternational Large Detector, as well as the calorimeter prototypes operated in\nthe CALICE test beam experiments. It has been utilized in many studies such as\nthe verification of detector geometry, analysis of the simulated full events\nand test beam data as well as reconstruction algorithm development and code\ndebugging. \n\n"}
{"id": "1303.6012", "contents": "Title: Are the Snapshot Difference Quotients Needed in the Proper Orthogonal\n  Decomposition? Abstract: This paper presents a theoretical and numerical investigation of the\nfollowing practical question: Should the time difference quotients of the\nsnapshots be used to generate the proper orthogonal decomposition basis\nfunctions? The answer to this question is important, since some published\nnumerical studies use the time difference quotients, whereas other numerical\nstudies do not. The criterion used in this paper to answer this question is the\nrate of convergence of the error of the reduced order model with respect to the\nnumber of proper orthogonal decomposition basis functions. Two cases are\nconsidered: the no_DQ case, in which the snapshot difference quotients are not\nused, and the DQ case, in which the snapshot difference quotients are used. The\nerror estimates suggest that the convergence rates in the $C^0(L^2)$-norm and\nin the $C^0(H^1)$-norm are optimal for the DQ case, but suboptimal for the\nno_DQ case. The convergence rates in the $L^2(H^1)$-norm are optimal for both\nthe DQ case and the no_DQ case. Numerical tests are conducted on the heat\nequation and on the Burgers equation. The numerical results support the\nconclusions drawn from the theoretical error estimates. Overall, the\ntheoretical and numerical results strongly suggest that, in order to achieve\noptimal pointwise in time rates of convergence with respect to the number of\nproper orthogonal decomposition basis functions, one should use the snapshot\ndifference quotients. \n\n"}
{"id": "1304.1222", "contents": "Title: Alternating minimal energy methods for linear systems in higher\n  dimensions. Part II: Faster algorithm and application to nonsymmetric systems Abstract: In this paper we accomplish the development of the fast rank-adaptive solver\nfor tensor-structured symmetric positive definite linear systems in higher\ndimensions. In [arXiv:1301.6068] this problem is approached by alternating\nminimization of the energy function, which we combine with steps of the basis\nexpansion in accordance with the steepest descent algorithm. In this paper we\ncombine the same steps in such a way that the resulted algorithm works with one\nor two neighboring cores at a time. The recurrent interpretation of the\nalgorithm allows to prove the global convergence and to estimate the\nconvergence rate. We also propose several strategies, both rigorous and\nheuristic, to compute new subspaces for the basis enrichment in a more\nefficient way. We test the algorithm on a number of high-dimensional problems,\nincluding the non-symmetrical Fokker-Planck and chemical master equations, for\nwhich the efficiency of the method is not fully supported by the theory. In all\nexamples we observe a convincing fast convergence and high efficiency of the\nproposed method. \n\n"}
{"id": "1304.3696", "contents": "Title: Registration of reactor neutrinos with the highly segmented plastic\n  scintillator detector DANSSino Abstract: DANSSino is a simplified pilot version of a solid-state detector of reactor\nantineutrino (it is being created within the DANSS project and will be\ninstalled close to an industrial nuclear power reactor). Numerous tests\nperformed under a 3 GW(th) reactor of the Kalinin NPP at a distance of 11 m\nfrom the core demonstrate operability of the chosen design and reveal the main\nsources of the background. In spite of its small size (20x20x100 ccm), the\npilot detector turned out to be quite sensitive to reactor neutrinos, detecting\nabout 70 IBD events per day with the signal-to-background ratio about unity. \n\n"}
{"id": "1304.4976", "contents": "Title: An Optimization-Based Atomistic-to-Continuum Coupling Method Abstract: We present a new optimization-based method for atomistic-to-continuum (AtC)\ncoupling. The main idea is to cast the coupling of the atomistic and continuum\nmodels as a constrained optimization problem with virtual Dirichlet controls on\nthe interfaces between the atomistic and continuum subdomains. The optimization\nobjective is to minimize the error between the atomistic and continuum\nsolutions on the overlap between the two subdomains, while the atomistic and\ncontinuum force balance equations provide the constraints. Splitting of the\natomistic and continuum problems instead of blending them and their subsequent\nuse as constraints in the optimization problem distinguishes our approach from\nthe existing AtC formulations. We present and analyze the method in the context\nof a one-dimensional chain of atoms modeled using a linearized two-body\nnext-nearest neighbor interactions. \n\n"}
{"id": "1304.5521", "contents": "Title: Vortex Filament Equation for a Regular Polygon Abstract: In this paper, we study the evolution of the vortex filament equation (VFE),\n$$\\mathbf X_t = \\mathbf X_s \\wedge \\mathbf X_{ss},$$ with $\\mathbf X(s, 0)$\nbeing a regular planar polygon. Using algebraic techniques, supported by full\nnumerical simulations, we give strong evidence that $\\mathbf X(s, t)$ is also a\npolygon at any rational time; moreover, it can be fully characterized, up to a\nrigid movement, by a generalized quadratic Gau{\\ss} sum.\n  We also study the fractal behavior of $\\mathbf X(0, t)$, relating it with the\nso-called Riemann's non-differentiable function, that was proved by Jaffard to\nbe a multifractal. \n\n"}
{"id": "1304.6475", "contents": "Title: Revisiting Asynchronous Linear Solvers: Provable Convergence Rate\n  Through Randomization Abstract: Asynchronous methods for solving systems of linear equations have been\nresearched since Chazan and Miranker's pioneering 1969 paper on chaotic\nrelaxation. The underlying idea of asynchronous methods is to avoid processor\nidle time by allowing the processors to continue to make progress even if not\nall progress made by other processors has been communicated to them.\n  Historically, the applicability of asynchronous methods for solving linear\nequations was limited to certain restricted classes of matrices, such as\ndiagonally dominant matrices. Furthermore, analysis of these methods focused on\nproving convergence in the limit. Comparison of the asynchronous convergence\nrate with its synchronous counterpart and its scaling with the number of\nprocessors were seldom studied, and are still not well understood.\n  In this paper, we propose a randomized shared-memory asynchronous method for\ngeneral symmetric positive definite matrices. We rigorously analyze the\nconvergence rate and prove that it is linear, and is close to that of the\nmethod's synchronous counterpart if the processor count is not excessive\nrelative to the size and sparsity of the matrix. We also present an algorithm\nfor unsymmetric systems and overdetermined least-squares. Our work presents a\nsignificant improvement in the applicability of asynchronous linear solvers as\nwell as in their convergence analysis, and suggests randomization as a key\nparadigm to serve as a foundation for asynchronous methods. \n\n"}
{"id": "1304.7147", "contents": "Title: Mixed Mimetic Spectral Element method applied to Darcy's problem Abstract: We present a discretization for Darcy's problem using the recently developed\nMimetic Spectral Element Method. The gist lies in the exact discrete\nrepresentation of integral relations. In this paper, an anisotropic flow\nthrough a porous medium is considered and a discretization of a full\npermeability tensor is presented. The performance of the method is evaluated on\nstandard test problems, converging at the same rate as the best possible\napproximation. \n\n"}
{"id": "1304.7218", "contents": "Title: A Nystrom flavored Calder\\'on Calculus of order three for two\n  dimensional waves Abstract: In this paper we present and test a full discretization of all elements of\nthe Calder\\'on Calculus (layer potentials and integral operators) for the\nHelmholtz equation in smooth closed curves in the plane. The resulting integral\nequations provide approximations of order three for all variables involved.\nTest are shown for a wide array of direct, indirect and combined field integral\nequation at fixed frequency and for a Convolution Quadrature based\napproximation in the time domain. \n\n"}
{"id": "1304.7796", "contents": "Title: Adaptive Near-Optimal Rank Tensor Approximation for High-Dimensional\n  Operator Equations Abstract: We consider a framework for the construction of iterative schemes for\noperator equations that combine low-rank approximation in tensor formats and\nadaptive approximation in a basis. Under fairly general assumptions, we obtain\na rigorous convergence analysis, where all parameters required for the\nexecution of the methods depend only on the underlying infinite-dimensional\nproblem, but not on a concrete discretization. Under certain assumptions on the\nrates for the involved low-rank approximations and basis expansions, we can\nalso give bounds on the computational complexity of the iteration as a function\nof the prescribed target error. Our theoretical findings are illustrated and\nsupported by computational experiments. These demonstrate that problems in very\nhigh dimensions can be treated with controlled solution accuracy. \n\n"}
{"id": "1305.0161", "contents": "Title: On some properties of the Mittag-Leffler function $E_\\alpha(-t^\\alpha)$,\n  completely monotone for $t > 0$ with $0 < \\alpha < 1$ Abstract: We analyse some peculiar properties of the function of the Mittag-Leffler\n(M-L) type, $e_\\alpha(t):= E_\\alpha(-t^\\alpha)$ for $0 <\\alpha < 1$ and $t >\n0$, which is known to be completely monotone (CM) with a non negative spectrum\nof frequencies and times, suitable to model fractional relaxation processes. We\nfirst note that these two spectra coincide so providing a universal scaling\nproperty of this function. Furthermore, we consider the problem of\napproximating our M-L function with simpler CM functions for small and large\ntimes. We provide two different sets of elementary CM functions that are\nasymptotically equivalent to $e_\\alpha(t)$ as $t \\to 0$ and $t \\to \\infty$. \n\n"}
{"id": "1305.0646", "contents": "Title: Convolution spline approximations for time domain boundary integral\n  equations Abstract: We introduce a new \"convolution spline\" temporal approximation of time domain\nboundary integral equations (TDBIEs). It shares some properties of convolution\nquadrature (CQ), but instead of being based on an underlying ODE solver the\napproximation is explicitly constructed in terms of compactly supported basis\nfunctions. This results in sparse system matrices and makes it computationally\nmore efficient than using the linear multistep version of CQ for TDBIE\ntime-stepping. We use a Volterra integral equation (VIE) to illustrate the\nderivation of this new approach: at time step $t_n = n h$ the VIE solution is\napproximated in a backwards-in-time manner in terms of basis functions $\\phi_j$\nby $u(t_n-t) \\approx \\sum_{j=0}^n u_{n-j}\\,\\phi_j(t/h)$ for $t \\in [0,t_n]$. We\nshow that using isogeometric B-splines of degree $m\\ge 1$ on $[0,\\infty)$ in\nthis framework gives a second order accurate scheme, but cubic splines with the\nparabolic runout conditions at $t=0$ are fourth order accurate. We establish a\nmethodology for the stability analysis of VIEs and demonstrate that the new\nmethods are stable for non-smooth kernels which are related to convergence\nanalysis for TDBIEs, including the case of a Bessel function kernel oscillating\nat frequency $O(1/h)$. Numerical results for VIEs and for TDBIE problems on\nboth open and closed surfaces confirm the theoretical predictions. \n\n"}
{"id": "1305.0830", "contents": "Title: Pulsars Cannot Account for the Inner Galaxy's GeV Excess Abstract: Using data from the Fermi Gamma-Ray Space Telescope, a spatially extended\ncomponent of gamma rays has been identified from the direction of the Galactic\nCenter, peaking at energies of ~2-3 GeV. More recently, it has been shown that\nthis signal is not confined to the innermost hundreds of parsecs of the Galaxy,\nbut instead extends to at least ~3 kpc from the Galactic Center. While the\nspectrum, intensity, and angular distribution of this signal is in good\nagreement with predictions from annihilating dark matter, it has also been\nsuggested that a population of unresolved millisecond pulsars could be\nresponsible for this excess GeV emission from the Inner Galaxy. In this paper,\nwe consider this later possibility in detail. Comparing the observed spectral\nshape of the Inner Galaxy's GeV excess to the spectrum measured from 37\nmillisecond pulsars by Fermi, we find that these sources exhibit a spectral\nshape that is much too soft at sub-GeV energies to accommodate this signal. We\nalso construct population models to describe the spatial distribution and\nluminosity function of the Milky Way's millisecond pulsars. After taking into\naccount constraints from the observed distribution of Fermi sources (including\nboth sources known to be millisecond pulsars, and unidentified sources which\ncould be pulsars), we find that millisecond pulsars can account for no more\nthan ~10% of the Inner Galaxy's GeV excess. Each of these arguments strongly\ndisfavor millisecond pulsars as the source of this signal. \n\n"}
{"id": "1305.1922", "contents": "Title: Efficient Accelerated Coordinate Descent Methods and Faster Algorithms\n  for Solving Linear Systems Abstract: In this paper we show how to accelerate randomized coordinate descent methods\nand achieve faster convergence rates without paying per-iteration costs in\nasymptotic running time. In particular, we show how to generalize and\nefficiently implement a method proposed by Nesterov, giving faster asymptotic\nrunning times for various algorithms that use standard coordinate descent as a\nblack box. In addition to providing a proof of convergence for this new general\nmethod, we show that it is numerically stable, efficiently implementable, and\nin certain regimes, asymptotically optimal.\n  To highlight the computational power of this algorithm, we show how it can\nused to create faster linear system solvers in several regimes:\n  - We show how this method achieves a faster asymptotic runtime than conjugate\ngradient for solving a broad class of symmetric positive definite systems of\nequations.\n  - We improve the best known asymptotic convergence guarantees for Kaczmarz\nmethods, a popular technique for image reconstruction and solving\noverdetermined systems of equations, by accelerating a randomized algorithm of\nStrohmer and Vershynin.\n  - We achieve the best known running time for solving Symmetric Diagonally\nDominant (SDD) system of equations in the unit-cost RAM model, obtaining an O(m\nlog^{3/2} n (log log n)^{1/2} log (log n / eps)) asymptotic running time by\naccelerating a recent solver by Kelner et al.\n  Beyond the independent interest of these solvers, we believe they highlight\nthe versatility of the approach of this paper and we hope that they will open\nthe door for further algorithmic improvements in the future. \n\n"}
{"id": "1305.3350", "contents": "Title: DANSSino: a pilot version of the DANSS neutrino detector Abstract: DANSSino is a reduced pilot version of a solid-state detector of reactor\nantineutrinos (to be created within the DANSS project and installed under the\nindustrial 3 GW(th) reactor of the Kalinin Nuclear Power Plant -- KNPP).\nNumerous tests performed at a distance of 11 m from the reactor core\ndemonstrate operability of the chosen design and reveal the main sources of the\nbackground. In spite of its small size (20x20x100 ccm), the pilot detector\nturned out to be quite sensitive to reactor antineutrinos, detecting about 70\nIBD events per day with the signal-to-background ratio about unity. \n\n"}
{"id": "1305.3639", "contents": "Title: Local error estimates for adaptive simulation of the Reaction-Diffusion\n  Master Equation via operator splitting Abstract: The efficiency of exact simulation methods for the reaction-diffusion master\nequation (RDME) is severely limited by the large number of diffusion events if\nthe mesh is fine or if diffusion constants are large. Furthermore, inherent\nproperties of exact kinetic-Monte Carlo simulation methods limit the efficiency\nof parallel implementations. Several approximate and hybrid methods have\nappeared that enable more efficient simulation of the RDME. A common feature to\nmost of them is that they rely on splitting the system into its reaction and\ndiffusion parts and updating them sequentially over a discrete timestep. This\nuse of operator splitting enables more efficient simulation but it comes at the\nprice of a temporal discretization error that depends on the size of the\ntimestep. So far, existing methods have not attempted to estimate or control\nthis error in a systematic manner. This makes the solvers hard to use for\npractitioners since they must guess an appropriate timestep. It also makes the\nsolvers potentially less efficient than if the timesteps are adapted to control\nthe error. Here, we derive estimates of the local error and propose a strategy\nto adaptively select the timestep when the RDME is simulated via a first order\noperator splitting. While the strategy is general and applicable to a wide\nrange of approximate and hybrid methods, we exemplify it here by extending a\npreviously published approximate method, the Diffusive Finite-State Projection\n(DFSP) method, to incorporate temporal adaptivity. \n\n"}
{"id": "1305.4071", "contents": "Title: Several Approaches to Break the Curse of Dimensionality Abstract: In modern science the efficient numerical treatment of high-dimensional\nproblems becomes more and more important. A fundamental insight of the theory\nof information-based complexity (IBC for short) is that the computational\nhardness of a problem can not be described properly only by the rate of\nconvergence. There exist problems for which an exponential number of\ninformation operations is needed in order to reduce the initial error, although\nthere are algorithms which provide an arbitrary large rate of convergence.\nProblems that yield this exponential dependence are said to suffer from the\ncurse of dimensionality. While analyzing numerical problems it turns out that\nwe can often vanquish this curse by exploiting additional structural\nproperties. The aim of this thesis is to present several approaches of this\ntype. Moreover, a detailed introduction to the field of IBC is given. \n\n"}
{"id": "1305.4080", "contents": "Title: Two-Level discretization techniques for ground state computations of\n  Bose-Einstein condensates Abstract: This work presents a new methodology for computing ground states of\nBose-Einstein condensates based on finite element discretizations on two\ndifferent scales of numerical resolution. In a pre-processing step, a\nlow-dimensional (coarse) generalized finite element space is constructed. It is\nbased on a local orthogonal decomposition and exhibits high approximation\nproperties. The non-linear eigenvalue problem that characterizes the ground\nstate is solved by some suitable iterative solver exclusively in this\nlow-dimensional space, without loss of accuracy when compared with the solution\nof the full fine scale problem. The pre-processing step is independent of the\ntypes and numbers of bosons. A post-processing step further improves the\naccuracy of the method. We present rigorous a priori error estimates that\npredict convergence rates H^3 for the ground state eigenfunction and H^4 for\nthe corresponding eigenvalue without pre-asymptotic effects; H being the coarse\nscale discretization parameter. Numerical experiments indicate that these high\nrates may still be pessimistic. \n\n"}
{"id": "1305.4889", "contents": "Title: From microscopic theory to macroscopic theory: a systematic study on\n  static modeling for liquid crystals Abstract: In this paper, we propose a systematic way of liquid crystal modeling to\nbuild connection between microscopic theory and macroscopic theory. A new\nQ-tensor theory based on Onsager's molecular theory which leads to liquid\ncrystals with certain shape has been proposed. Making uniaxial assumption, we\ncan recover the Oseen-Frank theory from the derived $Q$-tensor theory, and the\nOseen-Frank model coefficients can be examined. In addition, the smectic-A\nphase can also be characterized by the derived macroscopic model. \n\n"}
{"id": "1305.5481", "contents": "Title: Rosenbrock-Krylov Methods for Large Systems of Differential Equations Abstract: This paper develops a new class of Rosenbrock-type integrators based on a\nKrylov space solution of the linear systems. The new family, called\nRosenbrock-Krylov (Rosenbrock-K), is well suited for solving large scale\nsystems of ODEs or semi-discrete PDEs. The time discretization and the Krylov\nspace approximation are treated as a single computational process, and the\nKrylov space properties are an integral part of the new Rosenbrock-K order\ncondition theory developed herein. Consequently, Rosenbrock-K methods require a\nsmall number of basis vectors determined solely by the temporal order of\naccuracy. The subspace size is independent of the ODE under consideration, and\nthere is no need to monitor the errors in linear system solutions at each\nstage. Numerical results show favorable properties of Rosenbrock-K methods when\ncompared to current Rosenbrock and Rosenbrock-W schemes. \n\n"}
{"id": "1305.6818", "contents": "Title: Partitioned treatment of uncertainty in coupled domain problems: A\n  separated representation approach Abstract: This work is concerned with the propagation of uncertainty across coupled\ndomain problems with high-dimensional random inputs. A stochastic model\nreduction approach based on low-rank separated representations is proposed for\nthe partitioned treatment of the uncertainty space. The construction of the\ncoupled domain solution is achieved though a sequence of approximations with\nrespect to the dimensionality of the random inputs associated with each\nindividual sub-domain and not the combined dimensionality, hence drastically\nreducing the overall computational cost. The coupling between the sub-domain\nsolutions is done via the classical Finite Element Tearing and Interconnecting\n(FETI) method, thus providing a well suited framework for parallel computing.\nTwo high-dimensional stochastic problems, a 2D elliptic PDE with random\ndiffusion coefficient and a stochastic linear elasticity problem, have been\nconsidered to study the performance and accuracy of the proposed stochastic\ncoupling approach. \n\n"}
{"id": "1305.6910", "contents": "Title: \\alpha_S from $F_\\pi$ and Renormalization Group Optimized Perturbation Abstract: A variant of variationally optimized perturbation, incorporating\nrenormalization group properties in a straightforward way, uniquely fixes the\nvariational mass interpolation in terms of the anomalous mass dimension. It is\nused at three successive orders to calculate the nonperturbative ratio\n$F_\\pi/\\Lambda$ of the pion decay constant and the basic QCD scale in the MSbar\nscheme. We demonstrate the good stability and (empirical) convergence\nproperties of this modified perturbative series for this quantity, and provide\nsimple and generic cures to previous problems of the method, principally the\ngenerally non-unique and non-real optimal solutions beyond lowest order. Using\nthe experimental $F_\\pi$ input value we determine \\Lambda^{n_f=2}\\simeq\n359^{+38}_{-25} \\pm 5 MeV and \\Lambda^{n_f=3}=317^{+14}_{-7} \\pm 13 MeV, where\nthe first quoted errors are our estimate of theoretical uncertainties of the\nmethod, which we consider conservative. The second uncertainties come from the\npresent uncertainties in F_\\pi/F and F_\\pi/F_0, where F (F_0) is $F_\\pi$ in the\nexact chiral SU(2) (SU(3)) limits. Combining the \\Lambda^{n_f=3} results with a\nstandard perturbative evolution provides a new independent determination of the\nstrong coupling constant at various relevant scales, in particular \\alpha_S\n(m_Z) =0.1174 ^{+.0010}_{-.0005} \\pm .001 \\pm .0005_{evol} and\n\\alpha_S^{n_f=3}(m_\\tau)= 0.308 ^{+.007}_{-.004} \\pm .007 \\pm .002_{evol}. A\nless conservative interpretation of our prescriptions favors central values\ncloser to the upper limits of the first uncertainties. The theoretical accuracy\nis well comparable to the most precise recent {\\em single} determinations of\n\\alpha_S, including some very recent lattice simulation determinations with\nfully dynamical quarks. \n\n"}
{"id": "1306.0612", "contents": "Title: Fast integral equation methods for the Laplace-Beltrami equation on the\n  sphere Abstract: Integral equation methods for solving the Laplace-Beltrami equation on the\nunit sphere in the presence of multiple \"islands\" are presented. The surface of\nthe sphere is first mapped to a multiply-connected region in the complex plane\nvia a stereographic projection. After discretizing the integral equation, the\nresulting dense linear system is solved iteratively using the fast multipole\nmethod for the 2D Coulomb potential in order to calculate the matrix-vector\nproducts. This numerical scheme requires only O(N) operations, where $N$ is the\nnumber of nodes in the discretization of the boundary. The performance of the\nmethod is demonstrated on several examples. \n\n"}
{"id": "1306.0936", "contents": "Title: Benchmarking the Immersed Finite Element Method for Fluid-Structure\n  Interaction Problems Abstract: We present an implementation of a fully variational formulation of an\nimmersed method for fluid-structure interaction problems based on the finite\nelement method. While typical implementation of immersed methods are\ncharacterized by the use of approximate Dirac delta distributions, fully\nvariational formulations of the method do not require the use of said\ndistributions. In our implementation the immersed solid is general in the sense\nthat it is not required to have the same mass density and the same viscous\nresponse as the surrounding fluid. We assume that the immersed solid can be\neither viscoelastic of differential type or hyperelastic. Here we focus on the\nvalidation of the method via various benchmarks for fluid-structure interaction\nnumerical schemes. This is the first time that the interaction of purely\nelastic compressible solids and an incompressible fluid is approached via an\nimmersed method allowing a direct comparison with established benchmarks. \n\n"}
{"id": "1306.1391", "contents": "Title: Measurement of the Luminosity in the ZEUS Experiment at HERA II Abstract: The luminosity in the ZEUS detector was measured using photons from electron\nbremsstrahlung. In 2001 the HERA collider was upgraded for operation at higher\nluminosity. At the same time the luminosity-measuring system of the ZEUS\nexperiment was modified to tackle the expected higher photon rate and\nsynchrotron radiation. The existing lead-scintillator calorimeter was equipped\nwith radiation hard scintillator tiles and shielded against synchrotron\nradiation. In addition, a magnetic spectrometer was installed to measure the\nluminosity independently using photons converted in the beam-pipe exit window.\nThe redundancy provided a reliable and robust luminosity determination with a\nsystematic uncertainty of 1.7%. The experimental setup, the techniques used for\nluminosity determination and the estimate of the systematic uncertainty are\nreported. \n\n"}
{"id": "1306.2269", "contents": "Title: Computation of extreme eigenvalues in higher dimensions using block\n  tensor train format Abstract: We consider an approximate computation of several minimal eigenpairs of large\nHermitian matrices which come from high--dimensional problems. We use the\ntensor train format (TT) for vectors and matrices to overcome the curse of\ndimensionality and make storage and computational cost feasible. Applying a\nblock version of the TT format to several vectors simultaneously, we compute\nthe low--lying eigenstates of a system by minimization of a block Rayleigh\nquotient performed in an alternating fashion for all dimensions. For several\nnumerical examples, we compare the proposed method with the deflation approach\nwhen the low--lying eigenstates are computed one-by-one, and also with the\nvariational algorithms used in quantum physics. \n\n"}
{"id": "1306.2655", "contents": "Title: The Electron Capture $^{163}$Ho Experiment ECHo Abstract: The determination of the absolute scale of the neutrino masses is one of the\nmost challenging questions in particle physics. Different approaches are\nfollowed to achieve a sensitivity on neutrino masses in the sub-eV range. Among\nthem, experiments exploring the beta decay and electron capture processes of\nsuitable nuclides can provide necessary information on the electron neutrino\nmass value. In this talk we present the Electron Capture 163-Ho experiment\nECHo, which aims to investigate the electron neutrino mass in the sub-eV range\nby means of the analysis of the calorimetrically measured energy spectrum\nfollowing the electron capture process of 163-Ho. A high precision and high\nstatistics spectrum will be measured by means of low temperature magnetic\ncalorimeter arrays. We present preliminary results obtained with a first\nprototype of single channel detectors as well as the participating groups and\ntheir on-going developments. \n\n"}
{"id": "1306.4075", "contents": "Title: Geometric aspects of Pellet's and related theorems Abstract: Pellet's theorem determines when the zeros of a polynomial can be separated\ninto two regions, according to their moduli. We refine one of those regions and\nreplace it with the closed interior of a lemniscate that provides more precise\ninformation on the location of the zeros. Moreover, Pellet's theorem is\nconsidered the generalization of a zero inclusion region due to Cauchy. Using\nlinear algebra tools, we derive a different generalization that leads to a\nsequence of smaller inclusion regions, which are also the closed interiors of\nlemniscates. \n\n"}
{"id": "1306.6401", "contents": "Title: Screening the fifth force in the Horndeski's most general scalar-tensor\n  theories Abstract: We study how the Vainshtein mechanism operates in the most general\nscalar-tensor theories with second-order equations of motion. The field\nequations of motion, which can be also applicable to most of other screening\nscenarios proposed in literature, are generally derived in a spherically\nsymmetric space-time with a matter source. In the presence of a field coupling\nto the Ricci scalar, we clarify conditions under which the Vainshtein mechanism\nis at work in a weak gravitational background. We also obtain the solutions of\nthe field equation inside a spherically symmetric body and show how they can be\nconnected to exterior solutions that accommodate the Vainshtein mechanism. We\napply our general results to a number of concrete models such as the\ncovariant/extended Galileons and the DBI Galileons with Gauss-Bonnet and other\nterms. In these models the fifth force can be suppressed to be compatible with\nsolar-system constraints, provided that non-linear field kinetic terms coupled\nto the Einstein tensor do not dominate over other non-linear field\nself-interactions. \n\n"}
{"id": "1307.0101", "contents": "Title: Current Direct Neutrino Mass Experiments Abstract: In this contribution we review the status and perspectives of direct neutrino\nmass experiments. These experiments investigate the kinematics of\n$\\beta$-decays of specific isotopes ($^3$H, $^{187}$Re, $^{163}$Ho) to derive\nmodel-independent information on the averaged electron (anti-) neutrino mass,\nwhich is formed by the incoherent sum of the neutrino mass eigenstates\ncontributing to the electron neutrino. We first review the kinematics of\n$\\beta$-decay and the determination of the neutrino mass, before giving a brief\noverview of past neutrino mass measurements (SN1987a-ToF studies, Mainz and\nTroitsk experiments for $^3$H, cryo-bolometers for $^{187}$Re). We then\ndescribe the Karlsruhe Tritium Neutrino (KATRIN) experiment which is currently\nunder construction at Karlsruhe Institute of Technology. The large-scale setup\nwill use the MAC-E-Filter principle pioneered earlier to push the sensitivity\ndown to a value of 200 meV(90% C.L.). KATRIN faces many technological\nchallenges that have to be resolved with regard to source intensity and\nstability, as well as precision energy analysis and low background rate close\nto the kinematic endpoint of tritium $\\beta$-decay at 18.6 keV. We then review\nnew experimental approaches such as the MARE, ECHO and Project8 experiments,\nwhich offer the promise to perform an independent measurement of the neutrino\nmass in the sub-eV region. This variety of methods and the novel technologies\ndeveloped in all present and future experiments demonstrate the great potential\nof direct neutrino mass experiments in providing vital information on the\nabsolute mass scale of neutrinos. \n\n"}
{"id": "1307.1089", "contents": "Title: The Daya Bay Antineutrino Detector Filling System and Liquid Mass\n  Measurement Abstract: The Daya Bay Reactor Neutrino Experiment has measured the neutrino mixing\nangle \\theta_{13} to world-leading precision. The experiment uses eight\nantineutrino detectors filled with 20-tons of gadolinium-doped liquid\nscintillator to detect antineutrinos emitted from the Daya Bay nuclear power\nplant through the inverse beta decay reaction. The precision measurement of\nsin^{2}2\\theta_{13} relies on the relative antineutrino interaction rates\nbetween detectors at near (400 m) and far (roughly 1.8 km) distances from the\nnuclear reactors. The measured interaction rate in each detector is directly\nproportional to the number of protons in the liquid scintillator target. A\nprecision detector filling system was developed to simultaneously fill the\nthree liquid zones of the antineutrino detectors and measure the relative\ntarget mass between detectors to <0.02%. This paper describes the design,\noperation, and performance of the system and the resulting precision\nmeasurement of the detectors' target liquid masses. \n\n"}
{"id": "1307.2448", "contents": "Title: Enhanced Bd --> mu+ mu- Decay: What if? Abstract: If the very rare $B_d^0 \\to \\mu^+\\mu^-$ decay is enhanced to (3--4) $\\times\n10^{-10}$ level or higher, it can be discovered with existing 2011-2012 LHC\ndata. It might then cast some doubt on the Higgs boson nature of the 126 GeV\nboson, since the likely explanation would be due to the fourth generation\n$t^\\prime$ quark. There is a mild motivation from the known tension in\n$\\sin2\\beta/\\phi_1$. If discovery is made before the 13 TeV run, then the $b\n\\to d$ quadrangle (modulo $m_{t'}$) would suddenly fall into our lap. Continued\npursuit in future runs can probe below $3 \\times 10^{-10}$. \n\n"}
{"id": "1307.4742", "contents": "Title: Optical Properties of Quantum-Dot-Doped Liquid Scintillators Abstract: Semiconductor nanoparticles (quantum dots) were studied in the context of\nliquid scintillator development for upcoming neutrino experiments. The unique\noptical and chemical properties of quantum dots are particularly promising for\nthe use in neutrinoless double beta decay experiments. Liquid scintillators for\nlarge scale neutrino detectors have to meet specific requirements which are\nreviewed, highlighting the peculiarities of quantum-dot-doping. In this paper,\nwe report results on laboratory-scale measurements of the attenuation length\nand the fluorescence properties of three commercial quantum dot samples. The\nresults include absorbance and emission stability measurements, improvement in\ntransparency due to filtering of the quantum dot samples, precipitation tests\nto isolate the quantum dots from solution and energy transfer studies with\nquantum dots and the fluorophore PPO. \n\n"}
{"id": "1307.7867", "contents": "Title: A space-time parallel solver for the three-dimensional heat equation Abstract: The paper presents a combination of the time-parallel \"parallel full\napproximation scheme in space and time\" (PFASST) with a parallel multigrid\nmethod (PMG) in space, resulting in a mesh-based solver for the\nthree-dimensional heat equation with a uniquely high degree of efficient\nconcurrency. Parallel scaling tests are reported on the Cray XE6 machine \"Monte\nRosa\" on up to 16,384 cores and on the IBM Blue Gene/Q system \"JUQUEEN\" on up\nto 65,536 cores. The efficacy of the combined spatial- and temporal\nparallelization is shown by demonstrating that using PFASST in addition to PMG\nsignificantly extends the strong-scaling limit. Implications of using spatial\ncoarsening strategies in PFASST's multi-level hierarchy in large-scale parallel\nsimulations are discussed. \n\n"}
{"id": "1307.8036", "contents": "Title: TPB-coated Light Guides for Liquid Argon TPC Light Detection Systems Abstract: Light detection systems in Liquid Argon Time Projection Chambers (LArTPCs)\nrequire the detection of the 128 nm light produced during argon scintillation.\nMost detectors use Tetraphenyl Butadiene (TPB) to shift the wavelength of the\nlight into a range visible to Photomultiplier Tubes (PMTs). These proceedings\nsummarize characterizations of light-guides coated with a matrix of TPB in UV\ntransmitting acrylic which are more compact than existing LArTPC light\ncollection systems. \n\n"}
{"id": "1307.8101", "contents": "Title: Improved Particle Identification Using Cluster Counting in a Full-Length\n  Drift Chamber Prototype Abstract: Single-cell prototype drift chambers were built at TRIUMF and tested with a\n$\\sim\\unit[210]{MeV/c}$ beam of positrons, muons, and pions. A cluster-counting\ntechnique is implemented which improves the ability to distinguish muons and\npions when combined with a traditional truncated-mean charge measurement.\nSeveral cluster-counting algorithms and equipment variations are tested, all\nshowing significant improvement when combined with the traditional method. The\nresults show that cluster counting is a feasible option for any particle\nphysics experiment using drift chambers for particle identification. The\ntechnique does not require electronics with an overly high sampling rate.\nOptimal results are found with a signal smoothing time of $\\sim\\unit[5]{ns}$\ncorresponding to a $\\sim\\unit[100]{MHz}$ Nyquist frequency. \n\n"}
{"id": "1308.4322", "contents": "Title: On the Optimal Rates of Convergence for Quadratures Derived from\n  Chebyshev Points Abstract: In this paper, we study the optimal general convergence rates for quadratures\nderived from Chebyshev points. By building on the aliasing errors on\nintegration of Chebyshev polynomials, together with the asymptotic formulae on\nthe coefficients of Chebyshev expansions, new and optimal convergence rates for\n$n$-point Clenshaw-Curtis, Fej\\'{e}r's first and second quadrature rules are\nestablished for Jacobi weights or Jacobi weights multiplied by $\\ln((x+1)/2)$.\nThe convergence orders are attainable for some functions of finite\nregularities. In addition, by using refined estimates on aliasing errors on\nintegration of Chebyshev polynomials by Gauss-Legendre quadrature, an improved\nconvergence rate for Gauss-Legendre is given too. \n\n"}
{"id": "1309.0826", "contents": "Title: Truncated hierarchical preconditioning for the stochastic Galerkin FEM Abstract: Stochastic Galerkin finite element discretizations of partial differential\nequations with coefficients characterized by arbitrary distributions lead, in\ngeneral, to fully block dense linear systems. We propose two novel strategies\nfor constructing preconditioners for these systems to be used with Krylov\nsubspace iterative solvers. In particular, we present a variation on of the\nhierarchical Schur complement preconditioner, developed recently by the\nauthors, and an adaptation of the symmetric block Gauss-Seidel method. Both\npreconditioners take advantage of the hierarchical structure of global\nstochastic Galerkin matrices, and also, when applicable, of the decay of the\nnorms of the stiffness matrices obtained from the polynomial chaos expansion of\nthe coefficients. This decay allows to truncate the matrix-vector\nmultiplications in the action of the preconditioners. Also, throughout the\nglobal matrix hierarchy, we approximate solves with certain submatrices by the\nassociated diagonal block solves. The preconditioners thus require only a\nlimited number of stiffness matrices obtained from the polynomial chaos\nexpansion of the coefficients, and a preconditioner for the diagonal blocks of\nthe global matrix. The performance is illustrated by numerical experiments. \n\n"}
{"id": "1309.4071", "contents": "Title: Comment on \"Charged vector mesons in a strong magnetic field\" Abstract: In a recent paper Y. Hidaka and A. Yamamoto [Phys. Rev. D 87 (2013) 094502]\nclaim -- using both analytical and numerical approaches -- that the charged rho\nmesons cannot condense in the vacuum subjected to a strong magnetic field. In\nthis Comment we point out that both analytical and numerical results of this\npaper are consistent with the inhomogeneous rho-meson condensation.\nFurthermore, we show that the numerical results of the paper support the\npresence of the expected (in quenched lattice QCD) crossover transition driven\nby the rho-meson condensation. Finally, we stress that the inhomogeneous\nrho-meson condensation is consistent with both Vafa-Witten and Elitzur\ntheorems. \n\n"}
{"id": "1309.6405", "contents": "Title: Error matrices in quantum process tomography Abstract: We discuss characterization of experimental quantum gates by the error\nmatrix, which is similar to the standard process matrix $\\chi$ in the Pauli\nbasis, except the desired unitary operation is factored out, by formally\nplacing it either before or after the error process. The error matrix has only\none large element, which is equal to the process fidelity, while other elements\nare small and indicate imperfections. The imaginary parts of the elements along\nthe left column and/or top row directly indicate the unitary imperfection and\ncan be used to find the needed correction. We discuss a relatively simple way\nto calculate the error matrix for a composition of quantum gates. Similarly, it\nis rather straightforward to find the first-order contribution to the error\nmatrix due to the Lindblad-form decoherence. We also discuss a way to identify\nand subtract the tomography procedure errors due to imperfect state preparation\nand measurement. In appendices we consider several simple examples of the\nprocess tomography and also discuss an intuitive physical interpretation of the\nLindblad-form decoherence. \n\n"}
{"id": "1309.6666", "contents": "Title: Two-dimensional wave propagation in layered periodic media Abstract: We study two-dimensional wave propagation in materials whose properties vary\nperiodically in one direction only. High order homogenization is carried out to\nderive a dispersive effective medium approximation. One-dimensional materials\nwith constant impedance exhibit no effective dispersion. We show that a new\nkind of effective dispersion may arise in two dimensions, even in materials\nwith constant impedance. This dispersion is a macroscopic effect of microscopic\ndiffraction caused by spatial variation in the sound speed. We analyze this\ndispersive effect by using high-order homogenization to derive an anisotropic,\ndispersive effective medium. We generalize to two dimensions a homogenization\napproach that has been used previously for one-dimensional problems.\nPseudospectral solutions of the effective medium equations agree to high\naccuracy with finite volume direct numerical simulations of the\nvariable-coefficient equations. \n\n"}
{"id": "1309.7896", "contents": "Title: A Tracker for the Mu3e Experiment based on High-Voltage Monolithic\n  Active Pixel Sensors Abstract: The Mu3e experiment searches for the lepton flavour violating decay mu+ ->\ne+e-e+, aiming for a branching fraction sensitivity of 10^-16. This requires an\nexcellent momentum resolution for low energy electrons, high rate capability\nand a large acceptance. In order to minimize multiple scattering, the amount of\nmaterial has to be as small as possible. These challenges can be met with a\ntracker built from high-voltage monolithic active pixel sensors (HV-MAPS),\nwhich can be thinned to 50 um and which incorporate the complete read-out\nelectronics on the sensor chip. To further minimise material, the sensors are\nsupported by a mechanical structure built from 25 um thick Kapton foil and\ncooled with gaseous helium. \n\n"}
{"id": "1309.7985", "contents": "Title: Experimental Challenges of the European Strategy for Particle Physics Abstract: In planning for the Phase II upgrades of CMS and ATLAS major considerations\nare: 1)being able to deal with degradation of tracking and calorimetry up to\nthe radiation doses to be expected with an integrated luminosity of 3000\n$fb^{-1}$ and 2)maintaining physics performance at a pileup level of ~140. Here\nI report on work started within the context of the CMS Forward Calorimetry Task\nForce and continuing in an expanded CERN RD52 R$&$D program integrating timing\n(i.e. measuring the time-of-arrival of physics objects) as a potential tool for\npileup mitigation and ideas for Forward Calorimetry. For the past 4 years our\ngroup has focused on precision timing at the level of 10-20 picoseconds in an\nenvironment with rates of $~10^6-10^7$ Hz/$cm^2 $ as is appropriate for the\nfuture running of the LHC (HL-LHC era). A time resolution of 10-20 picoseconds\nis one of the few clear criteria for pileup mitigation at the LHC, since the\ninteraction time of a bunch crossing has an rms of 170 picosec. While work on\ncharged particle timing in other contexts (i.e. ALICE R$&$D) is starting to\napproach this precision, there have been essentially no technologies that can\nsustain performance at these rates. I will present results on a tracker we\ndeveloped within the DOE Advanced Detector R$&$D program which is now meeting\nthese requirements. I will also review some results from Calorimeter Projects\ndeveloped within our group (PHENIX EMCAL and ATLAS ZDC) which achieved\ncalorimeter timing precision< 100 picoseconds. \n\n"}
{"id": "1310.0397", "contents": "Title: Project 8: Using Radio-Frequency Techniques to Measure Neutrino Mass Abstract: The Project 8 experiment aims to measure the neutrino mass using tritium beta\ndecays. Beta-decay electron energies will be measured with a novel technique:\nas the electrons travel in a uniform magnetic field their cyclotron radiation\nwill be detected. The frequency of each electron's cyclotron radiation is\ninversely proportional to its total relativistic energy; therefore, by\nobserving the cyclotron radiation we can make a precise measurement of the\nelectron energies. The advantages of this technique include scalability,\nexcellent energy resolution, and low backgrounds. The collaboration is using a\nprototype experiment to study the feasibility of the technique with a\n$^{83m}$Kr source. Demonstrating the ability to see the 17.8 keV and 30.2 keV\nconversion electrons from $^{83m}$Kr will show that it may be possible to\nmeasure tritium beta-decay electron energies ($Q \\approx 18.6$ keV) with their\ncyclotron radiation. Progress on the prototype, analysis and signal-extraction\ntechniques, and an estimate of the potential future of the experiment will be\ndiscussed. \n\n"}
{"id": "1310.2060", "contents": "Title: The Heavy Photon Search Experiment at Jefferson Lab Abstract: The Heavy Photon Search (HPS) is a new experiment at Jefferson Lab that will\nsearch for heavy U(1) vector bosons (heavy photons or dark photons) in the mass\nrange of 20 MeV/c$^2$ to 1 GeV/c$^2$. Dark photons in this mass range are\ntheoretically favorable and may mediate dark matter interactions. The dark\nphoton couples to electric charge through kinetic mixing with the photon,\nallowing its production through a process analogous to bremsstrahlung\nradiation. HPS will utilize this production mechanism to probe dark photons\nwith relative couplings of ${\\epsilon}^2 = {\\alpha}'/{\\alpha}$ ~ $10^{-5}$ to\n$10^{-10}$ and search for the $e^{+}e^{-}$ or $\\mu^{+}\\mu^{-}$ decay of the\ndark photon via two signatures (invariant mass and displaced vertex). Using\nJefferson Lab's high luminosity electron beam along with a compact large\nacceptance forward spectrometer consisting of a silicon vertex tracker, lead\ntungstate electromagnetic calorimeter and a muon detector, HPS will access\nhitherto unexplored regions in the mass/coupling space. \n\n"}
{"id": "1310.2828", "contents": "Title: A Two-Level Method for Mimetic Finite Difference Discretizations of\n  Elliptic Problems Abstract: We propose and analyze a two-level method for mimetic finite difference\napproximations of second order elliptic boundary value problems. We prove that\nthe two-level algorithm is uniformly convergent, i.e., the number of iterations\nneeded to achieve convergence is uniformly bounded independently of the\ncharacteristic size of the underling partition. We also show that the resulting\nscheme provides a uniform preconditioner with respect to the number of degrees\nof freedom. Numerical results that validate the theory are also presented. \n\n"}
{"id": "1310.2842", "contents": "Title: Wavelet methods for shape perception in electro-sensing Abstract: This paper aims at presenting a new approach to the electro-sensing problem\nusing wavelets. It provides an efficient algorithm for recognizing the shape of\na target from micro-electrical impedance measurements. Stability and resolution\ncapabilities of the proposed algorithm are quantified in numerical simulations. \n\n"}
{"id": "1310.2887", "contents": "Title: An Accelerated Randomized Kaczmarz Algorithm Abstract: The randomized Kaczmarz ($\\RK$) algorithm is a simple but powerful approach\nfor solving consistent linear systems $Ax=b$. This paper proposes an\naccelerated randomized Kaczmarz ($\\ARK$) algorithm with better convergence than\nthe standard $\\RK$ algorithm on ill conditioned problems. The per-iteration\ncost of $\\RK$ and $\\ARK$ are similar if $A$ is dense, but $\\RK$ is much more\nable to exploit sparsity in $A$ than is $\\ARK$. To deal with the sparse case,\nan efficient implementation for $\\ARK$, called $\\SARK$, is proposed. A\ncomparison of convergence rates and average per-iteration complexities among\n$\\RK$, $\\ARK$, and $\\SARK$ is given, taking into account different levels of\nsparseness and conditioning. Comparisons with the leading deterministic\nalgorithm --- conjugate gradient applied to the normal equations --- are also\ngiven. Finally, the analysis is validated via computational testing. \n\n"}
{"id": "1310.3240", "contents": "Title: Phase Retrieval from Coded Diffraction Patterns Abstract: This paper considers the question of recovering the phase of an object from\nintensity-only measurements, a problem which naturally appears in X-ray\ncrystallography and related disciplines. We study a physically realistic setup\nwhere one can modulate the signal of interest and then collect the intensity of\nits diffraction pattern, each modulation thereby producing a sort of coded\ndiffraction pattern. We show that PhaseLift, a recent convex programming\ntechnique, recovers the phase information exactly from a number of random\nmodulations, which is polylogarithmic in the number of unknowns. Numerical\nexperiments with noiseless and noisy data complement our theoretical analysis\nand illustrate our approach. \n\n"}
{"id": "1310.6582", "contents": "Title: Dark matter and U(1)' symmetry for the right-handed neutrinos Abstract: We consider a U(1)' gauge symmetry acting on three generations of\nright-handed neutrinos. The U(1)' symmetry is broken at the TeV scale and its\nremnant discrete symmetry makes one of the right-handed neutrinos stable. As a\nnatural consequence of the anomaly cancellation, the neutrino mass matrix\nconsists of a combination of Type I (TeV scale) seesaw and radiative\ncorrection. The stable right-handed neutrino communicates with the Standard\nModel via s-channel exchange of the Higgs field and the U(1)' gauge boson, so\nthat the observed relic density for dark matter is obtained in a wide range of\nthe parameter space. The experimental signatures in collider and other\nexperiments are briefly discussed. \n\n"}
{"id": "1310.8107", "contents": "Title: Scalable Frames and Convex Geometry Abstract: The recently introduced and characterized scalable frames can be considered\nas those frames which allow for perfect preconditioning in the sense that the\nframe vectors can be rescaled to yield a tight frame. In this paper we define\n$m$-scalability, a refinement of scalability based on the number of non-zero\nweights used in the rescaling process, and study the connection between this\nnotion and elements from convex geometry. Finally, we provide results on the\ntopology of scalable frames. In particular, we prove that the set of scalable\nframes with \"small\" redundancy is nowhere dense in the set of frames. \n\n"}
{"id": "1310.8219", "contents": "Title: Comparative model accuracy of a data-fitted generalized Aw-Rascle-Zhang\n  model Abstract: The Aw-Rascle-Zhang (ARZ) model can be interpreted as a generalization of the\nLighthill-Whitham-Richards (LWR) model, possessing a family of fundamental\ndiagram curves, each of which represents a class of drivers with a different\nempty road velocity. A weakness of this approach is that different drivers\npossess vastly different densities at which traffic flow stagnates. This\ndrawback can be overcome by modifying the pressure relation in the ARZ model,\nleading to the generalized Aw-Rascle-Zhang (GARZ) model. We present an approach\nto determine the parameter functions of the GARZ model from fundamental diagram\nmeasurement data. The predictive accuracy of the resulting data-fitted GARZ\nmodel is compared to other traffic models by means of a three-detector test\nsetup, employing two types of data: vehicle trajectory data, and sensor data.\nThis work also considers the extension of the ARZ and the GARZ models to models\nwith a relaxation term, and conducts an investigation of the optimal relaxation\ntime. \n\n"}
{"id": "1311.2777", "contents": "Title: Sensitivity of the DANSS detector to short range neutrino oscillations Abstract: DANSS is a highly segmented 1m^3 plastic scintillator detector. It's 2500\nscintillator strips have a Gd loaded reflective cover. Light is collected with\n3 wave length shifting fibers per strip and read out with 50 PMTs and 2500\nSiPMs. The DANSS will be installed under the industrial 3 GW reactor of the\nKalinin Nuclear Power Plant at distances varying from 9.7m to 12.2m from the\nreactor core. Tests of the detector prototype DANSSino demonstrated that in\nspite of a small size (20x20x100 cm^3) it is quite sensitive to reactor\nantineutrinos, detecting about 70 Inverse Beta Decay events per day with the\nsignal-to-background ratio of about unity. The prototype tests have\ndemonstrated feasibility to reach the design performance of the DANSS detector.\nThe DANSS experiment will detect about 10 thousand antineutrino events per day\nwith a background below ~1%. Detector will be calibrated every day and its\nposition will be changed frequently to reduce systematic errors. These features\nwill provide a high sensitivity to reactor antineutrino oscillations to sterile\nneutrinos, suggested recently to explain a so-called \"reactor anomaly\". Data\ntaking will start already next year. \n\n"}
{"id": "1311.4511", "contents": "Title: A light readout system for gas TPCs Abstract: A novel light detection scheme has been tested for use in medium-pressure gas\nTPCs, in view of rare events searches in low energy particle physics. It has\nthe advantage of minimal interference with the ionization collection system,\nused for track imaging. It provides an absolute time reference, which allows an\nabsolute determination of the Z coordinate of events, along the direction of\nthe drift field. This makes possible a fiducial cut along the Z-axis, allowing\nto reduce the background from the ends of the drift volume. \n\n"}
{"id": "1311.5958", "contents": "Title: A New Method for Measuring Coherent Elastic Neutrino Nucleus Scattering\n  at an Off-Axis High-Energy Neutrino Beam Target Abstract: We present a new experimental method for measuring the process of Coherent\nElastic Neutrino Nucleus Scattering (CENNS). This method uses a detector\nsituated transverse to a high energy neutrino beam production target. This\ndetector would be sensitive to the low energy neutrinos arising from pion\ndecays-at-rest in the target. We discuss the physics motivation for making this\nmeasurement and outline the predicted backgrounds and sensitivities using this\napproach. We report a measurement of neutron backgrounds as found in an\noff-axis surface location of the Fermilab Booster Neutrino Beam (BNB) target.\nThe results indicate that the Fermilab BNB target is a favorable location for a\nCENNS experiment. \n\n"}
{"id": "1311.6465", "contents": "Title: A New Method for the Spin Determination of Dark Matter Abstract: We construct a new kinematical variable that is able to fully reconstruct the\nabsolute value, and partially reconstruct the sign, of the angular distribution\nin the center of momentum system of a decaying particle in certain cases where\nthe center of momentum system is only known up to a two-fold ambiguity. After\nmaking contact with Drell-Yan production at the Large Hadron Collider, we apply\nthis method to the pair-production of dark matter in association with two\ncharged leptons at the International Linear Collider and show that for a small\nintermediate width, perfect agreement is found with the true angular\ndistribution in the absence of initial state radiation. In the presence of\ninitial state radiation, we find that the modification to the angular\ndistributions is small for most angles and that the different spin combinations\nshould still be distinguishable. This enables us to determine the spin of the\nmother particle and the dark matter particle in certain cases. \n\n"}
{"id": "1312.0484", "contents": "Title: Adaptive Crouzeix-Raviart Boundary Element Method Abstract: For the non-conforming Crouzeix-Raviart boundary elements from [Heuer, Sayas:\nCrouzeix-Raviart boundary elements, Numer. Math. 112, 2009], we develop and\nanalyze a posteriori error estimators based on the $h-h/2$ methodology. We\ndiscuss the optimal rate of convergence for uniform mesh refinement, and\npresent a numerical experiment with singular data where our adaptive algorithm\nrecovers the optimal rate while uniform mesh refinement is sub-optimal. We also\ndiscuss the case of reduced regularity by standard geometric singularities to\nconjecture that, in this situation, non-uniformly refined meshes are not\nsuperior to quasi-uniform meshes for Crouzeix-Raviart boundary elements. \n\n"}
{"id": "1312.1162", "contents": "Title: Interacting two-component fluid models with varying EoS parameter Abstract: In this paper, we consider Universe filled with two-component fluid. We study\ntwo different models. In the first model we assume barotropic fluid with the\nlinear equation of state as the first component of total fluid. In the second\nmodel we assume Van der Waals gas as the first component of total fluid. In\nboth models, the second component assumed generalized ghost dark energy. We\nconsider also interaction between component and discuss, numerically,\ncosmological quantities for two different parametrization of EoS which varies\nwith time. We consider this as a toy model of our Universe. We fix parameters\nof the model by using generalized second law of thermodynamics. Comparing our\nresults with some observational data suggests interacting barotropic fluid with\nEoS parameter $\\omega(t)=\\omega_{0}\\cos(tH)+\\omega_{1}t\\frac{\\dot{H}}{H}$ and\ngeneralized ghost dark energy as an appropriate model to describe our Universe. \n\n"}
{"id": "1312.4820", "contents": "Title: Wave propagation in a fractional viscoelastic Andrade medium: diffusive\n  approximation and numerical modeling Abstract: This study focuses on the numerical modeling of wave propagation in\nfractionally-dissipative media. These viscoelastic models are such that the\nattenuation is frequency dependent and follows a power law with non-integer\nexponent. As a prototypical example, the Andrade model is chosen for its\nsimplicity and its satisfactory fits of experimental flow laws in rocks and\nmetals. The corresponding constitutive equation features a fractional\nderivative in time, a non-local term that can be expressed as a convolution\nproduct which direct implementation bears substantial memory cost. To\ncircumvent this limitation, a diffusive representation approach is deployed,\nreplacing the convolution product by an integral of a function satisfying a\nlocal time-domain ordinary differential equation. An associated quadrature\nformula yields a local-in-time system of partial differential equations, which\nis then proven to be well-posed. The properties of the resulting model are also\ncompared to those of the original Andrade model. The quadrature scheme\nassociated with the diffusive approximation, and constructed either from a\nclassical polynomial approach or from a constrained optimization method, is\ninvestigated to finally highlight the benefits of using the latter approach.\nWave propagation simulations in homogeneous domains are performed within a\nsplit formulation framework that yields an optimal stability condition and\nwhich features a joint fourth-order time-marching scheme coupled with an exact\nintegration step. A set of numerical experiments is presented to assess the\nefficiency of the diffusive approximation method for such wave propagation\nproblems. \n\n"}
{"id": "1312.5523", "contents": "Title: A Data-Driven Edge-Preserving D-bar Method for Electrical Impedance\n  Tomography Abstract: In Electrical Impedance Tomography (EIT), the internal conductivity of a body\nis recovered via current and voltage measurements taken at its surface. The\nreconstruction task is a highly ill-posed nonlinear inverse problem, which is\nvery sensitive to noise, and requires the use of regularized solution methods,\nof which D-bar is the only proven method. The resulting EIT images have low\nspatial resolution due to smoothing caused by low-pass filtered regularization.\nIn many applications, such as medical imaging, it is known \\emph{a priori} that\nthe target contains sharp features such as organ boundaries, as well as\napproximate ranges for realistic conductivity values. In this paper, we use\nthis information in a new edge-preserving EIT algorithm, based on the original\nD-bar method coupled with a deblurring flow stopped at a minimal data\ndiscrepancy. The method makes heavy use of a novel data fidelity term based on\nthe so-called {\\em CGO sinogram}. This nonlinear data step provides superior\nrobustness over traditional EIT data formats such as current-to-voltage\nmatrices or Dirichlet-to-Neumann operators, for commonly used current patterns. \n\n"}
{"id": "1312.5774", "contents": "Title: Vertex-Detector R&D for CLIC Abstract: A detector concept based on hybrid planar pixel-detector technology is under\ndevelopment for the CLIC vertex detector. It comprises fast, low-power and\nsmall-pitch readout ASICs implemented in 65 nm CMOS technology (CLICpix)\ncoupled to ultra-thin sensors via low-mass interconnects. The power dissipation\nof the readout chips is reduced by means of power pulsing, allowing for a\ncooling system based on forced gas flow. In this paper the CLIC vertex-detector\nrequirements are reviewed and the current status of R&D on sensors, readout and\ndetector integration is presented. \n\n"}
{"id": "1312.5850", "contents": "Title: The $b$-adic tent transformation for quasi-Monte Carlo integration using\n  digital nets Abstract: In this paper we investigate quasi-Monte Carlo (QMC) integration using\ndigital nets over $\\mathbb{Z}_b$ in reproducing kernel Hilbert spaces. The tent\ntransformation, or the baker's transformation, was originally used for lattice\nrules by Hickernell (2002) to achieve higher order convergence of the\nintegration error for smooth non-periodic integrands, and later, has been\nsuccessfully applied to digital nets over $\\mathbb{Z}_2$ by Cristea et al.\n(2007) and Goda (2014). The aim of this paper is to generalize the latter two\nresults to digital nets over $\\mathbb{Z}_b$ for an arbitrary prime $b$. For\nthis purpose, we introduce the {\\em $b$-adic tent transformation} for an\narbitrary positive integer $b$ greater than 1, which is a generalization of the\noriginal (dyadic) tent transformation. Further, again for an arbitrary positive\ninteger $b$ greater than 1, we analyze the mean square worst-case error of QMC\nrules using digital nets over $\\mathbb{Z}_b$ which are randomly digitally\nshifted and then folded using the $b$-adic tent transformation in reproducing\nkernel Hilbert spaces. Using this result, for a prime $b$, we prove the\nexistence of good higher order polynomial lattice rules over $\\mathbb{Z}_b$\namong the smaller number of candidates as compared to the result by Dick and\nPillichshammer (2007), which achieve almost the optimal convergence rate of the\nmean square worst-case error in unanchored Sobolev spaces of smoothness of\narbitrary high order. \n\n"}
{"id": "1312.6092", "contents": "Title: A Simple and Efficient Preconditioning Scheme for Heaviside Enriched\n  XFEM Abstract: The eXtended Finite Element Method (XFEM) is an approach for solving problems\nwith non-smooth solutions. In the XFEM, the approximate solution is locally\nenriched to capture discontinuities without requiring a mesh which conforms to\nthe geometric features. One drawback of the XFEM is that an ill-conditioned\nsystem of equations results when the ratio of volumes on either side of the\ninterface in an element is small. In this paper, to avoid this\nill-conditioning, a simple and efficient scheme based on a geometric\npreconditioner and constraining degrees of freedom to zero for small\nintersections is proposed. This geometric preconditioner is computed from the\nnodal basis functions, and therefore may be constructed prior to building the\nsystem of equations. This feature and the low-cost of constructing the\npreconditioning matrix makes it well suited for nonlinear problems with fixed\nand moving interfaces. \n\n"}
{"id": "1401.0616", "contents": "Title: Compatible finite element methods for numerical weather prediction Abstract: This article takes the form of a tutorial on the use of a particular class of\nmixed finite element methods, which can be thought of as the finite element\nextension of the C-grid staggered finite difference method. The class is often\nreferred to as compatible finite elements, mimetic finite elements, discrete\ndifferential forms or finite element exterior calculus. We provide an\nelementary introduction in the case of the one-dimensional wave equation,\nbefore summarising recent results in applications to the rotating shallow water\nequations on the sphere, before taking an outlook towards applications in\nthree-dimensional compressible dynamical cores. \n\n"}
{"id": "1401.3739", "contents": "Title: On the Effect of Nuclear Response Functions in Dark Matter Direct\n  Detection Abstract: We examine the effect of nuclear response functions, as laid out in\n[Fitzpatrick et al, arXiv:1203.3542], on dark matter (DM) direct detection in\nthe context of well-motivated UV completions, including electric and magnetic\ndipoles, anapole, spin-orbit, and pseudoscalar-mediated DM. Together, these\nencompass five of the six nuclear responses extracted from the non-relativistic\neffective theory of [Fitzpatrick et al, arXiv:1203.3542] (with the sixth\ndifficult to UV complete), with two of the six combinations corresponding to\nstandard spin-independent and -dependent responses. For constraints from\nexisting direct detection experiments, we find that only the COUPP constraint,\ndue to its heavy iodine target with large angular momentum and an unpaired\nspin, and its large energy range sensitivity, is substantially modified by the\nnew responses compared to what would be inferred using the standard form\nfactors to model the energy dependence of the response. For heavy targets such\nas xenon and germanium, the behavior of the new nuclear responses as recoil\nenergy increases can be substantially different than that of the standard\nresponses, but this has almost no impact on the constraints derived from\nexperiments such as LUX, XENON100 and CDMS since the maximum nuclear recoil\nenergy detected in these experiments is relatively low. We simulate mock data\nfor 80 and 250 GeV DM candidates utilizing the new nuclear responses to\nhighlight how they might affect a putative signal, and find the new responses\nare most important for momentum-suppressed interactions such as the magnetic\ndipole or pseudoscalar-mediated interaction when the target is relatively heavy\n(such as xenon and iodine). \n\n"}
{"id": "1401.5886", "contents": "Title: Novel Heavy Quark Phenomena in QCD Abstract: Heavy quarks provide a new dimension to QCD, allowing tests of fundamental\ntheory, the nature of color confinement, and the production of new exotic\nmultiquark states. I also discuss novel explanations for several apparently\nanomalous experimental results, such as the large $t \\bar t$ forward-backward\nasymmetry observed in $p \\bar p$ colisions at the Tevatron, the large rates for\n$\\gamma$ or $Z$ plus high-$p_T$ charm jets observed at the Tevatron, the strong\nnuclear absorption of the $J/\\psi$ observed in $pA$ collisions at the LHC, as\nwell as fixed target experiments at high $x_F$. Precision measurements of the\nheavy quark distribution in hadrons at high $x$ are needed since intrinsic\nheavy quarks can play an important role in high $x$ phenomenology as well as\npredicting a new mechanism for high-$x_F$ Higgs production. The role of\nmulti-parton interactions, such as di-gluon initiated subprocesses for forward\nquarkonium hadroproduction, is discussed. I also briefly discuss a new approach\nto the QCD confinement potential and the origin of the QCD mass scale based on\nAdS/QCD, light-front holography and a unique extension of conformal theory. The\nrenormalization scale ambiguity can be eliminated at finite orders in pQCD\nusing the scheme-independent PMC procedure, thus increasing the precision of\npredictions and eliminating an unnecessary source of theoretical systematic\nerror. \n\n"}
{"id": "1401.6232", "contents": "Title: Discrete maximum principle for the weak Galerkin method for anisotropic\n  diffusion problems Abstract: A weak Galerkin discretization of the boundary value problem of a general\nanisotropic diffusion problem is studied for preservation of the maximum\nprinciple. It is shown that the direct application of the $M$-matrix theory to\nthe stiffness matrix of the weak Galerkin discretization leads to a strong mesh\ncondition requiring all of the mesh dihedral angles to be strictly acute (a\nconstant-order away from 90 degrees). To avoid this difficulty, a reduced\nsystem is considered and shown to satisfy the discrete maximum principle under\nweaker mesh conditions. The discrete maximum principle is then established for\nthe full weak Galerkin approximation using the relations between the degrees of\nfreedom located on elements and edges. Sufficient mesh conditions for both\npiecewise constant and general anisotropic diffusion matrices are obtained.\nThese conditions provide a guideline for practical mesh generation for\npreservation of the maximum principle. Numerical examples are presented. \n\n"}
{"id": "1401.6269", "contents": "Title: Hadronic production of $\\Xi_{cc}$ at a fixed-target experiment at the\n  LHC Abstract: In the paper, we present a detailed discussion on the $\\Xi_{cc}$ production\nat a fixed target experiment at the LHC (After@LHC). The doubly charmed baryon\n$\\Xi_{cc}$ is produced via the channel, ${\\rm Proton} + {\\rm\nProton}\\to\\Xi_{cc}+X$. In estimating its hadroproduction, we discuss three\ndominant subprocesses, e.g. $g+g\\to \\Xi_{cc} +\\bar{c} +\\bar{c}$, $g+c\\to\n\\Xi_{cc}+\\bar{c}$ and $c+c\\to \\Xi_{cc}+g$. During the production, it shall\nfirst generate a binding diquark and then form the $\\Xi_{cc}$ baryon by\ngrabbing soft light-quarks or gluons. We observe that both the two diquark\nconfigurations $(cc)[^3S_1]_{\\bf\\bar 3}$ and $(cc)[^1S_0]_{\\bf 6}$ can have\nsizable contributions to the $\\Xi_{cc}$ production. Large number of $\\Xi_{cc}$\nevents can be generated at the After@LHC, whose total production cross section\nis larger than that of the SELEX experiment by about thirty-five times. It may\nalso possible to study the properties of $\\Xi_{bc}$ at the After@LHC. More\nspecifically, we shall have about $8.3 \\times 10^6$ $\\Xi_{cc}$ events/year and\n$1.8 \\times 10^4$ $\\Xi_{bc}$ events/year when its integrated luminosity\napproaches to $2$ fb$^{-1}$/year. Thus, in addition to SELEX and LHC, the\nAfter@LHC shall provide another useful platform for studying the baryon\nproperties. \n\n"}
{"id": "1401.6625", "contents": "Title: Hadron Multiplicities in p+p and p+Pb Collisions Abstract: Experiments at the Large Hadron Collider (LHC) have measured multiplicity\ndistributions in p+p and p+Pb collisions at a new domain of collision energy.\nBased on considering an energy-dependent broadening of the nucleon's density\ndistribution, charged hadron multiplicities are studied with the\nphenomenological saturation model and the evolution equation dependent\nsaturation model. By assuming the saturation scale have a small dependence on\nthe 3-dimensional root mean square (rms) radius at different energy, the\ntheoretical results are in good agreement with the experimental data from CMS\nand ALICE collaboration. Then, the predictive results in p+p collisions at\n$\\sqrt{s}=$ 14 TeV of the LHC are also given. \n\n"}
{"id": "1402.0110", "contents": "Title: A partitioned scheme for fluid-composite structure interaction problems Abstract: We present a loosely-coupled partitioned scheme for a benchmark problem in\nfluid-composite structure interaction. The benchmark problem proposed here\nconsists of an incompressible, viscous fluid interacting with a composite\nstructure that consists of two layers: a thin elastic layer which is in contact\nwith the fluid, and a thick elastic layer which sits on top of the thin layer.\nThe motivation comes from fluid-structure interaction (FSI) in hemodyam- ics.\nThe equations of linear elasticity are used to model the thick structural\nlayer, while the Koiter member/shell equations are used to model the thin\nstructural layer which serves as fluid-structure interface with mass. An effi-\ncient, modular, operator-splitting scheme is proposed to simulate solutions to\nthe coupled, nonlinear FSI problem. The operator splitting scheme sepa- rates\nthe elastodynamics structure problem, from a fluid problem in which the thin\nstructure inertia is included as a Robin-type boundary condition to achieve\nunconditional stability, without requiring any sub-iterations within\ntime-steps. An energy estimate associated with unconditional stability is\nderived for the fully nonlinear FSI problem defined on moving domains. Two\ninstructive numerical examples are presented to test the performance of the\nscheme, where it is shown numerically, that the scheme is at least first-order\naccurate in time. The second example reveals a new phenomenon in FSI problems:\nthe presence of a thin fluid-structure interface with mass regularizes\nsolutions to the full FSI problem. \n\n"}
{"id": "1402.2052", "contents": "Title: Flavor structure in D-brane models: Majorana neutrino masses Abstract: We study the flavor structure in intersecting D-brane models. We study\nanomalies of the discrete flavor symmetries. We analyze the Majorana neutrino\nmasses, which can be generated by D-brane instanton effects. It is found that a\ncertain pattern of mass matrix is obtained and the cyclic permutation symmetry\nremains unbroken. As a result, trimaximal mixing matrix can be realized if\nDirac neutrino mass and charged lepton mass matrices are diagonal. \n\n"}
{"id": "1402.5822", "contents": "Title: Conformal symmetry of the Lange-Neubert evolution equation Abstract: The Lange-Neubert evolution equation describes the scale dependence of the\nwave function of a meson built of an infinitely heavy quark and light antiquark\nat light-like separations, which is the hydrogen atom problem of QCD. It has\nnumerous applications to the studies of B-meson decays. We show that the kernel\nof this equation can be written in a remarkably compact form, as a logarithm of\nthe generator of special conformal transformation in the light-ray direction.\nThis representation allows one to study solutions of this equation in a very\nsimple and mathematically consistent manner. Generalizing this result, we show\nthat all heavy-light evolution kernels that appear in the renormalization of\nhigher-twist B-meson distribution amplitudes can be written in the same form. \n\n"}
{"id": "1403.1404", "contents": "Title: DAMA/LIBRA results and perspectives, Bled 2013 Abstract: The DAMA/LIBRA experiment is composed by about 250 kg of highly radiopure\nNaI(Tl). It is in operation at the underground Gran Sasso National Laboratory\nof the INFN. The main aim of the experiment is to investigate the Dark Matter\n(DM) particles in the Galactic halo by exploiting the model independent DM\nannual modulation signature. The DAMA/LIBRA experiment and the former DAMA/NaI\n(the first generation experiment having an exposed mass of about 100 kg) have\nreleased results corresponding to a total exposure of 1.17 ton $\\times$ yr over\n13 annual cycles; they have provided a model independent evidence of the\npresence of DM particles in the galactic halo at 8.9 $\\sigma$ C.L.. The results\nof a further annual cycle, concluding the DAMA/LIBRA--phase1, have been\nreleased after this Workshop and are not included here. In the fall 2010 an\nimportant upgrade of the experiment have been performed. All the PMTs of the\nNaI(Tl) detectors have been replaced with new ones having higher quantum\nefficiency with the aim to decrease the software energy threshold considered in\nthe data analysis. The perspectives of the running DAMA/LIBRA--phase2 will be\nshortly summarized. \n\n"}
{"id": "1403.2286", "contents": "Title: Alignment of the CMS tracker with LHC and cosmic ray data Abstract: The central component of the CMS detector is the largest silicon tracker ever\nbuilt. The precise alignment of this complex device is a formidable challenge,\nand only achievable with a significant extension of the technologies routinely\nused for tracking detectors in the past. This article describes the full-scale\nalignment procedure as it is used during LHC operations. Among the specific\nfeatures of the method are the simultaneous determination of up to 200,000\nalignment parameters with tracks, the measurement of individual sensor\ncurvature parameters, the control of systematic misalignment effects, and the\nimplementation of the whole procedure in a multi-processor environment for high\nexecution speed. Overall, the achieved statistical accuracy on the module\nalignment is found to be significantly better than 10 micrometers. \n\n"}
{"id": "1403.3127", "contents": "Title: An asymptotic relationship between coupling methods for stochastically\n  modeled population processes Abstract: This paper is concerned with elucidating a relationship between two common\ncoupling methods for the continuous time Markov chain models utilized in the\ncell biology literature. The couplings considered here are primarily used in a\ncomputational framework by providing reductions in variance for different Monte\nCarlo estimators, thereby allowing for significantly more accurate results for\na fixed amount of computational time. Common applications of the couplings\ninclude the estimation of parametric sensitivities via finite difference\nmethods and the estimation of expectations via multi-level Monte Carlo\nalgorithms. While a number of coupling strategies have been proposed for the\nmodels considered here, and a number of articles have experimentally compared\nthe different strategies, to date there has been no mathematical analysis\ndescribing the connections between them. Such analyses are critical in order to\ndetermine the best use for each. In the current paper, we show a connection\nbetween the common reaction path (CRP) method and the split coupling (SC)\nmethod, which is termed coupled finite differences (CFD) in the parametric\nsensitivities literature. In particular, we show that the two couplings are\nboth limits of a third coupling strategy we call the \"local-CRP\" coupling, with\nthe split coupling method arising as a key parameter goes to infinity, and the\ncommon reaction path coupling arising as the same parameter goes to zero. The\nanalysis helps explain why the split coupling method often provides a lower\nvariance than does the common reaction path method, a fact previously shown\nexperimentally. \n\n"}
{"id": "1403.4680", "contents": "Title: Likelihood-informed dimension reduction for nonlinear inverse problems Abstract: The intrinsic dimensionality of an inverse problem is affected by prior\ninformation, the accuracy and number of observations, and the smoothing\nproperties of the forward operator. From a Bayesian perspective, changes from\nthe prior to the posterior may, in many problems, be confined to a relatively\nlow-dimensional subspace of the parameter space. We present a dimension\nreduction approach that defines and identifies such a subspace, called the\n\"likelihood-informed subspace\" (LIS), by characterizing the relative influences\nof the prior and the likelihood over the support of the posterior distribution.\nThis identification enables new and more efficient computational methods for\nBayesian inference with nonlinear forward models and Gaussian priors. In\nparticular, we approximate the posterior distribution as the product of a\nlower-dimensional posterior defined on the LIS and the prior distribution\nmarginalized onto the complementary subspace. Markov chain Monte Carlo sampling\ncan then proceed in lower dimensions, with significant gains in computational\nefficiency. We also introduce a Rao-Blackwellization strategy that\nde-randomizes Monte Carlo estimates of posterior expectations for additional\nvariance reduction. We demonstrate the efficiency of our methods using two\nnumerical examples: inference of permeability in a groundwater system governed\nby an elliptic PDE, and an atmospheric remote sensing problem based on Global\nOzone Monitoring System (GOMOS) observations. \n\n"}
{"id": "1403.6810", "contents": "Title: Dark Radiation predictions from general Large Volume Scenarios Abstract: Recent observations constrain the amount of Dark Radiation ($\\Delta N_{\\rm\neff}$) and may even hint towards a non-zero value of $\\Delta N_{\\rm eff}$. It\nis by now well-known that this puts stringent constraints on the sequestered\nLarge Volume Scenario (LVS), i.e. on LVS realisations with the Standard Model\nat a singularity. We go beyond this setting by considering LVS models where SM\nfields are realised on 7-branes in the geometric regime. As we argue, this\nnaturally goes together with high-scale supersymmetry. The abundance of Dark\nRadiation is determined by the competition between the decay of the lightest\nmodulus to axions, to the SM Higgs and to gauge fields. The latter decay\nchannel avoids the most stringent constraints of the sequestered setting.\nNevertheless, a rather robust prediction for a substantial amount of Dark\nRadiation can be made. This applies both to cases where the SM 4-cycles are\nstabilised by D-terms and are small \"by accident\" as well as to fibred models\nwith the small cycles stabilised by loops. Furthermore, we analyse a closely\nrelated setting where the SM lives at a singularity but couples to the volume\nmodulus through flavour branes. We conclude that some of the most natural LVS\nsettings with natural values of model parameters lead to Dark Radiation\npredictions just below the present observational limits. Barring a discovery,\nrather modest improvements of present Dark Radiation bounds can rule out many\nof these most simple and generic variants of the LVS. \n\n"}
{"id": "1403.7543", "contents": "Title: A sparse Kaczmarz solver and a linearized Bregman method for online\n  compressed sensing Abstract: An algorithmic framework to compute sparse or minimal-TV solutions of linear\nsystems is proposed. The framework includes both the Kaczmarz method and the\nlinearized Bregman method as special cases and also several new methods such as\na sparse Kaczmarz solver. The algorithmic framework has a variety of\napplications and is especially useful for problems in which the linear\nmeasurements are slow and expensive to obtain. We present examples for online\ncompressed sensing, TV tomographic reconstruction and radio interferometry. \n\n"}
{"id": "1404.2601", "contents": "Title: Inflation and String Theory Abstract: We review cosmological inflation and its realization in quantum field theory\nand in string theory. This material is a portion of a book, also entitled\n\"Inflation and String Theory\", to be published by Cambridge University Press. \n\n"}
{"id": "1404.2877", "contents": "Title: Quantum process tomography of unitary and near-unitary maps Abstract: We study quantum process tomography given the prior information that the map\nis a unitary or close to a unitary process. We show that a unitary map on a\n$d$-level system is completely characterized by a minimal set of $d^2{+}d$\nelements associated with a collection of POVMs, in contrast to the $d^4{-}d^2$\nelements required for a general completely positive trace-preserving map. To\nachieve this lower bound, one must probe the map with a particular set of $d$\npure states. We further compare the performance of different compressed sensing\nalgorithms used to reconstruct a near-unitary process from such data. We find\nthat when we have accurate prior information, an appropriate compressed sensing\nmethod reduces the required data needed for high-fidelity estimation, and\ndifferent estimators applied to the same data are sensitive to different types\nof noise. Compressed sensing techniques can therefore be used both as\nindicators of error models and to validate the use of the prior assumptions. \n\n"}
{"id": "1404.2925", "contents": "Title: Focal-plane detector system for the KATRIN experiment Abstract: The focal-plane detector system for the KArlsruhe TRItium Neutrino (KATRIN)\nexperiment consists of a multi-pixel silicon p-i-n-diode array, custom readout\nelectronics, two superconducting solenoid magnets, an ultra high-vacuum system,\na high-vacuum system, calibration and monitoring devices, a scintillating veto,\nand a custom data-acquisition system. It is designed to detect the low-energy\nelectrons selected by the KATRIN main spectrometer. We describe the system and\nsummarize its performance after its final installation. \n\n"}
{"id": "1404.4535", "contents": "Title: Physical limitations to the spatial resolution of solid-state detectors Abstract: In this paper we explore the effect of $\\delta$-ray emission, fluctuations in\nth e signal deposition on the detection of charged particles in silicon-based\ndetec tors. We show that these two effects ultimately limit the resolution that\ncan be achieved by interpolation of the signal in finely segmented\nposition-sensitive solid-state devices. \n\n"}
{"id": "1404.5087", "contents": "Title: A Generalized Multiscale Finite Element Method for the Brinkman Equation Abstract: In this paper we consider the numerical upscaling of the Brinkman equation in\nthe presence of high-contrast permeability fields. We develop and analyze a\nrobust and efficient Generalized Multiscale Finite Element Method (GMsFEM) for\nthe Brinkman model. In the fine grid, we use mixed finite element method with\nthe velocity and pressure being continuous piecewise quadratic and piecewise\nconstant finite element spaces, respectively. Using the GMsFEM framework we\nconstruct suitable coarse-scale spaces for the velocity and pressure that yield\na robust mixed GMsFEM. We develop a novel approach to construct a coarse\napproximation for the velocity snapshot space and a robust small offline space\nfor the velocity space. The stability of the mixed GMsFEM and a priori error\nestimates are derived. A variety of two-dimensional numerical examples are\npresented to illustrate the effectiveness of the algorithm. \n\n"}
{"id": "1404.5811", "contents": "Title: Construction and measurements of a vacuum-swing-adsorption\n  radon-mitigation system Abstract: Long-lived alpha and beta emitters in the $^{222}$Rn decay chain on (and\nnear) detector surfaces may be the limiting background in many experiments\nattempting to detect dark matter or neutrinoless double-beta decay, and in\nscreening detectors. In order to reduce backgrounds from radon-daughter\nplate-out onto the wires of the BetaCage during its assembly, an\nultra-low-radon cleanroom is being commissioned at Syracuse University using a\nvacuum-swing-adsorption radon-mitigation system. The radon filter shows\n~20$\\times$ reduction at its output, from 7.47$\\pm$0.56 to 0.37$\\pm$0.12\nBq/m$^3$, and the cleanroom radon activity meets project requirements, with a\nlowest achieved value consistent with that of the filter, and levels\nconsistently < 2 Bq/m$^3$. \n\n"}
{"id": "1404.7701", "contents": "Title: Constraining the strangeness content of the nucleon by measuring the\n  $\\phi$ meson mass shift in nuclear matter Abstract: The behavior of the $\\phi$ meson at finite density is studied, making use of\na QCD sum rule approach in combination with the maximum entropy method. It is\ndemonstrated that a possible mass shift of the $\\phi$ in nuclear matter is\nstrongly correlated to the strangeness content of the nucleon, which is\nproportional to the strange sigma term, $\\sigma_{sN} = m_s \\langle N |\n\\overline{s}s | N \\rangle$. Our results furthermore show that, depending on the\nvalue of $\\sigma_{sN}$, the $\\phi$ meson could receive both a positive or\nnegative mass shift at nuclear matter density. We find that these results\ndepend only weakly on potential modifications of the width of the $\\phi$ meson\npeak and on assumptions made on the behavior of four-quark condensates at\nfinite density. To check the stability of our findings, we take into account\nseveral higher order corrections to the operator product expansion, including\n$\\alpha_s$-corrections, terms of higher order in the strange quark mass and\nterms of higher twist that have not been considered in earlier works. \n\n"}
{"id": "1405.0069", "contents": "Title: Universal Bilinear Form of Quark and Lepton Mass Matrices Abstract: In the so-called ``yukawaon\" model, the (effective) Yukawa coupling constants\n$Y_f^{eff}$ are given by vacuum expectation values (VEVs) of scalars $Y_f$\n(yukawaons) with $3\\times 3$ components. In the present model, all of the VEV\nmatrices $\\langle Y_f \\rangle$ are given by a bilinear form of VEVs of flavons\n$\\Phi_f$, $\\langle Y_f \\rangle_i^{\\ j} = k_f \\langle \\Phi_f\\rangle_{ik} \\langle\n\\bar{\\Phi}_f\\rangle^{kj}$, where $\\Phi_f$ is assigned to ${\\bf 6}$ of U(3)\nfamily symmetry. As input parameters with family-number dependent values, we\nuse only charged lepton mass values. Under this formulation, we can give\nreasonable values of quark and lepton masses and their mixings. A $CP$\nviolating phase $\\delta_{CP}^\\ell=26^\\circ$ in the lepton sector is predicted.\nThe effective Majorana neutrino mass is also predicted. \n\n"}
{"id": "1405.0260", "contents": "Title: A Parallel Orbital-Updating Approach for Electronic Structure\n  Calculations Abstract: In this paper, we propose an orbital iteration based parallel approach for\nelectronic structure calculations. This approach is based on our understanding\nof the single-particle equations of independent particles that move in an\neffective potential. With this new approach, the solution of the\nsingle-particle equation is reduced to some solutions of independent linear\nalgebraic systems and a small scale algebraic problem. It is demonstrated by\nour numerical experiments that this new approach is quite efficient for\nfull-potential calculations for a class of molecular systems. \n\n"}
{"id": "1405.2096", "contents": "Title: Optimization on the Hierarchical Tucker manifold - applications to\n  tensor completion Abstract: In this work, we develop an optimization framework for problems whose\nsolutions are well-approximated by Hierarchical Tucker (HT) tensors, an\nefficient structured tensor format based on recursive subspace factorizations.\nBy exploiting the smooth manifold structure of these tensors, we construct\nstandard optimization algorithms such as Steepest Descent and Conjugate\nGradient for completing tensors from missing entries. Our algorithmic framework\nis fast and scalable to large problem sizes as we do not require SVDs on the\nambient tensor space, as required by other methods. Moreover, we exploit the\nstructure of the Gramian matrices associated with the HT format to regularize\nour problem, reducing overfitting for high subsampling ratios. We also find\nthat the organization of the tensor can have a major impact on completion from\nrealistic seismic acquisition geometries. These samplings are far from\nidealized randomized samplings that are usually considered in the literature\nbut are realizable in practical scenarios. Using these algorithms, we\nsuccessfully interpolate large-scale seismic data sets and demonstrate the\ncompetitive computational scaling of our algorithms as the problem sizes grow. \n\n"}
{"id": "1405.4456", "contents": "Title: Extraction Method of Fine Granular Performance from Scintillator Strip\n  Electromagnetic Calorimeter Abstract: We describe an algorithm which has been developed to extract fine granularity\ninformation from an electromagnetic calorimeter with strip-based readout. Such\na calorimeter, based on scintillator strips, is being developed to apply\nparticle flow reconstruction to future experiments in high energy physics.\nTests of this algorithm in full detector simulations, using strips of size 45 x\n5 mm^2 show that the performance is close to that of a calorimeter with true 5\nx 5 mm^2 readout granularity. The performance can be further improved by the\nuse of 10 x 10 mm^2 tile- shaped layers interspersed between strip layers. \n\n"}
{"id": "1405.4641", "contents": "Title: Superconvergent Two-grid Methods For Elliptic Eigenvalue Problems Abstract: Some numerical algorithms for elliptic eigenvalue problems are proposed,\nanalyzed, and numerically tested. The methods combine advantages of the\ntwo-grid algorithm, two-space method, the shifted inverse power method, and the\npolynomial preserving recovery technique . Our new algorithms compare favorably\nwith some existing methods and enjoy superconvergence property. \n\n"}
{"id": "1405.7808", "contents": "Title: Performance of the LHCb Vertex Locator Abstract: The Vertex Locator (VELO) is a silicon microstrip detector that surrounds the\nproton-proton interaction region in the LHCb experiment. The performance of the\ndetector during the first years of its physics operation is reviewed. The\nsystem is operated in vacuum, uses a bi-phase CO2 cooling system, and the\nsensors are moved to 7 mm from the LHC beam for physics data taking. The\nperformance and stability of these characteristic features of the detector are\ndescribed, and details of the material budget are given. The calibration of the\ntiming and the data processing algorithms that are implemented in FPGAs are\ndescribed. The system performance is fully characterised. The sensors have a\nsignal to noise ratio of approximately 20 and a best hit resolution of 4\nmicrons is achieved at the optimal track angle. The typical detector occupancy\nfor minimum bias events in standard operating conditions in 2011 is around\n0.5%, and the detector has less than 1% of faulty strips. The proximity of the\ndetector to the beam means that the inner regions of the n+-on-n sensors have\nundergone space-charge sign inversion due to radiation damage. The VELO\nperformance parameters that drive the experiment's physics sensitivity are also\ngiven. The track finding efficiency of the VELO is typically above 98% and the\nmodules have been aligned to a precision of 1 micron for translations in the\nplane transverse to the beam. A primary vertex resolution of 13 microns in the\ntransverse plane and 71 microns along the beam axis is achieved for vertices\nwith 25 tracks. An impact parameter resolution of less than 35 microns is\nachieved for particles with transverse momentum greater than 1 GeV/c. \n\n"}
{"id": "1406.1492", "contents": "Title: Experimental signatures of a light singlet-like scalar in NMSSM Abstract: NMSSM with a light singlet-like scalar and strongly suppressed couplings to\n$b$ and $\\tau$ is investigated. It is shown that in such a scenario the\nsinglet-like scalar to diphoton signal can be larger than for the SM Higgs for\na wide range of masses between 60 and 110 GeV, in agreement with all the LEP\nand LHC data. Enhancement of the singlet-like scalar to diphoton signal is\ncorrelated with positive correction to the SM-like Higgs mass from mixing\nbetween SM-like Higgs and the singlet. It is also shown that the couplings to\n$b$ and $\\tau$ and, in consequence, branching ratios of the SM-like Higgs are\nanti-correlated with those of the singlet-like scalar. If the singlet-like\nscalar to diphoton signal is enhanced, the signal strengths of the 125 GeV\nHiggs in the diphoton and $WW^*/ZZ^*$ channels are predicted to be smaller than\nfor the SM Higgs. \n\n"}
{"id": "1406.2276", "contents": "Title: Dark Nuclei I: Cosmology and Indirect Detection Abstract: In a companion paper (to be presented), lattice field theory methods are used\nto show that in two-color, two-flavor QCD there are stable nuclear states in\nthe spectrum. As a commonly studied theory of composite dark matter, this\nmotivates the consideration of possible nuclear physics in this and other\ncomposite dark sectors. In this work, early Universe cosmology and indirect\ndetection signatures are explored for both symmetric and asymmetric dark\nmatter, highlighting the unique features that arise from considerations of dark\nnuclei and associated dark nuclear processes. The present day dark matter\nabundance may be composed of dark nucleons and/or dark nuclei, where the latter\nare generated through it dark nucleosynthesis. For symmetric dark matter,\nindirect detection signatures are possible from annihilation, dark\nnucleosynthesis, and dark nuclear capture and we present a novel explanation of\nthe galactic center gamma ray excess based on the latter. For asymmetric dark\nmatter, dark nucleosynthesis may alter the capture of dark matter in stars,\nallowing for captured particles to be processed into nuclei and ejected from\nthe star through dark nucleosynthesis in the core. Notably, dark\nnucleosynthesis realizes a novel mechanism for indirect detection signals of\nasymmetric dark matter from regions such as the galactic center, without having\nto rely on a symmetric dark matter component. \n\n"}
{"id": "1406.3437", "contents": "Title: Performance of the ALICE muon trigger RPCs during LHC Run I Abstract: ALICE (A Large Ion Collider Experiment) studies the transition of nuclear\nmatter to a deconfined phase known as Quark Gluon Plasma, in ultra-relativistic\nheavy-ion collisions at the LHC. ALICE is equipped with a muon spectrometer for\nthe detection of quarkonia and heavy flavour particles. The trigger system of\nthe spectrometer consists of 72 RPCs arranged in four detection planes, with a\ntotal area of 140 m^{2}. In the first three years of LHC operation, the muon\ntrigger system was fully operational in data-taking in pp, Pb-Pb and p-Pb\ncollisions. The RPC performance and stability throughout the whole data-taking\nperiod is presented and discussed, for the parameters such as the efficiency,\nthe dark counting rate, the dark current and the cluster size. \n\n"}
{"id": "1406.5286", "contents": "Title: Enhancing Pure-Pixel Identification Performance via Preconditioning Abstract: In this paper, we analyze different preconditionings designed to enhance\nrobustness of pure-pixel search algorithms, which are used for blind\nhyperspectral unmixing and which are equivalent to near-separable nonnegative\nmatrix factorization algorithms. Our analysis focuses on the successive\nprojection algorithm (SPA), a simple, efficient and provably robust algorithm\nin the pure-pixel algorithm class. Recently, a provably robust preconditioning\nwas proposed by Gillis and Vavasis (arXiv:1310.2273) which requires the\nresolution of a semidefinite program (SDP) to find a data points-enclosing\nminimum volume ellipsoid. Since solving the SDP in high precisions can be time\nconsuming, we generalize the robustness analysis to approximate solutions of\nthe SDP, that is, solutions whose objective function values are some\nmultiplicative factors away from the optimal value. It is shown that a high\naccuracy solution is not crucial for robustness, which paves the way for faster\npreconditionings (e.g., based on first-order optimization methods). This first\ncontribution also allows us to provide a robustness analysis for two other\npreconditionings. The first one is pre-whitening, which can be interpreted as\nan optimal solution of the same SDP with additional constraints. We analyze\nrobustness of pre-whitening which allows us to characterize situations in which\nit performs competitively with the SDP-based preconditioning. The second one is\nbased on SPA itself and can be interpreted as an optimal solution of a\nrelaxation of the SDP. It is extremely fast while competing with the SDP-based\npreconditioning on several synthetic data sets. \n\n"}
{"id": "1406.7618", "contents": "Title: Can Effective Field Theory of inflation generate large tensor-to-scalar\n  ratio within Randall Sundrum single braneworld? Abstract: In this paper my prime objective is to explain the generation of large\ntensor-to-scalar ratio from the single field sub-Planckian inflationary\nparadigm within Randall Sundrum (RS) single braneworld scenario in a model\nindependent fashion. By explicit computation I have shown that the effective\nfield theory prescription of brane inflation within RS single brane setup is\nconsistent with sub- Planckian excursion of the inflaton field, which will\nfurther generate large value of tensor-to-scalar ratio, provided the energy\ndensity for inflaton degrees of freedom is high enough compared to the brane\ntension in high energy regime. Finally, I have mentioned the stringent\ntheoretical constraint on positive brane tension, cut-off of the quantum\ngravity scale and bulk cosmological constant to get sub-Planckian field\nexcursion along with large tensor-to-scalar ratio as recently observed by\nBICEP2 or at least generates the tensor-to-scalar ratio consistent with the\nupper bound of Planck (2013 and 2015) data and Planck+BICEP2+Keck Array joint\nconstraint. \n\n"}
{"id": "1407.0275", "contents": "Title: The muon system of the Daya Bay Reactor antineutrino experiment Abstract: The Daya Bay experiment consists of functionally identical antineutrino\ndetectors immersed in pools of ultrapure water in three well-separated\nunderground experimental halls near two nuclear reactor complexes. These pools\nserve both as shields against natural, low-energy radiation, and as water\nCherenkov detectors that efficiently detect cosmic muons using arrays of\nphotomultiplier tubes. Each pool is covered by a plane of resistive plate\nchambers as an additional means of detecting muons. Design, construction,\noperation, and performance of these muon detectors are described. \n\n"}
{"id": "1407.0533", "contents": "Title: Sampling by incomplete cosine expansion of the sinc function:\n  application to the Voigt/complex error function Abstract: A new sampling methodology based on incomplete cosine expansion series is\npresented as an alternative to the traditional sinc function approach.\nNumerical integration shows that this methodology is efficient and practical.\nApplying the incomplete cosine expansion we obtain a rational approximation of\nthe complex error function that with the same number of the summation terms\nprovides an accuracy exceeding the Weideman\\text{'}s approximation accuracy by\nseveral orders of the magnitude. Application of the expansion results in an\nintegration consisting of elementary function terms only. Consequently, this\napproach can be advantageous for accurate and rapid computation. \n\n"}
{"id": "1407.3043", "contents": "Title: Stabilized Finite Element Approximation of the Mean Curvature Vector on\n  Closed Surfaces Abstract: We develop a stabilized discrete Laplace-Beltrami operator that is used to\ncompute an approximate mean curvature vector which enjoys convergence of order\none in L2. The stabilization is of gradient jump type and we consider both\nstandard meshed surfaces and so called cut surfaces that are level sets of\npiecewise linear distance functions. We prove a priori error estimates and\nverify the theoretical results numerically. \n\n"}
{"id": "1407.6516", "contents": "Title: Neganov-Luke amplified cryogenic light detectors for the background\n  discrimination in neutrinoless double beta decay search with TeO$_{2}$\n  bolometers Abstract: We demonstrate that Neganov-Luke amplified cryogenic light detectors with\nTransition Edge Sensor read-out can be applied for the background suppression\nin cryogenic experiments searching for the neutrinoless double beta decay of\n$^{130}\\text{Te}$ with TeO$_{2}$ based bolometers. Electron and gamma induced\nevents can be discriminated from $\\alpha$ events by detecting the Cherenkov\nlight produced by the $\\beta$ particles emitted in the decay. We use the\nCherenkov light produced by events in the full energy peak of $^{208}\\text{Tl}$\nand by events from a $^{147}\\text{Sm}$ source to show that at the Q-value of\nthe neutrinoless double beta decay of $^{130}\\text{Te}$ ($Q_{\\beta \\beta} =\n2.53 \\,\\text{MeV}$), a separation of $e^{-}/\\gamma$ events from $\\alpha$ events\ncan be achieved on an event-by-event basis with practically no reduction in\nsignal acceptance. \n\n"}
{"id": "1407.6914", "contents": "Title: Holographic Glueball Decay Abstract: We announce new results on glueball decay rates in the Sakai-Sugimoto model,\na realization of holographic QCD from first principles that has only one\ncoupling constant and an overall mass scale as free parameters. We extend a\nprevious investigation by Hashimoto, Tan, and Terashima who have considered the\nlowest scalar glueball which arises from a somewhat exotic polarization of\nsupergravity modes and whose mass is uncomfortably small in comparison with\nlattice results. On the other hand, the scalar glueball dual to the dilaton\nturns out to have a mass of about twice the mass of the rho meson (1487 MeV),\nvery close to the scalar meson $f_0(1500)$ that is frequently interpreted as\npredominantly glue. Calculating the decay rate into two pions we find a\nsurprisingly good agreement with experimental data for the $f_0(1500)$. We have\nalso obtained decay widths for tensor and excited scalar glueballs, indicating\nuniversal narrowness. \n\n"}
{"id": "1407.7348", "contents": "Title: Measurement of the ionization yield of nuclear recoils in liquid argon\n  at 80 and 233 keV Abstract: The energy calibration of nuclear recoil detectors is of primary importance\nto rare-event experiments such as those of direct dark matter search and\ncoherent neutrino-nucleus scattering. In particular, such a calibration is\nperformed by measuring the ionization yield of nuclear recoils in liquid Ar and\nXe detection media, using neutron elastic scattering off nuclei. In the present\nwork, the ionization yield for nuclear recoils in liquid Ar has for the first\ntime been measured in the higher energy range, at 80 and 233 keV, using a\ntwo-phase Cryogenic Avalanche Detector (CRAD) and DD neutron generator. The\nionization yield in liquid Ar at an electric field of 2.3 kV/cm amounted to\n7.8+/-1.1 and 9.7+/-1.3 e-/keV at 80 and 233 keV respectively. The Jaffe model\nfor nuclear recoil-induced ionization, in contrast to that Thomas-Imel, can\nprobably consistently describe the energy dependence of the ionization yield. \n\n"}
{"id": "1407.7349", "contents": "Title: Regularization and Numerical Solution of the Inverse Scattering Problem\n  using Shearlet Frames Abstract: Regularization techniques for the numerical solution of inverse scattering\nproblems in two space dimensions are discussed. Assuming that the boundary of a\nscatterer is its most prominent feature, we exploit as model the class of\ncartoon-like functions. Since functions in this class are asymptotically\noptimally sparsely approximated by shearlet frames, we consider shearlets as a\nmeans for regularization in a Tikhonov method. We analyze two approaches,\nnamely solvers for the nonlinear problem and for the linearized problem\nobtained by the Born approximation technique. As example for the first class we\nstudy the acoustic inverse scattering problem, and for the second class, the\ninverse scattering problem of the Schr\\\"{o}dinger equation. In both cases, we\nderive analytical results for our approaches. Whereas our emphasis for the\nlinearized problem is more on the theoretical side due to the standardness of\nassociated solvers, we provide numerical examples for the nonlinear problem\nthat highlight the effectiveness of our algorithmic approach. \n\n"}
{"id": "1408.1082", "contents": "Title: Interpretations of anomalous LHC events with electrons and jets Abstract: The CMS Collaboration has recently reported some excess events in final\nstates with electrons and jets, in searches for leptoquarks and $W'$ bosons.\nAlthough these excesses may be due to some yet-to-be-understood background\nmismodeling, it is useful to seek realistic interpretations involving new\nparticles that could generate such events. We show that resonant pair\nproduction of vector-like leptons that decay to an electron and two jets leads\nto kinematic distributions consistent with the CMS data. \n\n"}
{"id": "1408.5165", "contents": "Title: A Stabilized Cut Finite Element Method for the Three Field Stokes\n  Problem Abstract: We propose a Nitsche-based fictitious domain method for the three field\nStokes problem in which the boundary of the domain is allowed to cross through\nthe elements of a fixed background mesh. The dependent variables of velocity,\npressure and extra-stress tensor are discretised on the background mesh using\nlinear finite elements. This equal order approximation is stabilized using a\ncontinuous interior penalty (CIP) method. On the unfitted domain boundary,\nDirichlet boundary conditions are weakly enforced using Nitsche's method. We\nadd CIP-like ghost penalties in the boundary region and prove that our scheme\nis inf-sup stable and that it has optimal convergence properties independent of\nhow the domain boundary intersects the mesh. Additionally, we demonstrate that\nthe condition number of the system matrix is bounded independently of the\nboundary location. We corroborate our theoretical findings with numerical\nexamples. \n\n"}
{"id": "1408.6384", "contents": "Title: A perturbative approach to the hydrodynamics of heavy ion collisions Abstract: Initial fluctuations in hydrodynamic fields such as energy density or flow\nvelocity give access to understanding initial state and equilibration physics\nas well as thermodynamic and transport properties. We provide evidence that the\nfluid dynamic propagation of fluctuations of realistic size can be based on a\nbackground-fluctuation splitting and a systematic perturbative expansion in the\nfluctuating fields. Initial conditions are characterized by a Bessel-Fourier\nexpansion for single events, event-by-event correlations and probability\ndistributions. The evolution equations can be solved order-by-order in the\nexpansion which allows to study the fluid dynamical propagation of single\nmodes, the study of interaction effects between modes, the determination of the\nassociated particle spectra and the generalization of the whole program to\nevent-by-event correlations and distributions. \n\n"}
{"id": "1409.1161", "contents": "Title: Quantitative estimates on the periodic approximation of the corrector in\n  stochastic homogenization Abstract: In the present contribution we establish quantitative results on the periodic\napproximation of the corrector equation for the stochastic homogenization of\nlinear elliptic equations in divergence form, when the diffusion coefficients\nsatisfy a spectral gap estimate in probability, and for $d>2$. The main\ndifference with respect to the first part of [Gloria-Otto, arXiv:1409.0801] is\nthat we avoid here the use of Green's functions and more directly rely on the\nDe Giorgi-Nash-Moser theory. \n\n"}
{"id": "1409.3550", "contents": "Title: Generalized Multiscale Finite-Element Method (GMsFEM) for elastic wave\n  propagation in heterogeneous, anisotropic media Abstract: It is important to develop fast yet accurate numerical methods for seismic\nwave propagation to characterize complex geological structures and oil and gas\nreservoirs. However, the computational cost of conventional numerical modeling\nmethods, such as finite-difference method and finite-element method, becomes\nprohibitively expensive when applied to very large models. We propose a\nGeneralized Multiscale Finite-Element Method (GMsFEM) for elastic wave\npropagation in heterogeneous, anisotropic media, where we construct basis\nfunctions from multiple local problems for both the boundaries and interior of\na coarse node support or coarse element. The application of multiscale basis\nfunctions can capture the fine scale medium property variations, and allows us\nto greatly reduce the degrees of freedom that are required to implement the\nmodeling compared with conventional finite-element method for wave equation,\nwhile restricting the error to low values. We formulate the continuous Galerkin\nand discontinuous Galerkin formulation of the multiscale method, both of which\nhave pros and cons. Applications of the multiscale method to three\nheterogeneous models show that our multiscale method can effectively model the\nelastic wave propagation in anisotropic media with a significant reduction in\nthe degrees of freedom in the modeling system. \n\n"}
{"id": "1409.4618", "contents": "Title: Fast MATLAB assembly of FEM matrices in 2D and 3D: Edge elements Abstract: We propose an effective and flexible way to assemble finite element stiffness\nand mass matrices in MATLAB. We apply this for problems discretized by edge\nfinite elements. Typical edge finite elements are Raviart-Thomas elements used\nin discretizations of H(div) spaces and Nedelec elements in discretizations of\nH(curl) spaces. We explain vectorization ideas and comment on a freely\navailable MATLAB code which is fast and scalable with respect to time. \n\n"}
{"id": "1409.5506", "contents": "Title: Efficient approximation of sparse Jacobians for time-implicit reduced\n  order models Abstract: This paper introduces a sparse matrix discrete interpolation method to\neffectively compute matrix approximations in the reduced order modeling\nframework. The sparse algorithm developed herein relies on the discrete\nempirical interpolation method and uses only samples of the nonzero entries of\nthe matrix series. The proposed approach can approximate very large matrices,\nunlike the current matrix discrete empirical interpolation method which is\nlimited by its large computational memory requirements. The empirical\ninterpolation indexes obtained by the sparse algorithm slightly differ from the\nones computed by the matrix discrete empirical interpolation method as a\nconsequence of the singular vectors round-off errors introduced by the economy\nor full singular value decomposition (SVD) algorithms when applied to the full\nmatrix snapshots. When appropriately padded with zeros the economy SVD\nfactorization of the nonzero elements of the snapshots matrix is a valid\neconomy SVD for the full snapshots matrix. Numerical experiments are performed\nwith the 1D Burgers and 2D Shallow Water Equations test problems where the\nquadratic reduced nonlinearities are computed via tensorial calculus. The\nsparse matrix approximation strategy is compared against five existing methods\nfor computing reduced Jacobians: a) matrix discrete empirical interpolation\nmethod, b) discrete empirical interpolation method, c) tensorial calculus, d)\nfull Jacobian projection onto the reduced basis subspace, and e) directional\nderivatives of the model along the reduced basis functions. The sparse matrix\nmethod outperforms all other algorithms. The use of traditional matrix discrete\nempirical interpolation method is not possible for very large instances due to\nits excessive memory requirements. \n\n"}
{"id": "1409.7464", "contents": "Title: High-order Numerical Methods for Riesz Space Fractional Turbulent\n  Diffusion Equation Abstract: Numerical methods for fractional calculus attract increasing interests due to\nits wide applications in various fields such as physics, mechanics, etc. In\nthis paper, we focus on constructing high-order algorithms for Riesz\nderivatives, where the convergence orders cover from the second order to the\nsixth order. Then we apply the established schemes to the Riesz space\nfractional turbulent diffusion equation. Numerical experiments are displayed\nwhich support the theoretical analysis. \n\n"}
{"id": "1410.0076", "contents": "Title: Underground physics without underground labs: large detectors in\n  solution-mined salt caverns Abstract: A number of current physics topics, including long-baseline neutrino physics,\nproton decay searches, and supernova neutrino searches, hope to someday\nconstruct huge (50 kiloton to megaton) particle detectors in shielded,\nunderground sites. With today's practices, this requires the costly excavation\nand stabilization of large rooms in mines. In this paper, we propose utilizing\nthe caverns created by the solution mining of salt. The challenge is that such\ncaverns must be filled with pressurized fluid and do not admit human access. We\nsketch some possible methods of installing familiar detector technologies in a\nsalt cavern under these constraints. Some of the detectors discussed are also\nsuitable for deep-sea experiments, discussed briefly. These sketches appear\nchallenging but feasible, and appear to force few major compromises on detector\ncapabilities. This scheme offers avenues for enormous cost savings on future\ndetector megaprojects. \n\n"}
{"id": "1410.0200", "contents": "Title: Hidden Photon Dark Matter Search with a Large Metallic Mirror Abstract: If Dark Matter is composed of hidden-sector photons that kinetically mix with\nphotons of the visible sector, then Dark Matter has a tiny oscillating electric\nfield component. Its presence would lead to a small amount of visible radiation\nbeing emitted from a conducting surface, with the photon frequency given\napproximately by the mass of the hidden photon. Here, we report on experimental\nefforts that have started recently to search for such hidden photon Dark Matter\nin the (sub-)eV regime with a prototype mirror for the Auger fluorescence\ndetector at the Karlsruhe Institute for Technology. \n\n"}
{"id": "1410.1797", "contents": "Title: The COMPASS Setup for Physics with Hadron Beams Abstract: The main characteristics of the COMPASS experimental setup for physics with\nhadron beams are described. This setup was designed to perform exclusive\nmeasurements of processes with several charged and/or neutral particles in the\nfinal state. Making use of a large part of the apparatus that was previously\nbuilt for spin structure studies with a muon beam, it also features a new\ntarget system as well as new or upgraded detectors. The hadron setup is able to\noperate at the high incident hadron flux available at CERN. It is characterised\nby large angular and momentum coverages, large and nearly flat acceptances, and\ngood two and three-particle mass resolutions. In 2008 and 2009 it was\nsuccessfully used with positive and negative hadron beams and with liquid\nhydrogen and solid nuclear targets. This article describes the new and upgraded\ndetectors and auxiliary equipment, outlines the reconstruction procedures used,\nand summarises the general performance of the setup. \n\n"}
{"id": "1410.2532", "contents": "Title: Signal Formation in a Detector with one Large Dimension Abstract: We present the theory for the signal formation in a multi conductor detector\nwith cylindrical geometry and long length. There exists electromagnetic wave\npropagation along the large dimension of the detector. The system is equivalent\nto a multi conductor transmission line. The treatment is in the TEM\napproximation. Each conductor is fed by its current source which is the same as\nin the case of small size detectors. A simple example is given for a long\nlength Monitored Drift Tube (MDT). One could apply the result to a long\nmicromegas-type detector or any long microstrip detector, ignoring propagation\nthat is transverse to the strips. \n\n"}
{"id": "1410.3253", "contents": "Title: A reduced basis localized orthogonal decomposition Abstract: In this work we combine the framework of the Reduced Basis method (RB) with\nthe framework of the Localized Orthogonal Decomposition (LOD) in order to solve\nparametrized elliptic multiscale problems. The idea of the LOD is to split a\nhigh dimensional Finite Element space into a low dimensional space with\ncomparably good approximation properties and a remainder space with negligible\ninformation. The low dimensional space is spanned by locally supported basis\nfunctions associated with the node of a coarse mesh obtained by solving\ndecoupled local problems. However, for parameter dependent multiscale problems,\nthe local basis has to be computed repeatedly for each choice of the parameter.\nTo overcome this issue, we propose an RB approach to compute in an \"offline\"\nstage LOD for suitable representative parameters. The online solution of the\nmultiscale problems can then be obtained in a coarse space (thanks to the LOD\ndecomposition) and for an arbitrary value of the parameters (thanks to a\nsuitable \"interpolation\" of the selected RB). The online RB-LOD has a basis\nwith local support and leads to sparse systems. Applications of the strategy to\nboth linear and nonlinear problems are given. \n\n"}
{"id": "1410.3547", "contents": "Title: Mathematical and numerical analysis of time-dependent Ginzburg--Landau\n  equations in nonconvex polygons based on Hodge decomposition Abstract: We prove well-posedness of time-dependent Ginzburg--Landau system in a\nnonconvex polygonal domain, and decompose the solution as a regular part plus a\nsingular part. We see that the magnetic potential is not in $H^1$ in general,\nand the finite element method (FEM) may give incorrect solutions. To remedy\nthis situation, we reformulate the equations into an equivalent system of\nelliptic and parabolic equations based on the Hodge decomposition, which avoids\ndirect calculation of the magnetic potential. The essential unknowns of the\nreformulated system admit $H^1$ solutions and can be solved correctly by the\nFEMs. We then propose a decoupled and linearized FEM to solve the reformulated\nequations and present error estimates based on proved regularity of the\nsolution. Numerical examples are provided to support our theoretical analysis\nand show the efficiency of the method. \n\n"}
{"id": "1410.5759", "contents": "Title: An SO(10) \\times SO(10)' model for common origin of neutrino masses,\n  ordinary and dark matter-antimatter asymmetries Abstract: We propose an SO(10) \\times SO(10)' model to simultaneously realize a seesaw\nfor Dirac neutrino masses and a leptogenesis for ordinary and dark\nmatter-antimatter asymmetries. A (16\\times \\overline{16}')_H scalar crossing\nthe SO(10) and SO(10)' sectors plays an essential role in this\nseesaw-leptogenesis scenario. As a result of lepton number conservation, the\nlightest dark nucleon as the dark matter particle should have a determined mass\naround 15 GeV to explain the comparable fractions of ordinary and dark matter\nin the present universe. The (16\\times \\overline{16}')_H scalar also mediates a\nU(1)_{em} \\times U(1)'_{em} kinetic mixing after the ordinary and dark\nleft-right symmetry breaking so that we can expect a dark nucleon scattering in\ndirect detection experiments and/or a dark nucleon decay in indirect detection\nexperiments. If a proper mirror symmetry is imposed, our Dirac seesaw will not\nrequire more unknown parameters than the canonical Majorana seesaw. \n\n"}
{"id": "1410.6256", "contents": "Title: Improved TPB-coated Light Guides for Liquid Argon TPC Light Detection\n  Systems Abstract: Scintillation light produced in liquid argon (LAr) must be shifted from 128\nnm to visible wavelengths in light detection systems used for liquid argon\ntime-projection chambers (LArTPCs). To date, LArTPC light collection systems\nhave employed tetraphenyl butadiene (TPB) coatings on photomultiplier tubes\n(PMTs) or plates placed in front of the PMTs. Recently, a new approach using\nTPB-coated light guides was proposed. In this paper, we report on light guides\nwith improved attenuation lengths above 100 cm when measured in air. This is an\nimportant step in the development of meter-scale light guides for future\nLArTPCs. Improvements come from using a new acrylic-based coating,\ndiamond-polished cast UV transmitting acrylic bars, and a hand-dipping\ntechnique to coat the bars. We discuss a model for connecting bar response in\nair to response in liquid argon and compare this to data taken in liquid argon.\nThe good agreement between the prediction of the model and the measured\nresponse in liquid argon demonstrates that characterization in air is\nsufficient for quality control of bar production. This model can be used in\nsimulations of light guides for future experiments. \n\n"}
{"id": "1410.8719", "contents": "Title: Study of the single cluster response of a helium-isobutane drift chamber\n  prototype using 8 keV X-rays Abstract: The identification of single clusters in the electronic signals produced by\nionizing particles within a drift chamber is expected to significantly improve\nthe performances of this kind of detectors in terms of particle identification\ncapabilities and space resolution. In order to develop refined cluster\nrecognition algorithms, it is essential to measure the response of the chamber\nand its electronics to single ionization clusters. This can be done by\nirradiating the chamber with X-rays. We report here on the studies performed on\na drift chamber prototype for the MEG-II experiment at the X-ray facility of\nthe INFN Frascati's National Laboratories \"XLab Frascati\". The prototype is\noperated with a helium-isobutane mixture and instrumented with high bandwidth\ncustom pre-amplifiers. The results of this study have been used to develop an\ninnovative method for cluster recognition, based on the Wiener filter\ntechnique. As a side measurement, we also performed a study of the gas gain in\na configuration which is similar to that of the MEG-II experiment. \n\n"}
{"id": "1411.0475", "contents": "Title: The Hunt for neutrinoless double beta decay with the NEXT experiment Abstract: The NEXT-100 detector will search for the neutrinoless double beta decay of\n$^{136}$Xe using an electroluminescent high-pressure xenon gas TPC filled with\n100 kg of enriched Xe. An observation of this hypothetical process would\nestablish a Majorana nature for the neutrino and prove the violation of lepton\nnumber. A scaled-down prototype, NEXT-DEMO, has been built to demonstrate the\nfeasibility of the technology. NEXT-DEMO includes an energy plane made of PMTs\nand a tracking plane made of SiPMs. X-ray energy depositions, produced by the\nde-excitation of xenon atoms after their interaction with gamma rays, have been\nused to characterize the detector response. With this method, the released\nenergy by gammas coming from $^{22}$Na source has been corrected, achieving an\nenergy resolution of 5.691% FWHM and 1.62% FWHM at the 29.7 keV and 511 keV\npeaks respectively, which extrapolate to 0.62% FWHM and 0.73% FWHM at Q$_{\\beta\n\\beta}$ value of Xenon. \n\n"}
{"id": "1411.0731", "contents": "Title: Quasi-Monte Carlo tractability of high dimensional integration over\n  products of simplices Abstract: Quasi-Monte Carlo (QMC) methods for high dimensional integrals over unit\ncubes and products of spheres are well-studied in literature. We study QMC\ntractability of integrals of functions defined over the product of $m$ copies\nof the simplex $T^d \\subset \\mathbb{R}^{d}$. The domain is a tensor product of\n$m$ reproducing kernel Hilbert spaces defined by `weights' $\\gamma_{m,j}$, for\n$j = 1,2, \\ldots, m$. Similar to the results on the unit cube in $m$\ndimensions, and the product of $m$ copies of the $d$-dimensional sphere, we\nprove that strong polynomial tractability holds iff $\\limsup_{m \\rightarrow\n\\infty} \\sum_{j=1}^m \\gamma_{m,j} < \\infty$ and polynomial tractability holds\niff $\\limsup_{m \\rightarrow \\infty} \\frac{\\sum_{j=1}^m \\gamma_{m,j}}{\\log(m + 1\n)} < \\infty$. We also show that weak tractability holds iff $\\lim_{m\n\\rightarrow \\infty} \\frac{\\sum_{j=1}^m \\gamma_{m,j}}{m} = 0$. The proofs employ\nSobolev space techniques and weighted reproducing kernel Hilbert space\ntechniques for the simplex and products of simplices as domain. Properties of\northogonal polynomials on a simplex are also used extensively. \n\n"}
{"id": "1411.1758", "contents": "Title: Where do the 3.5 keV photons come from? A morphological study of the\n  Galactic Center and of Perseus Abstract: We test the origin of the 3.5 keV line photons by analyzing the morphology of\nthe emission at that energy from the Galactic Center and from the Perseus\ncluster of galaxies. We employ a variety of different templates to model the\ncontinuum emission and analyze the resulting radial and azimuthal distribution\nof the residual emission. We then perform a pixel-by-pixel binned likelihood\nanalysis including line emission templates and dark matter templates and assess\nthe correlation of the 3.5 keV emission with these templates. We conclude that\nthe radial and azimuthal distribution of the residual emission is incompatible\nwith a dark matter origin for both the Galactic center and Perseus; the\nGalactic center 3.5 keV line photons trace the morphology of lines at\ncomparable energy, while the Perseus 3.5 keV photons are highly correlated with\nthe cluster's cool core, and exhibit a morphology incompatible with dark matter\ndecay. The template analysis additionally allows us to set the most stringent\nconstraints to date on lines in the 3.5 keV range from dark matter decay. \n\n"}
{"id": "1411.2985", "contents": "Title: Z-portal dark matter Abstract: We propose to generalize the extensions of the Standard Model where the $Z$\nboson serves as a mediator between the Standard Model sector and the dark\nsector $\\chi$. We show that, like in the Higgs portal case, the combined\nconstraints from the recent direct searches restrict severely the nature of the\ncoupling of the dark matter to the $Z$ boson and set a limit $m_\\chi \\gtrsim\n200$ GeV (except in a very narrow region around the $Z-$pole region). Using\ncomplementarity between spin dependent, spin independent and FERMI limits, we\npredict the nature of this coupling, more specifically the axial/vectorial\nratio that respects a thermal dark matter coupled through a $Z$-portal while\nnot being excluded by the current observations. We also show that the next\ngeneration of experiments of the type LZ or XENON1T will test Z-portal scenario\nfor dark matter mass up to 2 TeV. The condition of a thermal dark matter\nnaturally predicts the spin--dependent scattering cross section on the neutron\nto be $\\sigma^{SD}_{\\chi n} \\simeq 10^{-40} \\mrm{cm^2}$, which then becomes a\nclear prediction of the model and a signature testable in the near future\nexperiments. \n\n"}
{"id": "1411.3688", "contents": "Title: Dimension-independent likelihood-informed MCMC Abstract: Many Bayesian inference problems require exploring the posterior distribution\nof high-dimensional parameters that represent the discretization of an\nunderlying function. This work introduces a family of Markov chain Monte Carlo\n(MCMC) samplers that can adapt to the particular structure of a posterior\ndistribution over functions. Two distinct lines of research intersect in the\nmethods developed here. First, we introduce a general class of\noperator-weighted proposal distributions that are well defined on function\nspace, such that the performance of the resulting MCMC samplers is independent\nof the discretization of the function. Second, by exploiting local Hessian\ninformation and any associated low-dimensional structure in the change from\nprior to posterior distributions, we develop an inhomogeneous discretization\nscheme for the Langevin stochastic differential equation that yields\noperator-weighted proposals adapted to the non-Gaussian structure of the\nposterior. The resulting dimension-independent, likelihood-informed (DILI) MCMC\nsamplers may be useful for a large class of high-dimensional problems where the\ntarget probability measure has a density with respect to a Gaussian reference\nmeasure. Two nonlinear inverse problems are used to demonstrate the efficiency\nof these DILI samplers: an elliptic PDE coefficient inverse problem and path\nreconstruction in a conditioned diffusion. \n\n"}
{"id": "1411.4243", "contents": "Title: Recent progress in the development of large area silica aerogel for use\n  as RICH radiator in the Belle II experiment Abstract: We report recent progress in the development of large-area hydrophobic silica\naerogels for use as radiators in the aerogel-based ring-imaging Cherenkov\n(A-RICH) counter to be installed in the forward end cap of the Belle II\ndetector, which is currently being upgraded at the High Energy Accelerator\nResearch Organization (KEK), Japan. The production of approximately 450 aerogel\ntiles with refractive indices of either 1.045 or 1.055 was completed in May,\n2014, and the tiles are now undergoing optical characterization. Installation\nof the aerogels was tested by installing them into a partial mock-up of the\nsupport structure. \n\n"}
{"id": "1411.4651", "contents": "Title: Tomographic-spectral approach for dark matter detection in the\n  cross-correlation between cosmic shear and diffuse gamma-ray emission Abstract: We recently proposed to cross-correlate the diffuse extragalactic gamma-ray\nbackground with the gravitational lensing signal of cosmic shear. This\nrepresents a novel and promising strategy to search for annihilating or\ndecaying particle dark matter (DM) candidates. In the present work, we\ndemonstrate the potential of a tomographic-spectral approach: measuring the\ncross-correlation in separate bins of redshift and energy significantly\nimproves the sensitivity to a DM signal. Indeed, the technique proposed here\ntakes advantage of the different scaling of the astrophysical and DM components\nwith redshift and, simultaneously, of their different energy spectra and\ndifferent angular extensions. The sensitivity to a particle DM signal is\nextremely promising even when the DM-induced emission is quite faint. We first\nquantify the prospects of detecting DM by cross-correlating the Fermi Large\nArea Telescope (LAT) diffuse gamma-ray background with the cosmic shear\nexpected from the Dark Energy Survey. Under the hypothesis of a significant\nsubhalo boost, such a measurement can deliver a 5-sigma detection of DM, if the\nDM particle is lighter than 300 GeV and has a thermal annihilation rate. We\nthen forecast the capability of the European Space Agency Euclid satellite\n(whose launch is planned for 2020), in combination with an hypothetical future\ngamma-ray detector with slightly improved specifications compared to current\ntelescopes. We predict that the cross-correlation of their data will allow a\nmeasurement of the DM mass with an uncertainty of a factor of 1.5-2, even for\nmoderate subhalo boosts, for DM masses up to few hundreds of GeV and thermal\nannihilation rates. \n\n"}
{"id": "1411.5794", "contents": "Title: BMO and exponential Orlicz space estimates of the discrepancy function\n  in arbitrary dimension Abstract: In the current paper we obtain discrepancy estimates in exponential Orlicz\nand BMO spaces in arbitrary dimension $d \\ge 3$. In particular, we use dyadic\nharmonic analysis to prove that for the so-called digital nets of order $2$ the\nBMO${}^d$ and $\\exp \\big( L^{2/(d-1)} \\big)$ norms of the discrepancy function\nare bounded above by $(\\log N)^{\\frac{d-1}{2}}$. The latter bound has been\nrecently conjectured in several papers and is consistent with the best known\nlow-discrepancy constructions. Such estimates play an important role as an\nintermediate step between the well-understood $L_p$ bounds and the notorious\nopen problem of finding the precise $L_\\infty$ asymptotics of the discrepancy\nfunction in higher dimensions, which is still elusive. \n\n"}
{"id": "1411.6333", "contents": "Title: Analysis of a new stabilized discontinuous Galerkin method for the\n  reaction-diffusion problem with discontinuous coefficient Abstract: In this paper, a new stabilized discontinuous Galerkin method within a new\nfunction space setting is introduced, which involves an extra stabilization\nterm on the normal fluxes across the element interfaces. It is different from\nthe general DG methods. The formulation satisfies a local conservation property\nand we prove well posedness of the new formulation by Inf-Sup condition. A\npriori error estimates are derived, which are verified by a 2D experiment on a\nreaction-diffusion type model problem. \n\n"}
{"id": "1411.6961", "contents": "Title: Stochastic C-stability and B-consistency of explicit and implicit\n  Euler-type schemes Abstract: This paper is concerned with the numerical approximation of stochastic\nordinary differential equations, which satisfy a global monotonicity condition.\nThis condition includes several equations with super-linearly growing drift and\ndiffusion coefficient functions such as the stochastic Ginzburg-Landau equation\nand the 3/2-volatility model from mathematical finance. Our analysis of the\nmean-square error of convergence is based on a suitable generalization of the\nnotions of C-stability and B-consistency known from deterministic numerical\nanalysis for stiff ordinary differential equations. An important feature of our\nstability concept is that it does not rely on the availability of higher moment\nbounds of the numerical one-step scheme.\n  While the convergence theorem is derived in a somewhat more abstract\nframework, this paper also contains two more concrete examples of\nstochastically C-stable numerical one-step schemes: the split-step backward\nEuler method from Higham et al. (2002) and a newly proposed explicit variant of\nthe Euler-Maruyama scheme, the so called projected Euler-Maruyama method. For\nboth methods the optimal rate of strong convergence is proven theoretically and\nverified in a series of numerical experiments. \n\n"}
{"id": "1411.7226", "contents": "Title: Same-sign trileptons as a signal of sneutrino lightest supersymmetric\n  partlcle Abstract: Contrary to common expectation, a left-sneutrinos can occasionally be the\nlightest supersymmet- ric particle. This has important implications in both\ncollider and dark matter studies. We show that same-sign tri-lepton (SS3L)\nevents at the Large Hadron Collider, with any lepton having opposite sign\nvetoed, distinguish such scenarios, up to gluino masses exceeding 2 TeV. The\njets + M ET signal rate is somewhat suppressed in this case, thus enhancing the\nscope of leptonic signals. \n\n"}
{"id": "1412.0427", "contents": "Title: Time-dependent Hermite-Galerkin spectral method and its applications Abstract: A time-dependent Hermite-Galerkin spectral method (THGSM) is investigated in\nthis paper for the nonlinear convection-diffusion equations in the unbounded\ndomains. The time-dependent scaling factor and translating factor are\nintroduced in the definition of the generalized Hermite functions (GHF). As a\nconsequence, the THGSM based on these GHF has many advantages, not only in\ntheorethical proofs, but also in numerical implementations. The stability and\nspectral convergence of our proposed method have been established in this\npaper. The Korteweg-de Vries-Burgers (KdVB) equation and its special cases,\nincluding the heat equation and the Burgers' equation, as the examples, have\nbeen numerically solved by our method. The numerical results are presented, and\nit surpasses the existing methods in accuracy. Our theoretical proof of the\nspectral convergence has been supported by the numerical results. \n\n"}
{"id": "1412.0618", "contents": "Title: MT2 to the Rescue -- Searching for Sleptons in Compressed Spectra at the\n  LHC Abstract: We propose a novel method for probing sleptons in compressed spectra at\nhadron colliders. The process under study is slepton pair production in\nR-parity conserving supersymmetry, where the slepton decays to a neutralino LSP\nof mass close to the slepton mass. In order to pass the trigger and obtain\nlarge missing energy, an energetic mono-jet is required. Both leptons need to\nbe detected in order to suppress large standard model backgrounds with one\ncharged lepton. We study variables that can be used to distinguish the signal\nfrom the remaining major backgrounds, which include tt, WW+jet, Z+jet, and\nsingle top production. We find that the dilepton MT2, bound by the mass\ndifference, can be used as an upper bound to efficiently reduce the\nbackgrounds. It is estimated that sleptons with masses up to about 150 GeV can\nbe discovered at the 14 TeV LHC with 100/fb integrated luminosity. \n\n"}
{"id": "1412.3086", "contents": "Title: Letter of Intent to Construct a nuPRISM Detector in the J-PARC Neutrino\n  Beamline Abstract: As long-baseline neutrino experiments enter the precision era, the\ndifficulties associated with understanding neutrino interaction cross sections\non atomic nuclei are expected to limit experimental sensitivities to\noscillation parameters. In particular, the ability to relate experimental\nobservables to neutrino energy in previous experiments has relied solely on\ntheoretical models of neutrino-nucleus interactions, which currently suffer\nfrom very large theoretical uncertainties.\n  By observing charged current $\\nu_\\mu$ interactions over a continuous range\nof off-axis angles from 1 to 4 degrees, the nuPRISM water Cherenkov detector\ncan provide a direct measurement of the far detector lepton kinematics for any\ngiven set of oscillation parameters, which largely removes neutrino interaction\nmodeling uncertainties from T2K oscillation measurements. This naturally\nprovides a direct constraint on the relationship between lepton kinematics and\nneutrino energy. In addition, nuPRISM is a sensitive probe of sterile neutrino\noscillations with multiple energy spectra, which provides unique constraints on\npossible background-related explanations of the MiniBooNE anomaly. Finally,\nhigh-precision measurements of neutrino cross sections on water are possible,\nincluding $\\nu_e$ measurements and the first ever measurements of neutral\ncurrent interactions as a function of neutrino energy.\n  The nuPRISM detector also benefits the proposed Hyper-Kamiokande project. A\ndemonstration that neutrino interaction uncertainties can be controlled will be\nimportant to understanding the physics reach of Hyper-K. In addition, nuPRISM\nwill provide an easily accessible prototype detector for many of the new\nhardware components currently under consideration for Hyper-K. The following\ndocument presents the configuration, physics impact, and preliminary cost\nestimates for a nuPRISM detector in the J-PARC neutrino beamline. \n\n"}
{"id": "1412.3951", "contents": "Title: Adaptive Low-Rank Methods for Problems on Sobolev Spaces with Error\n  Control in $L_2$ Abstract: Low-rank tensor methods for the approximate solution of second-order elliptic\npartial differential equations in high dimensions have recently attracted\nsignificant attention. A critical issue is to rigorously bound the error of\nsuch approximations, not with respect to a fixed finite dimensional discrete\nbackground problem, but with respect to the exact solution of the continuous\nproblem. While the energy norm offers a natural error measure corresponding to\nthe underlying operator considered as an isomorphism from the energy space onto\nits dual, this norm requires a careful treatment in its interplay with the\ntensor structure of the problem. In this paper we build on our previous work on\nenergy norm-convergent subspace-based tensor schemes contriving, however, a\nmodified formulation which now enforces convergence only in $L_2$. In order to\nstill be able to exploit the mapping properties of elliptic operators, a\ncrucial ingredient of our approach is the development and analysis of a\nsuitable asymmetric preconditioning scheme. We provide estimates for the\ncomputational complexity of the resulting method in terms of the solution error\nand study the practical performance of the scheme in numerical experiments. In\nboth regards, we find that controlling solution errors in this weaker norm\nleads to substantial simplifications and to a reduction of the actual numerical\nwork required for a certain error tolerance. \n\n"}
{"id": "1412.4955", "contents": "Title: Automatic track recognition for large-angle minimum ionizing particles\n  in nuclear emulsions Abstract: We previously developed an automatic track scanning system which enables the\ndetection of large-angle nuclear fragments in the nuclear emulsion films of the\nOPERA experiment. As a next step, we have investigated this system's track\nrecognition capability for large-angle minimum ionizing particles $(1.0 \\leq\n|tan \\theta| \\leq 3.5)$. This paper shows that, for such tracks, the system has\na detection efficiency of 95$\\%$ or higher and reports the achieved angular\naccuracy of the automatically recognized tracks. This technology is of general\npurpose and will likely contribute not only to various analyses in the OPERA\nexperiment, but also to future experiments, e.g. on low-energy neutrino and\nhadron interactions, or to future research on cosmic rays using nuclear\nemulsions carried by balloons. \n\n"}
{"id": "1412.5443", "contents": "Title: Two component dark matter with multi-Higgs portals Abstract: With the assistance of two extra groups, i.e., an extra hidden gauge group\n$SU(2)_D$ and a global $U(1)$ group, we propose a two component dark matter\n(DM) model. After the symmetry $SU(2)_D\\times U(1)$ being broken, we obtain\nboth the vector and scalar DM candidates. The two DM candidates communicate\nwith the standard model (SM) via three Higgs as multi-Higgs portals. The three\nHiggs are mixing states of the SM Higgs, the Higgs of the hidden sector and\nreal part of a supplement complex scalar singlet. We study relic density and\ndirect detection of DM in three scenarios. The resonance behaviors and\ninterplay between the two component DM candidates are represented through\ninvestigating of the relic density in the parameter spaces of the two DMs\nmasses. The electroweak precision parameters constrains the two Higgs portals\ncouplings ($\\lambda_m$ and $\\delta_2$). The relevant vacuum stability and\nnaturalness problem in the parameter space of $\\lambda_m$ and $\\delta_2$ are\nstudied as well. The model could alleviate these two problems in some parameter\nspaces under the constraints of electroweak precision observables and Higgs\nindirect search. \n\n"}
{"id": "1412.5641", "contents": "Title: Analysis of the Diffuse Domain Method for second order elliptic boundary\n  value problems Abstract: The diffuse domain method for partial differential equations on complicated\ngeometries recently received strong attention in particular from practitioners,\nbut many fundamental issues in the analysis are still widely open. In this\npaper we study the diffuse domain method for approximating second order\nelliptic boundary value problems posed on bounded domains, and show convergence\nand rates of the approximations generated by the diffuse domain method to the\nsolution of the original second order problem when complemented by Robin,\nDirichlet or Neumann conditions. The main idea of the diffuse domain method is\nto relax these boundary conditions by introducing a family of phase-field\nfunctions such that the variational integrals of the original problem are\nreplaced by a weighted average of integrals of perturbed domains. From an\nfunctional analytic point of view, the phase-field functions naturally lead to\nweighted Sobolev spaces for which we present trace and embedding results as\nwell as various type of Poincar\\'e inequalities with constants independent of\nthe domain perturbations. Our convergence analysis is carried out in such\nspaces as well, but allows to draw conclusions also about unweighted norms\napplied to restrictions on the original domain. Our convergence results are\nsupported by numerical examples. \n\n"}
{"id": "1412.6291", "contents": "Title: Perona-Malik equation and its numerical properties Abstract: This work concerns the Perona-Malik equation, which plays essential role in\nimage processing. The first part gives a survey of results on existance,\nuniqueness and stability of solutions, the second part introduces\ndiscretisations of equation and deals with an analysis of discrete problem. In\nthe last part I present some numerical results, in particular with algorithms\napplied to real images. \n\n"}
{"id": "1412.8398", "contents": "Title: Fourier-based schemes for computing the mechanical response of\n  composites with accurate local fields Abstract: We modify the Green operator involved in Fourier-based computational schemes\nin elasticity, in 2D and 3D. The new operator is derived by expressing\ncontinuum mechanics in terms of centered differences on a rotated grid. Use of\nthe modified Green operator leads, in all systems investigated, to more\naccurate strain and stress fields than using the discretizations proposed by\nMoulinec and Suquet (1994) or Willot and Pellegrini (2008). Moreover, we\ncompared the convergence rates of the \"direct\" and \"accelerated\" FFT schemes\nwith the different discretizations. The discretization method proposed in this\nwork allows for much faster FFT schemes with respect to two criteria: stress\nequilibrium and effective elastic moduli. \n\n"}
{"id": "1501.00251", "contents": "Title: A Tutorial on Inverse Problems for Anomalous Diffusion Processes Abstract: Over the last two decades, anomalous diffusion processes in which the mean\nsquares variance grows slower or faster than that in a Gaussian process have\nfound many applications. At a macroscopic level, these processes are adequately\ndescribed by fractional differential equations, which involves fractional\nderivatives in time or/and space. The fractional derivatives describe either\nhistory mechanism or long range interactions of particle motions at a\nmicroscopic level. The new physics can change dramatically the behavior of the\nforward problems. Naturally one expects that the new physics will impact\nrelated inverse problems in terms of uniqueness, stability, and degree of\nill-posedness. The last aspect is especially important from a practical point\nof view, i.e., stably reconstructing the quantities of interest.\n  In this paper, we employ a formal analytic and numerical way to examine the\ndegree of ill-posedness of several \"classical\" inverse problems for fractional\ndifferential equations involving a Djrbashian-Caputo fractional derivative in\neither time or space, which represent the fractional analogues of that for\nclassical integral order differential equations. We discuss four inverse\nproblems, i.e., backward fractional diffusion, sideways problem, inverse source\nproblem and inverse potential problem for time fractional diffusion, and\ninverse Sturm-Liouville problem, Cauchy problem, backward fractional diffusion\nand sideways problem for space fractional diffusion. It is found that contrary\nto the wide belief, the influence of anomalous diffusion on the degree of\nill-posedness is not definitive: it can either significantly improve or worsen\nthe conditioning of related inverse problems, depending crucially on the\nspecific type of given data and quantity of interest. Further, the study\nexhibits distinct new features of \"fractional\" inverse problems. \n\n"}
{"id": "1501.03781", "contents": "Title: A Simple Motivated Completion of the Standard Model below the Planck\n  Scale: Axions and Right-Handed Neutrinos Abstract: We study a simple Standard Model (SM) extension, which includes three\nfamilies of right-handed neutrinos with generic non-trivial flavor structure\nand an economic implementation of the invisible axion idea. We find that in\nsome regions of the parameter space this model accounts for all experimentally\nconfirmed pieces of evidence for physics beyond the SM: it explains neutrino\nmasses (via the type-I see-saw mechanism), dark matter, baryon asymmetry\n(through leptogenesis), solve the strong CP problem and has a stable\nelectroweak vacuum. The last property may allow us to identify the Higgs field\nwith the inflaton. \n\n"}
{"id": "1501.04565", "contents": "Title: Residual-driven online Generalized Multiscale Finite Element Methods Abstract: The construction of local reduced-order models via multiscale basis functions\nhas been an area of active research. In this paper, we propose online\nmultiscale basis functions which are constructed using the offline space and\nthe current residual. Online multiscale basis functions are constructed\nadaptively in some selected regions based on our error indicators. We derive an\nerror estimator which shows that one needs to have an offline space with\ncertain properties to guarantee that additional online multiscale basis\nfunction will decrease the error. This error decrease is independent of\nphysical parameters, such as the contrast and multiple scales in the problem.\nThe offline spaces are constructed using Generalized Multiscale Finite Element\nMethods (GMsFEM). We show that if one chooses a sufficient number of offline\nbasis functions, one can guarantee that additional online multiscale basis\nfunctions will reduce the error independent of contrast. We note that the\nconstruction of online basis functions is motivated by the fact that the\noffline space construction does not take into account distant effects. Using\nthe residual information, we can incorporate the distant information provided\nthe offline approximation satisfies certain properties. In the paper,\ntheoretical and numerical results are presented. Our numerical results show\nthat if the offline space is sufficiently large (in terms of the dimension)\nsuch that the coarse space contains all multiscale spectral basis functions\nthat correspond to small eigenvalues, then the error reduction by adding online\nmultiscale basis function is independent of the contrast. We discuss various\nways computing online multiscale basis functions which include a use of small\ndimensional offline spaces. \n\n"}
{"id": "1501.06176", "contents": "Title: Footprint of Triplet Scalar Dark Matter in Direct, Indirect Search and\n  Invisible Higgs Decay Abstract: In this talk, we will review Inert Triplet Model (ITM) which provide\ncandidate for dark matter (DM) particles. Then we study possible decays of\nHiggs boson to DM candidate and apply current experimental data for invisible\nHiggs decay to constrain parameter space of ITM. We also consider indirect\nsearch for DM and use FermiLAT data to put constraints on parameter space.\nUltimately we compare this limit with constraints provided by LUX experiment\nfor low mass DM and invisible Higgs decay. \n\n"}
{"id": "1501.06625", "contents": "Title: Accelerating Polynomial Homotopy Continuation on a Graphics Processing\n  Unit with Double Double and Quad Double Arithmetic Abstract: Numerical continuation methods track a solution path defined by a homotopy.\nThe systems we consider are defined by polynomials in several variables with\ncomplex coefficients. For larger dimensions and degrees, the numerical\nconditioning worsens and hardware double precision becomes often insufficient\nto reach the end of the solution path. With double double and quad double\narithmetic, we can solve larger problems that we could not solve with hardware\ndouble arithmetic, but at a higher computational cost. This cost overhead can\nbe compensated by acceleration on a Graphics Processing Unit (GPU). We describe\nour implementation and report on computational results on benchmark polynomial\nsystems. \n\n"}
{"id": "1501.07564", "contents": "Title: The Lyapunov matrix equation. Matrix analysis from a computational\n  perspective Abstract: Decay properties of the solution $X$ to the Lyapunov matrix equation $AX + X\nA^T = D$ are investigated. Their exploitation in the understanding of equation\nmatrix properties, and in the development of new numerical solution strategies\nwhen $D$ is not low rank but possibly sparse is also briefly discussed. \n\n"}
{"id": "1501.07665", "contents": "Title: Neutrino induced decoherence and variation in nuclear decay rates Abstract: Recent work has proposed that the interaction between ordinary matter and a\nstochastic gravitational background can lead to the decoherence of large\naggregates of ordinary matter. In this work we point out that these arguments\ncan be carried over to a stochastic neutrino background but with the Planck\nscale of the gravitational decoherence replaced by the weak scale. This implies\nthat it might be possible to observe such neutrino induced decoherence on a\nsmall, microscopic system rather than a macroscopic system as is the case for\ngravitationally induced decoherence. In particular we suggest that neutrino\ndecoherence could be linked with observed variations in the decay rates of\ncertain nuclei. Finally we point out that this proposed neutrino induced\ndecoherence can be considered the complement of the Mikheev-Smirnov-Wolfenstein\n(MSW) effect. \n\n"}
{"id": "1502.04309", "contents": "Title: Semi-Discrete approximation of Optimal Mass Transport Abstract: Optimal mass transport is described by an approximation of transport cost via\nsemi-discrete costs. The notions of optimal partition and optimal strong\npartition are given as well. We also suggest an algorithm for computation of\nOptimal Transport for general cost functions induced by an action, an\nasymptotic error estimate and several numerical examples of optimal partitions. \n\n"}
{"id": "1502.05528", "contents": "Title: Word series for dynamical systems and their numerical integrators Abstract: We study word series and extended word series, classes of formal series for\nthe analysis of some dynamical systems and their discretizations. These series\nare similar to but more compact than B-series. They may be composed among\nthemselves by means of a simple rule. While word series have appeared before in\nthe literature, extended word series are introduced in this paper. We exemplify\nthe use of extended word series by studying the reduction to normal form and\naveraging of some perturbed integrable problems. We also provide a detailed\nanalysis of the behaviour of splitting numerical methods for those problems. \n\n"}
{"id": "1502.05954", "contents": "Title: Convection-adapted BEM-based FEM Abstract: We present a new discretization method for homogeneous\nconvection-diffusion-reaction boundary value problems in 3D that is a\nnon-standard finite element method with PDE-harmonic shape functions on\npolyhedral elements. The element stiffness matrices are constructed by means of\nlocal boundary element techniques. Our method, which we refer to as a BEM-based\nFEM, can therefore be considered a local Trefftz method with element-wise\n(locally) PDE-harmonic shape functions. The Dirichlet boundary data for these\nshape functions is chosen according to a convection-adapted procedure which\nsolves projections of the PDE onto the edges and faces of the elements. This\nimproves the stability of the discretization method for convection-dominated\nproblems both when compared to a standard FEM and to previous BEM-based FEM\napproaches, as we demonstrate in several numerical experiments. \n\n"}
{"id": "1502.07301", "contents": "Title: Cosmic Strings and the Origin of Globular Clusters Abstract: We hypothesize that cosmic string loops are the seeds about which globular\nclusters accrete. Fixing the cosmic string tension by demanding that the peak\nin the distribution of masses of objects accreting onto string loops agrees\nwith the peak in the observed mass distribution of globular clusters in our\nMilky Way galaxy, we then compute the expected number density and mass function\nof globular clusters, and compare with observations. Our hypothesis naturally\nexplains why globular clusters are the oldest and most dense objects in a\ngalaxy, and why they are found in the halo of the galaxy. \n\n"}
{"id": "1503.00282", "contents": "Title: Constructive sparse trigonometric approximation for functions with small\n  mixed smoothness Abstract: The paper gives a constructive method, based on greedy algorithms, that\nprovides for the classes of functions with small mixed smoothness the best\npossible in the sense of order approximation error for the $m$-term\napproximation with respect to the trigonometric system. \n\n"}
{"id": "1503.02042", "contents": "Title: A Virtual Element Method for elastic and inelastic problems on polytope\n  meshes Abstract: We present a Virtual Element Method (VEM) for possibly nonlinear elastic and\ninelastic problems, mainly focusing on a small deformation regime. The\nnumerical scheme is based on a low-order approximation of the displacement\nfield, as well as a suitable treatment of the displacement gradient. The\nproposed method allows for general polygonal and polyhedral meshes, it is\nefficient in terms of number of applications of the constitutive law, and it\ncan make use of any standard black-box constitutive law algorithm. Some\ntheoretical results have been developed for the elastic case. Several numerical\nresults within the 2D setting are presented, and a brief discussion on the\nextension to large deformation problems is included. \n\n"}
{"id": "1503.04071", "contents": "Title: Pieces of the Flavour Puzzle Abstract: An overview of the flavour problem is presented, with emphasis on the\ntheoretical efforts to find a satisfactory description of fermion masses and\nmixing angles. \n\n"}
{"id": "1503.04632", "contents": "Title: The AFP and CT-PPS projects Abstract: We present the project to install new forward proton detectors in the CMS and\nATLAS experiments called PPS and AFP respectively. \n\n"}
{"id": "1503.06002", "contents": "Title: DAFNE and KLOE-2 Abstract: The DAFNE collider, located in the Frascati National Laboratories of INFN,\nhas two main rings, where electrons and positrons are stored to collide at a\ncenter of mass energy of 1.02 GeV, the phi resonance mass. KLOE-2 experiment is\nlocated at the collider interaction region. The detector is capable to observe\nand collect data coming from phi decay: charged and neutral kaon pairs, lighter\nunflavored mesons (eta, eta', f0, a0, omega/rho). In the first half of 2013 the\nKLOE detector has been upgraded inserting new detector layers in the inner part\nof the apparatus, around the interaction region in order to improve detector\nhermeticity and acceptance. The long shutdown has been used to undertake a\ngeneral consolidation program aimed at improving the DAFNE performances. This\ncontribution presents the phi-factory setup and the achieved performances in\nterms of beam currents, luminosity and related aspects together with the KLOE-2\nphysics program, upgrade status report and recent physics results. \n\n"}
{"id": "1503.06740", "contents": "Title: Analysis of the $\\Lambda_c(2625)$ and $\\Xi_c(2815)$ with QCD sum rules Abstract: In this article, we study the charmed baryon states $\\Lambda_c(2625)$ and\n$\\Xi_c(2815)$ with the spin-parity ${3\\over 2}^-$ by subtracting the\ncontributions from the corresponding charmed baryon states with the spin-parity\n${3\\over 2}^+$ using the QCD sum rules, and suggest a formula $\n\\mu=\\sqrt{M_{\\Lambda_c/\\Xi_c}^2-{\\mathbb{M}}_c^2}$ with the effective mass\n${\\mathbb{M}}_c=1.8\\,\\rm{GeV}$ to determine the energy scales of the QCD\nspectral densities, and make reasonable predictions for the masses and pole\nresidues. The numerical results indicate that the $\\Lambda_c(2625)$ and\n$\\Xi_c(2815)$ have at least two remarkable under-structures. \n\n"}
{"id": "1503.07085", "contents": "Title: TREX-DM: a low background Micromegas-based TPC for low mass WIMP\n  detection Abstract: Dark Matter experiments are recently focusing their detection techniques in\nlow-mass WIMPs, which requires the use of light elements and low energy\nthreshold. In this context, we present the TREX-DM experiment, a low background\nMicromegas-based TPC for low-mass WIMP detection. Its main goal is the\noperation of an active detection mass $\\sim$0.300 kg, with an energy threshold\nbelow 0.4 keVee and fully built with previously selected radiopure materials.\nThis article describes the actual setup, the first results of the comissioning\nin Ar+2\\%iC$_4$H$_{10}$ at 1.2 bar and the future updates for a possible\nphysics run at the Canfranc Underground Laboratory in 2016. A first background\nmodel is also presented, based on Geant4 simulations and a muon/electron\ndiscrimination method. In a conservative scenario, TREX-DM could be sensitive\nto DAMA/LIBRA and other hints of positive WIMPs signals, with some space for\nimprovement with a neutron/electron discrimination method or the use of other\nlight gases. \n\n"}
{"id": "1503.07152", "contents": "Title: Compressing rank-structured matrices via randomized sampling Abstract: Randomized sampling has recently been proven a highly efficient technique for\ncomputing approximate factorizations of matrices that have low numerical rank.\nThis paper describes an extension of such techniques to a wider class of\nmatrices that are not themselves rank-deficient, but have off-diagonal blocks\nthat are; specifically, the classes of so called \\textit{Hierarchically\nOff-Diagonal Low Rank (HODLR)} matrices and \\textit{Hierarchically Block\nSeparable (HBS)} matrices. Such matrices arise frequently in numerical analysis\nand signal processing, in particular in the construction of fast methods for\nsolving differential and integral equations numerically. These structures admit\nalgebraic operations (matrix-vector multiplications, matrix factorizations,\nmatrix inversion, etc.) to be performed very rapidly; but only once a\ndata-sparse representation of the matrix has been constructed. How to rapidly\ncompute this representation in the first place is much less well understood.\nThe present paper demonstrates that if an $N\\times N$ matrix can be applied to\na vector in $O(N)$ time, and if the ranks of the off-diagonal blocks are\nbounded by an integer $k$, then the cost for constructing a HODLR\nrepresentation is $O(k^{2}\\,N\\,(\\log N)^{2})$, and the cost for constructing an\nHBS representation is $O(k^{2}\\,N\\,\\log N)$. The point is that when legacy\ncodes (based on, e.g., the Fast Multipole Method) can be used for the fast\nmatrix-vector multiply, the proposed algorithm can be used to obtain the\ndata-sparse representation of the matrix, and then well-established techniques\nfor HODLR/HBS matrices can be used to invert or factor the matrix. The proposed\nscheme is also useful in simplifying the implementation of certain operations\non rank-structured matrices such as the matrix-matrix multiplication, low-rank\nupdate, addition, etc. \n\n"}
{"id": "1504.00001", "contents": "Title: Measurement of spark probability of GEM detector for CBM muon chamber\n  (MUCH) Abstract: The stability of triple GEM detector setups in an environment of high\nenergetic showers is studied. To this end the spark probability in a shower\nenvironment is compared to the spark probability in a pion beam. \n\n"}
{"id": "1504.03997", "contents": "Title: Numerical approximation of positive power curvature flow via\n  deterministic games Abstract: We approximate the level set solution for the motion of an embedded closed\ncurve in the plane with normal speed $\\max(0, \\kappa)^{\\ga}$ where $\\kappa$ is\nthe curvature of the curve and $\\frac{1}{3}<\\ga<1$ by the value functions of a\nfamily of deterministic two person games. We show convergence of the value\nfunctions to the viscosity solution of the level set equation and propose a\nnumerical scheme for the calculation of the value function. \n\n"}
{"id": "1504.04023", "contents": "Title: Investigation of a direction sensitive sapphire detector stack at the 5\n  GeV electron beam at DESY-II Abstract: Extremely radiation hard sensors are needed in particle physics experiments\nto instrument the region near the beam pipe. Examples are beam halo and beam\nloss monitors at the Large Hadron Collider, FLASH or XFEL. Currently artificial\ndiamond sensors are widely used. In this paper single crystal sapphire sensors\nare considered as a promising alternative. Industrially grown sapphire wafers\nare available in large sizes, are of low cost and, like diamond sensors, can be\noperated without cooling. Here we present results of an irradiation study done\nwith sapphire sensors in a high intensity low energy electron beam. Then, a\nmultichannel direction-sensitive sapphire detector stack is described. It\ncomprises 8 sapphire plates of 1 cm^2 size and 525 micro m thickness,\nmetallized on both sides, and apposed to form a stack. Each second metal layer\nis supplied with a bias voltage, and the layers in between are connected to\ncharge-sensitive preamplifiers. The performance of the detector was studied in\na 5 GeV electron beam. The charge collection efficiency measured as a function\nof the bias voltage rises with the voltage, reaching about 10 % at 950 V. The\nsignal size obtained from electrons crossing the stack at this voltage is about\n22000 e, where e is the unit charge.\n  The signal size is measured as a function of the hit position, showing\nvariations of up to 20 % in the direction perpendicular to the beam and to the\nelectric field. The measurement of the signal size as a function of the\ncoordinate parallel to the electric field confirms the prediction that mainly\nelectrons contribute to the signal. Also evidence for the presence of a\npolarisation field was observed. \n\n"}
{"id": "1504.04417", "contents": "Title: An online generalized multiscale discontinuous Galerkin method (GMsDGM)\n  for flows in heterogeneous media Abstract: Offline computation is an essential component in most multiscale model\nreduction techniques. However, there are multiscale problems in which offline\nprocedure is insufficient to give accurate representations of solutions, due to\nthe fact that offline computations are typically performed locally and global\ninformation is missing in these offline information. To tackle this difficulty,\nwe develop an online local adaptivity technique for local multiscale model\nreduction problems. We design new online basis functions within Discontinuous\nGalerkin method based on local residuals and some optimally estimates. The\nresulting basis functions are able to capture the solution efficiently and\naccurately, and are added to the approximation iteratively. Moreover, we show\nthat the iterative procedure is convergent with a rate independent of physical\nscales if the initial space is chosen carefully. Our analysis also gives a\nguideline on how to choose the initial space. We present some numerical\nexamples to show the performance of the proposed method. \n\n"}
{"id": "1504.05030", "contents": "Title: The Cauchy-Lagrangian method for numerical analysis of Euler flow Abstract: A novel semi-Lagrangian method is introduced to solve numerically the Euler\nequation for ideal incompressible flow in arbitrary space dimension. It\nexploits the time-analyticity of fluid particle trajectories and requires, in\nprinciple, only limited spatial smoothness of the initial data. Efficient\ngeneration of high-order time-Taylor coefficients is made possible by a\nrecurrence relation that follows from the Cauchy invariants formulation of the\nEuler equation (Zheligovsky & Frisch, J. Fluid Mech. 2014, 749, 404-430).\nTruncated time-Taylor series of very high order allow the use of time steps\nvastly exceeding the Courant-Friedrichs-Lewy limit, without compromising the\naccuracy of the solution. Tests performed on the two-dimensional Euler equation\nindicate that the Cauchy-Lagrangian method is more - and occasionally much more\n- efficient and less prone to instability than Eulerian Runge-Kutta methods,\nand less prone to rapid growth of rounding errors than the high-order Eulerian\ntime-Taylor algorithm. We also develop tools of analysis adapted to the\nCauchy-Lagrangian method, such as the monitoring of the radius of convergence\nof the time-Taylor series. Certain other fluid equations can be handled\nsimilarly. \n\n"}
{"id": "1504.06222", "contents": "Title: Dark Radiation from a hidden U(1) Abstract: We discuss the impact of a hidden sector consisting of Minicharged Particles\n(MCPs) and massless hidden photons on the expansion history of our Universe. We\npresent parameter scans for the amount of extra relativistic particles (Neff)\nand the abundance of light nuclei for fermionic MCPs with masses between ~100\nkeV and 10 GeV and minicharges in the range 10^(-11)-1. Current CMB and BBN\ndata significantly constrain the available parameter space of MCPs. The shown\nresults are a valuable indicator for future experimental searches and are\npresented in a flexible way so that more accurate results on Neff can be easily\ninterpreted. \n\n"}
{"id": "1504.06289", "contents": "Title: Tensor Numerical Methods in Quantum Chemistry: from Hartree-Fock Energy\n  to Excited States Abstract: We resume the recent successes of the grid-based tensor numerical methods and\ndiscuss their prospects in real-space electronic structure calculations. These\nmethods, based on the low-rank representation of the multidimensional functions\nand integral operators, led to entirely grid-based tensor-structured 3D\nHartree-Fock eigenvalue solver. It benefits from tensor calculation of the core\nHamiltonian and two-electron integrals (TEI) in $O(n\\log n)$ complexity using\nthe rank-structured approximation of basis functions, electron densities and\nconvolution integral operators all represented on 3D $n\\times n\\times n $\nCartesian grids. The algorithm for calculating TEI tensor in a form of the\nCholesky decomposition is based on multiple factorizations using algebraic 1D\n``density fitting`` scheme. The basis functions are not restricted to separable\nGaussians, since the analytical integration is substituted by high-precision\ntensor-structured numerical quadratures. The tensor approaches to\npost-Hartree-Fock calculations for the MP2 energy correction and for the\nBethe-Salpeter excited states, based on using low-rank factorizations and the\nreduced basis method, were recently introduced. Another direction is related to\nthe recent attempts to develop a tensor-based Hartree-Fock numerical scheme for\nfinite lattice-structured systems, where one of the numerical challenges is the\nsummation of electrostatic potentials of a large number of nuclei. The 3D\ngrid-based tensor method for calculation of a potential sum on a $L\\times\nL\\times L$ lattice manifests the linear in $L$ computational work, $O(L)$,\ninstead of the usual $O(L^3 \\log L)$ scaling by the Ewald-type approaches. \n\n"}
{"id": "1504.06346", "contents": "Title: $D^+ \\to K^- \\pi^+ \\pi^+$ - the weak vector current Abstract: Studies of D and B mesons decays into hadrons have been used to test the\nstandard model in the last fifteen years. A heavy meson decay involves the\ncombined effects of a primary weak vertex and subsequent hadronic final state\ninteractions, which determine the shapes of Dalitz plots. The fact that final\nproducts involve light mesons indicates that the QCD vacuum is an active part\nof the problem. This makes the description of these processes rather involved\nand, in spite of its importance, phenomenological analyses tend to rely on\ncrude models. Our group produced, some time ago, a schematic calculation of the\ndecay $D^+ \\to K^- \\pi^+ \\pi^+$, which provided a reasonable description of\ndata. Its main assumption was the dominance of the weak vector-current, which\nyields a non-factorizable interaction. Here we refine that calculation by\nincluding the correct momentum dependence of the weak vertex and extending the\nenergy ranges of $\\pi\\pi$ and $K\\pi$ subamplitudes present into the problem.\nThese new features make the present treatment more realistic and bring theory\ncloser to data. \n\n"}
{"id": "1504.06520", "contents": "Title: Muon-induced background to proton decay in the $p \\rightarrow K^{+}\\nu$\n  decay channel with large underground liquid argon TPC detectors Abstract: Large liquid argon TPC detector programs such as LBNE and LAGUNA-LBNO will be\nable to make measurements of the proton lifetime which will outperform\nCherenkov detectors in the proton decay channel $p \\rightarrow K^{+}\\nu$. At\nthe large depths which are proposed for such experiments, a non-negligible\nsource of isolated charged kaons may be produced in the showers of cosmogenic\nmuons. We present an estimate of the cosmogenic muon background to proton decay\nin the $p \\rightarrow K^{+}\\nu$ channel. The simulation of muon transport to a\ndepth of 4 km w.e, is performed in the MUSIC framework and the propagation of\nmuons and secondary particles through to a cylindrical 20 kt LAr target is\nperformed using Geant4. An exposure time of 100 years is considered, with a\nrate of $< 0.0012$ events/kt/year at 90$\\%$ CL predicted from our simulations. \n\n"}
{"id": "1504.07230", "contents": "Title: Implications for dark matter annihilation from the AMS-02 $\\bar{p}/p$\n  ratio Abstract: The AMS-02 collaboration has just released the cosmic antiproton to proton\nratio $\\bar{p}/p$ with a high precision up to $\\sim 450$ GeV. In this work, we\ncalculate the secondary antiprotons generated by cosmic ray interactions with\nthe interstellar medium taking into account the uncertainties from the cosmic\nray propagation. The $\\bar{p}/p$ ratio predicted by these processes shows some\ntension with the AMS-02 data in some regions of propagation parameters, but the\nexcess is not significant. We then try to derive upper bounds on the dark\nmatter annihilation cross section from the $\\bar{p}/p$ data or signal regions\nfavored by the data. It is shown that the constraint derived by the AMS-02 data\nis similar to that from Fermi-LAT observations of dwarf galaxies. The signal\nregion for dark matter is usually required $m_\\chi \\sim O(10)$ TeV and\n$\\left<\\sigma v\\right>\\sim\\mathcal{O}(10^{-23})~\\cm^3~\\sec^{-1}$. \n\n"}
{"id": "1505.00042", "contents": "Title: Construction of the CHIPS-M prototype and simulations of a 10 kiloton\n  module Abstract: During the summer of 2014, the CHIPS collaboration constructed and deployed\nCHIPS-M, a 26 ton prototype water Cherenkov detector in a flooded mine pit in\nNorthern Minnesota, 7mrad off-axis from the NuMI neutrino beam. The detector\nwill be recovered in summer 2015 after taking cosmic ray data throughout the\nwinter to test the structure and materials, and the water filtration and\npumping system. Geant4 simulations of generic water Cherenkov detectors with a\nvariety of PMT types and layouts will be used to guide the design of a 10\nkiloton module, intended to provide complementary information to current\nexperiments on \\delta_{CP}, and chart a course towards cheaper large neutrino\ndetectors. \n\n"}
{"id": "1505.01229", "contents": "Title: Discretization of the Poisson equation with non-smooth data and emphasis\n  on non-convex domains Abstract: Several approaches are discussed how to understand the solution of the\nDirichlet problem for the Poisson equation when the Dirichlet data are\nnon-smooth such as if they are in $L^2$ only. For the method of transposition\n(sometimes called very weak formulation) three spaces for the test functions\nare considered, and a regularity result is proved. An approach of Berggren is\nrecovered as the method of transposition with the second variant of test\nfunctions. A further concept is the regularization of the boundary data\ncombined with the weak solution of the regularized problem. The effect of the\nregularization error is studied. The regularization approach is the simplest to\ndiscretize. The discretization error is estimated for a sequence of\nquasi-uniform meshes. Since this approach turns out to be equivalent to\nBerggren's discretization his error estimates are rendered more precisely.\nNumerical tests show that the error estimates are sharp, in particular that the\norder becomes arbitrarily small when the maximal interior angle of the domain\ntends to $2\\pi$. \n\n"}
{"id": "1505.01869", "contents": "Title: Modeling of heavy-flavor pair correlations in Au-Au collisions at 200 A\n  GeV at the BNL Relativistic Heavy Ion Collider Abstract: We study the nuclear modification of angular and momentum correlations\nbetween heavy quark pairs in ultrarelativistic heavy-ion collisions. The\nevolution of heavy quarks inside the thermalized medium is described via a\nmodified Langevin approach that incorporates both elastic and inelastic\ninteractions with the medium constituents. The spacetime evolution of the\nfireball is obtained from a (2+1)-dimensional viscous hydrodynamics simulation.\nThe hadronization of heavy quarks is performed utilizing a hybrid model of\nfragmentation and coalescence. Our results show that the nuclear modification\nof the transverse momentum imbalance of D\\bar{D} pairs reflects the total\nenergy loss experienced by the heavy quarks and may help us probe specific\nregions of the medium. The angular correlation of heavy flavor pairs,\nespecially in the low to intermediate transverse momentum regime, is sensitive\nto the detailed energy loss mechanism of heavy quarks inside the QGP. \n\n"}
{"id": "1505.02003", "contents": "Title: Super-polynomial convergence and tractability of multivariate\n  integration for infinitely times differentiable functions Abstract: We investigate multivariate integration for a space of infinitely times\ndifferentiable functions $\\mathcal{F}_{s, \\boldsymbol{u}} := \\{f \\in C^\\infty\n[0,1]^s \\mid \\| f \\|_{\\mathcal{F}_{s, \\boldsymbol{u}}} < \\infty \\}$, where $\\|\nf \\|_{\\mathcal{F}_{s, \\boldsymbol{u}}} := \\sup_{\\boldsymbol{\\alpha} =\n(\\alpha_1, \\dots, \\alpha_s) \\in \\mathbb{N}_0^s}\n\\|f^{(\\boldsymbol{\\alpha})}\\|_{L^1}/\\prod_{j=1}^s u_j^{\\alpha_j}$,\n$f^{(\\boldsymbol{\\alpha})} := \\frac{\\partial^{|\\boldsymbol{\\alpha}|}}{\\partial\nx_1^{\\alpha_1} \\cdots \\partial x_s^{\\alpha_s}}f$ and $\\boldsymbol{u} =\n\\{u_j\\}_{j \\geq 1}$ is a sequence of positive decreasing weights. Let $e(n,s)$\nbe the minimal worst-case error of all algorithms that use $n$ function values\nin the $s$-variate case. We prove that for any $\\boldsymbol{u}$ and $s$\nconsidered $e(n,s) \\leq C(s) \\exp(-c(s)(\\log{n})^2)$ holds for all $n$, where\n$C(s)$ and $c(s)$ are constants which may depend on $s$. Further we show that\nif the weights $\\boldsymbol{u}$ decay sufficiently fast then there exist some\n$1 < p < 2$ and absolute constants $C$ and $c$ such that $e(n,s) \\leq C\n\\exp(-c(\\log{n})^p)$ holds for all $s$ and $n$. These bounds are attained by\nquasi-Monte Carlo integration using digital nets. These convergence and\ntractability results come from those for the Walsh space into which\n$\\mathcal{F}_{s, \\boldsymbol{u}}$ is embedded. \n\n"}
{"id": "1505.02763", "contents": "Title: Resummation effects in forward production of Z0+jet at LHC Abstract: We calculate several differential cross sections for Z0 and high-pT jet\nproduction in the forward rapidity region at the LHC using the hybrid High\nEnergy Factorization. We test various unintegrated gluon distributions\ninvolving subleading BFKL effects (such as kinematic constraint, running strong\ncoupling and DGLAP correction) and compare the results with experimental data\nobtained by the LHCb experiment. We find that the hard scale dependence of\nunintegrated gluon distributions, which effectively resums the Sudakov-type\nlogarithms on the top of the resummation of the small x logarithms, is\nessential to describe the normalized azimuthal decorrelations between the\nZ0-boson and the jet. \n\n"}
{"id": "1505.03137", "contents": "Title: Massively Parallel Computing at the Large Hadron Collider up to the\n  HL-LHC Abstract: As the Large Hadron Collider (LHC) continues its upward progression in energy\nand luminosity towards the planned High-Luminosity LHC (HL-LHC) in 2025, the\nchallenges of the experiments in processing increasingly complex events will\nalso continue to increase. Improvements in computing technologies and\nalgorithms will be a key part of the advances necessary to meet this challenge.\nParallel computing techniques, especially those using massively parallel\ncomputing (MPC), promise to be a significant part of this effort. In these\nproceedings, we discuss these algorithms in the specific context of a\nparticularly important problem: the reconstruction of charged particle tracks\nin the trigger algorithms in an experiment, in which high computing performance\nis critical for executing the track reconstruction in the available time. We\ndiscuss some areas where parallel computing has already shown benefits to the\nLHC experiments, and also demonstrate how a MPC-based trigger at the CMS\nexperiment could not only improve performance, but also extend the reach of the\nCMS trigger system to capture events which are currently not practical to\nreconstruct at the trigger level. \n\n"}
{"id": "1505.03585", "contents": "Title: Measurement of scintillation and ionization yield with high-pressure\n  gaseous mixtures of Xe and TMA for improved neutrinoless double beta decay\n  and dark matter searches Abstract: Liquid Xe TPCs are among the most popular choices for double beta decay and\nWIMP dark matter searches. Gaseous Xe has intrinsic advantages when compared to\nLiquid Xe, specifically, tracking capability and better energy resolution for\ndouble beta decay searches. The performance of gaseous Xe can be further\nimproved by molecular additives such as trimethylamine(TMA), which are expected\nto (1) cool down the ionization electrons, (2) convert Xe excitation energy to\nTMA ionizations through Penning transfer, and (3) produce scintillation and\nelectroluminescence light in a more easily detectable wavelength (300 nm).\nThese features may provide better tracking and energy resolution for\ndouble-beta decay searches. They are also expected to enhance columnar\nrecombination for nuclear recoils, which can be used for searches for WIMP dark\nmatter with directional sensitivity. We constructed a test ionization chamber\nand successfully measured scintillation and ionization yields at high precision\nwith various Xe and TMA mixtures and pressures. We observed the Penning effect\nand an increase in recombination with the addition of TMA. However, many\nundesired features for dark matter searches, such as strong suppression of the\nscintillation light and no sign of recombination light, were also found. This\nwork has been carried out within the context of the NEXT collaboration. \n\n"}
{"id": "1505.05541", "contents": "Title: QM/MM methods for crystalline defects. Part 1: Locality of the tight\n  binding model Abstract: The tight binding model is a minimal electronic structure model for molecular\nmodelling and simulation. We show that the total energy in this model can be\ndecomposed into site energies, that is, into contributions from each atomic\nsite whose influence on their environment decays exponentially. This result\nlays the foundation for a rigorous analysis of QM/MM coupling schemes. \n\n"}
{"id": "1505.07865", "contents": "Title: An Immersed Boundary Method for Rigid Bodies Abstract: We develop an immersed boundary (IB) method for modeling flows around fixed\nor moving rigid bodies that is suitable for a broad range of Reynolds numbers,\nincluding steady Stokes flow. The spatio-temporal discretization of the fluid\nequations is based on a standard staggered-grid approach. Fluid-body\ninteraction is handled using Peskin's IB method; however, unlike existing IB\napproaches to such problems, we do not rely on penalty or fractional-step\nformulations. Instead, we use an unsplit scheme that ensures the no-slip\nconstraint is enforced exactly in terms of the Lagrangian velocity field\nevaluated at the IB markers. Fractional-step approaches, by contrast, can\nimpose such constraints only approximately. Imposing these constraints exactly\nrequires the solution of a large linear system that includes the fluid velocity\nand pressure as well as Lagrange multiplier forces that impose the motion of\nthe body. To solve this system efficiently, we develop a preconditioner for the\nconstrained IB formulation that is based on an analytical approximation to the\nSchur complement. This approach is enabled by the near translational and\nrotational invariance of Peskin's IB method. We demonstrate that only a few\ncycles of a geometric multigrid method for the fluid equations are required in\neach application of the preconditioner, and we demonstrate robust convergence\nof the overall Krylov solver despite the approximations made in the\npreconditioner. We apply the method to a number of test problems at zero and\nfinite Reynolds numbers, and we demonstrate first-order convergence of the\nmethod to several analytical solutions and benchmark computations. \n\n"}
{"id": "1506.00359", "contents": "Title: Towards the Natural Gauge Mediation Abstract: The sweet spot supersymmetry (SUSY) solves the mu problem in the Minimal\nSupersymmetric Standard Model (MSSM) with gauge mediated SUSY breaking (GMSB)\nvia the generalized Giudice-Masiero (GM) mechanism where only the mu-term and\nsoft Higgs masses are generated at the unification scale of the Grand Unified\nTheory (GUT) due to the approximate PQ symmetry. Because all the other SUSY\nbreaking soft terms are generated via the GMSB below the GUT scale, there\nexists SUSY electroweak (EW) fine-tuning problem to explain the 125 GeV Higgs\nboson mass due to small trilinear soft term. Thus, to explain the Higgs boson\nmass, we propose the GMSB with both the generalized GM mechanism and\nHiggs-messenger interactions. The renormalization group equations are runnings\nfrom the GUT scale down to EW scale. So the EW symmetry breaking can be\nrealized easier. We can keep the gauge coupling unification and solution to the\nflavor problem in the GMSB, as well as solve the \\mu/B_{\\mu}-problem. Moreover,\nthere are only five free parameters in our model. So we can determine the\ncharacteristic low energy spectra and explore its distinct phenomenology. The\nlow-scale fine-tuning measure can be as low as 20 with the light stop mass\nbelow 1 TeV and gluino mass below 2 TeV. The gravitino dark matter can come\nfrom a thermal production with the correct relic density and be consistent with\nthe thermal leptogenesis. Because gluino and stop can be relatively light in\nour model, how to search for such GMSB at the upcoming run II of the LHC\nexperiment could be very interesting. \n\n"}
{"id": "1506.00783", "contents": "Title: Shape Analysis on Lie Groups with Applications in Computer Animation Abstract: Shape analysis methods have in the past few years become very popular, both\nfor theoretical exploration as well as from an application point of view.\nOriginally developed for planar curves, these methods have been expanded to\nhigher dimensional curves, surfaces, activities, character motions and many\nother objects. In this paper, we develop a framework for shape analysis of\ncurves in Lie groups for problems of computer animations. In particular, we\nwill use these methods to find cyclic approximations of non-cyclic character\nanimations and interpolate between existing animations to generate new ones. \n\n"}
{"id": "1506.01043", "contents": "Title: Relationships between different types of initial conditions for\n  simultaneous root finding methods Abstract: The construction of initial conditions of an iterative method is one of the\nmost important problems in solving nonlinear equations. In this paper, we\nobtain relationships between different types of initial conditions that\nguarantee the convergence of iterative methods for simultaneous finding all\nzeros of a polynomial. In particular, we show that any local convergence\ntheorem for a simultaneous method can be converted into a convergence theorem\nwith computationally verifiable initial conditions which is of practical\nimportance. Thus, we propose a new approach for obtaining semilocal convergence\nresults for simultaneous methods via local convergence results. \n\n"}
{"id": "1506.02504", "contents": "Title: Ultrarelativistic Decoupling Transformation for Generalized Dirac\n  Equations Abstract: The Foldy--Wouthuysen transformation is known to uncover the nonrelativistic\nlimit of a generalized Dirac Hamiltonian, lending an intuitive physical\ninterpretation to the effective operators within Schr\\\"{o}dinger--Pauli theory.\nWe here discuss the opposite, ultrarelativistic limit which requires the use of\na fundamentally different expansion where the leading kinetic term in the Dirac\nequation is perturbed by the mass of the particle and other interaction\n(potential) terms, rather than vice versa. The ultrarelativistic decoupling\ntransformation is applied to free Dirac particles (in the Weyl basis) and to\nhigh-energy tachyons, which are faster-than-light particles described by a\nfully Lorentz-covariant equation. The effective gravitational interactions are\nfound. For tachyons, the dominant gravitational interaction term in the\nhigh-energy limit is shown to be attractive, and equal to the leading term for\nsubluminal Dirac particles (tardyons) in the high-energy limit. \n\n"}
{"id": "1506.03147", "contents": "Title: Continuation of Point Clouds via Persistence Diagrams Abstract: In this paper, we present a mathematical and algorithmic framework for the\ncontinuation of point clouds by persistence diagrams. A key property used in\nthe method is that the persistence map, which assigns a persistence diagram to\na point cloud, is differentiable. This allows us to apply the Newton-Raphson\ncontinuation method in this setting. Given an original point cloud $P$, its\npersistence diagram $D$, and a target persistence diagram $D'$, we gradually\nmove from $D$ to $D'$, by successively computing intermediate point clouds\nuntil we finally find a point cloud $P'$ having $D'$ as its persistence\ndiagram. Our method can be applied to a wide variety of situations in\ntopological data analysis where it is necessary to solve an inverse problem,\nfrom persistence diagrams to point cloud data. \n\n"}
{"id": "1506.03606", "contents": "Title: A convergent point integral method for isotropic elliptic equations on\n  point cloud Abstract: In this paper, we propose a numerical method to solve isotropic elliptic\nequations on point cloud by generalizing the point integral method. The idea of\nthe point integral method is to approximate the differential operators by\nintegral operators and discretize the corresponding integral equation on point\ncloud. The key step is to get the integral approximation. In this paper, with\nproper kernel function, we get an integral approximation for the elliptic\noperators with isotropic coefficients. Moreover, the integral approximation has\nbeen proved to keep the coercivity of the original elliptic operator. The\nconvergence of the point integral method is also proved. \n\n"}
{"id": "1506.08600", "contents": "Title: Approximation in Hermite spaces of smooth functions Abstract: We consider $\\mathbb{L}_2$-approximation of elements of a Hermite space of\nanalytic functions over $\\mathbb{R}^s$. The Hermite space is a weighted\nreproducing kernel Hilbert space of real valued functions for which the Hermite\ncoefficients decay exponentially fast. The weights are defined in terms of two\nsequences $\\boldsymbol{a} = \\{a_j\\}$ and $\\boldsymbol{b} = \\{b_j\\}$ of positive\nreal numbers. We study the $n$th minimal worst-case error $e(n,{\\rm\nAPP}_s;\\Lambda^{{\\rm std}})$ of all algorithms that use $n$ information\nevaluations from the class $\\Lambda^{{\\rm std}}$ which only allows function\nevaluations to be used.\n  We study (uniform) exponential convergence of the $n$th minimal worst-case\nerror, which means that $e(n,{\\rm APP}_s; \\Lambda^{{\\rm std}})$ converges to\nzero exponentially fast with increasing $n$. Furthermore, we consider how the\nerror depends on the dimension $s$. To this end, we study the minimal number of\ninformation evaluations needed to compute an $\\varepsilon$-approximation by\nconsidering several notions of tractability which are defined with respect to\n$s$ and $\\log \\varepsilon^{-1}$. We derive necessary and sufficient conditions\non the sequences $\\boldsymbol{a}$ and $\\boldsymbol{b}$ for obtaining\nexponential error convergence, and also for obtaining the various notions of\ntractability. It turns out that the conditions on the weight sequences are\nalmost the same as for the information class $\\Lambda^{{\\rm all}}$ which uses\nall linear functionals. The results are also constructive as the considered\nalgorithms are based on tensor products of Gauss-Hermite rules for multivariate\nintegration. The obtained results are compared with the analogous results for\nintegration in the same Hermite space. This allows us to give a new sufficient\ncondition for EC-weak tractability for integration. \n\n"}
{"id": "1506.09186", "contents": "Title: Nonperturbative pair production in interpolating fields Abstract: We compare the effects of timelike, lightlike and spacelike one-dimensional\ninhomogeneities on the probability of nonperturbative pair production in strong\nfields. Using interpolating coordinates we give a unifying picture in which the\neffect of the inhomogeneity is encoded in branch cuts and poles circulated by\ncomplex worldline instantons. For spacelike inhomogeneities the length of the\ncut is related to the existence of critical points, while for lightlike\ninhomogeneities the cut contracts to a pole and the instantons become\ncontractable to points, leading to simplifications particular to the lightlike\ncase. We calculate the effective action in fields with up to three nonzero\ncomponents, and investigate its behaviour under changes in field dependence. \n\n"}
{"id": "1507.01711", "contents": "Title: Quadratic Convergence of Levenberg-Marquardt Method for Elliptic and\n  Parabolic Inverse Robin Problems Abstract: We study the Levenberg-Marquardt (L-M) method for solving the highly\nnonlinear and ill-posed inverse problem of identifying the Robin coefficients\nin elliptic and parabolic systems. The L-M method transforms the Tikhonov\nregularized nonlinear non-convex minimizations into convex minimizations. And\nthe quadratic convergence of the L-M method is rigorously established for the\nnonlinear elliptic and parabolic inverse problems for the first time, under a\nsimple novel adaptive strategy for selecting regularization parameters during\nthe L-M iteration. Then the surrogate functional approach is adopted to solve\nthe strongly ill-conditioned convex minimizations, resulting in an explicit\nsolution of the minimisation at each L-M iteration for both the elliptic and\nparabolic cases. Numerical experiments are provided to demonstrate the accuracy\nand efficiency of the methods. \n\n"}
{"id": "1507.01914", "contents": "Title: Diboson resonant production in non-custodial composite Higgs models Abstract: We show that the recently reported excess in resonant diboson production can\nbe explained in the context of non-custodial composite Higgs models. Dibosons\nare generated via the s-channel exchange of massive vector bosons present in\nthese models. We discuss the compatibility of the signal excess with other\ndiboson experimental searches. We also discuss the tension between diboson\nproduction and other experimental tests of the model that include electroweak\nprecision data, dilepton, dijet and top pair production and show that there is\na region of parameter space in which they are all compatible with the excess. \n\n"}
{"id": "1507.02067", "contents": "Title: On the size of the largest empty box amidst a point set Abstract: The problem of finding the largest empty axis-parallel box amidst a point\nconfiguration is a classical problem in computational geometry. It is known\nthat the volume of the largest empty box is of asymptotic order $1/n$ for\n$n\\to\\infty$ and fixed dimension $d$. However, it is natural to assume that the\nvolume of the largest empty box increases as $d$ gets larger. In the present\npaper we prove that this actually is the case: for every set of $n$ points in\n$[0, 1]^d$ there exists an empty box of volume at least $c_d n^{-1}$ , where\n$c_d \\to \\infty$ as $d\\to \\infty$. More precisely, $c_d$ is at least of order\nroughly $\\log d$. \n\n"}
{"id": "1507.03074", "contents": "Title: GPGPU for track finding in High Energy Physics Abstract: The LHC experiments are designed to detect large amount of physics events\nproduced with a very high rate. Considering the future upgrades, the data\nacquisition rate will become even higher and new computing paradigms must be\nadopted for fast data-processing: General Purpose Graphics Processing Units\n(GPGPU) is a novel approach based on massive parallel computing. The intense\ncomputation power provided by Graphics Processing Units (GPU) is expected to\nreduce the computation time and to speed-up the low-latency applications used\nfor fast decision taking. In particular, this approach could be hence used for\nhigh-level triggering in very complex environments, like the typical inner\ntracking systems of the multi-purpose experiments at LHC, where a large number\nof charged particle tracks will be produced with the luminosity upgrade. In\nthis article we discuss a track pattern recognition algorithm based on the\nHough Transform, where a parallel approach is expected to reduce dramatically\nthe execution time. \n\n"}
{"id": "1507.03364", "contents": "Title: Projection methods for ill-posed problems revisited Abstract: The discretization of least-squares problems for linear ill-posed operator\nequations in Hilbert spaces is considered. The main subject of this article\nconcerns conditions for convergence of the associated discretized minimum-norm\nleast-squares solution to the exact solution using exact attainable data. The\ntwo cases of global convergence (convergence for all exact solution) or local\nconvergence (convergence for a specific exact solution) are investigated. We\nreview the existing results and prove new equivalent condition when the\ndiscretized solution always converges to the exact solution. An important tool\nis to recognize the discrete solution operator as oblique projection. Hence,\nglobal convergence can be characterized by certain subspaces having uniformly\nbounded angles. We furthermore derive practically useful conditions when this\nholds and put them into the context of known results. For local convergence we\ngeneralize results on the characterization of weak or strong convergence and\nstate some new sufficient conditions. We furthermore provide an example of a\nbounded sequence of discretized solutions which does not converge at all, not\neven weakly. \n\n"}
{"id": "1507.03948", "contents": "Title: Energy source for the magnetic field growth in magnetars driven by the\n  electron-nucleon interaction Abstract: We study the magnetic field generation in a neutron star within the model\nbased on the magnetic field instability in the nuclear matter owing to the\nelectron-nucleon parity violating interaction. We suggest that the growing\nmagnetic field takes the energy from thermal background fermions in the neutron\nstar matter. The system of kinetic equations for the spectra of the magnetic\nhelicity density and magnetic energy density as well as the chiral imbalance\nare solved numerically accounting for this energy source. We obtain that, for\nthe initial conditions corresponding to a typical neutron star, the large scale\nmagnetic field $\\sim 10^{15}\\thinspace\\text{G}$ is generated during\n$(10^4-10^5)\\thinspace\\text{yr}$. We suggest that the proposed model describes\nstrong magnetic fields observed in magnetars. \n\n"}
{"id": "1507.03971", "contents": "Title: On numerical study of the discrete spectrum of a two-dimensional\n  Schrodinger operator with soliton potential Abstract: The discrete spectra of certain two-dimensional Schrodinger operators are\nnumerically calculated. These operators have interesting spectral properties,\ni.e. their kernels are multi-dimensional and the deformations of potentials via\nthe Novikov-Veselov equation (a two-dimensional generalization of the\nKorteweg-de Vries equation) lead to blowups, and are obtained by the Moutard\ntransformation. The calculations supply the numerical evidence for certain\nstatements on integrable systems related to the 2D Schrodinger operator. The\nnumerical scheme is applicable to a general 2D Schrodinger operator with fast\ndecaying potential. \n\n"}
{"id": "1507.04011", "contents": "Title: Dirichlet-Neumann Waveform Relaxation Method for the 1D and 2D Heat and\n  Wave Equations in Multiple subdomains Abstract: We present a Waveform Relaxation (WR) version of the Dirichlet-Neumann\nalgorithm, formulated specially for multiple subdomains splitting for general\nparabolic and hyperbolic problems. This method is based on a non-overlapping\nspatial domain decomposition, and the iteration involves subdomain solves in\nspace-time with corresponding interface condition, and finally organize an\nexchange of information between neighboring subdomains. Using a Fourier-Laplace\ntransform argument, for a particular relaxation parameter, we present\nconvergence analysis of the algorithm for the heat and wave equations. We prove\nsuperlinear convergence for finite time window in case of the heat equation,\nand finite step convergence for the wave equation. The convergence behavior\nhowever depends on the size of the subdomains and the time window length on\nwhich the algorithm is employed. We illustrate the performance of the algorithm\nwith numerical results, and show a comparison with classical and optimized\nSchwarz WR methods. \n\n"}
{"id": "1507.05063", "contents": "Title: An extrapolation cascadic multigrid method combined with a fourth order\n  compact scheme for 3D poisson equation Abstract: In this paper, we develop an EXCMG method to solve the three-dimensional\nPoisson equation on rectangular domains by using the compact finite difference\n(FD) method with unequal meshsizes in different coordinate directions. The\nresulting linear system from compact FD discretization is solved by the\nconjugate gradient (CG) method with a relative residual stopping criterion. By\ncombining the Richardson extrapolation and tri-quartic Lagrange interpolation\nfor the numerical solutions from two-level of grids (current and previous\ngrids), we are able to produce an extremely accurate approximation of the\nactual numerical solution on the next finer grid, which can greatly reduce the\nnumber of relaxation sweeps needed. Additionally, a simple method based on the\nmidpoint extrapolation formula is used for the fourth-order FD solutions on\ntwo-level of grids to achieve sixth-order accuracy on the entire fine grid\ncheaply and directly. The gradient of the numerical solution can also be easily\nobtained through solving a series of tridiagonal linear systems resulting from\nthe fourth-order compact FD discretizations. Numerical results show that our\nEXCMG method is much more efficient than the classical V-cycle and W-cycle\nmultigrid methods. Moreover, only few CG iterations are required on the finest\ngrid to achieve full fourth-order accuracy in both the $L^2$-norm and\n$L^{\\infty}$-norm for the solution and its gradient when the exact solution\nbelongs to $C^6$. Finally, numerical result shows that our EXCMG method is\nstill effective when the exact solution has a lower regularity, which widens\nthe scope of applicability of our EXCMG method. \n\n"}
{"id": "1507.05613", "contents": "Title: Neutrino Physics with JUNO Abstract: The Jiangmen Underground Neutrino Observatory (JUNO), a 20 kton multi-purpose\nunderground liquid scintillator detector, was proposed with the determination\nof the neutrino mass hierarchy as a primary physics goal. It is also capable of\nobserving neutrinos from terrestrial and extra-terrestrial sources, including\nsupernova burst neutrinos, diffuse supernova neutrino background, geoneutrinos,\natmospheric neutrinos, solar neutrinos, as well as exotic searches such as\nnucleon decays, dark matter, sterile neutrinos, etc. We present the physics\nmotivations and the anticipated performance of the JUNO detector for various\nproposed measurements. By detecting reactor antineutrinos from two power plants\nat 53-km distance, JUNO will determine the neutrino mass hierarchy at a 3-4\nsigma significance with six years of running. The measurement of antineutrino\nspectrum will also lead to the precise determination of three out of the six\noscillation parameters to an accuracy of better than 1\\%. Neutrino burst from a\ntypical core-collapse supernova at 10 kpc would lead to ~5000\ninverse-beta-decay events and ~2000 all-flavor neutrino-proton elastic\nscattering events in JUNO. Detection of DSNB would provide valuable information\non the cosmic star-formation rate and the average core-collapsed neutrino\nenergy spectrum. Geo-neutrinos can be detected in JUNO with a rate of ~400\nevents per year, significantly improving the statistics of existing geoneutrino\nsamples. The JUNO detector is sensitive to several exotic searches, e.g. proton\ndecay via the $p\\to K^++\\bar\\nu$ decay channel. The JUNO detector will provide\na unique facility to address many outstanding crucial questions in particle and\nastrophysics. It holds the great potential for further advancing our quest to\nunderstanding the fundamental properties of neutrinos, one of the building\nblocks of our Universe. \n\n"}
{"id": "1507.05827", "contents": "Title: Relations between WENO3 and Third-order Limiting in Finite Volume\n  Methods Abstract: Weighted essentially non-oscillatory (WENO) and finite volume (FV) methods\nemploy different philosophies in their way to perform limiting. We show that a\ngeneralized view on limiter functions, which considers a two-dimensional,\nrather than a one-dimensional dependence on the slopes in neighboring cells,\nallows to write WENO3 and $3^\\text{rd}$-order FV schemes in the same fashion.\nWithin this framework, it becomes apparent that the classical approach of FV\nlimiters to only consider ratios of the slopes in neighboring cells, is overly\nrestrictive. The hope of this new perspective is to establish new connections\nbetween WENO3 and FV limiter functions, which may give rise to improvements for\nthe limiting behavior in both approaches. \n\n"}
{"id": "1507.05854", "contents": "Title: Global Convergence of Non-Convex Gradient Descent for Computing Matrix\n  Squareroot Abstract: While there has been a significant amount of work studying gradient descent\ntechniques for non-convex optimization problems over the last few years, all\nexisting results establish either local convergence with good rates or global\nconvergence with highly suboptimal rates, for many problems of interest. In\nthis paper, we take the first step in getting the best of both worlds --\nestablishing global convergence and obtaining a good rate of convergence for\nthe problem of computing squareroot of a positive definite (PD) matrix, which\nis a widely studied problem in numerical linear algebra with applications in\nmachine learning and statistics among others. Given a PD matrix $M$ and a PD\nstarting point $U_0$, we show that gradient descent with appropriately chosen\nstep-size finds an $\\epsilon$-accurate squareroot of $M$ in $O(\\alpha \\log\n(\\|M-U_0^2\\|_F /\\epsilon))$ iterations, where $\\alpha =\n(\\max\\{\\|U_0\\|_2^2,\\|M\\|_2\\} / \\min \\{\\sigma_{\\min}^2(U_0),\\sigma_{\\min}(M) \\}\n)^{3/2}$. Our result is the first to establish global convergence for this\nproblem and that it is robust to errors in each iteration. A key contribution\nof our work is the general proof technique which we believe should further\nexcite research in understanding deterministic and stochastic variants of\nsimple non-convex gradient descent algorithms with good global convergence\nrates for other problems in machine learning and numerical linear algebra. \n\n"}
{"id": "1507.06041", "contents": "Title: A stable partitioned FSI algorithm for incompressible flow and deforming\n  beams Abstract: An added-mass partitioned (AMP) algorithm is described for solving\nfluid-structure interaction (FSI) problems coupling incompressible flows with\nthin elastic structures undergoing finite deformations. The new AMP scheme is\nfully second-order accurate and stable, without sub-time-step iterations, even\nfor very light structures when added-mass effects are strong. The fluid,\ngoverned by the incompressible Navier-Stokes equations, is solved in\nvelocity-pressure form using a fractional-step method; large deformations are\ntreated with a mixed Eulerian-Lagrangian approach on deforming composite grids.\nThe motion of the thin structure is governed by a generalized Euler-Bernoulli\nbeam model, and these equations are solved in a Lagrangian frame using two\napproaches, one based on finite differences and the other on finite elements.\nSpecial treatment of the AMP condition is required to couple the finite-element\nbeam solver with the finite-difference-based fluid solver, and two coupling\napproaches are described. A normal-mode stability analysis is performed for a\nlinearized model problem involving a beam separating two fluid domains, and it\nis shown that the AMP scheme is stable independent of the ratio of the mass of\nthe fluid to that of the structure. A traditional partitioned (TP) scheme using\na Dirichlet-Neumann coupling for the same model problem is shown to be\nunconditionally unstable if the added mass of the fluid is too large. A series\nof benchmark problems of increasing complexity are considered to illustrate the\nbehavior of the AMP algorithm, and to compare the behavior with that of the TP\nscheme. The results of all these benchmark problems verify the stability and\naccuracy of the AMP scheme. Results for one benchmark problem modeling blood\nflow in a deforming artery are also compared with corresponding results\navailable in the literature. \n\n"}
{"id": "1507.08316", "contents": "Title: Lebesgue Constants Arising in a Class of Collocation Methods Abstract: Estimates are obtained for the Lebesgue constants associated with the Gauss\nquadrature points on $(-1, +1)$ augmented by the point $-1$ and with the Radau\nquadrature points on either $(-1, +1]$ or $[-1, +1)$. It is shown that the\nLebesgue constants are $O(\\sqrt{N})$, where $N$ is the number of quadrature\npoints. These point sets arise in the estimation of the residual associated\nwith recently developed orthogonal collocation schemes for optimal control\nproblems. For problems with smooth solutions, the estimates for the Lebesgue\nconstants can imply an exponential decay of the residual in the collocated\nproblem as a function of the number of quadrature points. \n\n"}
{"id": "1508.01709", "contents": "Title: Double-beta decay investigation with highly pure enriched $^{82}$Se for\n  the LUCIFER experiment Abstract: The LUCIFER project aims at deploying the first array of enriched\nscintillating bolometers for the investigation of neutrinoless double-beta\ndecay of $^{82}$Se. The matrix which embeds the source is an array of ZnSe\ncrystals, where enriched $^{82}$Se is used as decay isotope. The radiopurity of\nthe initial components employed for manufacturing crystals, that can be\noperated as bolometers, is crucial for achieving a null background level in the\nregion of interest for double-beta decay investigations. In this work, we\nevaluated the radioactive content in 2.5 kg of 96.3\\% enriched $^{82}$Se metal,\nmeasured with a high-purity germanium detector at the Gran Sasso deep\nunderground laboratory. The limits on internal contaminations of primordial\ndecay chain elements of $^{232}$Th, $^{238}$U and $^{235}$U are respectively:\n$<$61 $\\mu$Bq/kg, $< $110 $\\mu$Bq/kg and $<$74 $\\mu$Bq/kg at 90\\% C.L.. The\nextremely low-background conditions in which the measurement was carried out\nand the high radiopurity of the $^{82}$Se allowed us to establish the most\nstringent lower limits on the half-lives of double-beta decay of $^{82}$Se to\n0$^+_1$, 2$^+_2$ and 2$^+_1$ excited states of $^{82}$Kr of 3.4$\\cdot$10$^{22}$\ny, 1.3$\\cdot$10$^{22}$ y and 1.0$\\cdot$10$^{22}$ y, respectively, with a 90\\%\nC.L.. \n\n"}
{"id": "1508.03783", "contents": "Title: Convergence rate for a Radau collocation method applied to unconstrained\n  optimal control Abstract: A local convergence rate is established for an orthogonal collocation method\nbased on Radau quadrature applied to an unconstrained optimal control problem.\nIf the continuous problem has a sufficiently smooth solution and the\nHamiltonian satisfies a strong convexity condition, then the discrete problem\npossesses a local minimizer in a neighborhood of the continuous solution, and\nas the number of collocation points increases, the discrete solution\nconvergences exponentially fast in the sup-norm to the continuous solution. An\nearlier paper analyzes an orthogonal collocation method based on Gauss\nquadrature, where neither end point of the problem domain is a collocation\npoint. For the Radau quadrature scheme, one end point is a collocation point. \n\n"}
{"id": "1508.05160", "contents": "Title: Anisotropic emission of thermal dielectrons from Au+Au collisions at\n  $\\sqrt{s_{NN}}=200$~GeV with EPOS3 Abstract: Dileptons, as an electromagnetic probe, are crucial to study the properties\nof a Quark-Gluon Plasma (QGP) created in heavy ion collisions. We calculated\nthe invariant mass spectra and the anisotropic emission of thermal dielectrons\nfrom Au+Au collisions at the Relativistic Heavy Ion Collider (RHIC) energy\n$\\sqrt{s_{NN}}=200$~GeV based on EPOS3. This approach provides a realistic\n(3+1)-dimensional event-by-event viscous hydrodynamic description of the\nexpanding hot and dense matter with a very particular initial condition, and a\nlarge set of hadron data and direct photons (besides $v_{2}$ and $v_{3}$ !) can\nbe successfully reproduced. Thermal dilepton emission from both the QGP phase\nand the hadronic gas are considered, with the emission rates based on Lattice\nQCD and a vector meson model, respectively. We find that the computed invariant\nmass spectra (thermal contribution + STAR cocktail) can reproduce the measured\nones from STAR at different centralities. Different compared to other model\npredictions, the obtained elliptic flow of thermal dileptons is larger than the\nSTAR measurement referring to all dileptons. We observe a clear centrality\ndependence of thermal dilepton not only for elliptic flow $v_{2}$ but also for\nhigher orders. At a given centrality, $v_{n}$ of thermal dileptons decreases\nmonotonically with $n$ for $2\\leq n\\leq5$. \n\n"}
{"id": "1508.06084", "contents": "Title: Chiral dynamics of S-wave baryon resonances Abstract: As the pion mass approaches a critical value $m_\\pi^\\star$ from below, an\n$S$-wave resonance crosses pion-baryon threshold and becomes a bound state with\narbitrarily small binding energy, thus driving the scattering length to\ndiverge. I explore the consequences of chiral symmetry for the values of\n$m_\\pi$ close to $m_\\pi^\\star$. It turns out that chiral symmetry is crucial\nfor an $S$-wave resonance to be able to stand very near threshold and in the\nmeantime to remain narrow, provided that the mass splitting is reasonably\nsmall. The effective range of pion-baryon scattering is unexpectedly large,\nproportional to $ 4\\pi f_\\pi^2/m_\\pi^3$ when $m_\\pi$ is around $m_\\pi^\\star$.\nAs a result, this unexpected large length scale causes universality relations\nto break down much sooner than naively expected. \n\n"}
{"id": "1508.07029", "contents": "Title: Characterization and Modeling of a Water-based Liquid Scintillator Abstract: We have characterised Water-based Liquid Scintillator (WbLS) using low energy\nprotons, UV-VIS absorbance, and fluorescence spectroscopy. We have also\ndeveloped and validated a simulation model that describes the behaviour of WbLS\nin our detector configurations for proton beam energies of 2 GeV, 475 MeV, and\n210 MeV and for two WbLS compositions. Our results have enabled us to estimate\nthe light yield and ionisation quenching of WbLS, as well as to understand the\ninfluence of the wavelength shifting of Cerenkov light on our measurements.\nThese results are relevant to the suitability of water-based liquid\nscintillator materials for next generation intensity frontier experiments. \n\n"}
{"id": "1508.07981", "contents": "Title: Sensitivity to Z-prime and non-standard neutrino interactions from\n  ultra-low threshold neutrino-nucleus coherent scattering Abstract: We discuss prospects for probing Z-prime and non-standard neutrino\ninteractions using neutrino-nucleus coherent scattering with ultra-low energy\n(~ 10 eV) threshold Si and Ge detectors. The analysis is performed in the\ncontext of a specific and contemporary reactor-based experimental proposal,\ndeveloped in cooperation with the Nuclear Science Center at Texas A&M\nUniversity, and referencing available technology based upon economical and\nscalable detector arrays. For expected exposures, we show that sensitivity to\nthe Z-prime mass is on the order of several TeV, and is complementary to the\nLHC search with low mass detectors in the near term. This technology is also\nshown to provide sensitivity to the neutrino magnetic moment, at a level that\nsurpasses terrestrial limits, and is competitive with more stringent\nastrophysical bounds. We demonstrate the benefits of combining silicon and\ngermanium detectors for distinguishing between classes of models of new\nphysics, and for suppressing correlated systematic uncertainties. \n\n"}
{"id": "1509.00311", "contents": "Title: Alternating Least Squares Tensor Completion in The TT-Format Abstract: We consider the problem of fitting a low rank tensor\n$A\\in\\mathbb{R}^{{\\mathcal I}}$, ${\\mathcal I} = \\{1,\\ldots,n\\}^{d}$, to a\ngiven set of data points $\\{M_i\\in\\mathbb{R}\\mid i\\in P\\}$, $P\\subset{\\mathcal\nI}$.\n  The low rank format under consideration is the hierarchical or TT or MPS\nformat. It is characterized by rank bounds $r$ on certain matricizations of the\ntensor. The number of degrees of freedom is in ${\\cal O}(r^2dn)$.\n  For a fixed rank and mode size $n$ we observe that it is possible to\nreconstruct random (but rank structured) tensors as well as certain discretized\nmultivariate (but rank structured) functions from a number of samples that is\nin ${\\cal O}(\\log N)$ for a tensor having $N=n^d$ entries.\n  We compare an alternating least squares fit (ALS) to an overrelaxation scheme\ninspired by the LMaFit method for matrix completion.\n  Both approaches aim at finding a tensor $A$ that fulfils the first order\noptimality conditions by a nonlinear Gauss-Seidel type solver that consists of\nan alternating fit cycling through the directions $\\mu=1,\\ldots,d$.\n  The least squares fit is of complexity ${\\cal O}(r^4d\\#P)$ per step, whereas\neach step of ADF is in ${\\cal O}(r^2d\\#P)$, albeit with a slightly higher\nnumber of necessary steps.\n  In the numerical experiments we observe robustness of the completion\nalgorithm with respect to noise and good reconstruction capability.\n  Our tests provide evidence that the algorithm is suitable in higher dimension\n($>$10) as well as for moderate ranks.\n  Keywords: MPS, Tensor Completion, Tensor Train, TT, Hierarchical Tucker, HT,\nALS. \n\n"}
{"id": "1509.00664", "contents": "Title: Proportional electroluminescence in two-phase argon and its relevance to\n  rare-event experiments Abstract: Proportional electroluminescence (EL) in gaseous Ar has for the first time\nbeen systematically studied in the two-phase mode, at 87 K and 1.00 atm. Liquid\nargon had a minor (56 ppm) admixture of nitrogen, which allowed to understand,\ninter alia, the effect of N2 doping on the EL mechanism in rare-event\nexperiments using two-phase Ar detectors. The measurements were performed in a\ntwo-phase Cryogenic Avalanche Detector (CRAD) with EL gap located directly\nabove the liquid-gas interface. The EL gap was optically read out in the Vacuum\nUltraviolet (VUV), near 128 nm (Ar excimer emission), and in the near\nUltraviolet (UV), at 300-450 nm (N2 Second Positive System emission), via\ncryogenic PMTs and a Geiger-mode APD (GAPD). Proportional electroluminescence\nwas measured to have an amplification parameter of 109+-10 photons per drifting\nelectron per kV overall in the VUV and UV, of which 51+-6% were emitted in the\nUV. The measured EL threshold, at an electric field of 3.7+-0.2 kV/cm, was in\naccordance with that predicted by the theory. The latter result is particularly\nrelevant to DarkSide and SCENE dark matter search-related experiments, where\nthe operation electric field was thereby on the verge of appearance of the S2\n(ionization-induced) signal. The results obtained pave the way to the\ndevelopment of N2-doped two-phase Ar detectors with enhanced sensitivity to the\nS2 signal. \n\n"}
{"id": "1509.00792", "contents": "Title: nCTEQ15 - Global analysis of nuclear parton distributions with\n  uncertainties in the CTEQ framework Abstract: We present the new nCTEQ15 set of nuclear parton distribution functions with\nuncertainties. This fit extends the CTEQ proton PDFs to include the nuclear\ndependence using data on nuclei all the way up to 208^Pb. The uncertainties are\ndetermined using the Hessian method with an optimal rescaling of the\neigenvectors to accurately represent the uncertainties for the chosen tolerance\ncriteria. In addition to the Deep Inelastic Scattering (DIS) and Drell-Yan (DY)\nprocesses, we also include inclusive pion production data from RHIC to help\nconstrain the nuclear gluon PDF. Furthermore, we investigate the correlation of\nthe data sets with specific nPDF flavor components, and asses the impact of\nindividual experiments. We also provide comparisons of the nCTEQ15 set with\nrecent fits from other groups. \n\n"}
{"id": "1509.01462", "contents": "Title: A multilevel adaptive sparse grid stochastic collocation approach to the\n  non-smooth forward propagation of uncertainty in discretized problems Abstract: This work proposes a scheme for significantly reducing the computational\ncomplexity of discretized problems involving the non-smooth forward propagation\nof uncertainty by combining the adaptive hierarchical sparse grid stochastic\ncollocation method (ALSGC) with a hierarchy of successively finer spatial\ndiscretizations (e.g. finite elements) of the underlying deterministic problem.\nTo achieve this, we build strongly upon ideas from the Multilevel Monte Carlo\nmethod (MLMC), which represents a well-established technique for the reduction\nof computational complexity in problems affected by both deterministic and\nstochastic error contributions. The resulting approach is termed the Multilevel\nAdaptive Sparse Grid Collocation (MLASGC) method. Preliminary results for a\nlow-dimensional, non-smooth parametric ODE problem are promising: the proposed\nMLASGC method exhibits an error/cost-relation of $\\varepsilon \\sim t^{-0.95}$\nand therefore significantly outperforms the single-level ALSGC ($\\varepsilon\n\\sim t^{-0.65}$) and MLMC methods ($\\varepsilon \\lesssim t^{-0.5}$). \n\n"}
{"id": "1509.03136", "contents": "Title: MAP Estimators for Piecewise Continuous Inversion Abstract: We study the inverse problem of estimating a field $u$ from data comprising a\nfinite set of nonlinear functionals of $u$, subject to additive noise; we\ndenote this observed data by $y$. Our interest is in the reconstruction of\npiecewise continuous fields in which the discontinuity set is described by a\nfinite number of geometric parameters. Natural applications include groundwater\nflow and electrical impedance tomography. We take a Bayesian approach, placing\na prior distribution on $u$ and determining the conditional distribution on $u$\ngiven the data $y$. It is then natural to study maximum a posterior (MAP)\nestimators. Recently (Dashti et al 2013) it has been shown that MAP estimators\ncan be characterised as minimisers of a generalised Onsager-Machlup functional,\nin the case where the prior measure is a Gaussian random field. We extend this\ntheory to a more general class of prior distributions which allows for\npiecewise continuous fields. Specifically, the prior field is assumed to be\npiecewise Gaussian with random interfaces between the different Gaussians\ndefined by a finite number of parameters. We also make connections with recent\nwork on MAP estimators for linear problems and possibly non-Gaussian priors\n(Helin, Burger 2015) which employs the notion of Fomin derivative.\n  In showing applicability of our theory we focus on the groundwater flow and\nEIT models, though the theory holds more generally. Numerical experiments are\nimplemented for the groundwater flow model, demonstrating the feasibility of\ndetermining MAP estimators for these piecewise continuous models, but also that\nthe geometric formulation can lead to multiple nearby (local) MAP estimators.\nWe relate these MAP estimators to the behaviour of output from MCMC samples of\nthe posterior, obtained using a state-of-the-art function space\nMetropolis-Hastings method. \n\n"}
{"id": "1509.03225", "contents": "Title: Half-space Kinetic Equations with General Boundary Conditions Abstract: We study half-space linear kinetic equations with general boundary conditions\nthat consist of both given incoming data and various type of reflections,\nextending our previous work [LLS14] on half-space equations with incoming\nboundary conditions. As in [LLS14], the main technique is a damping\nadding-removing procedure. We establish the well-posedness of linear (or\nlinearized) half-space equations with general boundary conditions and\nquasi-optimality of the numerical scheme. The numerical method is validated by\nexamples including a two-species transport equation, a multi-frequency\ntransport equation, and the linearized BGK equation in 2D velocity space. \n\n"}
{"id": "1509.03386", "contents": "Title: Long-lived neutral-kaon flux measurement for the KOTO experiment Abstract: The KOTO ($K^0$ at Tokai) experiment aims to observe the CP-violating rare\ndecay $K_L \\rightarrow \\pi^0 \\nu \\bar{\\nu}$ by using a long-lived neutral-kaon\nbeam produced by the 30 GeV proton beam at the Japan Proton Accelerator\nResearch Complex. The $K_L$ flux is an essential parameter for the measurement\nof the branching fraction. Three $K_L$ neutral decay modes, $K_L \\rightarrow\n3\\pi^0$, $K_L \\rightarrow 2\\pi^0$, and $K_L \\rightarrow 2\\gamma$ were used to\nmeasure the $K_L$ flux in the beam line in the 2013 KOTO engineering run. A\nMonte Carlo simulation was used to estimate the detector acceptance for these\ndecays. Agreement was found between the simulation model and the experimental\ndata, and the remaining systematic uncertainty was estimated at the 1.4\\%\nlevel. The $K_L$ flux was measured as $(4.183 \\pm 0.017_{\\mathrm{stat.}} \\pm\n0.059_{\\mathrm{sys.}}) \\times 10^7$ $K_L$ per $2\\times 10^{14}$ protons on a\n66-mm-long Au target. \n\n"}
{"id": "1509.03605", "contents": "Title: Wilson RG of Noncommutative $\\Phi_{4}^4$ Abstract: We present a study of phi-four theory on noncommutative spaces using a\ncombination of the Wilson renormalization group recursion formula and the\nsolution to the zero dimensional vector/matrix models at large $N$. Three fixed\npoints are identified. The matrix model $\\theta=\\infty$ fixed point which\ndescribes the disordered-to-non-uniform-ordered transition. The Wilson-Fisher\nfixed point at $\\theta=0$ which describes the disordered-to-uniform-ordered\ntransition, and a noncommutative Wilson-Fisher fixed point at a maximum value\nof $\\theta$ which is associated with the transition between non-uniform-order\nand uniform-order phases. \n\n"}
{"id": "1509.04933", "contents": "Title: Natural Split Mechanism for Sfermions: $N$=2 Supersymmetry in\n  Phenomenology Abstract: We suggest a natural split mechanism for sfermions based on $N$=2\nsupersymmetry (SUSY). $N$=2 SUSY protects a sfermion in an $N$=2 multiplet from\ngaining weight by SUSY breaking. Therefore, if partly $N$=2 SUSY is effectively\nobtained, a split spectrum can be realized naturally. As an example of the\nnatural split mechanism, we build a gauge-mediated SUSY breaking-like model\nassuming $N$=2 SUSY is partly broken in a UV theory. The model explains the\nHiggs boson mass and the muon anomalous magnetic dipole moment within\n$1~\\sigma$ level with a splitting sfermion spectrum. The model has seven light\nsparticles described by three free parameters and predicts a new chiral\nmultiplet, sb: the $N$=2 partner of the ${\\rm U(1)_Y}$ vector multiplet. The\nbini, the fermion component of the sb, weighs MeVs. We mention the experimental\nand the cosmological aspects of the model. \n\n"}
{"id": "1509.05084", "contents": "Title: An Accelerated Dual Proximal Gradient Method for Applications in\n  Viscoplasticity Abstract: We present a very simple and fast algorithm for the numerical solution of\nviscoplastic flow problems without prior regularisation. Compared to the\nwidespread alternating direction method of multipliers (ADMM / ALG2), the new\nmethod features three key advantages: firstly, it accelerates the worst-case\nconvergence rate from $O(1/\\sqrt{k})$ to $O(1/k)$, where $k$ is the iteration\ncounter. Secondly, even for nonlinear constitutive models like those of Casson\nor Herschel-Bulkley, no nonlinear systems of equations have to be solved in the\nsubproblems of the algorithm. Thirdly, there is no need to augment the\nLagrangian, which eliminates the difficulty of choosing a penalty parameter\nheuristically.\n  In this paper, we transform the usual velocity-based formulation of\nviscoplastic flow problems to a dual formulation in terms of the stress. For\nthe numerical solution of this dual problem we apply FISTA, an accelerated\nfirst-order optimisation algorithm from the class of so-called proximal\ngradient methods. Finally, we conduct a series of numerical experiments,\nfocussing on stationary flow in two-dimensional square cavities.\n  Our results confirm that Algorithm FISTA*, the new dual-based FISTA,\noutperforms state-of-the-art algorithms such as ADMM / ALG2 by several orders\nof magnitude. We demonstrate how this speedup can be exploited to identify the\nfree boundary between yielded and unyielded regions with previously unknown\naccuracy. Since the accelerated algorithm relies solely on Stokes-type\nsubproblems and nonlinear function evaluations, existing code based on\naugmented Lagrangians would require only few minor adaptations to obtain an\nimplementation of FISTA*. \n\n"}
{"id": "1509.05610", "contents": "Title: Online Monitoring of the Osiris Reactor with the Nucifer Neutrino\n  Detector Abstract: Originally designed as a new nuclear reactor monitoring device, the Nucifer\ndetector has successfully detected its first neutrinos. We provide the second\nshortest baseline measurement of the reactor neutrino flux. The detection of\nelectron antineutrinos emitted in the decay chains of the fission products,\ncombined with reactor core simulations, provides an new tool to assess both the\nthermal power and the fissile content of the whole nuclear core and could be\nused by the Inter- national Agency for Atomic Energy (IAEA) to enhance the\nSafeguards of civil nuclear reactors. Deployed at only 7.2m away from the\ncompact Osiris research reactor core (70MW) operating at the Saclay research\ncentre of the French Alternative Energies and Atomic Energy Commission (CEA),\nthe experiment also exhibits a well-suited configuration to search for a new\nshort baseline oscillation. We report the first results of the Nucifer\nexperiment, describing the performances of the 0.85m3 detector remotely\noperating at a shallow depth equivalent to 12m of water and under intense\nbackground radiation conditions. Based on 145 (106) days of data with reactor\nON (OFF), leading to the detection of an estimated 40760 electron\nantineutrinos, the mean number of detected antineutrinos is 281 +- 7(stat) +-\n18(syst) electron antineutrinos/day, in agreement with the prediction 277(23)\nelectron antineutrinos/day. Due the the large background no conclusive results\non the existence of light sterile neutrinos could be derived, however. As a\nfirst societal application we quantify how antineutrinos could be used for the\nPlutonium Management and Disposition Agreement. \n\n"}
{"id": "1509.07619", "contents": "Title: Analysis-suitable $G^1$ multi-patch parametrizations for $C^1$\n  isogeometric spaces Abstract: One key feature of isogeometric analysis is that it allows smooth shape\nfunctions. Indeed, when isogeometric spaces are constructed from $p$-degree\nsplines (and extensions, such as NURBS), they enjoy up to $C^{p-1}$ continuity\nwithin each patch. However, global continuity beyond $C^0$ on so-called\nmulti-patch geometries poses some significant difficulties. In this work, we\nconsider planar multi-patch domains that have a parametrization which is only\n$C^0$ at the patch interface. On such domains we study the $h$-refinement of\n$C^1$-continuous isogeometric spaces. These spaces in general do not have\noptimal approximation properties. The reason is that the $C^1$-continuity\ncondition easily over-constrains the solution which is, in the worst cases,\nfully locked to linears at the patch interface. However, recent studies by Kapl\net al. have given numerical evidence that optimal convergence occurs for\nbilinear two-patch geometries and cubic (or higher degree) $C^1$ splines. This\nis the starting point of our study. We introduce the class of analysis-suitable\n$G^1$ geometry parametrizations, which includes piecewise bilinear\nparametrizations. We then analyze the structure of $C^1$ isogeometric spaces\nover analysis-suitable $G^1$ parametrizations and, by theoretical results and\nnumerical testing, discuss their approximation properties. We also consider\nexamples of geometry parametrizations that are not analysis-suitable, showing\nthat in this case optimal convergence of $C^1$ isogeometric spaces is\nprevented. \n\n"}
{"id": "1509.07739", "contents": "Title: The CAPTAIN Experiment Abstract: The Cryogenic Apparatus for Precision Tests of Argon Interactions with\nNeutrinos (CAPTAIN) program is designed to make measurements of scientific\nimportance to long-baseline neutrino physics and physics topics that will be\nexplored by large underground detectors. The experiment employs two liquid\nArgon time projection chambers (LArTPCs), a primary detector with a mass of\napproximately 10 ton that will be deployed at different facilities for physics\nmeasurements and a two ton prototype detector for configuration testing. The\nphysics programs for CAPTAIN include measuring neutron interactions at the Los\nAlamos Neutron Science Center, measuring neutrino interactions in the\nhigh-energy regime (1.5-5 GeV) at Fermilab NuMI beam, and measuring neutrino\ninteractions in the low-energy regime (<50 MeV) at stopped pion sources for\nsupernova neutrino studies. The prototype detector (Mini-CAPTAIN) has been\ncommissioned and the first UV laser track has been seen in its TPC. This paper\ngives an overview of the CAPTAIN program and reports the status of the\ncommissioning. The up-to-date detector design and running plans are also\ndescribed. \n\n"}
{"id": "1509.08657", "contents": "Title: Simulation of radiation-induced defects Abstract: Mainly due to their outstanding performance the position sensitive silicon\ndetectors are widely used in the tracking systems of High Energy Physics\nexperiments such as the ALICE, ATLAS, CMS and LHCb at LHC, the world's largest\nparticle physics accelerator at CERN, Geneva. The foreseen upgrade of the LHC\nto its high luminosity (HL) phase (HL-LHC scheduled for 2023), will enable the\nuse of maximal physics potential of the facility. After 10 years of operation\nthe expected fluence will expose the tracking systems at HL-LHC to a radiation\nenvironment that is beyond the capacity of the present system design. Thus, for\nthe required upgrade of the all-silicon central trackers extensive measurements\nand simulation studies for silicon sensors of different designs and materials\nwith sufficient radiation tolerance have been initiated within the RD50\nCollaboration.\n  Supplementing measurements, simulations are in vital role for e.g. device\nstructure optimization or predicting the electric fields and trapping in the\nsilicon sensors. The main objective of the device simulations in the RD50\nCollaboration is to develop an approach to model and predict the performance of\nthe irradiated silicon detectors using professional software. The first\nsuccessfully developed quantitative models for radiation damage, based on two\neffective midgap levels, are able to reproduce the experimentally observed\ndetector characteristics like leakage current, full depletion voltage and\ncharge collection efficiency (CCE). Recent implementations of additional traps\nat the SiO$_2$/Si interface or close to it have expanded the scope of the\nexperimentally agreeing simulations to such surface properties as the\ninterstrip resistance and capacitance, and the position dependency of CCE for\nstrip sensors irradiated up to $\\sim$$1.5\\times10^{15}$\nn$_{\\textrm{eq}}\\textrm{cm}^{-2}$. \n\n"}
{"id": "1510.00204", "contents": "Title: Measuring CP-Violating Observables in Rare Top Decays at the LHC Abstract: In this paper we consider CP-violating new-physics contributions to the decay\n$t \\to b \\bar b c$. We examine the prospects for detecting such new physics at\nthe LHC, which requires studying the process $gg \\to t (\\to b \\bar b c) \\bar t\n(\\to \\bar b \\ell \\bar \\nu)$. We find two observables that can be used to reveal\nthe presence of CP-violating new physics in $t \\to b \\bar b c$. They are (i)\nthe partial-rate asymmetry and (ii) the triple-product correlations involving\nthe momenta of various particles associated with the interaction. A Monte Carlo\nanalysis is performed to determine how well these observables can be used to\ndetect the presence of new physics, and to measure its parameters. We find that\nthere is little difficulty in extracting the value of the relevant new-physics\nparameter from the partial-rate asymmetry. For the triple-product correlations,\nwe test multiple strategies that can be used for the extraction of the\ncorresponding combination of new-physics parameters. \n\n"}
{"id": "1510.00572", "contents": "Title: LHCb Topological Trigger Reoptimization Abstract: The main b-physics trigger algorithm used by the LHCb experiment is the\nso-called topological trigger. The topological trigger selects vertices which\nare a) detached from the primary proton-proton collision and b) compatible with\ncoming from the decay of a b-hadron. In the LHC Run 1, this trigger, which\nutilized a custom boosted decision tree algorithm, selected a nearly 100% pure\nsample of b-hadrons with a typical efficiency of 60-70%; its output was used in\nabout 60% of LHCb papers. This talk presents studies carried out to optimize\nthe topological trigger for LHC Run 2. In particular, we have carried out a\ndetailed comparison of various machine learning classifier algorithms, e.g.,\nAdaBoost, MatrixNet and neural networks. The topological trigger algorithm is\ndesigned to select all \"interesting\" decays of b-hadrons, but cannot be trained\non every such decay. Studies have therefore been performed to determine how to\noptimize the performance of the classification algorithm on decays not used in\nthe training. Methods studied include cascading, ensembling and blending\ntechniques. Furthermore, novel boosting techniques have been implemented that\nwill help reduce systematic uncertainties in Run 2 measurements. We demonstrate\nthat the reoptimized topological trigger is expected to significantly improve\non the Run 1 performance for a wide range of b-hadron decays. \n\n"}
{"id": "1510.02745", "contents": "Title: Precision electromagnetic calorimetry at the energy frontier: CMS ECAL\n  at LHC Run 2 Abstract: The CMS electromagnetic calorimeter (ECAL) is a high-resolution, hermetic,\nand homogeneous calorimeter made of 75,848 scintillating lead tungstate\ncrystals. Following the discovery of the Higgs boson, the CMS ECAL is at the\nforefront of precision measurements and the search for new physics in data from\nthe LHC, which recently began producing collisions at the unprecedented energy\nof 13 TeV. The exceptional precision of the CMS ECAL, as well as its timing\nperformance, are invaluable tools for the discovery of new physics at the LHC\nRun 2. The excellent performance of the ECAL relies on precise calibration\nmaintained over time, despite severe irradiation conditions. A set of\ninter-calibration procedures using different physics channels is carried out at\nregular intervals to normalize the differences in crystal light transparency\nand photodetector response between channels, which can change due to\naccumulated radiation. In this talk we present new reconstruction algorithms\nand calibration strategies which aim to maintain, and even improve, the\nexcellent performance of the CMS ECAL under the new challenging conditions of\nRun 2. \n\n"}
{"id": "1510.03030", "contents": "Title: Tests of Scintillator+WLS strips for Muon System at Future Colliders Abstract: Prototype scintilator+WLS strips with SiPM readout for muon system at future\ncolliders were tested for light yield, time resolution and position resolution.\nDepending on the configuration, light yield of up to 36 photoelectrons per muon\nper SiPM has been achieved, as well as time resolution of 0.5 ns and position\nresolution of ~7 cm. \n\n"}
{"id": "1510.03078", "contents": "Title: Gravity experiments with ultracold neutrons and the qBounce experiment Abstract: This work focuses on the control and understanding of a gravitationally\ninteracting elementary quantum system. It offers a new way of looking at\ngravitation based on quantum interference: an ultracold neutron, a quantum\nparticle, as an object and as a tool. The ultracold neutron as a tool reflects\nfrom a mirror in well-defined quantum states in the gravity potential of the\nearth allowing to apply the concept of gravity resonance spectroscopy (GRS).\nGRS relies on frequency measurements, which provide a spectacular sensitivity. \n\n"}
{"id": "1510.03684", "contents": "Title: On the discretisation in time of the stochastic Allen-Cahn equation Abstract: We consider the stochastic Allen--Cahn equation perturbed by smooth additive\nGaussian noise in a spatial domain with smooth boundary in dimension $d\\le 3$,\nand study the semidiscretisation in time of the equation by an Euler type\nsplit-step method. We show that the method converges strongly with a rate\n$O(\\Delta t^{\\frac12}) $. By means of a perturbation argument, we also\nestablish the strong convergence of the standard backward Euler scheme with the\nsame rate. \n\n"}
{"id": "1510.04063", "contents": "Title: Detailed studies of hadronic showers and comparison to GEANT4\n  simulations with data from highly granular calorimeters Abstract: The highly granular calorimeter prototypes of the CALICE collaboration have\nprovided large data samples with precise three-dimensional information on\nhadronic showers with steel and tungsten absorbers and silicon, scintillator\nand gas detector readout. From these data sets, detailed measurements of the\nspatial structure, including longitudinal and lateral shower profiles and of\nthe shower substructure and time structure are extracted. Recent analyses have\nextended these studies to different particle species in calorimeters with\nscintillator readout and steel and tungsten absorbers, to energies below 10 GeV\nin a silicon tungsten calorimeter and have provided first studies of the shower\nsubstructure with gaseous readout and unprecedented granularity of\n$1\\times1$~cm$^{2}$ over a full cubic meter. These results are confronted with\nGeant4 simulations with different hadronic physics models. They present new\nchallenges to the simulation codes and provide the possibility to validate and\nimprove the simulation of hadronic interactions in high-energy physics\ndetectors. \n\n"}
{"id": "1510.06555", "contents": "Title: On numerical Landau damping for splitting methods applied to the\n  Vlasov-HMF model Abstract: We consider time discretizations of the Vlasov-HMF (Hamiltonian Mean-Field)\nequation based on splitting methods between the linear and non-linear parts. We\nconsider solutions starting in a small Sobolev neighborhood of a spatially\nhomogeneous state satisfying a linearized stability criterion (Penrose\ncriterion). We prove that the numerical solutions exhibit a scattering behavior\nto a modified state, which implies a nonlinear Landau damping effect with\npolynomial rate of damping. Moreover, we prove that the modified state is close\nto the continuous one and provide error estimates with respect to the time\nstepsize. \n\n"}
{"id": "1510.07189", "contents": "Title: Approximation of the high-frequency Helmholtz kernel by nested\n  directional interpolation Abstract: We present and analyze an approximation scheme for a class of highly\noscillatory kernel functions, taking the 2D and 3D Helmholtz kernels as\nexamples. The scheme is based on polynomial interpolation combined with\nsuitable pre- and postmultiplication by plane waves. It is shown to converge\nexponentially in the polynomial degree and supports multilevel approximation\ntechniques. Our convergence analysis may be employed to establish exponential\nconvergence of certain classes of fast methods for discretizations of the\nHelmholtz integral operator that feature polylogarithmic-linear complexity. \n\n"}
{"id": "1510.07363", "contents": "Title: Fast hierarchical solvers for sparse matrices using extended\n  sparsification and low-rank approximation Abstract: Inversion of sparse matrices with standard direct solve schemes is robust,\nbut computationally expensive. Iterative solvers, on the other hand,\ndemonstrate better scalability; but, need to be used with an appropriate\npreconditioner (e.g., ILU, AMG, Gauss-Seidel, etc.) for proper convergence. The\nchoice of an effective preconditioner is highly problem dependent. We propose a\nnovel fully algebraic sparse matrix solve algorithm, which has linear\ncomplexity with the problem size. Our scheme is based on the Gauss elimination.\nFor a given matrix, we approximate the LU factorization with a tunable accuracy\ndetermined a priori. This method can be used as a stand-alone direct solver\nwith linear complexity and tunable accuracy, or it can be used as a black-box\npreconditioner in conjunction with iterative methods such as GMRES. The\nproposed solver is based on the low-rank approximation of fill-ins generated\nduring the elimination. Similar to H-matrices, fill-ins corresponding to blocks\nthat are well-separated in the adjacency graph are represented via a\nhierarchical structure. The linear complexity of the algorithm is guaranteed if\nthe blocks corresponding to well-separated clusters of variables are\nnumerically low-rank. \n\n"}
{"id": "1510.07571", "contents": "Title: Implementation of an upward-going muon trigger for indirect dark matter\n  searches at the NO$\\nu$A far detector Abstract: The NO$\\nu$A collaboration has constructed a 14,000 ton, fine-grained, low-Z,\ntotal absorption tracking calorimeter at an off-axis angle to an upgraded NuMI\nneutrino beam. This detector, with its excellent granularity and energy\nresolution and relatively low-energy neutrino thresholds, was designed to\nobserve electron neutrino appearance in a muon neutrino beam, but it also has\nunique capabilities suitable for more exotic efforts. In fact, if an efficient\nupward-going muon trigger with sufficient cosmic ray background rejection can\nbe demonstrated, NO$\\nu$A will be capable of a competitive indirect dark matter\nsearch for low-mass WIMPs. The cosmic ray muon rate at the NO$\\nu$A far\ndetector is about 100 kHz and provides the primary challenge for triggering and\noptimizing such a search analysis. The status of the NO$\\nu$A upward-going muon\ntrigger is presented. \n\n"}
{"id": "1510.07988", "contents": "Title: Hunting for heavy composite Majorana neutrinos at the LHC Abstract: We investigate the search for heavy Majorana neutrinos stemming from a\ncomposite model scenario at the upcoming LHC Run II at a center of mass energy\nof 13 TeV. While previous studies of the composite Majorana neutrino were\nfocussed on gauge interactions via magnetic type transition coupling between\nordinary and heavy fermions (with mass $m^*$) here we complement the composite\nmodel with contact interactions at the energy scale $\\Lambda$ and we find that\nthe production cross sections are dominated by such contact interactions by\nroughly two/three orders of magnitude. This mechanism provides therefore very\ninteresting rates at the prospected luminosities. We study the same sign\ndi-lepton and di-jet signature ($pp \\to \\ell\\ell jj$) and perform a fast\ndetector simulation based on Delphes. We compute 3$\\sigma$ and 5$\\sigma$\ncontour plots of the statistical significance in the parameter space\n($\\Lambda,m^*$). We find that the potentially excluded regions at $\\sqrt{s}\n=13$ TeV are quite larger than those excluded so far at Run I considering\nsearches with other signatures. \n\n"}
{"id": "1511.00305", "contents": "Title: First Run of the LArIAT Testbeam Experiment Abstract: LArIAT (Liquid Argon In A Testbeam) aims to characterize the response of a\nliquid argon time projection chamber (LArTPC) to the particles often seen as\nfinal-state products of ~1 GeV neutrino interactions in existing and planned\ndetectors. The experiment uses the ArgoNeuT cryostat and its refurbished\n170-liter-active-volume TPC placed in a tunable tertiary beamline produced from\na high-energy pion beam at the Fermilab Test Beam Facility (FTBF). The TPC was\nmodified to accommodate cold readout electronics and a light collection system.\nThe first run took place May-June of 2015, and the collected data will help in\nunderstanding electron recombination behavior, shower reconstruction, particle\nidentification, muon sign determination, pion and kaon interactions in argon,\nand the use of scintillation light for calorimetry. \n\n"}
{"id": "1511.01288", "contents": "Title: Target Studies for Surface Muon Production Abstract: Meson factories are powerful drivers of diverse physics programmes. With beam\npowers already in the MW-regime attention has to be turned to target and beam\nline design to further significantly increase surface muon rates available for\nexperiments. For this reason we have explored the possibility of using a\nneutron spallation target as a source of surface muons by performing detailed\nGeant4 simulations with pion production cross sections based on a\nparametrization of existing data. While the spallation target outperforms\nstandard targets in the backward direction by more than a factor 7 it is not\nmore efficient than standard targets viewed under 90{\\deg}. Not surprisingly,\nthe geometry of the target plays a large role in the generation of surface\nmuons. Through careful optimization, a gain in surface muon rate of between 30\n- 60% over the standard \"box-like\" target used at the Paul Scherrer Institute\ncould be achieved by employing a rotated slab target. An additional 10% gain\ncould also be possible by utilizing novel target materials such as, e.g., boron\ncarbide. \n\n"}
{"id": "1511.03645", "contents": "Title: Adjoint Methods for Guiding Adaptive Mesh Refinement in Wave Propagation\n  Problems Abstract: One difficulty in developing numerical methods for hyperbolic systems of\nconservation laws is the fact that solutions often contain regions where much\nhigher resolution is required than elsewhere in the domain, particularly since\nthe solution may contain discontinuities or other localized features. The\nClawpack software deals with this issue by using block-structured adaptive mesh\nrefinement to selectively refine around propagating waves. For problems where\nonly a target area of the total solution is of interest, a method that allows\nidentifying and refining the grid only in regions that influence this target\narea would significantly reduce the computational cost of finding a solution.\n  In this work, we show that solving the time-dependent adjoint equation and\nusing a suitable inner product with the forward solution allows more precise\nrefinement of the relevant waves. We present acoustics examples in one and two\ndimensions and a tsunami propagation example. To perform these simulations, the\nuse of the adjoint method has been integrated into the adaptive mesh refinement\nstrategy of the open source Clawpack and GeoClaw software. We also present\nresults that show that the accuracy of the solution is maintained and the\ncomputational time required is significantly reduced through the integration of\nthe adjoint method into AMR. \n\n"}
{"id": "1511.06197", "contents": "Title: Belle II Silicon Vertex Detector Abstract: The Belle II experiment at the SuperKEKB collider in Japan is designed to\nindirectly probe new physics using approximately 50 times the data recorded by\nits predecessor. An accurate determination of the decay-point position of\nsubatomic particles such as beauty and charm hadrons as well as a precise\nmeasurement of low-momentum charged particles will play a key role in this\npursuit. These will be accomplished by an inner tracking device comprising two\nlayers of pixelated silicon detector and four layers of silicon vertex detector\nbased on double-sided microstrip sensors. We describe herein the design,\nprototyping and construction efforts of the Belle-II silicon vertex detector. \n\n"}
{"id": "1511.09246", "contents": "Title: Sensitivity of NEXT-100 to neutrinoless double beta decay Abstract: NEXT-100 is an electroluminescent high-pressure xenon gas time projection\nchamber that will search for the neutrinoless double beta ($\\beta \\beta 0 \\nu$)\ndecay of Xe-136. The detector possesses two features of great value for $\\beta\n\\beta 0 \\nu$ searches: energy resolution better than 1\\% FWHM at the $Q$ value\nof Xe-136 and track reconstruction for the discrimination of signal and\nbackground events. This combination results in excellent sensitivity, as\ndiscussed in this paper. Material-screening measurements and a detailed Monte\nCarlo detector simulation predict a background rate for NEXT-100 of at most\n$4\\times10^{-4}$ counts keV$^{-1}$ kg$^{-1}$ yr$^{-1}$. Accordingly, the\ndetector will reach a sensitivity to the \\bbonu-decay half-life of\n$2.8\\times10^{25}$ years (90\\% CL) for an exposure of 100\n$\\mathrm{kg}\\cdot\\mathrm{year}$, or $6.0\\times10^{25}$ years after a run of 3\neffective years. \n\n"}
{"id": "1512.00913", "contents": "Title: Formulae for flavour neutrino masses and its application to texture two\n  zeros Abstract: We demonstrate the usefulness of flavour neutrino masses expressed in terms\nof $M_{ee},M_{e\\mu}$ and $M_{e\\tau}$. The analytical expressions for the\nflavour neutrino masses, mass eigenstates and physical CP-violating Majorana\nphases for texture two zeros are obtained exactly. \n\n"}
{"id": "1512.02190", "contents": "Title: Amplitude Analysis for Mesons and Baryons: Tools and Technology Abstract: In these proceedings some facts about resonances are discussed focussing on\nthe analytic properties of resonant amplitudes with special emphasis on model\nindependent analyses. As an illustrative example of the latter point the decays\nB and B_s to J/psi pi pi are discussed in some detail. \n\n"}
{"id": "1512.02202", "contents": "Title: The PROSPECT Physics Program Abstract: The Precision Reactor Oscillation and Spectrum Experiment, PROSPECT, is\ndesigned to make a precise measurement of the antineutrino spectrum from a\nhighly-enriched uranium reactor and probe eV-scale sterile neutrinos by\nsearching for neutrino oscillations over meter-long distances. PROSPECT is\nconceived as a 2-phase experiment utilizing segmented $^6$Li-doped liquid\nscintillator detectors for both efficient detection of reactor antineutrinos\nthrough the inverse beta decay reaction and excellent background\ndiscrimination. PROSPECT Phase I consists of a movable 3-ton antineutrino\ndetector at distances of 7 - 12 m from the reactor core. It will probe the\nbest-fit point of the $\\nu_e$ disappearance experiments at 4$\\sigma$ in 1 year\nand the favored region of the sterile neutrino parameter space at $>$3$\\sigma$\nin 3 years. With a second antineutrino detector at 15 - 19 m from the reactor,\nPhase II of PROSPECT can probe the entire allowed parameter space below 10\neV$^{2}$ at 5$\\sigma$ in 3 additional years. The measurement of the reactor\nantineutrino spectrum and the search for short-baseline oscillations with\nPROSPECT will test the origin of the spectral deviations observed in recent\n$\\theta_{13}$ experiments, search for sterile neutrinos, and conclusively\naddress the hypothesis of sterile neutrinos as an explanation of the reactor\nanomaly. \n\n"}
{"id": "1512.05320", "contents": "Title: A Model for the Secondary Scintillation Pulse Shape from a Gas\n  Proportional Scintillation Counter Abstract: Proportional scintillation counters (PSCs), both single- and dual-phase, can\nmeasure the scintillation (S1) and ionization (S2) channels from particle\ninteractions within the detector volume. The signal obtained from these\ndetectors depends first on the physics of the medium (the initial scintillation\nand ionization), and second how the physics of the detector manipulates the\nresulting photons and liberated electrons. In this paper we develop a model of\nthe detector physics that incorporates event topology, detector geometry,\nelectric field configuration, purity, optical properties of components, and\nwavelength shifters. We present an analytic form of the model, which allows for\ngeneral study of detector design and operation, and a Monte Carlo model which\nenables a more detailed exploration of S2 events. This model may be used to\nstudy systematic effects in currents detectors such as energy and position\nreconstruction, pulse shape discrimination, event topology, dead time\ncalculations, purity, and electric field uniformity. We present a comparison of\nthis model with experimental data collected with an argon gas proportional\nscintillation counter (GPSC), operated at 20 C and 1 bar, and irradiated with\nan internal, collimated 55Fe source. Additionally we discuss how the model may\nbe incorporated in Monte Carlo simulations of both GPSCs and dual-phase\ndetectors, increasing the reliability of the simulation results and allowing\nfor tests of the experimental data analysis algorithms. \n\n"}
{"id": "1512.05409", "contents": "Title: Charge Transfer Properties Through Graphene for Applications in Gaseous\n  Detectors Abstract: Graphene is a single layer of carbon atoms arranged in a honeycomb lattice\nwith remarkable mechanical and electrical properties. Regarded as the thinnest\nand narrowest conductive mesh, it has drastically different transmission\nbehaviours when bombarded with electrons and ions in vacuum. This property, if\nconfirmed in gas, may be a definitive solution for the ion back-flow problem in\ngaseous detectors. In order to ascertain this aspect, graphene layers of\ndimensions of about 2x2cm$^2$, grown on a copper substrate, are transferred\nonto a flat metal surface with holes, so that the graphene layer is freely\nsuspended. The graphene and the support are installed into a gaseous detector\nequipped with a triple Gaseous Electron Multiplier (GEM), and the transparency\nproperties to electrons and ions are studied in gas as a function of the\nelectric fields. The techniques to produce the graphene samples are described,\nand we report on preliminary tests of graphene-coated GEMs. \n\n"}
{"id": "1512.05820", "contents": "Title: Krylov-subspace recycling via the POD-augmented conjugate-gradient\n  method Abstract: This work presents a new Krylov-subspace-recycling method for efficiently\nsolving sequences of linear systems of equations characterized by varying\nright-hand sides and symmetric-positive-definite matrices. As opposed to\ntypical truncation strategies used in recycling such as deflation, we propose a\ntruncation method inspired by goal-oriented proper orthogonal decomposition\n(POD) from model reduction. This idea is based on the observation that model\nreduction aims to compute a low-dimensional subspace that contains an accurate\nsolution; as such, we expect the proposed method to generate a low-dimensional\nsubspace that is well suited for computing solutions that can satisfy inexact\ntolerances. In particular, we propose specific goal-oriented POD `ingredients'\nthat align the optimality properties of POD with the objective of\nKrylov-subspace recycling. To compute solutions in the resulting `augmented'\nPOD subspace, we propose a hybrid direct/iterative three-stage method that\nleverages 1) the optimal ordering of POD basis vectors, and 2) well-conditioned\nreduced matrices. Numerical experiments performed on solid-mechanics problems\nhighlight te benefits of the proposed method over existing approaches for\nKrylov-subspace recycling. \n\n"}
{"id": "1512.05957", "contents": "Title: Technical Design Report for the AMoRE $0\\nu\\beta\\beta$ Decay Search\n  Experiment Abstract: The AMoRE (Advanced Mo-based Rare process Experiment) project is a series of\nexperiments that use advanced cryogenic techniques to search for the\nneutrinoless double-beta decay of \\mohundred. The work is being carried out by\nan international collaboration of researchers from eight countries. These\nsearches involve high precision measurements of radiation-induced temperature\nchanges and scintillation light produced in ultra-pure \\Mo[100]-enriched and\n\\Ca[48]-depleted calcium molybdate ($\\mathrm{^{48depl}Ca^{100}MoO_4}$) crystals\nthat are located in a deep underground laboratory in Korea. The \\mohundred\nnuclide was chosen for this \\zeronubb decay search because of its high\n$Q$-value and favorable nuclear matrix element. Tests have demonstrated that\n\\camo crystals produce the brightest scintillation light among all of the\nmolybdate crystals, both at room and at cryogenic temperatures.\n$\\mathrm{^{48depl}Ca^{100}MoO_4}$ crystals are being operated at milli-Kelvin\ntemperatures and read out via specially developed metallic-magnetic-calorimeter\n(MMC) temperature sensors that have excellent energy resolution and relatively\nfast response times. The excellent energy resolution provides good\ndiscrimination of signal from backgrounds, and the fast response time is\nimportant for minimizing the irreducible background caused by random\ncoincidence of two-neutrino double-beta decay events of \\mohundred nuclei.\nComparisons of the scintillating-light and phonon yields and pulse shape\ndiscrimination of the phonon signals will be used to provide redundant\nrejection of alpha-ray-induced backgrounds. An effective Majorana neutrino mass\nsensitivity that reaches the expected range of the inverted neutrino mass\nhierarchy, i.e., 20-50 meV, could be achieved with a 200~kg array of\n$\\mathrm{^{48depl}Ca^{100}MoO_4}$ crystals operating for three years. \n\n"}
{"id": "1512.07968", "contents": "Title: Technique of production of argon-37 at proton cyclotron and detector for\n  measurements Abstract: The technology of production of the isotope Ar-37 at proton cyclotron is\ndeveloped. It is based on irradiation of the Cl-37 target with the protons of\nenergy of a few a MeV. The example of production of tiny amount of Ar-37 is\ndescribed and discussed. The detectors to measure the intensity of the sample\nis discussed. \n\n"}
{"id": "1601.00640", "contents": "Title: 750 GeV Diphoton excess from $E_6$ in F-theory GUTs Abstract: We interpret the 750-760 GeV diphoton resonance as one or more of the\nspinless components of a singlet superfield arising from the three\n27-dimensional representations of $E_6$ in F-theory, which also contain three\ncopies of colour-triplet charge $\\mp 1/3$ vector-like fermions $D_i,\\bar{D}_i$\nand inert Higgs doublets to which the singlets may couple. For definiteness we\nconsider (without change) a model that was proposed some time ago which\ncontains such states, as well as bulk exotics, leading to gauge coupling\nunification. The smoking gun prediction of the model is the existence of other\nsimilar spinless resonances, possibly close in mass to 750-760 GeV, decaying\ninto diphotons, as well as the three families of vector-like fermions\n$D_i,\\bar{D}_i$. \n\n"}
{"id": "1601.01445", "contents": "Title: TREX-DM: a low background Micromegas-based TPC for low-mass WIMP\n  detection Abstract: Dark Matter experiments are recently focusing their detection techniques in\nlow-mass WIMPs, which requires the use of light elements and low energy\nthreshold. In this context, we describe the TREX-DM experiment, a low\nbackground Micromegas-based TPC for low-mass WIMP detection. Its main goal is\nthe operation of an active detection mass $\\sim$0.3 kg, with an energy\nthreshold below 0.4 keVee and fully built with previously selected radiopure\nmaterials. This work describes the commissioning of the actual setup situated\nin a laboratory on surface and the updates needed for a possible physics run at\nthe Canfranc Underground Laboratory (LSC) in 2016. A preliminary background\nmodel of TREX-DM is also presented, based on a Geant4 simulation, the\nsimulation of the detector's response and two discrimination methods: a\nconservative muon/electron and one based on a neutron source. Based on this\nbackground model, TREX-DM could be competitive in the search for low-mass\nWIMPs. In particular it could be sensitive, e.g., to the low-mass WIMP\ninterpretation of the DAMA/LIBRA and other hints in a conservative scenario. \n\n"}
{"id": "1601.01534", "contents": "Title: Prospects in MPGDs development for neutron detection Abstract: The aim of this document is to summarise the discussion and the contributions\nfrom the 2nd Academia-Industry Matching Event on Detecting Neutrons with MPGDs\nwhich took place at CERN on the 16th and the 17th of March 2015. These events\nprovide a platform for discussing the prospects of Micro-Pattern Gaseous\nDetectors (MPGDs) for thermal and fast neutron detection, commercial\nconstraints and possible solutions. The aim is to foster the collaboration\nbetween the particle physics community, the neutron detector users, instrument\nscientists and fabricants. \n\n"}
{"id": "1601.01751", "contents": "Title: The Joint Physics Analysis Center Website Abstract: The Joint Physics Analysis Center is a collaboration between theorists and\nexperimentalists working in hadronic physics. In order to facilitate the\nexchange of information between the different actors in hadron spectroscopy, we\ncreated an interactive website. In this note, I summarize the first projects\navailable on the website. \n\n"}
{"id": "1601.03779", "contents": "Title: The Majorana Demonstrator Radioassay Program Abstract: The MAJORANA collaboration is constructing the MAJORANA DEMONSTATOR at the\nSanford Underground Research Facility at the Homestake gold mine, in Lead, SD.\nThe apparatus will use Ge detectors, enriched in isotope \\nuc{76}{Ge}, to\ndemonstrate the feasibility of a large-scale Ge detector experiment to search\nfor neutrinoless double beta decay. The long half-life of this postulated\nprocess requires that the apparatus be extremely low in radioactive isotopes\nwhose decays may produce backgrounds to the search. The radioassay program\nconducted by the collaboration to ensure that the materials comprising the\napparatus are sufficiently pure is described. The resulting measurements of the\nradioactive-isotope contamination for a number of materials studied for use in\nthe detector are reported. \n\n"}
{"id": "1601.07107", "contents": "Title: Ergodic problems for Hamilton-Jacobi equations: yet another but\n  efficient numerical method Abstract: We propose a new approach to the numerical solution of ergodic problems\narising in the homogenization of Hamilton-Jacobi (HJ) equations. It is based on\na Newton-like method for solving inconsistent systems of nonlinear equations,\ncoming from the discretization of the corresponding ergodic HJ equations. We\nshow that our method is able to solve efficiently cell problems in very general\ncontexts, e.g., for first and second order scalar convex and nonconvex\nHamiltonians, weakly coupled systems, dislocation dynamics and mean field\ngames, also in the case of more competing populations. A large collection of\nnumerical tests in dimension one and two shows the performance of the proposed\nmethod, both in terms of accuracy and computational time. \n\n"}
{"id": "1601.08245", "contents": "Title: Kalman-Filter-Based Particle Tracking on Parallel Architectures at\n  Hadron Colliders Abstract: Power density constraints are limiting the performance improvements of modern\nCPUs. To address this we have seen the introduction of lower-power, multi-core\nprocessors such as GPGPU, ARM and Intel MIC. To stay within the power density\nlimits but still obtain Moore's Law performance/price gains, it will be\nnecessary to parallelize algorithms to exploit larger numbers of lightweight\ncores and specialized functions like large vector units. Track finding and\nfitting is one of the most computationally challenging problems for event\nreconstruction in particle physics. At the High-Luminosity Large Hadron\nCollider (HL-LHC), for example, this will be by far the dominant problem. The\nneed for greater parallelism has driven investigations of very different track\nfinding techniques such as Cellular Automata or Hough Transforms. The most\ncommon track finding techniques in use today, however, are those based on the\nKalman Filter. Significant experience has been accumulated with these\ntechniques on real tracking detector systems, both in the trigger and offline.\nThey are known to provide high physics performance, are robust, and are in use\ntoday at the LHC. We report on porting these algorithms to new parallel\narchitectures. Our previous investigations showed that, using optimized data\nstructures, track fitting with Kalman Filter can achieve large speedups both\nwith Intel Xeon and Xeon Phi. We report here our progress towards an end-to-end\ntrack reconstruction algorithm fully exploiting vectorization and\nparallelization techniques in a realistic experimental environment. \n\n"}
{"id": "1602.00814", "contents": "Title: Boundary Variation Diminishing (BVD) reconstruction: a new approach to\n  improve Godunov scheme Abstract: This paper presents a new approach, so-called boundary variation diminishing\n(BVD), for reconstructions that minimize the discontinuities (jumps) at cell\ninterfaces in Godunov type schemes. It is motivated by the observation that\ndiminishing the jump at the cell boundary might effectively reduce the\ndissipation in numerical flux. Different from the existing practices which seek\nhigh-order polynomials within mesh cells while assuming discontinuities being\nalways at the cell interfaces, we proposed a new strategy that combines a\nhigh-order polynomial-based interpolation and a jump-like reconstruction that\nallows a discontinuity being partly represented within the mesh cell rather\nthan at the interface. It is shown that new schemes of high fidelity for both\ncontinuous and discontinuous solutions can be devised by the BVD guideline with\nproperly-chosen candidate reconstruction schemes. Excellent numerical results\nhave been obtained for both scalar and Euler conservation laws with\nsubstantially improved solution quality in comparison with the existing\nmethods. This work provides a simple and accurate alternative of great\npractical significance to the current Godunov paradigm which overly pursues the\nsmoothness within mesh cell under the questionable premiss that discontinuities\nonly appear at cell interfaces. \n\n"}
{"id": "1602.02711", "contents": "Title: Residual equilibrium schemes for time dependent partial differential\n  equations Abstract: Many applications involve partial differential equations which admits\nnontrivial steady state solutions. The design of schemes which are able to\ndescribe correctly these equilibrium states may be challenging for numerical\nmethods, in particular for high order ones. In this paper, inspired by\nmicro-macro decomposition methods for kinetic equations, we present a class of\nschemes which are capable to preserve the steady state solution and achieve\nhigh order accuracy for a class of time dependent partial differential\nequations including nonlinear diffusion equations and kinetic equations.\nExtension to systems of conservation laws with source terms are also discussed. \n\n"}
{"id": "1602.03338", "contents": "Title: On a new property of $n$-poised and $GC_n$ sets Abstract: In this paper we consider n-poised planar node sets, as well as more special\nones, called $GC_n$-sets. For these sets all $n$-fundamental polynomials are\nproducts of n linear factors as it always takes place in the univariate case. A\nline ${\\ell}$ is called $k$-node line for a node set $\\mathcal X$ if it passes\nthrough exactly $k$ nodes. An $(n+1)$-node line is called maximal line. In 1982\nM. Gasca and J. I. Maeztu conjectured that every $GC_n$-set possesses\nnecessarily a maximal line. Till now the conjecture is confirmed to be true for\n$n \\le 5$. It is well-known that any maximal line $M$ of $\\mathcal X$ is used\nby each node in $\\mathcal X\\setminus M,$ meaning that it is a factor of the\nfundamental polynomial of each node. In this paper we prove, in particular,\nthat if the Gasca-Maeztu conjecture is true then any $n$-node line of\n$GC_n$-set $\\mathcal X$ is used either by exactly $\\binom{n}{2}$ nodes or by\nexactly $\\binom{n-1}{2}$ nodes. We prove also similar statements concerning\n$n$-node or $(n-1)$-node lines in more general $n$-poised sets. This is a new\nphenomenon in $n$-poised and $GC_n$ sets. At the end we present a conjecture\nconcerning any $k$-node line. \n\n"}
{"id": "1602.04442", "contents": "Title: Mass hierarchy sensitivity of medium baseline reactor neutrino\n  experiments with multiple detectors Abstract: We report the neutrino mass hierarchy (MH) sensitivity of medium baseline\nreactor neutrino experiments with multiple detectors. Sensitivity of\ndetermining the MH can be significantly improved by adding a near detector and\ncombining both the near and far detectors. The size of the sensitivity\nimprovement is related to accuracy of the individual mass-splitting\nmeasurements and requires strict control on the relative energy scale\nuncertainty of the near and far detectors. We study the impact of both baseline\nand target mass of the near detector on the combined sensitivity. A\nfigure-of-merit is defined to optimize the baseline and target mass of the near\ndetector and the optimal selections are $\\sim$13~km and $\\sim$4~kton\nrespectively for a far detector with the 20~kton target mass and 52.5~km\nbaseline. As typical examples of future medium baseline reactor neutrino\nexperiments, the optimal location and target mass of the near detector are\nselected for JUNO and RENO-50. Finally, we discuss distinct effects of the\nneutrino spectrum uncertainty for setups of a single detector and double\ndetectors, which indicate that the spectrum uncertainty can be well constrained\nin the presence of the near detector. \n\n"}
{"id": "1602.05354", "contents": "Title: An $hp$-Adaptive Newton-Galerkin Finite Element Procedure for Semilinear\n  Boundary Value Problems Abstract: In this paper we develop an $hp$-adaptive procedure for the numerical\nsolution of general, semilinear elliptic boundary value problems in 1d, with\npossible singular perturbations. Our approach combines both a prediction-type\nadaptive Newton method and an $hp$-version adaptive finite element\ndiscretization (based on a robust a posteriori residual analysis), thereby\nleading to a fully $hp$-adaptive Newton-Galerkin scheme. Numerical experiments\nunderline the robustness and reliability of the proposed approach for various\nexamples. \n\n"}
{"id": "1602.06146", "contents": "Title: Vacuum energy in some particular quantum field theories Abstract: We study the properties of a class of quantum field theories endowed with an\nequal number of anti commuting and commuting field variables, the most common\nexample being the supersymmetric models. Based on the scaling properties of the\npartition function we find that these theories have the quantum energy momentum\ntensor associated to dilatations and thus the vacuum energy equal to zero. \n\n"}
{"id": "1602.07234", "contents": "Title: UV (in)sensitivity of Higgs inflation Abstract: The predictions of Standard Model Higgs inflation are in excellent agreement\nwith the Planck data, without the need for new fields. However, consistency of\nthe theory requires the presence of (unknown) threshold corrections. These\nmodify the running of the couplings, and thereby change the shape of the\ninflationary potential. This raises the question how sensitive the CMB\nparameters are to the UV completion. We show that, due to a precise\ncancellation, the inflationary predictions are almost unaffected. This implies\nin general that one cannot relate the spectral index and tensor-to-scalar ratio\nto the precise top and Higgs mass measurements at the LHC, nor can one probe\neffects of UV physics on the running. \n\n"}
{"id": "1603.00098", "contents": "Title: Cosmogenic Activation of Materials Used in Rare Event Search Experiments Abstract: We evaluate the cosmogenic production rates in some materials that are\ncommonly used as targets and shielding/supporting components for detecting rare\nevents. The results from Geant4 simulations are compared with the calculations\nof ACTIVIA and the available experimental data. We demonstrate that the\nproduction rates from the Geant4-based simulations agree with the available\ndata reasonably well. As a result, we report that the cosmogenic production of\nseveral isotopes in various materials can generate potential backgrounds for\ndirect detection of dark matter and neutrinoless double-beta decay. \n\n"}
{"id": "1603.01251", "contents": "Title: An Intermediate Water Cherenkov Detector at J-PARC Abstract: Recent neutrino oscillation results have shown that the existing long\nbaseline experiments have some sensitivity to the effects of CP violation in\nthe neutrino sector. This sensitivity is currently statistically limited, but\nthe next generation of experiments, DUNE and Hyper-K, will provide an order of\nmagnitude more events. To reach the full potential of these datasets we must\nachieve a commensurate improvement in our understanding of the systematic\nuncertainties that beset them. This talk describes two proposed intermediate\ndetectors for the current and future long baseline oscillation experiments in\nJapan, TITUS and NuPRISM. These detectors are discussed in the context of the\ncurrent T2K oscillation analysis, highlighting the ways in which they could\nreduce the systematic uncertainty on this measurement. The talk also describes\nthe short baseline oscillation sensitivity of NuPRISM along with the neutrino\nscattering measurements the detector makes possible. \n\n"}
{"id": "1603.07798", "contents": "Title: Results of the 2015 testbeam of a 180 nm AMS High-Voltage CMOS sensor\n  prototype Abstract: Active pixel sensors based on the High-Voltage CMOS technology are being\ninvestigated as a viable option for the future pixel tracker of the ATLAS\nexperiment at the High-Luminosity LHC. This paper reports on the testbeam\nmeasurements performed at the H8 beamline of the CERN Super Proton Synchrotron\non a High-Voltage CMOS sensor prototype produced in 180 nm AMS technology.\nResults in terms of tracking efficiency and timing performance, for different\nthreshold and bias conditions, are shown. \n\n"}
{"id": "1603.08002", "contents": "Title: Simplified Models vs. Effective Field Theory Approaches in Dark Matter\n  Searches Abstract: In this review we discuss and compare the usage of simplified models and\nEffective Field Theory (EFT) approaches in dark matter searches. We provide a\nstate of the art description on the subject of EFTs and simplified models,\nespecially in the context of collider searches for dark matter, but also with\nimplications for direct and indirect detection searches, with the aim of\nconstituting a common language for future comparisons between different\nstrategies. The material is presented in a form that is as self-contained as\npossible, so that it may serve as an introductory review for the newcomer as\nwell as a reference guide for the practitioner. \n\n"}
{"id": "1603.08751", "contents": "Title: The MuPix System-on-Chip for the Mu3e Experiment Abstract: Mu3e is a novel experiment searching for charged lepton flavor violation in\nthe rare decay $\\mu^+ \\rightarrow e^+e^-e^+$. Decay vertex position, decay time\nand particle momenta have to be precisely measured in order to reject both\naccidental and physics background. A silicon pixel tracker based on $50\\,\\mu$m\nthin high voltage monolithic active pixel sensors (HV-MAPS) in a 1 T solenoidal\nmagnetic field provides precise vertex and momentum information. The MuPix chip\ncombines pixel sensor cells with integrated analog electronics and a periphery\nwith a complete digital readout. The MuPix7 is the first HV-MAPS prototype\nimplementing all functionalities of the final sensor including a readout state\nmachine and high speed serialization with 1.25 Gbit/s data output, allowing for\na streaming readout in parallel to the data taking. The observed efficiency of\nthe MuPix7 chip including the full readout system is $\\geq99\\%$ in a high rate\ntest beam. \n\n"}
{"id": "1603.09660", "contents": "Title: Stable Isogeometric Analysis of Trimmed Geometries Abstract: We explore extended B-splines as a stable basis for isogeometric analysis\nwith trimmed parameter spaces. The stabilization is accomplished by an\nappropriate substitution of B-splines that may lead to ill-conditioned system\nmatrices. The construction for non-uniform knot vectors is presented. The\nproperties of extended B-splines are examined in the context of interpolation,\npotential, and linear elasticity problems and excellent results are attained.\nThe analysis is performed by an isogeometric boundary element formulation using\ncollocation. It is argued that extended B-splines provide a flexible and simple\nstabilization scheme which ideally suits the isogeometric paradigm. \n\n"}
{"id": "1604.01083", "contents": "Title: A Comprehensive Study of Low-Energy Response for Xenon-Based Dark Matter\n  Experiments Abstract: We report a comprehensive study of the energy response to low-energy recoils\nin dual-phase xenon-based dark matter experiments. A recombination model is\ndeveloped to explain the recombination probability as a function of recoil\nenergy at zero field and non-zero field. The role of e-ion recombination is\ndiscussed for both parent recombination and volume recombination. We find that\nthe volume recombination under non-zero field is constrained by a plasma\neffect, which is caused by a high density of charge carriers along the\nionization track forming a plasma-like cloud of charge that shields the\ninterior from the influence of the external electric field. Subsequently, the\nplasma time that determines the volume recombination probability at non-zero\nfield is demonstrated to be different between electronic recoils and nuclear\nrecoils due to the difference of ionization density between two processes. We\nshow a weak field-dependence of the plasma time for nuclear recoils and a\nstronger field-dependence of the plasma time for electronic recoils. As a\nresult, the time-dependent recombination is implemented in the determination of\ncharge and light yield with a generic model. Our model agrees well with the\navailable experimental data from xenon-based dark matter experiments. \n\n"}
{"id": "1604.01415", "contents": "Title: Containment and resolution of hadronic showers at the FCC Abstract: The particles produced at a potential Future Circular Collider with\n$\\sqrt{s}$ = 100 TeV are of unprecented energies. In this document we present\nthe hadronic shower containment and resolution parametrizations based on Geant4\nsimulations for the Hadronic calorimetry needed for conceptual detector design\nat this energy. The Geant4 toolkit along with FTFP\\_BERT physics list are used\nin this study. Comparisons are made with test-beam data from the ATLAS Tile\nhadronic calorimeter. These simulations motivate a 12 $\\lambda$ calorimeter in\norder to contain at 98% level TeV single hadron showers and multi-TeV jets and\nkeep a pion energy resolution constant term of 3%. \n\n"}
{"id": "1604.02267", "contents": "Title: Material Optimization for Nonlinearly Elastic Planar Beams Abstract: We consider the problem of an optimal distribution of soft and hard material\nfor nonlinearly elastic planar beams. We prove that under gravitational force\nthe optimal distribution involves no microstructure and is ordered, and we\nprovide numerical simulations confirming and extending this observation. \n\n"}
{"id": "1604.02957", "contents": "Title: From vertex detectors to inner trackers with CMOS pixel sensors Abstract: The use of CMOS Pixel Sensors (CPS) for high resolution and low material\nvertex detectors has been validated with the 2014 and 2015 physics runs of the\nSTAR-PXL detector at RHIC/BNL. This opens the door to the use of CPS for inner\ntracking devices, with 10-100 times larger sensitive area, which require\ntherefore a sensor design privileging power saving, response uniformity and\nrobustness. The 350 nm CMOS technology used for the STAR-PXL sensors was\nconsidered as too poorly suited to upcoming applications like the upgraded\nALICE Inner Tracking System (ITS), which requires sensors with one order of\nmagnitude improvement on readout speed and improved radiation tolerance. This\ntriggered the exploration of a deeper sub-micron CMOS technology, Tower-Jazz\n180 nm, for the design of a CPS well adapted for the new ALICE-ITS running\nconditions. This paper reports the R&D results for the conception of a CPS well\nadapted for the ALICE-ITS. \n\n"}
{"id": "1604.04106", "contents": "Title: Investigation of the Coincidence Resolving Time performance of a PET\n  scanner based on liquid xenon: A Monte Carlo study Abstract: The measurement of the time of flight of the two 511 keV gammas recorded in\ncoincidence in a PET scanner provides an effective way of reducing the random\nbackground and therefore increases the scanner sensitivity, provided that the\ncoincidence resolving time (CRT) of the gammas is sufficiently good. The best\ncommercial PET-TOF system today (based in LYSO crystals and digital SiPMs), is\nthe VEREOS of Philips, boasting a CRT of 316 ps (FWHM). In this paper we\npresent a Monte Carlo investigation of the CRT performance of a PET scanner\nexploiting the scintillating properties of liquid xenon. We find that an\nexcellent CRT of 70 ps (depending on the PDE of the sensor) can be obtained if\nthe scanner is instrumented with silicon photomultipliers (SiPMs) sensitive to\nthe ultraviolet light emitted by xenon. Alternatively, a CRT of 160 ps can be\nobtained instrumenting the scanner with (much cheaper) blue-sensitive SiPMs\ncoated with a suitable wavelength shifter. These results show the excellent\ntime of flight capabilities of a PET device based in liquid xenon. \n\n"}
{"id": "1604.05825", "contents": "Title: Convergence of the Cyclic and Quasi-cyclic Block Jacobi Methods Abstract: The paper studies the global convergence of the block Jacobi me\\-thod for\nsymmetric matrices. Given a symmetric matrix $A$ of order $n$, the method\ngenerates a sequence of matrices by the rule $A^{(k+1)}=U_k^TA^{(k)}U_k$,\n$k\\geq0$, where $U_k$ are orthogonal elementary block matrices. A class of\ngeneralized serial pivot strategies is introduced, significantly enlarging the\nknown class of weak wavefront strategies, and appropriate global convergence\nproofs are obtained. The results are phrased in the stronger form: $S(A')\\leq c\nS(A)$, where $A'$ is the matrix obtained from $A$ after one full cycle, $c<1$\nis a constant and $S(A)$ is the off-norm of $A$. Hence, using the theory of\nblock Jacobi operators, one can apply the obtained results to prove convergence\nof block Jacobi methods for other eigenvalue problems, such as the generalized\neigenvalue problem. As an example, the results are applied to the block\n$J$-Jacobi method. Finally, all results are extended to the corresponding\nquasi-cyclic strategies. \n\n"}
{"id": "1604.05953", "contents": "Title: On the construction of Lyapunov functions with computer assistance Abstract: Computer assisted procedures of Lyapunov functions defined in given\nneighborhoods of fixed points for flows and maps are discussed. We provide a\nsystematic methodology for constructing explicit ranges where quadratic\nLyapunov functions exist in two stages; negative definiteness of associating\nmatrices and direct approach. We note that the former is equivalent to the\nprocedure of cones describing enclosures of the stable and the unstable\nmanifolds of invariant sets, which gives us flexible discussions of asymptotic\nbehavior not only around equilibria for flows but also fixed points for maps.\nAdditionally, our procedure admits a re-parameterization of trajectories in\nterms of values of Lyapunov functions. Several verification examples are shown\nfor discussions of applicability. \n\n"}
{"id": "1604.06043", "contents": "Title: M(s)stab(L): A Generalization of IDR(s)stab(L) for Sequences of Linear\n  Systems Abstract: We propose Mstab, a novel Krylov subspace recycling method for the iterative\nsolution of sequences of linear systems with fixed system matrix and changing\nright-hand sides. This new method is a straight and simple generalization of\nIDRstab. IDRstab in turn is a very efficient method and generalization of\nBiCGStab.\n  The theory of Mstab is based on a generalization of the IDR theorem and\nSonneveld spaces.\n  Numerical experiments indicate that Mstab can solve sequences of linear\nsystems faster than its corresponding IDRstab variant. Instead, when solving a\nsingle system both methods are identical. \n\n"}
{"id": "1604.07486", "contents": "Title: Fast polynomial transforms based on Toeplitz and Hankel matrices Abstract: Many standard conversion matrices between coefficients in classical\northogonal polynomial expansions can be decomposed using diagonally-scaled\nHadamard products involving Toeplitz and Hankel matrices. This allows us to\nderive $\\smash{\\mathcal{O}(N(\\log N)^2)}$ algorithms, based on the fast Fourier\ntransform, for converting coefficients of a degree $N$ polynomial in one\npolynomial basis to coefficients in another. Numerical results show that this\napproach is competitive with state-of-the-art techniques, requires no\nprecomputational cost, can be implemented in a handful of lines of code, and is\neasily adapted to extended precision arithmetic. \n\n"}
{"id": "1605.00143", "contents": "Title: Performance of the ALICE secondary vertex b-tagging algorithm Abstract: The identification of jets originating from beauty quarks in heavy-ion\ncollisions is important to study the properties of the hot and dense matter\nproduced in such collisions. A variety of algorithms for b-jet tagging was\nelaborated at the LHC experiments. They rely on the properties of B hadrons,\ni.e. their long lifetime, large mass and large multiplicity of decay products.\nIn this work, the b-tagging algorithm based on displaced secondary-vertex\ntopologies is described. We present Monte Carlo based performance studies of\nthe algorithm for charged jets reconstructed with the ALICE tracking system in\np-Pb collisions at $\\sqrt{s_\\text{NN}}$ = 5.02 TeV. The tagging efficiency,\nrejection rate and the correction of the smearing effects of non-ideal detector\nresponse are presented. \n\n"}
{"id": "1605.01040", "contents": "Title: Enhanced Rates for Diphoton Resonances in the MSSM Abstract: We propose a simple mechanism for copiously producing heavy Higgs bosons with\nenhanced decay rates to two photons at the LHC, within the context of the\nMinimal Supersymmetric extension of the Standard Model (MSSM). In the\nCP-conserving limit of the theory, such a diphoton resonance may be identified\nwith the heavier CP-even $H$ boson, whose gluon-fusion production and decay\ninto two photons are enhanced by loops of the lightest supersymmetric partner\nof the top quark $\\tilde{t}_1$ when its mass $m_{\\tilde{t}_1}$ happens to be\nnear the $\\tilde{t}^*_1\\tilde{t}_1$ threshold, i.e.~for\n$m_{\\tilde{t}_1}\\!\\simeq \\!\\frac12 M_H$. The scenario requires a relatively low\nsupersymmetry-breaking scale $M_S\\stackrel{<}{{}_\\sim} 1$ TeV, but large values\nof the higgsino mass parameter, $\\mu \\stackrel{>}{{}_\\sim} 1$ TeV, that lead to\na strong $H \\tilde{t}^*_1 \\tilde{t}_1$ coupling. Such parameters can\naccommodate the observed mass and standard-like couplings of the 125 GeV $h$\nboson in the MSSM, while satisfying all other constraints from the LHC and dark\nmatter searches. Additional enhancement to the diphoton rate could be provided\nby Coulombic QCD corrections and, to a lesser extent, by resonant contributions\ndue to $\\tilde{t}_1^* \\tilde{t}_1$ bound states. To discuss the characteristic\nfeatures of such a scenario, we consider as an illustrative example the case of\na diphoton resonance with a mass of approximately 750 GeV, for which an excess\nwas observed in the early LHC 13 TeV data and which later turned out to be\nsimply a statistical fluctuation. \n\n"}
{"id": "1605.01683", "contents": "Title: Direct and Semi-Direct Approaches to Lepton Mixing with a Massless\n  Neutrino Abstract: We discuss the possibility of enforcing a massless Majorana neutrino in the\ndirect and semi-direct approaches to lepton mixing, in which the PMNS matrix is\npartly predicted by subgroups of a discrete family symmetry, extending previous\ngroup searches up to order 1535. We find a phenomenologically viable scheme for\nthe semi-direct approach based on $Q(648)$ which contains $\\Delta(27)$ and the\nquaternion group as subgroups. This leads to novel predictions for the first\ncolumn of the PMNS matrix corresponding to a normal neutrino mass hierarchy\nwith $m_1=0$, and sum rules for the mixing angles and phase which are\ncharacterised by the solar angle being on the low side $\\theta_{12}\\sim\n31^{\\circ}$ and the Dirac (oscillation) CP phase $\\delta$ being either about\n$\\pm 45^\\circ$ or $\\pm \\pi$. \n\n"}
{"id": "1605.06102", "contents": "Title: hi_class: Horndeski in the Cosmic Linear Anisotropy Solving System Abstract: We present the public version of hi_class (www.hiclass-code.net), an\nextension of the Boltzmann code CLASS to a broad ensemble of modifications to\ngeneral relativity. In particular, hi_class can calculate predictions for\nmodels based on Horndeski's theory, which is the most general scalar-tensor\ntheory described by second-order equations of motion and encompasses any\nperfect-fluid dark energy, quintessence, Brans-Dicke, $f(R)$ and covariant\nGalileon models. hi_class has been thoroughly tested and can be readily used to\nunderstand the impact of alternative theories of gravity on linear structure\nformation as well as for cosmological parameter extraction. \n\n"}
{"id": "1605.06235", "contents": "Title: Development and Commissioning of the HARDROC based Readout for the\n  INO-ICAL Experiment Abstract: Glass based Resistive Plate Chambers (RPCs) are going to be used as an active\nelement in the Iron Calorimeter (ICAL) experiment at the India based Neutrino\nObservatory (INO), which is being constructed to study atmospheric neutrinos.\nThough the RPC detector operational parameters are more or less finalized, the\nreadout electronics is being developed using various technologies. The ICAL\nexperiment will consist of about 29,000 RPC detectors of 2 m $\\times$ 2 m in\nsize with each detector having 64 readout channels both in the X and Y\ndirections. The present study focusses on multi-channel electronics based on\nSiGe 350 nm technology as an option for the INO-ICAL RPC detectors. The study\nincludes commissioning and usage of frontend application specific integrated\ncircuit (ASIC) HARDROC chip in which 64 channels are handled independently to\nperform zero suppression. We present first testbench results using the HARDROC\nchip with the aim to use it finally in the ICAL experiment. \n\n"}
{"id": "1605.06515", "contents": "Title: A Determination of the Charm Content of the Proton Abstract: We present an unbiased determination of the charm content of the proton, in\nwhich the charm parton distribution function (PDF) is parametrized on the same\nfooting as the light quarks and the gluon in a global PDF analysis. This\ndetermination relies on the calculation of deep-inelastic structure functions\nin the FONLL scheme, generalized to account for massive charm-initiated\ncontributions. In contrast to the usual situation in which the charm PDF is\nassumed to be generated perturbatively by pair radiation off gluons and light\nquarks, vanishing at a scale set by the value of the charm mass m_c, we find\nthat the fitted charm PDF vanishes within uncertainties at a scale Q~1.5 GeV\nfor all x<~0.1, independent of the value of m_c used in the coefficient\nfunctions. We also find some evidence that the charm PDF at large x>~0.1 and\nlow scales does not vanish, but rather has an \"intrinsic\" component, very\nweakly scale dependent and almost independent of the value of m_c, carrying\nabout 1% of the total momentum of the proton. The uncertainties in all other\nPDFs are only slightly increased by the inclusion of fitted charm, while the\ndependence of these PDFs on m_c is significantly reduced. When the EMC charm\nstructure function dataset is included, it is well described by the fit, and\nPDF uncertainties in the fitted charm PDF are significantly reduced, though we\nverify that excluding the EMC data does not qualitatively modify any of our\nfindings. The increased stability with respect to m_c persists at high scales\nand is the main implication of our results for LHC phenomenology. Fitting the\ncharm PDF modifies the predictions for processes such as high p_T and large\nrapidity charm pair production and Z+c production, and thus we expect that\nfuture LHC data will further constrain the charm content of the proton. \n\n"}
{"id": "1605.06912", "contents": "Title: Approximations for the Caputo Derivative (I) Abstract: In this paper we construct approximations for the Caputo derivative of order\n$1-\\alpha,2-\\alpha,2$ and $3-\\alpha$. The approximations have weights\n$0.5\\left((k+1)^{-\\alpha}-(k-1)^{-\\alpha}\\right)/\\Gamma(1-\\alpha)$ and\n$k^{-1-\\alpha}/\\Gamma(-\\alpha)$, and the higher accuracy is achieved by\nmodifying the initial and last weights using the expansion formulas for the\nleft and right endpoints. The approximations are applied for computing the\nnumerical solution of ordinary fractional differential equations. The\nproperties of the weights of the approximations of order $2-\\alpha$ are similar\nto the properties of the $L1$ approximation. In all experiments presented in\nthe paper the accuracy of the numerical solutions using the approximation of\norder $2-\\alpha$ which has weights $k^{-1-\\alpha}/\\Gamma(-\\alpha)$ is higher\nthan the accuracy of the numerical solutions using the $L1$ approximation for\nthe Caputo derivative. \n\n"}
{"id": "1605.07458", "contents": "Title: Scale Invariance at low accelerations (aka MOND) and the dynamical\n  anomalies in the Universe Abstract: Galactic systems, and the Universe at large, exhibit large dynamical\nanomalies: The observed matter in them falls very short of providing enough\ngravity to account for their dynamics. The mainstream response to this\nconundrum is to invoke large quantities of `dark matter' -- which purportedly\nsupplies the needed extra gravity -- and also of `dark energy', to account for\nfurther anomalies in cosmology, such as the observed, accelerated expansion.\nThe MOND paradigm offers a different solution: a breakdown of standard dynamics\n(gravity and/or inertia) in the limit of low accelerations -- below some\nacceleration $a_0$. In this limit, dynamics become space-time scale invariant,\nand is controlled by a gravitational constant $\\mathcal{A}_0\\equiv Ga_0$, which\nreplaces Newton's $G$. With the new dynamics, the various detailed\nmanifestations of the anomalies in galaxies are predicted with no need for dark\nmatter. The cosmological anomalies could, but need not have to do with small\naccelerations. For example, the need for dark matter in accounting for the\nexpansion history of the Universe is eliminated if the relevant gravitational\nconstant is $\\approx 2\\pi G$. Such a `renormalization' of $G$ could be a\ndimensionless parameter of a MOND theory. The constant $a_0$ turns out to carry\ncosmological connotations, in that $2\\pi a_0\\approx cH_0\\approx\nc^2(\\Lambda/3)^{1/2}$, where $H_0$ is the present expansion rate of the\nUniverse, and $\\Lambda$ the measured `cosmological constant'. There are MOND\ntheories in which this `coincidence' is natural. I draw on enlightening\nhistorical and conceptual analogies from quantum theory to limelight aspects of\nMOND. I also explain how MOND may have strong connections with effects of the\nquantum vacuum on local dynamics. \n\n"}
{"id": "1605.07804", "contents": "Title: Galerkin Spectral Method for the Fractional Nonlocal Thermistor Problem Abstract: We develop and analyse a numerical method for the time-fractional nonlocal\nthermistor problem. By rigorous proofs, some error estimates in different\ncontexts are derived, showing that the combination of the backward\ndifferentiation in time and the Galerkin spectral method in space leads, for an\nenough smooth solution, to an approximation of exponential convergence in\nspace. \n\n"}
{"id": "1605.08101", "contents": "Title: Global rates of convergence for nonconvex optimization on manifolds Abstract: We consider the minimization of a cost function $f$ on a manifold $M$ using\nRiemannian gradient descent and Riemannian trust regions (RTR). We focus on\nsatisfying necessary optimality conditions within a tolerance $\\varepsilon$.\nSpecifically, we show that, under Lipschitz-type assumptions on the pullbacks\nof $f$ to the tangent spaces of $M$, both of these algorithms produce points\nwith Riemannian gradient smaller than $\\varepsilon$ in $O(1/\\varepsilon^2)$\niterations. Furthermore, RTR returns a point where also the Riemannian\nHessian's least eigenvalue is larger than $-\\varepsilon$ in\n$O(1/\\varepsilon^3)$ iterations. There are no assumptions on initialization.\nThe rates match their (sharp) unconstrained counterparts as a function of the\naccuracy $\\varepsilon$ (up to constants) and hence are sharp in that sense.\n  These are the first deterministic results for global rates of convergence to\napproximate first- and second-order Karush-Kuhn-Tucker points on manifolds.\nThey apply in particular for optimization constrained to compact submanifolds\nof $\\mathbb{R}^n$, under simpler assumptions. \n\n"}
{"id": "1605.08568", "contents": "Title: Computation of highly oscillatory Bessel transforms with algebraic\n  singularities Abstract: In this paper, we consider the Clenshaw-Curtis-Filon method for the highly\noscillatory Bessel transform $\\int_0^1x^\\alpha (1-x)^\\beta f(x) J_{\\nu}(\\omega\nx)dx$, where $f$ is a smooth function on $[0, 1]$, and $\\nu\\geq0.$ The method\nis based on Fast Fourier Transform (FFT) and fast computation of the modified\nmoments. We give a recurrence relation for the modified moments and present an\nefficient method for the evaluation of modified moments by using recurrence\nrelation. Moreover, the corresponding error bound in inverse powers of $N$ for\nthis method for the integral is presented. Numerical examples are provided to\nsupport our analysis and show the efficiency and accuracy of the method. \n\n"}
{"id": "1605.09118", "contents": "Title: JUNO: a General Purpose Experiment for Neutrino Physics Abstract: JUNO is a 20 kt Liquid Scintillator Antineutrino Detector currently under\nconstruction in the south of China. This report reviews JUNO's physics\nprogramme related to all neutrino sources but reactor antineutrinos, namely\nneutrinos from supernova burst, solar neutrinos and geoneutrinos. \n\n"}
{"id": "1605.09630", "contents": "Title: A compact light readout system for longitudinally segmented shashlik\n  calorimeters Abstract: The longitudinal segmentation of shashlik calorimeters is challenged by dead\nzones and non-uniformities introduced by the light collection and readout\nsystem. This limitation can be overcome by direct fiber-photosensor coupling,\navoiding routing and bundling of the wavelength shifter fibers and embedding\nultra-compact photosensors (SiPMs) in the bulk of the calorimeter. We present\nthe first experimental test of this readout scheme performed at the CERN PS-T9\nbeamline in 2015 with negative particles in the 1-5~GeV energy range. In this\npaper, we demonstrate that the scheme does not compromise the energy resolution\nand linearity compared with standard light collection and readout systems. In\naddition, we study the performance of the calorimeter for partially contained\ncharged hadrons to assess the $e/\\pi$ separation capability and the response of\nthe photosensors to direct ionization. \n\n"}
{"id": "1606.01398", "contents": "Title: High rate, fast timing Glass RPC for the high {\\eta} CMS muon detectors Abstract: The HL-LHC phase is designed to increase by an order of magnitude the amount\nof data to be collected by the LHC experiments. To achieve this goal in a\nreasonable time scale the instantaneous luminosity would also increase by an\norder of magnitude up to $6.10^{34} cm^{-2} s^{-1}$ . The region of the forward\nmuon spectrometer ($|{\\eta}| > 1.6$) is not equipped with RPC stations. The\nincrease of the expected particles rate up to $2 kHz/cm^{2}$ (including a\nsafety factor 3) motivates the installation of RPC chambers to guarantee\nredundancy with the CSC chambers already present. The actual RPC technology of\nCMS cannot sustain the expected background level. The new technology that will\nbe chosen should have a high rate capability and provides a good spatial and\ntiming resolution. A new generation of Glass-RPC (GRPC) using low-resistivity\n(LR) glass is proposed to equip at least the two most far away of the four high\n${\\eta}$ muon stations of CMS. First the design of small size prototypes and\nstudies of their performance in high-rate particles flux is presented. Then the\nproposed designs for large size chambers and their fast-timing electronic\nreadout are examined and preliminary results are provided. \n\n"}
{"id": "1606.02146", "contents": "Title: Low energy recoil detection with a spherical proportional counter Abstract: We present low energy recoil detection results in the keV energy region, from\nmeasurements performed with the Spherical Proportional Counter (SPC). An\n${}^{241}Am-{}^{9}{Be}$ fast neutron source is used in order to obtain\nneutron-nucleus elastic scattering events inside the gaseous volume of the\ndetector. The detector performance in the $keV$ energy region was resolved by\nobserving the $5.9\\ keV$ line of a ${}^{55}Fe$ X-ray source, with energy\nresolution of $9\\%$ ($\\sigma$). The toolkit GEANT4 was used to simulate the\nirradiation of the detector by an ${}^{241}Am-{}^{9}{Be}$ source, while SRIM\nwas used to calculate the Ionization Quenching Factor (IQF). The GEANT4\nsimulated energy deposition spectrum in addition with the SRIM calculated\nquenching factor provide valuable insight to the experimental results. The\nperformance of the SPC in low energy recoil detection makes the detector a good\ncandidate for a wide range of applications, including Supernova or reactor\nneutrino detection and Dark Matter (WIMP) searches (via coherent elastic\nscattering). \n\n"}
{"id": "1606.02259", "contents": "Title: Three-body scattering problem in the fixed center approximation: the\n  case of attraction Abstract: We study the scattering of a light particle on a bound pair of heavy\nparticles (e.g., the deuteron) within the fixed center approximation in the\ncase of light-heavy attraction, solving the integral equation for the\nthree-body Green's function both in the coordinate and in the momentum space.\nThe results for the three-body scattering amplitude appear to be ambiguous --\nthey depend on a single real parameter. This parameter may be fixed by a\nthree-body input, e.g., the three-body scattering length. We also solve the\nintegral equation for the three-body Green function in the momentum space,\nintroducing a finite cut-off. We show that all three approaches are equivalent.\nWe also discuss how our approach to the problem matches with the introduction\nof three-body contact interaction as done by other authors. \n\n"}
{"id": "1606.02290", "contents": "Title: Multi-channel front-end board for SiPM readout Abstract: We describe a novel high-speed front-end electronic board (FEB) for\ninterfacing an array of 32 Silicon Photo-multipliers (SiPM) with a computer.\nThe FEB provides individually adjustable bias on the SiPMs, and performs\nlow-noise analog signal amplification, conditioning and digitization. It\nprovides event timing information accurate to 1.3 ns RMS. The back-end data\ninterface is realized on the basis of 100 Mbps Ethernet. The design allows\ndaisy-chaining of up to 256 units into one network interface, thus enabling\ncompact and efficient readout schemes for multi-channel scintillating\ndetectors, using SiPMs as photo-sensors. \n\n"}
{"id": "1606.03379", "contents": "Title: A mixed finite element approximation for Darcy-Forchheimer flows of\n  slightly compressible fluids Abstract: In this paper, we consider the generalized Forchheimer flows for slightly\ncompressible fluids in porous media. Using Muskat's and Ward's general form of\nForchheimer equations, we describe the flow of a single-phase fluid in $\\mathbb\nR^d, d\\ge 2$ by a nonlinear degenerate system of density and momentum. A mixed\nfinite element method is proposed for the approximation of the solution of the\nabove system. The stability of the approximations are proved; the error\nestimates are derived for the numerical approximations for both continuous and\ndiscrete time procedures. The continuous dependence of numerical solutions on\nphysical parameters are demonstrated. Experimental studies are presented\nregarding convergence rates and showing the dependence of the solution on the\nphysical parameters. \n\n"}
{"id": "1606.04743", "contents": "Title: Jiangmen Underground Neutrino Observatory: Status and Prospectives Abstract: The Jiangmen Underground Neutrino Observatory (JUNO) is a 20 kton liquid\nscintillator (LS) detector, which is planed to determine the neutrino mass\nhierarchy and measure the oscillation parameters at the sub-percent level using\nreactor antineutrino oscillations. As a multipurpose neutrino experiment, JUNO\nis also capable of measuring supernova burst neutrinos, the diffuse supernova\nneutrino background, geo-neutrinos, solar neutrinos and atmospheric neutrinos.\nAfter a brief introduction to the physics motivation, we discuss the status of\nthe JUNO project, including the design of the detector systems. Finally the\nlatest civil progress and future prospectives are also highlighted. \n\n"}
{"id": "1606.04804", "contents": "Title: Ambiguities in one-dimensional phase retrieval from magnitudes of a\n  linear canonical transform Abstract: Phase retrieval problems occur in a wide range of applications in physics and\nengineering. Usually, these problems consist in the recovery of an unknown\nsignal from the magnitudes of its Fourier transform. In some applications,\nhowever, the given intensity arises from a different transformation such as the\nFresnel or fractional Fourier transform. More generally, we here consider the\nphase retrieval of an unknown signal from the magnitudes of an arbitrary linear\ncanonical transform. Using the close relation between the Fourier and the\nlinear canonical transform, we investigate the arising ambiguities of these\nphase retrieval problems and transfer the well-known characterizations of the\nsolution sets from the classical Fourier phase retrieval problem to the new\nsetting. \n\n"}
{"id": "1606.05070", "contents": "Title: Localized Reduced Basis Approximation of a Nonlinear Finite Volume\n  Battery Model with Resolved Electrode Geometry Abstract: In this contribution we present first results towards localized model order\nreduction for spatially resolved, three-dimensional lithium-ionbattery models.\nWe introduce a localized reduced basis scheme based on non-conforming local\napproximation spaces stemming from a finite volume discretizationof the\nanalytical model and localized empirical operator interpolation for the\napproximation of the model's nonlinearities. Numerical examples are provided\nindicating the feasibility of our approach. \n\n"}
{"id": "1606.08682", "contents": "Title: The SU(2|3) dynamic two-loop form factors Abstract: We compute two-loop form factors of operators in the $SU(2|3)$ closed\nsubsector of $N=4$ supersymmetric Yang-Mills. In particular, we focus on the\nnon-protected, dimension-three operators $\\mathrm{Tr} (X[Y,Z])$ and\n$\\mathrm{Tr} ( \\psi \\psi)$ for which we compute the four possible two-loop form\nfactors, and corresponding remainder functions, with external states $\\langle\n\\bar{X} \\bar{Y} \\bar{Z}|$ and $\\langle \\bar{\\psi} \\bar{\\psi}|$. Interestingly,\nthe maximally transcendental part of the two-loop remainder of $\\langle\\bar{X}\n\\bar{Y} \\bar{Z}| \\mathrm{Tr} (X[Y,Z]) |0\\rangle$ turns out to be identical to\nthat of the corresponding known quantity for the half-BPS operator $\\mathrm{Tr}\n(X^3)$. We also find a surprising connection between the terms subleading in\ntranscendentality and certain a priori unrelated remainder densities introduced\nin the study of the spin chain Hamiltonian in the SU(2) sector. Next, we use\nour calculation to resolve the mixing, recovering anomalous dimensions and\neigenstates of the dilatation operator in the SU(2|3) sector at two loops. We\nalso speculate on potential connections between our calculations in $N=4$ super\nYang-Mills and Higgs + multi-gluon amplitudes in QCD in an effective Lagrangian\napproach. \n\n"}
{"id": "1606.09402", "contents": "Title: Efficient Randomized Algorithms for the Fixed-Precision Low-Rank Matrix\n  Approximation Abstract: Randomized algorithms for low-rank matrix approximation are investigated,\nwith the emphasis on the fixed-precision problem and computational efficiency\nfor handling large matrices. The algorithms are based on the so-called QB\nfactorization, where Q is an orthonormal matrix. Firstly, a mechanism for\ncalculating the approximation error in Frobenius norm is proposed, which\nenables efficient adaptive rank determination for large and/or sparse matrix.\nIt can be combined with any QB-form factorization algorithm in which B's rows\nare incrementally generated. Based on the blocked randQB algorithm by P.-G.\nMartinsson and S. Voronin, this results in an algorithm called randQB EI. Then,\nwe further revise the algorithm to obtain a pass-efficient algorithm, randQB\nFP, which is mathematically equivalent to the existing randQB algorithms and\nalso suitable for the fixed-precision problem. Especially, randQB FP can serve\nas a single-pass algorithm for calculating leading singular values, under\ncertain condition. With large and/or sparse test matrices, we have empirically\nvalidated the merits of the proposed techniques, which exhibit remarkable\nspeedup and memory saving over the blocked randQB algorithm. We have also\ndemonstrated that the single-pass algorithm derived by randQB FP is much more\naccurate than an existing single-pass algorithm. And with data from a scenic\nimage and an information retrieval application, we have shown the advantages of\nthe proposed algorithms over the adaptive range finder algorithm for solving\nthe fixed-precision problem. \n\n"}
{"id": "1606.09451", "contents": "Title: Getting the Most Neutrinos out of IsoDAR Abstract: Several experimental collaborations worldwide intend to test sterile neutrino\nmodels by measuring the disappearance of antineutrinos produced via isotope\ndecay at rest (IsoDAR). The most advanced of these proposals have very similar\nsetups, in which a proton beam strikes a target yielding neutrons which are\nabsorbed by a high isotopic purity 7Li converter, yielding 8Li whose resulting\ndecay yields the antineutrinos. In this note, we use FLUKA and GEANT4\nsimulations to investigate three proposed modifications of this standard\nproposal. In the first, the 7Li is replaced with 7Li compounds including a\ndeuterium moderator. In the second, a gap is placed between the target and the\nconverter to reduce the neutron bounce-back. Finally, we consider cooling the\nconverter with liquid nitrogen. We find that these modifications can increase\nthe antineutrino yield by as much as 50 percent. The first also substantially\nreduces the quantity of high purity 7Li which is needed. \n\n"}
{"id": "1607.00219", "contents": "Title: The design and basic performance of a Spiral Fiber Tracker for the\n  J-PARC E36 experiment Abstract: A spiral fiber tracker (SFT) has been designed and produced for the J-PARC\nE36 experiment as an element of the tracking system for conducting a\nhigh-resolution momentum measurement of charge particles from kaon decays. A\nnovel technique to wind the pre-made fiber ribbons spirally was employed for\nthe configuration with four detector layers made of 1 mm diameter plastic\nscintillating fibers. Good position alignment and sufficiently high detection\nefficiency for charged particles with minimum ionizing energy were confirmed in\ncosmic ray test. The tracker was successfully used in the E36 experiment. \n\n"}
{"id": "1607.00301", "contents": "Title: A time-stepping DPG scheme for the heat equation Abstract: We introduce and analyze a discontinuous Petrov-Galerkin method with optimal\ntest functions for the heat equation. The scheme is based on the backward Euler\ntime stepping and uses an ultra-weak variational formulation at each time step.\nWe prove the stability of the method for the field variables (the original\nunknown and its gradient weighted by the square root of the time step) and\nderive a C\\'ea-type error estimate. For low-order approximation spaces this\nimplies certain convergence orders when time steps are not too small in\ncomparison with mesh sizes. Some numerical experiments are reported to support\nour theoretical results. \n\n"}
{"id": "1607.00650", "contents": "Title: The effects of the U$_\\textrm{Y}$(1) Chern-Simons term and its baryonic\n  contribution on matter asymmetries and hypermagnetic fields Abstract: In this paper, we study the significance of the U$_\\textrm{Y}$(1)\nChern-Simons term in general, and its baryonic contribution in particular, for\nthe evolution of the matter asymmetries and the hypermagnetic field in the\ntemperature range $100$GeV$\\leq T \\leq 10$TeV. We show that an initial helical\nhypermagnetic field, denoted by $B_Y^{(0)}$, can grow matter asymmetries from\nzero initial value. However, the growth which is initially quadratic with\nrespect to $B_Y^{(0)}$, saturates for values larger than a critical value. The\ninclusion of the baryonic contribution reduces this critical value, leading to\nsmaller final matter asymmetries. Meanwhile, $B_Y(T_{EW})$ becomes slightly\nlarger than $B_Y^{(0)}$. In the absence of the U$_\\textrm{Y}$(1) Chern-Simons\nterm, the final values of matter asymmetries grow without saturation.\nConversely, we show that an initial matter asymmetry can grow an initial seed\nof hypermagnetic field, provided the Chern-Simons term is taken into account.\nThe growth process saturates when the matter asymmetry drops abruptly. When the\nbaryonic contribution is included, the saturation occurs at an earlier time,\nand $B_Y (T_{EW})$ becomes larger. We also show the results can be within the\nacceptable range of present day data, provided the inverse cascade process is\nalso taken into account. \n\n"}
{"id": "1607.00663", "contents": "Title: Thermal mock-up studies of the DEPFET pixel vertex detector for Belle II Abstract: The Belle II experiment currently under construction at the $e^+e^-$-collider\nSuperKEKB in Japan is designed to explore new physics beyond the standard model\nwith an approximately 50 times larger data sample compared to its predecessor.\nThe vertex detector (VXD), comprising a two layer DEPFET pixel detector (PXD)\nsurrounded by four layers of double sided silicon strip detector (SVD), is\nindispensable for the accurate determination of the decay point of $B$ or $D$\nmeson as well as track reconstruction of low momentum particles. The DEPFET\nsensors in Belle II are thinned down to 75 $\\mu$m with low power consumption\nand low intrinsic noise. In the DEPFET concept, the front-end electronics is\nplaced outside of the sensitive area, and thus no cooling components are\nnecessary inside the physics acceptance of the detector. Evaporative two-phase\nCO$_2$ cooling in combination with forced air flow has been chosen as the\nscheme for the PXD cooling. To guarantee the DEPFET detector operation\ncondition and verify the cooling concept, a PXD mockup is constructed at DESY.\nStudies of the thermal and mechanical performance are presented in this paper. \n\n"}
{"id": "1607.01475", "contents": "Title: Preconditioned Steepest Descent Methods for some Nonlinear Elliptic\n  Equations Involving p-Laplacian Terms Abstract: We describe and analyze preconditioned steepest descent (PSD) solvers for\nfourth and sixth-order nonlinear elliptic equations that include p-Laplacian\nterms on periodic domains in 2 and 3 dimensions. The highest and lowest order\nterms of the equations are constant-coefficient, positive linear operators,\nwhich suggests a natural preconditioning strategy. Such nonlinear elliptic\nequations often arise from time discretization of parabolic equations that\nmodel various biological and physical phenomena, in particular, liquid\ncrystals, thin film epitaxial growth and phase transformations. The analyses of\nthe schemes involve the characterization of the strictly convex energies\nassociated with the equations. We first give a general framework for PSD in\ngeneric Hilbert spaces. Based on certain reasonable assumptions of the linear\npre-conditioner, a geometric convergence rate is shown for the nonlinear PSD\niteration. We then apply the general the theory to the fourth and sixth-order\nproblems of interest, making use of Sobolev embedding and regularity results to\nconfirm the appropriateness of our pre-conditioners for the regularized\np-Lapacian problems. Our results include a sharper theoretical convergence\nresult for p-Laplacian systems compared to what may be found in existing works.\nWe demonstrate rigorously how to apply the theory in the finite dimensional\nsetting using finite difference discretization methods. Numerical simulations\nfor some important physical application problems -- including thin film epitaxy\nwith slope selection and the square phase field crystal model -- are carried\nout to verify the efficiency of the scheme. \n\n"}
{"id": "1607.03526", "contents": "Title: Probabilistic solvers for partial differential equations Abstract: This work is concerned with the quantification of the epistemic uncertainties\ninduced the discretization of partial differential equations. Following the\nparadigm of probabilistic numerics, we quantify this uncertainty\nprobabilistically. Namely, we develop a probabilistic solver suitable for\nlinear partial differential equations (PDE) with mixed (Dirichlet and Neumann)\nboundary conditions defined on arbitrary geometries. The idea is to assign a\nprobability measure on the space of solutions of the PDE and then condition\nthis measure by enforcing that the PDE and the boundary conditions are\nsatisfied at a finite set of spatial locations. The resulting posterior\nprobability measure quantifies our state of knowledge about the solution of the\nproblem given this finite discretization. \n\n"}
{"id": "1607.04669", "contents": "Title: A Letter of Intent to Install a milli-charged Particle Detector at LHC\n  P5 Abstract: In this LOI we propose a dedicated experiment that would detect\n\"milli-charged\" particles produced by pp collisions at LHC Point 5. The\nexperiment would be installed during LS2 in the vestigial drainage gallery\nabove UXC and would not interfere with CMS operations. With 300 fb$^{-1}$ of\nintegrated luminosity, sensitivity to a particle with charge\n$\\mathcal{O}(10^{-3})~e$ can be achieved for masses of $\\mathcal{O}(1)$ GeV,\nand charge $\\mathcal{O}(10^{-2})~e$ for masses of $\\mathcal{O}(10)$ GeV,\ngreatly extending the parameter space explored for particles with small charge\nand masses above 100 MeV. \n\n"}
{"id": "1607.05790", "contents": "Title: A self-adaptive moving mesh method for the short pulse equation via its\n  hodograph link to the sine-Gordon equation Abstract: The short pulse equation was introduced by Schaefer--Wayne (2004) for\nmodeling the propagation of ultrashort optical pulses. While it can describe a\nwide range of solutions, its ultrashort pulse solutions with a few cycles,\nwhich the conventional nonlinear Schroedinger equation does not possess, have\ndrawn much attention. In such a region, existing numerical methods turn out to\nrequire very fine numerical mesh, and accordingly are computationally\nexpensive. In this paper, we establish a new efficient numerical method by\ncombining the idea of the hodograph transformation and the structure-preserving\nnumerical methods. The resulting scheme is a self-adaptive moving mesh scheme\nthat can successfully capture not only the ultrashort pulses but also exotic\nsolutions such as loop soliton solutions. \n\n"}
{"id": "1607.06850", "contents": "Title: Thermodynamic Limit of Crystal Defects with Finite Temperature Tight\n  Binding Abstract: We consider a tight binding model for localised crystalline defects with\nelectrons in the canonical ensemble (finite electronic temperature) and nuclei\npositions relaxed according to the Born--Oppenheimer approximation. We prove\nthat the limit model as the computational domain size grows to infinity is\nformulated in the grand-canonical ensemble for the electrons. The Fermi-level\nfor the limit model is fixed at a homogeneous crystal level, independent of the\ndefect or electron number in the sequence of finite-domain approximations. We\nquantify the rates of convergence for the nuclei configuration and for the\nFermi-level. \n\n"}
{"id": "1607.06897", "contents": "Title: Efficient spectral sparse grid approximations for solving\n  multi-dimensional forward backward SDEs Abstract: This is the second part in a series of papers on multi-step schemes for\nsolving coupled forward backward stochastic differential equations (FBSDEs). We\nextend the basic idea in our former paper [W. Zhao, Y. Fu and T. Zhou, SIAM J.\nSci. Comput., 36 (2014), pp. A1731-A1751] to solve high-dimensional FBSDEs, by\nusing the spectral sparse grid approximations. The main issue for solving high\ndimensional FBSDEs is to build an efficient spatial discretization, and deal\nwith the related high dimensional conditional expectations and interpolations.\nIn this work, we propose the sparse grid spatial discretization. We use the\nsparse grid Gaussian-Hermite quadrature rule to approximate the conditional\nexpectations. And for the associated high dimensional interpolations, we adopt\nan spectral expansion of functions in polynomial spaces with respect to the\nspatial variables, and use the sparse grid approximations to recover the\nexpansion coefficients. The FFT algorithm is used to speed up the recovery\nprocedure, and the entire algorithm admits efficient and high accurate\napproximations in high-dimensions, provided that the solutions are sufficiently\nsmooth. Several numerical examples are presented to demonstrate the efficiency\nof the proposed methods. \n\n"}
{"id": "1608.01565", "contents": "Title: The CONNIE experiment Abstract: The CONNIE experiment uses fully depleted, high resistivity CCDs as particle\ndetectors in an attempt to measure for the first time the Coherent\nNeutrino-Nucleus Elastic Scattering of antineutrinos from a nuclear reactor\nwith silicon nuclei.This talk, given at the XV Mexican Workshop on Particles\nand Fields (MWPF), discussed the potential of CONNIE to perform this\nmeasurement, the installation progress at the Angra dos Reis nuclear power\nplant, as well as the plans for future upgrades. \n\n"}
{"id": "1608.02240", "contents": "Title: The forward-backward algorithm and the normal problem Abstract: The forward-backward splitting technique is a popular method for solving\nmonotone inclusions that has applications in optimization. In this paper we\nexplore the behaviour of the algorithm when the inclusion problem has no\nsolution. We present a new formula to define the normal solutions using the\nforward-backward operator. We also provide a formula for the range of the\ndisplacement map of the forward-backward operator. Several examples illustrate\nour theory. \n\n"}
{"id": "1608.03077", "contents": "Title: Fractional-compact numerical algorithms for Riesz spatial fractional\n  reaction-dispersion equations Abstract: It is well known that using high-order numerical algorithms to solve\nfractional differential equations leads to almost the same computational cost\nwith low-order ones but the accuracy (or convergence order) is greatly\nimproved, due to the nonlocal properties of fractional operators. Therefore,\ndeveloping some high-order numerical approximation formulas for fractional\nderivatives play a more important role in numerically solving fractional\ndifferential equations. This paper focuses on constructing (generalized)\nhigh-order fractional-compact numerical approximation formulas for Riesz\nderivatives. Then we apply the developed formulas to the one- and two-dimension\nRiesz spatial fractional reaction-dispersion equations. The stability and\nconvergence of the derived numerical algorithms are strictly studied by using\nthe energy analysis method. Finally, numerical simulations are given to\ndemonstrate the efficiency and convergence orders of the presented numerical\nalgorithms. \n\n"}
{"id": "1608.03198", "contents": "Title: Associated production of a quarkonium and a Z boson at one loop in a\n  quark-hadron-duality approach Abstract: In view of the large discrepancy about the associated production of a prompt\n$J/\\psi$ and a $Z$ boson between the ATLAS data at $\\sqrt{s}=8$ TeV and\ntheoretical predictions for Single Parton Scattering (SPS) contributions, we\nperform an evaluation of the corresponding cross section at one loop accuracy\n(Next-to-Leading Order, NLO) in a quark-hadron-duality approach, also known as\nthe Colour-Evaporation Model (CEM). This work is motivated by (i) the extremely\ndisparate predictions based on the existing NRQCD fits conjugated with the\nabsence of a full NLO NRQCD computation and (ii) the fact that we believe that\nsuch an evaluation provides a likely upper limit of the SPS cross section. In\naddition to these theory improvements, we argue that the ATLAS estimation of\nthe Double Parton Scattering (DPS) yield may be underestimated by a factor as\nlarge as 3 which then reduces the size of the SPS yield extracted from the\nATLAS data. Our NLO SPS evaluation also allows us to set an upper limit on\n$\\sigma_{\\rm eff}$ driving the size of the DPS yield. Overall, the discrepancy\nbetween theory and experiment may be smaller than expected, which calls for\nfurther analyses by ATLAS and CMS, for which we provide predictions, and for\nfull NLO computations in other models. As an interesting side product of our\nanalysis, we have performed the first NLO computation of $d\\sigma / dP_T$ for\nprompt single-$J/\\psi$ production in the CEM from which we have fit the CEM\nnon-pertubative parameter at NLO using the most recent ATLAS data. \n\n"}
{"id": "1608.03288", "contents": "Title: CP violation in multibody decays of beauty baryons Abstract: Beauty baryons are being observed in large numbers in the LHCb detector. The\nrich kinematic distributions of their multibody decays are therefore becoming\naccessible and provide us with new opportunities to search for CP violation. We\nanalyse the angular distributions of some three- and four-body decays of\nspin-$1/2$ baryons using the Jacob-Wick helicity formalism. The asymmetries\nthat provide access to small differences of CP-odd phases between decay\namplitudes of identical CP-even phases are notably discussed. The understanding\ngained on processes featuring specific resonant intermediate states allows us\nto establish which asymmetries are relevant for what purpose. It is for\ninstance shown that some CP-odd angular asymmetries measured by the LHCb\ncollaboration in the $\\Lambda_b \\to \\Lambda\\,\\varphi \\to p\\,\\pi\\, K^+ K^-$\ndecay are expected to vanish identically. \n\n"}
{"id": "1608.03659", "contents": "Title: Structure-Preserving Galerkin POD Reduced-Order Modeling of Hamiltonian\n  Systems Abstract: The proper orthogonal decomposition reduced-order models (POD-ROMs) have been\nwidely used as a computationally efficient surrogate models in large-scale\nnumerical simulations of complex systems. However, when it is applied to a\nHamiltonian system, a naive application of the POD method can destroy its\nHamiltonian structure in the reduced-order model. In this paper, we develop a\nnew reduce-order modeling approach for the Hamiltonian system, which uses the\ntraditional framework of Galerkin projection-based model reduction but modifies\nthe ROM so that the appropriate Hamiltonian structure is preserved. Since the\nPOD truncation can degrade the approximation of the Hamiltonian function, we\npropose to use the POD basis from shifted snapshots to improve the Hamiltonian\nfunction approximation. We further derive a rigorous a priori error estimate of\nthe structure-preserving ROM and demonstrate its effectiveness in several\nnumerical examples. This approach can be readily extended to dissipative\nHamiltonian systems, port-Hamiltonian systems etc. \n\n"}
{"id": "1608.04719", "contents": "Title: Sizable NSI from the $SU(2)_L$ scalar doublet-singlet mixing and the\n  implications in DUNE Abstract: We propose a novel and simple mechanism where sizable effects of non-standard\ninteractions (NSI) in neutrino propagation are induced from the mixing between\nan electrophilic second Higgs doublet and a charged singlet. The mixing arises\nfrom a dimensionful coupling of the scalar doublet and singlet to the standard\nmodel Higgs boson. In light of the small mass, the light mass eigenstate from\nthe doublet-singlet mixing can generate much larger NSI than those induced by\nthe heavy eigenstate. We show that a sizable NSI $\\varepsilon_{e\\tau}$ ($\\sim\n0.3$) can be attained without being excluded by a variety of experimental\nconstraints. Furthermore, we demonstrate that NSI can mimic effects of the\nDirac CP phase in the neutrino mixing matrix but they can potentially be\ndisentangled by future long-baseline neutrino experiments, such as the Deep\nUnderground Neutrino Experiment (DUNE). \n\n"}
{"id": "1608.08279", "contents": "Title: Thermal and Tensile Strength Testing of Thermally-Conductive Adhesives\n  and Carbon Foam Abstract: Future collider detectors, including silicon tracking detectors planned for\nthe High Luminosity LHC, will require components and mechanical structures\nproviding unprecedented strength-to-mass ratios, thermal conductivity, and\nradiation tolerance. This paper studies carbon foam used in conjunction with\nthermally conductive epoxy and thermally conductive tape for such applications.\nThermal performance and tensile strength measurements of aluminum-carbon\nfoam-adhesive stacks are reported, along with initial radiation damage test\nresults. \n\n"}
{"id": "1609.00442", "contents": "Title: The role of $a_1(1260)$ in $\\pi^- p \\to a^-_1(1260) p$ and $\\pi^- p \\to\n  \\pi^- \\rho^0 p$ reactions near threshold Abstract: We report on a theoretical study of the $\\pi^- p \\to a^-_1(1260) p$ and\n$\\pi^- p \\to \\pi^- \\rho^0 p$ reactions near threshold within an effective\nLagrangian approach. The production process is described by $t$-channel\n$\\rho^0$ meson exchange. For the $\\pi^- p \\to \\pi^- \\rho^0 p$ reaction, the\nfinal $\\pi^- \\rho^0$ results from the decay of the $a_1(1260)$ resonance which\nis assumed as a dynamically generated state from the $K^* \\bar K$ and $\\rho\n\\pi$ coupled channel interactions. We calculate the total cross section of the\n$\\pi^- p \\to a^-_1(1260) p$ reaction. It is shown that, with the coupling\nconstant of the $a_1(1260)$ to $\\rho \\pi$ channel obtained from the chiral\nunitary theory and a cut off parameter $\\Lambda_\\rho \\sim 1.5$ GeV in the form\nfactors, the experimental measurement can be reproduced. Furthermore, the total\nand differential cross sections of $\\pi^- p \\to a^-_1(1260) p \\to \\pi^- \\rho^0\np$ reaction are evaluated, and it is expected that our model calculations can\nbe tested by future experiments. These reactions are important for the study of\nthe $a_1(1260)$ resonance and would provide further clue for the nature of\n$a_1(1260)$ state. \n\n"}
{"id": "1609.03851", "contents": "Title: Immersed Boundary Smooth Extension (IBSE): A high-order method for\n  solving incompressible flows in arbitrary smooth domains Abstract: The Immersed Boundary method is a simple, efficient, and robust numerical\nscheme for solving PDE in general domains, yet for fluid problems it only\nachieves first-order spatial accuracy near embedded boundaries for the velocity\nfield and fails to converge pointwise for elements of the stress tensor. In a\nprevious work we introduced the Immersed Boundary Smooth Extension (IBSE)\nmethod, a variation of the IB method that achieves high-order accuracy for\nelliptic PDE by smoothly extending the unknown solution of the PDE from a given\nsmooth domain to a larger computational domain, enabling the use of simple\nCartesian-grid discretizations. In this work, we extend the IBSE method to\nallow for the imposition of a divergence constraint, and demonstrate high-order\nconvergence for the Stokes and incompressible Navier-Stokes equations: up to\nthird-order pointwise convergence for the velocity field, and second-order\npointwise convergence for all elements of the stress tensor. The method is\nflexible to the underlying discretization: we demonstrate solutions produced\nusing both a Fourier spectral discretization and a standard second-order\nfinite-difference discretization. \n\n"}
{"id": "1609.04979", "contents": "Title: On Effective Degrees of Freedom in the Early Universe Abstract: We explore the effective degrees of freedom in the early universe, from\nbefore the electroweak scale at a few femtoseconds after the Big Bang, until\nthe last positrons disappeared a few minutes later. We first look at the\nestablished concepts of effective degrees of freedom for energy density,\npressure and entropy density, and introduce effective degrees of freedom for\nnumber density as well. We discuss what happens with particle species as their\ntemperature cools down from relativistic to semi- and non-relativistic\ntemperatures, and then annihilates completely. This will affect the pressure as\nwell as the entropy per particle. We also look at the transition from a\nquark-gluon plasma to a hadron gas. Using a list of known hadrons, we use a\n\"cross-over\" temperature of 214 MeV where the effective degrees of freedom for\na quark-gluon plasma equals that of a hadron gas. \n\n"}
{"id": "1609.05250", "contents": "Title: Investigation of thin n-in-p planar pixel modules for the ATLAS upgrade Abstract: In view of the High Luminosity upgrade of the Large Hadron Collider (HL-LHC),\nplanned to start around 2023-2025, the ATLAS experiment will undergo a\nreplacement of the Inner Detector. A higher luminosity will imply higher\nirradiation levels and hence will demand more ra- diation hardness especially\nin the inner layers of the pixel system. The n-in-p silicon technology is a\npromising candidate to instrument this region, also thanks to its\ncost-effectiveness because it only requires a single sided processing in\ncontrast to the n-in-n pixel technology presently employed in the LHC\nexperiments. In addition, thin sensors were found to ensure radiation hardness\nat high fluences. An overview is given of recent results obtained with not\nirradiated and irradiated n-in-p planar pixel modules. The focus will be on\nn-in-p planar pixel sensors with an active thickness of 100 and 150 um recently\nproduced at ADVACAM. To maximize the active area of the sensors, slim and\nactive edges are implemented. The performance of these modules is investigated\nat beam tests and the results on edge efficiency will be shown. \n\n"}
{"id": "1609.05407", "contents": "Title: Preconditioned steepest descent-like methods for symmetric indefinite\n  systems Abstract: This paper addresses the question of what exactly is an analogue of the\npreconditioned steepest descent (PSD) algorithm in the case of a symmetric\nindefinite system with an SPD preconditioner. We show that a basic PSD-like\nscheme for an SPD-preconditioned symmetric indefinite system is mathematically\nequivalent to the restarted PMINRES, where restarts occur after every two\nsteps. A convergence bound is derived. If certain information on the spectrum\nof the preconditioned system is available, we present a simpler PSD-like\nalgorithm that performs only one-dimensional residual minimization. Our primary\ngoal is to bridge the theoretical gap between optimal (PMINRES) and PSD-like\nmethods for solving symmetric indefinite systems, as well as point out\nsituations where the PSD-like schemes can be used in practice. \n\n"}
{"id": "1609.06363", "contents": "Title: Stationary averaging for multi-scale continuous time Markov chains using\n  parallel replica dynamics Abstract: We propose two algorithms for simulating continuous time Markov chains in the\npresence of metastability. We show that the algorithms correctly estimate,\nunder the ergodicity assumption, stationary averages of the process. Both\nalgorithms, based on the idea of the parallel replica method, use parallel\ncomputing in order to explore metastable sets more efficiently. The algorithms\nrequire no assumptions on the Markov chains beyond ergodicity and the presence\nof identifiable metastability.\n  In particular, there is no assumption on reversibility. For simpler\nillustration of the algorithms, we assume that a synchronous architecture is\nused throughout of the paper. We present error analyses, as well as numerical\nsimulations on multi-scale stochastic reaction network models in order to\ndemonstrate consistency of the method and its efficiency. \n\n"}
{"id": "1609.06674", "contents": "Title: Efficient methods for the estimation of homogenized coefficients Abstract: The main goal of this paper is to define and study new methods for the\ncomputation of effective coefficients in the homogenization of divergence-form\noperators with random coefficients. The methods introduced here are proved to\nhave optimal computational complexity, and are shown numerically to display\nsmall constant prefactors. In the spirit of multiscale methods, the main idea\nis to rely on a progressive coarsening of the problem, which we implement via a\ngeneralization of the Green-Kubo formula. The technique can be applied more\ngenerally to compute the effective diffusivity of any additive functional of a\nMarkov process. In this broader context, we also discuss the alternative\npossibility of using Monte-Carlo sampling, and show how a simple one-step\nextrapolation can considerably improve the performance of this alternative\nmethod. \n\n"}
{"id": "1609.06762", "contents": "Title: Sparsity-Preserving Difference of Positive Semidefinite Matrix\n  Representation of Indefinite Matrices Abstract: We consider the problem of writing an arbitrary symmetric matrix as the\ndifference of two positive semidefinite matrices. We start with simple ideas\nsuch as eigenvalue decomposition. Then, we develop a simple adaptation of the\nCholesky that returns a difference-of-Cholesky representation of indefinite\nmatrices. Heuristics that promote sparsity can be applied directly to this\nmodification. \n\n"}
{"id": "1609.07990", "contents": "Title: DEAP-3600 dark matter experiment Abstract: DEAP-3600 is a single phase liquid argon (LAr) dark matter experiment,\nlocated 2 km underground at SNOLAB, in Sudbury, Canada. The detector has 1\ntonne fiducial mass of LAr. The target sensitivity to spin-independent\nscattering of 100 GeV weakly interacting massive particles (WIMPs) is\n10$^{-46}$ cm$^{2}$. The DEAP-3600 background target is $<$ 0.6 background\nevents in the WIMP region of interest in 3 tonne-years. The strategies to\nachieve this background include pulse shape discrimination to mitigate electron\nrecoil and using ultra low radioactive materials for detector construction.\nFurthermore, to reduce neutron and alpha backgrounds, the DEAP-3600 acrylic\nvessel was sanded in situ to mitigate radon exposure of surfaces during\nconstruction and fabrication. The experiment is currently in the commissioning\nphase and will begin physics data taking later this year. This paper presents\nan overview of the experiment, its cross-section sensitivity to WIMPs and its\ncurrent status. \n\n"}
{"id": "1609.08251", "contents": "Title: Robust and efficient multi-way spectral clustering Abstract: We present a new algorithm for spectral clustering based on a column-pivoted\nQR factorization that may be directly used for cluster assignment or to provide\nan initial guess for k-means. Our algorithm is simple to implement, direct, and\nrequires no initial guess. Furthermore, it scales linearly in the number of\nnodes of the graph and a randomized variant provides significant computational\ngains. Provided the subspace spanned by the eigenvectors used for clustering\ncontains a basis that resembles the set of indicator vectors on the clusters,\nwe prove that both our deterministic and randomized algorithms recover a basis\nclose to the indicators in Frobenius norm. We also experimentally demonstrate\nthat the performance of our algorithm tracks recent information theoretic\nbounds for exact recovery in the stochastic block model. Finally, we explore\nthe performance of our algorithm when applied to a real world graph. \n\n"}
{"id": "1609.09125", "contents": "Title: Rotated $\\mu$\\,--\\,$\\tau$ Symmetry for One Generic Neutrino Mixing\n  Angle: An analytical Study Abstract: We find a realization of the $Z_2$-symmetry in the neutrino mass matrix which\nexpresses a rotation of the $\\mu-\\tau$ symmetry and is able to impose a generic\nsmallest mixing angle, in contrast to a zero-value predicted by the usual\nnon-rotated form of the $\\mu-\\tau$ symmetry. We extend this symmetry for the\nlepton sector within type-I seesaw scenario, and show it can accommodate the\nmixing angles, the mass hierarchies and the lepton asymmetry in the universe.\nWe then study the effects of perturbing the specific form of the neutrino mass\nmatrix imposed by the symmetry and compute the resulting mixing and mass\nspectrum. We trace back this \"low-scale\" perturbation to a \"high-scale\"\nperturbation, and find realizations of this latter one arising from exact\nsymmetries with an enriched matter content. \n\n"}
{"id": "1610.03262", "contents": "Title: Model Reduction for Systems with Inhomogeneous Initial Conditions Abstract: We consider the model reduction problem for linear time-invariant dynamical\nsystems having nonzero (but otherwise indeterminate) initial conditions.\nBuilding upon the observation that the full system response is decomposable as\na superposition of the response map for an unforced system having nontrivial\ninitial conditions and the response map for a forced system having null initial\nconditions, we develop a new approach that involves reducing these component\nresponses independently and then combining the reduced responses into an\naggregate reduced system response. This approach allows greater flexibility and\noffers better approximation properties than other comparable methods. \n\n"}
{"id": "1610.03404", "contents": "Title: Runge-Kutta discontinuous Galerkin methods for the special relativistic\n  magnetohydrodynamics Abstract: This paper develops $P^K$-based non-central and central Runge-Kutta\ndiscontinuous Galerkin (DG) methods with WENO limiter for the one- and\ntwo-dimensional special relativistic magnetohydrodynamical (RMHD) equations,\n$K=1,2,3$. The non-central DG methods are locally divergence-free, while the\ncentral DG are \"exactly\" divergence-free but have to find two approximate\nsolutions defined on mutually dual meshes. The adaptive WENO limiter first\nidentifies the \"troubled\" cells by using a modified TVB minmod function, and\nthen uses the WENO technique to locally reconstruct a new polynomial of degree\n$(2K+1)$ inside the \"troubled\" cells replacing the DG solution by based on the\ncell average values of the DG solutions in the neighboring cells as well as the\noriginal cell averages of the \"troubled\" cells. The WENO limiting procedure\ndoes not destroy the locally or \"exactly\" divergence-free property of magnetic\nfield and is only employed for finite \"troubled\" cells so that the\ncomputational cost can be as little as possible. Several test problems in one\nand two dimensions are solved by using our non-central and central Runge-Kutta\nDG methods with WENO limiter. The numerical results demonstrate that our\nmethods are stable, accurate, and robust in resolving complex wave structures. \n\n"}
{"id": "1610.04543", "contents": "Title: Constructing of constraint preserving scheme for Einstein equations Abstract: We propose a new numerical scheme of evolution for the Einstein equations\nusing the discrete variational derivative method (DVDM). We derive the discrete\nevolution equation of the constraint using this scheme and show the constraint\npreserves in the discrete level. In addition, to confirm the numerical\nstability using this scheme, we perform some numerical simulations by\ndiscretized equations with the Crank-Nicolson scheme and with the new scheme,\nand we find that the new discretized equations have better stability than that\nof the Crank-Nicolson scheme. \n\n"}
{"id": "1610.06743", "contents": "Title: Follow-the-leader approximations of macroscopic models for vehicular and\n  pedestrian flows Abstract: We review recent results and present new ones on a deterministic\nfollow-the-leader particle approximation of first and second order models for\ntraffic flow and pedestrian movements. We start by constructing the particle\nscheme for the first order Lighthill-Whitham-Richards (LWR) model for traffic\nflow. The approximation is performed by a set of ODEs following the position of\ndiscretised vehicles seen as moving particles. The convergence of the scheme in\nthe many particle limit towards the unique entropy solution of the LWR equation\nis proven in the case of the Cauchy problem on the real line. We then extend\nour approach to the Initial-Boundary Value Problem (IBVP) with time-varying\nDirichlet data on a bounded interval. In this case we prove that our scheme is\nconvergent strongly in $L^1$ up to a subsequence. We then review extensions of\nthis approach to the Hughes model for pedestrian movements and to the second\norder Aw-Rascle-Zhang (ARZ) model for vehicular traffic. Finally, we complement\nour results with numerical simulations. In particular, the simulations\nperformed on the IBVP and the ARZ model suggest the consistency of the\ncorresponding schemes, which is easy to prove rigorously in some simple cases. \n\n"}
{"id": "1610.07745", "contents": "Title: Momentum transfer dependence of generalized parton distributions Abstract: We revisit the model for parametrization of momentum dependence of nucleon\ngeneralized parton distributions in the light of recent MRST measurements of\nparton distribution functions. Our parametrization method with minimum set of\nfree parameters give a sufficiently good description of data for Dirac and\nPauli electromagnetic form factors of proton and neutron at small and\nintermediate values of momentum transfer. We also calculate the GPDs for up and\ndown quark by decomposing the electromagnetic form factors for nucleon using\nthe charge and isospin symmetry and also study the evolution of GPDs to a\nhigher scale. We further investigate the transverse charge densities for both\nthe unpolarized and transversely polarized nucleon and compare our results with\nthe Kelly's distribution. \n\n"}
{"id": "1610.08186", "contents": "Title: Status Report (22th J-PARC PAC): Searching for a Sterile Neutrino at\n  J-PARC MLF (E56, JSNS2) Abstract: The JSNS$^2$ (J-PARC E56) experiment aims to search for a sterile neutrino at\nthe J-PARC Materials and Life Sciences Experimental Facility (MLF). After the\nsubmission of a proposal to the J-PARC PAC, Stage-1 approval was granted to the\nJSNS$^2$ experiment on April 2015.This approval followed a series of background\nmeasurements which were performed in 2014.\n  Recently, funding (the grant-in-aid for scientific research (S)) in Japan for\nbuilding one 25~ton fiducial volume detector module was approved for the\nexperiment. Therefore, we aim to start the experiment with one detector in\nJFY2018-2019. We are now working to produce precise cost estimates and schedule\nfor construction, noting that most of the detector components can be produced\nwithin one year from the date of order. This will be reported at the next PAC\nmeeting.\n  In parallel to the detector construction schedule, JSNS$^2$ will submit a\nTechnical Design report (TDR) to obtain the Stage-2 approval from the J-PARC\nPAC.The recent progress of the R$\\&$D efforts towards this TDR are shown in\nthis report. In particular, the R$\\&$D status of the liquid scintillator,\ncosmic ray veto system, and software are shown.\n  We have performed a test-experiment using 1.6~L of liquid scintillator at the\n3rd floor of the MLF building in order to determine the identities of\nnon-neutrino background particles coming to this detector location during the\nproton bunch. This is the so-called \"MLF 2015AU0001\" experiment. We briefly\nshow preliminary results from this test-experiment. \n\n"}
{"id": "1610.08883", "contents": "Title: PandaX-III: Searching for Neutrinoless Double Beta Decay with High\n  Pressure $^{136}$Xe Gas Time Projection Chambers Abstract: Searching for the Neutrinoless Double Beta Decay (NLDBD) is now regarded as\nthe topmost promising technique to explore the nature of neutrinos after the\ndiscovery of neutrino masses in oscillation experiments. PandaX-III (Particle\nAnd Astrophysical Xenon Experiment III) will search for the NLDBD of $^{136}$Xe\nat the China Jin Ping underground Laboratory (CJPL). In the first phase of the\nexperiment, a high pressure gas Time Projection Chamber (TPC) will contain 200\nkg, 90% $^{136}$Xe enriched gas operated at 10 bar. Fine pitch micro-pattern\ngas detector (Microbulk Micromegas) will be used at both ends of the TPC for\nthe charge readout with a cathode in the middle. Charge signals can be used to\nreconstruct tracks of NLDBD events and provide good energy and spatial\nresolution. The detector will be immersed in a large water tank to ensure\n$\\sim$5 m of water shielding in all directions. The second phase, a ton-scale\nexperiment, will consist of five TPCs in the same water tank, with improved\nenergy resolution and better control over backgrounds. \n\n"}
{"id": "1611.00288", "contents": "Title: Efficient variants of the CMRH method for solving a sequence of\n  multi-shifted non-Hermitian linear systems simultaneously Abstract: Multi-shifted linear systems with non-Hermitian coefficient matrices arise in\nnumerical solutions of time-dependent partial/fractional differential equations\n(PDEs/FDEs), in control theory, PageRank problems, and other research fields.\nWe derive efficient variants of the restarted Changing Minimal Residual method\nbased on the cost-effective Hessenberg procedure (CMRH) for this problem class.\nThen, we introduce a flexible variant of the algorithm that allows to use\nvariable preconditioning at each iteration to further accelerate the\nconvergence of shifted CMRH. We analyse the performance of the new class of\nmethods in the numerical solution of PDEs and FDEs, also against other\nmulti-shifted Krylov subspace methods. \n\n"}
{"id": "1611.02985", "contents": "Title: Production of charmed baryons in $\\bar p p$ collisions close to their\n  thresholds Abstract: Cross sections for the charm-production reactions $\\bar p p \\to \\bar\n\\Lambda_c^- \\Sigma_c^+$, $\\bar \\Sigma_c\\Sigma_c$, $\\bar \\Xi_c\\Xi_c$, and $\\bar\n\\Xi_c'\\Xi_c'$ are presented, for energies near their respective thresholds. The\nresults are based on a calculation performed in the meson-exchange framework in\nclose analogy to earlier studies of the J\\\"ulich group on the\nstrangeness-production reactions $\\bar p p \\to \\bar \\Lambda\\Sigma$, $\\bar\n\\Sigma\\Sigma$, $\\bar \\Xi\\Xi$ by connecting the two sectors via SU(4) flavor\nsymmetry. The cross sections are found to be in the order of $0.1 - 1$ $\\mu b$\nat energies of $100$ MeV above the respective thresholds, for all considered\nchannels. Complementary to meson-exchange, where the charmed baryons are\nproduced by the exchange of $D$ and $D^*$ mesons, a charm-production potential\nderived in a quark model is employed for assessing uncertainties. The cross\nsections predicted within that picture turned out to be significantly smaller. \n\n"}
{"id": "1611.04713", "contents": "Title: Feasibility study of SiGHT: a novel ultra low background photosensor for\n  low temperature operation Abstract: Rare event search experiments, such as those searching for dark matter and\nobservations of neutrinoless double beta decay, require ultra low levels of\nradioactive background for unmistakable identification. In order to reduce the\nradioactive backgrounds of detectors used in these types of event searches, low\nbackground photosensors are required, as the physical size of these detectors\nbecome increasing larger, and hence the number of such photosensors used also\nincreases rapidly. Considering that most dark matter and neutrinoless double\nbeta decay experiments are turning towards using noble liquids as the target\nchoice, liquid xenon and liquid argon for instance, photosensors that can work\nwell at cryogenic temperatures are required, 165 K and 87 K for liquid xenon\nand liquid argon, respectively. The Silicon Geiger Hybrid Tube (SiGHT) is a\nnovel photosensor designed specifically for use in ultra low background\nexperiments operating at cryogenic temperatures. It is based on the proven\nphotocathode plus silicon photomultiplier (SiPM) hybrid technology and consists\nof very few other, but also ultra radio-pure, materials like fused silica and\nsilicon for the SiPM. The introduction of the SiGHT concept, as well as a\nfeasibility study for its production, is reported in this paper. \n\n"}
{"id": "1611.05531", "contents": "Title: Convolutional Neural Networks Applied to Neutrino Events in a Liquid\n  Argon Time Projection Chamber Abstract: We present several studies of convolutional neural networks applied to data\ncoming from the MicroBooNE detector, a liquid argon time projection chamber\n(LArTPC). The algorithms studied include the classification of single particle\nimages, the localization of single particle and neutrino interactions in an\nimage, and the detection of a simulated neutrino event overlaid with cosmic ray\nbackgrounds taken from real detector data. These studies demonstrate the\npotential of convolutional neural networks for particle identification or event\ndetection on simulated neutrino interactions. We also address technical issues\nthat arise when applying this technique to data from a large LArTPC at or near\nground level. \n\n"}
{"id": "1611.07377", "contents": "Title: Chiral Symmetry restoration from the hadronic regime Abstract: We discuss recent advances on QCD chiral symmetry restoration at finite\ntemperature, within the theoretical framework of Effective Theories. $U(3)$\nWard Identities are derived between pseudoscalar susceptibilities and quark\ncondensates, allowing to explain the behaviour of lattice meson screening\nmasses. Unitarized interactions and the generated $f_0(500)$ thermal state are\nshowed to play an essential role in the description of the transition through\nthe scalar susceptibility \n\n"}
{"id": "1611.08117", "contents": "Title: The condition number of join decompositions Abstract: The join set of a finite collection of smooth embedded submanifolds of a\nmutual vector space is defined as their Minkowski sum. Join decompositions\ngeneralize some ubiquitous decompositions in multilinear algebra, namely tensor\nrank, Waring, partially symmetric rank and block term decompositions. This\npaper examines the numerical sensitivity of join decompositions to\nperturbations; specifically, we consider the condition number for general join\ndecompositions. It is characterized as a distance to a set of ill-posed points\nin a supplementary product of Grassmannians. We prove that this condition\nnumber can be computed efficiently as the smallest singular value of an\nauxiliary matrix. For some special join sets, we characterized the behavior of\nsequences in the join set converging to the latter's boundary points. Finally,\nwe specialize our discussion to the tensor rank and Waring decompositions and\nprovide several numerical experiments confirming the key results. \n\n"}
{"id": "1611.08817", "contents": "Title: A General Truncated Regularization Framework for Contrast-Preserving\n  Variational Signal and Image Restoration: Motivation and Implementation Abstract: Variational methods have become an important kind of methods in signal and\nimage restoration - a typical inverse problem. One important minimization model\nconsists of the squared $\\ell_2$ data fidelity (corresponding to Gaussian\nnoise) and a regularization term constructed by a potential function composed\nof first order difference operators. It is well known that total variation (TV)\nregularization, although achieved great successes, suffers from a contrast\nreduction effect. Using a typical signal, we show that, actually all convex\nregularizers and most nonconvex regularizers have this effect. With this\nmotivation, we present a general truncated regularization framework. The\npotential function is a truncation of existing nonsmooth potential functions\nand thus flat on $(\\tau,+\\infty)$ for some positive $\\tau$. Some analysis in 1D\ntheoretically demonstrate the good contrast-preserving ability of the\nframework. We also give optimization algorithms with convergence verification\nin 2D, where global minimizers of each subproblem (either convex or nonconvenx)\nare calculated. Experiments numerically show the advantages of the framework. \n\n"}
{"id": "1611.09540", "contents": "Title: Probing the scotogenic FIMP at the LHC Abstract: We analyse the signatures at the Large Hadron Collider (LHC) of the\nscotogenic model, when the lightest Z2-odd particle is a singlet fermion and a\nfeebly interacting massive particle (FIMP). We further assume that the singlet\nfermion constitutes the dark matter and that it is produced in the early\nUniverse via the freeze-in mechanism. The small couplings required to reproduce\nthe observed dark matter abundance translate into decay-lengths for the\nnext-to-lightest Z2-odd particle which can be macroscopic, potentially leading\nto spectacular signatures at the LHC. We characterize the possible signals of\nthe model according to the spectrum of the Z2-odd particles and we derive, for\neach of the cases, bounds on the parameters of the model from current searches. \n\n"}
{"id": "1611.10029", "contents": "Title: Decoupled mixed element schemes for fourth order problems Abstract: In this paper, we study decoupled mixed element schemes for fourth order\nproblems. A general process is designed such that an elliptic problem on\nhigh-regularity space is transformed to a decoupled system with spaces of low\norder involved only and is further discretised by low-degree finite elements.\nThe process can be fit for various fourth order problems, and is used in the\nremaining of the paper particularly for three-dimensional bi-Laplacian equation\nto conduct a family of mixed element discretisation schemes. \n\n"}
{"id": "1612.01567", "contents": "Title: Lattice QCD spectroscopy for hadronic CP violation Abstract: The interpretation of nuclear electric dipole moment (EDM) experiments is\nclouded by large theoretical uncertainties associated with nonperturbative\nmatrix elements. In various beyond-the-Standard Model scenarios nuclear and\ndiamagnetic atomic EDMs are expected to be dominated by CP-violating\npion-nucleon interactions that arise from quark chromo-electric dipole moments.\nThe corresponding CP-violating pion-nucleon coupling strengths are, however,\npoorly known. In this work we propose a strategy to calculate these couplings\nby using spectroscopic lattice QCD techniques. Instead of directly calculating\nthe pion-nucleon coupling constants, a challenging task, we use chiral symmetry\nrelations that link the pion-nucleon couplings to nucleon sigma terms and mass\nsplittings that are significantly easier to calculate. In this work, we show\nthat these relations are reliable up to next-to-next-to-leading order in the\nchiral expansion in both SU(2) and SU(3) chiral perturbation theory. We\nconclude with a brief discussion about practical details regarding the required\nlattice QCD calculations and the phenomenological impact of an improved\nunderstanding of CP-violating matrix elements. \n\n"}
{"id": "1612.07233", "contents": "Title: Averages of $b$-hadron, $c$-hadron, and $\\tau$-lepton properties as of\n  summer 2016 Abstract: This article reports world averages of measurements of $b$-hadron,\n$c$-hadron, and $\\tau$-lepton properties obtained by the Heavy Flavor Averaging\nGroup using results available through summer 2016. For the averaging, common\ninput parameters used in the various analyses are adjusted (rescaled) to common\nvalues, and known correlations are taken into account. The averages include\nbranching fractions, lifetimes, neutral meson mixing parameters, \\CP~violation\nparameters, parameters of semileptonic decays and CKM matrix elements. \n\n"}
{"id": "1701.00551", "contents": "Title: The weak rate of convergence for the Euler-Maruyama approximation of\n  one-dimensional stochastic differential equations involving the local times\n  of the unknown process Abstract: In this paper, we consider the weak convergence of the Euler-Maruyama\napproximation for one dimensional stochastic differential equations involving\nthe local times of the unknown process. We use a transformation in order to\nremove the local time from the stochastic differential equations and we provide\nthe approximation of Euler-maruyama for the stochastic differential equations\nwithout local time. After that, we conclude the approximation of Euler-maruyama\nfor one dimensional stochastic differential equations involving the local times\nof the unknown process , and we provide the rate of weak convergence for any\nfunction G in a certain class. \n\n"}
{"id": "1701.02522", "contents": "Title: Magnus expansions and pseudospectra of Master Equations Abstract: New directions in research on master equations are showcased by example.\nMagnus expansions, time-varying rates, and pseudospectra are highlighted. Exact\neigenvalues are found and contrasted with the large errors produced by standard\nnumerical methods in some cases. Isomerisation provides a running example and\nan illustrative application to chemical kinetics. We also give a brief example\nof the totally asymmetric exclusion process. \n\n"}
{"id": "1701.02807", "contents": "Title: The Muon g-2 experiment at Fermilab Abstract: The upcoming Fermilab E989 experiment will measure the muon anomalous\nmagnetic moment $a_{\\mu}$ . This measurement is motivated by the previous\nmeasurement performed in 2001 by the BNL E821 experiment that reported a 3-4\nstandard deviation discrepancy between the measured value and the Standard\nModel prediction. The new measurement at Fermilab aims to improve the precision\nby a factor of four reducing the total uncertainty from 540 parts per billion\n(BNL E821) to 140 parts per billion (Fermilab E989). This paper gives the\nstatus of the experiment. \n\n"}
{"id": "1701.03084", "contents": "Title: Multitrace formulations and Domain Decomposition Methods for the\n  solution of Helmholtz transmission problems for bounded composite scatterers Abstract: We present Nystr\\\"om discretizations of multitrace formulations and\nnon-overlapping Domain Decomposition Methods (DDM) for the solution of\nHelmholtz transmission problems for bounded composite scatterers with piecewise\nconstant material properties. We investigate the performance of DDM with both\nclassical Robin and generalized Robin boundary conditions. The generalized\nRobin boundary conditions incorporate square root Fourier multiplier\napproximations of Dirichlet to Neumann operators. While the classical version\nof DDM is not particularly well suited for Krylov subspace iterative solvers,\nwe show that the associated DDM linear system can be efficiently solved by\nhierarchical elimination via Schur complements of the Robin data. We show\nthrough numerical examples that the latter version of DDM gives rise to small\nnumbers of Krylov subspace iterations that depend mildly on the frequency and\nnumber of subdomains. \n\n"}
{"id": "1701.05805", "contents": "Title: Structured low rank decomposition of multivariate Hankel matrices Abstract: We study the decomposition of a multivariate Hankel matrix H\\_$\\sigma$ as a\nsum of Hankel matrices of small rank in correlation with the decomposition of\nits symbol $\\sigma$ as a sum of polynomial-exponential series. We present a new\nalgorithm to compute the low rank decomposition of the Hankel operator and the\ndecomposition of its symbol exploiting the properties of the associated\nArtinian Gorenstein quotient algebra A\\_$\\sigma$. A basis of A\\_$\\sigma$ is\ncomputed from the Singular Value Decomposition of a sub-matrix of the Hankel\nmatrix H\\_$\\sigma$. The frequencies and the weights are deduced from the\ngeneralized eigenvectors of pencils of shifted sub-matrices of H $\\sigma$.\nExplicit formula for the weights in terms of the eigenvectors avoid us to solve\na Vandermonde system. This new method is a multivariate generalization of the\nso-called Pencil method for solving Prony-type decomposition problems. We\nanalyse its numerical behaviour in the presence of noisy input moments, and\ndescribe a rescaling technique which improves the numerical quality of the\nreconstruction for frequencies of high amplitudes. We also present a new Newton\niteration, which converges locally to the closest multivariate Hankel matrix of\nlow rank and show its impact for correcting errors on input moments. \n\n"}
{"id": "1701.07529", "contents": "Title: Transport reversal for model reduction of hyperbolic partial\n  differential equations Abstract: Snapshot matrices built from solutions to hyperbolic partial differential\nequations exhibit slow decay in singular values, whereas fast decay is crucial\nfor the success of projection- based model reduction methods. To overcome this\nproblem, we build on previous work in symmetry reduction [Rowley and Marsden,\nPhysica D (2000), pp. 1-19] and propose an iterative algorithm that decomposes\nthe snapshot matrix into multiple shifting profiles, each with a corresponding\nspeed. Its applicability to typical hyperbolic problems is demonstrated through\nnumerical examples, and other natural extensions that modify the shift operator\nare considered. Finally, we give a geometric interpretation of the algorithm. \n\n"}
{"id": "1701.07680", "contents": "Title: An H^1-conforming Virtual Element Method for Darcy equations and\n  Brinkman equations Abstract: The focus of the present paper is on developing a Virtual Element Method for\nDarcy and Brinkman equations. In [15] we presented a family of Virtual Elements\nfor Stokes equations and we defined a new Virtual Element space of velocities\nsuch that the associated discrete kernel is pointwise divergence-free. We use a\nslightly different Virtual Element space having two fundamental properties: the\nL^2-projection onto P_k is exactly computable on the basis of the degrees of\nfreedom, and the associated discrete kernel is still pointwise divergence-free.\nThe resulting numerical scheme for the Darcy equation has optimal order of\nconvergence and H^1 conforming velocity solution. We can apply the same\napproach to develop a robust virtual element method for the Brinkman equation\nthat is stable for both the Stokes and Darcy limit case. We provide a rigorous\nerror analysis of the method and several numerical tests. \n\n"}
{"id": "1701.08544", "contents": "Title: The Multi-Dimensional Decomposition with Constraints Abstract: We search for the best fit in Frobenius norm of $A \\in {\\mathbb C}^{m \\times\nn}$ by a matrix product $B C^*$, where $B \\in {\\mathbb C}^{m \\times r}$ and $C\n\\in {\\mathbb C}^{n \\times r}$, $r \\le m$ so $B = \\{b_{ij}\\}$, ($i=1, \\dots,\nm$,~ $j=1, \\dots, r$) definite by some unknown parameters $\\sigma_1, \\dots,\n\\sigma_k$, $k << mr$ and all partial derivatives of $\\displaystyle \\frac{\\delta\nb_{ij}}{\\delta \\sigma_l}$ are definite, bounded and can be computed\nanalytically.\n  We show that this problem transforms to a new minimization problem with only\n$k$ unknowns, with analytical computation of gradient of minimized function by\nall $\\sigma$. The complexity of computation of gradient is only 4 times bigger\nthan the complexity of computation of the function, and this new algorithm\nneeds only $3mr$ additional memory.\n  We apply this approach for solution of the three-way decomposition problem\nand obtain good results of convergence of Broyden algorithm. \n\n"}
{"id": "1702.00280", "contents": "Title: Two classes of quadratic vector fields for which the Kahan\n  discretization is integrable Abstract: Applying Kahan's discretization to the reduced Nahm equations, we obtain two\nclasses of integrable mappings. \n\n"}
{"id": "1702.01421", "contents": "Title: An extension of Chubanov's algorithm to symmetric cones Abstract: In this work we present an extension of Chubanov's algorithm to the case of\nhomogeneous feasibility problems over a symmetric cone K. As in Chubanov's\nmethod for linear feasibility problems, the algorithm consists of a basic\nprocedure and a step where the solutions are confined to the intersection of a\nhalf-space and K. Following an earlier work by Kitahara and Tsuchiya on second\norder cone feasibility problems, progress is measured through the volumes of\nthose intersections: when they become sufficiently small, we know it is time to\nstop. We never have to explicitly compute the volumes, it is only necessary to\nkeep track of the reductions between iterations. We show this is enough to\nobtain concrete upper bounds to the minimum eigenvalues of a scaled version of\nthe original feasibility problem. Another distinguishing feature of our\napproach is the usage of a spectral norm that takes into account the way that K\nis decomposed as simple cones. In several key cases, including semidefinite\nprogramming and second order cone programming, these norms make it possible to\nobtain better complexity bounds for the basic procedure when compared to a\nrecent approach by Pe\\~na and Soheili. Finally, in the appendix, we present a\ntranslation of the algorithm to the homogeneous feasibility problem in\nsemidefinite programming. \n\n"}
{"id": "1702.02646", "contents": "Title: Identification of Radiopure Titanium for the LZ Dark Matter Experiment\n  and Future Rare Event Searches Abstract: The LUX-ZEPLIN (LZ) experiment will search for dark matter particle\ninteractions with a detector containing a total of 10 tonnes of liquid xenon\nwithin a double-vessel cryostat. The large mass and proximity of the cryostat\nto the active detector volume demand the use of material with extremely low\nintrinsic radioactivity. We report on the radioassay campaign conducted to\nidentify suitable metals, the determination of factors limiting radiopure\nproduction, and the selection of titanium for construction of the LZ cryostat\nand other detector components. This titanium has been measured with activities\nof $^{238}$U$_{e}$~$<$1.6~mBq/kg, $^{238}$U$_{l}$~$<$0.09~mBq/kg,\n$^{232}$Th$_{e}$~$=0.28\\pm 0.03$~mBq/kg, $^{232}$Th$_{l}$~$=0.25\\pm\n0.02$~mBq/kg, $^{40}$K~$<$0.54~mBq/kg, and $^{60}$Co~$<$0.02~mBq/kg (68\\% CL).\nSuch low intrinsic activities, which are some of the lowest ever reported for\ntitanium, enable its use for future dark matter and other rare event searches.\nMonte Carlo simulations have been performed to assess the expected background\ncontribution from the LZ cryostat with this radioactivity. In 1,000 days of\nWIMP search exposure of a 5.6-tonne fiducial mass, the cryostat will contribute\nonly a mean background of $0.160\\pm0.001$(stat)$\\pm0.030$(sys) counts. \n\n"}
{"id": "1702.02912", "contents": "Title: Randomized Dynamic Mode Decomposition Abstract: This paper presents a randomized algorithm for computing the near-optimal\nlow-rank dynamic mode decomposition (DMD). Randomized algorithms are emerging\ntechniques to compute low-rank matrix approximations at a fraction of the cost\nof deterministic algorithms, easing the computational challenges arising in the\narea of `big data'. The idea is to derive a small matrix from the\nhigh-dimensional data, which is then used to efficiently compute the dynamic\nmodes and eigenvalues. The algorithm is presented in a modular probabilistic\nframework, and the approximation quality can be controlled via oversampling and\npower iterations. The effectiveness of the resulting randomized DMD algorithm\nis demonstrated on several benchmark examples of increasing complexity,\nproviding an accurate and efficient approach to extract spatiotemporal coherent\nstructures from big data in a framework that scales with the intrinsic rank of\nthe data, rather than the ambient measurement dimension. For this work we\nassume that the dynamics of the problem under consideration is evolving on a\nlow-dimensional subspace that is well characterized by a fast decaying singular\nvalue spectrum. \n\n"}
{"id": "1702.04068", "contents": "Title: Electroweak monopoles and the electroweak phase transition Abstract: We consider an isolated electroweak monopole solution within the Standard\nModel with a non-linear Born-Infeld extension of the hypercharge gauge field.\nMonopole (and dyon) solutions in such an extension are regular and their masses\nare predicted to be proportional to the Born-Infeld mass parameter. We argue\nthat cosmological production of electroweak monopoles may delay the electroweak\nphase transition and make it more strongly first order for monopole masses\n$M\\gtrsim 9.3\\cdot 10^3$ TeV, while the nucleosynthesis constraints on the\nabundance of relic monopoles impose the bound $M\\lesssim 2.3\\cdot 10^4$ TeV.\nThe monopoles with a mass in this shallow range may be responsible for the\ndynamical generation of the matter-antimatter asymmetry during the electroweak\nphase transition. \n\n"}
{"id": "1702.04959", "contents": "Title: Provable Accelerated Gradient Method for Nonconvex Low Rank Optimization Abstract: Optimization over low rank matrices has broad applications in machine\nlearning. For large scale problems, an attractive heuristic is to factorize the\nlow rank matrix to a product of two much smaller matrices. In this paper, we\nstudy the nonconvex problem $\\min_{U\\in\\mathcal{R}^{n\\times r}} g(U)=f(UU^T)$\nunder the assumptions that $f(X)$ is restricted $\\mu$-strongly convex and\n$L$-smooth on the set $\\{X:X\\succeq 0,rank(X)\\leq r\\}$. We propose an\naccelerated gradient method with alternating constraint that operates directly\non the $U$ factors and show that the method has local linear convergence rate\nwith the optimal dependence on the condition number of $\\sqrt{L/\\mu}$.\nGlobally, our method converges to the critical point with zero gradient from\nany initializer. Our method also applies to the problem with the asymmetric\nfactorization of $X=\\widetilde U\\widetilde V^T$ and the same convergence result\ncan be obtained. Extensive experimental results verify the advantage of our\nmethod. \n\n"}
{"id": "1702.05180", "contents": "Title: Test of UFSD Silicon Detectors for the TOTEM Upgrade Project Abstract: This paper describes the performance of a prototype timing detector, based on\n50 micrometer thick Ultra Fast Silicon Detector, as measured in a beam test\nusing a 180 GeV/c momentum pion beam. The dependence of the time precision on\nthe pixel capacitance and the bias voltage is investigated here. A timing\nprecision from 30 ps to 100 ps, depending on the pixel capacitance, has been\nmeasured at a bias voltage of 180 V. Timing precision has also been measured as\na function of the bias voltage. \n\n"}
{"id": "1702.06245", "contents": "Title: Pair production of the Elementary Goldstone Higgs boson at the LHC Abstract: The Elementary Goldstone Higgs (EGH) model is a perturbative extension of the\nstandard model (SM), which identifies the EGH boson as the observed Higgs\nboson. In this paper, we study pair production of the EGH boson via gluon\nfusion at the LHC and find that the resonant contribution of the heavy scalar\nis very small and the SM-like triangle diagram contribution is strongly\nsuppressed. The total production cross section mainly comes from the box\ndiagram contribution and its value can be significantly enhanced with respect\nto the SM prediction. \n\n"}
{"id": "1703.00235", "contents": "Title: Lagrange-Flux schemes and the entropy property Abstract: The Lagrange-Flux schemes are Eulerian finite volume schemes that make use of\nan approximate Riemann solver in Lagrangian description with particular upwind\nconvective fluxes. They have been recently designed as variant formulations of\nLagrange-remap schemes that provide better HPC performance on modern multicore\nprocessors, see~[De Vuyst et al., OGST 71(6), 2016]. Actually Lagrange-Flux\nschemes show several advantages compared to Lagrange-remap schemes, especially\nfor multidimensional problems: they do not require the computation of deformed\nLagrangian cells or mesh intersections as in the remapping process. The paper\nfocuses on the entropy property of Lagrange-Flux schemes in their semi-discrete\nin space form, for one-dimensional problems and for the compressible Euler\nequations as example. We provide pseudo-viscosity pressure terms that ensure\nentropy production of order $O(|\\Delta u|^3)$, where $|\\Delta u|$ represents a\nvelocity jump at a cell interface. Pseudo-viscosity terms are also designed to\nvanish into expansion regions as it is the case for rarefaction waves. \n\n"}
{"id": "1703.03841", "contents": "Title: Efficient Stochastic Asymptotic-Preserving IMEX Methods for Transport\n  Equations with Diffusive Scalings and Random Inputs Abstract: For linear transport and radiative heat transfer equations with random\ninputs, we develop new generalized polynomial chaos based Asymptotic-Preserving\nstochastic Galerkin schemes that allow efficient computation for the problems\nthat contain both uncertainties and multiple scales. Compared with previous\nmethods for these problems, our new method use the implicit-explicit (IMEX)\ntime discretization to gain higher order accuracy, and by using a modified\ndiffusion operator based penalty method, a more relaxed stability condition--a\nhyperbolic, rather than parabolic, CFL stability condition, is achieved in the\ncase of small mean free path in the diffusive regime. The stochastic\nAsymptotic-Preserving property of these methods will be shown asymptotically,\nand demonstrated numerically, along with computational cost comparison with\nprevious methods. \n\n"}
{"id": "1703.06428", "contents": "Title: Indefinite Integrals of Spherical Bessel Functions Abstract: Highly oscillatory integrals, such as those involving Bessel functions, are\nbest evaluated analytically as much as possible, as numerical errors can be\ndifficult to control. We investigate indefinite integrals involving monomials\nin $x$ multiplying one or two spherical Bessel functions of the first kind\n$j_l(x)$ with integer order $l$. Closed-form solutions are presented where\npossible, and recursion relations are developed that are guaranteed to reduce\nall integrals in this class to closed-form solutions. These results allow for\ndefinite integrals over spherical Bessel functions to be computed quickly and\naccurately. For completeness, we also present our results in terms of ordinary\nBessel functions, but in general, the recursion relations do not terminate. \n\n"}
{"id": "1703.06780", "contents": "Title: Decoupled, Energy Stable Scheme for Hydrodynamic Allen-Cahn Phase Field\n  Moving Contact Line Model Abstract: In this paper, we present an efficient energy stable scheme to solve a phase\nfield model incorporating contact line condition. Instead of the usually used\nCahn-Hilliard type phase equation, we adopt the Allen-Cahn type phase field\nmodel with the static contact line boundary condition that coupled with\nincompressible Navier-Stokes equations with Navier boundary condition. The\nprojection method is used to deal with the Navier-Stokes equa- tions and an\nauxiliary function is introduced for the non-convex Ginzburg-Landau bulk\npotential. We show that the scheme is linear, decoupled and energy stable.\nMoreover, we prove that fully discrete scheme is also energy stable. An\nefficient finite element spatial discretization method is implemented to verify\nthe accuracy and efficiency of proposed schemes. Numerical results show that\nthe proposed scheme is very efficient and accurate \n\n"}
{"id": "1703.07959", "contents": "Title: The rapidity dependence of the average transverse momentum in p+p and\n  p+Pb collisions - revisited Abstract: We revisit the rapidity dependence of the average transverse momentum\n$\\left\\langle p_{T}\\right\\rangle$ in a $pp$ and $pA$ collision, using the high\nenergy factorization (HEF). We update previous predictions for the\n$\\left\\langle p_{T}\\right\\rangle$ both in central and forward rapidity region\nusing parton densities following from extended BK and BFKL evolution equations\nto account for corrections of higher orders as well as one obtained by Sudakov\nresummation. Furthermore, we demonstrate that in the mid rapidity region the\nsaturation based formalisms predict increase of the transversal momentum while\nin the forward rapidity region the $\\left\\langle p_{T}(y)\\right\\rangle$\ndecreases. \n\n"}
{"id": "1703.08152", "contents": "Title: Performance of the LHCb RICH detectors during the LHC Run II Abstract: The LHCb RICH system provides hadron identification over a wide momentum\nrange (2-100 GeV/c). This detector system is key to LHCb's precision flavour\nphysics programme, which has unique sensitivity to physics beyond the standard\nmodel. This paper reports on the performance of the LHCb RICH in Run II,\nfollowing significant changes in the detector and operating conditions. The\nchanges include the refurbishment of significant number of photon detectors,\nassembled using new vacuum technologies, and the removal of the aerogel\nradiator. The start of Run II of the LHC saw the beam energy increase to 6.5\nTeV per beam and a new trigger strategy for LHCb with full online detector\ncalibration. The RICH information has also been made available for all trigger\nstreams in the High Level Trigger for the first time. \n\n"}
{"id": "1703.09628", "contents": "Title: Correlation femtoscopy study at NICA and STAR energies within a viscous\n  hydrodynamic plus cascade model Abstract: Correlation femtoscopy allows one to measure the space-time characteristics\nof particle production in relativistic heavy-ion collisions due to the effects\nof quantum statistics (QS) and final state interactions (FSI). The main\nfeatures of the femtoscopy measurements at top RHIC and LHC energies are\nconsidered as a manifestation of strong collective flow and are well\ninterpreted within hydrodynamic models employing equation of state (EoS) with a\ncrossover type transition between Quark-Gluon Plasma (QGP) and hadron gas\nphases. The femtoscopy at lower energies was intensively studied at AGS and SPS\naccelerators and is being studied now in the Beam Energy Scan program (BES) at\nthe BNL Relativistic Heavy Ion Collider in the context of exploration of the\nQCD phase diagram. In this article we present femtoscopic observables\ncalculated for Au-Au collisions at $\\sqrt{s_{NN}} = 7.7 - 62.4$ GeV in a\nviscous hydro + cascade model vHLLE+UrQMD and their dependence on the EoS of\nthermalized matter. \n\n"}
{"id": "1703.09971", "contents": "Title: A Geometric Framework for Stochastic Shape Analysis Abstract: We introduce a stochastic model of diffeomorphisms, whose action on a variety\nof data types descends to stochastic evolution of shapes, images and landmarks.\nThe stochasticity is introduced in the vector field which transports the data\nin the Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework for\nshape analysis and image registration. The stochasticity thereby models errors\nor uncertainties of the flow in following the prescribed deformation velocity.\nThe approach is illustrated in the example of finite dimensional landmark\nmanifolds, whose stochastic evolution is studied both via the Fokker-Planck\nequation and by numerical simulations. We derive two approaches for inferring\nparameters of the stochastic model from landmark configurations observed at\ndiscrete time points. The first of the two approaches matches moments of the\nFokker-Planck equation to sample moments of the data, while the second approach\nemploys an Expectation-Maximisation based algorithm using a Monte Carlo bridge\nsampling scheme to optimise the data likelihood. We derive and numerically test\nthe ability of the two approaches to infer the spatial correlation length of\nthe underlying noise. \n\n"}
{"id": "1704.03014", "contents": "Title: Jet observables and stops at 100 TeV collider Abstract: A future proton-proton collider with center of mass energy around 100 TeV\nwill have a remarkable capacity to discover massive new particles and continue\nexploring weak scale naturalness. In this work we will study its sensitivity to\ntwo stop simplified models as further examples of its potential power: pair\nproduction of stops that decay to tops or bottoms and higgsinos; and stops that\nare either pair produced or produced together with a gluino and then cascade\ndown through gluinos to the lightest superpartner (LSP). In both simplified\nmodels, super-boosted tops or bottoms with transverse momentum of order TeV\nwill be produced abundantly and call for new strategies to identify them. We\nwill apply a set of simple jet observables, including track-based jet mass,\nN-subjettiness and mass drop, to tag the boosted hadronic or leptonic decaying\nobjects and suppress the Standard Model as well as possible SUSY backgrounds.\nAssuming 10% systematic uncertainties, the future 100 TeV collider can discover\n(exclude) stops with masses up to 6 (7) TeV with 3 inverse attobarns of\nintegrated luminosity if the stops decay to higgsinos. If the stops decay\nthrough gluinos to LSPs, due to additional SUSY backgrounds from gluino pair\nproduction, a higher luminosity of about 30 inverse attobarns is needed to\ndiscover stops up to 6 TeV. We will also discuss how to use jet observables to\ndistinguish simplified models with different types of LSPs. The boosted top or\nbottom tagging strategies developed in this paper could also be used in other\nsearches at a 100 TeV collider. For example, the strategy could help discover\ngluino pair production with gluino mass close to 11 TeV with 3 inverse\nattobarns of integrated luminosity. \n\n"}
{"id": "1704.05451", "contents": "Title: Resolving Knudsen Layer by High Order Moment Expansion Abstract: We model the Knudsen layer in Kramers' problem by linearized high order\nhyperbolic moment system. Due to the hyperbolicity, the boundary conditions of\nthe moment system is properly reduced from the kinetic boundary condition. For\nKramers' problem, we give the analytical solutions of moment systems. With the\norder increasing of the moment model, the solutions are approaching to the\nsolution of the linearized BGK kinetic equation. The velocity profile in the\nKnudsen layer is captured with improved accuracy for a wide range of\naccommodation coefficients. \n\n"}
{"id": "1704.07272", "contents": "Title: Advanced Multilevel Monte Carlo Methods Abstract: This article reviews the application of advanced Monte Carlo techniques in\nthe context of Multilevel Monte Carlo (MLMC). MLMC is a strategy employed to\ncompute expectations which can be biased in some sense, for instance, by using\nthe discretization of a associated probability law. The MLMC approach works\nwith a hierarchy of biased approximations which become progressively more\naccurate and more expensive. Using a telescoping representation of the most\naccurate approximation, the method is able to reduce the computational cost for\na given level of error versus i.i.d. sampling from this latter approximation.\nAll of these ideas originated for cases where exact sampling from couples in\nthe hierarchy is possible. This article considers the case where such exact\nsampling is not currently possible. We consider Markov chain Monte Carlo and\nsequential Monte Carlo methods which have been introduced in the literature and\nwe describe different strategies which facilitate the application of MLMC\nwithin these methods. \n\n"}
{"id": "1704.07669", "contents": "Title: Single-Pass PCA of Large High-Dimensional Data Abstract: Principal component analysis (PCA) is a fundamental dimension reduction tool\nin statistics and machine learning. For large and high-dimensional data,\ncomputing the PCA (i.e., the singular vectors corresponding to a number of\ndominant singular values of the data matrix) becomes a challenging task. In\nthis work, a single-pass randomized algorithm is proposed to compute PCA with\nonly one pass over the data. It is suitable for processing extremely large and\nhigh-dimensional data stored in slow memory (hard disk) or the data generated\nin a streaming fashion. Experiments with synthetic and real data validate the\nalgorithm's accuracy, which has orders of magnitude smaller error than an\nexisting single-pass algorithm. For a set of high-dimensional data stored as a\n150 GB file, the proposed algorithm is able to compute the first 50 principal\ncomponents in just 24 minutes on a typical 24-core computer, with less than 1\nGB memory cost. \n\n"}
{"id": "1704.07912", "contents": "Title: Wiener-Hermite Polynomial Expansion for Multivariate Gaussian\n  Probability Measures Abstract: This paper introduces a new generalized polynomial chaos expansion (PCE)\ncomprising multivariate Hermite orthogonal polynomials in dependent Gaussian\nrandom variables. The second-moment properties of Hermite polynomials reveal a\nweakly orthogonal system when obtained for a general Gaussian probability\nmeasure. Still, the exponential integrability of norm allows the Hermite\npolynomials to constitute a complete set and hence a basis in a Hilbert space.\nThe completeness is vitally important for the convergence of the generalized\nPCE to the correct limit. The optimality of the generalized PCE and the\napproximation quality due to truncation are discussed. New analytical formulae\nare proposed to calculate the mean and variance of a generalized PCE\napproximation of a general output variable in terms of the expansion\ncoefficients and statistical properties of Hermite polynomials. However, unlike\nin the classical PCE, calculating the coefficients of the generalized PCE\nrequires solving a coupled system of linear equations. Besides, the variance\nformula of the generalized PCE contains additional terms due to statistical\ndependence among Gaussian variables. The additional terms vanish when the\nGaussian variables are statistically independent, reverting the generalized PCE\nto the classical PCE. Numerical examples illustrate the generalized PCE\napproximation in estimating the statistical properties of various output\nvariables. \n\n"}
{"id": "1704.08708", "contents": "Title: Indirect Detection of Neutrino Portal Dark Matter Abstract: We investigate the feasibility of the indirect detection of dark matter in a\nsimple model using the neutrino portal. The model is very economical, with\nright-handed neutrinos generating neutrino masses through the Type-I seesaw\nmechanism and simultaneously mediating interactions with dark matter. Given the\nsmall neutrino Yukawa couplings expected in a Type-I seesaw, direct detection\nand accelerator probes of dark matter in this scenario are challenging.\nHowever, dark matter can efficiently annihilate to right-handed neutrinos,\nwhich then decay via active-sterile mixing through the weak interactions,\nleading to a variety of indirect astronomical signatures. We derive the\nexisting constraints on this scenario from Planck cosmic microwave background\nmeasurements, Fermi dwarf spheroidal galaxies and Galactic Center gamma-rays\nobservations, and Alpha Magnetic Spectrometer - 02 antiprotons observations,\nand also discuss the future prospects of Fermi and the Cherenkov Telescope\nArray. Thermal annihilation rates are already being probed for dark matter\nlighter than about 50 GeV, and this can be extended to dark matter masses of\n100 GeV and beyond in the future. This scenario can also provide a dark matter\ninterpretation of the Fermi Galactic Center gamma ray excess, and we confront\nthis interpretation with other indirect constraints. Finally we discuss some of\nthe exciting implications of extensions of the minimal model with large\nneutrino Yukawa couplings and Higgs portal couplings. \n\n"}
{"id": "1704.08898", "contents": "Title: Machine Learning-based Energy Reconstruction for Water-Cherenkov\n  detectors Abstract: Hyper-Kamiokande (Hyper-K) is a proposed next generation underground water\nCherenkov (WCh) experiment. The far detector will measure the oscillated\nneutrino flux from the long-baseline neutrino experiment using 0.6 GeV\nneutrinos produced by a 1.3 MW proton beam at J-PARC. It has a broad program of\nphysics and astrophysics mainly focusing on the precise measurement of the\nlepton neutrino mixing matrix and the CP asymmetry. The unoscillated neutrino\nflux will be measured by an intermediate WCh detector. One of the proposed\ndesigns is the Tokai Intermediate Tank for the Unoscillated Spectrum (TITUS).\nWCh detectors are instrumented with photomultipliers to detect the Cherenkov\nlight emitted from charged particles which are produced by neutrino\ninteractions. The detection of light is used to measure the energy, position\nand direction of the charged particles. We propose machine learning-based\nmethods to reconstruct the energy of charged particles in WCh detectors and\npresent our results for the TITUS configuration. \n\n"}
{"id": "1705.02150", "contents": "Title: Discharge and stability studies for the new readout chambers of the\n  upgraded ALICE TPC Abstract: The ALICE (A Large Ion Collider Experiment) Time Projection Chamber (TPC) at\nCERN LHC is presently equipped with Multi Wire Proportional Chambers (MWPCs). A\ngating grid prevents ions produced during the gas amplification from moving\ninto the drift volume. The maximum drift time of the electrons together with\nthe closure time of the gating grid allows a maximum readout rate of about 3\nkHz. After the Long Shutdown 2 (from 2021 onwards), the LHC will provide\nlead-lead collisions at an expected interaction rate of 50 kHz. To take data at\nthis rate the TPC will be upgraded with new readout chambers, allowing for\ncontinuous read-out and preserving the energy and momentum resolution of the\ncurrent MWPCs.\n  Chambers with a stack of four Gas Electron Multipliers (GEMs) fulfil all the\nperformance requirements, if the voltages applied to the GEMs are tuned\nproperly. In order to ensure that these chambers are stable while being\noperated at the LHC, studies of the discharge behaviour were performed. We\nreport on studies done with small prototypes equipped with one or two GEMs.\nDischarges were voluntarily induced by a combination of high-voltages across\nthe GEM(s) and highly ionising particles. During these studies, the phenomenon\nof \"secondary discharges\" has been observed. These occur only after an initial\ndischarge when the electric field above or below the GEM is high enough. The\ntime between the initial and the secondary discharge ranges from several 10 us\nto less than 1 us, decreasing with increasing field. Using decoupling resistors\nin the high-voltage supply path of the bottom side of the GEM shifts the\noccurrence of these discharges to higher electric fields. \n\n"}
{"id": "1705.02978", "contents": "Title: Cubatures on Grassmannians: moments, dimension reduction, and related\n  topics Abstract: We briefly explain the use of cubature points on Grassmannians in numerical\nanalysis. \n\n"}
{"id": "1705.04106", "contents": "Title: Residual-Based A Posteriori Error Estimates for Symmetric Conforming\n  Mixed Finite Elements for Linear Elasticity Problems Abstract: A posteriori error estimators for the symmetric mixed finite element methods\nfor linear elasticity problems of Dirichlet and mixed boundary conditions are\nproposed. Stability and efficiency of the estimators are proved. Finally, we\nprovide numerical examples to verify the theoretical results. \n\n"}
{"id": "1705.04179", "contents": "Title: Soft Recovery With General Atomic Norms Abstract: This paper describes a dual certificate condition on a linear measurement\noperator $A$ (defined on a Hilbert space $\\mathcal{H}$ and having\nfinite-dimensional range) which guarantees that an atomic norm minimization, in\na certain sense, will be able to approximately recover a structured signal $v_0\n\\in \\mathcal{H}$ from measurements $Av_0$. Put very streamlined, the condition\nimplies that peaks in a sparse decomposition of $v_0$ are close the the support\nof the atomic decomposition of the solution $v^*$. The condition applies in a\nrelatively general context - in particular, the space $\\mathcal{H}$ can be\ninfinite-dimensional. The abstract framework is applied to several concrete\nexamples, one example being super-resolution. In this process, several novel\nresults which are interesting on its own are obtained. \n\n"}
{"id": "1705.04603", "contents": "Title: Parametric Imaging of FDG-PET Data Using Physiology and Iterative\n  Regularization: Application to the Hepatic and Renal Systems Abstract: The present paper proposes a novel computational method for parametric\nimaging of nuclear medicine data. The mathematical procedure is general enough\nto work for compartmental models of diverse complexity and is effective in the\ndetermination of the parametric maps of all kinetic parameters governing tracer\nflow. We consider applications to [18F]-fluorodeoxyglucose Positron Emission\nTomography (FDG-PET) data and analyze the two-compartment catenary model\ndescribing the standard FDG metabolization by an homogeneous tissue, e.g. the\nliver, and the three-compartment non-catenary model representing the renal\nphysiology. The proposed imaging method starts from the reconstructed FDG-PET\nimages of tracer concentration and preliminarily applies image processing\nalgorithms for noise reduction and image segmentation processes for selecting\nthe region enclosing the organ of physiologic interest. The optimization scheme\nsolves pixelwise the non-linear inverse problem of determining the kinetic\nparameters from dynamic concentration data through a Gauss-Newton iterative\nalgorithm with a penalty term accounting for the ill-posedness of the problem.\nWe tested our imaging approach on FDG-PET data of murine models obtained by\nmeans of a dedicated microPET system, and we analyzed different PET slices\ncontaining axial sections of the liver and axial sections of the kidneys. The\nreconstructed parametric images proved to be reliable and qualitatively\neffective in the description of the local FDG metabolism with respect to the\ndifferent physiologies. \n\n"}
{"id": "1705.04829", "contents": "Title: Space-Time Multi-patch Discontinuous Galerkin Isogeometric Analysis for\n  Parabolic Evolution Problems Abstract: We present and analyze a stable space-time multi-patch discontinuous Galerkin\nIsogeometric Analysis (dG-IgA) scheme for the numerical solution of parabolic\nevolution equations in moving space-time computational domains. Following\n\\cite{LangerMooreNeumueller:2016a}, we use a time-upwind test function and\napply multi-patch discontinuous Galerkin IgA methodology for discretizing the\nevolution problem both in space and in time. This yields a discrete bilinear\nform which is elliptic on the IgA space with respect to a space-time dG norm.\nThis property together with a corresponding boundedness property, consistency\nand approximation results for the IgA spaces yields an \\textit{a priori\ndiscretization} error estimate with respect to the space-time dG norm. The\ntheoretical results are confirmed by several numerical experiments with low-\nand high-order IgA spaces. \n\n"}
{"id": "1705.05925", "contents": "Title: The Large N Limit with Vanishing Leading Order Condensate for Zero Pion\n  Mass Abstract: It is conventionally assumed that the negative mass squared term in the\nlinear sigma model version of the pion Lagrangian is $M^2 \\sim \\Lambda_{\\rm\nQCD}^2$ in powers of $N_c$. We consider the case where $M^2 \\sim \\Lambda^2_{\\rm\nQCD}/N_c$ so that to leading order in $N_c$ this symmetry breaking term\nvanishes. We present some arguments why this might be plausible. One might\nthink that such a radical assumption would contradict lattice Monte Carlo data\non QCD as function of $N_c$. We show that the linear sigma model gives a fair\ndescription of the data of DeGrand and Liu both for $N_c = 3$, and for variable\n$N_c$. The values of quark masses considered by DeGrand and Liu, and by Bali\net. al. turn out to be too large to resolve the case we consider from that of\nthe conventional large $N_c$ limit. We argue that for quark masses $m_{q} \\ll\n\\Lambda_{\\rm QCD}/N_c^{3/2}$, both the baryon mass and nucleon size scale as\n$\\sqrt{N_c}$. For $m_{q} \\gg \\Lambda_{\\rm QCD}/N_c^{3/2}$ the conventional\nlarge-$N_c$ counting holds. The physical values of quark masses for QCD\ncorrespond to the small quark mass limit. We find pion-nucleon coupling\nstrengths are reduced to order ${\\cal O}(1)$ rather than ${\\cal O}(N_c)$. Under\nthe assumption that in the large $N_c$ limit the sigma meson mass is larger\nthan that of the omega, and that the omega-nucleon coupling constant is larger\nthan that of the sigma, we argue that the nucleon-nucleon large range potential\nis weakly attractive and admits an interaction energy of order $\\Lambda_{\\rm\nQCD}/N_c^{5/2} \\sim 10$ MeV. With these assumptions on coupling and masses,\nthere is no strong long range attractive channel for nucleon-nucleon\ninteractions, so that nuclear matter at densities much smaller than that where\nnucleons strongly interact is a weakly interacting configuration of nucleons\nwith strongly interacting localized cores. \n\n"}
{"id": "1705.06101", "contents": "Title: High order fast algorithm for the Caputo fractional derivative Abstract: In the paper, we present a high order fast algorithm with almost optimum\nmemory for the Caputo fractional derivative, which can be expressed as a\nconvolution of $u'(t)$ with the kernel $(t_n-t)^{-\\alpha}$. In the fast\nalgorithm, the interval $[0,t_{n-1}]$ is split into nonuniform subintervals.\nThe number of the subintervals is in the order of $\\log n$ at the $n$-th time\nstep. The fractional kernel function is approximated by a polynomial function\nof $K$-th degree with a uniform absolute error on each subinterval. We save\n$K+1$ integrals on each subinterval, which can be written as a convolution of\n$u'(t)$ with a polynomial base function. As compared with the direct method,\nthe proposed fast algorithm reduces the storage requirement and computational\ncost from $O(n)$ to $O((K+1)\\log n)$ at the $n$-th time step. We prove that the\nconvergence rate of the fast algorithm is the same as the direct method even a\nhigh order direct method is considered. The convergence rate and efficiency of\nthe fast algorithm are illustrated via several numerical examples. \n\n"}
{"id": "1705.07646", "contents": "Title: An approximate empirical Bayesian method for large-scale linear-Gaussian\n  inverse problems Abstract: We study Bayesian inference methods for solving linear inverse problems,\nfocusing on hierarchical formulations where the prior or the likelihood\nfunction depend on unspecified hyperparameters. In practice, these\nhyperparameters are often determined via an empirical Bayesian method that\nmaximizes the marginal likelihood function, i.e., the probability density of\nthe data conditional on the hyperparameters. Evaluating the marginal\nlikelihood, however, is computationally challenging for large-scale problems.\nIn this work, we present a method to approximately evaluate marginal likelihood\nfunctions, based on a low-rank approximation of the update from the prior\ncovariance to the posterior covariance. We show that this approximation is\noptimal in a minimax sense. Moreover, we provide an efficient algorithm to\nimplement the proposed method, based on a combination of the randomized SVD and\na spectral approximation method to compute square roots of the prior covariance\nmatrix. Several numerical examples demonstrate good performance of the proposed\nmethod. \n\n"}
{"id": "1705.08445", "contents": "Title: Stratification as a general variance reduction method for Markov chain\n  Monte Carlo Abstract: The Eigenvector Method for Umbrella Sampling (EMUS) belongs to a popular\nclass of methods in statistical mechanics which adapt the principle of\nstratified survey sampling to the computation of free energies. We develop a\ndetailed theoretical analysis of EMUS. Based on this analysis, we show that\nEMUS is an efficient general method for computing averages over arbitrary\ntarget distributions. In particular, we show that EMUS can be dramatically more\nefficient than direct MCMC when the target distribution is multimodal or when\nthe goal is to compute tail probabilities. To illustrate these theoretical\nresults, we present a tutorial application of the method to a problem from\nBayesian statistics. \n\n"}
{"id": "1705.09895", "contents": "Title: Status of installation and commissioning for the Belle II\n  time-of-propagation counter Abstract: The Time-Of-Propagation (TOP) counter is a novel device for particle\nidentification for the barrel region of the Belle II experiment, where,\ninformation of Cherenkov light propagation time is used to reconstruct its ring\nimage. We successfully finished the detector production and installation to the\nBelle II structure in 2016. Commissioning of the installed detector has been on\ngoing, where the detector operation in the 1.5-T magnetic field was studied.\nAlthough we found a problem where photomultipliers were mechanically moved due\nto the magnetic force, it was immediately fixed. Performance was evaluated with\ncosmic ray data, the number of photon hits were confirmed to be consistent with\nsimulation within 15-30%. \n\n"}
{"id": "1705.10086", "contents": "Title: Large-Scale Computation of ${\\mathcal L}_\\infty$-Norms by a Greedy\n  Subspace Method Abstract: We are concerned with the computation of the ${\\mathcal L}_\\infty$-norm for\nan ${\\mathcal L}_\\infty$-function of the form $H(s) = C(s) D(s)^{-1} B(s)$,\nwhere the middle factor is the inverse of a meromorphic matrix-valued function,\nand $C(s),\\, B(s)$ are meromorphic functions mapping to short-and-fat and\ntall-and-skinny matrices, respectively. For instance, transfer functions of\ndescriptor systems and delay systems fall into this family. We focus on the\ncase where the middle factor is large-scale. We propose a subspace projection\nmethod to obtain approximations of the function $H$ where the middle factor is\nof much smaller dimension. The ${\\mathcal L}_\\infty$-norms are computed for the\nresulting reduced functions, then the subspaces are refined by means of the\noptimal points on the imaginary axis where the ${\\mathcal L}_\\infty$-norm of\nthe reduced function is attained. The subspace method is designed so that\ncertain Hermite interpolation properties hold between the largest singular\nvalues of the original and reduced functions. This leads to a locally\nsuperlinearly convergent algorithm with respect to the subspace dimension,\nwhich we prove and illustrate on various numerical examples. \n\n"}
{"id": "1705.10175", "contents": "Title: Numerical low-rank approximation of matrix differential equations Abstract: The efficient numerical integration of large-scale matrix differential\nequations is a topical problem in numerical analysis and of great importance in\nmany applications. Standard numerical methods applied to such problems require\nan unduly amount of computing time and memory, in general. Based on a dynamical\nlow-rank approximation of the solution, a new splitting integrator is proposed\nfor a quite general class of stiff matrix differential equations. This class\ncomprises differential Lyapunov and differential Riccati equations that arise\nfrom spatial discretizations of partial differential equations. The proposed\nintegrator handles stiffness in an efficient way, and it preserves the symmetry\nand positive semidefiniteness of solutions of differential Lyapunov equations.\nNumerical examples that illustrate the benefits of this new method are given.\nIn particular, numerical results for the efficient simulation of the weather\nphenomenon El Ni\\~no are presented. \n\n"}
{"id": "1706.00971", "contents": "Title: A finite difference method for space fractional differential equations\n  with variable diffusivity coefficient Abstract: Anomalous diffusion is a phenomenon that cannot be modeled accurately by\nsecond-order diffusion equations, but is better described by fractional\ndiffusion models. The nonlocal nature of the fractional diffusion operators\nmakes substantially more difficult the mathematical analysis of these models\nand the establishment of suitable numerical schemes. This paper proposes and\nanalyzes the first finite difference method for solving {\\em\nvariable-coefficient} fractional differential equations, with two-sided\nfractional derivatives, in one-dimensional space. The proposed scheme combines\nfirst-order forward and backward Euler methods for approximating the left-sided\nfractional derivative when the right-sided fractional derivative is\napproximated by two consecutive applications of the first-order backward Euler\nmethod. Our finite difference scheme reduces to the standard second-order\ncentral difference scheme in the absence of fractional derivatives. The\nexistence and uniqueness of the solution for the proposed scheme are proved,\nand truncation errors of order $h$ are demonstrated, where $h$ denotes the\nmaximum space step size. The numerical tests illustrate the global $O(h)$\naccuracy of our scheme, except for nonsmooth cases which, as expected, have\ndeteriorated convergence rates. \n\n"}
{"id": "1706.02205", "contents": "Title: Compression, inversion, and approximate PCA of dense kernel matrices at\n  near-linear computational complexity Abstract: Dense kernel matrices $\\Theta \\in \\mathbb{R}^{N \\times N}$ obtained from\npoint evaluations of a covariance function $G$ at locations $\\{ x_{i} \\}_{1\n\\leq i \\leq N} \\subset \\mathbb{R}^{d}$ arise in statistics, machine learning,\nand numerical analysis. For covariance functions that are Green's functions of\nelliptic boundary value problems and homogeneously-distributed sampling points,\nwe show how to identify a subset $S \\subset \\{ 1 , \\dots , N \\}^2$, with $\\# S\n= O ( N \\log (N) \\log^{d} ( N /\\epsilon ) )$, such that the zero fill-in\nincomplete Cholesky factorisation of the sparse matrix $\\Theta_{ij} 1_{( i, j )\n\\in S}$ is an $\\epsilon$-approximation of $\\Theta$. This factorisation can\nprovably be obtained in complexity $O ( N \\log( N ) \\log^{d}( N /\\epsilon) )$\nin space and $O ( N \\log^{2}( N ) \\log^{2d}( N /\\epsilon) )$ in time, improving\nupon the state of the art for general elliptic operators; we further present\nnumerical evidence that $d$ can be taken to be the intrinsic dimension of the\ndata set rather than that of the ambient space. The algorithm only needs to\nknow the spatial configuration of the $x_{i}$ and does not require an analytic\nrepresentation of $G$. Furthermore, this factorization straightforwardly\nprovides an approximate sparse PCA with optimal rate of convergence in the\noperator norm. Hence, by using only subsampling and the incomplete Cholesky\nfactorization, we obtain, at nearly linear complexity, the compression,\ninversion and approximate PCA of a large class of covariance matrices. By\ninverting the order of the Cholesky factorization we also obtain a solver for\nelliptic PDE with complexity $O ( N \\log^{d}( N /\\epsilon) )$ in space and $O (\nN \\log^{2d}( N /\\epsilon) )$ in time, improving upon the state of the art for\ngeneral elliptic operators. \n\n"}
{"id": "1706.04561", "contents": "Title: Least Fine-Tuned U(1) Extended SSM Abstract: We consider the Higgs boson mass in a class of the UMSSM models in which the\nMSSM gauge group is extended by an additional U(1)' group. Implementing the\nuniversal boundary conditions at the GUT scale we target phenomenologically\ninteresting regions of UMSSM where the necessary radiative contributions to the\nlightest CP-even Higgs boson mass are significantly small and LSP is always the\nlightest neutralino. We find that the smallest amount of radiative\ncontributions is about 50 GeV in UMSSM, this result is much lower than that\nobtained in MSSM, which is around 90 GeV. Additionally, we examine the Higgs\nboson properties in these models to check if it can behave similar to the SM\nHiggs boson under the current experimental constraints. We find that\nenforcement of smaller radiative contribution mostly restricts the U(1)'\nbreaking scale as v_S <~ 10 TeV. Besides, such low contributions demand h_S ~\n0.2 - 0.45. Because of the model dependency in realizing these radiative\ncontributions theta_E_6 < 0 are more favored, if one seeks for the solutions\nconsistent with the current dark matter constraints. As to the mass spectrum,\nwe find that stop and stau can be degenerate with the LSP neutralino in the\nrange from 300 GeV to 700 GeV; however, the dark matter constraints restrict\nthis scale as m_stop, m_stau >~ 500$ GeV. Such degenerate solutions also\npredict stop-neutralino and stau-neutralino coannihilation channels, which are\neffective to reduce the relic abundance of neutralino down to the ranges\nconsistent with the current dark matter observations. Finally, we discuss the\neffects of heavy M_Z' in the fine-tuning. Even though the radiative\ncontributions are significantly low, the required fine-tuning can still be\nlarge. We comment about reinterpretation of the fine-tuning measure in the\nUMSSM framework, which can yield efficiently low results for the fine-tuning at\nthe electroweak scale. \n\n"}
{"id": "1706.06126", "contents": "Title: Analytic approximation of solutions of parabolic partial differential\n  equations with variable coefficients Abstract: A complete family of solutions for the one-dimensional reaction-diffusion\nequation \\[ u_{xx}(x,t)-q(x)u(x,t) = u_t(x,t) \\] with a coefficient $q$\ndepending on $x$ is constructed. The solutions represent the images of the heat\npolynomials under the action of a transmutation operator. Their use allows one\nto obtain an explicit solution of the noncharacteristic Cauchy problem for the\nconsidered equation with sufficiently regular Cauchy data as well as to solve\nnumerically initial boundary value problems. In the paper the Dirichlet\nboundary conditions are considered however the proposed method can be easily\nextended onto other standard boundary conditions. The proposed numerical method\nis shown to reveal good accuracy. \n\n"}
{"id": "1706.06141", "contents": "Title: A fast algorithm for regularized focused 3-D inversion of gravity data\n  using the randomized SVD Abstract: A fast algorithm for solving the under-determined 3-D linear gravity inverse\nproblem based on the randomized singular value decomposition (RSVD) is\ndeveloped. The algorithm combines an iteratively reweighted approach for\n$L_1$-norm regularization with the RSVD methodology in which the large scale\nlinear system at each iteration is replaced with a much smaller linear system.\nAlthough the optimal choice for the low rank approximation of the system matrix\nwith m rows is q=m, acceptable results are achievable with q<<m. In contrast to\nthe use of the LSQR algorithm for the solution of the linear systems at each\niteration, the singular values generated using the RSVD yield a good\napproximation of the dominant singular values of the large scale system matrix.\nThe regularization parameter found for the small system at each iteration is\nthus dependent on the dominant singular values of the large scale system matrix\nand appropriately regularizes the dominant singular space of the large scale\nproblem. The results achieved are comparable with those obtained using the LSQR\nalgorithm for solving each linear system, but are obtained at reduced\ncomputational cost. The method has been tested on synthetic models along with\nthe real gravity data from the Morro do Engenho complex from central Brazil. \n\n"}
{"id": "1706.08190", "contents": "Title: Multilevel Monte Carlo on a high-dimensional parameter space for\n  transmission problems with geometric uncertainties Abstract: In the framework of uncertainty quantification, we consider a quantity of\ninterest which depends non-smoothly on the high-dimensional parameter\nrepresenting the uncertainty. We show that, in this situation, the multilevel\nMonte Carlo algorithm is a valid option to compute moments of the quantity of\ninterest (here we focus on the expectation), as it allows to bypass the precise\nlocation of discontinuities in the parameter space. We illustrate how such lack\nof smoothness occurs for the point evaluation of the solution to a (Helmholtz)\ntransmission problem with uncertain interface, if the point can be crossed by\nthe interface for some realizations. For this case, we provide a space\nregularity analysis for the solution, in order to state converge results in the\nL1-norm for the finite element discretization. The latter are then used to\ndetermine the optimal distribution of samples among the Monte Carlo levels.\nParticular emphasis is given on the robustness of our estimates with respect to\nthe dimension of the parameter space. \n\n"}
{"id": "1706.08726", "contents": "Title: Pad\\'e approximants and analytic continuation of Euclidean Phi-derivable\n  approximations Abstract: We investigate the Pad\\'e approximation method for the analytic continuation\nof numerical data and its ability to access, from the Euclidean propagator,\nboth the spectral function and part of the physical information hidden in the\nsecond Riemann sheet. We test this method using various benchmarks at zero\ntemperature: a simple perturbative approximation as well as the two-loop\nPhi-derivable approximation. The analytic continuation method is then applied\nto Euclidean data previously obtained in the O(4) symmetric model (within a\ngiven renormalization scheme) to assess the difference between zero-momentum\nand pole masses, which is in general a difficult question to answer within\nnonperturbative approaches such as the Phi-derivable expansion scheme. \n\n"}
{"id": "1707.02569", "contents": "Title: On orthogonal tensors and best rank-one approximation ratio Abstract: As is well known, the smallest possible ratio between the spectral norm and\nthe Frobenius norm of an $m \\times n$ matrix with $m \\le n$ is $1/\\sqrt{m}$ and\nis (up to scalar scaling) attained only by matrices having pairwise orthonormal\nrows. In the present paper, the smallest possible ratio between spectral and\nFrobenius norms of $n_1 \\times \\dots \\times n_d$ tensors of order $d$, also\ncalled the best rank-one approximation ratio in the literature, is\ninvestigated. The exact value is not known for most configurations of $n_1 \\le\n\\dots \\le n_d$. Using a natural definition of orthogonal tensors over the real\nfield (resp., unitary tensors over the complex field), it is shown that the\nobvious lower bound $1/\\sqrt{n_1 \\cdots n_{d-1}}$ is attained if and only if a\ntensor is orthogonal (resp., unitary) up to scaling. Whether or not orthogonal\nor unitary tensors exist depends on the dimensions $n_1,\\dots,n_d$ and the\nfield. A connection between the (non)existence of real orthogonal tensors of\norder three and the classical Hurwitz problem on composition algebras can be\nestablished: existence of orthogonal tensors of size $\\ell \\times m \\times n$\nis equivalent to the admissibility of the triple $[\\ell,m,n]$ to the Hurwitz\nproblem. Some implications for higher-order tensors are then given. For\ninstance, real orthogonal $n \\times \\dots \\times n$ tensors of order $d \\ge 3$\ndo exist, but only when $n = 1,2,4,8$. In the complex case, the situation is\nmore drastic: unitary tensors of size $\\ell \\times m \\times n$ with $\\ell \\le m\n\\le n$ exist only when $\\ell m \\le n$. Finally, some numerical illustrations\nfor spectral norm computation are presented. \n\n"}
{"id": "1707.03733", "contents": "Title: Solving primal plasticity increment problems in the time of a single\n  predictor-corrector iteration Abstract: The Truncated Nonsmooth Newton Multigrid (TNNMG) method is a well-established\nmethod for the solution of strictly convex block-separably nondifferentiable\nminimization problems. It achieves multigrid-like performance even for\nnon-smooth nonlinear problems, while at the same time being globally convergent\nand without employing penalty parameters. We show that the algorithm can be\napplied to the primal problem of classical linear elastoplasticity with\nhardening. Numerical experiments show that the method is considerably faster\nthan classical predictor-corrector methods. Indeed, solving an entire increment\nproblem with TNNMG takes less time than a single predictor-corrector iteration\nfor the same problem. Since the algorithm does not rely on differentiability of\nthe objective functional, nonsmooth yield functions like the Tresca yield\nfunction can be easily incorporated. The method is closely related to a\npredictor-corrector scheme with a consistent tangent predictor and line search.\nWe explain the algorithm, prove global convergence, and show its efficiency\nusing a standard benchmark from the literature. \n\n"}
{"id": "1707.04525", "contents": "Title: Quantized-CP Approximation and Sparse Tensor Interpolation of Function\n  Generated Data Abstract: In this article we consider the iterative schemes to compute the canonical\n(CP) approximation of quantized data generated by a function discretized on a\nlarge uniform grid in an interval on the real line. This paper continues the\nresearch on the QTT method [16] developed for the tensor train (TT)\napproximation of the quantized images of function related data. In the QTT\napproach the target vector of length $2^{L}$ is reshaped to a $L^{th}$ order\ntensor with two entries in each mode (Quantized representation) and then\napproximated by the QTT tenor including $2r^2 L$ parameters, where $r$ is the\nmaximal TT rank. In what follows, we consider the Alternating Least-Squares\n(ALS) iterative scheme to compute the rank-$r$ CP approximation of the\nquantized vectors, which requires only $2 r L\\ll 2^L$ parameters for storage.\nIn the earlier papers [17] such a representation was called Q$_{Can}$ format,\nwhile in this paper we abbreviate it as the QCP representation. We test the ALS\nalgorithm to calculate the QCP approximation on various functions, and in all\ncases we observed the exponential error decay in the QCP rank. The main idea\nfor recovering a discretized function in the rank-$r$ QCP format using the\nreduced number the functional samples, calculated only at $O(2rL)$ grid points,\nis presented. The special version of ALS scheme for solving the arising\nminimization problem is described. This approach can be viewed as the sparse\nQCP-interpolation method that allows to recover all $2r L$ representation\nparameters of the rank-$r$ QCP tensor. Numerical examples show the efficiency\nof the QCP-ALS type iteration and indicate the exponential convergence rate in\n$r$. \n\n"}
{"id": "1707.06010", "contents": "Title: The KLASH Proposal Abstract: We propose a search of galactic axions with mass about 0.2 microeV using a\nlarge volume resonant cavity, about 50 m^3, cooled down to 4 K and immersed in\na moderate axial magnetic field of about 0.6 T generated inside the\nsuperconducting magnet of the KLOE experiment located at the National\nLaboratory of Frascati of INFN. This experiment, called KLASH (KLoe magnet for\nAxion SearcH) in the following, has a potential sensitivity on the\naxion-to-photon coupling, g_agg, of about 6x10^-17 GeV-1, reaching the region\npredicted by KSVZ and DFSZ models of QCD axions. \n\n"}
{"id": "1707.08004", "contents": "Title: Cryogenic readout for multiple VUV4 Multi-Pixel Photon Counters in\n  liquid xenon Abstract: We present the performances and characterization of an array made of\nS13370-3050CN (VUV4 generation) Multi-Pixel Photon Counters manufactured by\nHamamatsu and equipped with a low power consumption preamplifier operating at\nliquid xenon temperature (~ 175 K). The electronics is designed for the readout\nof a matrix of maximum dimension of 8 x 8 individual photosensors and it is\nbased on a single operational amplifier. The detector prototype presented in\nthis paper utilizes the Analog Devices AD8011 current feedback operational\namplifier, but other models can be used depending on the application. A biasing\ncorrection circuit has been implemented for the gain equalization of\nphotosensors operating at different voltages. The results show single photon\ndetection capability making this device a promising choice for future\ngeneration of large scale dark matter detectors based on liquid xenon, such as\nDARWIN. \n\n"}
{"id": "1707.08345", "contents": "Title: Fully Finite Element Adaptive Algebraic Multigrid Method for Time-Space\n  Caputo-Riesz Fractional Diffusion Equations Abstract: The paper aims to establish a fully discrete finite element (FE) scheme and\nprovide cost-effective solutions for one-dimensional time-space Caputo-Riesz\nfractional diffusion equations on a bounded domain $\\Omega$. Firstly, we\nconstruct a fully discrete scheme of the linear FE method in both temporal and\nspatial directions, derive many characterizations on the coefficient matrix and\nnumerically verify that the fully FE approximation possesses the saturation\nerror order under $L^2(\\Omega)$ norm. Secondly, we theoretically prove the\nestimation $1+\\mathcal{O}(\\tau^\\alpha h^{-2\\beta})$ on the condition number of\nthe coefficient matrix, in which $\\tau$ and $h$ respectively denote time and\nspace step sizes. Finally, on the grounds of the estimation and fast Fourier\ntransform, we develop and analyze an adaptive algebraic multigrid (AMG) method\nwith low algorithmic complexity, reveal a reference formula to measure the\nstrength-of-connection tolerance which severely affect the robustness of AMG\nmethods in handling fractional diffusion equations, and illustrate the well\nrobustness and high efficiency of the proposed algorithm compared with the\nclassical AMG, conjugate gradient and Jacobi iterative methods. \n\n"}
{"id": "1707.08486", "contents": "Title: Unifying Framework for Accelerated Randomized Methods in Convex\n  Optimization Abstract: In this paper, we consider smooth convex optimization problems with simple\nconstraints and inexactness in the oracle information such as value, partial or\ndirectional derivatives of the objective function. We introduce a unifying\nframework, which allows to construct different types of accelerated randomized\nmethods for such problems and to prove convergence rate theorems for them. We\nfocus on accelerated random block-coordinate descent, accelerated random\ndirectional search, accelerated random derivative-free method and, using our\nframework, provide their versions for problems with inexact oracle information.\nOur contribution also includes accelerated random block-coordinate descent with\ninexact oracle and entropy proximal setup as well as derivative-free version of\nthis method. Moreover, we present an extension of our framework for strongly\nconvex optimization problems. We also discuss an extension for the case of\ninexact model of the objective function. \n\n"}
{"id": "1708.00673", "contents": "Title: Solving the multi-frequency electromagnetic inverse source problem by\n  the Fourier method Abstract: This work is concerned with an inverse problem of identifying the current\nsource distribution of the time-harmonic Maxwell's equations from\nmulti-frequency measurements. Motivated by the Fourier method for the scalar\nHelmholtz equation and the polarization vector decomposition, we propose a\nnovel method for determining the source function in the full vector Maxwell's\nsystem. Rigorous mathematical justifications of the method are given and\nnumerical examples are provided to demonstrate the feasibility and\neffectiveness of the method. \n\n"}
{"id": "1708.00819", "contents": "Title: Improved performance of the LHCb Outer Tracker in LHC Run 2 Abstract: The LHCb Outer Tracker is a gaseous detector covering an area of $5\\times 6\nm^2$ with 12 double layers of straw tubes. The performance of the detector is\npresented based on data of the LHC Run 2 running period from 2015 and 2016.\nOccupancies and operational experience for data collected in $p p$, pPb and\nPbPb collisions are described. An updated study of the ageing effects is\npresented showing no signs of gain deterioration or other radiation damage\neffects. In addition several improvements with respect to LHC Run 1 data taking\nare introduced. A novel real-time calibration of the time-alignment of the\ndetector and the alignment of the single monolayers composing detector modules\nare presented, improving the drift-time and position resolution of the detector\nby 20\\%. Finally, a potential use of the improved resolution for the timing of\ncharged tracks is described, showing the possibility to identify low-momentum\nhadrons with their time-of-flight. \n\n"}
{"id": "1708.01243", "contents": "Title: On discretely entropy conservative and entropy stable discontinuous\n  Galerkin methods Abstract: High order methods based on diagonal-norm summation by parts operators can be\nshown to satisfy a discrete conservation or dissipation of entropy for\nnonlinear systems of hyperbolic PDEs. These methods can also be interpreted as\nnodal discontinuous Galerkin methods with diagonal mass matrices. In this work,\nwe describe how use flux differencing, quadrature-based projections, and\nSBP-like operators to construct discretely entropy conservative schemes for DG\nmethods under more arbitrary choices of volume and surface quadrature rules.\nThe resulting methods are semi-discretely entropy conservative or entropy\nstable with respect to the volume quadrature rule used. Numerical experiments\nconfirm the stability and high order accuracy of the proposed methods for the\ncompressible Euler equations in one and two dimensions. \n\n"}
{"id": "1708.01966", "contents": "Title: High dimensional finite elements for multiscale Maxwell wave equations Abstract: We develop an essentially optimal numerical method for solving multiscale\nMaxwell wave equations in a domain $D\\subset{\\mathbb R}^d$. The problems depend\non $n+1$ scales: one macroscopic scale and $n$ microscopic scales. Solving the\nmacroscopic multiscale homogenized problem, we obtain the desired macroscopic\nand microscopic information. This problem depends on $n+1$ variables in\n${\\mathbb R}^d$, one for each scale that the original multiscale equation\ndepends on, and is thus posed in a high dimensional tensorized domain. The\nstraightforward full tensor product finite element (FE) method is exceedingly\nexpensive. We develop the sparse tensor product FEs that solve this multiscale\nhomogenized problem with essentially optimal number of degrees of freedom, that\nis essentially equal to that required for solving a macroscopic problem in a\ndomain in ${\\mathbb R}^d$ only, for obtaining a required level of accuracy.\nNumerical correctors are constructed from the FE solution. For two scale\nproblems, we derive a rate of convergence for the numerical corrector in terms\nof the microscopic scale and the FE mesh width. Numerical examples confirm our\nanalysis. \n\n"}
{"id": "1708.02207", "contents": "Title: Partial inversion of the elliptic operator to speed up computation of\n  likelihood in Bayesian inference Abstract: Often, when solving forward, inverse or data assimilation problems, only a\npart of the solution is needed. As a model, we consider the stationary\ndiffusion problem. We demonstrate an algorithm that can compute only a part or\na functional of the solution, without calculating the full inversion operator\nand the complete solution. It is a well-known fact about partial differential\nequations that the solution at each discretisation point depends on the\nsolutions at all other discretisation points. Therefore, it is impossible to\ncompute the solution only at one point, without calculating the solution at all\nother points. The standard numerical methods like a conjugate gradient or Gauss\nelimination compute the whole solution and/or the complete inverse operator. We\nsuggest a method which can compute the solution of the given partial\ndifferential equation 1) at a point; 2) at few points; 3) on an interface; or a\nfunctional of the solution, without computing the solution at all points. The\nrequired storage cost and computational resources will be lower as in the\nstandard approach.\n  With this new method, we can speed up, for instance, computation of the\ninnovation in filtering or the likelihood distribution, which measures the data\nmisfit (mismatch). Further, we can speed up the solution of the regression,\nBayesian inversion, data assimilation, and Kalman filter update problems.\n  Applying additionally the hierarchical matrix approximation, we reduce the\ncubic computational cost to almost linear $\\mathcal{O}(k^2n \\log^2 n)$, where\n$k\\ll n$ and $n$ is the number of degrees of freedom.\n  Up to the hierarchical matrix approximation error, the computed solution is\nexact. One of the disadvantages of this method is the need to modify the\nexisting deterministic solver. \n\n"}
{"id": "1708.03602", "contents": "Title: Discretizations of the spectral fractional Laplacian on general domains\n  with Dirichlet, Neumann, and Robin boundary conditions Abstract: In this work, we propose novel discretizations of the spectral fractional\nLaplacian on bounded domains based on the integral formulation of the operator\nvia the heat-semigroup formalism. Specifically, we combine suitable quadrature\nformulas of the integral with a finite element method for the approximation of\nthe solution of the corresponding heat equation. We derive two families of\ndiscretizations with order of convergence depending on the regularity of the\ndomain and the function on which the spectral fractional Laplacian is acting.\nOur method does not require the computation of the eigenpairs of the Laplacian\non the considered domain, can be implemented on possibly irregular bounded\ndomains, and can naturally handle different types of boundary constraints.\nVarious numerical simulations are provided to illustrate performance of the\nproposed method and support our theoretical results. \n\n"}
{"id": "1708.04087", "contents": "Title: Performance of Multiplexed XY Resistive Micromegas detectors in a high\n  intensity beam Abstract: We present the performance of multiplexed XY resistive Micromegas detectors\ntested in the CERN SPS 100 GeV/c electron beam at intensities up to 3.3\n$\\times$ 10$^5$ e$^- $/(s$\\cdot$cm$^2$). So far, all studies with multiplexed\nMicromegas have only been reported for tests with radioactive sources and\ncosmic rays. The use of multiplexed modules in high intensity environments was\nnot explored due to the effect of ambiguities in the reconstruction of the hit\npoint caused by the multiplexing feature. At the beam intensities analysed in\nthis work and with a multiplexing factor of 5, more than 50% level of ambiguity\nis introduced. Our results prove that by using the additional information of\ncluster size and integrated charge from the signal clusters induced on the XY\nstrips, the ambiguities can be reduced to a level below 2%. The tested\ndetectors are used in the CERN NA64 experiment for tracking the incoming\nparticles bending in a magnetic field in order to reconstruct their momentum.\nThe average hit detection efficiency of each module was found to be $\\sim$ 96%\nat the highest beam intensities. By using four modules a tracking resolution of\n1.1% was obtained with $\\sim$ 85% combined tracking efficiency. \n\n"}
{"id": "1708.04219", "contents": "Title: Renormalization Mass Scale and Scheme Dependence in the Perturbative\n  Contribution to Inclusive Semileptonic $b$ Decays Abstract: We examine the perturbative calculation of the inclusive semi-leptonic decay\nrate $\\Gamma$ for the $b$-quark, using mass-independent renormalization. To\nfinite order of perturbation theory the series for $\\Gamma$ will depend on the\nunphysical renormalization scale parameter $\\mu$ and on the particular choice\nof mass-independent renormalization scheme; these dependencies will only be\nremoved after summing the series to all orders. In this paper we show that all\nexplicit $\\mu$-dependence of $\\Gamma$, through powers of ln$(\\mu)$, can be\nsummed by using the renormalization group equation. We then find that this\nexplicit $\\mu$-dependence can be combined together with the implicit\n$\\mu$-dependence of $\\Gamma$ (through powers of both the running coupling\n$a(\\mu)$ and the running $b$-quark mass $m(\\mu)$) to yield a $\\mu$-independent\nperturbative expansion for $\\Gamma$ in terms of $a(\\mu)$ and $m(\\mu)$ both\nevaluated at a renormalization scheme independent mass scale $I\\!\\!M$ which is\nfixed in terms of either the \"$\\overline{MS}$ mass\" $\\overline{m}_b$ of the $b$\nquark or its pole mass $m_{pole}$. At finite order the resulting perturbative\nexpansion retains a degree of arbitrariness associated with the particular\nchoice of mass-independent renormalization scheme. We use the coefficients\n$c_i$ and $g_i$ of the perturbative expansions of the renormalization group\nfunctions $\\beta(a)$ and $\\gamma(a)$, associated with $a(\\mu)$ and $m(\\mu)$\nrespectively, to characterize the remaining renormalization scheme\narbitrariness of $\\Gamma$. We further show that all terms in the expansion of\n$\\Gamma$ can be written in terms of the $c_i$ and $g_i$ coefficients and a set\nof renormalization scheme independent parameters $\\tau_i$. \n\n"}
{"id": "1708.06594", "contents": "Title: Direct Detection of MeV-Scale Dark Matter Utilizing Germanium Internal\n  Amplification for the Charge Created by the Ionization of Impurities Abstract: Light, MeV-scale dark matter (DM) is an exciting DM candidate that is\nundetectable by current experiments. A germanium (Ge) detector utilizing\ninternal charge amplification for the charge carriers created by the ionization\nof impurities is a promising new technology with experimental sensitivity for\ndetecting MeV-scale DM. We analyze the physics mechanisms of the signal\nformation, charge creation, charge internal amplification, and the projected\nsensitivity for directly detecting MeV-scale DM particles. We present a design\nfor a novel Ge detector at helium temperature ($\\sim$4 K) enabling ionization\nof impurities from DM impacts. With large localized E-fields, the ionized\nexcitations can be accelerated to kinetic energies larger than the Ge bandgap\nat which point they can create additional electron-hole pairs, producing\nintrinsic amplification to achieve an ultra-low energy threshold of $\\sim$0.1\neV for detecting low-mass DM particles in the MeV scale. Correspondingly, such\na Ge detector with 1 kg-year exposure will have high sensitivity to a\nDM-nucleon cross section of $\\sim$5$\\times$10$^{-45}$ cm$^{2}$ at a DM mass of\n$\\sim$10 MeV/c$^{2}$ and a DM-electron cross section of\n$\\sim$5$\\times$10$^{-46}$cm$^{2}$ at a DM mass of $\\sim$1 MeV/c$^2$. \n\n"}
{"id": "1709.00479", "contents": "Title: A Trace Finite Element Method for Vector-Laplacians on Surfaces Abstract: We consider a vector-Laplace problem posed on a 2D surface embedded in a 3D\ndomain, which results from the modeling of surface fluids based on exterior\nCartesian differential operators. The main topic of this paper is the\ndevelopment and analysis of a finite element method for the discretization of\nthis surface partial differential equation. We apply the trace finite element\ntechnique, in which finite element spaces on a background shape-regular\ntetrahedral mesh that is surface-independent are used for discretization. In\norder to satisfy the constraint that the solution vector field is tangential to\nthe surface we introduce a Lagrange multiplier. We show well-posedness of the\nresulting saddle point formulation. A discrete variant of this formulation is\nintroduced which contains suitable stabilization terms and is based on trace\nfinite element spaces. For this method we derive optimal discretization error\nbounds. Furthermore algebraic properties of the resulting discrete saddle point\nproblem are studied. In particular an optimal Schur complement preconditioner\nis proposed. Results of a numerical experiment are included. \n\n"}
{"id": "1709.01380", "contents": "Title: Forward $J/\\psi$ and very backward jet inclusive production at the LHC Abstract: In the spirit of Mueller-Navelet dijet production, we propose and study the\ninclusive production of a forward $J/\\psi$ and a very backward jet at the LHC\nas an observable to reveal high-energy resummation effects \\`a la BFKL. We\nobtain several predictions, which are based on the various mechanisms discussed\nin the literature to describe the production of the $J/\\psi$, namely, NRQCD\nsinglet and octet contributions, and the color evaporation model. \n\n"}
{"id": "1709.01781", "contents": "Title: Parameterizations for Ensemble Kalman Inversion Abstract: The use of ensemble methods to solve inverse problems is attractive because\nit is a derivative-free methodology which is also well-adapted to\nparallelization. In its basic iterative form the method produces an ensemble of\nsolutions which lie in the linear span of the initial ensemble. Choice of the\nparameterization of the unknown field is thus a key component of the success of\nthe method. We demonstrate how both geometric ideas and hierarchical ideas can\nbe used to design effective parameterizations for a number of applied inverse\nproblems arising in electrical impedance tomography, groundwater flow and\nsource inversion. In particular we show how geometric ideas, including the\nlevel set method, can be used to reconstruct piecewise continuous fields, and\nwe show how hierarchical methods can be used to learn key parameters in\ncontinuous fields, such as length-scales, resulting in improved\nreconstructions. Geometric and hierarchical ideas are combined in the level set\nmethod to find piecewise constant reconstructions with interfaces of unknown\ntopology. \n\n"}
{"id": "1709.04208", "contents": "Title: Approximation of a Brittle Fracture Energy with a Constraint of\n  Non-Interpenetration Abstract: Linear fracture mechanics (or at least the initiation part of that theory)\ncan be framed in a variational context as a minimization problem over a SBD\ntype space. The corresponding functional can in turn be approximated in the\nsense of $\\Gamma$-convergence by a sequence of functionals involving a phase\nfield as well as the displacement field. We show that a similar approximation\npersists if additionally imposing a non-interpenetration constraint in the\nminimization, namely that only nonnegative normal jumps should be permissible.\n2010 Mathematics subject classification: 26A45 \n\n"}
{"id": "1709.04768", "contents": "Title: Renormalization Group theory outperforms other approaches in statistical\n  comparison between upscaling techniques for porous media Abstract: Determining the pressure differential required to achieve a desired flow rate\nin a porous medium requires solving Darcy's law, a Laplace-like equation, with\na spatially varying tensor permeability. In various scenarios, the permeability\ncoefficient is sampled at high spatial resolution, which makes solving Darcy's\nequation numerically prohibitively expensive. As a consequence, much effort has\ngone into creating upscaled or low-resolution effective models of the\ncoefficient while ensuring that the estimated flow rate is well reproduced,\nbringing to fore the classic tradeoff between computational cost and numerical\naccuracy. Here we perform a statistical study to characterize the relative\nsuccess of upscaling methods on a large sample of permeability coefficients\nthat are above the percolation threshold. We introduce a new technique based on\nMode-Elimination Renormalization-Group theory (MG) to build coarse-scale\npermeability coefficients. Comparing the results with coefficients upscaled\nusing other methods, we find that MG is consistently more accurate,\nparticularly so due to its ability to address the tensorial nature of the\ncoefficients. MG places a low computational demand, in the manner that we have\nimplemented it, and accurate flow-rate estimates are obtained when using\nMG-upscaled permeabilities that approach or are beyond the percolation\nthreshold. \n\n"}
{"id": "1709.06082", "contents": "Title: Efficient Legendre polynomials transforms: from recurrence relations to\n  Schoenberg's theorem Abstract: We report results on various techniques which allow to compute the expansion\ninto Legendre (or in general Gegenbauer) polynomials in an efficient way. We\ndescribe in some detail the algebraic/symbolic approach already presented in\nRef.1 and expand on an alternative approach based on a theorem of Schoenberg. \n\n"}
{"id": "1709.07711", "contents": "Title: Calculation of the Decay Rate of Tachyonic Neutrinos against\n  Charged-Lepton-Pair and Neutrino-Pair Cerenkov Radiation Abstract: We consider in detail the calculation of the decay rate of high-energy\nsuperluminal neutrinos against (charged) lepton pair Cerenkov radiation (LPCR),\nand neutrino pair Cerenkov radiation (NPCR), i.e., against the decay channels\nnu -> nu e+ e- and nu -> nu nubar nu. Under the hypothesis of a tachyonic\nnature of neutrinos, these decay channels put constraints on the lifetime of\nhigh-energy neutrinos for terrestrial experiments as well as on cosmic scales.\nFor the oncoming neutrino, we use the Lorentz-covariant tachyonic relation E_nu\n= (p^2 - m_nu^2)^(1/2), where m_nu is the tachyonic mass parameter. We derive\nboth threshold conditions as well as decay and energy loss rates, using the\nplane-wave fundamental bispinor solutions of the tachyonic Dirac equation.\nVarious intricacies of rest frame versus lab frame calculations are\nhighlighted. The results are compared to the observations of high-energy\nIceCube neutrinos of cosmological origin. \n\n"}
{"id": "1709.08217", "contents": "Title: Estimates of W-exchange contributions to $\\Xi_{cc}$ decays Abstract: Encouraged by recent discovery of $\\Xi_{cc}^{++}$ baryon, we investigate two\nbody non-leptonic weak decays of doubly charmed, $\\Xi_{cc}$, baryons. We\ncalculate the branching ratios for CKM-favored and suppressed modes in\nfactorization and pole model approach. We give the first estimates of\nnonfactorizable W-exchange contributions using pole model. We find that\nW-exchange contributions to $\\Xi_{cc}$ decays being sizable can not be ignored. \n\n"}
{"id": "1710.00125", "contents": "Title: Randomized Complete Pivoting for Solving Symmetric Indefinite Linear\n  Systems Abstract: The Bunch-Kaufman algorithm and Aasen's algorithm are two of the most widely\nused methods for solving symmetric indefinite linear systems, yet they both are\nknown to suffer from occasional numerical instability due to potentially\nexponential element growth or unbounded entries in the matrix factorization. In\nthis work, we develop a randomized complete pivoting (RCP) algorithm for\nsolving symmetric indefinite linear systems. RCP is comparable to the\nBunch-Kaufman algorithm and Aasen's algorithm in computational efficiency, yet\nenjoys theoretical element growth and bounded entries in the factorization\ncomparable to that of complete-pivoting, up to a theoretical failure\nprobability that exponentially decays with an oversampling parameter. Our\nfinite precision analysis shows that RCP is as numerically stable as Gaussian\nelimination with complete pivoting, and RCP has been observed to be numerically\nstable in our extensive numerical experiments. \n\n"}
{"id": "1710.00898", "contents": "Title: Automated proton track identification in MicroBooNE using gradient\n  boosted decision trees Abstract: MicroBooNE is a liquid argon time projection chamber (LArTPC) neutrino\nexperiment that is currently running in the Booster Neutrino Beam at Fermilab.\nLArTPC technology allows for high-resolution, three-dimensional representations\nof neutrino interactions. A wide variety of software tools for automated\nreconstruction and selection of particle tracks in LArTPCs are actively being\ndeveloped. Short, isolated proton tracks, the signal for low- momentum-transfer\nneutral current (NC) elastic events, are easily hidden in a large cosmic\nbackground. Detecting these low-energy tracks will allow us to probe\ninteresting regions of the proton's spin structure. An effective method for\nselecting NC elastic events is to combine a highly efficient track\nreconstruction algorithm to find all candidate tracks with highly accurate\nparticle identification using a machine learning algorithm. We present our work\non particle track classification using gradient tree boosting software\n(XGBoost) and the performance on simulated neutrino data. \n\n"}
{"id": "1710.01386", "contents": "Title: Strong Convergence of the Linear Implicit Euler Method for the Finite\n  Element Discretization of Semilinear SPDEs Driven by Multiplicative and\n  Additive Noise Abstract: This paper aims to investigate the numerical approximation of a general\nsecond order parabolic stochastic partial differential equation(SPDE) driven by\nmultiplicative and additive noise under more relaxed conditions. The SPDE is\ndiscretized in space by the finite element method and in time by the linear\nimplicit Euler method. This extends the current results in the literature to\nnot necessary self-adjoint operator with more general boundary conditions. As a\nconsequence key part of the proof does not rely on the spectral decomposition\nof the linear operator. We achieve optimal convergence orders which depend on\nthe regularity of the noise and the initial data. In particular, for\nmultiplicative noise we achieve optimal order $\\mathcal{O}(h^2+\\Delta t^{1/2})$\nand for additive noise, we achieve optimal order $\\mathcal{O}(h^2+\\Delta t)$.\nIn contrast to current work in the literature, where the optimal convergence\norders are achieved for additive noise by incorporating further regularity\nassumptions on the nonlinear drift function, our optimal convergence orders are\nobtained under only the standard Lipschitz condition of the nonlinear drift\nterm. Numerical experiments to sustain our theoretical results are provided. \n\n"}
{"id": "1710.02242", "contents": "Title: Solving differential equations with unknown constitutive relations as\n  recurrent neural networks Abstract: We solve a system of ordinary differential equations with an unknown\nfunctional form of a sink (reaction rate) term. We assume that the measurements\n(time series) of state variables are partially available, and we use recurrent\nneural network to \"learn\" the reaction rate from this data. This is achieved by\nincluding a discretized ordinary differential equations as part of a recurrent\nneural network training problem. We extend TensorFlow's recurrent neural\nnetwork architecture to create a simple but scalable and effective solver for\nthe unknown functions, and apply it to a fedbatch bioreactor simulation\nproblem. Use of techniques from recent deep learning literature enables\ntraining of functions with behavior manifesting over thousands of time steps.\nOur networks are structurally similar to recurrent neural networks, but\ndifferences in design and function require modifications to the conventional\nwisdom about training such networks. \n\n"}
{"id": "1710.02307", "contents": "Title: A hybrid approach to solve the high-frequency Helmholtz equation with\n  source singularity in smooth heterogeneous media Abstract: We propose a hybrid approach to solve the high-frequency Helmholtz equation\nwith point source terms in smooth heterogeneous media. The method is based on\nthe ray-based finite element method (ray-FEM), whose original version can not\nhandle the singularity close to point sources accurately. This pitfall is\naddressed by combining the ray-FEM, which is used to compute the smooth\nfar-field of the solution accurately, with a high-order asymptotic expansion\nclose to the point source, which is used to properly capture the singularity of\nthe solution in the near-field. The method requires a fixed number of grid\npoints per wavelength to accurately represent the wave field with an asymptotic\nconvergence rate of $\\mathcal{O}(\\omega^{-1/2})$, where $\\omega$ is the\nfrequency parameter in the Helmholtz equation. In addition, a fast\nsweeping-type preconditioner is used to solve the resulting linear system.\n  We present numerical examples in 2D to show both accuracy and efficiency of\nour method as the frequency increases. In particular, we provide numerical\nevidence of the convergence rate, and we show empirically that the overall\ncomplexity is $\\mathcal{O}(\\omega^2)$ up to a poly-logarithmic factor. \n\n"}
{"id": "1710.02500", "contents": "Title: Computing Evans functions numerically via boundary-value problems Abstract: The Evans function has been used extensively to study spectral stability of\ntravelling-wave solutions in spatially extended partial differential equations.\nTo compute Evans functions numerically, several shooting methods have been\ndeveloped. In this paper, an alternative scheme for the numerical computation\nof Evans functions is presented that relies on an appropriate boundary-value\nproblem formulation. Convergence of the algorithm is proved, and several\nexamples, including the computation of eigenvalues for a multi-dimensional\nproblem, are given. The main advantage of the scheme proposed here compared\nwith earlier methods is that the scheme is linear and scalable to large\nproblems. \n\n"}
{"id": "1710.02752", "contents": "Title: Position Reconstruction in LUX Abstract: The $(x, y)$ position reconstruction method used in the analysis of the\ncomplete exposure of the Large Underground Xenon (LUX) experiment is presented.\nThe algorithm is based on a statistical test that makes use of an iterative\nmethod to recover the photomultiplier tube (PMT) light response directly from\nthe calibration data. The light response functions make use of a two\ndimensional functional form to account for the photons reflected on the inner\nwalls of the detector. To increase the resolution for small pulses, a photon\ncounting technique was employed to describe the response of the PMTs. The\nreconstruction was assessed with calibration data including\n${}^{\\mathrm{83m}}$Kr (releasing a total energy of 41.5 keV) and ${}^{3}$H\n($\\beta^-$ with Q = 18.6 keV) decays, and a deuterium-deuterium (D-D) neutron\nbeam (2.45 MeV). In the horizontal plane, the reconstruction has achieved an\n$(x, y)$ position uncertainty of $\\sigma$= 0.82 cm for events of only 200\nelectroluminescence photons and $\\sigma$ = 0.17 cm for 4,000\nelectroluminescence photons. Such signals are associated with electron recoils\nof energies $\\sim$0.25 keV and $\\sim$10 keV, respectively. The reconstructed\nposition of the smallest events with a single electron emitted from the liquid\nsurface has a horizontal $(x, y)$ uncertainty of 2.13 cm. \n\n"}
{"id": "1710.03622", "contents": "Title: Prototype tests for a highly granular scintillator-based hadronic\n  calorimeter Abstract: Within the CALICE collaboration, several concepts for the hadronic\ncalorimeter of a future lepton collider detector are studied. After having\ndemonstrated the capabilities of the measurement methods in \"physics\nprototypes\", the focus now lies on improving their implementation in\n\"technological prototypes\", that are scalable to the full linear collider\ndetector. The Analogue Hadronic Calorimeter (AHCAL) concept is a sampling\ncalorimeter of tungsten or steel absorber plates and plastic scintillator tiles\nread out by silicon photomultipliers (SiPMs) as active components. The\nfront-end electronics is fully integrated into the active layers of the\ncalorimeter and is designed for minimal power consumption (i.e. power pulsing).\nThe versatile electronics enables the prototype to be equipped with different\ntypes of scintillator tiles and SiPMs. In recent beam tests, a prototype with\n$\\sim$3700 channels, equipped with several types of scintillator tiles and\nSiPMs, was exposed to electron, muon and hadron beams. The experience of these\nbeam tests resulted in an optimal detector design with surface-mounted SiPMs\nsuitable for the automated mass assembly. The proceeding will cover topics\nincluding the testbeam measurements with the AHCAL technological prototype, the\nimproved detector design and the ongoing development of a large prototype for\nhadronic showers. \n\n"}
{"id": "1710.03772", "contents": "Title: Event Reconstruction in the NOvA Experiment Abstract: The NOvA experiment observes oscillations in two channels (electron-neutrino\nappearance and muon-neutrino disappearance) using a predominantly muon-neutrino\nNuMI beam. The Near Detector records multiple overlapping neutrino interactions\nin each event and the Far Detector has a large background of cosmic rays due to\nbeing located on the surface. The oscillation analyses rely on the accurate\nreconstruction of neutrino interactions in order to precisely measure the\nneutrino energy and identify the neutrino flavor and interaction mode.\nSimilarly, measurements of neutrino cross sections using the Near Detector\nrequire accurate identification of the particle content of each interaction. A\nseries of pattern recognition techniques have been developed to split event\nrecords into individual spatially and temporally separated interactions, to\nestimate the interaction vertex, and to isolate and classify individual\nparticles within the event. This combination of methods to achieve full event\nreconstruction in the NOvA detectors has discussed. \n\n"}
{"id": "1710.04315", "contents": "Title: Novel event classification based on spectral analysis of scintillation\n  waveforms in Double Chooz Abstract: Liquid scintillators are a common choice for neutrino physics experiments,\nbut their capabilities to perform background rejection by scintillation pulse\nshape discrimination is generally limited in large detectors. This paper\ndescribes a novel approach for a pulse shape based event classification\ndeveloped in the context of the Double Chooz reactor antineutrino experiment.\nUnlike previous implementations, this method uses the Fourier power spectra of\nthe scintillation pulse shapes to obtain event-wise information. A\nclassification variable built from spectral information was able to achieve an\nunprecedented performance, despite the lack of optimization at the detector\ndesign level. Several examples of event classification are provided, ranging\nfrom differentiation between the detector volumes and an efficient rejection of\ninstrumental light noise, to some sensitivity to the particle type, such as\nstopping muons, ortho-positronium formation, alpha particles as well as\nelectrons and positrons. In combination with other techniques the method is\nexpected to allow for a versatile and more efficient background rejection in\nthe future, especially if detector optimization is taken into account at the\ndesign level. \n\n"}
{"id": "1710.04536", "contents": "Title: Study of a spherical Xenon gas TPC for neutrinoless double beta\n  detection Abstract: Several efforts are ongoing for the development of spherical gaseous time\nprojection chamber detectors for the observation of rare phenomena such as\nweakly interacting massive particles or neutrino interactions. The proposed\ndetector, thanks to its simplicity, low energy threshold and energy resolution,\ncould be used to observe the $\\beta\\beta0\\nu$ process i.e. the neutrinoless\ndouble beta decay. In this work, a specific setup is presented for the\nmeasurement of $\\beta\\beta0\\nu$ on 50~kg of $^{136}$Xe. The different\nbackgrounds are studied, demonstrating the possibility to reach a total\nbackground per year in the detector mass at the level of 2 events per year. The\nobtained results are competitive with the present generation of experiments and\ncould represent the first step of a more ambitious roadmap including the\n$\\beta\\beta0\\nu$ search with different gases with the same detector and\ntherefore the same background sources. The constraints in terms of detector\nconstructions and material purity are also addressed, showing that none of them\nrepresents a show stopper for the proposed experimental setup. \n\n"}
{"id": "1710.05600", "contents": "Title: Helium-Xenon mixtures to improve topological signature in high pressure\n  gas Xenon TPCs Abstract: Within the framework of xenon-based double beta decay experiments, we propose\nthe possibility to improve the background rejection of an electroluminescent\nTime Projection Chamber (EL TPC) by reducing the diffusion of the drifting\nelectrons while keeping nearly intact the energy resolution of a pure xenon EL\nTPC. Based on state-of-the-art microscopic simulations, a substantial addition\nof helium, around 10 or 15~\\%, may reduce drastically the transverse diffusion\ndown to 2.5~mm/$\\sqrt{\\mathrm{m}}$ from the 10.5~mm/$\\sqrt{\\mathrm{m}}$ of pure\nxenon. The longitudinal diffusion remains around 4~mm/$\\sqrt{\\mathrm{m}}$.\nLight production studies have been performed as well. They show that the\nrelative variation in energy resolution introduced by such a change does not\nexceed a few percent, which leaves the energy resolution practically unchanged.\nThe technical caveats of using photomultipliers close to an helium atmosphere\nare also discussed in detail. \n\n"}
{"id": "1710.09309", "contents": "Title: Evolution and Recent Developments of the Gaseous Photon Detectors\n  Technologies Abstract: The evolution and the present status of the gaseous photon detectors\ntechnologies are reviewed. The most recent developments in several branches of\nthe field are described, in particular the installation and commissioning of\nthe first large area MPGD-based detectors of single photons on COMPASS RICH-1.\nInvestigation of novel detector architectures, different materials and various\napplications are reported, and the quest for visible light gaseous photon\ndetectors is discussed. The progress on the use of gaseous photon detector\nrelated techniques in the field of cryogenic applications and gaseous or liquid\nscintillation imaging are presented. \n\n"}
{"id": "1710.10846", "contents": "Title: A Quadratic-Time Algorithm for General Multivariate Polynomial\n  Interpolation Abstract: For $m,n \\in \\mathbb{N}$, $m\\geq 1$ and a given function $f :\n\\mathbb{R}^m\\longrightarrow \\mathbb{R}$ the polynomial interpolation problem\n(PIP) is to determine a \\emph{generic node set} $P \\subseteq \\mathbb{R}^m$ and\nthe coefficients of the uniquely defined polynomial\n$Q\\in\\mathbb{R}[x_1,\\dots,x_m]$ in $m$ variables of degree $\\mathrm{deg}(Q)\\leq\nn \\in \\mathbb{N}$ that fits $f$ on $P$, i.e., $Q(p) = f(p)$, $\\forall\\, p \\in\nP$. We here show that in general, i.e., for arbitrary $m,n \\in \\mathbb{N}$, $m\n\\geq 1$, there exists an algorithm that determines $P$ and computes the\n$N(\\mbox{m,n})=\\#P$ coefficients of $Q$ in\n$\\mathcal{O}\\big(N(\\mbox{m,n})^2\\big)$ time using\n$\\mathcal{O}\\big(\\mbox{m}N(\\mbox{m,n})\\big)$ storage, without inverting the\noccurring Vandermonde matrix. We provide such an algorithm, termed PIP-SOLVER,\nbased on a recursive decomposition of the problem and prove its correctness.\nSince the present approach solves the PIP without matrix inversion, it is\ncomputationally more efficient and numerically more robust than previous\napproaches. We demonstrate this in numerical experiments and compare with\nprevious approaches based on matrix inversion and linear systems solving. \n\n"}
{"id": "1711.00954", "contents": "Title: Efficient construction of tensor ring representations from sampling Abstract: In this paper we propose an efficient method to compress a high dimensional\nfunction into a tensor ring format, based on alternating least-squares (ALS).\nSince the function has size exponential in $d$ where $d$ is the number of\ndimensions, we propose efficient sampling scheme to obtain $O(d)$ important\nsamples in order to learn the tensor ring. Furthermore, we devise an\ninitialization method for ALS that allows fast convergence in practice.\nNumerical examples show that to approximate a function with similar accuracy,\nthe tensor ring format provided by the proposed method has less parameters than\ntensor-train format and also better respects the structure of the original\nfunction. \n\n"}
{"id": "1711.00984", "contents": "Title: Fast integration of DPG matrices based on tensorization Abstract: Numerical integration of the stiffness matrix in higher order finite element\n(FE) methods is recognized as one of the heaviest computational tasks in a FE\nsolver. The problem becomes even more relevant when computing the Gram matrix\nin the algorithm of the Discontinuous Petrov Galerkin (DPG) FE methodology.\nMaking use of 3D tensor-product shape functions, and the concept of sum\nfactorization, known from standard high order FE and spectral methods, here we\ntake advantage of this idea for the entire exact sequence of FE spaces defined\non the hexahedron. The key piece to the presented algorithms is the exact\nsequence for the one-dimensional element, and use of hierarchical shape\nfunctions. Consistent with existing results, the presented algorithms for the\nintegration of $H^1$, $H(\\text{curl})$, $H(\\text{div})$, and $L^2$ inner\nproducts, have the $O(p^7)$ computational complexity. Additionally, a modified\nversion of the algorithms is proposed when the element map can be simplified,\nresulting in the reduced $O(p^6)$ complexity. Use of Legendre polynomials for\nshape functions is critical in this implementation. Computational experiments\nperformed with $H^1$, $H(\\text{div})$ and $H(\\text{curl})$ test shape functions\nshow good correspondence with the expected rates. \n\n"}
{"id": "1711.01075", "contents": "Title: Low background techniques in bolometers for double-beta decay search Abstract: Bolometers are low temperature particle detectors with high energy resolution\nand detection efficiency. Some types of bolometric detectors are also able to\nperform an efficient particle identification. A wide variety of radiopure\ndielectric and diamagnetic materials makes the bolometric technique favorable\nfor applications in astroparticle physics. In particular, thanks to their\nsuperior performance, bolometers play an important role in the world-wide\nefforts on searches for neutrinoless double-beta decay. Such experiments\nstrongly require an extremely low level of the backgrounds that can easily\nmimic the process searched for. Here we overview recent progress in the\ndevelopment of low background techniques for bolometric double-beta decay\nsearches. \n\n"}
{"id": "1711.01230", "contents": "Title: A Model for the Global Quantum Efficiency for a TPB-based\n  Wavelength-Shifting System used with Photomultiplier Tubes in Liquid Argon in\n  MicroBooNE Abstract: We present a model for the Global Quantum Efficiency (GQE) of the MicroBooNE\noptical units. An optical unit consists of a flat, circular acrylic plate,\ncoated with tetraphenyl butadiene (TPB), positioned near the photocathode of a\n20.2-cm diameter photomultiplier tube. The plate converts the ultra-violet\nscintillation photons from liquid argon into visible-spectrum photons to which\nthe cryogenic phototubes are sensitive. The GQE is the convolution of the\nefficiency of the plates that convert the 128 nm scintillation light from\nliquid argon to visible light, the efficiency of the shifted light to reach the\nphotocathode, and the efficiency of the cryogenic photomultiplier tube. We\ndevelop a GEANT4-based model of the optical unit, based on first principles,\nand obtain the range of probable values for the expected number of detected\nphotoelectrons ($N_{\\rm PE}$) given the known systematic errors on the\nsimulation parameters. We compare results from four measurements of the $N_{\\rm\nPE}$ determined using alpha-particle sources placed at two distances from a\nTPB-coated plate in a liquid argon cryostat test stand. We also directly\nmeasured the radial dependence of the quantum efficiency, and find that this\nhas the same shape as predicted by our model. Our model results in a GQE of\n$0.0055\\pm0.0009$ for the MicroBooNE optical units. While the information shown\nhere is MicroBooNE specific, the approach to the model and the collection of\nsimulation parameters will be widely applicable to many liquid-argon-based\nlight collection systems. \n\n"}
{"id": "1711.01818", "contents": "Title: Dual Virtual Element Methods for Discrete Fracture Matrix Models Abstract: The accurate description of fluid flow and transport in fractured porous\nmedia is of paramount importance to capture the macroscopic behaviour of an oil\nreservoir, a geothermal system, or a CO2 sequestration site, to name few\napplications. The construction of accurate simulation model for flow in\nfractures is challenging due to the high ratios between a fracture's length and\nwidth, which makes modeling by lower-dimensional manifolds a natural option. In\nthis paper we present a mixed-dimensional Darcy problem able to describe\npressure and Darcy velocity in all the dimensions, i.e. in the rock matrix, in\nthe fractures, and in their intersections. Moreover, we present a\nmixed-dimensional transport problem which, given the Darcy velocity, describes\ncoupled advection and diffusion of a passive scalar into the fractured porous\nmedia. The approach can handle both conducting and blocking fractures. Our\ncomputational grids are created by coarsening of simplex tessellations that\nconform to the fractures surfaces. An accurate choice of the discrete\napproximation of the previous model, by virtual finite element and finite\nvolume, allows us to simulate complex problem with a good balance in term of\naccuracy and computational cost. We illustrate the performance of our method by\ncomparing to benchmark studies for two-dimensional fractured porous media, as\nwell as a complex three-dimensional fracture geometry. \n\n"}
{"id": "1711.03180", "contents": "Title: Deep D-bar: Real time Electrical Impedance Tomography Imaging with Deep\n  Neural Networks Abstract: The mathematical problem for Electrical Impedance Tomography (EIT) is a\nhighly nonlinear ill-posed inverse problem requiring carefully designed\nreconstruction procedures to ensure reliable image generation. D-bar methods\nare based on a rigorous mathematical analysis and provide robust direct\nreconstructions by using a low-pass filtering of the associated nonlinear\nFourier data. Similarly to low-pass filtering of linear Fourier data, only\nusing low frequencies in the image recovery process results in blurred images\nlacking sharp features such as clear organ boundaries. Convolutional Neural\nNetworks provide a powerful framework for post-processing such convolved direct\nreconstructions. In this study, we demonstrate that these CNN techniques lead\nto sharp and reliable reconstructions even for the highly nonlinear inverse\nproblem of EIT. The network is trained on data sets of simulated examples and\nthen applied to experimental data without the need to perform an additional\ntransfer training. Results for absolute EIT images are presented using\nexperimental EIT data from the ACT4 and KIT4 EIT systems. \n\n"}
{"id": "1711.03825", "contents": "Title: Deep Multigrid: learning prolongation and restriction matrices Abstract: This paper proposes the method to optimize restriction and prolongation\noperators in the two-grid method. The proposed method is straightforwardly\nextended to the geometric multigrid method (GMM). GMM is used in solving\ndiscretized partial differential equation (PDE) and based on the restriction\nand prolongation operators. The operators are crucial for fast convergence of\nGMM, but they are unknown. To find them we propose a reformulation of the\ntwo-grid method in terms of a deep neural network with a specific architecture.\nThis architecture is based on the idea that every operation in the two-grid\nmethod can be considered as a layer of a deep neural network. The parameters of\nlayers correspond to the restriction and prolongation operators. Therefore, we\nstate an optimization problem with respect to these operators and get optimal\nones through backpropagation approach. To illustrate the performance of the\nproposed approach, we carry out experiments on the discretized Laplace\nequation, Helmholtz equation and singularly perturbed convection-diffusion\nequation and demonstrate that proposed approach gives operators, which lead to\nfaster convergence. \n\n"}
{"id": "1711.04909", "contents": "Title: An Optimal Convergence Rate for the Gaussian Regularized Shannon\n  Sampling Series Abstract: We consider the reconstruction of a bandlimited function from its finite\nlocalized sample data. Truncating the classical Shannon sampling series results\nin an unsatisfactory convergence rate due to the slow decay of the sinc\nfunction. To overcome this drawback, a simple and highly effective method,\ncalled the Gaussian regularization of the Shannon series, was proposed in the\nengineering and has received remarkable attention. It works by multiplying the\nsinc function in the Shannon series with a regularized Gaussian function.\nRecently, it was proved that the upper error bound of this method can achieve a\nconvergence rate of the order\n$O(\\frac{1}{\\sqrt{n}}\\exp(-\\frac{\\pi-\\delta}{2}n))$, where $0<\\delta<\\pi$ is\nthe bandwidth and $n$ the number of sample data. The convergence rate is by far\nthe best convergence rate among all regularized methods for the Shannon\nsampling series. The main objective of this article is to present the\ntheoretical justification and numerical verification that the convergence rate\nis optimal when $0<\\delta<\\pi/2$ by estimating the lower error bound of the\ntruncated Gaussian regularized Shannon sampling series. \n\n"}
{"id": "1711.05056", "contents": "Title: Finite difference schemes for the tempered fractional Laplacian Abstract: The second and all higher order moments of the $\\beta$-stable L\\'{e}vy\nprocess diverge, the feature of which is sometimes referred to as shortcoming\nof the model when applied to physical processes. So, a parameter $\\lambda$ is\nintroduced to exponentially temper the L\\'{e}vy process. The generator of the\nnew process is tempered fractional Laplacian $(\\Delta+\\lambda)^{\\beta/2}$ [W.H.\nDeng, B.Y. Li, W.Y. Tian, and P.W. Zhang, Multiscale Model. Simul., in press,\n2017]. In this paper, we first design the finite difference schemes for the\ntempered fractional Laplacian equation with the generalized Dirichlet type\nboundary condition, their accuracy depending on the regularity of the exact\nsolution on $\\bar{\\Omega}$. Then the techniques of effectively solving the\nresulting algebraic equation are presented, and the performances of the schemes\nare demonstrated by several numerical examples. \n\n"}
{"id": "1711.06269", "contents": "Title: Ideal GLM-MHD: About the entropy consistent nine-wave magnetic field\n  divergence diminishing ideal magnetohydrodynamics equations Abstract: The paper presents two contributions in the context of the numerical\nsimulation of magnetized fluid dynamics. First, we show how to extend the ideal\nmagnetohydrodynamics (MHD) equations with an inbuilt magnetic field divergence\ncleaning mechanism in such a way that the resulting model is consistent with\nthe second law of thermodynamics. As a byproduct of these derivations, we show\nthat not all of the commonly used divergence cleaning extensions of the ideal\nMHD equations are thermodynamically consistent. Secondly, we present a\nnumerical scheme obtained by constructing a specific finite volume\ndiscretization that is consistent with the discrete thermodynamic entropy. It\nincludes a mechanism to control the discrete divergence error of the magnetic\nfield by construction and is Galilean invariant. We implement the new\nhigh-order MHD solver in the adaptive mesh refinement code FLASH where we\ncompare the divergence cleaning efficiency to the constrained transport solver\navailable in FLASH (unsplit staggered mesh scheme). \n\n"}
{"id": "1711.10253", "contents": "Title: Skew-symmetric Nitsche's formulation in isogeometric analysis: Dirichlet\n  and symmetry conditions, patch coupling and frictionless contact Abstract: A simple skew-symmetric Nitsche's formulation is introduced into the\nframework of isogeometric analysis (IGA) to deal with various problems in small\nstrain elasticity: essential boundary conditions, symmetry conditions for\nKirchhoff plates, patch coupling in statics and in modal analysis as well as\nSignorini contact conditions. For linear boundary or interface conditions, the\nskew-symmetric formulation is parameter-free. For contact conditions, it\nremains stable and accurate for a wide range of the stabilization parameter.\nSeveral numerical tests are performed to illustrate its accuracy, stability and\nconvergence performance. We investigate particularly the effects introduced by\nNitsche's coupling, including the convergence performance and condition numbers\nin statics as well as the extra \"outlier\" frequencies and corresponding\neigenmodes in structural dynamics. We present the Hertz test, the block test,\nand a 3D self-contact example showing that the skew-symmetric Nitsche's\nformulation is a suitable approach to simulate contact problems in IGA. \n\n"}
{"id": "1711.10426", "contents": "Title: A fully-discrete scheme for systems of nonlinear\n  Fokker-Planck-Kolmogorov equations Abstract: We consider a system of Fokker-Planck-Kolmogorov (FPK) equations, where the\ndependence of the coefficients is nonlinear and nonlocal in time with respect\nto the unknowns. We extend the numerical scheme proposed and studied recently\nby the authors for a single FPK equation of this type. We analyse the\nconvergence of the scheme and we study its applicability in two examples. The\nfirst one concerns a population model involving two interacting species and the\nsecond one concerns two populations Mean Field Games. \n\n"}
{"id": "1712.04028", "contents": "Title: Displacement interpolation using monotone rearrangement Abstract: When approximating a function that depends on a parameter, one encounters\nmany practical examples where linear interpolation or linear approximation with\nrespect to the parameters prove ineffective. This is particularly true for\nresponses from hyperbolic partial differential equations (PDEs) where linear,\nlow-dimensional bases are difficult to construct. We propose the use of\ndisplacement interpolation where the interpolation is done on the optimal\ntransport map between the functions at nearby parameters, to achieve an\neffective dimensionality reduction of hyperbolic phenomena. We further propose\na multi-dimensional extension by using the intertwining property of the Radon\ntransform. This extension is a generalization of the classical translational\nrepresentation of Lax-Philips [Lax and Philips, Bull. Amer. Math. Soc. 70\n(1964), pp.130--142]. \n\n"}
{"id": "1712.04749", "contents": "Title: Pre-Production and Quality Assurance of the Mu2e Calorimeter Silicon\n  Photomultipliers Abstract: The Mu2e electromagnetic calorimeter has to provide precise information on\nenergy, time and position for $\\sim$100 MeV electrons. It is composed of 1348\nun-doped CsI crystals, each coupled to two large area Silicon Photomultipliers\n(SiPMs). A modular and custom SiPM layout consisting of a 3$\\times$2 array of\n6$\\times$6 mm$^2$ UV-extended monolithic SiPMs has been developed to fulfill\nthe Mu2e calorimeter requirements and a pre-production of 150 prototypes has\nbeen procured by three international firms (Hamamatsu, SensL and Advansid). A\ndetailed quality assurance process has been carried out on this first batch of\nphotosensors: the breakdown voltage, the gain, the quenching time, the dark\ncurrent and the Photon Detection Efficiency (PDE) have been determined for each\nmonolithic cell of each SiPMs array. One sample for each vendor has been\nexposed to a neutron fluency up to $\\sim$8.5~$\\times$~10$^{11}$ 1 MeV (Si) eq.\nn/cm$^{2}$ and a linear increase of the dark current up to tens of mA has been\nobserved. Others 5 samples for each vendor have undergone an accelerated aging\nin order to verify a Mean Time To Failure (MTTF) higher than $\\sim$10$^{6}$\nhours. \n\n"}
{"id": "1712.05546", "contents": "Title: Two-stage fourth-order accurate time discretizations for 1D and 2D\n  special relativistic hydrodynamics Abstract: This paper studies the two-stage fourth-order accurate time discretization\n\\cite{LI-DU:2016} and applies it to special relativistic hydrodynamical\nequations. It is shown that new two-stage fourth-order accurate time\ndiscretizations can be proposed. With the aid of the direct Eulerian GRP\n(generalized Riemann problem) methods \\cite{Yang-He-Tang:2011,Yang-Tang:2012}\nand the analytical resolution of the local \"quasi 1D\" GRP, the two-stage\nfourth-order accurate time discretizations are successfully implemented for the\n1D and 2D special relativistic hydrodynamical equations. Several numerical\nexperiments demonstrate the performance and accuracy as well as robustness of\nour schemes. \n\n"}
{"id": "1712.05742", "contents": "Title: On the minimal ranks of matrix pencils and the existence of a best\n  approximate block-term tensor decomposition Abstract: Under the action of the general linear group with tensor structure, the ranks\nof matrices $A$ and $B$ forming an $m \\times n$ pencil $A + \\lambda B$ can\nchange, but in a restricted manner. Specifically, with every pencil one can\nassociate a pair of minimal ranks, which is unique up to a permutation. This\nnotion can be defined for matrix pencils and, more generally, also for matrix\npolynomials of arbitrary degree. In this paper, we provide a formal definition\nof the minimal ranks, discuss its properties and the natural hierarchy it\ninduces in a pencil space. Then, we show how the minimal ranks of a pencil can\nbe determined from its Kronecker canonical form. For illustration, we classify\nthe orbits according to their minimal ranks (under the action of the general\nlinear group) in the case of real pencils with $m, n \\le 4$. Subsequently, we\nshow that real regular $2k \\times 2k$ pencils having only complex-valued\neigenvalues, which form an open positive-volume set, do not admit a best\napproximation (in the norm topology) on the set of real pencils whose minimal\nranks are bounded by $2k-1$. Our results can be interpreted from a tensor\nviewpoint, where the minimal ranks of a degree-$(d-1)$ matrix polynomial\ncharacterize the minimal ranks of matrices constituting a block-term\ndecomposition of an $m \\times n \\times d$ tensor into a sum of matrix-vector\ntensor products. \n\n"}
{"id": "1712.06082", "contents": "Title: The fundamental Laplacian eigenvalue of the regular polygon with\n  Dirichlet boundary conditions Abstract: The lowest eigenvalue of the Laplacian within the S-sided regular polygon\nwith Dirichlet boundary conditions is the focus of this report. As suggested by\nothers, this eigenvalue may be expressed as an asymptotic expansion in powers\nof 1/S where, interestingly, they have shown that the first few coefficients in\nthat expansion, up to sixth order, may be expressed analytically in terms of\nRiemann zeta functions and roots of Bessel functions. This report builds on\nthat work with three main contributions: (1) compelling numerical evidence\nindependently supporting those published results, (2) a conjecture adding two\nmore terms to the asymptotic expansion, and (3) an observation that\nhigher-order coefficients both alternate in sign and grow rapidly in magnitude,\nwhich suggest the series doesn't converge unless S>=10. This report is based on\na numerical computation of the eigenvalues precise to fifty digits for S up to\n150.\n  Keywords: Laplacian eigenvalue; regular polygon; asymptotic expansion \n\n"}
{"id": "1712.06758", "contents": "Title: Scalable hierarchical PDE sampler for generating spatially correlated\n  random fields using non-matching meshes Abstract: This work describes a domain embedding technique between two non-matching\nmeshes used for generating realizations of spatially correlated random fields\nwith applications to large-scale sampling-based uncertainty quantification. The\ngoal is to apply the multilevel Monte Carlo (MLMC) method for the\nquantification of output uncertainties of PDEs with random input coefficients\non general, unstructured computational domains. We propose a highly scalable,\nhierarchical sampling method to generate realizations of a Gaussian random\nfield on a given unstructured mesh by solving a reaction-diffusion PDE with a\nstochastic right-hand side. The stochastic PDE is discretized using the mixed\nfinite element method on an embedded domain with a structured mesh, and then\nthe solution is projected onto the unstructured mesh. This work describes\nimplementation details on how to efficiently transfer data from the structured\nand unstructured meshes at coarse levels, assuming this can be done efficiently\non the finest level. We investigate the efficiency and parallel scalability of\nthe technique for the scalable generation of Gaussian random fields in three\ndimensions. An application of the MLMC method is presented for quantifying\nuncertainties of subsurface flow problems. We demonstrate the scalability of\nthe sampling method with non-matching mesh embedding, coupled with a parallel\nforward model problem solver, for large-scale 3D MLMC simulations with up to\n$1.9\\cdot 10^9$ unknowns. \n\n"}
{"id": "1712.08788", "contents": "Title: Quark deconfinement as supernova explosion engine for massive\n  blue-supergiant stars Abstract: Blue-supergiant stars develop into core-collapse supernovae --- one of the\nmost energetic outbursts in the universe --- when all nuclear burning fuel is\nexhausted in the stellar core. Previous attempts failed to explain observed\nexplosions of such stars which have a zero-age main sequence mass of\n50~M$_\\odot$ or more. Here we exploit the largely uncertain state of matter at\nhigh density, and connect the modeling of such stellar explosions with a\nfirst-order phase transition from nuclear matter to the quark-gluon plasma. The\nresulting energetic supernova explosions can account for a large variety of\nlightcurves, from peculiar type II to super-luminous events. The remnants are\nneutron stars with quark matter core, known as hybrid stars, of about\n2~M$_\\odot$ at birth. A galactic event of this kind could be observable due to\nthe release of a second neutrino burst. Its observation would confirm such a\nfirst-order phase transition at densities relevant for astrophysics. \n\n"}
{"id": "1712.09338", "contents": "Title: A Fast Algorithm for Multiresolution Mode Decomposition Abstract: \\emph{Multiresolution mode decomposition} (MMD) is an adaptive tool to\nanalyze a time series $f(t)=\\sum_{k=1}^K f_k(t)$, where $f_k(t)$ is a\n\\emph{multiresolution intrinsic mode function} (MIMF) of the form\n\\begin{eqnarray*} f_k(t)&=&\\sum_{n=-N/2}^{N/2-1} a_{n,k}\\cos(2\\pi\nn\\phi_k(t))s_{cn,k}(2\\pi N_k\\phi_k(t))\\\\&&+\\sum_{n=-N/2}^{N/2-1}b_{n,k}\n\\sin(2\\pi n\\phi_k(t))s_{sn,k}(2\\pi N_k\\phi_k(t)) \\end{eqnarray*} with\ntime-dependent amplitudes, frequencies, and waveforms. The multiresolution\nexpansion coefficients $\\{a_{n,k}\\}$, $\\{b_{n,k}\\}$, and the shape function\nseries $\\{s_{cn,k}(t)\\}$ and $\\{s_{sn,k}(t)\\}$ provide innovative features for\nadaptive time series analysis. The MMD aims at identifying these MIMF's\n(including their multiresolution expansion coefficients and shape functions\nseries) from their superposition. This paper proposes a fast algorithm for\nsolving the MMD problem based on recursive diffeomorphism-based spectral\nanalysis (RDSA). RDSA admits highly efficient numerical implementation via the\nnonuniform fast Fourier transform (NUFFT); its convergence and accuracy can be\nguaranteed theoretically. Numerical examples from synthetic data and natural\nphenomena are given to demonstrate the efficiency of the proposed method. \n\n"}
{"id": "1712.09777", "contents": "Title: Performance of a large aperture GEM-like gating device for the\n  International Linear Collider Abstract: One of the potential problems of a Micro-Pattern Gaseous Detector\n(MPGD)-based Time Projection Chamber (TPC) is the Ion back Flow (IBF): ions\ngenerated through the avalanche amplification process flow back to the drift\nvolume of the TPC and disarrange an electric field inside it. Consequently\nnon-negligible degradation of azimuthal spatial resolution is caused due to\nthis IBF. Meanwhile, it is necessary to collect primary ionized electrons to\nmaintain intrinsic performance of the MPGDs. The MPGD based TPC is currently\nplanned to be used as a central tracking detector of the International Large\nDetector (ILD), which is one of the detector concepts for the future\nInternational Linear Collider (ILC) project, and which requires fine azimuthal\nspatial resolution of less than 100 ${\\rm \\mu m}$ over the drift length of the\nTPC to attain high momentum resolution. Because of a unique beam structure of\nthe ILC, the IBF is a critical issue for the realization of the ILD-TPC. Not\nonly to suppress the ion back-flow to the drift volume, but also to allow the\nprimary electrons pass through, a large aperture GEM-like gating device has\nbeen developed. Several bench tests for confirming the performance of the\ngating device have been conducted, besides that, beam test with the full\ndetector module equipped with the gating device was carried out to verify the\nresolution that the full module can provide. As a result, it turned out that\nthe developed gating device fulfills requirements for maintaining the\nperformance of the MPGD based TPC, and it has sufficient performance for the\ncentral tracker of the ILD at the ILC. \n\n"}
{"id": "1801.00615", "contents": "Title: Computational multiscale methods for linear heterogeneous poroelasticity Abstract: We consider a strongly heterogeneous medium saturated by an incompressible\nviscous fluid as it appears in geomechanical modeling. This poroelasticity\nproblem suffers from rapidly oscillating material parameters, which calls for a\nthorough numerical treatment. In this paper, we propose a method based on the\nlocal orthogonal decomposition technique and motivated by a similar approach\nused for linear thermoelasticity. Therein, local corrector problems are\nconstructed in line with the static equations, whereas we propose to consider\nthe full system. This allows to benefit from the given saddle point structure\nand results in two decoupled corrector problems for the displacement and the\npressure. We prove the optimal first-order convergence of this method and\nverify the result by numerical experiments. \n\n"}
{"id": "1801.01206", "contents": "Title: Radial basis function collocation method for decoupled fractional\n  Laplacian wave equations Abstract: Decoupled fractional Laplacian wave equation can describe the seismic wave\npropagation in attenuating media. Fourier pseudospectral implementations, which\nsolve the equation in spatial frequency domain, are the only existing methods\nfor solving the equation. For the earth media with curved boundaries, the\npseudospectral methods could be less attractive to handle the irregular\ncomputational domains. In the paper, we propose a radial basis function\ncollocation method that can easily tackle the irregular domain problems. Unlike\nthe pseudospectral methods, the proposed method solves the equation in physical\nvariable domain. The directional fractional Laplacian is chosen from varied\ndefinitions of fractional Laplacian. Particularly, the vector\nGr\\\"unwald-Letnikov formula is employed to approximate fractional directional\nderivative of radial basis function. The convergence and stability of the\nmethod are numerically investigated by using the synthetic solution and the\nlong-time simulations, respectively. The method's flexibility is studied by\nconsidering homogeneous and multi-layer media having regular and irregular\ngeometric boundaries. \n\n"}
{"id": "1801.07178", "contents": "Title: ROPPERI - A TPC readout with GEMs, pads and Timepix Abstract: The concept of a hybrid readout of a time projection chamber is presented. It\ncombines a GEM-based amplification and a pad-based anode plane with a pixel\nchip as readout electronics. This way, a high granularity enabling to identify\nelectron clusters from the primary ionisation is achieved as well as\nflexibility and large anode coverage. The benefits of this high granularity, in\nparticular for dE/dx measurements, are outlined and results of a\nsimulation-based performance study are given. The structure of the first\nprototype board is discussed, including adaptions based on a very preliminary\nfirst measurement for a second production towards a proof-of-principle. \n\n"}
{"id": "1802.01108", "contents": "Title: Spherical function regularization for parallel MRI reconstruction Abstract: From the optimization point of view, a difficulty with parallel MRI with\nsimultaneous coil sensitivity estimation is the multiplicative nature of the\nnon-linear forward operator: the image being reconstructed and the coil\nsensitivities compete against each other, causing the optimization process to\nbe very sensitive to small perturbations. This can, to some extent, be avoided\nby regularizing the unknown in a suitably \"orthogonal\" fashion. In this paper,\nwe introduce such a regularization based on spherical function bases. To\nperform this regularization, we represent efficient recurrence formulas for\nspherical Bessel functions and associated Legendre functions. Numerically, we\nstudy the solution of the model with non-linear ADMM. We perform various\nnumerical simulations to demonstrate the efficacy of the proposed model in\nparallel MRI reconstruction. \n\n"}
{"id": "1802.02724", "contents": "Title: Primal-dual stochastic gradient method for convex programs with many\n  functional constraints Abstract: Stochastic gradient method (SGM) has been popularly applied to solve\noptimization problems with objective that is stochastic or an average of many\nfunctions. Most existing works on SGMs assume that the underlying problem is\nunconstrained or has an easy-to-project constraint set. In this paper, we\nconsider problems that have a stochastic objective and also many functional\nconstraints. For such problems, it could be extremely expensive to project a\npoint to the feasible set, or even compute subgradient and/or function value of\nall constraint functions. To find solutions of these problems, we propose a\nnovel (adaptive) SGM based on the classical augmented Lagrangian function.\nWithin every iteration, it inquires a stochastic subgradient of the objective,\nand a subgradient and the function value of one randomly sampled constraint\nfunction. Hence, the per-iteration complexity is low. We establish its\nconvergence rate for convex problems and also problems with strongly convex\nobjective. It can achieve the optimal $O(1/\\sqrt{k})$ convergence rate for\nconvex case and nearly optimal $O\\big((\\log k)/k\\big)$ rate for strongly convex\ncase. Numerical experiments on a sample approximation problem of the robust\nportfolio selection and quadratically constrained quadratic programming are\nconducted to demonstrate its efficiency. \n\n"}
{"id": "1802.03214", "contents": "Title: Vector-Interaction-Enhanced Bag Model Abstract: A commonly applied quark matter model in astrophysics is the thermodynamic\nbag model (tdBAG). The original MIT bag model approximates the effect of quark\nconfinement, but does not explicitly account for the breaking of chiral\nsymmetry, an important property of Quantum Chromodynamics (QCD). It further\nignores vector repulsion. The vector-interaction-enhanced bag model (vBag)\nimproves the tdBAG approach by accounting for both dynamical chiral symmetry\nbreaking and repulsive vector interactions. The latter is of particular\nimportance to studies of dense matter in beta-equilibriumto explain the two\nsolar mass maximum mass constraint for neutron stars. The model is motivated by\nanalyses of QCD based Dyson-Schwinger equations (DSE), assuming a simple\nquark-quark contact interaction. Here, we focus on the study of hybrid neutron\nstar properties resulting from the application of vBag and will discuss\npossible extensions. \n\n"}
{"id": "1802.04516", "contents": "Title: Arbitrary high order accurate space-time discontinuous Galerkin finite\n  element schemes on staggered unstructured meshes for linear elasticity Abstract: In this paper we propose a new high order accurate space-time DG finite\nelement scheme for the solution of the linear elastic wave equations in first\norder velocity-stress formulation in two and three-space dimensions on\nstaggered unstructured triangular and tetrahedral meshes. The method reaches\narbitrary high order of accuracy in both space and time via the use of\nspace-time basis and test functions. Within the staggered mesh formulation, we\ndefine the discrete velocity field in the control volumes of a primary mesh,\nwhile the discrete stress tensor is defined on a face-based staggered dual\nmesh. The space-time DG formulation leads to an implicit scheme that requires\nthe solution of a linear system for the unknown degrees of freedom at the new\ntime level. The number of unknowns is reduced at the aid of the Schur\ncomplement, so that in the end only a linear system for the degrees of freedom\nof the velocity field needs to be solved. Thanks to the use of a spatially\nstaggered mesh, the stencil of the final velocity system involves only the\nelement and its direct neighbors. The resulting linear system can be\nefficiently solved via matrix-free iterative methods. The chosen discretization\nand the linear nature of the governing PDE system lead to an unconditionally\nstable scheme, which allows large time steps even for low quality meshes that\ncontain sliver elements. The fully discrete staggered space-time DG method is\nproven to be energy stable for any order of accuracy, for any mesh and for any\ntime step size. For the particular case of Crank-Nicolson time discretization\nand homogeneous material, the final velocity system can be proven to be\nsymmetric and positive definite and in this case the scheme is also exactly\nenergy preserving. The new scheme is applied to several test problems in two\nand three space dimensions, providing also a comparison with high order\nexplicit ADER-DG schemes \n\n"}
{"id": "1802.04848", "contents": "Title: U(1) symmetric $\\alpha$-attractors Abstract: We present a class of supergravity $\\alpha$-attractors with an approximate\nglobal U(1) symmetry corresponding to the axion direction. We also develop a\nmulti-field generalization of these models and show that the $\\alpha$-attractor\nmodels with U(1) symmetries have a dual description in terms of a two-form\nsuperfield coupled to a three-form superfield. \n\n"}
{"id": "1802.04963", "contents": "Title: Superconvergent recovery of Raviart--Thomas mixed finite elements on\n  triangular grids Abstract: For the second lowest-order Raviart--Thomas mixed method, we prove that the\ncanonical interpolant and finite element solution for the vector variable in\nelliptic problems are superclose in the $H(\\text{div})$-norm on mildly\nstructured meshes, where most pairs of adjacent triangles form approximate\nparallelograms. We then develop a family of postprocessing operators for\nRaviart--Thomas mixed elements on triangular grids by using the idea of local\nleast squares fittings. Super-approximation property of the postprocessing\noperators for the lowest and second lowest order Raviart--Thomas elements is\nproved under mild conditions. Combining the supercloseness and\nsuper-approximation results, we prove that the postprocessed solution\nsuperconverges to the exact solution in the $L^2$-norm on mildly structured\nmeshes. \n\n"}
{"id": "1802.05743", "contents": "Title: A Multilevel Monte Carlo Ensemble Scheme for Solving Random Parabolic\n  PDEs Abstract: A first-order, Monte Carlo ensemble method has been recently introduced for\nsolving parabolic equations with random coefficients in [26], which is a\nnatural synthesis of the ensemble-based, Monte Carlo sampling algorithm and the\nensemble-based, first-order time stepping scheme. With the introduction of an\nensemble average of the diffusion function, this algorithm leads to a single\ndiscrete system with multiple right-hand sides for a group of realizations,\nwhich could be solved more efficiently than a sequence of linear systems. In\nthis paper, we pursue in the same direction and develop a new multilevel Monte\nCarlo ensemble method for solving random parabolic partial differential\nequations. Comparing with the approach in [26], this method possesses a\nhigh-order accuracy in time and further reduces the computational cost by using\nthe multilevel Monte Carlo method. Rigorous numerical analysis shows the method\nachieves the optimal rate of convergence. Several numerical experiments are\npresented to illustrate the theoretical results. \n\n"}
{"id": "1802.06546", "contents": "Title: A spectral interpolation scheme on the unit sphere based on the nodes of\n  spherical Lissajous curves Abstract: For sampling values along spherical Lissajous curves we establish a spectral\ninterpolation and quadrature scheme on the sphere. We provide a mathematical\nanalysis of spherical Lissajous curves and study the characteristic properties\nof their intersection points. Based on a discrete orthogonality structure we\nare able to prove the unisolvence of the interpolation problem. As basis\nfunctions for the interpolation space we use a parity-modified double Fourier\nbasis on the sphere which allows us to implement the interpolation scheme in an\nefficient way. We further show that the numerical condition number of the\ninterpolation scheme displays a logarithmic growth.\n  As an application, we use the developed interpolation algorithm to estimate\nthe rotation of an object based on measurements at the spherical Lissajous\nnodes. \n\n"}
{"id": "1802.07014", "contents": "Title: Electromechanical coupling of waves in nerve fibres Abstract: The propagation of an action potential (AP) in a nerve fibre is accompanied\nby mechanical and thermal effects. In this paper an attempt is made to build up\na mathematical model which couples the AP with a possible pressure wave (PW) in\nthe axoplasm and waves in the nerve fibre wall (longitudinal - LW and\ntransverse - TW) made of a lipid bilayer (biomembrane). A system of\ndifferential equations includes the governing equations of single waves with\ncoupling forces between them. The single equations are kept as simple as\npossible in order to carry out the proof of concept. An assumption based on\nearlier studies is made that the coupling forces depend on changes (the\ngradient, time derivative) of the voltage. In addition it is assumed that the\ntransverse displacement of the biomembrane can be calculated from the gradient\nof the LW in the biomembrane. The computational simulation is focused to\ndetermining the influence of possible coupling forces on the emergence of\nmechanical waves from the AP. As a result, an ensemble of waves (AP, PW, LW,\nTW) emerges. The further experiments should verify assumptions about coupling\nforces. In the Appendix, the numerical scheme used for simulations, is\npresented. \n\n"}
{"id": "1802.09020", "contents": "Title: Entropy stable modeling of non-isothermal multi-component\n  diffuse-interface two-phase flows with realistic equations of state Abstract: In this paper, we consider mathematical modeling and numerical simulation of\nnon-isothermal compressible multi-component diffuse-interface two-phase flows\nwith realistic equations of state. A general model with general reference\nvelocity is derived rigorously through thermodynamical laws and Onsager's\nreciprocal principle, and it is capable of characterizing compressibility and\npartial miscibility between multiple fluids. We prove a novel relation among\nthe pressure, temperature and chemical potentials, which results in a new\nformulation of the momentum conservation equation indicating that the gradients\nof chemical potentials and temperature become the primary driving force of the\nfluid motion except for the external forces. A key challenge in numerical\nsimulation is to develop entropy stable numerical schemes preserving the laws\nof thermodynamics. Based on the convex-concave splitting of Helmholtz free\nenergy density with respect to molar densities and temperature, we propose an\nentropy stable numerical method, which solves the total energy balance equation\ndirectly, and thus, naturally satisfies the first law of thermodynamics.\nUnconditional entropy stability (the second law of thermodynamics) of the\nproposed method is proved by estimating the variations of Helmholtz free energy\nand kinetic energy with time steps. Numerical results validate the proposed\nmethod. \n\n"}
{"id": "1802.09202", "contents": "Title: Simulation and Efficiency Studies of Optical Photon Transportation and\n  Detection with Plastic Antineutrino Detector Modules Abstract: In this work, the simulation of optical photons is carried out in an\nantineutrino detector module consisting of a plastic scintillator connected to\nlight guides and photomultipliers on both ends, which is considered to be used\nfor remote reactor monitoring in the field of nuclear safety. Using Monte Carlo\n(MC) based GEANT4 simulation, numerous parameters influencing the light\ncollection and thereby the energy resolution of the antineutrino detector\nmodule are studied: e.g., degrees of scintillator surface roughness, reflector\ntype, and its ap- plying method onto scintillator and light guide surface, the\nreflectivity of the reflector, light guide geometries and diameter of the\nphotocathode. The impact of each parameter is inves- tigated by looking at the\ndetected spectrum, i.e. the number photoelectrons per depositing energy. In\naddition, the average light collection efficiency of the detector module and\nits spatial variation are calculated for each simulation setup. According to\nthe simulation re- sults, it is found that photocathode size, light guide\nshape, reflectivity of reflecting material and wrapping method show a\nsignificant impact on the light collection efficiency while scin- tillator\nsurface polishing level and the choose of reflector type show relatively less\nimpact. This study demonstrates that these parameters are very important in the\ndesign of plastic scintillator included antineutrino detectors to improve the\nenergy resolution efficiency. \n\n"}
{"id": "1802.09518", "contents": "Title: Orthogonal Basis Function Over the Unit Circle with the Minimax Property Abstract: We construct an orthogonal basis of functions defined over the unit circle as\nthe product of the common sinusoidal functions of the azimuth angle by radial\nfunctions which are essentially sines of a polynomials of the radial distance\nto the origin. The main impetus of this approach is to generate basis functions\nwhere the minima and maxima along both coordinates, the azimuth and the\ndistance r to the center, have the same amplitude, akin to the Chebyshev\npolynomial basis of the one-dimensional unit interval. The construction is\nbased on numerical evaluation of the overlap integrals, which have the format\nof generalized Fresnel integrals. \n\n"}
{"id": "1802.09851", "contents": "Title: Searching for Lepton Flavour Violation with the Mu3e Experiment Abstract: The upcoming Mu3e experiment searches for the lepton flavour violating decay\n$\\mu^+\\,\\rightarrow\\,e^+ e^- e^+$ with the aim of a final sensitivity of one\nsignal decay in $10^{16}$ observed muon decays, an improvement over the\npreceding SINDRUM experiment by four orders of magnitude. In the first phase,\nthe experiment will be operated at an existing intense muon beam line at the\nPaul Scherrer Institute. With muon stopping rates of about\n$10^{8}\\text{s}^{-1}$, a single-event sensitivity of $2\\cdot 10^{-15}$ can be\nachieved. For the ultimate sensitivity, a new high intensity muon beam line is\nrequired. In order to suppress background, the tracking detector is designed to\nmeasure low momentum electron and positron tracks with excellent precision by\nmaking use of very thin silicon pixel sensors. In addition, scintillating\nfibres and tiles provide precise timing information. Currently, the\ncollaboration is finalizing the detector design and preparing for construction\nand commissioning. \n\n"}
{"id": "1803.00588", "contents": "Title: Precision constraints on radiative neutrino decay with CMB spectral\n  distortion Abstract: We investigate the radiative decay of the cosmic neutrino background, and its\nimpact on the spectrum of the cosmic microwave background (CMB) that is known\nto be a nearly perfect black body. We derive exact formulae for the decay of a\nheavier neutrino into a lighter neutrino and a photon, $\\nu_j \\to \\nu_i +\n\\gamma$, and of absorption as its inverse, $\\nu_i + \\gamma \\to \\nu_j$, by\naccounting for the precise form of the neutrino momentum distribution. Our\ncalculations show that if the neutrinos are heavier than $\\mathcal O(0.1)$ eV,\nthe exact formulae give results that differ by $\\sim$50%, compared with\napproximate ones where neutrinos are assumed to be at rest. We also find that\nspectral distortion due to absorption is more important for heavy neutrino\nmasses (by a factor of $\\sim$10 going from a neutrino mass of 0.01 eV to 0.1\neV). By analyzing the CMB spectral data measured with COBE-FIRAS, we obtain\nlower limits on the neutrino lifetime of $\\tau_{12} \\gtrsim 4 \\times 10^{21}$ s\n(95% C.L.) for the smaller mass splitting and $\\tau_{13} \\sim \\tau_{23} \\gtrsim\n10^{19}$ s for the larger mass splitting. These represent up to one order of\nmagnitude improvement over previous CMB constraints. With future CMB\nexperiments such as PIXIE, these limits will improve by roughly 4 orders of\nmagnitude. This translates to a projected upper limit on the neutrino magnetic\nmoment (for certain neutrino masses and decay modes) of $\\mu_\\nu < 3 \\times\n10^{-11}\\, \\mu_B$, where $\\mu_B$ is the Bohr magneton. Such constraints would\nmake future precision CMB measurements competitive with lab-based constraints\non neutrino magnetic moments. \n\n"}
{"id": "1803.00638", "contents": "Title: Fast and accurate computation of orthogonal moments for texture analysis Abstract: In this work we describe a fast and stable algorithm for the computation of\nthe orthogonal moments of an image. Indeed, orthogonal moments are\ncharacterized by a high discriminative power, but some of their possible\nformulations are characterized by a large computational complexity, which\nlimits their real-time application. This paper describes in detail an approach\nbased on recurrence relations, and proposes an optimized Matlab implementation\nof the corresponding computational procedure, aiming to solve the above\nlimitations and put at the community's disposal an efficient and easy to use\nsoftware. In our experiments we evaluate the effectiveness of the recurrence\nformulation, as well as its performance for the reconstruction task, in\ncomparison to the closed form representation, often used in the literature. The\nresults show a sensible reduction in the computational complexity, together\nwith a greater accuracy in reconstruction. In order to assess and compare the\naccuracy of the computed moments in texture analysis, we perform classification\nexperiments on six well-known databases of texture images. Again, the\nrecurrence formulation performs better in classification than the closed form\nrepresentation. More importantly, if computed from the GLCM of the image using\nthe proposed stable procedure, the orthogonal moments outperform in some\nsituations some of the most diffused state-of-the-art descriptors for texture\nclassification. \n\n"}
{"id": "1803.01581", "contents": "Title: Efficiency and timing performance of the MuPix7 high-voltage monolithic\n  active pixel sensor Abstract: The MuPix7 is a prototype high voltage monolithic active pixel sensor with\n103 times 80 um2 pixels thinned to 64 um and incorporating the complete\nread-out circuitry including a 1.25 Gbit/s differential data link. Using data\ntaken at the DESY electron test beam, we demonstrate an efficiency of 99.3% and\na time resolution of 14 ns. The efficiency and time resolution are studied with\nsub-pixel resolution and reproduced in simulations. \n\n"}
{"id": "1803.02424", "contents": "Title: Universal image systems for non-periodic and periodic Stokes flows above\n  a no-slip wall Abstract: It is well-known that by placing judiciously chosen image point forces and\ndoublets to the Stokeslet above a flat wall, the no-slip boundary condition can\nbe conveniently imposed on the wall [Blake, J. R. Math. Proc. Camb. Philos.\nSoc. 70(2), 1971: 303.]. However, to further impose periodic boundary\nconditions on directions parallel to the wall usually involves tedious\nderivations because single or double periodicity in Stokes flow may require the\nperiodic unit to have no net force, which is not satisfied by the well-known\nimage system. In this work we present a force-neutral image system. This\nneutrality allows us to represent the Stokes image system in a universal\nformulation for non-periodic, singly periodic and doubly periodic geometries.\nThis formulation enables the black-box style usage of fast kernel summation\nmethods. We demonstrate the efficiency and accuracy of this new image method\nwith the periodic kernel independent fast multipole method in both non-periodic\nand doubly periodic geometries. We then extend this new image system to other\nwidely used Stokes fundamental solutions, including the Laplacian of the\nStokeslet and the Rotne-Prager-Yamakawa tensor. \n\n"}
{"id": "1803.05919", "contents": "Title: Capturing near-equilibrium solutions: a comparison between high-order\n  discontinuous Galerkin methods and well-balanced schemes Abstract: Equilibrium or stationary solutions usually proceed through the exact balance\nbetween hyperbolic transport terms and source terms. Such equilibrium solutions\nare affected by truncation errors that prevent any classical numerical scheme\nfrom capturing the evolution of small amplitude waves of physical significance.\nIn order to overcome this problem, we compare two commonly adopted strategies:\ngoing to very high order and reduce drastically the truncation errors on the\nequilibrium solution, or design a specific scheme that preserves by\nconstruction the equilibrium exactly, the so-called well-balanced approach. We\npresent a modern numerical implementation of these two strategies and compare\nthem in details, using hydrostatic but also dynamical equilibrium solutions of\nseveral simple test cases. Finally, we apply our methodology to the simulation\nof a protoplanetary disc in centrifugal equilibrium around its star and model\nits interaction with an embedded planet, illustrating in a realistic\napplication the strength of both methods. \n\n"}
{"id": "1803.06379", "contents": "Title: Photon detector system timing performance in the DUNE 35-ton prototype\n  liquid argon time projection chamber Abstract: The 35-ton prototype for the Deep Underground Neutrino Experiment far\ndetector was a single-phase liquid argon time projection chamber with an\nintegrated photon detector system, all situated inside a membrane cryostat. The\ndetector took cosmic-ray data for six weeks during the period of February 1,\n2016 to March 12, 2016. The performance of the photon detection system was\nchecked with these data. An installed photon detector was demonstrated to\nmeasure the arrival times of cosmic-ray muons with a resolution better than 32\nns, limited by the timing of the trigger system. A measurement of the timing\nresolution using closely-spaced calibration pulses yielded a resolution of 15\nns for pulses at a level of 6 photo-electrons. Scintillation light from\ncosmic-ray muons was observed to be attenuated with increasing distance with a\ncharacteristic length of $155 \\pm 28$ cm. \n\n"}
{"id": "1803.08732", "contents": "Title: New physics searches in nuclear and neutron $\\beta$ decay Abstract: The status of tests of the standard electroweak model and of searches for new\nphysics in allowed nuclear $\\beta$ decay and neutron decay is reviewed\nincluding both theoretical and experimental developments. The sensitivity and\ncomplementarity of recent and ongoing experiments are discussed with emphasis\non their potential to look for new physics. Measurements are interpreted using\na model-independent effective field theory approach enabling to recast the\noutcome of the analysis in many specific new physics models. Special attention\nis given to the connection that this approach establishes with high-energy\nphysics. A new global fit of available $\\beta$-decay data is performed\nincorporating, for the first time in a consistent way, superallowed $0^+\\to\n0^+$ transitions, neutron decay and nuclear decays. The constraints on exotic\nscalar and tensor couplings involving left- or right-handed neutrinos are\ndetermined while a constraint on the pseudoscalar coupling from neutron decay\ndata is obtained for the first time as well. The values of the vector and\naxial-vector couplings, which are associated within the standard model to\n$V_{ud}$ and $g_A$ respectively, are also updated. The ratio between the axial\nand vector couplings obtained from the fit under standard model assumptions is\n$C_A/C_V = -1.27510(66)$. The relevance of the various experimental inputs and\nerror sources is critically discussed and the impact of ongoing measurements is\nstudied. The complementarity of the obtained bounds with other low- and\nhigh-energy probes is presented including ongoing searches at the Large Hadron\nCollider. \n\n"}
{"id": "1803.09697", "contents": "Title: Constraining Primordial Black Holes with the EDGES 21-cm Absorption\n  Signal Abstract: The EDGES experiment has recently measured an anomalous global 21-cm spectrum\ndue to hydrogen absorptions at redshifts of about $z\\sim 17$. Model\nindependently, the unusually low temperature of baryons probed by this\nobservable sets strong constraints on any physical process that transfers\nenergy into the baryonic environment at such redshifts. Here we make use of the\n21-cm spectrum to derive bounds on the energy injection due to a possible\npopulation of ${\\cal O}(1-100) M_\\odot$ primordial black holes, which induce a\nwide spectrum of radiation during the accretion of the surrounding gas. After\ncalculating the total radiative intensity of a primordial black hole\npopulation, we estimate the amount of heat and ionisations produced in the\nbaryonic gas and compute the resulting thermal history of the Universe with a\nmodified version of RECFAST code. Finally, by imposing that the temperature of\nthe gas at $z\\sim 17$ does not exceed the indications of EDGES, we constrain\nthe possible abundance of primordial black holes. Depending on uncertainties\nrelated to the accretion model, we find that ${\\cal O}(10) M_\\odot$ primordial\nblack holes can only contribute to a fraction $f_{\\rm PBH}<(1-10^{-3})$ of the\ntotal dark matter abundance. \n\n"}
{"id": "1803.10005", "contents": "Title: Strong reduction of the effective radiation length in an axially\n  oriented scintillator crystal Abstract: We measured a considerable increase of the emitted radiation by 120 GeV/c\nelectrons in an axially oriented lead tungstate scintillator crystal, if\ncompared to the case in which the sample was not aligned with the beam\ndirection. This enhancement resulted from the interaction of particles with the\nstrong crystalline electromagnetic field. The data collected at the external\nlines of CERN SPS were critically compared to Monte Carlo simulations based on\nthe Baier Katkov quasiclassical method, highlighting a reduction of the\nscintillator radiation length by a factor of five in case of beam alignment\nwith the [001] crystal axes. The observed effect opens the way to the\nrealization of compact electromagnetic calorimeters/detectors based on oriented\nscintillator crystals in which the amount of material can be strongly reduced\nwith respect to the state of the art. These devices could have relevant\napplications in fixed-target experiments as well as in satellite-borne\ngamma-telescopes. \n\n"}
{"id": "1803.10350", "contents": "Title: Sobolev spaces with non-Muckenhoupt weights, fractional elliptic\n  operators, and applications Abstract: We propose a new variational model in weighted Sobolev spaces with\nnon-standard weights and applications to image processing. We show that these\nweights are, in general, not of Muckenhoupt type and therefore the classical\nanalysis tools may not apply. For special cases of the weights, the resulting\nvariational problem is known to be equivalent to the fractional Poisson\nproblem. The trace space for the weighted Sobolev space is identified to be\nembedded in a weighted $L^2$ space. We propose a finite element scheme to solve\nthe Euler-Lagrange equations, and for the image denoising application we\npropose an algorithm to identify the unknown weights. The approach is\nillustrated on several test problems and it yields better results when compared\nto the existing total variation techniques. \n\n"}
{"id": "1803.11019", "contents": "Title: Optimal Convergence Rates for Tikhonov Regularization in Besov Spaces Abstract: This paper deals with Tikhonov regularization for linear and nonlinear\nill-posed operator equations with wavelet Besov norm penalties. We show order\noptimal rates of convergence for finitely smoothing operators and for the\nbackwards heat equation for a range of Besov spaces using variational source\nconditions. We also derive order optimal rates for a white noise model with the\nhelp of variational source conditions and concentration inequalities for sharp\nnegative Besov norms of the noise. \n\n"}
{"id": "1803.11193", "contents": "Title: Electrical Impedance Tomography with Restricted Dirichlet-to-Neumann Map\n  Data Abstract: We propose a new numerical method to reconstruct the isotropic electrical\nconductivity from measured restricted Dirichlet-to-Neumann map data in\nelectrical impedance tomography (EIT) model. \"Restricted Dirichlet-to-Neumann\n(DtN) map data\" means that the Dirichlet and Neumann boundary data for EIT are\ngenerated by a point source running either along an interval of a straight line\nor along a curve located outside of the domain of interest. We \"convexify\" the\nproblem via constructing a globally strictly convex Tikhonov-like functional\nusing a Carleman Weight Function. In particular, two new Carleman estimates are\nestablished. Global convergenceto the correct solution of the gradient\nprojection method for this functional is proven. Numerical examples demonstrate\na good performance of this numerical procedure. \n\n"}
{"id": "1804.00332", "contents": "Title: High Order Cut Finite Elements for the Elastic Wave Equation Abstract: A high order cut finite element method is formulated for solving the elastic\nwave equation. Both a single domain problem and an interface problem are\ntreated. The boundary or interface are allowed to cut through the background\nmesh. To avoid problems with small cuts, stabilizing terms are added to the\nbilinear forms corresponding to the mass and stiffness matrix. The stabilizing\nterms penalize jumps in normal derivatives over the faces of the elements cut\nby the boundary/interface. This ensures a stable discretization independently\nof how the boundary/interface cuts the mesh. Nitsche's method is used to\nenforce boundary and interface conditions, resulting in symmetric bilinear\nforms. As a result of the symmetry, an energy estimate can be made and optimal\norder a priori error estimates are derived for the single domain problem.\nFinally, numerical experiments in two dimensions are presented that verify the\norder of accuracy and stability with respect to small cuts. \n\n"}
{"id": "1804.00471", "contents": "Title: Measurement of radon-induced backgrounds in the NEXT double beta decay\n  experiment Abstract: The measurement of the internal $^{222}$Rn activity in the NEXT-White\ndetector during the so-called Run-II period with $^{136}$Xe-depleted xenon is\ndiscussed in detail, together with its implications for double beta decay\nsearches in NEXT. The activity is measured through the alpha production rate\ninduced in the fiducial volume by $^{222}$Rn and its alpha-emitting progeny.\nThe specific activity is measured to be $(38.1\\pm 2.2~\\mathrm{(stat.)}\\pm\n5.9~\\mathrm{(syst.)})$~mBq/m$^3$. Radon-induced electrons have also been\ncharacterized from the decay of the $^{214}$Bi daughter ions plating out on the\ncathode of the time projection chamber. From our studies, we conclude that\nradon-induced backgrounds are sufficiently low to enable a successful NEXT-100\nphysics program, as the projected rate contribution should not exceed\n0.1~counts/yr in the neutrinoless double beta decay sample. \n\n"}
{"id": "1804.00622", "contents": "Title: Beam test measurements of Low Gain Avalanche Detector single pads and\n  arrays for the ATLAS High Granularity Timing Detector Abstract: For the high luminosity upgrade of the LHC at CERN, ATLAS is considering the\naddition of a High Granularity Timing Detector (HGTD) in front of the end cap\nand forward calorimeters at |z| = 3.5 m and covering the region 2.4 < |{\\eta}|\n< 4 to help reducing the effect of pile-up. The chosen sensors are arrays of 50\n{\\mu}m thin Low Gain Avalanche Detectors (LGAD). This paper presents results on\nsingle LGAD sensors with a surface area of 1.3x1.3 mm2 and arrays with 2x2 pads\nwith a surface area of 2x2 mm^2 or 3x3 mm^2 each and different implant doses of\nthe p+ multiplication layer. They are obtained from data collected during a\nbeam test campaign in Autumn 2016 with a pion beam of 120 GeV energy at the\nCERN SPS. In addition to several quantities measured inclusively for each pad,\nthe gain, efficiency and time resolution have been estimated as a function of\nthe position of the incident particle inside the pad by using a beam telescope\nwith a position resolution of few {\\mu}m. Different methods to measure the time\nresolution are compared, yielding consistent results. The sensors with a\nsurface area of 1.3x1.3 mm^2 have a time resolution of about 40 ps for a gain\nof 20 and of about 27 ps for a gain of 50 and fulfill the HGTD requirements.\nLarger sensors have, as expected, a degraded time resolution. All sensors show\nvery good efficiency and time resolution uniformity. \n\n"}
{"id": "1804.00684", "contents": "Title: Graph-Based Deep Modeling and Real Time Forecasting of Sparse\n  Spatio-Temporal Data Abstract: We present a generic framework for spatio-temporal (ST) data modeling,\nanalysis, and forecasting, with a special focus on data that is sparse in both\nspace and time. Our multi-scaled framework is a seamless coupling of two major\ncomponents: a self-exciting point process that models the macroscale\nstatistical behaviors of the ST data and a graph structured recurrent neural\nnetwork (GSRNN) to discover the microscale patterns of the ST data on the\ninferred graph. This novel deep neural network (DNN) incorporates the real time\ninteractions of the graph nodes to enable more accurate real time forecasting.\nThe effectiveness of our method is demonstrated on both crime and traffic\nforecasting. \n\n"}
{"id": "1804.01780", "contents": "Title: Calibration of the NEXT-White detector using $^{83m}\\mathrm{Kr}$ decays Abstract: The NEXT-White (NEW) detector is currently the largest radio-pure\nhigh-pressure xenon gas time projection chamber with electroluminescent readout\nin the world. NEXT-White has been operating at Laboratorio Subterr\\'aneo de\nCanfranc (LSC) since October 2016. This paper describes the calibrations\nperformed with $^{83m}\\mathrm{Kr}$ decays during a long run taken from March to\nNovember 2017 (Run II). Krypton calibrations are used to correct for the finite\ndrift-electron lifetime as well as for the dependence of the measured energy on\nthe event position which is mainly caused by variations in solid angle\ncoverage. After producing calibration maps to correct for both effects we\nmeasure an excellent energy resolution for 41.5 keV point-like deposits of\n(4.553 $\\pm$ 0.010 (stat.) $\\pm$ 0.324 (sys.)) % FWHM in the full chamber and\n(3.804 $\\pm$ 0.013 (stat.) $\\pm$ 0.112 (sys.)) % FWHM in a restricted fiducial\nvolume. Using naive 1/$\\sqrt{E}$ scaling, these values translate into\nresolutions of (0.516 $\\pm$ 0.0014 (stat.) $\\pm$ 0.0421 (sys.)) % FWHM and\n(0.4943 $\\pm$ 0.0017 (stat.) $\\pm$ 0.0146 (sys.)) % FWHM at the\n$Q_{\\beta\\beta}$ energy of xenon double beta decay (2458 keV), well within\nrange of our target value of 1%. \n\n"}
{"id": "1804.04561", "contents": "Title: A low-rank algorithm for weakly compressible flow Abstract: In this paper, we propose a numerical method for solving weakly compressible\nfluid flow based on a dynamical low-rank projector splitting. The low-rank\nsplitting scheme is applied to the Boltzmann equation with BGK collision term,\nwhich results in a set of constant coefficient advection equations. This\nprocedure is numerically efficient as a small rank is sufficient to obtain the\nrelevant dynamics (described by the Navier--Stokes equations). The resulting\nmethod can be combined with a range of different discretization strategies; in\nparticular, it is possible to implement spectral and semi-Lagrangian methods,\nwhich allows us to design numerical schemes that are not encumbered by the\nsonic CFL condition. \n\n"}
{"id": "1804.07148", "contents": "Title: Feasibility study of the time reversal symmetry tests in decays of\n  metastable positronium atoms with the J-PET detector Abstract: This article reports on the feasibility of testing of the symmetry under\nreversal in time in a purely leptonic system constituted by positronium atoms\nusing the J-PET detector. The present state of T symmetry tests is discussed\nwith an emphasis on the scarcely explored sector of leptonic systems. Two\npossible strategies of searching for manifestations of T violation in\nnon-vanishing angular correlations of final state observables in the decays of\nmetastable triplet states of positronium available with J-PET are proposed and\ndiscussed. Results of a pilot measurement with J-PET and assessment of its\nperformance in reconstruction of three-photon decays are shown along with an\nanalysis of its impact on the sensitivity of the detector for the determination\nof T -violation sensitive observables. \n\n"}
{"id": "1804.09002", "contents": "Title: A Backward Stable Algorithm for Computing the CS Decomposition via the\n  Polar Decomposition Abstract: We introduce a backward stable algorithm for computing the CS decomposition\nof a partitioned $2n \\times n$ matrix with orthonormal columns, or a\nrank-deficient partial isometry. The algorithm computes two $n \\times n$ polar\ndecompositions (which can be carried out in parallel) followed by an\neigendecomposition of a judiciously crafted $n \\times n$ Hermitian matrix. We\nprove that the algorithm is backward stable whenever the aforementioned\ndecompositions are computed in a backward stable way. Since the polar\ndecomposition and the symmetric eigendecomposition are highly amenable to\nparallelization, the algorithm inherits this feature. We illustrate this fact\nby invoking recently developed algorithms for the polar decomposition and\nsymmetric eigendecomposition that leverage Zolotarev's best rational\napproximations of the sign function. Numerical examples demonstrate that the\nresulting algorithm for computing the CS decomposition enjoys excellent\nnumerical stability. \n\n"}
{"id": "1805.00015", "contents": "Title: Electroweak Dark Matter at Future Hadron Colliders Abstract: In a large class of scenarios, dark matter (DM) particles that belong to a\nmultiplet of the standard model (SM) weak interactions are challenging to probe\nin direct detection experiments due to loop-suppressed cross-sections. Direct\nproduction at colliders is thus crucial to look for such DM candidates, and\nunder current estimates, future runs of the 14-TeV LHC are projected to probe\nmasses of around 300 GeV for DM belonging to an SU(2) doublet (Higgsino-like),\nand 900 GeV for SU(2) triplet (wino-like). We examine how far this mass reach\ncan be extended at the proposed 27-TeV high-energy upgrade of the LHC (HE-LHC),\nand compare the results to the case for a 100-TeV hadron collider. Following a\ndetector setup similar to that of the ATLAS tracking system for the Run-2 LHC\nupgrade, with a new Insertable B-Layer (IBL), a disappearing charged track\nanalysis at the HE-LHC can probe Higgsino-like (wino-like) DM mass of up to 600\nGeV (2.1 TeV) at the 95% C.L. The monojet and missing transverse momentum\nsearch, on the otherhand, has a weaker reach of 490 GeV (700 GeV) at 95% C.L.\nfor the Higgsino-like (wino-like) states. The mass range accessible in the\ncollider searches can be complementary to the indirect detection probes using\ngamma rays from dwarf-spheroidal galaxies. \n\n"}
{"id": "1805.02485", "contents": "Title: A Randomized Multivariate Matrix Pencil Method for Superresolution\n  Microscopy Abstract: The matrix pencil method is an eigenvalue based approach for the parameter\nidentification of sparse exponential sums. We derive a reconstruction algorithm\nfor multivariate exponential sums that is based on simultaneous\ndiagonalization. Randomization is used and quantified to reduce the\nsimultaneous diagonalization to the eigendecomposition of a single random\nmatrix. To verify feasibility, the algorithm is applied to synthetic and\nexperimental fluorescence microscopy data. \n\n"}
{"id": "1805.03255", "contents": "Title: A Fixed Mesh Method With Immersed Finite Elements for Solving Interface\n  Inverse Problems Abstract: We present a new fixed mesh algorithm for solving a class of interface\ninverse problems for the typical elliptic interface problems. These interface\ninverse problems are formulated as shape optimization prob- lems whose\nobjective functionals depend on the shape of the interface. Regardless of the\nlocation of the interface, both the governing partial differential equations\nand the objective functional are discretized optimally, with respect to the\ninvolved polynomial space, by an immersed finite element (IFE) method on a\nfixed mesh. Furthermore, the formula for the gradient of the descritized\nobjective function is de- rived within the IFE framework that can be computed\naccurately and efficiently through the discretized adjoint procedure. Features\nof this proposed IFE method based on a fixed mesh are demonstrated by its\napplications to three representative interface inverse problems: the interface\ninverse problem with an internal measurement on a sub-domain, a\nDirichlet-Neumann type inverse problem whose data is given on the boundary, and\na heat dissipation design problem. \n\n"}
{"id": "1805.03436", "contents": "Title: Approximate Hamiltonian for baryons in heavy-flavor QCD Abstract: Aiming at relativistic description of gluons in hadrons, the renormalization\ngroup procedure for effective particles (RGPEP) is applied to baryons in QCD of\nheavy quarks. The baryon eigenvalue problem is posed using the Fock-space\nHamiltonian operator obtained by solving the RGPEP equations up to second order\nin powers of the coupling constant. The eigenstate components that contain\nthree quarks and two or more gluons are heuristically removed at the price of\ninserting a gluon-mass term in the component with one gluon. The resulting\nproblem is reduced to the equivalent one for the component of three quarks and\nno gluons. Each of the three quark-quark interaction terms thus obtained\nconsists of a spin-dependent Coulomb term and a spin-independent harmonic\noscillator term. Quark masses are chosen to fit the lightest spin-one quarkonia\nmasses most accurately. The resulting estimates for bbb and ccc states match\nestimates obtained in lattice QCD and in quark models. Masses of ccb and bbc\nstates are also estimated. The corresponding wave functions are invariant with\nrespect to boosts. In the ccb states, charm quarks tend to form diquarks. The\naccuracy of our approximate Hamiltonian can be estimated through comparison by\nincluding components with two gluons within the same method. \n\n"}
{"id": "1805.04471", "contents": "Title: An energy-conserving ultra-weak discontinuous Galerkin method for the\n  generalized Korteweg-De Vries equation Abstract: We propose an energy-conserving ultra-weak discontinuous Galerkin (DG) method\nfor the generalized Korteweg-De Vries(KdV) equation in one dimension. Optimal a\npriori error estimate of order $k + 1$ is obtained for the semi-discrete scheme\nfor the KdV equation without convection term on general nonuniform meshes when\npolynomials of degree $k\\ge 2$ is used. We also numerically observed optimal\nconvergence of the method for the KdV equation with linear or nonlinear\nconvection terms.\n  It is numerically observed for the new method to have a superior performance\nfor long-time simulations over existing DG methods. \n\n"}
{"id": "1805.07537", "contents": "Title: Strong convergence of numerical discretizations for semilinear\n  stochastic evolution equations driven by multiplicative white noise Abstract: For semilinear stochastic evolution equations whose coefficients are more\ngeneral than the classical global Lipschitz, we present results on the strong\nconvergence rates of numerical discretizations. The proof of them provides a\nnew approach to strong convergence analysis of numerical discretizations for a\nlarge family of second order parabolic stochastic partial differential\nequations driven by space-time white noises. We apply these results to the\nstochastic advection-diffusion-reaction equation with a gradient term and\nmultiplicative white noise, and show that the strong convergence rate of a\nfully discrete scheme constructed by spectral Galerkin approximation and\nexplicit exponential integrator is exactly $\\frac12$ in space and $\\frac14$ in\ntime. Compared with the optimal regularity of the mild solution, it indicates\nthat the spetral Galerkin approximation is superconvergent and the convergence\nrate of the exponential integrator is optimal. Numerical experiments support\nour theoretical analysis. \n\n"}
{"id": "1805.08100", "contents": "Title: An offline/online procedure for dual norm calculations of parameterized\n  functionals: empirical quadrature and empirical test spaces Abstract: We present an offline/online computational procedure for computing the dual\nnorm of parameterized linear functionals.\n  The key elements of the approach are\n  (i) an empirical test space for the manifold of Riesz elements associated\nwith the parameterized functional, and\n  (ii) an empirical quadrature procedure to efficiently deal with\nparametrically non-affine terms. We present a number of theoretical results to\nidentify the different sources of error and to motivate the technique. Finally,\nwe show the effectiveness of our approach to reduce both offline and online\ncosts associated with the computation of the time-averaged residual indicator\nproposed in [Fick, Maday, Patera, Taddei, Journal of Computational Physics,\n2018 (accepted)]. \n\n"}
{"id": "1805.08998", "contents": "Title: On the best approximation of the hierarchical matrix product Abstract: The multiplication of matrices is an important arithmetic operation in\ncomputational mathematics. In the context of hierarchical matrices, this\noperation can be realized by the multiplication of structured block-wise\nlow-rank matrices, resulting in an almost linear cost. However, the\ncomputational efficiency of the algorithm is based on a recursive scheme which\nmakes the error analysis quite involved. In this article, we propose a new\nalgorithmic framework for the multiplication of hierarchical matrices. It\nimproves currently known implementations by reducing the multiplication of\nhierarchical matrices towards finding a suitable low-rank approximation of sums\nof matrix-products. We propose several compression schemes to address this\ntask. As a consequence, we are able to compute the best-approximation of\nhierarchical matrix products. A cost analysis shows that, under reasonable\nassumptions on the low-rank approximation method, the cost of the framework is\nalmost linear with respect to the size of the matrix. Numerical experiments\nshow that the new approach produces indeed the best-approximation of the\nproduct of hierarchical matrices for a given tolerance. They also show that the\nnew multiplication can accomplish this task in less computation time than the\nestablished multiplication algorithm without error control. \n\n"}
{"id": "1805.09453", "contents": "Title: Solving Large-Scale Optimization Problems with a Convergence Rate\n  Independent of Grid Size Abstract: We present a primal-dual method to solve L1-type non-smooth optimization\nproblems independently of the grid size. We apply these results to two\nimportant problems : the Rudin-Osher-Fatemi image denoising model and the L1\nearth mover's distance from optimal transport. Crucially, we provide analysis\nthat determines the choice of optimal step sizes and we prove that our method\nconverges independently of the grid size. Our approach allows us to solve these\nproblems on grids as large as 4096 by 4096 in a few minutes without\nparallelization. \n\n"}
{"id": "1805.09818", "contents": "Title: Quantum Decoherence Effects in Neutrino Oscillations at DUNE Abstract: In this work we analyze quantum decoherence in neutrino oscillations\nconsidering the Open Quantum System framework and oscillations through matter\nfor three neutrino families. Taking DUNE as a case study we performed\nsensitivity analyses for two neutrino flux configurations finding limits for\nthe decoherence parameters. We also offer a physical interpretation for a new\npeak which arises at the $\\nu_{e}$ appearance probability with decoherence. The\nbest sensitivity regions found for the decoherence parameters are\n$\\Gamma_{21}\\le 1.2\\times10^{-23}\\,\\text{GeV}$ and $\\Gamma_{32}\\le\n7.7\\times10^{-25}\\,\\text{GeV}$ at $90\\%$ C. L. \n\n"}
{"id": "1805.10208", "contents": "Title: Radiation hardness of small-pitch 3D pixel sensors up to a fluence of\n  $3\\times10^{16}$ n$_{\\mathrm{eq}}$/cm$^2$ Abstract: Small-pitch 3D silicon pixel detectors have been investigated as\nradiation-hard candidates for the innermost layers of the HL-LHC pixel detector\nupgrades. Prototype 3D sensors with pixel sizes of 50$\\times$50 and\n25$\\times$100 $\\mu$m$^{2}$ connected to the existing ATLAS FE-I4 readout chip\nhave been produced by CNM Barcelona. Irradiations up to particle fluences of\n$3\\times10^{16}$ n$_{\\mathrm{eq}}$/cm$^2$, beyond the full expected HL-LHC\nfluences at the end of lifetime, have been carried out at Karlsruhe and CERN.\nThe performance of the 50$\\times$50 $\\mu$m$^{2}$ devices has been measured in\nthe laboratory and beam tests at CERN SPS. A high charge collected and a high\nhit efficiency of 98% were found up to the highest fluence. The bias voltage to\nreach the target efficiency of 97% at perpendicular beam incidence was found to\nbe about 100 V at $1.4\\times10^{16}$ n$_{\\mathrm{eq}}$/cm$^2$ and 150 V at\n$2.8\\times10^{16}$ n$_{\\mathrm{eq}}$/cm$^2$, significantly lower than for the\nprevious IBL 3D generation with larger inter-electrode distance and than for\nplanar sensors. The power dissipation at -25$^{\\circ}$C and $1.4\\times10^{16}$\nn$_{\\mathrm{eq}}$/cm$^2$ was found to be 13 mW/cm$^2$. Hence, 3D pixel\ndetectors demonstrated superior radiation hardness and were chosen as the\nbaseline for the inner layer of the ATLAS HL-LHC pixel detector upgrade. \n\n"}
{"id": "1805.10782", "contents": "Title: Numerical method for the time-fractional porous medium equation Abstract: This papers deals with a construction and convergence analysis of a finite\ndifference scheme for solving time-fractional porous medium equation. The\ngoverning equation exhibits both nonlocal and nonlinear behaviour making the\nnumerical computations challenging. Our strategy is to reduce the problem into\na single one-dimensional Volterra integral equation for the self-similar\nsolution and then to apply the discretization. The main difficulty arises due\nto the non-Lipschitzian behaviour of the equation's nonlinearity. By the\nanalysis of the recurrence relation for the error we are able to prove that\nthere exists a family of finite difference methods that is convergent for a\nlarge subset of the parameter space. We illustrate our results with a concrete\nexample of a method based on the midpoint quadrature. \n\n"}
{"id": "1805.10801", "contents": "Title: Sequential sampling for optimal weighted least squares approximations in\n  hierarchical spaces Abstract: We consider the problem of approximating an unknown function $u\\in\nL^2(D,\\rho)$ from its evaluations at given sampling points $x^1,\\dots,x^n\\in\nD$, where $D\\subset \\mathbb{R}^d$ is a general domain and $\\rho$ is a\nprobability measure. The approximation is picked in a linear space $V_m$ where\n$m=\\dim(V_m)$ and computed by a weighted least squares method. Recent results\nshow the advantages of picking the sampling points at random according to a\nwell-chosen probability measure $\\mu$ that depends both on $V_m$ and $\\rho$.\nWith such a random design, the weighted least squares approximation is proved\nto be stable with high probability, and having precision comparable to that of\nthe exact $L^2(D,\\rho)$-orthonormal projection onto $V_m$, in a near-linear\nsampling regime $n\\sim{m\\log m}$. The present paper is motivated by the\nadaptive approximation context, in which one typically generates a nested\nsequence of spaces $(V_m)_{m\\geq1}$ with increasing dimension. Although the\nmeasure $\\mu=\\mu_m$ changes with $V_m$, it is possible to recycle the\npreviously generated samples by interpreting $\\mu_m$ as a mixture between\n$\\mu_{m-1}$ and an update measure $\\sigma_m$. Based on this observation, we\ndiscuss sequential sampling algorithms that maintain the stability and\napproximation properties uniformly over all spaces $V_m$. Our main result is\nthat the total number of computed sample at step $m$ remains of the order\n$m\\log{m}$ with high probability. Numerical experiments confirm this analysis. \n\n"}
{"id": "1805.11580", "contents": "Title: Algebraic Linearizations of Matrix Polynomials Abstract: We show how to construct linearizations of matrix polynomials\n$z\\mathbf{a}(z)\\mathbf{d}_0 + \\mathbf{c}_0$, $\\mathbf{a}(z)\\mathbf{b}(z)$,\n$\\mathbf{a}(z) + \\mathbf{b}(z)$ (when $\\mathrm{deg}\\left(\\mathbf{b}(z)\\right) <\n\\mathrm{deg}\\left(\\mathbf{a}(z)\\right)$), and\n$z\\mathbf{a}(z)\\mathbf{d}_0\\mathbf{b}(z) + \\mathbf{c_0}$ from linearizations of\nthe component parts, $\\mathbf{a}(z)$ and $\\mathbf{b}(z)$. This allows the\nextension to matrix polynomials of a new companion matrix construction. \n\n"}
{"id": "1805.12028", "contents": "Title: Significant Excess of ElectronLike Events in the MiniBooNE\n  Short-Baseline Neutrino Experiment Abstract: The MiniBooNE experiment at Fermilab reports results from an analysis of\n$\\nu_e$ appearance data from $12.84 \\times 10^{20}$ protons on target in\nneutrino mode, an increase of approximately a factor of two over previously\nreported results. A $\\nu_e$ charged-current quasielastic event excess of $381.2\n\\pm 85.2$ events ($4.5 \\sigma$) is observed in the energy range\n$200<E_\\nu^{QE}<1250$~MeV. Combining these data with the $\\bar \\nu_e$\nappearance data from $11.27 \\times 10^{20}$ protons on target in antineutrino\nmode, a total $\\nu_e$ plus $\\bar \\nu_e$ charged-current quasielastic event\nexcess of $460.5 \\pm 99.0$ events ($4.7 \\sigma$) is observed. If interpreted in\na two-neutrino oscillation model, ${\\nu}_{\\mu} \\rightarrow {\\nu}_e$, the best\noscillation fit to the excess has a probability of $21.1\\%$, while the\nbackground-only fit has a $\\chi^2$ probability of $6 \\times 10^{-7}$ relative\nto the best fit. The MiniBooNE data are consistent in energy and magnitude with\nthe excess of events reported by the Liquid Scintillator Neutrino Detector\n(LSND), and the significance of the combined LSND and MiniBooNE excesses is\n$6.0 \\sigma$. A two-neutrino oscillation interpretation of the data would\nrequire at least four neutrino types and indicate physics beyond the three\nneutrino paradigm.Although the data are fit with a two-neutrino oscillation\nmodel, other models may provide better fits to the data. \n\n"}
{"id": "1806.00477", "contents": "Title: Fractional Sensitivity Equation Method: Applications to Fractional Model\n  Construction Abstract: Fractional differential equations provide a tractable mathematical framework\nto describe anomalous behavior in complex physical systems, yet they introduce\nnew sensitive model parameters, i.e. derivative orders, in addition to model\ncoefficients. We formulate a sensitivity analysis of fractional models by\ndeveloping a fractional sensitivity equation method. We obtain the adjoint\nfractional sensitivity equations, in which we present a fractional operator\nassociated with logarithmic-power law kernel. We further construct a\ngradient-based optimization algorithm to compute an accurate parameter\nestimation in fractional model construction. We develop a fast, stable, and\nconvergent Petrov-Galerkin spectral method to numerically solve the coupled\nsystem of original fractional model and its corresponding adjoint fractional\nsensitivity equations. \n\n"}
{"id": "1806.00657", "contents": "Title: Properties of solutions of the \"naive\" functional Schroedinger equation\n  for QCD Abstract: In this paper we consider the simplest functional Schroedinger equation of a\nquantum field theory (in particular QCD) and study its solutions. We observe\nthat the solutions to this equation must possess a number of properties. Its\nTaylor coefficients are multivalued functions with rational and logarithmic\nbranchings and essential singularities of exponential type. These singularities\noccur along a locus defined by polynomial equations. The conditions we find\ndefine a class of functions that generalizes to multiple dimensions meromorphic\nfunctions with finite Nevanlinna type. We note that in perturbation theory\nthese functions have local asymptotics that is given by multidimensional\nconfluent hypergeometric functions in the sense of Gelfand-Kapranov-Zelevinsky. \n\n"}
{"id": "1806.00860", "contents": "Title: Optimizing weighted ensemble sampling of steady states Abstract: We propose parameter optimization techniques for weighted ensemble sampling\nof Markov chains in the steady-state regime. Weighted ensemble consists of\nreplicas of a Markov chain, each carrying a weight, that are periodically\nresampled according to their weights inside of each of a number of bins that\npartition state space. We derive, from first principles, strategies for\noptimizing the choices of weighted ensemble parameters, in particular the\nchoice of bins and the number of replicas to maintain in each bin. In a simple\nnumerical example, we compare our new strategies with more traditional ones and\nwith direct Monte Carlo. \n\n"}
{"id": "1806.01101", "contents": "Title: Analysis of parametric models - linear methods and approximations Abstract: Parametric models in vector spaces are shown to possess an associated linear\nmap. This linear operator leads directly to reproducing kernel Hilbert spaces\nand affine- / linear- representations in terms of tensor products. From the\nassociated linear map analogues of covariance or rather correlation operators\ncan be formed. The associated linear map in fact provides a factorisation of\nthe correlation. Its spectral decomposition, and the associated\nKarhunen-Lo\\`eve- or proper orthogonal decomposition in a tensor product follow\ndirectly. It is shown that all factorisations of a certain class are unitarily\nequivalent, as well as that every factorisation induces a different\nrepresentation, and vice versa. A completely equivalent spectral and\nfactorisation analysis can be carried out in kernel space. The relevance of\nthese abstract constructions is shown on a number of mostly familiar examples,\nthus unifying many such constructions under one theoretical umbrella. From the\nfactorisation one obtains tensor representations, which may be cascaded,\nleading to tensors of higher degree. When carried over to a discretised level\nin the form of a model order reduction, such factorisations allow very sparse\nlow-rank approximations which lead to very efficient computations especially in\nhigh dimensions. \n\n"}
{"id": "1806.01646", "contents": "Title: On Wiener - Hopf factorization of scalar polynomial Abstract: In the work we propose an algorithm for a Wiener -- Hopf factorization of\nscalar polynomials based on notions of indices and essential polynomials. The\nalgorithm uses computations with finite Toeplitz matrices and permits to obtain\ncoefficients of both factorization factors simultaneously. Computation aspects\nof the algorithm are considered. An a priory estimate for the condition number\nof the used Toeplitz matrices is obtained. Upper bounds for the accuracy of the\nfactorization factors are established. All estimates are effective. \n\n"}
{"id": "1806.03317", "contents": "Title: A 4 tonne demonstrator for large-scale dual-phase liquid argon time\n  projection chambers Abstract: A 10 kilo-tonne dual-phase liquid argon TPC is one of the detector options\nconsidered for the Deep Underground Neutrino Experiment (DUNE). The detector\ntechnology relies on amplification of the ionisation charge in ultra-pure argon\nvapour and oers several advantages compared to the traditional single-phase\nliquid argon TPCs. A 4.2 tonne dual-phase liquid argon TPC prototype, the\nlargest of its kind, with an active volume of 3x1x1 $m^3$ has been constructed\nand operated at CERN. In this paper we describe in detail the experimental\nsetup and detector components as well as report on the operation experience. We\nalso present the first results on the achieved charge amplification, prompt\nscintillation and electroluminescence detection, and purity of the liquid argon\nfrom analyses of a collected sample of cosmic ray muons. \n\n"}
{"id": "1806.04518", "contents": "Title: A Soliton Solution for the Central Dark Masses in 47- Tuc Globular\n  Cluster and Implications for the Axiverse Abstract: We offer a standing wave explanation for the rising proper motions of stars\nat the center of the globular cluster 47-Tucanae, amounting to $\\simeq 0.44\\%$\nof the total mass. We show this can be explained as a solitonic core of dark\nmatter composed of light bosons, $ m \\geq 10^{-18} eV $, corresponding to $\n\\leq 0.27 pc$, as an alternative to a single black hole (BH) or a concentration\nof stellar BH remnants proposed recently. This is particularly important as\nhaving a concentrated stellar BH remnant with the above radii is very\nchallenging without the heavy core since the three body encounters would\nprevent the BHs to be that concentrated. We propose this core develops from\ndark matter captured in the deep gravitational potential of this globular\ncluster as it orbits the dark halo of our galaxy. This boson may be evidence\nfor a second light axion, additional to a lighter boson of $10^{-22} eV$,\nfavored for the dominant dark matter implied by the large dark cores of dwarf\nspheroidal galaxies. The identification of two such light bosonic mass scales\nfavors the generic string theory prediction of a wide, discrete mass spectrum\nof axionic scalar fields. \n\n"}
{"id": "1806.05016", "contents": "Title: Performance of the triple GEM detector built using commercially\n  manufactured GEM foils in India Abstract: The Gas Electron Multiplier (GEM) detectors has been utilized for various\napplications due to their excellent spatial resolution, high rate capabilities\nand flexibility in design. The GEM detectors stand as a promising device to be\nused in nuclear and particle physics experiments. Many future experiments and\nupgrades are looking forward to use this technology leading to high demand of\nGEM foils. Until now, CERN is the only reliable manufacturer and distributor of\nGEM foils, but with technology transfer, few other industries across the globe\nhave started manufacturing these foils employing the same photo-lithographic\ntechnique. The Micropack Pvt. Ltd. is one such industry in India which produced\nfirst few $10~cm ~\\times~ 10~cm$ GEM foils, which were then distributed to few\ncollaborating partners for testing reliability and performance of foils before\nthey can be accepted by the scientific community. Characterization of three\nsuch foils have already been performed by studying their optical and electrical\nproperties. Using these foils a triple GEM detector has been built and various\nperformance characteristics have been measured. In this paper, we specifically\nreport measurements on gain, resolution and response uniformity, by utilizing\nlocal quality control set-ups existing at University of Delhi. \n\n"}
{"id": "1806.05896", "contents": "Title: Interior Point Methods and Preconditioning for PDE-Constrained\n  Optimization Problems Involving Sparsity Terms Abstract: PDE-constrained optimization problems with control or state constraints are\nchallenging from an analytical as well as numerical perspective. The\ncombination of these constraints with a sparsity-promoting $\\rm L^1$ term\nwithin the objective function requires sophisticated optimization methods. We\npropose the use of an Interior Point scheme applied to a smoothed reformulation\nof the discretized problem, and illustrate that such a scheme exhibits robust\nperformance with respect to parameter changes. To increase the potency of this\nmethod we introduce fast and efficient preconditioners which enable us to solve\nproblems from a number of PDE applications in low iteration numbers and CPU\ntimes, even when the parameters involved are altered dramatically. \n\n"}
{"id": "1806.06956", "contents": "Title: Diffusion generated methods for denoising target-valued images Abstract: We consider the inverse problem of denoising an image where each point\n(pixel) is an element of a target set, which we refer to as a target-valued\nimage. The target sets considered are either (i) a closed convex set of\nEuclidean space or (ii) a closed subset of the sphere such that the closest\npoint mapping is defined almost everywhere. The energy for the denoising\nproblem consists of an $L^2$-fidelity term which is regularized by the\nDirichlet energy. A relaxation of this energy, based on the heat kernel, is\nintroduced and the associated minimization problem is proven to be well-posed.\nWe introduce a diffusion generated method which can be used to efficiently find\nminimizers of this energy. We prove results for the stability and convergence\nof the method for both types of target sets. The method is demonstrated on a\nvariety of synthetic and test problems, with associated target sets given by\nthe semi-positive definite matrices, the cube, spheres, the orthogonal\nmatrices, and the real projective line. \n\n"}
{"id": "1806.09340", "contents": "Title: The SABRE project and the SABRE PoP Abstract: SABRE aims to directly measure the annual modulation of the dark matter\ninteraction rate with NaI(Tl) crystals. A modulation compatible with the\nstandard hypothesis in which our Galaxy is embedded in a dark matter halo has\nbeen measured by the DAMA experiment in the same target material. Other direct\ndetection experiments, using different target materials, seem to exclude the\ninterpretation of such modulation in the simplest scenario of WIMP-nucleon\nelastic scattering. The SABRE experiment aims to carry out an independent\nsearch with sufficient sensitivity to confirm or refute the DAMA claim. The\nSABRE concept and goal is to obtain a background rate of the order of 0.1\ncpd/kg/keVee in the energy region of interest. This challenging goal is\nachievable by operating high-purity crystals inside a liquid scintillator veto\nfor active background rejection. In addition, twin detectors will be located in\nthe northern and southern hemispheres to identify possible contributions to the\nmodulation from seasonal or site-related effects. The SABRE project includes an\ninitial Proof-of-Principle phase at LNGS (Italy), to assess the radio-purity of\nthe crystals and the efficiency of the liquid scintillator veto. This paper\ndescribes the general concept of SABRE and the expected sensitivity to WIMP\nannual modulation. \n\n"}
{"id": "1806.09344", "contents": "Title: Monte Carlo simulation of the SABRE PoP background Abstract: SABRE (Sodium-iodide with Active Background REjection) is a direct dark\nmatter search experiment based on an array of radio-pure NaI(Tl) crystals\nsurrounded by a liquid scintillator veto. Twin SABRE experiments in the\nNorthern and Southern Hemispheres will differentiate a dark matter signal from\nseasonal and local effects. The experiment is currently in a Proof-of-Principle\n(PoP) phase, whose goal is to demonstrate that the background rate is low\nenough to carry out an independent search for a dark matter signal, with\nsufficient sensitivity to confirm or refute the DAMA result during the\nfollowing full-scale experimental phase. The impact of background radiation\nfrom the detector materials and the experimental site needs to be carefully\ninvestigated, including both intrinsic and cosmogenically activated\nradioactivity. Based on the best knowledge of the most relevant sources of\nbackground, we have performed a detailed Monte Carlo study evaluating the\nexpected background in the dark matter search spectral region. The simulation\nmodel described in this paper guides the design of the full-scale experiment\nand will be fundamental for the interpretation of the measured background and\nhence for the extraction of a possible dark matter signal. \n\n"}
{"id": "1806.09483", "contents": "Title: Optimal stopping of McKean-Vlasov diffusions via regression on particle\n  systems Abstract: In this paper we study optimal stopping problems for nonlinear Markov\nprocesses driven by a McKean-Vlasov SDE and aim at solving them numerically by\nMonte Carlo. To this end we propose a novel regression algorithm based on the\ncorresponding particle system and prove its convergence. The proof of\nconvergence is based on perturbation analysis of a related linear regression\nproblem. The performance of the proposed algorithms is illustrated by a\nnumerical example. \n\n"}
{"id": "1806.09922", "contents": "Title: Adaptive SOR methods based on the Wolfe conditions Abstract: Because the expense of estimating the optimal value of the relaxation\nparameter in the successive over-relaxation (SOR) method is usually\nprohibitive, the parameter is often adaptively controlled. In this paper, new\nadaptive SOR methods are presented that are applicable to a variety of\nsymmetric positive definite linear systems and do not require additional\nmatrix-vector products when updating the parameter. To this end, we regard the\nSOR method as an algorithm for minimising a certain objective function, which\nyields an interpretation of the relaxation parameter as the step size following\na certain change of variables. This interpretation enables us to adaptively\ncontrol the step size based on some line search techniques, such as the Wolfe\nconditions. Numerical examples demonstrate the favourable behaviour of the\nproposed methods. \n\n"}
{"id": "1806.10797", "contents": "Title: $\\mathcal{H}_2(t_f)$ Optimality Conditions for a Finite-time Horizon Abstract: In this paper we establish the interpolatory model reduction framework for\noptimal approximation of MIMO dynamical systems with respect to the\n$\\mathcal{H}_2$ norm over a finite-time horizon, denoted as the\n$\\mathcal{H}_2(t_f)$ norm. Using the underlying inner product space, we derive\nthe interpolatory first-order necessary optimality conditions for approximation\nin the $\\mathcal{H}_2(t_f)$ norm. Then, we develop an algorithm, which yields a\nlocally optimal reduced model that satisfies the established\ninterpolation-based optimality conditions. We test the algorithm on various\nnumerical examples to illustrate its performance. \n\n"}
{"id": "1806.10912", "contents": "Title: Conceptualization, implementation, and commissioning of real-time\n  analysis in the High Level Trigger of the LHCb experiment Abstract: LHCb is a general purpose forward detector located at the Large Hadron\nCollider (LHC) at CERN. Although initially optimized for the study of hadrons\ncontaining beauty quarks, the better than expected performance of the detector\nhardware and trigger system allowed LHCb to perform precise measurements of\nparticle properties across a wide range of light hadron species produced at the\nLHC. The abundance of these light hadron species, and the large branching\nratios of many theoretically interesting decay modes, have made it mandatory\nfor LHCb to perform a large part of its data analysis within the experiment's\ntrigger system, that is to say in real-time. This thesis describes the\nconceptualization, development, and commissioning of real-time analysis in\nLHCb, culminating in the proof-of-concept measurements produced with the first\ndata collected in Run II of the LHC. It also describes mistakes made in these\nfirst real-time analyses, and their implication for the future of real-time\nanalysis at LHCb and elsewhere. \n\n"}
{"id": "1807.00086", "contents": "Title: Hybridized discontinuous Galerkin methods for wave propagation Abstract: We present the recent development of hybridizable and embedded discontinuous\nGalerkin (DG) methods for wave propagation problems in fluids, solids, and\nelectromagnetism. In each of these areas, we describe the methods, discuss\ntheir main features, display numerical results to illustrate their performance,\nand conclude with bibliography notes. The main ingredients in devising these DG\nmethods are (i) a local Galerkin projection of the underlying partial\ndifferential equations at the element level onto spaces of polynomials of\ndegree k to parametrize the numerical solution in terms of the numerical trace;\n(ii) a judicious choice of the numerical flux to provide stability and\nconsistency; and (iii) a global jump condition that enforces the continuity of\nthe numerical flux to obtain a global system in terms of the numerical trace.\nThese DG methods are termed hybridized DG methods, because they are amenable to\nhybridization (static condensation) and hence to more efficient\nimplementations. They share many common advantages of DG methods and possess\nsome unique features that make them well-suited to wave propagation problems. \n\n"}
{"id": "1807.01741", "contents": "Title: Sparse Compression of Expected Solution Operators Abstract: We show that the expected solution operator of prototypical linear elliptic\npartial differential operators with random coefficients is well approximated by\na computable sparse matrix. This result is based on a random localized\northogonal multiresolution decomposition of the solution space that allows both\nthe sparse approximate inversion of the random operator represented in this\nbasis as well as its stochastic averaging. The approximate expected solution\noperator can be interpreted in terms of classical Haar wavelets. When combined\nwith a suitable sampling approach for the expectation, this construction leads\nto an efficient method for computing a sparse representation of the expected\nsolution operator. \n\n"}
{"id": "1807.02356", "contents": "Title: Hybrid Monte Carlo methods for sampling probability measures on\n  submanifolds Abstract: Probability measures supported on submanifolds can be sampled by adding an\nextra momentum variable to the state of the system, and discretizing the\nassociated Hamiltonian dynamics with some stochastic perturbation in the extra\nvariable. In order to avoid biases in the invariant probability measures\nsampled by discretizations of these stochastically perturbed Hamiltonian\ndynamics, a Metropolis rejection procedure can be considered. The so-obtained\nscheme belongs to the class of generalized Hybrid Monte Carlo (GHMC)\nalgorithms. We show here how to generalize to GHMC a procedure suggested by\nGoodman, Holmes-Cerfon and Zappa for Metropolis random walks on submanifolds,\nwhere a reverse projection check is performed to enforce the reversibility of\nthe algorithm for large timesteps and hence avoid biases in the invariant\nmeasure. We also provide a full mathematical analysis of such procedures, as\nwell as numerical experiments demonstrating the importance of the reverse\nprojection check on simple toy examples. \n\n"}
{"id": "1807.04722", "contents": "Title: Proof of Color Octet NRQCD Factorization of P-Wave Heavy Quarkonium\n  Production at All Orders in Coupling Constant Abstract: Recently we have proved color octet NRQCD factorization of S-wave heavy\nquarkonium production at all orders in coupling constant at high energy\ncolliders in Eur. Phys. J. C76 (2016) 448. In this paper we extend this to\nprove color octet NRQCD factorization of P-wave heavy quarkonium production at\nall orders in coupling constant at high energy colliders. We find that while\nthe color octet NRQCD S-wave non-perturbative matrix element contains two\ngauge-links in the adjoint representation of SU(3), the color octet NRQCD\nP-wave non-perturbative matrix element contains four gauge-links in the\nfundamental representation of SU(3). \n\n"}
{"id": "1807.05346", "contents": "Title: Quantitative analysis of finite-difference approximations of\n  free-discontinuity problems Abstract: Motivated by applications to image reconstruction, in this paper we analyse a\n\\emph{finite-difference discretisation} of the Ambrosio-Tortorelli functional.\nDenoted by $\\varepsilon$ the elliptic-approximation parameter and by $\\delta$\nthe discretisation step-size, we fully describe the relative impact of\n$\\varepsilon$ and $\\delta$ in terms of $\\Gamma$-limits for the corresponding\ndiscrete functionals, in the three possible scaling regimes. We show, in\nparticular, that when $\\varepsilon$ and $\\delta$ are of the same order, the\nunderlying lattice structure affects the $\\Gamma$-limit which turns out to be\nan anisotropic free-discontinuity functional. \n\n"}
{"id": "1807.05680", "contents": "Title: High Rate RPC detector for LHC Abstract: The High Luminosity LHC (HL-LHC) phase is designed to increase by an order of\nmagnitude the amount of data to be collected by the LHC experiments. The\nforeseen gradual increase of the instantaneous luminosity of up to more than\ntwice its nominal value of $10\\times10^{34}\\ {\\rm cm}^{-1}{\\rm s}^{-2}$ during\nPhase I and Phase II of the LHC running, presents special challenges for the\nexperiments. The region with high pseudo rapidity ($\\eta$) region of the\nforward muon spectrometer ($2.4 > |\\eta| > 1.9$) is not equipped with RPC\nstations. The increase of the expected particles rate up to 2 kHz cm$^{-1}$ (\nincluding a safety factor 3 ) motivates the installation of RPC chambers to\nguarantee redundancy with the CSC chambers already present. The current CMS RPC\ntechnology cannot sustain the expected background level. A new generation of\nGlass-RPC (GRPC) using low-resistivity glass was proposed to equip the two most\nfar away of the four high $\\eta$ muon stations of CMS. In their single-gap\nversion they can stand rates of few kHz cm$^{-1}$. Their time precision of\nabout 1 ns can allow to reduce the noise contribution leading to an improvement\nof the trigger rate. The proposed design for large size chambers is examined\nand some preliminary results obtained during beam tests at Gamma Irradiation\nFacility (GIF++) and Super Proton Synchrotron (SPS) at CERN are shown. They\nwere performed to validate the capability of such detectors to support high\nirradiation environment with limited consequence on their efficiency. \n\n"}
{"id": "1807.05950", "contents": "Title: Adaptive space-time isogeometric analysis for parabolic evolution\n  problems Abstract: The paper is concerned with locally stabilized space-time IgA approximations\nto initial boundary value problems of the parabolic type. Originally, similar\nschemes (but weighted with a global mesh parameter) was presented and studied\nby U. Langer, M. Neumueller, and S. Moore (2016). The current work devises a\nlocalised version of this scheme and establishes coercivity, boundedness, and\nconsistency of the corresponding bilinear form. Using these fundamental\nproperties together with the corresponding approximation error estimates for\nB-splines, we show that the space-time IgA solutions generated by the new\nscheme satisfy asymptotically optimal a priori discretization error estimates.\nThe adaptive mesh refinement algorithm proposed in the paper is based on a\nposteriori error estimates of the functional type that has been rigorously\nstudied in earlier works by S. Repin (2002) and U. Langer, S. Matculevich, and\nS. Repin (2017). Numerical results presented in the second part of the paper\nconfirm the improved convergence of global approximation errors. Moreover,\nthese results also confirm the local efficiency of the error indicators\nproduced by the error majorants. \n\n"}
{"id": "1807.06236", "contents": "Title: Numerical Simulation of Microflows using Hermite Spectral Methods Abstract: We propose a Hermite spectral method for the spatially inhomogeneous\nBoltzmann equation. For the inverse-power-law model, we generalize an\napproximate quadratic collision operator defined in the normalized and\ndimensionless setting to an operator for arbitrary distribution functions. An\nefficient algorithm with a fast transform is introduced to discretize this new\ncollision operator. The method is tested for one-dimensional benchmark\nmicroflow problems. \n\n"}
{"id": "1807.08102", "contents": "Title: Loop-induced Neutrino Non-Standard Interactions Abstract: Non-Standard Interactions (NSI) of neutrinos may originate from models in\nwhich new particles interact with neutrinos. In scalar extensions of the SM,\nthe typical approach to obtain NSI requires Fierz transformations and charged\nHiggses, which suffer from strong constraints from collider searches or charged\nlepton flavor violation processes. We propose here an alternative approach to\ngenerate NSI, namely via loop processes. We show that such loop-induced NSI\nfrom secret neutrino interactions can reach sizes of ${\\cal O}(0.1\\sim1)$\ncompared to standard Fermi interaction. This approach can also give rise to\nneutrino-quark NSI. \n\n"}
{"id": "1807.08987", "contents": "Title: Commissioning and first results from the CMS phase 1 upgrade pixel\n  detector Abstract: The phase 1 upgrade of the CMS pixel detector has been designed to maintain\nthe tracking performance at instantaneous luminosities of $2 \\times 10^{34}\n\\mathrm{~cm}^{-2} \\mathrm{~s}^{-1}$. Both barrel and endcap disk systems now\nfeature one extra layer (4 barrel layers and 3 endcap disks), and a digital\nreadout that provides a large enough bandwidth to read out its 124M pixel\nchannels (87.7 percent more pixels compared to the previous system). The\nbackend control and readout systems have been upgraded accordingly from\nVME-based to micro-TCA-based ones. The detector is now also equipped with a\nbi-phase CO$_2$ cooling system that reduces the material budget in the tracking\nregion. The detector has been installed inside CMS at the start of 2017 and is\nnow taking data. These proceedings discuss experiences in the commissioning and\noperation of the CMS phase 1 pixel detector. The first results from the CMS\nphase 1 pixel detector with this year's LHC proton-proton collision data are\npresented. The new pixel detector outperforms the previous one in terms of hit\nresolution, tracking, and vertex resolution. \n\n"}
{"id": "1807.10090", "contents": "Title: A variational model for data fitting on manifolds by minimizing the\n  acceleration of a B\\'ezier curve Abstract: We derive a variational model to fit a composite B\\'ezier curve to a set of\ndata points on a Riemannian manifold. The resulting curve is obtained in such a\nway that its mean squared acceleration is minimal in addition to remaining\nclose the data points. We approximate the acceleration by discretizing the\nsquared second order derivative along the curve. We derive a closed-form,\nnumerically stable and efficient algorithm to compute the gradient of a\nB\\'ezier curve on manifolds with respect to its control points, expressed as a\nconcatenation of so-called adjoint Jacobi fields. Several examples illustrate\nthe capabilites and validity of this approach both for interpolation and\napproximation. The examples also illustrate that the approach outperforms\nprevious works tackling this problem. \n\n"}
{"id": "1807.10340", "contents": "Title: The DUNE Far Detector Interim Design Report, Volume 3: Dual-Phase Module Abstract: The DUNE IDR describes the proposed physics program and technical designs of\nthe DUNE far detector modules in preparation for the full TDR to be published\nin 2019. It is intended as an intermediate milestone on the path to a full TDR,\njustifying the technical choices that flow down from the high-level physics\ngoals through requirements at all levels of the Project. These design choices\nwill enable the DUNE experiment to make the ground-breaking discoveries that\nwill help to answer fundamental physics questions. Volume 3 describes the\ndual-phase module's subsystems, the technical coordination required for its\ndesign, construction, installation, and integration, and its organizational\nstructure. \n\n"}
{"id": "1808.00711", "contents": "Title: Using holistic event information in the trigger Abstract: In order to achieve the data rates proposed for the future Run 3 upgrade of\nthe LHCb detector, new processing models must be developed to deal with the\nincreased throughput. For this reason, we aim to investigate the feasibility of\npurely data-driven holistic methods, with the constraint of introducing minimal\ncomputational overhead, hence using only raw detector information. These\nfilters should be unbiased - having a neutral effect with respect to the\nstudied physics channels. In particular, the use of machine learning based\nmethods seems particularly suitable, potentially providing a natural\nformulation for heuristic-free, unbiased filters whose objective would be to\noptimize between throughput and bandwidth. \n\n"}
{"id": "1808.01471", "contents": "Title: On energy dissipation theory and numerical stability for time-fractional\n  phase field equations Abstract: For the time-fractional phase field models, the corresponding energy\ndissipation law has not been settled on both the continuous level and the\ndiscrete level. In this work, we shall address this open issue. More precisely,\nwe prove for the first time that the time-fractional phase field models indeed\nadmit an energy dissipation law of an integral type. In the discrete level, we\npropose a class of finite difference schemes that can inherit the theoretical\nenergy stability. Our discussion covers the time-fractional gradient systems,\nincluding the time-fractional Allen-Cahn equation, the time-fractional\nCahn-Hilliard equation, and the time-fractional molecular beam epitaxy models.\nNumerical examples are presented to confirm the theoretical results. Moreover,\na numerical study of the coarsening rate of random initial states depending on\nthe fractional parameter $\\alpha$ reveals that there are several coarsening\nstages for both time-fractional Cahn-Hilliard equation and time-fractional\nmolecular beam epitaxy model, while there exists a $-\\alpha/3$ power law\ncoarsening stage. \n\n"}
{"id": "1808.02365", "contents": "Title: Pricing Financial Derivatives using Radial Basis Function generated\n  Finite Differences with Polyharmonic Splines on Smoothly Varying Node Layouts Abstract: In this paper, we study the benefits of using polyharmonic splines and node\nlayouts with smoothly varying density for developing robust and efficient\nradial basis function generated finite difference (RBF-FD) methods for pricing\nof financial derivatives. We present a significantly improved RBF-FD scheme and\nsuccessfully apply it to two types of multidimensional partial differential\nequations in finance: a two-asset European call basket option under the\nBlack--Scholes--Merton model, and a European call option under the Heston\nmodel. We also show that the performance of the improved method is equally high\nwhen it comes to pricing American options. By studying convergence,\ncomputational performance, and conditioning of the discrete systems, we show\nthe superiority of the introduced approaches over previously used versions of\nthe RBF-FD method in financial applications. \n\n"}
{"id": "1808.04932", "contents": "Title: Sparse Harmonic Transforms: A New Class of Sublinear-time Algorithms for\n  Learning Functions of Many Variables Abstract: We develop fast and memory efficient numerical methods for learning functions\nof many variables that admit sparse representations in terms of general bounded\northonormal tensor product bases. Such functions appear in many applications\nincluding, e.g., various Uncertainty Quantification(UQ) problems involving the\nsolution of parametric PDE that are approximately sparse in Chebyshev or\nLegendre product bases. We expect that our results provide a starting point for\na new line of research on sublinear-time solution techniques for UQ\napplications of the type above which will eventually be able to scale to\nsignificantly higher-dimensional problems than what are currently\ncomputationally feasible.\n  More concretely, let $B$ be a finite Bounded Orthonormal Product Basis (BOPB)\nof cardinality $|B|=N$. We will develop methods that approximate any function\n$f$ that is sparse in the BOPB, that is, $f:\\mathcal{D}\\subset R^D\\rightarrow\nC$ of the form $f(\\mathbf{x})=\\sum_{b\\in S}c_b\\cdot b(\\mathbf{x})$ with\n$S\\subset B$ of cardinality $|S| =s\\ll N$. Our method has a runtime of just\n$(s\\log N)^{O(1)}$, uses only $(s\\log N)^{O(1)}$ function evaluations on a\nfixed and nonadaptive grid, and not more than $(s\\log N)^{O(1)}$ bits of\nmemory.\n  For $s\\ll N$, the runtime $(s\\log N)^{O(1)}$ will be less than what is\nrequired to simply enumerate the elements of the basis $B$; thus our method is\nthe first approach applicable in a general BOPB framework that falls into the\nclass referred to as \"sublinear-time\". This and the similarly reduced sample\nand memory requirements set our algorithm apart from previous works based on\nstandard compressive sensing algorithms such as basis pursuit which typically\nstore and utilize full intermediate basis representations of size $\\Omega(N)$. \n\n"}
{"id": "1808.07802", "contents": "Title: Reweighting a parton shower using a neural network: the final-state case Abstract: The use of QCD calculations that include the resummation of soft-collinear\nlogarithms via parton-shower algorithms is currently not possible in PDF fits\ndue to the high computational cost of evaluating observables for each variation\nof the PDFs. Unfortunately the interpolation methods that are otherwise applied\nto overcome this issue are not readily generalised to all-order parton-shower\ncontributions. Instead, we propose an approximation based on training a neural\nnetwork to predict the effect of varying the input parameters of a parton\nshower on the cross section in a given observable bin, interpolating between\nthe variations of a training data set. This first publication focuses on\nproviding a proof-of-principle for the method, by varying the shower dependence\non $\\alpha_\\text{S}$ for both a simplified shower model and a complete shower\nimplementation for three different observables, the leading emission scale, the\nnumber of emissions and the Thrust event shape. The extension to the PDF\ndependence of the initial-state shower evolution that is needed for the\napplication to PDF fits is left to a forthcoming publication. \n\n"}
{"id": "1808.08050", "contents": "Title: Multiple multivariate subdivision schemes: matrix and operator\n  approaches Abstract: This paper extends the matrix based approach to the setting of multiple\nsubdivision schemes studied in [Sauer 2012]. Multiple subdivision schemes, in\ncontrast to stationary and non-stationary schemes, allow for level dependent\nsubdivision weights and for level dependent choice of the dilation matrices.\nThe latter property of multiple subdivision makes the standard definition of\nthe transition matrices, crucial ingredient of the matrix approach in the\nstationary and non-stationary settings, inapplicable. We show how to avoid this\nobstacle and characterize the convergence of multiple subdivision schemes in\nterms of the joint spectral radius of certain square matrices derived from\nsubdivision weights. We illustrate our results with several examples. \n\n"}
{"id": "1808.08645", "contents": "Title: Bernstein-Bezier weight-adjusted discontinuous Galerkin methods for wave\n  propagation in heterogeneous media Abstract: This paper presents an efficient discontinuous Galerkin method to simulate\nwave propagation in heterogeneous media with sub-cell variations. This method\nis based on a weight-adjusted discontinuous Galerkin method (WADG), which\nachieves high order accuracy for arbitrary heterogeneous media. However, the\ncomputational cost of WADG grows rapidly with the order of approximation. In\nthis work, we propose a Bernstein-B\\'ezier weight-adjusted discontinuous\nGalerkin method (BBWADG) to address this cost. By approximating sub-cell\nheterogeneities by a fixed degree polynomial, the main steps of WADG can be\nexpressed as polynomial multiplication and $L^2$ projection, which we carry out\nusing fast Bernstein algorithms. The proposed approach reduces the overall\ncomputational complexity from $O(N^{2d})$ to $O(N^{d+1})$ in $d$ dimensions.\nNumerical experiments illustrate the accuracy of the proposed approach, and\ncomputational experiments for a GPU implementation of BBWADG verify that this\ntheoretical complexity is achieved in practice. \n\n"}
{"id": "1808.09142", "contents": "Title: An alternating direction implicit spectral method for solving two\n  dimensional multi-term time fractional mixed diffusion and diffusion-wave\n  equations Abstract: In this paper, we consider the initial boundary value problem of the two\ndimensional multi-term time fractional mixed diffusion and diffusion-wave\nequations. An alternating direction implicit (ADI) spectral method is developed\nbased on Legendre spectral approximation in space and finite difference\ndiscretization in time. Numerical stability and convergence of the schemes are\nproved, the optimal error is $O(N^{-r}+\\tau^2)$, where $N, \\tau, r$ are the\npolynomial degree, time step size and the regularity of the exact solution,\nrespectively. We also consider the non-smooth solution case by adding some\ncorrection terms. Numerical experiments are presented to confirm our\ntheoretical analysis. These techniques can be used to model diffusion and\ntransport of viscoelastic non-Newtonian fluids. \n\n"}
{"id": "1808.10747", "contents": "Title: Geometry of the Phase Retrieval Problem Abstract: One of the most powerful approaches to imaging at the nanometer or\nsubnanometer length scale is coherent diffraction imaging using X-ray sources.\nFor amorphous (non-crystalline) samples, the raw data can be interpreted as the\nmodulus of the continuous Fourier transform of the unknown object. Making use\nof prior information about the sample (such as its support), a natural goal is\nto recover the phase through computational means, after which the unknown\nobject can be visualized at high resolution. While many algorithms have been\nproposed for this phase retrieval problem, careful analysis of its\nwell-posedness has received relatively little attention. In this paper, we show\nthat the problem is, in general, not well-posed and describe some of the\nunderlying issues that are responsible for the ill-posedness. We then show how\nthis analysis can be used to develop experimental protocols that lead to better\nconditioned inverse problems. \n\n"}
{"id": "1809.00354", "contents": "Title: The detectors of the SHiP experiment at CERN Abstract: SHiP is a proposed general purpose fixed target facility at the CERN SPS\naccelerator. The main focus will be the physics of the Hidden Sector,\n\\textit{i.e.} search for heavy neutrinos, dark photons and other long lived\nvery weakly interacting particles. A dedicated detector, based on a long vacuum\ntank followed by a spectrometer and particle identification detectors, will\nallow probing a variety of models with exotic particles in the GeV mass range.\nAnother dedicated detector will allow the study of Standard Model neutrino\ncross-sections and angular distribution, and allow detection of light dark\nmatter with world leading sensitivity. \n\n"}
{"id": "1809.05643", "contents": "Title: Kernel-based collocation methods for Heath-Jarrow-Morton models with\n  Musiela parametrization Abstract: We propose kernel-based collocation methods for numerical solutions to\nHeath-Jarrow-Morton models with Musiela parametrization. The methods can be\nseen as the Euler-Maruyama approximation of some finite dimensional stochastic\ndifferential equations, and allow us to compute the derivative prices by the\nusual Monte Carlo methods. We derive a bound on the rate of convergence under\nsome decay condition on the inverse of the interpolation matrix and some\nregularity conditions on the volatility functionals. \n\n"}
{"id": "1809.05986", "contents": "Title: Search for neutrinoless double-beta decay with SNO+ Abstract: The SNO+ experiment, located in SNOLAB, 2 kilometers underground in the\nCreighton mine, near Sudbury, Canada, is a large scale neutrino detector whose\nmain purpose is to search for neutrinoless double-beta decay and thus probe the\nMajorana nature of the neutrino. With 780 tons of liquid scintillator loaded\nwith tellurium, SNO+ aims at exploring the Majorana neutrino mass parameter\nspace down to the inverted mass hierarchy region. The versatility of the SNO+\ndetector also allows it to detect solar and reactor neutrinos, provide a\nmeasurement of the geoneutrino flux, detect galactic core-collapse supernovae\nand perform nucleon decay searches. The SNO+ experiment is currently taking\ndata with a detector fully filled with ultrapure water. The detector will be\ncompletely filled with liquid scintillator in the coming months and\nsubsequently loaded with tellurium. \n\n"}
{"id": "1809.06361", "contents": "Title: Radiation damage of SiPMs Abstract: The current understanding of radiation tollerance of Silicon Photomultipliers\n(SiPMs) is reviewd. Radiation damage in silicon sensors is briefly introduced,\nsurface and bulk effects are separately addressed. Results on the operation of\nirradiated SiPMs with X-ray, gamma, electron, proton and neutron sources are\npresented. The most critical effect of radiation on SiPMs is the increase of\ndark count rate, which makes it impossible to resolve signals generated by a\nsingle photon from the noise. Methods to characterize irradiated SiPMs after\ntheir single photo-electron resolution is lost are discussed. Due to the\nimportant similarity in the operation below the breakdown voltage, also older\nstudies on radiadion damage of avalange photodiodes (APD) are reviewed.\nFinally, ideas are presented on how to approach the development of radiation\nhard SiPMs in the future. \n\n"}
{"id": "1809.09966", "contents": "Title: Linear Whitham-Boussinesq modes in channels of constant cross-section Abstract: We study normal modes for the linear water wave problem in infinite straight\nchannels of bounded constant cross-section. Our goal is to compare semianalytic\nnormal mode solutions known in the literature for special triangular\ncross-sections, namely isosceles triangles of equal angle of 45 and 60 degrees,\nsee Lamb [17], Macdonald [19] , Greenhill [11], Packham [23], and Groves [12],\nto numerical solutions obtained using approximations of the non-local\nDirichlet-Neumann operator for linear waves, specifically an ad-hoc\napproximation proposed in [25], and a first order truncation of the systematic\ndepth expansion by Craig, Guyenne, Nicholls, and Sulem [6]. We consider cases\nof transverse (i.e. 2-D) modes and longitudinal modes, i.e. 3-D modes with\nsinusoidal dependence in the longitudinal direction. The triangular geometries\nconsidered have slopping beach boundaries that should in principle limit the\napplicability of the approximate Dirichlet-Neumann operators. We nevertheless\nsee that the approximate operators give remarkably close results for transverse\neven modes, while for odd transverse modes we have some discrepancies near the\nboundary. In the case of longitudinal modes, where the theory only yields even\nmodes, the different approximate operators show more discrepancies for the\nfirst two longitudinal modes and better agreement for higher modes. The ad-hoc\napproximation is generally closer to exact modes away from the boundary. \n\n"}
{"id": "1809.10255", "contents": "Title: Hessian-based sampling for high-dimensional model reduction Abstract: In this work we develop a Hessian-based sampling method for the construction\nof goal-oriented reduced order models with high-dimensional parameter inputs.\nModel reduction is known very challenging for high-dimensional parametric\nproblems whose solutions also live in high-dimensional manifolds. However, the\nmanifold of some quantity of interest (QoI) depending on the parametric\nsolutions may be low-dimensional. We use the Hessian of the QoI with respect to\nthe parameter to detect this low-dimensionality, and draw training samples by\nprojecting the high-dimensional parameter to a low-dimensional subspace spanned\nby the eigenvectors of the Hessian corresponding to its dominating eigenvalues.\nInstead of forming the full Hessian, which is computationally intractable for a\nhigh-dimensional parameter, we employ a randomized algorithm to efficiently\ncompute the dominating eigenpairs of the Hessian whose cost does not depend on\nthe nominal dimension of the parameter but only on the intrinsic dimension of\nthe QoI. We demonstrate that the Hessian-based sampling leads to much smaller\nerrors of the reduced basis approximation for the QoI compared to a random\nsampling for a diffusion equation with random input obeying either uniform or\nGaussian distributions. \n\n"}
{"id": "1809.10585", "contents": "Title: Fast QR decomposition of HODLR matrices Abstract: The efficient and accurate QR decomposition for matrices with hierarchical\nlow-rank structures, such as HODLR and hierarchical matrices, has been\nchallenging. Existing structure-exploiting algorithms are prone to numerical\ninstability as they proceed indirectly, via Cholesky decompositions or a block\nGram-Schmidt procedure. For a highly ill-conditioned matrix, such approaches\neither break down in finite-precision arithmetic or result in significant loss\nof orthogonality. Although these issues can sometimes be addressed by\nregularization and iterative refinement, it would be more desirable to have an\nalgorithm that avoids these detours and is numerically robust to\nill-conditioning. In this work, we propose such an algorithm for HODLR\nmatrices. It achieves accuracy by utilizing Householder reflectors. It achieves\nefficiency by utilizing fast operations in the HODLR format in combination with\ncompact WY representations and the recursive QR decomposition by Elmroth and\nGustavson. Numerical experiments demonstrate that our newly proposed algorithm\nis robust to ill-conditioning and capable of achieving numerical orthogonality\ndown to the level of roundoff error. \n\n"}
{"id": "1809.10603", "contents": "Title: The KATRIN Neutrino Mass Measurement: Experiment, Status, and Outlook Abstract: The Karlsruhe Tritium Neutrino (KATRIN) experiment will provide a measurement\nof the effective electron-neutrino mass, $m(\\nu_e)$, based on a precision\nmeasurement of the tritium beta decay spectrum near its endpoint. The effective\nmass is an average of the neutrino mass eigenvalues $m_i$ weighted by the\nflavor-mass mixing parameters $U_{ei}$ according to the relation $m^2(\\nu_e)=\n\\sum_{i=1}^3 |U_{ei} |^2 m_i^2$. The KATRIN apparatus uses a windowless gaseous\ntritium source (WGTS) and a spectrometer based on the MAC-E filter concept to\nmeasure the beta energy spectrum. The KATRIN program is designed to reach a\nmass sensitivity of 0.2~eV (90\\% C.L.). The collaboration has completed a\nseries of commissioning measurements and is moving into the first running of\ntritium. The KATRIN measurement technique, early commissioning results, and the\nfuture outlook will be presented. \n\n"}
{"id": "1810.00688", "contents": "Title: A Virtual Element Method for transversely isotropic elasticity Abstract: This work studies the approximation of plane problems concerning transversely\nisotropic elasticity, using a low-order Virtual Element Method (VEM), with a\nfocus on near-incompressibility and near-inextensibility. Additionally, both\nhomogeneous problems, in which the plane of isotropy is fixed; and\nnon-homogeneous problems, in which the fibre direction defining the isotropy\nplane varies with position, are explored. In the latter case various options\nare considered for approximating the non-homogeneous fibre directions at\nelement level. Through a range of numerical examples the VEM approximations are\nshown to be robust and locking-free for several element geometries and for\nfibre directions that correspond to mild and strong non-homogeneity. \n\n"}
{"id": "1810.01702", "contents": "Title: Nonparametric statistical inference for drift vector fields of\n  multi-dimensional diffusions Abstract: The problem of determining a periodic Lipschitz vector field $b=(b_1, \\dots,\nb_d)$ from an observed trajectory of the solution $(X_t: 0 \\le t \\le T)$ of the\nmulti-dimensional stochastic differential equation \\begin{equation*} dX_t =\nb(X_t)dt + dW_t, \\quad t \\geq 0, \\end{equation*} where $W_t$ is a standard\n$d$-dimensional Brownian motion, is considered. Convergence rates of a\npenalised least squares estimator, which equals the maximum a posteriori (MAP)\nestimate corresponding to a high-dimensional Gaussian product prior, are\nderived. These results are deduced from corresponding contraction rates for the\nassociated posterior distributions. The rates obtained are optimal up to\nlog-factors in $L^2$-loss in any dimension, and also for supremum norm loss\nwhen $d \\le 4$. Further, when $d \\le 3$, nonparametric Bernstein-von Mises\ntheorems are proved for the posterior distributions of $b$. From this we deduce\nfunctional central limit theorems for the implied estimators of the invariant\nmeasure $\\mu_b$. The limiting Gaussian process distributions have a covariance\nstructure that is asymptotically optimal from an information-theoretic point of\nview. \n\n"}
{"id": "1810.01822", "contents": "Title: Numerical Approximation of Stochastic Time-Fractional Diffusion Abstract: We develop and analyze a numerical method for stochastic time-fractional\ndiffusion driven by additive fractionally integrated Gaussian noise. The model\ninvolves two nonlocal terms in time, i.e., a Caputo fractional derivative of\norder $\\alpha\\in(0,1)$, and fractionally integrated Gaussian noise (with a\nRiemann-Liouville fractional integral of order $\\gamma \\in[0,1]$ in the front).\nThe numerical scheme approximates the model in space by the Galerkin method\nwith continuous piecewise linear finite elements and in time by the classical\nGr\\\"unwald-Letnikov method, and the noise by the $L^2$-projection. Sharp strong\nand weak convergence rates are established, using suitable nonsmooth data error\nestimates for the deterministic counterpart. Numerical results are presented to\nsupport the theoretical findings. \n\n"}
{"id": "1810.02818", "contents": "Title: Copositivity criteria, scalar mass eigenstates, and custodial symmetry\n  parameter $\\Delta \\rho$ for the $S_3 \\otimes \\mathbb{Z}_2$ model Abstract: We present the copositivity criteria for the scalar sector of our $S_3\n\\otimes \\mathbb{Z}_2$ model, which ensures that it is bounded from below. We\nalso show the scalar mass eigenstates, and identify the Standard Model Higgs\nboson among these by imposing that its Yukawa couplings are the same in our\nmodel and the Standard Model. The $\\Delta \\rho$ parameter, related to the\ncustodial symmetry, is calculated as well. \n\n"}
{"id": "1810.03677", "contents": "Title: A highly granular calorimeter concept for long baseline near detectors Abstract: Future long baseline neutrino experiments such as the DUNE experiment under\nconstruction at Fermilab will perform precision measurements of neutrino\noscillations, including the potential for the discovery of CP violation in the\nlepton sector. These measurements require an understanding of the unoscillated\nneutrino beam with unprecedented accuracy. This will be provided by complex\nnear detectors which consist of different subsystems including tracking\nelements and electromagnetic calorimetry. A high granularity in the\ncalorimeter, provided by scintillator tiles with SiPM readout as used in the\nCALICE analog hadron calorimeter, provides the capability for direction\nreconstruction of photon showers, which can be used to determine the decay\npositions of neutral pions. This can enable the association of neutral pions to\nneutrino interactions in the tracker volume, improving the event reconstruction\nof the near detector. Beyond photon and electron reconstruction, the\ncalorimeter also provides sensitivity to neutrons. In this presentation, we\nwill discuss a simulation study exploring the potential of high granularity for\nthe electromagnetic calorimeter of the DUNE near detector. Particular emphasis\nwill be placed on the combination with a high pressure TPC as tracking\ndetector, which puts particularly stringent requirements on the calorimeter.\nThe dependence of the projected detector performance on granularity, absorber\nmaterial and absorber thickness as well as geometric arrangement satisfying the\nconstraints of the TPC are explored. \n\n"}
{"id": "1810.05137", "contents": "Title: Hypocoercivity-compatible finite element methods for the long-time\n  computation of Kolmogorov's equation Abstract: This work is concerned with the development of a family of Galerkin finite\nelement methods for the classical Kolmogorov's equation. Kolmogorov's equation\nserves as a sufficiently rich, for our purposes, model problem for kinetic-type\nequations and is characterised by diffusion in one of the two (or three)\nspatial directions only. Nonetheless, its solution admits typically decay\nproperties to some long time equilibrium, depending on closure by suitable\nboundary/decay-at-infinity conditions. A key attribute of the proposed family\nof methods is that they also admit similar decay properties at the\n(semi)discrete level for very general families of triangulations. The method\nconstruction uses ideas by the general theory of hypocoercivity developed by\nVillani [23], along with judicious choice of numerical flux functions. These\ndevelopments turn out to be sufficient to imply that the proposed finite\nelement methods admit a priori error bounds with constants independent of the\nfinal time, despite Kolmogorov equation's degenerate diffusion nature. Thus,\nthe new methods provably allow for robust error analysis for final times\ntending to infinity. The extension to three spatial dimensions is also briefly\ndiscussed. \n\n"}
{"id": "1810.07131", "contents": "Title: Fast and accurate algorithms for the computation of spherically\n  symmetric nonlocal diffusion operators on lattices Abstract: We present a unified treatment of the Fourier spectra of spherically\nsymmetric nonlocal diffusion operators. We develop numerical and analytical\nresults for the class of kernels with weak algebraic singularity as the\ndistance between source and target tends to $0$. Rapid algorithms are derived\nfor their Fourier spectra with the computation of each eigenvalue independent\nof all others. The algorithms are trivially parallelizable, capable of\nleveraging more powerful compute environments, and the accuracy of the\neigenvalues is individually controllable. The algorithms include a Maclaurin\nseries and a full divergent asymptotic series valid for any $d$ spatial\ndimensions. Using Drummond's sequence transformation, we prove linear\ncomplexity recurrence relations for degree-graded sequences of numerators and\ndenominators in the rational approximations to the divergent asymptotic series.\nThese relations are important to ensure that the algorithms are efficient, and\nalso increase the numerical stability compared with the conventional algorithm\nwith quadratic complexity. \n\n"}
{"id": "1810.07645", "contents": "Title: On the convergence in $H^1$-norm for the fractional Laplacian Abstract: We consider the numerical solution of the fractional Laplacian of index\n$s\\in(1/2,1)$ in a bounded domain $\\Omega$ with homogeneous boundary\nconditions. Its solution a priori belongs to the fractional order Sobolev space\n${\\widetilde H}^s(\\Omega)$. For the Dirichlet problem and under suitable\nassumptions on the data, it can be shown that its solution is also in\n$H^1(\\Omega)$. In this case, if one uses the standard Lagrange finite element\nto discretize the problem, then both the exact and the computed solution belong\nto $H^1(\\Omega)$. A natural question is then whether one can obtain error\nestimates in $H^1(\\Omega)$-norm, in addition to the classical ones that can be\nderived in the ${\\widetilde H}^s(\\Omega)$ energy norm. We address this issue,\nand in particular we derive error estimates for the Lagrange finite element\nsolutions on both quasi-uniform and graded meshes. \n\n"}
{"id": "1810.08686", "contents": "Title: Seismic Inversion and the Data Normalization for Optimal Transport Abstract: Full waveform inversion (FWI) has recently become a favorite technique for\nthe inverse problem of finding properties in the earth from measurements of\nvibrations of seismic waves on the surface. Mathematically, FWI is PDE\nconstrained optimization where model parameters in a wave equation are adjusted\nsuch that the misfit between the computed and the measured dataset is\nminimized. In a sequence of papers, we have shown that the quadratic\nWasserstein distance from optimal transport is to prefer as misfit functional\nover the standard $L^2$ norm. Datasets need however first to be normalized\nsince seismic signals do not satisfy the requirements of optimal transport.\nThere has been a puzzling contradiction in the results. Normalization methods\nthat satisfy theorems pointing to ideal properties for FWI have not performed\nwell in practical computations, and other scaling methods that do not satisfy\nthese theorems have performed much better in practice. In this paper, we will\nshed light on this issue and resolve this contradiction. \n\n"}
{"id": "1810.09099", "contents": "Title: Wigner distributions and GTMDs in a proton using light-front\n  quark-diquark model Abstract: We investigate the Wigner distributions and generalized transverse\nmomentum-dependent distributions (GTMDs) for $u$ and $d$ quarks in the proton\nby using light-front quark-diquark model. We consider the contribution of\nscalar and axial-vector diquark having spin-0 and spin-1 respectively. We take\ndifferent polarization configurations of quark and proton to calculate the\nWigner distributions. The Wigner distributions are studied in the\nimpact-parameter space, momentum space and mixed space for $u$ and $d$ quarks\nin the proton. We also study the relation of GTMDs with longitudinal momentum\nfraction carried by the active quark $x$ for different values of $\\zeta$\n(skewness) which is defined as the longitudinal momentum transferred to the\nproton. Further, we study the GTMDs in the relation with $x$ for zero skewness\n$(\\zeta=0)$ at different values of quark transverse momentum $\\textbf{p}_\\perp$\nas well as at different values of total momentum transferred to the proton\n${\\bf \\Delta}_\\perp$. \n\n"}
{"id": "1810.09885", "contents": "Title: An embedded corrector problem for homogenization. Part II: Algorithms\n  and discretization Abstract: This contribution is the numerically oriented companion article of the work\n[E. Canc\\`es, V. Ehrlacher, F. Legoll, B. Stamm and S. Xiang, arxiv preprint\n1807.05131]. We focus here on the numerical resolution of the embedded\ncorrector problem introduced in [E. Canc\\`es, V. Ehrlacher, F. Legoll and B.\nStamm, CRAS 2015; E. Canc\\`es, V. Ehrlacher, F. Legoll, B. Stamm and S. Xiang,\narxiv preprint 1807.05131] in the context of homogenization of diffusion\nequations. Our approach consists in considering a corrector-type problem, posed\non the whole space, but with a diffusion matrix which is constant outside some\nbounded domain. In [E. Canc\\`es, V. Ehrlacher, F. Legoll, B. Stamm and S.\nXiang, arxiv preprint 1807.05131], we have shown how to define three\napproximate homogenized diffusion coefficients on the basis of the embedded\ncorrector problems. We have also proved that these approximations all converge\nto the exact homogenized coefficients when the size of the bounded domain\nincreases.\n  We show here that, under the assumption that the diffusion matrix is\npiecewise constant, the corrector problem to solve can be recast as an integral\nequation. In case of spherical inclusions with isotropic materials, we explain\nhow to efficiently discretize this integral equation using spherical harmonics,\nand how to use the fast multipole method (FMM) to compute the resulting\nmatrix-vector products at a cost which scales only linearly with respect to the\nnumber of inclusions. Numerical tests illustrate the performance of our\napproach in various settings. \n\n"}
{"id": "1810.10299", "contents": "Title: Higher order stable generalized finite element method for the elliptic\n  eigenvalue problem with an interface in 1D Abstract: We study the generalized finite element methods (GFEMs) for the second-order\nelliptic eigenvalue problem with an interface in 1D. The linear stable\ngeneralized finite element methods (SGFEM) were recently developed for the\nelliptic source problem with interfaces. We first generalize SGFEM to arbitrary\norder elements and establish the optimal error convergence of the approximate\nsolutions for the elliptic source problem with an interface. We then apply the\nabstract theory of spectral approximation of compact operators to establish the\nerror estimation for the eigenvalue problem with an interface. The error\nestimations on eigenpairs strongly depend on the estimation of the discrete\nsolution operator for the source problem. We verify our theoretical findings in\nvarious numerical examples including both source and eigenvalue problems. \n\n"}
{"id": "1810.12817", "contents": "Title: Nonlocal $p$-Laplacian Variational problems on graphs Abstract: In this paper, we study a nonlocal variational problem which consists of\nminimizing in $L^2$ the sum of a quadratic data fidelity and a regularization\nterm corresponding to the $L^p$-norm of the nonlocal gradient. In particular,\nwe study convergence of the numerical solution to a discrete version of this\nnonlocal variational problem to the unique solution of the continuum one. To do\nso, we derive an error bound and highlight the role of the initial data and the\nkernel governing the nonlocal interactions. When applied to variational problem\non graphs, this error bound allows us to show the consistency of the\ndiscretized variational problem as the number of vertices goes to infinity.\nMore precisely, for networks in convergent graph sequences (simple and weighted\ndeterministic dense graphs as well as random inhomogeneous graphs), we prove\nconvergence and provide rate of convergence of solutions for the discrete\nmodels to the solution of the continuum problem as the number of vertices\ngrows. \n\n"}
{"id": "1811.01264", "contents": "Title: Monolithic mixed-dimensional multigrid methods for single-phase flow in\n  fractured porous media Abstract: This paper deals with the efficient numerical solution of single-phase flow\nproblems in fractured porous media. A monolithic multigrid method is proposed\nfor solving two-dimensional arbitrary fracture networks with vertical and/or\nhorizontal possibly intersecting fractures. The key point is to combine\ntwo-dimensional multigrid components (smoother and inter-grid transfer\noperators) in the porous matrix with their one-dimensional counterparts within\nthe fractures, giving rise to a mixed-dimensional multigrid method. This\ncombination seems to be optimal since it provides an algorithm whose\nconvergence matches the multigrid convergence factor for solving the Darcy\nproblem. Several numerical experiments are presented to demonstrate the\nrobustness of the monolithic mixed-dimensional multigrid method with respect to\nthe permeability of the fractures, the grid size and the number of fractures in\nthe network. \n\n"}
{"id": "1811.01725", "contents": "Title: Lower and upper bounds for strong approximation errors for numerical\n  approximations of stochastic heat equations Abstract: Optimal upper and lower error estimates for strong full-discrete numerical\napproximations of the stochastic heat equation driven by space-time white noise\nare obtained. In particular, we establish the optimality of strong convergence\nrates for full-discrete approximations of stochastic Allen-Cahn equations with\nspace-time white noise which have recently been obtained in [Becker, S., Gess,\nB., Jentzen, A., and Kloeden, P. E., Strong convergence rates for explicit\nspace-time discrete numerical approximations of stochastic Allen-Cahn\nequations. arXiv:1711.02423 (2017)]. \n\n"}
{"id": "1811.03454", "contents": "Title: The Low Rank Approximations and Ritz Values in LSQR For Linear Discrete\n  Ill-Posed Problems Abstract: LSQR and its mathematically equivalent CGLS have been popularly used over the\ndecades for large-scale linear discrete ill-posed problems, where the iteration\nnumber $k$ plays the role of the regularization parameter. It has been long\nknown that if the Ritz values in LSQR converge to the large singular values of\n$A$ in natural order until its semi-convergence then LSQR must have the same\nthe regularization ability as the truncated singular value decomposition (TSVD)\nmethod and can compute a 2-norm filtering best possible regularized solution.\nHowever, hitherto there has been no definitive rigorous result on the\napproximation behavior of the Ritz values in the context of ill-posed problems.\nIn this paper, for severely, moderately and mildly ill-posed problems, we give\naccurate solutions of the two closely related fundamental and highly\nchallenging problems on the regularization of LSQR: (i) How accurate are the\nlow rank approximations generated by Lanczos bidiagonalization? (ii) Whether or\nnot the Ritz values involved in LSQR approximate the large singular values of\n$A$ in natural order? We also show how to judge the accuracy of low rank\napproximations reliably during computation without extra cost. Numerical\nexperiments confirm our results. \n\n"}
{"id": "1811.04598", "contents": "Title: Weighted block compressed sensing for parametrized function\n  approximation Abstract: In this paper we extend results taken from compressed sensing to recover\nHilbert-space valued vectors. This is an important problem in parametric\nfunction approximation in particular when the number of parameters is high. By\nexpanding our target functions in a polynomial chaos and assuming some\ncompressibility of such an expansion, we can exploit structured sparsity\n(typically a group sparsity structure) to recover the sequence of coefficients\nwith high accuracy.\n  While traditional compressed sensing would typically expect a number of\nsnapshots scaling exponentially with the number of parameters, we can beat this\ndependence by adding weights. This anisotropic handling of the parameter space\npermits to compute approximations with a number of samples scaling only\nlinearly (up to log-factors) with the intrinsic complexity of the polynomial\nexpansion.\n  Our results are applied to problems in high-dimensional parametric elliptic\nPDEs. We show that under some weighted uniform ellipticity assumptions of a\nparametric operator, we are capable of numerically approximating the full\nsolution (in contrast to the usual quantity of interest) to within a specified\naccuracy. \n\n"}
{"id": "1811.05151", "contents": "Title: An adaptive reduced basis ANOVA method for high-dimensional Bayesian\n  inverse problems Abstract: In Bayesian inverse problems sampling the posterior distribution is often a\nchallenging task when the underlying models are computationally intensive. To\nthis end, surrogates or reduced models are often used to accelerate the\ncomputation. However, in many practical problems, the parameter of interest can\nbe of high dimensionality, which renders standard model reduction techniques\ninfeasible. In this paper, we present an approach that employs the ANOVA\ndecomposition method to reduce the model with respect to the unknown\nparameters, and the reduced basis method to reduce the model with respect to\nthe physical parameters. Moreover, we provide an adaptive scheme within the\nMCMC iterations, to perform the ANOVA decomposition with respect to the\nposterior distribution. With numerical examples, we demonstrate that the\nproposed model reduction method can significantly reduce the computational cost\nof Bayesian inverse problems, without sacrificing much accuracy. \n\n"}
{"id": "1811.07091", "contents": "Title: A New Operator Splitting Method for Euler's Elastica Model Abstract: Euler's elastica model has a wide range of applications in Image Processing\nand Computer Vision. However, the non-convexity, the non-smoothness and the\nnonlinearity of the associated energy functional make its minimization a\nchallenging task, further complicated by the presence of high order derivatives\nin the model. In this article we propose a new operator-splitting algorithm to\nminimize the Euler elastica functional. This algorithm is obtained by applying\nan operator-splitting based time discretization scheme to an initial value\nproblem (dynamical flow) associated with the optimality system (a system of\nmultivalued equations). The sub-problems associated with the three fractional\nsteps of the splitting scheme have either closed form solutions or can be\nhandled by fast dedicated solvers. Compared with earlier approaches relying on\nADMM (Alternating Direction Method of Multipliers), the new method has,\nessentially, only the time discretization step as free parameter to choose,\nresulting in a very robust and stable algorithm. The simplicity of the\nsub-problems and its modularity make this algorithm quite efficient.\nApplications to the numerical solution of smoothing test problems demonstrate\nthe efficiency and robustness of the proposed methodology. \n\n"}
{"id": "1811.07658", "contents": "Title: Differential-Algebraic Equations and Beyond: From Smooth to Nonsmooth\n  Constrained Dynamical Systems Abstract: The present article presents a summarizing view at differential-algebraic\nequations (DAEs) and analyzes how new application fields and corresponding\nmathematical models lead to innovations both in theory and in numerical\nanalysis for this problem class. Recent numerical methods for nonsmooth\ndynamical systems subject to unilateral contact and friction illustrate the\ntopicality of this development. \n\n"}
{"id": "1811.08215", "contents": "Title: 2 Higgs Doublet Model Evolver -- Manual Abstract: Two-Higgs-Doublet Model Evolver (2HDME) is a C++ program that provides the\nfunctionality to perform fast renormalization group equation running of the\ngeneral, potentially CP-violating, 2 Higgs Doublet Model at 2-loop order.\nSimple tree-level calculations of masses; calculations of the oblique\nparameters S, T and U; different parameterizations of the scalar potential;\ntests of perturbativity, unitarity and tree-level stability of the scalar\npotential are also implemented. We briefly describe the 2HDME's structure,\nprovide a demonstration of how to use it and list some of the most useful\nfunctions. \n\n"}
{"id": "1811.10243", "contents": "Title: Letter of Intent for FASER: ForwArd Search ExpeRiment at the LHC Abstract: FASER is a proposed small and inexpensive experiment designed to search for\nlight, weakly-interacting particles at the LHC. Such particles are dominantly\nproduced along the beam collision axis and may be long-lived, traveling\nhundreds of meters before decaying. To exploit both of these properties, FASER\nis to be located along the beam collision axis, 480 m downstream from the ATLAS\ninteraction point, in the unused service tunnel TI18. We propose that FASER be\ninstalled in TI18 in Long Shutdown 2 in time to collect data from 2021-23\nduring Run 3 of the 14 TeV LHC. FASER will detect new particles that decay\nwithin a cylindrical volume with radius R= 10 cm and length L = 1.5 m. With\nthese small dimensions, FASER will complement the LHC's existing physics\nprogram, extending its discovery potential to a host of new particles,\nincluding dark photons, axion-like particles, and other CP-odd scalars. A FLUKA\nsimulation and analytical estimates have confirmed that numerous potential\nbackgrounds are highly suppressed at the FASER location, and the first in situ\nmeasurements are currently underway. We describe FASER's location and discovery\npotential, its target signals and backgrounds, the detector's layout and\ncomponents, and the experiment's preliminary cost estimate, funding, and\ntimeline. \n\n"}
{"id": "1812.02479", "contents": "Title: Preconditioners for symmetrized Toeplitz and multilevel Toeplitz\n  matrices Abstract: When solving linear systems with nonsymmetric Toeplitz or multilevel Toeplitz\nmatrices using Krylov subspace methods, the coefficient matrix may be\nsymmetrized. The preconditioned MINRES method can then be applied to this\nsymmetrized system, which allows rigorous upper bounds on the number of MINRES\niterations to be obtained. However, effective preconditioners for symmetrized\n(multilevel) Toeplitz matrices are lacking. Here, we propose novel ideal\npreconditioners, and investigate the spectra of the preconditioned matrices. We\nshow how these preconditioners can be approximated and demonstrate their\neffectiveness via numerical experiments. \n\n"}
{"id": "1812.02547", "contents": "Title: Non-Canonical Inflation and Primordial Black Holes Production Abstract: We study a mechanism for the amplification of the inflationary scalar\nperturbation when the inflaton field action is non-canonical, i.e. the inflaton\nkinetic term has a non-standard form. For such a case the speed of sound of the\nperturbations generated during inflation is less than one and in general\nchanges with time. Furthermore in such models, even when the scalar field\npotential is negligible, diverse inflationary attractors may exist. The\npossible effects of a speed of sound approaching zero during some stage of\ninflation may lead to a large amplification for the amplitude of the scalar\nspectrum which, on horizon re-entry during the radiation dominated phase, can\ncollapse and form primordial black holes (PBH) of a mass $M_{\\rm BH}\\sim\n10^{-15}M_{\\odot}$ which may constitute a large fraction of the total Dark\nMatter (DM) today. \n\n"}
{"id": "1812.03987", "contents": "Title: The Pulsed Neutron Beam EDM Experiment Abstract: We report on the Beam EDM experiment, which aims to employ a pulsed cold\nneutron beam to search for an electric dipole moment instead of the established\nuse of storable ultracold neutrons. We present a brief overview of the basic\nmeasurement concept and the current status of our proof-of-principle Ramsey\napparatus. \n\n"}
{"id": "1812.04256", "contents": "Title: Multivariate Newton Interpolation Abstract: For $m,n \\in \\mathbb{N}$, $m\\geq 1$ and a given function $f :\n\\mathbb{R}^m\\longrightarrow \\mathbb{R}$, the polynomial interpolation problem\n(PIP) is to determine a unisolvent node set $P_{m,n} \\subseteq \\mathbb{R}^m$ of\n$N(m,n):=|P_{m,n}|=\\binom{m+n}{n}$ points and the uniquely defined polynomial\n$Q_{m,n,f}\\in \\Pi_{m,n}$ in $m$ variables of degree\n$\\mathrm{deg}(Q_{m,n,f})\\leq n \\in \\mathbb{N}$ that fits $f$ on $P_{m,n}$,\ni.e., $Q_{m,n,f}(p) = f(p)$, $\\forall\\, p \\in P_{m,n}$. For $m=1$ the solution\nto the PIP is well known. In higher dimensions, however, no closed framework\nwas available. We here present a generalization of the classic Newton\ninterpolation from one-dimensional to arbitrary-dimensional spaces. Further we\nformulate an algorithm, termed PIP-SOLVER, based on a multivariate divided\ndifference scheme that computes the solution $Q_{m,n,f}$ in\n$\\mathcal{O}\\big(N(m,n)^2\\big)$ time using $\\mathcal{O}\\big(mN(m,n)\\big)$\nmemory. Further, we introduce unisolvent Newton-Chebyshev nodes and show that\nthese nodes avoid Runge's phenomenon in the sense that arbitrary periodic\nSobolev functions $f \\in H^k(\\Omega,\\mathbb{R}) \\subsetneq\nC^0(\\Omega,\\mathbb{R})$, $\\Omega =[-1,1]^m$ of regularity $k >m/2$ can be\nuniformly approximated, i.e., $ \\lim_{n\\rightarrow \\infty}||\\,f -Q_{m,n,f}\n\\,||_{C^0(\\Omega)}= 0$. Numerical experiments demonstrate the computational\nperformance and approximation accuracy of the PIP-SOLVER in practice. We expect\nthe presented results to be relevant for many applications, including numerical\nsolvers, quadrature, non-linear optimization, polynomial regression, adaptive\nsampling, Bayesian inference, and spectral analysis. \n\n"}
{"id": "1812.04489", "contents": "Title: Connections between numerical integration, discrepancy, dispersion, and\n  universal discretization Abstract: The main goal of this paper is to provide a brief survey of recent results\nwhich connect together results from different areas of research. It is well\nknown that numerical integration of functions with mixed smoothness is closely\nrelated to the discrepancy theory. We discuss this connection in detail and\nprovide a general view of this connection. It was established recently that the\nnew concept of {\\it fixed volume discrepancy} is very useful in proving the\nupper bounds for the dispersion. Also, it was understood recently that point\nsets with small dispersion are very good for the universal discretization of\nthe uniform norm of trigonometric polynomials. \n\n"}
{"id": "1812.05112", "contents": "Title: Distribution Amplitudes of Heavy-Light Mesons Abstract: A symmetry-preserving approach to the continuum bound-state problem in\nquantum field theory is used to calculate the masses, leptonic decay constants\nand light-front distribution amplitudes of empirically accessible heavy-light\nmesons. The inverse moment of the $B$-meson distribution is particularly\nimportant in treatments of exclusive $B$-decays using effective field theory\nand the factorisation formalism; and its value is therefore computed:\n$\\lambda_B(\\zeta = 2\\,{\\rm GeV}) = 0.54(3)\\,$GeV. As an example and in\nanticipation of precision measurements at new-generation $B$-factories, the\nbranching fraction for the rare $B\\to \\gamma(E_\\gamma) \\ell \\nu_\\ell$ radiative\ndecay is also calculated, retaining $1/m_B^2$ and $1/E_\\gamma^2$ corrections to\nthe differential decay width, with the result $\\Gamma_{B\\to \\gamma \\ell\n\\nu_\\ell}/\\Gamma_B = 0.47(15)$ on $E_\\gamma > 1.5\\,$GeV. \n\n"}
{"id": "1812.05786", "contents": "Title: Low-rank Matrix Completion in a General Non-orthogonal Basis Abstract: This paper considers theoretical analysis of recovering a low rank matrix\ngiven a few expansion coefficients with respect to any basis. The current\napproach generalizes the existing analysis for the low-rank matrix completion\nproblem with sampling under entry sensing or with respect to a symmetric\northonormal basis. The analysis is based on dual certificates using a dual\nbasis approach and does not assume the restricted isometry property (RIP). We\nintroduce a condition on the basis called the correlation condition. This\ncondition can be computed in time $O(n^3)$ and holds for many cases of\ndeterministic basis where RIP might not hold or is NP hard to verify. If the\ncorrelation condition holds and the underlying low rank matrix obeys the\ncoherence condition with parameter $\\nu$, under additional mild assumptions,\nour main result shows that the true matrix can be recovered with very high\nprobability from $O(nr\\nu\\log^2n)$ uniformly random expansion coefficients. \n\n"}
{"id": "1812.05931", "contents": "Title: Computational micromagnetics with Commics Abstract: We present our open-source Python module Commics for the study of the\nmagnetization dynamics in ferromagnetic materials via micromagnetic\nsimulations. It implements state-of-the-art unconditionally convergent finite\nelement methods for the numerical integration of the Landau-Lifshitz-Gilbert\nequation. The implementation is based on the multiphysics finite element\nsoftware Netgen/NGSolve. The simulation scripts are written in Python, which\nleads to very readable code and direct access to extensive post-processing.\nTogether with documentation and example scripts, the code is freely available\non GitLab. \n\n"}
{"id": "1812.07337", "contents": "Title: A detector for CLIC: main parameters and performance Abstract: Together with the recent CLIC detector model CLICdet a new software suite was\nintroduced for the simulation and reconstruction of events in this detector.\nThis note gives a brief introduction to CLICdet and describes the CLIC\nexperimental conditions at 380 GeV and 3 TeV, including beam-induced\nbackgrounds. The simulation and reconstruction tools are introduced, and the\nphysics performance obtained is described in terms of single particles,\nparticles in jets, jet energy resolution and flavour tagging. The performance\nof the very forward electromagnetic calorimeters is also discussed. \n\n"}
{"id": "1812.07761", "contents": "Title: Stable high-order randomized cubature formulae in arbitrary dimension Abstract: We propose and analyse randomized cubature formulae for the numerical\nintegration of functions with respect to a given probability measure $\\mu$\ndefined on a domain $\\Gamma \\subseteq \\mathbb{R}^d$, in any dimension $d$. Each\ncubature formula is exact on a given finite-dimensional subspace $V_n\\subset\nL^2(\\Gamma,\\mu)$ of dimension $n$, and uses pointwise evaluations of the\nintegrand function $\\phi : \\Gamma \\to \\mathbb{R}$ at $m>n$ independent random\npoints. These points are drawn from a suitable auxiliary probability measure\nthat depends on $V_n$. We show that, up to a logarithmic factor, a linear\nproportionality between $m$ and $n$ with dimension-independent constant ensures\nstability of the cubature formula with high probability. We also prove error\nestimates in probability and in expectation for any $n\\geq 1$ and $m>n$, thus\ncovering both preasymptotic and asymptotic regimes. Our analysis shows that the\nexpected cubature error decays as $\\sqrt{n/m}$ times the $L(\\Gamma, \\mu)$-best\napproximation error of $\\phi$ in $V_n$. On the one hand, for fixed $n$ and\n$m\\to \\infty$ our cubature formula can be seen as a variance reduction\ntechnique for a Monte Carlo estimator, and can lead to enormous variance\nreduction for smooth integrand functions and subspaces $V_n$ with spectral\napproximation properties. On the other hand, when we let $n,m\\to\\infty$, our\ncubature becomes of high order with spectral convergence. As a further\ncontribution, we analyse also another cubature formula whose expected error\ndecays as $\\sqrt{1/m}$ times the $L^2(\\Gamma,\\mu)$-best approximation error of\n$\\phi$ in $V_n$, which is asymptotically optimal but with constants that can be\nlarger in the preasymptotic regime. Finally we show that, under a more\ndemanding (at least quadratic) proportionality betweeen $m$ and $n$, the\nweights of the cubature are positive with high probability. \n\n"}
{"id": "1812.08509", "contents": "Title: On the positivity and magnitudes of Bayesian quadrature weights Abstract: This article reviews and studies the properties of Bayesian quadrature\nweights, which strongly affect stability and robustness of the quadrature rule.\nSpecifically, we investigate conditions that are needed to guarantee that the\nweights are positive or to bound their magnitudes. First, it is shown that the\nweights are positive in the univariate case if the design points locally\nminimise the posterior integral variance and the covariance kernel is totally\npositive (e.g., Gaussian and Hardy kernels). This suggests that gradient-based\noptimisation of design points may be effective in constructing stable and\nrobust Bayesian quadrature rules. Secondly, we show that magnitudes of the\nweights admit an upper bound in terms of the fill distance and separation\nradius if the RKHS of the kernel is a Sobolev space (e.g., Mat\\'ern kernels),\nsuggesting that quasi-uniform points should be used. A number of numerical\nexamples demonstrate that significant generalisations and improvements appear\nto be possible, manifesting the need for further research. \n\n"}
{"id": "1812.08669", "contents": "Title: Constraining heavy neutral gauge boson $Z'$ in the 3 - 3 - 1 models by\n  weak charge data of Cesium and proton Abstract: The recent experimental data of the weak charges of Cesium and proton is\nanalyzed in the framework of the models based on the $\\mbox{SU}(3)_C\\times\n\\mbox{SU}(3)_L \\times \\mbox{U}(1)_X$ (3-3-1) gauge group, including the 3-3-1\nmodel with CKS mechanism (3-3-1CKS) and the general 3-3-1 models with arbitrary\n$\\beta$ (3-3-1$\\beta$) with three Higgs triplets. We will show that at the TeV\nscale, the mixing among neutral gauge bosons plays significant effect. Within\nthe present values of the weak charges of Cesium and proton we get the lowest\nmass bound of the extra heavy neutral gauge boson to be 1.27 TeV. The results\nderived from the weak charge data, perturbative limit of Yukawa coupling of the\ntop quark, and the relevant Landau poles favor the models with $\\beta =\\pm\n1/\\sqrt{3}$ and $\\beta = 0$ while ruling out the ones with $\\beta= \\pm\n\\sqrt{3}$. In addition, there are some hints showing that in the 3-3-1 models,\nthe third quark family should be treated differently from the first twos. \n\n"}
{"id": "1812.08723", "contents": "Title: A Universal Sampling Method for Reconstructing Signals with Simple\n  Fourier Transforms Abstract: Reconstructing continuous signals from a small number of discrete samples is\na fundamental problem across science and engineering. In practice, we are often\ninterested in signals with 'simple' Fourier structure, such as bandlimited,\nmultiband, and Fourier sparse signals. More broadly, any prior knowledge about\na signal's Fourier power spectrum can constrain its complexity. Intuitively,\nsignals with more highly constrained Fourier structure require fewer samples to\nreconstruct.\n  We formalize this intuition by showing that, roughly, a continuous signal\nfrom a given class can be approximately reconstructed using a number of samples\nproportional to the *statistical dimension* of the allowed power spectrum of\nthat class. Further, in nearly all settings, this natural measure tightly\ncharacterizes the sample complexity of signal reconstruction.\n  Surprisingly, we also show that, up to logarithmic factors, a universal\nnon-uniform sampling strategy can achieve this optimal complexity for *any\nclass of signals*. We present a simple and efficient algorithm for recovering a\nsignal from the samples taken. For bandlimited and sparse signals, our method\nmatches the state-of-the-art. At the same time, it gives the first\ncomputationally and sample efficient solution to a broad range of problems,\nincluding multiband signal reconstruction and kriging and Gaussian process\nregression tasks in one dimension.\n  Our work is based on a novel connection between randomized linear algebra and\nsignal reconstruction with constrained Fourier structure. We extend tools based\non statistical leverage score sampling and column-based matrix reconstruction\nto the approximation of continuous linear operators that arise in signal\nreconstruction. We believe that these extensions are of independent interest\nand serve as a foundation for tackling a broad range of continuous time\nproblems using randomized methods. \n\n"}
{"id": "1812.08852", "contents": "Title: A Scale Invariant Approach for Sparse Signal Recovery Abstract: In this paper, we study the ratio of the $L_1 $ and $L_2 $ norms, denoted as\n$L_1/L_2$, to promote sparsity. Due to the non-convexity and non-linearity,\nthere has been little attention to this scale-invariant model. Compared to\npopular models in the literature such as the $L_p$ model for $p\\in(0,1)$ and\nthe transformed $L_1$ (TL1), this ratio model is parameter free. Theoretically,\nwe present a strong null space property (sNSP) and prove that any sparse vector\nis a local minimizer of the $L_1 /L_2 $ model provided with this sNSP\ncondition. Computationally, we focus on a constrained formulation that can be\nsolved via the alternating direction method of multipliers (ADMM). Experiments\nshow that the proposed approach is comparable to the state-of-the-art methods\nin sparse recovery. In addition, a variant of the $L_1/L_2$ model to apply on\nthe gradient is also discussed with a proof-of-concept example of the MRI\nreconstruction. \n\n"}
{"id": "1812.09088", "contents": "Title: Isogeometric analysis with $C^1$ functions on unstructured quadrilateral\n  meshes Abstract: In the context of isogeometric analysis, globally $C^1$ isogeometric spaces\nover unstructured quadrilateral meshes allow the direct solution of fourth\norder partial differential equations on complex geometries via their Galerkin\ndiscretization. The design of such smooth spaces has been intensively studied\nin the last five years, in particular for the case of planar domains, and is\nstill task of current research. In this paper, we first give a short survey of\nthe developed methods and especially focus on the approach [26]. There, the\nconstruction of a specific $C^1$ isogeometric spline space for the class of\nso-called analysis-suitable $G^1$ multi-patch parametrizations is presented.\nThis particular class of parameterizations comprises exactly those multi-patch\ngeometries, which ensure the design of $C^1$ spaces with optimal approximation\nproperties, and allows the representation of complex planar multi-patch\ndomains. We present known results in a coherent framework, and also extend the\nconstruction to parametrizations that are not analysis-suitable $G^1$ by\nallowing higher-degree splines in the neighborhood of the extraordinary\nvertices and edges. Finally, we present numerical tests that illustrate the\nbehavior of the proposed method on representative examples. \n\n"}
{"id": "1812.10921", "contents": "Title: Error estimates of semi-discrete and fully discrete finite element\n  methods for the Cahn-Hilliard-Cook equation Abstract: In two recent publications [Kov{\\'a}cs, Larsson, and Mesforush, SIAM J.\nNumer. Anal. 49(6), 2407-2429, 2011] and [Furihata, et al., SIAM J. Numer.\nAnal. 56(2), 708-731, 2018], strong convergence of the semi-discrete and fully\ndiscrete finite element methods is, respectively, proved for the\nCahn-Hilliard-Cook (CHC) equation, but without convergence rates revealed. The\npresent work aims to fill the left gap, by recovering strong convergence rates\nof (fully discrete) finite element methods for the CHC equation. More\naccurately, strong convergence rates of a full discretization are obtained,\nbased on Galerkin finite element methods for the spatial discretization and the\nbackward Euler method for the temporal discretization. It turns out that the\nconvergence rates heavily depend on the spatial regularity of the noise\nprocess. Different from the stochastic Allen-Cahn equation, the presence of the\nunbounded elliptic operator in front of the cubic nonlinearity in the\nunderlying model makes the error analysis much more challenging and demanding.\nTo address such difficulties, several new techniques and error estimates are\ndeveloped. Numerical examples are finally provided to confirm the previous\nfindings. \n\n"}
{"id": "1812.11364", "contents": "Title: Adaptive Synchrosqueezing Transform with a Time-Varying Parameter for\n  Non-stationary Signal Separation Abstract: The continuous wavelet transform (CWT) is a linear time-frequency\nrepresentation and a powerful tool for analyzing non-stationary signals. The\nsynchrosqueezing transform (SST) is a special type of the reassignment method\nwhich not only enhances the energy concentration of CWT in the time-frequency\nplane, but also separates the components of multicomponent signals. The \"bump\nwavelet\" and Morlet's wavelet are commonly used continuous wavelets for the\nwavelet-based SST. There is a parameter in these wavelets which controls the\nwidths of the time-frequency localization window. In most literature on SST,\nthis parameter is a fixed positive constant. In this paper, we consider the CWT\nwith a time-varying parameter (called the adaptive CWT) and the corresponding\nSST (called the adaptive SST) for instantaneous frequency estimation and\nmulticomponent signal separation. We also introduce the 2nd-order adaptive SST.\nWe analyze the separation conditions for non-stationary multicomponent signals\nwith the local approximation of linear frequency modulation mode. We derive\nwell-separated conditions of a multicomponent signal based on the adaptive CWT.\nWe propose methods to select the time-varying parameter so that the\ncorresponding adaptive SSTs of the components of a multicomponent signal have\nsharp representations and are well-separated, and hence the components can be\nrecovered more accurately. We provide comparison experimental results to\ndemonstrate the efficiency and robustness of the proposed adaptive CWT and\nadaptive SST in separating components of multicomponent signals with fast\nvarying frequencies. \n\n"}
{"id": "1812.11601", "contents": "Title: Allocation strategies for high fidelity models in the multifidelity\n  regime Abstract: We propose a novel approach to allocating resources for expensive simulations\nof high fidelity models when used in a multifidelity framework. Allocation\ndecisions that distribute computational resources across several simulation\nmodels become extremely important in situations where only a small number of\nexpensive high fidelity simulations can be run. We identify this allocation\ndecision as a problem in optimal subset selection, and subsequently regularize\nthis problem so that solutions can be computed. Our regularized formulation\nyields a type of group lasso problem that has been studied in the literature to\naccomplish subset selection. Our numerical results compare performance of\nalgorithms that solve the group lasso problem for algorithmic allocation\nagainst a variety of other strategies, including those based on classical\nlinear algebraic pivoting routines and those derived from more modern machine\nlearning-based methods. We demonstrate on well known synthetic problems and\nmore difficult real-world simulations that this group lasso solution to the\nrelaxed optimal subset selection problem performs better than the alternatives. \n\n"}
{"id": "1901.00792", "contents": "Title: An estimate of Green's function of the problem of bounded solutions in\n  the case of a triangular coefficient Abstract: An estimate of Green's function of the bounded solutions problem for the\nordinary differential equation $x'(t)-Bx(t)=f(t)$ is proposed. It is assumed\nthat the matrix coefficient $B$ is triangular. This estimate is a\ngeneralization of the estimate of the matrix exponential proved by Ch. F. Van\nLoan. \n\n"}
{"id": "1901.00913", "contents": "Title: Structured FISTA for Image Restoration Abstract: In this paper, we propose an efficient numerical scheme for solving some\nlarge scale ill-posed linear inverse problems arising from image restoration.\nIn order to accelerate the computation, two different hidden structures are\nexploited. First, the coefficient matrix is approximated as the sum of a small\nnumber of Kronecker products. This procedure not only introduces one more level\nof parallelism into the computation but also enables the usage of\ncomputationally intensive matrix-matrix multiplications in the subsequent\noptimization procedure. We then derive the corresponding Tikhonov regularized\nminimization model and extend the fast iterative shrinkage-thresholding\nalgorithm (FISTA) to solve the resulting optimization problem. Since the\nmatrices appearing in the Kronecker product approximation are all structured\nmatrices (Toeplitz, Hankel, etc.), we can further exploit their fast\nmatrix-vector multiplication algorithms at each iteration. The proposed\nalgorithm is thus called structured fast iterative shrinkage-thresholding\nalgorithm (sFISTA). In particular, we show that the approximation error\nintroduced by sFISTA is well under control and sFISTA can reach the same image\nrestoration accuracy level as FISTA. Finally, both the theoretical complexity\nanalysis and some numerical results are provided to demonstrate the efficiency\nof sFISTA. \n\n"}
{"id": "1901.02330", "contents": "Title: Parallel solvers for virtual element discretizations of elliptic\n  equations in mixed form Abstract: The aim of this paper is twofold. On the one hand, we test numerically the\nperformance of mixed virtual elements in three dimensions for the first time in\nthe literature to solve the mixed formulation of three-dimensional elliptic\nequations on polyhedral meshes. On the other hand, we focus on the parallel\nsolution of the linear system arising from such discretization, considering\nboth direct and iterative parallel solvers. In the latter case, we develop two\nblock preconditioners, one based on the approximate Schur complement and one on\na regularization technique. Both these topics are numerically validated by\nseveral parallel tests performed on a Linux cluster. More specifically, we show\nthat the proposed VEM discretization recovers the expected theoretical\nconvergence properties and we analize the performance of the direct and\niterative parallel solvers taken into account. \n\n"}
{"id": "1901.03453", "contents": "Title: The Fourier extension method and discrete orthogonal polynomials on an\n  arc of the circle Abstract: The Fourier extension method, also known as the Fourier continuation method,\nis a method for approximating non-periodic functions on an interval using\ntruncated Fourier series with period larger than the interval on which the\nfunction is defined. When the function being approximated is known at only\nfinitely many points, the approximation is constructed as a projection based on\nthis discrete set of points. In this paper we address the issue of estimating\nthe absolute error in the approximation. The error can be expressed in terms of\na system of discrete orthogonal polynomials on an arc of the unit circle, and\nthese polynomials are then evaluated asymptotically using Riemann--Hilbert\nmethods. \n\n"}
{"id": "1901.03750", "contents": "Title: T2K ND280 Upgrade -- Technical Design Report Abstract: In this document, we present the Technical Design Report of the Upgrade of\nthe T2K Near Detector ND280. The goal of this upgrade is to improve the Near\nDetector performance to measure the neutrino interaction rate and to constrain\nthe neutrino interaction cross-sections so that the uncertainty in the number\nof predicted events at Super-Kamiokande is reduced to about 4%. This will allow\nto improve the physics reach of the T2K-II project. This goal is achieved by\nmodifying the upstream part of the detector, adding a new highly granular\nscintillator detector (Super-FGD), two new TPCs (High-Angle TPC) and six TOF\nplanes. Details about the detector concepts, design and construction methods\nare presented, as well as a first look at the test-beam data taken in Summer\n2018. An update of the physics studies is also presented. \n\n"}
{"id": "1901.04255", "contents": "Title: Generalized Tensor Function via the Tensor Singular Value Decomposition\n  based on the T-Product Abstract: In this paper, we present the definition of generalized tensor function\naccording to the tensor singular value decomposition (T-SVD) via the tensor\nT-product. Also, we introduce the compact singular value decomposition (T-CSVD)\nof tensors via the T-product, from which the projection operators and Moore\nPenrose inverse of tensors are also obtained. We also establish the Cauchy\nintegral formula for tensors by using the partial isometry tensors and applied\nit into the solution of tensor equations. Then we establish the generalized\ntensor power and the Taylor expansion of tensors. Explicit generalized tensor\nfunctions are also listed. We define the tensor bilinear and sesquilinear forms\nand proposed theorems on structures preserved by generalized tensor functions.\nFor complex tensors, we established an isomorphism between complex tensors and\nreal tensors. In the last part of our paper, we find that the block circulant\noperator established an isomorphism between tensors and matrices. This\nisomorphism is used to prove the F-stochastic structure is invariant under\ngeneralized tensor functions. The concept of invariant tensor cones is also\nraised. \n\n"}
{"id": "1901.06254", "contents": "Title: FFT and orthogonal discrete transform on weight lattices of semi-simple\n  Lie groups Abstract: We give two algebro-geometric inspired approaches to fast algorithms for\nFourier transforms in algebraic signal processing theory based on polynomial\nalgebras in several variables. One is based on module induction and one is\nbased on a decomposition property of certain polynomials. The Gauss-Jacobi\nprocedure for the derivation of orthogonal transforms is extended to the\nmultivariate setting. This extension relies on a multivariate\nChristoffel-Darboux formula for orthogonal polynomials in several variables. As\na set of application examples a general scheme for the derivation of fast\ntransforms of weight lattices based on multivariate Chebyshev polynomials is\nderived. A special case of such transforms is considered, where one can apply\nthe Gauss-Jacobi procedure. \n\n"}
{"id": "1901.06506", "contents": "Title: Photoacoustic image reconstruction via deep learning Abstract: Applying standard algorithms to sparse data problems in photoacoustic\ntomography (PAT) yields low-quality images containing severe under-sampling\nartifacts. To some extent, these artifacts can be reduced by iterative image\nreconstruction algorithms which allow to include prior knowledge such as\nsmoothness, total variation (TV) or sparsity constraints. These algorithms tend\nto be time consuming as the forward and adjoint problems have to be solved\nrepeatedly. Further, iterative algorithms have additional drawbacks. For\nexample, the reconstruction quality strongly depends on a-priori model\nassumptions about the objects to be recovered, which are often not strictly\nsatisfied in practical applications. To overcome these issues, in this paper,\nwe develop direct and efficient reconstruction algorithms based on deep\nlearning. As opposed to iterative algorithms, we apply a convolutional neural\nnetwork, whose parameters are trained before the reconstruction process based\non a set of training data. For actual image reconstruction, a single evaluation\nof the trained network yields the desired result. Our presented numerical\nresults (using two different network architectures) demonstrate that the\nproposed deep learning approach reconstructs images with a quality comparable\nto state of the art iterative reconstruction methods. \n\n"}
{"id": "1901.06748", "contents": "Title: Affine approximation of parametrized kernels and model order reduction\n  for nonlocal and fractional Laplace models Abstract: We consider parametrized problems driven by spatially nonlocal integral\noperators with parameter-dependent kernels. In particular, kernels with varying\nnonlocal interaction radius $\\delta > 0$ and fractional Laplace kernels,\nparametrized by the fractional power $s\\in(0,1)$, are studied. In order to\nprovide an efficient and reliable approximation of the solution for different\nvalues of the parameters, we develop the reduced basis method as a parametric\nmodel order reduction approach. Major difficulties arise since the kernels are\nnot affine in the parameters, singular, and discontinuous. Moreover, the\nspatial regularity of the solutions depends on the varying fractional power\n$s$. To address this, we derive regularity and differentiability results with\nrespect to $\\delta$ and $s$, which are of independent interest for other\napplications such as optimization and parameter identification. We then use\nthese results to construct affine approximations of the kernels by local\npolynomials. Finally, we certify the method by providing reliable a posteriori\nerror estimators, which account for all approximation errors, and support the\ntheoretical findings by numerical experiments. \n\n"}
{"id": "1901.07598", "contents": "Title: On orthogonal projections for dimension reduction and applications in\n  augmented target loss functions for learning problems Abstract: The use of orthogonal projections on high-dimensional input and target data\nin learning frameworks is studied. First, we investigate the relations between\ntwo standard objectives in dimension reduction, preservation of variance and of\npairwise relative distances. Investigations of their asymptotic correlation as\nwell as numerical experiments show that a projection does usually not satisfy\nboth objectives at once. In a standard classification problem we determine\nprojections on the input data that balance the objectives and compare\nsubsequent results. Next, we extend our application of orthogonal projections\nto deep learning tasks and introduce a general framework of augmented target\nloss functions. These loss functions integrate additional information via\ntransformations and projections of the target data. In two supervised learning\nproblems, clinical image segmentation and music information classification, the\napplication of our proposed augmented target loss functions increase the\naccuracy. \n\n"}
{"id": "1901.07724", "contents": "Title: Analysis of FEAST spectral approximations using the DPG discretization Abstract: A filtered subspace iteration for computing a cluster of eigenvalues and its\naccompanying eigenspace, known as \"FEAST\", has gained considerable attention in\nrecent years. This work studies issues that arise when FEAST is applied to\ncompute part of the spectrum of an unbounded partial differential operator.\nSpecifically, when the resolvent of the partial differential operator is\napproximated by the discontinuous Petrov Galerkin (DPG) method, it is shown\nthat there is no spectral pollution. The theory also provides bounds on the\ndiscretization errors in the spectral approximations. Numerical experiments for\nsimple operators illustrate the theory and also indicate the value of the\nalgorithm beyond the confines of the theoretical assumptions. The utility of\nthe algorithm is illustrated by applying it to compute guided transverse core\nmodes of a realistic optical fiber. \n\n"}
{"id": "1901.08596", "contents": "Title: Observable signatures of dark photons from supernovae Abstract: A dark photon is a well-motivated new particle which, as a component of an\nassociated dark sector, could explain dark matter. One strong limit on dark\nphotons arises from excessive cooling of supernovae. We point out that even at\ncouplings where too few dark photons are produced in supernovae to violate the\ncooling bound, they can be observed directly through their decays. Supernovae\nproduce dark photons which decay to positrons, giving a signal in the 511 keV\nannihilation line observed by SPI/INTEGRAL. Further, prompt gamma-ray emission\nby these decaying dark photons gives a signal for gamma-ray telescopes.\nExisting GRS observations of SN1987a already constrain this, and a future\nnearby SN could provide a detection. Finally, dark photon decays from\nextragalactic SN would produce a diffuse flux of gamma rays observable by\ndetectors such as SMM and HEAO-1. Together these observations can probe dark\nphoton couplings several orders of magnitude beyond current constraints for\nmasses of roughly 1 - 100 MeV. \n\n"}
{"id": "1901.09162", "contents": "Title: A domain decomposition preconditioning for the integral equation\n  formulation of the inverse scattering problem Abstract: We propose domain decomposition preconditioners for the solution of an\nintegral equation formulation of forward and inverse acoustic scattering\nproblems with point scatterers. We study both forward and inverse problems and\npropose preconditioning techniques to accelerate the iterative solvers. For the\nforward scattering problem, we extend the domain decomposition based\npreconditioning techniques presented for partial differential equations in {\\em\n\"A restricted additive Schwarz preconditioner for general sparse linear\nsystems\", SIAM Journal on Scientific Computing, 21 (1999), pp. 792--797}, to\nintegral equations. We combine this domain decomposition preconditioner with a\nlow-rank correction, which is easy to construct, forming a new preconditioner.\nFor the inverse scattering problem, we use the forward problem preconditioner\nas a building block for constructing a preconditioner for the Gauss-Newton\nHessian. We present numerical results that demonstrate the performance of both\npreconditioning strategies. \n\n"}
{"id": "1901.10199", "contents": "Title: The projected Newton-Kleinman method for the algebraic Riccati equation Abstract: The numerical solution of the algebraic Riccati equation is a challenging\ntask especially for very large problem dimensions. In this paper we present a\nnew algorithm that combines the very appealing computational features of\nprojection methods with the convergence properties of the inexact\nNewton-Kleinman procedure equipped with a line search. In particular, the\nNewton scheme is completely merged in a projection framework with a single\napproximation space so that the Newton-Kleinman iteration is only implicitly\nperformed. Moreover, the line search turns out to be exact in our setting,\ni.e., the existence of a local minimum of the Riccati residual norm along the\ncurrent search direction is guaranteed and the corresponding minimizer is\nchosen as step-size. This property determines a monotone decrease of the\nRiccati residual norm under some mild assumptions. Several numerical results\nare reported to illustrate the potential of our novel approach. \n\n"}
{"id": "1901.10375", "contents": "Title: A low-rank technique for computing the quasi-stationary distribution of\n  subcritical Galton-Watson processes Abstract: We present a new algorithm for computing the quasi-stationary distribution of\nsubcritical Galton--Watson branching processes. This algorithm is based on a\nparticular discretization of a well-known functional equation that\ncharacterizes the quasi-stationary distribution of these processes. We provide\na theoretical analysis of the approximate low-rank structure that stems from\nthis discretization, and we extend the procedure to multitype branching\nprocesses. We use numerical examples to demonstrate that our algorithm is both\nmore accurate and more efficient than other approaches. \n\n"}
{"id": "1901.10470", "contents": "Title: Bounding the spectral gap for an elliptic eigenvalue problem with\n  uniformly bounded stochastic coefficients Abstract: A key quantity that occurs in the error analysis of several numerical methods\nfor eigenvalue problems is the distance between the eigenvalue of interest and\nthe next nearest eigenvalue. When we are interested in the smallest or\nfundamental eigenvalue, we call this the spectral or fundamental gap. In a\nrecent manuscript [Gilbert et al., arXiv:1808.02639], the current authors,\ntogether with Frances Kuo, studied an elliptic eigenvalue problem with\nhomogeneous Dirichlet boundary conditions, and with coefficients that depend on\nan infinite number of uniformly distributed stochastic parameters. In this\nsetting, the eigenvalues, and in turn the eigenvalue gap, also depend on the\nstochastic parameters. Hence, for a robust error analysis one needs to be able\nto bound the gap over all possible realisations of the parameters, and because\nthe gap depends on infinitely-many random parameters, this is not trivial. This\nshort note presents, in a simplified setting, an important result that was\nshown in the paper above. Namely, that, under certain decay assumptions on the\ncoefficient, the spectral gap of such a random elliptic eigenvalue problem can\nbe bounded away from 0, uniformly over the entire infinite-dimensional\nparameter space. \n\n"}
{"id": "1901.11158", "contents": "Title: NETT Regularization for Compressed Sensing Photoacoustic Tomography Abstract: We discuss several methods for image reconstruction in compressed sensing\nphotoacoustic tomography (CS-PAT). In particular, we apply the deep learning\nmethod of [H. Li, J. Schwab, S. Antholzer, and M. Haltmeier. NETT: Solving\nInverse Problems with Deep Neural Networks (2018), arXiv:1803.00092], which is\nbased on a learned regularizer, for the first time to the CS-PAT problem. We\npropose a network architecture and training strategy for the NETT that we\nexpect to be useful for other inverse problems as well. All algorithms are\ncompared and evaluated on simulated data, and validated using experimental data\nfor two different types of phantoms. The results on the one the hand indicate\ngreat potential of deep learning methods, and on the other hand show that\nsignificant future work is required to improve their performance on real-word\ndata. \n\n"}
{"id": "astro-ph/0101055", "contents": "Title: Are mirror planets opaque? Abstract: Over the last few years, many close orbiting ($\\sim 0.05$ A.U.) large mass\nplanets ($\\sim M_{J}$) of nearby stars have been discovered. Their existence\nhas been inferred from tiny Doppler shifts in the light from the star and in\none case a transit has been observed. Because ordinary planets are not expected\nto be able to form this close to ordinary stars due to the high temperatures,\nit has been speculated that the close-in large planets are in fact exotic\nheavenly bodies made of mirror matter. We show that the accretion of ordinary\nmatter onto the mirror planet (from e.g.the solar wind from the host star)\nshould make the mirror planet opaque to ordinary radiation with an effective\nradius ($R_p$) large enough to explain the measured size of the transiting\nclose-in extrasolar planet, HD209458b. Furthermore we obtain the rough\nprediction that $R_{p} \\propto \\sqrt{{T_s\\over M_p}}$ (where $T_s$, is the\nsurface temperature of the ordinary matter in the mirror planet and $M_p$ is\nthe mass of the mirror planet) which will be tested in the near future as more\ntransiting planets are found. We also show that the mirror world interpretation\nof the close-in extra solar planets explains the low albedo of $\\tau$ Boo b\nbecause the large estimated mass of $\\tau$ Boo b ($\\sim 7M_J$) implies a small\neffective radius of $R_p \\approx 0.5R_J$ for $\\tau$ Boo. \n\n"}
{"id": "astro-ph/0106035", "contents": "Title: The Case for Omega_M = 0.33 +/- 0.035 Abstract: For decades, the determination of the mean density of matter(Omega_M) has\nbeen tied to the distribution of light. This has led to a ``bias,'' perhaps as\nlarge as a factor of 2, in determining a key cosmological parameter. Recent\nmeasurements of the physical properties of clusters, cosmic microwave\nbackground (CMB) anisotropy and the power spectrum of mass inhomogeneity now\nallow a determination of Omega_M without ``visual bias.'' The early data lead\nto a consistent picture of the matter and baryon densities, with Omega_B =\n0.039 +/- 0.0075 and Omega_M = 0.33 +/- 0.035. \n\n"}
{"id": "astro-ph/0509414", "contents": "Title: Diffuse gamma-ray emission: lessons and perspectives Abstract: The Galactic diffuse emission is potentially able to reveal much about the\nsources and propagation of cosmic rays (CR), their spectra and intensities in\ndistant locations. It can possibly unveil WIMP dark matter (DM) through its\nannihilation signatures. The extragalactic background may provide vital\ninformation about the early stages of the universe, neutralino annihilation,\nand unresolved sources (blazars?) and their cosmological evolution. The\ngamma-ray instrument EGRET on the CGRO contributed much to the exploration of\nthe Galactic diffuse emission. The new NASA Gamma-ray Large Area Space\nTelescope (GLAST) is scheduled for launch in 2007; study of the diffuse\ngamma-ray emission is one of the priority goals. We describe current\nunderstanding of the diffuse emission and its potential for future discoveries. \n\n"}
{"id": "astro-ph/0605480", "contents": "Title: Limits on the Transient Ultra-High Energy Neutrino Flux from Gamma-Ray\n  Bursts (GRB) Derived from RICE Data Abstract: We present limits on ultra-high energy (UHE; E(nu)>1 PeV) neutrino fluxes\nfrom gamma-ray bursts (GRBs), based on recently presented data, limits, and\nsimulations from the RICE experiment. We use data from five recorded transients\nwith sufficient photon spectral shape and redshift information to derive an\nexpected neutrino flux, assuming that the observed photons are linked to\nneutrino production through pion decay via the well-known 'Waxman-Bahcall'\nprescription. Knowing the declination of the observed burst, as well as the\nRICE sensitivity as a function of polar angle and the previously published\nnon-observation of any neutrino events allows an estimate of the sensitivity to\na given neutrino flux. Although several orders of magnitude weaker than the\nexpected fluxes, our GRB neutrino flux limits are nevertheless the first in the\nPeV--EeV energy regime. For completeness, we also provide a listing of other\nbursts, recorded at times when the RICE experiment was active, but requiring\nsome assumptions regarding luminosity and redshift to permit estimates of the\nneutrino flux. \n\n"}
{"id": "astro-ph/9706271", "contents": "Title: CP Violating Solitons in the Early Universe Abstract: Solitons in extensions of the Standard Model can serve as localized sources\nof CP violation. Depending on their stability properties, they may serve either\nto create or to deplete the baryon asymmetry. The conditions for existence of a\nparticular soliton candidate, the membrane solution of the two-Higgs model, are\npresented. In the generic case, investigated by Bachas and Tomaras, membranes\nexist and are metastable for a wide range of parameters. For the more viable\nsupersymmetric case, it is shown that the present-day existence of CP-violating\nmembranes is experimentally excluded, but preliminary studies suggest that they\nmay have existed in the early universe soon after the electroweak phase\ntransition, with important consequences for the baryon asymmetry of the\nuniverse. \n\n"}
{"id": "astro-ph/9906322", "contents": "Title: A class of symplectic integrators with adaptive timestep for separable\n  Hamiltonian systems Abstract: Symplectic integration algorithms are well-suited for long-term integrations\nof Hamiltonian systems because they preserve the geometric structure of the\nHamiltonian flow. However, this desirable property is generally lost when\nadaptive timestep control is added to a symplectic integrator. We describe an\nadaptive-timestep symplectic integrator that can be used if the Hamiltonian is\nthe sum of kinetic and potential energy components and the required timestep\ndepends only on the potential energy (e.g. test-particle integrations in fixed\npotentials). In particular, we describe an explicit, reversible, symplectic,\nleapfrog integrator for a test particle in a near-Keplerian potential; this\nintegrator has timestep proportional to distance from the attracting mass and\nhas the remarkable property of integrating orbits in an inverse-square force\nfield with only \"along-track\" errors; i.e. the phase-space shape of a Keplerian\norbit is reproduced exactly, but the orbital period is in error by O(1/N^2),\nwhere N is the number of steps per period. \n\n"}
{"id": "cond-mat/0210177", "contents": "Title: Bose-Einstein condensation dynamics in three dimensions by the\n  pseudospectral and finite-difference methods Abstract: We suggest a pseudospectral method for solving the three-dimensional\ntime-dependent Gross-Pitaevskii (GP) equation and use it to study the resonance\ndynamics of a trapped Bose-Einstein condensate induced by a periodic variation\nin the atomic scattering length. When the frequency of oscillation of the\nscattering length is an even multiple of one of the trapping frequencies along\nthe $x$, $y$, or $z$ direction, the corresponding size of the condensate\nexecutes resonant oscillation. Using the concept of the differentiation matrix,\nthe partial-differential GP equation is reduced to a set of coupled ordinary\ndifferential equations which is solved by a fourth-order adaptive step-size\ncontrol Runge-Kutta method. The pseudospectral method is contrasted with the\nfinite-difference method for the same problem, where the time evolution is\nperformed by the Crank-Nicholson algorithm. The latter method is illustrated to\nbe more suitable for a three-dimensional standing-wave optical-lattice trapping\npotential. \n\n"}
{"id": "cond-mat/0507032", "contents": "Title: Engineering vortex rings and systems for controlled studies of vortex\n  interactions in Bose-Einstein condensates Abstract: We study controlled methods of preparing vortex configurations in atomic\nBose-Einstein condensates and their use in the studies of fundamental vortex\nscattering, reconnection processes and superfluid sound emission. We explore\ntechniques of imprinting closed vortex rings by means of coherently driving\ninternal atomic transitions with electromagnetic fields which exhibit singular\nphase profiles. In particular, we show that a vortex ring can be prepared in a\ncontrolled way by two focused co-propagating Gaussian laser beams. More complex\nvortex systems may also be imprinted by directly superposing simpler field\nconfigurations or by programming their phase profiles on optical holograms.\nThis provides the controlled method of studying vortex reconnections in atomic\nsuperfluids. We analyze specific examples of two merging vortex rings in a\ntrapped two-component Rb-87 condensate. We calculate the radiated sound energy\nin the vortex ring reconnection process and show that the vortex relaxation and\nthe re-distribution of sound energy can be controlled by the imprinting\nprocess. The energy is first concentrated towards the trap center and later\nemitted outwards as sound and transformed to surface excitations. As another\nsuch technique, we study creating pairs of 2D point vortices in Bose-Einstein\ncondensates using a 'light roadblock' in ultra-slow light propagation. We show\nhow this can be used to study vortex collisions in compressible superfluids and\nhow these collisions result in energy dissipation via phonons and, sometimes,\nannihilation of vortex pairs. \n\n"}
{"id": "gr-qc/0210053", "contents": "Title: Study of the coincidences between the gravitational wave detectors\n  EXPLORER and NAUTILUS in 2001 Abstract: We report the result from a search for bursts of gravitational waves using\ndata collected by the cryogenic resonant detectors EXPLORER and NAUTILUS during\nthe year 2001, for a total measuring time of 90 days. With these data we\nrepeated the coincidence search performed on the 1998 data (which showed a\nsmall coincidence excess) applying data analysis algorithms based on known\nphysical characteristics of the detectors. With the 2001 data a new interesting\ncoincidence excess is found when the detectors are favorably oriented with\nrespect to the Galactic Disk. \n\n"}
{"id": "hep-lat/0202005", "contents": "Title: Critical behaviour in QCD at finite isovector chemical potential Abstract: We report an investigation of criticality in QCD at finite isovector chemical\npotential, mu_3, and at zero temperature. At the critical point, mu_3^c = m_pi,\nwe find that an uncharged scalar and pseudoscalar and a charged pseudoscalar\nmeson become massless within the resolution of our measurement. The effective\nlong distance theory therefore breaks O(4) symmetry by charged pion\ncondensation. This results in a rising quark number susceptibility. The baryon\nremains massive, as indicated by a vanishing baryon number susceptibility. \n\n"}
{"id": "hep-lat/0212011", "contents": "Title: The nonperturbative quark-gluon vertex Abstract: We show results for the quark-gluon vertex in the Landau gauge, using a\nmean-field improved Sheikholeslami-Wohlert fermion action. We compute all the\nthree non-zero form factors of the vertex at zero gluon momentum, and compare\nthem to the abelian vertex. The quark mass dependence of the vertex is also\ninvestigated and found to be negligible for the range of masses considered. \n\n"}
{"id": "hep-lat/0504001", "contents": "Title: Nucleon and Delta masses in twisted mass chiral perturbation theory Abstract: We calculate the masses of the nucleons and deltas in twisted mass heavy\nbaryon chiral perturbation theory. We work to quadratic order in a power\ncounting scheme in which we treat the lattice spacing and the quark masses to\nbe of the same order. We give expressions for the mass and the mass splitting\nof the nucleons and deltas both in and away from the isospin limit. We give an\nargument using the chiral Lagrangian treatment that, in the strong isospin\nlimit, the nucleons remain degenerate and the delta multiplet breaks into two\ndegenerate pairs to all orders in chiral perturbation theory. We show that the\nmass splitting between the degenerate pairs of the deltas first appears at\nquadratic order in in the lattice spacing. We discuss the subtleties in the\neffective chiral theory that arise from the inclusion of isospin breaking. \n\n"}
{"id": "hep-lat/9808036", "contents": "Title: Chirality on the Lattice Abstract: During the last several years a non-perturbative formulation of exact chiral\nsymmetry on the lattice has been developed. I shall outline the main ideas of\nthese developments and discuss prospects for the future. The focus will be on\nthe basic concepts enciphered in a new jargon consisting of terms like\n``infinite number of fermions'', ``domain wall fermions'', ``the overlap'',\n``the Ginsparg-Wilson relation''. Technical details will be omitted. \n\n"}
{"id": "hep-lat/9809158", "contents": "Title: Aharonov-Bohm effect, Center Monopoles and Center Vortices in SU(2)\n  Lattice Gluodynamics Abstract: SU(2) gluodynamics is investigated numerically and analytically in the\n(Indirect) Maximal Center gauge at finite temperature. The center vortices are\nshown to be condensed in the confinement phase and dilute in the deconfinement\nphase. A new physical object, center monopole, is constructed. We show that the\ncenter monopole condensate is the order parameter of deconfinement phase\ntransition. The linking of the vortex worldsheets and quark trajectories is\nidentified with the Aharonov-Bohm interaction in an effective Abelian Higgs\ntheory. We conclude that the confinement in the Maximal Center gauge can be\nexplained by a new mechanism called \"the real superconductor mechanism\". \n\n"}
{"id": "hep-ph/0001207", "contents": "Title: CP Violating Phases and the Dark Matter Problem Abstract: New CP violating phases in the MSSM can affect both the abundance and\ndetection of neutralino dark matter. We discuss the effect of including\ncosmological constraints in the limits on new sources of CP violation in the\nMSSM and the effects of new CP violating parameters on dark matter densities\nand detection. \n\n"}
{"id": "hep-ph/0002102", "contents": "Title: Yukawa hierarchy from extra dimensions and infrared fixed points Abstract: We discuss the existence of hierarchy of Yukawa couplings in the models with\nextra spatial dimensions. The hierarchical structure is induced by the power\nbehavior of the cutoff dependence of the evolution equations which yield large\nsuppressions of couplings at the compactification scale. The values of coupling\nconstants at this scale can be made stable almost independently of the initial\ninput parameters by utilizing the infrared fixed point. We find that the Yukawa\ncouplings converge to the fixed points very quickly because of the enhanced\nenergy dependence of the suppression factor from extra dimensions as well as in\nthe case of large gauge couplings at high-energy scale. \n\n"}
{"id": "hep-ph/0003060", "contents": "Title: Virtual Color Superconductivity and Nucleon Structure Abstract: The observed electromagnetic (EM) properties of a nucleon at high energy are\nstudied to search for a possible metastable color superconducting phase, called\na virtual phase, that has an energy density close to the true ground state of\nthe vacuum. The discussion is based on a mechanism of spontaneous partial\nbreaking of the EM U(1) gauge symmetry inside a color superconductor. Favorable\nevidences for such a scenario are found. \n\n"}
{"id": "hep-ph/0003309", "contents": "Title: e^+ e^- --> {tilde t}_1 {tilde t}_1^* (H_1) in the MSSM with explicit CP\n  violations Abstract: The author considers the effects of the CP-violating phases, e. g. arg(A_t)\nand arg(mu) on the e^+ e^- --> {tilde t}_1 {tilde t}_1^* (H_1) processes. The\nthird generation squark trilinear terms give significant contributions to the\nHiggs potential at the one-loop level. This results in the changes of the stop\nmasses and the lighter stop - the lighter anti-stop - the lightest Higgs\ncoupling. The author shows the coupling and the loop effects on the processes.\nAnd the author will discuss the determination method of soft parameters. \n\n"}
{"id": "hep-ph/0008226", "contents": "Title: Lessons from Recent Measurements of CP Violation Abstract: We review various implications of recent experimental results concerning CP\nviolation and mixing in $K\\to\\pi\\pi$, $B\\to\\psi K_S$, $D\\to K\\pi$ and $D\\to KK$\ndecays. \n\n"}
{"id": "hep-ph/0009083", "contents": "Title: Massive sterile neutrinos as warm Dark Matter Abstract: We show that massive sterile neutrinos mixed with the ordinary ones may be\nproduced in the early universe in the right amount to be natural warm dark\nmatter particles. Their mass should be below 40 keV and the corresponding\nmixing angles sin^2 2\\theta > 10^{-11} for mixing with \\nu_\\mu or \\nu_\\tau,\nwhile mixing with \\nu_e is slightly stronger bounded with mass less than 30\nkeV. \n\n"}
{"id": "hep-ph/0010035", "contents": "Title: The Utility of Quantum Field Theory Abstract: This talk surveys a broad range of applications of quantum field theory, as\nwell as some recent developments. The stress is on the notion of effective\nfield theories. Topics include implications of neutrino mass and a possible\nsmall value of $\\sin(2\\beta)$, supersymmetric extensions of the standard model,\nthe use of field theory to understand fundamental issues in string theory (the\nproblem of multiple ground states and the question: does string theory predict\nlow energy supersymmetry), and the use of string theory to solve problems in\nfield theory. Also considered are a new type of field theory, and indications\nfrom black hole physics and the cosmological constant problem that effective\nfield theories may not completely describe theories of gravity. \n\n"}
{"id": "hep-ph/0012220", "contents": "Title: Hard Exclusive Production of Tensor Mesons Abstract: We point out that hard exclusive production of tensor mesons $f_2(1270)$ with\nhelicity $\\lambda=\\pm 2$ is dominated by the gluon component in the meson wave\nfunction and can be used to determine gluon admixture in tensor mesons in a\ntheoretically clean manner.\n  We present a detailed analysis of the tensor meson distribution amplitudes\nand calculate the transition form factor $\\gamma+\\gamma^*\\to f_2(1270)$ for one\nreal and one virtual photon. \n\n"}
{"id": "hep-ph/0102094", "contents": "Title: New Physics Working Group Summary of LCWS2000 at FNAL Abstract: Here I summarize P5-WG (New/Alternative Physics Working Group) of\nLCWS2000@FNAL, held on Oct 24-28, 2000. There were 13 talks altogether, 7 talks\non collider signals from new particles/interactions and 6 talks on extra\ndimensional physics. We had very active and hot discussions among participants\nfor those new/alternative physics/ideas. \n\n"}
{"id": "hep-ph/0104161", "contents": "Title: Standard Model Higgs Boson Mass from Borderline Metastability of the\n  Vacuum Abstract: We have studied imposing the condition that the Standard Model effective\nHiggs potential should have two approximately degenerate vacua, such that the\nvacuum we live in is just barely metastable: the one in which we live has a\nvacuum expectation value of 246 GeV and the other one should have a vacuum\nexpectation value of order the Planck scale. Alone borderline metastability\ngives, using the experimental top quark mass 173.1 \\pm 4.6 GeV, the Higgs mass\nprediction 121.8 \\pm 11 GeV. The requirement that the second minimum be at the\nPlanck scale already gave the prediction 173\\pm 4 GeV for the top quark mass\naccording to our 1995 paper. \n\n"}
{"id": "hep-ph/0105188", "contents": "Title: Pion light cone wave function in the non-local NJL model Abstract: We use the simple instanton motivated NJL-type model to calculate the leading\ntwist pion light cone wave function. The model consists in employing the\nmomentum dependent quark mass in the quark loop entering the definition of the\nwave function. The result is analytical up to a solution of a certain algebraic\nequation. Various properties including the kT dependence of the pion wave\nfunction are discussed. The resulting kT integrated wave function is not\nasymptotic and is in agreement with recent analysis of the CLEO data. \n\n"}
{"id": "hep-ph/0106246", "contents": "Title: Soft Color Interactions and Diffractive Hard Scattering at the Fermilab\n  Tevatron Abstract: An improved understanding of nonperturbative QCD can be obtained by the\nrecently developed soft color interaction models. Their essence is the\nvariation of color string-field topologies, giving a unified description of\nfinal states in high energy interactions, e.g., diffractive and nondiffractive\nevents in ep and ppbar. Here we present a detailed study of such models (the\nsoft color interaction model and the generalized area law model) applied to\nppbar, considering also the general problem of the underlying event including\nbeam particle remnants. With models tuned to HERA ep data, we find a good\ndescription also of Tevatron data on production of W, beauty and jets in\ndiffractive events defined either by leading antiprotons or by one or two\nrapidity gaps in the forward or backward regions. We also give predictions for\ndiffractive J/psi production where the soft exchange mechanism produces both a\ngap and a color singlet ccbar state in the same event. This soft color\ninteraction approach is also compared with Pomeron-based models for\ndiffraction, and some possibilities to experimentally discriminate between\nthese different approaches are discussed. \n\n"}
{"id": "hep-ph/0109068", "contents": "Title: Generic User Process Interface for Event Generators Abstract: Generic Fortran common blocks are presented for use by High Energy Physics\nevent generators for the transfer of event configurations from parton level\ngenerators to showering and hadronization event generators. \n\n"}
{"id": "hep-ph/0109128", "contents": "Title: Hyperfine structure in hydrogen and helium ion Abstract: QED theory of the hyperfine splitting of the $1s$ and $2s$ state in hydrogen\nisotopes and helium-3 ion is considered. We develop an accurate theory of a\nspecific difference 8E_{HFS}(2s)-E_{HFS}(1s). We take into account fourth order\ncorrections and nuclear structure effects. The theoretical prediction is now of\na higher accuracy than the experiment is. The study of the difference provides\nthe most accurate test (on a level of a part in 10^8) of the QED theory of $1s$\nHFS up to date. The theory agrees with most of the experimental data. \n\n"}
{"id": "hep-ph/0110248", "contents": "Title: Muon anomalous magnetic moment: a consistency check for the\n  next-to-leading order hadronic contributions Abstract: A model for verifying a consistency of the next-to-leading order hadronic\ncontributions to the muon anomalous magnetic moment with those of the leading\norder is proposed. A part of the next-to-leading order hadronic contributions\nrelated to the vacuum polarization is rather accurately reproduced in the\nmodel. I find a new numerical value for the light-by-light hadronic\ncontribution that leads to agreement with recent experimental result for the\nmuon anomalous magnetic moment. \n\n"}
{"id": "hep-ph/0111004", "contents": "Title: g_\\mu - 2 in Supersymmetry Abstract: The 2.6 sigma deviation in the muon's anomalous magnetic moment has strong\nimplications for supersymmetry. In the most model-independent analysis to date,\nwe consider gaugino masses with arbitrary magnitude and phase, and sleptons\nwith arbitrary masses and left-right mixings. For tan(beta)=50, we find that 1\nsigma agreement requires at least one charged superpartner with mass below 570\nGeV; at 2 sigma, this upper bound shifts to 850 GeV. The deviation is\nremarkably consistent with all constraints from colliders, dark matter, and b\n-> s gamma in supergravity models, but disfavors the characteristic gaugino\nmass relations of anomaly-mediation. \n\n"}
{"id": "hep-ph/0111032", "contents": "Title: Limitations of B-meson mixing bounds on technicolor theories Abstract: Recent work by Burdman, Lane, and Rador has shown that B-meson mixing places\nstringent lower bounds on the masses of topgluons and Z' bosons in classic\ntopcolor-assisted technicolor (TC2) models. This paper finds analogous limits\non the Z' bosons of flavor-universal TC2 and non-commuting extended technicolor\nmodels, and compares the limits with those from precision electroweak\nmeasurements. A discussion of the flavor structure of these models (contrasted\nwith that of classic TC2) shows that B-meson mixing is a less reliable probe of\nthese models than of classic TC2. \n\n"}
{"id": "hep-ph/0112023", "contents": "Title: Theoretical Aspects of Standard-Model Higgs-Boson Physics at a Future\n  e^+ e^- Linear Collider Abstract: The Higgs boson is the missing link of the Standard Model of elementary\nparticle physics. We review its decay properties and production mechanisms at a\nfuture e^+ e^- linear collider and its e^- e^-, e^+- gamma, and gamma gamma\nmodes, with special emphasis on the influence of quantum corrections. We also\ndiscuss how its quantum numbers and couplings can be extracted from the study\nof appropriate final states. \n\n"}
{"id": "hep-ph/0201018", "contents": "Title: Deconstruction, G_2 Holonomy, and Doublet-Triplet Splitting Abstract: We describe a mechanism for using discrete symmetries to solve the\ndoublet-triplet splitting problem of four-dimensional supersymmetric GUT's. We\npresent two versions of the mechanism, one via ``deconstruction,'' and one in\nterms of M-theory compactification to four dimensions on a manifold of G_2\nholonomy. \n\n"}
{"id": "hep-ph/0201023", "contents": "Title: $h \\to \\mu^+\\mu^-$ via gluon fusion at the LHC Abstract: We study the observability of the $h\\to \\mu^+\\mu^-$ decay in the Standard\nModel and the MSSM at the LHC. The observation of the $h\\mu\\mu$ coupling is\nimportant to determine whether the Higgs particle that generates mass for the\nweak bosons is also responsible for mass generation of the second generation of\nfermions. We find that the signal via the gluon fusion channel is comparable to\nthat from the weak-boson fusion. By combining these two channels, observing\n$h\\to \\mu^+\\mu^-$ is feasible at the LHC with a delivered luminosity of $300\nfb^{-1}$ at $3\\sigma$ statistical significance for 110 GeV $<m_h<140$ GeV in\nthe Standard Model. This corresponds to a $h\\mu\\mu$ coupling determination at\nabout 15% accuracy assuming $ht\\bar t, hb\\bar b$ couplings SM-like. The\nobservation becomes more promising in the MSSM for $\\tan\\beta>8$ and $M_A<130$. \n\n"}
{"id": "hep-ph/0204243", "contents": "Title: Measuring the Spin of Invisible Massive Graviton Excitations at Future\n  Linear Colliders Abstract: We consider the production process e-e+ -> G\\gamma of invisible gravitons (G)\nat future linear colliders. We discuss whether the angular distribution of the\nphoton (\\gamma) can be used to measure the spin of the invisible graviton, or\nof any other invisible objects produced. We propose a method based on the\nFourier expansion of the transverse energy squared moment distribution of the\nphoton. We provide justification for this method, and confirm, especially for\nthe case of two extra dimensions, that the method is valid within a realistic\nsetup, which includes the simulation of the Standard Model background,\nbeamstrahlung, bremsstrahlung, calorimeter resolution and calorimeter coverage.\nWhen the number of extra dimensions is increased, the angular distribution does\nnot provide sufficient information to extract the spin, but this method still\noffers a useful parameterization of the single photon cross section using which\nthe nature of the missing object can be studied. \n\n"}
{"id": "hep-ph/0206027", "contents": "Title: Explicit model realizing parton-hadron duality Abstract: An explicit model realizing parton-hadron duality and fitting the data is\nsuggested. Complex nonlinear Regge trajectories are important ingredients of\nthe model. The inclusion of $\\Delta$ and $N^*$ trajectories should account for\nall resonances in the direct channel. The exotic trajectory is responsible for\nthe smooth background. \n\n"}
{"id": "hep-ph/0206100", "contents": "Title: QED box amplitude in heavy fermion production Abstract: We evaluate the two-photon box contribution to heavy fermion production in\nelectron positron annihilation, that provides O(alpha^2) electromagnetic\ncorrections to the Born cross section. The study of its non-relativistic\nexpansion, relevant at energies close to the threshold of production, is also\nperformed. We also verify that the threshold expansion of the one-loop\nintegrals correctly reproduces our results, thus extending the applicability of\nthis technique to heavy fermion production diagrams. \n\n"}
{"id": "hep-ph/0206158", "contents": "Title: A Heavy-Light Chiral Quark Model Abstract: We present a new chiral quark model for mesons involving a heavy and a light\n(anti-) quark. The model relates various combinations of a quark - meson\ncoupling constant and loop integrals to physical quantities. Then, some\nquantities may be predicted and some used as input. The extension from other\nsimilar models is that the present model includes the lowest order gluon\ncondensate of the order (300 MeV)^4 determined by the mass splitting of the 0^-\nand the 1^- heavy meson states. Within the model, we find a reasonable\ndescription of parameters such as the decay constants f_B and f_D, the\nIsgur-Wise function and the axial vector coupling g_A in chiral perturbation\ntheory for light and heavy mesons. \n\n"}
{"id": "hep-ph/0206277", "contents": "Title: Landau-Khalatnikov-Fradkin Transformations and the Fermion Propagator in\n  Quantum Electrodynamics Abstract: We study the gauge covariance of the massive fermion propagator in three as\nwell as four dimensional Quantum Electrodynamics (QED). Starting from its value\nat the lowest order in perturbation theory, we evaluate a non-perturbative\nexpression for it by means of its Landau-Khalatnikov-Fradkin (LKF)\ntransformation. We compare the perturbative expansion of our findings with the\nknown one loop results and observe perfect agreement upto a gauge parameter\nindependent term, a difference permitted by the structure of the LKF\ntransformations. \n\n"}
{"id": "hep-ph/0208195", "contents": "Title: The structure functions F_2^c and F_L^c in the framework of the k_T\n  factorization Abstract: We present the perturbative parts of the structure functions F_2^c and F_L^c\nfor a gluon target having nonzero transverse momentum squared at order \\alpha\n_s. The results of the double convolution (with respect to the Bjorken variable\nx and the transverse momentum) of the perturbative part and the unintegrated\ngluon densities are compared with HERA experimental data for F_2^c. The\ncontribution from F_L^c structure function ranges 10\\div30% of that of F_2^c at\nthe HERA kinematical range. \n\n"}
{"id": "hep-ph/0209145", "contents": "Title: g factor in a light two body atomic system: a determination of\n  fundamental constants to test QED Abstract: Energy levels of a two-body atomic system in an external homogeneous magnetic\nfield can be presented in terms of magnetic moments of their components,\nhowever, those magnetic moments being related to bound particles differ from\ntheir free values. Study of bound g factors in simple atomic systems are now of\ninterest because of a recent progress in experiments on medium Z ions and of a\nnew generation of muonium experiments possible with upcoming intensive muon\nsources. We consider bound corrections to the g factors in several atomic\nsystems, experimental data for which are available in literature: hydrogen,\nhelium-3 ion, muonium, hydrogen-like ions with spinless nuclei with medium Z. \n\n"}
{"id": "hep-ph/0210048", "contents": "Title: Tests of Leptogenesis at Low Energy Abstract: The problem of testing leptogenesis from low energy experiments is discussed\nfollowing three different perspectives. Firstly, we review the prospects that\nfrom low energy experiments we could reconstruct the neutrino Yukawa coupling\nmatrix and hence constrain the leptogenesis mechanism. We emphasize the fact\nthat the experimental determination of the phases and mixings in the light\nneutrino mass matrix is irrelevant for leptogenesis, unless additional\ninformation about the texture of the Yukawa coupling matrix is provided by\nother observables. Secondly, we show how the discovery of an extra gauge boson\ncould bring us important indications for leptogenesis. Thirdly, we discuss the\nproblems one encounters when attempting to build a leptogenesis mechanism at a\ndirectly testable scale, presenting an explicit model which avoids these\nproblems. \n\n"}
{"id": "hep-ph/0210259", "contents": "Title: Radiative Corrections to Fixed Target Moller Scattering Including Hard\n  Bremsstrahlung Effects Abstract: We present a calculation of the complete $O(\\alpha)$ electroweak radiative\ncorrections to the Moller scattering process e^-e^- -> e^-e^-, including hard\nbremsstrahlung contributions. We study the effects of these corrections on both\nthe total cross section and polarization asymmetry measured in low energy fixed\ntarget experiments. Numerical results are presented for the experimental cuts\nrelevant for E-158, a fixed target e^-e^- experiment being performed at SLAC;\nthe effect of hard bremsstrahlung is to shift the measured polarization\nasymmetry by approximately +4%. We briefly discuss the remaining theoretical\nuncertainty in the prediction for the low energy Moller scattering polarization\nasymmetry. \n\n"}
{"id": "hep-ph/0210339", "contents": "Title: SUSY Dark Matter: Closing The Parameter Space Abstract: We consider here the constraints in SUGRA models on the SUSY parameter space\ndue to current experimental bounds on the light Higgs mass m_h, the b-> s gamma\ndecay, the amount of neutralino cold dark matter Omega h^2, and the muon\nmagnetic moment. Models with universal soft breaking (mSUGRA) and non-universal\ngaugino or Higgs masses at M_G are examined. For mSUGRA, the m_h, b->s gamma\nand Omega h^2 constraints imply a lower bound on the gaugino mass of\nm_{1/2}>~300GeV implying the gluino and squarks have mass >~700GeV, and the\nneutralino >~120GeV. The current status of the Brookhaven muon g - 2 experiment\nis reviewed, and if the Standard Model (SM) contribution evaluated using the\ne^+ + e^- data is correct, a 2 sigma bound on the deviation of experiment from\nthe SM produces an upper bound on m_{1/2} that eliminates the \"focus point\"\nregions of parameter space. Dark matter (DM) detection cross sections range\nfrom 5\\times10^{-8} pb to 5\\times10^{-10} pb which would be accessible to\nfuture planned detectors. The SUSY decay B_s->\\mu^+ +\\mu^- is seen to be\naccessible to the Tevatron Run 2B with 15 fb^{-1} luminosity for tanbeta >~30.\nThe most favorable signals of SUSY for linear colliders are stau pair\nproduction and neutralino pair production, though it will require an 800GeV\nmachine to cover the full parameter space. Non-universal models can modify some\nof the above results. Thus a non-universal (heavier) gluino mass at M_G can\nsignificantly reduce the lower bound constraints of b\\to s gamma and m_h giving\nrise to a lighter SUSY spectrum. A heavier up Higgs mass can open an additional\nregion with allowed relic density arising from annihilation via the s-channel Z\ndiagram with an O(10) larger DM detector cross section. \n\n"}
{"id": "hep-ph/0211114", "contents": "Title: Charged Higgs and Stau Production in Anomaly Mediated Supersymmetry\n  Breaking Abstract: Charged Higgs production in association with staus in electron positron\nannihilation is a signal of supersymmetry with bilinear R-Parity violation. In\nthis model, neutrino masses and mixing angles are generated due to mixing with\nneutralinos. We show how parameters related to neutrino physics can be\ndetermined at a $500 {\\mathrm fb}^{-1}$ Linear Collider from measurements of\ncharged Higgs and stau production cross sections and decay rates. This can be\nachieved in AMSB where charged Higgs and stau can have similar masses. \n\n"}
{"id": "hep-ph/0211239", "contents": "Title: Nonlinear corrections to the DGLAP equations in view of the HERA data Abstract: The effects of the first nonlinear corrections to the DGLAP evolution\nequations are studied by using the recent HERA data for the structure function\n$F_2(x,Q^2)$ of the free proton and the parton distributions from CTEQ5L and\nCTEQ6L as a baseline. By requiring a good fit to the H1 data, we determine\ninitial parton distributions at $Q_0^2=1.4$ GeV$^2$ for the nonlinear scale\nevolution. We show that the nonlinear corrections improve the agreement with\nthe $F_2(x,Q^2)$ data in the region of $x\\sim 3\\cdot 10^{-5}$ and $Q^2\\sim 1.5$\nGeV$^2$ without paying the price of obtaining a worse agreement at larger\nvalues of $x$ and $Q^2$. For the gluon distribution the nonlinear effects are\nfound to play an increasingly important role at $x\\lsim 10^{-3}$ and\n$Q^2\\lsim10$ GeV$^2$, but rapidly vanish at larger values of $x$ and $Q^2$.\nConsequently, contrary to CTEQ6L, the obtained gluon distribution at $Q^2=1.4$\nGeV$^2$ shows a power-like growth at small $x$. Relative to the CTEQ6L gluons,\nan enhancement up to a factor $\\sim6$ at $x=10^{-5}$, $Q_0^2=1.4$ GeV$^2$\nreduces to a negligible difference at $Q^2\\gsim 10$ GeV$^2$. \n\n"}
{"id": "hep-ph/0301189", "contents": "Title: Electroweak radiative corrections to single Higgs-boson production in\n  e+e- annihilation Abstract: We have calculated the complete electroweak O(alpha) radiative corrections to\nthe single Higgs-boson production processes e+ e- --> nu_l anti-nu_l H\n(l=e,mu,tau) in the electroweak Standard Model. Initial-state radiation beyond\nO(alpha) is included in the structure-function approach. The calculation of the\ncorrections is briefly described, and numerical results are presented for the\ntotal cross section. In the G_mu scheme, the bulk of the corrections is due to\ninitial-state radiation, which affects the cross section at the level of -7% at\nhigh energies and even more in the ZH threshold region. The remaining bosonic\nand fermionic corrections are at the level of a few per cent. The confusing\nsituation in the literature regarding differing results for the fermionic\ncorrections to this process is clarified. \n\n"}
{"id": "hep-ph/0301233", "contents": "Title: LFV decays and anomalous magnetic (electric) moments in a lepton mass\n  matrices ansatz induced by SUSY GUT Abstract: By using the anomalous magnetic and electric dipole moments of the $\\tau$\nlepton in an effective lagrangian approach to the new physics, we investigate\nthe lepton flavor violation (LFV) decays, $l\\to l'\\gamma$, and $\\mu,\\tau$\nanomalous magnetic and electric dipole moments in a lepton mass matrices ansatz\nwhich induced by SUSY GUT. We put very stringent constraints LFV decays and\n$\\tau$ anomalous magnetic and electric dipole moments. \n\n"}
{"id": "hep-ph/0302193", "contents": "Title: Choice of heavy baryon currents in QCD sum rules Abstract: In this paper we investigate the effects due to the mixing of two\ninterpolating currents for ground state baryons within the framework of Heavy\nQuark Effective Theory using the QCD sum rule approach. Both two-point and\nthree-point sum rules, thus the mass, coupling constant and Isgur-Wise function\nsum rules are considered. It is interesting to contrast those results with each\nother. Based on the Isgur-Wise functions obtained in this paper, we also\nanalyze the effects of current mixing to Lambda-type and and Sigma-type\nsemi-leptonic decays Lambda_b-->Lambda_c\\ell\\bar\\nu,\n\\Sigma_b-->\\Sigma_c\\ell\\bar\\nu and \\Sigma_b-->\\Sigma^*_c\\ell\\bar\\nu. Decay\nwidths corresponding to various mixing parameters are obtained and can be\ncompared to the experimental data. \n\n"}
{"id": "hep-ph/0303203", "contents": "Title: Large mixing angle solution to the solar neutrino problem and random\n  matter density perturbations Abstract: There are reasons to believe that mechanisms exist in the solar interior\nwhich lead to random density perturbations in the resonant region of the Large\nMixing Angle solution to the solar neutrino problem. We find that, in the\npresence of these density perturbations, the best fit point in the\n(sin^2(2\\theta), Delta_m^2) parameter space moves to smaller values, compared\nwith the values obtained for the standard LMA solution. Combining solar data\nwith KamLAND results, we find a new compatibility region, which we call\nVERY-LOW LMA, where sin^2(2\\theta) ~ 0.6 and Delta_m^2~2e-5 eV^2, for random\ndensity fluctuations of order 5% < \\xi< 8%. We argue that such values of\ndensity fluctuations are still allowed by helioseismological observations at\nsmall scales of order 10 - 1000 km deep inside the solar core. \n\n"}
{"id": "hep-ph/0304222", "contents": "Title: QCD Short-distance Constraints and Hadronic Approximations Abstract: This paper discusses a general class of ladder resummation inspired hadronic\napproximations. It is found that this approach naturally reproduces many\nsuccesses of single meson per channel saturation models (e.g. VMD) and NJL\nbased models. In particular the existence of a constituent quark mass and a gap\nequation follows naturally. We construct an approximation that satisfies a\nlarge set of QCD short-distance and large $N_c$ constraints and reproduces many\nhadronic observables.\n  We show how there exists in general a problem between QCD short-distance\nconstraints for Green Functions and those for form factors and cross-sections\nfollowing from the quark-counting rule. This problem while expected for Green\nfunctions that do not vanish in purely perturbative QCD also persists for many\nGreen functions that are order parameters. \n\n"}
{"id": "hep-ph/0306184", "contents": "Title: The little flavons Abstract: Fermion masses and mixing matrices can be described in terms of spontaneously\nbroken (global or gauge) flavor symmetries. We propose a little-Higgs inspired\nscenario in which an SU(2)xU(1) gauge flavor symmetry is spontaneously (and\ncompletely) broken by the vacuum of the dynamically induced potential for two\nscalar doublets (the flavons) which are pseudo-Goldstone bosons remaining after\nthe spontaneous breaking--at a scale between 10 and 100 TeV--of an approximate\nSU(6) global symmetry. The vacuum expectation values of the flavons give rise\nto the texture in the fermion mass matrices. We discuss in detail the case of\nleptons. Light-neutrino masses arise by means of a see-saw-like mechanism that\ntakes place at the same scale at which the SU(6) global symmetry is broken. We\nshow that without any fine tuning of the parameters the experimental values of\nthe charged-lepton masses,the neutrino square mass differences and the\nPontecorvo-Maki-Nakagawa-Sakata mixing matrix are reproduced. \n\n"}
{"id": "hep-ph/0308020", "contents": "Title: CMB constraints on non-thermal leptogenesis Abstract: Leptogenesis is at the heart of particle cosmology which requires physics\nbeyond the Standard Model. There are two possibilities of realizing\nleptogenesis; thermal and non-thermal. Both are viable given the scale of\ninflation and the constraint on the reheat temperature. However non-thermal\nleptogenesis can leave its imprint upon cosmic micro wave background radiation.\nIn this paper we will discuss cosmological constraints on non-thermal\nleptogenesis scenarios within supersymmetry. \n\n"}
{"id": "hep-ph/0308027", "contents": "Title: Unitarity at the LHC energies Abstract: Phenomena related to the non-perturbative aspects of strong interactions at\nthe LHC are discussed with emphasis on elastic and inelastic soft and hard\ndiffraction processes. Predictions for the global characteristics and angular\ndistributions in proton-proton collisions with elastic and multiparticle final\nstates are given. Potential for discovery of the novel effects related to the\nincreasing role of the elastic scattering at the LHC energies and its physical\nimplications in diffractive and multiparticle production processes are\nreviewed. \n\n"}
{"id": "hep-ph/0309009", "contents": "Title: Status of CCFM - unintegrated gluon densities Abstract: New fits of the unintegrated gluon density obtained from CCFM evolution to\nHERA $F_2(x,Q^2)$ data are presented. Also predictions of the unintegrated\ngluon density of the real photon are presented. \n\n"}
{"id": "hep-ph/0309162", "contents": "Title: Average Kinetic Energy of Heavy Quark ($\\mu_\\pi^2$) inside Heavy Meson\n  of $0^-$ State by Bethe-Salpeter Method Abstract: The average kinetic energy of the heavy quark inside $B$ or $D$ meson is\ncomputed by means of the instantaneous Bethe-Salpeter method. We first solve\nthe relativistic Salpeter equation and obtain the relativistic wave function\nand mass of $0^{-}$ state, then we use the relativistic wave function to\ncalculate the average kinetic energy of the heavy quark inside heavy meson of\n$0^{-}$ state. We find that the relativistic corrections to the average kinetic\nenergy of the heavy quark inside $B$ or $D$ meson are quite large and cannot be\nignored. We estimate $\\mu^2_\\pi~ (= - \\lambda_1)~ \\approx~ 0.35~ (B^0,B^\\pm)$,\n$~0.28~(D^0,D^\\pm)$, $~ 0.43~(B_s)$, $~0.34~(D_s)$, $~0.96~(B_c)$ and\n$0.62~(\\eta_c)$ GeV$^2$. \n\n"}
{"id": "hep-ph/0310249", "contents": "Title: Hadron resonance gas and nonperturbative QCD vacuum at finite\n  temperature Abstract: We study the nonperturbative QCD vacuum with two light quarks at finite\ntemperature in the framework of hadron resonance gas. Temperature dependence of\nthe quark and gluon condensates in the confined phase are obtained. We\ndemonstrate that the quark condensate and one half (chromo-electric component)\nof gluon condensate evaporate at the same temperature, which corresponds to the\ntemperature of quark-hadron phase transition. Critical temperature is T_c~190\nMeV when temperature shift of hadron masses is taken into account. \n\n"}
{"id": "hep-ph/0311257", "contents": "Title: The Top Priority: Precision Electroweak Physics from Low to High Energy Abstract: Overall, the Standard Model describes electroweak precision data rather well.\nThere are however a few areas of tension (charged current universality, NuTeV,\n(g-2)_\\mu, b quark asymmetries), which I review emphasizing recent theoretical\nand experimental progress. I also discuss what precision data tell us about the\nHiggs boson and new physics scenarios. In this context, the role of a precise\nmeasurement of the top mass is crucial. \n\n"}
{"id": "hep-ph/0312204", "contents": "Title: Fast simulation of flow effects in central and semi-central heavy ion\n  collisions at LHC Abstract: The simple method for simulation of ``thermal'' hadron spectra in\nultrarelativistic heavy ion collisions including longitudinal, transverse and\nelliptic flow is developed. The model is realized as fast Monte-Carlo event\ngenerator. \n\n"}
{"id": "hep-ph/0404273", "contents": "Title: Hyperon Radiative Decays in the 1/N_c Expansion Abstract: Using a recent calculation of transition magnetic moments in the 1/N_c\nexpansion and a calculation showing the suppression of E2/M1 by powers of N_c,\nwe compute the widths for the radiative decays Sigma^* --> Sigma gamma, Sigma^*\n--> Lambda gamma, and Xi^* --> Xi gamma. \n\n"}
{"id": "hep-ph/0406140", "contents": "Title: Transport equations for chiral fermions to order \\hbar and electroweak\n  baryogenesis: Part II Abstract: This is the second in a series of two papers. While in Paper I we derive\nsemiclassical Boltzmann transport equations and study their flow terms, here we\naddress the collision terms. We use a model Lagrangean, in which fermions\ncouple to scalars through Yukawa interactions and approximate the self-energies\nby the one-loop expressions. This approximation already contains important\naspects of thermalization and scatterings required for quantitative studies of\ntransport in plasmas. We compute the CP-violating contributions to both the\nscalar and the fermionic collision term. \n\n"}
{"id": "hep-ph/0406234", "contents": "Title: One-loop charge and colour breaking associated with the top Yukawa\n  coupling Abstract: We calculate the one-loop contributions to the MSSM effective potential when\nthe scalar top fields have non-zero vacuum expectation values and study their\nimpact on charge and colour breaking bounds. \n\n"}
{"id": "hep-ph/0407012", "contents": "Title: Kahler corrections and softly broken family symmetries Abstract: Spontaneously broken family symmetry provides a promising origin for the\nobserved quark and lepton mass and mixing angle structure. In a supersymmetric\ntheory such structure comes from a combination of the contributions from the\nsuperpotential and the K\\\"{a}hler potential. The superpotential effects have\nbeen widely studied but relatively little attention has been given to the\neffects of the K\\\"{a}hler sector. In this paper we develop techniques to\nsimplify the analysis of such K\\\"{a}hler effects. Using them we show that in\nthe class of theories with an hierarchical structure for the Yukawa couplings\nthe K\\\"{a}hler corrections to both the masses and mixing angles are\nsubdominant. This is true even in cases that texture zeros are filled in by the\nterms coming from the K\\\"{a}hler potential. \n\n"}
{"id": "hep-ph/0407358", "contents": "Title: A heavy Higgs boson from flavor and electroweak symmetry breaking\n  unification Abstract: We present a unified picture of flavor and electroweak symmetry breaking\nbased on a nonlinear sigma model spontaneously broken at the TeV scale. Flavor\nand Higgs bosons arise as pseudo-Goldstone modes. Explicit collective symmetry\nbreaking yields stable vacuum expectation values and masses protected at one\nloop by the little-Higgs mechanism. The coupling to the fermions generates\nwell-definite mass textures--according to a U(1) global flavor symmetry--that\ncorrectly reproduce the mass hierarchies and mixings of quarks and leptons. The\nmodel is more constrained than usual little-Higgs models because of bounds on\nweak and flavor physics. The main experimental signatures testable at the LHC\nare a rather large mass m_{h^0} = 317\\pm 80 GeV for the (lightest) Higgs boson\nand a characteristic spectrum of new bosons and fermions at the TeV scale. \n\n"}
{"id": "hep-ph/0408080", "contents": "Title: Pion and Kaon Decay Constants: Lattice vs. Resonance Chiral Theory Abstract: The Lattice results for the pion and kaon decay constants are analysed within\nthe Resonance Chiral Theory framework in the large NC limit. The approximately\nlinear behaviour of the observable at large light-quark mass is explained\nthrough the interaction with the lightest multiplet of scalar resonances. The\nanalysis of the Lattice results allows to obtain the resonance mass MS=1049 +-\n25 MeV and the Chiral Perturbation Theory parameters at leading order in 1/NC. \n\n"}
{"id": "hep-ph/0408158", "contents": "Title: Single top production and decay at next-to-leading order Abstract: We present the results of a next-to-leading order analysis of single top\nproduction including the decay of the top quark. Radiative effects are included\nboth in the production and decay stages, using a general subtraction method.\nThis calculation gives a good treatment of the jet activity associated with\nsingle top production. We perform an analysis of the single top search at the\nTevatron, including a consideration of the main backgrounds, many of which are\nalso calculated at next-to-leading order. \n\n"}
{"id": "hep-ph/0408276", "contents": "Title: Lepton Flavor Violation in the Higgs Boson Decay at a Linear Collider Abstract: We study possibility of observing the process $h^{0} \\to \\tau^{\\pm}\n\\mu^{\\mp}$ at a linear collider. The branching ratio is constrained to be of\nthe order of $10^{-4}$ by the $\\tau^{-} \\to \\mu^{-} \\eta$ result.\nSupersymmetric standard models can reproduce such amount of the branching ratio\nby taking a specific parameter set. The Higgsstrahlung process $e^{+}e^{-} \\to\nZh^{0}$ is preferable because of its simple kinematic structure, then, the\nsignal process is $e^{+} e^{-} \\to Z h^{0} \\to Z \\tau^{\\pm} \\mu^{\\mp}$. The\nmost serious background comes from the process, $e^{+} e^{-} \\to Zh^{0} \\to\nZ\\tau^{\\pm} \\tau^{\\mp} \\to \\tau^{\\pm} \\mu^{\\mp} \\nu \\bar{\\nu}$. We estimate the\nsignificance of the signal, taking into account the background reduction. \n\n"}
{"id": "hep-ph/0410279", "contents": "Title: Softly broken lepton number L_e - L_\\mu - L_\\tau with non-maximal solar\n  neutrino mixing Abstract: We consider the most general neutrino mass matrix which leads to $\\theta_{13}\n= 0$, and present the formulae needed for obtaining the neutrino masses and\nmixing parameters in that case. We apply this formalism to a model based on the\nlepton number $\\bar L = L_e - L_\\mu - L_\\tau$ and on the seesaw mechanism. This\nmodel needs only one Higgs doublet and has only two right-handed neutrino\nsinglets. Soft $\\bar L$ breaking is accomplished by the Majorana mass terms of\nthe right-handed neutrinos; if the $\\bar L$-conserving and $\\bar L$-breaking\nmass terms are of the same order of magnitude, then it is possible to obtain a\nconsistent $\\bar L$ model with a solar mixing angle significantly smaller than\n$45^\\circ$. We show that the predictions of this model, $m_3 = 0$ and\n$\\theta_{13} = 0$, are invariant under the renormalization-group running of the\nneutrino mass matrix. \n\n"}
{"id": "hep-ph/0411033", "contents": "Title: Power corrections in charmless B decays Abstract: Power corrections seem to play an important role in charmless B decays as\nindicated by recent analysis using QCD Factorization. In this talk, I would\nlike to report on a recent work on power corrections in charmless B decays. By\nusing the ratio of the branching fraction of $B^+ \\to \\pi^+ K^{\\ast 0}$ to that\nof $B^0 \\to \\pi^- \\rho^+$, for which the theoretical uncertainties are greatly\nreduced, it is shown in a transparent manner that power corrections in\ncharmless B decays are probably large and that the $B^0 \\to K^- \\rho^+$ decay\ncould be explained with the annihilation term included. For ratios of direct CP\nasymmetries, QCD Factorisation with the annihilation terms included would\npredict the direct CP asymmetry of $B \\to \\pi^+ \\pi^-$ to be about 3 times\nlarger than that of $B \\to \\pi^\\pm K^\\mp$, with opposite sign. In particular,\nthe large measured value for $B \\to \\pi^\\pm K^\\mp $ CP asymmetry implies\nnaturally a corresponding large $B \\to \\pi^+ \\pi^-$ CP asymmetry as observed by\nBelle. Experimentally any significant deviation from this prediction or\npossibly the importance of long-distance rescattering effects. \n\n"}
{"id": "hep-ph/0411058", "contents": "Title: Theoretical Overview: The New Mesons Abstract: After commenting on the state of contemporary hadronic physics and\nspectroscopy, I highlight four areas where the action is: searching for the\nrelevant degrees of freedom, mesons with beauty and charm, chiral symmetry and\nthe D_{sJ} levels, and X(3872) and the lost tribes of charmonium. \n\n"}
{"id": "hep-ph/0411064", "contents": "Title: Beyond The Standard Model Abstract: The present lectures contain an introduction to possible new physics beyond\nthe Standard Model. Having in mind first of all accelerator experiments of the\nnearest future we concentrate on supersymmetry, a new symmetry that relates\nbosons and fermions, as the first target of experimental search. Since\nsupersymmetry is widely covered in the literature, we mostly consider novel\ndevelopments and applications to hadron colliders. We describe then the\nso-called extra dimensional models in less detail and discuss their possible\nmanifestations. \n\n"}
{"id": "hep-ph/0412066", "contents": "Title: Can we distinguish between h^{SM} and h^0 in split supersymmetry? Abstract: We investigate the possibility to distinguish between the Standard Model\nHiggs boson and the lightest Higgs boson in Split Supersymmetry. We point out\nthat the best way to distinguish between these two Higgs bosons is through the\ndecay into two photons. It is shown that there are large differences of several\npercent between the predictions for \\Gamma(h\\to\\gamma\\gamma) in the two models,\nmaking possible the discrimination at future photon-photon colliders. Once the\ncharginos are discovered at the next generation of collider experiments, the\nwell defined predictions for the Higgs decay into two photons will become a\ncross check to identify the light Higgs boson in Split Supersymmetry. \n\n"}
{"id": "hep-ph/0412248", "contents": "Title: Pion distribution amplitude -- from theory to data Abstract: We describe the present status of the pion distribution amplitude as\noriginated from two sources: (i) a nonperturbative approach, based on QCD sum\nrules with nonlocal condensates, and (ii) a NLO QCD analysis of the CLEO data\non F^{\\gamma\\gamma^*\\pi}(Q^2), supplemented by the E791 data on diffractive\ndijet production, and the JLab F(pi) data on the pion electromagnetic form\nfactor. \n\n"}
{"id": "hep-ph/0501295", "contents": "Title: Sterile neutrinos in neutrinoless double beta decay Abstract: We study possible contribution of the Majorana neutrino mass eigenstate\n$\\nu_h$ dominated by a sterile neutrino component to neutrinoless double beta\n($0\\nu\\beta\\beta$) decay. From the current experimental lower bound on the\n$0\\nu\\beta\\beta$-decay half-life of $^{76}$Ge we derive stringent constraints\non the $\\nu_h-\\nu_e$ mixing in a wide region of the values of $\\nu_h$ mass. We\ndiscuss cosmological and astrophysical status of $\\nu_h$ in this mass region. \n\n"}
{"id": "hep-ph/0503231", "contents": "Title: Sleptonium at the linear collider and the slepton co-next-to-lightest\n  supersymmetric particle scenario in gauge mediated symmetry breaking models Abstract: We discuss the possibility of formation and subsequent detection of a\nsupersymmetric bound state composed of a slepton--antislepton pair at the next\nlinear collider. The Green function method is used within a non-relativistic\napproximation to estimate the threshold production cross-section of the $2P$\nbound state. The parameter space of Gauge Mediated Symmetry Breaking (GMSB)\nmodels allow a particular scenario in which a charged slepton\n($\\widetilde{e}_R, \\widetilde{\\mu}_R$ or $\\widetilde{\\tau}_1$) is the NLSP.\nWithin this scenario the produced $2P$ bound-state decays, through a dipole\ntransition, into the $1S$ ground-state with branching ratio $\\approx 100% $\nemitting a very soft ($\\approx 1 $ MeV) photon which goes undetected. The\nspectroscopy of the $1S$-state shows that it decays into two photons with $Br\n\\approx 0.5$ up to $m_{NLSP} \\approx 1$ TeV. Thus NLSP sleptonium threshold\nproduction gives rise to the signal $e^+e^- \\to 2P \\to 1S + \"soft \\gamma \" \\to\n\\gamma \\gamma$ which when compared with the standard model two-photon process\n($ e^+e^- \\to \\gamma \\gamma$) has a statistical significance\n($SS$=signal/noise) which, at an energy offset from threshold of E=20 GeV, goes\nfrom $SS=11$ to $SS=2$ when the mass of the NLSP ranges in the interval\n$[100,200]$ GeV. \n\n"}
{"id": "hep-ph/0506112", "contents": "Title: Large Non-perturbative Effects of Small \\Delta m^2_{21}/\\Delta m^2_{31}\n  and \\sin \\theta_{13} on Neutrino Oscillation and CP Violation in Matter Abstract: In the framework of three generations, we consider the CP violation in\nneutrino oscillation with matter effects. At first, we show that the\nnon-perturbative effects of two small parameters, \\Delta m_{21}^2/\\Delta\nm_{31}^2 and \\sin \\theta_{13}, become more than 50% in certain ranges of energy\nand baseline length. This means that the non-perturbative effects should be\nconsidered in detailed analysis in the long baseline experiments. Next, we\npropose a method to include these effects in approximate formulas for\noscillation probabilities. Assuming the two natural conditions,\n\\theta_{23}=45^\\circ and the fact that the matter density is symmetric, a set\nof approximate formulas, which involve the non-perturbative effects, has been\nderived in all channels. \n\n"}
{"id": "hep-ph/0506313", "contents": "Title: Smoking-gun signatures of little Higgs models Abstract: Little Higgs models predict new gauge bosons, fermions and scalars at the TeV\nscale that stabilize the Higgs mass against quadratically divergent one-loop\nradiative corrections. We categorize the many little Higgs models into two\nclasses based on the structure of the extended electroweak gauge group and\nexamine the experimental signatures that identify the little Higgs mechanism in\naddition to those that identify the particular little Higgs model. We find that\nby examining the properties of the new heavy fermion(s) at the LHC, one can\ndistinguish the structure of the top quark mass generation mechanism and test\nthe little Higgs mechanism in the top sector. Similarly, by studying the\ncouplings of the new gauge bosons to the light Higgs boson and to the Standard\nModel fermions, one can confirm the little Higgs mechanism and determine the\nstructure of the extended electroweak gauge group. \n\n"}
{"id": "hep-ph/0507320", "contents": "Title: Impact of the pion mass on nonpower expansion for QCD observables Abstract: A new set of functions, which form a basis of the massive nonpower expansion\nfor physical observables, is presented in the framework of the analytic\napproach to QCD at the four-loop level. The effects due to the $\\pi$ meson mass\nare taken into account by employing the dispersion relation for the Adler\nfunction. The nonvanishing pion mass substantially modifies the functional\nexpansion at low energies. Specifically, the spacelike functions are affected\nby the mass of the $\\pi$ meson in the infrared domain below few GeV, whereas\nthe timelike functions acquire characteristic plateaulike behavior below the\ntwo-pion threshold. At the same time, all the appealing features of the\nmassless nonpower expansion persist in the considered case of the nonvanishing\npion mass. \n\n"}
{"id": "hep-ph/0508106", "contents": "Title: Gravitational complementary principle: A new approach to quantum gravity Abstract: A new idea of quantum gravity is developed based on {\\it Gravitational\nComplementary Principle}. This principle states that gravity has dual\ncomplement features: The quantum and classical aspects of gravity are\ncomplement and absolutely separated by the planck length into planckian and\nover-planckian domains, respectively. The classical Einstein equations are\ncorrect at the fundamental level at over-planckian domain and general\nrelativity is not a low energy limit of a more fundamental theory. The quantum\ngravity is totally confined to the planckian domain with a new kind of\nultra-short range interaction, mediated by massive (Planck mass) particles,\nthrough the virtual microscopic wormholes of the Planck scale with action\n$\\hbar$. There is no room for gravitons or extra dimensions in this scenario.\nIt is shown that the hierarchy problem can solve the cosmological constant\nproblem via this new quantum gravity. \n\n"}
{"id": "hep-ph/0508108", "contents": "Title: Dark Matter visible by the EGRET Excess of Diffuse Galactic Gamma Rays? Abstract: The public data from the EGRET space telescope on diffuse galactic gamma rays\nin the energy range from 0.1 to 10 GeV show an excess for energies above 1 GeV\nin comparison with the expectations from conventional galactic models. This\nexcess shows all the key features of Dark Matter Annihilation (DMA), like being\nobservable in al sky directions with a shape corresponding to a WIMP mass\nbetween 50 and 100 GeV. The intensity of the excess in various directions can\nbe used to reconstruct the DM profile, which - combined with the distribution\nof visible matter - allows to calculate the rotation curve of our Galaxy. Its\npeculiar shape, which is not flat, but shows a minimum and maximum, is indeed\nreconstructed from the gamma rays, thus proving that the EGRET excess traces\nthe DM. Furthermore, the spectral shape of the excess is consistent with mSUGRA\nand the WMAP relic density for rather heavy squarks and sleptons - O(1 TeV) -\nand light charginos, neutralinos and gluinos (below 500 GeV). \n\n"}
{"id": "hep-ph/0509153", "contents": "Title: Hadronization -- the Unsung Hero rather than the Alleged Villain in the\n  Tale of CP Violation Abstract: The novel successes scored by the Standard Model of High Energy Physics in\nthe last few years concerning heavy flavour dynamics do not weaken the case for\n`New Physics' around the TeV scale. They do suggest however that one cannot\n{\\em count} on that New Physics impacting heavy flavour decays in a numerically\nmassive way. Yet studying this impact will be essential in diagnosing the\nfeatures of the New Physics. In particular the decays of beauty hadrons have to\nbe analyzed with considerable precision on the experimental as well as\ntheoretical side. While hadronization effects often represent the main\nbottleneck in our understanding in the short run, they will provide powerful\nand discriminating tools in the long run, when applied comprehensively and\njudiciously. The expertise required to exhaust the discovery potential in $B$\ndecays does exist in the hadron physics community or can be developed without\nneeding a new breakthrough -- yet a greater effort has to be made to\ncommunicate it to the heavy flavour community. \n\n"}
{"id": "hep-ph/0510076", "contents": "Title: Using high-power lasers for detection of elastic photon-photon\n  scattering Abstract: The properties of four-wave interaction via the nonlinear quantum vacuum is\ninvestigated. The effect of the quantum vacuum is to generate photons with new\nfrequencies and wave vectors, due to elastic photon-photon scattering. An\nexpression for the number of generated photons is derived and using\nstate-of-the-art laser data it is found that the number of photons can reach\ndetectable levels. In particular, the prospect of using the high repetition\nAstra Gemini system at the Rutherford Appleton Laboratory is discussed. The\nproblem of noise sources is reviewed, and it is found that the noise level can\nbe reduced well below the signal level. Thus, detection of elastic\nphoton-photon scattering may for the first time be achieved. \n\n"}
{"id": "hep-ph/0511285", "contents": "Title: Nonlinear $k_{\\perp}$-factorization: a new paradigm for an in-nucleus\n  hard QCD Abstract: We review the origin, and salient features, of the breaking of the\nconventional linear $k_{\\perp}$-factorization for an in-nucleus hard pQCD\nprocesses. A realization of the nonlinear $k_{\\perp}$-factorization which\nemerges instead is shown to depend on color properties of the underlying pQCD\nsubprocesses. We discuss the emerging universality classes and extend nonlinear\n$k_{\\perp}$-factorization to AGK unitarity rules for the excitation of the\ntarget nucleus. \n\n"}
{"id": "hep-ph/0602203", "contents": "Title: Meson Strings and Flavor Branes Abstract: In a QCD-like string model based on D6 flavor branes in the presence of D4\ncolor branes wrapping one of the compactified dimension on an $S^1$, the shape\nof meson strings in the five dimensional curved space as well as the potential\nbetween quark and anti-quark are investigated. The flavor branes on which both\nends of a meson string live are assumed to be separated in this five\ndimensional space, depending on the values of the constituent quark masses. It\nis shown in this picture that the meson string with different flavors on both\nends changes its shape at a critical distance. There is, however, no critical\ndistance for the meson with the same flavors. At this critical distance the\npotential between quark and anti-quark with different flavors gives a point of\nreflection and changes its shape around this point. Accordingly, the attractive\nforce between quark and anti-quark seems to become stronger when the distance\nof flavor branes connecting meson strings becomes larger. This indicates quark\nsystems with different flavors can form high-density states. \n\n"}
{"id": "hep-ph/0603034", "contents": "Title: Simulation of QED Radiation in Particle decays using the YFS Formalism Abstract: In this paper we describe a program (SOPHTY) implementing QED corrections to\ndecays in the HERWIG++ event generator. In order to resum the dominant soft\nemissions to all orders, the program is based on the YFS formalism. In\naddition, universal large collinear logarithms are included and the approach\ncan be systematically extended to incorporate exact, process specific, higher\norder corrections to decays. Due to the large number of possible decay modes\nthe program is designed to operate, as far as possible, independently of the\ndecay matrix elements. \n\n"}
{"id": "hep-ph/0603167", "contents": "Title: Boson Fusion and Higgs production at the LHC in six fermion final states\n  with one charged lepton pair Abstract: Boson boson scattering and Higgs production in boson boson fusion will be\nactively investigated at the LHC. We have performed a parton level study of all\nprocesses of the type $q_1 q_2 \\to q_3 q_4 q_5 q_6 l^+l^-$ using for the first\ntime a full fledged six fermion Monte Carlo event generator which employs exact\nmatrix elements at $\\O(\\alpha_{em}^6)$. We have examined Higgs production in\nvector boson fusion followed by the decay chain $H\\to ZZ\\to l^+l^-jj$,\nincluding exactly all electroweak irreducible backgrounds. In the high mass\nregion we have compared the case of a relatively light Higgs with the no-Higgs\ncase. The integrated cross section for the latter case is more than twice that\nin the former for a minimum invariant mass of the $ZV$ pair of about 800 \\GeV.\nWe find, in a preliminary anlysis at parton level that, summing up the muon and\nthe electron channels, about 30 events are expected in the light Higgs case for\nL=100 $fb^{-1}$. \n\n"}
{"id": "hep-ph/0604126", "contents": "Title: Lepton Flavor Violation in Intersecting D-brane Models Abstract: We investigate lepton flavor violation in the context of intersecting D-brane\nmodels. We point out that these models have a source to generate flavor\nviolation in the trilinear scalar couplings while the geometry of the\nconstruction leads to degenerate soft scalar masses for different generations\n(as in the minimal supergravity model) at the string scale. The trilinear\nscalar couplings are not proportional to the Yukawa couplings when the F-term\nof the U-moduli contribution is non-zero. Consequently, the lepton flavor\nviolating decay processes are generated. Only other sources of flavor\nviolations in this model are the Dirac neutrino Yukawa coupling and the\nMajorana couplings. The observed fermion mixings are realized from the ``almost\nrank 1\" Yukawa matrices, which generate a simple texture for the trilinear\nscalar terms. We calculate the branching ratios of tau -> mu gamma, mu -> e\ngamma and the electric dipole moment of the electron in this model. We find\nthat the observation of all the lepton flavor violating decay processes and the\nelectric dipole moment will be able to sort out different flavor violating\nsources. \n\n"}
{"id": "hep-ph/0605058", "contents": "Title: Two knees and the Evasion of Greisen-Zatsepin-Kuz'min Cutoff in Cosmic\n  Ray Spectrum -- Are Neutrinos the Tachyons? Abstract: The whole spectrum of high-energy cosmic ray (HECR) is, very likely,\ninfluenced by tachyonic neutrinos. Especially, the appearance of two knees can\nbe fitted by the tachyon mass $m(\\nu_e)=m(\\nu_\\mu)\\simeq 0.51$ eV/$c^2$ as\npredicted by a minimal three - flavor model for tachyonic neutrino with one\nparameter $\\delta=0.38$ eV only. Then the evasion of GZK cutoff could be\nascribed to $Z^0(W^\\pm)$-burst model together with the same mechanism for knees\nas well as a prediction of left-right polarization dependent lifetime\nasymmetry. A further conclusive experiment might be whether the protons of HECR\ndetected on Earth are really right handed polarized? \n\n"}
{"id": "hep-ph/0605117", "contents": "Title: Higgs + 2 Jets as a Probe for CP Properties Abstract: Azimuthal angle correlations of the jets in Hjj events at the LHC provide a\nprobe of the CP nature of Higgs couplings to gauge bosons. In weak boson fusion\nthe HWW and HZZ couplings are tested. Gluon fusion processes probe the tensor\nstructure of the effective Hgg vertex and thus the CP nature of the dominant\nquark couplings. \n\n"}
{"id": "hep-ph/0606101", "contents": "Title: Two modes of searching for new neutrino interactions at MINOS Abstract: The SuperKamiokande atmospheric neutrino measurements leave substantial room\nfor nonstandard interactions (NSI) of neutrinos with matter in the nu_e- nu_tau\nsector. Large values of the NSI couplings are accommodated if the vacuum\noscillation parameters are changed from their standard values. Short and medium\nbaseline neutrino beams can break this degeneracy by measuring the true vacuum\noscillation parameters with the muon neutrino disappearance mode, for which the\nmatter effects are negligible or subdominant. These experiments can also search\nfor the nu_e-nu_tau flavor changing effects directly, by looking for\nnu_mu->nu_e conversion caused by the intervening matter. We discuss both of\nthese methods for the case of MINOS. We find that, while the present MINOS data\non nu_mu disappearance induce only minor changes on the constraints on the NSI\nparameters, the situation will improve markedly with the planned increase of\nthe statistics by an order of magnitude. In that case, the precision will be\nenough to distinguish certain presently allowed NSI scenarios from the no-NSI\ncase. NSI per quark of about 10% the size of the standard weak interaction\ncould give a nu_mu - nu_e conversion probability of the order ~ 10^{-2},\nmeasurable by MINOS in the same high statistics scenario. In this nu_mu - nu_e\nchannel, the small effects of NSI could be comparable or larger than the vacuum\ncontribution of the small angle theta_{13}. The expected theta_{13} bound at\nMINOS should be more properly interpreted as a bound in the theta_{13}-NSI\nparameter space. \n\n"}
{"id": "hep-ph/0606224", "contents": "Title: A new understanding of fermion masses from the unified theory of spins\n  and charges Abstract: In this letter we try to answer those of the open questions of the Standard\nmodel which concern the appearance of families, mass protection mechanism and\nthe Yukawa couplings - by using the approach (proposed by one of us), which\nsuggests a new way beyond the Standard model. The approach has in the starting\naction for fermions, which carry in d(=1 +13)-dimensional space only the spin\n(two kinds of the spin) and interact with only spin connection and vielbein\nfields, the term manifesting as a mass term in d=1+3. (After making several\napproximations and assumptions) we connect free parameters of the approach with\nthe experimental data and investigate a possibility that the fourth family\nappears at low enough energies to be observable in the new generation of\naccelerators. \n\n"}
{"id": "hep-ph/0607283", "contents": "Title: Quark-Hadron Duality in Spin Structure Functions g1p and g1d Abstract: New measurements of the spin structure functions of the proton and deuteron\ng1p(x,Q2) and g1d(x,Q2) in the nucleon resonance region are compared with\nextrapolations of target-mass-corrected next-to-leading-order (NLO) QCD fits to\nhigher energy data. Averaged over the entire resonance region (W<2 GeV), the\ndata and QCD fits are in good agreement in both magnitude and Q2 dependence for\nQ2>1.7 GeV2. This global duality appears to result from cancellations among the\nprominent local resonance regions: in particular strong sigma{3/2}\ncontributions in the Delta(1232) region appear to be compensated by strong\nsigma{1/2} contributions in the resonance region centered on 1.5 GeV. These\nresults are encouraging for the extension of NLO QCD fits to lower W and Q2\nthan have been used previously. \n\n"}
{"id": "hep-ph/0608058", "contents": "Title: Quark-hadron duality in neutrino scattering Abstract: We present a phenomenological model of the quark-hadron transition in\nneutrino-nucleon scattering. Using recently extracted weak nucleon transition\nform factors, we investigate the extent to which local and global quark-hadron\nduality is applicable in the neutrino F_1, F_2 and F_3 structure functions, and\ncontrast this with duality in electron scattering. Our findings suggest that\nduality works relatively well for neutrino-nucleon scattering for the F_2 and\nF_3 structure functions, but not as well for F_1. We also calculate the\nquasielastic, resonance and deep inelastic contributions to the Adler sum rule,\nand find it to be satisfied to within 10% for 0.5 < Q^2 < 2 GeV^2. \n\n"}
{"id": "hep-ph/0608262", "contents": "Title: Strange nucleon form factors: Solitonic approach to $G_{M}^{s}$,\n  $G_{E}^{s}$, $\\tilde{G}_{A}^{p}$ and $\\tilde{G}_{A}^{n}$ and comparison with\n  world data Abstract: We summarize the results of the chiral quark-soliton model ($\\chi$QSM)\nconcerning basically all form factors necessary to interpret the present data\nof the parity violating electron scattering experiments SAMPLE, HAPPEX, A4 and\nG0. The results particularly focus on the recently measured asymmetries and the\ndetailed data for various combinations of $G_{M}^{s}$, $G_{E}^{s}$,\n$\\tilde{G}_{A}^{p}$ and $\\tilde{G}_{A}^{n}$ at $Q^2=0.1$ GeV$^2$. The\ncalculations yield positive strange magnetic and electric form factors and a\nnegative axial vector one, all being rather small. The results are very close\nto the combined experimental world data from parity violating electron\nscattering and elastic $\\nu p$- and $\\bar{\\nu p}$- scattering. \n\n"}
{"id": "hep-ph/0609061", "contents": "Title: Supersymmetric extra U(1) models with a singlino dominated LSP Abstract: We investigate phenomenology related to the neutral fields in supersymmetric\nmodels with an extra U(1) derived from $E_6$. Our study is concentrated into\nthe models which have a singlino dominated neutralino as the lightest\nsuperparticle (LSP). If such models satisfy a constraint for dark matter\nderived from the WMAP data, the lightest neutral Higgs scalar, a new neutral\ngauge field $Z^\\prime$ and the LSP may be interesting targets for the study at\nthe LHC. We also discuss features of the $Z^\\prime$ in the models and its\ndetectability at the LHC. \n\n"}
{"id": "hep-ph/0610005", "contents": "Title: Signals of the littlest Higgs model with T-parity at $e\\gamma$ and $ep$\n  collisions Abstract: Littlest Higgs model with T-parity predicts the existence of the neutral,\nweakly interacting, new gauge boson $B_{H}$, which can be seen as an attractive\ndark matter candidate. We study production of the new gauge boson $B_{H}$ via\n$e\\gamma$ and $ep$ collisions. We find that $B_{H}$ can be abundantly produced\nvia the subprocesses $e^{-}\\gamma\\to L^{-}B_{H}$ and $\\gamma q\\to B_{H}Q$,\nwhich might give rise to characteristic signals. Some discussions about the\n$SM$ backgrounds for this kind of signals are also given. \n\n"}
{"id": "hep-ph/0610084", "contents": "Title: The BFKL Pomeron Calculus in zero transverse dimensions: diffractive\n  processes and survival probability for central diffractive production Abstract: In this paper we discuss the processes of diffractive production in the\nframework of the BFKL Pomeron calculus in zero transverse dimension.\nConsidering the diffractive production of a bunch of particles with not very\nlarge masses, namely,\n  $\\ln\\Lb M^2/m^2 \\Rb \\ll \\frac{1}{\\bas} \\ln\\Lb \\frac{N^2_c}{\\bas^2}\\Rb$, we\nfound explicit formulae for calculation of the cross sections for the single\nand double diffractive production as well as for the value of the survival\nprobability for the diffractive central production. These formulae include the\ninfluence of the correlations due to so called Pomeron loops on the values of\nall discussed observables. The comparison with the other approaches on the\nmarket is given. The main conclusion of this comparison: the\nMueller-Patel-Salam-Iancu approximation gives sufficiently good descriptions\nand close to the exact result for elastic and diffractive cross section but\nconsiderable overshoot the value of the survival probability. \n\n"}
{"id": "hep-ph/0611198", "contents": "Title: Topological charge screening and the infrared behavior of the instanton\n  density Abstract: A new mechanism for suppression of the instanton density in the infrared is\nconsidered. This mechanism is based on the phenomenon of topological charge\nscreening, which leads to an effective cutoff in the contribution of large\ninstantons. \n\n"}
{"id": "hep-ph/0611232", "contents": "Title: Towards constraints on the SUSY seesaw from flavour-dependent\n  leptogenesis Abstract: We systematically investigate constraints on the parameters of the\nsupersymmetric type-I seesaw mechanism from the requirement of successful\nthermal leptogenesis in the presence of upper bounds on the reheat temperature\n$T_\\mathrm{RH}$ of the early Universe. To this end, we solve the\nflavour-dependent Boltzmann equations in the MSSM, extended to include\nreheating. With conservative bounds on $T_\\mathrm{RH}$, leading to mildly\nconstrained scenarios for thermal leptogenesis, compatibility with observation\ncan be obtained for extensive new regions of the parameter space, due to\nflavour-dependent effects. On the other hand, focusing on (normal) hierarchical\nlight and heavy neutrinos, the hypothesis that there is no CP violation\nassociated with the right-handed neutrino sector, and that leptogenesis\nexclusively arises from the CP-violating phases of the $U_\\text{MNS}$ matrix,\nis only marginally consistent. Taking into account stricter bounds on\n$T_\\mathrm{RH}$ further suggests that (additional) sources of CP violation must\narise from the right-handed neutrino sector, further implying stronger\nconstraints for the right-handed neutrino parameters. \n\n"}
{"id": "hep-ph/0703142", "contents": "Title: Cosmology in a supersymmetric model with gauged $B-L$ Abstract: We consider salient cosmological features of a supersymmetric model which is\nLeft-Right symmetric and therefore possessing gauged $B-L$ symmetry. The\nrequirement of breaking parity and also obtaining charge preserving vacua\nintroduces some unique features to this model (MSLRM), resulting in a\npreference for non-thermal Leptogenesis. Assuming that the model preserves TeV\nscale supersymmetry, we show that the vacuum structure generically possesses\ndomain walls, which can serve two important purposes. They can signal a\nsecondary inflation required to remove unwanted relics such as gravitino and\nmoduli and also generate lepton asymmetry by a mechanism similar to electroweak\nbaryogenesis. The requirement of disappearance of domain walls imposes\nconstraints on the soft parameters of the theory, testable at the TeV scale. We\nalso propose an alternative model with spontaneous parity violation\n(MSLR\\rlap/P). Incorporating the same cosmological considerations in this case\nentails constraints on a different set of soft parameters. \n\n"}
{"id": "hep-ph/9504244", "contents": "Title: Expansion, Thermalization and Entropy Production in High-Energy Nuclear\n  Collisions Abstract: The thermalization process is studied in an expanding parton gas using the\nBoltzmann equation with two types of collision terms. In the relaxation time\napproximation we determine the criteria under which a time-dependent relaxation\ntime leads to thermalization of the partons. We calculate the entropy\nproduction due to collisions for the general time-dependent relaxation time. In\na perturbative QCD approach on the other hand, we can estimate the parton\ncollision time and its dependence on expansion time. The effective `out of\nequilibrium' collision time differs from the standard transport relaxation\ntime, $\\tau_{\\rm tr}\\simeq(\\alpha_s^2\\ln(1/\\alpha_s)T)^{-1}$, by a weak time\ndependence. It is in both cases Debye screening and Landau damping that\nregulate the singular forward scattering processes. We find that the parton gas\ndoes thermalize eventually but only after having undergone a phase of free\nstreaming and gradual equilibration where considerable entropy is produced\n(``after-burning\"). The final entropy and thus particle density depends on the\ncollision time as well as the initial conditions (a ``memory effect\"). Results\nfor entropy production are presented based upon various model estimates of\nearly parton production. \n\n"}
{"id": "hep-ph/9601330", "contents": "Title: Recent Refinements in Higgs Physics Abstract: Recent refinements of the phenomenology of Higgs bosons in the Standard Model\nand the Minimal Supersymmetric Standard Model are reviewed. \n\n"}
{"id": "hep-ph/9604223", "contents": "Title: QCD and Yukawa corrections to single-top-quark production via q qbar ->\n  t bbar Abstract: We calculate the O(alpha_s) and O(alpha_W m_t^2/M_W^2) corrections to the\nproduction of a single top quark via the weak process q qbar -> t bbar at the\nFermilab Tevatron and the CERN Large Hadron Collider. An accurate calculation\nof the cross section is necessary in order to extract |V_tb| from experiment. \n\n"}
{"id": "hep-ph/9604382", "contents": "Title: Physically Motivated Approximation to a Parton Distribution Function in\n  QCD Abstract: It has been suggested that parton distributions in coordinate space, so\ncalled Ioffe-time distributions, provide a more natural object for\nnon-perturbative methods compared to the usual momentum distributions. In this\npaper we argue that the shape of experimentally determined Ioffe-time\ndistributions of quarks in a nucleon target clearly indicates separation of\nlongitudinal scales, which is not easily recognizable in terms of conventional\nlongitudinal momentum space considerations. We demonstrate how to use this\nobservation to determine parton distributions, using non-perturbative\ninformation about the first few moments and the Regge asymptotics at small $x$. \n\n"}
{"id": "hep-ph/9605338", "contents": "Title: Seeking Supersymmetry at LEP Abstract: 1. Scope and motivation\n  2. Lightning review of CMSSM\n  3. LEP 1 bounds and LEP 1.5 results\n  4. LEP 2 futurology\n  5. Bottomline \n\n"}
{"id": "hep-ph/9608479", "contents": "Title: Testing QCD Predictions for Multiplicity Distributions at HERA Abstract: On the basis of a recently introduced generalization of the negative binomial\ndistribution the influence of higher-order perturbative QCD effects on\nmultiplicity fluctuations are studied for deep inelastic e^+p scattering at\nHERA energies. It is found that the multiplicity distributions measured by the\nH1 Collaboration indicate violation of infinite divisibility in agreement with\npQCD calculations. Attention is called to future experimental analysis of\ncombinants whose nontrivial sign-changing oscillations are predicted using the\ngeneralized negative binomial law. \n\n"}
{"id": "hep-ph/9609243", "contents": "Title: Review of higher order QCD corrections to structure functions Abstract: A review is presented on all higher order QCD corrections to deep inelastic\nstructure functions. The implications of these corrections for polarized and\nunpolarized deep inelastic lepton-hadron scattering will be discussed. \n\n"}
{"id": "hep-ph/9610358", "contents": "Title: Signals for the Minimal Gauge-mediated Supersymmetry Breaking Model at\n  the Fermilab Tevatron Collider Abstract: We investigate the experimental implications of the minimal gauge-mediated\nlow energy supersymmetry breaking (GMLESB) model for Fermilab Tevatron collider\nexperiments. We map out the regions of parameter space of this model that have\nalready been excluded by collider searches and by limits on $b\\to s\\gamma$. We\nuse ISAJET to compute the cross sections for a variety of topological\nsignatures which include photons in assocation with multiple leptons, jets and\nmissing transverse energy. The reach in the parameter $\\Lambda$, which fixes\nthe scale of sparticle masses, is estimated to be $\\sim 60$, 100 and 135 TeV\nfor Tevatron integrated luminosities of 0.1, 2 and 25 fb$^{-1}$, respectively.\nThe largest signals occur in photon(s) plus lepton(s) plus multi-jet channels;\njet-free channels containing just photons plus leptons occur at much smaller\nrates, at least within this minimal framework. \n\n"}
{"id": "hep-ph/9611357", "contents": "Title: On the position of a heavy Higgs pole Abstract: Higher loop calculations in the Higgs sector of the standard model at the\nHiggs mass scale have shown that perturbation theory diverges very badly at\nabout 1 TeV in the on-shell renormalization scheme. The prediction of the\nposition of the Higgs pole in the complex s-plane becomes unreliable. We show\nthat in the pole renormalization scheme this appears to have much better\nconvergence properties, while showing good agreement with the on-shell scheme\nover the validity range of the latter. This suggests that the pole scheme\nshould be preferable for phenomenological studies of heavy Higgs bosons. We\ndiscuss whether this behaviour can be the result of a certain relation between\nthe on-shell mass and the pole mass at the nonperturbative level. \n\n"}
{"id": "hep-ph/9611390", "contents": "Title: Chiral Symmetry Breaking in Axial Gauge QCD from the Dyson Schwinger\n  Equations Abstract: We investigate the nonperturbative behaviour of the quark propagator in axial\ngauge using a truncation of the Dyson-Schwinger equations which respects the\nWard-Takahashi identity and multiplicative renormalisability. We demonstrate\nthat above a critical coupling $\\alpha_c$, which depends on the form of the\ngluon propagator, one can obtain massive solutions for both explicit and\ndynamically generated quark masses. The stability of these is discussed in the\ncontext of the Cornwall-Jackiw-Tomboulis effective action. \n\n"}
{"id": "hep-ph/9612397", "contents": "Title: A wide scalar neutrino resonance and b\\bar{b} production at LEP Abstract: In supersymmetric models with R-parity violation, scalar neutrinos may be\nproduced as s-channel resonances in e^+e^- colliders. We note that within\ncurrent constraints, the scalar neutrino may have a width of several GeV into\nb\\bar{b} and be produced with large cross section, leading to a novel\nsupersymmetry discovery signal at LEP II. In addition, if the scalar neutrino\nmass approximately equals m_Z, such a resonance necessarily increases R_b and\nreduces A_{FB}(b), significantly improving the fit to electroweak data. Bounds\nfrom B meson and top quark decays are leading constraints, and we stress the\nimportance of future measurements. \n\n"}
{"id": "hep-ph/9703417", "contents": "Title: Asymptotically Free Partons at High Energy Abstract: We describe the application of renormalization group improved perturbative\nQCD to inelastic lepton-hadron scattering at high center-of-mass energy but\ncomparatively low photon virtuality. We construct a high energy factorization\ntheorem which complements the mass factorization theorem used for processes\nwith high virtualities. From it we derive a renormalization group equation\nwhich resums all large logarithms at high energy, thereby extending to this\nregime asymptotic freedom and thus the full range of perturbative computational\ntechniques. We discuss the solution of this equation in various limits, and in\nparticular show that the high energy behaviour of physical cross-sections is\nconsistent with phenomenological expectations and unitarity bounds. \n\n"}
{"id": "hep-ph/9704237", "contents": "Title: Summary and Outlook Abstract: This will be more of an outlook than a summary ... \n\n"}
{"id": "hep-ph/9705327", "contents": "Title: Long distance $c \\to u \\gamma$ effects in weak radiative decays of\n  D-mesons Abstract: We present a detailed analysis of the $D \\to V \\gamma $ transitions, using a\nmodel which combines heavy quark effective theory and the chiral Lagrangian\napproach and includes symmetry breaking. We notice that in addition to the\npreviously considered s - channel annihilation and t - channel W - exchange,\nthere is a long distance penguin - like $ c \\to u \\gamma$ contribution in the t\n- channel of Cabibbo - suppressed modes. Its magnitude is determined by the\nsize of symmetry breaking which we calculate with a vector dominance approach.\nAlthough smaller in magnitude, the penguin - like contribution would lead to\nsizeable effects in case of cancellations among the other contributions to the\namplitude. Thus, it may invalidate suggested tests for beyond the standard\nmodel effects in these decays. We also indicate the range of expectations for\nthe branching ratios of various $D \\to V \\gamma$ modes. \n\n"}
{"id": "hep-ph/9709230", "contents": "Title: Comment on \"Hara's theorem in the constituent quark model\" Abstract: It is pointed out that current conservation alone does not suffice to prove\nHara's theorem as it was claimed recently. By explicit calculation we show that\nthe additional implicit assumption made in such \"proofs\" is that of a\nsufficiently localized current. \n\n"}
{"id": "hep-ph/9709291", "contents": "Title: CP Violation Beyond the Standard Model Abstract: Recent developments concerning CP violation beyond the Standard Model are\nreviewed. The central target of this presentation is the $B$ system, as it\nplays an outstanding role in the extraction of CKM phases. Besides a general\ndiscussion of the appearance of new physics in the corresponding CP-violating\nasymmetries through $B^0_q$--$\\bar{B^0_q}$ mixing $(q\\in\\{d,s\\})$, it is\nemphasized that CP violation in non-leptonic penguin modes, e.g. in $B_d\\to\\phi\nK_{S}$, offers a powerful tool to probe physics beyond the Standard Model. In\nthis respect $B\\to\\pi K$ modes, which have been observed recently by the CLEO\ncollaboration, may also turn out to be very useful. Their combined branching\nratios allow us to constrain the CKM angle $\\gamma$ and may indicate the\npresence of physics beyond the Standard Model. \n\n"}
{"id": "hep-ph/9710404", "contents": "Title: Neutrino helicity flip by Cerenkov emission and absorption of plasmons\n  in supernova Abstract: We show that in a supernova core the longitudinal photon (plasmon) has a\nspace-like dispersion and Cerenkov absorption and emission of such photons is\nkinematically allowed. If the neutrino has a non-zero magnetic moment, then\nhelicity flipping Cerenkov absorption of a plasmon $\\nu_L+\\gamma\\to\\nu_R$ is\nthe most efficient cooling mechanism of the supernova core, and this allows us\nto put a restrictive bound on the neutrino magnetic moment\n$\\mu_{\\nu}~<~0.7\\times 10^{-13}\\mu_B$. \n\n"}
{"id": "hep-ph/9711464", "contents": "Title: SUSY-QCD corrections to squark production and decays in e+e-\n  annihilation Abstract: We discuss the supersymmetric O(alpha_s) QCD corrections to e+ e- -> squark_i\n+ antisquark_j (i,j = 1,2) and to squark_i -> q' + chargino_j, q + neutralino_k\n(i,j = 1,2; k = 1...4) within the Minimal Supersymmetric Standard Model. In\nparticular we consider the squarks of the third generation stop_i and sbottom_i\nincluding the left-right mixing. In the on-shell scheme also the mixing angle\nhas to be renormalized. We use dimensional reduction (which preserves\nsupersymmetry) and compare it with the conventional dimensional regularization.\nA detailed numerical analysis is also presented. \n\n"}
{"id": "hep-ph/9711515", "contents": "Title: Tests of the Standard Model: W mass and WWZ Couplings Abstract: Recent tests of the electroweak Standard Model are reviewed, covering the\nprecise measurements of Z decays at LEP I and SLC and measurements of fermion\npair production at higher energies at LEP II. Special emphasis is given to new\nresults on W physics from LEP and FNAL. \n\n"}
{"id": "hep-ph/9801234", "contents": "Title: Precision Supersymmetry Measurements at the e^-e^- Collider Abstract: Measurements of supersymmetric particle couplings provide important\nverification of supersymmetry. If some of the superpartners are at the\nmulti-TeV scale, they will escape direct detection at planned future colliders.\nHowever, such particles induce nondecoupling corrections in processes involving\nthe accessible superparticles through violations of the supersymmetric\nequivalence between gauge boson and gaugino couplings. These violations are\nanalogous to the oblique corrections in the electroweak sector of the standard\nmodel, and can be parametrized in terms of super-oblique parameters. The $e^-\ne^-$ collision mode of a future linear collider is shown to be an excellent\nenvironment for such high precision measurements of these SUSY parameters,\nwhich will provide an important probe of superparticles beyond reachable\nenergies. \n\n"}
{"id": "hep-ph/9805346", "contents": "Title: Superheavy Dark Matter with Discrete Gauge Symmetries Abstract: We show that there are discrete gauge symmetries protect naturally heavy X\nparticles from decaying into the ordinary light particles in the supersymmetric\nstandard model. This makes the proposal very attractive that the superheavy X\nparticles constitute a part of the dark matter in the present universe. It is\nmore interesting that there are a class of discrete gauge symmetries which\nnaturally accommodate a long-lived unstable X particle. We find that in some\ndiscrete Z_{10} models, for example, a superheavy X particle has lifetime\n\\tau_X \\simeq 10^{11}-10^{26} years for its mass M_X \\simeq 10^{13}-10^{14}\nGeV. This long lifetime is guaranteed by the absence of lower dimensional\noperators (of light particles) couple to the X. We briefly discuss a possible\nexplanation for the recently observed ultra-high-energy cosmic ray events by\nthe decay of this unstable X particle. \n\n"}
{"id": "hep-ph/9805484", "contents": "Title: QCD Power Corrections from a Simple Model for the Running Coupling Abstract: A simple parametrization of the QCD running coupling at low scales is\nintroduced and used to illustrate various schemes for the estimation of\nnon-perturbative power corrections. The `infrared matching' scheme proposed\nearlier gives satisfactory results when combined with next-to-leading (or\nhigher) order perturbative predictions. Estimates based on renormalons are\nshown to be inconsistent with universal behaviour of the running coupling. \n\n"}
{"id": "hep-ph/9807265", "contents": "Title: Cosmological Moduli Problem in a Supersymmetric Model with Direct Gauge\n  Mediation Abstract: Recently, an interesting class of the direct gauge mediation supersymmetry\n(SUSY) breaking models are proposed, in which the minimum of the potential of\nthe SUSY breaking field is determined by the inverted hierarchy mechanism. We\nconsider their cosmological implications. In this class of models, SUSY\nbreaking field has a very flat potential, which may have a cosmological\nimportance. Assuming the initial amplitude of the SUSY breaking field to be of\nthe order of the Planck scale, it can be a source of a large entropy\nproduction. A special attention is paid to the cosmological moduli problem, and\nwe will see the cosmological mass density of the moduli field can be\nsignificantly reduced. \n\n"}
{"id": "hep-ph/9807453", "contents": "Title: Sigma-terms in heavy baryon chiral perturbation theory revisited Abstract: The $\\sigma$-terms are calculated at next-to-leading order in heavy baryon\nchiral perturbation theory by employing a cutoff regularization. The results do\nnot depend on the cutoff value to the order we are working . The baryon masses\nand $\\sigma_{\\pi N}(0)$ are used to perform a least-squares fit to the three\nappearing low-energy constants and predictions for the two $KN$ $\\sigma$-terms\nand the strange contribution to the nucleon mass are made. The lack of\nconvergence in the chiral expansions of these quantities when regularized\ndimensionally is overcome in the cutoff scheme. The $\\sigma$-term shifts to the\npertinent Cheng-Dashen points are calculated. We also include the spin-3/2\ndecuplet in the effective theory. \n\n"}
{"id": "hep-ph/9808251", "contents": "Title: Neutrino Textures in the Light of Super-Kamiokande Data and a Realistic\n  String Model Abstract: Motivated by the Super-Kamiokande atmospheric neutrino data, we discuss\npossible textures for Majorana and Dirac neutrino masses within the see-saw\nframework. The main purposes of this paper are twofold: first to obtain\nintuition from a purely phenomenological analysis, and secondly to explore to\nwhat extent it may be realized in a specific model. We comment initially on the\nsimplified two-generation case, emphasizing that large mixing is not\nincompatible with a large hierarchy of mass eigenvalues. We also emphasize that\nrenormalization-group effects may amplify neutrino mixing, presenting\nsemi-analytic expressions for estimating this amplification. Several examples\nare then given of three-family neutrino mass textures which may also\naccommodate the persistent solar neutrino deficit, with different assumptions\nfor the neutrino Dirac mass matrices. We comment on a few features of neutrino\nmass textures arising in models with a U(1) flavour symmetry. Finally, we\ndiscuss the possible pattern of neutrino masses in a `realistic' flipped SU(5)\nmodel derived from string theory, illustrating how a desirable pattern of\nmixing may emerge. Both small- or large-angle MSW solutions are possible,\nwhilst a hierarchy of neutrino masses appears more natural than\nnear-degeneracy. This model contains some unanticipated features that may also\nbe relevant in other models: the neutrino Dirac matrices may not be related\nclosely to the quark mass matrices, and the heavy Majorana states may include\nextra gauge-singlet fields. \n\n"}
{"id": "hep-ph/9812420", "contents": "Title: The Spin Structure of the Nucleon (Lectures at the 13th Lake Louise\n  Winter Institute) Abstract: This paper gives a pedagogical introduction to our knowledge of the spin\nstructure of the nucleon. In particular, polarised deep inelastic lepton\nscattering is presented as a tool to study how the nucleon's constituents\ncombine to generate its spin. The importance of semi-inclusive measurements is\ndiscussed and a window on future experiments in the field is given. \n\n"}
{"id": "hep-ph/9903245", "contents": "Title: R-parity violating decays of the Top-Quark and the Top-Squark at the\n  Tevatron Abstract: We study unconventional decays of the top-quark and the top-squark in the\nframework of SUSY models with broken R-parity. The model under study is the\nMSSM with an additional bilinear term that breaks R-parity. In this model the\ntop-squark behaves similar to a third generation leptoquark. We demonstrate\nthat existing Tevatron data on the top give rise to restrictions on the SUSY\nparameter space. In particular, we focus on scenarios where the tau-neutrino\nmass is smaller than 1 eV. We give an exclusion plot derived from the\nleptoquark searches at Tevatron. \n\n"}
{"id": "hep-ph/9905541", "contents": "Title: West Indies or Antarctica -- Direct CP Violation in B Decays Abstract: A Discovery Voyage into The Age of: PENGUINS (chubby little figure). \n\n"}
{"id": "hep-ph/9906237", "contents": "Title: Quark-antiquark Bethe-Salpeter formalism, spectrum and Regge\n  Trajectories Abstract: Starting from a path integral representation of appropriate 4-point and\n2-point gauge invariant Green functions and from the \"Modified Area Law\" model\nfor the evaluation of the Wilson loop, a q \\bar q Bethe-Salpeter like equation\nand a related Schwinger-Dyson equation can be obtained. From such equations an\neffective relativistic Hamiltonian can be derived by standard methods and then\napplied to the determination of the meson spectrum. The entire known\nheavy-heavy and heavy-light spectra and the lowest light-light Regge\ntrajectories are rather well reproduced in terms of four parameters alone, the\nlight quark masses being fixed a priori on typical current values. \n\n"}
{"id": "hep-ph/9906409", "contents": "Title: Exclusive evolution kernels in two-loop order: parity even sector Abstract: We complete the construction of the non-forward evolution kernels in\nnext-to-leading order responsible for the scale dependence of e.g. parity even\nsinglet distribution amplitudes. Our formalism is designed to avoid any\nexplicit two-loop calculations employing instead conformal and supersymmetric\nconstraints as well as known splitting functions. \n\n"}
{"id": "hep-ph/9906448", "contents": "Title: Reactions gamma gamma -> pi pi and gamma gamma -> K \\bar K: the\n  (IJ^{PC}=00^{++})-wave spectra at E_{gamma gamma}^{(c.m.)} = 300- 1900 MeV Abstract: We calculate the $00^{++}$-wave two-meson spectra for the reactions\n$\\gamma\\gamma\\to\\pi^0\\pi^0$, $\\gamma\\gamma\\to\\pi^+\\pi^-$, $\\gamma\\gamma\\to\nK^0\\bar K^0$ and $\\gamma\\gamma\\to K^+ K^-$ on the basis of: (i) the results of\nthe $K$-matrix analysis of the $00^{++}$ amplitudes for the reactions $\\pi\\pi\n\\to \\pi\\pi$, $K\\bar K$, $\\eta\\eta$, $\\eta\\eta'$, $\\pi\\pi\\pi\\pi $, and (ii)\nrecently developed method for calculation of the decay amplitudes\n$f_0(1^3P_0q\\bar q)\\to \\gamma\\gamma$, $f_0(2^3P_0q\\bar q)\\to \\gamma\\gamma$. The\nreconstructed $\\pi\\pi $ and $K\\bar K$ spectra can be used as a guide for the\nextraction of partial widths of scalar/isoscalar resonances $f_0(980)\\to\n\\gamma\\gamma$, $f_0(1300)\\to \\gamma\\gamma$, $f_0(1500)\\to \\gamma\\gamma$,\n$f_0(1750)\\to \\gamma\\gamma$. As follows from our calculations, the resonances\n$f_0(980)$ and $f_0(1500)$ in the $\\pi^+\\pi^-$ and $\\pi^0\\pi^0$ spectra reveal\nthemselves as dips. \n\n"}
{"id": "hep-ph/9907377", "contents": "Title: Large Higgs Boson Exchange Contribution in Three-Body Neutralino Decays Abstract: We show that the Higgs boson exchange contribution can be large in three-body\ndecays of neutralinos even in the case of small tan(beta). This enlarges the\nbranching ratios for the decays neutralino_2 -> neutralino_1 b \\bar{b} and\nneutralino_2 -> neutralino_1 tau- tau+. This is the case in the region of the\nparameter space where the two lightest neutralinos are gaugino-like, the\nsfermions are heavier than 300 GeV, and m_A0 = 200 GeV or smaller. \n\n"}
{"id": "hep-ph/9907408", "contents": "Title: A 3-Dimensional Calculation of Atmospheric Neutrino Flux Abstract: An extensive 3-dimensional Monte Carlo calculation of the atmospheric\nneutrino flux is in progress with the FLUKA Monte Carlo code. The results are\ncompared to those obtained under the 1-dimensional approximation, where\nsecondary particles and decay products are assumed to be collinear to the\nprimary cosmic ray, as usually done in most of the already existing flux\ncalculations. It is shown that the collinear approximation gives rise to a\nwrong angular distribution of neutrinos, essentially in the Sub-GeV region.\nHowever, the angular smearing introduced by the experimental inability of\ndetecting recoils in neutrino interactions with nuclei is large enough to wash\nout, in practice, most of the differences between 3-dimensional and\n1-dimensional flux calculations. Therefore, the use of the collinear\napproximation should have not introduced a significant bias in the\ndetermination of the flavor oscillation parameters in current experiments. \n\n"}
{"id": "hep-ph/9908431", "contents": "Title: Light-front quark model predictions of meson elastic and transition form\n  factors Abstract: We investigate the electroweak form factors and semileptonic decay rates of\nmesons using the constituent quark model based on the light-front degrees of\nfreedom. Our results demonstrate the broader applicability of light-front\napproach including the timelike region of exclusive processes. \n\n"}
{"id": "hep-ph/9910433", "contents": "Title: Comment on \"New conditions for a total neutrino conversion in a medium\" Abstract: We show that the conditions for total neutrino conversion found in [1] are\nequivalent to the conditions of maximal depth (parametric resonance) and\n($\\pi/2 + \\pi k$) - phase of parametric oscillations. Therefore the effects\nconsidered in [1] are a particular case of the parametric resonance in neutrino\noscillations. The existence of strong enhancement peaks in transition\nprobability P rather than the condition P=1 is of physical relevance. We\ncomment on possible realizations and implications of the parametric enhancement\nof neutrino oscillations. \n\n"}
{"id": "hep-ph/9911320", "contents": "Title: Pion-nucleon scattering and the nucleon sigma term in an extended sigma\n  model Abstract: A modified linear sigma model that allows for $g_A = 1.26$ by addition of\nvector and pseudovector $\\pi N$ coupling terms was discussed by Bjorken and\nNauenberg and by Lee. In this extended linear sigma model the elastic $\\pi $N\nscattering amplitudes satisfy the relevant chiral low-energy theorems, such as\nthe Weinberg-Tomozawa relation for the isovector scattering length and in some\ncases Adler's \"consistency condition\". The agreement of the isospin symmetric\n$\\pi N$ scattering length with experiment is substantially improved in this\nextended sigma model as compared with the original one. We show that the\nnucleon sigma term ($\\Sigma_N$) in the linear- and the extended sigma models\nwith three different kinds of chiral symmetry breaking terms are identical.\nWithin the tree approximation the formal operator expression for the $\\Sigma_N$\nterm and the value extracted from the $\\pi N$ scattering matrix coincide. Large\nvalues of $\\Sigma_N$ are easily obtained without any $s\\bar s$ content of the\nnucleon. Using chiral rotations the Lagrangian of this extended sigma model\nreproduces the lowest-order $\\pi N$ chiral perturbation theory Lagrangian. \n\n"}
{"id": "hep-th/0001047", "contents": "Title: Large-N Gauge Theories Abstract: Four pedagogical Lectures at the NATO-ASI on \"Quantum Geometry\" in Akureyri,\nIceland, August 1999. Contents: 1. O(N) Vector Models, 2. Large-N QCD, 3. QCD\nin Loop Space, 4. Large-N Reduction \n\n"}
{"id": "hep-th/0004170", "contents": "Title: Quantum-Induced Soft Supersymmetry Breaking In Supergravity Abstract: We calculate the one-loop quantum contributions to soft supersymmetry\nbreaking terms in the scalar potential in supergravity theories regulated \\`a\nla Pauli-Villars. We find ``universal'' contributions, independent of the\nregulator masses and tree level soft supersymmetry breaking, that contribute\ngaugino masses and A-terms equal to the ``anomaly mediated'' contributions\nfound in analyses using spurion techniques, as well as a scalar mass term not\nidentified in those analyses. The universal terms are in general modified --\nand in some cases canceled -- by model-dependent terms. Under certain\nrestrictions on the couplings we recover the one-loop results of previous\n``anomaly mediated'' supersymmetry breaking scenarios. We emphasize the model\ndependence of loop-induced soft terms in the potential, which are much more\nsensitive to the details of Planck scale physics then are the one-loop\ncontributions to gaugino masses. We discuss the relation of our results to\nprevious analyses. \n\n"}
{"id": "hep-th/0005255", "contents": "Title: Facts of life with gamma(5) Abstract: The increasing precision of many experiments in elementary particle physics\nleads to continuing interest in perturbative higher order calculations in the\nelectroweak Standard Model or extensions of it. Such calculations are of\nincreasing complexity because more loops and/or more legs are considered.\nCorrespondingly efficient computational methods are mandatory for many\ncalculations. One problem which affects the feasibility of higher order\ncalculations is the problem with gamma(5) in dimensional regularization. Since\nthe subject thirty years after its invention is still controversial I advocate\nhere some ideas which seem not to be common knowledge but might shed some new\nlight on the problem. I present arguments in favor of utilizing an\nanticommuting gamma(5) and a simple 4-dimensional treatment of the hard\nanomalies. \n\n"}
{"id": "hep-th/0008032", "contents": "Title: Spin 1/2 bosons etc. in a theory with Lorentz violation Abstract: An action with unconventional supersymmetry was introduced in an earlier\npaper. Here it is shown that this action leads to standard physics for fermions\nand gauge bosons at low energy, but to testable extensions of standard physics\nfor fermions at high energy and for fundamental bosons which have not yet been\nobserved. For example, the Lorentz-violating equation of motion for these\nbosons implies that they have spin 1/2. \n\n"}
{"id": "hep-th/0010234", "contents": "Title: Clocks, computers, black holes, spacetime foam, and holographic\n  principle Abstract: What do simple clocks, simple computers, black holes, space-time foam, and\nholographic principle have in common? I will show that the physics behind them\nis inter-related, linking together our concepts of information, gravity, and\nquantum uncertainty. Thus, the physics that sets the limits to computation and\nclock precision also yields Hawking radiation of black holes and the\nholographic principle. Moreover, the latter two strongly imply that space-time\nundergoes much larger quantum fluctuations than what the folklore suggests ---\nlarge enough to be detected with modern gravitational-wave interferometers\nthrough future refinements. \n\n"}
{"id": "hep-th/0107246", "contents": "Title: Exact solutions to Pauli-Villars-regulated field theories Abstract: We present a new class of quantum field theories which are exactly solvable.\nThe theories are generated by introducing Pauli-Villars fermionic and bosonic\nfields with masses degenerate with the physical positive metric fields. An\nalgorithm is given to compute the spectrum and corresponding eigensolutions. We\nalso give the operator solution for a particular case and use it to illustrate\nsome of the tenets of light-cone quantization. Since the solutions of the\nsolvable theory contain ghost quanta, these theories are unphysical. However,\nwe also discuss how perturbation theory in the difference between the masses of\nthe physical and Pauli-Villars particles could be developed, thus generating\nphysical theories. The existence of explicit solutions of the solvable theory\nalso allows one to study the relationship between the equal-time and light-cone\nvacua and eigensolutions. \n\n"}
{"id": "hep-th/0209237", "contents": "Title: Consistent power corrections to ultraviolet asymptotic solutions in\n  Yang-Mills theory Abstract: We show that the $1/p^2$ power corrections to the ultraviolet asymptotic\nsolutions are allowed as consistent solutions of the coupled Schwinger-Dyson\nequation for the gluon and (Faddeev-Popov) ghost propagators in Yang-Mills\ntheory. This result supports the existence of the vacuum condensate $<A_\\mu^2>$\nwith mass dimension 2, as recently suggested by the operator product expansion\nand lattice simulations. We compare the solution with the result of operator\nproduct expansion. \n\n"}
{"id": "hep-th/0301216", "contents": "Title: Stability of Neutral Fermi Balls with Multi-Flavor Fermions Abstract: A Fermi ball is a kind of non-topological soliton, which is thought to arise\nfrom the spontaneous breaking of an approximate $Z_2$ symmetry and to\ncontribute to cold dark matter. We consider a simple model in which fermion\nfields with multi-flavors are coupled to a scalar field through Yukawa\ncoupling, and examine how the number of the fermion flavors affects the\nstability of the Fermi ball against the fragmentation. (1)We find that the\nFermi ball is stable against the fragmentation in most cases even in the lowest\norder thin-wall approximation. (2)We then find that in the other specific\ncases, the stability is marginal in the lowest order thin-wall approximation,\nand the next-to-leading order correction determines the stable region of the\ncoupling constants; We examine the simplest case where the total fermion number\n$N_i$ and the Yukawa coupling constant $G_i$ of each flavor $i$ are common to\nthe flavor, and find that the Fermi ball is stable in the limited region of the\nparameters and has the broader region for the larger number of the flavors. \n\n"}
{"id": "hep-th/0303194", "contents": "Title: The statistics of string/M theory vacua Abstract: We discuss systematic approaches to the classification of string/M theory\nvacua, and physical questions this might help us resolve. To this end, we\ninitiate the study of ensembles of effective Lagrangians, which can be used to\nprecisely study the predictive power of string theory, and in simple examples\ncan lead to universality results. Using these ideas, we outline an approach to\nestimating the number of vacua of string/M theory which can realize the\nStandard Model. \n\n"}
{"id": "hep-th/0310213", "contents": "Title: Critical Phenomena in Continuous Dimension Abstract: We present a calculation of critical phenomena directly in continuous\ndimension d employing an exact renormalization group equation for the effective\naverage action. For an Ising-type scalar field theory we calculate the critical\nexponents nu(d) and eta(d) both from a lowest--order and a complete\nfirst--order derivative expansion of the effective average action. In\nparticular, this can be used to study critical behavior as a function of\ndimensionality at fixed temperature. \n\n"}
{"id": "hep-th/0402052", "contents": "Title: Cubic interactions in the BMN limit of AdS(3) x S(3) Abstract: We study the pp limit of AdS(3) x S(3) at the interaction level. We find the\ninteracting Hamiltonian for the bosonic fields of D=6 SUGRA in the pp-wave\nbackground, and compare it to the cubic couplings of the full AdS(3) x S(3). We\nshow how the pp-wave theory vertex arises in the large J limit. Our analysis\nalso provides some insight into the origin of specific prefactors which appear\nin the pp-wave interaction. \n\n"}
{"id": "hep-th/0406019", "contents": "Title: A CMB/Dark Energy Cosmic Duality Abstract: We investigate a possible connection between the suppression of the power at\nlow multipoles in the CMB spectrum and the late time acceleration. We show\nthat, assuming a cosmic IR/UV duality between the UV cutoff and a global\ninfrared cutoff given by the size of the future event horizon, the equation of\nstate of the dark energy can be related to the apparent cutoff in the CMB\nspectrum. The present limits on the equation of state of dark energy are shown\nto imply an IR cutoff in the CMB multipole interval of 9>l>8.5. \n\n"}
{"id": "hep-th/0410074", "contents": "Title: MSSM with Soft SUSY Breaking Terms from D7-Branes with Fluxes Abstract: We discuss the structure of the soft supersymmetry breaking terms in a MSSM\nlike model, which can be derived from D7-branes with chiral matter fields from\n2-form f-fluxes and supersymmetry breaking from 3-form G-fluxes. \n\n"}
{"id": "hep-th/0510101", "contents": "Title: Do We Have Evidence for New Physics in the Sky? Abstract: Predicting signatures of string theory on cosmological observables is not\nsufficient. Often the observable effects string theory may impact upon the\ncosmological arena may equally be predicted by features of inflationary\nphysics. The question: what observable signatures are unique to new physics, is\nthus of crucial importance for claiming evidence for the theory. Here we\ndiscuss recent progress in addressing the above question. The evidence relies\non identifying discrepancies between the source terms that give rise to large\nscale structure (LSS) and CMB, by cross-correlating the weak lensing potential\nmaps LSS with the CMB spectra. \n\n"}
{"id": "hep-th/0512194", "contents": "Title: Amplitudes in the beta-deformed Conformal Yang-Mills Abstract: We study perturbative amplitudes in a large class of theories obtained by\nmarginal deformations of the N=4 supersymmetric Yang-Mills. We find that planar\namplitudes in the deformed theories are closely related to planar amplitudes in\nthe original N=4 SYM. For some classes of deformations the amplitudes\nessentially coincide with the N=4 amplitudes to all orders in planar\nperturbation theory. For more general classes of marginal deformations, the\nequivalence holds at up to four loops, and at five loops it is likely to break\ndown. This implies that the iterative structure of planar MHV amplitudes\nrecently discovered by Bern, Dixon and Smirnov in hep-th/0505205 for the N=4\ntheory also manifests itself in a wider class of theories. \n\n"}
{"id": "hep-th/0604156", "contents": "Title: Nonequilibrium dynamics in the O(N) model to next-to-next-to-leading\n  order in the 1/N expansion Abstract: Nonequilibrium dynamics in quantum field theory has been studied extensively\nusing truncations of the 2PI effective action. Both 1/N and loop expansions\nbeyond leading order show remarkable improvement when compared to mean-field\napproximations. However, in truncations used so far, only the leading-order\nparts of the self energy responsible for memory loss, damping and equilibration\nare included, which makes it difficult to discuss convergence systematically.\nFor that reason we derive the real and causal evolution equations for an O(N)\nmodel to next-to-next-to-leading order in the 2PI-1/N expansion. Due to the\nappearance of internal vertices the resulting equations appear intractable for\na full-fledged 3+1 dimensional field theory. Instead, we solve the closely\nrelated three-loop approximation in the auxiliary-field formalism numerically\nin 0+1 dimensions (quantum mechanics) and compare to previous approximations\nand the exact numerical solution of the Schroedinger equation. \n\n"}
{"id": "hep-th/9907126", "contents": "Title: Elastic Parton-Parton Scattering from AdS/CFT Abstract: Using the AdS/CFT correspondence and the eikonal approximation, we evaluate\nthe elastic parton-parton scattering amplitude at large $N$ and strong coupling\n$g^2N$ in N=4 SYM. We obtain a scattering amplitude with a Regge behavior that\nunitarizes at large $\\sqrt{s}$. \n\n"}
{"id": "hep-th/9909048", "contents": "Title: Mass Hierarchy and Trapping of Gravity Abstract: We construct a model consisting of many D3-branes with only positive tension\nin a five-dimensional anti-de Sitter space-time geometry. It is shown that this\ntype of model naturally realizes not only exponential mass hierarchy between\nthe Planck scale and the electroweak scale but also trapping of the graviton on\nthe D3-branes. It is pointed out that our model may have a flexibility to\nexplain the existence of more than one disparate mass scales, such as the\nelectroweak scale and the GUT scale, on the same D3-brane. \n\n"}
{"id": "math-ph/0301028", "contents": "Title: Numerical Study of Nonlinear Equations with Infinite Number of\n  Derivatives Abstract: We study equations with infinitely many derivatives. Equations of this type\nform a new class of equations in mathematical physics. These equations\noriginally appeared in p-adic and later in fermionic string theories and their\ninvestigation is of much interest in mathematical physics and applications, in\nparticular in cosmology. Differential equation with infinite number of\nderivatives could be written as nonlinear integral equations. We perform\nnumerical investigation of solutions of the equations. It is established that\nthese equations have two different regimes of the solutions: interpolating and\nperiodic. The critical value of the parameter q separating these regimes is\nfound to be q^2=1.37. Convergence of iterative procedure for these equations is\nproved. \n\n"}
{"id": "math/0004108", "contents": "Title: New Numerical Algorithm for Modeling of Boson-Fermion Stars in Dilatonic\n  Gravity Abstract: We investigate numerically a models of the static spherically symmetric\nboson-fermion stars in scalar-tensor theory of gravity with massive dilaton\nfield. The proper mathematical model of such stars is interpreted as a\nnonlinear two-parametric eigenvalue problem with unknown internal boundary. We\nemploy the Continuous Analogue of Newton Method (CANM) which leads on each\niteration to two separate linear boundary value problems with different\ndimensions inside and outside the star, respectively. Along with them a\nnonlinear algebraic system for the spectral parameters - radius of the star\n$R_{s}$ and quantity $\\Omega $ is solved also.\n  In this way we obtain the behaviour of the basic geometric quantities and\nfunctions describing dilaton field and matter fields which build the star. \n\n"}
{"id": "math/0005035", "contents": "Title: Enhanced inverse-cascade of energy in the averaged Euler equations Abstract: For a particular choice of the smoothing kernel, it is shown that the system\nof partial differential equations governing the vortex-blob method corresponds\nto the averaged Euler equations. These latter equations have recently been\nderived by averaging the Euler equations over Lagrangian fluctuations of length\nscale $\\a$, and the same system is also encountered in the description of\ninviscid and incompressible flow of second-grade polymeric (non-Newtonian)\nfluids. While previous studies of this system have noted the suppression of\nnonlinear interaction between modes smaller than $\\a$, we show that the\nmodification of the nonlinear advection term also acts to enhance the\ninverse-cascade of energy in two-dimensional turbulence and thereby affects\nscales of motion larger than $\\a$ as well. This latter effect is reminiscent of\nthe drag-reduction that occurs in a turbulent flow when a dilute polymer is\nadded. \n\n"}
{"id": "math/0007113", "contents": "Title: Discrete singular convolution and its application to computational\n  electromagnetics Abstract: A new computational algorithm, the discrete singular convolution (DSC), is\nintroduced for computational electromagnetics. The basic philosophy behind the\nDSC algorithm for the approximation of functions and their derivatives is\nstudied. Approximations to the delta distribution are constructed as either\nbandlimited reproducing kernels or approximate reproducing kernels. A\nsystematic procedure is proposed to handle a number of boundary conditions\nwhich occur in practical applications. The unified features of the DSC\nalgorithm for solving differential equations are explored from the point of\nview of the method of weighted residuals. It is demonstrated that different\nmethods of implementation for the present algorithm, such as global, local,\nGalerkin, collocation, and finite difference, can be deduced from a single\nstarting point. Both the computational bandwidth and the accuracy of the DSC\nalgorithm are shown to be controllable. Three example problems are employed to\nillustrate the usefulness, test the accuracy and explore the limitation of the\nDSC algorithm. A Galerkin-induced collocation approach is used for a waveguide\nanalysis in both regular and irregular domains and for electrostatic field\nestimation via potential functions. Electromagnetic wave propagation in three\nspatial dimensions is integrated by using a generalized finite difference\napproach, which becomes a global-finite difference scheme at certain limit of\nDSC parameters. Numerical experiments indicate that the proposed algorithm is a\npromising approach for solving problems in electromagnetics. \n\n"}
{"id": "math/0202009", "contents": "Title: Convergence Acceleration Techniques Abstract: This work describes numerical methods that are useful in many areas: examples\ninclude statistical modelling (bioinformatics, computational biology),\ntheoretical physics, and even pure mathematics. The methods are primarily\nuseful for the acceleration of slowly convergent and the summation of divergent\nseries that are ubiquitous in relevant applications. The computing time is\nreduced in many cases by orders of magnitude. \n\n"}
{"id": "math/0503066", "contents": "Title: Stable Signal Recovery from Incomplete and Inaccurate Measurements Abstract: Suppose we wish to recover an n-dimensional real-valued vector x_0 (e.g. a\ndigital signal or image) from incomplete and contaminated observations y = A\nx_0 + e; A is a n by m matrix with far fewer rows than columns (n << m) and e\nis an error term. Is it possible to recover x_0 accurately based on the data y?\n  To recover x_0, we consider the solution x* to the l1-regularization problem\nmin \\|x\\|_1 subject to \\|Ax-y\\|_2 <= epsilon, where epsilon is the size of the\nerror term e. We show that if A obeys a uniform uncertainty principle (with\nunit-normed columns) and if the vector x_0 is sufficiently sparse, then the\nsolution is within the noise level \\|x* - x_0\\|_2 \\le C epsilon.\n  As a first example, suppose that A is a Gaussian random matrix, then stable\nrecovery occurs for almost all such A's provided that the number of nonzeros of\nx_0 is of about the same order as the number of observations. Second, suppose\none observes few Fourier samples of x_0, then stable recovery occurs for almost\nany set of p coefficients provided that the number of nonzeros is of the order\nof n/[\\log m]^6. In the case where the error term vanishes, the recovery is of\ncourse exact, and this work actually provides novel insights on the exact\nrecovery phenomenon discussed in earlier papers. The methodology also explains\nwhy one can also very nearly recover approximately sparse signals. \n\n"}
{"id": "math/0509016", "contents": "Title: Absolutely continuous laws of Jump-Diffusions in finite and infinite\n  dimensions with applications to mathematical Finance Abstract: In mathematical Finance calculating the Greeks by Malliavin weights has\nproved to be a numerically satisfactory procedure for finite-dimensional\nIt\\^{o}-diffusions. The existence of Malliavin weights relies on absolute\ncontinuity of laws of the projected diffusion process and a sufficiently\nregular density. In this article we first prove results on absolute continuity\nfor laws of projected jump-diffusion processes in finite and infinite\ndimensions, and a general result on the existence of Malliavin weights in\nfinite dimension. In both cases we assume H\\\"ormander conditions and hypotheses\non the invertibility of the so-called linkage operators. The purpose of this\narticle is to show that for the construction of numerical procedures for the\ncalculation of the Greeks in fairly general jump-diffusion cases one can\nproceed as in a pure diffusion case. We also show how the given results apply\nto infinite dimensional questions in mathematical Finance. There we start from\nthe Vasi\\v{c}ek model, and add -- by pertaining no arbitrage -- a jump\ndiffusion component. We prove that we can obtain in this case an interest rate\nmodel, where the law of any projection is absolutely continuous with respect to\nLebesgue measure on $\\mathbb{R}^M $. \n\n"}
{"id": "math/0509250", "contents": "Title: The max-plus finite element method for optimal control problems: further\n  approximation results Abstract: We develop the max-plus finite element method to solve finite horizon\ndeterministic optimal control problems. This method, that we introduced in a\nprevious work, relies on a max-plus variational formulation, and exploits the\nproperties of projectors on max-plus semimodules. We prove here a convergence\nresult, in arbitrary dimension, showing that for a subclass of problems, the\nerror estimate is of order $\\delta+\\Delta x(\\delta)^{-1}$, where $\\delta$ and\n$\\Delta x$ are the time and space steps respectively. We also show how the\nmax-plus analogues of the mass and stiffness matrices can be computed by convex\noptimization, even when the global problem is non convex. We illustrate the\nmethod by numerical examples in dimension 2. \n\n"}
{"id": "math/0512364", "contents": "Title: A quantitative investigation into the accumulation of rounding errors in\n  the numerical solution of ODEs Abstract: We examine numerical rounding errors of some deterministic solvers for\nsystems of ordinary differential equations (ODEs). We show that the\naccumulation of rounding errors results in a solution that is inherently random\nand we obtain the theoretical distribution of the trajectory as a function of\ntime, the step size and the numerical precision of the computer. We consider,\nin particular, systems which amplify the effect of the rounding errors so that\nover long time periods the solutions exhibit divergent behaviour. By performing\nmultiple repetitions with different values of the time step size, we observe\nnumerically the random distributions predicted theoretically. We mainly focus\non the explicit Euler and RK4 methods but also briefly consider more complex\nalgorithms such as the implicit solvers VODE and RADAU5. \n\n"}
{"id": "math/0601702", "contents": "Title: Resolve subgrid microscale interactions to discretise stochastic partial\n  differential equations Abstract: Constructing discrete models of stochastic partial differential equations is\nvery delicate. Stochastic centre manifold theory provides novel support for\ncoarse grained, macroscale, spatial discretisations of nonlinear stochastic\npartial differential or difference equations such as the example of the\nstochastically forced Burgers' equation. Dividing the physical domain into\nfinite length overlapping elements empowers the approach to resolve fully\ncoupled dynamical interactions between neighbouring elements. The crucial\naspect of this approach is that the underlying theory organises the resolution\nof the vast multitude of subgrid microscale noise processes interacting via the\nnonlinear dynamics within and between neighbouring elements. Noise processes\nwith coarse structure across a finite element are the most significant noises\nfor the discrete model. Their influence also diffuses away to weakly correlate\nthe noise in the spatial discretisation. Nonlinear interactions have two\nfurther consequences: additive forcing generates multiplicative noise in the\ndiscretisation; and effectively new noise processes appear in the macroscale\ndiscretisation. The techniques and theory developed here may be applied to\nsoundly discretise many dissipative stochastic partial differential and\ndifference equations. \n\n"}
{"id": "math/0602652", "contents": "Title: A numerical method for calculating the Green's function arising from\n  electronic structure theory Abstract: We developed a fast numerical methodfor complex symmetric shifted linear\nsystems, which is motivated by the quantum-mechanical (electronic-structure)\ntheory in nanoscale materials. The method is named shifted Conjugate Orthogonal\nConjugate Gradient (shifted COCG) method. The formulation is given and several\nnumerical aspects are discussed. \n\n"}
{"id": "math/0609549", "contents": "Title: Model selection for Poisson processes Abstract: Our purpose in this paper is to apply the general methodology for model\nselection based on T-estimators developed in Birg\\'{e} [Ann. Inst. H.\nPoincar\\'{e} Probab. Statist. 42 (2006) 273--325] to the particular situation\nof the estimation of the unknown mean measure of a Poisson process. We\nintroduce a Hellinger type distance between finite positive measures to serve\nas our loss function and we build suitable tests between balls (with respect to\nthis distance) in the set of mean measures. As a consequence of the existence\nof such tests, given a suitable family of approximating models, we can build\nT-estimators for the mean measure based on this family of models and analyze\ntheir performances. We provide a number of applications to adaptive intensity\nestimation when the square root of the intensity belongs to various smoothness\nclasses. We also give a method for aggregation of preliminary estimators. \n\n"}
{"id": "math/0612309", "contents": "Title: Universal algorithms for generalized discrete matrix Bellman equations\n  with symmetric Toeplitz matrix Abstract: This paper presents two universal algorithms for generalized Bellman\nequations with symmetric Toeplitz matrix. The algorithms are semiring\nextensions of two well-known methods solving Toeplitz systems in the ordinary\nlinear algebra. \n\n"}
{"id": "math/0702430", "contents": "Title: Approximate radical for clusters: a global approach using Gaussian\n  elimination or SVD Abstract: We present a method based on Dickson's lemma to compute the \"approximate\nradical\" of a zero dimensional ideal I in C[x1, . . ., xm] which has zero\nclusters: the approximate radical ideal has exactly one root in each cluster\nfor sufficiently small clusters. Our method is \"global\" in the sense that it\ndoes not require any local approximation of the zero clusters: it reduces the\nproblem to the computation of the numerical nullspace of the so called \"matrix\nof traces\", a matrix computable from the generating polynomials of I. To\ncompute the numerical nullspace of the matrix of traces we propose to use\nGaussian elimination with pivoting or singular value decomposition. We prove\nthat if I has k distinct zero clusters each of radius at most epsilon in the\nmax-norm, then k steps of Gauss elimination on the matrix of traces yields a\nsubmatrix with all entries asymptotically bounded by epsilon^2. We also show\nthat the (k+1)-th singular value of the matrix of traces is O(epsilon^2). The\nresulting approximate radical has one root in each cluster with coordinates\nwhich are the arithmetic mean of the cluster, up to an error term\nasymptotically bounded by epsilon^2. In the univariate case our method gives an\nalternative to known approximate square-free factorization algorithms which is\nsimpler and its accuracy is better understood. \n\n"}
{"id": "nucl-th/0011005", "contents": "Title: Dyson-Schwinger Equations - aspects of the pion Abstract: The contemporary use of Dyson-Schwinger equations in hadronic physics is\nexemplified via applications to the calculation of pseudoscalar meson masses,\nand inclusive deep inelastic scattering with a determination of the pion's\nvalence-quark distribution function. \n\n"}
{"id": "nucl-th/0109005", "contents": "Title: Neutron structure function $F_2^n(x)$ from deep inelastic electron\n  scattering off few-nucleon systems Abstract: The possibility of a reliable extraction of the neutron deep inelastic\nstructure function, $F_2^n(x)$, for $ x < 0.85$ from joint measurements of deep\ninelastic structure functions of deuteron, $^{3}He$ and $^{3}H$ is\ninvestigated. The model dependence in this extraction, linked to the possible\ndifferent interactions between nucleons in nuclei, is shown to be weak, if the\nnuclear structure effects are properly taken into account. A combined analysis\nof the deep inelastic structure functions of these nuclei is proposed to study\neffects beyond the impulse approximation. \n\n"}
{"id": "nucl-th/0207066", "contents": "Title: Vector meson production and nucleon resonance analysis in a\n  coupled-channel approach for energies m_N < sqrt(s) < 2 GeV I: pion-induced\n  results and hadronic parameters Abstract: We present a nucleon resonance analysis by simultaneously considering all\npion- and photon-induced experimental data on the final states gamma N, pi N, 2\npi N, eta N, K Lambda, K Sigma, and omega N for energies from the nucleon mass\nup to sqrt(s) = 2 GeV. In this analysis we find strong evidence for the\nresonances P_{31}(1750), P_{13}(1900), P_{33}(1920), and D_{13}(1950). The\nomega N production mechanism is dominated by large P_{11}(1710) and\nP_{13}(1900) contributions. In this first part, we present the results of the\npion-induced reactions and the extracted resonance and background properties\nwith emphasis on the difference between global and purely hadronic fits. \n\n"}
{"id": "nucl-th/0412033", "contents": "Title: The ground state in a spin-one color superconductor Abstract: Color superconductors in which quarks of the same flavor form Cooper pairs\nare investigated. These Cooper pairs carry total spin one. A systematic\ngroup-theoretical classification of possible phases in a spin-one color\nsuperconductor is presented, revealing parallels and differences to the theory\nof superfluid $^3$He. General expressions for the gap parameter, the critical\ntemperature, and the pressure are derived and evaluated for several spin-one\nphases, with special emphasis on the angular structure of the gap equation. It\nis shown that the (transverse) color-spin-locked phase is expected to be the\nground state. \n\n"}
{"id": "nucl-th/0507050", "contents": "Title: Hadrons in Medium Abstract: After a short motivation I outline a consistent treatment of hadronic\nspectral functions based on transport theory. As examples I discuss nucleon\nspectral functions and the observable effects of changes of the properties of\nvector mesons inside nuclei. \n\n"}
{"id": "nucl-th/0511054", "contents": "Title: Towards a field theoretic understanding of NN->NNpi Abstract: We study the production amplitude for the reaction NN->NNpi up to\nnext--to--leading order in chiral perturbation theory using a counting scheme\nthat takes into account the large scale introduced by the initial momentum. In\nparticular we investigate a subtlety that arises once the leading loop\ncontributions are convoluted with the NN wavefunctions as demanded by the\nnon--perturbative nature of the NN interaction. We show how to properly\nidentify the irreducible contribution of loop diagrams in such type of\nreaction. The net effect of the inclusion of all next-to-leading order loops is\nto enhance the leading rescattering amplitude by a factor of 4/3, bringing its\ncontribution to the cross section for pp->dpi+ close to the experimental value. \n\n"}
{"id": "nucl-th/0611033", "contents": "Title: Extraction and Interpretation of gamma N --> Delta Form Factors within a\n  Dynamical Model Abstract: Within the dynamical model of Refs. [Phys. Rev. C54, 2660 (1996); C63, 055201\n(2001)], we perform an analysis of recent data of pion electroproduction\nreactions at energies near the Delta(1232) resonance. We discuss possible\ninterpretations of the extracted bare and dressed gamma N --> Delta form\nfactors in terms of relativistic constituent quark models and Lattice QCD\ncalculations. Possible future developments are discussed. \n\n"}
{"id": "nucl-th/9801064", "contents": "Title: Nuclear forces from chiral Lagrangians using the method of unitary\n  transformation I: Formalism Abstract: We construct the two- and three-nucleon potential based on the most general\nchiral effective pion-nucleon Lagrangian using the method of unitary\ntransformations. For that, we develop a power counting scheme consistent with\nthis projection formalism. In contrast to previous results obtained in\nold-fashioned time-ordered perturbation theory, the method employed leads to\nenergy-independent potentials. We discuss in detail the similarities and\ndifferences to the existing chiral nucleon-nucleon potentials. We also show\nthat to leading order in the power counting, the three-nucleon forces vanish\nlending credit to the result obtained by Weinberg using old-fashioned\ntime-ordered perturbation theory. \n\n"}
{"id": "nucl-th/9807036", "contents": "Title: ${\\bar\\Lambda}/{\\bar p}$ ratios in heavy ion collisions at 11.6 AGeV/c Abstract: We attempt to explain the ${\\bar \\Lambda}/\\bar p$ ratios measured in heavy\nion collisions at $11.6~{\\rm A\\cdot GeV}/c$ beam momentum within a hadronic\nframework. This ratio is enhanced relative to corresponding ratios in $pp$\ncollisions, and is large when compared with thermal fits to heavy ion data.\nUsing a detailed cascade calculation, we show that different annihilation\ncross--sections of $\\bar \\Lambda$'s and $\\bar p$'s, and the net conversion of\n$\\bar p$'s to $\\bar \\Lambda$'s, do not account for the enhancement in central\ncollisions. For larger impact parameters, however, hadronic mechanisms may well\nsuffice to produce the observed enhancement. Uncertainties in elementary\ncross--sections and formation times are considered. \n\n"}
{"id": "nucl-th/9903080", "contents": "Title: Infinite Nuclear Matter on the Light Front: Nucleon-Nucleon Correlations Abstract: A relativistic light front formulation of nuclear dynamics is developed and\napplied to treating infinite nuclear matter in a method which includes the\ncorrelations of pairs of nucleons: this is light front Brueckner theory. We\nstart with a hadronic meson-baryon Lagrangian that is consistent with chiral\nsymmetry. This is used to obtain a light front version of a one-boson-exchange\nnucleon-nucleon potential (OBEP). The accuracy of our description of the\nnucleon-nucleon (NN) data is good, and similar to that of other relativistic\nOBEP models. We derive, within the light front formalism, the Hartree-Fock and\nBrueckner Hartree-Fock equations. Applying our light front OBEP, the nuclear\nmatter saturation properties are reasonably well reproduced. We obtain a value\nof the compressibility, 180 MeV, that is smaller than that of alternative\nrelativistic approaches to nuclear matter in which the compressibility usually\ncomes out too large. Because the derivation starts from a meson-baryon\nLagrangian, we are able to show that replacing the meson degrees of freedom by\na NN interaction is a consistent approximation, and the formalism allows one to\ncalculate corrections to this approximation in a well-organized manner. The\nsimplicity of the vacuum in our light front approach is an important feature in\nallowing the derivations to proceed. The mesonic Fock space components of the\nnuclear wave function are obtained also, and aspects of the meson and nucleon\nplus-momentum distribution functions are computed. We find that there are about\n0.05 excess pions per nucleon. \n\n"}
{"id": "nucl-th/9907026", "contents": "Title: Strangeness Enhancement in Heavy Ion Collisions - Evidence for\n  Quark-Gluon-Matter ? Abstract: The centrality dependence of (multi-)strange hadron abundances is studied for\nPb(158 AGeV)Pb reactions and compared to p(158 GeV)Pb collisions. The\nmicroscopic transport model UrQMD is used for this analysis. The predicted\nLambda/pi-, Xi-/pi- and Omega-/pi- ratios are enhanced due to rescattering in\ncentral Pb-Pb collisions as compared to peripheral Pb-Pb or p-Pb collisions. A\nreduction of the constituent quark masses to the current quark masses m_s \\sim\n230 MeV, m_q \\sim 10 MeV, as motivated by chiral symmetry restoration, enhances\nthe hyperon yields to the experimentally observed high values. Similar results\nare obtained by an ad hoc overall increase of the color electric field strength\n(effective string tension of kappa=3 GeV/fm). The enhancement depends strongly\non the kinematical cuts. The maximum enhancement is predicted around\nmidrapidity. For Lambda's, strangeness suppression is predicted at\nprojectile/target rapidity. For Omega's, the predicted enhancement can be as\nlarge as one order of magnitude. Comparisons of Pb-Pb data to proton induced\nasymmetric (p-A) collisions are hampered due to the predicted strong asymmetry\nin the various rapidity distributions of the different (strange) particle\nspecies. In p-Pb collisions, strangeness is locally (in rapidity) not\nconserved. The present comparison to the data of the WA97 and NA49\ncollaborations clearly supports the suggestion that conventional (free)\nhadronic scenarios are unable to describe the observed high (anti-)hyperon\nyields in central collisions. The doubling of the strangeness to nonstrange\nsuppression factor, gamma_s \\approx 0.65, might be interpreted as a signal of a\nphase of nearly massless particles. \n\n"}
{"id": "nucl-th/9909021", "contents": "Title: On Isgur's \"Critique of a Pion Exchange Model for Interquark Forces\" Abstract: The conceptual issues of low-energy baryon physics are discussed. In\nparticular, a comparison between the naive one gluon exchange model for the\ninteraction between constituent quarks in hadrons and the Goldstone boson\nexchange picture is made. The \"defects\" of the Goldstone boson exchange model\nfor baryons, indicated by Isgur are examined in detail. {\\it All} of the\npurported ``defects'' are shown to lack a valid basis. \n\n"}
{"id": "physics/0009047", "contents": "Title: The Longitudinal Polarimeter at HERA Abstract: The design, construction and operation of a Compton back-scattering laser\npolarimeter at the HERA storage ring at DESY are described. The device measures\nthe longitudinal polarization of the electron beam between the spin rotators at\nthe HERMES experiment with a fractional systematic uncertainty of 1.6%. A\nmeasurement of the beam polarization to an absolute statistical precision of\n0.01 requires typically one minute when the device is operated in the\nmulti-photon mode. The polarimeter also measures the polarization of each\nindividual electron bunch to an absolute statistical precision of 0.06 in\napproximately five minutes. It was found that colliding and non-colliding\nbunches can have substantially different polarizations. This information is\nimportant to the collider experiments H1 and ZEUS for their future\nlongitudinally polarized electron program because those experiments use the\ncolliding bunches only. \n\n"}
{"id": "physics/0409048", "contents": "Title: The detection of single electrons by means of a Micromegas-covered\n  MediPix2 pixel CMOS readout circuit Abstract: A small drift chamber was read out by means of a MediPix2 readout chip as\ndirect anode. A Micromegas foil was placed 50 $\\mu$m above the chip, and\nelectron multiplication occurred in the gap. With a He/Isobutane 80/20 mixture,\ngas multiplication factors up to tens of thousands were achieved, resulting in\nan efficiency for detecting single electrons of better than 90% . We recorded\nmany frames containing 2D images with tracks from cosmic muons. Along these\ntracks, electron clusters were observed, as well as delta-rays. \n\n"}
{"id": "physics/0410114", "contents": "Title: Pulsations of the electron-positron plasma in the field of optical\n  lasers Abstract: The possibility to observe vacuum electron-positron pair creation due to a\npowerful optical laser pulse is discussed. We employ a quantum kinetic\nformulation of the problem with a source term describing the vacuum pair\nproduction in a homogeneous electric field with arbitrary time dependence\n(dynamical Schwinger mechanism). For a periodic field weak in comparison with\nthe critical value E_{cr}=m^2/|e|, the electron-positron plasma density changes\napproximately periodically with twice the field frequency. Under these\nconditions, the mean value $<n>$ for the density per period in the volume\nlambda^3 is a more appropriate characteristic quantity than the residual\ndensity n_r which is taken over an integer number of field periods and\ncalculated using the imaginary time method. The value <n> is proportional to\nthe squared field intensity and does not depend on the frequency. We show that\nin terms of the parameter <n> an optical laser can be more effective than a\nX-ray one. We expect that it is possible to observe the vacuum creation effect\nnot only by means of the planned X-ray free electron lasers but already at\npresent-day optical lasers. \n\n"}
{"id": "physics/0608081", "contents": "Title: Performance of the CDF Calorimeter Simulation in Tevatron Run II Abstract: The CDF experiment is successfully collecting data from ppbar collisions at\nthe Tevatron in Run II. As the data samples are getting larger, systematic\nuncertainties due to the measurement of the jet energy scale assessed using the\ncalorimeter simulation have become increasingly important. In many years of\noperation, the collaboration has gained experience with GFLASH, a fast\nparametrization of electromagnetic and hadronic showers used for the\ncalorimeter simulation. We present the performance of the calorimeter\nsimulation and report on recent improvements based on a refined in situ tuning\ntechnique. The central calorimeter response is reproduced with a precision of\n1-2%. \n\n"}
{"id": "quant-ph/0411093", "contents": "Title: Optimal Experiment Design for Quantum State and Process Tomography and\n  Hamiltonian Parameter Estimation Abstract: A number of problems in quantum state and system identification are\naddressed. Specifically, it is shown that the maximum likelihood estimation\n(MLE) approach, already known to apply to quantum state tomography, is also\napplicable to quantum process tomography (estimating the Kraus operator sum\nrepresentation (OSR)), Hamiltonian parameter estimation, and the related\nproblems of state and process (OSR) distribution estimation. Except for\nHamiltonian parameter estimation, the other MLE problems are formally of the\nsame type of convex optimization problem and therefore can be solved very\nefficiently to within any desired accuracy.\n  Associated with each of these estimation problems, and the focus of the\npaper, is an optimal experiment design (OED) problem invoked by the Cramer-Rao\nInequality: find the number of experiments to be performed in a particular\nsystem configuration to maximize estimation accuracy; a configuration being any\nnumber of combinations of sample times, hardware settings, prepared initial\nstates, etc. We show that in all of the estimation problems, including\nHamiltonian parameter estimation, the optimal experiment design can be obtained\nby solving a convex optimization problem.\n  Software to solve the MLE and OED convex optimization problems is available\nupon request from the first author. \n\n"}
