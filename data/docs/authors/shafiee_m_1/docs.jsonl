{"id": "0810.4401", "contents": "Title: Efficient Exact Inference in Planar Ising Models Abstract: We give polynomial-time algorithms for the exact computation of lowest-energy\n(ground) states, worst margin violators, log partition functions, and marginal\nedge probabilities in certain binary undirected graphical models. Our approach\nprovides an interesting alternative to the well-known graph cut paradigm in\nthat it does not impose any submodularity constraints; instead we require\nplanarity to establish a correspondence with perfect matchings (dimer\ncoverings) in an expanded dual graph. We implement a unified framework while\ndelegating complex but well-understood subproblems (planar embedding,\nmaximum-weight perfect matching) to established algorithms for which efficient\nimplementations are freely available. Unlike graph cut methods, we can perform\npenalized maximum-likelihood as well as maximum-margin parameter estimation in\nthe associated conditional random fields (CRFs), and employ marginal posterior\nprobabilities as well as maximum a posteriori (MAP) states for prediction.\nMaximum-margin CRF parameter estimation on image denoising and segmentation\nproblems shows our approach to be efficient and effective. A C++ implementation\nis available from http://nic.schraudolph.org/isinf/ \n\n"}
{"id": "0906.5120", "contents": "Title: Comments on \"A new combination of evidence based on compromise\" by K.\n  Yamada Abstract: Comments on ``A new combination of evidence based on compromise'' by K.\nYamada \n\n"}
{"id": "0910.5002", "contents": "Title: An Iterative Shrinkage Approach to Total-Variation Image Restoration Abstract: The problem of restoration of digital images from their degraded measurements\nplays a central role in a multitude of practically important applications. A\nparticularly challenging instance of this problem occurs in the case when the\ndegradation phenomenon is modeled by an ill-conditioned operator. In such a\ncase, the presence of noise makes it impossible to recover a valuable\napproximation of the image of interest without using some a priori information\nabout its properties. Such a priori information is essential for image\nrestoration, rendering it stable and robust to noise. Particularly, if the\noriginal image is known to be a piecewise smooth function, one of the standard\npriors used in this case is defined by the Rudin-Osher-Fatemi model, which\nresults in total variation (TV) based image restoration. The current arsenal of\nalgorithms for TV-based image restoration is vast. In the present paper, a\ndifferent approach to the solution of the problem is proposed based on the\nmethod of iterative shrinkage (aka iterated thresholding). In the proposed\nmethod, the TV-based image restoration is performed through a recursive\napplication of two simple procedures, viz. linear filtering and soft\nthresholding. Therefore, the method can be identified as belonging to the group\nof first-order algorithms which are efficient in dealing with images of\nrelatively large sizes. Another valuable feature of the proposed method\nconsists in its working directly with the TV functional, rather then with its\nsmoothed versions. Moreover, the method provides a single solution for both\nisotropic and anisotropic definitions of the TV functional, thereby\nestablishing a useful connection between the two formulae. \n\n"}
{"id": "1008.3043", "contents": "Title: Learning Functions of Few Arbitrary Linear Parameters in High Dimensions Abstract: Let us assume that $f$ is a continuous function defined on the unit ball of\n$\\mathbb R^d$, of the form $f(x) = g (A x)$, where $A$ is a $k \\times d$ matrix\nand $g$ is a function of $k$ variables for $k \\ll d$. We are given a budget $m\n\\in \\mathbb N$ of possible point evaluations $f(x_i)$, $i=1,...,m$, of $f$,\nwhich we are allowed to query in order to construct a uniform approximating\nfunction. Under certain smoothness and variation assumptions on the function\n$g$, and an {\\it arbitrary} choice of the matrix $A$, we present in this paper\n  1. a sampling choice of the points $\\{x_i\\}$ drawn at random for each\nfunction approximation;\n  2. algorithms (Algorithm 1 and Algorithm 2) for computing the approximating\nfunction, whose complexity is at most polynomial in the dimension $d$ and in\nthe number $m$ of points.\n  Due to the arbitrariness of $A$, the choice of the sampling points will be\naccording to suitable random distributions and our results hold with\noverwhelming probability. Our approach uses tools taken from the {\\it\ncompressed sensing} framework, recent Chernoff bounds for sums of\npositive-semidefinite matrices, and classical stability bounds for invariant\nsubspaces of singular value decompositions. \n\n"}
{"id": "1107.2021", "contents": "Title: Multi-Instance Learning with Any Hypothesis Class Abstract: In the supervised learning setting termed Multiple-Instance Learning (MIL),\nthe examples are bags of instances, and the bag label is a function of the\nlabels of its instances. Typically, this function is the Boolean OR. The\nlearner observes a sample of bags and the bag labels, but not the instance\nlabels that determine the bag labels. The learner is then required to emit a\nclassification rule for bags based on the sample. MIL has numerous\napplications, and many heuristic algorithms have been used successfully on this\nproblem, each adapted to specific settings or applications. In this work we\nprovide a unified theoretical analysis for MIL, which holds for any underlying\nhypothesis class, regardless of a specific application or problem domain. We\nshow that the sample complexity of MIL is only poly-logarithmically dependent\non the size of the bag, for any underlying hypothesis class. In addition, we\nintroduce a new PAC-learning algorithm for MIL, which uses a regular supervised\nlearning algorithm as an oracle. We prove that efficient PAC-learning for MIL\ncan be generated from any efficient non-MIL supervised learning algorithm that\nhandles one-sided error. The computational complexity of the resulting\nalgorithm is only polynomially dependent on the bag size. \n\n"}
{"id": "1204.4710", "contents": "Title: Regret in Online Combinatorial Optimization Abstract: We address online linear optimization problems when the possible actions of\nthe decision maker are represented by binary vectors. The regret of the\ndecision maker is the difference between her realized loss and the best loss\nshe would have achieved by picking, in hindsight, the best possible action. Our\ngoal is to understand the magnitude of the best possible (minimax) regret. We\nstudy the problem under three different assumptions for the feedback the\ndecision maker receives: full information, and the partial information models\nof the so-called \"semi-bandit\" and \"bandit\" problems. Combining the Mirror\nDescent algorithm and the INF (Implicitely Normalized Forecaster) strategy, we\nare able to prove optimal bounds for the semi-bandit case. We also recover the\noptimal bounds for the full information setting. In the bandit case we discuss\nexisting results in light of a new lower bound, and suggest a conjecture on the\noptimal regret in that case. Finally we also prove that the standard\nexponentially weighted average forecaster is provably suboptimal in the setting\nof online combinatorial optimization. \n\n"}
{"id": "1205.5075", "contents": "Title: Efficient Sparse Group Feature Selection via Nonconvex Optimization Abstract: Sparse feature selection has been demonstrated to be effective in handling\nhigh-dimensional data. While promising, most of the existing works use convex\nmethods, which may be suboptimal in terms of the accuracy of feature selection\nand parameter estimation. In this paper, we expand a nonconvex paradigm to\nsparse group feature selection, which is motivated by applications that require\nidentifying the underlying group structure and performing feature selection\nsimultaneously. The main contributions of this article are twofold: (1)\nstatistically, we introduce a nonconvex sparse group feature selection model\nwhich can reconstruct the oracle estimator. Therefore, consistent feature\nselection and parameter estimation can be achieved; (2) computationally, we\npropose an efficient algorithm that is applicable to large-scale problems.\nNumerical results suggest that the proposed nonconvex method compares favorably\nagainst its competitors on synthetic data and real-world applications, thus\nachieving desired goal of delivering high performance. \n\n"}
{"id": "1206.6381", "contents": "Title: Shortest path distance in random k-nearest neighbor graphs Abstract: Consider a weighted or unweighted k-nearest neighbor graph that has been\nbuilt on n data points drawn randomly according to some density p on R^d. We\nstudy the convergence of the shortest path distance in such graphs as the\nsample size tends to infinity. We prove that for unweighted kNN graphs, this\ndistance converges to an unpleasant distance function on the underlying space\nwhose properties are detrimental to machine learning. We also study the\nbehavior of the shortest path distance in weighted kNN graphs. \n\n"}
{"id": "1208.0432", "contents": "Title: Efficient Point-to-Subspace Query in $\\ell^1$ with Application to Robust\n  Object Instance Recognition Abstract: Motivated by vision tasks such as robust face and object recognition, we\nconsider the following general problem: given a collection of low-dimensional\nlinear subspaces in a high-dimensional ambient (image) space, and a query point\n(image), efficiently determine the nearest subspace to the query in $\\ell^1$\ndistance. In contrast to the naive exhaustive search which entails large-scale\nlinear programs, we show that the computational burden can be cut down\nsignificantly by a simple two-stage algorithm: (1) projecting the query and\ndata-base subspaces into lower-dimensional space by random Cauchy matrix, and\nsolving small-scale distance evaluations (linear programs) in the projection\nspace to locate candidate nearest; (2) with few candidates upon independent\nrepetition of (1), getting back to the high-dimensional space and performing\nexhaustive search. To preserve the identity of the nearest subspace with\nnontrivial probability, the projection dimension typically is low-order\npolynomial of the subspace dimension multiplied by logarithm of number of the\nsubspaces (Theorem 2.1). The reduced dimensionality and hence complexity\nrenders the proposed algorithm particularly relevant to vision application such\nas robust face and object instance recognition that we investigate empirically. \n\n"}
{"id": "1209.0654", "contents": "Title: Compressive Optical Deflectometric Tomography: A Constrained\n  Total-Variation Minimization Approach Abstract: Optical Deflectometric Tomography (ODT) provides an accurate characterization\nof transparent materials whose complex surfaces present a real challenge for\nmanufacture and control. In ODT, the refractive index map (RIM) of a\ntransparent object is reconstructed by measuring light deflection under\nmultiple orientations. We show that this imaging modality can be made\n\"compressive\", i.e., a correct RIM reconstruction is achievable with far less\nobservations than required by traditional Filtered Back Projection (FBP)\nmethods. Assuming a cartoon-shape RIM model, this reconstruction is driven by\nminimizing the map Total-Variation under a fidelity constraint with the\navailable observations. Moreover, two other realistic assumptions are added to\nimprove the stability of our approach: the map positivity and a frontier\ncondition. Numerically, our method relies on an accurate ODT sensing model and\non a primal-dual minimization scheme, including easily the sensing operator and\nthe proposed RIM constraints. We conclude this paper by demonstrating the power\nof our method on synthetic and experimental data under various compressive\nscenarios. In particular, the compressiveness of the stabilized ODT problem is\ndemonstrated by observing a typical gain of 20 dB compared to FBP at only 5% of\n360 incident light angles for moderately noisy sensing. \n\n"}
{"id": "1209.1688", "contents": "Title: Rank Centrality: Ranking from Pair-wise Comparisons Abstract: The question of aggregating pair-wise comparisons to obtain a global ranking\nover a collection of objects has been of interest for a very long time: be it\nranking of online gamers (e.g. MSR's TrueSkill system) and chess players,\naggregating social opinions, or deciding which product to sell based on\ntransactions. In most settings, in addition to obtaining a ranking, finding\n`scores' for each object (e.g. player's rating) is of interest for\nunderstanding the intensity of the preferences.\n  In this paper, we propose Rank Centrality, an iterative rank aggregation\nalgorithm for discovering scores for objects (or items) from pair-wise\ncomparisons. The algorithm has a natural random walk interpretation over the\ngraph of objects with an edge present between a pair of objects if they are\ncompared; the score, which we call Rank Centrality, of an object turns out to\nbe its stationary probability under this random walk. To study the efficacy of\nthe algorithm, we consider the popular Bradley-Terry-Luce (BTL) model\n(equivalent to the Multinomial Logit (MNL) for pair-wise comparisons) in which\neach object has an associated score which determines the probabilistic outcomes\nof pair-wise comparisons between objects. In terms of the pair-wise marginal\nprobabilities, which is the main subject of this paper, the MNL model and the\nBTL model are identical. We bound the finite sample error rates between the\nscores assumed by the BTL model and those estimated by our algorithm. In\nparticular, the number of samples required to learn the score well with high\nprobability depends on the structure of the comparison graph. When the\nLaplacian of the comparison graph has a strictly positive spectral gap, e.g.\neach item is compared to a subset of randomly chosen items, this leads to\ndependence on the number of samples that is nearly order-optimal. \n\n"}
{"id": "1211.1043", "contents": "Title: Soft (Gaussian CDE) regression models and loss functions Abstract: Regression, unlike classification, has lacked a comprehensive and effective\napproach to deal with cost-sensitive problems by the reuse (and not a\nre-training) of general regression models. In this paper, a wide variety of\ncost-sensitive problems in regression (such as bids, asymmetric losses and\nrejection rules) can be solved effectively by a lightweight but powerful\napproach, consisting of: (1) the conversion of any traditional one-parameter\ncrisp regression model into a two-parameter soft regression model, seen as a\nnormal conditional density estimator, by the use of newly-introduced enrichment\nmethods; and (2) the reframing of an enriched soft regression model to new\ncontexts by an instance-dependent optimisation of the expected loss derived\nfrom the conditional normal distribution. \n\n"}
{"id": "1212.5156", "contents": "Title: Nonparametric ridge estimation Abstract: We study the problem of estimating the ridges of a density function. Ridge\nestimation is an extension of mode finding and is useful for understanding the\nstructure of a density. It can also be used to find hidden structure in point\ncloud data. We show that, under mild regularity conditions, the ridges of the\nkernel density estimator consistently estimate the ridges of the true density.\nWhen the data are noisy measurements of a manifold, we show that the ridges are\nclose and topologically similar to the hidden manifold. To find the estimated\nridges in practice, we adapt the modified mean-shift algorithm proposed by\nOzertem and Erdogmus [J. Mach. Learn. Res. 12 (2011) 1249-1286]. Some numerical\nexperiments verify that the algorithm is accurate. \n\n"}
{"id": "1301.4083", "contents": "Title: Knowledge Matters: Importance of Prior Information for Optimization Abstract: We explore the effect of introducing prior information into the intermediate\nlevel of neural networks for a learning task on which all the state-of-the-art\nmachine learning algorithms tested failed to learn. We motivate our work from\nthe hypothesis that humans learn such intermediate concepts from other\nindividuals via a form of supervision or guidance using a curriculum. The\nexperiments we have conducted provide positive evidence in favor of this\nhypothesis. In our experiments, a two-tiered MLP architecture is trained on a\ndataset with 64x64 binary inputs images, each image with three sprites. The\nfinal task is to decide whether all the sprites are the same or one of them is\ndifferent. Sprites are pentomino tetris shapes and they are placed in an image\nwith different locations using scaling and rotation transformations. The first\npart of the two-tiered MLP is pre-trained with intermediate-level targets being\nthe presence of sprites at each location, while the second part takes the\noutput of the first part as input and predicts the final task's target binary\nevent. The two-tiered MLP architecture, with a few tens of thousand examples,\nwas able to learn the task perfectly, whereas all other algorithms (include\nunsupervised pre-training, but also traditional algorithms like SVMs, decision\ntrees and boosting) all perform no better than chance. We hypothesize that the\noptimization difficulty involved when the intermediate pre-training is not\nperformed is due to the {\\em composition} of two highly non-linear tasks. Our\nfindings are also consistent with hypotheses on cultural learning inspired by\nthe observations of optimization problems with deep learning, presumably\nbecause of effective local minima. \n\n"}
{"id": "1302.2576", "contents": "Title: The trace norm constrained matrix-variate Gaussian process for multitask\n  bipartite ranking Abstract: We propose a novel hierarchical model for multitask bipartite ranking. The\nproposed approach combines a matrix-variate Gaussian process with a generative\nmodel for task-wise bipartite ranking. In addition, we employ a novel trace\nconstrained variational inference approach to impose low rank structure on the\nposterior matrix-variate Gaussian process. The resulting posterior covariance\nfunction is derived in closed form, and the posterior mean function is the\nsolution to a matrix-variate regression with a novel spectral elastic net\nregularizer. Further, we show that variational inference for the trace\nconstrained matrix-variate Gaussian process combined with maximum likelihood\nparameter estimation for the bipartite ranking model is jointly convex. Our\nmotivating application is the prioritization of candidate disease genes. The\ngoal of this task is to aid the identification of unobserved associations\nbetween human genes and diseases using a small set of observed associations as\nwell as kernels induced by gene-gene interaction networks and disease\nontologies. Our experimental results illustrate the performance of the proposed\nmodel on real world datasets. Moreover, we find that the resulting low rank\nsolution improves the computational scalability of training and testing as\ncompared to baseline models. \n\n"}
{"id": "1304.4344", "contents": "Title: Sparse Coding and Dictionary Learning for Symmetric Positive Definite\n  Matrices: A Kernel Approach Abstract: Recent advances suggest that a wide range of computer vision problems can be\naddressed more appropriately by considering non-Euclidean geometry. This paper\ntackles the problem of sparse coding and dictionary learning in the space of\nsymmetric positive definite matrices, which form a Riemannian manifold. With\nthe aid of the recently introduced Stein kernel (related to a symmetric version\nof Bregman matrix divergence), we propose to perform sparse coding by embedding\nRiemannian manifolds into reproducing kernel Hilbert spaces. This leads to a\nconvex and kernel version of the Lasso problem, which can be solved\nefficiently. We furthermore propose an algorithm for learning a Riemannian\ndictionary (used for sparse coding), closely tied to the Stein kernel.\nExperiments on several classification tasks (face recognition, texture\nclassification, person re-identification) show that the proposed sparse coding\napproach achieves notable improvements in discrimination accuracy, in\ncomparison to state-of-the-art methods such as tensor sparse coding, Riemannian\nlocality preserving projection, and symmetry-driven accumulation of local\nfeatures. \n\n"}
{"id": "1304.5583", "contents": "Title: Distributed Low-rank Subspace Segmentation Abstract: Vision problems ranging from image clustering to motion segmentation to\nsemi-supervised learning can naturally be framed as subspace segmentation\nproblems, in which one aims to recover multiple low-dimensional subspaces from\nnoisy and corrupted input data. Low-Rank Representation (LRR), a convex\nformulation of the subspace segmentation problem, is provably and empirically\naccurate on small problems but does not scale to the massive sizes of modern\nvision datasets. Moreover, past work aimed at scaling up low-rank matrix\nfactorization is not applicable to LRR given its non-decomposable constraints.\nIn this work, we propose a novel divide-and-conquer algorithm for large-scale\nsubspace segmentation that can cope with LRR's non-decomposable constraints and\nmaintains LRR's strong recovery guarantees. This has immediate implications for\nthe scalability of subspace segmentation, which we demonstrate on a benchmark\nface recognition dataset and in simulations. We then introduce novel\napplications of LRR-based subspace segmentation to large-scale semi-supervised\nlearning for multimedia event detection, concept detection, and image tagging.\nIn each case, we obtain state-of-the-art results and order-of-magnitude speed\nups. \n\n"}
{"id": "1306.3476", "contents": "Title: Hyperparameter Optimization and Boosting for Classifying Facial\n  Expressions: How good can a \"Null\" Model be? Abstract: One of the goals of the ICML workshop on representation and learning is to\nestablish benchmark scores for a new data set of labeled facial expressions.\nThis paper presents the performance of a \"Null\" model consisting of\nconvolutions with random weights, PCA, pooling, normalization, and a linear\nreadout. Our approach focused on hyperparameter optimization rather than novel\nmodel components. On the Facial Expression Recognition Challenge held by the\nKaggle website, our hyperparameter optimization approach achieved a score of\n60% accuracy on the test data. This paper also introduces a new ensemble\nconstruction variant that combines hyperparameter optimization with the\nconstruction of ensembles. This algorithm constructed an ensemble of four\nmodels that scored 65.5% accuracy. These scores rank 12th and 5th respectively\namong the 56 challenge participants. It is worth noting that our approach was\ndeveloped prior to the release of the data set, and applied without\nmodification; our strong competition performance suggests that the TPE\nhyperparameter optimization algorithm and domain expertise encoded in our Null\nmodel can generalize to new image classification data sets. \n\n"}
{"id": "1308.5038", "contents": "Title: Group-Sparse Signal Denoising: Non-Convex Regularization, Convex\n  Optimization Abstract: Convex optimization with sparsity-promoting convex regularization is a\nstandard approach for estimating sparse signals in noise. In order to promote\nsparsity more strongly than convex regularization, it is also standard practice\nto employ non-convex optimization. In this paper, we take a third approach. We\nutilize a non-convex regularization term chosen such that the total cost\nfunction (consisting of data consistency and regularization terms) is convex.\nTherefore, sparsity is more strongly promoted than in the standard convex\nformulation, but without sacrificing the attractive aspects of convex\noptimization (unique minimum, robust algorithms, etc.). We use this idea to\nimprove the recently developed 'overlapping group shrinkage' (OGS) algorithm\nfor the denoising of group-sparse signals. The algorithm is applied to the\nproblem of speech enhancement with favorable results in terms of both SNR and\nperceptual quality. \n\n"}
{"id": "1309.3533", "contents": "Title: Mixed Membership Models for Time Series Abstract: In this article we discuss some of the consequences of the mixed membership\nperspective on time series analysis. In its most abstract form, a mixed\nmembership model aims to associate an individual entity with some set of\nattributes based on a collection of observed data. Although much of the\nliterature on mixed membership models considers the setting in which\nexchangeable collections of data are associated with each member of a set of\nentities, it is equally natural to consider problems in which an entire time\nseries is viewed as an entity and the goal is to characterize the time series\nin terms of a set of underlying dynamic attributes or \"dynamic regimes\".\nIndeed, this perspective is already present in the classical hidden Markov\nmodel, where the dynamic regimes are referred to as \"states\", and the\ncollection of states realized in a sample path of the underlying process can be\nviewed as a mixed membership characterization of the observed time series. Our\ngoal here is to review some of the richer modeling possibilities for time\nseries that are provided by recent developments in the mixed membership\nframework. \n\n"}
{"id": "1311.5422", "contents": "Title: Sparse Overlapping Sets Lasso for Multitask Learning and its Application\n  to fMRI Analysis Abstract: Multitask learning can be effective when features useful in one task are also\nuseful for other tasks, and the group lasso is a standard method for selecting\na common subset of features. In this paper, we are interested in a less\nrestrictive form of multitask learning, wherein (1) the available features can\nbe organized into subsets according to a notion of similarity and (2) features\nuseful in one task are similar, but not necessarily identical, to the features\nbest suited for other tasks. The main contribution of this paper is a new\nprocedure called Sparse Overlapping Sets (SOS) lasso, a convex optimization\nthat automatically selects similar features for related learning tasks. Error\nbounds are derived for SOSlasso and its consistency is established for squared\nerror loss. In particular, SOSlasso is motivated by multi- subject fMRI studies\nin which functional activity is classified using brain voxels as features.\nExperiments with real and synthetic data demonstrate the advantages of SOSlasso\ncompared to the lasso and group lasso. \n\n"}
{"id": "1312.3429", "contents": "Title: Unsupervised learning of depth and motion Abstract: We present a model for the joint estimation of disparity and motion. The\nmodel is based on learning about the interrelations between images from\nmultiple cameras, multiple frames in a video, or the combination of both. We\nshow that learning depth and motion cues, as well as their combinations, from\ndata is possible within a single type of architecture and a single type of\nlearning algorithm, by using biologically inspired \"complex cell\" like units,\nwhich encode correlations between the pixels across image pairs. Our\nexperimental results show that the learning of depth and motion makes it\npossible to achieve state-of-the-art performance in 3-D activity analysis, and\nto outperform existing hand-engineered 3-D motion features by a very large\nmargin. \n\n"}
{"id": "1312.4400", "contents": "Title: Network In Network Abstract: We propose a novel deep network structure called \"Network In Network\" (NIN)\nto enhance model discriminability for local patches within the receptive field.\nThe conventional convolutional layer uses linear filters followed by a\nnonlinear activation function to scan the input. Instead, we build micro neural\nnetworks with more complex structures to abstract the data within the receptive\nfield. We instantiate the micro neural network with a multilayer perceptron,\nwhich is a potent function approximator. The feature maps are obtained by\nsliding the micro networks over the input in a similar manner as CNN; they are\nthen fed into the next layer. Deep NIN can be implemented by stacking mutiple\nof the above described structure. With enhanced local modeling via the micro\nnetwork, we are able to utilize global average pooling over feature maps in the\nclassification layer, which is easier to interpret and less prone to\noverfitting than traditional fully connected layers. We demonstrated the\nstate-of-the-art classification performances with NIN on CIFAR-10 and\nCIFAR-100, and reasonable performances on SVHN and MNIST datasets. \n\n"}
{"id": "1312.5604", "contents": "Title: Learning Transformations for Classification Forests Abstract: This work introduces a transformation-based learner model for classification\nforests. The weak learner at each split node plays a crucial role in a\nclassification tree. We propose to optimize the splitting objective by learning\na linear transformation on subspaces using nuclear norm as the optimization\ncriteria. The learned linear transformation restores a low-rank structure for\ndata from the same class, and, at the same time, maximizes the separation\nbetween different classes, thereby improving the performance of the split\nfunction. Theoretical and experimental results support the proposed framework. \n\n"}
{"id": "1401.4489", "contents": "Title: An Analysis of Random Projections in Cancelable Biometrics Abstract: With increasing concerns about security, the need for highly secure physical\nbiometrics-based authentication systems utilizing \\emph{cancelable biometric}\ntechnologies is on the rise. Because the problem of cancelable template\ngeneration deals with the trade-off between template security and matching\nperformance, many state-of-the-art algorithms successful in generating high\nquality cancelable biometrics all have random projection as one of their early\nprocessing steps. This paper therefore presents a formal analysis of why random\nprojections is an essential step in cancelable biometrics. By formally defining\nthe notion of an \\textit{Independent Subspace Structure} for datasets, it can\nbe shown that random projection preserves the subspace structure of data\nvectors generated from a union of independent linear subspaces. The bound on\nthe minimum number of random vectors required for this to hold is also derived\nand is shown to depend logarithmically on the number of data samples, not only\nin independent subspaces but in disjoint subspace settings as well. The\ntheoretical analysis presented is supported in detail with empirical results on\nreal-world face recognition datasets. \n\n"}
{"id": "1402.0030", "contents": "Title: Neural Variational Inference and Learning in Belief Networks Abstract: Highly expressive directed latent variable models, such as sigmoid belief\nnetworks, are difficult to train on large datasets because exact inference in\nthem is intractable and none of the approximate inference methods that have\nbeen applied to them scale well. We propose a fast non-iterative approximate\ninference method that uses a feedforward network to implement efficient exact\nsampling from the variational posterior. The model and this inference network\nare trained jointly by maximizing a variational lower bound on the\nlog-likelihood. Although the naive estimator of the inference model gradient is\ntoo high-variance to be useful, we make it practical by applying several\nstraightforward model-independent variance reduction techniques. Applying our\napproach to training sigmoid belief networks and deep autoregressive networks,\nwe show that it outperforms the wake-sleep algorithm on MNIST and achieves\nstate-of-the-art results on the Reuters RCV1 document dataset. \n\n"}
{"id": "1402.0453", "contents": "Title: Fine-Grained Visual Categorization via Multi-stage Metric Learning Abstract: Fine-grained visual categorization (FGVC) is to categorize objects into\nsubordinate classes instead of basic classes. One major challenge in FGVC is\nthe co-occurrence of two issues: 1) many subordinate classes are highly\ncorrelated and are difficult to distinguish, and 2) there exists the large\nintra-class variation (e.g., due to object pose). This paper proposes to\nexplicitly address the above two issues via distance metric learning (DML). DML\naddresses the first issue by learning an embedding so that data points from the\nsame class will be pulled together while those from different classes should be\npushed apart from each other; and it addresses the second issue by allowing the\nflexibility that only a portion of the neighbors (not all data points) from the\nsame class need to be pulled together. However, feature representation of an\nimage is often high dimensional, and DML is known to have difficulty in dealing\nwith high dimensional feature vectors since it would require $\\mathcal{O}(d^2)$\nfor storage and $\\mathcal{O}(d^3)$ for optimization. To this end, we proposed a\nmulti-stage metric learning framework that divides the large-scale high\ndimensional learning problem to a series of simple subproblems, achieving\n$\\mathcal{O}(d)$ computational complexity. The empirical study with FVGC\nbenchmark datasets verifies that our method is both effective and efficient\ncompared to the state-of-the-art FGVC approaches. \n\n"}
{"id": "1402.2333", "contents": "Title: Modeling sequential data using higher-order relational features and\n  predictive training Abstract: Bi-linear feature learning models, like the gated autoencoder, were proposed\nas a way to model relationships between frames in a video. By minimizing\nreconstruction error of one frame, given the previous frame, these models learn\n\"mapping units\" that encode the transformations inherent in a sequence, and\nthereby learn to encode motion. In this work we extend bi-linear models by\nintroducing \"higher-order mapping units\" that allow us to encode\ntransformations between frames and transformations between transformations.\n  We show that this makes it possible to encode temporal structure that is more\ncomplex and longer-range than the structure captured within standard bi-linear\nmodels. We also show that a natural way to train the model is by replacing the\ncommonly used reconstruction objective with a prediction objective which forces\nthe model to correctly predict the evolution of the input multiple steps into\nthe future. Learning can be achieved by back-propagating the multi-step\nprediction through time. We test the model on various temporal prediction\ntasks, and show that higher-order mappings and predictive training both yield a\nsignificant improvement over bi-linear models in terms of prediction accuracy. \n\n"}
{"id": "1402.2426", "contents": "Title: Imaging with Rays: Microscopy, Medical Imaging, and Computer Vision Abstract: In this paper we broadly consider techniques which utilize projections on\nrays for data collection, with particular emphasis on optical techniques. We\nformulate a variety of imaging techniques as either special cases or extensions\nof tomographic reconstruction. We then consider how the techniques must be\nextended to describe objects containing occlusion, as with a self-occluding\nopaque object. We formulate the reconstruction problem as a regularized\nnonlinear optimization problem to simultaneously solve for object brightness\nand attenuation, where the attenuation can become infinite. We demonstrate\nvarious simulated examples for imaging opaque objects, including sparse point\nsources, a conventional multiview reconstruction technique, and a\nsuper-resolving technique which exploits occlusion to resolve an image. \n\n"}
{"id": "1403.0700", "contents": "Title: Random Projections on Manifolds of Symmetric Positive Definite Matrices\n  for Image Classification Abstract: Recent advances suggest that encoding images through Symmetric Positive\nDefinite (SPD) matrices and then interpreting such matrices as points on\nRiemannian manifolds can lead to increased classification performance. Taking\ninto account manifold geometry is typically done via (1) embedding the\nmanifolds in tangent spaces, or (2) embedding into Reproducing Kernel Hilbert\nSpaces (RKHS). While embedding into tangent spaces allows the use of existing\nEuclidean-based learning algorithms, manifold shape is only approximated which\ncan cause loss of discriminatory information. The RKHS approach retains more of\nthe manifold structure, but may require non-trivial effort to kernelise\nEuclidean-based learning algorithms. In contrast to the above approaches, in\nthis paper we offer a novel solution that allows SPD matrices to be used with\nunmodified Euclidean-based learning algorithms, with the true manifold shape\nwell-preserved. Specifically, we propose to project SPD matrices using a set of\nrandom projection hyperplanes over RKHS into a random projection space, which\nleads to representing each matrix as a vector of projection coefficients.\nExperiments on face recognition, person re-identification and texture\nclassification show that the proposed approach outperforms several recent\nmethods, such as Tensor Sparse Coding, Histogram Plus Epitome, Riemannian\nLocality Preserving Projection and Relational Divergence Classification. \n\n"}
{"id": "1404.1777", "contents": "Title: Neural Codes for Image Retrieval Abstract: It has been shown that the activations invoked by an image within the top\nlayers of a large convolutional neural network provide a high-level descriptor\nof the visual content of the image. In this paper, we investigate the use of\nsuch descriptors (neural codes) within the image retrieval application. In the\nexperiments with several standard retrieval benchmarks, we establish that\nneural codes perform competitively even when the convolutional neural network\nhas been trained for an unrelated classification task (e.g.\\ Image-Net). We\nalso evaluate the improvement in the retrieval performance of neural codes,\nwhen the network is retrained on a dataset of images that are similar to images\nencountered at test time.\n  We further evaluate the performance of the compressed neural codes and show\nthat a simple PCA compression provides very good short codes that give\nstate-of-the-art accuracy on a number of datasets. In general, neural codes\nturn out to be much more resilient to such compression in comparison other\nstate-of-the-art descriptors. Finally, we show that discriminative\ndimensionality reduction trained on a dataset of pairs of matched photographs\nimproves the performance of PCA-compressed neural codes even further. Overall,\nour quantitative experiments demonstrate the promise of neural codes as visual\ndescriptors for image retrieval. \n\n"}
{"id": "1404.2188", "contents": "Title: A Convolutional Neural Network for Modelling Sentences Abstract: The ability to accurately represent sentences is central to language\nunderstanding. We describe a convolutional architecture dubbed the Dynamic\nConvolutional Neural Network (DCNN) that we adopt for the semantic modelling of\nsentences. The network uses Dynamic k-Max Pooling, a global pooling operation\nover linear sequences. The network handles input sentences of varying length\nand induces a feature graph over the sentence that is capable of explicitly\ncapturing short and long-range relations. The network does not rely on a parse\ntree and is easily applicable to any language. We test the DCNN in four\nexperiments: small scale binary and multi-class sentiment prediction, six-way\nquestion classification and Twitter sentiment prediction by distant\nsupervision. The network achieves excellent performance in the first three\ntasks and a greater than 25% error reduction in the last task with respect to\nthe strongest baseline. \n\n"}
{"id": "1405.3726", "contents": "Title: Topic words analysis based on LDA model Abstract: Social network analysis (SNA), which is a research field describing and\nmodeling the social connection of a certain group of people, is popular among\nnetwork services. Our topic words analysis project is a SNA method to visualize\nthe topic words among emails from Obama.com to accounts registered in Columbus,\nOhio. Based on Latent Dirichlet Allocation (LDA) model, a popular topic model\nof SNA, our project characterizes the preference of senders for target group of\nreceptors. Gibbs sampling is used to estimate topic and word distribution. Our\ntraining and testing data are emails from the carbon-free server\nDatagreening.com. We use parallel computing tool BashReduce for word processing\nand generate related words under each latent topic to discovers typical\ninformation of political news sending specially to local Columbus receptors.\nRunning on two instances using paralleling tool BashReduce, our project\ncontributes almost 30% speedup processing the raw contents, comparing with\nprocessing contents on one instance locally. Also, the experimental result\nshows that the LDA model applied in our project provides precision rate 53.96%\nhigher than TF-IDF model finding target words, on the condition that\nappropriate size of topic words list is selected. \n\n"}
{"id": "1405.6159", "contents": "Title: A Bi-clustering Framework for Consensus Problems Abstract: We consider grouping as a general characterization for problems such as\nclustering, community detection in networks, and multiple parametric model\nestimation. We are interested in merging solutions from different grouping\nalgorithms, distilling all their good qualities into a consensus solution. In\nthis paper, we propose a bi-clustering framework and perspective for reaching\nconsensus in such grouping problems. In particular, this is the first time that\nthe task of finding/fitting multiple parametric models to a dataset is formally\nposed as a consensus problem. We highlight the equivalence of these tasks and\nestablish the connection with the computational Gestalt program, that seeks to\nprovide a psychologically-inspired detection theory for visual events. We also\npresent a simple but powerful bi-clustering algorithm, specially tuned to the\nnature of the problem we address, though general enough to handle many\ndifferent instances inscribed within our characterization. The presentation is\naccompanied with diverse and extensive experimental results in clustering,\ncommunity detection, and multiple parametric model estimation in image\nprocessing applications. \n\n"}
{"id": "1406.1078", "contents": "Title: Learning Phrase Representations using RNN Encoder-Decoder for\n  Statistical Machine Translation Abstract: In this paper, we propose a novel neural network model called RNN\nEncoder-Decoder that consists of two recurrent neural networks (RNN). One RNN\nencodes a sequence of symbols into a fixed-length vector representation, and\nthe other decodes the representation into another sequence of symbols. The\nencoder and decoder of the proposed model are jointly trained to maximize the\nconditional probability of a target sequence given a source sequence. The\nperformance of a statistical machine translation system is empirically found to\nimprove by using the conditional probabilities of phrase pairs computed by the\nRNN Encoder-Decoder as an additional feature in the existing log-linear model.\nQualitatively, we show that the proposed model learns a semantically and\nsyntactically meaningful representation of linguistic phrases. \n\n"}
{"id": "1406.2199", "contents": "Title: Two-Stream Convolutional Networks for Action Recognition in Videos Abstract: We investigate architectures of discriminatively trained deep Convolutional\nNetworks (ConvNets) for action recognition in video. The challenge is to\ncapture the complementary information on appearance from still frames and\nmotion between frames. We also aim to generalise the best performing\nhand-crafted features within a data-driven learning framework.\n  Our contribution is three-fold. First, we propose a two-stream ConvNet\narchitecture which incorporates spatial and temporal networks. Second, we\ndemonstrate that a ConvNet trained on multi-frame dense optical flow is able to\nachieve very good performance in spite of limited training data. Finally, we\nshow that multi-task learning, applied to two different action classification\ndatasets, can be used to increase the amount of training data and improve the\nperformance on both.\n  Our architecture is trained and evaluated on the standard video actions\nbenchmarks of UCF-101 and HMDB-51, where it is competitive with the state of\nthe art. It also exceeds by a large margin previous attempts to use deep nets\nfor video classification. \n\n"}
{"id": "1406.3332", "contents": "Title: Convolutional Kernel Networks Abstract: An important goal in visual recognition is to devise image representations\nthat are invariant to particular transformations. In this paper, we address\nthis goal with a new type of convolutional neural network (CNN) whose\ninvariance is encoded by a reproducing kernel. Unlike traditional approaches\nwhere neural networks are learned either to represent data or for solving a\nclassification task, our network learns to approximate the kernel feature map\non training data. Such an approach enjoys several benefits over classical ones.\nFirst, by teaching CNNs to be invariant, we obtain simple network architectures\nthat achieve a similar accuracy to more complex ones, while being easy to train\nand robust to overfitting. Second, we bridge a gap between the neural network\nliterature and kernels, which are natural tools to model invariance. We\nevaluate our methodology on visual recognition tasks where CNNs have proven to\nperform well, e.g., digit recognition with the MNIST dataset, and the more\nchallenging CIFAR-10 and STL-10 datasets, where our accuracy is competitive\nwith the state of the art. \n\n"}
{"id": "1406.6603", "contents": "Title: A scaled gradient projection method for Bayesian learning in dynamical\n  systems Abstract: A crucial task in system identification problems is the selection of the most\nappropriate model class, and is classically addressed resorting to\ncross-validation or using asymptotic arguments. As recently suggested in the\nliterature, this can be addressed in a Bayesian framework, where model\ncomplexity is regulated by few hyperparameters, which can be estimated via\nmarginal likelihood maximization. It is thus of primary importance to design\neffective optimization methods to solve the corresponding optimization problem.\nIf the unknown impulse response is modeled as a Gaussian process with a\nsuitable kernel, the maximization of the marginal likelihood leads to a\nchallenging nonconvex optimization problem, which requires a stable and\neffective solution strategy. In this paper we address this problem by means of\na scaled gradient projection algorithm, in which the scaling matrix and the\nsteplength parameter play a crucial role to provide a meaning solution in a\ncomputational time comparable with second order methods. In particular, we\npropose both a generalization of the split gradient approach to design the\nscaling matrix in the presence of box constraints, and an effective\nimplementation of the gradient and objective function. The extensive numerical\nexperiments carried out on several test problems show that our method is very\neffective in providing in few tenths of a second solutions of the problems with\naccuracy comparable with state-of-the-art approaches. Moreover, the flexibility\nof the proposed strategy makes it easily adaptable to a wider range of problems\narising in different areas of machine learning, signal processing and system\nidentification. \n\n"}
{"id": "1407.1123", "contents": "Title: Expanding the Family of Grassmannian Kernels: An Embedding Perspective Abstract: Modeling videos and image-sets as linear subspaces has proven beneficial for\nmany visual recognition tasks. However, it also incurs challenges arising from\nthe fact that linear subspaces do not obey Euclidean geometry, but lie on a\nspecial type of Riemannian manifolds known as Grassmannian. To leverage the\ntechniques developed for Euclidean spaces (e.g, support vector machines) with\nsubspaces, several recent studies have proposed to embed the Grassmannian into\na Hilbert space by making use of a positive definite kernel. Unfortunately,\nonly two Grassmannian kernels are known, none of which -as we will show- is\nuniversal, which limits their ability to approximate a target function\narbitrarily well. Here, we introduce several positive definite Grassmannian\nkernels, including universal ones, and demonstrate their superiority over\npreviously-known kernels in various tasks, such as classification, clustering,\nsparse coding and hashing. \n\n"}
{"id": "1407.1974", "contents": "Title: Learning Discriminative Stein Kernel for SPD Matrices and Its\n  Applications Abstract: Stein kernel has recently shown promising performance on classifying images\nrepresented by symmetric positive definite (SPD) matrices. It evaluates the\nsimilarity between two SPD matrices through their eigenvalues. In this paper,\nwe argue that directly using the original eigenvalues may be problematic\nbecause: i) Eigenvalue estimation becomes biased when the number of samples is\ninadequate, which may lead to unreliable kernel evaluation; ii) More\nimportantly, eigenvalues only reflect the property of an individual SPD matrix.\nThey are not necessarily optimal for computing Stein kernel when the goal is to\ndiscriminate different sets of SPD matrices. To address the two issues in one\nshot, we propose a discriminative Stein kernel, in which an extra parameter\nvector is defined to adjust the eigenvalues of the input SPD matrices. The\noptimal parameter values are sought by optimizing a proxy of classification\nperformance. To show the generality of the proposed method, three different\nkernel learning criteria that are commonly used in the literature are employed\nrespectively as a proxy. A comprehensive experimental study is conducted on a\nvariety of image classification tasks to compare our proposed discriminative\nStein kernel with the original Stein kernel and other commonly used methods for\nevaluating the similarity between SPD matrices. The experimental results\ndemonstrate that, the discriminative Stein kernel can attain greater\ndiscrimination and better align with classification tasks by altering the\neigenvalues. This makes it produce higher classification performance than the\noriginal Stein kernel and other commonly used methods. \n\n"}
{"id": "1407.7556", "contents": "Title: Entropic one-class classifiers Abstract: The one-class classification problem is a well-known research endeavor in\npattern recognition. The problem is also known under different names, such as\noutlier and novelty/anomaly detection. The core of the problem consists in\nmodeling and recognizing patterns belonging only to a so-called target class.\nAll other patterns are termed non-target, and therefore they should be\nrecognized as such. In this paper, we propose a novel one-class classification\nsystem that is based on an interplay of different techniques. Primarily, we\nfollow a dissimilarity representation based approach; we embed the input data\ninto the dissimilarity space by means of an appropriate parametric\ndissimilarity measure. This step allows us to process virtually any type of\ndata. The dissimilarity vectors are then represented through a weighted\nEuclidean graphs, which we use to (i) determine the entropy of the data\ndistribution in the dissimilarity space, and at the same time (ii) derive\neffective decision regions that are modeled as clusters of vertices. Since the\ndissimilarity measure for the input data is parametric, we optimize its\nparameters by means of a global optimization scheme, which considers both\nmesoscopic and structural characteristics of the data represented through the\ngraphs. The proposed one-class classifier is designed to provide both hard\n(Boolean) and soft decisions about the recognition of test patterns, allowing\nan accurate description of the classification process. We evaluate the\nperformance of the system on different benchmarking datasets, containing either\nfeature-based or structured patterns. Experimental results demonstrate the\neffectiveness of the proposed technique. \n\n"}
{"id": "1408.0096", "contents": "Title: Conditional Restricted Boltzmann Machines for Cold Start Recommendations Abstract: Restricted Boltzman Machines (RBMs) have been successfully used in\nrecommender systems. However, as with most of other collaborative filtering\ntechniques, it cannot solve cold start problems for there is no rating for a\nnew item. In this paper, we first apply conditional RBM (CRBM) which could take\nextra information into account and show that CRBM could solve cold start\nproblem very well, especially for rating prediction task. CRBM naturally\ncombine the content and collaborative data under a single framework which could\nbe fitted effectively. Experiments show that CRBM can be compared favourably\nwith matrix factorization models, while hidden features learned from the former\nmodels are more easy to be interpreted. \n\n"}
{"id": "1408.3060", "contents": "Title: Fastfood: Approximate Kernel Expansions in Loglinear Time Abstract: Despite their successes, what makes kernel methods difficult to use in many\nlarge scale problems is the fact that storing and computing the decision\nfunction is typically expensive, especially at prediction time. In this paper,\nwe overcome this difficulty by proposing Fastfood, an approximation that\naccelerates such computation significantly. Key to Fastfood is the observation\nthat Hadamard matrices, when combined with diagonal Gaussian matrices, exhibit\nproperties similar to dense Gaussian random matrices. Yet unlike the latter,\nHadamard and diagonal matrices are inexpensive to multiply and store. These two\nmatrices can be used in lieu of Gaussian matrices in Random Kitchen Sinks\nproposed by Rahimi and Recht (2009) and thereby speeding up the computation for\na large range of kernel functions. Specifically, Fastfood requires O(n log d)\ntime and O(n) storage to compute n non-linear basis functions in d dimensions,\na significant improvement from O(nd) computation and storage, without\nsacrificing accuracy.\n  Our method applies to any translation invariant and any dot-product kernel,\nsuch as the popular RBF kernels and polynomial kernels. We prove that the\napproximation is unbiased and has low variance. Experiments show that we\nachieve similar accuracy to full kernel expansions and Random Kitchen Sinks\nwhile being 100x faster and using 1000x less memory. These improvements,\nespecially in terms of memory usage, make kernel methods more practical for\napplications that have large training sets and/or require real-time prediction. \n\n"}
{"id": "1409.4127", "contents": "Title: Transfer Learning for Video Recognition with Scarce Training Data for\n  Deep Convolutional Neural Network Abstract: Unconstrained video recognition and Deep Convolution Network (DCN) are two\nactive topics in computer vision recently. In this work, we apply DCNs as\nframe-based recognizers for video recognition. Our preliminary studies,\nhowever, show that video corpora with complete ground truth are usually not\nlarge and diverse enough to learn a robust model. The networks trained directly\non the video data set suffer from significant overfitting and have poor\nrecognition rate on the test set. The same lack-of-training-sample problem\nlimits the usage of deep models on a wide range of computer vision problems\nwhere obtaining training data are difficult. To overcome the problem, we\nperform transfer learning from images to videos to utilize the knowledge in the\nweakly labeled image corpus for video recognition. The image corpus help to\nlearn important visual patterns for natural images, while these patterns are\nignored by models trained only on the video corpus. Therefore, the resultant\nnetworks have better generalizability and better recognition rate. We show that\nby means of transfer learning from image to video, we can learn a frame-based\nrecognizer with only 4k videos. Because the image corpus is weakly labeled, the\nentire learning process requires only 4k annotated instances, which is far less\nthan the million scale image data sets required by previous works. The same\napproach may be applied to other visual recognition tasks where only scarce\ntraining data is available, and it improves the applicability of DCNs in\nvarious computer vision problems. Our experiments also reveal the correlation\nbetween meta-parameters and the performance of DCNs, given the properties of\nthe target problem and data. These results lead to a heuristic for\nmeta-parameter selection for future researches, which does not rely on the time\nconsuming meta-parameter search. \n\n"}
{"id": "1410.0510", "contents": "Title: Deep Sequential Neural Network Abstract: Neural Networks sequentially build high-level features through their\nsuccessive layers. We propose here a new neural network model where each layer\nis associated with a set of candidate mappings. When an input is processed, at\neach layer, one mapping among these candidates is selected according to a\nsequential decision process. The resulting model is structured according to a\nDAG like architecture, so that a path from the root to a leaf node defines a\nsequence of transformations. Instead of considering global transformations,\nlike in classical multilayer networks, this model allows us for learning a set\nof local transformations. It is thus able to process data with different\ncharacteristics through specific sequences of such local transformations,\nincreasing the expression power of this model w.r.t a classical multilayered\nnetwork. The learning algorithm is inspired from policy gradient techniques\ncoming from the reinforcement learning domain and is used here instead of the\nclassical back-propagation based gradient descent techniques. Experiments on\ndifferent datasets show the relevance of this approach. \n\n"}
{"id": "1410.0719", "contents": "Title: Proceedings of the second \"international Traveling Workshop on\n  Interactions between Sparse models and Technology\" (iTWIST'14) Abstract: The implicit objective of the biennial \"international - Traveling Workshop on\nInteractions between Sparse models and Technology\" (iTWIST) is to foster\ncollaboration between international scientific teams by disseminating ideas\nthrough both specific oral/poster presentations and free discussions. For its\nsecond edition, the iTWIST workshop took place in the medieval and picturesque\ntown of Namur in Belgium, from Wednesday August 27th till Friday August 29th,\n2014. The workshop was conveniently located in \"The Arsenal\" building within\nwalking distance of both hotels and town center. iTWIST'14 has gathered about\n70 international participants and has featured 9 invited talks, 10 oral\npresentations, and 14 posters on the following themes, all related to the\ntheory, application and generalization of the \"sparsity paradigm\":\nSparsity-driven data sensing and processing; Union of low dimensional\nsubspaces; Beyond linear and convex inverse problem; Matrix/manifold/graph\nsensing/processing; Blind inverse problems and dictionary learning; Sparsity\nand computational neuroscience; Information theory, geometry and randomness;\nComplexity/accuracy tradeoffs in numerical methods; Sparsity? What's next?;\nSparse machine learning and inference. \n\n"}
{"id": "1411.0972", "contents": "Title: Convex Optimization for Big Data Abstract: This article reviews recent advances in convex optimization algorithms for\nBig Data, which aim to reduce the computational, storage, and communications\nbottlenecks. We provide an overview of this emerging field, describe\ncontemporary approximation techniques like first-order methods and\nrandomization for scalability, and survey the important role of parallel and\ndistributed computation. The new Big Data algorithms are based on surprisingly\nsimple principles and attain staggering accelerations even on classical\nproblems. \n\n"}
{"id": "1411.1971", "contents": "Title: Power-Law Graph Cuts Abstract: Algorithms based on spectral graph cut objectives such as normalized cuts,\nratio cuts and ratio association have become popular in recent years because\nthey are widely applicable and simple to implement via standard eigenvector\ncomputations. Despite strong performance for a number of clustering tasks,\nspectral graph cut algorithms still suffer from several limitations: first,\nthey require the number of clusters to be known in advance, but this\ninformation is often unknown a priori; second, they tend to produce clusters\nwith uniform sizes. In some cases, the true clusters exhibit a known size\ndistribution; in image segmentation, for instance, human-segmented images tend\nto yield segment sizes that follow a power-law distribution. In this paper, we\npropose a general framework of power-law graph cut algorithms that produce\nclusters whose sizes are power-law distributed, and also does not fix the\nnumber of clusters upfront. To achieve our goals, we treat the Pitman-Yor\nexchangeable partition probability function (EPPF) as a regularizer to graph\ncut objectives. Because the resulting objectives cannot be solved by relaxing\nvia eigenvectors, we derive a simple iterative algorithm to locally optimize\nthe objectives. Moreover, we show that our proposed algorithm can be viewed as\nperforming MAP inference on a particular Pitman-Yor mixture model. Our\nexperiments on various data sets show the effectiveness of our algorithms. \n\n"}
{"id": "1411.2173", "contents": "Title: Stacked Quantizers for Compositional Vector Compression Abstract: Recently, Babenko and Lempitsky introduced Additive Quantization (AQ), a\ngeneralization of Product Quantization (PQ) where a non-independent set of\ncodebooks is used to compress vectors into small binary codes. Unfortunately,\nunder this scheme encoding cannot be done independently in each codebook, and\noptimal encoding is an NP-hard problem. In this paper, we observe that PQ and\nAQ are both compositional quantizers that lie on the extremes of the codebook\ndependence-independence assumption, and explore an intermediate approach that\nexploits a hierarchical structure in the codebooks. This results in a method\nthat achieves quantization error on par with or lower than AQ, while being\nseveral orders of magnitude faster. We perform a complexity analysis of PQ, AQ\nand our method, and evaluate our approach on standard benchmarks of SIFT and\nGIST descriptors, as well as on new datasets of features obtained from\nstate-of-the-art convolutional neural networks. \n\n"}
{"id": "1411.4033", "contents": "Title: Sparse And Low Rank Decomposition Based Batch Image Alignment for\n  Speckle Reduction of retinal OCT Images Abstract: Optical Coherence Tomography (OCT) is an emerging technique in the field of\nbiomedical imaging, with applications in ophthalmology, dermatology, coronary\nimaging etc. Due to the underlying physics, OCT images usually suffer from a\ngranular pattern, called speckle noise, which restricts the process of\ninterpretation. Here, a sparse and low rank decomposition based method is used\nfor speckle reduction in retinal OCT images. This technique works on input data\nthat consists of several B-scans of the same location. The next step is the\nbatch alignment of the images using a sparse and low-rank decomposition based\ntechnique. Finally the denoised image is created by median filtering of the\nlow-rank component of the processed data. Simultaneous decomposition and\nalignment of the images result in better performance in comparison to simple\nregistration-based methods that are used in the literature for noise reduction\nof OCT images. \n\n"}
{"id": "1411.4952", "contents": "Title: From Captions to Visual Concepts and Back Abstract: This paper presents a novel approach for automatically generating image\ndescriptions: visual detectors, language models, and multimodal similarity\nmodels learnt directly from a dataset of image captions. We use multiple\ninstance learning to train visual detectors for words that commonly occur in\ncaptions, including many different parts of speech such as nouns, verbs, and\nadjectives. The word detector outputs serve as conditional inputs to a\nmaximum-entropy language model. The language model learns from a set of over\n400,000 image descriptions to capture the statistics of word usage. We capture\nglobal semantics by re-ranking caption candidates using sentence-level features\nand a deep multimodal similarity model. Our system is state-of-the-art on the\nofficial Microsoft COCO benchmark, producing a BLEU-4 score of 29.1%. When\nhuman judges compare the system captions to ones written by other people on our\nheld-out test set, the system captions have equal or better quality 34% of the\ntime. \n\n"}
{"id": "1411.6067", "contents": "Title: Viewpoints and Keypoints Abstract: We characterize the problem of pose estimation for rigid objects in terms of\ndetermining viewpoint to explain coarse pose and keypoint prediction to capture\nthe finer details. We address both these tasks in two different settings - the\nconstrained setting with known bounding boxes and the more challenging\ndetection setting where the aim is to simultaneously detect and correctly\nestimate pose of objects. We present Convolutional Neural Network based\narchitectures for these and demonstrate that leveraging viewpoint estimates can\nsubstantially improve local appearance based keypoint predictions. In addition\nto achieving significant improvements over state-of-the-art in the above tasks,\nwe analyze the error modes and effect of object characteristics on performance\nto guide future efforts towards this goal. \n\n"}
{"id": "1411.6909", "contents": "Title: Image Classification and Retrieval from User-Supplied Tags Abstract: This paper proposes direct learning of image classification from\nuser-supplied tags, without filtering. Each tag is supplied by the user who\nshared the image online. Enormous numbers of these tags are freely available\nonline, and they give insight about the image categories important to users and\nto image classification. Our approach is complementary to the conventional\napproach of manual annotation, which is extremely costly. We analyze of the\nFlickr 100 Million Image dataset, making several useful observations about the\nstatistics of these tags. We introduce a large-scale robust classification\nalgorithm, in order to handle the inherent noise in these tags, and a\ncalibration procedure to better predict objective annotations. We show that\nfreely available, user-supplied tags can obtain similar or superior results to\nlarge databases of costly manual annotations. \n\n"}
{"id": "1412.1897", "contents": "Title: Deep Neural Networks are Easily Fooled: High Confidence Predictions for\n  Unrecognizable Images Abstract: Deep neural networks (DNNs) have recently been achieving state-of-the-art\nperformance on a variety of pattern-recognition tasks, most notably visual\nclassification problems. Given that DNNs are now able to classify objects in\nimages with near-human-level performance, questions naturally arise as to what\ndifferences remain between computer and human vision. A recent study revealed\nthat changing an image (e.g. of a lion) in a way imperceptible to humans can\ncause a DNN to label the image as something else entirely (e.g. mislabeling a\nlion a library). Here we show a related result: it is easy to produce images\nthat are completely unrecognizable to humans, but that state-of-the-art DNNs\nbelieve to be recognizable objects with 99.99% confidence (e.g. labeling with\ncertainty that white noise static is a lion). Specifically, we take\nconvolutional neural networks trained to perform well on either the ImageNet or\nMNIST datasets and then find images with evolutionary algorithms or gradient\nascent that DNNs label with high confidence as belonging to each dataset class.\nIt is possible to produce images totally unrecognizable to human eyes that DNNs\nbelieve with near certainty are familiar objects, which we call \"fooling\nimages\" (more generally, fooling examples). Our results shed light on\ninteresting differences between human vision and current DNNs, and raise\nquestions about the generality of DNN computer vision. \n\n"}
{"id": "1412.4729", "contents": "Title: Translating Videos to Natural Language Using Deep Recurrent Neural\n  Networks Abstract: Solving the visual symbol grounding problem has long been a goal of\nartificial intelligence. The field appears to be advancing closer to this goal\nwith recent breakthroughs in deep learning for natural language grounding in\nstatic images. In this paper, we propose to translate videos directly to\nsentences using a unified deep neural network with both convolutional and\nrecurrent structure. Described video datasets are scarce, and most existing\nmethods have been applied to toy domains with a small vocabulary of possible\nwords. By transferring knowledge from 1.2M+ images with category labels and\n100,000+ images with captions, our method is able to create sentence\ndescriptions of open-domain videos with large vocabularies. We compare our\napproach with recent work using language generation metrics, subject, verb, and\nobject prediction accuracy, and a human evaluation. \n\n"}
{"id": "1412.6504", "contents": "Title: Learning to Segment Moving Objects in Videos Abstract: We segment moving objects in videos by ranking spatio-temporal segment\nproposals according to \"moving objectness\": how likely they are to contain a\nmoving object. In each video frame, we compute segment proposals using multiple\nfigure-ground segmentations on per frame motion boundaries. We rank them with a\nMoving Objectness Detector trained on image and motion fields to detect moving\nobjects and discard over/under segmentations or background parts of the scene.\nWe extend the top ranked segments into spatio-temporal tubes using random\nwalkers on motion affinities of dense point trajectories. Our final tube\nranking consistently outperforms previous segmentation methods in the two\nlargest video segmentation benchmarks currently available, for any number of\nproposals. Further, our per frame moving object proposals increase the\ndetection rate up to 7\\% over previous state-of-the-art static proposal\nmethods. \n\n"}
{"id": "1412.6544", "contents": "Title: Qualitatively characterizing neural network optimization problems Abstract: Training neural networks involves solving large-scale non-convex optimization\nproblems. This task has long been believed to be extremely difficult, with fear\nof local minima and other obstacles motivating a variety of schemes to improve\noptimization, such as unsupervised pretraining. However, modern neural networks\nare able to achieve negligible training error on complex tasks, using only\ndirect training with stochastic gradient descent. We introduce a simple\nanalysis technique to look for evidence that such networks are overcoming local\noptima. We find that, in fact, on a straight path from initialization to\nsolution, a variety of state of the art neural networks never encounter any\nsignificant obstacles. \n\n"}
{"id": "1412.6622", "contents": "Title: Deep metric learning using Triplet network Abstract: Deep learning has proven itself as a successful set of models for learning\nuseful semantic representations of data. These, however, are mostly implicitly\nlearned as part of a classification task. In this paper we propose the triplet\nnetwork model, which aims to learn useful representations by distance\ncomparisons. A similar model was defined by Wang et al. (2014), tailor made for\nlearning a ranking for image information retrieval. Here we demonstrate using\nvarious datasets that our model learns a better representation than that of its\nimmediate competitor, the Siamese network. We also discuss future possible\nusage as a framework for unsupervised learning. \n\n"}
{"id": "1412.6830", "contents": "Title: Learning Activation Functions to Improve Deep Neural Networks Abstract: Artificial neural networks typically have a fixed, non-linear activation\nfunction at each neuron. We have designed a novel form of piecewise linear\nactivation function that is learned independently for each neuron using\ngradient descent. With this adaptive activation function, we are able to\nimprove upon deep neural network architectures composed of static rectified\nlinear units, achieving state-of-the-art performance on CIFAR-10 (7.51%),\nCIFAR-100 (30.83%), and a benchmark from high-energy physics involving Higgs\nboson decay modes. \n\n"}
{"id": "1412.7122", "contents": "Title: Learning Deep Object Detectors from 3D Models Abstract: Crowdsourced 3D CAD models are becoming easily accessible online, and can\npotentially generate an infinite number of training images for almost any\nobject category.We show that augmenting the training data of contemporary Deep\nConvolutional Neural Net (DCNN) models with such synthetic data can be\neffective, especially when real training data is limited or not well matched to\nthe target domain. Most freely available CAD models capture 3D shape but are\noften missing other low level cues, such as realistic object texture, pose, or\nbackground. In a detailed analysis, we use synthetic CAD-rendered images to\nprobe the ability of DCNN to learn without these cues, with surprising\nfindings. In particular, we show that when the DCNN is fine-tuned on the target\ndetection task, it exhibits a large degree of invariance to missing low-level\ncues, but, when pretrained on generic ImageNet classification, it learns better\nwhen the low-level cues are simulated. We show that our synthetic DCNN training\napproach significantly outperforms previous methods on the PASCAL VOC2007\ndataset when learning in the few-shot scenario and improves performance in a\ndomain shift scenario on the Office benchmark. \n\n"}
{"id": "1412.7210", "contents": "Title: Denoising autoencoder with modulated lateral connections learns\n  invariant representations of natural images Abstract: Suitable lateral connections between encoder and decoder are shown to allow\nhigher layers of a denoising autoencoder (dAE) to focus on invariant\nrepresentations. In regular autoencoders, detailed information needs to be\ncarried through the highest layers but lateral connections from encoder to\ndecoder relieve this pressure. It is shown that abstract invariant features can\nbe translated to detailed reconstructions when invariant features are allowed\nto modulate the strength of the lateral connection. Three dAE structures with\nmodulated and additive lateral connections, and without lateral connections\nwere compared in experiments using real-world images. The experiments verify\nthat adding modulated lateral connections to the model 1) improves the accuracy\nof the probability model for inputs, as measured by denoising performance; 2)\nresults in representations whose degree of invariance grows faster towards the\nhigher layers; and 3) supports the formation of diverse invariant poolings. \n\n"}
{"id": "1412.8307", "contents": "Title: Fast, simple and accurate handwritten digit classification by training\n  shallow neural network classifiers with the 'extreme learning machine'\n  algorithm Abstract: Recent advances in training deep (multi-layer) architectures have inspired a\nrenaissance in neural network use. For example, deep convolutional networks are\nbecoming the default option for difficult tasks on large datasets, such as\nimage and speech recognition. However, here we show that error rates below 1%\non the MNIST handwritten digit benchmark can be replicated with shallow\nnon-convolutional neural networks. This is achieved by training such networks\nusing the 'Extreme Learning Machine' (ELM) approach, which also enables a very\nrapid training time (~10 minutes). Adding distortions, as is common practise\nfor MNIST, reduces error rates even further. Our methods are also shown to be\ncapable of achieving less than 5.5% error rates on the NORB image database. To\nachieve these results, we introduce several enhancements to the standard ELM\nalgorithm, which individually and in combination can significantly improve\nperformance. The main innovation is to ensure each hidden-unit operates only on\na randomly sized and positioned patch of each image. This form of random\n`receptive field' sampling of the input ensures the input weight matrix is\nsparse, with about 90% of weights equal to zero. Furthermore, combining our\nmethods with a small number of iterations of a single-batch backpropagation\nmethod can significantly reduce the number of hidden-units required to achieve\na particular performance. Our close to state-of-the-art results for MNIST and\nNORB suggest that the ease of use and accuracy of the ELM algorithm for\ndesigning a single-hidden-layer neural network classifier should cause it to be\ngiven greater consideration either as a standalone method for simpler problems,\nor as the final classification stage in deep neural networks applied to more\ndifficult problems. \n\n"}
{"id": "1412.8493", "contents": "Title: An ADMM algorithm for solving a proximal bound-constrained quadratic\n  program Abstract: We consider a proximal operator given by a quadratic function subject to\nbound constraints and give an optimization algorithm using the alternating\ndirection method of multipliers (ADMM). The algorithm is particularly efficient\nto solve a collection of proximal operators that share the same quadratic form,\nor if the quadratic program is the relaxation of a binary quadratic problem. \n\n"}
{"id": "1501.03796", "contents": "Title: The Fast Convergence of Incremental PCA Abstract: We consider a situation in which we see samples in $\\mathbb{R}^d$ drawn\ni.i.d. from some distribution with mean zero and unknown covariance A. We wish\nto compute the top eigenvector of A in an incremental fashion - with an\nalgorithm that maintains an estimate of the top eigenvector in O(d) space, and\nincrementally adjusts the estimate with each new data point that arrives. Two\nclassical such schemes are due to Krasulina (1969) and Oja (1983). We give\nfinite-sample convergence rates for both. \n\n"}
{"id": "1501.04276", "contents": "Title: Correlation Adaptive Subspace Segmentation by Trace Lasso Abstract: This paper studies the subspace segmentation problem. Given a set of data\npoints drawn from a union of subspaces, the goal is to partition them into\ntheir underlying subspaces they were drawn from. The spectral clustering method\nis used as the framework. It requires to find an affinity matrix which is close\nto block diagonal, with nonzero entries corresponding to the data point pairs\nfrom the same subspace. In this work, we argue that both sparsity and the\ngrouping effect are important for subspace segmentation. A sparse affinity\nmatrix tends to be block diagonal, with less connections between data points\nfrom different subspaces. The grouping effect ensures that the highly corrected\ndata which are usually from the same subspace can be grouped together. Sparse\nSubspace Clustering (SSC), by using $\\ell^1$-minimization, encourages sparsity\nfor data selection, but it lacks of the grouping effect. On the contrary,\nLow-Rank Representation (LRR), by rank minimization, and Least Squares\nRegression (LSR), by $\\ell^2$-regularization, exhibit strong grouping effect,\nbut they are short in subset selection. Thus the obtained affinity matrix is\nusually very sparse by SSC, yet very dense by LRR and LSR.\n  In this work, we propose the Correlation Adaptive Subspace Segmentation\n(CASS) method by using trace Lasso. CASS is a data correlation dependent method\nwhich simultaneously performs automatic data selection and groups correlated\ndata together. It can be regarded as a method which adaptively balances SSC and\nLSR. Both theoretical and experimental results show the effectiveness of CASS. \n\n"}
{"id": "1501.04711", "contents": "Title: DeepHash: Getting Regularization, Depth and Fine-Tuning Right Abstract: This work focuses on representing very high-dimensional global image\ndescriptors using very compact 64-1024 bit binary hashes for instance\nretrieval. We propose DeepHash: a hashing scheme based on deep networks. Key to\nmaking DeepHash work at extremely low bitrates are three important\nconsiderations -- regularization, depth and fine-tuning -- each requiring\nsolutions specific to the hashing problem. In-depth evaluation shows that our\nscheme consistently outperforms state-of-the-art methods across all data sets\nfor both Fisher Vectors and Deep Convolutional Neural Network features, by up\nto 20 percent over other schemes. The retrieval performance with 256-bit hashes\nis close to that of the uncompressed floating point features -- a remarkable\n512 times compression. \n\n"}
{"id": "1502.02478", "contents": "Title: Efficient batchwise dropout training using submatrices Abstract: Dropout is a popular technique for regularizing artificial neural networks.\nDropout networks are generally trained by minibatch gradient descent with a\ndropout mask turning off some of the units---a different pattern of dropout is\napplied to every sample in the minibatch. We explore a very simple alternative\nto the dropout mask. Instead of masking dropped out units by setting them to\nzero, we perform matrix multiplication using a submatrix of the weight\nmatrix---unneeded hidden units are never calculated. Performing dropout\nbatchwise, so that one pattern of dropout is used for each sample in a\nminibatch, we can substantially reduce training times. Batchwise dropout can be\nused with fully-connected and convolutional neural networks. \n\n"}
{"id": "1502.02734", "contents": "Title: Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image\n  Segmentation Abstract: Deep convolutional neural networks (DCNNs) trained on a large number of\nimages with strong pixel-level annotations have recently significantly pushed\nthe state-of-art in semantic image segmentation. We study the more challenging\nproblem of learning DCNNs for semantic image segmentation from either (1)\nweakly annotated training data such as bounding boxes or image-level labels or\n(2) a combination of few strongly labeled and many weakly labeled images,\nsourced from one or multiple datasets. We develop Expectation-Maximization (EM)\nmethods for semantic image segmentation model training under these weakly\nsupervised and semi-supervised settings. Extensive experimental evaluation\nshows that the proposed techniques can learn models delivering competitive\nresults on the challenging PASCAL VOC 2012 image segmentation benchmark, while\nrequiring significantly less annotation effort. We share source code\nimplementing the proposed system at\nhttps://bitbucket.org/deeplab/deeplab-public. \n\n"}
{"id": "1502.04569", "contents": "Title: Image Specificity Abstract: For some images, descriptions written by multiple people are consistent with\neach other. But for other images, descriptions across people vary considerably.\nIn other words, some images are specific $-$ they elicit consistent\ndescriptions from different people $-$ while other images are ambiguous.\nApplications involving images and text can benefit from an understanding of\nwhich images are specific and which ones are ambiguous. For instance, consider\ntext-based image retrieval. If a query description is moderately similar to the\ncaption (or reference description) of an ambiguous image, that query may be\nconsidered a decent match to the image. But if the image is very specific, a\nmoderate similarity between the query and the reference description may not be\nsufficient to retrieve the image.\n  In this paper, we introduce the notion of image specificity. We present two\nmechanisms to measure specificity given multiple descriptions of an image: an\nautomated measure and a measure that relies on human judgement. We analyze\nimage specificity with respect to image content and properties to better\nunderstand what makes an image specific. We then train models to automatically\npredict the specificity of an image from image features alone without requiring\ntextual descriptions of the image. Finally, we show that modeling image\nspecificity leads to improvements in a text-based image retrieval application. \n\n"}
{"id": "1502.06464", "contents": "Title: Rectified Factor Networks Abstract: We propose rectified factor networks (RFNs) to efficiently construct very\nsparse, non-linear, high-dimensional representations of the input. RFN models\nidentify rare and small events in the input, have a low interference between\ncode units, have a small reconstruction error, and explain the data covariance\nstructure. RFN learning is a generalized alternating minimization algorithm\nderived from the posterior regularization method which enforces non-negative\nand normalized posterior means. We proof convergence and correctness of the RFN\nlearning algorithm. On benchmarks, RFNs are compared to other unsupervised\nmethods like autoencoders, RBMs, factor analysis, ICA, and PCA. In contrast to\nprevious sparse coding methods, RFNs yield sparser codes, capture the data's\ncovariance structure more precisely, and have a significantly smaller\nreconstruction error. We test RFNs as pretraining technique for deep networks\non different vision datasets, where RFNs were superior to RBMs and\nautoencoders. On gene expression data from two pharmaceutical drug discovery\nstudies, RFNs detected small and rare gene modules that revealed highly\nrelevant new biological insights which were so far missed by other unsupervised\nmethods. \n\n"}
{"id": "1502.07802", "contents": "Title: Modelling Local Deep Convolutional Neural Network Features to Improve\n  Fine-Grained Image Classification Abstract: We propose a local modelling approach using deep convolutional neural\nnetworks (CNNs) for fine-grained image classification. Recently, deep CNNs\ntrained from large datasets have considerably improved the performance of\nobject recognition. However, to date there has been limited work using these\ndeep CNNs as local feature extractors. This partly stems from CNNs having\ninternal representations which are high dimensional, thereby making such\nrepresentations difficult to model using stochastic models. To overcome this\nissue, we propose to reduce the dimensionality of one of the internal fully\nconnected layers, in conjunction with layer-restricted retraining to avoid\nretraining the entire network. The distribution of low-dimensional features\nobtained from the modified layer is then modelled using a Gaussian mixture\nmodel. Comparative experiments show that considerable performance improvements\ncan be achieved on the challenging Fish and UEC FOOD-100 datasets. \n\n"}
{"id": "1502.07816", "contents": "Title: Puzzle Imaging: Using Large-scale Dimensionality Reduction Algorithms\n  for Localization Abstract: Current high-resolution imaging techniques require an intact sample that\npreserves spatial relationships. We here present a novel approach, \"puzzle\nimaging,\" that allows imaging a spatially scrambled sample. This technique\ntakes many spatially disordered samples, and then pieces them back together\nusing local properties embedded within the sample. We show that puzzle imaging\ncan efficiently produce high-resolution images using dimensionality reduction\nalgorithms. We demonstrate the theoretical capabilities of puzzle imaging in\nthree biological scenarios, showing that (1) relatively precise 3-dimensional\nbrain imaging is possible; (2) the physical structure of a neural network can\noften be recovered based only on the neural connectivity matrix; and (3) a\nchemical map could be reproduced using bacteria with chemosensitive DNA and\nconjugative transfer. The ability to reconstruct scrambled images promises to\nenable imaging based on DNA sequencing of homogenized tissue samples. \n\n"}
{"id": "1503.01057", "contents": "Title: Kernel Interpolation for Scalable Structured Gaussian Processes\n  (KISS-GP) Abstract: We introduce a new structured kernel interpolation (SKI) framework, which\ngeneralises and unifies inducing point methods for scalable Gaussian processes\n(GPs). SKI methods produce kernel approximations for fast computations through\nkernel interpolation. The SKI framework clarifies how the quality of an\ninducing point approach depends on the number of inducing (aka interpolation)\npoints, interpolation strategy, and GP covariance kernel. SKI also provides a\nmechanism to create new scalable kernel methods, through choosing different\nkernel interpolation strategies. Using SKI, with local cubic kernel\ninterpolation, we introduce KISS-GP, which is 1) more scalable than inducing\npoint alternatives, 2) naturally enables Kronecker and Toeplitz algebra for\nsubstantial additional gains in scalability, without requiring any grid data,\nand 3) can be used for fast and expressive kernel learning. KISS-GP costs O(n)\ntime and storage for GP inference. We evaluate KISS-GP for kernel matrix\napproximation, kernel learning, and natural sound modelling. \n\n"}
{"id": "1503.01070", "contents": "Title: Using Descriptive Video Services to Create a Large Data Source for Video\n  Annotation Research Abstract: In this work, we introduce a dataset of video annotated with high quality\nnatural language phrases describing the visual content in a given segment of\ntime. Our dataset is based on the Descriptive Video Service (DVS) that is now\nencoded on many digital media products such as DVDs. DVS is an audio narration\ndescribing the visual elements and actions in a movie for the visually\nimpaired. It is temporally aligned with the movie and mixed with the original\nmovie soundtrack. We describe an automatic DVS segmentation and alignment\nmethod for movies, that enables us to scale up the collection of a DVS-derived\ndataset with minimal human intervention. Using this method, we have collected\nthe largest DVS-derived dataset for video description of which we are aware.\nOur dataset currently includes over 84.6 hours of paired video/sentences from\n92 DVDs and is growing. \n\n"}
{"id": "1503.01444", "contents": "Title: Partial Sum Minimization of Singular Values in Robust PCA: Algorithm and\n  Applications Abstract: Robust Principal Component Analysis (RPCA) via rank minimization is a\npowerful tool for recovering underlying low-rank structure of clean data\ncorrupted with sparse noise/outliers. In many low-level vision problems, not\nonly it is known that the underlying structure of clean data is low-rank, but\nthe exact rank of clean data is also known. Yet, when applying conventional\nrank minimization for those problems, the objective function is formulated in a\nway that does not fully utilize a priori target rank information about the\nproblems. This observation motivates us to investigate whether there is a\nbetter alternative solution when using rank minimization. In this paper,\ninstead of minimizing the nuclear norm, we propose to minimize the partial sum\nof singular values, which implicitly encourages the target rank constraint. Our\nexperimental analyses show that, when the number of samples is deficient, our\napproach leads to a higher success rate than conventional rank minimization,\nwhile the solutions obtained by the two approaches are almost identical when\nthe number of samples is more than sufficient. We apply our approach to various\nlow-level vision problems, e.g. high dynamic range imaging, motion edge\ndetection, photometric stereo, image alignment and recovery, and show that our\nresults outperform those obtained by the conventional nuclear norm rank\nminimization method. \n\n"}
{"id": "1503.02364", "contents": "Title: Neural Responding Machine for Short-Text Conversation Abstract: We propose Neural Responding Machine (NRM), a neural network-based response\ngenerator for Short-Text Conversation. NRM takes the general encoder-decoder\nframework: it formalizes the generation of response as a decoding process based\non the latent representation of the input text, while both encoding and\ndecoding are realized with recurrent neural networks (RNN). The NRM is trained\nwith a large amount of one-round conversation data collected from a\nmicroblogging service. Empirical study shows that NRM can generate\ngrammatically correct and content-wise appropriate responses to over 75% of the\ninput text, outperforming state-of-the-arts in the same setting, including\nretrieval-based and SMT-based models. \n\n"}
{"id": "1503.02427", "contents": "Title: Syntax-based Deep Matching of Short Texts Abstract: Many tasks in natural language processing, ranging from machine translation\nto question answering, can be reduced to the problem of matching two sentences\nor more generally two short texts. We propose a new approach to the problem,\ncalled Deep Match Tree (DeepMatch$_{tree}$), under a general setting. The\napproach consists of two components, 1) a mining algorithm to discover patterns\nfor matching two short-texts, defined in the product space of dependency trees,\nand 2) a deep neural network for matching short texts using the mined patterns,\nas well as a learning algorithm to build the network having a sparse structure.\nWe test our algorithm on the problem of matching a tweet and a response in\nsocial media, a hard matching problem proposed in [Wang et al., 2013], and show\nthat DeepMatch$_{tree}$ can outperform a number of competitor models including\none without using dependency trees and one based on word-embedding, all with\nlarge margins \n\n"}
{"id": "1503.02531", "contents": "Title: Distilling the Knowledge in a Neural Network Abstract: A very simple way to improve the performance of almost any machine learning\nalgorithm is to train many different models on the same data and then to\naverage their predictions. Unfortunately, making predictions using a whole\nensemble of models is cumbersome and may be too computationally expensive to\nallow deployment to a large number of users, especially if the individual\nmodels are large neural nets. Caruana and his collaborators have shown that it\nis possible to compress the knowledge in an ensemble into a single model which\nis much easier to deploy and we develop this approach further using a different\ncompression technique. We achieve some surprising results on MNIST and we show\nthat we can significantly improve the acoustic model of a heavily used\ncommercial system by distilling the knowledge in an ensemble of models into a\nsingle model. We also introduce a new type of ensemble composed of one or more\nfull models and many specialist models which learn to distinguish fine-grained\nclasses that the full models confuse. Unlike a mixture of experts, these\nspecialist models can be trained rapidly and in parallel. \n\n"}
{"id": "1503.03562", "contents": "Title: Training Binary Multilayer Neural Networks for Image Classification\n  using Expectation Backpropagation Abstract: Compared to Multilayer Neural Networks with real weights, Binary Multilayer\nNeural Networks (BMNNs) can be implemented more efficiently on dedicated\nhardware. BMNNs have been demonstrated to be effective on binary classification\ntasks with Expectation BackPropagation (EBP) algorithm on high dimensional text\ndatasets. In this paper, we investigate the capability of BMNNs using the EBP\nalgorithm on multiclass image classification tasks. The performances of binary\nneural networks with multiple hidden layers and different numbers of hidden\nunits are examined on MNIST. We also explore the effectiveness of image spatial\nfilters and the dropout technique in BMNNs. Experimental results on MNIST\ndataset show that EBP can obtain 2.12% test error with binary weights and 1.66%\ntest error with real weights, which is comparable to the results of standard\nBackPropagation algorithm on fully connected MNNs. \n\n"}
{"id": "1503.04596", "contents": "Title: Enhanced Image Classification With a Fast-Learning Shallow Convolutional\n  Neural Network Abstract: We present a neural network architecture and training method designed to\nenable very rapid training and low implementation complexity. Due to its\ntraining speed and very few tunable parameters, the method has strong potential\nfor applications requiring frequent retraining or online training. The approach\nis characterized by (a) convolutional filters based on biologically inspired\nvisual processing filters, (b) randomly-valued classifier-stage input weights,\n(c) use of least squares regression to train the classifier output weights in a\nsingle batch, and (d) linear classifier-stage output units. We demonstrate the\nefficacy of the method by applying it to image classification. Our results\nmatch existing state-of-the-art results on the MNIST (0.37% error) and\nNORB-small (2.2% error) image classification databases, but with very fast\ntraining times compared to standard deep network approaches. The network's\nperformance on the Google Street View House Number (SVHN) (4% error) database\nis also competitive with state-of-the art methods. \n\n"}
{"id": "1503.06350", "contents": "Title: Boosting Convolutional Features for Robust Object Proposals Abstract: Deep Convolutional Neural Networks (CNNs) have demonstrated excellent\nperformance in image classification, but still show room for improvement in\nobject-detection tasks with many categories, in particular for cluttered scenes\nand occlusion. Modern detection algorithms like Regions with CNNs (Girshick et\nal., 2014) rely on Selective Search (Uijlings et al., 2013) to propose regions\nwhich with high probability represent objects, where in turn CNNs are deployed\nfor classification. Selective Search represents a family of sophisticated\nalgorithms that are engineered with multiple segmentation, appearance and\nsaliency cues, typically coming with a significant run-time overhead.\nFurthermore, (Hosang et al., 2014) have shown that most methods suffer from low\nreproducibility due to unstable superpixels, even for slight image\nperturbations. Although CNNs are subsequently used for classification in\ntop-performing object-detection pipelines, current proposal methods are\nagnostic to how these models parse objects and their rich learned\nrepresentations. As a result they may propose regions which may not resemble\nhigh-level objects or totally miss some of them. To overcome these drawbacks we\npropose a boosting approach which directly takes advantage of hierarchical CNN\nfeatures for detecting regions of interest fast. We demonstrate its performance\non ImageNet 2013 detection benchmark and compare it with state-of-the-art\nmethods. \n\n"}
{"id": "1503.07077", "contents": "Title: Rotation-invariant convolutional neural networks for galaxy morphology\n  prediction Abstract: Measuring the morphological parameters of galaxies is a key requirement for\nstudying their formation and evolution. Surveys such as the Sloan Digital Sky\nSurvey (SDSS) have resulted in the availability of very large collections of\nimages, which have permitted population-wide analyses of galaxy morphology.\nMorphological analysis has traditionally been carried out mostly via visual\ninspection by trained experts, which is time-consuming and does not scale to\nlarge ($\\gtrsim10^4$) numbers of images.\n  Although attempts have been made to build automated classification systems,\nthese have not been able to achieve the desired level of accuracy. The Galaxy\nZoo project successfully applied a crowdsourcing strategy, inviting online\nusers to classify images by answering a series of questions. Unfortunately,\neven this approach does not scale well enough to keep up with the increasing\navailability of galaxy images.\n  We present a deep neural network model for galaxy morphology classification\nwhich exploits translational and rotational symmetry. It was developed in the\ncontext of the Galaxy Challenge, an international competition to build the best\nmodel for morphology classification based on annotated images from the Galaxy\nZoo project.\n  For images with high agreement among the Galaxy Zoo participants, our model\nis able to reproduce their consensus with near-perfect accuracy ($> 99\\%$) for\nmost questions. Confident model predictions are highly accurate, which makes\nthe model suitable for filtering large collections of images and forwarding\nchallenging images to experts for manual annotation. This approach greatly\nreduces the experts' workload without affecting accuracy. The application of\nthese algorithms to larger sets of training data will be critical for analysing\nresults from future surveys such as the LSST. \n\n"}
{"id": "1504.01639", "contents": "Title: Ego-Object Discovery Abstract: Lifelogging devices are spreading faster everyday. This growth can represent\ngreat benefits to develop methods for extraction of meaningful information\nabout the user wearing the device and his/her environment. In this paper, we\npropose a semi-supervised strategy for easily discovering objects relevant to\nthe person wearing a first-person camera. Given an egocentric video/images\nsequence acquired by the camera, our algorithm uses both the appearance\nextracted by means of a convolutional neural network and an object refill\nmethodology that allows to discover objects even in case of small amount of\nobject appearance in the collection of images. An SVM filtering strategy is\napplied to deal with the great part of the False Positive object candidates\nfound by most of the state of the art object detectors. We validate our method\non a new egocentric dataset of 4912 daily images acquired by 4 persons as well\nas on both PASCAL 2012 and MSRC datasets. We obtain for all of them results\nthat largely outperform the state of the art approach. We make public both the\nEDUB dataset and the algorithm code. \n\n"}
{"id": "1504.01806", "contents": "Title: Kernelized Low Rank Representation on Grassmann Manifolds Abstract: Low rank representation (LRR) has recently attracted great interest due to\nits pleasing efficacy in exploring low-dimensional subspace structures embedded\nin data. One of its successful applications is subspace clustering which means\ndata are clustered according to the subspaces they belong to. In this paper, at\na higher level, we intend to cluster subspaces into classes of subspaces. This\nis naturally described as a clustering problem on Grassmann manifold. The\nnovelty of this paper is to generalize LRR on Euclidean space onto an LRR model\non Grassmann manifold in a uniform kernelized framework. The new methods have\nmany applications in computer vision tasks. Several clustering experiments are\nconducted on handwritten digit images, dynamic textures, human face clips and\ntraffic scene sequences. The experimental results show that the proposed\nmethods outperform a number of state-of-the-art subspace clustering methods. \n\n"}
{"id": "1504.05277", "contents": "Title: Deep Spatial Pyramid: The Devil is Once Again in the Details Abstract: In this paper we show that by carefully making good choices for various\ndetailed but important factors in a visual recognition framework using deep\nlearning features, one can achieve a simple, efficient, yet highly accurate\nimage classification system. We first list 5 important factors, based on both\nexisting researches and ideas proposed in this paper. These important detailed\nfactors include: 1) $\\ell_2$ matrix normalization is more effective than\nunnormalized or $\\ell_2$ vector normalization, 2) the proposed natural deep\nspatial pyramid is very effective, and 3) a very small $K$ in Fisher Vectors\nsurprisingly achieves higher accuracy than normally used large $K$ values.\nAlong with other choices (convolutional activations and multiple scales), the\nproposed DSP framework is not only intuitive and efficient, but also achieves\nexcellent classification accuracy on many benchmark datasets. For example,\nDSP's accuracy on SUN397 is 59.78%, significantly higher than previous\nstate-of-the-art (53.86%). \n\n"}
{"id": "1505.00315", "contents": "Title: Learning Temporal Embeddings for Complex Video Analysis Abstract: In this paper, we propose to learn temporal embeddings of video frames for\ncomplex video analysis. Large quantities of unlabeled video data can be easily\nobtained from the Internet. These videos possess the implicit weak label that\nthey are sequences of temporally and semantically coherent images. We leverage\nthis information to learn temporal embeddings for video frames by associating\nframes with the temporal context that they appear in. To do this, we propose a\nscheme for incorporating temporal context based on past and future frames in\nvideos, and compare this to other contextual representations. In addition, we\nshow how data augmentation using multi-resolution samples and hard negatives\nhelps to significantly improve the quality of the learned embeddings. We\nevaluate various design decisions for learning temporal embeddings, and show\nthat our embeddings can improve performance for multiple video tasks such as\nretrieval, classification, and temporal order recovery in unconstrained\nInternet video. \n\n"}
{"id": "1505.00571", "contents": "Title: Higher Order Maximum Persistency and Comparison Theorems Abstract: We address combinatorial problems that can be formulated as minimization of a\npartially separable function of discrete variables (energy minimization in\ngraphical models, weighted constraint satisfaction, pseudo-Boolean\noptimization, 0-1 polynomial programming). For polyhedral relaxations of such\nproblems it is generally not true that variables integer in the relaxed\nsolution will retain the same values in the optimal discrete solution. Those\nwhich do are called persistent. Such persistent variables define a part of a\nglobally optimal solution. Once identified, they can be excluded from the\nproblem, reducing its size.\n  To any polyhedral relaxation we associate a sufficient condition proving\npersistency of a subset of variables. We set up a specially constructed linear\nprogram which determines the set of persistent variables maximal with respect\nto the relaxation. The condition improves as the relaxation is tightened and\npossesses all its invariances. The proposed framework explains a variety of\nexisting methods originating from different areas of research and based on\ndifferent principles. A theoretical comparison is established that relates\nthese methods to the standard linear relaxation and proves that the proposed\ntechnique identifies same or larger set of persistent variables. \n\n"}
{"id": "1505.02146", "contents": "Title: DeepBox: Learning Objectness with Convolutional Networks Abstract: Existing object proposal approaches use primarily bottom-up cues to rank\nproposals, while we believe that objectness is in fact a high level construct.\nWe argue for a data-driven, semantic approach for ranking object proposals. Our\nframework, which we call DeepBox, uses convolutional neural networks (CNNs) to\nrerank proposals from a bottom-up method. We use a novel four-layer CNN\narchitecture that is as good as much larger networks on the task of evaluating\nobjectness while being much faster. We show that DeepBox significantly improves\nover the bottom-up ranking, achieving the same recall with 500 proposals as\nachieved by bottom-up methods with 2000. This improvement generalizes to\ncategories the CNN has never seen before and leads to a 4.5-point gain in\ndetection mAP. Our implementation achieves this performance while running at\n260 ms per image. \n\n"}
{"id": "1505.06027", "contents": "Title: Weakly-Supervised Alignment of Video With Text Abstract: Suppose that we are given a set of videos, along with natural language\ndescriptions in the form of multiple sentences (e.g., manual annotations, movie\nscripts, sport summaries etc.), and that these sentences appear in the same\ntemporal order as their visual counterparts. We propose in this paper a method\nfor aligning the two modalities, i.e., automatically providing a time stamp for\nevery sentence. Given vectorial features for both video and text, we propose to\ncast this task as a temporal assignment problem, with an implicit linear\nmapping between the two feature modalities. We formulate this problem as an\ninteger quadratic program, and solve its continuous convex relaxation using an\nefficient conditional gradient algorithm. Several rounding procedures are\nproposed to construct the final integer solution. After demonstrating\nsignificant improvements over the state of the art on the related task of\naligning video with symbolic labels [7], we evaluate our method on a\nchallenging dataset of videos with associated textual descriptions [36], using\nboth bag-of-words and continuous representations for text. \n\n"}
{"id": "1505.06973", "contents": "Title: Efficient Decomposition of Image and Mesh Graphs by Lifted Multicuts Abstract: Formulations of the Image Decomposition Problem as a Multicut Problem (MP)\nw.r.t. a superpixel graph have received considerable attention. In contrast,\ninstances of the MP w.r.t. a pixel grid graph have received little attention,\nfirstly, because the MP is NP-hard and instances w.r.t. a pixel grid graph are\nhard to solve in practice, and, secondly, due to the lack of long-range terms\nin the objective function of the MP. We propose a generalization of the MP with\nlong-range terms (LMP). We design and implement two efficient algorithms\n(primal feasible heuristics) for the MP and LMP which allow us to study\ninstances of both problems w.r.t. the pixel grid graphs of the images in the\nBSDS-500 benchmark. The decompositions we obtain do not differ significantly\nfrom the state of the art, suggesting that the LMP is a competitive formulation\nof the Image Decomposition Problem. To demonstrate the generality of the LMP,\nwe apply it also to the Mesh Decomposition Problem posed by the Princeton\nbenchmark, obtaining state-of-the-art decompositions. \n\n"}
{"id": "1505.07409", "contents": "Title: Improving Spatial Codification in Semantic Segmentation Abstract: This paper explores novel approaches for improving the spatial codification\nfor the pooling of local descriptors to solve the semantic segmentation\nproblem. We propose to partition the image into three regions for each object\nto be described: Figure, Border and Ground. This partition aims at minimizing\nthe influence of the image context on the object description and vice versa by\nintroducing an intermediate zone around the object contour. Furthermore, we\nalso propose a richer visual descriptor of the object by applying a Spatial\nPyramid over the Figure region. Two novel Spatial Pyramid configurations are\nexplored: Cartesian-based and crown-based Spatial Pyramids. We test these\napproaches with state-of-the-art techniques and show that they improve the\nFigure-Ground based pooling in the Pascal VOC 2011 and 2012 semantic\nsegmentation challenges. \n\n"}
{"id": "1506.02617", "contents": "Title: Path-SGD: Path-Normalized Optimization in Deep Neural Networks Abstract: We revisit the choice of SGD for training deep neural networks by\nreconsidering the appropriate geometry in which to optimize the weights. We\nargue for a geometry invariant to rescaling of weights that does not affect the\noutput of the network, and suggest Path-SGD, which is an approximate steepest\ndescent method with respect to a path-wise regularizer related to max-norm\nregularization. Path-SGD is easy and efficient to implement and leads to\nempirical gains over SGD and AdaGrad. \n\n"}
{"id": "1506.02626", "contents": "Title: Learning both Weights and Connections for Efficient Neural Networks Abstract: Neural networks are both computationally intensive and memory intensive,\nmaking them difficult to deploy on embedded systems. Also, conventional\nnetworks fix the architecture before training starts; as a result, training\ncannot improve the architecture. To address these limitations, we describe a\nmethod to reduce the storage and computation required by neural networks by an\norder of magnitude without affecting their accuracy by learning only the\nimportant connections. Our method prunes redundant connections using a\nthree-step method. First, we train the network to learn which connections are\nimportant. Next, we prune the unimportant connections. Finally, we retrain the\nnetwork to fine tune the weights of the remaining connections. On the ImageNet\ndataset, our method reduced the number of parameters of AlexNet by a factor of\n9x, from 61 million to 6.7 million, without incurring accuracy loss. Similar\nexperiments with VGG-16 found that the number of parameters can be reduced by\n13x, from 138 million to 10.3 million, again with no loss of accuracy. \n\n"}
{"id": "1506.02753", "contents": "Title: Inverting Visual Representations with Convolutional Networks Abstract: Feature representations, both hand-designed and learned ones, are often hard\nto analyze and interpret, even when they are extracted from visual data. We\npropose a new approach to study image representations by inverting them with an\nup-convolutional neural network. We apply the method to shallow representations\n(HOG, SIFT, LBP), as well as to deep networks. For shallow representations our\napproach provides significantly better reconstructions than existing methods,\nrevealing that there is surprisingly rich information contained in these\nfeatures. Inverting a deep network trained on ImageNet provides several\ninsights into the properties of the feature representation learned by the\nnetwork. Most strikingly, the colors and the rough contours of an image can be\nreconstructed from activations in higher network layers and even from the\npredicted class probabilities. \n\n"}
{"id": "1506.03099", "contents": "Title: Scheduled Sampling for Sequence Prediction with Recurrent Neural\n  Networks Abstract: Recurrent Neural Networks can be trained to produce sequences of tokens given\nsome input, as exemplified by recent results in machine translation and image\ncaptioning. The current approach to training them consists of maximizing the\nlikelihood of each token in the sequence given the current (recurrent) state\nand the previous token. At inference, the unknown previous token is then\nreplaced by a token generated by the model itself. This discrepancy between\ntraining and inference can yield errors that can accumulate quickly along the\ngenerated sequence. We propose a curriculum learning strategy to gently change\nthe training process from a fully guided scheme using the true previous token,\ntowards a less guided scheme which mostly uses the generated token instead.\nExperiments on several sequence prediction tasks show that this approach yields\nsignificant improvements. Moreover, it was used successfully in our winning\nentry to the MSCOCO image captioning challenge, 2015. \n\n"}
{"id": "1506.03137", "contents": "Title: Symmetric Tensor Completion from Multilinear Entries and Learning\n  Product Mixtures over the Hypercube Abstract: We give an algorithm for completing an order-$m$ symmetric low-rank tensor\nfrom its multilinear entries in time roughly proportional to the number of\ntensor entries. We apply our tensor completion algorithm to the problem of\nlearning mixtures of product distributions over the hypercube, obtaining new\nalgorithmic results. If the centers of the product distribution are linearly\nindependent, then we recover distributions with as many as $\\Omega(n)$ centers\nin polynomial time and sample complexity. In the general case, we recover\ndistributions with as many as $\\tilde\\Omega(n)$ centers in quasi-polynomial\ntime, answering an open problem of Feldman et al. (SIAM J. Comp.) for the\nspecial case of distributions with incoherent bias vectors.\n  Our main algorithmic tool is the iterated application of a low-rank matrix\ncompletion algorithm for matrices with adversarially missing entries. \n\n"}
{"id": "1506.04757", "contents": "Title: Image-based Recommendations on Styles and Substitutes Abstract: Humans inevitably develop a sense of the relationships between objects, some\nof which are based on their appearance. Some pairs of objects might be seen as\nbeing alternatives to each other (such as two pairs of jeans), while others may\nbe seen as being complementary (such as a pair of jeans and a matching shirt).\nThis information guides many of the choices that people make, from buying\nclothes to their interactions with each other. We seek here to model this human\nsense of the relationships between objects based on their appearance. Our\napproach is not based on fine-grained modeling of user annotations but rather\non capturing the largest dataset possible and developing a scalable method for\nuncovering human notions of the visual relationships within. We cast this as a\nnetwork inference problem defined on graphs of related images, and provide a\nlarge-scale dataset for the training and evaluation of the same. The system we\ndevelop is capable of recommending which clothes and accessories will go well\ntogether (and which will not), amongst a host of other applications. \n\n"}
{"id": "1506.06272", "contents": "Title: Aligning where to see and what to tell: image caption with region-based\n  attention and scene factorization Abstract: Recent progress on automatic generation of image captions has shown that it\nis possible to describe the most salient information conveyed by images with\naccurate and meaningful sentences. In this paper, we propose an image caption\nsystem that exploits the parallel structures between images and sentences. In\nour model, the process of generating the next word, given the previously\ngenerated ones, is aligned with the visual perception experience where the\nattention shifting among the visual regions imposes a thread of visual\nordering. This alignment characterizes the flow of \"abstract meaning\", encoding\nwhat is semantically shared by both the visual scene and the text description.\nOur system also makes another novel modeling contribution by introducing\nscene-specific contexts that capture higher-level semantic information encoded\nin an image. The contexts adapt language models for word generation to specific\nscene types. We benchmark our system and contrast to published results on\nseveral popular datasets. We show that using either region-based attention or\nscene-specific contexts improves systems without those components. Furthermore,\ncombining these two modeling ingredients attains the state-of-the-art\nperformance. \n\n"}
{"id": "1506.06833", "contents": "Title: A Survey of Current Datasets for Vision and Language Research Abstract: Integrating vision and language has long been a dream in work on artificial\nintelligence (AI). In the past two years, we have witnessed an explosion of\nwork that brings together vision and language from images to videos and beyond.\nThe available corpora have played a crucial role in advancing this area of\nresearch. In this paper, we propose a set of quality metrics for evaluating and\nanalyzing the vision & language datasets and categorize them accordingly. Our\nanalyses show that the most recent datasets have been using more complex\nlanguage and more abstract concepts, however, there are different strengths and\nweaknesses in each. \n\n"}
{"id": "1506.08891", "contents": "Title: Detecting Table Region in PDF Documents Using Distant Supervision Abstract: Superior to state-of-the-art approaches which compete in table recognition\nwith 67 annotated government reports in PDF format released by {\\it ICDAR 2013\nTable Competition}, this paper contributes a novel paradigm leveraging\nlarge-scale unlabeled PDF documents to open-domain table detection. We\nintegrate the paradigm into our latest developed system ({\\it PdfExtra}) to\ndetect the region of tables by means of 9,466 academic articles from the entire\nrepository of {\\it ACL Anthology}, where almost all papers are archived by PDF\nformat without annotation for tables. The paradigm first designs heuristics to\nautomatically construct weakly labeled data. It then feeds diverse evidences,\nsuch as layouts of documents and linguistic features, which are extracted by\n{\\it Apache PDFBox} and processed by {\\it Stanford NLP} toolkit, into different\ncanonical classifiers. We finally use these classifiers, i.e. {\\it Naive\nBayes}, {\\it Logistic Regression} and {\\it Support Vector Machine}, to\ncollaboratively vote on the region of tables. Experimental results show that\n{\\it PdfExtra} achieves a great leap forward, compared with the\nstate-of-the-art approach. Moreover, we discuss the factors of different\nfeatures, learning models and even domains of documents that may impact the\nperformance. Extensive evaluations demonstrate that our paradigm is compatible\nenough to leverage various features and learning models for open-domain table\nregion detection within PDF files. \n\n"}
{"id": "1506.08909", "contents": "Title: The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured\n  Multi-Turn Dialogue Systems Abstract: This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost\n1 million multi-turn dialogues, with a total of over 7 million utterances and\n100 million words. This provides a unique resource for research into building\ndialogue managers based on neural language models that can make use of large\namounts of unlabeled data. The dataset has both the multi-turn property of\nconversations in the Dialog State Tracking Challenge datasets, and the\nunstructured nature of interactions from microblog services such as Twitter. We\nalso describe two neural learning architectures suitable for analyzing this\ndataset, and provide benchmark performance on the task of selecting the best\nnext response. \n\n"}
{"id": "1507.04844", "contents": "Title: Learning Robust Deep Face Representation Abstract: With the development of convolution neural network, more and more researchers\nfocus their attention on the advantage of CNN for face recognition task. In\nthis paper, we propose a deep convolution network for learning a robust face\nrepresentation. The deep convolution net is constructed by 4 convolution\nlayers, 4 max pooling layers and 2 fully connected layers, which totally\ncontains about 4M parameters. The Max-Feature-Map activation function is used\ninstead of ReLU because the ReLU might lead to the loss of information due to\nthe sparsity while the Max-Feature-Map can get the compact and discriminative\nfeature vectors. The model is trained on CASIA-WebFace dataset and evaluated on\nLFW dataset. The result on LFW achieves 97.77% on unsupervised setting for\nsingle net. \n\n"}
{"id": "1507.05775", "contents": "Title: Compression of Fully-Connected Layer in Neural Network by Kronecker\n  Product Abstract: In this paper we propose and study a technique to reduce the number of\nparameters and computation time in fully-connected layers of neural networks\nusing Kronecker product, at a mild cost of the prediction quality. The\ntechnique proceeds by replacing Fully-Connected layers with so-called Kronecker\nFully-Connected layers, where the weight matrices of the FC layers are\napproximated by linear combinations of multiple Kronecker products of smaller\nmatrices. In particular, given a model trained on SVHN dataset, we are able to\nconstruct a new KFC model with 73\\% reduction in total number of parameters,\nwhile the error only rises mildly. In contrast, using low-rank method can only\nachieve 35\\% reduction in total number of parameters given similar quality\ndegradation allowance. If we only compare the KFC layer with its counterpart\nfully-connected layer, the reduction in the number of parameters exceeds 99\\%.\nThe amount of computation is also reduced as we replace matrix product of the\nlarge matrices in FC layers with matrix products of a few smaller matrices in\nKFC layers. Further experiments on MNIST, SVHN and some Chinese Character\nrecognition models also demonstrate effectiveness of our technique. \n\n"}
{"id": "1507.06535", "contents": "Title: Manitest: Are classifiers really invariant? Abstract: Invariance to geometric transformations is a highly desirable property of\nautomatic classifiers in many image recognition tasks. Nevertheless, it is\nunclear to which extent state-of-the-art classifiers are invariant to basic\ntransformations such as rotations and translations. This is mainly due to the\nlack of general methods that properly measure such an invariance. In this\npaper, we propose a rigorous and systematic approach for quantifying the\ninvariance to geometric transformations of any classifier. Our key idea is to\ncast the problem of assessing a classifier's invariance as the computation of\ngeodesics along the manifold of transformed images. We propose the Manitest\nmethod, built on the efficient Fast Marching algorithm to compute the\ninvariance of classifiers. Our new method quantifies in particular the\nimportance of data augmentation for learning invariance from data, and the\nincreased invariance of convolutional neural networks with depth. We foresee\nthat the proposed generic tool for measuring invariance to a large class of\ngeometric transformations and arbitrary classifiers will have many applications\nfor evaluating and comparing classifiers based on their invariance, and help\nimproving the invariance of existing classifiers. \n\n"}
{"id": "1508.00776", "contents": "Title: Online Domain Adaptation for Multi-Object Tracking Abstract: Automatically detecting, labeling, and tracking objects in videos depends\nfirst and foremost on accurate category-level object detectors. These might,\nhowever, not always be available in practice, as acquiring high-quality large\nscale labeled training datasets is either too costly or impractical for all\npossible real-world application scenarios. A scalable solution consists in\nre-using object detectors pre-trained on generic datasets. This work is the\nfirst to investigate the problem of on-line domain adaptation of object\ndetectors for causal multi-object tracking (MOT). We propose to alleviate the\ndataset bias by adapting detectors from category to instances, and back: (i) we\njointly learn all target models by adapting them from the pre-trained one, and\n(ii) we also adapt the pre-trained model on-line. We introduce an on-line\nmulti-task learning algorithm to efficiently share parameters and reduce drift,\nwhile gradually improving recall. Our approach is applicable to any linear\nobject detector, and we evaluate both cheap \"mini-Fisher Vectors\" and expensive\n\"off-the-shelf\" ConvNet features. We quantitatively measure the benefit of our\ndomain adaptation strategy on the KITTI tracking benchmark and on a new dataset\n(PASCAL-to-KITTI) we introduce to study the domain mismatch problem in MOT. \n\n"}
{"id": "1508.01720", "contents": "Title: Mismatch in the Classification of Linear Subspaces: Sufficient\n  Conditions for Reliable Classification Abstract: This paper considers the classification of linear subspaces with mismatched\nclassifiers. In particular, we assume a model where one observes signals in the\npresence of isotropic Gaussian noise and the distribution of the signals\nconditioned on a given class is Gaussian with a zero mean and a low-rank\ncovariance matrix. We also assume that the classifier knows only a mismatched\nversion of the parameters of input distribution in lieu of the true parameters.\nBy constructing an asymptotic low-noise expansion of an upper bound to the\nerror probability of such a mismatched classifier, we provide sufficient\nconditions for reliable classification in the low-noise regime that are able to\nsharply predict the absence of a classification error floor. Such conditions\nare a function of the geometry of the true signal distribution, the geometry of\nthe mismatched signal distributions as well as the interplay between such\ngeometries, namely, the principal angles and the overlap between the true and\nthe mismatched signal subspaces. Numerical results demonstrate that our\nconditions for reliable classification can sharply predict the behavior of a\nmismatched classifier both with synthetic data and in a motion segmentation and\na hand-written digit classification applications. \n\n"}
{"id": "1508.01745", "contents": "Title: Semantically Conditioned LSTM-based Natural Language Generation for\n  Spoken Dialogue Systems Abstract: Natural language generation (NLG) is a critical component of spoken dialogue\nand it has a significant impact both on usability and perceived quality. Most\nNLG systems in common use employ rules and heuristics and tend to generate\nrigid and stylised responses without the natural variation of human language.\nThey are also not easily scaled to systems covering multiple domains and\nlanguages. This paper presents a statistical language generator based on a\nsemantically controlled Long Short-term Memory (LSTM) structure. The LSTM\ngenerator can learn from unaligned data by jointly optimising sentence planning\nand surface realisation using a simple cross entropy training criterion, and\nlanguage variation can be easily achieved by sampling from output candidates.\nWith fewer heuristics, an objective evaluation in two differing test domains\nshowed the proposed method improved performance compared to previous methods.\nHuman judges scored the LSTM system higher on informativeness and naturalness\nand overall preferred it to the other systems. \n\n"}
{"id": "1508.01755", "contents": "Title: Stochastic Language Generation in Dialogue using Recurrent Neural\n  Networks with Convolutional Sentence Reranking Abstract: The natural language generation (NLG) component of a spoken dialogue system\n(SDS) usually needs a substantial amount of handcrafting or a well-labeled\ndataset to be trained on. These limitations add significantly to development\ncosts and make cross-domain, multi-lingual dialogue systems intractable.\nMoreover, human languages are context-aware. The most natural response should\nbe directly learned from data rather than depending on predefined syntaxes or\nrules. This paper presents a statistical language generator based on a joint\nrecurrent and convolutional neural network structure which can be trained on\ndialogue act-utterance pairs without any semantic alignments or predefined\ngrammar trees. Objective metrics suggest that this new model outperforms\nprevious methods under the same experimental conditions. Results of an\nevaluation by human judges indicate that it produces not only high quality but\nlinguistically varied utterances which are preferred compared to n-gram and\nrule-based systems. \n\n"}
{"id": "1509.00111", "contents": "Title: Discovery Radiomics for Multi-Parametric MRI Prostate Cancer Detection Abstract: Prostate cancer is the most diagnosed form of cancer in Canadian men, and is\nthe third leading cause of cancer death. Despite these statistics, prognosis is\nrelatively good with a sufficiently early diagnosis, making fast and reliable\nprostate cancer detection crucial. As imaging-based prostate cancer screening,\nsuch as magnetic resonance imaging (MRI), requires an experienced medical\nprofessional to extensively review the data and perform a diagnosis,\nradiomics-driven methods help streamline the process and has the potential to\nsignificantly improve diagnostic accuracy and efficiency, and thus improving\npatient survival rates. These radiomics-driven methods currently rely on\nhand-crafted sets of quantitative imaging-based features, which are selected\nmanually and can limit their ability to fully characterize unique prostate\ncancer tumour phenotype. In this study, we propose a novel \\textit{discovery\nradiomics} framework for generating custom radiomic sequences tailored for\nprostate cancer detection. Discovery radiomics aims to uncover abstract\nimaging-based features that capture highly unique tumour traits and\ncharacteristics beyond what can be captured using predefined feature models. In\nthis paper, we discover new custom radiomic sequencers for generating new\nprostate radiomic sequences using multi-parametric MRI data. We evaluated the\nperformance of the discovered radiomic sequencer against a state-of-the-art\nhand-crafted radiomic sequencer for computer-aided prostate cancer detection\nwith a feedforward neural network using real clinical prostate multi-parametric\nMRI data. Results for the discovered radiomic sequencer demonstrate good\nperformance in prostate cancer detection and clinical decision support relative\nto the hand-crafted radiomic sequencer. The use of discovery radiomics shows\npotential for more efficient and reliable automatic prostate cancer detection. \n\n"}
{"id": "1509.02130", "contents": "Title: Structured Prediction with Output Embeddings for Semantic Image\n  Annotation Abstract: We address the task of annotating images with semantic tuples. Solving this\nproblem requires an algorithm which is able to deal with hundreds of classes\nfor each argument of the tuple. In such contexts, data sparsity becomes a key\nchallenge, as there will be a large number of classes for which only a few\nexamples are available. We propose handling this by incorporating feature\nrepresentations of both the inputs (images) and outputs (argument classes) into\na factorized log-linear model, and exploiting the flexibility of scoring\nfunctions based on bilinear forms. Experiments show that integrating feature\nrepresentations of the outputs in the structured prediction model leads to\nbetter overall predictions. We also conclude that the best output\nrepresentation is specific for each type of argument. \n\n"}
{"id": "1509.03248", "contents": "Title: A deep matrix factorization method for learning attribute\n  representations Abstract: Semi-Non-negative Matrix Factorization is a technique that learns a\nlow-dimensional representation of a dataset that lends itself to a clustering\ninterpretation. It is possible that the mapping between this new representation\nand our original data matrix contains rather complex hierarchical information\nwith implicit lower-level hidden attributes, that classical one level\nclustering methodologies can not interpret. In this work we propose a novel\nmodel, Deep Semi-NMF, that is able to learn such hidden representations that\nallow themselves to an interpretation of clustering according to different,\nunknown attributes of a given dataset. We also present a semi-supervised\nversion of the algorithm, named Deep WSF, that allows the use of (partial)\nprior information for each of the known attributes of a dataset, that allows\nthe model to be used on datasets with mixed attribute knowledge. Finally, we\nshow that our models are able to learn low-dimensional representations that are\nbetter suited for clustering, but also classification, outperforming\nSemi-Non-negative Matrix Factorization, but also other state-of-the-art\nmethodologies variants. \n\n"}
{"id": "1509.03371", "contents": "Title: Efficient Convolutional Neural Networks for Pixelwise Classification on\n  Heterogeneous Hardware Systems Abstract: This work presents and analyzes three convolutional neural network (CNN)\nmodels for efficient pixelwise classification of images. When using\nconvolutional neural networks to classify single pixels in patches of a whole\nimage, a lot of redundant computations are carried out when using sliding\nwindow networks. This set of new architectures solve this issue by either\nremoving redundant computations or using fully convolutional architectures that\ninherently predict many pixels at once.\n  The implementations of the three models are accessible through a new utility\non top of the Caffe library. The utility provides support for a wide range of\nimage input and output formats, pre-processing parameters and methods to\nequalize the label histogram during training. The Caffe library has been\nextended by new layers and a new backend for availability on a wider range of\nhardware such as CPUs and GPUs through OpenCL.\n  On AMD GPUs, speedups of $54\\times$ (SK-Net), $437\\times$ (U-Net) and\n$320\\times$ (USK-Net) have been observed, taking the SK equivalent SW (sliding\nwindow) network as the baseline. The label throughput is up to one megapixel\nper second.\n  The analyzed neural networks have distinctive characteristics that apply\nduring training or processing, and not every data set is suitable to every\narchitecture. The quality of the predictions is assessed on two neural tissue\ndata sets, of which one is the ISBI 2012 challenge data set. Two different loss\nfunctions, Malis loss and Softmax loss, were used during training.\n  The whole pipeline, consisting of models, interface and modified Caffe\nlibrary, is available as Open Source software under the working title Project\nGreentea. \n\n"}
{"id": "1509.04612", "contents": "Title: Adapting Resilient Propagation for Deep Learning Abstract: The Resilient Propagation (Rprop) algorithm has been very popular for\nbackpropagation training of multilayer feed-forward neural networks in various\napplications. The standard Rprop however encounters difficulties in the context\nof deep neural networks as typically happens with gradient-based learning\nalgorithms. In this paper, we propose a modification of the Rprop that combines\nstandard Rprop steps with a special drop out technique. We apply the method for\ntraining Deep Neural Networks as standalone components and in ensemble\nformulations. Results on the MNIST dataset show that the proposed modification\nalleviates standard Rprop's problems demonstrating improved learning speed and\naccuracy. \n\n"}
{"id": "1509.08038", "contents": "Title: Deep Trans-layer Unsupervised Networks for Representation Learning Abstract: Learning features from massive unlabelled data is a vast prevalent topic for\nhigh-level tasks in many machine learning applications. The recent great\nimprovements on benchmark data sets achieved by increasingly complex\nunsupervised learning methods and deep learning models with lots of parameters\nusually requires many tedious tricks and much expertise to tune. However,\nfilters learned by these complex architectures are quite similar to standard\nhand-crafted features visually. In this paper, unsupervised learning methods,\nsuch as PCA or auto-encoder, are employed as the building block to learn filter\nbanks at each layer. The lower layer responses are transferred to the last\nlayer (trans-layer) to form a more complete representation retaining more\ninformation. In addition, some beneficial methods such as local contrast\nnormalization and whitening are added to the proposed deep trans-layer networks\nto further boost performance. The trans-layer representations are followed by\nblock histograms with binary encoder schema to learn translation and rotation\ninvariant representations, which are utilized to do high-level tasks such as\nrecognition and classification. Compared to traditional deep learning methods,\nthe implemented feature learning method has much less parameters and is\nvalidated in several typical experiments, such as digit recognition on MNIST\nand MNIST variations, object recognition on Caltech 101 dataset and face\nverification on LFW dataset. The deep trans-layer unsupervised learning\nachieves 99.45% accuracy on MNIST dataset, 67.11% accuracy on 15 samples per\nclass and 75.98% accuracy on 30 samples per class on Caltech 101 dataset,\n87.10% on LFW dataset. \n\n"}
{"id": "1510.00143", "contents": "Title: Fast Single Image Super-Resolution Abstract: This paper addresses the problem of single image super-resolution (SR), which\nconsists of recovering a high resolution image from its blurred, decimated and\nnoisy version. The existing algorithms for single image SR use different\nstrategies to handle the decimation and blurring operators. In addition to the\ntraditional first-order gradient methods, recent techniques investigate\nsplitting-based methods dividing the SR problem into up-sampling and\ndeconvolution steps that can be easily solved. Instead of following this\nsplitting strategy, we propose to deal with the decimation and blurring\noperators simultaneously by taking advantage of their particular properties in\nthe frequency domain, leading to a new fast SR approach. Specifically, an\nanalytical solution can be obtained and implemented efficiently for the\nGaussian prior or any other regularization that can be formulated into an\n$\\ell_2$-regularized quadratic model, i.e., an $\\ell_2$-$\\ell_2$ optimization\nproblem. Furthermore, the flexibility of the proposed SR scheme is shown\nthrough the use of various priors/regularizations, ranging from generic image\npriors to learning-based approaches. In the case of non-Gaussian priors, we\nshow how the analytical solution derived from the Gaussian case can be embedded\nintotraditional splitting frameworks, allowing the computation cost of existing\nalgorithms to be decreased significantly. Simulation results conducted on\nseveral images with different priors illustrate the effectiveness of our fast\nSR approach compared with the existing techniques. \n\n"}
{"id": "1510.00259", "contents": "Title: A Generative Model of Words and Relationships from Multiple Sources Abstract: Neural language models are a powerful tool to embed words into semantic\nvector spaces. However, learning such models generally relies on the\navailability of abundant and diverse training examples. In highly specialised\ndomains this requirement may not be met due to difficulties in obtaining a\nlarge corpus, or the limited range of expression in average use. Such domains\nmay encode prior knowledge about entities in a knowledge base or ontology. We\npropose a generative model which integrates evidence from diverse data sources,\nenabling the sharing of semantic information. We achieve this by generalising\nthe concept of co-occurrence from distributional semantics to include other\nrelationships between entities or words, which we model as affine\ntransformations on the embedding space. We demonstrate the effectiveness of\nthis approach by outperforming recent models on a link prediction task and\ndemonstrating its ability to profit from partially or fully unobserved data\ntraining labels. We further demonstrate the usefulness of learning from\ndifferent data sources with overlapping vocabularies. \n\n"}
{"id": "1510.00562", "contents": "Title: Human Action Recognition using Factorized Spatio-Temporal Convolutional\n  Networks Abstract: Human actions in video sequences are three-dimensional (3D) spatio-temporal\nsignals characterizing both the visual appearance and motion dynamics of the\ninvolved humans and objects. Inspired by the success of convolutional neural\nnetworks (CNN) for image classification, recent attempts have been made to\nlearn 3D CNNs for recognizing human actions in videos. However, partly due to\nthe high complexity of training 3D convolution kernels and the need for large\nquantities of training videos, only limited success has been reported. This has\ntriggered us to investigate in this paper a new deep architecture which can\nhandle 3D signals more effectively. Specifically, we propose factorized\nspatio-temporal convolutional networks (FstCN) that factorize the original 3D\nconvolution kernel learning as a sequential process of learning 2D spatial\nkernels in the lower layers (called spatial convolutional layers), followed by\nlearning 1D temporal kernels in the upper layers (called temporal convolutional\nlayers). We introduce a novel transformation and permutation operator to make\nfactorization in FstCN possible. Moreover, to address the issue of sequence\nalignment, we propose an effective training and inference strategy based on\nsampling multiple video clips from a given action video sequence. We have\ntested FstCN on two commonly used benchmark datasets (UCF-101 and HMDB-51).\nWithout using auxiliary training videos to boost the performance, FstCN\noutperforms existing CNN based methods and achieves comparable performance with\na recent method that benefits from using auxiliary training videos. \n\n"}
{"id": "1510.01722", "contents": "Title: Structured Transforms for Small-Footprint Deep Learning Abstract: We consider the task of building compact deep learning pipelines suitable for\ndeployment on storage and power constrained mobile devices. We propose a\nunified framework to learn a broad family of structured parameter matrices that\nare characterized by the notion of low displacement rank. Our structured\ntransforms admit fast function and gradient evaluation, and span a rich range\nof parameter sharing configurations whose statistical modeling capacity can be\nexplicitly tuned along a continuum from structured to unstructured.\nExperimental results show that these transforms can significantly accelerate\ninference and forward/backward passes during training, and offer superior\naccuracy-compactness-speed tradeoffs in comparison to a number of existing\ntechniques. In keyword spotting applications in mobile speech recognition, our\nmethods are much more effective than standard linear low-rank bottleneck layers\nand nearly retain the performance of state of the art models, while providing\nmore than 3.5-fold compression. \n\n"}
{"id": "1510.03753", "contents": "Title: Improved Deep Learning Baselines for Ubuntu Corpus Dialogs Abstract: This paper presents results of our experiments for the next utterance ranking\non the Ubuntu Dialog Corpus -- the largest publicly available multi-turn dialog\ncorpus. First, we use an in-house implementation of previously reported models\nto do an independent evaluation using the same data. Second, we evaluate the\nperformances of various LSTMs, Bi-LSTMs and CNNs on the dataset. Third, we\ncreate an ensemble by averaging predictions of multiple models. The ensemble\nfurther improves the performance and it achieves a state-of-the-art result for\nthe next utterance ranking on this dataset. Finally, we discuss our future\nplans using this corpus. \n\n"}
{"id": "1510.06706", "contents": "Title: ZNN - A Fast and Scalable Algorithm for Training 3D Convolutional\n  Networks on Multi-Core and Many-Core Shared Memory Machines Abstract: Convolutional networks (ConvNets) have become a popular approach to computer\nvision. It is important to accelerate ConvNet training, which is\ncomputationally costly. We propose a novel parallel algorithm based on\ndecomposition into a set of tasks, most of which are convolutions or FFTs.\nApplying Brent's theorem to the task dependency graph implies that linear\nspeedup with the number of processors is attainable within the PRAM model of\nparallel computation, for wide network architectures. To attain such\nperformance on real shared-memory machines, our algorithm computes convolutions\nconverging on the same node of the network with temporal locality to reduce\ncache misses, and sums the convergent convolution outputs via an almost\nwait-free concurrent method to reduce time spent in critical sections. We\nimplement the algorithm with a publicly available software package called ZNN.\nBenchmarking with multi-core CPUs shows that ZNN can attain speedup roughly\nequal to the number of physical cores. We also show that ZNN can attain over\n90x speedup on a many-core CPU (Xeon Phi Knights Corner). These speedups are\nachieved for network architectures with widths that are in common use. The task\nparallelism of the ZNN algorithm is suited to CPUs, while the SIMD parallelism\nof previous algorithms is compatible with GPUs. Through examples, we show that\nZNN can be either faster or slower than certain GPU implementations depending\non specifics of the network architecture, kernel sizes, and density and size of\nthe output patch. ZNN may be less costly to develop and maintain, due to the\nrelative ease of general-purpose CPU programming. \n\n"}
{"id": "1510.08583", "contents": "Title: Privacy Prediction of Images Shared on Social Media Sites Using Deep\n  Features Abstract: Online image sharing in social media sites such as Facebook, Flickr, and\nInstagram can lead to unwanted disclosure and privacy violations, when privacy\nsettings are used inappropriately. With the exponential increase in the number\nof images that are shared online every day, the development of effective and\nefficient prediction methods for image privacy settings are highly needed. The\nperformance of models critically depends on the choice of the feature\nrepresentation. In this paper, we present an approach to image privacy\nprediction that uses deep features and deep image tags as feature\nrepresentations. Specifically, we explore deep features at various neural\nnetwork layers and use the top layer (probability) as an auto-annotation\nmechanism. The results of our experiments show that models trained on the\nproposed deep features and deep image tags substantially outperform baselines\nsuch as those based on SIFT and GIST as well as those that use \"bag of tags\" as\nfeatures. \n\n"}
{"id": "1511.00561", "contents": "Title: SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image\n  Segmentation Abstract: We present a novel and practical deep fully convolutional neural network\narchitecture for semantic pixel-wise segmentation termed SegNet. This core\ntrainable segmentation engine consists of an encoder network, a corresponding\ndecoder network followed by a pixel-wise classification layer. The architecture\nof the encoder network is topologically identical to the 13 convolutional\nlayers in the VGG16 network. The role of the decoder network is to map the low\nresolution encoder feature maps to full input resolution feature maps for\npixel-wise classification. The novelty of SegNet lies is in the manner in which\nthe decoder upsamples its lower resolution input feature map(s). Specifically,\nthe decoder uses pooling indices computed in the max-pooling step of the\ncorresponding encoder to perform non-linear upsampling. This eliminates the\nneed for learning to upsample. The upsampled maps are sparse and are then\nconvolved with trainable filters to produce dense feature maps. We compare our\nproposed architecture with the widely adopted FCN and also with the well known\nDeepLab-LargeFOV, DeconvNet architectures. This comparison reveals the memory\nversus accuracy trade-off involved in achieving good segmentation performance.\n  SegNet was primarily motivated by scene understanding applications. Hence, it\nis designed to be efficient both in terms of memory and computational time\nduring inference. It is also significantly smaller in the number of trainable\nparameters than other competing architectures. We also performed a controlled\nbenchmark of SegNet and other architectures on both road scenes and SUN RGB-D\nindoor scene segmentation tasks. We show that SegNet provides good performance\nwith competitive inference time and more efficient inference memory-wise as\ncompared to other architectures. We also provide a Caffe implementation of\nSegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/. \n\n"}
{"id": "1511.01865", "contents": "Title: Convolutional Neural Network for Stereotypical Motor Movement Detection\n  in Autism Abstract: Autism Spectrum Disorders (ASDs) are often associated with specific atypical\npostural or motor behaviors, of which Stereotypical Motor Movements (SMMs) have\na specific visibility. While the identification and the quantification of SMM\npatterns remain complex, its automation would provide support to accurate\ntuning of the intervention in the therapy of autism. Therefore, it is essential\nto develop automatic SMM detection systems in a real world setting, taking care\nof strong inter-subject and intra-subject variability. Wireless accelerometer\nsensing technology can provide a valid infrastructure for real-time SMM\ndetection, however such variability remains a problem also for machine learning\nmethods, in particular whenever handcrafted features extracted from\naccelerometer signal are considered. Here, we propose to employ the deep\nlearning paradigm in order to learn discriminating features from multi-sensor\naccelerometer signals. Our results provide preliminary evidence that feature\nlearning and transfer learning embedded in the deep architecture achieve higher\naccurate SMM detectors in longitudinal scenarios. \n\n"}
{"id": "1511.03163", "contents": "Title: Semi-supervised Tuning from Temporal Coherence Abstract: Recent works demonstrated the usefulness of temporal coherence to regularize\nsupervised training or to learn invariant features with deep architectures. In\nparticular, enforcing smooth output changes while presenting temporally-closed\nframes from video sequences, proved to be an effective strategy. In this paper\nwe prove the efficacy of temporal coherence for semi-supervised incremental\ntuning. We show that a deep architecture, just mildly trained in a supervised\nmanner, can progressively improve its classification accuracy, if exposed to\nvideo sequences of unlabeled data. The extent to which, in some cases, a\nsemi-supervised tuning allows to improve classification accuracy (approaching\nthe supervised one) is somewhat surprising. A number of control experiments\npointed out the fundamental role of temporal coherence. \n\n"}
{"id": "1511.03339", "contents": "Title: Attention to Scale: Scale-aware Semantic Image Segmentation Abstract: Incorporating multi-scale features in fully convolutional neural networks\n(FCNs) has been a key element to achieving state-of-the-art performance on\nsemantic image segmentation. One common way to extract multi-scale features is\nto feed multiple resized input images to a shared deep network and then merge\nthe resulting features for pixelwise classification. In this work, we propose\nan attention mechanism that learns to softly weight the multi-scale features at\neach pixel location. We adapt a state-of-the-art semantic image segmentation\nmodel, which we jointly train with multi-scale input images and the attention\nmodel. The proposed attention model not only outperforms average- and\nmax-pooling, but allows us to diagnostically visualize the importance of\nfeatures at different positions and scales. Moreover, we show that adding extra\nsupervision to the output at each scale is essential to achieving excellent\nperformance when merging multi-scale features. We demonstrate the effectiveness\nof our model with extensive experiments on three challenging datasets,\nincluding PASCAL-Person-Part, PASCAL VOC 2012 and a subset of MS-COCO 2014. \n\n"}
{"id": "1511.03979", "contents": "Title: Representational Distance Learning for Deep Neural Networks Abstract: Deep neural networks (DNNs) provide useful models of visual representational\ntransformations. We present a method that enables a DNN (student) to learn from\nthe internal representational spaces of a reference model (teacher), which\ncould be another DNN or, in the future, a biological brain. Representational\nspaces of the student and the teacher are characterized by representational\ndistance matrices (RDMs). We propose representational distance learning (RDL),\na stochastic gradient descent method that drives the RDMs of the student to\napproximate the RDMs of the teacher. We demonstrate that RDL is competitive\nwith other transfer learning techniques for two publicly available benchmark\ncomputer vision datasets (MNIST and CIFAR-100), while allowing for\narchitectural differences between student and teacher. By pulling the student's\nRDMs towards those of the teacher, RDL significantly improved visual\nclassification performance when compared to baseline networks that did not use\ntransfer learning. In the future, RDL may enable combined supervised training\nof deep neural networks using task constraints (e.g. images and category\nlabels) and constraints from brain-activity measurements, so as to build models\nthat replicate the internal representational spaces of biological brains. \n\n"}
{"id": "1511.04110", "contents": "Title: Going Deeper in Facial Expression Recognition using Deep Neural Networks Abstract: Automated Facial Expression Recognition (FER) has remained a challenging and\ninteresting problem. Despite efforts made in developing various methods for\nFER, existing approaches traditionally lack generalizability when applied to\nunseen images or those that are captured in wild setting. Most of the existing\napproaches are based on engineered features (e.g. HOG, LBPH, and Gabor) where\nthe classifier's hyperparameters are tuned to give best recognition accuracies\nacross a single database, or a small collection of similar databases.\nNevertheless, the results are not significant when they are applied to novel\ndata. This paper proposes a deep neural network architecture to address the FER\nproblem across multiple well-known standard face datasets. Specifically, our\nnetwork consists of two convolutional layers each followed by max pooling and\nthen four Inception layers. The network is a single component architecture that\ntakes registered facial images as the input and classifies them into either of\nthe six basic or the neutral expressions. We conducted comprehensive\nexperiments on seven publically available facial expression databases, viz.\nMultiPIE, MMI, CK+, DISFA, FERA, SFEW, and FER2013. The results of proposed\narchitecture are comparable to or better than the state-of-the-art methods and\nbetter than traditional convolutional neural networks and in both accuracy and\ntraining time. \n\n"}
{"id": "1511.04510", "contents": "Title: Semantic Object Parsing with Local-Global Long Short-Term Memory Abstract: Semantic object parsing is a fundamental task for understanding objects in\ndetail in computer vision community, where incorporating multi-level contextual\ninformation is critical for achieving such fine-grained pixel-level\nrecognition. Prior methods often leverage the contextual information through\npost-processing predicted confidence maps. In this work, we propose a novel\ndeep Local-Global Long Short-Term Memory (LG-LSTM) architecture to seamlessly\nincorporate short-distance and long-distance spatial dependencies into the\nfeature learning over all pixel positions. In each LG-LSTM layer, local\nguidance from neighboring positions and global guidance from the whole image\nare imposed on each position to better exploit complex local and global\ncontextual information. Individual LSTMs for distinct spatial dimensions are\nalso utilized to intrinsically capture various spatial layouts of semantic\nparts in the images, yielding distinct hidden and memory cells of each position\nfor each dimension. In our parsing approach, several LG-LSTM layers are stacked\nand appended to the intermediate convolutional layers to directly enhance\nvisual features, allowing network parameters to be learned in an end-to-end\nway. The long chains of sequential computation by stacked LG-LSTM layers also\nenable each pixel to sense a much larger region for inference benefiting from\nthe memorization of previous dependencies in all positions along all\ndimensions. Comprehensive evaluations on three public datasets well demonstrate\nthe significant superiority of our LG-LSTM over other state-of-the-art methods. \n\n"}
{"id": "1511.04906", "contents": "Title: Performing Highly Accurate Predictions Through Convolutional Networks\n  for Actual Telecommunication Challenges Abstract: We investigated how the application of deep learning, specifically the use of\nconvolutional networks trained with GPUs, can help to build better predictive\nmodels in telecommunication business environments, and fill this gap. In\nparticular, we focus on the non-trivial problem of predicting customer churn in\ntelecommunication operators. Our model, called WiseNet, consists of a\nconvolutional network and a novel encoding method that transforms customer\nactivity data and Call Detail Records (CDRs) into images. Experimental\nevaluation with several machine learning classifiers supports the ability of\nWiseNet for learning features when using structured input data. For this type\nof telecommunication business problems, we found that WiseNet outperforms\nmachine learning models with hand-crafted features, and does not require the\nlabor-intensive step of feature engineering. Furthermore, the same model has\nbeen applied without retraining to a different market, achieving consistent\nresults. This confirms the generalization property of WiseNet and the ability\nto extract useful representations. \n\n"}
{"id": "1511.06103", "contents": "Title: Principled Parallel Mean-Field Inference for Discrete Random Fields Abstract: Mean-field variational inference is one of the most popular approaches to\ninference in discrete random fields. Standard mean-field optimization is based\non coordinate descent and in many situations can be impractical. Thus, in\npractice, various parallel techniques are used, which either rely on ad-hoc\nsmoothing with heuristically set parameters, or put strong constraints on the\ntype of models. In this paper, we propose a novel proximal gradient-based\napproach to optimizing the variational objective. It is naturally\nparallelizable and easy to implement. We prove its convergence, and then\ndemonstrate that, in practice, it yields faster convergence and often finds\nbetter optima than more traditional mean-field optimization techniques.\nMoreover, our method is less sensitive to the choice of parameters. \n\n"}
{"id": "1511.06297", "contents": "Title: Conditional Computation in Neural Networks for faster models Abstract: Deep learning has become the state-of-art tool in many applications, but the\nevaluation and training of deep models can be time-consuming and\ncomputationally expensive. The conditional computation approach has been\nproposed to tackle this problem (Bengio et al., 2013; Davis & Arel, 2013). It\noperates by selectively activating only parts of the network at a time. In this\npaper, we use reinforcement learning as a tool to optimize conditional\ncomputation policies. More specifically, we cast the problem of learning\nactivation-dependent policies for dropping out blocks of units as a\nreinforcement learning problem. We propose a learning scheme motivated by\ncomputation speed, capturing the idea of wanting to have parsimonious\nactivations while maintaining prediction accuracy. We apply a policy gradient\nalgorithm for learning policies that optimize this loss function and propose a\nregularization mechanism that encourages diversification of the dropout policy.\nWe present encouraging empirical results showing that this approach improves\nthe speed of computation without impacting the quality of the approximation. \n\n"}
{"id": "1511.06448", "contents": "Title: Learning Representations from EEG with Deep Recurrent-Convolutional\n  Neural Networks Abstract: One of the challenges in modeling cognitive events from electroencephalogram\n(EEG) data is finding representations that are invariant to inter- and\nintra-subject differences, as well as to inherent noise associated with such\ndata. Herein, we propose a novel approach for learning such representations\nfrom multi-channel EEG time-series, and demonstrate its advantages in the\ncontext of mental load classification task. First, we transform EEG activities\ninto a sequence of topology-preserving multi-spectral images, as opposed to\nstandard EEG analysis techniques that ignore such spatial information. Next, we\ntrain a deep recurrent-convolutional network inspired by state-of-the-art video\nclassification to learn robust representations from the sequence of images. The\nproposed approach is designed to preserve the spatial, spectral, and temporal\nstructure of EEG which leads to finding features that are less sensitive to\nvariations and distortions within each dimension. Empirical evaluation on the\ncognitive load classification task demonstrated significant improvements in\nclassification accuracy over current state-of-the-art approaches in this field. \n\n"}
{"id": "1511.06586", "contents": "Title: Crowd Behavior Analysis: A Review where Physics meets Biology Abstract: Although the traits emerged in a mass gathering are often non-deliberative,\nthe act of mass impulse may lead to irre- vocable crowd disasters. The two-fold\nincrease of carnage in crowd since the past two decades has spurred significant\nadvances in the field of computer vision, towards effective and proactive crowd\nsurveillance. Computer vision stud- ies related to crowd are observed to\nresonate with the understanding of the emergent behavior in physics (complex\nsystems) and biology (animal swarm). These studies, which are inspired by\nbiology and physics, share surprisingly common insights, and interesting\ncontradictions. However, this aspect of discussion has not been fully explored.\nTherefore, this survey provides the readers with a review of the\nstate-of-the-art methods in crowd behavior analysis from the physics and\nbiologically inspired perspectives. We provide insights and comprehensive\ndiscussions for a broader understanding of the underlying prospect of blending\nphysics and biology studies in computer vision. \n\n"}
{"id": "1511.06951", "contents": "Title: Gradual DropIn of Layers to Train Very Deep Neural Networks Abstract: We introduce the concept of dynamically growing a neural network during\ntraining. In particular, an untrainable deep network starts as a trainable\nshallow network and newly added layers are slowly, organically added during\ntraining, thereby increasing the network's depth. This is accomplished by a new\nlayer, which we call DropIn. The DropIn layer starts by passing the output from\na previous layer (effectively skipping over the newly added layers), then\nincreasingly including units from the new layers for both feedforward and\nbackpropagation. We show that deep networks, which are untrainable with\nconventional methods, will converge with DropIn layers interspersed in the\narchitecture. In addition, we demonstrate that DropIn provides regularization\nduring training in an analogous way as dropout. Experiments are described with\nthe MNIST dataset and various expanded LeNet architectures, CIFAR-10 dataset\nwith its architecture expanded from 3 to 11 layers, and on the ImageNet dataset\nwith the AlexNet architecture expanded to 13 layers and the VGG 16-layer\narchitecture. \n\n"}
{"id": "1511.07111", "contents": "Title: Adapting Deep Visuomotor Representations with Weak Pairwise Constraints Abstract: Real-world robotics problems often occur in domains that differ significantly\nfrom the robot's prior training environment. For many robotic control tasks,\nreal world experience is expensive to obtain, but data is easy to collect in\neither an instrumented environment or in simulation. We propose a novel domain\nadaptation approach for robot perception that adapts visual representations\nlearned on a large easy-to-obtain source dataset (e.g. synthetic images) to a\ntarget real-world domain, without requiring expensive manual data annotation of\nreal world data before policy search. Supervised domain adaptation methods\nminimize cross-domain differences using pairs of aligned images that contain\nthe same object or scene in both the source and target domains, thus learning a\ndomain-invariant representation. However, they require manual alignment of such\nimage pairs. Fully unsupervised adaptation methods rely on minimizing the\ndiscrepancy between the feature distributions across domains. We propose a\nnovel, more powerful combination of both distribution and pairwise image\nalignment, and remove the requirement for expensive annotation by using weakly\naligned pairs of images in the source and target domains. Focusing on adapting\nfrom simulation to real world data using a PR2 robot, we evaluate our approach\non a manipulation task and show that by using weakly paired images, our method\ncompensates for domain shift more effectively than previous techniques,\nenabling better robot performance in the real world. \n\n"}
{"id": "1511.07125", "contents": "Title: What Happened to My Dog in That Network: Unraveling Top-down Generators\n  in Convolutional Neural Networks Abstract: Top-down information plays a central role in human perception, but plays\nrelatively little role in many current state-of-the-art deep networks, such as\nConvolutional Neural Networks (CNNs). This work seeks to explore a path by\nwhich top-down information can have a direct impact within current deep\nnetworks. We explore this path by learning and using \"generators\" corresponding\nto the network internal effects of three types of transformation (each a\nrestriction of a general affine transformation): rotation, scaling, and\ntranslation. We demonstrate how these learned generators can be used to\ntransfer top-down information to novel settings, as mediated by the \"feature\nflows\" that the transformations (and the associated generators) correspond to\ninside the network. Specifically, we explore three aspects: 1) using generators\nas part of a method for synthesizing transformed images --- given a previously\nunseen image, produce versions of that image corresponding to one or more\nspecified transformations, 2) \"zero-shot learning\" --- when provided with a\nfeature flow corresponding to the effect of a transformation of unknown amount,\nleverage learned generators as part of a method by which to perform an accurate\ncategorization of the amount of transformation, even for amounts never observed\nduring training, and 3) (inside-CNN) \"data augmentation\" --- improve the\nclassification performance of an existing network by using the learned\ngenerators to directly provide additional training \"inside the CNN\". \n\n"}
{"id": "1511.07409", "contents": "Title: Top-Down Learning for Structured Labeling with Convolutional Pseudoprior Abstract: Current practice in convolutional neural networks (CNN) remains largely\nbottom-up and the role of top-down process in CNN for pattern analysis and\nvisual inference is not very clear. In this paper, we propose a new method for\nstructured labeling by developing convolutional pseudo-prior (ConvPP) on the\nground-truth labels. Our method has several interesting properties: (1)\ncompared with classical machine learning algorithms like CRFs and Structural\nSVM, ConvPP automatically learns rich convolutional kernels to capture both\nshort- and long- range contexts; (2) compared with cascade classifiers like\nAuto-Context, ConvPP avoids the iterative steps of learning a series of\ndiscriminative classifiers and automatically learns contextual configurations;\n(3) compared with recent efforts combing CNN models with CRFs and RNNs, ConvPP\nlearns convolution in the labeling space with much improved modeling capability\nand less manual specification; (4) compared with Bayesian models like MRFs,\nConvPP capitalizes on the rich representation power of convolution by\nautomatically learning priors built on convolutional filters. We accomplish our\ntask using pseudo-likelihood approximation to the prior under a novel\nfixed-point network structure that facilitates an end-to-end learning process.\nWe show state-of-the-art results on sequential labeling and image labeling\nbenchmarks. \n\n"}
{"id": "1511.07710", "contents": "Title: Searching for Objects using Structure in Indoor Scenes Abstract: To identify the location of objects of a particular class, a passive computer\nvision system generally processes all the regions in an image to finally output\nfew regions. However, we can use structure in the scene to search for objects\nwithout processing the entire image. We propose a search technique that\nsequentially processes image regions such that the regions that are more likely\nto correspond to the query class object are explored earlier. We frame the\nproblem as a Markov decision process and use an imitation learning algorithm to\nlearn a search strategy. Since structure in the scene is essential for search,\nwe work with indoor scene images as they contain both unary scene context\ninformation and object-object context in the scene. We perform experiments on\nthe NYU-depth v2 dataset and show that the unary scene context features alone\ncan achieve a significantly high average precision while processing only\n20-25\\% of the regions for classes like bed and sofa. By considering\nobject-object context along with the scene context features, the performance is\nfurther improved for classes like counter, lamp, pillow and sofa. \n\n"}
{"id": "1511.08458", "contents": "Title: An Introduction to Convolutional Neural Networks Abstract: The field of machine learning has taken a dramatic twist in recent times,\nwith the rise of the Artificial Neural Network (ANN). These biologically\ninspired computational models are able to far exceed the performance of\nprevious forms of artificial intelligence in common machine learning tasks. One\nof the most impressive forms of ANN architecture is that of the Convolutional\nNeural Network (CNN). CNNs are primarily used to solve difficult image-driven\npattern recognition tasks and with their precise yet simple architecture,\noffers a simplified method of getting started with ANNs.\n  This document provides a brief introduction to CNNs, discussing recently\npublished papers and newly formed techniques in developing these brilliantly\nfantastic image recognition models. This introduction assumes you are familiar\nwith the fundamentals of ANNs and machine learning. \n\n"}
{"id": "1512.01979", "contents": "Title: Hyperspectral Chemical Plume Detection Algorithms Based On\n  Multidimensional Iterative Filtering Decomposition Abstract: Chemicals released in the air can be extremely dangerous for human beings and\nthe environment. Hyperspectral images can be used to identify chemical plumes,\nhowever the task can be extremely challenging. Assuming we know a priori that\nsome chemical plume, with a known frequency spectrum, has been photographed\nusing a hyperspectral sensor, we can use standard techniques like the so called\nmatched filter or adaptive cosine estimator, plus a properly chosen threshold\nvalue, to identify the position of the chemical plume. However, due to noise\nand sensors fault, the accurate identification of chemical pixels is not easy\neven in this apparently simple situation. In this paper we present a\npost-processing tool that, in a completely adaptive and data driven fashion,\nallows to improve the performance of any classification methods in identifying\nthe boundaries of a plume. This is done using the Multidimensional Iterative\nFiltering (MIF) algorithm (arXiv:1411.6051, arXiv:1507.07173), which is a\nnon-stationary signal decomposition method like the pioneering Empirical Mode\nDecomposition (EMD) method. Moreover, based on the MIF technique, we propose\nalso a pre-processing method that allows to decorrelate and mean-center a\nhyperspectral dataset. The Cosine Similarity measure, which often fails in\npractice, appears to become a successful and outperforming classifier when\nequipped with such pre-processing method. We show some examples of the proposed\nmethods when applied to real life problems. \n\n"}
{"id": "1512.03385", "contents": "Title: Deep Residual Learning for Image Recognition Abstract: Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation. \n\n"}
{"id": "1512.03929", "contents": "Title: Quantum assisted Gaussian process regression Abstract: Gaussian processes (GP) are a widely used model for regression problems in\nsupervised machine learning. Implementation of GP regression typically requires\n$O(n^3)$ logic gates. We show that the quantum linear systems algorithm [Harrow\net al., Phys. Rev. Lett. 103, 150502 (2009)] can be applied to Gaussian process\nregression (GPR), leading to an exponential reduction in computation time in\nsome instances. We show that even in some cases not ideally suited to the\nquantum linear systems algorithm, a polynomial increase in efficiency still\noccurs. \n\n"}
{"id": "1512.04086", "contents": "Title: Deep Learning-Based Image Kernel for Inductive Transfer Abstract: We propose a method to classify images from target classes with a small\nnumber of training examples based on transfer learning from non-target classes.\nWithout using any more information than class labels for samples from\nnon-target classes, we train a Siamese net to estimate the probability of two\nimages to belong to the same class. With some post-processing, output of the\nSiamese net can be used to form a gram matrix of a Mercer kernel. Coupled with\na support vector machine (SVM), such a kernel gave reasonable classification\naccuracy on target classes without any fine-tuning. When the Siamese net was\nonly partially fine-tuned using a small number of samples from the target\nclasses, the resulting classifier outperformed the state-of-the-art and other\nalternatives. We share class separation capabilities and insights into the\nlearning process of such a kernel on MNIST, Dogs vs. Cats, and CIFAR-10\ndatasets. \n\n"}
{"id": "1512.04295", "contents": "Title: Origami: A 803 GOp/s/W Convolutional Network Accelerator Abstract: An ever increasing number of computer vision and image/video processing\nchallenges are being approached using deep convolutional neural networks,\nobtaining state-of-the-art results in object recognition and detection,\nsemantic segmentation, action recognition, optical flow and superresolution.\nHardware acceleration of these algorithms is essential to adopt these\nimprovements in embedded and mobile computer vision systems. We present a new\narchitecture, design and implementation as well as the first reported silicon\nmeasurements of such an accelerator, outperforming previous work in terms of\npower-, area- and I/O-efficiency. The manufactured device provides up to 196\nGOp/s on 3.09 mm^2 of silicon in UMC 65nm technology and can achieve a power\nefficiency of 803 GOp/s/W. The massively reduced bandwidth requirements make it\nthe first architecture scalable to TOp/s performance. \n\n"}
{"id": "1512.05300", "contents": "Title: Multiregion Bilinear Convolutional Neural Networks for Person\n  Re-Identification Abstract: In this work we propose a new architecture for person re-identification. As\nthe task of re-identification is inherently associated with embedding learning\nand non-rigid appearance description, our architecture is based on the deep\nbilinear convolutional network (Bilinear-CNN) that has been proposed recently\nfor fine-grained classification of highly non-rigid objects. While the last\nstages of the original Bilinear-CNN architecture completely removes the\ngeometric information from consideration by performing orderless pooling, we\nobserve that a better embedding can be learned by performing bilinear pooling\nin a more local way, where each pooling is confined to a predefined region. Our\narchitecture thus represents a compromise between traditional convolutional\nnetworks and bilinear CNNs and strikes a balance between rigid matching and\ncompletely ignoring spatial information.\n  We perform the experimental validation of the new architecture on the three\npopular benchmark datasets (Market-1501, CUHK01, CUHK03), comparing it to\nbaselines that include Bilinear-CNN as well as prior art. The new architecture\noutperforms the baseline on all three datasets, while performing better than\nstate-of-the-art on two out of three. The code and the pretrained models of the\napproach can be found at https://github.com/madkn/MultiregionBilinearCNN-ReId. \n\n"}
{"id": "1512.05430", "contents": "Title: Large Scale Business Discovery from Street Level Imagery Abstract: Search with local intent is becoming increasingly useful due to the\npopularity of the mobile device. The creation and maintenance of accurate\nlistings of local businesses worldwide is time consuming and expensive. In this\npaper, we propose an approach to automatically discover businesses that are\nvisible on street level imagery. Precise business store front detection enables\naccurate geo-location of businesses, and further provides input for business\ncategorization, listing generation, etc. The large variety of business\ncategories in different countries makes this a very challenging problem.\nMoreover, manual annotation is prohibitive due to the scale of this problem. We\npropose the use of a MultiBox based approach that takes input image pixels and\ndirectly outputs store front bounding boxes. This end-to-end learning approach\ninstead preempts the need for hand modeling either the proposal generation\nphase or the post-processing phase, leveraging large labelled training\ndatasets. We demonstrate our approach outperforms the state of the art\ndetection techniques with a large margin in terms of performance and run-time\nefficiency. In the evaluation, we show this approach achieves human accuracy in\nthe low-recall settings. We also provide an end-to-end evaluation of business\ndiscovery in the real world. \n\n"}
{"id": "1512.09272", "contents": "Title: Learning Local Image Descriptors with Deep Siamese and Triplet\n  Convolutional Networks by Minimising Global Loss Functions Abstract: Recent innovations in training deep convolutional neural network (ConvNet)\nmodels have motivated the design of new methods to automatically learn local\nimage descriptors. The latest deep ConvNets proposed for this task consist of a\nsiamese network that is trained by penalising misclassification of pairs of\nlocal image patches. Current results from machine learning show that replacing\nthis siamese by a triplet network can improve the classification accuracy in\nseveral problems, but this has yet to be demonstrated for local image\ndescriptor learning. Moreover, current siamese and triplet networks have been\ntrained with stochastic gradient descent that computes the gradient from\nindividual pairs or triplets of local image patches, which can make them prone\nto overfitting. In this paper, we first propose the use of triplet networks for\nthe problem of local image descriptor learning. Furthermore, we also propose\nthe use of a global loss that minimises the overall classification error in the\ntraining set, which can improve the generalisation capability of the model.\nUsing the UBC benchmark dataset for comparing local image descriptors, we show\nthat the triplet network produces a more accurate embedding than the siamese\nnetwork in terms of the UBC dataset errors. Moreover, we also demonstrate that\na combination of the triplet and global losses produces the best embedding in\nthe field, using this triplet network. Finally, we also show that the use of\nthe central-surround siamese network trained with the global loss produces the\nbest result of the field on the UBC dataset. Pre-trained models are available\nonline at https://github.com/vijaykbg/deep-patchmatch \n\n"}
{"id": "1601.03128", "contents": "Title: Enhancing Energy Minimization Framework for Scene Text Recognition with\n  Top-Down Cues Abstract: Recognizing scene text is a challenging problem, even more so than the\nrecognition of scanned documents. This problem has gained significant attention\nfrom the computer vision community in recent years, and several methods based\non energy minimization frameworks and deep learning approaches have been\nproposed. In this work, we focus on the energy minimization framework and\npropose a model that exploits both bottom-up and top-down cues for recognizing\ncropped words extracted from street images. The bottom-up cues are derived from\nindividual character detections from an image. We build a conditional random\nfield model on these detections to jointly model the strength of the detections\nand the interactions between them. These interactions are top-down cues\nobtained from a lexicon-based prior, i.e., language statistics. The optimal\nword represented by the text image is obtained by minimizing the energy\nfunction corresponding to the random field model. We evaluate our proposed\nalgorithm extensively on a number of cropped scene text benchmark datasets,\nnamely Street View Text, ICDAR 2003, 2011 and 2013 datasets, and IIIT 5K-word,\nand show better performance than comparable methods. We perform a rigorous\nanalysis of all the steps in our approach and analyze the results. We also show\nthat state-of-the-art convolutional neural network features can be integrated\nin our framework to further improve the recognition performance. \n\n"}
{"id": "1601.04155", "contents": "Title: Brain-Inspired Deep Networks for Image Aesthetics Assessment Abstract: Image aesthetics assessment has been challenging due to its subjective\nnature. Inspired by the scientific advances in the human visual perception and\nneuroaesthetics, we design Brain-Inspired Deep Networks (BDN) for this task.\nBDN first learns attributes through the parallel supervised pathways, on a\nvariety of selected feature dimensions. A high-level synthesis network is\ntrained to associate and transform those attributes into the overall aesthetics\nrating. We then extend BDN to predicting the distribution of human ratings,\nsince aesthetics ratings are often subjective. Another highlight is our\nfirst-of-its-kind study of label-preserving transformations in the context of\naesthetics assessment, which leads to an effective data augmentation approach.\nExperimental results on the AVA dataset show that our biological inspired and\ntask-specific BDN model gains significantly performance improvement, compared\nto other state-of-the-art models with the same or higher parameter capacity. \n\n"}
{"id": "1601.06403", "contents": "Title: Synthesis of Gaussian Trees with Correlation Sign Ambiguity: An\n  Information Theoretic Approach Abstract: In latent Gaussian trees the pairwise correlation signs between the variables\nare intrinsically unrecoverable. Such information is vital since it completely\ndetermines the direction in which two variables are associated. In this work,\nwe resort to information theoretical approaches to achieve two fundamental\ngoals: First, we quantify the amount of information loss due to unrecoverable\nsign information. Second, we show the importance of such information in\ndetermining the maximum achievable rate region, in which the observed output\nvector can be synthesized, given its probability density function. In\nparticular, we model the graphical model as a communication channel and propose\na new layered encoding framework to synthesize observed data using upper layer\nGaussian inputs and independent Bernoulli correlation sign inputs from each\nlayer. We find the achievable rate region for the rate tuples of multi-layer\nlatent Gaussian messages to synthesize the desired observables. \n\n"}
{"id": "1602.01895", "contents": "Title: Generate Image Descriptions based on Deep RNN and Memory Cells for\n  Images Features Abstract: Generating natural language descriptions for images is a challenging task.\nThe traditional way is to use the convolutional neural network (CNN) to extract\nimage features, followed by recurrent neural network (RNN) to generate\nsentences. In this paper, we present a new model that added memory cells to\ngate the feeding of image features to the deep neural network. The intuition is\nenabling our model to memorize how much information from images should be fed\nat each stage of the RNN. Experiments on Flickr8K and Flickr30K datasets showed\nthat our model outperforms other state-of-the-art models with higher BLEU\nscores. \n\n"}
{"id": "1602.01921", "contents": "Title: Recognition of Visually Perceived Compositional Human Actions by\n  Multiple Spatio-Temporal Scales Recurrent Neural Networks Abstract: The current paper proposes a novel neural network model for recognizing\nvisually perceived human actions. The proposed multiple spatio-temporal scales\nrecurrent neural network (MSTRNN) model is derived by introducing multiple\ntimescale recurrent dynamics to the conventional convolutional neural network\nmodel. One of the essential characteristics of the MSTRNN is that its\narchitecture imposes both spatial and temporal constraints simultaneously on\nthe neural activity which vary in multiple scales among different layers. As\nsuggested by the principle of the upward and downward causation, it is assumed\nthat the network can develop meaningful structures such as functional hierarchy\nby taking advantage of such constraints during the course of learning. To\nevaluate the characteristics of the model, the current study uses three types\nof human action video dataset consisting of different types of primitive\nactions and different levels of compositionality on them. The performance of\nthe MSTRNN in testing with these dataset is compared with the ones by other\nrepresentative deep learning models used in the field. The analysis of the\ninternal representation obtained through the learning with the dataset\nclarifies what sorts of functional hierarchy can be developed by extracting the\nessential compositionality underlying the dataset. \n\n"}
{"id": "1602.02172", "contents": "Title: On Column Selection in Approximate Kernel Canonical Correlation Analysis Abstract: We study the problem of column selection in large-scale kernel canonical\ncorrelation analysis (KCCA) using the Nystr\\\"om approximation, where one\napproximates two positive semi-definite kernel matrices using \"landmark\" points\nfrom the training set. When building low-rank kernel approximations in KCCA,\nprevious work mostly samples the landmarks uniformly at random from the\ntraining set. We propose novel strategies for sampling the landmarks\nnon-uniformly based on a version of statistical leverage scores recently\ndeveloped for kernel ridge regression. We study the approximation accuracy of\nthe proposed non-uniform sampling strategy, develop an incremental algorithm\nthat explores the path of approximation ranks and facilitates efficient model\nselection, and derive the kernel stability of out-of-sample mapping for our\nmethod. Experimental results on both synthetic and real-world datasets\ndemonstrate the promise of our method. \n\n"}
{"id": "1602.03616", "contents": "Title: Multifaceted Feature Visualization: Uncovering the Different Types of\n  Features Learned By Each Neuron in Deep Neural Networks Abstract: We can better understand deep neural networks by identifying which features\neach of their neurons have learned to detect. To do so, researchers have\ncreated Deep Visualization techniques including activation maximization, which\nsynthetically generates inputs (e.g. images) that maximally activate each\nneuron. A limitation of current techniques is that they assume each neuron\ndetects only one type of feature, but we know that neurons can be multifaceted,\nin that they fire in response to many different types of features: for example,\na grocery store class neuron must activate either for rows of produce or for a\nstorefront. Previous activation maximization techniques constructed images\nwithout regard for the multiple different facets of a neuron, creating\ninappropriate mixes of colors, parts of objects, scales, orientations, etc.\nHere, we introduce an algorithm that explicitly uncovers the multiple facets of\neach neuron by producing a synthetic visualization of each of the types of\nimages that activate a neuron. We also introduce regularization methods that\nproduce state-of-the-art results in terms of the interpretability of images\nobtained by activation maximization. By separately synthesizing each type of\nimage a neuron fires in response to, the visualizations have more appropriate\ncolors and coherent global structure. Multifaceted feature visualization thus\nprovides a clearer and more comprehensive description of the role of each\nneuron. \n\n"}
{"id": "1602.04105", "contents": "Title: Convolutional Radio Modulation Recognition Networks Abstract: We study the adaptation of convolutional neural networks to the complex\ntemporal radio signal domain. We compare the efficacy of radio modulation\nclassification using naively learned features against using expert features\nwhich are widely used in the field today and we show significant performance\nimprovements. We show that blind temporal learning on large and densely encoded\ntime series using deep convolutional neural networks is viable and a strong\ncandidate approach for this task especially at low signal to noise ratio. \n\n"}
{"id": "1602.04589", "contents": "Title: Optimal Best Arm Identification with Fixed Confidence Abstract: We give a complete characterization of the complexity of best-arm\nidentification in one-parameter bandit problems. We prove a new, tight lower\nbound on the sample complexity. We propose the `Track-and-Stop' strategy, which\nwe prove to be asymptotically optimal. It consists in a new sampling rule\n(which tracks the optimal proportions of arm draws highlighted by the lower\nbound) and in a stopping rule named after Chernoff, for which we give a new\nanalysis. \n\n"}
{"id": "1602.04799", "contents": "Title: Quantum Perceptron Models Abstract: We demonstrate how quantum computation can provide non-trivial improvements\nin the computational and statistical complexity of the perceptron model. We\ndevelop two quantum algorithms for perceptron learning. The first algorithm\nexploits quantum information processing to determine a separating hyperplane\nusing a number of steps sublinear in the number of data points $N$, namely\n$O(\\sqrt{N})$. The second algorithm illustrates how the classical mistake bound\nof $O(\\frac{1}{\\gamma^2})$ can be further improved to\n$O(\\frac{1}{\\sqrt{\\gamma}})$ through quantum means, where $\\gamma$ denotes the\nmargin. Such improvements are achieved through the application of quantum\namplitude amplification to the version space interpretation of the perceptron\nmodel. \n\n"}
{"id": "1602.04951", "contents": "Title: Q($\\lambda$) with Off-Policy Corrections Abstract: We propose and analyze an alternate approach to off-policy multi-step\ntemporal difference learning, in which off-policy returns are corrected with\nthe current Q-function in terms of rewards, rather than with the target policy\nin terms of transition probabilities. We prove that such approximate\ncorrections are sufficient for off-policy convergence both in policy evaluation\nand control, provided certain conditions. These conditions relate the distance\nbetween the target and behavior policies, the eligibility trace parameter and\nthe discount factor, and formalize an underlying tradeoff in off-policy\nTD($\\lambda$). We illustrate this theoretical relationship empirically on a\ncontinuous-state control task. \n\n"}
{"id": "1602.07360", "contents": "Title: SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB\n  model size Abstract: Recent research on deep neural networks has focused primarily on improving\naccuracy. For a given accuracy level, it is typically possible to identify\nmultiple DNN architectures that achieve that accuracy level. With equivalent\naccuracy, smaller DNN architectures offer at least three advantages: (1)\nSmaller DNNs require less communication across servers during distributed\ntraining. (2) Smaller DNNs require less bandwidth to export a new model from\nthe cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on\nFPGAs and other hardware with limited memory. To provide all of these\nadvantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet\nachieves AlexNet-level accuracy on ImageNet with 50x fewer parameters.\nAdditionally, with model compression techniques we are able to compress\nSqueezeNet to less than 0.5MB (510x smaller than AlexNet).\n  The SqueezeNet architecture is available for download here:\nhttps://github.com/DeepScale/SqueezeNet \n\n"}
{"id": "1602.07373", "contents": "Title: On Study of the Binarized Deep Neural Network for Image Classification Abstract: Recently, the deep neural network (derived from the artificial neural\nnetwork) has attracted many researchers' attention by its outstanding\nperformance. However, since this network requires high-performance GPUs and\nlarge storage, it is very hard to use it on individual devices. In order to\nimprove the deep neural network, many trials have been made by refining the\nnetwork structure or training strategy. Unlike those trials, in this paper, we\nfocused on the basic propagation function of the artificial neural network and\nproposed the binarized deep neural network. This network is a pure binary\nsystem, in which all the values and calculations are binarized. As a result,\nour network can save a lot of computational resource and storage. Therefore, it\nis possible to use it on various devices. Moreover, the experimental results\nproved the feasibility of the proposed network. \n\n"}
{"id": "1602.08886", "contents": "Title: Collaborative Learning of Stochastic Bandits over a Social Network Abstract: We consider a collaborative online learning paradigm, wherein a group of\nagents connected through a social network are engaged in playing a stochastic\nmulti-armed bandit game. Each time an agent takes an action, the corresponding\nreward is instantaneously observed by the agent, as well as its neighbours in\nthe social network. We perform a regret analysis of various policies in this\ncollaborative learning setting. A key finding of this paper is that natural\nextensions of widely-studied single agent learning policies to the network\nsetting need not perform well in terms of regret. In particular, we identify a\nclass of non-altruistic and individually consistent policies, and argue by\nderiving regret lower bounds that they are liable to suffer a large regret in\nthe networked setting. We also show that the learning performance can be\nsubstantially improved if the agents exploit the structure of the network, and\ndevelop a simple learning algorithm based on dominating sets of the network.\nSpecifically, we first consider a star network, which is a common motif in\nhierarchical social networks, and show analytically that the hub agent can be\nused as an information sink to expedite learning and improve the overall\nregret. We also derive networkwide regret bounds for the algorithm applied to\ngeneral networks. We conduct numerical experiments on a variety of networks to\ncorroborate our analytical results. \n\n"}
{"id": "1603.02199", "contents": "Title: Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning\n  and Large-Scale Data Collection Abstract: We describe a learning-based approach to hand-eye coordination for robotic\ngrasping from monocular images. To learn hand-eye coordination for grasping, we\ntrained a large convolutional neural network to predict the probability that\ntask-space motion of the gripper will result in successful grasps, using only\nmonocular camera images and independently of camera calibration or the current\nrobot pose. This requires the network to observe the spatial relationship\nbetween the gripper and objects in the scene, thus learning hand-eye\ncoordination. We then use this network to servo the gripper in real time to\nachieve successful grasps. To train our network, we collected over 800,000\ngrasp attempts over the course of two months, using between 6 and 14 robotic\nmanipulators at any given time, with differences in camera placement and\nhardware. Our experimental evaluation demonstrates that our method achieves\neffective real-time control, can successfully grasp novel objects, and corrects\nmistakes by continuous servoing. \n\n"}
{"id": "1603.02200", "contents": "Title: Elastic Functional Coding of Riemannian Trajectories Abstract: Visual observations of dynamic phenomena, such as human actions, are often\nrepresented as sequences of smoothly-varying features . In cases where the\nfeature spaces can be structured as Riemannian manifolds, the corresponding\nrepresentations become trajectories on manifolds. Analysis of these\ntrajectories is challenging due to non-linearity of underlying spaces and\nhigh-dimensionality of trajectories. In vision problems, given the nature of\nphysical systems involved, these phenomena are better characterized on a\nlow-dimensional manifold compared to the space of Riemannian trajectories. For\ninstance, if one does not impose physical constraints of the human body, in\ndata involving human action analysis, the resulting representation space will\nhave highly redundant features. Learning an effective, low-dimensional\nembedding for action representations will have a huge impact in the areas of\nsearch and retrieval, visualization, learning, and recognition. The difficulty\nlies in inherent non-linearity of the domain and temporal variability of\nactions that can distort any traditional metric between trajectories. To\novercome these issues, we use the framework based on transported square-root\nvelocity fields (TSRVF); this framework has several desirable properties,\nincluding a rate-invariant metric and vector space representations. We propose\nto learn an embedding such that each action trajectory is mapped to a single\npoint in a low-dimensional Euclidean space, and the trajectories that differ\nonly in temporal rates map to the same point. We utilize the TSRVF\nrepresentation, and accompanying statistical summaries of Riemannian\ntrajectories, to extend existing coding methods such as PCA, KSVD and Label\nConsistent KSVD to Riemannian trajectories or more generally to Riemannian\nfunctions. \n\n"}
{"id": "1603.04136", "contents": "Title: On the Influence of Momentum Acceleration on Online Learning Abstract: The article examines in some detail the convergence rate and\nmean-square-error performance of momentum stochastic gradient methods in the\nconstant step-size and slow adaptation regime. The results establish that\nmomentum methods are equivalent to the standard stochastic gradient method with\na re-scaled (larger) step-size value. The size of the re-scaling is determined\nby the value of the momentum parameter. The equivalence result is established\nfor all time instants and not only in steady-state. The analysis is carried out\nfor general strongly convex and smooth risk functions, and is not limited to\nquadratic risks. One notable conclusion is that the well-known bene ts of\nmomentum constructions for deterministic optimization problems do not\nnecessarily carry over to the adaptive online setting when small constant\nstep-sizes are used to enable continuous adaptation and learn- ing in the\npresence of persistent gradient noise. From simulations, the equivalence\nbetween momentum and standard stochastic gradient methods is also observed for\nnon-differentiable and non-convex problems. \n\n"}
{"id": "1603.04981", "contents": "Title: An Approximate Dynamic Programming Approach to Adversarial Online\n  Learning Abstract: We describe an approximate dynamic programming (ADP) approach to compute\napproximations of the optimal strategies and of the minimal losses that can be\nguaranteed in discounted repeated games with vector-valued losses. Such games\nprominently arise in the analysis of regret in repeated decision-making in\nadversarial environments, also known as adversarial online learning. At the\ncore of our approach is a characterization of the lower Pareto frontier of the\nset of expected losses that a player can guarantee in these games as the unique\nfixed point of a set-valued dynamic programming operator. When applied to the\nproblem of regret minimization with discounted losses, our approach yields\nalgorithms that achieve markedly improved performance bounds compared to\noff-the-shelf online learning algorithms like Hedge. These results thus suggest\nthe significant potential of ADP-based approaches in adversarial online\nlearning. \n\n"}
{"id": "1603.05145", "contents": "Title: Suppressing the Unusual: towards Robust CNNs using Symmetric Activation\n  Functions Abstract: Many deep Convolutional Neural Networks (CNN) make incorrect predictions on\nadversarial samples obtained by imperceptible perturbations of clean samples.\nWe hypothesize that this is caused by a failure to suppress unusual signals\nwithin network layers. As remedy we propose the use of Symmetric Activation\nFunctions (SAF) in non-linear signal transducer units. These units suppress\nsignals of exceptional magnitude. We prove that SAF networks can perform\nclassification tasks to arbitrary precision in a simplified situation. In\npractice, rather than use SAFs alone, we add them into CNNs to improve their\nrobustness. The modified CNNs can be easily trained using popular strategies\nwith the moderate training load. Our experiments on MNIST and CIFAR-10 show\nthat the modified CNNs perform similarly to plain ones on clean samples, and\nare remarkably more robust against adversarial and nonsense samples. \n\n"}
{"id": "1603.05955", "contents": "Title: Transferring Learned Microcalcification Group Detection from 2D\n  Mammography to 3D Digital Breast Tomosynthesis Using a Hierarchical Model and\n  Scope-based Normalization Features Abstract: A novel hierarchical model is introduced to solve a general problem of\ndetecting groups of similar objects. Under this model, detection of groups is\nperformed in hierarchically organized layers while each layer represents a\nscope for target objects. The processing of these layers involves sequential\nextraction of appearance features for an individual object, consistency\nmeasurement features for nearby objects, and finally the distribution features\nfor all objects within the group. Using the concept of scope-based\nnormalization, the extracted features not only enhance local contrast of an\nindividual object, but also provide consistent characterization for all related\nobjects. As an example, a microcalcification group detection system for 2D\nmammography was developed, and then the learned model was transferred to 3D\ndigital breast tomosynthesis without any retraining or fine-tuning. The\ndetection system demonstrated state-of-the-art performance and detected 96% of\ncancerous lesions at the rate of 1.2 false positives per volume as measured on\nan independent tomosynthesis test set. \n\n"}
{"id": "1603.06127", "contents": "Title: Sentence Pair Scoring: Towards Unified Framework for Text Comprehension Abstract: We review the task of Sentence Pair Scoring, popular in the literature in\nvarious forms - viewed as Answer Sentence Selection, Semantic Text Scoring,\nNext Utterance Ranking, Recognizing Textual Entailment, Paraphrasing or e.g. a\ncomponent of Memory Networks.\n  We argue that all such tasks are similar from the model perspective and\npropose new baselines by comparing the performance of common IR metrics and\npopular convolutional, recurrent and attention-based neural models across many\nSentence Pair Scoring tasks and datasets. We discuss the problem of evaluating\nrandomized models, propose a statistically grounded methodology, and attempt to\nimprove comparisons by releasing new datasets that are much harder than some of\nthe currently used well explored benchmarks. We introduce a unified open source\nsoftware framework with easily pluggable models and tasks, which enables us to\nexperiment with multi-task reusability of trained sentence model. We set a new\nstate-of-art in performance on the Ubuntu Dialogue dataset. \n\n"}
{"id": "1603.07235", "contents": "Title: Global-Local Face Upsampling Network Abstract: Face hallucination, which is the task of generating a high-resolution face\nimage from a low-resolution input image, is a well-studied problem that is\nuseful in widespread application areas. Face hallucination is particularly\nchallenging when the input face resolution is very low (e.g., 10 x 12 pixels)\nand/or the image is captured in an uncontrolled setting with large pose and\nillumination variations. In this paper, we revisit the algorithm introduced in\n[1] and present a deep interpretation of this framework that achieves\nstate-of-the-art under such challenging scenarios. In our deep network\narchitecture the global and local constraints that define a face can be\nefficiently modeled and learned end-to-end using training data. Conceptually\nour network design can be partitioned into two sub-networks: the first one\nimplements the holistic face reconstruction according to global constraints,\nand the second one enhances face-specific details and enforces local patch\nstatistics. We optimize the deep network using a new loss function for\nsuper-resolution that combines reconstruction error with a learned face quality\nmeasure in adversarial setting, producing improved visual results. We conduct\nextensive experiments in both controlled and uncontrolled setups and show that\nour algorithm improves the state of the art both numerically and visually. \n\n"}
{"id": "1603.07763", "contents": "Title: Seeing Invisible Poses: Estimating 3D Body Pose from Egocentric Video Abstract: Understanding the camera wearer's activity is central to egocentric vision,\nyet one key facet of that activity is inherently invisible to the camera--the\nwearer's body pose. Prior work focuses on estimating the pose of hands and arms\nwhen they come into view, but this 1) gives an incomplete view of the full body\nposture, and 2) prevents any pose estimate at all in many frames, since the\nhands are only visible in a fraction of daily life activities. We propose to\ninfer the \"invisible pose\" of a person behind the egocentric camera. Given a\nsingle video, our efficient learning-based approach returns the full body 3D\njoint positions for each frame. Our method exploits cues from the dynamic\nmotion signatures of the surrounding scene--which changes predictably as a\nfunction of body pose--as well as static scene structures that reveal the\nviewpoint (e.g., sitting vs. standing). We further introduce a novel energy\nminimization scheme to infer the pose sequence. It uses soft predictions of the\nposes per time instant together with a non-parametric model of human pose\ndynamics over longer windows. Our method outperforms an array of possible\nalternatives, including deep learning approaches for direct pose regression\nfrom images. \n\n"}
{"id": "1603.07810", "contents": "Title: Conditional Similarity Networks Abstract: What makes images similar? To measure the similarity between images, they are\ntypically embedded in a feature-vector space, in which their distance preserve\nthe relative dissimilarity. However, when learning such similarity embeddings\nthe simplifying assumption is commonly made that images are only compared to\none unique measure of similarity. A main reason for this is that contradicting\nnotions of similarities cannot be captured in a single space. To address this\nshortcoming, we propose Conditional Similarity Networks (CSNs) that learn\nembeddings differentiated into semantically distinct subspaces that capture the\ndifferent notions of similarities. CSNs jointly learn a disentangled embedding\nwhere features for different similarities are encoded in separate dimensions as\nwell as masks that select and reweight relevant dimensions to induce a subspace\nthat encodes a specific similarity notion. We show that our approach learns\ninterpretable image representations with visually relevant semantic subspaces.\nFurther, when evaluating on triplet questions from multiple similarity notions\nour model even outperforms the accuracy obtained by training individual\nspecialized networks for each notion separately. \n\n"}
{"id": "1603.07965", "contents": "Title: Unsupervised Category Discovery via Looped Deep Pseudo-Task Optimization\n  Using a Large Scale Radiology Image Database Abstract: Obtaining semantic labels on a large scale radiology image database (215,786\nkey images from 61,845 unique patients) is a prerequisite yet bottleneck to\ntrain highly effective deep convolutional neural network (CNN) models for image\nrecognition. Nevertheless, conventional methods for collecting image labels\n(e.g., Google search followed by crowd-sourcing) are not applicable due to the\nformidable difficulties of medical annotation tasks for those who are not\nclinically trained. This type of image labeling task remains non-trivial even\nfor radiologists due to uncertainty and possible drastic inter-observer\nvariation or inconsistency.\n  In this paper, we present a looped deep pseudo-task optimization procedure\nfor automatic category discovery of visually coherent and clinically semantic\n(concept) clusters. Our system can be initialized by domain-specific (CNN\ntrained on radiology images and text report derived labels) or generic\n(ImageNet based) CNN models. Afterwards, a sequence of pseudo-tasks are\nexploited by the looped deep image feature clustering (to refine image labels)\nand deep CNN training/classification using new labels (to obtain more task\nrepresentative deep features). Our method is conceptually simple and based on\nthe hypothesized \"convergence\" of better labels leading to better trained CNN\nmodels which in turn feed more effective deep image features to facilitate more\nmeaningful clustering/labels. We have empirically validated the convergence and\ndemonstrated promising quantitative and qualitative results. Category labels of\nsignificantly higher quality than those in previous work are discovered. This\nallows for further investigation of the hierarchical semantic nature of the\ngiven large-scale radiology image database. \n\n"}
{"id": "1603.08029", "contents": "Title: Resnet in Resnet: Generalizing Residual Architectures Abstract: Residual networks (ResNets) have recently achieved state-of-the-art on\nchallenging computer vision tasks. We introduce Resnet in Resnet (RiR): a deep\ndual-stream architecture that generalizes ResNets and standard CNNs and is\neasily implemented with no computational overhead. RiR consistently improves\nperformance over ResNets, outperforms architectures with similar amounts of\naugmentation on CIFAR-10, and establishes a new state-of-the-art on CIFAR-100. \n\n"}
{"id": "1603.08079", "contents": "Title: Do You See What I Mean? Visual Resolution of Linguistic Ambiguities Abstract: Understanding language goes hand in hand with the ability to integrate\ncomplex contextual information obtained via perception. In this work, we\npresent a novel task for grounded language understanding: disambiguating a\nsentence given a visual scene which depicts one of the possible interpretations\nof that sentence. To this end, we introduce a new multimodal corpus containing\nambiguous sentences, representing a wide range of syntactic, semantic and\ndiscourse ambiguities, coupled with videos that visualize the different\ninterpretations for each sentence. We address this task by extending a vision\nmodel which determines if a sentence is depicted by a video. We demonstrate how\nsuch a model can be adjusted to recognize different interpretations of the same\nunderlying sentence, allowing to disambiguate sentences in a unified fashion\nacross the different ambiguity types. \n\n"}
{"id": "1603.08637", "contents": "Title: Learning a Predictable and Generative Vector Representation for Objects Abstract: What is a good vector representation of an object? We believe that it should\nbe generative in 3D, in the sense that it can produce new 3D objects; as well\nas be predictable from 2D, in the sense that it can be perceived from 2D\nimages. We propose a novel architecture, called the TL-embedding network, to\nlearn an embedding space with these properties. The network consists of two\ncomponents: (a) an autoencoder that ensures the representation is generative;\nand (b) a convolutional network that ensures the representation is predictable.\nThis enables tackling a number of tasks including voxel prediction from 2D\nimages and 3D model retrieval. Extensive experimental analysis demonstrates the\nusefulness and versatility of this embedding. \n\n"}
{"id": "1603.09056", "contents": "Title: Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks\n  with Symmetric Skip Connections Abstract: In this paper, we propose a very deep fully convolutional encoding-decoding\nframework for image restoration such as denoising and super-resolution. The\nnetwork is composed of multiple layers of convolution and de-convolution\noperators, learning end-to-end mappings from corrupted images to the original\nones. The convolutional layers act as the feature extractor, which capture the\nabstraction of image contents while eliminating noises/corruptions.\nDe-convolutional layers are then used to recover the image details. We propose\nto symmetrically link convolutional and de-convolutional layers with skip-layer\nconnections, with which the training converges much faster and attains a\nhigher-quality local optimum. First, The skip connections allow the signal to\nbe back-propagated to bottom layers directly, and thus tackles the problem of\ngradient vanishing, making training deep networks easier and achieving\nrestoration performance gains consequently. Second, these skip connections pass\nimage details from convolutional layers to de-convolutional layers, which is\nbeneficial in recovering the original image. Significantly, with the large\ncapacity, we can handle different levels of noises using a single model.\nExperimental results show that our network achieves better performance than all\npreviously reported state-of-the-art methods. \n\n"}
{"id": "1603.09128", "contents": "Title: Bilingual Learning of Multi-sense Embeddings with Discrete Autoencoders Abstract: We present an approach to learning multi-sense word embeddings relying both\non monolingual and bilingual information. Our model consists of an encoder,\nwhich uses monolingual and bilingual context (i.e. a parallel sentence) to\nchoose a sense for a given word, and a decoder which predicts context words\nbased on the chosen sense. The two components are estimated jointly. We observe\nthat the word representations induced from bilingual data outperform the\nmonolingual counterparts across a range of evaluation tasks, even though\ncrosslingual information is not available at test time. \n\n"}
{"id": "1604.00092", "contents": "Title: Variational reaction-diffusion systems for semantic segmentation Abstract: A novel global energy model for multi-class semantic image segmentation is\nproposed that admits very efficient exact inference and derivative calculations\nfor learning. Inference in this model is equivalent to MAP inference in a\nparticular kind of vector-valued Gaussian Markov random field, and ultimately\nreduces to solving a linear system of linear PDEs known as a reaction-diffusion\nsystem. Solving this system can be achieved in time scaling near-linearly in\nthe number of image pixels by reducing it to sequential FFTs, after a linear\nchange of basis. The efficiency and differentiability of the model make it\nespecially well-suited for integration with convolutional neural networks, even\nallowing it to be used in interior, feature-generating layers and stacked\nmultiple times. Experimental results are shown demonstrating that the model can\nbe employed profitably in conjunction with different convolutional net\narchitectures, and that doing so compares favorably to joint training of a\nfully-connected CRF with a convolutional net. \n\n"}
{"id": "1604.00289", "contents": "Title: Building Machines That Learn and Think Like People Abstract: Recent progress in artificial intelligence (AI) has renewed interest in\nbuilding systems that learn and think like people. Many advances have come from\nusing deep neural networks trained end-to-end in tasks such as object\nrecognition, video games, and board games, achieving performance that equals or\neven beats humans in some respects. Despite their biological inspiration and\nperformance achievements, these systems differ from human intelligence in\ncrucial ways. We review progress in cognitive science suggesting that truly\nhuman-like learning and thinking machines will have to reach beyond current\nengineering trends in both what they learn, and how they learn it.\nSpecifically, we argue that these machines should (a) build causal models of\nthe world that support explanation and understanding, rather than merely\nsolving pattern recognition problems; (b) ground learning in intuitive theories\nof physics and psychology, to support and enrich the knowledge that is learned;\nand (c) harness compositionality and learning-to-learn to rapidly acquire and\ngeneralize knowledge to new tasks and situations. We suggest concrete\nchallenges and promising routes towards these goals that can combine the\nstrengths of recent neural network advances with more structured cognitive\nmodels. \n\n"}
{"id": "1604.02275", "contents": "Title: Online Open World Recognition Abstract: As we enter into the big data age and an avalanche of images have become\nreadily available, recognition systems face the need to move from close, lab\nsettings where the number of classes and training data are fixed, to dynamic\nscenarios where the number of categories to be recognized grows continuously\nover time, as well as new data providing useful information to update the\nsystem. Recent attempts, like the open world recognition framework, tried to\ninject dynamics into the system by detecting new unknown classes and adding\nthem incrementally, while at the same time continuously updating the models for\nthe known classes. incrementally adding new classes and detecting instances\nfrom unknown classes, while at the same time continuously updating the models\nfor the known classes. In this paper we argue that to properly capture the\nintrinsic dynamic of open world recognition, it is necessary to add to these\naspects (a) the incremental learning of the underlying metric, (b) the\nincremental estimate of confidence thresholds for the unknown classes, and (c)\nthe use of local learning to precisely describe the space of classes. We extend\nthree existing metric learning algorithms towards these goals by using online\nmetric learning. Experimentally we validate our approach on two large-scale\ndatasets in different learning scenarios. For all these scenarios our proposed\nmethods outperform their non-online counterparts. We conclude that local and\nonline learning is important to capture the full dynamics of open world\nrecognition. \n\n"}
{"id": "1604.02715", "contents": "Title: Soccer Field Localization from a Single Image Abstract: In this work, we propose a novel way of efficiently localizing a soccer field\nfrom a single broadcast image of the game. Related work in this area relies on\nmanually annotating a few key frames and extending the localization to similar\nimages, or installing fixed specialized cameras in the stadium from which the\nlayout of the field can be obtained. In contrast, we formulate this problem as\na branch and bound inference in a Markov random field where an energy function\nis defined in terms of field cues such as grass, lines and circles. Moreover,\nour approach is fully automatic and depends only on single images from the\nbroadcast video of the game. We demonstrate the effectiveness of our method by\napplying it to various games and obtain promising results. Finally, we posit\nthat our approach can be applied easily to other sports such as hockey and\nbasketball. \n\n"}
{"id": "1604.03073", "contents": "Title: Reservoir computing for spatiotemporal signal classification without\n  trained output weights Abstract: Reservoir computing is a recently introduced machine learning paradigm that\nhas been shown to be well-suited for the processing of spatiotemporal data.\nRather than training the network node connections and weights via\nbackpropagation in traditional recurrent neural networks, reservoirs instead\nhave fixed connections and weights among the `hidden layer' nodes, and\ntraditionally only the weights to the output layer of neurons are trained using\nlinear regression. We claim that for signal classification tasks one may forgo\nthe weight training step entirely and instead use a simple supervised\nclustering method based upon principal components of norms of reservoir states.\nThe proposed method is mathematically analyzed and explored through numerical\nexperiments on real-world data. The examples demonstrate that the proposed may\noutperform the traditional trained output weight approach in terms of\nclassification accuracy and sensitivity to reservoir parameters. \n\n"}
{"id": "1604.03351", "contents": "Title: Orientation-boosted Voxel Nets for 3D Object Recognition Abstract: Recent work has shown good recognition results in 3D object recognition using\n3D convolutional networks. In this paper, we show that the object orientation\nplays an important role in 3D recognition. More specifically, we argue that\nobjects induce different features in the network under rotation. Thus, we\napproach the category-level classification task as a multi-task problem, in\nwhich the network is trained to predict the pose of the object in addition to\nthe class label as a parallel task. We show that this yields significant\nimprovements in the classification results. We test our suggested architecture\non several datasets representing various 3D data sources: LiDAR data, CAD\nmodels, and RGB-D images. We report state-of-the-art results on classification\nas well as significant improvements in precision and speed over the baseline on\n3D detection. \n\n"}
{"id": "1604.03901", "contents": "Title: Single-Image Depth Perception in the Wild Abstract: This paper studies single-image depth perception in the wild, i.e.,\nrecovering depth from a single image taken in unconstrained settings. We\nintroduce a new dataset \"Depth in the Wild\" consisting of images in the wild\nannotated with relative depth between pairs of random points. We also propose a\nnew algorithm that learns to estimate metric depth using annotations of\nrelative depth. Compared to the state of the art, our algorithm is simpler and\nperforms better. Experiments show that our algorithm, combined with existing\nRGB-D data and our new relative depth annotations, significantly improves\nsingle-image depth perception in the wild. \n\n"}
{"id": "1604.04004", "contents": "Title: Understanding How Image Quality Affects Deep Neural Networks Abstract: Image quality is an important practical challenge that is often overlooked in\nthe design of machine vision systems. Commonly, machine vision systems are\ntrained and tested on high quality image datasets, yet in practical\napplications the input images can not be assumed to be of high quality.\nRecently, deep neural networks have obtained state-of-the-art performance on\nmany machine vision tasks. In this paper we provide an evaluation of 4\nstate-of-the-art deep neural network models for image classification under\nquality distortions. We consider five types of quality distortions: blur,\nnoise, contrast, JPEG, and JPEG2000 compression. We show that the existing\nnetworks are susceptible to these quality distortions, particularly to blur and\nnoise. These results enable future work in developing deep neural networks that\nare more invariant to quality distortions. \n\n"}
{"id": "1604.04339", "contents": "Title: High-performance Semantic Segmentation Using Very Deep Fully\n  Convolutional Networks Abstract: We propose a method for high-performance semantic image segmentation (or\nsemantic pixel labelling) based on very deep residual networks, which achieves\nthe state-of-the-art performance. A few design factors are carefully considered\nto this end.\n  We make the following contributions. (i) First, we evaluate different\nvariations of a fully convolutional residual network so as to find the best\nconfiguration, including the number of layers, the resolution of feature maps,\nand the size of field-of-view. Our experiments show that further enlarging the\nfield-of-view and increasing the resolution of feature maps are typically\nbeneficial, which however inevitably leads to a higher demand for GPU memories.\nTo walk around the limitation, we propose a new method to simulate a high\nresolution network with a low resolution network, which can be applied during\ntraining and/or testing. (ii) Second, we propose an online bootstrapping method\nfor training. We demonstrate that online bootstrapping is critically important\nfor achieving good accuracy. (iii) Third we apply the traditional dropout to\nsome of the residual blocks, which further improves the performance. (iv)\nFinally, our method achieves the currently best mean intersection-over-union\n78.3\\% on the PASCAL VOC 2012 dataset, as well as on the recent dataset\nCityscapes. \n\n"}
{"id": "1604.05417", "contents": "Title: Triplet Probabilistic Embedding for Face Verification and Clustering Abstract: Despite significant progress made over the past twenty five years,\nunconstrained face verification remains a challenging problem. This paper\nproposes an approach that couples a deep CNN-based approach with a\nlow-dimensional discriminative embedding learned using triplet probability\nconstraints to solve the unconstrained face verification problem. Aside from\nyielding performance improvements, this embedding provides significant\nadvantages in terms of memory and for post-processing operations like subject\nspecific clustering. Experiments on the challenging IJB-A dataset show that the\nproposed algorithm performs comparably or better than the state of the art\nmethods in verification and identification metrics, while requiring much less\ntraining data and training time. The superior performance of the proposed\nmethod on the CFP dataset shows that the representation learned by our deep CNN\nis robust to extreme pose variation. Furthermore, we demonstrate the robustness\nof the deep features to challenges including age, pose, blur and clutter by\nperforming simple clustering experiments on both IJB-A and LFW datasets. \n\n"}
{"id": "1604.07360", "contents": "Title: Attributes for Improved Attributes: A Multi-Task Network for Attribute\n  Classification Abstract: Attributes, or semantic features, have gained popularity in the past few\nyears in domains ranging from activity recognition in video to face\nverification. Improving the accuracy of attribute classifiers is an important\nfirst step in any application which uses these attributes. In most works to\ndate, attributes have been considered to be independent. However, we know this\nnot to be the case. Many attributes are very strongly related, such as heavy\nmakeup and wearing lipstick. We propose to take advantage of attribute\nrelationships in three ways: by using a multi-task deep convolutional neural\nnetwork (MCNN) sharing the lowest layers amongst all attributes, sharing the\nhigher layers for related attributes, and by building an auxiliary network on\ntop of the MCNN which utilizes the scores from all attributes to improve the\nfinal classification of each attribute. We demonstrate the effectiveness of our\nmethod by producing results on two challenging publicly available datasets. \n\n"}
{"id": "1604.08685", "contents": "Title: Single Image 3D Interpreter Network Abstract: Understanding 3D object structure from a single image is an important but\ndifficult task in computer vision, mostly due to the lack of 3D object\nannotations in real images. Previous work tackles this problem by either\nsolving an optimization task given 2D keypoint positions, or training on\nsynthetic data with ground truth 3D information. In this work, we propose 3D\nINterpreter Network (3D-INN), an end-to-end framework which sequentially\nestimates 2D keypoint heatmaps and 3D object structure, trained on both real\n2D-annotated images and synthetic 3D data. This is made possible mainly by two\ntechnical innovations. First, we propose a Projection Layer, which projects\nestimated 3D structure to 2D space, so that 3D-INN can be trained to predict 3D\nstructural parameters supervised by 2D annotations on real images. Second,\nheatmaps of keypoints serve as an intermediate representation connecting real\nand synthetic data, enabling 3D-INN to benefit from the variation and abundance\nof synthetic 3D objects, without suffering from the difference between the\nstatistics of real and synthesized images due to imperfect rendering. The\nnetwork achieves state-of-the-art performance on both 2D keypoint estimation\nand 3D structure recovery. We also show that the recovered 3D information can\nbe used in other vision applications, such as 3D rendering and image retrieval. \n\n"}
{"id": "1605.00775", "contents": "Title: Spatially Aware Dictionary Learning and Coding for Fossil Pollen\n  Identification Abstract: We propose a robust approach for performing automatic species-level\nrecognition of fossil pollen grains in microscopy images that exploits both\nglobal shape and local texture characteristics in a patch-based matching\nmethodology. We introduce a novel criteria for selecting meaningful and\ndiscriminative exemplar patches. We optimize this function during training\nusing a greedy submodular function optimization framework that gives a\nnear-optimal solution with bounded approximation error. We use these selected\nexemplars as a dictionary basis and propose a spatially-aware sparse coding\nmethod to match testing images for identification while maintaining global\nshape correspondence. To accelerate the coding process for fast matching, we\nintroduce a relaxed form that uses spatially-aware soft-thresholding during\ncoding. Finally, we carry out an experimental study that demonstrates the\neffectiveness and efficiency of our exemplar selection and classification\nmechanisms, achieving $86.13\\%$ accuracy on a difficult fine-grained species\nclassification task distinguishing three types of fossil spruce pollen. \n\n"}
{"id": "1605.01397", "contents": "Title: Skin Lesion Analysis toward Melanoma Detection: A Challenge at the\n  International Symposium on Biomedical Imaging (ISBI) 2016, hosted by the\n  International Skin Imaging Collaboration (ISIC) Abstract: In this article, we describe the design and implementation of a publicly\naccessible dermatology image analysis benchmark challenge. The goal of the\nchallenge is to sup- port research and development of algorithms for automated\ndiagnosis of melanoma, a lethal form of skin cancer, from dermoscopic images.\nThe challenge was divided into sub-challenges for each task involved in image\nanalysis, including lesion segmentation, dermoscopic feature detection within a\nlesion, and classification of melanoma. Training data included 900 images. A\nseparate test dataset of 379 images was provided to measure resultant\nperformance of systems developed with the training data. Ground truth for both\ntraining and test sets was generated by a panel of dermoscopic experts. In\ntotal, there were 79 submissions from a group of 38 participants, making this\nthe largest standardized and comparative study for melanoma diagnosis in\ndermoscopic images to date. While the official challenge duration and ranking\nof participants has concluded, the datasets remain available for further\nresearch and development. \n\n"}
{"id": "1605.04711", "contents": "Title: Ternary Weight Networks Abstract: We present a memory and computation efficient ternary weight networks (TWNs)\n- with weights constrained to +1, 0 and -1. The Euclidian distance between full\n(float or double) precision weights and the ternary weights along with a\nscaling factor is minimized in training stage. Besides, a threshold-based\nternary function is optimized to get an approximated solution which can be fast\nand easily computed. TWNs have shown better expressive abilities than binary\nprecision counterparts. Meanwhile, TWNs achieve up to 16$\\times$ model\ncompression rate and need fewer multiplications compared with the float32\nprecision counterparts. Extensive experiments on MNIST, CIFAR-10, and ImageNet\ndatasets show that the TWNs achieve much better result than the\nBinary-Weight-Networks (BWNs) and the classification performance on MNIST and\nCIFAR-10 is very close to the full precision networks. We also verify our\nmethod on object detection task and show that TWNs significantly outperforms\nBWN by more than 10\\% mAP on PASCAL VOC dataset. The pytorch version of source\ncode is available at: https://github.com/Thinklab-SJTU/twns. \n\n"}
{"id": "1605.05110", "contents": "Title: Incorporating Loose-Structured Knowledge into Conversation Modeling via\n  Recall-Gate LSTM Abstract: Modeling human conversations is the essence for building satisfying chat-bots\nwith multi-turn dialog ability. Conversation modeling will notably benefit from\ndomain knowledge since the relationships between sentences can be clarified due\nto semantic hints introduced by knowledge. In this paper, a deep neural network\nis proposed to incorporate background knowledge for conversation modeling.\nThrough a specially designed Recall gate, domain knowledge can be transformed\ninto the extra global memory of Long Short-Term Memory (LSTM), so as to enhance\nLSTM by cooperating with its local memory to capture the implicit semantic\nrelevance between sentences within conversations. In addition, this paper\nintroduces the loose structured domain knowledge base, which can be built with\nslight amount of manual work and easily adopted by the Recall gate. Our model\nis evaluated on the context-oriented response selecting task, and experimental\nresults on both two datasets have shown that our approach is promising for\nmodeling human conversations and building key components of automatic chatting\nsystems. \n\n"}
{"id": "1605.05396", "contents": "Title: Generative Adversarial Text to Image Synthesis Abstract: Automatic synthesis of realistic images from text would be interesting and\nuseful, but current AI systems are still far from this goal. However, in recent\nyears generic and powerful recurrent neural network architectures have been\ndeveloped to learn discriminative text feature representations. Meanwhile, deep\nconvolutional generative adversarial networks (GANs) have begun to generate\nhighly compelling images of specific categories, such as faces, album covers,\nand room interiors. In this work, we develop a novel deep architecture and GAN\nformulation to effectively bridge these advances in text and image model- ing,\ntranslating visual concepts from characters to pixels. We demonstrate the\ncapability of our model to generate plausible images of birds and flowers from\ndetailed text descriptions. \n\n"}
{"id": "1605.05411", "contents": "Title: Are Facial Attributes Adversarially Robust? Abstract: Facial attributes are emerging soft biometrics that have the potential to\nreject non-matches, for example, based on mismatching gender. To be usable in\nstand-alone systems, facial attributes must be extracted from images\nautomatically and reliably. In this paper, we propose a simple yet effective\nsolution for automatic facial attribute extraction by training a deep\nconvolutional neural network (DCNN) for each facial attribute separately,\nwithout using any pre-training or dataset augmentation, and we obtain new\nstate-of-the-art facial attribute classification results on the CelebA\nbenchmark. To test the stability of the networks, we generated adversarial\nimages -- formed by adding imperceptible non-random perturbations to original\ninputs which result in classification errors -- via a novel fast flipping\nattribute (FFA) technique. We show that FFA generates more adversarial examples\nthan other related algorithms, and that DCNNs for certain attributes are\ngenerally robust to adversarial inputs, while DCNNs for other attributes are\nnot. This result is surprising because no DCNNs tested to date have exhibited\nrobustness to adversarial images without explicit augmentation in the training\nprocedure to account for adversarial examples. Finally, we introduce the\nconcept of natural adversarial samples, i.e., images that are misclassified but\ncan be easily turned into correctly classified images by applying small\nperturbations. We demonstrate that natural adversarial samples commonly occur,\neven within the training set, and show that many of these images remain\nmisclassified even with additional training epochs. This phenomenon is\nsurprising because correcting the misclassification, particularly when guided\nby training data, should require only a small adjustment to the DCNN\nparameters. \n\n"}
{"id": "1605.05414", "contents": "Title: On the Evaluation of Dialogue Systems with Next Utterance Classification Abstract: An open challenge in constructing dialogue systems is developing methods for\nautomatically learning dialogue strategies from large amounts of unlabelled\ndata. Recent work has proposed Next-Utterance-Classification (NUC) as a\nsurrogate task for building dialogue systems from text data. In this paper we\ninvestigate the performance of humans on this task to validate the relevance of\nNUC as a method of evaluation. Our results show three main findings: (1) humans\nare able to correctly classify responses at a rate much better than chance,\nthus confirming that the task is feasible, (2) human performance levels vary\nacross task domains (we consider 3 datasets) and expertise levels (novice vs\nexperts), thus showing that a range of performance is possible on this type of\ntask, (3) automated dialogue systems built using state-of-the-art machine\nlearning methods have similar performance to the human novices, but worse than\nthe experts, thus confirming the utility of this class of tasks for driving\nfurther research in automated dialogue systems. \n\n"}
{"id": "1605.06457", "contents": "Title: Virtual Worlds as Proxy for Multi-Object Tracking Analysis Abstract: Modern computer vision algorithms typically require expensive data\nacquisition and accurate manual labeling. In this work, we instead leverage the\nrecent progress in computer graphics to generate fully labeled, dynamic, and\nphoto-realistic proxy virtual worlds. We propose an efficient real-to-virtual\nworld cloning method, and validate our approach by building and publicly\nreleasing a new video dataset, called Virtual KITTI (see\nhttp://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds),\nautomatically labeled with accurate ground truth for object detection,\ntracking, scene and instance segmentation, depth, and optical flow. We provide\nquantitative experimental evidence suggesting that (i) modern deep learning\nalgorithms pre-trained on real data behave similarly in real and virtual\nworlds, and (ii) pre-training on virtual data improves performance. As the gap\nbetween real and virtual worlds is small, virtual worlds enable measuring the\nimpact of various weather and imaging conditions on recognition performance,\nall other things being equal. We show these factors may affect drastically\notherwise high-performing deep models for tracking. \n\n"}
{"id": "1605.06489", "contents": "Title: Deep Roots: Improving CNN Efficiency with Hierarchical Filter Groups Abstract: We propose a new method for creating computationally efficient and compact\nconvolutional neural networks (CNNs) using a novel sparse connection structure\nthat resembles a tree root. This allows a significant reduction in\ncomputational cost and number of parameters compared to state-of-the-art deep\nCNNs, without compromising accuracy, by exploiting the sparsity of inter-layer\nfilter dependencies. We validate our approach by using it to train more\nefficient variants of state-of-the-art CNN architectures, evaluated on the\nCIFAR10 and ILSVRC datasets. Our results show similar or higher accuracy than\nthe baseline architectures with much less computation, as measured by CPU and\nGPU timings. For example, for ResNet 50, our model has 40% fewer parameters,\n45% fewer floating point operations, and is 31% (12%) faster on a CPU (GPU).\nFor the deeper ResNet 200 our model has 25% fewer floating point operations and\n44% fewer parameters, while maintaining state-of-the-art accuracy. For\nGoogLeNet, our model has 7% fewer parameters and is 21% (16%) faster on a CPU\n(GPU). \n\n"}
{"id": "1605.07678", "contents": "Title: An Analysis of Deep Neural Network Models for Practical Applications Abstract: Since the emergence of Deep Neural Networks (DNNs) as a prominent technique\nin the field of computer vision, the ImageNet classification challenge has\nplayed a major role in advancing the state-of-the-art. While accuracy figures\nhave steadily increased, the resource utilisation of winning models has not\nbeen properly taken into account. In this work, we present a comprehensive\nanalysis of important metrics in practical applications: accuracy, memory\nfootprint, parameters, operations count, inference time and power consumption.\nKey findings are: (1) power consumption is independent of batch size and\narchitecture; (2) accuracy and inference time are in a hyperbolic relationship;\n(3) energy constraint is an upper bound on the maximum achievable accuracy and\nmodel complexity; (4) the number of operations is a reliable estimate of the\ninference time. We believe our analysis provides a compelling set of\ninformation that helps design and engineer efficient DNNs. \n\n"}
{"id": "1605.08003", "contents": "Title: Tight Complexity Bounds for Optimizing Composite Objectives Abstract: We provide tight upper and lower bounds on the complexity of minimizing the\naverage of $m$ convex functions using gradient and prox oracles of the\ncomponent functions. We show a significant gap between the complexity of\ndeterministic vs randomized optimization. For smooth functions, we show that\naccelerated gradient descent (AGD) and an accelerated variant of SVRG are\noptimal in the deterministic and randomized settings respectively, and that a\ngradient oracle is sufficient for the optimal rate. For non-smooth functions,\nhaving access to prox oracles reduces the complexity and we present optimal\nmethods based on smoothing that improve over methods using just gradient\naccesses. \n\n"}
{"id": "1605.08153", "contents": "Title: DeepMovie: Using Optical Flow and Deep Neural Networks to Stylize Movies Abstract: A recent paper by Gatys et al. describes a method for rendering an image in\nthe style of another image. First, they use convolutional neural network\nfeatures to build a statistical model for the style of an image. Then they\ncreate a new image with the content of one image but the style statistics of\nanother image. Here, we extend this method to render a movie in a given\nartistic style. The naive solution that independently renders each frame\nproduces poor results because the features of the style move substantially from\none frame to the next. The other naive method that initializes the optimization\nfor the next frame using the rendered version of the previous frame also\nproduces poor results because the features of the texture stay fixed relative\nto the frame of the movie instead of moving with objects in the scene. The main\ncontribution of this paper is to use optical flow to initialize the style\ntransfer optimization so that the texture features move with the objects in the\nvideo. Finally, we suggest a method to incorporate optical flow explicitly into\nthe cost function. \n\n"}
{"id": "1606.01141", "contents": "Title: On Valid Optimal Assignment Kernels and Applications to Graph\n  Classification Abstract: The success of kernel methods has initiated the design of novel positive\nsemidefinite functions, in particular for structured data. A leading design\nparadigm for this is the convolution kernel, which decomposes structured\nobjects into their parts and sums over all pairs of parts. Assignment kernels,\nin contrast, are obtained from an optimal bijection between parts, which can\nprovide a more valid notion of similarity. In general however, optimal\nassignments yield indefinite functions, which complicates their use in kernel\nmethods. We characterize a class of base kernels used to compare parts that\nguarantees positive semidefinite optimal assignment kernels. These base kernels\ngive rise to hierarchies from which the optimal assignment kernels are computed\nin linear time by histogram intersection. We apply these results by developing\nthe Weisfeiler-Lehman optimal assignment kernel for graphs. It provides high\nclassification accuracy on widely-used benchmark data sets improving over the\noriginal Weisfeiler-Lehman kernel. \n\n"}
{"id": "1606.01286", "contents": "Title: Incorporating long-range consistency in CNN-based texture generation Abstract: Gatys et al. (2015) showed that pair-wise products of features in a\nconvolutional network are a very effective representation of image textures. We\npropose a simple modification to that representation which makes it possible to\nincorporate long-range structure into image generation, and to render images\nthat satisfy various symmetry constraints. We show how this can greatly improve\nrendering of regular textures and of images that contain other kinds of\nsymmetric structure. We also present applications to inpainting and season\ntransfer. \n\n"}
{"id": "1606.01847", "contents": "Title: Multimodal Compact Bilinear Pooling for Visual Question Answering and\n  Visual Grounding Abstract: Modeling textual or visual information with vector representations trained\nfrom large language or visual datasets has been successfully explored in recent\nyears. However, tasks such as visual question answering require combining these\nvector representations with each other. Approaches to multimodal pooling\ninclude element-wise product or sum, as well as concatenation of the visual and\ntextual representations. We hypothesize that these methods are not as\nexpressive as an outer product of the visual and textual vectors. As the outer\nproduct is typically infeasible due to its high dimensionality, we instead\npropose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and\nexpressively combine multimodal features. We extensively evaluate MCB on the\nvisual question answering and grounding tasks. We consistently show the benefit\nof MCB over ablations without MCB. For visual question answering, we present an\narchitecture which uses MCB twice, once for predicting attention over spatial\nfeatures and again to combine the attended representation with the question\nrepresentation. This model outperforms the state-of-the-art on the Visual7W\ndataset and the VQA challenge. \n\n"}
{"id": "1606.01868", "contents": "Title: Unifying Count-Based Exploration and Intrinsic Motivation Abstract: We consider an agent's uncertainty about its environment and the problem of\ngeneralizing this uncertainty across observations. Specifically, we focus on\nthe problem of exploration in non-tabular reinforcement learning. Drawing\ninspiration from the intrinsic motivation literature, we use density models to\nmeasure uncertainty, and propose a novel algorithm for deriving a pseudo-count\nfrom an arbitrary density model. This technique enables us to generalize\ncount-based exploration algorithms to the non-tabular case. We apply our ideas\nto Atari 2600 games, providing sensible pseudo-counts from raw pixels. We\ntransform these pseudo-counts into intrinsic rewards and obtain significantly\nimproved exploration in a number of hard games, including the infamously\ndifficult Montezuma's Revenge. \n\n"}
{"id": "1606.01981", "contents": "Title: Deep neural networks are robust to weight binarization and other\n  non-linear distortions Abstract: Recent results show that deep neural networks achieve excellent performance\neven when, during training, weights are quantized and projected to a binary\nrepresentation. Here, we show that this is just the tip of the iceberg: these\nsame networks, during testing, also exhibit a remarkable robustness to\ndistortions beyond quantization, including additive and multiplicative noise,\nand a class of non-linear projections where binarization is just a special\ncase. To quantify this robustness, we show that one such network achieves 11%\ntest error on CIFAR-10 even with 0.68 effective bits per weight. Furthermore,\nwe find that a common training heuristic--namely, projecting quantized weights\nduring backpropagation--can be altered (or even removed) and networks still\nachieve a base level of robustness during testing. Specifically, training with\nweight projections other than quantization also works, as does simply clipping\nthe weights, both of which have never been reported before. We confirm our\nresults for CIFAR-10 and ImageNet datasets. Finally, drawing from these ideas,\nwe propose a stochastic projection rule that leads to a new state of the art\nnetwork with 7.64% test error on CIFAR-10 using no data augmentation. \n\n"}
{"id": "1606.02077", "contents": "Title: Regret Bounds for Non-decomposable Metrics with Missing Labels Abstract: We consider the problem of recommending relevant labels (items) for a given\ndata point (user). In particular, we are interested in the practically\nimportant setting where the evaluation is with respect to non-decomposable\n(over labels) performance metrics like the $F_1$ measure, and the training data\nhas missing labels. To this end, we propose a generic framework that given a\nperformance metric $\\Psi$, can devise a regularized objective function and a\nthreshold such that all the values in the predicted score vector above and only\nabove the threshold are selected to be positive. We show that the regret or\ngeneralization error in the given metric $\\Psi$ is bounded ultimately by\nestimation error of certain underlying parameters. In particular, we derive\nregret bounds under three popular settings: a) collaborative filtering, b)\nmultilabel classification, and c) PU (positive-unlabeled) learning. For each of\nthe above problems, we can obtain precise non-asymptotic regret bound which is\nsmall even when a large fraction of labels is missing. Our empirical results on\nsynthetic and benchmark datasets demonstrate that by explicitly modeling for\nmissing labels and optimizing the desired performance metric, our algorithm\nindeed achieves significantly better performance (like $F_1$ score) when\ncompared to methods that do not model missing label information carefully. \n\n"}
{"id": "1606.02228", "contents": "Title: Systematic evaluation of CNN advances on the ImageNet Abstract: The paper systematically studies the impact of a range of recent advances in\nCNN architectures and learning methods on the object categorization (ILSVRC)\nproblem. The evalution tests the influence of the following choices of the\narchitecture: non-linearity (ReLU, ELU, maxout, compatibility with batch\nnormalization), pooling variants (stochastic, max, average, mixed), network\nwidth, classifier design (convolutional, fully-connected, SPP), image\npre-processing, and of learning parameters: learning rate, batch size,\ncleanliness of the data, etc.\n  The performance gains of the proposed modifications are first tested\nindividually and then in combination. The sum of individual gains is bigger\nthan the observed improvement when all modifications are introduced, but the\n\"deficit\" is small suggesting independence of their benefits. We show that the\nuse of 128x128 pixel images is sufficient to make qualitative conclusions about\noptimal network structure that hold for the full size Caffe and VGG nets. The\nresults are obtained an order of magnitude faster than with the standard 224\npixel images. \n\n"}
{"id": "1606.02580", "contents": "Title: Convolution by Evolution: Differentiable Pattern Producing Networks Abstract: In this work we introduce a differentiable version of the Compositional\nPattern Producing Network, called the DPPN. Unlike a standard CPPN, the\ntopology of a DPPN is evolved but the weights are learned. A Lamarckian\nalgorithm, that combines evolution and learning, produces DPPNs to reconstruct\nan image. Our main result is that DPPNs can be evolved/trained to compress the\nweights of a denoising autoencoder from 157684 to roughly 200 parameters, while\nachieving a reconstruction accuracy comparable to a fully connected network\nwith more than two orders of magnitude more parameters. The regularization\nability of the DPPN allows it to rediscover (approximate) convolutional network\narchitectures embedded within a fully connected architecture. Such\nconvolutional architectures are the current state of the art for many computer\nvision applications, so it is satisfying that DPPNs are capable of discovering\nthis structure rather than having to build it in by design. DPPNs exhibit\nbetter generalization when tested on the Omniglot dataset after being trained\non MNIST, than directly encoded fully connected autoencoders. DPPNs are\ntherefore a new framework for integrating learning and evolution. \n\n"}
{"id": "1606.03439", "contents": "Title: Deep Directed Generative Models with Energy-Based Probability Estimation Abstract: Training energy-based probabilistic models is confronted with apparently\nintractable sums, whose Monte Carlo estimation requires sampling from the\nestimated probability distribution in the inner loop of training. This can be\napproximately achieved by Markov chain Monte Carlo methods, but may still face\na formidable obstacle that is the difficulty of mixing between modes with sharp\nconcentrations of probability. Whereas an MCMC process is usually derived from\na given energy function based on mathematical considerations and requires an\narbitrarily long time to obtain good and varied samples, we propose to train a\ndeep directed generative model (not a Markov chain) so that its sampling\ndistribution approximately matches the energy function that is being trained.\nInspired by generative adversarial networks, the proposed framework involves\ntraining of two models that represent dual views of the estimated probability\ndistribution: the energy function (mapping an input configuration to a scalar\nenergy value) and the generator (mapping a noise vector to a generated\nconfiguration), both represented by deep neural networks. \n\n"}
{"id": "1606.04884", "contents": "Title: cltorch: a Hardware-Agnostic Backend for the Torch Deep Neural Network\n  Library, Based on OpenCL Abstract: This paper presents cltorch, a hardware-agnostic backend for the Torch neural\nnetwork framework. cltorch enables training of deep neural networks on GPUs\nfrom diverse hardware vendors, including AMD, NVIDIA, and Intel. cltorch\ncontains sufficient implementation to run models such as AlexNet, VGG,\nOverfeat, and GoogleNet. It is written using the OpenCL language, a portable\ncompute language, governed by the Khronos Group. cltorch is the top-ranked\nhardware-agnostic machine learning framework on Chintala's convnet-benchmarks\npage.\n  This paper presents the technical challenges encountered whilst creating the\ncltorch backend for Torch, and looks in detail at the challenges related to\nobtaining a fast hardware-agnostic implementation.\n  The convolutional layers are identified as the key area of focus for\naccelerating hardware-agnostic frameworks. Possible approaches to accelerating\nthe convolutional implementation are identified including: implementation of\nthe convolutions using the implicitgemm or winograd algorithm, using a GEMM\nimplementation adapted to the geometries associated with the convolutional\nalgorithm, or using a pluggable hardware-specific convolutional implementation. \n\n"}
{"id": "1606.05763", "contents": "Title: Online and Offline Handwritten Chinese Character Recognition: A\n  Comprehensive Study and New Benchmark Abstract: Recent deep learning based methods have achieved the state-of-the-art\nperformance for handwritten Chinese character recognition (HCCR) by learning\ndiscriminative representations directly from raw data. Nevertheless, we believe\nthat the long-and-well investigated domain-specific knowledge should still help\nto boost the performance of HCCR. By integrating the traditional\nnormalization-cooperated direction-decomposed feature map (directMap) with the\ndeep convolutional neural network (convNet), we are able to obtain new highest\naccuracies for both online and offline HCCR on the ICDAR-2013 competition\ndatabase. With this new framework, we can eliminate the needs for data\naugmentation and model ensemble, which are widely used in other systems to\nachieve their best results. This makes our framework to be efficient and\neffective for both training and testing. Furthermore, although\ndirectMap+convNet can achieve the best results and surpass human-level\nperformance, we show that writer adaptation in this case is still effective. A\nnew adaptation layer is proposed to reduce the mismatch between training and\ntest data on a particular source layer. The adaptation process can be\nefficiently and effectively implemented in an unsupervised manner. By adding\nthe adaptation layer into the pre-trained convNet, it can adapt to the new\nhandwriting styles of particular writers, and the recognition accuracy can be\nfurther improved consistently and significantly. This paper gives an overview\nand comparison of recent deep learning based approaches for HCCR, and also sets\nnew benchmarks for both online and offline HCCR. \n\n"}
{"id": "1606.05929", "contents": "Title: Learning Convolutional Neural Networks using Hybrid Orthogonal\n  Projection and Estimation Abstract: Convolutional neural networks (CNNs) have yielded the excellent performance\nin a variety of computer vision tasks, where CNNs typically adopt a similar\nstructure consisting of convolution layers, pooling layers and fully connected\nlayers. In this paper, we propose to apply a novel method, namely Hybrid\nOrthogonal Projection and Estimation (HOPE), to CNNs in order to introduce\northogonality into the CNN structure. The HOPE model can be viewed as a hybrid\nmodel to combine feature extraction using orthogonal linear projection with\nmixture models. It is an effective model to extract useful information from the\noriginal high-dimension feature vectors and meanwhile filter out irrelevant\nnoises. In this work, we present three different ways to apply the HOPE models\nto CNNs, i.e., {\\em HOPE-Input}, {\\em single-HOPE-Block} and {\\em\nmulti-HOPE-Blocks}. For {\\em HOPE-Input} CNNs, a HOPE layer is directly used\nright after the input to de-correlate high-dimension input feature vectors.\nAlternatively, in {\\em single-HOPE-Block} and {\\em multi-HOPE-Blocks} CNNs, we\nconsider to use HOPE layers to replace one or more blocks in the CNNs, where\none block may include several convolutional layers and one pooling layer. The\nexperimental results on both Cifar-10 and Cifar-100 data sets have shown that\nthe orthogonal constraints imposed by the HOPE layers can significantly improve\nthe performance of CNNs in these image classification tasks (we have achieved\none of the best performance when image augmentation has not been applied, and\ntop 5 performance with image augmentation). \n\n"}
{"id": "1606.06472", "contents": "Title: DeepWriter: A Multi-Stream Deep CNN for Text-independent Writer\n  Identification Abstract: Text-independent writer identification is challenging due to the huge\nvariation of written contents and the ambiguous written styles of different\nwriters. This paper proposes DeepWriter, a deep multi-stream CNN to learn deep\npowerful representation for recognizing writers. DeepWriter takes local\nhandwritten patches as input and is trained with softmax classification loss.\nThe main contributions are: 1) we design and optimize multi-stream structure\nfor writer identification task; 2) we introduce data augmentation learning to\nenhance the performance of DeepWriter; 3) we introduce a patch scanning\nstrategy to handle text image with different lengths. In addition, we find that\ndifferent languages such as English and Chinese may share common features for\nwriter identification, and joint training can yield better performance.\nExperimental results on IAM and HWDB datasets show that our models achieve high\nidentification accuracy: 99.01% on 301 writers and 97.03% on 657 writers with\none English sentence input, 93.85% on 300 writers with one Chinese character\ninput, which outperform previous methods with a large margin. Moreover, our\nmodels obtain accuracy of 98.01% on 301 writers with only 4 English alphabets\nas input. \n\n"}
{"id": "1606.09282", "contents": "Title: Learning without Forgetting Abstract: When building a unified vision system or gradually adding new capabilities to\na system, the usual assumption is that training data for all tasks is always\navailable. However, as the number of tasks grows, storing and retraining on\nsuch data becomes infeasible. A new problem arises where we add new\ncapabilities to a Convolutional Neural Network (CNN), but the training data for\nits existing capabilities are unavailable. We propose our Learning without\nForgetting method, which uses only new task data to train the network while\npreserving the original capabilities. Our method performs favorably compared to\ncommonly used feature extraction and fine-tuning adaption techniques and\nperforms similarly to multitask learning that uses original task data we assume\nunavailable. A more surprising observation is that Learning without Forgetting\nmay be able to replace fine-tuning with similar old and new task datasets for\nimproved new task performance. \n\n"}
{"id": "1607.00360", "contents": "Title: A scaled Bregman theorem with applications Abstract: Bregman divergences play a central role in the design and analysis of a range\nof machine learning algorithms. This paper explores the use of Bregman\ndivergences to establish reductions between such algorithms and their analyses.\nWe present a new scaled isodistortion theorem involving Bregman divergences\n(scaled Bregman theorem for short) which shows that certain \"Bregman\ndistortions'\" (employing a potentially non-convex generator) may be exactly\nre-written as a scaled Bregman divergence computed over transformed data.\nAdmissible distortions include geodesic distances on curved manifolds and\nprojections or gauge-normalisation, while admissible data include scalars,\nvectors and matrices.\n  Our theorem allows one to leverage to the wealth and convenience of Bregman\ndivergences when analysing algorithms relying on the aforementioned Bregman\ndistortions. We illustrate this with three novel applications of our theorem: a\nreduction from multi-class density ratio to class-probability estimation, a new\nadaptive projection free yet norm-enforcing dual norm mirror descent algorithm,\nand a reduction from clustering on flat manifolds to clustering on curved\nmanifolds. Experiments on each of these domains validate the analyses and\nsuggest that the scaled Bregman theorem might be a worthy addition to the\npopular handful of Bregman divergence properties that have been pervasive in\nmachine learning. \n\n"}
{"id": "1607.03250", "contents": "Title: Network Trimming: A Data-Driven Neuron Pruning Approach towards\n  Efficient Deep Architectures Abstract: State-of-the-art neural networks are getting deeper and wider. While their\nperformance increases with the increasing number of layers and neurons, it is\ncrucial to design an efficient deep architecture in order to reduce\ncomputational and memory costs. Designing an efficient neural network, however,\nis labor intensive requiring many experiments, and fine-tunings. In this paper,\nwe introduce network trimming which iteratively optimizes the network by\npruning unimportant neurons based on analysis of their outputs on a large\ndataset. Our algorithm is inspired by an observation that the outputs of a\nsignificant portion of neurons in a large network are mostly zero, regardless\nof what inputs the network received. These zero activation neurons are\nredundant, and can be removed without affecting the overall accuracy of the\nnetwork. After pruning the zero activation neurons, we retrain the network\nusing the weights before pruning as initialization. We alternate the pruning\nand retraining to further reduce zero activations in a network. Our experiments\non the LeNet and VGG-16 show that we can achieve high compression ratio of\nparameters without losing or even achieving higher accuracy than the original\nnetwork. \n\n"}
{"id": "1607.03333", "contents": "Title: RGBD Salient Object Detection via Deep Fusion Abstract: Numerous efforts have been made to design different low level saliency cues\nfor the RGBD saliency detection, such as color or depth contrast features,\nbackground and color compactness priors. However, how these saliency cues\ninteract with each other and how to incorporate these low level saliency cues\neffectively to generate a master saliency map remain a challenging problem. In\nthis paper, we design a new convolutional neural network (CNN) to fuse\ndifferent low level saliency cues into hierarchical features for automatically\ndetecting salient objects in RGBD images. In contrast to the existing works\nthat directly feed raw image pixels to the CNN, the proposed method takes\nadvantage of the knowledge in traditional saliency detection by adopting\nvarious meaningful and well-designed saliency feature vectors as input. This\ncan guide the training of CNN towards detecting salient object more effectively\ndue to the reduced learning ambiguity. We then integrate a Laplacian\npropagation framework with the learned CNN to extract a spatially consistent\nsaliency map by exploiting the intrinsic structure of the input image.\nExtensive quantitative and qualitative experimental evaluations on three\ndatasets demonstrate that the proposed method consistently outperforms\nstate-of-the-art methods. \n\n"}
{"id": "1607.05418", "contents": "Title: Runtime Configurable Deep Neural Networks for Energy-Accuracy Trade-off Abstract: We present a novel dynamic configuration technique for deep neural networks\nthat permits step-wise energy-accuracy trade-offs during runtime. Our\nconfiguration technique adjusts the number of channels in the network\ndynamically depending on response time, power, and accuracy targets. To enable\nthis dynamic configuration technique, we co-design a new training algorithm,\nwhere the network is incrementally trained such that the weights in channels\ntrained in earlier steps are fixed. Our technique provides the flexibility of\nmultiple networks while storing and utilizing one set of weights. We evaluate\nour techniques using both an ASIC-based hardware accelerator as well as a\nlow-power embedded GPGPU and show that our approach leads to only a small or\nnegligible loss in the final network accuracy. We analyze the performance of\nour proposed methodology using three well-known networks for MNIST, CIFAR-10,\nand SVHN datasets, and we show that we are able to achieve up to 95% energy\nreduction with less than 1% accuracy loss across the three benchmarks. In\naddition, compared to prior work on dynamic network reconfiguration, we show\nthat our approach leads to approximately 50% savings in storage requirements,\nwhile achieving similar accuracy. \n\n"}
{"id": "1607.06317", "contents": "Title: A Multi-cut Formulation for Joint Segmentation and Tracking of Multiple\n  Objects Abstract: Recently, Minimum Cost Multicut Formulations have been proposed and proven to\nbe successful in both motion trajectory segmentation and multi-target tracking\nscenarios. Both tasks benefit from decomposing a graphical model into an\noptimal number of connected components based on attractive and repulsive\npairwise terms. The two tasks are formulated on different levels of granularity\nand, accordingly, leverage mostly local information for motion segmentation and\nmostly high-level information for multi-target tracking. In this paper we argue\nthat point trajectories and their local relationships can contribute to the\nhigh-level task of multi-target tracking and also argue that high-level cues\nfrom object detection and tracking are helpful to solve motion segmentation. We\npropose a joint graphical model for point trajectories and object detections\nwhose Multicuts are solutions to motion segmentation {\\it and} multi-target\ntracking problems at once. Results on the FBMS59 motion segmentation benchmark\nas well as on pedestrian tracking sequences from the 2D MOT 2015 benchmark\ndemonstrate the promise of this joint approach. \n\n"}
{"id": "1608.00218", "contents": "Title: Hyperparameter Transfer Learning through Surrogate Alignment for\n  Efficient Deep Neural Network Training Abstract: Recently, several optimization methods have been successfully applied to the\nhyperparameter optimization of deep neural networks (DNNs). The methods work by\nmodeling the joint distribution of hyperparameter values and corresponding\nerror. Those methods become less practical when applied to modern DNNs whose\ntraining may take a few days and thus one cannot collect sufficient\nobservations to accurately model the distribution. To address this challenging\nissue, we propose a method that learns to transfer optimal hyperparameter\nvalues for a small source dataset to hyperparameter values with comparable\nperformance on a dataset of interest. As opposed to existing transfer learning\nmethods, our proposed method does not use hand-designed features. Instead, it\nuses surrogates to model the hyperparameter-error distributions of the two\ndatasets and trains a neural network to learn the transfer function. Extensive\nexperiments on three CV benchmark datasets clearly demonstrate the efficiency\nof our method. \n\n"}
{"id": "1608.00525", "contents": "Title: Modeling Context Between Objects for Referring Expression Understanding Abstract: Referring expressions usually describe an object using properties of the\nobject and relationships of the object with other objects. We propose a\ntechnique that integrates context between objects to understand referring\nexpressions. Our approach uses an LSTM to learn the probability of a referring\nexpression, with input features from a region and a context region. The context\nregions are discovered using multiple-instance learning (MIL) since annotations\nfor context objects are generally not available for training. We utilize\nmax-margin based MIL objective functions for training the LSTM. Experiments on\nthe Google RefExp and UNC RefExp datasets show that modeling context between\nobjects provides better performance than modeling only object properties. We\nalso qualitatively show that our technique can ground a referring expression to\nits referred region along with the supporting context region. \n\n"}
{"id": "1608.00700", "contents": "Title: A Survey of Visual Analysis of Human Motion and Its Applications Abstract: This paper summarizes the recent progress in human motion analysis and its\napplications. In the beginning, we reviewed the motion capture systems and the\nrepresentation model of human's motion data. Next, we sketched the advanced\nhuman motion data processing technologies, including motion data filtering,\ntemporal alignment, and segmentation. The following parts overview the\nstate-of-the-art approaches of action recognition and dynamics measuring since\nthese two are the most active research areas in human motion analysis. The last\npart discusses some emerging applications of the human motion analysis in\nhealthcare, human robot interaction, security surveillance, virtual reality and\nanimation. The promising research topics of human motion analysis in the future\nis also summarized in the last part. \n\n"}
{"id": "1608.00775", "contents": "Title: Dense semantic labeling of sub-decimeter resolution images with\n  convolutional neural networks Abstract: Semantic labeling (or pixel-level land-cover classification) in ultra-high\nresolution imagery (< 10cm) requires statistical models able to learn high\nlevel concepts from spatial data, with large appearance variations.\nConvolutional Neural Networks (CNNs) achieve this goal by learning\ndiscriminatively a hierarchy of representations of increasing abstraction.\n  In this paper we present a CNN-based system relying on an\ndownsample-then-upsample architecture. Specifically, it first learns a rough\nspatial map of high-level representations by means of convolutions and then\nlearns to upsample them back to the original resolution by deconvolutions. By\ndoing so, the CNN learns to densely label every pixel at the original\nresolution of the image. This results in many advantages, including i)\nstate-of-the-art numerical accuracy, ii) improved geometric accuracy of\npredictions and iii) high efficiency at inference time.\n  We test the proposed system on the Vaihingen and Potsdam sub-decimeter\nresolution datasets, involving semantic labeling of aerial images of 9cm and\n5cm resolution, respectively. These datasets are composed by many large and\nfully annotated tiles allowing an unbiased evaluation of models making use of\nspatial information. We do so by comparing two standard CNN architectures to\nthe proposed one: standard patch classification, prediction of local label\npatches by employing only convolutions and full patch labeling by employing\ndeconvolutions. All the systems compare favorably or outperform a\nstate-of-the-art baseline relying on superpixels and powerful appearance\ndescriptors. The proposed full patch labeling CNN outperforms these models by a\nlarge margin, also showing a very appealing inference time. \n\n"}
{"id": "1608.03339", "contents": "Title: Distributed learning with regularized least squares Abstract: We study distributed learning with the least squares regularization scheme in\na reproducing kernel Hilbert space (RKHS). By a divide-and-conquer approach,\nthe algorithm partitions a data set into disjoint data subsets, applies the\nleast squares regularization scheme to each data subset to produce an output\nfunction, and then takes an average of the individual output functions as a\nfinal global estimator or predictor. We show with error bounds in expectation\nin both the $L^2$-metric and RKHS-metric that the global output function of\nthis distributed learning is a good approximation to the algorithm processing\nthe whole data in one single machine. Our error bounds are sharp and stated in\na general setting without any eigenfunction assumption. The analysis is\nachieved by a novel second order decomposition of operator differences in our\nintegral operator approach. Even for the classical least squares regularization\nscheme in the RKHS associated with a general kernel, we give the best learning\nrate in the literature. \n\n"}
{"id": "1608.03793", "contents": "Title: Applying Deep Learning to Basketball Trajectories Abstract: One of the emerging trends for sports analytics is the growing use of player\nand ball tracking data. A parallel development is deep learning predictive\napproaches that use vast quantities of data with less reliance on feature\nengineering. This paper applies recurrent neural networks in the form of\nsequence modeling to predict whether a three-point shot is successful. The\nmodels are capable of learning the trajectory of a basketball without any\nknowledge of physics. For comparison, a baseline static machine learning model\nwith a full set of features, such as angle and velocity, in addition to the\npositional data is also tested. Using a dataset of over 20,000 three pointers\nfrom NBA SportVu data, the models based simply on sequential positional data\noutperform a static feature rich machine learning model in predicting whether a\nthree-point shot is successful. This suggests deep learning models may offer an\nimprovement to traditional feature based machine learning methods for tracking\ndata. \n\n"}
{"id": "1608.04493", "contents": "Title: Dynamic Network Surgery for Efficient DNNs Abstract: Deep learning has become a ubiquitous technology to improve machine\nintelligence. However, most of the existing deep models are structurally very\ncomplex, making them difficult to be deployed on the mobile platforms with\nlimited computational power. In this paper, we propose a novel network\ncompression method called dynamic network surgery, which can remarkably reduce\nthe network complexity by making on-the-fly connection pruning. Unlike the\nprevious methods which accomplish this task in a greedy way, we properly\nincorporate connection splicing into the whole process to avoid incorrect\npruning and make it as a continual network maintenance. The effectiveness of\nour method is proved with experiments. Without any accuracy loss, our method\ncan efficiently compress the number of parameters in LeNet-5 and AlexNet by a\nfactor of $\\bm{108}\\times$ and $\\bm{17.7}\\times$ respectively, proving that it\noutperforms the recent pruning method by considerable margins. Code and some\nmodels are available at https://github.com/yiwenguo/Dynamic-Network-Surgery. \n\n"}
{"id": "1608.07251", "contents": "Title: Large-scale Collaborative Imaging Genetics Studies of Risk Genetic\n  Factors for Alzheimer's Disease Across Multiple Institutions Abstract: Genome-wide association studies (GWAS) offer new opportunities to identify\ngenetic risk factors for Alzheimer's disease (AD). Recently, collaborative\nefforts across different institutions emerged that enhance the power of many\nexisting techniques on individual institution data. However, a major barrier to\ncollaborative studies of GWAS is that many institutions need to preserve\nindividual data privacy. To address this challenge, we propose a novel\ndistributed framework, termed Local Query Model (LQM) to detect risk SNPs for\nAD across multiple research institutions. To accelerate the learning process,\nwe propose a Distributed Enhanced Dual Polytope Projection (D-EDPP) screening\nrule to identify irrelevant features and remove them from the optimization. To\nthe best of our knowledge, this is the first successful run of the\ncomputationally intensive model selection procedure to learn a consistent model\nacross different institutions without compromising their privacy while ranking\nthe SNPs that may collectively affect AD. Empirical studies are conducted on\n809 subjects with 5.9 million SNP features which are distributed across three\nindividual institutions. D-EDPP achieved a 66-fold speed-up by effectively\nidentifying irrelevant features. \n\n"}
{"id": "1608.07706", "contents": "Title: Multi-Path Feedback Recurrent Neural Network for Scene Parsing Abstract: In this paper, we consider the scene parsing problem and propose a novel\nMulti-Path Feedback recurrent neural network (MPF-RNN) for parsing scene\nimages. MPF-RNN can enhance the capability of RNNs in modeling long-range\ncontext information at multiple levels and better distinguish pixels that are\neasy to confuse. Different from feedforward CNNs and RNNs with only single\nfeedback, MPF-RNN propagates the contextual features learned at top layer\nthrough \\textit{multiple} weighted recurrent connections to learn bottom\nfeatures. For better training MPF-RNN, we propose a new strategy that considers\naccumulative loss at multiple recurrent steps to improve performance of the\nMPF-RNN on parsing small objects. With these two novel components, MPF-RNN has\nachieved significant improvement over strong baselines (VGG16 and Res101) on\nfive challenging scene parsing benchmarks, including traditional SiftFlow,\nBarcelona, CamVid, Stanford Background as well as the recently released\nlarge-scale ADE20K. \n\n"}
{"id": "1609.00017", "contents": "Title: Radiation Search Operations using Scene Understanding with Autonomous\n  UAV and UGV Abstract: Autonomously searching for hazardous radiation sources requires the ability\nof the aerial and ground systems to understand the scene they are scouting. In\nthis paper, we present systems, algorithms, and experiments to perform\nradiation search using unmanned aerial vehicles (UAV) and unmanned ground\nvehicles (UGV) by employing semantic scene segmentation. The aerial data is\nused to identify radiological points of interest, generate an orthophoto along\nwith a digital elevation model (DEM) of the scene, and perform semantic\nsegmentation to assign a category (e.g. road, grass) to each pixel in the\northophoto. We perform semantic segmentation by training a model on a dataset\nof images we collected and annotated, using the model to perform inference on\nimages of the test area unseen to the model, and then refining the results with\nthe DEM to better reason about category predictions at each pixel. We then use\nall of these outputs to plan a path for a UGV carrying a LiDAR to map the\nenvironment and avoid obstacles not present during the flight, and a radiation\ndetector to collect more precise radiation measurements from the ground.\nResults of the analysis for each scenario tested favorably. We also note that\nour approach is general and has the potential to work for a variety of\ndifferent sensing tasks. \n\n"}
{"id": "1609.00967", "contents": "Title: Vanishing point detection with convolutional neural networks Abstract: Inspired by the finding that vanishing point (road tangent) guides driver's\ngaze, in our previous work we showed that vanishing point attracts gaze during\nfree viewing of natural scenes as well as in visual search (Borji et al.,\nJournal of Vision 2016). We have also introduced improved saliency models using\nvanishing point detectors (Feng et al., WACV 2016). Here, we aim to predict\nvanishing points in naturalistic environments by training convolutional neural\nnetworks in an end-to-end manner over a large set of road images downloaded\nfrom Youtube with vanishing points annotated. Results demonstrate effectiveness\nof our approach compared to classic approaches of vanishing point detection in\nthe literature. \n\n"}
{"id": "1609.03986", "contents": "Title: The CUDA LATCH Binary Descriptor: Because Sometimes Faster Means Better Abstract: Accuracy, descriptor size, and the time required for extraction and matching\nare all important factors when selecting local image descriptors. To optimize\nover all these requirements, this paper presents a CUDA port for the recent\nLearned Arrangement of Three Patches (LATCH) binary descriptors to the GPU\nplatform. The design of LATCH makes it well suited for GPU processing. Owing to\nits small size and binary nature, the GPU can further be used to efficiently\nmatch LATCH features. Taken together, this leads to breakneck descriptor\nextraction and matching speeds. We evaluate the trade off between these speeds\nand the quality of results in a feature matching intensive application. To this\nend, we use our proposed CUDA LATCH (CLATCH) to recover structure from motion\n(SfM), comparing 3D reconstructions and speed using different representations.\nOur results show that CLATCH provides high quality 3D reconstructions at\nfractions of the time required by other representations, with little, if any,\nloss of reconstruction quality. \n\n"}
{"id": "1609.05600", "contents": "Title: Graph-Structured Representations for Visual Question Answering Abstract: This paper proposes to improve visual question answering (VQA) with\nstructured representations of both scene contents and questions. A key\nchallenge in VQA is to require joint reasoning over the visual and text\ndomains. The predominant CNN/LSTM-based approach to VQA is limited by\nmonolithic vector representations that largely ignore structure in the scene\nand in the form of the question. CNN feature vectors cannot effectively capture\nsituations as simple as multiple object instances, and LSTMs process questions\nas series of words, which does not reflect the true complexity of language\nstructure. We instead propose to build graphs over the scene objects and over\nthe question words, and we describe a deep neural network that exploits the\nstructure in these representations. This shows significant benefit over the\nsequential processing of LSTMs. The overall efficacy of our approach is\ndemonstrated by significant improvements over the state-of-the-art, from 71.2%\nto 74.4% in accuracy on the \"abstract scenes\" multiple-choice benchmark, and\nfrom 34.7% to 39.1% in accuracy over pairs of \"balanced\" scenes, i.e. images\nwith fine-grained differences and opposite yes/no answers to a same question. \n\n"}
{"id": "1609.06845", "contents": "Title: On the usability of deep networks for object-based image analysis Abstract: As computer vision before, remote sensing has been radically changed by the\nintroduction of Convolution Neural Networks. Land cover use, object detection\nand scene understanding in aerial images rely more and more on deep learning to\nachieve new state-of-the-art results. Recent architectures such as Fully\nConvolutional Networks (Long et al., 2015) can even produce pixel level\nannotations for semantic mapping. In this work, we show how to use such deep\nnetworks to detect, segment and classify different varieties of wheeled\nvehicles in aerial images from the ISPRS Potsdam dataset. This allows us to\ntackle object detection and classification on a complex dataset made up of\nvisually similar classes, and to demonstrate the relevance of such a subclass\nmodeling approach. Especially, we want to show that deep learning is also\nsuitable for object-oriented analysis of Earth Observation data. First, we\ntrain a FCN variant on the ISPRS Potsdam dataset and show how the learnt\nsemantic maps can be used to extract precise segmentation of vehicles, which\nallow us studying the repartition of vehicles in the city. Second, we train a\nCNN to perform vehicle classification on the VEDAI (Razakarivony and Jurie,\n2016) dataset, and transfer its knowledge to classify candidate segmented\nvehicles on the Potsdam dataset. \n\n"}
{"id": "1609.07093", "contents": "Title: Neural Photo Editing with Introspective Adversarial Networks Abstract: The increasingly photorealistic sample quality of generative image models\nsuggests their feasibility in applications beyond image generation. We present\nthe Neural Photo Editor, an interface that leverages the power of generative\nneural networks to make large, semantically coherent changes to existing\nimages. To tackle the challenge of achieving accurate reconstructions without\nloss of feature quality, we introduce the Introspective Adversarial Network, a\nnovel hybridization of the VAE and GAN. Our model efficiently captures\nlong-range dependencies through use of a computational block based on\nweight-shared dilated convolutions, and improves generalization performance\nwith Orthogonal Regularization, a novel weight regularization method. We\nvalidate our contributions on CelebA, SVHN, and CIFAR-100, and produce samples\nand reconstructions with high visual fidelity. \n\n"}
{"id": "1609.08209", "contents": "Title: Automatic Construction of a Recurrent Neural Network based Classifier\n  for Vehicle Passage Detection Abstract: Recurrent Neural Networks (RNNs) are extensively used for time-series\nmodeling and prediction. We propose an approach for automatic construction of a\nbinary classifier based on Long Short-Term Memory RNNs (LSTM-RNNs) for\ndetection of a vehicle passage through a checkpoint. As an input to the\nclassifier we use multidimensional signals of various sensors that are\ninstalled on the checkpoint. Obtained results demonstrate that the previous\napproach to handcrafting a classifier, consisting of a set of deterministic\nrules, can be successfully replaced by an automatic RNN training on an\nappropriately labelled data. \n\n"}
{"id": "1609.08221", "contents": "Title: Simultaneous Low-rank Component and Graph Estimation for\n  High-dimensional Graph Signals: Application to Brain Imaging Abstract: We propose an algorithm to uncover the intrinsic low-rank component of a\nhigh-dimensional, graph-smooth and grossly-corrupted dataset, under the\nsituations that the underlying graph is unknown. Based on a model with a\nlow-rank component plus a sparse perturbation, and an initial graph estimation,\nour proposed algorithm simultaneously learns the low-rank component and refines\nthe graph. Our evaluations using synthetic and real brain imaging data in\nunsupervised and supervised classification tasks demonstrate encouraging\nperformance. \n\n"}
{"id": "1609.09444", "contents": "Title: Contextual RNN-GANs for Abstract Reasoning Diagram Generation Abstract: Understanding, predicting, and generating object motions and transformations\nis a core problem in artificial intelligence. Modeling sequences of evolving\nimages may provide better representations and models of motion and may\nultimately be used for forecasting, simulation, or video generation.\nDiagrammatic Abstract Reasoning is an avenue in which diagrams evolve in\ncomplex patterns and one needs to infer the underlying pattern sequence and\ngenerate the next image in the sequence. For this, we develop a novel\nContextual Generative Adversarial Network based on Recurrent Neural Networks\n(Context-RNN-GANs), where both the generator and the discriminator modules are\nbased on contextual history (modeled as RNNs) and the adversarial discriminator\nguides the generator to produce realistic images for the particular time step\nin the image sequence. We evaluate the Context-RNN-GAN model (and its variants)\non a novel dataset of Diagrammatic Abstract Reasoning, where it performs\ncompetitively with 10th-grade human performance but there is still scope for\ninteresting improvements as compared to college-grade human performance. We\nalso evaluate our model on a standard video next-frame prediction task,\nachieving improved performance over comparable state-of-the-art. \n\n"}
{"id": "1609.09475", "contents": "Title: Multi-view Self-supervised Deep Learning for 6D Pose Estimation in the\n  Amazon Picking Challenge Abstract: Robot warehouse automation has attracted significant interest in recent\nyears, perhaps most visibly in the Amazon Picking Challenge (APC). A fully\nautonomous warehouse pick-and-place system requires robust vision that reliably\nrecognizes and locates objects amid cluttered environments, self-occlusions,\nsensor noise, and a large variety of objects. In this paper we present an\napproach that leverages multi-view RGB-D data and self-supervised, data-driven\nlearning to overcome those difficulties. The approach was part of the\nMIT-Princeton Team system that took 3rd- and 4th- place in the stowing and\npicking tasks, respectively at APC 2016. In the proposed approach, we segment\nand label multiple views of a scene with a fully convolutional neural network,\nand then fit pre-scanned 3D object models to the resulting segmentation to get\nthe 6D object pose. Training a deep neural network for segmentation typically\nrequires a large amount of training data. We propose a self-supervised method\nto generate a large labeled dataset without tedious manual segmentation. We\ndemonstrate that our system can reliably estimate the 6D pose of objects under\na variety of scenarios. All code, data, and benchmarks are available at\nhttp://apc.cs.princeton.edu/ \n\n"}
{"id": "1610.00291", "contents": "Title: Deep Feature Consistent Variational Autoencoder Abstract: We present a novel method for constructing Variational Autoencoder (VAE).\nInstead of using pixel-by-pixel loss, we enforce deep feature consistency\nbetween the input and the output of a VAE, which ensures the VAE's output to\npreserve the spatial correlation characteristics of the input, thus leading the\noutput to have a more natural visual appearance and better perceptual quality.\nBased on recent deep learning works such as style transfer, we employ a\npre-trained deep convolutional neural network (CNN) and use its hidden features\nto define a feature perceptual loss for VAE training. Evaluated on the CelebA\nface dataset, we show that our model produces better results than other methods\nin the literature. We also show that our method can produce latent vectors that\ncan capture the semantic information of face expressions and can be used to\nachieve state-of-the-art performance in facial attribute prediction. \n\n"}
{"id": "1610.00893", "contents": "Title: Adaptive Graph-based Total Variation for Tomographic Reconstructions Abstract: Sparsity exploiting image reconstruction (SER) methods have been extensively\nused with Total Variation (TV) regularization for tomographic reconstructions.\nLocal TV methods fail to preserve texture details and often create additional\nartefacts due to over-smoothing. Non-Local TV (NLTV) methods have been proposed\nas a solution to this but they either lack continuous updates due to\ncomputational constraints or limit the locality to a small region. In this\npaper, we propose Adaptive Graph-based TV (AGTV). The proposed method goes\nbeyond spatial similarity between different regions of an image being\nreconstructed by establishing a connection between similar regions in the\nentire image regardless of spatial distance. As compared to NLTV the proposed\nmethod is computationally efficient and involves updating the graph prior\nduring every iteration making the connection between similar regions stronger.\nMoreover, it promotes sparsity in the wavelet and graph gradient domains. Since\nTV is a special case of graph TV the proposed method can also be seen as a\ngeneralization of SER and TV methods. \n\n"}
{"id": "1610.01685", "contents": "Title: Supervision via Competition: Robot Adversaries for Learning Tasks Abstract: There has been a recent paradigm shift in robotics to data-driven learning\nfor planning and control. Due to large number of experiences required for\ntraining, most of these approaches use a self-supervised paradigm: using\nsensors to measure success/failure. However, in most cases, these sensors\nprovide weak supervision at best. In this work, we propose an adversarial\nlearning framework that pits an adversary against the robot learning the task.\nIn an effort to defeat the adversary, the original robot learns to perform the\ntask with more robustness leading to overall improved performance. We show that\nthis adversarial framework forces the the robot to learn a better grasping\nmodel in order to overcome the adversary. By grasping 82% of presented novel\nobjects compared to 68% without an adversary, we demonstrate the utility of\ncreating adversaries. We also demonstrate via experiments that having robots in\nadversarial setting might be a better learning strategy as compared to having\ncollaborative multiple robots. \n\n"}
{"id": "1610.02177", "contents": "Title: Automatic Liver and Lesion Segmentation in CT Using Cascaded Fully\n  Convolutional Neural Networks and 3D Conditional Random Fields Abstract: Automatic segmentation of the liver and its lesion is an important step\ntowards deriving quantitative biomarkers for accurate clinical diagnosis and\ncomputer-aided decision support systems. This paper presents a method to\nautomatically segment liver and lesions in CT abdomen images using cascaded\nfully convolutional neural networks (CFCNs) and dense 3D conditional random\nfields (CRFs). We train and cascade two FCNs for a combined segmentation of the\nliver and its lesions. In the first step, we train a FCN to segment the liver\nas ROI input for a second FCN. The second FCN solely segments lesions from the\npredicted liver ROIs of step 1. We refine the segmentations of the CFCN using a\ndense 3D CRF that accounts for both spatial coherence and appearance. CFCN\nmodels were trained in a 2-fold cross-validation on the abdominal CT dataset\n3DIRCAD comprising 15 hepatic tumor volumes. Our results show that CFCN-based\nsemantic liver and lesion segmentation achieves Dice scores over 94% for liver\nwith computation times below 100s per volume. We experimentally demonstrate the\nrobustness of the proposed method as a decision support system with a high\naccuracy and speed for usage in daily clinical routine. \n\n"}
{"id": "1610.02391", "contents": "Title: Grad-CAM: Visual Explanations from Deep Networks via Gradient-based\n  Localization Abstract: We propose a technique for producing \"visual explanations\" for decisions from\na large class of CNN-based models, making them more transparent. Our approach -\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of\nany target concept, flowing into the final convolutional layer to produce a\ncoarse localization map highlighting important regions in the image for\npredicting the concept. Grad-CAM is applicable to a wide variety of CNN\nmodel-families: (1) CNNs with fully-connected layers, (2) CNNs used for\nstructured outputs, (3) CNNs used in tasks with multimodal inputs or\nreinforcement learning, without any architectural changes or re-training. We\ncombine Grad-CAM with fine-grained visualizations to create a high-resolution\nclass-discriminative visualization and apply it to off-the-shelf image\nclassification, captioning, and visual question answering (VQA) models,\nincluding ResNet-based architectures. In the context of image classification\nmodels, our visualizations (a) lend insights into their failure modes, (b) are\nrobust to adversarial images, (c) outperform previous methods on localization,\n(d) are more faithful to the underlying model and (e) help achieve\ngeneralization by identifying dataset bias. For captioning and VQA, we show\nthat even non-attention based models can localize inputs. We devise a way to\nidentify important neurons through Grad-CAM and combine it with neuron names to\nprovide textual explanations for model decisions. Finally, we design and\nconduct human studies to measure if Grad-CAM helps users establish appropriate\ntrust in predictions from models and show that Grad-CAM helps untrained users\nsuccessfully discern a 'stronger' nodel from a 'weaker' one even when both make\nidentical predictions. Our code is available at\nhttps://github.com/ramprs/grad-cam/, along with a demo at\nhttp://gradcam.cloudcv.org, and a video at youtu.be/COjUB9Izk6E. \n\n"}
{"id": "1610.05211", "contents": "Title: Structured Sparse Subspace Clustering: A Joint Affinity Learning and\n  Subspace Clustering Framework Abstract: Subspace clustering refers to the problem of segmenting data drawn from a\nunion of subspaces. State-of-the-art approaches for solving this problem follow\na two-stage approach. In the first step, an affinity matrix is learned from the\ndata using sparse or low-rank minimization techniques. In the second step, the\nsegmentation is found by applying spectral clustering to this affinity. While\nthis approach has led to state-of-the-art results in many applications, it is\nsub-optimal because it does not exploit the fact that the affinity and the\nsegmentation depend on each other. In this paper, we propose a joint\noptimization framework --- Structured Sparse Subspace Clustering (S$^3$C) ---\nfor learning both the affinity and the segmentation. The proposed S$^3$C\nframework is based on expressing each data point as a structured sparse linear\ncombination of all other data points, where the structure is induced by a norm\nthat depends on the unknown segmentation. Moreover, we extend the proposed\nS$^3$C framework into Constrained Structured Sparse Subspace Clustering\n(CS$^3$C) in which available partial side-information is incorporated into the\nstage of learning the affinity. We show that both the structured sparse\nrepresentation and the segmentation can be found via a combination of an\nalternating direction method of multipliers with spectral clustering.\nExperiments on a synthetic data set, the Extended Yale B data set, the Hopkins\n155 motion segmentation database, and three cancer data sets demonstrate the\neffectiveness of our approach. \n\n"}
{"id": "1610.05541", "contents": "Title: M2CAI Workflow Challenge: Convolutional Neural Networks with Time\n  Smoothing and Hidden Markov Model for Video Frames Classification Abstract: Our approach is among the three best to tackle the M2CAI Workflow challenge.\nThe latter consists in recognizing the operation phase for each frames of\nendoscopic videos. In this technical report, we compare several classification\nmodels and temporal smoothing methods. Our submitted solution is a fine tuned\nResidual Network-200 on 80% of the training set with temporal smoothing using\nsimple temporal averaging of the predictions and a Hidden Markov Model modeling\nthe sequence. \n\n"}
{"id": "1610.06453", "contents": "Title: Change-point Detection Methods for Body-Worn Video Abstract: Body-worn video (BWV) cameras are increasingly utilized by police departments\nto provide a record of police-public interactions. However, large-scale BWV\ndeployment produces terabytes of data per week, necessitating the development\nof effective computational methods to identify salient changes in video. In\nwork carried out at the 2016 RIPS program at IPAM, UCLA, we present a novel\ntwo-stage framework for video change-point detection. First, we employ\nstate-of-the-art machine learning methods including convolutional neural\nnetworks and support vector machines for scene classification. We then develop\nand compare change-point detection algorithms utilizing mean squared-error\nminimization, forecasting methods, hidden Markov models, and maximum likelihood\nestimation to identify noteworthy changes. We test our framework on detection\nof vehicle exits and entrances in a BWV data set provided by the Los Angeles\nPolice Department and achieve over 90% recall and nearly 70% precision --\ndemonstrating robustness to rapid scene changes, extreme luminance differences,\nand frequent camera occlusions. \n\n"}
{"id": "1610.07008", "contents": "Title: Optimization on Submanifolds of Convolution Kernels in CNNs Abstract: Kernel normalization methods have been employed to improve robustness of\noptimization methods to reparametrization of convolution kernels, covariate\nshift, and to accelerate training of Convolutional Neural Networks (CNNs).\nHowever, our understanding of theoretical properties of these methods has\nlagged behind their success in applications. We develop a geometric framework\nto elucidate underlying mechanisms of a diverse range of kernel normalization\nmethods. Our framework enables us to expound and identify geometry of space of\nnormalized kernels. We analyze and delineate how state-of-the-art kernel\nnormalization methods affect the geometry of search spaces of the stochastic\ngradient descent (SGD) algorithms in CNNs. Following our theoretical results,\nwe propose a SGD algorithm with assurance of almost sure convergence of the\nmethods to a solution at single minimum of classification loss of CNNs.\nExperimental results show that the proposed method achieves state-of-the-art\nperformance for major image classification benchmarks with CNNs. \n\n"}
{"id": "1610.07432", "contents": "Title: Virtual Embodiment: A Scalable Long-Term Strategy for Artificial\n  Intelligence Research Abstract: Meaning has been called the \"holy grail\" of a variety of scientific\ndisciplines, ranging from linguistics to philosophy, psychology and the\nneurosciences. The field of Artifical Intelligence (AI) is very much a part of\nthat list: the development of sophisticated natural language semantics is a\nsine qua non for achieving a level of intelligence comparable to humans.\nEmbodiment theories in cognitive science hold that human semantic\nrepresentation depends on sensori-motor experience; the abundant evidence that\nhuman meaning representation is grounded in the perception of physical reality\nleads to the conclusion that meaning must depend on a fusion of multiple\n(perceptual) modalities. Despite this, AI research in general, and its\nsubdisciplines such as computational linguistics and computer vision in\nparticular, have focused primarily on tasks that involve a single modality.\nHere, we propose virtual embodiment as an alternative, long-term strategy for\nAI research that is multi-modal in nature and that allows for the kind of\nscalability required to develop the field coherently and incrementally, in an\nethically responsible fashion. \n\n"}
{"id": "1610.08481", "contents": "Title: Mask-off: Synthesizing Face Images in the Presence of Head-mounted\n  Displays Abstract: A head-mounted display (HMD) could be an important component of augmented\nreality system. However, as the upper face region is seriously occluded by the\ndevice, the user experience could be affected in applications such as\ntelecommunication and multi-player video games. In this paper, we first present\na novel experimental setup that consists of two near-infrared (NIR) cameras to\npoint to the eye regions and one visible-light RGB camera to capture the\nvisible face region. The main purpose of this paper is to synthesize realistic\nface images without occlusions based on the images captured by these cameras.\nTo this end, we propose a novel synthesis framework that contains four modules:\n3D head reconstruction, face alignment and tracking, face synthesis, and eye\nsynthesis. In face synthesis, we propose a novel algorithm that can robustly\nalign and track a personalized 3D head model given a face that is severely\noccluded by the HMD. In eye synthesis, in order to generate accurate eye\nmovements and dynamic wrinkle variations around eye regions, we propose another\nnovel algorithm to colorize the NIR eye images and further remove the \"red eye\"\neffects caused by the colorization. Results show that both hardware setup and\nsystem framework are robust to synthesize realistic face images in video\nsequences. \n\n"}
{"id": "1611.00850", "contents": "Title: Optical Flow Estimation using a Spatial Pyramid Network Abstract: We learn to compute optical flow by combining a classical spatial-pyramid\nformulation with deep learning. This estimates large motions in a\ncoarse-to-fine approach by warping one image of a pair at each pyramid level by\nthe current flow estimate and computing an update to the flow. Instead of the\nstandard minimization of an objective function at each pyramid level, we train\none deep network per level to compute the flow update. Unlike the recent\nFlowNet approach, the networks do not need to deal with large motions; these\nare dealt with by the pyramid. This has several advantages. First, our Spatial\nPyramid Network (SPyNet) is much simpler and 96% smaller than FlowNet in terms\nof model parameters. This makes it more efficient and appropriate for embedded\napplications. Second, since the flow at each pyramid level is small (< 1\npixel), a convolutional approach applied to pairs of warped images is\nappropriate. Third, unlike FlowNet, the learned convolution filters appear\nsimilar to classical spatio-temporal filters, giving insight into the method\nand how to improve it. Our results are more accurate than FlowNet on most\nstandard benchmarks, suggesting a new direction of combining classical flow\nmethods with deep learning. \n\n"}
{"id": "1611.00851", "contents": "Title: An All-In-One Convolutional Neural Network for Face Analysis Abstract: We present a multi-purpose algorithm for simultaneous face detection, face\nalignment, pose estimation, gender recognition, smile detection, age estimation\nand face recognition using a single deep convolutional neural network (CNN).\nThe proposed method employs a multi-task learning framework that regularizes\nthe shared parameters of CNN and builds a synergy among different domains and\ntasks. Extensive experiments show that the network has a better understanding\nof face and achieves state-of-the-art result for most of these tasks. \n\n"}
{"id": "1611.01331", "contents": "Title: RenderGAN: Generating Realistic Labeled Data Abstract: Deep Convolutional Neuronal Networks (DCNNs) are showing remarkable\nperformance on many computer vision tasks. Due to their large parameter space,\nthey require many labeled samples when trained in a supervised setting. The\ncosts of annotating data manually can render the use of DCNNs infeasible. We\npresent a novel framework called RenderGAN that can generate large amounts of\nrealistic, labeled images by combining a 3D model and the Generative\nAdversarial Network framework. In our approach, image augmentations (e.g.\nlighting, background, and detail) are learned from unlabeled data such that the\ngenerated images are strikingly realistic while preserving the labels known\nfrom the 3D model. We apply the RenderGAN framework to generate images of\nbarcode-like markers that are attached to honeybees. Training a DCNN on data\ngenerated by the RenderGAN yields considerably better performance than training\nit on various baselines. \n\n"}
{"id": "1611.01779", "contents": "Title: Learning to Act by Predicting the Future Abstract: We present an approach to sensorimotor control in immersive environments. Our\napproach utilizes a high-dimensional sensory stream and a lower-dimensional\nmeasurement stream. The cotemporal structure of these streams provides a rich\nsupervisory signal, which enables training a sensorimotor control model by\ninteracting with the environment. The model is trained using supervised\nlearning techniques, but without extraneous supervision. It learns to act based\non raw sensory input from a complex three-dimensional environment. The\npresented formulation enables learning without a fixed goal at training time,\nand pursuing dynamically changing goals at test time. We conduct extensive\nexperiments in three-dimensional simulations based on the classical\nfirst-person game Doom. The results demonstrate that the presented approach\noutperforms sophisticated prior formulations, particularly on challenging\ntasks. The results also show that trained models successfully generalize across\nenvironments and goals. A model trained using the presented approach won the\nFull Deathmatch track of the Visual Doom AI Competition, which was held in\npreviously unseen environments. \n\n"}
{"id": "1611.04201", "contents": "Title: CAD2RL: Real Single-Image Flight without a Single Real Image Abstract: Deep reinforcement learning has emerged as a promising and powerful technique\nfor automatically acquiring control policies that can process raw sensory\ninputs, such as images, and perform complex behaviors. However, extending deep\nRL to real-world robotic tasks has proven challenging, particularly in\nsafety-critical domains such as autonomous flight, where a trial-and-error\nlearning process is often impractical. In this paper, we explore the following\nquestion: can we train vision-based navigation policies entirely in simulation,\nand then transfer them into the real world to achieve real-world flight without\na single real training image? We propose a learning method that we call\nCAD$^2$RL, which can be used to perform collision-free indoor flight in the\nreal world while being trained entirely on 3D CAD models. Our method uses\nsingle RGB images from a monocular camera, without needing to explicitly\nreconstruct the 3D geometry of the environment or perform explicit motion\nplanning. Our learned collision avoidance policy is represented by a deep\nconvolutional neural network that directly processes raw monocular images and\noutputs velocity commands. This policy is trained entirely on simulated images,\nwith a Monte Carlo policy evaluation algorithm that directly optimizes the\nnetwork's ability to produce collision-free flight. By highly randomizing the\nrendering settings for our simulated training set, we show that we can train a\npolicy that generalizes to the real world, without requiring the simulator to\nbe particularly realistic or high-fidelity. We evaluate our method by flying a\nreal quadrotor through indoor environments, and further evaluate the design\nchoices in our simulator through a series of ablation studies on depth\nprediction. For supplementary video see: https://youtu.be/nXBWmzFrj5s \n\n"}
{"id": "1611.05138", "contents": "Title: S3Pool: Pooling with Stochastic Spatial Sampling Abstract: Feature pooling layers (e.g., max pooling) in convolutional neural networks\n(CNNs) serve the dual purpose of providing increasingly abstract\nrepresentations as well as yielding computational savings in subsequent\nconvolutional layers. We view the pooling operation in CNNs as a two-step\nprocedure: first, a pooling window (e.g., $2\\times 2$) slides over the feature\nmap with stride one which leaves the spatial resolution intact, and second,\ndownsampling is performed by selecting one pixel from each non-overlapping\npooling window in an often uniform and deterministic (e.g., top-left) manner.\nOur starting point in this work is the observation that this regularly spaced\ndownsampling arising from non-overlapping windows, although intuitive from a\nsignal processing perspective (which has the goal of signal reconstruction), is\nnot necessarily optimal for \\emph{learning} (where the goal is to generalize).\nWe study this aspect and propose a novel pooling strategy with stochastic\nspatial sampling (S3Pool), where the regular downsampling is replaced by a more\ngeneral stochastic version. We observe that this general stochasticity acts as\na strong regularizer, and can also be seen as doing implicit data augmentation\nby introducing distortions in the feature maps. We further introduce a\nmechanism to control the amount of distortion to suit different datasets and\narchitectures. To demonstrate the effectiveness of the proposed approach, we\nperform extensive experiments on several popular image classification\nbenchmarks, observing excellent improvements over baseline models. Experimental\ncode is available at https://github.com/Shuangfei/s3pool. \n\n"}
{"id": "1611.05335", "contents": "Title: Unsupervised Learning of Important Objects from First-Person Videos Abstract: A first-person camera, placed at a person's head, captures, which objects are\nimportant to the camera wearer. Most prior methods for this task learn to\ndetect such important objects from the manually labeled first-person data in a\nsupervised fashion. However, important objects are strongly related to the\ncamera wearer's internal state such as his intentions and attention, and thus,\nonly the person wearing the camera can provide the importance labels. Such a\nconstraint makes the annotation process costly and limited in scalability.\n  In this work, we show that we can detect important objects in first-person\nimages without the supervision by the camera wearer or even third-person\nlabelers. We formulate an important detection problem as an interplay between\nthe 1) segmentation and 2) recognition agents. The segmentation agent first\nproposes a possible important object segmentation mask for each image, and then\nfeeds it to the recognition agent, which learns to predict an important object\nmask using visual semantics and spatial features.\n  We implement such an interplay between both agents via an alternating\ncross-pathway supervision scheme inside our proposed Visual-Spatial Network\n(VSN). Our VSN consists of spatial (\"where\") and visual (\"what\") pathways, one\nof which learns common visual semantics while the other focuses on the spatial\nlocation cues. Our unsupervised learning is accomplished via a cross-pathway\nsupervision, where one pathway feeds its predictions to a segmentation agent,\nwhich proposes a candidate important object segmentation mask that is then used\nby the other pathway as a supervisory signal. We show our method's success on\ntwo different important object datasets, where our method achieves similar or\nbetter results as the supervised methods. \n\n"}
{"id": "1611.05368", "contents": "Title: Neural Style Representations and the Large-Scale Classification of\n  Artistic Style Abstract: The artistic style of a painting is a subtle aesthetic judgment used by art\nhistorians for grouping and classifying artwork. The recently introduced\n`neural-style' algorithm substantially succeeds in merging the perceived\nartistic style of one image or set of images with the perceived content of\nanother. In light of this and other recent developments in image analysis via\nconvolutional neural networks, we investigate the effectiveness of a\n`neural-style' representation for classifying the artistic style of paintings. \n\n"}
{"id": "1611.05418", "contents": "Title: VisualBackProp: efficient visualization of CNNs Abstract: This paper proposes a new method, that we call VisualBackProp, for\nvisualizing which sets of pixels of the input image contribute most to the\npredictions made by the convolutional neural network (CNN). The method heavily\nhinges on exploring the intuition that the feature maps contain less and less\nirrelevant information to the prediction decision when moving deeper into the\nnetwork. The technique we propose was developed as a debugging tool for\nCNN-based systems for steering self-driving cars and is therefore required to\nrun in real-time, i.e. it was designed to require less computations than a\nforward propagation. This makes the presented visualization method a valuable\ndebugging tool which can be easily used during both training and inference. We\nfurthermore justify our approach with theoretical arguments and theoretically\nconfirm that the proposed method identifies sets of input pixels, rather than\nindividual pixels, that collaboratively contribute to the prediction. Our\ntheoretical findings stand in agreement with the experimental results. The\nempirical evaluation shows the plausibility of the proposed approach on the\nroad video data as well as in other applications and reveals that it compares\nfavorably to the layer-wise relevance propagation approach, i.e. it obtains\nsimilar visualization results and simultaneously achieves order of magnitude\nspeed-ups. \n\n"}
{"id": "1611.05896", "contents": "Title: Answering Image Riddles using Vision and Reasoning through Probabilistic\n  Soft Logic Abstract: In this work, we explore a genre of puzzles (\"image riddles\") which involves\na set of images and a question. Answering these puzzles require both\ncapabilities involving visual detection (including object, activity\nrecognition) and, knowledge-based or commonsense reasoning. We compile a\ndataset of over 3k riddles where each riddle consists of 4 images and a\ngroundtruth answer. The annotations are validated using crowd-sourced\nevaluation. We also define an automatic evaluation metric to track future\nprogress. Our task bears similarity with the commonly known IQ tasks such as\nanalogy solving, sequence filling that are often used to test intelligence.\n  We develop a Probabilistic Reasoning-based approach that utilizes\nprobabilistic commonsense knowledge to answer these riddles with a reasonable\naccuracy. We demonstrate the results of our approach using both automatic and\nhuman evaluations. Our approach achieves some promising results for these\nriddles and provides a strong baseline for future attempts. We make the entire\ndataset and related materials publicly available to the community in\nImageRiddle Website (http://bit.ly/22f9Ala). \n\n"}
{"id": "1611.05927", "contents": "Title: Generalized BackPropagation, \\'{E}tude De Cas: Orthogonality Abstract: This paper introduces an extension of the backpropagation algorithm that\nenables us to have layers with constrained weights in a deep network. In\nparticular, we make use of the Riemannian geometry and optimization techniques\non matrix manifolds to step outside of normal practice in training deep\nnetworks, equipping the network with structures such as orthogonality or\npositive definiteness. Based on our development, we make another contribution\nby introducing the Stiefel layer, a layer with orthogonal weights. Among\nvarious applications, Stiefel layers can be used to design orthogonal filter\nbanks, perform dimensionality reduction and feature extraction. We demonstrate\nthe benefits of having orthogonality in deep networks through a broad set of\nexperiments, ranging from unsupervised feature learning to fine-grained image\nclassification. \n\n"}
{"id": "1611.05947", "contents": "Title: Minimal Problems for the Calibrated Trifocal Variety Abstract: We determine the algebraic degree of minimal problems for the calibrated\ntrifocal variety in computer vision. We rely on numerical algebraic geometry\nand the homotopy continuation software Bertini. \n\n"}
{"id": "1611.06211", "contents": "Title: NoiseOut: A Simple Way to Prune Neural Networks Abstract: Neural networks are usually over-parameterized with significant redundancy in\nthe number of required neurons which results in unnecessary computation and\nmemory usage at inference time. One common approach to address this issue is to\nprune these big networks by removing extra neurons and parameters while\nmaintaining the accuracy. In this paper, we propose NoiseOut, a fully automated\npruning algorithm based on the correlation between activations of neurons in\nthe hidden layers. We prove that adding additional output neurons with entirely\nrandom targets results into a higher correlation between neurons which makes\npruning by NoiseOut even more efficient. Finally, we test our method on various\nnetworks and datasets. These experiments exhibit high pruning rates while\nmaintaining the accuracy of the original network. \n\n"}
{"id": "1611.06307", "contents": "Title: Multi-Scale Saliency Detection using Dictionary Learning Abstract: Saliency detection has drawn a lot of attention of researchers in various\nfields over the past several years. Saliency is the perceptual quality that\nmakes an object, person to draw the attention of humans at the very sight.\nSalient object detection in an image has been used centrally in many\ncomputational photography and computer vision applications like video\ncompression, object recognition and classification, object segmentation,\nadaptive content delivery, motion detection, content aware resizing, camouflage\nimages and change blindness images to name a few. We propose a method to detect\nsaliency in the objects using multimodal dictionary learning which has been\nrecently used in classification and image fusion. The multimodal dictionary\nthat we are learning is task driven which gives improved performance over its\ncounterpart (the one which is not task specific). \n\n"}
{"id": "1611.06473", "contents": "Title: LCNN: Lookup-based Convolutional Neural Network Abstract: Porting state of the art deep learning algorithms to resource constrained\ncompute platforms (e.g. VR, AR, wearables) is extremely challenging. We propose\na fast, compact, and accurate model for convolutional neural networks that\nenables efficient learning and inference. We introduce LCNN, a lookup-based\nconvolutional neural network that encodes convolutions by few lookups to a\ndictionary that is trained to cover the space of weights in CNNs. Training LCNN\ninvolves jointly learning a dictionary and a small set of linear combinations.\nThe size of the dictionary naturally traces a spectrum of trade-offs between\nefficiency and accuracy. Our experimental results on ImageNet challenge show\nthat LCNN can offer 3.2x speedup while achieving 55.1% top-1 accuracy using\nAlexNet architecture. Our fastest LCNN offers 37.6x speed up over AlexNet while\nmaintaining 44.3% top-1 accuracy. LCNN not only offers dramatic speed ups at\ninference, but it also enables efficient training. In this paper, we show the\nbenefits of LCNN in few-shot learning and few-iteration learning, two crucial\naspects of on-device training of deep learning models. \n\n"}
{"id": "1611.06612", "contents": "Title: RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic\n  Segmentation Abstract: Recently, very deep convolutional neural networks (CNNs) have shown\noutstanding performance in object recognition and have also been the first\nchoice for dense classification problems such as semantic segmentation.\nHowever, repeated subsampling operations like pooling or convolution striding\nin deep CNNs lead to a significant decrease in the initial image resolution.\nHere, we present RefineNet, a generic multi-path refinement network that\nexplicitly exploits all the information available along the down-sampling\nprocess to enable high-resolution prediction using long-range residual\nconnections. In this way, the deeper layers that capture high-level semantic\nfeatures can be directly refined using fine-grained features from earlier\nconvolutions. The individual components of RefineNet employ residual\nconnections following the identity mapping mindset, which allows for effective\nend-to-end training. Further, we introduce chained residual pooling, which\ncaptures rich background context in an efficient manner. We carry out\ncomprehensive experiments and set new state-of-the-art results on seven public\ndatasets. In particular, we achieve an intersection-over-union score of 83.4 on\nthe challenging PASCAL VOC 2012 dataset, which is the best reported result to\ndate. \n\n"}
{"id": "1611.06949", "contents": "Title: Dense Captioning with Joint Inference and Visual Context Abstract: Dense captioning is a newly emerging computer vision topic for understanding\nimages with dense language descriptions. The goal is to densely detect visual\nconcepts (e.g., objects, object parts, and interactions between them) from\nimages, labeling each with a short descriptive phrase. We identify two key\nchallenges of dense captioning that need to be properly addressed when tackling\nthe problem. First, dense visual concept annotations in each image are\nassociated with highly overlapping target regions, making accurate localization\nof each visual concept challenging. Second, the large amount of visual concepts\nmakes it hard to recognize each of them by appearance alone. We propose a new\nmodel pipeline based on two novel ideas, joint inference and context fusion, to\nalleviate these two challenges. We design our model architecture in a\nmethodical manner and thoroughly evaluate the variations in architecture. Our\nfinal model, compact and efficient, achieves state-of-the-art accuracy on\nVisual Genome for dense captioning with a relative gain of 73\\% compared to the\nprevious best algorithm. Qualitative experiments also reveal the semantic\ncapabilities of our model in dense captioning. \n\n"}
{"id": "1611.07119", "contents": "Title: Max-Margin Deep Generative Models for (Semi-)Supervised Learning Abstract: Deep generative models (DGMs) are effective on learning multilayered\nrepresentations of complex data and performing inference of input data by\nexploring the generative ability. However, it is relatively insufficient to\nempower the discriminative ability of DGMs on making accurate predictions. This\npaper presents max-margin deep generative models (mmDGMs) and a\nclass-conditional variant (mmDCGMs), which explore the strongly discriminative\nprinciple of max-margin learning to improve the predictive performance of DGMs\nin both supervised and semi-supervised learning, while retaining the generative\ncapability. In semi-supervised learning, we use the predictions of a max-margin\nclassifier as the missing labels instead of performing full posterior inference\nfor efficiency; we also introduce additional max-margin and label-balance\nregularization terms of unlabeled data for effectiveness. We develop an\nefficient doubly stochastic subgradient algorithm for the piecewise linear\nobjectives in different settings. Empirical results on various datasets\ndemonstrate that: (1) max-margin learning can significantly improve the\nprediction performance of DGMs and meanwhile retain the generative ability; (2)\nin supervised learning, mmDGMs are competitive to the best fully discriminative\nnetworks when employing convolutional neural networks as the generative and\nrecognition models; and (3) in semi-supervised learning, mmDCGMs can perform\nefficient inference and achieve state-of-the-art classification results on\nseveral benchmarks. \n\n"}
{"id": "1611.07661", "contents": "Title: Multigrid Neural Architectures Abstract: We propose a multigrid extension of convolutional neural networks (CNNs).\nRather than manipulating representations living on a single spatial grid, our\nnetwork layers operate across scale space, on a pyramid of grids. They consume\nmultigrid inputs and produce multigrid outputs; convolutional filters\nthemselves have both within-scale and cross-scale extent. This aspect is\ndistinct from simple multiscale designs, which only process the input at\ndifferent scales. Viewed in terms of information flow, a multigrid network\npasses messages across a spatial pyramid. As a consequence, receptive field\nsize grows exponentially with depth, facilitating rapid integration of context.\nMost critically, multigrid structure enables networks to learn internal\nattention and dynamic routing mechanisms, and use them to accomplish tasks on\nwhich modern CNNs fail.\n  Experiments demonstrate wide-ranging performance advantages of multigrid. On\nCIFAR and ImageNet classification tasks, flipping from a single grid to\nmultigrid within the standard CNN paradigm improves accuracy, while being\ncompute and parameter efficient. Multigrid is independent of other\narchitectural choices; we show synergy in combination with residual\nconnections. Multigrid yields dramatic improvement on a synthetic semantic\nsegmentation dataset. Most strikingly, relatively shallow multigrid networks\ncan learn to directly perform spatial transformation tasks, where, in contrast,\ncurrent CNNs fail. Together, our results suggest that continuous evolution of\nfeatures on a multigrid pyramid is a more powerful alternative to existing CNN\ndesigns on a flat grid. \n\n"}
{"id": "1611.07810", "contents": "Title: A dataset and exploration of models for understanding video data through\n  fill-in-the-blank question-answering Abstract: While deep convolutional neural networks frequently approach or exceed\nhuman-level performance at benchmark tasks involving static images, extending\nthis success to moving images is not straightforward. Having models which can\nlearn to understand video is of interest for many applications, including\ncontent recommendation, prediction, summarization, event/object detection and\nunderstanding human visual perception, but many domains lack sufficient data to\nexplore and perfect video models. In order to address the need for a simple,\nquantitative benchmark for developing and understanding video, we present\nMovieFIB, a fill-in-the-blank question-answering dataset with over 300,000\nexamples, based on descriptive video annotations for the visually impaired. In\naddition to presenting statistics and a description of the dataset, we perform\na detailed analysis of 5 different models' predictions, and compare these with\nhuman performance. We investigate the relative importance of language, static\n(2D) visual features, and moving (3D) visual features; the effects of\nincreasing dataset size, the number of frames sampled; and of vocabulary size.\nWe illustrate that: this task is not solvable by a language model alone; our\nmodel combining 2D and 3D visual information indeed provides the best result;\nall models perform significantly worse than human-level. We provide human\nevaluations for responses given by different models and find that accuracy on\nthe MovieFIB evaluation corresponds well with human judgement. We suggest\navenues for improving video models, and hope that the proposed dataset can be\nuseful for measuring and encouraging progress in this very interesting field. \n\n"}
{"id": "1611.08229", "contents": "Title: Fast Orthonormal Sparsifying Transforms Based on Householder Reflectors Abstract: Dictionary learning is the task of determining a data-dependent transform\nthat yields a sparse representation of some observed data. The dictionary\nlearning problem is non-convex, and usually solved via computationally complex\niterative algorithms. Furthermore, the resulting transforms obtained generally\nlack structure that permits their fast application to data. To address this\nissue, this paper develops a framework for learning orthonormal dictionaries\nwhich are built from products of a few Householder reflectors. Two algorithms\nare proposed to learn the reflector coefficients: one that considers a\nsequential update of the reflectors and one with a simultaneous update of all\nreflectors that imposes an additional internal orthogonal constraint. The\nproposed methods have low computational complexity and are shown to converge to\nlocal minimum points which can be described in terms of the spectral properties\nof the matrices involved. The resulting dictionaries balance between the\ncomputational complexity and the quality of the sparse representations by\ncontrolling the number of Householder reflectors in their product. Simulations\nof the proposed algorithms are shown in the image processing setting where\nwell-known fast transforms are available for comparisons. The proposed\nalgorithms have favorable reconstruction error and the advantage of a fast\nimplementation relative to the classical, unstructured, dictionaries. \n\n"}
{"id": "1611.08663", "contents": "Title: Multi-Task Zero-Shot Action Recognition with Prioritised Data\n  Augmentation Abstract: Zero-Shot Learning (ZSL) promises to scale visual recognition by bypassing\nthe conventional model training requirement of annotated examples for every\ncategory. This is achieved by establishing a mapping connecting low-level\nfeatures and a semantic description of the label space, referred as\nvisual-semantic mapping, on auxiliary data. Reusing the learned mapping to\nproject target videos into an embedding space thus allows novel-classes to be\nrecognised by nearest neighbour inference. However, existing ZSL methods suffer\nfrom auxiliary-target domain shift intrinsically induced by assuming the same\nmapping for the disjoint auxiliary and target classes. This compromises the\ngeneralisation accuracy of ZSL recognition on the target data. In this work, we\nimprove the ability of ZSL to generalise across this domain shift in both\nmodel- and data-centric ways by formulating a visual-semantic mapping with\nbetter generalisation properties and a dynamic data re-weighting method to\nprioritise auxiliary data that are relevant to the target classes.\nSpecifically: (1) We introduce a multi-task visual-semantic mapping to improve\ngeneralisation by constraining the semantic mapping parameters to lie on a\nlow-dimensional manifold, (2) We explore prioritised data augmentation by\nexpanding the pool of auxiliary data with additional instances weighted by\nrelevance to the target domain. The proposed new model is applied to the\nchallenging zero-shot action recognition problem to demonstrate its advantages\nover existing ZSL models. \n\n"}
{"id": "1611.08669", "contents": "Title: Visual Dialog Abstract: We introduce the task of Visual Dialog, which requires an AI agent to hold a\nmeaningful dialog with humans in natural, conversational language about visual\ncontent. Specifically, given an image, a dialog history, and a question about\nthe image, the agent has to ground the question in image, infer context from\nhistory, and answer the question accurately. Visual Dialog is disentangled\nenough from a specific downstream task so as to serve as a general test of\nmachine intelligence, while being grounded in vision enough to allow objective\nevaluation of individual responses and benchmark progress. We develop a novel\ntwo-person chat data-collection protocol to curate a large-scale Visual Dialog\ndataset (VisDial). VisDial v0.9 has been released and contains 1 dialog with 10\nquestion-answer pairs on ~120k images from COCO, with a total of ~1.2M dialog\nquestion-answer pairs.\n  We introduce a family of neural encoder-decoder models for Visual Dialog with\n3 encoders -- Late Fusion, Hierarchical Recurrent Encoder and Memory Network --\nand 2 decoders (generative and discriminative), which outperform a number of\nsophisticated baselines. We propose a retrieval-based evaluation protocol for\nVisual Dialog where the AI agent is asked to sort a set of candidate answers\nand evaluated on metrics such as mean-reciprocal-rank of human response. We\nquantify gap between machine and human performance on the Visual Dialog task\nvia human studies. Putting it all together, we demonstrate the first 'visual\nchatbot'! Our dataset, code, trained models and visual chatbot are available on\nhttps://visualdialog.org \n\n"}
{"id": "1611.09326", "contents": "Title: The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for\n  Semantic Segmentation Abstract: State-of-the-art approaches for semantic image segmentation are built on\nConvolutional Neural Networks (CNNs). The typical segmentation architecture is\ncomposed of (a) a downsampling path responsible for extracting coarse semantic\nfeatures, followed by (b) an upsampling path trained to recover the input image\nresolution at the output of the model and, optionally, (c) a post-processing\nmodule (e.g. Conditional Random Fields) to refine the model predictions.\n  Recently, a new CNN architecture, Densely Connected Convolutional Networks\n(DenseNets), has shown excellent results on image classification tasks. The\nidea of DenseNets is based on the observation that if each layer is directly\nconnected to every other layer in a feed-forward fashion then the network will\nbe more accurate and easier to train.\n  In this paper, we extend DenseNets to deal with the problem of semantic\nsegmentation. We achieve state-of-the-art results on urban scene benchmark\ndatasets such as CamVid and Gatech, without any further post-processing module\nnor pretraining. Moreover, due to smart construction of the model, our approach\nhas much less parameters than currently published best entries for these\ndatasets.\n  Code to reproduce the experiments is available here :\nhttps://github.com/SimJeg/FC-DenseNet/blob/master/train.py \n\n"}
{"id": "1611.10229", "contents": "Title: End-to-End Training of Hybrid CNN-CRF Models for Stereo Abstract: We propose a novel and principled hybrid CNN+CRF model for stereo estimation.\nOur model allows to exploit the advantages of both, convolutional neural\nnetworks (CNNs) and conditional random fields (CRFs) in an unified approach.\nThe CNNs compute expressive features for matching and distinctive color edges,\nwhich in turn are used to compute the unary and binary costs of the CRF. For\ninference, we apply a recently proposed highly parallel dual block descent\nalgorithm which only needs a small fixed number of iterations to compute a\nhigh-quality approximate minimizer. As the main contribution of the paper, we\npropose a theoretically sound method based on the structured output support\nvector machine (SSVM) to train the hybrid CNN+CRF model on large-scale data\nend-to-end. Our trained models perform very well despite the fact that we are\nusing shallow CNNs and do not apply any kind of post-processing to the final\noutput of the CRF. We evaluate our combined models on challenging stereo\nbenchmarks such as Middlebury 2014 and Kitti 2015 and also investigate the\nperformance of each individual component. \n\n"}
{"id": "1612.00132", "contents": "Title: CDVAE: Co-embedding Deep Variational Auto Encoder for Conditional\n  Variational Generation Abstract: Problems such as predicting a new shading field (Y) for an image (X) are\nambiguous: many very distinct solutions are good. Representing this ambiguity\nrequires building a conditional model P(Y|X) of the prediction, conditioned on\nthe image. Such a model is difficult to train, because we do not usually have\ntraining data containing many different shadings for the same image. As a\nresult, we need different training examples to share data to produce good\nmodels. This presents a danger we call \"code space collapse\" - the training\nprocedure produces a model that has a very good loss score, but which\nrepresents the conditional distribution poorly. We demonstrate an improved\nmethod for building conditional models by exploiting a metric constraint on\ntraining data that prevents code space collapse. We demonstrate our model on\ntwo example tasks using real data: image saturation adjustment, image\nrelighting. We describe quantitative metrics to evaluate ambiguous generation\nresults. Our results quantitatively and qualitatively outperform different\nstrong baselines. \n\n"}
{"id": "1612.00155", "contents": "Title: Adversarial Images for Variational Autoencoders Abstract: We investigate adversarial attacks for autoencoders. We propose a procedure\nthat distorts the input image to mislead the autoencoder in reconstructing a\ncompletely different target image. We attack the internal latent\nrepresentations, attempting to make the adversarial input produce an internal\nrepresentation as similar as possible as the target's. We find that\nautoencoders are much more robust to the attack than classifiers: while some\nexamples have tolerably small input distortion, and reasonable similarity to\nthe target image, there is a quasi-linear trade-off between those aims. We\nreport results on MNIST and SVHN datasets, and also test regular deterministic\nautoencoders, reaching similar conclusions in all cases. Finally, we show that\nthe usual adversarial attack for classifiers, while being much easier, also\npresents a direct proportion between distortion on the input, and misdirection\non the output. That proportionality however is hidden by the normalization of\nthe output, which maps a linear layer into non-linear probabilities. \n\n"}
{"id": "1612.01051", "contents": "Title: SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural\n  Networks for Real-Time Object Detection for Autonomous Driving Abstract: Object detection is a crucial task for autonomous driving. In addition to\nrequiring high accuracy to ensure safety, object detection for autonomous\ndriving also requires real-time inference speed to guarantee prompt vehicle\ncontrol, as well as small model size and energy efficiency to enable embedded\nsystem deployment.\n  In this work, we propose SqueezeDet, a fully convolutional neural network for\nobject detection that aims to simultaneously satisfy all of the above\nconstraints. In our network, we use convolutional layers not only to extract\nfeature maps but also as the output layer to compute bounding boxes and class\nprobabilities. The detection pipeline of our model only contains a single\nforward pass of a neural network, thus it is extremely fast. Our model is\nfully-convolutional, which leads to a small model size and better energy\nefficiency. While achieving the same accuracy as previous baselines, our model\nis 30.4x smaller, 19.7x faster, and consumes 35.2x lower energy. The code is\nopen-sourced at \\url{https://github.com/BichenWuUCB/squeezeDet}. \n\n"}
{"id": "1612.01254", "contents": "Title: Deep Symbolic Representation Learning for Heterogeneous Time-series\n  Classification Abstract: In this paper, we consider the problem of event classification with\nmulti-variate time series data consisting of heterogeneous (continuous and\ncategorical) variables. The complex temporal dependencies between the variables\ncombined with sparsity of the data makes the event classification problem\nparticularly challenging. Most state-of-art approaches address this either by\ndesigning hand-engineered features or breaking up the problem over homogeneous\nvariates. In this work, we propose and compare three representation learning\nalgorithms over symbolized sequences which enables classification of\nheterogeneous time-series data using a deep architecture. The proposed\nrepresentations are trained jointly along with the rest of the network\narchitecture in an end-to-end fashion that makes the learned features\ndiscriminative for the given task. Experiments on three real-world datasets\ndemonstrate the effectiveness of the proposed approaches. \n\n"}
{"id": "1612.01895", "contents": "Title: Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network\n  for Fast Artistic Style Transfer Abstract: Transferring artistic styles onto everyday photographs has become an\nextremely popular task in both academia and industry. Recently, offline\ntraining has replaced on-line iterative optimization, enabling nearly real-time\nstylization. When those stylization networks are applied directly to\nhigh-resolution images, however, the style of localized regions often appears\nless similar to the desired artistic style. This is because the transfer\nprocess fails to capture small, intricate textures and maintain correct texture\nscales of the artworks. Here we propose a multimodal convolutional neural\nnetwork that takes into consideration faithful representations of both color\nand luminance channels, and performs stylization hierarchically with multiple\nlosses of increasing scales. Compared to state-of-the-art networks, our network\ncan also perform style transfer in nearly real-time by conducting much more\nsophisticated training offline. By properly handling style and texture cues at\nmultiple scales using several modalities, we can transfer not just large-scale,\nobvious style cues but also subtle, exquisite ones. That is, our scheme can\ngenerate results that are visually pleasing and more similar to multiple\ndesired artistic styles with color and texture cues at multiple scales. \n\n"}
{"id": "1612.02559", "contents": "Title: AGA: Attribute Guided Augmentation Abstract: We consider the problem of data augmentation, i.e., generating artificial\nsamples to extend a given corpus of training data. Specifically, we propose\nattributed-guided augmentation (AGA) which learns a mapping that allows to\nsynthesize data such that an attribute of a synthesized sample is at a desired\nvalue or strength. This is particularly interesting in situations where little\ndata with no attribute annotation is available for learning, but we have access\nto a large external corpus of heavily annotated samples. While prior works\nprimarily augment in the space of images, we propose to perform augmentation in\nfeature space instead. We implement our approach as a deep encoder-decoder\narchitecture that learns the synthesis function in an end-to-end manner. We\ndemonstrate the utility of our approach on the problems of (1) one-shot object\nrecognition in a transfer-learning setting where we have no prior knowledge of\nthe new classes, as well as (2) object-based one-shot scene recognition. As\nexternal data, we leverage 3D depth and pose information from the SUN RGB-D\ndataset. Our experiments show that attribute-guided augmentation of high-level\nCNN features considerably improves one-shot recognition performance on both\nproblems. \n\n"}
{"id": "1612.02808", "contents": "Title: 3D Shape Segmentation with Projective Convolutional Networks Abstract: This paper introduces a deep architecture for segmenting 3D objects into\ntheir labeled semantic parts. Our architecture combines image-based Fully\nConvolutional Networks (FCNs) and surface-based Conditional Random Fields\n(CRFs) to yield coherent segmentations of 3D shapes. The image-based FCNs are\nused for efficient view-based reasoning about 3D object parts. Through a\nspecial projection layer, FCN outputs are effectively aggregated across\nmultiple views and scales, then are projected onto the 3D object surfaces.\nFinally, a surface-based CRF combines the projected outputs with geometric\nconsistency cues to yield coherent segmentations. The whole architecture\n(multi-view FCNs and CRF) is trained end-to-end. Our approach significantly\noutperforms the existing state-of-the-art methods in the currently largest\nsegmentation benchmark (ShapeNet). Finally, we demonstrate promising\nsegmentation results on noisy 3D shapes acquired from consumer-grade depth\ncameras. \n\n"}
{"id": "1612.02844", "contents": "Title: Deep TEN: Texture Encoding Network Abstract: We propose a Deep Texture Encoding Network (Deep-TEN) with a novel Encoding\nLayer integrated on top of convolutional layers, which ports the entire\ndictionary learning and encoding pipeline into a single model. Current methods\nbuild from distinct components, using standard encoders with separate\noff-the-shelf features such as SIFT descriptors or pre-trained CNN features for\nmaterial recognition. Our new approach provides an end-to-end learning\nframework, where the inherent visual vocabularies are learned directly from the\nloss function. The features, dictionaries and the encoding representation for\nthe classifier are all learned simultaneously. The representation is orderless\nand therefore is particularly useful for material and texture recognition. The\nEncoding Layer generalizes robust residual encoders such as VLAD and Fisher\nVectors, and has the property of discarding domain specific information which\nmakes the learned convolutional features easier to transfer. Additionally,\njoint training using multiple datasets of varied sizes and class labels is\nsupported resulting in increased recognition performance. The experimental\nresults show superior performance as compared to state-of-the-art methods using\ngold-standard databases such as MINC-2500, Flickr Material Database,\nKTH-TIPS-2b, and two recent databases 4D-Light-Field-Material and GTOS. The\nsource code for the complete system are publicly available. \n\n"}
{"id": "1612.03925", "contents": "Title: 3D fully convolutional networks for subcortical segmentation in MRI: A\n  large-scale study Abstract: This study investigates a 3D and fully convolutional neural network (CNN) for\nsubcortical brain structure segmentation in MRI. 3D CNN architectures have been\ngenerally avoided due to their computational and memory requirements during\ninference. We address the problem via small kernels, allowing deeper\narchitectures. We further model both local and global context by embedding\nintermediate-layer outputs in the final prediction, which encourages\nconsistency between features extracted at different scales and embeds\nfine-grained information directly in the segmentation process. Our model is\nefficiently trained end-to-end on a graphics processing unit (GPU), in a single\nstage, exploiting the dense inference capabilities of fully CNNs.\n  We performed comprehensive experiments over two publicly available datasets.\nFirst, we demonstrate a state-of-the-art performance on the ISBR dataset. Then,\nwe report a {\\em large-scale} multi-site evaluation over 1112 unregistered\nsubject datasets acquired from 17 different sites (ABIDE dataset), with ages\nranging from 7 to 64 years, showing that our method is robust to various\nacquisition protocols, demographics and clinical factors. Our method yielded\nsegmentations that are highly consistent with a standard atlas-based approach,\nwhile running in a fraction of the time needed by atlas-based methods and\navoiding registration/normalization steps. This makes it convenient for massive\nmulti-site neuroanatomical imaging studies. To the best of our knowledge, our\nwork is the first to study subcortical structure segmentation on such\nlarge-scale and heterogeneous data. \n\n"}
{"id": "1612.04357", "contents": "Title: Stacked Generative Adversarial Networks Abstract: In this paper, we propose a novel generative model named Stacked Generative\nAdversarial Networks (SGAN), which is trained to invert the hierarchical\nrepresentations of a bottom-up discriminative network. Our model consists of a\ntop-down stack of GANs, each learned to generate lower-level representations\nconditioned on higher-level representations. A representation discriminator is\nintroduced at each feature hierarchy to encourage the representation manifold\nof the generator to align with that of the bottom-up discriminative network,\nleveraging the powerful discriminative representations to guide the generative\nmodel. In addition, we introduce a conditional loss that encourages the use of\nconditional information from the layer above, and a novel entropy loss that\nmaximizes a variational lower bound on the conditional entropy of generator\noutputs. We first train each stack independently, and then train the whole\nmodel end-to-end. Unlike the original GAN that uses a single noise vector to\nrepresent all the variations, our SGAN decomposes variations into multiple\nlevels and gradually resolves uncertainties in the top-down generative process.\nBased on visual inspection, Inception scores and visual Turing test, we\ndemonstrate that SGAN is able to generate images of much higher quality than\nGANs without stacking. \n\n"}
{"id": "1612.04402", "contents": "Title: Finding Tiny Faces Abstract: Though tremendous strides have been made in object recognition, one of the\nremaining open challenges is detecting small objects. We explore three aspects\nof the problem in the context of finding small faces: the role of scale\ninvariance, image resolution, and contextual reasoning. While most recognition\napproaches aim to be scale-invariant, the cues for recognizing a 3px tall face\nare fundamentally different than those for recognizing a 300px tall face. We\ntake a different approach and train separate detectors for different scales. To\nmaintain efficiency, detectors are trained in a multi-task fashion: they make\nuse of features extracted from multiple layers of single (deep) feature\nhierarchy. While training detectors for large objects is straightforward, the\ncrucial challenge remains training detectors for small objects. We show that\ncontext is crucial, and define templates that make use of massively-large\nreceptive fields (where 99% of the template extends beyond the object of\ninterest). Finally, we explore the role of scale in pre-trained deep networks,\nproviding ways to extrapolate networks tuned for limited scales to rather\nextreme ranges. We demonstrate state-of-the-art results on\nmassively-benchmarked face datasets (FDDB and WIDER FACE). In particular, when\ncompared to prior art on WIDER FACE, our results reduce error by a factor of 2\n(our models produce an AP of 82% while prior art ranges from 29-64%). \n\n"}
{"id": "1612.04440", "contents": "Title: Disentangling Space and Time in Video with Hierarchical Variational\n  Auto-encoders Abstract: There are many forms of feature information present in video data. Principle\namong them are object identity information which is largely static across\nmultiple video frames, and object pose and style information which continuously\ntransforms from frame to frame. Most existing models confound these two types\nof representation by mapping them to a shared feature space. In this paper we\npropose a probabilistic approach for learning separable representations of\nobject identity and pose information using unsupervised video data. Our\napproach leverages a deep generative model with a factored prior distribution\nthat encodes properties of temporal invariances in the hidden feature set.\nLearning is achieved via variational inference. We present results of learning\nidentity and pose information on a dataset of moving characters as well as a\ndataset of rotating 3D objects. Our experimental results demonstrate our\nmodel's success in factoring its representation, and demonstrate that the model\nachieves improved performance in transfer learning tasks. \n\n"}
{"id": "1612.06052", "contents": "Title: Quantization and Training of Low Bit-Width Convolutional Neural Networks\n  for Object Detection Abstract: We present LBW-Net, an efficient optimization based method for quantization\nand training of the low bit-width convolutional neural networks (CNNs).\nSpecifically, we quantize the weights to zero or powers of two by minimizing\nthe Euclidean distance between full-precision weights and quantized weights\nduring backpropagation. We characterize the combinatorial nature of the low\nbit-width quantization problem. For 2-bit (ternary) CNNs, the quantization of\n$N$ weights can be done by an exact formula in $O(N\\log N)$ complexity. When\nthe bit-width is three and above, we further propose a semi-analytical\nthresholding scheme with a single free parameter for quantization that is\ncomputationally inexpensive. The free parameter is further determined by\nnetwork retraining and object detection tests. LBW-Net has several desirable\nadvantages over full-precision CNNs, including considerable memory savings,\nenergy efficiency, and faster deployment. Our experiments on PASCAL VOC dataset\nshow that compared with its 32-bit floating-point counterpart, the performance\nof the 6-bit LBW-Net is nearly lossless in the object detection tasks, and can\neven do better in some real world visual scenes, while empirically enjoying\nmore than 4$\\times$ faster deployment. \n\n"}
{"id": "1612.06669", "contents": "Title: Enhancing Observability in Distribution Grids using Smart Meter Data Abstract: Due to limited metering infrastructure, distribution grids are currently\nchallenged by observability issues. On the other hand, smart meter data,\nincluding local voltage magnitudes and power injections, are communicated to\nthe utility operator from grid buses with renewable generation and\ndemand-response programs. This work employs grid data from metered buses\ntowards inferring the underlying grid state. To this end, a coupled formulation\nof the power flow problem (CPF) is put forth. Exploiting the high variability\nof injections at metered buses, the controllability of solar inverters, and the\nrelative time-invariance of conventional loads, the idea is to solve the\nnon-linear power flow equations jointly over consecutive time instants. An\nintuitive and easily verifiable rule pertaining to the locations of metered and\nnon-metered buses on the physical grid is shown to be a necessary and\nsufficient criterion for local observability in radial networks. To account for\nnoisy smart meter readings, a coupled power system state estimation (CPSSE)\nproblem is further developed. Both CPF and CPSSE tasks are tackled via\naugmented semi-definite program relaxations. The observability criterion along\nwith the CPF and CPSSE solvers are numerically corroborated using synthetic and\nactual solar generation and load data on the IEEE 34-bus benchmark feeder. \n\n"}
{"id": "1612.09548", "contents": "Title: A Unified Tensor-based Active Appearance Face Model Abstract: Appearance variations result in many difficulties in face image analysis. To\ndeal with this challenge, we present a Unified Tensor-based Active Appearance\nModel (UT-AAM) for jointly modelling the geometry and texture information of 2D\nfaces. For each type of face information, namely shape and texture, we\nconstruct a unified tensor model capturing all relevant appearance variations.\nThis contrasts with the variation-specific models of the classical tensor AAM.\nTo achieve the unification across pose variations, a strategy for dealing with\nself-occluded faces is proposed to obtain consistent shape and texture\nrepresentations of pose-varied faces. In addition, our UT-AAM is capable of\nconstructing the model from an incomplete training dataset, using tensor\ncompletion methods. Last, we use an effective cascaded-regression-based method\nfor UT-AAM fitting. With these advancements, the utility of UT-AAM in practice\nis considerably enhanced. As an example, we demonstrate the improvements in\ntraining facial landmark detectors through the use of UT-AAM to synthesise a\nlarge number of virtual samples. Experimental results obtained using the\nMulti-PIE and 300-W face datasets demonstrate the merits of the proposed\napproach. \n\n"}
{"id": "1701.00193", "contents": "Title: Video-based Person Re-identification with Accumulative Motion Context Abstract: Video based person re-identification plays a central role in realistic\nsecurity and video surveillance. In this paper we propose a novel Accumulative\nMotion Context (AMOC) network for addressing this important problem, which\neffectively exploits the long-range motion context for robustly identifying the\nsame person under challenging conditions. Given a video sequence of the same or\ndifferent persons, the proposed AMOC network jointly learns appearance\nrepresentation and motion context from a collection of adjacent frames using a\ntwo-stream convolutional architecture. Then AMOC accumulates clues from motion\ncontext by recurrent aggregation, allowing effective information flow among\nadjacent frames and capturing dynamic gist of the persons. The architecture of\nAMOC is end-to-end trainable and thus motion context can be adapted to\ncomplement appearance clues under unfavorable conditions (e.g. occlusions).\nExtensive experiments are conduced on three public benchmark datasets, i.e.,\nthe iLIDS-VID, PRID-2011 and MARS datasets, to investigate the performance of\nAMOC. The experimental results demonstrate that the proposed AMOC network\noutperforms state-of-the-arts for video-based re-identification significantly\nand confirm the advantage of exploiting long-range motion context for video\nbased person re-identification, validating our motivation evidently. \n\n"}
{"id": "1701.00299", "contents": "Title: Dynamic Deep Neural Networks: Optimizing Accuracy-Efficiency Trade-offs\n  by Selective Execution Abstract: We introduce Dynamic Deep Neural Networks (D2NN), a new type of feed-forward\ndeep neural network that allows selective execution. Given an input, only a\nsubset of D2NN neurons are executed, and the particular subset is determined by\nthe D2NN itself. By pruning unnecessary computation depending on input, D2NNs\nprovide a way to improve computational efficiency. To achieve dynamic selective\nexecution, a D2NN augments a feed-forward deep neural network (directed acyclic\ngraph of differentiable modules) with controller modules. Each controller\nmodule is a sub-network whose output is a decision that controls whether other\nmodules can execute. A D2NN is trained end to end. Both regular and controller\nmodules in a D2NN are learnable and are jointly trained to optimize both\naccuracy and efficiency. Such training is achieved by integrating\nbackpropagation with reinforcement learning. With extensive experiments of\nvarious D2NN architectures on image classification tasks, we demonstrate that\nD2NNs are general and flexible, and can effectively optimize\naccuracy-efficiency trade-offs. \n\n"}
{"id": "1701.00485", "contents": "Title: Two-Bit Networks for Deep Learning on Resource-Constrained Embedded\n  Devices Abstract: With the rapid proliferation of Internet of Things and intelligent edge\ndevices, there is an increasing need for implementing machine learning\nalgorithms, including deep learning, on resource-constrained mobile embedded\ndevices with limited memory and computation power. Typical large Convolutional\nNeural Networks (CNNs) need large amounts of memory and computational power,\nand cannot be deployed on embedded devices efficiently. We present Two-Bit\nNetworks (TBNs) for model compression of CNNs with edge weights constrained to\n(-2, -1, 1, 2), which can be encoded with two bits. Our approach can reduce the\nmemory usage and improve computational efficiency significantly while achieving\ngood performance in terms of classification accuracy, thus representing a\nreasonable tradeoff between model size and performance. \n\n"}
{"id": "1701.02343", "contents": "Title: Information Pursuit: A Bayesian Framework for Sequential Scene Parsing Abstract: Despite enormous progress in object detection and classification, the problem\nof incorporating expected contextual relationships among object instances into\nmodern recognition systems remains a key challenge. In this work we propose\nInformation Pursuit, a Bayesian framework for scene parsing that combines prior\nmodels for the geometry of the scene and the spatial arrangement of objects\ninstances with a data model for the output of high-level image classifiers\ntrained to answer specific questions about the scene. In the proposed\nframework, the scene interpretation is progressively refined as evidence\naccumulates from the answers to a sequence of questions. At each step, we\nchoose the question to maximize the mutual information between the new answer\nand the full interpretation given the current evidence obtained from previous\ninquiries. We also propose a method for learning the parameters of the model\nfrom synthesized, annotated scenes obtained by top-down sampling from an\neasy-to-learn generative scene model. Finally, we introduce a database of\nannotated indoor scenes of dining room tables, which we use to evaluate the\nproposed approach. \n\n"}
{"id": "1701.02815", "contents": "Title: Stochastic Generative Hashing Abstract: Learning-based binary hashing has become a powerful paradigm for fast search\nand retrieval in massive databases. However, due to the requirement of discrete\noutputs for the hash functions, learning such functions is known to be very\nchallenging. In addition, the objective functions adopted by existing hashing\ntechniques are mostly chosen heuristically. In this paper, we propose a novel\ngenerative approach to learn hash functions through Minimum Description Length\nprinciple such that the learned hash codes maximally compress the dataset and\ncan also be used to regenerate the inputs. We also develop an efficient\nlearning algorithm based on the stochastic distributional gradient, which\navoids the notorious difficulty caused by binary output constraints, to jointly\noptimize the parameters of the hash function and the associated generative\nmodel. Extensive experiments on a variety of large-scale datasets show that the\nproposed method achieves better retrieval results than the existing\nstate-of-the-art methods. \n\n"}
{"id": "1701.04284", "contents": "Title: Hierarchical Salient Object Detection for Assisted Grasping Abstract: Visual scene decomposition into semantic entities is one of the major\nchallenges when creating a reliable object grasping system. Recently, we\nintroduced a bottom-up hierarchical clustering approach which is able to\nsegment objects and parts in a scene. In this paper, we introduce a transform\nfrom such a segmentation into a corresponding, hierarchical saliency function.\nIn comprehensive experiments we demonstrate its ability to detect salient\nobjects in a scene. Furthermore, this hierarchical saliency defines a most\nsalient corresponding region (scale) for every point in an image. Based on\nthis, an easy-to-use pick and place manipulation system was developed and\ntested exemplarily. \n\n"}
{"id": "1701.05003", "contents": "Title: Effective Multi-Query Expansions: Collaborative Deep Networks for Robust\n  Landmark Retrieval Abstract: Given a query photo issued by a user (q-user), the landmark retrieval is to\nreturn a set of photos with their landmarks similar to those of the query,\nwhile the existing studies on the landmark retrieval focus on exploiting\ngeometries of landmarks for similarity matches between candidate photos and a\nquery photo. We observe that the same landmarks provided by different users\nover social media community may convey different geometry information depending\non the viewpoints and/or angles, and may subsequently yield very different\nresults. In fact, dealing with the landmarks with \\illshapes caused by the\nphotography of q-users is often nontrivial and has seldom been studied. In this\npaper we propose a novel framework, namely multi-query expansions, to retrieve\nsemantically robust landmarks by two steps. Firstly, we identify the top-$k$\nphotos regarding the latent topics of a query landmark to construct multi-query\nset so as to remedy its possible \\illshape. For this purpose, we significantly\nextend the techniques of Latent Dirichlet Allocation. Then, motivated by the\ntypical \\emph{collaborative filtering} methods, we propose to learn a\n\\emph{collaborative} deep networks based semantically, nonlinear and high-level\nfeatures over the latent factor for landmark photo as the training set, which\nis formed by matrix factorization over \\emph{collaborative} user-photo matrix\nregarding the multi-query set. The learned deep network is further applied to\ngenerate the features for all the other photos, meanwhile resulting into a\ncompact multi-query set within such space. Extensive experiments are conducted\non real-world social media data with both landmark photos together with their\nuser information to show the superior performance over the existing methods. \n\n"}
{"id": "1701.05369", "contents": "Title: Variational Dropout Sparsifies Deep Neural Networks Abstract: We explore a recently proposed Variational Dropout technique that provided an\nelegant Bayesian interpretation to Gaussian Dropout. We extend Variational\nDropout to the case when dropout rates are unbounded, propose a way to reduce\nthe variance of the gradient estimator and report first experimental results\nwith individual dropout rates per weight. Interestingly, it leads to extremely\nsparse solutions both in fully-connected and convolutional layers. This effect\nis similar to automatic relevance determination effect in empirical Bayes but\nhas a number of advantages. We reduce the number of parameters up to 280 times\non LeNet architectures and up to 68 times on VGG-like networks with a\nnegligible decrease of accuracy. \n\n"}
{"id": "1701.05818", "contents": "Title: Fusion of Heterogeneous Data in Convolutional Networks for Urban\n  Semantic Labeling (Invited Paper) Abstract: In this work, we present a novel module to perform fusion of heterogeneous\ndata using fully convolutional networks for semantic labeling. We introduce\nresidual correction as a way to learn how to fuse predictions coming out of a\ndual stream architecture. Especially, we perform fusion of DSM and IRRG optical\ndata on the ISPRS Vaihingen dataset over a urban area and obtain new\nstate-of-the-art results. \n\n"}
{"id": "1701.06452", "contents": "Title: Learning what to look in chest X-rays with a recurrent visual attention\n  model Abstract: X-rays are commonly performed imaging tests that use small amounts of\nradiation to produce pictures of the organs, tissues, and bones of the body.\nX-rays of the chest are used to detect abnormalities or diseases of the\nairways, blood vessels, bones, heart, and lungs. In this work we present a\nstochastic attention-based model that is capable of learning what regions\nwithin a chest X-ray scan should be visually explored in order to conclude that\nthe scan contains a specific radiological abnormality. The proposed model is a\nrecurrent neural network (RNN) that learns to sequentially sample the entire\nX-ray and focus only on informative areas that are likely to contain the\nrelevant information. We report on experiments carried out with more than\n$100,000$ X-rays containing enlarged hearts or medical devices. The model has\nbeen trained using reinforcement learning methods to learn task-specific\npolicies. \n\n"}
{"id": "1701.06641", "contents": "Title: Perceptually Optimized Image Rendering Abstract: We develop a framework for rendering photographic images, taking into account\ndisplay limitations, so as to optimize perceptual similarity between the\nrendered image and the original scene. We formulate this as a constrained\noptimization problem, in which we minimize a measure of perceptual\ndissimilarity, the Normalized Laplacian Pyramid Distance (NLPD), which mimics\nthe early stage transformations of the human visual system. When rendering\nimages acquired with higher dynamic range than that of the display, we find\nthat the optimized solution boosts the contrast of low-contrast features\nwithout introducing significant artifacts, yielding results of comparable\nvisual quality to current state-of-the art methods with no manual intervention\nor parameter settings. We also examine a variety of other display constraints,\nincluding limitations on minimum luminance (black point), mean luminance (as a\nproxy for energy consumption), and quantized luminance levels (halftoning).\nFinally, we show that the method may be used to enhance details and contrast of\nimages degraded by optical scattering (e.g. fog). \n\n"}
{"id": "1701.08985", "contents": "Title: Deep Multitask Architecture for Integrated 2D and 3D Human Sensing Abstract: We propose a deep multitask architecture for \\emph{fully automatic 2d and 3d\nhuman sensing} (DMHS), including \\emph{recognition and reconstruction}, in\n\\emph{monocular images}. The system computes the figure-ground segmentation,\nsemantically identifies the human body parts at pixel level, and estimates the\n2d and 3d pose of the person. The model supports the joint training of all\ncomponents by means of multi-task losses where early processing stages\nrecursively feed into advanced ones for increasingly complex calculations,\naccuracy and robustness. The design allows us to tie a complete training\nprotocol, by taking advantage of multiple datasets that would otherwise\nrestrictively cover only some of the model components: complex 2d image data\nwith no body part labeling and without associated 3d ground truth, or complex\n3d data with limited 2d background variability. In detailed experiments based\non several challenging 2d and 3d datasets (LSP, HumanEva, Human3.6M), we\nevaluate the sub-structures of the model, the effect of various types of\ntraining data in the multitask loss, and demonstrate that state-of-the-art\nresults can be achieved at all processing levels. We also show that in the wild\nour monocular RGB architecture is perceptually competitive to a state-of-the\nart (commercial) Kinect system based on RGB-D data. \n\n"}
{"id": "1702.00338", "contents": "Title: Siamese Network of Deep Fisher-Vector Descriptors for Image Retrieval Abstract: This paper addresses the problem of large scale image retrieval, with the aim\nof accurately ranking the similarity of a large number of images to a given\nquery image. To achieve this, we propose a novel Siamese network. This network\nconsists of two computational strands, each comprising of a CNN component\nfollowed by a Fisher vector component. The CNN component produces dense, deep\nconvolutional descriptors that are then aggregated by the Fisher Vector method.\nCrucially, we propose to simultaneously learn both the CNN filter weights and\nFisher Vector model parameters. This allows us to account for the evolving\ndistribution of deep descriptors over the course of the learning process. We\nshow that the proposed approach gives significant improvements over the\nstate-of-the-art methods on the Oxford and Paris image retrieval datasets.\nAdditionally, we provide a baseline performance measure for both these datasets\nwith the inclusion of 1 million distractors. \n\n"}
{"id": "1702.02138", "contents": "Title: An Implementation of Faster RCNN with Study for Region Sampling Abstract: We adapted the join-training scheme of Faster RCNN framework from Caffe to\nTensorFlow as a baseline implementation for object detection. Our code is made\npublicly available. This report documents the simplifications made to the\noriginal pipeline, with justifications from ablation analysis on both PASCAL\nVOC 2007 and COCO 2014. We further investigated the role of non-maximal\nsuppression (NMS) in selecting regions-of-interest (RoIs) for region\nclassification, and found that a biased sampling toward small regions helps\nperformance and can achieve on-par mAP to NMS-based sampling when converged\nsufficiently. \n\n"}
{"id": "1702.02447", "contents": "Title: Region Ensemble Network: Improving Convolutional Network for Hand Pose\n  Estimation Abstract: Hand pose estimation from monocular depth images is an important and\nchallenging problem for human-computer interaction. Recently deep convolutional\nnetworks (ConvNet) with sophisticated design have been employed to address it,\nbut the improvement over traditional methods is not so apparent. To promote the\nperformance of directly 3D coordinate regression, we propose a tree-structured\nRegion Ensemble Network (REN), which partitions the convolution outputs into\nregions and integrates the results from multiple regressors on each regions.\nCompared with multi-model ensemble, our model is completely end-to-end\ntraining. The experimental results demonstrate that our approach achieves the\nbest performance among state-of-the-arts on two public datasets. \n\n"}
{"id": "1702.04405", "contents": "Title: ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes Abstract: A key requirement for leveraging supervised deep learning methods is the\navailability of large, labeled datasets. Unfortunately, in the context of RGB-D\nscene understanding, very little data is available -- current datasets cover a\nsmall range of scene views and have limited semantic annotations. To address\nthis issue, we introduce ScanNet, an RGB-D video dataset containing 2.5M views\nin 1513 scenes annotated with 3D camera poses, surface reconstructions, and\nsemantic segmentations. To collect this data, we designed an easy-to-use and\nscalable RGB-D capture system that includes automated surface reconstruction\nand crowdsourced semantic annotation. We show that using this data helps\nachieve state-of-the-art performance on several 3D scene understanding tasks,\nincluding 3D object classification, semantic voxel labeling, and CAD model\nretrieval. The dataset is freely available at http://www.scan-net.org. \n\n"}
{"id": "1702.05147", "contents": "Title: Automatic Handgun Detection Alarm in Videos Using Deep Learning Abstract: Current surveillance and control systems still require human supervision and\nintervention. This work presents a novel automatic handgun detection system in\nvideos appropriate for both, surveillance and control purposes. We reformulate\nthis detection problem into the problem of minimizing false positives and solve\nit by building the key training data-set guided by the results of a deep\nConvolutional Neural Networks (CNN) classifier, then assessing the best\nclassification model under two approaches, the sliding window approach and\nregion proposal approach. The most promising results are obtained by Faster\nR-CNN based model trained on our new database. The best detector show a high\npotential even in low quality youtube videos and provides satisfactory results\nas automatic alarm system. Among 30 scenes, it successfully activates the alarm\nafter five successive true positives in less than 0.2 seconds, in 27 scenes. We\nalso define a new metric, Alarm Activation per Interval (AApI), to assess the\nperformance of a detection model as an automatic detection system in videos. \n\n"}
{"id": "1702.06332", "contents": "Title: Just DIAL: DomaIn Alignment Layers for Unsupervised Domain Adaptation Abstract: The empirical fact that classifiers, trained on given data collections,\nperform poorly when tested on data acquired in different settings is\ntheoretically explained in domain adaptation through a shift among\ndistributions of the source and target domains. Alleviating the domain shift\nproblem, especially in the challenging setting where no labeled data are\navailable for the target domain, is paramount for having visual recognition\nsystems working in the wild. As the problem stems from a shift among\ndistributions, intuitively one should try to align them. In the literature,\nthis has resulted in a stream of works attempting to align the feature\nrepresentations learned from the source and target domains. Here we take a\ndifferent route. Rather than introducing regularization terms aiming to promote\nthe alignment of the two representations, we act at the distribution level\nthrough the introduction of \\emph{DomaIn Alignment Layers} (\\DIAL), able to\nmatch the observed source and target data distributions to a reference one.\nThorough experiments on three different public benchmarks we confirm the power\nof our approach. \n\n"}
{"id": "1702.06456", "contents": "Title: Online Representation Learning with Single and Multi-layer Hebbian\n  Networks for Image Classification Abstract: Unsupervised learning permits the development of algorithms that are able to\nadapt to a variety of different data sets using the same underlying rules\nthanks to the autonomous discovery of discriminating features during training.\nRecently, a new class of Hebbian-like and local unsupervised learning rules for\nneural networks have been developed that minimise a similarity matching\ncost-function. These have been shown to perform sparse representation learning.\nThis study tests the effectiveness of one such learning rule for learning\nfeatures from images. The rule implemented is derived from a nonnegative\nclassical multidimensional scaling cost-function, and is applied to both single\nand multi-layer architectures. The features learned by the algorithm are then\nused as input to an SVM to test their effectiveness in classification on the\nestablished CIFAR-10 image dataset. The algorithm performs well in comparison\nto other unsupervised learning algorithms and multi-layer networks, thus\nsuggesting its validity in the design of a new class of compact, online\nlearning networks. \n\n"}
{"id": "1702.06674", "contents": "Title: Unsupervised Diverse Colorization via Generative Adversarial Networks Abstract: Colorization of grayscale images has been a hot topic in computer vision.\nPrevious research mainly focuses on producing a colored image to match the\noriginal one. However, since many colors share the same gray value, an input\ngrayscale image could be diversely colored while maintaining its reality. In\nthis paper, we design a novel solution for unsupervised diverse colorization.\nSpecifically, we leverage conditional generative adversarial networks to model\nthe distribution of real-world item colors, in which we develop a fully\nconvolutional generator with multi-layer noise to enhance diversity, with\nmulti-layer condition concatenation to maintain reality, and with stride 1 to\nkeep spatial information. With such a novel network architecture, the model\nyields highly competitive performance on the open LSUN bedroom dataset. The\nTuring test of 80 humans further indicates our generated color schemes are\nhighly convincible. \n\n"}
{"id": "1702.07464", "contents": "Title: Deep Models Under the GAN: Information Leakage from Collaborative Deep\n  Learning Abstract: Deep Learning has recently become hugely popular in machine learning,\nproviding significant improvements in classification accuracy in the presence\nof highly-structured and large databases.\n  Researchers have also considered privacy implications of deep learning.\nModels are typically trained in a centralized manner with all the data being\nprocessed by the same training algorithm. If the data is a collection of users'\nprivate data, including habits, personal pictures, geographical positions,\ninterests, and more, the centralized server will have access to sensitive\ninformation that could potentially be mishandled. To tackle this problem,\ncollaborative deep learning models have recently been proposed where parties\nlocally train their deep learning structures and only share a subset of the\nparameters in the attempt to keep their respective training sets private.\nParameters can also be obfuscated via differential privacy (DP) to make\ninformation extraction even more challenging, as proposed by Shokri and\nShmatikov at CCS'15.\n  Unfortunately, we show that any privacy-preserving collaborative deep\nlearning is susceptible to a powerful attack that we devise in this paper. In\nparticular, we show that a distributed, federated, or decentralized deep\nlearning approach is fundamentally broken and does not protect the training\nsets of honest participants. The attack we developed exploits the real-time\nnature of the learning process that allows the adversary to train a Generative\nAdversarial Network (GAN) that generates prototypical samples of the targeted\ntraining set that was meant to be private (the samples generated by the GAN are\nintended to come from the same distribution as the training data).\nInterestingly, we show that record-level DP applied to the shared parameters of\nthe model, as suggested in previous work, is ineffective (i.e., record-level DP\nis not designed to address our attack). \n\n"}
{"id": "1702.07811", "contents": "Title: Adaptive Neural Networks for Efficient Inference Abstract: We present an approach to adaptively utilize deep neural networks in order to\nreduce the evaluation time on new examples without loss of accuracy. Rather\nthan attempting to redesign or approximate existing networks, we propose two\nschemes that adaptively utilize networks. We first pose an adaptive network\nevaluation scheme, where we learn a system to adaptively choose the components\nof a deep network to be evaluated for each example. By allowing examples\ncorrectly classified using early layers of the system to exit, we avoid the\ncomputational time associated with full evaluation of the network. We extend\nthis to learn a network selection system that adaptively selects the network to\nbe evaluated for each example. We show that computational time can be\ndramatically reduced by exploiting the fact that many examples can be correctly\nclassified using relatively efficient networks and that complex,\ncomputationally costly networks are only necessary for a small fraction of\nexamples. We pose a global objective for learning an adaptive early exit or\nnetwork selection policy and solve it by reducing the policy learning problem\nto a layer-by-layer weighted binary classification problem. Empirically, these\napproaches yield dramatic reductions in computational cost, with up to a 2.8x\nspeedup on state-of-the-art networks from the ImageNet image recognition\nchallenge with minimal (<1%) loss of top5 accuracy. \n\n"}
{"id": "1702.07811", "contents": "Title: Adaptive Neural Networks for Efficient Inference Abstract: We present an approach to adaptively utilize deep neural networks in order to\nreduce the evaluation time on new examples without loss of accuracy. Rather\nthan attempting to redesign or approximate existing networks, we propose two\nschemes that adaptively utilize networks. We first pose an adaptive network\nevaluation scheme, where we learn a system to adaptively choose the components\nof a deep network to be evaluated for each example. By allowing examples\ncorrectly classified using early layers of the system to exit, we avoid the\ncomputational time associated with full evaluation of the network. We extend\nthis to learn a network selection system that adaptively selects the network to\nbe evaluated for each example. We show that computational time can be\ndramatically reduced by exploiting the fact that many examples can be correctly\nclassified using relatively efficient networks and that complex,\ncomputationally costly networks are only necessary for a small fraction of\nexamples. We pose a global objective for learning an adaptive early exit or\nnetwork selection policy and solve it by reducing the policy learning problem\nto a layer-by-layer weighted binary classification problem. Empirically, these\napproaches yield dramatic reductions in computational cost, with up to a 2.8x\nspeedup on state-of-the-art networks from the ImageNet image recognition\nchallenge with minimal (<1%) loss of top5 accuracy. \n\n"}
{"id": "1702.07963", "contents": "Title: Spatially Aware Melanoma Segmentation Using Hybrid Deep Learning\n  Techniques Abstract: In this paper, we proposed using a hybrid method that utilises deep\nconvolutional and recurrent neural networks for accurate delineation of skin\nlesion of images supplied with ISBI 2017 lesion segmentation challenge. The\nproposed method was trained using 1800 images and tested on 150 images from\nISBI 2017 challenge. \n\n"}
{"id": "1702.08014", "contents": "Title: Adversarial Networks for the Detection of Aggressive Prostate Cancer Abstract: Semantic segmentation constitutes an integral part of medical image analyses\nfor which breakthroughs in the field of deep learning were of high relevance.\nThe large number of trainable parameters of deep neural networks however\nrenders them inherently data hungry, a characteristic that heavily challenges\nthe medical imaging community. Though interestingly, with the de facto standard\ntraining of fully convolutional networks (FCNs) for semantic segmentation being\nagnostic towards the `structure' of the predicted label maps, valuable\ncomplementary information about the global quality of the segmentation lies\nidle. In order to tap into this potential, we propose utilizing an adversarial\nnetwork which discriminates between expert and generated annotations in order\nto train FCNs for semantic segmentation. Because the adversary constitutes a\nlearned parametrization of what makes a good segmentation at a global level, we\nhypothesize that the method holds particular advantages for segmentation tasks\non complex structured, small datasets. This holds true in our experiments: We\nlearn to segment aggressive prostate cancer utilizing MRI images of 152\npatients and show that the proposed scheme is superior over the de facto\nstandard in terms of the detection sensitivity and the dice-score for\naggressive prostate cancer. The achieved relative gains are shown to be\nparticularly pronounced in the small dataset limit. \n\n"}
{"id": "1702.08171", "contents": "Title: Fixed-point optimization of deep neural networks with adaptive step size\n  retraining Abstract: Fixed-point optimization of deep neural networks plays an important role in\nhardware based design and low-power implementations. Many deep neural networks\nshow fairly good performance even with 2- or 3-bit precision when quantized\nweights are fine-tuned by retraining. We propose an improved fixedpoint\noptimization algorithm that estimates the quantization step size dynamically\nduring the retraining. In addition, a gradual quantization scheme is also\ntested, which sequentially applies fixed-point optimizations from high- to\nlow-precision. The experiments are conducted for feed-forward deep neural\nnetworks (FFDNNs), convolutional neural networks (CNNs), and recurrent neural\nnetworks (RNNs). \n\n"}
{"id": "1702.08231", "contents": "Title: Low-Precision Batch-Normalized Activations Abstract: Artificial neural networks can be trained with relatively low-precision\nfloating-point and fixed-point arithmetic, using between one and 16 bits.\nPrevious works have focused on relatively wide-but-shallow, feed-forward\nnetworks. We introduce a quantization scheme that is compatible with training\nvery deep neural networks. Quantizing the network activations in the middle of\neach batch-normalization module can greatly reduce the amount of memory and\ncomputational power needed, with little loss in accuracy. \n\n"}
{"id": "1702.08658", "contents": "Title: Towards Deeper Understanding of Variational Autoencoding Models Abstract: We propose a new family of optimization criteria for variational\nauto-encoding models, generalizing the standard evidence lower bound. We\nprovide conditions under which they recover the data distribution and learn\nlatent features, and formally show that common issues such as blurry samples\nand uninformative latent features arise when these conditions are not met.\nBased on these new insights, we propose a new sequential VAE model that can\ngenerate sharp samples on the LSUN image dataset based on pixel-wise\nreconstruction loss, and propose an optimization criterion that encourages\nunsupervised learning of informative latent features. \n\n"}
{"id": "1702.08740", "contents": "Title: Weakly- and Semi-Supervised Object Detection with\n  Expectation-Maximization Algorithm Abstract: Object detection when provided image-level labels instead of instance-level\nlabels (i.e., bounding boxes) during training is an important problem in\ncomputer vision, since large scale image datasets with instance-level labels\nare extremely costly to obtain. In this paper, we address this challenging\nproblem by developing an Expectation-Maximization (EM) based object detection\nmethod using deep convolutional neural networks (CNNs). Our method is\napplicable to both the weakly-supervised and semi-supervised settings.\nExtensive experiments on PASCAL VOC 2007 benchmark show that (1) in the weakly\nsupervised setting, our method provides significant detection performance\nimprovement over current state-of-the-art methods, (2) having access to a small\nnumber of strongly (instance-level) annotated images, our method can almost\nmatch the performace of the fully supervised Fast RCNN. We share our source\ncode at https://github.com/ZiangYan/EM-WSD. \n\n"}
{"id": "1703.00555", "contents": "Title: A Deep Cascade of Convolutional Neural Networks for MR Image\n  Reconstruction Abstract: The acquisition of Magnetic Resonance Imaging (MRI) is inherently slow.\nInspired by recent advances in deep learning, we propose a framework for\nreconstructing MR images from undersampled data using a deep cascade of\nconvolutional neural networks to accelerate the data acquisition process. We\nshow that for Cartesian undersampling of 2D cardiac MR images, the proposed\nmethod outperforms the state-of-the-art compressed sensing approaches, such as\ndictionary learning-based MRI (DLMRI) reconstruction, in terms of\nreconstruction error, perceptual quality and reconstruction speed for both\n3-fold and 6-fold undersampling. Compared to DLMRI, the error produced by the\nmethod proposed is approximately twice as small, allowing to preserve\nanatomical structures more faithfully. Using our method, each image can be\nreconstructed in 23 ms, which is fast enough to enable real-time applications. \n\n"}
{"id": "1703.00862", "contents": "Title: Binarized Convolutional Landmark Localizers for Human Pose Estimation\n  and Face Alignment with Limited Resources Abstract: Our goal is to design architectures that retain the groundbreaking\nperformance of CNNs for landmark localization and at the same time are\nlightweight, compact and suitable for applications with limited computational\nresources. To this end, we make the following contributions: (a) we are the\nfirst to study the effect of neural network binarization on localization tasks,\nnamely human pose estimation and face alignment. We exhaustively evaluate\nvarious design choices, identify performance bottlenecks, and more importantly\npropose multiple orthogonal ways to boost performance. (b) Based on our\nanalysis, we propose a novel hierarchical, parallel and multi-scale residual\narchitecture that yields large performance improvement over the standard\nbottleneck block while having the same number of parameters, thus bridging the\ngap between the original network and its binarized counterpart. (c) We perform\na large number of ablation studies that shed light on the properties and the\nperformance of the proposed block. (d) We present results for experiments on\nthe most challenging datasets for human pose estimation and face alignment,\nreporting in many cases state-of-the-art performance. Code can be downloaded\nfrom https://www.adrianbulat.com/binary-cnn-landmarks \n\n"}
{"id": "1703.02009", "contents": "Title: Learning across scales - A multiscale method for Convolution Neural\n  Networks Abstract: In this work we establish the relation between optimal control and training\ndeep Convolution Neural Networks (CNNs). We show that the forward propagation\nin CNNs can be interpreted as a time-dependent nonlinear differential equation\nand learning as controlling the parameters of the differential equation such\nthat the network approximates the data-label relation for given training data.\nUsing this continuous interpretation we derive two new methods to scale CNNs\nwith respect to two different dimensions. The first class of multiscale methods\nconnects low-resolution and high-resolution data through prolongation and\nrestriction of CNN parameters. We demonstrate that this enables classifying\nhigh-resolution images using CNNs trained with low-resolution images and vice\nversa and warm-starting the learning process. The second class of multiscale\nmethods connects shallow and deep networks and leads to new training strategies\nthat gradually increase the depths of the CNN while re-using parameters for\ninitializations. \n\n"}
{"id": "1703.03613", "contents": "Title: Fast LIDAR-based Road Detection Using Fully Convolutional Neural\n  Networks Abstract: In this work, a deep learning approach has been developed to carry out road\ndetection using only LIDAR data. Starting from an unstructured point cloud,\ntop-view images encoding several basic statistics such as mean elevation and\ndensity are generated. By considering a top-view representation, road detection\nis reduced to a single-scale problem that can be addressed with a simple and\nfast fully convolutional neural network (FCN). The FCN is specifically designed\nfor the task of pixel-wise semantic segmentation by combining a large receptive\nfield with high-resolution feature maps. The proposed system achieved excellent\nperformance and it is among the top-performing algorithms on the KITTI road\nbenchmark. Its fast inference makes it particularly suitable for real-time\napplications. \n\n"}
{"id": "1703.03872", "contents": "Title: Deep Image Matting Abstract: Image matting is a fundamental computer vision problem and has many\napplications. Previous algorithms have poor performance when an image has\nsimilar foreground and background colors or complicated textures. The main\nreasons are prior methods 1) only use low-level features and 2) lack high-level\ncontext. In this paper, we propose a novel deep learning based algorithm that\ncan tackle both these problems. Our deep model has two parts. The first part is\na deep convolutional encoder-decoder network that takes an image and the\ncorresponding trimap as inputs and predict the alpha matte of the image. The\nsecond part is a small convolutional network that refines the alpha matte\npredictions of the first network to have more accurate alpha values and sharper\nedges. In addition, we also create a large-scale image matting dataset\nincluding 49300 training images and 1000 testing images. We evaluate our\nalgorithm on the image matting benchmark, our testing set, and a wide variety\nof real images. Experimental results clearly demonstrate the superiority of our\nalgorithm over previous methods. \n\n"}
{"id": "1703.04775", "contents": "Title: Discriminate-and-Rectify Encoders: Learning from Image Transformation\n  Sets Abstract: The complexity of a learning task is increased by transformations in the\ninput space that preserve class identity. Visual object recognition for example\nis affected by changes in viewpoint, scale, illumination or planar\ntransformations. While drastically altering the visual appearance, these\nchanges are orthogonal to recognition and should not be reflected in the\nrepresentation or feature encoding used for learning. We introduce a framework\nfor weakly supervised learning of image embeddings that are robust to\ntransformations and selective to the class distribution, using sets of\ntransforming examples (orbit sets), deep parametrizations and a novel\norbit-based loss. The proposed loss combines a discriminative, contrastive part\nfor orbits with a reconstruction error that learns to rectify orbit\ntransformations. The learned embeddings are evaluated in distance metric-based\ntasks, such as one-shot classification under geometric transformations, as well\nas face verification and retrieval under more realistic visual variability. Our\nresults suggest that orbit sets, suitably computed or observed, can be used for\nefficient, weakly-supervised learning of semantically relevant image\nembeddings. \n\n"}
{"id": "1703.05161", "contents": "Title: Real-Time Panoramic Tracking for Event Cameras Abstract: Event cameras are a paradigm shift in camera technology. Instead of full\nframes, the sensor captures a sparse set of events caused by intensity changes.\nSince only the changes are transferred, those cameras are able to capture quick\nmovements of objects in the scene or of the camera itself. In this work we\npropose a novel method to perform camera tracking of event cameras in a\npanoramic setting with three degrees of freedom. We propose a direct camera\ntracking formulation, similar to state-of-the-art in visual odometry. We show\nthat the minimal information needed for simultaneous tracking and mapping is\nthe spatial position of events, without using the appearance of the imaged\nscene point. We verify the robustness to fast camera movements and dynamic\nobjects in the scene on a recently proposed dataset and self-recorded\nsequences. \n\n"}
{"id": "1703.05393", "contents": "Title: Convolutional Low-Resolution Fine-Grained Classification Abstract: Successful fine-grained image classification methods learn subtle details\nbetween visually similar (sub-)classes, but the problem becomes significantly\nmore challenging if the details are missing due to low resolution. Encouraged\nby the recent success of Convolutional Neural Network (CNN) architectures in\nimage classification, we propose a novel resolution-aware deep model which\ncombines convolutional image super-resolution and convolutional fine-grained\nclassification into a single model in an end-to-end manner. Extensive\nexperiments on the Stanford Cars and Caltech-UCSD Birds 200-2011 benchmarks\ndemonstrate that the proposed model consistently performs better than\nconventional convolutional net on classifying fine-grained object classes in\nlow-resolution images. \n\n"}
{"id": "1703.06283", "contents": "Title: Expecting the Unexpected: Training Detectors for Unusual Pedestrians\n  with Adversarial Imposters Abstract: As autonomous vehicles become an every-day reality, high-accuracy pedestrian\ndetection is of paramount practical importance. Pedestrian detection is a\nhighly researched topic with mature methods, but most datasets focus on common\nscenes of people engaged in typical walking poses on sidewalks. But performance\nis most crucial for dangerous scenarios, such as children playing in the street\nor people using bicycles/skateboards in unexpected ways. Such \"in-the-tail\"\ndata is notoriously hard to observe, making both training and testing\ndifficult. To analyze this problem, we have collected a novel annotated dataset\nof dangerous scenarios called the Precarious Pedestrian dataset. Even given a\ndedicated collection effort, it is relatively small by contemporary standards\n(around 1000 images). To allow for large-scale data-driven learning, we explore\nthe use of synthetic data generated by a game engine. A significant challenge\nis selected the right \"priors\" or parameters for synthesis: we would like\nrealistic data with poses and object configurations that mimic true Precarious\nPedestrians. Inspired by Generative Adversarial Networks (GANs), we generate a\nmassive amount of synthetic data and train a discriminative classifier to\nselect a realistic subset, which we deem the Adversarial Imposters. We\ndemonstrate that this simple pipeline allows one to synthesize realistic\ntraining data by making use of rendering/animation engines within a GAN\nframework. Interestingly, we also demonstrate that such data can be used to\nrank algorithms, suggesting that Adversarial Imposters can also be used for\n\"in-the-tail\" validation at test-time, a notoriously difficult challenge for\nreal-world deployment. \n\n"}
{"id": "1703.06585", "contents": "Title: Learning Cooperative Visual Dialog Agents with Deep Reinforcement\n  Learning Abstract: We introduce the first goal-driven training for visual question answering and\ndialog agents. Specifically, we pose a cooperative 'image guessing' game\nbetween two agents -- Qbot and Abot -- who communicate in natural language\ndialog so that Qbot can select an unseen image from a lineup of images. We use\ndeep reinforcement learning (RL) to learn the policies of these agents\nend-to-end -- from pixels to multi-agent multi-round dialog to game reward.\n  We demonstrate two experimental results.\n  First, as a 'sanity check' demonstration of pure RL (from scratch), we show\nresults on a synthetic world, where the agents communicate in ungrounded\nvocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We find\nthat two bots invent their own communication protocol and start using certain\nsymbols to ask/answer about certain visual attributes (shape/color/style).\nThus, we demonstrate the emergence of grounded language and communication among\n'visual' dialog agents with no human supervision.\n  Second, we conduct large-scale real-image experiments on the VisDial dataset,\nwhere we pretrain with supervised dialog data and show that the RL 'fine-tuned'\nagents significantly outperform SL agents. Interestingly, the RL Qbot learns to\nask questions that Abot is good at, ultimately resulting in more informative\ndialog and a better team. \n\n"}
{"id": "1703.06935", "contents": "Title: Fast Spectral Ranking for Similarity Search Abstract: Despite the success of deep learning on representing images for particular\nobject retrieval, recent studies show that the learned representations still\nlie on manifolds in a high dimensional space. This makes the Euclidean nearest\nneighbor search biased for this task. Exploring the manifolds online remains\nexpensive even if a nearest neighbor graph has been computed offline. This work\nintroduces an explicit embedding reducing manifold search to Euclidean search\nfollowed by dot product similarity search. This is equivalent to linear graph\nfiltering of a sparse signal in the frequency domain. To speed up online\nsearch, we compute an approximate Fourier basis of the graph offline. We\nimprove the state of art on particular object retrieval datasets including the\nchallenging Instre dataset containing small objects. At a scale of 10^5 images,\nthe offline cost is only a few hours, while query time is comparable to\nstandard similarity search. \n\n"}
{"id": "1703.07655", "contents": "Title: ASP: Learning to Forget with Adaptive Synaptic Plasticity in Spiking\n  Neural Networks Abstract: A fundamental feature of learning in animals is the \"ability to forget\" that\nallows an organism to perceive, model and make decisions from disparate streams\nof information and adapt to changing environments. Against this backdrop, we\npresent a novel unsupervised learning mechanism ASP (Adaptive Synaptic\nPlasticity) for improved recognition with Spiking Neural Networks (SNNs) for\nreal time on-line learning in a dynamic environment. We incorporate an adaptive\nweight decay mechanism with the traditional Spike Timing Dependent Plasticity\n(STDP) learning to model adaptivity in SNNs. The leak rate of the synaptic\nweights is modulated based on the temporal correlation between the spiking\npatterns of the pre- and post-synaptic neurons. This mechanism helps in gradual\nforgetting of insignificant data while retaining significant, yet old,\ninformation. ASP, thus, maintains a balance between forgetting and immediate\nlearning to construct a stable-plastic self-adaptive SNN for continuously\nchanging inputs. We demonstrate that the proposed learning methodology\naddresses catastrophic forgetting while yielding significantly improved\naccuracy over the conventional STDP learning method for digit recognition\napplications. Additionally, we observe that the proposed learning model\nautomatically encodes selective attention towards relevant features in the\ninput data while eliminating the influence of background noise (or denoising)\nfurther improving the robustness of the ASP learning. \n\n"}
{"id": "1703.07684", "contents": "Title: Predicting Deeper into the Future of Semantic Segmentation Abstract: The ability to predict and therefore to anticipate the future is an important\nattribute of intelligence. It is also of utmost importance in real-time\nsystems, e.g. in robotics or autonomous driving, which depend on visual scene\nunderstanding for decision making. While prediction of the raw RGB pixel values\nin future video frames has been studied in previous work, here we introduce the\nnovel task of predicting semantic segmentations of future frames. Given a\nsequence of video frames, our goal is to predict segmentation maps of not yet\nobserved video frames that lie up to a second or further in the future. We\ndevelop an autoregressive convolutional neural network that learns to\niteratively generate multiple frames. Our results on the Cityscapes dataset\nshow that directly predicting future segmentations is substantially better than\npredicting and then segmenting future RGB frames. Prediction results up to half\na second in the future are visually convincing and are much more accurate than\nthose of a baseline based on warping semantic segmentations using optical flow. \n\n"}
{"id": "1703.07915", "contents": "Title: Perspective: Energy Landscapes for Machine Learning Abstract: Machine learning techniques are being increasingly used as flexible\nnon-linear fitting and prediction tools in the physical sciences. Fitting\nfunctions that exhibit multiple solutions as local minima can be analysed in\nterms of the corresponding machine learning landscape. Methods to explore and\nvisualise molecular potential energy landscapes can be applied to these machine\nlearning landscapes to gain new insight into the solution space involved in\ntraining and the nature of the corresponding predictions. In particular, we can\ndefine quantities analogous to molecular structure, thermodynamics, and\nkinetics, and relate these emergent properties to the structure of the\nunderlying landscape. This Perspective aims to describe these analogies with\nexamples from recent applications, and suggest avenues for new\ninterdisciplinary research. \n\n"}
{"id": "1703.08033", "contents": "Title: Generative Adversarial Residual Pairwise Networks for One Shot Learning Abstract: Deep neural networks achieve unprecedented performance levels over many tasks\nand scale well with large quantities of data, but performance in the low-data\nregime and tasks like one shot learning still lags behind. While recent work\nsuggests many hypotheses from better optimization to more complicated network\nstructures, in this work we hypothesize that having a learnable and more\nexpressive similarity objective is an essential missing component. Towards\novercoming that, we propose a network design inspired by deep residual networks\nthat allows the efficient computation of this more expressive pairwise\nsimilarity objective. Further, we argue that regularization is key in learning\nwith small amounts of data, and propose an additional generator network based\non the Generative Adversarial Networks where the discriminator is our residual\npairwise network. This provides a strong regularizer by leveraging the\ngenerated data samples. The proposed model can generate plausible variations of\nexemplars over unseen classes and outperforms strong discriminative baselines\nfor few shot classification tasks. Notably, our residual pairwise network\ndesign outperforms previous state-of-theart on the challenging mini-Imagenet\ndataset for one shot learning by getting over 55% accuracy for the 5-way\nclassification task over unseen classes. \n\n"}
{"id": "1703.08987", "contents": "Title: LIDAR-based Driving Path Generation Using Fully Convolutional Neural\n  Networks Abstract: In this work, a novel learning-based approach has been developed to generate\ndriving paths by integrating LIDAR point clouds, GPS-IMU information, and\nGoogle driving directions. The system is based on a fully convolutional neural\nnetwork that jointly learns to carry out perception and path generation from\nreal-world driving sequences and that is trained using automatically generated\ntraining examples. Several combinations of input data were tested in order to\nassess the performance gain provided by specific information modalities. The\nfully convolutional neural network trained using all the available sensors\ntogether with driving directions achieved the best MaxF score of 88.13% when\nconsidering a region of interest of 60x60 meters. By considering a smaller\nregion of interest, the agreement between predicted paths and ground-truth\nincreased to 92.60%. The positive results obtained in this work indicate that\nthe proposed system may help fill the gap between low-level scene parsing and\nbehavior-reflex approaches by generating outputs that are close to vehicle\ncontrol and at the same time human-interpretable. \n\n"}
{"id": "1703.09529", "contents": "Title: Objects as context for detecting their semantic parts Abstract: We present a semantic part detection approach that effectively leverages\nobject information.We use the object appearance and its class as indicators of\nwhat parts to expect. We also model the expected relative location of parts\ninside the objects based on their appearance. We achieve this with a new\nnetwork module, called OffsetNet, that efficiently predicts a variable number\nof part locations within a given object. Our model incorporates all these cues\nto detect parts in the context of their objects. This leads to considerably\nhigher performance for the challenging task of part detection compared to using\npart appearance alone (+5 mAP on the PASCAL-Part dataset). We also compare to\nother part detection methods on both PASCAL-Part and CUB200-2011 datasets. \n\n"}
{"id": "1703.09695", "contents": "Title: Semi and Weakly Supervised Semantic Segmentation Using Generative\n  Adversarial Network Abstract: Semantic segmentation has been a long standing challenging task in computer\nvision. It aims at assigning a label to each image pixel and needs significant\nnumber of pixellevel annotated data, which is often unavailable. To address\nthis lack, in this paper, we leverage, on one hand, massive amount of available\nunlabeled or weakly labeled data, and on the other hand, non-real images\ncreated through Generative Adversarial Networks. In particular, we propose a\nsemi-supervised framework ,based on Generative Adversarial Networks (GANs),\nwhich consists of a generator network to provide extra training examples to a\nmulti-class classifier, acting as discriminator in the GAN framework, that\nassigns sample a label y from the K possible classes or marks it as a fake\nsample (extra class). The underlying idea is that adding large fake visual data\nforces real samples to be close in the feature space, enabling a bottom-up\nclustering process, which, in turn, improves multiclass pixel classification.\nTo ensure higher quality of generated images for GANs with consequent improved\npixel classification, we extend the above framework by adding weakly annotated\ndata, i.e., we provide class level information to the generator. We tested our\napproaches on several challenging benchmarking visual datasets, i.e. PASCAL,\nSiftFLow, Stanford and CamVid, achieving competitive performance also compared\nto state-of-the-art semantic segmentation method \n\n"}
{"id": "1703.09891", "contents": "Title: LabelBank: Revisiting Global Perspectives for Semantic Segmentation Abstract: Semantic segmentation requires a detailed labeling of image pixels by object\ncategory. Information derived from local image patches is necessary to describe\nthe detailed shape of individual objects. However, this information is\nambiguous and can result in noisy labels. Global inference of image content can\ninstead capture the general semantic concepts present. We advocate that\nholistic inference of image concepts provides valuable information for detailed\npixel labeling. We propose a generic framework to leverage holistic information\nin the form of a LabelBank for pixel-level segmentation.\n  We show the ability of our framework to improve semantic segmentation\nperformance in a variety of settings. We learn models for extracting a holistic\nLabelBank from visual cues, attributes, and/or textual descriptions. We\ndemonstrate improvements in semantic segmentation accuracy on standard datasets\nacross a range of state-of-the-art segmentation architectures and holistic\ninference approaches. \n\n"}
{"id": "1703.09913", "contents": "Title: Who's Better? Who's Best? Pairwise Deep Ranking for Skill Determination Abstract: We present a method for assessing skill from video, applicable to a variety\nof tasks, ranging from surgery to drawing and rolling pizza dough. We formulate\nthe problem as pairwise (who's better?) and overall (who's best?) ranking of\nvideo collections, using supervised deep ranking. We propose a novel loss\nfunction that learns discriminative features when a pair of videos exhibit\nvariance in skill, and learns shared features when a pair of videos exhibit\ncomparable skill levels. Results demonstrate our method is applicable across\ntasks, with the percentage of correctly ordered pairs of videos ranging from\n70% to 83% for four datasets. We demonstrate the robustness of our approach via\nsensitivity analysis of its parameters. We see this work as effort toward the\nautomated organization of how-to video collections and overall, generic skill\ndetermination in video. \n\n"}
{"id": "1703.09964", "contents": "Title: Image Restoration using Autoencoding Priors Abstract: We propose to leverage denoising autoencoder networks as priors to address\nimage restoration problems. We build on the key observation that the output of\nan optimal denoising autoencoder is a local mean of the true data density, and\nthe autoencoder error (the difference between the output and input of the\ntrained autoencoder) is a mean shift vector. We use the magnitude of this mean\nshift vector, that is, the distance to the local mean, as the negative log\nlikelihood of our natural image prior. For image restoration, we maximize the\nlikelihood using gradient descent by backpropagating the autoencoder error. A\nkey advantage of our approach is that we do not need to train separate networks\nfor different image restoration tasks, such as non-blind deconvolution with\ndifferent kernels, or super-resolution at different magnification factors. We\ndemonstrate state of the art results for non-blind deconvolution and\nsuper-resolution using the same autoencoding prior. \n\n"}
{"id": "1703.10444", "contents": "Title: On Fundamental Limits of Robust Learning Abstract: We consider the problems of robust PAC learning from distributed and\nstreaming data, which may contain malicious errors and outliers, and analyze\ntheir fundamental complexity questions. In particular, we establish lower\nbounds on the communication complexity for distributed robust learning\nperformed on multiple machines, and on the space complexity for robust learning\nfrom streaming data on a single machine. These results demonstrate that gaining\nrobustness of learning algorithms is usually at the expense of increased\ncomplexities. As far as we know, this work gives the first complexity results\nfor distributed and online robust PAC learning. \n\n"}
{"id": "1703.10593", "contents": "Title: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial\n  Networks Abstract: Image-to-image translation is a class of vision and graphics problems where\nthe goal is to learn the mapping between an input image and an output image\nusing a training set of aligned image pairs. However, for many tasks, paired\ntraining data will not be available. We present an approach for learning to\ntranslate an image from a source domain $X$ to a target domain $Y$ in the\nabsence of paired examples. Our goal is to learn a mapping $G: X \\rightarrow Y$\nsuch that the distribution of images from $G(X)$ is indistinguishable from the\ndistribution $Y$ using an adversarial loss. Because this mapping is highly\nunder-constrained, we couple it with an inverse mapping $F: Y \\rightarrow X$\nand introduce a cycle consistency loss to push $F(G(X)) \\approx X$ (and vice\nversa). Qualitative results are presented on several tasks where paired\ntraining data does not exist, including collection style transfer, object\ntransfiguration, season transfer, photo enhancement, etc. Quantitative\ncomparisons against several prior methods demonstrate the superiority of our\napproach. \n\n"}
{"id": "1704.00763", "contents": "Title: AMC: Attention guided Multi-modal Correlation Learning for Image Search Abstract: Given a user's query, traditional image search systems rank images according\nto its relevance to a single modality (e.g., image content or surrounding\ntext). Nowadays, an increasing number of images on the Internet are available\nwith associated meta data in rich modalities (e.g., titles, keywords, tags,\netc.), which can be exploited for better similarity measure with queries. In\nthis paper, we leverage visual and textual modalities for image search by\nlearning their correlation with input query. According to the intent of query,\nattention mechanism can be introduced to adaptively balance the importance of\ndifferent modalities. We propose a novel Attention guided Multi-modal\nCorrelation (AMC) learning method which consists of a jointly learned hierarchy\nof intra and inter-attention networks. Conditioned on query's intent,\nintra-attention networks (i.e., visual intra-attention network and language\nintra-attention network) attend on informative parts within each modality; a\nmulti-modal inter-attention network promotes the importance of the most\nquery-relevant modalities. In experiments, we evaluate AMC models on the search\nlogs from two real world image search engines and show a significant boost on\nthe ranking of user-clicked images in search results. Additionally, we extend\nAMC models to caption ranking task on COCO dataset and achieve competitive\nresults compared with recent state-of-the-arts. \n\n"}
{"id": "1704.00834", "contents": "Title: Cascaded Segmentation-Detection Networks for Word-Level Text Spotting Abstract: We introduce an algorithm for word-level text spotting that is able to\naccurately and reliably determine the bounding regions of individual words of\ntext \"in the wild\". Our system is formed by the cascade of two convolutional\nneural networks. The first network is fully convolutional and is in charge of\ndetecting areas containing text. This results in a very reliable but possibly\ninaccurate segmentation of the input image. The second network (inspired by the\npopular YOLO architecture) analyzes each segment produced in the first stage,\nand predicts oriented rectangular regions containing individual words. No\npost-processing (e.g. text line grouping) is necessary. With execution time of\n450 ms for a 1000-by-560 image on a Titan X GPU, our system achieves the\nhighest score to date among published algorithms on the ICDAR 2015 Incidental\nScene Text dataset benchmark. \n\n"}
{"id": "1704.01137", "contents": "Title: DyVEDeep: Dynamic Variable Effort Deep Neural Networks Abstract: Deep Neural Networks (DNNs) have advanced the state-of-the-art in a variety\nof machine learning tasks and are deployed in increasing numbers of products\nand services. However, the computational requirements of training and\nevaluating large-scale DNNs are growing at a much faster pace than the\ncapabilities of the underlying hardware platforms that they are executed upon.\nIn this work, we propose Dynamic Variable Effort Deep Neural Networks\n(DyVEDeep) to reduce the computational requirements of DNNs during inference.\nPrevious efforts propose specialized hardware implementations for DNNs,\nstatically prune the network, or compress the weights. Complementary to these\napproaches, DyVEDeep is a dynamic approach that exploits the heterogeneity in\nthe inputs to DNNs to improve their compute efficiency with comparable\nclassification accuracy. DyVEDeep equips DNNs with dynamic effort mechanisms\nthat, in the course of processing an input, identify how critical a group of\ncomputations are to classify the input. DyVEDeep dynamically focuses its\ncompute effort only on the critical computa- tions, while skipping or\napproximating the rest. We propose 3 effort knobs that operate at different\nlevels of granularity viz. neuron, feature and layer levels. We build DyVEDeep\nversions for 5 popular image recognition benchmarks - one for CIFAR-10 and four\nfor ImageNet (AlexNet, OverFeat and VGG-16, weight-compressed AlexNet). Across\nall benchmarks, DyVEDeep achieves 2.1x-2.6x reduction in the number of scalar\noperations, which translates to 1.8x-2.3x performance improvement over a\nCaffe-based implementation, with < 0.5% loss in accuracy. \n\n"}
{"id": "1704.01344", "contents": "Title: Not All Pixels Are Equal: Difficulty-aware Semantic Segmentation via\n  Deep Layer Cascade Abstract: We propose a novel deep layer cascade (LC) method to improve the accuracy and\nspeed of semantic segmentation. Unlike the conventional model cascade (MC) that\nis composed of multiple independent models, LC treats a single deep model as a\ncascade of several sub-models. Earlier sub-models are trained to handle easy\nand confident regions, and they progressively feed-forward harder regions to\nthe next sub-model for processing. Convolutions are only calculated on these\nregions to reduce computations. The proposed method possesses several\nadvantages. First, LC classifies most of the easy regions in the shallow stage\nand makes deeper stage focuses on a few hard regions. Such an adaptive and\n'difficulty-aware' learning improves segmentation performance. Second, LC\naccelerates both training and testing of deep network thanks to early decisions\nin the shallow stage. Third, in comparison to MC, LC is an end-to-end trainable\nframework, allowing joint learning of all sub-models. We evaluate our method on\nPASCAL VOC and Cityscapes datasets, achieving state-of-the-art performance and\nfast speed. \n\n"}
{"id": "1704.02081", "contents": "Title: Evolution in Groups: A deeper look at synaptic cluster driven evolution\n  of deep neural networks Abstract: A promising paradigm for achieving highly efficient deep neural networks is\nthe idea of evolutionary deep intelligence, which mimics biological evolution\nprocesses to progressively synthesize more efficient networks. A crucial design\nfactor in evolutionary deep intelligence is the genetic encoding scheme used to\nsimulate heredity and determine the architectures of offspring networks. In\nthis study, we take a deeper look at the notion of synaptic cluster-driven\nevolution of deep neural networks which guides the evolution process towards\nthe formation of a highly sparse set of synaptic clusters in offspring\nnetworks. Utilizing a synaptic cluster-driven genetic encoding, the\nprobabilistic encoding of synaptic traits considers not only individual\nsynaptic properties but also inter-synaptic relationships within a deep neural\nnetwork. This process results in highly sparse offspring networks which are\nparticularly tailored for parallel computational devices such as GPUs and deep\nneural network accelerator chips. Comprehensive experimental results using four\nwell-known deep neural network architectures (LeNet-5, AlexNet, ResNet-56, and\nDetectNet) on two different tasks (object categorization and object detection)\ndemonstrate the efficiency of the proposed method. Cluster-driven genetic\nencoding scheme synthesizes networks that can achieve state-of-the-art\nperformance with significantly smaller number of synapses than that of the\noriginal ancestor network. ($\\sim$125-fold decrease in synapses for MNIST).\nFurthermore, the improved cluster efficiency in the generated offspring\nnetworks ($\\sim$9.71-fold decrease in clusters for MNIST and a $\\sim$8.16-fold\ndecrease in clusters for KITTI) is particularly useful for accelerated\nperformance on parallel computing hardware architectures such as those in GPUs\nand deep neural network accelerator chips. \n\n"}
{"id": "1704.02081", "contents": "Title: Evolution in Groups: A deeper look at synaptic cluster driven evolution\n  of deep neural networks Abstract: A promising paradigm for achieving highly efficient deep neural networks is\nthe idea of evolutionary deep intelligence, which mimics biological evolution\nprocesses to progressively synthesize more efficient networks. A crucial design\nfactor in evolutionary deep intelligence is the genetic encoding scheme used to\nsimulate heredity and determine the architectures of offspring networks. In\nthis study, we take a deeper look at the notion of synaptic cluster-driven\nevolution of deep neural networks which guides the evolution process towards\nthe formation of a highly sparse set of synaptic clusters in offspring\nnetworks. Utilizing a synaptic cluster-driven genetic encoding, the\nprobabilistic encoding of synaptic traits considers not only individual\nsynaptic properties but also inter-synaptic relationships within a deep neural\nnetwork. This process results in highly sparse offspring networks which are\nparticularly tailored for parallel computational devices such as GPUs and deep\nneural network accelerator chips. Comprehensive experimental results using four\nwell-known deep neural network architectures (LeNet-5, AlexNet, ResNet-56, and\nDetectNet) on two different tasks (object categorization and object detection)\ndemonstrate the efficiency of the proposed method. Cluster-driven genetic\nencoding scheme synthesizes networks that can achieve state-of-the-art\nperformance with significantly smaller number of synapses than that of the\noriginal ancestor network. ($\\sim$125-fold decrease in synapses for MNIST).\nFurthermore, the improved cluster efficiency in the generated offspring\nnetworks ($\\sim$9.71-fold decrease in clusters for MNIST and a $\\sim$8.16-fold\ndecrease in clusters for KITTI) is particularly useful for accelerated\nperformance on parallel computing hardware architectures such as those in GPUs\nand deep neural network accelerator chips. \n\n"}
{"id": "1704.02694", "contents": "Title: ClusterNet: Detecting Small Objects in Large Scenes by Exploiting\n  Spatio-Temporal Information Abstract: Object detection in wide area motion imagery (WAMI) has drawn the attention\nof the computer vision research community for a number of years. WAMI proposes\na number of unique challenges including extremely small object sizes, both\nsparse and densely-packed objects, and extremely large search spaces (large\nvideo frames). Nearly all state-of-the-art methods in WAMI object detection\nreport that appearance-based classifiers fail in this challenging data and\ninstead rely almost entirely on motion information in the form of background\nsubtraction or frame-differencing. In this work, we experimentally verify the\nfailure of appearance-based classifiers in WAMI, such as Faster R-CNN and a\nheatmap-based fully convolutional neural network (CNN), and propose a novel\ntwo-stage spatio-temporal CNN which effectively and efficiently combines both\nappearance and motion information to significantly surpass the state-of-the-art\nin WAMI object detection. To reduce the large search space, the first stage\n(ClusterNet) takes in a set of extremely large video frames, combines the\nmotion and appearance information within the convolutional architecture, and\nproposes regions of objects of interest (ROOBI). These ROOBI can contain from\none to clusters of several hundred objects due to the large video frame size\nand varying object density in WAMI. The second stage (FoveaNet) then estimates\nthe centroid location of all objects in that given ROOBI simultaneously via\nheatmap estimation. The proposed method exceeds state-of-the-art results on the\nWPAFB 2009 dataset by 5-16% for moving objects and nearly 50% for stopped\nobjects, as well as being the first proposed method in wide area motion imagery\nto detect completely stationary objects. \n\n"}
{"id": "1704.02798", "contents": "Title: Bayesian Recurrent Neural Networks Abstract: In this work we explore a straightforward variational Bayes scheme for\nRecurrent Neural Networks. Firstly, we show that a simple adaptation of\ntruncated backpropagation through time can yield good quality uncertainty\nestimates and superior regularisation at only a small extra computational cost\nduring training, also reducing the amount of parameters by 80\\%. Secondly, we\ndemonstrate how a novel kind of posterior approximation yields further\nimprovements to the performance of Bayesian RNNs. We incorporate local gradient\ninformation into the approximate posterior to sharpen it around the current\nbatch statistics. We show how this technique is not exclusive to recurrent\nneural networks and can be applied more widely to train Bayesian neural\nnetworks. We also empirically demonstrate how Bayesian RNNs are superior to\ntraditional RNNs on a language modelling benchmark and an image captioning\ntask, as well as showing how each of these methods improve our model over a\nvariety of other schemes for training them. We also introduce a new benchmark\nfor studying uncertainty for language models so future methods can be easily\ncompared. \n\n"}
{"id": "1704.02906", "contents": "Title: Multi-Agent Diverse Generative Adversarial Networks Abstract: We propose MAD-GAN, an intuitive generalization to the Generative Adversarial\nNetworks (GANs) and its conditional variants to address the well known problem\nof mode collapse. First, MAD-GAN is a multi-agent GAN architecture\nincorporating multiple generators and one discriminator. Second, to enforce\nthat different generators capture diverse high probability modes, the\ndiscriminator of MAD-GAN is designed such that along with finding the real and\nfake samples, it is also required to identify the generator that generated the\ngiven fake sample. Intuitively, to succeed in this task, the discriminator must\nlearn to push different generators towards different identifiable modes. We\nperform extensive experiments on synthetic and real datasets and compare\nMAD-GAN with different variants of GAN. We show high quality diverse sample\ngenerations for challenging tasks such as image-to-image translation and face\ngeneration. In addition, we also show that MAD-GAN is able to disentangle\ndifferent modalities when trained using highly challenging diverse-class\ndataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the\nend, we show its efficacy on the unsupervised feature representation task. In\nAppendix, we introduce a similarity based competing objective (MAD-GAN-Sim)\nwhich encourages different generators to generate diverse samples based on a\nuser defined similarity metric. We show its performance on the image-to-image\ntranslation, and also show its effectiveness on the unsupervised feature\nrepresentation task. \n\n"}
{"id": "1704.02958", "contents": "Title: On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel\n  Methods and Neural Networks Abstract: Empirical risk minimization (ERM) is ubiquitous in machine learning and\nunderlies most supervised learning methods. While there has been a large body\nof work on algorithms for various ERM problems, the exact computational\ncomplexity of ERM is still not understood. We address this issue for multiple\npopular ERM problems including kernel SVMs, kernel ridge regression, and\ntraining the final layer of a neural network. In particular, we give\nconditional hardness results for these problems based on complexity-theoretic\nassumptions such as the Strong Exponential Time Hypothesis. Under these\nassumptions, we show that there are no algorithms that solve the aforementioned\nERM problems to high accuracy in sub-quadratic time. We also give similar\nhardness results for computing the gradient of the empirical loss, which is the\nmain computational burden in many non-convex learning tasks. \n\n"}
{"id": "1704.03373", "contents": "Title: Quality Aware Network for Set to Set Recognition Abstract: This paper targets on the problem of set to set recognition, which learns the\nmetric between two image sets. Images in each set belong to the same identity.\nSince images in a set can be complementary, they hopefully lead to higher\naccuracy in practical applications. However, the quality of each sample cannot\nbe guaranteed, and samples with poor quality will hurt the metric. In this\npaper, the quality aware network (QAN) is proposed to confront this problem,\nwhere the quality of each sample can be automatically learned although such\ninformation is not explicitly provided in the training stage. The network has\ntwo branches, where the first branch extracts appearance feature embedding for\neach sample and the other branch predicts quality score for each sample.\nFeatures and quality scores of all samples in a set are then aggregated to\ngenerate the final feature embedding. We show that the two branches can be\ntrained in an end-to-end manner given only the set-level identity annotation.\nAnalysis on gradient spread of this mechanism indicates that the quality\nlearned by the network is beneficial to set-to-set recognition and simplifies\nthe distribution that the network needs to fit. Experiments on both face\nverification and person re-identification show advantages of the proposed QAN.\nThe source code and network structure can be downloaded at\nhttps://github.com/sciencefans/Quality-Aware-Network. \n\n"}
{"id": "1704.03844", "contents": "Title: Determining Song Similarity via Machine Learning Techniques and Tagging\n  Information Abstract: The task of determining item similarity is a crucial one in a recommender\nsystem. This constitutes the base upon which the recommender system will work\nto determine which items are more likely to be enjoyed by a user, resulting in\nmore user engagement. In this paper we tackle the problem of determining song\nsimilarity based solely on song metadata (such as the performer, and song\ntitle) and on tags contributed by users. We evaluate our approach under a\nseries of different machine learning algorithms. We conclude that tf-idf\nachieves better results than Word2Vec to model the dataset to feature vectors.\nWe also conclude that k-NN models have better performance than SVMs and Linear\nRegression for this problem. \n\n"}
{"id": "1704.03899", "contents": "Title: Deep Reinforcement Learning-based Image Captioning with Embedding Reward Abstract: Image captioning is a challenging problem owing to the complexity in\nunderstanding the image content and diverse ways of describing it in natural\nlanguage. Recent advances in deep neural networks have substantially improved\nthe performance of this task. Most state-of-the-art approaches follow an\nencoder-decoder framework, which generates captions using a sequential\nrecurrent prediction model. However, in this paper, we introduce a novel\ndecision-making framework for image captioning. We utilize a \"policy network\"\nand a \"value network\" to collaboratively generate captions. The policy network\nserves as a local guidance by providing the confidence of predicting the next\nword according to the current state. Additionally, the value network serves as\na global and lookahead guidance by evaluating all possible extensions of the\ncurrent state. In essence, it adjusts the goal of predicting the correct words\ntowards the goal of generating captions similar to the ground truth captions.\nWe train both networks using an actor-critic reinforcement learning model, with\na novel reward defined by visual-semantic embedding. Extensive experiments and\nanalyses on the Microsoft COCO dataset show that the proposed framework\noutperforms state-of-the-art approaches across different evaluation metrics. \n\n"}
{"id": "1704.04861", "contents": "Title: MobileNets: Efficient Convolutional Neural Networks for Mobile Vision\n  Applications Abstract: We present a class of efficient models called MobileNets for mobile and\nembedded vision applications. MobileNets are based on a streamlined\narchitecture that uses depth-wise separable convolutions to build light weight\ndeep neural networks. We introduce two simple global hyper-parameters that\nefficiently trade off between latency and accuracy. These hyper-parameters\nallow the model builder to choose the right sized model for their application\nbased on the constraints of the problem. We present extensive experiments on\nresource and accuracy tradeoffs and show strong performance compared to other\npopular models on ImageNet classification. We then demonstrate the\neffectiveness of MobileNets across a wide range of applications and use cases\nincluding object detection, finegrain classification, face attributes and large\nscale geo-localization. \n\n"}
{"id": "1704.05796", "contents": "Title: Network Dissection: Quantifying Interpretability of Deep Visual\n  Representations Abstract: We propose a general framework called Network Dissection for quantifying the\ninterpretability of latent representations of CNNs by evaluating the alignment\nbetween individual hidden units and a set of semantic concepts. Given any CNN\nmodel, the proposed method draws on a broad data set of visual concepts to\nscore the semantics of hidden units at each intermediate convolutional layer.\nThe units with semantics are given labels across a range of objects, parts,\nscenes, textures, materials, and colors. We use the proposed method to test the\nhypothesis that interpretability of units is equivalent to random linear\ncombinations of units, then we apply our method to compare the latent\nrepresentations of various networks when trained to solve different supervised\nand self-supervised training tasks. We further analyze the effect of training\niterations, compare networks trained with different initializations, examine\nthe impact of network depth and width, and measure the effect of dropout and\nbatch normalization on the interpretability of deep visual representations. We\ndemonstrate that the proposed method can shed light on characteristics of CNN\nmodels and training methods that go beyond measurements of their discriminative\npower. \n\n"}
{"id": "1704.05982", "contents": "Title: Retrospective Higher-Order Markov Processes for User Trails Abstract: Users form information trails as they browse the web, checkin with a\ngeolocation, rate items, or consume media. A common problem is to predict what\na user might do next for the purposes of guidance, recommendation, or\nprefetching. First-order and higher-order Markov chains have been widely used\nmethods to study such sequences of data. First-order Markov chains are easy to\nestimate, but lack accuracy when history matters. Higher-order Markov chains,\nin contrast, have too many parameters and suffer from overfitting the training\ndata. Fitting these parameters with regularization and smoothing only offers\nmild improvements. In this paper we propose the retrospective higher-order\nMarkov process (RHOMP) as a low-parameter model for such sequences. This model\nis a special case of a higher-order Markov chain where the transitions depend\nretrospectively on a single history state instead of an arbitrary combination\nof history states. There are two immediate computational advantages: the number\nof parameters is linear in the order of the Markov chain and the model can be\nfit to large state spaces. Furthermore, by providing a specific structure to\nthe higher-order chain, RHOMPs improve the model accuracy by efficiently\nutilizing history states without risks of overfitting the data. We demonstrate\nhow to estimate a RHOMP from data and we demonstrate the effectiveness of our\nmethod on various real application datasets spanning geolocation data, review\nsequences, and business locations. The RHOMP model uniformly outperforms\nhigher-order Markov chains, Kneser-Ney regularization, and tensor\nfactorizations in terms of prediction accuracy. \n\n"}
{"id": "1704.06656", "contents": "Title: Feature selection algorithm based on Catastrophe model to improve the\n  performance of regression analysis Abstract: In this paper we introduce a new feature selection algorithm to remove the\nirrelevant or redundant features in the data sets. In this algorithm the\nimportance of a feature is based on its fitting to the Catastrophe model.\nAkaike information crite- rion value is used for ranking the features in the\ndata set. The proposed algorithm is compared with well-known RELIEF feature\nselection algorithm. Breast Cancer, Parkinson Telemonitoring data and Slice\nlocality data sets are used to evaluate the model. \n\n"}
{"id": "1704.07085", "contents": "Title: Unified Framework for Automated Person Re-identification and Camera\n  Network Topology Inference in Camera Networks Abstract: Person re-identification in large-scale multi-camera networks is a\nchallenging task because of the spatio-temporal uncertainty and high complexity\ndue to large numbers of cameras and people. To handle these difficulties,\nadditional information such as camera network topology should be provided,\nwhich is also difficult to automatically estimate. In this paper, we propose a\nunified framework which jointly solves both person re-id and camera network\ntopology inference problems. The proposed framework takes general multi-camera\nnetwork environments into account. To effectively show the superiority of the\nproposed framework, we also provide a new person re-id dataset with full\nannotations, named SLP, captured in the synchronized multi-camera network.\nExperimental results show that the proposed methods are promising for both\nperson re-id and camera topology inference tasks. \n\n"}
{"id": "1704.07244", "contents": "Title: Fast PET reconstruction using Multi-scale Fully Convolutional Neural\n  Networks Abstract: Reconstruction of PET images is an ill-posed inverse problem and often\nrequires iterative algorithms to achieve good image quality for reliable\nclinical use in practice, at huge computational costs. In this paper, we\nconsider the PET reconstruction a dense prediction problem where the large\nscale contextual information is essential, and propose a novel architecture of\nmulti-scale fully convolutional neural networks (msfCNN) for fast PET image\nreconstruction. The proposed msfCNN gains large receptive fields with both\nmemory and computational efficiency, by using a downscaling-upscaling structure\nand dilated convolutions. Instead of pooling and deconvolution, we propose to\nuse the periodic shuffling operation from sub-pixel convolution and its inverse\nto scale the size of feature maps without losing resolution. Residual\nconnections were added to improve training. We trained the proposed msfCNN\nmodel with simulated data, and applied it to clinical PET data acquired on a\nSiemens mMR scanner. The results from real oncological and neurodegenerative\ncases show that the proposed msfCNN-based reconstruction outperforms the\niterative approaches in terms of computational time while achieving comparable\nimage quality for quantification. The proposed msfCNN model can be applied to\nother dense prediction tasks, and fast msfCNN-based PET reconstruction could\nfacilitate the potential use of molecular imaging in interventional/surgical\nprocedures, where cancer surgery can particularly benefit. \n\n"}
{"id": "1704.08224", "contents": "Title: Punny Captions: Witty Wordplay in Image Descriptions Abstract: Wit is a form of rich interaction that is often grounded in a specific\nsituation (e.g., a comment in response to an event). In this work, we attempt\nto build computational models that can produce witty descriptions for a given\nimage. Inspired by a cognitive account of humor appreciation, we employ\nlinguistic wordplay, specifically puns, in image descriptions. We develop two\napproaches which involve retrieving witty descriptions for a given image from a\nlarge corpus of sentences, or generating them via an encoder-decoder neural\nnetwork architecture. We compare our approach against meaningful baseline\napproaches via human studies and show substantial improvements. We find that\nwhen a human is subject to similar constraints as the model regarding word\nusage and style, people vote the image descriptions generated by our model to\nbe slightly wittier than human-written witty descriptions. Unsurprisingly,\nhumans are almost always wittier than the model when they are free to choose\nthe vocabulary, style, etc. \n\n"}
{"id": "1705.02407", "contents": "Title: Knowledge-Guided Deep Fractal Neural Networks for Human Pose Estimation Abstract: Human pose estimation using deep neural networks aims to map input images\nwith large variations into multiple body keypoints which must satisfy a set of\ngeometric constraints and inter-dependency imposed by the human body model.\nThis is a very challenging nonlinear manifold learning process in a very high\ndimensional feature space. We believe that the deep neural network, which is\ninherently an algebraic computation system, is not the most effecient way to\ncapture highly sophisticated human knowledge, for example those highly coupled\ngeometric characteristics and interdependence between keypoints in human poses.\nIn this work, we propose to explore how external knowledge can be effectively\nrepresented and injected into the deep neural networks to guide its training\nprocess using learned projections that impose proper prior. Specifically, we\nuse the stacked hourglass design and inception-resnet module to construct a\nfractal network to regress human pose images into heatmaps with no explicit\ngraphical modeling. We encode external knowledge with visual features which are\nable to characterize the constraints of human body models and evaluate the\nfitness of intermediate network output. We then inject these external features\ninto the neural network using a projection matrix learned using an auxiliary\ncost function. The effectiveness of the proposed inception-resnet module and\nthe benefit in guided learning with knowledge projection is evaluated on two\nwidely used benchmarks. Our approach achieves state-of-the-art performance on\nboth datasets. \n\n"}
{"id": "1705.03572", "contents": "Title: Discovery Radiomics via Evolutionary Deep Radiomic Sequencer Discovery\n  for Pathologically-Proven Lung Cancer Detection Abstract: While lung cancer is the second most diagnosed form of cancer in men and\nwomen, a sufficiently early diagnosis can be pivotal in patient survival rates.\nImaging-based, or radiomics-driven, detection methods have been developed to\naid diagnosticians, but largely rely on hand-crafted features which may not\nfully encapsulate the differences between cancerous and healthy tissue.\nRecently, the concept of discovery radiomics was introduced, where custom\nabstract features are discovered from readily available imaging data. We\npropose a novel evolutionary deep radiomic sequencer discovery approach based\non evolutionary deep intelligence. Motivated by patient privacy concerns and\nthe idea of operational artificial intelligence, the evolutionary deep radiomic\nsequencer discovery approach organically evolves increasingly more efficient\ndeep radiomic sequencers that produce significantly more compact yet similarly\ndescriptive radiomic sequences over multiple generations. As a result, this\nframework improves operational efficiency and enables diagnosis to be run\nlocally at the radiologist's computer while maintaining detection accuracy. We\nevaluated the evolved deep radiomic sequencer (EDRS) discovered via the\nproposed evolutionary deep radiomic sequencer discovery framework against\nstate-of-the-art radiomics-driven and discovery radiomics methods using\nclinical lung CT data with pathologically-proven diagnostic data from the\nLIDC-IDRI dataset. The evolved deep radiomic sequencer shows improved\nsensitivity (93.42%), specificity (82.39%), and diagnostic accuracy (88.78%)\nrelative to previous radiomics approaches. \n\n"}
{"id": "1705.04358", "contents": "Title: Object-Level Context Modeling For Scene Classification with Context-CNN Abstract: Convolutional Neural Networks (CNNs) have been used extensively for computer\nvision tasks and produce rich feature representation for objects or parts of an\nimage. But reasoning about scenes requires integration between the low-level\nfeature representations and the high-level semantic information. We propose a\ndeep network architecture which models the semantic context of scenes by\ncapturing object-level information. We use Long Short Term Memory(LSTM) units\nin conjunction with object proposals to incorporate object-object relationship\nand object-scene relationship in an end-to-end trainable manner. We evaluate\nour model on the LSUN dataset and achieve results comparable to the\nstate-of-art. We further show visualization of the learned features and analyze\nthe model with experiments to verify our model's ability to model context. \n\n"}
{"id": "1705.04641", "contents": "Title: Single Image Action Recognition by Predicting Space-Time Saliency Abstract: We propose a novel approach based on deep Convolutional Neural Networks (CNN)\nto recognize human actions in still images by predicting the future motion, and\ndetecting the shape and location of the salient parts of the image. We make the\nfollowing major contributions to this important area of research: (i) We use\nthe predicted future motion in the static image (Walker et al., 2015) as a\nmeans of compensating for the missing temporal information, while using the\nsaliency map to represent the the spatial information in the form of location\nand shape of what is predicted as significant. (ii) We cast action\nclassification in static images as a domain adaptation problem by transfer\nlearning. We first map the input static image to a new domain that we refer to\nas the Predicted Optical Flow-Saliency Map domain (POF-SM), and then fine-tune\nthe layers of a deep CNN model trained on classifying the ImageNet dataset to\nperform action classification in the POF-SM domain. (iii) We tested our method\non the popular Willow dataset. But unlike existing methods, we also tested on a\nmore realistic and challenging dataset of over 2M still images that we\ncollected and labeled by taking random frames from the UCF-101 video dataset.\nWe call our dataset the UCF Still Image dataset or UCFSI-101 in short. Our\nresults outperform the state of the art. \n\n"}
{"id": "1705.06820", "contents": "Title: Pixel Deconvolutional Networks Abstract: Deconvolutional layers have been widely used in a variety of deep models for\nup-sampling, including encoder-decoder networks for semantic segmentation and\ndeep generative models for unsupervised learning. One of the key limitations of\ndeconvolutional operations is that they result in the so-called checkerboard\nproblem. This is caused by the fact that no direct relationship exists among\nadjacent pixels on the output feature map. To address this problem, we propose\nthe pixel deconvolutional layer (PixelDCL) to establish direct relationships\namong adjacent pixels on the up-sampled feature map. Our method is based on a\nfresh interpretation of the regular deconvolution operation. The resulting\nPixelDCL can be used to replace any deconvolutional layer in a plug-and-play\nmanner without compromising the fully trainable capabilities of original\nmodels. The proposed PixelDCL may result in slight decrease in efficiency, but\nthis can be overcome by an implementation trick. Experimental results on\nsemantic segmentation demonstrate that PixelDCL can consider spatial features\nsuch as edges and shapes and yields more accurate segmentation outputs than\ndeconvolutional layers. When used in image generation tasks, our PixelDCL can\nlargely overcome the checkerboard problem suffered by regular deconvolution\noperations. \n\n"}
{"id": "1705.06821", "contents": "Title: Spatial Variational Auto-Encoding via Matrix-Variate Normal\n  Distributions Abstract: The key idea of variational auto-encoders (VAEs) resembles that of\ntraditional auto-encoder models in which spatial information is supposed to be\nexplicitly encoded in the latent space. However, the latent variables in VAEs\nare vectors, which can be interpreted as multiple feature maps of size 1x1.\nSuch representations can only convey spatial information implicitly when\ncoupled with powerful decoders. In this work, we propose spatial VAEs that use\nfeature maps of larger size as latent variables to explicitly capture spatial\ninformation. This is achieved by allowing the latent variables to be sampled\nfrom matrix-variate normal (MVN) distributions whose parameters are computed\nfrom the encoder network. To increase dependencies among locations on latent\nfeature maps and reduce the number of parameters, we further propose spatial\nVAEs via low-rank MVN distributions. Experimental results show that the\nproposed spatial VAEs outperform original VAEs in capturing rich structural and\nspatial information. \n\n"}
{"id": "1705.07565", "contents": "Title: Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain\n  Surgeon Abstract: How to develop slim and accurate deep neural networks has become crucial for\nreal- world applications, especially for those employed in embedded systems.\nThough previous work along this research line has shown some promising results,\nmost existing methods either fail to significantly compress a well-trained deep\nnetwork or require a heavy retraining process for the pruned deep network to\nre-boost its prediction performance. In this paper, we propose a new layer-wise\npruning method for deep neural networks. In our proposed method, parameters of\neach individual layer are pruned independently based on second order\nderivatives of a layer-wise error function with respect to the corresponding\nparameters. We prove that the final prediction performance drop after pruning\nis bounded by a linear combination of the reconstructed errors caused at each\nlayer. Therefore, there is a guarantee that one only needs to perform a light\nretraining process on the pruned network to resume its original prediction\nperformance. We conduct extensive experiments on benchmark datasets to\ndemonstrate the effectiveness of our pruning method compared with several\nstate-of-the-art baseline methods. \n\n"}
{"id": "1705.07755", "contents": "Title: Improving classification accuracy of feedforward neural networks for\n  spiking neuromorphic chips Abstract: Deep Neural Networks (DNN) achieve human level performance in many image\nanalytics tasks but DNNs are mostly deployed to GPU platforms that consume a\nconsiderable amount of power. New hardware platforms using lower precision\narithmetic achieve drastic reductions in power consumption. More recently,\nbrain-inspired spiking neuromorphic chips have achieved even lower power\nconsumption, on the order of milliwatts, while still offering real-time\nprocessing.\n  However, for deploying DNNs to energy efficient neuromorphic chips the\nincompatibility between continuous neurons and synaptic weights of traditional\nDNNs, discrete spiking neurons and synapses of neuromorphic chips need to be\novercome. Previous work has achieved this by training a network to learn\ncontinuous probabilities, before it is deployed to a neuromorphic architecture,\nsuch as IBM TrueNorth Neurosynaptic System, by random sampling these\nprobabilities.\n  The main contribution of this paper is a new learning algorithm that learns a\nTrueNorth configuration ready for deployment. We achieve this by training\ndirectly a binary hardware crossbar that accommodates the TrueNorth axon\nconfiguration constrains and we propose a different neuron model.\n  Results of our approach trained on electroencephalogram (EEG) data show a\nsignificant improvement with previous work (76% vs 86% accuracy) while\nmaintaining state of the art performance on the MNIST handwritten data set. \n\n"}
{"id": "1705.08881", "contents": "Title: Dense Transformer Networks Abstract: The key idea of current deep learning methods for dense prediction is to\napply a model on a regular patch centered on each pixel to make pixel-wise\npredictions. These methods are limited in the sense that the patches are\ndetermined by network architecture instead of learned from data. In this work,\nwe propose the dense transformer networks, which can learn the shapes and sizes\nof patches from data. The dense transformer networks employ an encoder-decoder\narchitecture, and a pair of dense transformer modules are inserted into each of\nthe encoder and decoder paths. The novelty of this work is that we provide\ntechnical solutions for learning the shapes and sizes of patches from data and\nefficiently restoring the spatial correspondence required for dense prediction.\nThe proposed dense transformer modules are differentiable, thus the entire\nnetwork can be trained. We apply the proposed networks on natural and\nbiological image segmentation tasks and show superior performance is achieved\nin comparison to baseline methods. \n\n"}
{"id": "1705.09552", "contents": "Title: Classification regions of deep neural networks Abstract: The goal of this paper is to analyze the geometric properties of deep neural\nnetwork classifiers in the input space. We specifically study the topology of\nclassification regions created by deep networks, as well as their associated\ndecision boundary. Through a systematic empirical investigation, we show that\nstate-of-the-art deep nets learn connected classification regions, and that the\ndecision boundary in the vicinity of datapoints is flat along most directions.\nWe further draw an essential connection between two seemingly unrelated\nproperties of deep networks: their sensitivity to additive perturbations in the\ninputs, and the curvature of their decision boundary. The directions where the\ndecision boundary is curved in fact remarkably characterize the directions to\nwhich the classifier is the most vulnerable. We finally leverage a fundamental\nasymmetry in the curvature of the decision boundary of deep nets, and propose a\nmethod to discriminate between original images, and images perturbed with small\nadversarial examples. We show the effectiveness of this purely geometric\napproach for detecting small adversarial perturbations in images, and for\nrecovering the labels of perturbed images. \n\n"}
{"id": "1705.09700", "contents": "Title: Multi-scale Online Learning and its Applications to Online Auctions Abstract: We consider revenue maximization in online auction/pricing problems. A seller\nsells an identical item in each period to a new buyer, or a new set of buyers.\nFor the online posted pricing problem, we show regret bounds that scale with\nthe best fixed price, rather than the range of the values. We also show regret\nbounds that are almost scale free, and match the offline sample complexity,\nwhen comparing to a benchmark that requires a lower bound on the market share.\nThese results are obtained by generalizing the classical learning from experts\nand multi-armed bandit problems to their multi-scale versions. In this version,\nthe reward of each action is in a different range, and the regret w.r.t. a\ngiven action scales with its own range, rather than the maximum range. \n\n"}
{"id": "1705.09765", "contents": "Title: Deep Matching and Validation Network -- An End-to-End Solution to\n  Constrained Image Splicing Localization and Detection Abstract: Image splicing is a very common image manipulation technique that is\nsometimes used for malicious purposes. A splicing detec- tion and localization\nalgorithm usually takes an input image and produces a binary decision\nindicating whether the input image has been manipulated, and also a\nsegmentation mask that corre- sponds to the spliced region. Most existing\nsplicing detection and localization pipelines suffer from two main\nshortcomings: 1) they use handcrafted features that are not robust against\nsubsequent processing (e.g., compression), and 2) each stage of the pipeline is\nusually optimized independently. In this paper we extend the formulation of the\nunderlying splicing problem to consider two input images, a query image and a\npotential donor image. Here the task is to estimate the probability that the\ndonor image has been used to splice the query image, and obtain the splicing\nmasks for both the query and donor images. We introduce a novel deep\nconvolutional neural network architecture, called Deep Matching and Validation\nNetwork (DMVN), which simultaneously localizes and detects image splicing. The\nproposed approach does not depend on handcrafted features and uses raw input\nimages to create deep learned representations. Furthermore, the DMVN is\nend-to-end op- timized to produce the probability estimates and the\nsegmentation masks. Our extensive experiments demonstrate that this approach\noutperforms state-of-the-art splicing detection methods by a large margin in\nterms of both AUC score and speed. \n\n"}
{"id": "1705.09966", "contents": "Title: Attribute-Guided Face Generation Using Conditional CycleGAN Abstract: We are interested in attribute-guided face generation: given a low-res face\ninput image, an attribute vector that can be extracted from a high-res image\n(attribute image), our new method generates a high-res face image for the\nlow-res input that satisfies the given attributes. To address this problem, we\ncondition the CycleGAN and propose conditional CycleGAN, which is designed to\n1) handle unpaired training data because the training low/high-res and high-res\nattribute images may not necessarily align with each other, and to 2) allow\neasy control of the appearance of the generated face via the input attributes.\nWe demonstrate impressive results on the attribute-guided conditional CycleGAN,\nwhich can synthesize realistic face images with appearance easily controlled by\nuser-supplied attributes (e.g., gender, makeup, hair color, eyeglasses). Using\nthe attribute image as identity to produce the corresponding conditional vector\nand by incorporating a face verification network, the attribute-guided network\nbecomes the identity-guided conditional CycleGAN which produces impressive and\ninteresting results on identity transfer. We demonstrate three applications on\nidentity-guided conditional CycleGAN: identity-preserving face superresolution,\nface swapping, and frontal face generation, which consistently show the\nadvantage of our new method. \n\n"}
{"id": "1706.00550", "contents": "Title: On Unifying Deep Generative Models Abstract: Deep generative models have achieved impressive success in recent years.\nGenerative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), as\nemerging families for generative model learning, have largely been considered\nas two distinct paradigms and received extensive independent studies\nrespectively. This paper aims to establish formal connections between GANs and\nVAEs through a new formulation of them. We interpret sample generation in GANs\nas performing posterior inference, and show that GANs and VAEs involve\nminimizing KL divergences of respective posterior and inference distributions\nwith opposite directions, extending the two learning phases of classic\nwake-sleep algorithm, respectively. The unified view provides a powerful tool\nto analyze a diverse set of existing model variants, and enables to transfer\ntechniques across research lines in a principled way. For example, we apply the\nimportance weighting method in VAE literatures for improved GAN learning, and\nenhance VAEs with an adversarial mechanism that leverages generated samples.\nExperiments show generality and effectiveness of the transferred techniques. \n\n"}
{"id": "1706.01307", "contents": "Title: Submanifold Sparse Convolutional Networks Abstract: Convolutional network are the de-facto standard for analysing spatio-temporal\ndata such as images, videos, 3D shapes, etc. Whilst some of this data is\nnaturally dense (for instance, photos), many other data sources are inherently\nsparse. Examples include pen-strokes forming on a piece of paper, or (colored)\n3D point clouds that were obtained using a LiDAR scanner or RGB-D camera.\nStandard \"dense\" implementations of convolutional networks are very inefficient\nwhen applied on such sparse data. We introduce a sparse convolutional operation\ntailored to processing sparse data that differs from prior work on sparse\nconvolutional networks in that it operates strictly on submanifolds, rather\nthan \"dilating\" the observation with every layer in the network. Our empirical\nanalysis of the resulting submanifold sparse convolutional networks shows that\nthey perform on par with state-of-the-art methods whilst requiring\nsubstantially less computation. \n\n"}
{"id": "1706.01869", "contents": "Title: StreetStyle: Exploring world-wide clothing styles from millions of\n  photos Abstract: Each day billions of photographs are uploaded to photo-sharing services and\nsocial media platforms. These images are packed with information about how\npeople live around the world. In this paper we exploit this rich trove of data\nto understand fashion and style trends worldwide. We present a framework for\nvisual discovery at scale, analyzing clothing and fashion across millions of\nimages of people around the world and spanning several years. We introduce a\nlarge-scale dataset of photos of people annotated with clothing attributes, and\nuse this dataset to train attribute classifiers via deep learning. We also\npresent a method for discovering visually consistent style clusters that\ncapture useful visual correlations in this massive dataset. Using these tools,\nwe analyze millions of photos to derive visual insight, producing a\nfirst-of-its-kind analysis of global and per-city fashion choices and\nspatio-temporal trends. \n\n"}
{"id": "1706.02021", "contents": "Title: Network Sketching: Exploiting Binary Structure in Deep CNNs Abstract: Convolutional neural networks (CNNs) with deep architectures have\nsubstantially advanced the state-of-the-art in computer vision tasks. However,\ndeep networks are typically resource-intensive and thus difficult to be\ndeployed on mobile devices. Recently, CNNs with binary weights have shown\ncompelling efficiency to the community, whereas the accuracy of such models is\nusually unsatisfactory in practice. In this paper, we introduce network\nsketching as a novel technique of pursuing binary-weight CNNs, targeting at\nmore faithful inference and better trade-off for practical applications. Our\nbasic idea is to exploit binary structure directly in pre-trained filter banks\nand produce binary-weight models via tensor expansion. The whole process can be\ntreated as a coarse-to-fine model approximation, akin to the pencil drawing\nsteps of outlining and shading. To further speedup the generated models, namely\nthe sketches, we also propose an associative implementation of binary tensor\nconvolutions. Experimental results demonstrate that a proper sketch of AlexNet\n(or ResNet) outperforms the existing binary-weight models by large margins on\nthe ImageNet large scale classification task, while the committed memory for\nnetwork parameters only exceeds a little. \n\n"}
{"id": "1706.02631", "contents": "Title: Sliced Wasserstein Generative Models Abstract: In generative modeling, the Wasserstein distance (WD) has emerged as a useful\nmetric to measure the discrepancy between generated and real data\ndistributions. Unfortunately, it is challenging to approximate the WD of\nhigh-dimensional distributions. In contrast, the sliced Wasserstein distance\n(SWD) factorizes high-dimensional distributions into their multiple\none-dimensional marginal distributions and is thus easier to approximate. In\nthis paper, we introduce novel approximations of the primal and dual SWD.\nInstead of using a large number of random projections, as it is done by\nconventional SWD approximation methods, we propose to approximate SWDs with a\nsmall number of parameterized orthogonal projections in an end-to-end deep\nlearning fashion. As concrete applications of our SWD approximations, we design\ntwo types of differentiable SWD blocks to equip modern generative\nframeworks---Auto-Encoders (AE) and Generative Adversarial Networks (GAN). In\nthe experiments, we not only show the superiority of the proposed generative\nmodels on standard image synthesis benchmarks, but also demonstrate the\nstate-of-the-art performance on challenging high resolution image and video\ngeneration in an unsupervised manner. \n\n"}
{"id": "1706.03227", "contents": "Title: Generate Identity-Preserving Faces by Generative Adversarial Networks Abstract: Generating identity-preserving faces aims to generate various face images\nkeeping the same identity given a target face image. Although considerable\ngenerative models have been developed in recent years, it is still challenging\nto simultaneously acquire high quality of facial images and preserve the\nidentity. Here we propose a compelling method using generative adversarial\nnetworks (GAN). Concretely, we leverage the generator of trained GAN to\ngenerate plausible faces and FaceNet as an identity-similarity discriminator to\nensure the identity. Experimental results show that our method is qualified to\ngenerate both plausible and identity-preserving faces with high quality. In\naddition, our method provides a universal framework which can be realized in\nvarious ways by combining different face generators and identity-similarity\ndiscriminator. \n\n"}
{"id": "1706.03702", "contents": "Title: Progressive and Multi-Path Holistically Nested Neural Networks for\n  Pathological Lung Segmentation from CT Images Abstract: Pathological lung segmentation (PLS) is an important, yet challenging,\nmedical image application due to the wide variability of pathological lung\nappearance and shape. Because PLS is often a pre-requisite for other imaging\nanalytics, methodological simplicity and generality are key factors in\nusability. Along those lines, we present a bottom-up deep-learning based\napproach that is expressive enough to handle variations in appearance, while\nremaining unaffected by any variations in shape. We incorporate the deeply\nsupervised learning framework, but enhance it with a simple, yet effective,\nprogressive multi-path scheme, which more reliably merges outputs from\ndifferent network stages. The result is a deep model able to produce finer\ndetailed masks, which we call progressive holistically-nested networks\n(P-HNNs). Using extensive cross-validation, our method is tested on\nmulti-institutional datasets comprising 929 CT scans (848 publicly available),\nof pathological lungs, reporting mean dice scores of 0.985 and demonstrating\nsignificant qualitative and quantitative improvements over state-of-the art\napproaches. \n\n"}
{"id": "1706.03875", "contents": "Title: Contrast Enhancement Estimation for Digital Image Forensics Abstract: Inconsistency in contrast enhancement can be used to expose image forgeries.\nIn this work, we describe a new method to estimate contrast enhancement from a\nsingle image. Our method takes advantage of the nature of contrast enhancement\nas a mapping between pixel values, and the distinct characteristics it\nintroduces to the image pixel histogram. Our method recovers the original pixel\nhistogram and the contrast enhancement simultaneously from a single image with\nan iterative algorithm. Unlike previous methods, our method is robust in the\npresence of additive noise perturbations that are used to hide the traces of\ncontrast enhancement. Furthermore, we also develop an e effective method to to\ndetect image regions undergone contrast enhancement transformations that are\ndifferent from the rest of the image, and use this method to detect composite\nimages. We perform extensive experimental evaluations to demonstrate the\nefficacy and efficiency of our method method. \n\n"}
{"id": "1706.04568", "contents": "Title: SideEye: A Generative Neural Network Based Simulator of Human Peripheral\n  Vision Abstract: Foveal vision makes up less than 1% of the visual field. The other 99% is\nperipheral vision. Precisely what human beings see in the periphery is both\nobvious and mysterious in that we see it with our own eyes but can't visualize\nwhat we see, except in controlled lab experiments. Degradation of information\nin the periphery is far more complex than what might be mimicked with a radial\nblur. Rather, behaviorally-validated models hypothesize that peripheral vision\nmeasures a large number of local texture statistics in pooling regions that\noverlap and grow with eccentricity. In this work, we develop a new method for\nperipheral vision simulation by training a generative neural network on a\nbehaviorally-validated full-field synthesis model. By achieving a 21,000 fold\nreduction in running time, our approach is the first to combine realism and\nspeed of peripheral vision simulation to a degree that provides a whole new way\nto approach visual design: through peripheral visualization. \n\n"}
{"id": "1706.07680", "contents": "Title: Training Adversarial Discriminators for Cross-channel Abnormal Event\n  Detection in Crowds Abstract: Abnormal crowd behaviour detection attracts a large interest due to its\nimportance in video surveillance scenarios. However, the ambiguity and the lack\nof sufficient abnormal ground truth data makes end-to-end training of large\ndeep networks hard in this domain. In this paper we propose to use Generative\nAdversarial Nets (GANs), which are trained to generate only the normal\ndistribution of the data. During the adversarial GAN training, a discriminator\n(D) is used as a supervisor for the generator network (G) and vice versa. At\ntesting time we use D to solve our discriminative task (abnormality detection),\nwhere D has been trained without the need of manually-annotated abnormal data.\nMoreover, in order to prevent G learn a trivial identity function, we use a\ncross-channel approach, forcing G to transform raw-pixel data in motion\ninformation and vice versa. The quantitative results on standard benchmarks\nshow that our method outperforms previous state-of-the-art methods in both the\nframe-level and the pixel-level evaluation. \n\n"}
{"id": "1706.09262", "contents": "Title: Hierarchical Attentive Recurrent Tracking Abstract: Class-agnostic object tracking is particularly difficult in cluttered\nenvironments as target specific discriminative models cannot be learned a\npriori. Inspired by how the human visual cortex employs spatial attention and\nseparate \"where\" and \"what\" processing pathways to actively suppress irrelevant\nvisual features, this work develops a hierarchical attentive recurrent model\nfor single object tracking in videos. The first layer of attention discards the\nmajority of background by selecting a region containing the object of interest,\nwhile the subsequent layers tune in on visual features particular to the\ntracked object. This framework is fully differentiable and can be trained in a\npurely data driven fashion by gradient methods. To improve training\nconvergence, we augment the loss function with terms for a number of auxiliary\ntasks relevant for tracking. Evaluation of the proposed model is performed on\ntwo datasets: pedestrian tracking on the KTH activity recognition dataset and\nthe more difficult KITTI object tracking dataset. \n\n"}
{"id": "1706.09601", "contents": "Title: Actor-Critic Sequence Training for Image Captioning Abstract: Generating natural language descriptions of images is an important capability\nfor a robot or other visual-intelligence driven AI agent that may need to\ncommunicate with human users about what it is seeing. Such image captioning\nmethods are typically trained by maximising the likelihood of ground-truth\nannotated caption given the image. While simple and easy to implement, this\napproach does not directly maximise the language quality metrics we care about\nsuch as CIDEr. In this paper we investigate training image captioning methods\nbased on actor-critic reinforcement learning in order to directly optimise\nnon-differentiable quality metrics of interest. By formulating a per-token\nadvantage and value computation strategy in this novel reinforcement learning\nbased captioning model, we show that it is possible to achieve the state of the\nart performance on the widely used MSCOCO benchmark. \n\n"}
{"id": "1706.09858", "contents": "Title: What's Mine is Yours: Pretrained CNNs for Limited Training Sonar ATR Abstract: Finding mines in Sonar imagery is a significant problem with a great deal of\nrelevance for seafaring military and commercial endeavors. Unfortunately, the\nlack of enormous Sonar image data sets has prevented automatic target\nrecognition (ATR) algorithms from some of the same advances seen in other\ncomputer vision fields. Namely, the boom in convolutional neural nets (CNNs)\nwhich have been able to achieve incredible results - even surpassing human\nactors - has not been an easily feasible route for many practitioners of Sonar\nATR. We demonstrate the power of one avenue to incorporating CNNs into Sonar\nATR: transfer learning. We first show how well a straightforward, flexible CNN\nfeature-extraction strategy can be used to obtain impressive if not\nstate-of-the-art results. Secondly, we propose a way to utilize the powerful\ntransfer learning approach towards multiple instance target detection and\nidentification within a provided synthetic aperture Sonar data set. \n\n"}
{"id": "1706.10082", "contents": "Title: Persistence Diagrams with Linear Machine Learning Models Abstract: Persistence diagrams have been widely recognized as a compact descriptor for\ncharacterizing multiscale topological features in data. When many datasets are\navailable, statistical features embedded in those persistence diagrams can be\nextracted by applying machine learnings. In particular, the ability for\nexplicitly analyzing the inverse in the original data space from those\nstatistical features of persistence diagrams is significantly important for\npractical applications. In this paper, we propose a unified method for the\ninverse analysis by combining linear machine learning models with persistence\nimages. The method is applied to point clouds and cubical sets, showing the\nability of the statistical inverse analysis and its advantages. \n\n"}
{"id": "1707.00095", "contents": "Title: Exploring the Imposition of Synaptic Precision Restrictions For\n  Evolutionary Synthesis of Deep Neural Networks Abstract: A key contributing factor to incredible success of deep neural networks has\nbeen the significant rise on massively parallel computing devices allowing\nresearchers to greatly increase the size and depth of deep neural networks,\nleading to significant improvements in modeling accuracy. Although deeper,\nlarger, or complex deep neural networks have shown considerable promise, the\ncomputational complexity of such networks is a major barrier to utilization in\nresource-starved scenarios. We explore the synaptogenesis of deep neural\nnetworks in the formation of efficient deep neural network architectures within\nan evolutionary deep intelligence framework, where a probabilistic generative\nmodeling strategy is introduced to stochastically synthesize increasingly\nefficient yet effective offspring deep neural networks over generations,\nmimicking evolutionary processes such as heredity, random mutation, and natural\nselection in a probabilistic manner. In this study, we primarily explore the\nimposition of synaptic precision restrictions and its impact on the\nevolutionary synthesis of deep neural networks to synthesize more efficient\nnetwork architectures tailored for resource-starved scenarios. Experimental\nresults show significant improvements in synaptic efficiency (~10X decrease for\nGoogLeNet-based DetectNet) and inference speed (>5X increase for\nGoogLeNet-based DetectNet) while preserving modeling accuracy. \n\n"}
{"id": "1707.00095", "contents": "Title: Exploring the Imposition of Synaptic Precision Restrictions For\n  Evolutionary Synthesis of Deep Neural Networks Abstract: A key contributing factor to incredible success of deep neural networks has\nbeen the significant rise on massively parallel computing devices allowing\nresearchers to greatly increase the size and depth of deep neural networks,\nleading to significant improvements in modeling accuracy. Although deeper,\nlarger, or complex deep neural networks have shown considerable promise, the\ncomputational complexity of such networks is a major barrier to utilization in\nresource-starved scenarios. We explore the synaptogenesis of deep neural\nnetworks in the formation of efficient deep neural network architectures within\nan evolutionary deep intelligence framework, where a probabilistic generative\nmodeling strategy is introduced to stochastically synthesize increasingly\nefficient yet effective offspring deep neural networks over generations,\nmimicking evolutionary processes such as heredity, random mutation, and natural\nselection in a probabilistic manner. In this study, we primarily explore the\nimposition of synaptic precision restrictions and its impact on the\nevolutionary synthesis of deep neural networks to synthesize more efficient\nnetwork architectures tailored for resource-starved scenarios. Experimental\nresults show significant improvements in synaptic efficiency (~10X decrease for\nGoogLeNet-based DetectNet) and inference speed (>5X increase for\nGoogLeNet-based DetectNet) while preserving modeling accuracy. \n\n"}
{"id": "1707.00409", "contents": "Title: Deep Ranking Model by Large Adaptive Margin Learning for Person\n  Re-identification Abstract: Person re-identification aims to match images of the same person across\ndisjoint camera views, which is a challenging problem in video surveillance.\nThe major challenge of this task lies in how to preserve the similarity of the\nsame person against large variations caused by complex backgrounds, mutual\nocclusions and different illuminations, while discriminating the different\nindividuals. In this paper, we present a novel deep ranking model with feature\nlearning and fusion by learning a large adaptive margin between the intra-class\ndistance and inter-class distance to solve the person re-identification\nproblem. Specifically, we organize the training images into a batch of pairwise\nsamples. Treating these pairwise samples as inputs, we build a novel part-based\ndeep convolutional neural network (CNN) to learn the layered feature\nrepresentations by preserving a large adaptive margin. As a result, the final\nlearned model can effectively find out the matched target to the anchor image\namong a number of candidates in the gallery image set by learning\ndiscriminative and stable feature representations. Overcoming the weaknesses of\nconventional fixed-margin loss functions, our adaptive margin loss function is\nmore appropriate for the dynamic feature space. On four benchmark datasets,\nPRID2011, Market1501, CUHK01 and 3DPeS, we extensively conduct comparative\nevaluations to demonstrate the advantages of the proposed method over the\nstate-of-the-art approaches in person re-identification. \n\n"}
{"id": "1707.00860", "contents": "Title: Conditional generation of multi-modal data using constrained embedding\n  space mapping Abstract: We present a conditional generative model that maps low-dimensional\nembeddings of multiple modalities of data to a common latent space hence\nextracting semantic relationships between them. The embedding specific to a\nmodality is first extracted and subsequently a constrained optimization\nprocedure is performed to project the two embedding spaces to a common\nmanifold. The individual embeddings are generated back from this common latent\nspace. However, in order to enable independent conditional inference for\nseparately extracting the corresponding embeddings from the common latent space\nrepresentation, we deploy a proxy variable trick - wherein, the single shared\nlatent space is replaced by the respective separate latent spaces of each\nmodality. We design an objective function, such that, during training we can\nforce these separate spaces to lie close to each other, by minimizing the\ndistance between their probability distribution functions. Experimental results\ndemonstrate that the learned joint model can generalize to learning concepts of\ndouble MNIST digits with additional attributes of colors,from both textual and\nspeech input. \n\n"}
{"id": "1707.01083", "contents": "Title: ShuffleNet: An Extremely Efficient Convolutional Neural Network for\n  Mobile Devices Abstract: We introduce an extremely computation-efficient CNN architecture named\nShuffleNet, which is designed specially for mobile devices with very limited\ncomputing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new\noperations, pointwise group convolution and channel shuffle, to greatly reduce\ncomputation cost while maintaining accuracy. Experiments on ImageNet\nclassification and MS COCO object detection demonstrate the superior\nperformance of ShuffleNet over other structures, e.g. lower top-1 error\n(absolute 7.8%) than recent MobileNet on ImageNet classification task, under\nthe computation budget of 40 MFLOPs. On an ARM-based mobile device, ShuffleNet\nachieves ~13x actual speedup over AlexNet while maintaining comparable\naccuracy. \n\n"}
{"id": "1707.01357", "contents": "Title: Improving Content-Invariance in Gated Autoencoders for 2D and 3D Object\n  Rotation Abstract: Content-invariance in mapping codes learned by GAEs is a useful feature for\nvarious relation learning tasks. In this paper we show that the\ncontent-invariance of mapping codes for images of 2D and 3D rotated objects can\nbe substantially improved by extending the standard GAE loss (symmetric\nreconstruction error) with a regularization term that penalizes the symmetric\ncross-reconstruction error. This error term involves reconstruction of pairs\nwith mapping codes obtained from other pairs exhibiting similar\ntransformations. Although this would principally require knowledge of the\ntransformations exhibited by training pairs, our experiments show that a\nbootstrapping approach can sidestep this issue, and that the regularization\nterm can effectively be used in an unsupervised setting. \n\n"}
{"id": "1707.02120", "contents": "Title: Sparse Approximation of 3D Meshes using the Spectral Geometry of the\n  Hamiltonian Operator Abstract: The discrete Laplace operator is ubiquitous in spectral shape analysis, since\nits eigenfunctions are provably optimal in representing smooth functions\ndefined on the surface of the shape. Indeed, subspaces defined by its\neigenfunctions have been utilized for shape compression, treating the\ncoordinates as smooth functions defined on the given surface. However, surfaces\nof shapes in nature often contain geometric structures for which the general\nsmoothness assumption may fail to hold. At the other end, some explicit mesh\ncompression algorithms utilize the order by which vertices that represent the\nsurface are traversed, a property which has been ignored in spectral\napproaches. Here, we incorporate the order of vertices into an operator that\ndefines a novel spectral domain. We propose a method for representing 3D meshes\nusing the spectral geometry of the Hamiltonian operator, integrated within a\nsparse approximation framework. We adapt the concept of a potential function\nfrom quantum physics and incorporate vertex ordering information into the\npotential, yielding a novel data-dependent operator. The potential function\nmodifies the spectral geometry of the Laplacian to focus on regions with finer\ndetails of the given surface. By sparsely encoding the geometry of the shape\nusing the proposed data-dependent basis, we improve compression performance\ncompared to previous results that use the standard Laplacian basis and spectral\ngraph wavelets. \n\n"}
{"id": "1707.02554", "contents": "Title: Visual Analytics of Movement Pattern Based on Time-Spatial Data: A\n  Neural Net Approach Abstract: Time-Spatial data plays a crucial role for different fields such as traffic\nmanagement. These data can be collected via devices such as surveillance\nsensors or tracking systems. However, how to efficiently an- alyze and\nvisualize these data to capture essential embedded pattern information is\nbecoming a big challenge today. Classic visualization ap- proaches focus on\nrevealing 2D and 3D spatial information and modeling statistical test. Those\nmethods would easily fail when data become mas- sive. Recent attempts concern\non how to simply cluster data and perform prediction with time-oriented\ninformation. However, those approaches could still be further enhanced as they\nalso have limitations for han- dling massive clusters and labels. In this\npaper, we propose a visualiza- tion methodology for mobility data using\nartificial neural net techniques. This method aggregates three main parts that\nare Back-end Data Model, Neural Net Algorithm including clustering method\nSelf-Organizing Map (SOM) and prediction approach Recurrent Neural Net (RNN)\nfor ex- tracting the features and lastly a solid front-end that displays the\nresults to users with an interactive system. SOM is able to cluster the\nvisiting patterns and detect the abnormal pattern. RNN can perform the predic-\ntion for time series analysis using its dynamic architecture. Furthermore, an\ninteractive system will enable user to interpret the result with graph- ics,\nanimation and 3D model for a close-loop feedback. This method can be\nparticularly applied in two tasks that Commercial-based Promotion and abnormal\ntraffic patterns detection. \n\n"}
{"id": "1707.03167", "contents": "Title: RegNet: Multimodal Sensor Registration Using Deep Neural Networks Abstract: In this paper, we present RegNet, the first deep convolutional neural network\n(CNN) to infer a 6 degrees of freedom (DOF) extrinsic calibration between\nmultimodal sensors, exemplified using a scanning LiDAR and a monocular camera.\nCompared to existing approaches, RegNet casts all three conventional\ncalibration steps (feature extraction, feature matching and global regression)\ninto a single real-time capable CNN. Our method does not require any human\ninteraction and bridges the gap between classical offline and target-less\nonline calibration approaches as it provides both a stable initial estimation\nas well as a continuous online correction of the extrinsic parameters. During\ntraining we randomly decalibrate our system in order to train RegNet to infer\nthe correspondence between projected depth measurements and RGB image and\nfinally regress the extrinsic calibration. Additionally, with an iterative\nexecution of multiple CNNs, that are trained on different magnitudes of\ndecalibration, our approach compares favorably to state-of-the-art methods in\nterms of a mean calibration error of 0.28 degrees for the rotational and 6 cm\nfor the translation components even for large decalibrations up to 1.5 m and 20\ndegrees. \n\n"}
{"id": "1707.03501", "contents": "Title: NO Need to Worry about Adversarial Examples in Object Detection in\n  Autonomous Vehicles Abstract: It has been shown that most machine learning algorithms are susceptible to\nadversarial perturbations. Slightly perturbing an image in a carefully chosen\ndirection in the image space may cause a trained neural network model to\nmisclassify it. Recently, it was shown that physical adversarial examples\nexist: printing perturbed images then taking pictures of them would still\nresult in misclassification. This raises security and safety concerns.\n  However, these experiments ignore a crucial property of physical objects: the\ncamera can view objects from different distances and at different angles. In\nthis paper, we show experiments that suggest that current constructions of\nphysical adversarial examples do not disrupt object detection from a moving\nplatform. Instead, a trained neural network classifies most of the pictures\ntaken from different distances and angles of a perturbed image correctly. We\nbelieve this is because the adversarial property of the perturbation is\nsensitive to the scale at which the perturbed picture is viewed, so (for\nexample) an autonomous car will misclassify a stop sign only from a small range\nof distances.\n  Our work raises an important question: can one construct examples that are\nadversarial for many or most viewing conditions? If so, the construction should\noffer very significant insights into the internal representation of patterns by\ndeep networks. If not, there is a good prospect that adversarial examples can\nbe reduced to a curiosity with little practical impact. \n\n"}
{"id": "1707.03981", "contents": "Title: Learning Photography Aesthetics with Deep CNNs Abstract: Automatic photo aesthetic assessment is a challenging artificial intelligence\ntask. Existing computational approaches have focused on modeling a single\naesthetic score or a class (good or bad), however these do not provide any\ndetails on why the photograph is good or bad, or which attributes contribute to\nthe quality of the photograph. To obtain both accuracy and human interpretation\nof the score, we advocate learning the aesthetic attributes along with the\nprediction of the overall score. For this purpose, we propose a novel multitask\ndeep convolution neural network, which jointly learns eight aesthetic\nattributes along with the overall aesthetic score. We report near human\nperformance in the prediction of the overall aesthetic score. To understand the\ninternal representation of these attributes in the learned model, we also\ndevelop the visualization technique using back propagation of gradients. These\nvisualizations highlight the important image regions for the corresponding\nattributes, thus providing insights about model's representation of these\nattributes. We showcase the diversity and complexity associated with different\nattributes through a qualitative analysis of the activation maps. \n\n"}
{"id": "1707.05489", "contents": "Title: Vision-based Real Estate Price Estimation Abstract: Since the advent of online real estate database companies like Zillow, Trulia\nand Redfin, the problem of automatic estimation of market values for houses has\nreceived considerable attention. Several real estate websites provide such\nestimates using a proprietary formula. Although these estimates are often close\nto the actual sale prices, in some cases they are highly inaccurate. One of the\nkey factors that affects the value of a house is its interior and exterior\nappearance, which is not considered in calculating automatic value estimates.\nIn this paper, we evaluate the impact of visual characteristics of a house on\nits market value. Using deep convolutional neural networks on a large dataset\nof photos of home interiors and exteriors, we develop a method for estimating\nthe luxury level of real estate photos. We also develop a novel framework for\nautomated value assessment using the above photos in addition to home\ncharacteristics including size, offered price and number of bedrooms. Finally,\nby applying our proposed method for price estimation to a new dataset of real\nestate photos and metadata, we show that it outperforms Zillow's estimates. \n\n"}
{"id": "1707.05553", "contents": "Title: Spectral Filter Tracking Abstract: Visual object tracking is a challenging computer vision task with numerous\nreal-world applications. Here we propose a simple but efficient Spectral Filter\nTracking (SFT)method. To characterize rotational and translation invariance of\ntracking targets, the candidate image region is models as a pixelwise grid\ngraph. Instead of the conventional graph matching, we convert the tracking into\na plain least square regression problem to estimate the best center coordinate\nof the target. But different from the holistic regression of correlation filter\nbased methods, SFT can operate on localized surrounding regions of each pixel\n(i.e.,vertex) by using spectral graph filters, which thus is more robust to\nresist local variations and cluttered background.To bypass the eigenvalue\ndecomposition problem of the graph Laplacian matrix L, we parameterize spectral\ngraph filters as the polynomial of L by spectral graph theory, in which L k\nexactly encodes a k-hop local neighborhood of each vertex. Finally, the filter\nparameters (i.e., polynomial coefficients) as well as feature projecting\nfunctions are jointly integrated into the regression model. \n\n"}
{"id": "1707.06168", "contents": "Title: Channel Pruning for Accelerating Very Deep Neural Networks Abstract: In this paper, we introduce a new channel pruning method to accelerate very\ndeep convolutional neural networks.Given a trained CNN model, we propose an\niterative two-step algorithm to effectively prune each layer, by a LASSO\nregression based channel selection and least square reconstruction. We further\ngeneralize this algorithm to multi-layer and multi-branch cases. Our method\nreduces the accumulated error and enhance the compatibility with various\narchitectures. Our pruned VGG-16 achieves the state-of-the-art results by 5x\nspeed-up along with only 0.3% increase of error. More importantly, our method\nis able to accelerate modern networks like ResNet, Xception and suffers only\n1.4%, 1.0% accuracy loss under 2x speed-up respectively, which is significant.\nCode has been made publicly available. \n\n"}
{"id": "1707.06719", "contents": "Title: Generalized Convolutional Neural Networks for Point Cloud Data Abstract: The introduction of cheap RGB-D cameras, stereo cameras, and LIDAR devices\nhas given the computer vision community 3D information that conventional RGB\ncameras cannot provide. This data is often stored as a point cloud. In this\npaper, we present a novel method to apply the concept of convolutional neural\nnetworks to this type of data. By creating a mapping of nearest neighbors in a\ndataset, and individually applying weights to spatial relationships between\npoints, we achieve an architecture that works directly with point clouds, but\nclosely resembles a convolutional neural net in both design and behavior. Such\na method bypasses the need for extensive feature engineering, while proving to\nbe computationally efficient and requiring few parameters. \n\n"}
{"id": "1707.06772", "contents": "Title: Improved Bilinear Pooling with CNNs Abstract: Bilinear pooling of Convolutional Neural Network (CNN) features [22, 23], and\ntheir compact variants [10], have been shown to be effective at fine-grained\nrecognition, scene categorization, texture recognition, and visual\nquestion-answering tasks among others. The resulting representation captures\nsecond-order statistics of convolutional features in a translationally\ninvariant manner. In this paper we investigate various ways of normalizing\nthese statistics to improve their representation power. In particular we find\nthat the matrix square-root normalization offers significant improvements and\noutperforms alternative schemes such as the matrix logarithm normalization when\ncombined with elementwise square-root and l2 normalization. This improves the\naccuracy by 2-3% on a range of fine-grained recognition datasets leading to a\nnew state of the art. We also investigate how the accuracy of matrix function\ncomputations effect network training and evaluation. In particular we compare\nagainst a technique for estimating matrix square-root gradients via solving a\nLyapunov equation that is more numerically accurate than computing gradients\nvia a Singular Value Decomposition (SVD). We find that while SVD gradients are\nnumerically inaccurate the overall effect on the final accuracy is negligible\nonce boundary cases are handled carefully. We present an alternative scheme for\ncomputing gradients that is faster and yet it offers improvements over the\nbaseline model. Finally we show that the matrix square-root computed\napproximately using a few Newton iterations is just as accurate for the\nclassification task but allows an order-of-magnitude faster GPU implementation\ncompared to SVD decomposition. \n\n"}
{"id": "1707.06865", "contents": "Title: Retinal Microaneurysms Detection using Local Convergence Index Features Abstract: Retinal microaneurysms are the earliest clinical sign of diabetic retinopathy\ndisease. Detection of microaneurysms is crucial for the early diagnosis of\ndiabetic retinopathy and prevention of blindness. In this paper, a novel and\nreliable method for automatic detection of microaneurysms in retinal images is\nproposed. In the first stage of the proposed method, several preliminary\nmicroaneurysm candidates are extracted using a gradient weighting technique and\nan iterative thresholding approach. In the next stage, in addition to intensity\nand shape descriptors, a new set of features based on local convergence index\nfilters is extracted for each candidate. Finally, the collective set of\nfeatures is fed to a hybrid sampling/boosting classifier to discriminate the\nMAs from non-MAs candidates. The method is evaluated on images with different\nresolutions and modalities (RGB and SLO) using five publicly available datasets\nincluding the Retinopathy Online Challenge's dataset. The proposed method\nachieves an average sensitivity score of 0.471 on the ROC dataset outperforming\nstate-of-the-art approaches in an extensive comparison. The experimental\nresults on the other four datasets demonstrate the effectiveness and robustness\nof the proposed microaneurysms detection method regardless of different image\nresolutions and modalities. \n\n"}
{"id": "1707.07169", "contents": "Title: Comparing Apples and Oranges: Off-Road Pedestrian Detection on the NREC\n  Agricultural Person-Detection Dataset Abstract: Person detection from vehicles has made rapid progress recently with the\nadvent of multiple highquality datasets of urban and highway driving, yet no\nlarge-scale benchmark is available for the same problem in off-road or\nagricultural environments. Here we present the NREC Agricultural\nPerson-Detection Dataset to spur research in these environments. It consists of\nlabeled stereo video of people in orange and apple orchards taken from two\nperception platforms (a tractor and a pickup truck), along with vehicle\nposition data from RTK GPS. We define a benchmark on part of the dataset that\ncombines a total of 76k labeled person images and 19k sampled person-free\nimages. The dataset highlights several key challenges of the domain, including\nvarying environment, substantial occlusion by vegetation, people in motion and\nin non-standard poses, and people seen from a variety of distances; meta-data\nare included to allow targeted evaluation of each of these effects. Finally, we\npresent baseline detection performance results for three leading approaches\nfrom urban pedestrian detection and our own convolutional neural network\napproach that benefits from the incorporation of additional image context. We\nshow that the success of existing approaches on urban data does not transfer\ndirectly to this domain. \n\n"}
{"id": "1707.07204", "contents": "Title: Eyemotion: Classifying facial expressions in VR using eye-tracking\n  cameras Abstract: One of the main challenges of social interaction in virtual reality settings\nis that head-mounted displays occlude a large portion of the face, blocking\nfacial expressions and thereby restricting social engagement cues among users.\nHence, auxiliary means of sensing and conveying these expressions are needed.\nWe present an algorithm to automatically infer expressions by analyzing only a\npartially occluded face while the user is engaged in a virtual reality\nexperience. Specifically, we show that images of the user's eyes captured from\nan IR gaze-tracking camera within a VR headset are sufficient to infer a select\nsubset of facial expressions without the use of any fixed external camera.\nUsing these inferences, we can generate dynamic avatars in real-time which\nfunction as an expressive surrogate for the user. We propose a novel data\ncollection pipeline as well as a novel approach for increasing CNN accuracy via\npersonalization. Our results show a mean accuracy of 74% ($F1$ of 0.73) among 5\n`emotive' expressions and a mean accuracy of 70% ($F1$ of 0.68) among 10\ndistinct facial action units, outperforming human raters. \n\n"}
{"id": "1707.07890", "contents": "Title: Spatiotemporal Modeling for Crowd Counting in Videos Abstract: Region of Interest (ROI) crowd counting can be formulated as a regression\nproblem of learning a mapping from an image or a video frame to a crowd density\nmap. Recently, convolutional neural network (CNN) models have achieved\npromising results for crowd counting. However, even when dealing with video\ndata, CNN-based methods still consider each video frame independently, ignoring\nthe strong temporal correlation between neighboring frames. To exploit the\notherwise very useful temporal information in video sequences, we propose a\nvariant of a recent deep learning model called convolutional LSTM (ConvLSTM)\nfor crowd counting. Unlike the previous CNN-based methods, our method fully\ncaptures both spatial and temporal dependencies. Furthermore, we extend the\nConvLSTM model to a bidirectional ConvLSTM model which can access long-range\ninformation in both directions. Extensive experiments using four publicly\navailable datasets demonstrate the reliability of our approach and the\neffectiveness of incorporating temporal information to boost the accuracy of\ncrowd counting. In addition, we also conduct some transfer learning experiments\nto show that once our model is trained on one dataset, its learning experience\ncan be transferred easily to a new dataset which consists of only very few\nvideo frames for model adaptation. \n\n"}
{"id": "1707.08722", "contents": "Title: Algebraic Relations and Triangulation of Unlabeled Image Points Abstract: In multiview geometry when correspondences among multiple views are unknown\nthe image points can be understood as being unlabeled. This is a common problem\nin computer vision. We give a novel approach to handle such a situation by\nregarding unlabeled point configurations as points on the Chow variety\n$\\text{Sym}_m(\\mathbb{P}^2)$. For two unlabeled points we design an algorithm\nthat solves the triangulation problem with unknown correspondences. Further the\nunlabeled multiview variety $\\text{Sym}_m(V_A)$ is studied. \n\n"}
{"id": "1707.09376", "contents": "Title: Face Deidentification with Generative Deep Neural Networks Abstract: Face deidentification is an active topic amongst privacy and security\nresearchers. Early deidentification methods relying on image blurring or\npixelization were replaced in recent years with techniques based on formal\nanonymity models that provide privacy guaranties and at the same time aim at\nretaining certain characteristics of the data even after deidentification. The\nlatter aspect is particularly important, as it allows to exploit the\ndeidentified data in applications for which identity information is irrelevant.\nIn this work we present a novel face deidentification pipeline, which ensures\nanonymity by synthesizing artificial surrogate faces using generative neural\nnetworks (GNNs). The generated faces are used to deidentify subjects in images\nor video, while preserving non-identity-related aspects of the data and\nconsequently enabling data utilization. Since generative networks are very\nadaptive and can utilize a diverse set of parameters (pertaining to the\nappearance of the generated output in terms of facial expressions, gender,\nrace, etc.), they represent a natural choice for the problem of face\ndeidentification. To demonstrate the feasibility of our approach, we perform\nexperiments using automated recognition tools and human annotators. Our results\nshow that the recognition performance on deidentified images is close to\nchance, suggesting that the deidentification process based on GNNs is highly\neffective. \n\n"}
{"id": "1707.09870", "contents": "Title: Extremely Low Bit Neural Network: Squeeze the Last Bit Out with ADMM Abstract: Although deep learning models are highly effective for various learning\ntasks, their high computational costs prohibit the deployment to scenarios\nwhere either memory or computational resources are limited. In this paper, we\nfocus on compressing and accelerating deep models with network weights\nrepresented by very small numbers of bits, referred to as extremely low bit\nneural network. We model this problem as a discretely constrained optimization\nproblem. Borrowing the idea from Alternating Direction Method of Multipliers\n(ADMM), we decouple the continuous parameters from the discrete constraints of\nnetwork, and cast the original hard problem into several subproblems. We\npropose to solve these subproblems using extragradient and iterative\nquantization algorithms that lead to considerably faster convergency compared\nto conventional optimization methods. Extensive experiments on image\nrecognition and object detection verify that the proposed algorithm is more\neffective than state-of-the-art approaches when coming to extremely low bit\nneural network. \n\n"}
{"id": "1707.09872", "contents": "Title: Full-Network Embedding in a Multimodal Embedding Pipeline Abstract: The current state-of-the-art for image annotation and image retrieval tasks\nis obtained through deep neural networks, which combine an image representation\nand a text representation into a shared embedding space. In this paper we\nevaluate the impact of using the Full-Network embedding in this setting,\nreplacing the original image representation in a competitive multimodal\nembedding generation scheme. Unlike the one-layer image embeddings typically\nused by most approaches, the Full-Network embedding provides a multi-scale\nrepresentation of images, which results in richer characterizations. To measure\nthe influence of the Full-Network embedding, we evaluate its performance on\nthree different datasets, and compare the results with the original multimodal\nembedding generation scheme when using a one-layer image embedding, and with\nthe rest of the state-of-the-art. Results for image annotation and image\nretrieval tasks indicate that the Full-Network embedding is consistently\nsuperior to the one-layer embedding. These results motivate the integration of\nthe Full-Network embedding on any multimodal embedding generation scheme,\nsomething feasible thanks to the flexibility of the approach. \n\n"}
{"id": "1708.00377", "contents": "Title: Segmentation of Glioma Tumors in Brain Using Deep Convolutional Neural\n  Network Abstract: Detection of brain tumor using a segmentation based approach is critical in\ncases, where survival of a subject depends on an accurate and timely clinical\ndiagnosis. Gliomas are the most commonly found tumors having irregular shape\nand ambiguous boundaries, making them one of the hardest tumors to detect. The\nautomation of brain tumor segmentation remains a challenging problem mainly due\nto significant variations in its structure. An automated brain tumor\nsegmentation algorithm using deep convolutional neural network (DCNN) is\npresented in this paper. A patch based approach along with an inception module\nis used for training the deep network by extracting two co-centric patches of\ndifferent sizes from the input images. Recent developments in deep neural\nnetworks such as drop-out, batch normalization, non-linear activation and\ninception module are used to build a new ILinear nexus architecture. The module\novercomes the over-fitting problem arising due to scarcity of data using\ndrop-out regularizer. Images are normalized and bias field corrected in the\npre-processing step and then extracted patches are passed through a DCNN, which\nassigns an output label to the central pixel of each patch. Morphological\noperators are used for post-processing to remove small false positives around\nthe edges. A two-phase weighted training method is introduced and evaluated\nusing BRATS 2013 and BRATS 2015 datasets, where it improves the performance\nparameters of state-of-the-art techniques under similar settings. \n\n"}
{"id": "1708.00489", "contents": "Title: Active Learning for Convolutional Neural Networks: A Core-Set Approach Abstract: Convolutional neural networks (CNNs) have been successfully applied to many\nrecognition and learning tasks using a universal recipe; training a deep model\non a very large dataset of supervised examples. However, this approach is\nrather restrictive in practice since collecting a large set of labeled images\nis very expensive. One way to ease this problem is coming up with smart ways\nfor choosing images to be labelled from a very large collection (ie. active\nlearning).\n  Our empirical study suggests that many of the active learning heuristics in\nthe literature are not effective when applied to CNNs in batch setting.\nInspired by these limitations, we define the problem of active learning as\ncore-set selection, ie. choosing set of points such that a model learned over\nthe selected subset is competitive for the remaining data points. We further\npresent a theoretical result characterizing the performance of any selected\nsubset using the geometry of the datapoints. As an active learning algorithm,\nwe choose the subset which is expected to yield best result according to our\ncharacterization. Our experiments show that the proposed method significantly\noutperforms existing approaches in image classification experiments by a large\nmargin. \n\n"}
{"id": "1708.00630", "contents": "Title: ProjectionNet: Learning Efficient On-Device Deep Networks Using Neural\n  Projections Abstract: Deep neural networks have become ubiquitous for applications related to\nvisual recognition and language understanding tasks. However, it is often\nprohibitive to use typical neural networks on devices like mobile phones or\nsmart watches since the model sizes are huge and cannot fit in the limited\nmemory available on such devices. While these devices could make use of machine\nlearning models running on high-performance data centers with CPUs or GPUs,\nthis is not feasible for many applications because data can be privacy\nsensitive and inference needs to be performed directly \"on\" device.\n  We introduce a new architecture for training compact neural networks using a\njoint optimization framework. At its core lies a novel objective that jointly\ntrains using two different types of networks--a full trainer neural network\n(using existing architectures like Feed-forward NNs or LSTM RNNs) combined with\na simpler \"projection\" network that leverages random projections to transform\ninputs or intermediate representations into bits. The simpler network encodes\nlightweight and efficient-to-compute operations in bit space with a low memory\nfootprint. The two networks are trained jointly using backpropagation, where\nthe projection network learns from the full network similar to apprenticeship\nlearning. Once trained, the smaller network can be used directly for inference\nat low memory and computation cost. We demonstrate the effectiveness of the new\napproach at significantly shrinking the memory requirements of different types\nof neural networks while preserving good accuracy on visual recognition and\ntext classification tasks. We also study the question \"how many neural bits are\nrequired to solve a given task?\" using the new framework and show empirical\nresults contrasting model predictive capacity (in bits) versus accuracy on\nseveral datasets. \n\n"}
{"id": "1708.00674", "contents": "Title: Deep Detection of People and their Mobility Aids for a Hospital Robot Abstract: Robots operating in populated environments encounter many different types of\npeople, some of whom might have an advanced need for cautious interaction,\nbecause of physical impairments or their advanced age. Robots therefore need to\nrecognize such advanced demands to provide appropriate assistance, guidance or\nother forms of support. In this paper, we propose a depth-based perception\npipeline that estimates the position and velocity of people in the environment\nand categorizes them according to the mobility aids they use: pedestrian,\nperson in wheelchair, person in a wheelchair with a person pushing them, person\nwith crutches and person using a walker. We present a fast region proposal\nmethod that feeds a Region-based Convolutional Network (Fast R-CNN). With this,\nwe speed up the object detection process by a factor of seven compared to a\ndense sliding window approach. We furthermore propose a probabilistic position,\nvelocity and class estimator to smooth the CNN's detections and account for\nocclusions and misclassifications. In addition, we introduce a new hospital\ndataset with over 17,000 annotated RGB-D images. Extensive experiments confirm\nthat our pipeline successfully keeps track of people and their mobility aids,\neven in challenging situations with multiple people from different categories\nand frequent occlusions. Videos of our experiments and the dataset are\navailable at http://www2.informatik.uni-freiburg.de/~kollmitz/MobilityAids \n\n"}
{"id": "1708.01008", "contents": "Title: Beyond Low Rank: A Data-Adaptive Tensor Completion Method Abstract: Low rank tensor representation underpins much of recent progress in tensor\ncompletion. In real applications, however, this approach is confronted with two\nchallenging problems, namely (1) tensor rank determination; (2) handling real\ntensor data which only approximately fulfils the low-rank requirement. To\naddress these two issues, we develop a data-adaptive tensor completion model\nwhich explicitly represents both the low-rank and non-low-rank structures in a\nlatent tensor. Representing the non-low-rank structure separately from the\nlow-rank one allows priors which capture the important distinctions between the\ntwo, thus enabling more accurate modelling, and ultimately, completion. Through\ndefining a new tensor rank, we develop a sparsity induced prior for the\nlow-rank structure, with which the tensor rank can be automatically determined.\nThe prior for the non-low-rank structure is established based on a mixture of\nGaussians which is shown to be flexible enough, and powerful enough, to inform\nthe completion process for a variety of real tensor data. With these two\npriors, we develop a Bayesian minimum mean squared error estimate (MMSE)\nframework for inference which provides the posterior mean of missing entries as\nwell as their uncertainty. Compared with the state-of-the-art methods in\nvarious applications, the proposed model produces more accurate completion\nresults. \n\n"}
{"id": "1708.01494", "contents": "Title: Hierarchical Metric Learning for Optical Remote Sensing Scene\n  Categorization Abstract: We address the problem of scene classification from optical remote sensing\n(RS) images based on the paradigm of hierarchical metric learning. Ideally,\nsupervised metric learning strategies learn a projection from a set of training\ndata points so as to minimize intra-class variance while maximizing inter-class\nseparability to the class label space. However, standard metric learning\ntechniques do not incorporate the class interaction information in learning the\ntransformation matrix, which is often considered to be a bottleneck while\ndealing with fine-grained visual categories. As a remedy, we propose to\norganize the classes in a hierarchical fashion by exploring their visual\nsimilarities and subsequently learn separate distance metric transformations\nfor the classes present at the non-leaf nodes of the tree. We employ an\niterative max-margin clustering strategy to obtain the hierarchical\norganization of the classes. Experiment results obtained on the large-scale\nNWPU-RESISC45 and the popular UC-Merced datasets demonstrate the efficacy of\nthe proposed hierarchical metric learning based RS scene recognition strategy\nin comparison to the standard approaches. \n\n"}
{"id": "1708.01886", "contents": "Title: Probabilistic Generative Adversarial Networks Abstract: We introduce the Probabilistic Generative Adversarial Network (PGAN), a new\nGAN variant based on a new kind of objective function. The central idea is to\nintegrate a probabilistic model (a Gaussian Mixture Model, in our case) into\nthe GAN framework which supports a new kind of loss function (based on\nlikelihood rather than classification loss), and at the same time gives a\nmeaningful measure of the quality of the outputs generated by the network.\nExperiments with MNIST show that the model learns to generate realistic images,\nand at the same time computes likelihoods that are correlated with the quality\nof the generated images. We show that PGAN is better able to cope with\ninstability problems that are usually observed in the GAN training procedure.\nWe investigate this from three aspects: the probability landscape of the\ndiscriminator, gradients of the generator, and the perfect discriminator\nproblem. \n\n"}
{"id": "1708.01892", "contents": "Title: End-to-end learning potentials for structured attribute prediction Abstract: We present a structured inference approach in deep neural networks for\nmultiple attribute prediction. In attribute prediction, a common approach is to\nlearn independent classifiers on top of a good feature representation. However,\nsuch classifiers assume conditional independence on features and do not\nexplicitly consider the dependency between attributes in the inference process.\nWe propose to formulate attribute prediction in terms of marginal inference in\nthe conditional random field. We model potential functions by deep neural\nnetworks and apply the sum-product algorithm to solve for the approximate\nmarginal distribution in feed-forward networks. Our message passing layer\nimplements sparse pairwise potentials by a softplus-linear function that is\nequivalent to a higher-order classifier, and learns all the model parameters by\nend-to-end back propagation. The experimental results using SUN attributes and\nCelebA datasets suggest that the structured inference improves the attribute\nprediction performance, and possibly uncovers the hidden relationship between\nattributes. \n\n"}
{"id": "1708.02179", "contents": "Title: Self-supervised Learning of Pose Embeddings from Spatiotemporal\n  Relations in Videos Abstract: Human pose analysis is presently dominated by deep convolutional networks\ntrained with extensive manual annotations of joint locations and beyond. To\navoid the need for expensive labeling, we exploit spatiotemporal relations in\ntraining videos for self-supervised learning of pose embeddings. The key idea\nis to combine temporal ordering and spatial placement estimation as auxiliary\ntasks for learning pose similarities in a Siamese convolutional network. Since\nthe self-supervised sampling of both tasks from natural videos can result in\nambiguous and incorrect training labels, our method employs a curriculum\nlearning idea that starts training with the most reliable data samples and\ngradually increases the difficulty. To further refine the training process we\nmine repetitive poses in individual videos which provide reliable labels while\nremoving inconsistencies. Our pose embeddings capture visual characteristics of\nhuman pose that can boost existing supervised representations in human pose\nestimation and retrieval. We report quantitative and qualitative results on\nthese tasks in Olympic Sports, Leeds Pose Sports and MPII Human Pose datasets. \n\n"}
{"id": "1708.02478", "contents": "Title: From Deterministic to Generative: Multi-Modal Stochastic RNNs for Video\n  Captioning Abstract: Video captioning in essential is a complex natural process, which is affected\nby various uncertainties stemming from video content, subjective judgment, etc.\nIn this paper we build on the recent progress in using encoder-decoder\nframework for video captioning and address what we find to be a critical\ndeficiency of the existing methods, that most of the decoders propagate\ndeterministic hidden states. Such complex uncertainty cannot be modeled\nefficiently by the deterministic models. In this paper, we propose a generative\napproach, referred to as multi-modal stochastic RNNs networks (MS-RNN), which\nmodels the uncertainty observed in the data using latent stochastic variables.\nTherefore, MS-RNN can improve the performance of video captioning, and generate\nmultiple sentences to describe a video considering different random factors.\nSpecifically, a multi-modal LSTM (M-LSTM) is first proposed to interact with\nboth visual and textual features to capture a high-level representation. Then,\na backward stochastic LSTM (S-LSTM) is proposed to support uncertainty\npropagation by introducing latent variables. Experimental results on the\nchallenging datasets MSVD and MSR-VTT show that our proposed MS-RNN approach\noutperforms the state-of-the-art video captioning benchmarks. \n\n"}
{"id": "1708.02735", "contents": "Title: Gaussian Prototypical Networks for Few-Shot Learning on Omniglot Abstract: We propose a novel architecture for $k$-shot classification on the Omniglot\ndataset. Building on prototypical networks, we extend their architecture to\nwhat we call Gaussian prototypical networks. Prototypical networks learn a map\nbetween images and embedding vectors, and use their clustering for\nclassification. In our model, a part of the encoder output is interpreted as a\nconfidence region estimate about the embedding point, and expressed as a\nGaussian covariance matrix. Our network then constructs a direction and class\ndependent distance metric on the embedding space, using uncertainties of\nindividual data points as weights. We show that Gaussian prototypical networks\nare a preferred architecture over vanilla prototypical networks with an\nequivalent number of parameters. We report state-of-the-art performance in\n1-shot and 5-shot classification both in 5-way and 20-way regime (for 5-shot\n5-way, we are comparable to previous state-of-the-art) on the Omniglot dataset.\nWe explore artificially down-sampling a fraction of images in the training set,\nwhich improves our performance even further. We therefore hypothesize that\nGaussian prototypical networks might perform better in less homogeneous,\nnoisier datasets, which are commonplace in real world applications. \n\n"}
{"id": "1708.03383", "contents": "Title: Joint Multi-Person Pose Estimation and Semantic Part Segmentation Abstract: Human pose estimation and semantic part segmentation are two complementary\ntasks in computer vision. In this paper, we propose to solve the two tasks\njointly for natural multi-person images, in which the estimated pose provides\nobject-level shape prior to regularize part segments while the part-level\nsegments constrain the variation of pose locations. Specifically, we first\ntrain two fully convolutional neural networks (FCNs), namely Pose FCN and Part\nFCN, to provide initial estimation of pose joint potential and semantic part\npotential. Then, to refine pose joint location, the two types of potentials are\nfused with a fully-connected conditional random field (FCRF), where a novel\nsegment-joint smoothness term is used to encourage semantic and spatial\nconsistency between parts and joints. To refine part segments, the refined pose\nand the original part potential are integrated through a Part FCN, where the\nskeleton feature from pose serves as additional regularization cues for part\nsegments. Finally, to reduce the complexity of the FCRF, we induce human\ndetection boxes and infer the graph inside each box, making the inference forty\ntimes faster.\n  Since there's no dataset that contains both part segments and pose labels, we\nextend the PASCAL VOC part dataset with human pose joints and perform extensive\nexperiments to compare our method against several most recent strategies. We\nshow that on this dataset our algorithm surpasses competing methods by a large\nmargin in both tasks. \n\n"}
{"id": "1708.04099", "contents": "Title: Context-based Normalization of Histological Stains using Deep\n  Convolutional Features Abstract: While human observers are able to cope with variations in color and\nappearance of histological stains, digital pathology algorithms commonly\nrequire a well-normalized setting to achieve peak performance, especially when\na limited amount of labeled data is available. This work provides a fully\nautomated, end-to-end learning-based setup for normalizing histological stains,\nwhich considers the texture context of the tissue. We introduce Feature Aware\nNormalization, which extends the framework of batch normalization in\ncombination with gating elements from Long Short-Term Memory units for\nnormalization among different spatial regions of interest. By incorporating a\npretrained deep neural network as a feature extractor steering a pixelwise\nprocessing pipeline, we achieve excellent normalization results and ensure a\nconsistent representation of color and texture. The evaluation comprises a\ncomparison of color histogram deviations, structural similarity and measures\nthe color volume obtained by the different methods. \n\n"}
{"id": "1708.04225", "contents": "Title: Deep Object-Centric Representations for Generalizable Robot Learning Abstract: Robotic manipulation in complex open-world scenarios requires both reliable\nphysical manipulation skills and effective and generalizable perception. In\nthis paper, we propose a method where general purpose pretrained visual models\nserve as an object-centric prior for the perception system of a learned policy.\nWe devise an object-level attentional mechanism that can be used to determine\nrelevant objects from a few trajectories or demonstrations, and then\nimmediately incorporate those objects into a learned policy. A task-independent\nmeta-attention locates possible objects in the scene, and a task-specific\nattention identifies which objects are predictive of the trajectories. The\nscope of the task-specific attention is easily adjusted by showing\ndemonstrations with distractor objects or with diverse relevant objects. Our\nresults indicate that this approach exhibits good generalization across object\ninstances using very few samples, and can be used to learn a variety of\nmanipulation tasks using reinforcement learning. \n\n"}
{"id": "1708.04538", "contents": "Title: Artistic style transfer for videos and spherical images Abstract: Manually re-drawing an image in a certain artistic style takes a professional\nartist a long time. Doing this for a video sequence single-handedly is beyond\nimagination. We present two computational approaches that transfer the style\nfrom one image (for example, a painting) to a whole video sequence. In our\nfirst approach, we adapt to videos the original image style transfer technique\nby Gatys et al. based on energy minimization. We introduce new ways of\ninitialization and new loss functions to generate consistent and stable\nstylized video sequences even in cases with large motion and strong occlusion.\nOur second approach formulates video stylization as a learning problem. We\npropose a deep network architecture and training procedures that allow us to\nstylize arbitrary-length videos in a consistent and stable way, and nearly in\nreal time. We show that the proposed methods clearly outperform simpler\nbaselines both qualitatively and quantitatively. Finally, we propose a way to\nadapt these approaches also to 360 degree images and videos as they emerge with\nrecent virtual reality hardware. \n\n"}
{"id": "1708.04788", "contents": "Title: BitNet: Bit-Regularized Deep Neural Networks Abstract: We present a novel optimization strategy for training neural networks which\nwe call \"BitNet\". The parameters of neural networks are usually unconstrained\nand have a dynamic range dispersed over all real values. Our key idea is to\nlimit the expressive power of the network by dynamically controlling the range\nand set of values that the parameters can take. We formulate this idea using a\nnovel end-to-end approach that circumvents the discrete parameter space by\noptimizing a relaxed continuous and differentiable upper bound of the typical\nclassification loss function. The approach can be interpreted as a\nregularization inspired by the Minimum Description Length (MDL) principle. For\neach layer of the network, our approach optimizes real-valued translation and\nscaling factors and arbitrary precision integer-valued parameters (weights). We\nempirically compare BitNet to an equivalent unregularized model on the MNIST\nand CIFAR-10 datasets. We show that BitNet converges faster to a superior\nquality solution. Additionally, the resulting model has significant savings in\nmemory due to the use of integer-valued parameters. \n\n"}
{"id": "1708.05033", "contents": "Title: Corrupt Bandits for Preserving Local Privacy Abstract: We study a variant of the stochastic multi-armed bandit (MAB) problem in\nwhich the rewards are corrupted. In this framework, motivated by privacy\npreservation in online recommender systems, the goal is to maximize the sum of\nthe (unobserved) rewards, based on the observation of transformation of these\nrewards through a stochastic corruption process with known parameters. We\nprovide a lower bound on the expected regret of any bandit algorithm in this\ncorrupted setting. We devise a frequentist algorithm, KLUCB-CF, and a Bayesian\nalgorithm, TS-CF and give upper bounds on their regret. We also provide the\nappropriate corruption parameters to guarantee a desired level of local privacy\nand analyze how this impacts the regret. Finally, we present some experimental\nresults that confirm our analysis. \n\n"}
{"id": "1708.05070", "contents": "Title: Data-driven Advice for Applying Machine Learning to Bioinformatics\n  Problems Abstract: As the bioinformatics field grows, it must keep pace not only with new data\nbut with new algorithms. Here we contribute a thorough analysis of 13\nstate-of-the-art, commonly used machine learning algorithms on a set of 165\npublicly available classification problems in order to provide data-driven\nalgorithm recommendations to current researchers. We present a number of\nstatistical and visual comparisons of algorithm performance and quantify the\neffect of model selection and algorithm tuning for each algorithm and dataset.\nThe analysis culminates in the recommendation of five algorithms with\nhyperparameters that maximize classifier performance across the tested\nproblems, as well as general guidelines for applying machine learning to\nsupervised classification problems. \n\n"}
{"id": "1708.06039", "contents": "Title: More cat than cute? Interpretable Prediction of Adjective-Noun Pairs Abstract: The increasing availability of affect-rich multimedia resources has bolstered\ninterest in understanding sentiment and emotions in and from visual content.\nAdjective-noun pairs (ANP) are a popular mid-level semantic construct for\ncapturing affect via visually detectable concepts such as \"cute dog\" or\n\"beautiful landscape\". Current state-of-the-art methods approach ANP prediction\nby considering each of these compound concepts as individual tokens, ignoring\nthe underlying relationships in ANPs. This work aims at disentangling the\ncontributions of the `adjectives' and `nouns' in the visual prediction of ANPs.\nTwo specialised classifiers, one trained for detecting adjectives and another\nfor nouns, are fused to predict 553 different ANPs. The resulting ANP\nprediction model is more interpretable as it allows us to study contributions\nof the adjective and noun components. Source code and models are available at\nhttps://imatge-upc.github.io/affective-2017-musa2/ . \n\n"}
{"id": "1708.07120", "contents": "Title: Super-Convergence: Very Fast Training of Neural Networks Using Large\n  Learning Rates Abstract: In this paper, we describe a phenomenon, which we named \"super-convergence\",\nwhere neural networks can be trained an order of magnitude faster than with\nstandard training methods. The existence of super-convergence is relevant to\nunderstanding why deep networks generalize well. One of the key elements of\nsuper-convergence is training with one learning rate cycle and a large maximum\nlearning rate. A primary insight that allows super-convergence training is that\nlarge learning rates regularize the training, hence requiring a reduction of\nall other forms of regularization in order to preserve an optimal\nregularization balance. We also derive a simplification of the Hessian Free\noptimization method to compute an estimate of the optimal learning rate.\nExperiments demonstrate super-convergence for Cifar-10/100, MNIST and Imagenet\ndatasets, and resnet, wide-resnet, densenet, and inception architectures. In\naddition, we show that super-convergence provides a greater boost in\nperformance relative to standard training when the amount of labeled training\ndata is limited. The architectures and code to replicate the figures in this\npaper are available at github.com/lnsmith54/super-convergence. See\nhttp://www.fast.ai/2018/04/30/dawnbench-fastai/ for an application of\nsuper-convergence to win the DAWNBench challenge (see\nhttps://dawn.cs.stanford.edu/benchmark/). \n\n"}
{"id": "1708.07601", "contents": "Title: A wavelet frame coefficient total variational model for image\n  restoration Abstract: In this paper, we propose a vector total variation (VTV) of feature image\nmodel for image restoration. The VTV imposes different smoothing powers on\ndifferent features (e.g. edges and cartoons) based on choosing various\nregularization parameters. Thus, the model can simultaneously preserve edges\nand remove noises. Next, the existence of solution for the model is proved and\nthe split Bregman algorithm is used to solve the model. At last, we use the\nwavelet filter banks to explicitly define the feature operator and present some\nexperimental results to show its advantage over the related methods in both\nquality and efficiency. \n\n"}
{"id": "1708.07791", "contents": "Title: Shape Registration with Directional Data Abstract: We propose several cost functions for registration of shapes encoded with\nEuclidean and/or non-Euclidean information (unit vectors). Our framework is\nassessed for estimation of both rigid and non-rigid transformations between the\ntarget and model shapes corresponding to 2D contours and 3D surfaces. The\nexperimental results obtained confirm that using the combination of a point's\nposition and unit normal vector in a cost function can enhance the registration\nresults compared to state of the art methods. \n\n"}
{"id": "1708.09254", "contents": "Title: Interpretation of Mammogram and Chest X-Ray Reports Using Deep Neural\n  Networks - Preliminary Results Abstract: Radiology reports are an important means of communication between\nradiologists and other physicians. These reports express a radiologist's\ninterpretation of a medical imaging examination and are critical in\nestablishing a diagnosis and formulating a treatment plan. In this paper, we\npropose a Bi-directional convolutional neural network (Bi-CNN) model for the\ninterpretation and classification of mammograms based on breast density and\nchest radiographic radiology reports based on the basis of chest pathology. The\nproposed approach helps to organize databases of radiology reports, retrieve\nthem expeditiously, and evaluate the radiology report that could be used in an\nauditing system to decrease incorrect diagnoses. Our study revealed that the\nproposed Bi-CNN outperforms the random forest and the support vector machine\nmethods. \n\n"}
{"id": "1708.09259", "contents": "Title: Efficient Convolutional Network Learning using Parametric Log based\n  Dual-Tree Wavelet ScatterNet Abstract: We propose a DTCWT ScatterNet Convolutional Neural Network (DTSCNN) formed by\nreplacing the first few layers of a CNN network with a parametric log based\nDTCWT ScatterNet. The ScatterNet extracts edge based invariant representations\nthat are used by the later layers of the CNN to learn high-level features. This\nimproves the training of the network as the later layers can learn more complex\npatterns from the start of learning because the edge representations are\nalready present. The efficient learning of the DTSCNN network is demonstrated\non CIFAR-10 and Caltech-101 datasets. The generic nature of the ScatterNet\nfront-end is shown by an equivalent performance to pre-trained CNN front-ends.\nA comparison with the state-of-the-art on CIFAR-10 and Caltech-101 datasets is\nalso presented. \n\n"}
{"id": "1708.09666", "contents": "Title: Generating Video Descriptions with Topic Guidance Abstract: Generating video descriptions in natural language (a.k.a. video captioning)\nis a more challenging task than image captioning as the videos are\nintrinsically more complicated than images in two aspects. First, videos cover\na broader range of topics, such as news, music, sports and so on. Second,\nmultiple topics could coexist in the same video. In this paper, we propose a\nnovel caption model, topic-guided model (TGM), to generate topic-oriented\ndescriptions for videos in the wild via exploiting topic information. In\naddition to predefined topics, i.e., category tags crawled from the web, we\nalso mine topics in a data-driven way based on training captions by an\nunsupervised topic mining model. We show that data-driven topics reflect a\nbetter topic schema than the predefined topics. As for testing video topic\nprediction, we treat the topic mining model as teacher to train the student,\nthe topic prediction model, by utilizing the full multi-modalities in the video\nespecially the speech modality. We propose a series of caption models to\nexploit topic guidance, including implicitly using the topics as input features\nto generate words related to the topic and explicitly modifying the weights in\nthe decoder with topics to function as an ensemble of topic-aware language\ndecoders. Our comprehensive experimental results on the current largest video\ncaption dataset MSR-VTT prove the effectiveness of our topic-guided model,\nwhich significantly surpasses the winning performance in the 2016 MSR video to\nlanguage challenge. \n\n"}
{"id": "1709.00265", "contents": "Title: Adversarial Networks for Spatial Context-Aware Spectral Image\n  Reconstruction from RGB Abstract: Hyperspectral signal reconstruction aims at recovering the original spectral\ninput that produced a certain trichromatic (RGB) response from a capturing\ndevice or observer. Given the heavily underconstrained, non-linear nature of\nthe problem, traditional techniques leverage different statistical properties\nof the spectral signal in order to build informative priors from real world\nobject reflectances for constructing such RGB to spectral signal mapping.\nHowever, most of them treat each sample independently, and thus do not benefit\nfrom the contextual information that the spatial dimensions can provide. We\npose hyperspectral natural image reconstruction as an image to image mapping\nlearning problem, and apply a conditional generative adversarial framework to\nhelp capture spatial semantics. This is the first time Convolutional Neural\nNetworks -and, particularly, Generative Adversarial Networks- are used to solve\nthis task. Quantitative evaluation shows a Root Mean Squared Error (RMSE) drop\nof 33.2% and a Relative RMSE drop of 54.0% on the ICVL natural hyperspectral\nimage dataset. \n\n"}
{"id": "1709.01450", "contents": "Title: The Devil is in the Tails: Fine-grained Classification in the Wild Abstract: The world is long-tailed. What does this mean for computer vision and visual\nrecognition? The main two implications are (1) the number of categories we need\nto consider in applications can be very large, and (2) the number of training\nexamples for most categories can be very small. Current visual recognition\nalgorithms have achieved excellent classification accuracy. However, they\nrequire many training examples to reach peak performance, which suggests that\nlong-tailed distributions will not be dealt with well. We analyze this question\nin the context of eBird, a large fine-grained classification dataset, and a\nstate-of-the-art deep network classification algorithm. We find that (a) peak\nclassification performance on well-represented categories is excellent, (b)\ngiven enough data, classification performance suffers only minimally from an\nincrease in the number of classes, (c) classification performance decays\nprecipitously as the number of training examples decreases, (d) surprisingly,\ntransfer learning is virtually absent in current methods. Our findings suggest\nthat our community should come to grips with the question of long tails. \n\n"}
{"id": "1709.01686", "contents": "Title: BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks Abstract: Deep neural networks are state of the art methods for many learning tasks due\nto their ability to extract increasingly better features at each network layer.\nHowever, the improved performance of additional layers in a deep network comes\nat the cost of added latency and energy usage in feedforward inference. As\nnetworks continue to get deeper and larger, these costs become more prohibitive\nfor real-time and energy-sensitive applications. To address this issue, we\npresent BranchyNet, a novel deep network architecture that is augmented with\nadditional side branch classifiers. The architecture allows prediction results\nfor a large portion of test samples to exit the network early via these\nbranches when samples can already be inferred with high confidence. BranchyNet\nexploits the observation that features learned at an early layer of a network\nmay often be sufficient for the classification of many data points. For more\ndifficult samples, which are expected less frequently, BranchyNet will use\nfurther or all network layers to provide the best likelihood of correct\nprediction. We study the BranchyNet architecture using several well-known\nnetworks (LeNet, AlexNet, ResNet) and datasets (MNIST, CIFAR10) and show that\nit can both improve accuracy and significantly reduce the inference time of the\nnetwork. \n\n"}
{"id": "1709.02043", "contents": "Title: The Mating Rituals of Deep Neural Networks: Learning Compact Feature\n  Representations through Sexual Evolutionary Synthesis Abstract: Evolutionary deep intelligence was recently proposed as a method for\nachieving highly efficient deep neural network architectures over successive\ngenerations. Drawing inspiration from nature, we propose the incorporation of\nsexual evolutionary synthesis. Rather than the current asexual synthesis of\nnetworks, we aim to produce more compact feature representations by\nsynthesizing more diverse and generalizable offspring networks in subsequent\ngenerations via the combination of two parent networks. Experimental results\nwere obtained using the MNIST and CIFAR-10 datasets, and showed improved\narchitectural efficiency and comparable testing accuracy relative to the\nbaseline asexual evolutionary neural networks. In particular, the network\nsynthesized via sexual evolutionary synthesis for MNIST had approximately\ndouble the architectural efficiency (cluster efficiency of 34.29X and synaptic\nefficiency of 258.37X) in comparison to the network synthesized via asexual\nevolutionary synthesis, with both networks achieving a testing accuracy of\n~97%. \n\n"}
{"id": "1709.02538", "contents": "Title: DeepFense: Online Accelerated Defense Against Adversarial Deep Learning Abstract: Recent advances in adversarial Deep Learning (DL) have opened up a largely\nunexplored surface for malicious attacks jeopardizing the integrity of\nautonomous DL systems. With the wide-spread usage of DL in critical and\ntime-sensitive applications, including unmanned vehicles, drones, and video\nsurveillance systems, online detection of malicious inputs is of utmost\nimportance. We propose DeepFense, the first end-to-end automated framework that\nsimultaneously enables efficient and safe execution of DL models. DeepFense\nformalizes the goal of thwarting adversarial attacks as an optimization problem\nthat minimizes the rarely observed regions in the latent feature space spanned\nby a DL network. To solve the aforementioned minimization problem, a set of\ncomplementary but disjoint modular redundancies are trained to validate the\nlegitimacy of the input samples in parallel with the victim DL model. DeepFense\nleverages hardware/software/algorithm co-design and customized acceleration to\nachieve just-in-time performance in resource-constrained settings. The proposed\ncountermeasure is unsupervised, meaning that no adversarial sample is leveraged\nto train modular redundancies. We further provide an accompanying API to reduce\nthe non-recurring engineering cost and ensure automated adaptation to various\nplatforms. Extensive evaluations on FPGAs and GPUs demonstrate up to two orders\nof magnitude performance improvement while enabling online adversarial sample\ndetection. \n\n"}
{"id": "1709.02929", "contents": "Title: Model Distillation with Knowledge Transfer from Face Classification to\n  Alignment and Verification Abstract: Knowledge distillation is a potential solution for model compression. The\nidea is to make a small student network imitate the target of a large teacher\nnetwork, then the student network can be competitive to the teacher one. Most\nprevious studies focus on model distillation in the classification task, where\nthey propose different architects and initializations for the student network.\nHowever, only the classification task is not enough, and other related tasks\nsuch as regression and retrieval are barely considered. To solve the problem,\nin this paper, we take face recognition as a breaking point and propose model\ndistillation with knowledge transfer from face classification to alignment and\nverification. By selecting appropriate initializations and targets in the\nknowledge transfer, the distillation can be easier in non-classification tasks.\nExperiments on the CelebA and CASIA-WebFace datasets demonstrate that the\nstudent network can be competitive to the teacher one in alignment and\nverification, and even surpasses the teacher network under specific compression\nrates. In addition, to achieve stronger knowledge transfer, we also use a\ncommon initialization trick to improve the distillation performance of\nclassification. Evaluations on the CASIA-Webface and large-scale MS-Celeb-1M\ndatasets show the effectiveness of this simple trick. \n\n"}
{"id": "1709.03376", "contents": "Title: Stack-Captioning: Coarse-to-Fine Learning for Image Captioning Abstract: The existing image captioning approaches typically train a one-stage sentence\ndecoder, which is difficult to generate rich fine-grained descriptions. On the\nother hand, multi-stage image caption model is hard to train due to the\nvanishing gradient problem. In this paper, we propose a coarse-to-fine\nmulti-stage prediction framework for image captioning, composed of multiple\ndecoders each of which operates on the output of the previous stage, producing\nincreasingly refined image descriptions. Our proposed learning approach\naddresses the difficulty of vanishing gradients during training by providing a\nlearning objective function that enforces intermediate supervisions.\nParticularly, we optimize our model with a reinforcement learning approach\nwhich utilizes the output of each intermediate decoder's test-time inference\nalgorithm as well as the output of its preceding decoder to normalize the\nrewards, which simultaneously solves the well-known exposure bias problem and\nthe loss-evaluation mismatch problem. We extensively evaluate the proposed\napproach on MSCOCO and show that our approach can achieve the state-of-the-art\nperformance. \n\n"}
{"id": "1709.05038", "contents": "Title: Self-Guiding Multimodal LSTM - when we do not have a perfect training\n  dataset for image captioning Abstract: In this paper, a self-guiding multimodal LSTM (sg-LSTM) image captioning\nmodel is proposed to handle uncontrolled imbalanced real-world image-sentence\ndataset. We collect FlickrNYC dataset from Flickr as our testbed with 306,165\nimages and the original text descriptions uploaded by the users are utilized as\nthe ground truth for training. Descriptions in FlickrNYC dataset vary\ndramatically ranging from short term-descriptions to long\nparagraph-descriptions and can describe any visual aspects, or even refer to\nobjects that are not depicted. To deal with the imbalanced and noisy situation\nand to fully explore the dataset itself, we propose a novel guiding textual\nfeature extracted utilizing a multimodal LSTM (m-LSTM) model. Training of\nm-LSTM is based on the portion of data in which the image content and the\ncorresponding descriptions are strongly bonded. Afterwards, during the training\nof sg-LSTM on the rest training data, this guiding information serves as\nadditional input to the network along with the image representations and the\nground-truth descriptions. By integrating these input components into a\nmultimodal block, we aim to form a training scheme with the textual information\ntightly coupled with the image content. The experimental results demonstrate\nthat the proposed sg-LSTM model outperforms the traditional state-of-the-art\nmultimodal RNN captioning framework in successfully describing the key\ncomponents of the input images. \n\n"}
{"id": "1709.05188", "contents": "Title: Adversarial Occlusion-aware Face Detection Abstract: Occluded face detection is a challenging detection task due to the large\nappearance variations incurred by various real-world occlusions. This paper\nintroduces an Adversarial Occlusion-aware Face Detector (AOFD) by\nsimultaneously detecting occluded faces and segmenting occluded areas.\nSpecifically, we employ an adversarial training strategy to generate\nocclusion-like face features that are difficult for a face detector to\nrecognize. Occlusion mask is predicted simultaneously while detecting occluded\nfaces and the occluded area is utilized as an auxiliary instead of being\nregarded as a hindrance. Moreover, the supervisory signals from the\nsegmentation branch will reversely affect the features, aiding in detecting\nheavily-occluded faces accordingly. Consequently, AOFD is able to find the\nfaces with few exposed facial landmarks with very high confidences and keeps\nhigh detection accuracy even for masked faces. Extensive experiments\ndemonstrate that AOFD not only significantly outperforms state-of-the-art\nmethods on the MAFA occluded face detection dataset, but also achieves\ncompetitive detection accuracy on benchmark dataset for general face detection\nsuch as FDDB. \n\n"}
{"id": "1709.05943", "contents": "Title: Fast YOLO: A Fast You Only Look Once System for Real-time Embedded\n  Object Detection in Video Abstract: Object detection is considered one of the most challenging problems in this\nfield of computer vision, as it involves the combination of object\nclassification and object localization within a scene. Recently, deep neural\nnetworks (DNNs) have been demonstrated to achieve superior object detection\nperformance compared to other approaches, with YOLOv2 (an improved You Only\nLook Once model) being one of the state-of-the-art in DNN-based object\ndetection methods in terms of both speed and accuracy. Although YOLOv2 can\nachieve real-time performance on a powerful GPU, it still remains very\nchallenging for leveraging this approach for real-time object detection in\nvideo on embedded computing devices with limited computational power and\nlimited memory. In this paper, we propose a new framework called Fast YOLO, a\nfast You Only Look Once framework which accelerates YOLOv2 to be able to\nperform object detection in video on embedded devices in a real-time manner.\nFirst, we leverage the evolutionary deep intelligence framework to evolve the\nYOLOv2 network architecture and produce an optimized architecture (referred to\nas O-YOLOv2 here) that has 2.8X fewer parameters with just a ~2% IOU drop. To\nfurther reduce power consumption on embedded devices while maintaining\nperformance, a motion-adaptive inference method is introduced into the proposed\nFast YOLO framework to reduce the frequency of deep inference with O-YOLOv2\nbased on temporal motion characteristics. Experimental results show that the\nproposed Fast YOLO framework can reduce the number of deep inferences by an\naverage of 38.13%, and an average speedup of ~3.3X for objection detection in\nvideo compared to the original YOLOv2, leading Fast YOLO to run an average of\n~18FPS on a Nvidia Jetson TX1 embedded system. \n\n"}
{"id": "1709.07200", "contents": "Title: Temporal Multimodal Fusion for Video Emotion Classification in the Wild Abstract: This paper addresses the question of emotion classification. The task\nconsists in predicting emotion labels (taken among a set of possible labels)\nbest describing the emotions contained in short video clips. Building on a\nstandard framework -- lying in describing videos by audio and visual features\nused by a supervised classifier to infer the labels -- this paper investigates\nseveral novel directions. First of all, improved face descriptors based on 2D\nand 3D Convo-lutional Neural Networks are proposed. Second, the paper explores\nseveral fusion methods, temporal and multimodal, including a novel hierarchical\nmethod combining features and scores. In addition, we carefully reviewed the\ndifferent stages of the pipeline and designed a CNN architecture adapted to the\ntask; this is important as the size of the training set is small compared to\nthe difficulty of the problem, making generalization difficult. The so-obtained\nmodel ranked 4th at the 2017 Emotion in the Wild challenge with the accuracy of\n58.8 %. \n\n"}
{"id": "1709.07223", "contents": "Title: Convolutional neural networks that teach microscopes how to image Abstract: Deep learning algorithms offer a powerful means to automatically analyze the\ncontent of medical images. However, many biological samples of interest are\nprimarily transparent to visible light and contain features that are difficult\nto resolve with a standard optical microscope. Here, we use a convolutional\nneural network (CNN) not only to classify images, but also to optimize the\nphysical layout of the imaging device itself. We increase the classification\naccuracy of a microscope's recorded images by merging an optical model of image\nformation into the pipeline of a CNN. The resulting network simultaneously\ndetermines an ideal illumination arrangement to highlight important sample\nfeatures during image acquisition, along with a set of convolutional weights to\nclassify the detected images post-capture. We demonstrate our joint\noptimization technique with an experimental microscope configuration that\nautomatically identifies malaria-infected cells with 5-10% higher accuracy than\nstandard and alternative microscope lighting designs. \n\n"}
{"id": "1709.07368", "contents": "Title: Multi-label Pixelwise Classification for Reconstruction of Large-scale\n  Urban Areas Abstract: Object classification is one of the many holy grails in computer vision and\nas such has resulted in a very large number of algorithms being proposed\nalready. Specifically in recent years there has been considerable progress in\nthis area primarily due to the increased efficiency and accessibility of deep\nlearning techniques. In fact, for single-label object classification [i.e. only\none object present in the image] the state-of-the-art techniques employ deep\nneural networks and are reporting very close to human-like performance. There\nare specialized applications in which single-label object-level classification\nwill not suffice; for example in cases where the image contains multiple\nintertwined objects of different labels.\n  In this paper, we address the complex problem of multi-label pixelwise\nclassification. We present our distinct solution based on a convolutional\nneural network (CNN) for performing multi-label pixelwise classification and\nits application to large-scale urban reconstruction. A supervised learning\napproach is followed for training a 13-layer CNN using both LiDAR and satellite\nimages. An empirical study has been conducted to determine the hyperparameters\nwhich result in the optimal performance of the CNN. Scale invariance is\nintroduced by training the network on five different scales of the input and\nlabeled data. This results in six pixelwise classifications for each different\nscale. An SVM is then trained to map the six pixelwise classifications into a\nsingle-label. Lastly, we refine boundary pixel labels using graph-cuts for\nmaximum a-posteriori (MAP) estimation with Markov Random Field (MRF) priors.\nThe resulting pixelwise classification is then used to accurately extract and\nreconstruct the buildings in large-scale urban areas. The proposed approach has\nbeen extensively tested and the results are reported. \n\n"}
{"id": "1709.07689", "contents": "Title: Real-time 3D Shape Instantiation from Single Fluoroscopy Projection for\n  Fenestrated Stent Graft Deployment Abstract: Robot-assisted deployment of fenestrated stent grafts in Fenestrated\nEndovascular Aortic Repair (FEVAR) requires accurate geometrical alignment.\nCurrently, this process is guided by 2D fluoroscopy, which is uninformative and\nerror prone. In this paper, a real-time framework is proposed to instantiate\nthe 3D shape of a fenestrated stent graft based on only a single low-dose 2D\nfluoroscopic image. Firstly, the fenestrated stent graft was placed with\nmarkers. Secondly, the 3D pose of each stent segment was instantiated by the\nRPnP (Robust Perspective-n-Point) method. Thirdly, the 3D shape of the whole\nstent graft was instantiated via graft gap interpolation. Focal-Unet was\nproposed to segment the markers from 2D fluoroscopic images to achieve\nsemi-automatic marker detection. The proposed framework was validated on five\npatient-specific 3D printed phantoms of aortic aneurysms and three stent grafts\nwith new marker placements, showing an average distance error of 1-3mm and an\naverage angle error of 4 degree. \n\n"}
{"id": "1709.08421", "contents": "Title: Summarization of User-Generated Sports Video by Using Deep Action\n  Recognition Features Abstract: Automatically generating a summary of sports video poses the challenge of\ndetecting interesting moments, or highlights, of a game. Traditional sports\nvideo summarization methods leverage editing conventions of broadcast sports\nvideo that facilitate the extraction of high-level semantics. However,\nuser-generated videos are not edited, and thus traditional methods are not\nsuitable to generate a summary. In order to solve this problem, this work\nproposes a novel video summarization method that uses players' actions as a cue\nto determine the highlights of the original video. A deep neural network-based\napproach is used to extract two types of action-related features and to\nclassify video segments into interesting or uninteresting parts. The proposed\nmethod can be applied to any sports in which games consist of a succession of\nactions. Especially, this work considers the case of Kendo (Japanese fencing)\nas an example of a sport to evaluate the proposed method. The method is trained\nusing Kendo videos with ground truth labels that indicate the video highlights.\nThe labels are provided by annotators possessing different experience with\nrespect to Kendo to demonstrate how the proposed method adapts to different\nneeds. The performance of the proposed method is compared with several\ncombinations of different features, and the results show that it outperforms\nprevious summarization methods. \n\n"}
{"id": "1709.08524", "contents": "Title: Generative learning for deep networks Abstract: Learning, taking into account full distribution of the data, referred to as\ngenerative, is not feasible with deep neural networks (DNNs) because they model\nonly the conditional distribution of the outputs given the inputs. Current\nsolutions are either based on joint probability models facing difficult\nestimation problems or learn two separate networks, mapping inputs to outputs\n(recognition) and vice-versa (generation). We propose an intermediate approach.\nFirst, we show that forward computation in DNNs with logistic sigmoid\nactivations corresponds to a simplified approximate Bayesian inference in a\ndirected probabilistic multi-layer model. This connection allows to interpret\nDNN as a probabilistic model of the output and all hidden units given the\ninput. Second, we propose that in order for the recognition and generation\nnetworks to be more consistent with the joint model of the data, weights of the\nrecognition and generator network should be related by transposition. We\ndemonstrate in a tentative experiment that such a coupled pair can be learned\ngeneratively, modelling the full distribution of the data, and has enough\ncapacity to perform well in both recognition and generation. \n\n"}
{"id": "1709.09602", "contents": "Title: Exposure: A White-Box Photo Post-Processing Framework Abstract: Retouching can significantly elevate the visual appeal of photos, but many\ncasual photographers lack the expertise to do this well. To address this\nproblem, previous works have proposed automatic retouching systems based on\nsupervised learning from paired training images acquired before and after\nmanual editing. As it is difficult for users to acquire paired images that\nreflect their retouching preferences, we present in this paper a deep learning\napproach that is instead trained on unpaired data, namely a set of photographs\nthat exhibits a retouching style the user likes, which is much easier to\ncollect. Our system is formulated using deep convolutional neural networks that\nlearn to apply different retouching operations on an input image. Network\ntraining with respect to various types of edits is enabled by modeling these\nretouching operations in a unified manner as resolution-independent\ndifferentiable filters. To apply the filters in a proper sequence and with\nsuitable parameters, we employ a deep reinforcement learning approach that\nlearns to make decisions on what action to take next, given the current state\nof the image. In contrast to many deep learning systems, ours provides users\nwith an understandable solution in the form of conventional retouching edits,\nrather than just a \"black-box\" result. Through quantitative comparisons and\nuser studies, we show that this technique generates retouching results\nconsistent with the provided photo set. \n\n"}
{"id": "1710.00811", "contents": "Title: Deep Learning for Unsupervised Insider Threat Detection in Structured\n  Cybersecurity Data Streams Abstract: Analysis of an organization's computer network activity is a key component of\nearly detection and mitigation of insider threat, a growing concern for many\norganizations. Raw system logs are a prototypical example of streaming data\nthat can quickly scale beyond the cognitive power of a human analyst. As a\nprospective filter for the human analyst, we present an online unsupervised\ndeep learning approach to detect anomalous network activity from system logs in\nreal time. Our models decompose anomaly scores into the contributions of\nindividual user behavior features for increased interpretability to aid\nanalysts reviewing potential cases of insider threat. Using the CERT Insider\nThreat Dataset v6.2 and threat detection recall as our performance metric, our\nnovel deep and recurrent neural network models outperform Principal Component\nAnalysis, Support Vector Machine and Isolation Forest based anomaly detection\nbaselines. For our best model, the events labeled as insider threat activity in\nour dataset had an average anomaly score in the 95.53 percentile, demonstrating\nour approach's potential to greatly reduce analyst workloads. \n\n"}
{"id": "1710.01257", "contents": "Title: Deep learning for source camera identification on mobile devices Abstract: In the present paper, we propose a source camera identification method for\nmobile devices based on deep learning. Recently, convolutional neural networks\n(CNNs) have shown a remarkable performance on several tasks such as image\nrecognition, video analysis or natural language processing. A CNN consists on a\nset of layers where each layer is composed by a set of high pass filters which\nare applied all over the input image. This convolution process provides the\nunique ability to extract features automatically from data and to learn from\nthose features. Our proposal describes a CNN architecture which is able to\ninfer the noise pattern of mobile camera sensors (also known as camera\nfingerprint) with the aim at detecting and identifying not only the mobile\ndevice used to capture an image (with a 98\\% of accuracy), but also from which\nembedded camera the image was captured. More specifically, we provide an\nextensive analysis on the proposed architecture considering different\nconfigurations. The experiment has been carried out using the images captured\nfrom different mobile devices cameras (MICHE-I Dataset was used) and the\nobtained results have proved the robustness of the proposed method. \n\n"}
{"id": "1710.01559", "contents": "Title: Monitoring tool usage in surgery videos using boosted convolutional and\n  recurrent neural networks Abstract: This paper investigates the automatic monitoring of tool usage during a\nsurgery, with potential applications in report generation, surgical training\nand real-time decision support. Two surgeries are considered: cataract surgery,\nthe most common surgical procedure, and cholecystectomy, one of the most common\ndigestive surgeries. Tool usage is monitored in videos recorded either through\na microscope (cataract surgery) or an endoscope (cholecystectomy). Following\nstate-of-the-art video analysis solutions, each frame of the video is analyzed\nby convolutional neural networks (CNNs) whose outputs are fed to recurrent\nneural networks (RNNs) in order to take temporal relationships between events\ninto account. Novelty lies in the way those CNNs and RNNs are trained.\nComputational complexity prevents the end-to-end training of \"CNN+RNN\" systems.\nTherefore, CNNs are usually trained first, independently from the RNNs. This\napproach is clearly suboptimal for surgical tool analysis: many tools are very\nsimilar to one another, but they can generally be differentiated based on past\nevents. CNNs should be trained to extract the most useful visual features in\ncombination with the temporal context. A novel boosting strategy is proposed to\nachieve this goal: the CNN and RNN parts of the system are simultaneously\nenriched by progressively adding weak classifiers (either CNNs or RNNs) trained\nto improve the overall classification accuracy. Experiments were performed in a\ndataset of 50 cataract surgery videos and a dataset of 80 cholecystectomy\nvideos. Very good classification performance are achieved in both datasets:\ntool usage could be labeled with an average area under the ROC curve of $A_z =\n0.9961$ and $A_z = 0.9939$, respectively, in offline mode (using past, present\nand future information), and $A_z = 0.9957$ and $A_z = 0.9936$, respectively,\nin online mode (using past and present information only). \n\n"}
{"id": "1710.01688", "contents": "Title: On the Sample Complexity of the Linear Quadratic Regulator Abstract: This paper addresses the optimal control problem known as the Linear\nQuadratic Regulator in the case when the dynamics are unknown. We propose a\nmulti-stage procedure, called Coarse-ID control, that estimates a model from a\nfew experimental trials, estimates the error in that model with respect to the\ntruth, and then designs a controller using both the model and uncertainty\nestimate. Our technique uses contemporary tools from random matrix theory to\nbound the error in the estimation procedure. We also employ a recently\ndeveloped approach to control synthesis called System Level Synthesis that\nenables robust control design by solving a convex optimization problem. We\nprovide end-to-end bounds on the relative error in control cost that are nearly\noptimal in the number of parameters and that highlight salient properties of\nthe system to be controlled such as closed-loop sensitivity and optimal control\nmagnitude. We show experimentally that the Coarse-ID approach enables efficient\ncomputation of a stabilizing controller in regimes where simple control schemes\nthat do not take the model uncertainty into account fail to stabilize the true\nsystem. \n\n"}
{"id": "1710.01916", "contents": "Title: A self-organizing neural network architecture for learning human-object\n  interactions Abstract: The visual recognition of transitive actions comprising human-object\ninteractions is a key component for artificial systems operating in natural\nenvironments. This challenging task requires jointly the recognition of\narticulated body actions as well as the extraction of semantic elements from\nthe scene such as the identity of the manipulated objects. In this paper, we\npresent a self-organizing neural network for the recognition of human-object\ninteractions from RGB-D videos. Our model consists of a hierarchy of\nGrow-When-Required (GWR) networks that learn prototypical representations of\nbody motion patterns and objects, accounting for the development of\naction-object mappings in an unsupervised fashion. We report experimental\nresults on a dataset of daily activities collected for the purpose of this\nstudy as well as on a publicly available benchmark dataset. In line with\nneurophysiological studies, our self-organizing architecture exhibits higher\nneural activation for congruent action-object pairs learned during training\nsessions with respect to synthetically created incongruent ones. We show that\nour unsupervised model shows competitive classification results on the\nbenchmark dataset with respect to strictly supervised approaches. \n\n"}
{"id": "1710.03370", "contents": "Title: iVQA: Inverse Visual Question Answering Abstract: We propose the inverse problem of Visual question answering (iVQA), and\nexplore its suitability as a benchmark for visuo-linguistic understanding. The\niVQA task is to generate a question that corresponds to a given image and\nanswer pair. Since the answers are less informative than the questions, and the\nquestions have less learnable bias, an iVQA model needs to better understand\nthe image to be successful than a VQA model. We pose question generation as a\nmulti-modal dynamic inference process and propose an iVQA model that can\ngradually adjust its focus of attention guided by both a partially generated\nquestion and the answer. For evaluation, apart from existing linguistic\nmetrics, we propose a new ranking metric. This metric compares the ground truth\nquestion's rank among a list of distractors, which allows the drawbacks of\ndifferent algorithms and sources of error to be studied. Experimental results\nshow that our model can generate diverse, grammatically correct and content\ncorrelated questions that match the given answer. \n\n"}
{"id": "1710.03958", "contents": "Title: Detect to Track and Track to Detect Abstract: Recent approaches for high accuracy detection and tracking of object\ncategories in video consist of complex multistage solutions that become more\ncumbersome each year. In this paper we propose a ConvNet architecture that\njointly performs detection and tracking, solving the task in a simple and\neffective way. Our contributions are threefold: (i) we set up a ConvNet\narchitecture for simultaneous detection and tracking, using a multi-task\nobjective for frame-based object detection and across-frame track regression;\n(ii) we introduce correlation features that represent object co-occurrences\nacross time to aid the ConvNet during tracking; and (iii) we link the frame\nlevel detections based on our across-frame tracklets to produce high accuracy\ndetections at the video level. Our ConvNet architecture for spatiotemporal\nobject detection is evaluated on the large-scale ImageNet VID dataset where it\nachieves state-of-the-art results. Our approach provides better single model\nperformance than the winning method of the last ImageNet challenge while being\nconceptually much simpler. Finally, we show that by increasing the temporal\nstride we can dramatically increase the tracker speed. \n\n"}
{"id": "1710.05758", "contents": "Title: TensorQuant - A Simulation Toolbox for Deep Neural Network Quantization Abstract: Recent research implies that training and inference of deep neural networks\n(DNN) can be computed with low precision numerical representations of the\ntraining/test data, weights and gradients without a general loss in accuracy.\nThe benefit of such compact representations is twofold: they allow a\nsignificant reduction of the communication bottleneck in distributed DNN\ntraining and faster neural network implementations on hardware accelerators\nlike FPGAs. Several quantization methods have been proposed to map the original\n32-bit floating point problem to low-bit representations. While most related\npublications validate the proposed approach on a single DNN topology, it\nappears to be evident, that the optimal choice of the quantization method and\nnumber of coding bits is topology dependent. To this end, there is no general\ntheory available, which would allow users to derive the optimal quantization\nduring the design of a DNN topology. In this paper, we present a quantization\ntool box for the TensorFlow framework. TensorQuant allows a transparent\nquantization simulation of existing DNN topologies during training and\ninference. TensorQuant supports generic quantization methods and allows\nexperimental evaluation of the impact of the quantization on single layers as\nwell as on the full topology. In a first series of experiments with\nTensorQuant, we show an analysis of fix-point quantizations of popular CNN\ntopologies. \n\n"}
{"id": "1710.05941", "contents": "Title: Searching for Activation Functions Abstract: The choice of activation functions in deep networks has a significant effect\non the training dynamics and task performance. Currently, the most successful\nand widely-used activation function is the Rectified Linear Unit (ReLU).\nAlthough various hand-designed alternatives to ReLU have been proposed, none\nhave managed to replace it due to inconsistent gains. In this work, we propose\nto leverage automatic search techniques to discover new activation functions.\nUsing a combination of exhaustive and reinforcement learning-based search, we\ndiscover multiple novel activation functions. We verify the effectiveness of\nthe searches by conducting an empirical evaluation with the best discovered\nactivation function. Our experiments show that the best discovered activation\nfunction, $f(x) = x \\cdot \\text{sigmoid}(\\beta x)$, which we name Swish, tends\nto work better than ReLU on deeper models across a number of challenging\ndatasets. For example, simply replacing ReLUs with Swish units improves top-1\nclassification accuracy on ImageNet by 0.9\\% for Mobile NASNet-A and 0.6\\% for\nInception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it\neasy for practitioners to replace ReLUs with Swish units in any neural network. \n\n"}
{"id": "1710.06940", "contents": "Title: Concept Drift Learning with Alternating Learners Abstract: Data-driven predictive analytics are in use today across a number of\nindustrial applications, but further integration is hindered by the requirement\nof similarity among model training and test data distributions. This paper\naddresses the need of learning from possibly nonstationary data streams, or\nunder concept drift, a commonly seen phenomenon in practical applications. A\nsimple dual-learner ensemble strategy, alternating learners framework, is\nproposed. A long-memory model learns stable concepts from a long relevant time\nwindow, while a short-memory model learns transient concepts from a small\nrecent window. The difference in prediction performance of these two models is\nmonitored and induces an alternating policy to select, update and reset the two\nmodels. The method features an online updating mechanism to maintain the\nensemble accuracy, and a concept-dependent trigger to focus on relevant data.\nThrough empirical studies the method demonstrates effective tracking and\nprediction when the steaming data carry abrupt and/or gradual changes. \n\n"}
{"id": "1710.07096", "contents": "Title: Deep Self-taught Learning for Remote Sensing Image Classification Abstract: This paper addresses the land cover classification task for remote sensing\nimages by deep self-taught learning. Our self-taught learning approach learns\nsuitable feature representations of the input data using sparse representation\nand undercomplete dictionary learning. We propose a deep learning framework\nwhich extracts representations in multiple layers and use the output of the\ndeepest layer as input to a classification algorithm. We evaluate our approach\nusing a multispectral Landsat 5 TM image of a study area in the North of Novo\nProgresso (South America) and the Zurich Summer Data Set provided by the\nUniversity of Zurich. Experiments indicate that features learned by a deep\nself-taught learning framework can be used for classification and improve the\nresults compared to classification results using the original feature\nrepresentation. \n\n"}
{"id": "1710.07354", "contents": "Title: Learning to Recognize Actions from Limited Training Examples Using a\n  Recurrent Spiking Neural Model Abstract: A fundamental challenge in machine learning today is to build a model that\ncan learn from few examples. Here, we describe a reservoir based spiking neural\nmodel for learning to recognize actions with a limited number of labeled\nvideos. First, we propose a novel encoding, inspired by how microsaccades\ninfluence visual perception, to extract spike information from raw video data\nwhile preserving the temporal correlation across different frames. Using this\nencoding, we show that the reservoir generalizes its rich dynamical activity\ntoward signature action/movements enabling it to learn from few training\nexamples. We evaluate our approach on the UCF-101 dataset. Our experiments\ndemonstrate that our proposed reservoir achieves 81.3%/87% Top-1/Top-5\naccuracy, respectively, on the 101-class data while requiring just 8 video\nexamples per class for training. Our results establish a new benchmark for\naction recognition from limited video examples for spiking neural models while\nyielding competetive accuracy with respect to state-of-the-art non-spiking\nneural models. \n\n"}
{"id": "1710.07558", "contents": "Title: Classification Driven Dynamic Image Enhancement Abstract: Convolutional neural networks rely on image texture and structure to serve as\ndiscriminative features to classify the image content. Image enhancement\ntechniques can be used as preprocessing steps to help improve the overall image\nquality and in turn improve the overall effectiveness of a CNN. Existing image\nenhancement methods, however, are designed to improve the perceptual quality of\nan image for a human observer. In this paper, we are interested in learning\nCNNs that can emulate image enhancement and restoration, but with the overall\ngoal to improve image classification and not necessarily human perception. To\nthis end, we present a unified CNN architecture that uses a range of\nenhancement filters that can enhance image-specific details via end-to-end\ndynamic filter learning. We demonstrate the effectiveness of this strategy on\nfour challenging benchmark datasets for fine-grained, object, scene, and\ntexture classification: CUB-200-2011, PASCAL-VOC2007, MIT-Indoor, and DTD.\nExperiments using our proposed enhancement show promising results on all the\ndatasets. In addition, our approach is capable of improving the performance of\nall generic CNN architectures. \n\n"}
{"id": "1710.07859", "contents": "Title: Feature-Guided Black-Box Safety Testing of Deep Neural Networks Abstract: Despite the improved accuracy of deep neural networks, the discovery of\nadversarial examples has raised serious safety concerns. Most existing\napproaches for crafting adversarial examples necessitate some knowledge\n(architecture, parameters, etc.) of the network at hand. In this paper, we\nfocus on image classifiers and propose a feature-guided black-box approach to\ntest the safety of deep neural networks that requires no such knowledge. Our\nalgorithm employs object detection techniques such as SIFT (Scale Invariant\nFeature Transform) to extract features from an image. These features are\nconverted into a mutable saliency distribution, where high probability is\nassigned to pixels that affect the composition of the image with respect to the\nhuman visual system. We formulate the crafting of adversarial examples as a\ntwo-player turn-based stochastic game, where the first player's objective is to\nminimise the distance to an adversarial example by manipulating the features,\nand the second player can be cooperative, adversarial, or random. We show that,\ntheoretically, the two-player game can con- verge to the optimal strategy, and\nthat the optimal strategy represents a globally minimal adversarial image. For\nLipschitz networks, we also identify conditions that provide safety guarantees\nthat no adversarial examples exist. Using Monte Carlo tree search we gradually\nexplore the game state space to search for adversarial examples. Our\nexperiments show that, despite the black-box setting, manipulations guided by a\nperception-based saliency distribution are competitive with state-of-the-art\nmethods that rely on white-box saliency matrices or sophisticated optimization\nprocedures. Finally, we show how our method can be used to evaluate robustness\nof neural networks in safety-critical applications such as traffic sign\nrecognition in self-driving cars. \n\n"}
{"id": "1710.08177", "contents": "Title: Progressive Learning for Systematic Design of Large Neural Networks Abstract: We develop an algorithm for systematic design of a large artificial neural\nnetwork using a progression property. We find that some non-linear functions,\nsuch as the rectifier linear unit and its derivatives, hold the property. The\nsystematic design addresses the choice of network size and regularization of\nparameters. The number of nodes and layers in network increases in progression\nwith the objective of consistently reducing an appropriate cost. Each layer is\noptimized at a time, where appropriate parameters are learned using convex\noptimization. Regularization parameters for convex optimization do not need a\nsignificant manual effort for tuning. We also use random instances for some\nweight matrices, and that helps to reduce the number of parameters we learn.\nThe developed network is expected to show good generalization power due to\nappropriate regularization and use of random weights in the layers. This\nexpectation is verified by extensive experiments for classification and\nregression problems, using standard databases. \n\n"}
{"id": "1710.09282", "contents": "Title: A Survey of Model Compression and Acceleration for Deep Neural Networks Abstract: Deep neural networks (DNNs) have recently achieved great success in many\nvisual recognition tasks. However, existing deep neural network models are\ncomputationally expensive and memory intensive, hindering their deployment in\ndevices with low memory resources or in applications with strict latency\nrequirements. Therefore, a natural thought is to perform model compression and\nacceleration in deep networks without significantly decreasing the model\nperformance. During the past five years, tremendous progress has been made in\nthis area. In this paper, we review the recent techniques for compacting and\naccelerating DNN models. In general, these techniques are divided into four\ncategories: parameter pruning and quantization, low-rank factorization,\ntransferred/compact convolutional filters, and knowledge distillation. Methods\nof parameter pruning and quantization are described first, after that the other\ntechniques are introduced. For each category, we also provide insightful\nanalysis about the performance, related applications, advantages, and\ndrawbacks. Then we go through some very recent successful methods, for example,\ndynamic capacity networks and stochastic depths networks. After that, we survey\nthe evaluation matrices, the main datasets used for evaluating the model\nperformance, and recent benchmark efforts. Finally, we conclude this paper,\ndiscuss remaining the challenges and possible directions for future work. \n\n"}
{"id": "1710.09934", "contents": "Title: Data-driven Feature Sampling for Deep Hyperspectral Classification and\n  Segmentation Abstract: The high dimensionality of hyperspectral imaging forces unique challenges in\nscope, size and processing requirements. Motivated by the potential for an\nin-the-field cell sorting detector, we examine a $\\textit{Synechocystis sp.}$\nPCC 6803 dataset wherein cells are grown alternatively in nitrogen rich or\ndeplete cultures. We use deep learning techniques to both successfully classify\ncells and generate a mask segmenting the cells/condition from the background.\nFurther, we use the classification accuracy to guide a data-driven, iterative\nfeature selection method, allowing the design neural networks requiring 90%\nfewer input features with little accuracy degradation. \n\n"}
{"id": "1710.10121", "contents": "Title: Beyond Finite Layer Neural Networks: Bridging Deep Architectures and\n  Numerical Differential Equations Abstract: In our work, we bridge deep neural network design with numerical differential\nequations. We show that many effective networks, such as ResNet, PolyNet,\nFractalNet and RevNet, can be interpreted as different numerical\ndiscretizations of differential equations. This finding brings us a brand new\nperspective on the design of effective deep architectures. We can take\nadvantage of the rich knowledge in numerical analysis to guide us in designing\nnew and potentially more effective deep networks. As an example, we propose a\nlinear multi-step architecture (LM-architecture) which is inspired by the\nlinear multi-step method solving ordinary differential equations. The\nLM-architecture is an effective structure that can be used on any ResNet-like\nnetworks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the\nnetworks obtained by applying the LM-architecture on ResNet and ResNeXt\nrespectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on\nboth CIFAR and ImageNet with comparable numbers of trainable parameters. In\nparticular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly\ncompress ($>50$\\%) the original networks while maintaining a similar\nperformance. This can be explained mathematically using the concept of modified\nequation from numerical analysis. Last but not least, we also establish a\nconnection between stochastic control and noise injection in the training\nprocess which helps to improve generalization of the networks. Furthermore, by\nrelating stochastic training strategy with stochastic dynamic system, we can\neasily apply stochastic training to the networks with the LM-architecture. As\nan example, we introduced stochastic depth to LM-ResNet and achieve significant\nimprovement over the original LM-ResNet on CIFAR10. \n\n"}
{"id": "1710.10304", "contents": "Title: Few-shot Autoregressive Density Estimation: Towards Learning to Learn\n  Distributions Abstract: Deep autoregressive models have shown state-of-the-art performance in density\nestimation for natural images on large-scale datasets such as ImageNet.\nHowever, such models require many thousands of gradient-based weight updates\nand unique image examples for training. Ideally, the models would rapidly learn\nvisual concepts from only a handful of examples, similar to the manner in which\nhumans learns across many vision tasks. In this paper, we show how 1) neural\nattention and 2) meta learning techniques can be used in combination with\nautoregressive models to enable effective few-shot density estimation. Our\nproposed modifications to PixelCNN result in state-of-the art few-shot density\nestimation on the Omniglot dataset. Furthermore, we visualize the learned\nattention policy and find that it learns intuitive algorithms for simple tasks\nsuch as image mirroring on ImageNet and handwriting on Omniglot without\nsupervision. Finally, we extend the model to natural images and demonstrate\nfew-shot image generation on the Stanford Online Products dataset. \n\n"}
{"id": "1710.10460", "contents": "Title: Toward predictive machine learning for active vision Abstract: We develop a comprehensive description of the active inference framework, as\nproposed by Friston (2010), under a machine-learning compliant perspective.\nStemming from a biological inspiration and the auto-encoding principles, the\nsketch of a cognitive architecture is proposed that should provide ways to\nimplement estimation-oriented control policies. Computer simulations illustrate\nthe effectiveness of the approach through a foveated inspection of the input\ndata. The pros and cons of the control policy are analyzed in detail, showing\ninteresting promises in terms of processing compression. Though optimizing\nfuture posterior entropy over the actions set is shown enough to attain locally\noptimal action selection, offline calculation using class-specific saliency\nmaps is shown better for it saves processing costs through saccades pathways\npre-processing, with a negligible effect on the recognition/compression rates. \n\n"}
{"id": "1710.10741", "contents": "Title: Evolving Deep Convolutional Neural Networks for Image Classification Abstract: Evolutionary computation methods have been successfully applied to neural\nnetworks since two decades ago, while those methods cannot scale well to the\nmodern deep neural networks due to the complicated architectures and large\nquantities of connection weights. In this paper, we propose a new method using\ngenetic algorithms for evolving the architectures and connection weight\ninitialization values of a deep convolutional neural network to address image\nclassification problems. In the proposed algorithm, an efficient\nvariable-length gene encoding strategy is designed to represent the different\nbuilding blocks and the unpredictable optimal depth in convolutional neural\nnetworks. In addition, a new representation scheme is developed for effectively\ninitializing connection weights of deep convolutional neural networks, which is\nexpected to avoid networks getting stuck into local minima which is typically a\nmajor issue in the backward gradient-based optimization. Furthermore, a novel\nfitness evaluation method is proposed to speed up the heuristic search with\nsubstantially less computational resource. The proposed algorithm is examined\nand compared with 22 existing algorithms on nine widely used image\nclassification tasks, including the state-of-the-art methods. The experimental\nresults demonstrate the remarkable superiority of the proposed algorithm over\nthe state-of-the-art algorithms in terms of classification error rate and the\nnumber of parameters (weights). \n\n"}
{"id": "1710.11004", "contents": "Title: Denoising random forests Abstract: This paper proposes a novel type of random forests called a denoising random\nforests that are robust against noises contained in test samples. Such\nnoise-corrupted samples cause serious damage to the estimation performances of\nrandom forests, since unexpected child nodes are often selected and the leaf\nnodes that the input sample reaches are sometimes far from those for a clean\nsample. Our main idea for tackling this problem originates from a binary\nindicator vector that encodes a traversal path of a sample in the forest. Our\nproposed method effectively employs this vector by introducing denoising\nautoencoders into random forests. A denoising autoencoder can be trained with\nindicator vectors produced from clean and noisy input samples, and non-leaf\nnodes where incorrect decisions are made can be identified by comparing the\ninput and output of the trained denoising autoencoder. Multiple traversal paths\nwith respect to the nodes with incorrect decisions caused by the noises can\nthen be considered for the estimation. \n\n"}
{"id": "1710.11342", "contents": "Title: Generating Natural Adversarial Examples Abstract: Due to their complex nature, it is hard to characterize the ways in which\nmachine learning models can misbehave or be exploited when deployed. Recent\nwork on adversarial examples, i.e. inputs with minor perturbations that result\nin substantially different model predictions, is helpful in evaluating the\nrobustness of these models by exposing the adversarial scenarios where they\nfail. However, these malicious perturbations are often unnatural, not\nsemantically meaningful, and not applicable to complicated domains such as\nlanguage. In this paper, we propose a framework to generate natural and legible\nadversarial examples that lie on the data manifold, by searching in semantic\nspace of dense and continuous data representation, utilizing the recent\nadvances in generative adversarial networks. We present generated adversaries\nto demonstrate the potential of the proposed approach for black-box classifiers\nfor a wide range of applications such as image classification, textual\nentailment, and machine translation. We include experiments to show that the\ngenerated adversaries are natural, legible to humans, and useful in evaluating\nand analyzing black-box classifiers. \n\n"}
{"id": "1710.11345", "contents": "Title: Tensor Regression Meets Gaussian Processes Abstract: Low-rank tensor regression, a new model class that learns high-order\ncorrelation from data, has recently received considerable attention. At the\nsame time, Gaussian processes (GP) are well-studied machine learning models for\nstructure learning. In this paper, we demonstrate interesting connections\nbetween the two, especially for multi-way data analysis. We show that low-rank\ntensor regression is essentially learning a multi-linear kernel in Gaussian\nprocesses, and the low-rank assumption translates to the constrained Bayesian\ninference problem. We prove the oracle inequality and derive the average case\nlearning curve for the equivalent GP model. Our finding implies that low-rank\ntensor regression, though empirically successful, is highly dependent on the\neigenvalues of covariance functions as well as variable correlations. \n\n"}
{"id": "1711.00117", "contents": "Title: Countering Adversarial Images using Input Transformations Abstract: This paper investigates strategies that defend against adversarial-example\nattacks on image-classification systems by transforming the inputs before\nfeeding them to the system. Specifically, we study applying image\ntransformations such as bit-depth reduction, JPEG compression, total variance\nminimization, and image quilting before feeding the image to a convolutional\nnetwork classifier. Our experiments on ImageNet show that total variance\nminimization and image quilting are very effective defenses in practice, in\nparticular, when the network is trained on transformed images. The strength of\nthose defenses lies in their non-differentiable nature and their inherent\nrandomness, which makes it difficult for an adversary to circumvent the\ndefenses. Our best defense eliminates 60% of strong gray-box and 90% of strong\nblack-box attacks by a variety of major attack methods \n\n"}
{"id": "1711.00248", "contents": "Title: Query-free Clothing Retrieval via Implicit Relevance Feedback Abstract: Image-based clothing retrieval is receiving increasing interest with the\ngrowth of online shopping. In practice, users may often have a desired piece of\nclothing in mind (e.g., either having seen it before on the street or requiring\ncertain specific clothing attributes) but may be unable to supply an image as a\nquery. We model this problem as a new type of image retrieval task in which the\ntarget image resides only in the user's mind (called \"mental image retrieval\"\nhereafter). Because of the absence of an explicit query image, we propose to\nsolve this problem through relevance feedback. Specifically, a new Bayesian\nformulation is proposed that simultaneously models the retrieval target and its\nhigh-level representation in the mind of the user (called the \"user metric\"\nhereafter) as posterior distributions of pre-fetched shop images and\nheterogeneous features extracted from multiple clothing attributes,\nrespectively. Requiring only clicks as user feedback, the proposed algorithm is\nable to account for the variability in human decision-making. Experiments with\nreal users demonstrate the effectiveness of the proposed algorithm. \n\n"}
{"id": "1711.00436", "contents": "Title: Hierarchical Representations for Efficient Architecture Search Abstract: We explore efficient neural architecture search methods and show that a\nsimple yet powerful evolutionary algorithm can discover new architectures with\nexcellent performance. Our approach combines a novel hierarchical genetic\nrepresentation scheme that imitates the modularized design pattern commonly\nadopted by human experts, and an expressive search space that supports complex\ntopologies. Our algorithm efficiently discovers architectures that outperform a\nlarge number of manually designed models for image classification, obtaining\ntop-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, which\nis competitive with the best existing neural architecture search approaches. We\nalso present results using random search, achieving 0.3% less top-1 accuracy on\nCIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36\nhours down to 1 hour. \n\n"}
{"id": "1711.00970", "contents": "Title: A Classification-Based Study of Covariate Shift in GAN Distributions Abstract: A basic, and still largely unanswered, question in the context of Generative\nAdversarial Networks (GANs) is whether they are truly able to capture all the\nfundamental characteristics of the distributions they are trained on. In\nparticular, evaluating the diversity of GAN distributions is challenging and\nexisting methods provide only a partial understanding of this issue. In this\npaper, we develop quantitative and scalable tools for assessing the diversity\nof GAN distributions. Specifically, we take a classification-based perspective\nand view loss of diversity as a form of covariate shift introduced by GANs. We\nexamine two specific forms of such shift: mode collapse and boundary\ndistortion. In contrast to prior work, our methods need only minimal human\nsupervision and can be readily applied to state-of-the-art GANs on large,\ncanonical datasets. Examining popular GANs using our tools indicates that these\nGANs have significant problems in reproducing the more distributional\nproperties of their training dataset. \n\n"}
{"id": "1711.01371", "contents": "Title: An Iterative Co-Saliency Framework for RGBD Images Abstract: As a newly emerging and significant topic in computer vision community,\nco-saliency detection aims at discovering the common salient objects in\nmultiple related images. The existing methods often generate the co-saliency\nmap through a direct forward pipeline which is based on the designed cues or\ninitialization, but lack the refinement-cycle scheme. Moreover, they mainly\nfocus on RGB image and ignore the depth information for RGBD images. In this\npaper, we propose an iterative RGBD co-saliency framework, which utilizes the\nexisting single saliency maps as the initialization, and generates the final\nRGBD cosaliency map by using a refinement-cycle model. Three schemes are\nemployed in the proposed RGBD co-saliency framework, which include the addition\nscheme, deletion scheme, and iteration scheme. The addition scheme is used to\nhighlight the salient regions based on intra-image depth propagation and\nsaliency propagation, while the deletion scheme filters the saliency regions\nand removes the non-common salient regions based on interimage constraint. The\niteration scheme is proposed to obtain more homogeneous and consistent\nco-saliency map. Furthermore, a novel descriptor, named depth shape prior, is\nproposed in the addition scheme to introduce the depth information to enhance\nidentification of co-salient objects. The proposed method can effectively\nexploit any existing 2D saliency model to work well in RGBD co-saliency\nscenarios. The experiments on two RGBD cosaliency datasets demonstrate the\neffectiveness of our proposed framework. \n\n"}
{"id": "1711.01431", "contents": "Title: The Case for Meta-Cognitive Machine Learning: On Model Entropy and\n  Concept Formation in Deep Learning Abstract: Machine learning is usually defined in behaviourist terms, where external\nvalidation is the primary mechanism of learning. In this paper, I argue for a\nmore holistic interpretation in which finding more probable, efficient and\nabstract representations is as central to learning as performance. In other\nwords, machine learning should be extended with strategies to reason over its\nown learning process, leading to so-called meta-cognitive machine learning. As\nsuch, the de facto definition of machine learning should be reformulated in\nthese intrinsically multi-objective terms, taking into account not only the\ntask performance but also internal learning objectives. To this end, we suggest\na \"model entropy function\" to be defined that quantifies the efficiency of the\ninternal learning processes. It is conjured that the minimization of this model\nentropy leads to concept formation. Besides philosophical aspects, some initial\nillustrations are included to support the claims. \n\n"}
{"id": "1711.01742", "contents": "Title: Model-free Nonconvex Matrix Completion: Local Minima Analysis and\n  Applications in Memory-efficient Kernel PCA Abstract: This work studies low-rank approximation of a positive semidefinite matrix\nfrom partial entries via nonconvex optimization. We characterized how well\nlocal-minimum based low-rank factorization approximates a fixed positive\nsemidefinite matrix without any assumptions on the rank-matching, the condition\nnumber or eigenspace incoherence parameter. Furthermore, under certain\nassumptions on rank-matching and well-boundedness of condition numbers and\neigenspace incoherence parameters, a corollary of our main theorem improves the\nstate-of-the-art sampling rate results for nonconvex matrix completion with no\nspurious local minima in Ge et al. [2016, 2017]. In addition, we investigated\nwhen the proposed nonconvex optimization results in accurate low-rank\napproximations even in presence of large condition numbers, large incoherence\nparameters, or rank mismatching. We also propose to apply the nonconvex\noptimization to memory-efficient Kernel PCA. Compared to the well-known\nNystr\\\"{o}m methods, numerical experiments indicate that the proposed nonconvex\noptimization approach yields more stable results in both low-rank approximation\nand clustering. \n\n"}
{"id": "1711.02131", "contents": "Title: Characterizing Sparse Connectivity Patterns in Neural Networks Abstract: We propose a novel way of reducing the number of parameters in the\nstorage-hungry fully connected layers of a neural network by using pre-defined\nsparsity, where the majority of connections are absent prior to starting\ntraining. Our results indicate that convolutional neural networks can operate\nwithout any loss of accuracy at less than half percent classification layer\nconnection density, or less than 5 percent overall network connection density.\nWe also investigate the effects of pre-defining the sparsity of networks with\nonly fully connected layers. Based on our sparsifying technique, we introduce\nthe `scatter' metric to characterize the quality of a particular connection\npattern. As proof of concept, we show results on CIFAR, MNIST and a new dataset\non classifying Morse code symbols, which highlights some interesting trends and\nlimits of sparse connection patterns. \n\n"}
{"id": "1711.02679", "contents": "Title: Neural Variational Inference and Learning in Undirected Graphical Models Abstract: Many problems in machine learning are naturally expressed in the language of\nundirected graphical models. Here, we propose black-box learning and inference\nalgorithms for undirected models that optimize a variational approximation to\nthe log-likelihood of the model. Central to our approach is an upper bound on\nthe log-partition function parametrized by a function q that we express as a\nflexible neural network. Our bound makes it possible to track the partition\nfunction during learning, to speed-up sampling, and to train a broad class of\nhybrid directed/undirected models via a unified variational inference\nframework. We empirically demonstrate the effectiveness of our method on\nseveral popular generative modeling datasets. \n\n"}
{"id": "1711.02741", "contents": "Title: Recurrent Autoregressive Networks for Online Multi-Object Tracking Abstract: The main challenge of online multi-object tracking is to reliably associate\nobject trajectories with detections in each video frame based on their tracking\nhistory. In this work, we propose the Recurrent Autoregressive Network (RAN), a\ntemporal generative modeling framework to characterize the appearance and\nmotion dynamics of multiple objects over time. The RAN couples an external\nmemory and an internal memory. The external memory explicitly stores previous\ninputs of each trajectory in a time window, while the internal memory learns to\nsummarize long-term tracking history and associate detections by processing the\nexternal memory. We conduct experiments on the MOT 2015 and 2016 datasets to\ndemonstrate the robustness of our tracking method in highly crowded and\noccluded scenes. Our method achieves top-ranked results on the two benchmarks. \n\n"}
{"id": "1711.03357", "contents": "Title: Compact Neural Networks based on the Multiscale Entanglement\n  Renormalization Ansatz Abstract: This paper demonstrates a method for tensorizing neural networks based upon\nan efficient way of approximating scale invariant quantum states, the\nMulti-scale Entanglement Renormalization Ansatz (MERA). We employ MERA as a\nreplacement for the fully connected layers in a convolutional neural network\nand test this implementation on the CIFAR-10 and CIFAR-100 datasets. The\nproposed method outperforms factorization using tensor trains, providing\ngreater compression for the same level of accuracy and greater accuracy for the\nsame level of compression. We demonstrate MERA layers with 14000 times fewer\nparameters and a reduction in accuracy of less than 1% compared to the\nequivalent fully connected layers, scaling like O(N). \n\n"}
{"id": "1711.03404", "contents": "Title: A random matrix analysis and improvement of semi-supervised learning for\n  large dimensional data Abstract: This article provides an original understanding of the behavior of a class of\ngraph-oriented semi-supervised learning algorithms in the limit of large and\nnumerous data. It is demonstrated that the intuition at the root of these\nmethods collapses in this limit and that, as a result, most of them become\ninconsistent. Corrective measures and a new data-driven parametrization scheme\nare proposed along with a theoretical analysis of the asymptotic performances\nof the resulting approach. A surprisingly close behavior between theoretical\nperformances on Gaussian mixture models and on real datasets is also\nillustrated throughout the article, thereby suggesting the importance of the\nproposed analysis for dealing with practical data. As a result, significant\nperformance gains are observed on practical data classification using the\nproposed parametrization. \n\n"}
{"id": "1711.03800", "contents": "Title: Object Referring in Visual Scene with Spoken Language Abstract: Object referring has important applications, especially for human-machine\ninteraction. While having received great attention, the task is mainly attacked\nwith written language (text) as input rather than spoken language (speech),\nwhich is more natural. This paper investigates Object Referring with Spoken\nLanguage (ORSpoken) by presenting two datasets and one novel approach. Objects\nare annotated with their locations in images, text descriptions and speech\ndescriptions. This makes the datasets ideal for multi-modality learning. The\napproach is developed by carefully taking down ORSpoken problem into three\nsub-problems and introducing task-specific vision-language interactions at the\ncorresponding levels. Experiments show that our method outperforms competing\nmethods consistently and significantly. The approach is also evaluated in the\npresence of audio noise, showing the efficacy of the proposed vision-language\ninteraction methods in counteracting background noise. \n\n"}
{"id": "1711.04323", "contents": "Title: High-Order Attention Models for Visual Question Answering Abstract: The quest for algorithms that enable cognitive abilities is an important part\nof machine learning. A common trait in many recently investigated\ncognitive-like tasks is that they take into account different data modalities,\nsuch as visual and textual input. In this paper we propose a novel and\ngenerally applicable form of attention mechanism that learns high-order\ncorrelations between various data modalities. We show that high-order\ncorrelations effectively direct the appropriate attention to the relevant\nelements in the different data modalities that are required to solve the joint\ntask. We demonstrate the effectiveness of our high-order attention mechanism on\nthe task of visual question answering (VQA), where we achieve state-of-the-art\nperformance on the standard VQA dataset. \n\n"}
{"id": "1711.04366", "contents": "Title: A unified framework for hard and soft clustering with regularized\n  optimal transport Abstract: In this paper, we formulate the problem of inferring a Finite Mixture Model\nfrom discrete data as an optimal transport problem with entropic regularization\nof parameter $\\lambda\\geq 0$. Our method unifies hard and soft clustering, the\nExpectation-Maximization (EM) algorithm being exactly recovered for\n$\\lambda=1$. The family of clustering algorithm we propose rely on the\nresolution of nonconvex problems using alternating minimization. We study the\nconvergence property of our generalized $\\lambda-$EM algorithms and show that\neach step in the minimization process has a closed form solution when inferring\nfinite mixture models of exponential families. Experiments highlight the\nbenefits of taking a parameter $\\lambda>1$ to improve the inference performance\nand $\\lambda\\to 0$ for classification. \n\n"}
{"id": "1711.05866", "contents": "Title: Fast and Efficient Calculations of Structural Invariants of Chirality Abstract: Chirality plays an important role in physics, chemistry, biology, and other\nfields. It describes an essential symmetry in structure. However, chirality\ninvariants are usually complicated in expression or difficult to evaluate. In\nthis paper, we present five general three-dimensional chirality invariants\nbased on the generating functions. And the five chiral invariants have four\ncharacteristics:(1) They play an important role in the detection of symmetry,\nespecially in the treatment of 'false zero' problem. (2) Three of the five\nchiral invariants decode an universal chirality index. (3) Three of them are\nproposed for the first time. (4) The five chiral invariants have low order no\nbigger than 4, brief expression, low time complexity O(n) and can act as\ndescriptors of three-dimensional objects in shape analysis. The five chiral\ninvariants give a geometric view to study the chiral invariants. And the\nexperiments show that the five chirality invariants are effective and\nefficient, they can be used as a tool for symmetry detection or features in\nshape analysis. \n\n"}
{"id": "1711.05998", "contents": "Title: Minimizing Supervision for Free-space Segmentation Abstract: Identifying \"free-space,\" or safely driveable regions in the scene ahead, is\na fundamental task for autonomous navigation. While this task can be addressed\nusing semantic segmentation, the manual labor involved in creating pixelwise\nannotations to train the segmentation model is very costly. Although weakly\nsupervised segmentation addresses this issue, most methods are not designed for\nfree-space. In this paper, we observe that homogeneous texture and location are\ntwo key characteristics of free-space, and develop a novel, practical framework\nfor free-space segmentation with minimal human supervision. Our experiments\nshow that our framework performs better than other weakly supervised methods\nwhile using less supervision. Our work demonstrates the potential for\nperforming free-space segmentation without tedious and costly manual\nannotation, which will be important for adapting autonomous driving systems to\ndifferent types of vehicles and environments \n\n"}
{"id": "1711.07399", "contents": "Title: V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and\n  Human Pose Estimation from a Single Depth Map Abstract: Most of the existing deep learning-based methods for 3D hand and human pose\nestimation from a single depth map are based on a common framework that takes a\n2D depth map and directly regresses the 3D coordinates of keypoints, such as\nhand or human body joints, via 2D convolutional neural networks (CNNs). The\nfirst weakness of this approach is the presence of perspective distortion in\nthe 2D depth map. While the depth map is intrinsically 3D data, many previous\nmethods treat depth maps as 2D images that can distort the shape of the actual\nobject through projection from 3D to 2D space. This compels the network to\nperform perspective distortion-invariant estimation. The second weakness of the\nconventional approach is that directly regressing 3D coordinates from a 2D\nimage is a highly non-linear mapping, which causes difficulty in the learning\nprocedure. To overcome these weaknesses, we firstly cast the 3D hand and human\npose estimation problem from a single depth map into a voxel-to-voxel\nprediction that uses a 3D voxelized grid and estimates the per-voxel likelihood\nfor each keypoint. We design our model as a 3D CNN that provides accurate\nestimates while running in real-time. Our system outperforms previous methods\nin almost all publicly available 3D hand and human pose estimation datasets and\nplaced first in the HANDS 2017 frame-based 3D hand pose estimation challenge.\nThe code is available in https://github.com/mks0601/V2V-PoseNet_RELEASE. \n\n"}
{"id": "1711.07459", "contents": "Title: SquishedNets: Squishing SqueezeNet further for edge device scenarios via\n  deep evolutionary synthesis Abstract: While deep neural networks have been shown in recent years to outperform\nother machine learning methods in a wide range of applications, one of the\nbiggest challenges with enabling deep neural networks for widespread deployment\non edge devices such as mobile and other consumer devices is high computational\nand memory requirements. Recently, there has been greater exploration into\nsmall deep neural network architectures that are more suitable for edge\ndevices, with one of the most popular architectures being SqueezeNet, with an\nincredibly small model size of 4.8MB. Taking further advantage of the notion\nthat many applications of machine learning on edge devices are often\ncharacterized by a low number of target classes, this study explores the\nutility of combining architectural modifications and an evolutionary synthesis\nstrategy for synthesizing even smaller deep neural architectures based on the\nmore recent SqueezeNet v1.1 macroarchitecture for applications with fewer\ntarget classes. In particular, architectural modifications are first made to\nSqueezeNet v1.1 to accommodate for a 10-class ImageNet-10 dataset, and then an\nevolutionary synthesis strategy is leveraged to synthesize more efficient deep\nneural networks based on this modified macroarchitecture. The resulting\nSquishedNets possess model sizes ranging from 2.4MB to 0.95MB (~5.17X smaller\nthan SqueezeNet v1.1, or 253X smaller than AlexNet). Furthermore, the\nSquishedNets are still able to achieve accuracies ranging from 81.2% to 77%,\nand able to process at speeds of 156 images/sec to as much as 256 images/sec on\na Nvidia Jetson TX1 embedded chip. These preliminary results show that a\ncombination of architectural modifications and an evolutionary synthesis\nstrategy can be a useful tool for producing very small deep neural network\narchitectures that are well-suited for edge device scenarios. \n\n"}
{"id": "1711.07513", "contents": "Title: Self-Similarity Based Time Warping Abstract: In this work, we explore the problem of aligning two time-ordered point\nclouds which are spatially transformed and re-parameterized versions of each\nother. This has a diverse array of applications such as cross modal time series\nsynchronization (e.g. MOCAP to video) and alignment of discretized curves in\nimages. Most other works that address this problem attempt to jointly uncover a\nspatial alignment and correspondences between the two point clouds, or to\nderive local invariants to spatial transformations such as curvature before\ncomputing correspondences. By contrast, we sidestep spatial alignment\ncompletely by using self-similarity matrices (SSMs) as a proxy to the\ntime-ordered point clouds, since self-similarity matrices are blind to\nisometries and respect global geometry. Our algorithm, dubbed \"Isometry Blind\nDynamic Time Warping\" (IBDTW), is simple and general, and we show that its\nassociated dissimilarity measure lower bounds the L1 Gromov-Hausdorff distance\nbetween the two point sets when restricted to warping paths. We also present a\nlocal, partial alignment extension of IBDTW based on the Smith Waterman\nalgorithm. This eliminates the need for tedious manual cropping of time series,\nwhich is ordinarily necessary for global alignment algorithms to function\nproperly. \n\n"}
{"id": "1711.08598", "contents": "Title: An Improved Training Procedure for Neural Autoregressive Data Completion Abstract: Neural autoregressive models are explicit density estimators that achieve\nstate-of-the-art likelihoods for generative modeling. The D-dimensional data\ndistribution is factorized into an autoregressive product of one-dimensional\nconditional distributions according to the chain rule. Data completion is a\nmore involved task than data generation: the model must infer missing variables\nfor any partially observed input vector. Previous work introduced an\norder-agnostic training procedure for data completion with autoregressive\nmodels. Missing variables in any partially observed input vector can be imputed\nefficiently by choosing an ordering where observed dimensions precede\nunobserved ones and by computing the autoregressive product in this order. In\nthis paper, we provide evidence that the order-agnostic (OA) training procedure\nis suboptimal for data completion. We propose an alternative procedure (OA++)\nthat reaches better performance in fewer computations. It can handle all data\ncompletion queries while training fewer one-dimensional conditional\ndistributions than the OA procedure. In addition, these one-dimensional\nconditional distributions are trained proportionally to their expected usage at\ninference time, reducing overfitting. Finally, our OA++ procedure can exploit\nprior knowledge about the distribution of inference completion queries, as\nopposed to OA. We support these claims with quantitative experiments on\nstandard datasets used to evaluate autoregressive generative models. \n\n"}
{"id": "1711.08681", "contents": "Title: Beyond RGB: Very High Resolution Urban Remote Sensing With Multimodal\n  Deep Networks Abstract: In this work, we investigate various methods to deal with semantic labeling\nof very high resolution multi-modal remote sensing data. Especially, we study\nhow deep fully convolutional networks can be adapted to deal with multi-modal\nand multi-scale remote sensing data for semantic labeling. Our contributions\nare threefold: a) we present an efficient multi-scale approach to leverage both\na large spatial context and the high resolution data, b) we investigate early\nand late fusion of Lidar and multispectral data, c) we validate our methods on\ntwo public datasets with state-of-the-art results. Our results indicate that\nlate fusion make it possible to recover errors steaming from ambiguous data,\nwhile early fusion allows for better joint-feature learning but at the cost of\nhigher sensitivity to missing data. \n\n"}
{"id": "1711.08904", "contents": "Title: Adversarial Transfer Learning for Cross-domain Visual Recognition Abstract: In many practical visual recognition scenarios, feature distribution in the\nsource domain is generally different from that of the target domain, which\nresults in the emergence of general cross-domain visual recognition problems.\nTo address the problems of visual domain mismatch, we propose a novel\nsemi-supervised adversarial transfer learning approach, which is called Coupled\nadversarial transfer Domain Adaptation (CatDA), for distribution alignment\nbetween two domains. The proposed CatDA approach is inspired by cycleGAN, but\nleveraging multiple shallow multilayer perceptrons (MLPs) instead of deep\nnetworks. Specifically, our CatDA comprises of two symmetric and slim\nsub-networks, such that the coupled adversarial learning framework is\nformulated. With such symmetry of two generators, the input data from\nsource/target domain can be fed into the MLP network for target/source domain\ngeneration, supervised by two confrontation oriented coupled discriminators.\nNotably, in order to avoid the critical flaw of high-capacity of the feature\nextraction function during domain adversarial training, domain specific loss\nand domain knowledge fidelity loss are proposed in each generator, such that\nthe effectiveness of the proposed transfer network is guaranteed. Additionally,\nthe essential difference from cycleGAN is that our method aims to generate\ndomain-agnostic and aligned features for domain adaptation and transfer\nlearning rather than synthesize realistic images. We show experimentally on a\nnumber of benchmark datasets and the proposed approach achieves competitive\nperformance over state-of-the-art domain adaptation and transfer learning\napproaches. \n\n"}
{"id": "1711.08922", "contents": "Title: Summarizing First-Person Videos from Third Persons' Points of Views Abstract: Video highlight or summarization is among interesting topics in computer\nvision, which benefits a variety of applications like viewing, searching, or\nstorage. However, most existing studies rely on training data of third-person\nvideos, which cannot easily generalize to highlight the first-person ones. With\nthe goal of deriving an effective model to summarize first-person videos, we\npropose a novel deep neural network architecture for describing and\ndiscriminating vital spatiotemporal information across videos with different\npoints of view. Our proposed model is realized in a semi-supervised setting, in\nwhich fully annotated third-person videos, unlabeled first-person videos, and a\nsmall number of annotated first-person ones are presented during training. In\nour experiments, qualitative and quantitative evaluations on both benchmarks\nand our collected first-person video datasets are presented. \n\n"}
{"id": "1711.09726", "contents": "Title: Exploiting the potential of unlabeled endoscopic video data with\n  self-supervised learning Abstract: Surgical data science is a new research field that aims to observe all\naspects of the patient treatment process in order to provide the right\nassistance at the right time. Due to the breakthrough successes of deep\nlearning-based solutions for automatic image annotation, the availability of\nreference annotations for algorithm training is becoming a major bottleneck in\nthe field. The purpose of this paper was to investigate the concept of\nself-supervised learning to address this issue.\n  Our approach is guided by the hypothesis that unlabeled video data can be\nused to learn a representation of the target domain that boosts the performance\nof state-of-the-art machine learning algorithms when used for pre-training.\nCore of the method is an auxiliary task based on raw endoscopic video data of\nthe target domain that is used to initialize the convolutional neural network\n(CNN) for the target task. In this paper, we propose the re-colorization of\nmedical images with a generative adversarial network (GAN)-based architecture\nas auxiliary task. A variant of the method involves a second pre-training step\nbased on labeled data for the target task from a related domain. We validate\nboth variants using medical instrument segmentation as target task.\n  The proposed approach can be used to radically reduce the manual annotation\neffort involved in training CNNs. Compared to the baseline approach of\ngenerating annotated data from scratch, our method decreases exploratively the\nnumber of labeled images by up to 75% without sacrificing performance. Our\nmethod also outperforms alternative methods for CNN pre-training, such as\npre-training on publicly available non-medical or medical data using the target\ntask (in this instance: segmentation).\n  As it makes efficient use of available (non-)public and (un-)labeled data,\nthe approach has the potential to become a valuable tool for CNN\n(pre-)training. \n\n"}
{"id": "1711.10143", "contents": "Title: Revisiting hand-crafted feature for action recognition: a set of\n  improved dense trajectories Abstract: We propose a feature for action recognition called Trajectory-Set (TS), on\ntop of the improved Dense Trajectory (iDT). The TS feature encodes only\ntrajectories around densely sampled interest points, without any appearance\nfeatures. Experimental results on the UCF50, UCF101, and HMDB51 action datasets\ndemonstrate that TS is comparable to state-of-the-arts, and outperforms many\nother methods; for HMDB the accuracy of 85.4%, compared to the best accuracy of\n80.2% obtained by a deep method. Our code is available on-line at\nhttps://github.com/Gauffret/TrajectorySet . \n\n"}
{"id": "1711.10157", "contents": "Title: Deformation estimation of an elastic object by partial observation using\n  a neural network Abstract: Deformation estimation of elastic object assuming an internal organ is\nimportant for the computer navigation of surgery. The aim of this study is to\nestimate the deformation of an entire three-dimensional elastic object using\ndisplacement information of very few observation points. A learning approach\nwith a neural network was introduced to estimate the entire deformation of an\nobject. We applied our method to two elastic objects; a rectangular\nparallelepiped model, and a human liver model reconstructed from computed\ntomography data. The average estimation error for the human liver model was\n0.041 mm when the object was deformed up to 66.4 mm, from only around 3 %\nobservations. These results indicate that the deformation of an entire elastic\nobject can be estimated with an acceptable level of error from limited\nobservations by applying a trained neural network to a new deformation. \n\n"}
{"id": "1711.10761", "contents": "Title: Transfer Learning with Binary Neural Networks Abstract: Previous work has shown that it is possible to train deep neural networks\nwith low precision weights and activations. In the extreme case it is even\npossible to constrain the network to binary values. The costly floating point\nmultiplications are then reduced to fast logical operations. High end smart\nphones such as Google's Pixel 2 and Apple's iPhone X are already equipped with\nspecialised hardware for image processing and it is very likely that other\nfuture consumer hardware will also have dedicated accelerators for deep neural\nnetworks. Binary neural networks are attractive in this case because the\nlogical operations are very fast and efficient when implemented in hardware. We\npropose a transfer learning based architecture where we first train a binary\nnetwork on Imagenet and then retrain part of the network for different tasks\nwhile keeping most of the network fixed. The fixed binary part could be\nimplemented in a hardware accelerator while the last layers of the network are\nevaluated in software. We show that a single binary neural network trained on\nthe Imagenet dataset can indeed be used as a feature extractor for other\ndatasets. \n\n"}
{"id": "1711.11135", "contents": "Title: Video Captioning via Hierarchical Reinforcement Learning Abstract: Video captioning is the task of automatically generating a textual\ndescription of the actions in a video. Although previous work (e.g.\nsequence-to-sequence model) has shown promising results in abstracting a coarse\ndescription of a short video, it is still very challenging to caption a video\ncontaining multiple fine-grained actions with a detailed description. This\npaper aims to address the challenge by proposing a novel hierarchical\nreinforcement learning framework for video captioning, where a high-level\nManager module learns to design sub-goals and a low-level Worker module\nrecognizes the primitive actions to fulfill the sub-goal. With this\ncompositional framework to reinforce video captioning at different levels, our\napproach significantly outperforms all the baseline methods on a newly\nintroduced large-scale dataset for fine-grained video captioning. Furthermore,\nour non-ensemble model has already achieved the state-of-the-art results on the\nwidely-used MSR-VTT dataset. \n\n"}
{"id": "1711.11248", "contents": "Title: A Closer Look at Spatiotemporal Convolutions for Action Recognition Abstract: In this paper we discuss several forms of spatiotemporal convolutions for\nvideo analysis and study their effects on action recognition. Our motivation\nstems from the observation that 2D CNNs applied to individual frames of the\nvideo have remained solid performers in action recognition. In this work we\nempirically demonstrate the accuracy advantages of 3D CNNs over 2D CNNs within\nthe framework of residual learning. Furthermore, we show that factorizing the\n3D convolutional filters into separate spatial and temporal components yields\nsignificantly advantages in accuracy. Our empirical study leads to the design\nof a new spatiotemporal convolutional block \"R(2+1)D\" which gives rise to CNNs\nthat achieve results comparable or superior to the state-of-the-art on\nSports-1M, Kinetics, UCF101 and HMDB51. \n\n"}
{"id": "1712.00559", "contents": "Title: Progressive Neural Architecture Search Abstract: We propose a new method for learning the structure of convolutional neural\nnetworks (CNNs) that is more efficient than recent state-of-the-art methods\nbased on reinforcement learning and evolutionary algorithms. Our approach uses\na sequential model-based optimization (SMBO) strategy, in which we search for\nstructures in order of increasing complexity, while simultaneously learning a\nsurrogate model to guide the search through structure space. Direct comparison\nunder the same search space shows that our method is up to 5 times more\nefficient than the RL method of Zoph et al. (2018) in terms of number of models\nevaluated, and 8 times faster in terms of total compute. The structures we\ndiscover in this way achieve state of the art classification accuracies on\nCIFAR-10 and ImageNet. \n\n"}
{"id": "1712.00714", "contents": "Title: Spatial PixelCNN: Generating Images from Patches Abstract: In this paper we propose Spatial PixelCNN, a conditional autoregressive model\nthat generates images from small patches. By conditioning on a grid of pixel\ncoordinates and global features extracted from a Variational Autoencoder (VAE),\nwe are able to train on patches of images, and reproduce the full-sized image.\nWe show that it not only allows for generating high quality samples at the same\nresolution as the underlying dataset, but is also capable of upscaling images\nto arbitrary resolutions (tested at resolutions up to $50\\times$) on the MNIST\ndataset. Compared to a PixelCNN++ baseline, Spatial PixelCNN quantitatively and\nqualitatively achieves similar performance on the MNIST dataset. \n\n"}
{"id": "1712.00733", "contents": "Title: Incorporating External Knowledge to Answer Open-Domain Visual Questions\n  with Dynamic Memory Networks Abstract: Visual Question Answering (VQA) has attracted much attention since it offers\ninsight into the relationships between the multi-modal analysis of images and\nnatural language. Most of the current algorithms are incapable of answering\nopen-domain questions that require to perform reasoning beyond the image\ncontents. To address this issue, we propose a novel framework which endows the\nmodel capabilities in answering more complex questions by leveraging massive\nexternal knowledge with dynamic memory networks. Specifically, the questions\nalong with the corresponding images trigger a process to retrieve the relevant\ninformation in external knowledge bases, which are embedded into a continuous\nvector space by preserving the entity-relation structures. Afterwards, we\nemploy dynamic memory networks to attend to the large body of facts in the\nknowledge graph and images, and then perform reasoning over these facts to\ngenerate corresponding answers. Extensive experiments demonstrate that our\nmodel not only achieves the state-of-the-art performance in the visual question\nanswering task, but can also answer open-domain questions effectively by\nleveraging the external knowledge. \n\n"}
{"id": "1712.01361", "contents": "Title: A+D Net: Training a Shadow Detector with Adversarial Shadow Attenuation Abstract: We propose a novel GAN-based framework for detecting shadows in images, in\nwhich a shadow detection network (D-Net) is trained together with a shadow\nattenuation network (A-Net) that generates adversarial training examples. The\nA-Net modifies the original training images constrained by a simplified\nphysical shadow model and is focused on fooling the D-Net's shadow predictions.\nHence, it is effectively augmenting the training data for D-Net with\nhard-to-predict cases. The D-Net is trained to predict shadows in both original\nimages and generated images from the A-Net. Our experimental results show that\nthe additional training data from A-Net significantly improves the shadow\ndetection accuracy of D-Net. Our method outperforms the state-of-the-art\nmethods on the most challenging shadow detection benchmark (SBU) and also\nobtains state-of-the-art results on a cross-dataset task, testing on UCF.\nFurthermore, the proposed method achieves accurate real-time shadow detection\nat 45 frames per second. \n\n"}
{"id": "1712.01432", "contents": "Title: AI Oriented Large-Scale Video Management for Smart City: Technologies,\n  Standards and Beyond Abstract: Deep learning has achieved substantial success in a series of tasks in\ncomputer vision. Intelligent video analysis, which can be broadly applied to\nvideo surveillance in various smart city applications, can also be driven by\nsuch powerful deep learning engines. To practically facilitate deep neural\nnetwork models in the large-scale video analysis, there are still unprecedented\nchallenges for the large-scale video data management. Deep feature coding,\ninstead of video coding, provides a practical solution for handling the\nlarge-scale video surveillance data. To enable interoperability in the context\nof deep feature coding, standardization is urgent and important. However, due\nto the explosion of deep learning algorithms and the particularity of feature\ncoding, there are numerous remaining problems in the standardization process.\nThis paper envisions the future deep feature coding standard for the AI\noriented large-scale video management, and discusses existing techniques,\nstandards and possible solutions for these open problems. \n\n"}
{"id": "1712.01785", "contents": "Title: Towards Practical Verification of Machine Learning: The Case of Computer\n  Vision Systems Abstract: Due to the increasing usage of machine learning (ML) techniques in security-\nand safety-critical domains, such as autonomous systems and medical diagnosis,\nensuring correct behavior of ML systems, especially for different corner cases,\nis of growing importance. In this paper, we propose a generic framework for\nevaluating security and robustness of ML systems using different real-world\nsafety properties. We further design, implement and evaluate VeriVis, a\nscalable methodology that can verify a diverse set of safety properties for\nstate-of-the-art computer vision systems with only blackbox access. VeriVis\nleverage different input space reduction techniques for efficient verification\nof different safety properties. VeriVis is able to find thousands of safety\nviolations in fifteen state-of-the-art computer vision systems including ten\nDeep Neural Networks (DNNs) such as Inception-v3 and Nvidia's Dave self-driving\nsystem with thousands of neurons as well as five commercial third-party vision\nAPIs including Google vision and Clarifai for twelve different safety\nproperties. Furthermore, VeriVis can successfully verify local safety\nproperties, on average, for around 31.7% of the test images. VeriVis finds up\nto 64.8x more violations than existing gradient-based methods that, unlike\nVeriVis, cannot ensure non-existence of any violations. Finally, we show that\nretraining using the safety violations detected by VeriVis can reduce the\naverage number of violations up to 60.2%. \n\n"}
{"id": "1712.02502", "contents": "Title: Take it in your stride: Do we need striding in CNNs? Abstract: Since their inception, CNNs have utilized some type of striding operator to\nreduce the overlap of receptive fields and spatial dimensions. Although having\nclear heuristic motivations (i.e. lowering the number of parameters to learn)\nthe mathematical role of striding within CNN learning remains unclear. This\npaper offers a novel and mathematical rigorous perspective on the role of the\nstriding operator within modern CNNs. Specifically, we demonstrate\ntheoretically that one can always represent a CNN that incorporates striding\nwith an equivalent non-striding CNN which has more filters and smaller size.\nThrough this equivalence we are then able to characterize striding as an\nadditional mechanism for parameter sharing among channels, thus reducing\ntraining complexity. Finally, the framework presented in this paper offers a\nnew mathematical perspective on the role of striding which we hope shall\nfacilitate and simplify the future theoretical analysis of CNNs. \n\n"}
{"id": "1712.02679", "contents": "Title: AdaComp : Adaptive Residual Gradient Compression for Data-Parallel\n  Distributed Training Abstract: Highly distributed training of Deep Neural Networks (DNNs) on future compute\nplatforms (offering 100 of TeraOps/s of computational capacity) is expected to\nbe severely communication constrained. To overcome this limitation, new\ngradient compression techniques are needed that are computationally friendly,\napplicable to a wide variety of layers seen in Deep Neural Networks and\nadaptable to variations in network architectures as well as their\nhyper-parameters. In this paper we introduce a novel technique - the Adaptive\nResidual Gradient Compression (AdaComp) scheme. AdaComp is based on localized\nselection of gradient residues and automatically tunes the compression rate\ndepending on local activity. We show excellent results on a wide spectrum of\nstate of the art Deep Learning models in multiple domains (vision, speech,\nlanguage), datasets (MNIST, CIFAR10, ImageNet, BN50, Shakespeare), optimizers\n(SGD with momentum, Adam) and network parameters (number of learners,\nminibatch-size etc.). Exploiting both sparsity and quantization, we demonstrate\nend-to-end compression rates of ~200X for fully-connected and recurrent layers,\nand ~40X for convolutional layers, without any noticeable degradation in model\naccuracies. \n\n"}
{"id": "1712.02779", "contents": "Title: Exploring the Landscape of Spatial Robustness Abstract: The study of adversarial robustness has so far largely focused on\nperturbations bound in p-norms. However, state-of-the-art models turn out to be\nalso vulnerable to other, more natural classes of perturbations such as\ntranslations and rotations. In this work, we thoroughly investigate the\nvulnerability of neural network--based classifiers to rotations and\ntranslations. While data augmentation offers relatively small robustness, we\nuse ideas from robust optimization and test-time input aggregation to\nsignificantly improve robustness. Finally we find that, in contrast to the\np-norm case, first-order methods cannot reliably find worst-case perturbations.\nThis highlights spatial robustness as a fundamentally different setting\nrequiring additional study. Code available at\nhttps://github.com/MadryLab/adversarial_spatial and\nhttps://github.com/MadryLab/spatial-pytorch. \n\n"}
{"id": "1712.02781", "contents": "Title: On Usage of Autoencoders and Siamese Networks for Online Handwritten\n  Signature Verification Abstract: In this paper, we propose a novel writer-independent global feature\nextraction framework for the task of automatic signature verification which\naims to make robust systems for automatically distinguishing negative and\npositive samples. Our method consists of an autoencoder for modeling the sample\nspace into a fixed length latent space and a Siamese Network for classifying\nthe fixed-length samples obtained from the autoencoder based on the reference\nsamples of a subject as being \"Genuine\" or \"Forged.\" During our experiments,\nusage of Attention Mechanism and applying Downsampling significantly improved\nthe accuracy of the proposed framework. We evaluated our proposed framework\nusing SigWiComp2013 Japanese and GPDSsyntheticOnLineOffLineSignature datasets.\nOn the SigWiComp2013 Japanese dataset, we achieved 8.65% EER that means 1.2%\nrelative improvement compared to the best-reported result. Furthermore, on the\nGPDSsyntheticOnLineOffLineSignature dataset, we achieved average EERs of 0.13%,\n0.12%, 0.21% and 0.25% respectively for 150, 300, 1000 and 2000 test subjects\nwhich indicates improvement of relative EER on the best-reported result by\n95.67%, 95.26%, 92.9% and 91.52% respectively. Apart from the accuracy gain,\nbecause of the nature of our proposed framework which is based on neural\nnetworks and consequently is as simple as some consecutive matrix\nmultiplications, it has less computational cost than conventional methods such\nas DTW and could be used concurrently on devices such as GPU, TPU, etc. \n\n"}
{"id": "1712.03337", "contents": "Title: Bayesian Joint Matrix Decomposition for Data Integration with\n  Heterogeneous Noise Abstract: Matrix decomposition is a popular and fundamental approach in machine\nlearning and data mining. It has been successfully applied into various fields.\nMost matrix decomposition methods focus on decomposing a data matrix from one\nsingle source. However, it is common that data are from different sources with\nheterogeneous noise. A few of matrix decomposition methods have been extended\nfor such multi-view data integration and pattern discovery. While only few\nmethods were designed to consider the heterogeneity of noise in such multi-view\ndata for data integration explicitly. To this end, we propose a joint matrix\ndecomposition framework (BJMD), which models the heterogeneity of noise by\nGaussian distribution in a Bayesian framework. We develop two algorithms to\nsolve this model: one is a variational Bayesian inference algorithm, which\nmakes full use of the posterior distribution; and another is a maximum a\nposterior algorithm, which is more scalable and can be easily paralleled.\nExtensive experiments on synthetic and real-world datasets demonstrate that\nBJMD considering the heterogeneity of noise is superior or competitive to the\nstate-of-the-art methods. \n\n"}
{"id": "1712.03351", "contents": "Title: Peephole: Predicting Network Performance Before Training Abstract: The quest for performant networks has been a significant force that drives\nthe advancements of deep learning in recent years. While rewarding, improving\nnetwork design has never been an easy journey. The large design space combined\nwith the tremendous cost required for network training poses a major obstacle\nto this endeavor. In this work, we propose a new approach to this problem,\nnamely, predicting the performance of a network before training, based on its\narchitecture. Specifically, we develop a unified way to encode individual\nlayers into vectors and bring them together to form an integrated description\nvia LSTM. Taking advantage of the recurrent network's strong expressive power,\nthis method can reliably predict the performances of various network\narchitectures. Our empirical studies showed that it not only achieved accurate\npredictions but also produced consistent rankings across datasets -- a key\ndesideratum in performance prediction. \n\n"}
{"id": "1712.03541", "contents": "Title: An Architecture Combining Convolutional Neural Network (CNN) and Support\n  Vector Machine (SVM) for Image Classification Abstract: Convolutional neural networks (CNNs) are similar to \"ordinary\" neural\nnetworks in the sense that they are made up of hidden layers consisting of\nneurons with \"learnable\" parameters. These neurons receive inputs, performs a\ndot product, and then follows it with a non-linearity. The whole network\nexpresses the mapping between raw image pixels and their class scores.\nConventionally, the Softmax function is the classifier used at the last layer\nof this network. However, there have been studies (Alalshekmubarak and Smith,\n2013; Agarap, 2017; Tang, 2013) conducted to challenge this norm. The cited\nstudies introduce the usage of linear support vector machine (SVM) in an\nartificial neural network architecture. This project is yet another take on the\nsubject, and is inspired by (Tang, 2013). Empirical data has shown that the\nCNN-SVM model was able to achieve a test accuracy of ~99.04% using the MNIST\ndataset (LeCun, Cortes, and Burges, 2010). On the other hand, the CNN-Softmax\nwas able to achieve a test accuracy of ~99.23% using the same dataset. Both\nmodels were also tested on the recently-published Fashion-MNIST dataset (Xiao,\nRasul, and Vollgraf, 2017), which is suppose to be a more difficult image\nclassification dataset than MNIST (Zalandoresearch, 2017). This proved to be\nthe case as CNN-SVM reached a test accuracy of ~90.72%, while the CNN-Softmax\nreached a test accuracy of ~91.86%. The said results may be improved if data\npreprocessing techniques were employed on the datasets, and if the base CNN\nmodel was a relatively more sophisticated than the one used in this study. \n\n"}
{"id": "1712.04109", "contents": "Title: Im2Flow: Motion Hallucination from Static Images for Action Recognition Abstract: Existing methods to recognize actions in static images take the images at\ntheir face value, learning the appearances---objects, scenes, and body\nposes---that distinguish each action class. However, such models are deprived\nof the rich dynamic structure and motions that also define human activity. We\npropose an approach that hallucinates the unobserved future motion implied by a\nsingle snapshot to help static-image action recognition. The key idea is to\nlearn a prior over short-term dynamics from thousands of unlabeled videos,\ninfer the anticipated optical flow on novel static images, and then train\ndiscriminative models that exploit both streams of information. Our main\ncontributions are twofold. First, we devise an encoder-decoder convolutional\nneural network and a novel optical flow encoding that can translate a static\nimage into an accurate flow map. Second, we show the power of hallucinated flow\nfor recognition, successfully transferring the learned motion into a standard\ntwo-stream network for activity recognition. On seven datasets, we demonstrate\nthe power of the approach. It not only achieves state-of-the-art accuracy for\ndense optical flow prediction, but also consistently enhances recognition of\nactions and dynamic scenes. \n\n"}
{"id": "1712.04604", "contents": "Title: Deep Quaternion Networks Abstract: The field of deep learning has seen significant advancement in recent years.\nHowever, much of the existing work has been focused on real-valued numbers.\nRecent work has shown that a deep learning system using the complex numbers can\nbe deeper for a fixed parameter budget compared to its real-valued counterpart.\nIn this work, we explore the benefits of generalizing one step further into the\nhyper-complex numbers, quaternions specifically, and provide the architecture\ncomponents needed to build deep quaternion networks. We develop the theoretical\nbasis by reviewing quaternion convolutions, developing a novel quaternion\nweight initialization scheme, and developing novel algorithms for quaternion\nbatch-normalization. These pieces are tested in a classification model by\nend-to-end training on the CIFAR-10 and CIFAR-100 data sets and a segmentation\nmodel by end-to-end training on the KITTI Road Segmentation data set. These\nquaternion networks show improved convergence compared to real-valued and\ncomplex-valued networks, especially on the segmentation task, while having\nfewer parameters \n\n"}
{"id": "1712.05877", "contents": "Title: Quantization and Training of Neural Networks for Efficient\n  Integer-Arithmetic-Only Inference Abstract: The rising popularity of intelligent mobile devices and the daunting\ncomputational cost of deep learning-based models call for efficient and\naccurate on-device inference schemes. We propose a quantization scheme that\nallows inference to be carried out using integer-only arithmetic, which can be\nimplemented more efficiently than floating point inference on commonly\navailable integer-only hardware. We also co-design a training procedure to\npreserve end-to-end model accuracy post quantization. As a result, the proposed\nquantization scheme improves the tradeoff between accuracy and on-device\nlatency. The improvements are significant even on MobileNets, a model family\nknown for run-time efficiency, and are demonstrated in ImageNet classification\nand COCO detection on popular CPUs. \n\n"}
{"id": "1712.08642", "contents": "Title: Least-Squares Temporal Difference Learning for the Linear Quadratic\n  Regulator Abstract: Reinforcement learning (RL) has been successfully used to solve many\ncontinuous control tasks. Despite its impressive results however, fundamental\nquestions regarding the sample complexity of RL on continuous problems remain\nopen. We study the performance of RL in this setting by considering the\nbehavior of the Least-Squares Temporal Difference (LSTD) estimator on the\nclassic Linear Quadratic Regulator (LQR) problem from optimal control. We give\nthe first finite-time analysis of the number of samples needed to estimate the\nvalue function for a fixed static state-feedback policy to within\n$\\varepsilon$-relative error. In the process of deriving our result, we give a\ngeneral characterization for when the minimum eigenvalue of the empirical\ncovariance matrix formed along the sample path of a fast-mixing stochastic\nprocess concentrates above zero, extending a result by Koltchinskii and\nMendelson in the independent covariates setting. Finally, we provide\nexperimental evidence indicating that our analysis correctly captures the\nqualitative behavior of LSTD on several LQR instances. \n\n"}
{"id": "1712.08726", "contents": "Title: Denoising of 3D magnetic resonance images with multi-channel residual\n  learning of convolutional neural network Abstract: The denoising of magnetic resonance (MR) images is a task of great importance\nfor improving the acquired image quality. Many methods have been proposed in\nthe literature to retrieve noise free images with good performances. Howerever,\nthe state-of-the-art denoising methods, all needs a time-consuming optimization\nprocesses and their performance strongly depend on the estimated noise level\nparameter. Within this manuscript we propose the idea of denoising MRI Rician\nnoise using a convolutional neural network. The advantage of the proposed\nmethodology is that the learning based model can be directly used in the\ndenosing process without optimization and even without the noise level\nparameter. Specifically, a ten convolutional layers neural network combined\nwith residual learning and multi-channel strategy was proposed. Two training\nways: training on a specific noise level and training on a general level were\nconducted to demonstrate the capability of our methods. Experimental results\nover synthetic and real 3D MR data demonstrate our proposed network can achieve\nsuperior performance compared with other methods in term of both of the peak\nsignal to noise ratio and the global of structure similarity index. Without\nnoise level parameter, our general noise-applicable model is also better than\nthe other compared methods in two datasets. Furthermore, our training model\nshows good general applicability. \n\n"}
{"id": "1712.08968", "contents": "Title: Spurious Local Minima are Common in Two-Layer ReLU Neural Networks Abstract: We consider the optimization problem associated with training simple ReLU\nneural networks of the form $\\mathbf{x}\\mapsto\n\\sum_{i=1}^{k}\\max\\{0,\\mathbf{w}_i^\\top \\mathbf{x}\\}$ with respect to the\nsquared loss. We provide a computer-assisted proof that even if the input\ndistribution is standard Gaussian, even if the dimension is arbitrarily large,\nand even if the target values are generated by such a network, with orthonormal\nparameter vectors, the problem can still have spurious local minima once $6\\le\nk\\le 20$. By a concentration of measure argument, this implies that in high\ninput dimensions, \\emph{nearly all} target networks of the relevant sizes lead\nto spurious local minima. Moreover, we conduct experiments which show that the\nprobability of hitting such local minima is quite high, and increasing with the\nnetwork size. On the positive side, mild over-parameterization appears to\ndrastically reduce such local minima, indicating that an over-parameterization\nassumption is necessary to get a positive result in this setting. \n\n"}
{"id": "1801.03150", "contents": "Title: Moments in Time Dataset: one million videos for event understanding Abstract: We present the Moments in Time Dataset, a large-scale human-annotated\ncollection of one million short videos corresponding to dynamic events\nunfolding within three seconds. Modeling the spatial-audio-temporal dynamics\neven for actions occurring in 3 second videos poses many challenges: meaningful\nevents do not include only people, but also objects, animals, and natural\nphenomena; visual and auditory events can be symmetrical in time (\"opening\" is\n\"closing\" in reverse), and either transient or sustained. We describe the\nannotation process of our dataset (each video is tagged with one action or\nactivity label among 339 different classes), analyze its scale and diversity in\ncomparison to other large-scale video datasets for action recognition, and\nreport results of several baseline models addressing separately, and jointly,\nthree modalities: spatial, temporal and auditory. The Moments in Time dataset,\ndesigned to have a large coverage and diversity of events in both visual and\nauditory modalities, can serve as a new challenge to develop models that scale\nto the level of complexity and abstract reasoning that a human processes on a\ndaily basis. \n\n"}
{"id": "1801.04381", "contents": "Title: MobileNetV2: Inverted Residuals and Linear Bottlenecks Abstract: In this paper we describe a new mobile architecture, MobileNetV2, that\nimproves the state of the art performance of mobile models on multiple tasks\nand benchmarks as well as across a spectrum of different model sizes. We also\ndescribe efficient ways of applying these mobile models to object detection in\na novel framework we call SSDLite. Additionally, we demonstrate how to build\nmobile semantic segmentation models through a reduced form of DeepLabv3 which\nwe call Mobile DeepLabv3.\n  The MobileNetV2 architecture is based on an inverted residual structure where\nthe input and output of the residual block are thin bottleneck layers opposite\nto traditional residual models which use expanded representations in the input\nan MobileNetV2 uses lightweight depthwise convolutions to filter features in\nthe intermediate expansion layer. Additionally, we find that it is important to\nremove non-linearities in the narrow layers in order to maintain\nrepresentational power. We demonstrate that this improves performance and\nprovide an intuition that led to this design. Finally, our approach allows\ndecoupling of the input/output domains from the expressiveness of the\ntransformation, which provides a convenient framework for further analysis. We\nmeasure our performance on Imagenet classification, COCO object detection, VOC\nimage segmentation. We evaluate the trade-offs between accuracy, and number of\noperations measured by multiply-adds (MAdd), as well as the number of\nparameters \n\n"}
{"id": "1801.05038", "contents": "Title: An octree cells occupancy geometric dimensionality descriptor for\n  massive on-server point cloud visualisation and classification Abstract: Lidar datasets are becoming more and more common. They are appreciated for\ntheir precise 3D nature, and have a wide range of applications, such as surface\nreconstruction, object detection, visualisation, etc. For all this\napplications, having additional semantic information per point has potential of\nincreasing the quality and the efficiency of the application. In the last\ndecade the use of Machine Learning and more specifically classification methods\nhave proved to be successful to create this semantic information. In this\nparadigm, the goal is to classify points into a set of given classes (for\ninstance tree, building, ground, other). Some of these methods use descriptors\n(also called feature) of a point to learn and predict its class. Designing the\ndescriptors is then the heart of these methods. Descriptors can be based on\npoints geometry and attributes, use contextual information, etc. Furthermore,\ndescriptors can be used by humans for easier visual understanding and sometimes\nfiltering. In this work we propose a new simple geometric descriptor that gives\ninformation about the implicit local dimensionality of the point cloud at\nvarious scale. For instance a tree seen from afar is more volumetric in nature\n(3D), yet locally each leaves is rather planar (2D). To do so we build an\noctree centred on the point to consider, and compare the variation of the\noccupancy of the cells across the levels of the octree. We compare this\ndescriptor with the state of the art dimensionality descriptor and show its\ninterest. We further test the descriptor for classification within the Point\nCloud Server, and demonstrate efficiency and correctness results. \n\n"}
{"id": "1801.05574", "contents": "Title: Brenier approach for optimal transportation between a quasi-discrete\n  measure and a discrete measure Abstract: Correctly estimating the discrepancy between two data distributions has\nalways been an important task in Machine Learning. Recently, Cuturi proposed\nthe Sinkhorn distance which makes use of an approximate Optimal Transport cost\nbetween two distributions as a distance to describe distribution discrepancy.\nAlthough it has been successfully adopted in various machine learning\napplications (e.g. in Natural Language Processing and Computer Vision) since\nthen, the Sinkhorn distance also suffers from two unnegligible limitations. The\nfirst one is that the Sinkhorn distance only gives an approximation of the real\nWasserstein distance, the second one is the `divide by zero' problem which\noften occurs during matrix scaling when setting the entropy regularization\ncoefficient to a small value. In this paper, we introduce a new Brenier\napproach for calculating a more accurate Wasserstein distance between two\ndiscrete distributions, this approach successfully avoids the two limitations\nshown above for Sinkhorn distance and gives an alternative way for estimating\ndistribution discrepancy. \n\n"}
{"id": "1801.07145", "contents": "Title: E-swish: Adjusting Activations to Different Network Depths Abstract: Activation functions have a notorious impact on neural networks on both\ntraining and testing the models against the desired problem. Currently, the\nmost used activation function is the Rectified Linear Unit (ReLU). This paper\nintroduces a new and novel activation function, closely related with the new\nactivation $Swish = x * sigmoid(x)$ (Ramachandran et al., 2017) which\ngeneralizes it. We call the new activation $E-swish = \\beta x * sigmoid(x)$. We\nshow that E-swish outperforms many other well-known activations including both\nReLU and Swish. For example, using E-swish provided 1.5% and 4.6% accuracy\nimprovements on Cifar10 and Cifar100 respectively for the WRN 10-2 when\ncompared to ReLU and 0.35% and 0.6% respectively when compared to Swish. The\ncode to reproduce all our experiments can be found at\nhttps://github.com/EricAlcaide/E-swish \n\n"}
{"id": "1801.08186", "contents": "Title: MAttNet: Modular Attention Network for Referring Expression\n  Comprehension Abstract: In this paper, we address referring expression comprehension: localizing an\nimage region described by a natural language expression. While most recent work\ntreats expressions as a single unit, we propose to decompose them into three\nmodular components related to subject appearance, location, and relationship to\nother objects. This allows us to flexibly adapt to expressions containing\ndifferent types of information in an end-to-end framework. In our model, which\nwe call the Modular Attention Network (MAttNet), two types of attention are\nutilized: language-based attention that learns the module weights as well as\nthe word/phrase attention that each module should focus on; and visual\nattention that allows the subject and relationship modules to focus on relevant\nimage components. Module weights combine scores from all three modules\ndynamically to output an overall score. Experiments show that MAttNet\noutperforms previous state-of-art methods by a large margin on both\nbounding-box-level and pixel-level comprehension tasks. Demo and code are\nprovided. \n\n"}
{"id": "1801.09468", "contents": "Title: DeepSIC: Deep Semantic Image Compression Abstract: Incorporating semantic information into the codecs during image compression\ncan significantly reduce the repetitive computation of fundamental semantic\nanalysis (such as object recognition) in client-side applications. The same\npractice also enable the compressed code to carry the image semantic\ninformation during storage and transmission. In this paper, we propose a\nconcept called Deep Semantic Image Compression (DeepSIC) and put forward two\nnovel architectures that aim to reconstruct the compressed image and generate\ncorresponding semantic representations at the same time. The first architecture\nperforms semantic analysis in the encoding process by reserving a portion of\nthe bits from the compressed code to store the semantic representations. The\nsecond performs semantic analysis in the decoding step with the feature maps\nthat are embedded in the compressed code. In both architectures, the feature\nmaps are shared by the compression and the semantic analytics modules. To\nvalidate our approaches, we conduct experiments on the publicly available\nbenchmarking datasets and achieve promising results. We also provide a thorough\nanalysis of the advantages and disadvantages of the proposed technique. \n\n"}
{"id": "1801.09518", "contents": "Title: Learning-based Image Reconstruction via Parallel Proximal Algorithm Abstract: In the past decade, sparsity-driven regularization has led to advancement of\nimage reconstruction algorithms. Traditionally, such regularizers rely on\nanalytical models of sparsity (e.g. total variation (TV)). However, more recent\nmethods are increasingly centered around data-driven arguments inspired by deep\nlearning. In this letter, we propose to generalize TV regularization by\nreplacing the l1-penalty with an alternative prior that is trainable.\nSpecifically, our method learns the prior via extending the recently proposed\nfast parallel proximal algorithm (FPPA) to incorporate data-adaptive proximal\noperators. The proposed framework does not require additional inner iterations\nfor evaluating the proximal mappings of the corresponding learned prior.\nMoreover, our formalism ensures that the training and reconstruction processes\nshare the same algorithmic structure, making the end-to-end implementation\nintuitive. As an example, we demonstrate our algorithm on the problem of\ndeconvolution in a fluorescence microscope. \n\n"}
{"id": "1801.09859", "contents": "Title: Structured Memory based Deep Model to Detect as well as Characterize\n  Novel Inputs Abstract: While deep learning has pushed the boundaries in various machine learning\ntasks, the current models are still far away from replicating many functions\nthat a normal human brain can do. Explicit memorization based deep architecture\nhave been recently proposed with the objective to understand and predict\nbetter. In this work, we design a system that involves a primary learner and an\nadjacent representational memory bank which is organized using a comparative\nlearner. This spatially forked deep architecture with a structured memory can\nsimultaneously predict and reason about the nature of an input, which may even\nbelong to a category never seen in the training data, by relating it with the\nmemorized past representations at the higher layers. Characterizing images of\nunseen object classes in both synthetic and real world datasets is used as an\nexample to showcase the operational success of the proposed framework. \n\n"}
{"id": "1802.02212", "contents": "Title: Classification and Disease Localization in Histopathology Using Only\n  Global Labels: A Weakly-Supervised Approach Abstract: Analysis of histopathology slides is a critical step for many diagnoses, and\nin particular in oncology where it defines the gold standard. In the case of\ndigital histopathological analysis, highly trained pathologists must review\nvast whole-slide-images of extreme digital resolution ($100,000^2$ pixels)\nacross multiple zoom levels in order to locate abnormal regions of cells, or in\nsome cases single cells, out of millions. The application of deep learning to\nthis problem is hampered not only by small sample sizes, as typical datasets\ncontain only a few hundred samples, but also by the generation of ground-truth\nlocalized annotations for training interpretable classification and\nsegmentation models. We propose a method for disease localization in the\ncontext of weakly supervised learning, where only image-level labels are\navailable during training. Even without pixel-level annotations, we are able to\ndemonstrate performance comparable with models trained with strong annotations\non the Camelyon-16 lymph node metastases detection challenge. We accomplish\nthis through the use of pre-trained deep convolutional networks, feature\nembedding, as well as learning via top instances and negative evidence, a\nmultiple instance learning technique from the field of semantic segmentation\nand object detection. \n\n"}
{"id": "1802.02312", "contents": "Title: Machine Learning-Based Prototyping of Graphical User Interfaces for\n  Mobile Apps Abstract: It is common practice for developers of user-facing software to transform a\nmock-up of a graphical user interface (GUI) into code. This process takes place\nboth at an application's inception and in an evolutionary context as GUI\nchanges keep pace with evolving features. Unfortunately, this practice is\nchallenging and time-consuming. In this paper, we present an approach that\nautomates this process by enabling accurate prototyping of GUIs via three\ntasks: detection, classification, and assembly. First, logical components of a\nGUI are detected from a mock-up artifact using either computer vision\ntechniques or mock-up metadata. Then, software repository mining, automated\ndynamic analysis, and deep convolutional neural networks are utilized to\naccurately classify GUI-components into domain-specific types (e.g.,\ntoggle-button). Finally, a data-driven, K-nearest-neighbors algorithm generates\na suitable hierarchical GUI structure from which a prototype application can be\nautomatically assembled. We implemented this approach for Android in a system\ncalled ReDraw. Our evaluation illustrates that ReDraw achieves an average\nGUI-component classification accuracy of 91% and assembles prototype\napplications that closely mirror target mock-ups in terms of visual affinity\nwhile exhibiting reasonable code structure. Interviews with industrial\npractitioners illustrate ReDraw's potential to improve real development\nworkflows. \n\n"}
{"id": "1802.03345", "contents": "Title: A Two-Stage Method for Text Line Detection in Historical Documents Abstract: This work presents a two-stage text line detection method for historical\ndocuments. Each detected text line is represented by its baseline. In a first\nstage, a deep neural network called ARU-Net labels pixels to belong to one of\nthe three classes: baseline, separator or other. The separator class marks\nbeginning and end of each text line. The ARU-Net is trainable from scratch with\nmanageably few manually annotated example images (less than 50). This is\nachieved by utilizing data augmentation strategies. The network predictions are\nused as input for the second stage which performs a bottom-up clustering to\nbuild baselines. The developed method is capable of handling complex layouts as\nwell as curved and arbitrarily oriented text lines. It substantially\noutperforms current state-of-the-art approaches. For example, for the complex\ntrack of the cBAD: ICDAR2017 Competition on Baseline Detection the F-value is\nincreased from 0.859 to 0.922. The framework to train and run the ARU-Net is\nopen source. \n\n"}
{"id": "1802.03518", "contents": "Title: Hydra: an Ensemble of Convolutional Neural Networks for Geospatial Land\n  Classification Abstract: We describe in this paper Hydra, an ensemble of convolutional neural networks\n(CNN) for geospatial land classification. The idea behind Hydra is to create an\ninitial CNN that is coarsely optimized but provides a good starting pointing\nfor further optimization, which will serve as the Hydra's body. Then, the\nobtained weights are fine-tuned multiple times with different augmentation\ntechniques, crop styles, and classes weights to form an ensemble of CNNs that\nrepresent the Hydra's heads. By doing so, we prompt convergence to different\nendpoints, which is a desirable aspect for ensembles. With this framework, we\nwere able to reduce the training time while maintaining the classification\nperformance of the ensemble. We created ensembles for our experiments using two\nstate-of-the-art CNN architectures, ResNet and DenseNet. We have demonstrated\nthe application of our Hydra framework in two datasets, FMOW and NWPU-RESISC45,\nachieving results comparable to the state-of-the-art for the former and the\nbest reported performance so far for the latter. Code and CNN models are\navailable at https://github.com/maups/hydra-fmow \n\n"}
{"id": "1802.03654", "contents": "Title: Beyond the One Step Greedy Approach in Reinforcement Learning Abstract: The famous Policy Iteration algorithm alternates between policy improvement\nand policy evaluation. Implementations of this algorithm with several variants\nof the latter evaluation stage, e.g, $n$-step and trace-based returns, have\nbeen analyzed in previous works. However, the case of multiple-step lookahead\npolicy improvement, despite the recent increase in empirical evidence of its\nstrength, has to our knowledge not been carefully analyzed yet. In this work,\nwe introduce the first such analysis. Namely, we formulate variants of\nmultiple-step policy improvement, derive new algorithms using these definitions\nand prove their convergence. Moreover, we show that recent prominent\nReinforcement Learning algorithms are, in fact, instances of our framework. We\nthus shed light on their empirical success and give a recipe for deriving new\nalgorithms for future study. \n\n"}
{"id": "1802.04087", "contents": "Title: Deep learning based supervised semantic segmentation of Electron\n  Cryo-Subtomograms Abstract: Cellular Electron Cryo-Tomography (CECT) is a powerful imaging technique for\nthe 3D visualization of cellular structure and organization at submolecular\nresolution. It enables analyzing the native structures of macromolecular\ncomplexes and their spatial organization inside single cells. However, due to\nthe high degree of structural complexity and practical imaging limitations,\nsystematic macromolecular structural recovery inside CECT images remains\nchallenging. Particularly, the recovery of a macromolecule is likely to be\nbiased by its neighbor structures due to the high molecular crowding. To reduce\nthe bias, here we introduce a novel 3D convolutional neural network inspired by\nFully Convolutional Network and Encoder-Decoder Architecture for the supervised\nsegmentation of macromolecules of interest in subtomograms. The tests of our\nmodels on realistically simulated CECT data demonstrate that our new approach\nhas significantly improved segmentation performance compared to our baseline\napproach. Also, we demonstrate that the proposed model has generalization\nability to segment new structures that do not exist in training data. \n\n"}
{"id": "1802.05695", "contents": "Title: Explainable Prediction of Medical Codes from Clinical Text Abstract: Clinical notes are text documents that are created by clinicians for each\npatient encounter. They are typically accompanied by medical codes, which\ndescribe the diagnosis and treatment. Annotating these codes is labor intensive\nand error prone; furthermore, the connection between the codes and the text is\nnot annotated, obscuring the reasons and details behind specific diagnoses and\ntreatments. We present an attentional convolutional network that predicts\nmedical codes from clinical text. Our method aggregates information across the\ndocument using a convolutional neural network, and uses an attention mechanism\nto select the most relevant segments for each of the thousands of possible\ncodes. The method is accurate, achieving precision@8 of 0.71 and a Micro-F1 of\n0.54, which are both better than the prior state of the art. Furthermore,\nthrough an interpretability evaluation by a physician, we show that the\nattention mechanism identifies meaningful explanations for each code assignment \n\n"}
{"id": "1802.05800", "contents": "Title: Tree-CNN: A Hierarchical Deep Convolutional Neural Network for\n  Incremental Learning Abstract: Over the past decade, Deep Convolutional Neural Networks (DCNNs) have shown\nremarkable performance in most computer vision tasks. These tasks traditionally\nuse a fixed dataset, and the model, once trained, is deployed as is. Adding new\ninformation to such a model presents a challenge due to complex training\nissues, such as \"catastrophic forgetting\", and sensitivity to hyper-parameter\ntuning. However, in this modern world, data is constantly evolving, and our\ndeep learning models are required to adapt to these changes. In this paper, we\npropose an adaptive hierarchical network structure composed of DCNNs that can\ngrow and learn as new data becomes available. The network grows in a tree-like\nfashion to accommodate new classes of data, while preserving the ability to\ndistinguish the previously trained classes. The network organizes the\nincrementally available data into feature-driven super-classes and improves\nupon existing hierarchical CNN models by adding the capability of self-growth.\nThe proposed hierarchical model, when compared against fine-tuning a deep\nnetwork, achieves significant reduction of training effort, while maintaining\ncompetitive accuracy on CIFAR-10 and CIFAR-100. \n\n"}
{"id": "1802.06205", "contents": "Title: Towards Principled Design of Deep Convolutional Networks: Introducing\n  SimpNet Abstract: Major winning Convolutional Neural Networks (CNNs), such as VGGNet, ResNet,\nDenseNet, \\etc, include tens to hundreds of millions of parameters, which\nimpose considerable computation and memory overheads. This limits their\npractical usage in training and optimizing for real-world applications. On the\ncontrary, light-weight architectures, such as SqueezeNet, are being proposed to\naddress this issue. However, they mainly suffer from low accuracy, as they have\ncompromised between the processing power and efficiency. These inefficiencies\nmostly stem from following an ad-hoc designing procedure. In this work, we\ndiscuss and propose several crucial design principles for an efficient\narchitecture design and elaborate intuitions concerning different aspects of\nthe design procedure. Furthermore, we introduce a new layer called {\\it\nSAF-pooling} to improve the generalization power of the network while keeping\nit simple by choosing best features. Based on such principles, we propose a\nsimple architecture called {\\it SimpNet}. We empirically show that SimpNet\nprovides a good trade-off between the computation/memory efficiency and the\naccuracy solely based on these primitive but crucial principles. SimpNet\noutperforms the deeper and more complex architectures such as VGGNet, ResNet,\nWideResidualNet \\etc, on several well-known benchmarks, while having 2 to 25\ntimes fewer number of parameters and operations. We obtain state-of-the-art\nresults (in terms of a balance between the accuracy and the number of involved\nparameters) on standard datasets, such as CIFAR10, CIFAR100, MNIST and SVHN.\nThe implementations are available at\n\\href{url}{https://github.com/Coderx7/SimpNet}. \n\n"}
{"id": "1802.06259", "contents": "Title: Exact and Consistent Interpretation for Piecewise Linear Neural\n  Networks: A Closed Form Solution Abstract: Strong intelligent machines powered by deep neural networks are increasingly\ndeployed as black boxes to make decisions in risk-sensitive domains, such as\nfinance and medical. To reduce potential risk and build trust with users, it is\ncritical to interpret how such machines make their decisions. Existing works\ninterpret a pre-trained neural network by analyzing hidden neurons, mimicking\npre-trained models or approximating local predictions. However, these methods\ndo not provide a guarantee on the exactness and consistency of their\ninterpretation. In this paper, we propose an elegant closed form solution named\n$OpenBox$ to compute exact and consistent interpretations for the family of\nPiecewise Linear Neural Networks (PLNN). The major idea is to first transform a\nPLNN into a mathematically equivalent set of linear classifiers, then interpret\neach linear classifier by the features that dominate its prediction. We further\napply $OpenBox$ to demonstrate the effectiveness of non-negative and sparse\nconstraints on improving the interpretability of PLNNs. The extensive\nexperiments on both synthetic and real world data sets clearly demonstrate the\nexactness and consistency of our interpretation. \n\n"}
{"id": "1802.06260", "contents": "Title: A Collaborative Computer Aided Diagnosis (C-CAD) System with\n  Eye-Tracking, Sparse Attentional Model, and Deep Learning Abstract: There are at least two categories of errors in radiology screening that can\nlead to suboptimal diagnostic decisions and interventions:(i)human fallibility\nand (ii)complexity of visual search. Computer aided diagnostic (CAD) tools are\ndeveloped to help radiologists to compensate for some of these errors. However,\ndespite their significant improvements over conventional screening strategies,\nmost CAD systems do not go beyond their use as second opinion tools due to\nproducing a high number of false positives, which human interpreters need to\ncorrect. In parallel with efforts in computerized analysis of radiology scans,\nseveral researchers have examined behaviors of radiologists while screening\nmedical images to better understand how and why they miss tumors, how they\ninteract with the information in an image, and how they search for unknown\npathology in the images. Eye-tracking tools have been instrumental in exploring\nanswers to these fundamental questions. In this paper, we aim to develop a\nparadigm shift CAD system, called collaborative CAD (C-CAD), that unifies both\nof the above mentioned research lines: CAD and eye-tracking. We design an\neye-tracking interface providing radiologists with a real radiology reading\nroom experience. Then, we propose a novel algorithm that unifies eye-tracking\ndata and a CAD system. Specifically, we present a new graph based clustering\nand sparsification algorithm to transform eye-tracking data (gaze) into a\nsignal model to interpret gaze patterns quantitatively and qualitatively. The\nproposed C-CAD collaborates with radiologists via eye-tracking technology and\nhelps them to improve diagnostic decisions. The C-CAD learns radiologists'\nsearch efficiency by processing their gaze patterns. To do this, the C-CAD uses\na deep learning algorithm in a newly designed multi-task learning platform to\nsegment and diagnose cancers simultaneously. \n\n"}
{"id": "1802.06488", "contents": "Title: Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network\n  for Real-time Embedded Object Detection Abstract: Object detection is a major challenge in computer vision, involving both\nobject classification and object localization within a scene. While deep neural\nnetworks have been shown in recent years to yield very powerful techniques for\ntackling the challenge of object detection, one of the biggest challenges with\nenabling such object detection networks for widespread deployment on embedded\ndevices is high computational and memory requirements. Recently, there has been\nan increasing focus in exploring small deep neural network architectures for\nobject detection that are more suitable for embedded devices, such as Tiny YOLO\nand SqueezeDet. Inspired by the efficiency of the Fire microarchitecture\nintroduced in SqueezeNet and the object detection performance of the\nsingle-shot detection macroarchitecture introduced in SSD, this paper\nintroduces Tiny SSD, a single-shot detection deep convolutional neural network\nfor real-time embedded object detection that is composed of a highly optimized,\nnon-uniform Fire sub-network stack and a non-uniform sub-network stack of\nhighly optimized SSD-based auxiliary convolutional feature layers designed\nspecifically to minimize model size while maintaining object detection\nperformance. The resulting Tiny SSD possess a model size of 2.3MB (~26X smaller\nthan Tiny YOLO) while still achieving an mAP of 61.3% on VOC 2007 (~4.2% higher\nthan Tiny YOLO). These experimental results show that very small deep neural\nnetwork architectures can be designed for real-time object detection that are\nwell-suited for embedded scenarios. \n\n"}
{"id": "1802.07244", "contents": "Title: Steering Social Activity: A Stochastic Optimal Control Point Of View Abstract: User engagement in online social networking depends critically on the level\nof social activity in the corresponding platform--the number of online actions,\nsuch as posts, shares or replies, taken by their users. Can we design\ndata-driven algorithms to increase social activity? At a user level, such\nalgorithms may increase activity by helping users decide when to take an action\nto be more likely to be noticed by their peers. At a network level, they may\nincrease activity by incentivizing a few influential users to take more\nactions, which in turn will trigger additional actions by other users. In this\npaper, we model social activity using the framework of marked temporal point\nprocesses, derive an alternate representation of these processes using\nstochastic differential equations (SDEs) with jumps and, exploiting this\nalternate representation, develop two efficient online algorithms with provable\nguarantees to steer social activity both at a user and at a network level. In\ndoing so, we establish a previously unexplored connection between optimal\ncontrol of jump SDEs and doubly stochastic marked temporal point processes,\nwhich is of independent interest. Finally, we experiment both with synthetic\nand real data gathered from Twitter and show that our algorithms consistently\nsteer social activity more effectively than the state of the art. \n\n"}
{"id": "1802.07623", "contents": "Title: Explanations based on the Missing: Towards Contrastive Explanations with\n  Pertinent Negatives Abstract: In this paper we propose a novel method that provides contrastive\nexplanations justifying the classification of an input by a black box\nclassifier such as a deep neural network. Given an input we find what should be\n%necessarily and minimally and sufficiently present (viz. important object\npixels in an image) to justify its classification and analogously what should\nbe minimally and necessarily \\emph{absent} (viz. certain background pixels). We\nargue that such explanations are natural for humans and are used commonly in\ndomains such as health care and criminology. What is minimally but critically\n\\emph{absent} is an important part of an explanation, which to the best of our\nknowledge, has not been explicitly identified by current explanation methods\nthat explain predictions of neural networks. We validate our approach on three\nreal datasets obtained from diverse domains; namely, a handwritten digits\ndataset MNIST, a large procurement fraud dataset and a brain activity strength\ndataset. In all three cases, we witness the power of our approach in generating\nprecise explanations that are also easy for human experts to understand and\nevaluate. \n\n"}
{"id": "1802.07971", "contents": "Title: Robustness of classifiers to uniform $\\ell\\_p$ and Gaussian noise Abstract: We study the robustness of classifiers to various kinds of random noise\nmodels. In particular, we consider noise drawn uniformly from the $\\ell\\_p$\nball for $p \\in [1, \\infty]$ and Gaussian noise with an arbitrary covariance\nmatrix. We characterize this robustness to random noise in terms of the\ndistance to the decision boundary of the classifier. This analysis applies to\nlinear classifiers as well as classifiers with locally approximately flat\ndecision boundaries, a condition which is satisfied by state-of-the-art deep\nneural networks. The predicted robustness is verified experimentally. \n\n"}
{"id": "1802.08530", "contents": "Title: Training wide residual networks for deployment using a single bit for\n  each weight Abstract: For fast and energy-efficient deployment of trained deep neural networks on\nresource-constrained embedded hardware, each learned weight parameter should\nideally be represented and stored using a single bit. Error-rates usually\nincrease when this requirement is imposed. Here, we report large improvements\nin error rates on multiple datasets, for deep convolutional neural networks\ndeployed with 1-bit-per-weight. Using wide residual networks as our main\nbaseline, our approach simplifies existing methods that binarize weights by\napplying the sign function in training; we apply scaling factors for each layer\nwith constant unlearned values equal to the layer-specific standard deviations\nused for initialization. For CIFAR-10, CIFAR-100 and ImageNet, and models with\n1-bit-per-weight requiring less than 10 MB of parameter memory, we achieve\nerror rates of 3.9%, 18.5% and 26.0% / 8.5% (Top-1 / Top-5) respectively. We\nalso considered MNIST, SVHN and ImageNet32, achieving 1-bit-per-weight test\nresults of 0.27%, 1.9%, and 41.3% / 19.1% respectively. For CIFAR, our error\nrates halve previously reported values, and are within about 1% of our\nerror-rates for the same network with full-precision weights. For networks that\noverfit, we also show significant improvements in error rate by not learning\nbatch normalization scale and offset parameters. This applies to both full\nprecision and 1-bit-per-weight networks. Using a warm-restart learning-rate\nschedule, we found that training for 1-bit-per-weight is just as fast as\nfull-precision networks, with better accuracy than standard schedules, and\nachieved about 98%-99% of peak performance in just 62 training epochs for\nCIFAR-10/100. For full training code and trained models in MATLAB, Keras and\nPyTorch see https://github.com/McDonnell-Lab/1-bit-per-weight/ . \n\n"}
{"id": "1802.08717", "contents": "Title: Deep learning in radiology: an overview of the concepts and a survey of\n  the state of the art Abstract: Deep learning is a branch of artificial intelligence where networks of simple\ninterconnected units are used to extract patterns from data in order to solve\ncomplex problems. Deep learning algorithms have shown groundbreaking\nperformance in a variety of sophisticated tasks, especially those related to\nimages. They have often matched or exceeded human performance. Since the\nmedical field of radiology mostly relies on extracting useful information from\nimages, it is a very natural application area for deep learning, and research\nin this area has rapidly grown in recent years. In this article, we review the\nclinical reality of radiology and discuss the opportunities for application of\ndeep learning algorithms. We also introduce basic concepts of deep learning\nincluding convolutional neural networks. Then, we present a survey of the\nresearch in deep learning applied to radiology. We organize the studies by the\ntypes of specific tasks that they attempt to solve and review the broad range\nof utilized deep learning algorithms. Finally, we briefly discuss opportunities\nand challenges for incorporating deep learning in the radiology practice of the\nfuture. \n\n"}
{"id": "1802.08831", "contents": "Title: Convolutional Neural Networks combined with Runge-Kutta Methods Abstract: A convolutional neural network can be constructed using numerical methods for\nsolving dynamical systems, since the forward pass of the network can be\nregarded as a trajectory of a dynamical system. However, existing models based\non numerical solvers cannot avoid the iterations of implicit methods, which\nmakes the models inefficient at inference time. In this paper, we reinterpret\nthe pre-activation Residual Networks (ResNets) and their variants from the\ndynamical systems view. We consider that the iterations of implicit Runge-Kutta\nmethods are fused into the training of these models. Moreover, we propose a\nnovel approach to constructing network models based on high-order Runge-Kutta\nmethods in order to achieve higher efficiency. Our proposed models are referred\nto as the Runge-Kutta Convolutional Neural Networks (RKCNNs). The RKCNNs are\nevaluated on multiple benchmark datasets. The experimental results show that\nRKCNNs are vastly superior to other dynamical system network models: they\nachieve higher accuracy with much fewer resources. They also expand the family\nof network models based on numerical methods for dynamical systems. \n\n"}
{"id": "1802.09655", "contents": "Title: Translating and Segmenting Multimodal Medical Volumes with Cycle- and\n  Shape-Consistency Generative Adversarial Network Abstract: Synthesized medical images have several important applications, e.g., as an\nintermedium in cross-modality image registration and as supplementary training\nsamples to boost the generalization capability of a classifier. Especially,\nsynthesized computed tomography (CT) data can provide X-ray attenuation map for\nradiation therapy planning. In this work, we propose a generic cross-modality\nsynthesis approach with the following targets: 1) synthesizing realistic\nlooking 3D images using unpaired training data, 2) ensuring consistent\nanatomical structures, which could be changed by geometric distortion in\ncross-modality synthesis and 3) improving volume segmentation by using\nsynthetic data for modalities with limited training samples. We show that these\ngoals can be achieved with an end-to-end 3D convolutional neural network (CNN)\ncomposed of mutually-beneficial generators and segmentors for image synthesis\nand segmentation tasks. The generators are trained with an adversarial loss, a\ncycle-consistency loss, and also a shape-consistency loss, which is supervised\nby segmentors, to reduce the geometric distortion. From the segmentation view,\nthe segmentors are boosted by synthetic data from generators in an online\nmanner. Generators and segmentors prompt each other alternatively in an\nend-to-end training fashion. With extensive experiments on a dataset including\na total of 4,496 CT and magnetic resonance imaging (MRI) cardiovascular\nvolumes, we show both tasks are beneficial to each other and coupling these two\ntasks results in better performance than solving them exclusively. \n\n"}
{"id": "1802.10031", "contents": "Title: The Mirage of Action-Dependent Baselines in Reinforcement Learning Abstract: Policy gradient methods are a widely used class of model-free reinforcement\nlearning algorithms where a state-dependent baseline is used to reduce gradient\nestimator variance. Several recent papers extend the baseline to depend on both\nthe state and action and suggest that this significantly reduces variance and\nimproves sample efficiency without introducing bias into the gradient\nestimates. To better understand this development, we decompose the variance of\nthe policy gradient estimator and numerically show that learned\nstate-action-dependent baselines do not in fact reduce variance over a\nstate-dependent baseline in commonly tested benchmark domains. We confirm this\nunexpected result by reviewing the open-source code accompanying these prior\npapers, and show that subtle implementation decisions cause deviations from the\nmethods presented in the papers and explain the source of the previously\nobserved empirical gains. Furthermore, the variance decomposition highlights\nareas for improvement, which we demonstrate by illustrating a simple change to\nthe typical value function parameterization that can significantly improve\nperformance. \n\n"}
{"id": "1803.00401", "contents": "Title: Unravelling Robustness of Deep Learning based Face Recognition Against\n  Adversarial Attacks Abstract: Deep neural network (DNN) architecture based models have high expressive\npower and learning capacity. However, they are essentially a black box method\nsince it is not easy to mathematically formulate the functions that are learned\nwithin its many layers of representation. Realizing this, many researchers have\nstarted to design methods to exploit the drawbacks of deep learning based\nalgorithms questioning their robustness and exposing their singularities. In\nthis paper, we attempt to unravel three aspects related to the robustness of\nDNNs for face recognition: (i) assessing the impact of deep architectures for\nface recognition in terms of vulnerabilities to attacks inspired by commonly\nobserved distortions in the real world that are well handled by shallow\nlearning methods along with learning based adversaries; (ii) detecting the\nsingularities by characterizing abnormal filter response behavior in the hidden\nlayers of deep networks; and (iii) making corrections to the processing\npipeline to alleviate the problem. Our experimental evaluation using multiple\nopen-source DNN-based face recognition networks, including OpenFace and\nVGG-Face, and two publicly available databases (MEDS and PaSC) demonstrates\nthat the performance of deep learning based face recognition algorithms can\nsuffer greatly in the presence of such distortions. The proposed method is also\ncompared with existing detection algorithms and the results show that it is\nable to detect the attacks with very high accuracy by suitably designing a\nclassifier using the response of the hidden layers in the network. Finally, we\npresent several effective countermeasures to mitigate the impact of adversarial\nattacks and improve the overall robustness of DNN-based face recognition. \n\n"}
{"id": "1803.00702", "contents": "Title: Raw Multi-Channel Audio Source Separation using Multi-Resolution\n  Convolutional Auto-Encoders Abstract: Supervised multi-channel audio source separation requires extracting useful\nspectral, temporal, and spatial features from the mixed signals. The success of\nmany existing systems is therefore largely dependent on the choice of features\nused for training. In this work, we introduce a novel multi-channel,\nmulti-resolution convolutional auto-encoder neural network that works on raw\ntime-domain signals to determine appropriate multi-resolution features for\nseparating the singing-voice from stereo music. Our experimental results show\nthat the proposed method can achieve multi-channel audio source separation\nwithout the need for hand-crafted features or any pre- or post-processing. \n\n"}
{"id": "1803.00758", "contents": "Title: Driving Digital Rock towards Machine Learning: predicting permeability\n  with Gradient Boosting and Deep Neural Networks Abstract: We present a research study aimed at testing of applicability of machine\nlearning techniques for prediction of permeability of digitized rock samples.\nWe prepare a training set containing 3D images of sandstone samples imaged with\nX-ray microtomography and corresponding permeability values simulated with Pore\nNetwork approach. We also use Minkowski functionals and Deep Learning-based\ndescriptors of 3D images and 2D slices as input features for predictive model\ntraining and prediction. We compare predictive power of various feature sets\nand methods. The later include Gradient Boosting and various architectures of\nDeep Neural Networks (DNN). The results demonstrate applicability of machine\nlearning for image-based permeability prediction and open a new area of Digital\nRock research. \n\n"}
{"id": "1803.01541", "contents": "Title: Improving the Improved Training of Wasserstein GANs: A Consistency Term\n  and Its Dual Effect Abstract: Despite being impactful on a variety of problems and applications, the\ngenerative adversarial nets (GANs) are remarkably difficult to train. This\nissue is formally analyzed by \\cite{arjovsky2017towards}, who also propose an\nalternative direction to avoid the caveats in the minmax two-player training of\nGANs. The corresponding algorithm, called Wasserstein GAN (WGAN), hinges on the\n1-Lipschitz continuity of the discriminator. In this paper, we propose a novel\napproach to enforcing the Lipschitz continuity in the training procedure of\nWGANs. Our approach seamlessly connects WGAN with one of the recent\nsemi-supervised learning methods. As a result, it gives rise to not only better\nphoto-realistic samples than the previous methods but also state-of-the-art\nsemi-supervised learning results. In particular, our approach gives rise to the\ninception score of more than 5.0 with only 1,000 CIFAR-10 images and is the\nfirst that exceeds the accuracy of 90% on the CIFAR-10 dataset using only 4,000\nlabeled images, to the best of our knowledge. \n\n"}
{"id": "1803.02504", "contents": "Title: Exponential Discriminative Metric Embedding in Deep Learning Abstract: With the remarkable success achieved by the Convolutional Neural Networks\n(CNNs) in object recognition recently, deep learning is being widely used in\nthe computer vision community. Deep Metric Learning (DML), integrating deep\nlearning with conventional metric learning, has set new records in many fields,\nespecially in classification task. In this paper, we propose a replicable DML\nmethod, called Include and Exclude (IE) loss, to force the distance between a\nsample and its designated class center away from the mean distance of this\nsample to other class centers with a large margin in the exponential feature\nprojection space. With the supervision of IE loss, we can train CNNs to enhance\nthe intra-class compactness and inter-class separability, leading to great\nimprovements on several public datasets ranging from object recognition to face\nverification. We conduct a comparative study of our algorithm with several\ntypical DML methods on three kinds of networks with different capacity.\nExtensive experiments on three object recognition datasets and two face\nrecognition datasets demonstrate that IE loss is always superior to other\nmainstream DML methods and approach the state-of-the-art results. \n\n"}
{"id": "1803.02544", "contents": "Title: Visual Explanations From Deep 3D Convolutional Neural Networks for\n  Alzheimer's Disease Classification Abstract: We develop three efficient approaches for generating visual explanations from\n3D convolutional neural networks (3D-CNNs) for Alzheimer's disease\nclassification. One approach conducts sensitivity analysis on hierarchical 3D\nimage segmentation, and the other two visualize network activations on a\nspatial map. Visual checks and a quantitative localization benchmark indicate\nthat all approaches identify important brain parts for Alzheimer's disease\ndiagnosis. Comparative analysis show that the sensitivity analysis based\napproach has difficulty handling loosely distributed cerebral cortex, and\napproaches based on visualization of activations are constrained by the\nresolution of the convolutional layer. The complementarity of these methods\nimproves the understanding of 3D-CNNs in Alzheimer's disease classification\nfrom different perspectives. \n\n"}
{"id": "1803.03415", "contents": "Title: Fusing Hierarchical Convolutional Features for Human Body Segmentation\n  and Clothing Fashion Classification Abstract: The clothing fashion reflects the common aesthetics that people share with\neach other in dressing. To recognize the fashion time of a clothing is\nmeaningful for both an individual and the industry. In this paper, under the\nassumption that the clothing fashion changes year by year, the fashion-time\nrecognition problem is mapped into a clothing-fashion classification problem.\nSpecifically, a novel deep neural network is proposed which achieves accurate\nhuman body segmentation by fusing multi-scale convolutional features in a fully\nconvolutional network, and then feature learning and fashion classification are\nperformed on the segmented parts avoiding the influence of image background. In\nthe experiments, 9,339 fashion images from 8 continuous years are collected for\nperformance evaluation. The results demonstrate the effectiveness of the\nproposed body segmentation and fashion classification methods. \n\n"}
{"id": "1803.03474", "contents": "Title: An end-to-end TextSpotter with Explicit Alignment and Attention Abstract: Text detection and recognition in natural images have long been considered as\ntwo separate tasks that are processed sequentially. Training of two tasks in a\nunified framework is non-trivial due to significant dif- ferences in\noptimisation difficulties. In this work, we present a conceptually simple yet\nefficient framework that simultaneously processes the two tasks in one shot.\nOur main contributions are three-fold: 1) we propose a novel text-alignment\nlayer that allows it to precisely compute convolutional features of a text\ninstance in ar- bitrary orientation, which is the key to boost the per-\nformance; 2) a character attention mechanism is introduced by using character\nspatial information as explicit supervision, leading to large improvements in\nrecognition; 3) two technologies, together with a new RNN branch for word\nrecognition, are integrated seamlessly into a single model which is end-to-end\ntrainable. This allows the two tasks to work collaboratively by shar- ing\nconvolutional features, which is critical to identify challenging text\ninstances. Our model achieves impressive results in end-to-end recognition on\nthe ICDAR2015 dataset, significantly advancing most recent results, with\nimprovements of F-measure from (0.54, 0.51, 0.47) to (0.82, 0.77, 0.63), by\nusing a strong, weak and generic lexicon respectively. Thanks to joint\ntraining, our method can also serve as a good detec- tor by achieving a new\nstate-of-the-art detection performance on two datasets. \n\n"}
{"id": "1803.04460", "contents": "Title: Dissimilarity-based representation for radiomics applications Abstract: Radiomics is a term which refers to the analysis of the large amount of\nquantitative tumor features extracted from medical images to find useful\npredictive, diagnostic or prognostic information. Many recent studies have\nproved that radiomics can offer a lot of useful information that physicians\ncannot extract from the medical images and can be associated with other\ninformation like gene or protein data. However, most of the classification\nstudies in radiomics report the use of feature selection methods without\nidentifying the machine learning challenges behind radiomics. In this paper, we\nfirst show that the radiomics problem should be viewed as an high dimensional,\nlow sample size, multi view learning problem, then we compare different\nsolutions proposed in multi view learning for classifying radiomics data. Our\nexperiments, conducted on several real world multi view datasets, show that the\nintermediate integration methods work significantly better than filter and\nembedded feature selection methods commonly used in radiomics. \n\n"}
{"id": "1803.04680", "contents": "Title: Multi-Frame Quality Enhancement for Compressed Video Abstract: The past few years have witnessed great success in applying deep learning to\nenhance the quality of compressed image/video. The existing approaches mainly\nfocus on enhancing the quality of a single frame, ignoring the similarity\nbetween consecutive frames. In this paper, we investigate that heavy quality\nfluctuation exists across compressed video frames, and thus low quality frames\ncan be enhanced using the neighboring high quality frames, seen as Multi-Frame\nQuality Enhancement (MFQE). Accordingly, this paper proposes an MFQE approach\nfor compressed video, as a first attempt in this direction. In our approach, we\nfirstly develop a Support Vector Machine (SVM) based detector to locate Peak\nQuality Frames (PQFs) in compressed video. Then, a novel Multi-Frame\nConvolutional Neural Network (MF-CNN) is designed to enhance the quality of\ncompressed video, in which the non-PQF and its nearest two PQFs are as the\ninput. The MF-CNN compensates motion between the non-PQF and PQFs through the\nMotion Compensation subnet (MC-subnet). Subsequently, the Quality Enhancement\nsubnet (QE-subnet) reduces compression artifacts of the non-PQF with the help\nof its nearest PQFs. Finally, the experiments validate the effectiveness and\ngenerality of our MFQE approach in advancing the state-of-the-art quality\nenhancement of compressed video. The code of our MFQE approach is available at\nhttps://github.com/ryangBUAA/MFQE.git \n\n"}
{"id": "1803.05070", "contents": "Title: A Multi-Modal Approach to Infer Image Affect Abstract: The group affect or emotion in an image of people can be inferred by\nextracting features about both the people in the picture and the overall makeup\nof the scene. The state-of-the-art on this problem investigates a combination\nof facial features, scene extraction and even audio tonality. This paper\ncombines three additional modalities, namely, human pose, text-based tagging\nand CNN extracted features / predictions. To the best of our knowledge, this is\nthe first time all of the modalities were extracted using deep neural networks.\nWe evaluate the performance of our approach against baselines and identify\ninsights throughout this paper. \n\n"}
{"id": "1803.05265", "contents": "Title: Rotation-Sensitive Regression for Oriented Scene Text Detection Abstract: Text in natural images is of arbitrary orientations, requiring detection in\nterms of oriented bounding boxes. Normally, a multi-oriented text detector\noften involves two key tasks: 1) text presence detection, which is a\nclassification problem disregarding text orientation; 2) oriented bounding box\nregression, which concerns about text orientation. Previous methods rely on\nshared features for both tasks, resulting in degraded performance due to the\nincompatibility of the two tasks. To address this issue, we propose to perform\nclassification and regression on features of different characteristics,\nextracted by two network branches of different designs. Concretely, the\nregression branch extracts rotation-sensitive features by actively rotating the\nconvolutional filters, while the classification branch extracts\nrotation-invariant features by pooling the rotation-sensitive features. The\nproposed method named Rotation-sensitive Regression Detector (RRD) achieves\nstate-of-the-art performance on three oriented scene text benchmark datasets,\nincluding ICDAR 2015, MSRA-TD500, RCTW-17 and COCO-Text. Furthermore, RRD\nachieves a significant improvement on a ship collection dataset, demonstrating\nits generality on oriented object detection. \n\n"}
{"id": "1803.05785", "contents": "Title: Aggregated Sparse Attention for Steering Angle Prediction Abstract: In this paper, we apply the attention mechanism to autonomous driving for\nsteering angle prediction. We propose the first model, applying the recently\nintroduced sparse attention mechanism to visual domain, as well as the\naggregated extension for this model. We show the improvement of the proposed\nmethod, comparing to no attention as well as to different types of attention. \n\n"}
{"id": "1803.06459", "contents": "Title: Learning to Cluster for Proposal-Free Instance Segmentation Abstract: This work proposed a novel learning objective to train a deep neural network\nto perform end-to-end image pixel clustering. We applied the approach to\ninstance segmentation, which is at the intersection of image semantic\nsegmentation and object detection. We utilize the most fundamental property of\ninstance labeling -- the pairwise relationship between pixels -- as the\nsupervision to formulate the learning objective, then apply it to train a fully\nconvolutional network (FCN) for learning to perform pixel-wise clustering. The\nresulting clusters can be used as the instance labeling directly. To support\nlabeling of an unlimited number of instance, we further formulate ideas from\ngraph coloring theory into the proposed learning objective. The evaluation on\nthe Cityscapes dataset demonstrates strong performance and therefore proof of\nthe concept. Moreover, our approach won the second place in the lane detection\ncompetition of 2017 CVPR Autonomous Driving Challenge, and was the top\nperformer without using external data. \n\n"}
{"id": "1803.06492", "contents": "Title: Evolving Deep Convolutional Neural Networks by Variable-length Particle\n  Swarm Optimization for Image Classification Abstract: Convolutional neural networks (CNNs) are one of the most effective deep\nlearning methods to solve image classification problems, but the best\narchitecture of a CNN to solve a specific problem can be extremely complicated\nand hard to design. This paper focuses on utilising Particle Swarm Optimisation\n(PSO) to automatically search for the optimal architecture of CNNs without any\nmanual work involved. In order to achieve the goal, three improvements are made\nbased on traditional PSO. First, a novel encoding strategy inspired by computer\nnetworks which empowers particle vectors to easily encode CNN layers is\nproposed; Second, in order to allow the proposed method to learn\nvariable-length CNN architectures, a Disabled layer is designed to hide some\ndimensions of the particle vector to achieve variable-length particles; Third,\nsince the learning process on large data is slow, partial datasets are randomly\npicked for the evaluation to dramatically speed it up. The proposed algorithm\nis examined and compared with 12 existing algorithms including the state-of-art\nmethods on three widely used image classification benchmark datasets. The\nexperimental results show that the proposed algorithm is a strong competitor to\nthe state-of-art algorithms in terms of classification error. This is the first\nwork using PSO for automatically evolving the architectures of CNNs. \n\n"}
{"id": "1803.06744", "contents": "Title: Fast Neural Architecture Construction using EnvelopeNets Abstract: Fast Neural Architecture Construction (NAC) is a method to construct deep\nnetwork architectures by pruning and expansion of a base network. In recent\nyears, several automated search methods for neural network architectures have\nbeen proposed using methods such as evolutionary algorithms and reinforcement\nlearning. These methods use a single scalar objective function (usually\naccuracy) that is evaluated after a full training and evaluation cycle. In\ncontrast NAC directly compares the utility of different filters using\nstatistics derived from filter featuremaps reach a state where the utility of\ndifferent filters within a network can be compared and hence can be used to\nconstruct networks. The training epochs needed for filters within a network to\nreach this state is much less than the training epochs needed for the accuracy\nof a network to stabilize. NAC exploits this finding to construct convolutional\nneural nets (CNNs) with close to state of the art accuracy, in < 1 GPU day,\nfaster than most of the current neural architecture search methods. The\nconstructed networks show close to state of the art performance on the image\nclassification problem on well known datasets (CIFAR-10, ImageNet) and\nconsistently show better performance than hand constructed and randomly\ngenerated networks of the same depth, operators and approximately the same\nnumber of parameters. \n\n"}
{"id": "1803.07125", "contents": "Title: Local Binary Pattern Networks Abstract: Memory and computation efficient deep learning architec- tures are crucial to\ncontinued proliferation of machine learning capabili- ties to new platforms and\nsystems. Binarization of operations in convo- lutional neural networks has\nshown promising results in reducing model size and computing efficiency. In\nthis paper, we tackle the problem us- ing a strategy different from the\nexisting literature by proposing local binary pattern networks or LBPNet, that\nis able to learn and perform binary operations in an end-to-end fashion.\nLBPNet1 uses local binary comparisons and random projection in place of\nconventional convolu- tion (or approximation of convolution) operations. These\noperations can be implemented efficiently on different platforms including\ndirect hard- ware implementation. We applied LBPNet and its variants on\nstandard benchmarks. The results are promising across benchmarks while provid-\ning an important means to improve memory and speed efficiency that is\nparticularly suited for small footprint devices and hardware accelerators. \n\n"}
{"id": "1803.07985", "contents": "Title: BioTracker: An Open-Source Computer Vision Framework for Visual Animal\n  Tracking Abstract: The study of animal behavior increasingly relies on (semi-) automatic methods\nfor the extraction of relevant behavioral features from video or picture data.\nTo date, several specialized software products exist to detect and track\nanimals' positions in simple (laboratory) environments. Tracking animals in\ntheir natural environments, however, often requires substantial customization\nof the image processing algorithms to the problem-specific image\ncharacteristics. Here we introduce BioTracker, an open-source computer vision\nframework, that provides programmers with core functionalities that are\nessential parts of a tracking software, such as video I/O, graphics overlays\nand mouse and keyboard interfaces. BioTracker additionally provides a number of\ndifferent tracking algorithms suitable for a variety of image recording\nconditions. The main feature of BioTracker is however the straightforward\nimplementation of new problem-specific tracking modules and vision algorithms\nthat can build upon BioTracker's core functionalities. With this open-source\nframework the scientific community can accelerate their research and focus on\nthe development of new vision algorithms. \n\n"}
{"id": "1803.08024", "contents": "Title: Stacked Cross Attention for Image-Text Matching Abstract: In this paper, we study the problem of image-text matching. Inferring the\nlatent semantic alignment between objects or other salient stuff (e.g. snow,\nsky, lawn) and the corresponding words in sentences allows to capture\nfine-grained interplay between vision and language, and makes image-text\nmatching more interpretable. Prior work either simply aggregates the similarity\nof all possible pairs of regions and words without attending differentially to\nmore and less important words or regions, or uses a multi-step attentional\nprocess to capture limited number of semantic alignments which is less\ninterpretable. In this paper, we present Stacked Cross Attention to discover\nthe full latent alignments using both image regions and words in a sentence as\ncontext and infer image-text similarity. Our approach achieves the\nstate-of-the-art results on the MS-COCO and Flickr30K datasets. On Flickr30K,\nour approach outperforms the current best methods by 22.1% relatively in text\nretrieval from image query, and 18.2% relatively in image retrieval with text\nquery (based on Recall@1). On MS-COCO, our approach improves sentence retrieval\nby 17.8% relatively and image retrieval by 16.6% relatively (based on Recall@1\nusing the 5K test set). Code has been made available at:\nhttps://github.com/kuanghuei/SCAN. \n\n"}
{"id": "1803.08375", "contents": "Title: Deep Learning using Rectified Linear Units (ReLU) Abstract: We introduce the use of rectified linear units (ReLU) as the classification\nfunction in a deep neural network (DNN). Conventionally, ReLU is used as an\nactivation function in DNNs, with Softmax function as their classification\nfunction. However, there have been several studies on using a classification\nfunction other than Softmax, and this study is an addition to those. We\naccomplish this by taking the activation of the penultimate layer $h_{n - 1}$\nin a neural network, then multiply it by weight parameters $\\theta$ to get the\nraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,\ni.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide\nclass predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$. \n\n"}
{"id": "1803.08636", "contents": "Title: PDNet: Prior-model Guided Depth-enhanced Network for Salient Object\n  Detection Abstract: Fully convolutional neural networks (FCNs) have shown outstanding performance\nin many computer vision tasks including salient object detection. However,\nthere still remains two issues needed to be addressed in deep learning based\nsaliency detection. One is the lack of tremendous amount of annotated data to\ntrain a network. The other is the lack of robustness for extracting salient\nobjects in images containing complex scenes. In this paper, we present a new\narchitecture$ - $PDNet, a robust prior-model guided depth-enhanced network for\nRGB-D salient object detection. In contrast to existing works, in which RGB-D\nvalues of image pixels are fed directly to a network, the proposed architecture\nis composed of a master network for processing RGB values, and a sub-network\nmaking full use of depth cues and incorporate depth-based features into the\nmaster network. To overcome the limited size of the labeled RGB-D dataset for\ntraining, we employ a large conventional RGB dataset to pre-train the master\nnetwork, which proves to contribute largely to the final accuracy. Extensive\nevaluations over five benchmark datasets demonstrate that our proposed method\nperforms favorably against the state-of-the-art approaches. \n\n"}
{"id": "1803.08740", "contents": "Title: Speeding-up Object Detection Training for Robotics with FALKON Abstract: Latest deep learning methods for object detection provide remarkable\nperformance, but have limits when used in robotic applications. One of the most\nrelevant issues is the long training time, which is due to the large size and\nimbalance of the associated training sets, characterized by few positive and a\nlarge number of negative examples (i.e. background). Proposed approaches are\nbased on end-to-end learning by back-propagation [22] or kernel methods trained\nwith Hard Negatives Mining on top of deep features [8]. These solutions are\neffective, but prohibitively slow for on-line applications. In this paper we\npropose a novel pipeline for object detection that overcomes this problem and\nprovides comparable performance, with a 60x training speedup. Our pipeline\ncombines (i) the Region Proposal Network and the deep feature extractor from\n[22] to efficiently select candidate RoIs and encode them into powerful\nrepresentations, with (ii) the FALKON [23] algorithm, a novel kernel-based\nmethod that allows fast training on large scale problems (millions of points).\nWe address the size and imbalance of training data by exploiting the stochastic\nsubsampling intrinsic into the method and a novel, fast, bootstrapping\napproach. We assess the effectiveness of the approach on a standard Computer\nVision dataset (PASCAL VOC 2007 [5]) and demonstrate its applicability to a\nreal robotic scenario with the iCubWorld Transformations [18] dataset. \n\n"}
{"id": "1803.09014", "contents": "Title: Feature Transfer Learning for Deep Face Recognition with\n  Under-Represented Data Abstract: Despite the large volume of face recognition datasets, there is a significant\nportion of subjects, of which the samples are insufficient and thus\nunder-represented. Ignoring such significant portion results in insufficient\ntraining data. Training with under-represented data leads to biased classifiers\nin conventionally-trained deep networks. In this paper, we propose a\ncenter-based feature transfer framework to augment the feature space of\nunder-represented subjects from the regular subjects that have sufficiently\ndiverse samples. A Gaussian prior of the variance is assumed across all\nsubjects and the variance from regular ones are transferred to the\nunder-represented ones. This encourages the under-represented distribution to\nbe closer to the regular distribution. Further, an alternating training regimen\nis proposed to simultaneously achieve less biased classifiers and a more\ndiscriminative feature representation. We conduct ablative study to mimic the\nunder-represented datasets by varying the portion of under-represented classes\non the MS-Celeb-1M dataset. Advantageous results on LFW, IJB-A and MS-Celeb-1M\ndemonstrate the effectiveness of our feature transfer and training strategy,\ncompared to both general baselines and state-of-the-art methods. Moreover, our\nfeature transfer successfully presents smooth visual interpolation, which\nconducts disentanglement to preserve identity of a class while augmenting its\nfeature space with non-identity variations such as pose and lighting. \n\n"}
{"id": "1803.09172", "contents": "Title: Multiple Sclerosis Lesion Segmentation from Brain MRI via Fully\n  Convolutional Neural Networks Abstract: Multiple Sclerosis (MS) is an autoimmune disease that leads to lesions in the\ncentral nervous system. Magnetic resonance (MR) images provide sufficient\nimaging contrast to visualize and detect lesions, particularly those in the\nwhite matter. Quantitative measures based on various features of lesions have\nbeen shown to be useful in clinical trials for evaluating therapies. Therefore\nrobust and accurate segmentation of white matter lesions from MR images can\nprovide important information about the disease status and progression. In this\npaper, we propose a fully convolutional neural network (CNN) based method to\nsegment white matter lesions from multi-contrast MR images. The proposed CNN\nbased method contains two convolutional pathways. The first pathway consists of\nmultiple parallel convolutional filter banks catering to multiple MR\nmodalities. In the second pathway, the outputs of the first one are\nconcatenated and another set of convolutional filters are applied. The output\nof this last pathway produces a membership function for lesions that may be\nthresholded to obtain a binary segmentation. The proposed method is evaluated\non a dataset of 100 MS patients, as well as the ISBI 2015 challenge data\nconsisting of 14 patients. The comparison is performed against four publicly\navailable MS lesion segmentation methods. Significant improvement in\nsegmentation quality over the competing methods is demonstrated on various\nmetrics, such as Dice and false positive ratio. While evaluating on the ISBI\n2015 challenge data, our method produces a score of 90.48, where a score of 90\nis considered to be comparable to a human rater. \n\n"}
{"id": "1803.09180", "contents": "Title: Unsupervised Domain Adaptation: from Simulation Engine to the RealWorld Abstract: Large-scale labeled training datasets have enabled deep neural networks to\nexcel on a wide range of benchmark vision tasks. However, in many applications\nit is prohibitively expensive or time-consuming to obtain large quantities of\nlabeled data. To cope with limited labeled training data, many have attempted\nto directly apply models trained on a large-scale labeled source domain to\nanother sparsely labeled target domain. Unfortunately, direct transfer across\ndomains often performs poorly due to domain shift and dataset bias. Domain\nadaptation is the machine learning paradigm that aims to learn a model from a\nsource domain that can perform well on a different (but related) target domain.\nIn this paper, we summarize and compare the latest unsupervised domain\nadaptation methods in computer vision applications. We classify the non-deep\napproaches into sample re-weighting and intermediate subspace transformation\ncategories, while the deep strategy includes discrepancy-based methods,\nadversarial generative models, adversarial discriminative models and\nreconstruction-based methods. We also discuss some potential directions. \n\n"}
{"id": "1803.09672", "contents": "Title: On the Intrinsic Dimensionality of Image Representations Abstract: This paper addresses the following questions pertaining to the intrinsic\ndimensionality of any given image representation: (i) estimate its intrinsic\ndimensionality, (ii) develop a deep neural network based non-linear mapping,\ndubbed DeepMDS, that transforms the ambient representation to the minimal\nintrinsic space, and (iii) validate the veracity of the mapping through image\nmatching in the intrinsic space. Experiments on benchmark image datasets (LFW,\nIJB-C and ImageNet-100) reveal that the intrinsic dimensionality of deep neural\nnetwork representations is significantly lower than the dimensionality of the\nambient features. For instance, SphereFace's 512-dim face representation and\nResNet's 512-dim image representation have an intrinsic dimensionality of 16\nand 19 respectively. Further, the DeepMDS mapping is able to obtain a\nrepresentation of significantly lower dimensionality while maintaining\ndiscriminative ability to a large extent, 59.75% TAR @ 0.1% FAR in 16-dim vs\n71.26% TAR in 512-dim on IJB-C and a Top-1 accuracy of 77.0% at 19-dim vs 83.4%\nat 512-dim on ImageNet-100. \n\n"}
{"id": "1803.09820", "contents": "Title: A disciplined approach to neural network hyper-parameters: Part 1 --\n  learning rate, batch size, momentum, and weight decay Abstract: Although deep learning has produced dazzling successes for applications of\nimage, speech, and video processing in the past few years, most trainings are\nwith suboptimal hyper-parameters, requiring unnecessarily long training times.\nSetting the hyper-parameters remains a black art that requires years of\nexperience to acquire. This report proposes several efficient ways to set the\nhyper-parameters that significantly reduce training time and improves\nperformance. Specifically, this report shows how to examine the training\nvalidation/test loss function for subtle clues of underfitting and overfitting\nand suggests guidelines for moving toward the optimal balance point. Then it\ndiscusses how to increase/decrease the learning rate/momentum to speed up\ntraining. Our experiments show that it is crucial to balance every manner of\nregularization for each dataset and architecture. Weight decay is used as a\nsample regularizer to show how its optimal value is tightly coupled with the\nlearning rates and momentums. Files to help replicate the results reported here\nare available. \n\n"}
{"id": "1803.09882", "contents": "Title: Diversity Regularized Spatiotemporal Attention for Video-based Person\n  Re-identification Abstract: Video-based person re-identification matches video clips of people across\nnon-overlapping cameras. Most existing methods tackle this problem by encoding\neach video frame in its entirety and computing an aggregate representation\nacross all frames. In practice, people are often partially occluded, which can\ncorrupt the extracted features. Instead, we propose a new spatiotemporal\nattention model that automatically discovers a diverse set of distinctive body\nparts. This allows useful information to be extracted from all frames without\nsuccumbing to occlusions and misalignments. The network learns multiple spatial\nattention models and employs a diversity regularization term to ensure multiple\nmodels do not discover the same body part. Features extracted from local image\nregions are organized by spatial attention model and are combined using\ntemporal attention. As a result, the network learns latent representations of\nthe face, torso and other body parts using the best available image patches\nfrom the entire video sequence. Extensive evaluations on three datasets show\nthat our framework outperforms the state-of-the-art approaches by large margins\non multiple metrics. \n\n"}
{"id": "1803.10560", "contents": "Title: Normalization of Neural Networks using Analytic Variance Propagation Abstract: We address the problem of estimating statistics of hidden units in a neural\nnetwork using a method of analytic moment propagation. These statistics are\nuseful for approximate whitening of the inputs in front of saturating\nnon-linearities such as a sigmoid function. This is important for\ninitialization of training and for reducing the accumulated scale and bias\ndependencies (compensating covariate shift), which presumably eases the\nlearning. In batch normalization, which is currently a very widely applied\ntechnique, sample estimates of statistics of hidden units over a batch are\nused. The proposed estimation uses an analytic propagation of mean and variance\nof the training set through the network. The result depends on the network\nstructure and its current weights but not on the specific batch input. The\nestimates are suitable for initialization and normalization, efficient to\ncompute and independent of the batch size. The experimental verification well\nsupports these claims. However, the method does not share the generalization\nproperties of BN, to which our experiments give some additional insight. \n\n"}
{"id": "1803.10932", "contents": "Title: Learning Free-Form Deformations for 3D Object Reconstruction Abstract: Representing 3D shape in deep learning frameworks in an accurate, efficient\nand compact manner still remains an open challenge. Most existing work\naddresses this issue by employing voxel-based representations. While these\napproaches benefit greatly from advances in computer vision by generalizing 2D\nconvolutions to the 3D setting, they also have several considerable drawbacks.\nThe computational complexity of voxel-encodings grows cubically with the\nresolution thus limiting such representations to low-resolution 3D\nreconstruction. In an attempt to solve this problem, point cloud\nrepresentations have been proposed. Although point clouds are more efficient\nthan voxel representations as they only cover surfaces rather than volumes,\nthey do not encode detailed geometric information about relationships between\npoints. In this paper we propose a method to learn free-form deformations (FFD)\nfor the task of 3D reconstruction from a single image. By learning to deform\npoints sampled from a high-quality mesh, our trained model can be used to\nproduce arbitrarily dense point clouds or meshes with fine-grained geometry. We\nevaluate our proposed framework on both synthetic and real-world data and\nachieve state-of-the-art results on point-cloud and volumetric metrics.\nAdditionally, we qualitatively demonstrate its applicability to label\ntransferring for 3D semantic segmentation. \n\n"}
{"id": "1803.11232", "contents": "Title: Euphrates: Algorithm-SoC Co-Design for Low-Power Mobile Continuous\n  Vision Abstract: Continuous computer vision (CV) tasks increasingly rely on convolutional\nneural networks (CNN). However, CNNs have massive compute demands that far\nexceed the performance and energy constraints of mobile devices. In this paper,\nwe propose and develop an algorithm-architecture co-designed system, Euphrates,\nthat simultaneously improves the energy-efficiency and performance of\ncontinuous vision tasks.\n  Our key observation is that changes in pixel data between consecutive frames\nrepresents visual motion. We first propose an algorithm that leverages this\nmotion information to relax the number of expensive CNN inferences required by\ncontinuous vision applications. We co-design a mobile System-on-a-Chip (SoC)\narchitecture to maximize the efficiency of the new algorithm. The key to our\narchitectural augmentation is to co-optimize different SoC IP blocks in the\nvision pipeline collectively. Specifically, we propose to expose the motion\ndata that is naturally generated by the Image Signal Processor (ISP) early in\nthe vision pipeline to the CNN engine. Measurement and synthesis results show\nthat Euphrates achieves up to 66% SoC-level energy savings (4 times for the\nvision computations), with only 1% accuracy loss. \n\n"}
{"id": "1803.11395", "contents": "Title: Contrast-Oriented Deep Neural Networks for Salient Object Detection Abstract: Deep convolutional neural networks have become a key element in the recent\nbreakthrough of salient object detection. However, existing CNN-based methods\nare based on either patch-wise (region-wise) training and inference or fully\nconvolutional networks. Methods in the former category are generally\ntime-consuming due to severe storage and computational redundancies among\noverlapping patches. To overcome this deficiency, methods in the second\ncategory attempt to directly map a raw input image to a predicted dense\nsaliency map in a single network forward pass. Though being very efficient, it\nis arduous for these methods to detect salient objects of different scales or\nsalient regions with weak semantic information. In this paper, we develop\nhybrid contrast-oriented deep neural networks to overcome the aforementioned\nlimitations. Each of our deep networks is composed of two complementary\ncomponents, including a fully convolutional stream for dense prediction and a\nsegment-level spatial pooling stream for sparse saliency inference. We further\npropose an attentional module that learns weight maps for fusing the two\nsaliency predictions from these two streams. A tailored alternate scheme is\ndesigned to train these deep networks by fine-tuning pre-trained baseline\nmodels. Finally, a customized fully connected CRF model incorporating a salient\ncontour feature embedding can be optionally applied as a post-processing step\nto improve spatial coherence and contour positioning in the fused result from\nthese two streams. Extensive experiments on six benchmark datasets demonstrate\nthat our proposed model can significantly outperform the state of the art in\nterms of all popular evaluation metrics. \n\n"}
{"id": "1803.11410", "contents": "Title: The Resistance to Label Noise in K-NN and DNN Depends on its\n  Concentration Abstract: We investigate the classification performance of K-nearest neighbors (K-NN)\nand deep neural networks (DNNs) in the presence of label noise. We first show\nempirically that a DNN's prediction for a given test example depends on the\nlabels of the training examples in its local neighborhood. This motivates us to\nderive a realizable analytic expression that approximates the multi-class K-NN\nclassification error in the presence of label noise, which is of independent\nimportance. We then suggest that the expression for K-NN may serve as a\nfirst-order approximation for the DNN error. Finally, we demonstrate\nempirically the proximity of the developed expression to the observed\nperformance of K-NN and DNN classifiers. Our result may explain the already\nobserved surprising resistance of DNN to some types of label noise. It also\ncharacterizes an important factor of it showing that the more concentrated the\nnoise the greater is the degradation in performance. \n\n"}
{"id": "1803.11493", "contents": "Title: 3D Pose Estimation and 3D Model Retrieval for Objects in the Wild Abstract: We propose a scalable, efficient and accurate approach to retrieve 3D models\nfor objects in the wild. Our contribution is twofold. We first present a 3D\npose estimation approach for object categories which significantly outperforms\nthe state-of-the-art on Pascal3D+. Second, we use the estimated pose as a prior\nto retrieve 3D models which accurately represent the geometry of objects in RGB\nimages. For this purpose, we render depth images from 3D models under our\npredicted pose and match learned image descriptors of RGB images against those\nof rendered depth images using a CNN-based multi-view metric learning approach.\nIn this way, we are the first to report quantitative results for 3D model\nretrieval on Pascal3D+, where our method chooses the same models as human\nannotators for 50% of the validation images on average. In addition, we show\nthat our method, which was trained purely on Pascal3D+, retrieves rich and\naccurate 3D models from ShapeNet given RGB images of objects in the wild. \n\n"}
{"id": "1804.00326", "contents": "Title: Seeing Voices and Hearing Faces: Cross-modal biometric matching Abstract: We introduce a seemingly impossible task: given only an audio clip of someone\nspeaking, decide which of two face images is the speaker. In this paper we\nstudy this, and a number of related cross-modal tasks, aimed at answering the\nquestion: how much can we infer from the voice about the face and vice versa?\nWe study this task \"in the wild\", employing the datasets that are now publicly\navailable for face recognition from static images (VGGFace) and speaker\nidentification from audio (VoxCeleb). These provide training and testing\nscenarios for both static and dynamic testing of cross-modal matching. We make\nthe following contributions: (i) we introduce CNN architectures for both binary\nand multi-way cross-modal face and audio matching, (ii) we compare dynamic\ntesting (where video information is available, but the audio is not from the\nsame video) with static testing (where only a single still image is available),\nand (iii) we use human testing as a baseline to calibrate the difficulty of the\ntask. We show that a CNN can indeed be trained to solve this task in both the\nstatic and dynamic scenarios, and is even well above chance on 10-way\nclassification of the face given the voice. The CNN matches human performance\non easy examples (e.g. different gender across faces) but exceeds human\nperformance on more challenging examples (e.g. faces with the same gender, age\nand nationality). \n\n"}
{"id": "1804.00504", "contents": "Title: Generalizability vs. Robustness: Adversarial Examples for Medical\n  Imaging Abstract: In this paper, for the first time, we propose an evaluation method for deep\nlearning models that assesses the performance of a model not only in an unseen\ntest scenario, but also in extreme cases of noise, outliers and ambiguous input\ndata. To this end, we utilize adversarial examples, images that fool machine\nlearning models, while looking imperceptibly different from original data, as a\nmeasure to evaluate the robustness of a variety of medical imaging models.\nThrough extensive experiments on skin lesion classification and whole brain\nsegmentation with state-of-the-art networks such as Inception and UNet, we show\nthat models that achieve comparable performance regarding generalizability may\nhave significant variations in their perception of the underlying data\nmanifold, leading to an extensive performance gap in their robustness. \n\n"}
{"id": "1804.00532", "contents": "Title: Predictions of short-term driving intention using recurrent neural\n  network on sequential data Abstract: Predictions of driver's intentions and their behaviors using the road is of\ngreat importance for planning and decision making processes of autonomous\ndriving vehicles. In particular, relatively short-term driving intentions are\nthe fundamental units that constitute more sophisticated driving goals,\nbehaviors, such as overtaking the slow vehicle in front, exit or merge onto a\nhigh way, etc. While it is not uncommon that most of the time human driver can\nrationalize, in advance, various on-road behaviors, intentions, as well as the\nassociated risks, aggressiveness, reciprocity characteristics, etc., such\nreasoning skills can be challenging and difficult for an autonomous driving\nsystem to learn. In this article, we demonstrate a disciplined methodology that\ncan be used to build and train a predictive drive system, therefore to learn\nthe on-road characteristics aforementioned. \n\n"}
{"id": "1804.00582", "contents": "Title: Learning Intrinsic Image Decomposition from Watching the World Abstract: Single-view intrinsic image decomposition is a highly ill-posed problem, and\nso a promising approach is to learn from large amounts of data. However, it is\ndifficult to collect ground truth training data at scale for intrinsic images.\nIn this paper, we explore a different approach to learning intrinsic images:\nobserving image sequences over time depicting the same scene under changing\nillumination, and learning single-view decompositions that are consistent with\nthese changes. This approach allows us to learn without ground truth\ndecompositions, and to instead exploit information available from multiple\nimages when training. Our trained model can then be applied at test time to\nsingle views. We describe a new learning framework based on this idea,\nincluding new loss functions that can be efficiently evaluated over entire\nsequences. While prior learning-based methods achieve good performance on\nspecific benchmarks, we show that our approach generalizes well to several\ndiverse datasets, including MIT intrinsic images, Intrinsic Images in the Wild\nand Shading Annotations in the Wild. \n\n"}
{"id": "1804.00645", "contents": "Title: Universal Planning Networks Abstract: A key challenge in complex visuomotor control is learning abstract\nrepresentations that are effective for specifying goals, planning, and\ngeneralization. To this end, we introduce universal planning networks (UPN).\nUPNs embed differentiable planning within a goal-directed policy. This planning\ncomputation unrolls a forward model in a latent space and infers an optimal\naction plan through gradient descent trajectory optimization. The\nplan-by-gradient-descent process and its underlying representations are learned\nend-to-end to directly optimize a supervised imitation learning objective. We\nfind that the representations learned are not only effective for goal-directed\nvisual imitation via gradient-based trajectory optimization, but can also\nprovide a metric for specifying goals using images. The learned representations\ncan be leveraged to specify distance-based rewards to reach new target states\nfor model-free reinforcement learning, resulting in substantially more\neffective learning when solving new tasks described via image-based goals. We\nwere able to achieve successful transfer of visuomotor planning strategies\nacross robots with significantly different morphologies and actuation\ncapabilities. \n\n"}
{"id": "1804.00722", "contents": "Title: Hierarchical Novelty Detection for Visual Object Recognition Abstract: Deep neural networks have achieved impressive success in large-scale visual\nobject recognition tasks with a predefined set of classes. However, recognizing\nobjects of novel classes unseen during training still remains challenging. The\nproblem of detecting such novel classes has been addressed in the literature,\nbut most prior works have focused on providing simple binary or regressive\ndecisions, e.g., the output would be \"known,\" \"novel,\" or corresponding\nconfidence intervals. In this paper, we study more informative novelty\ndetection schemes based on a hierarchical classification framework. For an\nobject of a novel class, we aim for finding its closest super class in the\nhierarchical taxonomy of known classes. To this end, we propose two different\napproaches termed top-down and flatten methods, and their combination as well.\nThe essential ingredients of our methods are confidence-calibrated classifiers,\ndata relabeling, and the leave-one-out strategy for modeling novel classes\nunder the hierarchical taxonomy. Furthermore, our method can generate a\nhierarchical embedding that leads to improved generalized zero-shot learning\nperformance in combination with other commonly-used semantic embeddings. \n\n"}
{"id": "1804.01118", "contents": "Title: Synthesizing Programs for Images using Reinforced Adversarial Learning Abstract: Advances in deep generative networks have led to impressive results in recent\nyears. Nevertheless, such models can often waste their capacity on the minutiae\nof datasets, presumably due to weak inductive biases in their decoders. This is\nwhere graphics engines may come in handy since they abstract away low-level\ndetails and represent images as high-level programs. Current methods that\ncombine deep learning and renderers are limited by hand-crafted likelihood or\ndistance functions, a need for large amounts of supervision, or difficulties in\nscaling their inference algorithms to richer datasets. To mitigate these\nissues, we present SPIRAL, an adversarially trained agent that generates a\nprogram which is executed by a graphics engine to interpret and sample images.\nThe goal of this agent is to fool a discriminator network that distinguishes\nbetween real and rendered data, trained with a distributed reinforcement\nlearning setup without any supervision. A surprising finding is that using the\ndiscriminator's output as a reward signal is the key to allow the agent to make\nmeaningful progress at matching the desired output rendering. To the best of\nour knowledge, this is the first demonstration of an end-to-end, unsupervised\nand adversarial inverse graphics agent on challenging real world (MNIST,\nOmniglot, CelebA) and synthetic 3D datasets. \n\n"}
{"id": "1804.02204", "contents": "Title: Sequence Training of DNN Acoustic Models With Natural Gradient Abstract: Deep Neural Network (DNN) acoustic models often use discriminative sequence\ntraining that optimises an objective function that better approximates the word\nerror rate (WER) than frame-based training. Sequence training is normally\nimplemented using Stochastic Gradient Descent (SGD) or Hessian Free (HF)\ntraining. This paper proposes an alternative batch style optimisation framework\nthat employs a Natural Gradient (NG) approach to traverse through the parameter\nspace. By correcting the gradient according to the local curvature of the\nKL-divergence, the NG optimisation process converges more quickly than HF.\nFurthermore, the proposed NG approach can be applied to any sequence\ndiscriminative training criterion. The efficacy of the NG method is shown using\nexperiments on a Multi-Genre Broadcast (MGB) transcription task that\ndemonstrates both the computational efficiency and the accuracy of the\nresulting DNN models. \n\n"}
{"id": "1804.02595", "contents": "Title: Training Multi-organ Segmentation Networks with Sample Selection by\n  Relaxed Upper Confident Bound Abstract: Deep convolutional neural networks (CNNs), especially fully convolutional\nnetworks, have been widely applied to automatic medical image segmentation\nproblems, e.g., multi-organ segmentation. Existing CNN-based segmentation\nmethods mainly focus on looking for increasingly powerful network\narchitectures, but pay less attention to data sampling strategies for training\nnetworks more effectively. In this paper, we present a simple but effective\nsample selection method for training multi-organ segmentation networks. Sample\nselection exhibits an exploitation-exploration strategy, i.e., exploiting hard\nsamples and exploring less frequently visited samples. Based on the fact that\nvery hard samples might have annotation errors, we propose a new sample\nselection policy, named Relaxed Upper Confident Bound (RUCB). Compared with\nother sample selection policies, e.g., Upper Confident Bound (UCB), it exploits\na range of hard samples rather than being stuck with a small set of very hard\nones, which mitigates the influence of annotation errors during training. We\napply this new sample selection policy to training a multi-organ segmentation\nnetwork on a dataset containing 120 abdominal CT scans and show that it boosts\nsegmentation performance significantly. \n\n"}
{"id": "1804.02792", "contents": "Title: Occluded Person Re-identification Abstract: Person re-identification (re-id) suffers from a serious occlusion problem\nwhen applied to crowded public places. In this paper, we propose to retrieve a\nfull-body person image by using a person image with occlusions. This differs\nsignificantly from the conventional person re-id problem where it is assumed\nthat person images are detected without any occlusion. We thus call this new\nproblem the occluded person re-identitification. To address this new problem,\nwe propose a novel Attention Framework of Person Body (AFPB) based on deep\nlearning, consisting of 1) an Occlusion Simulator (OS) which automatically\ngenerates artificial occlusions for full-body person images, and 2) multi-task\nlosses that force the neural network not only to discriminate a person's\nidentity but also to determine whether a sample is from the occluded data\ndistribution or the full-body data distribution. Experiments on a new occluded\nperson re-id dataset and three existing benchmarks modified to include\nfull-body person images and occluded person images show the superiority of the\nproposed method. \n\n"}
{"id": "1804.03294", "contents": "Title: A Systematic DNN Weight Pruning Framework using Alternating Direction\n  Method of Multipliers Abstract: Weight pruning methods for deep neural networks (DNNs) have been investigated\nrecently, but prior work in this area is mainly heuristic, iterative pruning,\nthereby lacking guarantees on the weight reduction ratio and convergence time.\nTo mitigate these limitations, we present a systematic weight pruning framework\nof DNNs using the alternating direction method of multipliers (ADMM). We first\nformulate the weight pruning problem of DNNs as a nonconvex optimization\nproblem with combinatorial constraints specifying the sparsity requirements,\nand then adopt the ADMM framework for systematic weight pruning. By using ADMM,\nthe original nonconvex optimization problem is decomposed into two subproblems\nthat are solved iteratively. One of these subproblems can be solved using\nstochastic gradient descent, the other can be solved analytically. Besides, our\nmethod achieves a fast convergence rate.\n  The weight pruning results are very promising and consistently outperform the\nprior work. On the LeNet-5 model for the MNIST data set, we achieve 71.2 times\nweight reduction without accuracy loss. On the AlexNet model for the ImageNet\ndata set, we achieve 21 times weight reduction without accuracy loss. When we\nfocus on the convolutional layer pruning for computation reductions, we can\nreduce the total computation by five times compared with the prior work\n(achieving a total of 13.4 times weight reduction in convolutional layers). Our\nmodels and codes are released at https://github.com/KaiqiZhang/admm-pruning \n\n"}
{"id": "1804.03313", "contents": "Title: Cortex Neural Network: learning with Neural Network groups Abstract: Neural Network has been successfully applied to many real-world problems,\nsuch as image recognition and machine translation. However, for the current\narchitecture of neural networks, it is hard to perform complex cognitive tasks,\nfor example, to process the image and audio inputs together. Cortex, as an\nimportant architecture in the brain, is important for animals to perform the\ncomplex cognitive task. We view the architecture of Cortex in the brain as a\nmissing part in the design of the current artificial neural network. In this\npaper, we purpose Cortex Neural Network (CrtxNN). The Cortex Neural Network is\nan upper architecture of neural networks which motivated from cerebral cortex\nin the brain to handle different tasks in the same learning system. It is able\nto identify different tasks and solve them with different methods. In our\nimplementation, the Cortex Neural Network is able to process different\ncognitive tasks and perform reflection to get a higher accuracy. We provide a\nseries of experiments to examine the capability of the cortex architecture on\ntraditional neural networks. Our experiments proved its ability on the Cortex\nNeural Network can reach accuracy by 98.32% on MNIST and 62% on CIFAR10 at the\nsame time, which can promisingly reduce the loss by 40%. \n\n"}
{"id": "1804.03360", "contents": "Title: Reference-Conditioned Super-Resolution by Neural Texture Transfer Abstract: With the recent advancement in deep learning, we have witnessed a great\nprogress in single image super-resolution. However, due to the significant\ninformation loss of the image downscaling process, it has become extremely\nchallenging to further advance the state-of-the-art, especially for large\nupscaling factors. This paper explores a new research direction in super\nresolution, called reference-conditioned super-resolution, in which a reference\nimage containing desired high-resolution texture details is provided besides\nthe low-resolution image. We focus on transferring the high-resolution texture\nfrom reference images to the super-resolution process without the constraint of\ncontent similarity between reference and target images, which is a key\ndifference from previous example-based methods. Inspired by recent work on\nimage stylization, we address the problem via neural texture transfer. We\ndesign an end-to-end trainable deep model which generates detail enriched\nresults by adaptively fusing the content from the low-resolution image with the\ntexture patterns from the reference image. We create a benchmark dataset for\nthe general research of reference-based super-resolution, which contains\nreference images paired with low-resolution inputs with varying degrees of\nsimilarity. Both objective and subjective evaluations demonstrate the great\npotential of using reference images as well as the superiority of our results\nover other state-of-the-art methods. \n\n"}
{"id": "1804.03596", "contents": "Title: A Deep Information Sharing Network for Multi-contrast Compressed Sensing\n  MRI Reconstruction Abstract: In multi-contrast magnetic resonance imaging (MRI), compressed sensing theory\ncan accelerate imaging by sampling fewer measurements within each contrast. The\nconventional optimization-based models suffer several limitations: strict\nassumption of shared sparse support, time-consuming optimization and \"shallow\"\nmodels with difficulties in encoding the rich patterns hiding in massive MRI\ndata. In this paper, we propose the first deep learning model for\nmulti-contrast MRI reconstruction. We achieve information sharing through\nfeature sharing units, which significantly reduces the number of parameters.\nThe feature sharing unit is combined with a data fidelity unit to comprise an\ninference block. These inference blocks are cascaded with dense connections,\nwhich allows for information transmission across different depths of the\nnetwork efficiently. Our extensive experiments on various multi-contrast MRI\ndatasets show that proposed model outperforms both state-of-the-art\nsingle-contrast and multi-contrast MRI methods in accuracy and efficiency. We\nshow the improved reconstruction quality can bring great benefits for the later\nmedical image analysis stage. Furthermore, the robustness of the proposed model\nto the non-registration environment shows its potential in real MRI\napplications. \n\n"}
{"id": "1804.03867", "contents": "Title: Hybrid Binary Networks: Optimizing for Accuracy, Efficiency and Memory Abstract: Binarization is an extreme network compression approach that provides large\ncomputational speedups along with energy and memory savings, albeit at\nsignificant accuracy costs. We investigate the question of where to binarize\ninputs at layer-level granularity and show that selectively binarizing the\ninputs to specific layers in the network could lead to significant improvements\nin accuracy while preserving most of the advantages of binarization. We analyze\nthe binarization tradeoff using a metric that jointly models the input\nbinarization-error and computational cost and introduce an efficient algorithm\nto select layers whose inputs are to be binarized. Practical guidelines based\non insights obtained from applying the algorithm to a variety of models are\ndiscussed. Experiments on Imagenet dataset using AlexNet and ResNet-18 models\nshow 3-4% improvements in accuracy over fully binarized networks with minimal\nimpact on compression and computational speed. The improvements are even more\nsubstantial on sketch datasets like TU-Berlin, where we match state-of-the-art\naccuracy as well, getting over 8% increase in accuracies. We further show that\nour approach can be applied in tandem with other forms of compression that deal\nwith individual layers or overall model compression (e.g., SqueezeNets). Unlike\nprevious quantization approaches, we are able to binarize the weights in the\nlast layers of a network, which often have a large number of parameters,\nresulting in significant improvement in accuracy over fully binarized models. \n\n"}
{"id": "1804.04168", "contents": "Title: Differentiable Learning of Quantum Circuit Born Machine Abstract: Quantum circuit Born machines are generative models which represent the\nprobability distribution of classical dataset as quantum pure states.\nComputational complexity considerations of the quantum sampling problem suggest\nthat the quantum circuits exhibit stronger expressibility compared to classical\nneural networks. One can efficiently draw samples from the quantum circuits via\nprojective measurements on qubits. However, similar to the leading implicit\ngenerative models in deep learning, such as the generative adversarial\nnetworks, the quantum circuits cannot provide the likelihood of the generated\nsamples, which poses a challenge to the training. We devise an efficient\ngradient-based learning algorithm for the quantum circuit Born machine by\nminimizing the kerneled maximum mean discrepancy loss. We simulated generative\nmodeling of the Bars-and-Stripes dataset and Gaussian mixture distributions\nusing deep quantum circuits. Our experiments show the importance of circuit\ndepth and gradient-based optimization algorithm. The proposed learning\nalgorithm is runnable on near-term quantum device and can exhibit quantum\nadvantages for generative modeling. \n\n"}
{"id": "1804.04412", "contents": "Title: Unsupervised Discovery of Object Landmarks as Structural Representations Abstract: Deep neural networks can model images with rich latent representations, but\nthey cannot naturally conceptualize structures of object categories in a\nhuman-perceptible way. This paper addresses the problem of learning object\nstructures in an image modeling process without supervision. We propose an\nautoencoding formulation to discover landmarks as explicit structural\nrepresentations. The encoding module outputs landmark coordinates, whose\nvalidity is ensured by constraints that reflect the necessary properties for\nlandmarks. The decoding module takes the landmarks as a part of the learnable\ninput representations in an end-to-end differentiable framework. Our discovered\nlandmarks are semantically meaningful and more predictive of manually annotated\nlandmarks than those discovered by previous methods. The coordinates of our\nlandmarks are also complementary features to pretrained deep-neural-network\nrepresentations in recognizing visual attributes. In addition, the proposed\nmethod naturally creates an unsupervised, perceptible interface to manipulate\nobject shapes and decode images with controllable structures. The project\nwebpage is at http://ytzhang.net/projects/lmdis-rep \n\n"}
{"id": "1804.04878", "contents": "Title: Learning Contracting Vector Fields For Stable Imitation Learning Abstract: We propose a new non-parametric framework for learning incrementally stable\ndynamical systems x' = f(x) from a set of sampled trajectories. We construct a\nrich family of smooth vector fields induced by certain classes of matrix-valued\nkernels, whose equilibria are placed exactly at a desired set of locations and\nwhose local contraction and curvature properties at various points can be\nexplicitly controlled using convex optimization. With curl-free kernels, our\nframework may also be viewed as a mechanism to learn potential fields and\ngradient flows. We develop large-scale techniques using randomized kernel\napproximations in this context. We demonstrate our approach, called contracting\nvector fields (CVF), on imitation learning tasks involving complex\npoint-to-point human handwriting motions. \n\n"}
{"id": "1804.05018", "contents": "Title: Comparatives, Quantifiers, Proportions: A Multi-Task Model for the\n  Learning of Quantities from Vision Abstract: The present work investigates whether different quantification mechanisms\n(set comparison, vague quantification, and proportional estimation) can be\njointly learned from visual scenes by a multi-task computational model. The\nmotivation is that, in humans, these processes underlie the same cognitive,\nnon-symbolic ability, which allows an automatic estimation and comparison of\nset magnitudes. We show that when information about lower-complexity tasks is\navailable, the higher-level proportional task becomes more accurate than when\nperformed in isolation. Moreover, the multi-task model is able to generalize to\nunseen combinations of target/non-target objects. Consistently with behavioral\nevidence showing the interference of absolute number in the proportional task,\nthe multi-task model no longer works when asked to provide the number of target\nobjects in the scene. \n\n"}
{"id": "1804.05164", "contents": "Title: Road Segmentation Using CNN with GRU Abstract: This paper presents an accurate and fast algorithm for road segmentation\nusing convolutional neural network (CNN) and gated recurrent units (GRU). For\nautonomous vehicles, road segmentation is a fundamental task that can provide\nthe drivable area for path planning. The existing deep neural network based\nsegmentation algorithms usually take a very deep encoder-decoder structure to\nfuse pixels, which requires heavy computations, large memory and long\nprocessing time. Hereby, a CNN-GRU network model is proposed and trained to\nperform road segmentation using data captured by the front camera of a vehicle.\nGRU network obtains a long spatial sequence with lower computational\ncomplexity, comparing to traditional encoder-decoder architecture. The proposed\nroad detector is evaluated on the KITTI road benchmark and achieves high\naccuracy for road segmentation at real-time processing speed. \n\n"}
{"id": "1804.05482", "contents": "Title: Binary Matrix Factorization via Dictionary Learning Abstract: Matrix factorization is a key tool in data analysis; its applications include\nrecommender systems, correlation analysis, signal processing, among others.\nBinary matrices are a particular case which has received significant attention\nfor over thirty years, especially within the field of data mining. Dictionary\nlearning refers to a family of methods for learning overcomplete basis (also\ncalled frames) in order to efficiently encode samples of a given type; this\narea, now also about twenty years old, was mostly developed within the signal\nprocessing field. In this work we propose two binary matrix factorization\nmethods based on a binary adaptation of the dictionary learning paradigm to\nbinary matrices. The proposed algorithms focus on speed and scalability; they\nwork with binary factors combined with bit-wise operations and a few auxiliary\ninteger ones. Furthermore, the methods are readily applicable to online binary\nmatrix factorization. Another important issue in matrix factorization is the\nchoice of rank for the factors; we address this model selection problem with an\nefficient method based on the Minimum Description Length principle. Our\npreliminary results show that the proposed methods are effective at producing\ninterpretable factorizations of various data types of different nature. \n\n"}
{"id": "1804.05544", "contents": "Title: Building robust prediction models for defective sensor data using\n  Artificial Neural Networks Abstract: Predicting the health of components in complex dynamic systems such as an\nautomobile poses numerous challenges. The primary aim of such predictive\nsystems is to use the high-dimensional data acquired from different sensors and\npredict the state-of-health of a particular component, e.g., brake pad. The\nclassical approach involves selecting a smaller set of relevant sensor signals\nusing feature selection and using them to train a machine learning algorithm.\nHowever, this fails to address two prominent problems: (1) sensors are\nsusceptible to failure when exposed to extreme conditions over a long periods\nof time; (2) sensors are electrical devices that can be affected by noise or\nelectrical interference. Using the failed and noisy sensor signals as inputs\nlargely reduce the prediction accuracy. To tackle this problem, it is\nadvantageous to use the information from all sensor signals, so that the\nfailure of one sensor can be compensated by another. In this work, we propose\nan Artificial Neural Network (ANN) based framework to exploit the information\nfrom a large number of signals. Secondly, our framework introduces a data\naugmentation approach to perform accurate predictions in spite of noisy\nsignals. The plausibility of our framework is validated on real life industrial\napplication from Robert Bosch GmbH. \n\n"}
{"id": "1804.06208", "contents": "Title: Simple Baselines for Human Pose Estimation and Tracking Abstract: There has been significant progress on pose estimation and increasing\ninterests on pose tracking in recent years. At the same time, the overall\nalgorithm and system complexity increases as well, making the algorithm\nanalysis and comparison more difficult. This work provides simple and effective\nbaseline methods. They are helpful for inspiring and evaluating new ideas for\nthe field. State-of-the-art results are achieved on challenging benchmarks. The\ncode will be available at https://github.com/leoxiaobin/pose.pytorch. \n\n"}
{"id": "1804.06242", "contents": "Title: Vortex Pooling: Improving Context Representation in Semantic\n  Segmentation Abstract: Semantic segmentation is a fundamental task in computer vision, which can be\nconsidered as a per-pixel classification problem. Recently, although fully\nconvolutional neural network (FCN) based approaches have made remarkable\nprogress in such task, aggregating local and contextual information in\nconvolutional feature maps is still a challenging problem. In this paper, we\nargue that, when predicting the category of a given pixel, the regions close to\nthe target are more important than those far from it. To tackle this problem,\nwe then propose an effective yet efficient approach named Vortex Pooling to\neffectively utilize contextual information. Empirical studies are also provided\nto validate the effectiveness of the proposed method. To be specific, our\napproach outperforms the previous state-of-the-art model named DeepLab v3 by\n1.5% on the PASCAL VOC 2012 val set and 0.6% on the test set by replacing the\nAtrous Spatial Pyramid Pooling (ASPP) module in DeepLab v3 with the proposed\nVortex Pooling. Moreover, our model (10.13FPS) shares similar computation cost\nwith DeepLab v3 (10.37 FPS). \n\n"}
{"id": "1804.06364", "contents": "Title: DGPose: Deep Generative Models for Human Body Analysis Abstract: Deep generative modelling for human body analysis is an emerging problem with\nmany interesting applications. However, the latent space learned by such\napproaches is typically not interpretable, resulting in less flexibility. In\nthis work, we present deep generative models for human body analysis in which\nthe body pose and the visual appearance are disentangled. Such a\ndisentanglement allows independent manipulation of pose and appearance, and\nhence enables applications such as pose-transfer without specific training for\nsuch a task. Our proposed models, the Conditional-DGPose and the Semi-DGPose,\nhave different characteristics. In the first, body pose labels are taken as\nconditioners, from a fully-supervised training set. In the second, our\nstructured semi-supervised approach allows for pose estimation to be performed\nby the model itself and relaxes the need for labelled data. Therefore, the\nSemi-DGPose aims for the joint understanding and generation of people in\nimages. It is not only capable of mapping images to interpretable latent\nrepresentations but also able to map these representations back to the image\nspace. We compare our models with relevant baselines, the ClothNet-Body and the\nPose Guided Person Generation networks, demonstrating their merits on the\nHuman3.6M, ChictopiaPlus and DeepFashion benchmarks. \n\n"}
{"id": "1804.06964", "contents": "Title: GNAS: A Greedy Neural Architecture Search Method for Multi-Attribute\n  Learning Abstract: A key problem in deep multi-attribute learning is to effectively discover the\ninter-attribute correlation structures. Typically, the conventional deep\nmulti-attribute learning approaches follow the pipeline of manually designing\nthe network architectures based on task-specific expertise prior knowledge and\ncareful network tunings, leading to the inflexibility for various complicated\nscenarios in practice. Motivated by addressing this problem, we propose an\nefficient greedy neural architecture search approach (GNAS) to automatically\ndiscover the optimal tree-like deep architecture for multi-attribute learning.\nIn a greedy manner, GNAS divides the optimization of global architecture into\nthe optimizations of individual connections step by step. By iteratively\nupdating the local architectures, the global tree-like architecture gets\nconverged where the bottom layers are shared across relevant attributes and the\nbranches in top layers more encode attribute-specific features. Experiments on\nthree benchmark multi-attribute datasets show the effectiveness and compactness\nof neural architectures derived by GNAS, and also demonstrate the efficiency of\nGNAS in searching neural architectures. \n\n"}
{"id": "1804.07045", "contents": "Title: Semantic Adversarial Deep Learning Abstract: Fueled by massive amounts of data, models produced by machine-learning (ML)\nalgorithms, especially deep neural networks, are being used in diverse domains\nwhere trustworthiness is a concern, including automotive systems, finance,\nhealth care, natural language processing, and malware detection. Of particular\nconcern is the use of ML algorithms in cyber-physical systems (CPS), such as\nself-driving cars and aviation, where an adversary can cause serious\nconsequences. However, existing approaches to generating adversarial examples\nand devising robust ML algorithms mostly ignore the semantics and context of\nthe overall system containing the ML component. For example, in an autonomous\nvehicle using deep learning for perception, not every adversarial example for\nthe neural network might lead to a harmful consequence. Moreover, one may want\nto prioritize the search for adversarial examples towards those that\nsignificantly modify the desired semantics of the overall system. Along the\nsame lines, existing algorithms for constructing robust ML algorithms ignore\nthe specification of the overall system. In this paper, we argue that the\nsemantics and specification of the overall system has a crucial role to play in\nthis line of research. We present preliminary research results that support\nthis claim. \n\n"}
{"id": "1804.07839", "contents": "Title: Large Scale Automated Reading of Frontal and Lateral Chest X-Rays using\n  Dual Convolutional Neural Networks Abstract: The MIMIC-CXR dataset is (to date) the largest released chest x-ray dataset\nconsisting of 473,064 chest x-rays and 206,574 radiology reports collected from\n63,478 patients. We present the results of training and evaluating a collection\nof deep convolutional neural networks on this dataset to recognize multiple\ncommon thorax diseases. To the best of our knowledge, this is the first work\nthat trains CNNs for this task on such a large collection of chest x-ray\nimages, which is over four times the size of the largest previously released\nchest x-ray corpus (ChestX-Ray14). We describe and evaluate individual CNN\nmodels trained on frontal and lateral CXR view types. In addition, we present a\nnovel DualNet architecture that emulates routine clinical practice by\nsimultaneously processing both frontal and lateral CXR images obtained from a\nradiological exam. Our DualNet architecture shows improved performance in\nrecognizing findings in CXR images when compared to applying separate baseline\nfrontal and lateral classifiers. \n\n"}
{"id": "1804.07909", "contents": "Title: Learning to Refine Human Pose Estimation Abstract: Multi-person pose estimation in images and videos is an important yet\nchallenging task with many applications. Despite the large improvements in\nhuman pose estimation enabled by the development of convolutional neural\nnetworks, there still exist a lot of difficult cases where even the\nstate-of-the-art models fail to correctly localize all body joints. This\nmotivates the need for an additional refinement step that addresses these\nchallenging cases and can be easily applied on top of any existing method. In\nthis work, we introduce a pose refinement network (PoseRefiner) which takes as\ninput both the image and a given pose estimate and learns to directly predict a\nrefined pose by jointly reasoning about the input-output space. In order for\nthe network to learn to refine incorrect body joint predictions, we employ a\nnovel data augmentation scheme for training, where we model \"hard\" human pose\ncases. We evaluate our approach on four popular large-scale pose estimation\nbenchmarks such as MPII Single- and Multi-Person Pose Estimation, PoseTrack\nPose Estimation, and PoseTrack Pose Tracking, and report systematic improvement\nover the state of the art. \n\n"}
{"id": "1804.08042", "contents": "Title: Bridgeout: stochastic bridge regularization for deep neural networks Abstract: A major challenge in training deep neural networks is overfitting, i.e.\ninferior performance on unseen test examples compared to performance on\ntraining examples. To reduce overfitting, stochastic regularization methods\nhave shown superior performance compared to deterministic weight penalties on a\nnumber of image recognition tasks. Stochastic methods such as Dropout and\nShakeout, in expectation, are equivalent to imposing a ridge and elastic-net\npenalty on the model parameters, respectively. However, the choice of the norm\nof weight penalty is problem dependent and is not restricted to $\\{L_1,L_2\\}$.\nTherefore, in this paper we propose the Bridgeout stochastic regularization\ntechnique and prove that it is equivalent to an $L_q$ penalty on the weights,\nwhere the norm $q$ can be learned as a hyperparameter from data. Experimental\nresults show that Bridgeout results in sparse model weights, improved gradients\nand superior classification performance compared to Dropout and Shakeout on\nsynthetic and real datasets. \n\n"}
{"id": "1804.08071", "contents": "Title: Decoupled Networks Abstract: Inner product-based convolution has been a central component of convolutional\nneural networks (CNNs) and the key to learning visual representations. Inspired\nby the observation that CNN-learned features are naturally decoupled with the\nnorm of features corresponding to the intra-class variation and the angle\ncorresponding to the semantic difference, we propose a generic decoupled\nlearning framework which models the intra-class variation and semantic\ndifference independently. Specifically, we first reparametrize the inner\nproduct to a decoupled form and then generalize it to the decoupled convolution\noperator which serves as the building block of our decoupled networks. We\npresent several effective instances of the decoupled convolution operator. Each\ndecoupled operator is well motivated and has an intuitive geometric\ninterpretation. Based on these decoupled operators, we further propose to\ndirectly learn the operator from data. Extensive experiments show that such\ndecoupled reparameterization renders significant performance gain with easier\nconvergence and stronger robustness. \n\n"}
{"id": "1804.08220", "contents": "Title: Multi-scale prediction for robust hand detection and classification Abstract: In this paper, we present a multi-scale Fully Convolutional Networks\n(MSP-RFCN) to robustly detect and classify human hands under various\nchallenging conditions. In our approach, the input image is passed through the\nproposed network to generate score maps, based on multi-scale predictions. The\nnetwork has been specifically designed to deal with small objects. It uses an\narchitecture based on region proposals generated at multiple scales. Our method\nis evaluated on challenging hand datasets, namely the Vision for Intelligent\nVehicles and Applications (VIVA) Challenge and the Oxford hand dataset. It is\ncompared against recent hand detection algorithms. The experimental results\ndemonstrate that our proposed method achieves state-of-the-art detection for\nhands of various sizes. \n\n"}
{"id": "1804.08328", "contents": "Title: Taskonomy: Disentangling Task Transfer Learning Abstract: Do visual tasks have a relationship, or are they unrelated? For instance,\ncould having surface normals simplify estimating the depth of an image?\nIntuition answers these questions positively, implying existence of a structure\namong visual tasks. Knowing this structure has notable values; it is the\nconcept underlying transfer learning and provides a principled way for\nidentifying redundancies across tasks, e.g., to seamlessly reuse supervision\namong related tasks or solve many tasks in one system without piling up the\ncomplexity.\n  We proposes a fully computational approach for modeling the structure of\nspace of visual tasks. This is done via finding (first and higher-order)\ntransfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D,\nand semantic tasks in a latent space. The product is a computational taxonomic\nmap for task transfer learning. We study the consequences of this structure,\ne.g. nontrivial emerged relationships, and exploit them to reduce the demand\nfor labeled data. For example, we show that the total number of labeled\ndatapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3\n(compared to training independently) while keeping the performance nearly the\nsame. We provide a set of tools for computing and probing this taxonomical\nstructure including a solver that users can employ to devise efficient\nsupervision policies for their use cases. \n\n"}
{"id": "1804.08450", "contents": "Title: Decorrelated Batch Normalization Abstract: Batch Normalization (BN) is capable of accelerating the training of deep\nmodels by centering and scaling activations within mini-batches. In this work,\nwe propose Decorrelated Batch Normalization (DBN), which not just centers and\nscales activations but whitens them. We explore multiple whitening techniques,\nand find that PCA whitening causes a problem we call stochastic axis swapping,\nwhich is detrimental to learning. We show that ZCA whitening does not suffer\nfrom this problem, permitting successful learning. DBN retains the desirable\nqualities of BN and further improves BN's optimization efficiency and\ngeneralization ability. We design comprehensive experiments to show that DBN\ncan improve the performance of BN on multilayer perceptrons and convolutional\nneural networks. Furthermore, we consistently improve the accuracy of residual\nnetworks on CIFAR-10, CIFAR-100, and ImageNet. \n\n"}
{"id": "1804.08757", "contents": "Title: Siamese Generative Adversarial Privatizer for Biometric Data Abstract: State-of-the-art machine learning algorithms can be fooled by carefully\ncrafted adversarial examples. As such, adversarial examples present a concrete\nproblem in AI safety. In this work we turn the tables and ask the following\nquestion: can we harness the power of adversarial examples to prevent malicious\nadversaries from learning identifying information from data while allowing\nnon-malicious entities to benefit from the utility of the same data? For\ninstance, can we use adversarial examples to anonymize biometric dataset of\nfaces while retaining usefulness of this data for other purposes, such as\nemotion recognition? To address this question, we propose a simple yet\neffective method, called Siamese Generative Adversarial Privatizer (SGAP), that\nexploits the properties of a Siamese neural network to find discriminative\nfeatures that convey identifying information. When coupled with a generative\nmodel, our approach is able to correctly locate and disguise identifying\ninformation, while minimally reducing the utility of the privatized dataset.\nExtensive evaluation on a biometric dataset of fingerprints and cartoon faces\nconfirms usefulness of our simple yet effective method. \n\n"}
{"id": "1804.08944", "contents": "Title: Mining Automatically Estimated Poses from Video Recordings of Top\n  Athletes Abstract: Human pose detection systems based on state-of-the-art DNNs are on the go to\nbe extended, adapted and re-trained to fit the application domain of specific\nsports. Therefore, plenty of noisy pose data will soon be available from videos\nrecorded at a regular and frequent basis. This work is among the first to\ndevelop mining algorithms that can mine the expected abundance of noisy and\nannotation-free pose data from video recordings in individual sports. Using\nswimming as an example of a sport with dominant cyclic motion, we show how to\ndetermine unsupervised time-continuous cycle speeds and temporally striking\nposes as well as measure unsupervised cycle stability over time. Additionally,\nwe use long jump as an example of a sport with a rigid phase-based motion to\npresent a technique to automatically partition the temporally estimated pose\nsequences into their respective phases. This enables the extraction of\nperformance relevant, pose-based metrics currently used by national\nprofessional sports associations. Experimental results prove the effectiveness\nof our mining algorithms, which can also be applied to other cycle-based or\nphase-based types of sport. \n\n"}
{"id": "1804.09400", "contents": "Title: 3D Consistent & Robust Segmentation of Cardiac Images by Deep Learning\n  with Spatial Propagation Abstract: We propose a method based on deep learning to perform cardiac segmentation on\nshort axis MRI image stacks iteratively from the top slice (around the base) to\nthe bottom slice (around the apex). At each iteration, a novel variant of U-net\nis applied to propagate the segmentation of a slice to the adjacent slice below\nit. In other words, the prediction of a segmentation of a slice is dependent\nupon the already existing segmentation of an adjacent slice. 3D-consistency is\nhence explicitly enforced. The method is trained on a large database of 3078\ncases from UK Biobank. It is then tested on 756 different cases from UK Biobank\nand three other state-of-the-art cohorts (ACDC with 100 cases, Sunnybrook with\n30 cases, RVSC with 16 cases). Results comparable or even better than the\nstate-of-the-art in terms of distance measures are achieved. They also\nemphasize the assets of our method, namely enhanced spatial consistency\n(currently neither considered nor achieved by the state-of-the-art), and the\ngeneralization ability to unseen cases even from other databases. \n\n"}
{"id": "1804.09859", "contents": "Title: Competitive Learning Enriches Learning Representation and Accelerates\n  the Fine-tuning of CNNs Abstract: In this study, we propose the integration of competitive learning into\nconvolutional neural networks (CNNs) to improve the representation learning and\nefficiency of fine-tuning. Conventional CNNs use back propagation learning, and\nit enables powerful representation learning by a discrimination task. However,\nit requires huge amount of labeled data, and acquisition of labeled data is\nmuch harder than that of unlabeled data. Thus, efficient use of unlabeled data\nis getting crucial for DNNs. To address the problem, we introduce unsupervised\ncompetitive learning into the convolutional layer, and utilize unlabeled data\nfor effective representation learning. The results of validation experiments\nusing a toy model demonstrated that strong representation learning effectively\nextracted bases of images into convolutional filters using unlabeled data, and\naccelerated the speed of the fine-tuning of subsequent supervised back\npropagation learning. The leverage was more apparent when the number of filters\nwas sufficiently large, and, in such a case, the error rate steeply decreased\nin the initial phase of fine-tuning. Thus, the proposed method enlarged the\nnumber of filters in CNNs, and enabled a more detailed and generalized\nrepresentation. It could provide a possibility of not only deep but broad\nneural networks. \n\n"}
{"id": "1804.09862", "contents": "Title: Accelerator-Aware Pruning for Convolutional Neural Networks Abstract: Convolutional neural networks have shown tremendous performance capabilities\nin computer vision tasks, but their excessive amounts of weight storage and\narithmetic operations prevent them from being adopted in embedded environments.\nOne of the solutions involves pruning, where certain unimportant weights are\nforced to have a value of zero. Many pruning schemes have been proposed, but\nthese have mainly focused on the number of pruned weights. Previous pruning\nschemes scarcely considered ASIC or FPGA accelerator architectures. When these\npruned networks are run on accelerators, the lack of consideration of the\narchitecture causes some inefficiency problems, including internal buffer\nmisalignments and load imbalances. This paper proposes a new pruning scheme\nthat reflects accelerator architectures. In the proposed scheme, pruning is\nperformed so that the same number of weights remain for each weight group\ncorresponding to activations fetched simultaneously. In this way, the pruning\nscheme resolves the inefficiency problems, doubling the accelerator\nperformance. Even with this constraint, the proposed pruning scheme reached a\npruning ratio similar to that of previous unconstrained pruning schemes, not\nonly on AlexNet and VGG16 but also on state-of-the-art very deep networks such\nas ResNet. Furthermore, the proposed scheme demonstrated a comparable pruning\nratio on compact networks such as MobileNet and on slimmed networks that were\nalready pruned in a channel-wise manner. In addition to improving the\nefficiency of previous sparse accelerators, it will be also shown that the\nproposed pruning scheme can be used to reduce the logic complexity of sparse\naccelerators.The pruned models are publicly available at\nhttps://github.com/HyeongjuKang/accelerator-aware-pruning. \n\n"}
{"id": "1804.10337", "contents": "Title: Latent Fingerprint Recognition: Role of Texture Template Abstract: We propose a texture template approach, consisting of a set of virtual\nminutiae, to improve the overall latent fingerprint recognition accuracy. To\ncompensate for the lack of sufficient number of minutiae in poor quality latent\nprints, we generate a set of virtual minutiae. However, due to a large number\nof these regularly placed virtual minutiae, texture based template matching has\na large computational requirement compared to matching true minutiae templates.\nTo improve both the accuracy and efficiency of the texture template matching,\nwe investigate: i) both original and enhanced fingerprint patches for training\nconvolutional neural networks (ConvNets) to improve the distinctiveness of\ndescriptors associated with each virtual minutiae, ii) smaller patches around\nvirtual minutiae and a fast ConvNet architecture to speed up descriptor\nextraction, iii) reduce the descriptor length, iv) a modified hierarchical\ngraph matching strategy to improve the matching speed, and v) extraction of\nmultiple texture templates to boost the performance. Experiments on NIST SD27\nlatent database show that the above strategies can improve the matching speed\nfrom 11 ms (24 threads) per comparison (between a latent and a reference print)\nto only 7.7 ms (single thread) per comparison while improving the rank-1\naccuracy by 8.9% against 10K gallery. \n\n"}
{"id": "1804.10366", "contents": "Title: Online Convolutional Sparse Coding with Sample-Dependent Dictionary Abstract: Convolutional sparse coding (CSC) has been popularly used for the learning of\nshift-invariant dictionaries in image and signal processing. However, existing\nmethods have limited scalability. In this paper, instead of convolving with a\ndictionary shared by all samples, we propose the use of a sample-dependent\ndictionary in which filters are obtained as linear combinations of a small set\nof base filters learned from the data. This added flexibility allows a large\nnumber of sample-dependent patterns to be captured, while the resultant model\ncan still be efficiently learned by online learning. Extensive experimental\nresults show that the proposed method outperforms existing CSC algorithms with\nsignificantly reduced time and space requirements. \n\n"}
{"id": "1804.10500", "contents": "Title: Deep Reinforcement Learning to Acquire Navigation Skills for\n  Wheel-Legged Robots in Complex Environments Abstract: Mobile robot navigation in complex and dynamic environments is a challenging\nbut important problem. Reinforcement learning approaches fail to solve these\ntasks efficiently due to reward sparsities, temporal complexities and\nhigh-dimensionality of sensorimotor spaces which are inherent in such problems.\nWe present a novel approach to train action policies to acquire navigation\nskills for wheel-legged robots using deep reinforcement learning. The policy\nmaps height-map image observations to motor commands to navigate to a target\nposition while avoiding obstacles. We propose to acquire the multifaceted\nnavigation skill by learning and exploiting a number of manageable navigation\nbehaviors. We also introduce a domain randomization technique to improve the\nversatility of the training samples. We demonstrate experimentally a\nsignificant improvement in terms of data-efficiency, success rate, robustness\nagainst irrelevant sensory data, and also the quality of the maneuver skills. \n\n"}
{"id": "1804.10574", "contents": "Title: Decoupled Parallel Backpropagation with Convergence Guarantee Abstract: Backpropagation algorithm is indispensable for the training of feedforward\nneural networks. It requires propagating error gradients sequentially from the\noutput layer all the way back to the input layer. The backward locking in\nbackpropagation algorithm constrains us from updating network layers in\nparallel and fully leveraging the computing resources. Recently, several\nalgorithms have been proposed for breaking the backward locking. However, their\nperformances degrade seriously when networks are deep. In this paper, we\npropose decoupled parallel backpropagation algorithm for deep learning\noptimization with convergence guarantee. Firstly, we decouple the\nbackpropagation algorithm using delayed gradients, and show that the backward\nlocking is removed when we split the networks into multiple modules. Then, we\nutilize decoupled parallel backpropagation in two stochastic methods and prove\nthat our method guarantees convergence to critical points for the non-convex\nproblem. Finally, we perform experiments for training deep convolutional neural\nnetworks on benchmark datasets. The experimental results not only confirm our\ntheoretical analysis, but also demonstrate that the proposed method can achieve\nsignificant speedup without loss of accuracy. \n\n"}
{"id": "1804.10742", "contents": "Title: Novel Prediction Techniques Based on Clusterwise Linear Regression Abstract: In this paper we explore different regression models based on Clusterwise\nLinear Regression (CLR). CLR aims to find the partition of the data into $k$\nclusters, such that linear regressions fitted to each of the clusters minimize\noverall mean squared error on the whole data. The main obstacle preventing to\nuse found regression models for prediction on the unseen test points is the\nabsence of a reasonable way to obtain CLR cluster labels when the values of\ntarget variable are unknown. In this paper we propose two novel approaches on\nhow to solve this problem. The first approach, predictive CLR builds a separate\nclassification model to predict test CLR labels. The second approach,\nconstrained CLR utilizes a set of user-specified constraints that enforce\ncertain points to go to the same clusters. Assuming the constraint values are\nknown for the test points, they can be directly used to assign CLR labels. We\nevaluate these two approaches on three UCI ML datasets as well as on a large\ncorpus of health insurance claims. We show that both of the proposed algorithms\nsignificantly improve over the known CLR-based regression methods. Moreover,\npredictive CLR consistently outperforms linear regression and random forest,\nand shows comparable performance to support vector regression on UCI ML\ndatasets. The constrained CLR approach achieves the best performance on the\nhealth insurance dataset, while enjoying only $\\approx 20$ times increased\ncomputational time over linear regression. \n\n"}
{"id": "1804.10776", "contents": "Title: Multi Layered-Parallel Graph Convolutional Network (ML-PGCN) for Disease\n  Prediction Abstract: Structural data from Electronic Health Records as complementary information\nto imaging data for disease prediction. We incorporate novel weighting layer\ninto the Graph Convolutional Networks, which weights every element of\nstructural data by exploring its relation to the underlying disease. We\ndemonstrate the superiority of our developed technique in terms of\ncomputational speed and obtained encouraging results where our method\noutperforms the state-of-the-art methods when applied to two publicly available\ndatasets ABIDE and Chest X-ray in terms of relative performance for the\naccuracy of prediction by 5.31 % and 8.15 % and for the area under the ROC\ncurve by 4.96 % and 10.36 % respectively. Additionally, the model is\nlightweight, fast and easily trainable. \n\n"}
{"id": "1804.10938", "contents": "Title: Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge,\n  Deep Architectures, and Beyond Abstract: Automatic understanding of human affect using visual signals is of great\nimportance in everyday human-machine interactions. Appraising human emotional\nstates, behaviors and reactions displayed in real-world settings, can be\naccomplished using latent continuous dimensions (e.g., the circumplex model of\naffect). Valence (i.e., how positive or negative is an emotion) & arousal\n(i.e., power of the activation of the emotion) constitute popular and effective\naffect representations. Nevertheless, the majority of collected datasets this\nfar, although containing naturalistic emotional states, have been captured in\nhighly controlled recording conditions. In this paper, we introduce the\nAff-Wild benchmark for training and evaluating affect recognition algorithms.\nWe also report on the results of the First Affect-in-the-wild Challenge that\nwas organized in conjunction with CVPR 2017 on the Aff-Wild database and was\nthe first ever challenge on the estimation of valence and arousal in-the-wild.\nFurthermore, we design and extensively train an end-to-end deep neural\narchitecture which performs prediction of continuous emotion dimensions based\non visual cues. The proposed deep learning architecture, AffWildNet, includes\nconvolutional & recurrent neural network layers, exploiting the invariant\nproperties of convolutional features, while also modeling temporal dynamics\nthat arise in human behavior via the recurrent layers. The AffWildNet produced\nstate-of-the-art results on the Aff-Wild Challenge. We then exploit the AffWild\ndatabase for learning features, which can be used as priors for achieving best\nperformances both for dimensional, as well as categorical emotion recognition,\nusing the RECOLA, AFEW-VA and EmotiW datasets, compared to all other methods\ndesigned for the same goal. The database and emotion recognition models are\navailable at http://ibug.doc.ic.ac.uk/resources/first-affect-wild-challenge. \n\n"}
{"id": "1804.10974", "contents": "Title: From Credit Assignment to Entropy Regularization: Two New Algorithms for\n  Neural Sequence Prediction Abstract: In this work, we study the credit assignment problem in reward augmented\nmaximum likelihood (RAML) learning, and establish a theoretical equivalence\nbetween the token-level counterpart of RAML and the entropy regularized\nreinforcement learning. Inspired by the connection, we propose two sequence\nprediction algorithms, one extending RAML with fine-grained credit assignment\nand the other improving Actor-Critic with a systematic entropy regularization.\nOn two benchmark datasets, we show the proposed algorithms outperform RAML and\nActor-Critic respectively, providing new alternatives to sequence prediction. \n\n"}
{"id": "1804.11228", "contents": "Title: Dilated Temporal Relational Adversarial Network for Generic Video\n  Summarization Abstract: The large amount of videos popping up every day, make it more and more\ncritical that key information within videos can be extracted and understood in\na very short time. Video summarization, the task of finding the smallest subset\nof frames, which still conveys the whole story of a given video, is thus of\ngreat significance to improve efficiency of video understanding. We propose a\nnovel Dilated Temporal Relational Generative Adversarial Network (DTR-GAN) to\nachieve frame-level video summarization. Given a video, it selects the set of\nkey frames, which contain the most meaningful and compact information.\nSpecifically, DTR-GAN learns a dilated temporal relational generator and a\ndiscriminator with three-player loss in an adversarial manner. A new dilated\ntemporal relation (DTR) unit is introduced to enhance temporal representation\ncapturing. The generator uses this unit to effectively exploit global\nmulti-scale temporal context to select key frames and to complement the\ncommonly used Bi-LSTM. To ensure that summaries capture enough key video\nrepresentation from a global perspective rather than a trivial randomly shorten\nsequence, we present a discriminator that learns to enforce both the\ninformation completeness and compactness of summaries via a three-player loss.\nThe loss includes the generated summary loss, the random summary loss, and the\nreal summary (ground-truth) loss, which play important roles for better\nregularizing the learned model to obtain useful summaries. Comprehensive\nexperiments on three public datasets show the effectiveness of the proposed\napproach. \n\n"}
{"id": "1805.00251", "contents": "Title: Conditional Image-to-Image Translation Abstract: Image-to-image translation tasks have been widely investigated with\nGenerative Adversarial Networks (GANs) and dual learning. However, existing\nmodels lack the ability to control the translated results in the target domain\nand their results usually lack of diversity in the sense that a fixed image\nusually leads to (almost) deterministic translation result. In this paper, we\nstudy a new problem, conditional image-to-image translation, which is to\ntranslate an image from the source domain to the target domain conditioned on a\ngiven image in the target domain. It requires that the generated image should\ninherit some domain-specific features of the conditional image from the target\ndomain. Therefore, changing the conditional image in the target domain will\nlead to diverse translation results for a fixed input image from the source\ndomain, and therefore the conditional input image helps to control the\ntranslation results. We tackle this problem with unpaired data based on GANs\nand dual learning. We twist two conditional translation models (one translation\nfrom A domain to B domain, and the other one from B domain to A domain)\ntogether for inputs combination and reconstruction while preserving domain\nindependent features. We carry out experiments on men's faces from-to women's\nfaces translation and edges to shoes&bags translations. The results demonstrate\nthe effectiveness of our proposed method. \n\n"}
{"id": "1805.00309", "contents": "Title: An Universal Image Attractiveness Ranking Framework Abstract: We propose a new framework to rank image attractiveness using a novel\npairwise deep network trained with a large set of side-by-side multi-labeled\nimage pairs from a web image index. The judges only provide relative ranking\nbetween two images without the need to directly assign an absolute score, or\nrate any predefined image attribute, thus making the rating more intuitive and\naccurate. We investigate a deep attractiveness rank net (DARN), a combination\nof deep convolutional neural network and rank net, to directly learn an\nattractiveness score mean and variance for each image and the underlying\ncriteria the judges use to label each pair. The extension of this model\n(DARN-V2) is able to adapt to individual judge's personal preference. We also\nshow the attractiveness of search results are significantly improved by using\nthis attractiveness information in a real commercial search engine. We evaluate\nour model against other state-of-the-art models on our side-by-side web test\ndata and another public aesthetic data set. With much less judgments (1M vs\n50M), our model outperforms on side-by-side labeled data, and is comparable on\ndata labeled by absolute score. \n\n"}
{"id": "1805.00325", "contents": "Title: Study of Residual Networks for Image Recognition Abstract: Deep neural networks demonstrate to have a high performance on image\nclassification tasks while being more difficult to train. Due to the complexity\nand vanishing gradient problem, it normally takes a lot of time and more\ncomputational power to train deeper neural networks. Deep residual networks\n(ResNets) can make the training process faster and attain more accuracy\ncompared to their equivalent neural networks. ResNets achieve this improvement\nby adding a simple skip connection parallel to the layers of convolutional\nneural networks. In this project we first design a ResNet model that can\nperform the image classification task on the Tiny ImageNet dataset with a high\naccuracy, then we compare the performance of this ResNet model with its\nequivalent Convolutional Network (ConvNet). Our findings illustrate that\nResNets are more prone to overfitting despite their higher accuracy. Several\nmethods to prevent overfitting such as adding dropout layers and stochastic\naugmentation of the training dataset has been studied in this work. \n\n"}
{"id": "1805.00355", "contents": "Title: Sample-to-Sample Correspondence for Unsupervised Domain Adaptation Abstract: The assumption that training and testing samples are generated from the same\ndistribution does not always hold for real-world machine-learning applications.\nThe procedure of tackling this discrepancy between the training (source) and\ntesting (target) domains is known as domain adaptation. We propose an\nunsupervised version of domain adaptation that considers the presence of only\nunlabelled data in the target domain. Our approach centers on finding\ncorrespondences between samples of each domain. The correspondences are\nobtained by treating the source and target samples as graphs and using a convex\ncriterion to match them. The criteria used are first-order and second-order\nsimilarities between the graphs as well as a class-based regularization. We\nhave also developed a computationally efficient routine for the convex\noptimization, thus allowing the proposed method to be used widely. To verify\nthe effectiveness of the proposed method, computer simulations were conducted\non synthetic, image classification and sentiment classification datasets.\nResults validated that the proposed local sample-to-sample matching method\nout-performs traditional moment-matching methods and is competitive with\nrespect to current local domain-adaptation methods. \n\n"}
{"id": "1805.00553", "contents": "Title: Generating Synthetic X-ray Images of a Person from the Surface Geometry Abstract: We present a novel framework that learns to predict human anatomy from body\nsurface. Specifically, our approach generates a synthetic X-ray image of a\nperson only from the person's surface geometry. Furthermore, the synthetic\nX-ray image is parametrized and can be manipulated by adjusting a set of body\nmarkers which are also generated during the X-ray image prediction. With the\nproposed framework, multiple synthetic X-ray images can easily be generated by\nvarying surface geometry. By perturbing the parameters, several additional\nsynthetic X-ray images can be generated from the same surface geometry. As a\nresult, our approach offers a potential to overcome the training data barrier\nin the medical domain. This capability is achieved by learning a pair of\nnetworks - one learns to generate the full image from the partial image and a\nset of parameters, and the other learns to estimate the parameters given the\nfull image. During training, the two networks are trained iteratively such that\nthey would converge to a solution where the predicted parameters and the full\nimage are consistent with each other. In addition to medical data enrichment,\nour framework can also be used for image completion as well as anomaly\ndetection. \n\n"}
{"id": "1805.00611", "contents": "Title: Towards Interpretable Face Recognition Abstract: Deep CNNs have been pushing the frontier of visual recognition over past\nyears. Besides recognition accuracy, strong demands in understanding deep CNNs\nin the research community motivate developments of tools to dissect pre-trained\nmodels to visualize how they make predictions. Recent works further push the\ninterpretability in the network learning stage to learn more meaningful\nrepresentations. In this work, focusing on a specific area of visual\nrecognition, we report our efforts towards interpretable face recognition. We\npropose a spatial activation diversity loss to learn more structured face\nrepresentations. By leveraging the structure, we further design a feature\nactivation diversity loss to push the interpretable representations to be\ndiscriminative and robust to occlusions. We demonstrate on three face\nrecognition benchmarks that our proposed method is able to improve face\nrecognition accuracy with easily interpretable face representations. \n\n"}
{"id": "1805.00655", "contents": "Title: Convolutional Sequence to Sequence Model for Human Dynamics Abstract: Human motion modeling is a classic problem in computer vision and graphics.\nChallenges in modeling human motion include high dimensional prediction as well\nas extremely complicated dynamics.We present a novel approach to human motion\nmodeling based on convolutional neural networks (CNN). The hierarchical\nstructure of CNN makes it capable of capturing both spatial and temporal\ncorrelations effectively. In our proposed approach,a convolutional long-term\nencoder is used to encode the whole given motion sequence into a long-term\nhidden variable, which is used with a decoder to predict the remainder of the\nsequence. The decoder itself also has an encoder-decoder structure, in which\nthe short-term encoder encodes a shorter sequence to a short-term hidden\nvariable, and the spatial decoder maps the long and short-term hidden variable\nto motion predictions. By using such a model, we are able to capture both\ninvariant and dynamic information of human motion, which results in more\naccurate predictions. Experiments show that our algorithm outperforms the\nstate-of-the-art methods on the Human3.6M and CMU Motion Capture datasets. Our\ncode is available at the project website. \n\n"}
{"id": "1805.00721", "contents": "Title: Joint Surgical Gesture and Task Classification with Multi-Task and\n  Multimodal Learning Abstract: We propose a novel multi-modal and multi-task architecture for simultaneous\nlow level gesture and surgical task classification in Robot Assisted Surgery\n(RAS) videos.Our end-to-end architecture is based on the principles of a long\nshort-term memory network (LSTM) that jointly learns temporal dynamics on rich\nrepresentations of visual and motion features, while simultaneously classifying\nactivities of low-level gestures and surgical tasks. Our experimental results\nshow that our approach is superior compared to an ar- chitecture that\nclassifies the gestures and surgical tasks separately on visual cues and motion\ncues respectively. We train our model on a fixed random set of 1200 gesture\nvideo segments and use the rest 422 for testing. This results in around 42,000\ngesture frames sampled for training and 14,500 for testing. For a 6 split\nexperimentation, while the conventional approach reaches an Average Precision\n(AP) of only 29% (29.13%), our architecture reaches an AP of 51% (50.83%) for 3\ntasks and 14 possible gesture labels, resulting in an improvement of 22%\n(21.7%). Our architecture learns temporal dynamics on rich representations of\nvisual and motion features that compliment each other for classification of\nlow-level gestures and surgical tasks. Its multi-task learning nature makes use\nof learned joint re- lationships and combinations of shared and task-specific\nrepresentations. While benchmark studies focus on recognizing gestures that\ntake place under specific tasks, we focus on recognizing common gestures that\nreoccur across different tasks and settings and significantly perform better\ncompared to conventional architectures. \n\n"}
{"id": "1805.00980", "contents": "Title: SaaS: Speed as a Supervisor for Semi-supervised Learning Abstract: We introduce the SaaS Algorithm for semi-supervised learning, which uses\nlearning speed during stochastic gradient descent in a deep neural network to\nmeasure the quality of an iterative estimate of the posterior probability of\nunknown labels. Training speed in supervised learning correlates strongly with\nthe percentage of correct labels, so we use it as an inference criterion for\nthe unknown labels, without attempting to infer the model parameters at first.\nDespite its simplicity, SaaS achieves state-of-the-art results in\nsemi-supervised learning benchmarks. \n\n"}
{"id": "1805.01199", "contents": "Title: Label Embedding with Partial Heterogeneous Contexts Abstract: Label embedding plays an important role in many real-world applications. To\nenhance the label relatedness captured by the embeddings, multiple contexts can\nbe adopted. However, these contexts are heterogeneous and often partially\nobserved in practical tasks, imposing significant challenges to capture the\noverall relatedness among labels. In this paper, we propose a general Partial\nHeterogeneous Context Label Embedding (PHCLE) framework to address these\nchallenges. Categorizing heterogeneous contexts into two groups, relational\ncontext and descriptive context, we design tailor-made matrix factorization\nformula to effectively exploit the label relatedness in each context. With a\nshared embedding principle across heterogeneous contexts, the label relatedness\nis selectively aligned in a shared space. Due to our elegant formulation, PHCLE\novercomes the partial context problem and can nicely incorporate more contexts,\nwhich both cannot be tackled with existing multi-context label embedding\nmethods. An effective alternative optimization algorithm is further derived to\nsolve the sparse matrix factorization problem. Experimental results demonstrate\nthat the label embeddings obtained with PHCLE achieve superb performance in\nimage classification task and exhibit good interpretability in the downstream\nlabel similarity analysis and image understanding task. \n\n"}
{"id": "1805.01352", "contents": "Title: Spiking Deep Residual Network Abstract: Spiking neural networks (SNNs) have received significant attention for their\nbiological plausibility. SNNs theoretically have at least the same\ncomputational power as traditional artificial neural networks (ANNs). They\npossess potential of achieving energy-efficiency while keeping comparable\nperformance to deep neural networks (DNNs). However, it is still a big\nchallenge to train a very deep SNN. In this paper, we propose an efficient\napproach to build a spiking version of deep residual network (ResNet). ResNet\nis considered as a kind of the state-of-the-art convolutional neural networks\n(CNNs). We employ the idea of converting a trained ResNet to a network of\nspiking neurons, named Spiking ResNet (S-ResNet). We propose a shortcut\nconversion model to appropriately scale continuous-valued activations to match\nfiring rates in SNN, and a compensation mechanism to reduce the error caused by\ndiscretisation. Experimental results demonstrate that, compared with the\nstate-of-the-art SNN approaches, the proposed Spiking ResNet achieves the best\nperformance on CIFAR-10, CIFAR-100, and ImageNet 2012. Our work is the first\ntime to build a SNN deeper than 40, with comparable performance to ANNs on a\nlarge-scale dataset. \n\n"}
{"id": "1805.01972", "contents": "Title: Fast-converging Conditional Generative Adversarial Networks for Image\n  Synthesis Abstract: Building on top of the success of generative adversarial networks (GANs),\nconditional GANs attempt to better direct the data generation process by\nconditioning with certain additional information. Inspired by the most recent\nAC-GAN, in this paper we propose a fast-converging conditional GAN (FC-GAN). In\naddition to the real/fake classifier used in vanilla GANs, our discriminator\nhas an advanced auxiliary classifier which distinguishes each real class from\nan extra `fake' class. The `fake' class avoids mixing generated data with real\ndata, which can potentially confuse the classification of real data as AC-GAN\ndoes, and makes the advanced auxiliary classifier behave as another real/fake\nclassifier. As a result, FC-GAN can accelerate the process of differentiation\nof all classes, thus boost the convergence speed. Experimental results on image\nsynthesis demonstrate our model is competitive in the quality of images\ngenerated while achieving a faster convergence rate. \n\n"}
{"id": "1805.03096", "contents": "Title: Fast Feature Extraction with CNNs with Pooling Layers Abstract: In recent years, many publications showed that convolutional neural network\nbased features can have a superior performance to engineered features. However,\nnot much effort was taken so far to extract local features efficiently for a\nwhole image. In this paper, we present an approach to compute patch-based local\nfeature descriptors efficiently in presence of pooling and striding layers for\nwhole images at once. Our approach is generic and can be applied to nearly all\nexisting network architectures. This includes networks for all local feature\nextraction tasks like camera calibration, Patchmatching, optical flow\nestimation and stereo matching. In addition, our approach can be applied to\nother patch-based approaches like sliding window object detection and\nrecognition. We complete our paper with a speed benchmark of popular CNN based\nfeature extraction approaches applied on a whole image, with and without our\nspeedup, and example code (for Torch) that shows how an arbitrary CNN\narchitecture can be easily converted by our approach. \n\n"}
{"id": "1805.03305", "contents": "Title: The Effectiveness of Instance Normalization: a Strong Baseline for\n  Single Image Dehazing Abstract: We propose a novel deep neural network architecture for the challenging\nproblem of single image dehazing, which aims to recover the clear image from a\ndegraded hazy image. Instead of relying on hand-crafted image priors or\nexplicitly estimating the components of the widely used atmospheric scattering\nmodel, our end-to-end system directly generates the clear image from an input\nhazy image. The proposed network has an encoder-decoder architecture with skip\nconnections and instance normalization. We adopt the convolutional layers of\nthe pre-trained VGG network as encoder to exploit the representation power of\ndeep features, and demonstrate the effectiveness of instance normalization for\nimage dehazing. Our simple yet effective network outperforms the\nstate-of-the-art methods by a large margin on the benchmark datasets. \n\n"}
{"id": "1805.03596", "contents": "Title: Layered Optical Flow Estimation Using a Deep Neural Network with a Soft\n  Mask Abstract: Using a layered representation for motion estimation has the advantage of\nbeing able to cope with discontinuities and occlusions. In this paper, we learn\nto estimate optical flow by combining a layered motion representation with deep\nlearning. Instead of pre-segmenting the image to layers, the proposed approach\nautomatically generates a layered representation of optical flow using the\nproposed soft-mask module. The essential components of the soft-mask module are\nmaxout and fuse operations, which enable a disjoint layered representation of\noptical flow and more accurate flow estimation. We show that by using masks the\nmotion estimate results in a quadratic function of input features in the output\nlayer. The proposed soft-mask module can be added to any existing optical flow\nestimation networks by replacing their flow output layer. In this work, we use\nFlowNet as the base network to which we add the soft-mask module. The resulting\nnetwork is tested on three well-known benchmarks with both supervised and\nunsupervised flow estimation tasks. Evaluation results show that the proposed\nnetwork achieve better results compared with the original FlowNet. \n\n"}
{"id": "1805.04953", "contents": "Title: Learning Rich Features for Image Manipulation Detection Abstract: Image manipulation detection is different from traditional semantic object\ndetection because it pays more attention to tampering artifacts than to image\ncontent, which suggests that richer features need to be learned. We propose a\ntwo-stream Faster R-CNN network and train it endto- end to detect the tampered\nregions given a manipulated image. One of the two streams is an RGB stream\nwhose purpose is to extract features from the RGB image input to find tampering\nartifacts like strong contrast difference, unnatural tampered boundaries, and\nso on. The other is a noise stream that leverages the noise features extracted\nfrom a steganalysis rich model filter layer to discover the noise inconsistency\nbetween authentic and tampered regions. We then fuse features from the two\nstreams through a bilinear pooling layer to further incorporate spatial\nco-occurrence of these two modalities. Experiments on four standard image\nmanipulation datasets demonstrate that our two-stream framework outperforms\neach individual stream, and also achieves state-of-the-art performance compared\nto alternative methods with robustness to resizing and compression. \n\n"}
{"id": "1805.05086", "contents": "Title: Unsupervised Intuitive Physics from Visual Observations Abstract: While learning models of intuitive physics is an increasingly active area of\nresearch, current approaches still fall short of natural intelligences in one\nimportant regard: they require external supervision, such as explicit access to\nphysical states, at training and sometimes even at test times. Some authors\nhave relaxed such requirements by supplementing the model with an handcrafted\nphysical simulator. Still, the resulting methods are unable to automatically\nlearn new complex environments and to understand physical interactions within\nthem. In this work, we demonstrated for the first time learning such predictors\ndirectly from raw visual observations and without relying on simulators. We do\nso in two steps: first, we learn to track mechanically-salient objects in\nvideos using causality and equivariance, two unsupervised learning principles\nthat do not require auto-encoding. Second, we demonstrate that the extracted\npositions are sufficient to successfully train visual motion predictors that\ncan take the underlying environment into account. We validate our predictors on\nsynthetic datasets; then, we introduce a new dataset, ROLL4REAL, consisting of\nreal objects rolling on complex terrains (pool table, elliptical bowl, and\nrandom height-field). We show that in all such cases it is possible to learn\nreliable extrapolators of the object trajectories from raw videos alone,\nwithout any form of external supervision and with no more prior knowledge than\nthe choice of a convolutional neural network architecture. \n\n"}
{"id": "1805.06085", "contents": "Title: PACT: Parameterized Clipping Activation for Quantized Neural Networks Abstract: Deep learning algorithms achieve high classification accuracy at the expense\nof significant computation cost. To address this cost, a number of quantization\nschemes have been proposed - but most of these techniques focused on quantizing\nweights, which are relatively smaller in size compared to activations. This\npaper proposes a novel quantization scheme for activations during training -\nthat enables neural networks to work well with ultra low precision weights and\nactivations without any significant accuracy degradation. This technique,\nPArameterized Clipping acTivation (PACT), uses an activation clipping parameter\n$\\alpha$ that is optimized during training to find the right quantization\nscale. PACT allows quantizing activations to arbitrary bit precisions, while\nachieving much better accuracy relative to published state-of-the-art\nquantization schemes. We show, for the first time, that both weights and\nactivations can be quantized to 4-bits of precision while still achieving\naccuracy comparable to full precision networks across a range of popular models\nand datasets. We also show that exploiting these reduced-precision\ncomputational units in hardware can enable a super-linear improvement in\ninferencing performance due to a significant reduction in the area of\naccelerator compute engines coupled with the ability to retain the quantized\nmodel and activation data in on-chip memories. \n\n"}
{"id": "1805.06173", "contents": "Title: Lightweight Pyramid Networks for Image Deraining Abstract: Existing deep convolutional neural networks have found major success in image\nderaining, but at the expense of an enormous number of parameters. This limits\ntheir potential application, for example in mobile devices. In this paper, we\npropose a lightweight pyramid of networks (LPNet) for single image deraining.\nInstead of designing a complex network structures, we use domain-specific\nknowledge to simplify the learning process. Specifically, we find that by\nintroducing the mature Gaussian-Laplacian image pyramid decomposition\ntechnology to the neural network, the learning problem at each pyramid level is\ngreatly simplified and can be handled by a relatively shallow network with few\nparameters. We adopt recursive and residual network structures to build the\nproposed LPNet, which has less than 8K parameters while still achieving\nstate-of-the-art performance on rain removal. We also discuss the potential\nvalue of LPNet for other low- and high-level vision tasks. \n\n"}
{"id": "1805.06846", "contents": "Title: RotDCF: Decomposition of Convolutional Filters for Rotation-Equivariant\n  Deep Networks Abstract: Explicit encoding of group actions in deep features makes it possible for\nconvolutional neural networks (CNNs) to handle global deformations of images,\nwhich is critical to success in many vision tasks. This paper proposes to\ndecompose the convolutional filters over joint steerable bases across the space\nand the group geometry simultaneously, namely a rotation-equivariant CNN with\ndecomposed convolutional filters (RotDCF). This decomposition facilitates\ncomputing the joint convolution, which is proved to be necessary for the group\nequivariance. It significantly reduces the model size and computational\ncomplexity while preserving performance, and truncation of the bases expansion\nserves implicitly to regularize the filters. On datasets involving in-plane and\nout-of-plane object rotations, RotDCF deep features demonstrate greater\nrobustness and interpretability than regular CNNs. The stability of the\nequivariant representation to input variations is also proved theoretically\nunder generic assumptions on the filters in the decomposed form. The RotDCF\nframework can be extended to groups other than rotations, providing a general\napproach which achieves both group equivariance and representation stability at\na reduced model size. \n\n"}
{"id": "1805.06956", "contents": "Title: Identifying Object States in Cooking-Related Images Abstract: Understanding object states is as important as object recognition for robotic\ntask planning and manipulation. To our knowledge, this paper explicitly\nintroduces and addresses the state identification problem in cooking related\nimages for the first time. In this paper, objects and ingredients in cooking\nvideos are explored and the most frequent objects are analyzed. Eleven states\nfrom the most frequent cooking objects are examined and a dataset of images\ncontaining those objects and their states is created. As a solution to the\nstate identification problem, a Resnet based deep model is proposed. The model\nis initialized with Imagenet weights and trained on the dataset of eleven\nclasses. The trained state identification model is evaluated on a subset of the\nImagenet dataset and state labels are provided using a combination of the model\nwith manual checking. Moreover, an individual model is fine-tuned for each\nobject in the dataset using the weights from the initially trained model and\nobject-specific images, where significant improvement is demonstrated. \n\n"}
{"id": "1805.07647", "contents": "Title: Learning Hierarchical Visual Representations in Deep Neural Networks\n  Using Hierarchical Linguistic Labels Abstract: Modern convolutional neural networks (CNNs) are able to achieve human-level\nobject classification accuracy on specific tasks, and currently outperform\ncompeting models in explaining complex human visual representations. However,\nthe categorization problem is posed differently for these networks than for\nhumans: the accuracy of these networks is evaluated by their ability to\nidentify single labels assigned to each image. These labels often cut\narbitrarily across natural psychological taxonomies (e.g., dogs are separated\ninto breeds, but never jointly categorized as \"dogs\"), and bias the resulting\nrepresentations. By contrast, it is common for children to hear both \"dog\" and\n\"Dalmatian\" to describe the same stimulus, helping to group perceptually\ndisparate objects (e.g., breeds) into a common mental class. In this work, we\ntrain CNN classifiers with multiple labels for each image that correspond to\ndifferent levels of abstraction, and use this framework to reproduce classic\npatterns that appear in human generalization behavior. \n\n"}
{"id": "1805.08183", "contents": "Title: Constrained Sparse Subspace Clustering with Side-Information Abstract: Subspace clustering refers to the problem of segmenting high dimensional data\ndrawn from a union of subspaces into the respective subspaces. In some\napplications, partial side-information to indicate \"must-link\" or \"cannot-link\"\nin clustering is available. This leads to the task of subspace clustering with\nside-information. However, in prior work the supervision value of the\nside-information for subspace clustering has not been fully exploited. To this\nend, in this paper, we present an enhanced approach for constrained subspace\nclustering with side-information, termed Constrained Sparse Subspace Clustering\nplus (CSSC+), in which the side-information is used not only in the stage of\nlearning an affinity matrix but also in the stage of spectral clustering.\nMoreover, we propose to estimate clustering accuracy based on the partial\nside-information and theoretically justify the connection to the ground-truth\nclustering accuracy in terms of the Rand index. We conduct experiments on three\ncancer gene expression datasets to validate the effectiveness of our proposals. \n\n"}
{"id": "1805.08193", "contents": "Title: Masking: A New Perspective of Noisy Supervision Abstract: It is important to learn various types of classifiers given training data\nwith noisy labels. Noisy labels, in the most popular noise model hitherto, are\ncorrupted from ground-truth labels by an unknown noise transition matrix. Thus,\nby estimating this matrix, classifiers can escape from overfitting those noisy\nlabels. However, such estimation is practically difficult, due to either the\nindirect nature of two-step approaches, or not big enough data to afford\nend-to-end approaches. In this paper, we propose a human-assisted approach\ncalled Masking that conveys human cognition of invalid class transitions and\nnaturally speculates the structure of the noise transition matrix. To this end,\nwe derive a structure-aware probabilistic model incorporating a structure\nprior, and solve the challenges from structure extraction and structure\nalignment. Thanks to Masking, we only estimate unmasked noise transition\nprobabilities and the burden of estimation is tremendously reduced. We conduct\nextensive experiments on CIFAR-10 and CIFAR-100 with three noise structures as\nwell as the industrial-level Clothing1M with agnostic noise structure, and the\nresults show that Masking can improve the robustness of classifiers\nsignificantly. \n\n"}
{"id": "1805.08593", "contents": "Title: Confounding-Robust Policy Improvement Abstract: We study the problem of learning personalized decision policies from\nobservational data while accounting for possible unobserved confounding.\nPrevious approaches, which assume unconfoundedness, i.e., that no unobserved\nconfounders affect both the treatment assignment as well as outcome, can lead\nto policies that introduce harm rather than benefit when some unobserved\nconfounding is present, as is generally the case with observational data.\nInstead, since policy value and regret may not be point-identifiable, we study\na method that minimizes the worst-case estimated regret of a candidate policy\nagainst a baseline policy over an uncertainty set for propensity weights that\ncontrols the extent of unobserved confounding. We prove generalization\nguarantees that ensure our policy will be safe when applied in practice and\nwill in fact obtain the best-possible uniform control on the range of all\npossible population regrets that agree with the possible extent of confounding.\nWe develop efficient algorithmic solutions to compute this confounding-robust\npolicy. Finally, we assess and compare our methods on synthetic and\nsemi-synthetic data. In particular, we consider a case study on personalizing\nhormone replacement therapy based on observational data, where we validate our\nresults on a randomized experiment. We demonstrate that hidden confounding can\nhinder existing policy learning approaches and lead to unwarranted harm, while\nour robust approach guarantees safety and focuses on well-evidenced\nimprovement, a necessity for making personalized treatment policies learned\nfrom observational data reliable in practice. \n\n"}
{"id": "1805.08699", "contents": "Title: OFF-ApexNet on Micro-expression Recognition System Abstract: When a person attempts to conceal an emotion, the genuine emotion is manifest\nas a micro-expression. Exploration of automatic facial micro-expression\nrecognition systems is relatively new in the computer vision domain. This is\ndue to the difficulty in implementing optimal feature extraction methods to\ncope with the subtlety and brief motion characteristics of the expression. Most\nof the existing approaches extract the subtle facial movements based on\nhand-crafted features. In this paper, we address the micro-expression\nrecognition task with a convolutional neural network (CNN) architecture, which\nwell integrates the features extracted from each video. A new feature\ndescriptor, Optical Flow Features from Apex frame Network (OFF-ApexNet) is\nintroduced. This feature descriptor combines the optical ow guided context with\nthe CNN. Firstly, we obtain the location of the apex frame from each video\nsequence as it portrays the highest intensity of facial motion among all\nframes. Then, the optical ow information are attained from the apex frame and a\nreference frame (i.e., onset frame). Finally, the optical flow features are fed\ninto a pre-designed CNN model for further feature enhancement as well as to\ncarry out the expression classification. To evaluate the effectiveness of\nOFF-ApexNet, comprehensive evaluations are conducted on three public\nspontaneous micro-expression datasets (i.e., SMIC, CASME II and SAMM). The\npromising recognition result suggests that the proposed method can optimally\ndescribe the significant micro-expression details. In particular, we report\nthat, in a multi-database with leave-one-subject-out cross-validation\nexperimental protocol, the recognition performance reaches 74.60% of\nrecognition accuracy and F-measure of 71.04%. We also note that this is the\nfirst work that performs cross-dataset validation on three databases in this\ndomain. \n\n"}
{"id": "1805.08709", "contents": "Title: A Simple Cache Model for Image Recognition Abstract: Training large-scale image recognition models is computationally expensive.\nThis raises the question of whether there might be simple ways to improve the\ntest performance of an already trained model without having to re-train or\nfine-tune it with new data. Here, we show that, surprisingly, this is indeed\npossible. The key observation we make is that the layers of a deep network\nclose to the output layer contain independent, easily extractable\nclass-relevant information that is not contained in the output layer itself. We\npropose to extract this extra class-relevant information using a simple\nkey-value cache memory to improve the classification performance of the model\nat test time. Our cache memory is directly inspired by a similar cache model\npreviously proposed for language modeling (Grave et al., 2017). This cache\ncomponent does not require any training or fine-tuning; it can be applied to\nany pre-trained model and, by properly setting only two hyper-parameters, leads\nto significant improvements in its classification performance. Improvements are\nobserved across several architectures and datasets. In the cache component,\nusing features extracted from layers close to the output (but not from the\noutput layer itself) as keys leads to the largest improvements. Concatenating\nfeatures from multiple layers to form keys can further improve performance over\nusing single-layer features as keys. The cache component also has a\nregularizing effect, a simple consequence of which is that it substantially\nincreases the robustness of models against adversarial attacks. \n\n"}
{"id": "1805.08743", "contents": "Title: CascadeCNN: Pushing the performance limits of quantisation Abstract: This work presents CascadeCNN, an automated toolflow that pushes the\nquantisation limits of any given CNN model, to perform high-throughput\ninference by exploiting the computation time-accuracy trade-off. Without the\nneed for retraining, a two-stage architecture tailored for any given FPGA\ndevice is generated, consisting of a low- and a high-precision unit. A\nconfidence evaluation unit is employed between them to identify misclassified\ncases at run time and forward them to the high-precision unit or terminate\ncomputation. Experiments demonstrate that CascadeCNN achieves a performance\nboost of up to 55% for VGG-16 and 48% for AlexNet over the baseline design for\nthe same resource budget and accuracy. \n\n"}
{"id": "1805.08826", "contents": "Title: Rapid seismic domain transfer: Seismic velocity inversion and modeling\n  using deep generative neural networks Abstract: Traditional physics-based approaches to infer sub-surface properties such as\nfull-waveform inversion or reflectivity inversion are time-consuming and\ncomputationally expensive. We present a deep-learning technique that eliminates\nthe need for these computationally complex methods by posing the problem as one\nof domain transfer. Our solution is based on a deep convolutional generative\nadversarial network and dramatically reduces computation time. Training based\non two different types of synthetic data produced a neural network that\ngenerates realistic velocity models when applied to a real dataset. The\nsystem's ability to generalize means it is robust against the inherent\noccurrence of velocity errors and artifacts in both training and test datasets. \n\n"}
{"id": "1805.08974", "contents": "Title: Do Better ImageNet Models Transfer Better? Abstract: Transfer learning is a cornerstone of computer vision, yet little work has\nbeen done to evaluate the relationship between architecture and transfer. An\nimplicit hypothesis in modern computer vision research is that models that\nperform better on ImageNet necessarily perform better on other vision tasks.\nHowever, this hypothesis has never been systematically tested. Here, we compare\nthe performance of 16 classification networks on 12 image classification\ndatasets. We find that, when networks are used as fixed feature extractors or\nfine-tuned, there is a strong correlation between ImageNet accuracy and\ntransfer accuracy ($r = 0.99$ and $0.96$, respectively). In the former setting,\nwe find that this relationship is very sensitive to the way in which networks\nare trained on ImageNet; many common forms of regularization slightly improve\nImageNet accuracy but yield penultimate layer features that are much worse for\ntransfer learning. Additionally, we find that, on two small fine-grained image\nclassification datasets, pretraining on ImageNet provides minimal benefits,\nindicating the learned features from ImageNet do not transfer well to\nfine-grained tasks. Together, our results show that ImageNet architectures\ngeneralize well across datasets, but ImageNet features are less general than\npreviously suggested. \n\n"}
{"id": "1805.09298", "contents": "Title: Learning towards Minimum Hyperspherical Energy Abstract: Neural networks are a powerful class of nonlinear functions that can be\ntrained end-to-end on various applications. While the over-parametrization\nnature in many neural networks renders the ability to fit complex functions and\nthe strong representation power to handle challenging tasks, it also leads to\nhighly correlated neurons that can hurt the generalization ability and incur\nunnecessary computation cost. As a result, how to regularize the network to\navoid undesired representation redundancy becomes an important issue. To this\nend, we draw inspiration from a well-known problem in physics -- Thomson\nproblem, where one seeks to find a state that distributes N electrons on a unit\nsphere as evenly as possible with minimum potential energy. In light of this\nintuition, we reduce the redundancy regularization problem to generic energy\nminimization, and propose a minimum hyperspherical energy (MHE) objective as\ngeneric regularization for neural networks. We also propose a few novel\nvariants of MHE, and provide some insights from a theoretical point of view.\nFinally, we apply neural networks with MHE regularization to several\nchallenging tasks. Extensive experiments demonstrate the effectiveness of our\nintuition, by showing the superior performance with MHE regularization. \n\n"}
{"id": "1805.09701", "contents": "Title: R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual\n  Question Answering Abstract: Recently, Visual Question Answering (VQA) has emerged as one of the most\nsignificant tasks in multimodal learning as it requires understanding both\nvisual and textual modalities. Existing methods mainly rely on extracting image\nand question features to learn their joint feature embedding via multimodal\nfusion or attention mechanism. Some recent studies utilize external\nVQA-independent models to detect candidate entities or attributes in images,\nwhich serve as semantic knowledge complementary to the VQA task. However, these\ncandidate entities or attributes might be unrelated to the VQA task and have\nlimited semantic capacities. To better utilize semantic knowledge in images, we\npropose a novel framework to learn visual relation facts for VQA. Specifically,\nwe build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset\nvia a semantic similarity module, in which each data consists of an image, a\ncorresponding question, a correct answer and a supporting relation fact. A\nwell-defined relation detector is then adopted to predict visual\nquestion-related relation facts. We further propose a multi-step attention\nmodel composed of visual attention and semantic attention sequentially to\nextract related visual knowledge and semantic knowledge. We conduct\ncomprehensive experiments on the two benchmark datasets, demonstrating that our\nmodel achieves state-of-the-art performance and verifying the benefit of\nconsidering visual relation facts. \n\n"}
{"id": "1805.09791", "contents": "Title: Multi-Task Zipping via Layer-wise Neuron Sharing Abstract: Future mobile devices are anticipated to perceive, understand and react to\nthe world on their own by running multiple correlated deep neural networks\non-device. Yet the complexity of these neural networks needs to be trimmed down\nboth within-model and cross-model to fit in mobile storage and memory. Previous\nstudies focus on squeezing the redundancy within a single neural network. In\nthis work, we aim to reduce the redundancy across multiple models. We propose\nMulti-Task Zipping (MTZ), a framework to automatically merge correlated,\npre-trained deep neural networks for cross-model compression. Central in MTZ is\na layer-wise neuron sharing and incoming weight updating scheme that induces a\nminimal change in the error function. MTZ inherits information from each model\nand demands light retraining to re-boost the accuracy of individual tasks.\nEvaluations show that MTZ is able to fully merge the hidden layers of two\nVGG-16 networks with a 3.18% increase in the test error averaged on ImageNet\nand CelebA, or share 39.61% parameters between the two networks with <0.5%\nincrease in the test errors for both tasks. The number of iterations to retrain\nthe combined network is at least 17.8 times lower than that of training a\nsingle VGG-16 network. Moreover, experiments show that MTZ is also able to\neffectively merge multiple residual networks. \n\n"}
{"id": "1805.10002", "contents": "Title: Learning to Propagate Labels: Transductive Propagation Network for\n  Few-shot Learning Abstract: The goal of few-shot learning is to learn a classifier that generalizes well\neven when trained with a limited number of training instances per class. The\nrecently introduced meta-learning approaches tackle this problem by learning a\ngeneric classifier across a large number of multiclass classification tasks and\ngeneralizing the model to a new task. Yet, even with such meta-learning, the\nlow-data problem in the novel classification task still remains. In this paper,\nwe propose Transductive Propagation Network (TPN), a novel meta-learning\nframework for transductive inference that classifies the entire test set at\nonce to alleviate the low-data problem. Specifically, we propose to learn to\npropagate labels from labeled instances to unlabeled test instances, by\nlearning a graph construction module that exploits the manifold structure in\nthe data. TPN jointly learns both the parameters of feature embedding and the\ngraph construction in an end-to-end manner. We validate TPN on multiple\nbenchmark datasets, on which it largely outperforms existing few-shot learning\napproaches and achieves the state-of-the-art results. \n\n"}
{"id": "1805.10777", "contents": "Title: Object-Level Representation Learning for Few-Shot Image Classification Abstract: Few-shot learning that trains image classifiers over few labeled examples per\ncategory is a challenging task. In this paper, we propose to exploit an\nadditional big dataset with different categories to improve the accuracy of\nfew-shot learning over our target dataset. Our approach is based on the\nobservation that images can be decomposed into objects, which may appear in\nimages from both the additional dataset and our target dataset. We use the\nobject-level relation learned from the additional dataset to infer the\nsimilarity of images in our target dataset with unseen categories. Nearest\nneighbor search is applied to do image classification, which is a\nnon-parametric model and thus does not need fine-tuning. We evaluate our\nalgorithm on two popular datasets, namely Omniglot and MiniImagenet. We obtain\n8.5\\% and 2.7\\% absolute improvements for 5-way 1-shot and 5-way 5-shot\nexperiments on MiniImagenet, respectively. Source code will be published upon\nacceptance. \n\n"}
{"id": "1805.10917", "contents": "Title: Deep Anomaly Detection Using Geometric Transformations Abstract: We consider the problem of anomaly detection in images, and present a new\ndetection technique. Given a sample of images, all known to belong to a\n\"normal\" class (e.g., dogs), we show how to train a deep neural model that can\ndetect out-of-distribution images (i.e., non-dog objects). The main idea behind\nour scheme is to train a multi-class model to discriminate between dozens of\ngeometric transformations applied on all the given images. The auxiliary\nexpertise learned by the model generates feature detectors that effectively\nidentify, at test time, anomalous images based on the softmax activation\nstatistics of the model when applied on transformed images. We present\nextensive experiments using the proposed detector, which indicate that our\nalgorithm improves state-of-the-art methods by a wide margin. \n\n"}
{"id": "1805.11204", "contents": "Title: A Statistical Recurrent Model on the Manifold of Symmetric Positive\n  Definite Matrices Abstract: In a number of disciplines, the data (e.g., graphs, manifolds) to be analyzed\nare non-Euclidean in nature. Geometric deep learning corresponds to techniques\nthat generalize deep neural network models to such non-Euclidean spaces.\nSeveral recent papers have shown how convolutional neural networks (CNNs) can\nbe extended to learn with graph-based data. In this work, we study the setting\nwhere the data (or measurements) are ordered, longitudinal or temporal in\nnature and live on a Riemannian manifold -- this setting is common in a variety\nof problems in statistical machine learning, vision and medical imaging. We\nshow how recurrent statistical recurrent network models can be defined in such\nspaces. We give an efficient algorithm and conduct a rigorous analysis of its\nstatistical properties. We perform extensive numerical experiments\ndemonstrating competitive performance with state of the art methods but with\nsignificantly less number of parameters. We also show applications to a\nstatistical analysis task in brain imaging, a regime where deep neural network\nmodels have only been utilized in limited ways. \n\n"}
{"id": "1805.11504", "contents": "Title: Capturing Variabilities from Computed Tomography Images with Generative\n  Adversarial Networks Abstract: With the advent of Deep Learning (DL) techniques, especially Generative\nAdversarial Networks (GANs), data augmentation and generation are quickly\nevolving domains that have raised much interest recently. However, the DL\ntechniques are data demanding and since, medical data is not easily accessible,\nthey suffer from data insufficiency. To deal with this limitation, different\ndata augmentation techniques are used. Here, we propose a novel unsupervised\ndata-driven approach for data augmentation that can generate 2D Computed\nTomography (CT) images using a simple GAN. The generated CT images have good\nglobal and local features of a real CT image and can be used to augment the\ntraining datasets for effective learning. In this proof-of-concept study, we\nshow that our proposed solution using GANs is able to capture some of the\nglobal and local CT variabilities. Our network is able to generate visually\nrealistic CT images and we aim to further enhance its output by scaling it to a\nhigher resolution and potentially from 2D to 3D. \n\n"}
{"id": "1805.11592", "contents": "Title: Playing hard exploration games by watching YouTube Abstract: Deep reinforcement learning methods traditionally struggle with tasks where\nenvironment rewards are particularly sparse. One successful method of guiding\nexploration in these domains is to imitate trajectories provided by a human\ndemonstrator. However, these demonstrations are typically collected under\nartificial conditions, i.e. with access to the agent's exact environment setup\nand the demonstrator's action and reward trajectories. Here we propose a\ntwo-stage method that overcomes these limitations by relying on noisy,\nunaligned footage without access to such data. First, we learn to map unaligned\nvideos from multiple sources to a common representation using self-supervised\nobjectives constructed over both time and modality (i.e. vision and sound).\nSecond, we embed a single YouTube video in this representation to construct a\nreward function that encourages an agent to imitate human gameplay. This method\nof one-shot imitation allows our agent to convincingly exceed human-level\nperformance on the infamously hard exploration games Montezuma's Revenge,\nPitfall! and Private Eye for the first time, even if the agent is not presented\nwith any environment rewards. \n\n"}
{"id": "1805.11815", "contents": "Title: Enabling Pedestrian Safety using Computer Vision Techniques: A Case\n  Study of the 2018 Uber Inc. Self-driving Car Crash Abstract: Human lives are important. The decision to allow self-driving vehicles\noperate on our roads carries great weight. This has been a hot topic of debate\nbetween policy-makers, technologists and public safety institutions. The recent\nUber Inc. self-driving car crash, resulting in the death of a pedestrian, has\nstrengthened the argument that autonomous vehicle technology is still not ready\nfor deployment on public roads. In this work, we analyze the Uber car crash and\nshed light on the question, \"Could the Uber Car Crash have been avoided?\". We\napply state-of-the-art Computer Vision models to this highly practical\nscenario. More generally, our experimental results are an evaluation of various\nimage enhancement and object recognition techniques for enabling pedestrian\nsafety in low-lighting conditions using the Uber crash as a case study. \n\n"}
{"id": "1805.12024", "contents": "Title: Privacy Aware Offloading of Deep Neural Networks Abstract: Deep neural networks require large amounts of resources which makes them hard\nto use on resource constrained devices such as Internet-of-things devices.\nOffloading the computations to the cloud can circumvent these constraints but\nintroduces a privacy risk since the operator of the cloud is not necessarily\ntrustworthy. We propose a technique that obfuscates the data before sending it\nto the remote computation node. The obfuscated data is unintelligible for a\nhuman eavesdropper but can still be classified with a high accuracy by a neural\nnetwork trained on unobfuscated images. \n\n"}
{"id": "1805.12564", "contents": "Title: Modeling 4D fMRI Data via Spatio-Temporal Convolutional Neural Networks\n  (ST-CNN) Abstract: Simultaneous modeling of the spatio-temporal variation patterns of brain\nfunctional network from 4D fMRI data has been an important yet challenging\nproblem for the field of cognitive neuroscience and medical image analysis.\nInspired by the recent success in applying deep learning for functional brain\ndecoding and encoding, in this work we propose a spatio-temporal convolutional\nneural network (ST-CNN)to jointly learn the spatial and temporal patterns of\ntargeted network from the training data and perform automatic, pin-pointing\nfunctional network identification. The proposed ST-CNN is evaluated by the task\nof identifying the Default Mode Network (DMN) from fMRI data. Results show that\nwhile the framework is only trained on one fMRI dataset,it has the sufficient\ngeneralizability to identify the DMN from different populations of data as well\nas different cognitive tasks. Further investigation into the results show that\nthe superior performance of ST-CNN is driven by the jointly-learning scheme,\nwhich capture the intrinsic relationship between the spatial and temporal\ncharacteristic of DMN and ensures the accurate identification. \n\n"}
{"id": "1806.00437", "contents": "Title: Large-Margin Classification in Hyperbolic Space Abstract: Representing data in hyperbolic space can effectively capture latent\nhierarchical relationships. With the goal of enabling accurate classification\nof points in hyperbolic space while respecting their hyperbolic geometry, we\nintroduce hyperbolic SVM, a hyperbolic formulation of support vector machine\nclassifiers, and elucidate through new theoretical work its connection to the\nEuclidean counterpart. We demonstrate the performance improvement of hyperbolic\nSVM for multi-class prediction tasks on real-world complex networks as well as\nsimulated datasets. Our work allows analytic pipelines that take the inherent\nhyperbolic geometry of the data into account in an end-to-end fashion without\nresorting to ill-fitting tools developed for Euclidean space. \n\n"}
{"id": "1806.00525", "contents": "Title: Audio Visual Scene-Aware Dialog (AVSD) Challenge at DSTC7 Abstract: Scene-aware dialog systems will be able to have conversations with users\nabout the objects and events around them. Progress on such systems can be made\nby integrating state-of-the-art technologies from multiple research areas\nincluding end-to-end dialog systems visual dialog, and video description. We\nintroduce the Audio Visual Scene Aware Dialog (AVSD) challenge and dataset. In\nthis challenge, which is one track of the 7th Dialog System Technology\nChallenges (DSTC7) workshop1, the task is to build a system that generates\nresponses in a dialog about an input video \n\n"}
{"id": "1806.00578", "contents": "Title: SCAN: Sliding Convolutional Attention Network for Scene Text Recognition Abstract: Scene text recognition has drawn great attentions in the community of\ncomputer vision and artificial intelligence due to its challenges and wide\napplications. State-of-the-art recurrent neural networks (RNN) based models map\nan input sequence to a variable length output sequence, but are usually applied\nin a black box manner and lack of transparency for further improvement, and the\nmaintaining of the entire past hidden states prevents parallel computation in a\nsequence. In this paper, we investigate the intrinsic characteristics of text\nrecognition, and inspired by human cognition mechanisms in reading texts, we\npropose a scene text recognition method with sliding convolutional attention\nnetwork (SCAN). Similar to the eye movement during reading, the process of SCAN\ncan be viewed as an alternation between saccades and visual fixations. Compared\nto the previous recurrent models, computations over all elements of SCAN can be\nfully parallelized during training. Experimental results on several challenging\nbenchmarks, including the IIIT5k, SVT and ICDAR 2003/2013 datasets, demonstrate\nthe superiority of SCAN over state-of-the-art methods in terms of both the\nmodel interpretability and performance. \n\n"}
{"id": "1806.00580", "contents": "Title: Detecting Adversarial Examples via Key-based Network Abstract: Though deep neural networks have achieved state-of-the-art performance in\nvisual classification, recent studies have shown that they are all vulnerable\nto the attack of adversarial examples. Small and often imperceptible\nperturbations to the input images are sufficient to fool the most powerful deep\nneural networks. Various defense methods have been proposed to address this\nissue. However, they either require knowledge on the process of generating\nadversarial examples, or are not robust against new attacks specifically\ndesigned to penetrate the existing defense. In this work, we introduce\nkey-based network, a new detection-based defense mechanism to distinguish\nadversarial examples from normal ones based on error correcting output codes,\nusing the binary code vectors produced by multiple binary classifiers applied\nto randomly chosen label-sets as signatures to match normal images and reject\nadversarial examples. In contrast to existing defense methods, the proposed\nmethod does not require knowledge of the process for generating adversarial\nexamples and can be applied to defend against different types of attacks. For\nthe practical black-box and gray-box scenarios, where the attacker does not\nknow the encoding scheme, we show empirically that key-based network can\neffectively detect adversarial examples generated by several state-of-the-art\nattacks. \n\n"}
{"id": "1806.00806", "contents": "Title: k-Space Deep Learning for Parallel MRI: Application to Time-Resolved MR\n  Angiography Abstract: Time-resolved angiography with interleaved stochastic trajectories (TWIST)\nhas been widely used for dynamic contrast enhanced MRI (DCE-MRI). To achieve\nhighly accelerated acquisitions, TWIST combines the periphery of the k-space\ndata from several adjacent frames to reconstruct one temporal frame. However,\nthis view-sharing scheme limits the true temporal resolution of TWIST.\nMoreover, the k-space sampling patterns have been specially designed for a\nspecific generalized autocalibrating partial parallel acquisition (GRAPPA)\nfactor so that it is not possible to reduce the number of view-sharing once the\nk-data is acquired. To address these issues, this paper proposes a novel\nk-space deep learning approach for parallel MRI. In particular, we have\ndesigned our neural network so that accurate k-space interpolations are\nperformed simultaneously for multiple coils by exploiting the redundancies\nalong the coils and images. Reconstruction results using in vivo TWIST data set\nconfirm that the proposed method can immediately generate high-quality\nreconstruction results with various choices of view- sharing, allowing us to\nexploit the trade-off between spatial and temporal resolution in time-resolved\nMR angiography. \n\n"}
{"id": "1806.00880", "contents": "Title: Disconnected Manifold Learning for Generative Adversarial Networks Abstract: Natural images may lie on a union of disjoint manifolds rather than one\nglobally connected manifold, and this can cause several difficulties for the\ntraining of common Generative Adversarial Networks (GANs). In this work, we\nfirst show that single generator GANs are unable to correctly model a\ndistribution supported on a disconnected manifold, and investigate how sample\nquality, mode dropping and local convergence are affected by this. Next, we\nshow how using a collection of generators can address this problem, providing\nnew insights into the success of such multi-generator GANs. Finally, we explain\nthe serious issues caused by considering a fixed prior over the collection of\ngenerators and propose a novel approach for learning the prior and inferring\nthe necessary number of generators without any supervision. Our proposed\nmodifications can be applied on top of any other GAN model to enable learning\nof distributions supported on disconnected manifolds. We conduct several\nexperiments to illustrate the aforementioned shortcoming of GANs, its\nconsequences in practice, and the effectiveness of our proposed modifications\nin alleviating these issues. \n\n"}
{"id": "1806.00914", "contents": "Title: How Much Are You Willing to Share? A \"Poker-Styled\" Selective Privacy\n  Preserving Framework for Recommender Systems Abstract: Most industrial recommender systems rely on the popular collaborative\nfiltering (CF) technique for providing personalized recommendations to its\nusers. However, the very nature of CF is adversarial to the idea of user\nprivacy, because users need to share their preferences with others in order to\nbe grouped with like-minded people and receive accurate recommendations. While\nprevious privacy preserving approaches have been successful inasmuch as they\nconcealed user preference information to some extent from a centralized\nrecommender system, they have also, nevertheless, incurred significant\ntrade-offs in terms of privacy, scalability, and accuracy. They are also\nvulnerable to privacy breaches by malicious actors. In light of these\nobservations, we propose a novel selective privacy preserving (SP2) paradigm\nthat allows users to custom define the scope and extent of their individual\nprivacies, by marking their personal ratings as either public (which can be\nshared) or private (which are never shared and stored only on the user device).\nOur SP2 framework works in two steps: (i) First, it builds an initial\nrecommendation model based on the sum of all public ratings that have been\nshared by users and (ii) then, this public model is fine-tuned on each user's\ndevice based on the user private ratings, thus eventually learning a more\naccurate model. Furthermore, in this work, we introduce three different\nalgorithms for implementing an end-to-end SP2 framework that can scale\neffectively from thousands to hundreds of millions of items. Our user survey\nshows that an overwhelming fraction of users are likely to rate much more items\nto improve the overall recommendations when they can control what ratings will\nbe publicly shared with others. \n\n"}
{"id": "1806.00921", "contents": "Title: Automatic catheter detection in pediatric X-ray images using a\n  scale-recurrent network and synthetic data Abstract: Catheters are commonly inserted life supporting devices. X-ray images are\nused to assess the position of a catheter immediately after placement as\nserious complications can arise from malpositioned catheters. Previous computer\nvision approaches to detect catheters on X-ray images either relied on\nlow-level cues that are not sufficiently robust or only capable of processing a\nlimited number or type of catheters. With the resurgence of deep learning,\nsupervised training approaches are begining to showing promising results.\nHowever, dense annotation maps are required, and the work of a human annotator\nis hard to scale. In this work, we proposed a simple way of synthesizing\ncatheters on X-ray images and a scale recurrent network for catheter detection.\nBy training on adult chest X-rays, the proposed network exhibits promising\ndetection results on pediatric chest/abdomen X-rays in terms of both precision\nand recall. \n\n"}
{"id": "1806.01678", "contents": "Title: A Projection Method for Metric-Constrained Optimization Abstract: We outline a new approach for solving optimization problems which enforce\ntriangle inequalities on output variables. We refer to this as\nmetric-constrained optimization, and give several examples where problems of\nthis form arise in machine learning applications and theoretical approximation\nalgorithms for graph clustering. Although these problem are interesting from a\ntheoretical perspective, they are challenging to solve in practice due to the\nhigh memory requirement of black-box solvers. In order to address this\nchallenge we first prove that the metric-constrained linear program relaxation\nof correlation clustering is equivalent to a special case of the metric\nnearness problem. We then developed a general solver for metric-constrained\nlinear and quadratic programs by generalizing and improving a simple projection\nalgorithm originally developed for metric nearness. We give several novel\napproximation guarantees for using our framework to find lower bounds for\noptimal solutions to several challenging graph clustering problems. We also\ndemonstrate the power of our framework by solving optimizing problems involving\nup to 10^{8} variables and 10^{11} constraints. \n\n"}
{"id": "1806.01845", "contents": "Title: Deep Neural Networks with Multi-Branch Architectures Are Less Non-Convex Abstract: Several recently proposed architectures of neural networks such as ResNeXt,\nInception, Xception, SqueezeNet and Wide ResNet are based on the designing idea\nof having multiple branches and have demonstrated improved performance in many\napplications. We show that one cause for such success is due to the fact that\nthe multi-branch architecture is less non-convex in terms of duality gap. The\nduality gap measures the degree of intrinsic non-convexity of an optimization\nproblem: smaller gap in relative value implies lower degree of intrinsic\nnon-convexity. The challenge is to quantitatively measure the duality gap of\nhighly non-convex problems such as deep neural networks. In this work, we\nprovide strong guarantees of this quantity for two classes of network\narchitectures. For the neural networks with arbitrary activation functions,\nmulti-branch architecture and a variant of hinge loss, we show that the duality\ngap of both population and empirical risks shrinks to zero as the number of\nbranches increases. This result sheds light on better understanding the power\nof over-parametrization where increasing the network width tends to make the\nloss surface less non-convex. For the neural networks with linear activation\nfunction and $\\ell_2$ loss, we show that the duality gap of empirical risk is\nzero. Our two results work for arbitrary depths and adversarial data, while the\nanalytical techniques might be of independent interest to non-convex\noptimization more broadly. Experiments on both synthetic and real-world\ndatasets validate our results. \n\n"}
{"id": "1806.02003", "contents": "Title: Deep Algorithms: designs for networks Abstract: A new design methodology for neural networks that is guided by traditional\nalgorithm design is presented. To prove our point, we present two heuristics\nand demonstrate an algorithmic technique for incorporating additional weights\nin their signal-flow graphs. We show that with training the performance of\nthese networks can not only exceed the performance of the initial network, but\ncan match the performance of more-traditional neural network architectures. A\nkey feature of our approach is that these networks are initialized with\nparameters that provide a known performance threshold for the architecture on a\ngiven task. \n\n"}
{"id": "1806.02318", "contents": "Title: Adaptive feature recombination and recalibration for semantic\n  segmentation: application to brain tumor segmentation in MRI Abstract: Convolutional neural networks (CNNs) have been successfully used for brain\ntumor segmentation, specifically, fully convolutional networks (FCNs). FCNs can\nsegment a set of voxels at once, having a direct spatial correspondence between\nunits in feature maps (FMs) at a given location and the corresponding\nclassified voxels. In convolutional layers, FMs are merged to create new FMs,\nso, channel combination is crucial. However, not all FMs have the same\nrelevance for a given class. Recently, in classification problems,\nSqueeze-and-Excitation (SE) blocks have been proposed to re-calibrate FMs as a\nwhole, and suppress the less informative ones. However, this is not optimal in\nFCN due to the spatial correspondence between units and voxels. In this\narticle, we propose feature recombination through linear expansion and\ncompression to create more complex features for semantic segmentation.\nAdditionally, we propose a segmentation SE (SegSE) block for feature\nrecalibration that collects contextual information, while maintaining the\nspatial meaning. Finally, we evaluate the proposed methods in brain tumor\nsegmentation, using publicly available data. \n\n"}
{"id": "1806.02583", "contents": "Title: Generative Adversarial Networks for Realistic Synthesis of Hyperspectral\n  Samples Abstract: This work addresses the scarcity of annotated hyperspectral data required to\ntrain deep neural networks. Especially, we investigate generative adversarial\nnetworks and their application to the synthesis of consistent labeled spectra.\nBy training such networks on public datasets, we show that these models are not\nonly able to capture the underlying distribution, but also to generate\ngenuine-looking and physically plausible spectra. Moreover, we experimentally\nvalidate that the synthetic samples can be used as an effective data\naugmentation strategy. We validate our approach on several public\nhyper-spectral datasets using a variety of deep classifiers. \n\n"}
{"id": "1806.02679", "contents": "Title: Semi-Supervised Learning via Compact Latent Space Clustering Abstract: We present a novel cost function for semi-supervised learning of neural\nnetworks that encourages compact clustering of the latent space to facilitate\nseparation. The key idea is to dynamically create a graph over embeddings of\nlabeled and unlabeled samples of a training batch to capture underlying\nstructure in feature space, and use label propagation to estimate its high and\nlow density regions. We then devise a cost function based on Markov chains on\nthe graph that regularizes the latent space to form a single compact cluster\nper class, while avoiding to disturb existing clusters during optimization. We\nevaluate our approach on three benchmarks and compare to state-of-the art with\npromising results. Our approach combines the benefits of graph-based\nregularization with efficient, inductive inference, does not require\nmodifications to a network architecture, and can thus be easily applied to\nexisting networks to enable an effective use of unlabeled data. \n\n"}
{"id": "1806.02682", "contents": "Title: Transfer Learning for Illustration Classification Abstract: The field of image classification has shown an outstanding success thanks to\nthe development of deep learning techniques. Despite the great performance\nobtained, most of the work has focused on natural images ignoring other domains\nlike artistic depictions. In this paper, we use transfer learning techniques to\npropose a new classification network with better performance in illustration\nimages. Starting from the deep convolutional network VGG19, pre-trained with\nnatural images, we propose two novel models which learn object representations\nin the new domain. Our optimized network will learn new low-level features of\nthe images (colours, edges, textures) while keeping the knowledge of the\nobjects and shapes that it already learned from the ImageNet dataset. Thus,\nrequiring much less data for the training. We propose a novel dataset of\nillustration images labelled by content where our optimized architecture\nachieves $\\textbf{86.61\\%}$ of top-1 and $\\textbf{97.21\\%}$ of top-5 precision.\nWe additionally demonstrate that our model is still able to recognize objects\nin photographs. \n\n"}
{"id": "1806.02934", "contents": "Title: Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse\n  Annotations Abstract: Many structured prediction problems (particularly in vision and language\ndomains) are ambiguous, with multiple outputs being correct for an input - e.g.\nthere are many ways of describing an image, multiple ways of translating a\nsentence; however, exhaustively annotating the applicability of all possible\noutputs is intractable due to exponentially large output spaces (e.g. all\nEnglish sentences). In practice, these problems are cast as multi-class\nprediction, with the likelihood of only a sparse set of annotations being\nmaximized - unfortunately penalizing for placing beliefs on plausible but\nunannotated outputs. We make and test the following hypothesis - for a given\ninput, the annotations of its neighbors may serve as an additional supervisory\nsignal. Specifically, we propose an objective that transfers supervision from\nneighboring examples. We first study the properties of our developed method in\na controlled toy setup before reporting results on multi-label classification\nand two image-grounded sequence modeling tasks - captioning and question\ngeneration. We evaluate using standard task-specific metrics and measures of\noutput diversity, finding consistent improvements over standard maximum\nlikelihood training and other baselines. \n\n"}
{"id": "1806.03028", "contents": "Title: Unsupervised Feature Learning Toward a Real-time Vehicle Make and Model\n  Recognition Abstract: Vehicle Make and Model Recognition (MMR) systems provide a fully automatic\nframework to recognize and classify different vehicle models. Several\napproaches have been proposed to address this challenge, however they can\nperform in restricted conditions. Here, we formulate the vehicle make and model\nrecognition as a fine-grained classification problem and propose a new\nconfigurable on-road vehicle make and model recognition framework. We benefit\nfrom the unsupervised feature learning methods and in more details we employ\nLocality constraint Linear Coding (LLC) method as a fast feature encoder for\nencoding the input SIFT features. The proposed method can perform in real\nenvironments of different conditions. This framework can recognize fifty models\nof vehicles and has an advantage to classify every other vehicle not belonging\nto one of the specified fifty classes as an unknown vehicle. The proposed MMR\nframework can be configured to become faster or more accurate based on the\napplication domain. The proposed approach is examined on two datasets including\nIranian on-road vehicle dataset and CompuCar dataset. The Iranian on-road\nvehicle dataset contains images of 50 models of vehicles captured in real\nsituations by traffic cameras in different weather and lighting conditions.\nExperimental results show superiority of the proposed framework over the\nstate-of-the-art methods on Iranian on-road vehicle datatset and comparable\nresults on CompuCar dataset with 97.5% and 98.4% accuracies, respectively. \n\n"}
{"id": "1806.03796", "contents": "Title: Generative Adversarial Network Architectures For Image Synthesis Using\n  Capsule Networks Abstract: In this paper, we propose Generative Adversarial Network (GAN) architectures\nthat use Capsule Networks for image-synthesis. Based on the principal of\npositional-equivariance of features, Capsule Network's ability to encode\nspatial relationships between the features of the image helps it become a more\npowerful critic in comparison to Convolutional Neural Networks (CNNs) used in\ncurrent architectures for image synthesis. Our proposed GAN architectures learn\nthe data manifold much faster and therefore, synthesize visually accurate\nimages in significantly lesser number of training samples and training epochs\nin comparison to GANs and its variants that use CNNs. Apart from analyzing the\nquantitative results corresponding the images generated by different\narchitectures, we also explore the reasons for the lower coverage and diversity\nexplored by the GAN architectures that use CNN critics. \n\n"}
{"id": "1806.04012", "contents": "Title: Hierarchy of GANs for learning embodied self-awareness model Abstract: In recent years several architectures have been proposed to learn embodied\nagents complex self-awareness models. In this paper, dynamic incremental\nself-awareness (SA) models are proposed that allow experiences done by an agent\nto be modeled in a hierarchical fashion, starting from more simple situations\nto more structured ones. Each situation is learned from subsets of private\nagent perception data as a model capable to predict normal behaviors and detect\nabnormalities. Hierarchical SA models have been already proposed using low\ndimensional sensorial inputs. In this work, a hierarchical model is introduced\nby means of a cross-modal Generative Adversarial Networks (GANs) processing\nhigh dimensional visual data. Different levels of the GANs are detected in a\nself-supervised manner using GANs discriminators decision boundaries. Real\nexperiments on semi-autonomous ground vehicles are presented. \n\n"}
{"id": "1806.04224", "contents": "Title: NeuroNet: Fast and Robust Reproduction of Multiple Brain Image\n  Segmentation Pipelines Abstract: NeuroNet is a deep convolutional neural network mimicking multiple popular\nand state-of-the-art brain segmentation tools including FSL, SPM, and MALPEM.\nThe network is trained on 5,000 T1-weighted brain MRI scans from the UK Biobank\nImaging Study that have been automatically segmented into brain tissue and\ncortical and sub-cortical structures using the standard neuroimaging pipelines.\nTraining a single model from these complementary and partially overlapping\nlabel maps yields a new powerful \"all-in-one\", multi-output segmentation tool.\nThe processing time for a single subject is reduced by an order of magnitude\ncompared to running each individual software package. We demonstrate very good\nreproducibility of the original outputs while increasing robustness to\nvariations in the input data. We believe NeuroNet could be an important tool in\nlarge-scale population imaging studies and serve as a new standard in\nneuroscience by reducing the risk of introducing bias when choosing a specific\nsoftware package. \n\n"}
{"id": "1806.04932", "contents": "Title: Reservoir Computing Hardware with Cellular Automata Abstract: Elementary cellular automata (ECA) is a widely studied one-dimensional\nprocessing methodology where the successive iteration of the automaton may lead\nto the recreation of a rich pattern dynamic. Recently, cellular automata have\nbeen proposed as a feasible way to implement Reservoir Computing (RC) systems\nin which the automata rule is fixed and the training is performed using a\nlinear regression. In this work we perform an exhaustive study of the\nperformance of the different ECA rules when applied to pattern recognition of\ntime-independent input signals using a RC scheme. Once the different ECA rules\nhave been tested, the most accurate one (rule 90) is selected to implement a\ndigital circuit. Rule 90 is easily reproduced using a reduced set of XOR gates\nand shift-registers, thus representing a high-performance alternative for RC\nhardware implementation in terms of processing time, circuit area, power\ndissipation and system accuracy. The model (both in software and its hardware\nimplementation) has been tested using a pattern recognition task of handwritten\nnumbers (the MNIST database) for which we obtained competitive results in terms\nof accuracy, speed and power dissipation. The proposed model can be considered\nto be a low-cost method to implement fast pattern recognition digital circuits. \n\n"}
{"id": "1806.05034", "contents": "Title: A Probabilistic U-Net for Segmentation of Ambiguous Images Abstract: Many real-world vision problems suffer from inherent ambiguities. In clinical\napplications for example, it might not be clear from a CT scan alone which\nparticular region is cancer tissue. Therefore a group of graders typically\nproduces a set of diverse but plausible segmentations. We consider the task of\nlearning a distribution over segmentations given an input. To this end we\npropose a generative segmentation model based on a combination of a U-Net with\na conditional variational autoencoder that is capable of efficiently producing\nan unlimited number of plausible hypotheses. We show on a lung abnormalities\nsegmentation task and on a Cityscapes segmentation task that our model\nreproduces the possible segmentation variants as well as the frequencies with\nwhich they occur, doing so significantly better than published approaches.\nThese models could have a high impact in real-world applications, such as being\nused as clinical decision-making algorithms accounting for multiple plausible\nsemantic segmentation hypotheses to provide possible diagnoses and recommend\nfurther actions to resolve the present ambiguities. \n\n"}
{"id": "1806.05226", "contents": "Title: Human Activity Recognition Based on Wearable Sensor Data: A\n  Standardization of the State-of-the-Art Abstract: Human activity recognition based on wearable sensor data has been an\nattractive research topic due to its application in areas such as healthcare\nand smart environments. In this context, many works have presented remarkable\nresults using accelerometer, gyroscope and magnetometer data to represent the\nactivities categories. However, current studies do not consider important\nissues that lead to skewed results, making it hard to assess the quality of\nsensor-based human activity recognition and preventing a direct comparison of\nprevious works. These issues include the samples generation processes and the\nvalidation protocols used. We emphasize that in other research areas, such as\nimage classification and object detection, these issues are already\nwell-defined, which brings more efforts towards the application. Inspired by\nthis, we conduct an extensive set of experiments that analyze different sample\ngeneration processes and validation protocols to indicate the vulnerable points\nin human activity recognition based on wearable sensor data. For this purpose,\nwe implement and evaluate several top-performance methods, ranging from\nhandcrafted-based approaches to convolutional neural networks. According to our\nstudy, most of the experimental evaluations that are currently employed are not\nadequate to perform the activity recognition in the context of wearable sensor\ndata, in which the recognition accuracy drops considerably when compared to an\nappropriate evaluation approach. To the best of our knowledge, this is the\nfirst study that tackles essential issues that compromise the understanding of\nthe performance in human activity recognition based on wearable sensor data. \n\n"}
{"id": "1806.05421", "contents": "Title: Selfless Sequential Learning Abstract: Sequential learning, also called lifelong learning, studies the problem of\nlearning tasks in a sequence with access restricted to only the data of the\ncurrent task. In this paper we look at a scenario with fixed model capacity,\nand postulate that the learning process should not be selfish, i.e. it should\naccount for future tasks to be added and thus leave enough capacity for them.\nTo achieve Selfless Sequential Learning we study different regularization\nstrategies and activation functions. We find that imposing sparsity at the\nlevel of the representation (i.e.~neuron activations) is more beneficial for\nsequential learning than encouraging parameter sparsity. In particular, we\npropose a novel regularizer, that encourages representation sparsity by means\nof neural inhibition. It results in few active neurons which in turn leaves\nmore free neurons to be utilized by upcoming tasks. As neural inhibition over\nan entire layer can be too drastic, especially for complex tasks requiring\nstrong representations, our regularizer only inhibits other neurons in a local\nneighbourhood, inspired by lateral inhibition processes in the brain. We\ncombine our novel regularizer, with state-of-the-art lifelong learning methods\nthat penalize changes to important previously learned parts of the network. We\nshow that our new regularizer leads to increased sparsity which translates in\nconsistent performance improvement %over alternative regularizers we studied on\ndiverse datasets. \n\n"}
{"id": "1806.05473", "contents": "Title: Efficient Active Learning for Image Classification and Segmentation\n  using a Sample Selection and Conditional Generative Adversarial Network Abstract: Training robust deep learning (DL) systems for medical image classification\nor segmentation is challenging due to limited images covering different disease\ntypes and severity. We propose an active learning (AL) framework to select most\ninformative samples and add to the training data. We use conditional generative\nadversarial networks (cGANs) to generate realistic chest xray images with\ndifferent disease characteristics by conditioning its generation on a real\nimage sample. Informative samples to add to the training set are identified\nusing a Bayesian neural network. Experiments show our proposed AL framework is\nable to achieve state of the art performance by using about 35% of the full\ndataset, thus saving significant time and effort over conventional methods. \n\n"}
{"id": "1806.05512", "contents": "Title: NetScore: Towards Universal Metrics for Large-scale Performance Analysis\n  of Deep Neural Networks for Practical On-Device Edge Usage Abstract: Much of the focus in the design of deep neural networks has been on improving\naccuracy, leading to more powerful yet highly complex network architectures\nthat are difficult to deploy in practical scenarios, particularly on edge\ndevices such as mobile and other consumer devices given their high\ncomputational and memory requirements. As a result, there has been a recent\ninterest in the design of quantitative metrics for evaluating deep neural\nnetworks that accounts for more than just model accuracy as the sole indicator\nof network performance. In this study, we continue the conversation towards\nuniversal metrics for evaluating the performance of deep neural networks for\npractical on-device edge usage. In particular, we propose a new balanced metric\ncalled NetScore, which is designed specifically to provide a quantitative\nassessment of the balance between accuracy, computational complexity, and\nnetwork architecture complexity of a deep neural network, which is important\nfor on-device edge operation. In what is one of the largest comparative\nanalysis between deep neural networks in literature, the NetScore metric, the\ntop-1 accuracy metric, and the popular information density metric were compared\nacross a diverse set of 60 different deep convolutional neural networks for\nimage classification on the ImageNet Large Scale Visual Recognition Challenge\n(ILSVRC 2012) dataset. The evaluation results across these three metrics for\nthis diverse set of networks are presented in this study to act as a reference\nguide for practitioners in the field. The proposed NetScore metric, along with\nthe other tested metrics, are by no means perfect, but the hope is to push the\nconversation towards better universal metrics for evaluating deep neural\nnetworks for use in practical on-device edge scenarios to help guide\npractitioners in model design for such scenarios. \n\n"}
{"id": "1806.05789", "contents": "Title: Image classification and retrieval with random depthwise signed\n  convolutional neural networks Abstract: We propose a random convolutional neural network to generate a feature space\nin which we study image classification and retrieval performance. Put briefly\nwe apply random convolutional blocks followed by global average pooling to\ngenerate a new feature, and we repeat this k times to produce a k-dimensional\nfeature space. This can be interpreted as partitioning the space of image\npatches with random hyperplanes which we formalize as a random depthwise\nconvolutional neural network. In the network's final layer we perform image\nclassification and retrieval with the linear support vector machine and\nk-nearest neighbor classifiers and study other empirical properties. We show\nthat the ratio of image pixel distribution similarity across classes to within\nclasses is higher in our network's final layer compared to the input space.\nWhen we apply the linear support vector machine for image classification we see\nthat the accuracy is higher than if we were to train just the final layer of\nVGG16, ResNet18, and DenseNet40 with random weights. In the same setting we\ncompare it to an unsupervised feature learning method and find our accuracy to\nbe comparable on CIFAR10 but higher on CIFAR100 and STL10. We see that the\naccuracy is not far behind that of trained networks, particularly in the top-k\nsetting. For example the top-2 accuracy of our network is near 90% on both\nCIFAR10 and a 10-class mini ImageNet, and 85% on STL10. We find that k-nearest\nneighbor gives a comparable precision on the Corel Princeton Image Similarity\nBenchmark than if we were to use the final layer of trained networks. As with\nother networks we find that our network fails to a black box attack even though\nwe lack a gradient and use the sign activation. We highlight sensitivity of our\nnetwork to background as a potential pitfall and an advantage. Overall our work\npushes the boundary of what can be achieved with random weights. \n\n"}
{"id": "1806.05805", "contents": "Title: Molecular generative model based on conditional variational autoencoder\n  for de novo molecular design Abstract: We propose a molecular generative model based on the conditional variational\nautoencoder for de novo molecular design. It is specialized to control multiple\nmolecular properties simultaneously by imposing them on a latent space. As a\nproof of concept, we demonstrate that it can be used to generate drug-like\nmolecules with five target properties. We were also able to adjust a single\nproperty without changing the others and to manipulate it beyond the range of\nthe dataset. \n\n"}
{"id": "1806.05978", "contents": "Title: Uncertainty Estimations by Softplus normalization in Bayesian\n  Convolutional Neural Networks with Variational Inference Abstract: We introduce a novel uncertainty estimation for classification tasks for\nBayesian convolutional neural networks with variational inference. By\nnormalizing the output of a Softplus function in the final layer, we estimate\naleatoric and epistemic uncertainty in a coherent manner. The intractable\nposterior probability distributions over weights are inferred by Bayes by\nBackprop. Firstly, we demonstrate how this reliable variational inference\nmethod can serve as a fundamental construct for various network architectures.\nOn multiple datasets in supervised learning settings (MNIST, CIFAR-10,\nCIFAR-100), this variational inference method achieves performances equivalent\nto frequentist inference in identical architectures, while the two desiderata,\na measure for uncertainty and regularization are incorporated naturally.\nSecondly, we examine how our proposed measure for aleatoric and epistemic\nuncertainties is derived and validate it on the aforementioned datasets. \n\n"}
{"id": "1806.06296", "contents": "Title: Right for the Right Reason: Training Agnostic Networks Abstract: We consider the problem of a neural network being requested to classify\nimages (or other inputs) without making implicit use of a \"protected concept\",\nthat is a concept that should not play any role in the decision of the network.\nTypically these concepts include information such as gender or race, or other\ncontextual information such as image backgrounds that might be implicitly\nreflected in unknown correlations with other variables, making it insufficient\nto simply remove them from the input features. In other words, making accurate\npredictions is not good enough if those predictions rely on information that\nshould not be used: predictive performance is not the only important metric for\nlearning systems. We apply a method developed in the context of domain\nadaptation to address this problem of \"being right for the right reason\", where\nwe request a classifier to make a decision in a way that is entirely 'agnostic'\nto a given protected concept (e.g. gender, race, background etc.), even if this\ncould be implicitly reflected in other attributes via unknown correlations.\nAfter defining the concept of an 'agnostic model', we demonstrate how the\nDomain-Adversarial Neural Network can remove unwanted information from a model\nusing a gradient reversal layer. \n\n"}
{"id": "1806.06519", "contents": "Title: HitNet: a neural network with capsules embedded in a Hit-or-Miss layer,\n  extended with hybrid data augmentation and ghost capsules Abstract: Neural networks designed for the task of classification have become a\ncommodity in recent years. Many works target the development of better\nnetworks, which results in a complexification of their architectures with more\nlayers, multiple sub-networks, or even the combination of multiple classifiers.\nIn this paper, we show how to redesign a simple network to reach excellent\nperformances, which are better than the results reproduced with CapsNet on\nseveral datasets, by replacing a layer with a Hit-or-Miss layer. This layer\ncontains activated vectors, called capsules, that we train to hit or miss a\ncentral capsule by tailoring a specific centripetal loss function. We also show\nhow our network, named HitNet, is capable of synthesizing a representative\nsample of the images of a given class by including a reconstruction network.\nThis possibility allows to develop a data augmentation step combining\ninformation from the data space and the feature space, resulting in a hybrid\ndata augmentation process. In addition, we introduce the possibility for\nHitNet, to adopt an alternative to the true target when needed by using the new\nconcept of ghost capsules, which is used here to detect potentially mislabeled\nimages in the training data. \n\n"}
{"id": "1806.06763", "contents": "Title: Closing the Generalization Gap of Adaptive Gradient Methods in Training\n  Deep Neural Networks Abstract: Adaptive gradient methods, which adopt historical gradient information to\nautomatically adjust the learning rate, despite the nice property of fast\nconvergence, have been observed to generalize worse than stochastic gradient\ndescent (SGD) with momentum in training deep neural networks. This leaves how\nto close the generalization gap of adaptive gradient methods an open problem.\nIn this work, we show that adaptive gradient methods such as Adam, Amsgrad, are\nsometimes \"over adapted\". We design a new algorithm, called Partially adaptive\nmomentum estimation method, which unifies the Adam/Amsgrad with SGD by\nintroducing a partial adaptive parameter $p$, to achieve the best from both\nworlds. We also prove the convergence rate of our proposed algorithm to a\nstationary point in the stochastic nonconvex optimization setting. Experiments\non standard benchmarks show that our proposed algorithm can maintain a fast\nconvergence rate as Adam/Amsgrad while generalizing as well as SGD in training\ndeep neural networks. These results would suggest practitioners pick up\nadaptive gradient methods once again for faster training of deep neural\nnetworks. \n\n"}
{"id": "1806.06926", "contents": "Title: Understanding Patch-Based Learning by Explaining Predictions Abstract: Deep networks are able to learn highly predictive models of video data. Due\nto video length, a common strategy is to train them on small video snippets. We\napply the deep Taylor / LRP technique to understand the deep network's\nclassification decisions, and identify a \"border effect\": a tendency of the\nclassifier to look mainly at the bordering frames of the input. This effect\nrelates to the step size used to build the video snippet, which we can then\ntune in order to improve the classifier's accuracy without retraining the\nmodel. To our knowledge, this is the the first work to apply the deep Taylor /\nLRP technique on any video analyzing neural network. \n\n"}
{"id": "1806.07174", "contents": "Title: FRnet-DTI: Deep Convolutional Neural Networks with Evolutionary and\n  Structural Features for Drug-Target Interaction Abstract: The task of drug-target interaction prediction holds significant importance\nin pharmacology and therapeutic drug design. In this paper, we present\nFRnet-DTI, an auto encoder and a convolutional classifier for feature\nmanipulation and drug target interaction prediction. Two convolutional neural\nneworks are proposed where one model is used for feature manipulation and the\nother one for classification. Using the first method FRnet-1, we generate 4096\nfeatures for each of the instances in each of the datasets and use the second\nmethod, FRnet-2, to identify interaction probability employing those features.\nWe have tested our method on four gold standard datasets exhaustively used by\nother researchers. Experimental results shows that our method significantly\nimproves over the state-of-the-art method on three of the four drug-target\ninteraction gold standard datasets on both area under curve for Receiver\nOperating Characteristic(auROC) and area under Precision Recall curve(auPR)\nmetric. We also introduce twenty new potential drug-target pairs for\ninteraction based on high prediction scores. Codes Available: https: // github.\ncom/ farshidrayhanuiu/ FRnet-DTI/ Web Implementation: http: // farshidrayhan.\npythonanywhere. com/ FRnet-DTI/ \n\n"}
{"id": "1806.07409", "contents": "Title: Built-in Vulnerabilities to Imperceptible Adversarial Perturbations Abstract: Designing models that are robust to small adversarial perturbations of their\ninputs has proven remarkably difficult. In this work we show that the reverse\nproblem---making models more vulnerable---is surprisingly easy. After\npresenting some proofs of concept on MNIST, we introduce a generic tilting\nattack that injects vulnerabilities into the linear layers of pre-trained\nnetworks by increasing their sensitivity to components of low variance in the\ntraining data without affecting their performance on test data. We illustrate\nthis attack on a multilayer perceptron trained on SVHN and use it to design a\nstand-alone adversarial module which we call a steganogram decoder. Finally, we\nshow on CIFAR-10 that a poisoning attack with a poisoning rate as low as 0.1%\ncan induce vulnerabilities to chosen imperceptible backdoor signals in\nstate-of-the-art networks. Beyond their practical implications, these different\nresults shed new light on the nature of the adversarial example phenomenon. \n\n"}
{"id": "1806.07537", "contents": "Title: DeepAffinity: Interpretable Deep Learning of Compound-Protein Affinity\n  through Unified Recurrent and Convolutional Neural Networks Abstract: Motivation: Drug discovery demands rapid quantification of compound-protein\ninteraction (CPI). However, there is a lack of methods that can predict\ncompound-protein affinity from sequences alone with high applicability,\naccuracy, and interpretability.\n  Results: We present a seamless integration of domain knowledges and\nlearning-based approaches. Under novel representations of\nstructurally-annotated protein sequences, a semi-supervised deep learning model\nthat unifies recurrent and convolutional neural networks has been proposed to\nexploit both unlabeled and labeled data, for jointly encoding molecular\nrepresentations and predicting affinities. Our representations and models\noutperform conventional options in achieving relative error in IC$_{50}$ within\n5-fold for test cases and 20-fold for protein classes not included for\ntraining. Performances for new protein classes with few labeled data are\nfurther improved by transfer learning. Furthermore, separate and joint\nattention mechanisms are developed and embedded to our model to add to its\ninterpretability, as illustrated in case studies for predicting and explaining\nselective drug-target interactions. Lastly, alternative representations using\nprotein sequences or compound graphs and a unified RNN/GCNN-CNN model using\ngraph CNN (GCNN) are also explored to reveal algorithmic challenges ahead.\n  Availability: Data and source codes are available at\nhttps://github.com/Shen-Lab/DeepAffinity\n  Supplementary Information: Supplementary data are available at\nhttp://shen-lab.github.io/deep-affinity-bioinf18-supp-rev.pdf \n\n"}
{"id": "1806.07569", "contents": "Title: A Distributed Second-Order Algorithm You Can Trust Abstract: Due to the rapid growth of data and computational resources, distributed\noptimization has become an active research area in recent years. While\nfirst-order methods seem to dominate the field, second-order methods are\nnevertheless attractive as they potentially require fewer communication rounds\nto converge. However, there are significant drawbacks that impede their wide\nadoption, such as the computation and the communication of a large Hessian\nmatrix. In this paper we present a new algorithm for distributed training of\ngeneralized linear models that only requires the computation of diagonal blocks\nof the Hessian matrix on the individual workers. To deal with this approximate\ninformation we propose an adaptive approach that - akin to trust-region methods\n- dynamically adapts the auxiliary model to compensate for modeling errors. We\nprovide theoretical rates of convergence for a wide class of problems including\nL1-regularized objectives. We also demonstrate that our approach achieves\nstate-of-the-art results on multiple large benchmark datasets. \n\n"}
{"id": "1806.07589", "contents": "Title: A CADe System for Gliomas in Brain MRI using Convolutional Neural\n  Networks Abstract: Inspired by the success of Convolutional Neural Networks (CNN), we develop a\nnovel Computer Aided Detection (CADe) system using CNN for Glioblastoma\nMultiforme (GBM) detection and segmentation from multi channel MRI data. A\ntwo-stage approach first identifies the presence of GBM. This is followed by a\nGBM localization in each \"abnormal\" MR slice. As part of the CADe system, two\nCNN architectures viz. Classification CNN (C-CNN) and Detection CNN (D-CNN) are\nemployed. The CADe system considers MRI data consisting of four sequences\n($T_1$, $T_{1c},$ $T_2$, and $T_{2FLAIR}$) as input, and automatically\ngenerates the bounding boxes encompassing the tumor regions in each slice which\nis deemed abnormal. Experimental results demonstrate that the proposed CADe\nsystem, when used as a preliminary step before segmentation, can allow improved\ndelineation of tumor region while reducing false positives arising in normal\nareas of the brain. The GrowCut method, employed for tumor segmentation,\ntypically requires a foreground and background seed region for initialization.\nHere the algorithm is initialized with seeds automatically generated from the\noutput of the proposed CADe system, thereby resulting in improved performance\nas compared to that using random seeds. \n\n"}
{"id": "1806.07822", "contents": "Title: Learning Neural Parsers with Deterministic Differentiable Imitation\n  Learning Abstract: We explore the problem of learning to decompose spatial tasks into segments,\nas exemplified by the problem of a painting robot covering a large object.\nInspired by the ability of classical decision tree algorithms to construct\nstructured partitions of their input spaces, we formulate the problem of\ndecomposing objects into segments as a parsing approach. We make the insight\nthat the derivation of a parse-tree that decomposes the object into segments\nclosely resembles a decision tree constructed by ID3, which can be done when\nthe ground-truth available. We learn to imitate an expert parsing oracle, such\nthat our neural parser can generalize to parse natural images without ground\ntruth. We introduce a novel deterministic policy gradient update, DRAG (i.e.,\nDeteRministically AGgrevate) in the form of a deterministic actor-critic\nvariant of AggreVaTeD, to train our neural parser. From another perspective,\nour approach is a variant of the Deterministic Policy Gradient suitable for the\nimitation learning setting. The deterministic policy representation offered by\ntraining our neural parser with DRAG allows it to outperform state of the art\nimitation and reinforcement learning approaches. \n\n"}
{"id": "1806.07944", "contents": "Title: Searching for a Single Community in a Graph Abstract: In standard graph clustering/community detection, one is interested in\npartitioning the graph into more densely connected subsets of nodes. In\ncontrast, the \"search\" problem of this paper aims to only find the nodes in a\n\"single\" such community, the target, out of the many communities that may\nexist. To do so , we are given suitable side information about the target; for\nexample, a very small number of nodes from the target are labeled as such.\n  We consider a general yet simple notion of side information: all nodes are\nassumed to have random weights, with nodes in the target having higher weights\non average. Given these weights and the graph, we develop a variant of the\nmethod of moments that identifies nodes in the target more reliably, and with\nlower computation, than generic community detection methods that do not use\nside information and partition the entire graph. Our empirical results show\nsignificant gains in runtime, and also gains in accuracy over other graph\nclustering algorithms. \n\n"}
{"id": "1806.08672", "contents": "Title: Variational learning across domains with triplet information Abstract: The work investigates deep generative models, which allow us to use training\ndata from one domain to build a model for another domain. We propose the\nVariational Bi-domain Triplet Autoencoder (VBTA) that learns a joint\ndistribution of objects from different domains. We extend the VBTAs objective\nfunction by the relative constraints or triplets that sampled from the shared\nlatent space across domains. In other words, we combine the deep generative\nmodels with a metric learning ideas in order to improve the final objective\nwith the triplets information. The performance of the VBTA model is\ndemonstrated on different tasks: image-to-image translation, bi-directional\nimage generation and cross-lingual document classification. \n\n"}
{"id": "1806.08990", "contents": "Title: Stroke-based Character Reconstruction Abstract: Background elimination for noisy character images or character images from\nreal scene is still a challenging problem, due to the bewildering backgrounds,\nuneven illumination, low resolution and different distortions. We propose a\nstroke-based character reconstruction(SCR) method that use a weighted quadratic\nBezier curve(WQBC) to represent strokes of a character. Only training on our\nsynthetic data, our stroke extractor can achieve excellent reconstruction\neffect in real scenes. Meanwhile. It can also help achieve great ability in\ndefending adversarial attacks of character recognizers. \n\n"}
{"id": "1806.09093", "contents": "Title: Analysis of Cellular Feature Differences of Astrocytomas with Distinct\n  Mutational Profiles Using Digitized Histopathology Images Abstract: Cellular phenotypic features derived from histopathology images are the basis\nof pathologic diagnosis and are thought to be related to underlying molecular\nprofiles. Due to overwhelming cell numbers and population heterogeneity, it\nremains challenging to quantitatively compute and compare features of cells\nwith distinct molecular signatures. In this study, we propose a self-reliant\nand efficient analysis framework that supports quantitative analysis of\ncellular phenotypic difference across distinct molecular groups. To demonstrate\nefficacy, we quantitatively analyze astrocytomas that are molecularly\ncharacterized as either Isocitrate Dehydrogenase (IDH) mutant (MUT) or wildtype\n(WT) using imaging data from The Cancer Genome Atlas database. Representative\ncell instances that are phenotypically different between these two groups are\nretrieved after segmentation, feature computation, data pruning, dimensionality\nreduction, and unsupervised clustering. Our analysis is generic and can be\napplied to a wide set of cell-based biomedical research. \n\n"}
{"id": "1806.09507", "contents": "Title: Semi-Automatic RECIST Labeling on CT Scans with Cascaded Convolutional\n  Neural Networks Abstract: Response evaluation criteria in solid tumors (RECIST) is the standard\nmeasurement for tumor extent to evaluate treatment responses in cancer\npatients. As such, RECIST annotations must be accurate. However, RECIST\nannotations manually labeled by radiologists require professional knowledge and\nare time-consuming, subjective, and prone to inconsistency among different\nobservers. To alleviate these problems, we propose a cascaded convolutional\nneural network based method to semi-automatically label RECIST annotations and\ndrastically reduce annotation time. The proposed method consists of two stages:\nlesion region normalization and RECIST estimation. We employ the spatial\ntransformer network (STN) for lesion region normalization, where a localization\nnetwork is designed to predict the lesion region and the transformation\nparameters with a multi-task learning strategy. For RECIST estimation, we adapt\nthe stacked hourglass network (SHN), introducing a relationship constraint loss\nto improve the estimation precision. STN and SHN can both be learned in an\nend-to-end fashion. We train our system on the DeepLesion dataset, obtaining a\nconsensus model trained on RECIST annotations performed by multiple\nradiologists over a multi-year period. Importantly, when judged against the\ninter-reader variability of two additional radiologist raters, our system\nperforms more stably and with less variability, suggesting that RECIST\nannotations can be reliably obtained with reduced labor and time. \n\n"}
{"id": "1806.10787", "contents": "Title: How To Extract Fashion Trends From Social Media? A Robust Object\n  Detector With Support For Unsupervised Learning Abstract: With the proliferation of social media, fashion inspired from celebrities,\nreputed designers as well as fashion influencers has shortened the cycle of\nfashion design and manufacturing. However, with the explosion of fashion\nrelated content and large number of user generated fashion photos, it is an\narduous task for fashion designers to wade through social media photos and\ncreate a digest of trending fashion. This necessitates deep parsing of fashion\nphotos on social media to localize and classify multiple fashion items from a\ngiven fashion photo. While object detection competitions such as MSCOCO have\nthousands of samples for each of the object categories, it is quite difficult\nto get large labeled datasets for fast fashion items. Moreover,\nstate-of-the-art object detectors do not have any functionality to ingest large\namount of unlabeled data available on social media in order to fine tune object\ndetectors with labeled datasets. In this work, we show application of a generic\nobject detector, that can be pretrained in an unsupervised manner, on 24\ncategories from recently released Open Images V4 dataset. We first train the\nbase architecture of the object detector using unsupervisd learning on 60K\nunlabeled photos from 24 categories gathered from social media, and then\nsubsequently fine tune it on 8.2K labeled photos from Open Images V4 dataset.\nOn 300 X 300 image inputs, we achieve 72.7% mAP on a test dataset of 2.4K\nphotos while performing 11% to 17% better as compared to the state-of-the-art\nobject detectors. We show that this improvement is due to our choice of\narchitecture that lets us do unsupervised learning and that performs\nsignificantly better in identifying small objects. \n\n"}
{"id": "1806.10805", "contents": "Title: Beyond One-hot Encoding: lower dimensional target embedding Abstract: Target encoding plays a central role when learning Convolutional Neural\nNetworks. In this realm, One-hot encoding is the most prevalent strategy due to\nits simplicity. However, this so widespread encoding schema assumes a flat\nlabel space, thus ignoring rich relationships existing among labels that can be\nexploited during training. In large-scale datasets, data does not span the full\nlabel space, but instead lies in a low-dimensional output manifold. Following\nthis observation, we embed the targets into a low-dimensional space,\ndrastically improving convergence speed while preserving accuracy. Our\ncontribution is two fold: (i) We show that random projections of the label\nspace are a valid tool to find such lower dimensional embeddings, boosting\ndramatically convergence rates at zero computational cost; and (ii) we propose\na normalized eigenrepresentation of the class manifold that encodes the targets\nwith minimal information loss, improving the accuracy of random projections\nencoding while enjoying the same convergence rates. Experiments on CIFAR-100,\nCUB200-2011, Imagenet, and MIT Places demonstrate that the proposed approach\ndrastically improves convergence speed while reaching very competitive accuracy\nrates. \n\n"}
{"id": "1806.11382", "contents": "Title: Convergence Problems with Generative Adversarial Networks (GANs) Abstract: Generative adversarial networks (GANs) are a novel approach to generative\nmodelling, a task whose goal it is to learn a distribution of real data points.\nThey have often proved difficult to train: GANs are unlike many techniques in\nmachine learning, in that they are best described as a two-player game between\na discriminator and generator. This has yielded both unreliability in the\ntraining process, and a general lack of understanding as to how GANs converge,\nand if so, to what. The purpose of this dissertation is to provide an account\nof the theory of GANs suitable for the mathematician, highlighting both\npositive and negative results. This involves identifying the problems when\ntraining GANs, and how topological and game-theoretic perspectives of GANs have\ncontributed to our understanding and improved our techniques in recent years. \n\n"}
{"id": "1807.00448", "contents": "Title: Speeding up the Metabolism in E-commerce by Reinforcement Mechanism\n  Design Abstract: In a large E-commerce platform, all the participants compete for impressions\nunder the allocation mechanism of the platform. Existing methods mainly focus\non the short-term return based on the current observations instead of the\nlong-term return. In this paper, we formally establish the lifecycle model for\nproducts, by defining the introduction, growth, maturity and decline stages and\ntheir transitions throughout the whole life period. Based on such model, we\nfurther propose a reinforcement learning based mechanism design framework for\nimpression allocation, which incorporates the first principal component based\npermutation and the novel experiences generation method, to maximize short-term\nas well as long-term return of the platform. With the power of trial-and-error,\nit is possible to optimize impression allocation strategies globally which is\ncontribute to the healthy development of participants and the platform itself.\nWe evaluate our algorithm on a simulated environment built based on one of the\nlargest E-commerce platforms, and a significant improvement has been achieved\nin comparison with the baseline solutions. \n\n"}
{"id": "1807.00911", "contents": "Title: Semantic Segmentation with Scarce Data Abstract: Semantic segmentation is a challenging vision problem that usually\nnecessitates the collection of large amounts of finely annotated data, which is\noften quite expensive to obtain. Coarsely annotated data provides an\ninteresting alternative as it is usually substantially more cheap. In this\nwork, we present a method to leverage coarsely annotated data along with fine\nsupervision to produce better segmentation results than would be obtained when\ntraining using only the fine data. We validate our approach by simulating a\nscarce data setting with less than 200 low resolution images from the\nCityscapes dataset and show that our method substantially outperforms solely\ntraining on the fine annotation data by an average of 15.52% mIoU and\noutperforms the coarse mask by an average of 5.28% mIoU. \n\n"}
{"id": "1807.01066", "contents": "Title: Behaviour Policy Estimation in Off-Policy Policy Evaluation: Calibration\n  Matters Abstract: In this work, we consider the problem of estimating a behaviour policy for\nuse in Off-Policy Policy Evaluation (OPE) when the true behaviour policy is\nunknown. Via a series of empirical studies, we demonstrate how accurate OPE is\nstrongly dependent on the calibration of estimated behaviour policy models: how\nprecisely the behaviour policy is estimated from data. We show how powerful\nparametric models such as neural networks can result in highly uncalibrated\nbehaviour policy models on a real-world medical dataset, and illustrate how a\nsimple, non-parametric, k-nearest neighbours model produces better calibrated\nbehaviour policy estimates and can be used to obtain superior importance\nsampling-based OPE estimates. \n\n"}
{"id": "1807.01430", "contents": "Title: SGAD: Soft-Guided Adaptively-Dropped Neural Network Abstract: Deep neural networks (DNNs) have been proven to have many redundancies.\nHence, many efforts have been made to compress DNNs. However, the existing\nmodel compression methods treat all the input samples equally while ignoring\nthe fact that the difficulties of various input samples being correctly\nclassified are different. To address this problem, DNNs with adaptive dropping\nmechanism are well explored in this work. To inform the DNNs how difficult the\ninput samples can be classified, a guideline that contains the information of\ninput samples is introduced to improve the performance. Based on the developed\nguideline and adaptive dropping mechanism, an innovative soft-guided\nadaptively-dropped (SGAD) neural network is proposed in this paper. Compared\nwith the 32 layers residual neural networks, the presented SGAD can reduce the\nFLOPs by 77% with less than 1% drop in accuracy on CIFAR-10. \n\n"}
{"id": "1807.01697", "contents": "Title: Benchmarking Neural Network Robustness to Common Corruptions and Surface\n  Variations Abstract: In this paper we establish rigorous benchmarks for image classifier\nrobustness. Our first benchmark, ImageNet-C, standardizes and expands the\ncorruption robustness topic, while showing which classifiers are preferable in\nsafety-critical applications. Unlike recent robustness research, this benchmark\nevaluates performance on commonplace corruptions not worst-case adversarial\ncorruptions. We find that there are negligible changes in relative corruption\nrobustness from AlexNet to ResNet classifiers, and we discover ways to enhance\ncorruption robustness. Then we propose a new dataset called Icons-50 which\nopens research on a new kind of robustness, surface variation robustness. With\nthis dataset we evaluate the frailty of classifiers on new styles of known\nobjects and unexpected instances of known classes. We also demonstrate two\nmethods that improve surface variation robustness. Together our benchmarks may\naid future work toward networks that learn fundamental class structure and also\nrobustly generalize. \n\n"}
{"id": "1807.02087", "contents": "Title: A Region-based Gauss-Newton Approach to Real-Time Monocular Multiple\n  Object Tracking Abstract: We propose an algorithm for real-time 6DOF pose tracking of rigid 3D objects\nusing a monocular RGB camera. The key idea is to derive a region-based cost\nfunction using temporally consistent local color histograms. While such\nregion-based cost functions are commonly optimized using first-order gradient\ndescent techniques, we systematically derive a Gauss-Newton optimization scheme\nwhich gives rise to drastically faster convergence and highly accurate and\nrobust tracking performance. We furthermore propose a novel complex dataset\ndedicated for the task of monocular object pose tracking and make it publicly\navailable to the community. To our knowledge, it is the first to address the\ncommon and important scenario in which both the camera as well as the objects\nare moving simultaneously in cluttered scenes. In numerous experiments -\nincluding our own proposed dataset - we demonstrate that the proposed\nGauss-Newton approach outperforms existing approaches, in particular in the\npresence of cluttered backgrounds, heterogeneous objects and partial\nocclusions. \n\n"}
{"id": "1807.03165", "contents": "Title: Sparse Deep Neural Network Exact Solutions Abstract: Deep neural networks (DNNs) have emerged as key enablers of machine learning.\nApplying larger DNNs to more diverse applications is an important challenge.\nThe computations performed during DNN training and inference are dominated by\noperations on the weight matrices describing the DNN. As DNNs incorporate more\nlayers and more neurons per layers, these weight matrices may be required to be\nsparse because of memory limitations. Sparse DNNs are one possible approach,\nbut the underlying theory is in the early stages of development and presents a\nnumber of challenges, including determining the accuracy of inference and\nselecting nonzero weights for training. Associative array algebra has been\ndeveloped by the big data community to combine and extend database, matrix, and\ngraph/network concepts for use in large, sparse data problems. Applying this\nmathematics to DNNs simplifies the formulation of DNN mathematics and reveals\nthat DNNs are linear over oscillating semirings. This work uses associative\narray DNNs to construct exact solutions and corresponding perturbation models\nto the rectified linear unit (ReLU) DNN equations that can be used to construct\ntest vectors for sparse DNN implementations over various precisions. These\nsolutions can be used for DNN verification, theoretical explorations of DNN\nproperties, and a starting point for the challenge of sparse training. \n\n"}
{"id": "1807.03478", "contents": "Title: An Adaptive Learning Method of Restricted Boltzmann Machine by Neuron\n  Generation and Annihilation Algorithm Abstract: Restricted Boltzmann Machine (RBM) is a generative stochastic energy-based\nmodel of artificial neural network for unsupervised learning. Recently, RBM is\nwell known to be a pre-training method of Deep Learning. In addition to visible\nand hidden neurons, the structure of RBM has a number of parameters such as the\nweights between neurons and the coefficients for them. Therefore, we may meet\nsome difficulties to determine an optimal network structure to analyze big\ndata. In order to evade the problem, we investigated the variance of parameters\nto find an optimal structure during learning. For the reason, we should check\nthe variance of parameters to cause the fluctuation for energy function in RBM\nmodel. In this paper, we propose the adaptive learning method of RBM that can\ndiscover an optimal number of hidden neurons according to the training\nsituation by applying the neuron generation and annihilation algorithm. In this\nmethod, a new hidden neuron is generated if the energy function is not still\nconverged and the variance of the parameters is large. Moreover, the\ninactivated hidden neuron will be annihilated if the neuron does not affect the\nlearning situation. The experimental results for some benchmark data sets were\ndiscussed in this paper. \n\n"}
{"id": "1807.03931", "contents": "Title: A Hierarchical Bayesian Linear Regression Model with Local Features for\n  Stochastic Dynamics Approximation Abstract: One of the challenges in model-based control of stochastic dynamical systems\nis that the state transition dynamics are involved, and it is not easy or\nefficient to make good-quality predictions of the states. Moreover, there are\nnot many representational models for the majority of autonomous systems, as it\nis not easy to build a compact model that captures the entire dynamical\nsubtleties and uncertainties. In this work, we present a hierarchical Bayesian\nlinear regression model with local features to learn the dynamics of a\nmicro-robotic system as well as two simpler examples, consisting of a\nstochastic mass-spring damper and a stochastic double inverted pendulum on a\ncart. The model is hierarchical since we assume non-stationary priors for the\nmodel parameters. These non-stationary priors make the model more flexible by\nimposing priors on the priors of the model. To solve the maximum likelihood\n(ML) problem for this hierarchical model, we use the variational expectation\nmaximization (EM) algorithm, and enhance the procedure by introducing hidden\ntarget variables. The algorithm yields parsimonious model structures, and\nconsistently provides fast and accurate predictions for all our examples\ninvolving large training and test sets. This demonstrates the effectiveness of\nthe method in learning stochastic dynamics, which makes it suitable for future\nuse in a paradigm, such as model-based reinforcement learning, to compute\noptimal control policies in real time. \n\n"}
{"id": "1807.04585", "contents": "Title: Deep Learning for Imbalance Data Classification using Class Expert\n  Generative Adversarial Network Abstract: Without any specific way for imbalance data classification, artificial\nintelligence algorithm cannot recognize data from minority classes easily. In\ngeneral, modifying the existing algorithm by assuming that the training data is\nimbalanced, is the only way to handle imbalance data. However, for a normal\ndata handling, this way mostly produces a deficient result. In this research,\nwe propose a class expert generative adversarial network (CE-GAN) as the\nsolution for imbalance data classification. CE-GAN is a modification in deep\nlearning algorithm architecture that does not have an assumption that the\ntraining data is imbalance data. Moreover, CE-GAN is designed to identify more\ndetail about the character of each class before classification step. CE-GAN has\nbeen proved in this research to give a good performance for imbalance data\nclassification. \n\n"}
{"id": "1807.04950", "contents": "Title: Deep Learning in the Wild Abstract: Deep learning with neural networks is applied by an increasing number of\npeople outside of classic research environments, due to the vast success of the\nmethodology on a wide range of machine perception tasks. While this interest is\nfueled by beautiful success stories, practical work in deep learning on novel\ntasks without existing baselines remains challenging. This paper explores the\nspecific challenges arising in the realm of real world tasks, based on case\nstudies from research \\& development in conjunction with industry, and extracts\nlessons learned from them. It thus fills a gap between the publication of\nlatest algorithmic and methodical developments, and the usually omitted\nnitty-gritty of how to make them work. Specifically, we give insight into deep\nlearning projects on face matching, print media monitoring, industrial quality\ncontrol, music scanning, strategy game playing, and automated machine learning,\nthereby providing best practices for deep learning in practice. \n\n"}
{"id": "1807.05027", "contents": "Title: Are generative deep models for novelty detection truly better? Abstract: Many deep models have been recently proposed for anomaly detection. This\npaper presents comparison of selected generative deep models and classical\nanomaly detection methods on an extensive number of non--image benchmark\ndatasets. We provide statistical comparison of the selected models, in many\nconfigurations, architectures and hyperparamaters. We arrive to conclusion that\nperformance of the generative models is determined by the process of selection\nof their hyperparameters. Specifically, performance of the deep generative\nmodels deteriorates with decreasing amount of anomalous samples used in\nhyperparameter selection. In practical scenarios of anomaly detection, none of\nthe deep generative models systematically outperforms the kNN. \n\n"}
{"id": "1807.05688", "contents": "Title: SCAN: Self-and-Collaborative Attention Network for Video Person\n  Re-identification Abstract: Video person re-identification attracts much attention in recent years. It\naims to match image sequences of pedestrians from different camera views.\nPrevious approaches usually improve this task from three aspects, including a)\nselecting more discriminative frames, b) generating more informative temporal\nrepresentations, and c) developing more effective distance metrics. To address\nthe above issues, we present a novel and practical deep architecture for video\nperson re-identification termed Self-and-Collaborative Attention Network\n(SCAN). It has several appealing properties. First, SCAN adopts non-parametric\nattention mechanism to refine the intra-sequence and inter-sequence feature\nrepresentation of videos, and outputs self-and-collaborative feature\nrepresentation for each video, making the discriminative frames aligned between\nthe probe and gallery sequences.Second, beyond existing models, a generalized\npairwise similarity measurement is proposed to calculate the similarity feature\nrepresentations of video pairs, enabling computing the matching scores by the\nbinary classifier. Third, a dense clip segmentation strategy is also introduced\nto generate rich probe-gallery pairs to optimize the model. Extensive\nexperiments demonstrate the effectiveness of SCAN, which outperforms the\nbest-performing baselines on iLIDS-VID, PRID2011 and MARS dataset,\nrespectively. \n\n"}
{"id": "1807.06657", "contents": "Title: Airline Passenger Name Record Generation using Generative Adversarial\n  Networks Abstract: Passenger Name Records (PNRs) are at the heart of the travel industry.\nCreated when an itinerary is booked, they contain travel and passenger\ninformation. It is usual for airlines and other actors in the industry to\ninter-exchange and access each other's PNR, creating the challenge of using\nthem without infringing data ownership laws. To address this difficulty, we\npropose a method to generate realistic synthetic PNRs using Generative\nAdversarial Networks (GANs). Unlike other GAN applications, PNRs consist of\ncategorical and numerical features with missing/NaN values, which makes the use\nof GANs challenging. We propose a solution based on Cram\\'{e}r GANs,\ncategorical feature embedding and a Cross-Net architecture. The method was\ntested on a real PNR dataset, and evaluated in terms of distribution matching,\nmemorization, and performance of predictive models for two real business\nproblems: client segmentation and passenger nationality prediction. Results\nshow that the generated data matches well with the real PNRs without memorizing\nthem, and that it can be used to train models for real business applications. \n\n"}
{"id": "1807.06699", "contents": "Title: Adaptive Neural Trees Abstract: Deep neural networks and decision trees operate on largely separate\nparadigms; typically, the former performs representation learning with\npre-specified architectures, while the latter is characterised by learning\nhierarchies over pre-specified features with data-driven architectures. We\nunite the two via adaptive neural trees (ANTs) that incorporates representation\nlearning into edges, routing functions and leaf nodes of a decision tree, along\nwith a backpropagation-based training algorithm that adaptively grows the\narchitecture from primitive modules (e.g., convolutional layers). We\ndemonstrate that, whilst achieving competitive performance on classification\nand regression datasets, ANTs benefit from (i) lightweight inference via\nconditional computation, (ii) hierarchical separation of features useful to the\ntask e.g. learning meaningful class associations, such as separating natural\nvs. man-made objects, and (iii) a mechanism to adapt the architecture to the\nsize and complexity of the training dataset. \n\n"}
{"id": "1807.06714", "contents": "Title: Defend Deep Neural Networks Against Adversarial Examples via Fixed and\n  Dynamic Quantized Activation Functions Abstract: Recent studies have shown that deep neural networks (DNNs) are vulnerable to\nadversarial attacks. To this end, many defense approaches that attempt to\nimprove the robustness of DNNs have been proposed. In a separate and yet\nrelated area, recent works have explored to quantize neural network weights and\nactivation functions into low bit-width to compress model size and reduce\ncomputational complexity. In this work, we find that these two different\ntracks, namely the pursuit of network compactness and robustness, can be merged\ninto one and give rise to networks of both advantages. To the best of our\nknowledge, this is the first work that uses quantization of activation\nfunctions to defend against adversarial examples. We also propose to train\nrobust neural networks by using adaptive quantization techniques for the\nactivation functions. Our proposed Dynamic Quantized Activation (DQA) is\nverified through a wide range of experiments with the MNIST and CIFAR-10\ndatasets under different white-box attack methods, including FGSM, PGD, and C &\nW attacks. Furthermore, Zeroth Order Optimization and substitute model-based\nblack-box attacks are also considered in this work. The experimental results\nclearly show that the robustness of DNNs could be greatly improved using the\nproposed DQA. \n\n"}
{"id": "1807.06905", "contents": "Title: Melanoma Recognition with an Ensemble of Techniques for Segmentation and\n  a Structural Analysis for Classification Abstract: An approach to lesion recognition is described that for lesion localization\nuses an ensemble of segmentation techniques and for lesion classification an\nexhaustive structural analysis. For localization, candidate regions are\nobtained from global thresholding of the chromatic maps and from applying the\nK-Means algorithm to the RGB image; the candidate regions are then integrated.\nFor classification, a relatively exhaustive structural analysis of contours and\nregions is carried out. \n\n"}
{"id": "1807.07356", "contents": "Title: Aleatoric uncertainty estimation with test-time augmentation for medical\n  image segmentation with convolutional neural networks Abstract: Despite the state-of-the-art performance for medical image segmentation, deep\nconvolutional neural networks (CNNs) have rarely provided uncertainty\nestimations regarding their segmentation outputs, e.g., model (epistemic) and\nimage-based (aleatoric) uncertainties. In this work, we analyze these different\ntypes of uncertainties for CNN-based 2D and 3D medical image segmentation\ntasks. We additionally propose a test-time augmentation-based aleatoric\nuncertainty to analyze the effect of different transformations of the input\nimage on the segmentation output. Test-time augmentation has been previously\nused to improve segmentation accuracy, yet not been formulated in a consistent\nmathematical framework. Hence, we also propose a theoretical formulation of\ntest-time augmentation, where a distribution of the prediction is estimated by\nMonte Carlo simulation with prior distributions of parameters in an image\nacquisition model that involves image transformations and noise. We compare and\ncombine our proposed aleatoric uncertainty with model uncertainty. Experiments\nwith segmentation of fetal brains and brain tumors from 2D and 3D Magnetic\nResonance Images (MRI) showed that 1) the test-time augmentation-based\naleatoric uncertainty provides a better uncertainty estimation than calculating\nthe test-time dropout-based model uncertainty alone and helps to reduce\noverconfident incorrect predictions, and 2) our test-time augmentation\noutperforms a single-prediction baseline and dropout-based multiple\npredictions. \n\n"}
{"id": "1807.07688", "contents": "Title: Toward Characteristic-Preserving Image-based Virtual Try-On Network Abstract: Image-based virtual try-on systems for fitting new in-shop clothes into a\nperson image have attracted increasing research attention, yet is still\nchallenging. A desirable pipeline should not only transform the target clothes\ninto the most fitting shape seamlessly but also preserve well the clothes\nidentity in the generated image, that is, the key characteristics (e.g.\ntexture, logo, embroidery) that depict the original clothes. However, previous\nimage-conditioned generation works fail to meet these critical requirements\ntowards the plausible virtual try-on performance since they fail to handle\nlarge spatial misalignment between the input image and target clothes. Prior\nwork explicitly tackled spatial deformation using shape context matching, but\nfailed to preserve clothing details due to its coarse-to-fine strategy. In this\nwork, we propose a new fully-learnable Characteristic-Preserving Virtual Try-On\nNetwork(CP-VTON) for addressing all real-world challenges in this task. First,\nCP-VTON learns a thin-plate spline transformation for transforming the in-shop\nclothes into fitting the body shape of the target person via a new Geometric\nMatching Module (GMM) rather than computing correspondences of interest points\nas prior works did. Second, to alleviate boundary artifacts of warped clothes\nand make the results more realistic, we employ a Try-On Module that learns a\ncomposition mask to integrate the warped clothes and the rendered image to\nensure smoothness. Extensive experiments on a fashion dataset demonstrate our\nCP-VTON achieves the state-of-the-art virtual try-on performance both\nqualitatively and quantitatively. \n\n"}
{"id": "1807.07946", "contents": "Title: Future Semantic Segmentation with Convolutional LSTM Abstract: We consider the problem of predicting semantic segmentation of future frames\nin a video. Given several observed frames in a video, our goal is to predict\nthe semantic segmentation map of future frames that are not yet observed. A\nreliable solution to this problem is useful in many applications that require\nreal-time decision making, such as autonomous driving. We propose a novel model\nthat uses convolutional LSTM (ConvLSTM) to encode the spatiotemporal\ninformation of observed frames for future prediction. We also extend our model\nto use bidirectional ConvLSTM to capture temporal information in both\ndirections. Our proposed approach outperforms other state-of-the-art methods on\nthe benchmark dataset. \n\n"}
{"id": "1807.08108", "contents": "Title: Simultaneous Adversarial Training - Learn from Others Mistakes Abstract: Adversarial examples are maliciously tweaked images that can easily fool\nmachine learning techniques, such as neural networks, but they are normally not\nvisually distinguishable for human beings. One of the main approaches to solve\nthis problem is to retrain the networks using those adversarial examples,\nnamely adversarial training. However, standard adversarial training might not\nactually change the decision boundaries but cause the problem of gradient\nmasking, resulting in a weaker ability to generate adversarial examples.\nTherefore, it cannot alleviate the problem of black-box attacks, where\nadversarial examples generated from other networks can transfer to the targeted\none. In order to reduce the problem of black-box attacks, we propose a novel\nmethod that allows two networks to learn from each others' adversarial examples\nand become resilient to black-box attacks. We also combine this method with a\nsimple domain adaptation to further improve the performance. \n\n"}
{"id": "1807.08259", "contents": "Title: Deep Discriminative Model for Video Classification Abstract: This paper presents a new deep learning approach for video-based scene\nclassification. We design a Heterogeneous Deep Discriminative Model (HDDM)\nwhose parameters are initialized by performing an unsupervised pre-training in\na layer-wise fashion using Gaussian Restricted Boltzmann Machines (GRBM). In\norder to avoid the redundancy of adjacent frames, we extract spatiotemporal\nvariation patterns within frames and represent them sparsely using Sparse Cubic\nSymmetrical Pattern (SCSP). Then, a pre-initialized HDDM is separately trained\nusing the videos of each class to learn class-specific models. According to the\nminimum reconstruction error from the learnt class-specific models, a weighted\nvoting strategy is employed for the classification. The performance of the\nproposed method is extensively evaluated on two action recognition datasets;\nUCF101 and Hollywood II, and three dynamic texture and dynamic scene datasets;\nDynTex, YUPENN, and Maryland. The experimental results and comparisons against\nstate-of-the-art methods demonstrate that the proposed method consistently\nachieves superior performance on all datasets. \n\n"}
{"id": "1807.08260", "contents": "Title: Macro-Micro Adversarial Network for Human Parsing Abstract: In human parsing, the pixel-wise classification loss has drawbacks in its\nlow-level local inconsistency and high-level semantic inconsistency. The\nintroduction of the adversarial network tackles the two problems using a single\ndiscriminator. However, the two types of parsing inconsistency are generated by\ndistinct mechanisms, so it is difficult for a single discriminator to solve\nthem both. To address the two kinds of inconsistencies, this paper proposes the\nMacro-Micro Adversarial Net (MMAN). It has two discriminators. One\ndiscriminator, Macro D, acts on the low-resolution label map and penalizes\nsemantic inconsistency, e.g., misplaced body parts. The other discriminator,\nMicro D, focuses on multiple patches of the high-resolution label map to\naddress the local inconsistency, e.g., blur and hole. Compared with traditional\nadversarial networks, MMAN not only enforces local and semantic consistency\nexplicitly, but also avoids the poor convergence problem of adversarial\nnetworks when handling high resolution images. In our experiment, we validate\nthat the two discriminators are complementary to each other in improving the\nhuman parsing accuracy. The proposed framework is capable of producing\ncompetitive parsing performance compared with the state-of-the-art methods,\ni.e., mIoU=46.81% and 59.91% on LIP and PASCAL-Person-Part, respectively. On a\nrelatively small dataset PPSS, our pre-trained model demonstrates impressive\ngeneralization ability. The code is publicly available at\nhttps://github.com/RoyalVane/MMAN. \n\n"}
{"id": "1807.08430", "contents": "Title: Actor-Action Semantic Segmentation with Region Masks Abstract: In this paper, we study the actor-action semantic segmentation problem, which\nrequires joint labeling of both actor and action categories in video frames.\nOne major challenge for this task is that when an actor performs an action,\ndifferent body parts of the actor provide different types of cues for the\naction category and may receive inconsistent action labeling when they are\nlabeled independently. To address this issue, we propose an end-to-end\nregion-based actor-action segmentation approach which relies on region masks\nfrom an instance segmentation algorithm. Our main novelty is to avoid labeling\npixels in a region mask independently - instead we assign a single action label\nto these pixels to achieve consistent action labeling. When a pixel belongs to\nmultiple region masks, max pooling is applied to resolve labeling conflicts.\nOur approach uses a two-stream network as the front-end (which learns features\ncapturing both appearance and motion information), and uses two region-based\nsegmentation networks as the back-end (which takes the fused features from the\ntwo-stream network as the input and predicts actor-action labeling).\nExperiments on the A2D dataset demonstrate that both the region-based\nsegmentation strategy and the fused features from the two-stream network\ncontribute to the performance improvements. The proposed approach outperforms\nthe state-of-the-art results by more than 8% in mean class accuracy, and more\nthan 5% in mean class IOU, which validates its effectiveness. \n\n"}
{"id": "1807.08894", "contents": "Title: ClusterNet: 3D Instance Segmentation in RGB-D Images Abstract: We propose a method for instance-level segmentation that uses RGB-D data as\ninput and provides detailed information about the location, geometry and number\nof individual objects in the scene. This level of understanding is fundamental\nfor autonomous robots. It enables safe and robust decision-making under the\nlarge uncertainty of the real-world. In our model, we propose to use the first\nand second order moments of the object occupancy function to represent an\nobject instance. We train an hourglass Deep Neural Network (DNN) where each\npixel in the output votes for the 3D position of the corresponding object\ncenter and for the object's size and pose. The final instance segmentation is\nachieved through clustering in the space of moments. The object-centric\ntraining loss is defined on the output of the clustering. Our method\noutperforms the state-of-the-art instance segmentation method on our\nsynthesized dataset. We show that our method generalizes well on real-world\ndata achieving visually better segmentation results. \n\n"}
{"id": "1807.09097", "contents": "Title: Algorithm Selection for Collaborative Filtering: the influence of graph\n  metafeatures and multicriteria metatargets Abstract: To select the best algorithm for a new problem is an expensive and difficult\ntask. However, there are automatic solutions to address this problem: using\nMetalearning, which takes advantage of problem characteristics (i.e.\nmetafeatures), one is able to predict the relative performance of algorithms.\nIn the Collaborative Filtering scope, recent works have proposed diverse\nmetafeatures describing several dimensions of this problem. Despite interesting\nand effective findings, it is still unknown whether these are the most\neffective metafeatures. Hence, this work proposes a new set of graph\nmetafeatures, which approach the Collaborative Filtering problem from a Graph\nTheory perspective. Furthermore, in order to understand whether metafeatures\nfrom multiple dimensions are a better fit, we investigate the effects of\ncomprehensive metafeatures. These metafeatures are a selection of the best\nmetafeatures from all existing Collaborative Filtering metafeatures. The impact\nof the most representative metafeatures is investigated in a controlled\nexperimental setup. Another contribution we present is the use of a\nPareto-Efficient ranking procedure to create multicriteria metatargets. These\nnew rankings of algorithms, which take into account multiple evaluation\nmeasures, allow to explore the algorithm selection problem in a fairer and more\ndetailed way. According to the experimental results, the graph metafeatures are\na good alternative to related work metafeatures. However, the results have\nshown that the feature selection procedure used to create the comprehensive\nmetafeatures is is not effective, since there is no gain in predictive\nperformance. Finally, an extensive metaknowledge analysis was conducted to\nidentify the most influential metafeatures. \n\n"}
{"id": "1807.09303", "contents": "Title: User Loss -- A Forced-Choice-Inspired Approach to Train Neural Networks\n  directly by User Interaction Abstract: In this paper, we investigate whether is it possible to train a neural\nnetwork directly from user inputs. We consider this approach to be highly\nrelevant for applications in which the point of optimality is not well-defined\nand user-dependent. Our application is medical image denoising which is\nessential in fluoroscopy imaging. In this field every user, i.e. physician, has\na different flavor and image quality needs to be tailored towards each\nindividual.\n  To address this important problem, we propose to construct a loss function\nderived from a forced-choice experiment. In order to make the learning problem\nfeasible, we operate in the domain of precision learning, i.e., we inspire the\nnetwork architecture by traditional signal processing methods in order to\nreduce the number of trainable parameters. The algorithm that was used for this\nis a Laplacian pyramid with only six trainable parameters.\n  In the experimental results, we demonstrate that two image experts who prefer\ndifferent filter characteristics between sharpness and de-noising can be\ncreated using our approach. Also models trained for a specific user perform\nbest on this users test data. This approach opens the way towards\nimplementation of direct user feedback in deep learning and is applicable for a\nwide range of application. \n\n"}
{"id": "1807.09713", "contents": "Title: Asynchronous, Photometric Feature Tracking using Events and Frames Abstract: We present a method that leverages the complementarity of event cameras and\nstandard cameras to track visual features with low-latency. Event cameras are\nnovel sensors that output pixel-level brightness changes, called \"events\". They\noffer significant advantages over standard cameras, namely a very high dynamic\nrange, no motion blur, and a latency in the order of microseconds. However,\nbecause the same scene pattern can produce different events depending on the\nmotion direction, establishing event correspondences across time is\nchallenging. By contrast, standard cameras provide intensity measurements\n(frames) that do not depend on motion direction. Our method extracts features\non frames and subsequently tracks them asynchronously using events, thereby\nexploiting the best of both types of data: the frames provide a photometric\nrepresentation that does not depend on motion direction and the events provide\nlow-latency updates. In contrast to previous works, which are based on\nheuristics, this is the first principled method that uses raw intensity\nmeasurements directly, based on a generative event model within a\nmaximum-likelihood framework. As a result, our method produces feature tracks\nthat are both more accurate (subpixel accuracy) and longer than the state of\nthe art, across a wide variety of scenes. \n\n"}
{"id": "1807.09751", "contents": "Title: Multi-Perspective Neural Architecture for Recommendation System Abstract: Currently, there starts a research trend to leverage neural architecture for\nrecommendation systems. Though several deep recommender models are proposed,\nmost methods are too simple to characterize users' complex preference. In this\npaper, for a fine-grain analysis, users' ratings are explained from multiple\nperspectives, based on which, we propose our neural architecture. Specifically,\nour model employs several sequential stages to encode the user and item into\nhidden representations. In one stage, the user and item are represented from\nmultiple perspectives and in each perspective, the representations of user and\nitem put attentions to each other. Last, we metric the output representations\nof final stage to approach the users' rating. Extensive experiments demonstrate\nthat our method achieves substantial improvements against baselines. \n\n"}
{"id": "1807.09755", "contents": "Title: Flow-Grounded Spatial-Temporal Video Prediction from Still Images Abstract: Existing video prediction methods mainly rely on observing multiple\nhistorical frames or focus on predicting the next one-frame. In this work, we\nstudy the problem of generating consecutive multiple future frames by observing\none single still image only. We formulate the multi-frame prediction task as a\nmultiple time step flow (multi-flow) prediction phase followed by a\nflow-to-frame synthesis phase. The multi-flow prediction is modeled in a\nvariational probabilistic manner with spatial-temporal relationships learned\nthrough 3D convolutions. The flow-to-frame synthesis is modeled as a generative\nprocess in order to keep the predicted results lying closer to the manifold\nshape of real video sequence. Such a two-phase design prevents the model from\ndirectly looking at the high-dimensional pixel space of the frame sequence and\nis demonstrated to be more effective in predicting better and diverse results.\nExtensive experimental results on videos with different types of motion show\nthat the proposed algorithm performs favorably against existing methods in\nterms of quality, diversity and human perceptual evaluation. \n\n"}
{"id": "1807.09828", "contents": "Title: ADVIO: An authentic dataset for visual-inertial odometry Abstract: The lack of realistic and open benchmarking datasets for pedestrian\nvisual-inertial odometry has made it hard to pinpoint differences in published\nmethods. Existing datasets either lack a full six degree-of-freedom\nground-truth or are limited to small spaces with optical tracking systems. We\ntake advantage of advances in pure inertial navigation, and develop a set of\nversatile and challenging real-world computer vision benchmark sets for\nvisual-inertial odometry. For this purpose, we have built a test rig equipped\nwith an iPhone, a Google Pixel Android phone, and a Google Tango device. We\nprovide a wide range of raw sensor data that is accessible on almost any\nmodern-day smartphone together with a high-quality ground-truth track. We also\ncompare resulting visual-inertial tracks from Google Tango, ARCore, and Apple\nARKit with two recent methods published in academic forums. The data sets cover\nboth indoor and outdoor cases, with stairs, escalators, elevators, office\nenvironments, a shopping mall, and metro station. \n\n"}
{"id": "1807.09946", "contents": "Title: Computationally Efficient Measures of Internal Neuron Importance Abstract: The challenge of assigning importance to individual neurons in a network is\nof interest when interpreting deep learning models. In recent work, Dhamdhere\net al. proposed Total Conductance, a \"natural refinement of Integrated\nGradients\" for attributing importance to internal neurons. Unfortunately, the\nauthors found that calculating conductance in tensorflow required the addition\nof several custom gradient operators and did not scale well. In this work, we\nshow that the formula for Total Conductance is mathematically equivalent to\nPath Integrated Gradients computed on a hidden layer in the network. We provide\na scalable implementation of Total Conductance using standard tensorflow\ngradient operators that we call Neuron Integrated Gradients. We compare Neuron\nIntegrated Gradients to DeepLIFT, a pre-existing computationally efficient\napproach that is applicable to calculating internal neuron importance. We find\nthat DeepLIFT produces strong empirical results and is faster to compute, but\nbecause it lacks the theoretical properties of Neuron Integrated Gradients, it\nmay not always be preferred in practice. Colab notebook reproducing results:\nhttp://bit.ly/neuronintegratedgradients \n\n"}
{"id": "1807.10561", "contents": "Title: Towards an Embodied Semantic Fovea: Semantic 3D scene reconstruction\n  from ego-centric eye-tracker videos Abstract: Incorporating the physical environment is essential for a complete\nunderstanding of human behavior in unconstrained every-day tasks. This is\nespecially important in ego-centric tasks where obtaining 3 dimensional\ninformation is both limiting and challenging with the current 2D video analysis\nmethods proving insufficient. Here we demonstrate a proof-of-concept system\nwhich provides real-time 3D mapping and semantic labeling of the local\nenvironment from an ego-centric RGB-D video-stream with 3D gaze point\nestimation from head mounted eye tracking glasses. We augment existing work in\nSemantic Simultaneous Localization And Mapping (Semantic SLAM) with collected\ngaze vectors. Our system can then find and track objects both inside and\noutside the user field-of-view in 3D from multiple perspectives with reasonable\naccuracy. We validate our concept by producing a semantic map from images of\nthe NYUv2 dataset while simultaneously estimating gaze position and gaze\nclasses from recorded gaze data of the dataset images. \n\n"}
{"id": "1807.10573", "contents": "Title: LiDAR and Camera Detection Fusion in a Real Time Industrial Multi-Sensor\n  Collision Avoidance System Abstract: Collision avoidance is a critical task in many applications, such as ADAS\n(advanced driver-assistance systems), industrial automation and robotics. In an\nindustrial automation setting, certain areas should be off limits to an\nautomated vehicle for protection of people and high-valued assets. These areas\ncan be quarantined by mapping (e.g., GPS) or via beacons that delineate a\nno-entry area. We propose a delineation method where the industrial vehicle\nutilizes a LiDAR {(Light Detection and Ranging)} and a single color camera to\ndetect passive beacons and model-predictive control to stop the vehicle from\nentering a restricted space. The beacons are standard orange traffic cones with\na highly reflective vertical pole attached. The LiDAR can readily detect these\nbeacons, but suffers from false positives due to other reflective surfaces such\nas worker safety vests. Herein, we put forth a method for reducing false\npositive detection from the LiDAR by projecting the beacons in the camera\nimagery via a deep learning method and validating the detection using a neural\nnetwork-learned projection from the camera to the LiDAR space. Experimental\ndata collected at Mississippi State University's Center for Advanced Vehicular\nSystems (CAVS) shows the effectiveness of the proposed system in keeping the\ntrue detection while mitigating false positives. \n\n"}
{"id": "1807.11091", "contents": "Title: StructADMM: A Systematic, High-Efficiency Framework of Structured Weight\n  Pruning for DNNs Abstract: Weight pruning methods of DNNs have been demonstrated to achieve a good model\npruning rate without loss of accuracy, thereby alleviating the significant\ncomputation/storage requirements of large-scale DNNs. Structured weight pruning\nmethods have been proposed to overcome the limitation of irregular network\nstructure and demonstrated actual GPU acceleration. However, in prior work the\npruning rate (degree of sparsity) and GPU acceleration are limited (to less\nthan 50%) when accuracy needs to be maintained. In this work,we overcome these\nlimitations by proposing a unified, systematic framework of structured weight\npruning for DNNs. It is a framework that can be used to induce different types\nof structured sparsity, such as filter-wise, channel-wise, and shape-wise\nsparsity, as well non-structured sparsity. The proposed framework incorporates\nstochastic gradient descent with ADMM, and can be understood as a dynamic\nregularization method in which the regularization target is analytically\nupdated in each iteration. Without loss of accuracy on the AlexNet model, we\nachieve 2.58X and 3.65X average measured speedup on two GPUs, clearly\noutperforming the prior work. The average speedups reach 3.15X and 8.52X when\nallowing a moderate ac-curacy loss of 2%. In this case the model compression\nfor convolutional layers is 15.0X, corresponding to 11.93X measured CPU\nspeedup. Our experiments on ResNet model and on other data sets like UCF101 and\nCIFAR-10 demonstrate the consistently higher performance of our framework. \n\n"}
{"id": "1807.11228", "contents": "Title: Predicting Conversion of Mild Cognitive Impairments to Alzheimer's\n  Disease and Exploring Impact of Neuroimaging Abstract: Nowadays, a lot of scientific efforts are concentrated on the diagnosis of\nAlzheimer's Disease (AD) applying deep learning methods to neuroimaging data.\nEven for 2017, there were published more than a hundred papers dedicated to AD\ndiagnosis, whereas only a few works considered a problem of mild cognitive\nimpairments (MCI) conversion to the AD. However, the conversion prediction is\nan important problem since approximately 15% of patients with MCI converges to\nthe AD every year. In the current work, we are focusing on the conversion\nprediction using brain Magnetic Resonance Imaging and clinical data, such as\ndemographics, cognitive assessments, genetic, and biochemical markers. First of\nall, we applied state-of-the-art deep learning algorithms on the neuroimaging\ndata and compared these results with two machine learning algorithms that we\nfit using the clinical data. As a result, the models trained on the clinical\ndata outperform the deep learning algorithms applied to the MR images. To\nexplore the impact of neuroimaging further, we trained a deep feed-forward\nembedding using similarity learning with Histogram loss on all available MRIs\nand obtained 64-dimensional vector representation of neuroimaging data. The use\nof learned representation from the deep embedding allowed to increase the\nquality of prediction based on the neuroimaging. Finally, the current results\non this dataset show that the neuroimaging does affect conversion prediction,\nhowever, cannot noticeably increase the quality of the prediction. The best\nresults of predicting MCI-to-AD conversion are provided by XGBoost algorithm\ntrained on the clinical and embedding data. The resulting accuracy is 0.76 +-\n0.01 and the area under the ROC curve - 0.86 +- 0.01. \n\n"}
{"id": "1807.11234", "contents": "Title: Improving Electron Micrograph Signal-to-Noise with an Atrous\n  Convolutional Encoder-Decoder Abstract: We present an atrous convolutional encoder-decoder trained to denoise\n512$\\times$512 crops from electron micrographs. It consists of a modified\nXception backbone, atrous convoltional spatial pyramid pooling module and a\nmulti-stage decoder. Our neural network was trained end-to-end to remove\nPoisson noise applied to low-dose ($\\ll$ 300 counts ppx) micrographs created\nfrom a new dataset of 17267 2048$\\times$2048 high-dose ($>$ 2500 counts ppx)\nmicrographs and then fine-tuned for ordinary doses (200-2500 counts ppx). Its\nperformance is benchmarked against bilateral, non-local means, total variation,\nwavelet, Wiener and other restoration methods with their default parameters.\nOur network outperforms their best mean squared error and structural similarity\nindex performances by 24.6% and 9.6% for low doses and by 43.7% and 5.5% for\nordinary doses. In both cases, our network's mean squared error has the lowest\nvariance. Source code and links to our new high-quality dataset and trained\nnetwork have been made publicly available at\nhttps://github.com/Jeffrey-Ede/Electron-Micrograph-Denoiser \n\n"}
{"id": "1807.11436", "contents": "Title: Leveraging Motion Priors in Videos for Improving Human Segmentation Abstract: Despite many advances in deep-learning based semantic segmentation,\nperformance drop due to distribution mismatch is often encountered in the real\nworld. Recently, a few domain adaptation and active learning approaches have\nbeen proposed to mitigate the performance drop. However, very little attention\nhas been made toward leveraging information in videos which are naturally\ncaptured in most camera systems. In this work, we propose to leverage \"motion\nprior\" in videos for improving human segmentation in a weakly-supervised active\nlearning setting. By extracting motion information using optical flow in\nvideos, we can extract candidate foreground motion segments (referred to as\nmotion prior) potentially corresponding to human segments. We propose to learn\na memory-network-based policy model to select strong candidate segments\n(referred to as strong motion prior) through reinforcement learning. The\nselected segments have high precision and are directly used to finetune the\nmodel. In a newly collected surveillance camera dataset and a publicly\navailable UrbanStreet dataset, our proposed method improves the performance of\nhuman segmentation across multiple scenes and modalities (i.e., RGB to Infrared\n(IR)). Last but not least, our method is empirically complementary to existing\ndomain adaptation approaches such that additional performance gain is achieved\nby combining our weakly-supervised active learning approach with domain\nadaptation approaches. \n\n"}
{"id": "1807.11674", "contents": "Title: Improving the Annotation of DeepFashion Images for Fine-grained\n  Attribute Recognition Abstract: DeepFashion is a widely used clothing dataset with 50 categories and more\nthan overall 200k images where each image is annotated with fine-grained\nattributes. This dataset is often used for clothes recognition and although it\nprovides comprehensive annotations, the attributes distribution is unbalanced\nand repetitive specially for training fine-grained attribute recognition\nmodels. In this work, we tailored DeepFashion for fine-grained attribute\nrecognition task by focusing on each category separately. After selecting\ncategories with sufficient number of images for training, we remove very scarce\nattributes and merge the duplicate ones in each category, then we clean the\ndataset based on the new list of attributes. We use a bilinear convolutional\nneural network with pairwise ranking loss function for multi-label fine-grained\nattribute recognition and show that the new annotations improve the results for\nsuch a task. The detailed annotations for each of the selected categories are\nprovided for public use. \n\n"}
{"id": "1808.00043", "contents": "Title: The Unreasonable Effectiveness of Texture Transfer for Single Image\n  Super-resolution Abstract: While implicit generative models such as GANs have shown impressive results\nin high quality image reconstruction and manipulation using a combination of\nvarious losses, we consider a simpler approach leading to surprisingly strong\nresults. We show that texture loss alone allows the generation of perceptually\nhigh quality images. We provide a better understanding of texture constraining\nmechanism and develop a novel semantically guided texture constraining method\nfor further improvement. Using a recently developed perceptual metric employing\n\"deep features\" and termed LPIPS, the method obtains state-of-the-art results.\nMoreover, we show that a texture representation of those deep features better\ncapture the perceptual quality of an image than the original deep features.\nUsing texture information, off-the-shelf deep classification networks (without\ntraining) perform as well as the best performing (tuned and calibrated) LPIPS\nmetrics. The code is publicly available. \n\n"}
{"id": "1808.00193", "contents": "Title: Reinforced Evolutionary Neural Architecture Search Abstract: Neural Architecture Search (NAS) is an important yet challenging task in\nnetwork design due to its high computational consumption. To address this\nissue, we propose the Reinforced Evolutionary Neural Architecture Search (RE-\nNAS), which is an evolutionary method with the reinforced mutation for NAS. Our\nmethod integrates reinforced mutation into an evolution algorithm for neural\narchitecture exploration, in which a mutation controller is introduced to learn\nthe effects of slight modifications and make mutation actions. The reinforced\nmutation controller guides the model population to evolve efficiently.\nFurthermore, as child models can inherit parameters from their parents during\nevolution, our method requires very limited computational resources. In\nexperiments, we conduct the proposed search method on CIFAR-10 and obtain a\npowerful network architecture, RENASNet. This architecture achieves a\ncompetitive result on CIFAR-10. The explored network architecture is\ntransferable to ImageNet and achieves a new state-of-the-art accuracy, i.e.,\n75.7% top-1 accuracy with 5.36M parameters on mobile ImageNet. We further test\nits performance on semantic segmentation with DeepLabv3 on the PASCAL VOC.\nRENASNet outperforms MobileNet-v1, MobileNet-v2 and NASNet. It achieves 75.83%\nmIOU without being pre-trained on COCO. \n\n"}
{"id": "1808.00327", "contents": "Title: Generative Adversarial Frontal View to Bird View Synthesis Abstract: Environment perception is an important task with great practical value and\nbird view is an essential part for creating panoramas of surrounding\nenvironment. Due to the large gap and severe deformation between the frontal\nview and bird view, generating a bird view image from a single frontal view is\nchallenging. To tackle this problem, we propose the BridgeGAN, i.e., a novel\ngenerative model for bird view synthesis. First, an intermediate view, i.e.,\nhomography view, is introduced to bridge the large gap. Next, conditioned on\nthe three views (frontal view, homography view and bird view) in our task, a\nmulti-GAN based model is proposed to learn the challenging cross-view\ntranslation. Extensive experiments conducted on a synthetic dataset have\ndemonstrated that the images generated by our model are much better than those\ngenerated by existing methods, with more consistent global appearance and\nsharper details. Ablation studies and discussions show its reliability and\nrobustness in some challenging cases. \n\n"}
{"id": "1808.00783", "contents": "Title: The Quest for the Golden Activation Function Abstract: Deep Neural Networks have been shown to be beneficial for a variety of tasks,\nin particular allowing for end-to-end learning and reducing the requirement for\nmanual design decisions. However, still many parameters have to be chosen in\nadvance, also raising the need to optimize them. One important, but often\nignored system parameter is the selection of a proper activation function.\nThus, in this paper we target to demonstrate the importance of activation\nfunctions in general and show that for different tasks different activation\nfunctions might be meaningful. To avoid the manual design or selection of\nactivation functions, we build on the idea of genetic algorithms to learn the\nbest activation function for a given task. In addition, we introduce two new\nactivation functions, ELiSH and HardELiSH, which can easily be incorporated in\nour framework. In this way, we demonstrate for three different image\nclassification benchmarks that different activation functions are learned, also\nshowing improved results compared to typically used baselines. \n\n"}
{"id": "1808.01630", "contents": "Title: A Review of Learning with Deep Generative Models from Perspective of\n  Graphical Modeling Abstract: This document aims to provide a review on learning with deep generative\nmodels (DGMs), which is an highly-active area in machine learning and more\ngenerally, artificial intelligence. This review is not meant to be a tutorial,\nbut when necessary, we provide self-contained derivations for completeness.\nThis review has two features. First, though there are different perspectives to\nclassify DGMs, we choose to organize this review from the perspective of\ngraphical modeling, because the learning methods for directed DGMs and\nundirected DGMs are fundamentally different. Second, we differentiate model\ndefinitions from model learning algorithms, since different learning algorithms\ncan be applied to solve the learning problem on the same model, and an\nalgorithm can be applied to learn different models. We thus separate model\ndefinition and model learning, with more emphasis on reviewing, differentiating\nand connecting different learning algorithms. We also discuss promising future\nresearch directions. \n\n"}
{"id": "1808.02474", "contents": "Title: Multi-Label Zero-Shot Learning with Transfer-Aware Label Embedding\n  Projection Abstract: Zero-shot learning transfers knowledge from seen classes to novel unseen\nclasses to reduce human labor of labelling data for building new classifiers.\nMuch effort on zero-shot learning however has focused on the standard\nmulti-class setting, the more challenging multi-label zero-shot problem has\nreceived limited attention. In this paper we propose a transfer-aware embedding\nprojection approach to tackle multi-label zero-shot learning. The approach\nprojects the label embedding vectors into a low-dimensional space to induce\nbetter inter-label relationships and explicitly facilitate information transfer\nfrom seen labels to unseen labels, while simultaneously learning a max-margin\nmulti-label classifier with the projected label embeddings. Auxiliary\ninformation can be conveniently incorporated to guide the label embedding\nprojection to further improve label relation structures for zero-shot knowledge\ntransfer. We conduct experiments for zero-shot multi-label image\nclassification. The results demonstrate the efficacy of the proposed approach. \n\n"}
{"id": "1808.02559", "contents": "Title: A Joint Sequence Fusion Model for Video Question Answering and Retrieval Abstract: We present an approach named JSFusion (Joint Sequence Fusion) that can\nmeasure semantic similarity between any pairs of multimodal sequence data (e.g.\na video clip and a language sentence). Our multimodal matching network consists\nof two key components. First, the Joint Semantic Tensor composes a dense\npairwise representation of two sequence data into a 3D tensor. Then, the\nConvolutional Hierarchical Decoder computes their similarity score by\ndiscovering hidden hierarchical matches between the two sequence modalities.\nBoth modules leverage hierarchical attention mechanisms that learn to promote\nwell-matched representation patterns while prune out misaligned ones in a\nbottom-up manner. Although the JSFusion is a universal model to be applicable\nto any multimodal sequence data, this work focuses on video-language tasks\nincluding multimodal retrieval and video QA. We evaluate the JSFusion model in\nthree retrieval and VQA tasks in LSMDC, for which our model achieves the best\nperformance reported so far. We also perform multiple-choice and movie\nretrieval tasks for the MSR-VTT dataset, on which our approach outperforms many\nstate-of-the-art methods. \n\n"}
{"id": "1808.02610", "contents": "Title: L-Shapley and C-Shapley: Efficient Model Interpretation for Structured\n  Data Abstract: We study instancewise feature importance scoring as a method for model\ninterpretation. Any such method yields, for each predicted instance, a vector\nof importance scores associated with the feature vector. Methods based on the\nShapley score have been proposed as a fair way of computing feature\nattributions of this kind, but incur an exponential complexity in the number of\nfeatures. This combinatorial explosion arises from the definition of the\nShapley value and prevents these methods from being scalable to large data sets\nand complex models. We focus on settings in which the data have a graph\nstructure, and the contribution of features to the target variable is\nwell-approximated by a graph-structured factorization. In such settings, we\ndevelop two algorithms with linear complexity for instancewise feature\nimportance scoring. We establish the relationship of our methods to the Shapley\nvalue and another closely related concept known as the Myerson value from\ncooperative game theory. We demonstrate on both language and image data that\nour algorithms compare favorably with other methods for model interpretation. \n\n"}
{"id": "1808.03114", "contents": "Title: Classifier-Guided Visual Correction of Noisy Labels for Image\n  Classification Tasks Abstract: Training data plays an essential role in modern applications of machine\nlearning. However, gathering labeled training data is time-consuming.\nTherefore, labeling is often outsourced to less experienced users, or\ncompletely automated. This can introduce errors, which compromise valuable\ntraining data, and lead to suboptimal training results. We thus propose a novel\napproach that uses the power of pretrained classifiers to visually guide users\nto noisy labels, and let them interactively check error candidates, to\niteratively improve the training data set. To systematically investigate\ntraining data, we propose a categorization of labeling errors into three\ndifferent types, based on an analysis of potential pitfalls in label\nacquisition processes. For each of these types, we present approaches to\ndetect, reason about, and resolve error candidates, as we propose measures and\nvisual guidance techniques to support machine learning users. Our approach has\nbeen used to spot errors in well-known machine learning benchmark data sets,\nand we tested its usability during a user evaluation. While initially developed\nfor images, the techniques presented in this paper are independent of the\nclassification algorithm, and can also be extended to many other types of\ntraining data. \n\n"}
{"id": "1808.03857", "contents": "Title: Ranking with Features: Algorithm and A Graph Theoretic Analysis Abstract: We consider the problem of ranking a set of items from pairwise comparisons\nin the presence of features associated with the items. Recent works have\nestablished that $O(n\\log(n))$ samples are needed to rank well when there is no\nfeature information present. However, this might be sub-optimal in the presence\nof associated features. We introduce a new probabilistic preference model\ncalled feature-Bradley-Terry-Luce (f-BTL) model that generalizes the standard\nBTL model to incorporate feature information. We present a new least squares\nbased algorithm called fBTL-LS which we show requires much lesser than\n$O(n\\log(n))$ pairs to obtain a good ranking -- precisely our new sample\ncomplexity bound is of $O(\\alpha\\log \\alpha)$, where $\\alpha$ denotes the\nnumber of `independent items' of the set, in general $\\alpha << n$. Our\nanalysis is novel and makes use of tools from classical graph matching theory\nto provide tighter bounds that sheds light on the true complexity of the\nranking problem, capturing the item dependencies in terms of their feature\nrepresentations. This was not possible with earlier matrix completion based\ntools used for this problem. We also prove an information theoretic lower bound\non the required sample complexity for recovering the underlying ranking, which\nessentially shows the tightness of our proposed algorithms. The efficacy of our\nproposed algorithms are validated through extensive experimental evaluations on\na variety of synthetic and real world datasets. \n\n"}
{"id": "1808.04359", "contents": "Title: Community Regularization of Visually-Grounded Dialog Abstract: The task of conducting visually grounded dialog involves learning\ngoal-oriented cooperative dialog between autonomous agents who exchange\ninformation about a scene through several rounds of questions and answers in\nnatural language. We posit that requiring artificial agents to adhere to the\nrules of human language, while also requiring them to maximize information\nexchange through dialog is an ill-posed problem. We observe that humans do not\nstray from a common language because they are social creatures who live in\ncommunities, and have to communicate with many people everyday, so it is far\neasier to stick to a common language even at the cost of some efficiency loss.\nUsing this as inspiration, we propose and evaluate a multi-agent\ncommunity-based dialog framework where each agent interacts with, and learns\nfrom, multiple agents, and show that this community-enforced regularization\nresults in more relevant and coherent dialog (as judged by human evaluators)\nwithout sacrificing task performance (as judged by quantitative metrics). \n\n"}
{"id": "1808.04440", "contents": "Title: FaceOff: Anonymizing Videos in the Operating Rooms Abstract: Video capture in the surgical operating room (OR) is increasingly possible\nand has potential for use with computer assisted interventions (CAI), surgical\ndata science and within smart OR integration. Captured video innately carries\nsensitive information that should not be completely visible in order to\npreserve the patient's and the clinical teams' identities. When surgical video\nstreams are stored on a server, the videos must be anonymized prior to storage\nif taken outside of the hospital. In this article, we describe how a deep\nlearning model, Faster R-CNN, can be used for this purpose and help to\nanonymize video data captured in the OR. The model detects and blurs faces in\nan effort to preserve anonymity. After testing an existing face detection\ntrained model, a new dataset tailored to the surgical environment, with faces\nobstructed by surgical masks and caps, was collected for fine-tuning to achieve\nhigher face-detection rates in the OR. We also propose a temporal\nregularisation kernel to improve recall rates. The fine-tuned model achieves a\nface detection recall of 88.05 % and 93.45 % before and after applying\ntemporal-smoothing respectively. \n\n"}
{"id": "1808.04449", "contents": "Title: Starting Movement Detection of Cyclists Using Smart Devices Abstract: In near future, vulnerable road users (VRUs) such as cyclists and pedestrians\nwill be equipped with smart devices and wearables which are capable to\ncommunicate with intelligent vehicles and other traffic participants. Road\nusers are then able to cooperate on different levels, such as in cooperative\nintention detection for advanced VRU protection. Smart devices can be used to\ndetect intentions, e.g., an occluded cyclist intending to cross the road, to\nwarn vehicles of VRUs, and prevent potential collisions. This article presents\na human activity recognition approach to detect the starting movement of\ncyclists wearing smart devices. We propose a novel two-stage feature selection\nprocedure using a score specialized for robust starting detection reducing the\nfalse positive detections and leading to understandable and interpretable\nfeatures. The detection is modelled as a classification problem and realized by\nmeans of a machine learning classifier. We introduce an auxiliary class, that\nmodels starting movements and allows to integrate early movement indicators,\ni.e., body part movements indicating future behaviour. In this way we improve\nthe robustness and reduce the detection time of the classifier. Our empirical\nstudies with real-world data originating from experiments which involve 49 test\nsubjects and consists of 84 starting motions show that we are able to detect\nthe starting movements early. Our approach reaches an F1-score of 67 % within\n0.33 s after the first movement of the bicycle wheel. Investigations concerning\nthe device wearing location show that for devices worn in the trouser pocket\nthe detector has less false detections and detects starting movements faster on\naverage. We found that we can further improve the results when we train\ndistinct classifiers for different wearing locations. \n\n"}
{"id": "1808.04505", "contents": "Title: Fine-Grained Representation Learning and Recognition by Exploiting\n  Hierarchical Semantic Embedding Abstract: Object categories inherently form a hierarchy with different levels of\nconcept abstraction, especially for fine-grained categories. For example, birds\n(Aves) can be categorized according to a four-level hierarchy of order, family,\ngenus, and species. This hierarchy encodes rich correlations among various\ncategories across different levels, which can effectively regularize the\nsemantic space and thus make prediction less ambiguous. However, previous\nstudies of fine-grained image recognition primarily focus on categories of one\ncertain level and usually overlook this correlation information. In this work,\nwe investigate simultaneously predicting categories of different levels in the\nhierarchy and integrating this structured correlation information into the deep\nneural network by developing a novel Hierarchical Semantic Embedding (HSE)\nframework. Specifically, the HSE framework sequentially predicts the category\nscore vector of each level in the hierarchy, from highest to lowest. At each\nlevel, it incorporates the predicted score vector of the higher level as prior\nknowledge to learn finer-grained feature representation. During training, the\npredicted score vector of the higher level is also employed to regularize label\nprediction by using it as soft targets of corresponding sub-categories. To\nevaluate the proposed framework, we organize the 200 bird species of the\nCaltech-UCSD birds dataset with the four-level category hierarchy and construct\na large-scale butterfly dataset that also covers four level categories.\nExtensive experiments on these two and the newly-released VegFru datasets\ndemonstrate the superiority of our HSE framework over the baseline methods and\nexisting competitors. \n\n"}
{"id": "1808.04759", "contents": "Title: An Overview and a Benchmark of Active Learning for Outlier Detection\n  with One-Class Classifiers Abstract: Active learning methods increase classification quality by means of user\nfeedback. An important subcategory is active learning for outlier detection\nwith one-class classifiers. While various methods in this category exist,\nselecting one for a given application scenario is difficult. This is because\nexisting methods rely on different assumptions, have different objectives, and\noften are tailored to a specific use case. All this calls for a comprehensive\ncomparison, the topic of this article. This article starts with a\ncategorization of the various methods. We then propose ways to evaluate active\nlearning results. Next, we run extensive experiments to compare existing\nmethods, for a broad variety of scenarios. Based on our results, we formulate\nguidelines on how to select active learning methods for outlier detection with\none-class classifiers. \n\n"}
{"id": "1808.04848", "contents": "Title: URSA: A Neural Network for Unordered Point Clouds Using Constellations Abstract: This paper describes a neural network layer, named Ursa, that uses a\nconstellation of points to learn classification information from point cloud\ndata. Unlike other machine learning classification problems where the task is\nto classify an individual high-dimensional observation, in a point-cloud\nclassification problem the goal is to classify a set of d-dimensional\nobservations. Because a point cloud is a set, there is no ordering to the\ncollection of points in a point-cloud classification problem. Thus, the\nchallenge of classifying point clouds inputs is in building a classifier which\nis agnostic to the ordering of the observations, yet preserves the\nd-dimensional information of each point in the set. This research presents\nUrsa, a new layer type for an artificial neural network which achieves these\ntwo properties. Similar to new methods for this task, this architecture works\ndirectly on d-dimensional points rather than first converting the points to a\nd-dimensional volume. The Ursa layer is followed by a series of dense layers to\nclassify 2D and 3D objects from point clouds. Experiments on ModelNet40 and\nMNIST data show classification results comparable with current methods, while\nreducing the training parameters by over 50 percent. \n\n"}
{"id": "1808.05022", "contents": "Title: A Dense-Depth Representation for VLAD descriptors in Content-Based Image\n  Retrieval Abstract: The recent advances brought by deep learning allowed to improve the\nperformance in image retrieval tasks. Through the many convolutional layers,\navailable in a Convolutional Neural Network (CNN), it is possible to obtain a\nhierarchy of features from the evaluated image. At every step, the patches\nextracted are smaller than the previous levels and more representative.\nFollowing this idea, this paper introduces a new detector applied on the\nfeature maps extracted from pre-trained CNN. Specifically, this approach lets\nto increase the number of features in order to increase the performance of the\naggregation algorithms like the most famous and used VLAD embedding. The\nproposed approach is tested on different public datasets: Holidays, Oxford5k,\nParis6k and UKB. \n\n"}
{"id": "1808.05492", "contents": "Title: Metric Learning for Novelty and Anomaly Detection Abstract: When neural networks process images which do not resemble the distribution\nseen during training, so called out-of-distribution images, they often make\nwrong predictions, and do so too confidently. The capability to detect\nout-of-distribution images is therefore crucial for many real-world\napplications. We divide out-of-distribution detection between novelty detection\n---images of classes which are not in the training set but are related to\nthose---, and anomaly detection ---images with classes which are unrelated to\nthe training set. By related we mean they contain the same type of objects,\nlike digits in MNIST and SVHN. Most existing work has focused on anomaly\ndetection, and has addressed this problem considering networks trained with the\ncross-entropy loss. Differently from them, we propose to use metric learning\nwhich does not have the drawback of the softmax layer (inherent to\ncross-entropy methods), which forces the network to divide its prediction power\nover the learned classes. We perform extensive experiments and evaluate both\nnovelty and anomaly detection, even in a relevant application such as traffic\nsign recognition, obtaining comparable or better results than previous works. \n\n"}
{"id": "1808.05577", "contents": "Title: Deeper Image Quality Transfer: Training Low-Memory Neural Networks for\n  3D Images Abstract: In this paper we address the memory demands that come with the processing of\n3-dimensional, high-resolution, multi-channeled medical images in deep\nlearning. We exploit memory-efficient backpropagation techniques, to reduce the\nmemory complexity of network training from being linear in the network's depth,\nto being roughly constant $ - $ permitting us to elongate deep architectures\nwith negligible memory increase. We evaluate our methodology in the paradigm of\nImage Quality Transfer, whilst noting its potential application to various\ntasks that use deep learning. We study the impact of depth on accuracy and show\nthat deeper models have more predictive power, which may exploit larger\ntraining sets. We obtain substantially better results than the previous\nstate-of-the-art model with a slight memory increase, reducing the\nroot-mean-squared-error by $ 13\\% $. Our code is publicly available. \n\n"}
{"id": "1808.07272", "contents": "Title: Deep Adaptive Temporal Pooling for Activity Recognition Abstract: Deep neural networks have recently achieved competitive accuracy for human\nactivity recognition. However, there is room for improvement, especially in\nmodeling long-term temporal importance and determining the activity relevance\nof different temporal segments in a video. To address this problem, we propose\na learnable and differentiable module: Deep Adaptive Temporal Pooling (DATP).\nDATP applies a self-attention mechanism to adaptively pool the classification\nscores of different video segments. Specifically, using frame-level features,\nDATP regresses importance of different temporal segments and generates weights\nfor them. Remarkably, DATP is trained using only the video-level label. There\nis no need of additional supervision except video-level activity class label.\nWe conduct extensive experiments to investigate various input features and\ndifferent weight models. Experimental results show that DATP can learn to\nassign large weights to key video segments. More importantly, DATP can improve\ntraining of frame-level feature extractor. This is because relevant temporal\nsegments are assigned large weights during back-propagation. Overall, we\nachieve state-of-the-art performance on UCF101, HMDB51 and Kinetics datasets. \n\n"}
{"id": "1808.07784", "contents": "Title: Time-Agnostic Prediction: Predicting Predictable Video Frames Abstract: Prediction is arguably one of the most basic functions of an intelligent\nsystem. In general, the problem of predicting events in the future or between\ntwo waypoints is exceedingly difficult. However, most phenomena naturally pass\nthrough relatively predictable bottlenecks---while we cannot predict the\nprecise trajectory of a robot arm between being at rest and holding an object\nup, we can be certain that it must have picked the object up. To exploit this,\nwe decouple visual prediction from a rigid notion of time. While conventional\napproaches predict frames at regularly spaced temporal intervals, our\ntime-agnostic predictors (TAP) are not tied to specific times so that they may\ninstead discover predictable \"bottleneck\" frames no matter when they occur. We\nevaluate our approach for future and intermediate frame prediction across three\nrobotic manipulation tasks. Our predictions are not only of higher visual\nquality, but also correspond to coherent semantic subgoals in temporally\nextended tasks. \n\n"}
{"id": "1808.08460", "contents": "Title: The Social Cost of Strategic Classification Abstract: Consequential decision-making typically incentivizes individuals to behave\nstrategically, tailoring their behavior to the specifics of the decision rule.\nA long line of work has therefore sought to counteract strategic behavior by\ndesigning more conservative decision boundaries in an effort to increase\nrobustness to the effects of strategic covariate shift. We show that these\nefforts benefit the institutional decision maker at the expense of the\nindividuals being classified. Introducing a notion of social burden, we prove\nthat any increase in institutional utility necessarily leads to a corresponding\nincrease in social burden. Moreover, we show that the negative externalities of\nstrategic classification can disproportionately harm disadvantaged groups in\nthe population. Our results highlight that strategy-robustness must be weighed\nagainst considerations of social welfare and fairness. \n\n"}
{"id": "1808.08718", "contents": "Title: Wide Activation for Efficient and Accurate Image Super-Resolution Abstract: In this report we demonstrate that with same parameters and computational\nbudgets, models with wider features before ReLU activation have significantly\nbetter performance for single image super-resolution (SISR). The resulted SR\nresidual network has a slim identity mapping pathway with wider (\\(2\\times\\) to\n\\(4\\times\\)) channels before activation in each residual block. To further\nwiden activation (\\(6\\times\\) to \\(9\\times\\)) without computational overhead,\nwe introduce linear low-rank convolution into SR networks and achieve even\nbetter accuracy-efficiency tradeoffs. In addition, compared with batch\nnormalization or no normalization, we find training with weight normalization\nleads to better accuracy for deep super-resolution networks. Our proposed SR\nnetwork \\textit{WDSR} achieves better results on large-scale DIV2K image\nsuper-resolution benchmark in terms of PSNR with same or lower computational\ncomplexity. Based on WDSR, our method also won 1st places in NTIRE 2018\nChallenge on Single Image Super-Resolution in all three realistic tracks.\nExperiments and ablation studies support the importance of wide activation for\nimage super-resolution. Code is released at:\nhttps://github.com/JiahuiYu/wdsr_ntire2018 \n\n"}
{"id": "1808.08754", "contents": "Title: What Makes Natural Scene Memorable? Abstract: Recent studies on image memorability have shed light on the visual features\nthat make generic images, object images or face photographs memorable. However,\na clear understanding and reliable estimation of natural scene memorability\nremain elusive. In this paper, we provide an attempt to answer: \"what exactly\nmakes natural scene memorable\". Specifically, we first build LNSIM, a\nlarge-scale natural scene image memorability database (containing 2,632 images\nand memorability annotations). Then, we mine our database to investigate how\nlow-, middle- and high-level handcrafted features affect the memorability of\nnatural scene. In particular, we find that high-level feature of scene category\nis rather correlated with natural scene memorability. Thus, we propose a deep\nneural network based natural scene memorability (DeepNSM) predictor, which\ntakes advantage of scene category. Finally, the experimental results validate\nthe effectiveness of DeepNSM. \n\n"}
{"id": "1808.09347", "contents": "Title: Joint Domain Alignment and Discriminative Feature Learning for\n  Unsupervised Deep Domain Adaptation Abstract: Recently, considerable effort has been devoted to deep domain adaptation in\ncomputer vision and machine learning communities. However, most of existing\nwork only concentrates on learning shared feature representation by minimizing\nthe distribution discrepancy across different domains. Due to the fact that all\nthe domain alignment approaches can only reduce, but not remove the domain\nshift. Target domain samples distributed near the edge of the clusters, or far\nfrom their corresponding class centers are easily to be misclassified by the\nhyperplane learned from the source domain. To alleviate this issue, we propose\nto joint domain alignment and discriminative feature learning, which could\nbenefit both domain alignment and final classification. Specifically, an\ninstance-based discriminative feature learning method and a center-based\ndiscriminative feature learning method are proposed, both of which guarantee\nthe domain invariant features with better intra-class compactness and\ninter-class separability. Extensive experiments show that learning the\ndiscriminative features in the shared feature space can significantly boost the\nperformance of deep domain adaptation methods. \n\n"}
{"id": "1808.09560", "contents": "Title: On Learning 3D Face Morphable Model from In-the-wild Images Abstract: As a classic statistical model of 3D facial shape and albedo, 3D Morphable\nModel (3DMM) is widely used in facial analysis, e.g., model fitting, image\nsynthesis. Conventional 3DMM is learned from a set of 3D face scans with\nassociated well-controlled 2D face images, and represented by two sets of PCA\nbasis functions. Due to the type and amount of training data, as well as, the\nlinear bases, the representation power of 3DMM can be limited. To address these\nproblems, this paper proposes an innovative framework to learn a nonlinear 3DMM\nmodel from a large set of in-the-wild face images, without collecting 3D face\nscans. Specifically, given a face image as input, a network encoder estimates\nthe projection, lighting, shape and albedo parameters. Two decoders serve as\nthe nonlinear 3DMM to map from the shape and albedo parameters to the 3D shape\nand albedo, respectively. With the projection parameter, lighting, 3D shape,\nand albedo, a novel analytically-differentiable rendering layer is designed to\nreconstruct the original input face. The entire network is end-to-end trainable\nwith only weak supervision. We demonstrate the superior representation power of\nour nonlinear 3DMM over its linear counterpart, and its contribution to face\nalignment, 3D reconstruction, and face editing. \n\n"}
{"id": "1808.09744", "contents": "Title: Rule induction for global explanation of trained models Abstract: Understanding the behavior of a trained network and finding explanations for\nits outputs is important for improving the network's performance and\ngeneralization ability, and for ensuring trust in automated systems. Several\napproaches have previously been proposed to identify and visualize the most\nimportant features by analyzing a trained network. However, the relations\nbetween different features and classes are lost in most cases. We propose a\ntechnique to induce sets of if-then-else rules that capture these relations to\nglobally explain the predictions of a network. We first calculate the\nimportance of the features in the trained network. We then weigh the original\ninputs with these feature importance scores, simplify the transformed input\nspace, and finally fit a rule induction model to explain the model predictions.\nWe find that the output rule-sets can explain the predictions of a neural\nnetwork trained for 4-class text classification from the 20 newsgroups dataset\nto a macro-averaged F-score of 0.80. We make the code available at\nhttps://github.com/clips/interpret_with_rules. \n\n"}
{"id": "1808.09769", "contents": "Title: Tensor Alignment Based Domain Adaptation for Hyperspectral Image\n  Classification Abstract: This paper presents a tensor alignment (TA) based domain adaptation method\nfor hyperspectral image (HSI) classification. To be specific, HSIs in both\ndomains are first segmented into superpixels and tensors of both domains are\nconstructed to include neighboring samples from single superpixel. Then we\nconsider the subspace invariance between two domains as projection matrices and\noriginal tensors are projected as core tensors with lower dimensions into the\ninvariant tensor subspace by applying Tucker decomposition. To preserve\ngeometric information in original tensors, we employ a manifold regularization\nterm for core tensors into the decomposition progress. The projection matrices\nand core tensors are solved in an alternating optimization manner and the\nconvergence of TA algorithm is analyzed. In addition, a post-processing\nstrategy is defined via pure samples extraction for each superpixel to further\nimprove classification performance. Experimental results on four real HSIs\ndemonstrate that the proposed method can achieve better performance compared\nwith the state-of-the-art subspace learning methods when a limited amount of\nsource labeled samples are available. \n\n"}
{"id": "1808.10350", "contents": "Title: IEA: Inner Ensemble Average within a convolutional neural network Abstract: Ensemble learning is a method of combining multiple trained models to improve\nmodel accuracy. We propose the usage of such methods, specifically ensemble\naverage, inside Convolutional Neural Network (CNN) architectures by replacing\nthe single convolutional layers with Inner Average Ensembles (IEA) of multiple\nconvolutional layers. Empirical results on different benchmarking datasets show\nthat CNN models using IEA outperform those with regular convolutional layers. A\nvisual and a similarity score analysis of the features generated from IEA\nexplains why it boosts the model performance. \n\n"}
{"id": "1808.10544", "contents": "Title: LUCSS: Language-based User-customized Colourization of Scene Sketches Abstract: We introduce LUCSS, a language-based system for interactive col- orization of\nscene sketches, based on their semantic understanding. LUCSS is built upon deep\nneural networks trained via a large-scale repository of scene sketches and\ncartoon-style color images with text descriptions. It con- sists of three\nsequential modules. First, given a scene sketch, the segmenta- tion module\nautomatically partitions an input sketch into individual object instances.\nNext, the captioning module generates the text description with spatial\nrelationships based on the instance-level segmentation results. Fi- nally, the\ninteractive colorization module allows users to edit the caption and produce\ncolored images based on the altered caption. Our experiments show the\neffectiveness of our approach and the desirability of its compo- nents to\nalternative choices. \n\n"}
{"id": "1809.00366", "contents": "Title: Cold-start recommendations in Collective Matrix Factorization Abstract: This work explores the ability of collective matrix factorization models in\nrecommender systems to make predictions about users and items for which there\nis side information available but no feedback or interactions data, and\nproposes a new formulation with a faster cold-start prediction formula that can\nbe used in real-time systems. While these cold-start recommendations are not as\ngood as warm-start ones, they were found to be of better quality than\nnon-personalized recommendations, and predictions about new users were found to\nbe more reliable than those about new items. The formulation proposed here\nresulted in improved cold-start recommendations in many scenarios, at the\nexpense of worse warm-start ones. \n\n"}
{"id": "1809.00846", "contents": "Title: Towards Understanding Regularization in Batch Normalization Abstract: Batch Normalization (BN) improves both convergence and generalization in\ntraining neural networks. This work understands these phenomena theoretically.\nWe analyze BN by using a basic block of neural networks, consisting of a kernel\nlayer, a BN layer, and a nonlinear activation function. This basic network\nhelps us understand the impacts of BN in three aspects. First, by viewing BN as\nan implicit regularizer, BN can be decomposed into population normalization\n(PN) and gamma decay as an explicit regularization. Second, learning dynamics\nof BN and the regularization show that training converged with large maximum\nand effective learning rate. Third, generalization of BN is explored by using\nstatistical mechanics. Experiments demonstrate that BN in convolutional neural\nnetworks share the same traits of regularization as the above analyses. \n\n"}
{"id": "1809.00961", "contents": "Title: MSCE: An edge preserving robust loss function for improving\n  super-resolution algorithms Abstract: With the recent advancement in the deep learning technologies such as CNNs\nand GANs, there is significant improvement in the quality of the images\nreconstructed by deep learning based super-resolution (SR) techniques. In this\nwork, we propose a robust loss function based on the preservation of edges\nobtained by the Canny operator. This loss function, when combined with the\nexisting loss function such as mean square error (MSE), gives better SR\nreconstruction measured in terms of PSNR and SSIM. Our proposed loss function\nguarantees improved performance on any existing algorithm using MSE loss\nfunction, without any increase in the computational complexity during testing. \n\n"}
{"id": "1809.00970", "contents": "Title: Iterative multi-path tracking for video and volume segmentation with\n  sparse point supervision Abstract: Recent machine learning strategies for segmentation tasks have shown great\nability when trained on large pixel-wise annotated image datasets. It remains a\nmajor challenge however to aggregate such datasets, as the time and monetary\ncost associated with collecting extensive annotations is extremely high. This\nis particularly the case for generating precise pixel-wise annotations in video\nand volumetric image data. To this end, this work presents a novel framework to\nproduce pixel-wise segmentations using minimal supervision. Our method relies\non 2D point supervision, whereby a single 2D location within an object of\ninterest is provided on each image of the data. Our method then estimates the\nobject appearance in a semi-supervised fashion by learning\nobject-image-specific features and by using these in a semi-supervised learning\nframework. Our object model is then used in a graph-based optimization problem\nthat takes into account all provided locations and the image data in order to\ninfer the complete pixel-wise segmentation. In practice, we solve this\noptimally as a tracking problem using a K-shortest path approach. Both the\nobject model and segmentation are then refined iteratively to further improve\nthe final segmentation. We show that by collecting 2D locations using a gaze\ntracker, our approach can provide state-of-the-art segmentations on a range of\nobjects and image modalities (video and 3D volumes), and that these can then be\nused to train supervised machine learning classifiers. \n\n"}
{"id": "1809.01000", "contents": "Title: Bayesian Outdoor Defect Detection Abstract: We introduce a Bayesian defect detector to facilitate the defect detection on\nthe motion blurred images on rough texture surfaces. To enhance the accuracy of\nBayesian detection on removing non-defect pixels, we develop a class of\nreflected non-local prior distributions, which is constructed by using the mode\nof a distribution to subtract its density. The reflected non-local priors\nforces the Bayesian detector to approach 0 at the non-defect locations. We\nconduct experiments studies to demonstrate the superior performance of the\nBayesian detector in eliminating the non-defect points. We implement the\nBayesian detector in the motion blurred drone images, in which the detector\nsuccessfully identifies the hail damages on the rough surface and substantially\nenhances the accuracy of the entire defect detection pipeline. \n\n"}
{"id": "1809.01765", "contents": "Title: Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method\n  for Stochastic Sparse Linear Regression with Limited Attribute Observation Abstract: We develop new stochastic gradient methods for efficiently solving sparse\nlinear regression in a partial attribute observation setting, where learners\nare only allowed to observe a fixed number of actively chosen attributes per\nexample at training and prediction times. It is shown that the methods achieve\nessentially a sample complexity of $O(1/\\varepsilon)$ to attain an error of\n$\\varepsilon$ under a variant of restricted eigenvalue condition, and the rate\nhas better dependency on the problem dimension than existing methods.\nParticularly, if the smallest magnitude of the non-zero components of the\noptimal solution is not too small, the rate of our proposed {\\it Hybrid}\nalgorithm can be boosted to near the minimax optimal sample complexity of {\\it\nfull information} algorithms. The core ideas are (i) efficient construction of\nan unbiased gradient estimator by the iterative usage of the hard thresholding\noperator for configuring an exploration algorithm; and (ii) an adaptive\ncombination of the exploration and an exploitation algorithms for quickly\nidentifying the support of the optimum and efficiently searching the optimal\nparameter in its support. Experimental results are presented to validate our\ntheoretical findings and the superiority of our proposed methods. \n\n"}
{"id": "1809.01943", "contents": "Title: Cascaded Mutual Modulation for Visual Reasoning Abstract: Visual reasoning is a special visual question answering problem that is\nmulti-step and compositional by nature, and also requires intensive text-vision\ninteractions. We propose CMM: Cascaded Mutual Modulation as a novel end-to-end\nvisual reasoning model. CMM includes a multi-step comprehension process for\nboth question and image. In each step, we use a Feature-wise Linear Modulation\n(FiLM) technique to enable textual/visual pipeline to mutually control each\nother. Experiments show that CMM significantly outperforms most related models,\nand reach state-of-the-arts on two visual reasoning benchmarks: CLEVR and NLVR,\ncollected from both synthetic and natural languages. Ablation studies confirm\nthat both our multistep framework and our visual-guided language modulation are\ncritical to the task. Our code is available at\nhttps://github.com/FlamingHorizon/CMM-VR. \n\n"}
{"id": "1809.02108", "contents": "Title: Deep Audio-Visual Speech Recognition Abstract: The goal of this work is to recognise phrases and sentences being spoken by a\ntalking face, with or without the audio. Unlike previous works that have\nfocussed on recognising a limited number of words or phrases, we tackle lip\nreading as an open-world problem - unconstrained natural language sentences,\nand in the wild videos. Our key contributions are: (1) we compare two models\nfor lip reading, one using a CTC loss, and the other using a\nsequence-to-sequence loss. Both models are built on top of the transformer\nself-attention architecture; (2) we investigate to what extent lip reading is\ncomplementary to audio speech recognition, especially when the audio signal is\nnoisy; (3) we introduce and publicly release a new dataset for audio-visual\nspeech recognition, LRS2-BBC, consisting of thousands of natural sentences from\nBritish television. The models that we train surpass the performance of all\nprevious work on a lip reading benchmark dataset by a significant margin. \n\n"}
{"id": "1809.02440", "contents": "Title: Optimizing deep video representation to match brain activity Abstract: The comparison of observed brain activity with the statistics generated by\nartificial intelligence systems is useful to probe brain functional\norganization under ecological conditions. Here we study fMRI activity in ten\nsubjects watching color natural movies and compute deep representations of\nthese movies with an architecture that relies on optical flow and image\ncontent. The association of activity in visual areas with the different layers\nof the deep architecture displays complexity-related contrasts across visual\nareas and reveals a striking foveal/peripheral dichotomy. \n\n"}
{"id": "1809.03316", "contents": "Title: Hierarchical Video Understanding Abstract: We introduce a hierarchical architecture for video understanding that\nexploits the structure of real world actions by capturing targets at different\nlevels of granularity. We design the model such that it first learns simpler\ncoarse-grained tasks, and then moves on to learn more fine-grained targets. The\nmodel is trained with a joint loss on different granularity levels. We\ndemonstrate empirical results on the recent release of Something-Something\ndataset, which provides a hierarchy of targets, namely coarse-grained action\ngroups, fine-grained action categories, and captions. Experiments suggest that\nmodels that exploit targets at different levels of granularity achieve better\nperformance on all levels. \n\n"}
{"id": "1809.03368", "contents": "Title: Probabilistic Binary Neural Networks Abstract: Low bit-width weights and activations are an effective way of combating the\nincreasing need for both memory and compute power of Deep Neural Networks. In\nthis work, we present a probabilistic training method for Neural Network with\nboth binary weights and activations, called BLRNet. By embracing stochasticity\nduring training, we circumvent the need to approximate the gradient of\nnon-differentiable functions such as sign(), while still obtaining a fully\nBinary Neural Network at test time. Moreover, it allows for anytime ensemble\npredictions for improved performance and uncertainty estimates by sampling from\nthe weight distribution. Since all operations in a layer of the BLRNet operate\non random variables, we introduce stochastic versions of Batch Normalization\nand max pooling, which transfer well to a deterministic network at test time.\nWe evaluate the BLRNet on multiple standardized benchmarks. \n\n"}
{"id": "1809.03627", "contents": "Title: ClusterGAN : Latent Space Clustering in Generative Adversarial Networks Abstract: Generative Adversarial networks (GANs) have obtained remarkable success in\nmany unsupervised learning tasks and unarguably, clustering is an important\nunsupervised learning problem. While one can potentially exploit the\nlatent-space back-projection in GANs to cluster, we demonstrate that the\ncluster structure is not retained in the GAN latent space.\n  In this paper, we propose ClusterGAN as a new mechanism for clustering using\nGANs. By sampling latent variables from a mixture of one-hot encoded variables\nand continuous latent variables, coupled with an inverse network (which\nprojects the data to the latent space) trained jointly with a clustering\nspecific loss, we are able to achieve clustering in the latent space. Our\nresults show a remarkable phenomenon that GANs can preserve latent space\ninterpolation across categories, even though the discriminator is never exposed\nto such vectors. We compare our results with various clustering baselines and\ndemonstrate superior performance on both synthetic and real datasets. \n\n"}
{"id": "1809.03776", "contents": "Title: Solving Non-identifiable Latent Feature Models Abstract: Latent feature models (LFM)s are widely employed for extracting latent\nstructures of data. While offering high, parameter estimation is difficult with\nLFMs because of the combinational nature of latent features, and\nnon-identifiability is a particularly difficult problem when parameter\nestimation is not unique and there exists equivalent solutions. In this paper,\na necessary and sufficient condition for non-identifiability is shown. The\ncondition is significantly related to dependency of features, and this implies\nthat non-identifiability may often occur in real-world applications. A novel\nmethod for parameter estimation that solves the non-identifiability problem is\nalso proposed. This method can be combined as a post-process with existing\nmethods and can find an appropriate solution by hopping efficiently through\nequivalent solutions. We have evaluated the effectiveness of the method on both\nsynthetic and real-world datasets. \n\n"}
{"id": "1809.04364", "contents": "Title: Thermal Features for Presentation Attack Detection in Hand Biometrics Abstract: This paper proposes a method for utilizing thermal features of the hand for\nthe purpose of presentation attack detection (PAD) that can be employed in a\nhand biometrics system's pipeline. By envisaging two different operational\nmodes of our system, and by employing a DCNN-based classifiers fine-tuned with\na dataset of real and fake hand representations captured in both visible and\nther- mal spectrum, we were able to bring two important deliverables. First, a\nPAD method operating in an open-set mode, capable of correctly discerning 100%\nof fake thermal samples, achieving Attack Presentation Classification Error\nRate (APCER) and Bona-Fide Presentation Classification Error Rate (BPCER) equal\nto 0%, which can be easily implemented into any existing system as a separate\ncomponent. Second, a hand biometrics system operating in a closed-set mode,\nthat has PAD built right into the recognition pipeline, and operating\nsimultaneously with the user-wise classification, achieving rank-1 recognition\naccuracy of up to 99.75%. We also show that thermal images of the human hand,\nin addition to liveness features they carry, can also improve classification\naccuracy of a biometric system, when coupled with visible light images. To\nfollow the reproducibility guidelines and to stimulate further research in this\narea, we share the trained model weights, source codes, and a newly created\ndataset of fake hand representations with interested researchers. \n\n"}
{"id": "1809.04453", "contents": "Title: End-to-end depth from motion with stabilized monocular videos Abstract: We propose a depth map inference system from monocular videos based on a\nnovel dataset for navigation that mimics aerial footage from gimbal stabilized\nmonocular camera in rigid scenes. Unlike most navigation datasets, the lack of\nrotation implies an easier structure from motion problem which can be leveraged\nfor different kinds of tasks such as depth inference and obstacle avoidance. We\nalso propose an architecture for end-to-end depth inference with a fully\nconvolutional network. Results show that although tied to camera inner\nparameters, the problem is locally solvable and leads to good quality depth\nprediction. \n\n"}
{"id": "1809.04734", "contents": "Title: DispSegNet: Leveraging Semantics for End-to-End Learning of Disparity\n  Estimation from Stereo Imagery Abstract: Recent work has shown that convolutional neural networks (CNNs) can be\napplied successfully in disparity estimation, but these methods still suffer\nfrom errors in regions of low-texture, occlusions and reflections.\nConcurrently, deep learning for semantic segmentation has shown great progress\nin recent years. In this paper, we design a CNN architecture that combines\nthese two tasks to improve the quality and accuracy of disparity estimation\nwith the help of semantic segmentation. Specifically, we propose a network\nstructure in which these two tasks are highly coupled. One key novelty of this\napproach is the two-stage refinement process. Initial disparity estimates are\nrefined with an embedding learned from the semantic segmentation branch of the\nnetwork. The proposed model is trained using an unsupervised approach, in which\nimages from one half of the stereo pair are warped and compared against images\nfrom the other camera. Another key advantage of the proposed approach is that a\nsingle network is capable of outputting disparity estimates and semantic\nlabels. These outputs are of great use in autonomous vehicle operation; with\nreal-time constraints being key, such performance improvements increase the\nviability of driving applications. Experiments on KITTI and Cityscapes datasets\nshow that our model can achieve state-of-the-art results and that leveraging\nembedding learned from semantic segmentation improves the performance of\ndisparity estimation. \n\n"}
{"id": "1809.05852", "contents": "Title: Geometry-Consistent Generative Adversarial Networks for One-Sided\n  Unsupervised Domain Mapping Abstract: Unsupervised domain mapping aims to learn a function to translate domain X to\nY by a function GXY in the absence of paired examples. Finding the optimal GXY\nwithout paired data is an ill-posed problem, so appropriate constraints are\nrequired to obtain reasonable solutions. One of the most prominent constraints\nis cycle consistency, which enforces the translated image by GXY to be\ntranslated back to the input image by an inverse mapping GYX. While cycle\nconsistency requires the simultaneous training of GXY and GY X, recent studies\nhave shown that one-sided domain mapping can be achieved by preserving pairwise\ndistances between images. Although cycle consistency and distance preservation\nsuccessfully constrain the solution space, they overlook the special properties\nthat simple geometric transformations do not change the semantic structure of\nimages. Based on this special property, we develop a geometry-consistent\ngenerative adversarial network (GcGAN), which enables one-sided unsupervised\ndomain mapping. GcGAN takes the original image and its counterpart image\ntransformed by a predefined geometric transformation as inputs and generates\ntwo images in the new domain coupled with the corresponding\ngeometry-consistency constraint. The geometry-consistency constraint reduces\nthe space of possible solutions while keep the correct solutions in the search\nspace. Quantitative and qualitative comparisons with the baseline (GAN alone)\nand the state-of-the-art methods including CycleGAN and DistanceGAN demonstrate\nthe effectiveness of our method. \n\n"}
{"id": "1809.05962", "contents": "Title: Robust Adversarial Perturbation on Deep Proposal-based Models Abstract: Adversarial noises are useful tools to probe the weakness of deep learning\nbased computer vision algorithms. In this paper, we describe a robust\nadversarial perturbation (R-AP) method to attack deep proposal-based object\ndetectors and instance segmentation algorithms. Our method focuses on attacking\nthe common component in these algorithms, namely Region Proposal Network (RPN),\nto universally degrade their performance in a black-box fashion. To do so, we\ndesign a loss function that combines a label loss and a novel shape loss, and\noptimize it with respect to image using a gradient based iterative algorithm.\nEvaluations are performed on the MS COCO 2014 dataset for the adversarial\nattacking of 6 state-of-the-art object detectors and 2 instance segmentation\nalgorithms. Experimental results demonstrate the efficacy of the proposed\nmethod. \n\n"}
{"id": "1809.06719", "contents": "Title: Improvements on Hindsight Learning Abstract: Sparse reward problems are one of the biggest challenges in Reinforcement\nLearning. Goal-directed tasks are one such sparse reward problems where a\nreward signal is received only when the goal is reached. One promising way to\ntrain an agent to perform goal-directed tasks is to use Hindsight Learning\napproaches. In these approaches, even when an agent fails to reach the desired\ngoal, the agent learns to reach the goal it achieved instead. Doing this over\nmultiple trajectories while generalizing the policy learned from the achieved\ngoals, the agent learns a goal conditioned policy to reach any goal. One such\napproach is Hindsight Experience replay which uses an off-policy Reinforcement\nLearning algorithm to learn a goal conditioned policy. In this approach, a\nreplay of the past transitions happens in a uniformly random fashion. Another\napproach is to use a Hindsight version of the policy gradients to directly\nlearn a policy. In this work, we discuss different ways to replay past\ntransitions to improve learning in hindsight experience replay focusing on\nprioritized variants in particular. Also, we implement the Hindsight Policy\ngradient methods to robotic tasks. \n\n"}
{"id": "1809.07023", "contents": "Title: Removing the Feature Correlation Effect of Multiplicative Noise Abstract: Multiplicative noise, including dropout, is widely used to regularize deep\nneural networks (DNNs), and is shown to be effective in a wide range of\narchitectures and tasks. From an information perspective, we consider injecting\nmultiplicative noise into a DNN as training the network to solve the task with\nnoisy information pathways, which leads to the observation that multiplicative\nnoise tends to increase the correlation between features, so as to increase the\nsignal-to-noise ratio of information pathways. However, high feature\ncorrelation is undesirable, as it increases redundancy in representations. In\nthis work, we propose non-correlating multiplicative noise (NCMN), which\nexploits batch normalization to remove the correlation effect in a simple yet\neffective way. We show that NCMN significantly improves the performance of\nstandard multiplicative noise on image classification tasks, providing a better\nalternative to dropout for batch-normalized networks. Additionally, we present\na unified view of NCMN and shake-shake regularization, which explains the\nperformance gain of the latter. \n\n"}
{"id": "1809.07258", "contents": "Title: DPPy: Sampling DPPs with Python Abstract: Determinantal point processes (DPPs) are specific probability distributions\nover clouds of points that are used as models and computational tools across\nphysics, probability, statistics, and more recently machine learning. Sampling\nfrom DPPs is a challenge and therefore we present DPPy, a Python toolbox that\ngathers known exact and approximate sampling algorithms for both finite and\ncontinuous DPPs. The project is hosted on GitHub and equipped with an extensive\ndocumentation. \n\n"}
{"id": "1809.07402", "contents": "Title: Identifying Generalization Properties in Neural Networks Abstract: While it has not yet been proven, empirical evidence suggests that model\ngeneralization is related to local properties of the optima which can be\ndescribed via the Hessian. We connect model generalization with the local\nproperty of a solution under the PAC-Bayes paradigm. In particular, we prove\nthat model generalization ability is related to the Hessian, the higher-order\n\"smoothness\" terms characterized by the Lipschitz constant of the Hessian, and\nthe scales of the parameters. Guided by the proof, we propose a metric to score\nthe generalization capability of the model, as well as an algorithm that\noptimizes the perturbed model accordingly. \n\n"}
{"id": "1809.07436", "contents": "Title: Deep Generative Classifiers for Thoracic Disease Diagnosis with Chest\n  X-ray Images Abstract: Thoracic diseases are very serious health problems that plague a large number\nof people. Chest X-ray is currently one of the most popular methods to diagnose\nthoracic diseases, playing an important role in the healthcare workflow.\nHowever, reading the chest X-ray images and giving an accurate diagnosis remain\nchallenging tasks for expert radiologists. With the success of deep learning in\ncomputer vision, a growing number of deep neural network architectures were\napplied to chest X-ray image classification. However, most of the previous deep\nneural network classifiers were based on deterministic architectures which are\nusually very noise-sensitive and are likely to aggravate the overfitting issue.\nIn this paper, to make a deep architecture more robust to noise and to reduce\noverfitting, we propose using deep generative classifiers to automatically\ndiagnose thorax diseases from the chest X-ray images. Unlike the traditional\ndeterministic classifier, a deep generative classifier has a distribution\nmiddle layer in the deep neural network. A sampling layer then draws a random\nsample from the distribution layer and input it to the following layer for\nclassification. The classifier is generative because the class label is\ngenerated from samples of a related distribution. Through training the model\nwith a certain amount of randomness, the deep generative classifiers are\nexpected to be robust to noise and can reduce overfitting and then achieve good\nperformances. We implemented our deep generative classifiers based on a number\nof well-known deterministic neural network architectures, and tested our models\non the chest X-ray14 dataset. The results demonstrated the superiority of deep\ngenerative classifiers compared with the corresponding deep deterministic\nclassifiers. \n\n"}
{"id": "1809.07759", "contents": "Title: Implementing Adaptive Separable Convolution for Video Frame\n  Interpolation Abstract: As Deep Neural Networks are becoming more popular, much of the attention is\nbeing devoted to Computer Vision problems that used to be solved with more\ntraditional approaches. Video frame interpolation is one of such challenges\nthat has seen new research involving various techniques in deep learning. In\nthis paper, we replicate the work of Niklaus et al. on Adaptive Separable\nConvolution, which claims high quality results on the video frame interpolation\ntask. We apply the same network structure trained on a smaller dataset and\nexperiment with various different loss functions, in order to determine the\noptimal approach in data-scarce scenarios. The best resulting model is still\nable to provide visually pleasing videos, although achieving lower evaluation\nscores. \n\n"}
{"id": "1809.08541", "contents": "Title: DT-LET: Deep Transfer Learning by Exploring where to Transfer Abstract: Previous transfer learning methods based on deep network assume the knowledge\nshould be transferred between the same hidden layers of the source domain and\nthe target domains. This assumption doesn't always hold true, especially when\nthe data from the two domains are heterogeneous with different resolutions. In\nsuch case, the most suitable numbers of layers for the source domain data and\nthe target domain data would differ. As a result, the high level knowledge from\nthe source domain would be transferred to the wrong layer of target domain.\nBased on this observation, \"where to transfer\" proposed in this paper should be\na novel research frontier. We propose a new mathematic model named DT-LET to\nsolve this heterogeneous transfer learning problem. In order to select the best\nmatching of layers to transfer knowledge, we define specific loss function to\nestimate the corresponding relationship between high-level features of data in\nthe source domain and the target domain. To verify this proposed cross-layer\nmodel, experiments for two cross-domain recognition/classification tasks are\nconducted, and the achieved superior results demonstrate the necessity of layer\ncorrespondence searching. \n\n"}
{"id": "1809.08556", "contents": "Title: Self Attention Grid for Person Re-Identification Abstract: In this paper, we present an attention mechanism scheme to improve person\nre-identification task. Inspired by biology, we propose Self Attention Grid\n(SAG) to discover the most informative parts from a high-resolution image using\nits internal representation. In particular, given an input image, the proposed\nmodel is fed with two copies of the same image and consists of two branches.\nThe upper branch processes the high-resolution image and learns high\ndimensional feature representation while the lower branch processes the\nlow-resolution image and learn a filtering attention grid. We apply a max\nfilter operation to non-overlapping sub-regions on the high feature\nrepresentation before element-wise multiplied with the output of the second\nbranch. The feature maps of the second branch are subsequently weighted to\nreflect the importance of each patch of the grid using a softmax operation. Our\nattention module helps the network learn the most discriminative visual\nfeatures of multiple image regions and is specifically optimized to attend\nfeature representation at different levels. Extensive experiments on three\nlarge-scale datasets show that our self-attention mechanism significantly\nimproves the baseline model and outperforms various state-of-art models by a\nlarge margin. \n\n"}
{"id": "1809.09307", "contents": "Title: Utilizing Class Information for Deep Network Representation Shaping Abstract: Statistical characteristics of deep network representations, such as sparsity\nand correlation, are known to be relevant to the performance and\ninterpretability of deep learning. When a statistical characteristic is\ndesired, often an adequate regularizer can be designed and applied during the\ntraining phase. Typically, such a regularizer aims to manipulate a statistical\ncharacteristic over all classes together. For classification tasks, however, it\nmight be advantageous to enforce the desired characteristic per class such that\ndifferent classes can be better distinguished. Motivated by the idea, we design\ntwo class-wise regularizers that explicitly utilize class information:\nclass-wise Covariance Regularizer (cw-CR) and class-wise Variance Regularizer\n(cw-VR). cw-CR targets to reduce the covariance of representations calculated\nfrom the same class samples for encouraging feature independence. cw-VR is\nsimilar, but variance instead of covariance is targeted to improve feature\ncompactness. For the sake of completeness, their counterparts without using\nclass information, Covariance Regularizer (CR) and Variance Regularizer (VR),\nare considered together. The four regularizers are conceptually simple and\ncomputationally very efficient, and the visualization shows that the\nregularizers indeed perform distinct representation shaping. In terms of\nclassification performance, significant improvements over the baseline and\nL1/L2 weight regularization methods were found for 21 out of 22 tasks over\npopular benchmark datasets. In particular, cw-VR achieved the best performance\nfor 13 tasks including ResNet-32/110. \n\n"}
{"id": "1809.09501", "contents": "Title: Anderson Acceleration for Reinforcement Learning Abstract: Anderson acceleration is an old and simple method for accelerating the\ncomputation of a fixed point. However, as far as we know and quite\nsurprisingly, it has never been applied to dynamic programming or reinforcement\nlearning. In this paper, we explain briefly what Anderson acceleration is and\nhow it can be applied to value iteration, this being supported by preliminary\nexperiments showing a significant speed up of convergence, that we critically\ndiscuss. We also discuss how this idea could be applied more generally to\n(deep) reinforcement learning. \n\n"}
{"id": "1809.09607", "contents": "Title: Semantic and structural image segmentation for prosthetic vision Abstract: Prosthetic vision is being applied to partially recover the retinal\nstimulation of visually impaired people. However, the phosphenic images\nproduced by the implants have very limited information bandwidth due to the\npoor resolution and lack of color or contrast. The ability of object\nrecognition and scene understanding in real environments is severely restricted\nfor prosthetic users. Computer vision can play a key role to overcome the\nlimitations and to optimize the visual information in the simulated prosthetic\nvision, improving the amount of information that is presented. We present a new\napproach to build a schematic representation of indoor environments for\nphosphene images. The proposed method combines a variety of convolutional\nneural networks for extracting and conveying relevant information about the\nscene such as structural informative edges of the environment and silhouettes\nof segmented objects. Experiments were conducted with normal sighted subjects\nwith a Simulated Prosthetic Vision system. The results show good accuracy for\nobject recognition and room identification tasks for indoor scenes using the\nproposed approach, compared to other image processing methods. \n\n"}
{"id": "1809.09853", "contents": "Title: Stochastic Second-order Methods for Non-convex Optimization with Inexact\n  Hessian and Gradient Abstract: Trust region and cubic regularization methods have demonstrated good\nperformance in small scale non-convex optimization, showing the ability to\nescape from saddle points. Each iteration of these methods involves computation\nof gradient, Hessian and function value in order to obtain the search direction\nand adjust the radius or cubic regularization parameter. However, exactly\ncomputing those quantities are too expensive in large-scale problems such as\ntraining deep networks. In this paper, we study a family of stochastic trust\nregion and cubic regularization methods when gradient, Hessian and function\nvalues are computed inexactly, and show the iteration complexity to achieve\n$\\epsilon$-approximate second-order optimality is in the same order with\nprevious work for which gradient and function values are computed exactly. The\nmild conditions on inexactness can be achieved in finite-sum minimization using\nrandom sampling. We show the algorithm performs well on training convolutional\nneural networks compared with previous second-order methods. \n\n"}
{"id": "1809.10201", "contents": "Title: Visual Diver Recognition for Underwater Human-Robot Collaboration Abstract: This paper presents an approach for autonomous underwater robots to visually\ndetect and identify divers. The proposed approach enables an autonomous\nunderwater robot to detect multiple divers in a visual scene and distinguish\nbetween them. Such methods are useful for robots to identify a human leader,\nfor example, in multi-human/robot teams where only designated individuals are\nallowed to command or lean a team of robots. Initial diver identification is\nperformed using the Faster R-CNN algorithm with a region proposal network which\nproduces bounding boxes around the divers' locations. Subsequently, a suite of\nspatial and frequency domain descriptors are extracted from the bounding boxes\nto create a feature vector. A K-Means clustering algorithm, with k set to the\nnumber of detected bounding boxes, thereafter identifies the detected divers\nbased on these feature vectors. We evaluate the performance of the proposed\napproach on video footage of divers swimming in front of a mobile robot and\ndemonstrate its accuracy. \n\n"}
{"id": "1809.10203", "contents": "Title: Multi-Scale Fully Convolutional Network for Cardiac Left Ventricle\n  Segmentation Abstract: The morphological structure of left ventricle segmented from cardiac magnetic\nresonance images can be used to calculate key clinical parameters, and it is of\ngreat significance to the accurate and efficient diagnosis of cardiovascular\ndiseases. Compared with traditional methods, the segmentation algorithms based\non fully convolutional neural network greatly improve the accuracy of semantic\nsegmentation. For the problem of left ventricular segmentation, a new fully\nconvolutional neural network structure named MS-FCN is proposed in this paper.\nThe MS-FCN network employs a multi-scale pooling module to ensure that the\nnetwork maximises the feature extraction ability and uses a dense connectivity\ndecoder to refine the boundaries of the object. Based on the Sunnybrook cine-MR\ndataset provided by the MICCAI 2009 challenge, numerical experiments\ndemonstrate that our proposed model has obtained state-of-the-art segmentation\nresults: the Dice score of our method reaches 0.93 on the endocardium, and 0.96\non the epicardium. \n\n"}
{"id": "1809.10243", "contents": "Title: Segmentation of Skin Lesions and their Attributes Using Multi-Scale\n  Convolutional Neural Networks and Domain Specific Augmentations Abstract: Computer-aided diagnosis systems for classification of different type of skin\nlesions have been an active field of research in recent decades. It has been\nshown that introducing lesions and their attributes masks into lesion\nclassification pipeline can greatly improve the performance. In this paper, we\npropose a framework by incorporating transfer learning for segmenting lesions\nand their attributes based on the convolutional neural networks. The proposed\nframework is based on the encoder-decoder architecture which utilizes a variety\nof pre-trained networks in the encoding path and generates the prediction map\nby combining multi-scale information in decoding path using a pyramid pooling\nmanner. To address the lack of training data and increase the proposed model\ngeneralization, an extensive set of novel domain-specific augmentation routines\nhave been applied to simulate the real variations in dermoscopy images.\nFinally, by performing broad experiments on three different data sets obtained\nfrom International Skin Imaging Collaboration archive (ISIC2016, ISIC2017, and\nISIC2018 challenges data sets), we show that the proposed method outperforms\nother state-of-the-art approaches for ISIC2016 and ISIC2017 segmentation task\nand achieved the first rank on the leader-board of ISIC2018 attribute detection\ntask. \n\n"}
{"id": "1809.10711", "contents": "Title: Multi-Scale Recursive and Perception-Distortion Controllable Image\n  Super-Resolution Abstract: We describe our solution for the PIRM Super-Resolution Challenge 2018 where\nwe achieved the 2nd best perceptual quality for average RMSE<=16, 5th best for\nRMSE<=12.5, and 7th best for RMSE<=11.5. We modify a recently proposed\nMulti-Grid Back-Projection (MGBP) architecture to work as a generative system\nwith an input parameter that can control the amount of artificial details in\nthe output. We propose a discriminator for adversarial training with the\nfollowing novel properties: it is multi-scale that resembles a progressive-GAN;\nit is recursive that balances the architecture of the generator; and it\nincludes a new layer to capture significant statistics of natural images.\nFinally, we propose a training strategy that avoids conflicts between\nreconstruction and perceptual losses. Our configuration uses only 281k\nparameters and upscales each image of the competition in 0.2s in average. \n\n"}
{"id": "1809.10732", "contents": "Title: Multimodal Trajectory Predictions for Autonomous Driving using Deep\n  Convolutional Networks Abstract: Autonomous driving presents one of the largest problems that the robotics and\nartificial intelligence communities are facing at the moment, both in terms of\ndifficulty and potential societal impact. Self-driving vehicles (SDVs) are\nexpected to prevent road accidents and save millions of lives while improving\nthe livelihood and life quality of many more. However, despite large interest\nand a number of industry players working in the autonomous domain, there still\nremains more to be done in order to develop a system capable of operating at a\nlevel comparable to best human drivers. One reason for this is high uncertainty\nof traffic behavior and large number of situations that an SDV may encounter on\nthe roads, making it very difficult to create a fully generalizable system. To\nensure safe and efficient operations, an autonomous vehicle is required to\naccount for this uncertainty and to anticipate a multitude of possible\nbehaviors of traffic actors in its surrounding. We address this critical\nproblem and present a method to predict multiple possible trajectories of\nactors while also estimating their probabilities. The method encodes each\nactor's surrounding context into a raster image, used as input by deep\nconvolutional networks to automatically derive relevant features for the task.\nFollowing extensive offline evaluation and comparison to state-of-the-art\nbaselines, the method was successfully tested on SDVs in closed-course tests. \n\n"}
{"id": "1810.00461", "contents": "Title: 3D-PSRNet: Part Segmented 3D Point Cloud Reconstruction From a Single\n  Image Abstract: We propose a mechanism to reconstruct part annotated 3D point clouds of\nobjects given just a single input image. We demonstrate that jointly training\nfor both reconstruction and segmentation leads to improved performance in both\nthe tasks, when compared to training for each task individually. The key idea\nis to propagate information from each task so as to aid the other during the\ntraining procedure. Towards this end, we introduce a location-aware\nsegmentation loss in the training regime. We empirically show the effectiveness\nof the proposed loss in generating more faithful part reconstructions while\nalso improving segmentation accuracy. We thoroughly evaluate the proposed\napproach on different object categories from the ShapeNet dataset to obtain\nimproved results in reconstruction as well as segmentation. \n\n"}
{"id": "1810.00500", "contents": "Title: One Network to Solve All ROIs: Deep Learning CT for Any ROI using\n  Differentiated Backprojection Abstract: Computed tomography for region-of-interest (ROI) reconstruction has\nadvantages of reducing X-ray radiation dose and using a small detector.\nHowever, standard analytic reconstruction methods suffer from severe cupping\nartifacts, and existing model-based iterative reconstruction methods require\nextensive computations. Recently, we proposed a deep neural network to learn\nthe cupping artifact, but the network is not well generalized for different\nROIs due to the singularities in the corrupted images. Therefore, there is an\nincreasing demand for a neural network that works well for any ROI sizes. In\nthis paper, two types of neural networks are designed. The first type learns\nROI size-specific cupping artifacts from the analytic reconstruction images,\nwhereas the second type network is to learn to invert the finite Hilbert\ntransform from the truncated differentiated backprojection (DBP) data. Their\ngeneralizability for any ROI sizes is then examined. Experimental results show\nthat the new type of neural network significantly outperforms the existing\niterative methods for any ROI size in spite of significantly reduced run-time\ncomplexity. Since the proposed method consistently surpasses existing methods\nfor any ROIs, it can be used as a general CT reconstruction engine for many\npractical applications without compromising possible detector truncation. \n\n"}
{"id": "1810.00602", "contents": "Title: Privado: Practical and Secure DNN Inference with Enclaves Abstract: Cloud providers are extending support for trusted hardware primitives such as\nIntel SGX. Simultaneously, the field of deep learning is seeing enormous\ninnovation as well as an increase in adoption. In this paper, we ask a timely\nquestion: \"Can third-party cloud services use Intel SGX enclaves to provide\npractical, yet secure DNN Inference-as-a-service?\" We first demonstrate that\nDNN models executing inside enclaves are vulnerable to access pattern based\nattacks. We show that by simply observing access patterns, an attacker can\nclassify encrypted inputs with 97% and 71% attack accuracy for MNIST and\nCIFAR10 datasets on models trained to achieve 99% and 79% original accuracy\nrespectively. This motivates the need for PRIVADO, a system we have designed\nfor secure, easy-to-use, and performance efficient inference-as-a-service.\nPRIVADO is input-oblivious: it transforms any deep learning framework that is\nwritten in C/C++ to be free of input-dependent access patterns thus eliminating\nthe leakage. PRIVADO is fully-automated and has a low TCB: with zero developer\neffort, given an ONNX description of a model, it generates compact and\nenclave-compatible code which can be deployed on an SGX cloud platform. PRIVADO\nincurs low performance overhead: we use PRIVADO with Torch framework and show\nits overhead to be 17.18% on average on 11 different contemporary neural\nnetworks. \n\n"}
{"id": "1810.01829", "contents": "Title: Weighted Sigmoid Gate Unit for an Activation Function of Deep Neural\n  Network Abstract: An activation function has crucial role in a deep neural network.\n  A simple rectified linear unit (ReLU) are widely used for the activation\nfunction.\n  In this paper, a weighted sigmoid gate unit (WiG) is proposed as the\nactivation function.\n  The proposed WiG consists of a multiplication of inputs and the weighted\nsigmoid gate.\n  It is shown that the WiG includes the ReLU and same activation functions as a\nspecial case.\n  Many activation functions have been proposed to overcome the performance of\nthe ReLU.\n  In the literature, the performance is mainly evaluated with an object\nrecognition task.\n  The proposed WiG is evaluated with the object recognition task and the image\nrestoration task.\n  Then, the expeirmental comparisons demonstrate the proposed WiG overcomes the\nexisting activation functions including the ReLU. \n\n"}
{"id": "1810.03077", "contents": "Title: DeepGeo: Photo Localization with Deep Neural Network Abstract: In this paper we address the task of determining the geographical location of\nan image, a pertinent problem in learning and computer vision. This research\nwas inspired from playing GeoGuessr, a game that tests a humans' ability to\nlocalize themselves using just images of their surroundings. In particular, we\nwish to investigate how geographical, ecological and man-made features\ngeneralize for random location prediction. This is framed as a classification\nproblem: given images sampled from the USA, the most-probable state among 50 is\npredicted. Previous work uses models extensively trained on large, unfiltered\nonline datasets that are primed towards specific locations. To this end, we\ncreate (and open-source) the 50States10K dataset - with 0.5 million Google\nStreet View images of the country. A deep neural network based on the ResNet\narchitecture is trained, and four different strategies of incorporating\nlow-level cardinality information are presented. This model achieves an\naccuracy 20 times better than chance on a test dataset, which rises to 71.87%\nwhen taking the best of top-5 guesses. The network also beats human subjects in\n4 out of 5 rounds of GeoGuessr. \n\n"}
{"id": "1810.03292", "contents": "Title: Sanity Checks for Saliency Maps Abstract: Saliency methods have emerged as a popular tool to highlight features in an\ninput deemed relevant for the prediction of a learned model. Several saliency\nmethods have been proposed, often guided by visual appeal on image data. In\nthis work, we propose an actionable methodology to evaluate what kinds of\nexplanations a given method can and cannot provide. We find that reliance,\nsolely, on visual assessment can be misleading. Through extensive experiments\nwe show that some existing saliency methods are independent both of the model\nand of the data generating process. Consequently, methods that fail the\nproposed tests are inadequate for tasks that are sensitive to either data or\nmodel, such as, finding outliers in the data, explaining the relationship\nbetween inputs and outputs that the model learned, and debugging the model. We\ninterpret our findings through an analogy with edge detection in images, a\ntechnique that requires neither training data nor model. Theory in the case of\na linear model and a single-layer convolutional neural network supports our\nexperimental findings. \n\n"}
{"id": "1810.03307", "contents": "Title: Local Explanation Methods for Deep Neural Networks Lack Sensitivity to\n  Parameter Values Abstract: Explaining the output of a complicated machine learning model like a deep\nneural network (DNN) is a central challenge in machine learning. Several\nproposed local explanation methods address this issue by identifying what\ndimensions of a single input are most responsible for a DNN's output. The goal\nof this work is to assess the sensitivity of local explanations to DNN\nparameter values. Somewhat surprisingly, we find that DNNs with\nrandomly-initialized weights produce explanations that are both visually and\nquantitatively similar to those produced by DNNs with learned weights. Our\nconjecture is that this phenomenon occurs because these explanations are\ndominated by the lower level features of a DNN, and that a DNN's architecture\nprovides a strong prior which significantly affects the representations learned\nat these lower layers. NOTE: This work is now subsumed by our recent\nmanuscript, Sanity Checks for Saliency Maps (to appear NIPS 2018), where we\nexpand on findings and address concerns raised in Sundararajan et. al. (2018). \n\n"}
{"id": "1810.03756", "contents": "Title: SPIGAN: Privileged Adversarial Learning from Simulation Abstract: Deep Learning for Computer Vision depends mainly on the source of\nsupervision.Photo-realistic simulators can generate large-scale automatically\nlabeled syntheticdata, but introduce a domain gap negatively impacting\nperformance. We propose anew unsupervised domain adaptation algorithm, called\nSPIGAN, relying on Sim-ulator Privileged Information (PI) and Generative\nAdversarial Networks (GAN).We use internal data from the simulator as PI during\nthe training of a target tasknetwork. We experimentally evaluate our approach\non semantic segmentation. Wetrain the networks on real-world Cityscapes and\nVistas datasets, using only unla-beled real-world images and synthetic labeled\ndata with z-buffer (depth) PI fromthe SYNTHIA dataset. Our method improves over\nno adaptation and state-of-the-art unsupervised domain adaptation techniques. \n\n"}
{"id": "1810.03871", "contents": "Title: Conditional Generative Refinement Adversarial Networks for Unbalanced\n  Medical Image Semantic Segmentation Abstract: We propose a new generative adversarial architecture to mitigate imbalance\ndata problem in medical image semantic segmentation where the majority of\npixels belongs to a healthy region and few belong to lesion or non-health\nregion. A model trained with imbalanced data tends to bias toward healthy data\nwhich is not desired in clinical applications and predicted outputs by these\nnetworks have high precision and low sensitivity. We propose a new conditional\ngenerative refinement network with three components: a generative, a\ndiscriminative, and a refinement network to mitigate unbalanced data problem\nthrough ensemble learning. The generative network learns to a segment at the\npixel level by getting feedback from the discriminative network according to\nthe true positive and true negative maps. On the other hand, the refinement\nnetwork learns to predict the false positive and the false negative masks\nproduced by the generative network that has significant value, especially in\nmedical application. The final semantic segmentation masks are then composed by\nthe output of the three networks. The proposed architecture shows\nstate-of-the-art results on LiTS-2017 for liver lesion segmentation, and two\nmicroscopic cell segmentation datasets MDA231, PhC-HeLa. We have achieved\ncompetitive results on BraTS-2017 for brain tumour segmentation. \n\n"}
{"id": "1810.03969", "contents": "Title: A Generative Adversarial Model for Right Ventricle Segmentation Abstract: The clinical management of several cardiovascular conditions, such as\npulmonary hypertension, require the assessment of the right ventricular (RV)\nfunction. This work addresses the fully automatic and robust access to one of\nthe key RV biomarkers, its ejection fraction, from the gold standard imaging\nmodality, MRI. The problem becomes the accurate segmentation of the RV blood\npool from cine MRI sequences. This work proposes a solution based on Fully\nConvolutional Neural Networks (FCNN), where our first contribution is the\noptimal combination of three concepts (the convolution Gated Recurrent Units\n(GRU), the Generative Adversarial Networks (GAN), and the L1 loss function)\nthat achieves an improvement of 0.05 and 3.49 mm in Dice Index and Hausdorff\nDistance respectively with respect to the baseline FCNN. This improvement is\nthen doubled by our second contribution, the ROI-GAN, that sets two GANs to\ncooperate working at two fields of view of the image, its full resolution and\nthe region of interest (ROI). Our rationale here is to better guide the FCNN\nlearning by combining global (full resolution) and local Region Of Interest\n(ROI) features. The study is conducted in a large in-house dataset of $\\sim$\n23.000 segmented MRI slices, and its generality is verified in a publicly\navailable dataset. \n\n"}
{"id": "1810.03982", "contents": "Title: Deep Decoder: Concise Image Representations from Untrained\n  Non-convolutional Networks Abstract: Deep neural networks, in particular convolutional neural networks, have\nbecome highly effective tools for compressing images and solving inverse\nproblems including denoising, inpainting, and reconstruction from few and noisy\nmeasurements. This success can be attributed in part to their ability to\nrepresent and generate natural images well. Contrary to classical tools such as\nwavelets, image-generating deep neural networks have a large number of\nparameters---typically a multiple of their output dimension---and need to be\ntrained on large datasets. In this paper, we propose an untrained simple image\nmodel, called the deep decoder, which is a deep neural network that can\ngenerate natural images from very few weight parameters. The deep decoder has a\nsimple architecture with no convolutions and fewer weight parameters than the\noutput dimensionality. This underparameterization enables the deep decoder to\ncompress images into a concise set of network weights, which we show is on par\nwith wavelet-based thresholding. Further, underparameterization provides a\nbarrier to overfitting, allowing the deep decoder to have state-of-the-art\nperformance for denoising. The deep decoder is simple in the sense that each\nlayer has an identical structure that consists of only one upsampling unit,\npixel-wise linear combination of channels, ReLU activation, and channelwise\nnormalization. This simplicity makes the network amenable to theoretical\nanalysis, and it sheds light on the aspects of neural networks that enable them\nto form effective signal representations. \n\n"}
{"id": "1810.04020", "contents": "Title: A Comprehensive Survey of Deep Learning for Image Captioning Abstract: Generating a description of an image is called image captioning. Image\ncaptioning requires to recognize the important objects, their attributes and\ntheir relationships in an image. It also needs to generate syntactically and\nsemantically correct sentences. Deep learning-based techniques are capable of\nhandling the complexities and challenges of image captioning. In this survey\npaper, we aim to present a comprehensive review of existing deep learning-based\nimage captioning techniques. We discuss the foundation of the techniques to\nanalyze their performances, strengths and limitations. We also discuss the\ndatasets and the evaluation metrics popularly used in deep learning based\nautomatic image captioning. \n\n"}
{"id": "1810.04240", "contents": "Title: Deep Neural Network Compression for Aircraft Collision Avoidance Systems Abstract: One approach to designing decision making logic for an aircraft collision\navoidance system frames the problem as a Markov decision process and optimizes\nthe system using dynamic programming. The resulting collision avoidance\nstrategy can be represented as a numeric table. This methodology has been used\nin the development of the Airborne Collision Avoidance System X (ACAS X) family\nof collision avoidance systems for manned and unmanned aircraft, but the high\ndimensionality of the state space leads to very large tables. To improve\nstorage efficiency, a deep neural network is used to approximate the table.\nWith the use of an asymmetric loss function and a gradient descent algorithm,\nthe parameters for this network can be trained to provide accurate estimates of\ntable values while preserving the relative preferences of the possible\nadvisories for each state. By training multiple networks to represent\nsubtables, the network also decreases the required runtime for computing the\ncollision avoidance advisory. Simulation studies show that the network improves\nthe safety and efficiency of the collision avoidance system. Because only the\nnetwork parameters need to be stored, the required storage space is reduced by\na factor of 1000, enabling the collision avoidance system to operate using\ncurrent avionics systems. \n\n"}
{"id": "1810.04250", "contents": "Title: Bird Species Classification using Transfer Learning with Multistage\n  Training Abstract: Bird species classification has received more and more attention in the field\nof computer vision, for its promising applications in biology and environmental\nstudies. Recognizing bird species is difficult due to the challenges of\ndiscriminative region localization and fine-grained feature learning. In this\npaper, we have introduced a Transfer learning based method with multistage\ntraining. We have used both Pre-Trained Mask-RCNN and an ensemble model\nconsisting of Inception Nets (InceptionV3 & InceptionResNetV2 ) to get\nlocalization and species of the bird from the images respectively. Our final\nmodel achieves an F1 score of 0.5567 or 55.67 % on the dataset provided in CVIP\n2018 Challenge. \n\n"}
{"id": "1810.04274", "contents": "Title: Survival prediction using ensemble tumor segmentation and transfer\n  learning Abstract: Segmenting tumors and their subregions is a challenging task as demonstrated\nby the annual BraTS challenge. Moreover, predicting the survival of the patient\nusing mainly imaging features, while being a desirable outcome to evaluate the\ntreatment of the patient, it is also a difficult task. In this paper, we\npresent a cascaded pipeline to segment the tumor and its subregions and then we\nuse these results and other clinical features together with image features\ncoming from a pretrained VGG-16 network to predict the survival of the patient.\nPreliminary results with the training and validation dataset show a promising\nstart in terms of segmentation, while the prediction values could be improved\nwith further testing on the feature extraction part of the network. \n\n"}
{"id": "1810.04511", "contents": "Title: Interpretable Spatio-temporal Attention for Video Action Recognition Abstract: Inspired by the observation that humans are able to process videos\nefficiently by only paying attention where and when it is needed, we propose an\ninterpretable and easy plug-in spatial-temporal attention mechanism for video\naction recognition. For spatial attention, we learn a saliency mask to allow\nthe model to focus on the most salient parts of the feature maps. For temporal\nattention, we employ a convolutional LSTM based attention mechanism to identify\nthe most relevant frames from an input video. Further, we propose a set of\nregularizers to ensure that our attention mechanism attends to coherent regions\nin space and time. Our model not only improves video action recognition\naccuracy, but also localizes discriminative regions both spatially and\ntemporally, despite being trained in a weakly-supervised manner with only\nclassification labels (no bounding box labels or time frame temporal labels).\nWe evaluate our approach on several public video action recognition datasets\nwith ablation studies. Furthermore, we quantitatively and qualitatively\nevaluate our model's ability to localize discriminative regions spatially and\ncritical frames temporally. Experimental results demonstrate the efficacy of\nour approach, showing superior or comparable accuracy with the state-of-the-art\nmethods while increasing model interpretability. \n\n"}
{"id": "1810.05017", "contents": "Title: One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL Abstract: Humans are experts at high-fidelity imitation -- closely mimicking a\ndemonstration, often in one attempt. Humans use this ability to quickly solve a\ntask instance, and to bootstrap learning of new tasks. Achieving these\nabilities in autonomous agents is an open problem. In this paper, we introduce\nan off-policy RL algorithm (MetaMimic) to narrow this gap. MetaMimic can learn\nboth (i) policies for high-fidelity one-shot imitation of diverse novel skills,\nand (ii) policies that enable the agent to solve tasks more efficiently than\nthe demonstrators. MetaMimic relies on the principle of storing all experiences\nin a memory and replaying these to learn massive deep neural network policies\nby off-policy RL. This paper introduces, to the best of our knowledge, the\nlargest existing neural networks for deep RL and shows that larger networks\nwith normalization are needed to achieve one-shot high-fidelity imitation on a\nchallenging manipulation task. The results also show that both types of policy\ncan be learned from vision, in spite of the task rewards being sparse, and\nwithout access to demonstrator actions. \n\n"}
{"id": "1810.05206", "contents": "Title: MeshAdv: Adversarial Meshes for Visual Recognition Abstract: Highly expressive models such as deep neural networks (DNNs) have been widely\napplied to various applications. However, recent studies show that DNNs are\nvulnerable to adversarial examples, which are carefully crafted inputs aiming\nto mislead the predictions. Currently, the majority of these studies have\nfocused on perturbation added to image pixels, while such manipulation is not\nphysically realistic. Some works have tried to overcome this limitation by\nattaching printable 2D patches or painting patterns onto surfaces, but can be\npotentially defended because 3D shape features are intact. In this paper, we\npropose meshAdv to generate \"adversarial 3D meshes\" from objects that have rich\nshape features but minimal textural variation. To manipulate the shape or\ntexture of the objects, we make use of a differentiable renderer to compute\naccurate shading on the shape and propagate the gradient. Extensive experiments\nshow that the generated 3D meshes are effective in attacking both classifiers\nand object detectors. We evaluate the attack under different viewpoints. In\naddition, we design a pipeline to perform black-box attack on a photorealistic\nrenderer with unknown rendering parameters. \n\n"}
{"id": "1810.05358", "contents": "Title: Efficient architecture for deep neural networks with heterogeneous\n  sensitivity Abstract: This work presents a neural network that consists of nodes with heterogeneous\nsensitivity. Each node in a network is assigned a variable that determines the\nsensitivity with which it learns to perform a given task. The network is\ntrained by a constrained optimization that maximizes the sparsity of the\nsensitivity variables while ensuring the network's performance. As a result,\nthe network learns to perform a given task using only a small number of\nsensitive nodes. Insensitive nodes, the nodes with zero sensitivity, can be\nremoved from a trained network to obtain a computationally efficient network.\nRemoving zero-sensitivity nodes has no effect on the network's performance\nbecause the network has already been trained to perform the task without them.\nThe regularization parameter used to solve the optimization problem is found\nsimultaneously during the training of networks. To validate our approach, we\ndesign networks with computationally efficient architectures for various tasks\nsuch as autoregression, object recognition, facial expression recognition, and\nobject detection using various datasets. In our experiments, the networks\ndesigned by the proposed method provide the same or higher performance but with\nfar less computational complexity. \n\n"}
{"id": "1810.05444", "contents": "Title: Cats or CAT scans: transfer learning from natural or medical image\n  source datasets? Abstract: Transfer learning is a widely used strategy in medical image analysis.\nInstead of only training a network with a limited amount of data from the\ntarget task of interest, we can first train the network with other, potentially\nlarger source datasets, creating a more robust model. The source datasets do\nnot have to be related to the target task. For a classification task in lung CT\nimages, we could use both head CT images, or images of cats, as the source.\nWhile head CT images appear more similar to lung CT images, the number and\ndiversity of cat images might lead to a better model overall. In this survey we\nreview a number of papers that have performed similar comparisons. Although the\nanswer to which strategy is best seems to be \"it depends\", we discuss a number\nof research directions we need to take as a community, to gain more\nunderstanding of this topic. \n\n"}
{"id": "1810.05835", "contents": "Title: Characterising epithelial tissues using persistent entropy Abstract: In this paper, we apply persistent entropy, a novel topological statistic,\nfor characterization of images of epithelial tissues. We have found out that\npersistent entropy is able to summarize topological and geometric information\nencoded by \\alpha-complexes and persistent homology. After using some\nstatistical tests, we can guarantee the existence of significant differences in\nthe studied tissues. \n\n"}
{"id": "1810.05934", "contents": "Title: A System for Massively Parallel Hyperparameter Tuning Abstract: Modern learning models are characterized by large hyperparameter spaces and\nlong training times. These properties, coupled with the rise of parallel\ncomputing and the growing demand to productionize machine learning workloads,\nmotivate the need to develop mature hyperparameter optimization functionality\nin distributed computing settings. We address this challenge by first\nintroducing a simple and robust hyperparameter optimization algorithm called\nASHA, which exploits parallelism and aggressive early-stopping to tackle\nlarge-scale hyperparameter optimization problems. Our extensive empirical\nresults show that ASHA outperforms existing state-of-the-art hyperparameter\noptimization methods; scales linearly with the number of workers in distributed\nsettings; and is suitable for massive parallelism, as demonstrated on a task\nwith 500 workers. We then describe several design decisions we encountered,\nalong with our associated solutions, when integrating ASHA in Determined AI's\nend-to-end production-quality machine learning system that offers\nhyperparameter tuning as a service. \n\n"}
{"id": "1810.05943", "contents": "Title: Varifocal-Net: A Chromosome Classification Approach using Deep\n  Convolutional Networks Abstract: Chromosome classification is critical for karyotyping in abnormality\ndiagnosis. To expedite the diagnosis, we present a novel method named\nVarifocal-Net for simultaneous classification of chromosome's type and polarity\nusing deep convolutional networks. The approach consists of one global-scale\nnetwork (G-Net) and one local-scale network (L-Net). It follows three stages.\nThe first stage is to learn both global and local features. We extract global\nfeatures and detect finer local regions via the G-Net. By proposing a varifocal\nmechanism, we zoom into local parts and extract local features via the L-Net.\nResidual learning and multi-task learning strategies are utilized to promote\nhigh-level feature extraction. The detection of discriminative local parts is\nfulfilled by a localization subnet of the G-Net, whose training process\ninvolves both supervised and weakly-supervised learning. The second stage is to\nbuild two multi-layer perceptron classifiers that exploit features of both two\nscales to boost classification performance. The third stage is to introduce a\ndispatch strategy of assigning each chromosome to a type within each patient\ncase, by utilizing the domain knowledge of karyotyping. Evaluation results from\n1909 karyotyping cases showed that the proposed Varifocal-Net achieved the\nhighest accuracy per patient case (%) 99.2 for both type and polarity tasks. It\noutperformed state-of-the-art methods, demonstrating the effectiveness of our\nvarifocal mechanism, multi-scale feature ensemble, and dispatch strategy. The\nproposed method has been applied to assist practical karyotype diagnosis. \n\n"}
{"id": "1810.07322", "contents": "Title: Functionality-Oriented Convolutional Filter Pruning Abstract: The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As\nsignificant redundancies inevitably present in such a structure, many works\nhave been proposed to prune the convolutional filters for computation cost\nreduction. Although extremely effective, most works are based only on\nquantitative characteristics of the convolutional filters, and highly overlook\nthe qualitative interpretation of individual filter's specific functionality.\nIn this work, we interpreted the functionality and redundancy of the\nconvolutional filters from different perspectives, and proposed a\nfunctionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters' qualitative significance\nregardless of magnitude, demonstrated significant neural network redundancy due\nto repetitive filter functions, and analyzed the filter functionality defection\nunder inappropriate retraining process. Such an interpretable pruning approach\nnot only offers outstanding computation cost optimization over previous filter\npruning methods, but also interprets filter pruning process. \n\n"}
{"id": "1810.07378", "contents": "Title: Progressive Weight Pruning of Deep Neural Networks using ADMM Abstract: Deep neural networks (DNNs) although achieving human-level performance in\nmany domains, have very large model size that hinders their broader\napplications on edge computing devices. Extensive research work have been\nconducted on DNN model compression or pruning. However, most of the previous\nwork took heuristic approaches. This work proposes a progressive weight pruning\napproach based on ADMM (Alternating Direction Method of Multipliers), a\npowerful technique to deal with non-convex optimization problems with\npotentially combinatorial constraints. Motivated by dynamic programming, the\nproposed method reaches extremely high pruning rate by using partial prunings\nwith moderate pruning rates. Therefore, it resolves the accuracy degradation\nand long convergence time problems when pursuing extremely high pruning ratios.\nIt achieves up to 34 times pruning rate for ImageNet dataset and 167 times\npruning rate for MNIST dataset, significantly higher than those reached by the\nliterature work. Under the same number of epochs, the proposed method also\nachieves faster convergence and higher compression rates. The codes and pruned\nDNN models are released in the link bit.ly/2zxdlss \n\n"}
{"id": "1810.07406", "contents": "Title: Adversarial Balancing for Causal Inference Abstract: Biases in observational data of treatments pose a major challenge to\nestimating expected treatment outcomes in different populations. An important\ntechnique that accounts for these biases is reweighting samples to minimize the\ndiscrepancy between treatment groups. We present a novel reweighting approach\nthat uses bi-level optimization to alternately train a discriminator to\nminimize classification error, and a balancing weights generator that uses\nexponentiated gradient descent to maximize this error. This approach borrows\nprinciples from generative adversarial networks (GANs) to exploit the power of\nclassifiers for measuring two-sample divergence. We provide theoretical results\nfor conditions in which the estimation error is bounded by two factors: (i) the\ndiscrepancy measure induced by the discriminator; and (ii) the weights\nvariability. Experimental results on several benchmarks comparing to previous\nstate-of-the-art reweighting methods demonstrate the effectiveness of this\napproach in estimating causal effects. \n\n"}
{"id": "1810.08351", "contents": "Title: Exchangeability and Kernel Invariance in Trained MLPs Abstract: In the analysis of machine learning models, it is often convenient to assume\nthat the parameters are IID. This assumption is not satisfied when the\nparameters are updated through training processes such as SGD. A relaxation of\nthe IID condition is a probabilistic symmetry known as exchangeability. We show\nthe sense in which the weights in MLPs are exchangeable. This yields the result\nthat in certain instances, the layer-wise kernel of fully-connected layers\nremains approximately constant during training. We identify a sharp change in\nthe macroscopic behavior of networks as the covariance between weights changes\nfrom zero. \n\n"}
{"id": "1810.09102", "contents": "Title: Can We Gain More from Orthogonality Regularizations in Training Deep\n  CNNs? Abstract: This paper seeks to answer the question: as the (near-) orthogonality of\nweights is found to be a favorable property for training deep convolutional\nneural networks, how can we enforce it in more effective and easy-to-use ways?\nWe develop novel orthogonality regularizations on training deep CNNs, utilizing\nvarious advanced analytical tools such as mutual coherence and restricted\nisometry property. These plug-and-play regularizations can be conveniently\nincorporated into training almost any CNN without extra hassle. We then\nbenchmark their effects on state-of-the-art models: ResNet, WideResNet, and\nResNeXt, on several most popular computer vision datasets: CIFAR-10, CIFAR-100,\nSVHN and ImageNet. We observe consistent performance gains after applying those\nproposed regularizations, in terms of both the final accuracies achieved, and\nfaster and more stable convergences. We have made our codes and pre-trained\nmodels publicly available:\nhttps://github.com/nbansal90/Can-we-Gain-More-from-Orthogonality. \n\n"}
{"id": "1810.09111", "contents": "Title: Learning to Measure Change: Fully Convolutional Siamese Metric Networks\n  for Scene Change Detection Abstract: A critical challenge problem of scene change detection is that noisy changes\ngenerated by varying illumination, shadows and camera viewpoint make variances\nof a scene difficult to define and measure since the noisy changes and semantic\nones are entangled. Following the intuitive idea of detecting changes by\ndirectly comparing dissimilarities between a pair of features, we propose a\nnovel fully Convolutional siamese metric Network(CosimNet) to measure changes\nby customizing implicit metrics. To learn more discriminative metrics, we\nutilize contrastive loss to reduce the distance between the unchanged feature\npairs and to enlarge the distance between the changed feature pairs.\nSpecifically, to address the issue of large viewpoint differences, we propose\nThresholded Contrastive Loss (TCL) with a more tolerant strategy to punish\nnoisy changes. We demonstrate the effectiveness of the proposed approach with\nexperiments on three challenging datasets: CDnet, PCD2015, and VL-CMU-CD. Our\napproach is robust to lots of challenging conditions, such as illumination\nchanges, large viewpoint difference caused by camera motion and zooming. In\naddition, we incorporate the distance metric into the segmentation framework\nand validate the effectiveness through visualization of change maps and feature\ndistribution. The source code is available at\nhttps://github.com/gmayday1997/ChangeDet. \n\n"}
{"id": "1810.09176", "contents": "Title: Node Representation Learning for Directed Graphs Abstract: We propose a novel approach for learning node representations in directed\ngraphs, which maintains separate views or embedding spaces for the two distinct\nnode roles induced by the directionality of the edges. We argue that the\nprevious approaches either fail to encode the edge directionality or their\nencodings cannot be generalized across tasks. With our simple \\emph{alternating\nrandom walk} strategy, we generate role specific vertex neighborhoods and train\nnode embeddings in their corresponding source/target roles while fully\nexploiting the semantics of directed graphs. We also unearth the limitations of\nevaluations on directed graphs in previous works and propose a clear strategy\nfor evaluating link prediction and graph reconstruction in directed graphs. We\nconduct extensive experiments to showcase our effectiveness on several\nreal-world datasets on link prediction, node classification and graph\nreconstruction tasks. We show that the embeddings from our approach are indeed\nrobust, generalizable and well performing across multiple kinds of tasks and\ngraphs. We show that we consistently outperform all baselines for node\nclassification task. In addition to providing a theoretical interpretation of\nour method we also show that we are considerably more robust than the other\ndirected graph approaches. \n\n"}
{"id": "1810.09578", "contents": "Title: Bioresorbable Scaffold Visualization in IVOCT Images Using CNNs and\n  Weakly Supervised Localization Abstract: Bioresorbable scaffolds have become a popular choice for treatment of\ncoronary heart disease, replacing traditional metal stents. Often,\nintravascular optical coherence tomography is used to assess potential\nmalapposition after implantation and for follow-up examinations later on.\nTypically, the scaffold is manually reviewed by an expert, analyzing each of\nthe hundreds of image slices. As this is time consuming, automatic stent\ndetection and visualization approaches have been proposed, mostly for metal\nstent detection based on classic image processing. As bioresorbable scaffolds\nare harder to detect, recent approaches have used feature extraction and\nmachine learning methods for automatic detection. However, these methods\nrequire detailed, pixel-level labels in each image slice and extensive feature\nengineering for the particular stent type which might limit the approaches'\ngeneralization capabilities. Therefore, we propose a deep learning-based method\nfor bioresorbable scaffold visualization using only image-level labels. A\nconvolutional neural network is trained to predict whether an image slice\ncontains a metal stent, a bioresorbable scaffold, or no device. Then, we derive\nlocal stent strut information by employing weakly supervised localization using\nsaliency maps with guided backpropagation. As saliency maps are generally\ndiffuse and noisy, we propose a novel patch-based method with image shifting\nwhich allows for high resolution stent visualization. Our convolutional neural\nnetwork model achieves a classification accuracy of 99.0 % for image-level\nstent classification which can be used for both high quality in-slice stent\nvisualization and 3D rendering of the stent structure. \n\n"}
{"id": "1810.09988", "contents": "Title: Meta-Learning Multi-task Communication Abstract: In this paper, we describe a general framework: Parameters Read-Write\nNetworks (PRaWNs) to systematically analyze current neural models for\nmulti-task learning, in which we find that existing models expect to\ndisentangle features into different spaces while features learned in practice\nare still entangled in shared space, leaving potential hazards for other\ntraining or unseen tasks.\n  We propose to alleviate this problem by incorporating an inductive bias into\nthe process of multi-task learning, that each task can keep informed of not\nonly the knowledge stored in other tasks but the way how other tasks maintain\ntheir knowledge.\n  In practice, we achieve above inductive bias by allowing different tasks to\ncommunicate by passing both hidden variables and gradients explicitly.\n  Experimentally, we evaluate proposed methods on three groups of tasks and two\ntypes of settings (\\textsc{in-task} and \\textsc{out-of-task}). Quantitative and\nqualitative results show their effectiveness. \n\n"}
{"id": "1810.10327", "contents": "Title: BshapeNet: Object Detection and Instance Segmentation with Bounding\n  Shape Masks Abstract: Recent object detectors use four-coordinate bounding box (bbox) regression to\npredict object locations. Providing additional information indicating the\nobject positions and coordinates will improve detection performance. Thus, we\npropose two types of masks: a bbox mask and a bounding shape (bshape) mask, to\nrepresent the object's bbox and boundary shape, respectively. For each of these\ntypes, we consider two variants: the Thick model and the Scored model, both of\nwhich have the same morphology but differ in ways to make their boundaries\nthicker. To evaluate the proposed masks, we design extended frameworks by\nadding a bshape mask (or a bbox mask) branch to a Faster R-CNN framework, and\ncall this BshapeNet (or BboxNet). Further, we propose BshapeNet+, a network\nthat combines a bshape mask branch with a Mask R-CNN to improve instance\nsegmentation as well as detection. Among our proposed models, BshapeNet+\ndemonstrates the best performance in both tasks and achieves highly competitive\nresults with state of the art (SOTA) models. Particularly, it improves the\ndetection results over Faster R-CNN+RoIAlign (37.3% and 28.9%) with a detection\nAP of 42.4% and 32.3% on MS COCO test-dev and Cityscapes val, respectively.\nFurthermore, for small objects, it achieves 24.9% AP on COCO test-dev, a\nsignificant improvement over previous SOTA models. For instance segmentation,\nit is substantially superior to Mask R-CNN on both test datasets. \n\n"}
{"id": "1810.10687", "contents": "Title: Structure Learning of Deep Networks via DNA Computing Algorithm Abstract: Convolutional Neural Network (CNN) has gained state-of-the-art results in\nmany pattern recognition and computer vision tasks. However, most of the CNN\nstructures are manually designed by experienced researchers. Therefore, auto-\nmatically building high performance networks becomes an important problem. In\nthis paper, we introduce the idea of using DNA computing algorithm to\nautomatically learn high-performance architectures. In DNA computing algorithm,\nwe use short DNA strands to represent layers and long DNA strands to represent\noverall networks. We found that most of the learned models perform similarly,\nand only those performing worse during the first runs of training will perform\nworse finally than others. The indicates that: 1) Using DNA computing algorithm\nto learn deep architectures is feasible; 2) Local minima should not be a\nproblem of deep networks; 3) We can use early stop to kill the models with the\nbad performance just after several runs of training. In our experiments, an\naccuracy 99.73% was obtained on the MNIST data set and an accuracy 95.10% was\nobtained on the CIFAR-10 data set. \n\n"}
{"id": "1810.10818", "contents": "Title: HANDS18: Methods, Techniques and Applications for Hand Observation Abstract: This report outlines the proceedings of the Fourth International Workshop on\nObserving and Understanding Hands in Action (HANDS 2018). The fourth\ninstantiation of this workshop attracted significant interest from both\nacademia and the industry. The program of the workshop included regular papers\nthat are published as the workshop's proceedings, extended abstracts, invited\nposters, and invited talks. Topics of the submitted works and invited talks and\nposters included novel methods for hand pose estimation from RGB, depth, or\nskeletal data, datasets for special cases and real-world applications, and\ntechniques for hand motion re-targeting and hand gesture recognition. The\ninvited speakers are leaders in their respective areas of specialization,\ncoming from both industry and academia. The main conclusions that can be drawn\nare the turn of the community towards RGB data and the maturation of some\nmethods and techniques, which in turn has led to increasing interest for\nreal-world applications. \n\n"}
{"id": "1810.11710", "contents": "Title: Flash Photography for Data-Driven Hidden Scene Recovery Abstract: Vehicles, search and rescue personnel, and endoscopes use flash lights to\nlocate, identify, and view objects in their surroundings. Here we show the\nfirst steps of how all these tasks can be done around corners with consumer\ncameras. Recent techniques for NLOS imaging using consumer cameras have not\nbeen able to both localize and identify the hidden object. We introduce a\nmethod that couples traditional geometric understanding and data-driven\ntechniques. To avoid the limitation of large dataset gathering, we train the\ndata-driven models on rendered samples to computationally recover the hidden\nscene on real data. The method has three independent operating modes: 1) a\nregression output to localize a hidden object in 2D, 2) an identification\noutput to identify the object type or pose, and 3) a generative network to\nreconstruct the hidden scene from a new viewpoint. The method is able to\nlocalize 12cm wide hidden objects in 2D with 1.7cm accuracy. The method also\nidentifies the hidden object class with 87.7% accuracy (compared to 33.3%\nrandom accuracy). This paper also provides an analysis on the distribution of\ninformation that encodes the occluded object in the accessible scene. We show\nthat, unlike previously thought, the area that extends beyond the corner is\nessential for accurate object localization and identification. \n\n"}
{"id": "1810.11730", "contents": "Title: Low-shot Learning via Covariance-Preserving Adversarial Augmentation\n  Networks Abstract: Deep neural networks suffer from over-fitting and catastrophic forgetting\nwhen trained with small data. One natural remedy for this problem is data\naugmentation, which has been recently shown to be effective. However, previous\nworks either assume that intra-class variances can always be generalized to new\nclasses, or employ naive generation methods to hallucinate finite examples\nwithout modeling their latent distributions. In this work, we propose\nCovariance-Preserving Adversarial Augmentation Networks to overcome existing\nlimits of low-shot learning. Specifically, a novel Generative Adversarial\nNetwork is designed to model the latent distribution of each novel class given\nits related base counterparts. Since direct estimation of novel classes can be\ninductively biased, we explicitly preserve covariance information as the\n`variability' of base examples during the generation process. Empirical results\nshow that our model can generate realistic yet diverse examples, leading to\nsubstantial improvements on the ImageNet benchmark over the state of the art. \n\n"}
{"id": "1810.12532", "contents": "Title: Fully automatic structure from motion with a spline-based environment\n  representation Abstract: While the common environment representation in structure from motion is given\nby a sparse point cloud, the community has also investigated the use of lines\nto better enforce the inherent regularities in man-made surroundings. Following\nthe potential of this idea, the present paper introduces a more flexible\nhigher-order extension of points that provides a general model for structural\nedges in the environment, no matter if straight or curved. Our model relies on\nlinked B\\'ezier curves, the geometric intuition of which proves great benefits\nduring parameter initialization and regularization. We present the first fully\nautomatic pipeline that is able to generate spline-based representations\nwithout any human supervision. Besides a full graphical formulation of the\nproblem, we introduce both geometric and photometric cues as well as\nhigher-level concepts such overall curve visibility and viewing angle\nrestrictions to automatically manage the correspondences in the graph. Results\nprove that curve-based structure from motion with splines is able to outperform\nstate-of-the-art sparse feature-based methods, as well as to model curved edges\nin the environment. \n\n"}
{"id": "1810.13044", "contents": "Title: Scalable Laplacian K-modes Abstract: We advocate Laplacian K-modes for joint clustering and density mode finding,\nand propose a concave-convex relaxation of the problem, which yields a parallel\nalgorithm that scales up to large datasets and high dimensions. We optimize a\ntight bound (auxiliary function) of our relaxation, which, at each iteration,\namounts to computing an independent update for each cluster-assignment\nvariable, with guaranteed convergence. Therefore, our bound optimizer can be\ntrivially distributed for large-scale data sets. Furthermore, we show that the\ndensity modes can be obtained as byproducts of the assignment variables via\nsimple maximum-value operations whose additional computational cost is linear\nin the number of data points. Our formulation does not need storing a full\naffinity matrix and computing its eigenvalue decomposition, neither does it\nperform expensive projection steps and Lagrangian-dual inner iterates for the\nsimplex constraints of each point. Furthermore, unlike mean-shift, our\ndensity-mode estimation does not require inner-loop gradient-ascent iterates.\nIt has a complexity independent of feature-space dimension, yields modes that\nare valid data points in the input set and is applicable to discrete domains as\nwell as arbitrary kernels. We report comprehensive experiments over various\ndata sets, which show that our algorithm yields very competitive performances\nin term of optimization quality (i.e., the value of the discrete-variable\nobjective at convergence) and clustering accuracy. \n\n"}
{"id": "1810.13205", "contents": "Title: Multi-Task Learning for Left Atrial Segmentation on GE-MRI Abstract: Segmentation of the left atrium (LA) is crucial for assessing its anatomy in\nboth pre-operative atrial fibrillation (AF) ablation planning and\npost-operative follow-up studies. In this paper, we present a fully automated\nframework for left atrial segmentation in gadolinium-enhanced magnetic\nresonance images (GE-MRI) based on deep learning. We propose a fully\nconvolutional neural network and explore the benefits of multi-task learning\nfor performing both atrial segmentation and pre/post ablation classification.\nOur results show that, by sharing features between related tasks, the network\ncan gain additional anatomical information and achieve more accurate atrial\nsegmentation, leading to a mean Dice score of 0.901 on a test set of 20 3D MRI\nimages. Code of our proposed algorithm is available at\nhttps://github.com/cherise215/atria_segmentation_2018/. \n\n"}
{"id": "1810.13373", "contents": "Title: Analyzing biological and artificial neural networks: challenges with\n  opportunities for synergy? Abstract: Deep neural networks (DNNs) transform stimuli across multiple processing\nstages to produce representations that can be used to solve complex tasks, such\nas object recognition in images. However, a full understanding of how they\nachieve this remains elusive. The complexity of biological neural networks\nsubstantially exceeds the complexity of DNNs, making it even more challenging\nto understand the representations that they learn. Thus, both machine learning\nand computational neuroscience are faced with a shared challenge: how can we\nanalyze their representations in order to understand how they solve complex\ntasks?\n  We review how data-analysis concepts and techniques developed by\ncomputational neuroscientists can be useful for analyzing representations in\nDNNs, and in turn, how recently developed techniques for analysis of DNNs can\nbe useful for understanding representations in biological neural networks. We\nexplore opportunities for synergy between the two fields, such as the use of\nDNNs as in-silico model systems for neuroscience, and how this synergy can lead\nto new hypotheses about the operating principles of biological neural networks. \n\n"}
{"id": "1811.01085", "contents": "Title: Ischemic Stroke Lesion Segmentation in CT Perfusion Scans using Pyramid\n  Pooling and Focal Loss Abstract: We present a fully convolutional neural network for segmenting ischemic\nstroke lesions in CT perfusion images for the ISLES 2018 challenge. Treatment\nof stroke is time sensitive and current standards for lesion identification\nrequire manual segmentation, a time consuming and challenging process.\nAutomatic segmentation methods present the possibility of accurately\nidentifying lesions and improving treatment planning. Our model is based on the\nPSPNet, a network architecture that makes use of pyramid pooling to provide\nglobal and local contextual information. To learn the varying shapes of the\nlesions, we train our network using focal loss, a loss function designed for\nthe network to focus on learning the more difficult samples. We compare our\nmodel to networks trained using the U-Net and V-Net architectures. Our approach\ndemonstrates effective performance in lesion segmentation and ranked among the\ntop performers at the challenge conclusion. \n\n"}
{"id": "1811.01476", "contents": "Title: Dynamic Representations Toward Efficient Inference on Deep Neural\n  Networks by Decision Gates Abstract: While deep neural networks extract rich features from the input data, the\ncurrent trade-off between depth and computational cost makes it difficult to\nadopt deep neural networks for many industrial applications, especially when\ncomputing power is limited. Here, we are inspired by the idea that, while\ndeeper embeddings are needed to discriminate difficult samples (i.e.,\nfine-grained discrimination), a large number of samples can be well\ndiscriminated via much shallower embeddings (i.e., coarse-grained\ndiscrimination). In this study, we introduce the simple yet effective concept\nof decision gates (d-gate), modules trained to decide whether a sample needs to\nbe projected into a deeper embedding or if an early prediction can be made at\nthe d-gate, thus enabling the computation of dynamic representations at\ndifferent depths. The proposed d-gate modules can be integrated with any deep\nneural network and reduces the average computational cost of the deep neural\nnetworks while maintaining modeling accuracy. The proposed d-gate framework is\nexamined via different network architectures and datasets, with experimental\nresults showing that leveraging the proposed d-gate modules led to a ~43%\nspeed-up and 44% FLOPs reduction on ResNet-101 and 55% speed-up and 39% FLOPs\nreduction on DenseNet-201 trained on the CIFAR10 dataset with only ~2% drop in\naccuracy. Furthermore, experiments where d-gate modules are integrated into\nResNet-101 trained on the ImageNet dataset demonstrate that it is possible to\nreduce the computational cost of the network by 1.5 GFLOPs without any drop in\nthe modeling accuracy. \n\n"}
{"id": "1811.01686", "contents": "Title: GEMRank: Global Entity Embedding For Collaborative Filtering Abstract: Recently, word embedding algorithms have been applied to map the entities of\nrecommender systems, such as users and items, to new feature spaces using\ntextual element-context relations among them. Unlike many other domains, this\napproach has not achieved a desired performance in collaborative filtering\nproblems, probably due to unavailability of appropriate textual data. In this\npaper we propose a new recommendation framework, called GEMRank that can be\napplied when the user-item matrix is the sole available souce of information.\nIt uses the concept of profile co-occurrence for defining relations among\nentities and applies a factorization method for embedding the users and items.\nGEMRank then feeds the extracted representations to a neural network model to\npredict user-item like/dislike relations which the final recommendations are\nmade based on. We evaluated GEMRank in an extensive set of experiments against\nstate of the art recommendation methods. The results show that GEMRank\nsignificantly outperforms the baseline algorithms in a variety of data sets\nwith different degrees of density. \n\n"}
{"id": "1811.01753", "contents": "Title: How deep is deep enough? -- Quantifying class separability in the hidden\n  layers of deep neural networks Abstract: Deep neural networks typically outperform more traditional machine learning\nmodels in their ability to classify complex data, and yet is not clear how the\nindividual hidden layers of a deep network contribute to the overall\nclassification performance. We thus introduce a Generalized Discrimination\nValue (GDV) that measures, in a non-invasive manner, how well different data\nclasses separate in each given network layer. The GDV can be used for the\nautomatic tuning of hyper-parameters, such as the width profile and the total\ndepth of a network. Moreover, the layer-dependent GDV(L) provides new insights\ninto the data transformations that self-organize during training: In the case\nof multi-layer perceptrons trained with error backpropagation, we find that\nclassification of highly complex data sets requires a temporal {\\em reduction}\nof class separability, marked by a characteristic 'energy barrier' in the\ninitial part of the GDV(L) curve. Even more surprisingly, for a given data set,\nthe GDV(L) is running through a fixed 'master curve', independently from the\ntotal number of network layers. Furthermore, applying the GDV to Deep Belief\nNetworks reveals that also unsupervised training with the Contrastive\nDivergence method can systematically increase class separability over tens of\nlayers, even though the system does not 'know' the desired class labels. These\nresults indicate that the GDV may become a useful tool to open the black box of\ndeep learning. \n\n"}
{"id": "1811.01791", "contents": "Title: Confidence Propagation through CNNs for Guided Sparse Depth Regression Abstract: Generally, convolutional neural networks (CNNs) process data on a regular\ngrid, e.g. data generated by ordinary cameras. Designing CNNs for sparse and\nirregularly spaced input data is still an open research problem with numerous\napplications in autonomous driving, robotics, and surveillance. In this paper,\nwe propose an algebraically-constrained normalized convolution layer for CNNs\nwith highly sparse input that has a smaller number of network parameters\ncompared to related work. We propose novel strategies for determining the\nconfidence from the convolution operation and propagating it to consecutive\nlayers. We also propose an objective function that simultaneously minimizes the\ndata error while maximizing the output confidence. To integrate structural\ninformation, we also investigate fusion strategies to combine depth and RGB\ninformation in our normalized convolution network framework. In addition, we\nintroduce the use of output confidence as an auxiliary information to improve\nthe results. The capabilities of our normalized convolution network framework\nare demonstrated for the problem of scene depth completion. Comprehensive\nexperiments are performed on the KITTI-Depth and the NYU-Depth-v2 datasets. The\nresults clearly demonstrate that the proposed approach achieves superior\nperformance while requiring only about 1-5% of the number of parameters\ncompared to the state-of-the-art methods. \n\n"}
{"id": "1811.01907", "contents": "Title: A Unified Framework of DNN Weight Pruning and Weight\n  Clustering/Quantization Using ADMM Abstract: Many model compression techniques of Deep Neural Networks (DNNs) have been\ninvestigated, including weight pruning, weight clustering and quantization,\netc. Weight pruning leverages the redundancy in the number of weights in DNNs,\nwhile weight clustering/quantization leverages the redundancy in the number of\nbit representations of weights. They can be effectively combined in order to\nexploit the maximum degree of redundancy. However, there lacks a systematic\ninvestigation in literature towards this direction.\n  In this paper, we fill this void and develop a unified, systematic framework\nof DNN weight pruning and clustering/quantization using Alternating Direction\nMethod of Multipliers (ADMM), a powerful technique in optimization theory to\ndeal with non-convex optimization problems. Both DNN weight pruning and\nclustering/quantization, as well as their combinations, can be solved in a\nunified manner. For further performance improvement in this framework, we adopt\nmultiple techniques including iterative weight quantization and retraining,\njoint weight clustering training and centroid updating, weight clustering\nretraining, etc. The proposed framework achieves significant improvements both\nin individual weight pruning and clustering/quantization problems, as well as\ntheir combinations. For weight pruning alone, we achieve 167x weight reduction\nin LeNet-5, 24.7x in AlexNet, and 23.4x in VGGNet, without any accuracy loss.\nFor the combination of DNN weight pruning and clustering/quantization, we\nachieve 1,910x and 210x storage reduction of weight data on LeNet-5 and\nAlexNet, respectively, without accuracy loss. Our codes and models are released\nat the link http://bit.ly/2D3F0np \n\n"}
{"id": "1811.02132", "contents": "Title: Student's t-Generative Adversarial Networks Abstract: Generative Adversarial Networks (GANs) have a great performance in image\ngeneration, but they need a large scale of data to train the entire framework,\nand often result in nonsensical results. We propose a new method referring to\nconditional GAN, which equipments the latent noise with mixture of Student's\nt-distribution with attention mechanism in addition to class information.\nStudent's t-distribution has long tails that can provide more diversity to the\nlatent noise. Meanwhile, the discriminator in our model implements two tasks\nsimultaneously, judging whether the images come from the true data\ndistribution, and identifying the class of each generated images. The\nparameters of the mixture model can be learned along with those of GANs.\nMoreover, we mathematically prove that any multivariate Student's\nt-distribution can be obtained by a linear transformation of a normal\nmultivariate Student's t-distribution. Experiments comparing the proposed\nmethod with typical GAN, DeliGAN and DCGAN indicate that, our method has a\ngreat performance on generating diverse and legible objects with limited data. \n\n"}
{"id": "1811.02642", "contents": "Title: Computational Histological Staining and Destaining of Prostate Core\n  Biopsy RGB Images with Generative Adversarial Neural Networks Abstract: Histopathology tissue samples are widely available in two states:\nparaffin-embedded unstained and non-paraffin-embedded stained whole slide RGB\nimages (WSRI). Hematoxylin and eosin stain (H&E) is one of the principal stains\nin histology but suffers from several shortcomings related to tissue\npreparation, staining protocols, slowness and human error. We report two novel\napproaches for training machine learning models for the computational H&E\nstaining and destaining of prostate core biopsy RGB images. The staining model\nuses a conditional generative adversarial network that learns hierarchical\nnon-linear mappings between whole slide RGB image (WSRI) pairs of prostate core\nbiopsy before and after H&E staining. The trained staining model can then\ngenerate computationally H&E-stained prostate core WSRIs using previously\nunseen non-stained biopsy images as input. The destaining model, by learning\nmappings between an H&E stained WSRI and a non-stained WSRI of the same biopsy,\ncan computationally destain previously unseen H&E-stained images. Structural\nand anatomical details of prostate tissue and colors, shapes, geometries,\nlocations of nuclei, stroma, vessels, glands and other cellular components were\ngenerated by both models with structural similarity indices of 0.68 (staining)\nand 0.84 (destaining). The proposed staining and destaining models can engender\ncomputational H&E staining and destaining of WSRI biopsies without additional\nequipment and devices. \n\n"}
{"id": "1811.02656", "contents": "Title: Quaternion Convolutional Neural Networks for Heterogeneous Image\n  Processing Abstract: Convolutional neural networks (CNN) have recently achieved state-of-the-art\nresults in various applications. In the case of image recognition, an ideal\nmodel has to learn independently of the training data, both local dependencies\nbetween the three components (R,G,B) of a pixel, and the global relations\ndescribing edges or shapes, making it efficient with small or heterogeneous\ndatasets. Quaternion-valued convolutional neural networks (QCNN) solved this\nproblematic by introducing multidimensional algebra to CNN. This paper proposes\nto explore the fundamental reason of the success of QCNN over CNN, by\ninvestigating the impact of the Hamilton product on a color image\nreconstruction task performed from a gray-scale only training. By learning\nindependently both internal and external relations and with less parameters\nthan real valued convolutional encoder-decoder (CAE), quaternion convolutional\nencoder-decoders (QCAE) perfectly reconstructed unseen color images while CAE\nproduced worst and gray-scale versions. \n\n"}
{"id": "1811.02946", "contents": "Title: SurReal: enhancing Surgical simulation Realism using style transfer Abstract: Surgical simulation is an increasingly important element of surgical\neducation. Using simulation can be a means to address some of the significant\nchallenges in developing surgical skills with limited time and resources. The\nphoto-realistic fidelity of simulations is a key feature that can improve the\nexperience and transfer ratio of trainees. In this paper, we demonstrate how we\ncan enhance the visual fidelity of existing surgical simulation by performing\nstyle transfer of multi-class labels from real surgical video onto synthetic\ncontent. We demonstrate our approach on simulations of cataract surgery using\nreal data labels from an existing public dataset. Our results highlight the\nfeasibility of the approach and also the powerful possibility to extend this\ntechnique to incorporate additional temporal constraints and to different\napplications. \n\n"}
{"id": "1811.03032", "contents": "Title: A Holistic Visual Place Recognition Approach using Lightweight CNNs for\n  Significant ViewPoint and Appearance Changes Abstract: This paper presents a lightweight visual place recognition approach, capable\nof achieving high performance with low computational cost, and feasible for\nmobile robotics under significant viewpoint and appearance changes. Results on\nseveral benchmark datasets confirm an average boost of 13% in accuracy, and 12x\naverage speedup relative to state-of-the-art methods. \n\n"}
{"id": "1811.03196", "contents": "Title: Correlation Filter Selection for Visual Tracking Using Reinforcement\n  Learning Abstract: Correlation filter has been proven to be an effective tool for a number of\napproaches in visual tracking, particularly for seeking a good balance between\ntracking accuracy and speed. However, correlation filter based models are\nsusceptible to wrong updates stemming from inaccurate tracking results. To\ndate, little effort has been devoted towards handling the correlation filter\nupdate problem. In this paper, we propose a novel approach to address the\ncorrelation filter update problem. In our approach, we update and maintain\nmultiple correlation filter models in parallel, and we use deep reinforcement\nlearning for the selection of an optimal correlation filter model among them.\nTo facilitate the decision process in an efficient manner, we propose a\ndecision-net to deal target appearance modeling, which is trained through\nhundreds of challenging videos using proximal policy optimization and a\nlightweight learning network. An exhaustive evaluation of the proposed approach\non the OTB100 and OTB2013 benchmarks show that the approach is effective enough\nto achieve the average success rate of 62.3% and the average precision score of\n81.2%, both exceeding the performance of traditional correlation filter based\ntrackers. \n\n"}
{"id": "1811.03305", "contents": "Title: BAR: Bayesian Activity Recognition using variational inference Abstract: Uncertainty estimation in deep neural networks is essential for designing\nreliable and robust AI systems. Applications such as video surveillance for\nidentifying suspicious activities are designed with deep neural networks\n(DNNs), but DNNs do not provide uncertainty estimates. Capturing reliable\nuncertainty estimates in safety and security critical applications will help to\nestablish trust in the AI system. Our contribution is to apply Bayesian deep\nlearning framework to visual activity recognition application and quantify\nmodel uncertainty along with principled confidence. We utilize the stochastic\nvariational inference technique while training the Bayesian DNNs to infer the\napproximate posterior distribution around model parameters and perform Monte\nCarlo sampling on the posterior of model parameters to obtain the predictive\ndistribution. We show that the Bayesian inference applied to DNNs provide\nreliable confidence measures for visual activity recognition task as compared\nto conventional DNNs. We also show that our method improves the visual activity\nrecognition precision-recall AUC by 6.2% compared to non-Bayesian baseline. We\nevaluate our models on Moments-In-Time (MiT) activity recognition dataset by\nselecting a subset of in- and out-of-distribution video samples. \n\n"}
{"id": "1811.03403", "contents": "Title: ExGate: Externally Controlled Gating for Feature-based Attention in\n  Artificial Neural Networks Abstract: Perceptual capabilities of artificial systems have come a long way since the\nadvent of deep learning. These methods have proven to be effective, however\nthey are not as efficient as their biological counterparts. Visual attention is\na set of mechanisms that are employed in biological visual systems to ease\ncomputational load by only processing pertinent parts of the stimuli. This\npaper addresses the implementation of top-down, feature-based attention in an\nartificial neural network by use of externally controlled neuron gating. Our\nresults showed a 5% increase in classification accuracy on the CIFAR-10 dataset\nversus a non-gated version, while adding very few parameters. Our gated model\nalso produces more reasonable errors in predictions by drastically reducing\nprediction of classes that belong to a different category to the true class. \n\n"}
{"id": "1811.03433", "contents": "Title: Explainable cardiac pathology classification on cine MRI with motion\n  characterization by semi-supervised learning of apparent flow Abstract: We propose a method to classify cardiac pathology based on a novel approach\nto extract image derived features to characterize the shape and motion of the\nheart. An original semi-supervised learning procedure, which makes efficient\nuse of a large amount of non-segmented images and a small amount of images\nsegmented manually by experts, is developed to generate pixel-wise apparent\nflow between two time points of a 2D+t cine MRI image sequence. Combining the\napparent flow maps and cardiac segmentation masks, we obtain a local apparent\nflow corresponding to the 2D motion of myocardium and ventricular cavities.\nThis leads to the generation of time series of the radius and thickness of\nmyocardial segments to represent cardiac motion. These time series of motion\nfeatures are reliable and explainable characteristics of pathological cardiac\nmotion. Furthermore, they are combined with shape-related features to classify\ncardiac pathologies. Using only nine feature values as input, we propose an\nexplainable, simple and flexible model for pathology classification. On ACDC\ntraining set and testing set, the model achieves 95% and 94% respectively as\nclassification accuracy. Its performance is hence comparable to that of the\nstate-of-the-art. Comparison with various other models is performed to outline\nsome advantages of our model. \n\n"}
{"id": "1811.03600", "contents": "Title: Measuring the Effects of Data Parallelism on Neural Network Training Abstract: Recent hardware developments have dramatically increased the scale of data\nparallelism available for neural network training. Among the simplest ways to\nharness next-generation hardware is to increase the batch size in standard\nmini-batch neural network training algorithms. In this work, we aim to\nexperimentally characterize the effects of increasing the batch size on\ntraining time, as measured by the number of steps necessary to reach a goal\nout-of-sample error. We study how this relationship varies with the training\nalgorithm, model, and data set, and find extremely large variation between\nworkloads. Along the way, we show that disagreements in the literature on how\nbatch size affects model quality can largely be explained by differences in\nmetaparameter tuning and compute budgets at different batch sizes. We find no\nevidence that larger batch sizes degrade out-of-sample performance. Finally, we\ndiscuss the implications of our results on efforts to train neural networks\nmuch faster in the future. Our experimental data is publicly available as a\ndatabase of 71,638,836 loss measurements taken over the course of training for\n168,160 individual models across 35 workloads. \n\n"}
{"id": "1811.04250", "contents": "Title: Detecting Work Zones in SHRP 2 NDS Videos Using Deep Learning Based\n  Computer Vision Abstract: Naturalistic driving studies seek to perform the observations of human driver\nbehavior in the variety of environmental conditions necessary to analyze,\nunderstand and predict that behavior using statistical and physical models. The\nsecond Strategic Highway Research Program (SHRP 2) funds a number of\ntransportation safety-related projects including its primary effort, the\nNaturalistic Driving Study (NDS), and an effort supplementary to the NDS, the\nRoadway Information Database (RID). This work seeks to expand the range of\nanswerable research questions that researchers might pose to the NDS and RID\ndatabases. Specifically, we present the SHRP 2 NDS Video Analytics (SNVA)\nsoftware application, which extracts information from NDS-instrumented\nvehicles' forward-facing camera footage and efficiently integrates that\ninformation into the RID, tying the video content to geolocations and other\ntrip attributes. Of particular interest to researchers and other stakeholders\nis the integration of work zone, traffic signal state and weather information.\nThe version of SNVA introduced in this paper focuses on work zone detection,\nthe highest priority. The ability to automate the discovery and cataloging of\nthis information, and to do so quickly, is especially important given the two\npetabyte (2PB) size of the NDS video data set. \n\n"}
{"id": "1811.04595", "contents": "Title: Holistic Multi-modal Memory Network for Movie Question Answering Abstract: Answering questions according to multi-modal context is a challenging problem\nas it requires a deep integration of different data sources. Existing\napproaches only employ partial interactions among data sources in one attention\nhop. In this paper, we present the Holistic Multi-modal Memory Network (HMMN)\nframework which fully considers the interactions between different input\nsources (multi-modal context, question) in each hop. In addition, it takes\nanswer choices into consideration during the context retrieval stage.\nTherefore, the proposed framework effectively integrates multi-modal context,\nquestion, and answer information, which leads to more informative context\nretrieved for question answering. Our HMMN framework achieves state-of-the-art\naccuracy on MovieQA dataset. Extensive ablation studies show the importance of\nholistic reasoning and contributions of different attention strategies. \n\n"}
{"id": "1811.05512", "contents": "Title: A domain agnostic measure for monitoring and evaluating GANs Abstract: Generative Adversarial Networks (GANs) have shown remarkable results in\nmodeling complex distributions, but their evaluation remains an unsettled\nissue. Evaluations are essential for: (i) relative assessment of different\nmodels and (ii) monitoring the progress of a single model throughout training.\nThe latter cannot be determined by simply inspecting the generator and\ndiscriminator loss curves as they behave non-intuitively. We leverage the\nnotion of duality gap from game theory to propose a measure that addresses both\n(i) and (ii) at a low computational cost. Extensive experiments show the\neffectiveness of this measure to rank different GAN models and capture the\ntypical GAN failure scenarios, including mode collapse and non-convergent\nbehaviours. This evaluation metric also provides meaningful monitoring on the\nprogression of the loss during training. It highly correlates with FID on\nnatural image datasets, and with domain specific scores for text, sound and\ncosmology data where FID is not directly suitable. In particular, our proposed\nmetric requires no labels or a pretrained classifier, making it domain\nagnostic. \n\n"}
{"id": "1811.07023", "contents": "Title: An Infinite Parade of Giraffes: Expressive Augmentation and Complexity\n  Layers for Cartoon Drawing Abstract: In this paper, we explore creative image generation constrained by small\ndata. To partially automate the creation of cartoon sketches consistent with a\nspecific designer's style, where acquiring a very large original image set is\nimpossible or cost prohibitive, we exploit domain specific knowledge for a huge\nreduction in original image requirements, creating an effectively infinite\nnumber of cartoon giraffes from just nine original drawings. We introduce\n\"expressive augmentations\" for cartoon sketches, mathematical transformations\nthat create broad domain appropriate variation, far beyond the usual affine\ntransformations, and we show that chained GANs models trained on the temporal\nstages of drawing or \"complexity layers\" can effectively add character\nappropriate details and finish new drawings in the designer's style.\n  We discuss the application of these tools in design processes for textiles,\ngraphics, architectural elements and interior design. \n\n"}
{"id": "1811.07407", "contents": "Title: Multimodal Densenet Abstract: Humans make accurate decisions by interpreting complex data from multiple\nsources. Medical diagnostics, in particular, often hinge on human\ninterpretation of multi-modal information. In order for artificial intelligence\nto make progress in automated, objective, and accurate diagnosis and prognosis,\nmethods to fuse information from multiple medical imaging modalities are\nrequired. However, combining information from multiple data sources has several\nchallenges, as current deep learning architectures lack the ability to extract\nuseful representations from multimodal information, and often simple\nconcatenation is used to fuse such information. In this work, we propose\nMultimodal DenseNet, a novel architecture for fusing multimodal data. Instead\nof focusing on concatenation or early and late fusion, our proposed\narchitectures fuses information over several layers and gives the model\nflexibility in how it combines information from multiple sources. We apply this\narchitecture to the challenge of polyp characterization and landmark\nidentification in endoscopy. Features from white light images are fused with\nfeatures from narrow band imaging or depth maps. This study demonstrates that\nMultimodal DenseNet outperforms monomodal classification as well as other\nmultimodal fusion techniques by a significant margin on two different datasets. \n\n"}
{"id": "1811.07627", "contents": "Title: Mixed Likelihood Gaussian Process Latent Variable Model Abstract: We present the Mixed Likelihood Gaussian process latent variable model\n(GP-LVM), capable of modeling data with attributes of different types. The\nstandard formulation of GP-LVM assumes that each observation is drawn from a\nGaussian distribution, which makes the model unsuited for data with e.g.\ncategorical or nominal attributes. Our model, for which we use a sampling based\nvariational inference, instead assumes a separate likelihood for each observed\ndimension. This formulation results in more meaningful latent representations,\nand give better predictive performance for real world data with dimensions of\ndifferent types. \n\n"}
{"id": "1811.07745", "contents": "Title: Reinforcement Learning with A* and a Deep Heuristic Abstract: A* is a popular path-finding algorithm, but it can only be applied to those\ndomains where a good heuristic function is known. Inspired by recent methods\ncombining Deep Neural Networks (DNNs) and trees, this study demonstrates how to\ntrain a heuristic represented by a DNN and combine it with A*. This new\nalgorithm which we call aleph-star can be used efficiently in domains where the\ninput to the heuristic could be processed by a neural network. We compare\naleph-star to N-Step Deep Q-Learning (DQN Mnih et al. 2013) in a driving\nsimulation with pixel-based input, and demonstrate significantly better\nperformance in this scenario. \n\n"}
{"id": "1811.07966", "contents": "Title: Mitigating Architectural Mismatch During the Evolutionary Synthesis of\n  Deep Neural Networks Abstract: Evolutionary deep intelligence has recently shown great promise for producing\nsmall, powerful deep neural network models via the organic synthesis of\nincreasingly efficient architectures over successive generations. Existing\nevolutionary synthesis processes, however, have allowed the mating of parent\nnetworks independent of architectural alignment, resulting in a mismatch of\nnetwork structures. We present a preliminary study into the effects of\narchitectural alignment during evolutionary synthesis using a gene tagging\nsystem. Surprisingly, the network architectures synthesized using the gene\ntagging approach resulted in slower decreases in performance accuracy and\nstorage size; however, the resultant networks were comparable in size and\nperformance accuracy to the non-gene tagging networks. Furthermore, we\nspeculate that there is a noticeable decrease in network variability for\nnetworks synthesized with gene tagging, indicating that enforcing a\nlike-with-like mating policy potentially restricts the exploration of the\nsearch space of possible network architectures. \n\n"}
{"id": "1811.08075", "contents": "Title: Scene Graph Generation via Conditional Random Fields Abstract: Despite the great success object detection and segmentation models have\nachieved in recognizing individual objects in images, performance on cognitive\ntasks such as image caption, semantic image retrieval, and visual QA is far\nfrom satisfactory. To achieve better performance on these cognitive tasks,\nmerely recognizing individual object instances is insufficient. Instead, the\ninteractions between object instances need to be captured in order to\nfacilitate reasoning and understanding of the visual scenes in an image. Scene\ngraph, a graph representation of images that captures object instances and\ntheir relationships, offers a comprehensive understanding of an image. However,\nexisting techniques on scene graph generation fail to distinguish subjects and\nobjects in the visual scenes of images and thus do not perform well with\nreal-world datasets where exist ambiguous object instances. In this work, we\npropose a novel scene graph generation model for predicting object instances\nand its corresponding relationships in an image. Our model, SG-CRF, learns the\nsequential order of subject and object in a relationship triplet, and the\nsemantic compatibility of object instance nodes and relationship nodes in a\nscene graph efficiently. Experiments empirically show that SG-CRF outperforms\nthe state-of-the-art methods, on three different datasets, i.e., CLEVR, VRD,\nand Visual Genome, raising the Recall@100 from 24.99% to 49.95%, from 41.92% to\n50.47%, and from 54.69% to 54.77%, respectively. \n\n"}
{"id": "1811.09955", "contents": "Title: Online Newton Step Algorithm with Estimated Gradient Abstract: Online learning with limited information feedback (bandit) tries to solve the\nproblem where an online learner receives partial feedback information from the\nenvironment in the course of learning. Under this setting, Flaxman et al.[8]\nextended Zinkevich's classical Online Gradient Descent (OGD) algorithm [29] by\nproposing the Online Gradient Descent with Expected Gradient (OGDEG) algorithm.\nSpecifically, it uses a simple trick to approximate the gradient of the loss\nfunction $f_t$ by evaluating it at a single point and bounds the expected\nregret as $\\mathcal{O}(T^{5/6})$ [8], where the number of rounds is $T$.\nMeanwhile, past research efforts have shown that compared with the first-order\nalgorithms, second-order online learning algorithms such as Online Newton Step\n(ONS) [11] can significantly accelerate the convergence rate of traditional\nonline learning algorithms. Motivated by this, this paper aims to exploit the\nsecond-order information to speed up the convergence of the OGDEG algorithm. In\nparticular, we extend the ONS algorithm with the trick of expected gradient and\ndevelop a novel second-order online learning algorithm, i.e., Online Newton\nStep with Expected Gradient (ONSEG). Theoretically, we show that the proposed\nONSEG algorithm significantly reduces the expected regret of OGDEG algorithm\nfrom $\\mathcal{O}(T^{5/6})$ to $\\mathcal{O}(T^{2/3})$ in the bandit feedback\nscenario. Empirically, we further demonstrate the advantages of the proposed\nalgorithm on multiple real-world datasets. \n\n"}
{"id": "1811.10435", "contents": "Title: On Filter Size in Graph Convolutional Networks Abstract: Recently, many researchers have been focusing on the definition of neural\nnetworks for graphs. The basic component for many of these approaches remains\nthe graph convolution idea proposed almost a decade ago. In this paper, we\nextend this basic component, following an intuition derived from the well-known\nconvolutional filters over multi-dimensional tensors. In particular, we derive\na simple, efficient and effective way to introduce a hyper-parameter on graph\nconvolutions that influences the filter size, i.e. its receptive field over the\nconsidered graph. We show with experimental results on real-world graph\ndatasets that the proposed graph convolutional filter improves the predictive\nperformance of Deep Graph Convolutional Networks. \n\n"}
{"id": "1811.10581", "contents": "Title: HOGWILD!-Gibbs can be PanAccurate Abstract: Asynchronous Gibbs sampling has been recently shown to be fast-mixing and an\naccurate method for estimating probabilities of events on a small number of\nvariables of a graphical model satisfying Dobrushin's\ncondition~\\cite{DeSaOR16}. We investigate whether it can be used to accurately\nestimate expectations of functions of {\\em all the variables} of the model.\nUnder the same condition, we show that the synchronous (sequential) and\nasynchronous Gibbs samplers can be coupled so that the expected Hamming\ndistance between their (multivariate) samples remains bounded by $O(\\tau \\log\nn),$ where $n$ is the number of variables in the graphical model, and $\\tau$ is\na measure of the asynchronicity. A similar bound holds for any constant power\nof the Hamming distance. Hence, the expectation of any function that is\nLipschitz with respect to a power of the Hamming distance, can be estimated\nwith a bias that grows logarithmically in $n$. Going beyond Lipschitz\nfunctions, we consider the bias arising from asynchronicity in estimating the\nexpectation of polynomial functions of all variables in the model. Using recent\nconcentration of measure results, we show that the bias introduced by the\nasynchronicity is of smaller order than the standard deviation of the function\nvalue already present in the true model. We perform experiments on a\nmulti-processor machine to empirically illustrate our theoretical findings. \n\n"}
{"id": "1811.10797", "contents": "Title: Node Embedding with Adaptive Similarities for Scalable Learning over\n  Graphs Abstract: Node embedding is the task of extracting informative and descriptive features\nover the nodes of a graph. The importance of node embeddings for graph\nanalytics, as well as learning tasks such as node classification, link\nprediction and community detection, has led to increased interest on the\nproblem leading to a number of recent advances. Much like PCA in the feature\ndomain, node embedding is an inherently \\emph{unsupervised} task; in lack of\nmetadata used for validation, practical methods may require standardization and\nlimiting the use of tunable hyperparameters. Finally, node embedding methods\nare faced with maintaining scalability in the face of large-scale real-world\ngraphs of ever-increasing sizes. In the present work, we propose an adaptive\nnode embedding framework that adjusts the embedding process to a given\nunderlying graph, in a fully unsupervised manner. To achieve this, we adopt the\nnotion of a tunable node similarity matrix that assigns weights on paths of\ndifferent length. The design of the multilength similarities ensures that the\nresulting embeddings also inherit interpretable spectral properties. The\nproposed model is carefully studied, interpreted, and numerically evaluated\nusing stochastic block models. Moreover, an algorithmic scheme is proposed for\ntraining the model parameters effieciently and in an unsupervised manner. We\nperform extensive node classification, link prediction, and clustering\nexperiments on many real world graphs from various domains, and compare with\nstate-of-the-art scalable and unsupervised node embedding alternatives. The\nproposed method enjoys superior performance in many cases, while also yielding\ninterpretable information on the underlying structure of the graph. \n\n"}
{"id": "1811.10842", "contents": "Title: CIAN: Cross-Image Affinity Net for Weakly Supervised Semantic\n  Segmentation Abstract: Weakly supervised semantic segmentation with only image-level labels saves\nlarge human effort to annotate pixel-level labels. Cutting-edge approaches rely\non various innovative constraints and heuristic rules to generate the masks for\nevery single image. Although great progress has been achieved by these methods,\nthey treat each image independently and do not take account of the\nrelationships across different images. In this paper, however, we argue that\nthe cross-image relationship is vital for weakly supervised segmentation.\nBecause it connects related regions across images, where supplementary\nrepresentations can be propagated to obtain more consistent and integral\nregions. To leverage this information, we propose an end-to-end cross-image\naffinity module, which exploits pixel-level cross-image relationships with only\nimage-level labels. By means of this, our approach achieves 64.3% and 65.3%\nmIoU on Pascal VOC 2012 validation and test set respectively, which is a new\nstate-of-the-art result by only using image-level labels for weakly supervised\nsemantic segmentation, demonstrating the superiority of our approach. \n\n"}
{"id": "1811.11082", "contents": "Title: Automatic Face Aging in Videos via Deep Reinforcement Learning Abstract: This paper presents a novel approach to synthesize automatically\nage-progressed facial images in video sequences using Deep Reinforcement\nLearning. The proposed method models facial structures and the longitudinal\nface-aging process of given subjects coherently across video frames. The\napproach is optimized using a long-term reward, Reinforcement Learning function\nwith deep feature extraction from Deep Convolutional Neural Network. Unlike\nprevious age-progression methods that are only able to synthesize an aged\nlikeness of a face from a single input image, the proposed approach is capable\nof age-progressing facial likenesses in videos with consistently synthesized\nfacial features across frames. In addition, the deep reinforcement learning\nmethod guarantees preservation of the visual identity of input faces after\nage-progression. Results on videos of our new collected aging face AGFW-v2\ndatabase demonstrate the advantages of the proposed solution in terms of both\nquality of age-progressed faces, temporal smoothness, and cross-age face\nverification. \n\n"}
{"id": "1811.11209", "contents": "Title: Iterative Transformer Network for 3D Point Cloud Abstract: 3D point cloud is an efficient and flexible representation of 3D structures.\nRecently, neural networks operating on point clouds have shown superior\nperformance on 3D understanding tasks such as shape classification and part\nsegmentation. However, performance on such tasks is evaluated on complete\nshapes aligned in a canonical frame, while real world 3D data are partial and\nunaligned. A key challenge in learning from partial, unaligned point cloud data\nis to learn features that are invariant or equivariant with respect to\ngeometric transformations. To address this challenge, we propose the Iterative\nTransformer Network (IT-Net), a network module that canonicalizes the pose of a\npartial object with a series of 3D rigid transformations predicted in an\niterative fashion. We demonstrate the efficacy of IT-Net as an anytime pose\nestimator from partial point clouds without using complete object models.\nFurther, we show that IT-Net achieves superior performance over alternative 3D\ntransformer networks on various tasks, such as partial shape classification and\nobject part segmentation. \n\n"}
{"id": "1811.11304", "contents": "Title: Universal Adversarial Training Abstract: Standard adversarial attacks change the predicted class label of a selected\nimage by adding specially tailored small perturbations to its pixels. In\ncontrast, a universal perturbation is an update that can be added to any image\nin a broad class of images, while still changing the predicted class label. We\nstudy the efficient generation of universal adversarial perturbations, and also\nefficient methods for hardening networks to these attacks. We propose a simple\noptimization-based universal attack that reduces the top-1 accuracy of various\nnetwork architectures on ImageNet to less than 20%, while learning the\nuniversal perturbation 13X faster than the standard method.\n  To defend against these perturbations, we propose universal adversarial\ntraining, which models the problem of robust classifier generation as a\ntwo-player min-max game, and produces robust models with only 2X the cost of\nnatural training. We also propose a simultaneous stochastic gradient method\nthat is almost free of extra computation, which allows us to do universal\nadversarial training on ImageNet. \n\n"}
{"id": "1811.11314", "contents": "Title: Skin lesion segmentation using U-Net and good training strategies Abstract: In this paper we approach the problem of skin lesion segmentation using a\nconvolutional neural network based on the U-Net architecture. We present a set\nof training strategies that had a significant impact on the performance of this\nmodel. We evaluated this method on the ISIC Challenge 2018 - Skin Lesion\nAnalysis Towards Melanoma Detection, obtaining threshold Jaccard index of\n77.5%. \n\n"}
{"id": "1811.11524", "contents": "Title: Multi-granularity Generator for Temporal Action Proposal Abstract: Temporal action proposal generation is an important task, aiming to localize\nthe video segments containing human actions in an untrimmed video. In this\npaper, we propose a multi-granularity generator (MGG) to perform the temporal\naction proposal from different granularity perspectives, relying on the video\nvisual features equipped with the position embedding information. First, we\npropose to use a bilinear matching model to exploit the rich local information\nwithin the video sequence. Afterwards, two components, namely segment proposal\nproducer (SPP) and frame actionness producer (FAP), are combined to perform the\ntask of temporal action proposal at two distinct granularities. SPP considers\nthe whole video in the form of feature pyramid and generates segment proposals\nfrom one coarse perspective, while FAP carries out a finer actionness\nevaluation for each video frame. Our proposed MGG can be trained in an\nend-to-end fashion. By temporally adjusting the segment proposals with\nfine-grained frame actionness information, MGG achieves the superior\nperformance over state-of-the-art methods on the public THUMOS-14 and\nActivityNet-1.3 datasets. Moreover, we employ existing action classifiers to\nperform the classification of the proposals generated by MGG, leading to\nsignificant improvements compared against the competing methods for the video\ndetection task. \n\n"}
{"id": "1811.11606", "contents": "Title: Escaping Plato's Cave: 3D Shape From Adversarial Rendering Abstract: We introduce PlatonicGAN to discover the 3D structure of an object class from\nan unstructured collection of 2D images, i.e., where no relation between photos\nis known, except that they are showing instances of the same category. The key\nidea is to train a deep neural network to generate 3D shapes which, when\nrendered to images, are indistinguishable from ground truth images (for a\ndiscriminator) under various camera poses. Discriminating 2D images instead of\n3D shapes allows tapping into unstructured 2D photo collections instead of\nrelying on curated (e.g., aligned, annotated, etc.) 3D data sets. To establish\nconstraints between 2D image observation and their 3D interpretation, we\nsuggest a family of rendering layers that are effectively differentiable. This\nfamily includes visual hull, absorption-only (akin to x-ray), and\nemission-absorption. We can successfully reconstruct 3D shapes from\nunstructured 2D images and extensively evaluate PlatonicGAN on a range of\nsynthetic and real data sets achieving consistent improvements over baseline\nmethods. We further show that PlatonicGAN can be combined with 3D supervision\nto improve on and in some cases even surpass the quality of 3D-supervised\nmethods. \n\n"}
{"id": "1811.12084", "contents": "Title: Networks for Nonlinear Diffusion Problems in Imaging Abstract: A multitude of imaging and vision tasks have seen recently a major\ntransformation by deep learning methods and in particular by the application of\nconvolutional neural networks. These methods achieve impressive results, even\nfor applications where it is not apparent that convolutions are suited to\ncapture the underlying physics.\n  In this work we develop a network architecture based on nonlinear diffusion\nprocesses, named DiffNet. By design, we obtain a nonlinear network architecture\nthat is well suited for diffusion related problems in imaging. Furthermore, the\nperformed updates are explicit, by which we obtain better interpretability and\ngeneralisability compared to classical convolutional neural network\narchitectures. The performance of DiffNet tested on the inverse problem of\nnonlinear diffusion with the Perona-Malik filter on the STL-10 image dataset.\nWe obtain competitive results to the established U-Net architecture, with a\nfraction of parameters and necessary training data. \n\n"}
{"id": "1811.12231", "contents": "Title: ImageNet-trained CNNs are biased towards texture; increasing shape bias\n  improves accuracy and robustness Abstract: Convolutional Neural Networks (CNNs) are commonly thought to recognise\nobjects by learning increasingly complex representations of object shapes. Some\nrecent studies suggest a more important role of image textures. We here put\nthese conflicting hypotheses to a quantitative test by evaluating CNNs and\nhuman observers on images with a texture-shape cue conflict. We show that\nImageNet-trained CNNs are strongly biased towards recognising textures rather\nthan shapes, which is in stark contrast to human behavioural evidence and\nreveals fundamentally different classification strategies. We then demonstrate\nthat the same standard architecture (ResNet-50) that learns a texture-based\nrepresentation on ImageNet is able to learn a shape-based representation\ninstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\nThis provides a much better fit for human behavioural performance in our\nwell-controlled psychophysical lab setting (nine experiments totalling 48,560\npsychophysical trials across 97 observers) and comes with a number of\nunexpected emergent benefits such as improved object detection performance and\npreviously unseen robustness towards a wide range of image distortions,\nhighlighting advantages of a shape-based representation. \n\n"}
{"id": "1811.12766", "contents": "Title: Model-blind Video Denoising Via Frame-to-frame Training Abstract: Modeling the processing chain that has produced a video is a difficult\nreverse engineering task, even when the camera is available. This makes model\nbased video processing a still more complex task. In this paper we propose a\nfully blind video denoising method, with two versions off-line and on-line.\nThis is achieved by fine-tuning a pre-trained AWGN denoising network to the\nvideo with a novel frame-to-frame training strategy. Our denoiser can be used\nwithout knowledge of the origin of the video or burst and the post processing\nsteps applied from the camera sensor. The on-line process only requires a\ncouple of frames before achieving visually-pleasing results for a wide range of\nperturbations. It nonetheless reaches state of the art performance for standard\nGaussian noise, and can be used off-line with still better performance. \n\n"}
{"id": "1811.12866", "contents": "Title: Super-Resolution via Image-Adapted Denoising CNNs: Incorporating\n  External and Internal Learning Abstract: While deep neural networks exhibit state-of-the-art results in the task of\nimage super-resolution (SR) with a fixed known acquisition process (e.g., a\nbicubic downscaling kernel), they experience a huge performance loss when the\nreal observation model mismatches the one used in training. Recently, two\ndifferent techniques suggested to mitigate this deficiency, i.e., enjoy the\nadvantages of deep learning without being restricted by the training phase. The\nfirst one follows the plug-and-play (P&P) approach that solves general inverse\nproblems (e.g., SR) by using Gaussian denoisers for handling the prior term in\nmodel-based optimization schemes. The second builds on internal recurrence of\ninformation inside a single image, and trains a super-resolver network at test\ntime on examples synthesized from the low-resolution image. Our work\nincorporates these two independent strategies, enjoying the impressive\ngeneralization capabilities of deep learning, captured by the first, and\nfurther improving it through internal learning at test time. First, we apply a\nrecent P&P strategy to SR. Then, we show how it may become image-adaptive in\ntest time. This technique outperforms the above two strategies on popular\ndatasets and gives better results than other state-of-the-art methods in\npractical cases where the observation model is inexact or unknown in advance. \n\n"}
{"id": "1812.00139", "contents": "Title: Number of Connected Components in a Graph: Estimation via Counting\n  Patterns Abstract: Due to the limited resources and the scale of the graphs in modern datasets,\nwe often get to observe a sampled subgraph of a larger original graph of\ninterest, whether it is the worldwide web that has been crawled or social\nconnections that have been surveyed. Inferring a global property of the\noriginal graph from such a sampled subgraph is of a fundamental interest. In\nthis work, we focus on estimating the number of connected components. It is a\nchallenging problem and, for general graphs, little is known about the\nconnection between the observed subgraph and the number of connected components\nof the original graph. In order to make this connection, we propose a highly\nredundant and large-dimensional representation of the subgraph, which at first\nglance seems counter-intuitive. A subgraph is represented by the counts of\npatterns, known as network motifs. This representation is crucial in\nintroducing a novel estimator for the number of connected components for\ngeneral graphs, under the knowledge of the spectral gap of the original graph.\nThe connection is made precise via the Schatten $k$-norms of the graph\nLaplacian and the spectral representation of the number of connected\ncomponents. We provide a guarantee on the resulting mean squared error that\ncharacterizes the bias variance tradeoff. Experiments on synthetic and\nreal-world graphs suggest that we improve upon competing algorithms for graphs\nwith spectral gaps bounded away from zero. \n\n"}
{"id": "1812.00332", "contents": "Title: ProxylessNAS: Direct Neural Architecture Search on Target Task and\n  Hardware Abstract: Neural architecture search (NAS) has a great impact by automatically\ndesigning effective neural network architectures. However, the prohibitive\ncomputational demand of conventional NAS algorithms (e.g. $10^4$ GPU hours)\nmakes it difficult to \\emph{directly} search the architectures on large-scale\ntasks (e.g. ImageNet). Differentiable NAS can reduce the cost of GPU hours via\na continuous representation of network architecture but suffers from the high\nGPU memory consumption issue (grow linearly w.r.t. candidate set size). As a\nresult, they need to utilize~\\emph{proxy} tasks, such as training on a smaller\ndataset, or learning with only a few blocks, or training just for a few epochs.\nThese architectures optimized on proxy tasks are not guaranteed to be optimal\non the target task. In this paper, we present \\emph{ProxylessNAS} that can\n\\emph{directly} learn the architectures for large-scale target tasks and target\nhardware platforms. We address the high memory consumption issue of\ndifferentiable NAS and reduce the computational cost (GPU hours and GPU memory)\nto the same level of regular training while still allowing a large candidate\nset. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of\ndirectness and specialization. On CIFAR-10, our model achieves 2.08\\% test\nerror with only 5.7M parameters, better than the previous state-of-the-art\narchitecture AmoebaNet-B, while using 6$\\times$ fewer parameters. On ImageNet,\nour model achieves 3.1\\% better top-1 accuracy than MobileNetV2, while being\n1.2$\\times$ faster with measured GPU latency. We also apply ProxylessNAS to\nspecialize neural architectures for hardware with direct hardware metrics (e.g.\nlatency) and provide insights for efficient CNN architecture design. \n\n"}
{"id": "1812.00488", "contents": "Title: DeepLiDAR: Deep Surface Normal Guided Depth Prediction for Outdoor Scene\n  from Sparse LiDAR Data and Single Color Image Abstract: In this paper, we propose a deep learning architecture that produces accurate\ndense depth for the outdoor scene from a single color image and a sparse depth.\nInspired by the indoor depth completion, our network estimates surface normals\nas the intermediate representation to produce dense depth, and can be trained\nend-to-end. With a modified encoder-decoder structure, our network effectively\nfuses the dense color image and the sparse LiDAR depth. To address outdoor\nspecific challenges, our network predicts a confidence mask to handle mixed\nLiDAR signals near foreground boundaries due to occlusion, and combines\nestimates from the color image and surface normals with learned attention maps\nto improve the depth accuracy especially for distant areas. Extensive\nexperiments demonstrate that our model improves upon the state-of-the-art\nperformance on KITTI depth completion benchmark. Ablation study shows the\npositive impact of each model components to the final performance, and\ncomprehensive analysis shows that our model generalizes well to the input with\nhigher sparsity or from indoor scenes. \n\n"}
{"id": "1812.00883", "contents": "Title: Relation Networks for Optic Disc and Fovea Localization in Retinal\n  Images Abstract: Diabetic Retinopathy is the leading cause of blindness in the world. At least\n90\\% of new cases can be reduced with proper treatment and monitoring of the\neyes. However, scanning the entire population of patients is a difficult\nendeavor. Computer-aided diagnosis tools in retinal image analysis can make the\nprocess scalable and efficient. In this work, we focus on the problem of\nlocalizing the centers of the Optic disc and Fovea, a task crucial to the\nanalysis of retinal scans. Current systems recognize the Optic disc and Fovea\nindividually, without exploiting their relations during learning. We propose a\nnovel approach to localizing the centers of the Optic disc and Fovea by\nsimultaneously processing them and modeling their relative geometry and\nappearance. We show that our approach improves localization and recognition by\nincorporating object-object relations efficiently, and achieves highly\ncompetitive results. \n\n"}
{"id": "1812.01053", "contents": "Title: MS-ASL: A Large-Scale Data Set and Benchmark for Understanding American\n  Sign Language Abstract: Sign language recognition is a challenging and often underestimated problem\ncomprising multi-modal articulators (handshape, orientation, movement, upper\nbody and face) that integrate asynchronously on multiple streams. Learning\npowerful statistical models in such a scenario requires much data, particularly\nto apply recent advances of the field. However, labeled data is a scarce\nresource for sign language due to the enormous cost of transcribing these\nunwritten languages.\n  We propose the first real-life large-scale sign language data set comprising\nover 25,000 annotated videos, which we thoroughly evaluate with\nstate-of-the-art methods from sign and related action recognition. Unlike the\ncurrent state-of-the-art, the data set allows to investigate the generalization\nto unseen individuals (signer-independent test) in a realistic setting with\nover 200 signers. Previous work mostly deals with limited vocabulary tasks,\nwhile here, we cover a large class count of 1000 signs in challenging and\nunconstrained real-life recording conditions. We further propose I3D, known\nfrom video classifications, as a powerful and suitable architecture for sign\nlanguage recognition, outperforming the current state-of-the-art by a large\nmargin. The data set is publicly available to the community. \n\n"}
{"id": "1812.01222", "contents": "Title: Ladder Networks for Semi-Supervised Hyperspectral Image Classification Abstract: We used the Ladder Network [Rasmus et al. (2015)] to perform Hyperspectral\nImage Classification in a semi-supervised setting. The Ladder Network\ndistinguishes itself from other semi-supervised methods by jointly optimizing a\nsupervised and unsupervised cost. In many settings this has proven to be more\nsuccessful than other semi-supervised techniques, such as pretraining using\nunlabeled data. We furthermore show that the convolutional Ladder Network\noutperforms most of the current techniques used in hyperspectral image\nclassification and achieves new state-of-the-art performance on the Pavia\nUniversity dataset given only 5 labeled data points per class. \n\n"}
{"id": "1812.01397", "contents": "Title: Meta Learning Deep Visual Words for Fast Video Object Segmentation Abstract: Personal robots and driverless cars need to be able to operate in novel\nenvironments and thus quickly and efficiently learn to recognise new object\nclasses. We address this problem by considering the task of video object\nsegmentation. Previous accurate methods for this task finetune a model using\nthe first annotated frame, and/or use additional inputs such as optical flow\nand complex post-processing. In contrast, we develop a fast, causal algorithm\nthat requires no finetuning, auxiliary inputs or post-processing, and segments\na variable number of objects in a single forward-pass. We represent an object\nwith clusters, or \"visual words\", in the embedding space, which correspond to\nobject parts in the image space. This allows us to robustly match to the\nreference objects throughout the video, because although the global appearance\nof an object changes as it undergoes occlusions and deformations, the\nappearance of more local parts may stay consistent. We learn these visual words\nin an unsupervised manner, using meta-learning to ensure that our training\nobjective matches our inference procedure. We achieve comparable accuracy to\nfinetuning based methods (whilst being 1 to 2 orders of magnitude faster), and\nstate-of-the-art in terms of speed/accuracy trade-offs on four video\nsegmentation datasets. Code is available at\nhttps://github.com/harkiratbehl/MetaVOS. \n\n"}
{"id": "1812.01690", "contents": "Title: General-to-Detailed GAN for Infrequent Class Medical Images Abstract: Deep learning has significant potential for medical imaging. However, since\nthe incident rate of each disease varies widely, the frequency of classes in a\nmedical image dataset is imbalanced, leading to poor accuracy for such\ninfrequent classes. One possible solution is data augmentation of infrequent\nclasses using synthesized images created by Generative Adversarial Networks\n(GANs), but conventional GANs also require certain amount of images to learn.\nTo overcome this limitation, here we propose General-to-detailed GAN (GDGAN),\nserially connected two GANs, one for general labels and the other for detailed\nlabels. GDGAN produced diverse medical images, and the network trained with an\naugmented dataset outperformed other networks using existing methods with\nrespect to Area-Under-Curve (AUC) of Receiver Operating Characteristic (ROC)\ncurve. \n\n"}
{"id": "1812.01710", "contents": "Title: GANtruth - an unpaired image-to-image translation method for driving\n  scenarios Abstract: Synthetic image translation has significant potentials in autonomous\ntransportation systems. That is due to the expense of data collection and\nannotation as well as the unmanageable diversity of real-words situations. The\nmain issue with unpaired image-to-image translation is the ill-posed nature of\nthe problem. In this work, we propose a novel method for constraining the\noutput space of unpaired image-to-image translation. We make the assumption\nthat the environment of the source domain is known (e.g. synthetically\ngenerated), and we propose to explicitly enforce preservation of the\nground-truth labels on the translated images.\n  We experiment on preserving ground-truth information such as semantic\nsegmentation, disparity, and instance segmentation. We show significant\nevidence that our method achieves improved performance over the\nstate-of-the-art model of UNIT for translating images from SYNTHIA to\nCityscapes. The generated images are perceived as more realistic in human\nsurveys and outperforms UNIT when used in a domain adaptation scenario for\nsemantic segmentation. \n\n"}
{"id": "1812.01713", "contents": "Title: FineFool: Fine Object Contour Attack via Attention Abstract: Machine learning models have been shown vulnerable to adversarial attacks\nlaunched by adversarial examples which are carefully crafted by attacker to\ndefeat classifiers. Deep learning models cannot escape the attack either. Most\nof adversarial attack methods are focused on success rate or perturbations\nsize, while we are more interested in the relationship between adversarial\nperturbation and the image itself. In this paper, we put forward a novel\nadversarial attack based on contour, named FineFool. Finefool not only has\nbetter attack performance compared with other state-of-art white-box attacks in\naspect of higher attack success rate and smaller perturbation, but also capable\nof visualization the optimal adversarial perturbation via attention on object\ncontour. To the best of our knowledge, Finefool is for the first time combines\nthe critical feature of the original clean image with the optimal perturbations\nin a visible manner. Inspired by the correlations between adversarial\nperturbations and object contour, slighter perturbations is produced via\nfocusing on object contour features, which is more imperceptible and difficult\nto be defended, especially network add-on defense methods with the trade-off\nbetween perturbations filtering and contour feature loss. Compared with\nexisting state-of-art attacks, extensive experiments are conducted to show that\nFinefool is capable of efficient attack against defensive deep models. \n\n"}
{"id": "1812.01718", "contents": "Title: Deep Learning for Classical Japanese Literature Abstract: Much of machine learning research focuses on producing models which perform\nwell on benchmark tasks, in turn improving our understanding of the challenges\nassociated with those tasks. From the perspective of ML researchers, the\ncontent of the task itself is largely irrelevant, and thus there have\nincreasingly been calls for benchmark tasks to more heavily focus on problems\nwhich are of social or cultural relevance. In this work, we introduce\nKuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as\nwell as two larger, more challenging datasets, Kuzushiji-49 and\nKuzushiji-Kanji. Through these datasets, we wish to engage the machine learning\ncommunity into the world of classical Japanese literature. Dataset available at\nhttps://github.com/rois-codh/kmnist \n\n"}
{"id": "1812.01739", "contents": "Title: Benchmarking Keyword Spotting Efficiency on Neuromorphic Hardware Abstract: Using Intel's Loihi neuromorphic research chip and ABR's Nengo Deep Learning\ntoolkit, we analyze the inference speed, dynamic power consumption, and energy\ncost per inference of a two-layer neural network keyword spotter trained to\nrecognize a single phrase. We perform comparative analyses of this keyword\nspotter running on more conventional hardware devices including a CPU, a GPU,\nNvidia's Jetson TX1, and the Movidius Neural Compute Stick. Our results\nindicate that for this inference application, Loihi outperforms all of these\nalternatives on an energy cost per inference basis while maintaining equivalent\ninference accuracy. Furthermore, an analysis of tradeoffs between network size,\ninference speed, and energy cost indicates that Loihi's comparative advantage\nover other low-power computing devices improves for larger networks. \n\n"}
{"id": "1812.01969", "contents": "Title: Summarizing Videos with Attention Abstract: In this work we propose a novel method for supervised, keyshots based video\nsummarization by applying a conceptually simple and computationally efficient\nsoft, self-attention mechanism. Current state of the art methods leverage\nbi-directional recurrent networks such as BiLSTM combined with attention. These\nnetworks are complex to implement and computationally demanding compared to\nfully connected networks. To that end we propose a simple, self-attention based\nnetwork for video summarization which performs the entire sequence to sequence\ntransformation in a single feed forward pass and single backward pass during\ntraining. Our method sets a new state of the art results on two benchmarks\nTvSum and SumMe, commonly used in this domain. \n\n"}
{"id": "1812.02831", "contents": "Title: Neural Image Decompression: Learning to Render Better Image Previews Abstract: A rapidly increasing portion of Internet traffic is dominated by requests\nfrom mobile devices with limited- and metered-bandwidth constraints. To satisfy\nthese requests, it has become standard practice for websites to transmit small\nand extremely compressed image previews as part of the initial page-load\nprocess. Recent work, based on an adaptive triangulation of the target image,\nhas shown the ability to generate thumbnails of full images at extreme\ncompression rates: 200 bytes or less with impressive gains (in terms of PSNR\nand SSIM) over both JPEG and WebP standards. However, qualitative assessments\nand preservation of semantic content can be less favorable. We present a novel\nmethod to significantly improve the reconstruction quality of the original\nimage with no changes to the encoded information. Our neural-based decoding not\nonly achieves higher PSNR and SSIM scores than the original methods, but also\nyields a substantial increase in semantic-level content preservation. In\naddition, by keeping the same encoding stream, our solution is completely\ninter-operable with the original decoder. The end result is suitable for a\nrange of small-device deployments, as it involves only a single forward-pass\nthrough a small, scalable network. \n\n"}
{"id": "1812.02849", "contents": "Title: A Survey of Unsupervised Deep Domain Adaptation Abstract: Deep learning has produced state-of-the-art results for a variety of tasks.\nWhile such approaches for supervised learning have performed well, they assume\nthat training and testing data are drawn from the same distribution, which may\nnot always be the case. As a complement to this challenge, single-source\nunsupervised domain adaptation can handle situations where a network is trained\non labeled data from a source domain and unlabeled data from a related but\ndifferent target domain with the goal of performing well at test-time on the\ntarget domain. Many single-source and typically homogeneous unsupervised deep\ndomain adaptation approaches have thus been developed, combining the powerful,\nhierarchical representations from deep learning with domain adaptation to\nreduce reliance on potentially-costly target data labels. This survey will\ncompare these approaches by examining alternative methods, the unique and\ncommon elements, results, and theoretical insights. We follow this with a look\nat application areas and open research directions. \n\n"}
{"id": "1812.02863", "contents": "Title: Privacy Partitioning: Protecting User Data During the Deep Learning\n  Inference Phase Abstract: We present a practical method for protecting data during the inference phase\nof deep learning based on bipartite topology threat modeling and an interactive\nadversarial deep network construction. We term this approach \\emph{Privacy\nPartitioning}. In the proposed framework, we split the machine learning models\nand deploy a few layers into users' local devices, and the rest of the layers\ninto a remote server. We propose an approach to protect user's data during the\ninference phase, while still achieve good classification accuracy.\n  We conduct an experimental evaluation of this approach on benchmark datasets\nof three computer vision tasks. The experimental results indicate that this\napproach can be used to significantly attenuate the capacity for an adversary\nwith access to the state-of-the-art deep network's intermediate states to learn\nprivacy-sensitive inputs to the network. For example, we demonstrate that our\napproach can prevent attackers from inferring the private attributes such as\ngender from the Face image dataset without sacrificing the classification\naccuracy of the original machine learning task such as Face Identification. \n\n"}
{"id": "1812.02967", "contents": "Title: Scale-aware multi-level guidance for interactive instance segmentation Abstract: In interactive instance segmentation, users give feedback to iteratively\nrefine segmentation masks. The user-provided clicks are transformed into\nguidance maps which provide the network with necessary cues on the whereabouts\nof the object of interest. Guidance maps used in current systems are purely\ndistance-based and are either too localized or non-informative. We propose a\nnovel transformation of user clicks to generate scale-aware guidance maps that\nleverage the hierarchical structural information present in an image. Using our\nguidance maps, even the most basic FCNs are able to outperform existing\napproaches that require state-of-the-art segmentation networks pre-trained on\nlarge scale segmentation datasets. We demonstrate the effectiveness of our\nproposed transformation strategy through comprehensive experimentation in which\nwe significantly raise state-of-the-art on four standard interactive\nsegmentation benchmarks. \n\n"}
{"id": "1812.03170", "contents": "Title: Variational Saccading: Efficient Inference for Large Resolution Images Abstract: Image classification with deep neural networks is typically restricted to\nimages of small dimensionality such as 224 x 244 in Resnet models [24]. This\nlimitation excludes the 4000 x 3000 dimensional images that are taken by modern\nsmartphone cameras and smart devices. In this work, we aim to mitigate the\nprohibitive inferential and memory costs of operating in such large dimensional\nspaces. To sample from the high-resolution original input distribution, we\npropose using a smaller proxy distribution to learn the co-ordinates that\ncorrespond to regions of interest in the high-dimensional space. We introduce a\nnew principled variational lower bound that captures the relationship of the\nproxy distribution's posterior and the original image's co-ordinate space in a\nway that maximizes the conditional classification likelihood. We empirically\ndemonstrate on one synthetic benchmark and one real world large resolution DSLR\ncamera image dataset that our method produces comparable results with ~10x\nfaster inference and lower memory consumption than a model that utilizes the\nentire original input distribution. Finally, we experiment with a more complex\nsetting using mini-maps from Starcraft II [56] to infer the number of\ncharacters in a complex 3d-rendered scene. Even in such complicated scenes our\nmodel provides strong localization: a feature missing from traditional\nclassification models. \n\n"}
{"id": "1812.03205", "contents": "Title: Harmonic Networks: Integrating Spectral Information into CNNs Abstract: Convolutional neural networks (CNNs) learn filters in order to capture local\ncorrelation patterns in feature space. In contrast, in this paper we propose\nharmonic blocks that produce features by learning optimal combinations of\nspectral filters defined by the Discrete Cosine Transform. The harmonic blocks\nare used to replace conventional convolutional layers to construct partial or\nfully harmonic CNNs. We extensively validate our approach and show that the\nintroduction of harmonic blocks into state-of-the-art CNN baseline\narchitectures results in comparable or better performance in classification\ntasks on small NORB, CIFAR10 and CIFAR100 datasets. \n\n"}
{"id": "1812.03252", "contents": "Title: Face Completion with Semantic Knowledge and Collaborative Adversarial\n  Learning Abstract: Unlike a conventional background inpainting approach that infers a missing\narea from image patches similar to the background, face completion requires\nsemantic knowledge about the target object for realistic outputs. Current image\ninpainting approaches utilize generative adversarial networks (GANs) to achieve\nsuch semantic understanding. However, in adversarial learning, the semantic\nknowledge is learned implicitly and hence good semantic understanding is not\nalways guaranteed. In this work, we propose a collaborative adversarial\nlearning approach to face completion to explicitly induce the training process.\nOur method is formulated under a novel generative framework called\ncollaborative GAN (collaGAN), which allows better semantic understanding of a\ntarget object through collaborative learning of multiple tasks including face\ncompletion, landmark detection, and semantic segmentation. Together with the\ncollaGAN, we also introduce an inpainting concentrated scheme such that the\nmodel emphasizes more on inpainting instead of autoencoding. Extensive\nexperiments show that the proposed designs are indeed effective and\ncollaborative adversarial learning provides better feature representations of\nthe faces. In comparison with other generative image inpainting models and\nsingle task learning methods, our solution produces superior performances on\nall tasks. \n\n"}
{"id": "1812.03253", "contents": "Title: Counterfactuals uncover the modular structure of deep generative models Abstract: Deep generative models can emulate the perceptual properties of complex image\ndatasets, providing a latent representation of the data. However, manipulating\nsuch representation to perform meaningful and controllable transformations in\nthe data space remains challenging without some form of supervision. While\nprevious work has focused on exploiting statistical independence to disentangle\nlatent factors, we argue that such requirement is too restrictive and propose\ninstead a non-statistical framework that relies on counterfactual manipulations\nto uncover a modular structure of the network composed of disentangled groups\nof internal variables. Experiments with a variety of generative models trained\non complex image datasets show the obtained modules can be used to design\ntargeted interventions. This opens the way to applications such as\ncomputationally efficient style transfer and the automated assessment of\nrobustness to contextual changes in pattern recognition systems. \n\n"}
{"id": "1812.03664", "contents": "Title: Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions Abstract: Learning with limited data is a key challenge for visual recognition. Many\nfew-shot learning methods address this challenge by learning an instance\nembedding function from seen classes and apply the function to instances from\nunseen classes with limited labels. This style of transfer learning is\ntask-agnostic: the embedding function is not learned optimally discriminative\nwith respect to the unseen classes, where discerning among them leads to the\ntarget task. In this paper, we propose a novel approach to adapt the instance\nembeddings to the target classification task with a set-to-set function,\nyielding embeddings that are task-specific and are discriminative. We\nempirically investigated various instantiations of such set-to-set functions\nand observed the Transformer is most effective -- as it naturally satisfies key\nproperties of our desired model. We denote this model as FEAT (few-shot\nembedding adaptation w/ Transformer) and validate it on both the standard\nfew-shot classification benchmark and four extended few-shot learning settings\nwith essential use cases, i.e., cross-domain, transductive, generalized\nfew-shot learning, and low-shot learning. It archived consistent improvements\nover baseline models as well as previous methods and established the new\nstate-of-the-art results on two benchmarks. \n\n"}
{"id": "1812.04351", "contents": "Title: Multichannel Semantic Segmentation with Unsupervised Domain Adaptation Abstract: Most contemporary robots have depth sensors, and research on semantic\nsegmentation with RGBD images has shown that depth images boost the accuracy of\nsegmentation. Since it is time-consuming to annotate images with semantic\nlabels per pixel, it would be ideal if we could avoid this laborious work by\nutilizing an existing dataset or a synthetic dataset which we can generate on\nour own. Robot motions are often tested in a synthetic environment, where\nmultichannel (eg, RGB + depth + instance boundary) images plus their\npixel-level semantic labels are available. However, models trained simply on\nsynthetic images tend to demonstrate poor performance on real images. In order\nto address this, we propose two approaches that can efficiently exploit\nmultichannel inputs combined with an unsupervised domain adaptation (UDA)\nalgorithm. One is a fusion-based approach that uses depth images as inputs. The\nother is a multitask learning approach that uses depth images as outputs. We\ndemonstrated that the segmentation results were improved by using a multitask\nlearning approach with a post-process and created a benchmark for this task. \n\n"}
{"id": "1812.04448", "contents": "Title: seq2graph: Discovering Dynamic Dependencies from Multivariate Time\n  Series with Multi-level Attention Abstract: Discovering temporal lagged and inter-dependencies in multivariate time\nseries data is an important task. However, in many real-world applications,\nsuch as commercial cloud management, manufacturing predictive maintenance, and\nportfolios performance analysis, such dependencies can be non-linear and\ntime-variant, which makes it more challenging to extract such dependencies\nthrough traditional methods such as Granger causality or clustering. In this\nwork, we present a novel deep learning model that uses multiple layers of\ncustomized gated recurrent units (GRUs) for discovering both time lagged\nbehaviors as well as inter-timeseries dependencies in the form of directed\nweighted graphs. We introduce a key component of Dual-purpose recurrent neural\nnetwork that decodes information in the temporal domain to discover lagged\ndependencies within each time series, and encodes them into a set of vectors\nwhich, collected from all component time series, form the informative inputs to\ndiscover inter-dependencies. Though the discovery of two types of dependencies\nare separated at different hierarchical levels, they are tightly connected and\njointly trained in an end-to-end manner. With this joint training, learning of\none type of dependency immediately impacts the learning of the other one,\nleading to overall accurate dependencies discovery. We empirically test our\nmodel on synthetic time series data in which the exact form of (non-linear)\ndependencies is known. We also evaluate its performance on two real-world\napplications, (i) performance monitoring data from a commercial cloud provider,\nwhich exhibit highly dynamic, non-linear, and volatile behavior and, (ii)\nsensor data from a manufacturing plant. We further show how our approach is\nable to capture these dependency behaviors via intuitive and interpretable\ndependency graphs and use them to generate highly accurate forecasts. \n\n"}
{"id": "1812.04778", "contents": "Title: Bridging the Generalization Gap: Training Robust Models on Confounded\n  Biological Data Abstract: Statistical learning on biological data can be challenging due to confounding\nvariables in sample collection and processing. Confounders can cause models to\ngeneralize poorly and result in inaccurate prediction performance metrics if\nmodels are not validated thoroughly. In this paper, we propose methods to\ncontrol for confounding factors and further improve prediction performance. We\nintroduce OrthoNormal basis construction In cOnfounding factor Normalization\n(ONION) to remove confounding covariates and use the Domain-Adversarial Neural\nNetwork (DANN) to penalize models for encoding confounder information. We apply\nthe proposed methods to simulated and empirical patient data and show\nsignificant improvements in generalization. \n\n"}
{"id": "1812.04912", "contents": "Title: EasiCSDeep: A deep learning model for Cervical Spondylosis\n  Identification using surface electromyography signal Abstract: Cervical spondylosis (CS) is a common chronic disease that affects up to\ntwo-thirds of the population and poses a serious burden on individuals and\nsociety. The early identification has significant value in improving cure rate\nand reducing costs. However, the pathology is complex, and the mild symptoms\nincrease the difficulty of the diagnosis, especially in the early stage.\nBesides, the time-consuming and costliness of hospital medical service reduces\nthe attention to the CS identification. Thus, a convenient, low-cost\nintelligent CS identification method is imperious demanded. In this paper, we\npresent an intelligent method based on the deep learning to identify CS, using\nthe surface electromyography (sEMG) signal. Faced with the complex, high\ndimensionality and weak usability of the sEMG signal, we proposed and developed\na multi-channel EasiCSDeep algorithm based on the convolutional neural network,\nwhich consists of the feature extraction, spatial relationship representation\nand classification algorithm. To the best of our knowledge, this EasiCSDeep is\nthe first effort to employ the deep learning and the sEMG data to identify CS.\nCompared with previous state-of-the-art algorithm, our algorithm achieves a\nsignificant improvement. \n\n"}
{"id": "1812.05038", "contents": "Title: Long-Term Feature Banks for Detailed Video Understanding Abstract: To understand the world, we humans constantly need to relate the present to\nthe past, and put events in context. In this paper, we enable existing video\nmodels to do the same. We propose a long-term feature bank---supportive\ninformation extracted over the entire span of a video---to augment\nstate-of-the-art video models that otherwise would only view short clips of 2-5\nseconds. Our experiments demonstrate that augmenting 3D convolutional networks\nwith a long-term feature bank yields state-of-the-art results on three\nchallenging video datasets: AVA, EPIC-Kitchens, and Charades. \n\n"}
{"id": "1812.05040", "contents": "Title: Learning Semantic Segmentation from Synthetic Data: A Geometrically\n  Guided Input-Output Adaptation Approach Abstract: Recently, increasing attention has been drawn to training semantic\nsegmentation models using synthetic data and computer-generated annotation.\nHowever, domain gap remains a major barrier and prevents models learned from\nsynthetic data from generalizing well to real-world applications. In this work,\nwe take the advantage of additional geometric information from synthetic data,\na powerful yet largely neglected cue, to bridge the domain gap. Such geometric\ninformation can be generated easily from synthetic data, and is proven to be\nclosely coupled with semantic information. With the geometric information, we\npropose a model to reduce domain shift on two levels: on the input level, we\naugment the traditional image translation network with the additional geometric\ninformation to translate synthetic images into realistic styles; on the output\nlevel, we build a task network which simultaneously performs depth estimation\nand semantic segmentation on the synthetic data. Meanwhile, we encourage the\nnetwork to preserve correlation between depth and semantics by adversarial\ntraining on the output space. We then validate our method on two pairs of\nsynthetic to real dataset: Virtual KITTI to KITTI, and SYNTHIA to Cityscapes,\nwhere we achieve a significant performance gain compared to the non-adapt\nbaseline and methods using only semantic label. This demonstrates the\nusefulness of geometric information from synthetic data for cross-domain\nsemantic segmentation. \n\n"}
{"id": "1812.05252", "contents": "Title: Dynamic Fusion with Intra- and Inter- Modality Attention Flow for Visual\n  Question Answering Abstract: Learning effective fusion of multi-modality features is at the heart of\nvisual question answering. We propose a novel method of dynamically fusing\nmulti-modal features with intra- and inter-modality information flow, which\nalternatively pass dynamic information between and across the visual and\nlanguage modalities. It can robustly capture the high-level interactions\nbetween language and vision domains, thus significantly improves the\nperformance of visual question answering. We also show that the proposed\ndynamic intra-modality attention flow conditioned on the other modality can\ndynamically modulate the intra-modality attention of the target modality, which\nis vital for multimodality feature fusion. Experimental evaluations on the VQA\n2.0 dataset show that the proposed method achieves state-of-the-art VQA\nperformance. Extensive ablation studies are carried out for the comprehensive\nanalysis of the proposed method. \n\n"}
{"id": "1812.05262", "contents": "Title: ELASTIC: Improving CNNs with Dynamic Scaling Policies Abstract: Scale variation has been a challenge from traditional to modern approaches in\ncomputer vision. Most solutions to scale issues have a similar theme: a set of\nintuitive and manually designed policies that are generic and fixed (e.g. SIFT\nor feature pyramid). We argue that the scaling policy should be learned from\ndata. In this paper, we introduce ELASTIC, a simple, efficient and yet very\neffective approach to learn a dynamic scale policy from data. We formulate the\nscaling policy as a non-linear function inside the network's structure that (a)\nis learned from data, (b) is instance specific, (c) does not add extra\ncomputation, and (d) can be applied on any network architecture. We applied\nELASTIC to several state-of-the-art network architectures and showed consistent\nimprovement without extra (sometimes even lower) computation on ImageNet\nclassification, MSCOCO multi-label classification, and PASCAL VOC semantic\nsegmentation. Our results show major improvement for images with scale\nchallenges. Our code is available here: https://github.com/allenai/elastic \n\n"}
{"id": "1812.06181", "contents": "Title: Efficient Interpretation of Deep Learning Models Using Graph Structure\n  and Cooperative Game Theory: Application to ASD Biomarker Discovery Abstract: Discovering imaging biomarkers for autism spectrum disorder (ASD) is critical\nto help explain ASD and predict or monitor treatment outcomes. Toward this end,\ndeep learning classifiers have recently been used for identifying ASD from\nfunctional magnetic resonance imaging (fMRI) with higher accuracy than\ntraditional learning strategies. However, a key challenge with deep learning\nmodels is understanding just what image features the network is using, which\ncan in turn be used to define the biomarkers. Current methods extract\nbiomarkers, i.e., important features, by looking at how the prediction changes\nif \"ignoring\" one feature at a time. In this work, we go beyond looking at only\nindividual features by using Shapley value explanation (SVE) from cooperative\ngame theory. Cooperative game theory is advantageous here because it directly\nconsiders the interaction between features and can be applied to any machine\nlearning method, making it a novel, more accurate way of determining\ninstance-wise biomarker importance from deep learning models. A barrier to\nusing SVE is its computational complexity: $2^N$ given $N$ features. We\nexplicitly reduce the complexity of SVE computation by two approaches based on\nthe underlying graph structure of the input data: 1) only consider the\ncentralized coalition of each feature; 2) a hierarchical pipeline which first\nclusters features into small communities, then applies SVE in each community.\nMonte Carlo approximation can be used for large permutation sets. We first\nvalidate our methods on the MNIST dataset and compare to human perception.\nNext, to insure plausibility of our biomarker results, we train a Random Forest\n(RF) to classify ASD/control subjects from fMRI and compare SVE results to\nstandard RF-based feature importance. Finally, we show initial results on\nranked fMRI biomarkers using SVE on a deep learning classifier for the\nASD/control dataset. \n\n"}
{"id": "1812.06589", "contents": "Title: Arbitrary Talking Face Generation via Attentional Audio-Visual Coherence\n  Learning Abstract: Talking face generation aims to synthesize a face video with precise lip\nsynchronization as well as a smooth transition of facial motion over the entire\nvideo via the given speech clip and facial image. Most existing methods mainly\nfocus on either disentangling the information in a single image or learning\ntemporal information between frames. However, cross-modality coherence between\naudio and video information has not been well addressed during synthesis. In\nthis paper, we propose a novel arbitrary talking face generation framework by\ndiscovering the audio-visual coherence via the proposed Asymmetric Mutual\nInformation Estimator (AMIE). In addition, we propose a Dynamic Attention (DA)\nblock by selectively focusing the lip area of the input image during the\ntraining stage, to further enhance lip synchronization. Experimental results on\nbenchmark LRW dataset and GRID dataset transcend the state-of-the-art methods\non prevalent metrics with robust high-resolution synthesizing on gender and\npose variations. \n\n"}
{"id": "1812.06861", "contents": "Title: Taking a Deeper Look at the Inverse Compositional Algorithm Abstract: In this paper, we provide a modern synthesis of the classic inverse\ncompositional algorithm for dense image alignment. We first discuss the\nassumptions made by this well-established technique, and subsequently propose\nto relax these assumptions by incorporating data-driven priors into this model.\nMore specifically, we unroll a robust version of the inverse compositional\nalgorithm and replace multiple components of this algorithm using more\nexpressive models whose parameters we train in an end-to-end fashion from data.\nOur experiments on several challenging 3D rigid motion estimation tasks\ndemonstrate the advantages of combining optimization with learning-based\ntechniques, outperforming the classic inverse compositional algorithm as well\nas data-driven image-to-pose regression approaches. \n\n"}
{"id": "1812.06968", "contents": "Title: Geometric Scattering on Manifolds Abstract: The Euclidean scattering transform was introduced nearly a decade ago to\nimprove the mathematical understanding of the success of convolutional neural\nnetworks (ConvNets) in image data analysis and other tasks. Inspired by recent\ninterest in geometric deep learning, which aims to generalize ConvNets to\nmanifold and graph-structured domains, we generalize the scattering transform\nto compact manifolds. Similar to the Euclidean scattering transform, our\ngeometric scattering transform is based on a cascade of designed filters and\npointwise nonlinearities, which enables rigorous analysis of the feature\nextraction provided by scattering layers. Our main focus here is on theoretical\nunderstanding of this geometric scattering network, while setting aside\nimplementation aspects, although we remark that application of similar\ntransforms to graph data analysis has been studied recently in related work.\nOur results establish conditions under which geometric scattering provides\nlocalized isometry invariant descriptions of manifold signals, which are also\nstable to families of diffeomorphisms formulated in intrinsic manifolds terms.\nThese results not only generalize the deformation stability and local\nroto-translation invariance of Euclidean scattering, but also demonstrate the\nimportance of linking the used filter structures (e.g., in geometric deep\nlearning) to the underlying manifold geometry, or the data geometry it\nrepresents. \n\n"}
{"id": "1812.07049", "contents": "Title: DSNet for Real-Time Driving Scene Semantic Segmentation Abstract: We focus on the very challenging task of semantic segmentation for autonomous\ndriving system. It must deliver decent semantic segmentation result for traffic\ncritical objects real-time. In this paper, we propose a very efficient yet\npowerful deep neural network for driving scene semantic segmentation termed as\nDriving Segmentation Network (DSNet). DSNet achieves state-of-the-art balance\nbetween accuracy and inference speed through efficient units and architecture\ndesign inspired by ShuffleNet V2 and ENet. More importantly, DSNet highlights\nclasses most critical with driving decision making through our novel Driving\nImportance-weighted Loss. We evaluate DSNet on Cityscapes dataset, our DSNet\nachieves 71.8% mean Intersection-over-Union (IoU) on validation set and 69.3%\non test set. Class-wise IoU scores show that Driving Importance-weighted Loss\ncould improve most driving critical classes by a large margin. Compared with\nENet, DSNet is 18.9% more accurate and 1.1+ times faster which implies great\npotential for autonomous driving application. \n\n"}
{"id": "1812.07102", "contents": "Title: Deep Learning with Attention to Predict Gestational Age of the Fetal\n  Brain Abstract: Fetal brain imaging is a cornerstone of prenatal screening and early\ndiagnosis of congenital anomalies. Knowledge of fetal gestational age is the\nkey to the accurate assessment of brain development. This study develops an\nattention-based deep learning model to predict gestational age of the fetal\nbrain. The proposed model is an end-to-end framework that combines key insights\nfrom multi-view MRI including axial, coronal, and sagittal views. The model\nalso uses age-activated weakly-supervised attention maps to enable\nrotation-invariant localization of the fetal brain among background noise. We\nevaluate our methods on the collected fetal brain MRI cohort with a large age\ndistribution from 125 to 273 days. Our extensive experiments show age\nprediction performance with R2 = 0.94 using multi-view MRI and attention. \n\n"}
{"id": "1812.07103", "contents": "Title: Style Transfer and Extraction for the Handwritten Letters Using Deep\n  Learning Abstract: How can we learn, transfer and extract handwriting styles using deep neural\nnetworks? This paper explores these questions using a deep conditioned\nautoencoder on the IRON-OFF handwriting data-set. We perform three experiments\nthat systematically explore the quality of our style extraction procedure.\nFirst, We compare our model to handwriting benchmarks using multidimensional\nperformance metrics. Second, we explore the quality of style transfer, i.e. how\nthe model performs on new, unseen writers. In both experiments, we improve the\nmetrics of state of the art methods by a large margin. Lastly, we analyze the\nlatent space of our model, and we see that it separates consistently writing\nstyles. \n\n"}
{"id": "1812.08156", "contents": "Title: Unsupervised Event-based Learning of Optical Flow, Depth, and Egomotion Abstract: In this work, we propose a novel framework for unsupervised learning for\nevent cameras that learns motion information from only the event stream. In\nparticular, we propose an input representation of the events in the form of a\ndiscretized volume that maintains the temporal distribution of the events,\nwhich we pass through a neural network to predict the motion of the events.\nThis motion is used to attempt to remove any motion blur in the event image. We\nthen propose a loss function applied to the motion compensated event image that\nmeasures the motion blur in this image. We train two networks with this\nframework, one to predict optical flow, and one to predict egomotion and\ndepths, and evaluate these networks on the Multi Vehicle Stereo Event Camera\ndataset, along with qualitative results from a variety of different scenes. \n\n"}
{"id": "1812.08685", "contents": "Title: DeepFakes: a New Threat to Face Recognition? Assessment and Detection Abstract: It is becoming increasingly easy to automatically replace a face of one\nperson in a video with the face of another person by using a pre-trained\ngenerative adversarial network (GAN). Recent public scandals, e.g., the faces\nof celebrities being swapped onto pornographic videos, call for automated ways\nto detect these Deepfake videos. To help developing such methods, in this\npaper, we present the first publicly available set of Deepfake videos generated\nfrom videos of VidTIMIT database. We used open source software based on GANs to\ncreate the Deepfakes, and we emphasize that training and blending parameters\ncan significantly impact the quality of the resulted videos. To demonstrate\nthis impact, we generated videos with low and high visual quality (320 videos\neach) using differently tuned parameter sets. We showed that the state of the\nart face recognition systems based on VGG and Facenet neural networks are\nvulnerable to Deepfake videos, with 85.62% and 95.00% false acceptance rates\nrespectively, which means methods for detecting Deepfake videos are necessary.\nBy considering several baseline approaches, we found that audio-visual approach\nbased on lip-sync inconsistency detection was not able to distinguish Deepfake\nvideos. The best performing method, which is based on visual quality metrics\nand is often used in presentation attack detection domain, resulted in 8.97%\nequal error rate on high quality Deepfakes. Our experiments demonstrate that\nGAN-generated Deepfake videos are challenging for both face recognition systems\nand existing detection methods, and the further development of face swapping\ntechnology will make it even more so. \n\n"}
{"id": "1812.08848", "contents": "Title: SMILER: Saliency Model Implementation Library for Experimental Research Abstract: The Saliency Model Implementation Library for Experimental Research (SMILER)\nis a new software package which provides an open, standardized, and extensible\nframework for maintaining and executing computational saliency models. This\nwork drastically reduces the human effort required to apply saliency algorithms\nto new tasks and datasets, while also ensuring consistency and procedural\ncorrectness for results and conclusions produced by different parties. At its\nlaunch SMILER already includes twenty three saliency models (fourteen models\nbased in MATLAB and nine supported through containerization), and the open\ndesign of SMILER encourages this number to grow with future contributions from\nthe community. The project may be downloaded and contributed to through its\nGitHub page: https://github.com/tsotsoslab/smiler \n\n"}
{"id": "1812.08974", "contents": "Title: Multi-component Image Translation for Deep Domain Generalization Abstract: Domain adaption (DA) and domain generalization (DG) are two closely related\nmethods which are both concerned with the task of assigning labels to an\nunlabeled data set. The only dissimilarity between these approaches is that DA\ncan access the target data during the training phase, while the target data is\ntotally unseen during the training phase in DG. The task of DG is challenging\nas we have no earlier knowledge of the target samples. If DA methods are\napplied directly to DG by a simple exclusion of the target data from training,\npoor performance will result for a given task. In this paper, we tackle the\ndomain generalization challenge in two ways. In our first approach, we propose\na novel deep domain generalization architecture utilizing synthetic data\ngenerated by a Generative Adversarial Network (GAN). The discrepancy between\nthe generated images and synthetic images is minimized using existing domain\ndiscrepancy metrics such as maximum mean discrepancy or correlation alignment.\nIn our second approach, we introduce a protocol for applying DA methods to a DG\nscenario by excluding the target data from the training phase, splitting the\nsource data to training and validation parts, and treating the validation data\nas target data for DA. We conduct extensive experiments on four cross-domain\nbenchmark datasets. Experimental results signify our proposed model outperforms\nthe current state-of-the-art methods for DG. \n\n"}
{"id": "1812.08985", "contents": "Title: Non-Adversarial Image Synthesis with Generative Latent Nearest Neighbors Abstract: Unconditional image generation has recently been dominated by generative\nadversarial networks (GANs). GAN methods train a generator which regresses\nimages from random noise vectors, as well as a discriminator that attempts to\ndifferentiate between the generated images and a training set of real images.\nGANs have shown amazing results at generating realistic looking images. Despite\ntheir success, GANs suffer from critical drawbacks including: unstable training\nand mode-dropping. The weaknesses in GANs have motivated research into\nalternatives including: variational auto-encoders (VAEs), latent embedding\nlearning methods (e.g. GLO) and nearest-neighbor based implicit maximum\nlikelihood estimation (IMLE). Unfortunately at the moment, GANs still\nsignificantly outperform the alternative methods for image generation. In this\nwork, we present a novel method - Generative Latent Nearest Neighbors (GLANN) -\nfor training generative models without adversarial training. GLANN combines the\nstrengths of IMLE and GLO in a way that overcomes the main drawbacks of each\nmethod. Consequently, GLANN generates images that are far better than GLO and\nIMLE. Our method does not suffer from mode collapse which plagues GAN training\nand is much more stable. Qualitative results show that GLANN outperforms a\nbaseline consisting of 800 GANs and VAEs on commonly used datasets. Our models\nare also shown to be effective for training truly non-adversarial unsupervised\nimage translation. \n\n"}
{"id": "1812.09213", "contents": "Title: Learning Compositional Representations for Few-Shot Recognition Abstract: One of the key limitations of modern deep learning approaches lies in the\namount of data required to train them. Humans, by contrast, can learn to\nrecognize novel categories from just a few examples. Instrumental to this rapid\nlearning ability is the compositional structure of concept representations in\nthe human brain --- something that deep learning models are lacking. In this\nwork, we make a step towards bridging this gap between human and machine\nlearning by introducing a simple regularization technique that allows the\nlearned representation to be decomposable into parts. Our method uses\ncategory-level attribute annotations to disentangle the feature space of a\nnetwork into subspaces corresponding to the attributes. These attributes can be\neither purely visual, like object parts, or more abstract, like openness and\nsymmetry. We demonstrate the value of compositional representations on three\ndatasets: CUB-200-2011, SUN397, and ImageNet, and show that they require fewer\nexamples to learn classifiers for novel categories. \n\n"}
{"id": "1812.09232", "contents": "Title: Learning from Web Data: the Benefit of Unsupervised Object Localization Abstract: Annotating a large number of training images is very time-consuming. In this\nbackground, this paper focuses on learning from easy-to-acquire web data and\nutilizes the learned model for fine-grained image classification in labeled\ndatasets. Currently, the performance gain from training with web data is\nincremental, like a common saying \"better than nothing, but not by much\".\nConventionally, the community looks to correcting the noisy web labels to\nselect informative samples. In this work, we first systematically study the\nbuilt-in gap between the web and standard datasets, i.e. different data\ndistributions between the two kinds of data. Then, in addition to using web\nlabels, we present an unsupervised object localization method, which provides\ncritical insights into the object density and scale in web images.\nSpecifically, we design two constraints on web data to substantially reduce the\ndifference of data distributions for the web and standard datasets. First, we\npresent a method to control the scale, localization and number of objects in\nthe detected region. Second, we propose to select the regions containing\nobjects that are consistent with the web tag. Based on the two constraints, we\nare able to process web images to reduce the gap, and the processed web data is\nused to better assist the standard dataset to train CNNs. Experiments on\nseveral fine-grained image classification datasets confirm that our method\nperforms favorably against the state-of-the-art methods. \n\n"}
{"id": "1812.10016", "contents": "Title: A Unified Framework for Mutual Improvement of SLAM and Semantic\n  Segmentation Abstract: This paper presents a novel framework for simultaneously implementing\nlocalization and segmentation, which are two of the most important vision-based\ntasks for robotics. While the goals and techniques used for them were\nconsidered to be different previously, we show that by making use of the\nintermediate results of the two modules, their performance can be enhanced at\nthe same time. Our framework is able to handle both the instantaneous motion\nand long-term changes of instances in localization with the help of the\nsegmentation result, which also benefits from the refined 3D pose information.\nWe conduct experiments on various datasets, and prove that our framework works\neffectively on improving the precision and robustness of the two tasks and\noutperforms existing localization and segmentation algorithms. \n\n"}
{"id": "1812.10191", "contents": "Title: FPD-M-net: Fingerprint Image Denoising and Inpainting Using M-Net Based\n  Convolutional Neural Networks Abstract: Fingerprint is a common biometric used for authentication and verification of\nan individual. These images are degraded when fingers are wet, dirty, dry or\nwounded and due to the failure of the sensors, etc. The extraction of the\nfingerprint from a degraded image requires denoising and inpainting. We propose\nto address these problems with an end-to-end trainable Convolutional Neural\nNetwork based architecture called FPD-M-net, by posing the fingerprint\ndenoising and inpainting problem as a segmentation (foreground) task. Our\narchitecture is based on the M-net with a change: structure similarity loss\nfunction, used for better extraction of the fingerprint from the noisy\nbackground. Our method outperforms the baseline method and achieves an overall\n3rd rank in the Chalearn LAP Inpainting Competition Track 3 - Fingerprint\nDenoising and Inpainting, ECCV 2018 \n\n"}
{"id": "1812.10305", "contents": "Title: Spatial and Temporal Mutual Promotion for Video-based Person\n  Re-identification Abstract: Video-based person re-identification is a crucial task of matching video\nsequences of a person across multiple camera views. Generally, features\ndirectly extracted from a single frame suffer from occlusion, blur,\nillumination and posture changes. This leads to false activation or missing\nactivation in some regions, which corrupts the appearance and motion\nrepresentation. How to explore the abundant spatial-temporal information in\nvideo sequences is the key to solve this problem. To this end, we propose a\nRefining Recurrent Unit (RRU) that recovers the missing parts and suppresses\nnoisy parts of the current frame's features by referring historical frames.\nWith RRU, the quality of each frame's appearance representation is improved.\nThen we use the Spatial-Temporal clues Integration Module (STIM) to mine the\nspatial-temporal information from those upgraded features. Meanwhile, the\nmulti-level training objective is used to enhance the capability of RRU and\nSTIM. Through the cooperation of those modules, the spatial and temporal\nfeatures mutually promote each other and the final spatial-temporal feature\nrepresentation is more discriminative and robust. Extensive experiments are\nconducted on three challenging datasets, i.e., iLIDS-VID, PRID-2011 and MARS.\nThe experimental results demonstrate that our approach outperforms existing\nstate-of-the-art methods of video-based person re-identification on iLIDS-VID\nand MARS and achieves favorable results on PRID-2011. \n\n"}
{"id": "1812.10328", "contents": "Title: A Multi-Stream Convolutional Neural Network Framework for Group Activity\n  Recognition Abstract: In this work, we present a framework based on multi-stream convolutional\nneural networks (CNNs) for group activity recognition. Streams of CNNs are\nseparately trained on different modalities and their predictions are fused at\nthe end. Each stream has two branches to predict the group activity based on\nperson and scene level representations. A new modality based on the human pose\nestimation is presented to add extra information to the model. We evaluate our\nmethod on the Volleyball and Collective Activity datasets. Experimental results\nshow that the proposed framework is able to achieve state-of-the-art results\nwhen multiple or single frames are given as input to the model with 90.50% and\n86.61% accuracy on Volleyball dataset, respectively, and 87.01% accuracy of\nmultiple frames group activity on Collective Activity dataset. \n\n"}
{"id": "1812.10358", "contents": "Title: Informative Object Annotations: Tell Me Something I Don't Know Abstract: Capturing the interesting components of an image is a key aspect of image\nunderstanding. When a speaker annotates an image, selecting labels that are\ninformative greatly depends on the prior knowledge of a prospective listener.\nMotivated by cognitive theories of categorization and communication, we present\na new unsupervised approach to model this prior knowledge and quantify the\ninformativeness of a description. Specifically, we compute how knowledge of a\nlabel reduces uncertainty over the space of labels and utilize this to rank\ncandidate labels for describing an image. While the full estimation problem is\nintractable, we describe an efficient algorithm to approximate entropy\nreduction using a tree-structured graphical model. We evaluate our approach on\nthe open-images dataset using a new evaluation set of 10K ground-truth ratings\nand find that it achieves ~65% agreement with human raters, largely\noutperforming other unsupervised baseline approaches. \n\n"}
{"id": "1812.10907", "contents": "Title: Divergence Triangle for Joint Training of Generator Model, Energy-based\n  Model, and Inference Model Abstract: This paper proposes the divergence triangle as a framework for joint training\nof generator model, energy-based model and inference model. The divergence\ntriangle is a compact and symmetric (anti-symmetric) objective function that\nseamlessly integrates variational learning, adversarial learning, wake-sleep\nalgorithm, and contrastive divergence in a unified probabilistic formulation.\nThis unification makes the processes of sampling, inference, energy evaluation\nreadily available without the need for costly Markov chain Monte Carlo methods.\nOur experiments demonstrate that the divergence triangle is capable of learning\n(1) an energy-based model with well-formed energy landscape, (2) direct\nsampling in the form of a generator network, and (3) feed-forward inference\nthat faithfully reconstructs observed as well as synthesized data. The\ndivergence triangle is a robust training method that can learn from incomplete\ndata. \n\n"}
{"id": "1812.11092", "contents": "Title: Multi-resolution neural networks for tracking seismic horizons from few\n  training images Abstract: Detecting a specific horizon in seismic images is a valuable tool for\ngeological interpretation. Because hand-picking the locations of the horizon is\na time-consuming process, automated computational methods were developed\nstarting three decades ago. Older techniques for such picking include\ninterpolation of control points however, in recent years neural networks have\nbeen used for this task. Until now, most networks trained on small patches from\nlarger images. This limits the networks ability to learn from large-scale\ngeologic structures. Moreover, currently available networks and training\nstrategies require label patches that have full and continuous annotations,\nwhich are also time-consuming to generate.\n  We propose a projected loss-function for training convolutional networks with\na multi-resolution structure, including variants of the U-net. Our networks\nlearn from a small number of large seismic images without creating patches. The\nprojected loss-function enables training on labels with just a few annotated\npixels and has no issue with the other unknown label pixels. Training uses all\ndata without reserving some for validation. Only the labels are split into\ntraining/testing. Contrary to other work on horizon tracking, we train the\nnetwork to perform non-linear regression, and not classification. As such, we\npropose labels as the convolution of a Gaussian kernel and the known horizon\nlocations that indicate uncertainty in the labels. The network output is the\nprobability of the horizon location. We demonstrate the proposed computational\ningredients on two different datasets, for horizon extrapolation and\ninterpolation. We show that the predictions of our methodology are accurate\neven in areas far from known horizon locations because our learning strategy\nexploits all data in large seismic images. \n\n"}
{"id": "1812.11852", "contents": "Title: Fast Perceptual Image Enhancement Abstract: The vast majority of photos taken today are by mobile phones. While their\nquality is rapidly growing, due to physical limitations and cost constraints,\nmobile phone cameras struggle to compare in quality with DSLR cameras. This\nmotivates us to computationally enhance these images. We extend upon the\nresults of Ignatov et al., where they are able to translate images from compact\nmobile cameras into images with comparable quality to high-resolution photos\ntaken by DSLR cameras. However, the neural models employed require large\namounts of computational resources and are not lightweight enough to run on\nmobile devices. We build upon the prior work and explore different network\narchitectures targeting an increase in image quality and speed. With an\nefficient network architecture which does most of its processing in a lower\nspatial resolution, we achieve a significantly higher mean opinion score (MOS)\nthan the baseline while speeding up the computation by 6.3 times on a\nconsumer-grade CPU. This suggests a promising direction for\nneural-network-based photo enhancement using the phone hardware of the future. \n\n"}
{"id": "1901.00003", "contents": "Title: Learning Spatial Common Sense with Geometry-Aware Recurrent Networks Abstract: We integrate two powerful ideas, geometry and deep visual representation\nlearning, into recurrent network architectures for mobile visual scene\nunderstanding. The proposed networks learn to \"lift\" and integrate 2D visual\nfeatures over time into latent 3D feature maps of the scene. They are equipped\nwith differentiable geometric operations, such as projection, unprojection,\negomotion estimation and stabilization, in order to compute a\ngeometrically-consistent mapping between the world scene and their 3D latent\nfeature state. We train the proposed architectures to predict novel camera\nviews given short frame sequences as input. Their predictions strongly\ngeneralize to scenes with a novel number of objects, appearances and\nconfigurations; they greatly outperform previous works that do not consider\negomotion stabilization or a space-aware latent feature state. We train the\nproposed architectures to detect and segment objects in 3D using the latent 3D\nfeature map as input--as opposed to per frame features. The resulting object\ndetections persist over time: they continue to exist even when an object gets\noccluded or leaves the field of view. Our experiments suggest the proposed\nspace-aware latent feature memory and egomotion-stabilized convolutions are\nessential architectural choices for spatial common sense to emerge in\nartificial embodied visual agents. \n\n"}
{"id": "1901.00109", "contents": "Title: Morphological Network: How Far Can We Go with Morphological Neurons? Abstract: Morphological neurons, that is morphological operators such as dilation and\nerosion with learnable structuring elements, have intrigued researchers for\nquite some time because of the power these operators bring to the table despite\ntheir simplicity. These operators are known to be powerful nonlinear tools, but\nfor a given problem coming up with a sequence of operations and their\nstructuring element is a non-trivial task. So, the existing works have mainly\nfocused on this part of the problem without delving deep into their\napplicability as generic operators. A few works have tried to utilize\nmorphological neurons as a part of classification (and regression) networks\nwhen the input is a feature vector. However, these methods mainly focus on a\nspecific problem, without going into generic theoretical analysis. In this\nwork, we have theoretically analyzed morphological neurons and have shown that\nthese are far more powerful than previously anticipated. Our proposed\nmorphological block, containing dilation and erosion followed by their linear\ncombination, represents a sum of hinge functions. Existing works show that\nhinge functions perform quite well in classification and regression problems.\nTwo morphological blocks can even approximate any continuous function. However,\nto facilitate the theoretical analysis that we have done in this paper, we have\nrestricted ourselves to the 1D version of the operators, where the structuring\nelement operates on the whole input. Experimental evaluations also indicate the\neffectiveness of networks built with morphological neurons, over similarly\nstructured neural networks. \n\n"}
{"id": "1901.01706", "contents": "Title: Universal Deep Beamformer for Variable Rate Ultrasound Imaging Abstract: Ultrasound (US) imaging is based on the time-reversal principle, in which\nindividual channel RF measurements are back-propagated and accumulated to form\nan image after applying specific delays. While this time reversal is usually\nimplemented as a delay-and-sum (DAS) beamformer, the image quality quickly\ndegrades as the number of measurement channels decreases. To address this\nproblem, various types of adaptive beamforming techniques have been proposed\nusing predefined models of the signals. However, the performance of these\nadaptive beamforming approaches degrade when the underlying model is not\nsufficiently accurate. Here, we demonstrate for the first time that a single\nuniversal deep beamformer trained using a purely data-driven way can generate\nsignificantly improved images over widely varying aperture and channel\nsubsampling patterns. In particular, we design an end-to-end deep learning\nframework that can directly process sub-sampled RF data acquired at different\nsubsampling rate and detector configuration to generate high quality ultrasound\nimages using a single beamformer. Experimental results using B-mode focused\nultrasound confirm the efficacy of the proposed methods. \n\n"}
{"id": "1901.02511", "contents": "Title: Multi-stream CNN based Video Semantic Segmentation for Automated Driving Abstract: Majority of semantic segmentation algorithms operate on a single frame even\nin the case of videos. In this work, the goal is to exploit temporal\ninformation within the algorithm model for leveraging motion cues and temporal\nconsistency. We propose two simple high-level architectures based on Recurrent\nFCN (RFCN) and Multi-Stream FCN (MSFCN) networks. In case of RFCN, a recurrent\nnetwork namely LSTM is inserted between the encoder and decoder. MSFCN combines\nthe encoders of different frames into a fused encoder via 1x1 channel-wise\nconvolution. We use a ResNet50 network as the baseline encoder and construct\nthree networks namely MSFCN of order 2 & 3 and RFCN of order 2. MSFCN-3\nproduces the best results with an accuracy improvement of 9% and 15% for\nHighway and New York-like city scenarios in the SYNTHIA-CVPR'16 dataset using\nmean IoU metric. MSFCN-3 also produced 11% and 6% for SegTrack V2 and DAVIS\ndatasets over the baseline FCN network. We also designed an efficient version\nof MSFCN-2 and RFCN-2 using weight sharing among the two encoders. The\nefficient MSFCN-2 provided an improvement of 11% and 5% for KITTI and SYNTHIA\nwith negligible increase in computational complexity compared to the baseline\nversion. \n\n"}
{"id": "1901.02675", "contents": "Title: Low-Cost Transfer Learning of Face Tasks Abstract: Do we know what the different filters of a face network represent? Can we use\nthis filter information to train other tasks without transfer learning? For\ninstance, can age, head pose, emotion and other face related tasks be learned\nfrom face recognition network without transfer learning? Understanding the role\nof these filters allows us to transfer knowledge across tasks and take\nadvantage of large data sets in related tasks. Given a pretrained network, we\ncan infer which tasks the network generalizes for and the best way to transfer\nthe information to a new task. \n\n"}
{"id": "1901.03091", "contents": "Title: An MBO scheme for clustering and semi-supervised clustering of signed\n  networks Abstract: We introduce a principled method for the signed clustering problem, where the\ngoal is to partition a graph whose edge weights take both positive and negative\nvalues, such that edges within the same cluster are mostly positive, while\nedges spanning across clusters are mostly negative. Our method relies on a\ngraph-based diffuse interface model formulation utilizing the Ginzburg-Landau\nfunctional, based on an adaptation of the classic numerical\nMerriman-Bence-Osher (MBO) scheme for minimizing such graph-based functionals.\nThe proposed objective function aims to minimize the total weight of\ninter-cluster positively-weighted edges, while maximizing the total weight of\nthe inter-cluster negatively-weighted edges. Our method scales to large sparse\nnetworks, and can be easily adjusted to incorporate labelled data information,\nas is often the case in the context of semi-supervised learning. We tested our\nmethod on a number of both synthetic stochastic block models and real-world\ndata sets (including financial correlation matrices), and obtained promising\nresults that compare favourably against a number of state-of-the-art approaches\nfrom the recent literature. \n\n"}
{"id": "1901.03662", "contents": "Title: Individual common dolphin identification via metric embedding learning Abstract: Photo-identification (photo-id) of dolphin individuals is a commonly used\ntechnique in ecological sciences to monitor state and health of individuals, as\nwell as to study the social structure and distribution of a population.\nTraditional photo-id involves a laborious manual process of matching each\ndolphin fin photograph captured in the field to a catalogue of known\nindividuals.\n  We examine this problem in the context of open-set recognition and utilise a\ntriplet loss function to learn a compact representation of fin images in a\nEuclidean embedding, where the Euclidean distance metric represents fin\nsimilarity. We show that this compact representation can be successfully learnt\nfrom a fairly small (in deep learning context) training set and still\ngeneralise well to out-of-sample identities (completely new dolphin\nindividuals), with top-1 and top-5 test set (37 individuals) accuracy of\n$90.5\\pm2$ and $93.6\\pm1$ percent. In the presence of 1200 distractors, top-1\naccuracy dropped by $12\\%$; however, top-5 accuracy saw only a $2.8\\%$ drop \n\n"}
{"id": "1901.03781", "contents": "Title: DeepSpline: Data-Driven Reconstruction of Parametric Curves and Surfaces Abstract: Reconstruction of geometry based on different input modes, such as images or\npoint clouds, has been instrumental in the development of computer aided design\nand computer graphics. Optimal implementations of these applications have\ntraditionally involved the use of spline-based representations at their core.\nMost such methods attempt to solve optimization problems that minimize an\noutput-target mismatch. However, these optimization techniques require an\ninitialization that is close enough, as they are local methods by nature. We\npropose a deep learning architecture that adapts to perform spline fitting\ntasks accordingly, providing complementary results to the aforementioned\ntraditional methods. We showcase the performance of our approach, by\nreconstructing spline curves and surfaces based on input images or point\nclouds. \n\n"}
{"id": "1901.03912", "contents": "Title: Real-time Joint Object Detection and Semantic Segmentation Network for\n  Automated Driving Abstract: Convolutional Neural Networks (CNN) are successfully used for various visual\nperception tasks including bounding box object detection, semantic\nsegmentation, optical flow, depth estimation and visual SLAM. Generally these\ntasks are independently explored and modeled. In this paper, we present a joint\nmulti-task network design for learning object detection and semantic\nsegmentation simultaneously. The main motivation is to achieve real-time\nperformance on a low power embedded SOC by sharing of encoder for both the\ntasks. We construct an efficient architecture using a small ResNet10 like\nencoder which is shared for both decoders. Object detection uses YOLO v2 like\ndecoder and semantic segmentation uses FCN8 like decoder. We evaluate the\nproposed network in two public datasets (KITTI, Cityscapes) and in our private\nfisheye camera dataset, and demonstrate that joint network provides the same\naccuracy as that of separate networks. We further optimize the network to\nachieve 30 fps for 1280x384 resolution image. \n\n"}
{"id": "1901.06199", "contents": "Title: Generative Adversarial Classifier for Handwriting Characters\n  Super-Resolution Abstract: Generative Adversarial Networks (GAN) receive great attentions recently due\nto its excellent performance in image generation, transformation, and\nsuper-resolution. However, GAN has rarely been studied and trained for\nclassification, leading that the generated images may not be appropriate for\nclassification. In this paper, we propose a novel Generative Adversarial\nClassifier (GAC) particularly for low-resolution Handwriting Character\nRecognition. Specifically, involving additionally a classifier in the training\nprocess of normal GANs, GAC is calibrated for learning suitable structures and\nrestored characters images that benefits the classification. Experimental\nresults show that our proposed method can achieve remarkable performance in\nhandwriting characters 8x super-resolution, approximately 10% and 20% higher\nthan the present state-of-the-art methods respectively on benchmark data\nCASIA-HWDB1.1 and MNIST. \n\n"}
{"id": "1901.06595", "contents": "Title: Evaluating Text-to-Image Matching using Binary Image Selection (BISON) Abstract: Providing systems the ability to relate linguistic and visual content is one\nof the hallmarks of computer vision. Tasks such as text-based image retrieval\nand image captioning were designed to test this ability but come with\nevaluation measures that have a high variance or are difficult to interpret. We\nstudy an alternative task for systems that match text and images: given a text\nquery, the system is asked to select the image that best matches the query from\na pair of semantically similar images. The system's accuracy on this Binary\nImage SelectiON (BISON) task is interpretable, eliminates the reliability\nproblems of retrieval evaluations, and focuses on the system's ability to\nunderstand fine-grained visual structure. We gather a BISON dataset that\ncomplements the COCO dataset and use it to evaluate modern text-based image\nretrieval and image captioning systems. Our results provide novel insights into\nthe performance of these systems. The COCO-BISON dataset and corresponding\nevaluation code are publicly available from \\url{http://hexianghu.com/bison/}. \n\n"}
{"id": "1901.06706", "contents": "Title: Visual Entailment: A Novel Task for Fine-Grained Image Understanding Abstract: Existing visual reasoning datasets such as Visual Question Answering (VQA),\noften suffer from biases conditioned on the question, image or answer\ndistributions. The recently proposed CLEVR dataset addresses these limitations\nand requires fine-grained reasoning but the dataset is synthetic and consists\nof similar objects and sentence structures across the dataset.\n  In this paper, we introduce a new inference task, Visual Entailment (VE) -\nconsisting of image-sentence pairs whereby a premise is defined by an image,\nrather than a natural language sentence as in traditional Textual Entailment\ntasks. The goal of a trained VE model is to predict whether the image\nsemantically entails the text. To realize this task, we build a dataset SNLI-VE\nbased on the Stanford Natural Language Inference corpus and Flickr30k dataset.\nWe evaluate various existing VQA baselines and build a model called Explainable\nVisual Entailment (EVE) system to address the VE task. EVE achieves up to 71%\naccuracy and outperforms several other state-of-the-art VQA based models.\nFinally, we demonstrate the explainability of EVE through cross-modal attention\nvisualizations. The SNLI-VE dataset is publicly available at\nhttps://github.com/ necla-ml/SNLI-VE. \n\n"}
{"id": "1901.06778", "contents": "Title: Hybrid coarse-fine classification for head pose estimation Abstract: Head pose estimation, which computes the intrinsic Euler angles (yaw, pitch,\nroll) from the human, is crucial for gaze estimation, face alignment, and 3D\nreconstruction. Traditional approaches heavily relies on the accuracy of facial\nlandmarks. It limits their performances, especially when the visibility of the\nface is not in good condition. In this paper, to do the estimation without\nfacial landmarks, we combine the coarse and fine regression output together for\na deep network. Utilizing more quantization units for the angles, a fine\nclassifier is trained with the help of other auxiliary coarse units.\nIntegrating regression is adopted to get the final prediction. The proposed\napproach is evaluated on three challenging benchmarks. It achieves the\nstate-of-the-art on AFLW2000, BIWI and performs favorably on AFLW. The code has\nbeen released on Github. \n\n"}
{"id": "1901.06919", "contents": "Title: A Fourier Disparity Layer representation for Light Fields Abstract: In this paper, we present a new Light Field representation for efficient\nLight Field processing and rendering called Fourier Disparity Layers (FDL). The\nproposed FDL representation samples the Light Field in the depth (or\nequivalently the disparity) dimension by decomposing the scene as a discrete\nsum of layers. The layers can be constructed from various types of Light Field\ninputs including a set of sub-aperture images, a focal stack, or even a\ncombination of both. From our derivations in the Fourier domain, the layers are\nsimply obtained by a regularized least square regression performed\nindependently at each spatial frequency, which is efficiently parallelized in a\nGPU implementation. Our model is also used to derive a gradient descent based\ncalibration step that estimates the input view positions and an optimal set of\ndisparity values required for the layer construction. Once the layers are\nknown, they can be simply shifted and filtered to produce different viewpoints\nof the scene while controlling the focus and simulating a camera aperture of\narbitrary shape and size. Our implementation in the Fourier domain allows real\ntime Light Field rendering. Finally, direct applications such as view\ninterpolation or extrapolation and denoising are presented and evaluated. \n\n"}
{"id": "1901.07165", "contents": "Title: Generation High resolution 3D model from natural language by Generative\n  Adversarial Network Abstract: We present a method of generating high resolution 3D shapes from natural\nlanguage descriptions. To achieve this goal, we propose two steps that\ngenerating low resolution shapes which roughly reflect texts and generating\nhigh resolution shapes which reflect the detail of texts. In a previous paper,\nthe authors have shown a method of generating low resolution shapes. We improve\nit to generate 3D shapes more faithful to natural language and test the\neffectiveness of the method. To generate high resolution 3D shapes, we use the\nframework of Conditional Wasserstein GAN. We propose two roles of Critic\nseparately, which calculate the Wasserstein distance between two probability\ndistribution, so that we achieve generating high quality shapes or acceleration\nof learning speed of model. To evaluate our approach, we performed quantitive\nevaluation with several numerical metrics for Critic models. Our method is\nfirst to realize the generation of high quality model by propagating text\nembedding information to high resolution task when generating 3D model. \n\n"}
{"id": "1901.07196", "contents": "Title: CAE-ADMM: Implicit Bitrate Optimization via ADMM-based Pruning in\n  Compressive Autoencoders Abstract: We introduce ADMM-pruned Compressive AutoEncoder (CAE-ADMM) that uses\nAlternative Direction Method of Multipliers (ADMM) to optimize the trade-off\nbetween distortion and efficiency of lossy image compression. Specifically,\nADMM in our method is to promote sparsity to implicitly optimize the bitrate,\ndifferent from entropy estimators used in the previous research. The\nexperiments on public datasets show that our method outperforms the original\nCAE and some traditional codecs in terms of SSIM/MS-SSIM metrics, at reasonable\ninference speed. \n\n"}
{"id": "1901.08296", "contents": "Title: Deep Learning on Attributed Graphs: A Journey from Graphs to Their\n  Embeddings and Back Abstract: A graph is a powerful concept for representation of relations between pairs\nof entities. Data with underlying graph structure can be found across many\ndisciplines and there is a natural desire for understanding such data better.\nDeep learning (DL) has achieved significant breakthroughs in a variety of\nmachine learning tasks in recent years, especially where data is structured on\na grid, such as in text, speech, or image understanding. However, surprisingly\nlittle has been done to explore the applicability of DL on arbitrary\ngraph-structured data directly.\n  The goal of this thesis is to investigate architectures for DL on graphs and\nstudy how to transfer, adapt or generalize concepts that work well on\nsequential and image data to this domain. We concentrate on two important\nprimitives: embedding graphs or their nodes into a continuous vector space\nrepresentation (encoding) and, conversely, generating graphs from such vectors\nback (decoding). To that end, we make the following contributions.\n  First, we introduce Edge-Conditioned Convolutions (ECC), a convolution-like\noperation on graphs performed in the spatial domain where filters are\ndynamically generated based on edge attributes. The method is used to encode\ngraphs with arbitrary and varying structure.\n  Second, we propose SuperPoint Graph, an intermediate point cloud\nrepresentation with rich edge attributes encoding the contextual relationship\nbetween object parts. Based on this representation, ECC is employed to segment\nlarge-scale point clouds without major sacrifice in fine details.\n  Third, we present GraphVAE, a graph generator allowing us to decode graphs\nwith variable but upper-bounded number of nodes making use of approximate graph\nmatching for aligning the predictions of an autoencoder with its inputs. The\nmethod is applied to the task of molecule generation. \n\n"}
{"id": "1901.08394", "contents": "Title: Application of Decision Rules for Handling Class Imbalance in Semantic\n  Segmentation Abstract: As part of autonomous car driving systems, semantic segmentation is an\nessential component to obtain a full understanding of the car's environment.\nOne difficulty, that occurs while training neural networks for this purpose, is\nclass imbalance of training data. Consequently, a neural network trained on\nunbalanced data in combination with maximum a-posteriori classification may\neasily ignore classes that are rare in terms of their frequency in the dataset.\nHowever, these classes are often of highest interest. We approach such\npotential misclassifications by weighting the posterior class probabilities\nwith the prior class probabilities which in our case are the inverse\nfrequencies of the corresponding classes in the training dataset. More\nprecisely, we adopt a localized method by computing the priors pixel-wise such\nthat the impact can be analyzed at pixel level as well. In our experiments, we\ntrain one network from scratch using a proprietary dataset containing 20,000\nannotated frames of video sequences recorded from street scenes. The evaluation\non our test set shows an increase of average recall with regard to instances of\npedestrians and info signs by $25\\%$ and $23.4\\%$, respectively. In addition,\nwe significantly reduce the non-detection rate for instances of the same\nclasses by $61\\%$ and $38\\%$. \n\n"}
{"id": "1901.08469", "contents": "Title: Deep Generative Learning via Variational Gradient Flow Abstract: We propose a general framework to learn deep generative models via\n\\textbf{V}ariational \\textbf{Gr}adient Fl\\textbf{ow} (VGrow) on probability\nspaces. The evolving distribution that asymptotically converges to the target\ndistribution is governed by a vector field, which is the negative gradient of\nthe first variation of the $f$-divergence between them. We prove that the\nevolving distribution coincides with the pushforward distribution through the\ninfinitesimal time composition of residual maps that are perturbations of the\nidentity map along the vector field. The vector field depends on the density\nratio of the pushforward distribution and the target distribution, which can be\nconsistently learned from a binary classification problem. Connections of our\nproposed VGrow method with other popular methods, such as VAE, GAN and\nflow-based methods, have been established in this framework, gaining new\ninsights of deep generative learning. We also evaluated several commonly used\ndivergences, including Kullback-Leibler, Jensen-Shannon, Jeffrey divergences as\nwell as our newly discovered `logD' divergence which serves as the objective\nfunction of the logD-trick GAN. Experimental results on benchmark datasets\ndemonstrate that VGrow can generate high-fidelity images in a stable and\nefficient manner, achieving competitive performance with state-of-the-art GANs. \n\n"}
{"id": "1901.08576", "contents": "Title: Learning Interpretable Models with Causal Guarantees Abstract: Machine learning has shown much promise in helping improve the quality of\nmedical, legal, and financial decision-making. In these applications, machine\nlearning models must satisfy two important criteria: (i) they must be causal,\nsince the goal is typically to predict individual treatment effects, and (ii)\nthey must be interpretable, so that human decision makers can validate and\ntrust the model predictions. There has recently been much progress along each\ndirection independently, yet the state-of-the-art approaches are fundamentally\nincompatible. We propose a framework for learning interpretable models from\nobservational data that can be used to predict individual treatment effects\n(ITEs). In particular, our framework converts any supervised learning algorithm\ninto an algorithm for estimating ITEs. Furthermore, we prove an error bound on\nthe treatment effects predicted by our model. Finally, in an experiment on\nreal-world data, we show that the models trained using our framework\nsignificantly outperform a number of baselines. \n\n"}
{"id": "1901.08753", "contents": "Title: On Output Activation Functions for Adversarial Losses: A Theoretical\n  Analysis via Variational Divergence Minimization and An Empirical Study on\n  MNIST Classification Abstract: Recent years have seen adversarial losses been applied to many fields. Their\napplications extend beyond the originally proposed generative modeling to\nconditional generative and discriminative settings. While prior work has\nproposed various output activation functions and regularization approaches,\nsome open questions still remain unanswered. In this paper, we aim to study the\nfollowing two research questions: 1) What types of output activation functions\nform a well-behaved adversarial loss? 2) How different combinations of output\nactivation functions and regularization approaches perform empirically against\none another? To answer the first question, we adopt the perspective of\nvariational divergence minimization and consider an adversarial loss\nwell-behaved if it behaves as a divergence-like measure between the data and\nmodel distributions. Using a generalized formulation for adversarial losses, we\nderive the necessary and sufficient conditions of a well-behaved adversarial\nloss. Our analysis reveals a large class of theoretically valid adversarial\nlosses. For the second question, we propose a simple comparative framework for\nadversarial losses using discriminative adversarial networks. The proposed\nframework allows us to efficiently evaluate adversarial losses using a standard\nevaluation metric such as the classification accuracy. With the proposed\nframework, we evaluate a comprehensive set of 168 combinations of twelve output\nactivation functions and fourteen regularization approaches on the handwritten\ndigit classification problem to decouple their effects. Our empirical findings\nsuggest that there is no single winning combination of output activation\nfunctions and regularization approaches across all settings. Our theoretical\nand empirical results may together serve as a reference for choosing or\ndesigning adversarial losses in future research. \n\n"}
{"id": "1901.08817", "contents": "Title: State-Regularized Recurrent Neural Networks Abstract: Recurrent neural networks are a widely used class of neural architectures.\nThey have, however, two shortcomings. First, it is difficult to understand what\nexactly they learn. Second, they tend to work poorly on sequences requiring\nlong-term memorization, despite having this capacity in principle. We aim to\naddress both shortcomings with a class of recurrent networks that use a\nstochastic state transition mechanism between cell applications. This\nmechanism, which we term state-regularization, makes RNNs transition between a\nfinite set of learnable states. We evaluate state-regularized RNNs on (1)\nregular languages for the purpose of automata extraction; (2) nonregular\nlanguages such as balanced parentheses, palindromes, and the copy task where\nexternal memory is required; and (3) real-word sequence learning tasks for\nsentiment analysis, visual object recognition, and language modeling. We show\nthat state-regularization (a) simplifies the extraction of finite state\nautomata modeling an RNN's state transition dynamics; (b) forces RNNs to\noperate more like automata with external memory and less like finite state\nmachines; (c) makes RNNs have better interpretability and explainability. \n\n"}
{"id": "1901.09002", "contents": "Title: A Neurally-Inspired Hierarchical Prediction Network for Spatiotemporal\n  Sequence Learning and Prediction Abstract: In this paper we developed a hierarchical network model, called Hierarchical\nPrediction Network (HPNet), to understand how spatiotemporal memories might be\nlearned and encoded in the recurrent circuits in the visual cortical hierarchy\nfor predicting future video frames. This neurally inspired model operates in\nthe analysis-by-synthesis framework. It contains a feed-forward path that\ncomputes and encodes spatiotemporal features of successive complexity and a\nfeedback path for the successive levels to project their interpretations to the\nlevel below. Within each level, the feed-forward path and the feedback path\nintersect in a recurrent gated circuit, instantiated in a LSTM module, to\ngenerate a prediction or explanation of the incoming signals. The network\nlearns its internal model of the world by minimizing the errors of its\nprediction of the incoming signals at each level of the hierarchy. We found\nthat hierarchical interaction in the network increases semantic clustering of\nglobal movement patterns in the population codes of the units along the\nhierarchy, even in the earliest module. This facilitates the learning of\nrelationships among movement patterns, yielding state-of-the-art performance in\nlong range video sequence predictions in the benchmark datasets. The network\nmodel automatically reproduces a variety of prediction suppression and\nfamiliarity suppression neurophysiological phenomena observed in the visual\ncortex, suggesting that hierarchical prediction might indeed be an important\nprinciple for representational learning in the visual cortex. \n\n"}
{"id": "1901.09097", "contents": "Title: Driver Distraction Identification with an Ensemble of Convolutional\n  Neural Networks Abstract: The World Health Organization (WHO) reported 1.25 million deaths yearly due\nto road traffic accidents worldwide and the number has been continuously\nincreasing over the last few years. Nearly fifth of these accidents are caused\nby distracted drivers. Existing work of distracted driver detection is\nconcerned with a small set of distractions (mostly, cell phone usage).\nUnreliable ad-hoc methods are often used.In this paper, we present the first\npublicly available dataset for driver distraction identification with more\ndistraction postures than existing alternatives. In addition, we propose a\nreliable deep learning-based solution that achieves a 90% accuracy. The system\nconsists of a genetically-weighted ensemble of convolutional neural networks,\nwe show that a weighted ensemble of classifiers using a genetic algorithm\nyields in a better classification confidence. We also study the effect of\ndifferent visual elements in distraction detection by means of face and hand\nlocalizations, and skin segmentation. Finally, we present a thinned version of\nour ensemble that could achieve 84.64% classification accuracy and operate in a\nreal-time environment. \n\n"}
{"id": "1901.09178", "contents": "Title: A general model for plane-based clustering with loss function Abstract: In this paper, we propose a general model for plane-based clustering. The\ngeneral model contains many existing plane-based clustering methods, e.g.,\nk-plane clustering (kPC), proximal plane clustering (PPC), twin support vector\nclustering (TWSVC) and its extensions. Under this general model, one may obtain\nan appropriate clustering method for specific purpose. The general model is a\nprocedure corresponding to an optimization problem, where the optimization\nproblem minimizes the total loss of the samples. Thereinto, the loss of a\nsample derives from both within-cluster and between-cluster. In theory, the\ntermination conditions are discussed, and we prove that the general model\nterminates in a finite number of steps at a local or weak local optimal point.\nFurthermore, based on this general model, we propose a plane-based clustering\nmethod by introducing a new loss function to capture the data distribution\nprecisely. Experimental results on artificial and public available datasets\nverify the effectiveness of the proposed method. \n\n"}
{"id": "1901.09614", "contents": "Title: A Simple Method to Reduce Off-chip Memory Accesses on Convolutional\n  Neural Networks Abstract: For convolutional neural networks, a simple algorithm to reduce off-chip\nmemory accesses is proposed by maximally utilizing on-chip memory in a neural\nprocess unit. Especially, the algorithm provides an effective way to process a\nmodule which consists of multiple branches and a merge layer. For Inception-V3\non Samsung's NPU in Exynos, our evaluation shows that the proposed algorithm\nmakes off-chip memory accesses reduced by 1/50, and accordingly achieves 97.59\n% reduction in the amount of feature-map data to be transferred from/to\noff-chip memory. \n\n"}
{"id": "1901.09849", "contents": "Title: Activation Adaptation in Neural Networks Abstract: Many neural network architectures rely on the choice of the activation\nfunction for each hidden layer. Given the activation function, the neural\nnetwork is trained over the bias and the weight parameters. The bias catches\nthe center of the activation, and the weights capture the scale. Here we\npropose to train the network over a shape parameter as well. This view allows\neach neuron to tune its own activation function and adapt the neuron curvature\ntowards a better prediction. This modification only adds one further equation\nto the back-propagation for each neuron. Re-formalizing activation functions as\nCDF generalizes the class of activation function extensively. We aimed at\ngeneralizing an extensive class of activation functions to study: i) skewness\nand ii) smoothness of activation functions. Here we introduce adaptive Gumbel\nactivation function as a bridge between Gumbel and sigmoid. A similar approach\nis used to invent a smooth version of ReLU. Our comparison with common\nactivation functions suggests different data representation especially in early\nneural network layers. This adaptation also provides prediction improvement. \n\n"}
{"id": "1901.10204", "contents": "Title: Approximating Spectral Clustering via Sampling: a Review Abstract: Spectral clustering refers to a family of unsupervised learning algorithms\nthat compute a spectral embedding of the original data based on the\neigenvectors of a similarity graph. This non-linear transformation of the data\nis both the key of these algorithms' success and their Achilles heel: forming a\ngraph and computing its dominant eigenvectors can indeed be computationally\nprohibitive when dealing with more that a few tens of thousands of points. In\nthis paper, we review the principal research efforts aiming to reduce this\ncomputational cost. We focus on methods that come with a theoretical control on\nthe clustering performance and incorporate some form of sampling in their\noperation. Such methods abound in the machine learning, numerical linear\nalgebra, and graph signal processing literature and, amongst others, include\nNystr\\\"om-approximation, landmarks, coarsening, coresets, and compressive\nspectral clustering. We present the approximation guarantees available for each\nand discuss practical merits and limitations. Surprisingly, despite the breadth\nof the literature explored, we conclude that there is still a gap between\ntheory and practice: the most scalable methods are only intuitively motivated\nor loosely controlled, whereas those that come with end-to-end guarantees rely\non strong assumptions or enable a limited gain of computation time. \n\n"}
{"id": "1901.10277", "contents": "Title: High-Quality Self-Supervised Deep Image Denoising Abstract: We describe a novel method for training high-quality image denoising models\nbased on unorganized collections of corrupted images. The training does not\nneed access to clean reference images, or explicit pairs of corrupted images,\nand can thus be applied in situations where such data is unacceptably expensive\nor impossible to acquire. We build on a recent technique that removes the need\nfor reference data by employing networks with a \"blind spot\" in the receptive\nfield, and significantly improve two key aspects: image quality and training\nefficiency. Our result quality is on par with state-of-the-art neural network\ndenoisers in the case of i.i.d. additive Gaussian noise, and not far behind\nwith Poisson and impulse noise. We also successfully handle cases where\nparameters of the noise model are variable and/or unknown in both training and\nevaluation data. \n\n"}
{"id": "1901.10824", "contents": "Title: Diversity Regularized Adversarial Learning Abstract: The two key players in Generative Adversarial Networks (GANs), the\ndiscriminator and generator, are usually parameterized as deep neural networks\n(DNNs). On many generative tasks, GANs achieve state-of-the-art performance but\nare often unstable to train and sometimes miss modes. A typical failure mode is\nthe collapse of the generator to a single parameter configuration where its\noutputs are identical. When this collapse occurs, the gradient of the\ndiscriminator may point in similar directions for many similar points. We\nhypothesize that some of these shortcomings are in part due to primitive and\nredundant features extracted by discriminator and this can easily make the\ntraining stuck. We present a novel approach for regularizing adversarial models\nby enforcing diverse feature learning. In order to do this, both generator and\ndiscriminator are regularized by penalizing both negatively and positively\ncorrelated features according to their differentiation and based on their\nrelative cosine distances. In addition to the gradient information from the\nadversarial loss made available by the discriminator, diversity regularization\nalso ensures that a more stable gradient is provided to update both the\ngenerator and discriminator. Results indicate our regularizer enforces diverse\nfeatures, stabilizes training, and improves image synthesis. \n\n"}
{"id": "1901.11141", "contents": "Title: On the Consistency of Top-k Surrogate Losses Abstract: The top-$k$ error is often employed to evaluate performance for challenging\nclassification tasks in computer vision as it is designed to compensate for\nambiguity in ground truth labels. This practical success motivates our\ntheoretical analysis of consistent top-$k$ classification. Surprisingly, it is\nnot rigorously understood when taking the $k$-argmax of a vector is guaranteed\nto return the $k$-argmax of another vector, though doing so is crucial to\ndescribe Bayes optimality; we do both tasks. Then, we define top-$k$\ncalibration and show it is necessary and sufficient for consistency. Based on\nthe top-$k$ calibration analysis, we propose a class of top-$k$ calibrated\nBregman divergence surrogates. Our analysis continues by showing previously\nproposed hinge-like top-$k$ surrogate losses are not top-$k$ calibrated and\nsuggests no convex hinge loss is top-$k$ calibrated. On the other hand, we\npropose a new hinge loss which is consistent. We explore further, showing our\nhinge loss remains consistent under a restriction to linear functions, while\ncross entropy does not. Finally, we exhibit a differentiable, convex loss\nfunction which is top-$k$ calibrated for specific $k$. \n\n"}
{"id": "1901.11275", "contents": "Title: A Theory of Regularized Markov Decision Processes Abstract: Many recent successful (deep) reinforcement learning algorithms make use of\nregularization, generally based on entropy or Kullback-Leibler divergence. We\npropose a general theory of regularized Markov Decision Processes that\ngeneralizes these approaches in two directions: we consider a larger class of\nregularizers, and we consider the general modified policy iteration approach,\nencompassing both policy iteration and value iteration. The core building\nblocks of this theory are a notion of regularized Bellman operator and the\nLegendre-Fenchel transform, a classical tool of convex optimization. This\napproach allows for error propagation analyses of general algorithmic schemes\nof which (possibly variants of) classical algorithms such as Trust Region\nPolicy Optimization, Soft Q-learning, Stochastic Actor Critic or Dynamic Policy\nProgramming are special cases. This also draws connections to proximal convex\noptimization, especially to Mirror Descent. \n\n"}
{"id": "1901.11379", "contents": "Title: TUNet: Incorporating segmentation maps to improve classification Abstract: Determining the localization of specific protein in human cells is important\nfor understanding cellular functions and biological processes of underlying\ndiseases. Among imaging techniques, high-throughput fluorescence microscopy\nimaging is an efficient biotechnology to stain the protein of interest in a\ncell. In this work, we present a novel classification model Twin U-Net (TUNet)\nfor processing and classifying the belonging of protein in the Atlas images.\nSeveral notable Deep Learning models including GoogleNet and Resnet have been\nemployed for comparison. Results have shown that our system obtaining\ncompetitive performance. \n\n"}
{"id": "cs/0602065", "contents": "Title: Similarity of Objects and the Meaning of Words Abstract: We survey the emerging area of compression-based, parameter-free, similarity\ndistance measures useful in data-mining, pattern recognition, learning and\nautomatic semantics extraction. Given a family of distances on a set of\nobjects, a distance is universal up to a certain precision for that family if\nit minorizes every distance in the family between every two objects in the set,\nup to the stated precision (we do not require the universal distance to be an\nelement of the family). We consider similarity distances for two types of\nobjects: literal objects that as such contain all of their meaning, like\ngenomes or books, and names for objects. The latter may have literal\nembodyments like the first type, but may also be abstract like ``red'' or\n``christianity.'' For the first type we consider a family of computable\ndistance measures corresponding to parameters expressing similarity according\nto particular featuresdistances generated by web users corresponding to\nparticular semantic relations between the (names for) the designated objects.\nFor both families we give universal similarity distance measures, incorporating\nall particular distance measures in the family. In the first case the universal\ndistance is based on compression and in the second case it is based on Google\npage counts related to search terms. In both cases experiments on a massive\nscale give evidence of the viability of the approaches. between pairs of\nliteral objects. For the second type we consider similarity \n\n"}
{"id": "cs/0702082", "contents": "Title: Invariant template matching in systems with spatiotemporal coding: a\n  vote for instability Abstract: We consider the design of a pattern recognition that matches templates to\nimages, both of which are spatially sampled and encoded as temporal sequences.\nThe image is subject to a combination of various perturbations. These include\nones that can be modeled as parameterized uncertainties such as image blur,\nluminance, translation, and rotation as well as unmodeled ones. Biological and\nneural systems require that these perturbations be processed through a minimal\nnumber of channels by simple adaptation mechanisms. We found that the most\nsuitable mathematical framework to meet this requirement is that of weakly\nattracting sets. This framework provides us with a normative and unifying\nsolution to the pattern recognition problem. We analyze the consequences of its\nexplicit implementation in neural systems. Several properties inherent to the\nsystems designed in accordance with our normative mathematical argument\ncoincide with known empirical facts. This is illustrated in mental rotation,\nvisual search and blur/intensity adaptation. We demonstrate how our results can\nbe applied to a range of practical problems in template matching and pattern\nrecognition. \n\n"}
