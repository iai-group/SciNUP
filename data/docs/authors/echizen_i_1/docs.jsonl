{"id": "0705.2862", "contents": "Title: Cryptanalysis of group-based key agreement protocols using subgroup\n  distance functions Abstract: We introduce a new approach for cryptanalysis of key agreement protocols\nbased on noncommutative groups. This approach uses functions that estimate the\ndistance of a group element to a given subgroup. We test it against the\nShpilrain-Ushakov protocol, which is based on Thompson's group F. \n\n"}
{"id": "0705.2876", "contents": "Title: An online algorithm for generating fractal hash chains applied to\n  digital chains of custody Abstract: This paper gives an online algorithm for generating Jakobsson's fractal hash\nchains. Our new algorithm compliments Jakobsson's fractal hash chain algorithm\nfor preimage traversal since his algorithm assumes the entire hash chain is\nprecomputed and a particular list of Ceiling(log n) hash elements or pebbles\nare saved. Our online algorithm for hash chain traversal incrementally\ngenerates a hash chain of n hash elements without knowledge of n before it\nstarts. For any n, our algorithm stores only the Ceiling(log n) pebbles which\nare precisely the inputs for Jakobsson's amortized hash chain preimage\ntraversal algorithm. This compact representation is useful to generate,\ntraverse, and store a number of large digital hash chains on a small and\nconstrained device. We also give an application using both Jakobsson's and our\nnew algorithm applied to digital chains of custody for validating dynamically\nchanging forensics data. \n\n"}
{"id": "0705.4138", "contents": "Title: The Asymptotic Normalized Linear Complexity of Multisequences Abstract: We show that the asymptotic linear complexity of a multisequence a in\nF_q^\\infty that is I := liminf L_a(n)/n and S := limsup L_a(n)/n satisfy the\ninequalities M/(M+1) <= S <= 1 and M(1-S) <= I <= 1-S/M, if all M sequences\nhave nonzero discrepancy infinitely often, and all pairs (I,S) satisfying these\nconditions are met by 2^{\\aleph_0} multisequences a.\n  This answers an Open Problem by Dai, Imamura, and Yang.\n  Keywords: Linear complexity, multisequence, Battery Discharge Model,\nisometry. \n\n"}
{"id": "0706.0447", "contents": "Title: Non lin\\'earit\\'e des fonctions bool\\'eennes donn\\'ees par des traces de\n  polyn\\^omes de degr\\'e binaire 3 Abstract: Nous \\'etudions la non lin\\'earit\\'e des fonctions d\\'efinies sur F_{2^m}\no\\`u $m$ est un entier impair, associ\\'ees aux polyn\\^omes de degr\\'e 7 ou \\`a\ndes polyn\\^omes plus g\\'en\\'eraux.\n  -----\n  We study the nonlinearity of the functions defined on F_{2^m} where $m$ is an\nodd integer, associated to the polynomials of degree 7 or more general\npolynomials. \n\n"}
{"id": "0706.2888", "contents": "Title: Variations on Kak's Three Stage Quantum Cryptography Protocol Abstract: This paper introduces a variation on Kak's three-stage quanutm key\ndistribution protocol which allows for defence against the man in the middle\nattack. In addition, we introduce a new protocol, which also offers similar\nresiliance against such an attack. \n\n"}
{"id": "0708.1768", "contents": "Title: Cryptanalysis of shifted conjugacy authentication protocol Abstract: In this paper we present the first practical attack on the shifted\nconjugacy-based authentication protocol proposed by P. Dehornoy. We discuss the\nweaknesses of that primitive and propose ways to improve the protocol. \n\n"}
{"id": "0709.0289", "contents": "Title: Cryptography in the Bounded-Quantum-Storage Model Abstract: This thesis initiates the study of cryptographic protocols in the\nbounded-quantum-storage model. On the practical side, simple protocols for\nRabin Oblivious Transfer, 1-2 Oblivious Transfer and Bit Commitment are\npresented. No quantum memory is required for honest players, whereas the\nprotocols can only be broken by an adversary controlling a large amount of\nquantum memory. The protocols are efficient, non-interactive and can be\nimplemented with today's technology.\n  On the theoretical side, new entropic uncertainty relations involving\nmin-entropy are established and used to prove the security of protocols\naccording to new strong security definitions. For instance, in the realistic\nsetting of Quantum Key Distribution (QKD) against quantum-memory-bounded\neavesdroppers, the uncertainty relation allows to prove the security of QKD\nprotocols while tolerating considerably higher error rates compared to the\nstandard model with unbounded adversaries. \n\n"}
{"id": "0712.3203", "contents": "Title: Solving Medium-Density Subset Sum Problems in Expected Polynomial Time:\n  An Enumeration Approach Abstract: The subset sum problem (SSP) can be briefly stated as: given a target integer\n$E$ and a set $A$ containing $n$ positive integer $a_j$, find a subset of $A$\nsumming to $E$. The \\textit{density} $d$ of an SSP instance is defined by the\nratio of $n$ to $m$, where $m$ is the logarithm of the largest integer within\n$A$. Based on the structural and statistical properties of subset sums, we\npresent an improved enumeration scheme for SSP, and implement it as a complete\nand exact algorithm (EnumPlus). The algorithm always equivalently reduces an\ninstance to be low-density, and then solve it by enumeration. Through this\napproach, we show the possibility to design a sole algorithm that can\nefficiently solve arbitrary density instance in a uniform way. Furthermore, our\nalgorithm has considerable performance advantage over previous algorithms.\nFirstly, it extends the density scope, in which SSP can be solved in expected\npolynomial time. Specifically, It solves SSP in expected $O(n\\log{n})$ time\nwhen density $d \\geq c\\cdot \\sqrt{n}/\\log{n}$, while the previously best\ndensity scope is $d \\geq c\\cdot n/(\\log{n})^{2}$. In addition, the overall\nexpected time and space requirement in the average case are proven to be\n$O(n^5\\log n)$ and $O(n^5)$ respectively. Secondly, in the worst case, it\nslightly improves the previously best time complexity of exact algorithms for\nSSP. Specifically, the worst-case time complexity of our algorithm is proved to\nbe $O((n-6)2^{n/2}+n)$, while the previously best result is $O(n2^{n/2})$. \n\n"}
{"id": "0801.4714", "contents": "Title: Breaking One-Round Key-Agreement Protocols in the Random Oracle Model Abstract: In this paper we study one-round key-agreement protocols analogous to\nMerkle's puzzles in the random oracle model. The players Alice and Bob are\nallowed to query a random permutation oracle $n$ times and upon their queries\nand communication, they both output the same key with high probability. We\nprove that Eve can always break such a protocol by querying the oracle $O(n^2)$\ntimes. The long-time unproven optimality of the quadratic bound in the fully\ngeneral, multi-round scenario has been shown recently by Barak and\nMahmoody-Ghidary. The results in this paper have been found independently of\ntheir work. \n\n"}
{"id": "0803.0924", "contents": "Title: What Can We Learn Privately? Abstract: Learning problems form an important category of computational tasks that\ngeneralizes many of the computations researchers apply to large real-life data\nsets. We ask: what concept classes can be learned privately, namely, by an\nalgorithm whose output does not depend too heavily on any one input or specific\ntraining example? More precisely, we investigate learning algorithms that\nsatisfy differential privacy, a notion that provides strong confidentiality\nguarantees in contexts where aggregate information is released about a database\ncontaining sensitive information about individuals. We demonstrate that,\nignoring computational constraints, it is possible to privately agnostically\nlearn any concept class using a sample size approximately logarithmic in the\ncardinality of the concept class. Therefore, almost anything learnable is\nlearnable privately: specifically, if a concept class is learnable by a\n(non-private) algorithm with polynomial sample complexity and output size, then\nit can be learned privately using a polynomial number of samples. We also\npresent a computationally efficient private PAC learner for the class of parity\nfunctions. Local (or randomized response) algorithms are a practical class of\nprivate algorithms that have received extensive investigation. We provide a\nprecise characterization of local private learning algorithms. We show that a\nconcept class is learnable by a local algorithm if and only if it is learnable\nin the statistical query (SQ) model. Finally, we present a separation between\nthe power of interactive and noninteractive local learning algorithms. \n\n"}
{"id": "0804.2940", "contents": "Title: Secret Key Agreement by Soft-decision of Signals in Gaussian Maurer's\n  Model Abstract: We consider the problem of secret key agreement in Gaussian Maurer's Model.\nIn Gaussian Maurer's model, legitimate receivers, Alice and Bob, and a\nwire-tapper, Eve, receive signals randomly generated by a satellite through\nthree independent memoryless Gaussian channels respectively. Then Alice and Bob\ngenerate a common secret key from their received signals. In this model, we\npropose a protocol for generating a common secret key by using the result of\nsoft-decision of Alice and Bob's received signals. Then, we calculate a lower\nbound on the secret key rate in our proposed protocol. As a result of\ncomparison with the protocol that only uses hard-decision, we found that the\nhigher rate is obtained by using our protocol. \n\n"}
{"id": "0806.1231", "contents": "Title: Improving Classical Authentication with Quantum Communication Abstract: We propose a quantum-enhanced protocol to authenticate classical messages,\nwith improved security with respect to the classical scheme introduced by\nBrassard in 1983. In that protocol, the shared key is the seed of a\npseudo-random generator (PRG) and a hash function is used to create the\nauthentication tag of a public message. We show that a quantum encoding of\nsecret bits offers more security than the classical XOR function introduced by\nBrassard. Furthermore, we establish the relationship between the bias of a PRG\nand the amount of information about the key that the attacker can retrieve from\na block of authenticated messages. Finally, we prove that quantum resources can\nimprove both the secrecy of the key generated by the PRG and the secrecy of the\ntag obtained with a hidden hash function. \n\n"}
{"id": "0808.3574", "contents": "Title: Classical Knowledge for Quantum Security Abstract: We propose a decision procedure for analysing security of quantum\ncryptographic protocols, combining a classical algebraic rewrite system for\nknowledge with an operational semantics for quantum distributed computing. As a\ntest case, we use our procedure to reason about security properties of a\nrecently developed quantum secret sharing protocol that uses graph states. We\nanalyze three different scenarios based on the safety assumptions of the\nclassical and quantum channels and discover the path of an attack in the\npresence of an adversary. The epistemic analysis that leads to this and similar\ntypes of attacks is purely based on our classical notion of knowledge. \n\n"}
{"id": "0809.3273", "contents": "Title: Direct and Reverse Secret-Key Capacities of a Quantum Channel Abstract: We define the direct and reverse secret-key capacities of a memoryless\nquantum channel as the optimal rates that entanglement-based quantum key\ndistribution protocols can reach by using a single forward classical\ncommunication (direct reconciliation) or a single feedback classical\ncommunication (reverse reconciliation). In particular, the reverse secret-key\ncapacity can be positive for antidegradable channels, where no forward strategy\nis known to be secure. This property is explicitly shown in the continuous\nvariable framework by considering arbitrary one-mode Gaussian channels. \n\n"}
{"id": "0811.1859", "contents": "Title: A Basic Framework for the Cryptanalysis of Digital Chaos-Based\n  Cryptography Abstract: Chaotic cryptography is based on the properties of chaos as source of\nentropy. Many different schemes have been proposed to take advantage of those\nproperties and to design new strategies to encrypt information. However, the\nright and efficient use of chaos in the context of cryptography requires a\nthorough knowledge about the dynamics of the selected chaotic system. Indeed,\nif the final encryption system reveals enough information about the underlying\nchaotic system it could be possible for a cryptanalyst to get the key, part of\nthe key or some information somehow equivalent to the key just analyzing those\ndynamical properties leaked by the cryptosystem. This paper shows what those\ndynamical properties are and how a cryptanalyst can use them to prove the\ninadequacy of an encryption system for the secure exchange of information. This\nstudy is performed through the introduction of a series of mathematical tools\nwhich should be the basic framework of cryptanalysis in the context of digital\nchaos-based cryptography. \n\n"}
{"id": "0812.4835", "contents": "Title: Semi-Quantum Key Distribution Abstract: Secure key distribution among two remote parties is impossible when both are\nclassical, unless some unproven (and arguably unrealistic)\ncomputation-complexity assumptions are made, such as the difficulty of\nfactorizing large numbers. On the other hand, a secure key distribution is\npossible when both parties are quantum. What is possible when only one party\n(Alice) is quantum, yet the other (Bob) has only classical capabilities?\nRecently, a semi-quantum key distribution protocol was presented (Boyer,\nKenigsberg and Mor, Physical Review Letters, 2007), in which one of the parties\n(Bob) is classical, and yet, the protocol is proven to be completely robust\nagainst an eavesdropping attempt.\n  Here we extend that result much further. We present two protocols with this\nconstraint, and prove their robustness against attacks: we prove that any\nattempt of an adversary to obtain information (and even a tiny amount of\ninformation) necessarily induces some errors that the legitimate parties could\nnotice. One protocol presented here is identical to the one referred to above,\nhowever, its robustness is proven here in a much more general scenario. The\nother protocol is very different as it is based on randomization. \n\n"}
{"id": "0901.2166", "contents": "Title: A Trace Based Bisimulation for the Spi Calculus Abstract: A notion of open bisimulation is formulated for the spi calculus, an\nextension of the pi-calculus with cryptographic primitives. In this\nformulation, open bisimulation is indexed by pairs of symbolic traces, which\nrepresent the history of interactions between the environment with the pairs of\nprocesses being checked for bisimilarity. The use of symbolic traces allows for\na symbolic treatment of bound input in bisimulation checking which avoids\nquantification over input values. Open bisimilarity is shown to be sound with\nrespect to testing equivalence, and futher, it is shown to be an equivalence\nrelation on processes and a congruence relation on finite processes. As far as\nwe know, this is the first formulation of open bisimulation for the spi\ncalculus for which the congruence result is proved. \n\n"}
{"id": "0901.4023", "contents": "Title: Using Kolmogorov Complexity for Understanding Some Limitations on\n  Steganography Abstract: Recently perfectly secure steganographic systems have been described for a\nwide class of sources of covertexts. The speed of transmission of secret\ninformation for these stegosystems is proportional to the length of the\ncovertext. In this work we show that there are sources of covertexts for which\nsuch stegosystems do not exist. The key observation is that if the set of\npossible covertexts has a maximal Kolmogorov complexity, then a high-speed\nperfect stegosystem has to have complexity of the same order. \n\n"}
{"id": "0901.4322", "contents": "Title: Bounds on the degree of APN polynomials The Case of $x^{-1}+g(x)$ Abstract: We prove that functions $f:\\f{2^m} \\to \\f{2^m}$ of the form\n$f(x)=x^{-1}+g(x)$ where $g$ is any non-affine polynomial are APN on at most a\nfinite number of fields $\\f{2^m}$. Furthermore we prove that when the degree of\n$g$ is less then 7 such functions are APN only if $m \\le 3$ where these\nfunctions are equivalent to $x^3$. \n\n"}
{"id": "0902.0458", "contents": "Title: On the Applicability of Combinatorial Designs to Key Predistribution for\n  Wireless Sensor Networks Abstract: The constraints of lightweight distributed computing environments such as\nwireless sensor networks lend themselves to the use of symmetric cryptography\nto provide security services. The lack of central infrastructure after\ndeployment of such networks requires the necessary symmetric keys to be\npredistributed to participating nodes. The rich mathematical structure of\ncombinatorial designs has resulted in the proposal of several key\npredistribution schemes for wireless sensor networks based on designs. We\nreview and examine the appropriateness of combinatorial designs as a tool for\nbuilding key predistribution schemes suitable for such environments. \n\n"}
{"id": "0903.3480", "contents": "Title: Worst case attacks against binary probabilistic traitor tracing codes Abstract: An insightful view into the design of traitor tracing codes should\nnecessarily consider the worst case attacks that the colluders can lead. This\npaper takes an information-theoretic point of view where the worst case attack\nis defined as the collusion strategy minimizing the achievable rate of the\ntraitor tracing code. Two different decoders are envisaged, the joint decoder\nand the simple decoder, as recently defined by P. Moulin\n\\cite{Moulin08universal}. Several classes of colluders are defined with\nincreasing power. The worst case attack is derived for each class and each\ndecoder when applied to Tardos' codes and a probabilistic version of the\nBoneh-Shaw construction. This contextual study gives the real rates achievable\nby the binary probabilistic traitor tracing codes. Attacks usually considered\nin literature, such as majority or minority votes, are indeed largely\nsuboptimal. This article also shows the utmost importance of the time-sharing\nconcept in a probabilistic codes. \n\n"}
{"id": "0904.0308", "contents": "Title: Exponential decreasing rate of leaked information in universal random\n  privacy amplification Abstract: We derive a new upper bound for Eve's information in secret key generation\nfrom a common random number without communication. This bound improves on\nBennett et al(1995)'s bound based on the R\\'enyi entropy of order 2 because the\nbound obtained here uses the R\\'enyi entropy of order $1+s$ for $s \\in [0,1]$.\nThis bound is applied to a wire-tap channel. Then, we derive an exponential\nupper bound for Eve's information. Our exponent is compared with\nHayashi(2006)'s exponent. For the additive case, the bound obtained here is\nbetter. The result is applied to secret key agreement by public discussion. \n\n"}
{"id": "0904.4458", "contents": "Title: Learning Character Strings via Mastermind Queries, with a Case Study\n  Involving mtDNA Abstract: We study the degree to which a character string, $Q$, leaks details about\nitself any time it engages in comparison protocols with a strings provided by a\nquerier, Bob, even if those protocols are cryptographically guaranteed to\nproduce no additional information other than the scores that assess the degree\nto which $Q$ matches strings offered by Bob. We show that such scenarios allow\nBob to play variants of the game of Mastermind with $Q$ so as to learn the\ncomplete identity of $Q$. We show that there are a number of efficient\nimplementations for Bob to employ in these Mastermind attacks, depending on\nknowledge he has about the structure of $Q$, which show how quickly he can\ndetermine $Q$. Indeed, we show that Bob can discover $Q$ using a number of\nrounds of test comparisons that is much smaller than the length of $Q$, under\nreasonable assumptions regarding the types of scores that are returned by the\ncryptographic protocols and whether he can use knowledge about the distribution\nthat $Q$ comes from. We also provide the results of a case study we performed\non a database of mitochondrial DNA, showing the vulnerability of existing\nreal-world DNA data to the Mastermind attack. \n\n"}
{"id": "0905.0440", "contents": "Title: Tandem Coding and Cryptography on Wiretap Channels: EXIT Chart Analysis Abstract: Traditional cryptography assumes an eavesdropper receives an error-free copy\nof the transmitted ciphertext. Wyner's wiretap channel model recognizes that at\nthe physical layer both the intended receiver and the passive eavesdropper\ninevitably receive an error-prone version of the transmitted message which must\nbe corrected prior to decryption. This paper considers the implications of\nusing both channel and cryptographic codes under the wiretap channel model in a\nway that enhances the \\emph{information-theoretic} security for the friendly\nparties by keeping the information transfer to the eavesdropper small. We\nconsider a secret-key cryptographic system with a linear feedback shift\nregister (LFSR)-based keystream generator and observe the mutual information\nbetween an LFSR-generated sequence and the received noise-corrupted ciphertext\nsequence under a known-plaintext scenario. The effectiveness of a noniterative\nfast correlation attack, which reduces the search time in a brute-force attack,\nis shown to be correlated with this mutual information. For an iterative fast\ncorrelation attack on this cryptographic system, it is shown that an EXIT chart\nand mutual information are very good predictors of decoding success and failure\nby a passive eavesdropper. \n\n"}
{"id": "0905.1778", "contents": "Title: Encoding of Network Protection Codes Against Link and Node Failures Over\n  Finite Fields Abstract: Link and node failures are common two fundamental problems that affect\noperational networks. Hence, protection of communication networks is essential\nto increase their reliability, performance, and operations. Much research work\nhas been done to protect against link and node failures, and to provide\nreliable solutions based on pre-defined provision or dynamic restoration of the\ndomain. In this paper we develop network protection strategies against multiple\nlink failures using network coding and joint capacities. In these strategies,\nthe source nodes apply network coding for their transmitted data to provide\nbackup copies for recovery at the receivers' nodes. Such techniques can be\napplied to optical, IP, and mesh networks. The encoding operations of\nprotection codes are defined over finite fields. Furthermore, the normalized\ncapacity of the communication network is given by $(n-t)/n$ in case of $t$ link\nfailures. In addition, a bound on the minimum required field size is derived. \n\n"}
{"id": "0906.1835", "contents": "Title: Secret-Key Generation using Correlated Sources and Channels Abstract: We study the problem of generating a shared secret key between two terminals\nin a joint source-channel setup -- the sender communicates to the receiver over\na discrete memoryless wiretap channel and additionally the terminals have\naccess to correlated discrete memoryless source sequences. We establish lower\nand upper bounds on the secret-key capacity. These bounds coincide,\nestablishing the capacity, when the underlying channel consists of independent,\nparallel and reversely degraded wiretap channels. In the lower bound, the\nequivocation terms of the source and channel components are functionally\nadditive. The secret-key rate is maximized by optimally balancing the the\nsource and channel contributions. This tradeoff is illustrated in detail for\nthe Gaussian case where it is also shown that Gaussian codebooks achieve the\ncapacity. When the eavesdropper also observes a source sequence, the secret-key\ncapacity is established when the sources and channels of the eavesdropper are a\ndegraded version of the legitimate receiver. Finally the case when the\nterminals also have access to a public discussion channel is studied. We\npropose generating separate keys from the source and channel components and\nestablish the optimality of this approach when the when the channel outputs of\nthe receiver and the eavesdropper are conditionally independent given the\ninput. \n\n"}
{"id": "0909.4479", "contents": "Title: Information Flow in Secret Sharing Protocols Abstract: The entangled graph states have emerged as an elegant and powerful quantum\nresource, indeed almost all multiparty protocols can be written in terms of\ngraph states including measurement based quantum computation (MBQC), error\ncorrection and secret sharing amongst others. In addition they are at the\nforefront in terms of implementations. As such they represent an excellent\nopportunity to move towards integrated protocols involving many of these\nelements. In this paper we look at expressing and extending graph state secret\nsharing and MBQC in a common framework and graphical language related to flow.\nWe do so with two main contributions.\n  First we express in entirely graphical terms which set of players can access\nwhich information in graph state secret sharing protocols. These succinct\ngraphical descriptions of access allow us to take known results from graph\ntheory to make statements on the generalisation of the previous schemes to\npresent new secret sharing protocols.\n  Second, we give a set of necessary conditions as to when a graph with flow,\ni.e. capable of performing a class of unitary operations, can be extended to\ninclude vertices which can be ignored, pointless measurements, and hence\nconsidered as unauthorised players in terms of secret sharing, or error qubits\nin terms of fault tolerance. This offers a way to extend existing MBQC patterns\nto secret sharing protocols. Our characterisation of pointless measurements is\nbelieved also to be a useful tool for further integrated measurement based\nschemes, for example in constructing fault tolerant MBQC schemes. \n\n"}
{"id": "0909.4575", "contents": "Title: Randomness Efficient Steganography Abstract: Steganographic protocols enable one to embed covert messages into\ninconspicuous data over a public communication channel in such a way that no\none, aside from the sender and the intended receiver, can even detect the\npresence of the secret message. In this paper, we provide a new\nprovably-secure, private-key steganographic encryption protocol secure in the\nframework of Hopper et al. We first present a \"one-time stegosystem\" that\nallows two parties to transmit messages of length at most that of the shared\nkey with information-theoretic security guarantees. The employment of a\npseudorandom generator (PRG) permits secure transmission of longer messages in\nthe same way that such a generator allows the use of one-time pad encryption\nfor messages longer than the key in symmetric encryption. The advantage of our\nconstruction, compared to all previous work is randomness efficiency: in the\ninformation theoretic setting our protocol embeds a message of length n bits\nusing a shared secret key of length (1+o(1))n bits while achieving security\n2^{-n/log^{O(1)}n}; simply put this gives a rate of key over message that is 1\nas n tends to infinity (the previous best result achieved a constant rate\ngreater than 1 regardless of the security offered). In this sense, our protocol\nis the first truly randomness efficient steganographic system. Furthermore, in\nour protocol, we can permit a portion of the shared secret key to be public\nwhile retaining precisely n private key bits. In this setting, by separating\nthe public and the private randomness of the shared key, we achieve security of\n2^{-n}. Our result comes as an effect of the application of randomness\nextractors to stegosystem design. To the best of our knowledge this is the\nfirst time extractors have been applied in steganography. \n\n"}
{"id": "0910.5027", "contents": "Title: Information-theoretically Secret Key Generation for Fading Wireless\n  Channels Abstract: The multipath-rich wireless environment associated with typical wireless\nusage scenarios is characterized by a fading channel response that is\ntime-varying, location-sensitive, and uniquely shared by a given\ntransmitter-receiver pair. The complexity associated with a richly scattering\nenvironment implies that the short-term fading process is inherently hard to\npredict and best modeled stochastically, with rapid decorrelation properties in\nspace, time and frequency. In this paper, we demonstrate how the channel state\nbetween a wireless transmitter and receiver can be used as the basis for\nbuilding practical secret key generation protocols between two entities. We\nbegin by presenting a scheme based on level crossings of the fading process,\nwhich is well-suited for the Rayleigh and Rician fading models associated with\na richly scattering environment. Our level crossing algorithm is simple, and\nincorporates a self-authenticating mechanism to prevent adversarial\nmanipulation of message exchanges during the protocol. Since the level crossing\nalgorithm is best suited for fading processes that exhibit symmetry in their\nunderlying distribution, we present a second and more powerful approach that is\nsuited for more general channel state distributions. This second approach is\nmotivated by observations from quantizing jointly Gaussian processes, but\nexploits empirical measurements to set quantization boundaries and a heuristic\nlog likelihood ratio estimate to achieve an improved secret key generation\nrate. We validate both proposed protocols through experimentations using a\ncustomized 802.11a platform, and show for the typical WiFi channel that\nreliable secret key establishment can be accomplished at rates on the order of\n10 bits/second. \n\n"}
{"id": "0910.5595", "contents": "Title: An Improved Implementation of Grain Abstract: A common approach to protect confidential information is to use a stream\ncipher which combines plain text bits with a pseudo-random bit sequence. Among\nthe existing stream ciphers, Non-Linear Feedback Shift Register (NLFSR)-based\nones provide the best trade-off between cryptographic security and hardware\nefficiency. In this paper, we show how to further improve the hardware\nefficiency of Grain stream cipher. By transforming the NLFSR of Grain from its\noriginal Fibonacci configuration to the Galois configuration and by introducing\na clock division block, we double the throughput of the 80 and 128-bit key\n1bit/cycle architectures of Grain with no area penalty. \n\n"}
{"id": "0912.0597", "contents": "Title: Constructing Optimal Authentication Codes with Perfect Multi-fold\n  Secrecy Abstract: We establish a construction of optimal authentication codes achieving perfect\nmulti-fold secrecy by means of combinatorial designs. This continues the\nauthor's work (ISIT 2009) and answers an open question posed therein. As an\napplication, we present the first infinite class of optimal codes that provide\ntwo-fold security against spoofing attacks and at the same time perfect two-\nfold secrecy. \n\n"}
{"id": "0912.4742", "contents": "Title: Optimizing Histogram Queries under Differential Privacy Abstract: Differential privacy is a robust privacy standard that has been successfully\napplied to a range of data analysis tasks. Despite much recent work, optimal\nstrategies for answering a collection of correlated queries are not known.\n  We study the problem of devising a set of strategy queries, to be submitted\nand answered privately, that will support the answers to a given workload of\nqueries. We propose a general framework in which query strategies are formed\nfrom linear combinations of counting queries, and we describe an optimal method\nfor deriving new query answers from the answers to the strategy queries. Using\nthis framework we characterize the error of strategies geometrically, and we\npropose solutions to the problem of finding optimal strategies. \n\n"}
{"id": "0912.5514", "contents": "Title: Trevisan's extractor in the presence of quantum side information Abstract: Randomness extraction involves the processing of purely classical information\nand is therefore usually studied in the framework of classical probability\ntheory. However, such a classical treatment is generally too restrictive for\napplications, where side information about the values taken by classical random\nvariables may be represented by the state of a quantum system. This is\nparticularly relevant in the context of cryptography, where an adversary may\nmake use of quantum devices. Here, we show that the well known construction\nparadigm for extractors proposed by Trevisan is sound in the presence of\nquantum side information.\n  We exploit the modularity of this paradigm to give several concrete extractor\nconstructions, which, e.g, extract all the conditional (smooth) min-entropy of\nthe source using a seed of length poly-logarithmic in the input, or only\nrequire the seed to be weakly random. \n\n"}
{"id": "1001.2767", "contents": "Title: Universally Optimal Privacy Mechanisms for Minimax Agents Abstract: A scheme that publishes aggregate information about sensitive data must\nresolve the trade-off between utility to information consumers and privacy of\nthe database participants. Differential privacy is a well-established\ndefinition of privacy--this is a universal guarantee against all attackers,\nwhatever their side-information or intent. In this paper, we present a\nuniversal treatment of utility based on the standard minimax rule from decision\ntheory (in contrast to the utility model in, which is Bayesian). In our model,\ninformation consumers are minimax (risk-averse) agents, each possessing some\nside-information about the query, and each endowed with a loss-function which\nmodels their tolerance to inaccuracies. Further, information consumers are\nrational in the sense that they actively combine information from the mechanism\nwith their side-information in a way that minimizes their loss. Under this\nassumption of rational behavior, we show that for every fixed count query, a\ncertain geometric mechanism is universally optimal for all minimax information\nconsumers. Additionally, our solution makes it possible to release query\nresults at multiple levels of privacy in a collusion-resistant manner. \n\n"}
{"id": "1001.3387", "contents": "Title: Universal Secure Error-Correcting Schemes for Network Coding Abstract: This paper considers the problem of securing a linear network coding system\nagainst an adversary that is both an eavesdropper and a jammer. The network is\nassumed to transport n packets from source to each receiver, and the adversary\nis allowed to eavesdrop on \\mu arbitrarily chosen links and also to inject up\nto t erroneous packets into the network. The goal of the system is to achieve\nzero-error communication that is information-theoretically secure from the\nadversary. Moreover, this goal must be attained in a universal fashion, i.e.,\nregardless of the network topology or the underlying network code. An upper\nbound on the achievable rate under these requirements is shown to be n-\\mu-2t\npackets per transmission. A scheme is proposed that can achieve this maximum\nrate, for any n and any field size q, provided the packet length m is at least\nn symbols. The scheme is based on rank-metric codes and admits low-complexity\nencoding and decoding. In addition, the scheme is shown to be optimal in the\nsense that the required packet length is the smallest possible among all\nuniversal schemes that achieve the maximum rate. \n\n"}
{"id": "1002.4548", "contents": "Title: Interference Alignment for the Multi-Antenna Compound Wiretap Channel Abstract: We study a wiretap channel model where the sender has $M$ transmit antennas\nand there are two groups consisting of $J_1$ and $J_2$ receivers respectively.\nEach receiver has a single antenna. We consider two scenarios. First we\nconsider the compound wiretap model -- group 1 constitutes the set of\nlegitimate receivers, all interested in a common message, whereas group 2 is\nthe set of eavesdroppers. We establish new lower and upper bounds on the secure\ndegrees of freedom. Our lower bound is based on the recently proposed\n\\emph{real interference alignment} scheme. The upper bound provides the first\nknown example which illustrates that the \\emph{pairwise upper bound} used in\nearlier works is not tight.\n  The second scenario we study is the compound private broadcast channel. Each\ngroup is interested in a message that must be protected from the other group.\nUpper and lower bounds on the degrees of freedom are developed by extending the\nresults on the compound wiretap channel. \n\n"}
{"id": "1005.0419", "contents": "Title: Capacity-Equivocation Region of the Gaussian MIMO Wiretap Channel Abstract: We study the Gaussian multiple-input multiple-output (MIMO) wiretap channel,\nwhich consists of a transmitter, a legitimate user, and an eavesdropper. In\nthis channel, the transmitter sends a common message to both the legitimate\nuser and the eavesdropper. In addition to this common message, the legitimate\nuser receives a private message, which is desired to be kept hidden as much as\npossible from the eavesdropper. We obtain the entire capacity-equivocation\nregion of the Gaussian MIMO wiretap channel. This region contains all\nachievable common message, private message, and private message's equivocation\n(secrecy) rates. In particular, we show the sufficiency of jointly Gaussian\nauxiliary random variables and channel input to evaluate the existing\nsingle-letter description of the capacity-equivocation region due to\nCsiszar-Korner. \n\n"}
{"id": "1008.2147", "contents": "Title: Quantum Tagging: Authenticating Location via Quantum Information and\n  Relativistic Signalling Constraints Abstract: We define the task of {\\it quantum tagging}, that is, authenticating the\nclassical location of a classical tagging device by sending and receiving\nquantum signals from suitably located distant sites, in an environment\ncontrolled by an adversary whose quantum information processing and\ntransmitting power is unbounded. We define simple security models for this task\nand briefly discuss alternatives.\n  We illustrate the pitfalls of naive quantum cryptographic reasoning in this\ncontext by describing several protocols which at first sight appear\nunconditionally secure but which, as we show, can in fact be broken by\nteleportation-based attacks. We also describe some protocols which cannot be\nbroken by these specific attacks, but do not prove they are unconditionally\nsecure.\n  We review the history of quantum tagging protocols, which we first discussed\nin 2002 and described in a 2006 patent (for an insecure protocol). The\npossibility has recently been reconsidered by other authors. All the more\nrecently discussed protocols of which we are aware were either previously\nconsidered by us in 2002-3 or are variants of schemes then considered, and all\nare provably insecure. \n\n"}
{"id": "1008.5380", "contents": "Title: Quantum Tagging for Tags Containing Secret Classical Data Abstract: Various authors have considered schemes for {\\it quantum tagging}, that is,\nauthenticating the classical location of a classical tagging device by sending\nand receiving quantum signals from suitably located distant sites, in an\nenvironment controlled by an adversary whose quantum information processing and\ntransmitting power is potentially unbounded. This task raises some interesting\nnew questions about cryptographic security assumptions, as relatively subtle\ndetails in the security model can dramatically affect the security attainable.\nWe consider here the case in which the tag is cryptographically secure, and\nshow how to implement tagging securely within this model. \n\n"}
{"id": "1010.5034", "contents": "Title: Authentication from matrix conjugation Abstract: We propose an authentication scheme where forgery (a.k.a. impersonation)\nseems infeasible without finding the prover's long-term private key. The latter\nwould follow from solving the conjugacy search problem in the platform\n(noncommutative) semigroup, i.e., to recovering X from X^{-1}AX and A. The\nplatform semigroup that we suggest here is the semigroup of nxn matrices over\ntruncated multivariable polynomials over a ring. \n\n"}
{"id": "1010.6057", "contents": "Title: Ergodic Secret Alignment Abstract: In this paper, we introduce two new achievable schemes for the fading\nmultiple access wiretap channel (MAC-WT). In the model that we consider, we\nassume that perfect knowledge of the state of all channels is available at all\nthe nodes in a causal fashion. Our schemes use this knowledge together with the\ntime varying nature of the channel model to align the interference from\ndifferent users at the eavesdropper perfectly in a one-dimensional space while\ncreating a higher dimensionality space for the interfering signals at the\nlegitimate receiver hence allowing for better chance of recovery. While we\nachieve this alignment through signal scaling at the transmitters in our first\nscheme (scaling based alignment (SBA)), we let nature provide this alignment\nthrough the ergodicity of the channel coefficients in the second scheme\n(ergodic secret alignment (ESA)). For each scheme, we obtain the resulting\nachievable secrecy rate region. We show that the secrecy rates achieved by both\nschemes scale with SNR as 1/2log(SNR). Hence, we show the sub-optimality of the\ni.i.d. Gaussian signaling based schemes with and without cooperative jamming by\nshowing that the secrecy rates achieved using i.i.d. Gaussian signaling with\ncooperative jamming do not scale with SNR. In addition, we introduce an\nimproved version of our ESA scheme where we incorporate cooperative jamming to\nachieve higher secrecy rates. Moreover, we derive the necessary optimality\nconditions for the power control policy that maximizes the secrecy sum rate\nachievable by our ESA scheme when used solely and with cooperative jamming. \n\n"}
{"id": "1011.1375", "contents": "Title: Selling Privacy at Auction Abstract: We initiate the study of markets for private data, though the lens of\ndifferential privacy. Although the purchase and sale of private data has\nalready begun on a large scale, a theory of privacy as a commodity is missing.\nIn this paper, we propose to build such a theory. Specifically, we consider a\nsetting in which a data analyst wishes to buy information from a population\nfrom which he can estimate some statistic. The analyst wishes to obtain an\naccurate estimate cheaply. On the other hand, the owners of the private data\nexperience some cost for their loss of privacy, and must be compensated for\nthis loss. Agents are selfish, and wish to maximize their profit, so our goal\nis to design truthful mechanisms. Our main result is that such auctions can\nnaturally be viewed and optimally solved as variants of multi-unit procurement\nauctions. Based on this result, we derive auctions for two natural settings\nwhich are optimal up to small constant factors:\n  1. In the setting in which the data analyst has a fixed accuracy goal, we\nshow that an application of the classic Vickrey auction achieves the analyst's\naccuracy goal while minimizing his total payment.\n  2. In the setting in which the data analyst has a fixed budget, we give a\nmechanism which maximizes the accuracy of the resulting estimate while\nguaranteeing that the resulting sum payments do not exceed the analysts budget.\n  In both cases, our comparison class is the set of envy-free mechanisms, which\ncorrespond to the natural class of fixed-price mechanisms in our setting.\n  In both of these results, we ignore the privacy cost due to possible\ncorrelations between an individuals private data and his valuation for privacy\nitself. We then show that generically, no individually rational mechanism can\ncompensate individuals for the privacy loss incurred due to their reported\nvaluations for privacy. \n\n"}
{"id": "1011.5696", "contents": "Title: Quantifying and qualifying trust: Spectral decomposition of trust\n  networks Abstract: In a previous FAST paper, I presented a quantitative model of the process of\ntrust building, and showed that trust is accumulated like wealth: the rich get\nricher. This explained the pervasive phenomenon of adverse selection of trust\ncertificates, as well as the fragility of trust networks in general. But a\nsimple explanation does not always suggest a simple solution. It turns out that\nit is impossible to alter the fragile distribution of trust without sacrificing\nsome of its fundamental functions. A solution for the vulnerability of trust\nmust thus be sought elsewhere, without tampering with its distribution. This\nobservation was the starting point of the present paper. It explores a\ndifferent method for securing trust: not by redistributing it, but by mining\nfor its sources. The method used to break privacy is thus also used to secure\ntrust. A high level view of the mining methods that connect the two is provided\nin terms of *similarity networks*, and *spectral decomposition* of similarity\npreserving maps. This view may be of independent interest, as it uncovers a\ncommon conceptual and structural foundation of mathematical classification\ntheory on one hand, and of the spectral methods of graph clustering and data\nmining on the other hand. \n\n"}
{"id": "1012.2152", "contents": "Title: Secured histories: computing group statistics on encrypted data while\n  preserving individual privacy Abstract: As sensors become ever more prevalent, more and more information will be\ncollected about each of us. A longterm research question is how best to support\nbeneficial uses while preserving individual privacy. Presence systems are an\nemerging class of applications that support collaboration. These systems\nleverage pervasive sensors to estimate end-user location, activities, and\navailable communication channels. Because such presence data are sensitive, to\nachieve wide-spread adoption, sharing models must reflect the privacy and\nsharing preferences of the users. To reflect users' collaborative relationships\nand sharing desires, we introduce CollaPSE security, in which an individual has\nfull access to her own data, a third party processes the data without learning\nanything about the data values, and users higher up in the hierarchy learn only\nstatistical information about the employees under them. We describe simple\nschemes that efficiently realize CollaPSE security for time series data. We\nimplemented these protocols using readily available cryptographic functions,\nand integrated the protocols with FXPAL's myUnity presence system. \n\n"}
{"id": "1012.4626", "contents": "Title: A Pseudo Random Numbers Generator Based on Chaotic Iterations.\n  Application to Watermarking Abstract: In this paper, a new chaotic pseudo-random number generator (PRNG) is\nproposed. It combines the well-known ISAAC and XORshift generators with chaotic\niterations. This PRNG possesses important properties of topological chaos and\ncan successfully pass NIST and TestU01 batteries of tests. This makes our\ngenerator suitable for information security applications like cryptography. As\nan illustrative example, an application in the field of watermarking is\npresented. \n\n"}
{"id": "1012.5174", "contents": "Title: SNEED: Enhancing Network Security Services Using Network Coding and\n  Joint Capacity Abstract: Traditional network security protocols depend mainly on developing\ncryptographic schemes and on using biometric methods. These have led to several\nnetwork security protocols that are unbreakable based on difficulty of solving\nuntractable mathematical problems such as factoring large integers.\n  In this paper, Security of Networks Employing Encoding and Decoding (SNEED)\nis developed to mitigate single and multiple link attacks. Network coding and\nshared capacity among the working paths are used to provide data protection and\ndata integrity against network attackers and eavesdroppers.\n  SNEED can be incorporated into various applications in on-demand TV,\nsatellite communications and multimedia security. Finally, It is shown that\nSNEED can be implemented easily where there are k edge disjoint paths between\ntwo core nodes (routers or switches) in an enterprize network. \n\n"}
{"id": "1012.5997", "contents": "Title: Protection Over Asymmetric Channels, S-MATE: Secure Multipath Adaptive\n  Traffic Engineering Abstract: Several approaches have been proposed to the problem of provisioning traffic\nengineering between core network nodes in Internet Service Provider (ISP)\nnetworks. Such approaches aim to minimize network delay, increase capacity, and\nenhance security services between two core (relay) network nodes, an ingress\nnode and an egress node. MATE (Multipath Adaptive Traffic Engineering) has been\nproposed for multipath adaptive traffic engineering between an ingress node\n(source) and an egress node (destination) to distribute the network flow among\nmultiple disjoint paths. Its novel idea is to avoid network congestion and\nattacks that might exist in edge and node disjoint paths between two core\nnetwork nodes.\n  This paper proposes protection schemes over asymmetric channels. Precisely,\nthe paper aims to develop an adaptive, robust, and reliable traffic engineering\nscheme to improve performance and reliability of communication networks. This\nscheme will also provision Quality of Server (QoS) and protection of traffic\nengineering to maximize network efficiency. Specifically, S-MATE (secure MATE)\nis proposed to protect the network traffic between two core nodes (routers,\nswitches, etc.) in a cloud network. S-MATE secures against a single link\nattack/failure by adding redundancy in one of the operational redundant paths\nbetween the sender and receiver nodes. It is also extended to secure against\nmultiple attacked links. The proposed scheme can be applied to secure core\nnetworks such as optical and IP networks. \n\n"}
{"id": "1101.4341", "contents": "Title: Lossless Compression and Complexity of Chaotic Sequences Abstract: We investigate the complexity of short symbolic sequences of chaotic\ndynamical systems by using lossless compression algorithms. In particular, we\nstudy Non-Sequential Recursive Pair Substitution (NSRPS), a lossless\ncompression algorithm first proposed by W. Ebeling et al. [Math. Biosc. 52,\n1980] and Jim\\'{e}nez-Monta\\~{n}o et al. [arXiv:cond-mat/0204134, 2002]) which\nwas subsequently shown to be optimal. NSPRS has also been used to estimate\nEntropy of written English (P. Grassberger [arXiv:physics/0207023, 2002]). We\npropose a new measure of complexity - defined as the number of iterations of\nNSRPS required to transform the input sequence into a constant sequence. We\ntest this measure on symbolic sequences of the Logistic map for various values\nof the bifurcation parameter. The proposed measure of complexity is easy to\ncompute and is observed to be highly correlated with the Lyapunov exponent of\nthe original non-linear time series, even for very short symbolic sequences (as\nshort as 50 samples). Finally, we construct symbolic sequences from the\nSkew-Tent map which are incompressible by popular compression algorithms like\nWinZip, WinRAR and 7-Zip, but compressible by NSRPS. \n\n"}
{"id": "1101.5684", "contents": "Title: On the impossibility of non-static quantum bit commitment between two\n  parties Abstract: Recently, Choi \\emph{et al}. proposed an assumption on Mayers-Lo-Chau (MLC)\nno-go theorem that the state of the entire quantum system is invariable to both\nparticipants before the unveiling phase. This means that the theorem is only\napplicable to static quantum bit commitment (QBC). This paper find that the\nassumption is unnecessary and the MLC no-go theorem can be applied to not only\nstatic QBC, but also non-static one. A non-static QBC protocol proposed by Choi\n\\emph{et al.} is briefly reviewed and analyzed to work as a supporting example.\nIn addition, a novel way to prove the impossibility of the two kinds of QBC is\ngiven. \n\n"}
{"id": "1102.3173", "contents": "Title: Coding for Cryptographic Security Enhancement using Stopping Sets Abstract: In this paper we discuss the ability of channel codes to enhance\ncryptographic secrecy. Toward that end, we present the secrecy metric of\ndegrees of freedom in an attacker's knowledge of the cryptogram, which is\nsimilar to equivocation. Using this notion of secrecy, we show how a specific\npractical channel coding system can be used to hide information about the\nciphertext, thus increasing the difficulty of cryptographic attacks. The system\nsetup is the wiretap channel model where transmitted data traverse through\nindependent packet erasure channels with public feedback for authenticated ARQ\n(Automatic Repeat reQuest). The code design relies on puncturing nonsystematic\nlow-density parity-check codes with the intent of inflicting an eavesdropper\nwith stopping sets in the decoder. Furthermore, the design amplifies errors\nwhen stopping sets occur such that a receiver must guess all the channel-erased\nbits correctly to avoid an expected error rate of one half in the ciphertext.\nWe extend previous results on the coding scheme by giving design criteria that\nreduces the effectiveness of a maximum-likelihood attack to that of a\nmessage-passing attack. We further extend security analysis to models with\nmultiple receivers and collaborative attackers. Cryptographic security is\nenhanced in all these cases by exploiting properties of the physical-layer. The\nenhancement is accurately presented as a function of the degrees of freedom in\nthe eavesdropper's knowledge of the ciphertext, and is even shown to be present\nwhen eavesdroppers have better channel quality than legitimate receivers. \n\n"}
{"id": "1103.2626", "contents": "Title: Distributed Private Data Analysis: On Simultaneously Solving How and\n  What Abstract: We examine the combination of two directions in the field of privacy\nconcerning computations over distributed private inputs - secure function\nevaluation (SFE) and differential privacy. While in both the goal is to\nprivately evaluate some function of the individual inputs, the privacy\nrequirements are significantly different. The general feasibility results for\nSFE suggest a natural paradigm for implementing differentially private analyses\ndistributively: First choose what to compute, i.e., a differentially private\nanalysis; Then decide how to compute it, i.e., construct an SFE protocol for\nthis analysis.\n  We initiate an examination whether there are advantages to a paradigm where\nboth decisions are made simultaneously. In particular, we investigate under\nwhich accuracy requirements it is beneficial to adapt this paradigm for\ncomputing a collection of functions including binary sum, gap threshold, and\napproximate median queries. Our results imply that when computing the binary\nsum of $n$ distributed inputs then:\n  * When we require that the error is $o(\\sqrt{n})$ and the number of rounds is\nconstant, there is no benefit in the new paradigm.\n  * When we allow an error of $O(\\sqrt{n})$, the new paradigm yields more\nefficient protocols when we consider protocols that compute symmetric\nfunctions.\n  Our results also yield new separations between the local and global models of\ncomputations for private data analysis. \n\n"}
{"id": "1103.3296", "contents": "Title: Decoding square-free Goppa codes over $\\F_p$ Abstract: We propose a new, efficient non-deterministic decoding algorithm for\nsquare-free Goppa codes over $\\F_p$ for any prime $p$. If the code in question\nhas degree $t$ and the average distance to the closest codeword is at least\n$(4/p)t + 1$, the proposed decoder can uniquely correct up to $(2/p)t$ errors\nwith high probability. The correction capability is higher if the distribution\nof error magnitudes is not uniform, approaching or reaching $t$ errors when any\nparticular error value occurs much more often than others or exclusively. This\nmakes the method interesting for (semantically secure) cryptosystems based on\nthe decoding problem for permuted and punctured Goppa codes. \n\n"}
{"id": "1103.4093", "contents": "Title: Aspects of Nonabelian Group Based Cryptography: A Survey and Open\n  Problems Abstract: Most common public key cryptosystems and public key exchange protocols\npresently in use, such as the RSA algorithm, Diffie-Hellman, and elliptic curve\nmethods are number theory based and hence depend on the structure of abelian\ngroups. The strength of computing machinery has made these techniques\ntheoretically susceptible to attack and hence recently there has been an active\nline of research to develop cryptosystems and key exchange protocols using\nnoncommutative cryptographic platforms. This line of investigation has been\ngiven the broad title of noncommutative algebraic cryptography. This was\ninitiated by two public key protocols that used the braid groups, one by Ko,\nLee et.al.and one by Anshel, Anshel and Goldfeld. The study of these protocols\nand the group theory surrounding them has had a large effect on research in\ninfinite group theory. In this paper we survey these noncommutative group based\nmethods and discuss several ideas in abstract infinite group theory that have\narisen from them. We then present a set of open problems. \n\n"}
{"id": "1103.4401", "contents": "Title: On the gradual deployment of random pairwise key distribution schemes\n  (Extended Version) Abstract: In the context of wireless sensor networks, the pairwise key distribution\nscheme of Chan et al. has several advantages over other key distribution\nschemes including the original scheme of Eschenauer and Gligor. However, this\noffline pairwise key distribution mechanism requires that the network size be\nset in advance, and involves all sensor nodes simultaneously. Here, we address\nthis issue by describing an implementation of the pairwise scheme that supports\nthe gradual deployment of sensor nodes in several consecutive phases. We\ndiscuss the key ring size needed to maintain the secure connectivity throughout\nall the deployment phases. In particular we show that the number of keys at\neach sensor node can be taken to be $O(\\log n)$ in order to achieve secure\nconnectivity (with high probability). \n\n"}
{"id": "1103.5188", "contents": "Title: Differential Privacy: on the trade-off between Utility and Information\n  Leakage Abstract: Differential privacy is a notion of privacy that has become very popular in\nthe database community. Roughly, the idea is that a randomized query mechanism\nprovides sufficient privacy protection if the ratio between the probabilities\nthat two adjacent datasets give the same answer is bound by e^epsilon. In the\nfield of information flow there is a similar concern for controlling\ninformation leakage, i.e. limiting the possibility of inferring the secret\ninformation from the observables. In recent years, researchers have proposed to\nquantify the leakage in terms of R\\'enyi min mutual information, a notion\nstrictly related to the Bayes risk. In this paper, we show how to model the\nquery system in terms of an information-theoretic channel, and we compare the\nnotion of differential privacy with that of mutual information. We show that\ndifferential privacy implies a bound on the mutual information (but not\nvice-versa). Furthermore, we show that our bound is tight. Then, we consider\nthe utility of the randomization mechanism, which represents how close the\nrandomized answers are, in average, to the real ones. We show that the notion\nof differential privacy implies a bound on utility, also tight, and we propose\na method that under certain conditions builds an optimal randomization\nmechanism, i.e. a mechanism which provides the best utility while guaranteeing\ndifferential privacy. \n\n"}
{"id": "1105.3879", "contents": "Title: Non-Malleable Codes from the Wire-Tap Channel Abstract: Recently, Dziembowski et al. introduced the notion of non-malleable codes\n(NMC), inspired from the notion of non-malleability in cryptography and the\nwork of Gennaro et al. in 2004 on tamper proof security. Informally, when using\nNMC, if an attacker modifies a codeword, decoding this modified codeword will\nreturn either the original message or a completely unrelated value.\n  The definition of NMC is related to a family of modifications authorized to\nthe attacker. In their paper, Dziembowski et al. propose a construction valid\nfor the family of all bit-wise independent functions.\n  In this article, we study the link between the second version of the Wire-Tap\n(WT) Channel, introduced by Ozarow and Wyner in 1984, and NMC. Using\ncoset-coding, we describe a new construction for NMC w.r.t. a subset of the\nfamily of bit-wise independent functions. Our scheme is easier to build and\nmore efficient than the one proposed by Dziembowski et al. \n\n"}
{"id": "1105.6163", "contents": "Title: Assisted Common Information: Further Results Abstract: We presented assisted common information as a generalization of\nG\\'acs-K\\\"orner (GK) common information at ISIT 2010. The motivation for our\nformulation was to improve upperbounds on the efficiency of protocols for\nsecure two-party sampling (which is a form of secure multi-party computation).\nOur upperbound was based on a monotonicity property of a rate-region (called\nthe assisted residual information region) associated with the assisted common\ninformation formulation. In this note we present further results. We explore\nthe connection of assisted common information with the Gray-Wyner system. We\nshow that the assisted residual information region and the Gray-Wyner region\nare connected by a simple relationship: the assisted residual information\nregion is the increasing hull of the Gray-Wyner region under an affine map.\nSeveral known relationships between GK common information and Gray-Wyner system\nfall out as consequences of this. Quantities which arise in other source coding\ncontexts acquire new interpretations. In previous work we showed that assisted\ncommon information can be used to derive upperbounds on the rate at which a\npair of parties can {\\em securely sample} correlated random variables, given\ncorrelated random variables from another distribution. Here we present an\nexample where the bound derived using assisted common information is much\nbetter than previously known bounds, and in fact is tight. This example\nconsiders correlated random variables defined in terms of standard variants of\noblivious transfer, and is interesting on its own as it answers a natural\nquestion about these cryptographic primitives. \n\n"}
{"id": "1106.2275", "contents": "Title: Byzantine Fault Tolerance of Regenerating Codes Abstract: Recent years have witnessed a slew of coding techniques custom designed for\nnetworked storage systems. Network coding inspired regenerating codes are the\nmost prolifically studied among these new age storage centric codes. A lot of\neffort has been invested in understanding the fundamental achievable trade-offs\nof storage and bandwidth usage to maintain redundancy in presence of different\nmodels of failures, showcasing the efficacy of regenerating codes with respect\nto traditional erasure coding techniques. For practical usability in open and\nadversarial environments, as is typical in peer-to-peer systems, we need\nhowever not only resilience against erasures, but also from (adversarial)\nerrors. In this paper, we study the resilience of generalized regenerating\ncodes (supporting multi-repairs, using collaboration among newcomers) in the\npresence of two classes of Byzantine nodes, relatively benign selfish\n(non-cooperating) nodes, as well as under more active, malicious polluting\nnodes. We give upper bounds on the resilience capacity of regenerating codes,\nand show that the advantages of collaborative repair can turn to be detrimental\nin the presence of Byzantine nodes. We further exhibit that system mechanisms\ncan be combined with regenerating codes to mitigate the effect of rogue nodes. \n\n"}
{"id": "1107.3350", "contents": "Title: Compressive Mechanism: Utilizing Sparse Representation in Differential\n  Privacy Abstract: Differential privacy provides the first theoretical foundation with provable\nprivacy guarantee against adversaries with arbitrary prior knowledge. The main\nidea to achieve differential privacy is to inject random noise into statistical\nquery results. Besides correctness, the most important goal in the design of a\ndifferentially private mechanism is to reduce the effect of random noise,\nensuring that the noisy results can still be useful.\n  This paper proposes the \\emph{compressive mechanism}, a novel solution on the\nbasis of state-of-the-art compression technique, called \\emph{compressive\nsensing}. Compressive sensing is a decent theoretical tool for compact synopsis\nconstruction, using random projections. In this paper, we show that the amount\nof noise is significantly reduced from $O(\\sqrt{n})$ to $O(\\log(n))$, when the\nnoise insertion procedure is carried on the synopsis samples instead of the\noriginal database. As an extension, we also apply the proposed compressive\nmechanism to solve the problem of continual release of statistical results.\nExtensive experiments using real datasets justify our accuracy claims. \n\n"}
{"id": "1108.0377", "contents": "Title: On Detecting Pollution Attacks in Inter-Session Network Coding Abstract: Dealing with pollution attacks in inter-session network coding is challenging\ndue to the fact that sources, in addition to intermediate nodes, can be\nmalicious. In this work, we precisely define corrupted packets in inter-session\npollution based on the commitment of the source packets. We then propose three\ndetection schemes: one hash-based and two MAC-based schemes: InterMacCPK and\nSpaceMacPM. InterMacCPK is the first multi-source homomorphic MAC scheme that\nsupports multiple keys. Both MAC schemes can replace traditional MACs, e.g.,\nHMAC, in networks that employ inter-session coding. All three schemes provide\nin-network detection, are collusion-resistant, and have very low online\nbandwidth and computation overhead. \n\n"}
{"id": "1108.2462", "contents": "Title: Enhanced public key security for the McEliece cryptosystem Abstract: This paper studies a variant of the McEliece cryptosystem able to ensure that\nthe code used as the public key is no longer permutation-equivalent to the\nsecret code. This increases the security level of the public key, thus opening\nthe way for reconsidering the adoption of classical families of codes, like\nReed-Solomon codes, that have been longly excluded from the McEliece\ncryptosystem for security reasons. It is well known that codes of these classes\nare able to yield a reduction in the key size or, equivalently, an increased\nlevel of security against information set decoding; so, these are the main\nadvantages of the proposed solution. We also describe possible vulnerabilities\nand attacks related to the considered system, and show what design choices are\nbest suited to avoid them. \n\n"}
{"id": "1108.2879", "contents": "Title: Unconditionally Secure Bit Commitment by Transmitting Measurement\n  Outcomes Abstract: We propose a new unconditionally secure bit commitment scheme based on\nMinkowski causality and the properties of quantum information. The receiving\nparty sends a number of randomly chosen BB84 qubits to the committer at a given\npoint in space-time. The committer carries out measurements in one of the two\nBB84 bases, depending on the committed bit value, and transmits the outcomes\nsecurely at light speed in opposite directions to remote agents. These agents\nunveil the bit by returning the outcomes to adjacent agents of the receiver.\nThe security proofs rely only on simple properties of quantum information and\nthe impossibility of superluminal signalling. \n\n"}
{"id": "1108.3544", "contents": "Title: Secure Lossy Transmission of Vector Gaussian Sources Abstract: We study the secure lossy transmission of a vector Gaussian source to a\nlegitimate user in the presence of an eavesdropper, where both the legitimate\nuser and the eavesdropper have vector Gaussian side information. The aim of the\ntransmitter is to describe the source to the legitimate user in a way that the\nlegitimate user can reconstruct the source within a certain distortion level\nwhile the eavesdropper is kept ignorant of the source as much as possible as\nmeasured by the equivocation. We obtain an outer bound for the rate,\nequivocation and distortion region of this secure lossy transmission problem.\nThis outer bound is tight when the transmission rate constraint is removed. In\nother words, we obtain the maximum equivocation at the eavesdropper when the\nlegitimate user needs to reconstruct the source within a fixed distortion level\nwhile there is no constraint on the transmission rate. This characterization of\nthe maximum equivocation involves two auxiliary random variables. We show that\na non-trivial selection for both random variables may be necessary in general.\nThe necessity of two auxiliary random variables also implies that, in general,\nWyner-Ziv coding is suboptimal in the presence of an eavesdropper. In addition,\nwe show that, even when there is no rate constraint on the legitimate link,\nuncoded transmission (deterministic or stochastic) is suboptimal; the presence\nof an eavesdropper necessitates the use of a coded scheme to attain the maximum\nequivocation. \n\n"}
{"id": "1108.3790", "contents": "Title: Additive combinatorics with a view towards computer science and\n  cryptography: An exposition Abstract: Recently, additive combinatorics has blossomed into a vibrant area in\nmathematical sciences. But it seems to be a difficult area to define - perhaps\nbecause of a blend of ideas and techniques from several seemingly unrelated\ncontexts which are used there. One might say that additive combinatorics is a\nbranch of mathematics concerning the study of combinatorial properties of\nalgebraic objects, for instance, Abelian groups, rings, or fields. This\nemerging field has seen tremendous advances over the last few years, and has\nrecently become a focus of attention among both mathematicians and computer\nscientists. This fascinating area has been enriched by its formidable links to\ncombinatorics, number theory, harmonic analysis, ergodic theory, and some other\nbranches; all deeply cross-fertilize each other, holding great promise for all\nof them! In this exposition, we attempt to provide an overview of some\nbreakthroughs in this field, together with a number of seminal applications to\nsundry parts of mathematics and some other disciplines, with emphasis on\ncomputer science and cryptography. \n\n"}
{"id": "1109.2637", "contents": "Title: In Things We Trust? Towards trustability in the Internet of Things Abstract: This essay discusses the main privacy, security and trustability issues with\nthe Internet of Things. \n\n"}
{"id": "1110.1851", "contents": "Title: Oblivious Storage with Low I/O Overhead Abstract: We study oblivious storage (OS), a natural way to model privacy-preserving\ndata outsourcing where a client, Alice, stores sensitive data at an\nhonest-but-curious server, Bob. We show that Alice can hide both the content of\nher data and the pattern in which she accesses her data, with high probability,\nusing a method that achieves O(1) amortized rounds of communication between her\nand Bob for each data access. We assume that Alice and Bob exchange small\nmessages, of size $O(N^{1/c})$, for some constant $c\\ge2$, in a single round,\nwhere $N$ is the size of the data set that Alice is storing with Bob. We also\nassume that Alice has a private memory of size $2N^{1/c}$. These assumptions\nmodel real-world cloud storage scenarios, where trade-offs occur between\nlatency, bandwidth, and the size of the client's private memory. \n\n"}
{"id": "1111.3602", "contents": "Title: On the Rabin signature Abstract: Some Rabin signature schemes may be exposed to forgery; several variants are\nhere described to counter this vulnerability. Blind Rabin signatures are also\ndiscussed. \n\n"}
{"id": "1112.1978", "contents": "Title: Reidentification and k-anonymity: a model for disclosure risk in graphs Abstract: In this article we provide a formal framework for reidentification in\ngeneral. We define n-confusion as a concept for modelling the anonymity of a\ndatabase table and we prove that n-confusion is a generalization of k-\nanonymity. After a short survey on the different available definitions of k-\nanonymity for graphs we provide a new definition for k-anonymous graph, which\nwe consider to be the correct definition. We provide a description of the\nk-anonymous graphs, both for the regular and the non-regular case. We also\nintroduce the more flexible concept of (k,l)-anonymous graph. Our definition of\n(k,l)-anonymous graph is meant to replace a previous definition of (k,\nl)-anonymous graph, which we here prove to have severe weaknesses. Finally we\nprovide a set of algorithms for k-anonymization of graphs. \n\n"}
{"id": "1112.2262", "contents": "Title: Perfectly secure encryption of individual sequences Abstract: In analogy to the well-known notion of finite--state compressibility of\nindividual sequences, due to Lempel and Ziv, we define a similar notion of\n\"finite-state encryptability\" of an individual plaintext sequence, as the\nminimum asymptotic key rate that must be consumed by finite-state encrypters so\nas to guarantee perfect secrecy in a well-defined sense. Our main basic result\nis that the finite-state encryptability is equal to the finite-state\ncompressibility for every individual sequence. This is in parallelism to\nShannon's classical probabilistic counterpart result, asserting that the\nminimum required key rate is equal to the entropy rate of the source. However,\nthe redundancy, defined as the gap between the upper bound (direct part) and\nthe lower bound (converse part) in the encryption problem, turns out to decay\nat a different rate (in fact, much slower) than the analogous redundancy\nassociated with the compression problem. We also extend our main theorem in\nseveral directions, allowing: (i) availability of side information (SI) at the\nencrypter/decrypter/eavesdropper, (ii) lossy reconstruction at the decrypter,\nand (iii) the combination of both lossy reconstruction and SI, in the spirit of\nthe Wyner--Ziv problem. \n\n"}
{"id": "1201.3230", "contents": "Title: Increasing the security of the ping-pong protocol by using many mutually\n  unbiased bases Abstract: In this paper we propose an extended version of the ping-pong protocol and\nstudy its security. The proposed protocol incorporates the usage of mutually\nunbiased bases in the control mode. We show that, by increasing the number of\nbases, it is possible to improve the security of this protocol. We also provide\nthe upper bounds on eavesdropping average non-detection probability and propose\na control mode modification that increases the attack detection probability. \n\n"}
{"id": "1202.0325", "contents": "Title: Quantum wiretap channel with non-uniform random number and its exponent\n  and equivocation rate of leaked information Abstract: A usual code for quantum wiretap channel requires an auxiliary random\nvariable subject to the perfect uniform distribution. However, it is difficult\nto prepare such an auxiliary random variable. We propose a code that requires\nonly an auxiliary random variable subject to a non-uniform distribution instead\nof the perfect uniform distribution. Further, we evaluate the exponential\ndecreasing rate of leaked information and derive its equivocation rate. For\npractical constructions, we also discuss the security when our code consists of\na linear error correcting code. \n\n"}
{"id": "1202.1229", "contents": "Title: Key recycling in authentication Abstract: In their seminal work on authentication, Wegman and Carter propose that to\nauthenticate multiple messages, it is sufficient to reuse the same hash\nfunction as long as each tag is encrypted with a one-time pad. They argue that\nbecause the one-time pad is perfectly hiding, the hash function used remains\ncompletely unknown to the adversary.\n  Since their proof is not composable, we revisit it using a composable\nsecurity framework. It turns out that the above argument is insufficient: if\nthe adversary learns whether a corrupted message was accepted or rejected,\ninformation about the hash function is leaked, and after a bounded finite\namount of rounds it is completely known. We show however that this leak is very\nsmall: Wegman and Carter's protocol is still $\\epsilon$-secure, if\n$\\epsilon$-almost strongly universal$_2$ hash functions are used. This implies\nthat the secret key corresponding to the choice of hash function can be reused\nin the next round of authentication without any additional error than this\n$\\epsilon$.\n  We also show that if the players have a mild form of synchronization, namely\nthat the receiver knows when a message should be received, the key can be\nrecycled for any arbitrary task, not only new rounds of authentication. \n\n"}
{"id": "1202.5302", "contents": "Title: Application of Steganography for Anonymity through the Internet Abstract: In this paper, a novel steganographic scheme based on chaotic iterations is\nproposed. This research work takes place into the information hiding security\nframework. The applications for anonymity and privacy through the Internet are\nregarded too. To guarantee such an anonymity, it should be possible to set up a\nsecret communication channel into a web page, being both secure and robust. To\nachieve this goal, we propose an information hiding scheme being stego-secure,\nwhich is the highest level of security in a well defined and studied category\nof attacks called \"watermark-only attack\". This category of attacks is the best\ncontext to study steganography-based anonymity through the Internet. The\nsteganalysis of our steganographic process is also studied in order to show it\nsecurity in a real test framework. \n\n"}
{"id": "1204.0987", "contents": "Title: A formal definition and a new security mechanism of physical unclonable\n  functions Abstract: The characteristic novelty of what is generally meant by a \"physical\nunclonable function\" (PUF) is precisely defined, in order to supply a firm\nbasis for security evaluations and the proposal of new security mechanisms. A\nPUF is defined as a hardware device which implements a physical function with\nan output value that changes with its argument. A PUF can be clonable, but a\nsecure PUF must be unclonable. This proposed meaning of a PUF is cleanly\ndelineated from the closely related concepts of \"conventional unclonable\nfunction\", \"physically obfuscated key\", \"random-number generator\", \"controlled\nPUF\" and \"strong PUF\". The structure of a systematic security evaluation of a\nPUF enabled by the proposed formal definition is outlined. Practically all\ncurrent and novel physical (but not conventional) unclonable physical functions\nare PUFs by our definition. Thereby the proposed definition captures the\nexisting intuition about what is a PUF and remains flexible enough to encompass\nfurther research. In a second part we quantitatively characterize two classes\nof PUF security mechanisms, the standard one, based on a minimum secret\nread-out time, and a novel one, based on challenge-dependent erasure of stored\ninformation. The new mechanism is shown to allow in principle the construction\nof a \"quantum-PUF\", that is absolutely secure while not requiring the storage\nof an exponentially large secret. The construction of a PUF that is\nmathematically and physically unclonable in principle does not contradict the\nlaws of physics. \n\n"}
{"id": "1204.1935", "contents": "Title: New Sequential Methods for Detecting Portscanners Abstract: In this paper, we propose new sequential methods for detecting port-scan\nattackers which routinely perform random \"portscans\" of IP addresses to find\nvulnerable servers to compromise. In addition to rigorously control the\nprobability of falsely implicating benign remote hosts as malicious, our method\nperforms significantly faster than other current solutions. Moreover, our\nmethod guarantees that the maximum amount of observational time is bounded. In\ncontrast to the previous most effective method, Threshold Random Walk\nAlgorithm, which is explicit and analytical in nature, our proposed algorithm\ninvolve parameters to be determined by numerical methods. We have developed\ncomputational techniques such as iterative minimax optimization for quick\ndetermination of the parameters of the new detection algorithm. A framework of\nmulti-valued decision for testing portscanners is also proposed. \n\n"}
{"id": "1205.3736", "contents": "Title: Towards the Impossibility of Non-Signalling Privacy Amplification from\n  Time-Like Ordering Constraints Abstract: In the past few years there was a growing interest in proving the security of\ncryptographic protocols, such as key distribution protocols, from the sole\nassumption that the systems of Alice and Bob cannot signal to each other. This\ncan be achieved by making sure that Alice and Bob perform their measurements in\na space-like separated way (and therefore signalling is impossible according to\nthe non-signalling postulate of relativity theory) or even by shielding their\napparatus. Unfortunately, it was proven in [E. Haenggi, R. Renner, and S. Wolf.\nThe impossibility of non-signaling privacy amplification] that, no matter what\nhash function we use, privacy amplification is impossible if we only impose\nnon-signalling conditions between Alice and Bob and not within their systems.\nIn this letter we reduce the gap between the assumptions of Haenggi et al. and\nthe physical relevant assumptions, from an experimental point of view, which\nsay that the systems can only signal forward in time within the systems of\nAlice and Bob. We consider a set of assumptions which is very close to the\nconditions above and prove that the impossibility result of Haenggi et al.\nstill holds. \n\n"}
{"id": "1205.5073", "contents": "Title: Secure estimation and control for cyber-physical systems under\n  adversarial attacks Abstract: The vast majority of today's critical infrastructure is supported by numerous\nfeedback control loops and an attack on these control loops can have disastrous\nconsequences. This is a major concern since modern control systems are becoming\nlarge and decentralized and thus more vulnerable to attacks. This paper is\nconcerned with the estimation and control of linear systems when some of the\nsensors or actuators are corrupted by an attacker. In the first part we look at\nthe estimation problem where we characterize the resilience of a system to\nattacks and study the possibility of increasing its resilience by a change of\nparameters. We then propose an efficient algorithm to estimate the state\ndespite the attacks and we characterize its performance. Our approach is\ninspired from the areas of error-correction over the reals and compressed\nsensing. In the second part we consider the problem of designing\noutput-feedback controllers that stabilize the system despite attacks. We show\nthat a principle of separation between estimation and control holds and that\nthe design of resilient output feedback controllers can be reduced to the\ndesign of resilient state estimators. \n\n"}
{"id": "1206.1282", "contents": "Title: Assisted Common Information with an Application to Secure Two-Party\n  Sampling Abstract: In this paper we generalize the notion of common information of two dependent\nvariables introduced by G\\'acs & K\\\"orner. They defined common information as\nthe largest entropy rate of a common random variable two parties observing one\nof the sources each can agree upon. It is well-known that their common\ninformation captures only a limited form of dependence between the random\nvariables and is zero in most cases of interest. Our generalization, which we\ncall the Assisted Common Information system, takes into account almost-common\ninformation ignored by G\\'acs-K\\\"orner common information. In the assisted\ncommon information system, a genie assists the parties in agreeing on a more\nsubstantial common random variable; we characterize the trade-off between the\namount of communication from the genie and the quality of the common random\nvariable produced using a rate region we call the region of tension.\n  We show that this region has an application in deriving upperbounds on the\nefficiency of secure two-party sampling, which is a special case of secure\nmulti-party computation, a central problem in modern cryptography. Two parties\ndesire to produce samples of a pair of jointly distributed random variables\nsuch that neither party learns more about the other's output than what its own\noutput reveals. They have access to a set up - correlated random variables\nwhose distribution is different from the desired distribution - and noiseless\ncommunication. We present an upperbound on the rate at which a given set up can\nbe used to produce samples from a desired distribution by showing a\nmonotonicity property for the region of tension: a protocol between two parties\ncan only lower the tension between their views. Then, by calculating the bounds\non the region of tension of various pairs of correlated random variables, we\nderive bounds on the rate of secure two-party sampling. \n\n"}
{"id": "1206.5930", "contents": "Title: Linear spaces and transversal designs: k-anonymous combinatorial\n  configurations for anonymous database search Abstract: Anonymous database search protocols allow users to query a database\nanonymously. This can be achieved by letting the users form a peer-to-peer\ncommunity and post queries on behalf of each other. In this article we discuss\nan application of combinatorial configurations (also known as regular and\nuniform partial linear spaces) to a protocol for anonymous database search, as\ndefining the key-distribution within the user community that implements the\nprotocol. The degree of anonymity that can be provided by the protocol is\ndetermined by properties of the neighborhoods and the closed neighborhoods of\nthe points in the combinatorial configuration that is used. Combinatorial\nconfigurations with unique neighborhoods or unique closed neighborhoods are\ndescribed and we show how to attack the protocol if such configurations are\nused. We apply k-anonymity arguments and present the combinatorial\nconfigurations with k-anonymous neighborhoods and with k-anonymous closed\nneighborhoods. The transversal designs and the linear spaces are presented as\noptimal configurations among the configurations with k-anonymous neighborhoods\nand k-anonymous closed neighborhoods, respectively. \n\n"}
{"id": "1206.6720", "contents": "Title: Dynamic Traitor Tracing for Arbitrary Alphabets: Divide and Conquer Abstract: We give a generic divide-and-conquer approach for constructing\ncollusion-resistant probabilistic dynamic traitor tracing schemes with larger\nalphabets from schemes with smaller alphabets. This construction offers a\nlinear tradeoff between the alphabet size and the codelength. In particular, we\nshow that applying our results to the binary dynamic Tardos scheme of Laarhoven\net al. leads to schemes that are shorter by a factor equal to half the alphabet\nsize. Asymptotically, these codelengths correspond, up to a constant factor, to\nthe fingerprinting capacity for static probabilistic schemes. This gives a\nhierarchy of probabilistic dynamic traitor tracing schemes, and bridges the gap\nbetween the low bandwidth, high codelength scheme of Laarhoven et al. and the\nhigh bandwidth, low codelength scheme of Fiat and Tassa. \n\n"}
{"id": "1207.1271", "contents": "Title: Automated Verification of Quantum Protocols using MCMAS Abstract: We present a methodology for the automated verification of quantum protocols\nusing MCMAS, a symbolic model checker for multi-agent systems The method is\nbased on the logical framework developed by D'Hondt and Panangaden for\ninvestigating epistemic and temporal properties, built on the model for\nDistributed Measurement-based Quantum Computation (DMC), an extension of the\nMeasurement Calculus to distributed quantum systems. We describe the\ntranslation map from DMC to interpreted systems, the typical formalism for\nreasoning about time and knowledge in multi-agent systems. Then, we introduce\ndmc2ispl, a compiler into the input language of the MCMAS model checker. We\ndemonstrate the technique by verifying the Quantum Teleportation Protocol, and\ndiscuss the performance of the tool. \n\n"}
{"id": "1207.1336", "contents": "Title: Combinatorial Solutions Providing Improved Security for the Generalized\n  Russian Cards Problem Abstract: We present the first formal mathematical presentation of the generalized\nRussian cards problem, and provide rigorous security definitions that capture\nboth basic and extended versions of weak and perfect security notions. In the\ngeneralized Russian cards problem, three players, Alice, Bob, and Cathy, are\ndealt a deck of $n$ cards, each given $a$, $b$, and $c$ cards, respectively.\nThe goal is for Alice and Bob to learn each other's hands via public\ncommunication, without Cathy learning the fate of any particular card. The\nbasic idea is that Alice announces a set of possible hands she might hold, and\nBob, using knowledge of his own hand, should be able to learn Alice's cards\nfrom this announcement, but Cathy should not. Using a combinatorial approach,\nwe are able to give a nice characterization of informative strategies (i.e.,\nstrategies allowing Bob to learn Alice's hand), having optimal communication\ncomplexity, namely the set of possible hands Alice announces must be equivalent\nto a large set of $t-(n, a, 1)$-designs, where $t=a-c$. We also provide some\ninteresting necessary conditions for certain types of deals to be\nsimultaneously informative and secure. That is, for deals satisfying $c = a-d$\nfor some $d \\geq 2$, where $b \\geq d-1$ and the strategy is assumed to satisfy\na strong version of security (namely perfect $(d-1)$-security), we show that $a\n= d+1$ and hence $c=1$. We also give a precise characterization of informative\nand perfectly $(d-1)$-secure deals of the form $(d+1, b, 1)$ satisfying $b \\geq\nd-1$ involving $d-(n, d+1, 1)$-designs. \n\n"}
{"id": "1207.1936", "contents": "Title: New Parameters of Linear Codes Expressing Security Performance of\n  Universal Secure Network Coding Abstract: The universal secure network coding presented by Silva et al. realizes secure\nand reliable transmission of a secret message over any underlying network code,\nby using maximum rank distance codes. Inspired by their result, this paper\nconsiders the secure network coding based on arbitrary linear codes, and\ninvestigates its security performance and error correction capability that are\nguaranteed independently of the underlying network code. The security\nperformance and error correction capability are said to be universal when they\nare independent of underlying network codes. This paper introduces new code\nparameters, the relative dimension/intersection profile (RDIP) and the relative\ngeneralized rank weight (RGRW) of linear codes. We reveal that the universal\nsecurity performance and universal error correction capability of secure\nnetwork coding are expressed in terms of the RDIP and RGRW of linear codes. The\nsecurity and error correction of existing schemes are also analyzed as\napplications of the RDIP and RGRW. \n\n"}
{"id": "1207.2812", "contents": "Title: Near-Optimal Algorithms for Differentially-Private Principal Components Abstract: Principal components analysis (PCA) is a standard tool for identifying good\nlow-dimensional approximations to data in high dimension. Many data sets of\ninterest contain private or sensitive information about individuals. Algorithms\nwhich operate on such data should be sensitive to the privacy risks in\npublishing their outputs. Differential privacy is a framework for developing\ntradeoffs between privacy and the utility of these outputs. In this paper we\ninvestigate the theory and empirical performance of differentially private\napproximations to PCA and propose a new method which explicitly optimizes the\nutility of the output. We show that the sample complexity of the proposed\nmethod differs from the existing procedure in the scaling with the data\ndimension, and that our method is nearly optimal in terms of this scaling. We\nfurthermore illustrate our results, showing that on real data there is a large\nperformance gap between the existing method and our method. \n\n"}
{"id": "1207.2936", "contents": "Title: Torsion Limits and Riemann-Roch Systems for Function Fields and\n  Applications Abstract: The Ihara limit (or -constant) $A(q)$ has been a central problem of study in\nthe asymptotic theory of global function fields (or equivalently, algebraic\ncurves over finite fields). It addresses global function fields with many\nrational points and, so far, most applications of this theory do not require\nadditional properties. Motivated by recent applications, we require global\nfunction fields with the additional property that their zero class divisor\ngroups contain at most a small number of $d$-torsion points. We capture this by\nthe torsion limit, a new asymptotic quantity for global function fields. It\nseems that it is even harder to determine values of this new quantity than the\nIhara constant. Nevertheless, some non-trivial lower- and upper bounds are\nderived. Apart from this new asymptotic quantity and bounds on it, we also\nintroduce Riemann-Roch systems of equations. It turns out that this type of\nequation system plays an important role in the study of several other problems\nin areas such as coding theory, arithmetic secret sharing and multiplication\ncomplexity of finite fields etc. Finally, we show how our new asymptotic\nquantity, our bounds on it and Riemann-Roch systems can be used to improve\nresults in these areas. \n\n"}
{"id": "1207.4305", "contents": "Title: Differentially Private Filtering Abstract: Emerging systems such as smart grids or intelligent transportation systems\noften require end-user applications to continuously send information to\nexternal data aggregators performing monitoring or control tasks. This can\nresult in an undesirable loss of privacy for the users in exchange of the\nbenefits provided by the application. Motivated by this trend, this paper\nintroduces privacy concerns in a system theoretic context, and addresses the\nproblem of releasing filtered signals that respect the privacy of the user data\nstreams. Our approach relies on a formal notion of privacy from the database\nliterature, called differential privacy, which provides strong privacy\nguarantees against adversaries with arbitrary side information. Methods are\ndeveloped to approximate a given filter by a differentially private version, so\nthat the distortion introduced by the privacy mechanism is minimized. Two\nspecific scenarios are considered. First, the notion of differential privacy is\nextended to dynamic systems with many participants contributing independent\ninput signals. Kalman filtering is also discussed in this context, when a\nreleased output signal must preserve differential privacy for the measured\nsignals or state trajectories of the individual participants. Second,\ndifferentially private mechanisms are described to approximate stable filters\nwhen participants contribute to a single event stream, extending previous work\non differential privacy under continual observation. \n\n"}
{"id": "1207.4871", "contents": "Title: Intruder deducibility constraints with negation. Decidability and\n  application to secured service compositions Abstract: The problem of finding a mediator to compose secured services has been\nreduced in our former work to the problem of solving deducibility constraints\nsimilar to those employed for cryptographic protocol analysis. We extend in\nthis paper the mediator synthesis procedure by a construction for expressing\nthat some data is not accessible to the mediator. Then we give a decision\nprocedure for verifying that a mediator satisfying this non-disclosure policy\ncan be effectively synthesized. This procedure has been implemented in CL-AtSe,\nour protocol analysis tool. The procedure extends constraint solving for\ncryptographic protocol analysis in a significative way as it is able to handle\nnegative deducibility constraints without restriction. In particular it applies\nto all subterm convergent theories and therefore covers several interesting\ntheories in formal security analysis including encryption, hashing, signature\nand pairing. \n\n"}
{"id": "1207.6380", "contents": "Title: About the Linear Complexity of Ding-Hellesth Generalized Cyclotomic\n  Binary Sequences of Any Period Abstract: We defined sufficient conditions for designing Ding-Helleseth sequences with\narbitrary period and high linear complexity for generalized cyclotomies. Also\nwe discuss the method of computing the linear complexity of Ding-Helleseth\nsequences in the general case. \n\n"}
{"id": "1208.1458", "contents": "Title: Security Details for Bit Commitment by Transmitting Measurement Outcomes Abstract: We spell out details of a simple argument for a security bound for the secure\nrelativistic quantum bit commitment protocol of Ref. [1]. \n\n"}
{"id": "1208.2896", "contents": "Title: Efficient Quasigroup Block Cipher for Sensor Networks Abstract: We present a new quasigroup based block encryption system with and without\ncipher-block-chaining. We compare its performance against Advanced Encryption\nStandard-256 (AES256) bit algorithm using the NIST statistical test suite\n(NIST-STS) that tests for randomness of a sequence. Since it is well known that\na good encryption algorithm must destroy any statistical properties of the\ninput sequence and produce an output close to a true random sequence, the\nNIST-STS suite results provide a good test bench. In almost all tests from the\nsuite the proposed algorithm performs better than AES256. \n\n"}
{"id": "1208.3790", "contents": "Title: Secret Key Generation from Sparse Wireless Channels: Ergodic Capacity\n  and Secrecy Outage Abstract: This paper investigates generation of a secret key from a reciprocal wireless\nchannel. In particular we consider wireless channels that exhibit sparse\nstructure in the wideband regime and the impact of the sparsity on the secret\nkey capacity. We explore this problem in two steps. First, we study key\ngeneration from a state-dependent discrete memoryless multiple source. The\nstate of source captures the effect of channel sparsity. Secondly, we consider\na wireless channel model that captures channel sparsity and correlation between\nthe legitimate users' channel and the eavesdropper's channel. Such dependency\ncan significantly reduce the secret key capacity.\n  According to system delay requirements, two performance measures are\nconsidered: (i) ergodic secret key capacity and (ii) outage probability. We\nshow that in the wideband regime when a white sounding sequence is adopted, a\nsparser channel can achieve a higher ergodic secret key rate than a richer\nchannel can. For outage performance, we show that if the users generate secret\nkeys at a fraction of the ergodic capacity, the outage probability will decay\nexponentially in signal bandwidth. Moreover, a larger exponent is achieved by a\nricher channel. \n\n"}
{"id": "1208.5258", "contents": "Title: A Theory of Pricing Private Data Abstract: Personal data has value to both its owner and to institutions who would like\nto analyze it. Privacy mechanisms protect the owner's data while releasing to\nanalysts noisy versions of aggregate query results. But such strict protections\nof individual's data have not yet found wide use in practice. Instead, Internet\ncompanies, for example, commonly provide free services in return for valuable\nsensitive information from users, which they exploit and sometimes sell to\nthird parties.\n  As the awareness of the value of the personal data increases, so has the\ndrive to compensate the end user for her private information. The idea of\nmonetizing private data can improve over the narrower view of hiding private\ndata, since it empowers individuals to control their data through financial\nmeans.\n  In this paper we propose a theoretical framework for assigning prices to\nnoisy query answers, as a function of their accuracy, and for dividing the\nprice amongst data owners who deserve compensation for their loss of privacy.\nOur framework adopts and extends key principles from both differential privacy\nand query pricing in data markets. We identify essential properties of the\nprice function and micro-payments, and characterize valid solutions. \n\n"}
{"id": "1209.0365", "contents": "Title: Attacks on quantum key distribution protocols that employ non-ITS\n  authentication Abstract: We demonstrate how adversaries with unbounded computing resources can break\nQuantum Key Distribution (QKD) protocols which employ a particular message\nauthentication code suggested previously. This authentication code, featuring\nlow key consumption, is not Information-Theoretically Secure (ITS) since for\neach message the eavesdropper has intercepted she is able to send a different\nmessage from a set of messages that she can calculate by finding collisions of\na cryptographic hash function. However, when this authentication code was\nintroduced it was shown to prevent straightforward Man-In-The-Middle (MITM)\nattacks against QKD protocols.\n  In this paper, we prove that the set of messages that collide with any given\nmessage under this authentication code contains with high probability a message\nthat has small Hamming distance to any other given message. Based on this fact\nwe present extended MITM attacks against different versions of BB84 QKD\nprotocols using the addressed authentication code; for three protocols we\ndescribe every single action taken by the adversary. For all protocols the\nadversary can obtain complete knowledge of the key, and for most protocols her\nsuccess probability in doing so approaches unity.\n  Since the attacks work against all authentication methods which allow to\ncalculate colliding messages, the underlying building blocks of the presented\nattacks expose the potential pitfalls arising as a consequence of non-ITS\nauthentication in QKD-postprocessing. We propose countermeasures, increasing\nthe eavesdroppers demand for computational power, and also prove necessary and\nsufficient conditions for upgrading the discussed authentication code to the\nITS level. \n\n"}
{"id": "1209.2423", "contents": "Title: Reply to recent scepticism about the foundations of quantum cryptography Abstract: In a series of recent papers, Hirota and Yuen claim to have identified a\nfundamental flaw in the theory underlying quantum cryptography, which would\ninvalidate existing security proofs. In this short note, we sketch their\nargument and show that their conclusion is unjustified --- it originates from a\nconfusion between necessary and sufficient criteria for secrecy. \n\n"}
{"id": "1209.3458", "contents": "Title: A New Efficient Asymmetric Cryptosystem Based on the Integer\n  Factorization Problem Abstract: A new asymmetric cryptosystem based on the Integer Factorization Problem is\nproposed. It posses an encryption and decryption speed of $O(n^2)$, thus making\nit the fastest asymmetric encryption scheme available. It has a simple\nmathematical structure. Thus, it would have low computational requirements and\nwould enable communication devices with low computing power to deploy secure\ncommunication procedures efficiently. \n\n"}
{"id": "1209.5520", "contents": "Title: Accelerating Iterative SpMV for Discrete Logarithm Problem Using GPUs Abstract: In the context of cryptanalysis, computing discrete logarithms in large\ncyclic groups using index-calculus-based methods, such as the number field\nsieve or the function field sieve, requires solving large sparse systems of\nlinear equations modulo the group order. Most of the fast algorithms used to\nsolve such systems --- e.g., the conjugate gradient or the Lanczos and\nWiedemann algorithms --- iterate a product of the corresponding sparse matrix\nwith a vector (SpMV). This central operation can be accelerated on GPUs using\nspecific computing models and addressing patterns, which increase the\narithmetic intensity while reducing irregular memory accesses. In this work, we\ninvestigate the implementation of SpMV kernels on NVIDIA GPUs, for several\nrepresentations of the sparse matrix in memory. We explore the use of Residue\nNumber System (RNS) arithmetic to accelerate modular operations. We target\nlinear systems arising when attacking the discrete logarithm problem on groups\nof size 100 to 1000 bits, which includes the relevant range for current\ncryptanalytic computations. The proposed SpMV implementation contributed to\nsolving the discrete logarithm problem in GF($2^{619}$) and GF($2^{809}$) using\nthe FFS algorithm. \n\n"}
{"id": "1210.2123", "contents": "Title: Privacy Against Statistical Inference Abstract: We propose a general statistical inference framework to capture the privacy\nthreat incurred by a user that releases data to a passive but curious\nadversary, given utility constraints. We show that applying this general\nframework to the setting where the adversary uses the self-information cost\nfunction naturally leads to a non-asymptotic information-theoretic approach for\ncharacterizing the best achievable privacy subject to utility constraints.\nBased on these results we introduce two privacy metrics, namely average\ninformation leakage and maximum information leakage. We prove that under both\nmetrics the resulting design problem of finding the optimal mapping from the\nuser's data to a privacy-preserving output can be cast as a modified\nrate-distortion problem which, in turn, can be formulated as a convex program.\nFinally, we compare our framework with differential privacy. \n\n"}
{"id": "1210.7931", "contents": "Title: Polymatroids and polyquantoids Abstract: When studying entropy functions of multivariate probability distributions,\npolymatroids and matroids emerge. Entropy functions of pure multiparty quantum\nstates give rise to analogous notions, called here polyquantoids and quantoids.\nPolymatroids and polyquantoids are related via linear mappings and duality.\nQuantum secret sharing schemes that are ideal are described by selfdual\nmatroids. Expansions of integer polyquantoids to quantoids are studied and\nlinked to that of polymatroids. \n\n"}
{"id": "1210.8114", "contents": "Title: Polynomial-time solutions of computational problems in\n  noncommutative-algebraic cryptography Abstract: We introduce the \\emph{linear centralizer method}, and use it to devise a\nprovable polynomial time solution of the Commutator Key Exchange Problem, the\ncomputational problem on which, in the passive adversary model, the security of\nthe Anshel--Anshel--Goldfeld 1999 \\emph{Commutator} key exchange protocol is\nbased. We also apply this method to the computational problem underlying the\n\\emph{Centralizer} key exchange protocol, introduced by Shpilrain and Ushakov\nin 2006.\n  This is the first provable polynomial time cryptanalysis of the Commutator\nkey exchange protocol, hitherto the most important key exchange protocol in the\nrealm of noncommutative-algebraic cryptography, and the first cryptanalysis (of\nany kind) of the Centralizer key exchange protocol. Unlike earlier\ncryptanalyses of the Commutator key exchange protocol, our cryptanalyses cannot\nbe foiled by changing the distributions used in the protocol. \n\n"}
{"id": "1211.1125", "contents": "Title: Limits of privacy amplification against non-signalling memory attacks Abstract: The task of privacy amplification, in which Alice holds some partially secret\ninformation with respect to an adversary Eve and wishes to distill it until it\nis completely secret, is known to be solvable almost optimally both in the\nclassical and quantum world. Unfortunately, when considering an adversary who\nis only limited by non-signalling constraints such a statement cannot be made\nin general. We here prove that under the natural assumptions of time-ordered\nnon-signalling system, which allow past subsystems to signal future subsystems\n(using the device's memory for example), super-polynomial privacy amplification\nby any hashing is impossible. This is in great relevance when considering\npractical device independent key distribution protocols which assume a\nsuper-quantum adversary. \n\n"}
{"id": "1211.1572", "contents": "Title: Embedding grayscale halftone pictures in QR Codes using Correction Trees Abstract: Barcodes like QR Codes have made that encoded messages have entered our\neveryday life, what suggests to attach them a second layer of information:\ndirectly available to human receiver for informational or marketing purposes.\nWe will discuss a general problem of using codes with chosen statistical\nconstrains, for example reproducing given grayscale picture using halftone\ntechnique. If both sender and receiver know these constrains, the optimal\ncapacity can be easily approached by entropy coder. The problem is that this\ntime only the sender knows them - we will refer to these scenarios as\nconstrained coding. Kuznetsov and Tsybakov problem in which only the sender\nknows which bits are fixed can be seen as a special case, surprisingly\napproaching the same capacity as if both sides would know the constrains. We\nwill analyze Correction Trees to approach analogous capacity in the general\ncase - use weaker: statistical constrains, what allows to apply them to all\nbits. Finding satisfying coding is similar to finding the proper correction in\nerror correction problem, but instead of single ensured possibility, there are\nnow statistically expected some. While in standard steganography we hide\ninformation in the least important bits, this time we create codes resembling\ngiven picture - hide information in the freedom of realizing grayness by black\nand white pixels using halftone technique. We will also discuss combining with\nerror correction and application to rate distortion problem. \n\n"}
{"id": "1301.1026", "contents": "Title: On the complexity of the Rank Syndrome Decoding problem Abstract: In this paper we propose two new generic attacks on the Rank Syndrome\nDecoding (RSD) problem\n  Let $C$ be a random $[n,k]$ rank code over $GF(q^m)$ and let $y=x+e$ be a\nreceived word such that $x \\in C$ and the $Rank(e)=r$. The first attack is\ncombinatorial and permits to recover an error $e$ of rank weight $r$ in\n$min(O((n-k)^3m^3q^{r\\lfloor\\frac{km}{n}\\rfloor},\nO((n-k)^3m^3q^{(r-1)\\lfloor\\frac{(k+1)m}{n}\\rfloor}))$ operations on $GF(q)$.\nThis attack dramatically improves on previous attack by introducing the length\n$n$ of the code in the exponent of the complexity, which was not the case in\nprevious generic attacks. which can be considered The second attack is based on\na algebraic attacks: based on the theory of $q$-polynomials introduced by Ore\nwe propose a new algebraic setting for the RSD problem that permits to consider\nequations and unknowns in the extension field $GF(q^m)$ rather than in $GF(q)$\nas it is usually the case. We consider two approaches to solve the problem in\nthis new setting. Linearization technics show that if $n \\ge (k+1)(r+1)-1$ the\nRSD problem can be solved in polynomial time, more generally we prove that if\n$\\lceil \\frac{(r+1)(k+1)-(n+1)}{r} \\rceil \\le k$, the problem can be solved\nwith an average complexity $O(r^3k^3q^{r\\lceil \\frac{(r+1)(k+1)-(n+1)}{r}\n\\rceil})$. We also consider solving with \\grob bases for which which we discuss\ntheoretical complexity, we also consider consider hybrid solving with \\grob\nbases on practical parameters. As an example of application we use our new\nattacks on all proposed recent cryptosystems which reparation the GPT\ncryptosystem, we break all examples of published proposed parameters, some\nparameters are broken in less than 1 s in certain cases. \n\n"}
{"id": "1301.1746", "contents": "Title: Generalized Secure Transmission Protocol for Flexible Load-Balance\n  Control with Cooperative Relays in Two-Hop Wireless Networks Abstract: This work considers secure transmission protocol for flexible load-balance\ncontrol in two-hop relay wireless networks without the information of both\neavesdropper channels and locations. The available secure transmission\nprotocols via relay cooperation in physical layer secrecy framework cannot\nprovide a flexible load-balance control, which may significantly limit their\napplication scopes. This paper extends the conventional works and proposes a\ngeneral transmission protocol with considering load-balance control, in which\nthe relay is randomly selected from the first $k$ preferable assistant relays\nlocated in the circle area with the radius $r$ and the center at the middle\nbetween source and destination (2HR-($r,k$) for short). This protocol covers\nthe available works as special cases, like ones with the optimal relay\nselection ($r=\\infty$, $k=1$) and with the random relay selection ($r=\\infty$,\n$k = n$ i.e. the number of system nodes) in the case of equal path-loss, ones\nwith relay selected from relay selection region ($r \\in (0, \\infty), k = 1$) in\nthe case of distance-dependent path-loss. The theoretic analysis is further\nprovided to determine the maximum number of eavesdroppers one network can\ntolerate to ensure a desired performance in terms of the secrecy outage\nprobability and transmission outage probability. The analysis results also show\nthe proposed protocol can balance load distributed among the relays by a proper\nsetting of $r$ and $k$ under the premise of specified secure and reliable\nrequirements. \n\n"}
{"id": "1301.3402", "contents": "Title: Constraint Expressions and Workflow Satisfiability Abstract: A workflow specification defines a set of steps and the order in which those\nsteps must be executed. Security requirements and business rules may impose\nconstraints on which users are permitted to perform those steps. A workflow\nspecification is said to be satisfiable if there exists an assignment of\nauthorized users to workflow steps that satisfies all the constraints. An\nalgorithm for determining whether such an assignment exists is important, both\nas a static analysis tool for workflow specifications, and for the construction\nof run-time reference monitors for workflow management systems. We develop new\nmethods for determining workflow satisfiability based on the concept of\nconstraint expressions, which were introduced recently by Khan and Fong. These\nmethods are surprising versatile, enabling us to develop algorithms for, and\ndetermine the complexity of, a number of different problems related to workflow\nsatisfiability. \n\n"}
{"id": "1301.4289", "contents": "Title: A geometric protocol for cryptography with cards Abstract: In the generalized Russian cards problem, the three players Alice, Bob and\nCath draw a,b and c cards, respectively, from a deck of a+b+c cards. Players\nonly know their own cards and what the deck of cards is. Alice and Bob are then\nrequired to communicate their hand of cards to each other by way of public\nmessages. The communication is said to be safe if Cath does not learn the\nownership of any specific card; in this paper we consider a strengthened notion\nof safety introduced by Swanson and Stinson which we call k-safety.\n  An elegant solution by Atkinson views the cards as points in a finite\nprojective plane. We propose a general solution in the spirit of Atkinson's,\nalthough based on finite vector spaces rather than projective planes, and call\nit the `geometric protocol'. Given arbitrary c,k>0, this protocol gives an\ninformative and k-safe solution to the generalized Russian cards problem for\ninfinitely many values of (a,b,c) with b=O(ac). This improves on the collection\nof parameters for which solutions are known. In particular, it is the first\nsolution which guarantees $k$-safety when Cath has more than one card. \n\n"}
{"id": "1301.5136", "contents": "Title: Secret Key Agreement Using Conferencing in State- Dependent Multiple\n  Access Channels with An Eavesdropper Abstract: In this paper, the problem of secret key agreement in state-dependent\nmultiple access channels with an eavesdropper is studied. For this model, the\nchannel state information is non-causally available at the transmitters;\nfurthermore, a legitimate receiver observes a degraded version of the channel\nstate information. The transmitters can partially cooperate with each other\nusing a conferencing link with a limited rate. In addition, a backward public\nchannel is assumed between the terminals. The problem of secret key sharing\nconsists of two rounds. In the first round, the transmitters wish to share a\ncommon key with the legitimate receiver. Lower and upper bounds on the common\nkey capacity are established. In a special case, the capacity of the common key\nis obtained. In the second round, the legitimate receiver agrees on two\nindependent private keys with the corresponding transmitters using the public\nchannel. Inner and outer bounds on the private key capacity region are\ncharacterized. In a special case, the inner bound coincides with the outer\nbound. We provide some examples to illustrate our results. \n\n"}
{"id": "1301.5482", "contents": "Title: Relative Generalized Rank Weight of Linear Codes and Its Applications to\n  Network Coding Abstract: By extending the notion of minimum rank distance, this paper introduces two\nnew relative code parameters of a linear code C_1 of length n over a field\nextension and its subcode C_2. One is called the relative\ndimension/intersection profile (RDIP), and the other is called the relative\ngeneralized rank weight (RGRW). We clarify their basic properties and the\nrelation between the RGRW and the minimum rank distance. As applications of the\nRDIP and the RGRW, the security performance and the error correction capability\nof secure network coding, guaranteed independently of the underlying network\ncode, are analyzed and clarified. We propose a construction of secure network\ncoding scheme, and analyze its security performance and error correction\ncapability as an example of applications of the RDIP and the RGRW. Silva and\nKschischang showed the existence of a secure network coding in which no part of\nthe secret message is revealed to the adversary even if any dim C_1-1 links are\nwiretapped, which is guaranteed over any underlying network code. However, the\nexplicit construction of such a scheme remained an open problem. Our new\nconstruction is just one instance of secure network coding that solves this\nopen problem. \n\n"}
{"id": "1301.7351", "contents": "Title: Why quantum computing is hard - and quantum cryptography is not provably\n  secure Abstract: Despite high hopes for quantum computation in the 1990s, progress in the past\ndecade has been slow; we still cannot perform computation with more than about\nthree qubits and are no closer to solving problems of real interest than a\ndecade ago. Separately, recent experiments in fluid mechanics have demonstrated\nthe emergence of a full range of quantum phenomena from completely classical\nmotion. We present two specific hypotheses. First, Kuramoto theory may give a\nbasis for geometrical thinking about entanglement. Second, we consider a recent\nsoliton model of the electron, in which the quantum-mechanical wave function is\na phase modulation of a carrier wave. Both models are consistent with one\nanother and with observation. Both models suggest how entanglement and\ndecoherence may be related to device geometry. Both models predict that it will\nbe difficult to maintain phase coherence of more than three qubits in the\nplane, or four qubits in a three-dimensional structure. The soliton model also\nshows that the experimental work which appeared to demonstrate a violation of\nBell's inequalities might not actually do so; regardless of whether it is a\ncorrect description of the world, it exposes a flaw in the logic of the Bell\ntests. Thus the case for the security of EPR-based quantum cryptography has\njust not been made. We propose experiments in quantum computation to test this.\nFinally, we examine two possible interpretations of such soliton models: one is\nconsistent with the transactional interpretation of quantum mechanics, while\nthe other is an entirely classical model in which we do not have to abandon the\nidea of a single world where action is local and causal. \n\n"}
{"id": "1303.0707", "contents": "Title: On the Achievable Error Region of Physical Layer Authentication\n  Techniques over Rayleigh Fading Channels Abstract: For a physical layer message authentication procedure based on the comparison\nof channel estimates obtained from the received messages, we focus on an outer\nbound on the type I/II error probability region. Channel estimates are modelled\nas multivariate Gaussian vectors, and we assume that the attacker has only some\nside information on the channel estimate, which he does not know directly. We\nderive the attacking strategy that provides the tightest bound on the error\nregion, given the statistics of the side information. This turns out to be a\nzero mean, circularly symmetric Gaussian density whose correlation matrices may\nbe obtained by solving a constrained optimization problem. We propose an\niterative algorithm for its solution: Starting from the closed form solution of\na relaxed problem, we obtain, by projection, an initial feasible solution;\nthen, by an iterative procedure, we look for the fixed point solution of the\nproblem. Numerical results show that for cases of interest the iterative\napproach converges, and perturbation analysis shows that the found solution is\na local minimum. \n\n"}
{"id": "1303.0930", "contents": "Title: An Authentication Scheme for Subspace Codes over Network Based on Linear\n  Codes Abstract: Network coding provides the advantage of maximizing the usage of network\nresources, and has great application prospects in future network\ncommunications. However, the properties of network coding also make the\npollution attack more serious. In this paper, we give an unconditional secure\nauthentication scheme for network coding based on a linear code $C$.\nSafavi-Naini and Wang gave an authentication code for multi-receivers and\nmultiple messages. We notice that the scheme of Safavi-Naini and Wang is\nessentially constructed with Reed-Solomon codes. And we modify their\nconstruction slightly to make it serve for authenticating subspace codes over\nlinear network. Also, we generalize the construction with linear codes. The\ngeneralization to linear codes has the similar advantages as generalizing\nShamir's secret sharing scheme to linear secret sharing sceme based on linear\ncodes. One advantage of this generalization is that for a fixed message space,\nour scheme allows arbitrarily many receivers to check the integrity of their\nown messages, while the scheme with Reed-Solomon codes has a constraint on the\nnumber of verifying receivers. Another advantage is that we introduce access\nstructure in the generalized scheme. Massey characterized the access structure\nof linear secret sharing scheme by minimal codewords in the dual code whose\nfirst component is 1. We slightly modify the definition of minimal codewords.\nLet $C$ be a $[V,k]$ linear code. For any coordinate $i\\in \\{1,2,\\cdots,V\\}$, a\ncodeword $\\vec{c}$ in $C$ is called minimal respect to $i$ if the codeword\n$\\vec{c}$ has component 1 at the $i$-th coordinate and there is no other\ncodeword whose $i$-th component is 1 with support strictly contained in that of\n$\\vec{c}$. Then the security of receiver $R_i$ in our authentication scheme is\ncharacterized by the minimal codewords respect to $i$ in the dual code\n$C^\\bot$. \n\n"}
{"id": "1303.7328", "contents": "Title: Elementary Deduction Problem for Locally Stable Theories with Normal\n  Forms Abstract: We present an algorithm to decide the intruder deduction problem (IDP) for a\nclass of locally stable theories enriched with normal forms. Our result relies\non a new and efficient algorithm to solve a restricted case of higher-order\nassociative-commutative matching, obtained by combining the Distinct\nOccurrences of AC- matching algorithm and a standard algorithm to solve systems\nof linear Diophantine equations. A translation between natural deduction and\nsequent calculus allows us to use the same approach to decide the\n\\emphelementary deduction problem for locally stable theories. As an\napplication, we model the theory of blind signatures and derive an algorithm to\ndecide IDP in this context, extending previous decidability results. \n\n"}
{"id": "1304.0555", "contents": "Title: Distributed quantum election scheme Abstract: In an electronic voting protocol, a distributed scheme can be used for\nforbidding the malicious acts of the voting administrator and the counter\nduring the election, but it cannot prevent them from collaborating to trace the\nballots and destroy their privacy after the election. We present a distributed\nanonymous quantum key distribution scheme and further construct a distributed\nquantum election scheme with a voting administrator made up of more than one\npart. This quantum election scheme can resist the malicious acts of the voting\nadministrator and the counter after the election and can work in a system with\nlossy and noisy quantum channels. \n\n"}
{"id": "1304.2313", "contents": "Title: On Differentially Private Filtering for Event Streams Abstract: Rigorous privacy mechanisms that can cope with dynamic data are required to\nencourage a wider adoption of large-scale monitoring and decision systems\nrelying on end-user information. A promising approach to develop these\nmechanisms is to specify quantitative privacy requirements at design time\nrather than as an afterthought, and to rely on signal processing techniques to\nachieve satisfying trade-offs between privacy and performance specifications.\nThis paper discusses, from the signal processing point of view, an event stream\nanalysis problem introduced in the database and cryptography literature. A\ndiscrete-valued input signal describes the occurrence of events contributed by\nend-users, and a system is supposed to provide some output signal based on this\ninformation, while preserving the privacy of the participants. The notion of\nprivacy adopted here is that of event-level differential privacy, which\nprovides strong privacy guarantees and has important operational advantages.\nSeveral mechanisms are described to provide differentially private output\nsignals while minimizing the impact on performance. These mechanisms\ndemonstrate the benefits of leveraging system theoretic techniques to provide\nprivacy guarantees for dynamic systems. \n\n"}
{"id": "1304.4613", "contents": "Title: On the Benefits of Sampling in Privacy Preserving Statistical Analysis\n  on Distributed Databases Abstract: We consider a problem where mutually untrusting curators possess portions of\na vertically partitioned database containing information about a set of\nindividuals. The goal is to enable an authorized party to obtain aggregate\n(statistical) information from the database while protecting the privacy of the\nindividuals, which we formalize using Differential Privacy. This process can be\nfacilitated by an untrusted server that provides storage and processing\nservices but should not learn anything about the database. This work describes\na data release mechanism that employs Post Randomization (PRAM), encryption and\nrandom sampling to maintain privacy, while allowing the authorized party to\nconduct an accurate statistical analysis of the data. Encryption ensures that\nthe storage server obtains no information about the database, while PRAM and\nsampling ensures individual privacy is maintained against the authorized party.\nWe characterize how much the composition of random sampling with PRAM increases\nthe differential privacy of system compared to using PRAM alone. We also\nanalyze the statistical utility of our system, by bounding the estimation error\n- the expected l2-norm error between the true empirical distribution and the\nestimated distribution - as a function of the number of samples, PRAM noise,\nand other system parameters. Our analysis shows a tradeoff between increasing\nPRAM noise versus decreasing the number of samples to maintain a desired level\nof privacy, and we determine the optimal number of samples that balances this\ntradeoff and maximizes the utility. In experimental simulations with the UCI\n\"Adult Data Set\" and with synthetically generated data, we confirm that the\ntheoretically predicted optimal number of samples indeed achieves close to the\nminimal empirical error, and that our analytical error bounds match well with\nthe empirical results. \n\n"}
{"id": "1305.0854", "contents": "Title: Off-Path Hacking: The Illusion of Challenge-Response Authentication Abstract: Everyone is concerned about the Internet security, yet most traffic is not\ncryptographically protected. The usual justification is that most attackers are\nonly off-path and cannot intercept traffic; hence, challenge-response\nmechanisms suffice to ensure authenticity. Usually, the challenges re-use\nexisting `unpredictable' header fields to protect widely-deployed protocols\nsuch as TCP and DNS. We argue that this practice may often only give an\nillusion of security. We present recent off-path TCP injection and DNS\npoisoning attacks, enabling attackers to circumvent existing challenge-response\ndefenses. Both TCP and DNS attacks are non-trivial, yet very efficient and\npractical. The attacks foil widely deployed security mechanisms, such as the\nSame Origin Policy, and allow a wide range of exploits, e.g., long-term caching\nof malicious objects and scripts. We hope that this article will motivate\nadoption of cryptographic mechanisms such as SSL/TLS, IPsec and DNSSEC, and of\ncorrect, secure challenge-response mechanisms. \n\n"}
{"id": "1305.1415", "contents": "Title: Centralized and Cooperative Transmission of Secure Multiple Unicasts\n  using Network Coding Abstract: We introduce a method for securely delivering a set of messages to a group of\nclients over a broadcast erasure channel where each client is interested in a\ndistinct message. Each client is able to obtain its own message but not the\nothers'. In the proposed method the messages are combined together using a\nspecial variant of random linear network coding. Each client is provided with a\nprivate set of decoding coefficients to decode its own message. Our method\nprovides security for the transmission sessions against computational\nbrute-force attacks and also weakly security in information theoretic sense. As\nthe broadcast channel is assumed to be erroneous, the missing coded packets\nshould be recovered in some way. We consider two different scenarios. In the\nfirst scenario the missing packets are retransmitted by the base station\n(centralized). In the second scenario the clients cooperate with each other by\nexchanging packets (decentralized). In both scenarios, network coding\ntechniques are exploited to increase the total throughput. For the case of\ncentralized retransmissions we provide an analytical approximation for the\nthroughput performance of instantly decodable network coded (IDNC)\nretransmissions as well as numerical experiments. For the decentralized\nscenario, we propose a new IDNC based retransmission method where its\nperformance is evaluated via simulations and analytical approximation.\nApplication of this method is not limited to our special problem and can be\ngeneralized to a new class of problems introduced in this paper as the\ncooperative index coding problem. \n\n"}
{"id": "1305.4063", "contents": "Title: Group ring cryptography: Cryptography, key exchange, public key Abstract: General cryptographic schemes are presented where keys can be one-time or\nephemeral. Processes for key exchange are derived. Public key cryptographic\nschemes based on the new systems are easily established. Authentication and\nsignature schemes are implemented. The schemes are an advance on group ring\ntechniques and are easily implemented but highly secure. They may be integrated\nwith error-correcting coding schemes so that encryption/coding and\ndecryption/decoding may be done simultaneously. \n\n"}
{"id": "1305.4330", "contents": "Title: Computing class polynomials for abelian surfaces Abstract: We describe a quasi-linear algorithm for computing Igusa class polynomials of\nJacobians of genus 2 curves via complex floating-point approximations of their\nroots. After providing an explicit treatment of the computations in quartic CM\nfields and their Galois closures, we pursue an approach due to Dupont for\nevaluating $\\theta$- constants in quasi-linear time using Newton iterations on\nthe Borchardt mean. We report on experiments with our implementation and\npresent an example with class number 17608. \n\n"}
{"id": "1305.4401", "contents": "Title: Non-associative key establishment for left distributive systems Abstract: We construct non-associative key establishment protocols for all left\nself-distributive (LD), multi-LD-, and other left distributive systems.\nInstantiations of these protocols using generalized shifted conjugacy in braid\ngroups lead to instances of a natural and apparently new group-theoretic\nproblem, which we call the (subgroup) conjugacy coset problem. \n\n"}
{"id": "1305.5436", "contents": "Title: Using LDGM Codes and Sparse Syndromes to Achieve Digital Signatures Abstract: In this paper, we address the problem of achieving efficient code-based\ndigital signatures with small public keys. The solution we propose exploits\nsparse syndromes and randomly designed low-density generator matrix codes.\nBased on our evaluations, the proposed scheme is able to outperform existing\nsolutions, permitting to achieve considerable security levels with very small\npublic keys. \n\n"}
{"id": "1305.5640", "contents": "Title: On the post-quantum security of encrypted key exchange protocols Abstract: We investigate the post-quantum security of the encrypted key exchange(EKE)\nprotocols based on some basic physical parameters of ion-trap quantum computer,\nand show that the EKE protocol with a 40-bit password will be secure against a\nquantum adversary with several ion-trap quantum computers. We present a\npassword encrypted no-key protocol to resist middle-man attack, and prove that\nit is also with the post-quantum security. The analysis presented here is\nprobably of general meaning for the security evaluation of various hybrid\ncryptosystems. \n\n"}
{"id": "1306.0315", "contents": "Title: The Fiat-Shamir Transformation in a Quantum World Abstract: The Fiat-Shamir transformation is a famous technique to turn identification\nschemes into signature schemes. The derived scheme is provably secure in the\nrandom-oracle model against classical adversaries. Still, the technique has\nalso been suggested to be used in connection with quantum-immune identification\nschemes, in order to get quantum-immune signature schemes. However, a recent\npaper by Boneh et al. (Asiacrypt 2011) has raised the issue that results in the\nrandom-oracle model may not be immediately applicable to quantum adversaries,\nbecause such adversaries should be allowed to query the random oracle in\nsuperposition. It has been unclear if the Fiat-Shamir technique is still secure\nin this quantum oracle model (QROM).\n  Here, we discuss that giving proofs for the Fiat-Shamir transformation in the\nQROM is presumably hard. We show that there cannot be black-box extractors, as\nlong as the underlying quantum-immune identification scheme is secure against\nactive adversaries and the first message of the prover is independent of its\nwitness. Most schemes are of this type. We then discuss that for some schemes\none may be able to resurrect the Fiat-Shamir result in the QROM by modifying\nthe underlying protocol first. We discuss in particular a version of the\nLyubashevsky scheme which is provably secure in the QROM. \n\n"}
{"id": "1306.2083", "contents": "Title: Privacy and Mechanism Design Abstract: This paper is a survey of recent work at the intersection of mechanism design\nand privacy. The connection is a natural one, but its study has been\njump-started in recent years by the advent of differential privacy, which\nprovides a rigorous, quantitative way of reasoning about the costs that an\nagent might experience because of the loss of his privacy. Here, we survey\nseveral facets of this study, and differential privacy plays a role in more\nthan one way. Of course, it provides us a basis for modeling agent costs for\nprivacy, which is essential if we are to attempt mechanism design in a setting\nin which agents have preferences for privacy. It also provides a toolkit for\ncontrolling those costs. However, perhaps more surprisingly, it provides a\npowerful toolkit for controlling the stability of mechanisms in general, which\nyields a set of tools for designing novel mechanisms even in economic settings\ncompletely unrelated to privacy. \n\n"}
{"id": "1306.6260", "contents": "Title: Information-Theoretic Security for the Masses Abstract: We combine interactive zero-knowledge protocols and weak physical layer\nrandomness properties to construct a protocol which allows bootstrapping an\nIT-secure and PF-secure channel from a memorizable shared secret. The protocol\nalso tolerates failures of its components, still preserving most of its\nsecurity properties, which makes it accessible to regular users. \n\n"}
{"id": "1307.0475", "contents": "Title: A Random Matrix Approach to Differential Privacy and Structure Preserved\n  Social Network Graph Publishing Abstract: Online social networks are being increasingly used for analyzing various\nsocietal phenomena such as epidemiology, information dissemination, marketing\nand sentiment flow. Popular analysis techniques such as clustering and\ninfluential node analysis, require the computation of eigenvectors of the real\ngraph's adjacency matrix. Recent de-anonymization attacks on Netflix and AOL\ndatasets show that an open access to such graphs pose privacy threats. Among\nthe various privacy preserving models, Differential privacy provides the\nstrongest privacy guarantees.\n  In this paper we propose a privacy preserving mechanism for publishing social\nnetwork graph data, which satisfies differential privacy guarantees by\nutilizing a combination of theory of random matrix and that of differential\nprivacy. The key idea is to project each row of an adjacency matrix to a low\ndimensional space using the random projection approach and then perturb the\nprojected matrix with random noise. We show that as compared to existing\napproaches for differential private approximation of eigenvectors, our approach\nis computationally efficient, preserves the utility and satisfies differential\nprivacy. We evaluate our approach on social network graphs of Facebook, Live\nJournal and Pokec. The results show that even for high values of noise variance\nsigma=1 the clustering quality given by normalized mutual information gain is\nas low as 0.74. For influential node discovery, the propose approach is able to\ncorrectly recover 80 of the most influential nodes. We also compare our results\nwith an approach presented in [43], which directly perturbs the eigenvector of\nthe original data by a Laplacian noise. The results show that this approach\nrequires a large random perturbation in order to preserve the differential\nprivacy, which leads to a poor estimation of eigenvectors for large social\nnetworks. \n\n"}
{"id": "1307.0687", "contents": "Title: Security for Smart Mobile Networks: The NEMESYS Approach Abstract: The growing popularity of smart mobile devices such as smartphones and\ntablets has made them an attractive target for cyber-criminals, resulting in a\nrapidly growing and evolving mobile threat as attackers experiment with new\nbusiness models by targeting mobile users. With the emergence of the first\nlarge-scale mobile botnets, the core network has also become vulnerable to\ndistributed denial-of-service attacks such as the signaling attack.\nFurthermore, complementary access methods such as Wi-Fi and femtocells\nintroduce additional vulnerabilities for the mobile users as well as the core\nnetwork. In this paper, we present the NEMESYS approach to smart mobile network\nsecurity. The goal of the NEMESYS project is to develop novel security\ntechnologies for seamless service provisioning in the smart mobile ecosystem,\nand to improve mobile network security through a better understanding of the\nthreat landscape. To this purpose, NEMESYS will collect and analyze information\nabout the nature of cyber-attacks targeting smart mobile devices and the core\nnetwork so that appropriate counter-measures can be taken. We are developing a\ndata collection infrastructure that incorporates virtualized mobile honeypots\nand honeyclients in order to gather, detect and provide early warning of mobile\nattacks and understand the modus operandi of cyber-criminals that target mobile\ndevices. By correlating the extracted information with known attack patterns\nfrom wireline networks, we plan to reveal and identify the possible shift in\nthe way that cyber-criminals launch attacks against smart mobile devices. \n\n"}
{"id": "1307.3544", "contents": "Title: Distributed Bayesian Detection with Byzantine Data Abstract: In this paper, we consider the problem of distributed Bayesian detection in\nthe presence of Byzantines in the network. It is assumed that a fraction of the\nnodes in the network are compromised and reprogrammed by an adversary to\ntransmit false information to the fusion center (FC) to degrade detection\nperformance. The problem of distributed detection is formulated as a binary\nhypothesis test at the FC based on 1-bit data sent by the sensors. The\nexpression for minimum attacking power required by the Byzantines to blind the\nFC is obtained. More specifically, we show that above a certain fraction of\nByzantine attackers in the network, the detection scheme becomes completely\nincapable of utilizing the sensor data for detection. We analyze the problem\nunder different attacking scenarios and derive results for different\nnon-asymptotic cases. It is found that existing asymptotics-based results do\nnot hold under several non-asymptotic scenarios. When the fraction of\nByzantines is not sufficient to blind the FC, we also provide closed form\nexpressions for the optimal attacking strategies for the Byzantines that most\ndegrade the detection performance. \n\n"}
{"id": "1307.3699", "contents": "Title: Statistically-secure ORAM with $\\tilde{O}(\\log^2 n)$ Overhead Abstract: We demonstrate a simple, statistically secure, ORAM with computational\noverhead $\\tilde{O}(\\log^2 n)$; previous ORAM protocols achieve only\ncomputational security (under computational assumptions) or require\n$\\tilde{\\Omega}(\\log^3 n)$ overheard. An additional benefit of our ORAM is its\nconceptual simplicity, which makes it easy to implement in both software and\n(commercially available) hardware.\n  Our construction is based on recent ORAM constructions due to Shi, Chan,\nStefanov, and Li (Asiacrypt 2011) and Stefanov and Shi (ArXiv 2012), but with\nsome crucial modifications in the algorithm that simplifies the ORAM and enable\nour analysis. A central component in our analysis is reducing the analysis of\nour algorithm to a \"supermarket\" problem; of independent interest (and of\nimportance to our analysis,) we provide an upper bound on the rate of \"upset\"\ncustomers in the \"supermarket\" problem. \n\n"}
{"id": "1307.3753", "contents": "Title: Classical Encryption and Authentication under Quantum Attacks Abstract: Post-quantum cryptography studies the security of classical, i.e. non-quantum\ncryptographic protocols against quantum attacks. Until recently, the considered\nadversaries were assumed to use quantum computers and behave like classical\nadversaries otherwise. A more conservative approach is to assume that also the\ncommunication between the honest parties and the adversary is (partly) quantum.\nWe discuss several options to define secure encryption and authentication\nagainst these stronger adversaries who can carry out 'superposition attacks'.\nWe re-prove a recent result of Boneh and Zhandry, stating that a uniformly\nrandom function (and hence also a quantum-secure pseudorandom function) can\nserve as a message-authentication code which is secure, even if the adversary\ncan evaluate this function in superposition. \n\n"}
{"id": "1308.1539", "contents": "Title: Hardware-based Security for Virtual Trusted Platform Modules Abstract: Virtual Trusted Platform modules (TPMs) were proposed as a software-based\nalternative to the hardware-based TPMs to allow the use of their cryptographic\nfunctionalities in scenarios where multiple TPMs are required in a single\nplatform, such as in virtualized environments. However, virtualizing TPMs,\nespecially virutalizing the Platform Configuration Registers (PCRs), strikes\nagainst one of the core principles of Trusted Computing, namely the need for a\nhardware-based root of trust. In this paper we show how strength of\nhardware-based security can be gained in virtual PCRs by binding them to their\ncorresponding hardware PCRs. We propose two approaches for such a binding. For\nthis purpose, the first variant uses binary hash trees, whereas the other\nvariant uses incremental hashing. In addition, we present an FPGA-based\nimplementation of both variants and evaluate their performance. \n\n"}
{"id": "1309.1328", "contents": "Title: Logic of Intuitionistic Interactive Proofs (Formal Theory of Perfect\n  Knowledge Transfer) Abstract: We produce a decidable super-intuitionistic normal modal logic of\ninternalised intuitionistic (and thus disjunctive and monotonic) interactive\nproofs (LIiP) from an existing classical counterpart of classical monotonic\nnon-disjunctive interactive proofs (LiP). Intuitionistic interactive proofs\neffect a durable epistemic impact in the possibly adversarial communication\nmedium CM (which is imagined as a distinguished agent), and only in that, that\nconsists in the permanent induction of the perfect and thus disjunctive\nknowledge of their proof goal by means of CM's knowledge of the proof: If CM\nknew my proof then CM would persistently and also disjunctively know that my\nproof goal is true. So intuitionistic interactive proofs effect a lasting\ntransfer of disjunctive propositional knowledge (disjunctively knowable facts)\nin the communication medium of multi-agent distributed systems via the\ntransmission of certain individual knowledge (knowable intuitionistic proofs).\nOur (necessarily) CM-centred notion of proof is also a disjunctive explicit\nrefinement of KD45-belief, and yields also such a refinement of standard\nS5-knowledge. Monotonicity but not communality is a commonality of LiP, LIiP,\nand their internalised notions of proof. As a side-effect, we offer a short\ninternalised proof of the Disjunction Property of Intuitionistic Logic\n(originally proved by Goedel). \n\n"}
{"id": "1309.1596", "contents": "Title: Security analysis of epsilon-almost dual universal2 hash functions:\n  smoothing of min entropy vs. smoothing of R\\'enyi entropy of order 2 Abstract: Recently, $\\varepsilon$-almost dual universal$_2$ hash functions has been\nproposed as a new and wider class of hash functions. Using this class of hash\nfunctions, several efficient hash functions were proposed. This paper evaluates\nthe security performance when we apply this kind of hash functions. We evaluate\nthe security in several kinds of setting based on the $L_1$ distinguishability\ncriterion and the modified mutual information criterion. The obtained\nevaluation is based on smoothing of R\\'{e}nyi entropy of order 2 and/or min\nentropy. We clarify the difference between these two methods. \n\n"}
{"id": "1309.1859", "contents": "Title: The MOR cryptosystem and finite $p$-groups Abstract: The ElGamal cryptosystem is the most widely used public key cryptosystem. It\nuses the discrete logarithm problem as the cryptographic primitive. The MOR\ncryptosystem is a similar cryptosystem. It uses the discrete logarithm problem\nin the automorphism group as the cryptographic primitive. In this paper, we\nstudy the MOR cryptosystem for finite $p$-groups. The study is complete for\n$p^\\prime$-automorphisms. For $p$-automorphisms there are some interesting open\nproblems. \n\n"}
{"id": "1310.1861", "contents": "Title: Physical-Layer Cryptography Through Massive MIMO Abstract: We propose the new technique of physical-layer cryptography based on using a\nmassive MIMO channel as a key between the sender and desired receiver, which\nneed not be secret. The goal is for low-complexity encoding and decoding by the\ndesired transmitter-receiver pair, whereas decoding by an eavesdropper is hard\nin terms of prohibitive complexity. The decoding complexity is analyzed by\nmapping the massive MIMO system to a lattice. We show that the eavesdropper's\ndecoder for the MIMO system with M-PAM modulation is equivalent to solving\nstandard lattice problems that are conjectured to be of exponential complexity\nfor both classical and quantum computers. Hence, under the widely-held\nconjecture that standard lattice problems are hard to solve in the worst-case,\nthe proposed encryption scheme has a more robust notion of security than that\nof the most common encryption methods used today such as RSA and\nDiffie-Hellman. Additionally, we show that this scheme could be used to\nsecurely communicate without a pre-shared secret and little computational\noverhead. Thus, by exploiting the physical layer properties of the radio\nchannel, the massive MIMO system provides for low-complexity encryption\ncommensurate with the most sophisticated forms of application-layer encryption\nthat are currently known. \n\n"}
{"id": "1310.5059", "contents": "Title: Squashing model for detectors and applications to quantum key\n  distribution protocols Abstract: We develop a framework that allows a description of measurements in Hilbert\nspaces that are smaller than their natural representation. This description,\nwhich we call a \"squashing model\", consists of a squashing map that maps the\ninput states of the measurement from the original Hilbert space to the smaller\none, followed by a targeted prescribed measurement on the smaller Hilbert\nspace. This framework has applications in quantum key distribution, but also in\nother cryptographic tasks, as it greatly simplifies the theoretical analysis\nunder adversarial conditions. \n\n"}
{"id": "1310.6238", "contents": "Title: Quantum computation of discrete logarithms in semigroups Abstract: We describe an efficient quantum algorithm for computing discrete logarithms\nin semigroups using Shor's algorithms for period finding and discrete log as\nsubroutines. Thus proposed cryptosystems based on the presumed hardness of\ndiscrete logarithms in semigroups are insecure against quantum attacks. In\ncontrast, we show that some generalizations of the discrete log problem are\nhard in semigroups despite being easy in groups. We relate a shifted version of\nthe discrete log problem in semigroups to the dihedral hidden subgroup problem,\nand we show that the constructive membership problem with respect to $k \\ge 2$\ngenerators in a black-box abelian semigroup of order $N$ requires $\\tilde\n\\Theta(N^{\\frac{1}{2}-\\frac{1}{2k}})$ quantum queries. \n\n"}
{"id": "1310.6542", "contents": "Title: SensorCloud: Towards the Interdisciplinary Development of a Trustworthy\n  Platform for Globally Interconnected Sensors and Actuators Abstract: Although Cloud Computing promises to lower IT costs and increase users'\nproductivity in everyday life, the unattractive aspect of this new technology\nis that the user no longer owns all the devices which process personal data. To\nlower scepticism, the project SensorCloud investigates techniques to understand\nand compensate these adoption barriers in a scenario consisting of cloud\napplications that utilize sensors and actuators placed in private places. This\nwork provides an interdisciplinary overview of the social and technical core\nresearch challenges for the trustworthy integration of sensor and actuator\ndevices with the Cloud Computing paradigm. Most importantly, these challenges\ninclude i) ease of development, ii) security and privacy, and iii) social\ndimensions of a cloud-based system which integrates into private life. When\nthese challenges are tackled in the development of future cloud systems, the\nattractiveness of new use cases in a sensor-enabled world will considerably be\nincreased for users who currently do not trust the Cloud. \n\n"}
{"id": "1311.0776", "contents": "Title: The Composition Theorem for Differential Privacy Abstract: Sequential querying of differentially private mechanisms degrades the overall\nprivacy level. In this paper, we answer the fundamental question of\ncharacterizing the level of overall privacy degradation as a function of the\nnumber of queries and the privacy levels maintained by each privatization\nmechanism. Our solution is complete: we prove an upper bound on the overall\nprivacy level and construct a sequence of privatization mechanisms that\nachieves this bound. The key innovation is the introduction of an operational\ninterpretation of differential privacy (involving hypothesis testing) and the\nuse of new data processing inequalities. Our result improves over the\nstate-of-the-art, and has immediate applications in several problems studied in\nthe literature including differentially private multi-party computation. \n\n"}
{"id": "1312.2177", "contents": "Title: Machine Learning Techniques for Intrusion Detection Abstract: An Intrusion Detection System (IDS) is a software that monitors a single or a\nnetwork of computers for malicious activities (attacks) that are aimed at\nstealing or censoring information or corrupting network protocols. Most\ntechniques used in today's IDS are not able to deal with the dynamic and\ncomplex nature of cyber attacks on computer networks. Hence, efficient adaptive\nmethods like various techniques of machine learning can result in higher\ndetection rates, lower false alarm rates and reasonable computation and\ncommunication costs. In this paper, we study several such schemes and compare\ntheir performance. We divide the schemes into methods based on classical\nartificial intelligence (AI) and methods based on computational intelligence\n(CI). We explain how various characteristics of CI techniques can be used to\nbuild efficient IDS. \n\n"}
{"id": "1401.1331", "contents": "Title: Interpolation and Approximation of Polynomials in Finite Fields over a\n  Short Interval from Noisy Values Abstract: Motivated by a recently introduced HIMMO key distribution scheme, we consider\na modification of the noisy polynomial interpolation problem of recovering an\nunknown polynomial $f(X) \\in Z[X]$ from approximate values of the residues of\n$f(t)$ modulo a prime $p$ at polynomially many points $t$ taken from a short\ninterval. \n\n"}
{"id": "1401.5688", "contents": "Title: Capacities and Capacity-Achieving Decoders for Various Fingerprinting\n  Games Abstract: Combining an information-theoretic approach to fingerprinting with a more\nconstructive, statistical approach, we derive new results on the fingerprinting\ncapacities for various informed settings, as well as new log-likelihood\ndecoders with provable code lengths that asymptotically match these capacities.\nThe simple decoder built against the interleaving attack is further shown to\nachieve the simple capacity for unknown attacks, and is argued to be an\nimproved version of the recently proposed decoder of Oosterwijk et al. With\nthis new universal decoder, cut-offs on the bias distribution function can\nfinally be dismissed.\n  Besides the application of these results to fingerprinting, a direct\nconsequence of our results to group testing is that (i) a simple decoder\nasymptotically requires a factor 1.44 more tests to find defectives than a\njoint decoder, and (ii) the simple decoder presented in this paper provably\nachieves this bound. \n\n"}
{"id": "1401.6790", "contents": "Title: Optimal Power Allocation in Block Fading Gaussian Channels with Causal\n  CSI and Secrecy Constraints Abstract: The optimal power allocation that maximizes the secrecy capacity of block\nfading Gaussian (BF-Gaussian) networks with causal channel state information\n(CSI), M-block delay tolerance and a frame based power constraint is examined.\nIn particular, we formulate the secrecy capacity maximization as a dynamic\nprogram. We propose suitable linear approximations of the secrecy capacity\ndensity in the low SNR, the high SNR and the intermediate SNR regimes,\naccording to the overall available power budget. Our findings indicate that\nwhen the available power resources are very low (low SNR case) the optimal\nstrategy is a threshold policy. On the other hand when the available power\nbudget is infinite (high SNR case) a constant power policy maximizes the frame\nsecrecy capacity. Finally, when the power budget is finite (medium SNR case),\nan approximate tractable power allocation policy is derived. \n\n"}
{"id": "1401.7532", "contents": "Title: The MMO problem Abstract: We consider a two polynomials analogue of the polynomial interpolation\nproblem. Namely, we consider the Mixing Modular Operations (MMO) problem of\nrecovering two polynomials $f\\in \\Z_p[x]$ and $g\\in \\Z_q[x]$ of known degree,\nwhere $p$ and $q$ are two (un)known positive integers, from the values of\n$f(t)\\bmod p + g(t)\\bmod q$ at polynomially many points $t \\in \\Z$. We show\nthat if $p$ and $q$ are known, the MMO problem is equivalent to computing a\nclose vector in a lattice with respect to the infinity norm. We also\nimplemented in the SAGE system a heuristic polynomial-time algorithm. If $p$\nand $q$ are kept secret, we do not know how to solve this problem. This problem\nis motivated by several potential cryptographic applications. \n\n"}
{"id": "1402.5029", "contents": "Title: Optimal Geo-Indistinguishable Mechanisms for Location Privacy Abstract: We consider the geo-indistinguishability approach to location privacy, and\nthe trade-off with respect to utility. We show that, given a desired degree of\ngeo-indistinguishability, it is possible to construct a mechanism that\nminimizes the service quality loss, using linear programming techniques. In\naddition we show that, under certain conditions, such mechanism also provides\noptimal privacy in the sense of Shokri et al. Furthermore, we propose a method\nto reduce the number of constraints of the linear program from cubic to\nquadratic, maintaining the privacy guarantees and without affecting\nsignificantly the utility of the generated mechanism. This reduces considerably\nthe time required to solve the linear program, thus enlarging significantly the\nlocation sets for which the optimal mechanisms can be computed. \n\n"}
{"id": "1402.6246", "contents": "Title: An experimental exploration of Marsaglia's xorshift generators,\n  scrambled Abstract: Marsaglia proposed recently xorshift generators as a class of very fast,\ngood-quality pseudorandom number generators. Subsequent analysis by Panneton\nand L'Ecuyer has lowered the expectations raised by Marsaglia's paper, showing\nseveral weaknesses of such generators, verified experimentally using the\nTestU01 suite. Nonetheless, many of the weaknesses of xorshift generators fade\naway if their result is scrambled by a non-linear operation (as originally\nsuggested by Marsaglia). In this paper we explore the space of possible\ngenerators obtained by multiplying the result of a xorshift generator by a\nsuitable constant. We sample generators at 100 equispaced points of their state\nspace and obtain detailed statistics that lead us to choices of parameters that\nimprove on the current ones. We then explore for the first time the space of\nhigh-dimensional xorshift generators, following another suggestion in\nMarsaglia's paper, finding choices of parameters providing periods of length\n$2^{1024} - 1$ and $2^{4096} - 1$. The resulting generators are of extremely\nhigh quality, faster than current similar alternatives, and generate\nlong-period sequences passing strong statistical tests using only eight logical\noperations, one addition and one multiplication by a constant. \n\n"}
{"id": "1402.6658", "contents": "Title: Computing discrete logarithms in subfields of residue class rings Abstract: Recent breakthrough methods \\cite{gggz,joux,bgjt} on computing discrete\nlogarithms in small characteristic finite fields share an interesting feature\nin common with the earlier medium prime function field sieve method \\cite{jl}.\nTo solve discrete logarithms in a finite extension of a finite field $\\F$, a\npolynomial $h(x) \\in \\F[x]$ of a special form is constructed with an\nirreducible factor $g(x) \\in \\F[x]$ of the desired degree. The special form of\n$h(x)$ is then exploited in generating multiplicative relations that hold in\nthe residue class ring $\\F[x]/h(x)\\F[x]$ hence also in the target residue class\nfield $\\F[x]/g(x)\\F[x]$. An interesting question in this context and addressed\nin this paper is: when and how does a set of relations on the residue class\nring determine the discrete logarithms in the finite fields contained in it? We\ngive necessary and sufficient conditions for a set of relations on the residue\nclass ring to determine discrete logarithms in the finite fields contained in\nit. We also present efficient algorithms to derive discrete logarithms from the\nrelations when the conditions are met. The derived necessary conditions allow\nus to clearly identify structural obstructions intrinsic to the special\npolynomial $h(x)$ in each of the aforementioned methods, and propose\nmodifications to the selection of $h(x)$ so as to avoid obstructions. \n\n"}
{"id": "1403.3563", "contents": "Title: Proving Security Goals With Shape Analysis Sentences Abstract: The paper that introduced shape analysis sentences presented a method for\nextracting a sentence in first-order logic that completely characterizes a run\nof CPSA. Logical deduction can then be used to determine if a security goal is\nsatisfied.\n  This paper presents a method for importing shape analysis sentences into a\nproof assistant on top of a detailed theory of strand spaces. The result is a\nsemantically rich environment in which the validity of a security goal can be\ndetermined using shape analysis sentences and the foundation on which they are\nbased. \n\n"}
{"id": "1403.4153", "contents": "Title: A family of polycyclic groups over which the uniform conjugacy problem\n  is NP-complete Abstract: In this paper we study the conjugacy problem in polycyclic groups. Our main\nresult is that we construct polycyclic groups $G_n$ whose conjugacy problem is\nat least as hard as the subset sum problem with $n$ indeterminates. As such,\nthe conjugacy problem over the groups $G_n$ is NP-complete where the parameters\nof the problem are taken in terms of $n$ and the length of the elements given\non input. \n\n"}
{"id": "1403.5715", "contents": "Title: Mining Attribute-Based Access Control Policies from Logs Abstract: Attribute-based access control (ABAC) provides a high level of flexibility\nthat promotes security and information sharing. ABAC policy mining algorithms\nhave potential to significantly reduce the cost of migration to ABAC, by\npartially automating the development of an ABAC policy from information about\nthe existing access-control policy and attribute data. This paper presents an\nalgorithm for mining ABAC policies from operation logs and attribute data. To\nthe best of our knowledge, it is the first algorithm for this problem. \n\n"}
{"id": "1403.6135", "contents": "Title: Differentially Private Convex Optimization with Piecewise Affine\n  Objectives Abstract: Differential privacy is a recently proposed notion of privacy that provides\nstrong privacy guarantees without any assumptions on the adversary. The paper\nstudies the problem of computing a differentially private solution to convex\noptimization problems whose objective function is piecewise affine. Such\nproblem is motivated by applications in which the affine functions that define\nthe objective function contain sensitive user information. We propose several\nprivacy preserving mechanisms and provide analysis on the trade-offs between\noptimality and the level of privacy for these mechanisms. Numerical experiments\nare also presented to evaluate their performance in practice. \n\n"}
{"id": "1404.0024", "contents": "Title: Towards Human Computable Passwords Abstract: An interesting challenge for the cryptography community is to design\nauthentication protocols that are so simple that a human can execute them\nwithout relying on a fully trusted computer. We propose several candidate\nauthentication protocols for a setting in which the human user can only receive\nassistance from a semi-trusted computer --- a computer that stores information\nand performs computations correctly but does not provide confidentiality. Our\nschemes use a semi-trusted computer to store and display public challenges\n$C_i\\in[n]^k$. The human user memorizes a random secret mapping\n$\\sigma:[n]\\rightarrow\\mathbb{Z}_d$ and authenticates by computing responses\n$f(\\sigma(C_i))$ to a sequence of public challenges where\n$f:\\mathbb{Z}_d^k\\rightarrow\\mathbb{Z}_d$ is a function that is easy for the\nhuman to evaluate. We prove that any statistical adversary needs to sample\n$m=\\tilde{\\Omega}(n^{s(f)})$ challenge-response pairs to recover $\\sigma$, for\na security parameter $s(f)$ that depends on two key properties of $f$. To\nobtain our results, we apply the general hypercontractivity theorem to lower\nbound the statistical dimension of the distribution over challenge-response\npairs induced by $f$ and $\\sigma$. Our lower bounds apply to arbitrary\nfunctions $f $ (not just to functions that are easy for a human to evaluate),\nand generalize recent results of Feldman et al. As an application, we propose a\nfamily of human computable password functions $f_{k_1,k_2}$ in which the user\nneeds to perform $2k_1+2k_2+1$ primitive operations (e.g., adding two digits or\nremembering $\\sigma(i)$), and we show that $s(f) = \\min\\{k_1+1, (k_2+1)/2\\}$.\nFor these schemes, we prove that forging passwords is equivalent to recovering\nthe secret mapping. Thus, our human computable password schemes can maintain\nstrong security guarantees even after an adversary has observed the user login\nto many different accounts. \n\n"}
{"id": "1404.1503", "contents": "Title: Quantum Hashing via Classical $\\epsilon$-universal Hashing Constructions Abstract: In the paper, we define the concept of the quantum hash generator and offer\ndesign, which allows to build a large amount of different quantum hash\nfunctions. The construction is based on composition of classical\n$\\epsilon$-universal hash family and a given family of functions -- quantum\nhash generator.\n  The proposed construction combines the properties of robust presentation of\ninformation by classical error-correcting codes together with the possibility\nof highly compressed presentation of information by quantum systems.\n  In particularly, we present quantum hash function based on Reed-Solomon code,\nand we proved, that this construction is optimal in the sense of number of\nqubits needed. \n\n"}
{"id": "1404.1988", "contents": "Title: Actor Network Procedures as Psi-calculi for Security Ceremonies Abstract: The actor network procedures of Pavlovic and Meadows are a recent graphical\nformalism developed for describing security ceremonies and for reasoning about\ntheir security properties. The present work studies the relations of the actor\nnetwork procedures (ANP) to the recent psi-calculi framework. Psi-calculi is a\nparametric formalism where calculi like spi- or applied-pi are found as\ninstances. Psi-calculi are operational and largely non-graphical, but have\nstrong foundation based on the theory of nominal sets and process algebras. One\npurpose of the present work is to give a semantics to ANP through psi-calculi.\nAnother aim was to give a graphical language for a psi-calculus instance for\nsecurity ceremonies. At the same time, this work provides more insight into the\ndetails of the ANPs formalization and the graphical representation. \n\n"}
{"id": "1404.4679", "contents": "Title: Graph-based Anomaly Detection and Description: A Survey Abstract: Detecting anomalies in data is a vital task, with numerous high-impact\napplications in areas such as security, finance, health care, and law\nenforcement. While numerous techniques have been developed in past years for\nspotting outliers and anomalies in unstructured collections of\nmulti-dimensional points, with graph data becoming ubiquitous, techniques for\nstructured {\\em graph} data have been of focus recently. As objects in graphs\nhave long-range correlations, a suite of novel technology has been developed\nfor anomaly detection in graph data.\n  This survey aims to provide a general, comprehensive, and structured overview\nof the state-of-the-art methods for anomaly detection in data represented as\ngraphs. As a key contribution, we provide a comprehensive exploration of both\ndata mining and machine learning algorithms for these {\\em detection} tasks. we\ngive a general framework for the algorithms categorized under various settings:\nunsupervised vs. (semi-)supervised approaches, for static vs. dynamic graphs,\nfor attributed vs. plain graphs. We highlight the effectiveness, scalability,\ngenerality, and robustness aspects of the methods. What is more, we stress the\nimportance of anomaly {\\em attribution} and highlight the major techniques that\nfacilitate digging out the root cause, or the `why', of the detected anomalies\nfor further analysis and sense-making. Finally, we present several real-world\napplications of graph-based anomaly detection in diverse domains, including\nfinancial, auction, computer traffic, and social networks. We conclude our\nsurvey with a discussion on open theoretical and practical challenges in the\nfield. \n\n"}
{"id": "1404.5945", "contents": "Title: Previous Messages Provide the Key to Achieve Shannon Capacity in a\n  Wiretap Channel Abstract: We consider a wiretap channel and use previously transmitted messages to\ngenerate a secret key which increases the secrecy capacity. This can be\nbootstrapped to increase the secrecy capacity to the Shannon capacity without\nusing any feedback or extra channel while retaining the strong secrecy of the\nwiretap channel. \n\n"}
{"id": "1404.6822", "contents": "Title: vVote: a Verifiable Voting System Abstract: The Pret a Voter cryptographic voting system was designed to be flexible and\nto offer voters a familiar and easy voting experience. In this paper we present\na case study of our efforts to adapt Pret a Voter to the idiosyncrasies of\nelections in the Australian state of Victoria. This technical report includes\ngeneral background, user experience and details of the cryptographic protocols\nand human processes. We explain the problems, present solutions, then analyse\ntheir security properties and explain how they tie in to other design\ndecisions. We hope this will be an interesting case study on the application of\nend-to-end verifiable voting protocols to real elections.\n  A preliminary version of this paper appeared as the 10th February 2014\nversion of \"Draft Technical Report for VEC vVote System\".\n  The team involved in developing the vVote design described in this report\nwere: Craig Burton, Chris Culnane, James Heather, Rui Joaquim, Peter Y. A.\nRyan, Steve Schneider and Vanessa Teague. \n\n"}
{"id": "1404.6898", "contents": "Title: Quantum Attacks on Classical Proof Systems - The Hardness of Quantum\n  Rewinding Abstract: Quantum zero-knowledge proofs and quantum proofs of knowledge are inherently\ndifficult to analyze because their security analysis uses rewinding. Certain\ncases of quantum rewinding are handled by the results by Watrous (SIAM J\nComput, 2009) and Unruh (Eurocrypt 2012), yet in general the problem remains\nelusive. We show that this is not only due to a lack of proof techniques:\nrelative to an oracle, we show that classically secure proofs and proofs of\nknowledge are insecure in the quantum setting.\n  More specifically, sigma-protocols, the Fiat-Shamir construction, and\nFischlin's proof system are quantum insecure under assumptions that are\nsufficient for classical security. Additionally, we show that for similar\nreasons, computationally binding commitments provide almost no security\nguarantees in a quantum setting.\n  To show these results, we develop the \"pick-one trick\", a general technique\nthat allows an adversary to find one value satisfying a given predicate, but\nnot two. \n\n"}
{"id": "1404.7516", "contents": "Title: Classical leakage resilience from fault-tolerant quantum computation Abstract: Physical implementations of cryptographic algorithms leak information, which\nmakes them vulnerable to so-called side-channel attacks. The problem of secure\ncomputation in the presence of leakage is generally known as leakage\nresilience. In this work, we establish a connection between leakage resilience\nand fault-tolerant quantum computation. We first prove that for a general\nleakage model, there exists a corresponding noise model in which fault\ntolerance implies leakage resilience. Then we show how to use constructions for\nfault-tolerant quantum computation to implement classical circuits that are\nsecure in specific leakage models. \n\n"}
{"id": "1405.1328", "contents": "Title: What's the Gist? Privacy-Preserving Aggregation of User Profiles Abstract: Over the past few years, online service providers have started gathering\nincreasing amounts of personal information to build user profiles and monetize\nthem with advertisers and data brokers. Users have little control of what\ninformation is processed and are often left with an all-or-nothing decision\nbetween receiving free services or refusing to be profiled. This paper explores\nan alternative approach where users only disclose an aggregate model -- the\n\"gist\" -- of their data. We aim to preserve data utility and simultaneously\nprovide user privacy. We show that this approach can be efficiently supported\nby letting users contribute encrypted and differentially-private data to an\naggregator. The aggregator combines encrypted contributions and can only\nextract an aggregate model of the underlying data. We evaluate our framework on\na dataset of 100,000 U.S. users obtained from the U.S. Census Bureau and show\nthat (i) it provides accurate aggregates with as little as 100 users, (ii) it\ngenerates revenue for both users and data brokers, and (iii) its overhead is\nappreciably low. \n\n"}
{"id": "1405.1584", "contents": "Title: Modelling Delegation and Revocation Schemes in IDP Abstract: In ownership-based access control frameworks with the possibility of\ndelegating permissions and administrative rights, chains of delegated accesses\nwill form. There are different ways to treat these delegation chains when\nrevoking rights, which give rise to different revocation schemes. In this\npaper, we show how IDP - a knowledge base system that integrates technology\nfrom ASP, SAT and CP - can be used to efficiently implement executable\nrevocation schemes for an ownership-based access control system based on a\ndeclarative specification of their properties. \n\n"}
{"id": "1405.1891", "contents": "Title: Privacy in the Genomic Era Abstract: Genome sequencing technology has advanced at a rapid pace and it is now\npossible to generate highly-detailed genotypes inexpensively. The collection\nand analysis of such data has the potential to support various applications,\nincluding personalized medical services. While the benefits of the genomics\nrevolution are trumpeted by the biomedical community, the increased\navailability of such data has major implications for personal privacy; notably\nbecause the genome has certain essential features, which include (but are not\nlimited to) (i) an association with traits and certain diseases, (ii)\nidentification capability (e.g., forensics), and (iii) revelation of family\nrelationships. Moreover, direct-to-consumer DNA testing increases the\nlikelihood that genome data will be made available in less regulated\nenvironments, such as the Internet and for-profit companies. The problem of\ngenome data privacy thus resides at the crossroads of computer science,\nmedicine, and public policy. While the computer scientists have addressed data\nprivacy for various data types, there has been less attention dedicated to\ngenomic data. Thus, the goal of this paper is to provide a systematization of\nknowledge for the computer science community. In doing so, we address some of\nthe (sometimes erroneous) beliefs of this field and we report on a survey we\nconducted about genome data privacy with biomedical specialists. Then, after\ncharacterizing the genome privacy problem, we review the state-of-the-art\nregarding privacy attacks on genomic data and strategies for mitigating such\nattacks, as well as contextualizing these attacks from the perspective of\nmedicine and public policy. This paper concludes with an enumeration of the\nchallenges for genome data privacy and presents a framework to systematize the\nanalysis of threats and the design of countermeasures as the field moves\nforward. \n\n"}
{"id": "1405.2555", "contents": "Title: How to Securely Compute the Modulo-Two Sum of Binary Sources Abstract: In secure multiparty computation, mutually distrusting users in a network\nwant to collaborate to compute functions of data which is distributed among the\nusers. The users should not learn any additional information about the data of\nothers than what they may infer from their own data and the functions they are\ncomputing. Previous works have mostly considered the worst case context (i.e.,\nwithout assuming any distribution for the data); Lee and Abbe (2014) is a\nnotable exception. Here, we study the average case (i.e., we work with a\ndistribution on the data) where correctness and privacy is only desired\nasymptotically.\n  For concreteness and simplicity, we consider a secure version of the function\ncomputation problem of K\\\"orner and Marton (1979) where two users observe a\ndoubly symmetric binary source with parameter p and the third user wants to\ncompute the XOR. We show that the amount of communication and randomness\nresources required depends on the level of correctness desired. When zero-error\nand perfect privacy are required, the results of Data et al. (2014) show that\nit can be achieved if and only if a total rate of 1 bit is communicated between\nevery pair of users and private randomness at the rate of 1 is used up. In\ncontrast, we show here that, if we only want the probability of error to vanish\nasymptotically in block length, it can be achieved by a lower rate (binary\nentropy of p) for all the links and for private randomness; this also\nguarantees perfect privacy. We also show that no smaller rates are possible\neven if privacy is only required asymptotically. \n\n"}
{"id": "1406.1543", "contents": "Title: Untappable key distribution system: a one-time-pad booster Abstract: One-time-pad (OTP) encryption simply cannot be cracked, even by a quantum\ncomputer. The need of sharing in a secure way supplies of symmetric random keys\nturned the method almost obsolete as a standing-alone method for fast and large\nvolume telecommunication. Basically, this secure sharing of keys and their\nrenewal, once exhausted, had to be done through couriers, in a slow and costly\nprocess. This paper presents a solution for this problem providing a fast and\nunlimited renewal of secure keys: An untappable key distribution system is\npresented and detailed. This fast key distribution system utilizes two layers\nof confidentially protection: 1) Physical noise intrinsic to the optical\nchannel that turn the coded signals into stealth signals and 2) Privacy\namplification using a bit pool of refreshed entropy run after run, to eliminate\nany residual information.\n  The resulting level of security is rigorously calculated and demonstrates\nthat the level of information an eavesdropper could obtain is completely\nnegligible. The random bit sequences, fast and securely distributed, can be\nused to encrypt text, data or voice. \n\n"}
{"id": "1406.2456", "contents": "Title: Limitations on information theoretically secure quantum homomorphic\n  encryption Abstract: Homomorphic encryption is a form of encryption which allows computation to be\ncarried out on the encrypted data without the need for decryption. The success\nof quantum approaches to related tasks in a delegated computation setting has\nraised the question of whether quantum mechanics may be used to achieve\ninformation theoretically secure fully homomorphic encryption. Here we show,\nvia an information localisation argument, that deterministic fully homomorphic\nencryption necessarily incurs exponential overhead if perfect security is\nrequired. \n\n"}
{"id": "1406.5694", "contents": "Title: Cryptocurrencies without Proof of Work Abstract: We study decentralized cryptocurrency protocols in which the participants do\nnot deplete physical scarce resources. Such protocols commonly rely on Proof of\nStake, i.e., on mechanisms that extend voting power to the stakeholders of the\nsystem. We offer analysis of existing protocols that have a substantial amount\nof popularity. We then present our novel pure Proof of Stake protocols, and\nargue that they help in mitigating problems that the existing protocols\nexhibit. \n\n"}
{"id": "1406.6758", "contents": "Title: Information Spectrum Approach to Strong Converse Theorems for Degraded\n  Wiretap Channels Abstract: We consider block codes for degraded wiretap channels in which the legitimate\nreceiver decodes the message with an asymptotic error probability no larger\nthan $\\varepsilon$ but the leakage to the eavesdropper vanishes. For discrete\nmemoryless and Gaussian wiretap channels, we show that the maximum rate of\ntransmission does not depend on $\\varepsilon\\in [0,1)$, i.e., such channels\npossess the partial strong converse property. Furthermore, we derive sufficient\nconditions for the partial strong converse property to hold for memoryless but\nnon-stationary symmetric and degraded wiretap channels. Our proof techniques\nleverage the information spectrum method, which allows us to establish a\nnecessary and sufficient condition for the partial strong converse to hold for\ngeneral wiretap channels without any information stability assumptions. \n\n"}
{"id": "1407.0333", "contents": "Title: Coded Cooperative Data Exchange for a Secret Key Abstract: We consider a coded cooperative data exchange problem with the goal of\ngenerating a secret key. Specifically, we investigate the number of public\ntransmissions required for a set of clients to agree on a secret key with\nprobability one, subject to the constraint that it remains private from an\neavesdropper.\n  Although the problems are closely related, we prove that secret key\ngeneration with fewest number of linear transmissions is NP-hard, while it is\nknown that the analogous problem in traditional cooperative data exchange can\nbe solved in polynomial time. In doing this, we completely characterize the\nbest possible performance of linear coding schemes, and also prove that linear\ncodes can be strictly suboptimal. Finally, we extend the single-key results to\ncharacterize the minimum number of public transmissions required to generate a\ndesired integer number of statistically independent secret keys. \n\n"}
{"id": "1407.1270", "contents": "Title: A New Primitive for a Diffie-Hellman-like Key Exchange Protocol Based on\n  Multivariate Ore Polynomials Abstract: In this paper we present a new primitive for a key exchange protocol based on\nmultivariate non-commutative polynomial rings, analogous to the classic\nDiffie-Hellman method. Our technique extends the proposed scheme of Boucher et\nal. from 2010. Their method was broken by Dubois and Kammerer in 2011, who\nexploited the Euclidean domain structure of the chosen ring. However, our\nproposal is immune against such attacks, without losing the advantages of\nnon-commutative polynomial rings as outlined by Boucher et al. Moreover, our\nextension is not restricted to any particular ring, but is designed to allow\nusers to readily choose from a large class of rings when applying the protocol.\nOur primitive can also be applied to other cryptographic paradigms. In\nparticular, we develop a three-pass protocol, a public key cryptosystem, a\ndigital signature scheme and a zero-knowledge proof protocol. \n\n"}
{"id": "1407.6350", "contents": "Title: Symmetric Disclosure: a Fresh Look at k-Anonymity Abstract: We analyze how the sparsity of a typical aggregate social relation impacts\nthe network overhead of online communication systems designed to provide\nk-anonymity. Once users are grouped in anonymity sets there will likely be few\nrelated pairs of users between any two particular sets, and so the sets need to\nbe large in order to provide cover traffic between them. We can reduce the\nassociated overhead by having both parties in a communication specify both the\norigin and the target sets of the communication. We propose to call this\ncommunication primitive \"symmetric disclosure.\" If in order to retrieve\nmessages a user specifies a group from which he expects to receive them, the\nnegative impact of the sparsity is offset. \n\n"}
{"id": "1408.0718", "contents": "Title: Improvements to the number field sieve for non-prime finite fields Abstract: We propose various strategies for improving the computation of discrete\nlogarithms in non-prime fields of medium to large characteristic using the\nNumber Field Sieve. This includes new methods for selecting the polynomials;\nthe use of explicit automorphisms; explicit computations in the number fields;\nand prediction that some units have a zero virtual logarithm. On the\ntheoretical side, we obtain a new complexity bound of\n$L_{p^n}(1/3,\\sqrt[3]{96/9})$ in the medium characteristic case. On the\npractical side, we computed discrete logarithms in $F_{p^2}$ for a prime number\n$p$ with $80$ decimal digits.Warning: This unpublished version contains some\ninexact statements. \n\n"}
{"id": "1408.0784", "contents": "Title: Blindspot: Indistinguishable Anonymous Communications Abstract: Communication anonymity is a key requirement for individuals under targeted\nsurveillance. Practical anonymous communications also require\nindistinguishability - an adversary should be unable to distinguish between\nanonymised and non-anonymised traffic for a given user. We propose Blindspot, a\ndesign for high-latency anonymous communications that offers\nindistinguishability and unobservability under a (qualified) global active\nadversary. Blindspot creates anonymous routes between sender-receiver pairs by\nsubliminally encoding messages within the pre-existing communication behaviour\nof users within a social network. Specifically, the organic image sharing\nbehaviour of users. Thus channel bandwidth depends on the intensity of image\nsharing behaviour of users along a route. A major challenge we successfully\novercome is that routing must be accomplished in the face of significant\nrestrictions - channel bandwidth is stochastic. We show that conventional\nsocial network routing strategies do not work. To solve this problem, we\npropose a novel routing algorithm. We evaluate Blindspot using a real-world\ndataset. We find that it delivers reasonable results for applications requiring\nlow-volume unobservable communication. \n\n"}
{"id": "1408.2385", "contents": "Title: Trace representation of pseudorandom binary sequences derived from Euler\n  quotients Abstract: We give the trace representation of a family of binary sequences derived from\nEuler quotients by determining the corresponding defining polynomials. Trace\nrepresentation can help us producing the sequences efficiently and analyzing\ntheir cryptographic properties, such as linear complexity. \n\n"}
{"id": "1409.1556", "contents": "Title: Very Deep Convolutional Networks for Large-Scale Image Recognition Abstract: In this work we investigate the effect of the convolutional network depth on\nits accuracy in the large-scale image recognition setting. Our main\ncontribution is a thorough evaluation of networks of increasing depth using an\narchitecture with very small (3x3) convolution filters, which shows that a\nsignificant improvement on the prior-art configurations can be achieved by\npushing the depth to 16-19 weight layers. These findings were the basis of our\nImageNet Challenge 2014 submission, where our team secured the first and the\nsecond places in the localisation and classification tracks respectively. We\nalso show that our representations generalise well to other datasets, where\nthey achieve state-of-the-art results. We have made our two best-performing\nConvNet models publicly available to facilitate further research on the use of\ndeep visual representations in computer vision. \n\n"}
{"id": "1409.1716", "contents": "Title: Prolonging the Hide-and-Seek Game: Optimal Trajectory Privacy for\n  Location-Based Services Abstract: Human mobility is highly predictable. Individuals tend to only visit a few\nlocations with high frequency, and to move among them in a certain sequence\nreflecting their habits and daily routine. This predictability has to be taken\ninto account in the design of location privacy preserving mechanisms (LPPMs) in\norder to effectively protect users when they continuously expose their position\nto location-based services (LBSs). In this paper, we describe a method for\ncreating LPPMs that are customized for a user's mobility profile taking into\naccount privacy and quality of service requirements. By construction, our LPPMs\ntake into account the sequential correlation across the user's exposed\nlocations, providing the maximum possible trajectory privacy, i.e., privacy for\nthe user's present location, as well as past and expected future locations.\nMoreover, our LPPMs are optimal against a strategic adversary, i.e., an\nattacker that implements the strongest inference attack knowing both the LPPM\noperation and the user's mobility profile. The optimality of the LPPMs in the\ncontext of trajectory privacy is a novel contribution, and it is achieved by\nformulating the LPPM design problem as a Bayesian Stackelberg game between the\nuser and the adversary. An additional benefit of our formal approach is that\nthe design parameters of the LPPM are chosen by the optimization algorithm. \n\n"}
{"id": "1409.2187", "contents": "Title: A Note on Quantum Security for Post-Quantum Cryptography Abstract: Shor's quantum factoring algorithm and a few other efficient quantum\nalgorithms break many classical crypto-systems. In response, people proposed\npost-quantum cryptography based on computational problems that are believed\nhard even for quantum computers. However, security of these schemes against\n\\emph{quantum} attacks is elusive. This is because existing security analysis\n(almost) only deals with classical attackers and arguing security in the\npresence of quantum adversaries is challenging due to unique quantum features\nsuch as no-cloning.\n  This work proposes a general framework to study which classical security\nproofs can be restored in the quantum setting. Basically, we split a security\nproof into (a sequence of) classical security reductions, and investigate what\nsecurity reductions are \"quantum-friendly\". We characterize sufficient\nconditions such that a classical reduction can be \"lifted\" to the quantum\nsetting. We then apply our lifting theorems to post-quantum signature schemes.\nWe are able to show that the classical generic construction of hash-tree based\nsignatures from one-way functions and and a more efficient variant proposed\nin~\\cite{BDH11} carry over to the quantum setting. Namely, assuming existence\nof (classical) one-way functions that are resistant to efficient quantum\ninversion algorithms, there exists a quantum-secure signature scheme. We note\nthat the scheme in~\\cite{BDH11} is a promising (post-quantum) candidate to be\nimplemented in practice and our result further justifies it. Finally we\ndemonstrate the generality of our framework by showing that several existing\nworks (Full-Domain hash in the quantum random-oracle model~\\cite{Zha12ibe} and\nthe simple hybrid arguments framework in~\\cite{HSS11}) can be reformulated\nunder our unified framework. \n\n"}
{"id": "1409.2432", "contents": "Title: The Crypto-democracy and the Trustworthy Abstract: In the current architecture of the Internet, there is a strong asymmetry in\nterms of power between the entities that gather and process personal data\n(e.g., major Internet companies, telecom operators, cloud providers, ...) and\nthe individuals from which this personal data is issued. In particular,\nindividuals have no choice but to blindly trust that these entities will\nrespect their privacy and protect their personal data. In this position paper,\nwe address this issue by proposing an utopian crypto-democracy model based on\nexisting scientific achievements from the field of cryptography. More\nprecisely, our main objective is to show that cryptographic primitives,\nincluding in particular secure multiparty computation, offer a practical\nsolution to protect privacy while minimizing the trust assumptions. In the\ncrypto-democracy envisioned, individuals do not have to trust a single physical\nentity with their personal data but rather their data is distributed among\nseveral institutions. Together these institutions form a virtual entity called\nthe Trustworthy that is responsible for the storage of this data but which can\nalso compute on it (provided first that all the institutions agree on this).\nFinally, we also propose a realistic proof-of-concept of the Trustworthy, in\nwhich the roles of institutions are played by universities. This\nproof-of-concept would have an important impact in demonstrating the\npossibilities offered by the crypto-democracy paradigm. \n\n"}
{"id": "1409.4696", "contents": "Title: Differentially Private Exponential Random Graphs Abstract: We propose methods to release and analyze synthetic graphs in order to\nprotect privacy of individual relationships captured by the social network.\nProposed techniques aim at fitting and estimating a wide class of exponential\nrandom graph models (ERGMs) in a differentially private manner, and thus offer\nrigorous privacy guarantees. More specifically, we use the randomized response\nmechanism to release networks under $\\epsilon$-edge differential privacy. To\nmaintain utility for statistical inference, treating the original graph as\nmissing, we propose a way to use likelihood based inference and Markov chain\nMonte Carlo (MCMC) techniques to fit ERGMs to the produced synthetic networks.\nWe demonstrate the usefulness of the proposed techniques on a real data\nexample. \n\n"}
{"id": "1409.5844", "contents": "Title: Key Capacity for Product Sources with Application to Stationary Gaussian\n  Processes Abstract: We show that for product sources, rate splitting is optimal for secret key\nagreement using limited one-way communication between two terminals. This\nyields an alternative information-theoretic-converse-style proof of the\ntensorization property of a strong data processing inequality originally\nstudied by Erkip and Cover and amended recently by Anantharam et al. We derive\na water-filling solution of the communication-rate--key-rate tradeoff for a\nwide class of discrete memoryless vector Gaussian sources which subsumes the\ncase without an eavesdropper. Moreover, we derive an explicit formula for the\nmaximum secret key per bit of communication for all discrete memoryless vector\nGaussian sources using a tensorization property and a variation on the enhanced\nchannel technique of Weingarten et al. Finally, a one-shot information spectrum\nachievability bound for key generation is proved from which we characterize the\ncommunication-rate--key-rate tradeoff for stationary Gaussian processes. \n\n"}
{"id": "1410.2435", "contents": "Title: Quantum fully homomorphic encryption scheme based on universal quantum\n  circuit Abstract: Fully homomorphic encryption enables arbitrary computation on encrypted data\nwithout decrypting the data. Here it is studied in the context of quantum\ninformation processing. Based on universal quantum circuit, we present a\nquantum fully homomorphic encryption (QFHE) scheme, which permits arbitrary\nquantum transformation on an encrypted data. The QFHE scheme is proved to be\nperfectly secure. In the scheme, the decryption key is different from the\nencryption key, however, the encryption key cannot be public. Moreover, the\nevaluate algorithm of the scheme is independent of the encryption key, so it is\nvery applicable in delegated quantum computing between two parties. \n\n"}
{"id": "1410.3812", "contents": "Title: Polar Coding for the General Wiretap Channel Abstract: Information-theoretic work for wiretap channels is mostly based on random\ncoding schemes. Designing practical coding schemes to achieve\ninformation-theoretic security is an important problem. By applying the two\nrecently developed techniques for polar codes, we propose a polar coding scheme\nto achieve the secrecy capacity of the general wiretap channel. \n\n"}
{"id": "1411.7210", "contents": "Title: Analyzing the BrowserID SSO System with Primary Identity Providers Using\n  an Expressive Model of the Web Abstract: BrowserID is a complex, real-world Single Sign-On (SSO) System for web\napplications recently developed by Mozilla. It employs new HTML5 features (such\nas web messaging and web storage) and cryptographic assertions to provide\ndecentralized login, with the intent to respect users' privacy. It can operate\nin a primary and a secondary identity provider mode. While in the primary mode\nBrowserID runs with arbitrary identity providers (IdPs), in the secondary mode\nthere is one IdP only, namely Mozilla's default IdP.\n  We recently proposed an expressive general model for the web infrastructure\nand, based on this web model, analyzed the security of the secondary IdP mode\nof BrowserID. The analysis revealed several severe vulnerabilities.\n  In this paper, we complement our prior work by analyzing the even more\ncomplex primary IdP mode of BrowserID. We do not only study authentication\nproperties as before, but also privacy properties. During our analysis we\ndiscovered new and practical attacks that do not apply to the secondary mode:\nan identity injection attack, which violates a central authentication property\nof SSO systems, and attacks that break an important privacy promise of\nBrowserID and which do not seem to be fixable without a major redesign of the\nsystem. Some of our attacks on privacy make use of a browser side channel that\nhas not gained a lot of attention so far.\n  For the authentication bug, we propose a fix and formally prove in a slight\nextension of our general web model that the fixed system satisfies all the\nrequirements we consider. This constitutes the most complex formal analysis of\na web application based on an expressive model of the web infrastructure so\nfar.\n  As another contribution, we identify and prove important security properties\nof generic web features in the extended web model to facilitate future analysis\nefforts of web standards and web applications. \n\n"}
{"id": "1412.0008", "contents": "Title: ScreenAvoider: Protecting Computer Screens from Ubiquitous Cameras Abstract: We live and work in environments that are inundated with cameras embedded in\ndevices such as phones, tablets, laptops, and monitors. Newer wearable devices\nlike Google Glass, Narrative Clip, and Autographer offer the ability to quietly\nlog our lives with cameras from a `first person' perspective. While capturing\nseveral meaningful and interesting moments, a significant number of images\ncaptured by these wearable cameras can contain computer screens. Given the\npotentially sensitive information that is visible on our displays, there is a\nneed to guard computer screens from undesired photography. People need\nprotection against photography of their screens, whether by other people's\ncameras or their own cameras.\n  We present ScreenAvoider, a framework that controls the collection and\ndisclosure of images with computer screens and their sensitive content.\nScreenAvoider can detect images with computer screens with high accuracy and\ncan even go so far as to discriminate amongst screen content. We also introduce\na ScreenTag system that aids in the identification of screen content, flagging\nimages with highly sensitive content such as messaging applications or email\nwebpages. We evaluate our concept on realistic lifelogging datasets, showing\nthat ScreenAvoider provides a practical and useful solution that can help users\nmanage their privacy. \n\n"}
{"id": "1412.4324", "contents": "Title: Secure State Estimation For Cyber Physical Systems Under Sensor Attacks:\n  A Satisfiability Modulo Theory Approach Abstract: We address the problem of detecting and mitigating the effect of malicious\nattacks to the sensors of a linear dynamical system. We develop a novel,\nefficient algorithm that uses a Satisfiability-Modulo-Theory approach to\nisolate the compromised sensors and estimate the system state despite the\npresence of the attack, thus harnessing the intrinsic combinatorial complexity\nof the problem. By leveraging results from formal methods over real numbers, we\nprovide guarantees on the soundness and completeness of our algorithm. We then\nreport simulation results to compare its runtime performance with alternative\ntechniques. Finally, we demonstrate its application to the problem of\ncontrolling an unmanned ground vehicle. \n\n"}
{"id": "1412.5012", "contents": "Title: A Storage-Efficient and Robust Private Information Retrieval Scheme\n  Allowing Few Servers Abstract: Since the concept of locally decodable codes was introduced by Katz and\nTrevisan in 2000, it is well-known that information the-oretically secure\nprivate information retrieval schemes can be built using locally decodable\ncodes. In this paper, we construct a Byzantine ro-bust PIR scheme using the\nmultiplicity codes introduced by Kopparty et al. Our main contributions are on\nthe one hand to avoid full replica-tion of the database on each server; this\nsignificantly reduces the global redundancy. On the other hand, to have a much\nlower locality in the PIR context than in the LDC context. This shows that\nthere exists two different notions: LDC-locality and PIR-locality. This is made\npossible by exploiting geometric properties of multiplicity codes. \n\n"}
{"id": "1412.6011", "contents": "Title: Montgomery's method of polynomial selection for the number field sieve Abstract: The number field sieve is the most efficient known algorithm for factoring\nlarge integers that are free of small prime factors. For the polynomial\nselection stage of the algorithm, Montgomery proposed a method of generating\npolynomials which relies on the construction of small modular geometric\nprogressions. Montgomery's method is analysed in this paper and the existence\nof suitable geometric progressions is considered. \n\n"}
{"id": "1412.7935", "contents": "Title: Bitcoin Meets Strong Consistency Abstract: The Bitcoin system only provides eventual consistency. For everyday life, the\ntime to confirm a Bitcoin transaction is prohibitively slow. In this paper we\npropose a new system, built on the Bitcoin blockchain, which enables strong\nconsistency. Our system, PeerCensus, acts as a certification authority, manages\npeer identities in a peer-to-peer network, and ultimately enhances Bitcoin and\nsimilar systems with strong consistency. Our extensive analysis shows that\nPeerCensus is in a secure state with high probability. We also show how\nDiscoin, a Bitcoin variant that decouples block creation and transaction\nconfirmation, can be built on top of PeerCensus, enabling real-time payments.\nUnlike Bitcoin, once transactions in Discoin are committed, they stay\ncommitted. \n\n"}
{"id": "1501.01042", "contents": "Title: Augur: a decentralized oracle and prediction market platform Abstract: Augur is a trustless, decentralized oracle and platform for prediction\nmarkets. The outcomes of Augur's prediction markets are chosen by users that\nhold Augur's native Reputation token, who stake their tokens on the actual\nobserved outcome and, in return, receive settlement fees from the markets.\nAugur's incentive structure is designed to ensure that honest, accurate\nreporting of outcomes is always the most profitable option for Reputation token\nholders. Token holders can post progressively-larger Reputation bonds to\ndispute proposed market outcomes. If the size of these bonds reaches a certain\nthreshold, Reputation splits into multiple versions, one for each possible\noutcome of the disputed market; token holders must then exchange their\nReputation tokens for one of these versions. Versions of Reputation which do\nnot correspond to the real-world outcome will become worthless, as no one will\nparticipate in prediction markets unless they are confident that the markets\nwill resolve correctly. Therefore, token holders will select the only version\nof Reputation which they know will continue to have value: the version that\ncorresponds to reality. \n\n"}
{"id": "1501.01152", "contents": "Title: Linear decomposition attack on public key exchange protocols using\n  semidirect products of (semi)groups Abstract: We show that a linear decomposition attack based on the decomposition method\nintroduced by the author works by finding the exchanged secret keys in all main\nprotocols using semidirect products of (semi)grops proposed by Kahrobaei,\nShpilrain, Habeeb, Koupparis and Lam. \n\n"}
{"id": "1501.01549", "contents": "Title: Quantifying the Leakage of Quantum Protocols for Classical Two-Party\n  Cryptography Abstract: We study quantum protocols among two distrustful parties. By adopting a\nrather strict definition of correctness - guaranteeing that honest players\nobtain their correct outcomes only - we can show that every strictly correct\nquantum protocol implementing a non-trivial classical primitive necessarily\nleaks information to a dishonest player. This extends known impossibility\nresults to all non-trivial primitives. We provide a framework for quantifying\nthis leakage and argue that leakage is a good measure for the privacy provided\nto the players by a given protocol. Our framework also covers the case where\nthe two players are helped by a trusted third party. We show that despite the\nhelp of a trusted third party, the players cannot amplify the cryptographic\npower of any primitive. All our results hold even against quantum\nhonest-but-curious adversaries who honestly follow the protocol but purify\ntheir actions and apply a different measurement at the end of the protocol. As\nconcrete examples, we establish lower bounds on the leakage of standard\nuniversal two-party primitives such as oblivious transfer. \n\n"}
{"id": "1501.03056", "contents": "Title: Non-Abelian Analogs of Lattice Rounding Abstract: Lattice rounding in Euclidean space can be viewed as finding the nearest\npoint in the orbit of an action by a discrete group, relative to the norm\ninherited from the ambient space. Using this point of view, we initiate the\nstudy of non-abelian analogs of lattice rounding involving matrix groups. In\none direction, we give an algorithm for solving a normed word problem when the\ninputs are random products over a basis set, and give theoretical justification\nfor its success. In another direction, we prove a general inapproximability\nresult which essentially rules out strong approximation algorithms (i.e., whose\napproximation factors depend only on dimension) analogous to LLL in the general\ncase. \n\n"}
{"id": "1501.05943", "contents": "Title: Bit-oriented quantum public-key encryption Abstract: We propose a bit-oriented quantum public-key scheme which uses Boolean\nfunction as private-key and randomly changed pairs of quantum state and\nclassical string as public-keys. Contrast to the typical classical public-key\nscheme, one private-key in our scheme corresponds to an exponential number of\npublic-keys. The goal of our scheme is to achieve information-theoretic\nsecurity, and the security analysis is also given. \n\n"}
{"id": "1501.06095", "contents": "Title: Between Pure and Approximate Differential Privacy Abstract: We show a new lower bound on the sample complexity of $(\\varepsilon,\n\\delta)$-differentially private algorithms that accurately answer statistical\nqueries on high-dimensional databases. The novelty of our bound is that it\ndepends optimally on the parameter $\\delta$, which loosely corresponds to the\nprobability that the algorithm fails to be private, and is the first to\nsmoothly interpolate between approximate differential privacy ($\\delta > 0$)\nand pure differential privacy ($\\delta = 0$).\n  Specifically, we consider a database $D \\in \\{\\pm1\\}^{n \\times d}$ and its\n\\emph{one-way marginals}, which are the $d$ queries of the form \"What fraction\nof individual records have the $i$-th bit set to $+1$?\" We show that in order\nto answer all of these queries to within error $\\pm \\alpha$ (on average) while\nsatisfying $(\\varepsilon, \\delta)$-differential privacy, it is necessary that\n$$ n \\geq \\Omega\\left( \\frac{\\sqrt{d \\log(1/\\delta)}}{\\alpha \\varepsilon}\n\\right), $$ which is optimal up to constant factors. To prove our lower bound,\nwe build on the connection between \\emph{fingerprinting codes} and lower bounds\nin differential privacy (Bun, Ullman, and Vadhan, STOC'14).\n  In addition to our lower bound, we give new purely and approximately\ndifferentially private algorithms for answering arbitrary statistical queries\nthat improve on the sample complexity of the standard Laplace and Gaussian\nmechanisms for achieving worst-case accuracy guarantees by a logarithmic\nfactor. \n\n"}
{"id": "1502.00389", "contents": "Title: Privacy-preserving Network Functionality Outsourcing Abstract: Since the advent of software defined networks ({SDN}), there have been many\nattempts to outsource the complex and costly local network functionality, i.e.\nthe middlebox, to the cloud in the same way as outsourcing computation and\nstorage. The privacy issues, however, may thwart the enterprises' willingness\nto adopt this innovation since the underlying configurations of these\nmiddleboxes may leak crucial and confidential information which can be utilized\nby attackers. To address this new problem, we use firewall as an sample\nfunctionality and propose the first privacy preserving outsourcing framework\nand schemes in SDN. The basic technique that we exploit is a ground-breaking\ntool in cryptography, the \\textit{cryptographic multilinear map}. In contrast\nto the infeasibility in efficiency if a naive approach is adopted, we devise\npractical schemes that can outsource the middlebox as a blackbox after\n\\textit{obfuscating} it such that the cloud provider can efficiently perform\nthe same functionality without knowing its underlying private configurations.\nBoth theoretical analysis and experiments on real-world firewall rules\ndemonstrate that our schemes are secure, accurate, and practical. \n\n"}
{"id": "1502.00433", "contents": "Title: Multi-sources Randomness Extraction over Finite Fields and Elliptic\n  Curve Abstract: This work is based on the proposal of a deterministic randomness extractor of\na random Diffie-Hellman element defined over two prime order multiplicative\nsubgroups of a finite fields $\\mathbb{F}_{p^n}$, $G_1$ and $G_2$. We show that\nthe least significant bits of a random element in $G_1*G_2$, are\nindistinguishable from a uniform bit-string of the same length.\n  One of the main application of this extractor is to replace the use of hash\nfunctions in pairing by the use of a good deterministic randomness extractor. \n\n"}
{"id": "1502.01609", "contents": "Title: Robust and Effective Malware Detection through Quantitative Data Flow\n  Graph Metrics Abstract: We present a novel malware detection approach based on metrics over\nquantitative data flow graphs. Quantitative data flow graphs (QDFGs) model\nprocess behavior by interpreting issued system calls as aggregations of\nquantifiable data flows.Due to the high abstraction level we consider QDFG\nmetric based detection more robust against typical behavior obfuscation like\nbogus call injection or call reordering than other common behavioral models\nthat base on raw system calls. We support this claim with experiments on\nobfuscated malware logs and demonstrate the superior obfuscation robustness in\ncomparison to detection using n-grams. Our evaluations on a large and diverse\ndata set consisting of about 7000 malware and 500 goodware samples show an\naverage detection rate of 98.01% and a false positive rate of 0.48%. Moreover,\nwe show that our approach is able to detect new malware (i.e. samples from\nmalware families not included in the training set) and that the consideration\nof quantities in itself significantly improves detection precision. \n\n"}
{"id": "1502.02563", "contents": "Title: Device-Independent Verifiable Blind Quantum Computation Abstract: As progress on experimental quantum processors continues to advance, the\nproblem of verifying the correct operation of such devices is becoming a\npressing concern. The recent discovery of protocols for verifying computation\nperformed by entangled but non-communicating quantum processors holds the\npromise of certifying the correctness of arbitrary quantum computations in a\nfully device-independent manner. Unfortunately, all known schemes have\nprohibitive overhead, with resources scaling as extremely high degree\npolynomials in the number of gates constituting the computation. Here we\npresent a novel approach based on a combination of verified blind quantum\ncomputation and Bell state self-testing. This approach has dramatically reduced\noverhead, with resources scaling as only $O(m^4\\ln m)$ in the number of gates. \n\n"}
{"id": "1502.03167", "contents": "Title: Batch Normalization: Accelerating Deep Network Training by Reducing\n  Internal Covariate Shift Abstract: Training Deep Neural Networks is complicated by the fact that the\ndistribution of each layer's inputs changes during training, as the parameters\nof the previous layers change. This slows down the training by requiring lower\nlearning rates and careful parameter initialization, and makes it notoriously\nhard to train models with saturating nonlinearities. We refer to this\nphenomenon as internal covariate shift, and address the problem by normalizing\nlayer inputs. Our method draws its strength from making normalization a part of\nthe model architecture and performing the normalization for each training\nmini-batch. Batch Normalization allows us to use much higher learning rates and\nbe less careful about initialization. It also acts as a regularizer, in some\ncases eliminating the need for Dropout. Applied to a state-of-the-art image\nclassification model, Batch Normalization achieves the same accuracy with 14\ntimes fewer training steps, and beats the original model by a significant\nmargin. Using an ensemble of batch-normalized networks, we improve upon the\nbest published result on ImageNet classification: reaching 4.9% top-5\nvalidation error (and 4.8% test error), exceeding the accuracy of human raters. \n\n"}
{"id": "1502.03182", "contents": "Title: PowerSpy: Location Tracking using Mobile Device Power Analysis Abstract: Modern mobile platforms like Android enable applications to read aggregate\npower usage on the phone. This information is considered harmless and reading\nit requires no user permission or notification. We show that by simply reading\nthe phone's aggregate power consumption over a period of a few minutes an\napplication can learn information about the user's location. Aggregate phone\npower consumption data is extremely noisy due to the multitude of components\nand applications that simultaneously consume power. Nevertheless, by using\nmachine learning algorithms we are able to successfully infer the phone's\nlocation. We discuss several ways in which this privacy leak can be remedied. \n\n"}
{"id": "1502.06309", "contents": "Title: Learning with Differential Privacy: Stability, Learnability and the\n  Sufficiency and Necessity of ERM Principle Abstract: While machine learning has proven to be a powerful data-driven solution to\nmany real-life problems, its use in sensitive domains has been limited due to\nprivacy concerns. A popular approach known as **differential privacy** offers\nprovable privacy guarantees, but it is often observed in practice that it could\nsubstantially hamper learning accuracy. In this paper we study the learnability\n(whether a problem can be learned by any algorithm) under Vapnik's general\nlearning setting with differential privacy constraint, and reveal some\nintricate relationships between privacy, stability and learnability.\n  In particular, we show that a problem is privately learnable **if an only\nif** there is a private algorithm that asymptotically minimizes the empirical\nrisk (AERM). In contrast, for non-private learning AERM alone is not sufficient\nfor learnability. This result suggests that when searching for private learning\nalgorithms, we can restrict the search to algorithms that are AERM. In light of\nthis, we propose a conceptual procedure that always finds a universally\nconsistent algorithm whenever the problem is learnable under privacy\nconstraint. We also propose a generic and practical algorithm and show that\nunder very general conditions it privately learns a wide class of learning\nproblems. Lastly, we extend some of the results to the more practical\n$(\\epsilon,\\delta)$-differential privacy and establish the existence of a\nphase-transition on the class of problems that are approximately privately\nlearnable with respect to how small $\\delta$ needs to be. \n\n"}
{"id": "1503.01214", "contents": "Title: Building a RAPPOR with the Unknown: Privacy-Preserving Learning of\n  Associations and Data Dictionaries Abstract: Techniques based on randomized response enable the collection of potentially\nsensitive data from clients in a privacy-preserving manner with strong local\ndifferential privacy guarantees. One of the latest such technologies, RAPPOR,\nallows the marginal frequencies of an arbitrary set of strings to be estimated\nvia privacy-preserving crowdsourcing. However, this original estimation process\nrequires a known set of possible strings; in practice, this dictionary can\noften be extremely large and sometimes completely unknown.\n  In this paper, we propose a novel decoding algorithm for the RAPPOR mechanism\nthat enables the estimation of \"unknown unknowns,\" i.e., strings we do not even\nknow we should be estimating. To enable learning without explicit knowledge of\nthe dictionary, we develop methodology for estimating the joint distribution of\ntwo or more variables collected with RAPPOR. This is a critical step towards\nunderstanding relationships between multiple variables collected in a\nprivacy-preserving manner. \n\n"}
{"id": "1503.04371", "contents": "Title: Uniform Random Number Generation from Markov Chains: Non-Asymptotic and\n  Asymptotic Analyses Abstract: In this paper, we derive non-asymptotic achievability and converse bounds on\nthe random number generation with/without side-information. Our bounds are\nefficiently computable in the sense that the computational complexity does not\ndepend on the block length. We also characterize the asymptotic behaviors of\nthe large deviation regime and the moderate deviation regime by using our\nbounds, which implies that our bounds are asymptotically tight in those\nregimes. We also show the second order rates of those problems, and derive\nsingle letter forms of the variances characterizing the second order rates.\nFurther, we address the equivocation rates for these problems. \n\n"}
{"id": "1503.04729", "contents": "Title: Skilled Impostor Attacks Against Fingerprint Verification Systems And\n  Its Remedy Abstract: Fingerprint verification systems are becoming ubiquitous in everyday life.\nThis trend is propelled especially by the proliferation of mobile devices with\nfingerprint sensors such as smartphones and tablet computers, and fingerprint\nverification is increasingly applied for authenticating financial transactions.\nIn this study we describe a novel attack vector against fingerprint\nverification systems which we coin skilled impostor attack. We show that\nexisting protocols for performance evaluation of fingerprint verification\nsystems are flawed and as a consequence of this, the system's real\nvulnerability is systematically underestimated. We examine a scenario in which\na fingerprint verification system is tuned to operate at false acceptance rate\nof 0.1% using the traditional verification protocols with random impostors\n(zero-effort attacks). We demonstrate that an active and intelligent attacker\ncan achieve a chance of success in the area of 89% or more against this system\nby performing skilled impostor attacks. We describe a new protocol for\nevaluating fingerprint verification performance in order to improve the\nassessment of potential and limitations of fingerprint recognition systems.\nThis new evaluation protocol enables a more informed decision concerning the\noperating threshold in practical applications and the respective trade-off\nbetween security (low false acceptance rates) and usability (low false\nrejection rates). The skilled impostor attack is a general attack concept which\nis independent of specific databases or comparison algorithms. The proposed\nprotocol relying on skilled impostor attacks can directly be applied for\nevaluating the verification performance of other biometric modalities such as\ne.g. iris, face, ear, finger vein, gait or speaker recognition. \n\n"}
{"id": "1504.00429", "contents": "Title: Gradual Release of Sensitive Data under Differential Privacy Abstract: We introduce the problem of releasing sensitive data under differential\nprivacy when the privacy level is subject to change over time. Existing work\nassumes that privacy level is determined by the system designer as a fixed\nvalue before sensitive data is released. For certain applications, however,\nusers may wish to relax the privacy level for subsequent releases of the same\ndata after either a re-evaluation of the privacy concerns or the need for\nbetter accuracy. Specifically, given a database containing sensitive data, we\nassume that a response $y_1$ that preserves $\\epsilon_{1}$-differential privacy\nhas already been published. Then, the privacy level is relaxed to $\\epsilon_2$,\nwith $\\epsilon_2 > \\epsilon_1$, and we wish to publish a more accurate response\n$y_2$ while the joint response $(y_1, y_2)$ preserves $\\epsilon_2$-differential\nprivacy. How much accuracy is lost in the scenario of gradually releasing two\nresponses $y_1$ and $y_2$ compared to the scenario of releasing a single\nresponse that is $\\epsilon_{2}$-differentially private? Our results show that\nthere exists a composite mechanism that achieves \\textit{no loss} in accuracy.\nWe consider the case in which the private data lies within $\\mathbb{R}^{n}$\nwith an adjacency relation induced by the $\\ell_{1}$-norm, and we focus on\nmechanisms that approximate identity queries. We show that the same accuracy\ncan be achieved in the case of gradual release through a mechanism whose\noutputs can be described by a \\textit{lazy Markov stochastic process}. This\nstochastic process has a closed form expression and can be efficiently sampled.\nOur results are applicable beyond identity queries. To this end, we demonstrate\nthat our results can be applied in several cases, including Google's RAPPOR\nproject, trading of sensitive data, and controlled transmission of private data\nin a social network. \n\n"}
{"id": "1504.00943", "contents": "Title: Deterministic Relativistic Quantum Bit Commitment Abstract: We describe new unconditionally secure bit commitment schemes whose security\nis based on Minkowski causality and the monogamy of quantum entanglement. We\nfirst describe an ideal scheme that is purely deterministic, in the sense that\nneither party needs to generate any secret randomness at any stage. We also\ndescribe a variant that allows the committer to proceed deterministically,\nrequires only local randomness generation from the receiver, and allows the\ncommitment to be verified in the neighbourhood of the unveiling point. We show\nthat these schemes still offer near-perfect security in the presence of losses\nand errors, which can be made perfect if the committer uses an extra single\nrandom secret bit. We discuss scenarios where these advantages are significant. \n\n"}
{"id": "1504.02347", "contents": "Title: Point Decomposition Problem in Binary Elliptic Curves Abstract: We analyze the point decomposition problem (PDP) in binary elliptic curves.\nIt is known that PDP in an elliptic curve group can be reduced to solving a\nparticular system of multivariate non-linear system of equations derived from\nthe so called Semaev summation polynomials. We modify the underlying system of\nequations by introducing some auxiliary variables. We argue that the trade-off\nbetween lowering the degree of Semaev polynomials and increasing the number of\nvariables is worth. \n\n"}
{"id": "1504.03561", "contents": "Title: On the Workflow Satisfiability Problem with Class-Independent\n  Constraints Abstract: A workflow specification defines sets of steps and users. An authorization\npolicy determines for each user a subset of steps the user is allowed to\nperform. Other security requirements, such as separation-of-duty, impose\nconstraints on which subsets of users may perform certain subsets of steps. The\n\\emph{workflow satisfiability problem} (WSP) is the problem of determining\nwhether there exists an assignment of users to workflow steps that satisfies\nall such authorizations and constraints. An algorithm for solving WSP is\nimportant, both as a static analysis tool for workflow specifications, and for\nthe construction of run-time reference monitors for workflow management\nsystems. Given the computational difficulty of WSP, it is important,\nparticularly for the second application, that such algorithms are as efficient\nas possible.\n  We introduce class-independent constraints, enabling us to model scenarios\nwhere the set of users is partitioned into groups, and the identities of the\nuser groups are irrelevant to the satisfaction of the constraint. We prove that\nsolving WSP is fixed-parameter tractable (FPT) for this class of constraints\nand develop an FPT algorithm that is useful in practice. We compare the\nperformance of the FPT algorithm with that of SAT4J (a pseudo-Boolean SAT\nsolver) in computational experiments, which show that our algorithm\nsignificantly outperforms SAT4J for many instances of WSP. User-independent\nconstraints, a large class of constraints including many practical ones, are a\nspecial case of class-independent constraints for which WSP was proved to be\nFPT (Cohen {\\em et al.}, J. Artif. Intel. Res. 2014). Thus our results\nconsiderably extend our knowledge of the fixed-parameter tractability of WSP. \n\n"}
{"id": "1504.04217", "contents": "Title: Quantum and classical coin-flipping protocols based on bit-commitment\n  and their point games Abstract: We focus on a family of quantum coin-flipping protocols based on\nbit-commitment. We discuss how the semidefinite programming formulations of\ncheating strategies can be reduced to optimizing a linear combination of\nfidelity functions over a polytope. These turn out to be much simpler\nsemidefinite programs which can be modelled using second-order cone programming\nproblems. We then use these simplifications to construct their point games as\ndeveloped by Kitaev. We also study the classical version of these protocols and\nuse linear optimization to formulate optimal cheating strategies. We then\nconstruct the point games for the classical protocols as well using the\nanalysis for the quantum case.\n  We discuss the philosophical connections between the classical and quantum\nprotocols and their point games as viewed from optimization theory. In\nparticular, we observe an analogy between a spectrum of physical theories (from\nclassical to quantum) and a spectrum of convex optimization problems (from\nlinear programming to semidefinite programming, through second-order cone\nprogramming). In this analogy, classical systems correspond to linear\nprogramming problems and the level of quantum features in the system is\ncorrelated to the level of sophistication of the semidefinite programming\nmodels on the optimization side.\n  Concerning security analysis, we use the classical point games to prove that\nevery classical protocol of this type allows exactly one of the parties to\nentirely determine the coin-flip. Using the relationships between the quantum\nand classical protocols, we show that only \"classical\" protocols can saturate\nKitaev's lower bound for strong coin-flipping. Moreover, if the product of\nAlice and Bob's optimal cheating probabilities is 1/2, then one party can cheat\nwith probability 1. This rules out quantum protocols of this type from\nattaining the optimal level of security. \n\n"}
{"id": "1504.04686", "contents": "Title: Local, Private, Efficient Protocols for Succinct Histograms Abstract: We give efficient protocols and matching accuracy lower bounds for frequency\nestimation in the local model for differential privacy. In this model,\nindividual users randomize their data themselves, sending differentially\nprivate reports to an untrusted server that aggregates them.\n  We study protocols that produce a succinct histogram representation of the\ndata. A succinct histogram is a list of the most frequent items in the data\n(often called \"heavy hitters\") along with estimates of their frequencies; the\nfrequency of all other items is implicitly estimated as 0.\n  If there are $n$ users whose items come from a universe of size $d$, our\nprotocols run in time polynomial in $n$ and $\\log(d)$. With high probability,\nthey estimate the accuracy of every item up to error\n$O\\left(\\sqrt{\\log(d)/(\\epsilon^2n)}\\right)$ where $\\epsilon$ is the privacy\nparameter. Moreover, we show that this much error is necessary, regardless of\ncomputational efficiency, and even for the simple setting where only one item\nappears with significant frequency in the data set.\n  Previous protocols (Mishra and Sandler, 2006; Hsu, Khanna and Roth, 2012) for\nthis task either ran in time $\\Omega(d)$ or had much worse error (about\n$\\sqrt[6]{\\log(d)/(\\epsilon^2n)}$), and the only known lower bound on error was\n$\\Omega(1/\\sqrt{n})$.\n  We also adapt a result of McGregor et al (2010) to the local setting. In a\nmodel with public coins, we show that each user need only send 1 bit to the\nserver. For all known local protocols (including ours), the transformation\npreserves computational efficiency. \n\n"}
{"id": "1504.05255", "contents": "Title: Semantic Security and Indistinguishability in the Quantum World Abstract: At CRYPTO 2013, Boneh and Zhandry initiated the study of quantum-secure\nencryption. They proposed first indistinguishability definitions for the\nquantum world where the actual indistinguishability only holds for classical\nmessages, and they provide arguments why it might be hard to achieve a stronger\nnotion. In this work, we show that stronger notions are achievable, where the\nindistinguishability holds for quantum superpositions of messages. We\ninvestigate exhaustively the possibilities and subtle differences in defining\nsuch a quantum indistinguishability notion for symmetric-key encryption\nschemes. We justify our stronger definition by showing its equivalence to novel\nquantum semantic-security notions that we introduce. Furthermore, we show that\nour new security definitions cannot be achieved by a large class of ciphers --\nthose which are quasi-preserving the message length. On the other hand, we\nprovide a secure construction based on quantum-resistant pseudorandom\npermutations; this construction can be used as a generic transformation for\nturning a large class of encryption schemes into quantum indistinguishable and\nhence quantum semantically secure ones. Moreover, our construction is the first\ncompletely classical encryption scheme shown to be secure against an even\nstronger notion of indistinguishability, which was previously known to be\nachievable only by using quantum messages and arbitrary quantum encryption\ncircuits. \n\n"}
{"id": "1504.05566", "contents": "Title: Secure State Estimation: Optimal Guarantees against Sensor Attacks in\n  the Presence of Noise Abstract: Motivated by the need to secure cyber-physical systems against attacks, we\nconsider the problem of estimating the state of a noisy linear dynamical system\nwhen a subset of sensors is arbitrarily corrupted by an adversary. We propose a\nsecure state estimation algorithm and derive (optimal) bounds on the achievable\nstate estimation error. In addition, as a result of independent interest, we\ngive a coding theoretic interpretation for prior work on secure state\nestimation against sensor attacks in a noiseless dynamical system. \n\n"}
{"id": "1504.05862", "contents": "Title: Compute-and-Forward Can Buy Secrecy Cheap Abstract: We consider a Gaussian multiple access channel with $K$ transmitters, a\n(intended) receiver and an external eavesdropper. The transmitters wish to\nreliably communicate with the receiver while concealing their messages from the\neavesdropper. This scenario has been investigated in prior works using two\ndifferent coding techniques; the random i.i.d. Gaussian coding and the signal\nalignment coding. Although, the latter offers promising results in a very high\nSNR regime, extending these results to the finite SNR regime is a challenging\ntask. In this paper, we propose a new lattice alignment scheme based on the\ncompute-and-forward framework which works at any finite SNR. We show that our\nachievable secure sum rate scales with $\\log(\\mathrm{SNR})$ and hence, in most\nSNR regimes, our scheme outperforms the random coding scheme in which the\nsecure sum rate does not grow with power. Furthermore, we show that our result\nmatches the prior work in the infinite SNR regime. Additionally, we analyze our\nresult numerically. \n\n"}
{"id": "1504.05880", "contents": "Title: Spectral Norm of Random Kernel Matrices with Applications to Privacy Abstract: Kernel methods are an extremely popular set of techniques used for many\nimportant machine learning and data analysis applications. In addition to\nhaving good practical performances, these methods are supported by a\nwell-developed theory. Kernel methods use an implicit mapping of the input data\ninto a high dimensional feature space defined by a kernel function, i.e., a\nfunction returning the inner product between the images of two data points in\nthe feature space. Central to any kernel method is the kernel matrix, which is\nbuilt by evaluating the kernel function on a given sample dataset.\n  In this paper, we initiate the study of non-asymptotic spectral theory of\nrandom kernel matrices. These are n x n random matrices whose (i,j)th entry is\nobtained by evaluating the kernel function on $x_i$ and $x_j$, where\n$x_1,...,x_n$ are a set of n independent random high-dimensional vectors. Our\nmain contribution is to obtain tight upper bounds on the spectral norm (largest\neigenvalue) of random kernel matrices constructed by commonly used kernel\nfunctions based on polynomials and Gaussian radial basis.\n  As an application of these results, we provide lower bounds on the distortion\nneeded for releasing the coefficients of kernel ridge regression under\nattribute privacy, a general privacy notion which captures a large class of\nprivacy definitions. Kernel ridge regression is standard method for performing\nnon-parametric regression that regularly outperforms traditional regression\napproaches in various domains. Our privacy distortion lower bounds are the\nfirst for any kernel technique, and our analysis assumes realistic scenarios\nfor the input, unlike all previous lower bounds for other release problems\nwhich only hold under very restrictive input settings. \n\n"}
{"id": "1504.07098", "contents": "Title: Secure and Verifiable Electronic Voting in Practice: the use of vVote in\n  the Victorian State Election Abstract: The November 2014 Australian State of Victoria election was the first\nstatutory political election worldwide at State level which deployed an\nend-to-end verifiable electronic voting system in polling places. This was the\nfirst time blind voters have been able to cast a fully secret ballot in a\nverifiable way, and the first time a verifiable voting system has been used to\ncollect remote votes in a political election. The code is open source, and the\noutput from the election is verifiable. The system took 1121 votes from these\nparticular groups, an increase on 2010 and with fewer polling places. \n\n"}
{"id": "1504.07313", "contents": "Title: Private Disclosure of Information in Health Tele-monitoring Abstract: We present a novel framework, called Private Disclosure of Information (PDI),\nwhich is aimed to prevent an adversary from inferring certain sensitive\ninformation about subjects using the data that they disclosed during\ncommunication with an intended recipient. We show cases where it is possible to\nachieve perfect privacy regardless of the adversary's auxiliary knowledge while\npreserving full utility of the information to the intended recipient and\nprovide sufficient conditions for such cases. We also demonstrate the\napplicability of PDI on a real-world data set that simulates a health\ntele-monitoring scenario. \n\n"}
{"id": "1505.00920", "contents": "Title: New 2D CA based Image Encryption Scheme and a novel Non-Parametric Test\n  for Pixel Randomness Abstract: In this paper we have proposed a new test for pixel randomness using\nnon-parametric method in statistics. In order to validate this new\nnon-parametric test we have designed an encryption scheme based on 2D cellular\nautomata. The strength of the designed encryption scheme is first assessed by\nstandard methods for security analysis and the pixel randomness is then\ndetermined by the newly proposed non-parametric method. \n\n"}
{"id": "1505.01131", "contents": "Title: Program Actions as Actual Causes: A Building Block for Accountability Abstract: Protocols for tasks such as authentication, electronic voting, and secure\nmultiparty computation ensure desirable security properties if agents follow\ntheir prescribed programs. However, if some agents deviate from their\nprescribed programs and a security property is violated, it is important to\nhold agents accountable by determining which deviations actually caused the\nviolation. Motivated by these applications, we initiate a formal study of\nprogram actions as actual causes. Specifically, we define in an interacting\nprogram model what it means for a set of program actions to be an actual cause\nof a violation. We present a sound technique for establishing program actions\nas actual causes. We demonstrate the value of this formalism in two ways.\nFirst, we prove that violations of a specific class of safety properties always\nhave an actual cause. Thus, our definition applies to relevant security\nproperties. Second, we provide a cause analysis of a representative protocol\ndesigned to address weaknesses in the current public key certification\ninfrastructure. \n\n"}
{"id": "1505.01750", "contents": "Title: Immutable Views -- Access control (to your information) for masses Abstract: There are a lot of on going efforts in the research community as well as\nindustry around providing privacy-preserving and secure storage for personal\ndata. Although, over time it has adopted many tag lines such as Personal\nInformation Hub [12], personal container [8], DataBox [4], Personal Data Store\n(PDS) [3] and many others, these are essentially reincarnations of a simple\nidea: provide a secure way and place for users to store their information and\nallow them to provision who has access to that information. In this paper, we\nwould like to discuss a way to facilitate access control mechanism (AC) in the\nvarious \"personal cloud\" proposals. \n\n"}
{"id": "1505.02414", "contents": "Title: A Game-Theoretic Study on Non-Monetary Incentives in Data Analytics\n  Projects with Privacy Implications Abstract: The amount of personal information contributed by individuals to digital\nrepositories such as social network sites has grown substantially. The\nexistence of this data offers unprecedented opportunities for data analytics\nresearch in various domains of societal importance including medicine and\npublic policy. The results of these analyses can be considered a public good\nwhich benefits data contributors as well as individuals who are not making\ntheir data available. At the same time, the release of personal information\ncarries perceived and actual privacy risks to the contributors. Our research\naddresses this problem area. In our work, we study a game-theoretic model in\nwhich individuals take control over participation in data analytics projects in\ntwo ways: 1) individuals can contribute data at a self-chosen level of\nprecision, and 2) individuals can decide whether they want to contribute at all\n(or not). From the analyst's perspective, we investigate to which degree the\nresearch analyst has flexibility to set requirements for data precision, so\nthat individuals are still willing to contribute to the project, and the\nquality of the estimation improves. We study this tradeoff scenario for\npopulations of homogeneous and heterogeneous individuals, and determine Nash\nequilibria that reflect the optimal level of participation and precision of\ncontributions. We further prove that the analyst can substantially increase the\naccuracy of the analysis by imposing a lower bound on the precision of the data\nthat users can reveal. \n\n"}
{"id": "1505.02824", "contents": "Title: Perfectly secure data aggregation via shifted projections Abstract: We study a general scenario where confidential information is distributed\namong a group of agents who wish to share it in such a way that the data\nbecomes common knowledge among them but an eavesdropper intercepting their\ncommunications would be unable to obtain any of said data. The information is\nmodelled as a deck of cards dealt among the agents, so that after the\ninformation is exchanged, all of the communicating agents must know the entire\ndeal, but the eavesdropper must remain ignorant about who holds each card.\n  Valentin Goranko and the author previously set up this scenario as the secure\naggregation of distributed information problem and constructed weakly safe\nprotocols, where given any card $c$, the eavesdropper does not know with\ncertainty which agent holds $c$. Here we present a perfectly safe protocol,\nwhich does not alter the eavesdropper's perceived probability that any given\nagent holds $c$. In our protocol, one of the communicating agents holds a\nlarger portion of the cards than the rest, but we show how for infinitely many\nvalues of $a$, the number of cards may be chosen so that each of the $m$ agents\nholds more than $a$ cards and less than $2m^2a$. \n\n"}
{"id": "1505.05960", "contents": "Title: Privacy-preserving Cross-domain Routing Optimization -- A Cryptographic\n  Approach Abstract: Today's large-scale enterprise networks, data center networks, and wide area\nnetworks can be decomposed into multiple administrative or geographical\ndomains. Domains may be owned by different administrative units or\norganizations. Hence protecting domain information is an important concern.\nExisting general-purpose Secure Multi-Party Computation (SMPC) methods that\npreserves privacy for domains are extremely slow for cross-domain routing\nproblems. In this paper we present PYCRO, a cryptographic protocol specifically\ndesigned for privacy-preserving cross-domain routing optimization in Software\nDefined Networking (SDN) environments. PYCRO provides two fundamental routing\nfunctions, policy-compliant shortest path computing and bandwidth allocation,\nwhile ensuring strong protection for the private information of domains. We\nrigorously prove the privacy guarantee of our protocol. We have implemented a\nprototype system that runs PYCRO on servers in a campus network. Experimental\nresults using real ISP network topologies show that PYCRO is very efficient in\ncomputation and communication costs. \n\n"}
{"id": "1506.04188", "contents": "Title: A case study in almost-perfect security for unconditionally secure\n  communication Abstract: In the Russian cards problem, Alice, Bob and Cath draw $a$, $b$ and $c$\ncards, respectively, from a publicly known deck. Alice and Bob must then\ncommunicate their cards to each other without Cath learning who holds a single\ncard. Solutions in the literature provide weak security, where Cath does not\nknow with certainty who holds each card that is not hers, or perfect security,\nwhere Cath learns no probabilistic information about who holds any given card\nfrom Alice and Bob's exchange. We propose an intermediate notion, which we call\n$\\varepsilon$-strong security, where the probabilities perceived by Cath may\nonly change by a factor of $\\varepsilon$. We then show that a mild variant of\nthe so-called geometric strategy gives $\\varepsilon$-strong safety for\narbitrarily small $\\varepsilon$ and appropriately chosen values of $a,b,c$. \n\n"}
{"id": "1506.07739", "contents": "Title: On Making Emerging Trusted Execution Environments Accessible to\n  Developers Abstract: New types of Trusted Execution Environment (TEE) architectures like TrustLite\nand Intel Software Guard Extensions (SGX) are emerging. They bring new features\nthat can lead to innovative security and privacy solutions. But each new TEE\nenvironment comes with its own set of interfaces and programming paradigms,\nthus raising the barrier for entry for developers who want to make use of these\nTEEs. In this paper, we motivate the need for realizing standard TEE interfaces\non such emerging TEE architectures and show that this exercise is not\nstraightforward. We report on our on-going work in mapping GlobalPlatform\nstandard interfaces to TrustLite and SGX. \n\n"}
{"id": "1507.00255", "contents": "Title: ReCon: Revealing and Controlling PII Leaks in Mobile Network Traffic Abstract: It is well known that apps running on mobile devices extensively track and\nleak users' personally identifiable information (PII); however, these users\nhave little visibility into PII leaked through the network traffic generated by\ntheir devices, and have poor control over how, when and where that traffic is\nsent and handled by third parties. In this paper, we present the design,\nimplementation, and evaluation of ReCon: a cross-platform system that reveals\nPII leaks and gives users control over them without requiring any special\nprivileges or custom OSes. ReCon leverages machine learning to reveal potential\nPII leaks by inspecting network traffic, and provides a visualization tool to\nempower users with the ability to control these leaks via blocking or\nsubstitution of PII. We evaluate ReCon's effectiveness with measurements from\ncontrolled experiments using leaks from the 100 most popular iOS, Android, and\nWindows Phone apps, and via an IRB-approved user study with 92 participants. We\nshow that ReCon is accurate, efficient, and identifies a wider range of PII\nthan previous approaches. \n\n"}
{"id": "1507.00576", "contents": "Title: Flip the Cloud: Cyber-Physical Signaling Games in the Presence of\n  Advanced Persistent Threats Abstract: Access to the cloud has the potential to provide scalable and cost effective\nenhancements of physical devices through the use of advanced computational\nprocesses run on apparently limitless cyber infrastructure. On the other hand,\ncyber-physical systems and cloud-controlled devices are subject to numerous\ndesign challenges; among them is that of security. In particular, recent\nadvances in adversary technology pose Advanced Persistent Threats (APTs) which\nmay stealthily and completely compromise a cyber system. In this paper, we\ndesign a framework for the security of cloud-based systems that specifies when\na device should trust commands from the cloud which may be compromised. This\ninteraction can be considered as a game between three players: a cloud\ndefender/administrator, an attacker, and a device. We use traditional signaling\ngames to model the interaction between the cloud and the device, and we use the\nrecently proposed FlipIt game to model the struggle between the defender and\nattacker for control of the cloud. Because attacks upon the cloud can occur\nwithout knowledge of the defender, we assume that strategies in both games are\npicked according to prior commitment. This framework requires a new equilibrium\nconcept, which we call Gestalt Equilibrium, a fixed-point that expresses the\ninterdependence of the signaling and FlipIt games. We present the solution to\nthis fixed-point problem under certain parameter cases, and illustrate an\nexample application of cloud control of an unmanned vehicle. Our results\ncontribute to the growing understanding of cloud-controlled systems. \n\n"}
{"id": "1507.01083", "contents": "Title: Interactive certificate for the verification of Wiedemann's Krylov\n  sequence: application to the certification of the determinant, the minimal\n  and the characteristic polynomials of sparse matrices Abstract: Certificates to a linear algebra computation are additional data structures\nfor each output, which can be used by a-possibly randomized- verification\nalgorithm that proves the correctness of each output. Wiede-mann's algorithm\nprojects the Krylov sequence obtained by repeatedly multiplying a vector by a\nmatrix to obtain a linearly recurrent sequence. The minimal polynomial of this\nsequence divides the minimal polynomial of the matrix. For instance, if the\n$n\\times n$ input matrix is sparse with n 1+o(1) non-zero entries, the\ncomputation of the sequence is quadratic in the dimension of the matrix while\nthe computation of the minimal polynomial is n 1+o(1), once that projected\nKrylov sequence is obtained. In this paper we give algorithms that compute\ncertificates for the Krylov sequence of sparse or structured $n\\times n$\nmatrices over an abstract field, whose Monte Carlo verification complexity can\nbe made essentially linear. As an application this gives certificates for the\ndeterminant, the minimal and characteristic polynomials of sparse or structured\nmatrices at the same cost. \n\n"}
{"id": "1507.01625", "contents": "Title: Classical Cryptographic Protocols in a Quantum World Abstract: Cryptographic protocols, such as protocols for secure function evaluation\n(SFE), have played a crucial role in the development of modern cryptography.\nThe extensive theory of these protocols, however, deals almost exclusively with\nclassical attackers. If we accept that quantum information processing is the\nmost realistic model of physically feasible computation, then we must ask: what\nclassical protocols remain secure against quantum attackers?\n  Our main contribution is showing the existence of classical two-party\nprotocols for the secure evaluation of any polynomial-time function under\nreasonable computational assumptions (for example, it suffices that the\nlearning with errors problem be hard for quantum polynomial time). Our result\nshows that the basic two-party feasibility picture from classical cryptography\nremains unchanged in a quantum world. \n\n"}
{"id": "1507.03114", "contents": "Title: A Placement Vulnerability Study in Multi-tenant Public Clouds Abstract: Public infrastructure-as-a-service clouds, such as Amazon EC2, Google Compute\nEngine (GCE) and Microsoft Azure allow clients to run virtual machines (VMs) on\nshared physical infrastructure. This practice of multi-tenancy brings economies\nof scale, but also introduces the risk of sharing a physical server with an\narbitrary and potentially malicious VM. Past works have demonstrated how to\nplace a VM alongside a target victim (co-location) in early-generation clouds\nand how to extract secret information via side- channels. Although there have\nbeen numerous works on side-channel attacks, there have been no studies on\nplacement vulnerabilities in public clouds since the adoption of stronger\nisolation technologies such as Virtual Private Clouds (VPCs).\n  We investigate this problem of placement vulnerabilities and quantitatively\nevaluate three popular public clouds for their susceptibility to co-location\nattacks. We find that adoption of new technologies (e.g., VPC) makes many prior\nattacks, such as cloud cartography, ineffective. We find new ways to reliably\ntest for co-location across Amazon EC2, Google GCE, and Microsoft Azure. We\nalso found ways to detect co-location with victim web servers in a multi-tiered\ncloud application located behind a load balancer.\n  We use our new co-residence tests and multiple customer accounts to launch VM\ninstances under different strategies that seek to maximize the likelihood of\nco-residency. We find that it is much easier (10x higher success rate) and\ncheaper (up to $114 less) to achieve co-location in these three clouds when\ncompared to a secure reference placement policy. \n\n"}
{"id": "1507.03117", "contents": "Title: Apate - A Linux Kernel Module for High Interaction Honeypots Abstract: Honeypots are used in IT Security to detect and gather information about\nongoing intrusions, e.g., by documenting the approach of an attacker. Honeypots\ndo so by presenting an interactive system that seems just like a valid\napplication to an attacker. One of the main design goals of honeypots is to\nstay unnoticed by attackers as long as possible. The longer the intruder\ninteracts with the honeypot, the more valuable information about the attack can\nbe collected. Of course, another main goal of honeypots is to not open new\nvulnerabilities that attackers can exploit. Thus, it is necessary to harden the\nhoneypot and the surrounding environment. This paper presents Apate, a Linux\nKernel Module (LKM) that is able to log, block and manipulate system calls\nbased on preconfigurable conditions like Process ID (PID), User Id (UID), and\nmany more. Apate can be used to build and harden High Interaction Honeypots.\nApate can be configured using an integrated high level language. Thus, Apate is\nan important and easy to use building block for upcoming High Interaction\nHoneypots. \n\n"}
{"id": "1507.03528", "contents": "Title: Visibility-Aware Optimal Contagion of Malware Epidemics Abstract: Recent innovations in the design of computer viruses have led to new\ntrade-offs for the attacker. Multiple variants of a malware may spread at\ndifferent rates and have different levels of visibility to the network. In this\nwork we examine the optimal strategies for the attacker so as to trade off the\nextent of spread of the malware against the need for stealth. We show that in\nthe mean-field deterministic regime, this spread-stealth trade-off is optimized\nby computationally simple single-threshold policies. Specifically, we show that\nonly one variant of the malware is spread by the attacker at each time, as\nthere exists a time up to which the attacker prioritizes maximizing the spread\nof the malware, and after which she prioritizes stealth. \n\n"}
{"id": "1507.06955", "contents": "Title: Rowhammer.js: A Remote Software-Induced Fault Attack in JavaScript Abstract: A fundamental assumption in software security is that a memory location can\nonly be modified by processes that may write to this memory location. However,\na recent study has shown that parasitic effects in DRAM can change the content\nof a memory cell without accessing it, but by accessing other memory locations\nin a high frequency. This so-called Rowhammer bug occurs in most of today's\nmemory modules and has fatal consequences for the security of all affected\nsystems, e.g., privilege escalation attacks.\n  All studies and attacks related to Rowhammer so far rely on the availability\nof a cache flush instruction in order to cause accesses to DRAM modules at a\nsufficiently high frequency. We overcome this limitation by defeating complex\ncache replacement policies. We show that caches can be forced into fast cache\neviction to trigger the Rowhammer bug with only regular memory accesses. This\nallows to trigger the Rowhammer bug in highly restricted and even scripting\nenvironments.\n  We demonstrate a fully automated attack that requires nothing but a website\nwith JavaScript to trigger faults on remote hardware. Thereby we can gain\nunrestricted access to systems of website visitors. We show that the attack\nworks on off-the-shelf systems. Existing countermeasures fail to protect\nagainst this new Rowhammer attack. \n\n"}
{"id": "1507.07848", "contents": "Title: Public-key cryptosystem based on invariants of diagonalizable groups Abstract: We develop a public key cryptosystem based on invariants of diagonalizable\ngroups and investigate properties of such cryptosystem first over finite\nfields, then over number fields and finally over finite rings. We consider the\nsecurity of these cryptosystem and show that it is necessary to restrict the\nset of parameters of the system to prevent various attacks (including linear\nalgebra attacks and attacks based on Euclidean algorithm). \n\n"}
{"id": "1507.07872", "contents": "Title: Web Tracking: Mechanisms, Implications, and Defenses Abstract: This articles surveys the existing literature on the methods currently used\nby web services to track the user online as well as their purposes,\nimplications, and possible user's defenses. A significant majority of reviewed\narticles and web resources are from years 2012-2014. Privacy seems to be the\nAchilles' heel of today's web. Web services make continuous efforts to obtain\nas much information as they can about the things we search, the sites we visit,\nthe people with who we contact, and the products we buy. Tracking is usually\nperformed for commercial purposes. We present 5 main groups of methods used for\nuser tracking, which are based on sessions, client storage, client cache,\nfingerprinting, or yet other approaches. A special focus is placed on\nmechanisms that use web caches, operational caches, and fingerprinting, as they\nare usually very rich in terms of using various creative methodologies. We also\nshow how the users can be identified on the web and associated with their real\nnames, e-mail addresses, phone numbers, or even street addresses. We show why\ntracking is being used and its possible implications for the users (price\ndiscrimination, assessing financial credibility, determining insurance\ncoverage, government surveillance, and identity theft). For each of the\ntracking methods, we present possible defenses. Apart from describing the\nmethods and tools used for keeping the personal data away from being tracked,\nwe also present several tools that were used for research purposes - their main\ngoal is to discover how and by which entity the users are being tracked on\ntheir desktop computers or smartphones, provide this information to the users,\nand visualize it in an accessible and easy to follow way. Finally, we present\nthe currently proposed future approaches to track the user and show that they\ncan potentially pose significant threats to the users' privacy. \n\n"}
{"id": "1508.00545", "contents": "Title: Connectivity in Secure Wireless Sensor Networks under Transmission\n  Constraints Abstract: In wireless sensor networks (WSNs), the Eschenauer-Gligor (EG) key\npre-distribution scheme is a widely recognized way to secure communications.\nAlthough connectivity properties of secure WSNs with the EG scheme have been\nextensively investigated, few results address physical transmission\nconstraints. These constraints reflect real-world implementations of WSNs in\nwhich two sensors have to be within a certain distance from each other to\ncommunicate. In this paper, we present zero-one laws for connectivity in WSNs\nemploying the EG scheme under transmission constraints. These laws help specify\nthe critical transmission ranges for connectivity. Our analytical findings are\nconfirmed via numerical experiments. In addition to secure WSNs, our\ntheoretical results are also applied to frequency hopping in wireless networks. \n\n"}
{"id": "1508.01746", "contents": "Title: Using Deep Learning for Detecting Spoofing Attacks on Speech Signals Abstract: It is well known that speaker verification systems are subject to spoofing\nattacks. The Automatic Speaker Verification Spoofing and Countermeasures\nChallenge -- ASVSpoof2015 -- provides a standard spoofing database, containing\nattacks based on synthetic speech, along with a protocol for experiments. This\npaper describes CPqD's systems submitted to the ASVSpoof2015 Challenge, based\non deep neural networks, working both as a classifier and as a feature\nextraction module for a GMM and a SVM classifier. Results show the validity of\nthis approach, achieving less than 0.5\\% EER for known attacks. \n\n"}
{"id": "1508.01818", "contents": "Title: Designing Incentive Schemes For Privacy-Sensitive Users Abstract: Businesses (retailers) often wish to offer personalized advertisements\n(coupons) to individuals (consumers), but run the risk of strong reactions from\nconsumers who want a customized shopping experience but feel their privacy has\nbeen violated. Existing models for privacy such as differential privacy or\ninformation theory try to quantify privacy risk but do not capture the\nsubjective experience and heterogeneous expression of privacy-sensitivity. We\npropose a Markov decision process (MDP) model to capture (i) different consumer\nprivacy sensitivities via a time-varying state; (ii) different coupon types\n(action set) for the retailer; and (iii) the action-and-state-dependent cost\nfor perceived privacy violations. For the simple case with two states (\"Normal\"\nand \"Alerted\"), two coupons (targeted and untargeted) model, and consumer\nbehavior statistics known to the retailer, we show that a stationary\nthreshold-based policy is the optimal coupon-offering strategy for a retailer\nthat wishes to minimize its expected discounted cost. The threshold is a\nfunction of all model parameters; the retailer offers a targeted coupon if\ntheir belief that the consumer is in the \"Alerted\" state is below the\nthreshold. We extend this two-state model to consumers with multiple\nprivacy-sensitivity states as well as coupon-dependent state transition\nprobabilities. Furthermore, we study the case with imperfect (noisy) cost\nfeedback from consumers and uncertain initial belief state. \n\n"}
{"id": "1508.07306", "contents": "Title: On the Privacy Properties of Variants on the Sparse Vector Technique Abstract: The sparse vector technique is a powerful differentially private primitive\nthat allows an analyst to check whether queries in a stream are greater or\nlesser than a threshold. This technique has a unique property -- the algorithm\nworks by adding noise with a finite variance to the queries and the threshold,\nand guarantees privacy that only degrades with (a) the maximum sensitivity of\nany one query in stream, and (b) the number of positive answers output by the\nalgorithm. Recent work has developed variants of this algorithm, which we call\n{\\em generalized private threshold testing}, and are claimed to have privacy\nguarantees that do not depend on the number of positive or negative answers\noutput by the algorithm. These algorithms result in a significant improvement\nin utility over the sparse vector technique for a given privacy budget, and\nhave found applications in frequent itemset mining, feature selection in\nmachine learning and generating synthetic data.\n  In this paper we critically analyze the privacy properties of generalized\nprivate threshold testing. We show that generalized private threshold testing\ndoes not satisfy \\epsilon-differential privacy for any finite \\epsilon. We\nidentify a subtle error in the privacy analysis of this technique in prior\nwork. Moreover, we show an adversary can use generalized private threshold\ntesting to recover counts from the datasets (especially small counts) exactly\nwith high accuracy, and thus can result in individuals being reidentified. We\ndemonstrate our attacks empirically on real datasets. \n\n"}
{"id": "1509.01552", "contents": "Title: Overview on Security Approaches in Intelligent Transportation Systems Abstract: Major standardization bodies developed and designed systems that should be\nused in vehicular ad-hoc networks. The Institute of Electrical and Electronics\nEngineers (IEEE) in America designed the wireless access in vehicular\nenvironments (WAVE) system. The European Telecommunications Standards Institute\n(ETSI) did come up with the \"ITS-G5\" system. Those Vehicular Ad-hoc Networks\n(VANETs) are the basis for Intelligent Transportation Systems (ITSs). They aim\nto efficiently communicate and provide benefits to people, ranging from\nimproved safety to convenience. But different design and architectural choices\nlead to different network properties, especially security properties that are\nfundamentally depending on the networks architecture. To be able to compare\ndifferent security architectures, different proposed approaches need to be\ndiscussed. One problem in current research is the missing focus on different\napproaches for trust establishment in VANETs. Therefore, this paper surveys\ndifferent security issues and solutions in VANETs and we furthermore categorize\nthese solutions into three basic trust defining architectures: centralized,\ndecentralized and hybrid. These categories represent how trust is build in a\nsystem, i.e., in a centralized, decentralized way or even by combining both\nopposing approaches to a hybrid solution, which aims to inherit the benefits of\nboth worlds. This survey defines those categories and finds that hybrid\napproaches are underrepresented in current research efforts. \n\n"}
{"id": "1509.03843", "contents": "Title: Attack on a classical analogue of the Dunjko, Wallden, Kent and\n  Andersson quantum digital signature protocol Abstract: A quantum digital signature (QDS) protocol is investigated in respect of an\nattacker who can impersonate other communicating principals in the style of\nLowe's attack on the Needham-Schroeder public-key authentication protocol. A\nman-in-the-middle attack is identified in respect of a classical variant of the\nprotocol and it is suggested that a similar attack would be effective against\nthe QDS protocol. The attack has been confirmed through initial protocol\nmodelling using a automated theorem prover, ProVerif. \n\n"}
{"id": "1509.04639", "contents": "Title: Jamming aided Generalized Data Attacks: Exposing Vulnerabilities in\n  Secure Estimation Abstract: Jamming refers to the deletion, corruption or damage of meter measurements\nthat prevents their further usage. This is distinct from adversarial data\ninjection that changes meter readings while preserving their utility in state\nestimation. This paper presents a generalized attack regime that uses jamming\nof secure and insecure measurements to greatly expand the scope of common\n'hidden' and 'detectable' data injection attacks in literature. For 'hidden'\nattacks, it is shown that with jamming, the optimal attack is given by the\nminimum feasible cut in a specific weighted graph. More importantly, for\n'detectable' data attacks, this paper shows that the entire range of relative\ncosts for adversarial jamming and data injection can be divided into three\nseparate regions, with distinct graph-cut based constructions for the optimal\nattack. Approximate algorithms for attack design are developed and their\nperformances are demonstrated by simulations on IEEE test cases. Further, it is\nproved that prevention of such attacks require security of all grid\nmeasurements. This work comprehensively quantifies the dual adversarial\nbenefits of jamming: (a) reduced attack cost and (b) increased resilience to\nsecure measurements, that strengthen the potency of data attacks. \n\n"}
{"id": "1510.00661", "contents": "Title: HTML5 Zero Configuration Covert Channels: Security Risks and Challenges Abstract: In recent months there has been an increase in the popularity and public\nawareness of secure, cloudless file transfer systems. The aim of these services\nis to facilitate the secure transfer of files in a peer-to- peer (P2P) fashion\nover the Internet without the need for centralised authentication or storage.\nThese services can take the form of client installed applications or entirely\nweb browser based interfaces. Due to their P2P nature, there is generally no\nlimit to the file sizes involved or to the volume of data transmitted - and\nwhere these limitations do exist they will be purely reliant on the capacities\nof the systems at either end of the transfer. By default, many of these\nservices provide seamless, end-to-end encryption to their users. The\ncybersecurity and cyberforensic consequences of the potential criminal use of\nsuch services are significant. The ability to easily transfer encrypted data\nover the Internet opens up a range of opportunities for illegal use to\ncybercriminals requiring minimal technical know-how. This paper explores a\nnumber of these services and provides an analysis of the risks they pose to\ncorporate and governmental security. A number of methods for the forensic\ninvestigation of such transfers are discussed. \n\n"}
{"id": "1510.03419", "contents": "Title: Operational Mermin non-locality and All-vs-Nothing arguments Abstract: Contextuality is a key resource in quantum information and the\ndevice-independent security of quantum algorithms. In this work, we show that\nthe recently developed, operational Mermin non-locality arguments provide a\nlarge, novel family of quantum realisable All-vs-Nothing models. In particular,\nthey result in a diverse wealth of quantum realisable models which are\nmaximally contextual (i.e. lie on the faces of the no-signalling polytope with\nno local elements), and could be used as a resource for the security of a new\nclass of quantum secret sharing algorithms. \n\n"}
{"id": "1510.06743", "contents": "Title: Quantum-proof multi-source randomness extractors in the Markov model Abstract: Randomness extractors, widely used in classical and quantum cryptography and\nother fields of computer science, e.g., derandomization, are functions which\ngenerate almost uniform randomness from weak sources of randomness. In the\nquantum setting one must take into account the quantum side information held by\nan adversary which might be used to break the security of the extractor. In the\ncase of seeded extractors the presence of quantum side information has been\nextensively studied. For multi-source extractors one can easily see that high\nconditional min-entropy is not sufficient to guarantee security against\narbitrary side information, even in the classical case. Hence, the interesting\nquestion is under which models of (both quantum and classical) side information\nmulti-source extractors remain secure. In this work we suggest a natural model\nof side information, which we call the Markov model, and prove that any\nmulti-source extractor remains secure in the presence of quantum side\ninformation of this type (albeit with weaker parameters). This improves on\nprevious results in which more restricted models were considered and the\nsecurity of only some types of extractors was shown. \n\n"}
{"id": "1510.07563", "contents": "Title: Practical Attacks Against Privacy and Availability in 4G/LTE Mobile\n  Communication Systems Abstract: Mobile communication systems now constitute an essential part of life\nthroughout the world. Fourth generation \"Long Term Evolution\" (LTE) mobile\ncommunication networks are being deployed. The LTE suite of specifications is\nconsidered to be significantly better than its predecessors not only in terms\nof functionality but also with respect to security and privacy for subscribers.\n  We carefully analyzed LTE access network protocol specifications and\nuncovered several vulnerabilities. Using commercial LTE mobile devices in real\nLTE networks, we demonstrate inexpensive, and practical attacks exploiting\nthese vulnerabilities. Our first class of attacks consists of three different\nways of making an LTE device leak its location: A semi-passive attacker can\nlocate an LTE device within a 2 sq.km area within a city whereas an active\nattacker can precisely locate an LTE device using GPS co-ordinates or\ntrilateration via cell-tower signal strength information. Our second class of\nattacks can persistently deny some or all services to a target LTE device. To\nthe best of our knowledge, our work constitutes the first publicly reported\npractical attacks against LTE access network protocols.\n  We present several countermeasures to resist our specific attacks. We also\ndiscuss possible trade-offs that may explain why these vulnerabilities exist\nand recommend that safety margins introduced into future specifications to\naddress such trade-offs should incorporate greater agility to accommodate\nsubsequent changes in the trade-off equilibrium. \n\n"}
{"id": "1510.08435", "contents": "Title: Private Webmail 2.0: Simple and Easy-to-Use Secure Email Abstract: Private Webmail 2.0 (Pwm 2.0) improves upon the current state of the art by\nincreasing the usability and practical security of secure email for ordinary\nusers. More users are able to send and receive encrypted emails without\nmistakenly revealing sensitive information. In this paper we describe user\ninterface traits that positively affect the usability and security of Pwm 2.0:\n(1) an artificial delay to encryption that enhances user confidence in Pwm 2.0\nwhile simultaneously instructing users on who can read their encrypted\nmessages; (2) a modified composition interface that helps protect users from\nmistakenly sending sensitive information in the clear; (3) an annotated secure\nemail composition interface that instructs users on how to correctly use secure\nemail; and (4) inline, context-sensitive tutorials, which improved view rates\nfor tutorials from less than 10% in earlier systems to over 90% for Pwm 2.0. In\na user study involving 51 participants we validate these interface\nmodifications, and also show that the use of manual encryption has no effect on\nusability or security. \n\n"}
{"id": "1510.08554", "contents": "Title: \"We're on the Same Page\": A Usability Study of Secure Email Using Pairs\n  of Novice Users Abstract: Secure email is increasingly being touted as usable by novice users, with a\npush for adoption based on recent concerns about government surveillance. To\ndetermine whether secure email is for grassroots adoption, we employ a\nlaboratory user study that recruits pairs of novice to install and use several\nof the latest systems to exchange secure messages. We present quantitative and\nqualitative results from 25 pairs of novice users as they use Pwm, Tutanota,\nand Virtru. Participants report being more at ease with this type of study and\nbetter able to cope with mistakes since both participants are \"on the same\npage\". We find that users prefer integrated solutions over depot-based\nsolutions, and that tutorials are important in helping first-time users. Hiding\nthe details of how a secure email system provides security can lead to a lack\nof trust in the system. Participants expressed a desire to use secure email,\nbut few wanted to use it regularly and most were unsure of when they might use\nit. \n\n"}
{"id": "1511.01549", "contents": "Title: Extension of Overbeck's Attack for Gabidulin Based Cryptosystems Abstract: We present a new attack against cryptosystems based on the rank metric. Our\nattack allows us to cryptanalyze two variants of the GPT cryptosystem which\nwere designed to resist the attack of Overbeck. \n\n"}
{"id": "1511.02338", "contents": "Title: Towards Quantum Enigma Cipher II-A protocol based on quantum\n  illumination- Abstract: This research note II introduces a way to understand a basic concept of the\nquantum enigma cipher. The conventional cipher is designed by a mathematical\nalgorithm and its security is evaluated by the complexity of the algorithm in\nsecurity analysis and ability of computers. This kind of cipher can be\ndecrypted with probability one in principle by the Brute force attack in which\nan eavesdropper tries all the possible keys based on the correct ciphertext and\nsome known plaintext. A cipher with quantum effects in physical layer may\nprotect the system from the Brute force attack by means of the quantum no\ncloning theorem and randomizations based on quantum noise effect. The\nrandomizations for the ciphertext which is the output from the mathematical\nencryption box is crucial to realize a quantum enigma cipher. Especially, by\nrandomizations, it is necessary to make a substantial difference in accuracy of\nciphertext in eavesdropper's observation and legitimate user's observation. The\nquantum illumination protocol can make a difference in error performance of the\nlegitimate's receiver and the eavesdropper's receiver. This difference is due\nto differences in ability of the legitimate's receiver with entanglement and\nthe eavesdropper's receiver without entanglement. It is shown in this note that\nthe quantum illumination can be employed as an element of the most simple\nquantum enigma cipher. \n\n"}
{"id": "1511.02513", "contents": "Title: Algorithmic Stability for Adaptive Data Analysis Abstract: Adaptivity is an important feature of data analysis---the choice of questions\nto ask about a dataset often depends on previous interactions with the same\ndataset. However, statistical validity is typically studied in a nonadaptive\nmodel, where all questions are specified before the dataset is drawn. Recent\nwork by Dwork et al. (STOC, 2015) and Hardt and Ullman (FOCS, 2014) initiated\nthe formal study of this problem, and gave the first upper and lower bounds on\nthe achievable generalization error for adaptive data analysis.\n  Specifically, suppose there is an unknown distribution $\\mathbf{P}$ and a set\nof $n$ independent samples $\\mathbf{x}$ is drawn from $\\mathbf{P}$. We seek an\nalgorithm that, given $\\mathbf{x}$ as input, accurately answers a sequence of\nadaptively chosen queries about the unknown distribution $\\mathbf{P}$. How many\nsamples $n$ must we draw from the distribution, as a function of the type of\nqueries, the number of queries, and the desired level of accuracy?\n  In this work we make two new contributions:\n  (i) We give upper bounds on the number of samples $n$ that are needed to\nanswer statistical queries. The bounds improve and simplify the work of Dwork\net al. (STOC, 2015), and have been applied in subsequent work by those authors\n(Science, 2015, NIPS, 2015).\n  (ii) We prove the first upper bounds on the number of samples required to\nanswer more general families of queries. These include arbitrary\nlow-sensitivity queries and an important class of optimization queries.\n  As in Dwork et al., our algorithms are based on a connection with algorithmic\nstability in the form of differential privacy. We extend their work by giving a\nquantitatively optimal, more general, and simpler proof of their main theorem\nthat stability implies low generalization error. We also study weaker stability\nguarantees such as bounded KL divergence and total variation distance. \n\n"}
{"id": "1511.03829", "contents": "Title: Secure Numerical and Logical Multi Party Operations Abstract: We derive algorithms for efficient secure numerical and logical operations\nusing a recently introduced scheme for secure multi-party\ncomputation~\\cite{sch15} in the semi-honest model ensuring statistical or\nperfect security. To derive our algorithms for trigonometric functions, we use\nbasic mathematical laws in combination with properties of the additive\nencryption scheme in a novel way. For division and logarithm we use a new\napproach to compute a Taylor series at a fixed point for all numbers. All our\nlogical operations such as comparisons and large fan-in AND gates are perfectly\nsecure. Our empirical evaluation yields speed-ups of more than a factor of 100\nfor the evaluated operations compared to the state-of-the-art. \n\n"}
{"id": "1511.04594", "contents": "Title: Flush+Flush: A Fast and Stealthy Cache Attack Abstract: Research on cache attacks has shown that CPU caches leak significant\ninformation. Proposed detection mechanisms assume that all cache attacks cause\nmore cache hits and cache misses than benign applications and use hardware\nperformance counters for detection.\n  In this article, we show that this assumption does not hold by developing a\nnovel attack technique: the Flush+Flush attack. The Flush+Flush attack only\nrelies on the execution time of the flush instruction, which depends on whether\ndata is cached or not. Flush+Flush does not make any memory accesses, contrary\nto any other cache attack. Thus, it causes no cache misses at all and the\nnumber of cache hits is reduced to a minimum due to the constant cache flushes.\nTherefore, Flush+Flush attacks are stealthy, i.e., the spy process cannot be\ndetected based on cache hits and misses, or state-of-the-art detection\nmechanisms. The Flush+Flush attack runs in a higher frequency and thus is\nfaster than any existing cache attack. With 496 KB/s in a cross-core covert\nchannel it is 6.7 times faster than any previously published cache covert\nchannel. \n\n"}
{"id": "1511.04631", "contents": "Title: Shortest Paths and Distances with Differential Privacy Abstract: We introduce a model for differentially private analysis of weighted graphs\nin which the graph topology $(V,E)$ is assumed to be public and the private\ninformation consists only of the edge weights $w:E\\to\\mathbb{R}^+$. This can\nexpress hiding congestion patterns in a known system of roads. Differential\nprivacy requires that the output of an algorithm provides little advantage,\nmeasured by privacy parameters $\\epsilon$ and $\\delta$, for distinguishing\nbetween neighboring inputs, which are thought of as inputs that differ on the\ncontribution of one individual. In our model, two weight functions $w,w'$ are\nconsidered to be neighboring if they have $\\ell_1$ distance at most one.\n  We study the problems of privately releasing a short path between a pair of\nvertices and of privately releasing approximate distances between all pairs of\nvertices. We are concerned with the approximation error, the difference between\nthe length of the released path or released distance and the length of the\nshortest path or actual distance.\n  For privately releasing a short path between a pair of vertices, we prove a\nlower bound of $\\Omega(|V|)$ on the additive approximation error for fixed\n$\\epsilon,\\delta$. We provide a differentially private algorithm that matches\nthis error bound up to a logarithmic factor and releases paths between all\npairs of vertices. The approximation error of our algorithm can be bounded by\nthe number of edges on the shortest path, so we achieve better accuracy than\nthe worst-case bound for vertex pairs that are connected by a low-weight path\nwith $o(|V|)$ vertices.\n  For privately releasing all-pairs distances, we show that for trees we can\nrelease all distances with approximation error $O(\\log^{2.5}|V|)$ for fixed\nprivacy parameters. For arbitrary bounded-weight graphs with edge weights in\n$[0,M]$ we can release all distances with approximation error\n$\\tilde{O}(\\sqrt{|V|M})$. \n\n"}
{"id": "1511.05680", "contents": "Title: Wishart Mechanism for Differentially Private Principal Components\n  Analysis Abstract: We propose a new input perturbation mechanism for publishing a covariance\nmatrix to achieve $(\\epsilon,0)$-differential privacy. Our mechanism uses a\nWishart distribution to generate matrix noise. In particular, We apply this\nmechanism to principal component analysis. Our mechanism is able to keep the\npositive semi-definiteness of the published covariance matrix. Thus, our\napproach gives rise to a general publishing framework for input perturbation of\na symmetric positive semidefinite matrix. Moreover, compared with the classic\nLaplace mechanism, our method has better utility guarantee. To the best of our\nknowledge, Wishart mechanism is the best input perturbation approach for\n$(\\epsilon,0)$-differentially private PCA. We also compare our work with\nprevious exponential mechanism algorithms in the literature and provide near\noptimal bound while having more flexibility and less computational\nintractability. \n\n"}
{"id": "1511.07122", "contents": "Title: Multi-Scale Context Aggregation by Dilated Convolutions Abstract: State-of-the-art models for semantic segmentation are based on adaptations of\nconvolutional networks that had originally been designed for image\nclassification. However, dense prediction and image classification are\nstructurally different. In this work, we develop a new convolutional network\nmodule that is specifically designed for dense prediction. The presented module\nuses dilated convolutions to systematically aggregate multi-scale contextual\ninformation without losing resolution. The architecture is based on the fact\nthat dilated convolutions support exponential expansion of the receptive field\nwithout loss of resolution or coverage. We show that the presented context\nmodule increases the accuracy of state-of-the-art semantic segmentation\nsystems. In addition, we examine the adaptation of image classification\nnetworks to dense prediction and show that simplifying the adapted network can\nincrease accuracy. \n\n"}
{"id": "1511.08681", "contents": "Title: Algorithms for Differentially Private Multi-Armed Bandits Abstract: We present differentially private algorithms for the stochastic Multi-Armed\nBandit (MAB) problem. This is a problem for applications such as adaptive\nclinical trials, experiment design, and user-targeted advertising where private\ninformation is connected to individual rewards. Our major contribution is to\nshow that there exist $(\\epsilon, \\delta)$ differentially private variants of\nUpper Confidence Bound algorithms which have optimal regret, $O(\\epsilon^{-1} +\n\\log T)$. This is a significant improvement over previous results, which only\nachieve poly-log regret $O(\\epsilon^{-2} \\log^{2} T)$, because of our use of a\nnovel interval-based mechanism. We also substantially improve the bounds of\nprevious family of algorithms which use a continual release mechanism.\nExperiments clearly validate our theoretical bounds. \n\n"}
{"id": "1512.00327", "contents": "Title: Technical Privacy Metrics: a Systematic Survey Abstract: The goal of privacy metrics is to measure the degree of privacy enjoyed by\nusers in a system and the amount of protection offered by privacy-enhancing\ntechnologies. In this way, privacy metrics contribute to improving user privacy\nin the digital world. The diversity and complexity of privacy metrics in the\nliterature makes an informed choice of metrics challenging. As a result,\ninstead of using existing metrics, new metrics are proposed frequently, and\nprivacy studies are often incomparable. In this survey we alleviate these\nproblems by structuring the landscape of privacy metrics. To this end, we\nexplain and discuss a selection of over eighty privacy metrics and introduce\ncategorizations based on the aspect of privacy they measure, their required\ninputs, and the type of data that needs protection. In addition, we present a\nmethod on how to choose privacy metrics based on nine questions that help\nidentify the right privacy metrics for a given scenario, and highlight topics\nwhere additional work on privacy metrics is needed. Our survey spans multiple\nprivacy domains and can be understood as a general framework for privacy\nmeasurement. \n\n"}
{"id": "1512.00351", "contents": "Title: Authentication Based Solutions to Counterfeiting of Manufactured Goods Abstract: Counterfeiting of manufactured goods is presented as the theft of\nintellectual property, patents, copyright etc. accompanied by identity theft.\nThe purpose of the identity theft is to facilitate the intellectual property\ntheft. Without it the intellectual property theft would be obvious and the\nproducts would be confiscated and destroyed. Authentication solutions, to\nprevent identity theft, were then developed for the two categories of\nmanufactured goods i.e. goods which can be subjected to destructive screening\nstrategies and goods which cannot e.g. pharmaceutical drugs and currencies,\nrespectively. The solutions developed were found to be analogous to digital\nsignatures. Tamper proof packaging on pharmaceutical drugs is analogous to\nencryption because it prevents Mallory from interfering with the product.\nBreaking the tamper proof packaging is a one-way function. Concealed inside the\npackaging a one-time password, which can be used to authenticate the product\nover the internet. The name of the authentication website must be common\nknowledge, just like a public key for authenticating digital signatures.\nOtherwise the counterfeiters will specify their own authentication website.\nThis solution can be altered for currencies i.e. the one-way function,\nequivalent to opening the tamper proof packaging, becomes the method of\nmanufacture of the currency. \n\n"}
{"id": "1512.02240", "contents": "Title: Causal Boxes: Quantum Information-Processing Systems Closed under\n  Composition Abstract: Complex information-processing systems, for example quantum circuits,\ncryptographic protocols, or multi-player games, are naturally described as\nnetworks composed of more basic information-processing systems. A modular\nanalysis of such systems requires a mathematical model of systems that is\nclosed under composition, i.e., a network of these objects is again an object\nof the same type. We propose such a model and call the corresponding systems\ncausal boxes.\n  Causal boxes capture superpositions of causal structures, e.g., messages sent\nby a causal box A can be in a superposition of different orders or in a\nsuperposition of being sent to box B and box C. Furthermore, causal boxes can\nmodel systems whose behavior depends on time. By instantiating the Abstract\nCryptography framework with causal boxes, we obtain the first composable\nsecurity framework that can handle arbitrary quantum protocols and relativistic\nprotocols. \n\n"}
{"id": "1512.07331", "contents": "Title: Plug-and-Play Priors for Bright Field Electron Tomography and Sparse\n  Interpolation Abstract: Many material and biological samples in scientific imaging are characterized\nby non-local repeating structures. These are studied using scanning electron\nmicroscopy and electron tomography. Sparse sampling of individual pixels in a\n2D image acquisition geometry, or sparse sampling of projection images with\nlarge tilt increments in a tomography experiment, can enable high speed data\nacquisition and minimize sample damage caused by the electron beam.\n  In this paper, we present an algorithm for electron tomographic\nreconstruction and sparse image interpolation that exploits the non-local\nredundancy in images. We adapt a framework, termed plug-and-play (P&P) priors,\nto solve these imaging problems in a regularized inversion setting. The power\nof the P&P approach is that it allows a wide array of modern denoising\nalgorithms to be used as a \"prior model\" for tomography and image\ninterpolation. We also present sufficient mathematical conditions that ensure\nconvergence of the P&P approach, and we use these insights to design a new\nnon-local means denoising algorithm. Finally, we demonstrate that the algorithm\nproduces higher quality reconstructions on both simulated and real electron\nmicroscope data, along with improved convergence properties compared to other\nmethods. \n\n"}
{"id": "1512.07438", "contents": "Title: Unified Description for Network Information Hiding Methods Abstract: Until now hiding methods in network steganography have been described in\narbitrary ways, making them difficult to compare. For instance, some\npublications describe classical channel characteristics, such as robustness and\nbandwidth, while others describe the embedding of hidden information. We\nintroduce the first unified description of hiding methods in network\nsteganography. Our description method is based on a comprehensive analysis of\nthe existing publications in the domain. When our description method is applied\nby the research community, future publications will be easier to categorize,\ncompare and extend. Our method can also serve as a basis to evaluate the\nnovelty of hiding methods proposed in the future. \n\n"}
{"id": "1601.00082", "contents": "Title: A wireless physically secure key distribution system Abstract: A secure key distribution protocol protected by light's noise was introduced\nin 2003 [Phys. Rev. A 68, 052307 (2003)]. That protocol utilized the shot noise\nof light present in the optical channel (eg., an optical fiber) to restrict\ninformation leaks to an adversary. An initial shared information between the\nlegitimate users allowed them to extract more information from the channel than\nthe one obtained by the adversary. That original paper recognized the need for\na privacy amplification step but no specific protocol was presented. More\nrecently that original idea was improved with a specific privacy amplification\nprotocol [arXiv:1406.1543v2 [cs.CR] 8 Jul 2015] while keeping the use of an\noptical communication channel. This work merges main ideas of the protection\ngiven by the light's noise in a protocol applied to wireless channels. The use\nof a wireless channels together with recorded physical noise was introduced\nfrom 2005 to 2007 (see eg, arXiv:quant-ph/0510011 v2 16 Nov 2005 and\narXiv:0705.2243v2 [quant-ph] 17 May 2007). This work improves those embrionary\nideas of wireless channels secured by recorded optical noise. The need for\nspecific optical channels is eliminated with the wireless variation and opens\nup the possibility to apply the technique to mobile devices. This work\nintroduces this new scheme and calculates the associated security level. \n\n"}
{"id": "1601.02298", "contents": "Title: How to Incentivize Data-Driven Collaboration Among Competing Parties Abstract: The availability of vast amounts of data is changing how we can make medical\ndiscoveries, predict global market trends, save energy, and develop educational\nstrategies. In some settings such as Genome Wide Association Studies or deep\nlearning, sheer size of data seems critical. When data is held distributedly by\nmany parties, they must share it to reap its full benefits.\n  One obstacle to this revolution is the lack of willingness of different\nparties to share data, due to reasons such as loss of privacy or competitive\nedge. Cryptographic works address privacy aspects, but shed no light on\nindividual parties' losses/gains when access to data carries tangible rewards.\nEven if it is clear that better overall conclusions can be drawn from\ncollaboration, are individual collaborators better off by collaborating?\nAddressing this question is the topic of this paper.\n  * We formalize a model of n-party collaboration for computing functions over\nprivate inputs in which participants receive their outputs in sequence, and the\norder depends on their private inputs. Each output \"improves\" on preceding\noutputs according to a score function.\n  * We say a mechanism for collaboration achieves collaborative equilibrium if\nit ensures higher reward for all participants when collaborating (rather than\nworking alone). We show that in general, computing a collaborative equilibrium\nis NP-complete, yet we design efficient algorithms to compute it in a range of\nnatural model settings.\n  Our collaboration mechanisms are in the standard model, and thus require a\ncentral trusted party; however, we show this assumption is unnecessary under\nstandard cryptographic assumptions. We show how to implement the mechanisms in\na decentralized way with new extensions of secure multiparty computation that\nimpose order/timing constraints on output delivery to different players, as\nwell as privacy and correctness. \n\n"}
{"id": "1601.05187", "contents": "Title: Dynamic Intransitive Noninterference Revisited Abstract: The paper studies dynamic information flow security policies in an\nautomaton-based model. Two semantic interpretations of such policies are\ndeveloped, both of which generalize the notion of TA-security [van der Meyden\nESORICS 2007] for static intransitive noninterference policies. One of the\ninterpretations focuses on information flows permitted by policy edges, the\nother focuses on prohibitions implied by absence of policy edges. In general,\nthe two interpretations differ, but necessary and sufficient conditions are\nidentified for the two interpretations to be equivalent. Sound and complete\nproof techniques are developed for both interpretations. Two applications of\nthe theory are presented. The first is a general result showing that access\ncontrol mechanisms are able to enforce a dynamic information flow policy. The\nsecond is a simple capability system motivated by the Flume operating system. \n\n"}
{"id": "1601.06454", "contents": "Title: Private Processing of Outsourced Network Functions: Feasibility and\n  Constructions Abstract: Aiming to reduce the cost and complexity of maintaining networking\ninfrastructures, organizations are increasingly outsourcing their network\nfunctions (e.g., firewalls, traffic shapers and intrusion detection systems) to\nthe cloud, and a number of industrial players have started to offer network\nfunction virtualization (NFV)-based solutions. Alas, outsourcing network\nfunctions in its current setting implies that sensitive network policies, such\nas firewall rules, are revealed to the cloud provider. In this paper, we\ninvestigate the use of cryptographic primitives for processing outsourced\nnetwork functions, so that the provider does not learn any sensitive\ninformation. More specifically, we present a cryptographic treatment of\nprivacy-preserving outsourcing of network functions, introducing security\ndefinitions as well as an abstract model of generic network functions, and then\npropose a few instantiations using partial homomorphic encryption and\npublic-key encryption with keyword search. We include a proof-of-concept\nimplementation of our constructions and show that network functions can be\nprivately processed by an untrusted cloud provider in a few milliseconds. \n\n"}
{"id": "1601.06502", "contents": "Title: Elliptic Curve Multiset Hash Abstract: A homomorphic, or incremental, multiset hash function, associates a hash\nvalue to arbitrary collections of objects (with possible repetitions) in such a\nway that the hash of the union of two collections is easy to compute from the\nhashes of the two collections themselves: it is simply their sum under a\nsuitable group operation. In particular, hash values of large collections can\nbe computed incrementally and/or in parallel. Homomorphic hashing is thus a\nvery useful primitive with applications ranging from database integrity\nverification to streaming set/multiset comparison and network coding.\n  Unfortunately, constructions of homomorphic hash functions in the literature\nare hampered by two main drawbacks: they tend to be much longer than usual hash\nfunctions at the same security level (e.g. to achieve a collision resistance of\n2^128, they are several thousand bits long, as opposed to 256 bits for usual\nhash functions), and they are also quite slow.\n  In this paper, we introduce the Elliptic Curve Multiset Hash (ECMH), which\ncombines a usual bit string-valued hash function like BLAKE2 with an efficient\nencoding into binary elliptic curves to overcome both difficulties. On the one\nhand, the size of ECMH digests is essentially optimal: 2m-bit hash values\nprovide O(2^m) collision resistance. On the other hand, we demonstrate a\nhighly-efficient software implementation of ECMH, which our thorough empirical\nevaluation shows to be capable of processing over 3 million set elements per\nsecond on a 4 GHz Intel Haswell machine at the 128-bit security level---many\ntimes faster than previous practical methods. \n\n"}
{"id": "1601.06562", "contents": "Title: Secure Computation of Randomized Functions Abstract: Two user secure computation of randomized functions is considered, where only\none user computes the output. Both the users are semi-honest; and computation\nis such that no user learns any additional information about the other user's\ninput and output other than what cannot be inferred from its own input and\noutput. First we consider a scenario, where privacy conditions are against both\nthe users. In perfect security setting Kilian [STOC 2000] gave a\ncharacterization of securely computable randomized functions, and we provide\nrate-optimal protocols for such functions. We prove that the same\ncharacterization holds in asymptotic security setting as well and give a\nrate-optimal protocol. In another scenario, where privacy condition is only\nagainst the user who is not computing the function, we provide rate-optimal\nprotocols. For perfect security in both the scenarios, our results are in terms\nof chromatic entropies of different graphs. In asymptotic security setting, we\nget single-letter expressions of rates in both the scenarios. \n\n"}
{"id": "1602.01771", "contents": "Title: On Quantum Obfuscation Abstract: Encryption of data is fundamental to secure communication in the modern\nworld. Beyond encryption of data lies obfuscation, i.e., encryption of\nfunctionality. It is well-known that the most powerful means of obfuscating\nclassical programs, so-called ``black-box obfuscation',' is provably impossible\n[Barak et al '12]. However, several recent results have yielded candidate\nschemes that satisfy a definition weaker than black-box, and yet still have\nnumerous applications.\n  In this work, we initialize the rigorous study of obfuscating programs via\nquantum-mechanical means. We define notions of quantum obfuscation which\nencompass several natural variants. The input to the obfuscator can describe\nclassical or quantum functionality, and the output can be a circuit description\nor a quantum state. The obfuscator can also satisfy one of a number of\nobfuscation conditions: black-box, information-theoretic black-box,\nindistinguishability, and best possible; the last two conditions come in three\nvariants: perfect, statistical, and computational. We discuss many\napplications, including CPA-secure quantum encryption, quantum\nfully-homomorphic encryption, and public-key quantum money.\n  We then prove several impossibility results, extending a number of\nfoundational papers on classical obfuscation to the quantum setting. We prove\nthat quantum black-box obfuscation is impossible in a setting where adversaries\ncan possess more than one output of the obfuscator. In particular, generic\ntransformation of quantum circuits into black-box-obfuscated quantum circuits\nis impossible. We also show that statistical indistinguishability obfuscation\nis impossible, up to an unlikely complexity-theoretic collapse. Our proofs\ninvolve a new tool: chosen-ciphertext-secure encryption of quantum data, which\nwas recently shown to be possible assuming quantum-secure one-way functions\nexist [Alagic et al '16]. \n\n"}
{"id": "1602.02046", "contents": "Title: MyAdChoices: Bringing Transparency and Control to Online Advertising Abstract: The intrusiveness and the increasing invasiveness of online advertising have,\nin the last few years, raised serious concerns regarding user privacy and Web\nusability. As a reaction to these concerns, we have witnessed the emergence of\na myriad of ad-blocking and anti-tracking tools, whose aim is to return control\nto users over advertising. The problem with these technologies, however, is\nthat they are extremely limited and radical in their approach: users can only\nchoose either to block or allow all ads. With around 200 million people\nregularly using these tools, the economic model of the Web ---in which users\nget content free in return for allowing advertisers to show them ads--- is at\nserious peril. In this paper, we propose a smart Web technology that aims at\nbringing transparency to online advertising, so that users can make an informed\nand equitable decision regarding ad blocking. The proposed technology is\nimplemented as a Web-browser extension and enables users to exert fine-grained\ncontrol over advertising, thus providing them with certain guarantees in terms\nof privacy and browsing experience, while preserving the Internet economic\nmodel. Experimental results in a real environment demonstrate the suitability\nand feasibility of our approach, and provide preliminary findings on behavioral\ntargeting from real user browsing profiles. \n\n"}
{"id": "1602.02452", "contents": "Title: Privacy Preserving Architectures for Collaborative Intrusion Detection Abstract: Collaboration among multiple organizations is imperative for contemporary\nintrusion detection. As modern threats become well sophisticated it is\ndifficult for organizations to defend with threat context local to their\nnetworks alone. Availability of global \\emph{threat intelligence} is must for\norganizations to defend against modern advanced persistent threats (APTs). In\norder to benefit from such global context of attacks, privacy concerns continue\nto be of major hindrance. In this position paper we identify real world privacy\nproblems as precise use cases, relevant cryptographic technologies and discuss\nprivacy preserving architectures for collaborative intrusion detection. \n\n"}
{"id": "1602.02697", "contents": "Title: Practical Black-Box Attacks against Machine Learning Abstract: Machine learning (ML) models, e.g., deep neural networks (DNNs), are\nvulnerable to adversarial examples: malicious inputs modified to yield\nerroneous model outputs, while appearing unmodified to human observers.\nPotential attacks include having malicious content like malware identified as\nlegitimate or controlling vehicle behavior. Yet, all existing adversarial\nexample attacks require knowledge of either the model internals or its training\ndata. We introduce the first practical demonstration of an attacker controlling\na remotely hosted DNN with no such knowledge. Indeed, the only capability of\nour black-box adversary is to observe labels given by the DNN to chosen inputs.\nOur attack strategy consists in training a local model to substitute for the\ntarget DNN, using inputs synthetically generated by an adversary and labeled by\nthe target DNN. We use the local substitute to craft adversarial examples, and\nfind that they are misclassified by the targeted DNN. To perform a real-world\nand properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online\ndeep learning API. We find that their DNN misclassifies 84.24% of the\nadversarial examples crafted with our substitute. We demonstrate the general\napplicability of our strategy to many ML techniques by conducting the same\nattack against models hosted by Amazon and Google, using logistic regression\nsubstitutes. They yield adversarial examples misclassified by Amazon and Google\nat rates of 96.19% and 88.94%. We also find that this black-box attack strategy\nis capable of evading defense strategies previously found to make adversarial\nexample crafting harder. \n\n"}
{"id": "1602.04056", "contents": "Title: Control-Flow Integrity: Precision, Security, and Performance Abstract: Memory corruption errors in C/C++ programs remain the most common source of\nsecurity vulnerabilities in today's systems. Control-flow hijacking attacks\nexploit memory corruption vulnerabilities to divert program execution away from\nthe intended control flow. Researchers have spent more than a decade studying\nand refining defenses based on Control-Flow Integrity (CFI), and this technique\nis now integrated into several production compilers. However, so far no study\nhas systematically compared the various proposed CFI mechanisms, nor is there\nany protocol on how to compare such mechanisms.\n  We compare a broad range of CFI mechanisms using a unified nomenclature based\non (i) a qualitative discussion of the conceptual security guarantees, (ii) a\nquantitative security evaluation, and (iii) an empirical evaluation of their\nperformance in the same test environment. For each mechanism, we evaluate (i)\nprotected types of control-flow transfers, (ii) the precision of the protection\nfor forward and backward edges. For open-source compiler-based implementations,\nwe additionally evaluate (iii) the generated equivalence classes and target\nsets, and (iv) the runtime performance. \n\n"}
{"id": "1602.04115", "contents": "Title: TouchSignatures: Identification of User Touch Actions and PINs Based on\n  Mobile Sensor Data via JavaScript Abstract: Conforming to W3C specifications, mobile web browsers allow JavaScript code\nin a web page to access motion and orientation sensor data without the user's\npermission. The associated risks to user security and privacy are however not\nconsidered in W3C specifications. In this work, for the first time, we show how\nuser security can be compromised using these sensor data via browser, despite\nthat the data rate is 3 to 5 times slower than what is available in app. We\nexamine multiple popular browsers on Android and iOS platforms and study their\npolicies in granting permissions to JavaScript code with respect to access to\nmotion and orientation sensor data. Based on our observations, we identify\nmultiple vulnerabilities, and propose TouchSignatures which implements an\nattack where malicious JavaScript code on an attack tab listens to such sensor\ndata measurements. Based on these streams, TouchSignatures is able to\ndistinguish the user's touch actions (i.e., tap, scroll, hold, and zoom) and\nher PINs, allowing a remote website to learn the client-side user activities.\nWe demonstrate the practicality of this attack by collecting data from real\nusers and reporting high success rates using our proof-of-concept\nimplementations. We also present a set of potential solutions to address the\nvulnerabilities. The W3C community and major mobile browser vendors including\nMozilla, Google, Apple and Opera have acknowledge our work and are implementing\nsome of our proposed countermeasures. \n\n"}
{"id": "1602.05973", "contents": "Title: Breaking Symmetric Cryptosystems using Quantum Period Finding Abstract: Due to Shor's algorithm, quantum computers are a severe threat for public key\ncryptography. This motivated the cryptographic community to search for\nquantum-safe solutions. On the other hand, the impact of quantum computing on\nsecret key cryptography is much less understood. In this paper, we consider\nattacks where an adversary can query an oracle implementing a cryptographic\nprimitive in a quantum superposition of different states. This model gives a\nlot of power to the adversary, but recent results show that it is nonetheless\npossible to build secure cryptosystems in it.\n  We study applications of a quantum procedure called Simon's algorithm (the\nsimplest quantum period finding algorithm) in order to attack symmetric\ncryptosystems in this model. Following previous works in this direction, we\nshow that several classical attacks based on finding collisions can be\ndramatically sped up using Simon's algorithm: finding a collision requires\n$\\Omega(2^{n/2})$ queries in the classical setting, but when collisions happen\nwith some hidden periodicity, they can be found with only $O(n)$ queries in the\nquantum model.\n  We obtain attacks with very strong implications. First, we show that the most\nwidely used modes of operation for authentication and authenticated encryption\ne.g. CBC-MAC, PMAC, GMAC, GCM, and OCB) are completely broken in this security\nmodel. Our attacks are also applicable to many CAESAR candidates: CLOC, AEZ,\nCOPA, OTR, POET, OMD, and Minalpher. This is quite surprising compared to the\nsituation with encryption modes: Anand et al. show that standard modes are\nsecure with a quantum-secure PRF.\n  Second, we show that Simon's algorithm can also be applied to slide attacks,\nleading to an exponential speed-up of a classical symmetric cryptanalysis\ntechnique in the quantum model. \n\n"}
{"id": "1603.00182", "contents": "Title: Protecting suppliers' private information: the case of stock levels and\n  the impact of correlated items Abstract: A marketplace is defined where the private data of suppliers (e.g.,\nprosumers) are protected, so that neither their identity nor their level of\nstock is made known to end customers, while they can sell their products at a\nreduced price. A broker acts as an intermediary, which takes care of providing\nthe items missing to meet the customers' demand and allows end customers to\ntake advantages of reduced prices through the subscription of option contracts.\nFormulas are provided for the option price under three different probability\nmodels for the availability of items. Option pricing allows the broker to\npartially transfer its risk on end customers. \n\n"}
{"id": "1603.01315", "contents": "Title: Ecology-Based DoS Attack in Cognitive Radio Networks Abstract: Cognitive radio technology, which is designed to enhance spectrum\nutilization, depends on the success of opportunistic access, where secondary\nusers (SUs) exploit spectrum void unoccupied by primary users (PUs) for\ntransmissions. We note that the system behaviors are very similar to the\ninteractions among different species coexisting in an ecosystem. However, SUs\nof a selfish nature or of misleading information may make concurrent\ntransmissions with PUs for additional incentives, and thus disrupt the entire\necosystem. By exploiting this vulnerability, this paper proposes a novel\ndistributed denial-of-service (DoS) attack where invasive species, i.e.,\nmalicious users (MUs), induce originally normal-behaved SUs to execute\nconcurrent transmissions with PUs and thus collapse the cognitive radio\nnetwork. We adopt stochastic geometry to model the spatial distributions of\nPUs, SUs, and MUs for the analysis of the mutual interference among them. The\naccess strategy of each SU in the spectrum sharing ecosystem, which evolves\nwith the experienced payoffs and interference, is modeled by an evolutionary\ngame. Based on the evolutionary stable strategy concept, we could efficiently\nidentify the fragile operating region at which normal-behaved SUs are\neventually evolved to conduct concurrent transmissions and thus to cause the\nruin of the network. \n\n"}
{"id": "1603.03501", "contents": "Title: AccConF: An Access Control Framework for Leveraging In-Network Cached\n  Data in ICNs Abstract: The fast-growing Internet traffic is increasingly becoming content-based and\ndriven by mobile users, with users more interested in data rather than its\nsource. This has precipitated the need for an information-centric Internet\narchitecture. Research in information-centric networks (ICNs) have resulted in\nnovel architectures, e.g., CCN/NDN, DONA, and PSIRP/PURSUIT; all agree on named\ndata based addressing and pervasive caching as integral design components. With\nnetwork-wide content caching, enforcement of content access control policies\nbecome non-trivial. Each caching node in the network needs to enforce access\ncontrol policies with the help of the content provider. This becomes\ninefficient and prone to unbounded latencies especially during provider\noutages.\n  In this paper, we propose an efficient access control framework for ICN,\nwhich allows legitimate users to access and use the cached content directly,\nand does not require verification/authentication by an online provider\nauthentication server or the content serving router. This framework would help\nreduce the impact of system down-time from server outages and reduce delivery\nlatency by leveraging caching while guaranteeing access only to legitimate\nusers. Experimental/simulation results demonstrate the suitability of this\nscheme for all users, but particularly for mobile users, especially in terms of\nthe security and latency overheads. \n\n"}
{"id": "1603.03977", "contents": "Title: Pufferfish Privacy Mechanisms for Correlated Data Abstract: Many modern databases include personal and sensitive correlated data, such as\nprivate information on users connected together in a social network, and\nmeasurements of physical activity of single subjects across time. However,\ndifferential privacy, the current gold standard in data privacy, does not\nadequately address privacy issues in this kind of data.\n  This work looks at a recent generalization of differential privacy, called\nPufferfish, that can be used to address privacy in correlated data. The main\nchallenge in applying Pufferfish is a lack of suitable mechanisms. We provide\nthe first mechanism -- the Wasserstein Mechanism -- which applies to any\ngeneral Pufferfish framework. Since this mechanism may be computationally\ninefficient, we provide an additional mechanism that applies to some practical\ncases such as physical activity measurements across time, and is\ncomputationally efficient. Our experimental evaluations indicate that this\nmechanism provides privacy and utility for synthetic as well as real data in\ntwo separate domains. \n\n"}
{"id": "1603.06028", "contents": "Title: A Survey of Stealth Malware: Attacks, Mitigation Measures, and Steps\n  Toward Autonomous Open World Solutions Abstract: As our professional, social, and financial existences become increasingly\ndigitized and as our government, healthcare, and military infrastructures rely\nmore on computer technologies, they present larger and more lucrative targets\nfor malware. Stealth malware in particular poses an increased threat because it\nis specifically designed to evade detection mechanisms, spreading dormant, in\nthe wild for extended periods of time, gathering sensitive information or\npositioning itself for a high-impact zero-day attack. Policing the growing\nattack surface requires the development of efficient anti-malware solutions\nwith improved generalization to detect novel types of malware and resolve these\noccurrences with as little burden on human experts as possible. In this paper,\nwe survey malicious stealth technologies as well as existing solutions for\ndetecting and categorizing these countermeasures autonomously. While machine\nlearning offers promising potential for increasingly autonomous solutions with\nimproved generalization to new malware types, both at the network level and at\nthe host level, our findings suggest that several flawed assumptions inherent\nto most recognition algorithms prevent a direct mapping between the stealth\nmalware recognition problem and a machine learning solution. The most notable\nof these flawed assumptions is the closed world assumption: that no sample\nbelonging to a class outside of a static training set will appear at query\ntime. We present a formalized adaptive open world framework for stealth malware\nrecognition and relate it mathematically to research from other machine\nlearning domains. \n\n"}
{"id": "1603.06133", "contents": "Title: An Observation About Passphrases: Syntax vs Entropy Abstract: On the premise that we are using passwords composed of multiple English\nwords, we argue that using syntactically correct passphrases has no significant\nimpact on the security in comparison to randomly arranged collections of words.\nWe only analyze the contribution of the syntax itself. A comparison to the\nother kinds of passwords is out of the scope. \n\n"}
{"id": "1603.06870", "contents": "Title: The Value of Privacy: Strategic Data Subjects, Incentive Mechanisms and\n  Fundamental Limits Abstract: We study the value of data privacy in a game-theoretic model of trading\nprivate data, where a data collector purchases private data from strategic data\nsubjects (individuals) through an incentive mechanism. The private data of each\nindividual represents her knowledge about an underlying state, which is the\ninformation that the data collector desires to learn. Different from most of\nthe existing work on privacy-aware surveys, our model does not assume the data\ncollector to be trustworthy. Then, an individual takes full control of its own\ndata privacy and reports only a privacy-preserving version of her data.\n  In this paper, the value of $\\epsilon$ units of privacy is measured by the\nminimum payment of all nonnegative payment mechanisms, under which an\nindividual's best response at a Nash equilibrium is to report the data with a\nprivacy level of $\\epsilon$. The higher $\\epsilon$ is, the less private the\nreported data is. We derive lower and upper bounds on the value of privacy\nwhich are asymptotically tight as the number of data subjects becomes large.\nSpecifically, the lower bound assures that it is impossible to use less amount\nof payment to buy $\\epsilon$ units of privacy, and the upper bound is given by\nan achievable payment mechanism that we designed. Based on these fundamental\nlimits, we further derive lower and upper bounds on the minimum total payment\nfor the data collector to achieve a given learning accuracy target, and show\nthat the total payment of the designed mechanism is at most one individual's\npayment away from the minimum. \n\n"}
{"id": "1603.09717", "contents": "Title: Quantum homomorphic encryption for polynomial-sized circuits Abstract: We present a new scheme for quantum homomorphic encryption which is compact\nand allows for efficient evaluation of arbitrary polynomial-sized quantum\ncircuits. Building on the framework of Broadbent and Jeffery and recent results\nin the area of instantaneous non-local quantum computation, we show how to\nconstruct quantum gadgets that allow perfect correction of the errors which\noccur during the homomorphic evaluation of T gates on encrypted quantum data.\nOur scheme can be based on any classical (leveled) fully homomorphic encryption\n(FHE) scheme and requires no computational assumptions besides those already\nused by the classical scheme. The size of our quantum gadget depends on the\nspace complexity of the classical decryption function -- which aligns well with\nthe current efforts to minimize the complexity of the decryption function.\n  Our scheme (or slight variants of it) offers a number of additional\nadvantages such as ideal compactness, the ability to supply gadgets \"on\ndemand\", circuit privacy for the evaluator against passive adversaries, and a\nthree-round scheme for blind delegated quantum computation which puts only very\nlimited demands on the quantum abilities of the client. \n\n"}
{"id": "1604.00273", "contents": "Title: Demonstrating topoS: Theorem-Prover-Based Synthesis of Secure Network\n  Configurations Abstract: In network management, when it comes to security breaches, human error\nconstitutes a dominant factor. We present our tool topoS which automatically\nsynthesizes low-level network configurations from high-level security goals.\nThe automation and a feedback loop help to prevent human errors. Except for a\nlast serialization step, topoS is formally verified with Isabelle/HOL, which\nprevents implementation errors. In a case study, we demonstrate topoS by\nexample. For the first time, the complete transition from high-level security\ngoals to both firewall and SDN configurations is presented. \n\n"}
{"id": "1604.01586", "contents": "Title: Blind quantum computing with two almost identical states Abstract: The question of whether a fully classical client can delegate a quantum\ncomputation to an untrusted quantum server while fully maintaining privacy\n(blindness) is one of the big open questions in quantum cryptography. Both yes\nand no answers have important practical and theoretical consequences, and the\nquestion seems genuinely hard. The state-of-the-art approaches to securely\ndelegating quantum computation, without exception, rely on granting the client\nmodest quantum powers, or on additional, non-communicating, quantum servers. In\nthis work, we consider the single server setting, and push the boundaries of\nthe minimal devices of the client, which still allow for blind quantum\ncomputation. Our approach is based on the observation that, in many blind\nquantum computing protocols, the \"quantum\" part of the protocol, from the\nclients perspective, boils down to the establishing classical-quantum\ncorrelations (independent from the computation) between the client and the\nserver, following which the steering of the computation itself requires only\nclassical communication. Here, we abstract this initial preparation phase,\nspecifically for the Universal Blind Quantum Computation protocol of Broadbent,\nFitzsimons and Kashefi. We identify sufficient criteria on the powers of the\nclient, which still allow for secure blind quantum computation. We work in a\nuniversally composable framework, and provide a series of protocols, where each\nstep reduces the number of differing states the client needs to be able to\nprepare. As the limit of such reductions, we show that the capacity to prepare\njust two pure states, which have an arbitrarily high overlap (thus are\narbitrarily close to identical), suffices for efficient and secure blind\nquantum computation. \n\n"}
{"id": "1604.02380", "contents": "Title: Group secret key agreement over state-dependent wireless broadcast\n  channels Abstract: We consider a group of $m$ trusted and authenticated nodes that aim to create\na shared secret key $K$ over a wireless channel in the presence of an\neavesdropper Eve. We assume that there exists a state dependent wireless\nbroadcast channel from one of the honest nodes to the rest of them including\nEve. All of the trusted nodes can also discuss over a cost-free, noiseless and\nunlimited rate public channel which is also overheard by Eve. For this setup,\nwe develop an information-theoretically secure secret key agreement protocol.\nWe show the optimality of this protocol for \"linear deterministic\" wireless\nbroadcast channels. This model generalizes the packet erasure model studied in\nliterature for wireless broadcast channels. For \"state-dependent Gaussian\"\nwireless broadcast channels, we propose an achievability scheme based on a\nmulti-layer wiretap code. Finding the best achievable secret key generation\nrate leads to solving a non-convex power allocation problem. We show that using\na dynamic programming algorithm, one can obtain the best power allocation for\nthis problem. Moreover, we prove the optimality of the proposed achievability\nscheme for the regime of high-SNR and large-dynamic range over the channel\nstates in the (generalized) degrees of freedom sense. \n\n"}
{"id": "1604.05180", "contents": "Title: Cryptographically secure multiparty evaluation of system reliability Abstract: The precise design of a system may be considered a trade secret which should\nbe protected, whilst at the same time component manufacturers are sometimes\nreluctant to release full test data (perhaps only providing mean time to\nfailure data). In this situation it seems impractical to both produce an\naccurate reliability assessment and satisfy all parties' privacy requirements.\nHowever, we present recent developments in cryptography which, when combined\nwith the recently developed survival signature in reliability theory, allows\nalmost total privacy to be maintained in a cryptographically strong manner in\nprecisely this setting. Thus, the system designer does not have to reveal their\ntrade secret design and the component manufacturer can retain component test\ndata in-house. \n\n"}
{"id": "1605.00677", "contents": "Title: Security and Privacy Aspects in MapReduce on Clouds: A Survey Abstract: MapReduce is a programming system for distributed processing large-scale data\nin an efficient and fault tolerant manner on a private, public, or hybrid\ncloud. MapReduce is extensively used daily around the world as an efficient\ndistributed computation tool for a large class of problems, e.g., search,\nclustering, log analysis, different types of join operations, matrix\nmultiplication, pattern matching, and analysis of social networks. Security and\nprivacy of data and MapReduce computations are essential concerns when a\nMapReduce computation is executed in public or hybrid clouds. In order to\nexecute a MapReduce job in public and hybrid clouds, authentication of\nmappers-reducers, confidentiality of data-computations, integrity of\ndata-computations, and correctness-freshness of the outputs are required.\nSatisfying these requirements shield the operation from several types of\nattacks on data and MapReduce computations. In this paper, we investigate and\ndiscuss security and privacy challenges and requirements, considering a variety\nof adversarial capabilities, and characteristics in the scope of MapReduce. We\nalso provide a review of existing security and privacy protocols for MapReduce\nand discuss their overhead issues. \n\n"}
{"id": "1605.00987", "contents": "Title: A practical attack to Bouftass's cryptosystem Abstract: Recently, a new fast public key exchange protocol was presented by S.\nBouftass. The protocol is based on the difficulty of inverting the function\n$F(x)=\\lfloor (zx \\mod 2^p)/ 2^q \\rfloor$. In this paper, we describe a\npractical attack against this protocol based on Closest Vector Problem (CVP)\nand Gaussian lattice reduction. \n\n"}
{"id": "1605.02062", "contents": "Title: Attack Resilience and Recovery using Physical Challenge Response\n  Authentication for Active Sensors Under Integrity Attacks Abstract: Embedded sensing systems are pervasively used in life- and security-critical\nsystems such as those found in airplanes, automobiles, and healthcare.\nTraditional security mechanisms for these sensors focus on data encryption and\nother post-processing techniques, but the sensors themselves often remain\nvulnerable to attacks in the physical/analog domain. If an adversary\nmanipulates a physical/analog signal prior to digitization, no amount of\ndigital security mechanisms after the fact can help. Fortunately, nature\nimposes fundamental constraints on how these analog signals can behave. This\nwork presents PyCRA, a physical challenge-response authentication scheme\ndesigned to protect active sensing systems against physical attacks occurring\nin the analog domain. PyCRA provides security for active sensors by continually\nchallenging the surrounding environment via random but deliberate physical\nprobes. By analyzing the responses to these probes, and by using the fact that\nthe adversary cannot change the underlying laws of physics, we provide an\nauthentication mechanism that not only detects malicious attacks but provides\nresilience against them. We demonstrate the effectiveness of PyCRA through\nseveral case studies using two sensing systems: (1) magnetic sensors like those\nfound wheel speed sensors in robotics and automotive, and (2) commercial RFID\ntags used in many security-critical applications. Finally, we outline methods\nand theoretical proofs for further enhancing the resilience of PyCRA to active\nattacks by means of a confusion phase---a period of low signal to noise ratio\nthat makes it more difficult for an attacker to correctly identify and respond\nto PyCRA's physical challenges. In doing so, we evaluate both the robustness\nand the limitations of PyCRA, concluding by outlining practical considerations\nas well as further applications for the proposed authentication mechanism. \n\n"}
{"id": "1605.02646", "contents": "Title: Information Theoretically Secure Databases Abstract: We introduce the notion of a database system that is information\ntheoretically \"Secure In Between Accesses\"--a database system with the\nproperties that 1) users can efficiently access their data, and 2) while a user\nis not accessing their data, the user's information is information\ntheoretically secure to malicious agents, provided that certain requirements on\nthe maintenance of the database are realized. We stress that the security\nguarantee is information theoretic and everlasting: it relies neither on\nunproved hardness assumptions, nor on the assumption that the adversary is\ncomputationally or storage bounded.\n  We propose a realization of such a database system and prove that a user's\nstored information, in between times when it is being legitimately accessed, is\ninformation theoretically secure both to adversaries who interact with the\ndatabase in the prescribed manner, as well as to adversaries who have installed\na virus that has access to the entire database and communicates with the\nadversary.\n  The central idea behind our design is the construction of a \"re-randomizing\ndatabase\" that periodically changes the internal representation of the\ninformation that is being stored. To ensure security, these remappings of the\nrepresentation of the data must be made sufficiently often in comparison to the\namount of information that is being communicated from the database between\nremappings and the amount of local memory in the database that a virus may\npreserve during the remappings. The core of the proof of the security guarantee\nis the following communication/data tradeoff for the problem of learning sparse\nparities from uniformly random $n$-bit examples: any algorithm that can learn a\nparity of size $k$ with probability at least $p$ and extracts at most $r$ bits\nof information from each example, must see at least $p\\cdot\n\\left(\\frac{n}{r}\\right)^{k/2} c_k$ examples. \n\n"}
{"id": "1605.03116", "contents": "Title: CALIPER: Continuous Authentication Layered with Integrated PKI Encoding\n  Recognition Abstract: Architectures relying on continuous authentication require a secure way to\nchallenge the user's identity without trusting that the Continuous\nAuthentication Subsystem (CAS) has not been compromised, i.e., that the\nresponse to the layer which manages service/application access is not fake. In\nthis paper, we introduce the CALIPER protocol, in which a separate Continuous\nAccess Verification Entity (CAVE) directly challenges the user's identity in a\ncontinuous authentication regime. Instead of simply returning authentication\nprobabilities or confidence scores, CALIPER's CAS uses live hard and soft\nbiometric samples from the user to extract a cryptographic private key embedded\nin a challenge posed by the CAVE. The CAS then uses this key to sign a response\nto the CAVE. CALIPER supports multiple modalities, key lengths, and security\nlevels and can be applied in two scenarios: One where the CAS must authenticate\nits user to a CAVE running on a remote server (device-server) for access to\nremote application data, and another where the CAS must authenticate its user\nto a locally running trusted computing module (TCM) for access to local\napplication data (device-TCM). We further demonstrate that CALIPER can leverage\ndevice hardware resources to enable privacy and security even when the device's\nkernel is compromised, and we show how this authentication protocol can even be\nexpanded to obfuscate direct kernel object manipulation (DKOM) malwares. \n\n"}
{"id": "1605.05887", "contents": "Title: A Rewriting System for the Assessment of XACML Policies Relationship Abstract: We propose in this paper a new approach to assess the relationship between\nXACML policies. Our approach spans over three steps. In the first one, the\nXACML policies are mapped to terms of a boolean ring while taking into account\nXACML policy and rule combining algorithms. In the second step, the\nrelationship problem between XACML policies is transformed into a validity\nproblem in a boolean ring. In the third step, the validity problem is resolved\nusing a dedicated rewriting system. The convergence of the rewriting system is\nproved in this paper. Moreover, the approach is implemented and its performance\nis evaluated. The results show that our approach enjoys better performance and\nmemory cost than the best so far published SMT based approach. \n\n"}
{"id": "1605.07511", "contents": "Title: A note on privacy preserving iteratively reweighted least squares Abstract: Iteratively reweighted least squares (IRLS) is a widely-used method in\nmachine learning to estimate the parameters in the generalised linear models.\nIn particular, IRLS for L1 minimisation under the linear model provides a\nclosed-form solution in each step, which is a simple multiplication between the\ninverse of the weighted second moment matrix and the weighted first moment\nvector. When dealing with privacy sensitive data, however, developing a privacy\npreserving IRLS algorithm faces two challenges. First, due to the inversion of\nthe second moment matrix, the usual sensitivity analysis in differential\nprivacy incorporating a single datapoint perturbation gets complicated and\noften requires unrealistic assumptions. Second, due to its iterative nature, a\nsignificant cumulative privacy loss occurs. However, adding a high level of\nnoise to compensate for the privacy loss hinders from getting accurate\nestimates. Here, we develop a practical algorithm that overcomes these\nchallenges and outputs privatised and accurate IRLS solutions. In our method,\nwe analyse the sensitivity of each moments separately and treat the matrix\ninversion and multiplication as a post-processing step, which simplifies the\nsensitivity analysis. Furthermore, we apply the {\\it{concentrated differential\nprivacy}} formalism, a more relaxed version of differential privacy, which\nrequires adding a significantly less amount of noise for the same level of\nprivacy guarantee, compared to the conventional and advanced compositions of\ndifferentially private mechanisms. \n\n"}
{"id": "1605.08563", "contents": "Title: Towards the Automated Verification of Cyber-Physical Security Protocols:\n  Bounding the Number of Timed Intruders Abstract: Timed Intruder Models have been proposed for the verification of\nCyber-Physical Security Protocols (CPSP) amending the traditional Dolev-Yao\nintruder to obey the physical restrictions of the environment. Since to learn a\nmessage, a Timed Intruder needs to wait for a message to arrive, mounting an\nattack may depend on where Timed Intruders are. It may well be the case that in\nthe presence of a great number of intruders there is no attack, but there is an\nattack in the presence of a small number of well placed intruders. Therefore, a\nmajor challenge for the automated verification of CPSP is to determine how many\nTimed Intruders to use and where should they be placed. This paper answers this\nquestion by showing it is enough to use the same number of Timed Intruders as\nthe number of participants. We also report on some preliminary experimental\nresults in discovering attacks in CPSP. \n\n"}
{"id": "1605.09779", "contents": "Title: ObliviSync: Practical Oblivious File Backup and Synchronization Abstract: Oblivious RAM (ORAM) protocols are powerful techniques that hide a client's\ndata as well as access patterns from untrusted service providers. We present an\noblivious cloud storage system, ObliviSync, that specifically targets one of\nthe most widely-used personal cloud storage paradigms: synchronization and\nbackup services, popular examples of which are Dropbox, iCloud Drive, and\nGoogle Drive. This setting provides a unique opportunity because the above\nprivacy properties can be achieved with a simpler form of ORAM called\nwrite-only ORAM, which allows for dramatically increased efficiency compared to\nrelated work. Our solution is asymptotically optimal and practically efficient,\nwith a small constant overhead of approximately 4x compared with non-private\nfile storage, depending only on the total data size and parameters chosen\naccording to the usage rate, and not on the number or size of individual files.\nOur construction also offers protection against timing-channel attacks, which\nhas not been previously considered in ORAM protocols. We built and evaluated a\nfull implementation of ObliviSync that supports multiple simultaneous read-only\nclients and a single concurrent read/write client whose edits automatically and\nseamlessly propagate to the readers. We show that our system functions under\nhigh work loads, with realistic file size distributions, and with small\nadditional latency (as compared to a baseline encrypted file system) when\npaired with Dropbox as the synchronization service. \n\n"}
{"id": "1606.00629", "contents": "Title: RankSign: an efficient signature algorithm based on the rank metric Abstract: In this paper we propose a new approach to code-based signatures that makes\nuse in particular of rank metric codes. When the classical approach consists in\nfinding the unique preimage of a syndrome through a decoding algorithm, we\npropose to introduce the notion of mixed decoding of erasures and errors for\nbuilding signature schemes. In that case the difficult problem becomes, as is\nthe case in lattice-based cryptography, finding a preimage of weight above the\nGilbert-Varshamov bound (case where many solutions occur) rather than finding a\nunique preimage of weight below the Gilbert-Varshamov bound. The paper\ndescribes RankSign: a new signature algorithm for the rank metric based on a\nnew mixed algorithm for decoding erasures and errors for the recently\nintroduced Low Rank Parity Check (LRPC) codes. We explain how it is possible\n(depending on choices of parameters) to obtain a full decoding algorithm which\nis able to find a preimage of reasonable rank weight for any random syndrome\nwith a very strong probability. We study the semantic security of our signature\nalgorithm and show how it is possible to reduce the unforgeability to direct\nattacks on the public matrix, so that no information leaks through signatures.\nFinally, we give several examples of parameters for our scheme, some of which\nwith public key of size $11,520$ bits and signature of size $1728$ bits.\nMoreover the scheme can be very fast for small base fields. \n\n"}
{"id": "1606.01042", "contents": "Title: Machine Learning for E-mail Spam Filtering: Review,Techniques and Trends Abstract: We present a comprehensive review of the most effective content-based e-mail\nspam filtering techniques. We focus primarily on Machine Learning-based spam\nfilters and their variants, and report on a broad review ranging from surveying\nthe relevant ideas, efforts, effectiveness, and the current progress. The\ninitial exposition of the background examines the basics of e-mail spam\nfiltering, the evolving nature of spam, spammers playing cat-and-mouse with\ne-mail service providers (ESPs), and the Machine Learning front in fighting\nspam. We conclude by measuring the impact of Machine Learning-based filters and\nexplore the promising offshoots of latest developments. \n\n"}
{"id": "1606.01708", "contents": "Title: Quantifying Permission-Creep in the Google Play Store Abstract: Although there are over 1,600,000 third-party Android apps in the Google Play\nStore, little has been conclusively shown about how their individual (and\ncollective) permission usage has evolved over time. Recently, Android 6\noverhauled the way permissions are granted by users, by switching to run-time\npermission requests instead of install-time permission requests. This is a\nwelcome change, but recent research has shown that many users continue to\naccept run-time permissions blindly, leaving them at the mercy of third-party\napp developers and adversaries. Beyond intentionally invading privacy, highly\nprivileged apps increase the attack surface of smartphones and are more\nattractive targets for adversaries. This work focuses exclusively on dangerous\npermissions, i.e., those permissions identified by Android as guarding access\nto sensitive user data. By taking snapshots of the Google Play Store over a\n20-month period, we characterise changes in the number and type of dangerous\npermissions used by Android apps when they are updated, to gain a greater\nunderstanding of the evolution of permission usage. We found that approximately\n25,000 apps asked for additional permissions every three months. Worryingly, we\nmade statistically significant observations that free apps and highly popular\napps were more likely to ask for additional permissions when they were updated.\nBy looking at patterns in dangerous permission usage, we find evidence that\nsuggests developers may still be failing to correctly specify the permissions\ntheir apps need. \n\n"}
{"id": "1606.03182", "contents": "Title: Cyber Attack Thread: A Control-flow Based Approach to Deconstruct and\n  Mitigate Cyber Threats Abstract: Attacks in cyberspace have got attention due to risk at privacy, breach of\ntrust and financial losses for individuals as well as organizations. In recent\nyears, these attacks have become more complex to analyze technically, as well\nas to detect and prevent from accessing confidential data. Although there are\nmany methodologies and mechanisms which have been suggested for cyber-attack\ndetection and prevention, but not from the perspective of an attacker. This\npaper presents the cyber-defence as hindrances, faced by the attacker, by\nunderstanding attack thread and defence possibilities with existing security\nmechanisms. Seven phases of Cyber Attack Thread are introduced and technical\naspects are discussed with reference to APT attacks. The paper aims for\nsecurity practitioner and administrators as well as for the general audience to\nunderstand the attack scenario and defensive security measures. \n\n"}
{"id": "1607.00133", "contents": "Title: Deep Learning with Differential Privacy Abstract: Machine learning techniques based on neural networks are achieving remarkable\nresults in a wide variety of domains. Often, the training of models requires\nlarge, representative datasets, which may be crowdsourced and contain sensitive\ninformation. The models should not expose private information in these\ndatasets. Addressing this goal, we develop new algorithmic techniques for\nlearning and a refined analysis of privacy costs within the framework of\ndifferential privacy. Our implementation and experiments demonstrate that we\ncan train deep neural networks with non-convex objectives, under a modest\nprivacy budget, and at a manageable cost in software complexity, training\nefficiency, and model quality. \n\n"}
{"id": "1607.00497", "contents": "Title: Identifying ECUs Using Inimitable Characteristics of Signals in\n  Controller Area Networks Abstract: In the last several decades, the automotive industry has come to incorporate\nthe latest Information and Communications (ICT) technology, increasingly\nreplacing mechanical components of vehicles with electronic components. These\nelectronic control units (ECUs) communicate with each other in an in-vehicle\nnetwork that makes the vehicle both safer and easier to drive. Controller Area\nNetworks (CANs) are the current standard for such high quality in-vehicle\ncommunication. Unfortunately, however, CANs do not currently offer protection\nagainst security attacks. In particular, they do not allow for message\nauthentication and hence are open to attacks that replay ECU messages for\nmalicious purposes. Applying the classic cryptographic method of message\nauthentication code (MAC) is not feasible since the CAN data frame is not long\nenough to include a sufficiently long MAC to provide effective authentication.\nIn this paper, we propose a novel identification method, which works in the\nphysical layer of an in-vehicle CAN network. Our method identifies ECUs using\ninimitable characteristics of signals enabling detection of a compromised or\nalien ECU being used in a replay attack. Unlike previous attempts to address\nsecurity issues in the in-vehicle CAN network, our method works by simply\nadding a monitoring unit to the existing network, making it deployable in\ncurrent systems and compliant with required CAN standards. Our experimental\nresults show that the bit string and classification algorithm that we utilized\nyielded more accurate identification of compromised ECUs than any other method\nproposed to date. The false positive rate is more than 2 times lower than the\nmethod proposed by P.-S. Murvay et al. This paper is also the first to identify\npotential attack models that systems should be able to detect. \n\n"}
{"id": "1607.01797", "contents": "Title: Simple and tight device-independent security proofs Abstract: Device-independent security is the gold standard for quantum cryptography:\nnot only is security based entirely on the laws of quantum mechanics, but it\nholds irrespective of any a priori assumptions on the quantum devices used in a\nprotocol, making it particularly applicable in a quantum-wary environment.\nWhile the existence of device-independent protocols for tasks such as\nrandomness expansion and quantum key distribution has recently been\nestablished, the underlying proofs of security remain very challenging, yield\nrather poor key rates, and demand very high-quality quantum devices, thus\nmaking them all but impossible to implement in practice.\n  We introduce a technique for the analysis of device-independent cryptographic\nprotocols. We provide a flexible protocol and give a security proof that\nprovides quantitative bounds that are asymptotically tight, even in the\npresence of general quantum adversaries. At a high level our approach amounts\nto establishing a reduction to the scenario in which the untrusted device\noperates in an identical and independent way in each round of the protocol.\nThis is achieved by leveraging the sequential nature of the protocol, and makes\nuse of a newly developed tool, the \"entropy accumulation theorem\" of Dupuis et\nal.\n  As concrete applications we give simple and modular security proofs for\ndevice-independent quantum key distribution and randomness expansion protocols\nbased on the CHSH inequality. For both tasks we establish essentially optimal\nasymptotic key rates and noise tolerance. In view of recent experimental\nprogress, which has culminated in loophole-free Bell tests, it is likely that\nthese protocols can be practically implemented in the near future. \n\n"}
{"id": "1607.01842", "contents": "Title: Finding Significant Fourier Coefficients: Clarifications,\n  Simplifications, Applications and Limitations Abstract: Ideas from Fourier analysis have been used in cryptography for the last three\ndecades. Akavia, Goldwasser and Safra unified some of these ideas to give a\ncomplete algorithm that finds significant Fourier coefficients of functions on\nany finite abelian group. Their algorithm stimulated a lot of interest in the\ncryptography community, especially in the context of `bit security'. This\nmanuscript attempts to be a friendly and comprehensive guide to the tools and\nresults in this field. The intended readership is cryptographers who have heard\nabout these tools and seek an understanding of their mechanics and their\nusefulness and limitations. A compact overview of the algorithm is presented\nwith emphasis on the ideas behind it. We show how these ideas can be extended\nto a `modulus-switching' variant of the algorithm. We survey some applications\nof this algorithm, and explain that several results should be taken in the\nright context. In particular, we point out that some of the most important bit\nsecurity problems are still open. Our original contributions include: a\ndiscussion of the limitations on the usefulness of these tools; an answer to an\nopen question about the modular inversion hidden number problem. \n\n"}
{"id": "1607.02420", "contents": "Title: Blockchain Mining Games Abstract: We study the strategic considerations of miners participating in the\nbitcoin's protocol. We formulate and study the stochastic game that underlies\nthese strategic considerations. The miners collectively build a tree of blocks,\nand they are paid when they create a node (mine a block) which will end up in\nthe path of the tree that is adopted by all. Since the miners can hide newly\nmined nodes, they play a game with incomplete information. Here we consider two\nsimplified forms of this game in which the miners have complete information. In\nthe simplest game the miners release every mined block immediately, but are\nstrategic on which blocks to mine. In the second more complicated game, when a\nblock is mined it is announced immediately, but it may not be released so that\nother miners cannot continue mining from it. A miner not only decides which\nblocks to mine, but also when to release blocks to other miners. In both games,\nwe show that when the computational power of each miner is relatively small,\ntheir best response matches the expected behavior of the bitcoin designer.\nHowever, when the computational power of a miner is large, he deviates from the\nexpected behavior, and other Nash equilibria arise. \n\n"}
{"id": "1607.03854", "contents": "Title: The Partially Observable Hidden Markov Model and its Application to\n  Keystroke Dynamics Abstract: The partially observable hidden Markov model is an extension of the hidden\nMarkov Model in which the hidden state is conditioned on an independent Markov\nchain. This structure is motivated by the presence of discrete metadata, such\nas an event type, that may partially reveal the hidden state but itself\nemanates from a separate process. Such a scenario is encountered in keystroke\ndynamics whereby a user's typing behavior is dependent on the text that is\ntyped. Under the assumption that the user can be in either an active or passive\nstate of typing, the keyboard key names are event types that partially reveal\nthe hidden state due to the presence of relatively longer time intervals\nbetween words and sentences than between letters of a word. Using five public\ndatasets, the proposed model is shown to consistently outperform other anomaly\ndetectors, including the standard HMM, in biometric identification and\nverification tasks and is generally preferred over the HMM in a Monte Carlo\ngoodness of fit test. \n\n"}
{"id": "1607.04421", "contents": "Title: Password Generators: Old Ideas and New Abstract: This paper considers password generators, i.e. systems designed to generate\nsite-specific passwords on demand. Such systems are an alternative to password\nmanagers. Over the last 15 years a range of password generator systems have\nbeen described. This paper proposes the first general model for such systems,\nand critically examines options for instantiating this model; options\nconsidered include all those previously proposed as part of existing schemes as\nwell as certain novel possibilities. The model enables a more objective and\nhigh-level assessment of the design of such systems; it has also been used to\nsketch a possible new scheme, AutoPass, intended to incorporate the best\nfeatures of the prior art whilst also addressing many of the most serious\nshortcomings of existing systems through the inclusion of novel features. \n\n"}
{"id": "1607.04789", "contents": "Title: Sieving for closest lattice vectors (with preprocessing) Abstract: Lattice-based cryptography has recently emerged as a prime candidate for\nefficient and secure post-quantum cryptography. The two main hard problems\nunderlying its security are the shortest vector problem (SVP) and the closest\nvector problem (CVP). Various algorithms have been studied for solving these\nproblems, and for SVP, lattice sieving currently dominates in terms of the\nasymptotic time complexity: one can heuristically solve SVP in time\n$2^{0.292d}$ in high dimensions $d$ [BDGL'16]. Although several SVP algorithms\ncan also be used to solve CVP, it is not clear whether this also holds for\nheuristic lattice sieving methods. The best time complexity for CVP is\ncurrently $2^{0.377d}$ [BGJ'14].\n  In this paper we revisit sieving algorithms for solving SVP, and study how\nthese algorithms can be modified to solve CVP and its variants as well. Our\nfirst method is aimed at solving one problem instance and minimizes the overall\ntime complexity for a single CVP instance with a time complexity of\n$2^{0.292d}$. Our second method minimizes the amortized time complexity for\nseveral instances on the same lattice, at the cost of a larger preprocessing\ncost. We can solve the closest vector problem with preprocessing (CVPP) with\n$2^{0.636d}$ space and preprocessing, in $2^{0.136d}$ time, while the query\ncomplexity can even be reduced to $2^{\\epsilon d}$ at the cost of preprocessing\ntime and memory complexities of $(1/\\epsilon)^{O(d)}$.\n  For easier variants of CVP, such as approximate CVP and bounded distance\ndecoding (BDD), we further show how the preprocessing method achieves even\nbetter complexities. For instance, we can solve approximate CVPP with large\napproximation factors $k$ with polynomial-sized advice in polynomial time if $k\n= \\Omega(\\sqrt{d/\\log d})$, heuristically closing the gap between the\ndecision-CVPP result of [AR'04] and the search-CVPP result of [DRS'14]. \n\n"}
{"id": "1607.05113", "contents": "Title: On the Effectiveness of Defensive Distillation Abstract: We report experimental results indicating that defensive distillation\nsuccessfully mitigates adversarial samples crafted using the fast gradient sign\nmethod, in addition to those crafted using the Jacobian-based iterative attack\non which the defense mechanism was originally evaluated. \n\n"}
{"id": "1607.05171", "contents": "Title: LTE security, protocol exploits and location tracking experimentation\n  with low-cost software radio Abstract: The Long Term Evolution (LTE) is the latest mobile standard being implemented\nglobally to provide connectivity and access to advanced services for personal\nmobile devices. Moreover, LTE networks are considered to be one of the main\npillars for the deployment of Machine to Machine (M2M) communication systems\nand the spread of the Internet of Things (IoT). As an enabler for advanced\ncommunications services with a subscription count in the billions, security is\nof capital importance in LTE. Although legacy GSM (Global System for Mobile\nCommunications) networks are known for being insecure and vulnerable to rogue\nbase stations, LTE is assumed to guarantee confidentiality and strong\nauthentication. However, LTE networks are vulnerable to security threats that\ntamper availability, privacy and authentication. This manuscript, which\nsummarizes and expands the results presented by the author at ShmooCon 2016\n\\cite{jover2016lte}, investigates the insecurity rationale behind LTE protocol\nexploits and LTE rogue base stations based on the analysis of real LTE radio\nlink captures from the production network. Implementation results are discussed\nfrom the actual deployment of LTE rogue base stations, IMSI catchers and\nexploits that can potentially block a mobile device. A previously unknown\ntechnique to potentially track the location of mobile devices as they move from\ncell to cell is also discussed, with mitigations being proposed. \n\n"}
{"id": "1607.08228", "contents": "Title: LightDP: Towards Automating Differential Privacy Proofs Abstract: The growing popularity and adoption of differential privacy in academic and\nindustrial settings has resulted in the development of increasingly\nsophisticated algorithms for releasing information while preserving privacy.\nAccompanying this phenomenon is the natural rise in the development and\npublication of incorrect algorithms, thus demonstrating the necessity of formal\nverification tools. However, existing formal methods for differential privacy\nface a dilemma: methods based on customized logics can verify sophisticated\nalgorithms but come with a steep learning curve and significant annotation\nburden on the programmers, while existing programming platforms lack expressive\npower for some sophisticated algorithms.\n  In this paper, we present LightDP, a simple imperative language that strikes\na better balance between expressive power and usability. The core of LightDP is\na novel relational type system that separates relational reasoning from privacy\nbudget calculations. With dependent types, the type system is powerful enough\nto verify sophisticated algorithms where the composition theorem falls short.\nIn addition, the inference engine of LightDP infers most of the proof details,\nand even searches for the proof with minimal privacy cost bound when multiple\nproofs exist. We show that LightDP verifies sophisticated algorithms with\nlittle manual effort. \n\n"}
{"id": "1607.08554", "contents": "Title: Statistical Properties of Sanitized Results from Differentially Private\n  Laplace Mechanism with Univariate Bounding Constraints Abstract: Protection of individual privacy is a common concern when releasing and\nsharing data and information. Differential privacy (DP) formalizes privacy in\nprobabilistic terms without making assumptions about the background knowledge\nof data intruders, and thus provides a robust concept for privacy protection.\nPractical applications of DP involve development of differentially private\nmechanisms to generate sanitized results at a pre-specified privacy budget. For\nthe sanitization of statistics with publicly known bounds such as proportions\nand correlation coefficients, the bounding constraints will need to be\nincorporated in the differentially private mechanisms. There has been little\nwork on examining the consequences of the bounding constraints on the accuracy\nof sanitized results and the statistical inferences of the population\nparameters based on the sanitized results. In this paper, we formalize the\ndifferentially private truncated and boundary inflated truncated (BIT)\nprocedures for releasing statistics with publicly known bounding constraints.\nThe impacts of the truncated and BIT Laplace procedures on the statistical\naccuracy and validity of sanitized statistics are evaluated both theoretically\nand empirically via simulation studies. \n\n"}
{"id": "1608.02257", "contents": "Title: Robust High-Dimensional Linear Regression Abstract: The effectiveness of supervised learning techniques has made them ubiquitous\nin research and practice. In high-dimensional settings, supervised learning\ncommonly relies on dimensionality reduction to improve performance and identify\nthe most important factors in predicting outcomes. However, the economic\nimportance of learning has made it a natural target for adversarial\nmanipulation of training data, which we term poisoning attacks. Prior\napproaches to dealing with robust supervised learning rely on strong\nassumptions about the nature of the feature matrix, such as feature\nindependence and sub-Gaussian noise with low variance. We propose an integrated\nmethod for robust regression that relaxes these assumptions, assuming only that\nthe feature matrix can be well approximated by a low-rank matrix. Our\ntechniques integrate improved robust low-rank matrix approximation and robust\nprinciple component regression, and yield strong performance guarantees.\nMoreover, we experimentally show that our methods significantly outperform\nstate of the art both in running time and prediction error. \n\n"}
{"id": "1608.03398", "contents": "Title: Robust Relativistic Bit Commitment Abstract: Relativistic cryptography exploits the fact that no information can travel\nfaster than the speed of light in order to obtain security guarantees that\ncannot be achieved from the laws of quantum mechanics alone. Recently, Lunghi\net al [Phys. Rev. Lett. 2015] presented a bit commitment scheme where each\nparty uses two agents that exchange classical information in a synchronized\nfashion, and that is both hiding and binding. A caveat is that the commitment\ntime is intrinsically limited by the spatial configuration of the players, and\nincreasing this time requires the agents to exchange messages during the whole\nduration of the protocol. While such a solution remains computationally\nattractive, its practicality is severely limited in realistic settings since\nall communication must remain perfectly synchronized at all times.\n  In this work, we introduce a robust protocol for relativistic bit commitment\nthat tolerates failures of the classical communication network. This is done by\nadding a third agent to both parties. Our scheme provides a quadratic\nimprovement in terms of expected sustain time compared to the original\nprotocol, while retaining the same level of security. \n\n"}
{"id": "1608.04001", "contents": "Title: Almost Perfect Privacy for Additive Gaussian Privacy Filters Abstract: We study the maximal mutual information about a random variable $Y$\n(representing non-private information) displayed through an additive Gaussian\nchannel when guaranteeing that only $\\epsilon$ bits of information is leaked\nabout a random variable $X$ (representing private information) that is\ncorrelated with $Y$. Denoting this quantity by $g_\\epsilon(X,Y)$, we show that\nfor perfect privacy, i.e., $\\epsilon=0$, one has $g_0(X,Y)=0$ for any pair of\nabsolutely continuous random variables $(X,Y)$ and then derive a second-order\napproximation for $g_\\epsilon(X,Y)$ for small $\\epsilon$. This approximation is\nshown to be related to the strong data processing inequality for mutual\ninformation under suitable conditions on the joint distribution $P_{XY}$. Next,\nmotivated by an operational interpretation of data privacy, we formulate the\nprivacy-utility tradeoff in the same setup using estimation-theoretic\nquantities and obtain explicit bounds for this tradeoff when $\\epsilon$ is\nsufficiently small using the approximation formula derived for\n$g_\\epsilon(X,Y)$. \n\n"}
{"id": "1608.04727", "contents": "Title: Covert Bits Through Queues Abstract: We consider covert communication using a queuing timing channel in the\npresence of a warden. The covert message is encoded using the inter-arrival\ntimes of the packets, and the legitimate receiver and the warden observe the\ninter-departure times of the packets from their respective queues. The\ntransmitter and the legitimate receiver also share a secret key to facilitate\ncovert communication. We propose achievable schemes that obtain non-zero covert\nrate for both exponential and general queues when a sufficiently high rate\nsecret key is available. This is in contrast to other channel models such as\nthe Gaussian channel or the discrete memoryless channel where only\n$\\mathcal{O}(\\sqrt{n})$ covert bits can be sent over $n$ channel uses, yielding\na zero covert rate. \n\n"}
{"id": "1608.06249", "contents": "Title: A Survey on Honeypot Software and Data Analysis Abstract: In this survey, we give an extensive overview on honeypots. This includes not\nonly honeypot software but also methodologies to analyse honeypot data. \n\n"}
{"id": "1608.07032", "contents": "Title: The Discrete Logarithm Problem over Prime Fields can be transformed to a\n  Linear Multivariable Chinese Remainder Theorem Abstract: We show that the classical discrete logarithm problem over prime fields can\nbe reduced to that of solving a system of linear modular equations. \n\n"}
{"id": "1608.08182", "contents": "Title: Data Poisoning Attacks on Factorization-Based Collaborative Filtering Abstract: Recommendation and collaborative filtering systems are important in modern\ninformation and e-commerce applications. As these systems are becoming\nincreasingly popular in the industry, their outputs could affect business\ndecision making, introducing incentives for an adversarial party to compromise\nthe availability or integrity of such systems. We introduce a data poisoning\nattack on collaborative filtering systems. We demonstrate how a powerful\nattacker with full knowledge of the learner can generate malicious data so as\nto maximize his/her malicious objectives, while at the same time mimicking\nnormal user behavior to avoid being detected. While the complete knowledge\nassumption seems extreme, it enables a robust assessment of the vulnerability\nof collaborative filtering schemes to highly motivated attacks. We present\nefficient solutions for two popular factorization-based collaborative filtering\nalgorithms: the \\emph{alternative minimization} formulation and the\n\\emph{nuclear norm minimization} method. Finally, we test the effectiveness of\nour proposed algorithms on real-world data and discuss potential defensive\nstrategies. \n\n"}
{"id": "1609.00408", "contents": "Title: Defeating Image Obfuscation with Deep Learning Abstract: We demonstrate that modern image recognition methods based on artificial\nneural networks can recover hidden information from images protected by various\nforms of obfuscation. The obfuscation techniques considered in this paper are\nmosaicing (also known as pixelation), blurring (as used by YouTube), and P3, a\nrecently proposed system for privacy-preserving photo sharing that encrypts the\nsignificant JPEG coefficients to make images unrecognizable by humans. We\nempirically show how to train artificial neural networks to successfully\nidentify faces and recognize objects and handwritten digits even if the images\nare protected using any of the above obfuscation techniques. \n\n"}
{"id": "1609.02750", "contents": "Title: No Free Charge Theorem: a Covert Channel via USB Charging Cable on\n  Mobile Devices Abstract: More and more people are regularly using mobile and battery-powered handsets,\nsuch as smartphones and tablets. At the same time, thanks to the technological\ninnovation and to the high user demands, those devices are integrating\nextensive functionalities and developers are writing battery-draining apps,\nwhich results in a surge of energy consumption of these devices. This scenario\nleads many people to often look for opportunities to charge their devices at\npublic charging stations: the presence of such stations is already prominent\naround public areas such as hotels, shopping malls, airports, gyms and museums,\nand is expected to significantly grow in the future. While most of the time the\npower comes for free, there is no guarantee that the charging station is not\nmaliciously controlled by an adversary, with the intention to exfiltrate data\nfrom the devices that are connected to it.\n  In this paper, we illustrate for the first time how an adversary could\nleverage a maliciously controlled charging station to exfiltrate data from the\nsmartphone via a USB charging cable (i.e., without using the data transfer\nfunctionality), controlling a simple app running on the device, and without\nrequiring any permission to be granted by the user to send data out of the\ndevice. We show the feasibility of the proposed attack through a prototype\nimplementation in Android, which is able to send out potentially sensitive\ninformation, such as IMEI, contacts' phone number, and pictures. \n\n"}
{"id": "1609.02943", "contents": "Title: Stealing Machine Learning Models via Prediction APIs Abstract: Machine learning (ML) models may be deemed confidential due to their\nsensitive training data, commercial value, or use in security applications.\nIncreasingly often, confidential ML models are being deployed with publicly\naccessible query interfaces. ML-as-a-service (\"predictive analytics\") systems\nare an example: Some allow users to train models on potentially sensitive data\nand charge others for access on a pay-per-query basis.\n  The tension between model confidentiality and public access motivates our\ninvestigation of model extraction attacks. In such attacks, an adversary with\nblack-box access, but no prior knowledge of an ML model's parameters or\ntraining data, aims to duplicate the functionality of (i.e., \"steal\") the\nmodel. Unlike in classical learning theory settings, ML-as-a-service offerings\nmay accept partial feature vectors as inputs and include confidence values with\npredictions. Given these practices, we show simple, efficient attacks that\nextract target ML models with near-perfect fidelity for popular model classes\nincluding logistic regression, neural networks, and decision trees. We\ndemonstrate these attacks against the online services of BigML and Amazon\nMachine Learning. We further show that the natural countermeasure of omitting\nconfidence values from model outputs still admits potentially harmful model\nextraction attacks. Our results highlight the need for careful ML model\ndeployment and new model extraction countermeasures. \n\n"}
{"id": "1609.05178", "contents": "Title: Privacy Preserving Distance Computation using Somewhat-trusted Third\n  Parties Abstract: A critically important component of most signal processing procedures is that\nof computing the distance between signals. In multi-party processing\napplications where these signals belong to different parties, this introduces\nprivacy challenges. The signals may themselves be private, and the parties to\nthe computation may not be willing to expose them. Solutions proposed to the\nproblem in the literature generally invoke homomorphic encryption schemes,\nsecure multi-party computation, or other cryptographic methods which introduce\nsignificant computational complexity into the proceedings, often to the point\nof making more complex computations requiring repeated computations unfeasible.\nOther solutions invoke third parties, making unrealistic assumptions about\ntheir trustworthiness.\n  In this paper we propose an alternate approach, also based on third party\ncomputation, but without assuming as much trust in the third party. Individual\nparticipants to the computation \"secure\" their data through a proposed secure\nhashing scheme with shared keys, prior to sharing it with the third party. The\nhashing ensures that the third party cannot recover any information about the\nindividual signals or their statistics, either from analysis of individual\ncomputations or their long-term aggregate patterns. We provide theoretical\nproof of these properties and empirical demonstration of the feasibility of the\ncomputation. \n\n"}
{"id": "1609.06582", "contents": "Title: Privacy-Friendly Mobility Analytics using Aggregate Location Data Abstract: Location data can be extremely useful to study commuting patterns and\ndisruptions, as well as to predict real-time traffic volumes. At the same time,\nhowever, the fine-grained collection of user locations raises serious privacy\nconcerns, as this can reveal sensitive information about the users, such as,\nlife style, political and religious inclinations, or even identities. In this\npaper, we study the feasibility of crowd-sourced mobility analytics over\naggregate location information: users periodically report their location, using\na privacy-preserving aggregation protocol, so that the server can only recover\naggregates -- i.e., how many, but not which, users are in a region at a given\ntime. We experiment with real-world mobility datasets obtained from the\nTransport For London authority and the San Francisco Cabs network, and present\na novel methodology based on time series modeling that is geared to forecast\ntraffic volumes in regions of interest and to detect mobility anomalies in\nthem. In the presence of anomalies, we also make enhanced traffic volume\npredictions by feeding our model with additional information from correlated\nregions. Finally, we present and evaluate a mobile app prototype, called\nMobility Data Donors (MDD), in terms of computation, communication, and energy\noverhead, demonstrating the real-world deployability of our techniques. \n\n"}
{"id": "1609.06664", "contents": "Title: Why Johnny Can't Use Stego: a Human-oriented Perspective on the\n  Application of Steganography Abstract: Steganography is the discipline that deals with concealing the existence of\nsecret communications. Existing research already provided several fundamentals\nfor defining steganography and presented a multitude of hiding methods and\ncountermeasures for this research discipline.\n  We identified that no work exists that discusses the process of applying\nsteganography from an individual's perspective. This paper presents a phase\nmodel that explains pre-conditions of applying steganography as well as the\ndecision-making process and the final termination of a steganographic\ncommunication. The model can be used to explain whether an individual can use\nsteganography and to explain whether and why an individual desires to use\nsteganography. Moreover, the model can be used in research publications to\nindicate the addressed model's phase of scientific contributions. Furthermore,\nour model can be used to teach the process of steganography-application to\nstudents. \n\n"}
{"id": "1609.07922", "contents": "Title: It wasn't me! Plausible Deniability in Web Search Abstract: Our ability to control the flow of sensitive personal information to online\nsystems is key to trust in personal privacy on the internet. We ask how to\ndetect, assess and defend user privacy in the face of search engine\npersonalisation? We develop practical and scalable tools allowing a user to\ndetect, assess and defend against threats to plausible deniability. We show\nthat threats to plausible deniability of interest are readily detectable for\nall topics tested in an extensive testing program. We show this remains the\ncase when attempting to disrupt search engine learning through noise query\ninjection and click obfuscation are used. We use our model we design a defence\ntechnique exploiting uninteresting, proxy topics and show that it provides\namore effective defence of plausible deniability in our experiments. \n\n"}
{"id": "1609.08187", "contents": "Title: The Effect of DNS on Tor's Anonymity Abstract: Previous attacks that link the sender and receiver of traffic in the Tor\nnetwork (\"correlation attacks\") have generally relied on analyzing traffic from\nTCP connections. The TCP connections of a typical client application, however,\nare often accompanied by DNS requests and responses. This additional traffic\npresents more opportunities for correlation attacks. This paper quantifies how\nDNS traffic can make Tor users more vulnerable to correlation attacks. We\ninvestigate how incorporating DNS traffic can make existing correlation attacks\nmore powerful and how DNS lookups can leak information to third parties about\nanonymous communication. We (i) develop a method to identify the DNS resolvers\nof Tor exit relays; (ii) develop a new set of correlation attacks (DefecTor\nattacks) that incorporate DNS traffic to improve precision; (iii) analyze the\nInternet-scale effects of these new attacks on Tor users; and (iv) develop\nimproved methods to evaluate correlation attacks. First, we find that there\nexist adversaries who can mount DefecTor attacks: for example, Google's DNS\nresolver observes almost 40% of all DNS requests exiting the Tor network. We\nalso find that DNS requests often traverse ASes that the corresponding TCP\nconnections do not transit, enabling additional ASes to gain information about\nTor users' traffic. We then show that an adversary who can mount a DefecTor\nattack can often determine the website that a Tor user is visiting with perfect\nprecision, particularly for less popular websites where the set of DNS names\nassociated with that website may be unique to the site. We also use the Tor\nPath Simulator (TorPS) in combination with traceroute data from vantage points\nco-located with Tor exit relays to estimate the power of AS-level adversaries\nwho might mount DefecTor attacks in practice. \n\n"}
{"id": "1609.09047", "contents": "Title: Quantum Tokens for Digital Signatures Abstract: The fisherman caught a quantum fish. \"Fisherman, please let me go\", begged\nthe fish, \"and I will grant you three wishes\". The fisherman agreed. The fish\ngave the fisherman a quantum computer, three quantum signing tokens and his\nclassical public key. The fish explained: \"to sign your three wishes, use the\ntokenized signature scheme on this quantum computer, then show your valid\nsignature to the king, who owes me a favor\".\n  The fisherman used one of the signing tokens to sign the document \"give me a\ncastle!\" and rushed to the palace. The king executed the classical verification\nalgorithm using the fish's public key, and since it was valid, the king\ncomplied.\n  The fisherman's wife wanted to sign ten wishes using their two remaining\nsigning tokens. The fisherman did not want to cheat, and secretly sailed to\nmeet the fish. \"Fish, my wife wants to sign ten more wishes\". But the fish was\nnot worried: \"I have learned quantum cryptography following the previous story\n(The Fisherman and His Wife by the brothers Grimm). The quantum tokens are\nconsumed during the signing. Your polynomial wife cannot even sign four wishes\nusing the three signing tokens I gave you\".\n  \"How does it work?\" wondered the fisherman. \"Have you heard of quantum money?\nThese are quantum states which can be easily verified but are hard to copy.\nThis tokenized quantum signature scheme extends Aaronson and Christiano's\nquantum money scheme, which is why the signing tokens cannot be copied\".\n  \"Does your scheme have additional fancy properties?\" the fisherman asked.\n\"Yes, the scheme has other security guarantees: revocability, testability and\neverlasting security. Furthermore, if you're at sea and your quantum phone has\nonly classical reception, you can use this scheme to transfer the value of the\nquantum money to shore\", said the fish, and swam away. \n\n"}
{"id": "1609.09840", "contents": "Title: Regular and almost universal hashing: an efficient implementation Abstract: Random hashing can provide guarantees regarding the performance of data\nstructures such as hash tables---even in an adversarial setting. Many existing\nfamilies of hash functions are universal: given two data objects, the\nprobability that they have the same hash value is low given that we pick hash\nfunctions at random. However, universality fails to ensure that all hash\nfunctions are well behaved. We further require regularity: when picking data\nobjects at random they should have a low probability of having the same hash\nvalue, for any fixed hash function. We present the efficient implementation of\na family of non-cryptographic hash functions (PM+) offering good running times,\ngood memory usage as well as distinguishing theoretical guarantees: almost\nuniversality and component-wise regularity. On a variety of platforms, our\nimplementations are comparable to the state of the art in performance. On\nrecent Intel processors, PM+ achieves a speed of 4.7 bytes per cycle for 32-bit\noutputs and 3.3 bytes per cycle for 64-bit outputs. We review vectorization\nthrough SIMD instructions (e.g., AVX2) and optimizations for superscalar\nexecution. \n\n"}
{"id": "1610.02518", "contents": "Title: The Advantage of Truncated Permutations Abstract: Constructing a Pseudo Random Function (PRF) is a fundamental problem in\ncryptology. Such a construction, implemented by truncating the last $m$ bits of\npermutations of $\\{0, 1\\}^{n}$ was suggested by Hall et al. (1998). They\nconjectured that the distinguishing advantage of an adversary with $q$ queries,\n${\\bf Adv}_{n, m} (q)$, is small if $q = o (2^{(n+m)/2})$, established an upper\nbound on ${\\bf Adv}_{n, m} (q)$ that confirms the conjecture for $m < n/7$, and\nalso declared a general lower bound ${\\bf Adv}_{n,m}(q)=\\Omega(q^2/2^{n+m})$.\nThe conjecture was essentially confirmed by Bellare and Impagliazzo (1999).\nNevertheless, the problem of {\\em estimating} ${\\bf Adv}_{n, m} (q)$ remained\nopen. Combining the trivial bound $1$, the birthday bound, and a result of Stam\n(1978) leads to the upper bound \\begin{equation*} {\\bf Adv}_{n,m}(q) =\nO\\left(\\min\\left\\{\\frac{q(q-1)}{2^n},\\,\\frac{q}{2^{\\frac{n+m}{2}}},\\,1\\right\\}\\right).\n\\end{equation*} In this paper we show that this upper bound is tight for every\n$0\\leq m<n$ and any $q$. This, in turn, verifies that the converse to the\nconjecture of Hall et al. is also correct, i.e., that ${\\bf Adv}_{n, m} (q)$ is\nnegligible only for $q = o (2^{(n+m)/2})$. \n\n"}
{"id": "1610.03422", "contents": "Title: Quantum authentication with key recycling Abstract: We show that a family of quantum authentication protocols introduced in\n[Barnum et al., FOCS 2002] can be used to construct a secure quantum channel\nand additionally recycle all of the secret key if the message is successfully\nauthenticated, and recycle part of the key if tampering is detected. We give a\nfull security proof that constructs the secure channel given only insecure\nnoisy channels and a shared secret key. We also prove that the number of\nrecycled key bits is optimal for this family of protocols, i.e., there exists\nan adversarial strategy to obtain all non-recycled bits. Previous works\nrecycled less key and only gave partial security proofs, since they did not\nconsider all possible distinguishers (environments) that may be used to\ndistinguish the real setting from the ideal secure quantum channel and secret\nkey resource. \n\n"}
{"id": "1610.03647", "contents": "Title: Exploring Website Location as a Security Indicator Abstract: Authenticating websites is an ongoing problem for users. Recent proposals\nhave suggested strengthening current server authentication methods by\nincorporating website location as a comprehensible additional trust factor. In\nthis work, we explore users' acceptance of location information and how it\naffects decision-making for security and privacy. We conducted a series of\nqualitative interviews to learn how location can be integrated into users'\ndecision-making for security, and we designed a security indicator to alert the\nuser to changes in website locations. We evaluated our tool in a 44-participant\nuser study and found that users were less likely to perform security-sensitive\ntasks when alerted to location changes. Our results suggest that website\nlocation can be used as an effective indicator for users' security assessments. \n\n"}
{"id": "1610.05815", "contents": "Title: Statistical Learning Theory Approach for Data Classification with\n  l-diversity Abstract: Corporations are retaining ever-larger corpuses of personal data; the\nfrequency or breaches and corresponding privacy impact have been rising\naccordingly. One way to mitigate this risk is through use of anonymized data,\nlimiting the exposure of individual data to only where it is absolutely needed.\nThis would seem particularly appropriate for data mining, where the goal is\ngeneralizable knowledge rather than data on specific individuals. In practice,\ncorporate data miners often insist on original data, for fear that they might\n\"miss something\" with anonymized or differentially private approaches. This\npaper provides a theoretical justification for the use of anonymized data.\nSpecifically, we show that a support vector classifier trained on anatomized\ndata satisfying l-diversity should be expected to do as well as on the original\ndata. Anatomy preserves all data values, but introduces uncertainty in the\nmapping between identifying and sensitive values, thus satisfying l-diversity.\nThe theoretical effectiveness of the proposed approach is validated using\nseveral publicly available datasets, showing that we outperform the state of\nthe art for support vector classification using training data protected by\nk-anonymity, and are comparable to learning on the original data. \n\n"}
{"id": "1610.05945", "contents": "Title: A multi-task learning model for malware classification with useful file\n  access pattern from API call sequence Abstract: Based on API call sequences, semantic-aware and machine learning (ML) based\nmalware classifiers can be built for malware detection or classification.\nPrevious works concentrate on crafting and extracting various features from\nmalware binaries, disassembled binaries or API calls via static or dynamic\nanalysis and resorting to ML to build classifiers. However, they tend to\ninvolve too much feature engineering and fail to provide interpretability. We\nsolve these two problems with the recent advances in deep learning: 1)\nRNN-based autoencoders (RNN-AEs) can automatically learn low-dimensional\nrepresentation of a malware from its raw API call sequence. 2) Multiple\ndecoders can be trained under different supervisions to give more information,\nother than the class or family label of a malware. Inspired by the works of\ndocument classification and automatic sentence summarization, each API call\nsequence can be regarded as a sentence. In this paper, we make the first\nattempt to build a multi-task malware learning model based on API call\nsequences. The model consists of two decoders, one for malware classification\nand one for $\\emph{file access pattern}$ (FAP) generation given the API call\nsequence of a malware. We base our model on the general seq2seq framework.\nExperiments show that our model can give competitive classification results as\nwell as insightful FAP information. \n\n"}
{"id": "1610.06095", "contents": "Title: Privacy-preserving schemes for Ad Hoc Social Networks: A survey Abstract: In this paper, we review the state of the art of privacy-preserving schemes\nfor ad hoc social networks, including, mobile social networks (MSNs) and\nvehicular social networks (VSNs). Specifically, we select and in-detail examine\nthirty-three privacy preserving schemes developed for or applied in the context\nof ad hoc social networks. These schemes are published between 2008 and 2016.\nBased on this existing privacy preservation schemes, we survey privacy\npreservation models, including location privacy, identity privacy, anonymity,\ntraceability, interest privacy, backward privacy, and content oriented privacy.\nThe recent important attacks of leaking privacy, countermeasures, and game\ntheoretic approaches in VSNs and MSNs are summarized in form of tables. In\naddition, an overview of recommendations for further research is also provided.\nWith this survey, readers can have a more thorough understanding of research\ntrends in privacy-preserving schemes for ad hoc social networks \n\n"}
{"id": "1610.06140", "contents": "Title: Honey Onions: a Framework for Characterizing and Identifying Misbehaving\n  Tor HSDirs Abstract: In the last decade, Tor proved to be a very successful and widely popular\nsystem to protect users' anonymity. However, Tor remains a practical system\nwith a variety of limitations, some of which were indeed exploited in the\nrecent past. In particular, Tor's security relies on the fact that a\nsubstantial number of its nodes do not misbehave. In this work we introduce,\nthe concept of honey onions, a framework to detect misbehaving Tor relays with\nHSDir capability. This allows to obtain lower bounds on misbehavior among\nrelays. We propose algorithms to both estimate the number of snooping HSDirs\nand identify the most likely snoopers. Our experimental results indicate that\nduring the period of the study (72 days) at least 110 such nodes were snooping\ninformation about hidden services they host. We reveal that more than half of\nthem were hosted on cloud infrastructure and delayed the use of the learned\ninformation to prevent easy traceback. \n\n"}
{"id": "1610.06343", "contents": "Title: (Universal) Unconditional Verifiability in E-Voting without Trusted\n  Parties Abstract: In traditional e-voting protocols, privacy is often provided by a trusted\nauthority that learns the votes and computes the tally. Some protocols replace\nthe trusted authority by a set of authorities, and privacy is guaranteed if\nless than a threshold number of authorities are corrupt. For verifiability,\nstronger security guarantees are demanded. Typically, corrupt authorities that\ntry to fake the result of the tally must always be detected.\n  To provide verifiability, many e-voting protocols use Non-Interactive\nZero-Knowledge proofs (NIZKs). Thanks to their non-interactive nature, NIZKs\nallow anybody, including third parties that do not participate in the protocol,\nto verify the correctness of the tally. Therefore, NIZKs can be used to obtain\nuniversal verifiability. Additionally, NIZKs also improve usability because\nthey allow voters to cast a vote using a non-interactive protocol.\n  The disadvantage of NIZKs is that their security is based on setup\nassumptions such as the common reference string (CRS) or the random oracle (RO)\nmodel. The former requires a trusted party for the generation of a common\nreference string. The latter, though a popular methodology for designing secure\nprotocols, has been shown to be unsound.\n  In this paper, we address the design of an e-voting protocol that provides\nverifiability without any trust assumptions, where verifiability here is meant\nwithout eligibility verification. We show that Non-Interactive\nWitness-Indistinguishable proofs (NIWI) can be used for this purpose. The\ne-voting scheme is private under the Decision Linear assumption, while\nverifiability holds unconditionally. To our knowledge, this is the first\nprivate e-voting scheme with perfect universal verifiability, i.e. one in which\nthe probability of a fake tally not being detected is 0, and with {\\em\nnon-interactive} protocols that does not rely on trust assumptions. \n\n"}
{"id": "1610.06495", "contents": "Title: Cryptography with right-angled Artin groups Abstract: In this paper we propose right-angled Artin groups as a platform for secret\nsharing schemes based on the efficiency (linear time) of the word problem.\nInspired by previous work of Grigoriev-Shpilrain in the context of graphs, we\ndefine two new problems: Subgroup Isomorphism Problem and Group Homomorphism\nProblem. Based on them, we also propose two new authentication schemes. For\nright-angled Artin groups, the Group Homomorphism and Graph Homomorphism\nproblems are equivalent, and the later is known to be NP-complete. In the case\nof the Subgroup Isomorphism problem, we bring some results due to Bridson who\nshows there are right-angled Artin groups in which this problem is unsolvable. \n\n"}
{"id": "1610.07148", "contents": "Title: Revisiting optimal eavesdropping in quantum cryptography: Optimal\n  interaction is unique up to rotation of the underlying basis Abstract: A general framework of optimal eavesdropping on BB84 protocol was provided by\nFuchs et al. [Phys. Rev. A, 1997]. An upper bound on mutual information was\nderived, which could be achieved by a specific type of interaction and the\ncorresponding measurement. However, uniqueness of optimal interaction was posed\nas an unsolved problem there and it has remained open for almost two decades\nnow. In this paper, we solve this open problem and establish the uniqueness of\noptimal interaction up to rotation. The specific choice of optimal interaction\nby Fuchs et al. is shown to be a special case of the form derived in our work. \n\n"}
{"id": "1610.07662", "contents": "Title: A New Class of Private Chi-Square Tests Abstract: In this paper, we develop new test statistics for private hypothesis testing.\nThese statistics are designed specifically so that their asymptotic\ndistributions, after accounting for noise added for privacy concerns, match the\nasymptotics of the classical (non-private) chi-square tests for testing if the\nmultinomial data parameters lie in lower dimensional manifolds (examples\ninclude goodness of fit and independence testing). Empirically, these new test\nstatistics outperform prior work, which focused on noisy versions of existing\nstatistics. \n\n"}
{"id": "1610.08570", "contents": "Title: TrustBase: An Architecture to Repair and Strengthen Certificate-based\n  Authentication Abstract: We describe TrustBase, an architecture that provides certificate-based\nauthentication as an operating system service. TrustBase enforces best\npractices for certificate validation for all applications and transparently\nenables existing applications to be strengthened against failures of the CA\nsystem. The TrustBase system allows simple deployment of authentication systems\nthat harden the CA system. This enables system administrators, for example, to\nrequire certificate revocation checks on all TLS connections, or require\nSTARTTLS for email servers that support it. TrustBase is the first system that\nis able to secure all TLS traffic, using an approach compatible with all\noperating systems. We design and evaluate a prototype implementation of\nTrustBase on Linux, evaluate its security, and demonstrate that it has\nnegligible overhead and universal compatibility with applications. To\ndemonstrate the utility of TrustBase, we have developed six authentication\nservices that strengthen certificate validation for all applications. \n\n"}
{"id": "1610.08749", "contents": "Title: Differentially Private Variational Inference for Non-conjugate Models Abstract: Many machine learning applications are based on data collected from people,\nsuch as their tastes and behaviour as well as biological traits and genetic\ndata. Regardless of how important the application might be, one has to make\nsure individuals' identities or the privacy of the data are not compromised in\nthe analysis. Differential privacy constitutes a powerful framework that\nprevents breaching of data subject privacy from the output of a computation.\nDifferentially private versions of many important Bayesian inference methods\nhave been proposed, but there is a lack of an efficient unified approach\napplicable to arbitrary models. In this contribution, we propose a\ndifferentially private variational inference method with a very wide\napplicability. It is built on top of doubly stochastic variational inference, a\nrecent advance which provides a variational solution to a large class of\nmodels. We add differential privacy into doubly stochastic variational\ninference by clipping and perturbing the gradients. The algorithm is made more\nefficient through privacy amplification from subsampling. We demonstrate the\nmethod can reach an accuracy close to non-private level under reasonably strong\nprivacy guarantees, clearly improving over previous sampling-based alternatives\nespecially in the strong privacy regime. \n\n"}
{"id": "1611.00340", "contents": "Title: Variational Bayes In Private Settings (VIPS) Abstract: Many applications of Bayesian data analysis involve sensitive information,\nmotivating methods which ensure that privacy is protected. We introduce a\ngeneral privacy-preserving framework for Variational Bayes (VB), a widely used\noptimization-based Bayesian inference method. Our framework respects\ndifferential privacy, the gold-standard privacy criterion, and encompasses a\nlarge class of probabilistic models, called the Conjugate Exponential (CE)\nfamily. We observe that we can straightforwardly privatise VB's approximate\nposterior distributions for models in the CE family, by perturbing the expected\nsufficient statistics of the complete-data likelihood. For a broadly-used class\nof non-CE models, those with binomial likelihoods, we show how to bring such\nmodels into the CE family, such that inferences in the modified model resemble\nthe private variational Bayes algorithm as closely as possible, using the\nPolya-Gamma data augmentation scheme. The iterative nature of variational Bayes\npresents a further challenge since iterations increase the amount of noise\nneeded. We overcome this by combining: (1) an improved composition method for\ndifferential privacy, called the moments accountant, which provides a tight\nbound on the privacy cost of multiple VB iterations and thus significantly\ndecreases the amount of additive noise; and (2) the privacy amplification\neffect of subsampling mini-batches from large-scale data in stochastic\nlearning. We empirically demonstrate the effectiveness of our method in CE and\nnon-CE models including latent Dirichlet allocation, Bayesian logistic\nregression, and sigmoid belief networks, evaluated on real-world datasets. \n\n"}
{"id": "1611.01190", "contents": "Title: Conspiracies between Learning Algorithms, Circuit Lower Bounds and\n  Pseudorandomness Abstract: We prove several results giving new and stronger connections between\nlearning, circuit lower bounds and pseudorandomness. Among other results, we\nshow a generic learning speedup lemma, equivalences between various learning\nmodels in the exponential time and subexponential time regimes, a dichotomy\nbetween learning and pseudorandomness, consequences of non-trivial learning for\ncircuit lower bounds, Karp-Lipton theorems for probabilistic exponential time,\nand NC$^1$-hardness for the Minimum Circuit Size Problem. \n\n"}
{"id": "1611.01907", "contents": "Title: Privacy Preserving PageRank Algorithm By Using Secure Multi-Party\n  Computation Abstract: In this work, we study the problem of privacy preserving computation on\nPageRank algorithm. The idea is to enforce the secure multi party computation\nof the algorithm iteratively using homomorphic encryption based on Paillier\nscheme. In the proposed PageRank computation, a user encrypt its own graph data\nusing asymmetric encryption method, sends the data set into different parties\nin a privacy-preserving manner. Each party computes its own encrypted entity,\nbut learns nothing about the data at other parties. \n\n"}
{"id": "1611.02257", "contents": "Title: Multiround Private Information Retrieval: Capacity and Storage Overhead Abstract: The capacity has recently been characterized for the private information\nretrieval (PIR) problem as well as several of its variants. In every case it is\nassumed that all the queries are generated by the user simultaneously. Here we\nconsider multiround PIR, where the queries in each round are allowed to depend\non the answers received in previous rounds. We show that the capacity of\nmultiround PIR is the same as the capacity of single-round PIR (the result is\ngeneralized to also include $T$-privacy constraints). Combined with previous\nresults, this shows that there is no capacity advantage from multiround over\nsingle-round schemes, non-linear over linear schemes or from $\\epsilon$-error\nover zero-error schemes. However, we show through an example that there is an\nadvantage in terms of storage overhead. We provide an example of a multiround,\nnon-linear, $\\epsilon$-error PIR scheme that requires a strictly smaller\nstorage overhead than the best possible with single-round, linear, zero-error\nPIR schemes. \n\n"}
{"id": "1611.02675", "contents": "Title: $k$-connectivity of inhomogeneous random key graphs with unreliable\n  links Abstract: We consider secure and reliable connectivity in wireless sensor networks that\nutilize a heterogeneous random key predistribution scheme. We model the\nunreliability of wireless links by an on-off channel model that induces an\nErd\\H{o}s-R\\'enyi graph, while the heterogeneous scheme induces an\ninhomogeneous random key graph. The overall network can thus be modeled by the\nintersection of both graphs. We present conditions (in the form of zero-one\nlaws) on how to scale the parameters of the intersection model so that with\nhigh probability i) all of its nodes are connected to at least $k$ other nodes;\ni.e., the minimum node degree of the graph is no less than $k$ and ii) the\ngraph is $k$-connected, i.e., the graph remains connected even if any $k-1$\nnodes leave the network. We also present numerical results to support these\nconditions in the finite-node regime. Our results are shown to complement and\ngeneralize several previous work in the literature. \n\n"}
{"id": "1611.03021", "contents": "Title: Attributing Hacks Abstract: In this paper we describe an algorithm for estimating the provenance of hacks\non websites. That is, given properties of sites and the temporal occurrence of\nattacks, we are able to attribute individual attacks to joint causes and\nvulnerabilities, as well as estimating the evolution of these vulnerabilities\nover time. Specifically, we use hazard regression with a time-varying additive\nhazard function parameterized in a generalized linear form. The activation\ncoefficients on each feature are continuous-time functions over time. We\nformulate the problem of learning these functions as a constrained variational\nmaximum likelihood estimation problem with total variation penalty and show\nthat the optimal solution is a 0th order spline (a piecewise constant function)\nwith a finite number of known knots. This allows the inference problem to be\nsolved efficiently and at scale by solving a finite dimensional optimization\nproblem. Extensive experiments on real data sets show that our method\nsignificantly outperforms Cox's proportional hazard model. We also conduct a\ncase study and verify that the fitted functions are indeed recovering\nvulnerable features and real-life events such as the release of code to exploit\nthese features in hacker blogs. \n\n"}
{"id": "1611.03748", "contents": "Title: Systematic Classification of Side-Channel Attacks: A Case Study for\n  Mobile Devices Abstract: Side-channel attacks on mobile devices have gained increasing attention since\ntheir introduction in 2007. While traditional side-channel attacks, such as\npower analysis attacks and electromagnetic analysis attacks, required physical\npresence of the attacker as well as expensive equipment, an (unprivileged)\napplication is all it takes to exploit the leaking information on modern mobile\ndevices. Given the vast amount of sensitive information that are stored on\nsmartphones, the ramifications of side-channel attacks affect both the security\nand privacy of users and their devices.\n  In this paper, we propose a new categorization system for side-channel\nattacks, which is necessary as side-channel attacks have evolved significantly\nsince their scientific investigations during the smart card era in the 1990s.\nOur proposed classification system allows to analyze side-channel attacks\nsystematically, and facilitates the development of novel countermeasures.\nBesides this new categorization system, the extensive survey of existing\nattacks and attack strategies provides valuable insights into the evolving\nfield of side-channel attacks, especially when focusing on mobile devices. We\nconclude by discussing open issues and challenges in this context and outline\npossible future research directions. \n\n"}
{"id": "1611.03941", "contents": "Title: Anomaly Detection in Bitcoin Network Using Unsupervised Learning Methods Abstract: The problem of anomaly detection has been studied for a long time. In short,\nanomalies are abnormal or unlikely things. In financial networks, thieves and\nillegal activities are often anomalous in nature. Members of a network want to\ndetect anomalies as soon as possible to prevent them from harming the network's\ncommunity and integrity. Many Machine Learning techniques have been proposed to\ndeal with this problem; some results appear to be quite promising but there is\nno obvious superior method. In this paper, we consider anomaly detection\nparticular to the Bitcoin transaction network. Our goal is to detect which\nusers and transactions are the most suspicious; in this case, anomalous\nbehavior is a proxy for suspicious behavior. To this end, we use three\nunsupervised learning methods including k-means clustering, Mahalanobis\ndistance, and Unsupervised Support Vector Machine (SVM) on two graphs generated\nby the Bitcoin transaction network: one graph has users as nodes, and the other\nhas transactions as nodes. \n\n"}
{"id": "1611.04880", "contents": "Title: IoT Sentinel: Automated Device-Type Identification for Security\n  Enforcement in IoT Abstract: With the rapid growth of the Internet-of-Things (IoT), concerns about the\nsecurity of IoT devices have become prominent. Several vendors are producing\nIP-connected devices for home and small office networks that often suffer from\nflawed security designs and implementations. They also tend to lack mechanisms\nfor firmware updates or patches that can help eliminate security\nvulnerabilities. Securing networks where the presence of such vulnerable\ndevices is given, requires a brownfield approach: applying necessary protection\nmeasures within the network so that potentially vulnerable devices can coexist\nwithout endangering the security of other devices in the same network. In this\npaper, we present IOT SENTINEL, a system capable of automatically identifying\nthe types of devices being connected to an IoT network and enabling enforcement\nof rules for constraining the communications of vulnerable devices so as to\nminimize damage resulting from their compromise. We show that IOT SENTINEL is\neffective in identifying device types and has minimal performance overhead. \n\n"}
{"id": "1611.06150", "contents": "Title: Optimal Key Consensus in Presence of Noise Abstract: In this work, we abstract some key ingredients in previous LWE- and\nRLWE-based key exchange protocols, by introducing and formalizing the building\ntool, referred to as key consensus (KC) and its asymmetric variant AKC. KC and\nAKC allow two communicating parties to reach consensus from close values\nobtained by some secure information exchange. We then discover upper bounds on\nparameters for any KC and AKC. KC and AKC are fundamental to lattice based\ncryptography, in the sense that a list of cryptographic primitives based on\nLWR, LWE and RLWE (including key exchange, public-key encryption, and more) can\nbe modularly constructed from them. As a conceptual contribution, this much\nsimplifies the design and analysis of these cryptosystems in the future.\n  We then design and analyze both general and highly practical KC and AKC\nschemes, which are referred to as OKCN and AKCN respectively for presentation\nsimplicity. Based on KC and AKC, we present generic constructions of key\nexchange (KE) from LWR, LWE and RLWE. The generic construction allows versatile\ninstantiations with our OKCN and AKCN schemes, for which we elaborate on\nevaluating and choosing the concrete parameters in order to achieve an\noptimally-balanced performance among security, computational cost, bandwidth\nefficiency, error rate, and operation simplicity. \n\n"}
{"id": "1611.08648", "contents": "Title: Patient-Driven Privacy Control through Generalized Distillation Abstract: The introduction of data analytics into medicine has changed the nature of\npatient treatment. In this, patients are asked to disclose personal information\nsuch as genetic markers, lifestyle habits, and clinical history. This data is\nthen used by statistical models to predict personalized treatments. However,\ndue to privacy concerns, patients often desire to withhold sensitive\ninformation. This self-censorship can impede proper diagnosis and treatment,\nwhich may lead to serious health complications and even death over time. In\nthis paper, we present privacy distillation, a mechanism which allows patients\nto control the type and amount of information they wish to disclose to the\nhealthcare providers for use in statistical models. Meanwhile, it retains the\naccuracy of models that have access to all patient data under a sufficient but\nnot full set of privacy-relevant information. We validate privacy distillation\nusing a corpus of patients prescribed to warfarin for a personalized dosage. We\nuse a deep neural network to implement privacy distillation for training and\nmaking dose predictions. We find that privacy distillation with sufficient\nprivacy-relevant information i) retains accuracy almost as good as having all\npatient data (only 3\\% worse), and ii) is effective at preventing errors that\nintroduce health-related risks (only 3.9\\% worse under- or over-prescriptions). \n\n"}
{"id": "1612.00334", "contents": "Title: A Theoretical Framework for Robustness of (Deep) Classifiers against\n  Adversarial Examples Abstract: Most machine learning classifiers, including deep neural networks, are\nvulnerable to adversarial examples. Such inputs are typically generated by\nadding small but purposeful modifications that lead to incorrect outputs while\nimperceptible to human eyes. The goal of this paper is not to introduce a\nsingle method, but to make theoretical steps towards fully understanding\nadversarial examples. By using concepts from topology, our theoretical analysis\nbrings forth the key reasons why an adversarial example can fool a classifier\n($f_1$) and adds its oracle ($f_2$, like human eyes) in such analysis. By\ninvestigating the topological relationship between two (pseudo)metric spaces\ncorresponding to predictor $f_1$ and oracle $f_2$, we develop necessary and\nsufficient conditions that can determine if $f_1$ is always robust\n(strong-robust) against adversarial examples according to $f_2$. Interestingly\nour theorems indicate that just one unnecessary feature can make $f_1$ not\nstrong-robust, and the right feature representation learning is the key to\ngetting a classifier that is both accurate and strong-robust. \n\n"}
{"id": "1612.01188", "contents": "Title: Privacy on the Blockchain: Unique Ring Signatures Abstract: Ring signatures are cryptographic protocols designed to allow any member of a\ngroup to produce a signature on behalf of the group, without revealing the\nindividual signer's identity. This offers group members a level of anonymity\nnot attainable through generic digital signature schemes. We call this property\n'plausible deniability', or anonymity with respect to an anonymity set. We\nconcentrate in particular on implementing privacy on the blockchain,\nintroducing a unique ring signature scheme that works with existing blockchain\nsystems. We implement a unique ring signature (URS) scheme using secp256k1,\ncreating the first implementation compatible with blockchain libraries in this\nway, so as for easy implementation as an Ethereum smart contract. We review the\nprivacy and security properties offered by the scheme we have constructed, and\ncompare its efficiency with other commonly suggested approaches to privacy on\nthe blockchain. \n\n"}
{"id": "1612.02114", "contents": "Title: Experimental measurement-device-independent quantum random number\n  generation Abstract: The randomness from a quantum random number generator (QRNG) relies on the\naccurate characterization of its devices. However, device imperfections and\ninaccurate characterizations can result in wrong entropy estimation and bias in\npractice, which highly affects the genuine randomness generation and may even\ninduce the disappearance of quantum randomness in an extreme case. Here we\nexperimentally demonstrate a measurement-device-independent (MDI) QRNG based on\ntime-bin encoding to achieve certified quantum randomness even when the\nmeasurement devices are uncharacterized and untrusted. The MDI-QRNG is randomly\nswitched between the regular randomness generation mode and a test mode, in\nwhich four quantum states are randomly prepared to perform measurement\ntomography in real-time. With a clock rate of 25 MHz, the MDI-QRNG generates a\nfinal random bit rate of 5.7 Kbps. Such implementation with an all-fiber setup\nprovides an approach to construct a fully-integrated MDI-QRNG with trusted but\nerror-prone devices in practice. \n\n"}
{"id": "1612.02298", "contents": "Title: Individual Differential Privacy: A Utility-Preserving Formulation of\n  Differential Privacy Guarantees Abstract: Differential privacy is a popular privacy model within the research community\nbecause of the strong privacy guarantee it offers, namely that the presence or\nabsence of any individual in a data set does not significantly influence the\nresults of analyses on the data set. However, enforcing this strict guarantee\nin practice significantly distorts data and/or limits data uses, thus\ndiminishing the analytical utility of the differentially private results. In an\nattempt to address this shortcoming, several relaxations of differential\nprivacy have been proposed that trade off privacy guarantees for improved data\nutility. In this work, we argue that the standard formalization of differential\nprivacy is stricter than required by the intuitive privacy guarantee it seeks.\nIn particular, the standard formalization requires indistinguishability of\nresults between any pair of neighbor data sets, while indistinguishability\nbetween the actual data set and its neighbor data sets should be enough. This\nlimits the data controller's ability to adjust the level of protection to the\nactual data, hence resulting in significant accuracy loss. In this respect, we\npropose individual differential privacy, an alternative differential privacy\nnotion that offers em the same privacy guarantees as standard differential\nprivacy to individuals (even though not to groups of individuals). This new\nnotion allows the data controller to adjust the distortion to the actual data\nset, which results in less distortion and more analytical accuracy. We propose\nseveral mechanisms to attain individual differential privacy and we compare the\nnew notion against standard differential privacy in terms of the accuracy of\nthe analytical results. \n\n"}
{"id": "1612.02886", "contents": "Title: Homomorphic Encryption Experiments on IBM's Cloud Quantum Computing\n  Platform Abstract: Quantum computing has undergone rapid development in recent years. Owing to\nlimitations on scalability, personal quantum computers still seem slightly\nunrealistic in the near future. The first practical quantum computer for\nordinary users is likely to be on the cloud. However, the adoption of cloud\ncomputing is possible only if security is ensured. Homomorphic encryption is a\ncryptographic protocol that allows computation to be performed on encrypted\ndata without decrypting them, so it is well suited to cloud computing. Here, we\nfirst applied homomorphic encryption on IBM's cloud quantum computer platform.\nIn our experiments, we successfully implemented a quantum algorithm for linear\nequations while protecting our privacy. This demonstration opens a feasible\npath to the next stage of development of cloud quantum information technology. \n\n"}
{"id": "1612.04474", "contents": "Title: Your Processor Leaks Information - and There's Nothing You Can Do About\n  It Abstract: Timing channels are information flows, encoded in the relative timing of\nevents, that bypass the system's protection mechanisms. Any microarchitectural\nstate that depends on execution history and affects the rate of progress of\nlater executions potentially establishes a timing channel, unless explicit\nsteps are taken to close it. Such state includes CPU caches, TLBs, branch\npredictors and prefetchers; removing the channels requires that the OS can\npartition such state or flush it on a switch of security domains. We measure\nthe capacities of channels based on these microarchitectural features on\nseveral generations of processors across the two mainstream ISAs, x86 and ARM,\nand investigate the effectiveness of the flushing mechanisms provided by the\nrespective ISA.We find that in all processors we studied, at least one\nsignificant channel remains. This implies that closing all timing channels\nseems impossible on contemporary mainstream processors. \n\n"}
{"id": "1612.04914", "contents": "Title: Classical verification of quantum circuits containing few basis changes Abstract: We consider the task of verifying the correctness of quantum computation for\na restricted class of circuits which contain at most two basis changes. This\ncontains circuits giving rise to the second level of the Fourier Hierarchy, the\nlowest level for which there is an established quantum advantage. We show that,\nwhen the circuit has an outcome with probability at least the inverse of some\npolynomial in the circuit size, the outcome can be checked in polynomial time\nwith bounded error by a completely classical verifier. This verification\nprocedure is based on random sampling of computational paths and is only\npossible given knowledge of the likely outcome. \n\n"}
{"id": "1612.05085", "contents": "Title: Variations of the McEliece Cryptosystem Abstract: Two variations of the McEliece cryptosystem are presented. The first one is\nbased on a relaxation of the column permutation in the classical McEliece\nscrambling process. This is done in such a way that the Hamming weight of the\nerror, added in the encryption process, can be controlled so that efficient\ndecryption remains possible. The second variation is based on the use of\nspatially coupled moderate-density parity-check codes as secret codes. These\ncodes are known for their excellent error-correction performance and allow for\na relatively low key size in the cryptosystem. For both variants the security\nwith respect to known attacks is discussed. \n\n"}
{"id": "1612.05974", "contents": "Title: An IoT Endpoint System-on-Chip for Secure and Energy-Efficient\n  Near-Sensor Analytics Abstract: Near-sensor data analytics is a promising direction for IoT endpoints, as it\nminimizes energy spent on communication and reduces network load - but it also\nposes security concerns, as valuable data is stored or sent over the network at\nvarious stages of the analytics pipeline. Using encryption to protect sensitive\ndata at the boundary of the on-chip analytics engine is a way to address data\nsecurity issues. To cope with the combined workload of analytics and encryption\nin a tight power envelope, we propose Fulmine, a System-on-Chip based on a\ntightly-coupled multi-core cluster augmented with specialized blocks for\ncompute-intensive data processing and encryption functions, supporting software\nprogrammability for regular computing tasks. The Fulmine SoC, fabricated in\n65nm technology, consumes less than 20mW on average at 0.8V achieving an\nefficiency of up to 70pJ/B in encryption, 50pJ/px in convolution, or up to\n25MIPS/mW in software. As a strong argument for real-life flexible application\nof our platform, we show experimental results for three secure analytics use\ncases: secure autonomous aerial surveillance with a state-of-the-art deep CNN\nconsuming 3.16pJ per equivalent RISC op; local CNN-based face detection with\nsecured remote recognition in 5.74pJ/op; and seizure detection with encrypted\ndata collection from EEG within 12.7pJ/op. \n\n"}
{"id": "1612.06305", "contents": "Title: Handwritten Signature Verification Using Hand-Worn Devices Abstract: Online signature verification technologies, such as those available in banks\nand post offices, rely on dedicated digital devices such as tablets or smart\npens to capture, analyze and verify signatures. In this paper, we suggest a\nnovel method for online signature verification that relies on the increasingly\navailable hand-worn devices, such as smartwatches or fitness trackers, instead\nof dedicated ad-hoc devices. Our method uses a set of known genuine and forged\nsignatures, recorded using the motion sensors of a hand-worn device, to train a\nmachine learning classifier. Then, given the recording of an unknown signature\nand a claimed identity, the classifier can determine whether the signature is\ngenuine or forged. In order to validate our method, it was applied on 1980\nrecordings of genuine and forged signatures that we collected from 66 subjects\nin our institution. Using our method, we were able to successfully distinguish\nbetween genuine and forged signatures with a high degree of accuracy (0.98 AUC\nand 0.05 EER). \n\n"}
{"id": "1612.07003", "contents": "Title: Image biomarker standardisation initiative Abstract: The image biomarker standardisation initiative (IBSI) is an independent\ninternational collaboration which works towards standardising the extraction of\nimage biomarkers from acquired imaging for the purpose of high-throughput\nquantitative image analysis (radiomics). Lack of reproducibility and validation\nof high-throughput quantitative image analysis studies is considered to be a\nmajor challenge for the field. Part of this challenge lies in the scantiness of\nconsensus-based guidelines and definitions for the process of translating\nacquired imaging into high-throughput image biomarkers. The IBSI therefore\nseeks to provide image biomarker nomenclature and definitions, benchmark data\nsets, and benchmark values to verify image processing and image biomarker\ncalculations, as well as reporting guidelines, for high-throughput image\nanalysis. \n\n"}
{"id": "1612.07206", "contents": "Title: Authentication Protocols for Internet of Things: A Comprehensive Survey Abstract: In this paper, we present a comprehensive survey of authentication protocols\nfor Internet of Things (IoT). Specifically, we select and in-detail examine\nmore than forty authentication protocols developed for or applied in the\ncontext of the IoT under four environments, including: (1) Machine to machine\ncommunications (M2M), (2) Internet of Vehicles (IoV), (3) Internet of Energy\n(IoE), and (4) Internet of Sensors (IoS). We start by reviewing all survey\narticles published in the recent years that focusing on different aspects of\nthe IoT idea. Then, we review threat models, countermeasures, and formal\nsecurity verification techniques used in authentication protocols for the IoT.\nIn addition, we provide a taxonomy and comparison of authentication protocols\nfor the IoT in form of tables in five terms, namely, network model, goals, main\nprocesses, computation complexity, and communication overhead. Based on the\ncurrent survey, we identify open issues and suggest hints for future research. \n\n"}
{"id": "1701.00740", "contents": "Title: Optimized, Direct Sale of Privacy in Personal-Data Marketplaces Abstract: Very recently, we are witnessing the emergence of a number of start-ups that\nenables individuals to sell their private data directly to brokers and\nbusinesses. While this new paradigm may shift the balance of power between\nindividuals and companies that harvest data, it raises some practical,\nfundamental questions for users of these services: how they should decide which\ndata must be vended and which data protected, and what a good deal is. In this\nwork, we investigate a mechanism that aims at helping users address these\nquestions. The investigated mechanism relies on a hard-privacy model and allows\nusers to share partial or complete profile data with broker companies in\nexchange for an economic reward. The theoretical analysis of the trade-off\nbetween privacy and money posed by such mechanism is the object of this work.\nWe adopt a generic measure of privacy although part of our analysis focuses on\nsome important examples of Bregman divergences. We find a parametric solution\nto the problem of optimal exchange of privacy for money, and obtain a\nclosed-form expression and characterize the trade-off between\nprofile-disclosure risk and economic reward for several interesting cases. \n\n"}
{"id": "1701.01590", "contents": "Title: Detecting Arbitrary Attacks Using Continuous Secured Side Information in\n  Wireless Networks Abstract: This paper focuses on Byzantine attack detection for Gaussian two-hop one-way\nrelay network, where an amplify-and-forward relay may conduct Byzantine attacks\nby forwarding altered symbols to the destination. For facilitating attack\ndetection, we utilize the openness of wireless medium to make the destination\nobserve some secured signals that are not attacked. Then, a detection scheme is\ndeveloped for the destination by using its secured observations to\nstatistically check other observations from the relay. On the other hand,\nnotice the Gaussian channel is continuous, which allows the possible Byzantine\nattacks to be conducted within continuous alphabet(s). The existing work on\ndiscrete channel is not applicable for investigating the performance of the\nproposed scheme. The main contribution of this paper is to prove that if and\nonly if the wireless relay network satisfies a non-manipulable channel\ncondition, the proposed detection scheme achieves asymptotic errorless\nperformance against arbitrary attacks that allow the stochastic distributions\nof altered symbols to vary arbitrarily and depend on each other. No pre-shared\nsecret or secret transmission is needed for the detection. Furthermore, we also\nprove that the relay network is non-manipulable as long as all channel\ncoefficients are non-zero, which is not essential restrict for many practical\nsystems. \n\n"}
{"id": "1701.02120", "contents": "Title: Differentially Private Neighborhood-based Recommender Systems Abstract: Privacy issues of recommender systems have become a hot topic for the society\nas such systems are appearing in every corner of our life. In contrast to the\nfact that many secure multi-party computation protocols have been proposed to\nprevent information leakage in the process of recommendation computation, very\nlittle has been done to restrict the information leakage from the\nrecommendation results. In this paper, we apply the differential privacy\nconcept to neighborhood-based recommendation methods (NBMs) under a\nprobabilistic framework. We first present a solution, by directly calibrating\nLaplace noise into the training process, to differential-privately find the\nmaximum a posteriori parameters similarity. Then we connect differential\nprivacy to NBMs by exploiting a recent observation that sampling from the\nscaled posterior distribution of a Bayesian model results in provably\ndifferentially private systems. Our experiments show that both solutions allow\npromising accuracy with a modest privacy budget, and the second solution yields\nbetter accuracy if the sampling asymptotically converges. We also compare our\nsolutions to the recent differentially private matrix factorization (MF)\nrecommender systems, and show that our solutions achieve better accuracy when\nthe privacy budget is reasonably small. This is an interesting result because\nMF systems often offer better accuracy when differential privacy is not\napplied. \n\n"}
{"id": "1701.02446", "contents": "Title: SIPHON: Towards Scalable High-Interaction Physical Honeypots Abstract: In recent years, the emerging Internet-of-Things (IoT) has led to rising\nconcerns about the security of networked embedded devices. In this work, we\nfocus on the adaptation of Honeypots for improving the security of IoTs.\nLow-interaction honeypots are used so far in the context of IoT. Such honeypots\nare limited and easily detectable, and thus, there is a need to find ways how\nto develop high-interaction, reliable, IoT honeypots that will attract skilled\nattackers. In this work, we propose the SIPHON architecture - a Scalable\nhigh-Interaction Honeypot platform for IoT devices. Our architecture leverages\nIoT devices that are physically at one location and are connected to the\nInternet through so-called wormholes distributed around the world. The\nresulting architecture allows exposing few physical devices over a large number\nof geographically distributed IP addresses. We demonstrate the proposed\narchitecture in a large scale experiment with 39 wormhole instances in 16\ncities in 9 countries. Based on this setup, six physical IP cameras, one NVR\nand one IP printer are presented as 85 real IoT devices on the Internet,\nattracting a daily traffic of 700MB for a period of two months. A preliminary\nanalysis of the collected traffic indicates that devices in some cities\nattracted significantly more traffic than others (ranging from 600 000 incoming\nTCP connections for the most popular destination to less than 50000 for the\nleast popular). We recorded over 400 brute-force login attempts to the\nweb-interface of our devices using a total of 1826 distinct credentials, from\nwhich 11 attempts were successful. Moreover, we noted login attempts to Telnet\nand SSH ports some of which used credentials found in the recently disclosed\nMirai malware. \n\n"}
{"id": "1701.07676", "contents": "Title: Mobile phone identification through the built-in magnetometers Abstract: Mobile phones identification through their built in components has been\ndemonstrated in literature for various types of sensors including the camera,\nmicrophones and accelerometers. The identification is performed by the\nexploitation of the small but significant differences in the electronic\ncircuits generated during the production process. Thus, these differences\nbecome an intrinsic property of the electronic components, which can be\ndetected and become an unique fingerprint of the component and of the mobile\nphone. In this paper, we investigate the identification of mobile phones\nthrough their builtin magnetometers, which has not been reported in literature\nyet. Magnetometers are stimulated with different waveforms using a solenoid\nconnected to a computer s audio board. The identification is performed\nanalyzing the digital output of the magnetometer through the use of statistical\nfeatures and the Support Vector Machine (SVM) machine learning algorithm. We\nprove that this technique can distinguish different models and brands with very\nhigh accuracy but it can only distinguish phones of the same model with limited\naccuracy. \n\n"}
{"id": "1701.07860", "contents": "Title: JSForce: A Forced Execution Engine for Malicious JavaScript Detection Abstract: The drastic increase of JavaScript exploitation attacks has led to a strong\ninterest in developing techniques to enable malicious JavaScript analysis.\nExisting analysis tech- niques fall into two general categories: static\nanalysis and dynamic analysis. Static analysis tends to produce inaccurate\nresults (both false positive and false negative) and is vulnerable to a wide\nseries of obfuscation techniques. Thus, dynamic analysis is constantly gaining\npopularity for exposing the typical features of malicious JavaScript. However,\nexisting dynamic analysis techniques possess limitations such as limited code\ncoverage and incomplete environment setup, leaving a broad attack surface for\nevading the detection. To overcome these limitations, we present the design and\nimplementation of a novel JavaScript forced execution engine named JSForce\nwhich drives an arbitrary JavaScript snippet to execute along different paths\nwithout any input or environment setup. We evaluate JSForce using 220,587 HTML\nand 23,509 PDF real- world samples. Experimental results show that by adopting\nour forced execution engine, the malicious JavaScript detection rate can be\nsubstantially boosted by 206.29% using same detection policy without any\nnoticeable false positive increase. We also make JSForce publicly available as\nan online service and will release the source code to the security community\nupon the acceptance for publication. \n\n"}
{"id": "1701.08308", "contents": "Title: Anonymous or not? Understanding the Factors Affecting Personal Mobile\n  Data Disclosure Abstract: The wide adoption of mobile devices and social media platforms have\ndramatically increased the collection and sharing of personal information. More\nand more frequently, users are called to take decisions concerning the\ndisclosure of their personal information. In this study, we investigate the\nfactors affecting users' choices toward the disclosure of their personal data,\nincluding not only their demographic and self-reported individual\ncharacteristics, but also their social interactions and their mobility patterns\ninferred from months of mobile phone data activity. We report the findings of a\nfield-study conducted with a community of 63 subjects provided with (i) a\nsmart-phone and (ii) a Personal Data Store (PDS) enabling them to control the\ndisclosure of their data. We monitor the sharing behavior of our participants\nthrough the PDS, and evaluate the contribution of different factors affecting\ntheir disclosing choices of location and social interaction data. Our analysis\nshows that social interaction inferred by mobile phones is an important factor\nrevealing willingness to share, regardless of the data type. In addition, we\nprovide further insights on the individual traits relevant to the prediction of\nsharing behavior. \n\n"}
{"id": "1701.08312", "contents": "Title: ClipAudit: A Simple Risk-Limiting Post-Election Audit Abstract: We propose a simple risk-limiting audit for elections, ClipAudit. To\ndetermine whether candidate A (the reported winner) actually beat candidate B\nin a plurality election, ClipAudit draws ballots at random, without\nreplacement, until either all cast ballots have been drawn, or until \\[ a - b\n\\ge \\beta \\sqrt{a+b}\n  \\] where $a$ is the number of ballots in the sample for the reported winner\nA, and $b$ is the number of ballots in the sample for opponent B, and where\n$\\beta$ is a constant determined a priori as a function of the number $n$ of\nballots cast and the risk-limit $\\alpha$. ClipAudit doesn't depend on the\nunofficial margin (as does Bravo). We show how to extend ClipAudit to contests\nwith multiple winners or losers, or to multiple contests. \n\n"}
{"id": "1701.08421", "contents": "Title: Decentralized Prediction Market without Arbiters Abstract: We consider a prediction market in which all aspects are controlled by market\nforces, in particular the correct outcomes of events are decided by the market\nitself rather than by trusted arbiters. This kind of a decentralized prediction\nmarket can sustain betting on events whose outcome may remain unresolved for a\nlong or even unlimited time period, and can facilitate trades among\nparticipants who are spread across diverse geographical locations, may wish to\nremain anonymous and/or avoid burdensome identification procedures, and are\ndistrustful of each other. We describe how a cryptocurrency such as Bitcoin can\nbe enhanced to accommodate a truly decentralized prediction market, by\nemploying an innovative variant of the Colored Coins concept. We examine the\ngame-theoretic properties of our design, and offer extensions that enable other\nfinancial instruments as well as real-time exchange. \n\n"}
{"id": "1701.08644", "contents": "Title: Security Game with Non-additive Utilities and Multiple Attacker\n  Resources Abstract: There has been significant interest in studying security games for modeling\nthe interplay of attacks and defenses on various systems involving critical\ninfrastructure, financial system security, political campaigns, and civil\nsafeguarding. However, existing security game models typically either assume\nadditive utility functions, or that the attacker can attack only one target.\nSuch assumptions lead to tractable analysis, but miss key inherent dependencies\nthat exist among different targets in current complex networks. In this paper,\nwe generalize the classical security game models to allow for non-additive\nutility functions. We also allow attackers to be able to attack multiple\ntargets. We examine such a general security game from a theoretical perspective\nand provide a unified view. In particular, we show that each security game is\nequivalent to a combinatorial optimization problem over a set system\n$\\varepsilon$, which consists of defender's pure strategy space. The key\ntechnique we use is based on the transformation, projection of a polytope, and\nthe elipsoid method. This work settles several open questions in security game\ndomain and significantly extends the state of-the-art of both the polynomial\nsolvable and NP-hard class of the security game. \n\n"}
{"id": "1702.00535", "contents": "Title: Composing Differential Privacy and Secure Computation: A case study on\n  scaling private record linkage Abstract: Private record linkage (PRL) is the problem of identifying pairs of records\nthat are similar as per an input matching rule from databases held by two\nparties that do not trust one another. We identify three key desiderata that a\nPRL solution must ensure: 1) perfect precision and high recall of matching\npairs, 2) a proof of end-to-end privacy, and 3) communication and computational\ncosts that scale subquadratically in the number of input records. We show that\nall of the existing solutions for PRL - including secure 2-party computation\n(S2PC), and their variants that use non-private or differentially private (DP)\nblocking to ensure subquadratic cost - violate at least one of the three\ndesiderata. In particular, S2PC techniques guarantee end-to-end privacy but\nhave either low recall or quadratic cost. In contrast, no end-to-end privacy\nguarantee has been formalized for solutions that achieve subquadratic cost.\nThis is true even for solutions that compose DP and S2PC: DP does not permit\nthe release of any exact information about the databases, while S2PC algorithms\nfor PRL allow the release of matching records.\n  In light of this deficiency, we propose a novel privacy model, called output\nconstrained differential privacy, that shares the strong privacy protection of\nDP, but allows for the truthful release of the output of a certain function\napplied to the data. We apply this to PRL, and show that protocols satisfying\nthis privacy model permit the disclosure of the true matching records, but\ntheir execution is insensitive to the presence or absence of a single\nnon-matching record. We find that prior work that combine DP and S2PC\ntechniques even fail to satisfy this end-to-end privacy model. Hence, we\ndevelop novel protocols that provably achieve this end-to-end privacy\nguarantee, together with the other two desiderata of PRL. \n\n"}
{"id": "1702.02284", "contents": "Title: Adversarial Attacks on Neural Network Policies Abstract: Machine learning classifiers are known to be vulnerable to inputs maliciously\nconstructed by adversaries to force misclassification. Such adversarial\nexamples have been extensively studied in the context of computer vision\napplications. In this work, we show adversarial attacks are also effective when\ntargeting neural network policies in reinforcement learning. Specifically, we\nshow existing adversarial example crafting techniques can be used to\nsignificantly degrade test-time performance of trained policies. Our threat\nmodel considers adversaries capable of introducing small perturbations to the\nraw input of the policy. We characterize the degree of vulnerability across\ntasks and training algorithms, for a subclass of adversarial-example attacks in\nwhite-box and black-box settings. Regardless of the learned task or training\nalgorithm, we observe a significant drop in performance, even with small\nadversarial perturbations that do not interfere with human perception. Videos\nare available at http://rll.berkeley.edu/adversarial. \n\n"}
{"id": "1702.02450", "contents": "Title: Ironwood Meta Key Agreement and Authentication Protocol Abstract: Number theoretic public-key solutions, currently used in many applications\nworldwide, will be subject to various quantum attacks, making them less\nattractive for longer-term use. Certain group theoretic constructs are now\nshowing promise in providing quantum-resistant cryptographic primitives, and\nmay provide suitable alternatives for those looking to address known quantum\nattacks. In this paper, we introduce a new protocol called a Meta Key Agreement\nand Authentication Protocol (MKAAP) that has some characteristics of a\npublic-key solution and some of a shared-key solution. Specifically it has the\ndeployment benefits of a public-key system, allowing two entities that have\nnever met before to authenticate without requiring real-time access to a\nthird-party, but does require secure provisioning of key material from a\ntrusted key distribution system (similar to a symmetric system) prior to\ndeployment. We then describe a specific MKAAP instance, the Ironwood MKAAP,\ndiscuss its security, and show how it resists certain quantum attacks such as\nShor's algorithm or Grover's quantum search algorithm. We also show Ironwood\nimplemented on several ``internet of things'' (IoT devices), measure its\nperformance, and show how it performs significantly better than ECC using fewer\ndevice resources. \n\n"}
{"id": "1702.02566", "contents": "Title: Design of Distributed Voting Systems Abstract: Countries like Estonia, Norway or Australia developed electronic voting\nsystems, which could be used to realize parliamentary elections with the help\nof personal computers and the Internet. These systems are completely different\nin their design and their way to solve the same problem. In this thesis, we\nanalyze some of the largest real-world systems, describe their building blocks\nand their general design to focus on possible problems in these electronic\nvoting systems.\n  Furthermore, we present a template for an e-voting system, which we designed\nto try to fulfill the preliminaries and requirements of a secure electronic\nvoting system. We use the experiences and the building blocks of existing\nsystems to combine them to another more secure system. Afterwards, we compare\nour concept with real-world systems to evaluate the fulfillments of the\nrequirements. Conclusively, we discuss the occurring problems when designing a\nsecure system.\n  Peer-to-peer networks provide many advantages, like decentralization, which\nmight be applicable to electronic voting systems. Therefore, we take a look on\nthe distributed database called blockchain and the usage in a peer-to-peer\nvoting system. Our contribution to this topic is a modification of the\nproof-of-stake, which enables the usage of common devices, like smartphones or\ntablets, for the blockchain verification and inclusion of new ballots to the\nchain. This proof does not need much computing power and has a lower carbon\nfootprint than the proof-of-work in the Bitcoin protocol. \n\n"}
{"id": "1702.02721", "contents": "Title: Analytic Theory to Differential Privacy Abstract: The purpose of this paper is to develop a mathematical analysis theory to\nsolve differential privacy problems. The heart of our approaches is to use\nanalytic tools to characterize the correlations among the outputs of different\ndatasets, which makes it feasible to represent a differentially private\nmechanism with minimal number of parameters. These results are then used to\nconstruct differentially private mechanisms analytically. Furthermore, our\napproaches are universal to almost all query functions. We believe that the\napproaches and results of this paper are indispensable complements to the\ncurrent studies of differential privacy that are ruled by the ad hoc and\nalgorithmic approaches. \n\n"}
{"id": "1702.02867", "contents": "Title: Double spend races Abstract: We correct the double spend race analysis given in Nakamoto's foundational\nBitcoin article and give a closed-form formula for the probability of success\nof a double spend attack using the Regularized Incomplete Beta Function. We\ngive a proof of the exponential decay on the number of confirmations, often\ncited in the literature, and find an asymptotic formula. Larger number of\nconfirmations are necessary compared to those given by Nakamoto. We also\ncompute the probability conditional to the known validation time of the blocks.\nThis provides a finer risk analysis than the classical one. \n\n"}
{"id": "1702.02970", "contents": "Title: The Price of Selection in Differential Privacy Abstract: In the differentially private top-$k$ selection problem, we are given a\ndataset $X \\in \\{\\pm 1\\}^{n \\times d}$, in which each row belongs to an\nindividual and each column corresponds to some binary attribute, and our goal\nis to find a set of $k \\ll d$ columns whose means are approximately as large as\npossible. Differential privacy requires that our choice of these $k$ columns\ndoes not depend too much on any on individual's dataset. This problem can be\nsolved using the well known exponential mechanism and composition properties of\ndifferential privacy. In the high-accuracy regime, where we require the error\nof the selection procedure to be to be smaller than the so-called sampling\nerror $\\alpha \\approx \\sqrt{\\ln(d)/n}$, this procedure succeeds given a dataset\nof size $n \\gtrsim k \\ln(d)$.\n  We prove a matching lower bound, showing that a dataset of size $n \\gtrsim k\n\\ln(d)$ is necessary for private top-$k$ selection in this high-accuracy\nregime. Our lower bound is the first to show that selecting the $k$ largest\ncolumns requires more data than simply estimating the value of those $k$\ncolumns, which can be done using a dataset of size just $n \\gtrsim k$. \n\n"}
{"id": "1702.03068", "contents": "Title: DBFT: Efficient Byzantine Consensus with a Weak Coordinator and its\n  Application to Consortium Blockchains Abstract: This paper introduces a deterministic Byzantine consensus algorithm that\nrelies on a new weak coordinator. As opposed to previous algorithms that cannot\nterminate in the presence of a faulty or slow coordinator, our algorithm can\nterminate even when its coordinator is faulty, hence the name weak coordinator.\nThe key idea is to allow processes to complete asynchronous rounds as soon as\nthey receive a threshold of messages, instead of having to wait for a message\nfrom a coordinator that may be slow.\n  The resulting algorithm assumes partial synchrony, is resilience optimal,\ntime optimal and does not need signatures. Our presentation is didactic: we\nfirst present a simple safe binary Byzantine consensus algorithm, modify it to\nensure termination, and finally present an optimized reduction from multivalue\nconsensus to binary consensus that may terminate in 4 message delays. To\nevaluate our algorithm, we deployed it on 100 machines distributed in 5\ndatacenters across different continents and compared its performance against\nthe randomized solution from Mostefaoui, Moumem and Raynal [PODC14] that\nterminates in O(1) rounds in expectation. Our algorithm always outperforms the\nlatter even in the presence of Byzantine behaviors. Our algorithm has a\nsubsecond average latency in most of our geo-distributed experiments, even when\nattacked by a well-engineered coalition of Byzantine processes. \n\n"}
{"id": "1702.03379", "contents": "Title: Secure Fingerprint Alignment and Matching Protocols Abstract: We present three private fingerprint alignment and matching protocols, based\non what are considered to be the most precise and efficient fingerprint\nrecognition algorithms, which use minutia points. Our protocols allow two or\nmore honest-but-curious parties to compare their respective privately-held\nfingerprints in a secure way such that they each learn nothing more than an\naccurate score of how well the fingerprints match. To the best of our\nknowledge, this is the first time fingerprint alignment based on minutiae is\nconsidered in a secure computation framework. We build secure fingerprint\nalignment and matching protocols in both the two-party setting using garbled\ncircuit evaluation and in the multi-party setting using secret sharing\ntechniques. In addition to providing precise and efficient secure fingerprint\nalignment and matching, our contributions include the design of a number of\nsecure sub-protocols for complex operations such as sine, cosine, arctangent,\nsquare root, and selection, which are likely to be of independent interest. \n\n"}
{"id": "1702.04421", "contents": "Title: Satoshi Risk Tables Abstract: We present Bitcoin Security Tables computing the probability of success\np(z,q,t) of a double spend attack by an attacker controlling a share q of the\nhashrate after z confirmations in time t. \n\n"}
{"id": "1702.05812", "contents": "Title: Sprites and State Channels: Payment Networks that Go Faster than\n  Lightning Abstract: Bitcoin, Ethereum and other blockchain-based cryptocurrencies, as deployed\ntoday, cannot scale for wide-spread use. A leading approach for cryptocurrency\nscaling is a smart contract mechanism called a payment channel which enables\ntwo mutually distrustful parties to transact efficiently (and only requires a\nsingle transaction in the blockchain to set-up). Payment channels can be linked\ntogether to form a payment network, such that payments between any two parties\ncan (usually) be routed through the network along a path that connects them.\nCrucially, both parties can transact without trusting hops along the route.\n  In this paper, we propose a novel variant of payment channels, called\nSprites, that reduces the worst-case \"collateral cost\" that each hop along the\nroute may incur. The benefits of Sprites are two-fold. 1) In Lightning Network,\na payment across a path of $\\ell$ channels requires locking up collateral for\n$\\Theta(\\ell\\Delta)$ time, where $\\Delta$ is the time to commit an on-chain\ntransaction. Sprites reduces this cost to $O(\\ell + \\Delta)$. 2) Unlike prior\nwork, Sprites supports partial withdrawals and deposits, during which the\nchannel can continue to operate without interruption.\n  In evaluating Sprites we make several additional contributions. First, our\nsimulation-based security model is the first formalism to model timing\nguarantees in payment channels. Our construction is also modular, making use of\na generic abstraction from folklore, called the \"state channel,\" which we are\nthe first to formalize. We also provide a simulation framework for payment\nnetwork protocols, which we use to confirm that the Sprites construction\nmitigates against throughput-reducing attacks. \n\n"}
{"id": "1702.05983", "contents": "Title: Generating Adversarial Malware Examples for Black-Box Attacks Based on\n  GAN Abstract: Machine learning has been used to detect new malware in recent years, while\nmalware authors have strong motivation to attack such algorithms. Malware\nauthors usually have no access to the detailed structures and parameters of the\nmachine learning models used by malware detection systems, and therefore they\ncan only perform black-box attacks. This paper proposes a generative\nadversarial network (GAN) based algorithm named MalGAN to generate adversarial\nmalware examples, which are able to bypass black-box machine learning based\ndetection models. MalGAN uses a substitute detector to fit the black-box\nmalware detection system. A generative network is trained to minimize the\ngenerated adversarial examples' malicious probabilities predicted by the\nsubstitute detector. The superiority of MalGAN over traditional gradient based\nadversarial example generation algorithms is that MalGAN is able to decrease\nthe detection rate to nearly zero and make the retraining based defensive\nmethod against adversarial examples hard to work. \n\n"}
{"id": "1702.06280", "contents": "Title: On the (Statistical) Detection of Adversarial Examples Abstract: Machine Learning (ML) models are applied in a variety of tasks such as\nnetwork intrusion detection or Malware classification. Yet, these models are\nvulnerable to a class of malicious inputs known as adversarial examples. These\nare slightly perturbed inputs that are classified incorrectly by the ML model.\nThe mitigation of these adversarial inputs remains an open problem. As a step\ntowards understanding adversarial examples, we show that they are not drawn\nfrom the same distribution than the original data, and can thus be detected\nusing statistical tests. Using thus knowledge, we introduce a complimentary\napproach to identify specific inputs that are adversarial. Specifically, we\naugment our ML model with an additional output, in which the model is trained\nto classify all adversarial inputs. We evaluate our approach on multiple\nadversarial example crafting methods (including the fast gradient sign and\nsaliency map methods) with several datasets. The statistical test flags sample\nsets containing adversarial inputs confidently at sample sizes between 10 and\n100 data points. Furthermore, our augmented model either detects adversarial\nexamples as outliers with high accuracy (> 80%) or increases the adversary's\ncost - the perturbation added - by more than 150%. In this way, we show that\nstatistical properties of adversarial examples are essential to their\ndetection. \n\n"}
{"id": "1702.06475", "contents": "Title: Mathematical Backdoors in Symmetric Encryption Systems - Proposal for a\n  Backdoored AES-like Block Cipher Abstract: Recent years have shown that more than ever governments and intelligence\nagencies try to control and bypass the cryptographic means used for the\nprotection of data. Backdooring encryption algorithms is considered as the best\nway to enforce cryptographic control. Until now, only implementation backdoors\n(at the protocol/implementation/management level) are generally considered. In\nthis paper we propose to address the most critical issue of backdoors:\nmathematical backdoors or by-design backdoors, which are put directly at the\nmathematical design of the encryption algorithm. While the algorithm may be\ntotally public, proving that there is a backdoor, identifying it and exploiting\nit, may be an intractable problem. We intend to explain that it is probably\npossible to design and put such backdoors. Considering a particular family\n(among all the possible ones), we present BEA-1, a block cipher algorithm which\nis similar to the AES and which contains a mathematical backdoor enabling an\noperational and effective cryptanalysis. The BEA-1 algorithm (80-bit block\nsize, 120-bit key, 11 rounds) is designed to resist to linear and differential\ncryptanalyses. A challenge will be proposed to the cryptography community soon.\nIts aim is to assess whether our backdoor is easily detectable and exploitable\nor not. \n\n"}
{"id": "1702.06763", "contents": "Title: DeepCloak: Masking Deep Neural Network Models for Robustness Against\n  Adversarial Samples Abstract: Recent studies have shown that deep neural networks (DNN) are vulnerable to\nadversarial samples: maliciously-perturbed samples crafted to yield incorrect\nmodel outputs. Such attacks can severely undermine DNN systems, particularly in\nsecurity-sensitive settings. It was observed that an adversary could easily\ngenerate adversarial samples by making a small perturbation on irrelevant\nfeature dimensions that are unnecessary for the current classification task. To\novercome this problem, we introduce a defensive mechanism called DeepCloak. By\nidentifying and removing unnecessary features in a DNN model, DeepCloak limits\nthe capacity an attacker can use generating adversarial samples and therefore\nincrease the robustness against such inputs. Comparing with other defensive\napproaches, DeepCloak is easy to implement and computationally efficient.\nExperimental results show that DeepCloak can increase the performance of\nstate-of-the-art DNN models against adversarial samples. \n\n"}
{"id": "1702.07107", "contents": "Title: The discrete logarithm problem over prime fields: the safe prime case.\n  The Smart attack, non-canonical lifts and logarithmic derivatives Abstract: In this brief note we connect the discrete logarithm problem over prime\nfields in the safe prime case to the logarithmic derivative. \n\n"}
{"id": "1702.07124", "contents": "Title: Trojan of Things: Embedding Malicious NFC Tags into Common Objects Abstract: We present a novel proof-of-concept attack named Trojan of Things (ToT),\nwhich aims to attack NFC- enabled mobile devices such as smartphones. The key\nidea of ToT attacks is to covertly embed maliciously programmed NFC tags into\ncommon objects routinely encountered in daily life such as banknotes, clothing,\nor furniture, which are not considered as NFC touchpoints. To fully explore the\nthreat of ToT, we develop two striking techniques named ToT device and Phantom\ntouch generator. These techniques enable an attacker to carry out various\nsevere and sophisticated attacks unbeknownst to the device owner who\nunintentionally puts the device close to a ToT. We discuss the feasibility of\nthe attack as well as the possible countermeasures against the threats of ToT\nattacks. \n\n"}
{"id": "1702.07464", "contents": "Title: Deep Models Under the GAN: Information Leakage from Collaborative Deep\n  Learning Abstract: Deep Learning has recently become hugely popular in machine learning,\nproviding significant improvements in classification accuracy in the presence\nof highly-structured and large databases.\n  Researchers have also considered privacy implications of deep learning.\nModels are typically trained in a centralized manner with all the data being\nprocessed by the same training algorithm. If the data is a collection of users'\nprivate data, including habits, personal pictures, geographical positions,\ninterests, and more, the centralized server will have access to sensitive\ninformation that could potentially be mishandled. To tackle this problem,\ncollaborative deep learning models have recently been proposed where parties\nlocally train their deep learning structures and only share a subset of the\nparameters in the attempt to keep their respective training sets private.\nParameters can also be obfuscated via differential privacy (DP) to make\ninformation extraction even more challenging, as proposed by Shokri and\nShmatikov at CCS'15.\n  Unfortunately, we show that any privacy-preserving collaborative deep\nlearning is susceptible to a powerful attack that we devise in this paper. In\nparticular, we show that a distributed, federated, or decentralized deep\nlearning approach is fundamentally broken and does not protect the training\nsets of honest participants. The attack we developed exploits the real-time\nnature of the learning process that allows the adversary to train a Generative\nAdversarial Network (GAN) that generates prototypical samples of the targeted\ntraining set that was meant to be private (the samples generated by the GAN are\nintended to come from the same distribution as the training data).\nInterestingly, we show that record-level DP applied to the shared parameters of\nthe model, as suggested in previous work, is ineffective (i.e., record-level DP\nis not designed to address our attack). \n\n"}
{"id": "1703.00207", "contents": "Title: A Quantum-Classical Scheme towards Quantum Functional Encryption Abstract: Quantum encryption is a well studied problem for both classical and quantum\ninformation. However, little is known about quantum encryption schemes which\nenable the user, under different keys, to learn different functions of the\nplaintext, given the ciphertext. In this paper, we give a novel one-bit\nsecret-key quantum encryption scheme, a classical extension of which allows\ndifferent key holders to learn different length subsequences of the plaintext\nfrom the ciphertext. We prove our quantum-classical scheme secure under the\nnotions of quantum semantic security, quantum entropic indistinguishability,\nand recent security definitions from the field of functional encryption. \n\n"}
{"id": "1703.00263", "contents": "Title: Quantum Information Set Decoding Algorithms Abstract: The security of code-based cryptosystems such as the McEliece cryptosystem\nrelies primarily on the difficulty of decoding random linear codes. The best\ndecoding algorithms are all improvements of an old algorithm due to Prange:\nthey are known under the name of information set decoding techniques. It is\nalso important to assess the security of such cryptosystems against a quantum\ncomputer. This research thread started in Overbeck and Sendrier's 2009 survey\non code-based cryptography, and the best algorithm to date has been Bernstein's\nquantising of the simplest information set decoding algorithm, namely Prange's\nalgorithm. It consists in applying Grover's quantum search to obtain a\nquadratic speed-up of Prange's algorithm. In this paper, we quantise other\ninformation set decoding algorithms by using quantum walk techniques which were\ndevised for the subset-sum problem by Bernstein, Jeffery, Lange and Meurer.\nThis results in improving the worst-case complexity of $2^{0.06035n}$ of\nBernstein's algorithm to $2^{0.05869n}$ with the best algorithm presented here\n(where $n$ is the codelength). \n\n"}
{"id": "1703.00366", "contents": "Title: What Does The Crowd Say About You? Evaluating Aggregation-based Location\n  Privacy Abstract: Information about people's movements and the locations they visit enables an\nincreasing number of mobility analytics applications, e.g., in the context of\nurban and transportation planning, In this setting, rather than collecting or\nsharing raw data, entities often use aggregation as a privacy protection\nmechanism, aiming to hide individual users' location traces. Furthermore, to\nbound information leakage from the aggregates, they can perturb the input of\nthe aggregation or its output to ensure that these are differentially private.\n  In this paper, we set to evaluate the impact of releasing aggregate location\ntime-series on the privacy of individuals contributing to the aggregation. We\nintroduce a framework allowing us to reason about privacy against an adversary\nattempting to predict users' locations or recover their mobility patterns. We\nformalize these attacks as inference problems, and discuss a few strategies to\nmodel the adversary's prior knowledge based on the information she may have\naccess to. We then use the framework to quantify the privacy loss stemming from\naggregate location data, with and without the protection of differential\nprivacy, using two real-world mobility datasets. We find that aggregates do\nleak information about individuals' punctual locations and mobility profiles.\nThe density of the observations, as well as timing, play important roles, e.g.,\nregular patterns during peak hours are better protected than sporadic\nmovements. Finally, our evaluation shows that both output and input\nperturbation offer little additional protection, unless they introduce large\namounts of noise ultimately destroying the utility of the data. \n\n"}
{"id": "1703.00536", "contents": "Title: The Loopix Anonymity System Abstract: We present Loopix, a low-latency anonymous communication system that provides\nbi-directional 'third-party' sender and receiver anonymity and unobservability.\nLoopix leverages cover traffic and brief message delays to provide anonymity\nand achieve traffic analysis resistance, including against a global network\nadversary. Mixes and clients self-monitor the network via loops of traffic to\nprovide protection against active attacks, and inject cover traffic to provide\nstronger anonymity and a measure of sender and receiver unobservability.\nService providers mediate access in and out of a stratified network of Poisson\nmix nodes to facilitate accounting and off-line message reception, as well as\nto keep the number of links in the system low, and to concentrate cover\ntraffic. We provide a theoretical analysis of the Poisson mixing strategy as\nwell as an empirical evaluation of the anonymity provided by the protocol and a\nfunctional implementation that we analyze in terms of scalability by running it\non AWS EC2. We show that a Loopix relay can handle upwards of 300 messages per\nsecond, at a small delay overhead of less than 1.5 ms on top of the delays\nintroduced into messages to provide security. Overall message latency is in the\norder of seconds - which is low for a mix-system. Furthermore, many mix nodes\ncan be securely added to a stratified topology to scale throughput without\nsacrificing anonymity. \n\n"}
{"id": "1703.01101", "contents": "Title: Adversarial Examples for Semantic Image Segmentation Abstract: Machine learning methods in general and Deep Neural Networks in particular\nhave shown to be vulnerable to adversarial perturbations. So far this\nphenomenon has mainly been studied in the context of whole-image\nclassification. In this contribution, we analyse how adversarial perturbations\ncan affect the task of semantic segmentation. We show how existing adversarial\nattackers can be transferred to this task and that it is possible to create\nimperceptible adversarial perturbations that lead a deep network to misclassify\nalmost all pixels of a chosen class while leaving network prediction nearly\nunchanged outside this class. \n\n"}
{"id": "1703.02200", "contents": "Title: Stealthy Malware Traffic - Not as Innocent as It Looks Abstract: Malware is constantly evolving. Although existing countermeasures have\nsuccess in malware detection, corresponding counter-countermeasures are always\nemerging. In this study, a counter-countermeasure that avoids network-based\ndetection approaches by camouflaging malicious traffic as an innocuous protocol\nis presented. The approach includes two steps: Traffic format transformation\nand side-channel massage (SCM). Format transforming encryption (FTE) translates\nprotocol syntax to mimic another innocuous protocol while SCM obscures traffic\nside-channels. The proposed approach is illustrated by transforming Zeus botnet\n(Zbot) Command and Control (C&C) traffic into smart grid Phasor Measurement\nUnit (PMU) data. The experimental results show that the transformed traffic is\nidentified by Wireshark as synchrophasor protocol, and the transformed protocol\nfools current side-channel attacks. Moreover, it is shown that a real smart\ngrid Phasor Data Concentrator (PDC) accepts the false PMU data. \n\n"}
{"id": "1703.02577", "contents": "Title: SAFETY: Secure gwAs in Federated Environment Through a hYbrid solution\n  with Intel SGX and Homomorphic Encryption Abstract: Recent studies demonstrate that effective healthcare can benefit from using\nthe human genomic information. For instance, analysis of tumor genomes has\nrevealed 140 genes whose mutations contribute to cancer. As a result, many\ninstitutions are using statistical analysis of genomic data, which are mostly\nbased on genome-wide association studies (GWAS). GWAS analyze genome sequence\nvariations in order to identify genetic risk factors for diseases. These\nstudies often require pooling data from different sources together in order to\nunravel statistical patterns or relationships between genetic variants and\ndiseases. In this case, the primary challenge is to fulfill one major\nobjective: accessing multiple genomic data repositories for collaborative\nresearch in a privacy-preserving manner. Due to the sensitivity and privacy\nconcerns regarding the genomic data, multi-jurisdictional laws and policies of\ncross-border genomic data sharing are enforced among different regions of the\nworld. In this article, we present SAFETY, a hybrid framework, which can\nsecurely perform GWAS on federated genomic datasets using homomorphic\nencryption and recently introduced secure hardware component of Intel Software\nGuard Extensions (Intel SGX) to ensure high efficiency and privacy at the same\ntime. Different experimental settings show the efficacy and applicability of\nsuch hybrid framework in secure conduction of GWAS. To the best of our\nknowledge, this hybrid use of homomorphic encryption along with Intel SGX is\nnot proposed or experimented to this date. Our proposed framework, SAFETY is up\nto 4.82 times faster than the best existing secure computation technique. \n\n"}
{"id": "1703.02868", "contents": "Title: Discriminative models for multi-instance problems with tree-structure Abstract: Modeling network traffic is gaining importance in order to counter modern\nthreats of ever increasing sophistication. It is though surprisingly difficult\nand costly to construct reliable classifiers on top of telemetry data due to\nthe variety and complexity of signals that no human can manage to interpret in\nfull. Obtaining training data with sufficiently large and variable body of\nlabels can thus be seen as prohibitive problem. The goal of this work is to\ndetect infected computers by observing their HTTP(S) traffic collected from\nnetwork sensors, which are typically proxy servers or network firewalls, while\nrelying on only minimal human input in model training phase. We propose a\ndiscriminative model that makes decisions based on all computer's traffic\nobserved during predefined time window (5 minutes in our case). The model is\ntrained on collected traffic samples over equally sized time window per large\nnumber of computers, where the only labels needed are human verdicts about the\ncomputer as a whole (presumed infected vs. presumed clean). As part of training\nthe model itself recognizes discriminative patterns in traffic targeted to\nindividual servers and constructs the final high-level classifier on top of\nthem. We show the classifier to perform with very high precision, while the\nlearned traffic patterns can be interpreted as Indicators of Compromise. In the\nfollowing we implement the discriminative model as a neural network with\nspecial structure reflecting two stacked multi-instance problems. The main\nadvantages of the proposed configuration include not only improved accuracy and\nability to learn from gross labels, but also automatic learning of server types\n(together with their detectors) which are typically visited by infected\ncomputers. \n\n"}
{"id": "1703.02874", "contents": "Title: A Study of MAC Address Randomization in Mobile Devices and When it Fails Abstract: MAC address randomization is a privacy technique whereby mobile devices\nrotate through random hardware addresses in order to prevent observers from\nsingling out their traffic or physical location from other nearby devices.\nAdoption of this technology, however, has been sporadic and varied across\ndevice manufacturers. In this paper, we present the first wide-scale study of\nMAC address randomization in the wild, including a detailed breakdown of\ndifferent randomization techniques by operating system, manufacturer, and model\nof device.\n  We then identify multiple flaws in these implementations which can be\nexploited to defeat randomization as performed by existing devices. First, we\nshow that devices commonly make improper use of randomization by sending\nwireless frames with the true, global address when they should be using a\nrandomized address. We move on to extend the passive identification techniques\nof Vanhoef et al. to effectively defeat randomization in ~96% of Android\nphones. Finally, we show a method that can be used to track 100% of devices\nusing randomization, regardless of manufacturer, by exploiting a previously\nunknown flaw in the way existing wireless chipsets handle low-level control\nframes. \n\n"}
{"id": "1703.03473", "contents": "Title: Efficiency Optimizations on Yao's Garbled Circuits and Their Practical\n  Applications Abstract: The advance of cloud computing and big data technologies brings out major\nchanges in the ways that people make use of information systems. While those\ntechnologies extremely ease our lives, they impose the danger of compromising\nprivacy and security of data due to performing the computation on an untrusted\nremote server. Moreover, there are also many other real-world scenarios\nrequiring two or more (possibly distrustful) parties to securely compute a\nfunction without leaking their respective inputs to each other. In this\nrespect, various secure computation mechanisms have been proposed in order to\nprotect users' data privacy. Yao's garbled circuit protocol is one of the most\npowerful solutions for this problem. In this thesis, we first describe the\nYao's protocol in detail, and include the complete list of optimizations over\nthe Yao's protocol. We also compare their advantages in terms of communication\nand computation complexities, and analyse their compatibility with each other.\nWe also look into generic Yao implementations (including garbled RAM) to\ndemonstrate the use of this powerful tool in practice. We compare those generic\nimplementations in terms of their use of garbled circuit optimizations. We also\ncover the specific real-world applications for further illustration. Moreover,\nin some scenarios, the functionality itself may also need to be kept private\nwhich leads to an ideal solution of secure computation problem. In this\ndirection, we finally cover the problem of Private Function Evaluation, in\nparticular for the 2-party case where garbled circuits have an important role.\nWe finally analyse the generic mechanism of Mohassel et al. and contribute to\nit by proposing a new technique for the computation of the number of possible\ncircuit mappings. \n\n"}
{"id": "1703.04285", "contents": "Title: Practical cryptographic strategies in the post-quantum era Abstract: We review new frontiers in information security technologies in\ncommunications and distributed storage technologies with the use of classical,\nquantum, hybrid classical-quantum, and post-quantum cryptography. We analyze\nthe current state-of-the-art, critical characteristics, development trends, and\nlimitations of these techniques for application in enterprise information\nprotection systems. An approach concerning the selection of practical\nencryption technologies for enterprises with branched communication networks is\nintroduced. \n\n"}
{"id": "1703.06322", "contents": "Title: An empirical analysis of smart contracts: platforms, applications, and\n  design patterns Abstract: Smart contracts are computer programs that can be consistently executed by a\nnetwork of mutually distrusting nodes, without the arbitration of a trusted\nauthority. Because of their resilience to tampering, smart contracts are\nappealing in many scenarios, especially in those which require transfers of\nmoney to respect certain agreed rules (like in financial services and in\ngames). Over the last few years many platforms for smart contracts have been\nproposed, and some of them have been actually implemented and used. We study\nhow the notion of smart contract is interpreted in some of these platforms.\nFocussing on the two most widespread ones, Bitcoin and Ethereum, we quantify\nthe usage of smart contracts in relation to their application domain. We also\nanalyse the most common programming patterns in Ethereum, where the source code\nof smart contracts is available. \n\n"}
{"id": "1703.06748", "contents": "Title: Tactics of Adversarial Attack on Deep Reinforcement Learning Agents Abstract: We introduce two tactics to attack agents trained by deep reinforcement\nlearning algorithms using adversarial examples, namely the strategically-timed\nattack and the enchanting attack. In the strategically-timed attack, the\nadversary aims at minimizing the agent's reward by only attacking the agent at\na small subset of time steps in an episode. Limiting the attack activity to\nthis subset helps prevent detection of the attack by the agent. We propose a\nnovel method to determine when an adversarial example should be crafted and\napplied. In the enchanting attack, the adversary aims at luring the agent to a\ndesignated target state. This is achieved by combining a generative model and a\nplanning algorithm: while the generative model predicts the future states, the\nplanning algorithm generates a preferred sequence of actions for luring the\nagent. A sequence of adversarial examples is then crafted to lure the agent to\ntake the preferred sequence of actions. We apply the two tactics to the agents\ntrained by the state-of-the-art deep reinforcement learning algorithm including\nDQN and A3C. In 5 Atari games, our strategically timed attack reduces as much\nreward as the uniform attack (i.e., attacking at every time step) does by\nattacking the agent 4 times less often. Our enchanting attack lures the agent\ntoward designated target states with a more than 70% success rate. Videos are\navailable at http://yenchenlin.me/adversarial_attack_RL/ \n\n"}
{"id": "1703.06986", "contents": "Title: CacheZoom: How SGX Amplifies The Power of Cache Attacks Abstract: In modern computing environments, hardware resources are commonly shared, and\nparallel computation is widely used. Parallel tasks can cause privacy and\nsecurity problems if proper isolation is not enforced. Intel proposed SGX to\ncreate a trusted execution environment within the processor. SGX relies on the\nhardware, and claims runtime protection even if the OS and other software\ncomponents are malicious. However, SGX disregards side-channel attacks. We\nintroduce a powerful cache side-channel attack that provides system adversaries\na high resolution channel. Our attack tool named CacheZoom is able to virtually\ntrack all memory accesses of SGX enclaves with high spatial and temporal\nprecision. As proof of concept, we demonstrate AES key recovery attacks on\ncommonly used implementations including those that were believed to be\nresistant in previous scenarios. Our results show that SGX cannot protect\ncritical data sensitive computations, and efficient AES key recovery is\npossible in a practical environment. In contrast to previous works which\nrequire hundreds of measurements, this is the first cache side-channel attack\non a real system that can recover AES keys with a minimal number of\nmeasurements. We can successfully recover AES keys from T-Table based\nimplementations with as few as ten measurements. \n\n"}
{"id": "1703.06992", "contents": "Title: A Framework and Comparative Analysis of Control Plane Security of SDN\n  and Conventional Networks Abstract: Software defined networking implements the network control plane in an\nexternal entity, rather than in each individual device as in conventional\nnetworks. This architectural difference implies a different design for control\nfunctions necessary for essential network properties, e.g., loop prevention and\nlink redundancy. We explore how such differences redefine the security\nweaknesses in the SDN control plane and provide a framework for comparative\nanalysis which focuses on essential network properties required by typical\nproduction networks. This enables analysis of how these properties are\ndelivered by the control planes of SDN and conventional networks, and to\ncompare security risks and mitigations. Despite the architectural difference,\nwe find similar, but not identical, exposures in control plane security if both\nnetwork paradigms provide the same network properties and are analyzed under\nthe same threat model. However, defenses vary; SDN cannot depend on edge based\nfiltering to protect its control plane, while this is arguably the primary\ndefense in conventional networks. Our concrete security analysis suggests that\na distributed SDN architecture that supports fault tolerance and consistency\nchecks is important for SDN control plane security. Our analysis methodology\nmay be of independent interest for future security analysis of SDN and\nconventional networks. \n\n"}
{"id": "1703.07474", "contents": "Title: Achieving Dalenius' Goal of Data Privacy with Practical Assumptions Abstract: Recent studies show that differential privacy is vulnerable when different\nindividuals' data in the dataset are correlated, and that there are many cases\nwhere differential privacy implies poor utility. In order to treat the two\nweaknesses, we traced the origin of differential privacy to Dalenius' goal, a\nmore rigorous privacy measure. We formalized Dalenius' goal by using Shannon's\nperfect secrecy and tried to achieve Dalenius' goal with better utility. Our\nfirst result is that, if the independence assumption is true, then differential\nprivacy is equivalent to Dalenius' goal, where the independence assumption\nassumes that each adversary has no knowledge of the correlation among different\nindividuals' data in the dataset. This implies that the security of\ndifferential privacy is based on the independence assumption. Since the\nindependence assumption is impractical, we introduced a new practical\nassumption, which assumes that each adversary is unknown to some data of the\ndataset if the dataset is large enough. Based on the assumption, we can achieve\nDalenius' goal with better utility. Furthermore, we proved a useful result\nwhich can transplant results or approaches of information theory into data\nprivacy protection. We then proved that several basic privacy\nmechanisms/channels satisfy Dalenuis' goal, such as the random response, the\nexponential, and the Gaussian privacy channels, which are respective\ncounterparts of the random response, the exponential, and the Gaussian\nmechanisms of differential privacy. Moreover, the group and the composition\nproperties were also proved. Finally, by using Yao's computational information\ntheory, we extend our model to the computational-bounded case. \n\n"}
{"id": "1703.09471", "contents": "Title: Adversarial Image Perturbation for Privacy Protection -- A Game Theory\n  Perspective Abstract: Users like sharing personal photos with others through social media. At the\nsame time, they might want to make automatic identification in such photos\ndifficult or even impossible. Classic obfuscation methods such as blurring are\nnot only unpleasant but also not as effective as one would expect. Recent\nstudies on adversarial image perturbations (AIP) suggest that it is possible to\nconfuse recognition systems effectively without unpleasant artifacts. However,\nin the presence of counter measures against AIPs, it is unclear how effective\nAIP would be in particular when the choice of counter measure is unknown. Game\ntheory provides tools for studying the interaction between agents with\nuncertainties in the strategies. We introduce a general game theoretical\nframework for the user-recogniser dynamics, and present a case study that\ninvolves current state of the art AIP and person recognition techniques. We\nderive the optimal strategy for the user that assures an upper bound on the\nrecognition rate independent of the recogniser's counter measure. Code is\navailable at https://goo.gl/hgvbNK. \n\n"}
{"id": "1704.01046", "contents": "Title: Using Echo State Networks for Cryptography Abstract: Echo state networks are simple recurrent neural networks that are easy to\nimplement and train. Despite their simplicity, they show a form of memory and\ncan predict or regenerate sequences of data. We make use of this property to\nrealize a novel neural cryptography scheme. The key idea is to assume that\nAlice and Bob share a copy of an echo state network. If Alice trains her copy\nto memorize a message, she can communicate the trained part of the network to\nBob who plugs it into his copy to regenerate the message. Considering a\nbyte-level representation of in- and output, the technique applies to arbitrary\ntypes of data (texts, images, audio files, etc.) and practical experiments\nreveal it to satisfy the fundamental cryptographic properties of diffusion and\nconfusion. \n\n"}
{"id": "1704.01155", "contents": "Title: Feature Squeezing: Detecting Adversarial Examples in Deep Neural\n  Networks Abstract: Although deep neural networks (DNNs) have achieved great success in many\ntasks, they can often be fooled by \\emph{adversarial examples} that are\ngenerated by adding small but purposeful distortions to natural examples.\nPrevious studies to defend against adversarial examples mostly focused on\nrefining the DNN models, but have either shown limited success or required\nexpensive computation. We propose a new strategy, \\emph{feature squeezing},\nthat can be used to harden DNN models by detecting adversarial examples.\nFeature squeezing reduces the search space available to an adversary by\ncoalescing samples that correspond to many different feature vectors in the\noriginal space into a single sample. By comparing a DNN model's prediction on\nthe original input with that on squeezed inputs, feature squeezing detects\nadversarial examples with high accuracy and few false positives. This paper\nexplores two feature squeezing methods: reducing the color bit depth of each\npixel and spatial smoothing. These simple strategies are inexpensive and\ncomplementary to other defenses, and can be combined in a joint detection\nframework to achieve high detection rates against state-of-the-art attacks. \n\n"}
{"id": "1704.01759", "contents": "Title: A Multi-view Context-aware Approach to Android Malware Detection and\n  Malicious Code Localization Abstract: Existing Android malware detection approaches use a variety of features such\nas security sensitive APIs, system calls, control-flow structures and\ninformation flows in conjunction with Machine Learning classifiers to achieve\naccurate detection. Each of these feature sets provides a unique semantic\nperspective (or view) of apps' behaviours with inherent strengths and\nlimitations. Meaning, some views are more amenable to detect certain attacks\nbut may not be suitable to characterise several other attacks. Most of the\nexisting malware detection approaches use only one (or a selected few) of the\naforementioned feature sets which prevent them from detecting a vast majority\nof attacks. Addressing this limitation, we propose MKLDroid, a unified\nframework that systematically integrates multiple views of apps for performing\ncomprehensive malware detection and malicious code localisation. The rationale\nis that, while a malware app can disguise itself in some views, disguising in\nevery view while maintaining malicious intent will be much harder.\n  MKLDroid uses a graph kernel to capture structural and contextual information\nfrom apps' dependency graphs and identify malice code patterns in each view.\nSubsequently, it employs Multiple Kernel Learning (MKL) to find a weighted\ncombination of the views which yields the best detection accuracy. Besides\nmulti-view learning, MKLDroid's unique and salient trait is its ability to\nlocate fine-grained malice code portions in dependency graphs (e.g.,\nmethods/classes). Through our large-scale experiments on several datasets\n(incl. wild apps), we demonstrate that MKLDroid outperforms three\nstate-of-the-art techniques consistently, in terms of accuracy while\nmaintaining comparable efficiency. In our malicious code localisation\nexperiments on a dataset of repackaged malware, MKLDroid was able to identify\nall the malice classes with 94% average recall. \n\n"}
{"id": "1704.02086", "contents": "Title: A Zero Knowledge Sumcheck and its Applications Abstract: Many seminal results in Interactive Proofs (IPs) use algebraic techniques\nbased on low-degree polynomials, the study of which is pervasive in theoretical\ncomputer science. Unfortunately, known methods for endowing such proofs with\nzero knowledge guarantees do not retain this rich algebraic structure.\n  In this work, we develop algebraic techniques for obtaining zero knowledge\nvariants of proof protocols in a way that leverages and preserves their\nalgebraic structure. Our constructions achieve unconditional (perfect) zero\nknowledge in the Interactive Probabilistically Checkable Proof (IPCP) model of\nKalai and Raz [KR08] (the prover first sends a PCP oracle, then the prover and\nverifier engage in an Interactive Proof in which the verifier may query the\nPCP).\n  Our main result is a zero knowledge variant of the sumcheck protocol [LFKN92]\nin the IPCP model. The sumcheck protocol is a key building block in many IPs,\nincluding the protocol for polynomial-space computation due to Shamir [Sha92],\nand the protocol for parallel computation due to Goldwasser, Kalai, and\nRothblum [GKR15]. A core component of our result is an algebraic commitment\nscheme, whose hiding property is guaranteed by algebraic query complexity lower\nbounds [AW09,JKRS09]. This commitment scheme can then be used to considerably\nstrengthen our previous work [BCFGRS16] that gives a sumcheck protocol with\nmuch weaker zero knowledge guarantees, itself using algebraic techniques based\non algorithms for polynomial identity testing [RS05,BW04].\n  We demonstrate the applicability of our techniques by deriving zero knowledge\nvariants of well-known protocols based on algebraic techniques, including the\nprotocols of Shamir and of Goldwasser, Kalai, and Rothblum, as well as the\nprotocol of Babai, Fortnow, and Lund [BFL91]. \n\n"}
{"id": "1704.02203", "contents": "Title: Privacy-Preserving Visual Learning Using Doubly Permuted Homomorphic\n  Encryption Abstract: We propose a privacy-preserving framework for learning visual classifiers by\nleveraging distributed private image data. This framework is designed to\naggregate multiple classifiers updated locally using private data and to ensure\nthat no private information about the data is exposed during and after its\nlearning procedure. We utilize a homomorphic cryptosystem that can aggregate\nthe local classifiers while they are encrypted and thus kept secret. To\novercome the high computational cost of homomorphic encryption of\nhigh-dimensional classifiers, we (1) impose sparsity constraints on local\nclassifier updates and (2) propose a novel efficient encryption scheme named\ndoubly-permuted homomorphic encryption (DPHE) which is tailored to sparse\nhigh-dimensional data. DPHE (i) decomposes sparse data into its constituent\nnon-zero values and their corresponding support indices, (ii) applies\nhomomorphic encryption only to the non-zero values, and (iii) employs double\npermutations on the support indices to make them secret. Our experimental\nevaluation on several public datasets shows that the proposed approach achieves\ncomparable performance against state-of-the-art visual recognition methods\nwhile preserving privacy and significantly outperforms other privacy-preserving\nmethods. \n\n"}
{"id": "1704.02883", "contents": "Title: Update-tolerant and Revocable Password Backup (Extended Version) Abstract: It is practically impossible for users to memorize a large portfolio of\nstrong and individual passwords for their online accounts. A solution is to\ngenerate passwords randomly and store them. Yet, storing passwords instead of\nmemorizing them bears the risk of loss, e.g., in situations where the device on\nwhich the passwords are stored is damaged, lost, or stolen. This makes the\ncreation of backups of the passwords indispensable. However, placing such\nbackups at secure locations to protect them as well from loss and unauthorized\naccess and keeping them up-to-date at the same time is an unsolved problem in\npractice.\n  We present PASCO, a backup solution for passwords that solves this challenge.\nPASCO backups need not to be updated, even when the user's password portfolio\nis changed. PASCO backups can be revoked without having physical access to\nthem. This prevents password leakage, even when a user loses control over a\nbackup. Additionally, we show how to extend PASCO to enable a fully\ncontrollable emergency access. It allows a user to give someone else access to\nhis passwords in urgent situations. We also present a security evaluation and\nan implementation of PASCO. \n\n"}
{"id": "1704.03387", "contents": "Title: Enhancement of Physical Layer Security Using Destination Artificial\n  Noise Based on Outage Probability Abstract: In this paper, we study using Destination Artificial Noise (DAN) besides\nSource Artificial Noise (SAN) to enhance physical layer secrecy with an outage\nprobability based approach. It is assumed that all nodes in the network (i.e.\nsource, destination and eavesdropper) are equipped with multiple antennas. In\naddition, the eavesdropper is passive and its channel state and location are\nunknown at the source and destination. In our proposed scheme, by optimized\nallocation of power to the SAN, DAN and data signal, a minimum value for the\noutage probability is guaranteed at the eavesdropper, and at the same time a\ncertain level of signal to noise ratio (SNR) at the destination is ensured. Our\nsimulation results show that using DAN along with SAN brings a significant\nenhancement in power consumption compared to methods that merely adopt SAN to\nachieve the same outage probability at the eavesdropper. \n\n"}
{"id": "1704.03606", "contents": "Title: Privacy-Aware Guessing Efficiency Abstract: We investigate the problem of guessing a discrete random variable $Y$ under a\nprivacy constraint dictated by another correlated discrete random variable $X$,\nwhere both guessing efficiency and privacy are assessed in terms of the\nprobability of correct guessing. We define $h(P_{XY}, \\epsilon)$ as the maximum\nprobability of correctly guessing $Y$ given an auxiliary random variable $Z$,\nwhere the maximization is taken over all $P_{Z|Y}$ ensuring that the\nprobability of correctly guessing $X$ given $Z$ does not exceed $\\epsilon$. We\nshow that the map $\\epsilon\\mapsto h(P_{XY}, \\epsilon)$ is strictly increasing,\nconcave, and piecewise linear, which allows us to derive a closed form\nexpression for $h(P_{XY}, \\epsilon)$ when $X$ and $Y$ are connected via a\nbinary-input binary-output channel. For $(X^n, Y^n)$ being pairs of independent\nand identically distributed binary random vectors, we similarly define\n$\\underline{h}_n(P_{X^nY^n}, \\epsilon)$ under the assumption that $Z^n$ is also\na binary vector. Then we obtain a closed form expression for\n$\\underline{h}_n(P_{X^nY^n}, \\epsilon)$ for sufficiently large, but nontrivial\nvalues of $\\epsilon$. \n\n"}
{"id": "1704.04299", "contents": "Title: An Empirical Analysis of Traceability in the Monero Blockchain Abstract: Monero is a privacy-centric cryptocurrency that allows users to obscure their\ntransactions by including chaff coins, called \"mixins,\" along with the actual\ncoins they spend. In this paper, we empirically evaluate two weaknesses in\nMonero's mixin sampling strategy. First, about 62% of transaction inputs with\none or more mixins are vulnerable to \"chain-reaction\" analysis -- that is, the\nreal input can be deduced by elimination. Second, Monero mixins are sampled in\nsuch a way that they can be easily distinguished from the real coins by their\nage distribution; in short, the real input is usually the \"newest\" input. We\nestimate that this heuristic can be used to guess the real input with 80%\naccuracy over all transactions with 1 or more mixins. Next, we turn to the\nMonero ecosystem and study the importance of mining pools and the former\nanonymous marketplace AlphaBay on the transaction volume. We find that after\nremoving mining pool activity, there remains a large amount of potentially\nprivacy-sensitive transactions that are affected by these weaknesses. We\npropose and evaluate two countermeasures that can improve the privacy of future\ntransactions. \n\n"}
{"id": "1704.07309", "contents": "Title: Computational Notions of Quantum Min-Entropy Abstract: We initiate the study of computational entropy in the quantum setting. We\ninvestigate to what extent the classical notions of computational entropy\ngeneralize to the quantum setting, and whether quantum analogues of classical\ntheorems hold. Our main results are as follows. (1) The classical Leakage Chain\nRule for pseudoentropy can be extended to the case that the leakage information\nis quantum (while the source remains classical). Specifically, if the source\nhas pseudoentropy at least $k$, then it has pseudoentropy at least $k-\\ell$\nconditioned on an $\\ell$-qubit leakage. (2) As an application of the Leakage\nChain Rule, we construct the first quantum leakage-resilient stream-cipher in\nthe bounded-quantum-storage model, assuming the existence of a quantum-secure\npseudorandom generator. (3) We show that the general form of the classical\nDense Model Theorem (interpreted as the equivalence between two definitions of\npseudo-relative-min-entropy) does not extend to quantum states. Along the way,\nwe develop quantum analogues of some classical techniques (e.g. the Leakage\nSimulation Lemma, which is proven by a Non-uniform Min-Max Theorem or\nBoosting). On the other hand, we also identify some classical techniques (e.g.\nGap Amplification) that do not work in the quantum setting. Moreover, we\nintroduce a variety of notions that combine quantum information and quantum\ncomplexity, and this raises several directions for future work. \n\n"}
{"id": "1704.07525", "contents": "Title: Graph Theoretic Properties of the Darkweb Abstract: We collect and analyze the darkweb (a.k.a. the \"onionweb\") hyperlink graph.\nWe find properties highly dissimilar to the well-studied world wide web\nhyperlink graph; for example, our analysis finds that >87% of darkweb sites\nnever link to another site. We compare our results to prior work on\nworld-wide-web and speculate about reasons for their differences. We conclude\nthat in the term \"darkweb\", the word \"web\" is a connectivity misnomer. Instead,\nit is more accurate to view the darkweb as a set of largely isolated dark\nsilos. \n\n"}
{"id": "1704.08847", "contents": "Title: Parseval Networks: Improving Robustness to Adversarial Examples Abstract: We introduce Parseval networks, a form of deep neural networks in which the\nLipschitz constant of linear, convolutional and aggregation layers is\nconstrained to be smaller than 1. Parseval networks are empirically and\ntheoretically motivated by an analysis of the robustness of the predictions\nmade by deep neural networks when their input is subject to an adversarial\nperturbation. The most important feature of Parseval networks is to maintain\nweight matrices of linear and convolutional layers to be (approximately)\nParseval tight frames, which are extensions of orthogonal matrices to\nnon-square matrices. We describe how these constraints can be maintained\nefficiently during SGD. We show that Parseval networks match the\nstate-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House\nNumbers (SVHN) while being more robust than their vanilla counterpart against\nadversarial examples. Incidentally, Parseval networks also tend to train faster\nand make a better usage of the full capacity of the networks. \n\n"}
{"id": "1705.00139", "contents": "Title: On Statistically-Secure Quantum Homomorphic Encryption Abstract: Homomorphic encryption is an encryption scheme that allows computations to be\nevaluated on encrypted inputs without knowledge of their raw messages. Recently\nOuyang et al. constructed a quantum homomorphic encryption (QHE) scheme for\nClifford circuits with statistical security (or information-theoretic security\n(IT-security)). It is desired to see whether an\ninformation-theoretically-secure (ITS) quantum FHE exists. If not, what other\nnontrivial class of quantum circuits can be homomorphically evaluated with\nIT-security? We provide a limitation for the first question that an ITS quantum\nFHE necessarily incurs exponential overhead. As for the second one, we propose\na QHE scheme for the instantaneous quantum polynomial-time (IQP) circuits. Our\nQHE scheme for IQP circuits follows from the one-time pad. \n\n"}
{"id": "1705.00795", "contents": "Title: Automated Analysis of Voting Systems under an Active Intruder Model in\n  CSP Abstract: This article presents a novel intruder model for automated reasoning about\nanonymity (vote-privacy) and secrecy properties of voting systems. We adapt the\nlazy spy for this purpose, as it avoids the eagerness of pre-computation of\nunnecessary deductions, reducing the required state space for the analysis.\nThis powerful intruder behaves as a Dolev-Yao intruder, which not only observes\na protocol run but also interacts with the protocol participants, overhears\ncommunication channels, intercepts and spoofs any messages that he has learned\nor generated from any prior knowledge.\n  We make several important modifications in relation to existing channel types\nand the deductive system. For the former, we define various channel types for\ndifferent threat models. For the latter, we construct a large deductive system\nover the space of messages transmitted in the voting system model. The model\nrepresents the first formal treatment of the vVote system, which was used in\nNovember 2014, in state elections in Victoria, Australia. \n\n"}
{"id": "1705.00831", "contents": "Title: BLENDER: Enabling Local Search with a Hybrid Differential Privacy Model Abstract: We propose a hybrid model of differential privacy that considers a\ncombination of regular and opt-in users who desire the differential privacy\nguarantees of the local privacy model and the trusted curator model,\nrespectively. We demonstrate that within this model, it is possible to design a\nnew type of blended algorithm for the task of privately computing the head of a\nsearch log. This blended approach provides significant improvements in the\nutility of obtained data compared to related work while providing users with\ntheir desired privacy guarantees. Specifically, on two large search click data\nsets, comprising 1.75 and 16 GB respectively, our approach attains NDCG values\nexceeding 95% across a range of privacy budget values. \n\n"}
{"id": "1705.02510", "contents": "Title: Texture to the Rescue: Practical Paper Fingerprinting based on Texture\n  Patterns Abstract: In this paper, we propose a novel paper fingerprinting technique based on\nanalyzing the translucent patterns revealed when a light source shines through\nthe paper. These patterns represent the inherent texture of paper, formed by\nthe random interleaving of wooden particles during the manufacturing process.\nWe show these patterns can be easily captured by a commodity camera and\ncondensed into to a compact 2048-bit fingerprint code. Prominent works in this\narea (Nature 2005, IEEE S&P 2009, CCS 2011) have all focused on fingerprinting\npaper based on the paper \"surface\". We are motivated by the observation that\ncapturing the surface alone misses important distinctive features such as the\nnon-even thickness, the random distribution of impurities, and different\nmaterials in the paper with varying opacities. Through experiments, we\ndemonstrate that the embedded paper texture provides a more reliable source for\nfingerprinting than features on the surface. Based on the collected datasets,\nwe achieve 0% false rejection and 0% false acceptance rates. We further report\nthat our extracted fingerprints contain 807 degrees-of-freedom (DoF), which is\nmuch higher than the 249 DoF with iris codes (that have the same size of 2048\nbits). The high amount of DoF for texture-based fingerprints makes our method\nextremely scalable for recognition among very large databases; it also allows\nsecure usage of the extracted fingerprint in privacy-preserving authentication\nschemes based on error correction techniques. \n\n"}
{"id": "1705.02561", "contents": "Title: A Reconnaissance Attack Mechanism for Fixed-Priority Real-Time Systems Abstract: In real-time embedded systems (RTS), failures due to security breaches can\ncause serious damage to the system, the environment and/or injury to humans.\nTherefore, it is very important to understand the potential threats and attacks\nagainst these systems. In this paper we present a novel reconnaissance attack\nthat extracts the exact schedule of real-time systems designed using fixed\npriority scheduling algorithms. The attack is demonstrated on both a real\nhardware platform and a simulator, with a high success rate. Our evaluation\nresults show that the algorithm is robust even in the presence of execution\ntime variation. \n\n"}
{"id": "1705.03042", "contents": "Title: Polar codes for secret sharing Abstract: A secret can be an encrypted message or a private key to decrypt the\nciphertext. One of the main issues in cryptography is keeping this secret safe.\nEntrusting secret to one person or saving it in a computer can conclude\nbetrayal of the person or destruction of that device. For solving this issue,\nsecret sharing can be used between some individuals which a coalition of a\nspecific number of them can only get access to the secret. In practical issues,\nsome of the members have more power and by a coalition of fewer of them, they\nshould know about the secret. In a bank, for example, president and deputy can\nhave a union with two members by each other. In this paper, by using Polar\ncodes secret sharing has been studied and a secret sharing scheme based on\nPolar codes has been introduced. Information needed for any member would be\nsent by the channel which Polar codes are constructed by it. \n\n"}
{"id": "1705.04407", "contents": "Title: Convolutional Sparse Representations with Gradient Penalties Abstract: While convolutional sparse representations enjoy a number of useful\nproperties, they have received limited attention for image reconstruction\nproblems. The present paper compares the performance of block-based and\nconvolutional sparse representations in the removal of Gaussian white noise.\nWhile the usual formulation of the convolutional sparse coding problem is\nslightly inferior to the block-based representations in this problem, the\nperformance of the convolutional form can be boosted beyond that of the\nblock-based form by the inclusion of suitable penalties on the gradients of the\ncoefficient maps. \n\n"}
{"id": "1705.04785", "contents": "Title: Aiming to Detect a malware of GSM frequency Abstract: In order to find a specific type of malware which is related to GSM\nfrequency, we propose an algorithm according to the most essential\ncharacteristics of this malware. At first, detect whether or not there exists a\nspecific thread in the memory. And then, the generated binary strings will be\ntried to be matched with the one in the target computer. At last, determine\nwhether this threat occurs or not. Furthermore, we study the effective of the\nnew method via some simulations. \n\n"}
{"id": "1705.06640", "contents": "Title: DeepXplore: Automated Whitebox Testing of Deep Learning Systems Abstract: Deep learning (DL) systems are increasingly deployed in safety- and\nsecurity-critical domains including self-driving cars and malware detection,\nwhere the correctness and predictability of a system's behavior for corner case\ninputs are of great importance. Existing DL testing depends heavily on manually\nlabeled data and therefore often fails to expose erroneous behaviors for rare\ninputs.\n  We design, implement, and evaluate DeepXplore, the first whitebox framework\nfor systematically testing real-world DL systems. First, we introduce neuron\ncoverage for systematically measuring the parts of a DL system exercised by\ntest inputs. Next, we leverage multiple DL systems with similar functionality\nas cross-referencing oracles to avoid manual checking. Finally, we demonstrate\nhow finding inputs for DL systems that both trigger many differential behaviors\nand achieve high neuron coverage can be represented as a joint optimization\nproblem and solved efficiently using gradient-based search techniques.\n  DeepXplore efficiently finds thousands of incorrect corner case behaviors\n(e.g., self-driving cars crashing into guard rails and malware masquerading as\nbenign software) in state-of-the-art DL models with thousands of neurons\ntrained on five popular datasets including ImageNet and Udacity self-driving\nchallenge data. For all tested DL models, on average, DeepXplore generated one\ntest input demonstrating incorrect behavior within one second while running\nonly on a commodity laptop. We further show that the test inputs generated by\nDeepXplore can also be used to retrain the corresponding DL model to improve\nthe model's accuracy by up to 3%. \n\n"}
{"id": "1705.06929", "contents": "Title: MPC meets SNA: A Privacy Preserving Analysis of Distributed Sensitive\n  Social Networks Abstract: In this paper, we formalize the notion of distributed sensitive social\nnetworks (DSSNs), which encompasses networks like enmity networks, financial\ntransaction networks, supply chain networks and sexual relationship networks.\nCompared to the well studied traditional social networks, DSSNs are often more\nchallenging to study, given the privacy concerns of the individuals on whom the\nnetwork is knit. In the current work, we envision the use of secure multiparty\ntools and techniques for performing privacy preserving social network analysis\nover DSSNs. As a step towards realizing this, we design efficient\ndata-oblivious algorithms for computing the K-shell decomposition and the\nPageRank centrality measure for a given DSSN. The designed data-oblivious\nalgorithms can be translated into equivalent secure computation protocols. We\nalso list a string of challenges that are needed to be addressed, for employing\nsecure computation protocols as a practical solution for studying DSSNs. \n\n"}
{"id": "1705.07065", "contents": "Title: Analyzing Privacy Breaches in the Aircraft Communications Addressing and\n  Reporting System (ACARS) Abstract: The manner in which Aircraft Communications, Addressing and Reporting System\n(ACARS) is being used has significantly changed over time. Whilst originally\nused by commercial airliners to track their flights and provide automated\ntimekeeping on crew, today it serves as a multi-purpose air-ground data link\nfor many aviation stakeholders including private jet owners, state actors and\nmilitary. Since ACARS messages are still mostly sent in the clear over a\nwireless channel, any sensitive information sent with ACARS can potentially\nlead to a privacy breach for users. Naturally, different stakeholders consider\ndifferent types of data sensitive. In this paper we propose a privacy framework\nmatching aviation stakeholders to a range of sensitive information types and\nassess the impact for each. Based on more than one million ACARS messages,\ncollected over several months, we then demonstrate that current ACARS usage\nsystematically breaches privacy for all stakeholder groups. We further support\nour findings with a number of cases of significant privacy issues for each\ngroup and analyze the impact of such leaks. While it is well-known that ACARS\nmessages are susceptible to eavesdropping attacks, this work is the first to\nquantify the extent and impact of privacy leakage in the real world for the\nrelevant aviation stakeholders. \n\n"}
{"id": "1705.07154", "contents": "Title: Demonstration of a quantum key distribution network in urban fibre-optic\n  communication lines Abstract: We report the results of the implementation of a quantum key distribution\n(QKD) network using standard fibre communication lines in Moscow. The developed\nQKD network is based on the paradigm of trusted repeaters and allows a common\nsecret key to be generated between users via an intermediate trusted node. The\nmain feature of the network is the integration of the setups using two types of\nencoding, i.e. polarisation encoding and phase encoding. One of the possible\napplications of the developed QKD network is the continuous key renewal in\nexisting symmetric encryption devices with a key refresh time of up to 14 s. \n\n"}
{"id": "1705.07213", "contents": "Title: MTDeep: Boosting the Security of Deep Neural Nets Against Adversarial\n  Attacks with Moving Target Defense Abstract: Present attack methods can make state-of-the-art classification systems based\non deep neural networks misclassify every adversarially modified test example.\nThe design of general defense strategies against a wide range of such attacks\nstill remains a challenging problem. In this paper, we draw inspiration from\nthe fields of cybersecurity and multi-agent systems and propose to leverage the\nconcept of Moving Target Defense (MTD) in designing a meta-defense for\n'boosting' the robustness of an ensemble of deep neural networks (DNNs) for\nvisual classification tasks against such adversarial attacks. To classify an\ninput image, a trained network is picked randomly from this set of networks by\nformulating the interaction between a Defender (who hosts the classification\nnetworks) and their (Legitimate and Malicious) users as a Bayesian Stackelberg\nGame (BSG). We empirically show that this approach, MTDeep, reduces\nmisclassification on perturbed images in various datasets such as MNIST,\nFashionMNIST, and ImageNet while maintaining high classification accuracy on\nlegitimate test images. We then demonstrate that our framework, being the first\nmeta-defense technique, can be used in conjunction with any existing defense\nmechanism to provide more resilience against adversarial attacks that can be\nafforded by these defense mechanisms. Lastly, to quantify the increase in\nrobustness of an ensemble-based classification system when we use MTDeep, we\nanalyze the properties of a set of DNNs and introduce the concept of\ndifferential immunity that formalizes the notion of attack transferability. \n\n"}
{"id": "1705.07263", "contents": "Title: Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection\n  Methods Abstract: Neural networks are known to be vulnerable to adversarial examples: inputs\nthat are close to natural inputs but classified incorrectly. In order to better\nunderstand the space of adversarial examples, we survey ten recent proposals\nthat are designed for detection and compare their efficacy. We show that all\ncan be defeated by constructing new loss functions. We conclude that\nadversarial examples are significantly harder to detect than previously\nappreciated, and the properties believed to be intrinsic to adversarial\nexamples are in fact not. Finally, we propose several simple guidelines for\nevaluating future proposed defenses. \n\n"}
{"id": "1705.07289", "contents": "Title: Leaky Cauldron on the Dark Land: Understanding Memory Side-Channel\n  Hazards in SGX Abstract: Side-channel risks of Intel's SGX have recently attracted great attention.\nUnder the spotlight is the newly discovered page-fault attack, in which an\nOS-level adversary induces page faults to observe the page-level access\npatterns of a protected process running in an SGX enclave. With almost all\nproposed defense focusing on this attack, little is known about whether such\nefforts indeed raise the bar for the adversary, whether a simple variation of\nthe attack renders all protection ineffective, not to mention an in-depth\nunderstanding of other attack surfaces in the SGX system. In the paper, we\nreport the first step toward systematic analyses of side-channel threats that\nSGX faces, focusing on the risks associated with its memory management. Our\nresearch identifies 8 potential attack vectors, ranging from TLB to DRAM\nmodules. More importantly, we highlight the common misunderstandings about SGX\nmemory side channels, demonstrating that high frequent AEXs can be avoided when\nrecovering EdDSA secret key through a new page channel and fine-grained\nmonitoring of enclave programs (at the level of 64B) can be done through\ncombining both cache and cross-enclave DRAM channels. Our findings reveal the\ngap between the ongoing security research on SGX and its side-channel\nweaknesses, redefine the side-channel threat model for secure enclaves, and can\nprovoke a discussion on when to use such a system and how to use it securely. \n\n"}
{"id": "1705.08151", "contents": "Title: A note on some algebraic trapdoors for block ciphers Abstract: We provide sufficient conditions to guarantee that a translation based cipher\nis not vulnerable with respect to the partition-based trapdoor. This trapdoor\nhas been introduced, recently, by Bannier et al. (2016) and it generalizes that\nintroduced by Paterson in 1999. Moreover, we discuss the fact that studying the\ngroup generated by the round functions of a block cipher may not be sufficient\nto guarantee security against these trapdoors for the cipher. \n\n"}
{"id": "1705.09765", "contents": "Title: Deep Matching and Validation Network -- An End-to-End Solution to\n  Constrained Image Splicing Localization and Detection Abstract: Image splicing is a very common image manipulation technique that is\nsometimes used for malicious purposes. A splicing detec- tion and localization\nalgorithm usually takes an input image and produces a binary decision\nindicating whether the input image has been manipulated, and also a\nsegmentation mask that corre- sponds to the spliced region. Most existing\nsplicing detection and localization pipelines suffer from two main\nshortcomings: 1) they use handcrafted features that are not robust against\nsubsequent processing (e.g., compression), and 2) each stage of the pipeline is\nusually optimized independently. In this paper we extend the formulation of the\nunderlying splicing problem to consider two input images, a query image and a\npotential donor image. Here the task is to estimate the probability that the\ndonor image has been used to splice the query image, and obtain the splicing\nmasks for both the query and donor images. We introduce a novel deep\nconvolutional neural network architecture, called Deep Matching and Validation\nNetwork (DMVN), which simultaneously localizes and detects image splicing. The\nproposed approach does not depend on handcrafted features and uses raw input\nimages to create deep learned representations. Furthermore, the DMVN is\nend-to-end op- timized to produce the probability estimates and the\nsegmentation masks. Our extensive experiments demonstrate that this approach\noutperforms state-of-the-art splicing detection methods by a large margin in\nterms of both AUC score and speed. \n\n"}
{"id": "1705.10295", "contents": "Title: HardScope: Thwarting DOP with Hardware-assisted Run-time Scope\n  Enforcement Abstract: Widespread use of memory unsafe programming languages (e.g., C and C++)\nleaves many systems vulnerable to memory corruption attacks. A variety of\ndefenses have been proposed to mitigate attacks that exploit memory errors to\nhijack the control flow of the code at run-time, e.g., (fine-grained)\nrandomization or Control Flow Integrity. However, recent work on data-oriented\nprogramming (DOP) demonstrated highly expressive (Turing-complete) attacks,\neven in the presence of these state-of-the-art defenses. Although multiple\nreal-world DOP attacks have been demonstrated, no efficient defenses are yet\navailable. We propose run-time scope enforcement (RSE), a novel approach\ndesigned to efficiently mitigate all currently known DOP attacks by enforcing\ncompile-time memory safety constraints (e.g., variable visibility rules) at\nrun-time. We present HardScope, a proof-of-concept implementation of\nhardware-assisted RSE for the new RISC-V open instruction set architecture. We\ndiscuss our systematic empirical evaluation of HardScope which demonstrates\nthat it can mitigate all currently known DOP attacks, and has a real-world\nperformance overhead of 3.2% in embedded benchmarks. \n\n"}
{"id": "1706.00324", "contents": "Title: Order-Preserving Encryption Using Approximate Integer Common Divisors Abstract: We present a new, but simple, randomised order-preserving encryption (OPE)\nscheme based on the general approximate common divisor problem (GACDP). This\nappears to be the first OPE scheme to be based on a computational hardness\nprimitive, rather than a security game. This scheme requires only $O(1)$\narithmetic operations for encryption and decryption. We show that the scheme\nhas optimal information leakage under the assumption of uniformly distributed\nplaintexts, and we indicate that this property extends to some non-uniform\ndistributions. We report on an extensive evaluation of our algorithms. The\nresults clearly demonstrate highly favourable execution times in comparison\nwith existing OPE schemes. \n\n"}
{"id": "1706.00611", "contents": "Title: Quantum key distribution protocol with pseudorandom bases Abstract: Quantum key distribution (QKD) offers a way for establishing\ninformation-theoretically secure communications. An important part of QKD\ntechnology is a high-quality random number generator (RNG) for quantum states\npreparation and for post-processing procedures. In the present work, we\nconsider a novel class of prepare-and-measure QKD protocols, utilizing\nadditional pseudorandomness in the preparation of quantum states. We study one\nof such protocols and analyze its security against the intercept-resend attack.\nWe demonstrate that, for single-photon sources, the considered protocol gives\nbetter secret key rates than the BB84 and the asymmetric BB84 protocol.\nHowever, the protocol strongly requires single-photon sources. \n\n"}
{"id": "1706.01560", "contents": "Title: Stateless Puzzles for Real Time Online Fraud Preemption Abstract: The profitability of fraud in online systems such as app markets and social\nnetworks marks the failure of existing defense mechanisms. In this paper, we\npropose FraudSys, a real-time fraud preemption approach that imposes\nBitcoin-inspired computational puzzles on the devices that post online system\nactivities, such as reviews and likes. We introduce and leverage several novel\nconcepts that include (i) stateless, verifiable computational puzzles, that\nimpose minimal performance overhead, but enable the efficient verification of\ntheir authenticity, (ii) a real-time, graph-based solution to assign fraud\nscores to user activities, and (iii) mechanisms to dynamically adjust puzzle\ndifficulty levels based on fraud scores and the computational capabilities of\ndevices. FraudSys does not alter the experience of users in online systems, but\ndelays fraudulent actions and consumes significant computational resources of\nthe fraudsters. Using real datasets from Google Play and Facebook, we\ndemonstrate the feasibility of FraudSys by showing that the devices of honest\nusers are minimally impacted, while fraudster controlled devices receive daily\ncomputational penalties of up to 3,079 hours. In addition, we show that with\nFraudSys, fraud does not pay off, as a user equipped with mining hardware\n(e.g., AntMiner S7) will earn less than half through fraud than from honest\nBitcoin mining. \n\n"}
{"id": "1706.01628", "contents": "Title: Optimal Attack against Cyber-Physical Control Systems with Reactive\n  Attack Mitigation Abstract: This paper studies the performance and resilience of a cyber-physical control\nsystem (CPCS) with attack detection and reactive attack mitigation. It\naddresses the problem of deriving an optimal sequence of false data injection\nattacks that maximizes the state estimation error of the system. The results\nprovide basic understanding about the limit of the attack impact. The design of\nthe optimal attack is based on a Markov decision process (MDP) formulation,\nwhich is solved efficiently using the value iteration method. Using the\nproposed framework, we quantify the effect of false positives and\nmis-detections on the system performance, which can help the joint design of\nthe attack detection and mitigation. To demonstrate the use of the proposed\nframework in a real-world CPCS, we consider the voltage control system of power\ngrids, and run extensive simulations using PowerWorld, a high-fidelity power\nsystem simulator, to validate our analysis. The results show that by carefully\ndesigning the attack sequence using our proposed approach, the attacker can\ncause a large deviation of the bus voltages from the desired setpoint. Further,\nthe results verify the optimality of the derived attack sequence and show that,\nto cause maximum impact, the attacker must carefully craft his attack to strike\na balance between the attack magnitude and stealthiness, due to the\nsimultaneous presence of attack detection and mitigation. \n\n"}
{"id": "1706.01763", "contents": "Title: Adversarial-Playground: A Visualization Suite for Adversarial Sample\n  Generation Abstract: With growing interest in adversarial machine learning, it is important for\nmachine learning practitioners and users to understand how their models may be\nattacked. We propose a web-based visualization tool, Adversarial-Playground, to\ndemonstrate the efficacy of common adversarial methods against a deep neural\nnetwork (DNN) model, built on top of the TensorFlow library.\nAdversarial-Playground provides users an efficient and effective experience in\nexploring techniques generating adversarial examples, which are inputs crafted\nby an adversary to fool a machine learning system. To enable\nAdversarial-Playground to generate quick and accurate responses for users, we\nuse two primary tactics: (1) We propose a faster variant of the\nstate-of-the-art Jacobian saliency map approach that maintains a comparable\nevasion rate. (2) Our visualization does not transmit the generated adversarial\nimages to the client, but rather only the matrix describing the sample and the\nvector representing classification likelihoods.\n  The source code along with the data from all of our experiments are available\nat \\url{https://github.com/QData/AdversarialDNN-Playground}. \n\n"}
{"id": "1706.03827", "contents": "Title: Deterministic, Stash-Free Write-Only ORAM Abstract: Write-Only Oblivious RAM (WoORAM) protocols provide privacy by encrypting the\ncontents of data and also hiding the pattern of write operations over that\ndata. WoORAMs provide better privacy than plain encryption and better\nperformance than more general ORAM schemes (which hide both writing and reading\naccess patterns), and the write-oblivious setting has been applied to important\napplications of cloud storage synchronization and encrypted hidden volumes. In\nthis paper, we introduce an entirely new technique for Write-Only ORAM, called\nDetWoORAM. Unlike previous solutions, DetWoORAM uses a deterministic,\nsequential writing pattern without the need for any \"stashing\" of blocks in\nlocal state when writes fail. Our protocol, while conceptually simple, provides\nsubstantial improvement over prior solutions, both asymptotically and\nexperimentally. In particular, under typical settings the DetWoORAM writes only\n2 blocks (sequentially) to backend memory for each block written to the device,\nwhich is optimal. We have implemented our solution using the BUSE (block device\nin user-space) module and tested DetWoORAM against both an encryption only\nbaseline of dm-crypt and prior, randomized WoORAM solutions, measuring only a\n3x-14x slowdown compared to an encryption-only baseline and around 6x-19x\nspeedup compared to prior work. \n\n"}
{"id": "1706.04009", "contents": "Title: Secure uniform random number extraction via incoherent strategies Abstract: To guarantee the security of uniform random numbers generated by a quantum\nrandom number generator, we study secure extraction of uniform random numbers\nwhen the environment of a given quantum state is controlled by the third party,\nthe eavesdropper. Here we restrict our operations to incoherent strategies that\nare composed of the measurement on the computational basis and incoherent\noperations (or incoherence-preserving operations). We show that the maximum\nsecure extraction rate is equal to the relative entropy of coherence. By\ncontrast, the coherence of formation gives the extraction rate when a certain\nconstraint is imposed on eavesdropper's operations. The condition under which\nthe two extraction rates coincide is then determined. Furthermore, we find that\nthe exponential decreasing rate of the leaked information is characterized by\nR\\'{e}nyi relative entropies of coherence. These results clarify the power of\nincoherent strategies in random number generation, and can be applied to\nguarantee the quality of random numbers generated by a quantum random number\ngenerator. \n\n"}
{"id": "1706.04759", "contents": "Title: PrettyCat: Adaptive guarantee-controlled software partitioning of\n  security protocols Abstract: One single error can result in a total compromise of all security in today's\nlarge, monolithic software. Partitioning of software can help simplify\ncode-review and verification, whereas isolated execution of software-components\nlimits the impact of incorrect implementations. However, existing application\npartitioning techniques are too expensive, too imprecise, or involve unsafe\nmanual steps. An automatic, yet safe, approach to dissect security protocols\ninto component-based systems is not available. We present a method and toolset\nto automatically segregate security related software into an indefinite number\nof partitions, based on the security guarantees required by the deployed\ncryptographic building blocks. As partitioning imposes communication overhead,\nwe offer a range of sound performance optimizations. Furthermore, by applying\nour approach to the secure messaging protocol OTR, we demonstrate its\napplicability and achieve a significant reduction of the trusted computing\nbase. Compared to a monolithic implementation, only 29% of the partitioned\nprotocol requires confidentiality guarantees with a process overhead comparable\nto common sandboxing techniques. \n\n"}
{"id": "1706.07373", "contents": "Title: Testing isomorphism of lattices over CM-orders Abstract: A CM-order is a reduced order equipped with an involution that mimics complex\nconjugation. The Witt-Picard group of such an order is a certain group of ideal\nclasses that is closely related to the \"minus part\" of the class group. We\npresent a deterministic polynomial-time algorithm for the following problem,\nwhich may be viewed as a special case of the principal ideal testing problem:\ngiven a CM-order, decide whether two given elements of its Witt-Picard group\nare equal. In order to prevent coefficient blow-up, the algorithm operates with\nlattices rather than with ideals. An important ingredient is a technique\nintroduced by Gentry and Szydlo in a cryptographic context. Our application of\nit to lattices over CM-orders hinges upon a novel existence theorem for\nauxiliary ideals, which we deduce from a result of Konyagin and Pomerance in\nelementary number theory. \n\n"}
{"id": "1706.08065", "contents": "Title: The problem with the SURF scheme Abstract: There is a serious problem with one of the assumptions made in the security\nproof of the SURF scheme. This problem turns out to be easy in the regime of\nparameters needed for the SURF scheme to work.\n  We give afterwards the old version of the paper for the reader's convenience. \n\n"}
{"id": "1706.10268", "contents": "Title: SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted\n  Cloud Abstract: Inference using deep neural networks is often outsourced to the cloud since\nit is a computationally demanding task. However, this raises a fundamental\nissue of trust. How can a client be sure that the cloud has performed inference\ncorrectly? A lazy cloud provider might use a simpler but less accurate model to\nreduce its own computational load, or worse, maliciously modify the inference\nresults sent to the client. We propose SafetyNets, a framework that enables an\nuntrusted server (the cloud) to provide a client with a short mathematical\nproof of the correctness of inference tasks that they perform on behalf of the\nclient. Specifically, SafetyNets develops and implements a specialized\ninteractive proof (IP) protocol for verifiable execution of a class of deep\nneural networks, i.e., those that can be represented as arithmetic circuits.\nOur empirical results on three- and four-layer deep neural networks demonstrate\nthe run-time costs of SafetyNets for both the client and server are low.\nSafetyNets detects any incorrect computations of the neural network by the\nuntrusted server with high probability, while achieving state-of-the-art\naccuracy on the MNIST digit recognition (99.4%) and TIMIT speech recognition\ntasks (75.22%). \n\n"}
{"id": "1707.00641", "contents": "Title: Effect of Pipelining and Multiplexing in Estimating HTTP/2.0 Web Object\n  Sizes Abstract: HTTP response size is a well-known side channel attack. With the deployment\nof HTTP/2.0, response size estimation attacks are generally dismissed with the\nargument that pipelining and response multiplexing prevent eavesdroppers from\nfinding out response sizes. Yet the impact that pipelining and response\nmultiplexing actually have in estimating HTTP response sizes has not been\nadequately investigated. In this paper we set out to help understand the effect\nof pipelining and response multiplexing in estimating the size of web objects\non the Internet. We conduct an experiment that collects HTTP response sizes and\nTLS record sizes from 10k popular web sites. We gather evidence on and discuss\nreasons for the limited amount of pipelining and response multiplexing used on\nthe Internet today: only 29% of the HTTP2 web objects we observe are pipelined\nand only 5% multiplexed. We also provide worst case results under different\nattack assumptions and show how effective a simple model for estimating\nresponse sizes from TLS record sizes can be. Our conclusion is that pipelining\nand especially response multiplexing can yield, as expected, a perceivable\nincrease in relative object size estimation error yet the limited extent of\nmultiplexing observed on the Internet today and the relative simplicity of\nattacks to the current pipelining mechanisms hinder their ability to help\nprevent web object size estimation. \n\n"}
{"id": "1707.00810", "contents": "Title: R\\'enyi Resolvability and Its Applications to the Wiretap Channel Abstract: The conventional channel resolvability problem refers to the determination of\nthe minimum rate required for an input process so that the output distribution\napproximates a target distribution in either the total variation distance or\nthe relative entropy. In contrast to previous works, in this paper, we use the\n(normalized or unnormalized) R\\'enyi divergence (with the R\\'enyi parameter in\n$[0,2]\\cup\\{\\infty\\}$) to measure the level of approximation. We also provide\nasymptotic expressions for normalized R\\'enyi divergence when the R\\'enyi\nparameter is larger than or equal to $1$ as well as (lower and upper) bounds\nfor the case when the same parameter is smaller than $1$. We characterize the\nR\\'enyi resolvability, which is defined as the minimum rate required to ensure\nthat the R\\'enyi divergence vanishes asymptotically. The R\\'enyi\nresolvabilities are the same for both the normalized and unnormalized\ndivergence cases. In addition, when the R\\'enyi parameter smaller than~$1$,\nconsistent with the traditional case where the R\\'enyi parameter is equal\nto~$1$, the R\\'enyi resolvability equals the minimum mutual information over\nall input distributions that induce the target output distribution. When the\nR\\'enyi parameter is larger than $1$ the R\\'enyi resolvability is, in general,\nlarger than the mutual information. The optimal R\\'enyi divergence is proven to\nvanish at least exponentially fast for both of these two cases, as long as the\ncode rate is larger than the R\\'enyi resolvability. The optimal exponential\nrate of decay for i.i.d.\\ random codes is also characterized exactly. We apply\nthese results to the wiretap channel, and completely characterize the optimal\ntradeoff between the rates of the secret and non-secret messages when the\nleakage measure is given by the (unnormalized) R\\'enyi divergence. \n\n"}
{"id": "1707.01189", "contents": "Title: More Flexible Differential Privacy: The Application of Piecewise Mixture\n  Distributions in Query Release Abstract: There is an increasing demand to make data \"open\" to third parties, as data\nsharing has great benefits in data-driven decision making. However, with a wide\nvariety of sensitive data collected, protecting privacy of individuals,\ncommunities and organizations, is an essential factor in making data \"open\".\nThe approaches currently adopted by industry in releasing private data are\noften ad hoc and prone to a number of attacks, including re-identification\nattacks, as they do not provide adequate privacy guarantees. While differential\nprivacy has attracted significant interest from academia and industry by\nproviding rigorous and reliable privacy guarantees, the reduced utility and\ninflexibility of current differentially private algorithms for data release is\na barrier to their use in real-life. This paper aims to address these two\nchallenges. First, we propose a novel mechanism to augment the conventional\nutility of differential privacy by fusing two Laplace or geometric\ndistributions together. We derive closed form expressions for entropy, variance\nof added noise, and absolute expectation of noise for the proposed piecewise\nmixtures. Then the relevant distributions are utilised to theoretically prove\nthe privacy and accuracy guarantees of the proposed mechanisms. Second, we show\nthat our proposed mechanisms have greater flexibility, with three parameters to\nadjust, giving better utility in bounding noise, and mitigating larger\ninaccuracy, in comparison to typical one-parameter differentially private\nmechanisms. We then empirically evaluate the performance of piecewise mixture\ndistributions with extensive simulations and with a real-world dataset for both\nlinear count queries and histogram queries. The empirical results show an\nincrease in all utility measures considered, while maintaining privacy, for the\npiecewise mixture mechanisms compared to standard Laplace or geometric\nmechanisms. \n\n"}
{"id": "1707.01871", "contents": "Title: Achieving Secure and Differentially Private Computations in Multiparty\n  Settings Abstract: Sharing and working on sensitive data in distributed settings from healthcare\nto finance is a major challenge due to security and privacy concerns. Secure\nmultiparty computation (SMC) is a viable panacea for this, allowing distributed\nparties to make computations while the parties learn nothing about their data,\nbut the final result. Although SMC is instrumental in such distributed\nsettings, it does not provide any guarantees not to leak any information about\nindividuals to adversaries. Differential privacy (DP) can be utilized to\naddress this; however, achieving SMC with DP is not a trivial task, either. In\nthis paper, we propose a novel Secure Multiparty Distributed Differentially\nPrivate (SM-DDP) protocol to achieve secure and private computations in a\nmultiparty environment. Specifically, with our protocol, we simultaneously\nachieve SMC and DP in distributed settings focusing on linear regression on\nhorizontally distributed data. That is, parties do not see each others' data\nand further, can not infer information about individuals from the final\nconstructed statistical model. Any statistical model function that allows\nindependent calculation of local statistics can be computed through our\nprotocol. The protocol implements homomorphic encryption for SMC and functional\nmechanism for DP to achieve the desired security and privacy guarantees. In\nthis work, we first introduce the theoretical foundation for the SM-DDP\nprotocol and then evaluate its efficacy and performance on two different\ndatasets. Our results show that one can achieve individual-level privacy\nthrough the proposed protocol with distributed DP, which is independently\napplied by each party in a distributed fashion. Moreover, our results also show\nthat the SM-DDP protocol incurs minimal computational overhead, is scalable,\nand provides security and privacy guarantees. \n\n"}
{"id": "1707.01879", "contents": "Title: Internet of Things: Survey on Security and Privacy Abstract: The Internet of Things (IoT) is intended for ubiquitous connectivity among\ndifferent entities or \"things\". While its purpose is to provide effective and\nefficient solutions, security of the devices and network is a challenging\nissue. The number of devices connected along with the ad-hoc nature of the\nsystem further exacerbates the situation. Therefore, security and privacy has\nemerged as a significant challenge for the IoT. In this paper,we aim to provide\na thorough survey related to the privacy and security challenges of the IoT.\nThis document addresses these challenges from the perspective of technologies\nand architecture used. This work focuses also in IoT intrinsic vulnerabilities\nas well as the security challenges of various layers based on the security\nprinciples of data confidentiality, integrity and availability. This survey\nanalyzes articles published for the IoT at the time and relates it to the\nsecurity conjuncture of the field and its projection to the future. \n\n"}
{"id": "1707.02702", "contents": "Title: Composition Properties of Inferential Privacy for Time-Series Data Abstract: With the proliferation of mobile devices and the internet of things,\ndeveloping principled solutions for privacy in time series applications has\nbecome increasingly important. While differential privacy is the gold standard\nfor database privacy, many time series applications require a different kind of\nguarantee, and a number of recent works have used some form of inferential\nprivacy to address these situations.\n  However, a major barrier to using inferential privacy in practice is its lack\nof graceful composition -- even if the same or related sensitive data is used\nin multiple releases that are safe individually, the combined release may have\npoor privacy properties. In this paper, we study composition properties of a\nform of inferential privacy called Pufferfish when applied to time-series data.\nWe show that while general Pufferfish mechanisms may not compose gracefully, a\nspecific Pufferfish mechanism, called the Markov Quilt Mechanism, which was\nrecently introduced, has strong composition properties comparable to that of\npure differential privacy when applied to time series data. \n\n"}
{"id": "1707.04131", "contents": "Title: Foolbox: A Python toolbox to benchmark the robustness of machine\n  learning models Abstract: Even todays most advanced machine learning models are easily fooled by almost\nimperceptible perturbations of their inputs. Foolbox is a new Python package to\ngenerate such adversarial perturbations and to quantify and compare the\nrobustness of machine learning models. It is build around the idea that the\nmost comparable robustness measure is the minimum perturbation needed to craft\nan adversarial example. To this end, Foolbox provides reference implementations\nof most published adversarial attack methods alongside some new ones, all of\nwhich perform internal hyperparameter tuning to find the minimum adversarial\nperturbation. Additionally, Foolbox interfaces with most popular deep learning\nframeworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows\ndifferent adversarial criteria such as targeted misclassification and top-k\nmisclassification as well as different distance measures. The code is licensed\nunder the MIT license and is openly available at\nhttps://github.com/bethgelab/foolbox . The most up-to-date documentation can be\nfound at http://foolbox.readthedocs.io . \n\n"}
{"id": "1707.05005", "contents": "Title: graph2vec: Learning Distributed Representations of Graphs Abstract: Recent works on representation learning for graph structured data\npredominantly focus on learning distributed representations of graph\nsubstructures such as nodes and subgraphs. However, many graph analytics tasks\nsuch as graph classification and clustering require representing entire graphs\nas fixed length feature vectors. While the aforementioned approaches are\nnaturally unequipped to learn such representations, graph kernels remain as the\nmost effective way of obtaining them. However, these graph kernels use\nhandcrafted features (e.g., shortest paths, graphlets, etc.) and hence are\nhampered by problems such as poor generalization. To address this limitation,\nin this work, we propose a neural embedding framework named graph2vec to learn\ndata-driven distributed representations of arbitrary sized graphs. graph2vec's\nembeddings are learnt in an unsupervised manner and are task agnostic. Hence,\nthey could be used for any downstream task such as graph classification,\nclustering and even seeding supervised representation learning approaches. Our\nexperiments on several benchmark and large real-world datasets show that\ngraph2vec achieves significant improvements in classification and clustering\naccuracies over substructure representation learning approaches and are\ncompetitive with state-of-the-art graph kernels. \n\n"}
{"id": "1707.05373", "contents": "Title: Houdini: Fooling Deep Structured Prediction Models Abstract: Generating adversarial examples is a critical step for evaluating and\nimproving the robustness of learning machines. So far, most existing methods\nonly work for classification and are not designed to alter the true performance\nmeasure of the problem at hand. We introduce a novel flexible approach named\nHoudini for generating adversarial examples specifically tailored for the final\nperformance measure of the task considered, be it combinatorial and\nnon-decomposable. We successfully apply Houdini to a range of applications such\nas speech recognition, pose estimation and semantic segmentation. In all cases,\nthe attacks based on Houdini achieve higher success rate than those based on\nthe traditional surrogates used to train the models while using a less\nperceptible adversarial perturbation. \n\n"}
{"id": "1707.05454", "contents": "Title: Teechain: A Secure Payment Network with Asynchronous Blockchain Access Abstract: Blockchains such as Bitcoin and Ethereum execute payment transactions\nsecurely, but their performance is limited by the need for global consensus.\nPayment networks overcome this limitation through off-chain transactions.\nInstead of writing to the blockchain for each transaction, they only settle the\nfinal payment balances with the underlying blockchain. When executing off-chain\ntransactions in current payment networks, parties must access the blockchain\nwithin bounded time to detect misbehaving parties that deviate from the\nprotocol. This opens a window for attacks in which a malicious party can steal\nfunds by deliberately delaying other parties' blockchain access and prevents\nparties from using payment networks when disconnected from the blockchain.\n  We present Teechain, the first layer-two payment network that executes\noff-chain transactions asynchronously with respect to the underlying\nblockchain. To prevent parties from misbehaving, Teechain uses treasuries,\nprotected by hardware trusted execution environments (TEEs), to establish\noff-chain payment channels between parties. Treasuries maintain collateral\nfunds and can exchange transactions efficiently and securely, without\ninteracting with the underlying blockchain. To mitigate against treasury\nfailures and to avoid having to trust all TEEs, Teechain replicates the state\nof treasuries using committee chains, a new variant of chain replication with\nthreshold secret sharing. Teechain achieves at least a 33x higher transaction\nthroughput than the state-of-the-art Lightning payment network. A 30-machine\nTeechain deployment can handle over 1 million Bitcoin transactions per second. \n\n"}
{"id": "1707.07112", "contents": "Title: Switching and Data Injection Attacks on Stochastic Cyber-Physical\n  Systems: Modeling, Resilient Estimation and Attack Mitigation Abstract: In this paper, we consider the problem of attack-resilient state estimation,\nthat is to reliably estimate the true system states despite two classes of\nattacks: (i) attacks on the switching mechanisms and (ii) false data injection\nattacks on actuator and sensor signals, in the presence of unbounded stochastic\nprocess and measurement noise signals. We model the systems under attack as\nhidden mode stochastic switched linear systems with unknown inputs and propose\nthe use of a multiple-model inference algorithm to tackle these security\nissues. Moreover, we characterize fundamental limitations to resilient\nestimation (e.g., upper bound on the number of tolerable signal attacks) and\ndiscuss the topics of attack detection, identification and mitigation under\nthis framework. Simulation examples of switching and false data injection\nattacks on a benchmark system and an IEEE 68-bus test system show the efficacy\nof our approach to recover resilient (i.e., asymptotically unbiased) state\nestimates as well as to identify and mitigate the attacks. \n\n"}
{"id": "1707.07128", "contents": "Title: Single Image Super-Resolution with Dilated Convolution based Multi-Scale\n  Information Learning Inception Module Abstract: Traditional works have shown that patches in a natural image tend to\nredundantly recur many times inside the image, both within the same scale, as\nwell as across different scales. Make full use of these multi-scale information\ncan improve the image restoration performance. However, the current proposed\ndeep learning based restoration methods do not take the multi-scale information\ninto account. In this paper, we propose a dilated convolution based inception\nmodule to learn multi-scale information and design a deep network for single\nimage super-resolution. Different dilated convolution learns different scale\nfeature, then the inception module concatenates all these features to fuse\nmulti-scale information. In order to increase the reception field of our\nnetwork to catch more contextual information, we cascade multiple inception\nmodules to constitute a deep network to conduct single image super-resolution.\nWith the novel dilated convolution based inception module, the proposed\nend-to-end single image super-resolution network can take advantage of\nmulti-scale information to improve image super-resolution performance.\nExperimental results show that our proposed method outperforms many\nstate-of-the-art single image super-resolution methods. \n\n"}
{"id": "1707.08619", "contents": "Title: Public Evidence from Secret Ballots Abstract: Elections seem simple---aren't they just counting? But they have a unique,\nchallenging combination of security and privacy requirements. The stakes are\nhigh; the context is adversarial; the electorate needs to be convinced that the\nresults are correct; and the secrecy of the ballot must be ensured. And they\nhave practical constraints: time is of the essence, and voting systems need to\nbe affordable and maintainable, and usable by voters, election officials, and\npollworkers. It is thus not surprising that voting is a rich research area\nspanning theory, applied cryptography, practical systems analysis, usable\nsecurity, and statistics. Election integrity involves two key concepts:\nconvincing evidence that outcomes are correct and privacy, which amounts to\nconvincing assurance that there is no evidence about how any given person\nvoted. These are obviously in tension. We examine how current systems walk this\ntightrope. \n\n"}
{"id": "1707.08945", "contents": "Title: Robust Physical-World Attacks on Deep Learning Models Abstract: Recent studies show that the state-of-the-art deep neural networks (DNNs) are\nvulnerable to adversarial examples, resulting from small-magnitude\nperturbations added to the input. Given that that emerging physical systems are\nusing DNNs in safety-critical situations, adversarial examples could mislead\nthese systems and cause dangerous situations.Therefore, understanding\nadversarial examples in the physical world is an important step towards\ndeveloping resilient learning algorithms. We propose a general attack\nalgorithm,Robust Physical Perturbations (RP2), to generate robust visual\nadversarial perturbations under different physical conditions. Using the\nreal-world case of road sign classification, we show that adversarial examples\ngenerated using RP2 achieve high targeted misclassification rates against\nstandard-architecture road sign classifiers in the physical world under various\nenvironmental conditions, including viewpoints. Due to the current lack of a\nstandardized testing method, we propose a two-stage evaluation methodology for\nrobust physical adversarial examples consisting of lab and field tests. Using\nthis methodology, we evaluate the efficacy of physical adversarial\nmanipulations on real objects. Witha perturbation in the form of only black and\nwhite stickers,we attack a real stop sign, causing targeted misclassification\nin 100% of the images obtained in lab settings, and in 84.8%of the captured\nvideo frames obtained on a moving vehicle(field test) for the target\nclassifier. \n\n"}
{"id": "1707.09043", "contents": "Title: ERASMUS: Efficient Remote Attestation via Self- Measurement for\n  Unattended Settings Abstract: Remote attestation (RA) is a popular means of detecting malware in embedded\nand IoT devices. RA is usually realized as an interactive protocol, whereby a\ntrusted party -- verifier -- measures integrity of a potentially compromised\nremote device -- prover. Early work focused on purely software-based and fully\nhardware-based techniques, neither of which is ideal for low-end devices. More\nrecent results have yielded hybrid (SW/HW) security architectures comprised of\na minimal set of features to support efficient and secure RA on low-end\ndevices.\n  All prior RA techniques require on-demand operation, i.e, RA is performed in\nreal time. We identify some drawbacks of this general approach in the context\nof unattended devices: First, it fails to detect mobile malware that enters and\nleaves the prover between successive RA instances. Second, it requires the\nprover to engage in a potentially expensive (in terms of time and energy)\ncomputation, which can be harmful for critical or real-time devices.\n  To address these drawbacks, we introduce the concept of self-measurement\nwhere a prover device periodically (and securely) measures and records its own\nsoftware state, based on a pre-established schedule. A possibly untrusted\nverifier occasionally collects and verifies these measurements. We present the\ndesign of a concrete technique called ERASMUS : Efficient Remote Attestation\nvia Self-Measurement for Unattended Settings, justify its features and evaluate\nits performance. In the process, we also define a new metric -- Quality of\nAttestation (QoA). We argue that ERASMUS is well-suited for time-sensitive\nand/or safety-critical applications that are not served well by on-demand RA.\nFinally, we show that ERASMUS is a promising stepping stone towards handling\nattestation of multiple devices (i.e., a group or swarm) with high mobility. \n\n"}
{"id": "1708.00807", "contents": "Title: Adversarial-Playground: A Visualization Suite Showing How Adversarial\n  Examples Fool Deep Learning Abstract: Recent studies have shown that attackers can force deep learning models to\nmisclassify so-called \"adversarial examples\": maliciously generated images\nformed by making imperceptible modifications to pixel values. With growing\ninterest in deep learning for security applications, it is important for\nsecurity experts and users of machine learning to recognize how learning\nsystems may be attacked. Due to the complex nature of deep learning, it is\nchallenging to understand how deep models can be fooled by adversarial\nexamples. Thus, we present a web-based visualization tool,\nAdversarial-Playground, to demonstrate the efficacy of common adversarial\nmethods against a convolutional neural network (CNN) system.\nAdversarial-Playground is educational, modular and interactive. (1) It enables\nnon-experts to compare examples visually and to understand why an adversarial\nexample can fool a CNN-based image classifier. (2) It can help security experts\nexplore more vulnerability of deep learning as a software module. (3) Building\nan interactive visualization is challenging in this domain due to the large\nfeature space of image classification (generating adversarial examples is slow\nin general and visualizing images are costly). Through multiple novel design\nchoices, our tool can provide fast and accurate responses to user requests.\nEmpirically, we find that our client-server division strategy reduced the\nresponse time by an average of 1.5 seconds per sample. Our other innovation, a\nfaster variant of JSMA evasion algorithm, empirically performed twice as fast\nas JSMA and yet maintains a comparable evasion rate.\n  Project source code and data from our experiments available at:\nhttps://github.com/QData/AdversarialDNN-Playground \n\n"}
{"id": "1708.05811", "contents": "Title: Secure Search on the Cloud via Coresets and Sketches Abstract: \\emph{Secure Search} is the problem of retrieving from a database table (or\nany unsorted array) the records matching specified attributes, as in SQL SELECT\nqueries, but where the database and the query are encrypted. Secure search has\nbeen the leading example for practical applications of Fully Homomorphic\nEncryption (FHE) starting in Gentry's seminal work; however, to the best of our\nknowledge all state-of-the-art secure search algorithms to date are realized by\na polynomial of degree $\\Omega(m)$ for $m$ the number of records, which is\ntypically too slow in practice even for moderate size $m$.\n  In this work we present the first algorithm for secure search that is\nrealized by a polynomial of degree polynomial in $\\log m$. We implemented our\nalgorithm in an open source library based on HELib implementation for the\nBrakerski-Gentry-Vaikuntanthan's FHE scheme, and ran experiments on Amazon's\nEC2 cloud. Our experiments show that we can retrieve the first match in a\ndatabase of millions of entries in less than an hour using a single machine;\nthe time reduced almost linearly with the number of machines.\n  Our result utilizes a new paradigm of employing coresets and sketches, which\nare modern data summarization techniques common in computational geometry and\nmachine learning, for efficiency enhancement for homomorphic encryption. As a\ncentral tool we design a novel sketch that returns the first positive entry in\na (not necessarily sparse) array; this sketch may be of independent interest. \n\n"}
{"id": "1708.05907", "contents": "Title: Electricity Theft Detection using Machine Learning Abstract: Non-technical losses (NTL) in electric power grids arise through electricity\ntheft, broken electric meters or billing errors. They can harm the power\nsupplier as well as the whole economy of a country through losses of up to 40%\nof the total power distribution. For NTL detection, researchers use artificial\nintelligence to analyse data. This work is about improving the extraction of\nmore meaningful features from a data set. With these features, the prediction\nquality will increase. \n\n"}
{"id": "1708.06145", "contents": "Title: Knock Knock, Who's There? Membership Inference on Aggregate Location\n  Data Abstract: Aggregate location data is often used to support smart services and\napplications, e.g., generating live traffic maps or predicting visits to\nbusinesses. In this paper, we present the first study on the feasibility of\nmembership inference attacks on aggregate location time-series. We introduce a\ngame-based definition of the adversarial task, and cast it as a classification\nproblem where machine learning can be used to distinguish whether or not a\ntarget user is part of the aggregates.\n  We empirically evaluate the power of these attacks on both raw and\ndifferentially private aggregates using two mobility datasets. We find that\nmembership inference is a serious privacy threat, and show how its\neffectiveness depends on the adversary's prior knowledge, the characteristics\nof the underlying location data, as well as the number of users and the\ntimeframe on which aggregation is performed. Although differentially private\nmechanisms can indeed reduce the extent of the attacks, they also yield a\nsignificant loss in utility. Moreover, a strategic adversary mimicking the\nbehavior of the defense mechanism can greatly limit the protection they\nprovide. Overall, our work presents a novel methodology geared to evaluate\nmembership inference on aggregate location data in real-world settings and can\nbe used by providers to assess the quality of privacy protection before data\nrelease or by regulators to detect violations. \n\n"}
{"id": "1708.06376", "contents": "Title: Automated Website Fingerprinting through Deep Learning Abstract: Several studies have shown that the network traffic that is generated by a\nvisit to a website over Tor reveals information specific to the website through\nthe timing and sizes of network packets. By capturing traffic traces between\nusers and their Tor entry guard, a network eavesdropper can leverage this\nmeta-data to reveal which website Tor users are visiting. The success of such\nattacks heavily depends on the particular set of traffic features that are used\nto construct the fingerprint. Typically, these features are manually engineered\nand, as such, any change introduced to the Tor network can render these\ncarefully constructed features ineffective. In this paper, we show that an\nadversary can automate the feature engineering process, and thus automatically\ndeanonymize Tor traffic by applying our novel method based on deep learning. We\ncollect a dataset comprised of more than three million network traces, which is\nthe largest dataset of web traffic ever used for website fingerprinting, and\nfind that the performance achieved by our deep learning approaches is\ncomparable to known methods which include various research efforts spanning\nover multiple years. The obtained success rate exceeds 96% for a closed world\nof 100 websites and 94% for our biggest closed world of 900 classes. In our\nopen world evaluation, the most performant deep learning model is 2% more\naccurate than the state-of-the-art attack. Furthermore, we show that the\nimplicit features automatically learned by our approach are far more resilient\nto dynamic changes of web content over time. We conclude that the ability to\nautomatically construct the most relevant traffic features and perform accurate\ntraffic recognition makes our deep learning based approach an efficient,\nflexible and robust technique for website fingerprinting. \n\n"}
{"id": "1708.07548", "contents": "Title: Audio signal encryption using chaotic H\\'enon map and lifting wavelet\n  transforms Abstract: We propose a new audio signal encryption scheme based on the chaotic H\\'enon\nmap. The scheme mainly comprises two phases: one is the preprocessing stage\nwhere the audio signal is transformed into a data by the lifting wavelet scheme\nand the other in which the transformed data is encrypted by chaotic data set\nand hyperbolic functions. Furthermore, we use dynamic keys and consider the key\nspace size to be large enough to resist any kind of cryptographic attacks. A\nstatistical investigation is also made to test the security and the efficiency\nof the proposed scheme. \n\n"}
{"id": "1708.08022", "contents": "Title: On the Protection of Private Information in Machine Learning Systems:\n  Two Recent Approaches Abstract: The recent, remarkable growth of machine learning has led to intense interest\nin the privacy of the data on which machine learning relies, and to new\ntechniques for preserving privacy. However, older ideas about privacy may well\nremain valid and useful. This note reviews two recent works on privacy in the\nlight of the wisdom of some of the early literature, in particular the\nprinciples distilled by Saltzer and Schroeder in the 1970s. \n\n"}
{"id": "1708.08086", "contents": "Title: LocalCoin: An Ad-hoc Payment Scheme for Areas with High Connectivity Abstract: The popularity of digital currencies, especially cryptocurrencies, has been\ncontinuously growing since the appearance of Bitcoin. Bitcoin's security lies\nin a proof-of-work scheme, which requires high computational resources at the\nminers. Despite advances in mobile technology, existing cryptocurrencies cannot\nbe maintained by mobile devices due to their low processing capabilities.\nMobile devices can only accommodate mobile applications (wallets) that allow\nusers to exchange credits of cryptocurrencies. In this work, we propose\nLocalCoin, an alternative cryptocurrency that requires minimal computational\nresources, produces low data traffic and works with off-the-shelf mobile\ndevices. LocalCoin replaces the computational hardness that is at the root of\nBitcoin's security with the social hardness of ensuring that all witnesses to a\ntransaction are colluders. Localcoin features (i) a lightweight proof-of-work\nscheme and (ii) a distributed blockchain. We analyze LocalCoin for double\nspending for passive and active attacks and prove that under the assumption of\nsufficient number of users and properly selected tuning parameters the\nprobability of double spending is close to zero. Extensive simulations on real\nmobility traces, realistic urban settings, and random geometric graphs show\nthat the probability of success of one transaction converges to 1 and the\nprobability of the success of a double spending attempt converges to 0. \n\n"}
{"id": "1708.08221", "contents": "Title: walk2friends: Inferring Social Links from Mobility Profiles Abstract: The development of positioning technologies has resulted in an increasing\namount of mobility data being available. While bringing a lot of convenience to\npeople's life, such availability also raises serious concerns about privacy. In\nthis paper, we concentrate on one of the most sensitive information that can be\ninferred from mobility data, namely social relationships. We propose a novel\nsocial relation inference attack that relies on an advanced feature learning\ntechnique to automatically summarize users' mobility features. Compared to\nexisting approaches, our attack is able to predict any two individuals' social\nrelation, and it does not require the adversary to have any prior knowledge on\nexisting social relations. These advantages significantly increase the\napplicability of our attack and the scope of the privacy assessment. Extensive\nexperiments conducted on a large dataset demonstrate that our inference attack\nis effective, and achieves between 13% to 20% improvement over the best\nstate-of-the-art scheme. We propose three defense mechanisms -- hiding,\nreplacement and generalization -- and evaluate their effectiveness for\nmitigating the social link privacy risks stemming from mobility data sharing.\nOur experimental results show that both hiding and replacement mechanisms\noutperform generalization. Moreover, hiding and replacement achieve a\ncomparable trade-off between utility and privacy, the former preserving better\nutility and the latter providing better privacy. \n\n"}
{"id": "1708.08437", "contents": "Title: SlowFuzz: Automated Domain-Independent Detection of Algorithmic\n  Complexity Vulnerabilities Abstract: Algorithmic complexity vulnerabilities occur when the worst-case time/space\ncomplexity of an application is significantly higher than the respective\naverage case for particular user-controlled inputs. When such conditions are\nmet, an attacker can launch Denial-of-Service attacks against a vulnerable\napplication by providing inputs that trigger the worst-case behavior. Such\nattacks have been known to have serious effects on production systems, take\ndown entire websites, or lead to bypasses of Web Application Firewalls.\n  Unfortunately, existing detection mechanisms for algorithmic complexity\nvulnerabilities are domain-specific and often require significant manual\neffort. In this paper, we design, implement, and evaluate SlowFuzz, a\ndomain-independent framework for automatically finding algorithmic complexity\nvulnerabilities. SlowFuzz automatically finds inputs that trigger worst-case\nalgorithmic behavior in the tested binary. SlowFuzz uses resource-usage-guided\nevolutionary search techniques to automatically find inputs that maximize\ncomputational resource utilization for a given application. \n\n"}
{"id": "1708.09038", "contents": "Title: Convolutional Sparse Coding with Overlapping Group Norms Abstract: The most widely used form of convolutional sparse coding uses an $\\ell_1$\nregularization term. While this approach has been successful in a variety of\napplications, a limitation of the $\\ell_1$ penalty is that it is homogeneous\nacross the spatial and filter index dimensions of the sparse representation\narray, so that sparsity cannot be separately controlled across these\ndimensions. The present paper considers the consequences of replacing the\n$\\ell_1$ penalty with a mixed group norm, motivated by recent theoretical\nresults for convolutional sparse representations. Algorithms are developed for\nsolving the resulting problems, which are quite challenging, and the impact on\nthe performance of the denoising problem is evaluated. The mixed group norms\nare found to perform very poorly in this application. While their performance\nis greatly improved by introducing a weighting strategy, such a strategy also\nimproves the performance obtained from the much simpler and computationally\ncheaper $\\ell_1$ norm. \n\n"}
{"id": "1708.09114", "contents": "Title: FirmUSB: Vetting USB Device Firmware using Domain Informed Symbolic\n  Execution Abstract: The USB protocol has become ubiquitous, supporting devices from high-powered\ncomputing devices to small embedded devices and control systems. USB's greatest\nfeature, its openness and expandability, is also its weakness, and attacks such\nas BadUSB exploit the unconstrained functionality afforded to these devices as\na vector for compromise. Fundamentally, it is virtually impossible to know\nwhether a USB device is benign or malicious. This work introduces FirmUSB, a\nUSB-specific firmware analysis framework that uses domain knowledge of the USB\nprotocol to examine firmware images and determine the activity that they can\nproduce. Embedded USB devices use microcontrollers that have not been well\nstudied by the binary analysis community, and our work demonstrates how lifters\ninto popular intermediate representations for analysis can be built, as well as\nthe challenges of doing so. We develop targeting algorithms and use domain\nknowledge to speed up these processes by a factor of 7 compared to\nunconstrained fully symbolic execution. We also successfully find malicious\nactivity in embedded 8051 firmwares without the use of source code. Finally, we\nprovide insights into the challenges of symbolic analysis on embedded\narchitectures and provide guidance on improving tools to better handle this\nimportant class of devices. \n\n"}
{"id": "1708.09790", "contents": "Title: Be Selfish and Avoid Dilemmas: Fork After Withholding (FAW) Attacks on\n  Bitcoin Abstract: In the Bitcoin system, participants are rewarded for solving cryptographic\npuzzles. In order to receive more consistent rewards over time, some\nparticipants organize mining pools and split the rewards from the pool in\nproportion to each participant's contribution. However, several attacks\nthreaten the ability to participate in pools. The block withholding (BWH)\nattack makes the pool reward system unfair by letting malicious participants\nreceive unearned wages while only pretending to contribute work. When two pools\nlaunch BWH attacks against each other, they encounter the miner's dilemma: in a\nNash equilibrium, the revenue of both pools is diminished. In another attack\ncalled selfish mining, an attacker can unfairly earn extra rewards by\ndeliberately generating forks. In this paper, we propose a novel attack called\na fork after withholding (FAW) attack. FAW is not just another attack. The\nreward for an FAW attacker is always equal to or greater than that for a BWH\nattacker, and it is usable up to four times more often per pool than in BWH\nattack. When considering multiple pools - the current state of the Bitcoin\nnetwork - the extra reward for an FAW attack is about 56% more than that for a\nBWH attack. Furthermore, when two pools execute FAW attacks on each other, the\nminer's dilemma may not hold: under certain circumstances, the larger pool can\nconsistently win. More importantly, an FAW attack, while using intentional\nforks, does not suffer from practicality issues, unlike selfish mining. We also\ndiscuss partial countermeasures against the FAW attack, but finding a cheap and\nefficient countermeasure remains an open problem. As a result, we expect to see\nFAW attacks among mining pools. \n\n"}
{"id": "1709.00106", "contents": "Title: First and Second Order Methods for Online Convolutional Dictionary\n  Learning Abstract: Convolutional sparse representations are a form of sparse representation with\na structured, translation invariant dictionary. Most convolutional dictionary\nlearning algorithms to date operate in batch mode, requiring simultaneous\naccess to all training images during the learning process, which results in\nvery high memory usage and severely limits the training data that can be used.\nVery recently, however, a number of authors have considered the design of\nonline convolutional dictionary learning algorithms that offer far better\nscaling of memory and computational cost with training set size than batch\nmethods. This paper extends our prior work, improving a number of aspects of\nour previous algorithm; proposing an entirely new one, with better performance,\nand that supports the inclusion of a spatial mask for learning from incomplete\ndata; and providing a rigorous theoretical analysis of these methods. \n\n"}
{"id": "1709.00112", "contents": "Title: Private Information Retrieval with Side Information Abstract: We study the problem of Private Information Retrieval (PIR) in the presence\nof prior side information. The problem setup includes a database of $K$\nindependent messages possibly replicated on several servers, and a user that\nneeds to retrieve one of these messages. In addition, the user has some prior\nside information in the form of a subset of $M$ messages, not containing the\ndesired message and unknown to the servers. This problem is motivated by\npractical settings in which the user can obtain side information\nopportunistically from other users or has previously downloaded some messages\nusing classical PIR schemes. The objective of the user is to retrieve the\nrequired message without revealing its identity while minimizing the amount of\ndata downloaded from the servers.\n  We focus on achieving information-theoretic privacy in two scenarios: (i) the\nuser wants to protect jointly its demand and side information; (ii) the user\nwants to protect only the information about its demand, but not the side\ninformation. To highlight the role of side information, we focus first on the\ncase of a single server (single database). In the first scenario, we prove that\nthe minimum download cost is $K-M$ messages, and in the second scenario it is\n$\\lceil \\frac{K}{M+1}\\rceil$ messages, which should be compared to $K$\nmessages, the minimum download cost in the case of no side information. Then,\nwe extend some of our results to the case of the database replicated on\nmultiple servers. Our proof techniques relate PIR with side information to the\nindex coding problem. We leverage this connection to prove converse results, as\nwell as to design achievability schemes. \n\n"}
{"id": "1709.00194", "contents": "Title: Improving Automated Symbolic Analysis for E-voting Protocols: A Method\n  Based on Sufficient Conditions for Ballot Secrecy Abstract: We advance the state-of-the-art in automated symbolic analysis for e-voting\nprotocols by introducing three conditions that together are sufficient to\nguarantee ballot secrecy. There are two main advantages to using our\nconditions, compared to existing automated approaches. The first is a\nsubstantial expansion of the class of protocols and threat models that can be\nautomatically analysed: we can systematically deal with (a) honest authorities\npresent in different phases, (b) threat models in which no dishonest voters\noccur, and (c) protocols whose ballot secrecy depends on fresh data coming from\nother phases. The second advantage is that it can significantly improve\nverification efficiency, as the individual conditions are often simpler to\nverify. E.g., for the LEE protocol, we obtain a speedup of over two orders of\nmagnitude. We show the scope and effectiveness of our approach using ProVerif\nin several case studies, including FOO, LEE, JCJ, and Belenios. In these case\nstudies, our approach does not yield any false attacks, suggesting that our\nconditions are tight. \n\n"}
{"id": "1709.00440", "contents": "Title: PassGAN: A Deep Learning Approach for Password Guessing Abstract: State-of-the-art password guessing tools, such as HashCat and John the\nRipper, enable users to check billions of passwords per second against password\nhashes. In addition to performing straightforward dictionary attacks, these\ntools can expand password dictionaries using password generation rules, such as\nconcatenation of words (e.g., \"password123456\") and leet speak (e.g.,\n\"password\" becomes \"p4s5w0rd\"). Although these rules work well in practice,\nexpanding them to model further passwords is a laborious task that requires\nspecialized expertise. To address this issue, in this paper we introduce\nPassGAN, a novel approach that replaces human-generated password rules with\ntheory-grounded machine learning algorithms. Instead of relying on manual\npassword analysis, PassGAN uses a Generative Adversarial Network (GAN) to\nautonomously learn the distribution of real passwords from actual password\nleaks, and to generate high-quality password guesses. Our experiments show that\nthis approach is very promising. When we evaluated PassGAN on two large\npassword datasets, we were able to surpass rule-based and state-of-the-art\nmachine learning password guessing tools. However, in contrast with the other\ntools, PassGAN achieved this result without any a-priori knowledge on passwords\nor common password structures. Additionally, when we combined the output of\nPassGAN with the output of HashCat, we were able to match 51%-73% more\npasswords than with HashCat alone. This is remarkable, because it shows that\nPassGAN can autonomously extract a considerable number of password properties\nthat current state-of-the art rules do not encode. \n\n"}
{"id": "1709.01008", "contents": "Title: Mix-ORAM: Using delegate shuffles Abstract: Oblivious RAM (ORAM) is a key technology for providing private storage and\nquerying on untrusted machines but is commonly seen as impractical due to the\nhigh overhead of the re-randomization, called the eviction, the client incurs.\nWe propose in this work to securely delegate the eviction to semi-trusted third\nparties to enable any client to accede the ORAM technology and present four\ndifferent designs inspired by mix-net technologies with reasonable periodic\ncosts. \n\n"}
{"id": "1709.01261", "contents": "Title: SafeKeeper: Protecting Web Passwords using Trusted Execution\n  Environments Abstract: Passwords are undoubtedly the most dominant user authentication mechanism on\nthe web today. Although they are inexpensive and easy-to-use, security concerns\nof password-based authentication are serious. Phishing and theft of password\ndatabases are two critical concerns. The tendency of users to re-use passwords\nacross different services exacerbates the impact of these two concerns. Current\nsolutions addressing these concerns are not fully satisfactory: they typically\naddress only one of the two concerns; they do not protect passwords from rogue\nservers; they do not provide any verifiable evidence of their (server-side)\nadoption to users; and they face deployability challenges in terms of the cost\nfor service providers and/or ease-of-use for end users.\n  We present SafeKeeper, a comprehensive approach to protect the\nconfidentiality of passwords in web authentication systems. Unlike previous\napproaches, SafeKeeper protects user passwords against very strong adversaries,\nincluding rogue servers and sophisticated external phishers. It is relatively\ninexpensive to deploy as it (i) uses widely available hardware security\nmechanisms like Intel SGX, (ii) is integrated into popular web platforms like\nWordPress, and (iii) has small performance overhead. We describe a variety of\nchallenges in designing and implementing such a system, and how we overcome\nthem. Through an 86-participant user study, and systematic analysis and\nexperiments, we demonstrate the usability, security and deployability of\nSafeKeeper, which is available as open-source. \n\n"}
{"id": "1709.01795", "contents": "Title: CacheShield: Protecting Legacy Processes Against Cache Attacks Abstract: Cache attacks pose a threat to any code whose execution flow or memory\naccesses depend on sensitive information. Especially in public clouds, where\ncaches are shared across several tenants, cache attacks remain an unsolved\nproblem. Cache attacks rely on evictions by the spy process, which alter the\nexecution behavior of the victim process. We show that hardware performance\nevents of cryptographic routines reveal the presence of cache attacks. Based on\nthis observation, we propose CacheShield, a tool to protect legacy code by\nmonitoring its execution and detecting the presence of cache attacks, thus\nproviding the opportunity to take preventative measures. CacheShield can be run\nby users and does not require alteration of the OS or hypervisor, while\npreviously proposed software-based countermeasures require cooperation from the\nhypervisor. Unlike methods that try to detect malicious processes, our approach\nis lean, as only a fraction of the system needs to be monitored. It also\nintegrates well into today's cloud infrastructure, as concerned users can opt\nto use CacheShield without support from the cloud service provider. Our results\nshow that CacheShield detects cache attacks fast, with high reliability, and\nwith few false positives, even in the presence of strong noise. \n\n"}
{"id": "1709.02489", "contents": "Title: BlockSci: Design and applications of a blockchain analysis platform Abstract: Analysis of blockchain data is useful for both scientific research and\ncommercial applications. We present BlockSci, an open-source software platform\nfor blockchain analysis. BlockSci is versatile in its support for different\nblockchains and analysis tasks. It incorporates an in-memory, analytical\n(rather than transactional) database, making it several hundred times faster\nthan existing tools. We describe BlockSci's design and present four analyses\nthat illustrate its capabilities.\n  This is a working paper that accompanies the first public release of\nBlockSci, available at https://github.com/citp/BlockSci. We seek input from the\ncommunity to further develop the software and explore other potential\napplications. \n\n"}
{"id": "1709.03082", "contents": "Title: A Neural Network Architecture Combining Gated Recurrent Unit (GRU) and\n  Support Vector Machine (SVM) for Intrusion Detection in Network Traffic Data Abstract: Gated Recurrent Unit (GRU) is a recently-developed variation of the long\nshort-term memory (LSTM) unit, both of which are types of recurrent neural\nnetwork (RNN). Through empirical evidence, both models have been proven to be\neffective in a wide variety of machine learning tasks such as natural language\nprocessing (Wen et al., 2015), speech recognition (Chorowski et al., 2015), and\ntext classification (Yang et al., 2016). Conventionally, like most neural\nnetworks, both of the aforementioned RNN variants employ the Softmax function\nas its final output layer for its prediction, and the cross-entropy function\nfor computing its loss. In this paper, we present an amendment to this norm by\nintroducing linear support vector machine (SVM) as the replacement for Softmax\nin the final output layer of a GRU model. Furthermore, the cross-entropy\nfunction shall be replaced with a margin-based function. While there have been\nsimilar studies (Alalshekmubarak & Smith, 2013; Tang, 2013), this proposal is\nprimarily intended for binary classification on intrusion detection using the\n2013 network traffic data from the honeypot systems of Kyoto University.\nResults show that the GRU-SVM model performs relatively higher than the\nconventional GRU-Softmax model. The proposed model reached a training accuracy\nof ~81.54% and a testing accuracy of ~84.15%, while the latter was able to\nreach a training accuracy of ~63.07% and a testing accuracy of ~70.75%. In\naddition, the juxtaposition of these two final output layers indicate that the\nSVM would outperform Softmax in prediction time - a theoretical implication\nwhich was supported by the actual training and testing time in the study. \n\n"}
{"id": "1709.03776", "contents": "Title: Privacy Risk Assessment: From Art to Science, By Metrics Abstract: Privacy risk assessments aim to analyze and quantify the privacy risks\nassociated with new systems. As such, they are critically important in ensuring\nthat adequate privacy protections are built in. However, current methods to\nquantify privacy risk rely heavily on experienced analysts picking the\n\"correct\" risk level on e.g. a five-point scale. In this paper, we argue that a\nmore scientific quantification of privacy risk increases accuracy and\nreliability and can thus make it easier to build privacy-friendly systems. We\ndiscuss how the impact and likelihood of privacy violations can be decomposed\nand quantified, and stress the importance of meaningful metrics and units of\nmeasurement. We suggest a method of quantifying and representing privacy risk\nthat considers a collection of factors as well as a variety of contexts and\nattacker models. We conclude by identifying some of the major research\nquestions to take this approach further in a variety of application scenarios. \n\n"}
{"id": "1709.05748", "contents": "Title: Settling Payments Fast and Private: Efficient Decentralized Routing for\n  Path-Based Transactions Abstract: Path-based transaction (PBT) networks, which settle payments from one user to\nanother via a path of intermediaries, are a growing area of research. They\novercome the scalability and privacy issues in cryptocurrencies like Bitcoin\nand Ethereum by replacing expensive and slow on-chain blockchain operations\nwith inexpensive and fast off-chain transfers. In the form of credit networks\nsuch as Ripple and Stellar, they also enable low-price real-time gross\nsettlements across different currencies. For example, SilentWhsipers is a\nrecently proposed fully distributed credit network relying on path-based\ntransactions for secure and in particular private payments without a public\nledger. At the core of a decentralized PBT network is a routing algorithm that\ndiscovers transaction paths between payer and payee. During the last year, a\nnumber of routing algorithms have been proposed. However, the existing ad hoc\nefforts lack either efficiency or privacy. In this work, we first identify\nseveral efficiency concerns in SilentWhsipers. Armed with this knowledge, we\ndesign and evaluate SpeedyMurmurs, a novel routing algorithm for decentralized\nPBT networks using efficient and flexible embedding-based path discovery and\non-demand efficient stabilization to handle the dynamics of a PBT network. Our\nsimulation study, based on real-world data from the currently deployed Ripple\ncredit network, indicates that SpeedyMurmurs reduces the overhead of\nstabilization by up to two orders of magnitude and the overhead of routing a\ntransaction by more than a factor of two. Furthermore, using SpeedyMurmurs\nmaintains at least the same success ratio as decentralized landmark routing,\nwhile providing lower delays. Finally, SpeedyMurmurs achieves key privacy goals\nfor routing in PBT networks. \n\n"}
{"id": "1709.06528", "contents": "Title: Secure and Trustable Electronic Medical Records Sharing using Blockchain Abstract: Electronic medical records (EMRs) are critical, highly sensitive private\ninformation in healthcare, and need to be frequently shared among peers.\nBlockchain provides a shared, immutable and transparent history of all the\ntransactions to build applications with trust, accountability and transparency.\nThis provides a unique opportunity to develop a secure and trustable EMR data\nmanagement and sharing system using blockchain. In this paper, we present our\nperspectives on blockchain based healthcare data management, in particular, for\nEMR data sharing between healthcare providers and for research studies. We\npropose a framework on managing and sharing EMR data for cancer patient care.\nIn collaboration with Stony Brook University Hospital, we implemented our\nframework in a prototype that ensures privacy, security, availability, and\nfine-grained access control over EMR data. The proposed work can significantly\nreduce the turnaround time for EMR sharing, improve decision making for medical\ncare, and reduce the overall cost \n\n"}
{"id": "1709.06870", "contents": "Title: A tight security reduction in the quantum random oracle model for\n  code-based signature schemes Abstract: Quantum secure signature schemes have a lot of attention recently, in\nparticular because of the NIST call to standardize quantum safe cryptography.\nHowever, only few signature schemes can have concrete quantum security because\nof technical difficulties associated with the Quantum Random Oracle Model\n(QROM). In this paper, we show that code-based signature schemes based on the\nfull domain hash paradigm can behave very well in the QROM i.e. that we can\nhave tight security reductions. We also study quantum algorithms related to the\nunderlying code-based assumption. Finally, we apply our reduction to a concrete\nexample: the SURF signature scheme. We provide parameters for 128 bits of\nquantum security in the QROM and show that the obtained parameters are\ncompetitive compared to other similar quantum secure signature schemes. \n\n"}
{"id": "1709.06921", "contents": "Title: A Byzantine Fault-Tolerant Ordering Service for the Hyperledger Fabric\n  Blockchain Platform Abstract: Hyperledger Fabric (HLF) is a flexible permissioned blockchain platform\ndesigned for business applications beyond the basic digital coin addressed by\nBitcoin and other existing networks. A key property of HLF is its\nextensibility, and in particular the support for multiple ordering services for\nbuilding the blockchain. Nonetheless, the version 1.0 was launched in early\n2017 without an implementation of a Byzantine fault-tolerant (BFT) ordering\nservice. To overcome this limitation, we designed, implemented, and evaluated a\nBFT ordering service for HLF on top of the BFT-SMaRt state machine\nreplication/consensus library, implementing also optimizations for wide-area\ndeployment. Our results show that HLF with our ordering service can achieve up\nto ten thousand transactions per second and write a transaction irrevocably in\nthe blockchain in half a second, even with peers spread in different\ncontinents. \n\n"}
{"id": "1709.07574", "contents": "Title: Modeling and Detecting False Data Injection Attacks against Railway\n  Traction Power Systems Abstract: Modern urban railways extensively use computerized sensing and control\ntechnologies to achieve safe, reliable, and well-timed operations. However, the\nuse of these technologies may provide a convenient leverage to cyber-attackers\nwho have bypassed the air gaps and aim at causing safety incidents and service\ndisruptions. In this paper, we study false data injection (FDI) attacks against\nrailways' traction power systems (TPSes). Specifically, we analyze two types of\nFDI attacks on the train-borne voltage, current, and position sensor\nmeasurements - which we call efficiency attack and safety attack -- that (i)\nmaximize the system's total power consumption and (ii) mislead trains' local\nvoltages to exceed given safety-critical thresholds, respectively. To\ncounteract, we develop a global attack detection (GAD) system that serializes a\nbad data detector and a novel secondary attack detector designed based on\nunique TPS characteristics. With intact position data of trains, our detection\nsystem can effectively detect the FDI attacks on trains' voltage and current\nmeasurements even if the attacker has full and accurate knowledge of the TPS,\nattack detection, and real-time system state. In particular, the GAD system\nfeatures an adaptive mechanism that ensures low false positive and negative\nrates in detecting the attacks under noisy system measurements. Extensive\nsimulations driven by realistic running profiles of trains verify that a TPS\nsetup is vulnerable to the FDI attacks, but these attacks can be detected\neffectively by the proposed GAD while ensuring a low false positive rate. \n\n"}
{"id": "1709.07886", "contents": "Title: Machine Learning Models that Remember Too Much Abstract: Machine learning (ML) is becoming a commodity. Numerous ML frameworks and\nservices are available to data holders who are not ML experts but want to train\npredictive models on their data. It is important that ML models trained on\nsensitive inputs (e.g., personal images or documents) not leak too much\ninformation about the training data.\n  We consider a malicious ML provider who supplies model-training code to the\ndata holder, does not observe the training, but then obtains white- or\nblack-box access to the resulting model. In this setting, we design and\nimplement practical algorithms, some of them very similar to standard ML\ntechniques such as regularization and data augmentation, that \"memorize\"\ninformation about the training dataset in the model yet the model is as\naccurate and predictive as a conventionally trained model. We then explain how\nthe adversary can extract memorized information from the model.\n  We evaluate our techniques on standard ML tasks for image classification\n(CIFAR10), face recognition (LFW and FaceScrub), and text analysis (20\nNewsgroups and IMDB). In all cases, we show how our algorithms create models\nthat have high predictive power yet allow accurate extraction of subsets of\ntheir training data. \n\n"}
{"id": "1709.08149", "contents": "Title: Stabilization of Networked Control Systems under DoS Attacks and Output\n  Quantization Abstract: This paper addresses quantized output feedback stabilization under\nDenial-of-Service (DoS) attacks. First, assuming that the duration and\nfrequency of DoS attacks are averagely bounded and that an initial bound of the\nplant state is known, we propose an output encoding scheme that achieves\nexponential convergence with finite data rates. Next we show that a suitable\nstate transformation allows us to remove the assumption on the DoS frequency.\nFinally, we discuss the derivation of state bounds under DoS attacks and obtain\nsufficient conditions on the bounds of DoS duration and frequency for achieving\nLyapunov stability of the closed-loop system. \n\n"}
{"id": "1710.00809", "contents": "Title: The Capacity of Private Information Retrieval with Partially Known\n  Private Side Information Abstract: We consider the problem of private information retrieval (PIR) of a single\nmessage out of $K$ messages from $N$ replicated and non-colluding databases\nwhere a cache-enabled user (retriever) of cache-size $M$ possesses side\ninformation in the form of full messages that are partially known to the\ndatabases. In this model, the user and the databases engage in a two-phase\nscheme, namely, the prefetching phase where the user acquires side information\nand the retrieval phase where the user downloads desired information. In the\nprefetching phase, the user receives $m_n$ full messages from the $n$th\ndatabase, under the cache memory size constraint $\\sum_{n=1}^N m_n \\leq M$. In\nthe retrieval phase, the user wishes to retrieve a message such that no\nindividual database learns anything about the identity of the desired message.\nIn addition, the identities of the side information messages that the user did\nnot prefetch from a database must remain private against that database. Since\nthe side information provided by each database in the prefetching phase is\nknown by the providing database and the side information must be kept private\nagainst the remaining databases, we coin this model as \\textit{partially known\nprivate side information}. We characterize the capacity of the PIR with\npartially known private side information to be\n$C=\\left(1+\\frac{1}{N}+\\cdots+\\frac{1}{N^{K-M-1}}\\right)^{-1}=\\frac{1-\\frac{1}{N}}{1-(\\frac{1}{N})^{K-M}}$.\nInterestingly, this result is the same if none of the databases knows any of\nthe prefetched side information, i.e., when the side information is obtained\nexternally, a problem posed by Kadhe et al. and settled by Chen-Wang-Jafar\nrecently. Thus, our result implies that there is no loss in using the same\ndatabases for both prefetching and retrieval phases. \n\n"}
{"id": "1710.01567", "contents": "Title: Cloud/fog computing resource management and pricing for blockchain\n  networks Abstract: The mining process in blockchain requires solving a proof-of-work puzzle,\nwhich is resource expensive to implement in mobile devices due to the high\ncomputing power and energy needed. In this paper, we, for the first time,\nconsider edge computing as an enabler for mobile blockchain. In particular, we\nstudy edge computing resource management and pricing to support mobile\nblockchain applications in which the mining process of miners can be offloaded\nto an edge computing service provider. We formulate a two-stage Stackelberg\ngame to jointly maximize the profit of the edge computing service provider and\nthe individual utilities of the miners. In the first stage, the service\nprovider sets the price of edge computing nodes. In the second stage, the\nminers decide on the service demand to purchase based on the observed prices.\nWe apply the backward induction to analyze the sub-game perfect equilibrium in\neach stage for both uniform and discriminatory pricing schemes. For the uniform\npricing where the same price is applied to all miners, the existence and\nuniqueness of Stackelberg equilibrium are validated by identifying the best\nresponse strategies of the miners. For the discriminatory pricing where the\ndifferent prices are applied to different miners, the Stackelberg equilibrium\nis proved to exist and be unique by capitalizing on the Variational Inequality\ntheory. Further, the real experimental results are employed to justify our\nproposed model. \n\n"}
{"id": "1710.03959", "contents": "Title: Deep learning in remote sensing: a review Abstract: Standing at the paradigm shift towards data-intensive science, machine\nlearning techniques are becoming increasingly important. In particular, as a\nmajor breakthrough in the field, deep learning has proven as an extremely\npowerful tool in many fields. Shall we embrace deep learning as the key to all?\nOr, should we resist a 'black-box' solution? There are controversial opinions\nin the remote sensing community. In this article, we analyze the challenges of\nusing deep learning for remote sensing data analysis, review the recent\nadvances, and provide resources to make deep learning in remote sensing\nridiculously simple to start with. More importantly, we advocate remote sensing\nscientists to bring their expertise into deep learning, and use it as an\nimplicit general model to tackle unprecedented large-scale influential\nchallenges, such as climate change and urbanization. \n\n"}
{"id": "1710.05233", "contents": "Title: Learners that Use Little Information Abstract: We study learning algorithms that are restricted to using a small amount of\ninformation from their input sample. We introduce a category of learning\nalgorithms we term $d$-bit information learners, which are algorithms whose\noutput conveys at most $d$ bits of information of their input. A central theme\nin this work is that such algorithms generalize.\n  We focus on the learning capacity of these algorithms, and prove sample\ncomplexity bounds with tight dependencies on the confidence and error\nparameters. We also observe connections with well studied notions such as\nsample compression schemes, Occam's razor, PAC-Bayes and differential privacy.\n  We discuss an approach that allows us to prove upper bounds on the amount of\ninformation that algorithms reveal about their inputs, and also provide a lower\nbound by showing a simple concept class for which every (possibly randomized)\nempirical risk minimizer must reveal a lot of information. On the other hand,\nwe show that in the distribution-dependent setting every VC class has empirical\nrisk minimizers that do not reveal a lot of information. \n\n"}
{"id": "1710.05527", "contents": "Title: The Devils in The Details: Placing Decoy Routers in the Internet Abstract: Decoy Routing, the use of routers (rather than end hosts) as proxies, is a\nnew direction in anti-censorship research. Decoy Routers (DRs), placed in\nAutonomous Systems, proxy traffic from users; so the adversary, e.g., a\ncensorious government, attempts to avoid them. It is quite difficult to place\nDRs so the adversary cannot route around them for example, we need the\ncooperation of 850 ASes to contain China alone. In this paper, we consider a\ndifferent approach. We begin by noting that DRs need not intercept all the\nnetwork paths from a country, just those leading to Overt Destinations, i.e.,\nunfiltered websites hosted outside the country (usually popular ones, so that\nclient traffic to the OD does not make the censor suspicious. Our first\nquestion is; How many ASes are required for installing DRs to intercept a large\nfraction of paths from, e.g., China to the top n websites (as per Alexa)? How\ndoes this number grow with n? Few ASes (approx. 30) intercept over 90% of paths\nto the top n sites, for n = 10, 20...200. Our first contribution is to\ndemonstrate with real paths that the number of ASes required for a world-wide\nDR framework is small (approx. 30). Further, censor nations attempts to filter\ntraffic along the paths transiting these 30 ASes will not only block their own\ncitizens, but others residing in foreign ASes. Our second contribution in this\npaper is to consider the details of DR placement: not just in which ASes DRs\nshould be placed to intercept traffic, but exactly where in each AS. We find\nthat even with our small number of ASes, we still need a total of about 11,700\nDRs.We conclude that, even though a DR system involves far fewer ASes than\npreviously thought, it is still a major undertaking. For example, the current\nrouters cost over 10.3 billion USD, so if DR at line speed requires all new\nhardware, the cost alone would make such a project unfeasible for most actors. \n\n"}
{"id": "1710.05798", "contents": "Title: Requirements for Secure Clock Synchronization Abstract: This paper establishes a fundamental theory of secure clock synchronization.\nAccurate clock synchronization is the backbone of systems managing power\ndistribution, financial transactions, telecommunication operations, database\nservices, etc. Some clock synchronization (time transfer) systems, such as the\nGlobal Navigation Satellite Systems (GNSS), are based on one-way communication\nfrom a master to a slave clock. Others, such as the Network Transport Protocol\n(NTP), and the IEEE 1588 Precision Time Protocol (PTP), involve two-way\ncommunication between the master and slave. This paper shows that all one-way\ntime transfer protocols are vulnerable to replay attacks that can potentially\ncompromise timing information. A set of conditions for secure two-way clock\nsynchronization is proposed and proved to be necessary and sufficient. It is\nshown that IEEE 1588 PTP, although a two-way synchronization protocol, is not\ncompliant with these conditions, and is therefore insecure. Requirements for\nsecure IEEE 1588 PTP are proposed, and a second example protocol is offered to\nillustrate the range of compliant systems. \n\n"}
{"id": "1710.06304", "contents": "Title: Towards CT-quality Ultrasound Imaging using Deep Learning Abstract: The cost-effectiveness and practical harmlessness of ultrasound imaging have\nmade it one of the most widespread tools for medical diagnosis. Unfortunately,\nthe beam-forming based image formation produces granular speckle noise,\nblurring, shading and other artifacts. To overcome these effects, the ultimate\ngoal would be to reconstruct the tissue acoustic properties by solving a full\nwave propagation inverse problem. In this work, we make a step towards this\ngoal, using Multi-Resolution Convolutional Neural Networks (CNN). As a result,\nwe are able to reconstruct CT-quality images from the reflected ultrasound\nradio-frequency(RF) data obtained by simulation from real CT scans of a human\nbody. We also show that CNN is able to imitate existing computationally heavy\ndespeckling methods, thereby saving orders of magnitude in computations and\nmaking them amenable to real-time applications. \n\n"}
{"id": "1710.07308", "contents": "Title: Formally Secure Compilation of Unsafe Low-Level Components (Extended\n  Abstract) Abstract: We propose a new formal criterion for secure compilation, providing strong\nsecurity guarantees for components written in unsafe, low-level languages with\nC-style undefined behavior. Our criterion goes beyond recent proposals, which\nprotect the trace properties of a single component against an adversarial\ncontext, to model dynamic compromise in a system of mutually distrustful\ncomponents. Each component is protected from all the others until it receives\nan input that triggers an undefined behavior, causing it to become compromised\nand attack the remaining uncompromised components. To illustrate this model, we\ndemonstrate a secure compilation chain for an unsafe language with buffers,\nprocedures, and components, compiled to a simple RISC abstract machine with\nbuilt-in compartmentalization. The protection guarantees offered by this\nabstract machine can be achieved at the machine-code level using either\nsoftware fault isolation or tag-based reference monitoring. We are working on\nmachine-checked proofs showing that this compiler satisfies our secure\ncompilation criterion. \n\n"}
{"id": "1710.08223", "contents": "Title: Learning With Errors and Extrapolated Dihedral Cosets Abstract: The hardness of the learning with errors (LWE) problem is one of the most\nfruitful resources of modern cryptography. In particular, it is one of the most\nprominent candidates for secure post-quantum cryptography. Understanding its\nquantum complexity is therefore an important goal. We show that under quantum\npolynomial time reductions, LWE is equivalent to a relaxed version of the\ndihedral coset problem (DCP), which we call extrapolated DCP (eDCP). The extent\nof extrapolation varies with the LWE noise rate. By considering different\nextents of extrapolation, our result generalizes Regev's famous proof that if\nDCP is in BQP (quantum poly-time) then so is LWE (FOCS'02). We also discuss a\nconnection between eDCP and Childs and Van Dam's algorithm for generalized\nhidden shift problems (SODA'07). Our result implies that a BQP solution for LWE\nmight not require the full power of solving DCP, but rather only a solution for\nits relaxed version, eDCP, which could be easier. \n\n"}
{"id": "1710.09437", "contents": "Title: Casper the Friendly Finality Gadget Abstract: We introduce Casper, a proof of stake-based finality system which overlays an\nexisting proof of work blockchain. Casper is a partial consensus mechanism\ncombining proof of stake algorithm research and Byzantine fault tolerant\nconsensus theory. We introduce our system, prove some desirable features, and\nshow defenses against long range revisions and catastrophic crashes. The Casper\noverlay provides almost any proof of work chain with additional protections\nagainst block reversions. \n\n"}
{"id": "1710.09549", "contents": "Title: Context-Aware Generative Adversarial Privacy Abstract: Preserving the utility of published datasets while simultaneously providing\nprovable privacy guarantees is a well-known challenge. On the one hand,\ncontext-free privacy solutions, such as differential privacy, provide strong\nprivacy guarantees, but often lead to a significant reduction in utility. On\nthe other hand, context-aware privacy solutions, such as information theoretic\nprivacy, achieve an improved privacy-utility tradeoff, but assume that the data\nholder has access to dataset statistics. We circumvent these limitations by\nintroducing a novel context-aware privacy framework called generative\nadversarial privacy (GAP). GAP leverages recent advancements in generative\nadversarial networks (GANs) to allow the data holder to learn privatization\nschemes from the dataset itself. Under GAP, learning the privacy mechanism is\nformulated as a constrained minimax game between two players: a privatizer that\nsanitizes the dataset in a way that limits the risk of inference attacks on the\nindividuals' private variables, and an adversary that tries to infer the\nprivate variables from the sanitized dataset. To evaluate GAP's performance, we\ninvestigate two simple (yet canonical) statistical dataset models: (a) the\nbinary data model, and (b) the binary Gaussian mixture model. For both models,\nwe derive game-theoretically optimal minimax privacy mechanisms, and show that\nthe privacy mechanisms learned from data (in a generative adversarial fashion)\nmatch the theoretically optimal ones. This demonstrates that our framework can\nbe easily applied in practice, even in the absence of dataset statistics. \n\n"}
{"id": "1711.00385", "contents": "Title: Pseudorandom States, Non-Cloning Theorems and Quantum Money Abstract: We propose the concept of pseudorandom states and study their constructions,\nproperties, and applications. Under the assumption that quantum-secure one-way\nfunctions exist, we present concrete and efficient constructions of\npseudorandom states. The non-cloning theorem plays a central role in our\nstudy---it motivates the proper definition and characterizes one of the\nimportant properties of pseudorandom quantum states. Namely, there is no\nefficient quantum algorithm that can create more copies of the state from a\ngiven number of pseudorandom states. As the main application, we prove that any\nfamily of pseudorandom states naturally gives rise to a private-key quantum\nmoney scheme. \n\n"}
{"id": "1711.00795", "contents": "Title: Talos: Neutralizing Vulnerabilities with Security Workarounds for Rapid\n  Response Abstract: Considerable delays often exist between the discovery of a vulnerability and\nthe issue of a patch. One way to mitigate this window of vulnerability is to\nuse a configuration workaround, which prevents the vulnerable code from being\nexecuted at the cost of some lost functionality -- but only if one is\navailable. Since program configurations are not specifically designed to\nmitigate software vulnerabilities, we find that they only cover 25.2% of\nvulnerabilities.\n  To minimize patch delay vulnerabilities and address the limitations of\nconfiguration workarounds, we propose Security Workarounds for Rapid Response\n(SWRRs), which are designed to neutralize security vulnerabilities in a timely,\nsecure, and unobtrusive manner. Similar to configuration workarounds, SWRRs\nneutralize vulnerabilities by preventing vulnerable code from being executed at\nthe cost of some lost functionality. However, the key difference is that SWRRs\nuse existing error-handling code within programs, which enables them to be\nmechanically inserted with minimal knowledge of the program and minimal\ndeveloper effort. This allows SWRRs to achieve high coverage while still being\nfast and easy to deploy.\n  We have designed and implemented Talos, a system that mechanically\ninstruments SWRRs into a given program, and evaluate it on five popular Linux\nserver programs. We run exploits against 11 real-world software vulnerabilities\nand show that SWRRs neutralize the vulnerabilities in all cases. Quantitative\nmeasurements on 320 SWRRs indicate that SWRRs instrumented by Talos can\nneutralize 75.1% of all potential vulnerabilities and incur a loss of\nfunctionality similar to configuration workarounds in 71.3% of those cases. Our\noverall conclusion is that automatically generated SWRRs can safely mitigate\n2.1x more vulnerabilities, while only incurring a loss of functionality\ncomparable to that of traditional configuration workarounds. \n\n"}
{"id": "1711.00853", "contents": "Title: Using Bernstein-Vazirani Algorithm to Attack Block Ciphers Abstract: In this paper, we study applications of Bernstein-Vazirani algorithm and\npresent several new methods to attack block ciphers. Specifically, we first\npresent a quantum algorithm for finding the linear structures of a function.\nBased on it, we propose new quantum distinguishers for the 3-round Feistel\nscheme and a new quantum algorithm to recover partial key of the Even-Mansour\nconstruction. Afterwards, by observing that the linear structures of a\nencryption function are actually high probability differentials of it, we apply\nour algorithm to differential analysis and impossible differential\ncryptanalysis respectively. We also propose a new kind of differential\ncryptanalysis, called quantum small probability differential cryptanalysis,\nbased on the fact that the linear structures found by our algorithm are also\nthe linear structure of each component function. To our knowledge, no similar\nmethod was proposed before. The efficiency and success probability of all\nattacks are analyzed rigorously. Since our algorithm treats the encryption\nfunction as a whole, it avoid the disadvantage of traditional differential\ncryptanalysis that it is difficult to extending the differential path. \n\n"}
{"id": "1711.01218", "contents": "Title: Background Subtraction via Fast Robust Matrix Completion Abstract: Background subtraction is the primary task of the majority of video\ninspection systems. The most important part of the background subtraction which\nis common among different algorithms is background modeling. In this regard,\nour paper addresses the problem of background modeling in a computationally\nefficient way, which is important for current eruption of \"big data\" processing\ncoming from high resolution multi-channel videos. Our model is based on the\nassumption that background in natural images lies on a low-dimensional\nsubspace. We formulated and solved this problem in a low-rank matrix completion\nframework. In modeling the background, we benefited from the in-face extended\nFrank-Wolfe algorithm for solving a defined convex optimization problem. We\nevaluated our fast robust matrix completion (fRMC) method on both background\nmodels challenge (BMC) and Stuttgart artificial background subtraction (SABS)\ndatasets. The results were compared with the robust principle component\nanalysis (RPCA) and low-rank robust matrix completion (RMC) methods, both\nsolved by inexact augmented Lagrangian multiplier (IALM). The results showed\nfaster computation, at least twice as when IALM solver is used, while having a\ncomparable accuracy even better in some challenges, in subtracting the\nbackgrounds in order to detect moving objects in the scene. \n\n"}
{"id": "1711.01306", "contents": "Title: Deep Learning-Based Dynamic Watermarking for Secure Signal\n  Authentication in the Internet of Things Abstract: Securing the Internet of Things (IoT) is a necessary milestone toward\nexpediting the deployment of its applications and services. In particular, the\nfunctionality of the IoT devices is extremely dependent on the reliability of\ntheir message transmission. Cyber attacks such as data injection,\neavesdropping, and man-in-the-middle threats can lead to security challenges.\nSecuring IoT devices against such attacks requires accounting for their\nstringent computational power and need for low-latency operations. In this\npaper, a novel deep learning method is proposed for dynamic watermarking of IoT\nsignals to detect cyber attacks. The proposed learning framework, based on a\nlong short-term memory (LSTM) structure, enables the IoT devices to extract a\nset of stochastic features from their generated signal and dynamically\nwatermark these features into the signal. This method enables the IoT's cloud\ncenter, which collects signals from the IoT devices, to effectively\nauthenticate the reliability of the signals. Furthermore, the proposed method\nprevents complicated attack scenarios such as eavesdropping in which the cyber\nattacker collects the data from the IoT devices and aims to break the\nwatermarking algorithm. Simulation results show that, with an attack detection\ndelay of under 1 second the messages can be transmitted from IoT devices with\nan almost 100% reliability. \n\n"}
{"id": "1711.01894", "contents": "Title: Adversarial Frontier Stitching for Remote Neural Network Watermarking Abstract: The state of the art performance of deep learning models comes at a high cost\nfor companies and institutions, due to the tedious data collection and the\nheavy processing requirements. Recently, [35, 22] proposed to watermark\nconvolutional neural networks for image classification, by embedding\ninformation into their weights. While this is a clear progress towards model\nprotection, this technique solely allows for extracting the watermark from a\nnetwork that one accesses locally and entirely.\n  Instead, we aim at allowing the extraction of the watermark from a neural\nnetwork (or any other machine learning model) that is operated remotely, and\navailable through a service API. To this end, we propose to mark the model's\naction itself, tweaking slightly its decision frontiers so that a set of\nspecific queries convey the desired information. In the present paper, we\nformally introduce the problem and propose a novel zero-bit watermarking\nalgorithm that makes use of adversarial model examples. While limiting the loss\nof performance of the protected model, this algorithm allows subsequent\nextraction of the watermark using only few queries. We experimented the\napproach on three neural networks designed for image classification, in the\ncontext of MNIST digit recognition task. \n\n"}
{"id": "1711.01939", "contents": "Title: Advanced Analytics for Connected Cars Cyber Security Abstract: The vehicular connectivity revolution is fueling the automotive industry's\nmost significant transformation seen in decades. However, as modern vehicles\nbecome more connected, they also become much more vulnerable to cyber-attacks.\nIn this paper, a fully working machine learning approach is proposed to protect\nconnected vehicles (fleets and individuals) against such attacks. We present a\nsystem that monitors different vehicle's interfaces (Network, CAN and OS),\nextracts relevant information based on configurable rules and sends it to a\ntrained generative model to detect deviations from normal behavior. Using\nconfigurable data collector, we provide a higher level of data abstraction as\nthe model is trained based on events instead of raw data, which has a\nnoise-filtering effect and eliminates the need to retrain the model whenever a\nprotocol changes. We present a new approach for detecting anomalies, tailored\nto the temporal nature of our domain. Adapting the hybrid approach of Gutflaish\net al. (2017) to the fully temporal setting, we first train a Hidden Markov\nModel to learn normal vehicle behavior, and then a regression model to\ncalibrate the likelihood threshold for anomaly. Using this architecture, our\nmethod detects sophisticated and realistic anomalies, which are missed by other\nexisting methods monitoring the CAN bus only. We also demonstrate the\nsuperiority of adaptive thresholds over static ones. Furthermore, our approach\nscales efficiently from monitoring individual cars to serving large fleets. We\ndemonstrate the competitive advantage of our model via encouraging empirical\nresults. \n\n"}
{"id": "1711.02879", "contents": "Title: LatentPoison - Adversarial Attacks On The Latent Space Abstract: Robustness and security of machine learning (ML) systems are intertwined,\nwherein a non-robust ML system (classifiers, regressors, etc.) can be subject\nto attacks using a wide variety of exploits. With the advent of scalable deep\nlearning methodologies, a lot of emphasis has been put on the robustness of\nsupervised, unsupervised and reinforcement learning algorithms. Here, we study\nthe robustness of the latent space of a deep variational autoencoder (dVAE), an\nunsupervised generative framework, to show that it is indeed possible to\nperturb the latent space, flip the class predictions and keep the\nclassification probability approximately equal before and after an attack. This\nmeans that an agent that looks at the outputs of a decoder would remain\noblivious to an attack. \n\n"}
{"id": "1711.03235", "contents": "Title: Exfiltration of Data from Air-gapped Networks via Unmodulated LED Status\n  Indicators Abstract: The light-emitting diode(LED) is widely used as an indicator on the\ninformation device. Early in 2002, Loughry et al studied the exfiltration of\nLED indicators and found the kind of LEDs unmodulated to indicate some state of\nthe device can hardly be utilized to establish covert channels. In our paper, a\nnovel approach is proposed to modulate this kind of LEDs. We use binary\nfrequency shift keying(B-FSK) to replace on-off keying(OOK) in modulation. In\norder to verify the validity, we implement a prototype of an exfiltration\nmalware. Our experiment show a great improvement in the imperceptibility of\ncovert communication. It is available to leak data covertly from air-gapped\nnetworks via unmodulated LED status indicators. \n\n"}
{"id": "1711.03656", "contents": "Title: p-FP: Extraction, Classification, and Prediction of Website Fingerprints\n  with Deep Learning Abstract: Recent advances in learning Deep Neural Network (DNN) architectures have\nreceived a great deal of attention due to their ability to outperform\nstate-of-the-art classifiers across a wide range of applications, with little\nor no feature engineering. In this paper, we broadly study the applicability of\ndeep learning to website fingerprinting. We show that unsupervised DNNs can be\nused to extract low-dimensional feature vectors that improve the performance of\nstate-of-the-art website fingerprinting attacks. When used as classifiers, we\nshow that they can match or exceed performance of existing attacks across a\nrange of application scenarios, including fingerprinting Tor website traces,\nfingerprinting search engine queries over Tor, defeating fingerprinting\ndefenses, and fingerprinting TLS-encrypted websites. Finally, we show that DNNs\ncan be used to predict the fingerprintability of a website based on its\ncontents, achieving 99% accuracy on a data set of 4500 website downloads. \n\n"}
{"id": "1711.03707", "contents": "Title: Learning under $p$-Tampering Attacks Abstract: Recently, Mahloujifar and Mahmoody (TCC'17) studied attacks against learning\nalgorithms using a special case of Valiant's malicious noise, called\n$p$-tampering, in which the adversary gets to change any training example with\nindependent probability $p$ but is limited to only choose malicious examples\nwith correct labels. They obtained $p$-tampering attacks that increase the\nerror probability in the so called targeted poisoning model in which the\nadversary's goal is to increase the loss of the trained hypothesis over a\nparticular test example. At the heart of their attack was an efficient\nalgorithm to bias the expected value of any bounded real-output function\nthrough $p$-tampering.\n  In this work, we present new biasing attacks for increasing the expected\nvalue of bounded real-valued functions. Our improved biasing attacks, directly\nimply improved $p$-tampering attacks against learners in the targeted poisoning\nmodel. As a bonus, our attacks come with considerably simpler analysis. We also\nstudy the possibility of PAC learning under $p$-tampering attacks in the\nnon-targeted (aka indiscriminate) setting where the adversary's goal is to\nincrease the risk of the generated hypothesis (for a random test example). We\nshow that PAC learning is possible under $p$-tampering poisoning attacks\nessentially whenever it is possible in the realizable setting without the\nattacks. We further show that PAC learning under \"correct-label\" adversarial\nnoise is not possible in general, if the adversary could choose the (still\nlimited to only $p$ fraction of) tampered examples that she substitutes with\nadversarially chosen ones. Our formal model for such \"bounded-budget\" tampering\nattackers is inspired by the notions of (strong) adaptive corruption in secure\nmulti-party computation. \n\n"}
{"id": "1711.04069", "contents": "Title: Towards ECDSA key derivation from deep embeddings for novel Blockchain\n  applications Abstract: In this work, we propose a straightforward method to derive Elliptic Curve\nDigital Signature Algorithm (ECDSA) key pairs from embeddings created using\nDeep Learning and Metric Learning approaches. We also show that these keys\nallows the derivation of cryptocurrencies (such as Bitcoin) addresses that can\nbe used to transfer and receive funds, allowing novel Blockchain-based\napplications that can be used to transfer funds or data directly to domains\nsuch as image, text, sound or any other domain where Deep Learning can extract\nhigh-quality embeddings; providing thus a novel integration between the\nproperties of the Blockchain-based technologies such as trust minimization and\ndecentralization together with the high-quality learned representations from\nDeep Learning techniques. \n\n"}
{"id": "1711.05189", "contents": "Title: CryptoDL: Deep Neural Networks over Encrypted Data Abstract: Machine learning algorithms based on deep neural networks have achieved\nremarkable results and are being extensively used in different domains.\nHowever, the machine learning algorithms requires access to raw data which is\noften privacy sensitive. To address this issue, we develop new techniques to\nprovide solutions for running deep neural networks over encrypted data. In this\npaper, we develop new techniques to adopt deep neural networks within the\npractical limitation of current homomorphic encryption schemes. More\nspecifically, we focus on classification of the well-known convolutional neural\nnetworks (CNN). First, we design methods for approximation of the activation\nfunctions commonly used in CNNs (i.e. ReLU, Sigmoid, and Tanh) with low degree\npolynomials which is essential for efficient homomorphic encryption schemes.\nThen, we train convolutional neural networks with the approximation polynomials\ninstead of original activation functions and analyze the performance of the\nmodels. Finally, we implement convolutional neural networks over encrypted data\nand measure performance of the models. Our experimental results validate the\nsoundness of our approach with several convolutional neural networks with\nvarying number of layers and structures. When applied to the MNIST optical\ncharacter recognition tasks, our approach achieves 99.52\\% accuracy which\nsignificantly outperforms the state-of-the-art solutions and is very close to\nthe accuracy of the best non-private version, 99.77\\%. Also, it can make close\nto 164000 predictions per hour. We also applied our approach to CIFAR-10, which\nis much more complex compared to MNIST, and were able to achieve 91.5\\%\naccuracy with approximation polynomials used as activation functions. These\nresults show that CryptoDL provides efficient, accurate and scalable\nprivacy-preserving predictions. \n\n"}
{"id": "1711.05244", "contents": "Title: Private Information Retrieval from Storage Constrained Databases --\n  Coded Caching meets PIR Abstract: Private information retrieval (PIR) allows a user to retrieve a desired\nmessage out of $K$ possible messages from $N$ databases without revealing the\nidentity of the desired message. Majority of existing works on PIR assume the\npresence of replicated databases, each storing all the $K$ messages. In this\nwork, we consider the problem of PIR from storage constrained databases. Each\ndatabase has a storage capacity of $\\mu KL$ bits, where $K$ is the number of\nmessages, $L$ is the size of each message in bits, and $\\mu \\in [1/N, 1]$ is\nthe normalized storage. In the storage constrained PIR problem, there are two\nkey design questions: a) how to store content across each database under\nstorage constraints; and b) construction of schemes that allow efficient PIR\nthrough storage constrained databases. The main contribution of this work is a\ngeneral achievable scheme for PIR from storage constrained databases for any\nvalue of storage. In particular, for any $(N,K)$, with normalized storage $\\mu=\nt/N$, where the parameter $t$ can take integer values $t \\in \\{1, 2, \\ldots,\nN\\}$, we show that our proposed PIR scheme achieves a download cost of\n$\\left(1+ \\frac{1}{t}+ \\frac{1}{t^{2}}+ \\cdots + \\frac{1}{t^{K-1}}\\right)$. The\nextreme case when $\\mu=1$ (i.e., $t=N$) corresponds to the setting of\nreplicated databases with full storage. For this extremal setting, our scheme\nrecovers the information-theoretically optimal download cost characterized by\nSun and Jafar as $\\left(1+ \\frac{1}{N}+ \\cdots + \\frac{1}{N^{K-1}}\\right)$. For\nthe other extreme, when $\\mu= 1/N$ (i.e., $t=1$), the proposed scheme achieves\na download cost of $K$. The interesting aspect of the result is that for\nintermediate values of storage, i.e., $1/N < \\mu <1$, the proposed scheme can\nstrictly outperform memory-sharing between extreme values of storage. \n\n"}
{"id": "1711.05296", "contents": "Title: Practical Whole-System Provenance Capture Abstract: Data provenance describes how data came to be in its present form. It\nincludes data sources and the transformations that have been applied to them.\nData provenance has many uses, from forensics and security to aiding the\nreproducibility of scientific experiments. We present CamFlow, a whole-system\nprovenance capture mechanism that integrates easily into a PaaS offering. While\nthere have been several prior whole-system provenance systems that captured a\ncomprehensive, systemic and ubiquitous record of a system's behavior, none have\nbeen widely adopted. They either A) impose too much overhead, B) are designed\nfor long-outdated kernel releases and are hard to port to current systems, C)\ngenerate too much data, or D) are designed for a single system. CamFlow\naddresses these shortcoming by: 1) leveraging the latest kernel design advances\nto achieve efficiency; 2) using a self-contained, easily maintainable\nimplementation relying on a Linux Security Module, NetFilter, and other\nexisting kernel facilities; 3) providing a mechanism to tailor the captured\nprovenance data to the needs of the application; and 4) making it easy to\nintegrate provenance across distributed systems. The provenance we capture is\nstreamed and consumed by tenant-built auditor applications. We illustrate the\nusability of our implementation by describing three such applications:\ndemonstrating compliance with data regulations; performing fault/intrusion\ndetection; and implementing data loss prevention. We also show how CamFlow can\nbe leveraged to capture meaningful provenance without modifying existing\napplications. \n\n"}
{"id": "1711.07220", "contents": "Title: Integrating Privacy-Enhancing Technologies into the Internet\n  Infrastructure Abstract: The AN.ON-Next project aims to integrate privacy-enhancing technologies into\nthe internet's infrastructure and establish them in the consumer mass market.\n  The technologies in focus include a basis protection at internet service\nprovider level, an improved overlay network-based protection and a concept for\nprivacy protection in the emerging 5G mobile network. A crucial success factor\nwill be the viable adjustment and development of standards, business models and\npricing strategies for those new technologies. \n\n"}
{"id": "1711.07356", "contents": "Title: Evaluating Robustness of Neural Networks with Mixed Integer Programming Abstract: Neural networks have demonstrated considerable success on a wide variety of\nreal-world problems. However, networks trained only to optimize for training\naccuracy can often be fooled by adversarial examples - slightly perturbed\ninputs that are misclassified with high confidence. Verification of networks\nenables us to gauge their vulnerability to such adversarial examples. We\nformulate verification of piecewise-linear neural networks as a mixed integer\nprogram. On a representative task of finding minimum adversarial distortions,\nour verifier is two to three orders of magnitude quicker than the\nstate-of-the-art. We achieve this computational speedup via tight formulations\nfor non-linearities, as well as a novel presolve algorithm that makes full use\nof all information available. The computational speedup allows us to verify\nproperties on convolutional networks with an order of magnitude more ReLUs than\nnetworks previously verified by any complete verifier. In particular, we\ndetermine for the first time the exact adversarial accuracy of an MNIST\nclassifier to perturbations with bounded $l_\\infty$ norm $\\epsilon=0.1$: for\nthis classifier, we find an adversarial example for 4.38% of samples, and a\ncertificate of robustness (to perturbations with bounded norm) for the\nremainder. Across all robust training procedures and network architectures\nconsidered, we are able to certify more samples than the state-of-the-art and\nfind more adversarial examples than a strong first-order attack. \n\n"}
{"id": "1711.07451", "contents": "Title: AndroVault: Constructing Knowledge Graph from Millions of Android Apps\n  for Automated Analysis Abstract: Data driven research on Android has gained a great momentum these years. The\nabundance of data facilitates knowledge learning, however, also increases the\ndifficulty of data preprocessing. Therefore, it is non-trivial to prepare a\ndemanding and accurate set of data for research. In this work, we put forward\nAndroVault, a framework for the Android research composing of data collection,\nknowledge representation and knowledge extraction. It has started with a\nlong-running web crawler for data collection (both apps and description) since\n2013, which guarantees the timeliness of data; With static analysis and dynamic\nanalysis of the collected data, we compute a variety of attributes to\ncharacterize Android apps. After that, we employ a knowledge graph to connect\nall these apps by computing their correlation in terms of attributes; Last, we\nleverage multiple technologies such as logical inference, machine learning, and\ncorrelation analysis to extract facts (more accurate and demanding, either high\nlevel or not, data) that are beneficial for a specific research problem. With\nthe produced data of high quality, we have successfully conducted many research\nworks including malware detection, code generation, and Android testing. We\nwould like to release our data to the research community in an authenticated\nmanner, and encourage them to conduct productive research. \n\n"}
{"id": "1711.08002", "contents": "Title: MemJam: A False Dependency Attack against Constant-Time Crypto\n  Implementations Abstract: Cache attacks exploit memory access patterns of cryptographic\nimplementations. Constant-Time implementation techniques have become an\nindispensable tool in fighting cache timing attacks. These techniques engineer\nthe memory accesses of cryptographic operations to follow a uniform key\nindependent pattern. However, the constant-time behavior is dependent on the\nunderlying architecture, which can be highly complex and often incorporates\nunpublished features. CacheBleed attack targets cache bank conflicts and\nthereby invalidates the assumption that microarchitectural side-channel\nadversaries can only observe memory with cache line granularity. In this work,\nwe propose MemJam, a side-channel attack that exploits false dependency of\nmemory read-after-write and provides a high quality intra cache level timing\nchannel. As a proof of concept, we demonstrate the first key recovery attacks\non a constant-time implementation of AES, and a SM4 implementation with cache\nprotection in the current Intel Integrated Performance Primitives (Intel IPP)\ncryptographic library. Further, we demonstrate the first intra cache level\ntiming attack on SGX by reproducing the AES key recovery results on an enclave\nthat performs encryption using the aforementioned constant-time implementation\nof AES. Our results show that we can not only use this side channel to\nefficiently attack memory dependent cryptographic operations but also to bypass\nproposed protections. Compared to CacheBleed, which is limited to older\nprocessor generations, MemJam is the first intra cache level attack applicable\nto all major Intel processors including the latest generations that support the\nSGX extension. \n\n"}
{"id": "1711.09666", "contents": "Title: DeepAPT: Nation-State APT Attribution Using End-to-End Deep Neural\n  Networks Abstract: In recent years numerous advanced malware, aka advanced persistent threats\n(APT) are allegedly developed by nation-states. The task of attributing an APT\nto a specific nation-state is extremely challenging for several reasons. Each\nnation-state has usually more than a single cyber unit that develops such\nadvanced malware, rendering traditional authorship attribution algorithms\nuseless. Furthermore, those APTs use state-of-the-art evasion techniques,\nmaking feature extraction challenging. Finally, the dataset of such available\nAPTs is extremely small.\n  In this paper we describe how deep neural networks (DNN) could be\nsuccessfully employed for nation-state APT attribution. We use sandbox reports\n(recording the behavior of the APT when run dynamically) as raw input for the\nneural network, allowing the DNN to learn high level feature abstractions of\nthe APTs itself. Using a test set of 1,000 Chinese and Russian developed APTs,\nwe achieved an accuracy rate of 94.6%. \n\n"}
{"id": "1711.09793", "contents": "Title: The Status of Quantum-Based Long-Term Secure Communication over the\n  Internet Abstract: Sensitive digital data, such as health information or governmental archives,\nare often stored for decades or centuries. The processing of such data calls\nfor long-term security. Secure channels on the Internet require robust key\nestablishment methods. Currently used key distribution protocols are either\nvulnerable to future attacks based on Shor's algorithm, or vulnerable in\nprinciple due to their reliance on computational problems. Quantum-based key\ndistribution protocols are information-theoretically secure and offer long-term\nsecurity. However, significant obstacles to their real-world use remain. This\npaper, which results from a multidisciplinary project involving computer\nscientists and physicists, systematizes knowledge about obstacles to and\nstrategies for the realization of long-term secure Internet communication from\nquantum-based key distribution. We discuss performance and security\nparticulars, consider the specific challenges arising from multi-user network\nsettings, and identify key challenges for actual deployment. \n\n"}
{"id": "1711.11008", "contents": "Title: Security Risks in Deep Learning Implementations Abstract: Advance in deep learning algorithms overshadows their security risk in\nsoftware implementations. This paper discloses a set of vulnerabilities in\npopular deep learning frameworks including Caffe, TensorFlow, and Torch.\nContrast to the small code size of deep learning models, these deep learning\nframeworks are complex and contain heavy dependencies on numerous open source\npackages. This paper considers the risks caused by these vulnerabilities by\nstudying their impact on common deep learning applications such as voice\nrecognition and image classifications. By exploiting these framework\nimplementations, attackers can launch denial-of-service attacks that crash or\nhang a deep learning application, or control-flow hijacking attacks that cause\neither system compromise or recognition evasions. The goal of this paper is to\ndraw attention on the software implementations and call for the community\neffort to improve the security of deep learning frameworks. \n\n"}
{"id": "1711.11386", "contents": "Title: MR image reconstruction using deep density priors Abstract: Algorithms for Magnetic Resonance (MR) image reconstruction from undersampled\nmeasurements exploit prior information to compensate for missing k-space data.\nDeep learning (DL) provides a powerful framework for extracting such\ninformation from existing image datasets, through learning, and then using it\nfor reconstruction. Leveraging this, recent methods employed DL to learn\nmappings from undersampled to fully sampled images using paired datasets,\nincluding undersampled and corresponding fully sampled images, integrating\nprior knowledge implicitly. In this article, we propose an alternative approach\nthat learns the probability distribution of fully sampled MR images using\nunsupervised DL, specifically Variational Autoencoders (VAE), and use this as\nan explicit prior term in reconstruction, completely decoupling the encoding\noperation from the prior. The resulting reconstruction algorithm enjoys a\npowerful image prior to compensate for missing k-space data without requiring\npaired datasets for training nor being prone to associated sensitivities, such\nas deviations in undersampling patterns used in training and test time or coil\nsettings. We evaluated the proposed method with T1 weighted images from a\npublicly available dataset, multi-coil complex images acquired from healthy\nvolunteers (N=8) and images with white matter lesions. The proposed algorithm,\nusing the VAE prior, produced visually high quality reconstructions and\nachieved low RMSE values, outperforming most of the alternative methods on the\nsame dataset. On multi-coil complex data, the algorithm yielded accurate\nmagnitude and phase reconstruction results. In the experiments on images with\nwhite matter lesions, the method faithfully reconstructed the lesions.\n  Keywords: Reconstruction, MRI, prior probability, machine learning, deep\nlearning, unsupervised learning, density estimation \n\n"}
{"id": "1712.02193", "contents": "Title: Systematizing Genome Privacy Research: A Privacy-Enhancing Technologies\n  Perspective Abstract: Rapid advances in human genomics are enabling researchers to gain a better\nunderstanding of the role of the genome in our health and well-being,\nstimulating hope for more effective and cost efficient healthcare. However,\nthis also prompts a number of security and privacy concerns stemming from the\ndistinctive characteristics of genomic data. To address them, a new research\ncommunity has emerged and produced a large number of publications and\ninitiatives.\n  In this paper, we rely on a structured methodology to contextualize and\nprovide a critical analysis of the current knowledge on privacy-enhancing\ntechnologies used for testing, storing, and sharing genomic data, using a\nrepresentative sample of the work published in the past decade. We identify and\ndiscuss limitations, technical challenges, and issues faced by the community,\nfocusing in particular on those that are inherently tied to the nature of the\nproblem and are harder for the community alone to address. Finally, we report\non the importance and difficulty of the identified challenges based on an\nonline survey of genome data privacy experts \n\n"}
{"id": "1712.02875", "contents": "Title: One More Way to Encrypt a Message Abstract: This work describes an example of an application of a novel method for\nsymmetric cryptography. Its purpose is to show how a regular message can be\nencrypted and then decrypted in an easy, yet secure way. The encrypting method\nintroduced in this work is different from others because it involves decimals\nas well as integers, encrypting the same initial message differently every\ntime, and inserting misleading digits into every encrypted message, thus making\nthe task of breaking the code even harder. A C++ program was written to support\neach chapter. \n\n"}
{"id": "1712.03031", "contents": "Title: An Empirical Study on Price Differentiation Based on System Fingerprints Abstract: Price differentiation describes a marketing strategy to determine the price\nof goods on the basis of a potential customer's attributes like location,\nfinancial status, possessions, or behavior. Several cases of online price\ndifferentiation have been revealed in recent years. For example, different\npricing based on a user's location was discovered for online office supply\nchain stores and there were indications that offers for hotel rooms are priced\nhigher for Apple users compared to Windows users at certain online booking\nwebsites. One potential source for relevant distinctive features are\n\\emph{system fingerprints}, i.\\,e., a technique to recognize users' systems by\nidentifying unique attributes such as the source IP address or system\nconfiguration. In this paper, we shed light on the ecosystem of pricing at\nonline platforms and aim to detect if and how such platform providers make use\nof price differentiation based on digital system fingerprints. We designed and\nimplemented an automated price scanner capable of disguising itself as an\narbitrary system, leveraging real-world system fingerprints, and searched for\nprice differences related to different features (e.\\,g., user location,\nlanguage setting, or operating system). This system allows us to explore price\ndifferentiation cases and expose those characteristic features of a system that\nmay influence a product's price. \n\n"}
{"id": "1712.05419", "contents": "Title: DANCin SEQ2SEQ: Fooling Text Classifiers with Adversarial Text Example\n  Generation Abstract: Machine learning models are powerful but fallible. Generating adversarial\nexamples - inputs deliberately crafted to cause model misclassification or\nother errors - can yield important insight into model assumptions and\nvulnerabilities. Despite significant recent work on adversarial example\ngeneration targeting image classifiers, relatively little work exists exploring\nadversarial example generation for text classifiers; additionally, many\nexisting adversarial example generation algorithms require full access to\ntarget model parameters, rendering them impractical for many real-world\nattacks. In this work, we introduce DANCin SEQ2SEQ, a GAN-inspired algorithm\nfor adversarial text example generation targeting largely black-box text\nclassifiers. We recast adversarial text example generation as a reinforcement\nlearning problem, and demonstrate that our algorithm offers preliminary but\npromising steps towards generating semantically meaningful adversarial text\nexamples in a real-world attack scenario. \n\n"}
{"id": "1712.05908", "contents": "Title: Fingerprinting Cryptographic Protocols with Key Exchange using an\n  Entropy Measure Abstract: Encryption has increasingly been used in all applications for various\npurposes, but it also brings big challenges to network security. In this paper,\nwe take first steps towards addressing some of these chal- lenges by\nintroducing a novel system to identify key exchange protocols, which are\nusually required if encryption keys are not pre-shared. We ob- served that key\nexchange protocols yield certain patterns of high-entropy data blocks, e.g. as\nfound in key material. We propose a multi-resolution approach of accurately\ndetecting high-entropy data blocks and a method of generating scalable\nfingerprints for cryptographic protocols. We pro- vide experimental evidence\nthat our approach has great potential for identifying cryptographic protocols\nby their unique key exchanges, and furthermore for detecting malware traffic\nthat includes customized key exchange protocols. \n\n"}
{"id": "1712.05958", "contents": "Title: Toward Secure Edge Networks Taming Device to Device (D2D) Communication\n  in IoT Abstract: The growing popularity of Internet-of-Things (IoT) has created the need for\nnetwork-based traffic anomaly detection systems that could identify misbehaving\ndevices. In this work, we propose a lightweight technique, IoT-guard, for\nidentifying malicious traffic flows. IoT-guard uses semi-supervised learning to\ndistinguish between malicious and benign device behaviours using the network\ntraffic generated by devices. In order to achieve this, we extracted 39\nfeatures from network logs and discard any features containing redundant\ninformation. After feature selection, fuzzy C-Mean (FCM) algorithm was trained\nto obtain clusters discriminating benign traffic from malicious traffic. We\nstudied the feature scores in these clusters and use this information to\npredict the type of new traffic flows. IoT-guard was evaluated using a\nreal-world testbed with more than 30 devices. The results show that IoTguard\nachieves high accuracy (98%), in differentiating various types of malicious and\nbenign traffic, with low false positive rates. Furthermore, it has low resource\nfootprint and can operate on OpenWRT enabled access points and COTS computing\nboards. \n\n"}
{"id": "1712.07008", "contents": "Title: Privacy-Preserving Adversarial Networks Abstract: We propose a data-driven framework for optimizing privacy-preserving data\nrelease mechanisms to attain the information-theoretically optimal tradeoff\nbetween minimizing distortion of useful data and concealing specific sensitive\ninformation. Our approach employs adversarially-trained neural networks to\nimplement randomized mechanisms and to perform a variational approximation of\nmutual information privacy. We validate our Privacy-Preserving Adversarial\nNetworks (PPAN) framework via proof-of-concept experiments on discrete and\ncontinuous synthetic data, as well as the MNIST handwritten digits dataset. For\nsynthetic data, our model-agnostic PPAN approach achieves tradeoff points very\nclose to the optimal tradeoffs that are analytically-derived from model\nknowledge. In experiments with the MNIST data, we visually demonstrate a\nlearned tradeoff between minimizing the pixel-level distortion versus\nconcealing the written digit. \n\n"}
{"id": "1712.07882", "contents": "Title: The Pyramid Scheme: Oblivious RAM for Trusted Processors Abstract: Modern processors, e.g., Intel SGX, allow applications to isolate secret code\nand data in encrypted memory regions called enclaves. While encryption\neffectively hides the contents of memory, the sequence of address references\nissued by the secret code leaks information. This is a serious problem because\nthese leaks can easily break the confidentiality guarantees of enclaves.\n  In this paper, we explore Oblivious RAM (ORAM) designs that prevent these\ninformation leaks under the constraints of modern SGX processors. Most ORAMs\nare a poor fit for these processors because they have high constant overhead\nfactors or require large private memories, which are not available in these\nprocessors. We address these limitations with a new hierarchical ORAM\nconstruction, the Pyramid ORAM, that is optimized towards online bandwidth cost\nand small blocks. It uses a new hashing scheme that circumvents the complexity\nof previous hierarchical schemes.\n  We present an efficient x64-optimized implementation of Pyramid ORAM that\nuses only the processor's registers as private memory. We compare Pyramid ORAM\nwith Circuit ORAM, a state-of-the-art tree-based ORAM scheme that also uses\nconstant private memory. Pyramid ORAM has better online asymptotical complexity\nthan Circuit ORAM. Our implementation of Pyramid ORAM and Circuit ORAM\nvalidates this: as all hierarchical schemes, Pyramid ORAM has high variance of\naccess latencies; although latency can be high for some accesses, for typical\nconfigurations Pyramid ORAM provides access latencies that are 8X better than\nCircuit ORAM for 99% of accesses. Although the best known hierarchical ORAM has\nbetter asymptotical complexity, Pyramid ORAM has significantly lower constant\noverhead factors, making it the preferred choice in practice. \n\n"}
{"id": "1712.08427", "contents": "Title: Contour: A Practical System for Binary Transparency Abstract: Transparency is crucial in security-critical applications that rely on\nauthoritative information, as it provides a robust mechanism for holding these\nauthorities accountable for their actions. A number of solutions have emerged\nin recent years that provide transparency in the setting of certificate\nissuance, and Bitcoin provides an example of how to enforce transparency in a\nfinancial setting. In this work we shift to a new setting, the distribution of\nsoftware package binaries, and present a system for so-called \"binary\ntransparency.\" Our solution, Contour, uses proactive methods for providing\ntransparency, privacy, and availability, even in the face of persistent\nman-in-the-middle attacks. We also demonstrate, via benchmarks and a test\ndeployment for the Debian software repository, that Contour is the only system\nfor binary transparency that satisfies the efficiency and coordination\nrequirements that would make it possible to deploy today. \n\n"}
{"id": "1712.08675", "contents": "Title: Boundary-sensitive Network for Portrait Segmentation Abstract: Compared to the general semantic segmentation problem, portrait segmentation\nhas higher precision requirement on boundary area. However, this problem has\nnot been well studied in previous works. In this paper, we propose a\nboundary-sensitive deep neural network (BSN) for portrait segmentation. BSN\nintroduces three novel techniques. First, an individual boundary-sensitive\nkernel is proposed by dilating the contour line and assigning the boundary\npixels with multi-class labels. Second, a global boundary-sensitive kernel is\nemployed as a position sensitive prior to further constrain the overall shape\nof the segmentation map. Third, we train a boundary-sensitive attribute\nclassifier jointly with the segmentation network to reinforce the network with\nsemantic boundary shape information. We have evaluated BSN on the current\nlargest public portrait segmentation dataset, i.e, the PFCN dataset, as well as\nthe portrait images collected from other three popular image segmentation\ndatasets: COCO, COCO-Stuff, and PASCAL VOC. Our method achieves the superior\nquantitative and qualitative performance over state-of-the-arts on all the\ndatasets, especially on the boundary area. \n\n"}
{"id": "1712.08713", "contents": "Title: Query-limited Black-box Attacks to Classifiers Abstract: We study black-box attacks on machine learning classifiers where each query\nto the model incurs some cost or risk of detection to the adversary. We focus\nexplicitly on minimizing the number of queries as a major objective.\nSpecifically, we consider the problem of attacking machine learning classifiers\nsubject to a budget of feature modification cost while minimizing the number of\nqueries, where each query returns only a class and confidence score. We\ndescribe an approach that uses Bayesian optimization to minimize the number of\nqueries, and find that the number of queries can be reduced to approximately\none tenth of the number needed through a random strategy for scenarios where\nthe feature modification cost budget is low. \n\n"}
{"id": "1712.08940", "contents": "Title: Studying the Impact of Managers on Password Strength and Reuse Abstract: Despite their well-known security problems, passwords are still the incumbent\nauthentication method for virtually all online services. To remedy the\nsituation, end-users are very often referred to password managers as a solution\nto the password reuse and password weakness problems. However, to date the\nactual impact of password managers on password security and reuse has not been\nstudied systematically.\n  In this paper, we provide the first large-scale study of the password\nmanagers' influence on users' real-life passwords. From 476 participants of an\nonline survey on users' password creation and management strategies, we recruit\n170 participants that allowed us to monitor their passwords in-situ through a\nbrowser plugin. In contrast to prior work, we collect the passwords' entry\nmethods (e.g., human or password manager) in addition to the passwords and\ntheir metrics. Based on our collected data and our survey, we gain a more\ncomplete picture of the factors that influence our participants' passwords'\nstrength and reuse. We quantify for the first time that password managers\nindeed benefit the password strength and uniqueness, however, also our results\nalso suggest that those benefits depend on the users' strategies and that\nmanagers without password generators rather aggravate the existing problems. \n\n"}
{"id": "1712.09722", "contents": "Title: Satellite-Based Continuous-Variable Quantum Communications:\n  State-of-the-Art and a Predictive Outlook Abstract: The recent launch of the Micius quantum-enabled satellite heralds a major\nstep forward for long-range quantum communication. Using single-photon\ndiscrete-variable quantum states, this exciting new development proves beyond\nany doubt that all of the quantum protocols previously deployed over limited\nranges in terrestrial experiments can, in fact, be translated to global\ndistances via the use of low-orbit satellites. In this work, we survey the\nimminent extension of space-based quantum communication to the\ncontinuous-variable regime - the quantum regime perhaps most closely related to\nclassical wireless communications. The CV regime offers the potential for\nincreased communication performance and represents the next major step forward\nfor quantum communications and the development of the global quantum internet. \n\n"}
{"id": "1801.00129", "contents": "Title: Why the Equifax Breach Should Not Have Mattered Abstract: Data security, which is concerned with the prevention of unauthorized access\nto computers, databases, and websites, helps protect digital privacy and ensure\ndata integrity. It is extremely difficult, however, to make security\nwatertight, and security breaches are not uncommon. The consequences of stolen\ncredentials go well beyond the leakage of other types of information because\nthey can further compromise other systems. This paper criticizes the practice\nof using clear-text identity attributes, such as Social Security or driver's\nlicense numbers -- which are in principle not even secret -- as acceptable\nauthentication tokens or assertions of ownership, and proposes a simple\nprotocol that straightforwardly applies public-key cryptography to make\nidentity claims verifiable, even when they are issued remotely via the\nInternet. This protocol has the potential of elevating the business practices\nof credit providers, rental agencies, and other service companies that have\nhitherto exposed consumers to the risk of identity theft, to where identity\ntheft becomes virtually impossible. \n\n"}
{"id": "1801.00318", "contents": "Title: Towards Building an Intelligent Anti-Malware System: A Deep Learning\n  Approach using Support Vector Machine (SVM) for Malware Classification Abstract: Effective and efficient mitigation of malware is a long-time endeavor in the\ninformation security community. The development of an anti-malware system that\ncan counteract an unknown malware is a prolific activity that may benefit\nseveral sectors. We envision an intelligent anti-malware system that utilizes\nthe power of deep learning (DL) models. Using such models would enable the\ndetection of newly-released malware through mathematical generalization. That\nis, finding the relationship between a given malware $x$ and its corresponding\nmalware family $y$, $f: x \\mapsto y$. To accomplish this feat, we used the\nMalimg dataset (Nataraj et al., 2011) which consists of malware images that\nwere processed from malware binaries, and then we trained the following DL\nmodels 1 to classify each malware family: CNN-SVM (Tang, 2013), GRU-SVM\n(Agarap, 2017), and MLP-SVM. Empirical evidence has shown that the GRU-SVM\nstands out among the DL models with a predictive accuracy of ~84.92%. This\nstands to reason for the mentioned model had the relatively most sophisticated\narchitecture design among the presented models. The exploration of an even more\noptimal DL-SVM model is the next stage towards the engineering of an\nintelligent anti-malware system. \n\n"}
{"id": "1801.00349", "contents": "Title: A General Framework for Adversarial Examples with Objectives Abstract: Images perturbed subtly to be misclassified by neural networks, called\nadversarial examples, have emerged as a technically deep challenge and an\nimportant concern for several application domains. Most research on adversarial\nexamples takes as its only constraint that the perturbed images are similar to\nthe originals. However, real-world application of these ideas often requires\nthe examples to satisfy additional objectives, which are typically enforced\nthrough custom modifications of the perturbation process. In this paper, we\npropose adversarial generative nets (AGNs), a general methodology to train a\ngenerator neural network to emit adversarial examples satisfying desired\nobjectives. We demonstrate the ability of AGNs to accommodate a wide range of\nobjectives, including imprecise ones difficult to model, in two application\ndomains. In particular, we demonstrate physical adversarial examples---eyeglass\nframes designed to fool face recognition---with better robustness,\ninconspicuousness, and scalability than previous approaches, as well as a new\nattack to fool a handwritten-digit classifier. \n\n"}
{"id": "1801.00528", "contents": "Title: Bayesian Tabulation Audits: Explained and Extended Abstract: Tabulation audits for an election provide statistical evidence that a\nreported contest outcome is \"correct\" (meaning that the tabulation of votes was\nproperly performed), or else the tabulation audit determines the correct\noutcome.\n  Stark proposed risk-limiting tabulation audits for this purpose; such audits\nare effective and are beginning to be used in practice.\n  We expand the study of election audits based on Bayesian methods, first\nintroduced by Rivest and Shen in 2012. (The risk-limiting audits proposed by\nStark are \"frequentist\" rather than Bayesian in character.)\n  We first provide a simplified presentation of Bayesian tabulation audits. A\nBayesian tabulation audit begins by drawing a random sample of the votes in\nthat contest, and tallying those votes. It then considers what effect\nstatistical variations of this tally have on the contest outcome. If such\nvariations almost always yield the previously-reported outcome, the audit\nterminates, accepting the reported outcome. Otherwise the audit is repeated\nwith an enlarged sample.\n  Bayesian audits are attractive because they work with any method for\ndetermining the winner (such as ranked-choice voting).\n  We then show how Bayesian audits may be extended to handle more complex\nsituations, such as auditing contests that \\emph{span multiple jurisdictions},\nor are otherwise \"stratified.\"\n  We highlight the auditing of such multiple-jurisdiction contests where some\nof the jurisdictions have an electronic cast vote record (CVR) for each cast\npaper vote, while the others do not. Complex situations such as this may arise\nnaturally when some counties in a state have upgraded to new equipment, while\nothers have not. Bayesian audits are able to handle such situations in a\nstraightforward manner.\n  We also discuss the benefits and relevant considerations for using Bayesian\naudits in practice. \n\n"}
{"id": "1801.00554", "contents": "Title: Did you hear that? Adversarial Examples Against Automatic Speech\n  Recognition Abstract: Speech is a common and effective way of communication between humans, and\nmodern consumer devices such as smartphones and home hubs are equipped with\ndeep learning based accurate automatic speech recognition to enable natural\ninteraction between humans and machines. Recently, researchers have\ndemonstrated powerful attacks against machine learning models that can fool\nthem to produceincorrect results. However, nearly all previous research in\nadversarial attacks has focused on image recognition and object detection\nmodels. In this short paper, we present a first of its kind demonstration of\nadversarial attacks against speech classification model. Our algorithm performs\ntargeted attacks with 87% success by adding small background noise without\nhaving to know the underlying model parameter and architecture. Our attack only\nchanges the least significant bits of a subset of audio clip samples, and the\nnoise does not change 89% the human listener's perception of the audio clip as\nevaluated in our human study. \n\n"}
{"id": "1801.00634", "contents": "Title: High Dimensional Spaces, Deep Learning and Adversarial Examples Abstract: In this paper, we analyze deep learning from a mathematical point of view and\nderive several novel results. The results are based on intriguing mathematical\nproperties of high dimensional spaces. We first look at perturbation based\nadversarial examples and show how they can be understood using topological and\ngeometrical arguments in high dimensions. We point out mistake in an argument\npresented in prior published literature, and we present a more rigorous,\ngeneral and correct mathematical result to explain adversarial examples in\nterms of topology of image manifolds. Second, we look at optimization\nlandscapes of deep neural networks and examine the number of saddle points\nrelative to that of local minima. Third, we show how multiresolution nature of\nimages explains perturbation based adversarial examples in form of a stronger\nresult. Our results state that expectation of $L_2$-norm of adversarial\nperturbations is $O\\left(\\frac{1}{\\sqrt{n}}\\right)$ and therefore shrinks to 0\nas image resolution $n$ becomes arbitrarily large. Finally, by incorporating\nthe parts-whole manifold learning hypothesis for natural images, we investigate\nthe working of deep neural networks and root causes of adversarial examples and\ndiscuss how future improvements can be made and how adversarial examples can be\neliminated. \n\n"}
{"id": "1801.00933", "contents": "Title: New Directions for Trust in the Certificate Authority Ecosystem Abstract: Many of the benefits we derive from the Internet require trust in the\nauthenticity of HTTPS connections. Unfortunately, the public key certification\necosystem that underwrites this trust has failed us on numerous occasions.\nTowards an exploration of the root causes we present an update to the common\nknowledge about the Certificate Authority (CA) ecosystem. Based on our findings\nthe certificate ecosystem currently undergoes a drastic transformation. Big\nsteps towards ubiquitous encryption were made, however, on the expense of trust\nfor authentication of communication partners. Furthermore we describe systemic\nproblems rooted in misaligned incentives between players in the ecosystem. We\ndepict that proposed security extensions do not correctly realign these\nincentives. As such we argue that it is worth considering alternative methods\nof authentication. As a first step in this direction we propose an\ninsurance-based mechanism and we demonstrate that it is technically feasible. \n\n"}
{"id": "1801.01571", "contents": "Title: Robust PCA for Anomaly Detection in Cyber Networks Abstract: This paper uses network packet capture data to demonstrate how Robust\nPrincipal Component Analysis (RPCA) can be used in a new way to detect\nanomalies which serve as cyber-network attack indicators. The approach requires\nonly a few parameters to be learned using partitioned training data and shows\npromise of ameliorating the need for an exhaustive set of examples of different\ntypes of network attacks. For Lincoln Lab's DARPA intrusion detection data set,\nthe method achieves low false-positive rates while maintaining reasonable\ntrue-positive rates on individual packets. In addition, the method correctly\ndetected packet streams in which an attack which was not previously\nencountered, or trained on, appears. \n\n"}
{"id": "1801.01944", "contents": "Title: Audio Adversarial Examples: Targeted Attacks on Speech-to-Text Abstract: We construct targeted audio adversarial examples on automatic speech\nrecognition. Given any audio waveform, we can produce another that is over\n99.9% similar, but transcribes as any phrase we choose (recognizing up to 50\ncharacters per second of audio). We apply our white-box iterative\noptimization-based attack to Mozilla's implementation DeepSpeech end-to-end,\nand show it has a 100% success rate. The feasibility of this attack introduce a\nnew domain to study adversarial examples. \n\n"}
{"id": "1801.02613", "contents": "Title: Characterizing Adversarial Subspaces Using Local Intrinsic\n  Dimensionality Abstract: Deep Neural Networks (DNNs) have recently been shown to be vulnerable against\nadversarial examples, which are carefully crafted instances that can mislead\nDNNs to make errors during prediction. To better understand such attacks, a\ncharacterization is needed of the properties of regions (the so-called\n'adversarial subspaces') in which adversarial examples lie. We tackle this\nchallenge by characterizing the dimensional properties of adversarial regions,\nvia the use of Local Intrinsic Dimensionality (LID). LID assesses the\nspace-filling capability of the region surrounding a reference example, based\non the distance distribution of the example to its neighbors. We first provide\nexplanations about how adversarial perturbation can affect the LID\ncharacteristic of adversarial regions, and then show empirically that LID\ncharacteristics can facilitate the distinction of adversarial examples\ngenerated using state-of-the-art attacks. As a proof-of-concept, we show that a\npotential application of LID is to distinguish adversarial examples, and the\npreliminary results show that it can outperform several state-of-the-art\ndetection measures by large margins for five attack strategies considered in\nthis paper across three benchmark datasets. Our analysis of the LID\ncharacteristic for adversarial regions not only motivates new directions of\neffective adversarial defense, but also opens up more challenges for developing\nnew attacks to better understand the vulnerabilities of DNNs. \n\n"}
{"id": "1801.02780", "contents": "Title: Rogue Signs: Deceiving Traffic Sign Recognition with Malicious Ads and\n  Logos Abstract: We propose a new real-world attack against the computer vision based systems\nof autonomous vehicles (AVs). Our novel Sign Embedding attack exploits the\nconcept of adversarial examples to modify innocuous signs and advertisements in\nthe environment such that they are classified as the adversary's desired\ntraffic sign with high confidence. Our attack greatly expands the scope of the\nthreat posed to AVs since adversaries are no longer restricted to just\nmodifying existing traffic signs as in previous work. Our attack pipeline\ngenerates adversarial samples which are robust to the environmental conditions\nand noisy image transformations present in the physical world. We ensure this\nby including a variety of possible image transformations in the optimization\nproblem used to generate adversarial samples. We verify the robustness of the\nadversarial samples by printing them out and carrying out drive-by tests\nsimulating the conditions under which image capture would occur in a real-world\nscenario. We experimented with physical attack samples for different distances,\nlighting conditions and camera angles. In addition, extensive evaluations were\ncarried out in the virtual setting for a variety of image transformations. The\nadversarial samples generated using our method have adversarial success rates\nin excess of 95% in the physical as well as virtual settings. \n\n"}
{"id": "1801.02850", "contents": "Title: Less is More: Culling the Training Set to Improve Robustness of Deep\n  Neural Networks Abstract: Deep neural networks are vulnerable to adversarial examples. Prior defenses\nattempted to make deep networks more robust by either changing the network\narchitecture or augmenting the training set with adversarial examples, but both\nhave inherent limitations. Motivated by recent research that shows outliers in\nthe training set have a high negative influence on the trained model, we\nstudied the relationship between model robustness and the quality of the\ntraining set. We first show that outliers give the model better generalization\nability but weaker robustness. Next, we propose an adversarial example\ndetection framework, in which we design two methods for removing outliers from\ntraining set to obtain the sanitized model and then detect adversarial example\nby calculating the difference of outputs between the original and the sanitized\nmodel. We evaluated the framework on both MNIST and SVHN. Based on the\ndifference measured by Kullback-Leibler divergence, we could detect adversarial\nexamples with accuracy between 94.67% to 99.89%. \n\n"}
{"id": "1801.02950", "contents": "Title: Adversarial Deep Learning for Robust Detection of Binary Encoded Malware Abstract: Malware is constantly adapting in order to avoid detection. Model based\nmalware detectors, such as SVM and neural networks, are vulnerable to so-called\nadversarial examples which are modest changes to detectable malware that allows\nthe resulting malware to evade detection. Continuous-valued methods that are\nrobust to adversarial examples of images have been developed using saddle-point\noptimization formulations. We are inspired by them to develop similar methods\nfor the discrete, e.g. binary, domain which characterizes the features of\nmalware. A specific extra challenge of malware is that the adversarial examples\nmust be generated in a way that preserves their malicious functionality. We\nintroduce methods capable of generating functionally preserved adversarial\nmalware examples in the binary domain. Using the saddle-point formulation, we\nincorporate the adversarial examples into the training of models that are\nrobust to them. We evaluate the effectiveness of the methods and others in the\nliterature on a set of Portable Execution~(PE) files. Comparison prompts our\nintroduction of an online measure computed during training to assess general\nexpectation of robustness. \n\n"}
{"id": "1801.04179", "contents": "Title: Arhuaco: Deep Learning and Isolation Based Security for Distributed\n  High-Throughput Computing Abstract: Grid computing systems require innovative methods and tools to identify\ncybersecurity incidents and perform autonomous actions i.e. without\nadministrator intervention. They also require methods to isolate and trace job\npayload activity in order to protect users and find evidence of malicious\nbehavior. We introduce an integrated approach of security monitoring via\nSecurity by Isolation with Linux Containers and Deep Learning methods for the\nanalysis of real time data in Grid jobs running inside virtualized\nHigh-Throughput Computing infrastructure in order to detect and prevent\nintrusions. A dataset for malware detection in Grid computing is described. We\nshow in addition the utilization of generative methods with Recurrent Neural\nNetworks to improve the collected dataset. We present Arhuaco, a prototype\nimplementation of the proposed methods. We empirically study the performance of\nour technique. The results show that Arhuaco outperforms other methods used in\nIntrusion Detection Systems for Grid Computing. The study is carried out in the\nALICE Collaboration Grid, part of the Worldwide LHC Computing Grid. \n\n"}
{"id": "1801.04354", "contents": "Title: Black-box Generation of Adversarial Text Sequences to Evade Deep\n  Learning Classifiers Abstract: Although various techniques have been proposed to generate adversarial\nsamples for white-box attacks on text, little attention has been paid to\nblack-box attacks, which are more realistic scenarios. In this paper, we\npresent a novel algorithm, DeepWordBug, to effectively generate small text\nperturbations in a black-box setting that forces a deep-learning classifier to\nmisclassify a text input. We employ novel scoring strategies to identify the\ncritical tokens that, if modified, cause the classifier to make an incorrect\nprediction. Simple character-level transformations are applied to the\nhighest-ranked tokens in order to minimize the edit distance of the\nperturbation, yet change the original classification. We evaluated DeepWordBug\non eight real-world text datasets, including text classification, sentiment\nanalysis, and spam detection. We compare the result of DeepWordBug with two\nbaselines: Random (Black-box) and Gradient (White-box). Our experimental\nresults indicate that DeepWordBug reduces the prediction accuracy of current\nstate-of-the-art deep-learning models, including a decrease of 68\\% on average\nfor a Word-LSTM model and 48\\% on average for a Char-CNN model. \n\n"}
{"id": "1801.04598", "contents": "Title: Non-Locality in Interactive Proofs Abstract: In multi-prover interactive proofs (MIPs), the verifier is usually\nnon-adaptive. This stems from an implicit problem which we call\n``contamination'' by the verifier. We make explicit the verifier contamination\nproblem, and identify a solution by constructing a generalization of the MIP\nmodel. This new model quantifies non-locality as a new dimension in the\ncharacterization of MIPs. A new property of zero-knowledge emerges naturally as\na result by also quantifying the non-locality of the simulator. \n\n"}
{"id": "1801.04668", "contents": "Title: The decoding failure probability of MDPC codes Abstract: Moderate Density Parity Check (MDPC) codes are defined here as codes which\nhave a parity-check matrix whose row weight is $O(\\sqrt{n})$ where $n$ is the\nlength $n$ of the code. They can be decoded like LDPC codes but they decode\nmuch less errors than LDPC codes: the number of errors they can decode in this\ncase is of order $\\Theta(\\sqrt{n})$. Despite this fact they have been proved\nvery useful in cryptography for devising key exchange mechanisms. They have\nalso been proposed in McEliece type cryptosystems. However in this case, the\nparameters that have been proposed in \\cite{MTSB13} were broken in\n\\cite{GJS16}. This attack exploits the fact that the decoding failure\nprobability is non-negligible. We show here that this attack can be thwarted by\nchoosing the parameters in a more conservative way. We first show that such\ncodes can decode with a simple bit-flipping decoder any pattern of\n$O\\left(\\frac{\\sqrt{n} \\log \\log n}{\\log n}\\right)$ errors. This avoids the\nprevious attack at the cost of significantly increasing the key size of the\nscheme. We then show that under a very reasonable assumption the decoding\nfailure probability decays almost exponentially with the codelength with just\ntwo iterations of bit-flipping. With an additional assumption it has even been\nproved that it decays exponentially with an unbounded number of iterations and\nwe show that in this case the increase of the key size which is required for\nresisting to the attack of \\cite{GJS16} is only moderate. \n\n"}
{"id": "1801.04693", "contents": "Title: Towards Imperceptible and Robust Adversarial Example Attacks against\n  Neural Networks Abstract: Machine learning systems based on deep neural networks, being able to produce\nstate-of-the-art results on various perception tasks, have gained mainstream\nadoption in many applications. However, they are shown to be vulnerable to\nadversarial example attack, which generates malicious output by adding slight\nperturbations to the input. Previous adversarial example crafting methods,\nhowever, use simple metrics to evaluate the distances between the original\nexamples and the adversarial ones, which could be easily detected by human\neyes. In addition, these attacks are often not robust due to the inevitable\nnoises and deviation in the physical world. In this work, we present a new\nadversarial example attack crafting method, which takes the human perceptual\nsystem into consideration and maximizes the noise tolerance of the crafted\nadversarial example. Experimental results demonstrate the efficacy of the\nproposed technique. \n\n"}
{"id": "1801.06277", "contents": "Title: Deep Chain HDRI: Reconstructing a High Dynamic Range Image from a Single\n  Low Dynamic Range Image Abstract: In this paper, we propose a novel deep neural network model that reconstructs\na high dynamic range (HDR) image from a single low dynamic range (LDR) image.\nThe proposed model is based on a convolutional neural network composed of\ndilated convolutional layers, and infers LDR images with various exposures and\nillumination from a single LDR image of the same scene. Then, the final HDR\nimage can be formed by merging these inference results. It is relatively easy\nfor the proposed method to find the mapping between the LDR and an HDR with a\ndifferent bit depth because of the chaining structure inferring the\nrelationship between the LDR images with brighter (or darker) exposures from a\ngiven LDR image. The method not only extends the range, but also has the\nadvantage of restoring the light information of the actual physical world. For\nthe HDR images obtained by the proposed method, the HDR-VDP2 Q score, which is\nthe most popular evaluation metric for HDR images, was 56.36 for a display with\na 1920$\\times$1200 resolution, which is an improvement of 6 compared with the\nscores of conventional algorithms. In addition, when comparing the peak\nsignal-to-noise ratio values for tone mapped HDR images generated by the\nproposed and conventional algorithms, the average value obtained by the\nproposed algorithm is 30.86 dB, which is 10 dB higher than those obtained by\nthe conventional algorithms. \n\n"}
{"id": "1801.06822", "contents": "Title: ERIM: Secure, Efficient In-process Isolation with Memory Protection Keys\n  (MPK) Abstract: Isolating sensitive state and data can increase the security and robustness\nof many applications. Examples include protecting cryptographic keys against\nexploits like OpenSSL's Heartbleed bug or protecting a language runtime from\nnative libraries written in unsafe languages. When runtime references across\nisolation boundaries occur relatively infrequently, then conventional\npage-based hardware isolation can be used, because the cost of kernel- or\nhypervisor-mediated domain switching is tolerable. However, some applications,\nsuch as the isolation of cryptographic session keys in network-facing services,\nrequire very frequent domain switching. In such applications, the overhead of\nkernel- or hypervisor-mediated domain switching is prohibitive.\n  In this paper, we present ERIM, a novel technique that provides\nhardware-enforced isolation with low overhead on x86 CPUs, even at high\nswitching rates (ERIM's measured overhead is less than 1% for 100,000 switches\nper second). The key idea is to combine protection keys (MPKs), a feature\nrecently added to x86 that allows protection domain switches in userspace, with\nbinary inspection to prevent circumvention. We show that ERIM can be applied\nwith little effort to new and existing applications, doesn't require compiler\nchanges, can run on a stock Linux kernel, and has low runtime overhead even at\nhigh domain switching rates. \n\n"}
{"id": "1801.07301", "contents": "Title: Secure $k$-ish Nearest Neighbors Classifier Abstract: In machine learning, classifiers are used to predict a class of a given query\nbased on an existing (classified) database. Given a database S of n\nd-dimensional points and a d-dimensional query q, the k-nearest neighbors (kNN)\nclassifier assigns q with the majority class of its k nearest neighbors in S.\n  In the secure version of kNN, S and q are owned by two different parties that\ndo not want to share their data. Unfortunately, all known solutions for secure\nkNN either require a large communication complexity between the parties, or are\nvery inefficient to run.\n  In this work we present a classifier based on kNN, that can be implemented\nefficiently with homomorphic encryption (HE). The efficiency of our classifier\ncomes from a relaxation we make on kNN, where we allow it to consider kappa\nnearest neighbors for kappa ~ k with some probability. We therefore call our\nclassifier k-ish Nearest Neighbors (k-ish NN).\n  The success probability of our solution depends on the distribution of the\ndistances from q to S and increase as its statistical distance to Gaussian\ndecrease.\n  To implement our classifier we introduce the concept of double-blinded\ncoin-toss. In a doubly-blinded coin-toss the success probability as well as the\noutput of the toss are encrypted. We use this coin-toss to efficiently\napproximate the average and variance of the distances from q to S. We believe\nthese two techniques may be of independent interest.\n  When implemented with HE, the k-ish NN has a circuit depth that is\nindependent of n, therefore making it scalable. We also implemented our\nclassifier in an open source library based on HELib and tested it on a breast\ntumor database. The accuracy of our classifier (F_1 score) were 98\\% and\nclassification took less than 3 hours compared to (estimated) weeks in current\nHE implementations. \n\n"}
{"id": "1801.07447", "contents": "Title: Block arrivals in the Bitcoin blockchain Abstract: Bitcoin is a electronic payment system where payment transactions are\nverified and stored in a data structure called the blockchain. Bitcoin miners\nwork individually to solve a computationally intensive problem, and with each\nsolution a Bitcoin block is generated, resulting in a new arrival to the\nblockchain. The difficulty of the computational problem is updated every 2,016\nblocks in order to control the rate at which blocks are generated. In the\noriginal Bitcoin paper, it was suggested that the blockchain arrivals occur\naccording to a homogeneous Poisson process. Based on blockchain block arrival\ndata and stochastic analysis of the block arrival process, we demonstrate that\nthis is not the case. We present a refined mathematical model for block\narrivals, focusing on both the block arrivals during a period of constant\ndifficulty and how the difficulty level evolves over time. \n\n"}
{"id": "1801.07451", "contents": "Title: Novel digital tissue phenotypic signatures of distant metastasis in\n  colorectal cancer Abstract: Distant metastasis is the major cause of death in colorectal cancer (CRC).\nPatients at high risk of developing distant metastasis could benefit from\nappropriate adjuvant and follow-up treatments if stratified accurately at an\nearly stage of the disease. Studies have increasingly recognized the role of\ndiverse cellular components within the tumor microenvironment in the\ndevelopment and progression of CRC tumors. In this paper, we show that a new\nmethod of automated analysis of digitized images from colorectal cancer tissue\nslides can provide important estimates of distant metastasis-free survival\n(DMFS, the time before metastasis is first observed) on the basis of details of\nthe microenvironment. Specifically, we determine what cell types are found in\nthe vicinity of other cell types, and in what numbers, rather than\nconcentrating exclusively on the cancerous cells. We then extract novel tissue\nphenotypic signatures using statistical measurements about tissue composition.\nSuch signatures can underpin clinical decisions about the advisability of\nvarious types of adjuvant therapy. \n\n"}
{"id": "1801.08664", "contents": "Title: Linear Complexity and Autocorrelation of two Classes of New Interleaved\n  Sequences of Period $2N$ Abstract: The autocorrelation and the linear complexity of a key stream sequence in a\nstream cipher are important cryptographic properties. Many sequences with these\ngood properties have interleaved structure, three classes of binary sequences\nof period $4N$ with optimal autocorrelation values have been constructed by\nTang and Gong based on interleaving certain kinds of sequences of period $N$.\nIn this paper, we use the interleaving technique to construct a binary sequence\nwith the optimal autocorrelation of period $2N$, then we calculate its\nautocorrelation values and its distribution, and give a lower bound of linear\ncomplexity. Results show that these sequences have low autocorrelation and the\nlinear complexity satisfies the requirements of cryptography. \n\n"}
{"id": "1801.08917", "contents": "Title: Learning to Evade Static PE Machine Learning Malware Models via\n  Reinforcement Learning Abstract: Machine learning is a popular approach to signatureless malware detection\nbecause it can generalize to never-before-seen malware families and polymorphic\nstrains. This has resulted in its practical use for either primary detection\nengines or for supplementary heuristic detection by anti-malware vendors.\nRecent work in adversarial machine learning has shown that deep learning models\nare susceptible to gradient-based attacks, whereas non-differentiable models\nthat report a score can be attacked by genetic algorithms that aim to\nsystematically reduce the score. We propose a more general framework based on\nreinforcement learning (RL) for attacking static portable executable (PE)\nanti-malware engines. The general framework does not require a differentiable\nmodel nor does it require the engine to produce a score. Instead, an RL agent\nis equipped with a set of functionality-preserving operations that it may\nperform on the PE file. Through a series of games played against the\nanti-malware engine, it learns which sequences of operations are likely to\nresult in evading the detector for any given malware sample. This enables\ncompletely black-box attacks against static PE anti-malware, and produces\nfunctional evasive malware samples as a direct result. We show in experiments\nthat our method can attack a gradient-boosted machine learning model with\nevasion rates that are substantial and appear to be strongly dependent on the\ndataset. We demonstrate that attacks against this model appear to also evade\ncomponents of publicly hosted antivirus engines. Adversarial training results\nare also presented: by retraining the model on evasive ransomware samples, a\nsubsequent attack is 33% less effective. However, there are overfitting dangers\nwhen adversarial training, which we note. We release code to allow researchers\nto reproduce and improve this approach. \n\n"}
{"id": "1801.10117", "contents": "Title: PrivPy: Enabling Scalable and General Privacy-Preserving Machine\n  Learning Abstract: We introduce PrivPy, a practical privacy-preserving collaborative computation\nframework, especially optimized for machine learning tasks. PrivPy provides an\neasy-to-use and highly compatible Python programming front-end which supports\nhigh-level array operations and different secure computation engines to allow\nfor security assumptions and performance trade-offs. With PrivPy, programmers\ncan write modern machine learning algorithms conveniently and efficiently in\nPython. We also design and implement a new efficient computation engine, with\nwhich people can use competing cloud providers to efficiently perform general\narithmetics over real numbers. We demonstrate the usability and scalability of\nPrivPy using common machine learning models (e.g. logistic regression and\nconvolutional neural networks) and real-world datasets (including a\n5000-by-1-million matrix). \n\n"}
{"id": "1801.10228", "contents": "Title: Hyperledger Fabric: A Distributed Operating System for Permissioned\n  Blockchains Abstract: Fabric is a modular and extensible open-source system for deploying and\noperating permissioned blockchains and one of the Hyperledger projects hosted\nby the Linux Foundation (www.hyperledger.org).\n  Fabric is the first truly extensible blockchain system for running\ndistributed applications. It supports modular consensus protocols, which allows\nthe system to be tailored to particular use cases and trust models. Fabric is\nalso the first blockchain system that runs distributed applications written in\nstandard, general-purpose programming languages, without systemic dependency on\na native cryptocurrency. This stands in sharp contrast to existing blockchain\nplatforms that require \"smart-contracts\" to be written in domain-specific\nlanguages or rely on a cryptocurrency. Fabric realizes the permissioned model\nusing a portable notion of membership, which may be integrated with\nindustry-standard identity management. To support such flexibility, Fabric\nintroduces an entirely novel blockchain design and revamps the way blockchains\ncope with non-determinism, resource exhaustion, and performance attacks.\n  This paper describes Fabric, its architecture, the rationale behind various\ndesign decisions, its most prominent implementation aspects, as well as its\ndistributed application programming model. We further evaluate Fabric by\nimplementing and benchmarking a Bitcoin-inspired digital currency. We show that\nFabric achieves end-to-end throughput of more than 3500 transactions per second\nin certain popular deployment configurations, with sub-second latency, scaling\nwell to over 100 peers. \n\n"}
{"id": "1802.00561", "contents": "Title: Block4Forensic: An Integrated Lightweight Blockchain Framework for\n  Forensics Applications of Connected Vehicles Abstract: Today's vehicles are becoming cyber-physical systems that do not only\ncommunicate with other vehicles but also gather various information from\nhundreds of sensors within them. These developments help create smart and\nconnected (e.g., self-driving) vehicles that will introduce significant\ninformation to drivers, manufacturers, insurance companies and maintenance\nservice providers for various applications. One such application that is\nbecoming crucial with the introduction of self-driving cars is the forensic\nanalysis for traffic accidents. The utilization of vehicle-related data can be\ninstrumental in post-accident scenarios to find out the faulty party,\nparticularly for self-driving vehicles. With the opportunity of being able to\naccess various information on the cars, we propose a permissioned blockchain\nframework among the various elements involved to manage the collected\nvehicle-related data. Specifically, we first integrate Vehicular Public Key\nManagement (VPKI) to the proposed blockchain to provide membership\nestablishment and privacy. Next, we design a fragmented ledger that will store\ndetailed data related to vehicle such as maintenance information/history, car\ndiagnosis reports, etc. The proposed forensic framework enables trustless,\ntraceable and privacy-aware post-accident analysis with minimal storage and\nprocessing overhead. \n\n"}
{"id": "1802.00664", "contents": "Title: Convolutional neural network-based regression for depth prediction in\n  digital holography Abstract: Digital holography enables us to reconstruct objects in three-dimensional\nspace from holograms captured by an imaging device. For the reconstruction, we\nneed to know the depth position of the recoded object in advance. In this\nstudy, we propose depth prediction using convolutional neural network\n(CNN)-based regression. In the previous researches, the depth of an object was\nestimated through reconstructed images at different depth positions from a\nhologram using a certain metric that indicates the most focused depth position;\nhowever, such a depth search is time-consuming. The CNN of the proposed method\ncan directly predict the depth position with millimeter precision from\nholograms. \n\n"}
{"id": "1802.02040", "contents": "Title: Multispectral Compressive Imaging Strategies using Fabry-P\\'erot\n  Filtered Sensors Abstract: This paper introduces two acquisition device architectures for multispectral\ncompressive imaging. Unlike most existing methods, the proposed computational\nimaging techniques do not include any dispersive element, as they use a\ndedicated sensor which integrates narrowband Fabry-P\\'erot spectral filters at\nthe pixel level. The first scheme leverages joint inpainting and\nsuper-resolution to fill in those voxels that are missing due to the device's\nlimited pixel count. The second scheme, in link with compressed sensing,\nintroduces spatial random convolutions, but is more complex and may be affected\nby diffraction. In both cases we solve the associated inverse problems by using\nthe same signal prior. Specifically, we propose a redundant analysis signal\nprior in a convex formulation. Through numerical simulations, we explore\ndifferent realistic setups. Our objective is also to highlight some practical\nguidelines and discuss their complexity trade-offs to integrate these schemes\ninto actual computational imaging systems. Our conclusion is that the second\ntechnique performs best at high compression levels, in a properly sized and\ncalibrated setup. Otherwise, the first, simpler technique should be favored. \n\n"}
{"id": "1802.02638", "contents": "Title: Tight Lower Bounds for Locally Differentially Private Selection Abstract: We prove a tight lower bound (up to constant factors) on the sample\ncomplexity of any non-interactive local differentially private protocol for\noptimizing a linear function over the simplex. This lower bound also implies a\ntight lower bound (again, up to constant factors) on the sample complexity of\nany non-interactive local differentially private protocol implementing the\nexponential mechanism. These results reveal that any local protocol for these\nproblems has exponentially worse dependence on the dimension than corresponding\nalgorithms in the central model. Previously, Kasiviswanathan et al. (FOCS 2008)\nproved an exponential separation between local and central model algorithms for\nPAC learning the class of parity functions. In contrast, our lower bound are\nquantitatively tight, apply to a simple and natural class of linear\noptimization problems, and our techniques are arguably simpler. \n\n"}
{"id": "1802.03248", "contents": "Title: Piecewise Flat Embedding for Image Segmentation Abstract: We introduce a new multi-dimensional nonlinear embedding -- Piecewise Flat\nEmbedding (PFE) -- for image segmentation. Based on the theory of sparse signal\nrecovery, piecewise flat embedding with diverse channels attempts to recover a\npiecewise constant image representation with sparse region boundaries and\nsparse cluster value scattering. The resultant piecewise flat embedding\nexhibits interesting properties such as suppressing slowly varying signals, and\noffers an image representation with higher region identifiability which is\ndesirable for image segmentation or high-level semantic analysis tasks. We\nformulate our embedding as a variant of the Laplacian Eigenmap embedding with\nan $L_{1,p} (0<p\\leq1)$ regularization term to promote sparse solutions. First,\nwe devise a two-stage numerical algorithm based on Bregman iterations to\ncompute $L_{1,1}$-regularized piecewise flat embeddings. We further generalize\nthis algorithm through iterative reweighting to solve the general\n$L_{1,p}$-regularized problem. To demonstrate its efficacy, we integrate PFE\ninto two existing image segmentation frameworks, segmentation based on\nclustering and hierarchical segmentation based on contour detection.\nExperiments on four major benchmark datasets, BSDS500, MSRC, Stanford\nBackground Dataset, and PASCAL Context, show that segmentation algorithms\nincorporating our embedding achieve significantly improved results. \n\n"}
{"id": "1802.04085", "contents": "Title: Empirical Risk Minimization in Non-interactive Local Differential\n  Privacy: Efficiency and High Dimensional Case Abstract: In this paper, we study the Empirical Risk Minimization problem in the\nnon-interactive local model of differential privacy. In the case of constant or\nlow dimensionality ($p\\ll n$), we first show that if the ERM loss function is\n$(\\infty, T)$-smooth, then we can avoid a dependence of the sample complexity,\nto achieve error $\\alpha$, on the exponential of the dimensionality $p$ with\nbase $1/\\alpha$ (i.e., $\\alpha^{-p}$), which answers a question in [smith 2017\ninteraction]. Our approach is based on polynomial approximation. Then, we\npropose player-efficient algorithms with $1$-bit communication complexity and\n$O(1)$ computation cost for each player. The error bound is asymptotically the\nsame as the original one. Also with additional assumptions we show a server\nefficient algorithm. Next we consider the high dimensional case ($n\\ll p$), we\nshow that if the loss function is Generalized Linear function and convex, then\nwe could get an error bound which is dependent on the Gaussian width of the\nunderlying constrained set instead of $p$, which is lower than that in [smith\n2017 interaction]. \n\n"}
{"id": "1802.04122", "contents": "Title: Tagvisor: A Privacy Advisor for Sharing Hashtags Abstract: Hashtag has emerged as a widely used concept of popular culture and\ncampaigns, but its implications on people's privacy have not been investigated\nso far. In this paper, we present the first systematic analysis of privacy\nissues induced by hashtags. We concentrate in particular on location, which is\nrecognized as one of the key privacy concerns in the Internet era. By relying\non a random forest model, we show that we can infer a user's precise location\nfrom hashtags with accuracy of 70\\% to 76\\%, depending on the city. To remedy\nthis situation, we introduce a system called Tagvisor that systematically\nsuggests alternative hashtags if the user-selected ones constitute a threat to\nlocation privacy. Tagvisor realizes this by means of three conceptually\ndifferent obfuscation techniques and a semantics-based metric for measuring the\nconsequent utility loss. Our findings show that obfuscating as little as two\nhashtags already provides a near-optimal trade-off between privacy and utility\nin our dataset. This in particular renders Tagvisor highly time-efficient, and\nthus, practical in real-world settings. \n\n"}
{"id": "1802.04259", "contents": "Title: Sphinx: A Secure Architecture Based on Binary Code Diversification and\n  Execution Obfuscation Abstract: Sphinx, a hardware-software co-design architecture for binary code and\nruntime obfuscation. The Sphinx architecture uses binary code diversification\nand self-reconfigurable processing elements to maintain application\nfunctionality while obfuscating the binary code and architecture states to\nattackers. This approach dramatically reduces an attacker's ability to exploit\ninformation gained from one deployment to attack another deployment. Our\nresults show that the Sphinx is able to decouple the program's execution time,\npower and memory and I/O activities from its functionality. It is also\npractical in the sense that the system (both software and hardware) overheads\nare minimal. \n\n"}
{"id": "1802.04365", "contents": "Title: Learning a Neural-network-based Representation for Open Set Recognition Abstract: Open set recognition problems exist in many domains. For example in security,\nnew malware classes emerge regularly; therefore malware classification systems\nneed to identify instances from unknown classes in addition to discriminating\nbetween known classes. In this paper we present a neural network based\nrepresentation for addressing the open set recognition problem. In this\nrepresentation instances from the same class are close to each other while\ninstances from different classes are further apart, resulting in statistically\nsignificant improvement when compared to other approaches on three datasets\nfrom two different domains. \n\n"}
{"id": "1802.06739", "contents": "Title: Differentially Private Generative Adversarial Network Abstract: Generative Adversarial Network (GAN) and its variants have recently attracted\nintensive research interests due to their elegant theoretical foundation and\nexcellent empirical performance as generative models. These tools provide a\npromising direction in the studies where data availability is limited. One\ncommon issue in GANs is that the density of the learned generative distribution\ncould concentrate on the training data points, meaning that they can easily\nremember training samples due to the high model complexity of deep networks.\nThis becomes a major concern when GANs are applied to private or sensitive data\nsuch as patient medical records, and the concentration of distribution may\ndivulge critical patient information. To address this issue, in this paper we\npropose a differentially private GAN (DPGAN) model, in which we achieve\ndifferential privacy in GANs by adding carefully designed noise to gradients\nduring the learning procedure. We provide rigorous proof for the privacy\nguarantee, as well as comprehensive empirical evidence to support our analysis,\nwhere we demonstrate that our method can generate high quality data points at a\nreasonable privacy level. \n\n"}
{"id": "1802.06816", "contents": "Title: Shield: Fast, Practical Defense and Vaccination for Deep Learning using\n  JPEG Compression Abstract: The rapidly growing body of research in adversarial machine learning has\ndemonstrated that deep neural networks (DNNs) are highly vulnerable to\nadversarially generated images. This underscores the urgent need for practical\ndefense that can be readily deployed to combat attacks in real-time. Observing\nthat many attack strategies aim to perturb image pixels in ways that are\nvisually imperceptible, we place JPEG compression at the core of our proposed\nShield defense framework, utilizing its capability to effectively \"compress\naway\" such pixel manipulation. To immunize a DNN model from artifacts\nintroduced by compression, Shield \"vaccinates\" a model by re-training it with\ncompressed images, where different compression levels are applied to generate\nmultiple vaccinated models that are ultimately used together in an ensemble\ndefense. On top of that, Shield adds an additional layer of protection by\nemploying randomization at test time that compresses different regions of an\nimage using random compression levels, making it harder for an adversary to\nestimate the transformation performed. This novel combination of vaccination,\nensembling, and randomization makes Shield a fortified multi-pronged\nprotection. We conducted extensive, large-scale experiments using the ImageNet\ndataset, and show that our approaches eliminate up to 94% of black-box attacks\nand 98% of gray-box attacks delivered by the recent, strongest attacks, such as\nCarlini-Wagner's L2 and DeepFool. Our approaches are fast and work without\nrequiring knowledge about the model. \n\n"}
{"id": "1802.06993", "contents": "Title: A Survey on the Security of Blockchain Systems Abstract: Since its inception, the blockchain technology has shown promising\napplication prospects. From the initial cryptocurrency to the current smart\ncontract, blockchain has been applied to many fields. Although there are some\nstudies on the security and privacy issues of blockchain, there lacks a\nsystematic examination on the security of blockchain systems. In this paper, we\nconduct a systematic study on the security threats to blockchain and survey the\ncorresponding real attacks by examining popular blockchain systems. We also\nreview the security enhancement solutions for blockchain, which could be used\nin the development of various blockchain systems, and suggest some future\ndirections to stir research efforts into this area. \n\n"}
{"id": "1802.07060", "contents": "Title: CATTmew: Defeating Software-only Physical Kernel Isolation Abstract: All the state-of-the-art rowhammer attacks can break the MMU-enforced\ninter-domain isolation because the physical memory owned by each domain is\nadjacent to each other. To mitigate these attacks, physical domain isolation,\nintroduced by CATT, physically separates each domain by dividing the physical\nmemory into multiple partitions and keeping each partition occupied by only one\ndomain. CATT implemented physical kernel isolation as the first generic and\npractical software-only defense to protect kernel from being rowhammered as\nkernel is one of the most appealing targets.\n  In this paper, we develop a novel exploit that could effectively defeat the\nphysical kernel isolation and gain both root and kernel privileges. Our exploit\ncan work without exhausting the page cache or the system memory, or relying on\nthe information of the virtual-to-physical address mapping. The exploit is\nmotivated by our key observation that the modern OSes have double-owned kernel\nbuffers (e.g., video buffers and SCSI Generic buffers) owned concurrently by\nthe kernel and user domains. The existence of such buffers invalidates the\nphysical kernel isolation and makes the rowhammer-based attack possible again.\nExisting conspicuous rowhammer attacks achieving the root/kernel privilege\nescalation exhaust the page cache or even the whole system memory. Instead, we\npropose a new technique, named memory ambush. It is able to place the\nhammerable double-owned kernel buffers physically adjacent to the target\nobjects (e.g., page tables) with only a small amount of memory. As a result,\nour exploit is stealthier and has fewer memory footprints. We also replace the\ninefficient rowhammer algorithm that blindly picks up addresses to hammer with\nan efficient one. Our algorithm selects suitable addresses based on an existing\ntiming channel. \n\n"}
{"id": "1802.07101", "contents": "Title: Stroke Controllable Fast Style Transfer with Adaptive Receptive Fields Abstract: The Fast Style Transfer methods have been recently proposed to transfer a\nphotograph to an artistic style in real-time. This task involves controlling\nthe stroke size in the stylized results, which remains an open challenge. In\nthis paper, we present a stroke controllable style transfer network that can\nachieve continuous and spatial stroke size control. By analyzing the factors\nthat influence the stroke size, we propose to explicitly account for the\nreceptive field and the style image scales. We propose a StrokePyramid module\nto endow the network with adaptive receptive fields, and two training\nstrategies to achieve faster convergence and augment new stroke sizes upon a\ntrained model respectively. By combining the proposed runtime control\nstrategies, our network can achieve continuous changes in stroke sizes and\nproduce distinct stroke sizes in different spatial regions within the same\noutput image. \n\n"}
{"id": "1802.07523", "contents": "Title: Toward Open Data Blockchain Analytics: A Bitcoin Perspective Abstract: Bitcoin is the first implementation of what has become known as a 'public\npermissionless' blockchain. Guaranteeing security and protocol conformity\nthrough its elegant combination of cryptographic assurances and game theoretic\neconomic incentives, it permits censorship resistant public read-write access\nto its append-only blockchain database without the need for any mediating\ncentral authority. Not until its advent has such a trusted, transparent,\ncomprehensive and granular data set of digital economic behaviours been\navailable for public network analysis. In this article, by translating the\ncumbersome binary data structure of the Bitcoin blockchain into a high fidelity\ngraph model, we demonstrate through various analyses the often overlooked\nsocial and econometric benefits of employing such a novel open data\narchitecture. Specifically we show (a) how repeated patterns of transaction\nbehaviours can be revealed to link user activity across the blockchain; (b) how\nnewly mined bitcoin can be associated to demonstrate individual accumulations\nof wealth; (c) through application of the naive quantity theory of money that\nBitcoin's disinflationary properties can be revealed and measured; and (d) how\nthe user community can develop coordinated defences against repeated denial of\nservice attacks on the network. All of the aforementioned being exemplary\nbenefits that would be lost with the closed data models of the 'private\npermissioned' distributed ledger architectures that are dominating enterprise\nlevel development due to existing blockchain issues of governance, scalability\nand confidentiality. \n\n"}
{"id": "1802.07975", "contents": "Title: Options for encoding names for data linking at the Australian Bureau of\n  Statistics Abstract: Publicly, ABS has said it would use a cryptographic hash function to convert\nnames collected in the 2016 Census of Population and Housing into an\nunrecognisable value in a way that is not reversible. In 2016, the ABS engaged\nthe University of Melbourne to provide expert advice on cryptographic hash\nfunctions to meet this objective.\n  For complex unit-record level data, including Census data, auxiliary data can\nbe often be used to link individual records, even without names. This is the\nbasis of ABS's existing bronze linking. This means that records can probably be\nre-identified without the encoded name anyway. Protection against\nre-identification depends on good processes within ABS.\n  The undertaking on the encoding of names should therefore be considered in\nthe full context of auxiliary data and ABS processes. There are several\nreasonable interpretations:\n  1. That the encoding cannot be reversed except with a secret key held by ABS.\nThis is the property achieved by encryption (Option 1), if properly\nimplemented;\n  2. That the encoding, taken alone without auxiliary data, cannot be reversed\nto a single value. This is the property achieved by lossy encoding (Option 2),\nif properly implemented;\n  3. That the encoding doesn't make re-identification easier, or increase the\nnumber of records that can be re-identified, except with a secret key held by\nABS. This is the property achieved by HMAC-based linkage key derivation using\nsubsets of attributes (Option 3), if properly implemented.\n  We explain and compare the privacy and accuracy guarantees of five possible\napproaches. Options 4 and 5 investigate more sophisticated options for future\ndata linking. We also explain how some commonly-advocated techniques can be\nreversed, and hence should not be used. \n\n"}
{"id": "1802.08232", "contents": "Title: The Secret Sharer: Evaluating and Testing Unintended Memorization in\n  Neural Networks Abstract: This paper describes a testing methodology for quantitatively assessing the\nrisk that rare or unique training-data sequences are unintentionally memorized\nby generative sequence models---a common type of machine-learning model.\nBecause such models are sometimes trained on sensitive data (e.g., the text of\nusers' private messages), this methodology can benefit privacy by allowing\ndeep-learning practitioners to select means of training that minimize such\nmemorization.\n  In experiments, we show that unintended memorization is a persistent,\nhard-to-avoid issue that can have serious consequences. Specifically, for\nmodels trained without consideration of memorization, we describe new,\nefficient procedures that can extract unique, secret sequences, such as credit\ncard numbers. We show that our testing strategy is a practical and easy-to-use\nfirst line of defense, e.g., by describing its application to quantitatively\nlimit data exposure in Google's Smart Compose, a commercial text-completion\nneural network trained on millions of users' email messages. \n\n"}
{"id": "1802.08288", "contents": "Title: Confidential Boosting with Random Linear Classifiers for Outsourced\n  User-generated Data Abstract: User-generated data is crucial to predictive modeling in many applications.\nWith a web/mobile/wearable interface, a data owner can continuously record data\ngenerated by distributed users and build various predictive models from the\ndata to improve their operations, services, and revenue. Due to the large size\nand evolving nature of users data, data owners may rely on public cloud service\nproviders (Cloud) for storage and computation scalability. Exposing sensitive\nuser-generated data and advanced analytic models to Cloud raises privacy\nconcerns. We present a confidential learning framework, SecureBoost, for data\nowners that want to learn predictive models from aggregated user-generated data\nbut offload the storage and computational burden to Cloud without having to\nworry about protecting the sensitive data. SecureBoost allows users to submit\nencrypted or randomly masked data to designated Cloud directly. Our framework\nutilizes random linear classifiers (RLCs) as the base classifiers in the\nboosting framework to dramatically simplify the design of the proposed\nconfidential boosting protocols, yet still preserve the model quality. A\nCryptographic Service Provider (CSP) is used to assist the Cloud's processing,\nreducing the complexity of the protocol constructions. We present two\nconstructions of SecureBoost: HE+GC and SecSh+GC, using combinations of\nhomomorphic encryption, garbled circuits, and random masking to achieve both\nsecurity and efficiency. For a boosted model, Cloud learns only the RLCs and\nthe CSP learns only the weights of the RLCs. Finally, the data owner collects\nthe two parts to get the complete model. We conduct extensive experiments to\nunderstand the quality of the RLC-based boosting and the cost distribution of\nthe constructions. Our results show that SecureBoost can efficiently learn\nhigh-quality boosting models from protected user-generated data. \n\n"}
{"id": "1802.08686", "contents": "Title: Adversarial vulnerability for any classifier Abstract: Despite achieving impressive performance, state-of-the-art classifiers remain\nhighly vulnerable to small, imperceptible, adversarial perturbations. This\nvulnerability has proven empirically to be very intricate to address. In this\npaper, we study the phenomenon of adversarial perturbations under the\nassumption that the data is generated with a smooth generative model. We derive\nfundamental upper bounds on the robustness to perturbations of any\nclassification function, and prove the existence of adversarial perturbations\nthat transfer well across different classifiers with small risk. Our analysis\nof the robustness also provides insights onto key properties of generative\nmodels, such as their smoothness and dimensionality of latent space. We\nconclude with numerical experimental results showing that our bounds provide\ninformative baselines to the maximal achievable robustness on several datasets. \n\n"}
{"id": "1802.08701", "contents": "Title: Machine learning based hyperspectral image analysis: A survey Abstract: Hyperspectral sensors enable the study of the chemical properties of scene\nmaterials remotely for the purpose of identification, detection, and chemical\ncomposition analysis of objects in the environment. Hence, hyperspectral images\ncaptured from earth observing satellites and aircraft have been increasingly\nimportant in agriculture, environmental monitoring, urban planning, mining, and\ndefense. Machine learning algorithms due to their outstanding predictive power\nhave become a key tool for modern hyperspectral image analysis. Therefore, a\nsolid understanding of machine learning techniques have become essential for\nremote sensing researchers and practitioners. This paper reviews and compares\nrecent machine learning-based hyperspectral image analysis methods published in\nliterature. We organize the methods by the image analysis task and by the type\nof machine learning algorithm, and present a two-way mapping between the image\nanalysis tasks and the types of machine learning algorithms that can be applied\nto them. The paper is comprehensive in coverage of both hyperspectral image\nanalysis tasks and machine learning algorithms. The image analysis tasks\nconsidered are land cover classification, target detection, unmixing, and\nphysical parameter estimation. The machine learning algorithms covered are\nGaussian models, linear regression, logistic regression, support vector\nmachines, Gaussian mixture model, latent linear models, sparse linear models,\nGaussian mixture models, ensemble learning, directed graphical models,\nundirected graphical models, clustering, Gaussian processes, Dirichlet\nprocesses, and deep learning. We also discuss the open challenges in the field\nof hyperspectral image analysis and explore possible future directions. \n\n"}
{"id": "1802.08908", "contents": "Title: Scalable Private Learning with PATE Abstract: The rapid adoption of machine learning has increased concerns about the\nprivacy implications of machine learning models trained on sensitive data, such\nas medical records or other personal information. To address those concerns,\none promising approach is Private Aggregation of Teacher Ensembles, or PATE,\nwhich transfers to a \"student\" model the knowledge of an ensemble of \"teacher\"\nmodels, with intuitive privacy provided by training teachers on disjoint data\nand strong privacy guaranteed by noisy aggregation of teachers' answers.\nHowever, PATE has so far been evaluated only on simple classification tasks\nlike MNIST, leaving unclear its utility when applied to larger-scale learning\ntasks and real-world datasets.\n  In this work, we show how PATE can scale to learning tasks with large numbers\nof output classes and uncurated, imbalanced training data with errors. For\nthis, we introduce new noisy aggregation mechanisms for teacher ensembles that\nare more selective and add less noise, and prove their tighter\ndifferential-privacy guarantees. Our new mechanisms build on two insights: the\nchance of teacher consensus is increased by using more concentrated noise and,\nlacking consensus, no answer need be given to a student. The consensus answers\nused are more likely to be correct, offer better intuitive privacy, and incur\nlower-differential privacy cost. Our evaluation shows our mechanisms improve on\nthe original PATE on all measures, and scale to larger tasks with both high\nutility and very strong privacy ($\\varepsilon$ < 1.0). \n\n"}
{"id": "1802.09026", "contents": "Title: Building Instance Classification Using Street View Images Abstract: Land-use classification based on spaceborne or aerial remote sensing images\nhas been extensively studied over the past decades. Such classification is\nusually a patch-wise or pixel-wise labeling over the whole image. But for many\napplications, such as urban population density mapping or urban utility\nplanning, a classification map based on individual buildings is much more\ninformative. However, such semantic classification still poses some fundamental\nchallenges, for example, how to retrieve fine boundaries of individual\nbuildings. In this paper, we proposed a general framework for classifying the\nfunctionality of individual buildings. The proposed method is based on\nConvolutional Neural Networks (CNNs) which classify facade structures from\nstreet view images, such as Google StreetView, in addition to remote sensing\nimages which usually only show roof structures. Geographic information was\nutilized to mask out individual buildings, and to associate the corresponding\nstreet view images. We created a benchmark dataset which was used for training\nand evaluating CNNs. In addition, the method was applied to generate building\nclassification maps on both region and city scales of several cities in Canada\nand the US. Keywords: CNN, Building instance classification, Street view\nimages, OpenStreetMap \n\n"}
{"id": "1802.09089", "contents": "Title: Kitsune: An Ensemble of Autoencoders for Online Network Intrusion\n  Detection Abstract: Neural networks have become an increasingly popular solution for network\nintrusion detection systems (NIDS). Their capability of learning complex\npatterns and behaviors make them a suitable solution for differentiating\nbetween normal traffic and network attacks. However, a drawback of neural\nnetworks is the amount of resources needed to train them. Many network gateways\nand routers devices, which could potentially host an NIDS, simply do not have\nthe memory or processing power to train and sometimes even execute such models.\nMore importantly, the existing neural network solutions are trained in a\nsupervised manner. Meaning that an expert must label the network traffic and\nupdate the model manually from time to time.\n  In this paper, we present Kitsune: a plug and play NIDS which can learn to\ndetect attacks on the local network, without supervision, and in an efficient\nonline manner. Kitsune's core algorithm (KitNET) uses an ensemble of neural\nnetworks called autoencoders to collectively differentiate between normal and\nabnormal traffic patterns. KitNET is supported by a feature extraction\nframework which efficiently tracks the patterns of every network channel. Our\nevaluations show that Kitsune can detect various attacks with a performance\ncomparable to offline anomaly detectors, even on a Raspberry PI. This\ndemonstrates that Kitsune can be a practical and economic NIDS. \n\n"}
{"id": "1802.09575", "contents": "Title: i3PosNet: Instrument Pose Estimation from X-Ray in temporal bone surgery Abstract: Purpose: Accurate estimation of the position and orientation (pose) of\nsurgical instruments is crucial for delicate minimally invasive temporal bone\nsurgery. Current techniques lack in accuracy and/or line-of-sight constraints\n(conventional tracking systems) or expose the patient to prohibitive ionizing\nradiation (intra-operative CT). A possible solution is to capture the\ninstrument with a c-arm at irregular intervals and recover the pose from the\nimage.\n  Methods: i3PosNet infers the position and orientation of instruments from\nimages using a pose estimation network. Said framework considers localized\npatches and outputs pseudo-landmarks. The pose is reconstructed from\npseudo-landmarks by geometric considerations.\n  Results: We show i3PosNet reaches errors less than 0.05mm. It outperforms\nconventional image registration-based approaches reducing average and maximum\nerrors by at least two thirds. i3PosNet trained on synthetic images generalizes\nto real x-rays without any further adaptation.\n  Conclusion: The translation of Deep Learning based methods to surgical\napplications is difficult, because large representative datasets for training\nand testing are not available. This work empirically shows sub-millimeter pose\nestimation trained solely based on synthetic training data. \n\n"}
{"id": "1802.10077", "contents": "Title: A Differential Privacy Mechanism Design Under Matrix-Valued Query Abstract: Traditionally, differential privacy mechanism design has been tailored for a\nscalar-valued query function. Although many mechanisms such as the Laplace and\nGaussian mechanisms can be extended to a matrix-valued query function by adding\ni.i.d. noise to each element of the matrix, this method is often sub-optimal as\nit forfeits an opportunity to exploit the structural characteristics typically\nassociated with matrix analysis. In this work, we consider the design of\ndifferential privacy mechanism specifically for a matrix-valued query function.\nThe proposed solution is to utilize a matrix-variate noise, as opposed to the\ntraditional scalar-valued noise. Particularly, we propose a novel differential\nprivacy mechanism called the Matrix-Variate Gaussian (MVG) mechanism, which\nadds a matrix-valued noise drawn from a matrix-variate Gaussian distribution.\nWe prove that the MVG mechanism preserves $(\\epsilon,\\delta)$-differential\nprivacy, and show that it allows the structural characteristics of the\nmatrix-valued query function to naturally be exploited. Furthermore, due to the\nmulti-dimensional nature of the MVG mechanism and the matrix-valued query, we\nintroduce the concept of directional noise, which can be utilized to mitigate\nthe impact the noise has on the utility of the query. Finally, we demonstrate\nthe performance of the MVG mechanism and the advantages of directional noise\nusing three matrix-valued queries on three privacy-sensitive datasets. We find\nthat the MVG mechanism notably outperforms four previous state-of-the-art\napproaches, and provides comparable utility to the non-private baseline. Our\nwork thus presents a promising prospect for both future research and\nimplementation of differential privacy for matrix-valued query functions. \n\n"}
{"id": "1802.10135", "contents": "Title: Microsoft Malware Classification Challenge Abstract: The Microsoft Malware Classification Challenge was announced in 2015 along\nwith a publication of a huge dataset of nearly 0.5 terabytes, consisting of\ndisassembly and bytecode of more than 20K malware samples. Apart from serving\nin the Kaggle competition, the dataset has become a standard benchmark for\nresearch on modeling malware behaviour. To date, the dataset has been cited in\nmore than 50 research papers. Here we provide a high-level comparison of the\npublications citing the dataset. The comparison simplifies finding potential\nresearch directions in this field and future performance evaluation of the\ndataset. \n\n"}
{"id": "1803.00260", "contents": "Title: Five-point Fundamental Matrix Estimation for Uncalibrated Cameras Abstract: We aim at estimating the fundamental matrix in two views from five\ncorrespondences of rotation invariant features obtained by e.g.\\ the SIFT\ndetector. The proposed minimal solver first estimates a homography from three\ncorrespondences assuming that they are co-planar and exploiting their\nrotational components. Then the fundamental matrix is obtained from the\nhomography and two additional point pairs in general position. The proposed\napproach, combined with robust estimators like Graph-Cut RANSAC, is superior to\nother state-of-the-art algorithms both in terms of accuracy and number of\niterations required. This is validated on synthesized data and $561$ real image\npairs. Moreover, the tests show that requiring three points on a plane is not\ntoo restrictive in urban environment and locally optimized robust estimators\nlead to accurate estimates even if the points are not entirely co-planar. As a\npotential application, we show that using the proposed method makes two-view\nmulti-motion estimation more accurate. \n\n"}
{"id": "1803.00387", "contents": "Title: A General Pipeline for 3D Detection of Vehicles Abstract: Autonomous driving requires 3D perception of vehicles and other objects in\nthe in environment. Much of the current methods support 2D vehicle detection.\nThis paper proposes a flexible pipeline to adopt any 2D detection network and\nfuse it with a 3D point cloud to generate 3D information with minimum changes\nof the 2D detection networks. To identify the 3D box, an effective model\nfitting algorithm is developed based on generalised car models and score maps.\nA two-stage convolutional neural network (CNN) is proposed to refine the\ndetected 3D box. This pipeline is tested on the KITTI dataset using two\ndifferent 2D detection networks. The 3D detection results based on these two\nnetworks are similar, demonstrating the flexibility of the proposed pipeline.\nThe results rank second among the 3D detection algorithms, indicating its\ncompetencies in 3D detection. \n\n"}
{"id": "1803.00860", "contents": "Title: Can we steal your vocal identity from the Internet?: Initial\n  investigation of cloning Obama's voice using GAN, WaveNet and low-quality\n  found data Abstract: Thanks to the growing availability of spoofing databases and rapid advances\nin using them, systems for detecting voice spoofing attacks are becoming more\nand more capable, and error rates close to zero are being reached for the\nASVspoof2015 database. However, speech synthesis and voice conversion paradigms\nthat are not considered in the ASVspoof2015 database are appearing. Such\nexamples include direct waveform modelling and generative adversarial networks.\nWe also need to investigate the feasibility of training spoofing systems using\nonly low-quality found data. For that purpose, we developed a generative\nadversarial network-based speech enhancement system that improves the quality\nof speech data found in publicly available sources. Using the enhanced data, we\ntrained state-of-the-art text-to-speech and voice conversion models and\nevaluated them in terms of perceptual speech quality and speaker similarity.\nThe results show that the enhancement models significantly improved the SNR of\nlow-quality degraded data found in publicly available sources and that they\nsignificantly improved the perceptual cleanliness of the source speech without\nsignificantly degrading the naturalness of the voice. However, the results also\nshow limitations when generating speech with the low-quality found data. \n\n"}
{"id": "1803.00892", "contents": "Title: A Framework for Blockchain-Based Applications Abstract: Blockchains have recently generated explosive interest from both academia and\nindustry, with many proposed applications. But descriptions of many these\nproposals are more visionary projections than realizable proposals, and even\nbasic definitions are often missing. We define \"blockchain\" and \"blockchain\nnetwork\", and then discuss two very different, well known classes of blockchain\nnetworks: cryptocurrencies and Git repositories. We identify common primitive\nelements of both and use them to construct a framework for explicitly\narticulating what characterizes blockchain networks. The framework consists of\na set of questions that every blockchain initiative should address at the very\noutset. It is intended to help one decide whether or not blockchain is an\nappropriate approach to a particular application, and if it is, to assist in\nits initial design stage. \n\n"}
{"id": "1803.00965", "contents": "Title: Type-Preserving Matrices and Security of Block Ciphers Abstract: We provide a new property, called Non-Type-Preserving, for a mixing layer\nwhich guarantees protection against algebraic attacks based on the\nimprimitivity of the group generated by the round functions. Our main result is\nto present necessary and sufficient conditions on the structure of the binary\nmatrix associated to the mixing layer, so that it has this property. Then we\nshow how several families of linear maps are Non-Type-Preserving, including the\nmixing layers of AES, GOST and PRESENT. Finally we prove that the group\ngenerated by the round functions of an SPN cipher with addition modulo a power\nof 2 as key mixing function is primitive if its mixing layer satisfies this\nproperty. Moreover we generalise the definition of a GOST-like cipher using a\nNon-Type-Preserving matrix as mixing layer and we show, under the only\nassumption of invertibility of the S-Boxes, that the corresponding group is\nprimitive. \n\n"}
{"id": "1803.01798", "contents": "Title: One-Class Adversarial Nets for Fraud Detection Abstract: Many online applications, such as online social networks or knowledge bases,\nare often attacked by malicious users who commit different types of actions\nsuch as vandalism on Wikipedia or fraudulent reviews on eBay. Currently, most\nof the fraud detection approaches require a training dataset that contains\nrecords of both benign and malicious users. However, in practice, there are\noften no or very few records of malicious users. In this paper, we develop\none-class adversarial nets (OCAN) for fraud detection using training data with\nonly benign users. OCAN first uses LSTM-Autoencoder to learn the\nrepresentations of benign users from their sequences of online activities. It\nthen detects malicious users by training a discriminator with a complementary\nGAN model that is different from the regular GAN model. Experimental results\nshow that our OCAN outperforms the state-of-the-art one-class classification\nmodels and achieves comparable performance with the latest multi-source LSTM\nmodel that requires both benign and malicious users in the training phase. \n\n"}
{"id": "1803.02560", "contents": "Title: Vesper: Using Echo-Analysis to Detect Man-in-the-Middle Attacks in LANs Abstract: The Man-in-the-Middle (MitM) attack is a cyber-attack in which an attacker\nintercepts traffic, thus harming the confidentiality, integrity, and\navailability of the network. It remains a popular attack vector due to its\nsimplicity. However, existing solutions are either not portable, suffer from a\nhigh false positive rate, or are simply not generic. In this paper, we propose\nVesper: a novel plug-and-play MitM detector for local area networks. Vesper\nuses a technique inspired from impulse response analysis used in the domain of\nacoustic signal processing. Analogous to how echoes in a cave capture the shape\nand construction of the environment, so to can a short and intense pulse of\nICMP echo requests model the link between two network hosts. Vesper uses neural\nnetworks called autoencoders to model the normal patterns of the echoed pulses,\nand detect when the environment changes. Using this technique, Vesper is able\nto detect MitM attacks with high accuracy while incurring minimal network\noverhead. We evaluate Vesper on LANs consisting of video surveillance cameras,\nservers, and PC workstations. We also investigate several possible adversarial\nattacks against Vesper, and demonstrate how Vesper mitigates these attacks. \n\n"}
{"id": "1803.02623", "contents": "Title: TRLG: Fragile blind quad watermarking for image tamper detection and\n  recovery by providing compact digests with quality optimized using LWT and GA Abstract: In this paper, an efficient fragile blind quad watermarking scheme for image\ntamper detection and recovery based on lifting wavelet transform and genetic\nalgorithm is proposed. TRLG generates four compact digests with super quality\nbased on lifting wavelet transform and halftoning technique by distinguishing\nthe types of image blocks. In other words, for each 2*2 non-overlap blocks,\nfour chances for recovering destroyed blocks are considered. A special\nparameter estimation technique based on genetic algorithm is performed to\nimprove and optimize the quality of digests and watermarked image. Furthermore,\nCCS map is used to determine the mapping block for embedding information,\nencrypting and confusing the embedded information. In order to improve the\nrecovery rate, Mirror-aside and Partner-block are proposed. The experiments\nthat have been conducted to evaluate the performance of TRLG proved the\nsuperiority in terms of quality of the watermarked and recovered image, tamper\nlocalization and security compared with state-of-the-art methods. The results\nindicate that the PSNR and SSIM of the watermarked image are about 46 dB and\napproximately one, respectively. Also, the mean of PSNR and SSIM of several\nrecovered images which has been destroyed about 90% is reached to 24 dB and\n0.86, respectively. \n\n"}
{"id": "1803.03148", "contents": "Title: Generating Artificial Data for Private Deep Learning Abstract: In this paper, we propose generating artificial data that retain statistical\nproperties of real data as the means of providing privacy with respect to the\noriginal dataset. We use generative adversarial network to draw\nprivacy-preserving artificial data samples and derive an empirical method to\nassess the risk of information disclosure in a differential-privacy-like way.\nOur experiments show that we are able to generate artificial data of high\nquality and successfully train and validate machine learning models on this\ndata while limiting potential privacy loss. \n\n"}
{"id": "1803.03448", "contents": "Title: A Family of Droids -- Android Malware Detection via Behavioral Modeling:\n  Static vs Dynamic Analysis Abstract: Following the increasing popularity of mobile ecosystems, cybercriminals have\nincreasingly targeted them, designing and distributing malicious apps that\nsteal information or cause harm to the device's owner. Aiming to counter them,\ndetection techniques based on either static or dynamic analysis that model\nAndroid malware, have been proposed. While the pros and cons of these analysis\ntechniques are known, they are usually compared in the context of their\nlimitations e.g., static analysis is not able to capture runtime behaviors,\nfull code coverage is usually not achieved during dynamic analysis, etc.\nWhereas, in this paper, we analyze the performance of static and dynamic\nanalysis methods in the detection of Android malware and attempt to compare\nthem in terms of their detection performance, using the same modeling approach.\n  To this end, we build on MaMaDroid, a state-of-the-art detection system that\nrelies on static analysis to create a behavioral model from the sequences of\nabstracted API calls. Then, aiming to apply the same technique in a dynamic\nanalysis setting, we modify CHIMP, a platform recently proposed to crowdsource\nhuman inputs for app testing, in order to extract API calls' sequences from the\ntraces produced while executing the app on a CHIMP virtual device. We call this\nsystem AuntieDroid and instantiate it by using both automated (Monkey) and\nuser-generated inputs. We find that combining both static and dynamic analysis\nyields the best performance, with F-measure reaching 0.92. We also show that\nstatic analysis is at least as effective as dynamic analysis, depending on how\napps are stimulated during execution, and, finally, investigate the reasons for\ninconsistent misclassifications across methods. \n\n"}
{"id": "1803.03465", "contents": "Title: Malytics: A Malware Detection Scheme Abstract: An important problem of cyber-security is malware analysis. Besides good\nprecision and recognition rate, a malware detection scheme needs to be able to\ngeneralize well for novel malware families (a.k.a zero-day attacks). It is\nimportant that the system does not require excessive computation particularly\nfor deployment on the mobile devices. In this paper, we propose a novel scheme\nto detect malware which we call Malytics. It is not dependent on any particular\ntool or operating system. It extracts static features of any given binary file\nto distinguish malware from benign. Malytics consists of three stages: feature\nextraction, similarity measurement and classification. The three phases are\nimplemented by a neural network with two hidden layers and an output layer. We\nshow feature extraction, which is performed by tf -simhashing, is equivalent to\nthe first layer of a particular neural network. We evaluate Malytics\nperformance on both Android and Windows platforms. Malytics outperforms a wide\nrange of learning-based techniques and also individual state-of-the-art models\non both platforms. We also show Malytics is resilient and robust in addressing\nzero-day malware samples. The F1-score of Malytics is 97.21% and 99.45% on\nAndroid dex file and Windows PE files respectively, in the applied datasets.\nThe speed and efficiency of Malytics are also evaluated. \n\n"}
{"id": "1803.04228", "contents": "Title: Omnidirectional CNN for Visual Place Recognition and Navigation Abstract: $ $Visual place recognition is challenging, especially when only a few place\nexemplars are given. To mitigate the challenge, we consider place recognition\nmethod using omnidirectional cameras and propose a novel Omnidirectional\nConvolutional Neural Network (O-CNN) to handle severe camera pose variation.\nGiven a visual input, the task of the O-CNN is not to retrieve the matched\nplace exemplar, but to retrieve the closest place exemplar and estimate the\nrelative distance between the input and the closest place. With the ability to\nestimate relative distance, a heuristic policy is proposed to navigate a robot\nto the retrieved closest place. Note that the network is designed to take\nadvantage of the omnidirectional view by incorporating circular padding and\nrotation invariance. To train a powerful O-CNN, we build a virtual world for\ntraining on a large scale. We also propose a continuous lifted structured\nfeature embedding loss to learn the concept of distance efficiently. Finally,\nour experimental results confirm that our method achieves state-of-the-art\naccuracy and speed with both the virtual world and real-world datasets. \n\n"}
{"id": "1803.04861", "contents": "Title: SHARVOT: secret SHARe-based VOTing on the blockchain Abstract: Recently, there has been a growing interest in using online technologies to\ndesign protocols for secure electronic voting. The main challenges include vote\nprivacy and anonymity, ballot irrevocability and transparency throughout the\nvote counting process. The introduction of the blockchain as a basis for\ncryptocurrency protocols, provides for the exploitation of the immutability and\ntransparency properties of these distributed ledgers.\n  In this paper, we discuss possible uses of the blockchain technology to\nimplement a secure and fair voting system. In particular, we introduce a secret\nshare-based voting system on the blockchain, the so-called SHARVOT protocol.\nOur solution uses Shamir's Secret Sharing to enable on-chain, i.e. within the\ntransactions script, votes submission and winning candidate determination. The\nprotocol is also using a shuffling technique, Circle Shuffle, to de-link voters\nfrom their submissions. \n\n"}
{"id": "1803.05022", "contents": "Title: Securing the Internet of Things in the Age of Machine Learning and\n  Software-defined Networking Abstract: The Internet of Things (IoT) realizes a vision where billions of\ninterconnected devices are deployed just about everywhere, from inside our\nbodies to the most remote areas of the globe. As the IoT will soon pervade\nevery aspect of our lives and will be accessible from anywhere, addressing\ncritical IoT security threats is now more important than ever. Traditional\napproaches where security is applied as an afterthought and as a \"patch\"\nagainst known attacks are insufficient. Indeed, next-generation IoT challenges\nwill require a new secure-by-design vision, where threats are addressed\nproactively and IoT devices learn to dynamically adapt to different threats. To\nthis end, machine learning and software-defined networking will be key to\nprovide both reconfigurability and intelligence to the IoT devices. In this\npaper, we first provide a taxonomy and survey the state of the art in IoT\nsecurity research, and offer a roadmap of concrete research challenges related\nto the application of machine learning and software-defined networking to\naddress existing and next-generation IoT security threats. \n\n"}
{"id": "1803.05123", "contents": "Title: Defending against Adversarial Attack towards Deep Neural Networks via\n  Collaborative Multi-task Training Abstract: Deep neural networks (DNNs) are known to be vulnerable to adversarial\nexamples which contain human-imperceptible perturbations. A series of defending\nmethods, either proactive defence or reactive defence, have been proposed in\nthe recent years. However, most of the methods can only handle specific\nattacks. For example, proactive defending methods are invalid against grey-box\nor white-box attacks, while reactive defending methods are challenged by\nlow-distortion adversarial examples or transferring adversarial examples. This\nbecomes a critical problem since a defender usually does not have the type of\nthe attack as a priori knowledge. Moreover, existing two-pronged defences\n(e.g., MagNet), which take advantages of both proactive and reactive methods,\nhave been reported as broken under transferring attacks. To address this\nproblem, this paper proposed a novel defensive framework based on collaborative\nmulti-task training, aiming at providing defence for different types of\nattacks. The proposed defence first encodes training labels into label pairs\nand counters black-box attacks leveraging adversarial training supervised by\nthe encoded label pairs. The defence further constructs a detector to identify\nand reject high-confidence adversarial examples that bypass the black-box\ndefence. In addition, the proposed collaborative architecture can prevent\nadversaries from finding valid adversarial examples when the defence strategy\nis exposed. In the experiments, we evaluated our defence against four\nstate-of-the-art attacks on $MNIST$ and $CIFAR10$ datasets. The results showed\nthat our defending method achieved up to $96.3\\%$ classification accuracy on\nblack-box adversarial examples, and detected up to $98.7\\%$ of the high\nconfidence adversarial examples. It only decreased the model accuracy on benign\nexample classification by $2.1\\%$ for the $CIFAR10$ dataset. \n\n"}
{"id": "1803.05307", "contents": "Title: Deep CNN based feature extractor for text-prompted speaker recognition Abstract: Deep learning is still not a very common tool in speaker verification field.\nWe study deep convolutional neural network performance in the text-prompted\nspeaker verification task. The prompted passphrase is segmented into word\nstates - i.e. digits -to test each digit utterance separately. We train a\nsingle high-level feature extractor for all states and use cosine similarity\nmetric for scoring. The key feature of our network is the Max-Feature-Map\nactivation function, which acts as an embedded feature selector. By using\nmultitask learning scheme to train the high-level feature extractor we were\nable to surpass the classic baseline systems in terms of quality and achieved\nimpressive results for such a novice approach, getting 2.85% EER on the RSR2015\nevaluation set. Fusion of the proposed and the baseline systems improves this\nresult. \n\n"}
{"id": "1803.06312", "contents": "Title: EVA$^2$: Exploiting Temporal Redundancy in Live Computer Vision Abstract: Hardware support for deep convolutional neural networks (CNNs) is critical to\nadvanced computer vision in mobile and embedded devices. Current designs,\nhowever, accelerate generic CNNs; they do not exploit the unique\ncharacteristics of real-time vision. We propose to use the temporal redundancy\nin natural video to avoid unnecessary computation on most frames. A new\nalgorithm, activation motion compensation, detects changes in the visual input\nand incrementally updates a previously-computed output. The technique takes\ninspiration from video compression and applies well-known motion estimation\ntechniques to adapt to visual changes. We use an adaptive key frame rate to\ncontrol the trade-off between efficiency and vision quality as the input\nchanges. We implement the technique in hardware as an extension to existing\nstate-of-the-art CNN accelerator designs. The new unit reduces the average\nenergy per frame by 54.2%, 61.7%, and 87.6% for three CNNs with less than 1%\nloss in vision accuracy. \n\n"}
{"id": "1803.06975", "contents": "Title: Technical Report: When Does Machine Learning FAIL? Generalized\n  Transferability for Evasion and Poisoning Attacks Abstract: Recent results suggest that attacks against supervised machine learning\nsystems are quite effective, while defenses are easily bypassed by new attacks.\nHowever, the specifications for machine learning systems currently lack precise\nadversary definitions, and the existing attacks make diverse, potentially\nunrealistic assumptions about the strength of the adversary who launches them.\nWe propose the FAIL attacker model, which describes the adversary's knowledge\nand control along four dimensions. Our model allows us to consider a wide range\nof weaker adversaries who have limited control and incomplete knowledge of the\nfeatures, learning algorithms and training instances utilized. To evaluate the\nutility of the FAIL model, we consider the problem of conducting targeted\npoisoning attacks in a realistic setting: the crafted poison samples must have\nclean labels, must be individually and collectively inconspicuous, and must\nexhibit a generalized form of transferability, defined by the FAIL model. By\ntaking these constraints into account, we design StingRay, a targeted poisoning\nattack that is practical against 4 machine learning applications, which use 3\ndifferent learning algorithms, and can bypass 2 existing defenses. Conversely,\nwe show that a prior evasion attack is less effective under generalized\ntransferability. Such attack evaluations, under the FAIL adversary model, may\nalso suggest promising directions for future defenses. \n\n"}
{"id": "1803.07187", "contents": "Title: Unveiling the invisible - mathematical methods for restoring and\n  interpreting illuminated manuscripts Abstract: The last fifty years have seen an impressive development of mathematical\nmethods for the analysis and processing of digital images, mostly in the\ncontext of photography, biomedical imaging and various forms of engineering.\nThe arts have been mostly overlooked in this process, apart from a few\nexceptional works in the last ten years. With the rapid emergence of\ndigitisation in the arts, however, the arts domain is becoming increasingly\nreceptive to digital image processing methods and the importance of paying\nattention to this therefore increases. In this paper we discuss a range of\nmathematical methods for digital image restoration and digital visualisation\nfor illuminated manuscripts. The latter provide an interesting opportunity for\ndigital manipulation because they traditionally remain physically untouched. At\nthe same time they also serve as an example for the possibilities mathematics\nand digital restoration offer as a generic and objective toolkit for the arts. \n\n"}
{"id": "1803.07211", "contents": "Title: DoubleEcho: Mitigating Context-Manipulation Attacks in Copresence\n  Verification Abstract: Copresence verification based on context can improve usability and strengthen\nsecurity of many authentication and access control systems. By sensing and\ncomparing their surroundings, two or more devices can tell whether they are\ncopresent and use this information to make access control decisions. To the\nbest of our knowledge, all context-based copresence verification mechanisms to\ndate are susceptible to context-manipulation attacks. In such attacks, a\ndistributed adversary replicates the same context at the (different) locations\nof the victim devices, and induces them to believe that they are copresent. In\nthis paper we propose DoubleEcho, a context-based copresence verification\ntechnique that leverages acoustic Room Impulse Response (RIR) to mitigate\ncontext-manipulation attacks. In DoubleEcho, one device emits a wide-band\naudible chirp and all participating devices record reflections of the chirp\nfrom the surrounding environment. Since RIR is, by its very nature, dependent\non the physical surroundings, it constitutes a unique location signature that\nis hard for an adversary to replicate. We evaluate DoubleEcho by collecting RIR\ndata with various mobile devices and in a range of different locations. We show\nthat DoubleEcho mitigates context-manipulation attacks whereas all other\napproaches to date are entirely vulnerable to such attacks. DoubleEcho detects\ncopresence (or lack thereof) in roughly 2 seconds and works on commodity\ndevices. \n\n"}
{"id": "1803.07438", "contents": "Title: Ontology-Based Reasoning about the Trustworthiness of Cyber-Physical\n  Systems Abstract: It has been challenging for the technical and regulatory communities to\nformulate requirements for trustworthiness of the cyber-physical systems (CPS)\ndue to the complexity of the issues associated with their design, deployment,\nand operations. The US National Institute of Standards and Technology (NIST),\nthrough a public working group, has released a CPS Framework that adopts a\nbroad and integrated view of CPS and positions trustworthiness among other\naspects of CPS. This paper takes the model created by the CPS Framework and its\nfurther developments one step further, by applying ontological approaches and\nreasoning techniques in order to achieve greater understanding of CPS. The\nexample analyzed in the paper demonstrates the enrichment of the original CPS\nmodel obtained through ontology and reasoning and its ability to deliver\nadditional insights to the developers and operators of CPS. \n\n"}
{"id": "1803.07519", "contents": "Title: DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems Abstract: Deep learning (DL) defines a new data-driven programming paradigm that\nconstructs the internal system logic of a crafted neuron network through a set\nof training data. We have seen wide adoption of DL in many safety-critical\nscenarios. However, a plethora of studies have shown that the state-of-the-art\nDL systems suffer from various vulnerabilities which can lead to severe\nconsequences when applied to real-world applications. Currently, the testing\nadequacy of a DL system is usually measured by the accuracy of test data.\nConsidering the limitation of accessible high quality test data, good accuracy\nperformance on test data can hardly provide confidence to the testing adequacy\nand generality of DL systems. Unlike traditional software systems that have\nclear and controllable logic and functionality, the lack of interpretability in\na DL system makes system analysis and defect detection difficult, which could\npotentially hinder its real-world deployment. In this paper, we propose\nDeepGauge, a set of multi-granularity testing criteria for DL systems, which\naims at rendering a multi-faceted portrayal of the testbed. The in-depth\nevaluation of our proposed testing criteria is demonstrated on two well-known\ndatasets, five DL systems, and with four state-of-the-art adversarial attack\ntechniques against DL. The potential usefulness of DeepGauge sheds light on the\nconstruction of more generic and robust DL systems. \n\n"}
{"id": "1803.08396", "contents": "Title: Densely Connected Pyramid Dehazing Network Abstract: We propose a new end-to-end single image dehazing method, called Densely\nConnected Pyramid Dehazing Network (DCPDN), which can jointly learn the\ntransmission map, atmospheric light and dehazing all together. The end-to-end\nlearning is achieved by directly embedding the atmospheric scattering model\ninto the network, thereby ensuring that the proposed method strictly follows\nthe physics-driven scattering model for dehazing. Inspired by the dense network\nthat can maximize the information flow along features from different levels, we\npropose a new edge-preserving densely connected encoder-decoder structure with\nmulti-level pyramid pooling module for estimating the transmission map. This\nnetwork is optimized using a newly introduced edge-preserving loss function. To\nfurther incorporate the mutual structural information between the estimated\ntransmission map and the dehazed result, we propose a joint-discriminator based\non generative adversarial network framework to decide whether the corresponding\ndehazed image and the estimated transmission map are real or fake. An ablation\nstudy is conducted to demonstrate the effectiveness of each module evaluated at\nboth estimated transmission map and dehazed result. Extensive experiments\ndemonstrate that the proposed method achieves significant improvements over the\nstate-of-the-art methods. Code will be made available at:\nhttps://github.com/hezhangsprinter \n\n"}
{"id": "1803.09160", "contents": "Title: Handling Adversarial Concept Drift in Streaming Data Abstract: Classifiers operating in a dynamic, real world environment, are vulnerable to\nadversarial activity, which causes the data distribution to change over time.\nThese changes are traditionally referred to as concept drift, and several\napproaches have been developed in literature to deal with the problem of drift\nhandling and detection. However, most concept drift handling techniques,\napproach it as a domain independent task, to make them applicable to a wide\ngamut of reactive systems. These techniques were developed from an adversarial\nagnostic perspective, where they are naive and assume that drift is a benign\nchange, which can be fixed by updating the model. However, this is not the case\nwhen an active adversary is trying to evade the deployed classification system.\nIn such an environment, the properties of concept drift are unique, as the\ndrift is intended to degrade the system and at the same time designed to avoid\ndetection by traditional concept drift detection techniques. This special\ncategory of drift is termed as adversarial drift, and this paper analyzes its\ncharacteristics and impact, in a streaming environment. A novel framework for\ndealing with adversarial concept drift is proposed, called the Predict-Detect\nstreaming framework. Experimental evaluation of the framework, on generated\nadversarial drifting data streams, demonstrates that this framework is able to\nprovide reliable unsupervised indication of drift, and is able to recover from\ndrifts swiftly. While traditional partially labeled concept drift detection\nmethodologies fail to detect adversarial drifts, the proposed framework is able\nto detect such drifts and operates with <6% labeled data, on average. Also, the\nframework provides benefits for active learning over imbalanced data streams,\nby innately providing for feature space honeypots, where minority class\nadversarial samples may be captured. \n\n"}
{"id": "1803.09163", "contents": "Title: Security Theater: On the Vulnerability of Classifiers to Exploratory\n  Attacks Abstract: The increasing scale and sophistication of cyberattacks has led to the\nadoption of machine learning based classification techniques, at the core of\ncybersecurity systems. These techniques promise scale and accuracy, which\ntraditional rule or signature based methods cannot. However, classifiers\noperating in adversarial domains are vulnerable to evasion attacks by an\nadversary, who is capable of learning the behavior of the system by employing\nintelligently crafted probes. Classification accuracy in such domains provides\na false sense of security, as detection can easily be evaded by carefully\nperturbing the input samples. In this paper, a generic data driven framework is\npresented, to analyze the vulnerability of classification systems to black box\nprobing based attacks. The framework uses an exploration exploitation based\nstrategy, to understand an adversary's point of view of the attack defense\ncycle. The adversary assumes a black box model of the defender's classifier and\ncan launch indiscriminate attacks on it, without information of the defender's\nmodel type, training data or the domain of application. Experimental evaluation\non 10 real world datasets demonstrates that even models having high perceived\naccuracy (>90%), by a defender, can be effectively circumvented with a high\nevasion rate (>95%, on average). The detailed attack algorithms, adversarial\nmodel and empirical evaluation, serve. \n\n"}
{"id": "1803.10024", "contents": "Title: Cryptanalysis of a Chaotic Image Encryption Algorithm Based on\n  Information Entropy Abstract: Recently, a chaotic image encryption algorithm based on information entropy\n(IEAIE) was proposed. This paper scrutinizes the security properties of the\nalgorithm and evaluates the validity of the used quantifiable security metrics.\nWhen the round number is only one, the equivalent secret key of every basic\noperation of IEAIE can be recovered with a differential attack separately. Some\ncommon insecurity problems in the field of chaotic image encryption are found\nin IEAIE, e.g. the short orbits of the digital chaotic system and the invalid\nsensitivity mechanism built on information entropy of the plain image. Even\nworse, each security metric is questionable, which undermines the security\ncredibility of IEAIE. Hence, IEAIE can only serve as a counterexample for\nillustrating common pitfalls in designing secure communication method for image\ndata. \n\n"}
{"id": "1803.11556", "contents": "Title: Learning to Anonymize Faces for Privacy Preserving Action Detection Abstract: There is an increasing concern in computer vision devices invading users'\nprivacy by recording unwanted videos. On the one hand, we want the camera\nsystems to recognize important events and assist human daily lives by\nunderstanding its videos, but on the other hand we want to ensure that they do\nnot intrude people's privacy. In this paper, we propose a new principled\napproach for learning a video \\emph{face anonymizer}. We use an adversarial\ntraining setting in which two competing systems fight: (1) a video anonymizer\nthat modifies the original video to remove privacy-sensitive information while\nstill trying to maximize spatial action detection performance, and (2) a\ndiscriminator that tries to extract privacy-sensitive information from the\nanonymized videos. The end result is a video anonymizer that performs\npixel-level modifications to anonymize each person's face, with minimal effect\non action detection performance. We experimentally confirm the benefits of our\napproach compared to conventional hand-crafted anonymization methods including\nmasking, blurring, and noise adding. Code, demo, and more results can be found\non our project page https://jason718.github.io/project/privacy/main.html. \n\n"}
{"id": "1804.00308", "contents": "Title: Manipulating Machine Learning: Poisoning Attacks and Countermeasures for\n  Regression Learning Abstract: As machine learning becomes widely used for automated decisions, attackers\nhave strong incentives to manipulate the results and models generated by\nmachine learning algorithms. In this paper, we perform the first systematic\nstudy of poisoning attacks and their countermeasures for linear regression\nmodels. In poisoning attacks, attackers deliberately influence the training\ndata to manipulate the results of a predictive model. We propose a\ntheoretically-grounded optimization framework specifically designed for linear\nregression and demonstrate its effectiveness on a range of datasets and models.\nWe also introduce a fast statistical attack that requires limited knowledge of\nthe training process. Finally, we design a new principled defense method that\nis highly resilient against all poisoning attacks. We provide formal guarantees\nabout its convergence and an upper bound on the effect of poisoning attacks\nwhen the defense is deployed. We evaluate extensively our attacks and defenses\non three realistic datasets from health care, loan assessment, and real estate\ndomains. \n\n"}
{"id": "1804.00399", "contents": "Title: Towards Scaling Blockchain Systems via Sharding Abstract: Existing blockchain systems scale poorly because of their distributed\nconsensus protocols. Current attempts at improving blockchain scalability are\nlimited to cryptocurrency. Scaling blockchain systems under general workloads\n(i.e., non-cryptocurrency applications) remains an open question. In this work,\nwe take a principled approach to apply sharding, which is a well-studied and\nproven technique to scale out databases, to blockchain systems in order to\nimprove their transaction throughput at scale. This is challenging, however,\ndue to the fundamental difference in failure models between databases and\nblockchain. To achieve our goal, we first enhance the performance of Byzantine\nconsensus protocols, by doing so we improve individual shards' throughput.\nNext, we design an efficient shard formation protocol that leverages a trusted\nrandom beacon to securely assign nodes into shards. We rely on trusted\nhardware, namely Intel SGX, to achieve high performance for both consensus and\nshard formation protocol. Third, we design a general distributed transaction\nprotocol that ensures safety and liveness even when transaction coordinators\nare malicious. Finally, we conduct an extensive evaluation of our design both\non a local cluster and on Google Cloud Platform. The results show that our\nconsensus and shard formation protocols outperform state-of-the-art solutions\nat scale. More importantly, our sharded blockchain reaches a high throughput\nthat can handle Visa-level workloads, and is the largest ever reported in a\nrealistic environment. \n\n"}
{"id": "1804.00623", "contents": "Title: Hyperdrive: A Multi-Chip Systolically Scalable Binary-Weight CNN\n  Inference Engine Abstract: Deep neural networks have achieved impressive results in computer vision and\nmachine learning. Unfortunately, state-of-the-art networks are extremely\ncompute and memory intensive which makes them unsuitable for mW-devices such as\nIoT end-nodes. Aggressive quantization of these networks dramatically reduces\nthe computation and memory footprint. Binary-weight neural networks (BWNs)\nfollow this trend, pushing weight quantization to the limit. Hardware\naccelerators for BWNs presented up to now have focused on core efficiency,\ndisregarding I/O bandwidth and system-level efficiency that are crucial for\ndeployment of accelerators in ultra-low power devices. We present Hyperdrive: a\nBWN accelerator dramatically reducing the I/O bandwidth exploiting a novel\nbinary-weight streaming approach, which can be used for arbitrarily sized\nconvolutional neural network architecture and input resolution by exploiting\nthe natural scalability of the compute units both at chip-level and\nsystem-level by arranging Hyperdrive chips systolically in a 2D mesh while\nprocessing the entire feature map together in parallel. Hyperdrive achieves 4.3\nTOp/s/W system-level efficiency (i.e., including I/Os)---3.1x higher than\nstate-of-the-art BWN accelerators, even if its core uses resource-intensive\nFP16 arithmetic for increased robustness. \n\n"}
{"id": "1804.00920", "contents": "Title: Speech waveform synthesis from MFCC sequences with generative\n  adversarial networks Abstract: This paper proposes a method for generating speech from filterbank mel\nfrequency cepstral coefficients (MFCC), which are widely used in speech\napplications, such as ASR, but are generally considered unusable for speech\nsynthesis. First, we predict fundamental frequency and voicing information from\nMFCCs with an autoregressive recurrent neural net. Second, the spectral\nenvelope information contained in MFCCs is converted to all-pole filters, and a\npitch-synchronous excitation model matched to these filters is trained.\nFinally, we introduce a generative adversarial network -based noise model to\nadd a realistic high-frequency stochastic component to the modeled excitation\nsignal. The results show that high quality speech reconstruction can be\nobtained, given only MFCC information at test time. \n\n"}
{"id": "1804.01341", "contents": "Title: On the Economic Significance of Ransomware Campaigns: A Bitcoin\n  Transactions Perspective Abstract: Bitcoin cryptocurrency system enables users to transact securely and\npseudo-anonymously by using an arbitrary number of aliases (Bitcoin addresses).\nCybercriminals exploit these characteristics to commit immutable and presumably\nuntraceable monetary fraud, especially via ransomware; a type of malware that\nencrypts files of the infected system and demands ransom for decryption.\n  In this paper, we present our comprehensive study on all recent ransomware\nand report the economic impact of such ransomware from the Bitcoin payment\nperspective. We also present a lightweight framework to identify, collect, and\nanalyze Bitcoin addresses managed by the same user or group of users\n(cybercriminals, in this case), which includes a novel approach for classifying\na payment as ransom. To verify the correctness of our framework, we compared\nour findings on CryptoLocker ransomware with the results presented in the\nliterature. Our results align with the results found in the previous works\nexcept for the final valuation in USD. The reason for this discrepancy is that\nwe used the average Bitcoin price on the day of each ransom payment whereas the\nauthors of the previous studies used the Bitcoin price on the day of their\nevaluation. Furthermore, for each investigated ransomware, we provide a\nholistic view of its genesis, development, the process of infection and\nexecution, and characteristic of ransom demands. Finally, we also release our\ndataset that contains a detailed transaction history of all the Bitcoin\naddresses we identified for each ransomware. \n\n"}
{"id": "1804.02149", "contents": "Title: Context-aware Data Aggregation with Localized Information Privacy Abstract: In this paper, localized information privacy (LIP) is proposed, as a new\nprivacy definition, which allows statistical aggregation while protecting\nusers' privacy without relying on a trusted third party. The notion of\ncontext-awareness is incorporated in LIP by the introduction of priors, which\nenables the design of privacy-preserving data aggregation with knowledge of\npriors. We show that LIP relaxes the Localized Differential Privacy (LDP)\nnotion by explicitly modeling the adversary's knowledge. However, it is\nstricter than $2\\epsilon$-LDP and $\\epsilon$-mutual information privacy. The\nincorporation of local priors allows LIP to achieve higher utility compared to\nother approaches. We then present an optimization framework for\nprivacy-preserving data aggregation, with the goal of minimizing the expected\nsquared error while satisfying the LIP privacy constraints. Utility-privacy\ntradeoffs are obtained under several models in closed-form. We then validate\nour analysis by {numerical analysis} using both synthetic and real-world data.\nResults show that our LIP mechanism provides better utility-privacy tradeoffs\nthan LDP and when the prior is not uniformly distributed, the advantage of LIP\nis even more significant. \n\n"}
{"id": "1804.02161", "contents": "Title: Decentralizing Privacy Enforcement for Internet of Things Smart Objects Abstract: Internet of Things (IoT) is now evolving into a loosely coupled,\ndecentralized system of cooperating smart objects, where high- speed data\nprocessing, analytics and shorter response times are becoming more necessary\nthan ever. Such decentralization has a great impact on the way personal\ninformation generated and consumed by smart objects should be protected,\nbecause, without centralized data management, it is more difficult to control\nhow data are combined and used by smart objects. To cope with this issue, in\nthis paper, we propose a framework where users of smart objects can specify\ntheir privacy preferences. Compliance check of user individual privacy\npreferences is performed directly by smart objects. Moreover, acknowledging\nthat embedding the enforcement mechanism into smart objects implies some\noverhead, we have extensively tested the proposed framework on different\nscenarios, and the obtained results show the feasibility of our approach. \n\n"}
{"id": "1804.02237", "contents": "Title: Quantum ciphertext authentication and key recycling with the trap code Abstract: We investigate quantum authentication schemes constructed from quantum\nerror-correcting codes. We show that if the code has a property called purity\ntesting, then the resulting authentication scheme guarantees the integrity of\nciphertexts, not just plaintexts. On top of that, if the code is strong purity\ntesting, the authentication scheme also allows the encryption key to be\nrecycled, partially even if the authentication rejects. Such a strong notion of\nauthentication is useful in a setting where multiple ciphertexts can be present\nsimultaneously, such as in interactive or delegated quantum computation. With\nthese settings in mind, we give an explicit code (based on the trap code) that\nis strong purity testing but, contrary to other known strong-purity-testing\ncodes, allows for natural computation on ciphertexts. \n\n"}
{"id": "1804.02549", "contents": "Title: A comparison of recent waveform generation and acoustic modeling methods\n  for neural-network-based speech synthesis Abstract: Recent advances in speech synthesis suggest that limitations such as the\nlossy nature of the amplitude spectrum with minimum phase approximation and the\nover-smoothing effect in acoustic modeling can be overcome by using advanced\nmachine learning approaches. In this paper, we build a framework in which we\ncan fairly compare new vocoding and acoustic modeling techniques with\nconventional approaches by means of a large scale crowdsourced evaluation.\nResults on acoustic models showed that generative adversarial networks and an\nautoregressive (AR) model performed better than a normal recurrent network and\nthe AR model performed best. Evaluation on vocoders by using the same AR\nacoustic model demonstrated that a Wavenet vocoder outperformed classical\nsource-filter-based vocoders. Particularly, generated speech waveforms from the\ncombination of AR acoustic model and Wavenet vocoder achieved a similar score\nof speech quality to vocoded speech. \n\n"}
{"id": "1804.03286", "contents": "Title: On the Robustness of the CVPR 2018 White-Box Adversarial Example\n  Defenses Abstract: Neural networks are known to be vulnerable to adversarial examples. In this\nnote, we evaluate the two white-box defenses that appeared at CVPR 2018 and\nfind they are ineffective: when applying existing techniques, we can reduce the\naccuracy of the defended models to 0%. \n\n"}
{"id": "1804.03648", "contents": "Title: DeepMarks: A Digital Fingerprinting Framework for Deep Neural Networks Abstract: This paper proposes DeepMarks, a novel end-to-end framework for systematic\nfingerprinting in the context of Deep Learning (DL). Remarkable progress has\nbeen made in the area of deep learning. Sharing the trained DL models has\nbecome a trend that is ubiquitous in various fields ranging from biomedical\ndiagnosis to stock prediction. As the availability and popularity of\npre-trained models are increasing, it is critical to protect the Intellectual\nProperty (IP) of the model owner. DeepMarks introduces the first fingerprinting\nmethodology that enables the model owner to embed unique fingerprints within\nthe parameters (weights) of her model and later identify undesired usages of\nher distributed models. The proposed framework embeds the fingerprints in the\nProbability Density Function (pdf) of trainable weights by leveraging the extra\ncapacity available in contemporary DL models. DeepMarks is robust against\nfingerprints collusion as well as network transformation attacks, including\nmodel compression and model fine-tuning. Extensive proof-of-concept evaluations\non MNIST and CIFAR10 datasets, as well as a wide variety of deep neural\nnetworks architectures such as Wide Residual Networks (WRNs) and Convolutional\nNeural Networks (CNNs), corroborate the effectiveness and robustness of\nDeepMarks framework. \n\n"}
{"id": "1804.03794", "contents": "Title: Differentially Private Confidence Intervals for Empirical Risk\n  Minimization Abstract: The process of data mining with differential privacy produces results that\nare affected by two types of noise: sampling noise due to data collection and\nprivacy noise that is designed to prevent the reconstruction of sensitive\ninformation. In this paper, we consider the problem of designing confidence\nintervals for the parameters of a variety of differentially private machine\nlearning models. The algorithms can provide confidence intervals that satisfy\ndifferential privacy (as well as the more recently proposed concentrated\ndifferential privacy) and can be used with existing differentially private\nmechanisms that train models using objective perturbation and output\nperturbation. \n\n"}
{"id": "1804.03819", "contents": "Title: Efficient (nonrandom) construction and decoding for non-adaptive group\n  testing Abstract: The task of non-adaptive group testing is to identify up to $d$ defective\nitems from $N$ items, where a test is positive if it contains at least one\ndefective item, and negative otherwise. If there are $t$ tests, they can be\nrepresented as a $t \\times N$ measurement matrix. We have answered the question\nof whether there exists a scheme such that a larger measurement matrix, built\nfrom a given $t\\times N$ measurement matrix, can be used to identify up to $d$\ndefective items in time $O(t \\log_2{N})$. In the meantime, a $t \\times N$\nnonrandom measurement matrix with $t = O \\left(\\frac{d^2\n\\log_2^2{N}}{(\\log_2(d\\log_2{N}) - \\log_2{\\log_2(d\\log_2{N})})^2} \\right)$ can\nbe obtained to identify up to $d$ defective items in time $\\mathrm{poly}(t)$.\nThis is much better than the best well-known bound, $t = O \\left( d^2\n\\log_2^2{N} \\right)$. For the special case $d = 2$, there exists an efficient\nnonrandom construction in which at most two defective items can be identified\nin time $4\\log_2^2{N}$ using $t = 4\\log_2^2{N}$ tests. Numerical results show\nthat our proposed scheme is more practical than existing ones, and experimental\nresults confirm our theoretical analysis. In particular, up to $2^{7} = 128$\ndefective items can be identified in less than $16$s even for $N = 2^{100}$. \n\n"}
{"id": "1804.03820", "contents": "Title: KRB-CCN: Lightweight Authentication & Access Control for Private\n  Content-Centric Networks Abstract: Content-Centric Networking (CCN) is an internetworking paradigm that offers\nan alternative to today's IP-based Internet Architecture. Instead of focusing\non hosts and their locations, CCN emphasizes addressable named content. By\ndecoupling content from its location, CCN allows opportunistic in-network\ncontent caching, thus enabling better network utilization, at least for\nscalable content distribution. However, in order to be considered seriously,\nCCN must support basic security services, including content authenticity,\nintegrity, confidentiality, authorization and access control. Current\napproaches rely on content producers to perform authorization and access\ncontrol. This general approach has several disadvantages. First, consumer\nprivacy vis-a-vis producers is not preserved. Second, identity management and\naccess control impose high computational overhead on producers. Also,\nunnecessary repeated authentication and access control decisions must be made\nfor each content request.\n  These issues motivate our design of KRB-CCN - a complete authorization and\naccess control system for private CCNs. Inspired by Kerberos in IP-based\nnetworks, KRB-CCN involves distinct authentication and authorization\nauthorities. By doing so, KRB-CCN obviates the need for producers to make\nconsumer authentication and access control decisions. KRB-CCN preserves\nconsumer privacy since producers are unaware of consumer identities. Producers\nare also not required to keep any hard state and only need to perform two\nsymmetric key operations to guarantee that sensitive content is confidentially\ndelivered only to authenticated and authorized consumers. Most importantly,\nunlike prior designs, KRB-CCN leaves the network (i.e., CCN routers) out of any\nauthorization, access control or confidentiality issues. We describe KRB-CCN\ndesign and implementation, analyze its security, and report on its performance. \n\n"}
{"id": "1804.04005", "contents": "Title: Non-Malleable Extractors and Non-Malleable Codes: Partially Optimal\n  Constructions Abstract: The recent line of study on randomness extractors has been a great success,\nresulting in exciting new techniques, new connections, and breakthroughs to\nlong standing open problems in several seemingly different topics. These\ninclude seeded non-malleable extractors, privacy amplification protocols with\nan active adversary, independent source extractors (and explicit Ramsey\ngraphs), and non-malleable codes in the split state model. However, in all\ncases there is still a gap to optimum and the motivation to close this gap\nremains strong.\n  In this paper, we introduce a set of new techniques to further push the\nfrontier in the above questions. Our techniques lead to improvements in all of\nthe above questions, and in several cases partially optimal constructions.\nSpecifically, we obtain: 1. A seeded non-malleable extractor with seed length\n$O(log n)+log^{1+o(1)}(1/\\epsilon) and entropy requirement O(log log\nn+log(1/\\epsilon)), where the entropy requirement is asymptotically optimal by\na recent result of Gur and Shinkar \\cite{GurS17}; 2. A two-round privacy\namplification protocol with optimal entropy loss for security parameter up to\n\\Omega(k), which solves the privacy amplification problem completely; 3. A\ntwo-source extractor for entropy O(\\frac{log n log log n}{log log log n}),\nwhich also gives an explicit Ramsey graph on N vertices with no clique or\nindependent set of size (log N)^{O(\\frac{log log log N}{log log log log N})};\nand 4. The first explicit non-malleable code in the 2-split state model with\n\\emph{constant} rate, which has been a major goal in the study of non-malleable\ncodes for quite some time. One small caveat is that the error of this code is\nonly (an arbitrarily small) constant, but we can also achieve negligible error\nwith rate \\Omega(log log log n/log log n), which already improves the rate in\n\\cite{Li17} exponentially. \n\n"}
{"id": "1804.04014", "contents": "Title: PowerHammer: Exfiltrating Data from Air-Gapped Computers through Power\n  Lines Abstract: In this paper we provide an implementation, evaluation, and analysis of\nPowerHammer, a malware (bridgeware [1]) that uses power lines to exfiltrate\ndata from air-gapped computers. In this case, a malicious code running on a\ncompromised computer can control the power consumption of the system by\nintentionally regulating the CPU utilization. Data is modulated, encoded, and\ntransmitted on top of the current flow fluctuations, and then it is conducted\nand propagated through the power lines. This phenomena is known as a 'conducted\nemission'. We present two versions of the attack. Line level powerhammering: In\nthis attack, the attacker taps the in-home power lines1 that are directly\nattached to the electrical outlet. Phase level power-hammering: In this attack,\nthe attacker taps the power lines at the phase level, in the main electrical\nservice panel. In both versions of the attack, the attacker measures the\nemission conducted and then decodes the exfiltrated data. We describe the\nadversarial attack model and present modulations and encoding schemes along\nwith a transmission protocol. We evaluate the covert channel in different\nscenarios and discuss signal-to-noise (SNR), signal processing, and forms of\ninterference. We also present a set of defensive countermeasures. Our results\nshow that binary data can be covertly exfiltrated from air-gapped computers\nthrough the power lines at bit rates of 1000 bit/sec for the line level\npower-hammering attack and 10 bit/sec for the phase level power-hammering\nattack. \n\n"}
{"id": "1804.04080", "contents": "Title: Ransomware Payments in the Bitcoin Ecosystem Abstract: Ransomware can prevent a user from accessing a device and its files until a\nransom is paid to the attacker, most frequently in Bitcoin. With over 500 known\nransomware families, it has become one of the dominant cybercrime threats for\nlaw enforcement, security professionals and the public. However, a more\ncomprehensive, evidence-based picture on the global direct financial impact of\nransomware attacks is still missing. In this paper, we present a data-driven\nmethod for identifying and gathering information on Bitcoin transactions\nrelated to illicit activity based on footprints left on the public Bitcoin\nblockchain. We implement this method on-top-of the GraphSense open-source\nplatform and apply it to empirically analyze transactions related to 35\nransomware families. We estimate the lower bound direct financial impact of\neach ransomware family and find that, from 2013 to mid-2017, the market for\nransomware payments has a minimum worth of USD 12,768,536 (22,967.54 BTC). We\nalso find that the market is highly skewed with only a few number of players\nresponsible for the majority of the payments. Based on these research findings,\npolicy-makers and law enforcement agencies can use the statistics provided to\nunderstand the size of the illicit market and make informed decisions on how\nbest to address the threat. \n\n"}
{"id": "1804.04262", "contents": "Title: The Voice Conversion Challenge 2018: Promoting Development of Parallel\n  and Nonparallel Methods Abstract: We present the Voice Conversion Challenge 2018, designed as a follow up to\nthe 2016 edition with the aim of providing a common framework for evaluating\nand comparing different state-of-the-art voice conversion (VC) systems. The\nobjective of the challenge was to perform speaker conversion (i.e. transform\nthe vocal identity) of a source speaker to a target speaker while maintaining\nlinguistic information. As an update to the previous challenge, we considered\nboth parallel and non-parallel data to form the Hub and Spoke tasks,\nrespectively. A total of 23 teams from around the world submitted their\nsystems, 11 of them additionally participated in the optional Spoke task. A\nlarge-scale crowdsourced perceptual evaluation was then carried out to rate the\nsubmitted converted speech in terms of naturalness and similarity to the target\nspeaker identity. In this paper, we present a brief summary of the\nstate-of-the-art techniques for VC, followed by a detailed explanation of the\nchallenge tasks and the results that were obtained. \n\n"}
{"id": "1804.04406", "contents": "Title: Cashtag piggybacking: uncovering spam and bot activity in stock\n  microblogs on Twitter Abstract: Microblogs are increasingly exploited for predicting prices and traded\nvolumes of stocks in financial markets. However, it has been demonstrated that\nmuch of the content shared in microblogging platforms is created and publicized\nby bots and spammers. Yet, the presence (or lack thereof) and the impact of\nfake stock microblogs has never systematically been investigated before. Here,\nwe study 9M tweets related to stocks of the 5 main financial markets in the US.\nBy comparing tweets with financial data from Google Finance, we highlight\nimportant characteristics of Twitter stock microblogs. More importantly, we\nuncover a malicious practice - referred to as cashtag piggybacking -\nperpetrated by coordinated groups of bots and likely aimed at promoting\nlow-value stocks by exploiting the popularity of high-value ones. Among the\nfindings of our study is that as much as 71% of the authors of suspicious\nfinancial tweets are classified as bots by a state-of-the-art spambot detection\nalgorithm. Furthermore, 37% of them were suspended by Twitter a few months\nafter our investigation. Our results call for the adoption of spam and bot\ndetection techniques in all studies and applications that exploit\nuser-generated content for predicting the stock market. \n\n"}
{"id": "1804.04426", "contents": "Title: QRES: Quantitative Reasoning on Encrypted Security SLAs Abstract: While regulators advocate for higher cloud transparency, many Cloud Service\nProviders (CSPs) often do not provide detailed information regarding their\nsecurity implementations in their Service Level Agreements (SLAs). In practice,\nCSPs are hesitant to release detailed information regarding their security\nposture for security and proprietary reasons. This lack of transparency hinders\nthe adoption of cloud computing by enterprises and individuals. Unless CSPs\nshare information regarding the technical details of their security proceedings\nand standards, customers cannot verify which cloud provider matched their needs\nin terms of security and privacy guarantees. To address this problem, we\npropose QRES, the first system that enables (a) CSPs to disclose detailed\ninformation about their offered security services in an encrypted form to\nensure data confidentiality, and (b) customers to assess the CSPs' offered\nsecurity services and find those satisfying their security requirements. Our\nsystem preserves each party's privacy by leveraging a novel evaluation method\nbased on Secure Two Party Computation (2PC) and Searchable Encryption\ntechniques. We implement QRES and highlight its usefulness by applying it to\nexisting standardized SLAs. The real world tests illustrate that the system\nruns in acceptable time for practical application even when used with a\nmultitude of CSPs. We formally prove the security requirements of the proposed\nsystem against a strong realistic adversarial model, using an automated\ncryptographic protocol verifier. \n\n"}
{"id": "1804.04783", "contents": "Title: Comments on \"Defeating HaTCh: Building Malicious IP Cores\" Abstract: Recently, Haider et al. introduced the first rigorous hardware Trojan\ndetection algorithm called HaTCh. The foundation of HaTCh is a formal framework\nof hardware Trojan design, which formally characterizes all the hardware\nTrojans based on its properties. However, Bhardwaj et al. recently published\none paper \"Defeating HaTCh: Building Malicious IP Cores\", which incorrectly\nclaims that their newly designed hardware Trojan can evade the detection by\nHaTCh. In this paper, we explain why the claim of \"defeating HaTCh\" is\nincorrect, and we clarify several common misunderstandings about HaTCh. \n\n"}
{"id": "1804.05141", "contents": "Title: Ekiden: A Platform for Confidentiality-Preserving, Trustworthy, and\n  Performant Smart Contract Execution Abstract: Smart contracts are applications that execute on blockchains. Today they\nmanage billions of dollars in value and motivate visionary plans for pervasive\nblockchain deployment. While smart contracts inherit the availability and other\nsecurity assurances of blockchains, however, they are impeded by blockchains'\nlack of confidentiality and poor performance.\n  We present Ekiden, a system that addresses these critical gaps by combining\nblockchains with Trusted Execution Environments (TEEs). Ekiden leverages a\nnovel architecture that separates consensus from execution, enabling efficient\nTEE-backed confidentiality-preserving smart-contracts and high scalability. Our\nprototype (with Tendermint as the consensus layer) achieves example performance\nof 600x more throughput and 400x less latency at 1000x less cost than the\nEthereum mainnet.\n  Another contribution of this paper is that we systematically identify and\ntreat the pitfalls arising from harmonizing TEEs and blockchains. Treated\nseparately, both TEEs and blockchains provide powerful guarantees, but\nhybridized, though, they engender new attacks. For example, in naive designs,\nprivacy in TEE-backed contracts can be jeopardized by forgery of blocks, a\nseemingly unrelated attack vector. We believe the insights learned from Ekiden\nwill prove to be of broad importance in hybridized TEE-blockchain systems. \n\n"}
{"id": "1804.05164", "contents": "Title: Road Segmentation Using CNN with GRU Abstract: This paper presents an accurate and fast algorithm for road segmentation\nusing convolutional neural network (CNN) and gated recurrent units (GRU). For\nautonomous vehicles, road segmentation is a fundamental task that can provide\nthe drivable area for path planning. The existing deep neural network based\nsegmentation algorithms usually take a very deep encoder-decoder structure to\nfuse pixels, which requires heavy computations, large memory and long\nprocessing time. Hereby, a CNN-GRU network model is proposed and trained to\nperform road segmentation using data captured by the front camera of a vehicle.\nGRU network obtains a long spatial sequence with lower computational\ncomplexity, comparing to traditional encoder-decoder architecture. The proposed\nroad detector is evaluated on the KITTI road benchmark and achieves high\naccuracy for road segmentation at real-time processing speed. \n\n"}
{"id": "1804.05246", "contents": "Title: Summoning, No-Signaling and Relativistic Bit Commitments Abstract: Summoning is a task between two parties, Alice and Bob, with distributed\nnetworks of agents in space-time. Bob gives Alice a random quantum state, known\nto him but not her, at some point. She is required to return the state at some\nlater point, belonging to a subset defined by communications received from Bob\nat other points. Many results about summoning, including the impossibility of\nunrestricted summoning tasks and the necessary conditions for specific types of\nsummoning tasks to be possible, follow directly from the quantum no-cloning\ntheorem and the relativistic no-superluminal-signalling principle. The\nimpossibility of cloning devices can be derived from the impossibility of\nsuperluminal signalling and the projection postulate, together with assumptions\nabout the devices' location-independent functioning. In this qualified sense,\nknown summoning results follow from the causal structure of space-time and the\nproperties of quantum measurements. Bounds on the fidelity of approximate\ncloning can be similarly derived. Bit commitment protocols and other\ncryptographic protocols based on the no-summoning theorem can thus be proven\nsecure against some classes of post-quantum but non-signalling adversaries. \n\n"}
{"id": "1804.06514", "contents": "Title: The Reincarnation of Grille Cipher: A Generative Approach Abstract: In order to keep the data secret, various techniques have been implemented to\nencrypt and decrypt the secret data. Cryptography is committed to the security\nof content, i.e. it cannot be restored with a given ciphertext. Steganography\nis to hiding the existence of a communication channel within a stego. However,\nit has been difficult to construct a cipher (cypher) that simultaneously\nsatisfy both channel and content security for secure communication. Inspired by\nthe Cardan grille, this paper presents a new generative framework for grille\ncipher. A digital cardan grille is used for message encryption and decryption.\nThe ciphertext is directly sampled by a powerful generator without an explicit\ncover. Message loss and prior loss are proposed for penalizing message\nextraction error and unrealistic ciphertext. Jensen-Shannon Divergence is\nintroduced as new criteria for channel security. A simple practical data-driven\ngrille cipher is proposed using semantic image inpainting and generative\nadversarial network. Experimental results demonstrate the promising of the\nproposed method. \n\n"}
{"id": "1804.06701", "contents": "Title: VeReMi: A Dataset for Comparable Evaluation of Misbehavior Detection in\n  VANETs Abstract: Vehicular networks are networks of communicating vehicles, a major enabling\ntechnology for future cooperative and autonomous driving technologies. The most\nimportant messages in these networks are broadcast-authenticated periodic\none-hop beacons, used for safety and traffic efficiency applications such as\ncollision avoidance and traffic jam detection. However, broadcast authenticity\nis not sufficient to guarantee message correctness. The goal of misbehavior\ndetection is to analyze application data and knowledge about physical processes\nin these cyber-physical systems to detect incorrect messages, enabling local\nrevocation of vehicles transmitting malicious messages. Comparative studies\nbetween detection mechanisms are rare due to the lack of a reference dataset.\nWe take the first steps to address this challenge by introducing the Vehicular\nReference Misbehavior Dataset (VeReMi) and a discussion of valid metrics for\nsuch an assessment. VeReMi is the first public extensible dataset, allowing\nanyone to reproduce the generation process, as well as contribute attacks and\nuse the data to compare new detection mechanisms against existing ones. The\nresult of our analysis shows that the acceptance range threshold and the simple\nspeed check are complementary mechanisms that detect different attacks. This\nsupports the intuitive notion that fusion can lead to better results with data,\nand we suggest that future work should focus on effective fusion with VeReMi as\nan evaluation baseline. \n\n"}
{"id": "1804.06752", "contents": "Title: When the signal is in the noise: Exploiting Diffix's Sticky Noise Abstract: Anonymized data is highly valuable to both businesses and researchers. A\nlarge body of research has however shown the strong limits of the\nde-identification release-and-forget model, where data is anonymized and\nshared. This has led to the development of privacy-preserving query-based\nsystems. Based on the idea of \"sticky noise\", Diffix has been recently proposed\nas a novel query-based mechanism satisfying alone the EU Article~29 Working\nParty's definition of anonymization. According to its authors, Diffix adds less\nnoise to answers than solutions based on differential privacy while allowing\nfor an unlimited number of queries.\n  This paper presents a new class of noise-exploitation attacks, exploiting the\nnoise added by the system to infer private information about individuals in the\ndataset. Our first differential attack uses samples extracted from Diffix in a\nlikelihood ratio test to discriminate between two probability distributions. We\nshow that using this attack against a synthetic best-case dataset allows us to\ninfer private information with 89.4% accuracy using only 5 attributes. Our\nsecond cloning attack uses dummy conditions that conditionally strongly affect\nthe output of the query depending on the value of the private attribute. Using\nthis attack on four real-world datasets, we show that we can infer private\nattributes of at least 93% of the users in the dataset with accuracy between\n93.3% and 97.1%, issuing a median of 304 queries per user. We show how to\noptimize this attack, targeting 55.4% of the users and achieving 91.7%\naccuracy, using a maximum of only 32 queries per user.\n  Our attacks demonstrate that adding data-dependent noise, as done by Diffix,\nis not sufficient to prevent inference of private attributes. We furthermore\nargue that Diffix alone fails to satisfy Art. 29 WP's definition of\nanonymization. [...] \n\n"}
{"id": "1804.07391", "contents": "Title: Don't Mine, Wait in Line: Fair and Efficient Blockchain Consensus with\n  Robust Round Robin Abstract: Proof-of-Stake systems randomly choose, on each round, one of the\nparticipants as a consensus leader that extends the chain with the next block\nsuch that the selection probability is proportional to the owned stake.\nHowever, distributed random number generation is notoriously difficult. Systems\nthat derive randomness from the previous blocks are completely insecure;\nsolutions that provide secure random selection are inefficient due to their\nhigh communication complexity; and approaches that balance security and\nperformance exhibit selection bias. When block creation is rewarded with new\nstake, even a minor bias can have a severe cumulative effect.\n  In this paper, we propose Robust Round Robin, a new consensus scheme that\naddresses this selection problem. We create reliable long-term identities by\nbootstrapping from an existing infrastructure, such as Intel's SGX processors,\nor by mining them starting from an initial fair distribution. For leader\nselection we use a deterministic approach. On each round, we select a set of\nthe previously created identities as consensus leader candidates in round robin\nmanner. Because simple round-robin alone is vulnerable to attacks and offers\npoor liveness, we complement such deterministic selection policy with a\nlightweight endorsement mechanism that is an interactive protocol between the\nleader candidates and a small subset of other system participants. Our solution\nhas low good efficiency as it requires no expensive distributed randomness\ngeneration and it provides block creation fairness which is crucial in\ndeployments that reward it with new stake. \n\n"}
{"id": "1804.08778", "contents": "Title: Query-Efficient Black-Box Attack Against Sequence-Based Malware\n  Classifiers Abstract: In this paper, we present a generic, query-efficient black-box attack against\nAPI call-based machine learning malware classifiers. We generate adversarial\nexamples by modifying the malware's API call sequences and non-sequential\nfeatures (printable strings), and these adversarial examples will be\nmisclassified by the target malware classifier without affecting the malware's\nfunctionality. In contrast to previous studies, our attack minimizes the number\nof malware classifier queries required. In addition, in our attack, the\nattacker must only know the class predicted by the malware classifier; attacker\nknowledge of the malware classifier's confidence score is optional. We evaluate\nthe attack effectiveness when attacks are performed against a variety of\nmalware classifier architectures, including recurrent neural network (RNN)\nvariants, deep neural networks, support vector machines, and gradient boosted\ndecision trees. Our attack success rate is around 98% when the classifier's\nconfidence score is known and 64% when just the classifier's predicted class is\nknown. We implement four state-of-the-art query-efficient attacks and show that\nour attack requires fewer queries and less knowledge about the attacked model's\narchitecture than other existing query-efficient attacks, making it practical\nfor attacking cloud-based malware classifiers at a minimal cost. \n\n"}
{"id": "1804.10189", "contents": "Title: The Capacity of Private Information Retrieval with Eavesdroppers Abstract: We consider the problem of private information retrieval (PIR) with colluding\nservers and eavesdroppers (abbreviated as ETPIR). The ETPIR problem is\ncomprised of $K$ messages, $N$ servers where each server stores all $K$\nmessages, a user who wants to retrieve one of the $K$ messages without\nrevealing the desired message index to any set of $T$ colluding servers, and an\neavesdropper who can listen to the queries and answers of any $E$ servers but\nis prevented from learning any information about the messages. The information\ntheoretic capacity of ETPIR is defined to be the maximum number of desired\nmessage symbols retrieved privately per information symbol downloaded. We show\nthat the capacity of ETPIR is $C = \\left( 1- \\frac{E}{N} \\right) \\left(1 +\n\\frac{T-E}{N-E} + \\cdots + \\left( \\frac{T-E}{N-E} \\right)^{K-1} \\right)^{-1}$\nwhen $E < T$, and $C = \\left( 1 - \\frac{E}{N} \\right)$ when $E \\geq T$. To\nachieve the capacity, the servers need to share a common random variable\n(independent of the messages), and its size must be at least $\\frac{E}{N} \\cdot\n\\frac{1}{C}$ symbols per message symbol. Otherwise, with less amount of shared\ncommon randomness, ETPIR is not feasible and the capacity reduces to zero.\n  An interesting observation is that the ETPIR capacity expression takes\ndifferent forms in two regimes. When $E < T$, the capacity equals the inverse\nof a sum of a geometric series with $K$ terms and decreases with $K$; this form\nis typical for capacity expressions of PIR. When $E \\geq T$, the capacity does\nnot depend on $K$, a typical form for capacity expressions of SPIR (symmetric\nPIR, which further requires data-privacy, {\\it i.e.,} the user learns no\ninformation about other undesired messages); the capacity does not depend on\n$T$ either. In addition, the ETPIR capacity result includes multiple previous\nPIR and SPIR capacity results as special cases. \n\n"}
{"id": "1805.00074", "contents": "Title: Checking is Believing: Event-Aware Program Anomaly Detection in\n  Cyber-Physical Systems Abstract: Securing cyber-physical systems (CPS) against malicious attacks is of\nparamount importance because these attacks may cause irreparable damages to\nphysical systems. Recent studies have revealed that control programs running on\nCPS devices suffer from both control-oriented attacks (e.g., code-injection or\ncode-reuse attacks) and data-oriented attacks (e.g., non-control data attacks).\nUnfortunately, existing detection mechanisms are insufficient to detect runtime\ndata-oriented exploits, due to the lack of runtime execution semantics\nchecking. In this work, we propose Orpheus, a new security methodology for\ndefending against data-oriented attacks by enforcing cyber-physical execution\nsemantics. We first present a general method for reasoning cyber-physical\nexecution semantics of a control program (i.e., causal dependencies between the\nphysical context and program control flows), including the event identification\nand dependence analysis. As an instantiation of Orpheus, we then present a new\nprogram behavior model, i.e., the event-aware finite-state automaton (eFSA).\neFSA takes advantage of the event-driven nature of CPS control programs and\nincorporates event checking in anomaly detection. It detects data-oriented\nexploits if a specific physical event is missing along with the corresponding\nevent dependent state transition. We evaluate our prototype's performance by\nconducting case studies under data-oriented attacks. Results show that eFSA can\nsuccessfully detect different runtime attacks. Our prototype on Raspberry Pi\nincurs a low overhead, taking 0.0001s for each state transition integrity\nchecking, and 0.063s~0.211s for the cyber-physical contextual consistency\nchecking. \n\n"}
{"id": "1805.00216", "contents": "Title: Privately Learning High-Dimensional Distributions Abstract: We present novel, computationally efficient, and differentially private\nalgorithms for two fundamental high-dimensional learning problems: learning a\nmultivariate Gaussian and learning a product distribution over the Boolean\nhypercube in total variation distance. The sample complexity of our algorithms\nnearly matches the sample complexity of the optimal non-private learners for\nthese tasks in a wide range of parameters, showing that privacy comes\nessentially for free for these problems. In particular, in contrast to previous\napproaches, our algorithm for learning Gaussians does not require strong a\npriori bounds on the range of the parameters. Our algorithms introduce a novel\ntechnical approach to reducing the sensitivity of the estimation procedure that\nwe call recursive private preconditioning. \n\n"}
{"id": "1805.00310", "contents": "Title: On the Limitation of MagNet Defense against $L_1$-based Adversarial\n  Examples Abstract: In recent years, defending adversarial perturbations to natural examples in\norder to build robust machine learning models trained by deep neural networks\n(DNNs) has become an emerging research field in the conjunction of deep\nlearning and security. In particular, MagNet consisting of an adversary\ndetector and a data reformer is by far one of the strongest defenses in the\nblack-box oblivious attack setting, where the attacker aims to craft\ntransferable adversarial examples from an undefended DNN model to bypass an\nunknown defense module deployed on the same DNN model. Under this setting,\nMagNet can successfully defend a variety of attacks in DNNs, including the\nhigh-confidence adversarial examples generated by the Carlini and Wagner's\nattack based on the $L_2$ distortion metric. However, in this paper, under the\nsame attack setting we show that adversarial examples crafted based on the\n$L_1$ distortion metric can easily bypass MagNet and mislead the target DNN\nimage classifiers on MNIST and CIFAR-10. We also provide explanations on why\nthe considered approach can yield adversarial examples with superior attack\nperformance and conduct extensive experiments on variants of MagNet to verify\nits lack of robustness to $L_1$ distortion based attacks. Notably, our results\nsubstantially weaken the assumption of effective threat models on MagNet that\nrequire knowing the deployed defense technique when attacking DNNs (i.e., the\ngray-box attack setting). \n\n"}
{"id": "1805.00403", "contents": "Title: iSTRICT: An Interdependent Strategic Trust Mechanism for the\n  Cloud-Enabled Internet of Controlled Things Abstract: The cloud-enabled Internet of controlled things (IoCT) envisions a network of\nsensors, controllers, and actuators connected through a local cloud in order to\nintelligently control physical devices. Because cloud services are vulnerable\nto advanced persistent threats (APTs), each device in the IoCT must\nstrategically decide whether to trust cloud services that may be compromised.\nIn this paper, we present iSTRICT, an interdependent strategic trust mechanism\nfor the cloud-enabled IoCT. iSTRICT is composed of three interdependent layers.\nIn the cloud layer, iSTRICT uses FlipIt games to conceptualize APTs. In the\ncommunication layer, it captures the interaction between devices and the cloud\nusing signaling games. In the physical layer, iSTRICT uses optimal control to\nquantify the utilities in the higher level games. Best response dynamics link\nthe three layers in an overall \"game-of-games,\" for which the outcome is\ncaptured by a concept called Gestalt Nash equilibrium (GNE). We prove the\nexistence of a GNE under a set of natural assumptions and develop an adaptive\nalgorithm to iteratively compute the equilibrium. Finally, we apply iSTRICT to\ntrust management for autonomous vehicles that rely on measurements from remote\nsources. We show that strategic trust in the communication layer achieves a\nworst-case probability of compromise for any attack and defense costs in the\ncyber layer. \n\n"}
{"id": "1805.02628", "contents": "Title: PRADA: Protecting against DNN Model Stealing Attacks Abstract: Machine learning (ML) applications are increasingly prevalent. Protecting the\nconfidentiality of ML models becomes paramount for two reasons: (a) a model can\nbe a business advantage to its owner, and (b) an adversary may use a stolen\nmodel to find transferable adversarial examples that can evade classification\nby the original model. Access to the model can be restricted to be only via\nwell-defined prediction APIs. Nevertheless, prediction APIs still provide\nenough information to allow an adversary to mount model extraction attacks by\nsending repeated queries via the prediction API. In this paper, we describe new\nmodel extraction attacks using novel approaches for generating synthetic\nqueries, and optimizing training hyperparameters. Our attacks outperform\nstate-of-the-art model extraction in terms of transferability of both targeted\nand non-targeted adversarial examples (up to +29-44 percentage points, pp), and\nprediction accuracy (up to +46 pp) on two datasets. We provide take-aways on\nhow to perform effective model extraction attacks. We then propose PRADA, the\nfirst step towards generic and effective detection of DNN model extraction\nattacks. It analyzes the distribution of consecutive API queries and raises an\nalarm when this distribution deviates from benign behavior. We show that PRADA\ncan detect all prior model extraction attacks with no false positives. \n\n"}
{"id": "1805.02996", "contents": "Title: Moir\\'{e} Photo Restoration Using Multiresolution Convolutional Neural\n  Networks Abstract: Digital cameras and mobile phones enable us to conveniently record precious\nmoments. While digital image quality is constantly being improved, taking\nhigh-quality photos of digital screens still remains challenging because the\nphotos are often contaminated with moir\\'{e} patterns, a result of the\ninterference between the pixel grids of the camera sensor and the device\nscreen. Moir\\'{e} patterns can severely damage the visual quality of photos.\nHowever, few studies have aimed to solve this problem. In this paper, we\nintroduce a novel multiresolution fully convolutional network for automatically\nremoving moir\\'{e} patterns from photos. Since a moir\\'{e} pattern spans over a\nwide range of frequencies, our proposed network performs a nonlinear\nmultiresolution analysis of the input image before computing how to cancel\nmoir\\'{e} artefacts within every frequency band. We also create a large-scale\nbenchmark dataset with $100,000^+$ image pairs for investigating and evaluating\nmoir\\'{e} pattern removal algorithms. Our network achieves state-of-the-art\nperformance on this dataset in comparison to existing learning architectures\nfor image restoration problems. \n\n"}
{"id": "1805.03553", "contents": "Title: On Visual Hallmarks of Robustness to Adversarial Malware Abstract: A central challenge of adversarial learning is to interpret the resulting\nhardened model. In this contribution, we ask how robust generalization can be\nvisually discerned and whether a concise view of the interactions between a\nhardened decision map and input samples is possible. We first provide a means\nof visually comparing a hardened model's loss behavior with respect to the\nadversarial variants generated during training versus loss behavior with\nrespect to adversarial variants generated from other sources. This allows us to\nconfirm that the association of observed flatness of a loss landscape with\ngeneralization that is seen with naturally trained models extends to\nadversarially hardened models and robust generalization. To complement these\nmeans of interpreting model parameter robustness we also use self-organizing\nmaps to provide a visual means of superimposing adversarial and natural\nvariants on a model's decision space, thus allowing the model's global\nrobustness to be comprehensively examined. \n\n"}
{"id": "1805.04101", "contents": "Title: Adding Salt to Pepper: A Structured Security Assessment over a Humanoid\n  Robot Abstract: The rise of connectivity, digitalization, robotics, and artificial\nintelligence (AI) is rapidly changing our society and shaping its future\ndevelopment. During this technological and societal revolution, security has\nbeen persistently neglected, yet a hacked robot can act as an insider threat in\norganizations, industries, public spaces, and private homes. In this paper, we\nperform a structured security assessment of Pepper, a commercial humanoid\nrobot. Our analysis, composed by an automated and a manual part, points out a\nrelevant number of security flaws that can be used to take over and command the\nrobot. Furthermore, we suggest how these issues could be fixed, thus, avoided\nin the future. The very final aim of this work is to push the rise of the\nsecurity level of IoT products before they are sold on the public market. \n\n"}
{"id": "1805.04772", "contents": "Title: VAMS: Verifiable Auditing of Access to Confidential Data Abstract: We propose VAMS, a system that enables transparency for audits of access to\ndata requests without compromising the privacy of parties in the system. VAMS\nsupports audits on an aggregate level and an individual level, by relying on\nthree mechanisms. A tamper-evident log provides integrity for the log entries\nthat are audited. A tagging scheme allows users to query log entries that\nrelate to them, without allowing others to do so. MultiBallot, a novel\nextension of the ThreeBallot voting scheme, is used to generate a synthetic\ndataset that can be used to publicly verify published statistics with a low\nexpected privacy loss. We evaluate two implementations of VAMS, and show that\nboth the log and the ability to verify published statistics are practical for\nrealistic use cases such as access to healthcare records and law enforcement\naccess to communications records. \n\n"}
{"id": "1805.05098", "contents": "Title: Hu-Fu: Hardware and Software Collaborative Attack Framework against\n  Neural Networks Abstract: Recently, Deep Learning (DL), especially Convolutional Neural Network (CNN),\ndevelops rapidly and is applied to many tasks, such as image classification,\nface recognition, image segmentation, and human detection. Due to its superior\nperformance, DL-based models have a wide range of application in many areas,\nsome of which are extremely safety-critical, e.g. intelligent surveillance and\nautonomous driving. Due to the latency and privacy problem of cloud computing,\nembedded accelerators are popular in these safety-critical areas. However, the\nrobustness of the embedded DL system might be harmed by inserting\nhardware/software Trojans into the accelerator and the neural network model,\nsince the accelerator and deploy tool (or neural network model) are usually\nprovided by third-party companies. Fortunately, inserting hardware Trojans can\nonly achieve inflexible attack, which means that hardware Trojans can easily\nbreak down the whole system or exchange two outputs, but can't make CNN\nrecognize unknown pictures as targets. Though inserting software Trojans has\nmore freedom of attack, it often requires tampering input images, which is not\neasy for attackers. So, in this paper, we propose a hardware-software\ncollaborative attack framework to inject hidden neural network Trojans, which\nworks as a back-door without requiring manipulating input images and is\nflexible for different scenarios. We test our attack framework for image\nclassification and face recognition tasks, and get attack success rate of 92.6%\nand 100% on CIFAR10 and YouTube Faces, respectively, while keeping almost the\nsame accuracy as the unattacked model in the normal mode. In addition, we show\na specific attack scenario in which a face recognition system is attacked and\ngives a specific wrong answer. \n\n"}
{"id": "1805.05288", "contents": "Title: The Gap Game Abstract: Blockchain-based cryptocurrencies secure a decentralized consensus protocol\nby incentives. The protocol participants, called miners, generate (mine) a\nseries of blocks, each containing monetary transactions created by system\nusers. As incentive for participation, miners receive newly minted currency and\ntransaction fees paid by transaction creators. Blockchain bandwidth limits lead\nusers to pay increasing fees in order to prioritize their transactions.\nHowever, most prior work focused on models where fees are negligible. In a\nnotable exception, Carlsten et al. postulated in CCS'16 that if incentives come\nonly from fees then a mining gap would form~--- miners would avoid mining when\nthe available fees are insufficient.\n  In this work, we analyze cryptocurrency security in realistic settings,\ntaking into account all elements of expenses and rewards. To study when gaps\nform, we analyze the system as a game we call \\emph{the gap game}. We analyze\nthe game with a combination of symbolic and numeric analysis tools in a wide\nrange of scenarios.\n  Our analysis confirms Carlsten et al.'s postulate; indeed, we show that gaps\nform well before fees are the only incentive, and analyze the implications on\nsecurity. Perhaps surprisingly, we show that different miners choose different\ngap sizes to optimize their utility, even when their operating costs are\nidentical. Alarmingly, we see that the system incentivizes large miner\ncoalitions, reducing system decentralization. We describe the required\nconditions to avoid the incentive misalignment, providing guidelines for future\ncryptocurrency design. \n\n"}
{"id": "1805.05603", "contents": "Title: Neural Classification of Malicious Scripts: A study with JavaScript and\n  VBScript Abstract: Malicious scripts are an important computer infection threat vector. Our\nanalysis reveals that the two most prevalent types of malicious scripts include\nJavaScript and VBScript. The percentage of detected JavaScript attacks are on\nthe rise. To address these threats, we investigate two deep recurrent models,\nLaMP (LSTM and Max Pooling) and CPoLS (Convoluted Partitioning of Long\nSequences), which process JavaScript and VBScript as byte sequences. Lower\nlayers capture the sequential nature of these byte sequences while higher\nlayers classify the resulting embedding as malicious or benign. Unlike\npreviously proposed solutions, our models are trained in an end-to-end fashion\nallowing discriminative training even for the sequential processing layers.\nEvaluating these models on a large corpus of 296,274 JavaScript files indicates\nthat the best performing LaMP model has a 65.9% true positive rate (TPR) at a\nfalse positive rate (FPR) of 1.0%. Similarly, the best CPoLS model has a TPR of\n45.3% at an FPR of 1.0%. LaMP and CPoLS yield a TPR of 69.3% and 67.9%,\nrespectively, at an FPR of 1.0% on a collection of 240,504 VBScript files. \n\n"}
{"id": "1805.05838", "contents": "Title: Gradient-Leaks: Understanding and Controlling Deanonymization in\n  Federated Learning Abstract: Federated Learning (FL) systems are gaining popularity as a solution to\ntraining Machine Learning (ML) models from large-scale user data collected on\npersonal devices (e.g., smartphones) without their raw data leaving the device.\nAt the core of FL is a network of anonymous user devices sharing training\ninformation (model parameter updates) computed locally on personal data.\nHowever, the type and degree to which user-specific information is encoded in\nthe model updates is poorly understood. In this paper, we identify model\nupdates encode subtle variations in which users capture and generate data. The\nvariations provide a strong statistical signal, allowing an adversary to\neffectively deanonymize participating devices using a limited set of auxiliary\ndata. We analyze resulting deanonymization attacks on diverse tasks on\nreal-world (anonymized) user-generated data across a range of closed- and\nopen-world scenarios. We study various strategies to mitigate the risks of\ndeanonymization. As random perturbation methods do not offer convincing\noperating points, we propose data-augmentation strategies which introduces\nadversarial biases in device data and thereby, offer substantial protection\nagainst deanonymization threats with little effect on utility. \n\n"}
{"id": "1805.05887", "contents": "Title: LUCON: Data Flow Control for Message-Based IoT Systems Abstract: Today's emerging Industrial Internet of Things (IIoT) scenarios are\ncharacterized by the exchange of data between services across enterprises.\nTraditional access and usage control mechanisms are only able to determine if\ndata may be used by a subject, but lack an understanding of how it may be used.\nThe ability to control the way how data is processed is however crucial for\nenterprises to guarantee (and provide evidence of) compliant processing of\ncritical data, as well as for users who need to control if their private data\nmay be analyzed or linked with additional information - a major concern in IoT\napplications processing personal information. In this paper, we introduce\nLUCON, a data-centric security policy framework for distributed systems that\nconsiders data flows by controlling how messages may be routed across services\nand how they are combined and processed. LUCON policies prevent information\nleaks, bind data usage to obligations, and enforce data flows across services.\nPolicy enforcement is based on a dynamic taint analysis at runtime and an\nupfront static verification of message routes against policies. We discuss the\nsemantics of these two complementing enforcement models and illustrate how\nLUCON policies are compiled from a simple policy language into a first-order\nlogic representation. We demonstrate the practical application of LUCON in a\nreal-world IoT middleware and discuss its integration into Apache Camel.\nFinally, we evaluate the runtime impact of LUCON and discuss performance and\nscalability aspects. \n\n"}
{"id": "1805.07894", "contents": "Title: Constructing Unrestricted Adversarial Examples with Generative Models Abstract: Adversarial examples are typically constructed by perturbing an existing data\npoint within a small matrix norm, and current defense methods are focused on\nguarding against this type of attack. In this paper, we propose unrestricted\nadversarial examples, a new threat model where the attackers are not restricted\nto small norm-bounded perturbations. Different from perturbation-based attacks,\nwe propose to synthesize unrestricted adversarial examples entirely from\nscratch using conditional generative models. Specifically, we first train an\nAuxiliary Classifier Generative Adversarial Network (AC-GAN) to model the\nclass-conditional distribution over data samples. Then, conditioned on a\ndesired class, we search over the AC-GAN latent space to find images that are\nlikely under the generative model and are misclassified by a target classifier.\nWe demonstrate through human evaluation that unrestricted adversarial examples\ngenerated this way are legitimate and belong to the desired class. Our\nempirical results on the MNIST, SVHN, and CelebA datasets show that\nunrestricted adversarial examples can bypass strong adversarial training and\ncertified defense methods designed for traditional adversarial attacks. \n\n"}
{"id": "1805.08281", "contents": "Title: On profitability of selfish mining Abstract: We review the so called selfish mining strategy in the Bitcoin network and\ncompare its profitability to honest mining.We build a rigorous profitability\nmodel for repetition games. The time analysis of the attack has been ignored in\nthe previous literature based on a Markov model,but is critical. Using\nmartingale's techniques and Doob Stopping Time Theorem we compute the expected\nduration of attack cycles. We discover a remarkable property of the bitcoin\nnetwork: no strategy is more profitable than the honest strategy before a\ndifficulty adjustment. So selfish mining can only become profitable afterwards,\nthus it is an attack on the difficulty adjustment algorithm. We propose an\nimprovement of Bitcoin protocol making it immune to selfish mining attacks. We\nalso study miner's attraction to selfish mining pools. We calculate the\nexpected duration time before profit for the selfish miner, a computation that\nis out of reach by the previous Markov models. \n\n"}
{"id": "1805.09110", "contents": "Title: The Topology ToolKit Abstract: This system paper presents the Topology ToolKit (TTK), a software platform\ndesigned for topological data analysis in scientific visualization. TTK\nprovides a unified, generic, efficient, and robust implementation of key\nalgorithms for the topological analysis of scalar data, including: critical\npoints, integral lines, persistence diagrams, persistence curves, merge trees,\ncontour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots,\nJacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due\nto a tight integration with ParaView. It is also easily accessible to\ndevelopers through a variety of bindings (Python, VTK/C++) for fast prototyping\nor through direct, dependence-free, C++, to ease integration into pre-existing\ncomplex systems. While developing TTK, we faced several algorithmic and\nsoftware engineering challenges, which we document in this paper. In\nparticular, we present an algorithm for the construction of a discrete gradient\nthat complies to the critical points extracted in the piecewise-linear setting.\nThis algorithm guarantees a combinatorial consistency across the topological\nabstractions supported by TTK, and importantly, a unified implementation of\ntopological data simplification for multi-scale exploration and analysis. We\nalso present a cached triangulation data structure, that supports time\nefficient and generic traversals, which self-adjusts its memory usage on demand\nfor input simplicial meshes and which implicitly emulates a triangulation for\nregular grids with no memory overhead. Finally, we describe an original\nsoftware architecture, which guarantees memory efficient and direct accesses to\nTTK features, while still allowing for researchers powerful and easy bindings\nand extensions. TTK is open source (BSD license) and its code, online\ndocumentation and video tutorials are available on TTK's website. \n\n"}
{"id": "1805.10032", "contents": "Title: Zeno: Distributed Stochastic Gradient Descent with Suspicion-based\n  Fault-tolerance Abstract: We present Zeno, a technique to make distributed machine learning,\nparticularly Stochastic Gradient Descent (SGD), tolerant to an arbitrary number\nof faulty workers. Zeno generalizes previous results that assumed a majority of\nnon-faulty nodes; we need assume only one non-faulty worker. Our key idea is to\nsuspect workers that are potentially defective. Since this is likely to lead to\nfalse positives, we use a ranking-based preference mechanism. We prove the\nconvergence of SGD for non-convex problems under these scenarios. Experimental\nresults show that Zeno outperforms existing approaches. \n\n"}
{"id": "1805.10133", "contents": "Title: Laplacian Networks: Bounding Indicator Function Smoothness for Neural\n  Network Robustness Abstract: For the past few years, Deep Neural Network (DNN) robustness has become a\nquestion of paramount importance. As a matter of fact, in sensitive settings\nmisclassification can lead to dramatic consequences. Such misclassifications\nare likely to occur when facing adversarial attacks, hardware failures or\nlimitations, and imperfect signal acquisition. To address this question,\nauthors have proposed different approaches aiming at increasing the robustness\nof DNNs, such as adding regularizers or training using noisy examples. In this\npaper we propose a new regularizer built upon the Laplacian of similarity\ngraphs obtained from the representation of training data at each layer of the\nDNN architecture. This regularizer penalizes large changes (across consecutive\nlayers in the architecture) in the distance between examples of different\nclasses, and as such enforces smooth variations of the class boundaries. Since\nit is agnostic to the type of deformations that are expected when predicting\nwith the DNN, the proposed regularizer can be combined with existing ad-hoc\nmethods. We provide theoretical justification for this regularizer and\ndemonstrate its effectiveness to improve robustness of DNNs on classical\nsupervised learning vision datasets. \n\n"}
{"id": "1805.10259", "contents": "Title: An evaluation of the security of the Bitcoin Peer-to- Peer Network Abstract: Bitcoin is a decentralised digital currency that relies on cryptography\nrather than trusted third parties such as central banks for its security.\nUnderpinning the operation of the currency is a peer-to-peer (P2P) network that\nfacilitates the execution of transactions by end users, as well as the\ntransaction confirmation process known as bitcoin mining. The security of this\nP2P network is vital for the currency to function and subversion of the\nunderlying network can lead to attacks on bitcoin users including theft of\nbitcoins, manipulation of the mining process and denial of service (DoS). As\npart of this paper the network protocol and bitcoin core software are analysed,\nwith three bitcoin message exchanges (the connection handshake,\nGETHEADERS/HEADERS and MEMPOOL/INV) found to be potentially vulnerable to\nspoofing and use in distributed denial of service (DDoS) attacks. Possible\nsolutions to the identified weaknesses and vulnerabilities are evaluated, such\nas the introduction of random nonces into network messages exchanges. \n\n"}
{"id": "1805.10277", "contents": "Title: Detecting Violations of Differential Privacy Abstract: The widespread acceptance of differential privacy has led to the publication\nof many sophisticated algorithms for protecting privacy. However, due to the\nsubtle nature of this privacy definition, many such algorithms have bugs that\nmake them violate their claimed privacy. In this paper, we consider the problem\nof producing counterexamples for such incorrect algorithms. The counterexamples\nare designed to be short and human-understandable so that the counterexample\ngenerator can be used in the development process -- a developer could quickly\nexplore variations of an algorithm and investigate where they break down. Our\napproach is statistical in nature. It runs a candidate algorithm many times and\nuses statistical tests to try to detect violations of differential privacy. An\nevaluation on a variety of incorrect published algorithms validates the\nusefulness of our approach: it correctly rejects incorrect algorithms and\nprovides counterexamples for them within a few seconds. \n\n"}
{"id": "1805.10815", "contents": "Title: NETRA: Enhancing IoT Security using NFV-based Edge Traffic Analysis Abstract: This is the era of smart devices or things which are fueling the growth of\nInternet of Things (IoT). It is impacting every sphere around us, making our\nlife dependent on this technological feat. It is of high concern that these\nsmart things are being targeted by cyber criminals taking advantage of\nheterogeneity, minuscule security features and vulnerabilities within these\ndevices. Conventional centralized IT security measures have limitations in\nterms of scalability and cost. Therefore, these smart devices are required to\nbe monitored closer to their location ideally at the edge of IoT networks. In\nthis paper, we explore how some security features can be implemented at the\nnetwork edge to secure these smart devices. We explain the importance of\nNetwork Function Virtualization (NFV) in order to deploy security functions at\nthe network edge. To achieve this goal, we introduce NETRA - a novel\nlightweight Docker-based architecture for virtualizing network functions to\nprovide IoT security. Also, we highlight the advantages of the proposed\narchitecture over the standardized NFV architecture in terms of storage, memory\nusage, latency, throughput, load average, scalability and explain why the\nstandardized architecture is not suitable for IoT. We study the performance of\nproposed NFV based edge analysis for IoT security and show that attacks can be\ndetected with more than 95% accuracy in less than a second. \n\n"}
{"id": "1805.10891", "contents": "Title: Automated Verification of Accountability in Security Protocols Abstract: Accountability is a recent paradigm in security protocol design which aims to\neliminate traditional trust assumptions on parties and hold them accountable\nfor their misbehavior. It is meant to establish trust in the first place and to\nrecognize and react if this trust is violated. In this work, we discuss a\nprotocol agnostic definition of accountability: a protocol provides\naccountability (w.r.t. some security property) if it can identify all\nmisbehaving parties, where misbehavior is defined as a deviation from the\nprotocol that causes a security violation. We provide a mechanized method for\nthe verification of accountability and demonstrate its use for verification and\nattack finding on various examples from the accountability and causality\nliterature, including Certificate Transparency and Kroll Accountable Algorithms\nprotocol. We reach a high degree of automation by expressing accountability in\nterms of a set of trace properties and show their soundness and completeness. \n\n"}
{"id": "1805.11090", "contents": "Title: GenAttack: Practical Black-box Attacks with Gradient-Free Optimization Abstract: Deep neural networks are vulnerable to adversarial examples, even in the\nblack-box setting, where the attacker is restricted solely to query access.\nExisting black-box approaches to generating adversarial examples typically\nrequire a significant number of queries, either for training a substitute\nnetwork or performing gradient estimation. We introduce GenAttack, a\ngradient-free optimization technique that uses genetic algorithms for\nsynthesizing adversarial examples in the black-box setting. Our experiments on\ndifferent datasets (MNIST, CIFAR-10, and ImageNet) show that GenAttack can\nsuccessfully generate visually imperceptible adversarial examples against\nstate-of-the-art image recognition models with orders of magnitude fewer\nqueries than previous approaches. Against MNIST and CIFAR-10 models, GenAttack\nrequired roughly 2,126 and 2,568 times fewer queries respectively, than ZOO,\nthe prior state-of-the-art black-box attack. In order to scale up the attack to\nlarge-scale high-dimensional ImageNet models, we perform a series of\noptimizations that further improve the query efficiency of our attack leading\nto 237 times fewer queries against the Inception-v3 model than ZOO.\nFurthermore, we show that GenAttack can successfully attack some\nstate-of-the-art ImageNet defenses, including ensemble adversarial training and\nnon-differentiable or randomized input transformations. Our results suggest\nthat evolutionary algorithms open up a promising area of research into\neffective black-box attacks. \n\n"}
{"id": "1805.11318", "contents": "Title: CNN-Based Detection of Generic Constrast Adjustment with JPEG\n  Post-processing Abstract: Detection of contrast adjustments in the presence of JPEG postprocessing is\nknown to be a challenging task. JPEG post processing is often applied\ninnocently, as JPEG is the most common image format, or it may correspond to a\nlaundering attack, when it is purposely applied to erase the traces of\nmanipulation. In this paper, we propose a CNN-based detector for generic\ncontrast adjustment, which is robust to JPEG compression. The proposed system\nrelies on a patch-based Convolutional Neural Network (CNN), trained to\ndistinguish pristine images from contrast adjusted images, for some selected\nadjustment operators of different nature. Robustness to JPEG compression is\nachieved by training the CNN with JPEG examples, compressed over a range of\nQuality Factors (QFs). Experimental results show that the detector works very\nwell and scales well with respect to the adjustment type, yielding very good\nperformance under a large variety of unseen tonal adjustments. \n\n"}
{"id": "1805.11748", "contents": "Title: Sublinear decoding schemes for non-adaptive group testing with\n  inhibitors Abstract: Identification of up to $d$ defective items and up to $h$ inhibitors in a set\nof $n$ items is the main task of non-adaptive group testing with inhibitors. To\nefficiently reduce the cost of this Herculean task, a subset of the $n$ items\nis formed and then tested. This is called \\textit{group testing}. A test\noutcome on a subset of items is positive if the subset contains at least one\ndefective item and no inhibitors, and negative otherwise. We present two\ndecoding schemes for efficiently identifying the defective items and the\ninhibitors in the presence of $e$ erroneous outcomes in time $\\mathsf{poly}(d,\nh, e, \\log_2{n})$, which is sublinear to the number of items $n$. This decoding\ncomplexity significantly improves the state-of-the-art schemes in which the\ndecoding time is linear to the number of items $n$, i.e., $\\mathsf{poly}(d, h,\ne, n)$. Moreover, each column of the measurement matrices associated with the\nproposed schemes can be nonrandomly generated in polynomial order of the number\nof rows. As a result, one can save space for storing them. Simulation results\nconfirm our theoretical analysis. When the number of items is sufficiently\nlarge, the decoding time in our proposed scheme is smallest in comparison with\nexisting work. In addition, when some erroneous outcomes are allowed, the\nnumber of tests in the proposed scheme is often smaller than the number of\ntests in existing work. \n\n"}
{"id": "1805.11852", "contents": "Title: ADAGIO: Interactive Experimentation with Adversarial Attack and Defense\n  for Audio Abstract: Adversarial machine learning research has recently demonstrated the\nfeasibility to confuse automatic speech recognition (ASR) models by introducing\nacoustically imperceptible perturbations to audio samples. To help researchers\nand practitioners gain better understanding of the impact of such attacks, and\nto provide them with tools to help them more easily evaluate and craft strong\ndefenses for their models, we present ADAGIO, the first tool designed to allow\ninteractive experimentation with adversarial attacks and defenses on an ASR\nmodel in real time, both visually and aurally. ADAGIO incorporates AMR and MP3\naudio compression techniques as defenses, which users can interactively apply\nto attacked audio samples. We show that these techniques, which are based on\npsychoacoustic principles, effectively eliminate targeted attacks, reducing the\nattack success rate from 92.5% to 0%. We will demonstrate ADAGIO and invite the\naudience to try it on the Mozilla Common Voice dataset. \n\n"}
{"id": "1805.12185", "contents": "Title: Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural\n  Networks Abstract: Deep neural networks (DNNs) provide excellent performance across a wide range\nof classification tasks, but their training requires high computational\nresources and is often outsourced to third parties. Recent work has shown that\noutsourced training introduces the risk that a malicious trainer will return a\nbackdoored DNN that behaves normally on most inputs but causes targeted\nmisclassifications or degrades the accuracy of the network when a trigger known\nonly to the attacker is present. In this paper, we provide the first effective\ndefenses against backdoor attacks on DNNs. We implement three backdoor attacks\nfrom prior work and use them to investigate two promising defenses, pruning and\nfine-tuning. We show that neither, by itself, is sufficient to defend against\nsophisticated attackers. We then evaluate fine-pruning, a combination of\npruning and fine-tuning, and show that it successfully weakens or even\neliminates the backdoors, i.e., in some cases reducing the attack success rate\nto 0% with only a 0.4% drop in accuracy for clean (non-triggering) inputs. Our\nwork provides the first step toward defenses against backdoor attacks in deep\nneural networks. \n\n"}
{"id": "1806.00081", "contents": "Title: Resisting Adversarial Attacks using Gaussian Mixture Variational\n  Autoencoders Abstract: Susceptibility of deep neural networks to adversarial attacks poses a major\ntheoretical and practical challenge. All efforts to harden classifiers against\nsuch attacks have seen limited success. Two distinct categories of samples to\nwhich deep networks are vulnerable, \"adversarial samples\" and \"fooling\nsamples\", have been tackled separately so far due to the difficulty posed when\nconsidered together. In this work, we show how one can address them both under\none unified framework. We tie a discriminative model with a generative model,\nrendering the adversarial objective to entail a conflict. Our model has the\nform of a variational autoencoder, with a Gaussian mixture prior on the latent\nvector. Each mixture component of the prior distribution corresponds to one of\nthe classes in the data. This enables us to perform selective classification,\nleading to the rejection of adversarial samples instead of misclassification.\nOur method inherently provides a way of learning a selective classifier in a\nsemi-supervised scenario as well, which can resist adversarial attacks. We also\nshow how one can reclassify the rejected adversarial samples. \n\n"}
{"id": "1806.00139", "contents": "Title: Tokenized Data Markets Abstract: We formalize the construction of decentralized data markets by introducing\nthe mathematical construction of tokenized data structures, a new form of\nincentivized data structure. These structures both specialize and extend past\nwork on token curated registries and distributed data structures. They provide\na unified model for reasoning about complex data structures assembled by\nmultiple agents with differing incentives. We introduce a number of examples of\ntokenized data structures and introduce a simple mathematical framework for\nanalyzing their properties. We demonstrate how tokenized data structures can be\nused to instantiate a decentralized, tokenized data market, and conclude by\ndiscussing how such decentralized markets could prove fruitful for the further\ndevelopment of machine learning and AI. \n\n"}
{"id": "1806.01143", "contents": "Title: Securify: Practical Security Analysis of Smart Contracts Abstract: Permissionless blockchains allow the execution of arbitrary programs (called\nsmart contracts), enabling mutually untrusted entities to interact without\nrelying on trusted third parties. Despite their potential, repeated security\nconcerns have shaken the trust in handling billions of USD by smart contracts.\n  To address this problem, we present Securify, a security analyzer for\nEthereum smart contracts that is scalable, fully automated, and able to prove\ncontract behaviors as safe/unsafe with respect to a given property. Securify's\nanalysis consists of two steps. First, it symbolically analyzes the contract's\ndependency graph to extract precise semantic information from the code. Then,\nit checks compliance and violation patterns that capture sufficient conditions\nfor proving if a property holds or not. To enable extensibility, all patterns\nare specified in a designated domain-specific language.\n  Securify is publicly released, it has analyzed >18K contracts submitted by\nits users, and is regularly used to conduct security audits by experts. We\npresent an extensive evaluation of Securify over real-world Ethereum smart\ncontracts and demonstrate that it can effectively prove the correctness of\nsmart contracts and discover critical violations. \n\n"}
{"id": "1806.01246", "contents": "Title: ML-Leaks: Model and Data Independent Membership Inference Attacks and\n  Defenses on Machine Learning Models Abstract: Machine learning (ML) has become a core component of many real-world\napplications and training data is a key factor that drives current progress.\nThis huge success has led Internet companies to deploy machine learning as a\nservice (MLaaS). Recently, the first membership inference attack has shown that\nextraction of information on the training set is possible in such MLaaS\nsettings, which has severe security and privacy implications.\n  However, the early demonstrations of the feasibility of such attacks have\nmany assumptions on the adversary, such as using multiple so-called shadow\nmodels, knowledge of the target model structure, and having a dataset from the\nsame distribution as the target model's training data. We relax all these key\nassumptions, thereby showing that such attacks are very broadly applicable at\nlow cost and thereby pose a more severe risk than previously thought. We\npresent the most comprehensive study so far on this emerging and developing\nthreat using eight diverse datasets which show the viability of the proposed\nattacks across domains.\n  In addition, we propose the first effective defense mechanisms against such\nbroader class of membership inference attacks that maintain a high level of\nutility of the ML model. \n\n"}
{"id": "1806.01471", "contents": "Title: PAC-learning in the presence of evasion adversaries Abstract: The existence of evasion attacks during the test phase of machine learning\nalgorithms represents a significant challenge to both their deployment and\nunderstanding. These attacks can be carried out by adding imperceptible\nperturbations to inputs to generate adversarial examples and finding effective\ndefenses and detectors has proven to be difficult. In this paper, we step away\nfrom the attack-defense arms race and seek to understand the limits of what can\nbe learned in the presence of an evasion adversary. In particular, we extend\nthe Probably Approximately Correct (PAC)-learning framework to account for the\npresence of an adversary. We first define corrupted hypothesis classes which\narise from standard binary hypothesis classes in the presence of an evasion\nadversary and derive the Vapnik-Chervonenkis (VC)-dimension for these, denoted\nas the adversarial VC-dimension. We then show that sample complexity upper\nbounds from the Fundamental Theorem of Statistical learning can be extended to\nthe case of evasion adversaries, where the sample complexity is controlled by\nthe adversarial VC-dimension. We then explicitly derive the adversarial\nVC-dimension for halfspace classifiers in the presence of a sample-wise\nnorm-constrained adversary of the type commonly studied for evasion attacks and\nshow that it is the same as the standard VC-dimension, closing an open\nquestion. Finally, we prove that the adversarial VC-dimension can be either\nlarger or smaller than the standard VC-dimension depending on the hypothesis\nclass and adversary, making it an interesting object of study in its own right. \n\n"}
{"id": "1806.01994", "contents": "Title: Truth in Web Mining: Measuring the Profitability and Cost of\n  Cryptominers as a Web Monetization Model Abstract: The recent advances of web-based cryptomining libraries along with the\nwhopping market value of cryptocoins have convinced an increasing number of\npublishers to switch to web mining as a source of monetization for their\nwebsites. The conditions could not be better nowadays: the inevitable arms race\nbetween adblockers and advertisers is at its peak with publishers caught in the\ncrossfire. But, can cryptomining be the next primary monetization model in the\npost advertising era of free Internet? In this paper, we respond to this exact\nquestion. In particular, we compare the profitability of cryptomining and\nadvertising to assess the most advantageous option for a content provider. In\naddition, we measure the costs imposed to the user in each case with regards to\npower consumption, resources utilization, network traffic, device temperature\nand user experience. Our results show that cryptomining can surpass the\nprofitability of advertising under specific circumstances, however users need\nto sustain a significant cost on their devices. \n\n"}
{"id": "1806.02053", "contents": "Title: A Policy based Security Architecture for Software Defined Networks Abstract: As networks expand in size and complexity, they pose greater administrative\nand management challenges. Software Defined Networks (SDN) offer a promising\napproach to meeting some of these challenges. In this paper, we propose a\npolicy driven security architecture for securing end to end services across\nmultiple SDN domains. We develop a language based approach to design security\npolicies that are relevant for securing SDN services and communications. We\ndescribe the policy language and its use in specifying security policies to\ncontrol the flow of information in a multi-domain SDN. We demonstrate the\nspecification of fine grained security policies based on a variety of\nattributes such as parameters associated with users and devices/switches,\ncontext information such as location and routing information, and services\naccessed in SDN as well as security attributes associated with the switches and\nControllers in different domains. An important feature of our architecture is\nits ability to specify path and flow based security policies, which are\nsignificant for securing end to end services in SDNs. We describe the design\nand the implementation of our proposed policy based security architecture and\ndemonstrate its use in scenarios involving both intra and inter-domain\ncommunications with multiple SDN Controllers. We analyse the performance\ncharacteristics of our architecture as well as discuss how our architecture is\nable to counteract various security attacks. The dynamic security policy based\napproach and the distribution of corresponding security capabilities\nintelligently as a service layer that enable flow based security enforcement\nand protection of multitude of network devices against attacks are important\ncontributions of this paper. \n\n"}
{"id": "1806.02190", "contents": "Title: Mitigation of Policy Manipulation Attacks on Deep Q-Networks with\n  Parameter-Space Noise Abstract: Recent developments have established the vulnerability of deep reinforcement\nlearning to policy manipulation attacks via intentionally perturbed inputs,\nknown as adversarial examples. In this work, we propose a technique for\nmitigation of such attacks based on addition of noise to the parameter space of\ndeep reinforcement learners during training. We experimentally verify the\neffect of parameter-space noise in reducing the transferability of adversarial\nexamples, and demonstrate the promising performance of this technique in\nmitigating the impact of whitebox and blackbox attacks at both test and\ntraining times. \n\n"}
{"id": "1806.02246", "contents": "Title: Improving the Privacy and Accuracy of ADMM-Based Distributed Algorithms Abstract: Alternating direction method of multiplier (ADMM) is a popular method used to\ndesign distributed versions of a machine learning algorithm, whereby local\ncomputations are performed on local data with the output exchanged among\nneighbors in an iterative fashion. During this iterative process the leakage of\ndata privacy arises. A differentially private ADMM was proposed in prior work\n(Zhang & Zhu, 2017) where only the privacy loss of a single node during one\niteration was bounded, a method that makes it difficult to balance the tradeoff\nbetween the utility attained through distributed computation and privacy\nguarantees when considering the total privacy loss of all nodes over the entire\niterative process. We propose a perturbation method for ADMM where the\nperturbed term is correlated with the penalty parameters; this is shown to\nimprove the utility and privacy simultaneously. The method is based on a\nmodified ADMM where each node independently determines its own penalty\nparameter in every iteration and decouples it from the dual updating step size.\nThe condition for convergence of the modified ADMM and the lower bound on the\nconvergence rate are also derived. \n\n"}
{"id": "1806.02709", "contents": "Title: Secure Multilayer Perceptron Based On Homomorphic Encryption Abstract: In this work, we propose an outsourced Secure Multilayer Perceptron (SMLP)\nscheme where privacy and confidentiality of both the data and the model are\nensured during the training and the classification phases. More clearly, this\nSMLP : i) can be trained by a cloud server based on data previously outsourced\nby a user in an homomorphically encrypted form; ii) its parameters are\nhomomorphically encrypted giving thus no clues to the cloud; and iii) it can\nalso be used for classifying new encrypted data sent by the user returning him\nthe encrypted classification result encrypted. The originality of this scheme\nis threefold. To the best of our knowledge, it is the first multilayer\nperceptron (MLP) secured in its training phase over homomorphically encrypted\ndata with no problem of convergence. And It does not require\nextra-communications between the server and the user. It is based on the\nRectified Linear Unit (ReLU) activation function that we secure with no\napproximation contrarily to actual SMLP solutions. To do so, we take advantage\nof two semi-honest non-colluding servers. Experimental results carried out on a\nbinary database encrypted with the Paillier cryptosystem demonstrate the\noverall performance of our scheme and its convergence. \n\n"}
{"id": "1806.03108", "contents": "Title: Ergodic Mean-Payoff Games for the Analysis of Attacks in\n  Crypto-Currencies Abstract: Crypto-currencies are digital assets designed to work as a medium of\nexchange, e.g., Bitcoin, but they are susceptible to attacks (dishonest\nbehavior of participants). A framework for the analysis of attacks in\ncrypto-currencies requires (a) modeling of game-theoretic aspects to analyze\nincentives for deviation from honest behavior; (b) concurrent interactions\nbetween participants; and (c) analysis of long-term monetary gains. Traditional\ngame-theoretic approaches for the analysis of security protocols consider\neither qualitative temporal properties such as safety and termination, or the\nvery special class of one-shot (stateless) games. However, to analyze general\nattacks on protocols for crypto-currencies, both stateful analysis and\nquantitative objectives are necessary. In this work our main contributions are\nas follows: (a) we show how a class of concurrent mean-payoff games, namely\nergodic games, can model various attacks that arise naturally in\ncrypto-currencies; (b) we present the first practical implementation of\nalgorithms for ergodic games that scales to model realistic problems for\ncrypto-currencies; and (c) we present experimental results showing that our\nframework can handle games with thousands of states and millions of\ntransitions. \n\n"}
{"id": "1806.03281", "contents": "Title: Blind Justice: Fairness with Encrypted Sensitive Attributes Abstract: Recent work has explored how to train machine learning models which do not\ndiscriminate against any subgroup of the population as determined by sensitive\nattributes such as gender or race. To avoid disparate treatment, sensitive\nattributes should not be considered. On the other hand, in order to avoid\ndisparate impact, sensitive attributes must be examined, e.g., in order to\nlearn a fair model, or to check if a given model is fair. We introduce methods\nfrom secure multi-party computation which allow us to avoid both. By encrypting\nsensitive attributes, we show how an outcome-based fair model may be learned,\nchecked, or have its outputs verified and held to account, without users\nrevealing their sensitive attributes. \n\n"}
{"id": "1806.03287", "contents": "Title: Slalom: Fast, Verifiable and Private Execution of Neural Networks in\n  Trusted Hardware Abstract: As Machine Learning (ML) gets applied to security-critical or sensitive\ndomains, there is a growing need for integrity and privacy for outsourced ML\ncomputations. A pragmatic solution comes from Trusted Execution Environments\n(TEEs), which use hardware and software protections to isolate sensitive\ncomputations from the untrusted software stack. However, these isolation\nguarantees come at a price in performance, compared to untrusted alternatives.\nThis paper initiates the study of high performance execution of Deep Neural\nNetworks (DNNs) in TEEs by efficiently partitioning DNN computations between\ntrusted and untrusted devices. Building upon an efficient outsourcing scheme\nfor matrix multiplication, we propose Slalom, a framework that securely\ndelegates execution of all linear layers in a DNN from a TEE (e.g., Intel SGX\nor Sanctum) to a faster, yet untrusted, co-located processor. We evaluate\nSlalom by running DNNs in an Intel SGX enclave, which selectively delegates\nwork to an untrusted GPU. For canonical DNNs (VGG16, MobileNet and ResNet\nvariants) we obtain 6x to 20x increases in throughput for verifiable inference,\nand 4x to 11x for verifiable and private inference. \n\n"}
{"id": "1806.03461", "contents": "Title: TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service Abstract: Machine learning methods are widely used for a variety of prediction\nproblems. \\emph{Prediction as a service} is a paradigm in which service\nproviders with technological expertise and computational resources may perform\npredictions for clients. However, data privacy severely restricts the\napplicability of such services, unless measures to keep client data private\n(even from the service provider) are designed. Equally important is to minimize\nthe amount of computation and communication required between client and server.\nFully homomorphic encryption offers a possible way out, whereby clients may\nencrypt their data, and on which the server may perform arithmetic\ncomputations. The main drawback of using fully homomorphic encryption is the\namount of time required to evaluate large machine learning models on encrypted\ndata. We combine ideas from the machine learning literature, particularly work\non binarization and sparsification of neural networks, together with\nalgorithmic tools to speed-up and parallelize computation using encrypted data. \n\n"}
{"id": "1806.04847", "contents": "Title: Android Malware Detection using Large-scale Network Representation\n  Learning Abstract: With the growth of mobile devices and applications, the number of malicious\nsoftware, or malware, is rapidly increasing in recent years, which calls for\nthe development of advanced and effective malware detection approaches.\nTraditional methods such as signature-based ones cannot defend users from an\nincreasing number of new types of malware or rapid malware behavior changes. In\nthis paper, we propose a new Android malware detection approach based on deep\nlearning and static analysis. Instead of using Application Programming\nInterfaces (APIs) only, we further analyze the source code of Android\napplications and create their higher-level graphical semantics, which makes it\nharder for attackers to evade detection. In particular, we use a call graph\nfrom method invocations in an Android application to represent the application,\nand further analyze method attributes to form a structured Program\nRepresentation Graph (PRG) with node attributes. Then, we use a graph\nconvolutional network (GCN) to yield a graph representation of the application\nby embedding the entire graph into a dense vector, and classify whether it is a\nmalware or not. To efficiently train such a graph convolutional network, we\npropose a batch training scheme that allows multiple heterogeneous graphs to be\ninput as a batch. To the best of our knowledge, this is the first work to use\ngraph representation learning for malware detection. We conduct extensive\nexperiments from real-world sample collections and demonstrate that our\ndeveloped system outperforms multiple other existing malware detection\ntechniques. \n\n"}
{"id": "1806.04935", "contents": "Title: Convolutional sparse coding for capturing high speed video content Abstract: Video capture is limited by the trade-off between spatial and temporal\nresolution: when capturing videos of high temporal resolution, the spatial\nresolution decreases due to bandwidth limitations in the capture system.\nAchieving both high spatial and temporal resolution is only possible with\nhighly specialized and very expensive hardware, and even then the same basic\ntrade-off remains. The recent introduction of compressive sensing and sparse\nreconstruction techniques allows for the capture of single-shot high-speed\nvideo, by coding the temporal information in a single frame, and then\nreconstructing the full video sequence from this single coded image and a\ntrained dictionary of image patches. In this paper, we first analyze this\napproach, and find insights that help improve the quality of the reconstructed\nvideos. We then introduce a novel technique, based on convolutional sparse\ncoding (CSC), and show how it outperforms the state-of-the-art, patch-based\napproach in terms of flexibility and efficiency, due to the convolutional\nnature of its filter banks. The key idea for CSC high-speed video acquisition\nis extending the basic formulation by imposing an additional constraint in the\ntemporal dimension, which enforces sparsity of the first-order derivatives over\ntime. \n\n"}
{"id": "1806.05233", "contents": "Title: End-to-End Parkinson Disease Diagnosis using Brain MR-Images by 3D-CNN Abstract: In this work, we use a deep learning framework for simultaneous\nclassification and regression of Parkinson disease diagnosis based on MR-Images\nand personal information (i.e. age, gender). We intend to facilitate and\nincrease the confidence in Parkinson disease diagnosis through our deep\nlearning framework. \n\n"}
{"id": "1806.05768", "contents": "Title: Hardware Trojan Attacks on Neural Networks Abstract: With the rising popularity of machine learning and the ever increasing demand\nfor computational power, there is a growing need for hardware optimized\nimplementations of neural networks and other machine learning models. As the\ntechnology evolves, it is also plausible that machine learning or artificial\nintelligence will soon become consumer electronic products and military\nequipment, in the form of well-trained models. Unfortunately, the modern\nfabless business model of manufacturing hardware, while economic, leads to\ndeficiencies in security through the supply chain. In this paper, we illuminate\nthese security issues by introducing hardware Trojan attacks on neural\nnetworks, expanding the current taxonomy of neural network security to\nincorporate attacks of this nature. To aid in this, we develop a novel\nframework for inserting malicious hardware Trojans in the implementation of a\nneural network classifier. We evaluate the capabilities of the adversary in\nthis setting by implementing the attack algorithm on convolutional neural\nnetworks while controlling a variety of parameters available to the adversary.\nOur experimental results show that the proposed algorithm could effectively\nclassify a selected input trigger as a specified class on the MNIST dataset by\ninjecting hardware Trojans into $0.03\\%$, on average, of neurons in the 5th\nhidden layer of arbitrary 7-layer convolutional neural networks, while\nundetectable under the test data. Finally, we discuss the potential defenses to\nprotect neural networks against hardware Trojan attacks. \n\n"}
{"id": "1806.06169", "contents": "Title: B-FICA: BlockChain based Framework for Auto-insurance Claim and\n  Adjudication Abstract: In this paper, we propose a partitioned BlockChain based Framework for\nAuto-insurance Claims and Adjudication (B-FICA) for CAVs that tracks both\nsensor data and entity interactions with two-sided verification. B-FICA uses\npermissioned BC with two partitions to share information on a need to know\nbasis. It also uses multi-signed transactions for proof of execution of\ninstructions, for reliability and auditability and also uses a dynamic\nlightweight consensus and validation protocol to prevent evidence alteration.\nQualitative evaluation shows that B-FICA is resilient to several security\nattacks from potential liable entities. Finally, simulations show that compared\nto the state of the art, B-FICA reduces processing time and its delay overhead\nis negligible for practical scenarios and at marginal security cost. \n\n"}
{"id": "1806.06427", "contents": "Title: Property Testing for Differential Privacy Abstract: We consider the problem of property testing for differential privacy: with\nblack-box access to a purportedly private algorithm, can we verify its privacy\nguarantees? In particular, we show that any privacy guarantee that can be\nefficiently verified is also efficiently breakable in the sense that there\nexist two databases between which we can efficiently distinguish. We give lower\nbounds on the query complexity of verifying pure differential privacy,\napproximate differential privacy, random pure differential privacy, and random\napproximate differential privacy. We also give algorithmic upper bounds. The\nlower bounds obtained in the work are infeasible for the scale of parameters\nthat are typically considered reasonable in the differential privacy\nliterature, even when we suppose that the verifier has access to an (untrusted)\ndescription of the algorithm. A central message of this work is that verifying\nprivacy requires compromise by either the verifier or the algorithm owner.\nEither the verifier has to be satisfied with a weak privacy guarantee, or the\nalgorithm owner has to compromise on side information or access to the\nalgorithm. \n\n"}
{"id": "1806.06881", "contents": "Title: CryptoGuard: High Precision Detection of Cryptographic Vulnerabilities\n  in Massive-sized Java Projects Abstract: Cryptographic API misuses, such as exposed secrets, predictable random\nnumbers, and vulnerable certificate verification, seriously threaten software\nsecurity. The vision of automatically screening cryptographic API calls in\nmassive-sized (e.g., millions of LoC) Java programs is not new. However,\nhindered by the practical difficulty of reducing false positives without\ncompromising analysis quality, this goal has not been accomplished.\nState-of-the-art crypto API screening solutions are not designed to operate on\na large scale.\n  Our technical innovation is a set of fast and highly accurate slicing\nalgorithms. Our algorithms refine program slices by identifying\nlanguage-specific irrelevant elements. The refinements reduce false alerts by\n76% to 80% in our experiments. Running our tool, CrytoGuard, on 46 high-impact\nlarge-scale Apache projects and 6,181 Android apps generate many security\ninsights. Our findings helped multiple popular Apache projects to harden their\ncode, including Spark, Ranger, and Ofbiz. We also have made substantial\nprogress towards the science of analysis in this space, including: i) manually\nanalyzing 1,295 Apache alerts and confirming 1,277 true positives (98.61%\nprecision), ii) creating a benchmark with 38-unit basic cases and 74-unit\nadvanced cases, iii) performing an in-depth comparison with leading solutions\nincluding CrySL, SpotBugs, and Coverity. We are in the process of integrating\nCryptoGuard with the Software Assurance Marketplace (SWAMP). \n\n"}
{"id": "1806.07534", "contents": "Title: Crowdsensing and privacy in smart city applications Abstract: Smartness in smart cities is achieved by sensing phenomena of interest and\nusing them to make smart decisions. Since the decision makers may not own all\nthe necessary sensing infrastructures, crowdsourced sensing, can help collect\nimportant information of the city in near real-time. However, involving people\nbrings of the risk of exposing their private information.This chapter explores\ncrowdsensing in smart city applications and its privacy implications. \n\n"}
{"id": "1806.07723", "contents": "Title: Combinatorial Testing for Deep Learning Systems Abstract: Deep learning (DL) has achieved remarkable progress over the past decade and\nbeen widely applied to many safety-critical applications. However, the\nrobustness of DL systems recently receives great concerns, such as adversarial\nexamples against computer vision systems, which could potentially result in\nsevere consequences. Adopting testing techniques could help to evaluate the\nrobustness of a DL system and therefore detect vulnerabilities at an early\nstage. The main challenge of testing such systems is that its runtime state\nspace is too large: if we view each neuron as a runtime state for DL, then a DL\nsystem often contains massive states, rendering testing each state almost\nimpossible. For traditional software, combinatorial testing (CT) is an\neffective testing technique to reduce the testing space while obtaining\nrelatively high defect detection abilities. In this paper, we perform an\nexploratory study of CT on DL systems. We adapt the concept in CT and propose a\nset of coverage criteria for DL systems, as well as a CT coverage guided test\ngeneration technique. Our evaluation demonstrates that CT provides a promising\navenue for testing DL systems. We further pose several open questions and\ninteresting directions for combinatorial testing of DL systems. \n\n"}
{"id": "1806.08941", "contents": "Title: A Recursive PLS (Partial Least Squares) based Approach for Enterprise\n  Threat Management Abstract: Most of the existing solutions to enterprise threat management are preventive\napproaches prescribing means to prevent policy violations with varying degrees\nof success. In this paper we consider the complementary scenario where a number\nof security violations have already occurred, or security threats, or\nvulnerabilities have been reported and a security administrator needs to\ngenerate optimal response to these security events. We present a principled\napproach to study and model the human expertise in responding to the emergent\nthreats owing to these security events. A recursive Partial Least Squares based\nadaptive learning model is defined using a factorial analysis of the security\nevents together with a method for estimating the effect of global context\ndependent semantic information used by the security administrators. Presented\nmodel is theoretically optimal and operationally recursive in nature to deal\nwith the set of security events being generated continuously. We discuss the\nunderlying challenges and ways in which the model could be operationalized in\ncentralized versus decentralized, and real-time versus batch processing modes. \n\n"}
{"id": "1806.09035", "contents": "Title: Defending Malware Classification Networks Against Adversarial\n  Perturbations with Non-Negative Weight Restrictions Abstract: There is a growing body of literature showing that deep neural networks are\nvulnerable to adversarial input modification. Recently this work has been\nextended from image classification to malware classification over boolean\nfeatures. In this paper we present several new methods for training restricted\nnetworks in this specific domain that are highly effective at preventing\nadversarial perturbations. We start with a fully adversarially resistant neural\nnetwork that has hard non-negative weight restrictions and is equivalent to\nlearning a monotonic boolean function and then attempt to relax the constraints\nto improve classifier accuracy. \n\n"}
{"id": "1806.10055", "contents": "Title: Twisted Gabidulin Codes in the GPT Cryptosystem Abstract: In this paper, we investigate twisted Gabidulin codes in the GPT code-based\npublic-key cryptosystem. We show that Overbeck's attack is not feasible for a\nsubfamily of twisted Gabidulin codes. The resulting key sizes are significantly\nlower than in the original McEliece system and also slightly smaller than in\nLoidreau's unbroken GPT variant. \n\n"}
{"id": "1806.10313", "contents": "Title: DeepObfuscation: Securing the Structure of Convolutional Neural Networks\n  via Knowledge Distillation Abstract: This paper investigates the piracy problem of deep learning models. Designing\nand training a well-performing model is generally expensive. However, when\nreleasing them, attackers may reverse engineer the models and pirate their\ndesign. This paper, therefore, proposes deep learning obfuscation, aiming at\nobstructing attackers from pirating a deep learning model. In particular, we\nfocus on obfuscating convolutional neural networks (CNN), a widely employed\ntype of deep learning architectures for image recognition. Our approach\nobfuscates a CNN model eventually by simulating its feature extractor with a\nshallow and sequential convolutional block. To this end, we employ a recursive\nsimulation method and a joint training method to train the simulation network.\nThe joint training method leverages both the intermediate knowledge generated\nby a feature extractor and data labels to train a simulation network. In this\nway, we can obtain an obfuscated model without accuracy loss. We have verified\nthe feasibility of our approach with three prevalent CNNs, i.e., GoogLeNet,\nResNet, and DenseNet. Although these networks are very deep with tens or\nhundreds of layers, we can simulate them in a shallow network including only\nfive or seven convolutional layers. The obfuscated models are even more\nefficient than the original models. Our obfuscation approach is very effective\nto protect the critical structure of a deep learning model from being exposed\nto attackers. Moreover, it can also thwart attackers from pirating the model\nwith transfer learning or incremental learning techniques because the shallow\nsimulation network bears poor learning ability. To our best knowledge, this\npaper serves as a first attempt to obfuscate deep learning models, which may\nshed light on more future studies. \n\n"}
{"id": "1806.10496", "contents": "Title: Customizing an Adversarial Example Generator with Class-Conditional GANs Abstract: Adversarial examples are intentionally crafted data with the purpose of\ndeceiving neural networks into misclassification. When we talk about strategies\nto create such examples, we usually refer to perturbation-based methods that\nfabricate adversarial examples by applying invisible perturbations onto normal\ndata. The resulting data reserve their visual appearance to human observers,\nyet can be totally unrecognizable to DNN models, which in turn leads to\ncompletely misleading predictions. In this paper, however, we consider crafting\nadversarial examples from existing data as a limitation to example diversity.\nWe propose a non-perturbation-based framework that generates native adversarial\nexamples from class-conditional generative adversarial networks.As such, the\ngenerated data will not resemble any existing data and thus expand example\ndiversity, raising the difficulty in adversarial defense. We then extend this\nframework to pre-trained conditional GANs, in which we turn an existing\ngenerator into an \"adversarial-example generator\". We conduct experiments on\nour approach for MNIST and CIFAR10 datasets and have satisfactory results,\nshowing that this approach can be a potential alternative to previous attack\nstrategies. \n\n"}
{"id": "1806.10741", "contents": "Title: Robust Neural Malware Detection Models for Emulation Sequence Learning Abstract: Malicious software, or malware, presents a continuously evolving challenge in\ncomputer security. These embedded snippets of code in the form of malicious\nfiles or hidden within legitimate files cause a major risk to systems with\ntheir ability to run malicious command sequences. Malware authors even use\npolymorphism to reorder these commands and create several malicious variations.\nHowever, if executed in a secure environment, one can perform early malware\ndetection on emulated command sequences.\n  The models presented in this paper leverage this sequential data derived via\nemulation in order to perform Neural Malware Detection. These models target the\ncore of the malicious operation by learning the presence and pattern of\nco-occurrence of malicious event actions from within these sequences. Our\nmodels can capture entire event sequences and be trained directly using the\nknown target labels. These end-to-end learning models are powered by two\ncommonly used structures - Long Short-Term Memory (LSTM) Networks and\nConvolutional Neural Networks (CNNs). Previously proposed sequential malware\nclassification models process no more than 200 events. Attackers can evade\ndetection by delaying any malicious activity beyond the beginning of the file.\nWe present specialized models that can handle extremely long sequences while\nsuccessfully performing malware detection in an efficient way. We present an\nimplementation of the Convoluted Partitioning of Long Sequences approach in\norder to tackle this vulnerability and operate on long sequences. We present\nour results on a large dataset consisting of 634,249 file sequences, with\nextremely long file sequences. \n\n"}
{"id": "1806.10781", "contents": "Title: Accurate and efficient video de-fencing using convolutional neural\n  networks and temporal information Abstract: De-fencing is to eliminate the captured fence on an image or a video,\nproviding a clear view of the scene. It has been applied for many purposes\nincluding assisting photographers and improving the performance of computer\nvision algorithms such as object detection and recognition. However, the\nstate-of-the-art de-fencing methods have limited performance caused by the\ndifficulty of fence segmentation and also suffer from the motion of the camera\nor objects. To overcome these problems, we propose a novel method consisting of\nsegmentation using convolutional neural networks and a fast/robust recovery\nalgorithm. The segmentation algorithm using convolutional neural network\nachieves significant improvement in the accuracy of fence segmentation. The\nrecovery algorithm using optical flow produces plausible de-fenced images and\nvideos. The proposed method is experimented on both our diverse and complex\ndataset and publicly available datasets. The experimental results demonstrate\nthat the proposed method achieves the state-of-the-art performance for both\nsegmentation and content recovery. \n\n"}
{"id": "1806.10883", "contents": "Title: Securing the Storage Data Path with SGX Enclaves Abstract: We explore the use of SGX enclaves as a means to improve the security of\nhandling keys and data in storage systems. We study two main configurations for\nSGX computations, as they apply to performing data-at-rest encryption in a\nstorage system. The first configuration aims to protect the encryption keys\nused in the encryption process. The second configuration aims to protect both\nthe encryption keys and the data, thus providing end-to-end security of the\nentire data path.\n  Our main contribution is an evaluation of the viability of SGX for\ndata-at-rest encryption from a performance perspective and an understanding of\nthe details that go into using enclaves in a performance sensitive environment.\nOur tests paint a complex picture: On the one hand SGX can indeed achieve high\nencryption and decryption throughput, comparable to running without SGX. On the\nother hand, there are many subtleties to achieving such performance and careful\ndesign choices and testing are required. \n\n"}
{"id": "1806.10929", "contents": "Title: When Can a Distributed Ledger Replace a Trusted Third Party? Abstract: The functionality that distributed ledger technology provides, i.e., an\nimmutable and fraud-resistant registry with validation and verification\nmechanisms, has traditionally been implemented with a trusted third party. Due\nto the distributed nature of ledger technology, there is a strong recent trend\ntowards using ledgers to implement novel decentralized applications for a wide\nrange of use cases, e.g., in the financial sector and sharing economy. While\nthere can be several arguments for the use of a ledger, the key question is\nwhether it can fully replace any single trusted party in the system as\notherwise a (potentially simpler) solution can be built around the trusted\nparty. In this paper, we introduce an abstract view on ledger use cases and\npresent two fundamental criteria that must be met for any use case to be\nimplemented using a ledger-based approach without having to rely on any\nparticular party in the system. Moreover, we evaluate several ledger use cases\nthat have recently received considerable attention according to these criteria,\nrevealing that often participants need to trust each other despite using a\ndistributed ledger. Consequently, the potential of using a ledger as a\nreplacement for a trusted party is limited for these use cases. \n\n"}
{"id": "1806.11146", "contents": "Title: Adversarial Reprogramming of Neural Networks Abstract: Deep neural networks are susceptible to \\emph{adversarial} attacks. In\ncomputer vision, well-crafted perturbations to images can cause neural networks\nto make mistakes such as confusing a cat with a computer. Previous adversarial\nattacks have been designed to degrade performance of models or cause machine\nlearning models to produce specific outputs chosen ahead of time by the\nattacker. We introduce attacks that instead {\\em reprogram} the target model to\nperform a task chosen by the attacker---without the attacker needing to specify\nor compute the desired output for each test-time input. This attack finds a\nsingle adversarial perturbation, that can be added to all test-time inputs to a\nmachine learning model in order to cause the model to perform a task chosen by\nthe adversary---even if the model was not trained to do this task. These\nperturbations can thus be considered a program for the new task. We demonstrate\nadversarial reprogramming on six ImageNet classification models, repurposing\nthese models to perform a counting task, as well as classification tasks:\nclassification of MNIST and CIFAR-10 examples presented as inputs to the\nImageNet model. \n\n"}
{"id": "1807.00459", "contents": "Title: How To Backdoor Federated Learning Abstract: Federated learning enables thousands of participants to construct a deep\nlearning model without sharing their private training data with each other. For\nexample, multiple smartphones can jointly train a next-word predictor for\nkeyboards without revealing what individual users type. We demonstrate that any\nparticipant in federated learning can introduce hidden backdoor functionality\ninto the joint global model, e.g., to ensure that an image classifier assigns\nan attacker-chosen label to images with certain features, or that a word\npredictor completes certain sentences with an attacker-chosen word.\n  We design and evaluate a new model-poisoning methodology based on model\nreplacement. An attacker selected in a single round of federated learning can\ncause the global model to immediately reach 100% accuracy on the backdoor task.\nWe evaluate the attack under different assumptions for the standard\nfederated-learning tasks and show that it greatly outperforms data poisoning.\nOur generic constrain-and-scale technique also evades anomaly detection-based\ndefenses by incorporating the evasion into the attacker's loss function during\ntraining. \n\n"}
{"id": "1807.00482", "contents": "Title: Tap-based User Authentication for Smartwatches Abstract: This paper presents TapMeIn, an eyes-free, two-factor authentication method\nfor smartwatches. It allows users to tap a memorable melody (tap-password) of\ntheir choice anywhere on the touchscreen to unlock their watch. A user is\nverified based on the tap-password as well as her physiological and behavioral\ncharacteristics when tapping. Results from preliminary experiments with 41\nparticipants show that TapMeIn could achieve an accuracy of 98.7% with a False\nPositive Rate of only 0.98%. In addition, TapMeIn retains its performance in\ndifferent conditions such as sitting and walking. In terms of speed, TapMeIn\nhas an average authentication time of 2 seconds. A user study with the System\nUsability Scale (SUS) tool suggests that TapMeIn has a high usability score. \n\n"}
{"id": "1807.00752", "contents": "Title: Waveform to Single Sinusoid Regression to Estimate the F0 Contour from\n  Noisy Speech Using Recurrent Deep Neural Networks Abstract: The fundamental frequency (F0) represents pitch in speech that determines\nprosodic characteristics of speech and is needed in various tasks for speech\nanalysis and synthesis. Despite decades of research on this topic, F0\nestimation at low signal-to-noise ratios (SNRs) in unexpected noise conditions\nremains difficult. This work proposes a new approach to noise robust F0\nestimation using a recurrent neural network (RNN) trained in a supervised\nmanner. Recent studies employ deep neural networks (DNNs) for F0 tracking as a\nframe-by-frame classification task into quantised frequency states but we\npropose waveform-to-sinusoid regression instead to achieve both noise\nrobustness and accurate estimation with increased frequency resolution.\n  Experimental results with PTDB-TUG corpus contaminated by additive noise\n(NOISEX-92) demonstrate that the proposed method improves gross pitch error\n(GPE) rate and fine pitch error (FPE) by more than 35 % at SNRs between -10 dB\nand +10 dB compared with well-known noise robust F0 tracker, PEFAC.\nFurthermore, the proposed method also outperforms state-of-the-art DNN-based\napproaches by more than 15 % in terms of both FPE and GPE rate over the\npreceding SNR range. \n\n"}
{"id": "1807.00969", "contents": "Title: Confidential Inference via Ternary Model Partitioning Abstract: Today's cloud vendors are competing to provide various offerings to simplify\nand accelerate AI service deployment. However, cloud users always have concerns\nabout the confidentiality of their runtime data, which are supposed to be\nprocessed on third-party's compute infrastructures. Information disclosure of\nuser-supplied data may jeopardize users' privacy and breach increasingly\nstringent data protection regulations. In this paper, we systematically\ninvestigate the life cycles of inference inputs in deep learning image\nclassification pipelines and understand how the information could be leaked.\nBased on the discovered insights, we develop a Ternary Model Partitioning\nmechanism and bring trusted execution environments to mitigate the identified\ninformation leakages. Our research prototype consists of two co-operative\ncomponents: (1) Model Assessment Framework, a local model evaluation and\npartitioning tool that assists cloud users in deployment preparation; (2)\nInfenclave, an enclave-based model serving system for online confidential\ninference in the cloud. We have conducted comprehensive security and\nperformance evaluation on three representative ImageNet-level deep learning\nmodels with different network depths and architectural complexity. Our results\ndemonstrate the feasibility of launching confidential inference services in the\ncloud with maximized confidentiality guarantees and low performance costs. \n\n"}
{"id": "1807.01276", "contents": "Title: A non-convex approach to low-rank and sparse matrix decomposition Abstract: In this paper, we develop a nonconvex approach to the problem of low-rank and\nsparse matrix decomposition. In our nonconvex method, we replace the rank\nfunction and the $l_{0}$-norm of a given matrix with a non-convex fraction\nfunction on the singular values and the elements of the matrix respectively. An\nalternative direction method of multipliers algorithm is utilized to solve our\nproposed nonconvex problem with the nonconvex fraction function penalty.\nNumerical experiments on some low-rank and sparse matrix decomposition problems\nshow that our method performs very well in recovering low-rank matrices which\nare heavily corrupted by large sparse errors. \n\n"}
{"id": "1807.01462", "contents": "Title: Video Frame Interpolation by Plug-and-Play Deep Locally Linear Embedding Abstract: We propose a generative framework which takes on the video frame\ninterpolation problem. Our framework, which we call Deep Locally Linear\nEmbedding (DeepLLE), is powered by a deep convolutional neural network (CNN)\nwhile it can be used instantly like conventional models. DeepLLE fits an\nauto-encoding CNN to a set of several consecutive frames and embeds a linearity\nconstraint on the latent codes so that new frames can be generated by\ninterpolating new latent codes. Different from the current deep learning\nparadigm which requires training on large datasets, DeepLLE works in a\nplug-and-play and unsupervised manner, and is able to generate an arbitrary\nnumber of frames. Thorough experiments demonstrate that without bells and\nwhistles, our method is highly competitive among current state-of-the-art\nmodels. \n\n"}
{"id": "1807.01647", "contents": "Title: Privacy Amplification by Subsampling: Tight Analyses via Couplings and\n  Divergences Abstract: Differential privacy comes equipped with multiple analytical tools for the\ndesign of private data analyses. One important tool is the so-called \"privacy\namplification by subsampling\" principle, which ensures that a differentially\nprivate mechanism run on a random subsample of a population provides higher\nprivacy guarantees than when run on the entire population. Several instances of\nthis principle have been studied for different random subsampling methods, each\nwith an ad-hoc analysis. In this paper we present a general method that\nrecovers and improves prior analyses, yields lower bounds and derives new\ninstances of privacy amplification by subsampling. Our method leverages a\ncharacterization of differential privacy as a divergence which emerged in the\nprogram verification community. Furthermore, it introduces new tools, including\nadvanced joint convexity and privacy profiles, which might be of independent\ninterest. \n\n"}
{"id": "1807.01860", "contents": "Title: Privacy-preserving Machine Learning through Data Obfuscation Abstract: As machine learning becomes a practice and commodity, numerous cloud-based\nservices and frameworks are provided to help customers develop and deploy\nmachine learning applications. While it is prevalent to outsource model\ntraining and serving tasks in the cloud, it is important to protect the privacy\nof sensitive samples in the training dataset and prevent information leakage to\nuntrusted third parties. Past work have shown that a malicious machine learning\nservice provider or end user can easily extract critical information about the\ntraining samples, from the model parameters or even just model outputs.\n  In this paper, we propose a novel and generic methodology to preserve the\nprivacy of training data in machine learning applications. Specifically we\nintroduce an obfuscate function and apply it to the training data before\nfeeding them to the model training task. This function adds random noise to\nexisting samples, or augments the dataset with new samples. By doing so\nsensitive information about the properties of individual samples, or\nstatistical properties of a group of samples, is hidden. Meanwhile the model\ntrained from the obfuscated dataset can still achieve high accuracy. With this\napproach, the customers can safely disclose the data or models to third-party\nproviders or end users without the need to worry about data privacy. Our\nexperiments show that this approach can effective defeat four existing types of\nmachine learning privacy attacks at negligible accuracy cost. \n\n"}
{"id": "1807.03227", "contents": "Title: FHIRChain: Applying Blockchain to Securely and Scalably Share Clinical\n  Data Abstract: Secure and scalable data sharing is essential for collaborative clinical\ndecision making. Conventional clinical data efforts are often siloed, however,\nwhich creates barriers to efficient information exchange and impedes effective\ntreatment decision made for patients. This paper provides four contributions to\nthe study of applying blockchain technology to clinical data sharing in the\ncontext of technical requirements defined in the \"Shared Nationwide\nInteroperability Roadmap\" from the Office of the National Coordinator for\nHealth Information Technology (ONC). First, we analyze the ONC requirements and\ntheir implications for blockchain-based systems. Second, we present FHIRChain,\nwhich is a blockchain-based architecture designed to meet ONC requirements by\nencapsulating the HL7 Fast Healthcare Interoperability Resources (FHIR)\nstandard for shared clinical data. Third, we demonstrate a FHIRChain-based\ndecentralized app using digital health identities to authenticate participants\nin a case study of collaborative decision making for remote cancer care.\nFourth, we highlight key lessons learned from our case study. \n\n"}
{"id": "1807.03343", "contents": "Title: Complex Fully Convolutional Neural Networks for MR Image Reconstruction Abstract: Undersampling the k-space data is widely adopted for acceleration of Magnetic\nResonance Imaging (MRI). Current deep learning based approaches for supervised\nlearning of MRI image reconstruction employ real-valued operations and\nrepresentations by treating complex valued k-space/spatial-space as real\nvalues. In this paper, we propose complex dense fully convolutional neural\nnetwork ($\\mathbb{C}$DFNet) for learning to de-alias the reconstruction\nartifacts within undersampled MRI images. We fashioned a densely-connected\nfully convolutional block tailored for complex-valued inputs by introducing\ndedicated layers such as complex convolution, batch normalization,\nnon-linearities etc. $\\mathbb{C}$DFNet leverages the inherently complex-valued\nnature of input k-space and learns richer representations. We demonstrate\nimproved perceptual quality and recovery of anatomical structures through\n$\\mathbb{C}$DFNet in contrast to its real-valued counterparts. \n\n"}
{"id": "1807.03757", "contents": "Title: Speculative Buffer Overflows: Attacks and Defenses Abstract: Practical attacks that exploit speculative execution can leak confidential\ninformation via microarchitectural side channels. The recently-demonstrated\nSpectre attacks leverage speculative loads which circumvent access checks to\nread memory-resident secrets, transmitting them to an attacker using cache\ntiming or other covert communication channels.\n  We introduce Spectre1.1, a new Spectre-v1 variant that leverages speculative\nstores to create speculative buffer overflows. Much like classic buffer\noverflows, speculative out-of-bounds stores can modify data and code pointers.\nData-value attacks can bypass some Spectre-v1 mitigations, either directly or\nby redirecting control flow. Control-flow attacks enable arbitrary speculative\ncode execution, which can bypass fence instructions and all other software\nmitigations for previous speculative-execution attacks. It is easy to construct\nreturn-oriented-programming (ROP) gadgets that can be used to build alternative\nattack payloads.\n  We also present Spectre1.2: on CPUs that do not enforce read/write\nprotections, speculative stores can overwrite read-only data and code pointers\nto breach sandboxes.\n  We highlight new risks posed by these vulnerabilities, discuss possible\nsoftware mitigations, and sketch microarchitectural mechanisms that could serve\nas hardware defenses. We have not yet evaluated the performance impact of our\nproposed software and hardware mitigations. We describe the salient\nvulnerability features and additional hypothetical attack scenarios only to the\ndetail necessary to guide hardware and software vendors in threat analysis and\nmitigations. We advise users to refer to more user-friendly vendor\nrecommendations for mitigations against speculative buffer overflows or\navailable patches. \n\n"}
{"id": "1807.04739", "contents": "Title: When deep learning meets security Abstract: Deep learning is an emerging research field that has proven its effectiveness\ntowards deploying more efficient intelligent systems. Security, on the other\nhand, is one of the most essential issues in modern communication systems.\nRecently many papers have shown that using deep learning models can achieve\npromising results when applied to the security domain. In this work, we provide\nan overview for the recent studies that apply deep learning techniques to the\nfield of security. \n\n"}
{"id": "1807.06179", "contents": "Title: Real-Time Index Authentication for Event-Oriented Surveillance Video\n  Query using Blockchain Abstract: Information from surveillance video is essential for situational awareness\n(SAW). Nowadays, a prohibitively large amount of surveillance data is being\ngenerated continuously by ubiquitously distributed video sensors. It is very\nchallenging to immediately identify the objects of interest or zoom in\nsuspicious actions from thousands of video frames. Making the big data\nindexable is critical to tackle this problem. It is ideal to generate pattern\nindexes in a real-time, on-site manner on the video streaming instead of\ndepending on the batch processing at the cloud centers. The modern\nedge-fog-cloud computing paradigm allows implementation of time sensitive tasks\nat the edge of the network. The on-site edge devices collect the information\nsensed in format of frames and extracts useful features. The near-site fog\nnodes conduct the contextualization and classification of the features. The\nremote cloud center is in charge of more data intensive and computing intensive\ntasks. However, exchanging the index information among devices in different\nlayers raises security concerns where an adversary can capture or tamper with\nfeatures to mislead the surveillance system. In this paper, a blockchain\nenabled scheme is proposed to protect the index data through an encrypted\nsecure channel between the edge and fog nodes. It reduces the chance of attacks\non the small edge and fog devices. The feasibility of the proposal is validated\nthrough intensive experimental analysis. \n\n"}
{"id": "1807.07978", "contents": "Title: Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors Abstract: We study the problem of generating adversarial examples in a black-box\nsetting in which only loss-oracle access to a model is available. We introduce\na framework that conceptually unifies much of the existing work on black-box\nattacks, and we demonstrate that the current state-of-the-art methods are\noptimal in a natural sense. Despite this optimality, we show how to improve\nblack-box attacks by bringing a new element into the problem: gradient priors.\nWe give a bandit optimization-based algorithm that allows us to seamlessly\nintegrate any such priors, and we explicitly identify and incorporate two\nexamples. The resulting methods use two to four times fewer queries and fail\ntwo to five times less often than the current state-of-the-art. \n\n"}
{"id": "1807.08613", "contents": "Title: Restructuring of Discrete Logarithm Problem and ElGamal Cryptosystem by\n  Using the Power Fibonacci Sequence Module M Abstract: In this paper, we have studied on adapting to asymmetric cryptography power\nFibonacci sequence module m . To do this, We have restructed Discreate\nLogarithm Problem which is one of mathematical difficult problems by using\npower Fibonacci sequence module m and by means of this sequences, we have made\nthe mathematical difficult problem which is used only in prime modules is also\nuseful for composite modules. Then we have constructed cryptographic system\nbased on this more difficult problem which we have rearranged. Hence, we have\nobtained a new cryptosystem as ElGamal Cryptosystem. Lastly, we have compared\nthat ElGamal Cryptosystem and a new cryptosystem which we constitute in terms\nof cryptography and we have obtained that a new cryptosystem is more\nadvantageuos than ElGamal Cryptosystem. \n\n"}
{"id": "1807.08644", "contents": "Title: Atomic Swaptions: Cryptocurrency Derivatives Abstract: The atomic swap protocol allows for the exchange of cryptocurrencies on\ndifferent blockchains without the need to trust a third-party. However, market\nparticipants who desire to hold derivative assets such as options or futures\nwould also benefit from trustless exchange. In this paper I propose the atomic\nswaption, which extends the atomic swap to allow for such exchanges. Crucially,\natomic swaptions do not require the use of oracles. I also introduce the margin\ncontract, which provides the ability to create leveraged and short positions.\nLastly, I discuss how atomic swaptions may be routed on the Lightning Network. \n\n"}
{"id": "1807.09173", "contents": "Title: Towards Demystifying Membership Inference Attacks Abstract: Membership inference attacks seek to infer membership of individual training\ninstances of a model to which an adversary has black-box access through a\nmachine learning-as-a-service API. In providing an in-depth characterization of\nmembership privacy risks against machine learning models, this paper presents a\ncomprehensive study towards demystifying membership inference attacks from two\ncomplimentary perspectives. First, we provide a generalized formulation of the\ndevelopment of a black-box membership inference attack model. Second, we\ncharacterize the importance of model choice on model vulnerability through a\nsystematic evaluation of a variety of machine learning models and model\ncombinations using multiple datasets. Through formal analysis and empirical\nevidence from extensive experimentation, we characterize under what conditions\na model may be vulnerable to such black-box membership inference attacks. We\nshow that membership inference vulnerability is data-driven and corresponding\nattack models are largely transferable. Though different model types display\ndifferent vulnerabilities to membership inference, so do different datasets.\nOur empirical results additionally show that (1) using the type of target model\nunder attack within the attack model may not increase attack effectiveness and\n(2) collaborative learning exposes vulnerabilities to membership inference\nrisks when the adversary is a participant. We also discuss countermeasure and\nmitigation strategies. \n\n"}
{"id": "1807.09764", "contents": "Title: Architectures for Detecting Interleaved Multi-stage Network Attacks\n  Using Hidden Markov Models Abstract: With the growing amount of cyber threats, the need for development of\nhigh-assurance cyber systems is becoming increasingly important. The objective\nof this paper is to address the challenges of modeling and detecting\nsophisticated network attacks, such as multiple interleaved attacks. We present\nthe interleaving concept and investigate how interleaving multiple attacks can\ndeceive intrusion detection systems. Using one of the important statistical\nmachine learning (ML) techniques, Hidden Markov Models (HMM), we develop two\narchitectures that take into account the stealth nature of the interleaving\nattacks, and that can detect and track the progress of these attacks. These\narchitectures deploy a database of HMM templates of known attacks and exhibit\nvarying performance and complexity. For performance evaluation, in the presence\nof multiple multi-stage attack scenarios, various metrics are proposed which\ninclude (1) attack risk probability, (2) detection error rate, and (3) the\nnumber of correctly detected stages. Extensive simulation experiments are used\nto demonstrate the efficacy of the proposed architectures. \n\n"}
{"id": "1807.10108", "contents": "Title: Effects of Degradations on Deep Neural Network Architectures Abstract: Deep convolutional neural networks (CNN) have massively influenced recent\nadvances in large-scale image classification. More recently, a dynamic routing\nalgorithm with capsules (groups of neurons) has shown state-of-the-art\nrecognition performance. However, the behavior of such networks in the presence\nof a degrading signal (noise) is mostly unexplored. An analytical study on\ndifferent network architectures toward noise robustness is essential for\nselecting the appropriate model in a specific application scenario. This paper\npresents an extensive performance analysis of six deep architectures for image\nclassification on six most common image degradation models. In this study, we\nhave compared VGG-16, VGG-19, ResNet-50, Inception-v3, MobileNet and CapsuleNet\narchitectures on Gaussian white, Gaussian color, salt-and-pepper, Gaussian\nblur, motion blur and JPEG compression noise models. \n\n"}
{"id": "1807.10234", "contents": "Title: RADIS: Remote Attestation of Distributed IoT Services Abstract: Remote attestation is a security technique through which a remote trusted\nparty (i.e., Verifier) checks the trustworthiness of a potentially untrusted\ndevice (i.e., Prover). In the Internet of Things (IoT) systems, the existing\nremote attestation protocols propose various approaches to detect the modified\nsoftware and physical tampering attacks. However, in an interoperable IoT\nsystem, in which IoT devices interact autonomously among themselves, an\nadditional problem arises: a compromised IoT service can influence the genuine\noperation of other invoked service, without changing the software of the\nlatter. In this paper, we propose a protocol for Remote Attestation of\nDistributed IoT Services (RADIS), which verifies the trustworthiness of\ndistributed IoT services. Instead of attesting the complete memory content of\nthe entire interoperable IoT devices, RADIS attests only the services involved\nin performing a certain functionality. RADIS relies on a control-flow\nattestation technique to detect IoT services that perform an unexpected\noperation due to their interactions with a malicious remote service. Our\nexperiments show the effectiveness of our protocol in validating the integrity\nstatus of a distributed IoT service. \n\n"}
{"id": "1807.10357", "contents": "Title: Towards an open standard for assessing the severity of robot security\n  vulnerabilities, the Robot Vulnerability Scoring System (RVSS) Abstract: Robots are typically not created with security as a main concern. Contrasting\nto typical IT systems, cyberphysical systems rely on security to handle safety\naspects. In light of the former, classic scoring methods such as the Common\nVulnerability Scoring System (CVSS) are not able to accurately capture the\nseverity of robot vulnerabilities. The present research work focuses upon\ncreating an open and free to access Robot Vulnerability Scoring System (RVSS)\nthat considers major relevant issues in robotics including a) robot safety\naspects, b) assessment of downstream implications of a given vulnerability, c)\nlibrary and third-party scoring assessments and d) environmental variables,\nsuch as time since vulnerability disclosure or exposure on the web. Finally, an\nexperimental evaluation of RVSS with contrast to CVSS is provided and discussed\nwith focus on the robotics security landscape. \n\n"}
{"id": "1807.10535", "contents": "Title: NetSpectre: Read Arbitrary Memory over Network Abstract: In this paper, we present NetSpectre, a generic remote Spectre variant 1\nattack. For this purpose, we demonstrate the first access-driven remote\nEvict+Reload cache attack over network, leaking 15 bits per hour. Beyond\nretrofitting existing attacks to a network scenario, we also demonstrate the\nfirst Spectre attack which does not use a cache covert channel. Instead, we\npresent a novel high-performance AVX-based covert channel that we use in our\ncache-free Spectre attack. We show that in particular remote Spectre attacks\nperform significantly better with the AVX-based covert channel, leaking 60 bits\nper hour from the target system. We verified that our NetSpectre attacks work\nin local-area networks as well as between virtual machines in the Google cloud.\n  NetSpectre marks a paradigm shift from local attacks, to remote attacks,\nexposing a much wider range and larger number of devices to Spectre attacks.\nSpectre attacks now must also be considered on devices which do not run any\npotentially attacker-controlled code at all. We show that especially in this\nremote scenario, attacks based on weaker gadgets which do not leak actual data,\nare still very powerful to break address-space layout randomization remotely.\nSeveral of the Spectre gadgets we discuss are more versatile than anticipated.\nIn particular, value-thresholding is a technique we devise, which leaks a\nsecret value without the typical bit selection mechanisms. We outline\nchallenges for future research on Spectre attacks and Spectre mitigations. \n\n"}
{"id": "1807.10868", "contents": "Title: A Survey of Cyber Security Countermeasures Using Hardware Performance\n  Counters Abstract: Cyber attacks and malware are now more prevalent than ever and the trend is\never upward. There have been several approaches to attack detection including\nresident software applications at the root or user level, e.g., virus\ndetection, and modifications to the OS, e.g., encryption, application signing,\netc. Some approaches have moved to lower level detection and preven- tion,\ne.g., Data Execution Prevention. An emerging approach in countermeasure\ndevelopment is the use of hardware performance counters existing in the\nmicro-architecture of modern processors. These are at the lowest level,\nimplemented in processor hardware, and the wealth of data collected by these\ncounters affords some very promising countermeasures with minimal overhead as\nwell as protection from being sabotaged themselves by attackers. Here, we\nconduct a survey of recent techniques in realizing effective countermeasures\nfor cyber attack detection from these hardware performance counters. \n\n"}
{"id": "1807.11655", "contents": "Title: Security and Privacy Issues in Deep Learning Abstract: To promote secure and private artificial intelligence (SPAI), we review\nstudies on the model security and data privacy of DNNs. Model security allows\nsystem to behave as intended without being affected by malicious external\ninfluences that can compromise its integrity and efficiency. Security attacks\ncan be divided based on when they occur: if an attack occurs during training,\nit is known as a poisoning attack, and if it occurs during inference (after\ntraining) it is termed an evasion attack. Poisoning attacks compromise the\ntraining process by corrupting the data with malicious examples, while evasion\nattacks use adversarial examples to disrupt entire classification process.\nDefenses proposed against such attacks include techniques to recognize and\nremove malicious data, train a model to be insensitive to such data, and mask\nthe model's structure and parameters to render attacks more challenging to\nimplement. Furthermore, the privacy of the data involved in model training is\nalso threatened by attacks such as the model-inversion attack, or by dishonest\nservice providers of AI applications. To maintain data privacy, several\nsolutions that combine existing data-privacy techniques have been proposed,\nincluding differential privacy and modern cryptography techniques. In this\npaper, we describe the notions of some of methods, e.g., homomorphic\nencryption, and review their advantages and challenges when implemented in\ndeep-learning models. \n\n"}
{"id": "1807.11679", "contents": "Title: Wasserstein GAN and Waveform Loss-based Acoustic Model Training for\n  Multi-speaker Text-to-Speech Synthesis Systems Using a WaveNet Vocoder Abstract: Recent neural networks such as WaveNet and sampleRNN that learn directly from\nspeech waveform samples have achieved very high-quality synthetic speech in\nterms of both naturalness and speaker similarity even in multi-speaker\ntext-to-speech synthesis systems. Such neural networks are being used as an\nalternative to vocoders and hence they are often called neural vocoders. The\nneural vocoder uses acoustic features as local condition parameters, and these\nparameters need to be accurately predicted by another acoustic model. However,\nit is not yet clear how to train this acoustic model, which is problematic\nbecause the final quality of synthetic speech is significantly affected by the\nperformance of the acoustic model. Significant degradation happens, especially\nwhen predicted acoustic features have mismatched characteristics compared to\nnatural ones. In order to reduce the mismatched characteristics between natural\nand generated acoustic features, we propose frameworks that incorporate either\na conditional generative adversarial network (GAN) or its variant, Wasserstein\nGAN with gradient penalty (WGAN-GP), into multi-speaker speech synthesis that\nuses the WaveNet vocoder. We also extend the GAN frameworks and use the\ndiscretized mixture logistic loss of a well-trained WaveNet in addition to mean\nsquared error and adversarial losses as parts of objective functions.\nExperimental results show that acoustic models trained using the WGAN-GP\nframework using back-propagated discretized-mixture-of-logistics (DML) loss\nachieves the highest subjective evaluation scores in terms of both quality and\nspeaker similarity. \n\n"}
{"id": "1808.00118", "contents": "Title: Toward Multimodal Interaction in Scalable Visual Digital Evidence\n  Visualization Using Computer Vision Techniques and ISS Abstract: Visualization requirements in Forensic Lucid have to do with different levels\nof case knowledge abstraction, representation, aggregation, as well as the\noperational aspects as the final long-term goal of this proposal. It\nencompasses anything from the finer detailed representation of hierarchical\ncontexts to Forensic Lucid programs, to the documented evidence and its\nmanagement, its linkage to programs, to evaluation, and to the management of\nGIPSY software networks. This includes an ability to arbitrarily switch between\nthose views combined with usable multimodal interaction. The purpose is to\ndetermine how the findings can be applied to Forensic Lucid and investigation\ncase management. It is also natural to want a convenient and usable evidence\nvisualization, its semantic linkage and the reasoning machinery for it. Thus,\nwe propose a scalable management, visualization, and evaluation of digital\nevidence using the modified interactive 3D documentary system - Illimitable\nSpace System - (ISS) to represent, semantically link, and provide a usable\ninterface to digital investigators that is navigable via different multimodal\ninteraction techniques using Computer Vision techniques including gestures, as\nwell as eye-gaze and audio. \n\n"}
{"id": "1808.00641", "contents": "Title: Object Localization and Size Estimation from RGB-D Images Abstract: Depth sensing cameras (e.g., Kinect sensor, Tango phone) can acquire color\nand depth images that are registered to a common viewpoint. This opens the\npossibility of developing algorithms that exploit the advantages of both\nsensing modalities. Traditionally, cues from color images have been used for\nobject localization (e.g., YOLO). However, the addition of a depth image can be\nfurther used to segment images that might otherwise have identical color\ninformation. Further, the depth image can be used for object size\n(height/width) estimation (in real-world measurements units, such as meters) as\nopposed to image based segmentation that would only support drawing bounding\nboxes around objects of interest. In this paper, we first collect color camera\ninformation along with depth information using a custom Android application on\nTango Phab2 phone. Second, we perform timing and spatial alignment between the\ntwo data sources. Finally, we evaluate several ways of measuring the height of\nthe object of interest within the captured images under a variety of settings. \n\n"}
{"id": "1808.00665", "contents": "Title: Investigating accuracy of pitch-accent annotations in neural\n  network-based speech synthesis and denoising effects Abstract: We investigated the impact of noisy linguistic features on the performance of\na Japanese speech synthesis system based on neural network that uses WaveNet\nvocoder. We compared an ideal system that uses manually corrected linguistic\nfeatures including phoneme and prosodic information in training and test sets\nagainst a few other systems that use corrupted linguistic features. Both\nsubjective and objective results demonstrate that corrupted linguistic\nfeatures, especially those in the test set, affected the ideal system's\nperformance significantly in a statistical sense due to a mismatched condition\nbetween the training and test sets. Interestingly, while an utterance-level\nTuring test showed that listeners had a difficult time differentiating\nsynthetic speech from natural speech, it further indicated that adding noise to\nthe linguistic features in the training set can partially reduce the effect of\nthe mismatch, regularize the model, and help the system perform better when\nlinguistic features of the test set are noisy. \n\n"}
{"id": "1808.01202", "contents": "Title: Non-Reciprocity Compensation Combined with Turbo Codes for Secret Key\n  Generation in Vehicular Ad Hoc Social IoT Networks Abstract: The physical attributes of the dynamic vehicle-to-vehicle (V2V) propagation\nchannel can be utilised for the generation of highly random and symmetric\ncryptographic keys. However, in a physical-layer key agreement scheme,\nnon-reciprocity due to inherent channel noise and hardware impairments can\npropagate bit disagreements. This has to be addressed prior to the symmetric\nkey generation which is inherently important in social Internet of Things (IoT)\nnetworks, including in adversarial settings (e.g. battlefields). In this paper,\nwe parametrically incorporate temporal variability attributes, such as\nthree-dimensional (3D) scattering and scatterers mobility. Accordingly, this is\nthe first work to incorporate such features into the key generation process by\ncombining non-reciprocity compensation with turbo codes. Preliminary results\nindicate a significant improvement when using Turbo Codes in bit mismatch rate\n(BMR) and key generation rate (KGR) in comparison to sample indexing\ntechniques. \n\n"}
{"id": "1808.01348", "contents": "Title: CT-Wasm: Type-Driven Secure Cryptography for the Web Ecosystem Abstract: A significant amount of both client and server-side cryptography is\nimplemented in JavaScript. Despite widespread concerns about its security, no\nother language has been able to match the convenience that comes from its\nubiquitous support on the \"web ecosystem\" - the wide variety of technologies\nthat collectively underpins the modern World Wide Web. With the new\nintroduction of the WebAssembly bytecode language (Wasm) into the web\necosystem, we have a unique opportunity to advance a principled alternative to\nexisting JavaScript cryptography use cases which does not compromise this\nconvenience.\n  We present Constant-Time WebAssembly (CT-Wasm), a type-driven strict\nextension to WebAssembly which facilitates the verifiably secure implementation\nof cryptographic algorithms. CT-Wasm's type system ensures that code written in\nCT-Wasm is both information flow secure and resistant to timing side channel\nattacks; like base Wasm, these guarantees are verifiable in linear time.\nBuilding on an existing Wasm mechanization, we mechanize the full CT-Wasm\nspecification, prove soundness of the extended type system, implement a\nverified type checker, and give several proofs of the language's security\nproperties.\n  We provide two implementations of CT-Wasm: an OCaml reference interpreter and\na native implementation for Node.js and Chromium that extends Google's V8\nengine. We also implement a CT-Wasm to Wasm rewrite tool that allows developers\nto reap the benefits of CT-Wasm's type system today, while developing\ncryptographic algorithms for base Wasm environments. We evaluate the language,\nour implementations, and supporting tools by porting several cryptographic\nprimitives - Salsa20, SHA-256, and TEA - and the full TweetNaCl library. We\nfind that CT-Wasm is fast, expressive, and generates code that we\nexperimentally measure to be constant-time. \n\n"}
{"id": "1808.01394", "contents": "Title: Distributed Differential Privacy via Shuffling Abstract: We consider the problem of designing scalable, robust protocols for computing\nstatistics about sensitive data. Specifically, we look at how best to design\ndifferentially private protocols in a distributed setting, where each user\nholds a private datum. The literature has mostly considered two models: the\n\"central\" model, in which a trusted server collects users' data in the clear,\nwhich allows greater accuracy; and the \"local\" model, in which users\nindividually randomize their data, and need not trust the server, but accuracy\nis limited. Attempts to achieve the accuracy of the central model without a\ntrusted server have so far focused on variants of cryptographic MPC, which\nlimits scalability.\n  In this paper, we initiate the analytic study of a shuffled model for\ndistributed differentially private algorithms, which lies between the local and\ncentral models. This simple-to-implement model, a special case of the ESA\nframework of [Bittau et al., '17], augments the local model with an anonymous\nchannel that randomly permutes a set of user-supplied messages. For sum\nqueries, we show that this model provides the power of the central model while\navoiding the need to trust a central server and the complexity of cryptographic\nsecure function evaluation. More generally, we give evidence that the power of\nthe shuffled model lies strictly between those of the central and local models:\nfor a natural restriction of the model, we show that shuffled protocols for a\nwidely studied selection problem require exponentially higher sample complexity\nthan do central-model protocols. \n\n"}
{"id": "1808.01546", "contents": "Title: ATMPA: Attacking Machine Learning-based Malware Visualization Detection\n  Methods via Adversarial Examples Abstract: Since the threat of malicious software (malware) has become increasingly\nserious, automatic malware detection techniques have received increasing\nattention, where machine learning (ML)-based visualization detection methods\nbecome more and more popular. In this paper, we demonstrate that the\nstate-of-the-art ML-based visualization detection methods are vulnerable to\nAdversarial Example (AE) attacks. We develop a novel Adversarial Texture\nMalware Perturbation Attack (ATMPA) method based on the gradient descent and\nL-norm optimization method, where attackers can introduce some tiny\nperturbations on the transformed dataset such that ML-based malware detection\nmethods will completely fail. The experimental results on the MS BIG malware\ndataset show that a small interference can reduce the accuracy rate down to 0%\nfor several ML-based detection methods, and the rate of transferability is\n74.1% on average. \n\n"}
{"id": "1808.01735", "contents": "Title: Correspondences between Privacy and Nondiscrimination: Why They Should\n  Be Studied Together Abstract: Privacy and nondiscrimination are related but different. We make this\nobservation precise in two ways. First, we show that both privacy and\nnondiscrimination have two versions, a causal version and a statical\nassociative version, with each version corresponding to a competing view of the\nproper goal of privacy or nondiscrimination. Second, for each version, we show\nthat a difference between the privacy edition of the version and the\nnondiscrimination edition of the version is related to the difference between\nBayesian probabilities and frequentist probabilities. In particular, privacy\nadmits both Bayesian and frequentist interpretations whereas nondiscrimination\nis limited to the frequentist interpretation. We show how the introduced\ncorrespondence allows results from one area of research to be used for the\nother. \n\n"}
{"id": "1808.01947", "contents": "Title: Nonsense Attacks on Google Assistant Abstract: This paper presents a novel attack on voice-controlled digital assistants\nusing nonsensical word sequences. We present the results of experimental work\nwhich demonstrates that it is possible for malicious actors to gain covert\naccess to a voice-controlled system by hiding commands in apparently\nnonsensical sounds of which the meaning is opaque to humans. Several instances\nof nonsensical word sequences were identified which triggered a target command\nin a voice-controlled digital assistant, but which were incomprehensible to\nhumans, as shown in tests with human experimental subjects. Our work confirms\nthe potential for hiding malicious voice commands to voice-controlled digital\nassistants or other speech-controlled devices in speech sounds which are\nperceived by humans as nonsensical. \n\n"}
{"id": "1808.02024", "contents": "Title: Outlier detection on network flow analysis Abstract: It is important to be able to detect and classify malicious network traffic\nflows such as DDoS attacks from benign flows. Normally the task is performed by\nusing supervised classification algorithms. In this paper we analyze the usage\nof outlier detection algorithms for the network traffic classification problem. \n\n"}
{"id": "1808.02131", "contents": "Title: Piping Botnet - Turning Green Technology into a Water Disaster Abstract: The current generation of IoT devices is being used by clients and consumers\nto regulate resources (such as water and electricity) obtained from critical\ninfrastructure (such as urban water services and smart grids), creating a new\nattack vector against critical infrastructure. In this research we show that\nsmart irrigation systems, a new type of green technology and IoT device aimed\nat saving water and money, can be used by attackers as a means of attacking\nurban water services. We present a distributed attack model that can be used by\nan attacker to attack urban water services using a botnet of commercial smart\nirrigation systems. Then, we show how a bot running on a compromised device in\na LAN can:(1) detect a connected commercial smart irrigation system\n(RainMachine, BlueSpray, and GreenIQ) within 15 minutes by analyzing LAN's\nbehavior using a dedicated classification model, and (2) launch watering via a\ncommercial smart irrigation system according to an attacker's wishes using\nspoofing and replay attacks. In addition, we model the damage that can be\ncaused by performing such an attack and show that a standard water tower can be\nemptied in an hour using a botnet of 1,355 sprinklers and a flood water\nreservoir can be emptied overnight using a botnet of 23,866 sprinklers.\nFinally, we discuss countermeasure methods and hypothesize whether the next\ngeneration of plumbers will use Kali Linux instead of a monkey wrench. \n\n"}
{"id": "1808.02350", "contents": "Title: YOLO3D: End-to-end real-time 3D Oriented Object Bounding Box Detection\n  from LiDAR Point Cloud Abstract: Object detection and classification in 3D is a key task in Automated Driving\n(AD). LiDAR sensors are employed to provide the 3D point cloud reconstruction\nof the surrounding environment, while the task of 3D object bounding box\ndetection in real time remains a strong algorithmic challenge. In this paper,\nwe build on the success of the one-shot regression meta-architecture in the 2D\nperspective image space and extend it to generate oriented 3D object bounding\nboxes from LiDAR point cloud. Our main contribution is in extending the loss\nfunction of YOLO v2 to include the yaw angle, the 3D box center in Cartesian\ncoordinates and the height of the box as a direct regression problem. This\nformulation enables real-time performance, which is essential for automated\ndriving. Our results are showing promising figures on KITTI benchmark,\nachieving real-time performance (40 fps) on Titan X GPU. \n\n"}
{"id": "1808.02584", "contents": "Title: PreLatPUF: Exploiting DRAM Latency Variations for Generating Robust\n  Device Signatures Abstract: Physically Unclonable Functions (PUFs) are potential security blocks to\ngenerate unique and more secure keys in low-cost cryptographic applications.\nDynamic random-access memory (DRAM) has been proposed as one of the promising\ncandidates for generating robust keys. Unfortunately, the existing techniques\nof generating device signatures from DRAM is very slow, destructive (destroy\nthe current data), and disruptive to system operation. In this paper, we\npropose \\textit{precharge} latency-based PUF (PreLatPUF) that exploits DRAM\n\\textit{precharge} latency variations to generate signatures. The proposed\nPreLatPUF is fast, robust, least disruptive, and non-destructive. The silicon\nresults from commercially available $DDR3$ chips from different manufacturers\nshow that the proposed key generation technique is at least $ \\sim 1,192X$\nfaster than the existing approaches, while reliably reproducing the key in\nextreme operating conditions. \n\n"}
{"id": "1808.02741", "contents": "Title: Peek-a-Boo: I see your smart home activities, even encrypted! Abstract: A myriad of IoT devices such as bulbs, switches, speakers in a smart home\nenvironment allow users to easily control the physical world around them and\nfacilitate their living styles through the sensors already embedded in these\ndevices. Sensor data contains a lot of sensitive information about the user and\ndevices. However, an attacker inside or near a smart home environment can\npotentially exploit the innate wireless medium used by these devices to\nexfiltrate sensitive information from the encrypted payload (i.e., sensor data)\nabout the users and their activities, invading user privacy. With this in\nmind,in this work, we introduce a novel multi-stage privacy attack against user\nprivacy in a smart environment. It is realized utilizing state-of-the-art\nmachine-learning approaches for detecting and identifying the types of IoT\ndevices, their states, and ongoing user activities in a cascading style by only\npassively sniffing the network traffic from smart home devices and sensors. The\nattack effectively works on both encrypted and unencrypted communications. We\nevaluate the efficiency of the attack with real measurements from an extensive\nset of popular off-the-shelf smart home IoT devices utilizing a set of diverse\nnetwork protocols like WiFi, ZigBee, and BLE. Our results show that an\nadversary passively sniffing the traffic can achieve very high accuracy (above\n90%) in identifying the state and actions of targeted smart home devices and\ntheir users. To protect against this privacy leakage, we also propose a\ncountermeasure based on generating spoofed traffic to hide the device states\nand demonstrate that it provides better protection than existing solutions. \n\n"}
{"id": "1808.03702", "contents": "Title: A robust image-based cryptology scheme based on cellular non-linear\n  network and local image descriptors Abstract: Cellular nonlinear network (CNN) provides an infrastructure for Cellular\nAutomata to have not only an initial state but an input which has a local\nmemory in each cell with much more complexity. This property has many\napplications which we have investigated it in proposing a robust cryptology\nscheme. This scheme consists of a cryptography and steganography sub-module in\nwhich a 3D CNN is designed to produce a chaotic map as the kernel of the system\nto preserve confidentiality and data integrity in cryptology. Our contributions\nare three-fold including (1) a feature descriptor is applied to the cover image\nto form the secret key while conventional methods use a predefined key, (2) a\n3D CNN is used to make a chaotic map for making cipher from the visual message,\nand (3) the proposed CNN is also used to make a dynamic $k$-LSB steganography.\nConducted experiments on 25 standard images prove the effectiveness of the\nproposed cryptology scheme in terms of security, visual, and complexity\nanalysis. \n\n"}
{"id": "1808.04450", "contents": "Title: Road Segmentation Using CNN and Distributed LSTM Abstract: In automated driving systems (ADS) and advanced driver-assistance systems\n(ADAS), an efficient road segmentation is necessary to perceive the drivable\nregion and build an occupancy map for path planning. The existing algorithms\nimplement gigantic convolutional neural networks (CNNs) that are\ncomputationally expensive and time consuming. In this paper, we introduced\ndistributed LSTM, a neural network widely used in audio and video processing,\nto process rows and columns in images and feature maps. We then propose a new\nnetwork combining the convolutional and distributed LSTM layers to solve the\nroad segmentation problem. In the end, the network is trained and tested in\nKITTI road benchmark. The result shows that the combined structure enhances the\nfeature extraction and processing but takes less processing time than pure CNN\nstructure. \n\n"}
{"id": "1808.04761", "contents": "Title: Cache Telepathy: Leveraging Shared Resource Attacks to Learn DNN\n  Architectures Abstract: Deep Neural Networks (DNNs) are fast becoming ubiquitous for their ability to\nattain good accuracy in various machine learning tasks. A DNN's architecture\n(i.e., its hyper-parameters) broadly determines the DNN's accuracy and\nperformance, and is often confidential. Attacking a DNN in the cloud to obtain\nits architecture can potentially provide major commercial value. Further,\nattaining a DNN's architecture facilitates other, existing DNN attacks.\n  This paper presents Cache Telepathy: a fast and accurate mechanism to steal a\nDNN's architecture using the cache side channel. Our attack is based on the\ninsight that DNN inference relies heavily on tiled GEMM (Generalized Matrix\nMultiply), and that DNN architecture parameters determine the number of GEMM\ncalls and the dimensions of the matrices used in the GEMM functions. Such\ninformation can be leaked through the cache side channel.\n  This paper uses Prime+Probe and Flush+Reload to attack VGG and ResNet DNNs\nrunning OpenBLAS and Intel MKL libraries. Our attack is effective in helping\nobtain the architectures by very substantially reducing the search space of\ntarget DNN architectures. For example, for VGG using OpenBLAS, it reduces the\nsearch space from more than $10^{35}$ architectures to just 16. \n\n"}
{"id": "1808.05575", "contents": "Title: MicroWalk: A Framework for Finding Side Channels in Binaries Abstract: Microarchitectural side channels expose unprotected software to information\nleakage attacks where a software adversary is able to track runtime behavior of\na benign process and steal secrets such as cryptographic keys. As suggested by\nincremental software patches for the RSA algorithm against variants of\nside-channel attacks within different versions of cryptographic libraries,\nprotecting security-critical algorithms against side channels is an intricate\ntask. Software protections avoid leakages by operating in constant time with a\nuniform resource usage pattern independent of the processed secret. In this\nrespect, automated testing and verification of software binaries for\nleakage-free behavior is of importance, particularly when the source code is\nnot available. In this work, we propose a novel technique based on Dynamic\nBinary Instrumentation and Mutual Information Analysis to efficiently locate\nand quantify memory based and control-flow based microarchitectural leakages.\nWe develop a software framework named \\tool~for side-channel analysis of\nbinaries which can be extended to support new classes of leakage. For the first\ntime, by utilizing \\tool, we perform rigorous leakage analysis of two\nwidely-used closed-source cryptographic libraries: \\emph{Intel IPP} and\n\\emph{Microsoft CNG}. We analyze $15$ different cryptographic implementations\nconsisting of $112$ million instructions in about $105$ minutes of CPU time. By\nlocating previously unknown leakages in hardened implementations, our results\nsuggest that \\tool~can efficiently find microarchitectural leakages in software\nbinaries. \n\n"}
{"id": "1808.05705", "contents": "Title: Mitigation of Adversarial Attacks through Embedded Feature Selection Abstract: Machine learning has become one of the main components for task automation in\nmany application domains. Despite the advancements and impressive achievements\nof machine learning, it has been shown that learning algorithms can be\ncompromised by attackers both at training and test time. Machine learning\nsystems are especially vulnerable to adversarial examples where small\nperturbations added to the original data points can produce incorrect or\nunexpected outputs in the learning algorithms at test time. Mitigation of these\nattacks is hard as adversarial examples are difficult to detect. Existing\nrelated work states that the security of machine learning systems against\nadversarial examples can be weakened when feature selection is applied to\nreduce the systems' complexity. In this paper, we empirically disprove this\nidea, showing that the relative distortion that the attacker has to introduce\nto succeed in the attack is greater when the target is using a reduced set of\nfeatures. We also show that the minimal adversarial examples differ\nstatistically more strongly from genuine examples with a lower number of\nfeatures. However, reducing the feature count can negatively impact the\nsystem's performance. We illustrate the trade-off between security and accuracy\nwith specific examples. We propose a design methodology to evaluate the\nsecurity of machine learning classifiers with embedded feature selection\nagainst adversarial examples crafted using different attack strategies. \n\n"}
{"id": "1808.05760", "contents": "Title: Data Poisoning Attacks in Contextual Bandits Abstract: We study offline data poisoning attacks in contextual bandits, a class of\nreinforcement learning problems with important applications in online\nrecommendation and adaptive medical treatment, among others. We provide a\ngeneral attack framework based on convex optimization and show that by slightly\nmanipulating rewards in the data, an attacker can force the bandit algorithm to\npull a target arm for a target contextual vector. The target arm and target\ncontextual vector are both chosen by the attacker. That is, the attacker can\nhijack the behavior of a contextual bandit. We also investigate the feasibility\nand the side effects of such attacks, and identify future directions for\ndefense. Experiments on both synthetic and real-world data demonstrate the\nefficiency of the attack algorithm. \n\n"}
{"id": "1808.06049", "contents": "Title: Runtime Analysis of Whole-System Provenance Abstract: Identifying the root cause and impact of a system intrusion remains a\nfoundational challenge in computer security. Digital provenance provides a\ndetailed history of the flow of information within a computing system,\nconnecting suspicious events to their root causes. Although existing\nprovenance-based auditing techniques provide value in forensic analysis, they\nassume that such analysis takes place only retrospectively. Such post-hoc\nanalysis is insufficient for realtime security applications, moreover, even for\nforensic tasks, prior provenance collection systems exhibited poor performance\nand scalability, jeopardizing the timeliness of query responses.\n  We present CamQuery, which provides inline, realtime provenance analysis,\nmaking it suitable for implementing security applications. CamQuery is a Linux\nSecurity Module that offers support for both userspace and in-kernel execution\nof analysis applications. We demonstrate the applicability of CamQuery to a\nvariety of runtime security applications including data loss prevention,\nintrusion detection, and regulatory compliance. In evaluation, we demonstrate\nthat CamQuery reduces the latency of realtime query mechanisms, while imposing\nminimal overheads on system execution. CamQuery thus enables the further\ndeployment of provenance-based technologies to address central challenges in\ncomputer security. \n\n"}
{"id": "1808.06288", "contents": "Title: Multimodal speech synthesis architecture for unsupervised speaker\n  adaptation Abstract: This paper proposes a new architecture for speaker adaptation of\nmulti-speaker neural-network speech synthesis systems, in which an unseen\nspeaker's voice can be built using a relatively small amount of speech data\nwithout transcriptions. This is sometimes called \"unsupervised speaker\nadaptation\". More specifically, we concatenate the layers to the audio inputs\nwhen performing unsupervised speaker adaptation while we concatenate them to\nthe text inputs when synthesizing speech from text. Two new training schemes\nfor the new architecture are also proposed in this paper. These training\nschemes are not limited to speech synthesis, other applications are suggested.\nExperimental results show that the proposed model not only enables adaptation\nto unseen speakers using untranscribed speech but it also improves the\nperformance of multi-speaker modeling and speaker adaptation using transcribed\naudio files. \n\n"}
{"id": "1808.06487", "contents": "Title: Toric Varieties and Codes, Error-correcting Codes, Quantum Codes, Secret\n  Sharing and Decoding Abstract: Toric varieties and their associated toric codes, as well as determination of\ntheir parameters with intersection theory, are presented in the two dimensional\ncase.\n  Linear Secret Sharing Schemes with strong multiplication are constructed from\ntoric varieties and codes by the J. L. Massey construction.\n  Asymmetric Quantum Codes are obtained from toric codes by the A.R.\nCalderbank, P.W. Shor and A.M. Steane construction of stabilizer codes from\nlinear codes containing their dual codes.\n  Decoding of a class of toric codes is presented. \n\n"}
{"id": "1808.06645", "contents": "Title: Stochastic Combinatorial Ensembles for Defending Against Adversarial\n  Examples Abstract: Many deep learning algorithms can be easily fooled with simple adversarial\nexamples. To address the limitations of existing defenses, we devised a\nprobabilistic framework that can generate an exponentially large ensemble of\nmodels from a single model with just a linear cost. This framework takes\nadvantage of neural network depth and stochastically decides whether or not to\ninsert noise removal operators such as VAEs between layers. We show empirically\nthe important role that model gradients have when it comes to determining\ntransferability of adversarial examples, and take advantage of this result to\ndemonstrate that it is possible to train models with limited adversarial attack\ntransferability. Additionally, we propose a detection method based on metric\nlearning in order to detect adversarial examples that have no hope of being\ncleaned of maliciously engineered noise. \n\n"}
{"id": "1808.07285", "contents": "Title: DeepCorr: Strong Flow Correlation Attacks on Tor Using Deep Learning Abstract: Flow correlation is the core technique used in a multitude of deanonymization\nattacks on Tor. Despite the importance of flow correlation attacks on Tor,\nexisting flow correlation techniques are considered to be ineffective and\nunreliable in linking Tor flows when applied at a large scale, i.e., they\nimpose high rates of false positive error rates or require impractically long\nflow observations to be able to make reliable correlations. In this paper, we\nshow that, unfortunately, flow correlation attacks can be conducted on Tor\ntraffic with drastically higher accuracies than before by leveraging emerging\nlearning mechanisms. We particularly design a system, called DeepCorr, that\noutperforms the state-of-the-art by significant margins in correlating Tor\nconnections. DeepCorr leverages an advanced deep learning architecture to learn\na flow correlation function tailored to Tor's complex network this is in\ncontrast to previous works' use of generic statistical correlation metrics to\ncorrelated Tor flows. We show that with moderate learning, DeepCorr can\ncorrelate Tor connections (and therefore break its anonymity) with accuracies\nsignificantly higher than existing algorithms, and using substantially shorter\nlengths of flow observations. For instance, by collecting only about 900\npackets of each target Tor flow (roughly 900KB of Tor data), DeepCorr provides\na flow correlation accuracy of 96% compared to 4% by the state-of-the-art\nsystem of RAPTOR using the same exact setting.\n  We hope that our work demonstrates the escalating threat of flow correlation\nattacks on Tor given recent advances in learning algorithms, calling for the\ntimely deployment of effective countermeasures by the Tor community. \n\n"}
{"id": "1808.07536", "contents": "Title: Capacity-Achieving Private Information Retrieval Codes with Optimal\n  Message Size and Upload Cost Abstract: We propose a new capacity-achieving code for the private information\nretrieval (PIR) problem, and show that it has the minimum message size (being\none less than the number of servers) and the minimum upload cost (being roughly\nlinear in the number of messages) among a general class of capacity-achieving\ncodes, and in particular, among all capacity-achieving linear codes. Different\nfrom existing code constructions, the proposed code is asymmetric, and this\nasymmetry appears to be the key factor leading to the optimal message size and\nthe optimal upload cost. The converse results on the message size and the\nupload cost are obtained by a strategic analysis of the information theoretic\nproof of the PIR capacity, from which a set of critical properties of any\ncapacity-achieving code in the code class of interest is extracted. The\nsymmetry structure of the PIR problem is then analyzed, which allows us to\nconstruct symmetric codes from asymmetric ones, yielding a meaningful bridge\nbetween the proposed code and existing ones in the literature. \n\n"}
{"id": "1808.07814", "contents": "Title: Light Ears: Information Leakage via Smart Lights Abstract: Modern Internet-enabled smart lights promise energy efficiency and many\nadditional capabilities over traditional lamps. However, these connected lights\ncreate a new attack surface, which can be maliciously used to violate users'\nprivacy and security. In this paper, we design and evaluate novel attacks that\ntake advantage of light emitted by modern smart bulbs in order to infer users'\nprivate data and preferences. The first two attacks are designed to infer\nusers' audio and video playback by a systematic observation and analysis of the\nmultimedia-visualization functionality of smart light bulbs. The third attack\nutilizes the infrared capabilities of such smart light bulbs to create a\ncovert-channel, which can be used as a gateway to exfiltrate user's private\ndata out of their secured home or office network. A comprehensive evaluation of\nthese attacks in various real-life settings confirms their feasibility and\naffirms the need for new privacy protection mechanisms. \n\n"}
{"id": "1808.09897", "contents": "Title: Towards security defect prediction with AI Abstract: In this study, we investigate the limits of the current state of the art AI\nsystem for detecting buffer overflows and compare it with current static\nanalysis tools. To do so, we developed a code generator, s-bAbI, capable of\nproducing an arbitrarily large number of code samples of controlled complexity.\nWe found that the static analysis engines we examined have good precision, but\npoor recall on this dataset, except for a sound static analyzer that has good\nprecision and recall. We found that the state of the art AI system, a memory\nnetwork modeled after Choi et al. [1], can achieve similar performance to the\nstatic analysis engines, but requires an exhaustive amount of training data in\norder to do so. Our work points towards future approaches that may solve these\nproblems; namely, using representations of code that can capture appropriate\nscope information and using deep learning methods that are able to perform\narithmetic operations. \n\n"}
{"id": "1809.00141", "contents": "Title: A Graph Based Framework for Malicious Insider Threat Detection Abstract: While most security projects have focused on fending off attacks coming from\noutside the organizational boundaries, a real threat has arisen from the people\nwho are inside those perimeter protections. Insider threats have shown their\npower by hugely affecting national security, financial stability, and the\nprivacy of many thousands of people. What is in the news is the tip of the\niceberg, with much more going on under the radar, and some threats never being\ndetected. We propose a hybrid framework based on graphical analysis and anomaly\ndetection approaches, to combat this severe cybersecurity threat. Our framework\nanalyzes heterogeneous data in isolating possible malicious users hiding behind\nothers. Empirical results reveal this framework to be effective in\ndistinguishing the majority of users who demonstrate typical behavior from the\nminority of users who show suspicious behavior. \n\n"}
{"id": "1809.00615", "contents": "Title: Have You Stolen My Model? Evasion Attacks Against Deep Neural Network\n  Watermarking Techniques Abstract: Deep neural networks have had enormous impact on various domains of computer\nscience, considerably outperforming previous state of the art machine learning\ntechniques. To achieve this performance, neural networks need large quantities\nof data and huge computational resources, which heavily increases their\nconstruction costs. The increased cost of building a good deep neural network\nmodel gives rise to a need for protecting this investment from potential\ncopyright infringements. Legitimate owners of a machine learning model want to\nbe able to reliably track and detect a malicious adversary that tries to steal\nthe intellectual property related to the model. Recently, this problem was\ntackled by introducing in deep neural networks the concept of watermarking,\nwhich allows a legitimate owner to embed some secret information(watermark) in\na given model. The watermark allows the legitimate owner to detect copyright\ninfringements of his model. This paper focuses on verifying the robustness and\nreliability of state-of- the-art deep neural network watermarking schemes. We\nshow that, a malicious adversary, even in scenarios where the watermark is\ndifficult to remove, can still evade the verification by the legitimate owners,\nthus avoiding the detection of model theft. \n\n"}
{"id": "1809.00888", "contents": "Title: MesoNet: a Compact Facial Video Forgery Detection Network Abstract: This paper presents a method to automatically and efficiently detect face\ntampering in videos, and particularly focuses on two recent techniques used to\ngenerate hyper-realistic forged videos: Deepfake and Face2Face. Traditional\nimage forensics techniques are usually not well suited to videos due to the\ncompression that strongly degrades the data. Thus, this paper follows a deep\nlearning approach and presents two networks, both with a low number of layers\nto focus on the mesoscopic properties of images. We evaluate those fast\nnetworks on both an existing dataset and a dataset we have constituted from\nonline videos. The tests demonstrate a very successful detection rate with more\nthan 98% for Deepfake and 95% for Face2Face. \n\n"}
{"id": "1809.00939", "contents": "Title: Decentralized Search on Decentralized Web Abstract: Decentralized Web, or DWeb, is envisioned as a promising future of the Web.\nBeing decentralized, there are no dedicated web servers in DWeb; Devices that\nretrieve web contents also serve their cached data to peer devices with\nstraight privacy-preserving mechanisms. The fact that contents in DWeb are\ndistributed, replicated, and decentralized lead to a number of key advantages\nover the conventional web. These include better resiliency against network\npartitioning and distributed-denial-of-service attacks (DDoS), and better\nbrowsing experiences in terms of shorter latency and higher throughput.\nMoreover, DWeb provides tamper-proof contents because each content piece is\nuniquely identified by a cryptographic hash. DWeb also clicks well with future\nInternet architectures, such as Named Data Networking (NDN).Search engines have\nbeen an inseparable element of the Web. Contemporary (\"Web 2.0\") search\nengines, however, provide centralized services. They are thus subject to DDoS\nattacks, insider threat, and ethical issues like search bias and censorship. As\nthe web moves from being centralized to being decentralized, search engines\nought to follow. We propose QueenBee, a decentralized search engine for DWeb.\nQueenBee is so named because worker bees and honeycomb are a common metaphor\nfor distributed architectures, with the queen being the one that holds the\ncolony together. QueenBee aims to revolutionize the search engine business\nmodel by offering incentives to both content providers and peers that\nparticipate in QueenBee's page indexing and ranking operations. \n\n"}
{"id": "1809.00962", "contents": "Title: Blind Ptychography by Douglas-Rachford Splitting Abstract: Blind ptychography is the scanning version of coherent diffractive imaging\nwhich seeks to recover both the object and the probe simultaneously. Based on\nalternating minimization by Douglas-Rachford splitting, AMDRS is a blind\nptychographic algorithm informed by the uniqueness theory, the Poisson noise\nmodel and the stability analysis. Enhanced by the initialization method and the\nuse of a randomly phased mask, AMDRS converges globally and geometrically.\nThree boundary conditions are considered in the simulations: periodic,\ndark-field and bright-field boundary conditions. The dark-field boundary\ncondition is suited for isolated objects while the bright-field boundary\ncondition is for non-isolated objects. The periodic boundary condition is a\nmathematically convenient reference point. Depending on the avail- ability of\nthe boundary prior the dark-field and the bright-field boundary conditions may\nor may not be enforced in the reconstruction. Not surprisingly, enforcing the\nboundary condition improves the rate of convergence, sometimes in a significant\nway. Enforcing the bright-field condition in the reconstruction can also remove\nthe linear phase ambiguity. \n\n"}
{"id": "1809.01031", "contents": "Title: Constructing Trustworthy and Safe Communities on a Blockchain-Enabled\n  Social Credits System Abstract: The emergence of big data and Artificial Intelligence (AI) technology is\nreshaping the world. While the technological revolution improves the quality of\nour life, new concerns are triggered. The superhuman capability enables AI to\noutperform human workers in many data- and/or computing-intensive tasks. Also,\ndigital superpowers are showing arrogance towards individuals, which erodes the\ntrust foundation of the society. In this position paper, we suggest to\nconstruct trustworthy and safe communities based on a BLockchain-Enabled Social\ncredits System (BLESS) that rewards the residents who commit in socially\nbeneficial activities. Human being's true value lies in serving other people.\nThe BLESS system is considered as an efficient approach to promote the value\nand dignity in efforts focused on enhancing our communities and regulating\nbusiness and private behaviors. The BLESS system leverages the decentralized\narchitecture of the blockchain network, which not only allows grassroots\nindividuals to participate rating process of a social credit system (SCS), but\nalso provides tamper proof of transaction data in the trustless network\nenvironment. The anonymity in blockchain records also protects individuals from\nbeing targeted in the fight against powerful enterprises. Smart contract\nenabled authentication and authorization strategy prevents any unauthorized\nentity from accessing the credit system. The BLESS scheme is promising to offer\na secure, transparent and decentralized SCS. \n\n"}
{"id": "1809.01093", "contents": "Title: Adversarial Attacks on Node Embeddings via Graph Poisoning Abstract: The goal of network representation learning is to learn low-dimensional node\nembeddings that capture the graph structure and are useful for solving\ndownstream tasks. However, despite the proliferation of such methods, there is\ncurrently no study of their robustness to adversarial attacks. We provide the\nfirst adversarial vulnerability analysis on the widely used family of methods\nbased on random walks. We derive efficient adversarial perturbations that\npoison the network structure and have a negative effect on both the quality of\nthe embeddings and the downstream tasks. We further show that our attacks are\ntransferable since they generalize to many models and are successful even when\nthe attacker is restricted. \n\n"}
{"id": "1809.01410", "contents": "Title: Generating Highly Realistic Images of Skin Lesions with GANs Abstract: As many other machine learning driven medical image analysis tasks, skin\nimage analysis suffers from a chronic lack of labeled data and skewed class\ndistributions, which poses problems for the training of robust and\nwell-generalizing models. The ability to synthesize realistic looking images of\nskin lesions could act as a reliever for the aforementioned problems.\nGenerative Adversarial Networks (GANs) have been successfully used to\nsynthesize realistically looking medical images, however limited to low\nresolution, whereas machine learning models for challenging tasks such as skin\nlesion segmentation or classification benefit from much higher resolution data.\nIn this work, we successfully synthesize realistically looking images of skin\nlesions with GANs at such high resolution. Therefore, we utilize the concept of\nprogressive growing, which we both quantitatively and qualitatively compare to\nother GAN architectures such as the DCGAN and the LAPGAN. Our results show that\nwith the help of progressive growing, we can synthesize highly realistic\ndermoscopic images of skin lesions that even expert dermatologists find hard to\ndistinguish from real ones. \n\n"}
{"id": "1809.01715", "contents": "Title: Bridging machine learning and cryptography in defence against\n  adversarial attacks Abstract: In the last decade, deep learning algorithms have become very popular thanks\nto the achieved performance in many machine learning and computer vision tasks.\nHowever, most of the deep learning architectures are vulnerable to so called\nadversarial examples. This questions the security of deep neural networks (DNN)\nfor many security- and trust-sensitive domains. The majority of the proposed\nexisting adversarial attacks are based on the differentiability of the DNN cost\nfunction.Defence strategies are mostly based on machine learning and signal\nprocessing principles that either try to detect-reject or filter out the\nadversarial perturbations and completely neglect the classical cryptographic\ncomponent in the defence. In this work, we propose a new defence mechanism\nbased on the second Kerckhoffs's cryptographic principle which states that the\ndefence and classification algorithm are supposed to be known, but not the key.\nTo be compliant with the assumption that the attacker does not have access to\nthe secret key, we will primarily focus on a gray-box scenario and do not\naddress a white-box one. More particularly, we assume that the attacker does\nnot have direct access to the secret block, but (a) he completely knows the\nsystem architecture, (b) he has access to the data used for training and\ntesting and (c) he can observe the output of the classifier for each given\ninput. We show empirically that our system is efficient against most famous\nstate-of-the-art attacks in black-box and gray-box scenarios. \n\n"}
{"id": "1809.02013", "contents": "Title: Dynamic Bayesian Games for Adversarial and Defensive Cyber Deception Abstract: Security challenges accompany the efficiency. The pervasive integration of\ninformation and communications technologies (ICTs) makes cyber-physical systems\nvulnerable to targeted attacks that are deceptive, persistent, adaptive and\nstrategic. Attack instances such as Stuxnet, Dyn, and WannaCry ransomware have\nshown the insufficiency of off-the-shelf defensive methods including the\nfirewall and intrusion detection systems. Hence, it is essential to design\nup-to-date security mechanisms that can mitigate the risks despite the\nsuccessful infiltration and the strategic response of sophisticated attackers.\nIn this chapter, we use game theory to model competitive interactions between\ndefenders and attackers. First, we use the static Bayesian game to capture the\nstealthy and deceptive characteristics of the attacker. A random variable\ncalled the \\textit{type} characterizes users' essences and objectives, e.g., a\nlegitimate user or an attacker. The realization of the user's type is private\ninformation due to the cyber deception. Then, we extend the one-shot\nsimultaneous interaction into the one-shot interaction with asymmetric\ninformation structure, i.e., the signaling game. Finally, we investigate the\nmulti-stage transition under a case study of Advanced Persistent Threats (APTs)\nand Tennessee Eastman (TE) process. Two-Sided incomplete information is\nintroduced because the defender can adopt defensive deception techniques such\nas honey files and honeypots to create sufficient amount of uncertainties for\nthe attacker. Throughout this chapter, the analysis of the Nash equilibrium\n(NE), Bayesian Nash equilibrium (BNE), and perfect Bayesian Nash equilibrium\n(PBNE) enables the policy prediction of the adversary and the design of\nproactive and strategic defenses to deter attackers and mitigate losses. \n\n"}
{"id": "1809.02077", "contents": "Title: IDSGAN: Generative Adversarial Networks for Attack Generation against\n  Intrusion Detection Abstract: As an essential tool in security, the intrusion detection system bears the\nresponsibility of the defense to network attacks performed by malicious\ntraffic. Nowadays, with the help of machine learning algorithms, intrusion\ndetection systems develop rapidly. However, the robustness of this system is\nquestionable when it faces adversarial attacks. For the robustness of detection\nsystems, more potential attack approaches are under research. In this paper, a\nframework of the generative adversarial networks, called IDSGAN, is proposed to\ngenerate the adversarial malicious traffic records aiming to attack intrusion\ndetection systems by deceiving and evading the detection. Given that the\ninternal structure and parameters of the detection system are unknown to\nattackers, the adversarial attack examples perform the black-box attacks\nagainst the detection system. IDSGAN leverages a generator to transform\noriginal malicious traffic records into adversarial malicious ones. A\ndiscriminator classifies traffic examples and dynamically learns the real-time\nblack-box detection system. More significantly, the restricted modification\nmechanism is designed for the adversarial generation to preserve original\nattack functionalities of adversarial traffic records. The effectiveness of the\nmodel is indicated by attacking multiple algorithm-based detection models with\ndifferent attack categories. The robustness is verified by changing the number\nof the modified features. A comparative experiment with adversarial attack\nbaselines demonstrates the superiority of our model. \n\n"}
{"id": "1809.02397", "contents": "Title: Detecting Potential Local Adversarial Examples for Human-Interpretable\n  Defense Abstract: Machine learning models are increasingly used in the industry to make\ndecisions such as credit insurance approval. Some people may be tempted to\nmanipulate specific variables, such as the age or the salary, in order to get\nbetter chances of approval. In this ongoing work, we propose to discuss, with a\nfirst proposition, the issue of detecting a potential local adversarial example\non classical tabular data by providing to a human expert the locally critical\nfeatures for the classifier's decision, in order to control the provided\ninformation and avoid a fraud. \n\n"}
{"id": "1809.02444", "contents": "Title: Metamorphic Relation Based Adversarial Attacks on Differentiable Neural\n  Computer Abstract: Deep neural networks (DNN), while becoming the driving force of many novel\ntechnology and achieving tremendous success in many cutting-edge applications,\nare still vulnerable to adversarial attacks. Differentiable neural computer\n(DNC) is a novel computing machine with DNN as its central controller operating\non an external memory module for data processing. The unique architecture of\nDNC contributes to its state-of-the-art performance in tasks which requires the\nability to represent variables and data structure as well as to store data over\nlong timescales. However, there still lacks a comprehensive study on how\nadversarial examples affect DNC in terms of robustness. In this paper, we\npropose metamorphic relation based adversarial techniques for a range of tasks\ndescribed in the natural processing language domain. We show that the\nnear-perfect performance of the DNC in bAbI logical question answering tasks\ncan be degraded by adversarially injected sentences. We further perform\nin-depth study on the role of DNC's memory size in its robustness and analyze\nthe potential reason causing why DNC fails. Our study demonstrates the current\nchallenges and potential opportunities towards constructing more robust DNCs. \n\n"}
{"id": "1809.02629", "contents": "Title: Synesthesia: Detecting Screen Content via Remote Acoustic Side Channels Abstract: We show that subtle acoustic noises emanating from within computer screens\ncan be used to detect the content displayed on the screens. This sound can be\npicked up by ordinary microphones built into webcams or screens, and is\ninadvertently transmitted to other parties, e.g., during a videoconference call\nor archived recordings. It can also be recorded by a smartphone or \"smart\nspeaker\" placed on a desk next to the screen, or from as far as 10 meters away\nusing a parabolic microphone.\n  Empirically demonstrating various attack scenarios, we show how this channel\ncan be used for real-time detection of on-screen text, or users' input into\non-screen virtual keyboards. We also demonstrate how an attacker can analyze\nthe audio received during video call (e.g., on Google Hangout) to infer whether\nthe other side is browsing the web in lieu of watching the video call, and\nwhich web site is displayed on their screen. \n\n"}
{"id": "1809.02702", "contents": "Title: Empirical Vulnerability Analysis of Automated Smart Contracts Security\n  Testing on Blockchains Abstract: The emerging blockchain technology supports decentralized computing paradigm\nshift and is a rapidly approaching phenomenon. While blockchain is thought\nprimarily as the basis of Bitcoin, its application has grown far beyond\ncryptocurrencies due to the introduction of smart contracts. Smart contracts\nare self-enforcing pieces of software, which reside and run over a hosting\nblockchain. Using blockchain-based smart contracts for secure and transparent\nmanagement to govern interactions (authentication, connection, and transaction)\nin Internet-enabled environments, mostly IoT, is a niche area of research and\npractice. However, writing trustworthy and safe smart contracts can be\ntremendously challenging because of the complicated semantics of underlying\ndomain-specific languages and its testability. There have been high-profile\nincidents that indicate blockchain smart contracts could contain various\ncode-security vulnerabilities, instigating financial harms. When it involves\nsecurity of smart contracts, developers embracing the ability to write the\ncontracts should be capable of testing their code, for diagnosing security\nvulnerabilities, before deploying them to the immutable environments on\nblockchains. However, there are only a handful of security testing tools for\nsmart contracts. This implies that the existing research on automatic smart\ncontracts security testing is not adequate and remains in a very stage of\ninfancy. With a specific goal to more readily realize the application of\nblockchain smart contracts in security and privacy, we should first understand\ntheir vulnerabilities before widespread implementation. Accordingly, the goal\nof this paper is to carry out a far-reaching experimental assessment of current\nstatic smart contracts security testing tools, for the most widely used\nblockchain, the Ethereum and its domain-specific programming language, Solidity\nto provide the first... \n\n"}
{"id": "1809.02861", "contents": "Title: Why Do Adversarial Attacks Transfer? Explaining Transferability of\n  Evasion and Poisoning Attacks Abstract: Transferability captures the ability of an attack against a machine-learning\nmodel to be effective against a different, potentially unknown, model.\nEmpirical evidence for transferability has been shown in previous work, but the\nunderlying reasons why an attack transfers or not are not yet well understood.\nIn this paper, we present a comprehensive analysis aimed to investigate the\ntransferability of both test-time evasion and training-time poisoning attacks.\nWe provide a unifying optimization framework for evasion and poisoning attacks,\nand a formal definition of transferability of such attacks. We highlight two\nmain factors contributing to attack transferability: the intrinsic adversarial\nvulnerability of the target model, and the complexity of the surrogate model\nused to optimize the attack. Based on these insights, we define three metrics\nthat impact an attack's transferability. Interestingly, our results derived\nfrom theoretical analysis hold for both evasion and poisoning attacks, and are\nconfirmed experimentally using a wide range of linear and non-linear\nclassifiers and datasets. \n\n"}
{"id": "1809.02888", "contents": "Title: Lost in the Digital Wild: Hiding Information in Digital Activities Abstract: This paper presents a new general framework of information hiding, in which\nthe hidden information is embedded into a collection of activities conducted by\nselected human and computer entities (e.g., a number of online accounts of one\nor more online social networks) in a selected digital world. Different from\nother traditional schemes, where the hidden information is embedded into one or\nmore selected or generated cover objects, in the new framework the hidden\ninformation is embedded in the fact that some particular digital activities\nwith some particular attributes took place in some particular ways in the\nreceiver-observable digital world.\n  In the new framework the concept of \"cover\" almost disappears, or one can say\nthat now the whole digital world selected becomes the cover. The new framework\ncan find applications in both security (e.g., steganography) and non-security\ndomains (e.g., gaming). For security applications we expect that the new\nframework calls for completely new steganalysis techniques, which are likely\nmore complicated, less effective and less efficient than existing ones due to\nthe need to monitor and analyze the whole digital world constantly and in real\ntime. A proof-of-concept system was developed as a mobile app based on Twitter\nactivities to demonstrate the information hiding framework works. We are\ndeveloping a more hybrid system involving several online social networks. \n\n"}
{"id": "1809.03008", "contents": "Title: Training for Faster Adversarial Robustness Verification via Inducing\n  ReLU Stability Abstract: We explore the concept of co-design in the context of neural network\nverification. Specifically, we aim to train deep neural networks that not only\nare robust to adversarial perturbations but also whose robustness can be\nverified more easily. To this end, we identify two properties of network models\n- weight sparsity and so-called ReLU stability - that turn out to significantly\nimpact the complexity of the corresponding verification task. We demonstrate\nthat improving weight sparsity alone already enables us to turn computationally\nintractable verification problems into tractable ones. Then, improving ReLU\nstability leads to an additional 4-13x speedup in verification times. An\nimportant feature of our methodology is its \"universality,\" in the sense that\nit can be used with a broad range of training procedures and verification\napproaches. \n\n"}
{"id": "1809.03113", "contents": "Title: Certified Adversarial Robustness with Additive Noise Abstract: The existence of adversarial data examples has drawn significant attention in\nthe deep-learning community; such data are seemingly minimally perturbed\nrelative to the original data, but lead to very different outputs from a\ndeep-learning algorithm. Although a significant body of work on developing\ndefensive models has been considered, most such models are heuristic and are\noften vulnerable to adaptive attacks. Defensive methods that provide\ntheoretical robustness guarantees have been studied intensively, yet most fail\nto obtain non-trivial robustness when a large-scale model and data are present.\nTo address these limitations, we introduce a framework that is scalable and\nprovides certified bounds on the norm of the input manipulation for\nconstructing adversarial examples. We establish a connection between robustness\nagainst adversarial perturbation and additive random noise, and propose a\ntraining strategy that can significantly improve the certified bounds. Our\nevaluation on MNIST, CIFAR-10 and ImageNet suggests that the proposed method is\nscalable to complicated models and large data sets, while providing competitive\nrobustness to state-of-the-art provable defense methods. \n\n"}
{"id": "1809.03390", "contents": "Title: Tandem: Securing Keys by Using a Central Server While Preserving Privacy Abstract: Users' devices, e.g., smartphones or laptops, are typically incapable of\nsecurely storing and processing cryptographic keys. We present Tandem, a novel\nset of protocols for securing cryptographic keys with support from a central\nserver. Tandem uses one-time-use key-share tokens to preserve users' privacy\nwith respect to a malicious central server. Additionally, Tandem enables users\nto block their keys if they lose their device, and it enables the server to\nlimit how often an adversary can use an unblocked key. We prove Tandem's\nsecurity and privacy properties, apply Tandem to attribute-based credentials,\nand implement a Tandem proof of concept to show that it causes little overhead. \n\n"}
{"id": "1809.03421", "contents": "Title: Performance Evaluation of the Quorum Blockchain Platform Abstract: Quorum is a permissioned blockchain platform built from the Ethereum codebase\nwith adaptations to make it a permissioned consortium platform. It is one of\nthe key contenders in the permissioned ledger space. Quorum supports\nconfidentiality and privacy of smart contracts and transactions, and crash and\nByzantine fault tolerant consensus algorithms. In this paper, we characterize\nthe performance features of Quorum. We study the throughput and latency\ncharacteristics of Quorum with different workloads and consensus algorithms\nthat it supports. Through a suite of micro-benchmarks, we explore how certain\ntransaction and smart contract parameters can affect transaction latencies. \n\n"}
{"id": "1809.03832", "contents": "Title: Learning Rate Adaptation for Federated and Differentially Private\n  Learning Abstract: We propose an algorithm for the adaptation of the learning rate for\nstochastic gradient descent (SGD) that avoids the need for validation set use.\nThe idea for the adaptiveness comes from the technique of extrapolation: to get\nan estimate for the error against the gradient flow which underlies SGD, we\ncompare the result obtained by one full step and two half-steps. The algorithm\nis applied in two separate frameworks: federated and differentially private\nlearning. Using examples of deep neural networks we empirically show that the\nadaptive algorithm is competitive with manually tuned commonly used\noptimisation methods for differentially privately training. We also show that\nit works robustly in the case of federated learning unlike commonly used\noptimisation methods. \n\n"}
{"id": "1809.04274", "contents": "Title: Transforming acoustic characteristics to deceive playback spoofing\n  countermeasures of speaker verification systems Abstract: Automatic speaker verification (ASV) systems use a playback detector to\nfilter out playback attacks and ensure verification reliability. Since current\nplayback detection models are almost always trained using genuine and\nplayed-back speech, it may be possible to degrade their performance by\ntransforming the acoustic characteristics of the played-back speech close to\nthat of the genuine speech. One way to do this is to enhance speech \"stolen\"\nfrom the target speaker before playback. We tested the effectiveness of a\nplayback attack using this method by using the speech enhancement generative\nadversarial network to transform acoustic characteristics. Experimental results\nshowed that use of this \"enhanced stolen speech\" method significantly increases\nthe equal error rates for the baseline used in the ASVspoof 2017 challenge and\nfor a light convolutional neural network-based method. The results also showed\nthat its use degrades the performance of a Gaussian mixture model-universal\nbackground model-based ASV system. This type of attack is thus an urgent\nproblem needing to be solved. \n\n"}
{"id": "1809.04332", "contents": "Title: Deep Learning in Information Security Abstract: Machine learning has a long tradition of helping to solve complex information\nsecurity problems that are difficult to solve manually. Machine learning\ntechniques learn models from data representations to solve a task. These data\nrepresentations are hand-crafted by domain experts. Deep Learning is a\nsub-field of machine learning, which uses models that are composed of multiple\nlayers. Consequently, representations that are used to solve a task are learned\nfrom the data instead of being manually designed.\n  In this survey, we study the use of DL techniques within the domain of\ninformation security. We systematically reviewed 77 papers and presented them\nfrom a data-centric perspective. This data-centric perspective reflects one of\nthe most crucial advantages of DL techniques -- domain independence. If\nDL-methods succeed to solve problems on a data type in one domain, they most\nlikely will also succeed on similar data from another domain. Other advantages\nof DL methods are unrivaled scalability and efficiency, both regarding the\nnumber of examples that can be analyzed as well as with respect of\ndimensionality of the input data. DL methods generally are capable of achieving\nhigh-performance and generalize well.\n  However, information security is a domain with unique requirements and\nchallenges. Based on an analysis of our reviewed papers, we point out\nshortcomings of DL-methods to those requirements and discuss further research\nopportunities. \n\n"}
{"id": "1809.04583", "contents": "Title: Efficient and Privacy-preserving Voice-based Search over mHealth Data Abstract: In-home IoT devices play a major role in healthcare systems as smart personal\nassistants. They usually come with a voice-enabled feature to add an extra\nlevel of usability and convenience to elderly, disabled people, and patients.\nIn this paper, we propose an efficient and privacy-preserving voice-based\nsearch scheme to enhance the efficiency and the privacy of in-home healthcare\napplications. We consider an application scenario where patients use the\ndevices to record and upload their voice to servers and the caregivers search\nthe interested voices of their patient's based on the voice content, mood, tone\nand background sound. Our scheme preserves the richness and privacy of voice\ndata and enables accurate and efficient voice-based search, while in current\nsystems that use speech recognition the richness and privacy of voice data are\ncompromised. Specifically, our scheme achieves the privacy by employing a\nhomomorphic encryption; only encrypted voice data is uploaded to the server who\nis unable to access the original voice data. In addition, our scheme enables\nthe server to selectively and accurately respond to caregiver's queries on the\nvoice data based on voice's feature similarity. We evaluate our scheme through\nreal experiments and show that our scheme even with privacy preservation can\nsuccessfully match similar voice data at an average accuracy of 80.8%. \n\n"}
{"id": "1809.04693", "contents": "Title: An Online Plug-and-Play Algorithm for Regularized Image Reconstruction Abstract: Plug-and-play priors (PnP) is a powerful framework for regularizing imaging\ninverse problems by using advanced denoisers within an iterative algorithm.\nRecent experimental evidence suggests that PnP algorithms achieve\nstate-of-the-art performance in a range of imaging applications. In this paper,\nwe introduce a new online PnP algorithm based on the iterative\nshrinkage/thresholding algorithm (ISTA). The proposed algorithm uses only a\nsubset of measurements at every iteration, which makes it scalable to very\nlarge datasets. We present a new theoretical convergence analysis, for both\nbatch and online variants of PnP-ISTA, for denoisers that do not necessarily\ncorrespond to proximal operators. We also present simulations illustrating the\napplicability of the algorithm to image reconstruction in diffraction\ntomography. The results in this paper have the potential to expand the\napplicability of the PnP framework to very large and redundant datasets. \n\n"}
{"id": "1809.04774", "contents": "Title: Fidelius: Protecting User Secrets from Compromised Browsers Abstract: Users regularly enter sensitive data, such as passwords, credit card numbers,\nor tax information, into the browser window. While modern browsers provide\npowerful client-side privacy measures to protect this data, none of these\ndefenses prevent a browser compromised by malware from stealing it. In this\nwork, we present Fidelius, a new architecture that uses trusted hardware\nenclaves integrated into the browser to enable protection of user secrets\nduring web browsing sessions, even if the entire underlying browser and OS are\nfully controlled by a malicious attacker.\n  Fidelius solves many challenges involved in providing protection for browsers\nin a fully malicious environment, offering support for integrity and privacy\nfor form data, JavaScript execution, XMLHttpRequests, and protected web\nstorage, while minimizing the TCB. Moreover, interactions between the enclave\nand the browser, the keyboard, and the display all require new protocols, each\nwith their own security considerations. Finally, Fidelius takes into account UI\nconsiderations to ensure a consistent and simple interface for both developers\nand users.\n  As part of this project, we develop the first open source system that\nprovides a trusted path from input and output peripherals to a hardware enclave\nwith no reliance on additional hypervisor security assumptions. These\ncomponents may be of independent interest and useful to future projects.\n  We implement and evaluate Fidelius to measure its performance overhead,\nfinding that Fidelius imposes acceptable overhead on page load and user\ninteraction for secured pages and has no impact on pages and page components\nthat do not use its enhanced security features. \n\n"}
{"id": "1809.04786", "contents": "Title: Assessing the Effectiveness of Attack Detection at a Hackfest on\n  Industrial Control Systems Abstract: A hackfest named SWaT Security Showdown (S3) has been organized consecutively\nfor two years. S3 has enabled researchers and practitioners to assess the\neffectiveness of methods and products aimed at detecting cyber attacks launched\nin real-time on an operational water treatment plant, namely, Secure Water\nTreatment (SWaT). In S3 independent attack teams design and launch attacks on\nSWaT while defence teams protect the plant passively and raise alarms upon\nattack detection. Attack teams are scored according to how successful they are\nin performing attacks based on specific intents while the defense teams are\nscored based on the effectiveness of their methods to detect the attacks. This\npaper focuses on the first two instances of S3 and summarizes the benefits of\nhackfest and the performance of an attack detection mechanism, named Water\nDefense, that was exposed to attackers during S3. \n\n"}
{"id": "1809.04803", "contents": "Title: Pre- and post-quantum Diffie-Hellman from groups, actions, and isogenies Abstract: Diffie-Hellman key exchange is at the foundations of public-key cryptography,\nbut conventional group-based Diffie-Hellman is vulnerable to Shor's quantum\nalgorithm. A range of \"post-quantum Diffie-Hellman\" protocols have been\nproposed to mitigate this threat, including the Couveignes,\nRostovtsev-Stolbunov, SIDH, and CSIDH schemes, all based on the combinatorial\nand number-theoretic structures formed by isogenies of elliptic curves. Pre-and\npost-quantum Diffie-Hellman schemes resemble each other at the highest level,\nbut the further down we dive, the more differences emerge-differences that are\ncritical when we use Diffie-Hellman as a basic component in more complicated\nconstructions. In this survey we compare and contrast pre-and post-quantum\nDiffie-Hellman algorithms, highlighting some important subtleties. \n\n"}
{"id": "1809.05888", "contents": "Title: An investigation of a deep learning based malware detection system Abstract: We investigate a Deep Learning based system for malware detection. In the\ninvestigation, we experiment with different combination of Deep Learning\narchitectures including Auto-Encoders, and Deep Neural Networks with varying\nlayers over Malicia malware dataset on which earlier studies have obtained an\naccuracy of (98%) with an acceptable False Positive Rates (1.07%). But these\nresults were done using extensive man-made custom domain features and investing\ncorresponding feature engineering and design efforts. In our proposed approach,\nbesides improving the previous best results (99.21% accuracy and a False\nPositive Rate of 0.19%) indicates that Deep Learning based systems could\ndeliver an effective defense against malware. Since it is good in automatically\nextracting higher conceptual features from the data, Deep Learning based\nsystems could provide an effective, general and scalable mechanism for\ndetection of existing and unknown malware. \n\n"}
{"id": "1809.05889", "contents": "Title: Comparison of Deep Learning and the Classical Machine Learning Algorithm\n  for the Malware Detection Abstract: Recently, Deep Learning has been showing promising results in various\nArtificial Intelligence applications like image recognition, natural language\nprocessing, language modeling, neural machine translation, etc. Although, in\ngeneral, it is computationally more expensive as compared to classical machine\nlearning techniques, their results are found to be more effective in some\ncases. Therefore, in this paper, we investigated and compared one of the Deep\nLearning Architecture called Deep Neural Network (DNN) with the classical\nRandom Forest (RF) machine learning algorithm for the malware classification.\nWe studied the performance of the classical RF and DNN with 2, 4 & 7 layers\narchitectures with the four different feature sets, and found that irrespective\nof the features inputs, the classical RF accuracy outperforms the DNN. \n\n"}
{"id": "1809.06013", "contents": "Title: DASNet: Reducing Pixel-level Annotations for Instance and Semantic\n  Segmentation Abstract: Pixel-level annotation demands expensive human efforts and limits the\nperformance of deep networks that usually benefits from more such training\ndata. In this work we aim to achieve high quality instance and semantic\nsegmentation results over a small set of pixel-level mask annotations and a\nlarge set of box annotations. The basic idea is exploring detection models to\nsimplify the pixel-level supervised learning task and thus reduce the required\namount of mask annotations. Our architecture, named DASNet, consists of three\nmodules: detection, attention, and segmentation. The detection module detects\nall classes of objects, the attention module generates multi-scale\nclass-specific features, and the segmentation module recovers the binary masks.\nOur method demonstrates substantially improved performance compared to existing\nsemi-supervised approaches on PASCAL VOC 2012 dataset. \n\n"}
{"id": "1809.06023", "contents": "Title: Learning-based attacks in cyber-physical systems Abstract: We introduce the problem of learning-based attacks in a simple abstraction of\ncyber-physical systems---the case of a discrete-time, linear, time-invariant\nplant that may be subject to an attack that overrides the sensor readings and\nthe controller actions. The attacker attempts to learn the dynamics of the\nplant and subsequently override the controller's actuation signal, to destroy\nthe plant without being detected. The attacker can feed fictitious sensor\nreadings to the controller using its estimate of the plant dynamics and mimic\nthe legitimate plant operation. The controller, on the other hand, is\nconstantly on the lookout for an attack; once the controller detects an attack,\nit immediately shuts the plant off. In the case of scalar plants, we derive an\nupper bound on the attacker's deception probability for any measurable control\npolicy when the attacker uses an arbitrary learning algorithm to estimate the\nsystem dynamics. We then derive lower bounds for the attacker's deception\nprobability for both scalar and vector plants by assuming a specific\nauthentication test that inspects the empirical variance of the system\ndisturbance. We also show how the controller can improve the security of the\nsystem by superimposing a carefully crafted privacy-enhancing signal on top of\nthe \"nominal control policy.\" Finally, for nonlinear scalar dynamics that\nbelong to the Reproducing Kernel Hilbert Space (RKHS), we investigate the\nperformance of attacks based on nonlinear Gaussian-processes (GP) learning\nalgorithms. \n\n"}
{"id": "1809.06557", "contents": "Title: Image Super-Resolution via Deterministic-Stochastic Synthesis and Local\n  Statistical Rectification Abstract: Single image superresolution has been a popular research topic in the last\ntwo decades and has recently received a new wave of interest due to deep neural\nnetworks. In this paper, we approach this problem from a different perspective.\nWith respect to a downsampled low resolution image, we model a high resolution\nimage as a combination of two components, a deterministic component and a\nstochastic component. The deterministic component can be recovered from the\nlow-frequency signals in the downsampled image. The stochastic component, on\nthe other hand, contains the signals that have little correlation with the low\nresolution image. We adopt two complementary methods for generating these two\ncomponents. While generative adversarial networks are used for the stochastic\ncomponent, deterministic component reconstruction is formulated as a regression\nproblem solved using deep neural networks. Since the deterministic component\nexhibits clearer local orientations, we design novel loss functions tailored\nfor such properties for training the deep regression network. These two methods\nare first applied to the entire input image to produce two distinct\nhigh-resolution images. Afterwards, these two images are fused together using\nanother deep neural network that also performs local statistical rectification,\nwhich tries to make the local statistics of the fused image match the same\nlocal statistics of the groundtruth image. Quantitative results and a user\nstudy indicate that the proposed method outperforms existing state-of-the-art\nalgorithms with a clear margin. \n\n"}
{"id": "1809.06784", "contents": "Title: Adversarial Reinforcement Learning for Observer Design in Autonomous\n  Systems under Cyber Attacks Abstract: Complex autonomous control systems are subjected to sensor failures,\ncyber-attacks, sensor noise, communication channel failures, etc. that\nintroduce errors in the measurements. The corrupted information, if used for\nmaking decisions, can lead to degraded performance. We develop a framework for\nusing adversarial deep reinforcement learning to design observer strategies\nthat are robust to adversarial errors in information channels. We further show\nthrough simulation studies that the learned observation strategies perform\nremarkably well when the adversary's injected errors are bounded in some sense.\nWe use neural network as function approximator in our studies with the\nunderstanding that any other suitable function approximating class can be used\nwithin our framework. \n\n"}
{"id": "1809.06925", "contents": "Title: Security and Protocol Exploit Analysis of the 5G Specifications Abstract: The Third Generation Partnership Project (3GPP) released its first 5G\nsecurity specifications in March 2018. This paper reviews the 5G security\narchitecture, requirements and main processes and evaluates them in the context\nof known and new protocol exploits. Although the security has been enhanced\nwhen compared to previous generations to tackle known protocol exploits, our\nanalysis identifies some potentially unrealistic system assumptions that are\ncritical for security as well as a number protocol edge cases that could render\n5G systems vulnerable to adversarial attacks. For example, null encryption and\nnull authentication are supported and can be used in valid system\nconfigurations, and certain key security functions are still left outside of\nthe scope of the specifications. Moreover, the prevention of pre-authentcation\nmessage exploits appears to rely on the implicit assumption of impractical\ncarrier and roaming agreements and the management of public keys from all\nglobal operators. In parallel, existing threats such as International Mobile\nSubscriber Identity (IMSI) catchers are prevented only if the serving network\nenforces optional security features and if the UE knows the public key of the\nhome network operator. The comparison with 4G LTE protocol exploits reveals\nthat the 5G security specifications, as of Release 15, do not fully address the\nuser privacy and network availability concerns, where one edge case can\ncompromise the privacy, security and availability of 5G users and services. \n\n"}
{"id": "1809.06962", "contents": "Title: Program Analysis of Commodity IoT Applications for Security and Privacy:\n  Challenges and Opportunities Abstract: Recent advances in Internet of Things (IoT) have enabled myriad domains such\nas smart homes, personal monitoring devices, and enhanced manufacturing. IoT is\nnow pervasive---new applications are being used in nearly every conceivable\nenvironment, which leads to the adoption of device-based interaction and\nautomation. However, IoT has also raised issues about the security and privacy\nof these digitally augmented spaces. Program analysis is crucial in identifying\nthose issues, yet the application and scope of program analysis in IoT remains\nlargely unexplored by the technical community. In this paper, we study privacy\nand security issues in IoT that require program-analysis techniques with an\nemphasis on identified attacks against these systems and defenses implemented\nso far. Based on a study of five IoT programming platforms, we identify the key\ninsights that result from research efforts in both the program analysis and\nsecurity communities and relate the efficacy of program-analysis techniques to\nsecurity and privacy issues. We conclude by studying recent IoT analysis\nsystems and exploring their implementations. Through these explorations, we\nhighlight key challenges and opportunities in calibrating for the environments\nin which IoT systems will be used. \n\n"}
{"id": "1809.07221", "contents": "Title: Exploring the Impact of Password Dataset Distribution on Guessing Abstract: Leaks from password datasets are a regular occurrence. An organization may\ndefend a leak with reassurances that just a small subset of passwords were\ntaken. In this paper we show that the leak of a relatively small number of\ntext-based passwords from an organizations' stored dataset can lead to a\nfurther large collection of users being compromised. Taking a sample of\npasswords from a given dataset of passwords we exploit the knowledge we gain of\nthe distribution to guess other samples from the same dataset. We show\ntheoretically and empirically that the distribution of passwords in the sample\nfollows the same distribution as the passwords in the whole dataset. We propose\na function that measures the ability of one distribution to estimate another.\nLeveraging this we show that a sample of passwords leaked from a given dataset,\nwill compromise the remaining passwords in that dataset better than a sample\nleaked from another source. \n\n"}
{"id": "1809.07655", "contents": "Title: Designing a blockchain-based IoT infrastructure with Ethereum, Swarm and\n  LoRa Abstract: Today, the number of IoT devices in all aspects of life is exponentially\nincreasing. The cities we are living in are getting smarter and informing us\nabout our surroundings in a contextual manner. However, there lay significant\nchallenges of deploying, managing and collecting data from these devices, in\naddition to the problem of storing and mining that data for higher-quality IoT\nservices. Blockchain technology, even in today's nascent form, contains the\npillars to create a common, distributed, trustless and autonomous\ninfrastructure system. This paper describes a standardized IoT infrastructure;\nwhere data is stored on a DDOS-resistant, fault-tolerant, distributed storage\nservice and data access is managed by a decentralized, trustless blockchain.\nThe illustrated system used LoRa as the emerging network technology, Swarm as\nthe distributed data storage and Ethereum as the blockchain platform. Such a\ndata backend will ensure high availability with minimal security risks while\nreplacing traditional backend systems with a single \"smart contract\". \n\n"}
{"id": "1809.08316", "contents": "Title: Adversarial Binaries for Authorship Identification Abstract: Binary code authorship identification determines authors of a binary program.\nExisting techniques have used supervised machine learning for this task. In\nthis paper, we look this problem from an attacker's perspective. We aim to\nmodify a test binary, such that it not only causes misprediction but also\nmaintains the functionality of the original input binary. Attacks against\nbinary code are intrinsically more difficult than attacks against domains such\nas computer vision, where attackers can change each pixel of the input image\nindependently and still maintain a valid image. For binary code, even flipping\none bit of a binary may cause the binary to be invalid, to crash at the\nrun-time, or to lose the original functionality. We investigate two types of\nattacks: untargeted attacks, causing misprediction to any of the incorrect\nauthors, and targeted attacks, causing misprediction to a specific one among\nthe incorrect authors. We develop two key attack capabilities: feature vector\nmodification, generating an adversarial feature vector that both corresponds to\na real binary and causes the required misprediction, and input binary\nmodification, modifying the input binary to match the adversarial feature\nvector while maintaining the functionality of the input binary. We evaluated\nour attack against classifiers trained with a state-of-the-art method for\nauthorship attribution. The classifiers for authorship identification have 91%\naccuracy on average. Our untargeted attack has a 96% success rate on average,\nshowing that we can effectively suppress authorship signal. Our targeted attack\nhas a 46% success rate on average, showing that it is possible, but\nsignificantly more difficult to impersonate a specific programmer's style. Our\nattack reveals that existing binary code authorship identification techniques\nrely on code features that are easy to modify, and thus are vulnerable to\nattacks. \n\n"}
{"id": "1809.08387", "contents": "Title: Towards Secure Blockchain-enabled Internet of Vehicles: Optimizing\n  Consensus Management Using Reputation and Contract Theory Abstract: In Internet of Vehicles (IoV), data sharing among vehicles is essential to\nimprove driving safety and enhance vehicular services. To ensure data sharing\nsecurity and traceability, highefficiency Delegated Proof-of-Stake consensus\nscheme as a hard security solution is utilized to establish blockchain-enabled\nIoV (BIoV). However, as miners are selected from miner candidates by\nstake-based voting, it is difficult to defend against voting collusion between\nthe candidates and compromised high-stake vehicles, which introduces serious\nsecurity challenges to the BIoV. To address such challenges, we propose a soft\nsecurity enhancement solution including two stages: (i) miner selection and\n(ii) block verification. In the first stage, a reputation-based voting scheme\nfor the blockchain is proposed to ensure secure miner selection. This scheme\nevaluates candidates' reputation by using both historical interactions and\nrecommended opinions from other vehicles. The candidates with high reputation\nare selected to be active miners and standby miners. In the second stage, to\nprevent internal collusion among the active miners, a newly generated block is\nfurther verified and audited by the standby miners. To incentivize the standby\nminers to participate in block verification, we formulate interactions between\nthe active miners and the standby miners by using contract theory, which takes\nblock verification security and delay into consideration. Numerical results\nbased on a real-world dataset indicate that our schemes are secure and\nefficient for data sharing in BIoV. \n\n"}
{"id": "1809.08479", "contents": "Title: DeepOrigin: End-to-End Deep Learning for Detection of New Malware\n  Families Abstract: In this paper, we present a novel method of differentiating known from\npreviously unseen malware families. We utilize transfer learning by learning\ncompact file representations that are used for a new classification task\nbetween previously seen malware families and novel ones. The learned file\nrepresentations are composed of static and dynamic features of malware and are\ninvariant to small modifications that do not change their malicious\nfunctionality. Using an extensive dataset that consists of thousands of\nvariants of malicious files, we were able to achieve 97.7% accuracy when\nclassifying between seen and unseen malware families. Our method provides an\nimportant focalizing tool for cybersecurity researchers and greatly improves\nthe overall ability to adapt to the fast-moving pace of the current threat\nlandscape. \n\n"}
{"id": "1809.08514", "contents": "Title: Fundamental Limits of Invisible Flow Fingerprinting Abstract: Network flow fingerprinting can be used to de-anonymize communications on\nanonymity systems such as Tor by linking the ingress and egress segments of\nanonymized connections. Assume Alice and Bob have access to the input and the\noutput links of an anonymous network, respectively, and they wish to\ncollaboratively reveal the connections between the input and the output links\nwithout being detected by Willie who protects the network. Alice generates a\ncodebook of fingerprints, where each fingerprint corresponds to a unique\nsequence of inter-packet delays and shares it only with Bob. For each input\nflow, she selects a fingerprint from the codebook and embeds it in the flow,\ni.e., changes the packet timings of the flow to follow the packet timings\nsuggested by the fingerprint, and Bob extracts the fingerprints from the output\nflows. We model the network as parallel $M/M/1$ queues where each queue is\nshared by a flow from Alice to Bob and other flows independent of the flow from\nAlice to Bob. The timings of the flows are governed by independent Poisson\npoint processes. Assuming all input flows have equal rates and that Bob\nobserves only flows with fingerprints, we first present two scenarios: 1) Alice\nfingerprints all the flows; 2) Alice fingerprints a subset of the flows,\nunknown to Willie. Then, we extend the construction and analysis to the case\nwhere flow rates are arbitrary as well as the case where not all the flows that\nBob observes have a fingerprint. For each scenario, we derive the number of\nflows that Alice can fingerprint and Bob can trace by fingerprinting. \n\n"}
{"id": "1809.08811", "contents": "Title: Pointing in the Right Direction - Securing Memory Accesses in a Faulty\n  World Abstract: Reading and writing memory are, besides computation, the most common\noperations a processor performs. The correctness of these operations is\ntherefore essential for the proper execution of any program. However, as soon\nas fault attacks are considered, assuming that the hardware performs its memory\noperations as instructed is not valid anymore. In particular, attackers may\ninduce faults with the goal of reading or writing incorrectly addressed memory,\nwhich can have various critical safety and security implications.\n  In this work, we present a solution to this problem and propose a new method\nfor protecting every memory access inside a program against address tampering.\nThe countermeasure comprises two building blocks. First, every pointer inside\nthe program is redundantly encoded using a multi-residue error detection code.\nThe redundancy information is stored in the unused upper bits of the pointer\nwith zero overhead in terms of storage. Second, load and store instructions are\nextended to link data with the corresponding encoded address from the pointer.\nWrong memory accesses subsequently infect the data value allowing the software\nto detect the error.\n  For evaluation purposes, we implemented our countermeasure into a RISC-V\nprocessor, tested it on a FPGA development board, and evaluated the induced\noverhead. Furthermore, a LLVM-based C compiler has been modified to\nautomatically encode all data pointers, to perform encoded pointer arithmetic,\nand to emit the extended load/store instructions with linking support. Our\nevaluations show that the countermeasure induces an average overhead of 10% in\nterms of code size and 7% regarding runtime, which makes it suitable for\npractical adoption. \n\n"}
{"id": "1809.08986", "contents": "Title: On The Utility of Conditional Generation Based Mutual Information for\n  Characterizing Adversarial Subspaces Abstract: Recent studies have found that deep learning systems are vulnerable to\nadversarial examples; e.g., visually unrecognizable adversarial images can\neasily be crafted to result in misclassification. The robustness of neural\nnetworks has been studied extensively in the context of adversary detection,\nwhich compares a metric that exhibits strong discriminate power between natural\nand adversarial examples. In this paper, we propose to characterize the\nadversarial subspaces through the lens of mutual information (MI) approximated\nby conditional generation methods. We use MI as an information-theoretic metric\nto strengthen existing defenses and improve the performance of adversary\ndetection. Experimental results on MagNet defense demonstrate that our proposed\nMI detector can strengthen its robustness against powerful adversarial attacks. \n\n"}
{"id": "1809.08999", "contents": "Title: Fast Geometrically-Perturbed Adversarial Faces Abstract: The state-of-the-art performance of deep learning algorithms has led to a\nconsiderable increase in the utilization of machine learning in\nsecurity-sensitive and critical applications. However, it has recently been\nshown that a small and carefully crafted perturbation in the input space can\ncompletely fool a deep model. In this study, we explore the extent to which\nface recognition systems are vulnerable to geometrically-perturbed adversarial\nfaces. We propose a fast landmark manipulation method for generating\nadversarial faces, which is approximately 200 times faster than the previous\ngeometric attacks and obtains 99.86% success rate on the state-of-the-art face\nrecognition models. To further force the generated samples to be natural, we\nintroduce a second attack constrained on the semantic structure of the face\nwhich has the half speed of the first attack with the success rate of 99.96%.\nBoth attacks are extremely robust against the state-of-the-art defense methods\nwith the success rate of equal or greater than 53.59%. Code is available at\nhttps://github.com/alldbi/FLM \n\n"}
{"id": "1809.09262", "contents": "Title: Neural Networks with Structural Resistance to Adversarial Attacks Abstract: In adversarial attacks to machine-learning classifiers, small perturbations\nare added to input that is correctly classified. The perturbations yield\nadversarial examples, which are virtually indistinguishable from the\nunperturbed input, and yet are misclassified. In standard neural networks used\nfor deep learning, attackers can craft adversarial examples from most input to\ncause a misclassification of their choice.\n  We introduce a new type of network units, called RBFI units, whose non-linear\nstructure makes them inherently resistant to adversarial attacks. On\npermutation-invariant MNIST, in absence of adversarial attacks, networks using\nRBFI units match the performance of networks using sigmoid units, and are\nslightly below the accuracy of networks with ReLU units. When subjected to\nadversarial attacks, networks with RBFI units retain accuracies above 90% for\nattacks that degrade the accuracy of networks with ReLU or sigmoid units to\nbelow 2%. RBFI networks trained with regular input are superior in their\nresistance to adversarial attacks even to ReLU and sigmoid networks trained\nwith the help of adversarial examples.\n  The non-linear structure of RBFI units makes them difficult to train using\nstandard gradient descent. We show that networks of RBFI units can be\nefficiently trained to high accuracies using pseudogradients, computed using\nfunctions especially crafted to facilitate learning instead of their true\nderivatives. We show that the use of pseudogradients makes training deep RBFI\nnetworks practical, and we compare several structural alternatives of RBFI\nnetworks for their accuracy. \n\n"}
{"id": "1809.09805", "contents": "Title: Towards Safer Smart Contracts: A Survey of Languages and Verification\n  Methods Abstract: With a market capitalisation of over USD 205 billion in just under ten years,\npublic distributed ledgers have experienced significant adoption. Apart from\nnovel consensus mechanisms, their success is also accountable to smart\ncontracts. These programs allow distrusting parties to enter agreements that\nare executed autonomously. However, implementation issues in smart contracts\ncaused severe losses to the users of such contracts. Significant efforts are\ntaken to improve their security by introducing new programming languages and\nadvance verification methods. We provide a survey of those efforts in two\nparts. First, we introduce several smart contract languages focussing on\nsecurity features. To that end, we present an overview concerning paradigm,\ntype, instruction set, semantics, and metering. Second, we examine verification\ntools and methods for smart contract and distributed ledgers. Accordingly, we\nintroduce their verification approach, level of automation, coverage, and\nsupported languages. Last, we present future research directions including\nformal semantics, verified compilers, and automated verification. \n\n"}
{"id": "1809.10244", "contents": "Title: Autonomously and Simultaneously Refining Deep Neural Network Parameters\n  by a Bi-Generative Adversarial Network Aided Genetic Algorithm Abstract: The choice of parameters, and the design of the network architecture are\nimportant factors affecting the performance of deep neural networks. Genetic\nAlgorithms (GA) have been used before to determine parameters of a network.\nYet, GAs perform a finite search over a discrete set of pre-defined candidates,\nand cannot, in general, generate unseen configurations. In this paper, to move\nfrom exploration to exploitation, we propose a novel and systematic method that\nautonomously and simultaneously optimizes multiple parameters of any deep\nneural network by using a GA aided by a bi-generative adversarial network\n(Bi-GAN). The proposed Bi-GAN allows the autonomous exploitation and choice of\nthe number of neurons, for fully-connected layers, and number of filters, for\nconvolutional layers, from a large range of values. Our proposed Bi-GAN\ninvolves two generators, and two different models compete and improve each\nother progressively with a GAN-based strategy to optimize the networks during\nGA evolution. Our proposed approach can be used to autonomously refine the\nnumber of convolutional layers and dense layers, number and size of kernels,\nand the number of neurons for the dense layers; choose the type of the\nactivation function; and decide whether to use dropout and batch normalization\nor not, to improve the accuracy of different deep neural network architectures.\nWithout loss of generality, the proposed method has been tested with the\nModelNet database, and compared with the 3D Shapenets and two GA-only methods.\nThe results show that the presented approach can simultaneously and\nsuccessfully optimize multiple neural network parameters, and achieve higher\naccuracy even with shallower networks. \n\n"}
{"id": "1809.10875", "contents": "Title: Characterizing Audio Adversarial Examples Using Temporal Dependency Abstract: Recent studies have highlighted adversarial examples as a ubiquitous threat\nto different neural network models and many downstream applications.\nNonetheless, as unique data properties have inspired distinct and powerful\nlearning principles, this paper aims to explore their potentials towards\nmitigating adversarial inputs. In particular, our results reveal the importance\nof using the temporal dependency in audio data to gain discriminate power\nagainst adversarial examples. Tested on the automatic speech recognition (ASR)\ntasks and three recent audio adversarial attacks, we find that (i) input\ntransformation developed from image adversarial defense provides limited\nrobustness improvement and is subtle to advanced attacks; (ii) temporal\ndependency can be exploited to gain discriminative power against audio\nadversarial examples and is resistant to adaptive attacks considered in our\nexperiments. Our results not only show promising means of improving the\nrobustness of ASR systems, but also offer novel insights in exploiting\ndomain-specific data properties to mitigate negative effects of adversarial\nexamples. \n\n"}
{"id": "1810.00024", "contents": "Title: Explainable Black-Box Attacks Against Model-based Authentication Abstract: Establishing unique identities for both humans and end systems has been an\nactive research problem in the security community, giving rise to innovative\nmachine learning-based authentication techniques. Although such techniques\noffer an automated method to establish identity, they have not been vetted\nagainst sophisticated attacks that target their core machine learning\ntechnique. This paper demonstrates that mimicking the unique signatures\ngenerated by host fingerprinting and biometric authentication systems is\npossible. We expose the ineffectiveness of underlying machine learning\nclassification models by constructing a blind attack based around the query\nsynthesis framework and utilizing Explainable-AI (XAI) techniques. We launch an\nattack in under 130 queries on a state-of-the-art face authentication system,\nand under 100 queries on a host authentication system. We examine how these\nattacks can be defended against and explore their limitations. XAI provides an\neffective means for adversaries to infer decision boundaries and provides a new\nway forward in constructing attacks against systems using machine learning\nmodels for authentication. \n\n"}
{"id": "1810.00329", "contents": "Title: An Overview of Blockchain Integration with Robotics and Artificial\n  Intelligence Abstract: Blockchain technology is growing everyday at a fast-passed rhythm and it's\npossible to integrate it with many systems, namely Robotics with AI services.\nHowever, this is still a recent field and there isn't yet a clear understanding\nof what it could potentially become. In this paper, we conduct an overview of\nmany different methods and platforms that try to leverage the power of\nblockchain into robotic systems, to improve AI services or to solve problems\nthat are present in the major blockchains, which can lead to the ability of\ncreating robotic systems with increased capabilities and security. We present\nan overview, discuss the methods and conclude the paper with our view on the\nfuture of the integration of these technologies. \n\n"}
{"id": "1810.00551", "contents": "Title: Generative Adversarial Network for Medical Images (MI-GAN) Abstract: Deep learning algorithms produces state-of-the-art results for different\nmachine learning and computer vision tasks. To perform well on a given task,\nthese algorithms require large dataset for training. However, deep learning\nalgorithms lack generalization and suffer from over-fitting whenever trained on\nsmall dataset, especially when one is dealing with medical images. For\nsupervised image analysis in medical imaging, having image data along with\ntheir corresponding annotated ground-truths is costly as well as time consuming\nsince annotations of the data is done by medical experts manually. In this\npaper, we propose a new Generative Adversarial Network for Medical Imaging\n(MI-GAN). The MI-GAN generates synthetic medical images and their segmented\nmasks, which can then be used for the application of supervised analysis of\nmedical images. Particularly, we present MI-GAN for synthesis of retinal\nimages. The proposed method generates precise segmented images better than the\nexisting techniques. The proposed model achieves a dice coefficient of 0.837 on\nSTARE dataset and 0.832 on DRIVE dataset which is state-of-the-art performance\non both the datasets. \n\n"}
{"id": "1810.00953", "contents": "Title: Improved robustness to adversarial examples using Lipschitz\n  regularization of the loss Abstract: We augment adversarial training (AT) with worst case adversarial training\n(WCAT) which improves adversarial robustness by 11% over the current\nstate-of-the-art result in the $\\ell_2$ norm on CIFAR-10. We obtain verifiable\naverage case and worst case robustness guarantees, based on the expected and\nmaximum values of the norm of the gradient of the loss. We interpret\nadversarial training as Total Variation Regularization, which is a fundamental\ntool in mathematical image processing, and WCAT as Lipschitz regularization. \n\n"}
{"id": "1810.01032", "contents": "Title: Reinforcement Learning with Perturbed Rewards Abstract: Recent studies have shown that reinforcement learning (RL) models are\nvulnerable in various noisy scenarios. For instance, the observed reward\nchannel is often subject to noise in practice (e.g., when rewards are collected\nthrough sensors), and is therefore not credible. In addition, for applications\nsuch as robotics, a deep reinforcement learning (DRL) algorithm can be\nmanipulated to produce arbitrary errors by receiving corrupted rewards. In this\npaper, we consider noisy RL problems with perturbed rewards, which can be\napproximated with a confusion matrix. We develop a robust RL framework that\nenables agents to learn in noisy environments where only perturbed rewards are\nobserved. Our solution framework builds on existing RL/DRL algorithms and\nfirstly addresses the biased noisy reward setting without any assumptions on\nthe true distribution (e.g., zero-mean Gaussian noise as made in previous\nworks). The core ideas of our solution include estimating a reward confusion\nmatrix and defining a set of unbiased surrogate rewards. We prove the\nconvergence and sample complexity of our approach. Extensive experiments on\ndifferent DRL platforms show that trained policies based on our estimated\nsurrogate reward can achieve higher expected rewards, and converge faster than\nexisting baselines. For instance, the state-of-the-art PPO algorithm is able to\nobtain 84.6% and 80.8% improvements on average score for five Atari games, with\nerror rates as 10% and 30% respectively. \n\n"}
{"id": "1810.01086", "contents": "Title: A framework for generalized group testing with inhibitors and its\n  potential application in neuroscience Abstract: The main goal of group testing with inhibitors (GTI) is to efficiently\nidentify a small number of defective items and inhibitor items in a large set\nof items. A test on a subset of items is positive if the subset satisfies some\nspecific properties. Inhibitor items cancel the effects of defective items,\nwhich often make the outcome of a test containing defective items negative.\nDifferent GTI models can be formulated by considering how specific properties\nhave different cancellation effects. This work introduces generalized GTI\n(GGTI) in which a new type of items is added, i.e., hybrid items. A hybrid item\nplays the roles of both defectives items and inhibitor items. Since the number\nof instances of GGTI is large (more than 7 million), we introduce a framework\nfor classifying all types of items non-adaptively, i.e., all tests are designed\nin advance. We then explain how GGTI can be used to classify neurons in\nneuroscience. Finally, we show how to realize our proposed scheme in practice. \n\n"}
{"id": "1810.01407", "contents": "Title: Can Adversarially Robust Learning Leverage Computational Hardness? Abstract: Making learners robust to adversarial perturbation at test time (i.e.,\nevasion attacks) or training time (i.e., poisoning attacks) has emerged as a\nchallenging task. It is known that for some natural settings, sublinear\nperturbations in the training phase or the testing phase can drastically\ndecrease the quality of the predictions. These negative results, however, are\ninformation theoretic and only prove the existence of such successful\nadversarial perturbations. A natural question for these settings is whether or\nnot we can make classifiers computationally robust to polynomial-time attacks.\n  In this work, we prove strong barriers against achieving such envisioned\ncomputational robustness both for evasion and poisoning attacks. In particular,\nwe show that if the test instances come from a product distribution (e.g.,\nuniform over $\\{0,1\\}^n$ or $[0,1]^n$, or isotropic $n$-variate Gaussian) and\nthat there is an initial constant error, then there exists a polynomial-time\nattack that finds adversarial examples of Hamming distance $O(\\sqrt n)$. For\npoisoning attacks, we prove that for any learning algorithm with sample\ncomplexity $m$ and any efficiently computable \"predicate\" defining some \"bad\"\nproperty $B$ for the produced hypothesis (e.g., failing on a particular test)\nthat happens with an initial constant probability, there exist polynomial-time\nonline poisoning attacks that tamper with $O (\\sqrt m)$ many examples, replace\nthem with other correctly labeled examples, and increases the probability of\nthe bad event $B$ to $\\approx 1$.\n  Both of our poisoning and evasion attacks are black-box in how they access\ntheir corresponding components of the system (i.e., the hypothesis, the\nconcept, and the learning algorithm) and make no further assumptions about the\nclassifier or the learning algorithm producing the classifier. \n\n"}
{"id": "1810.02023", "contents": "Title: Detecting DGA domains with recurrent neural networks and side\n  information Abstract: Modern malware typically makes use of a domain generation algorithm (DGA) to\navoid command and control domains or IPs being seized or sinkholed. This means\nthat an infected system may attempt to access many domains in an attempt to\ncontact the command and control server. Therefore, the automatic detection of\nDGA domains is an important task, both for the sake of blocking malicious\ndomains and identifying compromised hosts. However, many DGAs use English\nwordlists to generate plausibly clean-looking domain names; this makes\nautomatic detection difficult. In this work, we devise a notion of difficulty\nfor DGA families called the smashword score; this measures how much a DGA\nfamily looks like English words. We find that this measure accurately reflects\nhow much a DGA family's domains look like they are made from natural English\nwords. We then describe our new modeling approach, which is a combination of a\nnovel recurrent neural network architecture with domain registration side\ninformation. Our experiments show the model is capable of effectively\nidentifying domains generated by difficult DGA families. Our experiments also\nshow that our model outperforms existing approaches, and is able to reliably\ndetect difficult DGA families such as matsnu, suppobox, rovnix, and others. The\nmodel's performance compared to the state of the art is best for DGA families\nthat resemble English words. We believe that this model could either be used in\na standalone DGA domain detector---such as an endpoint security\napplication---or alternately the model could be used as a part of a larger\nmalware detection system. \n\n"}
{"id": "1810.02183", "contents": "Title: Revealing Network Structure, Confidentially: Improved Rates for\n  Node-Private Graphon Estimation Abstract: Motivated by growing concerns over ensuring privacy on social networks, we\ndevelop new algorithms and impossibility results for fitting complex\nstatistical models to network data subject to rigorous privacy guarantees. We\nconsider the so-called node-differentially private algorithms, which compute\ninformation about a graph or network while provably revealing almost no\ninformation about the presence or absence of a particular node in the graph.\n  We provide new algorithms for node-differentially private estimation for a\npopular and expressive family of network models: stochastic block models and\ntheir generalization, graphons. Our algorithms improve on prior work, reducing\ntheir error quadratically and matching, in many regimes, the optimal nonprivate\nalgorithm. We also show that for the simplest random graph models ($G(n,p)$ and\n$G(n,m)$), node-private algorithms can be qualitatively more accurate than for\nmore complex models---converging at a rate of $\\frac{1}{\\epsilon^2 n^{3}}$\ninstead of $\\frac{1}{\\epsilon^2 n^2}$. This result uses a new extension lemma\nfor differentially private algorithms that we hope will be broadly useful. \n\n"}
{"id": "1810.03197", "contents": "Title: Recycled ADMM: Improve Privacy and Accuracy with Less Computation in\n  Distributed Algorithms Abstract: Alternating direction method of multiplier (ADMM) is a powerful method to\nsolve decentralized convex optimization problems. In distributed settings, each\nnode performs computation with its local data and the local results are\nexchanged among neighboring nodes in an iterative fashion. During this\niterative process the leakage of data privacy arises and can accumulate\nsignificantly over many iterations, making it difficult to balance the\nprivacy-utility tradeoff. In this study we propose Recycled ADMM (R-ADMM),\nwhere a linear approximation is applied to every even iteration, its solution\ndirectly calculated using only results from the previous, odd iteration. It\nturns out that under such a scheme, half of the updates incur no privacy loss\nand require much less computation compared to the conventional ADMM. We obtain\na sufficient condition for the convergence of R-ADMM and provide the privacy\nanalysis based on objective perturbation. \n\n"}
{"id": "1810.03487", "contents": "Title: Security Analysis of Deep Neural Networks Operating in the Presence of\n  Cache Side-Channel Attacks Abstract: Recent work has introduced attacks that extract the architecture information\nof deep neural networks (DNN), as this knowledge enhances an adversary's\ncapability to conduct black-box attacks against the model. This paper presents\nthe first in-depth security analysis of DNN fingerprinting attacks that exploit\ncache side-channels. First, we define the threat model for these attacks: our\nadversary does not need the ability to query the victim model; instead, she\nruns a co-located process on the host machine victim's deep learning (DL)\nsystem is running and passively monitors the accesses of the target functions\nin the shared framework. Second, we introduce DeepRecon, an attack that\nreconstructs the architecture of the victim network by using the internal\ninformation extracted via Flush+Reload, a cache side-channel technique. Once\nthe attacker observes function invocations that map directly to architecture\nattributes of the victim network, the attacker can reconstruct the victim's\nentire network architecture. In our evaluation, we demonstrate that an attacker\ncan accurately reconstruct two complex networks (VGG19 and ResNet50) having\nobserved only one forward propagation. Based on the extracted architecture\nattributes, we also demonstrate that an attacker can build a meta-model that\naccurately fingerprints the architecture and family of the pre-trained model in\na transfer learning setting. From this meta-model, we evaluate the importance\nof the observed attributes in the fingerprinting process. Third, we propose and\nevaluate new framework-level defense techniques that obfuscate our attacker's\nobservations. Our empirical security analysis represents a step toward\nunderstanding the DNNs' vulnerability to cache side-channel attacks. \n\n"}
{"id": "1810.03510", "contents": "Title: Fundamental Limits of Covert Bit Insertion in Packets Abstract: Covert communication is necessary when revealing the mere existence of a\nmessage leaks sensitive information to an attacker. Consider a network link\nwhere an authorized transmitter Jack sends packets to an authorized receiver\nSteve, and the packets visit Alice, Willie, and Bob, respectively, before they\nreach Steve. Covert transmitter Alice wishes to alter the packet stream in some\nway to send information to covert receiver Bob without watchful and capable\nadversary Willie being able to detect the presence of the message. In our\nprevious works, we addressed two techniques for such covert transmission from\nAlice to Bob: packet insertion and packet timing. In this paper, we consider\ncovert communication via bit insertion in packets with available space (e.g.,\nwith size less than the maximum transmission unit). We consider three\nscenarios: 1) packet sizes are independent and identically distributed (i.i.d.)\nwith a probability mass function (pmf) whose support is a set of one bit spaced\nvalues; 2) packet sizes are i.i.d. with a pmf whose support is arbitrary; 3)\npacket sizes may be dependent. For the first and second assumptions, we show\nthat Alice can covertly insert $\\mathcal{O}(\\sqrt{n})$ bits of information in a\nflow of $n$ packets; conversely, if she inserts $\\omega(\\sqrt{n})$ bits of\ninformation, Willie can detect her with arbitrarily small error probability.\nFor the third assumption, we prove Alice can covertly insert on average\n$\\mathcal{O}(c(n)/\\sqrt{n})$ bits in a sequence of $n$ packets, where $c(n)$ is\nthe average number of conditional pmf of packet sizes given the history, with a\nsupport of at least size two. \n\n"}
{"id": "1810.05512", "contents": "Title: Federated Learning for Keyword Spotting Abstract: We propose a practical approach based on federated learning to solve\nout-of-domain issues with continuously running embedded speech-based models\nsuch as wake word detectors. We conduct an extensive empirical study of the\nfederated averaging algorithm for the \"Hey Snips\" wake word based on a\ncrowdsourced dataset that mimics a federation of wake word users. We\nempirically demonstrate that using an adaptive averaging strategy inspired from\nAdam in place of standard weighted model averaging highly reduces the number of\ncommunication rounds required to reach our target performance. The associated\nupstream communication costs per user are estimated at 8 MB, which is a\nreasonable in the context of smart home voice assistants. Additionally, the\ndataset used for these experiments is being open sourced with the aim of\nfostering further transparent research in the application of federated learning\nto speech data. \n\n"}
{"id": "1810.06323", "contents": "Title: Compressively Sensed Image Recognition Abstract: Compressive Sensing (CS) theory asserts that sparse signal reconstruction is\npossible from a small number of linear measurements. Although CS enables\nlow-cost linear sampling, it requires non-linear and costly reconstruction.\nRecent literature works show that compressive image classification is possible\nin CS domain without reconstruction of the signal. In this work, we introduce a\nDCT base method that extracts binary discriminative features directly from CS\nmeasurements. These CS measurements can be obtained by using (i) a random or a\npseudo-random measurement matrix, or (ii) a measurement matrix whose elements\nare learned from the training data to optimize the given classification task.\nWe further introduce feature fusion by concatenating Bag of Words (BoW)\nrepresentation of our binary features with one of the two state-of-the-art\nCNN-based feature vectors. We show that our fused feature outperforms the\nstate-of-the-art in both cases. \n\n"}
{"id": "1810.07248", "contents": "Title: ReDMark: Framework for Residual Diffusion Watermarking on Deep Networks Abstract: Due to the rapid growth of machine learning tools and specifically deep\nnetworks in various computer vision and image processing areas, application of\nConvolutional Neural Networks for watermarking have recently emerged. In this\npaper, we propose a deep end-to-end diffusion watermarking framework (ReDMark)\nwhich can be adapted for any desired transform space. The framework is composed\nof two Fully Convolutional Neural Networks with the residual structure for\nembedding and extraction. The whole deep network is trained end-to-end to\nconduct a blind secure watermarking. The framework is customizable for the\nlevel of robustness vs. imperceptibility. It is also adjustable for the\ntrade-off between capacity and robustness. The proposed framework simulates\nvarious attacks as a differentiable network layer to facilitate end-to-end\ntraining. For JPEG attack, a differentiable approximation is utilized, which\ndrastically improves the watermarking robustness to this attack. Another\nimportant characteristic of the proposed framework, which leads to improved\nsecurity and robustness, is its capability to diffuse watermark information\namong a relatively wide area of the image. Comparative results versus recent\nstate-of-the-art researches highlight the superiority of the proposed framework\nin terms of imperceptibility and robustness. \n\n"}
{"id": "1810.07652", "contents": "Title: Fine-tuning on Clean Data for End-to-End Speech Translation: FBK @ IWSLT\n  2018 Abstract: This paper describes FBK's submission to the end-to-end English-German speech\ntranslation task at IWSLT 2018. Our system relies on a state-of-the-art model\nbased on LSTMs and CNNs, where the CNNs are used to reduce the temporal\ndimension of the audio input, which is in general much higher than machine\ntranslation input. Our model was trained only on the audio-to-text parallel\ndata released for the task, and fine-tuned on cleaned subsets of the original\ntraining corpus. The addition of weight normalization and label smoothing\nimproved the baseline system by 1.0 BLEU point on our validation set. The final\nsubmission also featured checkpoint averaging within a training run and\nensemble decoding of models trained during multiple runs. On test data, our\nbest single model obtained a BLEU score of 9.7, while the ensemble obtained a\nBLEU score of 10.24. \n\n"}
{"id": "1810.08092", "contents": "Title: Deconstructing the Blockchain to Approach Physical Limits Abstract: Transaction throughput, confirmation latency and confirmation reliability are\nfundamental performance measures of any blockchain system in addition to its\nsecurity. In a decentralized setting, these measures are limited by two\nunderlying physical network attributes: communication capacity and\nspeed-of-light propagation delay. Existing systems operate far away from these\nphysical limits. In this work we introduce Prism, a new proof-of-work\nblockchain protocol, which can achieve 1) security against up to 50%\nadversarial hashing power; 2) optimal throughput up to the capacity C of the\nnetwork; 3) confirmation latency for honest transactions proportional to the\npropagation delay D, with confirmation error probability exponentially small in\nCD ; 4) eventual total ordering of all transactions. Our approach to the design\nof this protocol is based on deconstructing the blockchain into its basic\nfunctionalities and systematically scaling up these functionalities to approach\ntheir physical limits. \n\n"}
{"id": "1810.09160", "contents": "Title: Who Filters the Filters: Understanding the Growth, Usefulness and\n  Efficiency of Crowdsourced Ad Blocking Abstract: Ad and tracking blocking extensions are popular tools for improving web\nperformance, privacy and aesthetics. Content blocking extensions typically rely\non filter lists to decide whether a web request is associated with tracking or\nadvertising, and so should be blocked. Millions of web users rely on filter\nlists to protect their privacy and improve their browsing experience.\n  Despite their importance, the growth and health of filter lists are poorly\nunderstood. Filter lists are maintained by a small number of contributors, who\nuse a variety of undocumented heuristics to determine what rules should be\nincluded. Lists quickly accumulate rules, and rules are rarely removed. As a\nresult, users' browsing experiences are degraded as the number of stale, dead\nor otherwise not useful rules increasingly dwarf the number of useful rules,\nwith no attenuating benefit. An accumulation of \"dead weight\" rules also makes\nit difficult to apply filter lists on resource-limited mobile devices.\n  This paper improves the understanding of crowdsourced filter lists by\nstudying EasyList, the most popular filter list. We find that EasyList has\ngrown from several hundred rules, to well over 60,000 rules, during its 9-year\nhistory. We measure how EasyList affects web browsing by applying EasyList to a\nsample of 10,000 websites. We find that 90.16% of the resource blocking rules\nin EasyList provide no benefit to users in common browsing scenarios. We\nfurther use our changes in EasyList application rates to provide a taxonomy of\nthe ways advertisers evade EasyList rules. Finally, we propose optimizations\nfor popular ad-blocking tools, that allow EasyList to be applied on performance\nconstrained mobile devices, and improve desktop performance by 62.5%, while\npreserving over 99% of blocking coverage. \n\n"}
{"id": "1810.10031", "contents": "Title: Stochastic Substitute Training: A Gray-box Approach to Craft Adversarial\n  Examples Against Gradient Obfuscation Defenses Abstract: It has been shown that adversaries can craft example inputs to neural\nnetworks which are similar to legitimate inputs but have been created to\npurposely cause the neural network to misclassify the input. These adversarial\nexamples are crafted, for example, by calculating gradients of a carefully\ndefined loss function with respect to the input. As a countermeasure, some\nresearchers have tried to design robust models by blocking or obfuscating\ngradients, even in white-box settings. Another line of research proposes\nintroducing a separate detector to attempt to detect adversarial examples. This\napproach also makes use of gradient obfuscation techniques, for example, to\nprevent the adversary from trying to fool the detector. In this paper, we\nintroduce stochastic substitute training, a gray-box approach that can craft\nadversarial examples for defenses which obfuscate gradients. For those defenses\nthat have tried to make models more robust, with our technique, an adversary\ncan craft adversarial examples with no knowledge of the defense. For defenses\nthat attempt to detect the adversarial examples, with our technique, an\nadversary only needs very limited information about the defense to craft\nadversarial examples. We demonstrate our technique by applying it against two\ndefenses which make models more robust and two defenses which detect\nadversarial examples. \n\n"}
{"id": "1810.10123", "contents": "Title: Finding Safety in Numbers with Secure Allegation Escrows Abstract: For fear of retribution, the victim of a crime may be willing to report it\nonly if other victims of the same perpetrator also step forward. Common\nexamples include 1) identifying oneself as the victim of sexual harassment,\nespecially by a person in a position of authority or 2) accusing an influential\npolitician, an authoritarian government, or ones own employer of corruption. To\nhandle such situations, legal literature has proposed the concept of an\nallegation escrow: a neutral third-party that collects allegations anonymously,\nmatches them against each other, and de-anonymizes allegers only after\nde-anonymity thresholds (in terms of number of co-allegers), pre-specified by\nthe allegers, are reached.\n  An allegation escrow can be realized as a single trusted third party;\nhowever, this party must be trusted to keep the identity of the alleger and\ncontent of the allegation private. To address this problem, this paper\nintroduces Secure Allegation Escrows (SAE, pronounced \"say\"). A SAE is a group\nof parties with independent interests and motives, acting jointly as an escrow\nfor collecting allegations from individuals, matching the allegations, and\nde-anonymizing the allegations when designated thresholds are reached. By\ndesign, SAEs provide a very strong property: No less than a majority of parties\nconstituting a SAE can de-anonymize or disclose the content of an allegation\nwithout a sufficient number of matching allegations (even in collusion with any\nnumber of other allegers). Once a sufficient number of matching allegations\nexist, the join escrow discloses the allegation with the allegers' identities.\nWe describe how SAEs can be constructed using a novel authentication protocol\nand a novel allegation matching and bucketing algorithm, provide formal proofs\nof the security of our constructions, and evaluate a prototype implementation,\ndemonstrating feasibility in practice. \n\n"}
{"id": "1810.10156", "contents": "Title: Automatic Identification of Indicators of Compromise using Neural-Based\n  Sequence Labelling Abstract: Indicators of Compromise (IOCs) are artifacts observed on a network or in an\noperating system that can be utilized to indicate a computer intrusion and\ndetect cyber-attacks in an early stage. Thus, they exert an important role in\nthe field of cybersecurity. However, state-of-the-art IOCs detection systems\nrely heavily on hand-crafted features with expert knowledge of cybersecurity,\nand require a large amount of supervised training corpora to train an IOC\nclassifier. In this paper, we propose using a neural-based sequence labelling\nmodel to identify IOCs automatically from reports on cybersecurity without\nexpert knowledge of cybersecurity. Our work is the first to apply an end-to-end\nsequence labelling to the task in IOCs identification. By using an attention\nmechanism and several token spelling features, we find that the proposed model\nis capable of identifying the low frequency IOCs from long sentences contained\nin cybersecurity reports. Experiments show that the proposed model outperforms\nother sequence labelling models, achieving over 88% average F1-score. \n\n"}
{"id": "1810.10436", "contents": "Title: Entropy in Quantum Information Theory -- Communication and Cryptography Abstract: In this Thesis, several results in quantum information theory are collected,\nmost of which use entropy as the main mathematical tool. *While a direct\ngeneralization of the Shannon entropy to density matrices, the von Neumann\nentropy behaves differently. A long-standing open question is, whether there\nare quantum analogues of unconstrained non-Shannon type inequalities. Here, a\nnew constrained non-von-Neumann type inequality is proven, a step towards a\nconjectured unconstrained inequality by Linden and Winter. *IID quantum state\nmerging can be optimally achieved using the decoupling technique. The one-shot\nresults by Berta et al. and Anshu at al., however, had to bring in additional\nmathematical machinery. We introduce a natural generalized decoupling paradigm,\ncatalytic decoupling, that can reproduce the aforementioned results when used\nanalogously to the application of standard decoupling in the asymptotic case.\n*Port based teleportation, a variant of standard quantum teleportation\nprotocol, cannot be implemented perfectly. We prove several lower bounds on the\nnecessary number of output ports N to achieve port based teleportation for\ngiven error and input dimension, showing that N diverges uniformly in the\ndimension of the teleported quantum system, for vanishing error. As a\nbyproduct, a new lower bound for the size of the program register for an\napproximate universal programmable quantum processor is derived. *In the last\npart, we give a new definition for information-theoretic quantum\nnon-malleability, strengthening the previous definition by Ambainis et al. We\nshow that quantum non-malleability implies secrecy, analogous to quantum\nauthentication. Furthermore, non-malleable encryption schemes can be used as a\nprimitive to build authenticating encryption schemes. We also show that the\nstrong notion of authentication recently proposed by Garg et al. can be\nfulfilled using 2-designs. \n\n"}
{"id": "1810.10649", "contents": "Title: On the Effectiveness of Type-based Control Flow Integrity Abstract: Control flow integrity (CFI) has received significant attention in the\ncommunity to combat control hijacking attacks in the presence of memory\ncorruption vulnerabilities. The challenges in creating a practical CFI has\nresulted in the development of a new type of CFI based on runtime type checking\n(RTC). RTC-based CFI has been implemented in a number of recent practical\nefforts such as GRSecurity Reuse Attack Protector (RAP) and LLVM-CFI. While\nthere has been a number of previous efforts that studied the strengths and\nlimitations of other types of CFI techniques, little has been done to evaluate\nthe RTC-based CFI. In this work, we study the effectiveness of RTC from the\nsecurity and practicality aspects. From the security perspective, we observe\nthat type collisions are abundant in sufficiently large code bases but\nexploiting them to build a functional attack is not straightforward. Then we\nshow how an attacker can successfully bypass RTC techniques using a variant of\nROP attacks that respect type checking (called TROP) and also built two\nproof-of-concept exploits, one against Nginx web server and the other against\nExim mail server. We also discuss practical challenges of implementing RTC. Our\nfindings suggest that while RTC is more practical for applying CFI to large\ncode bases, its policy is not strong enough when facing a motivated attacker. \n\n"}
{"id": "1810.11215", "contents": "Title: Capsule-Forensics: Using Capsule Networks to Detect Forged Images and\n  Videos Abstract: Recent advances in media generation techniques have made it easier for\nattackers to create forged images and videos. State-of-the-art methods enable\nthe real-time creation of a forged version of a single video obtained from a\nsocial network. Although numerous methods have been developed for detecting\nforged images and videos, they are generally targeted at certain domains and\nquickly become obsolete as new kinds of attacks appear. The method introduced\nin this paper uses a capsule network to detect various kinds of spoofs, from\nreplay attacks using printed images or recorded videos to computer-generated\nvideos using deep convolutional neural networks. It extends the application of\ncapsule networks beyond their original intention to the solving of inverse\ngraphics problems. \n\n"}
{"id": "1810.11335", "contents": "Title: Outlier Detection using Generative Models with Theoretical Performance\n  Guarantees Abstract: This paper considers the problem of recovering signals from compressed\nmeasurements contaminated with sparse outliers, which has arisen in many\napplications. In this paper, we propose a generative model neural network\napproach for reconstructing the ground truth signals under sparse outliers. We\npropose an iterative alternating direction method of multipliers (ADMM)\nalgorithm for solving the outlier detection problem via $\\ell_1$ norm\nminimization, and a gradient descent algorithm for solving the outlier\ndetection problem via squared $\\ell_1$ norm minimization. We establish the\nrecovery guarantees for reconstruction of signals using generative models in\nthe presence of outliers, and give an upper bound on the number of outliers\nallowed for recovery. Our results are applicable to both the linear generator\nneural network and the nonlinear generator neural network with an arbitrary\nnumber of layers. We conduct extensive experiments using variational\nauto-encoder and deep convolutional generative adversarial networks, and the\nexperimental results show that the signals can be successfully reconstructed\nunder outliers using our approach. Our approach outperforms the traditional\nLasso and $\\ell_2$ minimization approach. \n\n"}
{"id": "1810.11641", "contents": "Title: Cross-Modal Distillation for RGB-Depth Person Re-Identification Abstract: Person re-identification is a key challenge for surveillance across multiple\nsensors. Prompted by the advent of powerful deep learning models for visual\nrecognition, and inexpensive RGB-D cameras and sensor-rich mobile robotic\nplatforms, e.g. self-driving vehicles, we investigate the relatively unexplored\nproblem of cross-modal re-identification of persons between RGB (color) and\ndepth images. The considerable divergence in data distributions across\ndifferent sensor modalities introduces additional challenges to the typical\ndifficulties like distinct viewpoints, occlusions, and pose and illumination\nvariation. While some work has investigated re-identification across RGB and\ninfrared, we take inspiration from successes in transfer learning from RGB to\ndepth in object detection tasks. Our main contribution is a novel method for\ncross-modal distillation for robust person re-identification, which learns a\nshared feature representation space of person's appearance in both RGB and\ndepth images. In addition, we propose a cross-modal attention mechanism where\nthe gating signal from one modality can dynamically activate the most\ndiscriminant CNN filters of the other modality. The proposed distillation\nmethod is compared to conventional and deep learning approaches proposed for\nother cross-domain re-identification tasks. Results obtained on the public BIWI\nand RobotPKU datasets indicate that the proposed method can significantly\noutperform the state-of-the-art approaches by up to 16.1% in mean Average\nPrecision (mAP), demonstrating the benefit of the distillation paradigm. The\nexperimental results also indicate that using cross-modal attention allows to\nimprove recognition accuracy considerably with respect to the proposed\ndistillation method and relevant state-of-the-art approaches. \n\n"}
{"id": "1810.11655", "contents": "Title: A privacy-preserving system for data ownership using blockchain and\n  distributed databases Abstract: Blockchain has the potential to revolutionize the way we store, use, and\nprocess data. Information on most blockchains can be viewed by every node\nhosting the blockchain, which means that most blockchains cannot handle private\ndata. Decentralized databases exist that guarantee privacy by encrypting user\ndata with the user's private key, but this prevents easy data sharing. However,\nin many real world applications, from student data to medical records, it is\ndesirable that user data is anonymously searchable. In this paper we present a\nnovel system that gives users ownership over their data while at the same time\nenabling them to make their data searchable within previously agreed upon\nlimits. Our system implements a strong notion of ownership using a\nself-sovereign identity system and a weak notion of ownership using multiple\ncentralized databases together with a blockchain and a tumbling process. We\ndiscuss applications of our methods to university's student records and medical\ndata. \n\n"}
{"id": "1810.11914", "contents": "Title: Rademacher Complexity for Adversarially Robust Generalization Abstract: Many machine learning models are vulnerable to adversarial attacks; for\nexample, adding adversarial perturbations that are imperceptible to humans can\noften make machine learning models produce wrong predictions with high\nconfidence. Moreover, although we may obtain robust models on the training\ndataset via adversarial training, in some problems the learned models cannot\ngeneralize well to the test data. In this paper, we focus on $\\ell_\\infty$\nattacks, and study the adversarially robust generalization problem through the\nlens of Rademacher complexity. For binary linear classifiers, we prove tight\nbounds for the adversarial Rademacher complexity, and show that the adversarial\nRademacher complexity is never smaller than its natural counterpart, and it has\nan unavoidable dimension dependence, unless the weight vector has bounded\n$\\ell_1$ norm. The results also extend to multi-class linear classifiers. For\n(nonlinear) neural networks, we show that the dimension dependence in the\nadversarial Rademacher complexity also exists. We further consider a surrogate\nadversarial loss for one-hidden layer ReLU network and prove margin bounds for\nthis setting. Our results indicate that having $\\ell_1$ norm constraints on the\nweight matrices might be a potential way to improve generalization in the\nadversarial setting. We demonstrate experimental results that validate our\ntheoretical findings. \n\n"}
{"id": "1810.11945", "contents": "Title: STFT spectral loss for training a neural speech waveform model Abstract: This paper proposes a new loss using short-time Fourier transform (STFT)\nspectra for the aim of training a high-performance neural speech waveform model\nthat predicts raw continuous speech waveform samples directly. Not only\namplitude spectra but also phase spectra obtained from generated speech\nwaveforms are used to calculate the proposed loss. We also mathematically show\nthat training of the waveform model on the basis of the proposed loss can be\ninterpreted as maximum likelihood training that assumes the amplitude and phase\nspectra of generated speech waveforms following Gaussian and von Mises\ndistributions, respectively. Furthermore, this paper presents a simple network\narchitecture as the speech waveform model, which is composed of uni-directional\nlong short-term memories (LSTMs) and an auto-regressive structure. Experimental\nresults showed that the proposed neural model synthesized high-quality speech\nwaveforms. \n\n"}
{"id": "1810.11956", "contents": "Title: Characterizing Entities in the Bitcoin Blockchain Abstract: Bitcoin has created a new exchange paradigm within which financial\ntransactions can be trusted without an intermediary. This premise of a free\ndecentralized transactional network however requires, in its current\nimplementation, unrestricted access to the ledger for peer-based transaction\nverification. A number of studies have shown that, in this pseudonymous\ncontext, identities can be leaked based on transaction features or off-network\ninformation. In this work, we analyze the information revealed by the pattern\nof transactions in the neighborhood of a given entity transaction. By\ndefinition, these features which pertain to an extended network are not\ndirectly controllable by the entity, but might enable leakage of information\nabout transacting entities. We define a number of new features relevant to\nentity characterization on the Bitcoin Blockchain and study their efficacy in\npractice. We show that even a weak attacker with shallow data mining knowledge\nis able to leverage these features to characterize the entity properties. \n\n"}
{"id": "1810.11960", "contents": "Title: Investigation of enhanced Tacotron text-to-speech synthesis systems with\n  self-attention for pitch accent language Abstract: End-to-end speech synthesis is a promising approach that directly converts\nraw text to speech. Although it was shown that Tacotron2 outperforms classical\npipeline systems with regards to naturalness in English, its applicability to\nother languages is still unknown. Japanese could be one of the most difficult\nlanguages for which to achieve end-to-end speech synthesis, largely due to its\ncharacter diversity and pitch accents. Therefore, state-of-the-art systems are\nstill based on a traditional pipeline framework that requires a separate text\nanalyzer and duration model. Towards end-to-end Japanese speech synthesis, we\nextend Tacotron to systems with self-attention to capture long-term\ndependencies related to pitch accents and compare their audio quality with\nclassical pipeline systems under various conditions to show their pros and\ncons. In a large-scale listening test, we investigated the impacts of the\npresence of accentual-type labels, the use of force or predicted alignments,\nand acoustic features used as local condition parameters of the Wavenet\nvocoder. Our results reveal that although the proposed systems still do not\nmatch the quality of a top-line pipeline system for Japanese, we show important\nstepping stones towards end-to-end Japanese speech synthesis. \n\n"}
{"id": "1810.12188", "contents": "Title: Adversarial Attacks on Stochastic Bandits Abstract: We study adversarial attacks that manipulate the reward signals to control\nthe actions chosen by a stochastic multi-armed bandit algorithm. We propose the\nfirst attack against two popular bandit algorithms: $\\epsilon$-greedy and UCB,\n\\emph{without} knowledge of the mean rewards. The attacker is able to spend\nonly logarithmic effort, multiplied by a problem-specific parameter that\nbecomes smaller as the bandit problem gets easier to attack. The result means\nthe attacker can easily hijack the behavior of the bandit algorithm to promote\nor obstruct certain actions, say, a particular medical treatment. As bandits\nare seeing increasingly wide use in practice, our study exposes a significant\nsecurity threat. \n\n"}
{"id": "1810.12730", "contents": "Title: Audiovisual speaker conversion: jointly and simultaneously transforming\n  facial expression and acoustic characteristics Abstract: An audiovisual speaker conversion method is presented for simultaneously\ntransforming the facial expressions and voice of a source speaker into those of\na target speaker. Transforming the facial and acoustic features together makes\nit possible for the converted voice and facial expressions to be highly\ncorrelated and for the generated target speaker to appear and sound natural. It\nuses three neural networks: a conversion network that fuses and transforms the\nfacial and acoustic features, a waveform generation network that produces the\nwaveform from both the converted facial and acoustic features, and an image\nreconstruction network that outputs an RGB facial image also based on both the\nconverted features. The results of experiments using an emotional audiovisual\ndatabase showed that the proposed method achieved significantly higher\nnaturalness compared with one that separately transformed acoustic and facial\nfeatures. \n\n"}
{"id": "1810.13048", "contents": "Title: Attentive Filtering Networks for Audio Replay Attack Detection Abstract: An attacker may use a variety of techniques to fool an automatic speaker\nverification system into accepting them as a genuine user. Anti-spoofing\nmethods meanwhile aim to make the system robust against such attacks. The\nASVspoof 2017 Challenge focused specifically on replay attacks, with the\nintention of measuring the limits of replay attack detection as well as\ndeveloping countermeasures against them. In this work, we propose our replay\nattacks detection system - Attentive Filtering Network, which is composed of an\nattention-based filtering mechanism that enhances feature representations in\nboth the frequency and time domains, and a ResNet-based classifier. We show\nthat the network enables us to visualize the automatically acquired feature\nrepresentations that are helpful for spoofing detection. Attentive Filtering\nNetwork attains an evaluation EER of 8.99$\\%$ on the ASVspoof 2017 Version 2.0\ndataset. With system fusion, our best system further obtains a 30$\\%$ relative\nimprovement over the ASVspoof 2017 enhanced baseline system. \n\n"}
{"id": "1811.00653", "contents": "Title: SDN based Network Function Parallelism in Cloud Abstract: Network function virtualization (NFV) based service function chaining (SFC)\nallows the provisioning of various security and traffic engineering\napplications in a cloud network. Inefficient deployment of network functions\ncan lead to security violations and performance overhead. In an OpenFlow\nenabled cloud, the key problem with current mechanisms is that several packet\nfield match and flow rule action sets associated with the network functions are\nnon-overlapping and can be parallelized for performance enhancement. We\nintroduce Network Function Parallelism (NFP) SFC-NFP for OpenFlow network. Our\nsolution utilizes network function parallelism over the OpenFlow rules to\nimprove SFC performance in the cloud network. We have utilized the DPDK\nplatform with an OpenFlow switch (OVS) for experimental analysis. Our solution\nachieves a 1.40-1.90x reduction in latency for SFC in an OpenStack cloud\nnetwork managed by the SDN framework. \n\n"}
{"id": "1811.00830", "contents": "Title: Towards Adversarial Malware Detection: Lessons Learned from PDF-based\n  Attacks Abstract: Malware still constitutes a major threat in the cybersecurity landscape, also\ndue to the widespread use of infection vectors such as documents. These\ninfection vectors hide embedded malicious code to the victim users,\nfacilitating the use of social engineering techniques to infect their machines.\nResearch showed that machine-learning algorithms provide effective detection\nmechanisms against such threats, but the existence of an arms race in\nadversarial settings has recently challenged such systems. In this work, we\nfocus on malware embedded in PDF files as a representative case of such an arms\nrace. We start by providing a comprehensive taxonomy of the different\napproaches used to generate PDF malware, and of the corresponding\nlearning-based detection systems. We then categorize threats specifically\ntargeted against learning-based PDF malware detectors, using a well-established\nframework in the field of adversarial machine learning. This framework allows\nus to categorize known vulnerabilities of learning-based PDF malware detectors\nand to identify novel attacks that may threaten such systems, along with the\npotential defense mechanisms that can mitigate the impact of such threats. We\nconclude the paper by discussing how such findings highlight promising research\ndirections towards tackling the more general challenge of designing robust\nmalware detectors in adversarial settings. \n\n"}
{"id": "1811.01027", "contents": "Title: AiDroid: When Heterogeneous Information Network Marries Deep Neural\n  Network for Real-time Android Malware Detection Abstract: The explosive growth and increasing sophistication of Android malware call\nfor new defensive techniques that are capable of protecting mobile users\nagainst novel threats. In this paper, we first extract the runtime Application\nProgramming Interface (API) call sequences from Android apps, and then analyze\nhigher-level semantic relations within the ecosystem to comprehensively\ncharacterize the apps. To model different types of entities (i.e., app, API,\nIMEI, signature, affiliation) and the rich semantic relations among them, we\nthen construct a structural heterogeneous information network (HIN) and present\nmeta-path based approach to depict the relatedness over apps. To efficiently\nclassify nodes (e.g., apps) in the constructed HIN, we propose the HinLearning\nmethod to first obtain in-sample node embeddings and then learn representations\nof out-of-sample nodes without rerunning/adjusting HIN embeddings at the first\nattempt. Afterwards, we design a deep neural network (DNN) classifier taking\nthe learned HIN representations as inputs for Android malware detection. A\ncomprehensive experimental study on the large-scale real sample collections\nfrom Tencent Security Lab is performed to compare various baselines. Promising\nexperimental results demonstrate that our developed system AiDroid which\nintegrates our proposed method outperforms others in real-time Android malware\ndetection. AiDroid has already been incorporated into Tencent Mobile Security\nproduct that serves millions of users worldwide. \n\n"}
{"id": "1811.01057", "contents": "Title: Semidefinite relaxations for certifying robustness to adversarial\n  examples Abstract: Despite their impressive performance on diverse tasks, neural networks fail\ncatastrophically in the presence of adversarial inputs---imperceptibly but\nadversarially perturbed versions of natural inputs. We have witnessed an arms\nrace between defenders who attempt to train robust networks and attackers who\ntry to construct adversarial examples. One promise of ending the arms race is\ndeveloping certified defenses, ones which are provably robust against all\nattackers in some family. These certified defenses are based on convex\nrelaxations which construct an upper bound on the worst case loss over all\nattackers in the family. Previous relaxations are loose on networks that are\nnot trained against the respective relaxation. In this paper, we propose a new\nsemidefinite relaxation for certifying robustness that applies to arbitrary\nReLU networks. We show that our proposed relaxation is tighter than previous\nrelaxations and produces meaningful robustness guarantees on three different\n\"foreign networks\" whose training objectives are agnostic to our proposed\nrelaxation. \n\n"}
{"id": "1811.01213", "contents": "Title: Learning to Defend by Learning to Attack Abstract: Adversarial training provides a principled approach for training robust\nneural networks. From an optimization perspective, adversarial training is\nessentially solving a bilevel optimization problem. The leader problem is\ntrying to learn a robust classifier, while the follower problem is trying to\ngenerate adversarial samples. Unfortunately, such a bilevel problem is\ndifficult to solve due to its highly complicated structure. This work proposes\na new adversarial training method based on a generic learning-to-learn (L2L)\nframework. Specifically, instead of applying existing hand-designed algorithms\nfor the inner problem, we learn an optimizer, which is parametrized as a\nconvolutional neural network. At the same time, a robust classifier is learned\nto defense the adversarial attack generated by the learned optimizer.\nExperiments over CIFAR-10 and CIFAR-100 datasets demonstrate that L2L\noutperforms existing adversarial training methods in both classification\naccuracy and computational efficiency. Moreover, our L2L framework can be\nextended to generative adversarial imitation learning and stabilize the\ntraining. \n\n"}
{"id": "1811.01312", "contents": "Title: Adversarial Black-Box Attacks on Automatic Speech Recognition Systems\n  using Multi-Objective Evolutionary Optimization Abstract: Fooling deep neural networks with adversarial input have exposed a\nsignificant vulnerability in the current state-of-the-art systems in multiple\ndomains. Both black-box and white-box approaches have been used to either\nreplicate the model itself or to craft examples which cause the model to fail.\nIn this work, we propose a framework which uses multi-objective evolutionary\noptimization to perform both targeted and un-targeted black-box attacks on\nAutomatic Speech Recognition (ASR) systems. We apply this framework on two ASR\nsystems: Deepspeech and Kaldi-ASR, which increases the Word Error Rates (WER)\nof these systems by upto 980%, indicating the potency of our approach. During\nboth un-targeted and targeted attacks, the adversarial samples maintain a high\nacoustic similarity of 0.98 and 0.97 with the original audio. \n\n"}
{"id": "1811.01444", "contents": "Title: FAdeML: Understanding the Impact of Pre-Processing Noise Filtering on\n  Adversarial Machine Learning Abstract: Deep neural networks (DNN)-based machine learning (ML) algorithms have\nrecently emerged as the leading ML paradigm particularly for the task of\nclassification due to their superior capability of learning efficiently from\nlarge datasets. The discovery of a number of well-known attacks such as dataset\npoisoning, adversarial examples, and network manipulation (through the addition\nof malicious nodes) has, however, put the spotlight squarely on the lack of\nsecurity in DNN-based ML systems. In particular, malicious actors can use these\nwell-known attacks to cause random/targeted misclassification, or cause a\nchange in the prediction confidence, by only slightly but systematically\nmanipulating the environmental parameters, inference data, or the data\nacquisition block. Most of the prior adversarial attacks have, however, not\naccounted for the pre-processing noise filters commonly integrated with the\nML-inference module. Our contribution in this work is to show that this is a\nmajor omission since these noise filters can render ineffective the majority of\nthe existing attacks, which rely essentially on introducing adversarial noise.\nApart from this, we also extend the state of the art by proposing a novel\npre-processing noise Filter-aware Adversarial ML attack called FAdeML. To\ndemonstrate the effectiveness of the proposed methodology, we generate an\nadversarial attack image by exploiting the \"VGGNet\" DNN trained for the \"German\nTraffic Sign Recognition Benchmarks (GTSRB\" dataset, which despite having no\nvisual noise, can cause a classifier to misclassify even in the presence of\npre-processing noise filters. \n\n"}
{"id": "1811.02054", "contents": "Title: Exploring Connections Between Active Learning and Model Extraction Abstract: Machine learning is being increasingly used by individuals, research\ninstitutions, and corporations. This has resulted in the surge of Machine\nLearning-as-a-Service (MLaaS) - cloud services that provide (a) tools and\nresources to learn the model, and (b) a user-friendly query interface to access\nthe model. However, such MLaaS systems raise privacy concerns such as model\nextraction. In model extraction attacks, adversaries maliciously exploit the\nquery interface to steal the model. More precisely, in a model extraction\nattack, a good approximation of a sensitive or proprietary model held by the\nserver is extracted (i.e. learned) by a dishonest user who interacts with the\nserver only via the query interface. This attack was introduced by Tramer et\nal. at the 2016 USENIX Security Symposium, where practical attacks for various\nmodels were shown. We believe that better understanding the efficacy of model\nextraction attacks is paramount to designing secure MLaaS systems. To that end,\nwe take the first step by (a) formalizing model extraction and discussing\npossible defense strategies, and (b) drawing parallels between model extraction\nand established area of active learning. In particular, we show that recent\nadvancements in the active learning domain can be used to implement powerful\nmodel extraction attacks, and investigate possible defense strategies. \n\n"}
{"id": "1811.02536", "contents": "Title: A Bisimilarity Congruence for the Applied pi-Calculus Sufficiently\n  Coarse to Verify Privacy Properties Abstract: This paper is the first thorough investigation into the coarsest notion of\nbisimilarity for the applied pi-calculus that is a congruence relation: open\nbarbed bisimilarity. An open variant of labelled bisimilarity (quasi-open\nbisimilarity), better suited to constructing bisimulations, is proven to\ncoincide with open barbed bisimilarity. These bisimilary congruences are shown\nto be characterised by an intuitionistic modal logic that can be used, for\nexample, to describe an attack on privacy whenever a privacy property is\nviolated. Open barbed bisimilarity provides a compositional approach to\nverifying cryptographic protocols, since properties proven can be reused in any\ncontext, including under input prefix. Furthermore, open barbed bisimilarity is\nsufficiently coarse for reasoning about security and privacy properties of\ncryptographic protocols; in constrast to the finer bisimilarity congruence,\nopen bisimilarity, which cannot verify certain privacy properties. \n\n"}
{"id": "1811.02840", "contents": "Title: Neural Image Compression for Gigapixel Histopathology Image Analysis Abstract: We propose Neural Image Compression (NIC), a two-step method to build\nconvolutional neural networks for gigapixel image analysis solely using weak\nimage-level labels. First, gigapixel images are compressed using a neural\nnetwork trained in an unsupervised fashion, retaining high-level information\nwhile suppressing pixel-level noise. Second, a convolutional neural network\n(CNN) is trained on these compressed image representations to predict\nimage-level labels, avoiding the need for fine-grained manual annotations. We\ncompared several encoding strategies, namely reconstruction error minimization,\ncontrastive training and adversarial feature learning, and evaluated NIC on a\nsynthetic task and two public histopathology datasets. We found that NIC can\nexploit visual cues associated with image-level labels successfully,\nintegrating both global and local visual information. Furthermore, we\nvisualized the regions of the input gigapixel images where the CNN attended to,\nand confirmed that they overlapped with annotations from human experts. \n\n"}
{"id": "1811.03165", "contents": "Title: Shining Light On Shadow Stacks Abstract: Control-Flow Hijacking attacks are the dominant attack vector against C/C++\nprograms. Control-Flow Integrity (CFI) solutions mitigate these attacks on the\nforward edge,i.e., indirect calls through function pointers and virtual calls.\nProtecting the backward edge is left to stack canaries, which are easily\nbypassed through information leaks. Shadow Stacks are a fully precise mechanism\nfor protecting backwards edges, and should be deployed with CFI mitigations. We\npresent a comprehensive analysis of all possible shadow stack mechanisms along\nthree axes: performance, compatibility, and security. For performance\ncomparisons we use SPEC CPU2006, while security and compatibility are\nqualitatively analyzed. Based on our study, we renew calls for a shadow stack\ndesign that leverages a dedicated register, resulting in low performance\noverhead, and minimal memory overhead, but sacrifices compatibility. We present\ncase studies of our implementation of such a design, Shadesmar, on Phoronix and\nApache to demonstrate the feasibility of dedicating a general purpose register\nto a security monitor on modern architectures, and the deployability of\nShadesmar. Our comprehensive analysis, including detailed case studies for our\nnovel design, allows compiler designers and practitioners to select the correct\nshadow stack design for different usage scenarios. \n\n"}
{"id": "1811.03343", "contents": "Title: Repetitive Motion Estimation Network: Recover cardiac and respiratory\n  signal from thoracic imaging Abstract: Tracking organ motion is important in image-guided interventions, but motion\nannotations are not always easily available. Thus, we propose Repetitive Motion\nEstimation Network (RMEN) to recover cardiac and respiratory signals. It learns\nthe spatio-temporal repetition patterns, embedding high dimensional motion\nmanifolds to 1D vectors with partial motion phase boundary annotations.\nCompared with the best alternative models, our proposed RMEN significantly\ndecreased the QRS peaks detection offsets by 59.3%. Results showed that RMEN\ncould handle the irregular cardiac and respiratory motion cases. Repetitive\nmotion patterns learned by RMEN were visualized and indicated in the feature\nmaps. \n\n"}
{"id": "1811.03661", "contents": "Title: SpeedReader: Reader Mode Made Fast and Private Abstract: Most popular web browsers include \"reader modes\" that improve the user\nexperience by removing un-useful page elements. Reader modes reformat the page\nto hide elements that are not related to the page's main content. Such page\nelements include site navigation, advertising related videos and images, and\nmost JavaScript. The intended end result is that users can enjoy the content\nthey are interested in, without distraction.\n  In this work, we consider whether the \"reader mode\" can be widened to also\nprovide performance and privacy improvements. Instead of its use as a\npost-render feature to clean up the clutter on a page we propose SpeedReader as\nan alternative multistep pipeline that is part of the rendering pipeline. Once\nthe tool decides during the initial phase of a page load that a page is\nsuitable for reader mode use, it directly applies document tree translation\nbefore the page is rendered.\n  Based on our measurements, we believe that SpeedReader can be continuously\nenabled in order to drastically improve end-user experience, especially on\nslower mobile connections. Combined with our approach to predicting which pages\nshould be rendered in reader mode with 91% accuracy, it achieves drastic\nspeedups and bandwidth reductions of up to 27x and 84x respectively on average.\nWe further find that our novel \"reader mode\" approach brings with it\nsignificant privacy improvements to users. Our approach effectively removes all\ncommonly recognized trackers, issuing 115 fewer requests to third parties, and\ninteracts with 64 fewer trackers on average, on transformed pages. \n\n"}
{"id": "1811.03685", "contents": "Title: New CleverHans Feature: Better Adversarial Robustness Evaluations with\n  Attack Bundling Abstract: This technical report describes a new feature of the CleverHans library\ncalled \"attack bundling\". Many papers about adversarial examples present lists\nof error rates corresponding to different attack algorithms. A common approach\nis to take the maximum across this list and compare defenses against that error\nrate. We argue that a better approach is to use attack bundling: the max should\nbe taken across many examples at the level of individual examples, then the\nerror rate should be calculated by averaging after this maximization operation.\nReporting the bundled attacker error rate provides a lower bound on the true\nworst-case error rate. The traditional approach of reporting the maximum error\nrate across attacks can underestimate the true worst-case error rate by an\namount approaching 100\\% as the number of attacks approaches infinity. Attack\nbundling can be used with different prioritization schemes to optimize\nquantities such as error rate on adversarial examples, perturbation size needed\nto cause misclassification, or failure rate when using a specific confidence\nthreshold. \n\n"}
{"id": "1811.03761", "contents": "Title: RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed\n  Learning from Heterogeneous Datasets Abstract: In this paper, we propose a class of robust stochastic subgradient methods\nfor distributed learning from heterogeneous datasets at presence of an unknown\nnumber of Byzantine workers. The Byzantine workers, during the learning\nprocess, may send arbitrary incorrect messages to the master due to data\ncorruptions, communication failures or malicious attacks, and consequently bias\nthe learned model. The key to the proposed methods is a regularization term\nincorporated with the objective function so as to robustify the learning task\nand mitigate the negative effects of Byzantine attacks. The resultant\nsubgradient-based algorithms are termed Byzantine-Robust Stochastic Aggregation\nmethods, justifying our acronym RSA used henceforth. In contrast to most of the\nexisting algorithms, RSA does not rely on the assumption that the data are\nindependent and identically distributed (i.i.d.) on the workers, and hence fits\nfor a wider class of applications. Theoretically, we show that: i) RSA\nconverges to a near-optimal solution with the learning error dependent on the\nnumber of Byzantine workers; ii) the convergence rate of RSA under Byzantine\nattacks is the same as that of the stochastic gradient descent method, which is\nfree of Byzantine attacks. Numerically, experiments on real dataset corroborate\nthe competitive performance of RSA and a complexity reduction compared to the\nstate-of-the-art alternatives. \n\n"}
{"id": "1811.03934", "contents": "Title: RadIoT: Radio Communications Intrusion Detection for IoT - A Protocol\n  Independent Approach Abstract: Internet-of-Things (IoT) devices are nowadays massively integrated in daily\nlife: homes, factories, or public places. This technology offers attractive\nservices to improve the quality of life as well as new economic markets through\nthe exploitation of the collected data. However, these connected objects have\nalso become attractive targets for attackers because their current security\ndesign is often weak or flawed, as illustrated by several vulnerabilities such\nas Mirai, Blueborne, etc. This paper presents a novel approach for detecting\nintrusions in smart spaces such as smarthomes, or smartfactories, that is based\non the monitoring and profiling of radio communications at the physical layer\nusing machine learning techniques. The approach is designed to be independent\nof the large and heterogeneous set of wireless communication protocols\ntypically implemented by connected objects such as WiFi, Bluetooth, Zigbee,\nBluetooth-Low-Energy (BLE) or proprietary communication protocols. The main\nconcepts of the proposed approach are presented together with an experimental\ncase study illustrating its feasibility based on data collected during the\ndeployment of the intrusion detection approach in a smart home under real-life\nconditions. \n\n"}
{"id": "1811.04078", "contents": "Title: Blockchain for Economically Sustainable Wireless Mesh Networks Abstract: Decentralization, in the form of mesh networking and blockchain, two\npromising technologies, is coming to the telecommunications industry. Mesh\nnetworking allows wider low cost Internet access with infrastructures built\nfrom routers contributed by diverse owners, while blockchain enables\ntransparency and accountability for investments, revenue or other forms of\neconomic compensations from sharing of network traffic, content and services.\nCrowdsourcing network coverage, combined with crowdfunding costs, can create\neconomically sustainable yet decentralized Internet access. This means every\nparticipant can invest in resources, and pay or be paid for usage to recover\nthe costs of network devices and maintenance. While mesh networks and mesh\nrouting protocols enable self-organized networks that expand organically,\ncryptocurrencies and smart contracts enable the economic coordination among\nnetwork providers and consumers. We explore and evaluate two existing\nblockchain software stacks, Hyperledger Fabric (HLF) and Ethereum geth with\nProof of Authority (PoA) intended as a local lightweight distributed ledger,\ndeployed in a real city-wide production mesh network and also in laboratory\nnetwork. We quantify the performance, bottlenecks and identify the current\nlimitations and opportunities for improvement to serve locally the needs of\nwireless mesh networks, without the privacy and economic cost of relying on\npublic blockchains. \n\n"}
{"id": "1811.05187", "contents": "Title: An Orchestrated Empirical Study on Deep Learning Frameworks and\n  Platforms Abstract: Deep learning (DL) has recently achieved tremendous success in a variety of\ncutting-edge applications, e.g., image recognition, speech and natural language\nprocessing, and autonomous driving. Besides the available big data and hardware\nevolution, DL frameworks and platforms play a key role to catalyze the\nresearch, development, and deployment of DL intelligent solutions. However, the\ndifference in computation paradigm, architecture design and implementation of\nexisting DL frameworks and platforms brings challenges for DL software\ndevelopment, deployment, maintenance, and migration. Up to the present, it\nstill lacks a comprehensive study on how current diverse DL frameworks and\nplatforms influence the DL software development process.\n  In this paper, we initiate the first step towards the investigation on how\nexisting state-of-the-art DL frameworks (i.e., TensorFlow, Theano, and Torch)\nand platforms (i.e., server/desktop, web, and mobile) support the DL software\ndevelopment activities. We perform an in-depth and comparative evaluation on\nmetrics such as learning accuracy, DL model size, robustness, and performance,\non state-of-the-art DL frameworks across platforms using two popular datasets\nMNIST and CIFAR-10. Our study reveals that existing DL frameworks still suffer\nfrom compatibility issues, which becomes even more severe when it comes to\ndifferent platforms. We pinpoint the current challenges and opportunities\ntowards developing high quality and compatible DL systems. To ignite further\ninvestigation along this direction to address urgent industrial demands of\nintelligent solutions, we make all of our assembled feasible toolchain and\ndataset publicly available. \n\n"}
{"id": "1811.05296", "contents": "Title: SAFE: Self-Attentive Function Embeddings for Binary Similarity Abstract: The binary similarity problem consists in determining if two functions are\nsimilar by only considering their compiled form. Advanced techniques for binary\nsimilarity recently gained momentum as they can be applied in several fields,\nsuch as copyright disputes, malware analysis, vulnerability detection, etc.,\nand thus have an immediate practical impact. Current solutions compare\nfunctions by first transforming their binary code in multi-dimensional vector\nrepresentations (embeddings), and then comparing vectors through simple and\nefficient geometric operations. However, embeddings are usually derived from\nbinary code using manual feature extraction, that may fail in considering\nimportant function characteristics, or may consider features that are not\nimportant for the binary similarity problem. In this paper we propose SAFE, a\nnovel architecture for the embedding of functions based on a self-attentive\nneural network. SAFE works directly on disassembled binary functions, does not\nrequire manual feature extraction, is computationally more efficient than\nexisting solutions (i.e., it does not incur in the computational overhead of\nbuilding or manipulating control flow graphs), and is more general as it works\non stripped binaries and on multiple architectures. We report the results from\na quantitative and qualitative analysis that show how SAFE provides a\nnoticeable performance improvement with respect to previous solutions.\nFurthermore, we show how clusters of our embedding vectors are closely related\nto the semantic of the implemented algorithms, paving the way for further\ninteresting applications (e.g. semantic-based binary function search). \n\n"}
{"id": "1811.05378", "contents": "Title: Interface-Based Side Channel Attack Against Intel SGX Abstract: Intel has introduced a trusted computing technology, Intel Software Guard\nExtension (SGX), which provides an isolated and secure execution environment\ncalled enclave for a user program without trusting any privilege software\n(e.g., an operating system or a hypervisor) or firmware. Nevertheless, SGX is\nvulnerable to several side channel attacks (e.g. page-fault-based attack and\ncache-based attack). In this paper, we explore a new, yet critical side channel\nattack in SGX, interface-based side channel attack, which can infer the\ninformation of the enclave input data. The root cause of the interface-based\nside channel attack is the input dependent interface invocation information\n(e.g., interface information and invocation patterns) which can be observed by\nthe untrusted privilege software can reveal the control flow in the enclave. We\nstudy the methodology which can be used to conduct the interface-based side\nchannel attack. To illustrate the effectiveness of the interface-based\nside-channel attacks, we use our methodology to infer whether tracked web pages\nhave been processed by the SGX-assisted NFV platforms and achieve the accuracy\nof 87.6% and recall of 76.6%. We also identify the packets which belong to the\ntracked web pages, with the accuracy of 67.9%and recall of 71.1%. We finally\npropose some countermeasures to defense the interface-based side channel attack\nin SGX-assisted applications. \n\n"}
{"id": "1811.05441", "contents": "Title: A Systematic Evaluation of Transient Execution Attacks and Defenses Abstract: Research on transient execution attacks including Spectre and Meltdown showed\nthat exception or branch misprediction events might leave secret-dependent\ntraces in the CPU's microarchitectural state. This observation led to a\nproliferation of new Spectre and Meltdown attack variants and even more ad-hoc\ndefenses (e.g., microcode and software patches). Both the industry and academia\nare now focusing on finding effective defenses for known issues. However, we\nonly have limited insight on residual attack surface and the completeness of\nthe proposed defenses.\n  In this paper, we present a systematization of transient execution attacks.\nOur systematization uncovers 6 (new) transient execution attacks that have been\noverlooked and not been investigated so far: 2 new exploitable Meltdown\neffects: Meltdown-PK (Protection Key Bypass) on Intel, and Meltdown-BND (Bounds\nCheck Bypass) on Intel and AMD; and 4 new Spectre mistraining strategies. We\nevaluate the attacks in our classification tree through proof-of-concept\nimplementations on 3 major CPU vendors (Intel, AMD, ARM). Our systematization\nyields a more complete picture of the attack surface and allows for a more\nsystematic evaluation of defenses. Through this systematic evaluation, we\ndiscover that most defenses, including deployed ones, cannot fully mitigate all\nattack variants. \n\n"}
{"id": "1811.05905", "contents": "Title: Blockchain-based Firmware Update Scheme Tailored for Autonomous Vehicles Abstract: Recently, Autonomous Vehicles (AVs) have gained extensive attention from both\nacademia and industry. AVs are a complex system composed of many subsystems,\nmaking them a typical target for attackers. Therefore, the firmware of the\ndifferent subsystems needs to be updated to the latest version by the\nmanufacturer to fix bugs and introduce new features, e.g., using security\npatches. In this paper, we propose a distributed firmware update scheme for the\nAVs' subsystems, leveraging blockchain and smart contract technology. A\nconsortium blockchain made of different AVs manufacturers is used to ensure the\nauthenticity and integrity of firmware updates. Instead of depending on\ncentralized third parties to distribute the new updates, we enable AVs, namely\ndistributors, to participate in the distribution process and we take advantage\nof their mobility to guarantee high availability and fast delivery of the\nupdates. To incentivize AVs to distribute the updates, a reward system is\nestablished that maintains a credit reputation for each distributor account in\nthe blockchain. A zero-knowledge proof protocol is used to exchange the update\nin return for a proof of distribution in a trust-less environment. Moreover, we\nuse attribute-based encryption (ABE) scheme to ensure that only authorized AVs\nwill be able to download and use a new update. Our analysis indicates that the\nadditional cryptography primitives and exchanged transactions do not affect the\noperation of the AVs network. Also, our security analysis demonstrates that our\nscheme is efficient and secure against different attacks. \n\n"}
{"id": "1811.06343", "contents": "Title: Achieving Differential Privacy using Methods from Calculus Abstract: We introduce derivative sensitivity, an analogue to local sensitivity for\ncontinuous functions. We use this notion in an analysis that determines the\namount of noise to be added to the result of a database query in order to\nobtain a certain level of differential privacy, and demonstrate that derivative\nsensitivity allows us to employ powerful mechanisms from calculus to perform\nthe analysis for a variety of queries. We have implemented the analyzer and\nevaluated its efficiency and precision.\n  We also show the flexibility of derivative sensitivity in specifying the\nquantitative privacy notion of the database, as desired by the data owner.\nInstead of only using the `number of changed rows' metric, our metrics can\ndepend on the locations and amounts of changes in a much more nuanced manner.\nThis will help to make sure that the distance is not larger than the data owner\ndesires (which would undermine privacy), thereby encouraging the adoption of\ndifferentially private data analysis mechanisms. \n\n"}
{"id": "1811.06386", "contents": "Title: Tropical cryptography II: extensions by homomorphisms Abstract: We use extensions of tropical algebras as platforms for very efficient public\nkey exchange protocols. \n\n"}
{"id": "1811.06492", "contents": "Title: Mathematical Analysis of Adversarial Attacks Abstract: In this paper, we analyze efficacy of the fast gradient sign method (FGSM)\nand the Carlini-Wagner's L2 (CW-L2) attack. We prove that, within a certain\nregime, the untargeted FGSM can fool any convolutional neural nets (CNNs) with\nReLU activation; the targeted FGSM can mislead any CNNs with ReLU activation to\nclassify any given image into any prescribed class. For a special two-layer\nneural network: a linear layer followed by the softmax output activation, we\nshow that the CW-L2 attack increases the ratio of the classification\nprobability between the target and ground truth classes. Moreover, we provide\nnumerical results to verify all our theoretical results. \n\n"}
{"id": "1811.06822", "contents": "Title: Best of Both Worlds: Integration of Split Manufacturing and Camouflaging\n  into a Security-Driven CAD Flow for 3D ICs Abstract: With the globalization of manufacturing and supply chains, ensuring the\nsecurity and trustworthiness of ICs has become an urgent challenge. Split\nmanufacturing (SM) and layout camouflaging (LC) are promising techniques to\nprotect the intellectual property (IP) of ICs from malicious entities during\nand after manufacturing (i.e., from untrusted foundries and reverse-engineering\nby end-users). In this paper, we strive for \"the best of both worlds,\" that is\nof SM and LC. To do so, we extend both techniques towards 3D integration, an\nup-and-coming design and manufacturing paradigm based on stacking and\ninterconnecting of multiple chips/dies/tiers. Initially, we review prior art\nand their limitations. We also put forward a novel, practical threat model of\nIP piracy which is in line with the business models of present-day design\nhouses. Next, we discuss how 3D integration is a naturally strong match to\ncombine SM and LC. We propose a security-driven CAD and manufacturing flow for\nface-to-face (F2F) 3D ICs, along with obfuscation of interconnects. Based on\nthis CAD flow, we conduct comprehensive experiments on DRC-clean layouts.\nStrengthened by an extensive security analysis (also based on a novel attack to\nrecover obfuscated F2F interconnects), we argue that entering the next, third\ndimension is eminent for effective and efficient IP protection. \n\n"}
{"id": "1811.06969", "contents": "Title: DARCCC: Detecting Adversaries by Reconstruction from Class Conditional\n  Capsules Abstract: We present a simple technique that allows capsule models to detect\nadversarial images. In addition to being trained to classify images, the\ncapsule model is trained to reconstruct the images from the pose parameters and\nidentity of the correct top-level capsule. Adversarial images do not look like\na typical member of the predicted class and they have much larger\nreconstruction errors when the reconstruction is produced from the top-level\ncapsule for that class. We show that setting a threshold on the $l2$ distance\nbetween the input image and its reconstruction from the winning capsule is very\neffective at detecting adversarial images for three different datasets. The\nsame technique works quite well for CNNs that have been trained to reconstruct\nthe image from all or part of the last hidden layer before the softmax. We then\nexplore a stronger, white-box attack that takes the reconstruction error into\naccount. This attack is able to fool our detection technique but in order to\nmake the model change its prediction to another class, the attack must\ntypically make the \"adversarial\" image resemble images of the other class. \n\n"}
{"id": "1811.07018", "contents": "Title: Protecting Voice Controlled Systems Using Sound Source Identification\n  Based on Acoustic Cues Abstract: Over the last few years, a rapidly increasing number of Internet-of-Things\n(IoT) systems that adopt voice as the primary user input have emerged. These\nsystems have been shown to be vulnerable to various types of voice spoofing\nattacks. Existing defense techniques can usually only protect from a specific\ntype of attack or require an additional authentication step that involves\nanother device. Such defense strategies are either not strong enough or lower\nthe usability of the system. Based on the fact that legitimate voice commands\nshould only come from humans rather than a playback device, we propose a novel\ndefense strategy that is able to detect the sound source of a voice command\nbased on its acoustic features. The proposed defense strategy does not require\nany information other than the voice command itself and can protect a system\nfrom multiple types of spoofing attacks. Our proof-of-concept experiments\nverify the feasibility and effectiveness of this defense strategy. \n\n"}
{"id": "1811.07311", "contents": "Title: Regularized adversarial examples for model interpretability Abstract: As machine learning algorithms continue to improve, there is an increasing\nneed for explaining why a model produces a certain prediction for a certain\ninput. In recent years, several methods for model interpretability have been\ndeveloped, aiming to provide explanation of which subset regions of the model\ninput is the main reason for the model prediction. In parallel, a significant\nresearch community effort is occurring in recent years for developing\nadversarial example generation methods for fooling models, while not altering\nthe true label of the input,as it would have been classified by a human\nannotator. In this paper, we bridge the gap between adversarial example\ngeneration and model interpretability, and introduce a modification to the\nadversarial example generation process which encourages better\ninterpretability. We analyze the proposed method on a public medical imaging\ndataset, both quantitatively and qualitatively, and show that it significantly\noutperforms the leading known alternative method. Our suggested method is\nsimple to implement, and can be easily plugged into most common adversarial\nexample generation frameworks. Additionally, we propose an explanation quality\nmetric - $APE$ - \"Adversarial Perturbative Explanation\", which measures how\nwell an explanation describes model decisions. \n\n"}
{"id": "1811.07375", "contents": "Title: The Taboo Trap: Behavioural Detection of Adversarial Samples Abstract: Deep Neural Networks (DNNs) have become a powerful toolfor a wide range of\nproblems. Yet recent work has found an increasing variety of adversarial\nsamplesthat can fool them. Most existing detection mechanisms against\nadversarial attacksimpose significant costs, either by using additional\nclassifiers to spot adversarial samples, or by requiring the DNN to be\nrestructured. In this paper, we introduce a novel defence. We train our DNN so\nthat, as long as it is workingas intended on the kind of inputs we expect, its\nbehavior is constrained, in that some set of behaviors are taboo. If it is\nexposed to adversarial samples, they will often cause a taboo behavior, which\nwe can detect. Taboos can be both subtle and diverse, so their choice can\nencode and hide information. It is a well-established design principle that the\nsecurity of a system should not depend on the obscurity of its design, but on\nsome variable (the key) which can differ between implementations and bechanged\nas necessary. We discuss how taboos can be used to equip a classifier with just\nsuch a key, and how to tune the keying mechanism to adversaries of various\ncapabilities. We evaluate the performance of a prototype against a wide range\nof attacks and show how our simple defense can defend against cheap attacks at\nscale with zero run-time computation overhead, making it a suitable defense\nmethod for IoT devices. \n\n"}
{"id": "1811.07971", "contents": "Title: Private Selection from Private Candidates Abstract: Differentially Private algorithms often need to select the best amongst many\ncandidate options. Classical works on this selection problem require that the\ncandidates' goodness, measured as a real-valued score function, does not change\nby much when one person's data changes. In many applications such as\nhyperparameter optimization, this stability assumption is much too strong. In\nthis work, we consider the selection problem under a much weaker stability\nassumption on the candidates, namely that the score functions are\ndifferentially private. Under this assumption, we present algorithms that are\nnear-optimal along the three relevant dimensions: privacy, utility and\ncomputational efficiency.\n  Our result can be seen as a generalization of the exponential mechanism and\nits existing generalizations. We also develop an online version of our\nalgorithm, that can be seen as a generalization of the sparse vector technique\nto this weaker stability assumption. We show how our results imply better\nalgorithms for hyperparameter selection in differentially private machine\nlearning, as well as for adaptive data analysis. \n\n"}
{"id": "1811.08569", "contents": "Title: Encryption is Futile: Delay Attacks on High-Precision Clock\n  Synchronization Abstract: Clock synchronization has become essential to modern societies since many\ncritical infrastructures depend on a precise notion of time. This paper\nanalyzes security aspects of high-precision clock synchronization protocols,\nparticularly their alleged protection against delay attacks when clock\nsynchronization traffic is encrypted using standard network security protocols\nsuch as IPsec, MACsec, or TLS. We use the Precision Time Protocol (PTP), the\nmost widely used protocol for high-precision clock synchronization, to\ndemonstrate that statistical traffic analysis can identify properties that\nsupport selective message delay attacks even for encrypted traffic. We\nfurthermore identify a fundamental conflict in secure clock synchronization\nbetween the need of deterministic traffic to improve precision and the need to\nobfuscate traffic in order to mitigate delay attacks.\n  A theoretical analysis of clock synchronization protocols isolates the\ncharacteristics that make these protocols vulnerable to delay attacks and\nargues that such attacks cannot be prevented entirely but only be mitigated.\nKnowledge of the underlying communication network in terms of one-way delays\nand knowledge on physical constraints of these networks can help to compute\nguaranteed maximum bounds for slave clock offsets. These bounds are essential\nfor detecting delay attacks and minimizing their impact. In the general case,\nhowever, the precision that can be guaranteed in adversarial settings is orders\nof magnitude lower than required for high-precision clock synchronization in\ncritical infrastructures, which, therefore, must not rely on a precise notion\nof time when using untrusted networks. \n\n"}
{"id": "1811.08641", "contents": "Title: Malicious Web Request Detection Using Character-level CNN Abstract: Web parameter injection attacks are common and powerful. In this kind of\nattacks, malicious attackers can employ HTTP requests to implement attacks\nagainst servers by injecting some malicious codes into the parameters of the\nHTTP requests. Against the web parameter injection attacks, most of the\nexisting Web Intrusion Detection Systems (WIDS) cannot find unknown new attacks\nand have a high false positive rate (FPR), since they lack the ability of\nre-learning and rarely pay attention to the intrinsic relationship between the\ncharacters. In this paper, we propose a malicious requests detection system\nwith re-learning ability based on an improved convolution neural network (CNN)\nmodel. We add a character-level embedding layer before the convolution layer,\nwhich makes our model able to learn the intrinsic relationship between the\ncharacters of the query string. Further, we modify the filters of CNN and the\nmodified filters can extract the fine-grained features of the query string. The\ntest results demonstrate that our model has lower FPR compared with support\nvector machine (SVM) and random forest (RF). \n\n"}
{"id": "1811.08660", "contents": "Title: The Unwanted Sharing Economy: An Analysis of Cookie Syncing and User\n  Transparency under GDPR Abstract: The European General Data Protection Regulation (GDPR), which went into\neffect in May 2018, leads to important changes in this area: companies are now\nrequired to ask for users' consent before collecting and sharing personal data\nand by law users now have the right to gain access to the personal information\ncollected about them.\n  In this paper, we study and evaluate the effect of the GDPR on the online\nadvertising ecosystem. In a first step, we measure the impact of the\nlegislation on the connections (regarding cookie syncing) between third-parties\nand show that the general structure how the entities are arranged is not\naffected by the GDPR. However, we find that the new regulation has a\nstatistically significant impact on the number of connections, which shrinks by\naround 40%. Furthermore, we analyze the right to data portability by evaluating\nthe subject access right process of popular companies in this ecosystem and\nobserve differences between the processes implemented by the companies and how\nthey interpret the new legislation. We exercised our right of access under GDPR\nwith 36 companies that had tracked us online. Although 32 companies (89%) we\ninquired replied within the period defined by law, only 21 (58%) finished the\nprocess by the deadline set in the GDPR. Our work has implications regarding\nthe implementation of privacy law as well as what online tracking companies\nshould do to be more compliant with the new regulation. \n\n"}
{"id": "1811.09189", "contents": "Title: PAC it up: Towards Pointer Integrity using ARM Pointer Authentication Abstract: Run-time attacks against programs written in memory-unsafe programming\nlanguages (e.g., C and C++) remain a prominent threat against computer systems.\nThe prevalence of techniques like return-oriented programming (ROP) in\nattacking real-world systems has prompted major processor manufacturers to\ndesign hardware-based countermeasures against specific classes of run-time\nattacks. An example is the recently added support for pointer authentication\n(PA) in the ARMv8-A processor architecture, commonly used in devices like\nsmartphones. PA is a low-cost technique to authenticate pointers so as to\nresist memory vulnerabilities. It has been shown to enable practical protection\nagainst memory vulnerabilities that corrupt return addresses or function\npointers. However, so far, PA has received very little attention as a general\npurpose protection mechanism to harden software against various classes of\nmemory attacks. In this paper, we use PA to build novel defenses against\nvarious classes of run-time attacks, including the first PA-based mechanism for\ndata pointer integrity. We present PARTS, an instrumentation framework that\nintegrates our PA-based defenses into the LLVM compiler and the GNU/Linux\noperating system and show, via systematic evaluation, that PARTS provides\nbetter protection than current solutions at a reasonable performance overhead \n\n"}
{"id": "1811.09322", "contents": "Title: On Profitability of Trailing Mining Abstract: We compute the revenue ratio of the Trail Stubborn mining strategy in the\nBitcoin network and compare its profitability to other block-withholding\nstrategies. We use for this martingale techniques and a classical analysis of\nthe hiker problem. In this strategy the attacker could find himself mining in a\nshorter fork, but we prove that for some parameter values it is still\nprofitable to not give up. This confirms previous numerical studies. \n\n"}
{"id": "1811.09600", "contents": "Title: Decoupling Direction and Norm for Efficient Gradient-Based L2\n  Adversarial Attacks and Defenses Abstract: Research on adversarial examples in computer vision tasks has shown that\nsmall, often imperceptible changes to an image can induce misclassification,\nwhich has security implications for a wide range of image processing systems.\nConsidering $L_2$ norm distortions, the Carlini and Wagner attack is presently\nthe most effective white-box attack in the literature. However, this method is\nslow since it performs a line-search for one of the optimization terms, and\noften requires thousands of iterations. In this paper, an efficient approach is\nproposed to generate gradient-based attacks that induce misclassifications with\nlow $L_2$ norm, by decoupling the direction and the norm of the adversarial\nperturbation that is added to the image. Experiments conducted on the MNIST,\nCIFAR-10 and ImageNet datasets indicate that our attack achieves comparable\nresults to the state-of-the-art (in terms of $L_2$ norm) with considerably\nfewer iterations (as few as 100 iterations), which opens the possibility of\nusing these attacks for adversarial training. Models trained with our attack\nachieve state-of-the-art robustness against white-box gradient-based $L_2$\nattacks on the MNIST and CIFAR-10 datasets, outperforming the Madry defense\nwhen the attacks are limited to a maximum norm. \n\n"}
{"id": "1811.09680", "contents": "Title: Enhancing Engagement in Token-Curated Registries via an Inflationary\n  Mechanism Abstract: Token Curated Registries (TCR) are decentralized recommendation systems that\ncan be implemented using Blockchain smart contracts. They allow participants to\nvote for or against adding items to a list through a process that involves\nstaking tokens intrinsic to the registry, with winners receiving the staked\ntokens for each vote. A TCR aims to provide incentives to create a well-curated\nlist. In this work, we consider a challenge for these systems - incentivizing\ntoken-holders to actually engage and participate in the voting process. We\npropose a novel token-inflation mechanism for enhancing engagement, whereby\nonly voting participants see their token supply increased by a pre-defined\nmultiple after each round of voting. To evaluate this proposal, we propose a\nsimple 4-class model of voters that captures all possible combinations of two\nkey dimensions: whether they are engaged (likely to vote at all for a given\nitem) or disengaged, and whether they are informed (likely to vote in a way\nthat increases the quality of the list) or uninformed, and a simple metric to\nevaluate the quality of the list as a function of the vote outcomes. We conduct\nsimulations using this model of voters and show that implementing\ntoken-inflation results in greater wealth accumulation for engaged voters. In\nparticular, when the number of informed voters is sufficiently high, our\nsimulations show that voters that are both informed and engaged see the\ngreatest benefits from participating in the registry when our proposed\ntoken-inflation mechanism is employed. We further validate this finding using a\nsimplified mathematical analysis. \n\n"}
{"id": "1811.09878", "contents": "Title: Hydra: A Peer to Peer Distributed Training & Data Collection Framework Abstract: The world needs diverse and unbiased data to train deep learning models.\nCurrently data comes from a variety of sources that are unmoderated to a large\nextent. The outcomes of training neural networks with unverified data yields\nbiased models with various strains of homophobia, sexism and racism. Another\ntrend observed in the world of deep learning is the rise of distributed\ntraining. Although cloud companies provide high performance compute for\ntraining models in the form of GPU's connected with a low latency network,\nusing these services comes at a high cost. We propose Hydra, a system that\nseeks to solve both of these problems in a novel manner by proposing a\ndecentralized distributed framework which utilizes the substantial amount of\nidle compute of everyday electronic devices like smartphones and desktop\ncomputers for training and data collection purposes. Hydra couples a\nspecialized distributed training framework on a network of these low powered\ndevices with a reward scheme that incentivizes users to provide high quality\ndata to unleash the compute capability on this training framework. Such a\nsystem has the ability to capture data from a wide variety of diverse sources\nwhich has been an issue in the current scenario of deep learning. Hydra brings\nin several new innovations in training on low powered devices including a fault\ntolerant version of the All Reduce algorithm. Furthermore we introduce a\nreinforcement learning policy to decide the size of training jobs on different\nmachines on a heterogeneous cluster of devices with varying network latencies\nfor Synchronous SGD. The novel thing about such a network is the ability of\neach machine to shut down and resume training capabilities at any point of time\nwithout restarting the overall training. To enable such an asynchronous\nbehaviour we propose a communication framework inspired by the Bittorrent\nprotocol and the Kademlia DHT. \n\n"}
{"id": "1811.09931", "contents": "Title: Quantum Differential Cryptanalysis Abstract: In this paper, we propose a quantum version of the differential cryptanalysis\nwhich offers a quadratic speedup over the existing classical one and show the\nquantum circuit implementing it. The quantum differential cryptanalysis is\nbased on the quantum minimum/maximum-finding algorithm, where the values to be\ncompared and filtered are obtained by calling the quantum counting algorithm.\nAny cipher which is vulnerable to the classical differential cryptanalysis\nbased on counting procedures can be cracked more quickly under this quantum\ndifferential attack. \n\n"}
{"id": "1811.09943", "contents": "Title: Countering Selfish Mining in Blockchains Abstract: Selfish mining is a well known vulnerability in blockchains exploited by\nminers to steal block rewards. In this paper, we explore a new form of selfish\nmining attack that guarantees high rewards with low cost. We show the\nfeasibility of this attack facilitated by recent developments in blockchain\ntechnology opening new attack avenues. By outlining the limitations of existing\ncountermeasures, we highlight a need for new defense strategies to counter this\nattack, and leverage key system parameters in blockchain applications to\npropose an algorithm that enforces fair mining. We use the expected transaction\nconfirmation height and block publishing height to detect selfish mining\nbehavior and develop a network-wide defense mechanism to disincentivize selfish\nminers. Our design involves a simple modifications to transactions' data\nstructure in order to obtain a \"truth state\" used to catch the selfish miners\nand prevent honest miners from losing block rewards. \n\n"}
{"id": "1811.09953", "contents": "Title: Faster CryptoNets: Leveraging Sparsity for Real-World Encrypted\n  Inference Abstract: Homomorphic encryption enables arbitrary computation over data while it\nremains encrypted. This privacy-preserving feature is attractive for machine\nlearning, but requires significant computational time due to the large overhead\nof the encryption scheme. We present Faster CryptoNets, a method for efficient\nencrypted inference using neural networks. We develop a pruning and\nquantization approach that leverages sparse representations in the underlying\ncryptosystem to accelerate inference. We derive an optimal approximation for\npopular activation functions that achieves maximally-sparse encodings and\nminimizes approximation error. We also show how privacy-safe training\ntechniques can be used to reduce the overhead of encrypted inference for\nreal-world datasets by leveraging transfer learning and differential privacy.\nOur experiments show that our method maintains competitive accuracy and\nachieves a significant speedup over previous methods. This work increases the\nviability of deep learning systems that use homomorphic encryption to protect\nuser privacy. \n\n"}
{"id": "1811.10256", "contents": "Title: Generalised Differential Privacy for Text Document Processing Abstract: We address the problem of how to \"obfuscate\" texts by removing stylistic\nclues which can identify authorship, whilst preserving (as much as possible)\nthe content of the text. In this paper we combine ideas from \"generalised\ndifferential privacy\" and machine learning techniques for text processing to\nmodel privacy for text documents. We define a privacy mechanism that operates\nat the level of text documents represented as \"bags-of-words\" - these\nrepresentations are typical in machine learning and contain sufficient\ninformation to carry out many kinds of classification tasks including topic\nidentification and authorship attribution (of the original documents). We show\nthat our mechanism satisfies privacy with respect to a metric for semantic\nsimilarity, thereby providing a balance between utility, defined by the\nsemantic content of texts, with the obfuscation of stylistic clues. We\ndemonstrate our implementation on a \"fan fiction\" dataset, confirming that it\nis indeed possible to disguise writing style effectively whilst preserving\nenough information and variation for accurate content classification tasks. \n\n"}
{"id": "1811.10745", "contents": "Title: ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and\n  Robust Accuracies Abstract: Empirical adversarial risk minimization (EARM) is a widely used mathematical\nframework to robustly train deep neural nets (DNNs) that are resistant to\nadversarial attacks. However, both natural and robust accuracies, in\nclassifying clean and adversarial images, respectively, of the trained robust\nmodels are far from satisfactory. In this work, we unify the theory of optimal\ncontrol of transport equations with the practice of training and testing of\nResNets. Based on this unified viewpoint, we propose a simple yet effective\nResNets ensemble algorithm to boost the accuracy of the robustly trained model\non both clean and adversarial images. The proposed algorithm consists of two\ncomponents: First, we modify the base ResNets by injecting a variance specified\nGaussian noise to the output of each residual mapping. Second, we average over\nthe production of multiple jointly trained modified ResNets to get the final\nprediction. These two steps give an approximation to the Feynman-Kac formula\nfor representing the solution of a transport equation with viscosity, or a\nconvection-diffusion equation. For the CIFAR10 benchmark, this simple algorithm\nleads to a robust model with a natural accuracy of {\\bf 85.62}\\% on clean\nimages and a robust accuracy of ${\\bf 57.94 \\%}$ under the 20 iterations of the\nIFGSM attack, which outperforms the current state-of-the-art in defending\nagainst IFGSM attack on the CIFAR10. Both natural and robust accuracies of the\nproposed ResNets ensemble can be improved dynamically as the building block\nResNet advances. The code is available at:\n\\url{https://github.com/BaoWangMath/EnResNet}. \n\n"}
{"id": "1811.11079", "contents": "Title: Robust Classification of Financial Risk Abstract: Algorithms are increasingly common components of high-impact decision-making,\nand a growing body of literature on adversarial examples in laboratory settings\nindicates that standard machine learning models are not robust. This suggests\nthat real-world systems are also susceptible to manipulation or\nmisclassification, which especially poses a challenge to machine learning\nmodels used in financial services. We use the loan grade classification problem\nto explore how machine learning models are sensitive to small changes in\nuser-reported data, using adversarial attacks documented in the literature and\nan original, domain-specific attack. Our work shows that a robust optimization\nalgorithm can build models for financial services that are resistant to\nmisclassification on perturbations. To the best of our knowledge, this is the\nfirst study of adversarial attacks and defenses for deep learning in financial\nservices. \n\n"}
{"id": "1811.11148", "contents": "Title: The Structure of Optimal Private Tests for Simple Hypotheses Abstract: Hypothesis testing plays a central role in statistical inference, and is used\nin many settings where privacy concerns are paramount. This work answers a\nbasic question about privately testing simple hypotheses: given two\ndistributions $P$ and $Q$, and a privacy level $\\varepsilon$, how many i.i.d.\nsamples are needed to distinguish $P$ from $Q$ subject to\n$\\varepsilon$-differential privacy, and what sort of tests have optimal sample\ncomplexity? Specifically, we characterize this sample complexity up to constant\nfactors in terms of the structure of $P$ and $Q$ and the privacy level\n$\\varepsilon$, and show that this sample complexity is achieved by a certain\nrandomized and clamped variant of the log-likelihood ratio test. Our result is\nan analogue of the classical Neyman-Pearson lemma in the setting of private\nhypothesis testing. We also give an application of our result to the private\nchange-point detection. Our characterization applies more generally to\nhypothesis tests satisfying essentially any notion of algorithmic stability,\nwhich is known to imply strong generalization bounds in adaptive data analysis,\nand thus our results have applications even when privacy is not a primary\nconcern. \n\n"}
{"id": "1811.11304", "contents": "Title: Universal Adversarial Training Abstract: Standard adversarial attacks change the predicted class label of a selected\nimage by adding specially tailored small perturbations to its pixels. In\ncontrast, a universal perturbation is an update that can be added to any image\nin a broad class of images, while still changing the predicted class label. We\nstudy the efficient generation of universal adversarial perturbations, and also\nefficient methods for hardening networks to these attacks. We propose a simple\noptimization-based universal attack that reduces the top-1 accuracy of various\nnetwork architectures on ImageNet to less than 20%, while learning the\nuniversal perturbation 13X faster than the standard method.\n  To defend against these perturbations, we propose universal adversarial\ntraining, which models the problem of robust classifier generation as a\ntwo-player min-max game, and produces robust models with only 2X the cost of\nnatural training. We also propose a simultaneous stochastic gradient method\nthat is almost free of extra computation, which allows us to do universal\nadversarial training on ImageNet. \n\n"}
{"id": "1811.11389", "contents": "Title: Image Generation from Layout Abstract: Despite significant recent progress on generative models, controlled\ngeneration of images depicting multiple and complex object layouts is still a\ndifficult problem. Among the core challenges are the diversity of appearance a\ngiven object may possess and, as a result, exponential set of images consistent\nwith a specified layout. To address these challenges, we propose a novel\napproach for layout-based image generation; we call it Layout2Im. Given the\ncoarse spatial layout (bounding boxes + object categories), our model can\ngenerate a set of realistic images which have the correct objects in the\ndesired locations. The representation of each object is disentangled into a\nspecified/certain part (category) and an unspecified/uncertain part\n(appearance). The category is encoded using a word embedding and the appearance\nis distilled into a low-dimensional vector sampled from a normal distribution.\nIndividual object representations are composed together using convolutional\nLSTM, to obtain an encoding of the complete layout, and then decoded to an\nimage. Several loss terms are introduced to encourage accurate and diverse\ngeneration. The proposed Layout2Im model significantly outperforms the previous\nstate of the art, boosting the best reported inception score by 24.66% and\n28.57% on the very challenging COCO-Stuff and Visual Genome datasets,\nrespectively. Extensive experiments also demonstrate our method's ability to\ngenerate complex and diverse images with multiple objects. \n\n"}
{"id": "1811.11493", "contents": "Title: A randomized gradient-free attack on ReLU networks Abstract: It has recently been shown that neural networks but also other classifiers\nare vulnerable to so called adversarial attacks e.g. in object recognition an\nalmost non-perceivable change of the image changes the decision of the\nclassifier. Relatively fast heuristics have been proposed to produce these\nadversarial inputs but the problem of finding the optimal adversarial input,\nthat is with the minimal change of the input, is NP-hard. While methods based\non mixed-integer optimization which find the optimal adversarial input have\nbeen developed, they do not scale to large networks. Currently, the attack\nscheme proposed by Carlini and Wagner is considered to produce the best\nadversarial inputs. In this paper we propose a new attack scheme for the class\nof ReLU networks based on a direct optimization on the resulting linear\nregions. In our experimental validation we improve in all except one experiment\nout of 18 over the Carlini-Wagner attack with a relative improvement of up to\n9\\%. As our approach is based on the geometrical structure of ReLU networks, it\nis less susceptible to defences targeting their functional properties. \n\n"}
{"id": "1811.11629", "contents": "Title: Class of scalable parallel and vectorizable pseudorandom number\n  generators based on non-cryptographic RSA exponentiation ciphers Abstract: Parallel supercomputer-based Monte Carlo and stochastic simulations require\npseudorandom number generators that can produce distinct pseudorandom streams\nacross many independent processes. We propose a scalable class of parallel and\nvectorizable pseudorandom number generators based on a non-cryptographic\nversion of the RSA public-key exponentiation cipher. Our method generates\nuniformly distributed IEEE double-precision floating point pseudorandom\nsequences on $[0,1)$ by encrypting pseudorandom sequences of 64-bit integer\nmessages by modular exponentiation. The advantages of the method are: the\nmethod is parallelizable by parameterization with each pseudorandom number\ngenerator instance derived from an independent 64-bit composite modulus, the\nmethod is fully scalable on massively parallel computing clusters because of\nthe millions of available 32-bit prime numbers, the seeding and initialization\nof the independent streams is simple, the periods of the independent instances\nare all different and greater than $8.5\\times 10^{37}$, and the method passes a\nbattery of intrastream and interstream correlation tests. The calculations in\neach instance can be vectorized using steam splitting and can produce more than\n$10^8$ pseudorandom numbers per second on each multicore CPU. \n\n"}
{"id": "1811.11705", "contents": "Title: An Adversarial Approach for Explainable AI in Intrusion Detection\n  Systems Abstract: Despite the growing popularity of modern machine learning techniques (e.g.\nDeep Neural Networks) in cyber-security applications, most of these models are\nperceived as a black-box for the user. Adversarial machine learning offers an\napproach to increase our understanding of these models. In this paper we\npresent an approach to generate explanations for incorrect classifications made\nby data-driven Intrusion Detection Systems (IDSs). An adversarial approach is\nused to find the minimum modifications (of the input features) required to\ncorrectly classify a given set of misclassified samples. The magnitude of such\nmodifications is used to visualize the most relevant features that explain the\nreason for the misclassification. The presented methodology generated\nsatisfactory explanations that describe the reasoning behind the\nmis-classifications, with descriptions that match expert knowledge. The\nadvantages of the presented methodology are: 1) applicable to any classifier\nwith defined gradients. 2) does not require any modification of the classifier\nmodel. 3) can be extended to perform further diagnosis (e.g. vulnerability\nassessment) and gain further understanding of the system. Experimental\nevaluation was conducted on the NSL-KDD99 benchmark dataset using Linear and\nMultilayer perceptron classifiers. The results are shown using intuitive\nvisualizations in order to improve the interpretability of the results. \n\n"}
{"id": "1811.11858", "contents": "Title: Can you sign a quantum state? Abstract: Cryptography with quantum states exhibits a number of surprising and\ncounterintuitive features. In a 2002 work, Barnum et al. argue that these\nfeatures imply that digital signatures for quantum states are impossible\n(Barnum et al., FOCS 2002). In this work, we ask: can all forms of signing\nquantum data, even in a possibly weak sense, be completely ruled out? We give\ntwo results which shed significant light on this basic question.\n  First, we prove an impossibility result for digital signatures for quantum\ndata, which extends the result of Barnum et al. Specifically, we show that no\nnontrivial combination of correctness and security requirements can be\nfulfilled, beyond what is achievable simply by measuring the quantum message\nand then signing the outcome. In other words, only classical signature schemes\nexist.\n  We then show a positive result: a quantum state can be signed with the same\nsecurity guarantees as classically, provided that it is also encrypted with the\npublic key of the intended recipient. Following classical nomenclature, we call\nthis notion quantum signcryption. Classically, signcryption is only interesting\nif it provides superior performance to encypt-then-sign. Quantumly, it is far\nmore interesting: it is the only signing method available. We develop\n\"as-strong-as-classical\" security definitions for quantum signcryption and give\nsecure constructions based on post-quantum public-key primitives. Along the\nway, we show that a natural hybrid method of combining classical and quantum\nschemes can be used to \"upgrade\" a secure classical scheme to the fully-quantum\nsetting, in a wide range of cryptographic settings including signcryption,\nauthenticated encryption, and CCA security. \n\n"}
{"id": "1811.12395", "contents": "Title: CNN-Cert: An Efficient Framework for Certifying Robustness of\n  Convolutional Neural Networks Abstract: Verifying robustness of neural network classifiers has attracted great\ninterests and attention due to the success of deep neural networks and their\nunexpected vulnerability to adversarial perturbations. Although finding minimum\nadversarial distortion of neural networks (with ReLU activations) has been\nshown to be an NP-complete problem, obtaining a non-trivial lower bound of\nminimum distortion as a provable robustness guarantee is possible. However,\nmost previous works only focused on simple fully-connected layers (multilayer\nperceptrons) and were limited to ReLU activations. This motivates us to propose\na general and efficient framework, CNN-Cert, that is capable of certifying\nrobustness on general convolutional neural networks. Our framework is general\n-- we can handle various architectures including convolutional layers,\nmax-pooling layers, batch normalization layer, residual blocks, as well as\ngeneral activation functions; our approach is efficient -- by exploiting the\nspecial structure of convolutional layers, we achieve up to 17 and 11 times of\nspeed-up compared to the state-of-the-art certification algorithms (e.g.\nFast-Lin, CROWN) and 366 times of speed-up compared to the dual-LP approach\nwhile our algorithm obtains similar or even better verification bounds. In\naddition, CNN-Cert generalizes state-of-the-art algorithms e.g. Fast-Lin and\nCROWN. We demonstrate by extensive experiments that our method outperforms\nstate-of-the-art lower-bound-based certification algorithms in terms of both\nbound quality and speed. \n\n"}
{"id": "1811.12620", "contents": "Title: Change Point Models for Real-time V2I Cyber Attack Detection in a\n  Connected Vehicle Environment Abstract: Connected vehicle (CV) systems are cognizant of potential cyber attacks\nbecause of increasing connectivity between its different components such as\nvehicles, roadside infrastructure and traffic management centers. However, it\nis a challenge to detect security threats in real-time and develop\nappropriate/effective countermeasures for a CV system because of the dynamic\nbehavior of such attacks, high computational power requirement and a historical\ndata requirement for training detection models. To address these challenges,\nstatistical models, especially change point models, have potentials for\nreal-time anomaly detections. Thus, the objective of this study is to\ninvestigate the efficacy of two change point models, Expectation Maximization\n(EM) and Cumulative Sum (CUSUM), for real-time V2I cyber attack detection in a\nCV Environment. To prove the efficacy of these models, we evaluated these two\nmodels for three different type of cyber attack, denial of service (DOS),\nimpersonation, and false information, using basic safety messages (BSMs)\ngenerated from CVs through simulation. Results from numerical analysis revealed\nthat EM and CUSUM could detect these cyber attacks, DOS, impersonation, and\nfalse information, with an accuracy of 99\\%, 100\\%, and 98\\%, and 100\\%, 100\\%\nand 98\\%, respectively. \n\n"}
{"id": "1811.12740", "contents": "Title: Towards Secure and Efficient Payment Channels Abstract: Micropayment channels are the most prominent solution to the limitation on\ntransaction throughput in current blockchain systems. However, in practice\nchannels are risky because participants have to be online constantly to avoid\nfraud, and inefficient because participants have to open multiple channels and\nlock funds in them. To address the security issue, we propose a novel mechanism\nthat involves watchtowers incentivized to watch the channels and reveal a\nfraud. Our protocol does not require participants to be online constantly\nwatching the blockchain. The protocol is secure, incentive compatible and\nlightweight in communication. Furthermore, we present an adaptation of our\nprotocol implementable on the Lightning protocol. Towards efficiency, we\nexamine specific topological structures in the blockchain transaction graph and\ngeneralize the construction of channels to enable topologies better suited to\nspecific real-world needs. In these cases, our construction reduces the\nrequired amount of signatures for a transaction and the total amount of locked\nfunds in the system. \n\n"}
{"id": "1812.00140", "contents": "Title: The Art, Science, and Engineering of Fuzzing: A Survey Abstract: Among the many software vulnerability discovery techniques available today,\nfuzzing has remained highly popular due to its conceptual simplicity, its low\nbarrier to deployment, and its vast amount of empirical evidence in discovering\nreal-world software vulnerabilities. At a high level, fuzzing refers to a\nprocess of repeatedly running a program with generated inputs that may be\nsyntactically or semantically malformed. While researchers and practitioners\nalike have invested a large and diverse effort towards improving fuzzing in\nrecent years, this surge of work has also made it difficult to gain a\ncomprehensive and coherent view of fuzzing. To help preserve and bring\ncoherence to the vast literature of fuzzing, this paper presents a unified,\ngeneral-purpose model of fuzzing together with a taxonomy of the current\nfuzzing literature. We methodically explore the design decisions at every stage\nof our model fuzzer by surveying the related literature and innovations in the\nart, science, and engineering that make modern-day fuzzers effective. \n\n"}
{"id": "1812.00197", "contents": "Title: When a Patch is Not Enough - HardFails: Software-Exploitable Hardware\n  Bugs Abstract: In this paper, we take a deep dive into microarchitectural security from a\nhardware designer's perspective by reviewing the existing approaches to detect\nhardware vulnerabilities during the design phase. We show that a protection gap\ncurrently exists in practice that leaves chip designs vulnerable to\nsoftware-based attacks. In particular, existing verification approaches fail to\ndetect specific classes of vulnerabilities, which we call HardFails: these bugs\nevade detection by current verification techniques while being exploitable from\nsoftware. We demonstrate such vulnerabilities in real-world SoCs using RISC-V\nto showcase and analyze concrete instantiations of HardFails. Patching these\nhardware bugs may not always be possible and can potentially result in a\nproduct recall. We base our findings on two extensive case studies: the recent\nHack@DAC 2018 hardware security competition, where 54 independent teams of\nresearchers competed world-wide over a period of 12 weeks to catch inserted\nsecurity bugs in SoC RTL designs, and an in-depth systematic evaluation of\nstate-of-the-art verification approaches. Our findings indicate that even\ncombinations of techniques will miss high-impact bugs due to the large number\nof modules with complex interdependencies and fundamental limitations of\ncurrent detection approaches. We also craft a real-world software attack that\nexploits one of the RTL bugs from Hack@DAC that evaded detection and discuss\nnovel approaches to mitigate the growing problem of cross-layer bugs at design\ntime. \n\n"}
{"id": "1812.00910", "contents": "Title: Comprehensive Privacy Analysis of Deep Learning: Passive and Active\n  White-box Inference Attacks against Centralized and Federated Learning Abstract: Deep neural networks are susceptible to various inference attacks as they\nremember information about their training data. We design white-box inference\nattacks to perform a comprehensive privacy analysis of deep learning models. We\nmeasure the privacy leakage through parameters of fully trained models as well\nas the parameter updates of models during training. We design inference\nalgorithms for both centralized and federated learning, with respect to passive\nand active inference attackers, and assuming different adversary prior\nknowledge.\n  We evaluate our novel white-box membership inference attacks against deep\nlearning algorithms to trace their training data records. We show that a\nstraightforward extension of the known black-box attacks to the white-box\nsetting (through analyzing the outputs of activation functions) is ineffective.\nWe therefore design new algorithms tailored to the white-box setting by\nexploiting the privacy vulnerabilities of the stochastic gradient descent\nalgorithm, which is the algorithm used to train deep neural networks. We\ninvestigate the reasons why deep learning models may leak information about\ntheir training data. We then show that even well-generalized models are\nsignificantly susceptible to white-box membership inference attacks, by\nanalyzing state-of-the-art pre-trained and publicly available models for the\nCIFAR dataset. We also show how adversarial participants, in the federated\nlearning setting, can successfully run active membership inference attacks\nagainst other participants, even when the global model achieves high prediction\naccuracies. \n\n"}
{"id": "1812.00942", "contents": "Title: TxProbe: Discovering Bitcoin's Network Topology Using Orphan\n  Transactions Abstract: Bitcoin relies on a peer-to-peer overlay network to broadcast transactions\nand blocks. From the viewpoint of network measurement, we would like to observe\nthis topology so we can characterize its performance, fairness and robustness.\nHowever, this is difficult because Bitcoin is deliberately designed to hide its\ntopology from onlookers. Knowledge of the topology is not in itself a\nvulnerability, although it could conceivably help an attacker performing\ntargeted eclipse attacks or to deanonymize transaction senders.\n  In this paper we present TxProbe, a novel technique for reconstructing the\nBitcoin network topology. TxProbe makes use of peculiarities in how Bitcoin\nprocesses out of order, or \"orphaned\" transactions. We conducted experiments on\nBitcoin testnet that suggest our technique reconstructs topology with precision\nand recall surpassing 90%. We also used TxProbe to take a snapshot of the\nBitcoin testnet in just a few hours. TxProbe may be useful for future\nmeasurement campaigns of Bitcoin or other cryptocurrency networks. \n\n"}
{"id": "1812.02055", "contents": "Title: Calibrate: Frequency Estimation and Heavy Hitter Identification with\n  Local Differential Privacy via Incorporating Prior Knowledge Abstract: Estimating frequencies of certain items among a population is a basic step in\ndata analytics, which enables more advanced data analytics (e.g., heavy hitter\nidentification, frequent pattern mining), client software optimization, and\ndetecting unwanted or malicious hijacking of user settings in browsers.\nFrequency estimation and heavy hitter identification with local differential\nprivacy (LDP) protect user privacy as well as the data collector. Existing LDP\nalgorithms cannot leverage 1) prior knowledge about the noise in the estimated\nitem frequencies and 2) prior knowledge about the true item frequencies. As a\nresult, they achieve suboptimal performance in practice.\n  In this work, we aim to design LDP algorithms that can leverage such prior\nknowledge. Specifically, we design ${Calibrate}$ to incorporate the prior\nknowledge via statistical inference. ${Calibrate}$ can be appended to an\nexisting LDP algorithm to reduce its estimation errors. We model the prior\nknowledge about the noise and the true item frequencies as two probability\ndistributions, respectively. Given the two probability distributions and an\nestimated frequency of an item produced by an existing LDP algorithm, our\n${Calibrate}$ computes the conditional probability distribution of the item's\nfrequency and uses the mean of the conditional probability distribution as the\ncalibrated frequency for the item. It is challenging to estimate the two\nprobability distributions due to data sparsity. We address the challenge via\nintegrating techniques from statistics and machine learning. Our empirical\nresults on two real-world datasets show that ${Calibrate}$ significantly\noutperforms state-of-the-art LDP algorithms for frequency estimation and heavy\nhitter identification. \n\n"}
{"id": "1812.02428", "contents": "Title: A Review of Homomorphic Encryption Libraries for Secure Computation Abstract: In this paper we provide a survey of various libraries for homomorphic\nencryption. We describe key features and trade-offs that should be considered\nwhile choosing the right approach for secure computation. We then present a\ncomparison of six commonly available Homomorphic Encryption libraries - SEAL,\nHElib, TFHE, Paillier, ELGamal and RSA across these identified features.\nSupport for different languages and real-life applications are also elucidated. \n\n"}
{"id": "1812.02575", "contents": "Title: Prior Networks for Detection of Adversarial Attacks Abstract: Adversarial examples are considered a serious issue for safety critical\napplications of AI, such as finance, autonomous vehicle control and medicinal\napplications. Though significant work has resulted in increased robustness of\nsystems to these attacks, systems are still vulnerable to well-crafted attacks.\nTo address this problem, several adversarial attack detection methods have been\nproposed. However, a system can still be vulnerable to adversarial samples that\nare designed to specifically evade these detection methods. One recent\ndetection scheme that has shown good performance is based on uncertainty\nestimates derived from Monte-Carlo dropout ensembles. Prior Networks, a new\nmethod of estimating predictive uncertainty, has been shown to outperform\nMonte-Carlo dropout on a range of tasks. One of the advantages of this approach\nis that the behaviour of a Prior Network can be explicitly tuned to, for\nexample, predict high uncertainty in regions where there are no training data\nsamples. In this work, Prior Networks are applied to adversarial attack\ndetection using measures of uncertainty in a similar fashion to Monte-Carlo\nDropout. Detection based on measures of uncertainty derived from DNNs and\nMonte-Carlo dropout ensembles are used as a baseline. Prior Networks are shown\nto significantly out-perform these baseline approaches over a range of\nadversarial attacks in both detection of whitebox and blackbox configurations.\nEven when the adversarial attacks are constructed with full knowledge of the\ndetection mechanism, it is shown to be highly challenging to successfully\ngenerate an adversarial sample. \n\n"}
{"id": "1812.02606", "contents": "Title: The Limitations of Model Uncertainty in Adversarial Settings Abstract: Machine learning models are vulnerable to adversarial examples: minor\nperturbations to input samples intended to deliberately cause\nmisclassification. While an obvious security threat, adversarial examples yield\nas well insights about the applied model itself. We investigate adversarial\nexamples in the context of Bayesian neural network's (BNN's) uncertainty\nmeasures. As these measures are highly non-smooth, we use a smooth Gaussian\nprocess classifier (GPC) as substitute. We show that both confidence and\nuncertainty can be unsuspicious even if the output is wrong. Intriguingly, we\nfind subtle differences in the features influencing uncertainty and confidence\nfor most tasks. \n\n"}
{"id": "1812.02766", "contents": "Title: Knockoff Nets: Stealing Functionality of Black-Box Models Abstract: Machine Learning (ML) models are increasingly deployed in the wild to perform\na wide range of tasks. In this work, we ask to what extent can an adversary\nsteal functionality of such \"victim\" models based solely on blackbox\ninteractions: image in, predictions out. In contrast to prior work, we present\nan adversary lacking knowledge of train/test data used by the model, its\ninternals, and semantics over model outputs. We formulate model functionality\nstealing as a two-step approach: (i) querying a set of input images to the\nblackbox model to obtain predictions; and (ii) training a \"knockoff\" with\nqueried image-prediction pairs. We make multiple remarkable observations: (a)\nquerying random images from a different distribution than that of the blackbox\ntraining data results in a well-performing knockoff; (b) this is possible even\nwhen the knockoff is represented using a different architecture; and (c) our\nreinforcement learning approach additionally improves query sample efficiency\nin certain settings and provides performance gains. We validate model\nfunctionality stealing on a range of datasets and tasks, as well as on a\npopular image analysis API where we create a reasonable knockoff for as little\nas $30. \n\n"}
{"id": "1812.02848", "contents": "Title: Cyber Anomaly Detection Using Graph-node Role-dynamics Abstract: Intrusion detection systems (IDSs) generate valuable knowledge about network\nsecurity, but an abundance of false alarms and a lack of methods to capture the\ninterdependence among alerts hampers their utility for network defense. Here,\nwe explore a graph-based approach for fusing alerts generated by multiple IDSs\n(e.g., Snort, OSSEC, and Bro). Our approach generates a weighted graph of alert\nfields (not network topology) that makes explicit the connections between\nmultiple alerts, IDS systems, and other cyber artifacts. We use this\nmulti-modal graph to identify anomalous changes in the alert patterns of a\nnetwork. To detect the anomalies, we apply the role-dynamics approach, which\nhas successfully identified anomalies in social media, email, and IP\ncommunication graphs. In the cyber domain, each node (alert field) in the fused\nIDS alert graph is assigned a probability distribution across a small set of\nroles based on that node's features. A cyber attack should trigger IDS alerts\nand cause changes in the node features, but rather than track every feature for\nevery alert-field node individually, roles provide a succinct, integrated\nsummary of those feature changes. We measure changes in each node's\nprobabilistic role assignment over time, and identify anomalies as deviations\nfrom expected roles. We test our approach using simulations including three\nweeks of normal background traffic, as well as cyber attacks that occur near\nthe end of the simulations. This paper presents a novel approach to multi-modal\ndata fusion and a novel application of role dynamics within the cyber-security\ndomain. Our results show a drastic decrease in the false-positive rate when\nconsidering our anomaly indicator instead of the IDS alerts themselves, thereby\nreducing alarm fatigue and providing a promising avenue for threat intelligence\nin network defense. \n\n"}
{"id": "1812.02863", "contents": "Title: Privacy Partitioning: Protecting User Data During the Deep Learning\n  Inference Phase Abstract: We present a practical method for protecting data during the inference phase\nof deep learning based on bipartite topology threat modeling and an interactive\nadversarial deep network construction. We term this approach \\emph{Privacy\nPartitioning}. In the proposed framework, we split the machine learning models\nand deploy a few layers into users' local devices, and the rest of the layers\ninto a remote server. We propose an approach to protect user's data during the\ninference phase, while still achieve good classification accuracy.\n  We conduct an experimental evaluation of this approach on benchmark datasets\nof three computer vision tasks. The experimental results indicate that this\napproach can be used to significantly attenuate the capacity for an adversary\nwith access to the state-of-the-art deep network's intermediate states to learn\nprivacy-sensitive inputs to the network. For example, we demonstrate that our\napproach can prevent attackers from inferring the private attributes such as\ngender from the Face image dataset without sacrificing the classification\naccuracy of the original machine learning task such as Face Identification. \n\n"}
{"id": "1812.03087", "contents": "Title: Combatting Adversarial Attacks through Denoising and Dimensionality\n  Reduction: A Cascaded Autoencoder Approach Abstract: Machine Learning models are vulnerable to adversarial attacks that rely on\nperturbing the input data. This work proposes a novel strategy using\nAutoencoder Deep Neural Networks to defend a machine learning model against two\ngradient-based attacks: The Fast Gradient Sign attack and Fast Gradient attack.\nFirst we use an autoencoder to denoise the test data, which is trained with\nboth clean and corrupted data. Then, we reduce the dimension of the denoised\ndata using the hidden layer representation of another autoencoder. We perform\nthis experiment for multiple values of the bound of adversarial perturbations,\nand consider different numbers of reduced dimensions. When the test data is\npreprocessed using this cascaded pipeline, the tested deep neural network\nclassifier yields a much higher accuracy, thus mitigating the effect of the\nadversarial perturbation. \n\n"}
{"id": "1812.03230", "contents": "Title: Reaching Data Confidentiality and Model Accountability on the CalTrain Abstract: Distributed collaborative learning (DCL) paradigms enable building joint\nmachine learning models from distrusting multi-party participants. Data\nconfidentiality is guaranteed by retaining private training data on each\nparticipant's local infrastructure. However, this approach to achieving data\nconfidentiality makes today's DCL designs fundamentally vulnerable to data\npoisoning and backdoor attacks. It also limits DCL's model accountability,\nwhich is key to backtracking the responsible \"bad\" training data\ninstances/contributors. In this paper, we introduce CALTRAIN, a Trusted\nExecution Environment (TEE) based centralized multi-party collaborative\nlearning system that simultaneously achieves data confidentiality and model\naccountability. CALTRAIN enforces isolated computation on centrally aggregated\ntraining data to guarantee data confidentiality. To support building\naccountable learning models, we securely maintain the links between training\ninstances and their corresponding contributors. Our evaluation shows that the\nmodels generated from CALTRAIN can achieve the same prediction accuracy when\ncompared to the models trained in non-protected environments. We also\ndemonstrate that when malicious training participants tend to implant backdoors\nduring model training, CALTRAIN can accurately and precisely discover the\npoisoned and mislabeled training data that lead to the runtime mispredictions. \n\n"}
{"id": "1812.03303", "contents": "Title: Detecting Adversarial Examples in Convolutional Neural Networks Abstract: The great success of convolutional neural networks has caused a massive\nspread of the use of such models in a large variety of Computer Vision\napplications. However, these models are vulnerable to certain inputs, the\nadversarial examples, which although are not easily perceived by humans, they\ncan lead a neural network to produce faulty results. This paper focuses on the\ndetection of adversarial examples, which are created for convolutional neural\nnetworks that perform image classification. We propose three methods for\ndetecting possible adversarial examples and after we analyze and compare their\nperformance, we combine their best aspects to develop an even more robust\napproach. The first proposed method is based on the regularization of the\nfeature vector that the neural network produces as output. The second method\ndetects adversarial examples by using histograms, which are created from the\noutputs of the hidden layers of the neural network. These histograms create a\nfeature vector which is used as the input of an SVM classifier, which\nclassifies the original input either as an adversarial or as a real input.\nFinally, for the third method we introduce the concept of the residual image,\nwhich contains information about the parts of the input pattern that are\nignored by the neural network. This method aims at the detection of possible\nadversarial examples, by using the residual image and reinforcing the parts of\nthe input pattern that are ignored by the neural network. Each one of these\nmethods has some novelties and by combining them we can further improve the\ndetection results. For the proposed methods and their combination, we present\nthe results of detecting adversarial examples on the MNIST dataset. The\ncombination of the proposed methods offers some improvements over similar state\nof the art approaches. \n\n"}
{"id": "1812.03639", "contents": "Title: Crossfire Attack Detection using Deep Learning in Software Defined ITS\n  Networks Abstract: Recent developments in intelligent transport systems (ITS) based on smart\nmobility significantly improves safety and security over roads and highways.\nITS networks are comprised of the Internet-connected vehicles (mobile nodes),\nroadside units (RSU), cellular base stations and conventional core network\nrouters to create a complete data transmission platform that provides real-time\ntraffic information and enable prediction of future traffic conditions.\nHowever, the heterogeneity and complexity of the underlying ITS networks raise\nnew challenges in intrusion prevention of mobile network nodes and detection of\nsecurity attacks due to such highly vulnerable mobile nodes. In this paper, we\nconsider a new type of security attack referred to as crossfire attack, which\ninvolves a large number of compromised nodes that generate low-intensity\ntraffic in a temporally coordinated fashion such that target links or hosts\n(victims) are disconnected from the rest of the network. Detection of such\nattacks is challenging since the attacking traffic flows are indistinguishable\nfrom the legitimate flows. With the support of software-defined networking that\nenables dynamic network monitoring and traffic characteristic extraction, we\ndevelop a machine learning model that can learn the temporal correlation among\ntraffic flows traversing in the ITS network, thus differentiating legitimate\nflows from coordinated attacking flows. We use different deep learning\nalgorithms to train the model and study the performance using Mininet-WiFi\nemulation platform. The results show that our approach achieves a detection\naccuracy of at least 80%. \n\n"}
{"id": "1812.03705", "contents": "Title: Defending Against Universal Perturbations With Shared Adversarial\n  Training Abstract: Classifiers such as deep neural networks have been shown to be vulnerable\nagainst adversarial perturbations on problems with high-dimensional input\nspace. While adversarial training improves the robustness of image classifiers\nagainst such adversarial perturbations, it leaves them sensitive to\nperturbations on a non-negligible fraction of the inputs. In this work, we show\nthat adversarial training is more effective in preventing universal\nperturbations, where the same perturbation needs to fool a classifier on many\ninputs. Moreover, we investigate the trade-off between robustness against\nuniversal perturbations and performance on unperturbed data and propose an\nextension of adversarial training that handles this trade-off more gracefully.\nWe present results for image classification and semantic segmentation to\nshowcase that universal perturbations that fool a model hardened with\nadversarial training become clearly perceptible and show patterns of the target\nscene. \n\n"}
{"id": "1812.04142", "contents": "Title: Private Polynomial Computation from Lagrange Encoding Abstract: Private computation is a generalization of private information retrieval, in\nwhich a user is able to compute a function on a distributed dataset without\nrevealing the identity of that function to the servers. In this paper it is\nshown that Lagrange encoding, a powerful technique for encoding Reed-Solomon\ncodes, enables private computation in many cases of interest. In particular, we\npresent a scheme that enables private computation of polynomials of any degree\non Lagrange encoded data, while being robust to Byzantine and straggling\nservers, and to servers colluding to attempt to deduce the identities of the\nfunctions to be evaluated. Moreover, incorporating ideas from the well-known\nShamir secret sharing scheme allows the data itself to be concealed from the\nservers as well. Our results extend private computation to high degree\npolynomials and to data-privacy, and reveal a tight connection between private\ncomputation and coded computation. \n\n"}
{"id": "1812.04852", "contents": "Title: Recurrent Neural Networks for Fuzz Testing Web Browsers Abstract: Generation-based fuzzing is a software testing approach which is able to\ndiscover different types of bugs and vulnerabilities in software. It is,\nhowever, known to be very time consuming to design and fine tune classical\nfuzzers to achieve acceptable coverage, even for small-scale software systems.\nTo address this issue, we investigate a machine learning-based approach to fuzz\ntesting in which we outline a family of test-case generators based on Recurrent\nNeural Networks (RNNs) and train those on readily available datasets with a\nminimum of human fine tuning. The proposed generators do, in contrast to\nprevious work, not rely on heuristic sampling strategies but principled\nsampling from the predictive distributions. We provide a detailed analysis to\ndemonstrate the characteristics and efficacy of the proposed generators in a\nchallenging web browser testing scenario. The empirical results show that the\nRNN-based generators are able to provide better coverage than a mutation based\nmethod and are able to discover paths not discovered by a classical fuzzer. Our\nresults supplement findings in other domains suggesting that generation based\nfuzzing with RNNs is a viable route to better software quality conditioned on\nthe use of a suitable model selection/analysis procedure. \n\n"}
{"id": "1812.04959", "contents": "Title: Systematic Parsing of X.509: Eradicating Security Issues with a Parse\n  Tree Abstract: X.509 certificate parsing and validation is a critical task which has shown\nconsistent lack of effectiveness, with practical attacks being reported with a\nsteady rate during the last 10 years. In this work we analyze the X.509\nstandard and provide a grammar description of it amenable to the automated\ngeneration of a parser with strong termination guarantees, providing\nunambiguous input parsing. We report the results of analyzing a 11M X.509\ncertificate dump of the HTTPS servers running on the entire IPv4 space, showing\nthat 21.5% of the certificates in use are syntactically invalid. We compare the\nresults of our parsing against 7 widely used TLS libraries showing that 631k to\n1,156k syntactically incorrect certificates are deemed valid by them\n(5.7%--10.5%), including instances with security critical mis-parsings. We\nprove the criticality of such mis-parsing exploiting one of the syntactic flaws\nfound in existing certificates to perform an impersonation attack. \n\n"}
{"id": "1812.05252", "contents": "Title: Dynamic Fusion with Intra- and Inter- Modality Attention Flow for Visual\n  Question Answering Abstract: Learning effective fusion of multi-modality features is at the heart of\nvisual question answering. We propose a novel method of dynamically fusing\nmulti-modal features with intra- and inter-modality information flow, which\nalternatively pass dynamic information between and across the visual and\nlanguage modalities. It can robustly capture the high-level interactions\nbetween language and vision domains, thus significantly improves the\nperformance of visual question answering. We also show that the proposed\ndynamic intra-modality attention flow conditioned on the other modality can\ndynamically modulate the intra-modality attention of the target modality, which\nis vital for multimodality feature fusion. Experimental evaluations on the VQA\n2.0 dataset show that the proposed method achieves state-of-the-art VQA\nperformance. Extensive ablation studies are carried out for the comprehensive\nanalysis of the proposed method. \n\n"}
{"id": "1812.05671", "contents": "Title: Construction of Differentially Private Empirical Distributions from a\n  low-order Marginals Set through Solving Linear Equations with l2\n  Regularization Abstract: We introduce a new algorithm, Construction of dIfferentially Private\nEmpirical Distributions from a low-order marginals set tHrough solving linear\nEquations with l2 Regularization (CIPHER), that produces differentially private\nempirical joint distributions from a set of low-order marginals. CIPHER is\nconceptually simple and requires no more than decomposing joint probabilities\nvia basic probability rules to construct a linear equation set and subsequently\nsolving the equations. Compared to the full-dimensional histogram (FDH)\nsanitization, CIPHER has drastic\\-ally lower requirements on computational\nstorage and memory, which is practically attractive especially considering that\nthe high-order signals preserved by the FDH sanitization are likely just sample\nrandomness and rarely of interest. Our experiments demonstrate that CIPHER\noutperforms the multiplicative weighting exponential mechanism in preserving\noriginal information and has similar or superior cost-normalized utility to FDH\nsanitization at the same privacy budget. \n\n"}
{"id": "1812.05710", "contents": "Title: FPETS : Fully Parallel End-to-End Text-to-Speech System Abstract: End-to-end Text-to-speech (TTS) system can greatly improve the quality of\nsynthesised speech. But it usually suffers form high time latency due to its\nauto-regressive structure. And the synthesised speech may also suffer from some\nerror modes, e.g. repeated words, mispronunciations, and skipped words. In this\npaper, we propose a novel non-autoregressive, fully parallel end-to-end TTS\nsystem (FPETS). It utilizes a new alignment model and the recently proposed\nU-shape convolutional structure, UFANS. Different from RNN, UFANS can capture\nlong term information in a fully parallel manner. Trainable position encoding\nand two-step training strategy are used for learning better alignments.\nExperimental results show FPETS utilizes the power of parallel computation and\nreaches a significant speed up of inference compared with state-of-the-art\nend-to-end TTS systems. More specifically, FPETS is 600X faster than Tacotron2,\n50X faster than DCTTS and 10X faster than Deep Voice3. And FPETS can generates\naudios with equal or better quality and fewer errors comparing with other\nsystem. As far as we know, FPETS is the first end-to-end TTS system which is\nfully parallel. \n\n"}
{"id": "1812.05725", "contents": "Title: Training Set Camouflage Abstract: We introduce a form of steganography in the domain of machine learning which\nwe call training set camouflage. Imagine Alice has a training set on an illicit\nmachine learning classification task. Alice wants Bob (a machine learning\nsystem) to learn the task. However, sending either the training set or the\ntrained model to Bob can raise suspicion if the communication is monitored.\nTraining set camouflage allows Alice to compute a second training set on a\ncompletely different -- and seemingly benign -- classification task. By\nconstruction, sending the second training set will not raise suspicion. When\nBob applies his standard (public) learning algorithm to the second training\nset, he approximately recovers the classifier on the original task. Training\nset camouflage is a novel form of steganography in machine learning. We\nformulate training set camouflage as a combinatorial bilevel optimization\nproblem and propose solvers based on nonlinear programming and local search.\nExperiments on real classification tasks demonstrate the feasibility of such\ncamouflage. \n\n"}
{"id": "1812.07989", "contents": "Title: A Gated Peripheral-Foveal Convolutional Neural Network for Unified Image\n  Aesthetic Prediction Abstract: Learning fine-grained details is a key issue in image aesthetic assessment.\nMost of the previous methods extract the fine-grained details via random\ncropping strategy, which may undermine the integrity of semantic information.\nExtensive studies show that humans perceive fine-grained details with a mixture\nof foveal vision and peripheral vision. Fovea has the highest possible visual\nacuity and is responsible for seeing the details. The peripheral vision is used\nfor perceiving the broad spatial scene and selecting the attended regions for\nthe fovea. Inspired by these observations, we propose a Gated Peripheral-Foveal\nConvolutional Neural Network (GPF-CNN). It is a dedicated double-subnet neural\nnetwork, i.e. a peripheral subnet and a foveal subnet. The former aims to mimic\nthe functions of peripheral vision to encode the holistic information and\nprovide the attended regions. The latter aims to extract fine-grained features\non these key regions. Considering that the peripheral vision and foveal vision\nplay different roles in processing different visual stimuli, we further employ\na gated information fusion (GIF) network to weight their contributions. The\nweights are determined through the fully connected layers followed by a sigmoid\nfunction. We conduct comprehensive experiments on the standard AVA and\nPhoto.net datasets for unified aesthetic prediction tasks: (i) aesthetic\nquality classification; (ii) aesthetic score regression; and (iii) aesthetic\nscore distribution prediction. The experimental results demonstrate the\neffectiveness of the proposed method. \n\n"}
{"id": "1812.08043", "contents": "Title: Learning beamforming in ultrasound imaging Abstract: Medical ultrasound (US) is a widespread imaging modality owing its popularity\nto cost efficiency, portability, speed, and lack of harmful ionizing radiation.\nIn this paper, we demonstrate that replacing the traditional ultrasound\nprocessing pipeline with a data-driven, learnable counterpart leads to\nsignificant improvement in image quality. Moreover, we demonstrate that greater\nimprovement can be achieved through a learning-based design of the transmitted\nbeam patterns simultaneously with learning an image reconstruction pipeline. We\nevaluate our method on an in-vivo first-harmonic cardiac ultrasound dataset\nacquired from volunteers and demonstrate the significance of the learned\npipeline and transmit beam patterns on the image quality when compared to\nstandard transmit and receive beamformers used in high frame-rate US imaging.\nWe believe that the presented methodology provides a fundamentally different\nperspective on the classical problem of ultrasound beam pattern design. \n\n"}
{"id": "1812.08806", "contents": "Title: Blockchain and Cryptocurrency: A comparative framework of the main\n  Architectural Drivers Abstract: Blockchain is a decentralized transaction and data management solution, the\ntechnological weapon-of-choice behind the success of Bitcoin and other\ncryptocurrencies. As the number and variety of existing blockchain\nimplementations continues to increase, adopters should focus on selecting the\nbest one to support their decentralized applications (dApps), rather than\ndeveloping new ones from scratch. In this paper we present a framework to aid\nsoftware architects, developers, tool selectors and decision makers to adopt\nthe right blockchain technology for their problem at hand. The framework\nexposes the correlation between technological decisions and architectural\nfeatures, capturing the knowledge from existing industrial products, technical\nforums/blogs, experts' feedback and academic literature; plus our own\nexperience using and developing blockchain-based applications. We validate our\nframework by applying it to dissect the most outstanding blockchain platforms,\ni.e., the ones behind the top 10 cryptocurrencies apart from Bitcoin. Then, we\nshow how we applied it to a real-world case study in the insurtech domain. \n\n"}
{"id": "1812.09127", "contents": "Title: A Smart Security System with Face Recognition Abstract: Web-based technology has improved drastically in the past decade. As a\nresult, security technology has become a major help to protect our daily life.\nIn this paper, we propose a robust security based on face recognition system\n(SoF). In particular, we develop this system to giving access into a home for\nauthenticated users. The classifier is trained by using a new adaptive learning\nmethod. The training data are initially collected from social networks. The\naccuracy of the classifier is incrementally improved as the user starts using\nthe system. A novel method has been introduced to improve the classifier model\nby human interaction and social media. By using a deep learning framework -\nTensorFlow, it will be easy to reuse the framework to adopt with many devices\nand applications. \n\n"}
{"id": "1812.09323", "contents": "Title: Unsupervised Speech Recognition via Segmental Empirical Output\n  Distribution Matching Abstract: We consider the problem of training speech recognition systems without using\nany labeled data, under the assumption that the learner can only access to the\ninput utterances and a phoneme language model estimated from a non-overlapping\ncorpus. We propose a fully unsupervised learning algorithm that alternates\nbetween solving two sub-problems: (i) learn a phoneme classifier for a given\nset of phoneme segmentation boundaries, and (ii) refining the phoneme\nboundaries based on a given classifier. To solve the first sub-problem, we\nintroduce a novel unsupervised cost function named Segmental Empirical Output\nDistribution Matching, which generalizes the work in (Liu et al., 2017) to\nsegmental structures. For the second sub-problem, we develop an approximate MAP\napproach to refining the boundaries obtained from Wang et al. (2017).\nExperimental results on TIMIT dataset demonstrate the success of this fully\nunsupervised phoneme recognition system, which achieves a phone error rate\n(PER) of 41.6%. Although it is still far away from the state-of-the-art\nsupervised systems, we show that with oracle boundaries and matching language\nmodel, the PER could be improved to 32.5%.This performance approaches the\nsupervised system of the same model architecture, demonstrating the great\npotential of the proposed method. \n\n"}
{"id": "1812.09400", "contents": "Title: Towards resilient machine learning for ransomware detection Abstract: There has been a surge of interest in using machine learning (ML) to\nautomatically detect malware through their dynamic behaviors. These approaches\nhave achieved significant improvement in detection rates and lower false\npositive rates at large scale compared with traditional malware analysis\nmethods. ML in threat detection has demonstrated to be a good cop to guard\nplatform security. However it is imperative to evaluate - is ML-powered\nsecurity resilient enough?\n  In this paper, we juxtapose the resiliency and trustworthiness of ML\nalgorithms for security, via a case study of evaluating the resiliency of\nransomware detection via the generative adversarial network (GAN). In this case\nstudy, we propose to use GAN to automatically produce dynamic features that\nexhibit generalized malicious behaviors that can reduce the efficacy of\nblack-box ransomware classifiers. We examine the quality of the GAN-generated\nsamples by comparing the statistical similarity of these samples to real\nransomware and benign software. Further we investigate the latent subspace\nwhere the GAN-generated samples lie and explore reasons why such samples cause\na certain class of ransomware classifiers to degrade in performance. Our focus\nis to emphasize necessary defense improvement in ML-based approaches for\nransomware detection before deployment in the wild. Our results and discoveries\nshould pose relevant questions for defenders such as how ML models can be made\nmore resilient for robust enforcement of security objectives. \n\n"}
{"id": "1812.09803", "contents": "Title: Guessing Smart: Biased Sampling for Efficient Black-Box Adversarial\n  Attacks Abstract: We consider adversarial examples for image classification in the black-box\ndecision-based setting. Here, an attacker cannot access confidence scores, but\nonly the final label. Most attacks for this scenario are either unreliable or\ninefficient. Focusing on the latter, we show that a specific class of attacks,\nBoundary Attacks, can be reinterpreted as a biased sampling framework that\ngains efficiency from domain knowledge. We identify three such biases, image\nfrequency, regional masks and surrogate gradients, and evaluate their\nperformance against an ImageNet classifier. We show that the combination of\nthese biases outperforms the state of the art by a wide margin. We also\nshowcase an efficient way to attack the Google Cloud Vision API, where we craft\nconvincing perturbations with just a few hundred queries. Finally, the methods\nwe propose have also been found to work very well against strong defenses: Our\ntargeted attack won second place in the NeurIPS 2018 Adversarial Vision\nChallenge. \n\n"}
{"id": "1812.10113", "contents": "Title: Privacy-Preserving Collaborative Deep Learning with Unreliable\n  Participants Abstract: With powerful parallel computing GPUs and massive user data,\nneural-network-based deep learning can well exert its strong power in problem\nmodeling and solving, and has archived great success in many applications such\nas image classification, speech recognition and machine translation etc. While\ndeep learning has been increasingly popular, the problem of privacy leakage\nbecomes more and more urgent. Given the fact that the training data may contain\nhighly sensitive information, e.g., personal medical records, directly sharing\nthem among the users (i.e., participants) or centrally storing them in one\nsingle location may pose a considerable threat to user privacy.\n  In this paper, we present a practical privacy-preserving collaborative deep\nlearning system that allows users to cooperatively build a collective deep\nlearning model with data of all participants, without direct data sharing and\ncentral data storage. In our system, each participant trains a local model with\ntheir own data and only shares model parameters with the others. To further\navoid potential privacy leakage from sharing model parameters, we use\nfunctional mechanism to perturb the objective function of the neural network in\nthe training process to achieve $\\epsilon$-differential privacy. In particular,\nfor the first time, we consider the existence of~\\textit{unreliable\nparticipants}, i.e., the participants with low-quality data, and propose a\nsolution to reduce the impact of these participants while protecting their\nprivacy. We evaluate the performance of our system on two well-known real-world\ndatasets for regression and classification tasks. The results demonstrate that\nthe proposed system is robust against unreliable participants, and achieves\nhigh accuracy close to the model trained in a traditional centralized manner\nwhile ensuring rigorous privacy protection. \n\n"}
{"id": "1812.10199", "contents": "Title: A Multiversion Programming Inspired Approach to Detecting Audio\n  Adversarial Examples Abstract: Adversarial examples (AEs) are crafted by adding human-imperceptible\nperturbations to inputs such that a machine-learning based classifier\nincorrectly labels them. They have become a severe threat to the\ntrustworthiness of machine learning. While AEs in the image domain have been\nwell studied, audio AEs are less investigated. Recently, multiple techniques\nare proposed to generate audio AEs, which makes countermeasures against them an\nurgent task. Our experiments show that, given an AE, the transcription results\nby different Automatic Speech Recognition (ASR) systems differ significantly,\nas they use different architectures, parameters, and training datasets.\nInspired by Multiversion Programming, we propose a novel audio AE detection\napproach, which utilizes multiple off-the-shelf ASR systems to determine\nwhether an audio input is an AE. The evaluation shows that the detection\nachieves accuracies over 98.6%. \n\n"}
{"id": "1812.10217", "contents": "Title: Seeing isn't Believing: Practical Adversarial Attack Against Object\n  Detectors Abstract: In this paper, we presented systematic solutions to build robust and\npractical AEs against real world object detectors. Particularly, for Hiding\nAttack (HA), we proposed the feature-interference reinforcement (FIR) method\nand the enhanced realistic constraints generation (ERG) to enhance robustness,\nand for Appearing Attack (AA), we proposed the nested-AE, which combines two\nAEs together to attack object detectors in both long and short distance. We\nalso designed diverse styles of AEs to make AA more surreptitious. Evaluation\nresults show that our AEs can attack the state-of-the-art real-time object\ndetectors (i.e., YOLO V3 and faster-RCNN) at the success rate up to 92.4% with\nvarying distance from 1m to 25m and angles from -60{\\deg} to 60{\\deg}. Our AEs\nare also demonstrated to be highly transferable, capable of attacking another\nthree state-of-the-art black-box models with high success rate. \n\n"}
{"id": "1812.10345", "contents": "Title: Bitcoin Payment-channels for Resource Limited IoT Devices Abstract: Resource-constrained devices are unable to maintain a full copy of the\nBitcoin Blockchain in memory. This paper proposes a bidirectional payment\nchannel framework for IoT devices. This framework utilizes Bitcoin\nLightning-Network-like payment channels with low processing and storage\nrequirements. This protocol enables IoT devices to open and maintain payment\nchannels with traditional Bitcoin nodes without a view of the blockchain.\nUnlike existing solutions, it does not require a trusted third party to\ninteract with the blockchain nor does it burden the peer-to-peer network in the\nway SPV clients do. The contribution of this paper includes a secure and\ncrypto-economically fair protocol for bidirectional Bitcoin payment channels.\nIn addition, we demonstrate the security and fairness of the protocol by\nformulating it as a game in which the equilibrium is reached when all players\nfollow the protocol. \n\n"}
{"id": "1812.10748", "contents": "Title: Malicious Software Detection and Classification utilizing\n  Temporal-Graphs of System-call Group Relations Abstract: In this work we propose a graph-based model that, utilizing relations between\ngroups of System-calls, distinguishes malicious from benign software samples\nand classifies the detected malicious samples to one of a set of known malware\nfamilies. More precisely, given a System-call Dependency Graph (ScDG) that\ndepicts the malware's behavior, we first transform it to a more abstract\nrepresentation, utilizing the indexing of System-calls to a set of groups of\nsimilar functionality, constructing thus an abstract and mutation-tolerant\ngraph that we call Group Relation Graph (GrG); then, we construct another graph\nrepresentation, which we call Coverage Graph (CvG), that depicts the dominating\nrelations between the nodes of a GrG graph. Based on the research so far in the\nfield, we pointed out that behavior-based graph representations had not\nleveraged the aspect of the temporal evolution of the graph. Hence, the novelty\nof our work is that, preserving the initial representations of GrG and CvG\ngraphs, we focus on augmenting the potentials of theses graphs by adding\nfurther features that enhance its abilities on detecting and further\nclassifying to a known malware family an unknown malware sample. To that end,\nwe construct periodical instances of the graph that represent its temporal\nevolution concerning its structural modifications, creating another graph\nrepresentation that we call Temporal Graphs. In this paper, we present the\ntheoretical background behind our approach, discuss the current technological\nstatus on malware detection and classification and demonstrate the overall\narchitecture of our proposed detection and classification model alongside with\nits underlying main principles and its structural key-components. \n\n"}
{"id": "1812.10792", "contents": "Title: Analysis of Difficulty Control in Bitcoin and Proof-of-Work Blockchains Abstract: This paper presents a stochastic model for block arrival times based on the\ndifficulty retargeting rule used in Bitcoin, as well as other proof-of-work\nblockchains. Unlike some previous work, this paper explicitly models the\ndifficulty target as a random variable which is a function of the previous\nblock arrival times and affecting the block times in the next retargeting\nperiod. An explicit marginal distribution is derived for the time between\nsuccessive blocks (the blocktime), while allowing for randomly changing\ndifficulty. This paper also aims to serve as an introduction to Bitcoin and\nproof-of-work blockchains for the controls community, focusing on the\ndifficulty retargeting procedure used in Bitcoin. \n\n"}
{"id": "1812.11377", "contents": "Title: Hessian-Aware Zeroth-Order Optimization for Black-Box Adversarial Attack Abstract: Zeroth-order optimization is an important research topic in machine learning.\nIn recent years, it has become a key tool in black-box adversarial attack to\nneural network based image classifiers. However, existing zeroth-order\noptimization algorithms rarely extract second-order information of the model\nfunction. In this paper, we utilize the second-order information of the\nobjective function and propose a novel \\textit{Hessian-aware zeroth-order\nalgorithm} called \\texttt{ZO-HessAware}. Our theoretical result shows that\n\\texttt{ZO-HessAware} has an improved zeroth-order convergence rate and query\ncomplexity under structured Hessian approximation, where we propose a few\napproximation methods for estimating Hessian. Our empirical studies on the\nblack-box adversarial attack problem validate that our algorithm can achieve\nimproved success rates with a lower query complexity. \n\n"}
{"id": "1812.11596", "contents": "Title: Towards a CAN IDS based on a neural-network data field predictor Abstract: Modern vehicles contain a few controller area networks (CANs), which allow\nscores of on-board electronic control units (ECUs) to communicate messages\ncritical to vehicle functions and driver safety. CAN provide a lightweight and\nreliable broadcast protocol but is bereft of security features. As evidenced by\nmany recent research works, CAN exploits are possible both remotely and with\ndirect access, fueling a growing CAN intrusion detection system (IDS) body of\nresearch. A challenge for pioneering vehicle-agnostic IDSs is that passenger\nvehicles' CAN message encodings are proprietary, defined and held secret by\noriginal equipment manufacturers (OEMs). Targeting detection of next-generation\nattacks, in which messages are sent from the expected ECU at the expected time\nbut with malicious content, researchers are now seeking to leverage \"CAN data\nmodels\", which predict future CAN message contents and use prediction error to\nidentify anomalous, hopefully malicious CAN messages. Yet, current works model\nCAN signals post-translation, i.e., after applying OEM-donated or\nreverse-engineered translations from raw data. In this work, we present initial\nIDS results testing deep neural networks used to predict CAN data at the bit\nlevel, thereby providing IDS capabilities but avoiding reverse engineering\nproprietary encodings. Our results suggest the method is promising for\ncontinuous signals in CAN data, but struggles for discrete, e.g., binary,\nsignals. \n\n"}
{"id": "1812.11720", "contents": "Title: Stealing Neural Networks via Timing Side Channels Abstract: Deep learning is gaining importance in many applications. However, Neural\nNetworks face several security and privacy threats. This is particularly\nsignificant in the scenario where Cloud infrastructures deploy a service with\nNeural Network model at the back end. Here, an adversary can extract the Neural\nNetwork parameters, infer the regularization hyperparameter, identify if a data\npoint was part of the training data, and generate effective transferable\nadversarial examples to evade classifiers. This paper shows how a Neural\nNetwork model is susceptible to timing side channel attack. In this paper, a\nblack box Neural Network extraction attack is proposed by exploiting the timing\nside channels to infer the depth of the network. Although, constructing an\nequivalent architecture is a complex search problem, it is shown how\nReinforcement Learning with knowledge distillation can effectively reduce the\nsearch space to infer a target model. The proposed approach has been tested\nwith VGG architectures on CIFAR10 data set. It is observed that it is possible\nto reconstruct substitute models with test accuracy close to the target models\nand the proposed approach is scalable and independent of type of Neural Network\narchitectures. \n\n"}
{"id": "1901.00579", "contents": "Title: The Price of Free Illegal Live Streaming Services Abstract: As Internet streaming of live content has gained on traditional cable TV\nviewership, we have also seen significant growth of free live streaming\nservices which illegally provide free access to copyrighted content over the\nInternet. Some of these services draw millions of viewers each month. Moreover,\nthis viewership has continued to increase, despite the consistent coupling of\nthis free content with deceptive advertisements and user-hostile tracking.\n  In this paper, we explore the ecosystem of free illegal live streaming\nservices by collecting and examining the behavior of a large corpus of illegal\nsports streaming websites. We explore and quantify evidence of user tracking\nvia third-party HTTP requests, cookies, and fingerprinting techniques on more\nthan $27,303$ unique video streams provided by $467$ unique illegal live\nstreaming domains. We compare the behavior of illegal live streaming services\nwith legitimate services and find that the illegal services go to much greater\nlengths to track users than most legitimate services, and use more obscure\ntracking services. Similarly, we find that moderated sites that aggregate links\nto illegal live streaming content fail to moderate out sites that go to\nsignificant lengths to track users. In addition, we perform several case\nstudies which highlight deceptive behavior and modern techniques used by some\ndomains to avoid detection, monetize traffic, or otherwise exploit their\nviewers.\n  Overall, we find that despite recent improvements in mechanisms for detecting\nmalicious browser extensions, ad-blocking, and browser warnings, users of free\nillegal live streaming services are still exposed to deceptive ads, malicious\nbrowser extensions, scams, and extensive tracking. We conclude with insights\ninto the ecosystem and recommendations for addressing the challenges\nhighlighted by this study. \n\n"}
{"id": "1901.00798", "contents": "Title: Scalable Information-Flow Analysis of Secure Three-Party Affine\n  Computations Abstract: Elaborate protocols in Secure Multi-party Computation enable several\nparticipants to compute a public function of their own private inputs while\nensuring that no undesired information leaks about the private inputs, and\nwithout resorting to any trusted third party. However, the public output of the\ncomputation inevitably leaks some information about the private inputs. Recent\nworks have introduced a framework and proposed some techniques for quantifying\nsuch information flow. Yet, owing to their complexity, those methods do not\nscale to practical situations that may involve large input spaces. The main\ncontribution of the work reported here is to formally investigate the\ninformation flow captured by the min-entropy in the particular case of secure\nthree-party computations of affine functions in order to make its\nquantification scalable to realistic scenarios. To this end, we mathematically\nderive an explicit formula for this entropy under uniform prior beliefs about\nthe inputs. We show that this closed-form expression can be computed in time\nconstant in the inputs sizes and logarithmic in the coefficients of the affine\nfunction. Finally, we formulate some theoretical bounds for this privacy leak\nin the presence of non-uniform prior beliefs. \n\n"}
{"id": "1901.01148", "contents": "Title: Rational Threshold Cryptosystems Abstract: We propose a framework for threshold cryptosystems under a\npermissionless-economic model in which the participants are rational\nprofit-maximizing entities. To date, threshold cryptosystems have been\nconsidered under permissioned settings with a limited adversary. Our framework\nrelies on an escrow service that slashes and redistributes deposits to\nincentivize participants to adhere desired behaviors. Today, more than ever,\nsophisticated escrow services can be implemented over public blockchains like\nEthereum, without additional trust assumptions. The key threat to rational\nthreshold cryptosystems is collusion---by cooperating `illegally', a subset of\nparticipants can reveal the cryptosystem's secret, which, in turn is translated\nto unfair profit. Our countermeasure to collusion is framing. If the escrow is\nnotified of collusion, it rewards the framer and slashes the deposits of all\nother participants. We show that colluding parties find themselves in the\nprisoner's dilemma, where the dominant strategy is framing. \n\n"}
{"id": "1901.01292", "contents": "Title: VeriSolid: Correct-by-Design Smart Contracts for Ethereum Abstract: The adoption of blockchain based distributed ledgers is growing fast due to\ntheir ability to provide reliability, integrity, and auditability without\ntrusted entities. One of the key capabilities of these emerging platforms is\nthe ability to create self-enforcing smart contracts. However, the development\nof smart contracts has proven to be error-prone in practice, and as a result,\ncontracts deployed on public platforms are often riddled with security\nvulnerabilities. This issue is exacerbated by the design of these platforms,\nwhich forbids updating contract code and rolling back malicious transactions.\nIn light of this, it is crucial to ensure that a smart contract is secure\nbefore deploying it and trusting it with significant amounts of cryptocurrency.\nTo this end, we introduce the VeriSolid framework for the formal verification\nof contracts that are specified using a transition-system based model with\nrigorous operational semantics. Our model-based approach allows developers to\nreason about and verify contract behavior at a high level of abstraction.\nVeriSolid allows the generation of Solidity code from the verified models,\nwhich enables the correct-by-design development of smart contracts. \n\n"}
{"id": "1901.01598", "contents": "Title: Toward a Theory of Cyber Attacks Abstract: We provide a general methodology for analyzing defender-attacker based\n\"games\" in which we model such games as Markov models and introduce a capacity\nregion to analyze how defensive and adversarial strategies impact security.\nSuch a framework allows us to analyze under what kind of conditions we can\nprove statements (about an attack objective $k$) of the form \"if the attacker\nhas a time budget $T_{bud}$, then the probability that the attacker can reach\nan attack objective $\\geq k$ is at most $poly(T_{bud})negl(k)$\". We are\ninterested in such rigorous cryptographic security guarantees (that describe\nworst-case guarantees) as these shed light on the requirements of a defender's\nstrategy for preventing more and more the progress of an attack, in terms of\nthe \"learning rate\" of a defender's strategy. We explain the damage an attacker\ncan achieve by a \"containment parameter\" describing the maximally reached\nattack objective within a specific time window. \n\n"}
{"id": "1901.02348", "contents": "Title: Improving noise robustness of automatic speech recognition via parallel\n  data and teacher-student learning Abstract: For real-world speech recognition applications, noise robustness is still a\nchallenge. In this work, we adopt the teacher-student (T/S) learning technique\nusing a parallel clean and noisy corpus for improving automatic speech\nrecognition (ASR) performance under multimedia noise. On top of that, we apply\na logits selection method which only preserves the k highest values to prevent\nwrong emphasis of knowledge from the teacher and to reduce bandwidth needed for\ntransferring data. We incorporate up to 8000 hours of untranscribed data for\ntraining and present our results on sequence trained models apart from cross\nentropy trained ones. The best sequence trained student model yields relative\nword error rate (WER) reductions of approximately 10.1%, 28.7% and 19.6% on our\nclean, simulated noisy and real test sets respectively comparing to a sequence\ntrained teacher. \n\n"}
{"id": "1901.02438", "contents": "Title: Using fuzzy bits and neural networks to partially invert few rounds of\n  some cryptographic hash functions Abstract: We consider fuzzy, or continuous, bits, which take values in [0;1] and (-1;1]\ninstead of {0;1}, and operations on them (NOT, XOR etc.) and on their sequences\n(ADD), to obtain the generalization of cryptographic hash functions, CHFs, for\nthe messages consisting of fuzzy bits, so that CHFs become smooth and\nnon-constant functions of each bit of the message. We then train the neural\nnetworks to predict the message that has a given hash, where the loss function\nfor the hash of predicted message and given true hash is backpropagatable. The\nresults of the trainings for the standard CHFs - MD5, SHA1, SHA2-256, and\nSHA3/Keccak - with small number of (optionally weakened) rounds are presented\nand compared. \n\n"}
{"id": "1901.02590", "contents": "Title: Secure list decoding Abstract: We propose a new concept of secure list decoding. While the conventional list\ndecoding requires that the list contains the transmitted message, secure list\ndecoding requires the following additional security conditions. The first\nadditional security condition is the impossibility of the correct decoding,\ni.e., the receiver cannot uniquely identify the transmitted message even though\nthe transmitted message is contained in the list. This condition can be\ntrivially satisfied when the transmission rate is larger than the channel\ncapacity. The other additional security condition is the impossibility for the\nsender to estimate another element of the decoded list except for the\ntransmitted message. This protocol can be used for anonymous auction, which\nrealizes the anonymity for bidding. \n\n"}
{"id": "1901.03006", "contents": "Title: Extending Adversarial Attacks and Defenses to Deep 3D Point Cloud\n  Classifiers Abstract: 3D object classification and segmentation using deep neural networks has been\nextremely successful. As the problem of identifying 3D objects has many\nsafety-critical applications, the neural networks have to be robust against\nadversarial changes to the input data set. There is a growing body of research\non generating human-imperceptible adversarial attacks and defenses against them\nin the 2D image classification domain. However, 3D objects have various\ndifferences with 2D images, and this specific domain has not been rigorously\nstudied so far.\n  We present a preliminary evaluation of adversarial attacks on deep 3D point\ncloud classifiers, namely PointNet and PointNet++, by evaluating both white-box\nand black-box adversarial attacks that were proposed for 2D images and\nextending those attacks to reduce the perceptibility of the perturbations in 3D\nspace. We also show the high effectiveness of simple defenses against those\nattacks by proposing new defenses that exploit the unique structure of 3D point\nclouds. Finally, we attempt to explain the effectiveness of the defenses\nthrough the intrinsic structures of both the point clouds and the neural\nnetwork architectures. Overall, we find that networks that process 3D point\ncloud data are weak to adversarial attacks, but they are also more easily\ndefensible compared to 2D image classifiers. Our investigation will provide the\ngroundwork for future studies on improving the robustness of deep neural\nnetworks that handle 3D data. \n\n"}
{"id": "1901.03397", "contents": "Title: EmPoWeb: Empowering Web Applications with Browser Extensions Abstract: Browser extensions are third party programs, tightly integrated to browsers,\nwhere they execute with elevated privileges in order to provide users with\nadditional functionalities. Unlike web applications, extensions are not subject\nto the Same Origin Policy (SOP) and therefore can read and write user data on\nany web application. They also have access to sensitive user information\nincluding browsing history, bookmarks, cookies and list of installed\nextensions. Extensions have a permanent storage in which they can store data\nand can trigger the download of arbitrary files on the user's device. For\nsecurity reasons, browser extensions and web applications are executed in\nseparate contexts. Nonetheless, in all major browsers, extensions and web\napplications can interact by exchanging messages. Through these communication\nchannels, a web application can exploit extension privileged capabilities and\nthereby access and exfiltrate sensitive user information. In this work, we\nanalyzed the communication interfaces exposed to web applications by Chrome,\nFirefox and Opera browser extensions. As a result, we identified many\nextensions that web applications can exploit to access privileged capabilities.\nThrough extensions' APIS, web applications can bypass SOP, access user cookies,\nbrowsing history, bookmarks, list of installed extensions, extensions storage,\nand download arbitrary files on the user's device. Our results demonstrate that\nthe communications between browser extensions and web applications pose serious\nsecurity and privacy threats to browsers, web applications and more importantly\nto users. We discuss countermeasures and proposals, and believe that our study\nand in particular the tool we used to detect and exploit these threats, can be\nused as part of extensions review process by browser vendors to help them\nidentify and fix the aforementioned problems in extensions. \n\n"}
{"id": "1901.03535", "contents": "Title: PiNcH: an Effective, Efficient, and Robust Solution to Drone Detection\n  via Network Traffic Analysis Abstract: We propose PiNcH, a methodology to detect the presence of a drone, its\ncurrent status, and its movements by leveraging just the communication traffic\nexchanged between the drone and its Remote Controller (RC). PiNcH is built\napplying standard classification algorithms to the eavesdropped traffic,\nanalyzing features such as packets inter-arrival time and size. PiNcH is fully\npassive and it requires just cheap and general-purpose hardware. To evaluate\nthe effectiveness of our solution, we collected real communication traces\noriginated by a drone running the widespread ArduCopter open-source firmware,\ncurrently mounted on-board of a wide range (30+) of commercial amateur drones.\nWe tested our solution against different publicly available wireless traces.\nThe results prove that PiNcH can efficiently and effectively: (i) identify the\npresence of the drone in several heterogeneous scenarios; (ii) identify the\ncurrent state of a powered-on drone, i.e., flying or lying on the ground; (iii)\ndiscriminate the movements of the drone; and, finally, (iv) enjoy a reduced\nupper bound on the time required to identify a drone with the requested level\nof assurance. The effectiveness of PiNcH has been also evaluated in the\npresence of both heavy packet loss and evasion attacks. In this latter case,\nthe adversary modifies on purpose the profile of the traffic of the drone-RC\nlink to avoid the detection. In both the cited cases, PiNcH continues enjoying\na remarkable performance. Further, the comparison against state of the art\nsolution confirms the superior performance of PiNcH in several scenarios. Note\nthat all the drone-controller generated data traces have been released as\nopen-source, to allow replicability and foster follow-up. Finally, the quality\nand viability of our solution, do prove that network traffic analysis can be\nsuccessfully adopted for drone identification and status discrimination. \n\n"}
{"id": "1901.03597", "contents": "Title: CT-GAN: Malicious Tampering of 3D Medical Imagery using Deep Learning Abstract: In 2018, clinics and hospitals were hit with numerous attacks leading to\nsignificant data breaches and interruptions in medical services. An attacker\nwith access to medical records can do much more than hold the data for ransom\nor sell it on the black market.\n  In this paper, we show how an attacker can use deep-learning to add or remove\nevidence of medical conditions from volumetric (3D) medical scans. An attacker\nmay perform this act in order to stop a political candidate, sabotage research,\ncommit insurance fraud, perform an act of terrorism, or even commit murder. We\nimplement the attack using a 3D conditional GAN and show how the framework\n(CT-GAN) can be automated. Although the body is complex and 3D medical scans\nare very large, CT-GAN achieves realistic results which can be executed in\nmilliseconds.\n  To evaluate the attack, we focused on injecting and removing lung cancer from\nCT scans. We show how three expert radiologists and a state-of-the-art deep\nlearning AI are highly susceptible to the attack. We also explore the attack\nsurface of a modern radiology network and demonstrate one attack vector: we\nintercepted and manipulated CT scans in an active hospital network with a\ncovert penetration test.\n  Demo video: https://youtu.be/_mkRAArj-x0\n  Source code: https://github.com/ymirsky/CT-GAN \n\n"}
{"id": "1901.03706", "contents": "Title: Generating Adversarial Perturbation with Root Mean Square Gradient Abstract: We focus our attention on the problem of generating adversarial perturbations\nbased on the gradient in image classification domain \n\n"}
{"id": "1901.03899", "contents": "Title: Threats, Protection and Attribution of Cyber Attacks on Critical\n  Infrastructures Abstract: As Critical National Infrastructures are becoming more vulnerable to cyber\nattacks, their protection becomes a significant issue for any organization as\nwell as a nation. Moreover, the ability to attribute is a vital element of\navoiding impunity in cyberspace. In this article, we present main threats to\ncritical infrastructures along with protective measures that one nation can\ntake, and which are classified according to legal, technical, organizational,\ncapacity building, and cooperation aspects. Finally we provide an overview of\ncurrent methods and practices regarding cyber attribution and cyber peace\nkeeping \n\n"}
{"id": "1901.04100", "contents": "Title: LEP-CNN: A Lightweight Edge Device Assisted Privacy-preserving CNN\n  Inference Solution for IoT Abstract: Supporting convolutional neural network (CNN) inference on\nresource-constrained IoT devices in a timely manner has been an outstanding\nchallenge for emerging smart systems. To mitigate the burden on IoT devices,\nthe prevailing solution is to offload the CNN inference task, which is usually\ncomposed of billions of operations, to public cloud. However, the\n\"offloading-to-cloud\" solution may cause privacy breach while moving sensitive\ndata to cloud. For privacy protection, the research community has resorted to\nadvanced cryptographic primitives and approximation techniques to support CNN\ninference on encrypted data. Consequently, these attempts cause impractical\ncomputational overhead on IoT devices and degrade the performance of CNNs.\nMoreover, relying on the remote cloud can cause additional network latency and\neven make the system dysfunction when network connection is off.\n  We proposes an extremely lightweight edge device assisted private CNN\ninference solution for IoT devices, namely LEP-CNN. The main design of LEP-CNN\nis based on a novel online/offline encryption scheme. The decryption of LEP-CNN\nis pre-computed offline via utilizing the linear property of the most\ntime-consuming operations of CNNs. As a result, LEP-CNN allows IoT devices to\nsecurely offload over 99% CNN operations, and edge devices to execute CNN\ninference on encrypted data as efficient as on plaintext. LEP-CNN also provides\nan integrity check option to help IoT devices detect error results with a\nsuccessful rate over 99%. Experiments on AlexNet show that LEP-CNN can speed up\nthe CNN inference for more than 35 times for resource constrained IoT devices.\nA homomorphic encryption based AlexNet using CryptoNets is implemented to\ncompare with LEP-CNN to demonstrate that LEP-CNN has a better performance than\nhomomorphic encryption based privacy preserving neural networks under\ntime-sensitive scenarios. \n\n"}
{"id": "1901.04805", "contents": "Title: Early Detection Of Mirai-Like IoT Bots In Large-Scale Networks Through\n  Sub-Sampled Packet Traffic Analysis Abstract: The widespread adoption of Internet of Things has led to many security\nissues. Recently, there have been malware attacks on IoT devices, the most\nprominent one being that of Mirai. IoT devices such as IP cameras, DVRs and\nrouters were compromised by the Mirai malware and later large-scale DDoS\nattacks were propagated using those infected devices (bots) in October 2016. In\nthis research, we develop a network-based algorithm which can be used to detect\nIoT bots infected by Mirai or similar malware in large-scale networks (e.g. ISP\nnetwork). The algorithm particularly targets bots scanning the network for\nvulnerable devices since the typical scanning phase for botnets lasts for\nmonths and the bots can be detected much before they are involved in an actual\nattack. We analyze the unique signatures of the Mirai malware to identify its\npresence in an IoT device. The prospective deployment of our bot detection\nsolution is discussed next along with the countermeasures which can be taken\npost detection. Further, to optimize the usage of computational resources, we\nuse a two-dimensional (2D) packet sampling approach, wherein we sample the\npackets transmitted by IoT devices both across time and across the devices.\nLeveraging the Mirai signatures identified and the 2D packet sampling approach,\na bot detection algorithm is proposed. Subsequently, we use testbed\nmeasurements and simulations to study the relationship between bot detection\ndelays and the sampling frequencies for device packets. Finally, we derive\ninsights from the obtained results and use them to design our proposed bot\ndetection algorithm. \n\n"}
{"id": "1901.05107", "contents": "Title: Actions Speak Louder Than (Pass)words: Passive Authentication of\n  Smartphone Users via Deep Temporal Features Abstract: Prevailing user authentication schemes on smartphones rely on explicit user\ninteraction, where a user types in a passcode or presents a biometric cue such\nas face, fingerprint, or iris. In addition to being cumbersome and obtrusive to\nthe users, such authentication mechanisms pose security and privacy concerns.\nPassive authentication systems can tackle these challenges by frequently and\nunobtrusively monitoring the user's interaction with the device. In this paper,\nwe propose a Siamese Long Short-Term Memory network architecture for passive\nauthentication, where users can be verified without requiring any explicit\nauthentication step. We acquired a dataset comprising of measurements from 30\nsmartphone sensor modalities for 37 users. We evaluate our approach on 8\ndominant modalities, namely, keystroke dynamics, GPS location, accelerometer,\ngyroscope, magnetometer, linear accelerometer, gravity, and rotation sensors.\nExperimental results find that, within 3 seconds, a genuine user can be\ncorrectly verified 97.15% of the time at a false accept rate of 0.1%. \n\n"}
{"id": "1901.05347", "contents": "Title: Secure Cloud-Edge Deployments, with Trust Abstract: Assessing the security level of IoT applications to be deployed to\nheterogeneous Cloud-Edge infrastructures operated by different providers is a\nnon-trivial task. In this article, we present a methodology that permits to\nexpress security requirements for IoT applications, as well as infrastructure\nsecurity capabilities, in a simple and declarative manner, and to automatically\nobtain an explainable assessment of the security level of the possible\napplication deployments. The methodology also considers the impact of trust\nrelations among different stakeholders using or managing Cloud-Edge\ninfrastructures. A lifelike example is used to showcase the prototyped\nimplementation of the methodology. \n\n"}
{"id": "1901.06095", "contents": "Title: Taming Distrust in the Decentralized Internet with PIXIU Abstract: Decentralized Internet is booming. People are fascinated by its promise that\nusers can truly own their data. However, in a decentralized Internet,\ncompleting a task usually involves multiple nodes with mutual distrust. Such\ndistrust might eventually become a major obstacle for the growth of the\ndecentralized Internet. In this paper, we analyze the distrust using a simple\nmodel and highlight the properties required to faithfully accomplish one task\nin a decentralized Internet. We also introduce our draft solution -- PIXIU, a\nframework to mitigate the distrust among different nodes. In PIXIU, we design\nand utilize trust-{\\lambda} and decentralized executor to achieve the\nabove-needed properties. \n\n"}
{"id": "1901.07368", "contents": "Title: DCNN-GAN: Reconstructing Realistic Image from fMRI Abstract: Visualizing the perceptual content by analyzing human functional magnetic\nresonance imaging (fMRI) has been an active research area. However, due to its\nhigh dimensionality, complex dimensional structure, and small number of samples\navailable, reconstructing realistic images from fMRI remains challenging.\nRecently with the development of convolutional neural network (CNN) and\ngenerative adversarial network (GAN), mapping multi-voxel fMRI data to complex,\nrealistic images has been made possible. In this paper, we propose a model,\nDCNN-GAN, by combining a reconstruction network and GAN. We utilize the CNN for\nhierarchical feature extraction and the DCNN-GAN to reconstruct more realistic\nimages. Extensive experiments have been conducted, showing that our method\noutperforms previous works, regarding reconstruction quality and computational\ncost. \n\n"}
{"id": "1901.08449", "contents": "Title: CT synthesis from MR images for orthopedic applications in the lower arm\n  using a conditional generative adversarial network Abstract: Purpose: To assess the feasibility of deep learning-based high resolution\nsynthetic CT generation from MRI scans of the lower arm for orthopedic\napplications.\n  Methods: A conditional Generative Adversarial Network was trained to\nsynthesize CT images from multi-echo MR images. A training set of MRI and CT\nscans of 9 ex vivo lower arms was acquired and the CT images were registered to\nthe MRI images. Three-fold cross-validation was applied to generate independent\nresults for the entire dataset. The synthetic CT images were quantitatively\nevaluated with the mean absolute error metric, and Dice similarity and surface\nto surface distance on cortical bone segmentations.\n  Results: The mean absolute error was 63.5 HU on the overall tissue volume and\n144.2 HU on the cortical bone. The mean Dice similarity of the cortical bone\nsegmentations was 0.86. The average surface to surface distance between bone on\nreal and synthetic CT was 0.48 mm. Qualitatively, the synthetic CT images\ncorresponded well with the real CT scans and partially maintained high\nresolution structures in the trabecular bone. The bone segmentations on\nsynthetic CT images showed some false positives on tendons, but the general\nshape of the bone was accurately reconstructed.\n  Conclusions: This study demonstrates that high quality synthetic CT can be\ngenerated from MRI scans of the lower arm. The good correspondence of the bone\nsegmentations demonstrates that synthetic CT could be competitive with real CT\nin applications that depend on such segmentations, such as planning of\northopedic surgery and 3D printing. \n\n"}
{"id": "1901.08730", "contents": "Title: Better accuracy with quantified privacy: representations learned via\n  reconstructive adversarial network Abstract: The remarkable success of machine learning, especially deep learning, has\nproduced a variety of cloud-based services for mobile users. Such services\nrequire an end user to send data to the service provider, which presents a\nserious challenge to end-user privacy. To address this concern, prior works\neither add noise to the data or send features extracted from the raw data. They\nstruggle to balance between the utility and privacy because added noise reduces\nutility and raw data can be reconstructed from extracted features. This work\nrepresents a methodical departure from prior works: we balance between a\nmeasure of privacy and another of utility by leveraging adversarial learning to\nfind a sweeter tradeoff. We design an encoder that optimizes against the\nreconstruction error (a measure of privacy), adversarially by a Decoder, and\nthe inference accuracy (a measure of utility) by a Classifier. The result is\nRAN, a novel deep model with a new training algorithm that automatically\nextracts features for classification that are both private and useful. It turns\nout that adversarially forcing the extracted features to only conveys the\nintended information required by classification leads to an implicit\nregularization leading to better classification accuracy than the original\nmodel which completely ignores privacy. Thus, we achieve better privacy with\nbetter utility, a surprising possibility in machine learning! We conducted\nextensive experiments on five popular datasets over four training schemes, and\ndemonstrate the superiority of RAN compared with existing alternatives. \n\n"}
{"id": "1901.09113", "contents": "Title: Generative Adversarial Networks for Black-Box API Attacks with Limited\n  Training Data Abstract: As online systems based on machine learning are offered to public or paid\nsubscribers via application programming interfaces (APIs), they become\nvulnerable to frequent exploits and attacks. This paper studies adversarial\nmachine learning in the practical case when there are rate limitations on API\ncalls. The adversary launches an exploratory (inference) attack by querying the\nAPI of an online machine learning system (in particular, a classifier) with\ninput data samples, collecting returned labels to build up the training data,\nand training an adversarial classifier that is functionally equivalent and\nstatistically close to the target classifier. The exploratory attack with\nlimited training data is shown to fail to reliably infer the target classifier\nof a real text classifier API that is available online to the public. In\nreturn, a generative adversarial network (GAN) based on deep learning is built\nto generate synthetic training data from a limited number of real training data\nsamples, thereby extending the training data and improving the performance of\nthe inferred classifier. The exploratory attack provides the basis to launch\nthe causative attack (that aims to poison the training process) and evasion\nattack (that aims to fool the classifier into making wrong decisions) by\nselecting training and test data samples, respectively, based on the confidence\nscores obtained from the inferred classifier. These stealth attacks with small\nfootprint (using a small number of API calls) make adversarial machine learning\npractical under the realistic case with limited training data available to the\nadversary. \n\n"}
{"id": "1901.09136", "contents": "Title: Graphical-model based estimation and inference for differential privacy Abstract: Many privacy mechanisms reveal high-level information about a data\ndistribution through noisy measurements. It is common to use this information\nto estimate the answers to new queries. In this work, we provide an approach to\nsolve this estimation problem efficiently using graphical models, which is\nparticularly effective when the distribution is high-dimensional but the\nmeasurements are over low-dimensional marginals. We show that our approach is\nfar more efficient than existing estimation techniques from the privacy\nliterature and that it can improve the accuracy and scalability of many\nstate-of-the-art mechanisms. \n\n"}
{"id": "1901.09878", "contents": "Title: CapsAttacks: Robust and Imperceptible Adversarial Attacks on Capsule\n  Networks Abstract: Capsule Networks preserve the hierarchical spatial relationships between\nobjects, and thereby bears a potential to surpass the performance of\ntraditional Convolutional Neural Networks (CNNs) in performing tasks like image\nclassification. A large body of work has explored adversarial examples for\nCNNs, but their effectiveness on Capsule Networks has not yet been well\nstudied. In our work, we perform an analysis to study the vulnerabilities in\nCapsule Networks to adversarial attacks. These perturbations, added to the test\ninputs, are small and imperceptible to humans, but can fool the network to\nmispredict. We propose a greedy algorithm to automatically generate targeted\nimperceptible adversarial examples in a black-box attack scenario. We show that\nthis kind of attacks, when applied to the German Traffic Sign Recognition\nBenchmark (GTSRB), mislead Capsule Networks. Moreover, we apply the same kind\nof adversarial attacks to a 5-layer CNN and a 9-layer CNN, and analyze the\noutcome, compared to the Capsule Networks to study differences in their\nbehavior. \n\n"}
{"id": "1901.09942", "contents": "Title: On transaction parallelizability in Ethereum Abstract: Ethereum clients execute transactions in a sequential order prescribed by the\nconsensus protocol. This is a safe and conservative approach to blockchain\ntransaction processing which forgoes running transactions in parallel even when\ndoing so would be beneficial and safe, e.g., when there is no intersection in\nthe sets of accounts that the transactions read or modify. In this work we\nstudy the degree of transaction parallelizability and present results from\nthree different simulations using real Ethereum transaction data. Our\nsimulations demonstrate that notable gains are achievable with parallelization,\nand suggest that the potential for parallelizability improves as transaction\nrates increase. \n\n"}
{"id": "1901.10019", "contents": "Title: Blockchain Trilemma Solver Algorand has Dilemma over Undecidable\n  Messages Abstract: Recently, an ingenious protocol called Algorand has been proposed to overcome\nthese limitations. Algorand uses an innovative process - called cryptographic\nsortition - to securely and unpredictably elect a set of voters from the\nnetwork periodically. These voters are responsible for reaching consensus\nthrough a Byzantine Agreement (BA) protocol on one block per time, guaranteeing\nan overwhelming probability of linearity of the blockchain.\n  In this paper, we present a security analysis of Algorand. To the best of our\nknowledge, it is the first security analysis as well as the first formal study\non Algorand. We designed an attack scenario in which a group of malicious users\ntries to break the protocol, or at least limiting it to a reduced partition of\nnetwork users, by exploiting a possible security flaw in the messages\nvalidation process of the BA. Since the source code or an official simulator\nfor Algorand was not available at the time of our study, we created a simulator\n(which is available on request) to implement the protocol and assess the\nfeasibility of our attack scenario. Our attack requires the attacker to have a\ntrivial capability of establishing multiple connections with targeted nodes and\ncosts practically nothing to the attacker. Our results show that it is possible\nto slow down the message validation process on honest nodes, which eventually\nforces them to choose default values on the consensus; leaving the targeted\nnodes behind in the chain as compared to the non-attacked nodes. Even though\nour results are subject to the real implementation assumption, the core concept\nof our attack remains valid. \n\n"}
{"id": "1901.10590", "contents": "Title: Throttling Malware Families in 2D Abstract: Malicious software are categorized into families based on their static and\ndynamic characteristics, infection methods, and nature of threat. Visual\nexploration of malware instances and families in a low dimensional space helps\nin giving a first overview about dependencies and relationships among these\ninstances, detecting their groups and isolating outliers. Furthermore, visual\nexploration of different sets of features is useful in assessing the quality of\nthese sets to carry a valid abstract representation, which can be later used in\nclassification and clustering algorithms to achieve a high accuracy. In this\npaper, we investigate one of the best dimensionality reduction techniques known\nas t-SNE to reduce the malware representation from a high dimensional space\nconsisting of thousands of features to a low dimensional space. We experiment\nwith different feature sets and depict malware clusters in 2-D. Surprisingly,\nt-SNE does not only provide nice 2-D drawings, but also dramatically increases\nthe generalization power of SVM classifiers. Moreover, obtained results showed\nthat cross-validation accuracy is much better using the 2-D embedded\nrepresentation of samples than using the original high-dimensional\nrepresentation. \n\n"}
{"id": "1901.10794", "contents": "Title: Malicious cryptocurrency miners: Status and Outlook Abstract: In this study, we examine the behavior and profitability of modern malware\nthat mines cryptocurrency. Unlike previous studies, we look at the\ncryptocurrency market as a whole, rather than just Bitcoin. We not only\nconsider PCs, but also mobile phones, and IoT devices. In the past few years,\ncriminals have attacked all these platforms for the purpose of cryptocurrency\nmining. The question is: how much money do they make? It is common knowledge\nthat mining Bitcoin is now very difficult, so why do the criminals even target\nlow-end devices for mining purposes? By analyzing the most important families\nof malicious cryptocurrency miners that were active between 2014 and 2017, we\nare able to report how they work, which currency they mine, and how profitable\nit is to do so. We will see that the evolution of the cryptocurrency market\nwith many new cryptocurrencies that are still CPU minable and offer better\nprivacy to criminals and have contributed to making mining malware attractive\nagain -- with attackers generating a continuous stream of profit that in some\ncases may reach in the millions. \n\n"}
{"id": "cond-mat/0701319", "contents": "Title: Statistical Cryptography using a Fisher-Schr\\\"{o}dinger Model Abstract: A principled procedure to infer a hierarchy of statistical distributions\npossessing ill-conditioned eigenstructures, from incomplete constraints, is\npresented. The inference process of the \\textit{pdf}'s employs the Fisher\ninformation as the measure of uncertainty, and, utilizes a semi-supervised\nlearning paradigm based on a measurement-response model. The principle\nunderlying the learning paradigm involves providing a quantum mechanical\nconnotation to statistical processes. The inferred \\textit{pdf}'s constitute a\nstatistical host that facilitates the encryption/decryption of covert\ninformation (code). A systematic strategy to encrypt/decrypt code via unitary\nprojections into the \\textit{null spaces} of the ill-conditioned\neigenstructures, is presented. Numerical simulations exemplify the efficacy of\nthe model. \n\n"}
{"id": "cs/0110019", "contents": "Title: New approach for network monitoring and intrusion detection Abstract: The approach for a network behavior description in terms of numerical\ntime-dependant functions of the protocol parameters is suggested. This provides\na basis for application of methods of mathematical and theoretical physics for\ninformation flow analysis on network and for extraction of patterns of typical\nnetwork behavior. The information traffic can be described as a trajectory in\nmulti-dimensional parameter-time space with dimension about 10-12. Based on\nthis study some algorithms for the proposed intrusion detection system are\ndiscussed. \n\n"}
{"id": "cs/0301022", "contents": "Title: Homomorphic public-key cryptosystems and encrypting boolean circuits Abstract: In this paper homomorphic cryptosystems are designed for the first time over\nany finite group. Applying Barrington's construction we produce for any boolean\ncircuit of the logarithmic depth its encrypted simulation of a polynomial size\nover an appropriate finitely generated group. \n\n"}
{"id": "cs/0304013", "contents": "Title: Hidden Polynomial(s) Cryptosystems Abstract: We propose public-key cryptosystems with public key a system of polynomial\nequations, algebraic or differential, and private key a single polynomial or a\nsmall-size ideal. We set up probabilistic encryption, signature, and\nsigncryption protocols. \n\n"}
{"id": "cs/0401030", "contents": "Title: Pseudorandom number generation by $p$-adic ergodic transformations Abstract: The paper study counter-dependent pseudorandom generators; the latter are\ngenerators such that their state transition function (and output function) is\nbeing modified dynamically while working: For such a generator the recurrence\nsequence of states satisfies a congruence $x_{i+1}\\equiv f_i(x_i)\\pmod{2^n}$,\nwhile its output sequence is of the form $z_{i}=F_i(u_i)$. The paper introduces\ntechniques and constructions that enable one to compose generators that output\nuniformly distributed sequences of a maximum period length and with high linear\nand 2-adic spans. The corresponding stream chipher is provably strong against a\nknown plaintext attack (up to a plausible conjecture). Both state transition\nfunction and output function could be key-dependent, so the only information\navailable to a cryptanalyst is that these functions belong to some\n(exponentially large) class. These functions are compositions of standard\nmachine instructions (such as addition, multiplication, bitwise logical\noperations, etc.) The compositions should satisfy rather loose conditions; so\nthe corresponding generators are flexible enough and could be easily\nimplemented as computer programs. \n\n"}
{"id": "cs/0411003", "contents": "Title: Applications of LDPC Codes to the Wiretap Channel Abstract: With the advent of quantum key distribution (QKD) systems, perfect (i.e.\ninformation-theoretic) security can now be achieved for distribution of a\ncryptographic key. QKD systems and similar protocols use classical\nerror-correcting codes for both error correction (for the honest parties to\ncorrect errors) and privacy amplification (to make an eavesdropper fully\nignorant). From a coding perspective, a good model that corresponds to such a\nsetting is the wire tap channel introduced by Wyner in 1975. In this paper, we\nstudy fundamental limits and coding methods for wire tap channels. We provide\nan alternative view of the proof for secrecy capacity of wire tap channels and\nshow how capacity achieving codes can be used to achieve the secrecy capacity\nfor any wiretap channel. We also consider binary erasure channel and binary\nsymmetric channel special cases for the wiretap channel and propose specific\npractical codes. In some cases our designs achieve the secrecy capacity and in\nothers the codes provide security at rates below secrecy capacity. For the\nspecial case of a noiseless main channel and binary erasure channel, we\nconsider encoder and decoder design for codes achieving secrecy on the wiretap\nchannel; we show that it is possible to construct linear-time decodable secrecy\ncodes based on LDPC codes that achieve secrecy. \n\n"}
{"id": "cs/0411065", "contents": "Title: An Evaluated Certification Services System for the German National Root\n  CA - Legally Binding and Trustworthy Transactions in E-Business and\n  E-Government Abstract: National Root CAs enable legally binding E-Business and E-Government\ntransactions. This is a report about the development, the evaluation and the\ncertification of the new certification services system for the German National\nRoot CA. We illustrate why a new certification services system was necessary,\nand which requirements to the new system existed. Then we derive the tasks to\nbe done from the mentioned requirements. After that we introduce the initial\nsituation at the beginning of the project. We report about the very process and\ntalk about some unfamiliar situations, special approaches and remarkable\nexperiences. Finally we present the ready IT system and its impact to\nE-Business and E-Government. \n\n"}
{"id": "cs/0502048", "contents": "Title: An Automated Analysis of the Security of Quantum Key Distribution Abstract: This paper discusses the use of computer-aided verification as a practical\nmeans for analysing quantum information systems; specifically, the BB84\nprotocol for quantum key distribution is examined using this method. This\nprotocol has been shown to be unconditionally secure against all attacks in an\ninformation-theoretic setting, but the relevant security proof requires a\nthorough understanding of the formalism of quantum mechanics and is not easily\nadaptable to practical scenarios. Our approach is based on probabilistic\nmodel-checking; we have used the PRISM model-checker to show that, as the\nnumber of qubits transmitted in BB84 is increased, the equivocation of the\neavesdropper with respect to the channel decreases exponentially. We have also\nshown that the probability of detecting the presence of an eavesdropper\nincreases exponentially with the number of qubits. The results presented here\nare a testament to the effectiveness of the model-checking approach for systems\nwhere analytical solutions may not be possible or plausible. \n\n"}
{"id": "cs/0502062", "contents": "Title: Tree Parity Machine Rekeying Architectures Abstract: The necessity to secure the communication between hardware components in\nembedded systems becomes increasingly important with regard to the secrecy of\ndata and particularly its commercial use. We suggest a low-cost (i.e. small\nlogic-area) solution for flexible security levels and short key lifetimes. The\nbasis is an approach for symmetric key exchange using the synchronisation of\nTree Parity Machines. Fast successive key generation enables a key exchange\nwithin a few milliseconds, given realistic communication channels with a\nlimited bandwidth. For demonstration we evaluate characteristics of a\nstandard-cell ASIC design realisation as IP-core in 0.18-micrometer\nCMOS-technology. \n\n"}
{"id": "cs/0506003", "contents": "Title: Authentication and routing in simple Quantum Key Distribution networks Abstract: We consider various issues which arise as soon as one tries to practically\nimplement simple networks of quantum relays for QKD. In particular we discuss\nauthentication and routing which are essential ingredients of any QKD network.\nThis paper aims to address some gaps between quantum and networking aspects of\nQKD networks usually reserved to specialist in physics and computer science\nrespectively. \n\n"}
{"id": "cs/0509059", "contents": "Title: On an authentication scheme based on the Root Problem in the braid group Abstract: Lal and Chaturvedi proposed two authentication schemes based on the\ndifficulty of the Root Problem in the braid group. We point out that the first\nscheme is not really as secure as the Root Problem, and describe an efficient\nway to crack it. The attack works for any group. \n\n"}
{"id": "cs/0606032", "contents": "Title: A secure archive for Voice-over-IP conversations Abstract: An efficient archive securing the integrity of VoIP-based two-party\nconversations is presented. The solution is based on chains of hashes and\ncontinuously chained electronic signatures. Security is concentrated in a\nsingle, efficient component, allowing for a detailed analysis. \n\n"}
{"id": "cs/0607069", "contents": "Title: The B-Exponential Map: A Generalization of the Logistic Map, and Its\n  Applications In Generating Pseudo-random Numbers Abstract: A 1-dimensional generalization of the well known Logistic Map is proposed.\nThe proposed family of maps is referred to as the B-Exponential Map. The\ndynamics of this map are analyzed and found to have interesting properties. In\nparticular, the B-Exponential Map exhibits robust chaos for all real values of\nthe parameter B >= e^(-4). We then propose a pseudo-random number generator\nbased on the B-Exponential Map by chaotically hopping between different\ntrajectories for different values of B. We call this BEACH (B-Exponential\nAll-Chaotic Map Hopping) pseudo-random number generator. BEACH successfully\npasses stringent statistical randomness tests such as ENT, NIST and Diehard. An\nimplementation of BEACH is also outlined. \n\n"}
{"id": "cs/0607079", "contents": "Title: Length-based cryptanalysis: The case of Thompson's Group Abstract: The length-based approach is a heuristic for solving randomly generated\nequations in groups which possess a reasonably behaved length function. We\ndescribe several improvements of the previously suggested length-based\nalgorithms, that make them applicable to Thompson's group with significant\nsuccess rates. In particular, this shows that the Shpilrain-Ushakov public key\ncryptosystem based on Thompson's group is insecure, and suggests that no\npractical public key cryptosystem based on this group can be secure. \n\n"}
{"id": "math/0605232", "contents": "Title: Borne sur le degr\\'e des polyn\\^omes presque parfaitement\n  non-lin\\'eaires Abstract: The vectorial Boolean functions are employed in cryptography to build block\ncoding algorithms. An important criterion on these functions is their\nresistance to the differential cryptanalysis. Nyberg defined the notion of\nalmost perfect non-linearity (APN) to study resistance to the differential\nattacks. Up to now, the study of functions APN was especially devoted to power\nfunctions. Recently, Budaghyan and al. showed that certain quadratic\npolynomials were APN. Here, we will give a criterion so that a function is not\nalmost perfectly non-linear. H. Janwa showed, by using Weil's bound, that\ncertain cyclic codes could not correct two errors. A. Canteaut showed by using\nthe same method that the functions powers were not APN for a too large value of\nthe exponent. We use Lang and Weil's bound and a result of P. Deligne on the\nWeil's conjectures (or more exactly improvements given by Ghorpade and Lachaud)\nabout surfaces on finite fields to generalize this result to all the\npolynomials. We show therefore that a polynomial cannot be APN if its degree is\ntoo large. \n\n"}
{"id": "quant-ph/0111097", "contents": "Title: A proposal for founding mistrustful quantum cryptography on coin tossing Abstract: A significant branch of classical cryptography deals with the problems which\narise when mistrustful parties need to generate, process or exchange\ninformation. As Kilian showed a while ago, mistrustful classical cryptography\ncan be founded on a single protocol, oblivious transfer, from which general\nsecure multi-party computations can be built.\n  The scope of mistrustful quantum cryptography is limited by no-go theorems,\nwhich rule out, inter alia, unconditionally secure quantum protocols for\noblivious transfer or general secure two-party computations. These theorems\napply even to protocols which take relativistic signalling constraints into\naccount. The best that can be hoped for, in general, are quantum protocols\ncomputationally secure against quantum attack. I describe here a method for\nbuilding a classically certified bit commitment, and hence every other\nmistrustful cryptographic task, from a secure coin tossing protocol. No\nsecurity proof is attempted, but I sketch reasons why these protocols might\nresist quantum computational attack. \n\n"}
{"id": "quant-ph/0205128", "contents": "Title: Authentication of Quantum Messages Abstract: Authentication is a well-studied area of classical cryptography: a sender S\nand a receiver R sharing a classical private key want to exchange a classical\nmessage with the guarantee that the message has not been modified by any third\nparty with control of the communication line. In this paper we define and\ninvestigate the authentication of messages composed of quantum states. Assuming\nS and R have access to an insecure quantum channel and share a private,\nclassical random key, we provide a non-interactive scheme that enables S both\nto encrypt and to authenticate (with unconditional security) an m qubit message\nby encoding it into m+s qubits, where the failure probability decreases\nexponentially in the security parameter s. The classical private key is 2m+O(s)\nbits. To achieve this, we give a highly efficient protocol for testing the\npurity of shared EPR pairs. We also show that any scheme to authenticate\nquantum messages must also encrypt them. (In contrast, one can authenticate a\nclassical message while leaving it publicly readable.) This has two important\nconsequences: On one hand, it allows us to give a lower bound of 2m key bits\nfor authenticating m qubits, which makes our protocol asymptotically optimal.\nOn the other hand, we use it to show that digitally signing quantum states is\nimpossible, even with only computational security. \n\n"}
{"id": "quant-ph/0306118", "contents": "Title: Unconditionally Secure Multipartite Quantum Key Distribution Abstract: We consider the problem of secure key distribution among $n$ trustful agents:\nthe goal is to distribute an identical random bit-string among the $n$ agents\nover a noisy channel such that eavesdroppers learn little about it. We study\nthe general situation where the only resources required are secure bipartite\nkey distribution and authenticated classical communication. Accordingly,\nmultipartite quantum key distribution can be proven unconditionally secure by\nreducing the problem to the biparitite case and invoking the proof of security\nof bipartite quantum key distribution. \n\n"}
{"id": "quant-ph/0307200", "contents": "Title: Generalized Quantum Secret Sharing Abstract: We explore a generalization of quantum secret sharing (QSS) in which\nclassical shares play a complementary role to quantum shares, exploring further\nconsequences of an idea first studied by Nascimento, Mueller-Quade and Imai\n(Phys. Rev. {\\bf A64} 042311 (2001)). We examine three ways, termed inflation,\ncompression and twin-thresholding, by which the proportion of classical shares\ncan be augmented. This has the important application that it reduces quantum\n(information processing) players by replacing them with their classical\ncounterparts, thereby making quantum secret sharing considerably easier and\nless expensive to implement in a practical setting. In compression, a QSS\nscheme is turned into an equivalent scheme with fewer quantum players,\ncompensated for by suitable classical shares. In inflation, a QSS scheme is\nenlarged by adding only classical shares and players. In a twin-threshold\nscheme, we invoke two separate thresholds for classical and quantum shares\nbased on the idea of information dilution. \n\n"}
{"id": "quant-ph/0311064", "contents": "Title: Multipartite Bound Information exists and can be activated Abstract: We prove the conjectured existence of Bound Information, a classical analog\nof bound entanglement, in the multipartite scenario. We give examples of\ntripartite probability distributions from which it is impossible to extract any\nkind of secret key, even in the asymptotic regime, although they cannot be\ncreated by local operations and public communication. Moreover, we show that\nbound information can be activated: three honest parties can distill a common\nsecret key from different distributions having bound information. Our results\ndemonstrate that quantum information theory can provide useful insight for\nsolving open problems in classical information theory. \n\n"}
{"id": "quant-ph/0403076", "contents": "Title: Quantum key distribution using polarized coherent states Abstract: We discuss a continuous variables method of quantum key distribution\nemploying strongly polarized coherent states of light. The key encoding is\nperformed using the variables known as Stokes parameters, rather than the field\nquadratures. Their quantum counterpart, the Stokes operators $\\hat{S}_i$\n(i=1,2,3), constitute a set of non-commuting operators, being the precision of\nsimultaneous measurements of a pair of them limited by an uncertainty-like\nrelation. Alice transmits a conveniently modulated two-mode coherent state, and\nBob randomly measures one of the Stokes parameters of the incoming beam. After\nperforming reconciliation and privacy amplification procedures, it is possible\nto distill a secret common key. We also consider a non-ideal situation, in\nwhich coherent states with thermal noise, instead of pure coherent states, are\nused for encoding. \n\n"}
{"id": "quant-ph/0409201", "contents": "Title: Quantum Anonymous Transmissions Abstract: We consider the problem of hiding sender and receiver of classical and\nquantum bits (qubits), even if all physical transmissions can be monitored. We\npresent a quantum protocol for sending and receiving classical bits\nanonymously, which is completely traceless: it successfully prevents later\nreconstruction of the sender. We show that this is not possible classically. It\nappears that entangled quantum states are uniquely suited for traceless\nanonymous transmissions. We then extend this protocol to send and receive\nqubits anonymously. In the process we introduce a new primitive called\nanonymous entanglement, which may be useful in other contexts as well. \n\n"}
{"id": "quant-ph/0503139", "contents": "Title: Approximate Quantum Error-Correcting Codes and Secret Sharing Schemes Abstract: It is a standard result in the theory of quantum error-correcting codes that\nno code of length n can fix more than n/4 arbitrary errors, regardless of the\ndimension of the coding and encoded Hilbert spaces. However, this bound only\napplies to codes which recover the message exactly. Naively, one might expect\nthat correcting errors to very high fidelity would only allow small violations\nof this bound. This intuition is incorrect: in this paper we describe quantum\nerror-correcting codes capable of correcting up to (n-1)/2 arbitrary errors\nwith fidelity exponentially close to 1, at the price of increasing the size of\nthe registers (i.e., the coding alphabet). This demonstrates a sharp\ndistinction between exact and approximate quantum error correction. The codes\nhave the property that any $t$ components reveal no information about the\nmessage, and so they can also be viewed as error-tolerant secret sharing\nschemes.\n  The construction has several interesting implications for cryptography and\nquantum information theory. First, it suggests that secret sharing is a better\nclassical analogue to quantum error correction than is classical error\ncorrection. Second, it highlights an error in a purported proof that verifiable\nquantum secret sharing (VQSS) is impossible when the number of cheaters t is\nn/4. More generally, the construction illustrates a difference between exact\nand approximate requirements in quantum cryptography and (yet again) the\ndelicacy of security proofs and impossibility results in the quantum model. \n\n"}
{"id": "quant-ph/0503157", "contents": "Title: Secure Communication Using Qubits Abstract: A two-layer quantum protocol for secure transmission of data using qubits is\npresented. The protocol is an improvement over the BB84 QKD protocol. BB84, in\nconjunction with the one-time pad algorithm, has been shown to be\nunconditionally secure. However it suffers from two drawbacks: (1) Its security\nrelies on the assumption that Alice's qubit source is perfect in the sense that\nit does not inadvertently emit multiple copies of the same qubit. A multi-qubit\nemission attack can be launched if this assumption is violated. (2) BB84 cannot\ntransfer predetermined keys; the keys it can distribute are generated in the\nprocess. Our protocol does not have these drawbacks.\n  As in BB84, our protocol requires an authenticated public channel so as to\ndetect an intruder's interaction with the quantum channel, but unlike in\nsymmetric-key cryptography, the confidentiality of transmitted data does not\nrely on a shared secret key. \n\n"}
{"id": "quant-ph/0504207", "contents": "Title: Applications of quantum message sealing Abstract: In 2003, Bechmann-Pasquinucci introduced the concept of quantum seals, a\nquantum analogue to wax seals used to close letters and envelopes. Since then,\nsome improvements on the method have been found. We first review the current\nquantum sealing techniques, then introduce and discuss potential applications\nof quantum message sealing, and conclude with some discussion of the\nlimitations of quantum seals. \n\n"}
{"id": "quant-ph/0508072", "contents": "Title: Generic Security Proof of Quantum Key Exchange using Squeezed States Abstract: Recently, a Quantum Key Exchange protocol that uses squeezed states was\npresented by Gottesman and Preskill. In this paper we give a generic security\nproof for this protocol. The method used for this generic security proof is\nbased on recent work by Christiandl, Renner and Ekert. \n\n"}
{"id": "quant-ph/9611031", "contents": "Title: Insecurity of Quantum Secure Computations Abstract: It had been widely claimed that quantum mechanics can protect private\ninformation during public decision in for example the so-called two-party\nsecure computation. If this were the case, quantum smart-cards could prevent\nfake teller machines from learning the PIN (Personal Identification Number)\nfrom the customers' input. Although such optimism has been challenged by the\nrecent surprising discovery of the insecurity of the so-called quantum bit\ncommitment, the security of quantum two-party computation itself remains\nunaddressed. Here I answer this question directly by showing that all\n``one-sided'' two-party computations (which allow only one of the two parties\nto learn the result) are necessarily insecure. As corollaries to my results,\nquantum one-way oblivious password identification and the so-called quantum\none-out-of-two oblivious transfer are impossible. I also construct a class of\nfunctions that cannot be computed securely in any ``two-sided'' two-party\ncomputation. Nevertheless, quantum cryptography remains useful in key\ndistribution and can still provide partial security in ``quantum money''\nproposed by Wiesner. \n\n"}
{"id": "quant-ph/9810068", "contents": "Title: Unconditionally Secure Bit Commitment Abstract: We describe a new classical bit commitment protocol based on cryptographic\nconstraints imposed by special relativity. The protocol is unconditionally\nsecure against classical or quantum attacks. It evades the no-go results of\nMayers, Lo and Chau by requiring from Alice a sequence of communications,\nincluding a post-revelation verification, each of which is guaranteed to be\nindependent of its predecessor. \n\n"}
{"id": "quant-ph/9904091", "contents": "Title: A simple proof of the unconditional security of quantum key distribution Abstract: Quantum key distribution is the most well-known application of quantum\ncryptography. Previous proposed proofs of security of quantum key distribution\ncontain various technical subtleties. Here, a conceptually simpler proof of\nsecurity of quantum key distribution is presented. The new insight is the\ninvariance of the error rate of a teleportation channel: We show that the error\nrate of a teleportation channel is independent of the signals being\ntransmitted. This is because the non-trivial error patterns are permuted under\nteleportation. This new insight is combined with the recently proposed quantum\nto classical reduction theorem. Our result shows that assuming that Alice and\nBob have fault-tolerant quantum computers, quantum key distribution can be made\nunconditionally secure over arbitrarily long distances even against the most\ngeneral type of eavesdropping attacks and in the presence of all types of\nnoises. \n\n"}
